<!DOCTYPE html><html lang="en"><head><title>Help for package localICE</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {localICE}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#localICE'>
<p>Local Individual Conditional Expectation (localICE)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Local Individual Conditional Expectation</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Martin Walter &lt;mf-walter@web.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Local Individual Conditional Expectation ('localICE') is a local explanation approach from the field of eXplainable Artificial Intelligence (XAI). localICE is a model-agnostic XAI approach which provides three-dimensional local explanations for particular data instances. The approach is proposed in the master thesis of Martin Walter as an extension to ICE (see Reference). The three dimensions are the two features at the horizontal and vertical axes as well as the target represented by different colors. The approach is applicable for classification and regression problems to explain interactions of two features towards the target. For classification models, the number of classes can be more than two and each class is added as a different color to the plot. The given instance is added to the plot as two dotted lines according to the feature values. The localICE-package can explain features of type factor and numeric of any machine learning model. Automatically supported machine learning packages are 'mlr', 'randomForest', 'caret' or all other with an S3 predict function. For further model types from other libraries, a predict function has to be provided as an argument in order to get access to the model. Reference to the ICE approach: Alex Goldstein, Adam Kapelner, Justin Bleich, Emil Pitkin (2013) &lt;<a href="https://doi.org/10.48550/arXiv.1309.6392">doi:10.48550/arXiv.1309.6392</a>&gt;. </td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/viadee/localICE">https://github.com/viadee/localICE</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/viadee/localICE/issues">https://github.com/viadee/localICE/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/BSD-3-Clause">BSD_3_clause</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, checkmate</td>
</tr>
<tr>
<td>Suggests:</td>
<td>covr, h2o, mlbench, randomForest, stats, testthat, utils</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.0.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-02-07 21:30:03 UTC; WALMAR2</td>
</tr>
<tr>
<td>Author:</td>
<td>Martin Walter [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-02-07 23:20:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='localICE'>
Local Individual Conditional Expectation (localICE)
</h2><span id='topic+localICE'></span>

<h3>Description</h3>

<p>Local Individual Conditional Expectation (localICE) is a local explanation approach from the field of eXplainable Artificial Intelligence (XAI). It is proposed in the master thesis of the author of this package as an extension to ICE and is a three-dimensional local explanation for particular data instances. The three dimensions are the two features at the horizontal and vertical axes as well as the target represented by different colors. The approach is applicable for classification and regression problems to explain interactions of two features towards the target. The plot for discrete targets looks similar to plots of cluster algorithms like k-means, where different clusters represent different predictions. The given <code>instance</code> is added to the plot as two dotted lines according to the feature values. The <code>localICE</code>-package can explain features of type <code>factor</code> and <code>numeric</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>localICE(
  instance,
  data,
  feature_1,
  feature_2,
  target,
  model,
  predict.fun = NULL,
  regression = TRUE,
  step_1 = 1,
  step_2 = 1
  )
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="localICE_+3A_instance">instance</code></td>
<td>
<p>instance is a row of <code>data</code> that has to be explained by means of localICE.
</p>
</td></tr>
<tr><td><code id="localICE_+3A_data">data</code></td>
<td>
<p>a data frame containing all predictors and a representative distribution of data instances (rows). The data set can be the test data from model creation and does not have to contain predictions or true labels. The data set is needed to get the data distribution of <code>feature_1</code> and <code>feature_2</code> that should be explained for the given <code>instance</code>. The data distribution is then used to perturb the values of the two given features.</p>
</td></tr>
<tr><td><code id="localICE_+3A_feature_1">feature_1</code></td>
<td>
<p>a feature of interest as <code>character</code></p>
</td></tr>
<tr><td><code id="localICE_+3A_feature_2">feature_2</code></td>
<td>
<p>an other feature of interest as <code>character</code></p>
</td></tr>
<tr><td><code id="localICE_+3A_target">target</code></td>
<td>
<p>the name of the target as <code>character</code>. It is required to name the legend of the plot.</p>
</td></tr>
<tr><td><code id="localICE_+3A_model">model</code></td>
<td>
<p>a machine learning model as object.</p>
</td></tr>
<tr><td><code id="localICE_+3A_predict.fun">predict.fun</code></td>
<td>
<p>a prediction function if <code>model</code> is not of type <code>randomForest</code>, <code>mlr</code> or <code>caret</code>. An exemplary function for the machine learning library <code>h2o</code> is shown below in the &quot;Examples&quot; section</p>
</td></tr>
<tr><td><code id="localICE_+3A_regression">regression</code></td>
<td>
<p>if the model is not a regression problem but a classification problem, then set <code>regression = FALSE</code>.</p>
</td></tr>
<tr><td><code id="localICE_+3A_step_1">step_1</code></td>
<td>
<p>set how accurate the explanation according to <code>feature_1</code> should be. Step is only required if <code>feature_1</code> is numeric. The greater the step, the faster the computation and the less accurate the explanation for <code>feature_1</code>. The step has to be smaller than <code>max(data[,feature_1]) - min(data[,feature_1])</code> and greater than <code>0</code>. For integer features, the step should also be an integer to avoid biased model predictions.</p>
</td></tr>
<tr><td><code id="localICE_+3A_step_2">step_2</code></td>
<td>
<p>same as <code>step_1</code> but for <code>feature_2</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The computation time of <code>localICE</code> is strongly dependent to the distribution of <code>feature_1</code>, <code>feature_2</code> and the steps <code>step_1</code> and <code>step_2</code> for numerical features.</p>


<h3>Value</h3>

<p>The function <code>localICE</code> returns a <code>ggplot2</code> object that can be modified with further <code>ggplot2</code> functions.</p>


<h3>References</h3>

<p>Goldstein, Alex; Kapelner, Adam; Bleich, Justin; Pitkin, Emil (2013): &quot;Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation&quot;. In: Journal of Computational and Graphical Statistics 24.1 (2013), pp. 44-65. doi: 10.1080/10618600.2014.907095. url: https://doi.org/10.1080/10618600.2014.907095
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Regression example:
if(require("randomForest")){
  rf = randomForest(Sepal.Length ~., data = iris, ntree = 20)

  explanation = localICE(
    instance = iris[1, ],
    data = iris,
    feature_1 = "Species",
    feature_2 = "Sepal.Width",
    target = "Sepal.Length",
    model = rf,
    regression = TRUE,
    step_2 = 0.1
  )
  plot(explanation)
}

# Classification example:
if(require("randomForest") &amp;&amp; require("mlbench")){
  data("PimaIndiansDiabetes")
  rf = randomForest(diabetes ~., data = PimaIndiansDiabetes, ntree = 20)

  explanation = localICE(
    instance = PimaIndiansDiabetes[8, ],
    data = PimaIndiansDiabetes,
    feature_1 = "age",
    feature_2 = "glucose",
    target = "diabetes",
    model = rf,
    regression = FALSE,
    step_1 = 5,
    step_2 = 5
  )
  plot(explanation)
}
# An example of how to use predict.fun to use any machine learning library,
# in this case the library h2o (please see GitHub for the complete h2o example):
predict.fun = function(model, newdata){
  prediction = h2o.predict(model, as.h2o(newdata))
  prediction = as.data.frame(prediction)
  prediction = prediction$prediction
  return(prediction)
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
