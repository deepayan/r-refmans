<!DOCTYPE html><html><head><title>Help for package bigstep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bigstep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aic'><p>AIC</p></a></li>
<li><a href='#backward'><p>Backward step</p></a></li>
<li><a href='#bic'><p>BIC</p></a></li>
<li><a href='#bigstep'><p>Model selection</p></a></li>
<li><a href='#fast_forward'><p>Fast-forward step</p></a></li>
<li><a href='#forward'><p>Forward step</p></a></li>
<li><a href='#get_model'><p>Get the model</p></a></li>
<li><a href='#maic'><p>mAIC</p></a></li>
<li><a href='#maic2'><p>mAIC2</p></a></li>
<li><a href='#mbic'><p>mBIC</p></a></li>
<li><a href='#mbic2'><p>mBIC2</p></a></li>
<li><a href='#multi_backward'><p>Multi-backward step</p></a></li>
<li><a href='#prepare_data'><p>Data preparation</p></a></li>
<li><a href='#reduce_matrix'><p>Reducing number of variables</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#stepwise'><p>Stepwise</p></a></li>
<li><a href='#summary.big'><p>Summarizing model fit</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Stepwise Selection for Large Data Sets</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-5-11</td>
</tr>
<tr>
<td>Description:</td>
<td>Selecting linear and generalized linear models for large data sets
    using modified stepwise procedure and modern selection criteria (like
    modifications of Bayesian Information Criterion). Selection can be 
    performed on data which exceed RAM capacity. Bogdan et al., (2004)
    &lt;<a href="https://doi.org/10.1534%2Fgenetics.103.021683">doi:10.1534/genetics.103.021683</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/pmszulc/bigstep">https://github.com/pmszulc/bigstep</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/pmszulc/bigstep/issues">https://github.com/pmszulc/bigstep/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bigmemory, magrittr, matrixStats, R.utils, RcppEigen,
speedglm, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>devtools, knitr, rmarkdown, testthat</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-11 14:03:12 UTC; Piotr</td>
</tr>
<tr>
<td>Author:</td>
<td>Piotr Szulc [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Piotr Szulc &lt;piotr.michal.szulc@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-13 23:12:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='aic'>AIC</h2><span id='topic+aic'></span>

<h3>Description</h3>

<p>Calculate AIC (Akaike Information Criterion).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aic(loglik, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aic_+3A_loglik">loglik</code></td>
<td>
<p>A numeric, the log-likelihood.</p>
</td></tr>
<tr><td><code id="aic_+3A_k">k</code></td>
<td>
<p>An integer &gt;= 0, the number of selected variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number, a value of AIC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>aic(10, 5)
</code></pre>

<hr>
<h2 id='backward'>Backward step</h2><span id='topic+backward'></span>

<h3>Description</h3>

<p>Remove the worst variable from a model according to the given criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>backward(data, crit = mbic, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="backward_+3A_data">data</code></td>
<td>
<p>an object of class <code>big</code>.</p>
</td></tr>
<tr><td><code id="backward_+3A_crit">crit</code></td>
<td>
<p>a function defining the model selection criterion. You can use
your own function or one of these: <code>bic</code>, <code>mbic</code>, <code>mbic2</code>,
<code>aic</code>, <code>maic</code>, <code>maic2</code>.</p>
</td></tr>
<tr><td><code id="backward_+3A_...">...</code></td>
<td>
<p>optional arguments to <code>crit</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type <code>browseVignettes("bigstep")</code> for more details.
</p>


<h3>Value</h3>

<p>An object of class <code>big</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 30
p &lt;- 10
X &lt;- matrix(rnorm(n * p), ncol = p)
y &lt;- X[, 2] + 2*X[, 3] - X[, 6] + rnorm(n)
d &lt;- prepare_data(y, X)
d %&gt;%
  fast_forward(crit = aic) %&gt;%
  backward() %&gt;%
  backward()

</code></pre>

<hr>
<h2 id='bic'>BIC</h2><span id='topic+bic'></span>

<h3>Description</h3>

<p>Calculate BIC (Bayesian Information Criterion).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bic(loglik, k, n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bic_+3A_loglik">loglik</code></td>
<td>
<p>A numeric, the log-likelihood.</p>
</td></tr>
<tr><td><code id="bic_+3A_k">k</code></td>
<td>
<p>An integer &gt;= 0, the number of selected variables.</p>
</td></tr>
<tr><td><code id="bic_+3A_n">n</code></td>
<td>
<p>An integer &gt; 0, the number of observations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number, a value of BIC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bic(10, 5, 100)
</code></pre>

<hr>
<h2 id='bigstep'>Model selection</h2><span id='topic+bigstep'></span>

<h3>Description</h3>

<p>Model selection using the stepwise procedure and the chosen criterion.
</p>


<h3>Details</h3>

<p>The main goal of the package <code>bigstep</code> is to allow you to select a
regression model using the stepwise procedure when data is very big,
potentially larger than available RAM in your computer. What is more, the
package gives you a lot of control over how this procedure should look like.
At this moment, you can use one of these functions: <code>stepwise</code>,
<code>forward</code>, <code>backward</code>, <code>fast_forward</code>, <code>multi_backward</code>
and combinations of them. They can be treated as blocks from which the whole
procedure of finding the best model is built.
</p>
<p>When your data is larger than RAM you have in your computer, it is
impossible to read it in a normal way. Fortunately, in a process of building
a regression model it is not necessary to have access to all predictors at the
same time. Instead, you can read only a part of the matrix <code>X</code>, check
all variables from that part and then read another one. To do that with this
package, you only need to read the matrix <code>X</code> using
<code>read.big.matrix</code> from <code>bigmemory</code> package. The <code>prepare_data</code>
function has a parameter <code>maxp</code> which represents the maximum size (that
is the number of elements) of one part. If <code>X</code> is bigger, it will be
split. It will be done even if your matrix is big but you have enough RAM
to read it in a normal way. It may seem unnecessary, but it is worth to do
because R is not very efficient in dealing with big matrices.
</p>
<p>Another problem with a large number of predictors is choosing an appropriate
criterion. Classical ones like AIC or BIC are bad choice because they will
almost certainly select a model with two many variables [1]. You can use
modifications of them like mBIC [2], mBIC2 [3], mAIC or mAIC2. In brief,
these criteria have much heavier penalty for the number of parameters, so
they prefer smaller models than their classic versions.
</p>
<p>If you want to read more, type <code>browseVignettes("bigstep")</code>
</p>


<h3>Author(s)</h3>

<p>Piotr Szulc
</p>


<h3>References</h3>

<p>[1] M. Bogdan, J.K. Ghosh, M. Zak-Szatkowska. Selecting explanatory
variables with the modified version of Bayesian Information Criterion.
Quality and Reliability Engineering International, 24:989-999, 2008.
</p>
<p>[2] M. Bogdan, J.K. Ghosh, R.W. Doerge. Modifying the Schwarz Bayesian
Information Criterion to locate multiple interacting quantitative trait loci.
Genetics, 167:989-999, 2004.
</p>
<p>[3] F. Frommlet, A. Chakrabarti, M. Murawska, M. Bogdan. Asymptotic Bayes
optimality under sparsity for general distributions under the alternative,
Technical report, arXiv:1005.4753v2, 2011.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(bigstep)

### small data
set.seed(1)
n &lt;- 200
p &lt;- 20
X &lt;- matrix(rnorm(n * p), ncol = p)
colnames(X) &lt;- paste0("X", 1:p)
y &lt;- 1 + 0.4 * rowSums(X[, c(5, 10, 15, 20)]) + rnorm(n)

data &lt;- prepare_data(y, X)
results &lt;- stepwise(data, crit = aic)
results$model
summary(results)

### bigger data
set.seed(1)
n &lt;- 1e3
p &lt;- 1e4
X &lt;- matrix(rnorm(p * n), ncol = p)
colnames(X) &lt;- paste0("X", 1:p)
Xadd &lt;- matrix(rnorm(5 * n), n, 5)  # additional variables
colnames(Xadd) &lt;- paste0("Xadd", 1:5)
y &lt;- 0.2 * rowSums(X[, 1000 * (1:10)]) + Xadd[, 1] - 0.1 * Xadd[, 3] + rnorm(n)

data &lt;- prepare_data(y, X, Xadd = Xadd)
data %&gt;%
  reduce_matrix(minpv = 0.15) %&gt;%
  stepwise(mbic) -&gt;
  results
summary(results)

### big data
Xbig &lt;- read.big.matrix("X.txt", sep = " ", header = TRUE,
                        backingfile = "X.bin", descriptorfile = "X.desc")
# Xbig &lt;- attach.big.matrix("X.desc") # much faster
y &lt;- read.table("y.txt")
# data &lt;- prepare_data(y, Xbig) # slow because of checking NA
data &lt;- prepare_data(y, Xbig, na = FALSE) # set if you know that you do not have NA
m &lt;- data %&gt;%
  reduce_matrix(minpv = 0.001) %&gt;%
  fast_forward(crit = bic, maxf = 50) %&gt;%
  multi_backward(crit = mbic) %&gt;%
  stepwise(crit = mbic)
summary(m)

# more examples: type browseVignettes("bigstep")

## End(Not run)

</code></pre>

<hr>
<h2 id='fast_forward'>Fast-forward step</h2><span id='topic+fast_forward'></span>

<h3>Description</h3>

<p>Add variables to a model as long as they reduce the given criterion.
Variables are searched according to <code>candidates</code> and every one which
reduces the criterion is added (not necessarily the best one).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fast_forward(data, crit = bic, ..., maxf = 70)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fast_forward_+3A_data">data</code></td>
<td>
<p>an object of class <code>big</code>.</p>
</td></tr>
<tr><td><code id="fast_forward_+3A_crit">crit</code></td>
<td>
<p>a function defining the model selection criterion. You can use
your own function or one of these: <code>bic</code>, <code>mbic</code>, <code>mbic2</code>,
<code>aic</code>, <code>maic</code>, <code>maic2</code>.</p>
</td></tr>
<tr><td><code id="fast_forward_+3A_...">...</code></td>
<td>
<p>optional arguments to <code>crit</code>.</p>
</td></tr>
<tr><td><code id="fast_forward_+3A_maxf">maxf</code></td>
<td>
<p>a numeric, a maximal number of variables in the final model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type <code>browseVignettes("bigstep")</code> for more details.
</p>


<h3>Value</h3>

<p>An object of class <code>big</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 30
p &lt;- 10
X &lt;- matrix(rnorm(n * p), ncol = p)
y &lt;- X[, 2] + 2*X[, 3] - X[, 6] + rnorm(n)
d &lt;- prepare_data(y, X)
fast_forward(d)
</code></pre>

<hr>
<h2 id='forward'>Forward step</h2><span id='topic+forward'></span>

<h3>Description</h3>

<p>Add the best variable to a model according to the given criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forward(data, crit = mbic, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forward_+3A_data">data</code></td>
<td>
<p>an object of class <code>big</code>.</p>
</td></tr>
<tr><td><code id="forward_+3A_crit">crit</code></td>
<td>
<p>a function defining the model selection criterion. You can use
your own function or one of these: <code>bic</code>, <code>mbic</code>, <code>mbic2</code>,
<code>aic</code>, <code>maic</code>, <code>maic2</code>.</p>
</td></tr>
<tr><td><code id="forward_+3A_...">...</code></td>
<td>
<p>optional arguments to <code>crit</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type <code>browseVignettes("bigstep")</code> for more details.
</p>


<h3>Value</h3>

<p>An object of class <code>big</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 30
p &lt;- 10
X &lt;- matrix(rnorm(n * p), ncol = p)
y &lt;- X[, 2] + 2*X[, 3] - X[, 6] + rnorm(n)
d &lt;- prepare_data(y, X)
forward(d, crit = bic)
d %&gt;%
  forward() %&gt;%
  forward() %&gt;%
  forward()

</code></pre>

<hr>
<h2 id='get_model'>Get the model</h2><span id='topic+get_model'></span>

<h3>Description</h3>

<p>Extract the model (an object of class <code>lm</code>) from an object of class <code>big</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_model(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_model_+3A_object">object</code></td>
<td>
<p>an object of class <code>big</code>.</p>
</td></tr>
<tr><td><code id="get_model_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to or from other methods. They are
ignored in this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>lm</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 30
p &lt;- 10
X &lt;- matrix(rnorm(n * p), ncol = p)
y &lt;- X[, 2] + 2*X[, 3] - X[, 6] + rnorm(n)
d &lt;- prepare_data(y, X)
m &lt;- stepwise(d)
get_model(m)
</code></pre>

<hr>
<h2 id='maic'>mAIC</h2><span id='topic+maic'></span>

<h3>Description</h3>

<p>Calculate mAIC (modified Akaike Information Criterion).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maic(loglik, k, p, const = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maic_+3A_loglik">loglik</code></td>
<td>
<p>A numeric, the log-likelihood.</p>
</td></tr>
<tr><td><code id="maic_+3A_k">k</code></td>
<td>
<p>An integer &gt;= 0, the number of selected variables.</p>
</td></tr>
<tr><td><code id="maic_+3A_p">p</code></td>
<td>
<p>An integer &gt; 0, the number of all variables or a weight.</p>
</td></tr>
<tr><td><code id="maic_+3A_const">const</code></td>
<td>
<p>A numeric &gt; 0, the expected number of significant variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number, a value of mAIC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>maic(10, 5, 100, 50)
</code></pre>

<hr>
<h2 id='maic2'>mAIC2</h2><span id='topic+maic2'></span>

<h3>Description</h3>

<p>Calculate mAIC2 (the second version of modified Akaike Information
Criterion).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maic2(loglik, k, n, p, const = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maic2_+3A_loglik">loglik</code></td>
<td>
<p>A numeric, the log-likelihood.</p>
</td></tr>
<tr><td><code id="maic2_+3A_k">k</code></td>
<td>
<p>An integer &gt;= 0, the number of selected variables.</p>
</td></tr>
<tr><td><code id="maic2_+3A_n">n</code></td>
<td>
<p>An integer &gt; 0, the number of observations, used only to check if k
is not too large.</p>
</td></tr>
<tr><td><code id="maic2_+3A_p">p</code></td>
<td>
<p>An integer &gt; 0, the number of all variables or a weight.</p>
</td></tr>
<tr><td><code id="maic2_+3A_const">const</code></td>
<td>
<p>A numeric &gt; 0, the expected number of significant variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number, a value of mAIC2.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>maic2(10, 5, 100, 50)
</code></pre>

<hr>
<h2 id='mbic'>mBIC</h2><span id='topic+mbic'></span>

<h3>Description</h3>

<p>Calculate mBIC (modified Bayesian Information Criterion).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mbic(loglik, k, n, p, const = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mbic_+3A_loglik">loglik</code></td>
<td>
<p>A numeric, the log-likelihood.</p>
</td></tr>
<tr><td><code id="mbic_+3A_k">k</code></td>
<td>
<p>An integer &gt;= 0, the number of selected variables.</p>
</td></tr>
<tr><td><code id="mbic_+3A_n">n</code></td>
<td>
<p>An integer &gt; 0, the number of observations.</p>
</td></tr>
<tr><td><code id="mbic_+3A_p">p</code></td>
<td>
<p>An integer &gt; 0, the number of all variables or a weight.</p>
</td></tr>
<tr><td><code id="mbic_+3A_const">const</code></td>
<td>
<p>A numeric &gt; 0, the expected number of significant variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number, a value of mBIC.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mbic(10, 5, 100, 50)
</code></pre>

<hr>
<h2 id='mbic2'>mBIC2</h2><span id='topic+mbic2'></span>

<h3>Description</h3>

<p>Calculate mBIC2 (the second version of modified Bayesian Information
Criterion).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mbic2(loglik, k, n, p, const = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mbic2_+3A_loglik">loglik</code></td>
<td>
<p>A numeric, the log-likelihood.</p>
</td></tr>
<tr><td><code id="mbic2_+3A_k">k</code></td>
<td>
<p>An integer &gt;= 0, the number of selected variables.</p>
</td></tr>
<tr><td><code id="mbic2_+3A_n">n</code></td>
<td>
<p>An integer &gt; 0, the number of observations.</p>
</td></tr>
<tr><td><code id="mbic2_+3A_p">p</code></td>
<td>
<p>An integer &gt; 0, the number of all variables or a weight.</p>
</td></tr>
<tr><td><code id="mbic2_+3A_const">const</code></td>
<td>
<p>A numeric &gt; 0, the expected number of significant variables.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number, a value of mBIC2.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mbic2(10, 5, 100, 50)
</code></pre>

<hr>
<h2 id='multi_backward'>Multi-backward step</h2><span id='topic+multi_backward'></span>

<h3>Description</h3>

<p>Remove the worst variables from a model as long as they reduce the given
criterion (backward elimination).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multi_backward(data, crit = mbic, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multi_backward_+3A_data">data</code></td>
<td>
<p>an object of class <code>big</code>.</p>
</td></tr>
<tr><td><code id="multi_backward_+3A_crit">crit</code></td>
<td>
<p>a function defining the model selection criterion. You can use
your own function or one of these: <code>bic</code>, <code>mbic</code>, <code>mbic2</code>,
<code>aic</code>, <code>maic</code>, <code>maic2</code>.</p>
</td></tr>
<tr><td><code id="multi_backward_+3A_...">...</code></td>
<td>
<p>optional arguments to <code>crit</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type <code>browseVignettes("bigstep")</code> for more details.
</p>


<h3>Value</h3>

<p>An object of class <code>big</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 30
p &lt;- 10
X &lt;- matrix(rnorm(n * p), ncol = p)
y &lt;- X[, 2] + 2*X[, 3] - X[, 6] + rnorm(n)
d &lt;- prepare_data(y, X)
d %&gt;%
  fast_forward(crit = aic) %&gt;%
  multi_backward(crit = bic)

</code></pre>

<hr>
<h2 id='prepare_data'>Data preparation</h2><span id='topic+prepare_data'></span>

<h3>Description</h3>

<p>Create an object of class <code>big</code> which is needed to perform the selection
procedure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prepare_data(
  y,
  X,
  type = "linear",
  candidates = NULL,
  Xadd = NULL,
  na = NULL,
  maxp = 1e+06,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prepare_data_+3A_y">y</code></td>
<td>
<p>a numeric vector of dependent (target) variable.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_x">X</code></td>
<td>
<p>a numeric matrix or an object of class <code>big.matrix</code>. The
columns of <code>X</code> should contain dependent variables (predictors).</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_type">type</code></td>
<td>
<p>a string, type of the regression model you want to fit. You can
use one of these: <code>"linear"</code>, <code>"logistic"</code>, <code>"poisson"</code>.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_candidates">candidates</code></td>
<td>
<p>a numeric vector, columns from <code>X</code> which will be used
in the selection procedure. The order is important. If <code>NULL</code>, every
column will be used.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_xadd">Xadd</code></td>
<td>
<p>a numeric matrix, additional variables which will be included in
the model selection procedure (they will not be removed in any step). If
<code>NULL</code>, <code>Xadd</code> will contain only a column of ones (the
intercept). If you specify <code>Xadd</code>, a column of ones will be
automatically added (it is impossible to not include the intercept).</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_na">na</code></td>
<td>
<p>a logical. There are any missing values in <code>X</code>? If
<code>NULL</code>, it will be checked (it can take some time if <code>X</code> is big,
so it is reasonable to set it).</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_maxp">maxp</code></td>
<td>
<p>a numeric. The matrix <code>X</code> will be split into parts with
<code>maxp</code> elements. It will not change results, but it is necessary if
your computer does not have enough RAM. Set to a lower value if you still
have problems.</p>
</td></tr>
<tr><td><code id="prepare_data_+3A_verbose">verbose</code></td>
<td>
<p>a logical. Set <code>FALSE</code> if you do not want to see any
information during the selection procedure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function automatically removes observations which have missing
values in <code>y</code>. Type <code>browseVignettes("bigstep")</code> for more
details.
</p>


<h3>Value</h3>

<p>An object of class <code>big</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(rnorm(20), ncol = 4)
y &lt;- X[, 2] + rnorm(5)
data &lt;- prepare_data(y, X)

</code></pre>

<hr>
<h2 id='reduce_matrix'>Reducing number of variables</h2><span id='topic+reduce_matrix'></span>

<h3>Description</h3>

<p>Perform the Pearson correlation tests between a vector <code>y</code> and every
variable from a matrix <code>X</code> (separately) and remove uncorrelated
variables. The function is much faster when you do not have any missing
values (set <code>na = FALSE</code> in <code>prepare_data</code> in that case).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>reduce_matrix(data, minpv = 0.15)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="reduce_matrix_+3A_data">data</code></td>
<td>
<p>an object of class <code>big</code>.</p>
</td></tr>
<tr><td><code id="reduce_matrix_+3A_minpv">minpv</code></td>
<td>
<p>a numeric. Variables with p-values for the Pearson correlation
tests larger than <code>minpv</code> will be removed from <code>candidates</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type <code>browseVignettes("bigstep")</code> for more details.
</p>


<h3>Value</h3>

<p>An object of class <code>big</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 30
p &lt;- 10
X &lt;- matrix(rnorm(n * p), ncol = p)
y &lt;- X[, 2] + 2*X[, 3] - X[, 6] + rnorm(n)
d &lt;- prepare_data(y, X)
reduce_matrix(d)

</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic++25+3E+25'></span><span id='topic+read.big.matrix'></span><span id='topic+attach.big.matrix'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>bigmemory</dt><dd><p><code><a href="bigmemory.html#topic+attach.big.matrix">attach.big.matrix</a></code>, <code><a href="bigmemory.html#topic+write.big.matrix">read.big.matrix</a></code></p>
</dd>
<dt>magrittr</dt><dd><p><code><a href="magrittr.html#topic+pipe">%&gt;%</a></code></p>
</dd>
</dl>

<hr>
<h2 id='stepwise'>Stepwise</h2><span id='topic+stepwise'></span>

<h3>Description</h3>

<p>Build a model according to the stepwise procedure (bidirectional) and the
given criterion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepwise(data, crit = mbic, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stepwise_+3A_data">data</code></td>
<td>
<p>an object of class <code>big</code>.</p>
</td></tr>
<tr><td><code id="stepwise_+3A_crit">crit</code></td>
<td>
<p>a function defining the model selection criterion. You can use
your own function or one of these: <code>bic</code>, <code>mbic</code>, <code>mbic2</code>,
<code>aic</code>, <code>maic</code>, <code>maic2</code>.</p>
</td></tr>
<tr><td><code id="stepwise_+3A_...">...</code></td>
<td>
<p>optional arguments to <code>crit</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type <code>browseVignettes("bigstep")</code> for more details.
</p>


<h3>Value</h3>

<p>An object of class <code>big</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 30
p &lt;- 10
X &lt;- matrix(rnorm(n * p), ncol = p)
y &lt;- X[, 2] + 2*X[, 3] - X[, 6] + rnorm(n)
d &lt;- prepare_data(y, X)
stepwise(d)
d %&gt;%
  fast_forward(crit = aic) %&gt;%
  stepwise(crit = bic)

</code></pre>

<hr>
<h2 id='summary.big'>Summarizing model fit</h2><span id='topic+summary.big'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>big</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'big'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.big_+3A_object">object</code></td>
<td>
<p>an object of class <code>big</code>.</p>
</td></tr>
<tr><td><code id="summary.big_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to or from other methods. They are
ignored in this function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>summary.lm</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 30
p &lt;- 10
X &lt;- matrix(rnorm(n * p), ncol = p)
y &lt;- X[, 2] + 2*X[, 3] - X[, 6] + rnorm(n)
d &lt;- prepare_data(y, X)
m &lt;- stepwise(d)
summary(m)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
