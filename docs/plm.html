<!DOCTYPE html><html><head><title>Help for package plm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {plm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aneweytest'><p>Angrist and Newey's version of Chamberlain test for fixed effects</p></a></li>
<li><a href='#Cigar'><p>Cigarette Consumption</p></a></li>
<li><a href='#cipstest'><p>Cross-sectionally Augmented IPS Test for Unit Roots in Panel Models</p></a></li>
<li><a href='#cortab'><p>Cross&ndash;sectional correlation matrix</p></a></li>
<li><a href='#Crime'><p>Crime in North Carolina</p></a></li>
<li><a href='#detect.lindep'><p>Functions to detect linear dependence</p></a></li>
<li><a href='#EmplUK'><p>Employment and Wages in the United Kingdom</p></a></li>
<li><a href='#ercomp'><p>Estimation of the error components</p></a></li>
<li><a href='#fixef.plm'><p>Extract the Fixed Effects</p></a></li>
<li><a href='#Gasoline'><p>Gasoline Consumption</p></a></li>
<li><a href='#Grunfeld'><p>Grunfeld's Investment Data</p></a></li>
<li><a href='#has.intercept'><p>Check for the presence of an intercept in a formula or in a fitted</p>
model</a></li>
<li><a href='#Hedonic'><p>Hedonic Prices of Census Tracts in the Boston Area</p></a></li>
<li><a href='#index.plm'><p>Extract the indexes of panel data</p></a></li>
<li><a href='#is.pbalanced'><p>Check if data are balanced</p></a></li>
<li><a href='#is.pconsecutive'><p>Check if time periods are consecutive</p></a></li>
<li><a href='#is.pseries'><p>Check if an object is a pseries</p></a></li>
<li><a href='#LaborSupply'><p>Wages and Hours Worked</p></a></li>
<li><a href='#lag.plm'><p>lag, lead, and diff for panel data</p></a></li>
<li><a href='#make.dummies'><p>Create a Dummy Matrix</p></a></li>
<li><a href='#make.pbalanced'><p>Make data balanced</p></a></li>
<li><a href='#make.pconsecutive'><p>Make data consecutive (and, optionally, also balanced)</p></a></li>
<li><a href='#Males'><p>Wages and Education of Young Males</p></a></li>
<li><a href='#model.frame.pdata.frame'><p>model.frame and model.matrix for panel data</p></a></li>
<li><a href='#mtest'><p>Arellano&ndash;Bond Test of Serial Correlation</p></a></li>
<li><a href='#nobs.plm'><p>Extract Total Number of Observations Used in Estimated Panelmodel</p></a></li>
<li><a href='#Parity'><p>Purchasing Power Parity and other parity relationships</p></a></li>
<li><a href='#pbgtest'><p>Breusch&ndash;Godfrey Test for Panel Models</p></a></li>
<li><a href='#pbltest'><p>Baltagi and Li Serial Dependence Test For Random Effects Models</p></a></li>
<li><a href='#pbnftest'><p>Modified BNF&ndash;Durbin&ndash;Watson Test and Baltagi&ndash;Wu's LBI Test for Panel</p>
Models</a></li>
<li><a href='#pbsytest'><p>Bera, Sosa-Escudero and Yoon Locally&ndash;Robust Lagrange Multiplier</p>
Tests for Panel Models and Joint Test by Baltagi and Li</a></li>
<li><a href='#pcce'><p>Common Correlated Effects estimators</p></a></li>
<li><a href='#pcdtest'><p>Tests of cross-section dependence for panel models</p></a></li>
<li><a href='#pdata.frame'><p>data.frame for panel data</p></a></li>
<li><a href='#pdim'><p>Check for the Dimensions of the Panel</p></a></li>
<li><a href='#pdwtest'><p>Durbin&ndash;Watson Test for Panel Models</p></a></li>
<li><a href='#pFtest'><p>F Test for Individual and/or Time Effects</p></a></li>
<li><a href='#pggls'><p>General FGLS Estimators</p></a></li>
<li><a href='#pgmm'><p>Generalized Method of Moments (GMM) Estimation for Panel Data</p></a></li>
<li><a href='#pgrangertest'><p>Panel Granger (Non-)Causality Test (Dumitrescu/Hurlin (2012))</p></a></li>
<li><a href='#phansitest'><p>Simes Test for unit roots in panel data</p></a></li>
<li><a href='#pht'><p>Hausman&ndash;Taylor Estimator for Panel Data</p></a></li>
<li><a href='#phtest'><p>Hausman Test for Panel Models</p></a></li>
<li><a href='#piest'><p>Chamberlain estimator and test for fixed effects</p></a></li>
<li><a href='#pldv'><p>Panel estimators for limited dependent variables</p></a></li>
<li><a href='#plm'><p>Panel Data Estimators</p></a></li>
<li><a href='#plm-deprecated'><p>Deprecated functions of plm</p></a></li>
<li><a href='#plm-package'><p>plm package: linear models for panel data</p></a></li>
<li><a href='#plm.fast'><p>Option to Switch On/Off Fast Data Transformations</p></a></li>
<li><a href='#plmtest'><p>Lagrange FF Multiplier Tests for Panel Models</p></a></li>
<li><a href='#pmg'><p>Mean Groups (MG), Demeaned MG and CCE MG estimators</p></a></li>
<li><a href='#pmodel.response'><p>A function to extract the model.response</p></a></li>
<li><a href='#pooltest'><p>Test of Poolability</p></a></li>
<li><a href='#predict.plm'><p>Model Prediction for plm Objects</p></a></li>
<li><a href='#Produc'><p>US States Production</p></a></li>
<li><a href='#pseries'><p>panel series</p></a></li>
<li><a href='#pseriesfy'><p>Turn all columns of a pdata.frame into class pseries.</p></a></li>
<li><a href='#punbalancedness'><p>Measures for Unbalancedness of Panel Data</p></a></li>
<li><a href='#purtest'><p>Unit root tests for panel data</p></a></li>
<li><a href='#pvar'><p>Check for Cross-Sectional and Time Variation</p></a></li>
<li><a href='#pvcm'><p>Variable Coefficients Models for Panel Data</p></a></li>
<li><a href='#pwaldtest'><p>Wald-style Chi-square Test and F Test</p></a></li>
<li><a href='#pwartest'><p>Wooldridge Test for AR(1) Errors in FE Panel Models</p></a></li>
<li><a href='#pwfdtest'><p>Wooldridge first&ndash;difference&ndash;based test for AR(1) errors in levels</p>
or first&ndash;differenced panel models</a></li>
<li><a href='#pwtest'><p>Wooldridge's Test for Unobserved Effects in Panel Models</p></a></li>
<li><a href='#r.squared'><p>R squared and adjusted R squared for panel models</p></a></li>
<li><a href='#ranef.plm'><p>Extract the Random Effects</p></a></li>
<li><a href='#re-export_functions'><p>Functions exported from other packages</p></a></li>
<li><a href='#RiceFarms'><p>Production of Rice in Indonesia</p></a></li>
<li><a href='#sargan'><p>Hansen&ndash;Sargan Test of Overidentifying Restrictions</p></a></li>
<li><a href='#Snmesp'><p>Employment and Wages in Spain</p></a></li>
<li><a href='#SumHes'><p>The Penn World Table, v. 5</p></a></li>
<li><a href='#summary.plm.list'><p>Summary for plm objects</p></a></li>
<li><a href='#vcovBK'><p>Beck and Katz Robust Covariance Matrix Estimators</p></a></li>
<li><a href='#vcovDC'><p>Double-Clustering Robust Covariance Matrix Estimator</p></a></li>
<li><a href='#vcovG'><p>Generic Lego building block for Robust Covariance Matrix Estimators</p></a></li>
<li><a href='#vcovHC.plm'><p>Robust Covariance Matrix Estimators</p></a></li>
<li><a href='#vcovNW'><p>Newey and West (1987) Robust Covariance Matrix Estimator</p></a></li>
<li><a href='#vcovSCC'><p>Driscoll and Kraay (1998) Robust Covariance Matrix Estimator</p></a></li>
<li><a href='#Wages'><p>Panel Data of Individual Wages</p></a></li>
<li><a href='#within_intercept'><p>Overall Intercept for Within Models Along its Standard Error</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.6-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-04-09</td>
</tr>
<tr>
<td>Title:</td>
<td>Linear Models for Panel Data</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, bdsmatrix, collapse (&ge; 1.8.9), zoo, nlme, sandwich,
lattice, lmtest, maxLik, Rdpack, Formula, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>AER, car, statmod, urca, pder, texreg, knitr, rmarkdown,
fixest, lfe</td>
</tr>
<tr>
<td>Description:</td>
<td>A set of estimators for models and (robust) covariance matrices, and tests for panel data
             econometrics, including within/fixed effects, random effects, between, first-difference, 
             nested random effects as well as instrumental-variable (IV) and Hausman-Taylor-style models,
             panel generalized method of moments (GMM) and general FGLS models,
             mean groups (MG), demeaned MG, and common correlated effects (CCEMG) and pooled (CCEP) estimators
             with common factors, variable coefficients and limited dependent variables models.
             Test functions include model specification, serial correlation, cross-sectional dependence,
             panel unit root and panel Granger (non-)causality. Typical references are general econometrics 
             text books such as Baltagi (2021), Econometric Analysis of Panel Data (&lt;<a href="https://doi.org/10.1007%2F978-3-030-53953-5">doi:10.1007/978-3-030-53953-5</a>&gt;),
             Hsiao (2014), Analysis of Panel Data (&lt;<a href="https://doi.org/10.1017%2FCBO9781139839327">doi:10.1017/CBO9781139839327</a>&gt;), and Croissant and Millo (2018), 
             Panel Data Econometrics with R (&lt;<a href="https://doi.org/10.1002%2F9781119504641">doi:10.1002/9781119504641</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://cran.r-project.org/package=plm">https://cran.r-project.org/package=plm</a> (CRAN releases),
<a href="https://github.com/ycroissant/plm">https://github.com/ycroissant/plm</a> (development repository)</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/ycroissant/plm/issues">https://github.com/ycroissant/plm/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-09 10:39:10 UTC; kevin</td>
</tr>
<tr>
<td>Author:</td>
<td>Yves Croissant [aut],
  Giovanni Millo [aut],
  Kevin Tappe [aut, cre],
  Ott Toomet [ctb],
  Christian Kleiber [ctb],
  Achim Zeileis [ctb],
  Arne Henningsen [ctb],
  Liviu Andronic [ctb],
  Nina Schoenfelder [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Kevin Tappe &lt;kevin.tappe@bwi.uni-stuttgart.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-09 11:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='aneweytest'>Angrist and Newey's version of Chamberlain test for fixed effects</h2><span id='topic+aneweytest'></span>

<h3>Description</h3>

<p>Angrist and Newey's version of the Chamberlain test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aneweytest(formula, data, subset, na.action, index = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aneweytest_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be estimated,</p>
</td></tr>
<tr><td><code id="aneweytest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="aneweytest_+3A_subset">subset</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="aneweytest_+3A_na.action">na.action</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="aneweytest_+3A_index">index</code></td>
<td>
<p>the indexes,</p>
</td></tr>
<tr><td><code id="aneweytest_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Angrist and Newey's test is based on the results of the artifactual
regression of the within residuals on the covariates for all the
periods.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>Angrist JD, Newey WK (1991).
&ldquo;Over-identification tests in earnings functions with fixed effects.&rdquo;
<em>Journal of Business &amp; Economic Statistics</em>, <b>9</b>(3), 317&ndash;323.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+piest">piest()</a></code> for Chamberlain's test
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("RiceFarms", package = "plm")
aneweytest(log(goutput) ~ log(seed) + log(totlabor) + log(size), RiceFarms, index = "id")

</code></pre>

<hr>
<h2 id='Cigar'>Cigarette Consumption</h2><span id='topic+Cigar'></span>

<h3>Description</h3>

<p>a panel of 46 observations from 1963 to 1992
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>state</dt><dd><p>state abbreviation</p>
</dd>
<dt>year</dt><dd><p>the year</p>
</dd>
<dt>price</dt><dd><p>price per pack of cigarettes</p>
</dd>
<dt>pop</dt><dd><p>population</p>
</dd>
<dt>pop16</dt><dd><p>population above the age of 16</p>
</dd>
<dt>cpi</dt><dd><p>consumer price index (1983=100)</p>
</dd>
<dt>ndi</dt><dd><p>per capita disposable income</p>
</dd>
<dt>sales</dt><dd><p>cigarette sales in packs per capita</p>
</dd>
<dt>pimin</dt><dd><p>minimum price in adjoining states per pack of cigarettes</p>
</dd>
</dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 1380
</p>
<p><em>observation</em> : regional
</p>
<p><em>country</em> : United States
</p>


<h3>Source</h3>

<p>Online complements to Baltagi (2001):
</p>
<p><a href="https://www.wiley.com/legacy/wileychi/baltagi/">https://www.wiley.com/legacy/wileychi/baltagi/</a>
</p>
<p>Online complements to Baltagi (2013):
</p>
<p><a href="https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452">https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452</a>
</p>


<h3>References</h3>

<p>Baltagi BH (2001).
<em>Econometric Analysis of Panel Data</em>, 3rd edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi B, Levin D (1992).
&ldquo;Cigarette taxation: Raising revenues and reducing consumption.&rdquo;
<em>Structural Change and Economic Dynamics</em>, <b>3</b>(2), 321-335.
<a href="https://EconPapers.repec.org/RePEc:eee:streco:v:3:y:1992:i:2:p:321-335">https://EconPapers.repec.org/RePEc:eee:streco:v:3:y:1992:i:2:p:321-335</a>.
</p>
<p>Baltagi BH, Griffin JM, Xiong W (2000).
&ldquo;To Pool or Not to Pool: Homogeneous Versus Heterogeneous Estimators Applied to Cigarette Demand.&rdquo;
<em>The Review of Economics and Statistics</em>, <b>82</b>(1), 117-126.
<a href="https://doi.org/10.1162/003465300558551">doi:10.1162/003465300558551</a>, https://doi.org/10.1162/003465300558551.
</p>

<hr>
<h2 id='cipstest'>Cross-sectionally Augmented IPS Test for Unit Roots in Panel Models</h2><span id='topic+cipstest'></span>

<h3>Description</h3>

<p>Cross-sectionally augmented Im, Pesaran and Shin (IPS) test for
unit roots in panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cipstest(
  x,
  lags = 2L,
  type = c("trend", "drift", "none"),
  model = c("cmg", "mg", "dmg"),
  truncated = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cipstest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"pseries"</code>,</p>
</td></tr>
<tr><td><code id="cipstest_+3A_lags">lags</code></td>
<td>
<p>integer, lag order for Dickey-Fuller augmentation,</p>
</td></tr>
<tr><td><code id="cipstest_+3A_type">type</code></td>
<td>
<p>one of <code>"trend"</code> (default), <code>"drift"</code>, <code>"none"</code>,</p>
</td></tr>
<tr><td><code id="cipstest_+3A_model">model</code></td>
<td>
<p>one of <code>"cmg"</code> (default), <code>"mg"</code>, <code>"dmg"</code>,</p>
</td></tr>
<tr><td><code id="cipstest_+3A_truncated">truncated</code></td>
<td>
<p>logical, specifying whether to calculate the
truncated version of the test (default: <code>FALSE</code>),</p>
</td></tr>
<tr><td><code id="cipstest_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code>critvals.cips</code>
(non-exported function).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pesaran's (Pesaran 2007) cross-sectionally augmented version of
the IPS unit root test (Im et al. 2003) (H0: <code>pseries</code>
has a unit root) is a so-called second-generation panel unit root test: it
is in fact robust against cross-sectional dependence, provided that the default
<code>model="cmg"</code> is calculated. Else one can obtain the standard
(<code>model="mg"</code>) or cross-sectionally demeaned (<code>model="dmg"</code>)
versions of the IPS test.
</p>
<p>Argument <code>type</code> controls how the test is executed:
</p>

<ul>
<li> <p><code>"none"</code>: no intercept, no trend (Case I in (Pesaran 2007)),
</p>
</li>
<li> <p><code>"drift"</code>: with intercept, no trend (Case II),
</p>
</li>
<li> <p><code>"trend"</code> (default): with intercept, with trend (Case III).
</p>
</li></ul>



<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Im KS, Pesaran MH, Shin Y (2003).
&ldquo;Testing for unit roots in heterogenous panels.&rdquo;
<em>Journal of Econometrics</em>, <b>115(1)</b>, 53-74.<br /><br /> Pesaran MH (2007).
&ldquo;A simple panel unit root test in the presence of cross-section dependence.&rdquo;
<em>Journal of Applied Econometrics</em>, <b>22</b>(2), 265&ndash;312.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+purtest">purtest()</a></code>, <code><a href="#topic+phansitest">phansitest()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
Produc &lt;- pdata.frame(Produc, index=c("state", "year"))
## check whether the gross state product (gsp) is trend-stationary
cipstest(Produc$gsp, type = "trend")

</code></pre>

<hr>
<h2 id='cortab'>Cross&ndash;sectional correlation matrix</h2><span id='topic+cortab'></span>

<h3>Description</h3>

<p>Computes the cross&ndash;sectional correlation matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cortab(x, grouping, groupnames = NULL, value = "statistic", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cortab_+3A_x">x</code></td>
<td>
<p>an object of class <code>pseries</code></p>
</td></tr>
<tr><td><code id="cortab_+3A_grouping">grouping</code></td>
<td>
<p>grouping variable,</p>
</td></tr>
<tr><td><code id="cortab_+3A_groupnames">groupnames</code></td>
<td>
<p>a character vector of group names,</p>
</td></tr>
<tr><td><code id="cortab_+3A_value">value</code></td>
<td>
<p>to complete,</p>
</td></tr>
<tr><td><code id="cortab_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with average correlation coefficients within a group
(diagonal) and between groups (off-diagonal).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
pGrunfeld &lt;- pdata.frame(Grunfeld)
grp &lt;- c(rep(1, 100), rep(2, 50), rep(3, 50)) # make 3 groups
cortab(pGrunfeld$value, grouping = grp, groupnames = c("A", "B", "C"))

</code></pre>

<hr>
<h2 id='Crime'>Crime in North Carolina</h2><span id='topic+Crime'></span>

<h3>Description</h3>

<p>a panel of 90 observational units (counties) from 1981 to 1987
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>county</dt><dd><p>county identifier</p>
</dd>
<dt>year</dt><dd><p>year from 1981 to 1987</p>
</dd>
<dt>crmrte</dt><dd><p>crimes committed per person</p>
</dd>
<dt>prbarr</dt><dd><p>'probability' of arrest</p>
</dd>
<dt>prbconv</dt><dd><p>'probability' of conviction</p>
</dd>
<dt>prbpris</dt><dd><p>'probability' of prison sentence</p>
</dd>
<dt>avgsen</dt><dd><p>average sentence, days</p>
</dd>
<dt>polpc</dt><dd><p>police per capita</p>
</dd>
<dt>density</dt><dd><p>people per square mile</p>
</dd>
<dt>taxpc</dt><dd><p>tax revenue per capita</p>
</dd>
<dt>region</dt><dd><p>factor. One of 'other', 'west' or 'central'.</p>
</dd>
<dt>smsa</dt><dd><p>factor. (Also called &quot;urban&quot;.) Does the individual reside in a SMSA (standard metropolitan statistical area)?</p>
</dd>
<dt>pctmin</dt><dd><p>percentage minority in 1980</p>
</dd>
<dt>wcon</dt><dd><p>weekly wage in construction</p>
</dd>
<dt>wtuc</dt><dd><p>weekly wage in transportation, utilities, communications</p>
</dd>
<dt>wtrd</dt><dd><p>weekly wage in wholesale and retail trade</p>
</dd>
<dt>wfir</dt><dd><p>weekly wage in finance, insurance and real estate</p>
</dd>
<dt>wser</dt><dd><p>weekly wage in service industry</p>
</dd>
<dt>wmfg</dt><dd><p>weekly wage in manufacturing</p>
</dd>
<dt>wfed</dt><dd><p>weekly wage in federal government</p>
</dd>
<dt>wsta</dt><dd><p>weekly wage in state government</p>
</dd>
<dt>wloc</dt><dd><p>weekly wage in local government</p>
</dd>
<dt>mix</dt><dd><p>offence mix: face-to-face/other</p>
</dd>
<dt>pctymle</dt><dd><p>percentage of young males (between ages 15 to 24)</p>
</dd>
<dt>lcrmrte</dt><dd><p>log of crimes committed per person</p>
</dd>
<dt>lprbarr</dt><dd><p>log of 'probability' of arrest</p>
</dd>
<dt>lprbconv</dt><dd><p>log of 'probability' of conviction</p>
</dd>
<dt>lprbpris</dt><dd><p>log of 'probability' of prison sentence</p>
</dd>
<dt>lavgsen</dt><dd><p>log of average sentence, days</p>
</dd>
<dt>lpolpc</dt><dd><p>log of police per capita</p>
</dd>
<dt>ldensity</dt><dd><p>log of people per square mile</p>
</dd>
<dt>ltaxpc</dt><dd><p>log of tax revenue per capita</p>
</dd>
<dt>lpctmin</dt><dd><p>log of percentage minority in 1980</p>
</dd>
<dt>lwcon</dt><dd><p>log of weekly wage in construction</p>
</dd>
<dt>lwtuc</dt><dd><p>log of weekly wage in transportation, utilities, communications</p>
</dd>
<dt>lwtrd</dt><dd><p>log of weekly wage in wholesale and retail trade</p>
</dd>
<dt>lwfir</dt><dd><p>log of weekly wage in finance, insurance and real estate</p>
</dd>
<dt>lwser</dt><dd><p>log of weekly wage in service industry</p>
</dd>
<dt>lwmfg</dt><dd><p>log of weekly wage in manufacturing</p>
</dd>
<dt>lwfed</dt><dd><p>log of weekly wage in federal government</p>
</dd>
<dt>lwsta</dt><dd><p>log of weekly wage in state government</p>
</dd>
<dt>lwloc</dt><dd><p>log of weekly wage in local government</p>
</dd>
<dt>lmix</dt><dd><p>log of offence mix: face-to-face/other</p>
</dd>
<dt>lpctymle</dt><dd><p>log of percentage of young males (between ages 15 to 24)</p>
</dd></dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 630
</p>
<p><em>observation</em> : regional
</p>
<p><em>country</em> : United States
</p>
<p>The variables l* (lcrmrte, lprbarr, ...) contain the pre-computed logarithms
of the base variables as found in the original data set. Note that these
values slightly differ from what R's log() function yields for the base
variables.  In order to reproduce examples from the literature, the
pre-computed logs need to be used, otherwise the results differ slightly.
</p>


<h3>Source</h3>

<p>Journal of Applied Econometrics Data Archive (complements Baltagi
(2006)):
</p>
<p><a href="http://qed.econ.queensu.ca/jae/2006-v21.4/baltagi/">http://qed.econ.queensu.ca/jae/2006-v21.4/baltagi/</a>
</p>
<p>Online complements to Baltagi (2001):
</p>
<p><a href="https://www.wiley.com/legacy/wileychi/baltagi/">https://www.wiley.com/legacy/wileychi/baltagi/</a>
</p>
<p>Online complements to Baltagi (2013):
</p>
<p><a href="https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452">https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452</a>
</p>
<p>See also Journal of Applied Econometrics data archive entry for
Baltagi (2006) at
<a href="http://qed.econ.queensu.ca/jae/2006-v21.4/baltagi/">http://qed.econ.queensu.ca/jae/2006-v21.4/baltagi/</a>.
</p>


<h3>References</h3>

<p>Cornwell C, Trumbull WN (1994).
&ldquo;Estimating the economic model of crime with panel data.&rdquo;
<em>Review of Economics and Statistics</em>, <b>76</b>, 360&ndash;366.
</p>
<p>Baltagi BH (2006).
&ldquo;Estmating an economic model of crime using panel data from North Carolina.&rdquo;
<em>Journal of Applied Econometrics</em>, <b>21</b>(4).
</p>
<p>Baltagi BH (2001).
<em>Econometric Analysis of Panel Data</em>, 3rd edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>

<hr>
<h2 id='detect.lindep'>Functions to detect linear dependence</h2><span id='topic+detect.lindep'></span><span id='topic+detect.lindep.matrix'></span><span id='topic+detect.lindep.data.frame'></span><span id='topic+detect.lindep.plm'></span><span id='topic+alias.plm'></span><span id='topic+alias.pdata.frame'></span>

<h3>Description</h3>

<p>Little helper functions to aid users to detect linear dependent columns in a
two-dimensional data structure, especially in a (transformed) model matrix -
typically useful in interactive mode during model building phase.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect.lindep(object, ...)

## S3 method for class 'matrix'
detect.lindep(object, suppressPrint = FALSE, ...)

## S3 method for class 'data.frame'
detect.lindep(object, suppressPrint = FALSE, ...)

## S3 method for class 'plm'
detect.lindep(object, suppressPrint = FALSE, ...)

## S3 method for class 'plm'
alias(object, ...)

## S3 method for class 'pdata.frame'
alias(
  object,
  model = c("pooling", "within", "Between", "between", "mean", "random", "fd"),
  effect = c("individual", "time", "twoways"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect.lindep_+3A_object">object</code></td>
<td>
<p>for <code>detect.lindep</code>: an object which should be checked
for linear dependence (of class <code>"matrix"</code>, <code>"data.frame"</code>, or
<code>"plm"</code>); for <code>alias</code>: either an estimated model of class
<code>"plm"</code> or a <code>"pdata.frame"</code>. Usually, one wants to input a model
matrix here or check an already estimated plm model,</p>
</td></tr>
<tr><td><code id="detect.lindep_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="detect.lindep_+3A_suppressprint">suppressPrint</code></td>
<td>
<p>for <code>detect.lindep</code> only: logical indicating
whether a message shall be printed; defaults to printing the message, i. e.,
to <code>suppressPrint = FALSE</code>,</p>
</td></tr>
<tr><td><code id="detect.lindep_+3A_model">model</code></td>
<td>
<p>(see <code>plm</code>),</p>
</td></tr>
<tr><td><code id="detect.lindep_+3A_effect">effect</code></td>
<td>
<p>(see <code>plm</code>),</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Linear dependence of columns/variables is (usually) readily avoided when
building one's model.  However, linear dependence is sometimes not obvious
and harder to detect for less experienced applied statisticians. The so
called &quot;dummy variable trap&quot; is a common and probably the best&ndash;known
fallacy of this kind (see e. g. Wooldridge (2016), sec. 7-2.). When building
linear models with <code>lm</code> or <code>plm</code>'s <code>pooling</code> model, linear
dependence in one's model is easily detected, at times post hoc.
</p>
<p>However, linear dependence might also occur after some transformations of
the data, albeit it is not present in the untransformed data. The within
transformation (also called fixed effect transformation) used in the
<code>"within"</code> model can result in such linear dependence and this is
harder to come to mind when building a model. See <strong>Examples</strong> for two
examples of linear dependent columns after the within transformation: ex. 1)
the transformed variables have the opposite sign of one another; ex. 2) the
transformed variables are identical.
</p>
<p>During <code>plm</code>'s model estimation, linear dependent columns and their
corresponding coefficients in the resulting object are silently dropped,
while the corresponding model frame and model matrix still contain the
affected columns.  The plm object contains an element <code>aliased</code> which
indicates any such aliased coefficients by a named logical.
</p>
<p>Both functions, <code>detect.lindep</code> and <code>alias</code>, help to
detect linear dependence and accomplish almost the same:
<code>detect.lindep</code> is a stand alone implementation while
<code>alias</code> is a wrapper around
<code><a href="stats.html#topic+alias">stats::alias.lm()</a></code>, extending the <code>alias</code>
generic to classes <code>"plm"</code> and <code>"pdata.frame"</code>.
<code>alias</code> hinges on the availability of the package
<a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a> on the system. Not all arguments of <code>alias.lm</code>
are supported.  Output of <code>alias</code> is more informative as it
gives the linear combination of dependent columns (after data
transformations, i. e., after (quasi)-demeaning) while
<code>detect.lindep</code> only gives columns involved in the linear
dependence in a simple format (thus being more suited for automatic
post&ndash;processing of the information).
</p>


<h3>Value</h3>

<p>For <code>detect.lindep</code>: A named numeric vector containing column
numbers of the linear dependent columns in the object after data
transformation, if any are present. <code>NULL</code> if no linear dependent
columns are detected.
</p>
<p>For <code>alias</code>: return value of <code><a href="stats.html#topic+alias">stats::alias.lm()</a></code> run on the
(quasi-)demeaned model, i. e., the information outputted applies to
the transformed model matrix, not the original data.
</p>


<h3>Note</h3>

<p>function <code>detect.lindep</code> was called <code>detect_lin_dep</code>
initially but renamed for naming consistency later.
</p>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>References</h3>

<p>Wooldridge JM (2013).
<em>Introductory Econometrics: a modern approach</em>, 5th edition.
South-Western (Cengage Learning).
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+alias">stats::alias()</a></code>, <code><a href="stats.html#topic+model.matrix">stats::model.matrix()</a></code> and especially
<code>plm</code>'s <code><a href="stats.html#topic+model.matrix">model.matrix()</a></code> for (transformed) model matrices,
plm's <code><a href="stats.html#topic+model.frame">model.frame()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Example 1 ###
# prepare the data
data("Cigar" , package = "plm")
Cigar[ , "fact1"] &lt;- c(0,1)
Cigar[ , "fact2"] &lt;- c(1,0)
Cigar.p &lt;- pdata.frame(Cigar)

# setup a formula and a model frame
form &lt;- price ~ 0 + cpi + fact1 + fact2
mf &lt;- model.frame(Cigar.p, form)
# no linear dependence in the pooling model's model matrix
# (with intercept in the formula, there would be linear depedence)
detect.lindep(model.matrix(mf, model = "pooling"))
# linear dependence present in the FE transformed model matrix
modmat_FE &lt;- model.matrix(mf, model = "within")
detect.lindep(modmat_FE)
mod_FE &lt;- plm(form, data = Cigar.p, model = "within")
detect.lindep(mod_FE) 
alias(mod_FE) # =&gt; fact1 == -1*fact2
plm(form, data = mf, model = "within")$aliased # "fact2" indicated as aliased

# look at the data: after FE transformation fact1 == -1*fact2
head(modmat_FE)
all.equal(modmat_FE[ , "fact1"], -1*modmat_FE[ , "fact2"])

### Example 2 ###
# Setup the data:
# Assume CEOs stay with the firms of the Grunfeld data
# for the firm's entire lifetime and assume some fictional
# data about CEO tenure and age in year 1935 (first observation
# in the data set) to be at 1 to 10 years and 38 to 55 years, respectively.
# =&gt; CEO tenure and CEO age increase by same value (+1 year per year).
data("Grunfeld", package = "plm")
set.seed(42)
# add fictional data
Grunfeld$CEOtenure &lt;- c(replicate(10, seq(from=s&lt;-sample(1:10,  1), to=s+19, by=1)))
Grunfeld$CEOage    &lt;- c(replicate(10, seq(from=s&lt;-sample(38:65, 1), to=s+19, by=1)))

# look at the data
head(Grunfeld, 50)

form &lt;- inv ~ value + capital + CEOtenure + CEOage
mf &lt;- model.frame(pdata.frame(Grunfeld), form)
# no linear dependent columns in original data/pooling model
modmat_pool &lt;- model.matrix(mf, model="pooling")
detect.lindep(modmat_pool)
mod_pool &lt;- plm(form, data = Grunfeld, model = "pooling")
alias(mod_pool)

# CEOtenure and CEOage are linear dependent after FE transformation
# (demeaning per individual)
modmat_FE &lt;- model.matrix(mf, model="within")
detect.lindep(modmat_FE)
mod_FE &lt;- plm(form, data = Grunfeld, model = "within")
detect.lindep(mod_FE)
alias(mod_FE)

# look at the transformed data: after FE transformation CEOtenure == 1*CEOage
head(modmat_FE, 50)
all.equal(modmat_FE[ , "CEOtenure"], modmat_FE[ , "CEOage"])

</code></pre>

<hr>
<h2 id='EmplUK'>Employment and Wages in the United Kingdom</h2><span id='topic+EmplUK'></span>

<h3>Description</h3>

<p>An unbalanced panel of 140 observations from 1976 to 1984
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>firm</dt><dd><p>firm index</p>
</dd>
<dt>year</dt><dd><p>year</p>
</dd>
<dt>sector</dt><dd><p>the sector of activity</p>
</dd>
<dt>emp</dt><dd><p>employment</p>
</dd>
<dt>wage</dt><dd><p>wages</p>
</dd>
<dt>capital</dt><dd><p>capital</p>
</dd>
<dt>output</dt><dd><p>output</p>
</dd>
</dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 1031
</p>
<p><em>observation</em> : firms
</p>
<p><em>country</em> : United Kingdom
</p>


<h3>Source</h3>

<p>Arellano M, Bond S (1991).
&ldquo;Some Tests of Specification for Panel Data : Monte Carlo Evidence and an Application to Employment Equations.&rdquo;
<em>Review of Economic Studies</em>, <b>58</b>, 277&ndash;297.
</p>

<hr>
<h2 id='ercomp'>Estimation of the error components</h2><span id='topic+ercomp'></span><span id='topic+ercomp.plm'></span><span id='topic+ercomp.pdata.frame'></span><span id='topic+ercomp.formula'></span><span id='topic+print.ercomp'></span>

<h3>Description</h3>

<p>This function enables the estimation of the variance components of a panel
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ercomp(object, ...)

## S3 method for class 'plm'
ercomp(object, ...)

## S3 method for class 'pdata.frame'
ercomp(
  object,
  effect = c("individual", "time", "twoways", "nested"),
  method = NULL,
  models = NULL,
  dfcor = NULL,
  index = NULL,
  ...
)

## S3 method for class 'formula'
ercomp(
  object,
  data,
  effect = c("individual", "time", "twoways", "nested"),
  method = NULL,
  models = NULL,
  dfcor = NULL,
  index = NULL,
  ...
)

## S3 method for class 'ercomp'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ercomp_+3A_object">object</code></td>
<td>
<p>a <code>formula</code> or a <code>plm</code> object,</p>
</td></tr>
<tr><td><code id="ercomp_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="ercomp_+3A_effect">effect</code></td>
<td>
<p>the effects introduced in the model, see <code><a href="#topic+plm">plm()</a></code> for
details,</p>
</td></tr>
<tr><td><code id="ercomp_+3A_method">method</code></td>
<td>
<p>method of estimation for the variance components, see
<code><a href="#topic+plm">plm()</a></code> for details,</p>
</td></tr>
<tr><td><code id="ercomp_+3A_models">models</code></td>
<td>
<p>the models used to estimate the variance components
(an alternative to the previous argument),</p>
</td></tr>
<tr><td><code id="ercomp_+3A_dfcor">dfcor</code></td>
<td>
<p>a numeric vector of length 2 indicating which degree
of freedom should be used,</p>
</td></tr>
<tr><td><code id="ercomp_+3A_index">index</code></td>
<td>
<p>the indexes,</p>
</td></tr>
<tr><td><code id="ercomp_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="ercomp_+3A_x">x</code></td>
<td>
<p>an <code>ercomp</code> object,</p>
</td></tr>
<tr><td><code id="ercomp_+3A_digits">digits</code></td>
<td>
<p>digits,</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"ercomp"</code>: a list containing </p>

<ul>
<li> <p><code>sigma2</code> a named numeric with estimates of the variance
components, </p>
</li>
<li> <p><code>theta</code> contains the parameter(s) used for
the transformation of the variables: For a one-way model, a
numeric corresponding to the selected effect (individual or
time); for a two-ways model a list of length 3 with the
parameters. In case of a balanced model, the numeric has length
1 while for an unbalanced model, the numerics' length equal the
number of observations. </p>
</li></ul>



<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>Amemiya T (1971).
&ldquo;The Estimation of the Variances in a Variance&ndash;Components Model.&rdquo;
<em>International Economic Review</em>, <b>12</b>, 1&ndash;13.
</p>
<p>Nerlove M (1971).
&ldquo;Further Evidence on the Estimation of Dynamic Economic Relations from a Time&ndash;Series of Cross&ndash;Sections.&rdquo;
<em>Econometrica</em>, <b>39</b>, 359&ndash;382.
</p>
<p>Swamy PAVB, Arora SS (1972).
&ldquo;The Exact Finite Sample Properties of the Estimators of Coefficients in the Error Components Regression Models.&rdquo;
<em>Econometrica</em>, <b>40</b>, 261&ndash;275.
</p>
<p>Wallace TD, Hussain A (1969).
&ldquo;The Use of Error Components Models in Combining Cross Section With Time Series Data.&rdquo;
<em>Econometrica</em>, <b>37</b>(1), 55&ndash;72.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plm">plm()</a></code> where the estimates of the variance components are
used if a random effects model is estimated
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
# an example of the formula method
ercomp(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc,
       method = "walhus", effect = "time")
# same with the plm method
z &lt;- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,
         data = Produc, random.method = "walhus",
         effect = "time", model = "random")
ercomp(z)
# a two-ways model
ercomp(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc,
       method = "amemiya", effect = "twoways")

</code></pre>

<hr>
<h2 id='fixef.plm'>Extract the Fixed Effects</h2><span id='topic+fixef.plm'></span><span id='topic+fixef'></span><span id='topic+print.fixef'></span><span id='topic+summary.fixef'></span><span id='topic+print.summary.fixef'></span><span id='topic+fixef.pggls'></span>

<h3>Description</h3>

<p>Function to extract the fixed effects from a <code>plm</code> object and
associated summary method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plm'
fixef(
  object,
  effect = NULL,
  type = c("level", "dfirst", "dmean"),
  vcov = NULL,
  ...
)

## S3 method for class 'fixef'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)

## S3 method for class 'fixef'
summary(object, ...)

## S3 method for class 'summary.fixef'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)

## S3 method for class 'pggls'
fixef(
  object,
  effect = NULL,
  type = c("level", "dfirst", "dmean"),
  vcov = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixef.plm_+3A_effect">effect</code></td>
<td>
<p>one of <code>"individual"</code>, <code>"time"</code>, or <code>"twoways"</code>, only relevant in
case of two&ndash;ways effects models (where it defaults to <code>"individual"</code>),</p>
</td></tr>
<tr><td><code id="fixef.plm_+3A_type">type</code></td>
<td>
<p>one of <code>"level"</code>, <code>"dfirst"</code>, or <code>"dmean"</code>,</p>
</td></tr>
<tr><td><code id="fixef.plm_+3A_vcov">vcov</code></td>
<td>
<p>a variance&ndash;covariance matrix furnished by the user or
a function to calculate one (see <strong>Examples</strong>),</p>
</td></tr>
<tr><td><code id="fixef.plm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="fixef.plm_+3A_x">x</code>, <code id="fixef.plm_+3A_object">object</code></td>
<td>
<p>an object of class <code>"plm"</code>, an object of class
<code>"fixef"</code> for the <code>print</code> and the <code>summary</code> method,</p>
</td></tr>
<tr><td><code id="fixef.plm_+3A_digits">digits</code></td>
<td>
<p>digits,</p>
</td></tr>
<tr><td><code id="fixef.plm_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the print output,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>fixef</code> calculates the fixed effects and returns an object
of class <code>c("fixef", "numeric")</code>. By setting the <code>type</code> argument,
the fixed effects may be returned in levels (<code>"level"</code>), as
deviations from the first value of the index (<code>"dfirst"</code>), or as
deviations from the overall mean (<code>"dmean"</code>). If the argument
<code>vcov</code> was specified, the standard errors (stored as attribute &quot;se&quot;
in the return value) are the respective robust standard errors.
For two-way fixed-effect models, argument <code>effect</code> controls which
of the fixed effects are to be extracted: <code>"individual"</code>, <code>"time"</code>, or
the sum of individual and time effects (<code>"twoways"</code>).
NB: See <strong>Examples</strong> for how the sum of effects can be split in an individual
and a time component.
For one-way models, the effects of the model are extracted and the
argument <code>effect</code> is disrespected.
</p>
<p>The associated <code>summary</code> method returns an extended object of class
<code>c("summary.fixef", "matrix")</code> with more information (see sections
<strong>Value</strong> and <strong>Examples</strong>).
</p>
<p>References with formulae (except for the two-ways unbalanced case)
are, e.g., Greene (2012), Ch. 11.4.4, p. 364,
formulae (11-25); Wooldridge (2010), Ch. 10.5.3,
pp. 308-309, formula (10.58).
</p>


<h3>Value</h3>

<p>For function <code>fixef</code>, an object of class <code>c("fixef", "numeric")</code>
is returned: It is a numeric vector containing
the fixed effects with attribute <code>se</code> which contains the
standard errors. There are two further attributes: attribute
<code>type</code> contains the chosen type (the value of argument <code>type</code>
as a character); attribute <code>df.residual</code> holds the residual
degrees of freedom (integer) from the fixed effects model (plm
object) on which <code>fixef</code> was run. For the two-way unbalanced case, only
attribute <code>type</code> is added.
</p>
<p>For function <code>summary.fixef</code>, an object of class
<code>c("summary.fixef", "matrix")</code> is returned: It is a matrix with four
columns in this order: the estimated fixed effects, their standard
errors and associated t&ndash;values and p&ndash;values.
For the two-ways unbalanced case, the matrix contains only the estimates.
The type of the fixed effects and the standard errors in the
summary.fixef object correspond to was requested in the <code>fixef</code>
function by arguments <code>type</code> and <code>vcov</code>, respectively.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>Greene WH (2012).
<em>Econometric Analysis</em>, 7th edition.
Prentice Hall.<br /><br /> Wooldridge JM (2010).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>, 2nd edition.
MIT Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+within_intercept">within_intercept()</a></code> for the overall intercept of fixed
effect models along its standard error, <code><a href="#topic+plm">plm()</a></code> for plm objects
and within models (= fixed effects models) in general. See
<code><a href="#topic+ranef">ranef()</a></code> to extract the random effects from a random effects
model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
gi &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "within")
fixef(gi)
summary(fixef(gi))
summary(fixef(gi))[ , c("Estimate", "Pr(&gt;|t|)")] # only estimates and p-values

# relationship of type = "dmean" and "level" and overall intercept
fx_level &lt;- fixef(gi, type = "level")
fx_dmean &lt;- fixef(gi, type = "dmean")
overallint &lt;- within_intercept(gi)
all.equal(overallint + fx_dmean, fx_level, check.attributes = FALSE) # TRUE

# extract time effects in a twoways effects model
gi_tw &lt;- plm(inv ~ value + capital, data = Grunfeld,
          model = "within", effect = "twoways")
fixef(gi_tw, effect = "time")

# with supplied variance-covariance matrix as matrix, function,
# and function with additional arguments
fx_level_robust1 &lt;- fixef(gi, vcov = vcovHC(gi))
fx_level_robust2 &lt;- fixef(gi, vcov = vcovHC)
fx_level_robust3 &lt;- fixef(gi, vcov = function(x) vcovHC(x, method = "white2"))
summary(fx_level_robust1) # gives fixed effects, robust SEs, t- and p-values

# calc. fitted values of oneway within model:
fixefs &lt;- fixef(gi)[index(gi, which = "id")]
fitted_by_hand &lt;- fixefs + gi$coefficients["value"]   * gi$model$value +
                           gi$coefficients["capital"] * gi$model$capital

# calc. fittes values of twoway unbalanced within model via effects:
gtw_u &lt;- plm(inv ~ value + capital, data = Grunfeld[-200, ], effect = "twoways")
yhat &lt;- as.numeric(gtw_u$model[ , 1] - gtw_u$residuals) # reference
pred_beta &lt;- as.numeric(tcrossprod(coef(gtw_u), as.matrix(gtw_u$model[ , -1])))
pred_effs &lt;- as.numeric(fixef(gtw_u, "twoways")) # sum of ind and time effects
all.equal(pred_effs + pred_beta, yhat) # TRUE

# Splits of summed up individual and time effects:
# use one "level" and one "dfirst"
ii &lt;- index(gtw_u)[[1L]]; it &lt;- index(gtw_u)[[2L]]
eff_id_dfirst &lt;- c(0, as.numeric(fixef(gtw_u, "individual", "dfirst")))[ii]
eff_ti_dfirst &lt;- c(0, as.numeric(fixef(gtw_u, "time",       "dfirst")))[it]
eff_id_level &lt;- as.numeric(fixef(gtw_u, "individual"))[ii]
eff_ti_level &lt;- as.numeric(fixef(gtw_u, "time"))[it]

all.equal(pred_effs, eff_id_level  + eff_ti_dfirst) # TRUE
all.equal(pred_effs, eff_id_dfirst + eff_ti_level)  # TRUE

</code></pre>

<hr>
<h2 id='Gasoline'>Gasoline Consumption</h2><span id='topic+Gasoline'></span>

<h3>Description</h3>

<p>A panel of 18 observations from 1960 to 1978
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>country</dt><dd><p>a factor with 18 levels</p>
</dd>
<dt>year</dt><dd><p>the year</p>
</dd>
<dt>lgaspcar</dt><dd><p>logarithm of motor gasoline consumption per car</p>
</dd>
<dt>lincomep</dt><dd><p>logarithm of real per-capita income</p>
</dd>
<dt>lrpmg</dt><dd><p>logarithm of real motor gasoline price</p>
</dd>
<dt>lcarpcap</dt><dd><p>logarithm of the stock of cars per capita</p>
</dd>
</dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 342
</p>
<p><em>observation</em> : country
</p>
<p><em>country</em> : OECD
</p>


<h3>Source</h3>

<p>Online complements to Baltagi (2001):
</p>
<p><a href="https://www.wiley.com/legacy/wileychi/baltagi/">https://www.wiley.com/legacy/wileychi/baltagi/</a>
</p>
<p>Online complements to Baltagi (2013):
</p>
<p><a href="https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452">https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452</a>
</p>


<h3>References</h3>

<p>Baltagi BH (2001).
<em>Econometric Analysis of Panel Data</em>, 3rd edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH, Griffin JM (1983).
&ldquo;Gasoline demand in the OECD: An application of pooling and testing procedures.&rdquo;
<em>European Economic Review</em>, <b>22</b>(2), 117 - 137.
ISSN 0014-2921, <a href="https://www.sciencedirect.com/science/article/pii/0014292183900776">https://www.sciencedirect.com/science/article/pii/0014292183900776</a>.
</p>

<hr>
<h2 id='Grunfeld'>Grunfeld's Investment Data</h2><span id='topic+Grunfeld'></span>

<h3>Description</h3>

<p>A balanced panel of 10 observational units (firms) from 1935 to 1954
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>firm</dt><dd><p>observation</p>
</dd>
<dt>year</dt><dd><p>date</p>
</dd>
<dt>inv</dt><dd><p>gross Investment</p>
</dd>
<dt>value</dt><dd><p>value of the firm</p>
</dd>
<dt>capital</dt><dd><p>stock of plant and equipment</p>
</dd> </dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 200
</p>
<p><em>observation</em> : production units
</p>
<p><em>country</em> : United States
</p>


<h3>Note</h3>

<p>The Grunfeld data as provided in package <code>plm</code> is the
same data as used in Baltagi (2001), see <strong>Examples</strong> below.
</p>
<p>NB:<br /> Various versions of the Grunfeld data circulate
online. Also, various text books (and also varying among editions)
and papers use different subsets of the original Grunfeld data,
some of which contain errors in a few data points compared to the
original data used by Grunfeld (1958) in his PhD thesis. See
Kleiber/Zeileis (2010) and its accompanying website for a
comparison of various Grunfeld data sets in use.
</p>


<h3>Source</h3>

<p>Online complements to Baltagi (2001):
</p>
<p><a href="https://www.wiley.com/legacy/wileychi/baltagi/">https://www.wiley.com/legacy/wileychi/baltagi/</a>
</p>
<p><a href="https://www.wiley.com/legacy/wileychi/baltagi/supp/Grunfeld.fil">https://www.wiley.com/legacy/wileychi/baltagi/supp/Grunfeld.fil</a>
</p>
<p>Online complements to Baltagi (2013):
</p>
<p><a href="https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452">https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452</a>
</p>


<h3>References</h3>

<p>Baltagi BH (2001).
<em>Econometric Analysis of Panel Data</em>, 3rd edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Grunfeld Y (1958).
<em>The determinants of corporate investment</em>.
Ph.D. thesis, Department of Economics, University of Chicago.
</p>
<p>Kleiber C, Zeileis A (2010).
&ldquo;The Grunfeld Data at 50.&rdquo;
<em>German Economic Review</em>, <b>11</b>, 404-417.
<a href="https://doi.org/10.1111/j.1468-0475.2010.00513.x">https://doi.org/10.1111/j.1468-0475.2010.00513.x</a>.
</p>
<p>website accompanying the paper with various variants of the
Grunfeld data:
<a href="https://www.zeileis.org/grunfeld/">https://www.zeileis.org/grunfeld/</a>.
</p>


<h3>See Also</h3>

<p>For the complete Grunfeld data (11 firms), see
<a href="AER.html#topic+Grunfeld">AER::Grunfeld</a>, in the <code>AER</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# Compare plm's Grunfeld data to Baltagi's (2001) Grunfeld data:
  data("Grunfeld", package="plm")
  Grunfeld_baltagi2001 &lt;- read.csv("http://www.wiley.com/legacy/wileychi/
    baltagi/supp/Grunfeld.fil", sep="", header = FALSE)
  library(compare)
  compare::compare(Grunfeld, Grunfeld_baltagi2001, allowAll = T) # same data set
  
## End(Not run)

</code></pre>

<hr>
<h2 id='has.intercept'>Check for the presence of an intercept in a formula or in a fitted
model</h2><span id='topic+has.intercept'></span><span id='topic+has.intercept.default'></span><span id='topic+has.intercept.formula'></span><span id='topic+has.intercept.Formula'></span><span id='topic+has.intercept.panelmodel'></span><span id='topic+has.intercept.plm'></span>

<h3>Description</h3>

<p>The presence of an intercept is checked using the formula which is
either provided as the argument of the function or extracted from
a fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>has.intercept(object, ...)

## Default S3 method:
has.intercept(object, data = NULL, ...)

## S3 method for class 'formula'
has.intercept(object, data = NULL, ...)

## S3 method for class 'Formula'
has.intercept(object, rhs = NULL, data = NULL, ...)

## S3 method for class 'panelmodel'
has.intercept(object, ...)

## S3 method for class 'plm'
has.intercept(object, rhs = 1L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="has.intercept_+3A_object">object</code></td>
<td>
<p>a <code>formula</code>, a <code>Formula</code> or a fitted model (of class
<code>plm</code> or <code>panelmodel</code>),</p>
</td></tr>
<tr><td><code id="has.intercept_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="has.intercept_+3A_data">data</code></td>
<td>
<p>default is <code>NULL</code> and only needs to be changes to a data set if
the formula contains a dot (<code>.</code>) to allow evaluation of the dot,</p>
</td></tr>
<tr><td><code id="has.intercept_+3A_rhs">rhs</code></td>
<td>
<p>an integer (length &gt; 1 is possible), indicating the parts of right
hand sides of the formula to be evaluated for the presence of an
intercept or <code>NULL</code> for all parts of the right hand side
(relevant for the <code>Formula</code> and the <code>plm</code> methods),</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a logical
</p>

<hr>
<h2 id='Hedonic'>Hedonic Prices of Census Tracts in the Boston Area</h2><span id='topic+Hedonic'></span>

<h3>Description</h3>

<p>A cross-section
</p>


<h3>Format</h3>

<p>A dataframe containing:
</p>

<dl>
<dt>mv</dt><dd><p>median value of owner&ndash;occupied homes</p>
</dd>
<dt>crim</dt><dd><p>crime rate</p>
</dd>
<dt>zn</dt><dd><p>proportion of 25,000 square feet residential lots</p>
</dd>
<dt>indus</dt><dd><p>proportion of no&ndash;retail business acres</p>
</dd>
<dt>chas</dt><dd><p>is the tract bounds the Charles River?</p>
</dd>
<dt>nox</dt><dd><p>annual average nitrogen oxide concentration in parts per hundred million</p>
</dd>
<dt>rm</dt><dd><p>average number of rooms</p>
</dd>
<dt>age</dt><dd><p>proportion of owner units built prior to 1940</p>
</dd>
<dt>dis</dt><dd><p>weighted distances to five employment centers in the Boston area</p>
</dd>
<dt>rad</dt><dd><p>index of accessibility to radial highways</p>
</dd>
<dt>tax</dt><dd><p>full value property tax rate ($/$10,000)</p>
</dd>
<dt>ptratio</dt><dd><p>pupil/teacher ratio</p>
</dd>
<dt>blacks</dt><dd><p>proportion of blacks in the population</p>
</dd>
<dt>lstat</dt><dd><p>proportion of population that is lower status</p>
</dd>
<dt>townid</dt><dd><p>town identifier</p>
</dd> </dl>



<h3>Details</h3>

<p><em>number of observations</em> : 506
</p>
<p><em>observation</em> : regional
</p>
<p><em>country</em> : United States
</p>


<h3>Source</h3>

<p>Online complements to Baltagi (2001):
</p>
<p><a href="https://www.wiley.com/legacy/wileychi/baltagi/">https://www.wiley.com/legacy/wileychi/baltagi/</a>
</p>
<p>Online complements to Baltagi (2013):
</p>
<p><a href="https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452">https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452</a>
</p>


<h3>References</h3>

<p>Baltagi BH (2001).
<em>Econometric Analysis of Panel Data</em>, 3rd edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Besley DA, Kuh E, Welsch RE (1980).
<em>Regression diagnostics: identifying influential data and sources of collinearity</em>.
John Wiley and Sons ltd.
Wiley series in probability and statistics.
</p>
<p>Harrison D, Rubinfeld DL (1978).
&ldquo;Hedonic housing prices and the demand for clean air.&rdquo;
<em>Journal of Environmental Economics and Management</em>, <b>5</b>, 81-102.
</p>

<hr>
<h2 id='index.plm'>Extract the indexes of panel data</h2><span id='topic+index.plm'></span><span id='topic+index'></span><span id='topic+index.pindex'></span><span id='topic+index.pdata.frame'></span><span id='topic+index.pseries'></span><span id='topic+index.panelmodel'></span>

<h3>Description</h3>

<p>This function extracts the information about the structure of the
individual and time dimensions of panel data. Grouping information
can also be extracted if the panel data were created with a
grouping variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pindex'
index(x, which = NULL, ...)

## S3 method for class 'pdata.frame'
index(x, which = NULL, ...)

## S3 method for class 'pseries'
index(x, which = NULL, ...)

## S3 method for class 'panelmodel'
index(x, which = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="index.plm_+3A_x">x</code></td>
<td>
<p>an object of class <code>"pindex"</code>, <code>"pdata.frame"</code>,
<code>"pseries"</code> or <code>"panelmodel"</code>,</p>
</td></tr>
<tr><td><code id="index.plm_+3A_which">which</code></td>
<td>
<p>the index(es) to be extracted (see details),</p>
</td></tr>
<tr><td><code id="index.plm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Panel data are stored in a <code>"pdata.frame"</code> which has an <code>"index"</code>
attribute. Fitted models in <code>"plm"</code> have a <code>"model"</code> element which
is also a <code>"pdata.frame"</code> and therefore also has an <code>"index"</code>
attribute. Finally, each series, once extracted from a
<code>"pdata.frame"</code>, becomes of class <code>"pseries"</code>, which also has this
<code>"index"</code> attribute.  <code>"index"</code> methods are available for all these
objects.  The argument <code>"which"</code> indicates which index should be
extracted. If <code>which = NULL</code>, all indexes are extracted. <code>"which"</code>
can also be a vector of length 1, 2, or 3 (3 only if the pdata
frame was constructed with an additional group index) containing
either characters (the names of the individual variable and/or of
the time variable and/or the group variable or <code>"id"</code> and <code>"time"</code>)
and <code>"group"</code> or integers (1 for the individual index, 2 for the
time index, and 3 for the group index (the latter only if the pdata
frame was constructed with such).)
</p>


<h3>Value</h3>

<p>A vector or an object of class <code>c("pindex","data.frame")</code>
containing either one index, individual and time index, or (any
combination of) individual, time and group indexes.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdata.frame">pdata.frame()</a></code>, <code><a href="#topic+plm">plm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
Gr &lt;- pdata.frame(Grunfeld, index = c("firm", "year"))
m &lt;- plm(inv ~ value + capital, data = Gr)
index(Gr, "firm")
index(Gr, "time")
index(Gr$inv, c(2, 1))
index(m, "id")

# with additional group index
data("Produc", package = "plm")
pProduc &lt;- pdata.frame(Produc, index = c("state", "year", "region"))
index(pProduc, 3)
index(pProduc, "region")
index(pProduc, "group")

</code></pre>

<hr>
<h2 id='is.pbalanced'>Check if data are balanced</h2><span id='topic+is.pbalanced'></span><span id='topic+is.pbalanced.default'></span><span id='topic+is.pbalanced.data.frame'></span><span id='topic+is.pbalanced.pdata.frame'></span><span id='topic+is.pbalanced.pseries'></span><span id='topic+is.pbalanced.pggls'></span><span id='topic+is.pbalanced.pcce'></span><span id='topic+is.pbalanced.pmg'></span><span id='topic+is.pbalanced.pgmm'></span><span id='topic+is.pbalanced.panelmodel'></span>

<h3>Description</h3>

<p>This function checks if the data are balanced, i.e., if each individual has
the same time periods
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.pbalanced(x, ...)

## Default S3 method:
is.pbalanced(x, y, ...)

## S3 method for class 'data.frame'
is.pbalanced(x, index = NULL, ...)

## S3 method for class 'pdata.frame'
is.pbalanced(x, ...)

## S3 method for class 'pseries'
is.pbalanced(x, ...)

## S3 method for class 'pggls'
is.pbalanced(x, ...)

## S3 method for class 'pcce'
is.pbalanced(x, ...)

## S3 method for class 'pmg'
is.pbalanced(x, ...)

## S3 method for class 'pgmm'
is.pbalanced(x, ...)

## S3 method for class 'panelmodel'
is.pbalanced(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.pbalanced_+3A_x">x</code></td>
<td>
<p>an object of class <code>pdata.frame</code>, <code>data.frame</code>,
<code>pseries</code>, <code>panelmodel</code>, or <code>pgmm</code>,</p>
</td></tr>
<tr><td><code id="is.pbalanced_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="is.pbalanced_+3A_y">y</code></td>
<td>
<p>(only in default method) the time index variable (2nd index
variable),</p>
</td></tr>
<tr><td><code id="is.pbalanced_+3A_index">index</code></td>
<td>
<p>only relevant for <code>data.frame</code> interface; if
<code>NULL</code>, the first two columns of the data.frame are
assumed to be the index variables; if not <code>NULL</code>, both
dimensions ('individual', 'time') need to be specified by
<code>index</code> as character of length 2 for data frames, for
further details see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Balanced data are data for which each individual has the same time periods.
The returned values of the <code>is.pbalanced(object)</code> methods are identical
to <code>pdim(object)$balanced</code>.  <code>is.pbalanced</code> is provided as a short
cut and is faster than <code>pdim(object)$balanced</code> because it avoids those
computations performed by <code>pdim</code> which are unnecessary to determine the
balancedness of the data.
</p>


<h3>Value</h3>

<p>A logical indicating whether the data associated with
object <code>x</code> are balanced (<code>TRUE</code>) or not
(<code>FALSE</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+punbalancedness">punbalancedness()</a></code> for two measures of
unbalancedness, <code><a href="#topic+make.pbalanced">make.pbalanced()</a></code> to make data
balanced; <code><a href="#topic+is.pconsecutive">is.pconsecutive()</a></code> to check if data are
consecutive; <code><a href="#topic+make.pconsecutive">make.pconsecutive()</a></code> to make data
consecutive (and, optionally, also balanced).<br />
<code><a href="#topic+pdim">pdim()</a></code> to check the dimensions of a 'pdata.frame'
(and other objects), <code><a href="#topic+pvar">pvar()</a></code> to check for individual
and time variation of a 'pdata.frame' (and other objects),
<code><a href="#topic+pseries">pseries()</a></code>, <code><a href="base.html#topic+data.frame">data.frame()</a></code>,
<code><a href="#topic+pdata.frame">pdata.frame()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# take balanced data and make it unbalanced
# by deletion of 2nd row (2nd time period for first individual)
data("Grunfeld", package = "plm")
Grunfeld_missing_period &lt;- Grunfeld[-2, ]
is.pbalanced(Grunfeld_missing_period)     # check if balanced: FALSE
pdim(Grunfeld_missing_period)$balanced    # same

# pdata.frame interface
pGrunfeld_missing_period &lt;- pdata.frame(Grunfeld_missing_period)
is.pbalanced(Grunfeld_missing_period)

# pseries interface
is.pbalanced(pGrunfeld_missing_period$inv)

</code></pre>

<hr>
<h2 id='is.pconsecutive'>Check if time periods are consecutive</h2><span id='topic+is.pconsecutive'></span><span id='topic+is.pconsecutive.default'></span><span id='topic+is.pconsecutive.data.frame'></span><span id='topic+is.pconsecutive.pseries'></span><span id='topic+is.pconsecutive.pdata.frame'></span><span id='topic+is.pconsecutive.panelmodel'></span>

<h3>Description</h3>

<p>This function checks for each individual if its associated time periods are
consecutive (no &quot;gaps&quot; in time dimension per individual)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.pconsecutive(x, ...)

## Default S3 method:
is.pconsecutive(x, id, time, na.rm.tindex = FALSE, ...)

## S3 method for class 'data.frame'
is.pconsecutive(x, index = NULL, na.rm.tindex = FALSE, ...)

## S3 method for class 'pseries'
is.pconsecutive(x, na.rm.tindex = FALSE, ...)

## S3 method for class 'pdata.frame'
is.pconsecutive(x, na.rm.tindex = FALSE, ...)

## S3 method for class 'panelmodel'
is.pconsecutive(x, na.rm.tindex = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.pconsecutive_+3A_x">x</code></td>
<td>
<p>usually, an object of class <code>pdata.frame</code>,
<code>data.frame</code>, <code>pseries</code>, or an estimated
<code>panelmodel</code>; for the default method <code>x</code> can also be
an arbitrary vector or <code>NULL</code>, see <strong>Details</strong>,</p>
</td></tr>
<tr><td><code id="is.pconsecutive_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="is.pconsecutive_+3A_id">id</code>, <code id="is.pconsecutive_+3A_time">time</code></td>
<td>
<p>only relevant for default method: vectors specifying
the id and time dimensions, i. e., a sequence of individual and
time identifiers, each as stacked time series,</p>
</td></tr>
<tr><td><code id="is.pconsecutive_+3A_na.rm.tindex">na.rm.tindex</code></td>
<td>
<p>logical indicating whether any <code>NA</code> values
in the time index are removed before consecutiveness is
evaluated (defaults to <code>FALSE</code>),</p>
</td></tr>
<tr><td><code id="is.pconsecutive_+3A_index">index</code></td>
<td>
<p>only relevant for <code>data.frame</code> interface; if
<code>NULL</code>, the first two columns of the data.frame are
assumed to be the index variables; if not <code>NULL</code>, both
dimensions ('individual', 'time') need to be specified by
<code>index</code> for <code>is.pconsecutive</code> on data frames, for
further details see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(p)data.frame, pseries and estimated panelmodel objects can be tested if
their time periods are consecutive per individual.  For evaluation of
consecutiveness, the time dimension is interpreted to be numeric, and the
data are tested for being a regularly spaced sequence with distance 1
between the time periods for each individual (for each individual the time
dimension can be interpreted as sequence t, t+1, t+2, ... where t is an
integer). As such, the &quot;numerical content&quot; of the time index variable is
considered for consecutiveness, not the &quot;physical position&quot; of the various
observations for an individuals in the (p)data.frame/pseries (it is not
about &quot;neighbouring&quot; rows). If the object to be evaluated is a pseries or a
pdata.frame, the time index is coerced from factor via as.character to
numeric, i.e., the series
<code style="white-space: pre;">&#8288;as.numeric(as.character(index(&lt;pseries/pdata.frame&gt;)[[2]]))]&#8288;</code> is
evaluated for gaps.
</p>
<p>The default method also works for argument <code>x</code> being an arbitrary
vector (see <strong>Examples</strong>), provided one can supply arguments <code>id</code>
and <code>time</code>, which need to ordered as stacked time series. As only
<code>id</code> and <code>time</code> are really necessary for the default method to
evaluate the consecutiveness, <code>x = NULL</code> is also possible. However, if
the vector <code>x</code> is also supplied, additional input checking for equality
of the lengths of <code>x</code>, <code>id</code> and <code>time</code> is performed, which is
safer.
</p>
<p>For the data.frame interface, the data is ordered in the appropriate way
(stacked time series) before the consecutiveness is evaluated. For the
pdata.frame and pseries interface, ordering is not performed because both
data types are already ordered in the appropriate way when created.
</p>
<p>Note: Only the presence of the time period itself in the object is tested,
not if there are any other variables.  <code>NA</code> values in individual index
are not examined but silently dropped - In this case, it is not clear which
individual is meant by id value <code>NA</code>, thus no statement about
consecutiveness of time periods for those &quot;<code>NA</code>-individuals&quot; is
possible.
</p>


<h3>Value</h3>

<p>A named <code>logical</code> vector (names are those of the
individuals). The i-th element of the returned vector
corresponds to the i-th individual. The values of the i-th
element can be: </p>
<table>
<tr><td><code>TRUE</code></td>
<td>
<p>if the i-th individual has
consecutive time periods,</p>
</td></tr> <tr><td><code>FALSE</code></td>
<td>
<p>if the i-th
individual has non-consecutive time periods,</p>
</td></tr>
<tr><td><code>"NA"</code></td>
<td>
<p>if there are any NA values in time index of
the i-th the individual; see also argument <code>na.rm.tindex</code>
to remove those.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>See Also</h3>

<p><code><a href="#topic+make.pconsecutive">make.pconsecutive()</a></code> to make data consecutive
(and, as an option, balanced at the same time) and
<code><a href="#topic+make.pbalanced">make.pbalanced()</a></code> to make data balanced.<br />
<code><a href="#topic+pdim">pdim()</a></code> to check the dimensions of a 'pdata.frame'
(and other objects), <code><a href="#topic+pvar">pvar()</a></code> to check for individual
and time variation of a 'pdata.frame' (and other objects),
<code><a href="#topic+lag">lag()</a></code> for lagged (and leading) values of a
'pseries' object.<br />
</p>
<p><code><a href="#topic+pseries">pseries()</a></code>, <code><a href="base.html#topic+data.frame">data.frame()</a></code>, <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,
for class 'panelmodel' see <code><a href="#topic+plm">plm()</a></code> and <code><a href="#topic+pgmm">pgmm()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
is.pconsecutive(Grunfeld)
is.pconsecutive(Grunfeld, index=c("firm", "year"))

# delete 2nd row (2nd time period for first individual)
# -&gt; non consecutive 
Grunfeld_missing_period &lt;- Grunfeld[-2, ]
is.pconsecutive(Grunfeld_missing_period)
all(is.pconsecutive(Grunfeld_missing_period)) # FALSE

# delete rows 1 and 2 (1st and 2nd time period for first individual)
# -&gt; consecutive
Grunfeld_missing_period_other &lt;- Grunfeld[-c(1,2), ]
is.pconsecutive(Grunfeld_missing_period_other) # all TRUE

# delete year 1937 (3rd period) for _all_ individuals
Grunfeld_wo_1937 &lt;- Grunfeld[Grunfeld$year != 1937, ]
is.pconsecutive(Grunfeld_wo_1937) # all FALSE

# pdata.frame interface
pGrunfeld &lt;- pdata.frame(Grunfeld)
pGrunfeld_missing_period &lt;- pdata.frame(Grunfeld_missing_period)
is.pconsecutive(pGrunfeld) # all TRUE
is.pconsecutive(pGrunfeld_missing_period) # first FALSE, others TRUE


# panelmodel interface (first, estimate some models)
mod_pGrunfeld &lt;- plm(inv ~ value + capital, data = Grunfeld)
mod_pGrunfeld_missing_period &lt;- plm(inv ~ value + capital, data = Grunfeld_missing_period)

is.pconsecutive(mod_pGrunfeld)
is.pconsecutive(mod_pGrunfeld_missing_period)

nobs(mod_pGrunfeld) # 200
nobs(mod_pGrunfeld_missing_period) # 199


# pseries interface
pinv &lt;- pGrunfeld$inv
pinv_missing_period &lt;- pGrunfeld_missing_period$inv

is.pconsecutive(pinv)
is.pconsecutive(pinv_missing_period)

# default method for arbitrary vectors or NULL
inv &lt;- Grunfeld$inv
inv_missing_period &lt;- Grunfeld_missing_period$inv
is.pconsecutive(inv, id = Grunfeld$firm, time = Grunfeld$year)
is.pconsecutive(inv_missing_period, id = Grunfeld_missing_period$firm, 
                                    time = Grunfeld_missing_period$year)

# (not run) demonstrate mismatch lengths of x, id, time 
# is.pconsecutive(x = inv_missing_period, id = Grunfeld$firm, time = Grunfeld$year)

# only id and time are needed for evaluation
is.pconsecutive(NULL, id = Grunfeld$firm, time = Grunfeld$year)

</code></pre>

<hr>
<h2 id='is.pseries'>Check if an object is a pseries</h2><span id='topic+is.pseries'></span>

<h3>Description</h3>

<p>This function checks if an object qualifies as a pseries
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.pseries(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.pseries_+3A_object">object</code></td>
<td>
<p>object to be checked for pseries features</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A <code>"pseries"</code> is a wrapper around a &quot;basic class&quot; (numeric, factor,
logical, character, or complex).
</p>
<p>To qualify as a pseries, an object needs to have the following
features:
</p>

<ul>
<li><p> class contains <code>"pseries"</code> and there are at least two classes
(<code>"pseries"</code> and the basic class),
</p>
</li>
<li><p> have an appropriate index attribute (defines the panel
structure),
</p>
</li>
<li><p> any of <code>is.numeric</code>, <code>is.factor</code>, <code>is.logical</code>, <code>is.character</code>,
<code>is.complex</code> is <code>TRUE</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A logical indicating whether the object is a pseries (<code>TRUE</code>)
or not (<code>FALSE</code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pseries">pseries()</a></code> for some computations on pseries and some
further links.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create a pdata.frame and extract a series, which becomes a pseries
data("EmplUK", package = "plm")
Em &lt;- pdata.frame(EmplUK)
z &lt;- Em$output

class(z) # pseries as indicated by class
is.pseries(z) # and confirmed by check

# destroy index of pseries and re-check
attr(z, "index") &lt;- NA
is.pseries(z) # now FALSE

</code></pre>

<hr>
<h2 id='LaborSupply'>Wages and Hours Worked</h2><span id='topic+LaborSupply'></span>

<h3>Description</h3>

<p>A panel of 532 observations from 1979 to 1988
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>lnhr</dt><dd><p>log of annual hours worked</p>
</dd>
<dt>lnwg</dt><dd><p>log of hourly wage</p>
</dd>
<dt>kids</dt><dd><p>number of children</p>
</dd>
<dt>age</dt><dd><p>age</p>
</dd>
<dt>disab</dt><dd><p>bad health</p>
</dd>
<dt>id</dt><dd><p>id</p>
</dd>
<dt>year</dt><dd><p>year</p>
</dd>
</dl>



<h3>Details</h3>

<p><em>number of observations</em> : 5320
</p>


<h3>Source</h3>

<p>Online complements to Ziliak (1997).
</p>
<p>Journal of Business Economics and Statistics web site:
<a href="https://amstat.tandfonline.com/loi/ubes20/">https://amstat.tandfonline.com/loi/ubes20/</a>.
</p>


<h3>References</h3>

<p>Colin Cameron A, K. Trivedi P (2005).
<em>Microeconometrics: Methods and Applications</em>.
Cambridge University Press.
ISBN 0521848059, <a href="https://doi.org/10.1017/CBO9780511811241">doi:10.1017/CBO9780511811241</a>.
</p>
<p>Ziliak JP (1997).
&ldquo;Efficient Estimation with Panel Data When Instruments Are Predetermined: An Empirical Comparison of Moment-Condition Estimators.&rdquo;
<em>Journal of Business &amp; Economic Statistics</em>, <b>15</b>(4), 419&ndash;431.
ISSN 07350015.
</p>

<hr>
<h2 id='lag.plm'>lag, lead, and diff for panel data</h2><span id='topic+lag.plm'></span><span id='topic+lag'></span><span id='topic+lead'></span><span id='topic+diff'></span><span id='topic+lag.pseries'></span><span id='topic+lead.pseries'></span><span id='topic+diff.pseries'></span>

<h3>Description</h3>

<p>lag, lead, and diff functions for class pseries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lead(x, k = 1L, ...)

## S3 method for class 'pseries'
lag(x, k = 1L, shift = c("time", "row"), ...)

## S3 method for class 'pseries'
lead(x, k = 1L, shift = c("time", "row"), ...)

## S3 method for class 'pseries'
diff(x, lag = 1L, shift = c("time", "row"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lag.plm_+3A_x">x</code></td>
<td>
<p>a <code>pseries</code> object,</p>
</td></tr>
<tr><td><code id="lag.plm_+3A_k">k</code></td>
<td>
<p>an integer, the number of lags for the <code>lag</code> and <code>lead</code>
methods (can also be negative).  For the <code>lag</code> method, a
positive (negative) <code>k</code> gives lagged (leading) values.  For the
<code>lead</code> method, a positive (negative) <code>k</code> gives leading (lagged)
values, thus, <code>lag(x, k = -1L)</code> yields the same as <code>lead(x, k = 1L)</code>.
If <code>k</code> is an integer with length &gt; 1 (<code>k = c(k1, k2, ...)</code>), a
<code>matrix</code> with multiple lagged <code>pseries</code> is returned,</p>
</td></tr>
<tr><td><code id="lag.plm_+3A_...">...</code></td>
<td>
<p>further arguments (currently none evaluated).</p>
</td></tr>
<tr><td><code id="lag.plm_+3A_shift">shift</code></td>
<td>
<p>character, either <code>"time"</code> (default) or <code>"row"</code>
determining how the shifting in the <code>lag</code>/<code>lead</code>/<code>diff</code>
functions is performed (see Details and Examples).</p>
</td></tr>
<tr><td><code id="lag.plm_+3A_lag">lag</code></td>
<td>
<p>integer, the number of lags for the <code>diff</code> method, can also be of
length &gt; 1 (see argument <code>k</code>) (only non&ndash;negative values in
argument <code>lag</code> are allowed for <code>diff</code>),</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This set of functions perform lagging, leading (lagging in the
opposite direction), and differencing operations on <code>pseries</code>
objects, i. e., they take the panel structure of the data into
account by performing the operations per individual.
</p>
<p>Argument <code>shift</code> controls the shifting of observations to be used
by methods <code>lag</code>, <code>lead</code>, and <code>diff</code>:
</p>

<ul>
<li> <p><code>shift = "time"</code> (default): Methods respect the
numerical value in the time dimension of the index. The time
dimension needs to be interpretable as a sequence t, t+1, t+2,
... where t is an integer (from a technical viewpoint,
<code>as.numeric(as.character(index(your_pdata.frame)[[2]]))</code> needs to
result in a meaningful integer).
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;shift = "row": &#8288;</code>Methods perform the shifting operation based
solely on the &quot;physical position&quot; of the observations,
i.e., neighbouring rows are shifted per individual. The value in the
time index is not relevant in this case.
</p>
</li></ul>

<p>For consecutive time periods per individual, a switch of shifting
behaviour results in no difference. Different return values will
occur for non-consecutive time periods per individual
(&quot;holes in time&quot;), see also Examples.
</p>


<h3>Value</h3>


<ul>
<li><p> An object of class <code>pseries</code>, if the argument specifying the lag
has length 1 (argument <code>k</code> in functions <code>lag</code> and <code>lead</code>,
argument <code>lag</code> in function <code>diff</code>).
</p>
</li>
<li><p> A matrix containing the various series in its columns, if the
argument specifying the lag has length &gt; 1.
</p>
</li></ul>



<h3>Note</h3>

<p>The sign of <code>k</code> in <code>lag.pseries</code> results in inverse behaviour
compared to <code><a href="stats.html#topic+lag">stats::lag()</a></code> and <code><a href="zoo.html#topic+lag.zoo">zoo::lag.zoo()</a></code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant and Kevin Tappe
</p>


<h3>See Also</h3>

<p>To check if the time periods are consecutive per
individual, see <code><a href="#topic+is.pconsecutive">is.pconsecutive()</a></code>.
</p>
<p>For further function for 'pseries' objects: <code><a href="#topic+between">between()</a></code>,
<a href="#topic+between">Between()</a>, <code><a href="#topic+Within">Within()</a></code>, <code><a href="#topic+summary.pseries">summary.pseries()</a></code>,
<code><a href="#topic+print.summary.pseries">print.summary.pseries()</a></code>, <code><a href="#topic+as.matrix.pseries">as.matrix.pseries()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# First, create a pdata.frame
data("EmplUK", package = "plm")
Em &lt;- pdata.frame(EmplUK)

# Then extract a series, which becomes additionally a pseries
z &lt;- Em$output
class(z)

# compute the first and third lag, and the difference lagged twice
lag(z)
lag(z, 3L)
diff(z, 2L)

# compute negative lags (= leading values)
lag(z, -1L)
lead(z, 1L) # same as line above
identical(lead(z, 1L), lag(z, -1L)) # TRUE
 
# compute more than one lag and diff at once (matrix returned)
lag(z, c(1L,2L))
diff(z, c(1L,2L))

## demonstrate behaviour of shift = "time" vs. shift = "row"
# delete 2nd time period for first individual (1978 is missing (not NA)):
Em_hole &lt;- Em[-2L, ]
is.pconsecutive(Em_hole) # check: non-consecutive for 1st individual now

# original non-consecutive data:
head(Em_hole$emp, 10) 
# for shift = "time", 1-1979 contains the value of former 1-1977 (2 periods lagged):
head(lag(Em_hole$emp, k = 2L, shift = "time"), 10L)
# for shift = "row", 1-1979 contains NA (2 rows lagged (and no entry for 1976):
head(lag(Em_hole$emp, k = 2L, shift = "row"), 10L)

</code></pre>

<hr>
<h2 id='make.dummies'>Create a Dummy Matrix</h2><span id='topic+make.dummies'></span><span id='topic+make.dummies.default'></span><span id='topic+make.dummies.data.frame'></span><span id='topic+make.dummies.pdata.frame'></span>

<h3>Description</h3>

<p>Contrast-coded dummy matrix (treatment coding) created from a factor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.dummies(x, ...)

## Default S3 method:
make.dummies(x, base = 1L, base.add = TRUE, ...)

## S3 method for class 'data.frame'
make.dummies(x, col, base = 1L, base.add = TRUE, ...)

## S3 method for class 'pdata.frame'
make.dummies(x, col, base = 1L, base.add = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.dummies_+3A_x">x</code></td>
<td>
<p>a factor from which the dummies are created (x is coerced to
factor if not yet a factor) for the default method or a data
data frame/pdata.frame for the respective method.</p>
</td></tr>
<tr><td><code id="make.dummies_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="make.dummies_+3A_base">base</code></td>
<td>
<p>integer or character, specifies the reference level (base), if
integer it refers to position in <code>levels(x)</code>, if character the name
of a level,</p>
</td></tr>
<tr><td><code id="make.dummies_+3A_base.add">base.add</code></td>
<td>
<p>logical, if <code>TRUE</code> the reference level (base) is added
to the return value as first column, if <code>FALSE</code> the reference
level is not included.</p>
</td></tr>
<tr><td><code id="make.dummies_+3A_col">col</code></td>
<td>
<p>character (only for the data frame and pdata.frame methods), to
specify the column which is used to derive the dummies from,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates a matrix of dummies from the levels of a factor in
treatment coding. In model estimations, it is usually preferable to not
create the dummy matrix prior to estimation but to simply specify a factor
in the formula and let the estimation function handle the creation of the
dummies.
</p>
<p>This function is merely a convenience wrapper around <code>stats::contr.treatment</code>
to ease the dummy matrix creation process shall the dummy matrix be explicitly
required. See Examples for a use case in LSDV (least squares dummy variable)
model estimation.
</p>
<p>The default method uses a factor as main input (or something coercible to a
factor) to derive the dummy matrix from. Methods for data frame and pdata.frame
are available as well and have the additional argument <code>col</code> to specify the
the column from which the dummies are created; both methods merge the dummy
matrix to the data frame/pdata.frame yielding a ready-to-use data set.
See also Examples for use cases.
</p>


<h3>Value</h3>

<p>For the default method, a matrix containing the contrast-coded
dummies (treatment coding),
dimensions are n x n where <code>n = length(levels(x))</code> if argument
<code>base.add = TRUE</code> or <code>n = length(levels(x)-1)</code> if <code>base.add = FALSE</code>;
for the data frame and pdata.frame method, a data frame or pdata.frame,
respectively, with the dummies appropriately merged to the input as
last columns (column names are derived from the name of the column
used to create the dummies and its levels).
</p>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+contrast">stats::contr.treatment()</a></code>, <code><a href="stats.html#topic+contrasts">stats::contrasts()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(plm)
data("Grunfeld", package = "plm")
Grunfeld &lt;- Grunfeld[1:100, ] # reduce data set (down to 5 firms)

## default method
make.dummies(Grunfeld$firm) # gives 5 x 5 matrix (5 firms, base level incl.)
make.dummies(Grunfeld$firm, base = 2L, base.add = FALSE) # gives 5 x 4 matrix

## data frame method
Grun.dummies &lt;- make.dummies(Grunfeld, col = "firm")

## pdata.frame method
pGrun &lt;- pdata.frame(Grunfeld)
pGrun.dummies &lt;- make.dummies(pGrun, col = "firm")

## Model estimation:
## estimate within model (individual/firm effects) and LSDV models (firm dummies)
# within model:
plm(inv ~ value + capital, data = pGrun, model = "within")

## LSDV with user-created dummies by make.dummies:
form_dummies &lt;- paste0("firm", c(1:5), collapse = "+")
form_dummies &lt;- formula(paste0("inv ~ value + capital + ", form_dummies))
plm(form_dummies, data = pGrun.dummies, model = "pooling") # last dummy is dropped

# LSDV via factor(year) -&gt; let estimation function generate dummies:
plm(inv ~ value + capital + factor(firm), data = pGrun, model = "pooling")
</code></pre>

<hr>
<h2 id='make.pbalanced'>Make data balanced</h2><span id='topic+make.pbalanced'></span><span id='topic+make.pbalanced.pdata.frame'></span><span id='topic+make.pbalanced.pseries'></span><span id='topic+make.pbalanced.data.frame'></span>

<h3>Description</h3>

<p>This function makes the data balanced, i.e., each individual has the same
time periods, by filling in or dropping observations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.pbalanced(
  x,
  balance.type = c("fill", "shared.times", "shared.individuals"),
  ...
)

## S3 method for class 'pdata.frame'
make.pbalanced(
  x,
  balance.type = c("fill", "shared.times", "shared.individuals"),
  ...
)

## S3 method for class 'pseries'
make.pbalanced(
  x,
  balance.type = c("fill", "shared.times", "shared.individuals"),
  ...
)

## S3 method for class 'data.frame'
make.pbalanced(
  x,
  balance.type = c("fill", "shared.times", "shared.individuals"),
  index = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.pbalanced_+3A_x">x</code></td>
<td>
<p>an object of class <code>pdata.frame</code>, <code>data.frame</code>,
or <code>pseries</code>;</p>
</td></tr>
<tr><td><code id="make.pbalanced_+3A_balance.type">balance.type</code></td>
<td>
<p>character, one of <code>"fill"</code>,
<code>"shared.times"</code>, or <code>"shared.individuals"</code>, see
<strong>Details</strong>,</p>
</td></tr>
<tr><td><code id="make.pbalanced_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="make.pbalanced_+3A_index">index</code></td>
<td>
<p>only relevant for <code>data.frame</code> interface; if
<code>NULL</code>, the first two columns of the data.frame are
assumed to be the index variables; if not <code>NULL</code>, both
dimensions ('individual', 'time') need to be specified by
<code>index</code> as character of length 2 for data frames, for
further details see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(p)data.frame and pseries objects are made balanced, meaning each
individual has the same time periods.  Depending on the value of
<code>balance.type</code>, the balancing is done in different ways:
</p>
 <ul>
<li> <p><code>balance.type = "fill"</code> (default): The union
of available time periods over all individuals is taken (w/o
<code>NA</code> values).  Missing time periods for an individual are
identified and corresponding rows (elements for pseries) are
inserted and filled with <code>NA</code> for the non&ndash;index variables
(elements for a pseries).  This means, only time periods present
for at least one individual are inserted, if missing.
</p>
</li>
<li> <p><code>balance.type = "shared.times"</code>: The intersect of available time
periods over all individuals is taken (w/o <code>NA</code> values).  Thus, time
periods not available for all individuals are discarded, i. e., only time
periods shared by all individuals are left in the result).
</p>
</li>
<li> <p><code>balance.type = "shared.individuals"</code>: All available time periods
are kept and those individuals are dropped for which not all time periods
are available, i. e., only individuals shared by all time periods are left
in the result (symmetric to <code>"shared.times"</code>).  </p>
</li></ul>

<p>The data are not necessarily made consecutive (regular time series
with distance 1), because balancedness does not imply
consecutiveness. For making the data consecutive, use
<code><a href="#topic+make.pconsecutive">make.pconsecutive()</a></code> (and, optionally, set argument
<code>balanced = TRUE</code> to make consecutive and balanced, see also
<strong>Examples</strong> for a comparison of the two functions.
</p>
<p>Note: Rows of (p)data.frames (elements for pseries) with <code>NA</code>
values in individual or time index are not examined but silently
dropped before the data are made balanced. In this case, it cannot
be inferred which individual or time period is meant by the missing
value(s) (see also <strong>Examples</strong>).  Especially, this means:
<code>NA</code> values in the first/last position of the original time
periods for an individual are dropped, which are usually meant to
depict the beginning and ending of the time series for that
individual.  Thus, one might want to check if there are any
<code>NA</code> values in the index variables before applying
<code>make.pbalanced</code>, and especially check for <code>NA</code> values in the
first and last position for each individual in original data and,
if so, maybe set those to some meaningful begin/end value for the
time series.
</p>


<h3>Value</h3>

<p>An object of the same class as the input <code>x</code>, i.e., a
pdata.frame, data.frame or a pseries which is made balanced
based on the index variables. The returned data are sorted as a
stacked time series.
</p>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.pbalanced">is.pbalanced()</a></code> to check if data are balanced;
<code><a href="#topic+is.pconsecutive">is.pconsecutive()</a></code> to check if data are consecutive;
<code><a href="#topic+make.pconsecutive">make.pconsecutive()</a></code> to make data consecutive (and,
optionally, also balanced).<br /> <code><a href="#topic+punbalancedness">punbalancedness()</a></code>
for two measures of unbalancedness, <code><a href="#topic+pdim">pdim()</a></code> to check
the dimensions of a 'pdata.frame' (and other objects),
<code><a href="#topic+pvar">pvar()</a></code> to check for individual and time variation
of a 'pdata.frame' (and other objects), <code><a href="#topic+lag">lag()</a></code> for
lagging (and leading) values of a 'pseries' object.<br />
<code><a href="#topic+pseries">pseries()</a></code>, <code><a href="base.html#topic+data.frame">data.frame()</a></code>,
<code><a href="#topic+pdata.frame">pdata.frame()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# take data and make it unbalanced
# by deletion of 2nd row (2nd time period for first individual)
data("Grunfeld", package = "plm")
nrow(Grunfeld)                            # 200 rows
Grunfeld_missing_period &lt;- Grunfeld[-2, ]
pdim(Grunfeld_missing_period)$balanced    # check if balanced: FALSE
make.pbalanced(Grunfeld_missing_period)   # make it balanced (by filling)
make.pbalanced(Grunfeld_missing_period, balance.type = "shared.times") # (shared periods)
nrow(make.pbalanced(Grunfeld_missing_period))
nrow(make.pbalanced(Grunfeld_missing_period, balance.type = "shared.times"))

# more complex data:
# First, make data unbalanced (and non-consecutive) 
# by deletion of 2nd time period (year 1936) for all individuals
# and more time periods for first individual only
Grunfeld_unbalanced &lt;- Grunfeld[Grunfeld$year != 1936, ]
Grunfeld_unbalanced &lt;- Grunfeld_unbalanced[-c(1,4), ]
pdim(Grunfeld_unbalanced)$balanced        # FALSE
all(is.pconsecutive(Grunfeld_unbalanced)) # FALSE

g_bal &lt;- make.pbalanced(Grunfeld_unbalanced)
pdim(g_bal)$balanced        # TRUE
unique(g_bal$year)          # all years but 1936
nrow(g_bal)                 # 190 rows
head(g_bal)                 # 1st individual: years 1935, 1939 are NA

# NA in 1st, 3rd time period (years 1935, 1937) for first individual
Grunfeld_NA &lt;- Grunfeld
Grunfeld_NA[c(1, 3), "year"] &lt;- NA
g_bal_NA &lt;- make.pbalanced(Grunfeld_NA)
head(g_bal_NA)        # years 1935, 1937: NA for non-index vars
nrow(g_bal_NA)        # 200

# pdata.frame interface
pGrunfeld_missing_period &lt;- pdata.frame(Grunfeld_missing_period)
make.pbalanced(Grunfeld_missing_period)

# pseries interface
make.pbalanced(pGrunfeld_missing_period$inv)

# comparison to make.pconsecutive
g_consec &lt;- make.pconsecutive(Grunfeld_unbalanced)
all(is.pconsecutive(g_consec)) # TRUE
pdim(g_consec)$balanced        # FALSE
head(g_consec, 22)             # 1st individual:   no years 1935/6; 1939 is NA; 
                               # other indviduals: years 1935-1954, 1936 is NA
nrow(g_consec)                 # 198 rows

g_consec_bal &lt;- make.pconsecutive(Grunfeld_unbalanced, balanced = TRUE)
all(is.pconsecutive(g_consec_bal)) # TRUE
pdim(g_consec_bal)$balanced        # TRUE
head(g_consec_bal)                 # year 1936 is NA for all individuals
nrow(g_consec_bal)                 # 200 rows

head(g_bal)                        # no year 1936 at all
nrow(g_bal)                        # 190 rows

</code></pre>

<hr>
<h2 id='make.pconsecutive'>Make data consecutive (and, optionally, also balanced)</h2><span id='topic+make.pconsecutive'></span><span id='topic+make.pconsecutive.data.frame'></span><span id='topic+make.pconsecutive.pdata.frame'></span><span id='topic+make.pconsecutive.pseries'></span>

<h3>Description</h3>

<p>This function makes the data consecutive for each individual (no &quot;gaps&quot; in
time dimension per individual) and, optionally, also balanced
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make.pconsecutive(x, ...)

## S3 method for class 'data.frame'
make.pconsecutive(x, balanced = FALSE, index = NULL, ...)

## S3 method for class 'pdata.frame'
make.pconsecutive(x, balanced = FALSE, ...)

## S3 method for class 'pseries'
make.pconsecutive(x, balanced = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make.pconsecutive_+3A_x">x</code></td>
<td>
<p>an object of class <code>pdata.frame</code>, <code>data.frame</code>,
or <code>pseries</code>,</p>
</td></tr>
<tr><td><code id="make.pconsecutive_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="make.pconsecutive_+3A_balanced">balanced</code></td>
<td>
<p>logical, indicating whether the data should
<em>additionally</em> be made balanced (default: FALSE),</p>
</td></tr>
<tr><td><code id="make.pconsecutive_+3A_index">index</code></td>
<td>
<p>only relevant for <code>data.frame</code> interface; if
<code>NULL</code>, the first two columns of the data.frame are
assumed to be the index variables; if not <code>NULL</code>, both
dimensions ('individual', 'time') need to be specified by
<code>index</code> as character of length 2 for data frames, for
further details see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>(p)data.frame and pseries objects are made consecutive, meaning their time
periods are made consecutive per individual.  For consecutiveness, the time
dimension is interpreted to be numeric, and the data are extended to a
regularly spaced sequence with distance 1 between the time periods for each
individual (for each individual the time dimension become a sequence t, t+1,
t+2, ..., where t is an integer). Non&ndash;index variables are filled with
<code>NA</code> for the inserted elements (rows for (p)data.frames, vector
elements for pseries).
</p>
<p>With argument <code>balanced = TRUE</code>, additionally to be made consecutive,
the data also can be made a balanced panel/pseries.  Note: This means
consecutive AND balanced; balancedness does not imply consecutiveness. In
the result, each individual will have the same time periods in their time
dimension by taking the min and max of the time index variable over all
individuals (w/o <code>NA</code> values) and inserting the missing time periods.
Looking at the number of rows of the resulting (pdata.frame) (elements for
pseries), this results in <code style="white-space: pre;">&#8288;nrow(make.pconsecutive(&lt;.&gt;, balanced = FALSE))&#8288;</code> &lt;=
<code style="white-space: pre;">&#8288;nrow(make.pconsecutive(&lt;.&gt;, balanced = TRUE))&#8288;</code>. For making the data only
balanced, i.e., not demanding consecutiveness at the same time, use
<code><a href="#topic+make.pbalanced">make.pbalanced()</a></code> (see <strong>Examples</strong> for a comparison)).
</p>
<p>Note: rows of (p)data.frames (elements for pseries) with <code>NA</code> values in
individual or time index are not examined but silently dropped before the
data are made consecutive. In this case, it is not clear which individual or
time period is meant by the missing value(s). Especially, this means: If
there are <code>NA</code> values in the first/last position of the original time
periods for an individual, which usually depicts the beginning and ending of
the time series for that individual, the beginning/end of the resulting time
series is taken to be the min and max (w/o <code>NA</code> values) of the original
time series for that individual, see also <strong>Examples</strong>. Thus, one might
want to check if there are any <code>NA</code> values in the index variables
before applying <code>make.pconsecutive</code>, and especially check for <code>NA</code> values
in the first and last position for each individual in original data and, if
so, maybe set those to some meaningful begin/end value for the time series.
</p>


<h3>Value</h3>

<p>An object of the same class as the input <code>x</code>, i.e., a
pdata.frame, data.frame or a pseries which is made
time&ndash;consecutive based on the index variables. The returned
data are sorted as a stacked time series.
</p>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.pconsecutive">is.pconsecutive()</a></code> to check if data are
consecutive; <code><a href="#topic+make.pbalanced">make.pbalanced()</a></code> to make data only
balanced (not consecutive).<br /> <code><a href="#topic+punbalancedness">punbalancedness()</a></code>
for two measures of unbalancedness, <code><a href="#topic+pdim">pdim()</a></code> to check
the dimensions of a 'pdata.frame' (and other objects),
<code><a href="#topic+pvar">pvar()</a></code> to check for individual and time variation
of a 'pdata.frame' (and other objects), <code><a href="#topic+lag">lag()</a></code> for
lagged (and leading) values of a 'pseries' object.<br />
<code><a href="#topic+pseries">pseries()</a></code>, <code><a href="base.html#topic+data.frame">data.frame()</a></code>,
<code><a href="#topic+pdata.frame">pdata.frame()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# take data and make it non-consecutive
# by deletion of 2nd row (2nd time period for first individual)
data("Grunfeld", package = "plm")
nrow(Grunfeld)                             # 200 rows
Grunfeld_missing_period &lt;- Grunfeld[-2, ]
is.pconsecutive(Grunfeld_missing_period)   # check for consecutiveness
make.pconsecutive(Grunfeld_missing_period) # make it consecutiveness


# argument balanced:
# First, make data non-consecutive and unbalanced
# by deletion of 2nd time period (year 1936) for all individuals
# and more time periods for first individual only
Grunfeld_unbalanced &lt;- Grunfeld[Grunfeld$year != 1936, ]
Grunfeld_unbalanced &lt;- Grunfeld_unbalanced[-c(1,4), ]
all(is.pconsecutive(Grunfeld_unbalanced)) # FALSE
pdim(Grunfeld_unbalanced)$balanced        # FALSE

g_consec_bal &lt;- make.pconsecutive(Grunfeld_unbalanced, balanced = TRUE)
all(is.pconsecutive(g_consec_bal)) # TRUE
pdim(g_consec_bal)$balanced        # TRUE
nrow(g_consec_bal)                 # 200 rows
head(g_consec_bal)                 # 1st individual: years 1935, 1936, 1939 are NA

g_consec &lt;- make.pconsecutive(Grunfeld_unbalanced) # default: balanced = FALSE
all(is.pconsecutive(g_consec)) # TRUE
pdim(g_consec)$balanced        # FALSE
nrow(g_consec)                 # 198 rows
head(g_consec)                 # 1st individual: years 1935, 1936 dropped, 1939 is NA 


# NA in 1st, 3rd time period (years 1935, 1937) for first individual
Grunfeld_NA &lt;- Grunfeld
Grunfeld_NA[c(1, 3), "year"] &lt;- NA
g_NA &lt;- make.pconsecutive(Grunfeld_NA)
head(g_NA)        # 1936 is begin for 1st individual, 1937: NA for non-index vars
nrow(g_NA)        # 199, year 1935 from original data is dropped


# pdata.frame interface
pGrunfeld_missing_period &lt;- pdata.frame(Grunfeld_missing_period)
make.pconsecutive(Grunfeld_missing_period)


# pseries interface
make.pconsecutive(pGrunfeld_missing_period$inv)


# comparison to make.pbalanced (makes the data only balanced, not consecutive)
g_bal &lt;- make.pbalanced(Grunfeld_unbalanced)
all(is.pconsecutive(g_bal)) # FALSE
pdim(g_bal)$balanced        # TRUE
nrow(g_bal) # 190 rows

</code></pre>

<hr>
<h2 id='Males'>Wages and Education of Young Males</h2><span id='topic+Males'></span>

<h3>Description</h3>

<p>A panel of 545 observations from 1980 to 1987
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>nr</dt><dd><p>identifier</p>
</dd>
<dt>year</dt><dd><p>year</p>
</dd>
<dt>school</dt><dd><p>years of schooling</p>
</dd>
<dt>exper</dt><dd><p>years of experience (computed as <code>age-6-school</code>)</p>
</dd>
<dt>union</dt><dd><p>wage set by collective bargaining?</p>
</dd>
<dt>ethn</dt><dd><p>a factor with levels <code style="white-space: pre;">&#8288;black, hisp, other&#8288;</code></p>
</dd>
<dt>married</dt><dd><p>married?</p>
</dd>
<dt>health</dt><dd><p>health problem?</p>
</dd>
<dt>wage</dt><dd><p>log of hourly wage</p>
</dd>
<dt>industry</dt><dd><p>a factor with 12 levels</p>
</dd>
<dt>occupation</dt><dd><p>a factor with 9 levels</p>
</dd>
<dt>residence</dt><dd><p>a factor with levels <code style="white-space: pre;">&#8288;rural_area, north_east, northern_central, south&#8288;</code></p>
</dd>
</dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 4360
</p>
<p><em>observation</em> : individuals
</p>
<p><em>country</em> : United States
</p>


<h3>Source</h3>

<p>Journal of Applied Econometrics data archive
<a href="http://qed.econ.queensu.ca/jae/1998-v13.2/vella-verbeek/">http://qed.econ.queensu.ca/jae/1998-v13.2/vella-verbeek/</a>.
</p>


<h3>References</h3>

<p>Vella F, Verbeek M (1998).
&ldquo;Whose wages do unions raise? A dynamic model of unionism and wage rate determination for young men.&rdquo;
<em>Journal of Applied Econometrics</em>, <b>13</b>, 163&ndash;183.
</p>
<p>Verbeek M (2004).
<em>A Guide to Modern Econometrics</em>, 2nd edition.
Wiley.
</p>

<hr>
<h2 id='model.frame.pdata.frame'>model.frame and model.matrix for panel data</h2><span id='topic+model.frame.pdata.frame'></span><span id='topic+formula.pdata.frame'></span><span id='topic+model.matrix.plm'></span><span id='topic+model.matrix.pdata.frame'></span>

<h3>Description</h3>

<p>Methods to create model frame and model matrix for panel data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pdata.frame'
model.frame(
  formula,
  data = NULL,
  ...,
  lhs = NULL,
  rhs = NULL,
  dot = "previous"
)

## S3 method for class 'pdata.frame'
formula(x, ...)

## S3 method for class 'plm'
model.matrix(object, ...)

## S3 method for class 'pdata.frame'
model.matrix(
  object,
  model = c("pooling", "within", "Between", "Sum", "between", "mean", "random", "fd"),
  effect = c("individual", "time", "twoways", "nested"),
  rhs = 1,
  theta = NULL,
  cstcovar.rm = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model.frame.pdata.frame_+3A_data">data</code></td>
<td>
<p>a <code>formula</code>, see <strong>Details</strong>,</p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_lhs">lhs</code></td>
<td>
<p>inherited from package <code><a href="Formula.html#topic+Formula">Formula::Formula()</a></code> (see
there),</p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_rhs">rhs</code></td>
<td>
<p>inherited from package <code><a href="Formula.html#topic+Formula">Formula::Formula()</a></code> (see
there),</p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_dot">dot</code></td>
<td>
<p>inherited from package <code><a href="Formula.html#topic+Formula">Formula::Formula()</a></code> (see
there),</p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_x">x</code></td>
<td>
<p>a <code>model.frame</code></p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_object">object</code>, <code id="model.frame.pdata.frame_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>"pdata.frame"</code> or an
estimated model object of class <code>"plm"</code>,</p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_model">model</code></td>
<td>
<p>one of <code>"pooling"</code>, <code>"within"</code>, <code>"Sum"</code>, <code>"Between"</code>,
<code>"between"</code>, <code style="white-space: pre;">&#8288;"random",&#8288;</code> <code>"fd"</code> and <code>"ht"</code>,</p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_effect">effect</code></td>
<td>
<p>the effects introduced in the model, one of
<code>"individual"</code>, <code>"time"</code>, <code>"twoways"</code> or <code>"nested"</code>,</p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_theta">theta</code></td>
<td>
<p>the parameter for the transformation if <code>model = "random"</code>,</p>
</td></tr>
<tr><td><code id="model.frame.pdata.frame_+3A_cstcovar.rm">cstcovar.rm</code></td>
<td>
<p>remove the constant columns, one of <code style="white-space: pre;">&#8288;"none", "intercept", "covariates", "all")&#8288;</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>lhs</code> and <code>rhs</code> arguments are inherited from <code>Formula</code>, see
there for more details.<br /> The <code>model.frame</code> methods return a
<code>pdata.frame</code> object suitable as an input to plm's
<code>model.matrix</code>.<br /> The <code>model.matrix</code> methods builds a model matrix
with transformations performed as specified by the <code>model</code> and
<code>effect</code> arguments (and <code>theta</code> if <code>model = "random"</code> is
requested), in this case the supplied <code>data</code> argument should be a
model frame created by plm's <code>model.frame</code> method. If not, it is
tried to construct the model frame from the data. Constructing the
model frame first ensures proper <code>NA</code> handling, see <strong>Examples</strong>.
</p>


<h3>Value</h3>

<p>The <code>model.frame</code> methods return a <code>pdata.frame</code>.<br /> The
<code>model.matrix</code> methods return a <code>matrix</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pmodel.response">pmodel.response()</a></code> for (transformed) response
variable.<br /> <code><a href="Formula.html#topic+Formula">Formula::Formula()</a></code> from package <code>Formula</code>,
especially for the <code>lhs</code> and <code>rhs</code> arguments.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# First, make a pdata.frame
data("Grunfeld", package = "plm")
pGrunfeld &lt;- pdata.frame(Grunfeld)

# then make a model frame from a formula and a pdata.frame
form &lt;- inv ~ value
mf &lt;- model.frame(pGrunfeld, form)

# then construct the (transformed) model matrix (design matrix)
# from model frame
modmat &lt;- model.matrix(mf, model = "within")

## retrieve model frame and model matrix from an estimated plm object
fe_model &lt;- plm(form, data = pGrunfeld, model = "within")
model.frame(fe_model)
model.matrix(fe_model)

# same as constructed before
all.equal(mf, model.frame(fe_model), check.attributes = FALSE) # TRUE
all.equal(modmat, model.matrix(fe_model), check.attributes = FALSE) # TRUE

</code></pre>

<hr>
<h2 id='mtest'>Arellano&ndash;Bond Test of Serial Correlation</h2><span id='topic+mtest'></span><span id='topic+mtest.pgmm'></span>

<h3>Description</h3>

<p>Test of serial correlation for models estimated by GMM
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mtest(object, ...)

## S3 method for class 'pgmm'
mtest(object, order = 1L, vcov = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mtest_+3A_object">object</code></td>
<td>
<p>an object of class <code>"pgmm"</code>,</p>
</td></tr>
<tr><td><code id="mtest_+3A_...">...</code></td>
<td>
<p>further arguments (currently unused).</p>
</td></tr>
<tr><td><code id="mtest_+3A_order">order</code></td>
<td>
<p>integer: the order of the serial correlation,</p>
</td></tr>
<tr><td><code id="mtest_+3A_vcov">vcov</code></td>
<td>
<p>a matrix of covariance for the coefficients or a function to
compute it,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Arellano&ndash;Bond test is a test of correlation based on the residuals of
the estimation. By default, the computation is done with the standard
covariance matrix of the coefficients.  A robust estimator of this
covariance matrix can be supplied with the <code>vcov</code> argument.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>(Arellano and Bond 1991)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pgmm">pgmm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("EmplUK", package = "plm")
ar &lt;- pgmm(log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1) +
           lag(log(capital), 0:2) + lag(log(output), 0:2) | lag(log(emp), 2:99),
           data = EmplUK, effect = "twoways", model = "twosteps")
mtest(ar, order = 1L)
mtest(ar, order = 2L, vcov = vcovHC)

</code></pre>

<hr>
<h2 id='nobs.plm'>Extract Total Number of Observations Used in Estimated Panelmodel</h2><span id='topic+nobs.plm'></span><span id='topic+nobs'></span><span id='topic+nobs.panelmodel'></span><span id='topic+nobs.pgmm'></span>

<h3>Description</h3>

<p>This function extracts the total number of 'observations' from a
fitted panel model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'panelmodel'
nobs(object, ...)

## S3 method for class 'pgmm'
nobs(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nobs.plm_+3A_object">object</code></td>
<td>
<p>a <code>panelmodel</code> object for which the number of
total observations is to be extracted,</p>
</td></tr>
<tr><td><code id="nobs.plm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of observations is usually the length of the residuals
vector. Thus, <code>nobs</code> gives the number of observations actually
used by the estimation procedure. It is not necessarily the number
of observations of the model frame (number of rows in the model
frame), because sometimes the model frame is further reduced by the
estimation procedure. This is, e.g., the case for first&ndash;difference
models estimated by <code>plm(..., model = "fd")</code> where the model
frame does not yet contain the differences (see also
<strong>Examples</strong>).
</p>


<h3>Value</h3>

<p>A single number, normally an integer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdim">pdim()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# estimate a panelmodel
data("Produc", package = "plm")
z &lt;- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp,data=Produc,
         model="random", subset = gsp &gt; 5000)
         
nobs(z)       # total observations used in estimation
pdim(z)$nT$N  # same information
pdim(z)       # more information about the dimensions (no. of individuals and time periods)

# illustrate difference between nobs and pdim for first-difference model
data("Grunfeld", package = "plm")
fdmod &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "fd")
nobs(fdmod)      # 190
pdim(fdmod)$nT$N # 200

</code></pre>

<hr>
<h2 id='Parity'>Purchasing Power Parity and other parity relationships</h2><span id='topic+Parity'></span>

<h3>Description</h3>

<p>A panel of 104 quarterly observations from 1973Q1 to 1998Q4
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>country</dt><dd><p>country codes: a factor with 17 levels</p>
</dd>
<dt>time</dt><dd><p>the quarter index, 1973Q1-1998Q4</p>
</dd>
<dt>ls</dt><dd><p>log spot exchange rate vs. USD</p>
</dd>
<dt>lp</dt><dd><p>log price level</p>
</dd>
<dt>is</dt><dd><p>short term interest rate</p>
</dd>
<dt>il</dt><dd><p>long term interest rate</p>
</dd>
<dt>ld</dt><dd><p>log price differential vs. USA</p>
</dd>
<dt>uis</dt><dd><p>U.S. short term interest rate</p>
</dd>
<dt>uil</dt><dd><p>U.S. long term interest rate</p>
</dd> </dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 1768
</p>
<p><em>observation</em> : country
</p>
<p><em>country</em> : OECD
</p>


<h3>Source</h3>

<p>Coakley J, Fuertes A, Smith R (2006).
&ldquo;Unobserved heterogeneity in panel time series models.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>, <b>50</b>(9), 2361&ndash;2380.
</p>


<h3>References</h3>

<p>Coakley J, Fuertes A, Smith R (2006).
&ldquo;Unobserved heterogeneity in panel time series models.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>, <b>50</b>(9), 2361&ndash;2380.
</p>
<p>Driscoll JC, Kraay AC (1998).
&ldquo;Consistent covariance matrix estimation with spatially dependent panel data.&rdquo;
<em>Review of economics and statistics</em>, <b>80</b>(4), 549&ndash;560.
</p>

<hr>
<h2 id='pbgtest'>Breusch&ndash;Godfrey Test for Panel Models</h2><span id='topic+pbgtest'></span><span id='topic+pbgtest.panelmodel'></span><span id='topic+pbgtest.formula'></span>

<h3>Description</h3>

<p>Test of serial correlation for (the idiosyncratic component of) the
errors in panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pbgtest(x, ...)

## S3 method for class 'panelmodel'
pbgtest(x, order = NULL, type = c("Chisq", "F"), ...)

## S3 method for class 'formula'
pbgtest(
  x,
  order = NULL,
  type = c("Chisq", "F"),
  data,
  model = c("pooling", "random", "within"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pbgtest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"panelmodel"</code> or of class <code>"formula"</code>,</p>
</td></tr>
<tr><td><code id="pbgtest_+3A_...">...</code></td>
<td>
<p>further arguments (see <code><a href="lmtest.html#topic+bgtest">lmtest::bgtest()</a></code>).</p>
</td></tr>
<tr><td><code id="pbgtest_+3A_order">order</code></td>
<td>
<p>an integer indicating the order of serial correlation
to be tested for. <code>NULL</code> (default) uses the minimum number of
observations over the time dimension (see also section
<strong>Details</strong> below),</p>
</td></tr>
<tr><td><code id="pbgtest_+3A_type">type</code></td>
<td>
<p>type of test statistic to be calculated; either
<code>"Chisq"</code> (default) for the Chi-squared test statistic or <code>"F"</code>
for the F test statistic,</p>
</td></tr>
<tr><td><code id="pbgtest_+3A_data">data</code></td>
<td>
<p>only relevant for formula interface: data set for which
the respective panel model (see <code>model</code>) is to be evaluated,</p>
</td></tr>
<tr><td><code id="pbgtest_+3A_model">model</code></td>
<td>
<p>only relevant for formula interface: compute test
statistic for model <code>pooling</code> (default), <code>random</code>, or <code>within</code>.
When <code>model</code> is used, the <code>data</code> argument needs to be passed as
well,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This Lagrange multiplier test uses the auxiliary model on
(quasi-)demeaned data taken from a model of class <code>plm</code> which may
be a <code>pooling</code> (default for formula interface), <code>random</code> or
<code>within</code> model. It performs a Breusch&ndash;Godfrey test (using <code>bgtest</code>
from package <a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> on the residuals of the
(quasi-)demeaned model, which should be serially uncorrelated under
the null of no serial correlation in idiosyncratic errors, as
illustrated in Wooldridge (2010). The function
takes the demeaned data, estimates the model and calls <code>bgtest</code>.
</p>
<p>Unlike most other tests for serial correlation in panels, this one
allows to choose the order of correlation to test for.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Note</h3>

<p>The argument <code>order</code> defaults to the minimum number of
observations over the time dimension, while for
<code>lmtest::bgtest</code> it defaults to <code>1</code>.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Breusch TS (1978).
&ldquo;Testing for autocorrelation in dynamic linear models.&rdquo;
<em>Australian Economic Papers</em>, <b>17</b>(31), 334&ndash;355.
</p>
<p>Godfrey LG (1978).
&ldquo;Testing against general autoregressive and moving average error models when the regressors include lagged dependent variables.&rdquo;
<em>Econometrica</em>, <b>46</b>(6), 1293&ndash;1301.
</p>
<p>Wooldridge JM (2002).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>.
MIT Press.
</p>
<p>Wooldridge JM (2010).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>, 2nd edition.
MIT Press.
</p>
<p>Wooldridge JM (2013).
<em>Introductory Econometrics: a modern approach</em>, 5th edition.
South-Western (Cengage Learning).
Sec. 12.2, pp. 421&ndash;422.
</p>


<h3>See Also</h3>

<p>For the original test in package <a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> see
<code><a href="lmtest.html#topic+bgtest">lmtest::bgtest()</a></code>.  See <code><a href="#topic+pdwtest">pdwtest()</a></code> for the analogous
panel Durbin&ndash;Watson test.  See <code><a href="#topic+pbltest">pbltest()</a></code>, <code><a href="#topic+pbsytest">pbsytest()</a></code>,
<code><a href="#topic+pwartest">pwartest()</a></code> and <code><a href="#topic+pwfdtest">pwfdtest()</a></code> for other serial correlation
tests for panel models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
g &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "random")

# panelmodel interface
pbgtest(g)
pbgtest(g, order = 4)

# formula interface
pbgtest(inv ~ value + capital, data = Grunfeld, model = "random")

# F test statistic (instead of default type="Chisq")
pbgtest(g, type="F")
pbgtest(inv ~ value + capital, data = Grunfeld, model = "random", type = "F")

</code></pre>

<hr>
<h2 id='pbltest'>Baltagi and Li Serial Dependence Test For Random Effects Models</h2><span id='topic+pbltest'></span><span id='topic+pbltest.formula'></span><span id='topic+pbltest.plm'></span>

<h3>Description</h3>

<p>Baltagi and Li (1995)'s Lagrange multiplier test for
AR(1) or MA(1) idiosyncratic errors in panel models with random
effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pbltest(x, ...)

## S3 method for class 'formula'
pbltest(x, data, alternative = c("twosided", "onesided"), index = NULL, ...)

## S3 method for class 'plm'
pbltest(x, alternative = c("twosided", "onesided"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pbltest_+3A_x">x</code></td>
<td>
<p>a model formula or an estimated random&ndash;effects model of
class <code>plm</code> ,</p>
</td></tr>
<tr><td><code id="pbltest_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pbltest_+3A_data">data</code></td>
<td>
<p>for the formula interface only: a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pbltest_+3A_alternative">alternative</code></td>
<td>
<p>one of <code>"twosided"</code>,
<code>"onesided"</code>. Selects either <code class="reqn">H_A: \rho \neq 0</code> or
<code class="reqn">H_A: \rho = 0</code> (i.e., the Normal or the Chi-squared
version of the test),</p>
</td></tr>
<tr><td><code id="pbltest_+3A_index">index</code></td>
<td>
<p>the index of the <code>data.frame</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a Lagrange multiplier test for the null of no serial
correlation, against the alternative of either an AR(1) or a MA(1)
process, in the idiosyncratic component of the error term in a
random effects panel model (as the analytical expression of the
test turns out to be the same under both alternatives,
(see Baltagi and Li 1995 and Baltagi and Li 1997). The
<code>alternative</code> argument, defaulting to <code>twosided</code>, allows testing
for positive serial correlation only, if set to <code>onesided</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Baltagi B, Li Q (1995).
&ldquo;Testing AR(1) Against MA(1) Disturbances in an Error Component Model.&rdquo;
<em>Journal of Econometrics</em>, <b>68</b>, 133&ndash;151.
</p>
<p>Baltagi B, Li Q (1997).
&ldquo;Monte Carlo Results on Pure and Pretest Estimators of an Error Components Model With Autocorrelated Disturbances.&rdquo;
<em>Annales d'Economie et de Statistique</em>, <b>48</b>, 69&ndash;82.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdwtest">pdwtest()</a></code>, <code><a href="#topic+pbnftest">pbnftest()</a></code>, <code><a href="#topic+pbgtest">pbgtest()</a></code>,
<code><a href="#topic+pbsytest">pbsytest()</a></code>, <code><a href="#topic+pwartest">pwartest()</a></code> and
<code><a href="#topic+pwfdtest">pwfdtest()</a></code> for other serial correlation tests for
panel models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")

# formula interface
pbltest(inv ~ value + capital, data = Grunfeld)

# plm interface
re_mod &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "random")
pbltest(re_mod)
pbltest(re_mod, alternative = "onesided")

</code></pre>

<hr>
<h2 id='pbnftest'>Modified BNF&ndash;Durbin&ndash;Watson Test and Baltagi&ndash;Wu's LBI Test for Panel
Models</h2><span id='topic+pbnftest'></span><span id='topic+pbnftest.panelmodel'></span><span id='topic+pbnftest.formula'></span>

<h3>Description</h3>

<p>Tests for AR(1) disturbances in panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pbnftest(x, ...)

## S3 method for class 'panelmodel'
pbnftest(x, test = c("bnf", "lbi"), ...)

## S3 method for class 'formula'
pbnftest(
  x,
  data,
  test = c("bnf", "lbi"),
  model = c("pooling", "within", "random"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pbnftest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"panelmodel"</code> or of class <code>"formula"</code>,</p>
</td></tr>
<tr><td><code id="pbnftest_+3A_...">...</code></td>
<td>
<p>only relevant for formula interface: further arguments
to specify the model to test (arguments passed on to plm()),
e.g., <code>effect</code>.</p>
</td></tr>
<tr><td><code id="pbnftest_+3A_test">test</code></td>
<td>
<p>a character indicating the test to be performed, either
<code>"bnf"</code> or <code>"lbi"</code> for the (modified) BNF statistic or
Baltagi&ndash;Wu's LBI statistic, respectively,</p>
</td></tr>
<tr><td><code id="pbnftest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> (only relevant for formula interface),</p>
</td></tr>
<tr><td><code id="pbnftest_+3A_model">model</code></td>
<td>
<p>a character indicating on which type of model the test
shall be performed (<code>"pooling"</code>, <code>"within"</code>, <code>"random"</code>, only
relevant for formula interface),</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default, <code>test = "bnf"</code>, gives the (modified) BNF statistic,
the generalised Durbin-Watson statistic for panels. For balanced
and consecutive panels, the reference is
Bhargava/Franzini/Narendranathan (1982). The modified BNF is given
for unbalanced and/or non-consecutive panels (d1 in formula 16 of
Baltagi and Wu (1999)).
</p>
<p><code>test = "lbi"</code> yields Baltagi&ndash;Wu's LBI statistic
(Baltagi and Wu 1999), the locally best invariant test which
is based on the modified BNF statistic.
</p>
<p>No specific variants of these tests are available for random effect models.
As the within estimator is consistent also under the random effects
assumptions, the test for random effect models is performed by taking the
within residuals.
</p>
<p>No p-values are given for the statistics as their distribution is
quite difficult. Bhargava et al. (1982) supply
tabulated bounds for p = 0.05 for the balanced case and consecutive
case.
</p>
<p>For large N, (Bhargava et al. 1982) suggest it is
sufficient to check whether the BNF statistic is &lt; 2 to test
against positive serial correlation.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>References</h3>

<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH, Wu PX (1999).
&ldquo;Unequally Spaced Panel Data Regressions with AR(1) Disturbances.&rdquo;
<em>Econometric Theory</em>, <b>15</b>(6), 814&ndash;823.
ISSN 02664666, 14694360.
</p>
<p>Bhargava A, Franzini L, Narendranathan W (1982).
&ldquo;Serial Correlation and the Fixed Effects Model.&rdquo;
<em>The Review of Economic Studies</em>, <b>49</b>(4), 533&ndash;549.
ISSN 00346527, 1467937X.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdwtest">pdwtest()</a></code> for the original Durbin&ndash;Watson test using
(quasi-)demeaned residuals of the panel model without taking
the panel structure into account. <code><a href="#topic+pbltest">pbltest()</a></code>, <code><a href="#topic+pbsytest">pbsytest()</a></code>,
<code><a href="#topic+pwartest">pwartest()</a></code> and <code><a href="#topic+pwfdtest">pwfdtest()</a></code> for other serial correlation
tests for panel models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")

# formula interface, replicate Baltagi/Wu (1999), table 1, test case A:
data_A &lt;- Grunfeld[!Grunfeld[["year"]] %in% c("1943", "1944"), ]
pbnftest(inv ~ value + capital, data = data_A, model = "within")
pbnftest(inv ~ value + capital, data = data_A, test = "lbi", model = "within")

# replicate Baltagi (2013), p. 101, table 5.1:
re &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "random")
pbnftest(re)
pbnftest(re, test = "lbi")

</code></pre>

<hr>
<h2 id='pbsytest'>Bera, Sosa-Escudero and Yoon Locally&ndash;Robust Lagrange Multiplier
Tests for Panel Models and Joint Test by Baltagi and Li</h2><span id='topic+pbsytest'></span><span id='topic+pbsytest.formula'></span><span id='topic+pbsytest.panelmodel'></span>

<h3>Description</h3>

<p>Test for residual serial correlation (or individual random effects)
locally robust vs. individual random effects (serial correlation)
for panel models and joint test of serial correlation and the
random effect specification by Baltagi and Li.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pbsytest(x, ...)

## S3 method for class 'formula'
pbsytest(
  x,
  data,
  ...,
  test = c("ar", "re", "j"),
  re.normal = if (test == "re") TRUE else NULL
)

## S3 method for class 'panelmodel'
pbsytest(
  x,
  test = c("ar", "re", "j"),
  re.normal = if (test == "re") TRUE else NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pbsytest_+3A_x">x</code></td>
<td>
<p>an object of class <code>formula</code> or of class <code>panelmodel</code>,</p>
</td></tr>
<tr><td><code id="pbsytest_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pbsytest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pbsytest_+3A_test">test</code></td>
<td>
<p>a character string indicating which test to perform:
first&ndash;order serial correlation (<code>"ar"</code>), random effects (<code>"re"</code>)
or joint test for either of them (<code>"j"</code>),</p>
</td></tr>
<tr><td><code id="pbsytest_+3A_re.normal">re.normal</code></td>
<td>
<p>logical, only relevant for <code>test = "re"</code>: <code>TRUE</code>
(default) computes the one-sided <code>"re"</code> test, <code>FALSE</code> the
two-sided test (see also Details); not relevant for other values of
<code>test</code> and, thus, should be <code>NULL</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These Lagrange multiplier tests are robust vs. local
misspecification of the alternative hypothesis, i.e., they test the
null of serially uncorrelated residuals against AR(1) residuals in
a pooling model, allowing for local departures from the assumption
of no random effects; or they test the null of no random effects
allowing for local departures from the assumption of no serial
correlation in residuals.  They use only the residuals of the
pooled OLS model and correct for local misspecification as outlined
in Bera et al. (2001).
</p>
<p>For <code>test = "re"</code>, the default (<code>re.normal = TRUE</code>) is to compute
a one-sided test which is expected to lead to a more powerful test
(asymptotically N(0,1) distributed).  Setting <code>re.normal = FALSE</code> gives
the two-sided test (asymptotically chi-squared(2) distributed). Argument
<code>re.normal</code> is irrelevant for all other values of <code>test</code>.
</p>
<p>The joint test of serial correlation and the random effect
specification (<code>test = "j"</code>) is due to
Baltagi and Li (1991) (also mentioned in
Baltagi and Li (1995), pp. 135&ndash;136) and is added
for convenience under this same function.
</p>
<p>The unbalanced version of all tests are derived in
Sosa-Escudero and Bera (2008). The functions implemented
are suitable for balanced as well as unbalanced panel data sets.
</p>
<p>A concise treatment of the statistics for only balanced panels is
given in Baltagi (2013), p. 108.
</p>
<p>Here is an overview of how the various values of the <code>test</code>
argument relate to the literature:
</p>
 <ul>
<li> <p><code>test = "ar"</code>: </p>
 <ul>
<li> <p><code class="reqn">RS*_{\rho}</code> in Bera
et al. (2001), p. 9 (balanced) </p>
</li>
<li> <p><code class="reqn">LM*_{\rho}</code> in Baltagi (2013), p.
108 (balanced) </p>
</li>
<li> <p><code class="reqn">RS*_{\lambda}</code> in Sosa-Escudero/Bera (2008), p. 73
(unbalanced) </p>
</li></ul>

</li>
<li> <p><code style="white-space: pre;">&#8288;test = "re", re.normal = TRUE&#8288;</code> (default) (one-sided test,
asymptotically N(0,1) distributed): </p>
 <ul>
<li> <p><code class="reqn">RSO*_{\mu}</code> in Bera
et al. (2001), p. 11 (balanced) </p>
</li>
<li> <p><code class="reqn">RSO*_{\mu}</code> in Sosa-Escudero/Bera
(2008), p. 75 (unbalanced) </p>
</li></ul>

</li>
<li> <p><code style="white-space: pre;">&#8288;test = "re", re.normal = FALSE&#8288;</code> (two-sided test, asymptotically
chi-squared(2) distributed): </p>
 <ul>
<li> <p><code class="reqn">RS*_{\mu}</code> in Bera et al.
(2001), p. 7 (balanced) </p>
</li>
<li> <p><code class="reqn">LM*_{\mu}</code> in Baltagi (2013), p. 108
(balanced) </p>
</li>
<li> <p><code class="reqn">RS*_{\mu}</code> in Sosa-Escudero/Bera (2008), p. 73
(unbalanced) </p>
</li></ul>

</li>
<li> <p><code>test = "j"</code>: </p>
 <ul>
<li> <p><code class="reqn">RS_{\mu\rho}</code> in Bera et al.
(2001), p. 10 (balanced) </p>
</li>
<li> <p><code class="reqn">LM</code> in Baltagi/Li (2001), p. 279
(balanced) </p>
</li>
<li> <p><code class="reqn">LM_{1}</code> in Baltagi and Li (1995), pp. 135&ndash;136
(balanced) </p>
</li>
<li> <p><code class="reqn">LM1</code> in Baltagi (2013), p. 108 (balanced) </p>
</li>
<li>
<p><code class="reqn">RS_{\lambda\rho}</code> in Sosa-Escudero/Bera (2008), p. 74 (unbalanced) </p>
</li></ul>
 </li></ul>



<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo (initial implementation) &amp; Kevin Tappe (extension to
unbalanced panels)
</p>


<h3>References</h3>

<p>Bera AK, Sosa&ndash;Escudero W, Yoon M (2001).
&ldquo;Tests for the Error Component Model in the Presence of Local Misspecification.&rdquo;
<em>Journal of Econometrics</em>, <b>101</b>, 1&ndash;23.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi B, Li Q (1991).
&ldquo;A Joint Test for Serial Correlation and Random Individual Effects.&rdquo;
<em>Statistics and Probability Letters</em>, <b>11</b>, 277&ndash;280.
</p>
<p>Baltagi B, Li Q (1995).
&ldquo;Testing AR(1) Against MA(1) Disturbances in an Error Component Model.&rdquo;
<em>Journal of Econometrics</em>, <b>68</b>, 133&ndash;151.
</p>
<p>Sosa-Escudero W, Bera AK (2008).
&ldquo;Tests for Unbalanced Error-Components Models under Local Misspecification.&rdquo;
<em>The Stata Journal</em>, <b>8</b>(1), 68-78.
<a href="https://doi.org/10.1177/1536867X0800800105">doi:10.1177/1536867X0800800105</a>, https://doi.org/10.1177/1536867X0800800105.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plmtest">plmtest()</a></code> for individual and/or time random effects
tests based on a correctly specified model; <code><a href="#topic+pbltest">pbltest()</a></code>,
<code><a href="#topic+pbgtest">pbgtest()</a></code> and <code><a href="#topic+pdwtest">pdwtest()</a></code> for serial correlation tests
in random effects models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Bera et. al (2001), p. 13, table 1 use
## a subset of the original Grunfeld
## data which contains three errors -&gt; construct this subset:
data("Grunfeld", package = "plm")
Grunsubset &lt;- rbind(Grunfeld[1:80, ], Grunfeld[141:160, ])
Grunsubset[Grunsubset$firm == 2 &amp; Grunsubset$year %in% c(1940, 1952), ][["inv"]] &lt;- c(261.6, 645.2)
Grunsubset[Grunsubset$firm == 2 &amp; Grunsubset$year == 1946, ][["capital"]] &lt;- 232.6

## default is AR testing (formula interface)
pbsytest(inv ~ value + capital, data = Grunsubset, index = c("firm", "year"))
pbsytest(inv ~ value + capital, data = Grunsubset, index = c("firm", "year"), test = "re")
pbsytest(inv ~ value + capital, data = Grunsubset, index = c("firm", "year"), 
  test = "re", re.normal = FALSE)
pbsytest(inv ~ value + capital, data = Grunsubset, index = c("firm", "year"), test = "j")

## plm interface
mod &lt;- plm(inv ~ value + capital, data = Grunsubset, model = "pooling")
pbsytest(mod)

</code></pre>

<hr>
<h2 id='pcce'>Common Correlated Effects estimators</h2><span id='topic+pcce'></span><span id='topic+summary.pcce'></span><span id='topic+print.summary.pcce'></span><span id='topic+residuals.pcce'></span><span id='topic+model.matrix.pcce'></span><span id='topic+pmodel.response.pcce'></span>

<h3>Description</h3>

<p>Common Correlated Effects Mean Groups (CCEMG) and Pooled (CCEP)
estimators for panel data with common factors (balanced or
unbalanced)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcce(
  formula,
  data,
  subset,
  na.action,
  model = c("mg", "p"),
  index = NULL,
  trend = FALSE,
  ...
)

## S3 method for class 'pcce'
summary(object, vcov = NULL, ...)

## S3 method for class 'summary.pcce'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)

## S3 method for class 'pcce'
residuals(object, type = c("defactored", "standard"), ...)

## S3 method for class 'pcce'
model.matrix(object, ...)

## S3 method for class 'pcce'
pmodel.response(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcce_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be estimated,</p>
</td></tr>
<tr><td><code id="pcce_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pcce_+3A_subset">subset</code></td>
<td>
<p>see <code>lm</code>,</p>
</td></tr>
<tr><td><code id="pcce_+3A_na.action">na.action</code></td>
<td>
<p>see <code>lm</code>,</p>
</td></tr>
<tr><td><code id="pcce_+3A_model">model</code></td>
<td>
<p>one of <code>"mg"</code>, <code>"p"</code>, selects Mean Groups vs. Pooled
CCE model,</p>
</td></tr>
<tr><td><code id="pcce_+3A_index">index</code></td>
<td>
<p>the indexes, see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
<tr><td><code id="pcce_+3A_trend">trend</code></td>
<td>
<p>logical specifying whether an individual-specific
trend has to be included,</p>
</td></tr>
<tr><td><code id="pcce_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pcce_+3A_object">object</code>, <code id="pcce_+3A_x">x</code></td>
<td>
<p>an object of class <code>"pcce"</code>,</p>
</td></tr>
<tr><td><code id="pcce_+3A_vcov">vcov</code></td>
<td>
<p>a variance-covariance matrix furnished by the user or a function to calculate one,</p>
</td></tr>
<tr><td><code id="pcce_+3A_digits">digits</code></td>
<td>
<p>digits,</p>
</td></tr>
<tr><td><code id="pcce_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the print output,</p>
</td></tr>
<tr><td><code id="pcce_+3A_type">type</code></td>
<td>
<p>one of <code>"defactored"</code> or <code>"standard"</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pcce</code> is a function for the estimation of linear panel models by
the Common Correlated Effects Mean Groups or Pooled estimator,
consistent under the hypothesis of unobserved common factors and
idiosyncratic factor loadings. The CCE estimator works by
augmenting the model by cross-sectional averages of the dependent
variable and regressors in order to account for the common factors,
and adding individual intercepts and possibly trends.
</p>


<h3>Value</h3>

<p>An object of class <code>c("pcce", "panelmodel")</code> containing:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the vector of coefficients,</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the vector of (defactored) residuals,</p>
</td></tr>
<tr><td><code>stdres</code></td>
<td>
<p>the vector of (raw) residuals,</p>
</td></tr>
<tr><td><code>tr.model</code></td>
<td>
<p>the transformed data after projection on H,</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the vector of fitted values,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>the covariance matrix of the coefficients,</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>degrees of freedom of the residuals,</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>a data.frame containing the variables used for the
estimation,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call,</p>
</td></tr>
<tr><td><code>indcoef</code></td>
<td>
<p>the matrix of individual coefficients from
separate time series regressions,</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>numeric, the R squared.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Kapetanios G, Pesaran MH, Yamagata T (2011).
&ldquo;Panels with non-stationary multifactor error structures.&rdquo;
<em>Journal of Econometrics</em>, <b>160</b>(2), 326&ndash;348.
</p>
<p>Holly S, Pesaran MH, Yamagata T (2010).
&ldquo;A spatio-temporal model of house prices in the USA.&rdquo;
<em>Journal of Econometrics</em>, <b>158</b>(1), 160&ndash;173.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
ccepmod &lt;- pcce(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc, model="p")
summary(ccepmod)
summary(ccepmod, vcov = vcovHC) # use argument vcov for robust std. errors

ccemgmod &lt;- pcce(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc, model="mg")
summary(ccemgmod)

</code></pre>

<hr>
<h2 id='pcdtest'>Tests of cross-section dependence for panel models</h2><span id='topic+pcdtest'></span><span id='topic+pcdtest.formula'></span><span id='topic+pcdtest.panelmodel'></span><span id='topic+pcdtest.pseries'></span>

<h3>Description</h3>

<p>Pesaran's CD or Breusch&ndash;Pagan's LM (local or global) tests for cross
sectional dependence in panel models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcdtest(x, ...)

## S3 method for class 'formula'
pcdtest(
  x,
  data,
  index = NULL,
  model = NULL,
  test = c("cd", "sclm", "bcsclm", "lm", "rho", "absrho"),
  w = NULL,
  ...
)

## S3 method for class 'panelmodel'
pcdtest(
  x,
  test = c("cd", "sclm", "bcsclm", "lm", "rho", "absrho"),
  w = NULL,
  ...
)

## S3 method for class 'pseries'
pcdtest(
  x,
  test = c("cd", "sclm", "bcsclm", "lm", "rho", "absrho"),
  w = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcdtest_+3A_x">x</code></td>
<td>
<p>an object of class <code>formula</code>, <code>panelmodel</code>, or <code>pseries</code>
(depending on the respective interface) describing the model to
be tested,</p>
</td></tr>
<tr><td><code id="pcdtest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on for model estimation to <code>plm</code>,
such as <code>effect</code> or <code>random.method</code>.</p>
</td></tr>
<tr><td><code id="pcdtest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pcdtest_+3A_index">index</code></td>
<td>
<p>an optional numerical index, if <code>NULL</code>, the first two
columns of the data.frame provided in argument <code>data</code> are
assumed to be the index variables; for further details see
<code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
<tr><td><code id="pcdtest_+3A_model">model</code></td>
<td>
<p>an optional character string indicating which type of
model to estimate; if left to <code>NULL</code>, the original
heterogeneous specification of Pesaran is used,</p>
</td></tr>
<tr><td><code id="pcdtest_+3A_test">test</code></td>
<td>
<p>the type of test statistic to be returned. One of
</p>
 <ul>
<li> <p><code>"cd"</code> for Pesaran's CD statistic, </p>
</li>
<li> <p><code>"lm"</code>
for Breusch and Pagan's original LM statistic, </p>
</li>
<li> <p><code>"sclm"</code>
for the scaled version of Breusch and Pagan's LM statistic,
</p>
</li>
<li> <p><code>"bcsclm"</code> for the bias-corrected scaled version of
Breusch and Pagan's LM statistic, </p>
</li>
<li> <p><code>"rho"</code> for the average
correlation coefficient, </p>
</li>
<li> <p><code>"absrho"</code> for the average
absolute correlation coefficient,</p>
</li></ul>
</td></tr>
<tr><td><code id="pcdtest_+3A_w">w</code></td>
<td>
<p>either <code>NULL</code> (default) for the global tests or &ndash; for the
local versions of the statistics &ndash; a <code style="white-space: pre;">&#8288;n x n&#8288;</code> <code>matrix</code>
describing proximity between individuals, with <code class="reqn">w_ij = a</code>
where <code class="reqn">a</code> is any number such that <code>as.logical(a)==TRUE</code>, if
<code class="reqn">i,j</code> are neighbours, <code class="reqn">0</code> or any number <code class="reqn">b</code> such
that <code>as.logical(b)==FALSE</code> elsewhere. Only the lower
triangular part (without diagonal) of <code>w</code> after coercing by
<code>as.logical()</code> is evaluated for neighbouring information (but
<code>w</code> can be symmetric). See also <strong>Details</strong> and
<strong>Examples</strong>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These tests are originally meant to use the residuals of separate
estimation of one time&ndash;series regression for each cross-sectional
unit in order to check for cross&ndash;sectional dependence (<code>model = NULL</code>).
If a different model specification (<code>model = "within"</code>, <code>"random"</code>,
...) is assumed consistent, one can resort to its residuals for
testing (which is common, e.g., when the time dimension's length is
insufficient for estimating the heterogeneous model).
</p>
<p>If the time
dimension is insufficient and <code>model = NULL</code>, the function defaults
to estimation of a <code>within</code> model and issues a warning. The main
argument of this function may be either a model of class
<code>panelmodel</code> or a <code>formula</code> and <code style="white-space: pre;">&#8288;data frame&#8288;</code>; in the second case,
unless <code>model</code> is set to <code>NULL</code>, all usual parameters relative to
the estimation of a <code>plm</code> model may be passed on. The test is
compatible with any consistent <code>panelmodel</code> for the data at hand,
with any specification of <code>effect</code> (except for <code>test = "bcsclm"</code> which
requires a within model with either individual or two-ways effect).
E.g., specifying  <code>effect = "time"</code> or <code>effect = "twoways"</code> allows
to test for residual cross-sectional dependence after the introduction
of time fixed effects to account for common shocks.
</p>
<p>A <strong>local</strong> version of either test can be computed by supplying a
proximity matrix (elements coercible to <code>logical</code>) with argument
<code>w</code> which provides information on whether any pair of individuals
are neighbours or not. If <code>w</code> is supplied, only neighbouring pairs
will be used in computing the test; else, <code>w</code> will default to
<code>NULL</code> and all observations will be used. The matrix need not be
binary, so commonly used &quot;row&ndash;standardized&quot; matrices can be
employed as well. <code>nb</code> objects from <a href="https://CRAN.R-project.org/package=spdep"><span class="pkg">spdep</span></a> must instead be
transformed into matrices by <a href="https://CRAN.R-project.org/package=spdep"><span class="pkg">spdep</span></a>'s function <code>nb2mat</code>
before using.
</p>
<p>The methods implemented are suitable also for unbalanced panels.
</p>
<p>Pesaran's CD test (<code>test="cd"</code>), Breusch and Pagan's LM test
(<code>test="lm"</code>), and its scaled version (<code>test="sclm"</code>) are all
described in Pesaran (2004) (and complemented by
Pesaran (2005)). The bias-corrected scaled test (<code>test="bcsclm"</code>)
is due to (Baltagi et al. 2012) and only valid for
within models including the individual effect (it's unbalanced
version uses max(Tij) for T) in the bias-correction term).
Breusch and Pagan (1980) is the original source for
the LM test.
</p>
<p>The test on a <code>pseries</code> is the same as a test on a pooled
regression model of that variable on a constant, i.e.,
<code>pcdtest(some_pseries)</code> is equivalent to <code style="white-space: pre;">&#8288;pcdtest(plm(some_var ~ 1, data = some_pdata.frame, model = "pooling")&#8288;</code> and also equivalent to
<code>pcdtest(some_var ~ 1, data = some_data)</code>, where <code>some_var</code> is
the variable name in the data which corresponds to <code>some_pseries</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>References</h3>

<p>Baltagi BH, Feng Q, Kao C (2012).
&ldquo;A Lagrange Multiplier test for cross-sectional dependence in a fixed effects panel data model.&rdquo;
<em>Journal of Econometrics</em>, <b>170</b>(1), 164 - 177.
ISSN 0304-4076, <a href="https://www.sciencedirect.com/science/article/pii/S030440761200098X">https://www.sciencedirect.com/science/article/pii/S030440761200098X</a>.
</p>
<p>Breusch TS, Pagan AR (1980).
&ldquo;The Lagrange Multiplier Test and Its Applications to Model Specification in Econometrics.&rdquo;
<em>Review of Economic Studies</em>, <b>47</b>, 239&ndash;253.
</p>
<p>Pesaran MH (2004).
&ldquo;General Diagnostic Tests for Cross Section Dependence in Panels.&rdquo;
CESifo Working Paper Series, 1229.
</p>
<p>Pesaran MH (2015).
&ldquo;Testing Weak Cross-Sectional Dependence in Large Panels.&rdquo;
<em>Econometric Reviews</em>, <b>34</b>(6-10), 1089-1117.
<a href="https://doi.org/10.1080/07474938.2014.956623">doi:10.1080/07474938.2014.956623</a>, https://doi.org/10.1080/07474938.2014.956623.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
## test on heterogeneous model (separate time series regressions)
pcdtest(inv ~ value + capital, data = Grunfeld,
        index = c("firm", "year"))

## test on two-way fixed effects homogeneous model
pcdtest(inv ~ value + capital, data = Grunfeld, model = "within",
        effect = "twoways", index = c("firm", "year"))

## test on panelmodel object
g &lt;- plm(inv ~ value + capital, data = Grunfeld, index = c("firm", "year"))
pcdtest(g)

## scaled LM test
pcdtest(g, test = "sclm")

## test on pseries
pGrunfeld &lt;- pdata.frame(Grunfeld)
pcdtest(pGrunfeld$value)

## local test
## define neighbours for individual 2: 1, 3, 4, 5 in lower triangular matrix
w &lt;- matrix(0, ncol= 10, nrow=10)
w[2,1] &lt;- w[3,2] &lt;- w[4,2] &lt;- w[5,2] &lt;- 1
pcdtest(g, w = w)

</code></pre>

<hr>
<h2 id='pdata.frame'>data.frame for panel data</h2><span id='topic+pdata.frame'></span><span id='topic++24+3C-.pdata.frame'></span><span id='topic++5B.pdata.frame'></span><span id='topic++5B+5B.pdata.frame'></span><span id='topic++24.pdata.frame'></span><span id='topic+print.pdata.frame'></span><span id='topic+as.list.pdata.frame'></span><span id='topic+as.data.frame.pdata.frame'></span>

<h3>Description</h3>

<p>An object of class 'pdata.frame' is a data.frame with an index
attribute that describes its individual and time dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdata.frame(
  x,
  index = NULL,
  drop.index = FALSE,
  row.names = TRUE,
  stringsAsFactors = FALSE,
  replace.non.finite = FALSE,
  drop.NA.series = FALSE,
  drop.const.series = FALSE,
  drop.unused.levels = FALSE
)

## S3 replacement method for class 'pdata.frame'
x$name &lt;- value

## S3 method for class 'pdata.frame'
x[i, j, drop]

## S3 method for class 'pdata.frame'
x[[y]]

## S3 method for class 'pdata.frame'
x$y

## S3 method for class 'pdata.frame'
print(x, ...)

## S3 method for class 'pdata.frame'
as.list(x, keep.attributes = FALSE, ...)

## S3 method for class 'pdata.frame'
as.data.frame(
  x,
  row.names = NULL,
  optional = FALSE,
  keep.attributes = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdata.frame_+3A_x">x</code></td>
<td>
<p>a <code>data.frame</code> for the <code>pdata.frame</code> function and a
<code>pdata.frame</code> for the methods,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_index">index</code></td>
<td>
<p>this argument indicates the individual and time
indexes. See <strong>Details</strong>,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_drop.index">drop.index</code></td>
<td>
<p>logical, indicates whether the indexes are to be
excluded from the resulting pdata.frame,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_row.names">row.names</code></td>
<td>
<p><code>NULL</code> or logical, indicates whether &quot;fancy&quot; row
names (combination of individual index and time index) are to
be added to the returned (p)data.frame (<code>NULL</code> and <code>FALSE</code> have
the same meaning for <code>pdata.frame</code>; for
<code>as.data.frame.pdata.frame</code> see Details),</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>logical, indicating whether character
vectors are to be converted to factors,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_replace.non.finite">replace.non.finite</code></td>
<td>
<p>logical, indicating whether values for
which <code>is.finite()</code> yields <code>TRUE</code> are to be replaced by <code>NA</code>
values, except for character variables (defaults to <code>FALSE</code>),</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_drop.na.series">drop.NA.series</code></td>
<td>
<p>logical, indicating whether all-<code>NA</code> columns
are to be removed from the pdata.frame (defaults to <code>FALSE</code>),</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_drop.const.series">drop.const.series</code></td>
<td>
<p>logical, indicating whether constant
columns are to be removed from the pdata.frame (defaults to
<code>FALSE</code>),</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_drop.unused.levels">drop.unused.levels</code></td>
<td>
<p>logical, indicating whether unused levels
of factors are to be dropped (defaults to <code>FALSE</code>) (unused
levels are always dropped from variables serving to construct
the index variables),</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_name">name</code></td>
<td>
<p>the name of the <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_value">value</code></td>
<td>
<p>the name of the variable to include,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_i">i</code></td>
<td>
<p>see <code><a href="base.html#topic+Extract">Extract()</a></code>,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_j">j</code></td>
<td>
<p>see <code><a href="base.html#topic+Extract">Extract()</a></code>,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_drop">drop</code></td>
<td>
<p>see <code><a href="base.html#topic+Extract">Extract()</a></code>,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_y">y</code></td>
<td>
<p>one of the columns of the <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_keep.attributes">keep.attributes</code></td>
<td>
<p>logical, only for as.list and as.data.frame
methods, indicating whether the elements of the returned
list/columns of the data.frame should have the pdata.frame's
attributes added (default: FALSE for as.list, TRUE for
as.data.frame),</p>
</td></tr>
<tr><td><code id="pdata.frame_+3A_optional">optional</code></td>
<td>
<p>see <code><a href="base.html#topic+as.data.frame">as.data.frame()</a></code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>index</code> argument indicates the dimensions of the panel. It can
be: </p>

<ul>
<li><p> a vector of two character strings which
contains the names of the individual and of the time indexes,
</p>
</li>
<li>
<p>a character string which is the name of the individual index
variable. In this case, the time index is created automatically and
a new variable called &quot;time&quot; is added, assuming consecutive and
ascending time periods in the order of the original data,
</p>
</li>
<li><p> an integer, the number of individuals. In this case, the data
need to be a balanced panel and be organized as a stacked time series
(successive blocks of individuals, each block being a time series
for the respective individual) assuming consecutive and ascending
time periods in the order of the original data. Two new variables
are added: &quot;id&quot; and &quot;time&quot; which contain the individual and the
time indexes.
</p>
</li></ul>

<p>The <code>"[["</code> and <code>"$"</code> extract a series from the <code>pdata.frame</code>.  The
<code>"index"</code> attribute is then added to the series and a class
attribute <code>"pseries"</code> is added. The <code>"["</code> method behaves as for
<code>data.frame</code>, except that the extraction is also applied to the
<code>index</code> attribute.  A safe way to extract the index attribute is to
use the function <code><a href="#topic+index">index()</a></code> for 'pdata.frames' (and other objects).
</p>
<p><code>as.data.frame</code> removes the index attribute from the <code>pdata.frame</code>
and adds it to each column. For its argument <code>row.names</code> set to
<code>FALSE</code> row names are an integer series, <code>TRUE</code> gives &quot;fancy&quot; row
names; if a character (with length of the resulting data frame),
the row names will be the character's elements.
</p>
<p><code>as.list</code> behaves by default identical to
<code><a href="base.html#topic+list">base::as.list.data.frame()</a></code> which means it drops the
attributes specific to a pdata.frame; if a list of pseries is
wanted, the attribute <code>keep.attributes</code> can to be set to
<code>TRUE</code>. This also makes <code>lapply</code> work as expected on a pdata.frame
(see also <strong>Examples</strong>).
</p>


<h3>Value</h3>

<p>a <code>pdata.frame</code> object: this is a <code>data.frame</code> with an
<code>index</code> attribute which is a <code>data.frame</code> with two variables,
the individual and the time indexes, both being factors.  The
resulting pdata.frame is sorted by the individual index, then
by the time index.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>See Also</h3>

<p><code><a href="#topic+index">index()</a></code> to extract the index variables from a
'pdata.frame' (and other objects), <code><a href="#topic+pdim">pdim()</a></code> to check the
dimensions of a 'pdata.frame' (and other objects), <code><a href="#topic+pvar">pvar()</a></code> to
check for each variable if it varies cross-sectionally and over
time.  To check if the time periods are consecutive per
individual, see <code><a href="#topic+is.pconsecutive">is.pconsecutive()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Gasoline contains two variables which are individual and time
# indexes
data("Gasoline", package = "plm")
Gas &lt;- pdata.frame(Gasoline, index = c("country", "year"), drop.index = TRUE)

# Hedonic is an unbalanced panel, townid is the individual index
data("Hedonic", package = "plm")
Hed &lt;- pdata.frame(Hedonic, index = "townid", row.names = FALSE)

# In case of balanced panel, it is sufficient to give number of
# individuals data set 'Wages' is organized as a stacked time
# series
data("Wages", package = "plm")
Wag &lt;- pdata.frame(Wages, 595)

# lapply on a pdata.frame by making it a list of pseries first
lapply(as.list(Wag[ , c("ed", "lwage")], keep.attributes = TRUE), lag)


</code></pre>

<hr>
<h2 id='pdim'>Check for the Dimensions of the Panel</h2><span id='topic+pdim'></span><span id='topic+pdim.default'></span><span id='topic+pdim.data.frame'></span><span id='topic+pdim.pdata.frame'></span><span id='topic+pdim.pseries'></span><span id='topic+pdim.pggls'></span><span id='topic+pdim.pcce'></span><span id='topic+pdim.pmg'></span><span id='topic+pdim.pgmm'></span><span id='topic+pdim.panelmodel'></span><span id='topic+print.pdim'></span>

<h3>Description</h3>

<p>This function checks the number of individuals and time observations in the
panel and whether it is balanced or not.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdim(x, ...)

## Default S3 method:
pdim(x, y, ...)

## S3 method for class 'data.frame'
pdim(x, index = NULL, ...)

## S3 method for class 'pdata.frame'
pdim(x, ...)

## S3 method for class 'pseries'
pdim(x, ...)

## S3 method for class 'pggls'
pdim(x, ...)

## S3 method for class 'pcce'
pdim(x, ...)

## S3 method for class 'pmg'
pdim(x, ...)

## S3 method for class 'pgmm'
pdim(x, ...)

## S3 method for class 'panelmodel'
pdim(x, ...)

## S3 method for class 'pdim'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdim_+3A_x">x</code></td>
<td>
<p>a <code>data.frame</code>, a <code>pdata.frame</code>, a <code>pseries</code>, a
<code>panelmodel</code>, or a <code>pgmm</code> object,</p>
</td></tr>
<tr><td><code id="pdim_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pdim_+3A_y">y</code></td>
<td>
<p>a vector,</p>
</td></tr>
<tr><td><code id="pdim_+3A_index">index</code></td>
<td>
<p>see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pdim</code> is called by the estimation functions and can be also used
stand-alone.
</p>


<h3>Value</h3>

<p>An object of class <code>pdim</code> containing the following
elements:
</p>
<table>
<tr><td><code>nT</code></td>
<td>
<p>a list containing <code>n</code>, the number of individuals, <code>T</code>,
the number of time observations, <code>N</code> the total number of
observations,</p>
</td></tr>
<tr><td><code>Tint</code></td>
<td>
<p>a list containing two vectors (of type integer): <code>Ti</code>
gives the number of observations for each individual and <code>nt</code> gives
the number of individuals observed for each period,</p>
</td></tr>
<tr><td><code>balanced</code></td>
<td>
<p>a logical value: <code>TRUE</code> for a balanced panel,
<code>FALSE</code> for an unbalanced panel,</p>
</td></tr>
<tr><td><code>panel.names</code></td>
<td>
<p>a list of character vectors: <code>id.names</code> contains
the names of each individual and <code>time.names</code> contains the names of
each period.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Calling <code>pdim</code> on an estimated <code>panelmodel</code> object
and on the corresponding <code style="white-space: pre;">&#8288;(p)data.frame&#8288;</code> used for this
estimation does not necessarily yield the same result. When
called on an estimated <code>panelmodel</code>, the number of
observations (individual, time) actually used for model
estimation are taken into account.  When called on a
<code style="white-space: pre;">&#8288;(p)data.frame&#8288;</code>, the rows in the <code style="white-space: pre;">&#8288;(p)data.frame&#8288;</code> are
considered, disregarding any <code>NA</code> values in the dependent or
independent variable(s) which would be dropped during model
estimation.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.pbalanced">is.pbalanced()</a></code> to just determine balancedness
of data (slightly faster than <code>pdim</code>),<br />
<code><a href="#topic+punbalancedness">punbalancedness()</a></code> for measures of
unbalancedness,<br /> <code><a href="#topic+nobs">nobs()</a></code>,
<code><a href="#topic+pdata.frame">pdata.frame()</a></code>,<br /> <code><a href="#topic+pvar">pvar()</a></code> to check for
each variable if it varies cross-sectionally and over time.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# There are 595 individuals
data("Wages", package = "plm")
pdim(Wages, 595)

# Gasoline contains two variables which are individual and time
# indexes and are the first two variables
data("Gasoline", package="plm")
pdim(Gasoline)

# Hedonic is an unbalanced panel, townid is the individual index
data("Hedonic", package = "plm")
pdim(Hedonic, "townid")

# An example of the panelmodel method
data("Produc", package = "plm")
z &lt;- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp,data=Produc,
         model="random", subset = gsp &gt; 5000)
pdim(z)

</code></pre>

<hr>
<h2 id='pdwtest'>Durbin&ndash;Watson Test for Panel Models</h2><span id='topic+pdwtest'></span><span id='topic+pdwtest.panelmodel'></span><span id='topic+pdwtest.formula'></span>

<h3>Description</h3>

<p>Test of serial correlation for (the idiosyncratic component of) the errors
in panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdwtest(x, ...)

## S3 method for class 'panelmodel'
pdwtest(x, ...)

## S3 method for class 'formula'
pdwtest(x, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pdwtest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"panelmodel"</code> or of class
<code>"formula"</code>,</p>
</td></tr>
<tr><td><code id="pdwtest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on to <code>dwtest</code>,
e.g., <code>alternative</code>, see <code><a href="lmtest.html#topic+dwtest">lmtest::dwtest()</a></code> for
further details.</p>
</td></tr>
<tr><td><code id="pdwtest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This Durbin&ndash;Watson test uses the auxiliary model on
(quasi-)demeaned data taken from a model of class <code>plm</code> which may
be a <code>pooling</code> (the default), <code>random</code> or <code>within</code> model. It
performs a Durbin&ndash;Watson test (using <code>dwtest</code> from package
<a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> on the residuals of the (quasi-)demeaned model,
which should be serially uncorrelated under the null of no serial
correlation in idiosyncratic errors. The function takes the
demeaned data, estimates the model and calls <code>dwtest</code>. Thus, this
test does not take the panel structure of the residuals into
consideration; it shall not be confused with the generalized
Durbin-Watson test for panels in <code>pbnftest</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Durbin J, Watson GS (1950).
&ldquo;Testing for Serial Correlation in Least Squares Regression: I.&rdquo;
<em>Biometrika</em>, <b>37</b>(3/4), 409&ndash;428.
ISSN 00063444.
</p>
<p>Durbin J, Watson GS (1951).
&ldquo;Testing for serial correlation in least sqares regression. II.&rdquo;
<em>Biometrika</em>, <b>38</b>(1-2), 159-178.
ISSN 0006-3444, <a href="https://doi.org/10.1093/biomet/38.1-2.159">doi:10.1093/biomet/38.1-2.159</a>.
</p>
<p>Durbin J, Watson GS (1971).
&ldquo;Testing for Serial Correlation in Least Squares Regression. III.&rdquo;
<em>Biometrika</em>, <b>58</b>(1), 1&ndash;19.
ISSN 00063444.
</p>
<p>Wooldridge JM (2002).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>.
MIT Press.
</p>
<p>Wooldridge JM (2010).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>, 2nd edition.
MIT Press.
</p>


<h3>See Also</h3>

<p><code><a href="lmtest.html#topic+dwtest">lmtest::dwtest()</a></code> for the Durbin&ndash;Watson test
in <a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a>, <code><a href="#topic+pbgtest">pbgtest()</a></code> for the analogous
Breusch&ndash;Godfrey test for panel models,
<code><a href="lmtest.html#topic+bgtest">lmtest::bgtest()</a></code> for the Breusch&ndash;Godfrey test for
serial correlation in the linear model. <code><a href="#topic+pbltest">pbltest()</a></code>,
<code><a href="#topic+pbsytest">pbsytest()</a></code>, <code><a href="#topic+pwartest">pwartest()</a></code> and
<code><a href="#topic+pwfdtest">pwfdtest()</a></code> for other serial correlation tests for
panel models.
</p>
<p>For the Durbin-Watson test generalized to panel data models see
<code><a href="#topic+pbnftest">pbnftest()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
g &lt;- plm(inv ~ value + capital, data = Grunfeld, model="random")
pdwtest(g)
pdwtest(g, alternative="two.sided")
## formula interface
pdwtest(inv ~ value + capital, data=Grunfeld, model="random")

</code></pre>

<hr>
<h2 id='pFtest'>F Test for Individual and/or Time Effects</h2><span id='topic+pFtest'></span><span id='topic+pFtest.formula'></span><span id='topic+pFtest.plm'></span>

<h3>Description</h3>

<p>Test of individual and/or time effects based on the comparison of the
<code>within</code> and the <code>pooling</code> model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pFtest(x, ...)

## S3 method for class 'formula'
pFtest(x, data, ...)

## S3 method for class 'plm'
pFtest(x, z, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pFtest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code> or of class <code>"formula"</code>,</p>
</td></tr>
<tr><td><code id="pFtest_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pFtest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pFtest_+3A_z">z</code></td>
<td>
<p>an object of class <code>"plm"</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the <code>plm</code> method, the argument of this function is two <code>plm</code>
objects, the first being a within model, the second a pooling
model. The effects tested are either individual, time or twoways,
depending on the effects introduced in the within model.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plmtest">plmtest()</a></code> for Lagrange multiplier tests of individuals
and/or time effects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package="plm")
gp &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "pooling")
gi &lt;- plm(inv ~ value + capital, data = Grunfeld,
          effect = "individual", model = "within")
gt &lt;- plm(inv ~ value + capital, data = Grunfeld,
          effect = "time", model = "within")
gd &lt;- plm(inv ~ value + capital, data = Grunfeld,
          effect = "twoways", model = "within")
pFtest(gi, gp)
pFtest(gt, gp)
pFtest(gd, gp)
pFtest(inv ~ value + capital, data = Grunfeld, effect = "twoways")

</code></pre>

<hr>
<h2 id='pggls'>General FGLS Estimators</h2><span id='topic+pggls'></span><span id='topic+summary.pggls'></span><span id='topic+print.summary.pggls'></span><span id='topic+residuals.pggls'></span>

<h3>Description</h3>

<p>General FGLS estimators for panel data (balanced or unbalanced)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pggls(
  formula,
  data,
  subset,
  na.action,
  effect = c("individual", "time"),
  model = c("within", "pooling", "fd"),
  index = NULL,
  ...
)

## S3 method for class 'pggls'
summary(object, ...)

## S3 method for class 'summary.pggls'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)

## S3 method for class 'pggls'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pggls_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be estimated,</p>
</td></tr>
<tr><td><code id="pggls_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pggls_+3A_subset">subset</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="pggls_+3A_na.action">na.action</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="pggls_+3A_effect">effect</code></td>
<td>
<p>the effects introduced in the model, one of
<code>"individual"</code> or <code>"time"</code>,</p>
</td></tr>
<tr><td><code id="pggls_+3A_model">model</code></td>
<td>
<p>one of <code>"within"</code>, <code>"pooling"</code>, <code>"fd"</code>,</p>
</td></tr>
<tr><td><code id="pggls_+3A_index">index</code></td>
<td>
<p>the indexes, see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
<tr><td><code id="pggls_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pggls_+3A_object">object</code>, <code id="pggls_+3A_x">x</code></td>
<td>
<p>an object of class <code>pggls</code>,</p>
</td></tr>
<tr><td><code id="pggls_+3A_digits">digits</code></td>
<td>
<p>digits,</p>
</td></tr>
<tr><td><code id="pggls_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the print output,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pggls</code> is a function for the estimation of linear panel models by
general feasible generalized least squares, either with or without
fixed effects. General FGLS is based on a two-step estimation
process: first a model is estimated by OLS (<code>model = "pooling"</code>),
fixed effects (<code>model = "within"</code>) or first differences
(<code>model = "fd"</code>), then its residuals are used to estimate an error
covariance matrix for use in a feasible-GLS analysis. This framework allows
the error covariance structure inside every group
(if <code>effect = "individual"</code>, else symmetric) of observations to be fully
unrestricted and is therefore robust against any type of intragroup
heteroskedasticity and serial correlation. Conversely, this
structure is assumed identical across groups and thus general FGLS
estimation is inefficient under groupwise heteroskedasticity. Note
also that this method requires estimation of <code class="reqn">T(T+1)/2</code>
variance parameters, thus efficiency requires N &gt;&gt; T
(if <code>effect = "individual"</code>, else the opposite).
</p>
<p>If <code>model = "within"</code> (the default) then a FEGLS (fixed effects GLS, see
Wooldridge, Ch. 10.5) is estimated; if <code>model = "fd"</code> a FDGLS
(first-difference GLS). Setting <code>model = "pooling"</code> produces an unrestricted
FGLS model (see ibid.) (<code>model = "random"</code> does the same, but using this value
is deprecated and included only for retro&ndash;compatibility reasons).
</p>


<h3>Value</h3>

<p>An object of class <code>c("pggls","panelmodel")</code> containing:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the vector of coefficients,</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the vector of residuals,</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the vector of fitted values,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>the covariance matrix of the coefficients,</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>degrees of freedom of the residuals,</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>a data.frame containing the variables used for the
estimation,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call,</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the estimated intragroup (or cross-sectional, if
<code>effect = "time"</code>) covariance of errors,</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Im KS, Ahn SC, Schmidt P, Wooldridge JM (1999).
&ldquo;Efficient estimation of panel data models with strictly exogenous explanatory variables.&rdquo;
<em>Journal of Econometrics</em>, <b>93</b>(1), 177 - 201.
ISSN 0304-4076, <a href="https://www.sciencedirect.com/science/article/pii/S0304407699000081">https://www.sciencedirect.com/science/article/pii/S0304407699000081</a>.
</p>
<p>Kiefer NM (1980).
&ldquo;Estimation of fixed effect models for time series of cross-sections with arbitrary intertemporal covariance.&rdquo;
<em>Journal of Econometrics</em>, <b>14</b>(2), 195&ndash;202.
</p>
<p>Wooldridge JM (2002).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>.
MIT Press.
</p>
<p>Wooldridge JM (2010).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>, 2nd edition.
MIT Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
zz_wi &lt;- pggls(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,
               data = Produc, model = "within")
summary(zz_wi)

zz_pool &lt;- pggls(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,
                 data = Produc, model = "pooling")
summary(zz_pool)

zz_fd &lt;- pggls(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,
               data = Produc, model = "fd")
summary(zz_fd)


</code></pre>

<hr>
<h2 id='pgmm'>Generalized Method of Moments (GMM) Estimation for Panel Data</h2><span id='topic+pgmm'></span><span id='topic+coef.pgmm'></span><span id='topic+summary.pgmm'></span><span id='topic+print.summary.pgmm'></span>

<h3>Description</h3>

<p>Generalized method of moments estimation for static or dynamic
models with panel data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pgmm(
  formula,
  data,
  subset,
  na.action,
  effect = c("twoways", "individual"),
  model = c("onestep", "twosteps"),
  collapse = FALSE,
  lost.ts = NULL,
  transformation = c("d", "ld"),
  fsm = NULL,
  index = NULL,
  ...
)

## S3 method for class 'pgmm'
coef(object, ...)

## S3 method for class 'pgmm'
summary(object, robust = TRUE, time.dummies = FALSE, ...)

## S3 method for class 'summary.pgmm'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pgmm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be
estimated. The preferred interface is now to indicate a
multi&ndash;part formula, the first two parts describing the
covariates and the GMM instruments and, if any, the third part
the 'normal' instruments,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> (neither factors nor character vectors
will be accepted in <code>data.frame</code>),</p>
</td></tr>
<tr><td><code id="pgmm_+3A_subset">subset</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_na.action">na.action</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_effect">effect</code></td>
<td>
<p>the effects introduced in the model, one of
<code>"twoways"</code> (the default) or <code>"individual"</code>,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_model">model</code></td>
<td>
<p>one of <code>"onestep"</code> (the default) or <code>"twosteps"</code>,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_collapse">collapse</code></td>
<td>
<p>if <code>TRUE</code>, the GMM instruments are collapsed (default is
<code>FALSE</code>),</p>
</td></tr>
<tr><td><code id="pgmm_+3A_lost.ts">lost.ts</code></td>
<td>
<p>the number of lost time series: if <code>NULL</code>, this is
automatically computed. Otherwise, it can be defined by the
user as a numeric vector of length 1 or 2. The first element is
the number of lost time series in the model in difference, the
second one in the model in level. If the second element is
missing, it is set to the first one minus one,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_transformation">transformation</code></td>
<td>
<p>the kind of transformation to apply to the
model: either <code>"d"</code> (the default value) for the
&quot;difference GMM&quot; model or <code>"ld"</code> for the &quot;system GMM&quot; model,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_fsm">fsm</code></td>
<td>
<p>the matrix for the one step estimator: one of <code>"I"</code>
(identity matrix) or <code>"G"</code> (<code class="reqn">=D'D</code> where <code class="reqn">D</code> is the
first&ndash;difference operator) if <code>transformation="d"</code>, one of
<code>"GI"</code> or <code>"full"</code> if <code>transformation="ld"</code>,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_index">index</code></td>
<td>
<p>the indexes,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pgmm_+3A_object">object</code>, <code id="pgmm_+3A_x">x</code></td>
<td>
<p>an object of class <code>"pgmm"</code>,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_robust">robust</code></td>
<td>
<p>for pgmm's summary method: if <code>TRUE</code> (default), robust inference
is performed in the summary,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_time.dummies">time.dummies</code></td>
<td>
<p>for pgmm's summary method: if <code>TRUE</code>, the estimated
coefficients of time dummies are present in the table of coefficients;
default is <code>FALSE</code>, thus time dummies are dropped in summary's coefficient
table (argument is only meaningful if there are time dummies in the model,
i.e., only for <code>effect = "twoways"</code>),</p>
</td></tr>
<tr><td><code id="pgmm_+3A_digits">digits</code></td>
<td>
<p>digits,</p>
</td></tr>
<tr><td><code id="pgmm_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the print output.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pgmm</code> estimates a model for panel data with a generalized method
of moments (GMM) estimator. The description of the model to
estimate is provided with a multi&ndash;part formula which is (or which
is coerced to) a <code>Formula</code> object. The first right&ndash;hand side part
describes the covariates. The second one, which is mandatory,
describes the GMM instruments. The third one, which is optional,
describes the 'normal' instruments. By default, all the variables
of the model which are not used as GMM instruments are used as
normal instruments with the same lag structure as the one specified
in the model.
</p>
<p><code>y~lag(y, 1:2)+lag(x1, 0:1)+lag(x2, 0:2) | lag(y, 2:99)</code> is similar to
</p>
<p><code>y~lag(y, 1:2)+lag(x1, 0:1)+lag(x2, 0:2) | lag(y, 2:99) | lag(x1, 0:1)+lag(x2, 0:2)</code>
</p>
<p>and indicates that all lags from 2 of <code>y</code> are used
as GMM instruments.
</p>
<p><code>transformation</code> indicates how the model should be transformed for
the estimation. <code>"d"</code> gives the &quot;difference GMM&quot; model
(see Arellano and Bond 1991), <code>"ld"</code> the &quot;system GMM&quot; model
(see Blundell and Bond 1998).
</p>
<p><code>pgmm</code> is an attempt to adapt GMM estimators available within the
DPD library for GAUSS (see Arellano and Bond 1998) and Ox
(see Arellano and Bond 2012) and within the xtabond2
library for Stata (see Roodman 2009).
</p>


<h3>Value</h3>

<p>An object of class <code>c("pgmm","panelmodel")</code>, which has the
following elements:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the vector (or the list for fixed effects) of
coefficients,</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the list of residuals for each individual,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>the covariance matrix of the coefficients,</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the vector of fitted values,</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>degrees of freedom of the residuals,</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>a list containing the variables used for the
estimation for each individual,</p>
</td></tr>
<tr><td><code>W</code></td>
<td>
<p>a list containing the instruments for each individual (a matrix per
list element) (two lists in case of system GMM,</p>
</td></tr>
<tr><td><code>A1</code></td>
<td>
<p>the weighting matrix for the one&ndash;step estimator,</p>
</td></tr>
<tr><td><code>A2</code></td>
<td>
<p>the weighting matrix for the two&ndash;steps estimator,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call.</p>
</td></tr>
</table>
<p>In addition, it has attribute <code>"pdim"</code> which contains the pdim object for
the model.
</p>
<p>It has <code>print</code>, <code>summary</code> and <code>print.summary</code> methods.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>Arellano M, Bond S (1991).
&ldquo;Some Tests of Specification for Panel Data : Monte Carlo Evidence and an Application to Employment Equations.&rdquo;
<em>Review of Economic Studies</em>, <b>58</b>, 277&ndash;297.<br /><br /> Arellano M, Bond S (1998).
&ldquo;Dynamic panel data estimation using DPD98 for GAUSS: a guide for users.&rdquo;
unpublished.<br /><br /> Arellano M, Bond S (2012).
&ldquo;Panel data estimation using DPD for Ox.&rdquo;
unpublished, <a href="https://www.doornik.com/download/oxmetrics7/Ox_Packages/dpd.pdf">https://www.doornik.com/download/oxmetrics7/Ox_Packages/dpd.pdf</a>.<br /><br /> Blundell R, Bond S (1998).
&ldquo;Initital Conditions and Moment Restrictions in Dynamic Panel Data Models.&rdquo;
<em>Journal of Econometrics</em>, <b>87</b>, 115&ndash;143.<br /><br /> Roodman D (2009).
&ldquo;How to do xtabond2: An introduction to difference and system GMM in Stata.&rdquo;
<em>The Stata Journal</em>, <b>9</b>, 86-136.
<a href="https://www.stata-journal.com/article.html?article=st0159">https://www.stata-journal.com/article.html?article=st0159</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sargan">sargan()</a></code> for the Hansen&ndash;Sargan test and <code><a href="#topic+mtest">mtest()</a></code> for
Arellano&ndash;Bond's test of serial correlation.  <code><a href="#topic+dynformula">dynformula()</a></code> for
dynamic formulas (deprecated).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("EmplUK", package = "plm")

## Arellano and Bond (1991), table 4 col. b 
z1 &lt;- pgmm(log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1)
           + log(capital) + lag(log(output), 0:1) | lag(log(emp), 2:99),
            data = EmplUK, effect = "twoways", model = "twosteps")
summary(z1, robust = FALSE)

## Blundell and Bond (1998) table 4 (cf. DPD for OX p. 12 col. 4)
z2 &lt;- pgmm(log(emp) ~ lag(log(emp), 1)+ lag(log(wage), 0:1) +
           lag(log(capital), 0:1) | lag(log(emp), 2:99) +
           lag(log(wage), 2:99) + lag(log(capital), 2:99),
           data = EmplUK, effect = "twoways", model = "onestep", 
           transformation = "ld")
summary(z2, robust = TRUE)

## Not run: 
## Same with the old formula or dynformula interface
## Arellano and Bond (1991), table 4, col. b 
z1 &lt;- pgmm(log(emp) ~ log(wage) + log(capital) + log(output),
            lag.form = list(2,1,0,1), data = EmplUK, 
            effect = "twoways", model = "twosteps",
            gmm.inst = ~log(emp), lag.gmm = list(c(2,99)))
summary(z1, robust = FALSE)

## Blundell and Bond (1998) table 4 (cf DPD for OX p. 12 col. 4)
z2 &lt;- pgmm(dynformula(log(emp) ~ log(wage) + log(capital), list(1,1,1)), 
            data = EmplUK, effect = "twoways", model = "onestep", 
            gmm.inst = ~log(emp) + log(wage) + log(capital), 
            lag.gmm = c(2,99), transformation = "ld")
summary(z2, robust = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='pgrangertest'>Panel Granger (Non-)Causality Test (Dumitrescu/Hurlin (2012))</h2><span id='topic+pgrangertest'></span>

<h3>Description</h3>

<p>Test for Granger (non-)causality in panel data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pgrangertest(
  formula,
  data,
  test = c("Ztilde", "Zbar", "Wbar"),
  order = 1L,
  index = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pgrangertest_+3A_formula">formula</code></td>
<td>
<p>a <code>formula</code> object to describe the direction of the
hypothesized Granger causation,</p>
</td></tr>
<tr><td><code id="pgrangertest_+3A_data">data</code></td>
<td>
<p>a <code>pdata.frame</code> or a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pgrangertest_+3A_test">test</code></td>
<td>
<p>a character to request the statistic to be returned,
either <code>"Ztilde"</code> (default),or <code>"Zbar"</code>, alternatively, set to
<code>"Wbar"</code> for an intermediate statistic (see Details),</p>
</td></tr>
<tr><td><code id="pgrangertest_+3A_order">order</code></td>
<td>
<p>integer(s) giving the number of lags to include in the
test's auxiliary regressions, the length of order must be
either 1 (same lag order for all individuals) or equal to the
number of individuals (to specify a lag order per individual),</p>
</td></tr>
<tr><td><code id="pgrangertest_+3A_index">index</code></td>
<td>
<p>only relevant if <code>data</code> is <code>data.frame</code> and not a
<code>pdata.frame</code>; if <code>NULL</code>, the first two columns of the
data.frame are assumed to be the index variables, for further
details see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The panel Granger (non-)causality test is a combination of Granger
tests (Granger 1969) performed per individual. The test
is developed by Dumitrescu and Hurlin (2012), a shorter
exposition is given in Lopez and Weber (2017).
</p>
<p>The formula <code>formula</code> describes the direction of the (panel) Granger
causation where <code>y ~ x</code> means &quot;x (panel) Granger causes y&quot;.
</p>
<p>By setting argument <code>test</code> to either <code>"Ztilde"</code> (default) or
<code>"Zbar"</code>, two different statistics can be requested. <code>"Ztilde"</code>
gives the standardised statistic recommended by Dumitrescu/Hurlin (2012) for
fixed T samples. If set to <code>"Wbar"</code>, the intermediate Wbar statistic
(average of individual Granger chi-square statistics) is given which is used
to derive the other two.
</p>
<p>The Zbar statistic is not suitable for unbalanced panels. For the Wbar
statistic, no p-value is available.
</p>
<p>The implementation uses <code><a href="lmtest.html#topic+grangertest">lmtest::grangertest()</a></code> from
package <a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> to perform the individual Granger tests.
</p>


<h3>Value</h3>

<p>An object of class <code>c("pgrangertest", "htest")</code>. Besides
the usual elements of a <code>htest</code> object, it contains the data
frame <code>indgranger</code> which carries the Granger test statistics
per individual along the associated p-values, degrees of
freedom, and the specified lag order.
</p>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>References</h3>

<p>Dumitrescu E, Hurlin C (2012).
&ldquo;Testing for Granger non-causality in heterogeneous panels.&rdquo;
<em>Economic Modelling</em>, <b>29</b>(4), 1450 - 1460.
ISSN 0264-9993, <a href="https://www.sciencedirect.com/science/article/pii/S0264999312000491">https://www.sciencedirect.com/science/article/pii/S0264999312000491</a>.
</p>
<p>Granger CWJ (1969).
&ldquo;Investigating Causal Relations by Econometric Models and Cross-spectral Methods.&rdquo;
<em>Econometrica</em>, <b>37</b>(3), 424&ndash;438.
ISSN 00129682, 14680262.
</p>
<p>Lopez L, Weber S (2017).
&ldquo;Testing for Granger causality in panel data.&rdquo;
<em>Stata Journal</em>, <b>17</b>(4), 972-984.
<a href="https://www.stata-journal.com/article.html?article=st0507">https://www.stata-journal.com/article.html?article=st0507</a>.
</p>


<h3>See Also</h3>

<p><code><a href="lmtest.html#topic+grangertest">lmtest::grangertest()</a></code> for the original (non-panel)
Granger causality test in <a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## not meaningful, just to demonstrate usage
## H0: 'value' does not Granger cause 'inv' for all invididuals

data("Grunfeld", package = "plm")
pgrangertest(inv ~ value, data = Grunfeld)
pgrangertest(inv ~ value, data = Grunfeld, order = 2L)
pgrangertest(inv ~ value, data = Grunfeld, order = 2L, test = "Zbar")

# varying lag order (last individual lag order 3, others lag order 2)
(pgrt &lt;- pgrangertest(inv ~ value, data = Grunfeld, order = c(rep(2L, 9), 3L)))
# chisq statistics per individual
pgrt$indgranger

</code></pre>

<hr>
<h2 id='phansitest'>Simes Test for unit roots in panel data</h2><span id='topic+phansitest'></span><span id='topic+print.phansitest'></span>

<h3>Description</h3>

<p>Simes' test of intersection of individual hypothesis tests
(Simes (1986)) applied to panel unit root tests as suggested by
Hanck (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phansitest(object, alpha = 0.05)

## S3 method for class 'phansitest'
print(x, cutoff = 10L, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="phansitest_+3A_object">object</code></td>
<td>
<p>either a numeric containing p-values of individual unit root
test results (does not need to be sorted) or a suitable <code>purtest</code> object
(as produced by <code>purtest()</code> for a test which gives p-values of the individuals
(Hadri's test in <code>purtest</code> is not suitable)),</p>
</td></tr>
<tr><td><code id="phansitest_+3A_alpha">alpha</code></td>
<td>
<p>numeric, the pre-specified significance level (defaults to <code>0.05</code>),</p>
</td></tr>
<tr><td><code id="phansitest_+3A_x">x</code></td>
<td>
<p>an object of class <code>c("phansitest", "list")</code> as produced by
<code>phansitest</code> to be printed,</p>
</td></tr>
<tr><td><code id="phansitest_+3A_cutoff">cutoff</code></td>
<td>
<p>integer, cutoff value for printing of enumeration of individuals with
rejected individual H0, for print method only,</p>
</td></tr>
<tr><td><code id="phansitest_+3A_...">...</code></td>
<td>
<p>further arguments (currently not used).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Simes' approach to testing is combining p-values from single hypothesis tests
with a global (intersected) hypothesis. Hanck (2013)
mentions it can be applied to any panel unit root test which yield a p-value
for each individual series.
The test is robust versus general patterns of cross-sectional dependence.
</p>
<p>Further, this approach allows to discriminate between individuals for which
the individual H0 (unit root present for individual series) is rejected/is
not rejected by Hommel's procedure (Hommel (1988)) for
family-wise error rate control (FWER) at pre-specified significance level
alpha via argument <code>alpha</code> (defaulting to <code>0.05</code>), i.e., it controls for the
multiplicity in testing.
</p>
<p>The function <code>phansitest</code> takes as main input <code>object</code> either a plain numeric
containing p-values of individual tests or a <code>purtest</code> object which holds
a suitable pre-computed panel unit root test (one that produces p-values per
individual series).
</p>
<p>The function's return value (see section Value) is a list with detailed
evaluation of the applied Simes test.
</p>
<p>The associated <code>print</code> method prints a verbal evaluation.
</p>


<h3>Value</h3>

<p>For <code>phansitest</code>, an object of class <code>c("phansitest", "list")</code> which i
s a list with the elements:
</p>

<ul>
<li> <p><code>id</code>: integer, the identifier of the individual (integer sequence referring to
position in input),
</p>
</li>
<li> <p><code>name</code>: character, name of the input's individual (if it has a name,
otherwise &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, ...),
</p>
</li>
<li> <p><code>p</code>: numeric, p-values as input (either the numeric or extracted from
the purtest object),
</p>
</li>
<li> <p><code>p.hommel</code>: numeric, p-values after Hommel's transformation,
</p>
</li>
<li> <p><code>rejected</code>: logical, indicating for which individual the individual null
hypothesis is rejected (<code>TRUE</code>)/non-rejected (<code>FALSE</code>) (after controlling
for multiplicity),
</p>
</li>
<li> <p><code>rejected.no</code>: integer, giving the total number of rejected individual series,
</p>
</li>
<li> <p><code>alpha</code>: numeric, the input <code>alpha</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>References</h3>

<p>Hanck C (2013).
&ldquo;An Intersection Test for Panel Unit Roots.&rdquo;
<em>Econometric Reviews</em>, <b>32</b>, 183-203.<br /><br /> Hommel G (1988).
&ldquo;A stage wise rejective multiple test procedure based on a modified Bonferroni test.&rdquo;
<em>Biometrika</em>, <b>75</b>, 383-386.<br /><br /> Simes RJ (1986).
&ldquo;An improved Bonferroni procedure for multiple tests of significance.&rdquo;
<em>Biometrika</em>, <b>73</b>, 751-754.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+purtest">purtest()</a></code>, <code><a href="#topic+cipstest">cipstest()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### input is numeric (p-values)
#### example from Hanck (2013), Table 11 (left side)
pvals &lt;- c(0.0001,0.0001,0.0001,0.0001,0.0001,0.0001,0.0050,0.0050,0.0050,
           0.0050,0.0175,0.0175,0.0200,0.0250,0.0400,0.0500,0.0575,0.2375,0.2475)

countries &lt;- c("Argentina","Sweden","Norway","Mexico","Italy","Finland","France",
              "Germany","Belgium","U.K.","Brazil","Australia","Netherlands",
              "Portugal","Canada", "Spain","Denmark","Switzerland","Japan")
names(pvals) &lt;- countries

h &lt;- phansitest(pvals)
print(h)              # (explicitly) prints test's evaluation
print(h, cutoff = 3L) # print only first 3 rejected ids 
h$rejected # logical indicating the individuals with rejected individual H0


### input is a (suitable) purtest object
data("Grunfeld", package = "plm")
y &lt;- data.frame(split(Grunfeld$inv, Grunfeld$firm))
obj &lt;- purtest(y, pmax = 4, exo = "intercept", test = "madwu")

phansitest(obj)

</code></pre>

<hr>
<h2 id='pht'>Hausman&ndash;Taylor Estimator for Panel Data</h2><span id='topic+pht'></span><span id='topic+summary.pht'></span><span id='topic+print.summary.pht'></span>

<h3>Description</h3>

<p>The Hausman&ndash;Taylor estimator is an instrumental variable estimator without
external instruments (function deprecated).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pht(
  formula,
  data,
  subset,
  na.action,
  model = c("ht", "am", "bms"),
  index = NULL,
  ...
)

## S3 method for class 'pht'
summary(object, ...)

## S3 method for class 'summary.pht'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  subset = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pht_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be
estimated,</p>
</td></tr>
<tr><td><code id="pht_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pht_+3A_subset">subset</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code> for <code>"plm"</code>, a character or
numeric vector indicating a subset of the table of coefficient
to be printed for <code>"print.summary.plm"</code>,</p>
</td></tr>
<tr><td><code id="pht_+3A_na.action">na.action</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="pht_+3A_model">model</code></td>
<td>
<p>one of <code>"ht"</code> for Hausman&ndash;Taylor, <code>"am"</code>
for Amemiya&ndash;MaCurdy and <code>"bms"</code> for
Breusch&ndash;Mizon&ndash;Schmidt,</p>
</td></tr>
<tr><td><code id="pht_+3A_index">index</code></td>
<td>
<p>the indexes,</p>
</td></tr>
<tr><td><code id="pht_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pht_+3A_object">object</code>, <code id="pht_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code>,</p>
</td></tr>
<tr><td><code id="pht_+3A_digits">digits</code></td>
<td>
<p>digits,</p>
</td></tr>
<tr><td><code id="pht_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the print output,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pht</code> estimates panels models using the Hausman&ndash;Taylor estimator,
Amemiya&ndash;MaCurdy estimator, or Breusch&ndash;Mizon&ndash;Schmidt estimator, depending
on the argument <code>model</code>. The model is specified as a two&ndash;part formula,
the second part containing the exogenous variables.
</p>


<h3>Value</h3>

<p>An object of class <code>c("pht", "plm", "panelmodel")</code>.
</p>
<p>A <code>"pht"</code> object contains the same elements as <code>plm</code>
object, with a further argument called <code>varlist</code> which
describes the typology of the variables. It has <code>summary</code> and
<code>print.summary</code> methods.
</p>


<h3>Note</h3>

<p>The function <code>pht</code> is deprecated. Please use function <code>plm</code>
to estimate Taylor&ndash;Hausman models like this with a three-part
formula as shown in the example:<br /> <code style="white-space: pre;">&#8288;plm(&lt;formula&gt;, random.method = "ht", model = "random", inst.method = "baltagi")&#8288;</code>. The Amemiya&ndash;MaCurdy estimator and the
Breusch&ndash;Mizon&ndash;Schmidt estimator is computed likewise with
<code>plm</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>(Amemiya and MaCurdy 1986)
</p>
<p>(Baltagi 2013)
</p>
<p>(Breusch et al. 1989)
</p>
<p>(Hausman and Taylor 1981)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## replicates Baltagi (2005, 2013), table 7.4; Baltagi (2021), table 7.5
## preferred way with plm()
data("Wages", package = "plm")
ht &lt;- plm(lwage ~ wks + south + smsa + married + exp + I(exp ^ 2) + 
              bluecol + ind + union + sex + black + ed |
              bluecol + south + smsa + ind + sex + black |
              wks + married + union + exp + I(exp ^ 2), 
          data = Wages, index = 595,
          random.method = "ht", model = "random", inst.method = "baltagi")
summary(ht)

am &lt;- plm(lwage ~ wks + south + smsa + married + exp + I(exp ^ 2) + 
              bluecol + ind + union + sex + black + ed |
              bluecol + south + smsa + ind + sex + black |
              wks + married + union + exp + I(exp ^ 2), 
          data = Wages, index = 595,
          random.method = "ht", model = "random", inst.method = "am")
summary(am)

## deprecated way with pht() for HT
#ht &lt;- pht(lwage ~ wks + south + smsa + married + exp + I(exp^2) +
#          bluecol + ind + union + sex + black + ed | 
#          sex + black + bluecol + south + smsa + ind,
#          data = Wages, model = "ht", index = 595)
#summary(ht)
# deprecated way with pht() for AM
#am &lt;- pht(lwage ~ wks + south + smsa + married + exp + I(exp^2) +
#          bluecol + ind + union + sex + black + ed | 
#          sex + black + bluecol + south + smsa + ind,
#          data = Wages, model = "am", index = 595)
#summary(am)


</code></pre>

<hr>
<h2 id='phtest'>Hausman Test for Panel Models</h2><span id='topic+phtest'></span><span id='topic+phtest.formula'></span><span id='topic+phtest.panelmodel'></span>

<h3>Description</h3>

<p>Specification test for panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>phtest(x, ...)

## S3 method for class 'formula'
phtest(
  x,
  data,
  model = c("within", "random"),
  effect = c("individual", "time", "twoways"),
  method = c("chisq", "aux"),
  index = NULL,
  vcov = NULL,
  ...
)

## S3 method for class 'panelmodel'
phtest(x, x2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="phtest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"panelmodel"</code> or <code>"formula"</code>,</p>
</td></tr>
<tr><td><code id="phtest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on (currently none).</p>
</td></tr>
<tr><td><code id="phtest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="phtest_+3A_model">model</code></td>
<td>
<p>a character vector containing the names of two models
(length(model) must be 2),</p>
</td></tr>
<tr><td><code id="phtest_+3A_effect">effect</code></td>
<td>
<p>a character specifying the effect to be introduced to both models,
one of <code>"individual"</code>, <code>"time"</code>, or <code>"twoways"</code> (only for formula method),</p>
</td></tr>
<tr><td><code id="phtest_+3A_method">method</code></td>
<td>
<p>one of <code>"chisq"</code> or <code>"aux"</code>,</p>
</td></tr>
<tr><td><code id="phtest_+3A_index">index</code></td>
<td>
<p>an optional vector of index variables,</p>
</td></tr>
<tr><td><code id="phtest_+3A_vcov">vcov</code></td>
<td>
<p>an optional covariance function,</p>
</td></tr>
<tr><td><code id="phtest_+3A_x2">x2</code></td>
<td>
<p>an object of class <code>"panelmodel"</code> (only for panelmodel method/interface),</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Hausman test (sometimes also called Durbin&ndash;Wu&ndash;Hausman test)
is based on the difference of the vectors of coefficients of two
different models.  The <code>panelmodel</code> method computes the original
version of the test based on a quadratic form
(Hausman 1978). The <code>formula</code> method, if
<code>method = "chisq"</code> (default), computes the original version of the
test based on a quadratic form; if <code>method ="aux"</code> then the
auxiliary-regression-based version as in Wooldridge (2010),
Sec.10.7.3. Only the latter can be robustified by specifying a robust
covariance estimator as a function through the argument <code>vcov</code> (see
<strong>Examples</strong>).
</p>
<p>The <code>effect</code> argument is only relevant for the formula method/interface and
is then applied to both models. For the panelmodel method/interface, the test
is run with the effects of the already estimated models.
</p>
<p>The equivalent tests in the <strong>one-way</strong> case using a between
model (either &quot;within vs. between&quot; or &quot;random vs. between&quot;)
(see Hausman and Taylor 1981 or Baltagi 2013 Sec.4.3) can also
be performed by <code>phtest</code>, but only for <code>test = "chisq"</code>, not for
the regression-based test. NB: These equivalent tests using the
between model do not extend to the two-ways case.  There are,
however, some other equivalent tests,
(see Kang 1985 or Baltagi 2013 Sec.4.3.7),
but those are unsupported by <code>phtest</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant, Giovanni Millo
</p>


<h3>References</h3>

<p>Hausman JA (1978).
&ldquo;Specification Tests in Econometrics.&rdquo;
<em>Econometrica</em>, <b>46</b>, 1251&ndash;1271.
</p>
<p>Hausman JA, Taylor WE (1981).
&ldquo;Panel Data and Unobservable Individual Effects.&rdquo;
<em>Econometrica</em>, <b>49</b>, 1377&ndash;1398.
</p>
<p>Kang S (1985).
&ldquo;A note on the equivalence of specification tests in the two-factor multivariate variance components model.&rdquo;
<em>Journal of Econometrics</em>, <b>28</b>(2), 193 - 203.
ISSN 0304-4076, <a href="https://www.sciencedirect.com/science/article/pii/0304407685901198">https://www.sciencedirect.com/science/article/pii/0304407685901198</a>.
</p>
<p>Wooldridge JM (2010).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>, 2nd edition.
MIT Press.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Gasoline", package = "plm")
form &lt;- lgaspcar ~ lincomep + lrpmg + lcarpcap
wi &lt;- plm(form, data = Gasoline, model = "within")
re &lt;- plm(form, data = Gasoline, model = "random")
phtest(wi, re)
phtest(form, data = Gasoline)
phtest(form, data = Gasoline, effect = "time")

# Regression-based Hausman test
phtest(form, data = Gasoline, method = "aux")

# robust Hausman test with vcov supplied as a function and 
# with additional parameters
phtest(form, data = Gasoline, method = "aux", vcov = vcovHC)
phtest(form, data = Gasoline, method = "aux",
  vcov = function(x) vcovHC(x, method="white2", type="HC3"))

</code></pre>

<hr>
<h2 id='piest'>Chamberlain estimator and test for fixed effects</h2><span id='topic+piest'></span><span id='topic+print.piest'></span><span id='topic+summary.piest'></span><span id='topic+print.summary.piest'></span>

<h3>Description</h3>

<p>General estimator useful for testing the within specification
</p>


<h3>Usage</h3>

<pre><code class='language-R'>piest(formula, data, subset, na.action, index = NULL, robust = TRUE, ...)

## S3 method for class 'piest'
print(x, ...)

## S3 method for class 'piest'
summary(object, ...)

## S3 method for class 'summary.piest'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  subset = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="piest_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be estimated,</p>
</td></tr>
<tr><td><code id="piest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="piest_+3A_subset">subset</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="piest_+3A_na.action">na.action</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="piest_+3A_index">index</code></td>
<td>
<p>the indexes,</p>
</td></tr>
<tr><td><code id="piest_+3A_robust">robust</code></td>
<td>
<p>logical, if <code>FALSE</code>, the error is assumed to be spherical,
if <code>TRUE</code>, a robust estimation of the covariance matrix is computed,</p>
</td></tr>
<tr><td><code id="piest_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="piest_+3A_object">object</code>, <code id="piest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"piest"</code> and of class <code>"summary.piest"</code>
for the print method of summary for piest objects,</p>
</td></tr>
<tr><td><code id="piest_+3A_digits">digits</code></td>
<td>
<p>number of digits for printed output,</p>
</td></tr>
<tr><td><code id="piest_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the printed output,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Chamberlain method consists in using the covariates of all the
periods as regressors. It allows to test the within specification.
</p>


<h3>Value</h3>

<p>An object of class <code>"piest"</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>Chamberlain G (1982).
&ldquo;Multivariate regression models for panel data.&rdquo;
<em>Journal of Econometrics</em>, <b>18</b>, 5&ndash;46.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aneweytest">aneweytest()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("RiceFarms", package = "plm")
pirice &lt;- piest(log(goutput) ~ log(seed) + log(totlabor) + log(size), RiceFarms, index = "id")
summary(pirice)

</code></pre>

<hr>
<h2 id='pldv'>Panel estimators for limited dependent variables</h2><span id='topic+pldv'></span>

<h3>Description</h3>

<p>Fixed and random effects estimators for truncated or censored
limited dependent variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pldv(
  formula,
  data,
  subset,
  weights,
  na.action,
  model = c("fd", "random", "pooling"),
  index = NULL,
  R = 20,
  start = NULL,
  lower = 0,
  upper = +Inf,
  objfun = c("lsq", "lad"),
  sample = c("cens", "trunc"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pldv_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be
estimated,</p>
</td></tr>
<tr><td><code id="pldv_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pldv_+3A_subset">subset</code></td>
<td>
<p>see <code>lm</code>,</p>
</td></tr>
<tr><td><code id="pldv_+3A_weights">weights</code></td>
<td>
<p>see <code>lm</code>,</p>
</td></tr>
<tr><td><code id="pldv_+3A_na.action">na.action</code></td>
<td>
<p>see <code>lm</code>,</p>
</td></tr>
<tr><td><code id="pldv_+3A_model">model</code></td>
<td>
<p>one of <code>"fd"</code>, <code>"random"</code>, or <code>"pooling"</code>,</p>
</td></tr>
<tr><td><code id="pldv_+3A_index">index</code></td>
<td>
<p>the indexes, see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
<tr><td><code id="pldv_+3A_r">R</code></td>
<td>
<p>the number of points for the gaussian quadrature,</p>
</td></tr>
<tr><td><code id="pldv_+3A_start">start</code></td>
<td>
<p>a vector of starting values,</p>
</td></tr>
<tr><td><code id="pldv_+3A_lower">lower</code></td>
<td>
<p>the lower bound for the censored/truncated dependent
variable,</p>
</td></tr>
<tr><td><code id="pldv_+3A_upper">upper</code></td>
<td>
<p>the upper bound for the censored/truncated dependent
variable,</p>
</td></tr>
<tr><td><code id="pldv_+3A_objfun">objfun</code></td>
<td>
<p>the objective function for the fixed effect model (<code>model = "fd"</code>,
irrelevant for other values of the <code>model</code> argument ):
one of <code>"lsq"</code> for least squares (minimise sum of squares of the residuals)
and <code>"lad"</code> for least absolute deviations (minimise sum of absolute values
of the residuals),</p>
</td></tr>
<tr><td><code id="pldv_+3A_sample">sample</code></td>
<td>
<p><code>"cens"</code> for a censored (tobit-like) sample,
<code>"trunc"</code> for a truncated sample,</p>
</td></tr>
<tr><td><code id="pldv_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pldv</code> computes two kinds of models: a LSQ/LAD estimator for the
first-difference model (<code>model = "fd"</code>) and a maximum likelihood estimator
with an assumed normal distribution for the individual effects
(<code>model = "random"</code> or <code>"pooling"</code>).
</p>
<p>For maximum-likelihood estimations, <code>pldv</code> uses internally function
<code><a href="maxLik.html#topic+maxLik">maxLik::maxLik()</a></code> (from package <a href="https://CRAN.R-project.org/package=maxLik"><span class="pkg">maxLik</span></a>).
</p>


<h3>Value</h3>

<p>For <code>model = "fd"</code>, an object of class <code>c("plm", "panelmodel")</code>, for
<code>model = "random"</code> and <code>model = "pooling"</code> an object of class <code>c("maxLik", "maxim")</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>Honor BE (1992).
&ldquo;Trimmed LAD and least squares estimation of truncated and censored regression models with fixed effects.&rdquo;
<em>Econometrica</em>, <b>60</b>(3).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## as these examples take a bit of time, do not run them automatically
## Not run: 
data("Donors", package = "pder")
library("plm")
pDonors &lt;- pdata.frame(Donors, index = "id")

# replicate Landry/Lange/List/Price/Rupp (2010), online appendix, table 5a, models A and B
modA &lt;- pldv(donation ~ treatment +  prcontr, data = pDonors,
            model = "random", method = "bfgs")
summary(modA)
modB &lt;- pldv(donation ~ treatment * prcontr - prcontr, data = pDonors,
            model = "random", method = "bfgs")
summary(modB)

## End(Not run)

</code></pre>

<hr>
<h2 id='plm'>Panel Data Estimators</h2><span id='topic+plm'></span><span id='topic+print.plm.list'></span><span id='topic+terms.panelmodel'></span><span id='topic+vcov.panelmodel'></span><span id='topic+fitted.panelmodel'></span><span id='topic+residuals.panelmodel'></span><span id='topic+df.residual.panelmodel'></span><span id='topic+coef.panelmodel'></span><span id='topic+print.panelmodel'></span><span id='topic+update.panelmodel'></span><span id='topic+deviance.panelmodel'></span><span id='topic+formula.plm'></span><span id='topic+plot.plm'></span><span id='topic+residuals.plm'></span><span id='topic+fitted.plm'></span>

<h3>Description</h3>

<p>Linear models for panel data estimated using the <code>lm</code> function on
transformed data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plm(
  formula,
  data,
  subset,
  weights,
  na.action,
  effect = c("individual", "time", "twoways", "nested"),
  model = c("within", "random", "ht", "between", "pooling", "fd"),
  random.method = NULL,
  random.models = NULL,
  random.dfcor = NULL,
  inst.method = c("bvk", "baltagi", "am", "bms"),
  restrict.matrix = NULL,
  restrict.rhs = NULL,
  index = NULL,
  ...
)

## S3 method for class 'plm.list'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)

## S3 method for class 'panelmodel'
terms(x, ...)

## S3 method for class 'panelmodel'
vcov(object, ...)

## S3 method for class 'panelmodel'
fitted(object, ...)

## S3 method for class 'panelmodel'
residuals(object, ...)

## S3 method for class 'panelmodel'
df.residual(object, ...)

## S3 method for class 'panelmodel'
coef(object, ...)

## S3 method for class 'panelmodel'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)

## S3 method for class 'panelmodel'
update(object, formula., ..., evaluate = TRUE)

## S3 method for class 'panelmodel'
deviance(object, model = NULL, ...)

## S3 method for class 'plm'
formula(x, ...)

## S3 method for class 'plm'
plot(
  x,
  dx = 0.2,
  N = NULL,
  seed = 1,
  within = TRUE,
  pooling = TRUE,
  between = FALSE,
  random = FALSE,
  ...
)

## S3 method for class 'plm'
residuals(object, model = NULL, effect = NULL, ...)

## S3 method for class 'plm'
fitted(object, model = NULL, effect = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be
estimated,</p>
</td></tr>
<tr><td><code id="plm_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="plm_+3A_subset">subset</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">stats::lm()</a></code>,</p>
</td></tr>
<tr><td><code id="plm_+3A_weights">weights</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">stats::lm()</a></code>,</p>
</td></tr>
<tr><td><code id="plm_+3A_na.action">na.action</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">stats::lm()</a></code>; currently, not fully
supported,</p>
</td></tr>
<tr><td><code id="plm_+3A_effect">effect</code></td>
<td>
<p>the effects introduced in the model, one of
<code>"individual"</code>, <code>"time"</code>, <code>"twoways"</code>, or
<code>"nested"</code>,</p>
</td></tr>
<tr><td><code id="plm_+3A_model">model</code></td>
<td>
<p>one of <code>"pooling"</code>, <code>"within"</code>,
<code>"between"</code>, <code>"random"</code> <code>"fd"</code>, or <code>"ht"</code>,</p>
</td></tr>
<tr><td><code id="plm_+3A_random.method">random.method</code></td>
<td>
<p>method of estimation for the variance
components in the random effects model, one of <code>"swar"</code>
(default), <code>"amemiya"</code>, <code>"walhus"</code>, <code>"nerlove"</code>; for
Hausman-Taylor estimation set to <code>"ht"</code> (see Details and Examples),</p>
</td></tr>
<tr><td><code id="plm_+3A_random.models">random.models</code></td>
<td>
<p>an alternative to the previous argument, the
models used to compute the variance components estimations are
indicated,</p>
</td></tr>
<tr><td><code id="plm_+3A_random.dfcor">random.dfcor</code></td>
<td>
<p>a numeric vector of length 2 indicating which
degree of freedom should be used,</p>
</td></tr>
<tr><td><code id="plm_+3A_inst.method">inst.method</code></td>
<td>
<p>the instrumental variable transformation: one of
<code>"bvk"</code>, <code>"baltagi"</code>, <code>"am"</code>, or <code>"bms"</code> (see also Details),</p>
</td></tr>
<tr><td><code id="plm_+3A_restrict.matrix">restrict.matrix</code></td>
<td>
<p>a matrix which defines linear restrictions
on the coefficients,</p>
</td></tr>
<tr><td><code id="plm_+3A_restrict.rhs">restrict.rhs</code></td>
<td>
<p>the right hand side vector of the linear
restrictions on the coefficients,</p>
</td></tr>
<tr><td><code id="plm_+3A_index">index</code></td>
<td>
<p>the indexes,</p>
</td></tr>
<tr><td><code id="plm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="plm_+3A_x">x</code>, <code id="plm_+3A_object">object</code></td>
<td>
<p>an object of class <code>"plm"</code>,</p>
</td></tr>
<tr><td><code id="plm_+3A_digits">digits</code></td>
<td>
<p>number of digits for printed output,</p>
</td></tr>
<tr><td><code id="plm_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the printed output,</p>
</td></tr>
<tr><td><code id="plm_+3A_formula.">formula.</code></td>
<td>
<p>a new formula for the update method,</p>
</td></tr>
<tr><td><code id="plm_+3A_evaluate">evaluate</code></td>
<td>
<p>a boolean for the update method, if <code>TRUE</code> the
updated model is returned, if <code>FALSE</code> the call is returned,</p>
</td></tr>
<tr><td><code id="plm_+3A_dx">dx</code></td>
<td>
<p>the half&ndash;length of the individual lines for the plot
method (relative to x range),</p>
</td></tr>
<tr><td><code id="plm_+3A_n">N</code></td>
<td>
<p>the number of individual to plot,</p>
</td></tr>
<tr><td><code id="plm_+3A_seed">seed</code></td>
<td>
<p>the seed which will lead to individual selection,</p>
</td></tr>
<tr><td><code id="plm_+3A_within">within</code></td>
<td>
<p>if <code>TRUE</code>, the within model is plotted,</p>
</td></tr>
<tr><td><code id="plm_+3A_pooling">pooling</code></td>
<td>
<p>if <code>TRUE</code>, the pooling model is plotted,</p>
</td></tr>
<tr><td><code id="plm_+3A_between">between</code></td>
<td>
<p>if <code>TRUE</code>, the between model is plotted,</p>
</td></tr>
<tr><td><code id="plm_+3A_random">random</code></td>
<td>
<p>if <code>TRUE</code>, the random effect model is plotted,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plm</code> is a general function for the estimation of linear panel
models.  It supports the following estimation methods: pooled OLS
(<code>model = "pooling"</code>), fixed effects (<code>"within"</code>), random effects
(<code>"random"</code>), first&ndash;differences (<code>"fd"</code>), and between
(<code>"between"</code>). It supports unbalanced panels and two&ndash;way effects
(although not with all methods).
</p>
<p>For random effects models, four estimators of the transformation
parameter are available by setting <code>random.method</code> to one of
<code>"swar"</code> (Swamy and Arora 1972) (default), <code>"amemiya"</code>
(Amemiya 1971), <code>"walhus"</code>
(Wallace and Hussain 1969), or <code>"nerlove"</code>
(Nerlove 1971) (see below for Hausman-Taylor instrumental
variable case).
</p>
<p>For first&ndash;difference models, the intercept is maintained (which
from a specification viewpoint amounts to allowing for a trend in
the levels model). The user can exclude it from the estimated
specification the usual way by adding <code>"-1"</code> to the model formula.
</p>
<p>Instrumental variables estimation is obtained using two&ndash;part
formulas, the second part indicating the instrumental variables
used. This can be a complete list of instrumental variables or an
update of the first part. If, for example, the model is <code>y ~ x1 + x2 + x3</code>, with <code>x1</code> and <code>x2</code> endogenous and <code>z1</code> and <code>z2</code> external
instruments, the model can be estimated with:
</p>

<ul>
<li> <p><code>formula = y~x1+x2+x3 | x3+z1+z2</code>,
</p>
</li>
<li> <p><code>formula = y~x1+x2+x3 | . -x1-x2+z1+z2</code>.
</p>
</li></ul>

<p>If an instrument variable estimation is requested, argument
<code>inst.method</code> selects the instrument variable transformation
method:
</p>

<ul>
<li> <p><code>"bvk"</code> (default) for Balestra and Varadharajan&ndash;Krishnakumar (1987),
</p>
</li>
<li> <p><code>"baltagi"</code> for Baltagi (1981),
</p>
</li>
<li> <p><code>"am"</code> for Amemiya and MaCurdy (1986),
</p>
</li>
<li> <p><code>"bms"</code> for Breusch et al. (1989).
</p>
</li></ul>

<p>The Hausman&ndash;Taylor estimator (Hausman and Taylor 1981) is
computed with arguments <code>random.method = "ht"</code>, <code>model = "random"</code>,
<code>inst.method = "baltagi"</code> (the other way with only <code>model = "ht"</code>
is deprecated).
</p>
<p>See also the vignettes for introductions to model estimations (and more) with
examples.
</p>


<h3>Value</h3>

<p>An object of class <code>"plm"</code>.
</p>
<p>A <code>"plm"</code> object has the following elements :
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the vector of coefficients,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>the variance&ndash;covariance matrix of the coefficients,</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the vector of residuals (these are the residuals
of the (quasi-)demeaned model),</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>(only for weighted estimations) weights as
specified,</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>degrees of freedom of the residuals,</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>an object of class <code>"Formula"</code> describing the model,</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>the model frame as a <code>"pdata.frame"</code> containing the
variables used for estimation: the response is in first column followed by
the other variables, the individual and time indexes are in the 'index'
attribute of <code>model</code>,</p>
</td></tr>
<tr><td><code>ercomp</code></td>
<td>
<p>an object of class <code>"ercomp"</code> providing the
estimation of the components of the errors (for random effects
models only),</p>
</td></tr>
<tr><td><code>aliased</code></td>
<td>
<p>named logical vector indicating any aliased
coefficients which are silently dropped by <code>plm</code> due to
linearly dependent terms (see also <code><a href="#topic+detect.lindep">detect.lindep()</a></code>),</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call.</p>
</td></tr>
</table>
<p>It has <code>print</code>, <code>summary</code> and <code>print.summary</code> methods. The
<code>summary</code> method creates an object of class <code>"summary.plm"</code> that
extends the object it is run on with information about (inter alia) F
statistic and (adjusted) R-squared of model, standard errors, t&ndash;values, and
p&ndash;values of coefficients, (if supplied) the furnished vcov, see
<code><a href="#topic+summary.plm">summary.plm()</a></code> for further details.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>Amemiya T (1971).
&ldquo;The Estimation of the Variances in a Variance&ndash;Components Model.&rdquo;
<em>International Economic Review</em>, <b>12</b>, 1&ndash;13.
</p>
<p>Amemiya T, MaCurdy TE (1986).
&ldquo;Instrumental-Variable Estimation of an Error-Components Model.&rdquo;
<em>Econometrica</em>, <b>54</b>(4), 869-80.
</p>
<p>Balestra P, Varadharajan&ndash;Krishnakumar J (1987).
&ldquo;Full Information Estimations of a System of Simultaneous Equations With Error Components.&rdquo;
<em>Econometric Theory</em>, <b>3</b>, 223&ndash;246.
</p>
<p>Baltagi BH (1981).
&ldquo;Simultaneous Equations With Error Components.&rdquo;
<em>Journal of Econometrics</em>, <b>17</b>, 21&ndash;49.
</p>
<p>Baltagi BH, Song SH, Jung BC (2001).
&ldquo;The unbalanced nested error component regression model.&rdquo;
<em>Journal of Econometrics</em>, <b>101</b>, 357-381.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Breusch TS, Mizon GE, Schmidt P (1989).
&ldquo;Efficient Estimation Using Panel Data.&rdquo;
<em>Econometrica</em>, <b>57</b>(3), 695-700.
</p>
<p>Hausman JA, Taylor WE (1981).
&ldquo;Panel Data and Unobservable Individual Effects.&rdquo;
<em>Econometrica</em>, <b>49</b>, 1377&ndash;1398.
</p>
<p>Nerlove M (1971).
&ldquo;Further Evidence on the Estimation of Dynamic Economic Relations from a Time&ndash;Series of Cross&ndash;Sections.&rdquo;
<em>Econometrica</em>, <b>39</b>, 359&ndash;382.
</p>
<p>Swamy PAVB, Arora SS (1972).
&ldquo;The Exact Finite Sample Properties of the Estimators of Coefficients in the Error Components Regression Models.&rdquo;
<em>Econometrica</em>, <b>40</b>, 261&ndash;275.
</p>
<p>Wallace TD, Hussain A (1969).
&ldquo;The Use of Error Components Models in Combining Cross Section With Time Series Data.&rdquo;
<em>Econometrica</em>, <b>37</b>(1), 55&ndash;72.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.plm">summary.plm()</a></code> for further details about the associated
summary method and the &quot;summary.plm&quot; object both of which provide some model
tests and tests of coefficients.  <code><a href="#topic+fixef">fixef()</a></code> to compute the fixed
effects for &quot;within&quot; models (=fixed effects models). <code><a href="#topic+predict.plm">predict.plm()</a></code> for
predicted values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
zz &lt;- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,
          data = Produc, index = c("state","year"))
summary(zz)

# replicates some results from Baltagi (2013), table 3.1
data("Grunfeld", package = "plm")
p &lt;- plm(inv ~ value + capital,
         data = Grunfeld, model = "pooling")

wi &lt;- plm(inv ~ value + capital,
          data = Grunfeld, model = "within", effect = "twoways")

swar &lt;- plm(inv ~ value + capital,
            data = Grunfeld, model = "random", effect = "twoways")

amemiya &lt;- plm(inv ~ value + capital,
               data = Grunfeld, model = "random", random.method = "amemiya",
               effect = "twoways")

walhus &lt;- plm(inv ~ value + capital,
              data = Grunfeld, model = "random", random.method = "walhus",
              effect = "twoways")

# summary and summary with a furnished vcov (passed as matrix, 
# as function, and as function with additional argument)
summary(wi)
summary(wi, vcov = vcovHC(wi))
summary(wi, vcov = vcovHC)
summary(wi, vcov = function(x) vcovHC(x, method = "white2"))


## nested random effect model
# replicate Baltagi/Song/Jung (2001), p. 378 (table 6), columns SA, WH
# == Baltagi (2013), pp. 204-205
data("Produc", package = "plm")
pProduc &lt;- pdata.frame(Produc, index = c("state", "year", "region"))
form &lt;- log(gsp) ~ log(pc) + log(emp) + log(hwy) + log(water) + log(util) + unemp
summary(plm(form, data = pProduc, model = "random", effect = "nested"))
summary(plm(form, data = pProduc, model = "random", effect = "nested",
            random.method = "walhus"))

## Instrumental variable estimations
# replicate Baltagi (2013/2021), p. 133/162, table 7.1
data("Crime", package = "plm")
FE2SLS &lt;- plm(lcrmrte ~ lprbarr + lpolpc + lprbconv + lprbpris + lavgsen +
                ldensity + lwcon + lwtuc + lwtrd + lwfir + lwser + lwmfg + lwfed +
                lwsta + lwloc + lpctymle + lpctmin + region + smsa + factor(year)
              | . - lprbarr - lpolpc + ltaxpc + lmix,
              data = Crime, model = "within")
G2SLS &lt;- update(FE2SLS, model = "random", inst.method = "bvk")
EC2SLS &lt;- update(G2SLS, model = "random", inst.method = "baltagi")

## Hausman-Taylor estimator and Amemiya-MaCurdy estimator
# replicate Baltagi (2005, 2013), table 7.4; Baltagi (2021), table 7.5
data("Wages", package = "plm")
ht &lt;- plm(lwage ~ wks + south + smsa + married + exp + I(exp ^ 2) + 
              bluecol + ind + union + sex + black + ed |
              bluecol + south + smsa + ind + sex + black |
              wks + married + union + exp + I(exp ^ 2), 
          data = Wages, index = 595,
          random.method = "ht", model = "random", inst.method = "baltagi")
summary(ht)

am &lt;- plm(lwage ~ wks + south + smsa + married + exp + I(exp ^ 2) + 
              bluecol + ind + union + sex + black + ed |
              bluecol + south + smsa + ind + sex + black |
              wks + married + union + exp + I(exp ^ 2), 
          data = Wages, index = 595,
          random.method = "ht", model = "random", inst.method = "am")
summary(am)

</code></pre>

<hr>
<h2 id='plm-deprecated'>Deprecated functions of plm</h2><span id='topic+plm-deprecated'></span><span id='topic+detect_lin_dep'></span><span id='topic+pvcovHC'></span><span id='topic+plm.data'></span><span id='topic+dynformula'></span><span id='topic+formula.dynformula'></span><span id='topic+print.dynformula'></span>

<h3>Description</h3>

<p><code>dynformula</code>, <code>pht</code>, <code>plm.data</code>, and <code>pvcovHC</code> are
deprecated functions which could be removed from <span class="pkg">plm</span> in a near future.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvcovHC(x, ...)

plm.data(x, indexes = NULL)

dynformula(formula, lag.form = NULL, diff.form = NULL, log.form = NULL)

## S3 method for class 'dynformula'
formula(x, ...)

## S3 method for class 'dynformula'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plm-deprecated_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code>,</p>
</td></tr>
<tr><td><code id="plm-deprecated_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="plm-deprecated_+3A_indexes">indexes</code></td>
<td>
<p>a vector (of length one or two) indicating the (individual
and time) indexes (see Details);</p>
</td></tr>
<tr><td><code id="plm-deprecated_+3A_formula">formula</code></td>
<td>
<p>a formula,</p>
</td></tr>
<tr><td><code id="plm-deprecated_+3A_lag.form">lag.form</code></td>
<td>
<p>a list containing the lag structure of each variable in the
formula,</p>
</td></tr>
<tr><td><code id="plm-deprecated_+3A_diff.form">diff.form</code></td>
<td>
<p>a vector (or a list) of logical values indicating whether
variables should be differenced,</p>
</td></tr>
<tr><td><code id="plm-deprecated_+3A_log.form">log.form</code></td>
<td>
<p>a vector (or a list) of logical values indicating whether
variables should be in logarithms.</p>
</td></tr>
<tr><td><code id="plm-deprecated_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dynformula</code> was used to construct a dynamic formula which was the
first argument of <code>pgmm</code>. <code>pgmm</code> uses now multi-part formulas.
</p>
<p><code>pht</code> estimates the Hausman-Taylor model, which can now be estimated
using the more general <code>plm</code> function.
</p>
<p><code>plm.data</code> is replaced by <code>pdata.frame</code>.
</p>
<p><code>pvcovHC</code> is replaced by <code>vcovHC</code>.
</p>
<p><code>detect_lin_dep</code> was renamed to <code>detect.lindep</code>.
</p>

<hr>
<h2 id='plm-package'>plm package: linear models for panel data</h2><span id='topic+plm-package'></span>

<h3>Description</h3>

<p>plm is a package for R which intends to make the estimation of linear panel
models straightforward. plm provides functions to estimate a wide variety of
models and to make (robust) inference.
</p>


<h3>Details</h3>

<p>For a gentle and comprehensive introduction to the package, please see the
package's vignette.
</p>
<p>The main functions to estimate models are:
</p>

<ul>
<li> <p><code>plm</code>: panel data estimators using <code>lm</code> on transformed data,
</p>
</li>
<li> <p><code>pvcm</code>: variable coefficients models
</p>
</li>
<li> <p><code>pgmm</code>: generalized method of moments (GMM) estimation for panel
data,
</p>
</li>
<li> <p><code>pggls</code>: estimation of general feasible generalized least squares models,
</p>
</li>
<li> <p><code>pmg</code>: mean groups (MG), demeaned MG and common correlated effects
(CCEMG) estimators,
</p>
</li>
<li> <p><code>pcce</code>: estimators for common correlated effects mean groups (CCEMG) and
pooled (CCEP) for panel data with common factors,
</p>
</li>
<li> <p><code>pldv</code>: panel estimators for limited dependent variables.
</p>
</li></ul>

<p>Next to the model estimation functions, the package offers several
functions for statistical tests related to panel data/models.
</p>
<p>Multiple functions for (robust) variance&ndash;covariance matrices are
at hand as well.
</p>
<p>The package also provides data sets to demonstrate functions and to
replicate some text book/paper results.  Use
<code>data(package="plm")</code> to view a list of available data sets in
the package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
zz &lt;- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,
          data = Produc, index = c("state","year"))
summary(zz)

# replicates some results from Baltagi (2013), table 3.1
data("Grunfeld", package = "plm")
p &lt;- plm(inv ~ value + capital,
         data = Grunfeld, model="pooling")

wi &lt;- plm(inv ~ value + capital,
          data = Grunfeld, model="within", effect = "twoways")

swar &lt;- plm(inv ~ value + capital,
            data = Grunfeld, model="random", effect = "twoways")
          
amemiya &lt;- plm(inv ~ value + capital,
               data = Grunfeld, model = "random", random.method = "amemiya",
               effect = "twoways")
                
walhus &lt;- plm(inv ~ value + capital,
              data = Grunfeld, model = "random", random.method = "walhus",
              effect = "twoways")

</code></pre>

<hr>
<h2 id='plm.fast'>Option to Switch On/Off Fast Data Transformations</h2><span id='topic+plm.fast'></span>

<h3>Description</h3>

<p>A significant speed up can be gained by using fast (panel) data transformation
functions from package <code>collapse</code>.
An additional significant speed up for the two-way fixed effects case can be
achieved if package <code>fixest</code> or <code>lfe</code> is installed (package <code>collapse</code>
needs to be installed for the fast mode in any case).
</p>


<h3>Details</h3>

<p>By default, this speed up is enabled.
Option <code>plm.fast</code> can be used to enable/disable the speed up. The option is
evaluated prior to execution of supported transformations (see below), so
<code>option("plm.fast" = TRUE)</code> enables the speed up while
<code>option("plm.fast" = FALSE)</code> disables the speed up.
</p>
<p>To have it always switched off, put <code>options("plm.fast" = FALSE)</code> in your
.Rprofile file.
</p>
<p>See <strong>Examples</strong> for how to use the option and for a benchmarking example.
</p>
<p>For long, package <code>plm</code> used base R implementations and R-based code. The
package <code>collapse</code> provides fast data transformation functions written
in C/C++, among them some especially suitable for panel data.
Having package <code>collapse</code> installed is a requirement for the speed up, so
this package is a hard dependency for package <code>plm</code>.
</p>
<p>Availability of packages <code>fixest</code> and <code>lfe</code> is checked for once when
package plm is attached and the additional speed up for the two-way fixed
effect case is enabled automatically (<code>fixest</code> wins over <code>lfe</code>),
given one of the packages is detected and <code>options("plm.fast" = TRUE)</code>
(default) is set. If so, the packages' fast algorithms to partial out fixed
effects are used (<code>fixest::demean</code> (via <code>collapse::fhdwithin</code>),
<code>lfe::demeanlist</code>). Both packages are 'Suggests' dependencies.
</p>
<p>Users might experience neglectable numerical differences between enabled and
disabled fast mode and base R implementation, depending on the platform and
the additional packages installed.
</p>
<p>Currently, these basic functions benefit from the speed-up, used as building
blocks in most model estimation functions, e.g., in <code>plm</code> (more functions are
under investigation):
</p>

<ul>
<li><p> between,
</p>
</li>
<li><p> Between,
</p>
</li>
<li><p> Sum,
</p>
</li>
<li><p> Within,
</p>
</li>
<li><p> lag, lead, and diff,
</p>
</li>
<li><p> pseriesfy,
</p>
</li>
<li><p> pdiff (internal function).
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
### A benchmark of plm without and with speed-up
library("plm")
library("collapse")
library("microbenchmark")
rm(list = ls())
data("wlddev", package = "collapse")
form &lt;- LIFEEX ~ PCGDP + GINI

# produce big data set (taken from collapse's vignette)
wlddevsmall &lt;- get_vars(wlddev, c("iso3c","year","OECD","PCGDP","LIFEEX","GINI","ODA"))
wlddevsmall$iso3c &lt;- as.character(wlddevsmall$iso3c)
data &lt;- replicate(100, wlddevsmall, simplify = FALSE)
rm(wlddevsmall)
uniquify &lt;- function(x, i) {
  x$iso3c &lt;- paste0(x$iso3c, i)
  x
}
data &lt;- unlist2d(Map(uniquify, data, as.list(1:100)), idcols = FALSE)
data &lt;- pdata.frame(data, index = c("iso3c", "year"))
pdim(data) # Balanced Panel: n = 21600, T = 59, N = 1274400 // but many NAs
# data &lt;- na.omit(data)
# pdim(data) # Unbalanced Panel: n = 13300, T = 1-31, N = 93900

times &lt;- 1 # no. of repetitions for benchmark - this takes quite long!

onewayFE &lt;- microbenchmark(
 {options("plm.fast" = FALSE); plm(form, data = data, model = "within")},
 {options("plm.fast" = TRUE);  plm(form, data = data, model = "within")},
  times = times)

summary(onewayFE, unit = "relative")

## two-ways FE benchmark requires pkg fixest and lfe
## (End-users shall only set option plm.fast. Option plm.fast.pkg.FE.tw shall
##  _not_ be set by the end-user, it is determined automatically when pkg plm
## is attached; however, it needs to be set explicitly in this example for the
## benchmark.)
if(requireNamespace("fixest", quietly = TRUE) &amp;&amp;
   requireNamespace("lfe", quietly = TRUE)) {

twowayFE &lt;-  microbenchmark(
 {options("plm.fast" = FALSE);
    plm(form, data = data, model = "within", effect = "twoways")},
 {options("plm.fast" = TRUE, "plm.fast.pkg.FE.tw" = "collapse");
    plm(form, data = data, model = "within", effect = "twoways")},
 {options("plm.fast" = TRUE, "plm.fast.pkg.FE.tw" = "fixest");
    plm(form, data = data, model = "within", effect = "twoways")},
 {options("plm.fast" = TRUE, "plm.fast.pkg.FE.tw" = "lfe");
    plm(form, data = data, model = "within", effect = "twoways")},
  times = times)

summary(twowayFE, unit = "relative")
}

onewayRE &lt;- microbenchmark(
 {options("plm.fast" = FALSE); plm(form, data = data, model = "random")},
 {options("plm.fast" = TRUE);  plm(form, data = data, model = "random")},
  times = times)

summary(onewayRE, unit = "relative")

twowayRE &lt;-  microbenchmark(
 {options("plm.fast" = FALSE); plm(form, data = data, model = "random", effect = "twoways")},
 {options("plm.fast" = TRUE);  plm(form, data = data, model = "random", effect = "twoways")},
  times = times)

summary(twowayRE, unit = "relative")

## End(Not run)
</code></pre>

<hr>
<h2 id='plmtest'>Lagrange FF Multiplier Tests for Panel Models</h2><span id='topic+plmtest'></span><span id='topic+plmtest.plm'></span><span id='topic+plmtest.formula'></span>

<h3>Description</h3>

<p>Test of individual and/or time effects for panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plmtest(x, ...)

## S3 method for class 'plm'
plmtest(
  x,
  effect = c("individual", "time", "twoways"),
  type = c("honda", "bp", "ghm", "kw"),
  ...
)

## S3 method for class 'formula'
plmtest(
  x,
  data,
  ...,
  effect = c("individual", "time", "twoways"),
  type = c("honda", "bp", "ghm", "kw")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plmtest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code> or a formula of class
<code>"formula"</code>,</p>
</td></tr>
<tr><td><code id="plmtest_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code>plmtest</code>.</p>
</td></tr>
<tr><td><code id="plmtest_+3A_effect">effect</code></td>
<td>
<p>a character string indicating which effects are
tested: individual effects (<code>"individual"</code>), time effects
(<code>"time"</code>) or both (<code>"twoways"</code>),</p>
</td></tr>
<tr><td><code id="plmtest_+3A_type">type</code></td>
<td>
<p>a character string indicating the test to be performed:
</p>

<ul>
<li> <p><code>"honda"</code> (default) for Honda (1985),
</p>
</li>
<li> <p><code>"bp"</code> for Breusch and Pagan (1980),
</p>
</li>
<li> <p><code>"kw"</code> for King and Wu (1997), or
</p>
</li>
<li> <p><code>"ghm"</code> for Gourieroux et al. (1982) for
unbalanced panel data sets, the respective unbalanced version
of the tests are computed,
</p>
</li></ul>
</td></tr>
<tr><td><code id="plmtest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These Lagrange multiplier tests use only the residuals of the
pooling model.  The first argument of this function may be either a
pooling model of class <code>plm</code> or an object of class <code>formula</code>
describing the model. For input within (fixed effects) or random
effects models, the corresponding pooling model is calculated
internally first as the tests are based on the residuals of the
pooling model.
</p>
<p>The <code>"bp"</code> test for unbalanced panels was derived in
Baltagi and Li (1990)
(1990), the <code>"kw"</code> test for unbalanced panels in
Baltagi et al. (1998).
</p>
<p>The <code>"ghm"</code> test and the <code>"kw"</code> test were extended to two-way
effects in Baltagi et al. (1992).
</p>
<p>For a concise overview of all these statistics see
Baltagi (2003), Sec. 4.2, pp. 68&ndash;76 (for balanced
panels) and Sec. 9.5, pp. 200&ndash;203 (for unbalanced panels).
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Note</h3>

<p>For the King-Wu statistics (<code>"kw"</code>), the oneway statistics
(<code>"individual"</code> and <code>"time"</code>) coincide with the respective
Honda statistics (<code>"honda"</code>); twoway statistics of <code>"kw"</code> and
<code>"honda"</code> differ.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant (initial implementation), Kevin Tappe
(generalization to unbalanced panels)
</p>


<h3>References</h3>

<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH, Li Q (1990).
&ldquo;A Lagrange multiplier test for the error components model with incomplete panels.&rdquo;
<em>Econometric Reviews</em>, <b>9</b>, 103&ndash;107.
</p>
<p>Baltagi BH, Chang YJ, Li Q (1992).
&ldquo;Monte Carlo results on several new and existing tests for the error components model.&rdquo;
<em>Journal of Econometrics</em>, <b>54</b>, 95&ndash;120.
</p>
<p>Baltagi B, Chang YA, Li Q (1998).
&ldquo;Testing for random individual and time effects using unbalanced panel data.&rdquo;
<em>Advances in econometrics</em>, <b>13</b>, 1-20.
</p>
<p>Breusch TS, Pagan AR (1980).
&ldquo;The Lagrange Multiplier Test and Its Applications to Model Specification in Econometrics.&rdquo;
<em>Review of Economic Studies</em>, <b>47</b>, 239&ndash;253.
</p>
<p>Gourieroux C, Holly A, Monfort A (1982).
&ldquo;Likelihood Ratio Test, Wald Test, and Kuhn&ndash;Tucker Test in Linear Models With Inequality Constraints on the Regression Parameters.&rdquo;
<em>Econometrica</em>, <b>50</b>, 63&ndash;80.
</p>
<p>Honda Y (1985).
&ldquo;Testing the Error Components Model With Non&ndash;Normal Disturbances.&rdquo;
<em>Review of Economic Studies</em>, <b>52</b>, 681&ndash;690.
</p>
<p>King ML, Wu PX (1997).
&ldquo;Locally Optimal One&ndash;Sided Tests for Multiparameter Hypothese.&rdquo;
<em>Econometric Reviews</em>, <b>33</b>, 523&ndash;529.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pFtest">pFtest()</a></code> for individual and/or time effects tests based
on the within model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
g &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "pooling")
plmtest(g)
plmtest(g, effect="time")
plmtest(inv ~ value + capital, data = Grunfeld, type = "honda")
plmtest(inv ~ value + capital, data = Grunfeld, type = "bp")
plmtest(inv ~ value + capital, data = Grunfeld, type = "bp",  effect = "twoways")
plmtest(inv ~ value + capital, data = Grunfeld, type = "ghm", effect = "twoways")
plmtest(inv ~ value + capital, data = Grunfeld, type = "kw",  effect = "twoways")

Grunfeld_unbal &lt;- Grunfeld[1:(nrow(Grunfeld)-1), ] # create an unbalanced panel data set
g_unbal &lt;- plm(inv ~ value + capital, data = Grunfeld_unbal, model = "pooling")
plmtest(g_unbal) # unbalanced version of test is indicated in output

</code></pre>

<hr>
<h2 id='pmg'>Mean Groups (MG), Demeaned MG and CCE MG estimators</h2><span id='topic+pmg'></span><span id='topic+summary.pmg'></span><span id='topic+print.summary.pmg'></span><span id='topic+residuals.pmg'></span>

<h3>Description</h3>

<p>Mean Groups (MG), Demeaned MG (DMG) and Common Correlated Effects
MG (CCEMG) estimators for heterogeneous panel models, possibly with
common factors (CCEMG)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmg(
  formula,
  data,
  subset,
  na.action,
  model = c("mg", "cmg", "dmg"),
  index = NULL,
  trend = FALSE,
  ...
)

## S3 method for class 'pmg'
summary(object, ...)

## S3 method for class 'summary.pmg'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)

## S3 method for class 'pmg'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmg_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be estimated,</p>
</td></tr>
<tr><td><code id="pmg_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pmg_+3A_subset">subset</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="pmg_+3A_na.action">na.action</code></td>
<td>
<p>see <code><a href="stats.html#topic+lm">lm()</a></code>,</p>
</td></tr>
<tr><td><code id="pmg_+3A_model">model</code></td>
<td>
<p>one of <code>"mg"</code>, <code>"cmg"</code>, or <code>"dmg"</code>,</p>
</td></tr>
<tr><td><code id="pmg_+3A_index">index</code></td>
<td>
<p>the indexes, see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
<tr><td><code id="pmg_+3A_trend">trend</code></td>
<td>
<p>logical specifying whether an individual-specific
trend has to be included,</p>
</td></tr>
<tr><td><code id="pmg_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pmg_+3A_object">object</code>, <code id="pmg_+3A_x">x</code></td>
<td>
<p>an object of class <code>pmg</code>,</p>
</td></tr>
<tr><td><code id="pmg_+3A_digits">digits</code></td>
<td>
<p>digits,</p>
</td></tr>
<tr><td><code id="pmg_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the print output,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pmg</code> is a function for the estimation of linear panel models with
heterogeneous coefficients by various Mean Groups estimators. Setting
argument <code>model = "mg"</code> specifies the standard Mean Groups estimator, based on the
average of individual time series regressions. If <code>model = "dmg"</code>
the data are demeaned cross-sectionally, which is believed to
reduce the influence of common factors (and is akin to what is done
in homogeneous panels when <code>model = "within"</code> and <code>effect = "time"</code>).
Lastly, if <code>model = "cmg"</code> the CCEMG estimator is
employed which is consistent under the hypothesis of
unobserved common factors and idiosyncratic factor loadings; it
works by augmenting the model by cross-sectional averages of the
dependent variable and regressors in order to account for the
common factors, and adding individual intercepts and possibly
trends.
</p>


<h3>Value</h3>

<p>An object of class <code>c("pmg", "panelmodel")</code> containing:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the vector of coefficients,</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the vector of residuals,</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the vector of fitted values,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>the covariance matrix of the coefficients,</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>degrees of freedom of the residuals,</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>a data.frame containing the variables used for the
estimation,</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>numeric, the R squared,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call,</p>
</td></tr>
<tr><td><code>indcoef</code></td>
<td>
<p>the matrix of individual coefficients from
separate time series regressions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Pesaran MH (2006).
&ldquo;Estimation and inference in large heterogeneous panels with a multifactor error structure.&rdquo;
<em>Econometrica</em>, <b>74</b>(4), 967&ndash;1012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Produc", package = "plm")
## Mean Groups estimator
mgmod &lt;- pmg(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc)
summary(mgmod)

## demeaned Mean Groups
dmgmod &lt;- pmg(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, 
             data = Produc, model = "dmg")
summary(dmgmod)

## Common Correlated Effects Mean Groups
ccemgmod &lt;- pmg(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, 
                data = Produc, model = "cmg")
summary(ccemgmod)
</code></pre>

<hr>
<h2 id='pmodel.response'>A function to extract the model.response</h2><span id='topic+pmodel.response'></span><span id='topic+pmodel.response.plm'></span><span id='topic+pmodel.response.data.frame'></span><span id='topic+pmodel.response.formula'></span>

<h3>Description</h3>

<p>pmodel.response has several methods to conveniently extract the
response of several objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pmodel.response(object, ...)

## S3 method for class 'plm'
pmodel.response(object, ...)

## S3 method for class 'data.frame'
pmodel.response(object, ...)

## S3 method for class 'formula'
pmodel.response(object, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pmodel.response_+3A_object">object</code></td>
<td>
<p>an object of class <code>"plm"</code>, or a formula of
class <code>"Formula"</code>,</p>
</td></tr>
<tr><td><code id="pmodel.response_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pmodel.response_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The model response is extracted from a <code>pdata.frame</code> (where the
response must reside in the first column; this is the case for a
model frame), a <code>Formula</code> + <code>data</code> (being a model frame) or a <code>plm</code>
object, and the
transformation specified by <code>effect</code> and <code>model</code> is applied to
it.<br /> Constructing the model frame first ensures proper <code>NA</code>
handling and the response being placed in the first column, see
also <strong>Examples</strong> for usage.
</p>


<h3>Value</h3>

<p>A pseries except if model responses' of a <code>"between"</code>
or <code>"fd"</code> model as these models &quot;compress&quot; the data (the number
of observations used in estimation is smaller than the original
data due to the specific transformation). A numeric is returned
for the <code>"between"</code> and <code>"fd"</code> model.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>See Also</h3>

<p><code>plm</code>'s <code><a href="stats.html#topic+model.matrix">model.matrix()</a></code> for (transformed)
model matrix and the corresponding <code><a href="stats.html#topic+model.frame">model.frame()</a></code>
method to construct a model frame.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# First, make a pdata.frame
data("Grunfeld", package = "plm")
pGrunfeld &lt;- pdata.frame(Grunfeld)

# then make a model frame from a Formula and a pdata.frame
form &lt;- inv ~ value + capital
mf &lt;- model.frame(pGrunfeld, form)

# retrieve (transformed) response directly from model frame
resp_mf &lt;- pmodel.response(mf, model = "within", effect = "individual")

# retrieve (transformed) response from a plm object, i.e., an estimated model
fe_model &lt;- plm(form, data = pGrunfeld, model = "within")
pmodel.response(fe_model)

# same as constructed before
all.equal(resp_mf, pmodel.response(fe_model), check.attributes = FALSE) # TRUE

</code></pre>

<hr>
<h2 id='pooltest'>Test of Poolability</h2><span id='topic+pooltest'></span><span id='topic+pooltest.plm'></span><span id='topic+pooltest.formula'></span>

<h3>Description</h3>

<p>A Chow test for the poolability of the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pooltest(x, ...)

## S3 method for class 'plm'
pooltest(x, z, ...)

## S3 method for class 'formula'
pooltest(x, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pooltest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code> for the plm method; an object of
class <code>"formula"</code> for the formula interface,</p>
</td></tr>
<tr><td><code id="pooltest_+3A_...">...</code></td>
<td>
<p>further arguments passed to plm.</p>
</td></tr>
<tr><td><code id="pooltest_+3A_z">z</code></td>
<td>
<p>an object of class <code>"pvcm"</code> obtained with
<code>model="within"</code>,</p>
</td></tr>
<tr><td><code id="pooltest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pooltest</code> is a <em>F</em> test of stability (or Chow test) for the
coefficients of a panel model. For argument <code>x</code>, the estimated
<code>plm</code> object should be a <code>"pooling"</code> model or a <code>"within"</code> model
(the default); intercepts are assumed to be identical in the first
case and different in the second case.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Gasoline", package = "plm")
form &lt;- lgaspcar ~ lincomep + lrpmg + lcarpcap
gasw &lt;- plm(form, data = Gasoline, model = "within")
gasp &lt;- plm(form, data = Gasoline, model = "pooling")
gasnp &lt;- pvcm(form, data = Gasoline, model = "within")
pooltest(gasw, gasnp)
pooltest(gasp, gasnp)

pooltest(form, data = Gasoline, effect = "individual", model = "within")
pooltest(form, data = Gasoline, effect = "individual", model = "pooling")

</code></pre>

<hr>
<h2 id='predict.plm'>Model Prediction for plm Objects</h2><span id='topic+predict.plm'></span>

<h3>Description</h3>

<p>Predicted values of response based on plm models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plm'
predict(
  object,
  newdata = NULL,
  na.fill = !inherits(newdata, "pdata.frame"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.plm_+3A_object">object</code></td>
<td>
<p>An object of class <code>"plm"</code>,</p>
</td></tr>
<tr><td><code id="predict.plm_+3A_newdata">newdata</code></td>
<td>
<p>An optional pdata.frame in which to look for variables to be
used for prediction. If <code>NULL</code>, the fitted values are returned.
For fixed effects models, supplying a pdata.frame is recommended.</p>
</td></tr>
<tr><td><code id="predict.plm_+3A_na.fill">na.fill</code></td>
<td>
<p>A logical, only relevant if <code>object</code> is a pdata.frame, indicating
whether for any supplied out-of-sample indexes (individual, time,
combination of both), the missing fixed effect estimate is filled
with the weighted mean of the model's present fixed effect estimates
or not.</p>
</td></tr>
<tr><td><code id="predict.plm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>predict</code>calculates predicted values by evaluating the regression function of
a plm model for <code>newdata</code> or, if <code>newdata = NULL</code>, it returns the fitted values
the plm model.
</p>
<p>The fixed effects (within) model is somewhat special in prediction as it has
fixed effects estimated per individual, time period (one-way) or both (two-ways
model) which should to be respected when predicting values relating to these
fixed effects in the model: To do so, it is recommended to supply a pdata.frame
(and not a plain data.frame) in <code>newdata</code> as it describes the relationship
between the data supplied to the individual. and/or time periods. In case
the <code>newdata</code>'s pdata.frame has out-of-sample data (data contains individuals
and/or time periods not contained in the original model), it is not clear
how values are to be predicted and the result will contain <code>NA</code>
values for these out-of-sample data. Argument <code>na.fill</code> can be set to <code>TRUE</code>
to apply the original model's weighted mean of fixed effects for the
out-of-sample data to derive a prediction.
</p>
<p>If a plain data.frame is given in <code>newdata</code> for a fixed effects model, the
weighted mean is used for all fixed effects as <code>newdata</code> for prediction as a
plain data.frame cannot describe any relation to individuals/time periods
(<code>na.fill</code> is automatically set to <code>TRUE</code> and the function warns).
</p>
<p>See also <strong>Examples</strong>.
</p>


<h3>Value</h3>

<p>A numeric (or a pseries if <code>newdata</code> is a pdata.frame) carrying the
predicted values with length equal to the number of rows as the data
supplied in <code>newdata</code> and with names the row names of <code>newdata</code> or, if
<code>newdata = NULL</code>, the fitted values the original model given in <code>object</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(plm)
data("Grunfeld", package = "plm")

# fit a fixed effect model
fit.fe &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "within")

# generate 55 new observations of three firms used for prediction:
#  * firm 1 with years 1935:1964 (has out-of-sample years 1955:1964), 
#  * firm 2 with years 1935:1949 (all in sample),
#  * firm 11 with years 1935:1944 (firm 11 is out-of-sample)
set.seed(42L)

new.value2   &lt;- runif(55, min = min(Grunfeld$value),   max = max(Grunfeld$value))
new.capital2 &lt;- runif(55, min = min(Grunfeld$capital), max = max(Grunfeld$capital))

newdata &lt;- data.frame(firm = c(rep(1, 30), rep(2, 15), rep(11, 10)),
                      year = c(1935:(1935+29), 1935:(1935+14), 1935:(1935+9)),
                      value = new.value2, capital = new.capital2)
# make pdata.frame
newdata.p &lt;- pdata.frame(newdata, index = c("firm", "year"))

## predict from fixed effect model with new data as pdata.frame
predict(fit.fe, newdata = newdata.p)

## set na.fill = TRUE to have the weighted mean used to for fixed effects -&gt; no NA values
predict(fit.fe, newdata = newdata.p, na.fill = TRUE)

## predict with plain data.frame from fixed effect model: uses mean fixed effects 
## for prediction and, thus, yields different result with a warning
predict(fit.fe, newdata = newdata)

</code></pre>

<hr>
<h2 id='Produc'>US States Production</h2><span id='topic+Produc'></span>

<h3>Description</h3>

<p>A panel of 48 observations from 1970 to 1986
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>state</dt><dd><p>the state</p>
</dd>
<dt>year</dt><dd><p>the year</p>
</dd>
<dt>region</dt><dd><p>the region</p>
</dd>
<dt>pcap</dt><dd><p>public capital stock</p>
</dd>
<dt>hwy</dt><dd><p>highway and streets</p>
</dd>
<dt>water</dt><dd><p>water and sewer facilities</p>
</dd>
<dt>util</dt><dd><p>other public buildings and structures</p>
</dd>
<dt>pc</dt><dd><p>private capital stock</p>
</dd>
<dt>gsp</dt><dd><p>gross state product</p>
</dd>
<dt>emp</dt><dd><p>labor input measured by the employment in non&ndash;agricultural payrolls</p>
</dd>
<dt>unemp</dt><dd><p>state unemployment rate</p>
</dd> </dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 816
</p>
<p><em>observation</em> : regional
</p>
<p><em>country</em> : United States
</p>


<h3>Source</h3>

<p>Online complements to Baltagi (2001):
</p>
<p><a href="https://www.wiley.com/legacy/wileychi/baltagi/">https://www.wiley.com/legacy/wileychi/baltagi/</a>
</p>
<p>Online complements to Baltagi (2013):
</p>
<p><a href="https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452">https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452</a>
</p>


<h3>References</h3>

<p>Baltagi BH (2001).
<em>Econometric Analysis of Panel Data</em>, 3rd edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH, Pinnoi N (1995).
&ldquo;Public capital stock and state productivity growth: further evidence from an error components model.&rdquo;
<em>Empirical Economics</em>, <b>20</b>, 351-359.
</p>
<p>Munnell A (1990).
&ldquo;Why Has Productivity Growth Declined? Productivity and Public Investment.&rdquo;
<em>New England Economic Review</em>, 3&ndash;22.
</p>

<hr>
<h2 id='pseries'>panel series</h2><span id='topic+pseries'></span><span id='topic+print.pseries'></span><span id='topic+as.matrix.pseries'></span><span id='topic+plot.pseries'></span><span id='topic+summary.pseries'></span><span id='topic+plot.summary.pseries'></span><span id='topic+print.summary.pseries'></span><span id='topic+Sum'></span><span id='topic+Sum.default'></span><span id='topic+Sum.pseries'></span><span id='topic+Sum.matrix'></span><span id='topic+Between'></span><span id='topic+Between.default'></span><span id='topic+Between.pseries'></span><span id='topic+Between.matrix'></span><span id='topic+between'></span><span id='topic+between.default'></span><span id='topic+between.pseries'></span><span id='topic+between.matrix'></span><span id='topic+Within'></span><span id='topic+Within.default'></span><span id='topic+Within.pseries'></span><span id='topic+Within.matrix'></span>

<h3>Description</h3>

<p>A class for panel series for which several useful computations and
data transformations are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pseries'
print(x, ...)

## S3 method for class 'pseries'
as.matrix(x, idbyrow = TRUE, ...)

## S3 method for class 'pseries'
plot(
  x,
  plot = c("lattice", "superposed"),
  scale = FALSE,
  transparency = TRUE,
  col = "blue",
  lwd = 1,
  ...
)

## S3 method for class 'pseries'
summary(object, ...)

## S3 method for class 'summary.pseries'
plot(x, ...)

## S3 method for class 'summary.pseries'
print(x, ...)

Sum(x, ...)

## Default S3 method:
Sum(x, effect, ...)

## S3 method for class 'pseries'
Sum(x, effect = c("individual", "time", "group"), ...)

## S3 method for class 'matrix'
Sum(x, effect, ...)

Between(x, ...)

## Default S3 method:
Between(x, effect, ...)

## S3 method for class 'pseries'
Between(x, effect = c("individual", "time", "group"), ...)

## S3 method for class 'matrix'
Between(x, effect, ...)

between(x, ...)

## Default S3 method:
between(x, effect, ...)

## S3 method for class 'pseries'
between(x, effect = c("individual", "time", "group"), ...)

## S3 method for class 'matrix'
between(x, effect, ...)

Within(x, ...)

## Default S3 method:
Within(x, effect, ...)

## S3 method for class 'pseries'
Within(x, effect = c("individual", "time", "group", "twoways"), ...)

## S3 method for class 'matrix'
Within(x, effect, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pseries_+3A_x">x</code>, <code id="pseries_+3A_object">object</code></td>
<td>
<p>a <code>pseries</code> or a matrix; or a <code>summary.pseries</code> object,</p>
</td></tr>
<tr><td><code id="pseries_+3A_...">...</code></td>
<td>
<p>further arguments, e. g., <code>na.rm = TRUE</code> for
transformation functions like <code>beetween</code>, see <strong>Details</strong>
and <strong>Examples</strong>.</p>
</td></tr>
<tr><td><code id="pseries_+3A_idbyrow">idbyrow</code></td>
<td>
<p>if <code>TRUE</code> in the <code>as.matrix</code> method, the lines of
the matrix are the individuals,</p>
</td></tr>
<tr><td><code id="pseries_+3A_plot">plot</code>, <code id="pseries_+3A_scale">scale</code>, <code id="pseries_+3A_transparency">transparency</code>, <code id="pseries_+3A_col">col</code>, <code id="pseries_+3A_lwd">lwd</code></td>
<td>
<p>plot arguments,</p>
</td></tr>
<tr><td><code id="pseries_+3A_effect">effect</code></td>
<td>
<p>for the pseries methods: character string indicating the
<code>"individual"</code>, <code>"time"</code>, or <code>"group"</code> effect, for <code>Within</code>
<code>"twoways"</code> additionally; for non-pseries methods, <code>effect</code> is a factor
specifying the dimension (<code>"twoways"</code> is not possible),</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions <code>between</code>, <code>Between</code>, <code>Within</code>, and <code>Sum</code> perform specific
data transformations, i. e., the between, within, and sum transformation,
respectively.
</p>
<p><code>between</code> returns a vector/matrix containing the individual means (over
time) with the length of the vector equal to the number of
individuals (if <code>effect = "individual"</code> (default); if <code>effect = "time"</code>,
it returns the time means (over individuals)). <code>Between</code>
duplicates the values and returns a vector/matrix which length/number of rows
is the number of total observations. <code>Within</code> returns a vector/matrix
containing the values in deviation from the individual means
(if <code>effect = "individual"</code>, from time means if <code>effect = "time"</code>), the so
called demeaned data. <code>Sum</code> returns a vector/matrix with sum per individual
(over time) or the sum per time period (over individuals) with
<code>effect = "individual"</code> or <code>effect = "time"</code>, respectively, and has length/
number of rows of the total observations (like <code>Between</code>).
</p>
<p>For <code>between</code>, <code>Between</code>, <code>Within</code>, and <code>Sum</code> in presence of NA values it
can be useful to supply <code>na.rm = TRUE</code> as an additional argument to
keep as many observations as possible in the resulting transformation.
na.rm is passed on to the mean()/sum() function used by these transformations
(i.e., it does not remove NAs prior to any processing!), see also
<strong>Examples</strong>.
</p>


<h3>Value</h3>

<p>All these functions return an object of class <code>pseries</code> or a matrix,
except:<br /> <code>between</code>, which returns a numeric vector or a matrix;
<code>as.matrix</code>, which returns a matrix.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>See Also</h3>

<p><code><a href="#topic+is.pseries">is.pseries()</a></code> to check if an object is a pseries. For
more functions on class 'pseries' see <code><a href="#topic+lag">lag()</a></code>, <code><a href="#topic+lead">lead()</a></code>,
<code><a href="#topic+diff">diff()</a></code> for lagging values, leading values (negative lags) and
differencing.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# First, create a pdata.frame
data("EmplUK", package = "plm")
Em &lt;- pdata.frame(EmplUK)

# Then extract a series, which becomes additionally a pseries
z &lt;- Em$output
class(z)

# obtain the matrix representation
as.matrix(z)

# compute the between and within transformations
between(z)
Within(z)

# Between and Sum replicate the values for each time observation
Between(z)
Sum(z)

# between, Between, Within, and Sum transformations on other dimension
between(z, effect = "time")
Between(z, effect = "time")
Within(z, effect = "time")
Sum(z, effect = "time")

# NA treatment for between, Between, Within, and Sum
z2 &lt;- z
z2[length(z2)] &lt;- NA # set last value to NA
between(z2, na.rm = TRUE) # non-NA value for last individual
Between(z2, na.rm = TRUE) # only the NA observation is lost
Within(z2, na.rm = TRUE)  # only the NA observation is lost
Sum(z2, na.rm = TRUE)     # only the NA observation is lost

sum(is.na(Between(z2))) # 9 observations lost due to one NA value
sum(is.na(Between(z2, na.rm = TRUE))) # only the NA observation is lost
sum(is.na(Within(z2))) # 9 observations lost due to one NA value
sum(is.na(Within(z2, na.rm = TRUE))) # only the NA observation is lost
sum(is.na(Sum(z2))) # 9 observations lost due to one NA value
sum(is.na(Sum(z2, na.rm = TRUE))) # only the NA observation is lost

</code></pre>

<hr>
<h2 id='pseriesfy'>Turn all columns of a pdata.frame into class pseries.</h2><span id='topic+pseriesfy'></span>

<h3>Description</h3>

<p>This function takes a pdata.frame and turns all of its columns into
objects of class pseries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pseriesfy(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pseriesfy_+3A_x">x</code></td>
<td>
<p>an object of class <code>"pdata.frame"</code>,</p>
</td></tr>
<tr><td><code id="pseriesfy_+3A_...">...</code></td>
<td>
<p>further arguments (currently not used).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Background: Initially created pdata.frames have as columns the pure/basic
class (e.g., numeric, factor, character). When extracting a column from such
a pdata.frame, the extracted column is turned into a pseries.
</p>
<p>At times, it can be convenient to apply data transformation operations on
such a <code>pseriesfy</code>-ed pdata.frame, see Examples.
</p>


<h3>Value</h3>

<p>A pdata.frame like the input pdata.frame but with all columns
turned into pseries.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdata.frame">pdata.frame()</a></code>, <code><a href="base.html#topic+as.list">as.list()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library("plm")
data("Grunfeld", package = "plm")
pGrun &lt;- pdata.frame(Grunfeld[ , 1:4], drop.index = TRUE)
pGrun2 &lt;- pseriesfy(pGrun) # pseriesfy-ed pdata.frame

# compare classes of columns
lapply(pGrun,  class)
lapply(pGrun2, class)

# When using with()
with(pGrun,  lag(value)) # dispatches to base R's lag() 
with(pGrun2, lag(value)) # dispatches to plm's lag() respect. panel structure

# When lapply()-ing 
lapply(pGrun,  lag) # dispatches to base R's lag() 
lapply(pGrun2, lag) # dispatches to plm's lag() respect. panel structure

# as.list(., keep.attributes = TRUE) on a non-pseriesfy-ed
# pdata.frame is similar and dispatches to plm's lag
lapply(as.list(pGrun, keep.attributes = TRUE), lag) 

</code></pre>

<hr>
<h2 id='punbalancedness'>Measures for Unbalancedness of Panel Data</h2><span id='topic+punbalancedness'></span><span id='topic+punbalancedness.pdata.frame'></span><span id='topic+punbalancedness.data.frame'></span><span id='topic+punbalancedness.panelmodel'></span>

<h3>Description</h3>

<p>This function reports unbalancedness measures for panel data as
defined in Ahrens and Pincus (1981) and
Baltagi et al. (2001).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>punbalancedness(x, ...)

## S3 method for class 'pdata.frame'
punbalancedness(x, ...)

## S3 method for class 'data.frame'
punbalancedness(x, index = NULL, ...)

## S3 method for class 'panelmodel'
punbalancedness(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="punbalancedness_+3A_x">x</code></td>
<td>
<p>a <code>panelmodel</code>, a <code>data.frame</code>, or a <code>pdata.frame</code> object,</p>
</td></tr>
<tr><td><code id="punbalancedness_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="punbalancedness_+3A_index">index</code></td>
<td>
<p>only relevant for <code>data.frame</code> interface, for details
see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>punbalancedness</code> returns measures for the unbalancedness of a
panel data set.
</p>

<ul>
<li><p> For two-dimensional data:<br /> The two measures of
Ahrens and Pincus (1981) are calculated, called
&quot;gamma&quot; (<code class="reqn">\gamma</code>) and &quot;nu&quot; (<code class="reqn">\nu</code>).
</p>
</li></ul>

<p>If the panel data are balanced, both measures equal 1. The more
&quot;unbalanced&quot; the panel data, the lower the measures (but &gt; 0). The
upper and lower bounds as given in Ahrens and Pincus (1981)
are:<br />
<code class="reqn">0 &lt; \gamma, \nu \le 1</code>, and for <code class="reqn">\nu</code> more precisely
<code class="reqn">\frac{1}{n} &lt; \nu \le 1</code>, with <code class="reqn">n</code> being
the number of individuals (as in <code>pdim(x)$nT$n</code>).
</p>

<ul>
<li><p> For nested panel data (meaning including a grouping variable):<br />
The extension of the above measures by
Baltagi et al. (2001), p. 368, are
calculated:<br />
</p>

<ul>
<li><p> c1: measure of subgroup (individual) unbalancedness,
</p>
</li>
<li><p> c2: measure of time unbalancedness,
</p>
</li>
<li><p> c3: measure of group unbalancedness due to each group size.
</p>
</li></ul>

</li></ul>

<p>Values are 1 if the data are balanced and become smaller as the
data become more unbalanced.
</p>
<p>An application of the measure &quot;gamma&quot; is found in e. g.
Baltagi et al. (2001), pp. 488-491, and
Baltagi and Chang (1994), pp. 78&ndash;87, where it is
used to measure the unbalancedness of various unbalanced data sets
used for Monte Carlo simulation studies. Measures c1, c2, c3 are
used for similar purposes in
Baltagi et al. (2001).
</p>
<p>In the two-dimensional case, <code>punbalancedness</code> uses output of
<code><a href="#topic+pdim">pdim()</a></code> to calculate the two unbalancedness measures, so inputs to
<code>punbalancedness</code> can be whatever <code>pdim</code> works on. <code>pdim</code> returns
detailed information about the number of individuals and time
observations (see <code><a href="#topic+pdim">pdim()</a></code>).
</p>


<h3>Value</h3>

<p>A named numeric containing either two or three entries,
depending on the panel structure inputted:
</p>

<ul>
<li><p> For the two-dimensional panel structure, the entries are called
<code>gamma</code> and <code>nu</code>,
</p>
</li>
<li><p> For a nested panel structure, the entries are called <code>c1</code>, <code>c2</code>,
<code>c3</code>.
</p>
</li></ul>



<h3>Note</h3>

<p>Calling <code>punbalancedness</code> on an estimated <code>panelmodel</code> object
and on the corresponding <code style="white-space: pre;">&#8288;(p)data.frame&#8288;</code> used for this
estimation does not necessarily yield the same result (true
also for <code>pdim</code>). When called on an estimated <code>panelmodel</code>, the
number of observations (individual, time) actually used for
model estimation are taken into account. When called on a
<code style="white-space: pre;">&#8288;(p)data.frame&#8288;</code>, the rows in the <code style="white-space: pre;">&#8288;(p)data.frame&#8288;</code> are
considered, disregarding any <code>NA</code> values in the dependent or
independent variable(s) which would be dropped during model
estimation.
</p>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>References</h3>

<p>Ahrens H, Pincus R (1981).
&ldquo;On Two Measures of Unbalancedness in a One-Way Model and Their Relation to Efficiency.&rdquo;
<em>Biometrical Journal</em>, <b>23</b>(3), 227-235.
<a href="https://doi.org/10.1002/bimj.4710230302">doi:10.1002/bimj.4710230302</a>.
</p>
<p>Baltagi BH, Chang YJ (1994).
&ldquo;Incomplete panels: a comparative study of alternative estimators for the unbalanced one-way error component regression model.&rdquo;
<em>Journal of Econometrics</em>, <b>62</b>, 67-89.
</p>
<p>Baltagi BH, Song SH, Jung BC (2001).
&ldquo;The unbalanced nested error component regression model.&rdquo;
<em>Journal of Econometrics</em>, <b>101</b>, 357-381.
</p>
<p>Baltagi BH, Song SH, Jung BC (2002).
&ldquo;A comparative study of alternative estimators for the unbalanced two-way error component regression model.&rdquo;
<em>The Econometrics Journal</em>, <b>5</b>(2), 480&ndash;493.
ISSN 13684221, 1368423X.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nobs">nobs()</a></code>, <code><a href="#topic+pdim">pdim()</a></code>, <code><a href="#topic+pdata.frame">pdata.frame()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Grunfeld is a balanced panel, Hedonic is an unbalanced panel
data(list=c("Grunfeld", "Hedonic"), package="plm")

# Grunfeld has individual and time index in first two columns
punbalancedness(Grunfeld) # c(1,1) indicates balanced panel
pdim(Grunfeld)$balanced   # TRUE

# Hedonic has individual index in column "townid" (in last column)
punbalancedness(Hedonic, index="townid") # c(0.472, 0.519)
pdim(Hedonic, index="townid")$balanced   # FALSE

# punbalancedness on estimated models
plm_mod_pool &lt;- plm(inv ~ value + capital, data = Grunfeld)
punbalancedness(plm_mod_pool)

plm_mod_fe &lt;- plm(inv ~ value + capital, data = Grunfeld[1:99, ], model = "within")
punbalancedness(plm_mod_fe)

# replicate results for panel data design no. 1 in Ahrens/Pincus (1981), p. 234
ind_d1  &lt;- c(1,1,1,2,2,2,3,3,3,3,3,4,4,4,4,4,4,4,5,5,5,5,5,5,5)
time_d1 &lt;- c(1,2,3,1,2,3,1,2,3,4,5,1,2,3,4,5,6,7,1,2,3,4,5,6,7)
df_d1 &lt;- data.frame(individual = ind_d1, time = time_d1)
punbalancedness(df_d1) # c(0.868, 0.887)

# example for a nested panel structure with a third index variable
# specifying a group (states are grouped by region) and without grouping
data("Produc", package = "plm")
punbalancedness(Produc, index = c("state", "year", "region"))
punbalancedness(Produc, index = c("state", "year")) 

</code></pre>

<hr>
<h2 id='purtest'>Unit root tests for panel data</h2><span id='topic+purtest'></span><span id='topic+print.purtest'></span><span id='topic+summary.purtest'></span><span id='topic+print.summary.purtest'></span>

<h3>Description</h3>

<p><code>purtest</code> implements several testing procedures that have been proposed
to test unit root hypotheses with panel data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>purtest(
  object,
  data = NULL,
  index = NULL,
  test = c("levinlin", "ips", "madwu", "Pm", "invnormal", "logit", "hadri"),
  exo = c("none", "intercept", "trend"),
  lags = c("SIC", "AIC", "Hall"),
  pmax = 10,
  Hcons = TRUE,
  q = NULL,
  dfcor = FALSE,
  fixedT = TRUE,
  ips.stat = NULL,
  ...
)

## S3 method for class 'purtest'
print(x, ...)

## S3 method for class 'purtest'
summary(object, ...)

## S3 method for class 'summary.purtest'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="purtest_+3A_object">object</code>, <code id="purtest_+3A_x">x</code></td>
<td>
<p>Either a <code>"data.frame"</code> or a matrix containing the
time series (individuals as columns), a <code>"pseries"</code> object, a formula;
a <code>"purtest"</code> object for the print and summary methods,</p>
</td></tr>
<tr><td><code id="purtest_+3A_data">data</code></td>
<td>
<p>a <code>"data.frame"</code> or a <code>"pdata.frame"</code> object (required for
formula interface, see Details and Examples),</p>
</td></tr>
<tr><td><code id="purtest_+3A_index">index</code></td>
<td>
<p>the indexes,</p>
</td></tr>
<tr><td><code id="purtest_+3A_test">test</code></td>
<td>
<p>the test to be computed: one of <code>"levinlin"</code> for
Levin et al. (2002), <code>"ips"</code> for
Im et al. (2003), <code>"madwu"</code> for
Maddala and Wu (1999), <code>"Pm"</code> , <code>"invnormal"</code>,
or <code>"logit"</code> for various tests as in
Choi (2001), or <code>"hadri"</code> for
Hadri (2000), see Details,</p>
</td></tr>
<tr><td><code id="purtest_+3A_exo">exo</code></td>
<td>
<p>the exogenous variables to introduce in the augmented
Dickey&ndash;Fuller (ADF) regressions, one of: no exogenous
variables (<code>"none"</code>), individual intercepts (<code>"intercept"</code>), or
individual intercepts and trends (<code>"trend"</code>), but see Details,</p>
</td></tr>
<tr><td><code id="purtest_+3A_lags">lags</code></td>
<td>
<p>the number of lags to be used for the augmented
Dickey-Fuller regressions: either a single value integer (the number of
lags for all time series), a vector of integers (one for each
time series), or a character string for an automatic
computation of the number of lags, based on the AIC
(<code>"AIC"</code>), the SIC (<code>"SIC"</code>), or on the method by
Hall (1994) (<code>"Hall"</code>); argument is irrelevant
for <code>test = "hadri"</code>,</p>
</td></tr>
<tr><td><code id="purtest_+3A_pmax">pmax</code></td>
<td>
<p>maximum number of lags (irrelevant for <code>test = "hadri"</code>),</p>
</td></tr>
<tr><td><code id="purtest_+3A_hcons">Hcons</code></td>
<td>
<p>logical, only relevant for <code>test = "hadri"</code>,
indicating whether the heteroskedasticity-consistent test of
Hadri (2000) should be computed,</p>
</td></tr>
<tr><td><code id="purtest_+3A_q">q</code></td>
<td>
<p>the bandwidth for the estimation of the long-run variance
(only relevant for <code>test = "levinlin"</code>, the default (<code>q = NULL</code>)
gives the value as suggested by the authors as round(3.21 * T^(1/3))),</p>
</td></tr>
<tr><td><code id="purtest_+3A_dfcor">dfcor</code></td>
<td>
<p>logical, indicating whether the standard deviation of
the regressions is to be computed using a degrees-of-freedom
correction,</p>
</td></tr>
<tr><td><code id="purtest_+3A_fixedt">fixedT</code></td>
<td>
<p>logical, indicating whether the individual ADF
regressions are to be computed using the same number of
observations (irrelevant for <code>test = "hadri"</code>),</p>
</td></tr>
<tr><td><code id="purtest_+3A_ips.stat">ips.stat</code></td>
<td>
<p><code>NULL</code> or character of length 1 to request a specific
IPS statistic, one of <code>"Wtbar"</code> (also default if <code>ips.stat = NULL</code>),
<code>"Ztbar"</code>, <code>"tbar"</code>,</p>
</td></tr>
<tr><td><code id="purtest_+3A_...">...</code></td>
<td>
<p>further arguments (can set argument <code>p.approx</code> to be passed on
to non-exported function <code>padf</code> to either <code>"MacKinnon1994"</code> or <code>"MacKinnon1996"</code>
to force a specific method for p-value approximation, the latter only being
possible if package 'urca' is installed).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All these tests except <code>"hadri"</code> are based on the estimation of
augmented Dickey-Fuller (ADF) regressions for each time series. A
statistic is then computed using the t-statistics associated with
the lagged variable. The Hadri residual-based LM statistic is the
cross-sectional average of the individual KPSS statistics
Kwiatkowski et al. (1992), standardized by their
asymptotic mean and standard deviation.
</p>
<p>Several Fisher-type tests that combine p-values from tests based on
ADF regressions per individual are available:
</p>

<ul>
<li> <p><code>"madwu"</code> is the inverse chi-squared test
Maddala and Wu (1999), also called P test by
Choi (2001).
</p>
</li>
<li> <p><code>"Pm"</code> is the modified P test proposed by
Choi (2001) for large N,
</p>
</li>
<li> <p><code>"invnormal"</code> is the inverse normal test by Choi (2001), and
</p>
</li>
<li> <p><code>"logit"</code> is the logit test by Choi (2001).
</p>
</li></ul>

<p>The individual p-values for the Fisher-type tests are approximated
as described in MacKinnon (1996) if the package <a href="https://CRAN.R-project.org/package=urca"><span class="pkg">urca</span></a>
(Pfaff (2008)) is available, otherwise as described in
MacKinnon (1994).
</p>
<p>For the test statistic tbar of the test of Im/Pesaran/Shin (2003)
(<code>ips.stat = "tbar"</code>), no p-value is given but 1%, 5%, and 10% critical
values are interpolated from paper's tabulated values via inverse distance
weighting (printed and contained in the returned value's element
<code>statistic$ips.tbar.crit</code>).
</p>
<p>Hadri's test, the test of Levin/Lin/Chu, and the tbar statistic of
Im/Pesaran/Shin are not applicable to unbalanced panels; the tbar statistic
is not applicable when <code>lags &gt; 0</code> is given.
</p>
<p>The exogenous instruments of the tests (where applicable) can be specified
in several ways, depending on how the data is handed over to the function:
</p>

<ul>
<li><p> For the <code>formula</code>/<code>data</code> interface (if <code>data</code> is a <code>data.frame</code>,
an additional <code>index</code> argument should be specified); the formula
should be of the form: <code>y ~ 0</code>, <code>y ~ 1</code>, or <code>y ~ trend</code> for a test
with no exogenous variables, with an intercept, or with individual
intercepts and time trend, respectively. The <code>exo</code> argument is
ignored in this case.
</p>
</li>
<li><p> For the <code>data.frame</code>, <code>matrix</code>, and <code>pseries</code> interfaces: in
these cases, the exogenous variables are specified using the <code>exo</code>
argument.
</p>
</li></ul>

<p>With the associated <code>summary</code> and <code>print</code> methods, additional
information can be extracted/displayed (see also Value).
</p>


<h3>Value</h3>

<p>For purtest: An object of class <code>"purtest"</code>: a list with the elements
named:
</p>

<ul>
<li> <p><code>"statistic"</code> (a <code>"htest"</code> object),
</p>
</li>
<li> <p><code>"call"</code>,
</p>
</li>
<li> <p><code>"args"</code>,
</p>
</li>
<li> <p><code>"idres"</code> (containing results from the individual regressions),
</p>
</li>
<li> <p><code>"adjval"</code> (containing the simulated means and variances needed to compute
the statistic, for <code>test = "levinlin"</code> and <code>"ips"</code>, otherwise <code>NULL</code>),
</p>
</li>
<li> <p><code>"sigma2"</code> (short-run and long-run variance for <code>test = "levinlin"</code>,
otherwise <code>NULL</code>).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Yves Croissant and for &quot;Pm&quot;, &quot;invnormal&quot;, and &quot;logit&quot; Kevin Tappe
</p>


<h3>References</h3>

<p>Choi I (2001).
&ldquo;Unit root tests for panel data.&rdquo;
<em>Journal of International Money and Finance</em>, <b>20</b>(2), 249 - 272.
ISSN 0261-5606, <a href="https://www.sciencedirect.com/science/article/pii/S0261560600000486">https://www.sciencedirect.com/science/article/pii/S0261560600000486</a>.<br /><br /> Hadri K (2000).
&ldquo;Testing for stationarity in heterogeneous panel data.&rdquo;
<em>The Econometrics Journal</em>, <b>3</b>(2), 148&ndash;161.
ISSN 13684221, 1368423X.<br /><br /> Hall A (1994).
&ldquo;Testing for a unit root in time series with pretest data-based model selection.&rdquo;
<em>Journal of Business &amp; Economic Statistics</em>, <b>12</b>(4), 461&ndash;470.<br /><br /> Im KS, Pesaran MH, Shin Y (2003).
&ldquo;Testing for unit roots in heterogenous panels.&rdquo;
<em>Journal of Econometrics</em>, <b>115(1)</b>, 53-74.<br /><br /> Kwiatkowski D, Phillips PC, Schmidt P, Shin Y (1992).
&ldquo;Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root?&rdquo;
<em>Journal of Econometrics</em>, <b>54</b>(1), 159 - 178.
ISSN 0304-4076, <a href="https://www.sciencedirect.com/science/article/pii/030440769290104Y">https://www.sciencedirect.com/science/article/pii/030440769290104Y</a>.<br /><br /> Levin A, Lin CF, Chu CSJ (2002).
&ldquo;Unit root tests in panel data : asymptotic and finite-sample properties.&rdquo;
<em>Journal of Econometrics</em>, <b>108</b>, 1-24.<br /><br /> MacKinnon JG (1994).
&ldquo;Approximate Asymptotic Distribution Functions for Unit-Root and Cointegration Tests.&rdquo;
<em>Journal of Business &amp; Economic Statistics</em>, <b>12</b>(2), 167&ndash;176.
ISSN 07350015.<br /><br /> MacKinnon JG (1996).
&ldquo;Numerical Distribution Functions for Unit Root and Cointegration Tests.&rdquo;
<em>Journal of Applied Econometrics</em>, <b>11</b>(6), 601&ndash;618.
ISSN 08837252.<br /><br /> Maddala GS, Wu S (1999).
&ldquo;A comparative study of unit root tests with panel data and a new simple test.&rdquo;
<em>Oxford Bulletin of Economics and Statistics</em>, <b>61</b>, 631-52.<br /><br /> Pfaff B (2008).
<em>Analysis of Integrated and Cointegrated Time Series with R</em>, Second edition.
Springer, New York.
ISBN 0-387-27960-1, <a href="https://CRAN.r-project.org/package=urca">https://CRAN.r-project.org/package=urca</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cipstest">cipstest()</a></code>, <code><a href="#topic+phansitest">phansitest()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
y &lt;- data.frame(split(Grunfeld$inv, Grunfeld$firm)) # individuals in columns

purtest(y, pmax = 4, exo = "intercept", test = "madwu")

## same via pseries interface
pGrunfeld &lt;- pdata.frame(Grunfeld, index = c("firm", "year"))
purtest(pGrunfeld$inv, pmax = 4, exo = "intercept", test = "madwu")

## same via formula interface
purtest(inv ~ 1, data = Grunfeld, index = c("firm", "year"), pmax = 4, test = "madwu")

</code></pre>

<hr>
<h2 id='pvar'>Check for Cross-Sectional and Time Variation</h2><span id='topic+pvar'></span><span id='topic+pvar.matrix'></span><span id='topic+pvar.data.frame'></span><span id='topic+pvar.pdata.frame'></span><span id='topic+pvar.pseries'></span><span id='topic+print.pvar'></span>

<h3>Description</h3>

<p>This function checks for each variable of a panel if it varies
cross-sectionally and over time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvar(x, ...)

## S3 method for class 'matrix'
pvar(x, index = NULL, ...)

## S3 method for class 'data.frame'
pvar(x, index = NULL, ...)

## S3 method for class 'pdata.frame'
pvar(x, ...)

## S3 method for class 'pseries'
pvar(x, ...)

## S3 method for class 'pvar'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvar_+3A_x">x</code></td>
<td>
<p>a <code style="white-space: pre;">&#8288;(p)data.frame&#8288;</code> or a <code>matrix</code>,</p>
</td></tr>
<tr><td><code id="pvar_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pvar_+3A_index">index</code></td>
<td>
<p>see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For (p)data.frame and matrix interface: All-<code>NA</code> columns are removed
prior to calculation of variation due to coercing to pdata.frame
first.
</p>


<h3>Value</h3>

<p>An object of class <code>pvar</code> containing the following
elements:
</p>
<table>
<tr><td><code>id.variation</code></td>
<td>
<p>a logical vector with <code>TRUE</code> values if the
variable has individual variation, <code>FALSE</code> if not,</p>
</td></tr>
<tr><td><code>time.variation</code></td>
<td>
<p>a logical vector with <code>TRUE</code> values if the
variable has time variation, <code>FALSE</code> if not,</p>
</td></tr>
<tr><td><code>id.variation_anyNA</code></td>
<td>
<p>a logical vector with <code>TRUE</code> values if
the variable has at least one individual-time combination with all
<code>NA</code> values in the individual dimension for at least one time period,
<code>FALSE</code> if not,</p>
</td></tr>
<tr><td><code>time.variation_anyNA</code></td>
<td>
<p>a logical vector with <code>TRUE</code> values if
the variable has at least one individual-time combination with all
<code>NA</code> values in the time dimension for at least one individual,
<code>FALSE</code> if not.</p>
</td></tr>
</table>


<h3>Note</h3>

<p><code>pvar</code> can be time consuming for &ldquo;big&rdquo; panels. As a fast alternative
<code><a href="collapse.html#topic+varying">collapse::varying()</a></code> from package <a href="https://CRAN.R-project.org/package=collapse"><span class="pkg">collapse</span></a> could be used.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdim">pdim()</a></code> to check the dimensions of a 'pdata.frame' (and
other objects),
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# Gasoline contains two variables which are individual and time
# indexes and are the first two variables
data("Gasoline", package = "plm")
pvar(Gasoline)

# Hedonic is an unbalanced panel, townid is the individual index;
# the drop.index argument is passed to pdata.frame
data("Hedonic", package = "plm")
pvar(Hedonic, "townid", drop.index = TRUE)

# same using pdata.frame
Hed &lt;- pdata.frame(Hedonic, "townid", drop.index = TRUE)
pvar(Hed)

# Gasoline with pvar's matrix interface
Gasoline_mat &lt;- as.matrix(Gasoline)
pvar(Gasoline_mat)
pvar(Gasoline_mat, index=c("country", "year"))

</code></pre>

<hr>
<h2 id='pvcm'>Variable Coefficients Models for Panel Data</h2><span id='topic+pvcm'></span><span id='topic+summary.pvcm'></span><span id='topic+print.summary.pvcm'></span>

<h3>Description</h3>

<p>Estimators for random and fixed effects models with variable coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvcm(
  formula,
  data,
  subset,
  na.action,
  effect = c("individual", "time"),
  model = c("within", "random"),
  index = NULL,
  ...
)

## S3 method for class 'pvcm'
summary(object, ...)

## S3 method for class 'summary.pvcm'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvcm_+3A_formula">formula</code></td>
<td>
<p>a symbolic description for the model to be estimated,</p>
</td></tr>
<tr><td><code id="pvcm_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pvcm_+3A_subset">subset</code></td>
<td>
<p>see <code>lm</code>,</p>
</td></tr>
<tr><td><code id="pvcm_+3A_na.action">na.action</code></td>
<td>
<p>see <code>lm</code>,</p>
</td></tr>
<tr><td><code id="pvcm_+3A_effect">effect</code></td>
<td>
<p>the effects introduced in the model: one of
<code>"individual"</code>, <code>"time"</code>,</p>
</td></tr>
<tr><td><code id="pvcm_+3A_model">model</code></td>
<td>
<p>one of <code>"within"</code>, <code>"random"</code>,</p>
</td></tr>
<tr><td><code id="pvcm_+3A_index">index</code></td>
<td>
<p>the indexes, see <code><a href="#topic+pdata.frame">pdata.frame()</a></code>,</p>
</td></tr>
<tr><td><code id="pvcm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="pvcm_+3A_object">object</code>, <code id="pvcm_+3A_x">x</code></td>
<td>
<p>an object of class <code>"pvcm"</code>,</p>
</td></tr>
<tr><td><code id="pvcm_+3A_digits">digits</code></td>
<td>
<p>digits,</p>
</td></tr>
<tr><td><code id="pvcm_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the print output,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pvcm</code> estimates variable coefficients models. Individual or time
effects are introduced, respectively, if <code>effect = "individual"</code>
(default) or <code>effect = "time"</code>.
</p>
<p>Coefficients are assumed to be fixed if <code>model = "within"</code>, i.e., separate
pooled OLS models are estimated per individual (<code>effect = "individual"</code>)
or per time period (<code>effect = "time"</code>). Coefficients are assumed to be
random if <code>model = "random"</code> and the model by
Swamy (1970) is estimated. It is a generalized least
squares model which uses the results of the previous model.
</p>


<h3>Value</h3>

<p>An object of class <code>c("pvcm", "panelmodel")</code>, which has the
following elements:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the vector (or the data frame for fixed
effects) of coefficients,</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the vector of
residuals,</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the vector of fitted values,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>the covariance matrix of the coefficients (a list for
fixed effects model (<code>model = "within"</code>)),</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>degrees of freedom of the residuals,</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p>a data frame containing the variables used for the
estimation,</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call,</p>
</td></tr> <tr><td><code>Delta</code></td>
<td>
<p>the estimation of the
covariance matrix of the coefficients (random effect models only),</p>
</td></tr>
<tr><td><code>std.error</code></td>
<td>
<p>a data frame containing standard errors for all
coefficients for each individual (within models only).</p>
</td></tr>
</table>
<p><code>pvcm</code> objects have <code>print</code>, <code>summary</code> and <code>print.summary</code> methods.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>Swamy PAVB (1970).
&ldquo;Efficient Inference in a Random Coefficient Regression Model.&rdquo;
<em>Econometrica</em>, <b>38</b>, 311&ndash;323.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
zw &lt;- pvcm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc, model = "within")
zr &lt;- pvcm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc, model = "random")

## replicate Greene (2012), p. 419, table 11.14
summary(pvcm(log(gsp) ~ log(pc) + log(hwy) + log(water) + log(util) + log(emp) + unemp, 
             data = Produc, model = "random"))
             
## Not run: 
# replicate Swamy (1970), p. 166, table 5.2
data(Grunfeld, package = "AER") # 11 firm Grunfeld data needed from package AER
gw &lt;- pvcm(invest ~ value + capital, data = Grunfeld, index = c("firm", "year"))

## End(Not run)


</code></pre>

<hr>
<h2 id='pwaldtest'>Wald-style Chi-square Test and F Test</h2><span id='topic+pwaldtest'></span><span id='topic+pwaldtest.plm'></span><span id='topic+pwaldtest.pvcm'></span><span id='topic+pwaldtest.pgmm'></span>

<h3>Description</h3>

<p>Wald-style Chi-square test and F test of slope coefficients being
zero jointly, including robust versions of the tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwaldtest(x, ...)

## S3 method for class 'plm'
pwaldtest(
  x,
  test = c("Chisq", "F"),
  vcov = NULL,
  df2adj = (test == "F" &amp;&amp; !is.null(vcov) &amp;&amp; missing(.df2)),
  .df1,
  .df2,
  ...
)

## S3 method for class 'pvcm'
pwaldtest(x, ...)

## S3 method for class 'pgmm'
pwaldtest(x, param = c("coef", "time", "all"), vcov = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwaldtest_+3A_x">x</code></td>
<td>
<p>an estimated model of which the coefficients should be
tested (usually of class <code>"plm"</code>/<code>"pvcm"</code>/<code>"pgmm"</code>)',</p>
</td></tr>
<tr><td><code id="pwaldtest_+3A_...">...</code></td>
<td>
<p>further arguments (currently none).</p>
</td></tr>
<tr><td><code id="pwaldtest_+3A_test">test</code></td>
<td>
<p>a character, indicating the test to be performed, may
be either <code>"Chisq"</code> or <code>"F"</code> for the Wald-style
Chi-square test or F test, respectively,</p>
</td></tr>
<tr><td><code id="pwaldtest_+3A_vcov">vcov</code></td>
<td>
<p><code>NULL</code> by default; a <code>matrix</code> giving a
variance&ndash;covariance matrix or a function which computes such;
if supplied (non <code>NULL</code>), the test is carried out using
the variance&ndash;covariance matrix indicated resulting in a robust
test,</p>
</td></tr>
<tr><td><code id="pwaldtest_+3A_df2adj">df2adj</code></td>
<td>
<p>logical, only relevant for <code>test = "F"</code>,
indicating whether the adjustment for clustered standard errors
for the second degrees of freedom parameter should be performed
(see <strong>Details</strong>, also for further requirements regarding
the variance&ndash;covariance matrix in <code>vcov</code> for the
adjustment to be performed),</p>
</td></tr>
<tr><td><code id="pwaldtest_+3A_.df1">.df1</code></td>
<td>
<p>a numeric, used if one wants to overwrite the first
degrees of freedom parameter in the performed test (usually not
used),</p>
</td></tr>
<tr><td><code id="pwaldtest_+3A_.df2">.df2</code></td>
<td>
<p>a numeric, used if one wants to overwrite the second
degrees of freedom parameter for the F test (usually not used),</p>
</td></tr>
<tr><td><code id="pwaldtest_+3A_param">param</code></td>
<td>
<p>(for pgmm method only): select the parameters to be tested:
<code>"coef"</code>, <code>"time"</code>, or '&quot;all&quot;&ldquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>pwaldtest</code> can be used stand&ndash;alone with a plm object, a pvcm object,
and a pgmm object (for pvcm objects only the 'random' type is valid and no
further arguments are processed; for pgmm objects only arguments <code>param</code>
and <code>vcov</code> are valid). It is also used in
<code><a href="#topic+summary.plm">summary.plm()</a></code> to produce the F statistic and the Chi-square
statistic for the joint test of coefficients and in <code><a href="#topic+summary.pgmm">summary.pgmm()</a></code>.
</p>
<p><code>pwaldtest</code> performs the test if the slope coefficients of a panel
regression are jointly zero. It does not perform general purpose
Wald-style tests (for those, see <code><a href="lmtest.html#topic+waldtest">lmtest::waldtest()</a></code> (from package
<a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a>) or <code><a href="car.html#topic+linearHypothesis">car::linearHypothesis()</a></code> (from package
<a href="https://CRAN.R-project.org/package=car"><span class="pkg">car</span></a>)).
</p>
<p>If a user specified variance-covariance matrix/function is given in
argument <code>vcov</code>, the robust version of the tests are carried out.
In that case, if the F test is requested (<code>test = "F"</code>) and no
overwriting of the second degrees of freedom parameter is given (by
supplying argument (<code>.df2</code>)), the adjustment of the second degrees
of freedom parameter is performed by default. The second degrees of
freedom parameter is adjusted to be the number of unique elements
of the cluster variable - 1, e. g., the number of individuals minus 1.
For the degrees of freedom adjustment of the F test in general,
see e. g. Cameron and Miller (2015), section VII;
(Andre et al. 2013), pp. 126, footnote 4.
</p>
<p>The degrees of freedom adjustment requires the vcov object supplied
or created by a supplied function to carry an attribute called
&quot;cluster&quot; with a known clustering described as a character (for now
this could be either <code>"group"</code> or <code>"time"</code>). The vcovXX functions
of the package <span class="pkg">plm</span> provide such an attribute for their
returned variance&ndash;covariance matrices. No adjustment is done for
unknown descriptions given in the attribute &quot;cluster&quot; or when the
attribute &quot;cluster&quot; is not present. Robust vcov objects/functions
from package <a href="https://CRAN.R-project.org/package=clubSandwich"><span class="pkg">clubSandwich</span></a> work as inputs to <code>pwaldtest</code>'s
F test because a they are translated internally to match the needs
described above.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>, except for pvcm's within model for which
a data.frame with results of the Wald chi-square tests and F tests per
regression is returned.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant (initial implementation) and Kevin Tappe
(extensions: vcov argument and F test's df2 adjustment)
</p>


<h3>References</h3>

<p>Wooldridge JM (2010).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>, 2nd edition.
MIT Press.
</p>
<p>Andre H, Golsch K, Schmidt-Catran A (2013).
<em>Applied Panel Data Analysis for Economic and Social Surveys</em>.
Springer.
<a href="https://doi.org/10.1007/978-3-642-32914-2">doi:10.1007/978-3-642-32914-2</a>.
</p>
<p>Cameron AC, Miller DL (2015).
&ldquo;A Practitioner's Guide to Cluster-Robust Inference.&rdquo;
<em>Journal of Human Resources</em>, <b>50</b>(2), 317-372.
<a href="https://ideas.repec.org/a/uwp/jhriss/v50y2015i2p317-372.html">https://ideas.repec.org/a/uwp/jhriss/v50y2015i2p317-372.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vcovHC">vcovHC()</a></code> for an example of the vcovXX functions, a robust
estimation for the variance&ndash;covariance matrix; <code><a href="#topic+summary.plm">summary.plm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
mod_fe &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "within")
mod_re &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "random")
pwaldtest(mod_fe, test = "F")
pwaldtest(mod_re, test = "Chisq")

# with robust vcov (matrix, function)
pwaldtest(mod_fe, vcov = vcovHC(mod_fe))
pwaldtest(mod_fe, vcov = function(x) vcovHC(x, type = "HC3"))

pwaldtest(mod_fe, vcov = vcovHC(mod_fe), df2adj = FALSE) # w/o df2 adjustment

# example without attribute "cluster" in the vcov
vcov_mat &lt;- vcovHC(mod_fe)
attr(vcov_mat, "cluster") &lt;- NULL  # remove attribute
pwaldtest(mod_fe, vcov = vcov_mat) # no df2 adjustment performed


</code></pre>

<hr>
<h2 id='pwartest'>Wooldridge Test for AR(1) Errors in FE Panel Models</h2><span id='topic+pwartest'></span><span id='topic+pwartest.formula'></span><span id='topic+pwartest.panelmodel'></span>

<h3>Description</h3>

<p>Test of serial correlation for (the idiosyncratic component of) the errors
in fixed&ndash;effects panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwartest(x, ...)

## S3 method for class 'formula'
pwartest(x, data, ...)

## S3 method for class 'panelmodel'
pwartest(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwartest_+3A_x">x</code></td>
<td>
<p>an object of class <code>formula</code> or of class <code>panelmodel</code>,</p>
</td></tr>
<tr><td><code id="pwartest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on to <code>vcovHC</code> (see
Details and Examples).</p>
</td></tr>
<tr><td><code id="pwartest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As Wooldridge (2010), Sec. 10.5.4 observes, under
the null of no serial correlation in the errors, the residuals of a
FE model must be negatively serially correlated, with
<code class="reqn">cor(\hat{u}_{it}, \hat{u}_{is})=-1/(T-1)</code> for each
<code class="reqn">t,s</code>. He suggests basing a test for this null hypothesis on a
pooled regression of FE residuals on their first lag:
<code class="reqn">\hat{u}_{i,t} = \alpha + \delta \hat{u}_{i,t-1} +
\eta_{i,t}</code>. Rejecting the restriction <code class="reqn">\delta = -1/(T-1)</code>
makes us conclude against the original null of no serial
correlation.
</p>
<p><code>pwartest</code> estimates the <code>within</code> model and retrieves residuals,
then estimates an AR(1) <code>pooling</code> model on them. The test statistic
is obtained by applying a F test to the latter model to test the
above restriction on <code class="reqn">\delta</code>, setting the covariance matrix to
<code>vcovHC</code> with the option <code>method="arellano"</code> to control for serial
correlation.
</p>
<p>Unlike the <code><a href="#topic+pbgtest">pbgtest()</a></code> and <code><a href="#topic+pdwtest">pdwtest()</a></code>, this test does
not rely on large&ndash;T asymptotics and has therefore good properties in
&ldquo;short&rdquo; panels.  Furthermore, it is robust to general heteroskedasticity.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Wooldridge JM (2002).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>.
MIT Press.
</p>
<p>Wooldridge JM (2010).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>, 2nd edition.
MIT Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pwfdtest">pwfdtest()</a></code>, <code><a href="#topic+pdwtest">pdwtest()</a></code>, <code><a href="#topic+pbgtest">pbgtest()</a></code>, <code><a href="#topic+pbltest">pbltest()</a></code>,
<code><a href="#topic+pbsytest">pbsytest()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("EmplUK", package = "plm")
pwartest(log(emp) ~ log(wage) + log(capital), data = EmplUK)

# pass argument 'type' to vcovHC used in test
pwartest(log(emp) ~ log(wage) + log(capital), data = EmplUK, type = "HC3")


</code></pre>

<hr>
<h2 id='pwfdtest'>Wooldridge first&ndash;difference&ndash;based test for AR(1) errors in levels
or first&ndash;differenced panel models</h2><span id='topic+pwfdtest'></span><span id='topic+pwfdtest.formula'></span><span id='topic+pwfdtest.panelmodel'></span>

<h3>Description</h3>

<p>First&ndash;differencing&ndash;based test of serial correlation for (the idiosyncratic
component of) the errors in either levels or first&ndash;differenced panel
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwfdtest(x, ...)

## S3 method for class 'formula'
pwfdtest(x, data, ..., h0 = c("fd", "fe"))

## S3 method for class 'panelmodel'
pwfdtest(x, ..., h0 = c("fd", "fe"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwfdtest_+3A_x">x</code></td>
<td>
<p>an object of class <code>formula</code> or a <code>"fd"</code>-model (plm
object),</p>
</td></tr>
<tr><td><code id="pwfdtest_+3A_...">...</code></td>
<td>
<p>further arguments to be passed on to <code>vcovHC</code> (see Details
and Examples).</p>
</td></tr>
<tr><td><code id="pwfdtest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pwfdtest_+3A_h0">h0</code></td>
<td>
<p>the null hypothesis: one of <code>"fd"</code>, <code>"fe"</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As Wooldridge (2010), Sec. 10.6.3 observes, if the
idiosyncratic errors in the model in levels are uncorrelated (which
we label hypothesis <code>"fe"</code>), then the errors of the model in first
differences (FD) must be serially correlated with
<code class="reqn">cor(\hat{e}_{it}, \hat{e}_{is}) = -0.5</code> for each <code class="reqn">t,s</code>. If
on the contrary the levels model's errors are a random walk, then
there must be no serial correlation in the FD errors (hypothesis
<code>"fd"</code>). Both the fixed effects (FE) and the first&ndash;differenced
(FD) estimators remain consistent under either assumption, but the
relative efficiency changes: FE is more efficient under <code>"fe"</code>, FD
under <code>"fd"</code>.
</p>
<p>Wooldridge (ibid.) suggests basing a test for either hypothesis on
a pooled regression of FD residuals on their first lag:
<code class="reqn">\hat{e}_{i,t}=\alpha + \rho \hat{e}_{i,t-1} +
\eta_{i,t}</code>. Rejecting the restriction <code class="reqn">\rho = -0.5</code> makes us
conclude against the null of no serial correlation in errors of the
levels equation (<code>"fe"</code>). The null hypothesis of no serial
correlation in differenced errors (<code>"fd"</code>) is tested in a similar
way, but based on the zero restriction on <code class="reqn">\rho</code> (<code class="reqn">\rho =
0</code>). Rejecting <code>"fe"</code> favours the use of the first&ndash;differences
estimator and the contrary, although it is possible that both be
rejected.
</p>
<p><code>pwfdtest</code> estimates the <code>fd</code> model (or takes an <code>fd</code> model as
input for the panelmodel interface) and retrieves its residuals,
then estimates an AR(1) <code>pooling</code> model on them. The test statistic
is obtained by applying a F test to the latter model to test the
relevant restriction on <code class="reqn">\rho</code>, setting the covariance matrix
to <code>vcovHC</code> with the option <code>method="arellano"</code> to control for
serial correlation.
</p>
<p>Unlike the <code>pbgtest</code> and <code>pdwtest</code>, this test does not rely on
large&ndash;T asymptotics and has therefore good properties in &rdquo;short&rdquo;
panels.  Furthermore, it is robust to general
heteroskedasticity. The <code>"fe"</code> version can be used to test for
error autocorrelation regardless of whether the maintained
specification has fixed or random effects
(see Drukker 2003).
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Drukker DM (2003).
&ldquo;Testing for Serial Correlation in Linear Panel&ndash;Data Models.&rdquo;
<em>The Stata Journal</em>, <b>3</b>(2), 168-177.
</p>
<p>Wooldridge JM (2002).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>.
MIT Press.
Sec. 10.6.3, pp. 282&ndash;283.
</p>
<p>Wooldridge JM (2010).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>, 2nd edition.
MIT Press.
Sec. 10.6.3, pp. 319&ndash;320
</p>


<h3>See Also</h3>

<p><code>pdwtest</code>, <code>pbgtest</code>, <code>pwartest</code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("EmplUK" , package = "plm")
pwfdtest(log(emp) ~ log(wage) + log(capital), data = EmplUK)
pwfdtest(log(emp) ~ log(wage) + log(capital), data = EmplUK, h0 = "fe")

# pass argument 'type' to vcovHC used in test
pwfdtest(log(emp) ~ log(wage) + log(capital), data = EmplUK, type = "HC3", h0 = "fe")


# same with panelmodel interface
mod &lt;- plm(log(emp) ~ log(wage) + log(capital), data = EmplUK, model = "fd")
pwfdtest(mod)
pwfdtest(mod, h0 = "fe")
pwfdtest(mod, type = "HC3", h0 = "fe")


</code></pre>

<hr>
<h2 id='pwtest'>Wooldridge's Test for Unobserved Effects in Panel Models</h2><span id='topic+pwtest'></span><span id='topic+pwtest.formula'></span><span id='topic+pwtest.panelmodel'></span>

<h3>Description</h3>

<p>Semi-parametric test for the presence of (individual or time) unobserved
effects in panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwtest(x, ...)

## S3 method for class 'formula'
pwtest(x, data, effect = c("individual", "time"), ...)

## S3 method for class 'panelmodel'
pwtest(x, effect = c("individual", "time"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwtest_+3A_x">x</code></td>
<td>
<p>an object of class <code>"formula"</code>, or an estimated model of class
<code>panelmodel</code>,</p>
</td></tr>
<tr><td><code id="pwtest_+3A_...">...</code></td>
<td>
<p>further arguments passed to <code>plm</code>.</p>
</td></tr>
<tr><td><code id="pwtest_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code>,</p>
</td></tr>
<tr><td><code id="pwtest_+3A_effect">effect</code></td>
<td>
<p>the effect to be tested for, one of <code>"individual"</code>
(default) or <code>"time"</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This semi-parametric test checks the null hypothesis of zero
correlation between errors of the same group. Therefore, it has
power both against individual effects and, more generally, any kind
of serial correlation.
</p>
<p>The test relies on large-N asymptotics. It is valid under error
heteroskedasticity and departures from normality.
</p>
<p>The above is valid if <code>effect="individual"</code>, which is the most
likely usage. If <code>effect="time"</code>, symmetrically, the test relies on
large-T asymptotics and has power against time effects and, more
generally, against cross-sectional correlation.
</p>
<p>If the panelmodel interface is used, the inputted model must be a pooling
model.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Wooldridge JM (2002).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>.
MIT Press.
</p>
<p>Wooldridge JM (2010).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>, 2nd edition.
MIT Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pbltest">pbltest()</a></code>, <code><a href="#topic+pbgtest">pbgtest()</a></code>,
<code><a href="#topic+pdwtest">pdwtest()</a></code>, <code><a href="#topic+pbsytest">pbsytest()</a></code>, <code><a href="#topic+pwartest">pwartest()</a></code>,
<code><a href="#topic+pwfdtest">pwfdtest()</a></code> for tests for serial correlation in panel models.
<code><a href="#topic+plmtest">plmtest()</a></code> for tests for random effects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
## formula interface
pwtest(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc)
pwtest(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc, effect = "time")

## panelmodel interface
# first, estimate a pooling model, than compute test statistics
form &lt;- formula(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp)
pool_prodc &lt;- plm(form, data = Produc, model = "pooling")
pwtest(pool_prodc) # == effect="individual"
pwtest(pool_prodc, effect="time")

</code></pre>

<hr>
<h2 id='r.squared'>R squared and adjusted R squared for panel models</h2><span id='topic+r.squared'></span>

<h3>Description</h3>

<p>This function computes R squared or adjusted R squared for plm objects. It
allows to define on which transformation of the data the (adjusted) R
squared is to be computed and which method for calculation is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.squared(object, model = NULL, type = c("cor", "rss", "ess"), dfcor = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r.squared_+3A_object">object</code></td>
<td>
<p>an object of class <code>"plm"</code>,</p>
</td></tr>
<tr><td><code id="r.squared_+3A_model">model</code></td>
<td>
<p>on which transformation of the data the R-squared is to be
computed. If <code>NULL</code>, the transformation used to estimate the model is
also used for the computation of R squared,</p>
</td></tr>
<tr><td><code id="r.squared_+3A_type">type</code></td>
<td>
<p>indicates method which is used to compute R squared. One of<br />
<code>"rss"</code> (residual sum of squares),<br /> <code>"ess"</code> (explained sum of
squares), or<br /> <code>"cor"</code> (coefficient of correlation between the fitted
values and the response),</p>
</td></tr>
<tr><td><code id="r.squared_+3A_dfcor">dfcor</code></td>
<td>
<p>if <code>TRUE</code>, the adjusted R squared is computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numerical value. The R squared or adjusted R squared of the model
estimated on the transformed data, e. g., for the within model the so called
&quot;within R squared&quot;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plm">plm()</a></code> for estimation of various models;
<code><a href="#topic+summary.plm">summary.plm()</a></code> which makes use of <code>r.squared</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
p &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "pooling")
r.squared(p)
r.squared(p, dfcor = TRUE)

</code></pre>

<hr>
<h2 id='ranef.plm'>Extract the Random Effects</h2><span id='topic+ranef.plm'></span><span id='topic+ranef'></span>

<h3>Description</h3>

<p>Function to calculate the random effects from a <code>plm</code> object
(random effects model).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plm'
ranef(object, effect = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ranef.plm_+3A_object">object</code></td>
<td>
<p>an object of class <code>"plm"</code>, needs to be a fitted
random effects model,</p>
</td></tr>
<tr><td><code id="ranef.plm_+3A_effect">effect</code></td>
<td>
<p><code>NULL</code>, <code>"individual"</code>, or <code>"time"</code>, the effects to
be extracted, see <strong>Details</strong>,</p>
</td></tr>
<tr><td><code id="ranef.plm_+3A_...">...</code></td>
<td>
<p>further arguments (currently not used).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>ranef</code> calculates the random effects of a fitted random
effects model. For one-way models, the effects of the estimated
model are extracted (either individual or time effects). For
two-way models, extracting the individual effects is the default
(both, argument <code>effect = NULL</code> and <code>effect = "individual"</code> will
give individual effects). Time effects can be extracted by setting
<code>effect = "time"</code>.
</p>
<p>Not all random effect model types are supported (yet?).
</p>


<h3>Value</h3>

<p>A named numeric with the random effects per dimension
(individual or time).
</p>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fixef">fixef()</a></code> to extract the fixed effects from a fixed
effects model (within model).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Grunfeld", package = "plm")
m1 &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "random")
ranef(m1) # individual random effects

# compare to random effects by ML estimation via lme from package nlme
library(nlme)
m2 &lt;- lme(inv ~ value + capital, random = ~1|firm, data = Grunfeld)
cbind("plm" = ranef(m1), "lme" = unname(ranef(m2)))

# two-ways RE model, calculate individual and time random effects
data("Cigar", package = "plm")
tw &lt;- plm(sales ~ pop + price, data = Cigar, model = "random", effect = "twoways")
ranef(tw)                   # individual random effects
ranef(tw, effect = "time")  # time random effects

</code></pre>

<hr>
<h2 id='re-export_functions'>Functions exported from other packages</h2><span id='topic+re-export_functions'></span><span id='topic+maxLik'></span>

<h3>Description</h3>

<p>These functions are imported from other packages and re-exported by
<span class="pkg">plm</span> to enable smooth use within <span class="pkg">plm</span>.  Please follow the
links to view the function's original documentation.
</p>

<hr>
<h2 id='RiceFarms'>Production of Rice in Indonesia</h2><span id='topic+RiceFarms'></span>

<h3>Description</h3>

<p>a panel of 171 observations
</p>


<h3>Format</h3>

<p>A dataframe containing :
</p>

<dl>
<dt>id</dt><dd><p>the farm identifier</p>
</dd>
<dt>size</dt><dd><p>the total area cultivated with rice, measured in hectares</p>
</dd>
<dt>status</dt><dd><p>land status, on of <code>'owner'</code> (non sharecroppers,
owner operators or leaseholders or both), <code>'share'</code>
(sharecroppers), <code>'mixed'</code> (mixed of the two previous status)</p>
</dd>
<dt>varieties</dt><dd><p>one of <code>'trad'</code> (traditional varieties),
<code>'high'</code> (high yielding varieties) and <code>'mixed'</code> (mixed
varieties)</p>
</dd>
<dt>bimas</dt><dd><p>bIMAS is an intensification program; one of
<code>'no'</code> (non-bimas farmer), <code>'yes'</code> (bimas farmer) or
<code>'mixed'</code> (part but not all of farmer's land was registered to
be in the bimas program)</p>
</dd>
<dt>seed</dt><dd><p>seed in kilogram</p>
</dd>
<dt>urea</dt><dd><p>urea in kilogram</p>
</dd>
<dt>phosphate</dt><dd><p>phosphate in kilogram</p>
</dd>
<dt>pesticide</dt><dd><p>pesticide cost in Rupiah</p>
</dd>
<dt>pseed</dt><dd><p>price of seed in Rupiah per kg</p>
</dd>
<dt>purea</dt><dd><p>price of urea in Rupiah per kg</p>
</dd>
<dt>pphosph</dt><dd><p>price of phosphate in Rupiah per kg</p>
</dd>
<dt>hiredlabor</dt><dd><p>hired labor in hours</p>
</dd>
<dt>famlabor</dt><dd><p>family labor in hours</p>
</dd>
<dt>totlabor</dt><dd><p>total labor (excluding harvest labor)</p>
</dd>
<dt>wage</dt><dd><p>labor wage in Rupiah per hour</p>
</dd>
<dt>goutput</dt><dd><p>gross output of rice in kg</p>
</dd>
<dt>noutput</dt><dd><p>net output, gross output minus harvesting cost (paid
in terms of rice)</p>
</dd>
<dt>price</dt><dd><p>price of rough rice in Rupiah per kg</p>
</dd>
<dt>region</dt><dd><p>one of <code>'wargabinangun'</code>, <code>'langan'</code>,
<code>'gunungwangi'</code>, <code>'malausma'</code>, <code>'sukaambit'</code>,
<code>'ciwangi'</code></p>
</dd>
</dl>



<h3>Details</h3>

<p><em>number of observations</em> : 1026
</p>
<p><em>observation</em> : farms
</p>
<p><em>country</em> : Indonesia
</p>


<h3>Source</h3>

<p>Feng Q, Horrace WC (2012).
&ldquo;Alternative technical efficiency measures: Skew, bias and scale.&rdquo;
<em>Journal of Applied Econometrics</em>, <b>27</b>(2), 253-268.
<a href="https://doi.org/10.1002/jae.1190">doi:10.1002/jae.1190</a>.
</p>

<hr>
<h2 id='sargan'>Hansen&ndash;Sargan Test of Overidentifying Restrictions</h2><span id='topic+sargan'></span>

<h3>Description</h3>

<p>A test of overidentifying restrictions for models estimated by GMM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sargan(object, weights = c("twosteps", "onestep"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sargan_+3A_object">object</code></td>
<td>
<p>an object of class <code>"pgmm"</code>,</p>
</td></tr>
<tr><td><code id="sargan_+3A_weights">weights</code></td>
<td>
<p>the weighting matrix to be used for the computation of the
test.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Hansen&ndash;Sargan test (&quot;J test&quot;) calculates the quadratic form of the moment
restrictions that is minimized while computing the GMM estimator. It follows
asymptotically a chi-square distribution with number of degrees of freedom
equal to the difference between the number of moment conditions and the
number of coefficients.
</p>


<h3>Value</h3>

<p>An object of class <code>"htest"</code>.
</p>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>References</h3>

<p>(Hansen 1982)
</p>
<p>(Sargan 1958)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pgmm">pgmm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("EmplUK", package = "plm")
ar &lt;- pgmm(log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1) +
           lag(log(capital), 0:2) + lag(log(output), 0:2) | lag(log(emp), 2:99),
           data = EmplUK, effect = "twoways", model = "twosteps")
sargan(ar)

</code></pre>

<hr>
<h2 id='Snmesp'>Employment and Wages in Spain</h2><span id='topic+Snmesp'></span>

<h3>Description</h3>

<p>A panel of 738 observations from 1983 to 1990
</p>


<h3>Format</h3>

<p>A data frame containing:
</p>

<dl>
<dt>firm</dt><dd><p>firm index</p>
</dd>
<dt>year</dt><dd><p>year</p>
</dd>
<dt>n</dt><dd><p>log of employment</p>
</dd>
<dt>w</dt><dd><p>log of wages</p>
</dd>
<dt>y</dt><dd><p>log of real output</p>
</dd>
<dt>i</dt><dd><p>log of intermediate inputs</p>
</dd>
<dt>k</dt><dd><p>log of real capital stock</p>
</dd>
<dt>f</dt><dd><p>real cash flow</p>
</dd> </dl>



<h3>Details</h3>

<p><em>total number of observations</em>: 5904
</p>
<p><em>observation</em>: firms
</p>
<p><em>country</em>: Spain
</p>


<h3>Source</h3>

<p>Journal of Business Economics and Statistics data archive:
</p>
<p><a href="https://amstat.tandfonline.com/loi/ubes20/">https://amstat.tandfonline.com/loi/ubes20/</a>.
</p>


<h3>References</h3>

<p>Alonso-Borrego C, Arellano M (1999).
&ldquo;Symmetrically Normalized Instrumental-Variable Estimation Using Panel Data.&rdquo;
<em>Journal of Business and Economic Statistics</em>, <b>17</b>(1), 36-49.
</p>

<hr>
<h2 id='SumHes'>The Penn World Table, v. 5</h2><span id='topic+SumHes'></span>

<h3>Description</h3>

<p>A panel of 125 observations from 1960 to 1985
</p>


<h3>Format</h3>

<p>A data frame containing :
</p>

<dl>
<dt>year</dt><dd><p>the year</p>
</dd>
<dt>country</dt><dd><p>the country name (factor)</p>
</dd>
<dt>opec</dt><dd><p>OPEC member?</p>
</dd>
<dt>com</dt><dd><p>communist regime? </p>
</dd>
<dt>pop</dt><dd><p>country's population (in thousands)</p>
</dd>
<dt>gdp</dt><dd><p>real GDP per capita (in 1985 US dollars)</p>
</dd>
<dt>sr</dt><dd><p>saving rate (in percent)</p>
</dd></dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 3250
</p>
<p><em>observation</em> : country
</p>
<p><em>country</em> : World
</p>


<h3>Source</h3>

<p>Online supplements to Hayashi (2000).
</p>
<p><a href="http://fhayashi.fc2web.com/datasets.htm">http://fhayashi.fc2web.com/datasets.htm</a>
</p>


<h3>References</h3>

<p>Hayashi F (2000).
<em>Econometrics</em>.
Princeton University Press.
</p>
<p>Summers R, Heston A (1991).
&ldquo;The Penn World Table (Mark 5): An Expanded Set of International Comparisons, 19501988.&rdquo;
<em>The Quarterly Journal of Economics</em>, <b>106</b>, 327-68.
<a href="https://doi.org/10.2307/2937941">doi:10.2307/2937941</a>.
</p>

<hr>
<h2 id='summary.plm.list'>Summary for plm objects</h2><span id='topic+summary.plm.list'></span><span id='topic+coef.summary.plm.list'></span><span id='topic+print.summary.plm.list'></span><span id='topic+summary.plm'></span><span id='topic+print.summary.plm'></span>

<h3>Description</h3>

<p>The summary method for plm objects generates some more information about
estimated plm models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plm.list'
summary(object, ...)

## S3 method for class 'summary.plm.list'
coef(object, eq = NULL, ...)

## S3 method for class 'summary.plm.list'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  ...
)

## S3 method for class 'plm'
summary(object, vcov = NULL, ...)

## S3 method for class 'summary.plm'
print(
  x,
  digits = max(3, getOption("digits") - 2),
  width = getOption("width"),
  subset = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.plm.list_+3A_object">object</code></td>
<td>
<p>an object of class <code>"plm"</code>,</p>
</td></tr>
<tr><td><code id="summary.plm.list_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="summary.plm.list_+3A_eq">eq</code></td>
<td>
<p>the selected equation for list objects</p>
</td></tr>
<tr><td><code id="summary.plm.list_+3A_x">x</code></td>
<td>
<p>an object of class <code>"summary.plm"</code>,</p>
</td></tr>
<tr><td><code id="summary.plm.list_+3A_digits">digits</code></td>
<td>
<p>number of digits for printed output,</p>
</td></tr>
<tr><td><code id="summary.plm.list_+3A_width">width</code></td>
<td>
<p>the maximum length of the lines in the printed output,</p>
</td></tr>
<tr><td><code id="summary.plm.list_+3A_vcov">vcov</code></td>
<td>
<p>a variance&ndash;covariance matrix furnished by the user or
a function to calculate one (see <strong>Examples</strong>),</p>
</td></tr>
<tr><td><code id="summary.plm.list_+3A_subset">subset</code></td>
<td>
<p>a character or numeric vector indicating a subset of
the table of coefficients to be printed for
<code>"print.summary.plm"</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>summary</code> method for plm objects (<code>summary.plm</code>) creates an
object of class <code>c("summary.plm", "plm", "panelmodel")</code> that
extends the plm object it is run on with various information about
the estimated model like (inferential) statistics, see
<strong>Value</strong>. It has an associated print method
(<code>print.summary.plm</code>).
</p>


<h3>Value</h3>

<p>An object of class <code>c("summary.plm", "plm", "panelmodel")</code>.  Some of its elements are carried over from the
associated plm object and described there
(<code><a href="#topic+plm">plm()</a></code>). The following elements are new or changed
relative to the elements of a plm object:
</p>
<table>
<tr><td><code>fstatistic</code></td>
<td>
<p>'htest' object: joint test of significance of
coefficients (F or Chi-square test) (robust statistic in case of
supplied argument <code>vcov</code>, see <code><a href="#topic+pwaldtest">pwaldtest()</a></code> for details),</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a matrix with the estimated coefficients,
standard errors, t&ndash;values, and p&ndash;values, if argument <code>vcov</code> was
set to non-<code>NULL</code> the standard errors (and t&ndash; and p&ndash;values) in
their respective robust variant,</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>the &quot;regular&quot; variance&ndash;covariance matrix of the coefficients (class &quot;matrix&quot;),</p>
</td></tr>
<tr><td><code>rvcov</code></td>
<td>
<p>only present if argument <code>vcov</code> was set to non-<code>NULL</code>:
the furnished variance&ndash;covariance matrix of the coefficients
(class &quot;matrix&quot;),</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>a named numeric containing the R-squared (&quot;rsq&quot;)
and the adjusted R-squared (&quot;adjrsq&quot;) of the model,</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>an integer vector with 3 components, (p, n-p, p*), where
p is the number of estimated (non-aliased) coefficients of the
model, n-p are the residual degrees of freedom (n being number of
observations), and p* is the total number of coefficients
(incl. any aliased ones).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yves Croissant
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plm">plm()</a></code> for estimation of various models; <code><a href="#topic+vcovHC">vcovHC()</a></code> for
an example of a robust estimation of variance&ndash;covariance
matrix; <code><a href="#topic+r.squared">r.squared()</a></code> for the function to calculate R-squared;
<code><a href="stats.html#topic+print.power.htest">stats::print.power.htest()</a></code> for some information about class
&quot;htest&quot;; <code><a href="#topic+fixef">fixef()</a></code> to compute the fixed effects for &quot;within&quot;
(=fixed effects) models and <code><a href="#topic+within_intercept">within_intercept()</a></code> for an
&quot;overall intercept&quot; for such models; <code><a href="#topic+pwaldtest">pwaldtest()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
zz &lt;- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,
          data = Produc, index = c("state","year"))
summary(zz)

# summary with a furnished vcov, passed as matrix, as function, and
# as function with additional argument
data("Grunfeld", package = "plm")
wi &lt;- plm(inv ~ value + capital,
          data = Grunfeld, model="within", effect = "individual")
summary(wi, vcov = vcovHC(wi))
summary(wi, vcov = vcovHC)
summary(wi, vcov = function(x) vcovHC(x, method = "white2"))

# extract F statistic
wi_summary &lt;- summary(wi)
Fstat &lt;- wi_summary[["fstatistic"]]

# extract estimates and p-values
est &lt;- wi_summary[["coefficients"]][ , "Estimate"]
pval &lt;- wi_summary[["coefficients"]][ , "Pr(&gt;|t|)"]

# print summary only for coefficient "value"
print(wi_summary, subset = "value")

</code></pre>

<hr>
<h2 id='vcovBK'>Beck and Katz Robust Covariance Matrix Estimators</h2><span id='topic+vcovBK'></span><span id='topic+vcovBK.plm'></span>

<h3>Description</h3>

<p>Unconditional Robust covariance matrix estimators <em>a la Beck
and Katz</em> for panel models (a.k.a. Panel Corrected Standard Errors
(PCSE)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vcovBK(x, ...)

## S3 method for class 'plm'
vcovBK(
  x,
  type = c("HC0", "HC1", "HC2", "HC3", "HC4"),
  cluster = c("group", "time"),
  diagonal = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcovBK_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code>,</p>
</td></tr>
<tr><td><code id="vcovBK_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
<tr><td><code id="vcovBK_+3A_type">type</code></td>
<td>
<p>the weighting scheme used, one of <code>"HC0"</code>, <code>"HC1"</code>,
<code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, see Details,</p>
</td></tr>
<tr><td><code id="vcovBK_+3A_cluster">cluster</code></td>
<td>
<p>one of <code>"group"</code>, <code>"time"</code>,</p>
</td></tr>
<tr><td><code id="vcovBK_+3A_diagonal">diagonal</code></td>
<td>
<p>a logical value specifying whether to force
non-diagonal elements to zero,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>vcovBK</code> is a function for estimating a robust covariance matrix of
parameters for a panel model according to the
Beck and Katz (1995) method, a.k.a. Panel
Corrected Standard Errors (PCSE), which uses an unconditional
estimate of the error covariance across time periods (groups)
inside the standard formula for coefficient
covariance. Observations may be clustered either by <code>"group"</code> to
account for timewise heteroskedasticity and serial correlation or
by <code>"time"</code> to account for cross-sectional heteroskedasticity and
correlation. It must be borne in mind that the Beck and Katz
formula is based on N- (T-) asymptotics and will not be appropriate
elsewhere.
</p>
<p>The <code>diagonal</code> logical argument can be used, if set to
<code>TRUE</code>, to force to zero all non-diagonal elements in the
estimated error covariances; this is appropriate if both serial and
cross&ndash;sectional correlation are assumed out, and yields a
timewise- (groupwise-) heteroskedasticity&ndash;consistent estimator.
</p>
<p>Weighting schemes specified by <code>type</code> are analogous to those in
<code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> in package <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> and are
justified theoretically (although in the context of the standard
linear model) by MacKinnon and White (1985) and
Cribari&ndash;Neto (2004) (see Zeileis 2004).
</p>
<p>The main use of <code>vcovBK</code> (and the other variance-covariance estimators
provided in the package <code>vcovHC</code>, <code>vcovNW</code>, <code>vcovDC</code>, <code>vcovSCC</code>) is to pass
it to plm's own functions like <code>summary</code>, <code>pwaldtest</code>, and <code>phtest</code> or
together with testing functions from the <code>lmtest</code> and <code>car</code> packages. All of
these typically allow passing the <code>vcov</code> or <code>vcov.</code> parameter either as a
matrix or as a function, e.g., for Wald&ndash;type testing: argument <code>vcov.</code> to
<code>coeftest()</code>, argument <code>vcov</code> to <code>waldtest()</code> and other methods in the
<a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> package; and argument <code>vcov.</code> to
<code>linearHypothesis()</code> in the <a href="https://CRAN.R-project.org/package=car"><span class="pkg">car</span></a> package (see the
examples), see (see also Zeileis 2004), 4.1-2, and examples below.
</p>


<h3>Value</h3>

<p>An object of class <code>"matrix"</code> containing the estimate of
the covariance matrix of coefficients.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Beck N, Katz JN (1995).
&ldquo;What to do (and not to do) with time-series cross-section data.&rdquo;
<em>American Political Science Review</em>, <b>89</b>(03), 634&ndash;647.
</p>
<p>Cribari&ndash;Neto F (2004).
&ldquo;Asymptotic Inference Under Heteroskedasticity of Unknown Form.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>, <b>45</b>, 215&ndash;233.
</p>
<p>Greene WH (2003).
<em>Econometric Analysis</em>, 5th edition.
Prentice Hall.
</p>
<p>MacKinnon JG, White H (1985).
&ldquo;Some Heteroskedasticity&ndash;Consistent Covariance Matrix Estimators With Improved Finite Sample Properties.&rdquo;
<em>Journal of Econometrics</em>, <b>29</b>, 305&ndash;325.
</p>
<p>Zeileis A (2004).
&ldquo;Econometric Computing With HC and HAC Covariance Matrix Estimators.&rdquo;
<em>Journal of Statistical Software</em>, <b>11</b>(10), 1&ndash;17.
<a href="https://www.jstatsoft.org/article/view/v011i10">https://www.jstatsoft.org/article/view/v011i10</a>.
</p>


<h3>See Also</h3>

<p><code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> from the <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a>
package for weighting schemes (<code>type</code> argument).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package="plm")
zz &lt;- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp, data=Produc, model="random")
summary(zz, vcov = vcovBK)
summary(zz, vcov = function(x) vcovBK(x, type="HC1"))

## standard coefficient significance test
library(lmtest)
coeftest(zz)
## robust significance test, cluster by group
## (robust vs. serial correlation), default arguments
coeftest(zz, vcov.=vcovBK)
## idem with parameters, pass vcov as a function argument
coeftest(zz, vcov.=function(x) vcovBK(x, type="HC1"))
## idem, cluster by time period
## (robust vs. cross-sectional correlation)
coeftest(zz, vcov.=function(x) vcovBK(x, type="HC1", cluster="time"))
## idem with parameters, pass vcov as a matrix argument
coeftest(zz, vcov.=vcovBK(zz, type="HC1"))
## joint restriction test
waldtest(zz, update(zz, .~.-log(emp)-unemp), vcov=vcovBK)
## Not run: 
## test of hyp.: 2*log(pc)=log(emp)
library(car)
linearHypothesis(zz, "2*log(pc)=log(emp)", vcov.=vcovBK)

## End(Not run)
</code></pre>

<hr>
<h2 id='vcovDC'>Double-Clustering Robust Covariance Matrix Estimator</h2><span id='topic+vcovDC'></span><span id='topic+vcovDC.plm'></span>

<h3>Description</h3>

<p>High-level convenience wrapper for double-clustering robust
covariance matrix estimators <em>a la</em>
Thompson (2011) and
Cameron et al. (2011) for panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vcovDC(x, ...)

## S3 method for class 'plm'
vcovDC(x, type = c("HC0", "sss", "HC1", "HC2", "HC3", "HC4"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcovDC_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code> or <code>"pcce"</code></p>
</td></tr>
<tr><td><code id="vcovDC_+3A_...">...</code></td>
<td>
<p>further arguments</p>
</td></tr>
<tr><td><code id="vcovDC_+3A_type">type</code></td>
<td>
<p>the weighting scheme used, one of <code>"HC0"</code>, <code>"sss"</code>,
<code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, see Details,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>vcovDC</code> is a function for estimating a robust covariance matrix of
parameters for a panel model with errors clustering along both dimensions.
The function is a convenience wrapper simply summing a group- and a
time-clustered covariance matrix and subtracting a diagonal one <em>a la</em>
White.
</p>
<p>Weighting schemes specified by <code>type</code> are analogous to those in
<code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> in package <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> and are
justified theoretically (although in the context of the standard
linear model) by MacKinnon and White (1985) and
Cribari&ndash;Neto (2004) (see Zeileis 2004).
</p>
<p>The main use of <code>vcovDC</code> (and the other variance-covariance estimators
provided in the package <code>vcovHC</code>, <code>vcovBK</code>, <code>vcovNW</code>, <code>vcovSCC</code>) is to pass
it to plm's own functions like <code>summary</code>, <code>pwaldtest</code>, and <code>phtest</code> or
together with testing functions from the <code>lmtest</code> and <code>car</code> packages. All of
these typically allow passing the <code>vcov</code> or <code>vcov.</code> parameter either as a
matrix or as a function, e.g., for Wald&ndash;type testing: argument <code>vcov.</code> to
<code>coeftest()</code>, argument <code>vcov</code> to <code>waldtest()</code> and other methods in the
<a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> package; and argument <code>vcov.</code> to
<code>linearHypothesis()</code> in the <a href="https://CRAN.R-project.org/package=car"><span class="pkg">car</span></a> package (see the
examples), see (see also Zeileis 2004), 4.1-2, and examples below.
</p>


<h3>Value</h3>

<p>An object of class <code>"matrix"</code> containing the estimate of
the covariance matrix of coefficients.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Cameron AC, Gelbach JB, Miller DL (2011).
&ldquo;Robust inference with multiway clustering.&rdquo;
<em>Journal of Business &amp; Economic Statistics</em>, <b>29</b>(2).
</p>
<p>Cribari&ndash;Neto F (2004).
&ldquo;Asymptotic Inference Under Heteroskedasticity of Unknown Form.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>, <b>45</b>, 215&ndash;233.
</p>
<p>MacKinnon JG, White H (1985).
&ldquo;Some Heteroskedasticity&ndash;Consistent Covariance Matrix Estimators With Improved Finite Sample Properties.&rdquo;
<em>Journal of Econometrics</em>, <b>29</b>, 305&ndash;325.
</p>
<p>Thompson SB (2011).
&ldquo;Simple formulas for standard errors that cluster by both firm and time.&rdquo;
<em>Journal of Financial Economics</em>, <b>99</b>(1), 1&ndash;10.
</p>
<p>Zeileis A (2004).
&ldquo;Econometric Computing With HC and HAC Covariance Matrix Estimators.&rdquo;
<em>Journal of Statistical Software</em>, <b>11</b>(10), 1&ndash;17.
<a href="https://www.jstatsoft.org/article/view/v011i10">https://www.jstatsoft.org/article/view/v011i10</a>.
</p>


<h3>See Also</h3>

<p><code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> from the <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a>
package for weighting schemes (<code>type</code> argument).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package="plm")
zz &lt;- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp, data=Produc, model="pooling")
## as function input to plm's summary method (with and without additional arguments):
summary(zz, vcov = vcovDC)
summary(zz, vcov = function(x) vcovDC(x, type="HC1", maxlag=4))
## standard coefficient significance test
library(lmtest)
coeftest(zz)
## DC robust significance test, default
coeftest(zz, vcov.=vcovDC)
## idem with parameters, pass vcov as a function argument
coeftest(zz, vcov.=function(x) vcovDC(x, type="HC1", maxlag=4))
## joint restriction test
waldtest(zz, update(zz, .~.-log(emp)-unemp), vcov=vcovDC)
## Not run: 
## test of hyp.: 2*log(pc)=log(emp)
library(car)
linearHypothesis(zz, "2*log(pc)=log(emp)", vcov.=vcovDC)

## End(Not run)
</code></pre>

<hr>
<h2 id='vcovG'>Generic Lego building block for Robust Covariance Matrix Estimators</h2><span id='topic+vcovG'></span><span id='topic+vcovG.plm'></span><span id='topic+vcovG.pcce'></span>

<h3>Description</h3>

<p>Generic Lego building block for robust covariance matrix estimators
of the vcovXX kind for panel models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vcovG(x, ...)

## S3 method for class 'plm'
vcovG(
  x,
  type = c("HC0", "sss", "HC1", "HC2", "HC3", "HC4"),
  cluster = c("group", "time"),
  l = 0,
  inner = c("cluster", "white", "diagavg"),
  ...
)

## S3 method for class 'pcce'
vcovG(
  x,
  type = c("HC0", "sss", "HC1", "HC2", "HC3", "HC4"),
  cluster = c("group", "time"),
  l = 0,
  inner = c("cluster", "white", "diagavg"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcovG_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code> or <code>"pcce"</code></p>
</td></tr>
<tr><td><code id="vcovG_+3A_...">...</code></td>
<td>
<p>further arguments</p>
</td></tr>
<tr><td><code id="vcovG_+3A_type">type</code></td>
<td>
<p>the weighting scheme used, one of <code>"HC0"</code>,
<code>"sss"</code>, <code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>,
<code>"HC4"</code>,</p>
</td></tr>
<tr><td><code id="vcovG_+3A_cluster">cluster</code></td>
<td>
<p>one of <code>"group"</code>, <code>"time"</code>,</p>
</td></tr>
<tr><td><code id="vcovG_+3A_l">l</code></td>
<td>
<p>lagging order, defaulting to zero</p>
</td></tr>
<tr><td><code id="vcovG_+3A_inner">inner</code></td>
<td>
<p>the function to be applied to the residuals inside the
sandwich: one of <code>"cluster"</code> or <code>"white"</code> or
<code>"diagavg"</code>,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>vcovG</code> is the generic building block for use by higher&ndash;level
wrappers <code><a href="#topic+vcovHC">vcovHC()</a></code>, <code><a href="#topic+vcovSCC">vcovSCC()</a></code>, <code><a href="#topic+vcovDC">vcovDC()</a></code>, and <code><a href="#topic+vcovNW">vcovNW()</a></code>. The
main use of <code>vcovG</code> is to be used internally by the former, but it
is made available in the user space for use in non&ndash;standard
combinations. For more documentation, see see wrapper functions
mentioned.
</p>


<h3>Value</h3>

<p>An object of class <code>"matrix"</code> containing the estimate
of the covariance matrix of coefficients.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Millo G (2017).
&ldquo;Robust standard error estimators for panel models: A unifying approach.&rdquo;
<em>Journal of Statistical Software</em>, <b>82</b>(3), 1&ndash;27.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+vcovHC">vcovHC()</a></code>, <code><a href="#topic+vcovSCC">vcovSCC()</a></code>,
<code><a href="#topic+vcovDC">vcovDC()</a></code>, <code><a href="#topic+vcovNW">vcovNW()</a></code>, and
<code><a href="#topic+vcovBK">vcovBK()</a></code> albeit the latter does not make use of
vcovG.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package="plm")
zz &lt;- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp, data=Produc,
model="pooling")
## reproduce Arellano's covariance matrix
vcovG(zz, cluster="group", inner="cluster", l=0)
## define custom covariance function
## (in this example, same as vcovHC)
myvcov &lt;- function(x) vcovG(x, cluster="group", inner="cluster", l=0)
summary(zz, vcov = myvcov)
## use in coefficient significance test
library(lmtest)
## robust significance test
coeftest(zz, vcov. = myvcov)

</code></pre>

<hr>
<h2 id='vcovHC.plm'>Robust Covariance Matrix Estimators</h2><span id='topic+vcovHC.plm'></span><span id='topic+vcovHC'></span><span id='topic+vcovHC.pcce'></span><span id='topic+vcovHC.pgmm'></span>

<h3>Description</h3>

<p>Robust covariance matrix estimators <em>a la White</em> for panel
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'plm'
vcovHC(
  x,
  method = c("arellano", "white1", "white2"),
  type = c("HC0", "sss", "HC1", "HC2", "HC3", "HC4"),
  cluster = c("group", "time"),
  ...
)

## S3 method for class 'pcce'
vcovHC(
  x,
  method = c("arellano", "white1", "white2"),
  type = c("HC0", "sss", "HC1", "HC2", "HC3", "HC4"),
  cluster = c("group", "time"),
  ...
)

## S3 method for class 'pgmm'
vcovHC(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcovHC.plm_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code> which should be the result of a
random effects or a within model or a model of class <code>"pgmm"</code>
or an object of class <code>"pcce"</code>,</p>
</td></tr>
<tr><td><code id="vcovHC.plm_+3A_method">method</code></td>
<td>
<p>one of <code>"arellano"</code>, <code>"white1"</code>, <code>"white2"</code>,</p>
</td></tr>
<tr><td><code id="vcovHC.plm_+3A_type">type</code></td>
<td>
<p>the weighting scheme used, one of <code>"HC0"</code>, <code>"sss"</code>,
<code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, see Details,</p>
</td></tr>
<tr><td><code id="vcovHC.plm_+3A_cluster">cluster</code></td>
<td>
<p>one of <code>"group"</code>, <code>"time"</code>,</p>
</td></tr>
<tr><td><code id="vcovHC.plm_+3A_...">...</code></td>
<td>
<p>further arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>vcovHC</code> is a function for estimating a robust covariance matrix of
parameters for a fixed effects or random effects panel model
according to the White method
(White 1980, 1984; Arellano 1987). Observations may be
clustered by <code>"group"</code> (<code>"time"</code>) to account for serial
(cross-sectional) correlation.
</p>
<p>All types assume no intragroup (serial) correlation between errors
and allow for heteroskedasticity across groups (time periods). As
for the error covariance matrix of every single group of
observations, <code>"white1"</code> allows for general heteroskedasticity but
no serial (cross&ndash;sectional) correlation; <code>"white2"</code> is <code>"white1"</code>
restricted to a common variance inside every group (time period)
(see Greene 2003, Sec. 13.7.1-2, Greene 2012, Sec. 11.6.1-2

and Wooldridge 2002, Sec. 10.7.2); <code>"arellano"</code> (see

ibid. and the original ref. Arellano 1987) allows a fully general
structure w.r.t. heteroskedasticity and serial (cross&ndash;sectional)
correlation.
</p>
<p>Weighting schemes specified by <code>type</code> are analogous to those in
<code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> in package <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> and are
justified theoretically (although in the context of the standard
linear model) by MacKinnon and White (1985) and
Cribari&ndash;Neto (2004)
(Zeileis 2004). <code>type = "sss"</code> employs the small sample
correction as used by Stata.
</p>
<p>The main use of <code>vcovHC</code> (and the other variance-covariance estimators
provided in the package <code>vcovBK</code>, <code>vcovNW</code>, <code>vcovDC</code>, <code>vcovSCC</code>) is to pass
it to plm's own functions like <code>summary</code>, <code>pwaldtest</code>, and <code>phtest</code> or
together with testing functions from the <code>lmtest</code> and <code>car</code> packages. All of
these typically allow passing the <code>vcov</code> or <code>vcov.</code> parameter either as a
matrix or as a function, e.g., for Wald&ndash;type testing: argument <code>vcov.</code> to
<code>coeftest()</code>, argument <code>vcov</code> to <code>waldtest()</code> and other methods in the
<a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> package; and argument <code>vcov.</code> to
<code>linearHypothesis()</code> in the <a href="https://CRAN.R-project.org/package=car"><span class="pkg">car</span></a> package (see the
examples), see (see also Zeileis 2004), 4.1-2, and examples below.
</p>
<p>A special procedure for <code>pgmm</code> objects, proposed by
Windmeijer (2005), is also provided.
</p>


<h3>Value</h3>

<p>An object of class <code>"matrix"</code> containing the estimate of
the asymptotic covariance matrix of coefficients.
</p>


<h3>Note</h3>

<p>The function <code>pvcovHC</code> is deprecated. Use <code>vcovHC</code> for the
same functionality.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo &amp; Yves Croissant
</p>


<h3>References</h3>

<p>Arellano M (1987).
&ldquo;Computing Robust Standard Errors for Within-groups Estimators.&rdquo;
<em>Oxford bulletin of Economics and Statistics</em>, <b>49</b>(4), 431&ndash;434.
</p>
<p>Cribari&ndash;Neto F (2004).
&ldquo;Asymptotic Inference Under Heteroskedasticity of Unknown Form.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>, <b>45</b>, 215&ndash;233.
</p>
<p>Greene WH (2003).
<em>Econometric Analysis</em>, 5th edition.
Prentice Hall.
</p>
<p>Greene WH (2012).
<em>Econometric Analysis</em>, 7th edition.
Prentice Hall.
</p>
<p>MacKinnon JG, White H (1985).
&ldquo;Some Heteroskedasticity&ndash;Consistent Covariance Matrix Estimators With Improved Finite Sample Properties.&rdquo;
<em>Journal of Econometrics</em>, <b>29</b>, 305&ndash;325.
</p>
<p>Windmeijer F (2005).
&ldquo;A Finite Sample Correction for the Variance of Linear Efficient Two&ndash;Steps GMM Estimators.&rdquo;
<em>Journal of Econometrics</em>, <b>126</b>, 25&ndash;51.
</p>
<p>White H (1984).
<em>Asymptotic Theory for Econometricians</em>.
New York: Academic press.
chap. 6
</p>
<p>White H (1980).
&ldquo;A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity.&rdquo;
<em>Econometrica</em>, <b>48</b>(4), 817&ndash;838.
</p>
<p>Wooldridge JM (2002).
<em>Econometric Analysis of Cross&ndash;Section and Panel Data</em>.
MIT Press.
</p>
<p>Zeileis A (2004).
&ldquo;Econometric Computing With HC and HAC Covariance Matrix Estimators.&rdquo;
<em>Journal of Statistical Software</em>, <b>11</b>(10), 1&ndash;17.
<a href="https://www.jstatsoft.org/article/view/v011i10">https://www.jstatsoft.org/article/view/v011i10</a>.
</p>


<h3>See Also</h3>

<p><code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> from the <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a>
package for weighting schemes (<code>type</code> argument).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package = "plm")
zz &lt;- plm(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp,
          data = Produc, model = "random")
## as function input to plm's summary method (with and without additional arguments):
summary(zz, vcov = vcovHC)
summary(zz, vcov = function(x) vcovHC(x, method="arellano", type="HC1"))

## standard coefficient significance test
library(lmtest)
coeftest(zz)
## robust significance test, cluster by group
## (robust vs. serial correlation)
coeftest(zz, vcov.=vcovHC)
## idem with parameters, pass vcov as a function argument
coeftest(zz, vcov.=function(x) vcovHC(x, method="arellano", type="HC1"))
## idem, cluster by time period
## (robust vs. cross-sectional correlation)
coeftest(zz, vcov.=function(x) vcovHC(x, method="arellano",
 type="HC1", cluster="group"))
## idem with parameters, pass vcov as a matrix argument
coeftest(zz, vcov.=vcovHC(zz, method="arellano", type="HC1"))
## joint restriction test
waldtest(zz, update(zz, .~.-log(emp)-unemp), vcov=vcovHC)
## Not run: 
## test of hyp.: 2*log(pc)=log(emp)
library(car)
linearHypothesis(zz, "2*log(pc)=log(emp)", vcov.=vcovHC)

## End(Not run)
## Robust inference for CCE models
data("Produc", package = "plm")
ccepmod &lt;- pcce(log(gsp) ~ log(pcap) + log(pc) + log(emp) + unemp, data = Produc, model="p")
summary(ccepmod, vcov = vcovHC)

## Robust inference for GMM models
data("EmplUK", package="plm")
ar &lt;- pgmm(log(emp) ~ lag(log(emp), 1:2) + lag(log(wage), 0:1)
           + log(capital) + lag(log(capital), 2) + log(output)
           + lag(log(output),2) | lag(log(emp), 2:99),
            data = EmplUK, effect = "twoways", model = "twosteps")
rv &lt;- vcovHC(ar)
mtest(ar, order = 2, vcov = rv)
</code></pre>

<hr>
<h2 id='vcovNW'>Newey and West (1987) Robust Covariance Matrix Estimator</h2><span id='topic+vcovNW'></span><span id='topic+vcovNW.plm'></span><span id='topic+vcovNW.pcce'></span>

<h3>Description</h3>

<p>Nonparametric robust covariance matrix estimators <em>a la Newey
and West</em> for panel models with serial correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vcovNW(x, ...)

## S3 method for class 'plm'
vcovNW(
  x,
  type = c("HC0", "sss", "HC1", "HC2", "HC3", "HC4"),
  maxlag = NULL,
  wj = function(j, maxlag) 1 - j/(maxlag + 1),
  ...
)

## S3 method for class 'pcce'
vcovNW(
  x,
  type = c("HC0", "sss", "HC1", "HC2", "HC3", "HC4"),
  maxlag = NULL,
  wj = function(j, maxlag) 1 - j/(maxlag + 1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcovNW_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code> or <code>"pcce"</code></p>
</td></tr>
<tr><td><code id="vcovNW_+3A_...">...</code></td>
<td>
<p>further arguments</p>
</td></tr>
<tr><td><code id="vcovNW_+3A_type">type</code></td>
<td>
<p>the weighting scheme used, one of <code>"HC0"</code>, <code>"sss"</code>,
<code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, see Details,</p>
</td></tr>
<tr><td><code id="vcovNW_+3A_maxlag">maxlag</code></td>
<td>
<p>either <code>NULL</code> or a positive integer specifying the
maximum lag order before truncation</p>
</td></tr>
<tr><td><code id="vcovNW_+3A_wj">wj</code></td>
<td>
<p>weighting function to be applied to lagged terms,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>vcovNW</code> is a function for estimating a robust covariance matrix of
parameters for a panel model according to the
Newey and West (1987) method.  The function works
as a restriction of the Driscoll and Kraay (1998) covariance (see
<code><a href="#topic+vcovSCC">vcovSCC()</a></code>) to no cross&ndash;sectional correlation.
</p>
<p>Weighting schemes specified by <code>type</code> are analogous to those in
<code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> in package <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> and are
justified theoretically (although in the context of the standard
linear model) by MacKinnon and White (1985) and
Cribari&ndash;Neto (2004) (see Zeileis 2004).
</p>
<p>The main use of <code>vcovNW</code> (and the other variance-covariance estimators
provided in the package <code>vcovHC</code>, <code>vcovBK</code>, <code>vcovDC</code>, <code>vcovSCC</code>) is to pass
it to plm's own functions like <code>summary</code>, <code>pwaldtest</code>, and <code>phtest</code> or
together with testing functions from the <code>lmtest</code> and <code>car</code> packages. All of
these typically allow passing the <code>vcov</code> or <code>vcov.</code> parameter either as a
matrix or as a function, e.g., for Wald&ndash;type testing: argument <code>vcov.</code> to
<code>coeftest()</code>, argument <code>vcov</code> to <code>waldtest()</code> and other methods in the
<a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> package; and argument <code>vcov.</code> to
<code>linearHypothesis()</code> in the <a href="https://CRAN.R-project.org/package=car"><span class="pkg">car</span></a> package (see the
examples), see (see also Zeileis 2004), 4.1-2, and examples below.
</p>


<h3>Value</h3>

<p>An object of class <code>"matrix"</code> containing the estimate of
the covariance matrix of coefficients.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo
</p>


<h3>References</h3>

<p>Cribari&ndash;Neto F (2004).
&ldquo;Asymptotic Inference Under Heteroskedasticity of Unknown Form.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>, <b>45</b>, 215&ndash;233.
</p>
<p>Driscoll JC, Kraay AC (1998).
&ldquo;Consistent covariance matrix estimation with spatially dependent panel data.&rdquo;
<em>Review of economics and statistics</em>, <b>80</b>(4), 549&ndash;560.
</p>
<p>MacKinnon JG, White H (1985).
&ldquo;Some Heteroskedasticity&ndash;Consistent Covariance Matrix Estimators With Improved Finite Sample Properties.&rdquo;
<em>Journal of Econometrics</em>, <b>29</b>, 305&ndash;325.
</p>
<p>Newey WK, West KD (1987).
&ldquo;A Simple, Positive Semi-definite, Heteroskedasticity and Autocorrelation Consistent Covariance Matrix.&rdquo;
<em>Econometrica</em>, <b>55</b>(3), 703&ndash;08.
</p>
<p>Zeileis A (2004).
&ldquo;Econometric Computing With HC and HAC Covariance Matrix Estimators.&rdquo;
<em>Journal of Statistical Software</em>, <b>11</b>(10), 1&ndash;17.
<a href="https://www.jstatsoft.org/article/view/v011i10">https://www.jstatsoft.org/article/view/v011i10</a>.
</p>


<h3>See Also</h3>

<p><code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> from the <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> package
for weighting schemes (<code>type</code> argument).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package="plm")
zz &lt;- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp, data=Produc, model="pooling")
## as function input to plm's summary method (with and without additional arguments):
summary(zz, vcov = vcovNW)
summary(zz, vcov = function(x) vcovNW(x, method="arellano", type="HC1"))
## standard coefficient significance test
library(lmtest)
coeftest(zz)
## NW robust significance test, default
coeftest(zz, vcov.=vcovNW)
## idem with parameters, pass vcov as a function argument
coeftest(zz, vcov.=function(x) vcovNW(x, type="HC1", maxlag=4))
## joint restriction test
waldtest(zz, update(zz, .~.-log(emp)-unemp), vcov=vcovNW)
## Not run: 
## test of hyp.: 2*log(pc)=log(emp)
library(car)
linearHypothesis(zz, "2*log(pc)=log(emp)", vcov.=vcovNW)

## End(Not run)
</code></pre>

<hr>
<h2 id='vcovSCC'>Driscoll and Kraay (1998) Robust Covariance Matrix Estimator</h2><span id='topic+vcovSCC'></span><span id='topic+vcovSCC.plm'></span><span id='topic+vcovSCC.pcce'></span>

<h3>Description</h3>

<p>Nonparametric robust covariance matrix estimators <em>a la
Driscoll and Kraay</em> for panel models with cross-sectional
<em>and</em> serial correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vcovSCC(x, ...)

## S3 method for class 'plm'
vcovSCC(
  x,
  type = c("HC0", "sss", "HC1", "HC2", "HC3", "HC4"),
  cluster = "time",
  maxlag = NULL,
  inner = c("cluster", "white", "diagavg"),
  wj = function(j, maxlag) 1 - j/(maxlag + 1),
  ...
)

## S3 method for class 'pcce'
vcovSCC(
  x,
  type = c("HC0", "sss", "HC1", "HC2", "HC3", "HC4"),
  cluster = "time",
  maxlag = NULL,
  inner = c("cluster", "white", "diagavg"),
  wj = function(j, maxlag) 1 - j/(maxlag + 1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcovSCC_+3A_x">x</code></td>
<td>
<p>an object of class <code>"plm"</code> or <code>"pcce"</code></p>
</td></tr>
<tr><td><code id="vcovSCC_+3A_...">...</code></td>
<td>
<p>further arguments</p>
</td></tr>
<tr><td><code id="vcovSCC_+3A_type">type</code></td>
<td>
<p>the weighting scheme used, one of <code>"HC0"</code>, <code>"sss"</code>,
<code>"HC1"</code>, <code>"HC2"</code>, <code>"HC3"</code>, <code>"HC4"</code>, see Details,</p>
</td></tr>
<tr><td><code id="vcovSCC_+3A_cluster">cluster</code></td>
<td>
<p>switch for vcovG; set at <code>"time"</code> here,</p>
</td></tr>
<tr><td><code id="vcovSCC_+3A_maxlag">maxlag</code></td>
<td>
<p>either <code>NULL</code> or a positive integer specifying the
maximum lag order before truncation</p>
</td></tr>
<tr><td><code id="vcovSCC_+3A_inner">inner</code></td>
<td>
<p>the function to be applied to the residuals inside the
sandwich: <code>"cluster"</code> for SCC, <code>"white"</code> for Newey-West,
(<code>"diagavg"</code> for compatibility reasons)</p>
</td></tr>
<tr><td><code id="vcovSCC_+3A_wj">wj</code></td>
<td>
<p>weighting function to be applied to lagged terms,</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>vcovSCC</code> is a function for estimating a robust covariance matrix
of parameters for a panel model according to the
Driscoll and Kraay (1998) method, which is consistent
with cross&ndash;sectional and serial correlation in a T-asymptotic
setting and irrespective of the N dimension. The use with random
effects models is undocumented.
</p>
<p>Weighting schemes specified by <code>type</code> are analogous to those in
<code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> in package <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> and are
justified theoretically (although in the context of the standard
linear model) by MacKinnon and White (1985) and
Cribari&ndash;Neto (2004) (see Zeileis 2004)).
</p>
<p>The main use of <code>vcovSCC</code> (and the other variance-covariance estimators
provided in the package <code>vcovHC</code>, <code>vcovBK</code>, <code>vcovNW</code>, <code>vcovDC</code>) is to pass
it to plm's own functions like <code>summary</code>, <code>pwaldtest</code>, and <code>phtest</code> or
together with testing functions from the <code>lmtest</code> and <code>car</code> packages. All of
these typically allow passing the <code>vcov</code> or <code>vcov.</code> parameter either as a
matrix or as a function, e.g., for Wald&ndash;type testing: argument <code>vcov.</code> to
<code>coeftest()</code>, argument <code>vcov</code> to <code>waldtest()</code> and other methods in the
<a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> package; and argument <code>vcov.</code> to
<code>linearHypothesis()</code> in the <a href="https://CRAN.R-project.org/package=car"><span class="pkg">car</span></a> package (see the
examples), (see also Zeileis 2004), 4.1-2, and examples below.
</p>


<h3>Value</h3>

<p>An object of class <code>"matrix"</code> containing the estimate of
the covariance matrix of coefficients.
</p>


<h3>Author(s)</h3>

<p>Giovanni Millo, partially ported from Daniel Hoechle's
(2007) Stata code
</p>


<h3>References</h3>

<p>Cribari&ndash;Neto F (2004).
&ldquo;Asymptotic Inference Under Heteroskedasticity of Unknown Form.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>, <b>45</b>, 215&ndash;233.
</p>
<p>Driscoll JC, Kraay AC (1998).
&ldquo;Consistent covariance matrix estimation with spatially dependent panel data.&rdquo;
<em>Review of economics and statistics</em>, <b>80</b>(4), 549&ndash;560.
</p>
<p>Hoechle D (2007).
&ldquo;Robust standard errors for panel regressions with cross-sectional dependence.&rdquo;
<em>Stata Journal</em>, <b>7</b>(3), 281-312.
<a href="https://ideas.repec.org/a/tsj/stataj/v7y2007i3p281-312.html">https://ideas.repec.org/a/tsj/stataj/v7y2007i3p281-312.html</a>.
</p>
<p>MacKinnon JG, White H (1985).
&ldquo;Some Heteroskedasticity&ndash;Consistent Covariance Matrix Estimators With Improved Finite Sample Properties.&rdquo;
<em>Journal of Econometrics</em>, <b>29</b>, 305&ndash;325.
</p>
<p>Zeileis A (2004).
&ldquo;Econometric Computing With HC and HAC Covariance Matrix Estimators.&rdquo;
<em>Journal of Statistical Software</em>, <b>11</b>(10), 1&ndash;17.
<a href="https://www.jstatsoft.org/article/view/v011i10">https://www.jstatsoft.org/article/view/v011i10</a>.
</p>


<h3>See Also</h3>

<p><code><a href="sandwich.html#topic+vcovHC">sandwich::vcovHC()</a></code> from the <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a>
package for weighting schemes (<code>type</code> argument).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("Produc", package="plm")
zz &lt;- plm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp, data=Produc, model="pooling")
## as function input to plm's summary method (with and without additional arguments):
summary(zz, vcov = vcovSCC)
summary(zz, vcov = function(x) vcovSCC(x, method="arellano", type="HC1"))
## standard coefficient significance test
library(lmtest)
coeftest(zz)
## SCC robust significance test, default
coeftest(zz, vcov.=vcovSCC)
## idem with parameters, pass vcov as a function argument
coeftest(zz, vcov.=function(x) vcovSCC(x, type="HC1", maxlag=4))
## joint restriction test
waldtest(zz, update(zz, .~.-log(emp)-unemp), vcov=vcovSCC)
## Not run: 
## test of hyp.: 2*log(pc)=log(emp)
library(car)
linearHypothesis(zz, "2*log(pc)=log(emp)", vcov.=vcovSCC)

## End(Not run)
</code></pre>

<hr>
<h2 id='Wages'>Panel Data of Individual Wages</h2><span id='topic+Wages'></span>

<h3>Description</h3>

<p>A panel of 595 individuals from 1976 to 1982, taken from the Panel Study of
Income Dynamics (PSID).<br /><br /> The data are organized as a stacked time
series/balanced panel, see <strong>Examples</strong> on how to convert to a
<code>pdata.frame</code>.
</p>


<h3>Format</h3>

<p>A data frame containing:
</p>

<dl>
<dt>exp</dt><dd><p>years of full-time work experience.</p>
</dd>
<dt>wks</dt><dd><p>weeks  worked.</p>
</dd>
<dt>bluecol</dt><dd><p>blue collar?</p>
</dd>
<dt>ind</dt><dd><p>works in a manufacturing industry?</p>
</dd>
<dt>south</dt><dd><p>resides in the south?</p>
</dd>
<dt>smsa</dt><dd><p>resides in a standard metropolitan statistical area?</p>
</dd>
<dt>married</dt><dd><p>married?</p>
</dd>
<dt>sex</dt><dd><p>a factor with levels <code>"male"</code> and <code>"female"</code></p>
</dd>
<dt>union</dt><dd><p>individual's wage set by a union contract?</p>
</dd>
<dt>ed</dt><dd><p>years of education.</p>
</dd>
<dt>black</dt><dd><p>is the individual black?</p>
</dd>
<dt>lwage</dt><dd><p>logarithm of wage.</p>
</dd> </dl>



<h3>Details</h3>

<p><em>total number of observations</em> : 4165
</p>
<p><em>observation</em> : individuals
</p>
<p><em>country</em> : United States
</p>


<h3>Source</h3>

<p>Online complements to Baltagi (2001):
</p>
<p><a href="https://www.wiley.com/legacy/wileychi/baltagi/">https://www.wiley.com/legacy/wileychi/baltagi/</a>
</p>
<p>Online complements to Baltagi (2013):
</p>
<p><a href="https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452">https://bcs.wiley.com/he-bcs/Books?action=resource&amp;bcsId=4338&amp;itemId=1118672321&amp;resourceId=13452</a>
</p>


<h3>References</h3>

<p>Baltagi BH (2001).
<em>Econometric Analysis of Panel Data</em>, 3rd edition.
John Wiley and Sons ltd.
</p>
<p>Baltagi BH (2013).
<em>Econometric Analysis of Panel Data</em>, 5th edition.
John Wiley and Sons ltd.
</p>
<p>Cornwell C, Rupert P (1988).
&ldquo;Efficient Estimation With Panel Data: an Empirical Comparison of Instrumental Variables Estimators.&rdquo;
<em>Journal of Applied Econometrics</em>, <b>3</b>, 149&ndash;155.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# data set 'Wages' is organized as a stacked time series/balanced panel
data("Wages", package = "plm")
Wag &lt;- pdata.frame(Wages, index=595)

</code></pre>

<hr>
<h2 id='within_intercept'>Overall Intercept for Within Models Along its Standard Error</h2><span id='topic+within_intercept'></span><span id='topic+within_intercept.plm'></span>

<h3>Description</h3>

<p>This function gives an overall intercept for within models and its
accompanying standard error or an within model with the overall intercept
</p>


<h3>Usage</h3>

<pre><code class='language-R'>within_intercept(object, ...)

## S3 method for class 'plm'
within_intercept(object, vcov = NULL, return.model = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="within_intercept_+3A_object">object</code></td>
<td>
<p>object of class <code>plm</code> which must be a within
model (fixed effects model),</p>
</td></tr>
<tr><td><code id="within_intercept_+3A_...">...</code></td>
<td>
<p>further arguments (currently none).</p>
</td></tr>
<tr><td><code id="within_intercept_+3A_vcov">vcov</code></td>
<td>
<p>if not <code>NULL</code> (default), a function to calculate a
user defined variance&ndash;covariance matrix (function for robust
vcov), only used if <code>return.model = FALSE</code>,</p>
</td></tr>
<tr><td><code id="within_intercept_+3A_return.model">return.model</code></td>
<td>
<p>a logical to indicate whether only the overall intercept
(<code>FALSE</code> is default) or a full model object (<code>TRUE</code>) is to be returned,</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The (somewhat artificial) intercept for within models (fixed
effects models) was made popular by Stata of StataCorp
(see Gould 2013), EViews of IHS, and gretl
(see Cottrell and Lucchetti 2021, p. 200-201, listing 23.1), see for
treatment in the literature,
e.g., Greene (2012), Ch. 11.4.4, p. 364. It can
be considered an overall intercept in the within model framework
and is the weighted mean of fixed effects (see <strong>Examples</strong> for the
relationship).
</p>
<p><code>within_intercept</code> estimates a new model which is
computationally more demanding than just taking the weighted
mean. However, with <code>within_intercept</code> one also gets the
associated standard error and it is possible to get an overall
intercept for twoway fixed effect models.
</p>
<p>Users can set argument <code>vcov</code> to a function to calculate a
specific (robust) variance&ndash;covariance matrix and get the
respective (robust) standard error for the overall intercept,
e.g., the function <code><a href="#topic+vcovHC">vcovHC()</a></code>, see examples for
usage. Note: The argument <code>vcov</code> must be a function, not a
matrix, because the model to calculate the overall intercept for
the within model is different from the within model itself.
</p>
<p>If argument <code>return.model = TRUE</code> is set, the full model object is returned,
while in the default case only the intercept is returned.
</p>


<h3>Value</h3>

<p>Depending on argument <code>return.model</code>:  If <code>FALSE</code> (default), a named
<code>numeric</code> of length one: The overall intercept for the estimated within model
along attribute &quot;se&quot; which contains the standard error for the intercept.
If <code>return.model = TRUE</code>, the full model object, a within model with the
overall intercept (NB: the model identifies itself as a pooling model, e.g.,
in summary()).
</p>


<h3>Author(s)</h3>

<p>Kevin Tappe
</p>


<h3>References</h3>

<p>Cottrell A, Lucchetti R (2021).
&ldquo;Gretl Users Guide.&rdquo;
<a href="https://gretl.sourceforge.net/">https://gretl.sourceforge.net/</a>.<br /><br /> Gould W (2013).
&ldquo;How can there be an intercept in the fixed-effects model estimated by xtreg, fe?&rdquo;
<a href="https://www.stata.com/support/faqs/statistics/intercept-in-fixed-effects-model/">https://www.stata.com/support/faqs/statistics/intercept-in-fixed-effects-model/</a>.<br /><br /> Greene WH (2012).
<em>Econometric Analysis</em>, 7th edition.
Prentice Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fixef">fixef()</a></code> to extract the fixed effects of a within model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Hedonic", package = "plm")
mod_fe &lt;- plm(mv ~ age + crim, data = Hedonic, index = "townid")
overallint &lt;- within_intercept(mod_fe)
attr(overallint, "se") # standard error

# overall intercept is the weighted mean of fixed effects in the
# one-way case
weighted.mean(fixef(mod_fe), pdim(mod_fe)$Tint$Ti)

### relationship of type="dmean", "level" and within_intercept
## one-way balanced case
data("Grunfeld", package = "plm")
gi &lt;- plm(inv ~ value + capital, data = Grunfeld, model = "within")
fx_level &lt;- fixef(gi, type = "level")
fx_dmean &lt;- fixef(gi, type = "dmean")
overallint &lt;- within_intercept(gi)
all.equal(overallint + fx_dmean, fx_level, check.attributes = FALSE) # TRUE
## two-ways unbalanced case
gtw_u &lt;- plm(inv ~ value + capital, data = Grunfeld[-200, ], effect = "twoways")
int_tw_u &lt;- within_intercept(gtw_u)
fx_dmean_tw_i_u &lt;- fixef(gtw_u, type = "dmean", effect = "individual")[index(gtw_u)[[1L]]]
fx_dmean_tw_t_u &lt;- fixef(gtw_u, type = "dmean", effect = "time")[index(gtw_u)[[2L]]]
fx_level_tw_u &lt;- as.numeric(fixef(gtw_u, "twoways", "level"))
fx_level_tw_u2 &lt;- int_tw_u + fx_dmean_tw_i_u + fx_dmean_tw_t_u
all.equal(fx_level_tw_u, fx_level_tw_u2, check.attributes = FALSE) # TRUE

## overall intercept with robust standard error
within_intercept(gi, vcov = function(x) vcovHC(x, method="arellano", type="HC0"))

## have a model returned
mod_fe_int &lt;- within_intercept(gi, return.model = TRUE)
summary(mod_fe_int)
# replicates Stata's robust standard errors
summary(mod_fe_int, vcvov = function(x) vcovHC(x, type = "sss")) 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
