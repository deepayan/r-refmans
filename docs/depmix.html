<!DOCTYPE html><html><head><title>Help for package depmix</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {depmix}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#depmix-internal'><p>Depmix utility functions</p></a></li>
<li><a href='#discrimination'><p>Discrimination Learning Data</p></a></li>
<li><a href='#dmm'><p>Dependent Mixture Model Specifiction</p></a></li>
<li><a href='#fitdmm'><p>Fitting Dependent Mixture Models</p></a></li>
<li><a href='#generate'><p>Generate data from a dependent mixture model</p></a></li>
<li><a href='#markovdata'><p>Specifying Markov data objects</p></a></li>
<li><a href='#mgdmm'><p>Multi group model specification</p></a></li>
<li><a href='#mixdmm'><p>Mixture of dmm's specification</p></a></li>
<li><a href='#speed'><p>Speed Accuracy Switching Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.9.16</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-01-09</td>
</tr>
<tr>
<td>Title:</td>
<td>Dependent Mixture Models</td>
</tr>
<tr>
<td>Author:</td>
<td>Ingmar Visser &lt;i.visser@uva.nl&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ingmar Visser &lt;i.visser@uva.nl&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), MASS, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>Rdonlp2</td>
</tr>
<tr>
<td>Additional_repositories:</td>
<td><a href="http://R-Forge.R-project.org">http://R-Forge.R-project.org</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Fits (multigroup) mixtures of latent or hidden Markov models on mixed categorical and continuous (timeseries) data. The 'Rdonlp2' package can optionally be used for optimization of the log-likelihood and is available from R-forge. See Visser et al. (2009, &lt;<a href="https://doi.org/10.1007%2F978-0-387-95922-1_13">doi:10.1007/978-0-387-95922-1_13</a>&gt;) for examples and applications. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-01-10 08:21:23 UTC; ingmar</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-01-10 10:30:13 UTC</td>
</tr>
</table>
<hr>
<h2 id='depmix-internal'>Depmix utility functions</h2><span id='topic+checkSetRecode'></span><span id='topic+recode'></span><span id='topic+fblo'></span><span id='topic+fbuo'></span><span id='topic+ppar'></span><span id='topic+recitt'></span><span id='topic+pp'></span><span id='topic+np'></span><span id='topic+pa2conr'></span><span id='topic+paridx'></span><span id='topic+fresp'></span><span id='topic+bdiag'></span><span id='topic+cl2st'></span><span id='topic+cl2stob'></span><span id='topic+kmstart'></span><span id='topic+poststart'></span><span id='topic+tr2stin'></span>

<h3>Description</h3>

<p>These functions are used internally by depmix functions. They should not be called
directly unless you know what you're doing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	
	checkSetRecode(dat,dmm,tdcov,printlevel=1)
	recode(dat,xm)
	fblo(x,i,bigB)
	fbuo(x,i,bigB)
	ppar(x,z)
	recitt(itemtypes)
	pp(x)
	np(x)
	pa2conr(x)
	paridx(nstates,itemtypes,mat,idx1=0,idx2=0,it=0,comp=1,group=1)
	fresp(x,pars)
	bdiag(x)
	cl2st(cluster,dat,dmm)
	cl2stob(cluster,dat,dmm)
	kmstart(dat,dmm)
	poststart(dat,dmm)
	tr2stin(sttr)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="depmix-internal_+3A_dat">dat</code>, <code id="depmix-internal_+3A_xm">xm</code></td>
<td>
<p>See markovdata help.</p>
</td></tr>
<tr><td><code id="depmix-internal_+3A_dmm">dmm</code>, <code id="depmix-internal_+3A_itemtypes">itemtypes</code>, <code id="depmix-internal_+3A_nstates">nstates</code></td>
<td>
<p>See dmm help.</p>
</td></tr>
<tr><td><code id="depmix-internal_+3A_cluster">cluster</code></td>
<td>
<p>Some clustering of the data, eg from kmeans or posterior
estimates that can be used to arrive at starting values for parameters.</p>
</td></tr>
<tr><td><code id="depmix-internal_+3A_sttr">sttr</code></td>
<td>
<p>transition matrix starting values.</p>
</td></tr>
<tr><td><code id="depmix-internal_+3A_printlevel">printlevel</code>, <code id="depmix-internal_+3A_tdcov">tdcov</code></td>
<td>
<p>See depmix help.</p>
</td></tr>
<tr><td><code id="depmix-internal_+3A_x">x</code>, <code id="depmix-internal_+3A_mat">mat</code>, <code id="depmix-internal_+3A_idx1">idx1</code>, <code id="depmix-internal_+3A_idx2">idx2</code>, <code id="depmix-internal_+3A_it">it</code>, <code id="depmix-internal_+3A_comp">comp</code>, <code id="depmix-internal_+3A_group">group</code></td>
<td>
<p>A vector/matrix(name)/indices et cetera.</p>
</td></tr>
<tr><td><code id="depmix-internal_+3A_i">i</code>, <code id="depmix-internal_+3A_z">z</code>, <code id="depmix-internal_+3A_bigb">bigB</code>, <code id="depmix-internal_+3A_pars">pars</code></td>
<td>
<p>More internal stuff.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function bdiag takes as argument a list of matrices and returns the 
blockdiagonal matrix formed from these, and the other entries padded with 
zeroes. This function is from package assist by Chunlei Ke and Yuedong Wang.
</p>


<h3>Value</h3>

<p>Most of these functions are used for their side-effect, ie sending stuff to C-routines,
or returning recoded stuff (data, itemtypes) et cetera.
</p>


<h3>Author(s)</h3>

<p>Ingmar Visser <a href="mailto:i.visser@uva.nl">i.visser@uva.nl</a></p>

<hr>
<h2 id='discrimination'>Discrimination Learning Data</h2><span id='topic+discrimination'></span>

<h3>Description</h3>

<p>This data set is from a simple discrimation learning experiment.  It
consists of 192 binary series of responses of different lengths. This
is a subset of the data described by <cite>Raijmakers et al. (2001)</cite>, and
it is analyzed much more extensively using latent Markov models and depmix in
<cite>Schmittmann et al. (2006)</cite> and <cite>Visser et al. (2006).</cite>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(discrimination)</code></pre>


<h3>Format</h3>

<p>An object of class <code>markovdata</code>.</p>


<h3>Source</h3>

<p>Maartje E. J. Raijmakers, Conor V. Dolan and Peter C. M. Molenaar 
(2001).  Finite mixture distribution models of simple discrimination
learning. <em>Memory \&amp; Cognition</em>, vol 29(5).
</p>
<p>Ingmar Visser, Verena D. Schmittmann, and Maartje E. J. Raijmakers
(2007).  Markov process models for discrimination learning.  In: Kees
van Montfort, Han Oud, and Albert Satorra (Eds.), <em>Longitudinal
models in the behavioral and related sciences</em>, Mahwah (NJ): Lawrence
Erlbaum Associates.
</p>
<p>Verena D. Schmittmann, Ingmar Visser and Maartje E. J. Raijmakers
(2006).  Multiple learning modes in the development of rule-based
category-learning task performance.  <em>Neuropsychologia, vol
44(11)</em>, p.  2079-2091.
</p>

<hr>
<h2 id='dmm'>Dependent Mixture Model Specifiction</h2><span id='topic+dmm'></span><span id='topic+summary.dmm'></span><span id='topic+lcm'></span><span id='topic+lca'></span>

<h3>Description</h3>

<p><code>dmm</code> creates an object of class <code>dmm</code>, a
dependent mixture model.
</p>
<p><code>lca</code> creates an object of class <code>dmm,lca</code>, a
latent class model or an independent mixture model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	dmm(nstates, itemtypes, modname = NULL, fixed = NULL,
                 stval = NULL, conrows = NULL, conpat = NULL, tdfix =
                 NULL, tdst = NULL, linmat = NULL, snames = NULL,
                 inames = NULL)
	## S3 method for class 'dmm'
summary(object, specs=FALSE, precision=3, se=NULL, ...)

	lca(nclasses, itemtypes, modname = NULL, fixed = NULL,
                 stval = NULL, conrows = NULL, conpat = NULL, 
				 linmat = NULL, snames = NULL, inames = NULL)
	
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dmm_+3A_nstates">nstates</code></td>
<td>
<p>The number of latent states/classes of the model.</p>
</td></tr>
<tr><td><code id="dmm_+3A_nclasses">nclasses</code></td>
<td>
<p>The number of classes of an lca model, ie the number of
states in a <code>dmm</code> model. They are now called classes because they do
not change over time.</p>
</td></tr>
<tr><td><code id="dmm_+3A_itemtypes">itemtypes</code></td>
<td>
<p>A vector of length <code>nitems</code> providing the type of
measurement, 1 for gaussian data, 2 for a binary item, n&gt;3 for
categorical items with n answer possibilities. Answer categories are 
assumed to be unordered categorical. Ordinal responses can be implemented 
using inequality and/or linear constraints.</p>
</td></tr>
<tr><td><code id="dmm_+3A_modname">modname</code></td>
<td>
<p>A character string with the name of the model, good when 
fitting many models. Components of mixture models keep their own names. 
Names are printed in the summary. Boring default names are provided.</p>
</td></tr>
<tr><td><code id="dmm_+3A_fixed">fixed</code></td>
<td>
<p>A vector of length the number of parameters of the model
idicating whether parameters are fixed (0) or not (&gt;0).  This may be
identical to conpat (see below).</p>
</td></tr>
<tr><td><code id="dmm_+3A_stval">stval</code></td>
<td>
<p>Start values of the parameters.  These will be random if
not specified.  Start values must be specified (for all parameters) if
there are fixed parameters.</p>
</td></tr>
<tr><td><code id="dmm_+3A_conrows">conrows</code></td>
<td>
<p>Argument <code>conrows</code> can be used to specify general
constraints between parameters. See details below.</p>
</td></tr>
<tr><td><code id="dmm_+3A_conpat">conpat</code></td>
<td>
<p>Argument <code>conpat</code> can be used to specify fixed
parameters and equality constraints.  It can not be used in conjuction
with fixed.  See details below.</p>
</td></tr>
<tr><td><code id="dmm_+3A_tdfix">tdfix</code>, <code id="dmm_+3A_tdst">tdst</code></td>
<td>
<p>The first is a logical vector indicating (with 1's) 
which parameters are dependent on covariates (it should have length npars). 
tdst provides the starting values for the regression parameters. 
Using tdcov=TRUE in fitdmm will actually fit the regression parameters. 
The covariate itself has to be specified in the data as 
&quot;covariate&quot; (see help on markovdata) and should be scaled to 0-1.</p>
</td></tr>
<tr><td><code id="dmm_+3A_linmat">linmat</code></td>
<td>
<p>A complete matrix of linear constraints.  This argument
is intended for internal use only, it is used by the fit routine to
re-create the model with the fitted parameter values.  Warning: use of
this argument results in complete replacement of the otherwise created
matrix A, which contains e.g. sum contraints for transition matrix
parameters.  If <code>linmat</code> is provided, make sure it is correct,
otherwise strange results may occur in fitting models.</p>
</td></tr>
<tr><td><code id="dmm_+3A_snames">snames</code></td>
<td>
<p>Names for the states may be provided in snames. 
Defaults are State1, State2 etc. These are printed in the summary.</p>
</td></tr>
<tr><td><code id="dmm_+3A_inames">inames</code></td>
<td>
<p>Names for items may be provided in inames. 
Defaults are Item1, Item2 etc. They are printed in the summary.</p>
</td></tr>
<tr><td><code id="dmm_+3A_dmm">dmm</code></td>
<td>
<p>Object of class <code>dmm</code>.</p>
</td></tr>
<tr><td><code id="dmm_+3A_precision">precision</code></td>
<td>
<p>Precision sets the number of digits to be printed in the
summary functions.</p>
</td></tr>
<tr><td><code id="dmm_+3A_se">se</code></td>
<td>
<p>Vector with standard errors, these are passed on from the 
summary.fit function if and when ses are available.</p>
</td></tr>
<tr><td><code id="dmm_+3A_specs">specs</code>, <code id="dmm_+3A_...">...</code></td>
<td>
<p>Internal use.</p>
</td></tr>
<tr><td><code id="dmm_+3A_object">object</code></td>
<td>
<p>An object of class <code>dmm</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The function <code>dmm</code> creates an object of class <code>dmm</code> and sets
random initial parameter values if these are not provided.  Even though
<code>dmm</code> is not a mixture of Markov models, the mixture parameter is
is included in the parameter vector.  This is important when specifying
constraints.  Parameters are ordered as follows: the first parameter(s)
are the mixing proportions of the mixture of Markov and/or latent class
models.  I.e., when a single latent class model or a single Markov
chain is fitted, this mixture proportion has value 1.0 and is it is
fixed in estimation.  After the mixing proportions, the next parameters
in the parameter vector are the transition matrix parameters, the
square of nstates in row-major order.  That is, first the transition
probabilities from state 1 to all the other states are given, then the
probabilities from state 2 to all the other states etc.  Next are the
observation matrix parameters.  These are provided consecutively for
each state/class.  Ie a trichtomous item model with two states has 6
observation parameters; the first three are the probabilities of
observing category 1, 2 and 3 respectively in state 1 (which sum to
one), and then similarly for state 2.  As another example: suppose we
have model for one binary item and one gaussian item, in that order, we
would have 4 observation parameters for each state, first the
probabilities of observing a symbol from category 1 or 2 in state 1,
the two parameters, the mean and standard deviation for state 1, and
then the same state 2 (see the example in fitdmm with data from rudy).
Finally the initial state probabilities are provided, in the order of
the states.  In the case of a latent class model or a finite mixture
model, these parameters are usually denote as the mixture proportions.
</p>
<p>Linear constraints can be set using arguments <code>conrows</code> and
<code>conpat</code>.  <code>conrows</code> must be contain nc by npars values, in
row major order, with nc the number of contraints to be specified.
<code>conrows</code> is used to define general linear constraints.  A row of
<code>conrows</code> must contain the partial derivatives of a general linear
constraint with respect to each of the parameters.  Suppose we want the
constraint x1 -2*x2=0, one row of conrows should contain a 1 in
position one and -2 in position and zeroes in the remaining positions.
In the function <code>mixdmm</code> <code>conrows</code> is understood to specify
linear constraints on the mixing proportions only.  As a consequence,
it is not possible to easily constrain parameters between components of
a mixture model.
</p>
<p><code>conpat</code> can be used as a shortcut for both fixed and conrows.  It
must be a single vector of length npars contaning 0's (zeroes) for
fixed parameters, 1's (ones) for free parameters and higher numbers for
possibly equality constrained parameters.  E.g.
<code>conpat=c(1,1,0,2,2,3,3,3)</code> would indicate that pars 1 and 2 are
freely estimated, par 3 is fixed at its startvalue (which must be
provided in this case), par 4 and 5 are to estimated equal and pars 6,
7 and 8 are also to be estimated equal.
</p>


<h3>Value</h3>

<p><code>dmm</code> returns an object of class <code>dmm</code> which has its own summary
method.  This will print the parameter values, itemtypes, number of (free)
parameters, and the number of states.  There is no print method.  Using
print will print all fields of the model which is a list of the following:
</p>
<table>
<tr><td><code>modname</code></td>
<td>
<p>See above.</p>
</td></tr>
<tr><td><code>nstates</code></td>
<td>
<p>See above</p>
</td></tr>
<tr><td><code>snames</code></td>
<td>
<p>See above.</p>
</td></tr>
<tr><td><code>nitems</code></td>
<td>
<p>The number of items(=length(itemtypes)).</p>
</td></tr>
<tr><td><code>itemtypes</code></td>
<td>
<p>See above.</p>
</td></tr>
<tr><td><code>inames</code></td>
<td>
<p>See above.</p>
</td></tr>
<tr><td><code>npars</code></td>
<td>
<p>The total parameter count of the model.</p>
</td></tr>
<tr><td><code>nparstotal</code></td>
<td>
<p>The total number of parameters of when the covariate 
parameters are included.</p>
</td></tr>
<tr><td><code>freepars</code></td>
<td>
<p>The number of freely estimated parameters (it is
computed as sum(as.logical(fixed))-rank(qr(A)).</p>
</td></tr>
<tr><td><code>freeparsnotd</code></td>
<td>
<p>The number of freely estimated parameters (it is
computed as sum(as.logical(fixed))-rank(qr(A)); this version without
the covariate parameters.</p>
</td></tr>
<tr><td><code>pars</code></td>
<td>
<p>A vector of length npars containing parameter values.</p>
</td></tr>
<tr><td><code>fixed</code></td>
<td>
<p><code>fixed</code> is a (logical) vector of length npars
specifying which parameters are fixed and which are not.</p>
</td></tr>
<tr><td><code>A</code></td>
<td>
<p>The matrix A contains the general linear constraints of the
model.  nrow(A) is the number of linear constraints.  A starts with a
number of rows for the sum constraints for the transition, observation
and initial state parameters, after which the user provided constraints
are added.</p>
</td></tr>
<tr><td><code>bu</code>, <code>bl</code></td>
<td>
<p>bu and bl represent the upper and lower bounds of the
parameters and the constraints.  These vectors are each of length npars
+ nrow(A).</p>
</td></tr>
<tr><td><code>bllin</code>, <code>bulin</code></td>
<td>
<p>The lower and upper bounds of the linear
constraints.</p>
</td></tr>
<tr><td><code>td</code>, <code>tdin</code>, <code>tdtr</code>, <code>tdob</code>, <code>tdfit</code></td>
<td>
<p>Logicals indicating whehter there
covariates, in which parameters they are, and whether they are
estimated or not (the latter is used to decide whether to print those
values or not).</p>
</td></tr>
<tr><td><code>st</code></td>
<td>
<p>Logical indicating whether the model has user specified
starting values.</p>
</td></tr>
</table>
<p><code>lca</code> returns an object of class <code>dmm, lca</code>, and is otherwise
identical to a <code>dmm</code> object. The only difference is that the
transition matrix parameters are irrelevant, and
consequently they are not printed in the summary function. 
</p>


<h3>Author(s)</h3>

<p>Ingmar Visser <a href="mailto:i.visser@uva.nl">i.visser@uva.nl</a></p>


<h3>References</h3>

<p>On hidden Markov models: Lawrence R. Rabiner (1989).  A tutorial on
hidden Markov models and selected applications in speech recognition.
<em>Proceedings of IEEE</em>, 77-2, p.  267-295.
</p>
<p>On latent class models: A. L. McCutcheon (1987).  <em>Latent class
analysis</em>.  Sage Publications.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mixdmm">mixdmm</a></code> on defining mixtures of <code>dmm</code>'s,
<code><a href="#topic+mgdmm">mgdmm</a></code> for defining multi group models, and
<code><a href="#topic+generate">generate</a></code> for generating data from models. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# create a 2 state model with one continuous and one binary response
# with start values provided in st
st &lt;- c(1,0.9,0.1,0.2,0.8,2,1,0.7,0.3,5,2,0.2,0.8,0.5,0.5)
mod &lt;- dmm(nsta=2,itemt=c(1,2), stval=st)
summary(mod)

# 2 class latent class model with equal conditional probabilities in each class
stv=c(1,rep(c(0.9,0.1),5),rep(c(0.1,0.9),5),0.5,0.5)
# here the conditional probs of the first item are set equal to those in
# the subsequent items
conpat=c(1,rep(c(2,3),5),rep(c(4,5),5),1,1)
lc=lca(ncl=2,itemtypes=rep(2,5),conpat=conpat,stv=stv)
summary(lc)

</code></pre>

<hr>
<h2 id='fitdmm'>Fitting Dependent Mixture Models</h2><span id='topic+depmix'></span><span id='topic+fitdmm'></span><span id='topic+loglike'></span><span id='topic+posterior'></span><span id='topic+computeSes'></span><span id='topic+bootstrap'></span><span id='topic+summary.fit'></span><span id='topic+oneliner'></span>

<h3>Description</h3>

<p><code>fitdmm</code> fits mixtures of hidden/latent Markov
models on arbitrary length time series of mixed categorical and
continuous data.  This includes latent class models and finite mixture
models (for time series of length 1), which are in effect independent
mixture models.
</p>
<p><code>posterior</code> computes the most likely
latent state sequence for a given dataset and model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	fitdmm(dat, dmm, printlevel = 1, poster = TRUE, tdcov = 0,
                 ses = TRUE, method = "optim", vfactor=15, der = 1, iterlim = 100,
                 kmst = !dmm$st, kmrep = 5, postst = FALSE)
	loglike(dat, dmm, tdcov = 0, grad = FALSE, hess = FALSE, set
                 = TRUE, grInd = 0, sca = 1, printlevel = 1)
	posterior(dat,dmm,tdcov=0,printlevel=1)
	computeSes(dat,dmm) 
	bootstrap(object,dat,samples=100, pvalonly=0,...)
	## S3 method for class 'fit'
summary(object, precision=3, fd=1, ...)
	oneliner(object,precision=3)
	
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitdmm_+3A_dat">dat</code></td>
<td>
<p> An object (or list of objects) of class <code>md</code>, see
markovdata.  If dat is a list of objects of class <code>md</code> a
multigroup model is fitted on these data sets.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_dmm">dmm</code></td>
<td>
<p> An object (or a list of objects) of class <code>dmm</code>, see
dmm.  If dmm is a list of objects of class <code>dmm</code>, these are taken
to components of a mixture of dmm's model and will be coerced to class
<code>mixdmm</code>.  In any case, the model that is fitted a multigroup
mixture of dmm's with default ngroups=1 and number of components=1.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_printlevel">printlevel</code></td>
<td>
<p><code>printlevel</code> controls the output provided by the
C-routines that are called to optimize the parameters.  The default of
1 provides minmal output: just the initial and final loglikelihood of
the model.  Setting higher values will provide more output on the
progress the iterations.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_poster">poster</code></td>
<td>
<p>By default posteriors are computed, the result of which
can be found in fit\$post.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_method">method</code></td>
<td>
<p>This is the optimization algorithm that is used.  donlp2
from the Rdonlp2 package is the default method.  There is optional
support for NPSOL.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_der">der</code></td>
<td>
<p>Specifies whether derivatives are to be used in optimization.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_vfactor">vfactor</code></td>
<td>
<p>vfactor controls optimization in optim and nlm. Since in 
those routines there is no possibility for enforcing constraints, 
constraints are enforced by adding a penalty term to the loglikelihood. 
The penalty term is printed at the end of optimization if it is not close
enough to zero. This may have several reasons. When parameters are 
estimated at bounds for example. This can be solved by fixing those 
parameters on their boundary values. When this is not acceptable vfactor 
may be increased such that the penalty is larger and the probability that 
they actually hold in the fitted model is correspondingly higher.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_tdcov">tdcov</code></td>
<td>
<p>Logical, when set to TRUE, given that the model and data have 
covariates, the corresponding parameters will be estimated.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_ses">ses</code></td>
<td>
<p>Logical, determines whether standard errors are computed after
optimization.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_iterlim">iterlim</code></td>
<td>
<p>The iteration limit for npsol, defaults to 100, which may
be too low for large models.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_grad">grad</code></td>
<td>
<p>logical; if TRUE the gradients are returned.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_hess">hess</code></td>
<td>
<p>logical; if TRUE the hessian is returned; it is not
implemented currently and hence setting it to true will produce a 
warning.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_set">set</code></td>
<td>
<p>Whith the default value TRUE, the data and models parameters
are sent to the C/C++ routines before computing the loglikelihood.
When set is FALSE, this is not done.  If an incorrect model was set
earlier in the C-routines this may cause serious errors and/or
crashes.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_sca">sca</code></td>
<td>
<p>If set to -1.0 the negative loglikelihood, gradients and
hessian are returned.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_object">object</code></td>
<td>
<p>An object of class <code>fit</code>, ie the return value of 
fitdmm.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_kmst">kmst</code>, <code id="fitdmm_+3A_postst">postst</code></td>
<td>
<p>These arguments control the generation of starting
values by kmeans and posterior estimates respectively.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_kmrep">kmrep</code></td>
<td>
<p>If no starting values are provided, <code>kmrep</code> sets of
starting values are generated using kmeans in appropriate cases. The
best resulting set of starting values is optimized further.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_grind">grInd</code></td>
<td>
<p>Logical argument; if TRUE, individual contributions of
each independent realization to the gradient vector will be returned.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_fd">fd</code></td>
<td>
<p>Print the finite difference based standard errors in the summary
if both those and bootstrapped standard errors are available.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_samples">samples</code></td>
<td>
<p>The number of samples to be used in bootstrapping.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_pvalonly">pvalonly</code></td>
<td>
<p>Logical, if 1 only a bootstrapped pvalue is returned and not 
fitted paramaters to compute standard errors, optimization is truncated
when the loglikelihood is better than the original loglikelihood.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_precision">precision</code></td>
<td>
<p>Precision sets the number of digits to be printed in the
summary functions.</p>
</td></tr>
<tr><td><code id="fitdmm_+3A_...">...</code></td>
<td>
<p>Used in summary.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>fitdmm</code> optimizes the parameters of a mixture of
<code>dmm</code>s using a general purpose optimization routine subject to linear
constraints on the parameters. 
</p>


<h3>Value</h3>

<p><code>fitdmm</code> returns an object of class <code>fit</code> which has a summary
method that prints the summary of the fitted model, and the following fields:
</p>
<table>
<tr><td><code>date</code>, <code>timeUsed</code>, <code>totMem</code></td>
<td>
<p>The date that the model was fitted, the
time it took to so and the memory usage.</p>
</td></tr>
<tr><td><code>loglike</code></td>
<td>
<p>The loglikelihood of the fitted model.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>The AIC of the fitted model.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>The BIC of the fitted model.</p>
</td></tr> 
<tr><td><code>mod</code></td>
<td>
<p>The fitted model.</p>
</td></tr>
<tr><td><code>post</code></td>
<td>
<p>See function posterior for details.</p>
</td></tr>
</table>
<p><code>loglike</code> returns a list of the following: 
</p>
<table>
<tr><td><code>logl</code></td>
<td>
<p>The loglikelihood.</p>
</td></tr>
<tr><td><code>gr</code>, <code>grset</code></td>
<td>
<p><code>gr</code> contains the gradients. <code>grset</code> is a logical vector
giving information as to which gradients are set, currently all gradients are set 
except the gradients for the mixing proportions.</p>
</td></tr>
<tr><td><code>hs</code>, <code>hsset</code></td>
<td>
<p><code>hs</code> contains the hessian. <code>hsset</code> is a logical giving 
information as to which elements are computed.</p>
</td></tr>
</table>
<p><code>posterior</code> returns lists of the following: 
</p>
<table>
<tr><td><code>states</code></td>
<td>
<p>A matrix of dimension 2+sum(nstates) by
sum(length(ntimes)) containing in the first column the a posteriori
component, in the second column the a posteriori state and in the
remaining column the posterior probabilities of all states.</p>
</td></tr>
<tr><td><code>comp</code></td>
<td>
<p>Contains the posterior component number for each
independent realization; all ones for a single component model.</p>
</td></tr>
</table>
<p><code>computeSes</code> returns a vector of length <code>npars</code> with the standard
errors and a matrix <code>hs</code> with the hessian used to compute them.  The
routine is not fail safe and can produce errors, ie when the (corrected)
hessian is singular; a warning is issued when the hessian is close to being
singular.
</p>
<p><code>bootstrap</code> returns an object of class <code>fit</code> with three extra
fields, the bootstrapped standard errors, bse, a matrix with
goodness-of-fit measures of the bootstrap samples, ie logl, AIC and BIC and
pbetter, which is the proportion of bootstrap samples that resulted in
better fits than the original model.
</p>
<p><code>summary.fit</code> pretty-prints the outputs.
</p>
<p><code>oneliner</code> returns a vector of loglike, aic, bic, mod$npars,
mod$freepars, date.
</p>


<h3>Note</h3>

<p><code>fitdmm</code> fits time series of arbitrary length and mixtures of
<code>dmm</code>s, where, to the best of my knowledge, other packages are limited
due to the different optimization routines that are commonly used for these
types of models.</p>


<h3>Author(s)</h3>

<p>Ingmar Visser <a href="mailto:i.visser@uva.nl">i.visser@uva.nl</a>, Development of this pacakge
was supported by European Commission grant 51652 (NEST) and by a VENI grant
from the Dutch Organization for Scientific Research (NWO).</p>


<h3>References</h3>

<p>Lawrence R. Rabiner (1989).  A tutorial on hidden Markov models and
selected applications in speech recognition.  <em>Proceedings of
IEEE</em>, 77-2, p.  267-295.
</p>
<p>Theodore C. Lystig and James P. Hughes (2002).  Exact computation of
the observed information matrix for hidden Markov models.
<em>Journal of Computational and Graphical Statistics</em>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dmm">dmm</a></code>,<code><a href="#topic+markovdata">markovdata</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# COMBINED RT AND CORRECT/INCORRECT SCORES from a 'switching' experiment

data(speed)
mod &lt;- dmm(nsta=2,itemt=c(1,2)) # gaussian and binary items
ll &lt;- loglike(speed,mod)
fit1 &lt;- fitdmm(dat=speed,dmm=mod)
summary(fit1)
ll &lt;- loglike(speed,fit1)

# bootstrap
## Not run: 
pst &lt;- posterior(dat=speed,dmm=fit1)
bs &lt;- bootstrap(fit1,speed,samples=50)

## End(Not run) # end not run


# add some constraints using conpat
conpat=rep(1,15)
conpat[1]=0
conpat[14:15]=0
conpat[8:9]=0
# use starting values from the previous model fit, except for the guessing 
# parameters which should really be 0.5
stv=c(1,.896,.104,.084,.916,5.52,.20,.5,.5,6.39,.24,.098,.90,0,1)
mod=dmm(nstates=2,itemt=c("n",2),stval=stv,conpat=conpat)

fit2 &lt;- fitdmm(dat=speed,dmm=mod)
summary(fit2)


# add covariates to the model to incorporate the fact the accuracy pay off changes per trial
# 2-state model with covariates + other constraints

## Not run: 

conpat=rep(1,15)
conpat[1]=0
conpat[8:9]=0
conpat[14:15]=0
conpat[2]=2
conpat[5]=2
stv=c(1,0.9,0.1,0.1,0.9,5.5,0.2,0.5,0.5,6.4,0.25,0.9,0.1,0,1)
tdfix=rep(0,15)
tdfix[2:5]=1
stcov=rep(0,15)
stcov[2:5]=c(-0.4,0.4,0.15,-0.15)

mod&lt;-dmm(nstates=2,itemt=c("n",2),stval=stv,conpat=conpat,tdfix=tdfix,tdst=stcov,
modname="twoboth+cov")

fit3 &lt;- fitdmm(dat=speed,dmm=mod,tdcov=1,der=0,ses=0,vfa=80)
summary(fit3)

# split the data into three time series
data(speed)
r1=markovdata(dat=speed[1:168,],item=itemtypes(speed))
r2=markovdata(dat=speed[169:302,],item=itemtypes(speed))
r3=markovdata(dat=speed[303:439,],item=itemtypes(speed))

# define 2-state model with constraints
conpat=rep(1,15)
conpat[1]=0
conpat[8:9]=0
conpat[14:15]=0
stv=c(1,0.9,0.1,0.1,0.9,5.5,0.2,0.5,0.5,6.4,0.25,0.9,0.1,0,1)
mod&lt;-dmm(nstates=2,itemt=c("n",2),stval=stv,conpat=conpat)

# define 3-group model with equal transition parameters, and no 
# equalities between the obser parameters
mgr &lt;-mgdmm(dmm=mod,ng=3,trans=TRUE,obser=FALSE)

fitmg &lt;- fitdmm(dat=list(r1,r2,r3),dmm=mgr)
summary(fitmg)


## End(Not run) # end not run

# LEARNING DATA AND MODELS (with absorbing states)

## Not run: 

data(discrimination)

# all or none model with error prob in the learned state
fixed = c(0,0,0,1,1,1,1,0,0,0,0)
stv = c(1,1,0,0.03,0.97,0.1,0.9,0.5,0.5,0,1)
allor &lt;- dmm(nstates=2,itemtypes=2,fixed=fixed,stval=stv,modname="All-or-none")

# Concept identification model: learning only after an error
st=c(1,1,0,0,0,0.5,0.5,0.5,0.25,0.25,0.05,0.95,0,1,1,0,0.25,0.375,0.375)
# fix some parameters
fx=rep(0,19)
fx[8:12]=1
fx[17:19]=1
# add a couple of constraints
conr1 &lt;- rep(0,19)
conr1[9]=1
conr1[10]=-1
conr2 &lt;- rep(0,19)
conr2[18]=1
conr2[19]=-1
conr3 &lt;- rep(0,19)
conr3[8]=1
conr3[17]=-2
conr=c(conr1,conr2,conr3)
cim &lt;- dmm(nstates=3,itemtypes=2,fixed=fx,conrows=conr,stval=st,modname="CIM")

# define a mixture of the above models ...
mix &lt;- mixdmm(dmm=list(allor,cim),modname="MixAllCim")

# ... and fit it on the combined data discrimination
fitmix &lt;- fitdmm(discrimination,mix)
summary(fitmix)


## End(Not run) # end not run

</code></pre>

<hr>
<h2 id='generate'>Generate data from a dependent mixture model</h2><span id='topic+generate'></span>

<h3>Description</h3>

<p><code>generate</code> generates a dataset according to a
given <code>dmm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	
	generate(ntimes,dmm,nreal=1) 

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_+3A_ntimes">ntimes</code></td>
<td>
<p>The number of repeated measurements, ie the length of the 
time series (this may be a vector containing the lengths of independent 
realiazations).</p>
</td></tr>
<tr><td><code id="generate_+3A_dmm">dmm</code></td>
<td>
<p>Object of class <code>dmm</code> or <code>mixdmm</code>.</p>
</td></tr>
<tr><td><code id="generate_+3A_nreal">nreal</code></td>
<td>
<p>The number of independent realizations that is to generated. 
Each of them will have the dimension of <code>ntimes</code>; all this does is
replace ntimes by rep(ntimes,nreal).</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p><code>generate</code> generates a date set of the specified dimensions
<code>ntimes</code> and <code>nreal</code> using the parameter values in
<code>dmm</code>, which should be an object of class <code>dmm</code> or
<code>mixdmm</code>.  <code>generate</code> does not handle multi group models,
which can be run separately.
</p>
<p>This function is used in the <code>bootstrap</code>'ping routine to compute
standard errors based on parametric bootstraps.
</p>


<h3>Value</h3>

<p>Generate returns an object of class <code><a href="#topic+markovdata">markovdata</a></code>.  The
return object has an attribute called instates, a vector with the starting
states of each realization.  When the model is a mixture the return has
another attribute <code>incomp</code> containing the components of each realization.
</p>


<h3>Author(s)</h3>

<p>Ingmar Visser <a href="mailto:i.visser@uva.nl">i.visser@uva.nl</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+dmm">dmm</a></code>, <code><a href="#topic+markovdata">markovdata</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
# create a 2 state model with one continuous and one binary response
# with start values provided in st
st &lt;- c(1,0.9,0.1,0.2,0.8,2,1,0.7,0.3,5,2,0.2,0.8,0.5,0.5)
mod &lt;- dmm(nsta=2,itemt=c(1,2), stval=st)

# generate two series of lengths 100 and 50 respectively using above model
gen&lt;-generate(c(100,50),mod)

summary(gen)
plot(gen)

</code></pre>

<hr>
<h2 id='markovdata'>Specifying Markov data objects</h2><span id='topic+markovdata'></span><span id='topic+summary.md'></span><span id='topic+plot.md'></span><span id='topic+print.md'></span><span id='topic+plot.ts2'></span><span id='topic+dname'></span><span id='topic+ntimes'></span><span id='topic+itemtypes'></span><span id='topic+replicates'></span><span id='topic+ncov'></span><span id='topic+inames'></span><span id='topic+nitems'></span><span id='topic+ind'></span>

<h3>Description</h3>

<p>Markovdata creates an object of class <code>md</code>, to be used 
by <code><a href="#topic+fitdmm">fitdmm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
	markovdata(dat, itemtypes, nitems = length(itemtypes), ntimes =
                 length(as.matrix(dat))/nitems, replicates = rep(1,
                 length(ntimes)), inames = NULL, dname = NULL, xm =
                 NA)
				 
	## S3 method for class 'md'
summary(object, ...)
	## S3 method for class 'md'
plot(x, nitems = 1:(min(5, dim(x)[2])), 
			nind = 1:(min(5,length(attributes(x)$ntimes))),...)
	## S3 method for class 'md'
print(x, ...) 
	
	dname(object)
	ntimes(object)
	itemtypes(object)
	replicates(object)
	
	ncov(object)
	inames(object)
	nitems(object)
	ind(object)
	
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="markovdata_+3A_dat">dat</code></td>
<td>
<p>An R object to be coerced to markovdata, a data frame or
matrix.</p>
</td></tr>
<tr><td><code id="markovdata_+3A_itemtypes">itemtypes</code></td>
<td>
<p>A vector providing the types of measurement with
possible values &lsquo;continuous&rsquo;, &lsquo;categorical&rsquo;, and
&lsquo;covariate&rsquo;.  This is mainly only used to rearrange the data
when there are covariates in such a way that the covariate is in the
last column.  Only one covariate is supported in estimation of models.</p>
</td></tr>
<tr><td><code id="markovdata_+3A_ntimes">ntimes</code></td>
<td>
<p>The number of repeated measurements, ie the length of the
time series (this may be a vector containing the lengths of independent
realiazations).  It defaults the number of rows of the data frame or
data matrix.</p>
</td></tr>
<tr><td><code id="markovdata_+3A_replicates">replicates</code></td>
<td>
<p>Using this argument case weights can be provided.
This is particularly usefull in eg latent class analysis with
categorical variables when there usually are huge numbers of
replicates, ie identical response patterns.  <code>depmix</code> computes the
raw data log likelihood for each case separately.  Thus, when there are
many replicates of a case a lot of computation time is saved by
specifying case weights instead of providing the full data set.</p>
</td></tr>
<tr><td><code id="markovdata_+3A_inames">inames</code></td>
<td>
<p>The names of items. These default to the column names of 
matrices or dataframes.</p>
</td></tr>
<tr><td><code id="markovdata_+3A_dname">dname</code></td>
<td>
<p>The name of the dataset, used in summary, print and plot
functions.</p>
</td></tr>
<tr><td><code id="markovdata_+3A_xm">xm</code></td>
<td>
<p><code>xm</code> is the missing data code.  It can be any value but
zero. Missing data are recoded into <code>NA</code>.</p>
</td></tr>
<tr><td><code id="markovdata_+3A_object">object</code>, <code id="markovdata_+3A_x">x</code></td>
<td>
<p>An object of class <code>md</code>.</p>
</td></tr>
<tr><td><code id="markovdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed on to plot and summary.</p>
</td></tr>
<tr><td><code id="markovdata_+3A_nitems">nitems</code>, <code id="markovdata_+3A_nind">nind</code></td>
<td>
<p>In the plot function, these arguments control which
data are to be plotted, ie nitems indicates a range of items, and nind
a range of realizations, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The function <code>markovdata</code> coerces a given data frame or matrix to be
an object of class <code>md</code> such that it can be used in
<code><a href="#topic+fitdmm">fitdmm</a></code>.  The <code>md</code> object has its own summary,
print and plot methods.
</p>
<p>The functions dname, itemtypes, ntimes, and replicates retrieve the
respective attributes with these names; similarly <code>ncov, nitems,
inames</code>, and <code>ind</code> retrieve the number of covariates, the number of
items (the number of columns of the data), the column names and the number
of <code>ind</code>ependent realizations respectively.
</p>


<h3>Value</h3>

<p> An <code>md</code>-object is a
matrix of dimensions sum(ntimes) by nitems, containing the
measured variables and covariates rearranged such that the
covariate appears in the last column. The column names are
<code>inames</code> and the matrix has three further attributes: 
</p>
<table>
<tr><td><code>dname</code></td>
<td>
<p>The name of the data set.</p>
</td></tr>	
<tr><td><code>itemtypes</code></td>
<td>
<p>See above.</p>
</td></tr>
<tr><td><code>ntimes</code></td>
<td>
<p>See above. This will be a vector computed as 
ntimes=rep(ntimes,nreal).</p>
</td></tr>
<tr><td><code>replicates</code></td>
<td>
<p>The number of replications of each case, used as
weigths in computing the log likelihood.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ingmar Visser <a href="mailto:i.visser@uva.nl">i.visser@uva.nl</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+dmm">dmm</a></code>, <code><a href="#topic+depmix">depmix</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
x=rnorm(100,10,2)
y=ifelse(runif(100)&lt;0.5,0,1)
z=matrix(c(x,y),100,2)
md=markovdata(z,itemtypes=c("cont","cat"))
summary(md)

data(speed)
summary(speed)
plot(speed,nind=2)

# split the data into three data sets 
# (to perform multi group analysis) 
r1=markovdata(dat=speed[1:168,],item=itemtypes(speed))
r2=markovdata(dat=speed[169:302,],item=itemtypes(speed))
r3=markovdata(dat=speed[303:439,],item=itemtypes(speed))
summary(r2)

</code></pre>

<hr>
<h2 id='mgdmm'>Multi group model specification</h2><span id='topic+mgdmm'></span><span id='topic+summary.mgd'></span>

<h3>Description</h3>

<p><code>mgdmm</code> creates an object of class <code>mgd</code>, a
multi-group model, from a given model of either class <code>dmm</code> or
class <code>mixdmm</code> or lists of these.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
	mgdmm(dmm,ng=1,modname=NULL,trans=FALSE,obser=FALSE,init=FALSE,conpat=NULL)
	## S3 method for class 'mgd'
summary(object, specs=FALSE, precision=3, se=NULL, ...)
	
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mgdmm_+3A_modname">modname</code></td>
<td>
<p>A character string with the name of the model, good when
fitting many models.  Components of mixture models keep their own
names.  Names are printed in the summary.  Boring default names are
provided.</p>
</td></tr>
<tr><td><code id="mgdmm_+3A_dmm">dmm</code></td>
<td>
<p>Object (or list of objects) of class <code>dmm</code>; 
see details below.</p>
</td></tr>
<tr><td><code id="mgdmm_+3A_ng">ng</code></td>
<td>
<p>Number of groups for a multigroup model.</p>
</td></tr>
<tr><td><code id="mgdmm_+3A_trans">trans</code>, <code id="mgdmm_+3A_obser">obser</code>, <code id="mgdmm_+3A_init">init</code></td>
<td>
<p>Logical arguments specify whether
<code>trans</code>ition parameters, <code>obser</code>vation parameters and
<code>init</code>ial state parameters should be estimated equal across
groups.</p>
</td></tr>
<tr><td><code id="mgdmm_+3A_conpat">conpat</code></td>
<td>
<p>Can be used to specify general linear constraints. 
See <code><a href="#topic+dmm">dmm</a></code> for details.</p>
</td></tr>
<tr><td><code id="mgdmm_+3A_precision">precision</code></td>
<td>
<p>Precision sets the number of digits to be printed in
the summary functions.</p>
</td></tr>
<tr><td><code id="mgdmm_+3A_se">se</code></td>
<td>
<p>Vector with standard errors, these are passed on from the 
summary.fit function if and when ses are available.</p>
</td></tr>
<tr><td><code id="mgdmm_+3A_specs">specs</code>, <code id="mgdmm_+3A_...">...</code></td>
<td>
<p>Internal use.</p>
</td></tr>
<tr><td><code id="mgdmm_+3A_object">object</code></td>
<td>
<p>An object of class <code>mgd</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The function <code>mgdmm</code> can be used to define an <code>mgd</code>-model or
multi group <code>dmm</code>.  Its default behavior is to create <code>ng</code>
copies of the <code>dmm</code> argument, thereby providing identical starting
values for each group's model.  If the <code>dmm</code> argument is a list of
models of length <code>ng</code>, the starting values of those models will be
used instead.  This may save quite some cpu time when fitting large
models by providing the parameter values of separately fitted models as
starting values.  Currently, <code>depmix</code> does not automatically
generate starting values for multi group models.
</p>


<h3>Value</h3>

<p><code>mgdmm</code> returns an object of class <code>mgd</code> which contains all the
fields of an object of class <code>dmm</code> and the following extra:
</p>
<table>
<tr><td><code>ng</code></td>
<td>
<p><code>ng</code> is the number of groups in the multigroup model.</p>
</td></tr>
<tr><td><code>mixmod</code></td>
<td>
<p><code>mixmod</code> is a list of length <code>ng</code> of <code>mixdmm</code> 
models for each group.</p>
</td></tr>
<tr><td><code>itemtypes</code></td>
<td>
<p>See above.</p>
</td></tr>
<tr><td><code>npars</code>, <code>freepars</code>, <code>pars</code>, <code>fixed</code>, <code>A</code>, <code>bl</code>, <code>bu</code></td>
<td>
<p>The same as above but now for
the combined model, here npars equals the sum of npars of the component
models plus the mixing proportions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ingmar Visser <a href="mailto:i.visser@uva.nl">i.visser@uva.nl</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+dmm">dmm</a></code> on defining single component models, and
<code><a href="#topic+mixdmm">mixdmm</a></code> for defining mixtures of <code>dmm</code>'s.</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# create a 2 state model with one continuous and one binary response
# with start values provided in st
st &lt;- c(1,0.9,0.1,0.2,0.8,2,1,0.7,0.3,5,2,0.2,0.8,0.5,0.5)
mod &lt;- dmm(nsta=2,itemt=c(1,2), stval=st)

# define 3-group model with equal transition parameters, and no 
# equalities between the obser parameters
mgr &lt;- mgdmm(dmm=mod,ng=3,trans=TRUE,obser=FALSE)
summary(mgr)

</code></pre>

<hr>
<h2 id='mixdmm'>Mixture of dmm's specification</h2><span id='topic+mixdmm'></span><span id='topic+summary.mixdmm'></span>

<h3>Description</h3>

<p><code>mixdmm</code> creates an object of class <code>mixdmm</code>,
ie a mixture of <code>dmm</code>'s, given a list of component models of class
<code>dmm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	
	mixdmm(dmm, modname=NULL, mixprop=NULL, conrows=NULL)
	## S3 method for class 'mixdmm'
summary(object, specs=FALSE, precision=3, se=NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixdmm_+3A_dmm">dmm</code></td>
<td>
<p>A list of <code>dmm</code> objects to form the mixture.</p>
</td></tr>
<tr><td><code id="mixdmm_+3A_modname">modname</code></td>
<td>
<p>A character string with the name of the model, good when 
fitting many models. Components of mixture models keep their own names. 
Names are printed in the summary. Boring default names are provided.</p>
</td></tr>
<tr><td><code id="mixdmm_+3A_conrows">conrows</code></td>
<td>
<p>Argument <code>conrows</code> can be used to specify general
constraints between parameters.</p>
</td></tr>
<tr><td><code id="mixdmm_+3A_mixprop">mixprop</code></td>
<td>
<p>Arugement <code>mixprop</code> can be used to set the initial
values of the mixing proportions of a mixture of <code>dmm</code>'s.</p>
</td></tr>
<tr><td><code id="mixdmm_+3A_precision">precision</code></td>
<td>
<p>Precision sets the number of digits to be printed in the
summary functions.</p>
</td></tr>
<tr><td><code id="mixdmm_+3A_object">object</code></td>
<td>
<p>An object of class <code>mixdmm</code>.</p>
</td></tr>
<tr><td><code id="mixdmm_+3A_specs">specs</code>, <code id="mixdmm_+3A_...">...</code></td>
<td>
<p>Internal use. Not functioning currently.</p>
</td></tr>
<tr><td><code id="mixdmm_+3A_se">se</code></td>
<td>
<p>Vector with standard errors, these are passed on from the 
summary.fit function if and when ses are available.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The function <code>mixdmm</code> can be used to define a mixture of
<code>dmm</code>'s by providing a list of such objects as argument to this
function. See the <code>dmm</code> helpfile on how to use the <code>conrows</code> 
argument. Note that it has to be of length <code>npars</code>, ie including
all parameters of the model and not just the mixing proportions. 
</p>


<h3>Value</h3>

<p><code>mixdmm</code> returns an object of class <code>mixdmm</code> which has the same
fields as a <code>dmm</code> object.  In addition it has the following fields:
</p>
<table>
<tr><td><code>nrcomp</code></td>
<td>
<p>The number of components of the mixture model.</p>
</td></tr>
<tr><td><code>mod</code></td>
<td>
<p>A list of the component models, that is a list of objects of
class <code>dmm</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ingmar Visser <a href="mailto:i.visser@uva.nl">i.visser@uva.nl</a></p>


<h3>See Also</h3>

<p><code><a href="#topic+dmm">dmm</a></code> on defining single component models, and
<code><a href="#topic+mgdmm">mgdmm</a></code> on defining multi group models.
See <code><a href="#topic+generate">generate</a></code> for generating data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# define component 1
# all or none model with error prob in the learned state
fixed = c(0,0,0,1,1,1,1,0,0,0,0)
stv = c(1,1,0,0.07,0.93,0.9,0.1,0.5,0.5,0,1)
allor &lt;- dmm(nstates=2,itemtypes=2,fixed=fixed,stval=stv,modname="All-or-none")

# define component 2
# Concept identification model: learning only after an error
st=c(1,1,0,0,0,0.5,0.5,0.5,0.25,0.25,0.8,0.2,1,0,0,1,0.25,0.375,0.375)
# fix some parameters
fx=rep(0,19)
fx[8:12]=1
fx[17:19]=1
# add a couple of constraints
conr1 &lt;- rep(0,19)
conr1[9]=1
conr1[10]=-1
conr2 &lt;- rep(0,19)
conr2[18]=1
conr2[19]=-1
conr3 &lt;- rep(0,19)
conr3[8]=1
conr3[17]=-2
conr=c(conr1,conr2,conr3)
cim &lt;- dmm(nstates=3,itemtypes=2,fixed=fx,conrows=conr,stval=st,modname="CIM")

# define a mixture of the above component models
mix &lt;- mixdmm(dmm=list(allor,cim),modname="MixAllCim")
summary(mix)

</code></pre>

<hr>
<h2 id='speed'>Speed Accuracy Switching Data</h2><span id='topic+speed'></span>

<h3>Description</h3>

<p>This data set is a bivariate series of reaction times and accuracy
scores of a single subject switching between slow and accurate responding
and fast guessing on a lexical decision task.  The slow and accurate
responding, and the fast guessing can be modelled using two states,
with a switching regime between them.  The dataset further contains a
third variable called Pacc, representing the relative pay-off for
accurate responding, which is on a scale of zero to one.  The value of
Pacc was varied during the experiment to induce the switching.
This data set is a subset of data from experiment 2 in <cite>Van der
Maas et al, 2005</cite>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(speed)</code></pre>


<h3>Format</h3>

<p>An object of class <code>markovdata</code>.</p>


<h3>Source</h3>

<p>Han L. J. Van der Maas, Conor V. Dolan and Peter C. M. Molenaar (2005),
Phase Transitions in the Trade-Off between Speed and Accuracy in Choice
Reaction Time Tasks.  <em>Manuscript in revision</em>. 
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
