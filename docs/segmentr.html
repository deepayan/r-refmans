<!DOCTYPE html><html><head><title>Help for package segmentr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {segmentr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#auto_penalize'><p>Penalize a likelihood function with a guessed penalty function</p></a></li>
<li><a href='#base_segment'><p>Base arguments for segment function</p></a></li>
<li><a href='#berlin'><p>Daily temperatures from weather stations in Berlin</p></a></li>
<li><a href='#calculate_likelihood'><p>Calculate a dataset's likelihood using change points of <code>segmentr</code> object</p></a></li>
<li><a href='#exactalg'><p>Segment data into exact change points</p></a></li>
<li><a href='#hieralg'><p>Segment data into change points assuming hierarchical structure</p></a></li>
<li><a href='#hybridalg'><p>Segment data into change points using a mixed hierarchical-exact approach</p></a></li>
<li><a href='#multivariate'><p>Efficient Logarithmic Discrete Multivariate Likelihood estimation</p></a></li>
<li><a href='#print.segmentr'><p>Print a segmentr object</p></a></li>
<li><a href='#r_multivariate'><p>Logarithmic Discrete Multivariate Likelihood estimation function implemented</p>
in R</a></li>
<li><a href='#segment'><p>Segment data into change points</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Segment Data With Maximum Likelihood</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thales Mello &lt;thalesmello@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Given a likelihood provided by the user, this package applies it
    to a given matrix dataset in order to find change points in the data that
    maximize the sum of the likelihoods of all the segments. This package provides
    a handful of algorithms with different time complexities and assumption compromises
    so the user is able to choose the best one for the problem at hand. The implementation
    of the segmentation algorithms in this package are based on the paper by Bruno M. de Castro,
	Florencia Leonardi (2018) &lt;<a href="https://arxiv.org/abs/1501.01756">arXiv:1501.01756</a>&gt;. The Berlin
	weather sample dataset was provided by Deutscher Wetterdienst <a href="https://dwd.de/">https://dwd.de/</a>.
	You can find all the references in the Acknowledgments section of this package's
	repository via the URL below.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.16), foreach, glue</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, doParallel, knitr, rmarkdown, tidyr, tibble, dplyr,
lubridate, magrittr, rdwd, purrr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/thalesmello/segmentr">https://github.com/thalesmello/segmentr</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-08-28 20:36:43 UTC; thales</td>
</tr>
<tr>
<td>Author:</td>
<td>Thales Mello [aut, cre, cph],
  Florencia Leonardi [aut, cph, ths],
  Bruno M. de Castro [cph],
  Deutscher Wetterdienst [cph]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-08-28 21:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='auto_penalize'>Penalize a likelihood function with a guessed penalty function</h2><span id='topic+auto_penalize'></span>

<h3>Description</h3>

<p>Given a dataset, a likelihood function and penalty parameters on how to
penalize big and small segments, this function makes an educated guess
on a penalty function for the likelihood function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auto_penalize(data, likelihood, big_segment_penalty = 10,
  small_segment_penalty = 10)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auto_penalize_+3A_data">data</code></td>
<td>
<p>dataset to be segmented by the <code><a href="#topic+segment">segment()</a></code> function</p>
</td></tr>
<tr><td><code id="auto_penalize_+3A_likelihood">likelihood</code></td>
<td>
<p>function to be maximized using the <code><a href="#topic+segment">segment()</a></code> function.
It's used to find out the scale of the values in the segment function</p>
</td></tr>
<tr><td><code id="auto_penalize_+3A_big_segment_penalty">big_segment_penalty</code></td>
<td>
<p>penalty factor for big segments. The bigger it is, the bigger the penalty on big segments. Must be greater than or equal to 1. Penalty on big segments is constant when it's equal to 1. Default: 10</p>
</td></tr>
<tr><td><code id="auto_penalize_+3A_small_segment_penalty">small_segment_penalty</code></td>
<td>
<p>penalty factor for small segments. The bigger it is, the bigger the penalty on small segments. Must be greater than or equal to 1. Penalty on small segments is constant when it's equal to 1. Default: 10</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function tries to fit a sum of two exponential functions to values inferred
from the dataset and the likelihood function. The model for the penalty function
we try to fit is in the form:
</p>
<p style="text-align: center;"><code class="reqn">C1 exp(s1(x - L/2)) + C2 exp(s2(-x + L/2))</code>
</p>

<p>In the equation, <code class="reqn">C1</code> and <code class="reqn">s1</code> are, respectively,
a multiplier constant and an exponential scale modifier for small segments,
whereas <code class="reqn">C2</code> and <code class="reqn">s2</code> are the equivalent ones for
big segments. <code class="reqn">L</code> is the number of columns in the <code>data</code> matrix.
</p>
<p>Assuming the penalty function to be as such, the parameters are estimated
considering the scale of values yielded by the likelihood function for small
and big segments, also taking into account the <code>big_segment_penalty</code> and
<code>small_segment_penalty</code> tuning parameters, which can be used to adjust
the effect of the penalty function over big and small segments, respectively.
</p>


<h3>Value</h3>

<p>the likelihood function with the guessed penalty function applied
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
penalized_likelihood &lt;- auto_penalize(berlin, multivariate)

## End(Not run)
</code></pre>

<hr>
<h2 id='base_segment'>Base arguments for segment function</h2><span id='topic+base_segment'></span>

<h3>Description</h3>

<p>Describe base arguments for segment function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>base_segment(data, likelihood, max_segments, allow_parallel)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="base_segment_+3A_data">data</code></td>
<td>
<p>matrix for which to find the change points</p>
</td></tr>
<tr><td><code id="base_segment_+3A_likelihood">likelihood</code></td>
<td>
<p>a function receives the segment matrix as argument
and returns a likelihood estimation. This function is used to calculate the
change points that maximize the total likelihood. Depending on the algorithm
being used, this function is likely to be executed many times, in which
case it's also likely to be the bottleneck of the function execution, so
it's advised that this function should have fast implementation.</p>
</td></tr>
<tr><td><code id="base_segment_+3A_max_segments">max_segments</code></td>
<td>
<p>an integer that defines the maximum amount of segments to
split the data into.</p>
</td></tr>
<tr><td><code id="base_segment_+3A_allow_parallel">allow_parallel</code></td>
<td>
<p>allows parallel execution to take place using the
registered cluster. Assumes a cluster is registered with the <code>foreach</code>
package. Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list of type <code>segmentr</code>, which has the two attributes:
</p>

<ul>
<li> <p><code>changepoints</code>: a vector with the first index of each identified change point
</p>
</li>
<li> <p><code>segments</code>: a list of vectors, in which each vector corresponds to the indices
that identifies a segment.
</p>
</li></ul>


<hr>
<h2 id='berlin'>Daily temperatures from weather stations in Berlin</h2><span id='topic+berlin'></span>

<h3>Description</h3>

<p>Contains weather daily weather data from many <a href="https://dwd.de/">Deutscher Wetterdienst</a>
weather stations in Berlin from the years of 2010 and 2011. Data was obtained using the
package <a href="https://CRAN.R-project.org/package=rdwd">rdwd</a>
and reformatted to a format appropriate to be used for analysis in this object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>berlin
</code></pre>


<h3>Format</h3>

<p>A matrix containing daily temperatures, with each column representing
a date and each column representing a weather station in Berlin
</p>

<dl>
<dt>rows</dt><dd></dd>
<dt>columns</dt><dd><p>dates from the years 2010 and 2011</p>
</dd>
</dl>
<p>...
</p>


<h3>Source</h3>

<p><a href="https://www.dwd.de/DE/Home/home_node.html">https://www.dwd.de/DE/Home/home_node.html</a>
</p>

<hr>
<h2 id='calculate_likelihood'>Calculate a dataset's likelihood using change points of <code>segmentr</code> object</h2><span id='topic+calculate_likelihood'></span>

<h3>Description</h3>

<p>Given the change points in a segmentr object, this function splits a
new dataset into segments and then calculates the total likelihood
using the likelihood function of the <code>segmentr</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate_likelihood(results, newdata, likelihood)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate_likelihood_+3A_results">results</code></td>
<td>
<p>a segmentr object, which contains the definition of the change points to be applied</p>
</td></tr>
<tr><td><code id="calculate_likelihood_+3A_newdata">newdata</code></td>
<td>
<p>a dataset for which we wish to calculate the total likelihood</p>
</td></tr>
<tr><td><code id="calculate_likelihood_+3A_likelihood">likelihood</code></td>
<td>
<p>a likelihood function to be used to calculate the likelihood of each segment</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function splits a <code>newdata</code> dataset into segments according to the
change points in the <code>results</code> segmentr object. It then uses the <code>likelihood</code>
function of the segmentr object to calculate the total likelihood of the new object.
</p>

<hr>
<h2 id='exactalg'>Segment data into exact change points</h2><span id='topic+exactalg'></span>

<h3>Description</h3>

<p>Find changes points in data calculating the penalized likelihood for all possible
segment combinations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exactalg(data, likelihood, max_segments = ncol(data),
  allow_parallel = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exactalg_+3A_data">data</code></td>
<td>
<p>matrix for which to find the change points</p>
</td></tr>
<tr><td><code id="exactalg_+3A_likelihood">likelihood</code></td>
<td>
<p>a function receives the segment matrix as argument
and returns a likelihood estimation. This function is used to calculate the
change points that maximize the total likelihood. Depending on the algorithm
being used, this function is likely to be executed many times, in which
case it's also likely to be the bottleneck of the function execution, so
it's advised that this function should have fast implementation.</p>
</td></tr>
<tr><td><code id="exactalg_+3A_max_segments">max_segments</code></td>
<td>
<p>an integer that defines the maximum amount of segments to
split the data into.</p>
</td></tr>
<tr><td><code id="exactalg_+3A_allow_parallel">allow_parallel</code></td>
<td>
<p>allows parallel execution to take place using the
registered cluster. Assumes a cluster is registered with the <code>foreach</code>
package. Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function that implements the dynamic programming algorithm, with the intent
of finding points of independent change points for which the likelihood
function is maximized. It analyzes all possible combinations, returning the
change points that are guaranteed to segment the data matrix in the maximum
likelihood independent change points. Because it analyzes all possible combinations
of change points, it has a O-squared algorithm complexity, meaning it works
in an acceptable computation time for small datasets, but it takes quite
longer for datasets with many columns. For big datasets, <code><a href="#topic+hieralg">hieralg()</a></code> might
be more adequate.
</p>


<h3>Value</h3>

<p>a list of type <code>segmentr</code>, which has the two attributes:
</p>

<ul>
<li> <p><code>changepoints</code>: a vector with the first index of each identified change point
</p>
</li>
<li> <p><code>segments</code>: a list of vectors, in which each vector corresponds to the indices
that identifies a segment.
</p>
</li></ul>


<hr>
<h2 id='hieralg'>Segment data into change points assuming hierarchical structure</h2><span id='topic+hieralg'></span>

<h3>Description</h3>

<p>By assuming change points follow an hierarchical architecture, this architecture
manages to run faster by not searching all possible branches
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hieralg(data, likelihood, max_segments = ncol(data),
  allow_parallel = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hieralg_+3A_data">data</code></td>
<td>
<p>matrix for which to find the change points</p>
</td></tr>
<tr><td><code id="hieralg_+3A_likelihood">likelihood</code></td>
<td>
<p>a function receives the segment matrix as argument
and returns a likelihood estimation. This function is used to calculate the
change points that maximize the total likelihood. Depending on the algorithm
being used, this function is likely to be executed many times, in which
case it's also likely to be the bottleneck of the function execution, so
it's advised that this function should have fast implementation.</p>
</td></tr>
<tr><td><code id="hieralg_+3A_max_segments">max_segments</code></td>
<td>
<p>an integer that defines the maximum amount of segments to
split the data into.</p>
</td></tr>
<tr><td><code id="hieralg_+3A_allow_parallel">allow_parallel</code></td>
<td>
<p>allows parallel execution to take place using the
registered cluster. Assumes a cluster is registered with the <code>foreach</code>
package. Defaults to TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Fast algorithm that segments data into change points, and it does so by
simplifying by reducing the search possibilities by assuming data split in an
hierarchical structure, i.e. a segment found in a first trial is assumed to
contain only segments independent of the rest of the data. This algorithm
usually runs very fast, but is known to yield less accurate results, possibly
not finding the exact change points that would maximize likelihood.
</p>


<h3>Value</h3>

<p>a list of type <code>segmentr</code>, which has the two attributes:
</p>

<ul>
<li> <p><code>changepoints</code>: a vector with the first index of each identified change point
</p>
</li>
<li> <p><code>segments</code>: a list of vectors, in which each vector corresponds to the indices
that identifies a segment.
</p>
</li></ul>


<hr>
<h2 id='hybridalg'>Segment data into change points using a mixed hierarchical-exact approach</h2><span id='topic+hybridalg'></span>

<h3>Description</h3>

<p>For the larger datasets, assume the data is hierarchical, but calculate
the exact segments when they're smaller than a threshold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hybridalg(data, likelihood, allow_parallel = TRUE,
  max_segments = ncol(data), threshold = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hybridalg_+3A_data">data</code></td>
<td>
<p>matrix for which to find the change points</p>
</td></tr>
<tr><td><code id="hybridalg_+3A_likelihood">likelihood</code></td>
<td>
<p>a function receives the segment matrix as argument
and returns a likelihood estimation. This function is used to calculate the
change points that maximize the total likelihood. Depending on the algorithm
being used, this function is likely to be executed many times, in which
case it's also likely to be the bottleneck of the function execution, so
it's advised that this function should have fast implementation.</p>
</td></tr>
<tr><td><code id="hybridalg_+3A_allow_parallel">allow_parallel</code></td>
<td>
<p>allows parallel execution to take place using the
registered cluster. Assumes a cluster is registered with the <code>foreach</code>
package. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="hybridalg_+3A_max_segments">max_segments</code></td>
<td>
<p>an integer that defines the maximum amount of segments to
split the data into.</p>
</td></tr>
<tr><td><code id="hybridalg_+3A_threshold">threshold</code></td>
<td>
<p>the threshold for which the exact algorithm will be used,
i.e. when the number of columns in the segment is less than or equal to the
threshold.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This algorithm implements an approach mixing the hierarchical and exact
algorithms. It uses the hierarchical algorithms when the size of the segment
is bigger than the threshold, and then goes on to use the exact algorithm
when the size of the segment is less than or equal to the threshold.
</p>


<h3>Value</h3>

<p>a list of type <code>segmentr</code>, which has the two attributes:
</p>

<ul>
<li> <p><code>changepoints</code>: a vector with the first index of each identified change point
</p>
</li>
<li> <p><code>segments</code>: a list of vectors, in which each vector corresponds to the indices
that identifies a segment.
</p>
</li></ul>


<hr>
<h2 id='multivariate'>Efficient Logarithmic Discrete Multivariate Likelihood estimation</h2><span id='topic+multivariate'></span>

<h3>Description</h3>

<p>Estimate the likelihood of a given segment using the discrete multivariate
estimation, implemented efficiently in C++
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multivariate(data, na_action = function(d) d[, colSums(is.na(d)) == 0,
  drop = FALSE])
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multivariate_+3A_data">data</code></td>
<td>
<p>Matrix to estimate the multivariate of. Each row is considered to
be an observation, and each column is considered to be a different
variable.</p>
</td></tr>
<tr><td><code id="multivariate_+3A_na_action">na_action</code></td>
<td>
<p>A function that is applied to the <code>data</code> parameter. Defaults to
removing columns with NA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculates the discrete log likelihood multivariate estimation of a data
matrix using an algorithm implemented in C++ for performance. This is
intended to be used in conjunction with <code><a href="#topic+segment">segment()</a></code>, as the log likelihood
function is executed multiple times, which makes it the bottleneck of the
computation. Because the multivariate is so commonly used, this efficient
implementation is provided.
</p>


<h3>Value</h3>

<p>the estimate of the Discrete Maximum Likelihood for the dataframe
provided.
</p>

<hr>
<h2 id='print.segmentr'>Print a segmentr object</h2><span id='topic+print.segmentr'></span>

<h3>Description</h3>

<p>Prints a short description of the segments found in the <code>segmentr</code> object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'segmentr'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.segmentr_+3A_x">x</code></td>
<td>
<p>an object of type segmentr, containing change point information</p>
</td></tr>
<tr><td><code id="print.segmentr_+3A_...">...</code></td>
<td>
<p>further arguments to be passed down to other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A short representation of the segments is printed on the screen, using the
<code>start:end</code> range notation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>make_segment &lt;- function(n, p) matrix(rbinom(100 * n, 1, p), nrow = 100)
data &lt;- cbind(make_segment(5, 0.1), make_segment(10, 0.9), make_segment(2, 0.1))
mean_lik &lt;- function(X) abs(mean(X) - 0.5) * ncol(X)^2
x &lt;- segment(data, likelihood = mean_lik, algorithm = "hieralg")
print(x)
</code></pre>

<hr>
<h2 id='r_multivariate'>Logarithmic Discrete Multivariate Likelihood estimation function implemented
in R</h2><span id='topic+r_multivariate'></span>

<h3>Description</h3>

<p>Estimate the likelihood of a given segment using the discrete multivariate
estimation, but code runs more slowly due to R implementation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r_multivariate(data, na.omit = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r_multivariate_+3A_data">data</code></td>
<td>
<p>Matrix to estimate the multivariate of. Each row is considered to
be an observation, and each column is considered to be a different
variable.</p>
</td></tr>
<tr><td><code id="r_multivariate_+3A_na.omit">na.omit</code></td>
<td>
<p>If true, omits NAs from the dataset.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This log likelihood function is implemented in R in order to be used to
benchmark against the <code><a href="#topic+multivariate">multivariate()</a></code> version implemented in C++ for
performance.
</p>


<h3>Value</h3>

<p>The estimate of the Discrete Maximum Likelihood for the dataframe
provided.
</p>

<hr>
<h2 id='segment'>Segment data into change points</h2><span id='topic+segment'></span>

<h3>Description</h3>

<p>Generic function to segment data into separate change points according to
specified algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>segment(data, likelihood, max_segments = ncol(data),
  allow_parallel = TRUE, algorithm = "exact", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="segment_+3A_data">data</code></td>
<td>
<p>matrix for which to find the change points</p>
</td></tr>
<tr><td><code id="segment_+3A_likelihood">likelihood</code></td>
<td>
<p>a function receives the segment matrix as argument
and returns a likelihood estimation. This function is used to calculate the
change points that maximize the total likelihood. Depending on the algorithm
being used, this function is likely to be executed many times, in which
case it's also likely to be the bottleneck of the function execution, so
it's advised that this function should have fast implementation.</p>
</td></tr>
<tr><td><code id="segment_+3A_max_segments">max_segments</code></td>
<td>
<p>an integer that defines the maximum amount of segments to
split the data into.</p>
</td></tr>
<tr><td><code id="segment_+3A_allow_parallel">allow_parallel</code></td>
<td>
<p>allows parallel execution to take place using the
registered cluster. Assumes a cluster is registered with the <code>foreach</code>
package. Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="segment_+3A_algorithm">algorithm</code></td>
<td>
<p>can be of type <code>exact</code>, <code>hierarchical</code> or <code>hybrid</code>, Default: <code>exact</code></p>
</td></tr>
<tr><td><code id="segment_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to the underlying function</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used as a generic function to call any of the algorithms implemented
by the package. Depending on the type of data the user wants to segment, one algorithm
might be more adequate than the others.
</p>


<h3>Value</h3>

<p>a list of type <code>segmentr</code>, which has the two attributes:
</p>

<ul>
<li> <p><code>changepoints</code>: a vector with the first index of each identified change point
</p>
</li>
<li> <p><code>segments</code>: a list of vectors, in which each vector corresponds to the indices
that identifies a segment.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+exactalg">exactalg()</a></code> for the exact algorithm, <code><a href="#topic+hieralg">hieralg()</a></code> for the
hierarchical algorithm implementation, <code><a href="#topic+hybridalg">hybridalg()</a></code> for the hybrid
algorithm implementation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
make_segment &lt;- function(n, p) matrix(rbinom(100 * n, 1, p), nrow = 100)
data &lt;- cbind(make_segment(5, 0.1), make_segment(10, 0.9), make_segment(2, 0.1))
mean_lik &lt;- function(X) abs(mean(X) - 0.5) * ncol(X)^2
segment(data, likelihood = mean_lik, algorithm = "hieralg")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
