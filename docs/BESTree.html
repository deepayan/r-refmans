<!DOCTYPE html><html><head><title>Help for package BESTree</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {BESTree}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Acc'><p>Computes the proportion of matching terms in two vectors of the same length.</p>
Used to compute the accuracy for prediction on test set.</a></li>
<li><a href='#BaggedBEST'><p>Performs Bootstrap Aggregating of BEST trees</p></a></li>
<li><a href='#BEST'><p>Main function of the package.</p>
It produces Classification Trees with Branch-Exclusive variables.</a></li>
<li><a href='#BESTForest'><p>Generates a random forest of BEST trees</p></a></li>
<li><a href='#Data'><p>Data generated according to decision tree for simulation purposes</p></a></li>
<li><a href='#Fit'><p>Data generated according to decision tree for simulation purposes</p></a></li>
<li><a href='#ForgeVA'><p>Quickly build the Available Variable list necessary for BEST</p>
This list contains details as to which variables is available for the partitioning.
It also contains which variables are gating variables.</a></li>
<li><a href='#FPredict'><p>Emits prediction from a forest of BEST's</p></a></li>
<li><a href='#MPredict'><p>Classify a set of new observation points</p></a></li>
<li><a href='#Predict'><p>Classify a new observation point</p></a></li>
<li><a href='#TreePruning'><p>Uses a Validation Set to select the best trees within the list of pruned trees.</p></a></li>
<li><a href='#VI'><p>Produces a variable important analysis using the mean decrease in node impurity</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Branch-Exclusive Splits Trees</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.2</td>
</tr>
<tr>
<td>Description:</td>
<td>Decision tree algorithm with a major feature added. Allows for users to define an ordering on the partitioning process.
    Resulting in Branch-Exclusive Splits Trees (BEST). Cedric Beaulac and Jeffrey S. Rosentahl (2019) &lt;<a href="https://doi.org/10.48550/arXiv.1804.10168">doi:10.48550/arXiv.1804.10168</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>plyr, compiler, utils, stats</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-08-08 16:22:38 UTC; The Beast</td>
</tr>
<tr>
<td>Author:</td>
<td>Beaulac Cedric [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Beaulac Cedric &lt;cedric@utstat.toronto.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-08-09 11:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='Acc'>Computes the proportion of matching terms in two vectors of the same length.
Used to compute the accuracy for prediction on test set.</h2><span id='topic+Acc'></span>

<h3>Description</h3>

<p>Computes the proportion of matching terms in two vectors of the same length.
Used to compute the accuracy for prediction on test set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Acc(Vec1, Vec2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Acc_+3A_vec1">Vec1</code></td>
<td>
<p>A vector of labels</p>
</td></tr>
<tr><td><code id="Acc_+3A_vec2">Vec2</code></td>
<td>
<p>Another vector of labels</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Percentage of identical labels (accuracy)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>Vec1 &lt;- c(1,1,2,3,1)
Vec2 &lt;- c(1,2,2,3,1)
Acc(Vec1,Vec2)
</code></pre>

<hr>
<h2 id='BaggedBEST'>Performs Bootstrap Aggregating of BEST trees</h2><span id='topic+BaggedBEST'></span>

<h3>Description</h3>

<p>Performs Bootstrap Aggregating of BEST trees
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BaggedBEST(Data, VA, NoT = 50, Size = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BaggedBEST_+3A_data">Data</code></td>
<td>
<p>A data set (Data Frame): Can take on both numerical and categorical predictors. Last column of the data set must be the Repsonse Variable (Categorical Variables only)</p>
</td></tr>
<tr><td><code id="BaggedBEST_+3A_va">VA</code></td>
<td>
<p>Variable Availability structure</p>
</td></tr>
<tr><td><code id="BaggedBEST_+3A_not">NoT</code></td>
<td>
<p>Number of Trees in the bag</p>
</td></tr>
<tr><td><code id="BaggedBEST_+3A_size">Size</code></td>
<td>
<p>Minimal Number of Observation within a leaf needed for partitionning (default is 50)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of BEST Objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
Data &lt;- BESTree::Data[1:n,]
d &lt;- ncol(Data)-1
VA &lt;- ForgeVA(d,1,0,0,0)
Size &lt;- 50
NoT &lt;- 10
Fit &lt;- BESTree::BaggedBEST(Data,VA,NoT,Size)
</code></pre>

<hr>
<h2 id='BEST'>Main function of the package.
It produces Classification Trees with Branch-Exclusive variables.</h2><span id='topic+BEST'></span>

<h3>Description</h3>

<p>Main function of the package.
It produces Classification Trees with Branch-Exclusive variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BEST(Data, Size, VA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BEST_+3A_data">Data</code></td>
<td>
<p>A data set (Data Frame): Can take on both numerical and categorical predictors. Last column of the data set must be the Repsonse Variable (Categorical Variables only)</p>
</td></tr>
<tr><td><code id="BEST_+3A_size">Size</code></td>
<td>
<p>Minimal Number of Observation within a leaf needed for partitionning</p>
</td></tr>
<tr><td><code id="BEST_+3A_va">VA</code></td>
<td>
<p>Variable Availability structure</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A BEST object with is a list containing the resulting tree, row numbers for each regions and the split points
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 1000
Data &lt;- BESTree::Data[1:n,]
d &lt;- ncol(Data)-1
VA &lt;- ForgeVA(d,1,0,0,0)
Size &lt;- 50
Fit &lt;- BESTree::BEST(Data,Size,VA)
</code></pre>

<hr>
<h2 id='BESTForest'>Generates a random forest of BEST trees</h2><span id='topic+BESTForest'></span>

<h3>Description</h3>

<p>Generates a random forest of BEST trees
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BESTForest(Data, VA, NoT = 50, Size = 50)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BESTForest_+3A_data">Data</code></td>
<td>
<p>A data set (Data Frame): Can take on both numerical and categorical predictors. Last column of the data set must be the Repsonse Variable (Categorical Variables only)</p>
</td></tr>
<tr><td><code id="BESTForest_+3A_va">VA</code></td>
<td>
<p>Variable Availability structure</p>
</td></tr>
<tr><td><code id="BESTForest_+3A_not">NoT</code></td>
<td>
<p>Number of Trees in the bag</p>
</td></tr>
<tr><td><code id="BESTForest_+3A_size">Size</code></td>
<td>
<p>Minimal Number of Observation within a leaf needed for partitionning (default is 50)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of BEST Objects (Random Forest)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
Data &lt;- BESTree::Data[1:n,]
d &lt;- ncol(Data)-1
VA &lt;- ForgeVA(d,1,0,0,0)
Size &lt;- 50
NoT &lt;- 10
Fit &lt;- BESTree::BESTForest(Data,VA,NoT,Size)
</code></pre>

<hr>
<h2 id='Data'>Data generated according to decision tree for simulation purposes</h2><span id='topic+Data'></span>

<h3>Description</h3>

<p>Data generated according to decision tree for simulation purposes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Data
</code></pre>


<h3>Format</h3>

<p>A data frame with 10000 rows and 5 variables:
</p>

<dl>
<dt>X_1</dt><dd><p>Binary predictor</p>
</dd>
<dt>X_2</dt><dd><p>Binary predictor</p>
</dd>
<dt>X_3</dt><dd><p>Continuous predictor between 0 and 1</p>
</dd>
<dt>X_4</dt><dd><p>Continuous predictor between 0 and 1</p>
</dd>
<dt>Y</dt><dd><p>The response variable</p>
</dd>
</dl>
<p>...
</p>

<hr>
<h2 id='Fit'>Data generated according to decision tree for simulation purposes</h2><span id='topic+Fit'></span>

<h3>Description</h3>

<p>Data generated according to decision tree for simulation purposes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Fit
</code></pre>


<h3>Format</h3>

<p>A typical list produced by the BEST function:
</p>

<dl>
<dt>1</dt><dd><p>Tree structure indicating spliting variables, impurity of the region and split variable</p>
</dd>
<dt>2</dt><dd><p>List of splitting values</p>
</dd>
<dt>3</dt><dd><p>Observaton numbers in the respective regions</p>
</dd>
</dl>
<p>...
</p>

<hr>
<h2 id='ForgeVA'>Quickly build the Available Variable list necessary for BEST
This list contains details as to which variables is available for the partitioning.
It also contains which variables are gating variables.</h2><span id='topic+ForgeVA'></span>

<h3>Description</h3>

<p>Quickly build the Available Variable list necessary for BEST
This list contains details as to which variables is available for the partitioning.
It also contains which variables are gating variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ForgeVA(d, GV, BEV, Thresh = 0.5, Direc = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ForgeVA_+3A_d">d</code></td>
<td>
<p>Number of predictors</p>
</td></tr>
<tr><td><code id="ForgeVA_+3A_gv">GV</code></td>
<td>
<p>Gating variables</p>
</td></tr>
<tr><td><code id="ForgeVA_+3A_bev">BEV</code></td>
<td>
<p>Branch-Exclusive Variables</p>
</td></tr>
<tr><td><code id="ForgeVA_+3A_thresh">Thresh</code></td>
<td>
<p>Threshold for Gates</p>
</td></tr>
<tr><td><code id="ForgeVA_+3A_direc">Direc</code></td>
<td>
<p>Direction of Gates ( 1 means add variable if bigger than thresh)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The list containing the Variable Availability structure
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This function can be used to set up the variable availability structure.
#Suppose we want to fit a regular decision tree on a data set containing d predictors
d &lt;- 10
VA &lt;- ForgeVA(d,1,0,0,0)
#Suppose now that predictor x5 is a binary gating variable for x4
#such that x4 is available if x5 = 1
GV &lt;- 5 #The gating variable
BEV &lt;- 4 #The Branch-Exclusive variable
Tresh = 0.5 #Value between 0 and 1
Direc = 1 #X4 is available if X5 is bigger than Tresh
VA &lt;- ForgeVA(d,GV,BEV,Tresh,Direc)
</code></pre>

<hr>
<h2 id='FPredict'>Emits prediction from a forest of BEST's</h2><span id='topic+FPredict'></span>

<h3>Description</h3>

<p>Emits prediction from a forest of BEST's
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FPredict(M, LFit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FPredict_+3A_m">M</code></td>
<td>
<p>A matrix of new observations where one row is one observation</p>
</td></tr>
<tr><td><code id="FPredict_+3A_lfit">LFit</code></td>
<td>
<p>A list of BEST Objects (Usually produced by RBEST or BESTForest)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of predictions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
Data &lt;- BESTree::Data[1:n,]
d &lt;- ncol(Data)-1
NewPoints &lt;- BESTree::Data[(n+1):(n+11),1:d]
VA &lt;- ForgeVA(d,1,0,0,0)
Size &lt;- 50
NoT &lt;- 10
Fit &lt;- BESTree::BaggedBEST(Data,VA,NoT,Size)
Predictions &lt;- BESTree::FPredict(NewPoints,Fit)
</code></pre>

<hr>
<h2 id='MPredict'>Classify a set of new observation points</h2><span id='topic+MPredict'></span>

<h3>Description</h3>

<p>Classify a set of new observation points
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MPredict(M, Fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MPredict_+3A_m">M</code></td>
<td>
<p>A matrix of new observations where one row is one observation</p>
</td></tr>
<tr><td><code id="MPredict_+3A_fit">Fit</code></td>
<td>
<p>A BEST object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predicted class
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
Data &lt;- BESTree::Data[1:n,]
d &lt;- ncol(Data)-1
NewPoints &lt;- BESTree::Data[(n+1):(n+11),1:d]
VA &lt;- ForgeVA(d,1,0,0,0)
Size &lt;- 50
Fit &lt;- BESTree::BEST(Data,Size,VA)
Predictions &lt;- BESTree::MPredict(NewPoints,Fit)
</code></pre>

<hr>
<h2 id='Predict'>Classify a new observation point</h2><span id='topic+Predict'></span>

<h3>Description</h3>

<p>Classify a new observation point
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Predict(Point, Fit)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict_+3A_point">Point</code></td>
<td>
<p>A new observation</p>
</td></tr>
<tr><td><code id="Predict_+3A_fit">Fit</code></td>
<td>
<p>A BEST object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predicted class
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
Data &lt;- BESTree::Data[1:n,]
NewPoint &lt;- BESTree::Data[n+1,]
d &lt;- ncol(Data)-1
VA &lt;- ForgeVA(d,1,0,0,0)
Size &lt;- 50
Fit &lt;- BESTree::BEST(Data,Size,VA)
BESTree::Predict(NewPoint[1:d],Fit)
</code></pre>

<hr>
<h2 id='TreePruning'>Uses a Validation Set to select the best trees within the list of pruned trees.</h2><span id='topic+TreePruning'></span>

<h3>Description</h3>

<p>Uses a Validation Set to select the best trees within the list of pruned trees.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TreePruning(Fit, VSet)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TreePruning_+3A_fit">Fit</code></td>
<td>
<p>A BEST object</p>
</td></tr>
<tr><td><code id="TreePruning_+3A_vset">VSet</code></td>
<td>
<p>A Validation Set (Can also be used in CV loop)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The shallower trees among trees wiht Highest accuracy. This replaces the first element in the BEST object list.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>nv &lt;- 50
ValData &lt;- BESTree::Data[(1000+1):nv,]
Fit &lt;- BESTree::Fit
Fit[[1]] &lt;- BESTree::TreePruning(Fit,ValData)
</code></pre>

<hr>
<h2 id='VI'>Produces a variable important analysis using the mean decrease in node impurity</h2><span id='topic+VI'></span>

<h3>Description</h3>

<p>Produces a variable important analysis using the mean decrease in node impurity
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VI(Forest)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VI_+3A_forest">Forest</code></td>
<td>
<p>A list of BEST Objects (Usually produced by RBEST or BESTForest)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of importance (size d)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 500
Data &lt;- BESTree::Data[1:n,]
d &lt;- ncol(Data)-1
NewPoints &lt;- BESTree::Data[(n+1):(n+11),1:d]
VA &lt;- ForgeVA(d,1,0,0,0)
Size &lt;- 50
NoT &lt;- 10
Fit &lt;- BESTree::BaggedBEST(Data,VA,NoT,Size)
VI &lt;- BESTree::VI(Fit)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
