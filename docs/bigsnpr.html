<!DOCTYPE html><html><head><title>Help for package bigsnpr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bigsnpr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#[,bed,ANY,ANY,ANY-method'><p>Accessor methods for class <code>bed</code>.</p></a></li>
<li><a href='#bed_clumping'><p>LD clumping</p></a></li>
<li><a href='#bed_counts'><p>Counts</p></a></li>
<li><a href='#bed_cprodVec'><p>Cross-product with a vector</p></a></li>
<li><a href='#bed_MAF'><p>Allele frequencies</p></a></li>
<li><a href='#bed_prodVec'><p>Product with a vector</p></a></li>
<li><a href='#bed_projectPCA'><p>Projecting PCA</p></a></li>
<li><a href='#bed_projectSelfPCA'><p>Projecting PCA</p></a></li>
<li><a href='#bed_randomSVD'><p>Randomized partial SVD</p></a></li>
<li><a href='#bed_scaleBinom'><p>Binomial(2, p) scaling</p></a></li>
<li><a href='#bed_tcrossprodSelf'><p>tcrossprod / GRM</p></a></li>
<li><a href='#bed-class'><p>Class bed</p></a></li>
<li><a href='#bed-methods'><p>Methods for the bed class</p></a></li>
<li><a href='#bigSNP-class'><p>Class bigSNP</p></a></li>
<li><a href='#bigsnpr-package'><p>bigsnpr: Analysis of Massive SNP Arrays</p></a></li>
<li><a href='#CODE_012'><p>CODE_012: code genotype calls (3) and missing values.</p></a></li>
<li><a href='#coef_to_liab'><p>Liability scale</p></a></li>
<li><a href='#download_1000G'><p>Download 1000G</p></a></li>
<li><a href='#download_beagle'><p>Download Beagle 4.1</p></a></li>
<li><a href='#download_plink'><p>Download PLINK</p></a></li>
<li><a href='#LD.wiki34'><p>Long-range LD regions</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#same_ref'><p>Determine reference divergence</p></a></li>
<li><a href='#SCT'><p>Stacked C+T (SCT)</p></a></li>
<li><a href='#seq_log'><p>Sequence, evenly spaced on a logarithmic scale</p></a></li>
<li><a href='#snp_ancestry_summary'><p>Estimation of ancestry proportions</p></a></li>
<li><a href='#snp_asGeneticPos'><p>Interpolate to genetic positions</p></a></li>
<li><a href='#snp_attach'><p>Attach a &quot;bigSNP&quot; from backing files</p></a></li>
<li><a href='#snp_attachExtdata'><p>Attach a &quot;bigSNP&quot; for examples and tests</p></a></li>
<li><a href='#snp_autoSVD'><p>Truncated SVD while limiting LD</p></a></li>
<li><a href='#snp_beagleImpute'><p>Imputation</p></a></li>
<li><a href='#snp_cor'><p>Correlation matrix</p></a></li>
<li><a href='#snp_fake'><p>Fake a &quot;bigSNP&quot;</p></a></li>
<li><a href='#snp_fastImpute'><p>Fast imputation</p></a></li>
<li><a href='#snp_fastImputeSimple'><p>Fast imputation</p></a></li>
<li><a href='#snp_fst'><p>Fixation index (Fst)</p></a></li>
<li><a href='#snp_gc'><p>Genomic Control</p></a></li>
<li><a href='#snp_getSampleInfos'><p>Get sample information</p></a></li>
<li><a href='#snp_lassosum2'><p>lassosum2</p></a></li>
<li><a href='#snp_ld_scores'><p>LD scores</p></a></li>
<li><a href='#snp_ldpred2_inf'><p>LDpred2</p></a></li>
<li><a href='#snp_ldsc'><p>LD score regression</p></a></li>
<li><a href='#snp_ldsplit'><p>Independent LD blocks</p></a></li>
<li><a href='#snp_MAF'><p>MAF</p></a></li>
<li><a href='#snp_manhattan'><p>Manhattan plot</p></a></li>
<li><a href='#snp_match'><p>Match alleles</p></a></li>
<li><a href='#snp_MAX3'><p>MAX3 statistic</p></a></li>
<li><a href='#snp_modifyBuild'><p>Modify genome build</p></a></li>
<li><a href='#snp_pcadapt'><p>Outlier detection</p></a></li>
<li><a href='#snp_plinkIBDQC'><p>Identity-by-descent</p></a></li>
<li><a href='#snp_plinkKINGQC'><p>Relationship-based pruning</p></a></li>
<li><a href='#snp_plinkQC'><p>Quality Control</p></a></li>
<li><a href='#snp_plinkRmSamples'><p>Remove samples</p></a></li>
<li><a href='#snp_prodBGEN'><p>BGEN matrix product</p></a></li>
<li><a href='#snp_PRS'><p>PRS</p></a></li>
<li><a href='#snp_qq'><p>Q-Q plot</p></a></li>
<li><a href='#snp_readBed'><p>Read PLINK files into a &quot;bigSNP&quot;</p></a></li>
<li><a href='#snp_readBGEN'><p>Read BGEN files into a &quot;bigSNP&quot;</p></a></li>
<li><a href='#snp_readBGI'><p>Read variant info from one BGI file</p></a></li>
<li><a href='#snp_save'><p>Save modifications</p></a></li>
<li><a href='#snp_scaleAlpha'><p>Binomial(n, p) scaling</p></a></li>
<li><a href='#snp_simuPheno'><p>Simulate phenotypes</p></a></li>
<li><a href='#snp_split'><p>Split-parApply-Combine</p></a></li>
<li><a href='#snp_subset'><p>Subset a bigSNP</p></a></li>
<li><a href='#snp_thr_correct'><p>Thresholding and correction</p></a></li>
<li><a href='#snp_writeBed'><p>Write PLINK files from a &quot;bigSNP&quot;</p></a></li>
<li><a href='#sub_bed'><p>Replace extension '.bed'</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Analysis of Massive SNP Arrays</td>
</tr>
<tr>
<td>Version:</td>
<td>1.12.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-03-08</td>
</tr>
<tr>
<td>Description:</td>
<td>Easy-to-use, efficient, flexible and scalable tools for analyzing 
    massive SNP arrays. Privé et al. (2018) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbty185">doi:10.1093/bioinformatics/bty185</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>C++11. Also a few functions from package 'bigsnpr'
wrap existing software such as 'PLINK'
&lt;www.cog-genomics.org/plink2&gt;. Functions are provided to
download these software. Note that these external software
might not work for some operating systems (e.g. 'PLINK' might
not work on Solaris).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4), bigstatsr (&ge; 1.5.11)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bigassertr (&ge; 0.1.6), bigparallelr, bigsparser (&ge; 0.6),
bigreadr, bigutilsr (&ge; 0.3.3), data.table (&ge; 1.12.4), doRNG,
foreach, ggplot2, magrittr, Matrix (&ge; 1.3.0), methods, Rcpp,
runonce (&ge; 0.2.3), stats, vctrs</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>bigsparser, bigstatsr, Rcpp, RcppArmadillo (&ge; 0.9.600),
rmio, roptim (&ge; 0.1.6)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bindata, covr, dbplyr (&ge; 1.4), dplyr, gaston, glue, Hmisc,
microbenchmark, pcadapt (&ge; 4.1), quadprog, RhpcBLASctl,
rmutil, RSpectra, RSQLite, R.utils, spelling, testthat, tibble,
xgboost</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://privefl.github.io/bigsnpr/">https://privefl.github.io/bigsnpr/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/privefl/bigsnpr/issues">https://github.com/privefl/bigsnpr/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-28 08:44:04 UTC; au639593</td>
</tr>
<tr>
<td>Author:</td>
<td>Florian Privé [aut, cre],
  Michael Blum [ths],
  Hugues Aschard [ths],
  Bjarni Jóhann Vilhjálmsson [ths]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Florian Privé &lt;florian.prive.21@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-28 09:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+5B+2Cbed+2CANY+2CANY+2CANY-method'>Accessor methods for class <code>bed</code>.</h2><span id='topic++5B+2Cbed+2CANY+2CANY+2CANY-method'></span>

<h3>Description</h3>

<p>Accessor methods for class <code>bed</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'bed,ANY,ANY,ANY'
x[i, j, ..., drop = TRUE]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B+2B2Cbed+2B2CANY+2B2CANY+2B2CANY-method_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bed-class">bed</a> object.</p>
</td></tr>
<tr><td><code id="+2B5B+2B2Cbed+2B2CANY+2B2CANY+2B2CANY-method_+3A_i">i</code></td>
<td>
<p>A vector of indices (or nothing). You can use positive and negative
indices, and also logical indices (that are recycled).</p>
</td></tr>
<tr><td><code id="+2B5B+2B2Cbed+2B2CANY+2B2CANY+2B2CANY-method_+3A_j">j</code></td>
<td>
<p>A vector of indices (or nothing). You can use positive and negative
indices, and also logical indices (that are recycled).</p>
</td></tr>
<tr><td><code id="+2B5B+2B2Cbed+2B2CANY+2B2CANY+2B2CANY-method_+3A_...">...</code></td>
<td>
<p>Not used. Just to make <a href="base.html#topic+nargs">nargs</a> work.</p>
</td></tr>
<tr><td><code id="+2B5B+2B2Cbed+2B2CANY+2B2CANY+2B2CANY-method_+3A_drop">drop</code></td>
<td>
<p>Whether to drop dimensions (to a vector) when a dimension is 1.
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example-missing.bed", package = "bigsnpr")
(obj.bed &lt;- bed(bedfile))
obj.bed[1:5, 1]
obj.bed[1:5, 1:2]
typeof(obj.bed[1, 1])

</code></pre>

<hr>
<h2 id='bed_clumping'>LD clumping</h2><span id='topic+bed_clumping'></span><span id='topic+snp_clumping'></span><span id='topic+snp_pruning'></span><span id='topic+snp_indLRLDR'></span>

<h3>Description</h3>

<p>For a <code>bigSNP</code>:
</p>

<ul>
<li> <p><code>snp_pruning()</code>: LD pruning. Similar to &quot;<code style="white-space: pre;">&#8288;--indep-pairwise (size+1) 1 thr.r2&#8288;</code>&quot;
in <a href="https://www.cog-genomics.org/plink/1.9/ld">PLINK</a>.
<strong>This function is deprecated (see
<a href="https://privefl.github.io/bigsnpr/articles/pruning-vs-clumping.html">this article</a>).</strong>
</p>
</li>
<li> <p><code>snp_clumping()</code> (and <code>bed_clumping()</code>): LD clumping. If you do not provide
any statistic to rank SNPs, it would use minor allele frequencies (MAFs),
making clumping similar to pruning.
</p>
</li>
<li> <p><code>snp_indLRLDR()</code>: Get SNP indices of long-range LD regions for the
human genome.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bed_clumping(
  obj.bed,
  ind.row = rows_along(obj.bed),
  S = NULL,
  thr.r2 = 0.2,
  size = 100/thr.r2,
  exclude = NULL,
  ncores = 1
)

snp_clumping(
  G,
  infos.chr,
  ind.row = rows_along(G),
  S = NULL,
  thr.r2 = 0.2,
  size = 100/thr.r2,
  infos.pos = NULL,
  is.size.in.bp = NULL,
  exclude = NULL,
  ncores = 1
)

snp_pruning(
  G,
  infos.chr,
  ind.row = rows_along(G),
  size = 49,
  is.size.in.bp = FALSE,
  infos.pos = NULL,
  thr.r2 = 0.2,
  exclude = NULL,
  nploidy = 2,
  ncores = 1
)

snp_indLRLDR(infos.chr, infos.pos, LD.regions = LD.wiki34)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_clumping_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_s">S</code></td>
<td>
<p>A vector of column statistics which express the importance
of each SNP (the more important is the SNP, the greater should be
the corresponding statistic).<br />
For example, if <code>S</code> follows the standard normal distribution, and &quot;important&quot;
means significantly different from 0, you must use <code>abs(S)</code> instead.<br />
<strong>If not specified, MAFs are computed and used.</strong></p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_thr.r2">thr.r2</code></td>
<td>
<p>Threshold over the squared correlation between two SNPs.
Default is <code>0.2</code>.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_size">size</code></td>
<td>
<p>For one SNP, window size around this SNP to compute correlations.
Default is <code>100 / thr.r2</code> for clumping (0.2 -&gt; 500; 0.1 -&gt; 1000; 0.5 -&gt; 200).
If not providing <code>infos.pos</code> (<code>NULL</code>, the default), this is a window in
number of SNPs, otherwise it is a window in kb (genetic distance).
I recommend that you provide the positions if available.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_exclude">exclude</code></td>
<td>
<p>Vector of SNP indices to exclude anyway. For example,
can be used to exclude long-range LD regions (see Price2008). Another use
can be for thresholding with respect to p-values associated with <code>S</code>.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_g">G</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
<strong>You shouldn't have missing values.</strong> Also, remember to do quality control,
e.g. some algorithms in this package won't work if you use SNPs with 0 MAF.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_infos.chr">infos.chr</code></td>
<td>
<p>Vector of integers specifying each SNP's chromosome.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$chromosome&#8288;</code>.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_infos.pos">infos.pos</code></td>
<td>
<p>Vector of integers specifying the physical position
on a chromosome (in base pairs) of each SNP.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$physical.pos&#8288;</code>.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_is.size.in.bp">is.size.in.bp</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_nploidy">nploidy</code></td>
<td>
<p>Number of trials, parameter of the binomial distribution.
Default is <code>2</code>, which corresponds to diploidy, such as for the human genome.</p>
</td></tr>
<tr><td><code id="bed_clumping_+3A_ld.regions">LD.regions</code></td>
<td>
<p>A <code>data.frame</code> with columns &quot;Chr&quot;, &quot;Start&quot; and &quot;Stop&quot;.
Default use the table of 34 long-range LD regions that you can find
<a href="https://goo.gl/0Ou7uI">there</a>.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>snp_clumping()</code> (and <code>bed_clumping()</code>): SNP indices that are <strong>kept</strong>.
</p>
</li>
<li> <p><code>snp_indLRLDR()</code>: SNP indices to be used as (part of) the '<strong><code>exclude</code></strong>'
parameter of <code>snp_clumping()</code>.
</p>
</li></ul>



<h3>References</h3>

<p>Price AL, Weale ME, Patterson N, et al.
Long-Range LD Can Confound Genome Scans in Admixed Populations.
Am J Hum Genet. 2008;83(1):132-135. <a href="https://doi.org/10.1016/j.ajhg.2008.06.005">doi:10.1016/j.ajhg.2008.06.005</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test &lt;- snp_attachExtdata()
G &lt;- test$genotypes

# clumping (prioritizing higher MAF)
ind.keep &lt;- snp_clumping(G, infos.chr = test$map$chromosome,
                         infos.pos = test$map$physical.pos,
                         thr.r2 = 0.1)

# keep most of them -&gt; not much LD in this simulated dataset
length(ind.keep) / ncol(G)

</code></pre>

<hr>
<h2 id='bed_counts'>Counts</h2><span id='topic+bed_counts'></span>

<h3>Description</h3>

<p>Counts the number of 0s, 1s, 2s and NAs by variants in the bed file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed_counts(
  obj.bed,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  byrow = FALSE,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_counts_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_counts_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_counts_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_counts_+3A_byrow">byrow</code></td>
<td>
<p>Whether to count by individual rather than by variant?
Default is <code>FALSE</code> (count by variant).</p>
</td></tr>
<tr><td><code id="bed_counts_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of with 4 rows and <code>length(ind.col)</code> columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example-missing.bed", package = "bigsnpr")
obj.bed &lt;- bed(bedfile)

bed_counts(obj.bed, ind.col = 1:5)

bed_counts(obj.bed, ind.row = 1:5, byrow = TRUE)

</code></pre>

<hr>
<h2 id='bed_cprodVec'>Cross-product with a vector</h2><span id='topic+bed_cprodVec'></span>

<h3>Description</h3>

<p>Cross-product between a &quot;bed&quot; object and a vector.
</p>
<p>Missing values are replaced by 0 (after centering), as if they
had been imputed using parameter <code>center</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed_cprodVec(
  obj.bed,
  y.row,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  center = rep(0, length(ind.col)),
  scale = rep(1, length(ind.col)),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_cprodVec_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_cprodVec_+3A_y.row">y.row</code></td>
<td>
<p>A vector of same size as <code>ind.row</code>.</p>
</td></tr>
<tr><td><code id="bed_cprodVec_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_cprodVec_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_cprodVec_+3A_center">center</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to subtract from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="bed_cprodVec_+3A_scale">scale</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to divide from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="bed_cprodVec_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">X^T \cdot y</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr")
obj.bed &lt;- bed(bedfile)

y.row &lt;- rep(1, nrow(obj.bed))
str(bed_cprodVec(obj.bed, y.row))

</code></pre>

<hr>
<h2 id='bed_MAF'>Allele frequencies</h2><span id='topic+bed_MAF'></span>

<h3>Description</h3>

<p>Allele frequencies of a <a href="#topic+bed">bed</a> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed_MAF(
  obj.bed,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_MAF_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_MAF_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_MAF_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_MAF_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data.frame with
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$ac&#8288;</code>: allele counts,
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$mac&#8288;</code>: minor allele counts,
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$af&#8288;</code>: allele frequencies,
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$maf&#8288;</code>: minor allele frequencies,
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$N&#8288;</code>: numbers of non-missing values.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example-missing.bed", package = "bigsnpr")
obj.bed &lt;- bed(bedfile)

bed_MAF(obj.bed, ind.col = 1:5)

</code></pre>

<hr>
<h2 id='bed_prodVec'>Product with a vector</h2><span id='topic+bed_prodVec'></span>

<h3>Description</h3>

<p>Product between a &quot;bed&quot; object and a vector.
</p>
<p>Missing values are replaced by 0 (after centering), as if they
had been imputed using parameter <code>center</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed_prodVec(
  obj.bed,
  y.col,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  center = rep(0, length(ind.col)),
  scale = rep(1, length(ind.col)),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_prodVec_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_prodVec_+3A_y.col">y.col</code></td>
<td>
<p>A vector of same size as <code>ind.col</code>.</p>
</td></tr>
<tr><td><code id="bed_prodVec_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_prodVec_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_prodVec_+3A_center">center</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to subtract from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="bed_prodVec_+3A_scale">scale</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to divide from columns of <code>X</code>.</p>
</td></tr>
<tr><td><code id="bed_prodVec_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code class="reqn">X \cdot y</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr")
obj.bed &lt;- bed(bedfile)

y.col &lt;- rep(1, ncol(obj.bed))
str(bed_prodVec(obj.bed, y.col))

</code></pre>

<hr>
<h2 id='bed_projectPCA'>Projecting PCA</h2><span id='topic+bed_projectPCA'></span>

<h3>Description</h3>

<p>Computing and projecting PCA of reference dataset to a target dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed_projectPCA(
  obj.bed.ref,
  obj.bed.new,
  k = 10,
  ind.row.new = rows_along(obj.bed.new),
  ind.row.ref = rows_along(obj.bed.ref),
  ind.col.ref = cols_along(obj.bed.ref),
  strand_flip = TRUE,
  join_by_pos = TRUE,
  match.min.prop = 0.5,
  build.new = "hg19",
  build.ref = "hg19",
  liftOver = NULL,
  ...,
  verbose = TRUE,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_projectPCA_+3A_obj.bed.ref">obj.bed.ref</code></td>
<td>
<p>Object of type bed, which is the mapping of the bed file of
the reference data. Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_obj.bed.new">obj.bed.new</code></td>
<td>
<p>Object of type bed, which is the mapping of the bed file of
the target data. Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_k">k</code></td>
<td>
<p>Number of principal components to compute and project.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_ind.row.new">ind.row.new</code></td>
<td>
<p>Rows to be used in the target data. Default uses them all.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_ind.row.ref">ind.row.ref</code></td>
<td>
<p>Rows to be used in the reference data.
Default uses them all.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_ind.col.ref">ind.col.ref</code></td>
<td>
<p>Columns to be potentially used in the reference data.
Default uses all the ones in common with target data.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_strand_flip">strand_flip</code></td>
<td>
<p>Whether to try to flip strand? (default is <code>TRUE</code>)
If so, ambiguous alleles A/T and C/G are removed.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_join_by_pos">join_by_pos</code></td>
<td>
<p>Whether to join by chromosome and position (default),
or instead by rsid.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_match.min.prop">match.min.prop</code></td>
<td>
<p>Minimum proportion of variants in the smallest data
to be matched, otherwise stops with an error. Default is <code style="white-space: pre;">&#8288;20%&#8288;</code>.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_build.new">build.new</code></td>
<td>
<p>Genome build of the target data. Default is <code>hg19</code>.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_build.ref">build.ref</code></td>
<td>
<p>Genome build of the reference data. Default is <code>hg19</code>.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_liftover">liftOver</code></td>
<td>
<p>Path to liftOver executable. Binaries can be downloaded at
<a href="https://hgdownload.cse.ucsc.edu/admin/exe/macOSX.x86_64/liftOver">https://hgdownload.cse.ucsc.edu/admin/exe/macOSX.x86_64/liftOver</a> for Mac
and at <a href="https://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/liftOver">https://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/liftOver</a>
for Linux.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+bed_autoSVD">bed_autoSVD</a></code>
</p>

<dl>
<dt><code>fun.scaling</code></dt><dd><p>A function with parameters <code>X</code> (or <code>obj.bed</code>), <code>ind.row</code> and
<code>ind.col</code>, and that returns a data.frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code> for the
columns corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default uses binomial scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code>as_scaling_fun()</code>.</p>
</dd>
<dt><code>roll.size</code></dt><dd><p>Radius of rolling windows to smooth log-p-values.
Default is <code>50</code>.</p>
</dd>
<dt><code>int.min.size</code></dt><dd><p>Minimum number of consecutive outlier SNPs
in order to be reported as long-range LD region. Default is <code>20</code>.</p>
</dd>
<dt><code>thr.r2</code></dt><dd><p>Threshold over the squared correlation between two SNPs.
Default is <code>0.2</code>. Use <code>NA</code> if you want to skip the clumping step.</p>
</dd>
<dt><code>alpha.tukey</code></dt><dd><p>Default is <code>0.1</code>. The type-I error rate in outlier
detection (that is further corrected for multiple testing).</p>
</dd>
<dt><code>min.mac</code></dt><dd><p>Minimum minor allele count (MAC) for variants to be included.
Default is <code>10</code>.</p>
</dd>
<dt><code>max.iter</code></dt><dd><p>Maximum number of iterations of outlier detection.
Default is <code>5</code>.</p>
</dd>
<dt><code>size</code></dt><dd><p>For one SNP, window size around this SNP to compute correlations.
Default is <code>100 / thr.r2</code> for clumping (0.2 -&gt; 500; 0.1 -&gt; 1000; 0.5 -&gt; 200).
If not providing <code>infos.pos</code> (<code>NULL</code>, the default), this is a window in
number of SNPs, otherwise it is a window in kb (genetic distance).
I recommend that you provide the positions if available.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_verbose">verbose</code></td>
<td>
<p>Output some information on the iterations? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="bed_projectPCA_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of 3 elements:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$obj.svd.ref&#8288;</code>: big_SVD object computed from reference data.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$simple_proj&#8288;</code>: simple projection of new data into space of reference PCA.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$OADP_proj&#8288;</code>: Online Augmentation, Decomposition, and Procrustes (OADP)
projection of new data into space of reference PCA.
</p>
</li></ul>


<hr>
<h2 id='bed_projectSelfPCA'>Projecting PCA</h2><span id='topic+bed_projectSelfPCA'></span>

<h3>Description</h3>

<p>Projecting PCA using individuals from one dataset
to other individuals from the same dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed_projectSelfPCA(
  obj.svd,
  obj.bed,
  ind.row,
  ind.col = attr(obj.svd, "subset"),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_projectSelfPCA_+3A_obj.svd">obj.svd</code></td>
<td>
<p>List with <code>v</code>, <code>d</code>, <code>center</code> and <code>scale</code>. Typically the an
object of type &quot;big_SVD&quot;.</p>
</td></tr>
<tr><td><code id="bed_projectSelfPCA_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type bed, which is the mapping of the bed file of
the data containing both the individuals that were used to compute the PCA
and the other individuals to be projected.</p>
</td></tr>
<tr><td><code id="bed_projectSelfPCA_+3A_ind.row">ind.row</code></td>
<td>
<p>Rows (individuals) to be projected.</p>
</td></tr>
<tr><td><code id="bed_projectSelfPCA_+3A_ind.col">ind.col</code></td>
<td>
<p>Columns that were used for computing PCA. If <a href="#topic+bed_autoSVD">bed_autoSVD</a> was
used, then <code>attr(obj.svd, "subset")</code> is automatically used by default.
Otherwise (e.g. if <a href="#topic+bed_randomSVD">bed_randomSVD</a> was used), you have to pass <code>ind.col</code>.</p>
</td></tr>
<tr><td><code id="bed_projectSelfPCA_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of 3 elements:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$obj.svd.ref&#8288;</code>: big_SVD object computed from reference data.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$simple_proj&#8288;</code>: simple projection of new data into space of reference PCA.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$OADP_proj&#8288;</code>: Online Augmentation, Decomposition, and Procrustes (OADP)
projection of new data into space of reference PCA.
</p>
</li></ul>


<hr>
<h2 id='bed_randomSVD'>Randomized partial SVD</h2><span id='topic+bed_randomSVD'></span>

<h3>Description</h3>

<p>Partial SVD (or PCA) of a genotype matrix stored as a PLINK (.bed) file.#'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed_randomSVD(
  obj.bed,
  fun.scaling = bed_scaleBinom,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  k = 10,
  tol = 1e-04,
  verbose = FALSE,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_randomSVD_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_randomSVD_+3A_fun.scaling">fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code>, <code>ind.row</code> and <code>ind.col</code>,
and that returns a data.frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code> for the columns
corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default doesn't use any scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code><a href="bigstatsr.html#topic+as_scaling_fun">as_scaling_fun()</a></code>.</p>
</td></tr>
<tr><td><code id="bed_randomSVD_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_randomSVD_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_randomSVD_+3A_k">k</code></td>
<td>
<p>Number of singular vectors/values to compute. Default is <code>10</code>.
<strong>This algorithm should be used to compute only a few singular vectors/values.</strong></p>
</td></tr>
<tr><td><code id="bed_randomSVD_+3A_tol">tol</code></td>
<td>
<p>Precision parameter of <a href="RSpectra.html#topic+svds">svds</a>. Default is <code>1e-4</code>.</p>
</td></tr>
<tr><td><code id="bed_randomSVD_+3A_verbose">verbose</code></td>
<td>
<p>Should some progress be printed? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="bed_randomSVD_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named list (an S3 class &quot;big_SVD&quot;) of
</p>

<ul>
<li> <p><code>d</code>, the singular values,
</p>
</li>
<li> <p><code>u</code>, the left singular vectors,
</p>
</li>
<li> <p><code>v</code>, the right singular vectors,
</p>
</li>
<li> <p><code>niter</code>, the number of the iteration of the algorithm,
</p>
</li>
<li> <p><code>nops</code>, number of Matrix-Vector multiplications used,
</p>
</li>
<li> <p><code>center</code>, the centering vector,
</p>
</li>
<li> <p><code>scale</code>, the scaling vector.
</p>
</li></ul>

<p>Note that to obtain the Principal Components, you must use
<a href="bigstatsr.html#topic+predict.big_SVD">predict</a> on the result. See examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr")
obj.bed &lt;- bed(bedfile)

str(bed_randomSVD(obj.bed))

</code></pre>

<hr>
<h2 id='bed_scaleBinom'>Binomial(2, p) scaling</h2><span id='topic+bed_scaleBinom'></span>

<h3>Description</h3>

<p>Binomial(2, p) scaling where <code>p</code> is estimated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed_scaleBinom(
  obj.bed,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_scaleBinom_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_scaleBinom_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_scaleBinom_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_scaleBinom_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You will probably not use this function as is but as parameter
<code>fun.scaling</code> of other functions (e.g. <code>bed_autoSVD</code> and <code>bed_randomSVD</code>).
</p>


<h3>Value</h3>

<p>A data frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code>.
</p>


<h3>References</h3>

<p>This scaling is widely used for SNP arrays.
Patterson N, Price AL, Reich D (2006). Population Structure and Eigenanalysis.
PLoS Genet 2(12): e190. <a href="https://doi.org/10.1371/journal.pgen.0020190">doi:10.1371/journal.pgen.0020190</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example-missing.bed", package = "bigsnpr")
obj.bed &lt;- bed(bedfile)

str(bed_scaleBinom(obj.bed))

str(bed_randomSVD(obj.bed, bed_scaleBinom))

</code></pre>

<hr>
<h2 id='bed_tcrossprodSelf'>tcrossprod / GRM</h2><span id='topic+bed_tcrossprodSelf'></span>

<h3>Description</h3>

<p>Compute <code class="reqn">G G^T</code> from a bed object, with possible filtering and scaling
of <code>G</code>. For example, this can be used to compute GRMs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed_tcrossprodSelf(
  obj.bed,
  fun.scaling = bed_scaleBinom,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  block.size = block_size(length(ind.row))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed_tcrossprodSelf_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
<tr><td><code id="bed_tcrossprodSelf_+3A_fun.scaling">fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code> (or <code>obj.bed</code>), <code>ind.row</code> and
<code>ind.col</code>, and that returns a data.frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code> for the
columns corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default uses binomial scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code>as_scaling_fun()</code>.</p>
</td></tr>
<tr><td><code id="bed_tcrossprodSelf_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_tcrossprodSelf_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bed_tcrossprodSelf_+3A_block.size">block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses <a href="bigstatsr.html#topic+block_size">block_size</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A temporary <a href="bigstatsr.html#topic+FBM-class">FBM</a>, with the following two attributes:
</p>

<ul>
<li><p> a numeric vector <code>center</code> of column scaling,
</p>
</li>
<li><p> a numeric vector <code>scale</code> of column scaling.
</p>
</li></ul>



<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks.
Instead, you may use <a href="https://mran.microsoft.com/open/">Microsoft R Open</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can also control the number of cores used with
<code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr")
obj.bed &lt;- bed(bedfile)

K &lt;- bed_tcrossprodSelf(obj.bed)
K[1:4, 1:6] / ncol(obj.bed)

</code></pre>

<hr>
<h2 id='bed-class'>Class bed</h2><span id='topic+bed-class'></span><span id='topic+bed_RC'></span><span id='topic+bed'></span>

<h3>Description</h3>

<p>A reference class for storing a pointer to a mapped version of a bed file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bed(bedfile)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed-class_+3A_bedfile">bedfile</code></td>
<td>
<p>Path to file with extension &quot;.bed&quot; to read.
You need the corresponding &quot;.bim&quot; and &quot;.fam&quot; in the same directory.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A <code>bed</code> object has many field:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$address&#8288;</code>: address of the external pointer containing the underlying
C++ object, to be used internally as a <code style="white-space: pre;">&#8288;XPtr&lt;bed&gt;&#8288;</code> in C++ code
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$extptr&#8288;</code>: use <code style="white-space: pre;">&#8288;$address&#8288;</code> instead
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$bedfile&#8288;</code>: path to the bed file
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$bimfile&#8288;</code>: path to the corresponding bim file
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$famfile&#8288;</code>: path to the corresponding fam file
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$prefix&#8288;</code>: path without extension
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$nrow&#8288;</code>: number of samples in the bed file
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$ncol&#8288;</code>: number of variants in the bed file
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$map&#8288;</code>: data frame read from <code style="white-space: pre;">&#8288;$bimfile&#8288;</code>
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$fam&#8288;</code>: data frame read from <code style="white-space: pre;">&#8288;$famfile&#8288;</code>
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$.map&#8288;</code>: use <code style="white-space: pre;">&#8288;$map&#8288;</code> instead
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$.fam&#8288;</code>: use <code style="white-space: pre;">&#8288;$fam&#8288;</code> instead
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$light&#8288;</code>: get a lighter version of this object for parallel algorithms
to not have to transfer e.g. <code style="white-space: pre;">&#8288;$.map&#8288;</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example-missing.bed", package = "bigsnpr")
(obj.bed &lt;- bed(bedfile))

</code></pre>

<hr>
<h2 id='bed-methods'>Methods for the bed class</h2><span id='topic+bed-methods'></span><span id='topic+dim+2Cbed-method'></span><span id='topic+length+2Cbed-method'></span>

<h3>Description</h3>

<p>Methods for the bed class
</p>
<p>Dimension methods for class <code>bed</code>.
Methods <code>nrow()</code> and <code>ncol()</code> are automatically defined with <code>dim()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'bed'
dim(x)

## S4 method for signature 'bed'
length(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bed-methods_+3A_x">x</code></td>
<td>
<p>Object of type <code>bed</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Dimensions of <code>x</code>.
</p>

<hr>
<h2 id='bigSNP-class'>Class bigSNP</h2><span id='topic+bigSNP-class'></span><span id='topic+bigSNP'></span>

<h3>Description</h3>

<p>An S3 class for representing information on massive SNP arrays.
</p>


<h3>Value</h3>

<p>A named list with at least 3 slots: </p>

<dl>
<dt>genotypes</dt><dd><p>A FBM.code256 which is
a special Filebacked Big Matrix encoded with type <code>raw</code> (one byte
unsigned integer), representing genotype calls and possibly imputed
allele dosages. Rows are individuals and columns are SNPs.</p>
</dd>
<dt>fam</dt><dd><p>A <code>data.frame</code> containing some information on the individuals
(read from a &quot;.fam&quot; file).</p>
</dd>
<dt>map</dt><dd><p>A <code>data.frame</code> giving some information on the variants
(read from a &quot;.bim&quot; file).</p>
</dd>
</dl>



<h3>See Also</h3>

<p><a href="#topic+snp_readBed">snp_readBed</a>
</p>

<hr>
<h2 id='bigsnpr-package'>bigsnpr: Analysis of Massive SNP Arrays</h2><span id='topic+bigsnpr'></span><span id='topic+bigsnpr-package'></span>

<h3>Description</h3>

<p>Easy-to-use, efficient, flexible and scalable tools for analyzing massive SNP arrays. Privé et al. (2018) <a href="https://doi.org/10.1093/bioinformatics/bty185">doi:10.1093/bioinformatics/bty185</a>.
</p>


<h3>Arguments</h3>

<table>
<tr><td><code id="bigsnpr-package_+3A_g">G</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
<strong>You shouldn't have missing values.</strong> Also, remember to do quality control,
e.g. some algorithms in this package won't work if you use SNPs with 0 MAF.</p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_gna">Gna</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
You can have missing values in these data.</p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bigSNP-class">bigSNP</a>.</p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_infos.chr">infos.chr</code></td>
<td>
<p>Vector of integers specifying each SNP's chromosome.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$chromosome&#8288;</code>.</p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_infos.pos">infos.pos</code></td>
<td>
<p>Vector of integers specifying the physical position
on a chromosome (in base pairs) of each SNP.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$physical.pos&#8288;</code>.</p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_nploidy">nploidy</code></td>
<td>
<p>Number of trials, parameter of the binomial distribution.
Default is <code>2</code>, which corresponds to diploidy, such as for the human genome.</p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_is.size.in.bp">is.size.in.bp</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="bigsnpr-package_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Florian Privé <a href="mailto:florian.prive.21@gmail.com">florian.prive.21@gmail.com</a>
</p>
<p>Other contributors:
</p>

<ul>
<li><p> Michael Blum [thesis advisor]
</p>
</li>
<li><p> Hugues Aschard <a href="mailto:hugues.aschard@pasteur.fr">hugues.aschard@pasteur.fr</a> [thesis advisor]
</p>
</li>
<li><p> Bjarni Jóhann Vilhjálmsson <a href="mailto:bjv@econ.au.dk">bjv@econ.au.dk</a> [thesis advisor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://privefl.github.io/bigsnpr/">https://privefl.github.io/bigsnpr/</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/privefl/bigsnpr/issues">https://github.com/privefl/bigsnpr/issues</a>
</p>
</li></ul>


<hr>
<h2 id='CODE_012'>CODE_012: code genotype calls (3) and missing values.</h2><span id='topic+CODE_012'></span><span id='topic+CODE_DOSAGE'></span><span id='topic+CODE_IMPUTE_PRED'></span>

<h3>Description</h3>

<p>CODE_012: code genotype calls (3) and missing values.
</p>
<p>CODE_DOSAGE: code genotype calls and missing values (4), and imputed calls (3)
and imputed allele dosages rounded to two decimal places (201).
</p>
<p>CODE_IMPUTE_PRED: code genotype calls and missing values (4),
and imputed calls (3).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CODE_012

CODE_DOSAGE

CODE_IMPUTE_PRED
</code></pre>


<h3>Format</h3>

<p>An object of class <code>numeric</code> of length 256.
</p>
<p>An object of class <code>numeric</code> of length 256.
</p>
<p>An object of class <code>numeric</code> of length 256.
</p>

<hr>
<h2 id='coef_to_liab'>Liability scale</h2><span id='topic+coef_to_liab'></span>

<h3>Description</h3>

<p>Coefficient to convert to the liability scale. E.g. h2_liab = coef * h2_obs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coef_to_liab(K_pop, K_gwas = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef_to_liab_+3A_k_pop">K_pop</code></td>
<td>
<p>Prevalence in the population.</p>
</td></tr>
<tr><td><code id="coef_to_liab_+3A_k_gwas">K_gwas</code></td>
<td>
<p>Prevalence in the GWAS. You should provide this if you used
(<code>n_case + n_control</code>) as sample size. If using the effective sample size
<code>4 / (1 / n_case + 1 / n_control)</code> instead, you should keep the default
value of <code>K_gwas = 0.5</code> as the GWAS case-control ascertainment is already
accounted for in the effective sample size.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Scaling coefficient to convert e.g. heritability to the liability scale.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>h2 &lt;- 0.2
h2 * coef_to_liab(0.02)
</code></pre>

<hr>
<h2 id='download_1000G'>Download 1000G</h2><span id='topic+download_1000G'></span>

<h3>Description</h3>

<p>Download 1000 genomes project (phase 3) data in PLINK bed/bim/fam format,
including 2490 (mostly unrelated) individuals
and ~1.7M SNPs in common with either HapMap3 or the UK Biobank.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_1000G(dir, overwrite = FALSE, delete_zip = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_1000G_+3A_dir">dir</code></td>
<td>
<p>The directory where to put the downloaded files.</p>
</td></tr>
<tr><td><code id="download_1000G_+3A_overwrite">overwrite</code></td>
<td>
<p>Whether to overwrite files when downloading and unzipping?
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="download_1000G_+3A_delete_zip">delete_zip</code></td>
<td>
<p>Whether to delete zip after decompressing the file in it?
Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The path of the downloaded bed file.
</p>

<hr>
<h2 id='download_beagle'>Download Beagle 4.1</h2><span id='topic+download_beagle'></span>

<h3>Description</h3>

<p>Download Beagle 4.1 from
<a href="https://faculty.washington.edu/browning/beagle/beagle.html">https://faculty.washington.edu/browning/beagle/beagle.html</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_beagle(dir = tempdir())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_beagle_+3A_dir">dir</code></td>
<td>
<p>The directory where to put the Beagle Java Archive.
Default is a temporary directory.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The path of the downloaded Beagle Java Archive.
</p>

<hr>
<h2 id='download_plink'>Download PLINK</h2><span id='topic+download_plink'></span><span id='topic+download_plink2'></span>

<h3>Description</h3>

<p>Download PLINK 1.9 from <a href="https://www.cog-genomics.org/plink2">https://www.cog-genomics.org/plink2</a>.
</p>
<p>Download PLINK 2.0 from <a href="https://www.cog-genomics.org/plink/2.0/">https://www.cog-genomics.org/plink/2.0/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_plink(dir = tempdir(), overwrite = FALSE, verbose = TRUE)

download_plink2(
  dir = tempdir(),
  AVX2 = TRUE,
  ARM = FALSE,
  AMD = FALSE,
  overwrite = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_plink_+3A_dir">dir</code></td>
<td>
<p>The directory where to put the PLINK executable.
Default is a temporary directory.</p>
</td></tr>
<tr><td><code id="download_plink_+3A_overwrite">overwrite</code></td>
<td>
<p>Whether to overwrite file? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="download_plink_+3A_verbose">verbose</code></td>
<td>
<p>Whether to output details of downloading. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="download_plink_+3A_avx2">AVX2</code></td>
<td>
<p>Whether to download the AVX2 version? This is only available for
64 bits architectures. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="download_plink_+3A_arm">ARM</code></td>
<td>
<p>Whether to download an ARM version. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="download_plink_+3A_amd">AMD</code></td>
<td>
<p>Whether to download an AMD version. Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The path of the downloaded PLINK executable.
</p>

<hr>
<h2 id='LD.wiki34'>Long-range LD regions</h2><span id='topic+LD.wiki34'></span>

<h3>Description</h3>

<p>34 long-range Linkage Disequilibrium (LD) regions for the human genome
based on some <a href="https://goo.gl/0Ou7uI">wiki table</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LD.wiki34
</code></pre>


<h3>Format</h3>

<p>A data frame with 34 rows (regions) and 4 variables:
</p>

<ul>
<li> <p><code>Chr</code>: region's chromosome
</p>
</li>
<li> <p><code>Start</code>: starting position of the region (in bp)
</p>
</li>
<li> <p><code>Stop</code>: stopping position of the region (in bp)
</p>
</li>
<li> <p><code>ID</code>: some ID of the region.
</p>
</li></ul>


<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+as_SFBM'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>bigsparser</dt><dd><p><code><a href="bigsparser.html#topic+SFBM-class">as_SFBM</a></code></p>
</dd>
</dl>

<hr>
<h2 id='same_ref'>Determine reference divergence</h2><span id='topic+same_ref'></span>

<h3>Description</h3>

<p>Determine reference divergence while accounting for strand flips.
<strong>This does not remove ambiguous alleles.</strong>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>same_ref(ref1, alt1, ref2, alt2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="same_ref_+3A_ref1">ref1</code></td>
<td>
<p>The reference alleles of the first dataset.</p>
</td></tr>
<tr><td><code id="same_ref_+3A_alt1">alt1</code></td>
<td>
<p>The alternative alleles of the first dataset.</p>
</td></tr>
<tr><td><code id="same_ref_+3A_ref2">ref2</code></td>
<td>
<p>The reference alleles of the second dataset.</p>
</td></tr>
<tr><td><code id="same_ref_+3A_alt2">alt2</code></td>
<td>
<p>The alternative alleles of the second dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical vector whether the references alleles are the same.
Missing values can result from missing values in the inputs or from
ambiguous matching (e.g. matching A/C and A/G).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+snp_match">snp_match()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>same_ref(ref1 = c("A", "C", "T", "G", NA),
         alt1 = c("C", "T", "C", "A", "A"),
         ref2 = c("A", "C", "A", "A", "C"),
         alt2 = c("C", "G", "G", "G", "A"))
</code></pre>

<hr>
<h2 id='SCT'>Stacked C+T (SCT)</h2><span id='topic+SCT'></span><span id='topic+snp_grid_clumping'></span><span id='topic+snp_grid_PRS'></span><span id='topic+snp_grid_stacking'></span>

<h3>Description</h3>

<p>Polygenic Risk Scores for a grid of clumping and thresholding parameters.
</p>
<p>Stacking over many Polygenic Risk Scores, corresponding to a grid of many
different parameters for clumping and thresholding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_grid_clumping(
  G,
  infos.chr,
  infos.pos,
  lpS,
  ind.row = rows_along(G),
  grid.thr.r2 = c(0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 0.95),
  grid.base.size = c(50, 100, 200, 500),
  infos.imp = rep(1, ncol(G)),
  grid.thr.imp = 1,
  groups = list(cols_along(G)),
  exclude = NULL,
  ncores = 1
)

snp_grid_PRS(
  G,
  all_keep,
  betas,
  lpS,
  n_thr_lpS = 50,
  grid.lpS.thr = 0.9999 * seq_log(max(0.1, min(lpS, na.rm = TRUE)), max(lpS, na.rm =
    TRUE), n_thr_lpS),
  ind.row = rows_along(G),
  backingfile = tempfile(),
  type = c("float", "double"),
  ncores = 1
)

snp_grid_stacking(
  multi_PRS,
  y.train,
  alphas = c(1, 0.01, 1e-04),
  ncores = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SCT_+3A_g">G</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
<strong>You shouldn't have missing values.</strong> Also, remember to do quality control,
e.g. some algorithms in this package won't work if you use SNPs with 0 MAF.</p>
</td></tr>
<tr><td><code id="SCT_+3A_infos.chr">infos.chr</code></td>
<td>
<p>Vector of integers specifying each SNP's chromosome.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$chromosome&#8288;</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_infos.pos">infos.pos</code></td>
<td>
<p>Vector of integers specifying the physical position
on a chromosome (in base pairs) of each SNP.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$physical.pos&#8288;</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_lps">lpS</code></td>
<td>
<p>Numeric vector of <code>-log10(p-value)</code> associated with <code>betas</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="SCT_+3A_grid.thr.r2">grid.thr.r2</code></td>
<td>
<p>Grid of thresholds over the squared correlation between
two SNPs for clumping. Default is <code>c(0.01, 0.05, 0.1, 0.2, 0.5, 0.8, 0.95)</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_grid.base.size">grid.base.size</code></td>
<td>
<p>Grid for base window sizes. Sizes are then computed as
<code>base.size / thr.r2</code> (in kb). Default is <code>c(50, 100, 200, 500)</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_infos.imp">infos.imp</code></td>
<td>
<p>Vector of imputation scores. Default is all <code>1</code> if you do
not provide it.</p>
</td></tr>
<tr><td><code id="SCT_+3A_grid.thr.imp">grid.thr.imp</code></td>
<td>
<p>Grid of thresholds over <code>infos.imp</code> (default is <code>1</code>), but
you should change it (e.g. <code>c(0.3, 0.6, 0.9, 0.95)</code>) if providing <code>infos.imp</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_groups">groups</code></td>
<td>
<p>List of vectors of indices to define your own categories.
This could be used e.g. to derive C+T scores using two different GWAS
summary statistics, or to include other information such as functional
annotations. Default just makes one group with all variants.</p>
</td></tr>
<tr><td><code id="SCT_+3A_exclude">exclude</code></td>
<td>
<p>Vector of SNP indices to exclude anyway.</p>
</td></tr>
<tr><td><code id="SCT_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="SCT_+3A_all_keep">all_keep</code></td>
<td>
<p>Output of <code>snp_grid_clumping()</code> (indices passing clumping).</p>
</td></tr>
<tr><td><code id="SCT_+3A_betas">betas</code></td>
<td>
<p>Numeric vector of weights (effect sizes from GWAS) associated
with each variant (column of <code>G</code>). If alleles are reversed, make sure to
multiply corresponding effects by <code>-1</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_n_thr_lps">n_thr_lpS</code></td>
<td>
<p>Length for default <code>grid.lpS.thr</code>. Default is <code>50</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_grid.lps.thr">grid.lpS.thr</code></td>
<td>
<p>Sequence of thresholds to apply on <code>lpS</code>.
Default is a grid (of length <code>n_thr_lpS</code>) evenly spaced on a logarithmic
scale, i.e. on a log-log scale for p-values.</p>
</td></tr>
<tr><td><code id="SCT_+3A_backingfile">backingfile</code></td>
<td>
<p>Prefix for backingfiles where to store scores of C+T.
As we typically use a large grid, this can result in a large matrix so that
we store it on disk. Default uses a temporary file.</p>
</td></tr>
<tr><td><code id="SCT_+3A_type">type</code></td>
<td>
<p>Type of backingfile values. Either <code>"float"</code> (the default) or
<code>"double"</code>. Using <code>"float"</code> requires half disk space.</p>
</td></tr>
<tr><td><code id="SCT_+3A_multi_prs">multi_PRS</code></td>
<td>
<p>Output of <code>snp_grid_PRS()</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_y.train">y.train</code></td>
<td>
<p>Vector of phenotypes. If there are two levels (binary 0/1),
it uses <code>big_spLogReg()</code> for stacking, otherwise <code>big_spLinReg()</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_alphas">alphas</code></td>
<td>
<p>Vector of values for grid-search. See <code>big_spLogReg()</code>.
Default for this function is <code>c(1, 0.01, 0.0001)</code>.</p>
</td></tr>
<tr><td><code id="SCT_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed to <code>big_spLogReg()</code>. For example,
using <code>covar.train</code>, you can add covariates in the model with all C+T scores.
You can also use <code>pf.covar</code> if you do not want to penalize these covariates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>snp_grid_PRS()</code>: An <code>FBM</code> (matrix on disk) that stores the C+T scores
for all parameters of the grid (and for each chromosome separately).
It also stores as attributes the input parameters <code>all_keep</code>, <code>betas</code>,
<code>lpS</code> and <code>grid.lpS.thr</code> that are also needed in <code>snp_grid_stacking()</code>.
</p>

<hr>
<h2 id='seq_log'>Sequence, evenly spaced on a logarithmic scale</h2><span id='topic+seq_log'></span>

<h3>Description</h3>

<p>Sequence, evenly spaced on a logarithmic scale
</p>


<h3>Usage</h3>

<pre><code class='language-R'>seq_log(from, to, length.out)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="seq_log_+3A_from">from</code>, <code id="seq_log_+3A_to">to</code></td>
<td>
<p>the starting and (maximal) end values of the
sequence.  Of length <code>1</code> unless just <code>from</code> is supplied as
an unnamed argument.</p>
</td></tr>
<tr><td><code id="seq_log_+3A_length.out">length.out</code></td>
<td>
<p>desired length of the sequence.  A
non-negative number, which for <code>seq</code> and <code>seq.int</code> will be
rounded up if fractional.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A sequence of length <code>length.out</code>, evenly spaced on a logarithmic scale
between <code>from</code> and <code>to</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>seq_log(1, 1000, 4)
seq_log(1, 100, 5)

</code></pre>

<hr>
<h2 id='snp_ancestry_summary'>Estimation of ancestry proportions</h2><span id='topic+snp_ancestry_summary'></span>

<h3>Description</h3>

<p>Estimation of ancestry proportions. Make sure to match summary statistics
using <code><a href="#topic+snp_match">snp_match()</a></code> (and to reverse frequencies correspondingly).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_ancestry_summary(freq, info_freq_ref, projection, correction)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_ancestry_summary_+3A_freq">freq</code></td>
<td>
<p>Vector of frequencies from which to estimate ancestry proportions.</p>
</td></tr>
<tr><td><code id="snp_ancestry_summary_+3A_info_freq_ref">info_freq_ref</code></td>
<td>
<p>A data frame (or matrix) with the set of frequencies to
be used as reference (one population per column).</p>
</td></tr>
<tr><td><code id="snp_ancestry_summary_+3A_projection">projection</code></td>
<td>
<p>Matrix of &quot;loadings&quot; for each variant/PC to be used to
project allele frequencies.</p>
</td></tr>
<tr><td><code id="snp_ancestry_summary_+3A_correction">correction</code></td>
<td>
<p>Coefficients to correct for shrinkage when projecting.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of coefficients representing the ancestry proportions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# GWAS summary statistics for Epilepsy (supposedly in EUR+EAS+AFR)
gz &lt;- runonce::download_file(
  "http://www.epigad.org/gwas_ilae2018_16loci/all_epilepsy_METAL.gz",
  dir = "tmp-data")
readLines(gz, n = 3)

library(dplyr)
sumstats &lt;- bigreadr::fread2(
  gz, select = c("CHR", "BP", "Allele2", "Allele1", "Freq1"),
  col.names = c("chr", "pos", "a0", "a1", "freq")
) %&gt;%
  mutate_at(3:4, toupper)
# It is a good idea to filter for similar per-variant N (when available..)

all_freq &lt;- bigreadr::fread2(
  runonce::download_file("https://figshare.com/ndownloader/files/31620968",
                         dir = "tmp-data", fname = "ref_freqs.csv.gz"))
projection &lt;- bigreadr::fread2(
  runonce::download_file("https://figshare.com/ndownloader/files/31620953",
                         dir = "tmp-data", fname = "projection.csv.gz"))

matched &lt;- snp_match(
  mutate(sumstats, chr = as.integer(chr), beta = 1),
  all_freq[1:5],
  return_flip_and_rev = TRUE
) %&gt;%
  mutate(freq = ifelse(`_REV_`, 1 - freq, freq))

res &lt;- snp_ancestry_summary(
  freq = matched$freq,
  info_freq_ref = all_freq[matched$`_NUM_ID_`, -(1:5)],
  projection = projection[matched$`_NUM_ID_`, -(1:5)],
  correction = c(1, 1, 1, 1.008, 1.021, 1.034, 1.052, 1.074, 1.099,
                 1.123, 1.15, 1.195, 1.256, 1.321, 1.382, 1.443)
)

# Some ancestry groups are very close to each other, and should be merged
group &lt;- colnames(all_freq)[-(1:5)]
group[group %in% c("Scandinavia", "United Kingdom", "Ireland")]   &lt;- "Europe (North West)"
group[group %in% c("Europe (South East)", "Europe (North East)")] &lt;- "Europe (East)"

tapply(res, factor(group, unique(group)), sum)

## End(Not run)
</code></pre>

<hr>
<h2 id='snp_asGeneticPos'>Interpolate to genetic positions</h2><span id='topic+snp_asGeneticPos'></span>

<h3>Description</h3>

<p>Use genetic maps available at
<a href="https://github.com/joepickrell/1000-genomes-genetic-maps/">https://github.com/joepickrell/1000-genomes-genetic-maps/</a>
to interpolate physical positions (in bp) to genetic positions (in cM).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_asGeneticPos(
  infos.chr,
  infos.pos,
  dir = tempdir(),
  ncores = 1,
  rsid = NULL,
  type = c("OMNI", "hapmap")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_asGeneticPos_+3A_infos.chr">infos.chr</code></td>
<td>
<p>Vector of integers specifying each SNP's chromosome.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$chromosome&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_asGeneticPos_+3A_infos.pos">infos.pos</code></td>
<td>
<p>Vector of integers specifying the physical position
on a chromosome (in base pairs) of each SNP.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$physical.pos&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_asGeneticPos_+3A_dir">dir</code></td>
<td>
<p>Directory where to download and decompress files.
Default is <code>tempdir()</code>. Directly use <em>uncompressed</em> files there if already
present. You can use <code><a href="R.utils.html#topic+compressFile">R.utils::gunzip()</a></code> to uncompress local files.</p>
</td></tr>
<tr><td><code id="snp_asGeneticPos_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_asGeneticPos_+3A_rsid">rsid</code></td>
<td>
<p>If providing rsIDs, the matching is performed using those
(instead of positions) and variants not matched are interpolated using
spline interpolation of variants that have been matched.</p>
</td></tr>
<tr><td><code id="snp_asGeneticPos_+3A_type">type</code></td>
<td>
<p>Whether to use the genetic maps interpolated from &quot;OMNI&quot;
(the default), or from &quot;hapmap&quot;.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The new vector of genetic positions.
</p>

<hr>
<h2 id='snp_attach'>Attach a &quot;bigSNP&quot; from backing files</h2><span id='topic+snp_attach'></span>

<h3>Description</h3>

<p>Load a <a href="#topic+bigSNP-class">bigSNP</a> from backing files into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_attach(rdsfile)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_attach_+3A_rdsfile">rdsfile</code></td>
<td>
<p>The path of the &quot;.rds&quot; which stores the <code>bigSNP</code> object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is often just a call to <a href="base.html#topic+readRDS">readRDS</a>. But it also checks if you have moved
the two (&quot;.bk&quot; and &quot;.rds&quot;) backing files to another directory.
</p>


<h3>Value</h3>

<p>The <code>bigSNP</code> object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr"))

# Reading the bedfile and storing the data in temporary directory
rds &lt;- snp_readBed(bedfile, backingfile = tempfile())

# Loading the data from backing files
test &lt;- snp_attach(rds)

str(test)
dim(G &lt;- test$genotypes)
G[1:8, 1:8]
</code></pre>

<hr>
<h2 id='snp_attachExtdata'>Attach a &quot;bigSNP&quot; for examples and tests</h2><span id='topic+snp_attachExtdata'></span>

<h3>Description</h3>

<p>Attach a &quot;bigSNP&quot; for examples and tests
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_attachExtdata(bedfile = c("example.bed", "example-missing.bed"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_attachExtdata_+3A_bedfile">bedfile</code></td>
<td>
<p>Name of one example bed file. Either
</p>

<ul>
<li> <p><code>"example.bed"</code> (the default),
</p>
</li>
<li> <p><code>"example-missing.bed"</code>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Value</h3>

<p>The example &quot;bigSNP&quot;, filebacked in the &quot;/tmp/&quot; directory.
</p>

<hr>
<h2 id='snp_autoSVD'>Truncated SVD while limiting LD</h2><span id='topic+snp_autoSVD'></span><span id='topic+bed_autoSVD'></span>

<h3>Description</h3>

<p>Fast truncated SVD with initial pruning and that iteratively removes
long-range LD regions. Some variants are removing due to the initial clumping,
then more and more variants are removed at each iteration. You can access the
indices of the remaining variants with <code style="white-space: pre;">&#8288;attr(*, "subset")&#8288;</code>. If some of the
variants removed are contiguous, the regions are reported in <code style="white-space: pre;">&#8288;attr(*, "lrldr")&#8288;</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_autoSVD(
  G,
  infos.chr,
  infos.pos = NULL,
  ind.row = rows_along(G),
  ind.col = cols_along(G),
  fun.scaling = snp_scaleBinom(),
  thr.r2 = 0.2,
  size = 100/thr.r2,
  k = 10,
  roll.size = 50,
  int.min.size = 20,
  alpha.tukey = 0.05,
  min.mac = 10,
  max.iter = 5,
  is.size.in.bp = NULL,
  ncores = 1,
  verbose = TRUE
)

bed_autoSVD(
  obj.bed,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  fun.scaling = bed_scaleBinom,
  thr.r2 = 0.2,
  size = 100/thr.r2,
  k = 10,
  roll.size = 50,
  int.min.size = 20,
  alpha.tukey = 0.05,
  min.mac = 10,
  max.iter = 5,
  ncores = 1,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_autoSVD_+3A_g">G</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
<strong>You shouldn't have missing values.</strong> Also, remember to do quality control,
e.g. some algorithms in this package won't work if you use SNPs with 0 MAF.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_infos.chr">infos.chr</code></td>
<td>
<p>Vector of integers specifying each SNP's chromosome.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$chromosome&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_infos.pos">infos.pos</code></td>
<td>
<p>Vector of integers specifying the physical position
on a chromosome (in base pairs) of each SNP.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$physical.pos&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_fun.scaling">fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code> (or <code>obj.bed</code>), <code>ind.row</code> and
<code>ind.col</code>, and that returns a data.frame with <code style="white-space: pre;">&#8288;$center&#8288;</code> and <code style="white-space: pre;">&#8288;$scale&#8288;</code> for the
columns corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default uses binomial scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code>as_scaling_fun()</code>.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_thr.r2">thr.r2</code></td>
<td>
<p>Threshold over the squared correlation between two SNPs.
Default is <code>0.2</code>. Use <code>NA</code> if you want to skip the clumping step.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_size">size</code></td>
<td>
<p>For one SNP, window size around this SNP to compute correlations.
Default is <code>100 / thr.r2</code> for clumping (0.2 -&gt; 500; 0.1 -&gt; 1000; 0.5 -&gt; 200).
If not providing <code>infos.pos</code> (<code>NULL</code>, the default), this is a window in
number of SNPs, otherwise it is a window in kb (genetic distance).
I recommend that you provide the positions if available.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_k">k</code></td>
<td>
<p>Number of singular vectors/values to compute. Default is <code>10</code>.
<strong>This algorithm should be used to compute a few singular vectors/values.</strong></p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_roll.size">roll.size</code></td>
<td>
<p>Radius of rolling windows to smooth log-p-values.
Default is <code>50</code>.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_int.min.size">int.min.size</code></td>
<td>
<p>Minimum number of consecutive outlier SNPs
in order to be reported as long-range LD region. Default is <code>20</code>.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_alpha.tukey">alpha.tukey</code></td>
<td>
<p>Default is <code>0.1</code>. The type-I error rate in outlier
detection (that is further corrected for multiple testing).</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_min.mac">min.mac</code></td>
<td>
<p>Minimum minor allele count (MAC) for variants to be included.
Default is <code>10</code>.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations of outlier detection.
Default is <code>5</code>.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_is.size.in.bp">is.size.in.bp</code></td>
<td>
<p>Deprecated.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_verbose">verbose</code></td>
<td>
<p>Output some information on the iterations? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="snp_autoSVD_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you don't have any information about SNPs, you can try using
</p>

<ul>
<li> <p><code>infos.chr = rep(1, ncol(G))</code>,
</p>
</li>
<li> <p><code>size = ncol(G)</code> (if SNPs are not sorted),
</p>
</li>
<li> <p><code>roll.size = 0</code> (if SNPs are not sorted).
</p>
</li></ul>



<h3>Value</h3>

<p>A named list (an S3 class &quot;big_SVD&quot;) of
</p>

<ul>
<li> <p><code>d</code>, the singular values,
</p>
</li>
<li> <p><code>u</code>, the left singular vectors,
</p>
</li>
<li> <p><code>v</code>, the right singular vectors,
</p>
</li>
<li> <p><code>niter</code>, the number of the iteration of the algorithm,
</p>
</li>
<li> <p><code>nops</code>, number of Matrix-Vector multiplications used,
</p>
</li>
<li> <p><code>center</code>, the centering vector,
</p>
</li>
<li> <p><code>scale</code>, the scaling vector.
</p>
</li></ul>

<p>Note that to obtain the Principal Components, you must use
<a href="bigstatsr.html#topic+predict.big_SVD">predict</a> on the result. See examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ex &lt;- snp_attachExtdata()
G &lt;- ex$genotypes

obj.svd &lt;- snp_autoSVD(G,
                       infos.chr = ex$map$chromosome,
                       infos.pos = ex$map$physical.position)

str(obj.svd)

</code></pre>

<hr>
<h2 id='snp_beagleImpute'>Imputation</h2><span id='topic+snp_beagleImpute'></span>

<h3>Description</h3>

<p>Imputation using <strong>Beagle</strong> version 4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_beagleImpute(
  beagle.path,
  plink.path,
  bedfile.in,
  bedfile.out = NULL,
  memory.max = 3,
  ncores = 1,
  extra.options = "",
  plink.options = "",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_beagleImpute_+3A_beagle.path">beagle.path</code></td>
<td>
<p>Path to the executable of Beagle v4+.</p>
</td></tr>
<tr><td><code id="snp_beagleImpute_+3A_plink.path">plink.path</code></td>
<td>
<p>Path to the executable of PLINK 1.9.</p>
</td></tr>
<tr><td><code id="snp_beagleImpute_+3A_bedfile.in">bedfile.in</code></td>
<td>
<p>Path to the input bedfile.</p>
</td></tr>
<tr><td><code id="snp_beagleImpute_+3A_bedfile.out">bedfile.out</code></td>
<td>
<p>Path to the output bedfile. Default is created by
appending <code>"_impute"</code> to <code>prefix.in</code> (<code>bedfile.in</code> without extension).</p>
</td></tr>
<tr><td><code id="snp_beagleImpute_+3A_memory.max">memory.max</code></td>
<td>
<p>Max memory (in GB) to be used. It is internally rounded
to be an integer. Default is <code>3</code>.</p>
</td></tr>
<tr><td><code id="snp_beagleImpute_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_beagleImpute_+3A_extra.options">extra.options</code></td>
<td>
<p>Other options to be passed to Beagle as a string. More
options can be found at Beagle's website.</p>
</td></tr>
<tr><td><code id="snp_beagleImpute_+3A_plink.options">plink.options</code></td>
<td>
<p>Other options to be passed to PLINK as a string. More
options can be found at <a href="https://www.cog-genomics.org/plink2/filter">https://www.cog-genomics.org/plink2/filter</a>.</p>
</td></tr>
<tr><td><code id="snp_beagleImpute_+3A_verbose">verbose</code></td>
<td>
<p>Whether to show PLINK log? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Downloads and more information can be found at the following websites
</p>

<ul>
<li> <p><a href="https://www.cog-genomics.org/plink2">PLINK</a>,
</p>
</li>
<li> <p><a href="https://faculty.washington.edu/browning/beagle/beagle.html">Beagle</a>.
</p>
</li></ul>



<h3>Value</h3>

<p>The path of the new bedfile.
</p>


<h3>References</h3>

<p>Browning, Brian L., and Sharon R. Browning.
&quot;Genotype imputation with millions of reference samples.&quot;
The American Journal of Human Genetics 98.1 (2016): 116-126.
</p>


<h3>See Also</h3>

<p><a href="#topic+download_plink">download_plink</a> <a href="#topic+download_beagle">download_beagle</a>
</p>

<hr>
<h2 id='snp_cor'>Correlation matrix</h2><span id='topic+snp_cor'></span><span id='topic+bed_cor'></span>

<h3>Description</h3>

<p>Get significant (Pearson) correlations between nearby SNPs of the same chromosome
(p-values are computed using a two-sided t-test).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_cor(
  Gna,
  ind.row = rows_along(Gna),
  ind.col = cols_along(Gna),
  size = 500,
  alpha = 1,
  thr_r2 = 0,
  fill.diag = TRUE,
  infos.pos = NULL,
  ncores = 1
)

bed_cor(
  obj.bed,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  size = 500,
  alpha = 1,
  thr_r2 = 0,
  fill.diag = TRUE,
  infos.pos = NULL,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_cor_+3A_gna">Gna</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
You can have missing values in these data.</p>
</td></tr>
<tr><td><code id="snp_cor_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_cor_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_cor_+3A_size">size</code></td>
<td>
<p>For one SNP, window size around this SNP to compute correlations.
Default is <code>500</code>. If not providing <code>infos.pos</code> (<code>NULL</code>, the default), this is
a window in number of SNPs, otherwise it is a window in kb (genetic distance).</p>
</td></tr>
<tr><td><code id="snp_cor_+3A_alpha">alpha</code></td>
<td>
<p>Type-I error for testing correlations.
Default is <code>1</code> (no threshold is applied).</p>
</td></tr>
<tr><td><code id="snp_cor_+3A_thr_r2">thr_r2</code></td>
<td>
<p>Threshold to apply on squared correlations. Default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="snp_cor_+3A_fill.diag">fill.diag</code></td>
<td>
<p>Whether to fill the diagonal with 1s (the default)
or to keep it as 0s.</p>
</td></tr>
<tr><td><code id="snp_cor_+3A_infos.pos">infos.pos</code></td>
<td>
<p>Vector of integers specifying the physical position
on a chromosome (in base pairs) of each SNP.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$physical.pos&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_cor_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_cor_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The (Pearson) correlation matrix. This is a sparse symmetric matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test &lt;- snp_attachExtdata()
G &lt;- test$genotypes

corr &lt;- snp_cor(G, ind.col = 1:1000)
corr[1:10, 1:10]

# Sparsity
length(corr@x) / length(corr)

</code></pre>

<hr>
<h2 id='snp_fake'>Fake a &quot;bigSNP&quot;</h2><span id='topic+snp_fake'></span>

<h3>Description</h3>

<p>Fake a &quot;bigSNP&quot;
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_fake(n, m)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_fake_+3A_n">n</code></td>
<td>
<p>Number of individuals.</p>
</td></tr>
<tr><td><code id="snp_fake_+3A_m">m</code></td>
<td>
<p>Number of SNPs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A new temporary <code>bigSNP</code> object representing <code>n</code> individuals
and <code>m</code> SNPs. The genotype Filebacked Big Matrix is initialized
with missing values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(test &lt;- snp_fake(5, 12))

# The genotype Filebackeg Big Matrix is initialized with missing values
G &lt;- test$genotypes
G[]

# Modify the genotype `big.matrix`
G[] &lt;- sample(as.raw(0:3), size = length(G), replace = TRUE)
G[]

</code></pre>

<hr>
<h2 id='snp_fastImpute'>Fast imputation</h2><span id='topic+snp_fastImpute'></span>

<h3>Description</h3>

<p>Fast imputation algorithm based on local XGBoost models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_fastImpute(
  Gna,
  infos.chr,
  alpha = 1e-04,
  size = 200,
  p.train = 0.8,
  n.cor = nrow(Gna),
  seed = NA,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_fastImpute_+3A_gna">Gna</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
You can have missing values in these data.</p>
</td></tr>
<tr><td><code id="snp_fastImpute_+3A_infos.chr">infos.chr</code></td>
<td>
<p>Vector of integers specifying each SNP's chromosome.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$chromosome&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_fastImpute_+3A_alpha">alpha</code></td>
<td>
<p>Type-I error for testing correlations. Default is <code>1e-4</code>.</p>
</td></tr>
<tr><td><code id="snp_fastImpute_+3A_size">size</code></td>
<td>
<p>Number of neighbor SNPs to be possibly included in the model
imputing this particular SNP. Default is <code>200</code>.</p>
</td></tr>
<tr><td><code id="snp_fastImpute_+3A_p.train">p.train</code></td>
<td>
<p>Proportion of non missing genotypes that are used for training
the imputation model while the rest is used to assess the accuracy of
this imputation model. Default is <code>0.8</code>.</p>
</td></tr>
<tr><td><code id="snp_fastImpute_+3A_n.cor">n.cor</code></td>
<td>
<p>Number of rows that are used to estimate correlations.
Default uses them all.</p>
</td></tr>
<tr><td><code id="snp_fastImpute_+3A_seed">seed</code></td>
<td>
<p>An integer, for reproducibility. Default doesn't use seeds.</p>
</td></tr>
<tr><td><code id="snp_fastImpute_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An FBM with
</p>

<ul>
<li><p> the proportion of missing values by SNP (first row),
</p>
</li>
<li><p> the estimated proportion of imputation errors by SNP (second row).
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+snp_fastImputeSimple">snp_fastImputeSimple()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

fake &lt;- snp_attachExtdata("example-missing.bed")
G &lt;- fake$genotypes
CHR &lt;- fake$map$chromosome
infos &lt;- snp_fastImpute(G, CHR)
infos[, 1:5]

# Still missing values
big_counts(G, ind.col = 1:10)
# You need to change the code of G
# To make this permanent, you need to save (modify) the file on disk
fake$genotypes$code256 &lt;- CODE_IMPUTE_PRED
fake &lt;- snp_save(fake)
big_counts(fake$genotypes, ind.col = 1:10)

# Plot for post-checking
## Here there is no SNP with more than 1% error (estimated)
pvals &lt;- c(0.01, 0.005, 0.002, 0.001); colvals &lt;- 2:5
df &lt;- data.frame(pNA = infos[1, ], pError = infos[2, ])

# base R
plot(subset(df, pNA &gt; 0.001), pch = 20)
idc &lt;- lapply(seq_along(pvals), function(i) {
  curve(pvals[i] / x, from = 0, lwd = 2,
        col = colvals[i], add = TRUE)
})
legend("topright", legend = pvals, title = "p(NA &amp; Error)",
       col = colvals, lty = 1, lwd = 2)

# ggplot2
library(ggplot2)
Reduce(function(p, i) {
  p + stat_function(fun = function(x) pvals[i] / x, color = colvals[i])
}, x = seq_along(pvals), init = ggplot(df, aes(pNA, pError))) +
  geom_point() +
  coord_cartesian(ylim = range(df$pError, na.rm = TRUE)) +
  theme_bigstatsr()

## End(Not run)
</code></pre>

<hr>
<h2 id='snp_fastImputeSimple'>Fast imputation</h2><span id='topic+snp_fastImputeSimple'></span>

<h3>Description</h3>

<p>Fast imputation via mode, mean, sampling according to allele frequencies, or 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_fastImputeSimple(
  Gna,
  method = c("mode", "mean0", "mean2", "random"),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_fastImputeSimple_+3A_gna">Gna</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
You can have missing values in these data.</p>
</td></tr>
<tr><td><code id="snp_fastImputeSimple_+3A_method">method</code></td>
<td>
<p>Either <code>"random"</code> (sampling according to allele frequencies),
<code>"mean0"</code> (rounded mean), <code>"mean2"</code> (rounded mean to 2 decimal places),
<code>"mode"</code> (most frequent call).</p>
</td></tr>
<tr><td><code id="snp_fastImputeSimple_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A new <code>FBM.code256</code> object (same file, but different code).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+snp_fastImpute">snp_fastImpute()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bigsnp &lt;- snp_attachExtdata("example-missing.bed")
G &lt;- bigsnp$genotypes
G[, 2]  # some missing values
G2 &lt;- snp_fastImputeSimple(G)
G2[, 2]  # no missing values anymore
G[, 2]  # imputed, but still returning missing values
G$copy(code = CODE_IMPUTE_PRED)[, 2]  # need to decode imputed values

G$copy(code = c(0, 1, 2, rep(0, 253)))[, 2]  # "imputation" by 0

</code></pre>

<hr>
<h2 id='snp_fst'>Fixation index (Fst)</h2><span id='topic+snp_fst'></span>

<h3>Description</h3>

<p>Fixation index (Fst), either per variant, or genome-wide
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_fst(list_df_af, min_maf = 0, overall = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_fst_+3A_list_df_af">list_df_af</code></td>
<td>
<p>List of data frames with <code style="white-space: pre;">&#8288;$af&#8288;</code> (allele frequency per variant)
and <code style="white-space: pre;">&#8288;$N&#8288;</code> (sample size per variant). Typically, the outputs of <code><a href="#topic+bed_MAF">bed_MAF()</a></code>.
Each new data frame of the list should correspond to a different population.</p>
</td></tr>
<tr><td><code id="snp_fst_+3A_min_maf">min_maf</code></td>
<td>
<p>Minimum MAF threshold (for the average of populations) to be
included in the final results. Default is <code>0</code> (remove monomorphic variants).</p>
</td></tr>
<tr><td><code id="snp_fst_+3A_overall">overall</code></td>
<td>
<p>Whether to compute Fst genome-wide (<code>TRUE</code>) or per variant
(<code>FALSE</code>, the default).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>overall</code>, then one value, otherwise a value for each variant
with missing values for the variants not passing <code>min_maf</code>.
This should be equivalent to using '<code>--fst --within</code>' in PLINK.
</p>


<h3>References</h3>

<p>Weir, B. S., &amp; Cockerham, C. C. (1984). Estimating F-statistics for the
analysis of population structure. Evolution, 1358-1370.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr")
obj.bed &lt;- bed(bedfile)

pop &lt;- rep(1:3, c(143, 167, 207))
ind_pop &lt;- split(seq_along(pop), pop)
list_df_af &lt;- lapply(ind_pop, function(ind) bed_MAF(obj.bed, ind.row = ind))

snp_fst(list_df_af)
snp_fst(list_df_af[c(1, 2)], overall = TRUE)
snp_fst(list_df_af[c(1, 3)], overall = TRUE)
snp_fst(list_df_af[c(3, 2)], overall = TRUE)

</code></pre>

<hr>
<h2 id='snp_gc'>Genomic Control</h2><span id='topic+snp_gc'></span>

<h3>Description</h3>

<p>Genomic Control
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_gc(gwas)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_gc_+3A_gwas">gwas</code></td>
<td>
<p>A <code>mhtest</code> object with the p-values associated with each SNP.
Typically, the output of big_univLinReg, big_univLogReg or <a href="#topic+snp_pcadapt">snp_pcadapt</a>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot2</code> object. You can plot it using the <code>print</code> method.
You can modify it as you wish by adding layers. You might want to read
<a href="https://r4ds.had.co.nz/data-visualisation.html">this chapter</a>
to get more familiar with the package <strong>ggplot2</strong>.
</p>


<h3>References</h3>

<p>Devlin, B., &amp; Roeder, K. (1999).
Genomic control for association studies.
Biometrics, 55(4), 997-1004.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(9)

test &lt;- snp_attachExtdata()
G &lt;- test$genotypes
y &lt;- rnorm(nrow(G))

gwas &lt;- big_univLinReg(G, y)
snp_qq(gwas)
gwas_gc &lt;- snp_gc(gwas) # change attr(gwas_gc, "transfo")

snp_qq(gwas_gc)
# The next plot should be prettier with a real dataset
snp_manhattan(gwas_gc,
              infos.chr = test$map$chromosome,
              infos.pos = test$map$physical.pos)

p &lt;- snp_qq(gwas_gc) + ggplot2::aes(text = asPlotlyText(test$map))
## Not run: plotly::ggplotly(p, tooltip = "text")
</code></pre>

<hr>
<h2 id='snp_getSampleInfos'>Get sample information</h2><span id='topic+snp_getSampleInfos'></span>

<h3>Description</h3>

<p>Get information of individuals by matching from an external file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_getSampleInfos(
  x,
  df.or.files,
  col.family.ID = 1,
  col.sample.ID = 2,
  col.infos = -c(1, 2),
  pair.sep = "-_-",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_getSampleInfos_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bigSNP-class">bigSNP</a>.</p>
</td></tr>
<tr><td><code id="snp_getSampleInfos_+3A_df.or.files">df.or.files</code></td>
<td>
<p>Either
</p>

<ul>
<li><p> A <code>data.frame</code>,
</p>
</li>
<li><p> A character vector of file names where to find at the information you want.
You should have one column for family IDs and one for sample IDs.
</p>
</li></ul>
</td></tr>
<tr><td><code id="snp_getSampleInfos_+3A_col.family.id">col.family.ID</code></td>
<td>
<p>Index of the column containing the family IDs to match
with those of the study. Default is the first one.</p>
</td></tr>
<tr><td><code id="snp_getSampleInfos_+3A_col.sample.id">col.sample.ID</code></td>
<td>
<p>Index of the column containing the sample IDs to match
with those of the study. Default is the second one.</p>
</td></tr>
<tr><td><code id="snp_getSampleInfos_+3A_col.infos">col.infos</code></td>
<td>
<p>Indices of the column containing the information you want.
Default is all but the first and the second columns.</p>
</td></tr>
<tr><td><code id="snp_getSampleInfos_+3A_pair.sep">pair.sep</code></td>
<td>
<p>Separator used for concatenation of family and sample IDs to
make unique IDs for matching between the two datasets. Default is <code>"-_-"</code>.</p>
</td></tr>
<tr><td><code id="snp_getSampleInfos_+3A_...">...</code></td>
<td>
<p>Any additional parameter to pass to <code><a href="bigreadr.html#topic+fread2">bigreadr::fread2()</a></code>.
Particularly, option <code>header = FALSE</code> is sometimes needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The requested information as a <code>data.frame</code>.
</p>


<h3>See Also</h3>

<p><a href="base.html#topic+list.files">list.files</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test &lt;- snp_attachExtdata()
table(test$fam$family.ID)

# Get populations clusters from external files
files &lt;- system.file("extdata", paste0("cluster", 1:3), package = "bigsnpr")
bigreadr::fread2(files[1])
bigreadr::fread2(files[1], header = FALSE)  # need header option here

infos &lt;- snp_getSampleInfos(test, files, header = FALSE)
table(infos[[1]])

</code></pre>

<hr>
<h2 id='snp_lassosum2'>lassosum2</h2><span id='topic+snp_lassosum2'></span>

<h3>Description</h3>

<p>lassosum2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_lassosum2(
  corr,
  df_beta,
  delta = c(0.001, 0.01, 0.1, 1),
  nlambda = 30,
  lambda.min.ratio = 0.01,
  dfmax = 2e+05,
  maxiter = 1000,
  tol = 1e-05,
  ind.corr = cols_along(corr),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_lassosum2_+3A_corr">corr</code></td>
<td>
<p>Sparse correlation matrix as an SFBM.
If <code>corr</code> is a dsCMatrix or a dgCMatrix, you can use <code>as_SFBM(corr)</code>.</p>
</td></tr>
<tr><td><code id="snp_lassosum2_+3A_df_beta">df_beta</code></td>
<td>
<p>A data frame with 3 columns:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$beta&#8288;</code>: effect size estimates
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$beta_se&#8288;</code>: standard errors of effect size estimates
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$n_eff&#8288;</code>: sample size when estimating <code>beta</code>
(in the case of binary traits, this is <code>4 / (1 / n_control + 1 / n_case)</code>)
</p>
</li></ul>
</td></tr>
<tr><td><code id="snp_lassosum2_+3A_delta">delta</code></td>
<td>
<p>Vector of shrinkage parameters to try (L2-regularization).
Default is <code>c(0.001, 0.01, 0.1, 1)</code>.</p>
</td></tr>
<tr><td><code id="snp_lassosum2_+3A_nlambda">nlambda</code></td>
<td>
<p>Number of different lambdas to try (L1-regularization).
Default is <code>30</code>.</p>
</td></tr>
<tr><td><code id="snp_lassosum2_+3A_lambda.min.ratio">lambda.min.ratio</code></td>
<td>
<p>Ratio between last and first lambdas to try.
Default is <code>0.01</code>.</p>
</td></tr>
<tr><td><code id="snp_lassosum2_+3A_dfmax">dfmax</code></td>
<td>
<p>Maximum number of non-zero effects in the model.
Default is <code>200e3</code>.</p>
</td></tr>
<tr><td><code id="snp_lassosum2_+3A_maxiter">maxiter</code></td>
<td>
<p>Maximum number of iterations before convergence.
Default is <code>1000</code>.</p>
</td></tr>
<tr><td><code id="snp_lassosum2_+3A_tol">tol</code></td>
<td>
<p>Tolerance parameter for assessing convergence.
Default is <code>1e-5</code>.</p>
</td></tr>
<tr><td><code id="snp_lassosum2_+3A_ind.corr">ind.corr</code></td>
<td>
<p>Indices to &quot;subset&quot; <code>corr</code>, as if this was run with
<code>corr[ind.corr, ind.corr]</code> instead. No subsetting by default.</p>
</td></tr>
<tr><td><code id="snp_lassosum2_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of effect sizes, one vector (column) for each row in
<code style="white-space: pre;">&#8288;attr(&lt;res&gt;, "grid_param")&#8288;</code>. Missing values are returned when strong
divergence is detected.
</p>

<hr>
<h2 id='snp_ld_scores'>LD scores</h2><span id='topic+snp_ld_scores'></span><span id='topic+bed_ld_scores'></span>

<h3>Description</h3>

<p>LD scores
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_ld_scores(
  Gna,
  ind.row = rows_along(Gna),
  ind.col = cols_along(Gna),
  size = 500,
  infos.pos = NULL,
  ncores = 1
)

bed_ld_scores(
  obj.bed,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  size = 500,
  infos.pos = NULL,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_ld_scores_+3A_gna">Gna</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
You can have missing values in these data.</p>
</td></tr>
<tr><td><code id="snp_ld_scores_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_ld_scores_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_ld_scores_+3A_size">size</code></td>
<td>
<p>For one SNP, window size around this SNP to compute correlations.
Default is <code>500</code>. If not providing <code>infos.pos</code> (<code>NULL</code>, the default), this is
a window in number of SNPs, otherwise it is a window in kb (genetic distance).</p>
</td></tr>
<tr><td><code id="snp_ld_scores_+3A_infos.pos">infos.pos</code></td>
<td>
<p>Vector of integers specifying the physical position
on a chromosome (in base pairs) of each SNP.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$physical.pos&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_ld_scores_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_ld_scores_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of LD scores. For each variant, this is the sum of squared
correlations with the neighboring variants (including itself).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test &lt;- snp_attachExtdata()
G &lt;- test$genotypes

(ld &lt;- snp_ld_scores(G, ind.col = 1:1000))

</code></pre>

<hr>
<h2 id='snp_ldpred2_inf'>LDpred2</h2><span id='topic+snp_ldpred2_inf'></span><span id='topic+snp_ldpred2_grid'></span><span id='topic+snp_ldpred2_auto'></span>

<h3>Description</h3>

<p>LDpred2. Tutorial at <a href="https://privefl.github.io/bigsnpr/articles/LDpred2.html">https://privefl.github.io/bigsnpr/articles/LDpred2.html</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_ldpred2_inf(corr, df_beta, h2)

snp_ldpred2_grid(
  corr,
  df_beta,
  grid_param,
  burn_in = 50,
  num_iter = 100,
  ncores = 1,
  return_sampling_betas = FALSE,
  ind.corr = cols_along(corr)
)

snp_ldpred2_auto(
  corr,
  df_beta,
  h2_init,
  vec_p_init = 0.1,
  burn_in = 500,
  num_iter = 200,
  sparse = FALSE,
  verbose = FALSE,
  report_step = num_iter + 1L,
  allow_jump_sign = TRUE,
  shrink_corr = 1,
  use_MLE = TRUE,
  alpha_bounds = c(-1.5, 0.5),
  ind.corr = cols_along(corr),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_ldpred2_inf_+3A_corr">corr</code></td>
<td>
<p>Sparse correlation matrix as an SFBM.
If <code>corr</code> is a dsCMatrix or a dgCMatrix, you can use <code>as_SFBM(corr)</code>.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_df_beta">df_beta</code></td>
<td>
<p>A data frame with 3 columns:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$beta&#8288;</code>: effect size estimates
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$beta_se&#8288;</code>: standard errors of effect size estimates
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$n_eff&#8288;</code>: sample size when estimating <code>beta</code>
(in the case of binary traits, this is <code>4 / (1 / n_control + 1 / n_case)</code>)
</p>
</li></ul>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_h2">h2</code></td>
<td>
<p>Heritability estimate.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_grid_param">grid_param</code></td>
<td>
<p>A data frame with 3 columns as a grid of hyper-parameters:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$p&#8288;</code>: proportion of causal variants
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$h2&#8288;</code>: heritability (captured by the variants used)
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$sparse&#8288;</code>: boolean, whether a sparse model is sought
They can be run in parallel by changing <code>ncores</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_burn_in">burn_in</code></td>
<td>
<p>Number of burn-in iterations.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_num_iter">num_iter</code></td>
<td>
<p>Number of iterations after burn-in.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_return_sampling_betas">return_sampling_betas</code></td>
<td>
<p>Whether to return all sampling betas (after
burn-in)? This is useful for assessing the uncertainty of the PRS at the
individual level (see <a href="https://doi.org/10.1101/2020.11.30.403188">doi:10.1101/2020.11.30.403188</a>).
Default is <code>FALSE</code> (only returns the averaged final vectors of betas).
If <code>TRUE</code>, only one set of parameters is allowed.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_ind.corr">ind.corr</code></td>
<td>
<p>Indices to &quot;subset&quot; <code>corr</code>, as if this was run with
<code>corr[ind.corr, ind.corr]</code> instead. No subsetting by default.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_h2_init">h2_init</code></td>
<td>
<p>Heritability estimate for initialization.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_vec_p_init">vec_p_init</code></td>
<td>
<p>Vector of initial values for p. Default is <code>0.1</code>.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_sparse">sparse</code></td>
<td>
<p>In LDpred2-auto, whether to also report a sparse solution by
running LDpred2-grid with the estimates of p and h2 from LDpred2-auto, and
sparsity enabled. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_verbose">verbose</code></td>
<td>
<p>Whether to print &quot;p // h2&quot; estimates at each iteration.
Disabled when parallelism is used.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_report_step">report_step</code></td>
<td>
<p>Step to report sampling betas (after burn-in and before
unscaling). Nothing is reported by default. If using <code>num_iter = 200</code> and
<code>report_step = 20</code>, then 10 vectors of sampling betas are reported
(as a sparse matrix with 10 columns).</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_allow_jump_sign">allow_jump_sign</code></td>
<td>
<p>Whether to allow for effects sizes to change sign in
consecutive iterations? Default is <code>TRUE</code> (normal sampling). You can use
<code>FALSE</code> to force effects to go through 0 first before changing sign. Setting
this parameter to <code>FALSE</code> could be useful to prevent instability (oscillation
and ultimately divergence) of the Gibbs sampler. This would also be useful
for accelerating convergence of chains with a large initial value for p.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_shrink_corr">shrink_corr</code></td>
<td>
<p>Shrinkage multiplicative coefficient to apply to off-diagonal
elements of the correlation matrix. Default is <code>1</code> (unchanged).
You can use e.g. <code>0.95</code> to add a bit of regularization.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_use_mle">use_MLE</code></td>
<td>
<p>Whether to use maximum likelihood estimation (MLE) to estimate
alpha and the variance component (since v1.11.4), or assume that alpha is
-1 and estimate the variance of (scaled) effects as h2/(m*p), as it was
done in earlier versions of LDpred2-auto (e.g. in v1.10.8). Default is <code>TRUE</code>,
which should provide a better model fit, but might also be less robust.</p>
</td></tr>
<tr><td><code id="snp_ldpred2_inf_+3A_alpha_bounds">alpha_bounds</code></td>
<td>
<p>Boundaries for the estimates of <code class="reqn">\alpha</code>.
Default is <code>c(-1.5, 0.5)</code>. You can use the same value twice to fix <code class="reqn">\alpha</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For reproducibility, <code>set.seed()</code> can be used to ensure that two runs of
LDpred2 give the exact same results (since v1.10).
</p>


<h3>Value</h3>

<p><code>snp_ldpred2_inf</code>: A vector of effects, assuming an infinitesimal model.
</p>
<p><code>snp_ldpred2_grid</code>: A matrix of effect sizes, one vector (column)
for each row of <code>grid_param</code>. Missing values are returned when strong
divergence is detected. If using <code>return_sampling_betas</code>, each column
corresponds to one iteration instead (after burn-in).
</p>
<p><code>snp_ldpred2_auto</code>: A list (over <code>vec_p_init</code>) of lists with
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$beta_est&#8288;</code>: vector of effect sizes (on the allele scale); note that
missing values are returned when strong divergence is detected
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$beta_est_sparse&#8288;</code> (only when <code>sparse = TRUE</code>): sparse vector of effect sizes
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$postp_est&#8288;</code>: vector of posterior probabilities of being causal
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$corr_est&#8288;</code>, the &quot;imputed&quot; correlations between variants and phenotypes,
which can be used for post-QCing variants by comparing those to
<code>with(df_beta, beta / sqrt(n_eff * beta_se^2 + beta^2))</code>
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$sample_beta&#8288;</code>: sparse matrix of sampling betas (see parameter <code>report_step</code>),
<em>not</em> on the allele scale, for which you need to multiply by
<code>with(df_beta, sqrt(n_eff * beta_se^2 + beta^2))</code>
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$path_p_est&#8288;</code>: full path of p estimates (including burn-in);
useful to check convergence of the iterative algorithm
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$path_h2_est&#8288;</code>: full path of h2 estimates (including burn-in);
useful to check convergence of the iterative algorithm
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$path_alpha_est&#8288;</code>: full path of alpha estimates (including burn-in);
useful to check convergence of the iterative algorithm
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$h2_est&#8288;</code>: estimate of the (SNP) heritability (also see <a href="#topic+coef_to_liab">coef_to_liab</a>)
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$p_est&#8288;</code>: estimate of p, the proportion of causal variants
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$alpha_est&#8288;</code>: estimate of alpha, the parameter controlling the
relationship between allele frequencies and expected effect sizes
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$h2_init&#8288;</code> and <code style="white-space: pre;">&#8288;$p_init&#8288;</code>: input parameters, for convenience
</p>
</li></ul>


<hr>
<h2 id='snp_ldsc'>LD score regression</h2><span id='topic+snp_ldsc'></span><span id='topic+snp_ldsc2'></span>

<h3>Description</h3>

<p>LD score regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_ldsc(
  ld_score,
  ld_size,
  chi2,
  sample_size,
  blocks = 200,
  intercept = NULL,
  chi2_thr1 = 30,
  chi2_thr2 = Inf,
  ncores = 1
)

snp_ldsc2(
  corr,
  df_beta,
  blocks = NULL,
  intercept = 1,
  ncores = 1,
  ind.beta = cols_along(corr),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_ldsc_+3A_ld_score">ld_score</code></td>
<td>
<p>Vector of LD scores.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_ld_size">ld_size</code></td>
<td>
<p>Number of variants used to compute <code>ld_score</code>.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_chi2">chi2</code></td>
<td>
<p>Vector of chi-squared statistics.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_sample_size">sample_size</code></td>
<td>
<p>Sample size of GWAS corresponding to chi-squared statistics.
Possibly a vector, or just a single value.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_blocks">blocks</code></td>
<td>
<p>Either a single number specifying the number of blocks,
or a vector of integers specifying the block number of each <code>chi2</code> value.
Default is <code>200</code> for <code>snp_ldsc()</code>, dividing into 200 blocks of approximately
equal size. <code>NULL</code> can also be used to skip estimating standard errors,
which is the default for <code>snp_ldsc2()</code>.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_intercept">intercept</code></td>
<td>
<p>You can constrain the intercept to some value (e.g. 1).
Default is <code>NULL</code> in <code>snp_ldsc()</code> (the intercept is estimated)
and is <code>1</code> in <code>snp_ldsc2()</code> (the intercept is fixed to 1).
This is equivalent to parameter <code>--intercept-h2</code>.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_chi2_thr1">chi2_thr1</code></td>
<td>
<p>Threshold on <code>chi2</code> in step 1. Default is <code>30</code>.
This is equivalent to parameter <code>--two-step</code>.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_chi2_thr2">chi2_thr2</code></td>
<td>
<p>Threshold on <code>chi2</code> in step 2. Default is <code>Inf</code> (none).</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_corr">corr</code></td>
<td>
<p>Sparse correlation matrix. Can also be an SFBM.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_df_beta">df_beta</code></td>
<td>
<p>A data frame with 3 columns:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$beta&#8288;</code>: effect size estimates
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$beta_se&#8288;</code>: standard errors of effect size estimates
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$n_eff&#8288;</code>: sample size when estimating <code>beta</code>
(in the case of binary traits, this is <code>4 / (1 / n_control + 1 / n_case)</code>)
</p>
</li></ul>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_ind.beta">ind.beta</code></td>
<td>
<p>Indices in <code>corr</code> corresponding to <code>df_beta</code>. Default is all.</p>
</td></tr>
<tr><td><code id="snp_ldsc_+3A_...">...</code></td>
<td>

<p>Arguments passed on to <code><a href="#topic+snp_ldsc">snp_ldsc</a></code>
</p>

<dl>
<dt></dt><dd></dd>
</dl>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector of 4 values (or only the first 2 if <code>blocks = NULL</code>):
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;[["int"]]&#8288;</code>: LDSC regression intercept,
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;[["int_se"]]&#8288;</code>: SE of this intercept,
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;[["h2"]]&#8288;</code>: LDSC regression estimate of (SNP) heritability (also see
<a href="#topic+coef_to_liab">coef_to_liab</a>),
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;[["h2_se"]]&#8288;</code>: SE of this heritability estimate.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>bigsnp &lt;- snp_attachExtdata()
G &lt;- bigsnp$genotypes
y &lt;- bigsnp$fam$affection - 1
corr &lt;- snp_cor(G, ind.col = 1:1000)

gwas &lt;- big_univLogReg(G, y, ind.col = 1:1000)
df_beta &lt;- data.frame(beta = gwas$estim, beta_se = gwas$std.err,
                      n_eff = 4 / (1 / sum(y == 0) + 1 / sum(y == 1)))

snp_ldsc2(corr, df_beta)
snp_ldsc2(corr, df_beta, blocks = 20, intercept = NULL)

</code></pre>

<hr>
<h2 id='snp_ldsplit'>Independent LD blocks</h2><span id='topic+snp_ldsplit'></span>

<h3>Description</h3>

<p>Split a correlation matrix in blocks as independent as possible.
This finds the splitting in blocks that minimizes the sum of squared
correlation between these blocks (i.e. everything outside these blocks).
In case of equivalent splits, it then minimizes the sum of squared sizes
of the blocks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_ldsplit(
  corr,
  thr_r2,
  min_size,
  max_size,
  max_K = 500,
  max_r2 = 0.3,
  max_cost = ncol(corr)/200,
  pos_scaled = rep(0, ncol(corr))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_ldsplit_+3A_corr">corr</code></td>
<td>
<p>Sparse correlation matrix. Usually, the output of <code><a href="#topic+snp_cor">snp_cor()</a></code>.</p>
</td></tr>
<tr><td><code id="snp_ldsplit_+3A_thr_r2">thr_r2</code></td>
<td>
<p>Threshold under which squared correlations are ignored.
This is useful to avoid counting noise, which should give clearer patterns
of costs vs. number of blocks. It is therefore possible to have a splitting
cost of 0. If this parameter is used, then <code>corr</code> can be computed using the
same parameter in <code><a href="#topic+snp_cor">snp_cor()</a></code> (to increase the sparsity of the resulting matrix).</p>
</td></tr>
<tr><td><code id="snp_ldsplit_+3A_min_size">min_size</code></td>
<td>
<p>Minimum number of variants in each block. This is used not to
have a disproportionate number of small blocks.</p>
</td></tr>
<tr><td><code id="snp_ldsplit_+3A_max_size">max_size</code></td>
<td>
<p>Maximum number of variants in each block. This is used not to
have blocks that are too large, e.g. to limit computational and memory
requirements of applications that would use these blocks. For some long-range
LD regions, it may be needed to allow for large blocks. You can now provide a
vector of values to try.</p>
</td></tr>
<tr><td><code id="snp_ldsplit_+3A_max_k">max_K</code></td>
<td>
<p>Maximum number of blocks to consider. All optimal solutions for K
from 1 to <code>max_K</code> will be returned. Some of these K might not have any corresponding
solution due to the limitations in size of the blocks. For example, splitting
10,000 variants in blocks with at least 500 and at most 2000 variants implies
that there are at least 5 and at most 20 blocks. Then, the choice of K depends
on the application, but a simple solution is to choose the largest K for which
the cost is lower than some threshold. Default is <code>500</code>.</p>
</td></tr>
<tr><td><code id="snp_ldsplit_+3A_max_r2">max_r2</code></td>
<td>
<p>Maximum squared correlation allowed for one pair of variants in
two different blocks. This is used to make sure that strong correlations are
not discarded and also to speed up the algorithm. Default is <code>0.3</code>.</p>
</td></tr>
<tr><td><code id="snp_ldsplit_+3A_max_cost">max_cost</code></td>
<td>
<p>Maximum cost reported. Default is <code>ncol(corr) / 200</code>.</p>
</td></tr>
<tr><td><code id="snp_ldsplit_+3A_pos_scaled">pos_scaled</code></td>
<td>
<p>Vector of positions. The positions should be scaled so that
limits of a block must be separated by a distance of 1 at the maximum. E.g.
if the positions are in base pairs (bp), and you want a maximum distance of
10 Mbp, you need to provide the vector of positions divided by 10e6.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either <code>NULL</code> when no block splitting satisfies the conditions,
or a tibble with seven columns:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$max_size&#8288;</code>: Input parameter, useful when providing a vector of values to try.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$n_block&#8288;</code>: Number of blocks.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$cost&#8288;</code>: The sum of squared correlations outside the blocks.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$cost2&#8288;</code>: The sum of squared sizes of the blocks.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$perc_kept&#8288;</code>: Percentage of initial non-zero values kept within the blocks defined.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$all_last&#8288;</code>: Last index of each block.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$all_size&#8288;</code>: Sizes of the blocks.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$block_num&#8288;</code>: Resulting block numbers for each variant. This is not reported
anymore, but can be computed with <code>rep(seq_along(all_size), all_size)</code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

  corr &lt;- readRDS(url("https://www.dropbox.com/s/65u96jf7y32j2mj/spMat.rds?raw=1"))

  # adjust `THR_R2` depending on sample size used to compute corr
  # use e.g. 0.05 for small sample sizes, and 0.01 for large sample sizes
  THR_R2 &lt;- 0.02
  m &lt;- ncol(corr)
  (SEQ &lt;- round(seq_log(m / 30, m / 5, length.out = 10)))
  # replace `min_size` by e.g. 100 for larger data
  (res &lt;- snp_ldsplit(corr, thr_r2 = THR_R2, min_size = 10, max_size = SEQ))

  # add the variant block IDs corresponding to each split
  res$block_num &lt;- lapply(res$all_size, function(.) rep(seq_along(.), .))

  library(ggplot2)
  # trade-off cost / number of blocks
  qplot(n_block, cost, color = factor(max_size, SEQ), data = res) +
    theme_bw(14) +
    scale_y_log10() +
    theme(legend.position = "top") +
    labs(x = "Number of blocks", color = "Maximum block size",
         y = "Sum of squared correlations outside blocks")

  # trade-off cost / number of non-zero values
  qplot(perc_kept, cost, color = factor(max_size, SEQ), data = res) +
    theme_bw(14) +
    # scale_y_log10() +
    theme(legend.position = "top") +
    labs(x = "Percentage of non-zero values kept", color = "Maximum block size",
         y = "Sum of squared correlations outside blocks")

  # trade-off cost / sum of squared sizes
  qplot(cost2, cost, color = factor(max_size, SEQ), data = res) +
    theme_bw(14) +
    scale_y_log10() +
    geom_vline(xintercept = 0)+
    theme(legend.position = "top") +
    labs(x = "Sum of squared blocks", color = "Maximum block size",
         y = "Sum of squared correlations outside blocks")


  ## Pick one solution and visualize blocks
  library(dplyr)
  all_ind &lt;- res %&gt;%
    arrange(cost2 * sqrt(5 + cost)) %&gt;%
    print() %&gt;%
    slice(1) %&gt;%
    pull(all_last)

  ## Transform sparse representation into (i,j,x) triplets
  corrT &lt;- as(corr, "dgTMatrix")
  upper &lt;- (corrT@i &lt;= corrT@j &amp; corrT@x^2 &gt;= THR_R2)
  df &lt;- data.frame(
    i = corrT@i[upper] + 1L,
    j = corrT@j[upper] + 1L,
    r2 = corrT@x[upper]^2
  )
  df$y &lt;- (df$j - df$i) / 2

  ggplot(df) +
    geom_point(aes(i + y, y, alpha = r2)) +
    theme_minimal() +
    theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
          strip.background = element_blank(), strip.text.x = element_blank()) +
    scale_alpha_continuous(range = 0:1) +
    scale_x_continuous(expand = c(0.02, 0.02), minor_breaks = NULL,
                       breaks = head(all_ind[[1]], -1) + 0.5) +
    facet_wrap(~ cut(i + y, 4), scales = "free", ncol = 1) +
    labs(x = "Position", y = NULL)

## End(Not run)
</code></pre>

<hr>
<h2 id='snp_MAF'>MAF</h2><span id='topic+snp_MAF'></span>

<h3>Description</h3>

<p>Minor Allele Frequency.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_MAF(
  G,
  ind.row = rows_along(G),
  ind.col = cols_along(G),
  nploidy = 2,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_MAF_+3A_g">G</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
<strong>You shouldn't have missing values.</strong> Also, remember to do quality control,
e.g. some algorithms in this package won't work if you use SNPs with 0 MAF.</p>
</td></tr>
<tr><td><code id="snp_MAF_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_MAF_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_MAF_+3A_nploidy">nploidy</code></td>
<td>
<p>Number of trials, parameter of the binomial distribution.
Default is <code>2</code>, which corresponds to diploidy, such as for the human genome.</p>
</td></tr>
<tr><td><code id="snp_MAF_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of MAFs, corresponding to <code>ind.col</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>obj.bigsnp &lt;- snp_attachExtdata()
str(maf &lt;- snp_MAF(obj.bigsnp$genotypes))

</code></pre>

<hr>
<h2 id='snp_manhattan'>Manhattan plot</h2><span id='topic+snp_manhattan'></span>

<h3>Description</h3>

<p>Creates a manhattan plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_manhattan(
  gwas,
  infos.chr,
  infos.pos,
  colors = c("black", "grey60"),
  dist.sep.chrs = 1e+07,
  ind.highlight = integer(0),
  col.highlight = "red",
  labels = NULL,
  npoints = NULL,
  coeff = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_manhattan_+3A_gwas">gwas</code></td>
<td>
<p>A <code>mhtest</code> object with the p-values associated with each SNP.
Typically, the output of big_univLinReg, big_univLogReg or <a href="#topic+snp_pcadapt">snp_pcadapt</a>.</p>
</td></tr>
<tr><td><code id="snp_manhattan_+3A_infos.chr">infos.chr</code></td>
<td>
<p>Vector of integers specifying each SNP's chromosome.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$chromosome&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_manhattan_+3A_infos.pos">infos.pos</code></td>
<td>
<p>Vector of integers specifying the physical position
on a chromosome (in base pairs) of each SNP.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$physical.pos&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_manhattan_+3A_colors">colors</code></td>
<td>
<p>Colors used for each chromosome (they are recycled).
Default is an alternation of black and gray.</p>
</td></tr>
<tr><td><code id="snp_manhattan_+3A_dist.sep.chrs">dist.sep.chrs</code></td>
<td>
<p>&quot;Physical&quot; distance that separates two chromosomes.
Default is 10 Mbp.</p>
</td></tr>
<tr><td><code id="snp_manhattan_+3A_ind.highlight">ind.highlight</code></td>
<td>
<p>Indices of SNPs you want to highlight (of interest).
Default doesn't highlight any SNPs.</p>
</td></tr>
<tr><td><code id="snp_manhattan_+3A_col.highlight">col.highlight</code></td>
<td>
<p>Color used for highlighting SNPs. Default uses red.</p>
</td></tr>
<tr><td><code id="snp_manhattan_+3A_labels">labels</code></td>
<td>
<p>Labels of the x axis. Default uses the number of the
chromosome there are in <code>infos.chr</code>(<code>sort(unique(infos.chr))</code>). This may be
useful to restrict the number of labels so that they are not overlapping.</p>
</td></tr>
<tr><td><code id="snp_manhattan_+3A_npoints">npoints</code></td>
<td>
<p>Number of points to keep (ranked by p-value) in order to get
a lighter object (and plot). Default doesn't cut anything.
If used, the resulting object will have an attribute called <code>subset</code>
giving the indices of the kept points.</p>
</td></tr>
<tr><td><code id="snp_manhattan_+3A_coeff">coeff</code></td>
<td>
<p>Relative size of text. Default is <code>1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If you don't have information of chromosome and position, you should simply
use <code>plot</code> instead.
</p>


<h3>Value</h3>

<p>A <code>ggplot2</code> object. You can plot it using the <code>print</code> method.
You can modify it as you wish by adding layers. You might want to read
<a href="https://r4ds.had.co.nz/data-visualisation.html">this chapter</a>
to get more familiar with the package <strong>ggplot2</strong>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(9)

test &lt;- snp_attachExtdata()
G &lt;- test$genotypes
y &lt;- rnorm(nrow(G))

gwas &lt;- big_univLinReg(G, y)
snp_qq(gwas)
gwas_gc &lt;- snp_gc(gwas) # change attr(gwas_gc, "transfo")

snp_qq(gwas_gc)
# The next plot should be prettier with a real dataset
snp_manhattan(gwas_gc,
              infos.chr = test$map$chromosome,
              infos.pos = test$map$physical.pos)

p &lt;- snp_qq(gwas_gc) + ggplot2::aes(text = asPlotlyText(test$map))
## Not run: plotly::ggplotly(p, tooltip = "text")
</code></pre>

<hr>
<h2 id='snp_match'>Match alleles</h2><span id='topic+snp_match'></span>

<h3>Description</h3>

<p>Match alleles between summary statistics and SNP information.
Match by (&quot;chr&quot;, &quot;a0&quot;, &quot;a1&quot;) and (&quot;pos&quot; or &quot;rsid&quot;), accounting for possible
strand flips and reverse reference alleles (opposite effects).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_match(
  sumstats,
  info_snp,
  strand_flip = TRUE,
  join_by_pos = TRUE,
  remove_dups = TRUE,
  match.min.prop = 0.2,
  return_flip_and_rev = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_match_+3A_sumstats">sumstats</code></td>
<td>
<p>A data frame with columns &quot;chr&quot;, &quot;pos&quot;, &quot;a0&quot;, &quot;a1&quot; and &quot;beta&quot;.</p>
</td></tr>
<tr><td><code id="snp_match_+3A_info_snp">info_snp</code></td>
<td>
<p>A data frame with columns &quot;chr&quot;, &quot;pos&quot;, &quot;a0&quot; and &quot;a1&quot;.</p>
</td></tr>
<tr><td><code id="snp_match_+3A_strand_flip">strand_flip</code></td>
<td>
<p>Whether to try to flip strand? (default is <code>TRUE</code>)
If so, ambiguous alleles A/T and C/G are removed.</p>
</td></tr>
<tr><td><code id="snp_match_+3A_join_by_pos">join_by_pos</code></td>
<td>
<p>Whether to join by chromosome and position (default),
or instead by rsid.</p>
</td></tr>
<tr><td><code id="snp_match_+3A_remove_dups">remove_dups</code></td>
<td>
<p>Whether to remove duplicates (same physical position)?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="snp_match_+3A_match.min.prop">match.min.prop</code></td>
<td>
<p>Minimum proportion of variants in the smallest data
to be matched, otherwise stops with an error. Default is <code style="white-space: pre;">&#8288;20%&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_match_+3A_return_flip_and_rev">return_flip_and_rev</code></td>
<td>
<p>Whether to return internal boolean variables
<code>"_FLIP_"</code> (whether the alleles must be flipped: A &lt;&ndash;&gt; T &amp; C &lt;&ndash;&gt; G,
because on the opposite strand) and <code>"_REV_"</code> (whether alleles must be
swapped: <code style="white-space: pre;">&#8288;$a0&#8288;</code> &lt;&ndash;&gt; <code style="white-space: pre;">&#8288;$a1&#8288;</code>, in which case corresponding <code style="white-space: pre;">&#8288;$beta&#8288;</code> are multiplied
by -1). Default is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A single data frame with matched variants. Values in column <code style="white-space: pre;">&#8288;$beta&#8288;</code>
are multiplied by -1 for variants with alleles reversed (i.e. swapped).
New variable <code>"_NUM_ID_.ss"</code> returns the corresponding row indices of the
input <code>sumstats</code> (first argument of this function), and <code>"_NUM_ID_"</code>
corresponding to the input <code>info_snp</code> (second argument).
</p>


<h3>See Also</h3>

<p><a href="#topic+snp_modifyBuild">snp_modifyBuild</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sumstats &lt;- data.frame(
  chr = 1,
  pos = c(86303, 86331, 162463, 752566, 755890, 758144),
  a0 = c("T", "G", "C", "A", "T", "G"),
  a1 = c("G", "A", "T", "G", "A", "A"),
  beta = c(-1.868, 0.250, -0.671, 2.112, 0.239, 1.272),
  p = c(0.860, 0.346, 0.900, 0.456, 0.776, 0.383)
)

info_snp &lt;- data.frame(
  id = c("rs2949417", "rs115209712", "rs143399298", "rs3094315", "rs3115858"),
  chr = 1,
  pos = c(86303, 86331, 162463, 752566, 755890),
  a0 = c("T", "A", "G", "A", "T"),
  a1 = c("G", "G", "A", "G", "A")
)

snp_match(sumstats, info_snp)
snp_match(sumstats, info_snp, strand_flip = FALSE)
</code></pre>

<hr>
<h2 id='snp_MAX3'>MAX3 statistic</h2><span id='topic+snp_MAX3'></span>

<h3>Description</h3>

<p>Compute the MAX3 statistic, which tests for three genetic models
(additive, recessive and dominant).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_MAX3(Gna, y01.train, ind.train = rows_along(Gna), val = c(0, 0.5, 1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_MAX3_+3A_gna">Gna</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
You can have missing values in these data.</p>
</td></tr>
<tr><td><code id="snp_MAX3_+3A_y01.train">y01.train</code></td>
<td>
<p>Vector of responses, corresponding to <code>ind.train</code>.
<strong>Must be only 0s and 1s.</strong></p>
</td></tr>
<tr><td><code id="snp_MAX3_+3A_ind.train">ind.train</code></td>
<td>
<p>An optional vector of the row indices that are used,
for the training part. If not specified, all rows are used.
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_MAX3_+3A_val">val</code></td>
<td>
<p>Computing <code class="reqn">\smash{\displaystyle\max_{x \in val}}~Z_{CATT}^2(x)</code>.
</p>

<ul>
<li><p> Default is <code>c(0, 0.5, 1)</code> and corresponds to the <em>MAX3</em> statistic.
</p>
</li>
<li><p> Only <code>c(0, 1)</code> corresponds to <em>MAX2</em>.
</p>
</li>
<li><p> And only <code>0.5</code> corresponds to the Armitage trend test.
</p>
</li>
<li><p> Finally, <code>seq(0, 1, length.out = L)</code> corresponds to <em>MAXL</em>.
</p>
</li></ul>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>P-values associated with returned scores are in fact the minimum of the
p-values of each test separately. Thus, they are biased downward.</strong>
</p>


<h3>Value</h3>

<p>An object of classes <code>mhtest</code> and <code>data.frame</code> returning one
score by SNP. See <code>methods(class = "mhtest")</code>.
</p>


<h3>References</h3>

<p>Zheng, G., Yang, Y., Zhu, X., &amp; Elston, R. (2012).
Robust Procedures. Analysis Of Genetic Association Studies, 151-206.
<a href="https://doi.org/10.1007/978-1-4614-2245-7_6">doi:10.1007/978-1-4614-2245-7_6</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

# constructing a fake genotype big.matrix
N &lt;- 50; M &lt;- 1200
fake &lt;- snp_fake(N, M)
G &lt;- fake$genotypes
G[] &lt;- sample(as.raw(0:3), size = length(G), replace = TRUE)
G[1:8, 1:10]

# Specify case/control phenotypes
fake$fam$affection &lt;- rep(1:2, each = N / 2)

# Get MAX3 statistics
y01 &lt;- fake$fam$affection - 1
str(test &lt;- snp_MAX3(fake$genotypes, y01.train = y01))
# p-values are not well calibrated
snp_qq(test)
# genomic control is not of much help
snp_qq(snp_gc(test))

# Armitage trend test (well calibrated because only one test)
test2 &lt;- snp_MAX3(fake$genotypes, y01.train = y01, val = 0.5)
snp_qq(test2)

</code></pre>

<hr>
<h2 id='snp_modifyBuild'>Modify genome build</h2><span id='topic+snp_modifyBuild'></span>

<h3>Description</h3>

<p>Modify the physical position information of a data frame
when converting genome build using executable <em>liftOver</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_modifyBuild(
  info_snp,
  liftOver,
  from = "hg18",
  to = "hg19",
  check_reverse = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_modifyBuild_+3A_info_snp">info_snp</code></td>
<td>
<p>A data frame with columns &quot;chr&quot; and &quot;pos&quot;.</p>
</td></tr>
<tr><td><code id="snp_modifyBuild_+3A_liftover">liftOver</code></td>
<td>
<p>Path to liftOver executable. Binaries can be downloaded at
<a href="https://hgdownload.cse.ucsc.edu/admin/exe/macOSX.x86_64/liftOver">https://hgdownload.cse.ucsc.edu/admin/exe/macOSX.x86_64/liftOver</a> for Mac
and at <a href="https://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/liftOver">https://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/liftOver</a>
for Linux.</p>
</td></tr>
<tr><td><code id="snp_modifyBuild_+3A_from">from</code></td>
<td>
<p>Genome build to convert from. Default is <code>hg18</code>.</p>
</td></tr>
<tr><td><code id="snp_modifyBuild_+3A_to">to</code></td>
<td>
<p>Genome build to convert to. Default is <code>hg19</code>.</p>
</td></tr>
<tr><td><code id="snp_modifyBuild_+3A_check_reverse">check_reverse</code></td>
<td>
<p>Whether to discard positions for which we cannot go back
to initial values by doing 'from -&gt; to -&gt; from'. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Input data frame <code>info_snp</code> with column &quot;pos&quot; in the new build.
</p>


<h3>References</h3>

<p>Hinrichs, Angela S., et al. &quot;The UCSC genome browser database: update 2006.&quot;
Nucleic acids research 34.suppl_1 (2006): D590-D598.
</p>

<hr>
<h2 id='snp_pcadapt'>Outlier detection</h2><span id='topic+snp_pcadapt'></span><span id='topic+bed_pcadapt'></span>

<h3>Description</h3>

<p>Method to detect genetic markers involved in biological adaptation.
This provides a statistical tool for outlier detection based on
Principal Component Analysis. This corresponds to the statistic based
on mahalanobis distance, as implemented in package <strong>pcadapt</strong>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_pcadapt(
  G,
  U.row,
  ind.row = rows_along(G),
  ind.col = cols_along(G),
  ncores = 1
)

bed_pcadapt(
  obj.bed,
  U.row,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_pcadapt_+3A_g">G</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
<strong>You shouldn't have missing values.</strong> Also, remember to do quality control,
e.g. some algorithms in this package won't work if you use SNPs with 0 MAF.</p>
</td></tr>
<tr><td><code id="snp_pcadapt_+3A_u.row">U.row</code></td>
<td>
<p>Left singular vectors (not scores, <code class="reqn">U^T U = I</code>)
corresponding to <code>ind.row</code>.</p>
</td></tr>
<tr><td><code id="snp_pcadapt_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_pcadapt_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_pcadapt_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_pcadapt_+3A_obj.bed">obj.bed</code></td>
<td>
<p>Object of type <a href="#topic+bed">bed</a>, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of classes <code>mhtest</code> and <code>data.frame</code> returning one
score by SNP. See <code>methods(class = "mhtest")</code>.
</p>


<h3>References</h3>

<p>Luu, K., Bazin, E., &amp; Blum, M. G. (2017).
pcadapt: an R package to perform genome scans for selection
based on principal component analysis.
Molecular ecology resources, 17(1), 67-77.
</p>


<h3>See Also</h3>

<p><a href="#topic+snp_manhattan">snp_manhattan</a>, <a href="#topic+snp_qq">snp_qq</a> and <a href="#topic+snp_gc">snp_gc</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test &lt;- snp_attachExtdata()
G &lt;- test$genotypes
obj.svd &lt;- big_SVD(G, fun.scaling = snp_scaleBinom(), k = 10)
plot(obj.svd) # there seems to be 3 "significant" components
pcadapt &lt;- snp_pcadapt(G, obj.svd$u[, 1:3])
snp_qq(pcadapt)

</code></pre>

<hr>
<h2 id='snp_plinkIBDQC'>Identity-by-descent</h2><span id='topic+snp_plinkIBDQC'></span>

<h3>Description</h3>

<p>Quality Control based on Identity-by-descent (IBD) computed by
<a href="https://www.cog-genomics.org/plink2"><strong>PLINK 1.9</strong></a>
using its method-of-moments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_plinkIBDQC(
  plink.path,
  bedfile.in,
  bedfile.out = NULL,
  pi.hat = 0.08,
  ncores = 1,
  pruning.args = c(100, 0.2),
  do.blind.QC = TRUE,
  extra.options = "",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_plinkIBDQC_+3A_plink.path">plink.path</code></td>
<td>
<p>Path to the executable of PLINK 1.9.</p>
</td></tr>
<tr><td><code id="snp_plinkIBDQC_+3A_bedfile.in">bedfile.in</code></td>
<td>
<p>Path to the input bedfile.</p>
</td></tr>
<tr><td><code id="snp_plinkIBDQC_+3A_bedfile.out">bedfile.out</code></td>
<td>
<p>Path to the output bedfile. Default is created by
appending <code>"_norel"</code> to <code>prefix.in</code> (<code>bedfile.in</code> without extension).</p>
</td></tr>
<tr><td><code id="snp_plinkIBDQC_+3A_pi.hat">pi.hat</code></td>
<td>
<p>PI_HAT value threshold for individuals (first by pairs)
to be excluded. Default is <code>0.08</code>.</p>
</td></tr>
<tr><td><code id="snp_plinkIBDQC_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_plinkIBDQC_+3A_pruning.args">pruning.args</code></td>
<td>
<p>A vector of 2 pruning parameters, respectively
the window size (in variant count) and the pairwise $r^2$ threshold
(the step size is fixed to 1). Default is <code>c(100, 0.2)</code>.</p>
</td></tr>
<tr><td><code id="snp_plinkIBDQC_+3A_do.blind.qc">do.blind.QC</code></td>
<td>
<p>Whether to do QC with <code>pi.hat</code> without visual inspection.
Default is <code>TRUE</code>. If <code>FALSE</code>, return the <code>data.frame</code> of the corresponding
&quot;.genome&quot; file without doing QC. One could use
<code>ggplot2::qplot(Z0, Z1, data = mydf, col = RT)</code> for visual inspection.</p>
</td></tr>
<tr><td><code id="snp_plinkIBDQC_+3A_extra.options">extra.options</code></td>
<td>
<p>Other options to be passed to PLINK as a string
(for the IBD part). More options can be found at
<a href="https://www.cog-genomics.org/plink/1.9/ibd">https://www.cog-genomics.org/plink/1.9/ibd</a>.</p>
</td></tr>
<tr><td><code id="snp_plinkIBDQC_+3A_verbose">verbose</code></td>
<td>
<p>Whether to show PLINK log? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The path of the new bedfile.
If no sample is filter, no new bed/bim/fam files are created and
then the path of the input bedfile is returned.
</p>


<h3>References</h3>

<p>Chang, Christopher C, Carson C Chow, Laurent CAM Tellier,
Shashaank Vattikuti, Shaun M Purcell, and James J Lee. 2015.
<em>Second-generation PLINK: rising to the challenge of larger and richer
datasets.</em> GigaScience 4 (1): 7. <a href="https://doi.org/10.1186/s13742-015-0047-8">doi:10.1186/s13742-015-0047-8</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+download_plink">download_plink</a> <a href="#topic+snp_plinkQC">snp_plinkQC</a> <a href="#topic+snp_plinkKINGQC">snp_plinkKINGQC</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr")
plink &lt;- download_plink()

bedfile &lt;- snp_plinkIBDQC(plink, bedfile,
                          bedfile.out = tempfile(fileext = ".bed"),
                          ncores = 2)

df_rel &lt;- snp_plinkIBDQC(plink, bedfile, do.blind.QC = FALSE, ncores = 2)
str(df_rel)

library(ggplot2)
qplot(Z0, Z1, data = df_rel, col = RT)
qplot(y = PI_HAT, data = df_rel) +
  geom_hline(yintercept = 0.2, color = "blue", linetype = 2)
snp_plinkRmSamples(plink, bedfile,
                   bedfile.out = tempfile(fileext = ".bed"),
                   df.or.files = subset(df_rel, PI_HAT &gt; 0.2))

## End(Not run)

</code></pre>

<hr>
<h2 id='snp_plinkKINGQC'>Relationship-based pruning</h2><span id='topic+snp_plinkKINGQC'></span>

<h3>Description</h3>

<p>Quality Control based on KING-robust kinship estimator. More information can
be found at <a href="https://www.cog-genomics.org/plink/2.0/distance#king_cutoff">https://www.cog-genomics.org/plink/2.0/distance#king_cutoff</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_plinkKINGQC(
  plink2.path,
  bedfile.in,
  bedfile.out = NULL,
  thr.king = 2^-3.5,
  make.bed = TRUE,
  ncores = 1,
  extra.options = "",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_plinkKINGQC_+3A_plink2.path">plink2.path</code></td>
<td>
<p>Path to the executable of PLINK 2.</p>
</td></tr>
<tr><td><code id="snp_plinkKINGQC_+3A_bedfile.in">bedfile.in</code></td>
<td>
<p>Path to the input bedfile.</p>
</td></tr>
<tr><td><code id="snp_plinkKINGQC_+3A_bedfile.out">bedfile.out</code></td>
<td>
<p>Path to the output bedfile. Default is created by
appending <code>"_norel"</code> to <code>prefix.in</code> (<code>bedfile.in</code> without extension).</p>
</td></tr>
<tr><td><code id="snp_plinkKINGQC_+3A_thr.king">thr.king</code></td>
<td>
<p>Note that KING kinship coefficients are scaled such that
duplicate samples have kinship 0.5, not 1. First-degree relations
(parent-child, full siblings) correspond to ~0.25, second-degree relations
correspond to ~0.125, etc. It is conventional to use a cutoff of ~0.354
(2^-1.5, the geometric mean of 0.5 and 0.25) to screen for monozygotic
twins and duplicate samples, ~0.177 (2^-2.5) to remove first-degree
relations as well, and ~0.0884 (2^-3.5, <strong>default</strong>) to remove
second-degree relations as well, etc.</p>
</td></tr>
<tr><td><code id="snp_plinkKINGQC_+3A_make.bed">make.bed</code></td>
<td>
<p>Whether to create new bed/bim/fam files (default).
Otherwise, returns a table with coefficients of related pairs.</p>
</td></tr>
<tr><td><code id="snp_plinkKINGQC_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_plinkKINGQC_+3A_extra.options">extra.options</code></td>
<td>
<p>Other options to be passed to PLINK2 as a string.</p>
</td></tr>
<tr><td><code id="snp_plinkKINGQC_+3A_verbose">verbose</code></td>
<td>
<p>Whether to show PLINK log? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>See parameter <code>make-bed</code>.
</p>


<h3>References</h3>

<p>Manichaikul, Ani, Josyf C. Mychaleckyj, Stephen S. Rich, Kathy Daly,
Michele Sale, and Wei-Min Chen. &quot;Robust relationship inference in genome-wide
association studies.&quot; Bioinformatics 26, no. 22 (2010): 2867-2873.
</p>


<h3>See Also</h3>

<p><a href="#topic+download_plink2">download_plink2</a> <a href="#topic+snp_plinkQC">snp_plinkQC</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr")
plink2 &lt;- download_plink2(AVX2 = FALSE)

bedfile2 &lt;- snp_plinkKINGQC(plink2, bedfile,
                            bedfile.out = tempfile(fileext = ".bed"),
                            ncores = 2)

df_rel &lt;- snp_plinkKINGQC(plink2, bedfile, make.bed = FALSE, ncores = 2)
str(df_rel)

## End(Not run)

</code></pre>

<hr>
<h2 id='snp_plinkQC'>Quality Control</h2><span id='topic+snp_plinkQC'></span>

<h3>Description</h3>

<p>Quality Control (QC) and possible conversion to <em>bed</em>/<em>bim</em>/<em>fam</em> files
using <a href="https://www.cog-genomics.org/plink2"><strong>PLINK 1.9</strong></a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_plinkQC(
  plink.path,
  prefix.in,
  file.type = "--bfile",
  prefix.out = paste0(prefix.in, "_QC"),
  maf = 0.01,
  geno = 0.1,
  mind = 0.1,
  hwe = 1e-50,
  autosome.only = FALSE,
  extra.options = "",
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_plinkQC_+3A_plink.path">plink.path</code></td>
<td>
<p>Path to the executable of PLINK 1.9.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_prefix.in">prefix.in</code></td>
<td>
<p>Prefix (path without extension) of the dataset to be QCed.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_file.type">file.type</code></td>
<td>
<p>Type of the dataset to be QCed. Default is <code>"--bfile"</code> and
corresponds to bed/bim/fam files. You can also use <code>"--file"</code> for ped/map
files, <code>"--vcf"</code> for a VCF file, or <code>"--gzvcf"</code> for a gzipped VCF.
More information can be found at
<a href="https://www.cog-genomics.org/plink/1.9/input">https://www.cog-genomics.org/plink/1.9/input</a>.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_prefix.out">prefix.out</code></td>
<td>
<p>Prefix (path without extension) of the bed/bim/fam dataset
to be created. Default is created by appending <code>"_QC"</code> to <code>prefix.in</code>.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_maf">maf</code></td>
<td>
<p>Minimum Minor Allele Frequency (MAF) for a SNP to be kept.
Default is <code>0.01</code>.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_geno">geno</code></td>
<td>
<p>Maximum proportion of missing values for a SNP to be kept.
Default is <code>0.1</code>.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_mind">mind</code></td>
<td>
<p>Maximum proportion of missing values for a sample to be kept.
Default is <code>0.1</code>.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_hwe">hwe</code></td>
<td>
<p>Filters out all variants which have Hardy-Weinberg equilibrium
exact test p-value below the provided threshold. Default is <code>1e-50</code>.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_autosome.only">autosome.only</code></td>
<td>
<p>Whether to exclude all unplaced and non-autosomal
variants? Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_extra.options">extra.options</code></td>
<td>
<p>Other options to be passed to PLINK as a string. More
options can be found at <a href="https://www.cog-genomics.org/plink2/filter">https://www.cog-genomics.org/plink2/filter</a>.
If using PLINK 2.0, you could e.g. use <code>"--king-cutoff 0.0884"</code> to remove
some related samples at the same time of quality controls.</p>
</td></tr>
<tr><td><code id="snp_plinkQC_+3A_verbose">verbose</code></td>
<td>
<p>Whether to show PLINK log? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The path of the newly created bedfile.
</p>


<h3>References</h3>

<p>Chang, Christopher C, Carson C Chow, Laurent CAM Tellier,
Shashaank Vattikuti, Shaun M Purcell, and James J Lee. 2015.
<em>Second-generation PLINK: rising to the challenge of larger and richer
datasets.</em> GigaScience 4 (1): 7. <a href="https://doi.org/10.1186/s13742-015-0047-8">doi:10.1186/s13742-015-0047-8</a>.
</p>


<h3>See Also</h3>

<p><a href="#topic+download_plink">download_plink</a> <a href="#topic+snp_plinkIBDQC">snp_plinkIBDQC</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr")
prefix  &lt;- sub_bed(bedfile)
plink &lt;- download_plink()
test &lt;- snp_plinkQC(plink.path = plink,
                    prefix.in = prefix,
                    prefix.out = tempfile(),
                    file.type = "--bfile",  # the default (for ".bed")
                    maf = 0.05,
                    geno = 0.05,
                    mind = 0.05,
                    hwe = 1e-10,
                    autosome.only = TRUE)
test

## End(Not run)

</code></pre>

<hr>
<h2 id='snp_plinkRmSamples'>Remove samples</h2><span id='topic+snp_plinkRmSamples'></span>

<h3>Description</h3>

<p>Create new <em>bed</em>/<em>bim</em>/<em>fam</em> files by removing samples with PLINK.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_plinkRmSamples(
  plink.path,
  bedfile.in,
  bedfile.out,
  df.or.files,
  col.family.ID = 1,
  col.sample.ID = 2,
  ...,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_plinkRmSamples_+3A_plink.path">plink.path</code></td>
<td>
<p>Path to the executable of PLINK 1.9.</p>
</td></tr>
<tr><td><code id="snp_plinkRmSamples_+3A_bedfile.in">bedfile.in</code></td>
<td>
<p>Path to the input bedfile.</p>
</td></tr>
<tr><td><code id="snp_plinkRmSamples_+3A_bedfile.out">bedfile.out</code></td>
<td>
<p>Path to the output bedfile.</p>
</td></tr>
<tr><td><code id="snp_plinkRmSamples_+3A_df.or.files">df.or.files</code></td>
<td>
<p>Either
</p>

<ul>
<li><p> A <code>data.frame</code>,
</p>
</li>
<li><p> A character vector of file names where to find at the information you want.
You should have one column for family IDs and one for sample IDs.
</p>
</li></ul>
</td></tr>
<tr><td><code id="snp_plinkRmSamples_+3A_col.family.id">col.family.ID</code></td>
<td>
<p>Index of the column containing the family IDs to match
with those of the study. Default is the first one.</p>
</td></tr>
<tr><td><code id="snp_plinkRmSamples_+3A_col.sample.id">col.sample.ID</code></td>
<td>
<p>Index of the column containing the sample IDs to match
with those of the study. Default is the second one.</p>
</td></tr>
<tr><td><code id="snp_plinkRmSamples_+3A_...">...</code></td>
<td>
<p>Any additional parameter to pass to <code><a href="bigreadr.html#topic+fread2">bigreadr::fread2()</a></code>.
Particularly, option <code>header = FALSE</code> is sometimes needed.</p>
</td></tr>
<tr><td><code id="snp_plinkRmSamples_+3A_verbose">verbose</code></td>
<td>
<p>Whether to show PLINK log? Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The path of the new bedfile.
</p>


<h3>See Also</h3>

<p><a href="#topic+download_plink">download_plink</a>
</p>

<hr>
<h2 id='snp_prodBGEN'>BGEN matrix product</h2><span id='topic+snp_prodBGEN'></span>

<h3>Description</h3>

<p>Compute a matrix product between BGEN files and a matrix. This removes the
need to read an intermediate FBM object with <code><a href="#topic+snp_readBGEN">snp_readBGEN()</a></code> to compute the
product. Moreover, when using dosages, they are not rounded to two decimal
places anymore.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_prodBGEN(
  bgenfiles,
  beta,
  list_snp_id,
  ind_row = NULL,
  bgi_dir = dirname(bgenfiles),
  read_as = c("dosage", "random"),
  block_size = 1000,
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_prodBGEN_+3A_bgenfiles">bgenfiles</code></td>
<td>
<p>Character vector of paths to files with extension &quot;.bgen&quot;.
The corresponding &quot;.bgen.bgi&quot; index files must exist.</p>
</td></tr>
<tr><td><code id="snp_prodBGEN_+3A_beta">beta</code></td>
<td>
<p>A matrix (or a vector), with rows corresponding to <code>list_snp_id</code>.</p>
</td></tr>
<tr><td><code id="snp_prodBGEN_+3A_list_snp_id">list_snp_id</code></td>
<td>
<p>List (same length as the number of BGEN files) of
character vector of SNP IDs to read. These should be in the form
<code>"&lt;chr&gt;_&lt;pos&gt;_&lt;a1&gt;_&lt;a2&gt;"</code> (e.g. <code>"1_88169_C_T"</code> or <code>"01_88169_C_T"</code>).
If you have one BGEN file only, just wrap your vector of IDs with <code>list()</code>.
<strong>This function assumes that these IDs are uniquely identifying variants.</strong></p>
</td></tr>
<tr><td><code id="snp_prodBGEN_+3A_ind_row">ind_row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used. <strong>Don't use negative indices.</strong>
You can access the sample IDs corresponding to the genotypes from the <em>.sample</em>
file, and use e.g. <code>match()</code> to get indices corresponding to the ones you want.</p>
</td></tr>
<tr><td><code id="snp_prodBGEN_+3A_bgi_dir">bgi_dir</code></td>
<td>
<p>Directory of index files. Default is the same as <code>bgenfiles</code>.</p>
</td></tr>
<tr><td><code id="snp_prodBGEN_+3A_read_as">read_as</code></td>
<td>
<p>How to read BGEN probabilities? Currently implemented:
</p>

<ul>
<li><p> as dosages (rounded to two decimal places), the default,
</p>
</li>
<li><p> as hard calls, randomly sampled based on those probabilities
(similar to PLINK option '<code style="white-space: pre;">&#8288;--hard-call-threshold random&#8288;</code>').
</p>
</li></ul>
</td></tr>
<tr><td><code id="snp_prodBGEN_+3A_block_size">block_size</code></td>
<td>
<p>Maximum size of temporary blocks (in number of variants).
Default is <code>1000</code>.</p>
</td></tr>
<tr><td><code id="snp_prodBGEN_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <code>nb_cores()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The product <code>bgen_data[ind_row, 'list_snp_id'] %*% beta</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+snp_readBGEN">snp_readBGEN()</a></code>
</p>

<hr>
<h2 id='snp_PRS'>PRS</h2><span id='topic+snp_PRS'></span>

<h3>Description</h3>

<p>Polygenic Risk Scores with possible clumping and thresholding.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_PRS(
  G,
  betas.keep,
  ind.test = rows_along(G),
  ind.keep = cols_along(G),
  same.keep = rep(TRUE, length(ind.keep)),
  lpS.keep = NULL,
  thr.list = 0
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_PRS_+3A_g">G</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
<strong>You shouldn't have missing values.</strong> Also, remember to do quality control,
e.g. some algorithms in this package won't work if you use SNPs with 0 MAF.</p>
</td></tr>
<tr><td><code id="snp_PRS_+3A_betas.keep">betas.keep</code></td>
<td>
<p>Numeric vector of weights associated with each SNP
corresponding to <code>ind.keep</code>.
You may want to see big_univLinReg or big_univLogReg.</p>
</td></tr>
<tr><td><code id="snp_PRS_+3A_ind.test">ind.test</code></td>
<td>
<p>The individuals on whom to project the scores. Default uses all.</p>
</td></tr>
<tr><td><code id="snp_PRS_+3A_ind.keep">ind.keep</code></td>
<td>
<p>Column (SNP) indices to use (if using clumping, the
output of <a href="#topic+snp_clumping">snp_clumping</a>). Default doesn't clump.</p>
</td></tr>
<tr><td><code id="snp_PRS_+3A_same.keep">same.keep</code></td>
<td>
<p>A logical vector associated with <code>betas.keep</code> whether the
reference allele is the same for G. Default is all <code>TRUE</code> (for example when
you train the betas on the same dataset). Otherwise, use <a href="#topic+same_ref">same_ref</a>.</p>
</td></tr>
<tr><td><code id="snp_PRS_+3A_lps.keep">lpS.keep</code></td>
<td>
<p>Numeric vector of <code>-log10(p-value)</code> associated with
<code>betas.keep</code>. Default doesn't use thresholding.</p>
</td></tr>
<tr><td><code id="snp_PRS_+3A_thr.list">thr.list</code></td>
<td>
<p>Threshold vector on <code>lpS.keep</code> at which SNPs are excluded if
they are not significant enough. Default doesn't use thresholding.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of scores, where rows correspond to <code>ind.test</code> and
columns correspond to <code>thr.list</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test &lt;- snp_attachExtdata()
G &lt;- big_copy(test$genotypes, ind.col = 1:1000)
CHR &lt;- test$map$chromosome[1:1000]
POS &lt;- test$map$physical.position[1:1000]
y01 &lt;- test$fam$affection - 1

# PCA -&gt; covariables
obj.svd &lt;- snp_autoSVD(G, infos.chr = CHR, infos.pos = POS)

# train and test set
ind.train &lt;- sort(sample(nrow(G), 400))
ind.test &lt;- setdiff(rows_along(G), ind.train) # 117

# GWAS
gwas.train &lt;- big_univLogReg(G, y01.train = y01[ind.train],
                             ind.train = ind.train,
                             covar.train = obj.svd$u[ind.train, ])
# clumping
ind.keep &lt;- snp_clumping(G, infos.chr = CHR,
                         ind.row = ind.train,
                         S = abs(gwas.train$score))
# -log10(p-values) and thresolding
summary(lpS.keep &lt;- -predict(gwas.train)[ind.keep])
thrs &lt;- seq(0, 4, by = 0.5)
nb.pred &lt;- sapply(thrs, function(thr) sum(lpS.keep &gt; thr))

# PRS
prs &lt;- snp_PRS(G, betas.keep = gwas.train$estim[ind.keep],
               ind.test = ind.test,
               ind.keep = ind.keep,
               lpS.keep = lpS.keep,
               thr.list = thrs)

# AUC as a function of the number of predictors
aucs &lt;- apply(prs, 2, AUC, target = y01[ind.test])
library(ggplot2)
qplot(nb.pred, aucs) +
  geom_line() +
  scale_x_log10(breaks = nb.pred) +
  labs(x = "Number of predictors", y = "AUC") +
  theme_bigstatsr()

</code></pre>

<hr>
<h2 id='snp_qq'>Q-Q plot</h2><span id='topic+snp_qq'></span>

<h3>Description</h3>

<p>Creates a quantile-quantile plot from p-values from a GWAS study.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_qq(gwas, lambdaGC = TRUE, coeff = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_qq_+3A_gwas">gwas</code></td>
<td>
<p>A <code>mhtest</code> object with the p-values associated with each SNP.
Typically, the output of big_univLinReg, big_univLogReg or <a href="#topic+snp_pcadapt">snp_pcadapt</a>.</p>
</td></tr>
<tr><td><code id="snp_qq_+3A_lambdagc">lambdaGC</code></td>
<td>
<p>Add the Genomic Control coefficient as subtitle to the plot?</p>
</td></tr>
<tr><td><code id="snp_qq_+3A_coeff">coeff</code></td>
<td>
<p>Relative size of text. Default is <code>1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot2</code> object. You can plot it using the <code>print</code> method.
You can modify it as you wish by adding layers. You might want to read
<a href="https://r4ds.had.co.nz/data-visualisation.html">this chapter</a>
to get more familiar with the package <strong>ggplot2</strong>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(9)

test &lt;- snp_attachExtdata()
G &lt;- test$genotypes
y &lt;- rnorm(nrow(G))

gwas &lt;- big_univLinReg(G, y)
snp_qq(gwas)
gwas_gc &lt;- snp_gc(gwas) # change attr(gwas_gc, "transfo")

snp_qq(gwas_gc)
# The next plot should be prettier with a real dataset
snp_manhattan(gwas_gc,
              infos.chr = test$map$chromosome,
              infos.pos = test$map$physical.pos)

p &lt;- snp_qq(gwas_gc) + ggplot2::aes(text = asPlotlyText(test$map))
## Not run: plotly::ggplotly(p, tooltip = "text")
</code></pre>

<hr>
<h2 id='snp_readBed'>Read PLINK files into a &quot;bigSNP&quot;</h2><span id='topic+snp_readBed'></span><span id='topic+snp_readBed2'></span>

<h3>Description</h3>

<p>Functions to read bed/bim/fam files into a <a href="#topic+bigSNP-class">bigSNP</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_readBed(bedfile, backingfile = sub_bed(bedfile))

snp_readBed2(
  bedfile,
  backingfile = sub_bed(bedfile),
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_readBed_+3A_bedfile">bedfile</code></td>
<td>
<p>Path to file with extension &quot;.bed&quot; to read.
You need the corresponding &quot;.bim&quot; and &quot;.fam&quot; in the same directory.</p>
</td></tr>
<tr><td><code id="snp_readBed_+3A_backingfile">backingfile</code></td>
<td>
<p>The path (without extension) for the backing files
for the cache of the <a href="#topic+bigSNP-class">bigSNP</a> object. Default takes the bedfile
without the &quot;.bed&quot; extension.</p>
</td></tr>
<tr><td><code id="snp_readBed_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_readBed_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_readBed_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more information on these formats, please visit
<a href="https://www.cog-genomics.org/plink/1.9/formats#bed">PLINK webpage</a>.
For other formats, please use PLINK to convert them in bedfiles,
which require minimal space to store and are faster to read. For example,
to convert from a VCF file, use the <code>--vcf</code> option. See <a href="#topic+snp_plinkQC">snp_plinkQC</a>.
</p>


<h3>Value</h3>

<p>The path to the RDS file that stores the <code>bigSNP</code> object.
Note that this function creates one other file which stores the values of
the Filebacked Big Matrix.<br />
<strong>You shouldn't read from PLINK files more than once.</strong> Instead, use
<a href="#topic+snp_attach">snp_attach</a> to load the &quot;bigSNP&quot; object in any R session from backing files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr"))

# Reading the bedfile and storing the data in temporary directory
rds &lt;- snp_readBed(bedfile, backingfile = tempfile())

# Loading the data from backing files
test &lt;- snp_attach(rds)

str(test)
dim(G &lt;- test$genotypes)
G[1:8, 1:8]
</code></pre>

<hr>
<h2 id='snp_readBGEN'>Read BGEN files into a &quot;bigSNP&quot;</h2><span id='topic+snp_readBGEN'></span>

<h3>Description</h3>

<p>Function to read the UK Biobank BGEN files into a <a href="#topic+bigSNP-class">bigSNP</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_readBGEN(
  bgenfiles,
  backingfile,
  list_snp_id,
  ind_row = NULL,
  bgi_dir = dirname(bgenfiles),
  read_as = c("dosage", "random"),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_readBGEN_+3A_bgenfiles">bgenfiles</code></td>
<td>
<p>Character vector of paths to files with extension &quot;.bgen&quot;.
The corresponding &quot;.bgen.bgi&quot; index files must exist.</p>
</td></tr>
<tr><td><code id="snp_readBGEN_+3A_backingfile">backingfile</code></td>
<td>
<p>The path (without extension) for the backing files (&quot;.bk&quot;
and &quot;.rds&quot;) that are created by this function for storing the
<a href="#topic+bigSNP-class">bigSNP</a> object.</p>
</td></tr>
<tr><td><code id="snp_readBGEN_+3A_list_snp_id">list_snp_id</code></td>
<td>
<p>List (same length as the number of BGEN files) of
character vector of SNP IDs to read. These should be in the form
<code>"&lt;chr&gt;_&lt;pos&gt;_&lt;a1&gt;_&lt;a2&gt;"</code> (e.g. <code>"1_88169_C_T"</code> or <code>"01_88169_C_T"</code>).
If you have one BGEN file only, just wrap your vector of IDs with <code>list()</code>.
<strong>This function assumes that these IDs are uniquely identifying variants.</strong></p>
</td></tr>
<tr><td><code id="snp_readBGEN_+3A_ind_row">ind_row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used. <strong>Don't use negative indices.</strong>
You can access the sample IDs corresponding to the genotypes from the <em>.sample</em>
file, and use e.g. <code>match()</code> to get indices corresponding to the ones you want.</p>
</td></tr>
<tr><td><code id="snp_readBGEN_+3A_bgi_dir">bgi_dir</code></td>
<td>
<p>Directory of index files. Default is the same as <code>bgenfiles</code>.</p>
</td></tr>
<tr><td><code id="snp_readBGEN_+3A_read_as">read_as</code></td>
<td>
<p>How to read BGEN probabilities? Currently implemented:
</p>

<ul>
<li><p> as dosages (rounded to two decimal places), the default,
</p>
</li>
<li><p> as hard calls, randomly sampled based on those probabilities
(similar to PLINK option '<code style="white-space: pre;">&#8288;--hard-call-threshold random&#8288;</code>').
</p>
</li></ul>
</td></tr>
<tr><td><code id="snp_readBGEN_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use <code>nb_cores()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more information on this format, please visit
<a href="https://bitbucket.org/gavinband/bgen/">BGEN webpage</a>.
</p>
<p>This function is designed to read UK Biobank imputation files. This assumes
that variants have been compressed with zlib, that there are only 2 possible
alleles, and that each probability is stored on 8 bits. For example, if you
use <em>qctool</em> to generate your own BGEN files, please make sure you are using
options '<code style="white-space: pre;">&#8288;-ofiletype bgen_v1.2 -bgen-bits 8&#8288;</code>'.
</p>
<p>If the format is not the expected one, this will result in an error or even
a crash of your R session. Another common source of error is due to corrupted
files; e.g. if using UK Biobank files, compare the result of <code><a href="tools.html#topic+md5sum">tools::md5sum()</a></code>
with the ones at <a href="https://biobank.ndph.ox.ac.uk/ukb/refer.cgi?id=998">https://biobank.ndph.ox.ac.uk/ukb/refer.cgi?id=998</a>.
</p>
<p>You can look at some example code from my papers on how to use this function:
</p>

<ul>
<li> <p><a href="https://github.com/privefl/paper-misspec/blob/main/code/prepare-genotypes.R">https://github.com/privefl/paper-misspec/blob/main/code/prepare-genotypes.R</a>
</p>
</li>
<li> <p><a href="https://github.com/privefl/paper-ldpred2/blob/master/code/prepare-genotypes.R#L1-L62">https://github.com/privefl/paper-ldpred2/blob/master/code/prepare-genotypes.R#L1-L62</a>
</p>
</li>
<li> <p><a href="https://github.com/privefl/paper4-bedpca/blob/master/code/missing-values-UKBB.R#L34-L75">https://github.com/privefl/paper4-bedpca/blob/master/code/missing-values-UKBB.R#L34-L75</a>
</p>
</li></ul>



<h3>Value</h3>

<p>The path to the RDS file <code style="white-space: pre;">&#8288;&lt;backingfile&gt;.rds&#8288;</code> that stores the <code>bigSNP</code>
object created by this function. Note that this function creates another
file (<em>.bk</em>) which stores the values of the FBM (<code style="white-space: pre;">&#8288;$genotypes&#8288;</code>). The <code style="white-space: pre;">&#8288;$map&#8288;</code>
component of the <code>bigSNP</code> object stores some information on the variants
(including allele frequencies and INFO scores computed from the probabilities).
However, it does not have a <code style="white-space: pre;">&#8288;$fam&#8288;</code> component; you should use the individual
IDs in the <em>.sample</em> file (filtered with <code>ind_row</code>) to add external information
on the individuals.<br />
<strong>You shouldn't read from BGEN files more than once.</strong> Instead, use
<a href="#topic+snp_attach">snp_attach</a> to load the &quot;bigSNP&quot; object in any R session from backing files.
</p>

<hr>
<h2 id='snp_readBGI'>Read variant info from one BGI file</h2><span id='topic+snp_readBGI'></span>

<h3>Description</h3>

<p>Read variant info from one BGI file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_readBGI(bgifile, snp_id = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_readBGI_+3A_bgifile">bgifile</code></td>
<td>
<p>Path to one file with extension &quot;.bgi&quot;.</p>
</td></tr>
<tr><td><code id="snp_readBGI_+3A_snp_id">snp_id</code></td>
<td>
<p>Character vector of SNP IDs. These should be in the form
<code>"&lt;chr&gt;_&lt;pos&gt;_&lt;a1&gt;_&lt;a2&gt;"</code> (e.g. <code>"1_88169_C_T"</code> or <code>"01_88169_C_T"</code>).
<strong>This function assumes that these IDs are uniquely identifying variants.</strong>
Default is <code>NULL</code>, and returns information on all variants.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing variant information.
</p>

<hr>
<h2 id='snp_save'>Save modifications</h2><span id='topic+snp_save'></span>

<h3>Description</h3>

<p>Save a <code>bigSNP</code> after having made some modifications to it.
As <code>bigSNP</code> is an S3 class, you can add any slot you want
to an object of this class, then use <code>snp_save</code> to
save these modifications in the corresponding &quot;.rds&quot; backing file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_save(x, version = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_save_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bigSNP-class">bigSNP</a>.</p>
</td></tr>
<tr><td><code id="snp_save_+3A_version">version</code></td>
<td>
<p>the workspace format version to use.  <code>NULL</code>
specifies the current default version (3). The only other supported
value is 2, the default from <span class="rlang"><b>R</b></span> 1.4.0 to <span class="rlang"><b>R</b></span> 3.5.0.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The (saved) <code>bigSNP</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

# Reading example
test &lt;- snp_attachExtdata()

# I can add whatever I want to an S3 class
test$map$`p-values` &lt;- runif(nrow(test$map))
str(test$map)

# Reading again
rds &lt;- test$genotypes$rds
test2 &lt;- snp_attach(rds)
str(test2$map) # new slot wasn't saved

# Save it
snp_save(test)

# Reading again
test3 &lt;- snp_attach(rds)
str(test3$map) # it is saved now

# The complicated code of this function
snp_save
</code></pre>

<hr>
<h2 id='snp_scaleAlpha'>Binomial(n, p) scaling</h2><span id='topic+snp_scaleAlpha'></span><span id='topic+snp_scaleBinom'></span>

<h3>Description</h3>

<p>Binomial(n, p) scaling where <code>n</code> is fixed and <code>p</code> is estimated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_scaleAlpha(alpha = -1)

snp_scaleBinom(nploidy = 2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_scaleAlpha_+3A_alpha">alpha</code></td>
<td>
<p>Assumes that the average contribution (e.g. heritability)
of a SNP of frequency <code class="reqn">p</code> is proportional to
<code class="reqn">[2p(1-p)]^{1+\alpha}</code>. The <code>center</code> is then <code class="reqn">2 p</code> and the <code>scale</code>
is <code class="reqn">[2p(1-p)]^{-\alpha/2}</code>. Default is <code>-1</code>.</p>
</td></tr>
<tr><td><code id="snp_scaleAlpha_+3A_nploidy">nploidy</code></td>
<td>
<p>Number of trials, parameter of the binomial distribution.
Default is <code>2</code>, which corresponds to diploidy, such as for the human genome.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You will probably not use this function as is but as the
<code>fun.scaling</code> parameter of other functions of package <code>bigstatsr</code>.
</p>


<h3>Value</h3>

<p>A new <strong>function</strong> that returns a data.frame of two vectors
&quot;center&quot; and &quot;scale&quot; which are of the length of <code>ind.col</code>.
</p>


<h3>References</h3>

<p>This scaling is widely used for SNP arrays.
Patterson N, Price AL, Reich D (2006). Population Structure and Eigenanalysis.
PLoS Genet 2(12): e190. <a href="https://doi.org/10.1371/journal.pgen.0020190">doi:10.1371/journal.pgen.0020190</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

a &lt;- matrix(0, 93, 170)
p &lt;- 0.2
a[] &lt;- rbinom(length(a), 2, p)
X &lt;- add_code256(big_copy(a, type = "raw"), code = c(0, 1, 2, rep(NA, 253)))
X.svd &lt;- big_SVD(X, fun.scaling = snp_scaleBinom())
str(X.svd)
plot(X.svd$center)
abline(h = 2 * p, col = "red")
plot(X.svd$scale)
abline(h = sqrt(2 * p * (1 - p)), col = "red")
</code></pre>

<hr>
<h2 id='snp_simuPheno'>Simulate phenotypes</h2><span id='topic+snp_simuPheno'></span>

<h3>Description</h3>

<p>Simulate phenotypes using a linear model. When a prevalence is given, the
liability threshold is used to convert liabilities to a binary outcome.
The genetic and environmental liabilities are scaled such that the variance
of the genetic liability is exactly equal to the requested heritability, and
the variance of the total liability is equal to 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_simuPheno(
  G,
  h2,
  M,
  K = NULL,
  alpha = -1,
  ind.row = rows_along(G),
  ind.possible = cols_along(G),
  prob = NULL,
  effects.dist = c("gaussian", "laplace"),
  ncores = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_simuPheno_+3A_g">G</code></td>
<td>
<p>A FBM.code256
(typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$genotypes&#8288;</code>).<br />
<strong>You shouldn't have missing values.</strong> Also, remember to do quality control,
e.g. some algorithms in this package won't work if you use SNPs with 0 MAF.</p>
</td></tr>
<tr><td><code id="snp_simuPheno_+3A_h2">h2</code></td>
<td>
<p>Heritability.</p>
</td></tr>
<tr><td><code id="snp_simuPheno_+3A_m">M</code></td>
<td>
<p>Number of causal variants.</p>
</td></tr>
<tr><td><code id="snp_simuPheno_+3A_k">K</code></td>
<td>
<p>Prevalence. Default is <code>NULL</code>, giving a continuous trait.</p>
</td></tr>
<tr><td><code id="snp_simuPheno_+3A_alpha">alpha</code></td>
<td>
<p>Assumes that the average contribution (e.g. heritability)
of a SNP of frequency <code class="reqn">p</code> is proportional to
<code class="reqn">[2p(1-p)]^{1+\alpha}</code>. Default is <code>-1</code>.</p>
</td></tr>
<tr><td><code id="snp_simuPheno_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_simuPheno_+3A_ind.possible">ind.possible</code></td>
<td>
<p>Indices of possible causal variants.</p>
</td></tr>
<tr><td><code id="snp_simuPheno_+3A_prob">prob</code></td>
<td>
<p>Vector of probability weights for sampling causal indices.
It can have 0s (discarded) and is automatically scaled to sum to 1.
Default is <code>NULL</code> (all indices have the same probability).</p>
</td></tr>
<tr><td><code id="snp_simuPheno_+3A_effects.dist">effects.dist</code></td>
<td>
<p>Distribution of effects.
Either <code>"gaussian"</code> (the default) or <code>"laplace"</code>.</p>
</td></tr>
<tr><td><code id="snp_simuPheno_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with 3 elements:
</p>

<ul>
<li> <p><code style="white-space: pre;">&#8288;$pheno&#8288;</code>: vector of phenotypes,
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$set&#8288;</code>: indices of causal variants,
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$effects&#8288;</code>: effect sizes (of scaled genotypes) corresponding to <code>set</code>.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;$allelic_effects&#8288;</code>: effect sizes, but on the allele scale (0|1|2).
</p>
</li></ul>


<hr>
<h2 id='snp_split'>Split-parApply-Combine</h2><span id='topic+snp_split'></span>

<h3>Description</h3>

<p>A Split-Apply-Combine strategy to parallelize the evaluation of a function
on each SNP, independently.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_split(infos.chr, FUN, combine, ncores = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_split_+3A_infos.chr">infos.chr</code></td>
<td>
<p>Vector of integers specifying each SNP's chromosome.<br />
Typically <code style="white-space: pre;">&#8288;&lt;bigSNP&gt;$map$chromosome&#8288;</code>.</p>
</td></tr>
<tr><td><code id="snp_split_+3A_fun">FUN</code></td>
<td>
<p>The function to be applied. It must take a
FBM.code256 as first argument and <code>ind.chr</code>,
an another argument to provide subsetting over SNPs.
You can access the number of the chromosome by using <code>attr(ind.chr, "chr")</code>.</p>
</td></tr>
<tr><td><code id="snp_split_+3A_combine">combine</code></td>
<td>
<p>function that is used by <a href="foreach.html#topic+foreach">foreach</a> to process the tasks
results as they generated. This can be specified as either a function or a
non-empty character string naming the function. Specifying 'c' is useful
for concatenating the results into a vector, for example. The values 'cbind'
and 'rbind' can combine vectors into a matrix. The values '+' and '*' can be
used to process numeric data. By default, the results are returned in a list.</p>
</td></tr>
<tr><td><code id="snp_split_+3A_ncores">ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td></tr>
<tr><td><code id="snp_split_+3A_...">...</code></td>
<td>
<p>Extra arguments to be passed to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function splits indices for each chromosome, then apply a given function
to each part (chromosome) and finally combine the results.
</p>


<h3>Value</h3>

<p>The result of <a href="foreach.html#topic+foreach">foreach</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># parallelize over chromosomes made easy
# examples of functions from this package
snp_pruning
snp_clumping
snp_fastImpute

</code></pre>

<hr>
<h2 id='snp_subset'>Subset a bigSNP</h2><span id='topic+snp_subset'></span><span id='topic+subset.bigSNP'></span>

<h3>Description</h3>

<p>Subset (copy) of a <code>bigSNP</code>, also stored on disk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_subset(
  x,
  ind.row = rows_along(x$fam),
  ind.col = rows_along(x$map),
  backingfile = NULL
)

## S3 method for class 'bigSNP'
subset(
  x,
  ind.row = rows_along(x$fam),
  ind.col = rows_along(x$map),
  backingfile = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_subset_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bigSNP-class">bigSNP</a>.</p>
</td></tr>
<tr><td><code id="snp_subset_+3A_ind.row">ind.row</code></td>
<td>
<p>Indices of the rows (individuals) to keep.
Negative indices <strong>can</strong> be used to exclude row indices.
Default: keep them all.</p>
</td></tr>
<tr><td><code id="snp_subset_+3A_ind.col">ind.col</code></td>
<td>
<p>Indices of the columns (SNPs) to keep.
Negative indices <strong>can</strong> be used to exclude column indices.
Default: keep them all.</p>
</td></tr>
<tr><td><code id="snp_subset_+3A_backingfile">backingfile</code></td>
<td>
<p>Prefix of the two new files created (&quot;.bk&quot; and &quot;.rds&quot;).
By default, it is automatically determined by appending &quot;_sub&quot; and a number
to the prefix of the input bigSNP backing files.</p>
</td></tr>
<tr><td><code id="snp_subset_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The path to the RDS file that stores the <code>bigSNP</code> object.
</p>


<h3>See Also</h3>

<p><a href="#topic+bigSNP-class">bigSNP</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(test &lt;- snp_attachExtdata())

# keep only first 50 samples and SNPs
rdsfile &lt;- snp_subset(test, ind.row = 1:50, ind.col = 1:50)
str(snp_attach(rdsfile))

# remove only first 50 samples and SNPs
rdsfile2 &lt;- snp_subset(test, ind.row = -(1:50), ind.col = -(1:50))
str(snp_attach(rdsfile2))

</code></pre>

<hr>
<h2 id='snp_thr_correct'>Thresholding and correction</h2><span id='topic+snp_thr_correct'></span>

<h3>Description</h3>

<p>P-value thresholding and correction of summary statistics for winner's curse.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_thr_correct(beta, beta_se, lpS, thr_lpS)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_thr_correct_+3A_beta">beta</code></td>
<td>
<p>Vector of effect sizes.</p>
</td></tr>
<tr><td><code id="snp_thr_correct_+3A_beta_se">beta_se</code></td>
<td>
<p>Vector of standard errors for <code>beta</code>.
Either <code>beta_se</code> or <code>lpS</code> must be provided.</p>
</td></tr>
<tr><td><code id="snp_thr_correct_+3A_lps">lpS</code></td>
<td>
<p>Vector of -log10(p-value) associated with <code>beta</code>.
Either <code>beta_se</code> or <code>lpS</code> must be provided.</p>
</td></tr>
<tr><td><code id="snp_thr_correct_+3A_thr_lps">thr_lpS</code></td>
<td>
<p>Threshold on <code>lpS</code> (-log10(p-value) at which variants are
excluded if they  not significant enough.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>beta</code> after p-value thresholding and shrinkage.
</p>


<h3>References</h3>

<p>Zhong, H., &amp; Prentice, R. L. (2008). Bias-reduced estimators and confidence
intervals for odds ratios in genome-wide association studies.
Biostatistics, 9(4), 621-634.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>beta &lt;- rnorm(1000)
beta_se &lt;- runif(1000, min = 0.3, max = 0.5)
new_beta &lt;- snp_thr_correct(beta, beta_se = beta_se, thr_lpS = 1)
plot(beta / beta_se, new_beta / beta_se, pch = 20); abline(0, 1, col = "red")
plot(beta, new_beta, pch = 20); abline(0, 1, col = "red")

# Can provide -log10(p-values) instead of standard errors
lpval &lt;- -log10(pchisq((beta / beta_se)^2, df = 1, lower.tail = FALSE))
new_beta2 &lt;- snp_thr_correct(beta, lpS = lpval, thr_lpS = 1)
all.equal(new_beta2, new_beta)

</code></pre>

<hr>
<h2 id='snp_writeBed'>Write PLINK files from a &quot;bigSNP&quot;</h2><span id='topic+snp_writeBed'></span>

<h3>Description</h3>

<p>Function to write bed/bim/fam files from a <a href="#topic+bigSNP-class">bigSNP</a>.
This will use the slot <code>code</code> <strong>rounded</strong> to write 0s, 1s, 2s or NAs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>snp_writeBed(x, bedfile, ind.row = rows_along(G), ind.col = cols_along(G))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="snp_writeBed_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bigSNP-class">bigSNP</a>.</p>
</td></tr>
<tr><td><code id="snp_writeBed_+3A_bedfile">bedfile</code></td>
<td>
<p>Path to file with extension &quot;.bed&quot; to create.</p>
</td></tr>
<tr><td><code id="snp_writeBed_+3A_ind.row">ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
<tr><td><code id="snp_writeBed_+3A_ind.col">ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br />
<strong>Don't use negative indices.</strong></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input <code>bedfile</code> path.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 17
M &lt;- 911

fake &lt;- snp_fake(N, M)
G &lt;- fake$genotypes
G[] &lt;- sample(as.raw(0:3), size = length(G), replace = TRUE)

# Write the object as a bed/bim/fam object
tmp &lt;- tempfile(fileext = ".bed")
bed &lt;- snp_writeBed(fake, tmp)

# Read this new file for the first time
rds &lt;- snp_readBed(bed, backingfile = tempfile())
# Attach object in R session
fake2 &lt;- snp_attach(rds)

# Same content
all.equal(fake$genotypes[], fake2$genotypes[])
all.equal(fake$fam, fake2$fam)
all.equal(fake$map, fake2$map)

# Two different backingfiles
fake$genotypes$backingfile
fake2$genotypes$backingfile
</code></pre>

<hr>
<h2 id='sub_bed'>Replace extension '.bed'</h2><span id='topic+sub_bed'></span>

<h3>Description</h3>

<p>Replace extension '.bed'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sub_bed(path, replacement = "", stop_if_not_ext = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sub_bed_+3A_path">path</code></td>
<td>
<p>String with extension '.bed'.</p>
</td></tr>
<tr><td><code id="sub_bed_+3A_replacement">replacement</code></td>
<td>
<p>Replacement of '.bed'. Default replaces by nothing.
Can be useful to replace e.g. by '.bim' or '.fam'.</p>
</td></tr>
<tr><td><code id="sub_bed_+3A_stop_if_not_ext">stop_if_not_ext</code></td>
<td>
<p>If <code>replacement != ""</code>, whether to error if
replacement is not an extension (starting with a '.').</p>
</td></tr>
</table>


<h3>Value</h3>

<p>String with extension '.bed' replaced by <code>replacement</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>path &lt;- "toto.bed"
sub_bed(path)
sub_bed(path, ".bim")
sub_bed(path, ".fam")
sub_bed(path, "_QC", stop_if_not_ext = FALSE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
