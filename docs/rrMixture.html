<!DOCTYPE html><html><head><title>Help for package rrMixture</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rrMixture}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#initialize.para'><p>Initialization of Parameter Estimates</p></a></li>
<li><a href='#plot'><p>Visualize rrmix Objects</p></a></li>
<li><a href='#rrmix'><p>Reduced-Rank Mixture Models in Multivariate Regression</p></a></li>
<li><a href='#rrmix.sim.norm'><p>Simulation Data Generator</p></a></li>
<li><a href='#rrMixture'><p>rrMixture: Reduced-Rank Mixture Models.</p></a></li>
<li><a href='#summary'><p>Summarize rrmix Objects</p></a></li>
<li><a href='#tune.rrmix'><p>Reduced-rank mixture models with optimal tuning parameter(s)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Reduced-Rank Mixture Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1-2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-04-06</td>
</tr>
<tr>
<td>Description:</td>
<td>We implement full-ranked, rank-penalized, and adaptive nuclear norm penalized estimation methods using multivariate mixture models proposed by Kang, Chen, and Yao (2022+).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, Rcpp (&ge; 1.0.8), Matrix, matrixcalc, gtools, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>bayesm, rrpack, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-04-08 02:56:06 UTC; Suyeon Kang</td>
</tr>
<tr>
<td>Author:</td>
<td>Suyeon Kang [aut, cre],
  Weixin Yao [aut],
  Kun Chen [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Suyeon Kang &lt;skang062@ucr.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-04-08 03:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='initialize.para'>Initialization of Parameter Estimates</h2><span id='topic+initialize.para'></span>

<h3>Description</h3>

<p>&lsquo;initialize.para&rsquo; is used to initialize parameter estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>initialize.para(K, X, Y, ind0 = NULL,
                seed = NULL, km.nstart = 20, kmscale = FALSE, n.init = 100,
                commonvar = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="initialize.para_+3A_k">K</code></td>
<td>
<p>number of mixture components.</p>
</td></tr>
<tr><td><code id="initialize.para_+3A_x">X</code></td>
<td>
<p>n by p design matrix where n is the number of observations and
p is the number of predictors.</p>
</td></tr>
<tr><td><code id="initialize.para_+3A_y">Y</code></td>
<td>
<p>n by q response matrix where n is the number of observations and
q is the number of responses.</p>
</td></tr>
<tr><td><code id="initialize.para_+3A_ind0">ind0</code></td>
<td>
<p>vector of length n, specifying the initial assignment of the
mixture membership of n observations when there is prior information on
the membership. If &lsquo;NULL&rsquo;, K-means clustering technique is used to assign
the membership for n observations. Default is &lsquo;NULL&rsquo;.</p>
</td></tr>
<tr><td><code id="initialize.para_+3A_seed">seed</code></td>
<td>
<p>seed number for the reproducibility of results. Default is &lsquo;NULL&rsquo;.</p>
</td></tr>
<tr><td><code id="initialize.para_+3A_km.nstart">km.nstart</code></td>
<td>
<p>number of random sets considered to perform K-means
clustering. Only used for K-means clustering. Default is 20.</p>
</td></tr>
<tr><td><code id="initialize.para_+3A_kmscale">kmscale</code></td>
<td>
<p>logical value, indicating whether Y is scaled prior to K-means
clustering. Only used for K-means clustering. Default is &lsquo;FALSE&rsquo;.</p>
</td></tr>
<tr><td><code id="initialize.para_+3A_n.init">n.init</code></td>
<td>
<p>number of initializations to try. Two methods for initial
clustering are used: K-means and random clustering.</p>
</td></tr>
<tr><td><code id="initialize.para_+3A_commonvar">commonvar</code></td>
<td>
<p>logical value, indicating the homogeneity assumption of
variance-covariance matrices across K mixture components. Default is &lsquo;FALSE&rsquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>para</code></td>
<td>
<p>array of length K. It consists of K lists, each of which contains
initial estimates of membership probability, coefficient matrix, and variance-
covariance matrix.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Suyeon Kang, University of California, Riverside, <a href="mailto:skang062@ucr.edu">skang062@ucr.edu</a>;
Weixin Yao, University of California, Riverside, <a href="mailto:weixin.yao@ucr.edu">weixin.yao@ucr.edu</a>;
Kun Chen, University of Connecticut, <a href="mailto:kun.chen@uconn.edu">kun.chen@uconn.edu</a>.
</p>


<h3>References</h3>

<p>Kang, S., Chen, K., and Yao, W. (2022+). &quot;Reduced rank estimation in mixtures
of multivariate linear regression&quot;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rrmix.sim.norm">rrmix.sim.norm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-----------------------------------------------------------#
# Simulation 1: Two Components Case
#-----------------------------------------------------------#
K2mod &lt;- rrmix.sim.norm(K = 2, n = 100, p = 5, q = 5, rho = .5,
         b = 1, shift = 1, r.star = c(1, 3), sigma = c(1, 1),
         pr = c(.5, .5), seed = 1215)
K2ini &lt;- initialize.para(K = 2, X = K2mod$X, Y = K2mod$Y,
         seed = 100)

#-----------------------------------------------------------#
# Simulation 2: Four Components Case
#-----------------------------------------------------------#

K4mod &lt;- rrmix.sim.norm(K = 4, n = 600, p = 15, q = 15,
         rho = .5, b = 1, shift = 1, r.star = c(1, 1, 3, 3),
         sigma = c(1, 1, 1, 1), pr = c(.25, .25, .25, .25),
         seed = 1215)
K4ini &lt;- initialize.para(K = 4, X = K4mod$X, Y = K4mod$Y,
         seed = 100)
</code></pre>

<hr>
<h2 id='plot'>Visualize rrmix Objects</h2><span id='topic+plot'></span><span id='topic+plot.rrmix'></span><span id='topic+plot.tune.rrmix'></span>

<h3>Description</h3>

<p>S3 methods visualizing results for some objects generated by <code>rrmix</code> and <code>tune.rrmix</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rrmix'
plot(
  x,
  pch.L = 1,
  pch.F = 2,
  col.L = "red",
  col.F = "blue",
  lty.L = 1,
  lty.F = 1,
  type = "b",
  ...
)

## S3 method for class 'tune.rrmix'
plot(
  x,
  metric = c("bic", "soft.class.err", "hard.class.err", "est.err", "pred.err"),
  col = "blue",
  main = NULL,
  xlab = NULL,
  ylab = NULL,
  swapxy = FALSE,
  transform.x = NULL,
  transform.y = NULL,
  transform.z = NULL,
  color.palette = hsv_palette(),
  nlevels = 20,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_+3A_x">x</code></td>
<td>
<p>an object of class <code>rrmix</code> or <code>tune.rrmix</code>.</p>
</td></tr>
<tr><td><code id="plot_+3A_pch.l">pch.L</code></td>
<td>
<p>symbol to use for displaying log-likelihood.</p>
</td></tr>
<tr><td><code id="plot_+3A_pch.f">pch.F</code></td>
<td>
<p>symbol to use for displaying penalized log-likelihood.</p>
</td></tr>
<tr><td><code id="plot_+3A_col.l">col.L</code></td>
<td>
<p>color code or name for displaying log-likelihood.</p>
</td></tr>
<tr><td><code id="plot_+3A_col.f">col.F</code></td>
<td>
<p>color code or name displaying penalized log-likelihood.</p>
</td></tr>
<tr><td><code id="plot_+3A_lty.l">lty.L</code></td>
<td>
<p>line type for displaying log-likelihood.</p>
</td></tr>
<tr><td><code id="plot_+3A_lty.f">lty.F</code></td>
<td>
<p>line type for displaying penalized log-likelihood.</p>
</td></tr>
<tr><td><code id="plot_+3A_type">type</code></td>
<td>
<p>character indicating the type of plotting.</p>
</td></tr>
<tr><td><code id="plot_+3A_...">...</code></td>
<td>
<p>Other arguments for future usage.</p>
</td></tr>
<tr><td><code id="plot_+3A_metric">metric</code></td>
<td>
<p>performance metric to use for finding best &lsquo;rrmix&rsquo; model.
&lsquo;soft.class.err&rsquo;, &lsquo;hard.class.err&rsquo;, &lsquo;est.err&rsquo;, and &lsquo;pred.err&rsquo; can only be
used when true parameter values are known.</p>
</td></tr>
<tr><td><code id="plot_+3A_col">col</code></td>
<td>
<p>the color(s) of the surface facets. Transparent colors are ignored.</p>
</td></tr>
<tr><td><code id="plot_+3A_main">main</code></td>
<td>
<p>main title.</p>
</td></tr>
<tr><td><code id="plot_+3A_xlab">xlab</code></td>
<td>
<p>title for the x-axis.</p>
</td></tr>
<tr><td><code id="plot_+3A_ylab">ylab</code></td>
<td>
<p>title for the y-axis.</p>
</td></tr>
<tr><td><code id="plot_+3A_swapxy">swapxy</code></td>
<td>
<p>if TRUE, the parameter axes are swaped (only used in case of
two parameters).</p>
</td></tr>
<tr><td><code id="plot_+3A_transform.x">transform.x</code>, <code id="plot_+3A_transform.y">transform.y</code>, <code id="plot_+3A_transform.z">transform.z</code></td>
<td>
<p>functions to transform the parameters
(x and y) and the error measures (z). Ignored if NULL.</p>
</td></tr>
<tr><td><code id="plot_+3A_color.palette">color.palette</code></td>
<td>
<p>color palette used in contour plot.</p>
</td></tr>
<tr><td><code id="plot_+3A_nlevels">nlevels</code></td>
<td>
<p>number of levels used in contour plot.</p>
</td></tr>
</table>

<hr>
<h2 id='rrmix'>Reduced-Rank Mixture Models in Multivariate Regression</h2><span id='topic+rrmix'></span>

<h3>Description</h3>

<p>&lsquo;rrmix&rsquo; is used to estimate parameters of reduced-rank mixture models in
multivariate linear regression using the full-ranked, rank-penalized, and
adaptive nuclear norm penalized estimators proposed by Kang et. al. (2022+).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrmix(K = 2, X, Y, est = c("FR", "RP", "ANNP"),
      lambda = 0, gamma = 2, ind0 = NULL, para0 = NULL, seed = NULL,
      kmscale = FALSE, km.nstart = 20, n.init = 100, commonvar = FALSE,
      maxiter = 1000, maxiter.int = 100, thres = 1e-05, thres.int = 1e-05,
      visible = FALSE, para.true = NULL, ind.true = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrmix_+3A_k">K</code></td>
<td>
<p>number of mixture components.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_x">X</code></td>
<td>
<p>n by p design matrix where n is the number of observations and
p is the number of predictors.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_y">Y</code></td>
<td>
<p>n by q response matrix where n is the number of observations and
q is the number of responses.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_est">est</code></td>
<td>
<p>character, specifying the estimation method. &lsquo;FR&rsquo;, &lsquo;RP&rsquo;, and &lsquo;ANNP&rsquo;
refers to as the full-ranked, rank-penalized, and adaptive nuclear norm
penalized method, respectively.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_lambda">lambda</code></td>
<td>
<p>numerical value, specifying tuning parameter. Only used in the
estimation method of &lsquo;RP&rsquo; and &lsquo;ANNP&rsquo;. If 0, all estimation methods (&lsquo;FR&rsquo;,
&lsquo;RP&rsquo;, and &lsquo;ANNP&rsquo;) provide the same estimation results.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_gamma">gamma</code></td>
<td>
<p>numerical value, specifying additional tuning parameter, only
used in the estimation method of &lsquo;ANNP&rsquo;. It must be nonnegative.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_ind0">ind0</code></td>
<td>
<p>vector of length n, specifying the initial assignment of the
mixture membership of n observations when there is prior information on
the membership. If &lsquo;NULL&rsquo;, K-means clustering technique is used to assign
the membership for n observations. Default is &lsquo;NULL&rsquo;.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_para0">para0</code></td>
<td>
<p>array of length K. It consists of K lists, each of which contains
initial values of membership probability, coefficient matrix, and variance-
covariance matrix.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_seed">seed</code></td>
<td>
<p>seed number for the reproducibility of initialization results in
the EM algorithm. Default is &lsquo;NULL&rsquo;.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_kmscale">kmscale</code></td>
<td>
<p>logical value, indicating whether Y is scaled prior to K-means
clustering for initialization. Default is &lsquo;FALSE&rsquo;.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_km.nstart">km.nstart</code></td>
<td>
<p>number of random sets considered to perform K-means
clustering for initialization. Default is 20.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_n.init">n.init</code></td>
<td>
<p>number of initializations to try. Two methods for initial
clustering are used: K-means and random clustering.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_commonvar">commonvar</code></td>
<td>
<p>logical value, indicating the homogeneity assumption of
variance-covariance matrices across K mixture components. Default is &lsquo;FALSE&rsquo;.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations for external iterative
algorithm, used in all estimation methods.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_maxiter.int">maxiter.int</code></td>
<td>
<p>maximum number of iterations for internal iterative
algorithm, only used in the estimation method of &lsquo;ANNP&rsquo;.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_thres">thres</code></td>
<td>
<p>threshold value for external EM algorithm, used in all
estimation methods. It controls the termination of the EM algorithm.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_thres.int">thres.int</code></td>
<td>
<p>threshold value for internal iterative algorithm, only used
in the estimation method of &lsquo;ANNP&rsquo;. It controls the termination of the
internal algorithm.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_visible">visible</code></td>
<td>
<p>logical value, indicating whether the outputs from each iteration
are printed. Useful when the whole algorithm takes long. Default is &lsquo;FALSE&rsquo;.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_para.true">para.true</code></td>
<td>
<p>array of length K. It consists of K lists, each of which
contains a coefficient matrix and its true rank. Only used when true models
are known, e.g., in a simulation study.</p>
</td></tr>
<tr><td><code id="rrmix_+3A_ind.true">ind.true</code></td>
<td>
<p>vector of length n, specifying the true mixture membership
for n observations. Only used when true models are known, e.g., in a
simulation study.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>rrmix</code> containing the fitted model, including: 
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>original function call.</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p>seed number which is set for the initilization.</p>
</td></tr>
<tr><td><code>n.est</code></td>
<td>
<p>vector of length K, specifying the estimated number of
observations in each mixture components.</p>
</td></tr>
<tr><td><code>para</code></td>
<td>
<p>array of length K. It consists of K lists, each of which contains
final estimates of membership probability, coefficient matrix, and variance-
covariance matrix.</p>
</td></tr>
<tr><td><code>est.rank</code></td>
<td>
<p>vector of length K, specifying the estimated ranks of
coefficient matrices.</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>number of parameters in the model, used to estimate the BIC.</p>
</td></tr>
<tr><td><code>n.iter</code></td>
<td>
<p>number of iterations (external EM algorithm).</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>tuning parameter for the estimation method of 'RP' or 'ANNP'.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>tuning parameter for the estimation method of 'ANNP'.</p>
</td></tr>
<tr><td><code>ind</code></td>
<td>
<p>vector of length n, specifying the estimated mixture membership
for n observations.</p>
</td></tr>
<tr><td><code>ind.true</code></td>
<td>
<p>vector of length n, specifying the true mixture membership
for n observations. Only returned when the true models are known.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>log-likelihood of the final model.</p>
</td></tr>
<tr><td><code>penloglik</code></td>
<td>
<p>penalized log-likelihood of the final model.</p>
</td></tr>
<tr><td><code>penalty</code></td>
<td>
<p>penalty in the penalized log-likelihood of the final model.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>BIC of the final model.</p>
</td></tr>
<tr><td><code>avg.nn.iter</code></td>
<td>
<p>average number of iterations for internal iterative
algorithm, only returned for the estimation method of 'ANNP'.</p>
</td></tr>
<tr><td><code>resmat</code></td>
<td>
<p>matrix containing the information for each iteration of the
EM algorithm, e.g., iteration number, log-likelihood, penalized log-
likelihood, difference between penalized log-likelihood values from two
consecutive iterations, and computing time.</p>
</td></tr>   
<tr><td><code>class.err</code></td>
<td>
<p>Soft and hard classification errors for mixture membership.
Only returned when the true models are known.</p>
</td></tr> 
<tr><td><code>est.err</code></td>
<td>
<p>estimation error from the comparison between the estimated
and true coefficient matrices. Only returned when the true models are
known.</p>
</td></tr> 
<tr><td><code>pred.err</code></td>
<td>
<p>prediction error. Only returned when the true models are
known.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Suyeon Kang, University of California, Riverside, <a href="mailto:skang062@ucr.edu">skang062@ucr.edu</a>;
Weixin Yao, University of California, Riverside, <a href="mailto:weixin.yao@ucr.edu">weixin.yao@ucr.edu</a>;
Kun Chen, University of Connecticut, <a href="mailto:kun.chen@uconn.edu">kun.chen@uconn.edu</a>.
</p>


<h3>References</h3>

<p>Kang, S., Chen, K., and Yao, W. (2022+). &quot;Reduced rank estimation in mixtures
of multivariate linear regression&quot;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rrmix.sim.norm">rrmix.sim.norm</a></code>, <code><a href="#topic+initialize.para">initialize.para</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(rrMixture)

#-----------------------------------------------------------#
# Real Data Example: Tuna Data
#-----------------------------------------------------------#
require(bayesm)
data(tuna)
tunaY &lt;- log(tuna[, c("MOVE1", "MOVE2", "MOVE3", "MOVE4",
                  "MOVE5", "MOVE6", "MOVE7")])
tunaX &lt;- tuna[, c("NSALE1", "NSALE2", "NSALE3", "NSALE4",
              "NSALE5", "NSALE6", "NSALE7",
              "LPRICE1", "LPRICE2", "LPRICE3", "LPRICE4",
              "LPRICE5", "LPRICE6", "LPRICE7")]
tunaX &lt;- cbind(intercept = 1, tunaX)

# Rank-penalized estimation

tuna.rp &lt;- rrmix(K = 2, X = tunaX, Y = tunaY, lambda = 3, est = "RP",
           seed = 100, n.init = 100)
summary(tuna.rp)
plot(tuna.rp) 

# Adaptive nuclear norm penalized estimation

tuna.annp &lt;- rrmix(K = 2, X = tunaX, Y = tunaY, lambda = 3, gamma = 2, est = "ANNP",
             seed = 100, n.init = 100)
summary(tuna.annp)
plot(tuna.annp)       

#-----------------------------------------------------------#
# Simulation: Two Components Case
#-----------------------------------------------------------#
# Simulation Data
K2mod &lt;- rrmix.sim.norm(K = 2, n = 100, p = 5, q = 5, rho = .5,
         b = 1, shift = 1, r.star = c(1, 3), sigma = c(1, 1),
         pr = c(.5, .5), seed = 1215)
         
# Rank-penalized estimation

K2.rp &lt;- rrmix(K = 2, X = K2mod$X, Y = K2mod$Y, lambda = 1,
         seed = 17, est = "RP", ind.true = K2mod$ind.true,
         para.true = K2mod$para.true, n.init = 100)
summary(K2.rp)
plot(K2.rp)
         
# Adaptive nuclear norm penalized estimation

K2.annp &lt;- rrmix(K = 2, X = K2mod$X, Y = K2mod$Y, lambda = 1,
           seed = 17, est = "ANNP", ind.true = K2mod$ind.true,
           para.true = K2mod$para.true, n.init = 100)
summary(K2.annp)
plot(K2.annp)
</code></pre>

<hr>
<h2 id='rrmix.sim.norm'>Simulation Data Generator</h2><span id='topic+rrmix.sim.norm'></span>

<h3>Description</h3>

<p>&lsquo;rrmix.sim.norm&rsquo; is used to create synthetic data from the multivariate
normal distribution, which is used in a numerical study of Kang et. al.
(2022+).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrmix.sim.norm(
  K = 2,
  n = 100,
  p = 5,
  q = 5,
  rho = 0.5,
  b = 1,
  shift = 1,
  r.star = NULL,
  sigma = NULL,
  pr = NULL,
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrmix.sim.norm_+3A_k">K</code></td>
<td>
<p>number of mixture components.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_n">n</code></td>
<td>
<p>number of observations.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_p">p</code></td>
<td>
<p>number of predictors including an intercept.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_q">q</code></td>
<td>
<p>number of responses.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_rho">rho</code></td>
<td>
<p>correlation between predictors used to make a design matrix.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_b">b</code></td>
<td>
<p>signal strength which controls the magnitude of coefficient matrices.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_shift">shift</code></td>
<td>
<p>mean shift which measures how separate the mixture components are.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_r.star">r.star</code></td>
<td>
<p>vector of length K, specifying the true ranks of K coefficient
matrices.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_sigma">sigma</code></td>
<td>
<p>vector of length K, specifying the noise strength of K
multivariate normal distributions.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_pr">pr</code></td>
<td>
<p>vector of length K, specifying the multinomial probabilities for
the K mixture components.</p>
</td></tr>
<tr><td><code id="rrmix.sim.norm_+3A_seed">seed</code></td>
<td>
<p>seed number for the reproducibility of results. Default is &lsquo;NULL&rsquo;.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>X</code></td>
<td>
<p>n by p design matrix.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>n by q response matrix.</p>
</td></tr>
<tr><td><code>E</code></td>
<td>
<p>p by q error matrix.</p>
</td></tr>
<tr><td><code>ind.true</code></td>
<td>
<p>vector of length n, specifying the true mixture membership
for n observations.</p>
</td></tr>
<tr><td><code>para.true</code></td>
<td>
<p>array of length K. It consists of K lists, each of which
contains a coefficient matrix and its true rank.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Suyeon Kang, University of California, Riverside, <a href="mailto:skang062@ucr.edu">skang062@ucr.edu</a>;
Weixin Yao, University of California, Riverside, <a href="mailto:weixin.yao@ucr.edu">weixin.yao@ucr.edu</a>;
Kun Chen, University of Connecticut, <a href="mailto:kun.chen@uconn.edu">kun.chen@uconn.edu</a>.
</p>


<h3>References</h3>

<p>Kang, S., Chen, K., and Yao, W. (2022+). &quot;Reduced rank estimation in mixtures
of multivariate linear regression&quot;.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-----------------------------------------------------------#
# Simulation 1: Two Components Case
#-----------------------------------------------------------#
K2mod &lt;- rrmix.sim.norm(K = 2, n = 100, p = 5, q = 5, rho = .5,
         b = 1, shift = 1, r.star = c(1, 3), sigma = c(1, 1),
         pr = c(.5, .5), seed = 1215)

#-----------------------------------------------------------#
# Simulation 2: Four Components Case
#-----------------------------------------------------------#
K4mod &lt;- rrmix.sim.norm(K = 4, n = 600, p = 15, q = 15,
         rho = .5, b = 1, shift = 1, r.star = c(1, 1, 3, 3),
         sigma = c(1, 1, 1, 1), pr = c(.25, .25, .25, .25),
         seed = 1215)
</code></pre>

<hr>
<h2 id='rrMixture'>rrMixture: Reduced-Rank Mixture Models.</h2><span id='topic+rrMixture'></span>

<h3>Description</h3>

<p>The rrMixture package provides three important functions currently:
rrmix, rrmix.sim.norm, and initialize.para.
</p>

<hr>
<h2 id='summary'>Summarize rrmix Objects</h2><span id='topic+summary'></span><span id='topic+summary.rrmix'></span><span id='topic+summary.tune.rrmix'></span>

<h3>Description</h3>

<p>S3 methods summarizing objects generated by <code>rrmix</code> and <code>tune.rrmix</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'rrmix'
summary(object, ...)

## S3 method for class 'tune.rrmix'
summary(
  object,
  metric = c("bic", "soft.class.err", "hard.class.err", "est.err", "pred.err"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>Object generated from <code>rrmix</code> or <code>tune.rrmix</code>.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>Other arguments for future usage.</p>
</td></tr>
<tr><td><code id="summary_+3A_metric">metric</code></td>
<td>
<p>performance metric to use for finding best &lsquo;rrmix&rsquo; model.
&lsquo;soft.class.err&rsquo;, &lsquo;hard.class.err&rsquo;, &lsquo;est.err&rsquo;, and &lsquo;pred.err&rsquo; can only be
used when true parameter values are known.</p>
</td></tr>
</table>

<hr>
<h2 id='tune.rrmix'>Reduced-rank mixture models with optimal tuning parameter(s)</h2><span id='topic+tune.rrmix'></span>

<h3>Description</h3>

<p>Reduced-rank mixture models with optimal tuning parameter(s)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tune.rrmix(K = NULL, K.max = NULL, X, Y, est = c("FR", "RP", "ANNP"),
           lambda = NULL, n.lambda = 20, gamma = 2,
           ind0 = NULL, para0 = NULL, seed = NULL, kmscale = FALSE, km.nstart = 20,
           n.init = 100, commonvar = FALSE, maxiter = 1000, maxiter.int = 100,
           thres = 1e-05, thres.int = 1e-05, 
           para.true = NULL, ind.true = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tune.rrmix_+3A_k">K</code></td>
<td>
<p>number of mixture components. Required when K.max is &lsquo;NULL&rsquo;.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_k.max">K.max</code></td>
<td>
<p>maximum of mixture components. Default is &lsquo;NULL&rsquo;. When provided,
the argument K is ignored.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_x">X</code></td>
<td>
<p>n by p design matrix where n is the number of observations and
p is the number of predictors.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_y">Y</code></td>
<td>
<p>n by q response matrix where n is the number of observations and
q is the number of responses.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_est">est</code></td>
<td>
<p>character, specifying the estimation method. &lsquo;FR&rsquo;, &lsquo;RP&rsquo;, and &lsquo;ANNP&rsquo;
refers to as the full-ranked, rank-penalized, and adaptive nuclear norm
penalized method, respectively.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_lambda">lambda</code></td>
<td>
<p>vector consisting of lambda candidates. Only used in the
estimation method of &lsquo;RP&rsquo; and &lsquo;ANNP&rsquo;. If 0, all estimation methods (&lsquo;FR&rsquo;,
&lsquo;RP&rsquo;, and &lsquo;ANNP&rsquo;) provide the same estimation results. Default is 'NULL'.
If 'NULL', data-adaptive range of lambda will be provided internally.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_n.lambda">n.lambda</code></td>
<td>
<p>number of lambda candidates to explore. Only used when
'lambda' is 'NULL'. Default is 20.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_gamma">gamma</code></td>
<td>
<p>numerical value, specifying additional tuning parameter, only
used in the estimation method of &lsquo;ANNP&rsquo;. It must be nonnegative.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_ind0">ind0</code></td>
<td>
<p>vector of length n, specifying the initial assignment of the
mixture membership of n observations when there is prior information on
the membership. If &lsquo;NULL&rsquo;, K-means clustering technique is used to assign
the membership for n observations. Default is &lsquo;NULL&rsquo;.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_para0">para0</code></td>
<td>
<p>array of length K. It consists of K lists, each of which contains
initial values of membership probability, coefficient matrix, and variance-
covariance matrix.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_seed">seed</code></td>
<td>
<p>seed number for the reproducibility of results. Default of &lsquo;NULL&rsquo;.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_kmscale">kmscale</code></td>
<td>
<p>logical value, indicating whether Y is scaled prior to K-means
clustering for initialization. Default is &lsquo;FALSE&rsquo;.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_km.nstart">km.nstart</code></td>
<td>
<p>number of random sets considered to perform K-means
clustering for initialization. Default is 20.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_n.init">n.init</code></td>
<td>
<p>number of initializations to try. Two methods for initial
clustering are used: K-means and random clustering.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_commonvar">commonvar</code></td>
<td>
<p>logical value, indicating the homogeneity assumption of
variance-covariance matrices across K mixture components. Default is &lsquo;FALSE&rsquo;.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations for external iterative
algorithm, used in all estimation methods.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_maxiter.int">maxiter.int</code></td>
<td>
<p>maximum number of iterations for internal iterative
algorithm, only used in the estimation method of &lsquo;ANNP&rsquo;.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_thres">thres</code></td>
<td>
<p>threshold value for external EM algorithm, used in all
estimation methods. It controls the termination of the EM algorithm.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_thres.int">thres.int</code></td>
<td>
<p>threshold value for internal iterative algorithm, only used
in the estimation method of &lsquo;ANNP&rsquo;. It controls the termination of the
internal algorithm.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_para.true">para.true</code></td>
<td>
<p>array of length K. It consists of K lists, each of which
contains a coefficient matrix and its true rank. Only used when true models
are known, e.g., in a simulation study.</p>
</td></tr>
<tr><td><code id="tune.rrmix_+3A_ind.true">ind.true</code></td>
<td>
<p>vector of length n, specifying the true mixture membership
for n observations. Only used when true models are known, e.g., in a
simulation study.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>lambda.cand</code></td>
<td>
<p>lambda values used as input.</p>
</td></tr>
<tr><td><code>penloglik</code></td>
<td>
<p>penalized log-likelihood values corresponding to the set
of lambda values.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>BIC values corresponding to the set of lambda values.</p>
</td></tr>
<tr><td><code>est.rank</code></td>
<td>
<p>estimated ranks corresponding to the set of lambda values.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Suyeon Kang, University of California, Riverside, <a href="mailto:skang062@ucr.edu">skang062@ucr.edu</a>;
Weixin Yao, University of California, Riverside, <a href="mailto:weixin.yao@ucr.edu">weixin.yao@ucr.edu</a>;
Kun Chen, University of Connecticut, <a href="mailto:kun.chen@uconn.edu">kun.chen@uconn.edu</a>.
</p>


<h3>References</h3>

<p>Kang, S., Chen, K., and Yao, W. (2022+). &quot;Reduced rank estimation in mixtures
of multivariate linear regression&quot;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rrmix">rrmix</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#-----------------------------------------------------------#
# Real Data Example: Tuna Data
#-----------------------------------------------------------#
require(bayesm)
data(tuna)
tunaY &lt;- log(tuna[, c("MOVE1", "MOVE2", "MOVE3", "MOVE4",
                  "MOVE5", "MOVE6", "MOVE7")])
tunaX &lt;- tuna[, c("NSALE1", "NSALE2", "NSALE3", "NSALE4",
              "NSALE5", "NSALE6", "NSALE7",
              "LPRICE1", "LPRICE2", "LPRICE3", "LPRICE4",
              "LPRICE5", "LPRICE6", "LPRICE7")]
tunaX &lt;- cbind(intercept = 1, tunaX)


tuna.tune &lt;- tune.rrmix(K.max = 3, X = tunaX, Y = tunaY, est = "RP",
             lambda = exp(seq(0, log(100), length = 20)),
             seed = 100, n.init = 100)
summary(tuna.tune)
plot(tuna.tune, transform.y = log, ylab = "log(lambda)") 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
