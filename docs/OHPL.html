<!DOCTYPE html><html lang="en"><head><title>Help for package OHPL</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {OHPL}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#OHPL-package'><p>OHPL: Ordered Homogeneity Pursuit Lasso for Group Variable Selection</p></a></li>
<li><a href='#beer'><p>The beer dataset</p></a></li>
<li><a href='#cv.OHPL'><p>Cross-validation for Ordered Homogeneity Pursuit Lasso</p></a></li>
<li><a href='#dlc'><p>Compute D, L, and C in the Fisher optimal partitions algorithm</p></a></li>
<li><a href='#FOP'><p>Fisher optimal partition</p></a></li>
<li><a href='#OHPL'><p>Ordered Homogeneity Pursuit Lasso</p></a></li>
<li><a href='#OHPL.RMSEP'><p>Compute RMSEP, MAE, and Q2 for a test set</p></a></li>
<li><a href='#OHPL.sim'><p>Generate simulation data for benchmarking sparse regressions</p>
(Gaussian response)</a></li>
<li><a href='#predict.OHPL'><p>Make predictions based on the fitted OHPL model</p></a></li>
<li><a href='#proto'><p>Extract the prototype from each variable group</p></a></li>
<li><a href='#soil'><p>The soil dataset</p></a></li>
<li><a href='#wheat'><p>The wheat dataset</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Ordered Homogeneity Pursuit Lasso for Group Variable Selection</td>
</tr>
<tr>
<td>Version:</td>
<td>1.4.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Ordered homogeneity pursuit lasso (OHPL)
    algorithm for group variable selection proposed in Lin et al. (2017)
    &lt;<a href="https://doi.org/10.1016%2Fj.chemolab.2017.07.004">doi:10.1016/j.chemolab.2017.07.004</a>&gt;. The OHPL method exploits the
    homogeneity structure in high-dimensional data and enjoys the
    grouping effect to select groups of important variables
    automatically. This feature makes it particularly useful for
    high-dimensional datasets with strongly correlated variables,
    such as spectroscopic data.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> | file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://ohpl.io">https://ohpl.io</a>, <a href="https://ohpl.io/doc/">https://ohpl.io/doc/</a>,
<a href="https://github.com/nanxstats/OHPL">https://github.com/nanxstats/OHPL</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/nanxstats/OHPL/issues">https://github.com/nanxstats/OHPL/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.2)</td>
</tr>
<tr>
<td>Imports:</td>
<td>glmnet, mvtnorm, pls</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-20 19:19:07 UTC; nanx</td>
</tr>
<tr>
<td>Author:</td>
<td>You-Wu Lin [aut],
  Nan Xiao <a href="https://orcid.org/0000-0002-0250-5673"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Nan Xiao &lt;me@nanx.me&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-20 19:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='OHPL-package'>OHPL: Ordered Homogeneity Pursuit Lasso for Group Variable Selection</h2><span id='topic+OHPL-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Ordered homogeneity pursuit lasso (OHPL) algorithm for group variable selection proposed in Lin et al. (2017) <a href="https://doi.org/10.1016/j.chemolab.2017.07.004">doi:10.1016/j.chemolab.2017.07.004</a>. The OHPL method exploits the homogeneity structure in high-dimensional data and enjoys the grouping effect to select groups of important variables automatically. This feature makes it particularly useful for high-dimensional datasets with strongly correlated variables, such as spectroscopic data.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Nan Xiao <a href="mailto:me@nanx.me">me@nanx.me</a> (<a href="https://orcid.org/0000-0002-0250-5673">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> You-Wu Lin <a href="mailto:lyw015813@126.com">lyw015813@126.com</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://ohpl.io">https://ohpl.io</a>
</p>
</li>
<li> <p><a href="https://ohpl.io/doc/">https://ohpl.io/doc/</a>
</p>
</li>
<li> <p><a href="https://github.com/nanxstats/OHPL">https://github.com/nanxstats/OHPL</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/nanxstats/OHPL/issues">https://github.com/nanxstats/OHPL/issues</a>
</p>
</li></ul>


<hr>
<h2 id='beer'>The beer dataset</h2><span id='topic+beer'></span>

<h3>Description</h3>

<p>The beer dataset contains 60 samples published by Norgaard et al.
Recorded with a 30mm quartz cell on the undiluted degassed beer
and measured from 1100 to 2250 nm (576 data points) in steps of 2 nm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(beer)
</code></pre>


<h3>References</h3>

<p>Norgaard, L., Saudland, A., Wagner, J., Nielsen, J. P., Munck, L., &amp;
Engelsen, S. B. (2000). Interval partial least-squares regression (iPLS):
a comparative chemometric study with an example from near-infrared
spectroscopy. <em>Applied Spectroscopy</em>, 54(3), 413&ndash;419.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("beer")
x.cal &lt;- beer$xtrain
dim(x.cal)
x.test &lt;- beer$xtest
dim(x.test)
y.cal &lt;- beer$ytrain
dim(y.cal)
y.test &lt;- beer$ytest
dim(y.test)

X &lt;- rbind(x.cal, x.test)
y &lt;- rbind(y.cal, y.test)
n &lt;- nrow(y)

set.seed(1001)
samp.idx &lt;- sample(1L:n, round(n * 0.7))
X.cal &lt;- X[samp.idx, ]
y.cal &lt;- y[samp.idx]
X.test &lt;- X[-samp.idx, ]
y.test &lt;- y[-samp.idx]
</code></pre>

<hr>
<h2 id='cv.OHPL'>Cross-validation for Ordered Homogeneity Pursuit Lasso</h2><span id='topic+cv.OHPL'></span>

<h3>Description</h3>

<p>Use cross-validation to help select the optimal number
of variable groups and the value of <code>gamma</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.OHPL(
  X.cal,
  y.cal,
  maxcomp,
  gamma = seq(0.1, 0.9, 0.1),
  X.test,
  y.test,
  cv.folds = 5L,
  G = 30L,
  type = c("max", "median"),
  scale = TRUE,
  pls.method = "simpls"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.OHPL_+3A_x.cal">X.cal</code></td>
<td>
<p>Predictor matrix (training).</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_y.cal">y.cal</code></td>
<td>
<p>Response matrix with one column (training).</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_maxcomp">maxcomp</code></td>
<td>
<p>Maximum number of components for PLS.</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_gamma">gamma</code></td>
<td>
<p>A vector of the gamma sequence between (0, 1).</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_x.test">X.test</code></td>
<td>
<p>X.test Predictor matrix (test).</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_y.test">y.test</code></td>
<td>
<p>y.test Response matrix with one column (test).</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_cv.folds">cv.folds</code></td>
<td>
<p>Number of cross-validation folds.</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_g">G</code></td>
<td>
<p>Maximum number of variable groups.</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_type">type</code></td>
<td>
<p>Find the maximum absolute correlation (<code>"max"</code>)
or find the median of absolute correlation (<code>"median"</code>).
Default is <code>"max"</code>.</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_scale">scale</code></td>
<td>
<p>Should the predictor matrix be scaled?
Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cv.OHPL_+3A_pls.method">pls.method</code></td>
<td>
<p>Method for fitting the PLS model.
Default is <code>"simpls"</code>. See the details section
in <code><a href="pls.html#topic+mvr">pls::plsr()</a></code> for all possible options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the optimal model, RMSEP, Q2,
and other evaluation metrics. Also the optimal number
of groups to use in group lasso.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wheat")

X &lt;- wheat$x
y &lt;- wheat$protein
n &lt;- nrow(wheat$x)

set.seed(1001)
samp.idx &lt;- sample(1L:n, round(n * 0.7))
X.cal &lt;- X[samp.idx, ]
y.cal &lt;- y[samp.idx]
X.test &lt;- X[-samp.idx, ]
y.test &lt;- y[-samp.idx]

# This could run for a while
## Not run: 
cv.fit &lt;- cv.OHPL(
  x, y,
  maxcomp = 6, gamma = seq(0.1, 0.9, 0.1),
  x.test, y.test, cv.folds = 5, G = 30, type = "max"
)
# the optimal G and gamma
cv.fit$opt.G
cv.fit$opt.gamma

## End(Not run)
</code></pre>

<hr>
<h2 id='dlc'>Compute D, L, and C in the Fisher optimal partitions algorithm</h2><span id='topic+dlc'></span>

<h3>Description</h3>

<p>Compute D, L, and C in the Fisher optimal partitions algorithm
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dlc(X, maxk)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dlc_+3A_x">X</code></td>
<td>
<p>A set of samples.</p>
</td></tr>
<tr><td><code id="dlc_+3A_maxk">maxk</code></td>
<td>
<p>Maximum number of <code>k</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The D, L, and C statistics in the
Fisher optimal partitions algorithm.
</p>

<hr>
<h2 id='FOP'>Fisher optimal partition</h2><span id='topic+FOP'></span>

<h3>Description</h3>

<p>The Fisher optimal partition algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FOP(X, k, C)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FOP_+3A_x">X</code></td>
<td>
<p>A set of samples.</p>
</td></tr>
<tr><td><code id="FOP_+3A_k">k</code></td>
<td>
<p>Number of classes.</p>
</td></tr>
<tr><td><code id="FOP_+3A_c">C</code></td>
<td>
<p>Statistic from the output of <code><a href="#topic+dlc">dlc()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Index vector for each sample's classification.
</p>


<h3>References</h3>

<p>W. D. Fisher (1958). On grouping for maximum homogeneity.
<em>Journal of the American Statistical Association</em>,
vol. 53, pp. 789&ndash;798.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- matrix(c(
  9.3, 1.8, 1.9, 1.7, 1.5, 1.3,
  1.4, 2.0, 1.9, 2.3, 2.1
))
C &lt;- dlc(X, maxk = 8)$C
F &lt;- FOP(X, 8, C)
</code></pre>

<hr>
<h2 id='OHPL'>Ordered Homogeneity Pursuit Lasso</h2><span id='topic+OHPL'></span>

<h3>Description</h3>

<p>Fits the ordered homogeneity pursuit lasso (OHPL) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OHPL(
  x,
  y,
  maxcomp,
  gamma,
  cv.folds = 5L,
  G = 30L,
  type = c("max", "median"),
  scale = TRUE,
  pls.method = "simpls"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="OHPL_+3A_x">x</code></td>
<td>
<p>Predictor matrix.</p>
</td></tr>
<tr><td><code id="OHPL_+3A_y">y</code></td>
<td>
<p>Response matrix with one column.</p>
</td></tr>
<tr><td><code id="OHPL_+3A_maxcomp">maxcomp</code></td>
<td>
<p>Maximum number of components for PLS.</p>
</td></tr>
<tr><td><code id="OHPL_+3A_gamma">gamma</code></td>
<td>
<p>A number between (0, 1) for generating the gamma sequence.
An usual choice for gamma could be <code>n * 0.05</code>, where <code>n</code> is a number
in 2, 3, ..., 19.</p>
</td></tr>
<tr><td><code id="OHPL_+3A_cv.folds">cv.folds</code></td>
<td>
<p>Number of cross-validation folds.</p>
</td></tr>
<tr><td><code id="OHPL_+3A_g">G</code></td>
<td>
<p>Maximum number of variable groups.</p>
</td></tr>
<tr><td><code id="OHPL_+3A_type">type</code></td>
<td>
<p>Find the maximum absolute correlation (<code>"max"</code>)
or find the median of absolute correlation (<code>"median"</code>).
Default is <code>"max"</code>.</p>
</td></tr>
<tr><td><code id="OHPL_+3A_scale">scale</code></td>
<td>
<p>Should the predictor matrix be scaled? Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="OHPL_+3A_pls.method">pls.method</code></td>
<td>
<p>Method for fitting the PLS model. Default is <code>"simpls"</code>.
See the details section in <code><a href="pls.html#topic+mvr">pls::plsr()</a></code> for all possible options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of fitted OHPL model object with performance metrics.
</p>


<h3>References</h3>

<p>You-Wu Lin, Nan Xiao, Li-Li Wang, Chuan-Quan Li, and Qing-Song Xu (2017).
Ordered homogeneity pursuit lasso for group variable selection with
applications to spectroscopic data.
<em>Chemometrics and Intelligent Laboratory Systems</em> 168, 62&ndash;71.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate simulation data
dat &lt;- OHPL.sim(
  n = 100, p = 100, rho = 0.8,
  coef = rep(1, 10), snr = 3, p.train = 0.5,
  seed = 1010
)

# Split training and test set
x &lt;- dat$x.tr
y &lt;- dat$y.tr
x.test &lt;- dat$x.te
y.test &lt;- dat$y.te

# Fit the OHPL model
fit &lt;- OHPL(x, y, maxcomp = 3, gamma = 0.5, G = 10, type = "max")

# Selected variables
fit$Vsel

# Make predictions
y.pred &lt;- predict(fit, x.test)

# Compute evaluation metric RMSEP, Q2 and MAE for the test set
perf &lt;- OHPL.RMSEP(fit, x.test, y.test)
perf$RMSEP
perf$Q2
perf$MAE
</code></pre>

<hr>
<h2 id='OHPL.RMSEP'>Compute RMSEP, MAE, and Q2 for a test set</h2><span id='topic+OHPL.RMSEP'></span>

<h3>Description</h3>

<p>Makes predictions on new data and computes the performance evaluation
metrics RMSEP, MAE, and Q2.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OHPL.RMSEP(object, newx, newy)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="OHPL.RMSEP_+3A_object">object</code></td>
<td>
<p>Object of class <code>OHPL</code> fitted by <code><a href="#topic+OHPL">OHPL()</a></code>.</p>
</td></tr>
<tr><td><code id="OHPL.RMSEP_+3A_newx">newx</code></td>
<td>
<p>Predictor matrix of the new data.</p>
</td></tr>
<tr><td><code id="OHPL.RMSEP_+3A_newy">newy</code></td>
<td>
<p>Response matrix of the new data (matrix with one column).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the performance metrics.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate simulation data
dat &lt;- OHPL.sim(
  n = 100, p = 100, rho = 0.8,
  coef = rep(1, 10), snr = 3, p.train = 0.5,
  seed = 1010
)

# Split training and test set
x &lt;- dat$x.tr
y &lt;- dat$y.tr
x.test &lt;- dat$x.te
y.test &lt;- dat$y.te

# Fit the OHPL model
fit &lt;- OHPL(x, y, maxcomp = 3, gamma = 0.5, G = 10, type = "max")

# Compute evaluation metric RMSEP, Q2 and MAE for the test set
perf &lt;- OHPL.RMSEP(fit, x.test, y.test)
perf$RMSEP
perf$Q2
perf$MAE
</code></pre>

<hr>
<h2 id='OHPL.sim'>Generate simulation data for benchmarking sparse regressions
(Gaussian response)</h2><span id='topic+OHPL.sim'></span>

<h3>Description</h3>

<p>Generate simulation data (Gaussian case) following the
settings in Xiao and Xu (2015).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OHPL.sim(
  n = 100,
  p = 100,
  rho = 0.8,
  coef = rep(1, 10),
  snr = 3,
  p.train = 0.5,
  seed = 1001
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="OHPL.sim_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="OHPL.sim_+3A_p">p</code></td>
<td>
<p>Number of variables.</p>
</td></tr>
<tr><td><code id="OHPL.sim_+3A_rho">rho</code></td>
<td>
<p>Correlation base for generating correlated variables.</p>
</td></tr>
<tr><td><code id="OHPL.sim_+3A_coef">coef</code></td>
<td>
<p>Vector of non-zero coefficients.</p>
</td></tr>
<tr><td><code id="OHPL.sim_+3A_snr">snr</code></td>
<td>
<p>Signal-to-noise ratio (SNR).</p>
</td></tr>
<tr><td><code id="OHPL.sim_+3A_p.train">p.train</code></td>
<td>
<p>Percentage of training set.</p>
</td></tr>
<tr><td><code id="OHPL.sim_+3A_seed">seed</code></td>
<td>
<p>Random seed for reproducibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing <code>x.tr</code>, <code>x.te</code>, <code>y.tr</code>, and <code>y.te</code>.
</p>


<h3>Author(s)</h3>

<p>Nan Xiao <\url{https://nanx.me}>
</p>


<h3>References</h3>

<p>Nan Xiao and Qing-Song Xu. (2015). Multi-step adaptive elastic-net:
reducing false positives in high-dimensional variable selection.
<em>Journal of Statistical Computation and Simulation</em> 85(18), 3755&ndash;3765.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dat &lt;- OHPL.sim(
  n = 100, p = 100, rho = 0.8,
  coef = rep(1, 10), snr = 3, p.train = 0.5,
  seed = 1010
)

dim(dat$x.tr)
dim(dat$x.te)
</code></pre>

<hr>
<h2 id='predict.OHPL'>Make predictions based on the fitted OHPL model</h2><span id='topic+predict.OHPL'></span>

<h3>Description</h3>

<p>Make predictions on new data by an OHPL model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'OHPL'
predict(object, newx, ncomp = NULL, type = "response", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.OHPL_+3A_object">object</code></td>
<td>
<p>Object of class <code>OHPL</code> fitted by <code><a href="#topic+OHPL">OHPL()</a></code>.</p>
</td></tr>
<tr><td><code id="predict.OHPL_+3A_newx">newx</code></td>
<td>
<p>Predictor matrix of the new data.</p>
</td></tr>
<tr><td><code id="predict.OHPL_+3A_ncomp">ncomp</code></td>
<td>
<p>Optimal number of components.
If is <code>NULL</code>, the optimal number of components
stored in the model object will be used.</p>
</td></tr>
<tr><td><code id="predict.OHPL_+3A_type">type</code></td>
<td>
<p>Prediction type.</p>
</td></tr>
<tr><td><code id="predict.OHPL_+3A_...">...</code></td>
<td>
<p>Additional parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric matrix of the predicted values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># generate simulation data
dat &lt;- OHPL.sim(
  n = 100, p = 100, rho = 0.8,
  coef = rep(1, 10), snr = 3, p.train = 0.5,
  seed = 1010
)

# split training and test set
x &lt;- dat$x.tr
y &lt;- dat$y.tr
x.test &lt;- dat$x.te
y.test &lt;- dat$y.te

# fit the OHPL model
fit &lt;- OHPL(x, y, maxcomp = 3, gamma = 0.5, G = 10, type = "max")
# make predictions
y.pred &lt;- predict(fit, x.test)
y.pred
</code></pre>

<hr>
<h2 id='proto'>Extract the prototype from each variable group</h2><span id='topic+proto'></span>

<h3>Description</h3>

<p>Extracts the prototype from each variable group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>proto(X, y, groups, type = c("max", "median"), mu = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="proto_+3A_x">X</code></td>
<td>
<p>Predictor matrix.</p>
</td></tr>
<tr><td><code id="proto_+3A_y">y</code></td>
<td>
<p>Response matrix with one column.</p>
</td></tr>
<tr><td><code id="proto_+3A_groups">groups</code></td>
<td>
<p>An group index vector containing the
group number each variable belongs to. For example:
<code>c(1, 1, 1, 1, 1, 2, 2, 2, ...)</code>.
Variable groups can be generated by the Fisher optimal
partition algorithm implemented in <code><a href="#topic+FOP">FOP()</a></code>.</p>
</td></tr>
<tr><td><code id="proto_+3A_type">type</code></td>
<td>
<p>The rule for extracting the prototype.
Possible options are <code>"max"</code> and <code>"median"</code>.</p>
</td></tr>
<tr><td><code id="proto_+3A_mu">mu</code></td>
<td>
<p>The mean value of <code>y</code> for standardization.
Default is <code>NULL</code>, which uses the sample mean of <code>y</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The prototypes (variable index) extracted
from each group (cluster).
</p>

<hr>
<h2 id='soil'>The soil dataset</h2><span id='topic+soil'></span>

<h3>Description</h3>

<p>The soil dataset contains 108 sample measurements from the
wavelength range of 400â€“2500 nm (visible and near infrared spectrum)
published by Rinnan et al.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(soil)
</code></pre>


<h3>References</h3>

<p>Rinnan, R., &amp; Rinnan, A. (2007). Application of near infrared
reflectance (NIR) and fluorescence spectroscopy to analysis of
microbiological and chemical properties of arctic soil.
<em>Soil biology and Biochemistry</em>, 39(7), 1664&ndash;1673.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("soil")

X &lt;- soil$x
y &lt;- soil$som
n &lt;- nrow(soil$x)

set.seed(1001)
samp.idx &lt;- sample(1L:n, round(n * 0.7))
X.cal &lt;- X[samp.idx, ]
y.cal &lt;- y[samp.idx]
X.test &lt;- X[-samp.idx, ]
y.test &lt;- y[-samp.idx]
</code></pre>

<hr>
<h2 id='wheat'>The wheat dataset</h2><span id='topic+wheat'></span>

<h3>Description</h3>

<p>The wheat dataset contains 100 wheat samples with specified
protein and moisture content, published by J. Kalivas.
Samples were measured by diffuse reflectance as log (I/R)
from 1100 to 2500 nm (701 data points) in 2 nm intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wheat)
</code></pre>


<h3>References</h3>

<p>Kalivas, J. H. (1997). Two data sets of near infrared spectra.
<em>Chemometrics and Intelligent Laboratory Systems</em>, 37(2), 255&ndash;259.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wheat")

X &lt;- wheat$x
y &lt;- wheat$protein
n &lt;- nrow(wheat$x)

set.seed(1001)
samp.idx &lt;- sample(1L:n, round(n * 0.7))
X.cal &lt;- X[samp.idx, ]
y.cal &lt;- y[samp.idx]
X.test &lt;- X[-samp.idx, ]
y.test &lt;- y[-samp.idx]
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
