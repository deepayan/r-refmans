<!DOCTYPE html><html><head><title>Help for package eatRep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {eatRep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#checkLEs'><p>Checks compatibility of linking errors with GADS data bases.</p></a></li>
<li><a href='#eatRep-package'>
<p>Statistical analyses in complex survey designs with multiple imputed data and trend estimation.</p></a></li>
<li><a href='#generateRandomJk1Zones'><p>Generates random jackknife-1 zones based on sampling units in the data set.</p></a></li>
<li><a href='#lsa'><p>Achievement data from two large-scale assessments of 2010 and 2015.</p></a></li>
<li><a href='#repGlm'><p>Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation.</p></a></li>
<li><a href='#repLmer'><p>Replication methods (JK1 and JK2) for multilevel linear regression models and trend estimation.</p></a></li>
<li><a href='#repMean'><p>Replication methods (JK1, JK2 and BRR) for descriptive statistics.</p></a></li>
<li><a href='#report'><p>Reporting function for <code>repMean</code>, <code>repTable</code>,</p>
<code>repQuantile</code>, and <code>repGlm</code></a></li>
<li><a href='#repQuantile'><p>Replication methods (JK1, JK2 and BRR) for quantiles and trend estimation.</p></a></li>
<li><a href='#repTable'><p>JK1, JK2 and BRR for frequency tables and trend estimation.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Educational Assessment Tools for Replication Methods</td>
</tr>
<tr>
<td>Version:</td>
<td>0.14.7</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1), survey (&ge; 4.1-1), BIFIEsurvey, progress, lavaan
(&ge; 0.6-7)</td>
</tr>
<tr>
<td>Imports:</td>
<td>Hmisc, fmsb, mice (&ge; 2.46), boot, car, reshape2, plyr,
combinat, miceadds, tidyr, EffectLiteR, estimatr, eatTools (&ge;
0.7.4), eatGADS (&ge; 0.20.0), janitor, msm, lme4, utils, methods</td>
</tr>
<tr>
<td>Description:</td>
<td>Replication methods to compute some basic statistic operations (means, standard deviations,
  frequency tables, percentiles and generalized linear models) in complex survey designs comprising multiple
  imputed variables and/or a clustered sampling structure which both deserve special procedures at least in
  estimating standard errors. See the package documentation for a more detailed description along with references.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/weirichs/eatRep">https://github.com/weirichs/eatRep</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-26 20:33:56 UTC; Sebastian Weirich</td>
</tr>
<tr>
<td>Author:</td>
<td>Sebastian Weirich [aut, cre],
  Martin Hecht [aut],
  Karoline Sachse [aut],
  Benjamin Becker [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sebastian Weirich &lt;sebastian.weirich@iqb.hu-berlin.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-26 22:30:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='checkLEs'>Checks compatibility of linking errors with GADS data bases.</h2><span id='topic+checkLEs'></span>

<h3>Description</h3>

<p>This function checks if a linking error <code>data.frame</code> is compatible with multiple trend <code>eatGADS</code> data bases. </p>


<h3>Usage</h3>

<pre><code class='language-R'>checkLEs(filePaths, leDF)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="checkLEs_+3A_filepaths">filePaths</code></td>
<td>


<p>Character vectors with at least two paths to the <code>eatGADS</code> db files.
</p>
</td></tr>
<tr><td><code id="checkLEs_+3A_ledf">leDF</code></td>
<td>


<p>Linking error <code>data.frame</code>. 
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>This function inspects whether all linking error variables correspond to variables in the <code>eatGADS</code> data base 
and if the key variables also correspond to existing variables in the trend <code>eatGADS</code> data bases.
</p>


<h3>Value</h3>






<p>Returns a report list.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># define eatGADs data bases
trenddat1 &lt;- system.file("extdata", "trend_gads_2010.db", package = "eatGADS")
trenddat2 &lt;- system.file("extdata", "trend_gads_2015.db", package = "eatGADS")
trenddat3 &lt;- system.file("extdata", "trend_gads_2020.db", package = "eatGADS")
# use template linking Error Object
load(system.file("extdata", "linking_error.rda", package = "eatRep"))
check1 &lt;- checkLEs(c(trenddat1, trenddat2, trenddat3), lErr)
check2 &lt;- checkLEs(c(trenddat1, trenddat2, trenddat3), lErr[1:14,])
</code></pre>

<hr>
<h2 id='eatRep-package'>
Statistical analyses in complex survey designs with multiple imputed data and trend estimation.
</h2><span id='topic+eatRep-package'></span>

<h3>Description</h3>

<p>The package provide functions to computes some basic statistic operations&mdash;(adjusted) means, standard deviations,
frequency tables, percentiles and generalized linear models&mdash;in complex survey designs comprising multiple
imputed variables and/or a clustered sampling structure which both deserve special procedures at least in
estimating standard errors. In large-scale assessments, standard errors are comprised of three components:
the measurement error, the sampling error, and (if trend estimation of at least two times of measurement
are involved) the linking error.
</p>
<p><strong>Measurement error:</strong> In complex surveys or large-scale assessments, measurement errors are taken
into account by the mean of multiple imputed variables. The computation of standard errors for the mean
of a multiple imputed variable (e.g. plausible values) involves the formulas provided by Rubin (1987).
Computing standard errors for the mean of a nested imputed variable involves the formulas provided by
Rubin (2003). Both methods are implemented in the package. The estimation of <code class="reqn">R^2</code> and adjusted
<code class="reqn">R^2</code> in linear and generalized linear regression models with multiple imputed data sets is
realized using the methods provided in Harel (2009).
</p>
<p><strong>Sampling error:</strong> Computation of sampling errors of variables which stem from a clustered design may
involve replication methods like balanced repeated replicate (BRR), bootstrap or Jackknife methods.
See Westat (2000), Foy, Galia &amp; Li (2008), Rust and Rao (1996), and Wolter (1985) for details. To date,
the Jackknife-1 (JK1), Jackknife-2 (JK2) and the Balanced Repeated Replicates (BRR; optionally with Fay's
method) procedures are supported.
</p>
<p><strong>Linking error:</strong> Lastly, standard errors for trend estimates may involve incorporating
linking errors to account for potential differential item functioning or item parameter drift.
<code>eatRep</code> allows to account for linking error when computing standard errors for trend
estimates. Standard error estimation is conducted according to the operational practice in
PISA, see equation 5 in Sachse &amp; Haag (2017).
</p>
<p>The package <code>eatRep</code> is designed to combine one or several error types which is necessary,
for example, if (nested) multiple imputed data are used in clustered designs. Considering the
structure is relevant especially for the estimation of standard errors. The estimation of national
trends requires a sequential analysis for both measurements and a comparison of estimates between them.
</p>
<p>Technically, <code>eatRep</code> is a wrapper for the <code>survey</code> package (Lumley, 2004). Each function in
<code>eatRep</code> corresponds to a specific function in <code>survey</code> which is called repeatedly during the analysis.
Hence, a nested loop is used. We use &ldquo;trend replicates&rdquo; in the outer loop, &ldquo;imputation replicates&rdquo; 
in the middle loop to account for multiple imputed data, and &ldquo;cluster replicates&rdquo; in the inner loop to 
account for the clustered sampling structure. While the functional principle of <code>survey</code> is based on 
replication of standard analyses, <code>eatRep</code> is based on replication of <code>survey</code> analyses to take 
multiple imputed data into account. More recent versions of the package additionally allow estimations using
the <code>BIFIEsurvey</code> package instead of <code>survey</code> which provide substantial advantages in terms of speed. 
</p>
<p>For each imputed data set in each measurement, i.e. in the inner loop, the <code>eatRep</code> function first creates 
replicate weights based on the primary sampling unit (PSU) variable and the replication indicator variable. In 
the jackknife procedure, the first one is often referred to as &ldquo;jackknife zone&rdquo;, whereas the second one 
is often referred to as &ldquo;jackknife replicate&rdquo;. The number of distinct units in the PSU variable defines
the number of replications which are necessary due to the clustered structure. A design object is created and 
the appropriate <code>survey</code> function is called. The process is repeated for each imputed dataset and the 
results of the analyses are pooled. The pooling procedure varies in relation to the type of variable to be 
pooled. For examples, means or regression coefficients are pooled according to Rubin (1987) or Rubin (2003). 
<code class="reqn">R^2</code> is pooled according to Harel (2009), using a Fisher <em>z</em>-transformation. Chi-square distributed values 
are pooled according to Thomas and Rao (1990) for clustered data and according to Enders (2010) and 
Allison (2002) for multiple imputed data. For trend analyses, the whole process is repeated two times 
(according to the two measurements) and the difference of the estimates are computed along with their 
pooled standard errors. 
</p>
<p>Without trend estimation, the outer loop has only one cycle (instead of two). Without multiple imputations, 
the middle loop has only one cycle. Without a clustered sampling structure (i.e, in a random sample), the 
inner loop has only one cycle. Without trend, imputation and clustered structure, no replication is performed 
at all. To compute simple mean estimates, for example, <code>eatRep</code> then simply calls <code>mean</code> instead 
of <code>svymean</code> from the <code>survey</code> package. A special case occurs with nested multiple imputation. 
We then have four loops in a nested structure. Hence, the corresponding analyses may take considerably 
computational effort. 
</p>
<p><em>Important note:</em> Starting with version 0.10.0, several methods for the standard error estimation
of cross level differences are implemented. Prior to version 0.10.0, the standard error for the difference
between one single group (e.g., Belgium) and the total population (which is comprised of several states including 
Belgium) was estimated as if both groups would have been independent from each other. The standard errors,
however, are biased then. Two new methods are now applicable using the argument <code>crossDiffSE</code> in 
<code><a href="#topic+repMean">repMean</a></code> and provide unbiased standard errors&mdash;weighted effect coding (wec) and replication
methods (rep); see, for example te Grotenhuis et al. (2017) and Weirich et al. (2021). The old method is still available by
using <code>crossDiffSE = "old"</code>. Note that the default method now is weighted effect coding.
</p>
<p><em>Second important note:</em> Starting with version 0.13.0, function names have been changed due to
inconsistent former denomination: Function <code>jk2.mean</code> now goes under the name of <code><a href="#topic+repMean">repMean</a></code>,
<code>jk2.table</code> was  renamed to <code><a href="#topic+repTable">repTable</a></code>, <code>jk2.quantile</code> was  renamed to <code><a href="#topic+repQuantile">repQuantile</a></code>,
and <code>jk2.glm</code> now goes under the name of <code><a href="#topic+repGlm">repGlm</a></code>. The old functions are deprecated and will
be removed in further package publications. Renaming was driven by the fact that the corresponding
functions now have broader range of methods than only jackknife-2.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> eatRep</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.14.7</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-03-24</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL(&gt;=2)
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Authors: Sebastian Weirich &lt;sebastian.weirich@iqb.hu-berlin.de&gt;, Martin Hecht &lt;martin.hecht@hu-berlin.de&gt;,
Benjamin Becker &lt;b.becker@iqb.hu-berlin.de&gt;
</p>


<h3>References</h3>

<p>Allison, P. D. (2002). Missing data. Newbury Park, CA: Sage.
</p>
<p>Enders, C. K. (2010). Applied missing data analysis. Guilford Press.
</p>
<p>Foy, P., Galia , J. &amp; Li, I. (2008). Scaling the data from the TIMSS 2007 mathematics
and science assessment. In J. F. Olson, M. O. Martin &amp; I. V. S. Mullis (ed.),
<em>TIMSS 2007 Technical Report</em> (S. 225&ndash;280). Chestnut Hill, MA: TIMSS &amp; PIRLS
International Study Center, Lynch School of Education, Boston College.
</p>
<p>Harel, O. (2009): The estimation of <code class="reqn">R^2</code> and adjusted <code class="reqn">R^2</code> in incomplete data 
sets using multiple imputation. <em>Journal of Applied Statistics.</em> <b>36, 10</b>, 1109&ndash;1118.
</p>
<p>Lumley, T. (2004). Analysis of complex survey samples. <em>Journal of Statistical Software</em> <b>9(1)</b>: 1&ndash;19
</p>
<p>Rubin, D. B. (1987). <em>Multiple imputation for nonresponse in surveys.</em> New York: Wiley.
</p>
<p>Rubin, D.B. (2003): Nested multiple imputation of NMES via partially incompatible MCMC.
<em>Statistica Neerlandica</em> <b>57, 1</b>, 3&ndash;18.
</p>
<p>Rust, K., &amp; Rao, JNK. (1996): Variance estimation for complex surveys using 
replication techniques. <em>Statistical Methods in Medical Research</em> <b>5</b>, 283&ndash;310.
</p>
<p>Sachse, K. A. &amp; Haag, N. (2017). Standard errors for national trends in international
large-scale assessments in the case of cross-national differential item functioning. <em>Applied
Measurement in Education, 30</em>, (2), 102-116. http://dx.doi.org/10.1080/08957347.2017.1283315
</p>
<p>Satorra, A., &amp; Bentler, P. M. (1994). Corrections to test statistics
and standard errors in covariance structure analysis.
</p>
<p>te Grotenhuis, M., Pelzer, B., Eisinga, R., Nieuwenhuis, R., Schmidt-Catran, A., &amp; Konig, R. (2017).
When size matters: advantages of weighted effect coding in observational studies.
<em>International Journal of Public Health.</em> <b>62</b>, 163&ndash;167.
</p>
<p>Thomas, D. R. &amp; Rao, JNK (1990): Small-sample comparison of level and power for simple goodness-of-
fit statistics under cluster sampling. JASA 82:630-636
</p>
<p>Weirich, S., Hecht, M., Becker, B. et al. (2021). Comparing group means with the total mean in random samples,
surveys, and large-scale assessments: A tutorial and software illustration. Behavior Research Methods.
https://doi.org/10.3758/s13428-021-01553-1
</p>
<p>Westat (2000). <em>WesVar.</em> Rockville, MD: Westat.
</p>
<p>Wolter, K. M. (1985). <em>Introduction to variance estimation.</em> New York: Springer.
</p>

<hr>
<h2 id='generateRandomJk1Zones'>Generates random jackknife-1 zones based on sampling units in the data set.</h2><span id='topic+generateRandomJk1Zones'></span>

<h3>Description</h3>

<p>Function adds randomly generated jackknife-1 zones to the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateRandomJk1Zones (datL, unit, nZones, name = "randomCluster")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generateRandomJk1Zones_+3A_datl">datL</code></td>
<td>
<p>Data frame containing at least the primary sampling unit variable</p>
</td></tr>
<tr><td><code id="generateRandomJk1Zones_+3A_unit">unit</code></td>
<td>
<p>Variable name or column number of the primary sampling unit (i.e.
student or class identifier</p>
</td></tr>
<tr><td><code id="generateRandomJk1Zones_+3A_nzones">nZones</code></td>
<td>
<p>integer: number of jackknife zones. Note: The umber of jackknife
zones must not exceed the number of distinct sampling units</p>
</td></tr>
<tr><td><code id="generateRandomJk1Zones_+3A_name">name</code></td>
<td>
<p>New name of the jackknife-zone variable in the data set</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The original data with an additional column of the jackknife-zone variable
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lsa)

### We only consider year 2010
lsa10&lt;- lsa[which(lsa[,"year"] == 2010),]
lsa10&lt;- generateRandomJk1Zones(datL = lsa10, unit="idclass", nZones = 50)
</code></pre>

<hr>
<h2 id='lsa'>Achievement data from two large-scale assessments of 2010 and 2015.</h2><span id='topic+lsa'></span>

<h3>Description</h3>

<p>This example data set contains fictional achievement scores of 11637 students from three countries
and two times of measurement in two domains (reading and listening comprehension) in the long format.
The data set contains nested multiple imputed plausible values of achievement scores as well as some
demographic variables. Illustrating trend analyses, data from two fictional time points (2010 and 2015)
are included.
</p>
<p>The data set can be used for several illustration purposes. For example, if only multiple imputation
should be considered (without nesting), simply use only cases from the first nest (by subsetting). If
only one time of measurement should be considered (i.e., without any trend analyses), simply choose
only cases from 2010 or 2015. If only reading or listening should be considered, choose the desired
domain by subsetting according to the <code>domain</code> column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lsa)</code></pre>


<h3>Format</h3>

<p>'data.frame':   77322 obs. of  25 variables
</p>

<dl>
<dt>year</dt><dd><p>Year of evaluation</p>
</dd>
<dt>idstud</dt><dd><p>individual student identification</p>
</dd>
<dt>idclass</dt><dd><p>class identifier</p>
</dd>
<dt>wgt</dt><dd><p>Total case weight</p>
</dd>
<dt>L2wgt</dt><dd><p>School weight (level 2 weight)</p>
</dd>
<dt>L1wgt</dt><dd><p>Student weight (level 1 weight)</p>
</dd>
<dt>jkzone</dt><dd><p>jackknifing zone (jk2) </p>
</dd>
<dt>jkrep</dt><dd><p>jackknife replicate</p>
</dd>
<dt>imp</dt><dd><p>Number of imputation</p>
</dd>
<dt>nest</dt><dd><p>Number of nest (for nested imputation only)</p>
</dd>
<dt>country</dt><dd><p>The country an examinee stems from</p>
</dd>
<dt>sex</dt><dd><p>student's sex</p>
</dd>
<dt>ses</dt><dd><p>student's socio-economical status</p>
</dd>
<dt>mig</dt><dd><p>student's migration background</p>
</dd>
<dt>domain</dt><dd><p>The domain the corresponding score belongs to</p>
</dd>
<dt>score</dt><dd><p>student's achievement score (corresponding to the domain reading or listening, and to the imputation 1, 2, or 3)</p>
</dd>
<dt>comp</dt><dd><p>student's competence level</p>
</dd>
<dt>failMin</dt><dd><p>dichotomous indicator whether the student fails to fulfill the minimal standard</p>
</dd>
<dt>passReg</dt><dd><p>dichotomous indicator whether the student fulfills at least the regular standard</p>
</dd>
<dt>passOpt</dt><dd><p>dichotomous indicator whether the student fulfills the optimal standard</p>
</dd>
<dt>leSore</dt><dd><p>linking error of each student's achievement score</p>
</dd>
<dt>leComp</dt><dd><p>linking error of each student's competence level</p>
</dd>
<dt>leFailMin</dt><dd><p>linking error of each student's indicator of failing to fulfill the minimal standard</p>
</dd>
<dt>lePassReg</dt><dd><p>linking error of each student's indicator of fulfilling the regular standard</p>
</dd>
<dt>lePassOpt</dt><dd><p>linking error of each student's indicator of fulfilling the optimal standard</p>
</dd>
</dl>



<h3>Source</h3>

<p>Simulated data</p>

<hr>
<h2 id='repGlm'>Replication methods (JK1, JK2 and BRR) for linear regression models and trend estimation.</h2><span id='topic+repGlm'></span><span id='topic+jk2.glm'></span>

<h3>Description</h3>

<p>Compute generalized linear models for complex cluster designs with multiple imputed variables based 
on the Jackknife (JK1, JK2) or balanced repeated replicates (BRR) procedure. Conceptually, the function combines replication 
methods and methods for multiple imputed data. Technically, this is a wrapper for the <code><a href="survey.html#topic+svyglm">svyglm</a></code> function
of the <code>survey</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repGlm(datL, ID, wgt = NULL, type = c("none", "JK2", "JK1", "BRR", "Fay"), PSU = NULL,
        repInd = NULL, repWgt = NULL, nest=NULL, imp=NULL, groups = NULL,
        group.splits = length(groups), group.delimiter = "_",
        cross.differences = FALSE, trend = NULL, linkErr = NULL, formula,
        family=gaussian, forceSingularityTreatment = FALSE,
        glmTransformation = c("none", "sdY"), doCheck = TRUE, na.rm = FALSE,
        poolMethod = c("mice", "scalar"), useWec = FALSE,
        scale = 1, rscales = 1, mse=TRUE, rho=NULL, hetero=TRUE,
        se_type = c("HC3", "HC0", "HC1", "HC2", "CR0", "CR2"),
        clusters = NULL, crossDiffSE.engine= c("lavaan", "lm"),
        stochasticGroupSizes = FALSE, verbose = TRUE, progress = TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repGlm_+3A_datl">datL</code></td>
<td>


<p>Data frame in the long format (i.e. each line represents one ID unit in one imputation of one nest) containing all 
variables for analysis.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_id">ID</code></td>
<td>


<p>Variable name or column number of student identifier (ID) variable. ID variable must not contain any missing values. 
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_wgt">wgt</code></td>
<td>


<p>Optional: Variable name or column number of weighting variable. If no weighting variable is specified,
all cases will be equally weighted.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_type">type</code></td>
<td>


<p>Defines the replication method for cluster replicates which is to be applied. Depending on <code>type</code>, additional
arguments must be specified (e.g., <code>PSU</code> and/or <code>repInd</code> or <code>repWgt</code>).
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_psu">PSU</code></td>
<td>


<p>Variable name or column number of variable indicating the primary sampling unit (PSU). When a jackknife procedure is applied, 
the PSU is the jackknife zone variable. If <code>NULL</code>, no cluster structure is assumed and
standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_repind">repInd</code></td>
<td>


<p>Variable name or column number of variable indicating replicate ID. In a jackknife procedure, this is the jackknife replicate 
variable. If <code>NULL</code>, no cluster structure is assumed and standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_repwgt">repWgt</code></td>
<td>


<p>Normally, replicate weights are created by <code>repGlm</code> directly from <code>PSU</code> and <code>repInd</code> variables. Alternatively,
if replicate weights are included in the data.frame, specify the variable names or column number in the <code>repWgt</code> argument.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_nest">nest</code></td>
<td>
<p>Optional: name or column number of the nesting variable. Only applies in nested multiple imputed data sets.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_imp">imp</code></td>
<td>
<p>Optional: name or column number of the imputation variable. Only applies in multiple imputed data sets.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_groups">groups</code></td>
<td>


<p>Optional: vector of names or column numbers of one or more grouping variables. 
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_group.splits">group.splits</code></td>
<td>


<p>Optional: If groups are defined, <code>group.splits</code> optionally specifies whether analysis should be done also
in the whole group or overlying groups. See examples for more details.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_group.delimiter">group.delimiter</code></td>
<td>


<p>Character string which separates the group names in the output frame.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_cross.differences">cross.differences</code></td>
<td>


<p>Either a list of vectors, specifying the pairs of levels for which cross-level differences should be computed.
Alternatively, if <code>TRUE</code>, cross-level differences for all pairs of levels are computed. If <code>FALSE</code>, no cross-level
differences are computed. (see examples 2a, 3, and 4 in the help file of the <code>repMean</code> function)
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_trend">trend</code></td>
<td>


<p>Optional: name or column number of the trend variable. Note: Trend variable must have exact two levels. Levels for 
grouping variables must be equal in both 'sub populations' partitioned by the trend variable. 
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_linkerr">linkErr</code></td>
<td>


<p>Optional: name or column number of the linking error variable. If <code>NULL</code>, a linking error of 0 will be assumed in trend estimation.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_formula">formula</code></td>
<td>


<p>Model formula, see help page of <code>glm</code> for details. 
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_family">family</code></td>
<td>


<p>A description of the error distribution and link function to be used in the model. See help page of <code>glm</code> for details. 
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_forcesingularitytreatment">forceSingularityTreatment</code></td>
<td>


<p>Logical: Forces the function to use the workaround to handle singularities in regression models.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_glmtransformation">glmTransformation</code></td>
<td>

<p>Optional: Allows for transformation of parameters from linear regression and logistic regression before pooling.
Useful to compare parameters from different glm models, see Mood (2010). Note: This argument applies only if 
<code>forceSingularityTreatment</code> is set to 'TRUE'.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_docheck">doCheck</code></td>
<td>

<p>Logical: Check the data for consistency before analysis? If <code>TRUE</code> groups with insufficient data are excluded from
analysis to prevent subsequent functions from crashing.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_na.rm">na.rm</code></td>
<td>

<p>Logical: Should cases with missing values be dropped?
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_poolmethod">poolMethod</code></td>
<td>

<p>Which pooling method should be used? The &ldquo;mice&rdquo; method is recommended.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_usewec">useWec</code></td>
<td>

<p>Logical: use weighted effect coding? 
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_scale">scale</code></td>
<td>

<p>scaling constant for variance, for details, see help page of <code>svrepdesign</code> from the <code>survey</code> package
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_rscales">rscales</code></td>
<td>

<p>scaling constant for variance, for details, see help page of <code>svrepdesign</code> from the <code>survey</code> package
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_mse">mse</code></td>
<td>

<p>Logical: If <code>TRUE</code>, compute variances based on sum of squares around the point estimate, rather than the mean of the replicates.
See help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_rho">rho</code></td>
<td>

<p>Shrinkage factor for weights in Fay's method. See help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_hetero">hetero</code></td>
<td>

<p>Logical: Assume heteroscedastic variance for weighted effect coding? Only applies for random samples, i.e. if no replication analyses are executed. 
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_se_type">se_type</code></td>
<td>

<p>The sort of standard error sought for cross level differences. Only applies if <code>crossDiffSE == "wec"</code> and <code>hetero == TRUE</code>
and <code>crossDiffSE.engine == "lm"</code>. See the help page of <code><a href="estimatr.html#topic+lm_robust">lm_robust</a></code> from the <code>estimatr</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_clusters">clusters</code></td>
<td>

<p>Optional: Variable name or column number of cluster variable. Only necessary if weighted effecting coding
should be performed using heteroscedastic variances. See the help page of <code><a href="estimatr.html#topic+lm_robust">lm_robust</a></code>
from the <code>estimatr</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_crossdiffse.engine">crossDiffSE.engine</code></td>
<td>

<p>Optional: Sort of estimator which should be used for standard error estimation in weighted effect coding regression.
Only applies if <code>useWec == TRUE</code>. To date, only lavaan allows for stochastic group sizes.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_stochasticgroupsizes">stochasticGroupSizes</code></td>
<td>

<p>Logical: Assume stochastic group sizes for using weighted effect coding regression with categorical predictors? Note: To date,
only lavaan allows for stochastic group sizes. Stochastic group sizes cannot be assumed if any replication method
(jackknife, BRR) is applied.
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_verbose">verbose</code></td>
<td>

<p>Logical: Show analysis information on console?
</p>
</td></tr>
<tr><td><code id="repGlm_+3A_progress">progress</code></td>
<td>

<p>Logical: Show progress bar on console?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function first creates replicate weights based on <code>PSU</code> and <code>repInd</code> variables according to JK2 or
BRR procedure. According to multiple imputed data sets, a workbook with several analyses is created.
The function afterwards serves as a wrapper for <code><a href="survey.html#topic+svyglm">svyglm</a></code> implemented in the <code>survey</code> package.
The results of the several analyses are then pooled according to Rubin's rule, which is adapted for nested 
imputations if the <code>nest</code> argument implies a nested structure.
</p>


<h3>Value</h3>

<p>A list of data frames in the long format. The output can be summarized using the <code>report</code> function.
The first element of the list is a list with either one (no trend analyses) or two (trend analyses)
data frames with at least six columns each. For each subpopulation denoted by the <code>groups</code>
statement, each dependent variable, each parameter and each coefficient the corresponding value is given. 
</p>
<table>
<tr><td><code>group</code></td>
<td>
<p>Denotes the group an analysis belongs to. If no groups were specified and/or analysis for the 
whole sample were requested, the value of &lsquo;group&rsquo; is &lsquo;wholeGroup&rsquo;.</p>
</td></tr>
<tr><td><code>depVar</code></td>
<td>
<p>Denotes the name of the dependent variable in the analysis. </p>
</td></tr>
<tr><td><code>modus</code></td>
<td>
<p>Denotes the mode of the analysis. For example, if a JK2 analysis without sampling weights was 
conducted, &lsquo;modus&rsquo; takes the value &lsquo;jk2.unweighted&rsquo;. If a analysis without any replicates but with sampling
weights was conducted, &lsquo;modus&rsquo; takes the value &lsquo;weighted&rsquo;.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Denotes the parameter of the regression model for which the corresponding value is given
further. Amongst others, the &lsquo;parameter&rsquo; column takes the values &lsquo;(Intercept)&rsquo; and &lsquo;gendermale&rsquo; if &lsquo;gender&rsquo; 
was the dependent variable, for instance. See example 1 for further details.</p>
</td></tr>
<tr><td><code>coefficient</code></td>
<td>
<p>Denotes the coefficient for which the corresponding value is given further. Takes the 
values &lsquo;est&rsquo; (estimate) and &lsquo;se&rsquo; (standard error of the estimate).</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of the parameter estimate in the corresponding group.</p>
</td></tr>
</table>
<p>If groups were specified, further columns which are denoted by the group names are added to the data frame. 
</p>


<h3>References</h3>

<p>te Grotenhuis, M., Pelzer, B., Eisinga, R., Nieuwenhuis, R., Schmidt-Catran, A., &amp; Konig, R. (2017).
When size matters: advantages of weighted effect coding in observational studies. <em>International Journal of Public Health.</em> <b>62</b>, 163&ndash;167.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load example data (long format)
data(lsa)
### use only the first nest
bt         &lt;- lsa[which(lsa[,"nest"] == 1),]
### use only data from 2010
bt2010     &lt;- bt[which(bt[,"year"] == 2010),]
## use only reading data
bt2010read &lt;- bt2010[which(bt2010[,"domain"] == "reading"),]

### Example 1: Computes linear regression from reading score on gender separately
### for each country. Assume no nested structure.
mod1 &lt;- repGlm(datL = bt2010read, ID = "idstud", wgt = "wgt", type = "jk2",
        PSU = "jkzone", repInd = "jkrep", imp = "imp", groups = "country",
        formula = score~sex, family ="gaussian")
res1 &lt;- report(mod1, printGlm = TRUE)


### Example 2: Computes log linear regression from pass/fail on ses and gender
### separately for each country in a nested structure. Assuming equally weighted
### cases by omitting "wgt" argument
dat  &lt;- lsa[intersect(which(lsa[,"year"] == 2010), which(lsa[,"domain"] == "reading")),]
mod2 &lt;- repGlm(datL = dat, ID = "idstud", type = "JK2",  PSU = "jkzone",
        repInd = "jkrep", imp = "imp", nest="nest", groups = "country",
        formula = passReg~sex*ses, family = quasibinomial(link="logit"))
res2 &lt;- report(mod2, printGlm = TRUE)

### Example 3: Like example 1, but without any replication methods
### trend estimation (without linking error) and nested imputation
dat  &lt;- lsa[which(lsa[,"domain"] == "reading"),]
mod3 &lt;- repGlm(datL = dat, ID = "idstud", wgt = "wgt", imp = "imp", nest = "nest",
        groups = "country",  formula = score~sex, trend = "year")
res3 &lt;- report(mod3, printGlm = TRUE)

### Example 4: weighted effect coding to estimate whether a specific country's mean
### differs from the overall mean (whereas the overall population is a composite of 
### all countries). The procedure adapts the weighted effect coding procedures 
### described in te Grotenhuis (2017) for multiple imputation and replication methods. 
mod4 &lt;- repGlm(datL = bt2010read, ID = "idstud", wgt = "wgt", type = "jk2",
        PSU = "jkzone", repInd = "jkrep", imp = "imp", formula = score~country,
        useWec=TRUE)
res4 &lt;- report(mod4, printGlm = FALSE)
</code></pre>

<hr>
<h2 id='repLmer'>Replication methods (JK1 and JK2) for multilevel linear regression models and trend estimation.</h2><span id='topic+repLmer'></span>

<h3>Description</h3>

<p>Compute multilevel linear models for complex cluster designs with multiple imputed variables based
on the Jackknife (JK1, JK2) procedure. Conceptually, the function combines replication
methods and methods for multiple imputed data. Technically, this is a wrapper for the <code><a href="BIFIEsurvey.html#topic+BIFIE.twolevelreg">BIFIE.twolevelreg</a></code> function
of the <code>BIFIEsurvey</code> package. <code>repLmer</code> only adds functionality for trend estimation. Please note
that the function is not suitable for logistic logit/probit models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repLmer(datL, ID, wgt = NULL, L1wgt=NULL, L2wgt=NULL, type = c("JK2", "JK1"),
            PSU = NULL, repInd = NULL, jkfac = NULL, rho = NULL, imp=NULL,
            group = NULL, trend = NULL, dependent, formula.fixed, formula.random,
            doCheck = TRUE, na.rm = FALSE, clusters, verbose = TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repLmer_+3A_datl">datL</code></td>
<td>

<p>Data frame in the long format (i.e. each line represents one ID unit in one imputation of one nest) containing all
variables for analysis.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_id">ID</code></td>
<td>

<p>Variable name or column number of student identifier (ID) variable. ID variable must not contain any missing values.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_wgt">wgt</code></td>
<td>

<p>Optional: Variable name or column number of case weighting variable. If no weighting variable is specified,
all cases will be equally weighted.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_l1wgt">L1wgt</code></td>
<td>

<p>Name of Level 1 weight variable. This is optional. If it is not provided, <code>L1wgt</code> is calculated from the
total weight (i.e., <code>wgt</code>) and <code>L2wgt</code>.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_l2wgt">L2wgt</code></td>
<td>

<p>Name of Level 2 weight variable
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_type">type</code></td>
<td>

<p>Defines the replication method for cluster replicates which is to be applied. Depending on <code>type</code>, additional
arguments must be specified (e.g., <code>PSU</code> and/or <code>repInd</code> or <code>repWgt</code>).
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_psu">PSU</code></td>
<td>


<p>Variable name or column number of variable indicating the primary sampling unit (PSU). When a jackknife procedure is applied,
the PSU is the jackknife zone variable. If <code>NULL</code>, no cluster structure is assumed and
standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_repind">repInd</code></td>
<td>


<p>Variable name or column number of variable indicating replicate ID. In a jackknife procedure, this is the jackknife replicate
variable. If <code>NULL</code>, no cluster structure is assumed and standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_jkfac">jkfac</code></td>
<td>

<p>Argument is passed to <code><a href="BIFIEsurvey.html#topic+BIFIE.data.jack">BIFIE.data.jack</a></code> and specifies the factor for multiplying jackknife replicate
weights.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_rho">rho</code></td>
<td>

<p>Fay factor for statistical inference. The argument is passed to the <code>fayfac</code> argument of the
<code><a href="BIFIEsurvey.html#topic+BIFIE.data.jack">BIFIE.data.jack</a></code> function from the <code>BIFIEsurvey</code> package. See the
corresponding help page for further details. For convenience, if <code>rho = NULL</code> (the default)
and <code>type = "JK1"</code>, <code><a href="BIFIEsurvey.html#topic+BIFIE.data.jack">BIFIE.data.jack</a></code> is called with
<code>jktype="JK_GROUP"</code> and <code>fayfac = rho</code>, where <code class="reqn">\rho = (N_{cluster} - 1) \times N_{cluster}^{-1}</code>
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_imp">imp</code></td>
<td>
<p>Name or column number of the imputation variable.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_group">group</code></td>
<td>


<p>Optional: column number or name of one grouping variable. Note: in contrast to <code>repMean</code>, only one grouping variable can be specified.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_trend">trend</code></td>
<td>

<p>Optional: name or column number of the trend variable. Note: Trend variable must have exact two levels. Levels for
grouping variables must be equal in both 'sub populations' partitioned by the trend variable.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_dependent">dependent</code></td>
<td>

<p>Name or column number of the dependent variable
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_formula.fixed">formula.fixed</code></td>
<td>

<p>An R formula for fixed effects
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_formula.random">formula.random</code></td>
<td>

<p>An R formula for random effects
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_docheck">doCheck</code></td>
<td>

<p>Logical: Check the data for consistency before analysis? If <code>TRUE</code> groups with insufficient data are excluded from
analysis to prevent subsequent functions from crashing.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_na.rm">na.rm</code></td>
<td>

<p>Logical: Should cases with missing values be dropped?
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_clusters">clusters</code></td>
<td>

<p>Variable name or column number of cluster variable.
</p>
</td></tr>
<tr><td><code id="repLmer_+3A_verbose">verbose</code></td>
<td>

<p>Logical: Show analysis information on console?
</p>
</td></tr>
</table>


<h3>Value</h3>






<p>A list of data frames in the long format. The output can be summarized using the <code>report</code> function.
The first element of the list is a list with either one (no trend analyses) or two (trend analyses)
data frames with at least six columns each. For each subpopulation denoted by the <code>groups</code>
statement, each dependent variable, each parameter and each coefficient the corresponding value is given. 
</p>
<table>
<tr><td><code>group</code></td>
<td>
<p>Denotes the group an analysis belongs to. If no groups were specified and/or analysis for the 
whole sample were requested, the value of &lsquo;group&rsquo; is &lsquo;wholeGroup&rsquo;.</p>
</td></tr>
<tr><td><code>depVar</code></td>
<td>
<p>Denotes the name of the dependent variable in the analysis. </p>
</td></tr>
<tr><td><code>modus</code></td>
<td>
<p>Denotes the mode of the analysis. For example, if a JK2 analysis without sampling weights was 
conducted, &lsquo;modus&rsquo; takes the value &lsquo;jk2.unweighted&rsquo;. If a analysis without any replicates but with sampling
weights was conducted, &lsquo;modus&rsquo; takes the value &lsquo;weighted&rsquo;.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Denotes the parameter of the regression model for which the corresponding value is given
further. Amongst others, the &lsquo;parameter&rsquo; column takes the values &lsquo;(Intercept)&rsquo; and &lsquo;gendermale&rsquo; if &lsquo;gender&rsquo; 
was the dependent variable, for instance. See example 1 for further details.</p>
</td></tr>
<tr><td><code>coefficient</code></td>
<td>
<p>Denotes the coefficient for which the corresponding value is given further. Takes the 
values &lsquo;est&rsquo; (estimate) and &lsquo;se&rsquo; (standard error of the estimate).</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of the parameter estimate in the corresponding group.</p>
</td></tr>
</table>
<p>If groups were specified, further columns which are denoted by the group names are added to the data frame. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load example data (long format)
data(lsa)
### use only the first nest, use only reading
btRead &lt;- subset(lsa, nest==1 &amp; domain=="reading")


### random intercept model with groups
mod1 &lt;- repLmer(datL = btRead, ID = "idstud", wgt = "wgt", L1wgt="L1wgt", L2wgt="L2wgt",
        type = "jk2", PSU = "jkzone", repInd = "jkrep", imp = "imp",trend="year",
        group="country", dependent="score", formula.fixed = ~as.factor(sex)+mig,
        formula.random=~1, clusters="idclass")
res1 &lt;- report(mod1)

### random slope without groups and without trend
mod2 &lt;- repLmer(datL = subset(btRead, country=="countryA" &amp; year== 2010),
        ID = "idstud", wgt = "wgt", L1wgt="L1wgt", L2wgt="L2wgt", type = "jk2",
        PSU = "jkzone", repInd = "jkrep", imp = "imp", dependent="score",
        formula.fixed = ~as.factor(sex)*mig, formula.random=~mig, clusters="idclass")
res2 &lt;- report(mod2)
</code></pre>

<hr>
<h2 id='repMean'>Replication methods (JK1, JK2 and BRR) for descriptive statistics.</h2><span id='topic+repMean'></span><span id='topic+jk2.mean'></span>

<h3>Description</h3>

<p>Compute totals, means, adjusted means, mean differences, variances and standard deviations
with standard errors in random or clustered or complex samples. Variance estimation in complex cluster
designs based on Jackknife (JK1, JK2) or Balanced Repeated Replicates (BRR) procedure. Moreover, analyses
can be customized for multiple or nested imputed variables, applying the combination rules of Rubin (1987)
for imputed data and Rubin (2003) for nested imputed data. Conceptually, the function combines replication
methods and methods for multiple imputed data. Trend estimation as usual in large-scale assessments is supported as well.
Technically, this is a wrapper for the <code><a href="survey.html#topic+svymean">svymean</a></code> and <code><a href="survey.html#topic+svyvar">svyvar</a></code> functions of the <code>survey</code> package.</p>


<h3>Usage</h3>

<pre><code class='language-R'>repMean (datL, ID, wgt = NULL, type = c("none", "JK2", "JK1", "BRR", "Fay"), PSU = NULL,
         repInd = NULL, jkfac=NULL, repWgt = NULL, nest=NULL, imp=NULL, groups = NULL,
         group.splits = length(groups), group.differences.by = NULL,
         cross.differences = FALSE, crossDiffSE = c("wec", "rep","old"),
         adjust = NULL, useEffectLiteR = FALSE, nBoot = 100, group.delimiter = "_",
         trend = NULL, linkErr = NULL, dependent, na.rm = FALSE, doCheck = TRUE,
         engine = c("survey", "BIFIEsurvey"), scale = 1, rscales = 1, mse=TRUE,
         rho=NULL, hetero=TRUE, se_type = c("HC3", "HC0", "HC1", "HC2", "CR0", "CR2"),
         clusters = NULL, crossDiffSE.engine= c("lavaan", "lm"),
         stochasticGroupSizes = FALSE, verbose = TRUE, progress = TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repMean_+3A_datl">datL</code></td>
<td>

<p>Data frame in the long format (i.e. each line represents one ID unit in one imputation of one nest) containing all
variables for analysis.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_id">ID</code></td>
<td>

<p>Variable name or column number of student identifier (ID) variable. ID variable must not contain any missing values.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_wgt">wgt</code></td>
<td>

<p>Optional: Variable name or column number of weighting variable. If no weighting variable is specified,
all cases will be equally weighted.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_type">type</code></td>
<td>

<p>Defines the replication method for cluster replicates which is to be applied. Depending on <code>type</code>, additional
arguments must be specified (e.g., <code>PSU</code> and/or <code>repInd</code> or <code>repWgt</code>).
</p>
</td></tr>
<tr><td><code id="repMean_+3A_psu">PSU</code></td>
<td>

<p>Variable name or column number of variable indicating the primary sampling unit (PSU). When a jackknife procedure is applied,
the PSU is the jackknife zone variable. If <code>NULL</code>, no cluster structure is assumed and
standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_repind">repInd</code></td>
<td>

<p>Variable name or column number of variable indicating replicate ID. In a jackknife procedure, this is the jackknife replicate
variable. If <code>NULL</code>, no cluster structure is assumed and standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_jkfac">jkfac</code></td>
<td>

<p>Only applies if <code>engine = "BIFIEsurvey"</code>. Argument is passed to <code><a href="BIFIEsurvey.html#topic+BIFIE.data.jack">BIFIE.data.jack</a></code> and specifies
the factor for multiplying jackknife replicate weights.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_repwgt">repWgt</code></td>
<td>

<p>Normally, replicate weights are created by <code>repMean</code> directly from <code>PSU</code> and <code>repInd</code> variables. Alternatively,
if replicate weights are included in the data.frame, specify the variable names or column number in the <code>repWgt</code> argument.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_nest">nest</code></td>
<td>
<p>Optional: name or column number of the nesting variable. Only applies in nested multiple imputed data sets.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_imp">imp</code></td>
<td>
<p>Optional: name or column number of the imputation variable. Only applies in multiple imputed data sets.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_groups">groups</code></td>
<td>

<p>Optional: vector of names or column numbers of one or more grouping variables.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_group.splits">group.splits</code></td>
<td>

<p>Optional: If groups are defined, <code>group.splits</code> optionally specifies whether analysis should be done also
in the whole group or overlying groups. See examples for more details.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_group.differences.by">group.differences.by</code></td>
<td>

<p>Optional: Specifies variable group differences should be computed for. The corresponding variable must be included in
the <code>groups</code> statement. Exception: choose 'wholePop' if you want to estimate each's group difference from the
overall sample mean. See examples for further details.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_cross.differences">cross.differences</code></td>
<td>

<p>Either a list of vectors, specifying the pairs of levels for which cross-level differences should be computed.
Alternatively, if <code>TRUE</code>, cross-level differences for all pairs of levels are computed. If <code>FALSE</code>, no cross-level
differences are computed. (see example 2a, 3, and 4)
</p>
</td></tr>
<tr><td><code id="repMean_+3A_crossdiffse">crossDiffSE</code></td>
<td>

<p>Method for standard error estimation for cross level differences, where groups are dependent.
<code>wec</code> uses weighted effect coding, <code>rep</code> uses replication methods (bootstrap or jackknife) to
estimate the standard error between the total mean and group-specific means. <code>old</code> does not account for dependent
groups and treat the groups as if they were independent from each other.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_adjust">adjust</code></td>
<td>

<p>Variable name or column number of variable(s) for which adjusted means should be computed. Non-numeric variables (factors) will
be converted to 0/1 dichotomous variables.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_useeffectliter">useEffectLiteR</code></td>
<td>

<p>Logical: use the <code>lavaan</code>-wrapper <code>EffectLiteR</code> to compute adjusted means? Alternatively, adjusted means
are computed by applying a simple linear regression model in each group, using the variables in <code>adjust</code> as
independent variables. Afterwards, the coefficients are weighted with the (weighted) means of the independent
variables. Standard errors for this procedure are received using the delta method by applying an augmented
variance-covariance matrix which assumes zero covariances between independent variable means and regression
coefficients. We recommend to set <code>useEffectLiteR = TRUE</code> if no replication methods are applied. When
replication methods are used (jackknife-1, jackknife-2, BRR), we recommend to set <code>useEffectLiteR = FALSE</code>,
because otherwise the estimation is very slow.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_nboot">nBoot</code></td>
<td>

<p>Without replicates (i.e., for completely random samples), the <code>rep</code> method for standard error estimation for
cross level differences needs a bootstrap. <code>nBoot</code> therefore specifies the number of bootstrap samples.
This argument is only necessary, if <code>crossDiffSE = "rep"</code> <em>and</em> none of the replicate methods
(JK1, JK2, or BRR) is applied. Otherwise, <code>nBoot</code> will be ignored.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_group.delimiter">group.delimiter</code></td>
<td>

<p>Character string which separates the group names in the output frame.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_trend">trend</code></td>
<td>

<p>Optional: name or column number of the trend variable. Note: Trend variable must have exact two levels. Levels for
grouping variables must be equal in both 'sub populations' partitioned by the trend variable.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_linkerr">linkErr</code></td>
<td>

<p>Optional: Either the name or column number of the linking error variable. If <code>NULL</code>, a linking error of 0 will be assumed in trend estimation.
Alternatively, linking errors may be
given as <code>data.frame</code> with following specifications: Two columns, named <code>trendLevel1</code> and <code>trendLevel2</code> which contain the
levels of the trend variable. The contrasts between both values indicates which trend is meant. For only two measurement occasions, i.e.
2010 and 2015, <code>trendLevel1</code> should be <code>2010</code>, and <code>trendLevel2</code> should be <code>2015</code>. For three measurement occasions,
i.e. 2010, 2015, and 2020, additional lines are necessary where <code>trendLevel1</code> should be <code>2010</code>, and <code>trendLevel2</code> should be
<code>2020</code>, to mark the contrast between 2010 and 2020, and further additional lines are necessary where <code>trendLevel1</code> should be
<code>2015</code>, and <code>trendLevel2</code> should be <code>2020</code>. The column <code>depVar</code> must include the name of the dependent variable. This
string must correspond to the name of the dependent variable in the data. The column <code>parameter</code> indicates the parameter the linking
error belongs to. Column <code>linkingError</code> includes the linking error value. Providing linking error in a data.frame is necessary for
more than two measurement occasions. See the example 3a for further details.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_dependent">dependent</code></td>
<td>

<p>Variable name or column number of the dependent variable.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_na.rm">na.rm</code></td>
<td>

<p>Logical: Should cases with missing values be dropped?
</p>
</td></tr>
<tr><td><code id="repMean_+3A_docheck">doCheck</code></td>
<td>

<p>Logical: Check the data for consistency before analysis? If <code>TRUE</code> groups with insufficient data are excluded from
analysis to prevent subsequent functions from crashing.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_engine">engine</code></td>
<td>

<p>Which package should be used for estimation?
</p>
</td></tr>
<tr><td><code id="repMean_+3A_scale">scale</code></td>
<td>

<p>scaling constant for variance, for details, see help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package
</p>
</td></tr>
<tr><td><code id="repMean_+3A_rscales">rscales</code></td>
<td>

<p>scaling constant for variance, for details, see help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package
</p>
</td></tr>
<tr><td><code id="repMean_+3A_mse">mse</code></td>
<td>

<p>Logical: If <code>TRUE</code>, compute variances based on sum of squares around the point estimate, rather than the mean of the replicates.
See help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_rho">rho</code></td>
<td>

<p>Shrinkage factor for weights in Fay's method. If <code>engine = "survey"</code>, argument is passed to the <code>rho</code> argument of
the <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> function from the <code>survey</code> package. See the corresponding help page for further
details. If <code>engine = "BIFIEsurvey"</code>, argument is passed to the <code>fayfac</code> argument of the
<code><a href="BIFIEsurvey.html#topic+BIFIE.data.jack">BIFIE.data.jack</a></code> function from the <code>BIFIEsurvey</code> package. See the
corresponding help page for further details. For convenience, if <code>rho = NULL</code> (the default)
and <code>engine = "BIFIEsurvey"</code> and <code>type = "JK1"</code>, <code><a href="BIFIEsurvey.html#topic+BIFIE.data.jack">BIFIE.data.jack</a></code>
is called with <code>jktype="JK_GROUP"</code> and <code>fayfac = rho</code>, where <code class="reqn">\rho = (N_{cluster} - 1) \times N_{cluster}^{-1}</code>
</p>
</td></tr>
<tr><td><code id="repMean_+3A_hetero">hetero</code></td>
<td>

<p>Logical: Assume heteroscedastic variance for weighted effect coding?
</p>
</td></tr>
<tr><td><code id="repMean_+3A_se_type">se_type</code></td>
<td>

<p>The sort of standard error sought for cross level differences. Only applies if <code>crossDiffSE == "wec"</code> and <code>hetero == TRUE</code>
and <code>crossDiffSE.engine == "lm"</code>. See the help page of <code><a href="estimatr.html#topic+lm_robust">lm_robust</a></code> from the <code>estimatr</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_clusters">clusters</code></td>
<td>

<p>Optional: Variable name or column number of cluster variable. Only necessary if weighted effecting coding
should be performed using heteroscedastic variances. See the help page of <code><a href="estimatr.html#topic+lm_robust">lm_robust</a></code>
from the <code>estimatr</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_crossdiffse.engine">crossDiffSE.engine</code></td>
<td>

<p>Software implementation used for estimating cross-level differences. Choices are either <code>"lavaan"</code> (required if
<code>stochasticGroupSites == "TRUE"</code>) or R function <code><a href="stats.html#topic+lm">lm</a></code>. <code>"lavaan"</code> is the default.
</p>
</td></tr>
<tr><td><code id="repMean_+3A_stochasticgroupsizes">stochasticGroupSizes</code></td>
<td>

<p>Logical: Assume stochastic group sizes for using weighted effect coding in cross-level differences? Note: To date,
only <code>crossDiffSE.engine = "lavaan"</code> allows for stochastic group sizes. Stochastic group sizes are not yet
implemented for any replication method (jackknife, BRR).
</p>
</td></tr>
<tr><td><code id="repMean_+3A_verbose">verbose</code></td>
<td>

<p>Logical: Show analysis information on console?
</p>
</td></tr>
<tr><td><code id="repMean_+3A_progress">progress</code></td>
<td>

<p>Logical: Show progress bar on console?
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Function first creates replicate weights based on PSU and repInd variables (if defined) according to JK2 or BRR procedure
as implemented in WesVar. According to multiple imputed data sets, a workbook with several analyses is created.
The function afterwards serves as a wrapper for <code><a href="survey.html#topic+svymean">svymean</a></code> called by <code><a href="survey.html#topic+svyby">svyby</a></code> implemented in
the &lsquo;survey&rsquo; package. The results of the several analyses are then pooled according to Rubin's rule.
</p>


<h3>Value</h3>






<p>A list of data frames in the long format. The output can be summarized using the <code>report</code> function.
The first element of the list is a list with either one (no trend analyses) or two (trend analyses)
data frames with at least six columns each. For each subpopulation denoted by the <code>groups</code>
statement, each parameter (i.e., mean, variance, or group differences) and each coefficient (i.e., the estimate 
and the corresponding standard error) the corresponding value is given.
</p>
<table>
<tr><td><code>group</code></td>
<td>
<p>Denotes the group an analysis belongs to. If no groups were specified and/or analysis for the 
whole sample were requested, the value of &lsquo;group&rsquo; is &lsquo;wholeGroup&rsquo;.</p>
</td></tr>
<tr><td><code>depVar</code></td>
<td>
<p>Denotes the name of the dependent variable in the analysis. </p>
</td></tr>
<tr><td><code>modus</code></td>
<td>
<p>Denotes the mode of the analysis. For example, if a JK2 analysis without sampling weights was 
conducted, &lsquo;modus&rsquo; takes the value &lsquo;jk2.unweighted&rsquo;. If a analysis without any replicates but with sampling
weights was conducted, &lsquo;modus&rsquo; takes the value &lsquo;weighted&rsquo;.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Denotes the parameter of the regression model for which the corresponding value is given
further. Amongst others, the &lsquo;parameter&rsquo; column takes the values &lsquo;mean&rsquo;, &lsquo;sd&rsquo;, &lsquo;var&rsquo; and &lsquo;meanGroupDiff&rsquo; if 
group differences were requested.</p>
</td></tr>
<tr><td><code>coefficient</code></td>
<td>
<p>Denotes the coefficient for which the corresponding value is given further. Takes the 
values &lsquo;est&rsquo; (estimate) and &lsquo;se&rsquo; (standard error of the estimate).</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of the parameter estimate in the corresponding group.</p>
</td></tr>
</table>
<p>If groups were specified, further columns which are denoted by the group names are added to the data frame. 
</p>


<h3>References</h3>

<p>te Grotenhuis, M., Pelzer, B., Eisinga, R., Nieuwenhuis, R., Schmidt-Catran, A., &amp; Konig, R. (2017).
When size matters: advantages of weighted effect coding in observational studies. <em>International Journal of Public Health.</em> <b>62</b>, 163&ndash;167.
</p>
<p>Sachse, K. A. &amp; Haag, N. (2017). Standard errors for national trends in international
large-scale assessments in the case of cross-national differential item functioning. <em>Applied
Measurement in Education, 30</em>, (2), 102-116. http://dx.doi.org/10.1080/08957347.2017.1283315
</p>
<p>Weirich, S., Hecht, M., Becker, B. et al. Comparing group means with the total mean in random samples,
surveys, and large-scale assessments: A tutorial and software illustration. Behav Res (2021).
https://doi.org/10.3758/s13428-021-01553-1
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lsa)

### Example 1: only means, SD and variances for each country
### We only consider domain 'reading'
rd     &lt;- lsa[which(lsa[,"domain"] == "reading"),]

### We only consider the first "nest".
rdN1   &lt;- rd[which(rd[,"nest"] == 1),]

### First, we only consider year 2010
rdN1y10&lt;- rdN1[which(rdN1[,"year"] == 2010),]

### mean estimation
means1 &lt;- repMean(datL = rdN1y10, ID="idstud", wgt="wgt", type = "JK2", PSU = "jkzone",
          repInd = "jkrep", imp="imp", groups = "country", dependent = "score",
          na.rm=FALSE, doCheck=TRUE, engine = "BIFIEsurvey")
### reporting function: the function does not know which content domain is being considered,
### so the user may add new columns in the output using the 'add' argument
res1   &lt;- report(means1, add = list(domain = "reading"))


### Example 1a: Additionally to example 1, we decide to estimate whether
### each country's mean differ significantly from the overall mean as well
### as from the individual means of the other contries
means1a&lt;- repMean(datL = rdN1y10, ID="idstud", wgt="wgt", type = "JK2", PSU = "jkzone",
          repInd = "jkrep", imp="imp", groups = "country", group.splits = 0:1,
          group.differences.by = "country", cross.differences = TRUE,
          dependent = "score", na.rm=FALSE, doCheck=TRUE, hetero=FALSE)
res1a  &lt;- report(means1a, add = list(domain = "reading"))

### See that the means of 'countryA' and 'countryB' significantly differ from the overall mean.
print(res1a[intersect(which(res1a[,"comparison"] == "crossDiff"),
      which(res1a[,"parameter"] == "mean")),], digits = 3)

### Example 2: Sex differences by country. Assume equally weighted cases by omitting
### 'wgt' argument.
means2 &lt;- repMean(datL = rdN1y10, ID="idstud", type = "JK2", PSU = "jkzone",
          repInd = "jkrep", imp="imp", groups = c("country", "sex"), group.splits = 0:2,
          group.differences.by="sex", dependent = "score", na.rm=FALSE, doCheck=TRUE,
          cross.differences =TRUE, crossDiffSE.engine= "lm")
res2   &lt;- report(means2,add = list(domain = "reading"))

### Example 2a: Additionally to example 2, we decide to estimate whether
### each country's mean differ significantly from the overall mean. (Note: by default,
### such cross level differences are estimated using 'weighted effect coding'. Use the
### 'crossDiffSE' argument to choose alternative methods.) Moreover, we estimate whether
### each country's sex difference differ significantly from the sex difference in the
### whole population.
means2a&lt;- repMean(datL = rdN1y10, ID="idstud", wgt="wgt", type = "JK2", PSU = "jkzone",
          repInd = "jkrep", imp="imp", groups = c("country", "sex"), group.splits = 0:2,
          group.differences.by="sex", cross.differences = list(c(0,1), c(0,2)),
          dependent = "score", na.rm=FALSE, doCheck=TRUE,
          crossDiffSE.engine= "lm", clusters = "idclass")
res2a  &lt;- report(means2a,add = list(domain = "reading"), trendDiffs = TRUE)

### Third example: like example 2a, but using nested imputations of dependent variable,
### and additionally estimating trend: use 'rd' instead of 'rdN1y10'
### assume equally weighted cases by omitting 'wgt' argument
### ignoring jackknife by omitting 'type', 'PSU' and 'repInd' argument
means3T&lt;- repMean(datL = rd, ID="idstud", imp="imp", nest="nest",
          groups = c("country", "sex"), group.splits = 0:2, group.differences.by="sex",
          cross.differences = list(c(0,1), c(0,2)), dependent = "score", na.rm=FALSE,
          doCheck=TRUE, trend = "year", linkErr = "leScore",
          crossDiffSE = "wec", crossDiffSE.engine= "lavaan")
res3T  &lt;- report(means3T, add = list(domain = "reading"))

### Example 3a: like example 3, but providing linking errors in an additional data.frame
### This is optional for two measurement occasions but mandatory if the analysis contains
### more than two measurement occasions
linkErr&lt;- data.frame ( trendLevel1 = 2010, trendLevel2 = 2015,  depVar = "score",
          parameter = "mean", unique(lsa[,c("domain", "leScore")]),
          stringsAsFactors = FALSE)
colnames(linkErr) &lt;- car::recode(colnames(linkErr), "'leScore'='linkingError'")
### note that the linking errors for the specified domain have to be chosen via
### subsetting
means3a&lt;- repMean(datL = rd, ID="idstud", imp="imp", nest="nest",
          groups = c("country", "sex"),
          group.splits = 0:2, group.differences.by="sex",
          cross.differences = list(c(0,1), c(0,2)),
          dependent = "score", na.rm=FALSE, doCheck=TRUE, trend = "year",
          linkErr = linkErr[which(linkErr[,"domain"] == "reading"),],
          crossDiffSE = "wec", crossDiffSE.engine= "lavaan")
res3a  &lt;- report(means3a, add = list(domain = "reading"))

### Fourth example: using a loop do analyse 'reading' and 'listening' comprehension
### in one function call. Again with group and cross differences and trends, and
### trend differences
### we use weights but omit jackknife analysis by omitting 'type', 'PSU' and 'repInd'
### argument
means4T&lt;- by ( data = lsa, INDICES = lsa[,"domain"], FUN = function (sub.dat) {
          repMean(datL = sub.dat, ID="idstud", wgt="wgt", imp="imp", nest="nest",
                 groups = c("country", "sex"), group.splits = 0:2,
                 group.differences.by="sex",
                 cross.differences = list(c(0,1), c(0,2)), dependent = "score",
                 na.rm=FALSE, doCheck=TRUE,
                 trend = "year", linkErr = "leScore", crossDiffSE.engine= "lm") })
ret4T  &lt;- do.call("rbind", lapply(names(means4T), FUN = function ( domain ) {
          report(means4T[[domain]], trendDiffs = TRUE, add = list(domain = domain))}))
          
### Fifth example: compute adjusted means, also with trend estimation
### Note: all covariates must be numeric or 0/1 dichotomous
rdN1[,"mignum"] &lt;- as.numeric(rdN1[,"mig"])
rdN1[,"sexnum"] &lt;- car::recode(rdN1[,"sex"], "'male'=0; 'female'=1", as.numeric=TRUE,
                   as.factor=FALSE)
means5 &lt;- repMean(datL = rdN1, ID="idstud", wgt="wgt", type = "JK2", PSU = "jkzone",
          repInd = "jkrep", imp="imp", groups = "country",
          adjust = c("sexnum", "ses", "mignum"), useEffectLiteR = FALSE,
          dependent = "score", na.rm=FALSE, doCheck=TRUE, trend = "year",
          linkErr = "leScore")
res5   &lt;- report(means5, add = list(domain = "reading"))

## Not run: 
############################################################################################
#    Example 6: R code for running the PISA 2015 science example to compare group means    #
#                    with the total mean using weighted effect coding                      #
############################################################################################

# Warning: large PISA data set requires at least 16 GB free working memory (RAM):

### define necessary directories (note: writing permissions required)
folder &lt;- tempdir()

### download PISA 2015 zipped student questionnaire data (420 MB) to a folder with
### writing permissions
download.file(url = "https://webfs.oecd.org/pisa/PUF_SPSS_COMBINED_CMB_STU_QQQ.zip",
         destfile = file.path(folder, "pisa2015.zip"))

### unzip PISA 2015 student questionnaire data (1.5 GB) to temporary folder
zip::unzip(zipfile = file.path(folder, "pisa2015.zip"), files= "CY6_MS_CMB_STU_QQQ.sav",
     exdir=folder)

### read data
pisa &lt;- foreign::read.spss(file.path (folder, "CY6_MS_CMB_STU_QQQ.sav"),
        to.data.frame=TRUE, use.value.labels = FALSE, use.missings = TRUE)

# dependent variables
measure.vars &lt;- paste0("PV", 1:10, "SCIE")

### choose desired variables and reshape into the long format
#              'CNTSTUID' = individual student identifier
#                   'CNT' = country identifier
#                 'SENWT' = senate weight (assume a population of 5000 in each country)
#              'W_FSTUWT' = final student weight
#                  'OECD' = dummy variable indicating which country is part of the OECD
#   'W_FSTURWT' (1 to 80) = balanced repeated replicate weights
# 'PV1SCIE' to 'PV10SCIE' = 10 plausible values of (latent) science performance
pisaLong &lt;- reshape2::melt(pisa, id.vars = c("CNTSTUID", "CNT", "SENWT", "W_FSTUWT",
            "OECD", paste0("W_FSTURWT", 1:80)),
            measure.vars = measure.vars, value.name = "value", variable.name="imp",
            na.rm=TRUE)

### choose OECD countries
oecd &lt;- pisaLong[which(pisaLong[,"OECD"] == 1),]

### analyze data
### analysis takes approximately 30 minutes on an Intel i5-6500 machine with 32 GB RAM
means   &lt;- repMean( datL = oecd,         # data.frame in the long format
    ID                   = "CNTSTUID",   # student identifier
    dependent            = "value",      # the dependent variable in the data
    groups               = "CNT",        # the grouping variable
    wgt                  = "SENWT",      # (optional) weighting variable. We use senate
                                         # weights (assume a population of 5000 in each
                                         # country)
    type                 = "Fay",        # type of replication method. Corresponding to
                                         # the PISA sampling method, we use "Fay"
    rho                  = 0.5,          # shrinkage factor for weights in Fay's method
    scale                = NULL,         # scaling constant for variance, set to NULL
                                         # according to PISA's sampling method
    rscales              = NULL,         # scaling constant for variance, set to NULL
                                         # according to PISA's sampling method
    repWgt               = paste0("W_FSTURWT", 1:80), # the replicate weights,
                                                      # provided by the OECD
    imp                  = "imp",        # the imputation variable
    mse                  = FALSE,        # if TRUE, compute variances based on sum of
                                         # squares around the point estimate, rather
                                         # than the mean of the replicates.
    group.splits         = 0:1,          # defining the 'levels' for which means should
                                         # be computed. 0:1 implies that means for the
                                         # whole sample (level 0) as well as for groups
                                         # (level 1) are computed
    cross.differences    = TRUE,         # defines whether (and which) cross level mean
                                         # differences should be computed. TRUE means
                                         # that all cross level mean differences are
                                         # computed
    crossDiffSE          = "wec",        # method for standard errors of mean
                                         # differences
    crossDiffSE.engine   = "lm",         # software implementation for standard
                                         # errors of mean differences
    hetero               = TRUE,         # assume heteroscedastic group variances
    stochasticGroupSizes = FALSE         # assume fixed group sizes
                   )

### call a reporting function to generate user-friendly output
results &lt;- report(means, exclude = c("Ncases", "NcasesValid", "var", "sd"))

## End(Not run)</code></pre>

<hr>
<h2 id='report'>Reporting function for <code><a href="#topic+repMean">repMean</a></code>, <code><a href="#topic+repTable">repTable</a></code>,
<code><a href="#topic+repQuantile">repQuantile</a></code>, and <code><a href="#topic+repGlm">repGlm</a></code> </h2><span id='topic+report'></span>

<h3>Description</h3>

<p>Summarizes the output of the four main functions <code><a href="#topic+repMean">repMean</a></code>,<code><a href="#topic+repTable">repTable</a></code>,
<code><a href="#topic+repQuantile">repQuantile</a></code>, and <code><a href="#topic+repGlm">repGlm</a></code>, and provides a single data.frame with all
results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>report(repFunOut, trendDiffs = FALSE, add = list(),
      exclude = c("NcasesValid", "var", "sampleSize"), printGlm = FALSE,
      round = TRUE, digits = 3, printDeviance = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="report_+3A_repfunout">repFunOut</code></td>
<td>
<p>output of one of the four <code>eatRep</code>-functions. </p>
</td></tr>
<tr><td><code id="report_+3A_trenddiffs">trendDiffs</code></td>
<td>
<p>Logical: compute differences of trends? </p>
</td></tr>
<tr><td><code id="report_+3A_add">add</code></td>
<td>
<p>Optional: additional columns for output. See examples of the jk2-functions</p>
</td></tr>
<tr><td><code id="report_+3A_exclude">exclude</code></td>
<td>
<p>Which parameters should be excluded from reporting?</p>
</td></tr>
<tr><td><code id="report_+3A_printglm">printGlm</code></td>
<td>
<p>Only relevant for <code><a href="#topic+repGlm">repGlm</a></code>: print summary on console?</p>
</td></tr>
<tr><td><code id="report_+3A_round">round</code></td>
<td>
<p>Logical: should the results be rounded to a limited number of digits?</p>
</td></tr>
<tr><td><code id="report_+3A_digits">digits</code></td>
<td>
<p>How many digits should be used for rounding?</p>
</td></tr>
<tr><td><code id="report_+3A_printdeviance">printDeviance</code></td>
<td>
<p>Only relevant for <code><a href="#topic+repGlm">repGlm</a></code> when other than the
identical function is used as link function, and if <code>printGlm</code> is TRUE.
Should the deviance information printed additionally? Note: To print deviance information,
the argument <code>poolMethod</code> of the <code><a href="#topic+repGlm">repGlm</a></code> function must be set
to <code>"scalar"</code>. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame with at least nine columns.
</p>
<table>
<tr><td><code>group</code></td>
<td>
<p>Denotes the group an analysis belongs to. If no groups were specified and/or analysis for the
whole sample were requested, the value of &lsquo;group&rsquo; is &lsquo;wholeGroup&rsquo;.</p>
</td></tr>
<tr><td><code>depVar</code></td>
<td>
<p>Denotes the name of the dependent variable in the analysis. </p>
</td></tr>
<tr><td><code>modus</code></td>
<td>
<p>Denotes the mode of the analysis. For example, if a JK2 regression analysis was
conducted, &lsquo;modus&rsquo; takes the value &lsquo;JK2.glm&rsquo;. If a mean analysis without any replicates
was conducted, &lsquo;modus&rsquo; takes the value &lsquo;CONV.mean&rsquo;.</p>
</td></tr>
<tr><td><code>comparison</code></td>
<td>
<p>Denotes whether group mean comparisons or cross-level comparisons were conducted.
Without any comparisons, &lsquo;comparison&rsquo; takes the value &lsquo;NA&rsquo; </p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Denotes the parameter of the corresponding analysis. If regression analysis was applied,
the regression parameter is given. Amongst others, the &lsquo;parameter&rsquo; column takes the values
&lsquo;(Intercept)&rsquo; and &lsquo;gendermale&rsquo; if &lsquo;gender&rsquo; was the independent variable, for instance.
If mean analysis was applied, the &lsquo;parameter&rsquo; column takes the values &lsquo;mean&rsquo;, &lsquo;sd&rsquo;,
&lsquo;var&rsquo;, or &lsquo;Nvalid&rsquo;. See the examples of <code><a href="#topic+repMean">repMean</a></code>,<code><a href="#topic+repTable">repTable</a></code>,
<code><a href="#topic+repQuantile">repQuantile</a></code>, or <code><a href="#topic+repGlm">repGlm</a></code> for further details. </p>
</td></tr>
<tr><td><code>depVar</code></td>
<td>
<p>Denotes the name of the dependent variable (only if <code><a href="#topic+repGlm">repGlm</a></code> was called before) </p>
</td></tr>
<tr><td><code>est</code></td>
<td>
<p>Denotes the estimate of the corresponding analysis.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>Denotes the standard error of the corresponding estimate.</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>Denotes the p value of the estimate.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Benjamin Becker, Sebastian Weirich
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### see examples of the eatRep main functions.
</code></pre>

<hr>
<h2 id='repQuantile'>Replication methods (JK1, JK2 and BRR) for quantiles and trend estimation.</h2><span id='topic+repQuantile'></span><span id='topic+jk2.quantile'></span>

<h3>Description</h3>

<p>Compute quantiles with standard errors for complex cluster designs with multiple imputed variables
(e.g. plausible values) based on Jackknife (JK1, JK2) or balanced repeated replicates (BRR) procedure. Conceptually, 
the function combines replication methods and methods for multiple imputed data. Technically, this is a wrapper for
the <code>svyquantile()</code> function of the survey package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repQuantile(datL, ID, wgt = NULL, type = c("none", "JK2", "JK1", "BRR", "Fay"),
            PSU = NULL, repInd = NULL, repWgt = NULL, nest=NULL, imp=NULL,
            groups = NULL, group.splits = length(groups), cross.differences = FALSE,
            group.delimiter = "_", trend = NULL, linkErr = NULL, dependent,
            probs = c(0.25, 0.50, 0.75),  na.rm = FALSE, nBoot = NULL,
            bootMethod = c("wSampling","wQuantiles") , doCheck = TRUE,
            scale = 1, rscales = 1, mse=TRUE,
            rho=NULL, verbose = TRUE, progress = TRUE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repQuantile_+3A_datl">datL</code></td>
<td>


<p>Data frame in the long format (i.e. each line represents one ID unit in one imputation of one nest) containing all
variables for analysis.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_id">ID</code></td>
<td>


<p>Variable name or column number of student identifier (ID) variable. ID variable must not contain any missing values.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_wgt">wgt</code></td>
<td>


<p>Optional: Variable name or column number of weighting variable. If no weighting variable is specified,
all cases will be equally weighted.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_type">type</code></td>
<td>


<p>Defines the replication method for cluster replicates which is to be applied. Depending on <code>type</code>, additional
arguments must be specified (e.g., <code>PSU</code> and/or <code>repInd</code> or <code>repWgt</code>).
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_psu">PSU</code></td>
<td>


<p>Variable name or column number of variable indicating the primary sampling unit (PSU). When a jackknife procedure is applied,
the PSU is the jackknife zone variable. If <code>NULL</code>, no cluster structure is assumed and
standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_repind">repInd</code></td>
<td>


<p>Variable name or column number of variable indicating replicate ID. In a jackknife procedure, this is the jackknife replicate
variable. If <code>NULL</code>, no cluster structure is assumed and standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_repwgt">repWgt</code></td>
<td>


<p>Normally, replicate weights are created by <code>repQuantile</code> directly from <code>PSU</code> and <code>repInd</code> variables. Alternatively,
if replicate weights are included in the data.frame, specify the variable names or column number in the <code>repWgt</code> argument.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_nest">nest</code></td>
<td>
<p>Optional: name or column number of the nesting variable. Only applies in nested multiple imputed data sets.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_imp">imp</code></td>
<td>
<p>Optional: name or column number of the imputation variable. Only applies in multiple imputed data sets.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_groups">groups</code></td>
<td>


<p>Optional: vector of names or column numbers of one or more grouping variables.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_group.splits">group.splits</code></td>
<td>


<p>Optional: If groups are defined, <code>group.splits</code> optionally specifies whether analysis should be done also
in the whole group or overlying groups. See examples for more details.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_cross.differences">cross.differences</code></td>
<td>


<p>Either a list of vectors, specifying the pairs of levels for which cross-level differences should be computed.
Alternatively, if TRUE, cross-level differences for all pairs of levels are computed. If FALSE, no cross-level
differences are computed. (see examples 2a, 3, and 4 in the help file of the <code><a href="#topic+repMean">repMean</a></code> function)
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_group.delimiter">group.delimiter</code></td>
<td>


<p>Character string which separates the group names in the output frame.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_trend">trend</code></td>
<td>


<p>Optional: name or column number of the trend variable. Note: Trend variable must have exact two levels. Levels for
grouping variables must be equal in both 'sub populations' partitioned by the trend variable.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_linkerr">linkErr</code></td>
<td>


<p>Optional: name or column number of the linking error variable. If 'NULL', a linking error of 0 will be assumed in trend estimation.
Alternatively, the linking error may be given as a single scalar value (i.e. 'linkErr = 1.225').
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_dependent">dependent</code></td>
<td>


<p>Variable name or column number of the dependent variable.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_probs">probs</code></td>
<td>


<p>Numeric vector with probabilities for which to compute quantiles.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_na.rm">na.rm</code></td>
<td>


<p>Logical: Should cases with missing values be dropped?
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_nboot">nBoot</code></td>
<td>


<p>Optional: Without replicates, standard error cannot be computed in a weighted sample. Alternatively, standard errors may
be computed using the <code>boot</code> package. <code>nBoot</code> therefore specifies the number of bootstrap samples. If not specified,
no standard errors will be given. In analyses containing replicates or samples without specifying person weights,
<code>nBoot</code> will be ignored.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_bootmethod">bootMethod</code></td>
<td>


<p>Optional: If standard error are computed in a bootstrap, two possible methods may be applied.
<code>wSampling</code> requests the function to draw <code>nBoot</code> weighted bootstrap samples for which unweighted quantiles
are computed. <code>wQuantiles</code> requests the function to draw <code>nBoot</code> unweighted bootstrap samples for which
weighted quantiles are computed.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_docheck">doCheck</code></td>
<td>

<p>Logical: Check the data for consistency before analysis? If <code>TRUE</code> groups with insufficient data are excluded from
analysis to prevent subsequent functions from crashing.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_scale">scale</code></td>
<td>

<p>scaling constant for variance, for details, see help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_rscales">rscales</code></td>
<td>

<p>scaling constant for variance, for details, see help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_mse">mse</code></td>
<td>

<p>Logical: If <code>TRUE</code>, compute variances based on sum of squares around the point estimate, rather than the mean of the replicates.
See help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_rho">rho</code></td>
<td>

<p>Shrinkage factor for weights in Fay's method. See help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_verbose">verbose</code></td>
<td>

<p>Logical: Show analysis information on console?
</p>
</td></tr>
<tr><td><code id="repQuantile_+3A_progress">progress</code></td>
<td>

<p>Logical: Show progress bar on console?
</p>
</td></tr>
</table>


<h3>Details</h3>


<p>Function first creates replicate weights based on PSU and repInd variables according to JK2 or BRR procedure
implemented in WesVar. According to multiple imputed data sets, a workbook with several analyses is created.
The function afterwards serves as a wrapper for <code><a href="survey.html#topic+svyquantile">svyquantile</a></code> called by <code><a href="survey.html#topic+svyby">svyby</a></code> implemented in
the <code>survey</code> package. The results of the several analyses are then pooled according to Rubins rule, which
is adapted for nested imputations if the <code>dependent</code> argument implies a nested structure.
</p>


<h3>Value</h3>






<p>A list of data frames in the long format. The output can be summarized using the <code>report</code> function.
The first element of the list is a list with either one (no trend analyses) or two (trend analyses)
data frames with at least six columns each. For each subpopulation denoted by the <code>groups</code> statement, each
dependent variable, each parameter (i.e., the values of the corresponding categories of the dependent variable)
and each coefficient (i.e., the estimate and the corresponding standard error) the corresponding value is given.
</p>
<table>
<tr><td><code>group</code></td>
<td>
<p>Denotes the group an analysis belongs to. If no groups were specified and/or analysis for the 
whole sample were requested, the value of &lsquo;group&rsquo; is &lsquo;wholeGroup&rsquo;.</p>
</td></tr>
<tr><td><code>depVar</code></td>
<td>
<p>Denotes the name of the dependent variable in the analysis. </p>
</td></tr>
<tr><td><code>modus</code></td>
<td>
<p>Denotes the mode of the analysis. For example, if a JK2 analysis without sampling weights was 
conducted, &lsquo;modus&rsquo; takes the value &lsquo;jk2.unweighted&rsquo;. If a analysis without any replicates but with sampling
weights was conducted, &lsquo;modus&rsquo; takes the value &lsquo;weighted&rsquo;.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Denotes the parameter of the regression model for which the corresponding value is given
further. For frequency tables, this is the value of the category of the dependent variable which relative
frequency is given further.</p>
</td></tr>
<tr><td><code>coefficient</code></td>
<td>
<p>Denotes the coefficient for which the corresponding value is given further. Takes the 
values &lsquo;est&rsquo; (estimate) and &lsquo;se&rsquo; (standard error of the estimate).</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of the parameter, i.e. the relative frequency or its standard error.</p>
</td></tr>
</table>
<p>If groups were specified, further columns which are denoted by the group names are added to the data frame. 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(lsa)
### Example 1: only means, SD and variances for each country
### We only consider domain 'reading'
rd     &lt;- lsa[which(lsa[,"domain"] == "reading"),]

### We only consider the first "nest".
rdN1   &lt;- rd[which(rd[,"nest"] == 1),]

### First, we only consider year 2010
rdN1y10&lt;- rdN1[which(rdN1[,"year"] == 2010),]

### First example: Computes percentile in a nested data structure for reading 
### scores conditionally on country and for the whole group 
perzent   &lt;- repQuantile(datL = rd, ID = "idstud", wgt = "wgt", type = "JK2",
             PSU = "jkzone", repInd = "jkrep", imp = "imp", nest="nest",
             groups = "country", group.splits = c(0:1), dependent = "score", 
             probs = seq(0.1,0.9,0.2) )
res       &lt;- report(perzent, add = list(domain = "reading"))

### Second example: Computes percentile for reading scores conditionally on country,
### use 100 bootstrap samples, assume no nested structure 
perzent   &lt;- repQuantile(datL = rdN1y10, ID = "idstud", wgt = "wgt",
             imp = "imp", groups = "country", dependent = "score",
             probs = seq(0.1,0.9,0.2), nBoot = 100 )
res       &lt;- report(perzent, add = list(domain = "reading"))
</code></pre>

<hr>
<h2 id='repTable'>JK1, JK2 and BRR for frequency tables and trend estimation.</h2><span id='topic+repTable'></span><span id='topic+jk2.table'></span>

<h3>Description</h3>

<p>Compute frequency tables for categorical variables (e.g. factors: dichotomous or polytomous) in complex
cluster designs. Estimation of standard errors optionally takes the clustered structure and multiple imputed
variables into account. To date, Jackknife-1 (JK1), Jackknife-2 (JK2) and Balanced repeated replicate (BRR) methods are 
implemented to account for clustered designs. Procedures of Rubin (1987) and Rubin (2003) are implemented to account for 
multiple imputed data and nested imputed data, if necessary. Conceptually, the function combines replication and imputation 
methods. Technically, this is a wrapper for the <code><a href="survey.html#topic+svymean">svymean</a></code> function of the <code>survey</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>repTable(datL, ID, wgt = NULL, type = c("none", "JK2", "JK1", "BRR", "Fay"), PSU = NULL,
          repInd = NULL, jkfac=NULL, repWgt = NULL, nest=NULL, imp=NULL, groups = NULL,
          group.splits = length(groups), group.differences.by = NULL,
          cross.differences = FALSE, crossDiffSE = c("wec", "rep","old"),
          nBoot = 100, chiSquare = FALSE, correct = TRUE, group.delimiter = "_",
          trend = NULL, linkErr = NULL, dependent, separate.missing.indicator = FALSE,
          na.rm=FALSE, expected.values = NULL, doCheck = TRUE, forceTable = FALSE,
          engine = c("survey", "BIFIEsurvey"), scale = 1, rscales = 1, mse=TRUE,
          rho=NULL, verbose = TRUE, progress = TRUE )</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="repTable_+3A_datl">datL</code></td>
<td>

<p>Data frame in the long format (i.e. each line represents one ID unit in one imputation of one nest) containing all
variables for analysis.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_id">ID</code></td>
<td>

<p>Variable name or column number of student identifier (ID) variable. ID variable must not contain any missing values.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_wgt">wgt</code></td>
<td>

<p>Optional: Variable name or column number of weighting variable. If no weighting variable is specified,
all cases will be equally weighted.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_type">type</code></td>
<td>

<p>Defines the replication method for cluster replicates which is to be applied. Depending on <code>type</code>, additional
arguments must be specified (e.g., <code>PSU</code> and/or <code>repInd</code> or <code>repWgt</code>).
</p>
</td></tr>
<tr><td><code id="repTable_+3A_psu">PSU</code></td>
<td>

<p>Variable name or column number of variable indicating the primary sampling unit (PSU). When a jackknife procedure is applied,
the PSU is the jackknife zone variable. If <code>NULL</code>, no cluster structure is assumed and
standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_repind">repInd</code></td>
<td>

<p>Variable name or column number of variable indicating replicate ID. In a jackknife procedure, this is the jackknife replicate
variable. If <code>NULL</code>, no cluster structure is assumed and standard errors are computed according to a random sample.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_jkfac">jkfac</code></td>
<td>

<p>Only applies if <code>engine = "BIFIEsurvey"</code>. Argument is passed to <code><a href="BIFIEsurvey.html#topic+BIFIE.data.jack">BIFIE.data.jack</a></code> and specifies
the factor for multiplying jackknife replicate weights.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_repwgt">repWgt</code></td>
<td>

<p>Normally, replicate weights are created by <code>repTable</code> directly from <code>PSU</code> and <code>repInd</code> variables. Alternatively,
if replicate weights are included in the data.frame, specify the variable names or column number in the <code>repWgt</code> argument.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_nest">nest</code></td>
<td>
<p>Optional: name or column number of the nesting variable. Only applies in nested multiple imputed data sets.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_imp">imp</code></td>
<td>
<p>Optional: name or column number of the imputation variable. Only applies in multiple imputed data sets.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_groups">groups</code></td>
<td>

<p>Optional: vector of names or column numbers of one or more grouping variables.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_group.splits">group.splits</code></td>
<td>

<p>Optional: If groups are defined, <code>group.splits</code> optionally specifies whether analysis should be done also
in the whole group or overlying groups. See examples for more details.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_group.differences.by">group.differences.by</code></td>
<td>

<p>Optional: Specifies one grouping variable for which a chi-square test should be applied.
The corresponding variable must be included in the <code>groups</code> statement. If specified, the
distribution of the dependent variable is compared between the groups. See examples for
further details.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_cross.differences">cross.differences</code></td>
<td>

<p>Either a list of vectors, specifying the pairs of levels for which cross-level differences should be computed.
Alternatively, if TRUE, cross-level differences for all pairs of levels are computed. If FALSE, no cross-level
differences are computed. (see examples 2a, 3, and 4 in the help file of the <code>repMean</code> function)
</p>
</td></tr>
<tr><td><code id="repTable_+3A_crossdiffse">crossDiffSE</code></td>
<td>

<p>Method for standard error estimation for cross level differences, where groups are dependent.
<code>wec</code> uses weighted effect coding, <code>rep</code> uses replication methods (bootstrap or jackknife) to
estimate the standard error between the total mean and group-specific means. <code>old</code> does not account for dependent
groups and treat the groups as if they were independent from each other.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_nboot">nBoot</code></td>
<td>

<p>Without replicates (i.e., for completely random samples), the <code>rep</code> method for standard error estimation for
cross level differences needs a bootstrap. <code>nBoot</code> therefore specifies the number of bootstrap samples.
This argument is only necessary, if <code>crossDiffSE = "rep"</code> <em>and</em> none of the replicate methods
(JK1, JK2, or BRR) is applied. Otherwise, <code>nBoot</code> will be ignored.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_chisquare">chiSquare</code></td>
<td>

<p>Logical. Applies only if <code>group.differences.by</code> was specified. Defines whether
group differences should be represented in a chi square test or in (mean) differences of each
group's relative frequency. Note: To date, chi square test is not available for <code>engine = "BIFIEsurvey"</code>.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_correct">correct</code></td>
<td>

<p>Logical. Applies only if 'group.differences.by' is requested without cluster replicates. A logical indicating whether to apply
continuity correction when computing the test statistic for 2 by 2 tables. See help page of 'chisq.test' for further details.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_group.delimiter">group.delimiter</code></td>
<td>

<p>Character string which separates the group names in the output frame.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_trend">trend</code></td>
<td>

<p>Optional: name or column number of the trend variable. Note: Trend variable must have exact two levels. Levels for
grouping variables must be equal in both 'sub populations' partitioned by the trend variable.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_linkerr">linkErr</code></td>
<td>

<p>Optional: Either the name or column number of the linking error variable. If <code>NULL</code>, a linking error of 0 will be assumed in trend estimation.
Alternatively, linking errors may be
given as <code>data.frame</code> with following specifications: Two columns, named <code>trendLevel1</code> and <code>trendLevel2</code> which contain the
levels of the trend variable. The contrasts between both values indicates which trend is meant. For only two measurement occasions, i.e.
2010 and 2015, <code>trendLevel1</code> should be <code>2010</code>, and <code>trendLevel2</code> should be <code>2015</code>. For three measurement occasions,
i.e. 2010, 2015, and 2020, additional lines are necessary where <code>trendLevel1</code> should be <code>2010</code>, and <code>trendLevel2</code> should be
<code>2020</code>, to mark the contrast between 2010 and 2020, and further additional lines are necessary where <code>trendLevel1</code> should be
<code>2015</code>, and <code>trendLevel2</code> should be <code>2020</code>. The column <code>depVar</code> must include the name of the dependent variable. This
string must correspond to the name of the dependent variable in the data. The column <code>parameter</code> indicates the parameter the linking
error belongs to. Column <code>linkingError</code> includes the linking error value. Providing linking error in a data.frame is necessary for
more than two measurement occasions. See the fourth example below for further details.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_dependent">dependent</code></td>
<td>

<p>Variable name or column number of the dependent variable.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_separate.missing.indicator">separate.missing.indicator</code></td>
<td>

<p>Logical. Should frequencies of missings in dependent variable be integrated? Note: That is only useful if missing occur as <code>NA</code>. If the dependent variable
is coded as character, for example <code>'male', 'female', 'missing'</code>, separate missing indicator is not necessary.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_na.rm">na.rm</code></td>
<td>

<p>Logical: Should cases with missing values be dropped?
</p>
</td></tr>
<tr><td><code id="repTable_+3A_expected.values">expected.values</code></td>
<td>

<p>Optional. A vector of values expected in dependent variable. Recommend to left this argument empty.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_docheck">doCheck</code></td>
<td>

<p>Logical: Check the data for consistency before analysis? If <code>TRUE</code> groups with insufficient data are excluded from
analysis to prevent subsequent functions from crashing.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_forcetable">forceTable</code></td>
<td>

<p>Logical: Function decides internally whether the table or the mean function of <code>survey</code> is called.
If the mean function is called, the polytomous dependent variable is converted to dichotomous indicator
variables. If mean is called, group differences for each category of the polytomous dependent variable
can be computed. If table is called, a chi square statistic may be computed. The argument allows to
force the function either to call mean or table.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_engine">engine</code></td>
<td>

<p>Which package should be used for estimation?
</p>
</td></tr>
<tr><td><code id="repTable_+3A_scale">scale</code></td>
<td>

<p>scaling constant for variance, for details, see help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package
</p>
</td></tr>
<tr><td><code id="repTable_+3A_rscales">rscales</code></td>
<td>

<p>scaling constant for variance, for details, see help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package
</p>
</td></tr>
<tr><td><code id="repTable_+3A_mse">mse</code></td>
<td>

<p>Logical: If <code>TRUE</code>, compute variances based on sum of squares around the point estimate, rather than the mean of the replicates.
See help page of <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> from the <code>survey</code> package for further details.
</p>
</td></tr>
<tr><td><code id="repTable_+3A_rho">rho</code></td>
<td>

<p>Shrinkage factor for weights in Fay's method. If <code>engine = "survey"</code>, argument is passed to the <code>rho</code> argument of
the <code><a href="survey.html#topic+svrepdesign">svrepdesign</a></code> function from the <code>survey</code> package. See the corresponding help page for further
details. If <code>engine = "BIFIEsurvey"</code>, argument is passed to the <code>fayfac</code> argument of the
<code><a href="BIFIEsurvey.html#topic+BIFIE.data.jack">BIFIE.data.jack</a></code> function from the <code>BIFIEsurvey</code> package. See the
corresponding help page for further details. For convenience, if <code>rho = NULL</code> (the default)
and <code>engine = "BIFIEsurvey"</code> and <code>type = "JK1"</code>, <code><a href="BIFIEsurvey.html#topic+BIFIE.data.jack">BIFIE.data.jack</a></code>
is called with <code>jktype="JK_GROUP"</code> and <code>fayfac = rho</code>, where <code class="reqn">\rho = (N_{cluster} - 1) \times N_{cluster}^{-1}</code>
</p>
</td></tr>
<tr><td><code id="repTable_+3A_verbose">verbose</code></td>
<td>

<p>Logical: Show analysis information on console?
</p>
</td></tr>
<tr><td><code id="repTable_+3A_progress">progress</code></td>
<td>

<p>Logical: Show progress bar on console?
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function first creates replicate weights based on PSU and repInd variables according to JK2 procedure
implemented in WesVar. According to multiple imputed data sets, a workbook with several analyses is created.
The function afterwards serves as a wrapper for <code><a href="survey.html#topic+svymean">svymean</a></code> called by <code><a href="survey.html#topic+svyby">svyby</a></code> implemented in the <code>survey</code> package.
Relative frequencies of the categories of the dependent variable are computed by the means of the dichotomous indicators
(e.g. dummy variables) of each category. The results of the several analyses are then pooled according to Rubin's rule,
which is adapted for nested imputations if the <code>dependent</code> argument implies a nested structure.
</p>


<h3>Value</h3>






<p>A list of data frames in the long format. The output can be summarized using the <code>report</code> function.
The first element of the list is a list with either one (no trend analyses) or two (trend analyses)
data frames with at least six columns each. For each subpopulation denoted by the <code>groups</code> statement, each
dependent variable, each parameter (i.e., the values of the corresponding categories of the dependent variable)
and each coefficient (i.e., the estimate and the corresponding standard error) the corresponding value is given.
</p>
<table>
<tr><td><code>group</code></td>
<td>
<p>Denotes the group an analysis belongs to. If no groups were specified and/or analysis for the 
whole sample were requested, the value of &lsquo;group&rsquo; is &lsquo;wholeGroup&rsquo;.</p>
</td></tr>
<tr><td><code>depVar</code></td>
<td>
<p>Denotes the name of the dependent variable in the analysis. </p>
</td></tr>
<tr><td><code>modus</code></td>
<td>
<p>Denotes the mode of the analysis. For example, if a JK2 analysis without sampling weights was 
conducted, &lsquo;modus&rsquo; takes the value &lsquo;jk2.unweighted&rsquo;. If a analysis without any replicates but with sampling
weights was conducted, &lsquo;modus&rsquo; takes the value &lsquo;weighted&rsquo;.</p>
</td></tr>
<tr><td><code>parameter</code></td>
<td>
<p>Denotes the parameter of the regression model for which the corresponding value is given
further. For frequency tables, this is the value of the category of the dependent variable which relative
frequency is given further.</p>
</td></tr>
<tr><td><code>coefficient</code></td>
<td>
<p>Denotes the coefficient for which the corresponding value is given further. Takes the 
values &lsquo;est&rsquo; (estimate) and &lsquo;se&rsquo; (standard error of the estimate).</p>
</td></tr>
<tr><td><code>value</code></td>
<td>
<p>The value of the parameter, i.e. the relative frequency or its standard error.</p>
</td></tr>
</table>
<p>If groups were specified, further columns which are denoted by the group names are added to the data frame. 
</p>


<h3>References</h3>

<p>Rubin, D.B. (2003): Nested multiple imputation of NMES
via partially incompatible MCMC.
<em>Statistica Neerlandica</em> <b>57, 1</b>, 3&ndash;18.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lsa)

### Example 1: only means, SD and variances for each country
### subsetting: We only consider domain 'reading'
rd     &lt;- lsa[which(lsa[,"domain"] == "reading"),]

### We only consider the first "nest".
rdN1   &lt;- rd[which(rd[,"nest"] == 1),]

### First, we only consider year 2010
rdN1y10&lt;- rdN1[which(rdN1[,"year"] == 2010),]

### First example: Computes frequencies of polytomous competence levels (1, 2, 3, 4, 5)
### conditionally on country, using a chi-square test to decide whether the distribution
### varies between countries (it's an overall test, i.e. with three groups, df1=8).
freq.tab1 &lt;- repTable(datL = rdN1y10, ID = "idstud", wgt = "wgt", imp="imp",
             type = "JK2", PSU = "jkzone", repInd = "jkrep", groups = "country",
             group.differences.by = "country", dependent = "comp", chiSquare = TRUE)
res1      &lt;- report(freq.tab1, add = list ( domain = "reading" ))


### Second example: Computes frequencies of polytomous competence levels (1, 2, 3, 4, 5)
### conditionally on country. Now we test whether the frequency of each single category
### differs between pairs of countries (it's not an overall test ... repTable now
### calls repMean internally, using dummy variables
freq.tab2 &lt;- repTable(datL = rdN1y10, ID = "idstud", wgt = "wgt", imp="imp",
             type = "JK2", PSU = "jkzone", repInd = "jkrep", groups = "country",
             group.differences.by = "country", dependent = "comp", chiSquare = FALSE)
res2      &lt;- report(freq.tab2, add = list ( domain = "reading" ))

### Third example: trend estimation and nested imputation and 'by' loop
### (to date, only crossDiffSE = "old" works)
freq.tab3 &lt;- by ( data = lsa, INDICES = lsa[,"domain"], FUN = function (subdat) {
             repTable(datL = subdat, ID = "idstud", wgt = "wgt", imp="imp",
                 nest = "nest", type = "JK2", PSU = "jkzone", repInd = "jkrep",
                 groups = "country", group.differences.by = "country",
                 group.splits = 0:1, cross.differences = TRUE, crossDiffSE = "old",
                 dependent = "comp", chiSquare = FALSE, trend = "year",
                 linkErr = "leComp") })
res3      &lt;- do.call("rbind", lapply(names(freq.tab3), FUN = function (domain) {
             report(freq.tab3[[domain]], trendDiffs = TRUE,
                    add = list ( domain = domain ))
             }))
             
### Fourth example: similar to example 3. trend estimation using a linking
### error data.frame
linkErrs  &lt;- data.frame ( trendLevel1 = 2010, trendLevel2 = 2015,  depVar = "comp",
             unique(lsa[,c("domain", "comp", "leComp")]), stringsAsFactors = FALSE)
colnames(linkErrs) &lt;- car::recode(colnames(linkErrs),
                      "'comp'='parameter'; 'leComp'='linkingError'")
freq.tab4 &lt;- by ( data = lsa, INDICES = lsa[,"domain"], FUN = function (subdat) {
             repTable(datL = subdat, ID = "idstud", wgt = "wgt", type="none",
                 imp="imp", nest = "nest", groups = "country",
                 group.differences.by = "country", group.splits = 0:1,
                 cross.differences = FALSE, dependent = "comp", chiSquare = FALSE,
                 trend = "year",
                 linkErr = linkErrs[which(linkErrs[,"domain"] == subdat[1,"domain"]),])
             })
res4      &lt;- do.call("rbind", lapply(names(freq.tab4), FUN = function (domain) {
             report(freq.tab4[[domain]], trendDiffs = TRUE,
                    add = list ( domain = domain ))
             }))

### Fifth example: minimal example for three measurement occasions
### borrow data from the eatGADS package
trenddat1 &lt;- system.file("extdata", "trend_gads_2010.db", package = "eatGADS")
trenddat2 &lt;- system.file("extdata", "trend_gads_2015.db", package = "eatGADS")
trenddat3 &lt;- system.file("extdata", "trend_gads_2020.db", package = "eatGADS")
trenddat  &lt;- eatGADS::getTrendGADS(filePaths = c(trenddat1, trenddat2, trenddat3),
             years = c(2010, 2015, 2020), fast=FALSE)
dat       &lt;- eatGADS::extractData(trenddat)
### use template linking Error Object
load(system.file("extdata", "linking_error.rda", package = "eatRep"))
### check consistency of data and linking error object
check1 &lt;- checkLEs(c(trenddat1, trenddat2, trenddat3), lErr)
### Analysis for reading comprehension
freq.tab5 &lt;- repTable(datL = dat[which(dat[,"dimension"] == "reading"),],
             ID = "idstud", type="none", imp="imp", dependent = "traitLevel",
             chiSquare = FALSE, trend = "year",
             linkErr = lErr[which(lErr[,"domain"] == "reading"),])
res5      &lt;- report(freq.tab5, trendDiffs = TRUE, add = list ( domain = "reading" ))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
