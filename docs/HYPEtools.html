<!DOCTYPE html><html><head><title>Help for package HYPEtools</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HYPEtools}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#HYPEtools-package'><p>HYPEtools: Tools for Processing and Analyzing Files from the Hydrological Catchment Model HYPE</p></a></li>
<li><a href='#AllDownstreamSubids'><p>Find All Downstream SUBIDs</p></a></li>
<li><a href='#AllUpstreamSubids'><p>Find All Upstream SUBIDs</p></a></li>
<li><a href='#AnnualRegime'><p>Calculate annual regimes</p></a></li>
<li><a href='#BarplotUpstreamClasses'><p>Bar plots of upstream-averaged classes of HYPE sub-basins</p></a></li>
<li><a href='#BoxplotSLCClasses'><p>Box plots of SLC distributions</p></a></li>
<li><a href='#CleanSLCClasses'><p>Clean Soil-Landuse classes (SLCs) from small fractions</p></a></li>
<li><a href='#CompareFiles'><p>Compare HYPE model files to identify any differences.</p></a></li>
<li><a href='#ConvertDischarge'><p>Calculate Specific runoff from volumetric discharge and vice versa</p></a></li>
<li><a href='#CreateOptpar'><p>Create an optpar list</p></a></li>
<li><a href='#CustomColors'><p>Custom color ramp palettes</p></a></li>
<li><a href='#DirectUpstreamSubids'><p>Find Direct Upstream SUBIDs, with Flow Fractions</p></a></li>
<li><a href='#distinctColorPalette'><p>Generate optimally distinct color palettes</p></a></li>
<li><a href='#EquallySpacedObs'><p>Create an equally spaced time series from irregular observations</p></a></li>
<li><a href='#ExtractFreq'><p>Extract quantiles for use in a frequency distribution plot, e.g. a flow duration curve</p></a></li>
<li><a href='#ExtractStats'><p>Extract statistics from time series</p></a></li>
<li><a href='#GOF'><p>Goodness of Fit Functions</p></a></li>
<li><a href='#GroupSLCClasses'><p>Calculate grouped sums for SLC classes in a GeoData file</p></a></li>
<li><a href='#GwRetention'><p>Calculate groundwater retention of nutrients</p></a></li>
<li><a href='#HeadwaterSubids'><p>Find all headwater SUBIDs of a model domain</p></a></li>
<li><a href='#HypeAttrAccess'><p>Quickly query and set HYPE-specific attributes</p></a></li>
<li><a href='#HypeDataExport'><p>Write HYPE data files</p></a></li>
<li><a href='#HypeDataImport'><p>Read HYPE data files</p></a></li>
<li><a href='#HypeGeoData'><p>HypeGeoData data frames</p></a></li>
<li><a href='#HypeMultiVar'><p>HypeMultiVar arrays</p></a></li>
<li><a href='#HypeSingleVar'><p>HypeSingleVar arrays</p></a></li>
<li><a href='#HypeSubidChecks'><p>Check HYPE SUBID properties</p></a></li>
<li><a href='#HypeXobs'><p>HypeXobs data frames</p></a></li>
<li><a href='#InfoManipulation'><p>Functions to Manipulate HYPE Info Files</p></a></li>
<li><a href='#MapRegionalSources'><p>Map regional irrigation source connection as spatial lines</p></a></li>
<li><a href='#merge'><p>Merge HypeGeoData object</p></a></li>
<li><a href='#MergeObs'><p>Merge two HYPE observation data frames</p></a></li>
<li><a href='#MergeXobs'><p>Merge two Xobs data frames</p></a></li>
<li><a href='#NSE.HypeSingleVar'><p>Nash-Sutcliffe Efficiency</p></a></li>
<li><a href='#OptimisedClasses'><p>Get optimized classes from an imported optpar.txt file</p></a></li>
<li><a href='#OutletIds'><p>Find Outlet IDs</p></a></li>
<li><a href='#OutletNearObs'><p>Find outlet-near observations in HYPE observation data files.</p></a></li>
<li><a href='#OutletSubids'><p>Find all Outlet SUBIDs of a model domain</p></a></li>
<li><a href='#PartyParrot'><p>Create a Party Parrot.</p></a></li>
<li><a href='#pbias.HypeSingleVar'><p>Percent bias</p></a></li>
<li><a href='#PlotAnnualRegime'><p>Plot annual regimes</p></a></li>
<li><a href='#PlotBasinOutput'><p>Plot a suite of time series plots from a HYPE basin output file</p></a></li>
<li><a href='#PlotBasinSummary'><p>Plot a summary of model results for a single sub-basin</p></a></li>
<li><a href='#PlotDurationCurve'><p>Plot duration curves</p></a></li>
<li><a href='#PlotMapOutput'><p>Plot function for HYPE map results.</p></a></li>
<li><a href='#PlotMapPoints'><p>Plot function for mapped point information</p></a></li>
<li><a href='#PlotPerformanceByAttribute'><p>Plot model performance by SUBID attributes</p></a></li>
<li><a href='#PlotSimObsRegime'><p>Plot annual regimes of simulated and observed variables</p></a></li>
<li><a href='#PlotSubbasinRouting'><p>Plot HYPE model subbasin routing.</p></a></li>
<li><a href='#r'><p>Pearson product-moment correlation coefficient r</p></a></li>
<li><a href='#ReadBasinOutput'><p>Read a Basin Output File</p></a></li>
<li><a href='#ReadClassData'><p>Read a 'ClassData.txt' File</p></a></li>
<li><a href='#ReadDescription'><p>Read a 'description.txt' file</p></a></li>
<li><a href='#ReadGeoClass'><p>Read a 'GeoClass.txt' File</p></a></li>
<li><a href='#ReadGeoData'><p>Read a 'GeoData.txt' file</p></a></li>
<li><a href='#ReadInfo'><p>Read an 'info.txt' file</p></a></li>
<li><a href='#ReadMapOutput'><p>Read a Map Output File</p></a></li>
<li><a href='#ReadObs'><p>Read HYPE observation data files</p></a></li>
<li><a href='#ReadOptpar'><p>Read an 'optpar.txt' file</p></a></li>
<li><a href='#ReadPar'><p>Read a 'par.txt' file</p></a></li>
<li><a href='#ReadPmsf'><p>Read a 'pmsf.txt' file</p></a></li>
<li><a href='#ReadSimass'><p>Read a 'simass.txt' file</p></a></li>
<li><a href='#ReadSubass'><p>Read a 'subassX.txt' file</p></a></li>
<li><a href='#ReadTimeOutput'><p>Read a Time Output File</p></a></li>
<li><a href='#ReadWsOutput'><p>Read optimization simulation results</p></a></li>
<li><a href='#ReadXobs'><p>Read an 'Xobs.txt' file</p></a></li>
<li><a href='#RescaleSLCClasses'><p>Re-scale SLC classes in a GeoData data frame</p></a></li>
<li><a href='#ScalePar'><p>Scale 'par.txt' files to different model time step</p></a></li>
<li><a href='#SimToPar'><p>HYPE Calibration Outputs to par.txt</p></a></li>
<li><a href='#SortGeoData'><p>Sort a GeoData dataframe in downstream order</p></a></li>
<li><a href='#SubidAttributeSummary'><p>Summarize subbasin attributes</p></a></li>
<li><a href='#SumSLCClasses'><p>Calculate sums of SLC classes in a GeoData file</p></a></li>
<li><a href='#SumUpstreamArea'><p>Calculate upstream area sums</p></a></li>
<li><a href='#UpstreamGeoData'><p>Calculate upstream sums and averages of selected GeoData contents</p></a></li>
<li><a href='#UpstreamGroupSLCClasses'><p>Calculate area-weighted upstream averages of grouped SLC class fractions.</p></a></li>
<li><a href='#UpstreamPointSources'><p>Summarize point source emissions of all upstream areas</p></a></li>
<li><a href='#UpstreamSLCClasses'><p>Calculate SLC class fractions of all upstream areas</p></a></li>
<li><a href='#VariableLookup'><p>Lookup Functions For HYPE Variables</p></a></li>
<li><a href='#VisualizeMapOutput'><p>Shiny App for visualizing HYPE MapOutputs.</p></a></li>
<li><a href='#VisualizeMapPoints'><p>Shiny App for visualizing Mapped Point Information.</p></a></li>
<li><a href='#WriteBasinOutput'><p>Write a basin output '[SUBID].txt' file</p></a></li>
<li><a href='#WriteGeoClass'><p>Write a 'GeoClass.txt' file</p></a></li>
<li><a href='#WriteGeoData'><p>Write a 'GeoData.txt' file</p></a></li>
<li><a href='#WriteHarmonizedData'><p>Write a Harmonized Data File</p></a></li>
<li><a href='#WriteHarmonizedSpatialDescription'><p>Write a Harmonized Spatial Description File</p></a></li>
<li><a href='#WriteInfo'><p>Write a 'info.txt' File</p></a></li>
<li><a href='#WriteMapOutput'><p>Write a 'mapXXXX.txt' file</p></a></li>
<li><a href='#WriteObs'><p>Write 'Pobs.txt', 'Tobs.txt', 'Qobs.txt', and other observation data files</p></a></li>
<li><a href='#WriteOptpar'><p>Write an 'optpar.txt' File</p></a></li>
<li><a href='#WritePar'><p>Write a 'par.txt' File</p></a></li>
<li><a href='#WritePmsf'><p>Write a 'pmsf.txt' file</p></a></li>
<li><a href='#WriteTimeOutput'><p>Write a 'timeXXXX.txt' file</p></a></li>
<li><a href='#WriteXobs'><p>Write an 'Xobs.txt' File</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.6.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools for Processing and Analyzing Files from the Hydrological
Catchment Model HYPE</td>
</tr>
<tr>
<td>Description:</td>
<td>Work with model files (setup, input, output) from
    the hydrological catchment model HYPE: Streamlined file import and export, standard 
    evaluation plot routines, diverse post-processing and aggregation routines 
    for hydrological model analysis.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>clipr, colorspace, data.table (&ge; 1.9.8), dplyr, ggplot2,
ggpubr, ggrepel, grDevices, graphics, lubridate, methods,
ncdf4, parallel, patchwork, pbapply, purrr, rlang, scales,
stats, stringr, tidyr, tidyselect, utils, zoo</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://hypeweb.smhi.se/">https://hypeweb.smhi.se/</a>, <a href="https://github.com/rcapell/HYPEtools">https://github.com/rcapell/HYPEtools</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/rcapell/HYPEtools/issues">https://github.com/rcapell/HYPEtools/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown, knitr, beepr, DT, htmlwidgets, leaflet,
leaflet.extras, mapview, plotly, sf, shiny, shinyalert,
shinyFiles, shinyWidgets, webshot</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-12 15:42:31 UTC; a002416</td>
</tr>
<tr>
<td>Author:</td>
<td>Rene Capell <a href="https://orcid.org/0000-0002-7784-1313"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Conrad Brendel <a href="https://orcid.org/0000-0002-5199-0580"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Jafet Andersson [ctb],
  David Gustafsson [ctb],
  Jude Musuuza [ctb],
  Jude Lubega [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Rene Capell &lt;hypetools.rene@smhi.se&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-12 17:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='HYPEtools-package'>HYPEtools: Tools for Processing and Analyzing Files from the Hydrological Catchment Model HYPE</h2><span id='topic+HYPEtools'></span><span id='topic+HYPEtools-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Work with model files (setup, input, output) from the hydrological catchment model HYPE: Streamlined file import and export, standard evaluation plot routines, diverse post-processing and aggregation routines for hydrological model analysis.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Rene Capell <a href="mailto:hypetools.rene@smhi.se">hypetools.rene@smhi.se</a> (<a href="https://orcid.org/0000-0002-7784-1313">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Conrad Brendel <a href="mailto:conrad.brendel@smhi.se">conrad.brendel@smhi.se</a> (<a href="https://orcid.org/0000-0002-5199-0580">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Jafet Andersson [contributor]
</p>
</li>
<li><p> David Gustafsson [contributor]
</p>
</li>
<li><p> Jude Musuuza [contributor]
</p>
</li>
<li><p> Jude Lubega [contributor]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://hypeweb.smhi.se/">https://hypeweb.smhi.se/</a>
</p>
</li>
<li> <p><a href="https://github.com/rcapell/HYPEtools">https://github.com/rcapell/HYPEtools</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/rcapell/HYPEtools/issues">https://github.com/rcapell/HYPEtools/issues</a>
</p>
</li></ul>


<hr>
<h2 id='AllDownstreamSubids'>Find All Downstream SUBIDs</h2><span id='topic+AllDownstreamSubids'></span>

<h3>Description</h3>

<p>Function to find all SUBIDs of downstream sub-catchments along the main stem for a single
sub-catchment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AllDownstreamSubids(subid, gd, bd = NULL, write.arcgis = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AllDownstreamSubids_+3A_subid">subid</code></td>
<td>
<p>Integer, SUBID of a target sub-catchment (must exist in <code>gd</code>).</p>
</td></tr>
<tr><td><code id="AllDownstreamSubids_+3A_gd">gd</code></td>
<td>
<p>Dataframe, an imported 'GeoData.txt' file. Mandatory argument. See 'Details'.</p>
</td></tr>
<tr><td><code id="AllDownstreamSubids_+3A_bd">bd</code></td>
<td>
<p>Dataframe, an imported 'BranchData.txt' file. Optional argument. See 'Details'.</p>
</td></tr>
<tr><td><code id="AllDownstreamSubids_+3A_write.arcgis">write.arcgis</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a string containing an SQL expression suitable for ArcGIS's
'Select By Attributes' feature will be written to the clipboard.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>AllDownstreamSubids</code> finds all downstream SUBIDs of a given SUBID along the main stem (including itself but not
including potential irrigation links or groundwater flows) using GeoData columns 'SUBID' and 'MAINDOWN'. If a BranchData file
is provided, the function will also include information on downstream bifurcations.
</p>


<h3>Value</h3>

<p><code>AllDownstreamSubids</code> returns a vector of downstream SUBIDs to the outlet if no BranchData is provided, otherwise a data frame with
two columns <code>downstream</code> with downstream SUBIDs and <code>is.branch</code> with logical values indicating if a downstream SUBID contains a
bifurcation ('branch' in HYPE terms). Downstream SUBIDs are ordered from source to final outlet SUBID.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids</a></code>, <code><a href="#topic+OutletSubids">OutletSubids</a></code>, <code><a href="#topic+OutletIds">OutletIds</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
AllDownstreamSubids(subid = 3344, gd = te)

</code></pre>

<hr>
<h2 id='AllUpstreamSubids'>Find All Upstream SUBIDs</h2><span id='topic+AllUpstreamSubids'></span>

<h3>Description</h3>

<p>Function to find all SUBIDs of upstream sub-catchments for a single
sub-catchment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AllUpstreamSubids(
  subid,
  gd,
  bd = NULL,
  sort = FALSE,
  get.weights = FALSE,
  write.arcgis = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AllUpstreamSubids_+3A_subid">subid</code></td>
<td>
<p>SUBID of a target sub-catchment (must exist in <code>gd</code>).</p>
</td></tr>
<tr><td><code id="AllUpstreamSubids_+3A_gd">gd</code></td>
<td>
<p>A data frame, containing 'SUBID' and 'MAINDOWN' columns, e.g. an imported 'GeoData.txt' file. Mandatory argument. See 'Details'.</p>
</td></tr>
<tr><td><code id="AllUpstreamSubids_+3A_bd">bd</code></td>
<td>
<p>A data frame, containing 'BRANCHID' and 'SOURCEID' columns, and 'MAINPART' with argument <code>get.weights</code>,
e.g. an imported 'BranchData.txt' file. Optional argument.</p>
</td></tr>
<tr><td><code id="AllUpstreamSubids_+3A_sort">sort</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the resulting upstream SUBID vector will be sorted according to order in argument <code>gd</code>, i.e. in
downstream order for a working GeoData table.</p>
</td></tr>
<tr><td><code id="AllUpstreamSubids_+3A_get.weights">get.weights</code></td>
<td>
<p>Logical. If <code>TRUE</code>, flow weights are computed along the upstream SUBID sequence. See details.</p>
</td></tr>
<tr><td><code id="AllUpstreamSubids_+3A_write.arcgis">write.arcgis</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a string containing an SQL expression suitable for ArcGIS's
'Select By Attributes' feature will be written to the clipboard.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>AllUpstreamSubids</code> finds all upstream SUBIDs of a given SUBID (including itself but not
including potential irrigation links or groundwater flows) using GeoData columns 'SUBID' and 'MAINDOWN', i.e the full upstream catchment.
If a BranchData file is provided, the function will also include upstream areas which are connected through an upstream bifurcation. The
results can be directly used as 'partial model setup file' ('pmsf.txt') using the export function <code><a href="#topic+WritePmsf">WritePmsf</a></code>.
</p>
<p>If argument <code>get.weights</code> is set to <code>TRUE</code>, weighting fractions are returned along with upstream SUBIDs. The fractions are based
on column 'MAINPART' in argument <code>bd</code>. The function considers fractions from bifurcation branches which flow into the basin, and
fractions where bifurcation branches remove discharge from the basin. Fractions are incrementally updated, i.e. nested bifurcation fractions
are multiplied.
</p>
<p>For details on bifurcation handling in HYPE, see the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:branchdata.txt">HYPE online documentation for BranchData.txt</a>.
</p>


<h3>Value</h3>

<p>If <code>get.weights</code> is <code>FALSE</code>, <code>AllUpstreamSubids</code> returns a vector of SUBIDs, otherwise a two-column data frame with SUBIDs in
the first, and flow weight fractions in the second column.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+UpstreamGeoData">UpstreamGeoData</a></code>, <code><a href="#topic+AllDownstreamSubids">AllDownstreamSubids</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
AllUpstreamSubids(subid = 63794, gd = te)

</code></pre>

<hr>
<h2 id='AnnualRegime'>Calculate annual regimes</h2><span id='topic+AnnualRegime'></span>

<h3>Description</h3>

<p>Calculate annual regimes based on long-term time series, typically imported HYPE basin output and time output result files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AnnualRegime(
  x,
  stat = c("mean", "sum"),
  ts.in = NULL,
  ts.out = NULL,
  start.mon = 1,
  incl.leap = FALSE,
  na.rm = TRUE,
  format = c("list", "long")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="AnnualRegime_+3A_x">x</code></td>
<td>
<p>Data frame, with column-wise equally-spaced time series. Date-times in <code><a href="base.html#topic+POSIXct">POSIXct</a></code> format in first column.
Typically an imported basin or time output file from HYPE. See details.</p>
</td></tr>
<tr><td><code id="AnnualRegime_+3A_stat">stat</code></td>
<td>
<p>Character string, either <code>"mean"</code> or <code>"sum"</code>. Defines the type of aggregation to be computed for output
time periods, see Details. Defaults to <code>"mean"</code>.</p>
</td></tr>
<tr><td><code id="AnnualRegime_+3A_ts.in">ts.in</code></td>
<td>
<p>Character string, timestep of <code>x</code>, attribute <code>timestep</code> in <code>x</code> per default.
Otherwise one of <code>"month"</code>, <code>"week"</code>, <code>"day"</code>, or <code>"nhour"</code> (n = number of hours).</p>
</td></tr>
<tr><td><code id="AnnualRegime_+3A_ts.out">ts.out</code></td>
<td>
<p>Character string, timestep for results, defaults to <code>ts.in</code>. This timestep must be equal to or longer than
<code>ts.in</code>.</p>
</td></tr>
<tr><td><code id="AnnualRegime_+3A_start.mon">start.mon</code></td>
<td>
<p>Integer between 1 and 12, starting month of the hydrological year, used to order the output.</p>
</td></tr>
<tr><td><code id="AnnualRegime_+3A_incl.leap">incl.leap</code></td>
<td>
<p>Logical, leap days (Feb 29) are removed from results per default, set to <code>TRUE</code> to keep them. Applies
to daily and shorter time steps only.</p>
</td></tr>
<tr><td><code id="AnnualRegime_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, indicating if <code>NA</code> values should be stripped before averages are calculated.</p>
</td></tr>
<tr><td><code id="AnnualRegime_+3A_format">format</code></td>
<td>
<p>Character string. Output format, <code>list</code> (default) or <code>long</code>. See Value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>AnnualRegime</code> uses <code><a href="stats.html#topic+aggregate">aggregate</a></code> to calculate long-term average regimes for all data columns provided in <code>x</code>,
including long-term arithmetic means, medians, minima and maxima, and 5%, 25%, 75%, and 95% percentiles. With HYPE result files,
<code>AnnualRegime</code> is particularly applicable to basin and time output files imported using <code><a href="#topic+ReadBasinOutput">ReadBasinOutput</a></code> and
<code><a href="#topic+ReadTimeOutput">ReadTimeOutput</a></code>. The function does not check if equally spaced time steps are provided in <code>x</code> or if the
overall time period in <code>x</code> covers full years so that the calculated averages are based on the same number of values.
</p>
<p>Values within each output time period can be aggregated either by arithmetic means or by sums within each period, e.g. typically
means for temperatures and sums for precipitation. Long-term aggregated values are always computed as arithmetic means.
</p>


<h3>Value</h3>

<p>If argument <code>format</code> is <code>list</code>, <code>AnnualRegime</code> returns a list with 8 elements and two additional <code><a href="base.html#topic+attributes">attributes()</a></code>. Each list element contains a
named data frame with aggregated annual regime data: arithmetic means, medians, minima, maxima, and 5%, 25%, 75%, and 95%
percentiles.
</p>
<p>Each data frames contains, in column-wise order: reference dates in <code>POSIXct</code> format, date information as string, and aggregated
variables found in <code>x</code>.
</p>
<p>Reference dates are given as dates in either 1911, 1912, or 1913 (just because a leap day and outer weeks '00'/'53' occur during
these years) and can be used for plots starting at the beginning of the hydrological year (with axis annotations set to months only).
Daily and hourly time steps are given as is, weekly time steps are given as mid-week dates (Wednesday), monthly time steps as
mid month dates (15th).
</p>
<p>If argument <code>format</code> is <code>long</code>, <code>AnnualRegime</code> returns a four-column data frame with one value per row, and all variable information aligned
with the values. Columns in the data frame: <code>id</code> with SUBIDs or HYPE variable IDs, <code>month/week/day</code> with aggregation time steps, <code>name</code> with
short names of regime data (means, medians, minima, maxima, percentiles), and <code>value</code> with the variable value.
</p>
<p>Attribute <code>period</code> contains a two-element POSIXct vector containing start and end dates of the
source data. Attribute <code>timestep</code> contains a timestep keyword corresponding to function argument <code>ts.out</code>.
</p>


<h3>Note</h3>

<p>If weekly data are provided in <code>x</code>, <code>AnnualRegime</code> will inflate <code>x</code> to daily time steps before computing
results. Values in <code>x</code> will be assigned to the preceeding week days, corresponding to HYPE file output, where weekly
values are conventionally printed on the last day of the week. If <code>NA</code> values are present in the original weekly data,
these will be filled with the next available value as a side effect of the inflation.
</p>
<p>If weekly output time steps are computed in combination with a user-defined start month, the function will round up weeks to
determine the first week of the hydrological year. Weeks are identified using Monday as first day of the week and the first Monday
of the year as day 1 of week 1 (see conversion code <code>%W</code> in <code><a href="base.html#topic+strptime">strptime</a></code>). Boundary weeks <code>'00'</code> and
<code>'53'</code> are merged to week <code>'00'</code> prior to average computations.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotAnnualRegime">PlotAnnualRegime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Source data, HYPE basin output with a number of result variables
te &lt;- ReadBasinOutput(filename = system.file("demo_model", "results", "0003587.txt", 
package = "HYPEtools"))
# Daily discharge regime, computed and observed, hydrologigical year from October 
AnnualRegime(te[, c("DATE", "COUT", "ROUT")], ts.in = "day", start.mon = 10)
# Id., aggregated to weekly means
AnnualRegime(te[, c("DATE", "COUT", "ROUT")], ts.in = "day", ts.out = "week", start.mon = 10)
# Long format, e.g. for subsequent plotting with ggplot
AnnualRegime(te[, c("DATE", "COUT", "ROUT")], ts.in = "day", ts.out = "week", format = "long", 
start.mon = 10)
# Precipitation regime, monthly sums
AnnualRegime(te[, c("DATE", "UPCPRC")], ts.in = "day", ts.out = "month", stat = "sum")

</code></pre>

<hr>
<h2 id='BarplotUpstreamClasses'>Bar plots of upstream-averaged classes of HYPE sub-basins</h2><span id='topic+BarplotUpstreamClasses'></span>

<h3>Description</h3>

<p>Function to plot upstream-averaged landscape property classes of one or several sub-basins as bar plots, e.g.
land use or soils. Builds on <code><a href="graphics.html#topic+barplot">barplot</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BarplotUpstreamClasses(
  x,
  type = c("custom", "landuse", "soil", "crop"),
  desc = NULL,
  class.names = NULL,
  xlab = NULL,
  ylab = "Area fraction (%)",
  ylim = c(-0.05, max(x[, -1] * 150)),
  names.arg = rep("", ncol(x) - 1),
  cex.axis = 1,
  cex.names = 0.9,
  col = NULL,
  border = NA,
  legend.text = NULL,
  legend.pos = "left",
  pars = list(mar = c(1.5, 3, 0.5, 0.5) + 0.1, mgp = c(1.5, 0.3, 0), tcl = NA, xaxs =
    "i")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BarplotUpstreamClasses_+3A_x">x</code></td>
<td>
<p>Data frame, containing column-wise class group fractions with SUBIDs in first column. Typically a result
from <code><a href="#topic+UpstreamGroupSLCClasses">UpstreamGroupSLCClasses</a></code>. Column names of class group fractions <em>must</em> end with <code>_x</code>, with x giving the
class group ID, see details.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_type">type</code></td>
<td>
<p>Character string keyword for class group labeling, used in combination with <code>desc</code>. Type of class groups,
either <code>"landuse"</code>, <code>"soil"</code>, or <code>"crop"</code> (abbreviations allowed). If <code>"custom"</code> (default),  labeling can be fine-
tuned with argument <code>class.names</code>.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_desc">desc</code></td>
<td>
<p>List for use with <code>type</code>. Class description labels imported from a 'description.txt' file, for labeling of
standard class groups. See <code><a href="#topic+ReadDescription">ReadDescription</a></code> for formatting details.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_class.names">class.names</code></td>
<td>
<p>Character vector of class group names, with same length as number of class group fractions in <code>x</code>.
Specification of bar labels, alternative to arguments <code>type</code> and <code>desc</code>, in particular for cases where a non-standard
grouping was used for <code>x</code>.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_xlab">xlab</code></td>
<td>
<p>Character string, x-axis label, with defaults for standard groups land use, soil, and crops.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_ylab">ylab</code></td>
<td>
<p>Character string, y-axis label.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_ylim">ylim</code></td>
<td>
<p>Numeric, two element vector with limits for the y-axis. Defaults to values which give ample space for bar labels.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_names.arg">names.arg</code></td>
<td>
<p>Character vector, see <code><a href="graphics.html#topic+barplot">barplot</a></code>. Defaults to no labeling below bars (text labels within plot through
arguments above).</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_cex.axis">cex.axis</code></td>
<td>
<p>Numeric, character expansion factor for axis annotation and labels.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_cex.names">cex.names</code></td>
<td>
<p>Numeric, character expansion factor for class group labels.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_col">col</code></td>
<td>
<p>Colors for bars. Defaults to <code>type</code>-specific pre-defined color.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_border">border</code></td>
<td>
<p>Colors for bar borders. Defaults to no borders.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_legend.text">legend.text</code></td>
<td>
<p>Character, if provided, a legend will be plotted. Defaults to none if one sub-basin is plotted, and SUBIDs
if several sub-basins are plotted. Set to <code>NA</code> to prevent legend plotting in any case.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_legend.pos">legend.pos</code></td>
<td>
<p>Character keyword for legend positioning, most likely <code>"left"</code> or <code>"right"</code>. For details, see
<code><a href="graphics.html#topic+legend">legend</a></code>.</p>
</td></tr>
<tr><td><code id="BarplotUpstreamClasses_+3A_pars">pars</code></td>
<td>
<p>List of tagged values which are passed to <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>BarplotUpstreamClasses</code> is a wrapper for <code><a href="graphics.html#topic+barplot">barplot</a></code>, with vertical labels plotted over the class group bars.
Most arguments have sensible defaults, but can be adapted for fine-tuning if necessary.
</p>
<p>Column names of <code>x</code> are used to link class groups to class IDs in <code>desc</code>. HYPE has no formal
requirements on how class IDs are numbered and when one of the standard groups land use, soil, or crop are provided in <code>x</code>,
there might be missing class IDs. Class names in <code>desc</code> are matched against column name endings <code>'_x'</code> in <code>x</code>.
If manual names are provided in <code>class.names</code>, the column name endings must be a consecutive sequence from 1 to number of elements
in <code>class.names</code>.
</p>


<h3>Value</h3>

<p>The function returns bar midpoints, see description in <code><a href="graphics.html#topic+barplot">barplot</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+UpstreamGroupSLCClasses">UpstreamGroupSLCClasses</a></code>
<code><a href="graphics.html#topic+barplot">barplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import source data
te1 &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
te2 &lt;- ReadGeoClass(filename = system.file("demo_model", "GeoClass.txt", package = "HYPEtools"))
te3 &lt;- ReadDescription(filename = system.file("demo_model", "description.txt", 
                       package = "HYPEtools"))
# Calculate plot data, upstream soil fractions
te4 &lt;- UpstreamGroupSLCClasses(subid = 63794, gd = te1, gcl = te2, type = "soil")
# Function call
BarplotUpstreamClasses(x = te4, type = "s", desc = te4, ylim = c(0,100))

</code></pre>

<hr>
<h2 id='BoxplotSLCClasses'>Box plots of SLC distributions</h2><span id='topic+BoxplotSLCClasses'></span>

<h3>Description</h3>

<p><code>BoxplotSLCClasses</code> plots SLC class distributions for all SUBIDs in a GeoData data frame as boxplots. Boxes can represent distributions
of area fractions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BoxplotSLCClasses(
  gd,
  gcl,
  col.landuse = "rainbow",
  col.group = NULL,
  lab.legend = NULL,
  pos.legend = 1,
  abs.area = FALSE,
  log = "",
  ylim = NULL,
  range = 0,
  mar = c(3, 3, 1, 7) + 0.1,
  mgp = c(1.5, 0.2, 0),
  tcl = 0.1,
  xaxs = "i",
  xpd = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BoxplotSLCClasses_+3A_gd">gd</code></td>
<td>
<p>Data frame containing columns with SLC fractions, typically a 'GeoData.txt' file imported with <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_gcl">gcl</code></td>
<td>
<p>Data frame containing columns with SLCs and corresponding land use and soil class IDs, typically a 'GeoClass.txt'
file imported with <code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code>.</p>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_col.landuse">col.landuse</code></td>
<td>
<p>Specification of colors for box outlines, to represent land use classes. Either a keyword character string, or a vector of
colors with one element for each land use class as given in argument <code>gcl</code> in ascending order. Possible keywords are <code>'rainbow'</code> (default)
or <code>'auto'</code>. <code>'rainbow'</code> triggers a generation of land use class colors using the <code><a href="grDevices.html#topic+rainbow">rainbow</a></code> palette. <code>'auto'</code> triggers
generation of a pretty color palette with similar colors for land use groups. This option requires specification of land use groups in argument
<code>col.group</code>.</p>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_col.group">col.group</code></td>
<td>
<p>Integer vector of the same length as the number of land use classes given in <code>gcl</code>. Specifies a land use group ID for
each land use class ID, in ascending order. Groups and group IDs to use (in parentheses):
</p>

<ul>
<li><p> Water, snow, and ice (1)
</p>
</li>
<li><p> Urban (2)
</p>
</li>
<li><p> Forests (3)
</p>
</li>
<li><p> Agriculture and pastures (4)
</p>
</li>
<li><p> Natural non-forested (5)
</p>
</li></ul>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_lab.legend">lab.legend</code></td>
<td>
<p>Character string giving optional land use and soil class names to label the legend. Land use classes first, then soil classes.
Both following class IDs as given in <code>gcl</code> in ascending order.</p>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_pos.legend">pos.legend</code></td>
<td>
<p>Numeric, legend position in x direction. Given as position on the right hand outside of the plot area in x-axis units.</p>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_abs.area">abs.area</code></td>
<td>
<p>Logical, if <code>TRUE</code>, boxes will be plotted for absolute areas instead of area fractions.</p>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_log">log</code></td>
<td>
<p>Character string, passed to <code><a href="graphics.html#topic+boxplot">boxplot</a></code>. Empty string for linearly scaled axes, <code>'y'</code> for log scaled y-axis
(particularly in combination with <code>abs.area = TRUE</code>).</p>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_ylim">ylim</code></td>
<td>
<p>Numeric vector of length 2, y-axis minimum and maximum. Set automatically if not specified.</p>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_range">range</code></td>
<td>
<p>Argument to <code><a href="graphics.html#topic+boxplot">boxplot</a></code> with changed default. See documentation in there.</p>
</td></tr>
<tr><td><code id="BoxplotSLCClasses_+3A_mar">mar</code>, <code id="BoxplotSLCClasses_+3A_mgp">mgp</code>, <code id="BoxplotSLCClasses_+3A_tcl">tcl</code>, <code id="BoxplotSLCClasses_+3A_xaxs">xaxs</code>, <code id="BoxplotSLCClasses_+3A_xpd">xpd</code></td>
<td>
<p>Arguments passed to <code><a href="graphics.html#topic+par">par</a></code>. See documentation in there.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>BoxplotSLCClasses</code> allows to analyze the occurrence of individual SLCs in a given model set-up. both in terms of area fractions (SLC values)
and absolute areas. The function uses <code><a href="graphics.html#topic+boxplot">boxplot</a></code> to plot distributions of SLCs of all SUBIDs in a GeoData data frame. Land use classes
are color-coded, and soil classes marked by a point symbol below each box. Box whiskers extend to the data extremes.
</p>


<h3>Value</h3>

<p><code>BoxplotSLCClasses</code> returns a plot to the currently active plot device, and invisibly a data frame of SLC class fractions with <code>0</code>
values replaced by <code>NA</code>s. If absolute areas are plotted, these are returned in the data frame.
</p>


<h3>Note</h3>

<p>There is a maximum of 26 symbols available for marking soil classes. <code>BoxplotSLCClasses</code> can be quite crowded, depending on the number of SLCs
in a model set-up. Tested and recommended plot device dimensions are 14 x 7 inches (width x height), e.g.:
</p>
<p><kbd>&gt; x11(width = 14, height = 7)</kbd>
</p>
<p><kbd>&gt; png("mySLCdistri.png", width = 14, height = 7, units = "in", res = 600)</kbd>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import source data
te1 &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
te2 &lt;- ReadGeoClass(filename = system.file("demo_model", "GeoClass.txt", package = "HYPEtools"))
BoxplotSLCClasses(gd = te1, gcl = te2)

</code></pre>

<hr>
<h2 id='CleanSLCClasses'>Clean Soil-Landuse classes (SLCs) from small fractions</h2><span id='topic+CleanSLCClasses'></span>

<h3>Description</h3>

<p><code>CleanSLCClasses</code> attempts to clean small SLC fractions within each SUBID (sub-catchment) from an imported GeoData file using user-provided
area thresholds. Cleaning can be performed along class similarity rules or along SLC area alone.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CleanSLCClasses(
  gd,
  gcl,
  m1.file = NULL,
  m1.class = "s",
  m1.clean = rep(TRUE, 2),
  m1.precedence = rep(TRUE, 2),
  m2.frac = NULL,
  m2.abs = NULL,
  signif.digits = 3,
  verbose = TRUE,
  progbar = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CleanSLCClasses_+3A_gd">gd</code></td>
<td>
<p>Data frame containing columns with SUBIDs, SUBID areas in m^2, and SLC fractions, typically a 'GeoData.txt' file
imported with <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_gcl">gcl</code></td>
<td>
<p>Data frame containing columns with SLCs and corresponding land use and soil class IDs, typically a 'GeoClass.txt'
file imported with <code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code>.</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_m1.file">m1.file</code></td>
<td>
<p>Character string, path and file name of the soil or land use class transfer table, a tab-separated text file. Format see details.
A value of <code>NULL</code> (default) prevents method 1 cleaning.</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_m1.class">m1.class</code></td>
<td>
<p>Character string, either &quot;soil&quot; or &quot;landuse&quot;, can be abbreviated. Gives the type of transfer class table for method 1 cleaning.
See Details.</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_m1.clean">m1.clean</code></td>
<td>
<p>A logical vector of length 2 which indicates if cleaning should be performed for area fraction thresholds (position 1) and/or
absolute area thresholds (position 2).</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_m1.precedence">m1.precedence</code></td>
<td>
<p>A logical vector of length 2 which indicates if areas below cleaning threshold should be moved to similar areas according to
precedence in the transfer table given in <code>m1.file</code> (<code>TRUE</code>) or to the largest area of available transfer classes (<code>FALSE</code>). Area
fraction thresholds (position 1) and absolute area thresholds (position 2).</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_m2.frac">m2.frac</code></td>
<td>
<p>Numeric, area fraction threshold for method 2 cleaning, i.e. moving of small SLC areas to largest SLC in each SUBID without considering
similarity between classes. Either a single value or a vector of the same length as the number of SLC classes in <code>gd</code>, giving area fraction
thresholds for each SLC separately, with a value <code>0</code> for SLCs to omit from cleaning. A value of <code>NULL</code> (default) prevents method 2 area
fraction cleaning.</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_m2.abs">m2.abs</code></td>
<td>
<p>Numeric, see <code>m2.frac</code>. Threshold(s) for absolute areas in <code class="reqn">m^{2}</code>.</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_signif.digits">signif.digits</code></td>
<td>
<p>Integer, number of significant digits to round cleaned SLCs to. See also <code><a href="base.html#topic+signif">signif</a></code>. Set to <code>NULL</code> to prevent rounding.</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_verbose">verbose</code></td>
<td>
<p>Logical, print some information during runtime.</p>
</td></tr>
<tr><td><code id="CleanSLCClasses_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while calculating SLC class fractions. Adds overhead to calculation time but useful when <code>subid</code>
is <code>NULL</code> or contains many SUBIDs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>CleanSLCClasses</code> performs a clean-up of small SLC fractions in an imported GeoData file. Small SLCs are eliminated either by moving their
area to similar classes according to rules which are passed to the function in a text file (<em>Method 1</em>), or by simply moving their area to the
largest SLC in the SUBID (<em>Method 2</em>). Moving rules for the first method can be based on either soil classes or land use classes but these cannot
be combined in one function call. Run the function two times to combine soil and land use based clean-up. Method 1 and 2, however, can be combined
in one function call, in which case the rule-based classification will be executed first. Clean-up precedence in method 1: if
clean-ups based on area fractions and absolute areas are combined (<code>m1.clean = rep(TRUE, 2)</code>), then area fractions will be cleaned first. In
order to reverse precedence, call <code>CleanSLCClasses</code> two times with absolute area cleaning activated in first call and area fraction cleaning
in second. In both methods, SLCs in each SUBID are cleaned iteratively in numerical order, starting with SLC_1. This implies a greater likelihood of
eliminating SLCs with smaller indices.
</p>
<p><b>Method 1</b>
</p>
<p>For method one, small SLC fractions are moved to either similar land use classes within the same soil class, or vice versa. Similarities are
defined by the user in a tab-separated text file, which is read by <code>CleanSLCClasses</code> during runtime. Soil and land use classes correspond to
the classes given in column two and three in the <code>GeoClass</code> file. The file must have the following format:
</p>

<table>
<tr>
 <td style="text-align: center;">
<em>class.1</em></td><td style="text-align: center;"><em>thres.frac.1</em></td><td style="text-align: center;"><em>thres.abs.1</em></td><td style="text-align: center;"><em>transfer.1</em></td><td style="text-align: center;"><em>...</em></td><td style="text-align: center;"><em>transfer.n</em></td>
</tr>
<tr>
 <td style="text-align: center;">
<em>class.2</em></td><td style="text-align: center;"><em>thres.frac.2</em></td><td style="text-align: center;"><em>thres.abs.2</em></td><td style="text-align: center;"><em>transfer.1</em></td><td style="text-align: center;"><em>...</em></td><td style="text-align: center;"><em>transfer.o</em></td>
</tr>
<tr>
 <td style="text-align: center;">
<em>...</em></td><td style="text-align: center;"><em>...</em></td><td style="text-align: center;"><em>...</em></td><td style="text-align: center;"><em>...</em></td><td style="text-align: center;"><em>...</em></td><td style="text-align: center;"><em>...</em></td>
</tr>
<tr>
 <td style="text-align: center;">
<em>class.m</em></td><td style="text-align: center;"><em>thres.frac.m</em></td><td style="text-align: center;"><em>thres.abs.m</em></td><td style="text-align: center;"><em>transfer.1</em></td><td style="text-align: center;"><em>...</em></td><td style="text-align: center;"><em>transfer.p</em></td>
</tr>
<tr>
 <td style="text-align: center;">
</td>
</tr>

</table>

<p>Column 1 contains the source land use or soil classes subjected to clean-up, columns 2 and 3 contain threshold values for area fractions and
absolute areas. The remaining columns contain classes to which areas below threshold will be transferred, in order of precedence. Each class can
have one or several transfer classes. <code>CleanSLCClasses</code> will derive SLC classes to clean from the given soil or land use class using the
GeoClass table given in argument <code>gcl</code>.
No header is allowed. At least one transfer class must exist, but classes can be omitted and will then be ignored by <code>CleanSLCClasses</code>.
The order of transfer classes in the transfer file indicates transfer preference. <code>CleanSLCClasses</code> constructs a transfer list for each SLC
class in the model set-up and per default uses the order to choose a preferred SLC to transfer to. However, if several SLCs exist for a given soil
or land use class, one of them will be chosen without further sorting. If argument <code>m1.precedence</code> is set to <code>FALSE</code> for either area
fractions or absolute areas, precedence will be ignored and the largest area available will be chosen to transfer small areas to. Area fraction
thresholds are given as fractions of 1, absolute area thresholds as values in <code class="reqn">m^{2}</code>. If an area below threshold is identified but there
are no fitting SLCs available to transfer to, the area will remain unchanged.
</p>
<p><b>Method 2</b>
</p>
<p>This method is more rigid than method one and can also be applied as a post-processor after clean-up using method 1 to force a removal of all SLCs
below a given threshold from a GeoData file (method 1 cleaning can be be very selective, depending on how many transfer classes are provided in
the transfer table). Cleaning thresholds for method 2 area fractions and absolute areas are given in arguments <code>m2.frac</code> and <code>m2.abs</code>.
SLC areas below the given thresholds will be moved to the largest SLC in the given SUBID without considering any similarity between classes.
</p>


<h3>Value</h3>

<p><code>CleanSLCClasses</code> returns the GeoData data frame passed to the function in argument <code>gd</code> with cleaned SLC class columns.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RescaleSLCClasses">RescaleSLCClasses</a></code> for re-scaling of SLC area fraction sums.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import source data
te1 &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
te2 &lt;- ReadGeoClass(filename = system.file("demo_model", "GeoClass.txt", package = "HYPEtools"))
# Clean-up using method 2, 0.5 % area fraction threshold and 100 m^2 absolute area threshold
te3 &lt;- CleanSLCClasses(gd = te1, gcl = te2, m2.frac = 0.005, m2.abs = 100)
# Detailed comparison with function CompareFiles
te4 &lt;- CompareFiles(te1, te3, type = "GeoData")
te4

</code></pre>

<hr>
<h2 id='CompareFiles'>Compare HYPE model files to identify any differences.</h2><span id='topic+CompareFiles'></span>

<h3>Description</h3>

<p>Compare HYPE model files to identify any differences, typically used to check that no undesired changes were made when writing a new file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CompareFiles(
  x,
  y,
  type,
  by = NULL,
  compare.order = TRUE,
  threshold = 1e-10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CompareFiles_+3A_x">x</code></td>
<td>
<p>Path to a HYPE model file to read, or an existing list/data frame object for a HYPE model file.
File contents are compared to those of <code>y</code>.</p>
</td></tr>
<tr><td><code id="CompareFiles_+3A_y">y</code></td>
<td>
<p>Path to a HYPE model file to read, or an existing list/data frame object for a HYPE model file.
File contents are compared to those of <code>x</code>.</p>
</td></tr>
<tr><td><code id="CompareFiles_+3A_type">type</code></td>
<td>
<p>Character string identifying the type of HYPE model file. Used to determine appropriate read function. One of
<code>AquiferData</code>, <code>BasinOutput</code>, <code>BranchData</code>, <code>CropData</code>, <code>DamData</code>, <code>ForcKey</code>, <code>GeoClass</code>,
<code>GeoData</code>, <code>Info</code>, <code>LakeData</code>, <code>MapOutput</code>, <code>MgmtData</code>, <code>Optpar</code>, <code>Par</code>, <code>PointSourceData</code>, <code>Obs</code>,
<code>Simass</code>, <code>Subass</code>, <code>TimeOutput</code>, or <code>Xobs</code>.</p>
</td></tr>
<tr><td><code id="CompareFiles_+3A_by">by</code></td>
<td>
<p>Character vector, names of columns in <code>x</code> and <code>y</code> to use to join data. See <code><a href="dplyr.html#topic+mutate-joins">dplyr::full_join()</a></code>.</p>
</td></tr>
<tr><td><code id="CompareFiles_+3A_compare.order">compare.order</code></td>
<td>
<p>Logical, whether or not the order of the rows should be compared. If <code>TRUE</code>, then <code>x</code> and <code>y</code>
will also be joined by row number. See <code><a href="dplyr.html#topic+full_join">full_join</a></code>.</p>
</td></tr>
<tr><td><code id="CompareFiles_+3A_threshold">threshold</code></td>
<td>
<p>Numeric, threshold difference for comparison of numeric values. Set to 0 to only accept identical values.</p>
</td></tr>
<tr><td><code id="CompareFiles_+3A_...">...</code></td>
<td>
<p>Other arguments passed on to functions to read the files to compare (e.g. <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>, <code><a href="#topic+ReadPar">ReadPar</a></code>, etc.).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>CompareFiles</code> compares two HYPE model files and identifies any differences in values. The function reads two model files, compares
the values in columns with corresponding names, and returns a data frame consisting of rows/columns with any differences. Values that are
the same in both files are set to <code>NA</code>. If numeric values in two columns aren't exactly the same, then the difference between the values will be taken
and compare to <code>theshold</code>. If the difference is &lt;= <code>theshold</code>, then the values will be considered the equal and set to <code>NA</code>.
The function is primarily intended as a check to ensure that no unintended changes were made when writing
model files using the various HYPEtools write functions. However, it can also be used to e.g. compare files between different model versions.
</p>


<h3>Value</h3>

<p>Returns invisibly a data frame containing rows and columns in which differences exist between <code>x</code> and <code>y</code>. Values that are the same in both
files are set to <code>NA</code>. If the returned data frame has 0 row, then there were no differences between the files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import demo model GeoData file, edit a SUBID
te1 &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
te1$SUBID[1] &lt;- 1
# Compare with original file
te2 &lt;- CompareFiles(system.file("demo_model", "GeoData.txt", package = "HYPEtools"), te1, 
                    type = "GeoData")
te2

</code></pre>

<hr>
<h2 id='ConvertDischarge'>Calculate Specific runoff from volumetric discharge and vice versa</h2><span id='topic+ConvertDischarge'></span>

<h3>Description</h3>

<p><code>ConvertDischarge</code> converts volumetric discharge to specific discharge (unit area discharge) and vice versa.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ConvertDischarge(q, area, from = "m3s", to = "mmd")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ConvertDischarge_+3A_q">q</code></td>
<td>
<p>An object of type <code>numeric</code>, containing volumetric or specific discharge values,
typically HYPE variables COUT or ROUT.</p>
</td></tr>
<tr><td><code id="ConvertDischarge_+3A_area">area</code></td>
<td>
<p>An object of type <code>numeric</code>, containing a catchment area in <code class="reqn">m^2</code>.</p>
</td></tr>
<tr><td><code id="ConvertDischarge_+3A_from">from</code></td>
<td>
<p>Character string keyword, giving the current unit of <code>q</code>. Either a specific discharge, one of:
</p>
<p><code>"mmy"</code> (<code class="reqn">mm y^{-1}</code>)
</p>
<p><code>"mmd"</code> (<code class="reqn">mm d^{-1}</code>)
</p>
<p><code>"mmh"</code> (<code class="reqn">mm h^{-1}</code>),
</p>
<p>or a volumetric discharge, one of:
</p>
<p><code>"m3s"</code> (<code class="reqn">m^3 s^{-1}</code>)
</p>
<p><code>"ls"</code> (<code class="reqn">l s^{-1}</code>).</p>
</td></tr>
<tr><td><code id="ConvertDischarge_+3A_to">to</code></td>
<td>
<p>Character string keyword, see <code>from</code>. Conversion will not work between units within volumetric or specific discharge groups.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ConvertDischarge</code> is a simple conversion function, most likely to be used in combination with <code><a href="base.html#topic+apply">apply</a></code>
or related functions.
</p>


<h3>Value</h3>

<p><code>ConvertDischarge</code> returns a numeric object of the same type as provided in argument <code>q</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ConvertDischarge(6, 400000000)
ConvertDischarge(c(1.1, 1.2, 1.9, 2.8, 2, 1.5, 1.3, 1.2, 1.15, 1.1), 
                 from = "mmd", to = "ls", area = 1.2e6)
</code></pre>

<hr>
<h2 id='CreateOptpar'>Create an optpar list</h2><span id='topic+CreateOptpar'></span>

<h3>Description</h3>

<p><code>CreateOptpar</code> creates a list representing a HYPE optpar.txt file from an imported par.txt file
and a selection of parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CreateOptpar(
  x,
  pars,
  tasks = data.frame(character(), character()),
  comment = "",
  fun.ival = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CreateOptpar_+3A_x">x</code></td>
<td>
<p>a list with named vector elements, as an object returned from <code><a href="#topic+ReadPar">ReadPar</a></code>.</p>
</td></tr>
<tr><td><code id="CreateOptpar_+3A_pars">pars</code></td>
<td>
<p>Character vector with HYPE parameter names to be included in optpar list. Parameters must
exist in <code>x</code>. Not case-sensitive. For a complete list of HYPE parameters, see the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:par.txt">par.txt online documentation</a>.</p>
</td></tr>
<tr><td><code id="CreateOptpar_+3A_tasks">tasks</code></td>
<td>
<p>Data frame with two columns providing optimization tasks and settings (key-value pairs) as
described in the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:optpar.txt">optpar.txt online documentation</a>.
Defaults to an empty task section.</p>
</td></tr>
<tr><td><code id="CreateOptpar_+3A_comment">comment</code></td>
<td>
<p>Character string, comment (first row in optpar.txt file).</p>
</td></tr>
<tr><td><code id="CreateOptpar_+3A_fun.ival">fun.ival</code></td>
<td>
<p>Either <code>NULL</code> (default), or a function with a single argument. See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>CreateOptpar</code> makes it a bit more convenient to compose a HYPE optimization file. The function creates a template
with all parameters to be included in an optimization run.
</p>
<p>Parameter boundaries for individual classes have to be adapted after creation of the template, the function takes the
existing parameter value(s) in <code>x</code> as upper and lower boundaries.
</p>
<p>Parameter step width intervals (third parameter rows in optpar.txt files) are calculated with an internal function
which per default returns the nearest single 1/1000th of the parameter value, with conditional replacement of '0' intervals:
</p>
<pre>function(x) {
  res &lt;- 10^floor(log10(x/1000))
  ifelse(res == 0, .1, res)
}</pre>
<p>Alternative functions can be passed to <code>CreateOptpar</code> using argument <code>fun.ival</code>. Such functions must have a
single argument <code>x</code>, which represents the parameter value taken from argument <code>x</code>. The function is applied to
all parameters in the resulting optpar list.
</p>


<h3>Value</h3>

<p>The function returns a list with elements as described in <code><a href="#topic+ReadOptpar">ReadOptpar</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadOptpar">ReadOptpar</a></code> <code><a href="#topic+WriteOptpar">WriteOptpar</a></code> <code><a href="#topic+OptimisedClasses">OptimisedClasses</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import a HYPE parameter file
te1 &lt;- ReadPar(filename = system.file("demo_model", "par.txt", package = "HYPEtools"))
# Create optimization parameters for a Monte Carlo run with 1000 iterations
te2 &lt;- data.frame(key = c("task", "num_mc", "task"), value = c("MC", 1000, "WS"))
# Create an optpar file structure for HYPE recession coefficients
te3 &lt;- CreateOptpar(x = te1, pars = c("rrcs1", "rrcs2"), tasks = te2)
te3

</code></pre>

<hr>
<h2 id='CustomColors'>Custom color ramp palettes</h2><span id='topic+CustomColors'></span><span id='topic+ColNitr'></span><span id='topic+ColPhos'></span><span id='topic+ColPrec'></span><span id='topic+ColTemp'></span><span id='topic+ColQ'></span><span id='topic+ColDiffTemp'></span><span id='topic+ColDiffGeneric'></span><span id='topic+ColBlues'></span><span id='topic+ColReds'></span><span id='topic+ColGreens'></span><span id='topic+ColYOB'></span><span id='topic+ColPurples'></span>

<h3>Description</h3>

<p>Pre-defined color ramp palettes which are used in other <code>HYPEtools</code> functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ColNitr(n)

ColPhos(n)

ColPrec(n)

ColTemp(n)

ColQ(n)

ColDiffTemp(n)

ColDiffGeneric(n)

ColBlues(n)

ColReds(n)

ColGreens(n)

ColYOB(n)

ColPurples(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CustomColors_+3A_n">n</code></td>
<td>
<p>Integer, number of colors to generate.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions build on calls to <code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code>.
</p>


<h3>Value</h3>

<p>All functions return vectors of length <code>n</code> with interpolated RGB color values in hexadecimal
notation (see <code><a href="grDevices.html#topic+rgb">rgb</a></code>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ColNitr(10)
ColGreens(6)
barplot(rep(1, 11), col = ColTemp(11))

</code></pre>

<hr>
<h2 id='DirectUpstreamSubids'>Find Direct Upstream SUBIDs, with Flow Fractions</h2><span id='topic+DirectUpstreamSubids'></span>

<h3>Description</h3>

<p>Function to find <b>direct</b> upstream SUBIDs including flow fractions for MAINDOWN/BRANCHDOWN splits for a single
sub-catchment or all sub-catchments in a GeoData-like data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DirectUpstreamSubids(subid = NULL, gd, bd = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DirectUpstreamSubids_+3A_subid">subid</code></td>
<td>
<p>Integer, SUBID of a target sub-catchment (must exist in <code>gd</code>), defaults to
<code>NULL</code>. If non-<code>NULL</code>, <code>DirectUpstreamSubids</code>
returns the direct upstream SUBIDs for this sub-catchment, otherwise for all sub-catchments in <code>gd</code>.</p>
</td></tr>
<tr><td><code id="DirectUpstreamSubids_+3A_gd">gd</code></td>
<td>
<p>Data frame, typically an imported 'GeoData.txt' file. Mandatory argument. See 'Details'.</p>
</td></tr>
<tr><td><code id="DirectUpstreamSubids_+3A_bd">bd</code></td>
<td>
<p>Data frame, typically an imported 'BranchData.txt' file. Optional argument, defaults to
an empty placeholder. See 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>DirectUpstreamSubids</code> identifies <b>direct</b> upstream SUBIDs for a user-provided target SUBID or
for all SUBIDs given in a data frame <code>gd</code>, typically an imported GeoData file.
</p>
<p>A sub-catchment in HYPE can have several upstream sub-catchments. If there are more than one upstream sub-catchments,
the downstream sub-catchment is a confluence. HYPE stores these connections in the GeoData file, in downstream direction,
given as downstream SUBID in column 'MAINDOWN'. Bifurcations, i.e. splits in downstream direction, are also possible to model in HYPE.
These additional downstream connections are provided in the BranchData file, together with flow fractions to each downstream SUBID.
</p>
<p>Formally, <code>gd</code> can be any data frame which contains columns 'SUBID' and 'MAINDOWN' (not case-sensitive), and <code>bd</code> any
data frame which contains three columns: 'BRANCHID', 'SOURCEID', and 'MAINPART', and optionally columns 'MAXQMAIN', 'MINQMAIN', 'MAXQBRANCH'.
Typically, these are HYPE data files
imported through <code><a href="#topic+ReadGeoData">ReadGeoData</a></code> and <code><a href="#topic+ReadBranchData">ReadBranchData</a></code>. See HYPE documentation for further details on connections
Between SUBIDs in the model.
</p>


<h3>Value</h3>

<p><code>DirectUpstreamSubids</code> always returns a <a href="base.html#topic+list">list</a>. If argument <code>subid</code> is non-<code>NULL</code>, a list with two elements is returned:
<code>subid</code> contains an integer giving the target SUBID and <code>upstr.df</code> contains a data frame with columns
<code>upstream</code> (upstream SUBID), <code>is.main</code> (logical, <code>TRUE</code> if it is a MAINDOWN connection),
<code>fraction</code> (fraction of flow going into the target SUBID), and <code>llim</code> and <code>ulim</code> giving upper and lower flow boundaries which
optionally limit flow into the target SUBID.
</p>
<p>If no specific SUBID was provided, <code>DirectUpstreamSubids</code> returns a list with upstream information for all SUBIDs in argument
<code>gd</code>, each list element containing the list described above, i.e. with an integer element (SUBID) and a data frame element
(upstream connections).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids</a></code>, which returns all upstream SUBIDs, i.e. the full upstream network up to the headwaters, for a given SUBID.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
DirectUpstreamSubids(subid = 3594, gd = te)

</code></pre>

<hr>
<h2 id='distinctColorPalette'>Generate optimally distinct color palettes</h2><span id='topic+distinctColorPalette'></span>

<h3>Description</h3>

<p><code>distinctColorPalette</code> generates an attractive palette of random colors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distinctColorPalette(count = 1, seed = NULL, darken = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="distinctColorPalette_+3A_count">count</code></td>
<td>
<p>Integer, number of colors (&gt;= 1). May be ineffective for count &gt; 40.</p>
</td></tr>
<tr><td><code id="distinctColorPalette_+3A_seed">seed</code></td>
<td>
<p>Integer, seed number to produce repeatable palettes.</p>
</td></tr>
<tr><td><code id="distinctColorPalette_+3A_darken">darken</code></td>
<td>
<p>Numeric specifying the amount of darkening applied to the color palette. See <code><a href="colorspace.html#topic+darken">darken</a></code>.
Negative values will lighten the palette.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adapted from the randomcoloR package <a href="https://cran.r-project.org/package=randomcoloR">https://cran.r-project.org/package=randomcoloR</a>.
</p>


<h3>Value</h3>

<p><code>distinctColorPalette</code> returns a character vector of <code>count</code> optimally distinct colors in hexadecimal codes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>distinctColorPalette()
</code></pre>

<hr>
<h2 id='EquallySpacedObs'>Create an equally spaced time series from irregular observations</h2><span id='topic+EquallySpacedObs'></span>

<h3>Description</h3>

<p><code>EquallySpacedObs</code> creates equally spaced time series with missing observations from a data frame with irregular
observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EquallySpacedObs(x, sort.data = TRUE, timestep, ts.col = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EquallySpacedObs_+3A_x">x</code></td>
<td>
<p>A <code>data.frame</code>, with a date-time column in <code><a href="base.html#topic+POSIXt">POSIXt</a></code> or
<code><a href="base.html#topic+Date">Date</a></code> format, and one or several columns with observed variables.</p>
</td></tr>
<tr><td><code id="EquallySpacedObs_+3A_sort.data">sort.data</code></td>
<td>
<p>Logical, if <code>TRUE</code>, <code>x</code> will be sorted by date-time.</p>
</td></tr>
<tr><td><code id="EquallySpacedObs_+3A_timestep">timestep</code></td>
<td>
<p>Character string keyword, giving the target time step length. Either <code>"day"</code> or <code>"hour"</code>.</p>
</td></tr>
<tr><td><code id="EquallySpacedObs_+3A_ts.col">ts.col</code></td>
<td>
<p>Integer, column index of datetime column.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>EquallySpacedObs</code> will preserve additional attributes present in <code>x</code>. If datetime column is of class
<code><a href="base.html#topic+Date">Date</a></code>, there may occur problems with daylight saving time shifts. To avoid problems, use class
<code><a href="base.html#topic+POSIXct">POSIXct</a></code> and set time zone to <code>"UTC"</code>.
</p>


<h3>Value</h3>

<p><code>EquallySpacedObs</code> returns a dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- data.frame(date = as.POSIXct(c("2000-01-01", "2000-02-01"), tz = "gmt"), obs = c(1, 2))
EquallySpacedObs(x = te, timestep = "day")

</code></pre>

<hr>
<h2 id='ExtractFreq'>Extract quantiles for use in a frequency distribution plot, e.g. a flow duration curve</h2><span id='topic+ExtractFreq'></span>

<h3>Description</h3>

<p>This function calculates quantiles suitable for duration curves of environmental time series data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExtractFreq(
  data,
  probs = c(0, 1e-05, 1e-04, 0.001, seq(0.01, 0.99, by = 0.01), 0.999, 0.9999, 0.99999,
    1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ExtractFreq_+3A_data">data</code></td>
<td>
<p>either a numeric vector or an all-numeric dataframe (<code>NA</code>s allowed) which holds the variables for which
quantiles are computed.</p>
</td></tr>
<tr><td><code id="ExtractFreq_+3A_probs">probs</code></td>
<td>
<p>numeric, vector of probabilities as in <code><a href="stats.html#topic+quantile">quantile</a></code> with default suitable for flow duration curves.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ExtractFreq</code> is a convenience wrapper function, it uses <code><a href="stats.html#topic+quantile">quantile</a></code> to calculate the quantiles
of one or more time series with a density appropriate for duration curves.
<code>NA</code>s are allowed in the input data. For the results to be meaningful, input should represent equally-spaced time series,
e.g. HYPE basin output files.
</p>


<h3>Value</h3>

<p><code>ExtractFreq</code> returns a dataframe with probabilities in the first column, and quantiles of data in the following columns.
Number of observations per variable in <code>data</code> are given in an attribute <code>n.obs</code> (see <code><a href="base.html#topic+attributes">attributes</a></code>).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotDurationCurve">PlotDurationCurve</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ExtractFreq(rnorm(1000))

</code></pre>

<hr>
<h2 id='ExtractStats'>Extract statistics from time series</h2><span id='topic+ExtractStats'></span>

<h3>Description</h3>

<p>Calculate aggregated statistics from long-term time series, typically imported HYPE time output files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ExtractStats(
  x,
  start.mon = 1,
  aggperiod = c("year", "season1", "season2", "month"),
  timestep = attr(x, "timestep"),
  subid = attr(x, "subid"),
  FUN,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ExtractStats_+3A_x">x</code></td>
<td>
<p>Data frame, with column-wise equally-spaced time series. Date-times in <code><a href="base.html#topic+POSIXct">POSIXct</a></code> format in first column.
Typically an imported time output file from HYPE.</p>
</td></tr>
<tr><td><code id="ExtractStats_+3A_start.mon">start.mon</code></td>
<td>
<p>Integer between 1 and 12, starting month of the hydrological year.</p>
</td></tr>
<tr><td><code id="ExtractStats_+3A_aggperiod">aggperiod</code></td>
<td>
<p>Character string, timestep for aggregated results. One of <code>"year"</code> for annual statistics,
<code>"season1"</code> (winter/summer half-years), <code>"season2"</code> (4 seasons), or <code>"month"</code>. See details.</p>
</td></tr>
<tr><td><code id="ExtractStats_+3A_timestep">timestep</code></td>
<td>
<p>Character string, timestep of data in <code>x</code>. Attribute <code>timestep</code> in <code>x</code> per default.
Otherwise one of <code>"month"</code> (not allowed with <code>aggperiod = "month"</code>), <code>"week"</code>, <code>"day"</code>, or
<code>"nhour"</code> (n = number of hours).</p>
</td></tr>
<tr><td><code id="ExtractStats_+3A_subid">subid</code></td>
<td>
<p>Integer, a vector of HYPE subbasin IDs for data in <code>x</code>. Attribute <code>subid</code> in <code>x</code> per default.</p>
</td></tr>
<tr><td><code id="ExtractStats_+3A_fun">FUN</code></td>
<td>
<p>A function to compute for each <code>aggperiod</code> in <code>x</code>.</p>
</td></tr>
<tr><td><code id="ExtractStats_+3A_...">...</code></td>
<td>
<p>Optional arguments to <code>FUN</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ExtractStats</code> uses <code><a href="stats.html#topic+aggregate">aggregate</a></code> to calculate statistics for all data columns provided in <code>x</code>. Argument
<code>start.mon</code> allows to define the start of the hydrological year. Hydrological seasons begin with winter (season1) or
autumn (season2).
</p>


<h3>Value</h3>

<p><code>ExtractStats</code> returns a dataframe with starting dates for each aggregation period in the first column, and a descriptive
aggregation period name in the second. Remaining columns contain aggregated results as ordered in <code>x</code>. Additional attributes
<code>subid</code> with subbasin IDs, <code>timestep</code> with time step of the source data, and <code>period</code> with a two-element POSIXct vector
containing start and end dates of the source data.
</p>


<h3>Note</h3>

<p>If <code>FUN</code> returns several values per aggregation period, these are returned in nested columns in the resulting dataframe. See
<code>Value</code> section for <code><a href="stats.html#topic+aggregate">aggregate</a></code> and example code below.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import example data
te1 &lt;- ReadTimeOutput(filename = system.file("demo_model", "results",
"timeCOUT.txt", package = "HYPEtools"), dt.format = "%Y-%m")
# Extract maxima
ExtractStats(x = te1, start.mon = 1, FUN = max)
# Multiple result stats: Extract min, mean, and max in one go:
te2 &lt;- ExtractStats(x = te1, start.mon = 1,
FUN = function(x) {c(min(x), mean(x), max(x))})
# extract mean from resulting nested dataframe:
data.frame(te2[, 1:2], sapply(te2[, -c(1:2)], function(x){x[, 2]}))

</code></pre>

<hr>
<h2 id='GOF'>Goodness of Fit Functions</h2><span id='topic+GOF'></span><span id='topic+gof'></span><span id='topic+gof.default'></span><span id='topic+valindex'></span><span id='topic+valindex.default'></span><span id='topic+rPearson'></span><span id='topic+rPearson.default'></span><span id='topic+sKGE'></span><span id='topic+sKGE.default'></span><span id='topic+KGE'></span><span id='topic+KGE.default'></span><span id='topic+NSE'></span><span id='topic+NSE.default'></span><span id='topic+pbias'></span><span id='topic+pbias.default'></span><span id='topic+mae'></span><span id='topic+mae.default'></span><span id='topic+VE'></span><span id='topic+VE.default'></span>

<h3>Description</h3>

<p>Numerical goodness-of-fit measures between sim and obs, with treatment of missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gof(sim, obs, ...)

## Default S3 method:
gof(
  sim,
  obs,
  na.rm = TRUE,
  do.spearman = FALSE,
  s = c(1, 1, 1),
  method = c("2009", "2012"),
  start.month = 1,
  digits = 2,
  fun = NULL,
  ...,
  epsilon.type = c("none", "Pushpalatha2012", "otherFactor", "otherValue"),
  epsilon.value = NA
)

valindex(sim, obs, ...)

## Default S3 method:
valindex(sim, obs, ...)

rPearson(sim, obs, ...)

## Default S3 method:
rPearson(
  sim,
  obs,
  fun = NULL,
  ...,
  epsilon.type = c("none", "Pushpalatha2012", "otherFactor", "otherValue"),
  epsilon.value = NA
)

sKGE(sim, obs, ...)

## Default S3 method:
sKGE(
  sim,
  obs,
  s = c(1, 1, 1),
  na.rm = TRUE,
  method = c("2009", "2012"),
  start.month = 1,
  out.PerYear = FALSE,
  fun = NULL,
  ...,
  epsilon.type = c("none", "Pushpalatha2012", "otherFactor", "otherValue"),
  epsilon.value = NA
)

KGE(sim, obs, ...)

## Default S3 method:
KGE(
  sim,
  obs,
  s = c(1, 1, 1),
  na.rm = TRUE,
  method = c("2009", "2012", "2021"),
  out.type = c("single", "full"),
  fun = NULL,
  ...,
  epsilon.type = c("none", "Pushpalatha2012", "otherFactor", "otherValue"),
  epsilon.value = NA
)

NSE(sim, obs, ...)

## Default S3 method:
NSE(
  sim,
  obs,
  na.rm = TRUE,
  fun = NULL,
  ...,
  epsilon.type = c("none", "Pushpalatha2012", "otherFactor", "otherValue"),
  epsilon.value = NA
)

pbias(sim, obs, ...)

## Default S3 method:
pbias(
  sim,
  obs,
  na.rm = TRUE,
  dec = 1,
  fun = NULL,
  ...,
  epsilon.type = c("none", "Pushpalatha2012", "otherFactor", "otherValue"),
  epsilon.value = NA
)

mae(sim, obs, ...)

## Default S3 method:
mae(
  sim,
  obs,
  na.rm = TRUE,
  fun = NULL,
  ...,
  epsilon.type = c("none", "Pushpalatha2012", "otherFactor", "otherValue"),
  epsilon.value = NA
)

VE(sim, obs, ...)

## Default S3 method:
VE(
  sim,
  obs,
  na.rm = TRUE,
  fun = NULL,
  ...,
  epsilon.type = c("none", "Pushpalatha2012", "otherFactor", "otherValue"),
  epsilon.value = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GOF_+3A_sim">sim</code></td>
<td>
<p>numeric, vector of simulated values</p>
</td></tr>
<tr><td><code id="GOF_+3A_obs">obs</code></td>
<td>
<p>numeric, vector of observed values</p>
</td></tr>
<tr><td><code id="GOF_+3A_...">...</code></td>
<td>
<p>further arguments passed to/from other methods.</p>
</td></tr>
<tr><td><code id="GOF_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether 'NA' should be stripped before the computation proceeds.
When an 'NA' value is found at the i-th position in obs OR sim, the i-th value of obs AND sim are removed before the computation.</p>
</td></tr>
<tr><td><code id="GOF_+3A_do.spearman">do.spearman</code></td>
<td>
<p>logical, indicates if the Spearman correlation should be computed. The default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="GOF_+3A_s">s</code></td>
<td>
<p>argument passed to the <code><a href="#topic+KGE">KGE</a></code> function.</p>
</td></tr>
<tr><td><code id="GOF_+3A_method">method</code></td>
<td>
<p>argument passed to the <code><a href="#topic+KGE">KGE</a></code> function.</p>
</td></tr>
<tr><td><code id="GOF_+3A_start.month">start.month</code></td>
<td>
<p>argument passed to the <code><a href="#topic+sKGE">sKGE</a></code> function.</p>
</td></tr>
<tr><td><code id="GOF_+3A_digits">digits</code></td>
<td>
<p>integer, numer of decimal places used for rounding the goodness of fit indexes.</p>
</td></tr>
<tr><td><code id="GOF_+3A_fun">fun</code></td>
<td>
<p>function to be applied to <code>sim</code> and <code>obs</code> in order to obtain transformed values thereof before applying any goodness-of-fit function</p>
</td></tr>
<tr><td><code id="GOF_+3A_epsilon.type">epsilon.type</code></td>
<td>
<p>argument used to define a numeric value to be added to both <code>sim</code> and <code>obs</code> before applying fun. It was designed to allow the use of
logarithm and other similar functions that do not work with zero values. It must be one of the following possible values:
</p>

<ul>
<li><p><em>none</em>: no value added to <code>sim</code> or <code>obs</code>.
</p>
</li>
<li><p><em>Pushpalatha2012</em>: one hundredth of the mean observed values is added to both <code>sim</code> and <code>obs</code> as described in Pushpalatha et al., 2012.
</p>
</li>
<li><p><em>otherFactor</em>: the numeric value defined in <code>epsilon.value</code> is used to multiply the mean observed values instead of the one hundredth (1/100)
described in Pushpalatha et al., (2012). The resulting value is then added to both <code>sim</code> and <code>obs</code>.
</p>
</li>
<li><p><em>otherValue</em>: the numeric value defined in <code>epsilon.value</code> is directly added to both <code>sim</code> and <code>obs</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="GOF_+3A_epsilon.value">epsilon.value</code></td>
<td>
<p>numeric, value to be added to both <code>sim</code> and <code>obs</code> when <code>epsilon</code> = &quot;otherValue&quot;.</p>
</td></tr>
<tr><td><code id="GOF_+3A_out.peryear">out.PerYear</code></td>
<td>
<p>logical, argument passed to the <code><a href="#topic+sKGE">sKGE</a></code> function.</p>
</td></tr>
<tr><td><code id="GOF_+3A_out.type">out.type</code></td>
<td>
<p>argument passed to the <code><a href="#topic+KGE">KGE</a></code> function.</p>
</td></tr>
<tr><td><code id="GOF_+3A_dec">dec</code></td>
<td>
<p>argument passed to the <code><a href="#topic+pbias">pbias</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>gof</code>, <code>mae</code>, <code>pbias</code>, <code>NSE</code>, <code>rPearson</code>, <code>sKGE</code>, and <code>KGE</code> functions are provided to calculate goodness of fit statistics.
The functions were adapted from the hydroGOF package <a href="https://github.com/hzambran/hydroGOF">https://github.com/hzambran/hydroGOF</a>.
</p>


<h3>Value</h3>

<p><code>gof</code> Returns a matrix of goodness of fit statistics. <code>mae</code>, <code>pbias</code>, <code>NSE</code>, <code>rPearson</code>, <code>sKGE</code>, and <code>KGE</code> return a numeric of the goodness of fit statistic.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gof(sim = sample(1:100), obs = sample(1:100))

</code></pre>

<hr>
<h2 id='GroupSLCClasses'>Calculate grouped sums for SLC classes in a GeoData file</h2><span id='topic+GroupSLCClasses'></span>

<h3>Description</h3>

<p><code>GroupSLCClasses</code> calculates grouped sums for SLC classes (area fractions or absolute areas) based on land use, soil, or crop groups in a GeoClass
table, or any other user-provided grouping index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GroupSLCClasses(
  gd,
  gcl = NULL,
  type = c("landuse", "soil", "crop"),
  group = NULL,
  abs.area = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GroupSLCClasses_+3A_gd">gd</code></td>
<td>
<p>Data frame containing columns with SUBIDs, SLC fractions, and SUBID areas if <code>abs.area = TRUE</code>. Typically a 'GeoData.txt' file
imported with <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="GroupSLCClasses_+3A_gcl">gcl</code></td>
<td>
<p>Data frame containing columns with SLCs and corresponding landuse and soil class IDs, typically a 'GeoClass.txt'
file imported with <code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code>. Must be provided if no <code>group</code> argument is given.</p>
</td></tr>
<tr><td><code id="GroupSLCClasses_+3A_type">type</code></td>
<td>
<p>Character string keyword for use with <code>gcl</code>. Type of grouping index, either <code>"landuse"</code>, <code>"soil"</code>, or <code>"crop"</code>,
can be abbreviated.</p>
</td></tr>
<tr><td><code id="GroupSLCClasses_+3A_group">group</code></td>
<td>
<p>Integer vector, of same length as number of SLC classes in <code>gd</code>. Alternative grouping index specification to <code>gcl</code> + <code>type</code>.</p>
</td></tr>
<tr><td><code id="GroupSLCClasses_+3A_abs.area">abs.area</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then absolute areas will be calculated for each group, rather than area fractions.</p>
</td></tr>
<tr><td><code id="GroupSLCClasses_+3A_verbose">verbose</code></td>
<td>
<p>Logical, if <code>TRUE</code> then information and progress bar will be printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If absolute areas are calculated, area units will correspond to areas provided in <code>gd</code>.
</p>


<h3>Value</h3>

<p><code>GroupSLClasses</code> returns the data frame with SUBIDs, SUBID areas, and grouped SLC class columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import source data
te1 &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
te2 &lt;- ReadGeoClass(filename = system.file("demo_model", "GeoClass.txt", package = "HYPEtools"))
# Calculate soil groups
GroupSLCClasses(gd = te1, gcl = te2, type = "s")

</code></pre>

<hr>
<h2 id='GwRetention'>Calculate groundwater retention of nutrients</h2><span id='topic+GwRetention'></span>

<h3>Description</h3>

<p>Function to calculate nutrient load retention fractions in groundwater parts of HYPE, i.e. after root zone retention. See Details for
exact definition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GwRetention(nfrz, nfs3, gts3, gd, par, unit.area = TRUE, nutrient = "tn")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="GwRetention_+3A_nfrz">nfrz</code></td>
<td>
<p>Data frame with two-columns. Sub-basin IDs in first column, net loads from root zone in kg/year in second column. Typically an
imported HYPE map output file, HYPE output variable SL06. See Details.</p>
</td></tr>
<tr><td><code id="GwRetention_+3A_nfs3">nfs3</code></td>
<td>
<p>Data frame with two-columns. Sub-basin IDs in first column, net loads from soil layer 3 in kg/year in second column.
Typically an imported HYPE map output file, HYPE output variable SL18. See Details.</p>
</td></tr>
<tr><td><code id="GwRetention_+3A_gts3">gts3</code></td>
<td>
<p>Data frame with two-columns. Sub-basin IDs in first column, gross loads to soil layer 3 in kg/year in second column.
Typically an imported HYPE map output file, HYPE output variable SL17. See Details.</p>
</td></tr>
<tr><td><code id="GwRetention_+3A_gd">gd</code></td>
<td>
<p>Data frame, with columns containing sub-basin IDs and rural household emissions, e.g. an imported 'GeoData.txt' file.
See details.</p>
</td></tr>
<tr><td><code id="GwRetention_+3A_par">par</code></td>
<td>
<p>List, HYPE parameter list, typically an imported 'par.txt' file. Must contain parameter <em>locsoil</em> (not case-sensitive).</p>
</td></tr>
<tr><td><code id="GwRetention_+3A_unit.area">unit.area</code></td>
<td>
<p>Logical, set to <code>FALSE</code> to calculate incoming load (leaching rates) in kg/year instead of kg/(ha year).</p>
</td></tr>
<tr><td><code id="GwRetention_+3A_nutrient">nutrient</code></td>
<td>
<p>Character keyword, one of the HYPE-modeled nutrient groups, for which to calculate groundwater retention. Not
case-sensitive. <em>Currently, only <code>tn</code> (total nitrogen) is implemented.</em></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>GwRetention</code> calculates a groundwater nutrient retention as fractions of outgoing and incoming loads using HYPE soil load variables. Incoming loads
include drainage into layer 3 from the root zone (defined as soil layer 1 and 2), rural load fractions into soil (dependent on parameter <em>locsoil</em>),
tile drainage, surface flow, and flow from layer 1 and 2. Outgoing loads include runoff from all soil layers, tile drain, and surface flow.
</p>
<p>The retention fraction <em>R</em> is calculated as (see also the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_model_description:hype_np_soil#diagnostic_output_variables_of_soil_nutrients">variable description in the HYPE online documentation</a>):
</p>
<p><code class="reqn">R = 1 - \frac{OUT}{IN} = 1 - \frac{nfrz - gts3 + nfs3 + locsoil * lr}{nfrz + locsoil * lr}</code> <a href="base.html#topic+-">-</a>
</p>
<p><code class="reqn">li = nfrz + locsoil * lr</code> [kg/y]
</p>
<p><code class="reqn">lr = LOC_VOL * LOC_TN * 0.365</code> [kg/y]
</p>
<p>, where <em>li</em> is incoming load to groundwater (leaching rates), <em>lr</em> is rural load (total from GeoData converted to kg/yr; <em>locsoil</em> in the formula converts it to rural load into soil layer 3), and
<em>nfrz</em>, <em>gts3</em>, <em>nfs3</em> are soil loads as in function arguments described above. See Examples for HYPE variable names for <code>TN</code> loads.
</p>
<p>Columns <code>SUBID</code>, <code>LOC_VOL</code>, and <code>LOC_TN</code> must be present in <code>gd</code>, for a description of column contents see the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:geodata.txt">GeoData file description in the HYPE online documentation</a>.
Column names are not case-sensitive.
</p>


<h3>Value</h3>

<p><code>GwRetention</code> returns a three-column data frame, containing SUBIDs, retention in groundwater as a fraction of incoming loads
(if multiplied by 100, it becomes \
.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create dummy data
te1 &lt;- ReadGeoData(filename = system.file("demo_model",
"GeoData.txt", package = "HYPEtools"))
te1$loc_tn &lt;- runif(n = nrow(te1), min = 0, max = 100)
te1$loc_vol &lt;- runif(n = nrow(te1), min = 0, max = 2)
te2 &lt;- ReadPar(filename = system.file("demo_model",
"par.txt", package = "HYPEtools"))
te2$locsoil &lt;- .3
# HYPE soil load (sl) variables for TN, dummy loads
GwRetention(nfrz = data.frame(SUBID = te1$SUBID, SL06 = runif(n = nrow(te1), 10, 50)), 
            gts3 = data.frame(SUBID = te1$SUBID, SL17 = runif(n = nrow(te1), 10, 50)), 
            nfs3 = data.frame(SUBID = te1$SUBID, SL18 = runif(n = nrow(te1), 10, 50)), 
            gd = te1, par = te2)

</code></pre>

<hr>
<h2 id='HeadwaterSubids'>Find all headwater SUBIDs of a model domain</h2><span id='topic+HeadwaterSubids'></span>

<h3>Description</h3>

<p>Function to find all headwater SUBIDs of a HYPE model domain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HeadwaterSubids(gd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HeadwaterSubids_+3A_gd">gd</code></td>
<td>
<p>A data frame, containing among others two columns <code>subid</code> and <code>maindown</code>. Column names are not case-sensitive
and column positions in the data frame are irrelevant.
Typically a 'GeoData.txt' file imported using <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>HeadwaterSubids</code> finds all headwater SUBIDs of a model domain as provided in a 'GeoData.txt' file, i.e. all subcatchments
which do not have any upstream subcatchments.
</p>


<h3>Value</h3>

<p><code>HeadwaterSubids</code> returns a vector of outlet SUBIDs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
HeadwaterSubids(gd = te)

</code></pre>

<hr>
<h2 id='HypeAttrAccess'>Quickly query and set HYPE-specific attributes</h2><span id='topic+HypeAttrAccess'></span><span id='topic+datetime'></span><span id='topic+datetime+3C-'></span><span id='topic+hypeunit'></span><span id='topic+hypeunit+3C-'></span><span id='topic+obsid'></span><span id='topic+obsid+3C-'></span><span id='topic+outregid'></span><span id='topic+outregid+3C-'></span><span id='topic+subid'></span><span id='topic+subid+3C-'></span><span id='topic+timestep'></span><span id='topic+timestep+3C-'></span><span id='topic+variable'></span><span id='topic+variable+3C-'></span>

<h3>Description</h3>

<p>These are simple convenience wrapper functions to quickly query and assign values of attributes which are added to HYPE data
on import.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>datetime(x)

datetime(x) &lt;- value

hypeunit(x)

hypeunit(x) &lt;- value

obsid(x)

obsid(x) &lt;- value

outregid(x)

outregid(x) &lt;- value

subid(x)

subid(x) &lt;- value

timestep(x)

timestep(x) &lt;- value

variable(x)

variable(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HypeAttrAccess_+3A_x">x</code></td>
<td>
<p>Object whose attribute is to be accessed</p>
</td></tr>
<tr><td><code id="HypeAttrAccess_+3A_value">value</code></td>
<td>
<p>Value to be assigned</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions are just shortcuts for <code><a href="base.html#topic+attr">attr</a></code>.
</p>


<h3>Value</h3>

<p>The extractor functions return the value of the respective attribute or <code>NULL</code> if no matching attribute is found.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadBasinOutput(filename = system.file("demo_model", "results",
"0003587.txt", package = "HYPEtools"))
hypeunit(te)
timestep(te)
subid(te)

</code></pre>

<hr>
<h2 id='HypeDataExport'>Write HYPE data files</h2><span id='topic+HypeDataExport'></span><span id='topic+WriteAquiferData'></span><span id='topic+WriteOutregions'></span><span id='topic+WriteBranchData'></span><span id='topic+WriteCropData'></span><span id='topic+WriteDamData'></span><span id='topic+WriteLakeData'></span><span id='topic+WriteMgmtData'></span><span id='topic+WritePointSourceData'></span><span id='topic+WriteForcKey'></span><span id='topic+WriteGlacierData'></span>

<h3>Description</h3>

<p>These are simple convenience wrapper functions to export various HYPE data files from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteAquiferData(x, filename, verbose = TRUE)

WriteOutregions(x, filename, verbose = TRUE)

WriteBranchData(x, filename, verbose = TRUE)

WriteCropData(x, filename, verbose = TRUE)

WriteDamData(x, filename, verbose = TRUE)

WriteLakeData(x, filename, verbose = TRUE)

WriteMgmtData(x, filename, verbose = TRUE)

WritePointSourceData(x, filename, verbose = TRUE)

WriteForcKey(x, filename)

WriteGlacierData(x, filename, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HypeDataExport_+3A_x">x</code></td>
<td>
<p>The object to be written, a dataframe as returned from the <code><a href="#topic+HypeDataImport">HypeDataImport</a></code> functions.</p>
</td></tr>
<tr><td><code id="HypeDataExport_+3A_filename">filename</code></td>
<td>
<p>A character string naming a path and file name to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="HypeDataExport_+3A_verbose">verbose</code></td>
<td>
<p>Logical, display informative warning messages if columns contain <code>NA</code> values or if character strings are
too long. See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hype data file exports, simple <code><a href="data.table.html#topic+fwrite">fwrite</a></code> wrappers with formatting options adjusted to match HYPE file
specifications:
</p>

<ul>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:lakedata.txt">LakeData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:damdata.txt">DamData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:mgmtdata.txt">MgmtData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:aquiferdata.txt">AquiferData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:pointsourcedata.txt">PointSourceData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:glacierdata.txt">GlacierData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:cropdata.txt">CropData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:branchdata.txt">BranchData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:forckey.txt">forckey.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:outregions.txt">Outregions.txt</a>
</p>
</li></ul>

<p>In most files, HYPE requires <code>NA</code>-free input in required columns, but empty values are
allowed in additional comment columns which are not read by HYPE. Informative warnings will be thrown if <code>NA</code>s are
found during export. Character string lengths in comment columns of HYPE data files are restricted to 100 characters,
the functions will return with a warning if longer strings were exported.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadForcKey(filename = system.file("demo_model", "ForcKey.txt", package = "HYPEtools"))
WriteForcKey(x = te, filename = tempfile())

</code></pre>

<hr>
<h2 id='HypeDataImport'>Read HYPE data files</h2><span id='topic+HypeDataImport'></span><span id='topic+ReadAquiferData'></span><span id='topic+ReadOutregions'></span><span id='topic+ReadBranchData'></span><span id='topic+ReadCropData'></span><span id='topic+ReadDamData'></span><span id='topic+ReadGlacierData'></span><span id='topic+ReadLakeData'></span><span id='topic+ReadMgmtData'></span><span id='topic+ReadPointSourceData'></span><span id='topic+ReadAllsim'></span><span id='topic+ReadForcKey'></span><span id='topic+ReadUpdate'></span>

<h3>Description</h3>

<p>These are simple convenience wrapper functions to import various HYPE data files as data frame into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadAquiferData(
  filename = "AquiferData.txt",
  verbose = TRUE,
  header = TRUE,
  na.strings = "-9999",
  sep = "\t",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  ...
)

ReadOutregions(
  filename = "Outregions.txt",
  verbose = TRUE,
  header = TRUE,
  na.strings = "-9999",
  sep = "\t",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  ...
)

ReadBranchData(
  filename = "BranchData.txt",
  verbose = TRUE,
  header = TRUE,
  na.strings = "-9999",
  sep = "\t",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  ...
)

ReadCropData(
  filename = "CropData.txt",
  verbose = TRUE,
  header = TRUE,
  na.strings = "-9999",
  sep = "\t",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  ...
)

ReadDamData(
  filename = "DamData.txt",
  verbose = TRUE,
  header = TRUE,
  na.strings = "-9999",
  sep = "\t",
  quote = "",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  ...
)

ReadGlacierData(
  filename = "GlacierData.txt",
  verbose = TRUE,
  header = TRUE,
  na.strings = "-9999",
  sep = "\t",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  ...
)

ReadLakeData(
  filename = "LakeData.txt",
  verbose = TRUE,
  header = TRUE,
  na.strings = "-9999",
  sep = "\t",
  quote = "",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  ...
)

ReadMgmtData(
  filename = "MgmtData.txt",
  verbose = TRUE,
  header = TRUE,
  na.strings = "-9999",
  sep = "\t",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  ...
)

ReadPointSourceData(
  filename = "PointSourceData.txt",
  verbose = TRUE,
  header = TRUE,
  na.strings = "-9999",
  sep = "\t",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  data.table = FALSE,
  ...
)

ReadAllsim(filename = "allsim.txt", na.strings = "-9999")

ReadForcKey(
  filename = "ForcKey.txt",
  sep = "\t",
  encoding = c("unknown", "latin1", "UTF-8")
)

ReadUpdate(
  filename = "update.txt",
  header = TRUE,
  sep = "\t",
  stringsAsFactors = FALSE,
  encoding = c("unknown", "latin1", "UTF-8"),
  data.table = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HypeDataImport_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of HYPE data file file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="HypeDataImport_+3A_verbose">verbose</code></td>
<td>
<p>Logical, display message if columns contain <code>NA</code> values.</p>
</td></tr>
<tr><td><code id="HypeDataImport_+3A_header">header</code></td>
<td>
<p><code><a href="utils.html#topic+read.table">read.table</a></code> or <code><a href="data.table.html#topic+fread">fread</a></code> argument, with appropriate default for HYPE data file import.</p>
</td></tr>
<tr><td><code id="HypeDataImport_+3A_na.strings">na.strings</code></td>
<td>
<p>See <code>header</code>.</p>
</td></tr>
<tr><td><code id="HypeDataImport_+3A_sep">sep</code></td>
<td>
<p>See <code>header</code>.</p>
</td></tr>
<tr><td><code id="HypeDataImport_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>See <code>header</code>.</p>
</td></tr>
<tr><td><code id="HypeDataImport_+3A_encoding">encoding</code></td>
<td>
<p><code><a href="utils.html#topic+read.table">read.table</a></code> argument. Specify character encoding when
importing files created under Windows (default encoding &quot;latin1&quot;) in Linux (default encoding &quot;UTF-8&quot;)
and vice versa.</p>
</td></tr>
<tr><td><code id="HypeDataImport_+3A_...">...</code></td>
<td>
<p>Other parameters passed to <code><a href="utils.html#topic+read.table">read.table</a></code>.</p>
</td></tr>
<tr><td><code id="HypeDataImport_+3A_quote">quote</code></td>
<td>
<p>See <code>header</code>.</p>
</td></tr>
<tr><td><code id="HypeDataImport_+3A_data.table">data.table</code></td>
<td>
<p>Logical, return data.table instead of data frame. <code><a href="data.table.html#topic+fread">fread</a></code> argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hype data file imports, simple <code><a href="utils.html#topic+read.table">read.table</a></code> or <code><a href="data.table.html#topic+fread">fread</a></code> wrappers with
formatting arguments set to match HYPE file specifications:
</p>

<ul>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:lakedata.txt">LakeData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:damdata.txt">DamData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:mgmtdata.txt">MgmtData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:aquiferdata.txt">AquiferData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:pointsourcedata.txt">PointSourceData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:glacierdata.txt">GlacierData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:cropdata.txt">CropData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:branchdata.txt">BranchData.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:outregions.txt">Outregions.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:allsim.txt">allsim.txt</a>
</p>
</li>
<li> <p><a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:update.txt">update.txt</a>
</p>
</li></ul>

<p>In most files, HYPE requires <code>NA</code>-free input in required columns, but empty values are
allowed in additional comment columns. Informative warnings will be thrown if <code>NA</code>s are found during import.
</p>


<h3>Value</h3>

<p>Imported files are returned as data frames.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadForcKey(filename = system.file("demo_model", "ForcKey.txt", package = "HYPEtools"))

</code></pre>

<hr>
<h2 id='HypeGeoData'>HypeGeoData data frames</h2><span id='topic+HypeGeoData'></span>

<h3>Description</h3>

<p>Constructor function for data frames which hold HYPE GeoData tables with information on sub-basins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HypeGeoData(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HypeGeoData_+3A_x">x</code></td>
<td>
<p>Data frame with at least five mandatory columns, see details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>S3 constructor function for data frames which hold HYPE GeoData tables. These are normal data frames with at least five mandatory
columns, all <code>numeric</code>: <em>AREA</em>, <em>SUBID</em>, <em>MAINDOWN</em>, <em>RIVLEN</em>, and <em>SLC_n</em>, where <em>n</em> are
consecutive SLC class numbers (up to 999).See also the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables">HYPE file description</a>
for GeoData.txt files for reference.
</p>
<p>Usually, this class will be assigned to GeoData tables on import with <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>. A <code>summary</code> method exists for
<code>HypeGeoData</code> data frames.
</p>


<h3>Value</h3>

<p>Returns a data frame with added <code><a href="base.html#topic+class">class</a></code> attribute <code>HypeGeoData</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadGeoData">ReadGeoData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- data.table::fread(file = system.file("demo_model",
"GeoData.txt", package = "HYPEtools"), data.table = FALSE)
HypeGeoData(x = te)
summary(te)

</code></pre>

<hr>
<h2 id='HypeMultiVar'>HypeMultiVar arrays</h2><span id='topic+HypeMultiVar'></span>

<h3>Description</h3>

<p>Constructor function for arrays which hold equidistant time series of multiple HYPE variables for a single sub-basin and
multiple model runs, typically imported HYPE basin output results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HypeMultiVar(
  x,
  datetime,
  hype.var,
  hype.unit,
  subid = NULL,
  outregid = NULL,
  hype.comment = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HypeMultiVar_+3A_x">x</code></td>
<td>
<p>numeric <code><a href="base.html#topic+array">array</a></code> with three dimensions, which holds HYPE results for one sub-basin as (in order)
<code>[datetime, variable, iteration]</code>.</p>
</td></tr>
<tr><td><code id="HypeMultiVar_+3A_datetime">datetime</code></td>
<td>
<p><code><a href="base.html#topic+POSIXct">POSIXct</a></code> date-time vector of the same length as <code>time</code> dimension of <code>x</code>
with equidistant time steps (starting day for time steps from weekly to annual), or character string for full model
period averages, e.g. <code>"2000-2010"</code>.</p>
</td></tr>
<tr><td><code id="HypeMultiVar_+3A_hype.var">hype.var</code>, <code id="HypeMultiVar_+3A_hype.unit">hype.unit</code></td>
<td>
<p>Character vectors of keywords to specify HYPE variable IDs, corresponding to second dimension
(columns) in <code>x</code>. See
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables">list of HYPE variables</a></p>
</td></tr>
<tr><td><code id="HypeMultiVar_+3A_subid">subid</code></td>
<td>
<p>Integer, HYPE sub-basin ID. Either this or <code>outregid</code> needs to be supplied.</p>
</td></tr>
<tr><td><code id="HypeMultiVar_+3A_outregid">outregid</code></td>
<td>
<p>Integer, HYPE output region ID, alternative to <code>subid</code>.</p>
</td></tr>
<tr><td><code id="HypeMultiVar_+3A_hype.comment">hype.comment</code></td>
<td>
<p>Character, first-row optional comment string of basin output file. Empty string, if non-existing.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>S3 class constructor function for array objects which can hold (multiple) HYPE basin output results.
</p>


<h3>Value</h3>

<p>Returns a 3-dimensional array with
<code>[time, variable, iteration]</code> dimensions and additional <code><a href="base.html#topic+attributes">attributes</a></code>:
</p>

<dl>
<dt><strong>datetime</strong></dt><dd><p>A vector of date-times. Corresponds to 1st array dimension.</p>
</dd>
<dt><strong>variable</strong></dt><dd><p>A character vector of HYPE output variable IDs.</p>
</dd>
<dt><strong>hypeunit</strong></dt><dd><p>A character vector of HYPE output variable units.</p>
</dd>
<dt><strong>subid</strong></dt><dd><p>A single SUBID.</p>
</dd>
<dt><strong>outregid</strong></dt><dd><p>A single OUTREGID.</p>
</dd>
<dt><strong>timestep</strong></dt><dd><p>A character keyword for the time step.</p>
</dd>
<dt><strong>comment</strong></dt><dd><p>A comment string, currently used for class group outputs.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># import a basin output file
te1 &lt;- ReadBasinOutput(filename = system.file("demo_model",
"results", "0003587.txt", package = "HYPEtools"))
# create a dummy array with two iterations from imported basin file
te2 &lt;- array(data = c(unlist(te1[, -1]),  unlist(te1[, -1])), 
             dim = c(nrow(te1), ncol(te1) - 1, 2), 
             dimnames = list(rownames(te1), colnames(te1)[-1]))
# Construct HypeMultiVar array
HypeMultiVar(te2, datetime = te1$DATE, hype.var = variable(te1),
hype.unit = hypeunit(te1), subid = 3587)

</code></pre>

<hr>
<h2 id='HypeSingleVar'>HypeSingleVar arrays</h2><span id='topic+HypeSingleVar'></span>

<h3>Description</h3>

<p>Constructor function for arrays which hold equidistant time series of a single HYPE variable for multiple sub-basins
and multiple model runs, typically imported time and map output results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HypeSingleVar(x, datetime, subid = NULL, outregid = NULL, hype.var)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HypeSingleVar_+3A_x">x</code></td>
<td>
<p>numeric <code><a href="base.html#topic+array">array</a></code> with three dimensions, which holds HYPE results for one variable as (in order)
<code>[datetime, subid/outregid, iteration]</code>.</p>
</td></tr>
<tr><td><code id="HypeSingleVar_+3A_datetime">datetime</code></td>
<td>
<p><code><a href="base.html#topic+POSIXct">POSIXct</a></code> date-time vector of the same length as <code>time</code> dimension of <code>x</code>
with equidistant time steps (starting day for time steps from weekly to annual), or character string for full model
period averages, e.g. <code>"2000-2010"</code>.</p>
</td></tr>
<tr><td><code id="HypeSingleVar_+3A_subid">subid</code></td>
<td>
<p>Integer vector with HYPE sub-basin IDs, of the same length as <code>subid</code> dimension of <code>x</code>. Either this
or <code>outregid</code> must be supplied.</p>
</td></tr>
<tr><td><code id="HypeSingleVar_+3A_outregid">outregid</code></td>
<td>
<p>Integer vector with HYPE output region IDs, alternative to <code>subid</code>.</p>
</td></tr>
<tr><td><code id="HypeSingleVar_+3A_hype.var">hype.var</code></td>
<td>
<p>Character string, keyword to specify HYPE variable ID, see
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables">list of HYPE variable</a>.
Not case-sensitive.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>S3 class constructor function for array objects which can hold (multiple) HYPE time or map output results.
</p>


<h3>Value</h3>

<p>Returns a 3-dimensional array with
<code>[time, subid, iteration]</code> dimensions and additional <code><a href="base.html#topic+attributes">attributes</a></code>:
</p>

<dl>
<dt><strong>datetime</strong></dt><dd><p>A vector of date-times. Corresponds to 1st array dimension.</p>
</dd>
<dt><strong>subid</strong></dt><dd><p>A vector of SUBIDs. Corresponds to 2nd array dimension (<code>NA</code>, if it does not apply to data contents).</p>
</dd>
<dt><strong>outregid</strong></dt><dd><p>A vector of OUTREGIDs. Corresponds to 2nd array dimension (<code>NA</code>, if it does not apply to data contents).</p>
</dd>
<dt><strong>variable</strong></dt><dd><p>HYPE output variable ID.</p>
</dd>
<dt><strong>timestep</strong></dt><dd><p>A character keyword for the time step.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># Import a time output file
te1 &lt;- ReadTimeOutput(filename = system.file("demo_model", "results",
"timeCOUT.txt", package = "HYPEtools"), dt.format = "%Y-%m")
# Create a dummy array with two iterations from imported time file
te2 &lt;- array(data = c(unlist(te1[, -1]),  unlist(te1[, -1])), 
             dim = c(nrow(te1), ncol(te1) - 1, 2), 
             dimnames = list(rownames(te1), colnames(te1)[-1]))
# Construct HypeSingleVar array
HypeSingleVar(x = te2, datetime = te1$DATE,
subid = subid(te1), hype.var = variable(te1))

</code></pre>

<hr>
<h2 id='HypeSubidChecks'>Check HYPE SUBID properties</h2><span id='topic+HypeSubidChecks'></span><span id='topic+IsHeadwater'></span><span id='topic+IsOutlet'></span><span id='topic+IsRegulated'></span>

<h3>Description</h3>

<p>Quickly query vectors of HYPE sub-basin IDs (SUBID) for various properties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IsHeadwater(subid, gd)

IsOutlet(subid, gd)

IsRegulated(subid, gd, dd = NULL, ld = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HypeSubidChecks_+3A_subid">subid</code></td>
<td>
<p>Numeric, vector of SUBIDs to be queried</p>
</td></tr>
<tr><td><code id="HypeSubidChecks_+3A_gd">gd</code></td>
<td>
<p><code><a href="#topic+HypeGeoData">HypeGeoData</a></code> or base data frame with columns <code>SUBID</code> and <code>MAINDOWN</code>, typically an imported
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:geodata.txt">GeoData.txt</a> file.</p>
</td></tr>
<tr><td><code id="HypeSubidChecks_+3A_dd">dd</code></td>
<td>
<p>Data frame, typically an imported
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:damdata.txt">DamData.txt</a> file. Defaults
to <code>NULL</code>. <code>dd</code> or <code>ld</code> has to be provided in <code>IsRegulated</code>.</p>
</td></tr>
<tr><td><code id="HypeSubidChecks_+3A_ld">ld</code></td>
<td>
<p>Data frame, typically an imported
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:lakedata.txt">LakeData.txt</a> file. Defaults
to <code>NULL</code>. <code>dd</code> or <code>ld</code> has to be provided in <code>IsRegulated</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are convenience functions to query subbasin properties. Some functions can be inefficient if applied to many or all
subbasins of a HYPE model setup and more efficient functions may exist in HYPEtools, see links in <em>See also</em> section below or browse
the package index.
</p>


<h3>Value</h3>

<p>The functions return a logical vector of the same length as <code>subid</code>, with <code>NA</code> values for all SUBIDs which do not exist
in <code>gd</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids()</a></code>; <code><a href="#topic+AllDownstreamSubids">AllDownstreamSubids()</a></code>; <code><a href="#topic+OutletSubids">OutletSubids()</a></code>; <code><a href="#topic+OutletIds">OutletIds()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
IsHeadwater(subid = 40556, gd = te)
IsHeadwater(subid = te$SUBID, gd = te)

</code></pre>

<hr>
<h2 id='HypeXobs'>HypeXobs data frames</h2><span id='topic+HypeXobs'></span>

<h3>Description</h3>

<p>Constructor function for data frames which hold HYPE Xobs.txt file contents, i.e. time series of a multiple observation
variables for multiple sub-basins and equidistant time steps in POSIXct format in the first column.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HypeXobs(x, comment, variable, subid, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="HypeXobs_+3A_x">x</code></td>
<td>
<p><code><a href="base.html#topic+data.frame">data.frame</a></code> with <code><a href="base.html#topic+POSIXct">POSIXct</a></code> formatted time steps in the first, and <code><a href="base.html#topic+numeric">numeric</a></code>
variables in the remaining columns.</p>
</td></tr>
<tr><td><code id="HypeXobs_+3A_comment">comment</code></td>
<td>
<p>Character string, metadata or other information, first line of a HYPE Xobs.txt file.</p>
</td></tr>
<tr><td><code id="HypeXobs_+3A_variable">variable</code></td>
<td>
<p>Character vector of four-letter keywords to specify HYPE variable IDs, corresponding to second to
last column in <code>x</code>.</p>
</td></tr>
<tr><td><code id="HypeXobs_+3A_subid">subid</code></td>
<td>
<p>Integer vector with HYPE sub-basin IDs, corresponding to second to last column in <code>x</code>.</p>
</td></tr>
<tr><td><code id="HypeXobs_+3A_verbose">verbose</code></td>
<td>
<p>Logical, throw warning if attribute <code>timestep</code> cannot be computed.
</p>
<p>Not case-sensitive.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>S3 class constructor function for <code>HypeXobs</code> data frame objects which hold HYPE Xobs.txt file contents. Xobs.txt
files contain three header rows, see the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:xobs.txt">Xobs.txt description in the HYPE documentation</a>.
These headers are stored as additional attributes in  objects.
</p>


<h3>Value</h3>

<p>Returns a data frame of class <code>HypeXobs</code> with additional <code><a href="base.html#topic+attributes">attributes</a></code>:
</p>

<dl>
<dt><strong>comment</strong></dt><dd><p>A character vector.</p>
</dd>
<dt><strong>variable</strong></dt><dd><p>A character vector of HYPE variable IDs.</p>
</dd>
<dt><strong>subid</strong></dt><dd><p>A vector of SUBIDs.</p>
</dd>
<dt><strong>timestep</strong></dt><dd><p>Time step keyword, <code>"day"</code>, or <code>"n hour"</code> (n = number of hours). <code>NULL</code>, if <code>x</code>
contains just one row.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'># Use the Xobs file import function instead of the class constructor for standard work flows
te &lt;- ReadXobs(file = system.file("demo_model", "Xobs.txt", package = "HYPEtools"))
summary(te)
# Class constructor
HypeXobs(x = as.data.frame(te), comment = comment(te), variable = variable(te), subid = subid(te))

</code></pre>

<hr>
<h2 id='InfoManipulation'>Functions to Manipulate HYPE Info Files</h2><span id='topic+InfoManipulation'></span><span id='topic+AddInfoLine'></span><span id='topic+RemoveInfoLine'></span>

<h3>Description</h3>

<p>Add/Remove lines to HYPE info.txt files
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AddInfoLine(info, name, value, after = NULL)

RemoveInfoLine(info, name)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="InfoManipulation_+3A_info">info</code></td>
<td>
<p>Named list containing the info.txt file data, typically created using <code><a href="#topic+ReadInfo">ReadInfo</a></code> with the <code>exact</code> mode.</p>
</td></tr>
<tr><td><code id="InfoManipulation_+3A_name">name</code></td>
<td>
<p>Name of info.txt code to add/remove.</p>
</td></tr>
<tr><td><code id="InfoManipulation_+3A_value">value</code></td>
<td>
<p>Value of the info.txt code to add/remove.</p>
</td></tr>
<tr><td><code id="InfoManipulation_+3A_after">after</code></td>
<td>
<p>String vector containing the name(s) of info.txt codes that the new info.txt code should be inserted below.
If multiple values are specified and all codes are present in <code>info</code>, then the new code will be inserted below the match that is farthest down in the info.txt file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>AddInfoLine</code> and <code>RemoveInfoLine</code> functions provide features to add/remove lines to an imported info.txt
file. Info.txt codes can be found on the <a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt">HYPE Wiki</a>.
</p>


<h3>Value</h3>

<p><code>AddInfoLine</code> and <code>RemoveInfoLine</code> return a named list in the info.txt file structure.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>info &lt;- ReadInfo(filename = system.file("demo_model",
"info.txt", package = "HYPEtools"))
info &lt;- AddInfoLine(info, name = "testline", value = "testvalue")
info &lt;- RemoveInfoLine(info, name = "testline")

</code></pre>

<hr>
<h2 id='MapRegionalSources'>Map regional irrigation source connection as spatial lines</h2><span id='topic+MapRegionalSources'></span>

<h3>Description</h3>

<p>By default, this function creates an <code>sf</code> object which contains regional irrigation connections between
source and target HYPE sub-catchments. However, this function can also be used to create interactive Leaflet maps.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MapRegionalSources(
  data,
  map,
  map.subid.column = 1,
  group.column = NULL,
  group.colors = NULL,
  digits = 3,
  progbar = FALSE,
  map.type = "default",
  plot.scale = TRUE,
  plot.searchbar = FALSE,
  weight = 0.5,
  opacity = 1,
  fillColor = "#4d4d4d",
  fillOpacity = 0.25,
  line.weight = 5,
  line.opacity = 1,
  seed = NULL,
  darken = 0,
  font.size = 10,
  file = "",
  vwidth = 1424,
  vheight = 1000,
  html.name = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MapRegionalSources_+3A_data">data</code></td>
<td>
<p>Dataframe, containing a column <code>SUBID</code> and a column <code>REGSRCID</code> (not case-sensitive), which identify
irrigation target and source sub-catchments, respectively. Typically a HYPE 'MgmtData.txt' file, imported with <code><a href="#topic+ReadMgmtData">ReadMgmtData</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_map">map</code></td>
<td>
<p>A <code>sf</code>, <code>SpatialPointsDataFrame</code>, or <code>SpatialPolygonsDataFrame</code> object providing sub-catchment locations as points or polygons. Typically an imported SUBID
center-point shape file or geopackage. If provided polygon data, then the polygon centroids will be calculated and used as the point locations (See <code><a href="sf.html#topic+geos_unary">sf::st_centroid()</a></code>). Spatial data import requires additional packages, e.g. <code>sf</code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_map.subid.column">map.subid.column</code></td>
<td>
<p>Integer, index of the column in <code>map</code> holding SUBIDs (sub-catchment IDs).</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_group.column">group.column</code></td>
<td>
<p>Integer, optional index of the column in <code>data</code> providing grouping of connections to allow toggling of groups in Leaflet maps. Default <code>NULL</code> will produce maps without
grouping.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_group.colors">group.colors</code></td>
<td>
<p>Named list providing colors for connection groups in Leaflet maps. List names represent the names of the groups in the <code>group.column</code> of <code>data</code>, and list values represent the colors.
Example: <code>groups.colors = list("GROUP 1" = "black", "GROUP 2" = "red")</code>. If a group is not included in <code>group.colors</code>, then random colors will be assigned to the connections in the group.
Default <code>NULL</code> will produce maps using random colors for all groups.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_digits">digits</code></td>
<td>
<p>Integer, number of digits to which irrigation connection lengths are rounded to.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while calculating.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_map.type">map.type</code></td>
<td>
<p>Map type keyword string. Choose either <code>"default"</code> for the default static plots or <code>"leaflet"</code> for interactive Leaflet maps.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_plot.scale">plot.scale</code></td>
<td>
<p>Logical, include a scale bar on Leaflet maps.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_plot.searchbar">plot.searchbar</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then a search bar will be included on Leaflet maps. See <code><a href="leaflet.extras.html#topic+search-features">leaflet.extras::addSearchFeatures()</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_weight">weight</code></td>
<td>
<p>Numeric, weight of subbasin boundary lines in Leaflet maps. Used if <code>map</code> contains polygon data. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_opacity">opacity</code></td>
<td>
<p>Numeric, opacity of subbasin boundary lines in Leaflet maps. Used if <code>map</code> contains polygon data. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_fillcolor">fillColor</code></td>
<td>
<p>String, color of subbasin polygons in Leaflet maps. Used if <code>map</code> contains polygon data. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_fillopacity">fillOpacity</code></td>
<td>
<p>Numeric, opacity of subbasin polygons in Leaflet maps. Used if <code>map</code> contains polygon data. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_line.weight">line.weight</code></td>
<td>
<p>Numeric, weight of connection lines in Leaflet maps. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolylines()</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_line.opacity">line.opacity</code></td>
<td>
<p>Numeric, opacity of connection lines in Leaflet maps. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolylines()</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_seed">seed</code></td>
<td>
<p>Integer, seed number to to produce repeatable color palette.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_darken">darken</code></td>
<td>
<p>Numeric specifying the amount of darkening applied to the random color palette. Negative values will lighten the palette. See <code><a href="#topic+distinctColorPalette">distinctColorPalette</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_font.size">font.size</code></td>
<td>
<p>Numeric, font size (px) for subbasin labels in Leaflet maps.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_file">file</code></td>
<td>
<p>Save a Leaflet map to an image file by specifying the path to the desired output file using this argument. File extension must be specified.
See <code><a href="mapview.html#topic+mapshot">mapview::mapshot()</a></code>.
You may need to run <code><a href="webshot.html#topic+install_phantomjs">webshot::install_phantomjs()</a></code> the first time you save a map to an image file.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_vwidth">vwidth</code></td>
<td>
<p>Numeric, width of the exported Leaflet map image in pixels. See <code><a href="webshot.html#topic+webshot">webshot::webshot()</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_vheight">vheight</code></td>
<td>
<p>Numeric, height of the exported Leaflet map image in pixels. See <code><a href="webshot.html#topic+webshot">webshot::webshot()</a></code>.</p>
</td></tr>
<tr><td><code id="MapRegionalSources_+3A_html.name">html.name</code></td>
<td>
<p>Save a Leaflet map to an interactive HTML file by specifying the path to the desired output file using this argument. File extension must be specified.
See <code><a href="htmlwidgets.html#topic+saveWidget">htmlwidgets::saveWidget()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>MapRegionalSources</code> can return static plots or interactive Leaflet maps depending on value provided for the argument <code>map.type</code>.
By default, <code>MapRegionalSources</code> creates an <code>sf</code> object from HYPE SUBID centerpoints using a table of SUBID pairs. Regional
irrigation sources in HYPE are transfers from outlet lakes or rivers in a source sub-catchment to the soil storage of irrigated SLC classes
(Soil, Land use, Crop) in a target sub-catchment. If <code>map.type</code> is set to &quot;leaflet&quot;, then  <code>MapRegionalSources</code> returns an object of class <code>leaflet</code>.
</p>


<h3>Value</h3>

<p>For default static maps, <code>MapRegionalSources</code> returns an <code>sf</code> object containing columns <code>SUBID</code> (irrigation target
sub-catchment),  <code>REGSRCID</code> (irrigation source sub-catchment), and  <code>Length_[unit]</code> (distance between sub-catchments) where
'unit' is the actual length unit of the distances. The projection of the returned object is always identical to the projection of
argument <code>map</code>. For interactive Leaflet maps, <code>PlotMapOutput</code> returns an object of class <code>leaflet</code>. If <code>map</code> contains
polygon data, then the interactive map will include the polygons as a background layer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import subbasin centroids and subbasin polygons (to use as background)
require(sf)
te1 &lt;- st_read(dsn = system.file("demo_model", "gis",
"Nytorp_centroids.gpkg", package = "HYPEtools"))
te2 &lt;- st_read(dsn = system.file("demo_model", "gis",
"Nytorp_map.gpkg", package = "HYPEtools"))
# Create dummy MgmtData file with irrigation links
te3 &lt;- data.frame(SUBID = c(3594, 63794), REGSRCID = c(40556, 3486))

# Plot regional irrigation links between subbasins with subbasin outlines as background
MapRegionalSources(data = te3, map = te1, map.subid.column = 25)
plot(st_geometry(te2), add = TRUE, border = 2)


</code></pre>

<hr>
<h2 id='merge'>Merge HypeGeoData object</h2><span id='topic+merge'></span><span id='topic+merge.HypeGeoData'></span>

<h3>Description</h3>

<p>Merge an imported HYPE GeoData table of class <code>link{HypeGeoData}</code> with another data frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HypeGeoData'
merge(x, y, all.x = TRUE, sort = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_+3A_x">x</code></td>
<td>
<p><code><a href="#topic+HypeGeoData">HypeGeoData</a></code> data frame, HYPE GeoData table to be extended with new columns.</p>
</td></tr>
<tr><td><code id="merge_+3A_y">y</code></td>
<td>
<p>Data frame, with mandatory <code>SUBID</code> column.</p>
</td></tr>
<tr><td><code id="merge_+3A_all.x">all.x</code></td>
<td>
<p>Logical, keep all rows from <code>x</code>. Defaults to <code>TRUE</code>, as opposed to default method, thus extending the GeoData
table with columns in <code>y</code>.</p>
</td></tr>
<tr><td><code id="merge_+3A_sort">sort</code></td>
<td>
<p>Logical, result sorting by <code>by</code> columns. In addition to the default method's choices <code>TRUE, FALSE</code>, a third
option <code>NA</code> (default) will use sorting of <code>x</code> for results. I.e. a sorted GeoData table will be runnable in HYPE even after
merging.</p>
</td></tr>
<tr><td><code id="merge_+3A_...">...</code></td>
<td>
<p>Arguments passed to S3 method for data frames, see <code><a href="base.html#topic+merge">merge</a></code> and Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>merge.HypeGeoData</code> allows to merge new columns to an existing HYPE GeoData table, while preserving the <code>HypeGeoData</code>
class attribute. Duplicate columns are marked with a <code>".y"</code>-suffix for the merged <code>y</code> data frame.
</p>
<p>The following arguments of the default method are hard-coded:
</p>

<ul>
<li><p><code>by, by.x, by.y</code>, set to <code>"SUBID"</code>
</p>
</li>
<li><p><code>suffixes</code>, set to <code>c("", ".y")</code>
</p>
</li></ul>

<p>The method warns if any of these arguments is supplied by the user. To override, use the GeoData table as argument <code>y</code> or
call the data frame method explicitly (<code>merge.data.frame()</code>).
</p>


<h3>Value</h3>

<p>A <code>HypeGeoData</code> data frame.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+merge">merge</a></code>, the S3 generic function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># import and create dummy data
te1 &lt;- ReadGeoData(filename = system.file("demo_model",
"GeoData.txt", package = "HYPEtools"))
te2 &lt;- data.frame(SUBID = sample(x = te1$SUBID, size = 10),
loc_vol = runif(n = 10, 10, 50))
merge(x = te1, y = te2)

</code></pre>

<hr>
<h2 id='MergeObs'>Merge two HYPE observation data frames</h2><span id='topic+MergeObs'></span>

<h3>Description</h3>

<p>Function to merge two HYPE observation data frames, with handling of overlapping time periods and time periods gaps
as well as merging of common columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MergeObs(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MergeObs_+3A_x">x</code>, <code id="MergeObs_+3A_y">y</code></td>
<td>
<p>Data frames containing observation timeseries data. Typically imported using <code><a href="#topic+ReadObs">ReadObs</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>MergeObs</code> handles time steps of different lengths (e.g. daily, hourly), but requires identical time
step lengths from both inputs data frames.
</p>
<p>In case of common columns (identical date and SUBID combinations in <code>x</code> and <code>y</code>),
values from columns in <code>x</code> will take precedence, and values from <code>y</code> will only be added if
<code>x</code> values are missing.
</p>


<h3>Value</h3>

<p><code>MergeObs</code> returns a data frame with merged Obs data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import dummy data, add new observations to second Obs table, and merge
te1 &lt;- ReadObs(filename = system.file("demo_model", "Tobs.txt", package = "HYPEtools"))
te2 &lt;- ReadObs(filename = system.file("demo_model", "Tobs.txt", package = "HYPEtools"))
te2$X0000[1:365] &lt;- runif(n = 365, -20, 25)
MergeObs(x = te1, y = te2)

</code></pre>

<hr>
<h2 id='MergeXobs'>Merge two Xobs data frames</h2><span id='topic+MergeXobs'></span>

<h3>Description</h3>

<p>Function to merge two Xobs data frames, with handling of overlapping time periods and time periods gaps
as well as merging of common columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MergeXobs(x, y, comment = "")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MergeXobs_+3A_x">x</code>, <code id="MergeXobs_+3A_y">y</code></td>
<td>
<p>Data frames of class <code><a href="#topic+HypeXobs">HypeXobs</a></code>, including additional attributes <code>comment</code>,
<code>variable</code>, <code>subid</code>, and <code>timestep</code>, typically imported using <code><a href="#topic+ReadXobs">ReadXobs</a></code>.
For details on attribute format, see the class description. Class attribute not formally necessary.</p>
</td></tr>
<tr><td><code id="MergeXobs_+3A_comment">comment</code></td>
<td>
<p>Character string, will be added to the result as attribute <code>comment</code>. If empty,
comment attributes from <code>x</code> and <code>y</code> will be merged to new comment string.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>MergeXobs</code> handles time steps of different lengths (e.g. daily, hourly), but requires identical time
step lengths from both inputs data frames. The functions expects data frames of class <code><a href="#topic+HypeXobs">HypeXobs</a></code>
or data frames with comparable structure and will throw a warning if the class attribute is missing.
</p>
<p>In case of common columns (identical observation variable and SUBID combinations in <code>x</code> and <code>y</code>),
values from columns in <code>x</code> will take precedence, and values from <code>y</code> will only be added if
<code>x</code> values are missing
</p>


<h3>Value</h3>

<p><code>MergeXobs</code> returns a data frame with attributes for Xobs data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import dummy data, add new observations to second Xobs table
te1 &lt;- ReadXobs(filename = system.file("demo_model", "Xobs.txt", package = "HYPEtools"))
te2 &lt;- ReadXobs(filename = system.file("demo_model", "Xobs.txt", package = "HYPEtools"))
te2$WSTR_40541[1:10] &lt;- runif(n = 10, 50, 100)
MergeXobs(x = te1, y = te2)

</code></pre>

<hr>
<h2 id='NSE.HypeSingleVar'>Nash-Sutcliffe Efficiency</h2><span id='topic+NSE.HypeSingleVar'></span>

<h3>Description</h3>

<p>Nash-Sutcliffe Efficiency calculation for imported HYPE outputs with single variables for several catchments, i.e. time and
map files, optionally multiple model run iterations combined.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HypeSingleVar'
NSE(sim, obs, na.rm = TRUE, progbar = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NSE.HypeSingleVar_+3A_sim">sim</code></td>
<td>
<p><code><a href="#topic+HypeSingleVar">HypeSingleVar</a></code> array with simulated variable (one or several iterations).</p>
</td></tr>
<tr><td><code id="NSE.HypeSingleVar_+3A_obs">obs</code></td>
<td>
<p><code><a href="#topic+HypeSingleVar">HypeSingleVar</a></code> array with observed variable, (one iteration). If several iterations are present
in the array, only the first will be used.</p>
</td></tr>
<tr><td><code id="NSE.HypeSingleVar_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. If <code>TRUE</code>, incomplete sim-obs pairs will be removed prior to NSE computation.</p>
</td></tr>
<tr><td><code id="NSE.HypeSingleVar_+3A_progbar">progbar</code></td>
<td>
<p>Logical, if <code>TRUE</code> progress bars will be printed for main computational steps.</p>
</td></tr>
<tr><td><code id="NSE.HypeSingleVar_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>NSE.HypeSingleVar</code> returns a 2-dimensional array of NSE performances for all SUBIDs and model iterations provided in
argument <code>sim</code>, with values in the same order
as the second and third dimension in <code>sim</code>, i.e. <code>[subid, iteration]</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create dummy data, discharge observations with added white noise as model simulations
te1 &lt;- ReadObs(filename = system.file("demo_model", "Qobs.txt", package = "HYPEtools"))
te1 &lt;- HypeSingleVar(x = array(data = unlist(te1[, -1]) + 
                                      runif(n = nrow(te1), min = -.5, max = .5), 
                               dim = c(nrow(te1), ncol(te1) - 1, 1), 
                               dimnames = list(rownames(te1), colnames(te1)[-1])), 
                     datetime = te1$DATE, subid = obsid(te1), hype.var = "cout")
te2 &lt;- ReadObs(filename = system.file("demo_model", "Qobs.txt", package = "HYPEtools"))
te2 &lt;- HypeSingleVar(x = array(data = unlist(te2[, -1]), 
                               dim = c(nrow(te2), ncol(te2) - 1, 1), 
                               dimnames = list(rownames(te2), colnames(te2)[-1])), 
                     datetime = te2$DATE, subid = obsid(te2), hype.var = "rout")
# Nash-Sutcliffe Efficiency
NSE(sim = te1, obs = te2, progbar = FALSE)




</code></pre>

<hr>
<h2 id='OptimisedClasses'>Get optimized classes from an imported optpar.txt file</h2><span id='topic+OptimisedClasses'></span><span id='topic+OptimizedClasses'></span>

<h3>Description</h3>

<p><code>OptimisedClasses</code> checks which classes (land use or soil) of parameters in an imported optpar list are actually
optimized, i.e. have a min/max range larger than zero.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OptimisedClasses(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OptimisedClasses_+3A_x">x</code></td>
<td>
<p>list with named elements, as an object returned from <code><a href="#topic+ReadOptpar">ReadOptpar</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>OptimisedClasses</code> allows to quickly check which classes of parameters in an optpar.txt file are actually optimized
during a HYPE optimization run. The function compares min and max values in the <code>pars</code> element of an imported HYPE
optpar.txt file to identify those.
</p>


<h3>Value</h3>

<p><code>OptimisedClasses</code> returns a named list with one vector element for each parameter found in <code>x</code>. List element
names are HYPE parameter names. Each vector contains the optimized class numbers for the respective parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadOptpar(filename = system.file("demo_model", "optpar.txt", package = "HYPEtools"))
OptimisedClasses(te)

</code></pre>

<hr>
<h2 id='OutletIds'>Find Outlet IDs</h2><span id='topic+OutletIds'></span>

<h3>Description</h3>

<p>Function to find the identifier(s) used to signify model domain outlets, i.e. the &quot;downstream&quot; ID of outlet catchments, in a GeoData file.
This is typically just one number, often e.g. '0' or '-9999', but can be one or several IDs if the GeoData file originates from a HYPE sub-model
set-up, e.g. created with the 'SelectAro' program. Use <code><a href="#topic+OutletSubids">OutletSubids</a></code> to find the actual SUBID values of the outlet catchments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OutletIds(gd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OutletIds_+3A_gd">gd</code></td>
<td>
<p>Data frame with two columns <code>subid</code> and <code>maindown</code> (not case-sensitive).
Typically a 'GeoData.txt' file imported using <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>OutletIds</code> finds the unique outlet IDs of a GeoData file. The outlet ID of a typical model
is a single placeholder number, often e.g. '0' or '-9999', but there can be several outlet IDs, e.g. one or
several SUBIDs if the GeoData file originates from a HYPE sub-model set-up, created
with the 'SelectAro' tool.
</p>


<h3>Value</h3>

<p><code>OutletIds</code> returns a vector of outlet IDs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AllDownstreamSubids">AllDownstreamSubids</a></code>, <code><a href="#topic+OutletSubids">OutletSubids</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
OutletIds(gd = te)

</code></pre>

<hr>
<h2 id='OutletNearObs'>Find outlet-near observations in HYPE observation data files.</h2><span id='topic+OutletNearObs'></span>

<h3>Description</h3>

<p>Find observation stations close to specified outlet subbasins of a HYPE model set-up. Proximity threshold as upstream area fraction of target
outlet subbasin(s). Currently, only upstream observations are identified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OutletNearObs(
  gd,
  file.qobs = NULL,
  file.xobs = NULL,
  variable = NULL,
  outlets = NULL,
  frac.drain = 0.8,
  nearest.only = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OutletNearObs_+3A_gd">gd</code></td>
<td>
<p>Data frame with two columns <code>subid</code> and <code>maindown</code> (not case-sensitive).
Typically a 'GeoData.txt' file imported using <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="OutletNearObs_+3A_file.qobs">file.qobs</code>, <code id="OutletNearObs_+3A_file.xobs">file.xobs</code></td>
<td>
<p>Character string, file location of HYPE observation data file. <em>Only one of these needs to be
supplied</em>, with <code>file.qobs</code> taking precedence if both are provided. Either an
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:xobs.txt">Xobs.txt</a> or a
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:qobs.txt">Qobs.txt</a> file.</p>
</td></tr>
<tr><td><code id="OutletNearObs_+3A_variable">variable</code></td>
<td>
<p>Character string, HYPE variable to use. Needed only with argument <code>file.xobs</code>. If <code>NULL</code> (default),
a vector of available variables in <code>file.xobs</code> is returned.</p>
</td></tr>
<tr><td><code id="OutletNearObs_+3A_outlets">outlets</code></td>
<td>
<p>Integer vector, HYPE SUBIDs of subbasins to be considered outlets. If <code>NULL</code> (default), all outlet
subbasins in <code>gd</code> are used.</p>
</td></tr>
<tr><td><code id="OutletNearObs_+3A_frac.drain">frac.drain</code></td>
<td>
<p>Numeric, minimum fraction of drainage area at corresponding outlet to be covered by observation site.</p>
</td></tr>
<tr><td><code id="OutletNearObs_+3A_nearest.only">nearest.only</code></td>
<td>
<p>Logical, if <code>TRUE</code> (default), only the nearest observation site SUBID is returned. If <code>FALSE</code>,
all observation site SUBIDs available within <code>frac.drain</code> are returned.</p>
</td></tr>
<tr><td><code id="OutletNearObs_+3A_verbose">verbose</code></td>
<td>
<p>Logical, print status messages and progress bars during runtime.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>OutletNearObs</code> finds observation sites for observation variables in
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:qobs.txt">HYPE 'Qobs.txt'</a> and
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:xobs.txt">HYPE 'Xobs.txt'</a> files
located upstream an outlet sub-basin. For <code>file.xobs</code> files, which can hold several observation variables, a single variable has
to be selected (the function conveniently prints available variables in <code>file.xobs</code>, if no <code>variable</code> is provided).
Any number of SUBIDs present in <code>gd</code> can be defined as outlet subbasins with argument <code>outlets</code>. The function handles nested
outlets, i.e. cases where user-provided subbasins in <code>outlets</code> are upstream basins of one another. Outlet proximity is
defined by drainage area size compared to the respective outlet. The function returns either the nearest or all sites matching
or exceeding fraction <code>frac.drain</code>, depending on argument <code>nearest.only</code>.
</p>


<h3>Value</h3>

<p><code>OutletNearObs</code> returns a data frame with 4 columns, containing row-wise all observation sites which match the search
criteria:
</p>

<dl>
<dt>subid.outlet</dt><dd><p>SUBID of outlet subbasin</p>
</dd>
<dt>subid.obs</dt><dd><p>SUBID of observation site</p>
</dd>
<dt>area.fraction</dt><dd><p>Relative drainage area fraction of observation site, compared to corresponding outlet subbasin</p>
</dd>
<dt>area.outlet</dt><dd><p>Drainage area of outlet subbasin, in km^2</p>
</dd>
<dt>area.obs</dt><dd><p>Drainage area of observation site, in km^2</p>
</dd>
</dl>

<p>If <code>file.xobs</code> is provided without <code>variable</code>, the function prints available HYPE observation variables in <code>file.xobs</code> and silently
returns the same information as character vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Import source data
te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
# Find observation near domain outlet
OutletNearObs(file.qobs = system.file("demo_model", "Qobs.txt", package = "HYPEtools"), gd = te,
verbose = FALSE)
# get vector of variables in an Xobs file
OutletNearObs(file.xobs = system.file("demo_model", "Xobs.txt", package = "HYPEtools"), gd = te,
verbose = FALSE)


</code></pre>

<hr>
<h2 id='OutletSubids'>Find all Outlet SUBIDs of a model domain</h2><span id='topic+OutletSubids'></span>

<h3>Description</h3>

<p>Function to find all outlet SUBIDs of a HYPE model domain.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OutletSubids(gd)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="OutletSubids_+3A_gd">gd</code></td>
<td>
<p>A data frame, with two columns <code>subid</code> and <code>maindown</code>, (not case-sensitive).
Typically a 'GeoData.txt' file imported using <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>OutletSubids</code> finds all outlet SUBIDs of a model domain as provided in a 'GeoData.txt' file, i.e. all SUBIDs from which
stream water leaves the model domain.
</p>


<h3>Value</h3>

<p><code>OutletSubids</code> returns a vector of outlet SUBIDs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AllDownstreamSubids">AllDownstreamSubids</a></code>, <code><a href="#topic+OutletIds">OutletIds</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
OutletSubids(gd = te)

</code></pre>

<hr>
<h2 id='PartyParrot'>Create a Party Parrot.</h2><span id='topic+PartyParrot'></span>

<h3>Description</h3>

<p>Creates a Party Parrot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PartyParrot(sound = 8)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PartyParrot_+3A_sound">sound</code></td>
<td>
<p>Character string or number specifying which sound to play when showing the Party Parrot. See the <code>beep</code> function in the <code>beepr</code> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PartyParrot</code> generates a Party Parrot. Uses for Party Parrots include, for example, celebrating the successful execution of a script.
</p>


<h3>Value</h3>

<p>Returns a Party Parrot to the Console.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>PartyParrot()

</code></pre>

<hr>
<h2 id='pbias.HypeSingleVar'>Percent bias</h2><span id='topic+pbias.HypeSingleVar'></span>

<h3>Description</h3>

<p>Percent bias (PBIAS) calculation for imported HYPE outputs with single variables for several catchments, i.e. time and
map files, optionally multiple model runs combined.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HypeSingleVar'
pbias(sim, obs, na.rm = TRUE, progbar = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pbias.HypeSingleVar_+3A_sim">sim</code></td>
<td>
<p><code><a href="#topic+HypeSingleVar">HypeSingleVar</a></code> array with simulated variable (one or several iterations).</p>
</td></tr>
<tr><td><code id="pbias.HypeSingleVar_+3A_obs">obs</code></td>
<td>
<p><code><a href="#topic+HypeSingleVar">HypeSingleVar</a></code> array with observed variable, (one iteration). If several iterations are present
in the array, only the first will be used.</p>
</td></tr>
<tr><td><code id="pbias.HypeSingleVar_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical. If <code>TRUE</code>, incomplete sim-obs pairs will be removed prior to PBIAS computation.</p>
</td></tr>
<tr><td><code id="pbias.HypeSingleVar_+3A_progbar">progbar</code></td>
<td>
<p>Logical. If <code>TRUE</code>, progress bars will be printed for main computational steps.</p>
</td></tr>
<tr><td><code id="pbias.HypeSingleVar_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>pbias.HypeSingleVar</code> returns a 2-dimensional array of NSE performances for all SUBIDs and model iterations provided in
argument <code>sim</code>, with values in the same order
as the second and third dimension in <code>sim</code>, i.e. <code>[subid, iteration]</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create dummy data, discharge observations with added white noise as model simulations
te1 &lt;- ReadObs(filename = system.file("demo_model", "Qobs.txt", package = "HYPEtools"))
te1 &lt;- HypeSingleVar(x = array(data = unlist(te1[, -1]) + 
                               runif(n = nrow(te1), min = -.5, max = .5), 
                               dim = c(nrow(te1), ncol(te1) - 1, 1), 
                               dimnames = list(rownames(te1), colnames(te1)[-1])), 
                     datetime = te1$DATE, subid = obsid(te1), hype.var = "cout")
te2 &lt;- ReadObs(filename = system.file("demo_model", "Qobs.txt", package = "HYPEtools"))
te2 &lt;- HypeSingleVar(x = array(data = unlist(te2[, -1]), 
                               dim = c(nrow(te2), ncol(te2) - 1, 1), 
                               dimnames = list(rownames(te2), colnames(te2)[-1])), 
                     datetime = te2$DATE, subid = obsid(te2), hype.var = "rout")
# Percentage bias
pbias(sim = te1, obs = te2, progbar = FALSE)



</code></pre>

<hr>
<h2 id='PlotAnnualRegime'>Plot annual regimes</h2><span id='topic+PlotAnnualRegime'></span>

<h3>Description</h3>

<p>Convenience wrapper function for a combined line <code><a href="graphics.html#topic+plot">plot</a></code> with <code><a href="graphics.html#topic+polygon">polygon</a></code> variation ranges.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotAnnualRegime(
  x,
  line = c("mean", "median"),
  band = c("none", "p05p95", "p25p75", "minmax"),
  add.legend = FALSE,
  l.legend = NULL,
  l.position = c("topright", "bottomright", "right", "topleft", "left", "bottomleft"),
  log = FALSE,
  ylim = NULL,
  ylab = expression(paste("Q (m"^3, " s"^{
     -1
 }, ")")),
  xlab = paste(format(attr(x, "period"), format = "%Y"), collapse = " to "),
  col = "blue",
  alpha = 30,
  lty = 1,
  lwd = 1,
  mar = c(3, 3, 1, 1) + 0.1,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotAnnualRegime_+3A_x">x</code></td>
<td>
<p>List, typically a result from <code><a href="#topic+AnnualRegime">AnnualRegime</a></code>, containing data frames with aggregated long-term average
regime data and two attributes <code>period</code> and <code>timestep</code>.
See Details and Value sections there.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_line">line</code></td>
<td>
<p>Character string, keyword for type of average line to plot. Either <code>"mean"</code> or <code>"median"</code>.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_band">band</code></td>
<td>
<p>Character vector, keyword for variation bands. If <code>"none"</code> (default), plot average line(s) only. <code>"minmax"</code>,
<code>"p25p75"</code>, or <code>p5p95</code> to include bands of variation. Combinations of bands are allowed, but providing <code>"none"</code>
will always prevent plotting of any band. See details.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_add.legend">add.legend</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a legend will be added to the plot.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_l.legend">l.legend</code></td>
<td>
<p>Character vector. If non-NULL, legend labels are read from here instead of from column names in <code>x$mean</code>.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_l.position">l.position</code></td>
<td>
<p>Legend position, keyword string. One of <code>"left"</code>, <code>"topleft"</code>, <code>"topright"</code>,
<code>"right"</code>, <code>"bottomright"</code>, <code>"bottomleft"</code>.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_log">log</code></td>
<td>
<p>Logical, if <code>TRUE</code>, y-axis will be log-scaled.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_ylim">ylim</code></td>
<td>
<p>Numeric vector of length two, giving y-axis limits. Defaults to min-max range of all plotted data.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_ylab">ylab</code></td>
<td>
<p>Character or <code><a href="grDevices.html#topic+plotmath">plotmath</a></code> expression string. Y-axis label, with a default for discharge regimes.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_xlab">xlab</code></td>
<td>
<p>Character string or <code><a href="grDevices.html#topic+plotmath">plotmath</a></code> expression string, x-axis label. Default prints the time period on which the
regime is based, read from <code>x$period</code>.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_col">col</code></td>
<td>
<p>Line color specification, see <code><a href="graphics.html#topic+par">par</a></code> for details. Defaults to blue. Either a single value or a vector of the same length as quantile
series in <code>freq</code>.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_alpha">alpha</code></td>
<td>
<p>Numeric, alpha transparency value for variation bands. Value between <code>0</code> (transparent) and <code>255</code> (opaque), see
also <code><a href="grDevices.html#topic+rgb">rgb</a></code></p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_lty">lty</code></td>
<td>
<p>Line type specification, see <code><a href="graphics.html#topic+par">par</a></code> for details. Either a single value or a vector of the same length as quantile
series in <code>freq</code>.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_lwd">lwd</code></td>
<td>
<p>Line width specification, see <code><a href="graphics.html#topic+par">par</a></code> for details. Either a single value or a vector of the same length as quantile
series in <code>freq</code>.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_mar">mar</code></td>
<td>
<p>Numeric vector of length 4, margin specification as in <code><a href="graphics.html#topic+par">par</a></code> with modified default. Details see there.</p>
</td></tr>
<tr><td><code id="PlotAnnualRegime_+3A_verbose">verbose</code></td>
<td>
<p>Logical, print warnings if <code>NA</code> values are found in <code>x</code>. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PlotAnnualRegime</code> plots contents from lists as returned by <code><a href="#topic+AnnualRegime">AnnualRegime</a></code> (for format details, see there). If
<code>NA</code> values are present in the plot data, the function will throw a warning if <code>verbose = TRUE</code> and proceed with plotting
all available data.
</p>
<p>Argument <code>band</code> allows to plot variation bands to be plotted in addition to average lines. These can be (combinations of) ranges
between minima and maxima, 5th and 95th percentiles, and 25th and 75th percentiles, i.e. all moments available in <code>AnnualRegime</code>
results.
</p>
<p>Grid lines plotted in the background are mid-month lines.
</p>


<h3>Value</h3>

<p><code>PlotAnnualRegime</code> returns a plot to the currently active plot device.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AnnualRegime">AnnualRegime</a></code>, <code><a href="#topic+PlotSimObsRegime">PlotSimObsRegime</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Source data, HYPE basin output with a number of result variables
te1 &lt;- ReadBasinOutput(filename = system.file("demo_model",
                                              "results", "0003587.txt",
                                              package = "HYPEtools"))
# Daily discharge regime, computed and observed,
# hydrological year from October, aggregated to weekly means
te2 &lt;- AnnualRegime(te1[, c("DATE", "COUT", "ROUT")],
                    ts.in = "day",
                    ts.out = "week", start.mon = 10)
                    
# Screen devices should not be used in examples
## Not run: 
PlotAnnualRegime(x = te2)
PlotAnnualRegime(x = te2, line = "median", band = "p05p95",
  add.legend = TRUE, col = c("red", "blue"))

## End(Not run)

</code></pre>

<hr>
<h2 id='PlotBasinOutput'>Plot a suite of time series plots from a HYPE basin output file</h2><span id='topic+PlotBasinOutput'></span>

<h3>Description</h3>

<p>Plot a standard suite of time series plots from a basin output file, typically used for model performance inspection and/or
during manual calibration
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotBasinOutput(
  x,
  filename,
  driver = c("default", "pdf", "png", "screen"),
  timestep = attr(x, "timestep"),
  hype.vars = "all",
  vol.err = TRUE,
  log.q = FALSE,
  start.mon = 1,
  from = 1,
  to = nrow(x),
  date.format = "",
  name = "",
  area = NULL,
  subid = attr(x, "subid"),
  gd = NULL,
  bd = NULL,
  ylab.t1 = "Conc."
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotBasinOutput_+3A_x">x</code></td>
<td>
<p>Data frame, with column-wise equally-spaced time series of HYPE variables. Date-times in
<code><a href="base.html#topic+POSIXct">POSIXct</a></code> format in first column. Typically an imported basin output file from HYPE using <code><a href="#topic+ReadBasinOutput">ReadBasinOutput</a></code>.
See details for HYPE output variables required for plotting.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_filename">filename</code></td>
<td>
<p>String, file name for plotting to file device, see argument <code>driver</code>. <em>No file extension!</em> Ignored with plotting
to screen device. <em>Device dimensions are currently hard-coded, see Details.</em></p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_driver">driver</code></td>
<td>
<p>String, device driver name, one of <code>default</code>, <code>pdf</code>, <code>png</code>, or <code>screen</code>.
Defaults to <code>default</code>, which plots using default plotting device <code>getOption("device")</code>.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_timestep">timestep</code></td>
<td>
<p>Character string, timestep of <code>x</code>, one of <code>"month"</code>, <code>"week"</code>, <code>"day"</code>, or
<code>"nhour"</code> (n = number of hours). If not provided, an attribute <code>timestep</code> is required in <code>x</code>.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_hype.vars">hype.vars</code></td>
<td>
<p>Either a keyword string or a character vector of HYPE output variables. User-specified selection of HYPE variables
to plot. Default (<code>"all"</code>) is to plot all variables which the function knows and which are available in <code>x</code>. See details
for a list of known variables. Other possible keywords are <code>"hydro"</code> and <code>"wq"</code> (water quality), for which a pre-selected range of
(available) result variables is plotted. Alternatively, a character vector holding HYPE output variables to be plotted. Variables unknown
to the function will be ignored with a warning.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_vol.err">vol.err</code></td>
<td>
<p>Logical, if <code>TRUE</code> and both observed and simulated discharge are available in <code>x</code>, the accumulated volume error
will be plotted.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_log.q">log.q</code></td>
<td>
<p>Logical, y-axis scaling for flow duration curve and discharge time series, set to <code>TRUE</code> for log-scaling.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_start.mon">start.mon</code></td>
<td>
<p>Integer between 1 and 12, starting month of the hydrological year. For runoff regime plot, see also
<code><a href="#topic+AnnualRegime">AnnualRegime</a></code>.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_from">from</code>, <code id="PlotBasinOutput_+3A_to">to</code></td>
<td>
<p>Integer or date string of format \
interpreted as row indices of <code>x</code>.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_date.format">date.format</code></td>
<td>
<p>String format for x-axis dates/times. See <code><a href="base.html#topic+strptime">strptime</a></code>.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_name">name</code></td>
<td>
<p>Character string, name to be printed on the plot.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_area">area</code></td>
<td>
<p>Numeric, upstream area of sub-basin in m^2. Required for calculation of accumulated volume error. Optional argument,
either this or arguments <code>subid</code>, <code>gd</code>, and <code>bd</code> are required.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_subid">subid</code></td>
<td>
<p>Integer, HYPE SUBID of a target sub-catchment (must exist in <code>gd</code>). Mandatory in combination with <code>gd</code> and
optionally <code>bd</code> if argument <code>area</code> is not defined.  If not provided, an attribute <code>subid</code> is required in <code>x</code>.
Used to calculate upstream area internally with function <code><a href="#topic+SumUpstreamArea">SumUpstreamArea</a></code>. For repeated calls to <code>PlotBasinOutput</code>
providing <code>area</code> in combination with a one-off separate call to <code><a href="#topic+SumUpstreamArea">SumUpstreamArea</a></code> saves computation time,
especially in basins with many upstream sub-basins.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_gd">gd</code></td>
<td>
<p>A data frame, containing 'SUBID' and 'MAINDOWN' columns, e.g. an imported 'GeoData.txt' file. Mandatory with argument
<code>subid</code>, details see there.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_bd">bd</code></td>
<td>
<p>A data frame, containing 'BRANCHID' and 'SOURCEID' columns, e.g. an imported 'BranchData.txt' file. Optional with argument
<code>subid</code>, details see there.</p>
</td></tr>
<tr><td><code id="PlotBasinOutput_+3A_ylab.t1">ylab.t1</code></td>
<td>
<p>String or <code><a href="grDevices.html#topic+plotmath">plotmath</a></code> expression, y axis label for T1 tracer time series panel (tracer concentration units
are not prescribed in HYPE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PlotBasinOutput</code> plots a suite of time series along with a flow duration curve, a flow regime plot, and a selection of
goodness-of-fit measures from an imported HYPE basin output file. The function selects from a range of &quot;known&quot; variables, and plots
those which are available in the user-supplied basin output. It is mostly meant as a support tool during calibration, manual or
automatic, providing a quick and comprehensive overview of model dynamics in a subbasin of interest.
</p>
<p>HYPE outputs which are known to <code>PlotBasinOutput</code> include:
</p>

<ul>
<li><p>precipitation
</p>
</li>
<li><p>air temperature
</p>
</li>
<li><p>discharge
</p>
</li>
<li><p>lake water level
</p>
</li>
<li><p>water temperature
</p>
</li>
<li><p>evapotranspiration
</p>
</li>
<li><p>snow water equivalent
</p>
</li>
<li><p>sub-surface storage components
</p>
</li>
<li><p>nitrogen concentrations
</p>
</li>
<li><p>phosphorus concentrations
</p>
</li>
<li><p>suspended sediment concentrations
</p>
</li>
<li><p>total sediment concentrations
</p>
</li>
<li><p>tracer concentration
</p>
</li></ul>

<p>Below a complete list of HYPE variables known to the function in HYPE info.txt format, ready to copy-paste into an info.txt file.
For a detailed description of the variables, see the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables">HYPE online documentation</a>.
</p>
<p><code>basinoutput variable upcprf upcpsf temp upepot upevap cout rout soim sm13 upsmfp snow upcprc cct2 ret2 ccin rein ccon reon cctn retn 
ccsp resp ccpp repp cctp retp wcom wstr ccss ress ccts rets cct1 ret1</code>
</p>
<p><em>Device dimensions</em> are hard-coded to a width of 15 inches and height depending on the number of plotted time series. When plotting
to a screen device, a maximum height of 10 inches is enforced in order to prevent automatic resizing with slow redrawing.
<code>PlotBasinOutput</code> throws a warning if the plot height exceeds 10 inches, which can lead to overlapping plot elements. On screens with
less than 10 inch screen, redrawing is inhibited, which can lead to an empty plot. The recommended solution for both effects
is to plot to pdf or png file devices instead.
</p>


<h3>Value</h3>

<p>Returns a multi-panel plot in a new graphics device.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotBasinSummary">PlotBasinSummary</a></code>, <code><a href="#topic+PlotAnnualRegime">PlotAnnualRegime</a></code>, <code><a href="#topic+PlotDurationCurve">PlotDurationCurve</a></code>, <code><a href="#topic+ReadBasinOutput">ReadBasinOutput</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Source data, HYPE basin output with a number of result variables
te1 &lt;- ReadBasinOutput(filename = system.file("demo_model",
"results","0003587.txt", package = "HYPEtools"))
te2 &lt;- ReadGeoData(filename = system.file("demo_model",
"GeoData.txt", package = "HYPEtools"))

## Not run:  
# Plot selected water variables on screen device
PlotBasinOutput(x = te1, gd = te2, driver = "screen",hype.vars = c("cout", "rout", 
"snow", "upcprf", "upcpsf"))

## End(Not run)

</code></pre>

<hr>
<h2 id='PlotBasinSummary'>Plot a summary of model results for a single sub-basin</h2><span id='topic+PlotBasinSummary'></span>

<h3>Description</h3>

<p>Plot a standard suite of plots summarizing properties of a sub-basin including upstream area and model performance
for discharge and concentrations of nutrients, sediment, and tracers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotBasinSummary(
  x,
  filename,
  driver = c("default", "pdf", "png", "screen"),
  panels = 1,
  gd = NULL,
  bd = NULL,
  gcl = NULL,
  psd = NULL,
  subid = NULL,
  desc = NULL,
  timestep = attr(x, "timestep"),
  hype.vars = "all",
  from = 1,
  to = nrow(x),
  log = FALSE,
  xscale = "gauss",
  start.mon = 10,
  name = "",
  ylab.t1 = "Conc."
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotBasinSummary_+3A_x">x</code></td>
<td>
<p>Data frame, with column-wise daily time series of HYPE variables. Date-times in
<code><a href="base.html#topic+POSIXct">POSIXct</a></code> format in first column. Typically an imported basin output file from HYPE using <code><a href="#topic+ReadBasinOutput">ReadBasinOutput</a></code>.
See details for HYPE output variables required for plotting.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_filename">filename</code></td>
<td>
<p>String, file name for plotting to file device, see argument <code>driver</code>. <em>No file extension!</em> Ignored with plotting
to screen device. <em>Device dimensions are currently hard-coded, see Details.</em></p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_driver">driver</code></td>
<td>
<p>String, device driver name, one of <code>default</code>, <code>pdf</code>, <code>png</code>, or <code>screen</code>.
Defaults to <code>default</code>, which plots using default plotting device <code>getOption("device")</code>.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_panels">panels</code></td>
<td>
<p>Integer, either <code>1</code>, <code>2</code>, or <code>3</code>, indicating which panels to plot. See Details.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_gd">gd</code></td>
<td>
<p>A data frame, containing 'SUBID', 'MAINDOWN', and 'AREA' columns, e.g. an imported 'GeoData.txt' file.
Only needed with bar chart panels, see Details.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_bd">bd</code></td>
<td>
<p>A data frame, containing 'BRANCHID' and 'SOURCEID' columns, e.g. an imported 'BranchData.txt' file.
Optional argument. Only needed with bar chart panels, see Details.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_gcl">gcl</code></td>
<td>
<p>Data frame containing columns with SLCs and corresponding land use and soil class IDs, typically a 'GeoClass.txt'
file imported with <code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code>. Only needed with bar chart panels, see Details.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_psd">psd</code></td>
<td>
<p>A data frame with HYPE point source specifications, typically a 'PointSourceData.txt' file imported with
<code><a href="#topic+ReadPointSourceData">ReadPointSourceData</a></code>. Only needed with bar chart panels, see Details.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_subid">subid</code></td>
<td>
<p>Integer, SUBID of sub-basin for which results are plotted. If <code>NULL</code> (default), a <code>subid</code> attribute is
required in <code>x</code>. Only needed with bar chart panels, see Details.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_desc">desc</code></td>
<td>
<p>List for use with <code>type</code>. Class description labels imported from a 'description.txt' file, for bar labeling.
See <code><a href="#topic+ReadDescription">ReadDescription</a></code> for formatting details. Only needed with bar chart panels, see Details.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_timestep">timestep</code></td>
<td>
<p>Character string, timestep of <code>x</code>, one of <code>"month"</code>, <code>"week"</code>, <code>"day"</code>, or
<code>"nhour"</code> (n = number of hours). If not provided, an attribute <code>timestep</code> is required in <code>x</code>.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_hype.vars">hype.vars</code></td>
<td>
<p>Either a keyword string or a character vector of HYPE output variables. User-specified selection of HYPE variables
to plot. Default (<code>"all"</code>) is to plot all variables which the function knows and which are available in <code>x</code>. See details
for a list of known variables. Other possible keywords are <code>"hydro"</code> and <code>"wq"</code> (water quality), for which a pre-selected range of
(available) result variables is plotted. Alternatively, a character vector holding HYPE output variable IDs to be plotted. Variables unknown
to the function will be ignored with a warning.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_from">from</code>, <code id="PlotBasinSummary_+3A_to">to</code></td>
<td>
<p>Integer or date string of format \
interpreted as row indices of <code>x</code>.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_log">log</code></td>
<td>
<p>Logical, log scaling discharge and concentrations.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_xscale">xscale</code></td>
<td>
<p>Character string, keyword for x-axis scaling. Either <code>"lin"</code> for linear scaling or <code>"gauss"</code> for gaussian scaling.
See description in <code><a href="#topic+PlotDurationCurve">PlotDurationCurve</a></code>.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_start.mon">start.mon</code></td>
<td>
<p>Integer between 1 and 12, starting month of the hydrological year. For regime plots, see also
<code><a href="#topic+AnnualRegime">AnnualRegime</a></code>.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_name">name</code></td>
<td>
<p>Character or expression string. Site name to plot besides bar chart panels. Only relevant with <code>panels</code> <code>1</code> or <code>3</code>.</p>
</td></tr>
<tr><td><code id="PlotBasinSummary_+3A_ylab.t1">ylab.t1</code></td>
<td>
<p>String or <code><a href="grDevices.html#topic+plotmath">plotmath</a></code> expression, y axis label for T1 tracer time series panel (tracer concentration units
are not prescribed in HYPE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PlotBasinSummary</code> plots a multi-panel plot with a number of plots to evaluate model properties and performances for a
chosen sub-basin. Performance plots include discharge, HYPE-modeled nutrient species for nitrogen (total, inorganic, organic)
and phosphorus (total, particulate, soluble), and HYPE modeled suspended and total sediment concentrations.
</p>
<p>Plotted panels show:
</p>

<ul>
<li><p><em>Summarized catchment characteristics as bar charts</em>: Upstream-averaged land use, soil, and crop group fractions; modeled nutrient
loads in sub-basin outlet, and summed upstream gross loads from point sources and rural households (if necessary variables available, omitted
otherwise).
</p>
</li>
<li><p><em>Goodness-of-fit measures for discharge and concentrations</em>: KGE (Kling-Gupta Efficiency), NSE (Nash-Sutcliffe Efficiency), PBIAS
(Percentage Bias, aka relative error), MAE (Mean Absolute Error), r (Pearson product-moment correlation coefficient), VE (Volumetric Efficiency).
</p>
</li>
<li><p><em>Simulation-observation relationships for discharge and concentrations</em>: Simulated and observed concentration-discharge relationships,
relationship between observed and simulated nutrient, sediment, and tracer concentrations.
</p>
</li>
<li><p><em>Duration curves for flow and concentrations</em>: Pairwise simulated and observed curves.
</p>
</li>
<li><p><em>Annual regimes for flow and concentrations</em>: Pairwise simulated and observed regime plots at monthly aggregation, with
number of observations for concentration regimes.
</p>
</li>
<li><p><em>Corresponding plots for IN/TN and SP/TP ratios</em>.
</p>
</li></ul>

<p>Per default, the function plots from available model variables in an imported HYPE basin output file, and missing variables will be
automatically omitted. Variable selection can be additionally fine-tuned using argument <code>hype.vars</code>.
</p>
<p>Argument <code>panels</code> allows to choose if bar chart panels should be plotted. This can be time-consuming for sites with many upstream
sub-basins and might not necessary e.g. during calibration. If <code>1</code> (default), all panels are plotted. If set to <code>2</code>, bar
charts will be excluded. If <code>3</code>, only bar charts will be plotted. Arguments <code>gd</code>, <code>bd</code>, <code>gcl</code>, <code>psd</code>, <code>subid</code>,
and <code>desc</code> are only needed for bar chart plotting.
</p>
<p>Below a complete list of HYPE variables known to the function in HYPE info.txt format, ready to copy-paste into an info.txt file.
For a detailed description of the variables, see the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables">HYPE online documentation</a>.
</p>
<p><code>basinoutput variable cout rout ccin rein ccon reon cctn retn ccsp resp ccpp repp cctp retp ctnl ctpl ccss ress ccts rets cct1 ret1</code>
</p>
<p>#' <em>Device dimensions</em> are hard-coded to a width of 13 inches and height depending on the number of plotted time series. When plotting
to a screen device, a maximum height of 10 inches is enforced in order to prevent automatic resizing with slow redrawing.
<code>PlotBasinOutput</code> throws a warning if the plot height exceeds 10 inches, which can lead to overlapping plot elements. On screens with
less than 10 inch screen height, redrawing is inhibited, which can lead to an empty plot. The recommended solution for both effects
is to plot to pdf or png file devices instead.
</p>


<h3>Value</h3>

<p>Returns a multi-panel plot in a new graphics device.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotBasinOutput">PlotBasinOutput</a></code>, <code><a href="#topic+BarplotUpstreamClasses">BarplotUpstreamClasses</a></code>, <code><a href="#topic+PlotSimObsRegime">PlotSimObsRegime</a></code>, <code><a href="#topic+PlotAnnualRegime">PlotAnnualRegime</a></code>,
<code><a href="#topic+PlotDurationCurve">PlotDurationCurve</a></code>, <code><a href="#topic+ReadBasinOutput">ReadBasinOutput</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Source data, HYPE basin output with a number of result variables
te1 &lt;- ReadBasinOutput(filename = system.file("demo_model", "results", "0003587.txt", 
                       package = "HYPEtools"))
te2 &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))

## Not run: 
# Plot basin summary for discharge on screen device
PlotBasinSummary(x = te1, gd = te2, driver = "screen", panels = 2)

## End(Not run)

</code></pre>

<hr>
<h2 id='PlotDurationCurve'>Plot duration curves</h2><span id='topic+PlotDurationCurve'></span>

<h3>Description</h3>

<p>Convenience wrapper function for a (multiple) line <code><a href="graphics.html#topic+plot">plot</a></code>, with pretty defaults for axis annotation and a Gaussian scaling option for the x-axis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotDurationCurve(
  freq,
  xscale = "lin",
  yscale = "log",
  add.legend = FALSE,
  l.legend = NULL,
  ylim = NULL,
  xlab = "Flow exceedance percentile",
  ylab = "m3s",
  col = "blue",
  lty = 1,
  lwd = 1,
  mar = c(3, 3, 1, 1) + 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotDurationCurve_+3A_freq">freq</code></td>
<td>
<p>Data frame with at least two columns, containing probabilities in the first and series of data quantiles in the remaining columns. Typically
an object as returned by <code><a href="#topic+ExtractFreq">ExtractFreq</a></code> or a subset thereof.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_xscale">xscale</code></td>
<td>
<p>Character string, keyword for x-axis scaling. Either <code>"lin"</code> for linear scaling or <code>"gauss"</code> for gaussian scaling as in a normal
probability plot, which allows for for better comparison of low flow and high flow frequencies.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_yscale">yscale</code></td>
<td>
<p>Character string, keyword for y-axis scaling. Either <code>"lin"</code> for linear scaling or <code>"log"</code> for common logarithm scaling.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_add.legend">add.legend</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a legend will be added to the plot, including the number of observations on which the quantiles are based for
each curve if <code>freq</code> is a result from <code><a href="#topic+ExtractFreq">ExtractFreq</a></code>.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_l.legend">l.legend</code></td>
<td>
<p>Character vector. If non-NULL, legend labels are read from here instead of from column names in <code>freq</code>.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_ylim">ylim</code></td>
<td>
<p>Numeric vector of length two, giving y-axis limits. <code>NULL</code> for default values.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_xlab">xlab</code></td>
<td>
<p>Character string, x-axis label.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_ylab">ylab</code></td>
<td>
<p>Character or <code><a href="grDevices.html#topic+plotmath">plotmath</a></code> expression string. Y-axis label, either as keyword <code>"m3s"</code> or <code>"mmd"</code> for pre-defined pretty
discharge labels, or any other string which will be plotted unchanged.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_col">col</code></td>
<td>
<p>Line color specification, see <code><a href="graphics.html#topic+par">par</a></code> for details. Defaults to blue. Either a single value or a vector of the same length as quantile
series in <code>freq</code>.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_lty">lty</code></td>
<td>
<p>Line type specification, see <code><a href="graphics.html#topic+par">par</a></code> for details. Either a single value or a vector of the same length as quantile
series in <code>freq</code>.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_lwd">lwd</code></td>
<td>
<p>Line width specification, see <code><a href="graphics.html#topic+par">par</a></code> for details. Either a single value or a vector of the same length as quantile
series in <code>freq</code>.</p>
</td></tr>
<tr><td><code id="PlotDurationCurve_+3A_mar">mar</code></td>
<td>
<p>Numeric vector of length 4, margin specification as in <code><a href="graphics.html#topic+par">par</a></code> with modified default. Details see there.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PlotDurationCurve</code> plots a duration curve with pretty formatting defaults. The function sets <code><a href="graphics.html#topic+par">par</a></code> parameters <code>tcl</code> and <code>mgp</code>
internally and will override previously set values for the returned plot. It typically uses results from <code><a href="#topic+ExtractFreq">ExtractFreq</a></code> as input data and via that
function it can be used to visualize and compare time series properties.
</p>


<h3>Value</h3>

<p><code>PlotDurationCurve</code> returns a plot to the currently active plot device.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ExtractFreq">ExtractFreq</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import source data
te1 &lt;- ReadBasinOutput(filename = system.file("demo_model", "results", "0003587.txt", 
                       package = "HYPEtools"))
te2 &lt;- ExtractFreq(te1[, c("COUT", "ROUT")])
# Plot flow duration curves for simulated and observed discharge
PlotDurationCurve(freq = te2, add.legend = TRUE, col = c("red", "blue"))

</code></pre>

<hr>
<h2 id='PlotMapOutput'>Plot function for HYPE map results.</h2><span id='topic+PlotMapOutput'></span>

<h3>Description</h3>

<p>Draw HYPE map results, with pretty scale discretizations and color ramp defaults for select HYPE variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotMapOutput(
  x,
  map = NULL,
  map.subid.column = 1,
  var.name = "",
  map.type = "default",
  shiny.data = FALSE,
  plot.legend = TRUE,
  legend.pos = "right",
  legend.title = NULL,
  legend.signif = 2,
  col = "auto",
  col.ramp.fun,
  col.breaks = NULL,
  col.labels = NULL,
  col.rev = FALSE,
  plot.scale = TRUE,
  scale.pos = "br",
  plot.arrow = TRUE,
  arrow.pos = "tr",
  weight = 0.15,
  opacity = 0.75,
  fillOpacity = 0.5,
  outline.color = "black",
  na.color = "#808080",
  plot.searchbar = FALSE,
  plot.label = FALSE,
  plot.label.size = 2.5,
  plot.label.geometry = c("centroid", "surface"),
  file = "",
  width = NA,
  height = NA,
  units = c("in", "cm", "mm", "px"),
  dpi = 300,
  vwidth = 1424,
  vheight = 1000,
  html.name = "",
  map.adj = 0,
  legend.outer = FALSE,
  legend.inset = c(0, 0),
  par.cex = 1,
  par.mar = rep(0, 4) + 0.1,
  add = FALSE,
  sites = NULL,
  sites.subid.column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotMapOutput_+3A_x">x</code></td>
<td>
<p>HYPE model results, typically 'map output' results. Data frame object with two columns, first column containing SUBIDs and
second column containing model results to plot. See details.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_map">map</code>, <code id="PlotMapOutput_+3A_sites">sites</code></td>
<td>
<p>A <code>SpatialPolygonsDataFrame</code> or <code>sf</code> object. Typically an imported sub-basin vector polygon file. Import of vector polygons
requires additional packages, e.g. <a href="sf.html#topic+st_read">sf::st_read</a>. For interactive Leaflet maps a small/simplified polygon file should be used as larger
files can take an excessive amount of time to render.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_map.subid.column">map.subid.column</code>, <code id="PlotMapOutput_+3A_sites.subid.column">sites.subid.column</code></td>
<td>
<p>Integer, column index in the <code>map</code> 'data' <code><a href="methods.html#topic+slot">slot</a></code> holding SUBIDs (sub-catchment IDs).</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_var.name">var.name</code></td>
<td>
<p>Character string. HYPE variable name to be plotted. Mandatory for automatic color ramp selection of pre-defined
HYPE variables (<code>col = "auto"</code>). Not case-sensitive. See details.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_map.type">map.type</code></td>
<td>
<p>Map type keyword string. Choose either <code>"default"</code> for the default static plots or <code>"leaflet"</code> for interactive Leaflet maps. Use <code>"legacy"</code> for deprecated static plots.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_shiny.data">shiny.data</code></td>
<td>
<p>Logical, if <code>map.type</code> is <code>"leaflet"</code>, then should the output be a list containing the basemap, formatted data, legend colors, and legend labels? Typically set to <code>FALSE</code> unless using <code>PlotMapOutput</code> to create Shiny apps or custom Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_plot.legend">plot.legend</code></td>
<td>
<p>Logical, plot a legend along with the map.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_legend.pos">legend.pos</code></td>
<td>
<p>Keyword string for legend position. For static plots, one of: <code>"none"</code>, <code>"left"</code>, <code>"right"</code>,
<code>"bottom"</code>, <code>"top"</code>, or a two-element numeric vector. For interactive Leaflet maps, one of: <code>"topleft"</code>, <code>"topright"</code>, <code>"bottomright"</code>, <code>"bottomleft"</code>. For legacy static plots, one of: <code>"left"</code>, <code>"topleft"</code>, <code>"topright"</code>,
<code>"right"</code>, <code>"bottomright"</code>, <code>"bottomleft"</code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_legend.title">legend.title</code></td>
<td>
<p>Character string or mathematical expression. An optional title for the legend. If none is provided here, <code>var.name</code>
is used as legend title string. For select HYPE variables, pretty legend titles are in-built.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_legend.signif">legend.signif</code></td>
<td>
<p>Integer, number of significant digits to display in legend labels.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_col">col</code></td>
<td>
<p>Colors to use on the map. One of the following: </p>

<ul>
<li> <p><code>"auto"</code> to allow for automatic selection from tailored color ramp palettes and break points based on argument <code>var.name</code>,
see details
</p>
</li>
<li><p> A color ramp palette function, e.g. as returned from a call to <code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code>. A number of tailored functions are
available in <code>HYPEtools</code>, see <code><a href="#topic+CustomColors">CustomColors</a></code>
</p>
</li>
<li><p> A vector of colors. This can be a character vector of R's built-in color names or hexadecimal strings as returned by
<code><a href="grDevices.html#topic+rgb">rgb</a></code>, or an integer vector of current <code><a href="grDevices.html#topic+palette">palette</a></code> indices.
</p>
</li></ul>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_col.ramp.fun">col.ramp.fun</code></td>
<td>
<p>DEPRECATED, for backwards compatibility only.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_col.breaks">col.breaks</code></td>
<td>
<p>A numeric vector, specifying break points for discretization of model result values into classes. Used if a color palette is specified with <code>col</code> argument.
Class boundaries will be interpreted as right-closed, i.e upper boundaries included in class. Lowest class boundary included in lowest class as well.
Meaningful results require the lowest and uppermost breaks to bracket all model result values, otherwise there will be
unclassified white spots on the map plot. Not mandatory, can optionally
be combined with one of the pre-defined palettes, including <code>"auto"</code> selection. Per default, a generic
classification will be applied (see details).</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_col.labels">col.labels</code></td>
<td>
<p>A character vector, specifying custom labels to be used for each legend item. Works with <code>map.type</code> set to <code>default</code> or <code>leaflet</code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_col.rev">col.rev</code></td>
<td>
<p>Logical, If <code>TRUE</code>, then color palette will be reversed.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_plot.scale">plot.scale</code></td>
<td>
<p>Logical, plot a scale bar on map. NOTE: Scale bar may be inaccurate for geographic coordinate systems (Consider switching to projected coordinate system).</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_scale.pos">scale.pos</code></td>
<td>
<p>Keyword string for scalebar position for static maps. One of <code>bl</code>, <code>br</code>, <code>tr</code>, or <code>tl</code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_plot.arrow">plot.arrow</code></td>
<td>
<p>Logical, plot a North arrow in static maps.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_arrow.pos">arrow.pos</code></td>
<td>
<p>Keyword string for north arrow position for static maps. One of <code>bl</code>, <code>br</code>, <code>tr</code>, or <code>tl</code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_weight">weight</code></td>
<td>
<p>Numeric, weight of subbasin boundary lines. See <code><a href="ggplot2.html#topic+geom_sf">geom_sf</a></code> for static maps and <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code> for Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_opacity">opacity</code></td>
<td>
<p>Numeric, opacity of subbasin boundary lines in Leaflet maps. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_fillopacity">fillOpacity</code></td>
<td>
<p>Numeric, opacity of subbasin polygons in Leaflet maps. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_outline.color">outline.color</code></td>
<td>
<p>Character string of color to use to for subbasin polygon outlines. Use <code>NA</code> to hide the outlines.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_na.color">na.color</code></td>
<td>
<p>Character string of color to use to symbolize subbasin polygons in maps which correspond to <code>NA</code> values.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_plot.searchbar">plot.searchbar</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then a search bar will be included within Leaflet maps. See <code><a href="leaflet.extras.html#topic+search-features">leaflet.extras::addSearchFeatures()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_plot.label">plot.label</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then labels will be displayed on default static maps and in Leaflet maps when the cursor hovers over subbasins.
See <code><a href="ggplot2.html#topic+geom_sf_text">geom_sf_text</a></code> for default maps and <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code> for Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_plot.label.size">plot.label.size</code></td>
<td>
<p>Numeric, size of text for labels on default static plots. See <code><a href="ggplot2.html#topic+geom_sf_text">geom_sf_text</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_plot.label.geometry">plot.label.geometry</code></td>
<td>
<p>Keyword string to select where plot labels should be displayed on the default static plots. Either <code>centroid</code> to use <code>sf::st_centroid</code> or <code>surface</code> to use <code>sf::st_point_on_surface</code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_file">file</code></td>
<td>
<p>Save map to an image file by specifying the path to the desired output file using this argument. File extension must be specified. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code> for static maps and
<code><a href="mapview.html#topic+mapshot">mapview::mapshot()</a></code> for Leaflet maps. You may need to run <code>webshot::install_phantomjs()</code> the first time you save a Leaflet map to an image file. See <code><a href="webshot.html#topic+install_phantomjs">webshot::install_phantomjs()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_width">width</code></td>
<td>
<p>Numeric, width of output plot for static maps in units of <code>units</code>. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_height">height</code></td>
<td>
<p>Numeric, height of output plot for static maps in units of <code>units</code>. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_units">units</code></td>
<td>
<p>Keyword string for units to save static map. One of <code>"in"</code>, <code>"cm"</code>, <code>"mm"</code>, <code>"px"</code>. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_dpi">dpi</code></td>
<td>
<p>Integer, resolution to save static map. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_vwidth">vwidth</code></td>
<td>
<p>Numeric, width of the exported Leaflet map image in pixels. See <code><a href="mapview.html#topic+mapshot">mapview::mapshot()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_vheight">vheight</code></td>
<td>
<p>Numeric, height of the exported Leaflet map image in pixels. See <code><a href="mapview.html#topic+mapshot">mapview::mapshot()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_html.name">html.name</code></td>
<td>
<p>Save Leaflet map to an interactive HTML file by specifying the path to the desired output file using this argument.
File extension must be specified. See <code><a href="htmlwidgets.html#topic+saveWidget">htmlwidgets::saveWidget()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_map.adj">map.adj</code></td>
<td>
<p>Numeric, map adjustment in direction where it is smaller than the plot window. A value of <code>0</code> means left-justified
or bottom-justified, <code>0.5</code> (the default) means centered, and <code>1</code> means right-justified or top-justified. Only used for default maps.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_legend.outer">legend.outer</code></td>
<td>
<p>Logical. If <code>TRUE</code>, outer break point values will be plotted in legend.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_legend.inset">legend.inset</code></td>
<td>
<p>Numeric, inset distance(s) from the margins as a fraction of the plot region for legend, scale and north arrow.
See <code><a href="graphics.html#topic+legend">legend</a></code> and details below.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_par.cex">par.cex</code></td>
<td>
<p>Numeric, character expansion factor. See description of <code>cex</code> in <code><a href="graphics.html#topic+par">par</a></code>. Only used for default maps.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_par.mar">par.mar</code></td>
<td>
<p>Plot margins as in <code><a href="graphics.html#topic+par">par</a></code> argument <code>mar</code>. Defaults to a nearly margin-less plot.
In standard use cases of this function, plot margins do not need to be changed. Only used for default maps.</p>
</td></tr>
<tr><td><code id="PlotMapOutput_+3A_add">add</code></td>
<td>
<p>Logical, default <code>FALSE</code>. If <code>TRUE</code>, add to existing plot. In that case <code>map.adj</code> has no effect. Only used for default maps.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PlotMapOutput</code> plots HYPE results from 'map[variable name].txt' files, typically imported using <code><a href="#topic+ReadMapOutput">ReadMapOutput</a></code>.
<code>x</code> arguments <strong>must</strong> contain the variable of interest in the second column. For map results with multiple columns, i.e.
several time periods, pass index selections to <code>x</code>, e.g. <code>mymapresult[, c(1, 3)]</code>.
</p>
<p><code>PlotMapOutput</code> can return static plots or interactive Leaflet maps depending on value provided for the argument <code>map.type</code>.
For backwards compatibility, legacy static plots can still be generated by setting <code>map.type</code> to <code>legacy</code>. For legacy plots, <code>legend.pos</code> and
<code>map.adj</code> should be chosen so that legend and map do not overlap, and the legend position can be fine-tuned using
argument <code>legend.inset</code>. This is particularly useful for legend titles with more than one line. In order to move map and legend closer to each other, change the plot device width.
For details on inset specification for the default maps, see <code>inset</code> in <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>
<p>Mapped variables are visualized using color-coded data intervals. <code>HYPEtools</code> provides a number of color ramps functions for HYPE variables,
see <code><a href="#topic+CustomColors">CustomColors</a></code>. These are either single-color ramps with less saturated colors for smaller values
and more saturated values for higher values, suitable for e.g. concentration or volume ranges, or multi-color ramps suitable for calculated
differences, e.g. between two model runs.
</p>
<p>Break points between color classes of in-built or user-provided color ramp palettes can optionally be provided in argument
<code>col.breaks</code>. This is particularly useful when specific pretty class boundaries are needed, e.g. for publication figures. Per default,
break points for internal single color ramps and user-provided ramps are calculated based on 10\
<code>x</code>. Default break points for internal color ramp <code>ColDiffGeneric</code> are based on an equal distance classification of log-scaled
<code>x</code> ranges, centered around zero. For internal color ramp <code>ColDiffTemp</code>, they are breaks in an interval from -7.5 to 7.5 K.
</p>
<p>For select common HYPE variables, given in argument <code>var.name</code>, an automatic color ramp selection including pretty breaks and legend titles
is built into <code>PlotMapOutput</code>. These are 'CCTN', 'CCTP', 'COUT', and 'TEMP'. Automatic selection is activated by choosing keyword
<code>"auto"</code> in <code>col</code>. All other HYPE variables will be plotted using a generic color ramp palette and generic break points with
<code>"auto"</code> color selection.
</p>


<h3>Value</h3>

<p>For default static maps, <code>PlotMapOutput</code> returns an object of class <code>ggplot</code>. This plot can also be assigned to a variable in the environment.
For interactive Leaflet maps, <code>PlotMapOutput</code> returns an object of class <code>leaflet</code>. For legacy static plots, <code>PlotMapOutput</code> returns a plot to the
currently active plot device, and invisibly an object of class <code>SpatialPolygonsDataFrame</code> as provided in argument <code>map</code>, with plotted values and color codes added as columns
in the data slot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadMapOutput">ReadMapOutput</a></code> for HYPE result import; <code><a href="#topic+PlotMapPoints">PlotMapPoints</a></code> for plotting HYPE results at points, e.g. sub-basin outlets.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Import plot data and subbasin polygons
require(sf)
te1 &lt;- ReadMapOutput(filename = system.file("demo_model",
"results", "mapCRUN.txt", package = "HYPEtools"), dt.format = NULL)
te2 &lt;- st_read(dsn = system.file("demo_model",
"gis", "Nytorp_map.gpkg", package = "HYPEtools"))
# plot runoff map
PlotMapOutput(x = te1, map = te2, map.subid.column = 25,
var.name = "CRUN", col = ColQ)



</code></pre>

<hr>
<h2 id='PlotMapPoints'>Plot function for mapped point information</h2><span id='topic+PlotMapPoints'></span>

<h3>Description</h3>

<p>Plot mapped point information, e.g. model performances at observation sites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotMapPoints(
  x,
  sites = NULL,
  sites.subid.column = 1,
  sites.groups = NULL,
  bg = NULL,
  bg.label.column = 1,
  var.name = "",
  map.type = "default",
  shiny.data = FALSE,
  plot.legend = TRUE,
  legend.pos = "right",
  legend.title = NULL,
  legend.signif = 2,
  col = NULL,
  col.breaks = NULL,
  col.labels = NULL,
  col.rev = FALSE,
  plot.scale = TRUE,
  scale.pos = "br",
  plot.arrow = TRUE,
  arrow.pos = "tr",
  radius = 5,
  weight = 0.15,
  opacity = 0.75,
  fillOpacity = 0.5,
  na.color = "#808080",
  jitter = 0.01,
  bg.weight = 0.15,
  bg.opacity = 0.75,
  bg.fillColor = "#e5e5e5",
  bg.fillOpacity = 0.75,
  plot.label = FALSE,
  plot.label.size = 2.5,
  plot.label.geometry = c("centroid", "surface"),
  noHide = FALSE,
  textOnly = FALSE,
  font.size = 10,
  plot.bg.label = NULL,
  file = "",
  width = NA,
  height = NA,
  units = c("in", "cm", "mm", "px"),
  dpi = 300,
  vwidth = 1424,
  vheight = 1000,
  html.name = "",
  map.adj = 0,
  legend.outer = FALSE,
  legend.inset = c(0, 0),
  pt.cex = 1,
  par.cex = 1,
  par.mar = rep(0, 4) + 0.1,
  pch = 21,
  lwd = 0.8,
  add = FALSE,
  map = NULL,
  map.subid.column = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotMapPoints_+3A_x">x</code></td>
<td>
<p>Information to plot, typically model performances from imported HYPE 'subassX.txt' files. Data frame object
with two columns, first column containing SUBIDs and second column containing model results to plot. See details.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_sites">sites</code>, <code id="PlotMapPoints_+3A_map">map</code></td>
<td>
<p>A <code>SpatialPointsDataFrame</code> or <code>sf</code> object. Typically an imported outlet point vector point file. Import of vector points
requires additional packages, e.g. <code><a href="sf.html#topic+st_read">sf::st_read()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_sites.subid.column">sites.subid.column</code>, <code id="PlotMapPoints_+3A_map.subid.column">map.subid.column</code></td>
<td>
<p>Integer, column index in the <code>sites</code> 'data' <code><a href="methods.html#topic+slot">slot</a></code> holding SUBIDs (sub-catchment IDs).</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_sites.groups">sites.groups</code></td>
<td>
<p>Named list providing groups of SUBIDs to allow toggling of point groups in Leaflet maps. Default <code>NULL</code> will produce maps without
point groups. List names represent the names of the groups to plot, and list values represent the SUBIDs within the group.
Example: <code>sites.groups = list("GROUP 1" = c(1, 2, 3), "GROUP 2" = c(4, 5, 6))</code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_bg">bg</code></td>
<td>
<p>A <code>SpatialPolygonsDataFrame</code> or <code>sf</code> object to plot in the background. Typically an imported sub-basin vector polygon file.
For default maps with several background layers, use <code>add = TRUE</code> and plot background layer(s) first.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_bg.label.column">bg.label.column</code></td>
<td>
<p>Integer, column index in the <code>bg</code> 'data' <code><a href="methods.html#topic+slot">slot</a></code> holding labels (e.g. SUBIDs) to use for plotting.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_var.name">var.name</code></td>
<td>
<p>Character string. HYPE variable name to be plotted. Mandatory for automatic color ramp selection of pre-defined
HYPE variables (<code>col = "auto"</code>). Not case-sensitive.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_map.type">map.type</code></td>
<td>
<p>Map type keyword string. Choose either <code>"default"</code> for the default static plots or <code>"leaflet"</code> for interactive Leaflet maps. Use <code>"legacy"</code> for deprecated static plots.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_shiny.data">shiny.data</code></td>
<td>
<p>Logical, if <code>map.type</code> is <code>"leaflet"</code>, then should the output be a list containing the basemap, formatted data, legend colors, and legend labels? Typically set to <code>FALSE</code> unless using <code>PlotMapOutput</code> to create Shiny apps or custom Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_plot.legend">plot.legend</code></td>
<td>
<p>Logical, plot a legend along with the map.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_legend.pos">legend.pos</code></td>
<td>
<p>Keyword string for legend position. For static plots, one of: <code>"none"</code>, <code>"left"</code>, <code>"right"</code>,
<code>"bottom"</code>, <code>"top"</code>, or a two-element numeric vector. For interactive Leaflet maps, one of: <code>"topleft"</code>, <code>"topright"</code>, <code>"bottomright"</code>, <code>"bottomleft"</code>. For legacy static plots, one of: <code>"left"</code>, <code>"topleft"</code>, <code>"topright"</code>,
<code>"right"</code>, <code>"bottomright"</code>, <code>"bottomleft"</code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_legend.title">legend.title</code></td>
<td>
<p>Character string or mathematical expression. An optional title for the legend. If none is provided here, the name of the second column in <code>x</code>
is used as legend title string.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_legend.signif">legend.signif</code></td>
<td>
<p>Integer, number of significant digits to display in legend labels.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_col">col</code></td>
<td>
<p>Colors to use on the map. One of the following: </p>

<ul>
<li> <p><code>NULL</code>, to use a default purple-red-yellow-blue color ramp, best used with <code>col.breaks = NULL</code>.
</p>
</li>
<li><p> A color ramp palette function, e.g. as returned from a call to <code><a href="grDevices.html#topic+colorRampPalette">colorRampPalette</a></code>
</p>
</li>
<li><p> A vector of colors. This can be a character vector of R's built-in color names or hexadecimal strings as returned by
<code><a href="grDevices.html#topic+rgb">rgb</a></code>, or an integer vector of current <code><a href="grDevices.html#topic+palette">palette</a></code> indices.
</p>
</li></ul>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_col.breaks">col.breaks</code></td>
<td>
<p>A numeric vector, specifying break points for discretization of model result values into classes. Class boundaries will be
interpreted as right-closed, i.e upper boundaries included in class. Lowest class boundary included in lowest class as well.
Meaningful results require the lowest and uppermost breaks to bracket all model result values, otherwise there will be
unclassified white spots on the map plot. If <code>NULL</code> (the default), <code>col.breaks</code> covers a range from 0 to 1
with 9 intervals, and an additional interval for negative values. This is suitable for e.g. NSE performances.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_col.labels">col.labels</code></td>
<td>
<p>A character vector, specifying custom labels to be used for each legend item. Works with <code>map.type</code> set to <code>default</code> or <code>leaflet</code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_col.rev">col.rev</code></td>
<td>
<p>Logical, If <code>TRUE</code>, then color palette will be reversed.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_plot.scale">plot.scale</code></td>
<td>
<p>Logical, plot a scale bar on map. NOTE: Scale bar may be inaccurate for geographic coordinate systems (Consider switching to projected coordinate system).</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_scale.pos">scale.pos</code></td>
<td>
<p>Keyword string for scalebar position for static maps. One of <code>bl</code>, <code>br</code>, <code>tr</code>, or <code>tl</code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_plot.arrow">plot.arrow</code></td>
<td>
<p>Logical, plot a North arrow in static maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_arrow.pos">arrow.pos</code></td>
<td>
<p>Keyword string for north arrow position for static maps. One of <code>bl</code>, <code>br</code>, <code>tr</code>, or <code>tl</code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_radius">radius</code></td>
<td>
<p>Numeric, radius of markers maps. See <code><a href="ggplot2.html#topic+geom_sf">geom_sf</a></code> for static maps and <code><a href="leaflet.html#topic+map-layers">leaflet::addCircleMarkers()</a></code> for Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_weight">weight</code></td>
<td>
<p>Numeric, weight of marker outlines in Leaflet maps. See <code><a href="leaflet.html#topic+map-layers">leaflet::addCircleMarkers()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_opacity">opacity</code></td>
<td>
<p>Numeric, opacity of marker outlines in Leaflet maps. See <code><a href="leaflet.html#topic+map-layers">leaflet::addCircleMarkers()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_fillopacity">fillOpacity</code></td>
<td>
<p>Numeric, opacity of markers in Leaflet maps. See <code><a href="leaflet.html#topic+map-layers">leaflet::addCircleMarkers()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_na.color">na.color</code></td>
<td>
<p>Character string of color to use to symbolize markers in maps which correspond to <code>NA</code> values.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_jitter">jitter</code></td>
<td>
<p>Numeric, amount to jitter points with duplicate geometries. See <code><a href="sf.html#topic+st_jitter">sf::st_jitter()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_bg.weight">bg.weight</code></td>
<td>
<p>Numeric, weight of <code>bg</code> subbasin outlines in Leaflet maps. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_bg.opacity">bg.opacity</code></td>
<td>
<p>Numeric, opacity of <code>bg</code> subbasin outlines in Leaflet maps. See <code><a href="ggplot2.html#topic+geom_sf">geom_sf</a></code> for static maps and <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code> for Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_bg.fillcolor">bg.fillColor</code></td>
<td>
<p>Character string of color to use to symbolize <code>bg</code> subbasin polygons in maps. See <code><a href="ggplot2.html#topic+geom_sf">geom_sf</a></code> for static maps and <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code> for Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_bg.fillopacity">bg.fillOpacity</code></td>
<td>
<p>Numeric in range 0-1, opacity of <code>bg</code> subbasin polygons in maps. See <code><a href="ggplot2.html#topic+geom_sf">geom_sf</a></code> for static maps and <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code> for Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_plot.label">plot.label</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then labels will be displayed on default static maps and in Leaflet maps when the cursor hovers over markers.
See <code><a href="ggplot2.html#topic+geom_sf_text">geom_sf_text</a></code> for default maps and <code><a href="leaflet.html#topic+map-layers">leaflet::addCircleMarkers()</a></code> for Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_plot.label.size">plot.label.size</code></td>
<td>
<p>Numeric, size of text for labels on default static plots. See <code><a href="ggplot2.html#topic+geom_sf_text">geom_sf_text</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_plot.label.geometry">plot.label.geometry</code></td>
<td>
<p>Keyword string to select where plot labels should be displayed on the default static plots. Either <code>centroid</code> to use <code>sf::st_centroid</code> or <code>surface</code> to use <code>sf::st_point_on_surface</code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_nohide">noHide</code></td>
<td>
<p>Logical, set to <code>TRUE</code> to always display marker labels in Leaflet maps. See <code><a href="leaflet.html#topic+map-options">leaflet::labelOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_textonly">textOnly</code></td>
<td>
<p>Logical, set to <code>TRUE</code> to hide marker label background in Leaflet maps. See <code><a href="leaflet.html#topic+map-options">leaflet::labelOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_font.size">font.size</code></td>
<td>
<p>Numeric, font size (px) for marker labels in Leaflet maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_plot.bg.label">plot.bg.label</code></td>
<td>
<p>String, if <code>hover</code>, then labels will be displayed in Leaflet maps for <code>bg</code> when the cursor hovers over polygons. If <code>static</code>, then static
labels for <code>bg</code> will be displayed in Leaflet maps. If any string is specified, then background labels will be added to default static maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_file">file</code></td>
<td>
<p>Save map to an image file by specifying the path to the desired output file using this argument. File extension must be specified. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code> for static maps and
<code><a href="mapview.html#topic+mapshot">mapview::mapshot()</a></code> for Leaflet maps. You may need to run <code>webshot::install_phantomjs()</code> the first time you save a Leaflet map to an image file. See <code><a href="webshot.html#topic+install_phantomjs">webshot::install_phantomjs()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_width">width</code></td>
<td>
<p>Numeric, width of output plot for static maps in units of <code>units</code>. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_height">height</code></td>
<td>
<p>Numeric, height of output plot for static maps in units of <code>units</code>. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_units">units</code></td>
<td>
<p>Keyword string for units to save static map. One of <code>"in"</code>, <code>"cm"</code>, <code>"mm"</code>, <code>"px"</code>. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_dpi">dpi</code></td>
<td>
<p>Integer, resolution to save static map. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_vwidth">vwidth</code></td>
<td>
<p>Numeric, width of the exported Leaflet map image in pixels. See <code><a href="webshot.html#topic+webshot">webshot::webshot()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_vheight">vheight</code></td>
<td>
<p>Numeric, height of the exported Leaflet map image in pixels. See <code><a href="webshot.html#topic+webshot">webshot::webshot()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_html.name">html.name</code></td>
<td>
<p>Save Leaflet map to an interactive HTML file by specifying the path to the desired output file using this argument. File extension must be specified.
See <code><a href="htmlwidgets.html#topic+saveWidget">htmlwidgets::saveWidget()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_map.adj">map.adj</code></td>
<td>
<p>Numeric, map adjustment in direction where it is smaller than the plot window. A value of <code>0</code> means left-justified
or bottom-justified, <code>0.5</code> (the default) means centered, and <code>1</code> means right-justified or top-justified. Only used for legacy static maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_legend.outer">legend.outer</code></td>
<td>
<p>Logical. If <code>TRUE</code>, outer break point values will be plotted in legend. Only used for legacy static maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_legend.inset">legend.inset</code></td>
<td>
<p>Numeric, inset distance(s) from the margins as a fraction of the plot region for legend, scale and north arrow.
See <code><a href="graphics.html#topic+legend">legend</a></code> and details below. Only used for legacy static maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_pt.cex">pt.cex</code></td>
<td>
<p>Numeric, plot point size expansion factor, works on top of <code>par.cex</code>.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_par.cex">par.cex</code></td>
<td>
<p>Numeric, character expansion factor. See description of <code>cex</code> in <code><a href="graphics.html#topic+par">par</a></code>. Only used for legacy maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_par.mar">par.mar</code></td>
<td>
<p>Plot margins as in <code><a href="graphics.html#topic+par">par</a></code> argument <code>mar</code>. Defaults to a nearly margin-less plot.
In standard use cases of this function, plot margins do not need to be changed. Only used for legacy maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_pch">pch</code>, <code id="PlotMapPoints_+3A_lwd">lwd</code></td>
<td>
<p>Integer, plotting symbol and line width. See <code><a href="graphics.html#topic+points">points</a></code>. Only used for legacy maps.</p>
</td></tr>
<tr><td><code id="PlotMapPoints_+3A_add">add</code></td>
<td>
<p>Logical, default <code>FALSE</code>. If <code>TRUE</code>, add to existing plot. In that case <code>map.adj</code> has no effect. Only used for legacy maps.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PlotMapPoints</code> can be used to print point information on a mapped surface. The primary target are model performance
measures as written to
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:subassx.txt">HYPE 'subassX.txt' files</a>, but
color scale and break point arguments are flexible enough to also be used with e.g. HYPE output variables or other data.
</p>
<p><code>PlotMapOutput</code> can return static plots or interactive Leaflet maps depending on value provided for the argument <code>map.type</code>.
For backwards compatibility, legacy static plots can still be generated by setting <code>map.type</code> to <code>legacy</code>. For legacy plots, <code>legend.pos</code> and
<code>map.adj</code> should be chosen so that legend and map do not overlap, and the legend position can be fine-tuned using
argument <code>legend.inset</code>. This is particularly useful for legend titles with more than one line. For details on inset
specification for the default maps, see <code>inset</code> in <code><a href="graphics.html#topic+legend">legend</a></code>.
</p>


<h3>Value</h3>

<p>For default static maps, <code>PlotMapPoints</code> returns an object of class <code>ggplot</code>. This plot can also be assigned to a variable in the environment.
For interactive Leaflet maps, <code>PlotMapOutput</code> returns an object of class <code>leaflet</code>. For legacy static plots, <code>PlotMapOutput</code> returns a plot to the
currently active plot device and invisibly an object of class <code>SpatialPointsDataFrame</code> as provided in argument <code>sites</code>, with plotted values and color codes added as columns
in the data slot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadSubass">ReadSubass</a></code> for HYPE result import; <code><a href="#topic+ReadMapOutput">ReadMapOutput</a></code> for a similar plot function
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Import plot data and subbasin points
require(sf)
te1 &lt;- ReadSubass(filename = system.file("demo_model",
"results", "subass1.txt", package = "HYPEtools"))
te2 &lt;- st_read(dsn = system.file("demo_model",
"gis", "Nytorp_station.gpkg", package = "HYPEtools"))
te2$SUBID &lt;- 3587 # add station SUBID to point
te3 &lt;- st_read(dsn = system.file("demo_model",
"gis", "Nytorp_map.gpkg", package = "HYPEtools"))
# plot NSE performance for discharge
PlotMapPoints(x = te1[, 1:2], sites = te2, sites.subid.column = 4, bg = te3)


</code></pre>

<hr>
<h2 id='PlotPerformanceByAttribute'>Plot model performance by SUBID attributes</h2><span id='topic+PlotPerformanceByAttribute'></span><span id='topic+PlotJohan'></span>

<h3>Description</h3>

<p>Create scatterplots of model performance by SUBID attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotPerformanceByAttribute(
  subass,
  subass.column = 2,
  groups = NULL,
  attributes,
  join.type = c("join", "cbind"),
  group.join.type = c("join", "cbind"),
  groups.color.pal = NULL,
  drop = TRUE,
  alpha = 0.4,
  trendline = TRUE,
  trendline.method = "lm",
  trendline.formula = NULL,
  trendline.alpha = 0.5,
  trendline.darken = 15,
  density.plot = FALSE,
  density.plot.type = c("density", "boxplot"),
  scale.x.log = FALSE,
  scale.y.log = FALSE,
  xsigma = 1,
  ysigma = 1,
  xlimits = c(NA, NA),
  ylimits = c(NA, NA),
  xbreaks = waiver(),
  ybreaks = waiver(),
  xlabels = waiver(),
  ylabels = waiver(),
  xlab = NULL,
  ylab = NULL,
  ncol = NULL,
  nrow = NULL,
  align = "hv",
  common.legend = TRUE,
  legend.position = "bottom",
  group.legend.title = "Group",
  common.y.axis = FALSE,
  summary.table = FALSE,
  table.margin = 0.4,
  filename = NULL,
  width = NA,
  height = NA,
  units = c("in", "cm", "mm", "px"),
  dpi = 300
)

PlotJohan(
  subass,
  subass.column = 2,
  groups = NULL,
  attributes,
  join.type = c("join", "cbind"),
  group.join.type = c("join", "cbind"),
  groups.color.pal = NULL,
  drop = TRUE,
  alpha = 0.4,
  trendline = TRUE,
  trendline.method = "lm",
  trendline.formula = NULL,
  trendline.alpha = 0.5,
  trendline.darken = 15,
  density.plot = FALSE,
  density.plot.type = c("density", "boxplot"),
  scale.x.log = FALSE,
  scale.y.log = FALSE,
  xsigma = 1,
  ysigma = 1,
  xlimits = c(NA, NA),
  ylimits = c(NA, NA),
  xbreaks = waiver(),
  ybreaks = waiver(),
  xlabels = waiver(),
  ylabels = waiver(),
  xlab = NULL,
  ylab = NULL,
  ncol = NULL,
  nrow = NULL,
  align = "hv",
  common.legend = TRUE,
  legend.position = "bottom",
  group.legend.title = "Group",
  common.y.axis = FALSE,
  summary.table = FALSE,
  table.margin = 0.4,
  filename = NULL,
  width = NA,
  height = NA,
  units = c("in", "cm", "mm", "px"),
  dpi = 300
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotPerformanceByAttribute_+3A_subass">subass</code></td>
<td>
<p>Information to plot, typically model performances from imported HYPE 'subassX.txt' files. Data frame object
with first column containing SUBIDs and additional columns containing model results to plot. See details.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_subass.column">subass.column</code></td>
<td>
<p>Column index of information in <code>subass</code> to plot on the y-axis of the output plots.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_groups">groups</code></td>
<td>
<p>Optional data frame object to specify groups of SUBIDs to plot separately. First column should contain SUBIDs and second column should contain group IDs.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_attributes">attributes</code></td>
<td>
<p>Data frame object containing the subbasin attribute information to plot on the x-axis of the output plots. Typically a data frame created by <code><a href="#topic+SubidAttributeSummary">SubidAttributeSummary</a></code></p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_join.type">join.type</code></td>
<td>
<p>Specify how to join <code>subass</code> to <code>attributes</code>. Default &quot;join&quot; will perform a <code><a href="dplyr.html#topic+left_join">left_join</a></code> in which the order of the SUBIDs does not need to match. Additional option &quot;cbind&quot;
will perform a <code><a href="base.html#topic+cbind">cbind</a></code> in which the order of the SUBIDs needs to match; this can be helpful if you want to create plots where <code>subass</code> performance data is calculated according to a
grouping variable (e.g. month).</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_group.join.type">group.join.type</code></td>
<td>
<p>Specify how to join <code>subass</code> to <code>groups</code>. Default &quot;join&quot; will perform a <code><a href="dplyr.html#topic+left_join">left_join</a></code> in which the order of the SUBIDs does not need to match. Additional option &quot;cbind&quot;
will perform a <code><a href="base.html#topic+cbind">cbind</a></code> in which the order of the SUBIDs needs to match; this can be helpful if you want to create plots where <code>subass</code> performance data is calculated according to a
grouping variable (e.g. month).</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_groups.color.pal">groups.color.pal</code></td>
<td>
<p>Vector containing colors to use when plotting groups. Only used if groups is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_drop">drop</code></td>
<td>
<p>Logical, should unused factor levels be omitted from the legend. See <code><a href="ggplot2.html#topic+scale_color_manual">scale_color_manual</a></code> and <code>link{scale_fill_manual}</code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_alpha">alpha</code></td>
<td>
<p>Numeric value to set transparency of dots in output plots. Should be in the range 0-1.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_trendline">trendline</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then trendlines will be added to the output plots. Set to <code>FALSE</code> to hide trendlines. See <code><a href="ggplot2.html#topic+geom_smooth">geom_smooth</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_trendline.method">trendline.method</code></td>
<td>
<p>Specify method used to create trendlines. See <code><a href="ggplot2.html#topic+geom_smooth">geom_smooth</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_trendline.formula">trendline.formula</code></td>
<td>
<p>Specify formula used to create trendlines. See <code><a href="ggplot2.html#topic+geom_smooth">geom_smooth</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_trendline.alpha">trendline.alpha</code></td>
<td>
<p>Numeric value to set transparency of trendlines in output plots. Should be in the range 0-1.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_trendline.darken">trendline.darken</code></td>
<td>
<p>Numeric value to make the trendlines darker color shades of their corresponding scatterplot points. Should be in the range 1-100.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_density.plot">density.plot</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then density plots will be added to the output plots. Set to <code>FALSE</code> to hide density plots.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_density.plot.type">density.plot.type</code></td>
<td>
<p>String, type of plot geometry to use for density plots: <code>"density"</code> for <code><a href="ggplot2.html#topic+geom_density">geom_density</a></code> or <code>"boxplot"</code> for <code><a href="ggplot2.html#topic+geom_boxplot">geom_boxplot</a></code>. Outliers are hidden from the boxplots.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_scale.x.log">scale.x.log</code></td>
<td>
<p>Vector describing if output plots should use a log scale on the x-axis. A pseudo-log scale will be used if any zero or negative values are present. If length of vector == 1, then the value will be used for all output plots. Vector values should be either <code>TRUE</code> or <code>FALSE</code>. See <code><a href="ggplot2.html#topic+scale_x_log10">scale_x_log10</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_scale.y.log">scale.y.log</code></td>
<td>
<p>Vector describing if output plots should use a log scale on the y-axis. A pseudo-log scale will be used if any zero or negative values are present. If length of vector == 1, then the value will be used for all output plots. Vector values should be either <code>TRUE</code> or <code>FALSE</code>. See <code><a href="ggplot2.html#topic+scale_y_log10">scale_y_log10</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_xsigma">xsigma</code></td>
<td>
<p>Numeric, scaling factor for the linear part of psuedo-long transformation of x axis. Used if <code>scale.x.log</code> is <code>TRUE</code> and zero or negative values are present. See <code><a href="scales.html#topic+pseudo_log_trans">pseudo_log_trans</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_ysigma">ysigma</code></td>
<td>
<p>Numeric, scaling factor for the linear part of psuedo-long transformation of y axis. Used if <code>scale.y.log</code> is <code>TRUE</code> and zero or negative values are present. See <code><a href="scales.html#topic+pseudo_log_trans">pseudo_log_trans</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_xlimits">xlimits</code></td>
<td>
<p>Vector containing minimum and maximum values for the x-axis of the output plots. See <code><a href="ggplot2.html#topic+scale_x_continuous">scale_x_continuous</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_ylimits">ylimits</code></td>
<td>
<p>Vector containing minimum and maximum values for the y-axis of the output plots. See <code><a href="ggplot2.html#topic+scale_y_continuous">scale_y_continuous</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_xbreaks">xbreaks</code></td>
<td>
<p>Vector containing the break values used for the x-axis of the output plots. See <code><a href="ggplot2.html#topic+scale_x_continuous">scale_x_continuous</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_ybreaks">ybreaks</code></td>
<td>
<p>Vector containing the break values used for the y-axis of the output plots. See <code><a href="ggplot2.html#topic+scale_y_continuous">scale_y_continuous</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_xlabels">xlabels</code></td>
<td>
<p>Vector containing the labels for each break value used for the x-axis of the output plots. See <code><a href="ggplot2.html#topic+scale_x_continuous">scale_x_continuous</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_ylabels">ylabels</code></td>
<td>
<p>Vector containing the labels for each break value used for the y-axis of the output plots. See <code><a href="ggplot2.html#topic+scale_y_continuous">scale_y_continuous</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_xlab">xlab</code></td>
<td>
<p>String containing the text to use for the x-axis title of the output plots. See <code><a href="ggplot2.html#topic+xlab">xlab</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_ylab">ylab</code></td>
<td>
<p>String containing the text to use for the y-axis title of the output plots. See <code><a href="ggplot2.html#topic+ylab">ylab</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_ncol">ncol</code></td>
<td>
<p>Integer, number of columns to use in the output arranged plot. See <code><a href="ggpubr.html#topic+ggarrange">ggarrange</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_nrow">nrow</code></td>
<td>
<p>Integer, number of rows to use in the output arranged plot. See <code><a href="ggpubr.html#topic+ggarrange">ggarrange</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_align">align</code></td>
<td>
<p>Specify how output plots should be arranged. See <code><a href="ggpubr.html#topic+ggarrange">ggarrange</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_common.legend">common.legend</code></td>
<td>
<p>Specify if arranged plot should use a common legend. See <code><a href="ggpubr.html#topic+ggarrange">ggarrange</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_legend.position">legend.position</code></td>
<td>
<p>Specify position of common legend for arranged plot. See <code><a href="ggpubr.html#topic+ggarrange">ggarrange</a></code>. Use <code>"none"</code> to hide legend.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_group.legend.title">group.legend.title</code></td>
<td>
<p>String, title for plot legend when generating plots with <code>groups</code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_common.y.axis">common.y.axis</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then only one y-axis label and marginal density plot will be provided. If <code>FALSE</code>, then separate y-axis labels and marginal density plots will be included for each subplot.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_summary.table">summary.table</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then a table providing summary statistics will be included at the bottom of the output plot.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_table.margin">table.margin</code></td>
<td>
<p>Numeric, controls spacing between plots and summary table.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_filename">filename</code></td>
<td>
<p>String, filename used to save plot. File extension must be specified. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_width">width</code></td>
<td>
<p>Numeric, specify width of output plot. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_height">height</code></td>
<td>
<p>Numeric, specify height of output plot. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_units">units</code></td>
<td>
<p>Specify units of <code>width</code> and <code>height</code>. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
<tr><td><code id="PlotPerformanceByAttribute_+3A_dpi">dpi</code></td>
<td>
<p>Specify resolution of output plot. See <code><a href="ggplot2.html#topic+ggsave">ggsave</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PlotPerformanceByAttribute</code> can be used to analyze model performance according to subbasin attributes. The function requires two primary inputs; Model performance
information is contained in the <code>subass</code> input, and subbasin attribute information is contained in the <code>attributes</code> input. The <code>subass.column</code> argument controls
which column of the <code>subass</code> data frame will be used as the y-coordinate of points. Plots will be generated for each column in the <code>attributes</code> data frame
(except for the column named &quot;SUBID&quot;) using the column values as the x-coordinate of the points.
</p>
<p>A subbasin attribute summary table can be generated using <code><a href="#topic+SubidAttributeSummary">SubidAttributeSummary</a></code>, and additional columns can be joined to the data frame to add additional output plots.
</p>


<h3>Value</h3>

<p><code>PlotPerformanceByAttribute</code> returns a plot to the currently active plot device.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadSubass">ReadSubass</a></code> for HYPE result import; <code><a href="#topic+SubidAttributeSummary">SubidAttributeSummary</a></code> for subbasin attribute summary
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
subass &lt;- ReadSubass(filename = system.file("demo_model", "results",
  "subass1.txt",
  package = "HYPEtools"
), check.names = TRUE)
gd &lt;- ReadGeoData(filename = system.file("demo_model",
  "GeoData.txt",
  package = "HYPEtools"
))
gc &lt;- ReadGeoClass(filename = system.file("demo_model",
  "GeoClass.txt",
  package = "HYPEtools"
))

attributes &lt;- SubidAttributeSummary(subids &lt;- subass$SUBID,
  gd = gd, gc = gc,
  mapoutputs = c(system.file("demo_model", "results", "mapCOUT.txt", package = "HYPEtools")),
  upstream.gd.cols = c("SLOPE_MEAN")
)

PlotPerformanceByAttribute(
  subass = subass,
  attributes = attributes[, c("SUBID", "landuse_1", "landuse_2", "landuse_3")],
  xlimits = c(0, 1)
)


</code></pre>

<hr>
<h2 id='PlotSimObsRegime'>Plot annual regimes of simulated and observed variables</h2><span id='topic+PlotSimObsRegime'></span>

<h3>Description</h3>

<p>A combined plot for annual regimes with box plot elements for observed variables and ribbon elements
for simulated variables. Particularly designed for comparisons of sparse observations with
high-density model results, e.g. for in-stream nutrients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotSimObsRegime(
  x,
  sim,
  obs,
  ts.in = NULL,
  ts.out = "month",
  start.mon = 1,
  add.legend = TRUE,
  pos.legend = "topright",
  inset = 0,
  l.legend = NULL,
  log = FALSE,
  ylim = NULL,
  xlab = NULL,
  ylab = NULL,
  mar = c(3, 3, 1, 1) + 0.1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotSimObsRegime_+3A_x">x</code></td>
<td>
<p>Data frame, with column-wise equally-spaced time series of HYPE variables. Date-times in
<code><a href="base.html#topic+POSIXct">POSIXct</a></code> format in first column. Typically an imported basin output file from HYPE using <code><a href="#topic+ReadBasinOutput">ReadBasinOutput</a></code>.
See details for HYPE output variables required for plotting.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_sim">sim</code>, <code id="PlotSimObsRegime_+3A_obs">obs</code></td>
<td>
<p>Character string keywords, observed and simulated HYPE variable IDs to plot. Not case-sensitive, but must exist in <code>x</code>.
Set to <code>NULL</code> to omit corresponding elements in plot.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_ts.in">ts.in</code></td>
<td>
<p>Character string, timestep of <code>x</code>, searches for an attribute <code>timestep</code> in <code>x</code> per default.
Otherwise one of <code>"month"</code>, <code>"week"</code>, <code>"day"</code>, or <code>"nhour"</code> (n = number of hours).</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_ts.out">ts.out</code></td>
<td>
<p>Character string, aggregation timestep for simulation results, defaults to <code>ts.in</code>. This timestep must be equal
to or longer than <code>ts.in</code>.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_start.mon">start.mon</code></td>
<td>
<p>Integer between 1 and 12, starting month of the hydrological year, used to order the output.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_add.legend">add.legend</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a legend will be added to the plot.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_pos.legend">pos.legend</code></td>
<td>
<p>Character string keyword for legend positioning. See Details in <code>link{legend}</code>.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_inset">inset</code></td>
<td>
<p>Integer, legend inset as fraction of plot region, one or two values for x and y. See <code>link{legend}</code>.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_l.legend">l.legend</code></td>
<td>
<p>Character vector of length 2 containing variable labels for legend, first for <code>sim</code>, then for <code>obs</code>.
If non-NULL, variable labels are read from here instead of <code>sim</code> and <code>obs</code>.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_log">log</code></td>
<td>
<p>Logical, if <code>TRUE</code>, y-axis will be log-scaled.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_ylim">ylim</code></td>
<td>
<p>Numeric vector of length two, giving y-axis limits. Defaults to min-max range of all plotted data.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_xlab">xlab</code></td>
<td>
<p>Character string or <code><a href="grDevices.html#topic+plotmath">plotmath</a></code> expression string, x-axis label. Defaults to a string giving the
time period on which the regime is based.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_ylab">ylab</code></td>
<td>
<p>Character or <code><a href="grDevices.html#topic+plotmath">plotmath</a></code> expression string. Y-axis label. Defaults to a HYPE variable unit string taken from
<code>x</code> <code><a href="base.html#topic+attributes">attributes</a></code> <code>'hypeunit'</code>.</p>
</td></tr>
<tr><td><code id="PlotSimObsRegime_+3A_mar">mar</code></td>
<td>
<p>Numeric vector of length 4, margin specification passed to <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PlotSimObsRegime</code> combines ribbons and box plot elements. Box plot elements are composed as defaults from <code><a href="graphics.html#topic+boxplot">boxplot</a></code>,
i.e. boxes with 25\
extreme values as points. Observation counts per month over the observation period are printed above the x-axis.
</p>
<p>Aggregation time length of the simulated variable can be chosen in argument <code>ts.out</code>, resulting in more or less smoothed ribbons.
For the observed variable, the aggregation is fixed to months, in order to aggregate enough values for each box plot element.
</p>


<h3>Value</h3>

<p><code>PlotSimObsRegime</code> returns a plot to the currently active plot device, and invisibly a <code><a href="base.html#topic+list">list</a></code> object containing three
elements with the plotted data and variable IDs.
Element <code>obs</code> contains a list as returned by <code><a href="#topic+AnnualRegime">AnnualRegime</a></code>. Element <code>obs</code> contains a list with two elements, a
vector <code>refdate</code> with x positions of box plots elements, and a list <code>reg.obs</code> with observations for the monthly box plot elements.
Element <code>variable</code> contains a named vector with HYPE variable IDs for observations and simulations. <code>sim</code> and <code>obs</code> returned
empty if corresponding function argument was <code>NULL</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+PlotAnnualRegime">PlotAnnualRegime</a></code> for a more generic annual regime plot, <code><a href="#topic+AnnualRegime">AnnualRegime</a></code> to compute annual regimes only.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot observed and simulated discharge
te &lt;- ReadBasinOutput(filename = system.file("demo_model",
"results", "0003587.txt", package = "HYPEtools"))
PlotSimObsRegime(x = te, sim = "cout", obs = "rout", start.mon = 10)

</code></pre>

<hr>
<h2 id='PlotSubbasinRouting'>Plot HYPE model subbasin routing.</h2><span id='topic+PlotSubbasinRouting'></span>

<h3>Description</h3>

<p>Plot routing of subbasins for a HYPE model on an interactive map.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotSubbasinRouting(
  map,
  map.subid.column = 1,
  gd = NULL,
  bd = NULL,
  plot.scale = TRUE,
  plot.searchbar = FALSE,
  weight = 0.5,
  opacity = 1,
  fillColor = "#4d4d4d",
  fillOpacity = 0.25,
  line.weight = 5,
  line.opacity = 1,
  seed = NULL,
  darken = 0,
  font.size = 10,
  file = "",
  vwidth = 1424,
  vheight = 1000,
  html.name = ""
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotSubbasinRouting_+3A_map">map</code></td>
<td>
<p>Path to file containing subbasin polygon GIS data (e.g. shapefile or geopackage) or a <code>SpatialPolygonsDataFrame</code>
or <code>sf</code> object. For large maps, a small/simplified polygon file should be used as larger files can take an excessive amount of time to render.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_map.subid.column">map.subid.column</code></td>
<td>
<p>Integer, column index in the <code>map</code> 'data' <code><a href="methods.html#topic+slot">slot</a></code> holding SUBIDs (sub-catchment IDs).
Only required if providing GeoData information with <code>gd</code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_gd">gd</code></td>
<td>
<p>Path to model GeoData.txt or a GeoData object from <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>. Only required if <code>map</code> does not contain SUBID and/or MAINDOWN fields.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_bd">bd</code></td>
<td>
<p>Path to model BranchData.txt or a BranchData object from <code><a href="#topic+ReadBranchData">ReadBranchData</a></code>. Only required if model has a BranchData.txt file.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_plot.scale">plot.scale</code></td>
<td>
<p>Logical, include a scale bar on the map.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_plot.searchbar">plot.searchbar</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then a search bar will be included. See <code><a href="leaflet.extras.html#topic+search-features">leaflet.extras::addSearchFeatures()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_weight">weight</code></td>
<td>
<p>Numeric, weight of subbasin boundary lines. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_opacity">opacity</code></td>
<td>
<p>Numeric, opacity of subbasin boundary lines. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_fillcolor">fillColor</code></td>
<td>
<p>String, color of subbasin polygons. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_fillopacity">fillOpacity</code></td>
<td>
<p>Numeric, opacity of subbasin polygons. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolygons()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_line.weight">line.weight</code></td>
<td>
<p>Numeric, weight of routing lines. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolylines()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_line.opacity">line.opacity</code></td>
<td>
<p>Numeric, opacity of routing lines. See <code><a href="leaflet.html#topic+map-layers">leaflet::addPolylines()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_seed">seed</code></td>
<td>
<p>Integer, seed number to to produce repeatable color palette.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_darken">darken</code></td>
<td>
<p>Numeric specifying the amount of darkening applied to the random color palette. Negative values will lighten the palette. See <code><a href="#topic+distinctColorPalette">distinctColorPalette</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_font.size">font.size</code></td>
<td>
<p>Numeric, font size (px) for map subbasin labels.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_file">file</code></td>
<td>
<p>Save map to an image file by specifying the path to the desired output file using this argument. File extension must be specified.
See <code><a href="mapview.html#topic+mapshot">mapview::mapshot()</a></code>.
You may need to run <code><a href="webshot.html#topic+install_phantomjs">webshot::install_phantomjs()</a></code> the first time you save a map to an image file.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_vwidth">vwidth</code></td>
<td>
<p>Numeric, width of the exported map image in pixels. See <code><a href="webshot.html#topic+webshot">webshot::webshot()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_vheight">vheight</code></td>
<td>
<p>Numeric, height of the exported map image in pixels. See <code><a href="webshot.html#topic+webshot">webshot::webshot()</a></code>.</p>
</td></tr>
<tr><td><code id="PlotSubbasinRouting_+3A_html.name">html.name</code></td>
<td>
<p>Save map to an interactive HTML file by specifying the path to the desired output file using this argument. File extension must be specified.
See <code><a href="htmlwidgets.html#topic+saveWidget">htmlwidgets::saveWidget()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>PlotSubbasinRouting</code> generates an interactive Leaflet map with lines indicating the routing of flow between subbasins. GeoData information only needs
to be provided if the <code>map</code> GIS data does not include SUBID and/or MAINDOWN fields. BranchData information only needs to be provided if model has a
BranchData.txt file. Subbasin routing lines are randomly assigned a color using <code><a href="#topic+distinctColorPalette">distinctColorPalette</a></code>.
</p>


<h3>Value</h3>

<p>Returns an interactive Leaflet map.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
PlotSubbasinRouting(
  map = system.file("demo_model",
                    "gis", "Nytorp_map.gpkg",
                    package = "HYPEtools"
  ),
  gd = system.file("demo_model", "GeoData.txt", package = "HYPEtools"),
  map.subid.column = 25
)

## End(Not run)

</code></pre>

<hr>
<h2 id='r'>Pearson product-moment correlation coefficient r</h2><span id='topic+r'></span><span id='topic+r.HypeSingleVar'></span>

<h3>Description</h3>

<p>Pearson product-moment correlation coefficient calculation, a specific case of function <code><a href="stats.html#topic+cor">cor</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r(sim, obs, ...)

## S3 method for class 'HypeSingleVar'
r(sim, obs, progbar = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r_+3A_sim">sim</code></td>
<td>
<p><code><a href="#topic+HypeSingleVar">HypeSingleVar array</a></code> with simulated variable (one or several iterations).</p>
</td></tr>
<tr><td><code id="r_+3A_obs">obs</code></td>
<td>
<p><code><a href="#topic+HypeSingleVar">HypeSingleVar array</a></code> with observed variable, (one iteration). If several iterations
are present in the array, only the first will be used.</p>
</td></tr>
<tr><td><code id="r_+3A_...">...</code></td>
<td>
<p>Ignored.</p>
</td></tr>
<tr><td><code id="r_+3A_progbar">progbar</code></td>
<td>
<p>Logical, if <code>TRUE</code> progress bars will be printed for main computational steps.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function wraps a call to <code>cor(x = obs, y = sim, use = "na.or.complete", method = "pearson")</code>.
</p>
<p>Method <code>r.HypeSingleVar</code> calculates Pearson's r for imported HYPE outputs with single variables for several
catchments, i.e. time and map files, optionally multiple model runs combined, typically results from calibration runs.
</p>


<h3>Value</h3>

<p><code>r.HypeSingleVar</code> returns a 2-dimensional array of Pearson correlation coefficients for all SUBIDs and model
iterations provided in argument <code>sim</code>, with values in the same order
as the second and third dimension in <code>sim</code>, i.e. <code>[subid, iteration]</code>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+cor">cor</a></code>, on which the function is based. <code><a href="#topic+ReadWsOutput">ReadWsOutput</a></code> for importing HYPE calibration results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create dummy data, discharge observations with added white noise as model simulations
te1 &lt;- ReadObs(filename = system.file("demo_model", "Qobs.txt", package = "HYPEtools"))
te1 &lt;- HypeSingleVar(x = array(data = unlist(te1[, -1]) + runif(n = nrow(te1), 
                                                                min = -.5, max = .5), 
                               dim = c(nrow(te1), ncol(te1) - 1, 1), 
                               dimnames = list(rownames(te1), colnames(te1)[-1])), 
                     datetime = te1$DATE, subid = obsid(te1), hype.var = "cout")
te2 &lt;- ReadObs(filename = system.file("demo_model", "Qobs.txt", package = "HYPEtools"))
te2 &lt;- HypeSingleVar(x = array(data = unlist(te2[, -1]), 
                               dim = c(nrow(te2), ncol(te2) - 1, 1), 
                               dimnames = list(rownames(te2), colnames(te2)[-1])), 
                     datetime = te2$DATE, subid = obsid(te2), hype.var = "rout")
# Pearson correlation
r(sim = te1, obs = te2, progbar = FALSE)

</code></pre>

<hr>
<h2 id='ReadBasinOutput'>Read a Basin Output File</h2><span id='topic+ReadBasinOutput'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to import a basin output file as data frame or matrix into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadBasinOutput(
  filename,
  dt.format = "%Y-%m-%d",
  type = c("df", "dt", "hmv"),
  id = NULL,
  warn.nan = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadBasinOutput_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the basin output file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="ReadBasinOutput_+3A_dt.format">dt.format</code></td>
<td>
<p>Date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>. Incomplete format strings for monthly
and annual values allowed, e.g. '\
be imported as <code>character</code>, applicable e.g. for files containing just one row of summary values over the model period.</p>
</td></tr>
<tr><td><code id="ReadBasinOutput_+3A_type">type</code></td>
<td>
<p>Character, keyword for data type to return. <code>"df"</code> to return a standard data frame, <code>"dt"</code> to
return a <code><a href="data.table.html#topic+data.table">data.table</a></code> object, or <code>"hmv"</code> to return a <code><a href="#topic+HypeMultiVar">HypeMultiVar</a></code> array.</p>
</td></tr>
<tr><td><code id="ReadBasinOutput_+3A_id">id</code></td>
<td>
<p>Integer, SUBID or OUTREGID of the imported sub-basin or outregion results. If <code>NULL</code> (default), the function attempts to read this
from the imported file's name, which only works for standard HYPE basin output file names or any where the first 7 digits
give the SUBID or OUTREGID with leading zeros. See details.</p>
</td></tr>
<tr><td><code id="ReadBasinOutput_+3A_warn.nan">warn.nan</code></td>
<td>
<p>Logical, check if imported results contain any <code>NaN</code> values. If <code>TRUE</code> and <code>NaN</code>s are found,
a warning is thrown and affected SUBIDs saved in an attribute <code>subid.nan</code>. Adds noticeable overhead to import time for large files.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadBasinOutput</code> is a convenience wrapper function of <code><a href="data.table.html#topic+fread">fread</a></code> from package
<code><a href="data.table.html#topic+data.table">data.table</a></code>, with conversion of date-time strings to
POSIX time representations. Monthly and annual time steps are returned as first day of the time step period.
</p>
<p>HYPE basin output files can contain results for a single sub-basin or for a user-defined output region. <code>ReadBasinOutput</code> checks HYPE
variable names (column headers in imported file) for an &quot;RG&quot;-prefix. If it is found, the ID read from either file name or argument
<code>id</code> is saved to attribute <code>outregid</code>, otherwise to attribute <code>subid</code>.
</p>


<h3>Value</h3>

<p><code>ReadBasinOutput</code> returns a <code>data.frame</code>, <code><a href="data.table.html#topic+data.table">data.table</a></code>, or a <code><a href="#topic+HypeMultiVar">HypeMultiVar</a></code> array.
Data frames and data tables contain additional <code><a href="base.html#topic+attributes">attributes</a></code>: <code>hypeunit</code>, a vector of HYPE variable units,
<code>subid</code> and <code>outregid</code>, the HYPE SUBID/OUTREGID to which the time series belong (both attributes always created and assigned <code>NA</code>
if not applicable to data contents), <code>timestep</code> with a time step keyword attribute, and <code>comment</code> with contents of an optional
first-row comment (<code>NA</code> otherwise). An additional attribute <code>subid.nan</code> might be returned, see argument <code>warn.nan</code>.
</p>


<h3>Note</h3>

<p>For the conversion of date/time strings, time zone &quot;UTC&quot; is assumed. This is done to avoid potential daylight saving time
side effects when working with the imported data (and possibly converting to string representations during the process).
</p>
<p>HYPE results are printed to files using a user-specified accuracy. This accuracy is specified in 'info.txt' as a number of
decimals to print. If large numbers are printed, this can result in a total number of digits which is too large to print.
Results will then contain values of '****************'. <code>ReadBasinOutput</code> will convert those cases to 'NA' entries.
</p>
<p>Current versions of HYPE allow for defining significant numbers of digits instead of fixed ones, which should prevent this
issue from arising.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadBasinOutput(filename = system.file("demo_model",
"results", "0003587.txt", package = "HYPEtools"))

</code></pre>

<hr>
<h2 id='ReadClassData'>Read a 'ClassData.txt' File</h2><span id='topic+ReadClassData'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to import a ClassData file as data frame into R. ClassData files contain definitions
of SLC (<b>S</b>oil and <b>L</b>and use <b>C</b>rop) classes in five to 15 predefined columns, see
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:classdata.txt">ClassData.txt documentation</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadClassData(
  filename = "ClassData.txt",
  encoding = c("unknown", "UTF-8", "Latin-1"),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadClassData_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the ClassData file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="ReadClassData_+3A_encoding">encoding</code></td>
<td>
<p>Character string, encoding of non-ascii characters in imported text file. Particularly relevant when
importing files created under Windows (default encoding &quot;Latin-1&quot;) in Linux (default encoding &quot;UTF-8&quot;) and vice versa. See
also argument description in <code><a href="data.table.html#topic+fread">fread</a></code>.</p>
</td></tr>
<tr><td><code id="ReadClassData_+3A_verbose">verbose</code></td>
<td>
<p>Print information on number of data columns in imported file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadClassData</code> is a convenience wrapper function of <code><a href="data.table.html#topic+fread">fread</a></code>, with treatment of leading
comment rows. Column names are created on import, optional comment rows are imported as strings in <code>attribute</code> 'comment'.
Optional inline comments (additional non-numeric columns) are automatically identified and imported along with data columns.
</p>


<h3>Value</h3>

<p><code>ReadClassData</code> returns a data frame with added attribute 'comment'.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadClassData(filename = system.file("demo_model", "ClassData.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='ReadDescription'>Read a 'description.txt' file</h2><span id='topic+ReadDescription'></span>

<h3>Description</h3>

<p>Read a 'description.txt' file as <code>list</code> object into R. A 'description.txt' file contains land use, soil, and crop
class names of a HYPE set-up, as well as model set-up name and version.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadDescription(
  filename,
  gcl = NULL,
  encoding = c("unknown", "UTF-8", "latin1")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadDescription_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the 'description.txt' file to import.</p>
</td></tr>
<tr><td><code id="ReadDescription_+3A_gcl">gcl</code></td>
<td>
<p>dataframe, GeoClass.txt file imported with <code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code> to compare class IDs with.
A warning will be thrown if not all class IDs in <code>gcl</code> exist in the description file.</p>
</td></tr>
<tr><td><code id="ReadDescription_+3A_encoding">encoding</code></td>
<td>
<p>Character string, encoding of non-ascii characters in imported text file. Particularly relevant when
importing files created under Windows (default encoding &quot;Latin-1&quot;) in Linux (default encoding &quot;UTF-8&quot;) and vice versa. See
also argument description in <code><a href="base.html#topic+scan">scan</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadDescription</code> imports a 'description.txt' into R. This file is not used by HYPE, but is convenient for
e.g. plotting legend labels or examining imported GeoClass files. E.g., <code><a href="#topic+PlotBasinSummary">PlotBasinSummary</a></code> requires a list
as returned from <code>ReadDescription</code> for labeling.
</p>
<p>A 'description.txt' file consists of 22 lines, alternating names and semicolon-separated content. Lines
with names are not read by the import function, they just make it easier to compose and read the actual text file.
</p>
<p>File contents read by <code>ReadDescription</code>:
</p>

<ul>
<li><p> HYPE set-up name (line 2)
</p>
</li>
<li><p> HYPE set-up version (line 4)
</p>
</li>
<li><p> Land use class IDs (line 6)
</p>
</li>
<li><p> Land use class names (line 6)
</p>
</li>
<li><p> Land use class short names (line 8)
</p>
</li>
<li><p> Soil class IDs (line 10)
</p>
</li>
<li><p> Soil class names (line 10)
</p>
</li>
<li><p> Soil class short names (line 12)
</p>
</li>
<li><p> Crop class IDs (line 14)
</p>
</li>
<li><p> Crop class names (line 14)
</p>
</li>
<li><p> Crop class short names (line 16)
</p>
</li></ul>

<p>Note that Crop class IDs start from <code>0</code>, which means no crop, whereas land use and soil IDs start from <code>1</code> (or higher).
</p>
<p>Formatting example for description.txt files:
</p>
<p><code># Name</code> <br />
<code>MyHYPE</code> <br />
<code># Version</code> <br />
<code>0.1</code> <br />
<code># Land use class IDs</code> <br />
<code>1;2</code> <br />
<code># Land use class names</code> <br />
<code>Agriculture;Coniferous forest</code> <br />
<code># Short land use class names</code> <br />
<code>Agric.;Conif. f.</code> <br />
<code># Soil class IDs</code> <br />
<code>1;2</code> <br />
<code># Soil class names</code> <br />
<code>Coarse soils;Medium to fine soils</code> <br />
<code># Short soil class names</code> <br />
<code>Coarse;Medium</code> <br />
<code># Crop class IDs</code> <br />
<code>0;1;2</code> <br />
<code># Crop class names</code> <br />
<code>None;Row crops;Autumn-sown cereal</code> <br />
<code># Short crop class names</code> <br />
<code>None;Row;Aut.-sown</code> <br />
</p>


<h3>Value</h3>

<p><code>ReadDescription</code> returns a named list with 11 named character elements, corresponding to the
imported lines:
</p>
<p><code>Name</code>, <code>Version</code>, <code>lu.id</code>, <code>Landuse</code>, <code>lu</code> (short names), <code>so.id</code>,
<code>Soil</code>, <code>so</code> (short names), <code>cr.id</code>, <code>Crop</code>, <code>cr</code> (short names)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadDescription(filename = system.file("demo_model",
"description.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='ReadGeoClass'>Read a 'GeoClass.txt' File</h2><span id='topic+ReadGeoClass'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to import a GeoClass file as data frame into R. GeoClass files contain definitions
of SLC (<b>S</b>oil and <b>L</b>and use <b>C</b>rop) classes in twelve to 14 predefined columns, see
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:geoclass.txt">GeoClass.txt documentation</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadGeoClass(
  filename = "GeoClass.txt",
  encoding = c("unknown", "UTF-8", "Latin-1"),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadGeoClass_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the GeoClass file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="ReadGeoClass_+3A_encoding">encoding</code></td>
<td>
<p>Character string, encoding of non-ascii characters in imported text file. Particularly relevant when
importing files created under Windows (default encoding &quot;Latin-1&quot;) in Linux (default encoding &quot;UTF-8&quot;) and vice versa. See
also argument description in <code><a href="data.table.html#topic+fread">fread</a></code>.</p>
</td></tr>
<tr><td><code id="ReadGeoClass_+3A_verbose">verbose</code></td>
<td>
<p>Print information on number of data columns in imported file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadGeoClass</code> is a convenience wrapper function of <code><a href="data.table.html#topic+fread">fread</a></code>, with treatment of leading
comment rows. Column names are created on import, optional comment rows are imported as strings in <code>attribute</code> 'comment'.
Optional inline comments (additional non-numeric columns) are automatically identified and imported along with data columns.
</p>


<h3>Value</h3>

<p><code>ReadGeoClass</code> returns a data frame with added attribute 'comment'.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadClassData">ReadClassData</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoClass(filename = system.file("demo_model", "GeoClass.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='ReadGeoData'>Read a 'GeoData.txt' file</h2><span id='topic+ReadGeoData'></span>

<h3>Description</h3>

<p>Import a GeoData file into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadGeoData(
  filename = "GeoData.txt",
  sep = "\t",
  encoding = c("unknown", "UTF-8", "Latin-1"),
  remove.na.cols = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadGeoData_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the GeoData file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="ReadGeoData_+3A_sep">sep</code></td>
<td>
<p>character string. Field separator character as described in <code><a href="utils.html#topic+read.table">read.table</a></code>.</p>
</td></tr>
<tr><td><code id="ReadGeoData_+3A_encoding">encoding</code></td>
<td>
<p>Character string, encoding of non-ascii characters in imported text file. Particularly relevant when
importing files created under Windows (default encoding &quot;Latin-1&quot;) in Linux (default encoding &quot;UTF-8&quot;) and vice versa. See
also argument description in <code><a href="data.table.html#topic+fread">fread</a></code>.</p>
</td></tr>
<tr><td><code id="ReadGeoData_+3A_remove.na.cols">remove.na.cols</code></td>
<td>
<p>Logical, remove columns which have all NA values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadGeoData</code> uses <code><a href="data.table.html#topic+fread">fread</a></code> from the <code><a href="data.table.html#topic+data.table">data.table</a></code> package
with type <code>numeric</code> type for columns <code>AREA</code> and <code>RIVLEN</code> (if they exist), and
upper-case column names.
</p>


<h3>Value</h3>

<p>If the imported file is a HYPE-conform GeoData file, <code>ReadGeoData</code> returns an object of S3 class <code><a href="#topic+HypeGeoData">HypeGeoData</a></code>
(see the class description there), providing its own <code>summary</code> method. If mandatory GeoData columns are missing,
a standard dataframe is returned along with informative warning messages.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
summary(te)

</code></pre>

<hr>
<h2 id='ReadInfo'>Read an 'info.txt' file</h2><span id='topic+ReadInfo'></span>

<h3>Description</h3>

<p>Import a HYPE model settings information file as list into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadInfo(
  filename = "info.txt",
  encoding = c("unknown", "UTF-8", "latin1"),
  mode = c("simple", "exact"),
  comment.duplicates = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadInfo_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the info.txt file to import.</p>
</td></tr>
<tr><td><code id="ReadInfo_+3A_encoding">encoding</code></td>
<td>
<p>Character string, encoding of non-ascii characters in imported text file. Particularly relevant when
importing files created under Windows (default encoding &quot;Latin-1&quot;) in Linux (default encoding &quot;UTF-8&quot;) and vice versa. See
also argument description in <code><a href="base.html#topic+scan">scan</a></code>.</p>
</td></tr>
<tr><td><code id="ReadInfo_+3A_mode">mode</code></td>
<td>
<p>Use <code>simple</code> to read info.txt file as a nested list to that provides easy access to key information.
Alternatively, use <code>exact</code> to read info.txt file as a list matching the exact info.txt file structure (including all comment lines).</p>
</td></tr>
<tr><td><code id="ReadInfo_+3A_comment.duplicates">comment.duplicates</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then duplicate codes will be commented out when reading the input file. If <code>FALSE</code>,
then the input file will not not be checked for duplicate codes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using <code>ReadInfo</code> with the <code>simple</code> mode discards all comments of the imported file (comment rows and in-line comments). The function's purpose is to quickly
provide access to settings and details of a model run, not to mirror the exact info.txt file structure into an R data object. If you would like to mirror the exact file
structure, then use the <code>exact</code> mode.
</p>


<h3>Value</h3>

<p><code>ReadInfo</code> returns a named list. List names are settings codes
(see <a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt">info.txt documentation</a>). Settings with two
codes are placed in nested lists, e.g. <code>myinfo$basinoutput$variable</code>. Multi-line subbasin definitions for basin outputs and class
outputs are merged to single vectors on import.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WriteInfo">WriteInfo</a></code>
<code><a href="#topic+AddInfoLine">AddInfoLine</a></code>
<code><a href="#topic+RemoveInfoLine">RemoveInfoLine</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadInfo(filename = system.file("demo_model",
"info.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='ReadMapOutput'>Read a Map Output File</h2><span id='topic+ReadMapOutput'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to import a
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:mapxxxx.txt">map output file</a>
('map&lt;<em>HYPE_output_variable</em>&gt;.txt') into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadMapOutput(
  filename,
  dt.format = NULL,
  hype.var = NULL,
  type = c("df", "dt", "hsv"),
  warn.nan = FALSE,
  col.prefix = "X"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadMapOutput_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the map output file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="ReadMapOutput_+3A_dt.format">dt.format</code></td>
<td>
<p>Date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>, for conversion of date-time information in column
headers to POSIX dates, which are returned as attribute. Incomplete format strings for monthly and annual values allowed, e.g.
<code>"\%Y"</code>. <em>Defaults to <code>NULL</code>, which prevents date-time conversion</em>, applicable e.g. for files containing just one column of
summary values over the model period.</p>
</td></tr>
<tr><td><code id="ReadMapOutput_+3A_hype.var">hype.var</code></td>
<td>
<p>Character string, a four-letter keyword to specify HYPE variable ID of file contents. See
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables">list of HYPE variables</a>.
If <code>NULL</code> (default), the variable ID is extracted from the provided file name, which only works for standard HYPE
map output file names.</p>
</td></tr>
<tr><td><code id="ReadMapOutput_+3A_type">type</code></td>
<td>
<p>Character, keyword for data type to return. <code>"df"</code> to return a standard data frame, <code>"dt"</code> to
return a <code><a href="data.table.html#topic+data.table">data.table</a></code> object, or <code>"hsv"</code> to return a <code><a href="#topic+HypeSingleVar">HypeSingleVar</a></code> array.</p>
</td></tr>
<tr><td><code id="ReadMapOutput_+3A_warn.nan">warn.nan</code></td>
<td>
<p>Logical, check if imported results contain any <code>NaN</code> values. If <code>TRUE</code> and <code>NaN</code>s are found,
a warning is thrown and affected SUBIDs saved in an attribute <code>subid.nan</code>. Adds noticeable overhead to import time for large files.</p>
</td></tr>
<tr><td><code id="ReadMapOutput_+3A_col.prefix">col.prefix</code></td>
<td>
<p>String, prefix added to mapoutput column names. Default is <code>X</code>. Set to <code>NULL</code> to ignore.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadMapOutput</code> is a convenience wrapper function of <code><a href="data.table.html#topic+fread">fread</a></code> from package
<code><a href="data.table.html#topic+data.table">data.table</a></code>,
with conversion of date-time strings to POSIX time representations. Monthly and annual time steps are returned as first day
of the time step period.
</p>


<h3>Value</h3>

<p><code>ReadMapOutput</code> returns a <code>data.frame</code>, <code><a href="data.table.html#topic+data.table">data.table</a></code>, or a <code><a href="#topic+HypeSingleVar">HypeSingleVar</a></code> array.
Data frames and data tables contain additional <code><a href="base.html#topic+attributes">attributes</a></code>: <code>variable</code>, giving the HYPE variable ID,
<code>date</code>, a vector of date-times (corresponding to columns from column 2), <code>timestep</code> with a time step attribute,
and <code>comment</code> with the first line of the imported file as text string. An additional attribute <code>subid.nan</code> might be
returned, see argument <code>warn.nan</code>.
</p>


<h3>Note</h3>

<p>HYPE results are printed to files using a user-specified accuracy. This accuracy is specified in 'info.txt' as a number of
decimals to print. If large numbers are printed, this can result in a total number of digits which is too large to print.
Results will then contain values of '****************'. <code>ReadMapOutput</code> will convert those cases to 'NA' entries.
</p>
<p>Current versions of HYPE allow for defining significant instead of fixed number of digits, which should prevent this
issue from arising.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadMapOutput(filename = system.file("demo_model",
"results", "mapEVAP.txt", package = "HYPEtools"), dt.format = NULL)
te

</code></pre>

<hr>
<h2 id='ReadObs'>Read HYPE observation data files</h2><span id='topic+ReadObs'></span><span id='topic+ReadPTQobs'></span>

<h3>Description</h3>

<p>Import single-variable HYPE observation files into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadObs(
  filename,
  variable = "",
  dt.format = NULL,
  nrows = -1,
  type = c("df", "dt"),
  select = NULL,
  obsid = NULL
)

ReadPTQobs(
  filename,
  variable = "",
  dt.format = NULL,
  nrows = -1,
  type = c("df", "dt"),
  select = NULL,
  obsid = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadObs_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="ReadObs_+3A_variable">variable</code></td>
<td>
<p>Character string, HYPE variable ID of file contents. If <code>""</code> (default), the ID is extracted
from <code>filename</code>, which only works with HYPE input data file names or file names including those names
(e.g. 'Pobs_old.txt', 'testSFobs.txt'). Some of the observation data files have no corresponding HYPE variable ID.
In these cases, a dummy ID is used, see table in Details. If automatic extraction fails, attribute <code>variable</code> is set
to <code>"other"</code>. Alternatively, any other variable name can be provided.</p>
</td></tr>
<tr><td><code id="ReadObs_+3A_dt.format">dt.format</code></td>
<td>
<p>Optional date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>. If <code>NULL</code>, then HYPEtools will try to identify
the format automatically.</p>
</td></tr>
<tr><td><code id="ReadObs_+3A_nrows">nrows</code></td>
<td>
<p>Number of rows to import. A value of <code>-1</code> indicates all rows, a positive integer gives the number of rows
to import.</p>
</td></tr>
<tr><td><code id="ReadObs_+3A_type">type</code></td>
<td>
<p>Character, keyword for data type to return. <code>"df"</code> to return a standard data frame or <code>"dt"</code> to
return a <code><a href="data.table.html#topic+data.table">data.table</a></code> object.</p>
</td></tr>
<tr><td><code id="ReadObs_+3A_select">select</code></td>
<td>
<p>Integer vector, column numbers to import. Note: first column with dates must be imported and will be added if missing.</p>
</td></tr>
<tr><td><code id="ReadObs_+3A_obsid">obsid</code></td>
<td>
<p>Integer vector, HYPE OBSIDs to import. Alternative to argument <code>select</code>, takes precedence if both are provided.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadObs</code> is a convenience wrapper function of <code><a href="data.table.html#topic+fread">fread</a></code> from package
<code><a href="data.table.html#topic+data.table">data.table</a></code>,
with conversion of date-time strings to POSIX time representations. Observation IDs (SUBIDs or IDs connected to SUBIDs with a
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:forckey.txt">ForcKey.txt file</a>) are returned as integer
attribute <code>obsid</code> (directly accessible through <code><a href="#topic+obsid">obsid</a></code>).
</p>
<p>Observation file types with automatic (dummy) <code>variable</code> attribute assignment:</p>

<table>
<tr>
 <td style="text-align: left;">
   <strong>File</strong> </td><td style="text-align: center;"> <strong>HYPE variable ID</strong> </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td><td style="text-align: center;"> (*: dummy ID) </td>
</tr>
<tr>
 <td style="text-align: left;">
   Pobs.txt </td><td style="text-align: center;"> prec </td>
</tr>
<tr>
 <td style="text-align: left;">
   Tobs.txt </td><td style="text-align: center;"> temp </td>
</tr>
<tr>
 <td style="text-align: left;">
   Qobs.txt </td><td style="text-align: center;"> rout </td>
</tr>
<tr>
 <td style="text-align: left;">
   TMINobs.txt </td><td style="text-align: center;"> tmin* </td>
</tr>
<tr>
 <td style="text-align: left;">
   TMAXobs.txt </td><td style="text-align: center;"> tmax* </td>
</tr>
<tr>
 <td style="text-align: left;">
   VWobs.txt </td><td style="text-align: center;"> vwnd* </td>
</tr>
<tr>
 <td style="text-align: left;">
   UWobs.txt </td><td style="text-align: center;"> uwnd* </td>
</tr>
<tr>
 <td style="text-align: left;">
   SFobs.txt </td><td style="text-align: center;"> snff* </td>
</tr>
<tr>
 <td style="text-align: left;">
   SWobs.txt </td><td style="text-align: center;"> swrd* </td>
</tr>
<tr>
 <td style="text-align: left;">
   RHobs.txt </td><td style="text-align: center;"> rhum* </td>
</tr>
<tr>
 <td style="text-align: left;">
   Uobs.txt </td><td style="text-align: center;"> wind* </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Value</h3>

<p><code>ReadObs</code> returns a data frame or data table with additional attributes: <code>obsid</code> with observation IDs, <code>timestep</code>
with a time step string, either <code>"day"</code> or <code>"nhour"</code> (only daily or n-hourly time steps supported), and <code>variable</code>
with a HYPE variable ID string.
</p>


<h3>Note</h3>

<p>For the conversion of date/time strings, time zone &quot;UTC&quot; is assumed. This is done to avoid potential daylight saving time
side effects when working with the imported data (and e.g. converting to string representations during the process).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WriteObs">WriteObs</a></code>
<code><a href="#topic+ReadXobs">ReadXobs</a></code> for multi-variable HYPE observation files
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadObs(filename = system.file("demo_model", "Tobs.txt", package = "HYPEtools"))
head(te)

</code></pre>

<hr>
<h2 id='ReadOptpar'>Read an 'optpar.txt' file</h2><span id='topic+ReadOptpar'></span>

<h3>Description</h3>

<p>This function imports an 'optpar.txt' into a list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadOptpar(filename = "optpar.txt", encoding = c("unknown", "UTF-8", "latin1"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadOptpar_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the 'optpar.txt' file to import.</p>
</td></tr>
<tr><td><code id="ReadOptpar_+3A_encoding">encoding</code></td>
<td>
<p>Character string, encoding of non-ascii characters in imported text file. Particularly relevant when
importing files created under Windows (default encoding &quot;Latin-1&quot;) in Linux (default encoding &quot;UTF-8&quot;) and vice versa. See
also argument description in <code><a href="base.html#topic+scan">scan</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadOptpar</code> imports HYPE 'optpar.txt' files. Optpar files contain instructions for parameter calibration/optimization
and parameter value ranges, for details on the file format, see the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:optpar.txt">optpar.txt online documentation</a>.
</p>


<h3>Value</h3>

<p><code>ReadOptpar</code> returns a <code><a href="base.html#topic+list">list</a></code> object with three elements: </p>

<ul>
<li> <p><code>comment</code>, the file's first-row comment string.
</p>
</li>
<li> <p><code>tasks</code>, a two-column dataframe with row-wise key-value pairs for tasks and settings.
</p>
</li>
<li> <p><code>pars</code>, a list of dataframes, each containing values for one parameter. Three columns each, holding parameter
range minima, maxima, and intervals.
The number of rows in each dataframe corresponds to the number of soil or land use classes for class-specific parameters.
Parameter names as list element names.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ReadPar">ReadPar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadOptpar(filename = system.file("demo_model", "optpar.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='ReadPar'>Read a 'par.txt' file</h2><span id='topic+ReadPar'></span>

<h3>Description</h3>

<p>Import a HYPE parameter file as list into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadPar(filename = "par.txt", encoding = c("unknown", "UTF-8", "latin1"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadPar_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the parameter file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="ReadPar_+3A_encoding">encoding</code></td>
<td>
<p>Character string, encoding of non-ascii characters in imported text file. Particularly relevant when
importing files created under Windows (default encoding &quot;Latin-1&quot;) in Linux (default encoding &quot;UTF-8&quot;) and vice versa. See
also argument description in <code><a href="base.html#topic+scan">scan</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadPar</code> checks for inline comments in 'par.txt' files, these are moved to separate &quot;lines&quot; (list elements).
</p>


<h3>Value</h3>

<p><code>ReadPar</code> returns a list of named vectors. Parameters are returned as numeric vectors with HYPE parameter names as list
element names. Comments are returned in separate list elements as single character strings, former inline comments are moved
to elements preceding the original comment position (i.e. to a line above in the par.txt file structure). Comment elements are
named <code>`!!`</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadPar(filename = system.file("demo_model", "par.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='ReadPmsf'>Read a 'pmsf.txt' file</h2><span id='topic+ReadPmsf'></span>

<h3>Description</h3>

<p>This is a small convenience function to import a 'partial model setup file' as integer vector into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadPmsf(filename = "pmsf.txt")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadPmsf_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the pmsf file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadPmsf</code> imports 'pmsf.txt' files, which contain SUBIDs and are used to run only parts of a HYPE setup's domain
without having to extract a separate model setup. For details on the file format, see the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:pmsf.txt">pmsf.txt online documentation</a>.
Pmsf.txt files imported with <code>ReadPmsf</code> are stripped from the first value containing the total number of subcatchments
in the file. No additional attribute is added to hold this number since it can be easily obtained using <code><a href="base.html#topic+length">length</a></code>.
</p>


<h3>Value</h3>

<p><code>ReadPmsf</code> returns an integer vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='ReadSimass'>Read a 'simass.txt' file</h2><span id='topic+ReadSimass'></span>

<h3>Description</h3>

<p>Import a HYPE simass.txt simulation assessment file as data frame into R.
Simulation assessment files contain domain-wide aggregated performance criteria results, as defined in 'info.txt'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadSimass(filename = "simass.txt")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadSimass_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the 'simass.txt' file to import.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadSimass</code> imports a simulation assessment file into R.
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:simass.txt">HYPE simass.txt files</a> contain
domain-wide performance measures for observed-simulated variable pairs as defined in
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt#performance_criteria_options">HYPE info.txt files</a>.
</p>
<p>The function interprets character-coded time steps (e.g. <code>"DD"</code> for daily time steps), as used in some HYPE versions.
<strong>Sub-daily time steps are currently not treated</strong> and will probably result in a warning during time step evaluation within the
function. Please contact the developers if you need support for sub-daily time steps!
</p>


<h3>Value</h3>

<p><code>ReadSubass</code> returns a data frame with columns for HYPE variable names (observed, simulated), aggregation periods, and
performance measure values of evaluated variable pairs. Aggregation periods are coded as in info.txt files, i.e. 1 = daily,
2 = weekly, 3 = monthly, 4 = annual. Metadata is added to the data frame as additional <code><a href="base.html#topic+attributes">attributes</a></code>:
</p>

<ul>
<li><p><code>names.long</code>, <code>character</code> vector with long names, corresponding to abbreviations uses as actual column names
</p>
</li>
<li><p><code>n.simulation</code>, <code>integer</code>, simulation number (e.g. with Monte Carlo simulations)
</p>
</li>
<li><p><code>crit.total</code>, <code>numeric</code>, total criteria value
</p>
</li>
<li><p><code>crit.conditional</code>, <code>numeric</code>, conditional criteria value
</p>
</li>
<li><p><code>threshold</code>, <code>integer</code>, data limit threshold
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+ReadSubass">ReadSubass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadSimass(filename = system.file("demo_model",
"results", "simass.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='ReadSubass'>Read a 'subassX.txt' file</h2><span id='topic+ReadSubass'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to import an subassX.txt sub-basin assessment file as data frame into R.
Sub-basins assessment files contain performance criteria results, as defined in 'info.txt', for individual
sub-basins with observations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadSubass(
  filename = "subass1.txt",
  nhour = NULL,
  check.names = FALSE,
  na.strings = c("****************", "-9999")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadSubass_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the 'subassX.txt' file to import.</p>
</td></tr>
<tr><td><code id="ReadSubass_+3A_nhour">nhour</code></td>
<td>
<p>Integer, time step of sub-daily model results in hours. See details.</p>
</td></tr>
<tr><td><code id="ReadSubass_+3A_check.names">check.names</code></td>
<td>
<p>Logical. If <code>TRUE</code>, then the names of the variables are check to make sure they are syntactically valid.</p>
</td></tr>
<tr><td><code id="ReadSubass_+3A_na.strings">na.strings</code></td>
<td>
<p>Vector of strings that should be read as NA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadSubass</code> imports a sub-basin assessment file into R. Information on model variables evaluated in the
file is imported as additional <code><a href="base.html#topic+attributes">attributes</a></code> <code>variables</code>, the evaluation time step in an attribute
<code>timestep</code>.
</p>
<p>Sub-daily time steps are reported with time step code '0' in HYPE result files. In order to preserve the time step
information in the imported R object, users must provide the actual model evaluation time step in hours
in argument <code>nhour</code> in the sub-daily case.
</p>


<h3>Value</h3>

<p><code>ReadSubass</code> returns a data frame with two additional attributes: <code>variables</code> contains a 2-element
character vector with IDs of evaluated observed and simulated HYPE variables, <code>timestep</code> contains a character
keyword detailing the evaluation time step.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadSubass(filename = system.file("demo_model",
"results", "subass1.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='ReadTimeOutput'>Read a Time Output File</h2><span id='topic+ReadTimeOutput'></span>

<h3>Description</h3>

<p>Import a time output file 'time&lt;<em>HYPE_output_variable</em>&gt;.txt' or a converted time output file in netCDF format
into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadTimeOutput(
  filename,
  dt.format = "%Y-%m-%d",
  hype.var = NULL,
  out.reg = NULL,
  type = c("df", "dt", "hsv"),
  select = NULL,
  id = NULL,
  nrows = -1L,
  skip = 0L,
  warn.nan = FALSE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadTimeOutput_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the time output file to import. Acceptable file choices are <code>*.txt</code> files following
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:timexxxx.txt">HYPE time output file format</a> or <code>.nc</code>
files following the <a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_netcdf_standard">HYPE netCDF formatting standard</a>.
See also details for netCDF import.</p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_dt.format">dt.format</code></td>
<td>
<p>Date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>. Incomplete format strings for monthly
and annual values allowed, e.g. <code>"\%Y"</code>. If set to <code>NULL</code>, no date-time conversion will be attempted and the column will
be imported as <code>character</code>, applicable e.g. for files containing just one row of summary values over the model period.</p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_hype.var">hype.var</code></td>
<td>
<p>Character, HYPE variable ID in <code>x</code>. See
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables">list of HYPE variables</a>.
If <code>NULL</code> (default), the variable ID is extracted from the provided file name, which only works for standard HYPE
time output file names (incl. regional and class outputs).</p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_out.reg">out.reg</code></td>
<td>
<p>Logical, specify if file contents are sub-basin or output region results (i.e. SUBIDs or OUTREGIDs as columns).
<code>TRUE</code> for output regions, <code>FALSE</code> for sub-basins. <em>Use only in combination with user-provided <code>hype.var</code>
argument.</em></p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_type">type</code></td>
<td>
<p>Character, keyword for data type to return. <code>"df"</code> to return a standard data frame, <code>"dt"</code> to
return a <code><a href="data.table.html#topic+data.table">data.table</a></code> object, or <code>"hsv"</code> to return a <code><a href="#topic+HypeSingleVar">HypeSingleVar</a></code> array.</p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_select">select</code></td>
<td>
<p>Integer vector, column numbers to import. Note: first column with dates must be imported and will be added if missing.</p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_id">id</code></td>
<td>
<p>Integer vector, HYPE SUBIDs/OUTREGIDs to import. Alternative to argument <code>select</code>, takes precedence if both are provided.</p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_nrows">nrows</code></td>
<td>
<p>Integer, number of rows to import, see documentation in <code><a href="data.table.html#topic+fread">fread</a></code>.</p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_skip">skip</code></td>
<td>
<p>Integer, number of <em>data</em> rows to skip on import. Time output header lines are always skipped.</p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_warn.nan">warn.nan</code></td>
<td>
<p>Logical, check if imported results contain any <code>NaN</code> values. If <code>TRUE</code> and <code>NaN</code>s are found,
a warning is thrown and affected IDs saved in an attribute <code>id.nan</code>. Adds noticeable overhead to import time for large files.</p>
</td></tr>
<tr><td><code id="ReadTimeOutput_+3A_verbose">verbose</code></td>
<td>
<p>Logical, print information during import.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadTimeOutput</code> imports from text or netCDF files. <em>netCDF import is experimental and not feature-complete (e.g. attributes are
not yet fully digested).</em>
Text file import uses <code><a href="data.table.html#topic+fread">fread</a></code> from package
<code><a href="data.table.html#topic+data.table">data.table</a></code>, netCDF import extracts data and attributes using functions from package <code><a href="ncdf4.html#topic+nc_open">ncdf4</a></code>.
Date-time representations in data files are converted to POSIX time representations. Monthly and annual time steps are returned as
first day of the time step period.
</p>
<p>Import from netCDF files requires an <code>id</code> dimension in the netCDF data. Gridded data with remapped HYPE results in spatial x/y
dimensions as defined in the <a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_netcdf_standard">HYPE netCDF formatting standard</a>
are currently not supported.
</p>


<h3>Value</h3>

<p><code>ReadTimeOutput</code> returns a <code>data.frame</code>, <code><a href="data.table.html#topic+data.table">data.table</a></code>, or a <code><a href="#topic+HypeSingleVar">HypeSingleVar</a></code> array.
Data frames and data tables contain additional <code><a href="base.html#topic+attributes">attributes</a></code>: <code>variable</code>, giving the HYPE variable ID,
<code>subid</code> and <code>outregid</code>, the HYPE SUBIDs/OUTREGIDs (corresponding to columns from column two onward) to which the time
series belong (both attributes always created and assigned <code>NA</code> if not applicable to data contents), <code>timestep</code> with a
time step attribute, and <code>comment</code> with first row comment of imported text file as character string or global attributes of imported
netCDF file as character string of collated key-value pairs. An additional attribute <code>id.nan</code> might be returned, see argument
<code>warn.nan</code>.
</p>


<h3>Note</h3>

<p>For the conversion of date/time strings, time zone &quot;UTC&quot; is assumed. This is done to avoid potential daylight saving time
side effects when working with the imported data (and possibly converting to string representations during the process).
</p>
<p>HYPE results are printed to files using a user-specified accuracy. This accuracy is specified in 'info.txt' as a number of
decimals to print. If large numbers are printed, this can result in a total number of digits which is too large to print.
Results will then contain values of '****************'. <code>ReadTimeOutput</code> will convert those cases to 'NA' entries.
Current versions of HYPE allow for defining significant instead of fixed number of digits, which should prevent this
issue from arising.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadTimeOutput(filename = system.file("demo_model",
"results", "timeCOUT.txt", package = "HYPEtools"), dt.format = "%Y-%m")
te

</code></pre>

<hr>
<h2 id='ReadWsOutput'>Read optimization simulation results</h2><span id='topic+ReadWsOutput'></span>

<h3>Description</h3>

<p>Read and combine HYPE optimization simulation output files, generated with 'task WS' during HYPE optimization runs. Outputs can
consist of basin, time, or map output files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadWsOutput(
  path,
  type = c("time", "map", "basin"),
  hype.var = NULL,
  id = NULL,
  dt.format = NULL,
  select = NULL,
  from = NULL,
  to = NULL,
  progbar = TRUE,
  warn.nan = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadWsOutput_+3A_path">path</code></td>
<td>
<p>Character string, path to the directory holding simulation output files to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="ReadWsOutput_+3A_type">type</code></td>
<td>
<p>Character string, keyword for HYPE output file type to import. One of <code>"time"</code>, <code>"map"</code>, or
<code>"basin"</code>. Can be abbreviated. The first two require specification of argument <code>hype.var</code>, the latter of argument
<code>subid</code>. Format of return value depends on output type, see details.</p>
</td></tr>
<tr><td><code id="ReadWsOutput_+3A_hype.var">hype.var</code></td>
<td>
<p>Character string, keyword to specify HYPE output variable to import. Must include &quot;RG&quot;-prefix in case of output region files.
Not case-sensitive. Required in combination with <code>type</code> <code>"time"</code> or <code>"map"</code>.</p>
</td></tr>
<tr><td><code id="ReadWsOutput_+3A_id">id</code></td>
<td>
<p>Integer, giving a single SUBID or OUTREGID for which to import basin output files. Required in combination with <code>type</code>
<code>"basin"</code>.</p>
</td></tr>
<tr><td><code id="ReadWsOutput_+3A_dt.format">dt.format</code></td>
<td>
<p>Date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>, for conversion of date-time information in imported
result files to POSIX dates, which are returned as attribute. Incomplete format strings for monthly and annual values allowed, e.g.
'\
summary values over the model period.</p>
</td></tr>
<tr><td><code id="ReadWsOutput_+3A_select">select</code></td>
<td>
<p>Integer vector, column numbers to import, for use with <code>type = "time"</code>. Note: first column with dates must be
imported.</p>
</td></tr>
<tr><td><code id="ReadWsOutput_+3A_from">from</code></td>
<td>
<p>Integer. For partial imports, number of simulation iteration to start from.</p>
</td></tr>
<tr><td><code id="ReadWsOutput_+3A_to">to</code></td>
<td>
<p>Integer. For partial imports, number of simulation iteration to end with.</p>
</td></tr>
<tr><td><code id="ReadWsOutput_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while importing HYPE output files. Adds overhead to calculation time but useful
when many files are imported.</p>
</td></tr>
<tr><td><code id="ReadWsOutput_+3A_warn.nan">warn.nan</code></td>
<td>
<p>Logical, check if imported results contain any <code>NaN</code> values. If <code>TRUE</code> and <code>NaN</code>s are found,
a warning is thrown and affected SUBIDs and iterations are saved in an attribute <code>subid.nan</code>. Adds noticeable overhead to
import time for large simulation file sets.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>HYPE optimization routines optionally allow for generation of simulation output files for each iteration in the optimization routine.
For further details see documentation on 'task WS' in the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:optpar.txt">optpar.txt online documentation</a>.
</p>
<p><code>ReadWsOutput</code> imports and combines all simulation iterations in an <code><a href="base.html#topic+array">array</a></code>, which can then be easily used in
further analysis, most likely in combination with performance and parameter values from an imported corresponding 'allsim.txt' file.
</p>
<p>The result folder containing HYPE WS results, argument <code>path</code>, can contain other files as well, <code>ReadWsOutput</code> searches for
file name pattern to filter targeted result files. However, if files of the same type exist from different model runs, e.g.
from another calibration run or from a standard model run, the pattern search cannot distinguish these from the targeted files
and <code>ReadWsOutput</code> will fail.
</p>
<p>For large numbers of result files, simulations can be partially imported using arguments <code>from</code> and <code>to</code>, in order to avoid
memory exceedance problems.
</p>


<h3>Value</h3>

<p><code>ReadWsOutput</code> returns a 3-dimensional array with additional attributes. The array content depends on the HYPE output file type
specified in argument <code>type</code>. Time and map output file imports return an array of class <code><a href="#topic+HypeSingleVar">HypeSingleVar</a></code> with
<code>[time, subid, iteration]</code> dimensions, basin output file imports return an array of class <code><a href="#topic+HypeMultiVar">HypeMultiVar</a></code> with
<code>[time, variable, iteration]</code> dimensions. An additional attribute <code>subid.nan</code> might be
returned, see argument <code>warn.nan</code>, containing a list with SUBID vector elements. Vectors contain iterations where <code>NaN</code>
values occur for the given subid.
</p>
<p>Returned arrays contain additional <code><a href="base.html#topic+attributes">attributes</a></code>:
</p>

<dl>
<dt><strong>date</strong></dt><dd><p>A vector of date-times, <code>POSIX</code> if argument <code>dt.format</code> is non-<code>NULL</code>. Corresponds to 1st array
dimension.</p>
</dd>
<dt><strong>subid</strong></dt><dd><p>A (vector of) SUBID(s). Corresponds to 2nd array dimension for time and map output files.
<code>NA</code> if not applicable.</p>
</dd>
<dt><strong>outregid</strong></dt><dd><p>A (vector of) OUTREGID(s). Corresponds to 2nd array dimension for time and map output files.
<code>NA</code> if not applicable.</p>
</dd>
<dt><strong>variable</strong></dt><dd><p>A vector of HYPE output variables. Corresponds to 2nd array dimension for basin output files.</p>
</dd>
<dt><strong>nan (optional)</strong></dt><dd><p>A named list with SUBID or HYPE variable vector elements. Vectors contain iterations where <code>NaN</code>
values occur for the given SUBID/HYPE variable.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadWsOutput(path = system.file("demo_model",
"results", package = "HYPEtools"), type = "map",
hype.var = "cout", dt.format = "%Y-%m")
te

</code></pre>

<hr>
<h2 id='ReadXobs'>Read an 'Xobs.txt' file</h2><span id='topic+ReadXobs'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to import an Xobs file into R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadXobs(
  filename = "Xobs.txt",
  dt.format = "%Y-%m-%d",
  variable = NULL,
  nrows = -1L,
  verbose = if (nrows %in% 0:2) FALSE else TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ReadXobs_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the Xobs file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="ReadXobs_+3A_dt.format">dt.format</code></td>
<td>
<p>Date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>.</p>
</td></tr>
<tr><td><code id="ReadXobs_+3A_variable">variable</code></td>
<td>
<p>Character vector, HYPE variable ID(s) to select for import. Not case-sensitive. If <code>NULL</code> (default), all
variables are imported. See <a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:xobs.txt">Xobs.txt documentation</a>
for a list of variable IDs.</p>
</td></tr>
<tr><td><code id="ReadXobs_+3A_nrows">nrows</code></td>
<td>
<p>Integer, number of rows to import. A value of <code>-1</code> indicates all rows, a positive integer gives
the number of rows to import.</p>
</td></tr>
<tr><td><code id="ReadXobs_+3A_verbose">verbose</code></td>
<td>
<p>Logical, throw warning if class <code>HypeXobs</code>'s attribute <code>timestep</code> cannot be computed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ReadXobs</code> is a convenience wrapper function of <code><a href="data.table.html#topic+fread">fread</a></code> from package
<code><a href="data.table.html#topic+data.table">data.table</a></code>,
with conversion of date-time strings to POSIX time representations. Variable names, SUBIDs, comment, and timestep are returned as
attributes (see <code><a href="base.html#topic+attr">attr</a></code> on how to access these).
</p>
<p>Duplicated variable-SUBID combinations are not allowed in HYPE Xobs files, and the function will throw a warning if any are found.
</p>


<h3>Value</h3>

<p>If datetime import to POSIXct worked, <code>ReadXobs</code> returns a <code><a href="#topic+HypeXobs">HypeXobs</a></code> object, a data frame with four
additional attributes <code>variable</code>, <code>subid</code>, <code>comment</code>, and <code>timestep</code>: <code>variable</code>
and <code>subid</code> each contain a vector with column-wise HYPE IDs (first column with date/time information omitted).
<code>comment</code> contains the content of the Xobs file comment row as single string. <code>timestep</code> contains a keyword string.
Column names of the returned data frame are composed of variable names and SUBIDs, separated by an underscore,
i.e. <code>[variable]_[subid]</code>. If datetime conversion failed on import, the returned object is a data frame
(i.e. no class <code>HypeXobs</code>).
</p>


<h3>Note</h3>

<p>For the conversion of date/time strings, time zone &quot;UTC&quot; is assumed. This is done to avoid potential daylight saving time
side effects when working with the imported data (and e.g. converting to string representations during the process).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadXobs(filename = system.file("demo_model", "Xobs.txt", package = "HYPEtools"))
te

</code></pre>

<hr>
<h2 id='RescaleSLCClasses'>Re-scale SLC classes in a GeoData data frame</h2><span id='topic+RescaleSLCClasses'></span>

<h3>Description</h3>

<p><code>RescaleSLCClasses</code> re-scales several or all SLC classes for each SUBID in a GeoData data frame
to a new target sum for all classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RescaleSLCClasses(gd, slc.exclude = NULL, target = 1, plot.box = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RescaleSLCClasses_+3A_gd">gd</code></td>
<td>
<p>A data frame containing columns 'SLC_n' (<code class="reqn">n \ge 1</code>), typically an imported 'GeoData.txt' file.</p>
</td></tr>
<tr><td><code id="RescaleSLCClasses_+3A_slc.exclude">slc.exclude</code></td>
<td>
<p>Integer, SLC class numbers. Area fractions of classes listed here are kept fixed
during re-scaling. If <code>NULL</code> (default), all classes are re-scaled.</p>
</td></tr>
<tr><td><code id="RescaleSLCClasses_+3A_target">target</code></td>
<td>
<p>Numeric, target sum for SLC class fractions in each subbasin after re-scaling. Either a single
number or a vector with one value for each row in <code>gd</code>.</p>
</td></tr>
<tr><td><code id="RescaleSLCClasses_+3A_plot.box">plot.box</code></td>
<td>
<p>Logical, if <code>TRUE</code>, a box plot of SLC area sums is returned.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>RescaleSLCClasses</code> allows to rescale SLC classes, e.g. as part of a post-processing work flow during
HYPE model setup. Individual SLC classes can be excluded to protect. This can be useful e.g. for lake areas which
maybe must correspond to areas a LakeData file. The function will throw a warning if excluded SLC class fractions
are greater than sums provided in <code>target</code>, but not if they are smaller.
</p>


<h3>Value</h3>

<p><code>RescaleSLCClasses</code> returns the data frame provided in <code>gd</code>, with re-scaled SLC class fractions.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SumSLCClasses">SumSLCClasses</a></code> for inspection of SLC class fraction sums in each subbasin
<code><a href="#topic+CleanSLCClasses">CleanSLCClasses</a></code> for pruning of small SLC fractions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import source data
te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
# Re-scale SLC classes, protect the first two
RescaleSLCClasses(gd = te, slc.exclude = 1:2)

</code></pre>

<hr>
<h2 id='ScalePar'>Scale 'par.txt' files to different model time step</h2><span id='topic+ScalePar'></span>

<h3>Description</h3>

<p><code>ScalePar</code> scales time step-dependent parameters in an imported
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:par.txt">HYPE 'par.txt'</a> parameter file to a
new target time step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ScalePar(x, sfac = 1/24, digits = 3, verbose = TRUE, print.par = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ScalePar_+3A_x">x</code></td>
<td>
<p>List containing HYPE parameters. Typically imported with <code><a href="#topic+ReadPar">ReadPar()</a></code>.</p>
</td></tr>
<tr><td><code id="ScalePar_+3A_sfac">sfac</code></td>
<td>
<p>Numeric, scale factor. Defaults to scaling from daily to hourly time steps.</p>
</td></tr>
<tr><td><code id="ScalePar_+3A_digits">digits</code></td>
<td>
<p>Integer, number of significant digits <em>in SLC class columns</em> to export. See <code><a href="base.html#topic+signif">signif()</a></code>.</p>
</td></tr>
<tr><td><code id="ScalePar_+3A_verbose">verbose</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then information will be printed.</p>
</td></tr>
<tr><td><code id="ScalePar_+3A_print.par">print.par</code></td>
<td>
<p>Logical, print known time-scale dependent parameters instead of scaling a par list.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>ScalePar</code> simply applies a user-chosen scaling factor <code>sfac</code> to all time scale-dependent parameters
in a HYPE parameter list. Parameters are matched against an inbuilt set of parameter names.
<em><a href="https://github.com/rcapell/HYPEtools/issues">Please notify us</a> if you find parameters missing.</em>
</p>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+list">list()</a></code> object as supplied in <code>x</code>, with parameters re-scaled parameters, or nothing if <code>print.par = TRUE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import daily HYPE parameter file
hpar &lt;- ReadPar(filename = system.file("demo_model", "par.txt", package = "HYPEtools"))
# Scale to hourly time steps
ScalePar(x = hpar)
# Print all time scale-dependent parameters known to the function
ScalePar(print.par = TRUE)

</code></pre>

<hr>
<h2 id='SimToPar'>HYPE Calibration Outputs to par.txt</h2><span id='topic+SimToPar'></span><span id='topic+AllSimToPar'></span><span id='topic+BestSimsToPar'></span>

<h3>Description</h3>

<p>Update par.txt with values from an allsim.txt or bestsims.txt file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AllSimToPar(simfile, row, par)

BestSimsToPar(simfile, row, par)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SimToPar_+3A_simfile">simfile</code></td>
<td>
<p>Imported allsim.txt or bestsims.txt file imported as data frame.</p>
</td></tr>
<tr><td><code id="SimToPar_+3A_row">row</code></td>
<td>
<p>Integer, row number indicating row containing the parameter values that should be replaced/added to <code>par</code>.</p>
</td></tr>
<tr><td><code id="SimToPar_+3A_par">par</code></td>
<td>
<p>Imported par.txt file that should be updated using parameter values from <code>simfile</code>. Typically imported using <code><a href="#topic+ReadPar">ReadPar</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>AllSimToPar</code> and <code>BestSimsToPar</code> can be used to update an existing par.txt file with the parameter values from a HYPE allsim.txt or bestsims.txt file.
If a parameter in the allsim or bestsims file already exists in <code>par</code>, then the parameter values will be overwritten in <code>par</code>. If the parameter does not exist,
then the parameter will be added to the bottom of the output.
</p>


<h3>Value</h3>

<p><code>AllSimToPar</code> and <code>BestSimsToPar</code> return a list of named vectors in the format used by <code><a href="#topic+ReadPar">ReadPar</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadPar">ReadPar</a></code> for HYPE par.txt import; <code><a href="#topic+WritePar">WritePar</a></code> to export HYPE par.txt files
</p>


<h3>Examples</h3>

<pre><code class='language-R'>simfile &lt;- read.table(file = system.file("demo_model", "results",
  "bestsims.txt",
  package = "HYPEtools"
), header = TRUE, sep = ",")
par &lt;- ReadPar(filename = system.file("demo_model", "par.txt", package = "HYPEtools"))
BestSimsToPar(simfile, 1, par)

</code></pre>

<hr>
<h2 id='SortGeoData'>Sort a GeoData dataframe in downstream order</h2><span id='topic+SortGeoData'></span>

<h3>Description</h3>

<p>Function to sort an imported GeoData.txt file in downstream order, so that all upstream sub-basins are listed in rows above downstream sub-basins.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SortGeoData(gd, bd = NULL, progbar = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SortGeoData_+3A_gd">gd</code></td>
<td>
<p>A data frame containing a column with SUBIDs and a column (MAINDOWN) containing the corresponding downstream SUBID, e.g. an imported 'GeoData.txt' file.</p>
</td></tr>
<tr><td><code id="SortGeoData_+3A_bd">bd</code></td>
<td>
<p>A data frame with bifurcation connections, e.g. an imported 'BranchData.txt' file. Optional argument.</p>
</td></tr>
<tr><td><code id="SortGeoData_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while calculating SUBID sorting.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>GeoData.txt files need to be sorted in downstream order for HYPE to run without errors. <code>SortGeoData</code> considers bifurcation connections, but not
irrigation or groundwater flow links.
</p>


<h3>Value</h3>

<p><code>SortGeoData</code> returns a GeoData dataframe.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids</a></code>
<code><a href="#topic+OutletSubids">OutletSubids</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
SortGeoData(gd = te)

</code></pre>

<hr>
<h2 id='SubidAttributeSummary'>Summarize subbasin attributes</h2><span id='topic+SubidAttributeSummary'></span>

<h3>Description</h3>

<p>Prepare data frame containing summary of subbasin attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SubidAttributeSummary(
  subids = NULL,
  gd,
  bd = NULL,
  gc = NULL,
  desc = NULL,
  group = NULL,
  group.upstream = TRUE,
  signif.digits = NULL,
  progbar = FALSE,
  summarize.landuse = TRUE,
  summarize.soil = TRUE,
  summarize.crop = TRUE,
  summarize.upstreamarea = TRUE,
  unweighted.gd.cols = NULL,
  upstream.gd.cols = NULL,
  olake.slc = NULL,
  bd.weight = FALSE,
  mapoutputs = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SubidAttributeSummary_+3A_subids">subids</code></td>
<td>
<p>Vector containing SUBIDs of subbasins to summarize.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_gd">gd</code></td>
<td>
<p>Imported HYPE GeoData.txt file. See <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_bd">bd</code></td>
<td>
<p>Imported HYPE BranchData.txt file. See <code><a href="#topic+ReadBranchData">ReadBranchData</a></code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_gc">gc</code></td>
<td>
<p>Imported HYPE GeoClass.txt file. See <code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_desc">desc</code></td>
<td>
<p>Optional, Imported HYPE Description file. If provided, then dataframe columns will be renamed using the short names in the description file. See <code><a href="#topic+ReadDescription">ReadDescription</a></code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_group">group</code></td>
<td>
<p>Optional, Integer vector of same length as number of SLC classes in gd. Alternative grouping index specification to gcl + type for <code><a href="#topic+UpstreamGroupSLCClasses">UpstreamGroupSLCClasses</a></code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_group.upstream">group.upstream</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then SLC fractions will be summarized for upstream areas using <code><a href="#topic+UpstreamGroupSLCClasses">UpstreamGroupSLCClasses</a></code>.
If <code>FALSE</code>, then SLC fractions will be summarized for subbasin area only using <code><a href="#topic+GroupSLCClasses">GroupSLCClasses</a></code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_signif.digits">signif.digits</code></td>
<td>
<p>Optional, Integer specifying number of significant digits to round outputs to. Used by <code><a href="#topic+UpstreamGroupSLCClasses">UpstreamGroupSLCClasses</a></code> and <code>link{UpstreamGeoData}</code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while calculating summary information. Used by <code><a href="#topic+UpstreamGroupSLCClasses">UpstreamGroupSLCClasses</a></code> and <code>link{UpstreamGeoData}</code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_summarize.landuse">summarize.landuse</code></td>
<td>
<p>Logical, specify whether or not subbasin upstream landuse fractions should be calculated.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_summarize.soil">summarize.soil</code></td>
<td>
<p>Logical, specify whether or not subbasin upstream soil fractions should be calculated.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_summarize.crop">summarize.crop</code></td>
<td>
<p>Logical, specify whether or not subbasin upstream crop fractions should be calculated.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_summarize.upstreamarea">summarize.upstreamarea</code></td>
<td>
<p>Logical, specify whether or not subbasin upstream area should be calculated.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_unweighted.gd.cols">unweighted.gd.cols</code></td>
<td>
<p>Vector, names of <code>gd</code> columns which should be joined to the output data frame without any additional processing.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_upstream.gd.cols">upstream.gd.cols</code></td>
<td>
<p>Vector, specify column names of <code>gd</code> which should be summarized using <code><a href="#topic+UpstreamGeoData">UpstreamGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_olake.slc">olake.slc</code></td>
<td>
<p>Integer, SLC class number representing outlet lake fractions. Used by <code><a href="#topic+UpstreamGeoData">UpstreamGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_bd.weight">bd.weight</code></td>
<td>
<p>Logical, if set to TRUE, flow weights will be applied for areas upstream of stream bifurcations. See <code><a href="#topic+UpstreamGeoData">UpstreamGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="SubidAttributeSummary_+3A_mapoutputs">mapoutputs</code></td>
<td>
<p>Vector, paths to mapoutput files that should be read by <code><a href="#topic+ReadMapOutput">ReadMapOutput</a></code> and joined to the output data frame.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>SubidAttributeSummary</code> can be used to create a data frame object containing subbasin attribute summary information. This data frame can then be used as the <code>attributes</code>
input for <code><a href="#topic+PlotPerformanceByAttribute">PlotPerformanceByAttribute</a></code>. The function can summarize subbasin upstream landuse, soil, and crop fractions using <code><a href="#topic+UpstreamGroupSLCClasses">UpstreamGroupSLCClasses</a></code>. In addition, the
function can summarize upstream GeoData information using <code><a href="#topic+UpstreamGeoData">UpstreamGeoData</a></code>. Finally, the function can join mapoutput and GeoData columns directly to the output data frame (i.e without further processing).
</p>


<h3>Value</h3>

<p><code>SubidAttributeSummary</code> returns a data frame object containing subbasin attribute summary information.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+UpstreamGroupSLCClasses">UpstreamGroupSLCClasses</a></code>, <code><a href="#topic+GroupSLCClasses">GroupSLCClasses</a></code>, <code><a href="#topic+UpstreamGeoData">UpstreamGeoData</a></code>, <code><a href="#topic+ReadMapOutput">ReadMapOutput</a></code> for subbasin attribute summary functions; <code><a href="#topic+PlotPerformanceByAttribute">PlotPerformanceByAttribute</a></code> for related plotting function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
subass &lt;- ReadSubass(filename = system.file("demo_model", "results",
  "subass1.txt",
  package = "HYPEtools"
), check.names = TRUE)
gd &lt;- ReadGeoData(filename = system.file("demo_model",
  "GeoData.txt",
  package = "HYPEtools"
))
gc &lt;- ReadGeoClass(filename = system.file("demo_model",
  "GeoClass.txt",
  package = "HYPEtools"
))

SubidAttributeSummary(subids &lt;- subass$SUBID,
  gd = gd, gc = gc,
  mapoutputs = c(system.file("demo_model", "results", "mapCOUT.txt", package = "HYPEtools")),
  upstream.gd.cols = c("SLOPE_MEAN")
)


</code></pre>

<hr>
<h2 id='SumSLCClasses'>Calculate sums of SLC classes in a GeoData file</h2><span id='topic+SumSLCClasses'></span>

<h3>Description</h3>

<p><code>SumSLCClasses</code> sums all SLC classes for each SUBID in a GeoData data frame and optionally plots the results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SumSLCClasses(gd, plot.box = TRUE, silent = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SumSLCClasses_+3A_gd">gd</code></td>
<td>
<p>Data frame containing columns with SLC fractions, typically a 'GeoData.txt' file imported with <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="SumSLCClasses_+3A_plot.box">plot.box</code></td>
<td>
<p>Logical, if <code>TRUE</code>, a box plot of SLC area sums is returned.</p>
</td></tr>
<tr><td><code id="SumSLCClasses_+3A_silent">silent</code></td>
<td>
<p>Logical, if set to <code>TRUE</code>, the default printing of a result summary is suppressed.</p>
</td></tr>
<tr><td><code id="SumSLCClasses_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code><a href="graphics.html#topic+boxplot">boxplot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>SumSLCClasses</code> is a wrapper for <code><a href="Matrix.html#topic+colSums">colSums</a></code> with a boxplot output option, and allows to quickly control if SLCs of all SUBIDs in a
GeoData data frame sum up to 1.
</p>


<h3>Value</h3>

<p><code>SumSLCClasses</code> returns a vector of SLC sums, invisibly if <code>plot.box</code> is <code>TRUE</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
SumSLCClasses(gd = te, plot.box = TRUE)
SumSLCClasses(gd = te, plot.box = FALSE)


</code></pre>

<hr>
<h2 id='SumUpstreamArea'>Calculate upstream area sums</h2><span id='topic+SumUpstreamArea'></span>

<h3>Description</h3>

<p>Function to calculate upstream areas of a vector of SUBIDs or all SUBIDs in a GeoData table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SumUpstreamArea(subid = NULL, gd, bd = NULL, cl = 2, progbar = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SumUpstreamArea_+3A_subid">subid</code></td>
<td>
<p>Integer vector of SUBIDs to calculate upstream areas for (must exist in <code>gd</code>). If <code>NULL</code>, upstream areas for all
SUBIDs will be calculated.</p>
</td></tr>
<tr><td><code id="SumUpstreamArea_+3A_gd">gd</code></td>
<td>
<p>A data frame, containing 'SUBID', 'MAINDOWN', and 'AREA' columns, e.g. an imported 'GeoData.txt' file.</p>
</td></tr>
<tr><td><code id="SumUpstreamArea_+3A_bd">bd</code></td>
<td>
<p>A data frame, containing 'BRANCHID' and 'SOURCEID' columns, e.g. an imported 'BranchData.txt' file. Optional argument.</p>
</td></tr>
<tr><td><code id="SumUpstreamArea_+3A_cl">cl</code></td>
<td>
<p>Integer, number of processes to use for parallel computation. Set to <code>1</code> for serial computation. See <code><a href="parallel.html#topic+detectCores">parallel::detectCores()</a></code>.</p>
</td></tr>
<tr><td><code id="SumUpstreamArea_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while calculating upstream areas. Adds overhead to calculation time but useful if you want
HYPEtools to decide how long your coffee break should take.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>SumUpstreamArea</code> sums upstream areas of all connected upstream SUBIDs, including branch connections in case of stream bifurcations
but not including potential irrigation links or groundwater flows.
</p>


<h3>Value</h3>

<p><code>SumUpstreamArea</code> returns a data frame with two columns containing SUBIDs and total upstream areas (in area units as provided in <code>gd</code>).
Upstream areas include areas of outlet SUBIDs.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
SumUpstreamArea(subid = c(3361, 63794), gd = te, progbar = FALSE)

</code></pre>

<hr>
<h2 id='UpstreamGeoData'>Calculate upstream sums and averages of selected GeoData contents</h2><span id='topic+UpstreamGeoData'></span>

<h3>Description</h3>

<p>Function to calculate upstream sums and averages for selected variables of imported GeoData.txt files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UpstreamGeoData(
  subid = NULL,
  gd,
  bd = NULL,
  olake.slc = NULL,
  bd.weight = FALSE,
  signif.digits = 5,
  progbar = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UpstreamGeoData_+3A_subid">subid</code></td>
<td>
<p>Integer vector of SUBIDs for which to calculate upstream properties (must exist in <code>gd</code>).
If <code>NULL</code> (default), upstream areas for all SUBIDs will be calculated.</p>
</td></tr>
<tr><td><code id="UpstreamGeoData_+3A_gd">gd</code></td>
<td>
<p>A data frame containing a column with SUBIDs and a column with areas, e.g. an imported 'GeoData.txt' file.</p>
</td></tr>
<tr><td><code id="UpstreamGeoData_+3A_bd">bd</code></td>
<td>
<p>A data frame with bifurcation connections, e.g. an imported 'BranchData.txt' file. Optional argument.</p>
</td></tr>
<tr><td><code id="UpstreamGeoData_+3A_olake.slc">olake.slc</code></td>
<td>
<p>Integer,SLC class number which represents outlet lake fractions. Mandatory for weighted averaging of outlet lake depths.</p>
</td></tr>
<tr><td><code id="UpstreamGeoData_+3A_bd.weight">bd.weight</code></td>
<td>
<p>Logical, if set to <code>TRUE</code>, flow weights will be applied for areas upstream of stream bifurcations. See
<code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids</a></code> for further details on flow fraction computation.</p>
</td></tr>
<tr><td><code id="UpstreamGeoData_+3A_signif.digits">signif.digits</code></td>
<td>
<p>Integer, number of significant digits to round upstream variables to. See also <code><a href="base.html#topic+signif">signif</a></code>.
Set to <code>NULL</code> to prevent rounding.</p>
</td></tr>
<tr><td><code id="UpstreamGeoData_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while calculating SLC class fractions. Adds overhead to calculation time but useful
when <code>subid</code> is <code>NULL</code> or contains many SUBIDs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>UpstreamGeoData</code> calculates upstream averages or sums of selected variables in a GeoData data frame, including branch connections
in case of stream bifurcations but not including potential irrigation links or groundwater flows. Averages are weighted by sub-catchment area, with
the exception of outlet lake depths and rural household emission concentrations provided in GeoData variables 'lake_depth', 'loc_tn',
and 'loc_tp'. Outlet lake depths are weighted by outlet lake area and the GeoData column with
SLC class fractions for outlet lakes must be provided in function argument <code>col.olake.slc</code>. Rural household emissions are weighted by
emission volume as provided in column 'loc_vol'. Elevation and slope standard deviations are
averaged if the corresponding mean values exist (sample means are required to calculate overall means of standard deviations).
</p>
<p>Currently, the following variables are considered:
</p>

<dl>
<dt>Area-weighted average</dt><dd><p>elev_mean, slope_mean, buffer, close_w, latitude, longitude, all SLC classes, lake depths, elev_std, slope_std</p>
</dd>
<dt>Volume-weighted average</dt><dd><p>loc_tn, loc_tp</p>
</dd>
<dt>Sum</dt><dd><p>area, rivlen, loc_vol</p>
</dd>
</dl>



<h3>Value</h3>

<p><code>UpstreamGeoData</code> returns a data frame with the same number of columns as argument <code>gd</code> and number of rows corresponding to number of
SUBIDs in argument <code>subid</code>, with updated upstream columns marked with a leading 'UP_' in the column names.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+UpstreamSLCClasses">UpstreamSLCClasses</a></code>
<code><a href="#topic+SumUpstreamArea">SumUpstreamArea</a></code>
<code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
# Upstream stats for domain outlet
UpstreamGeoData(subid = OutletSubids(te), gd = te, olake.slc = 1, progbar = FALSE)

</code></pre>

<hr>
<h2 id='UpstreamGroupSLCClasses'>Calculate area-weighted upstream averages of grouped SLC class fractions.</h2><span id='topic+UpstreamGroupSLCClasses'></span>

<h3>Description</h3>

<p>Function to calculate averages of grouped SLC class fractions calculated from imported GeoData.txt and GeoClass.txt or any other user-defined grouping.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UpstreamGroupSLCClasses(
  subid = NULL,
  gd,
  bd = NULL,
  gcl = NULL,
  type = c("landuse", "soil", "crop"),
  group = NULL,
  signif.digits = 3,
  progbar = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UpstreamGroupSLCClasses_+3A_subid">subid</code></td>
<td>
<p>Integer vector of SUBIDs for which to calculate upstream properties (must exist in <code>gd</code>).
If <code>NULL</code> (default), upstream areas for all SUBIDs will be calculated.</p>
</td></tr>
<tr><td><code id="UpstreamGroupSLCClasses_+3A_gd">gd</code></td>
<td>
<p>A data frame containing a column with SUBIDs and a column with areas, e.g. an imported 'GeoData.txt' file imported with <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.</p>
</td></tr>
<tr><td><code id="UpstreamGroupSLCClasses_+3A_bd">bd</code></td>
<td>
<p>A data frame, containing 'BRANCHID' and 'SOURCEID' columns, e.g. an imported 'BranchData.txt' file. Optional argument.</p>
</td></tr>
<tr><td><code id="UpstreamGroupSLCClasses_+3A_gcl">gcl</code></td>
<td>
<p>Data frame containing columns with SLCs and corresponding land use and soil class IDs, typically a 'GeoClass.txt'
file imported with <code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code>. Must be provided if no <code>group</code> argument is given.</p>
</td></tr>
<tr><td><code id="UpstreamGroupSLCClasses_+3A_type">type</code></td>
<td>
<p>Keyword character string for use with <code>gcl</code>. Type of grouping index, choice of <code>"landuse"</code>, <code>"soil"</code>, and/or <code>"crop"</code>,
can be abbreviated.</p>
</td></tr>
<tr><td><code id="UpstreamGroupSLCClasses_+3A_group">group</code></td>
<td>
<p>Integer vector, of same length as number of SLC classes in <code>gd</code>. Alternative grouping index specification to <code>gcl</code> + <code>type</code>.</p>
</td></tr>
<tr><td><code id="UpstreamGroupSLCClasses_+3A_signif.digits">signif.digits</code></td>
<td>
<p>Integer, number of significant digits to round upstream SLCs to. See also <code><a href="base.html#topic+signif">signif</a></code>. Set to <code>NULL</code> to prevent rounding.</p>
</td></tr>
<tr><td><code id="UpstreamGroupSLCClasses_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while calculating SLC class fractions. Adds overhead to calculation time but useful when <code>subid</code>
is <code>NULL</code> or contains many SUBIDs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>UpstreamGroupSLCClasses</code> calculates area-weighted upstream averages of CropID fractions from SLC class fractions in a GeoData table and corresponding
grouping columns in a GeoClass table or a user-provided vector. Upstream calculations include branch connections in case of stream bifurcations but not
potential irrigation links or groundwater flows. Averages are weighted by sub-catchment area.
</p>
<p>The function builds on <code><a href="#topic+GroupSLCClasses">GroupSLCClasses</a></code>, which provides grouped sums of SLC classes for several or all sub-basins in a GeoData dataframe.
</p>


<h3>Value</h3>

<p><code>UpstreamGroupSLCClasses</code> returns a data frame with SUBIDs in the first column, and upstream group fractions in the following columns.
</p>


<h3>Note</h3>

<p><code>UpstreamGroupSLCClasses</code> expects SLC class columns in argument <code>gd</code> to be ordered in ascending order.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GroupSLCClasses">GroupSLCClasses</a></code>
<code><a href="#topic+UpstreamSLCClasses">UpstreamSLCClasses</a></code>
<code><a href="#topic+UpstreamGeoData">UpstreamGeoData</a></code>
<code><a href="#topic+SumUpstreamArea">SumUpstreamArea</a></code>
<code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import source data
te1 &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
te2 &lt;- ReadGeoClass(filename = system.file("demo_model", "GeoClass.txt", package = "HYPEtools"))
# Upstream land use fractions for single SUBID
UpstreamGroupSLCClasses(subid = 63794, gd = te1, gcl = te2, type = "landuse", progbar = FALSE)
# Upstream soil fraction for all SUBIDs in GeoData
UpstreamGroupSLCClasses(gd = te1, gcl = te2, type = "soil")

</code></pre>

<hr>
<h2 id='UpstreamPointSources'>Summarize point source emissions of all upstream areas</h2><span id='topic+UpstreamPointSources'></span>

<h3>Description</h3>

<p>Function to calculate point source emissions over all upstream areas of a vector of SUBIDs or all SUBIDs in a GeoData table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UpstreamPointSources(
  subid = NULL,
  gd,
  psd,
  bd = NULL,
  signif.digits = 4,
  progbar = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UpstreamPointSources_+3A_subid">subid</code></td>
<td>
<p>Integer vector of SUBIDs to calculate upstream point sources for (must exist in <code>gd</code>).
If <code>NULL</code>, upstream point sources for all SUBIDs in 'gd' will be calculated.</p>
</td></tr>
<tr><td><code id="UpstreamPointSources_+3A_gd">gd</code></td>
<td>
<p>A data frame containing columns 'SUBID' with SUBIDs and 'MAINDOWN' with downstream SUBIDs,
e.g. an imported 'GeoData.txt' file.</p>
</td></tr>
<tr><td><code id="UpstreamPointSources_+3A_psd">psd</code></td>
<td>
<p>A data frame with HYPE point source specifications, typically a 'PointSourceData.txt' file imported with <code><a href="#topic+ReadPointSourceData">ReadPointSourceData</a></code>.</p>
</td></tr>
<tr><td><code id="UpstreamPointSources_+3A_bd">bd</code></td>
<td>
<p>A data frame, containing 'BRANCHID' and 'SOURCEID' columns, e.g. an imported 'BranchData.txt' file. Optional argument.</p>
</td></tr>
<tr><td><code id="UpstreamPointSources_+3A_signif.digits">signif.digits</code></td>
<td>
<p>Integer, number of significant digits to round upstream SLCs to. See also <code><a href="base.html#topic+signif">signif</a></code>. Set to <code>NULL</code> to prevent rounding.</p>
</td></tr>
<tr><td><code id="UpstreamPointSources_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while calculating SLC class fractions. Adds overhead to calculation time but useful when <code>subid</code>
is <code>NULL</code> or contains many SUBIDs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>UpstreamPointSources</code> calculates summarized upstream point source emissions. For each sub-basin with at least one upstream
point source (including the sub-basin itself), summed emission volumes and volume weighted emission concentrations are calculated.
HYPE point source types ('ps_type') are returned in separate rows. <code>UpstreamPointSources</code> requires point source types to be one of <code>-1, 0, 1, 2, 3</code>,
corresponding to water abstractions, no differentiation/tracer, and type 1 to 3 (e.g. wastewater treatment plants, industries, and urban stormwater).
For water abstraction point sources, only summed upstream volumes are returned, i.e., concentrations are simply set to zero in results.
</p>


<h3>Value</h3>

<p><code>UpstreamPointSources</code> returns a data frame with columns containing SUBIDs, point source types, volumes, and concentrations found in <code>psd</code>: total nitrogen,
total phosphorus, total suspended sediment, tracer, and temperature.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te1 &lt;- ReadPointSourceData(filename = system.file("demo_model",
"PointSourceData.txt", package = "HYPEtools"))
te2 &lt;- ReadGeoData(filename = system.file("demo_model",
"GeoData.txt", package = "HYPEtools"))
UpstreamPointSources(subid = OutletSubids(te2), gd = te2,
psd = te1, progbar = FALSE)

</code></pre>

<hr>
<h2 id='UpstreamSLCClasses'>Calculate SLC class fractions of all upstream areas</h2><span id='topic+UpstreamSLCClasses'></span>

<h3>Description</h3>

<p>Function to calculate SLC class fractions over all upstream areas of a vector of SUBIDs or all SUBIDs in a GeoData table.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>UpstreamSLCClasses(
  subid = NULL,
  gd,
  bd = NULL,
  signif.digits = 3,
  progbar = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="UpstreamSLCClasses_+3A_subid">subid</code></td>
<td>
<p>Integer vector of SUBIDs to calculate upstream SUBID fractions for (must exist in <code>gd</code>).
If <code>NULL</code>, upstream areas for all SUBIDs will be calculated.</p>
</td></tr>
<tr><td><code id="UpstreamSLCClasses_+3A_gd">gd</code></td>
<td>
<p>A data frame containing columns 'SUBID' with SUBIDs, 'MAINDOWN' with downstream SUBIDs, and 'AREA' with sub-basin areas,
e.g. an imported 'GeoData.txt' file.</p>
</td></tr>
<tr><td><code id="UpstreamSLCClasses_+3A_bd">bd</code></td>
<td>
<p>A data frame with bifurcation connections, e.g. an imported 'BranchData.txt' file. Optional argument.</p>
</td></tr>
<tr><td><code id="UpstreamSLCClasses_+3A_signif.digits">signif.digits</code></td>
<td>
<p>Integer, number of significant digits to round upstream SLCs to. See also <code><a href="base.html#topic+signif">signif</a></code>. Set to <code>NULL</code> to prevent rounding.</p>
</td></tr>
<tr><td><code id="UpstreamSLCClasses_+3A_progbar">progbar</code></td>
<td>
<p>Logical, display a progress bar while calculating SLC class fractions. Adds overhead to calculation time but useful when <code>subid</code>
is <code>NULL</code> or contains many SUBIDs.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>UpstreamSLCClasses</code> sums upstream areas of all connected upstream SUBIDs, including branch connections in case of stream bifurcations
but not including potential irrigation links or groundwater flows.
</p>


<h3>Value</h3>

<p><code>UpstreamSLCClasses</code> returns a data frame with columns containing SUBIDs, total upstream areas (in area unit as provided in <code>gd</code>), and SLC
class fractions for upstream areas.
</p>


<h3>Note</h3>

<p>This function is now superseded by <code><a href="#topic+UpstreamGeoData">UpstreamGeoData</a></code>, which returns more upstream variables.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SumUpstreamArea">SumUpstreamArea</a></code>, <code><a href="#topic+UpstreamGeoData">UpstreamGeoData</a></code>, <code><a href="#topic+UpstreamGroupSLCClasses">UpstreamGroupSLCClasses</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Import source data
te1 &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
# Upstream SLCs for single SUBID
UpstreamSLCClasses(subid = 3361, gd = te1, progbar = FALSE)

</code></pre>

<hr>
<h2 id='VariableLookup'>Lookup Functions For HYPE Variables</h2><span id='topic+VariableLookup'></span><span id='topic+VariableInfo'></span><span id='topic+VariableSearch'></span>

<h3>Description</h3>

<p>Lookup information (e.g. Name, Units) for a specific HYPE variable ID, or find HYPE variable information for a search term.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VariableInfo(
  variable,
  info = c("ID", "Name", "Unit", "Description", "Aggregation", "Reference", "Component")
)

VariableSearch(
  search,
  info = c("ID", "Name", "Unit", "Description", "Aggregation", "Reference", "Component"),
  ignore_case = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VariableLookup_+3A_variable">variable</code></td>
<td>
<p>String, HYPE Variable ID (e.g. &quot;COUT&quot;).</p>
</td></tr>
<tr><td><code id="VariableLookup_+3A_info">info</code></td>
<td>
<p>A vector of strings describing HYPE variable attribute information to return/search: &quot;ID&quot;, &quot;Name&quot;, &quot;Unit&quot;, &quot;Description&quot;, &quot;Aggregation&quot;, and/or &quot;Component&quot;.</p>
</td></tr>
<tr><td><code id="VariableLookup_+3A_search">search</code></td>
<td>
<p>String, search HYPE variable info for string matches in <code>info</code> attributes.</p>
</td></tr>
<tr><td><code id="VariableLookup_+3A_ignore_case">ignore_case</code></td>
<td>
<p>Logical, should case differences be ignored in the match?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>VariableInfo</code> and <code>VariableSearch</code> functions provide features to lookup information on HYPE variables from the
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:info.txt:variables">HYPE Wiki</a>.
<code>VariableInfo</code> can be used to return information (e.g. Name, Units) for a known HYPE Variable ID.
<code>VariableSearch</code> can be used to search for e.g. an unknown HYPE variable ID based on a <code>search</code> term.
The <code>info</code> argument can be used to select which information to return or search.
</p>


<h3>Value</h3>

<p><code>VariableInfo</code> Returns a named list of the selected <code>info</code> for the specified <code>variable</code> ID.
<code>VariableInfo</code> returns a tibble of the search results.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>VariableInfo(variable = "COUT", info = c("Name","Unit"))
VariableSearch(search = "ccSS", info = c("ID", "Name", "Description"))

</code></pre>

<hr>
<h2 id='VisualizeMapOutput'>Shiny App for visualizing HYPE MapOutputs.</h2><span id='topic+VisualizeMapOutput'></span><span id='topic+VisualiseMapOutput'></span>

<h3>Description</h3>

<p>Interactive maps and plots for visualizing MapOutput files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VisualizeMapOutput(
  results.dir = NULL,
  file.pattern = "^map.*\\.(txt|csv)$",
  map = NULL,
  map.subid.column = 1,
  output.dir = NULL
)

VisualiseMapOutput(
  results.dir = NULL,
  file.pattern = "^map.*\\.(txt|csv)$",
  map = NULL,
  map.subid.column = 1,
  output.dir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VisualizeMapOutput_+3A_results.dir">results.dir</code></td>
<td>
<p>Optional string, path to a directory containing MapOutput files that should be loaded on app initialization.</p>
</td></tr>
<tr><td><code id="VisualizeMapOutput_+3A_file.pattern">file.pattern</code></td>
<td>
<p>Optional string, filename pattern to select files in <code>results.dir</code> that should be loaded on app initialization. See <code><a href="base.html#topic+list.files">list.files</a></code>.</p>
</td></tr>
<tr><td><code id="VisualizeMapOutput_+3A_map">map</code></td>
<td>
<p>Optional string, path to GIS file for subbasin polygons that should be loaded on app initialization. Typically a GeoPackage (.gpkg) or Shapefile (.shp).</p>
</td></tr>
<tr><td><code id="VisualizeMapOutput_+3A_map.subid.column">map.subid.column</code></td>
<td>
<p>Optional integer, column index in the <code>map</code> 'data' <code><a href="methods.html#topic+slot">slot</a></code> holding SUBIDs (sub-catchment IDs) that should be used on app initialization.</p>
</td></tr>
<tr><td><code id="VisualizeMapOutput_+3A_output.dir">output.dir</code></td>
<td>
<p>Optional string, path to a default output directory to save captured map images.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>VisualizeMapOutput</code> is a Shiny app that provides interactive maps, plots, and tables for visualizing HYPE MapOutput files. The interactive Leaflet map is generated using <code><a href="#topic+PlotMapOutput">PlotMapOutput</a></code>.
The app can be launched with or without the input arguments. All necessary input buttons and menus are provided within the app interface. For convenience, however, the input arguments can be provided in order to quickly launch the
app with desired settings.
</p>


<h3>Value</h3>

<p><code>VisualizeMapOutput</code> returns a Shiny application object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadMapOutput">ReadMapOutput</a></code>; <code><a href="#topic+PlotMapOutput">PlotMapOutput</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
if (interactive()) {
  VisualizeMapOutput(
    results.dir = system.file("demo_model", "results", package = "HYPEtools"),
    map = system.file("demo_model", "gis", "Nytorp_map.gpkg", package = "HYPEtools"),
    map.subid.column = 25
  )
}

## End(Not run)

</code></pre>

<hr>
<h2 id='VisualizeMapPoints'>Shiny App for visualizing Mapped Point Information.</h2><span id='topic+VisualizeMapPoints'></span><span id='topic+VisualiseMapPoints'></span>

<h3>Description</h3>

<p>Interactive maps and plots for visualizing mapped point information, e.g. HYPE MapOutput files or model performances at observation sites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>VisualizeMapPoints(
  results.dir = NULL,
  file.pattern = "^(map|subass).*\\.(txt|csv)$",
  sites = NULL,
  sites.subid.column = 1,
  bg = NULL,
  output.dir = NULL
)

VisualiseMapPoints(
  results.dir = NULL,
  file.pattern = "^(map|subass).*\\.(txt|csv)$",
  sites = NULL,
  sites.subid.column = 1,
  bg = NULL,
  output.dir = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="VisualizeMapPoints_+3A_results.dir">results.dir</code></td>
<td>
<p>Optional string, path to a directory containing e.g. MapOutput or Subass files that should be loaded on app initialization.</p>
</td></tr>
<tr><td><code id="VisualizeMapPoints_+3A_file.pattern">file.pattern</code></td>
<td>
<p>Optional string, filename pattern to select files in <code>results.dir</code> that should be loaded on app initialization. See <code><a href="base.html#topic+list.files">list.files</a></code>.</p>
</td></tr>
<tr><td><code id="VisualizeMapPoints_+3A_sites">sites</code></td>
<td>
<p>Optional string, path to GIS file for outlet points that should be loaded on app initialization. Typically a GeoPackage (.gpkg) or Shapefile (.shp).</p>
</td></tr>
<tr><td><code id="VisualizeMapPoints_+3A_sites.subid.column">sites.subid.column</code></td>
<td>
<p>Optional integer, column index in the <code>map</code> 'data' <code><a href="methods.html#topic+slot">slot</a></code> holding SUBIDs (sub-catchment IDs) that should be used on app initialization.</p>
</td></tr>
<tr><td><code id="VisualizeMapPoints_+3A_bg">bg</code></td>
<td>
<p>Optional string, path to GIS file with polygon geometry to plot in the background. Typically an imported sub-basin vector polygon file.</p>
</td></tr>
<tr><td><code id="VisualizeMapPoints_+3A_output.dir">output.dir</code></td>
<td>
<p>Optional string, path to a default output directory to save captured map images.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>VisualizeMapPoints</code> is a Shiny app that provides interactive maps, plots, and tables for visualizing mapped point information. The interactive Leaflet map is generated using <code><a href="#topic+PlotMapPoints">PlotMapPoints</a></code>.
The app can be launched with or without the input arguments. All necessary input buttons and menus are provided within the app interface. For convenience, however, the input arguments can be provided in order to quickly launch the
app with desired settings.
</p>


<h3>Value</h3>

<p><code>VisualizeMapPoints</code> returns a Shiny application object.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadMapOutput">ReadMapOutput</a></code>; <code><a href="#topic+PlotMapPoints">PlotMapPoints</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
if (interactive()) {
  VisualizeMapPoints(
    results.dir = system.file("demo_model", "results", package = "HYPEtools"),
    sites = system.file("demo_model", "gis", "Nytorp_centroids.gpkg", package = "HYPEtools"),
    sites.subid.column = 25,
    bg = system.file("demo_model", "gis", "Nytorp_map.gpkg", package = "HYPEtools")
  )
}

## End(Not run)

</code></pre>

<hr>
<h2 id='WriteBasinOutput'>Write a basin output '[SUBID].txt' file</h2><span id='topic+WriteBasinOutput'></span>

<h3>Description</h3>

<p>Function to export a basin output file from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteBasinOutput(x, filename, dt.format = "%Y-%m-%d")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteBasinOutput_+3A_x">x</code></td>
<td>
<p>The object to be written, a dataframe with <code>hypeunit</code> attribute, as an object returned from <code><a href="#topic+ReadBasinOutput">ReadBasinOutput</a></code>.</p>
</td></tr>
<tr><td><code id="WriteBasinOutput_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteBasinOutput_+3A_dt.format">dt.format</code></td>
<td>
<p>Date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>. Incomplete format strings for monthly
and annual values allowed, e.g. '\%Y'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteBasinOutput</code> exports a dataframe with headers and formatting options adjusted to match HYPE's basin output files.
</p>


<h3>Value</h3>

<p>No return value, called for file export.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadBasinOutput(filename = system.file("demo_model", "results", "0003587.txt", 
                      package = "HYPEtools"))
WriteBasinOutput(x = te, filename = tempfile())

</code></pre>

<hr>
<h2 id='WriteGeoClass'>Write a 'GeoClass.txt' file</h2><span id='topic+WriteGeoClass'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to export a 'GeoClass.txt' file from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteGeoClass(x, filename, use.comment = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteGeoClass_+3A_x">x</code></td>
<td>
<p>The object to be written, a dataframe, as an object returned from <code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code>.</p>
</td></tr>
<tr><td><code id="WriteGeoClass_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteGeoClass_+3A_use.comment">use.comment</code></td>
<td>
<p>Logical, set to <code>TRUE</code> to export comment lines saved in <code>attribute</code> 'comment'. Per
default, column names are exported as header. See details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteGeoClass</code> exports a GeoClass dataframe. HYPE accepts comment rows with a leading '!' in the beginning rows of a
GeoClass file. Comment rows typically contain some class descriptions in a non-structured way. With argument
<code>use.comment = TRUE</code>, the export function looks for those in <code>attribute</code> 'comment',
where <code><a href="#topic+ReadGeoClass">ReadGeoClass</a></code> stores such comments. Description files (see <code><a href="#topic+ReadDescription">ReadDescription</a></code>) offer a more structured
way of storing that information.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoClass(filename = system.file("demo_model", "GeoClass.txt", package = "HYPEtools"))
WriteGeoClass(x = te, filename = tempfile())

</code></pre>

<hr>
<h2 id='WriteGeoData'>Write a 'GeoData.txt' file</h2><span id='topic+WriteGeoData'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to export a 'GeoData.txt' file from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteGeoData(x, filename, digits = 6)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteGeoData_+3A_x">x</code></td>
<td>
<p>The object to be written, a dataframe, as an object returned from <code><a href="#topic+ReadGeoData">ReadGeoData</a></code>.
<code>NA</code>s in any column will result in a warning (no <code>NA</code>s allowed in GeoData data columns).</p>
</td></tr>
<tr><td><code id="WriteGeoData_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteGeoData_+3A_digits">digits</code></td>
<td>
<p>Integer, number of significant digits <strong>in SLC class columns</strong> to export. See <code><a href="base.html#topic+signif">signif</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteGeoData</code> exports a GeoData dataframe using <code><a href="data.table.html#topic+fwrite">fwrite</a></code>. <code>SUBID</code> and <code>MAINDOWN</code>
columns are forced to non-scientific notation by conversion to text strings prior to exporting. For all other numeric columns,
use <code><a href="data.table.html#topic+fwrite">fwrite</a></code> argument <code>scipen</code>.
HYPE does neither allow empty values in any GeoData column nor any string elements with more than 50 characters. The
function will return with warnings if <code>NA</code>s or long strings were exported.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
summary(te)
WriteGeoData(x = te, filename = tempfile())

</code></pre>

<hr>
<h2 id='WriteHarmonizedData'>Write a Harmonized Data File</h2><span id='topic+WriteHarmonizedData'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to export a data frame to the required Harmonized Data File format. See the
<a href="https://git.smhi.se/fouh/hypeobsmetadatatools">HYPEObsMetadataTools documentation</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteHarmonizedData(
  df,
  filename = "",
  replace.accents = FALSE,
  strip.punctuation = FALSE,
  ignore.cols = NULL,
  nThread = getDTthreads()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteHarmonizedData_+3A_df">df</code></td>
<td>
<p>Data frame containing the harmonized data.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedData_+3A_filename">filename</code></td>
<td>
<p>Path to and file name (including &quot;.csv&quot; file extension) of the Harmonized Data CSV file to export. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedData_+3A_replace.accents">replace.accents</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then accented characters (e.g. ä, ö, å) will be replaced with non-accented characters in all strings.
If <code>FALSE</code>, then strings will be left unmodified.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedData_+3A_strip.punctuation">strip.punctuation</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then punctuation characters (e.g. &quot;-&quot;, &quot;.&quot;, &quot;.&quot;) will be removed from all strings.
If <code>FALSE</code>, then strings will be left unmodified.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedData_+3A_ignore.cols">ignore.cols</code></td>
<td>
<p>Vector of columns in <code>df</code> that should be ignored when <code>replace.accents</code> or <code>strip.punctuation</code> are set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedData_+3A_nthread">nThread</code></td>
<td>
<p>Integer, set number of threads to be used when writing file. See <code><a href="data.table.html#topic+getDTthreads">getDTthreads</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteHarmonizedData</code> is a convenience wrapper function of <code><a href="data.table.html#topic+fread">fread</a></code> to export harmonized data in the HYPEObsMetadataTools Harmonized Data Format.
The function checks that all required columns are present, includes options to format strings, and exports data to output CSV files with the correct encoding and formatting.
</p>


<h3>Value</h3>

<p><code>WriteHarmonizedData</code> exports a CSV file if <code>filename</code> is specified. Otherwise, the function outputs a data frame to the console.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  "STATION_ID" = "A1",
  "DATE_START" = "2002-06-18 12:00",
  "DATE_END" = "2002-06-18 12:00",
  "PARAMETER" = "NH4_N",
  "VALUE" = 0.050,
  "UNIT" = "mg/L",
  "QUALITY_CODE" = "AA"
)
WriteHarmonizedData(df)

</code></pre>

<hr>
<h2 id='WriteHarmonizedSpatialDescription'>Write a Harmonized Spatial Description File</h2><span id='topic+WriteHarmonizedSpatialDescription'></span>

<h3>Description</h3>

<p>This is a convenience wrapper function to export a data frame to the required Harmonized Spatial Description File format. See the
<a href="https://git.smhi.se/fouh/hypeobsmetadatatools">HYPEObsMetadataTools documentation</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteHarmonizedSpatialDescription(
  df,
  filename = "",
  replace.accents = FALSE,
  strip.punctuation = FALSE,
  ignore.cols = NULL,
  nThread = getDTthreads()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteHarmonizedSpatialDescription_+3A_df">df</code></td>
<td>
<p>Data frame containing the harmonized spatial description data.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedSpatialDescription_+3A_filename">filename</code></td>
<td>
<p>Path to and file name (including &quot;.csv&quot; file extension) of the Harmonized Spatial Description CSV file to export. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedSpatialDescription_+3A_replace.accents">replace.accents</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then accented characters (e.g. ä, ö, å) will be replaced with non-accented characters in all strings.
If <code>FALSE</code>, then strings will be left unmodified.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedSpatialDescription_+3A_strip.punctuation">strip.punctuation</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then punctuation characters (e.g. &quot;-&quot;, &quot;.&quot;, &quot;.&quot;) will be removed from all strings.
If <code>FALSE</code>, then strings will be left unmodified.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedSpatialDescription_+3A_ignore.cols">ignore.cols</code></td>
<td>
<p>Vector of columns in <code>df</code> that should be ignored when <code>replace.accents</code> or <code>strip.punctuation</code> are set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="WriteHarmonizedSpatialDescription_+3A_nthread">nThread</code></td>
<td>
<p>Integer, set number of threads to be used when writing file. See <code><a href="data.table.html#topic+getDTthreads">getDTthreads</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteHarmonizedSpatialDescription</code> is a convenience wrapper function of <code><a href="data.table.html#topic+fread">fread</a></code> to export harmonized spatial description data in the HYPEObsMetadataTools Harmonized Spatial Description Format.
The function checks that all required columns are present, includes options to format strings, and exports data to output CSV files with the correct encoding and formatting.
</p>


<h3>Value</h3>

<p><code>WriteSpatialDescrption</code> exports a CSV file if <code>filename</code> is specified. Otherwise, the function outputs a data frame to the console.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  "STATION_ID" = "A1",
  "SRC_NAME" = "Example",
  "DOWNLOAD_DATE" = "2022-10-19",
  "SRC_STATNAME" = "Station",
  "SRC_WBNAME" = "River",
  "SRC_UAREA" = NA,
  "SRC_XCOORD" = 28.11831,
  "SRC_YCOORD" = -25.83053,
  "SRC_EPSG" = 4326,
  "ADJ_XCOORD" = 28.11831,
  "ADJ_YCOORD" = -25.83053,
  "ADJ_EPSG" = 4326
)

WriteHarmonizedSpatialDescription(df)

</code></pre>

<hr>
<h2 id='WriteInfo'>Write a 'info.txt' File</h2><span id='topic+WriteInfo'></span>

<h3>Description</h3>

<p><code>WriteInfo</code> writes its required argument <code>x</code> to a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteInfo(x, filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteInfo_+3A_x">x</code></td>
<td>
<p>The object to be written, a list with named vector elements, as an object returned from <code><a href="#topic+ReadInfo">ReadInfo</a></code> using the <code>exact</code> mode.</p>
</td></tr>
<tr><td><code id="WriteInfo_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteInfo</code> writes an 'info.txt' file, typically originating from an imported and modified 'info.txt'.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadInfo">ReadInfo</a></code> with a description of the expected content of <code>x</code>.
<code><a href="#topic+AddInfoLine">AddInfoLine</a></code>
<code><a href="#topic+RemoveInfoLine">RemoveInfoLine</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadInfo(filename = system.file("demo_model",
"info.txt", package = "HYPEtools"), mode = "exact")
WriteInfo(x = te, filename = tempfile())


</code></pre>

<hr>
<h2 id='WriteMapOutput'>Write a 'mapXXXX.txt' file</h2><span id='topic+WriteMapOutput'></span>

<h3>Description</h3>

<p>Function to export a map output file from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteMapOutput(x, filename, dt.format = "%Y-%m-%d")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteMapOutput_+3A_x">x</code></td>
<td>
<p>The object to be written, a dataframe with <code>comment</code>, <code>date</code>, and <code>timestep</code>
attributes, as an object returned from <code><a href="#topic+ReadMapOutput">ReadMapOutput</a></code>.</p>
</td></tr>
<tr><td><code id="WriteMapOutput_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteMapOutput_+3A_dt.format">dt.format</code></td>
<td>
<p>Date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>. Date format for export of column headers.
Incomplete format strings for monthly and annual values allowed, e.g. '\
Use <code>NULL</code> for single-column dataframes, i.e. long-term average map files.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteMapOutput</code> exports a dataframe with headers and formatting options adjusted to match HYPE's map output files.
The function attempts to format date-time information to strings and will return a warning if the attempt fails.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadMapOutput(filename = system.file("demo_model", "results", "mapEVAP.txt", 
                    package = "HYPEtools"), dt.format = NULL)
WriteMapOutput(x = te, filename = tempfile())

</code></pre>

<hr>
<h2 id='WriteObs'>Write 'Pobs.txt', 'Tobs.txt', 'Qobs.txt', and other observation data files</h2><span id='topic+WriteObs'></span><span id='topic+WritePTQobs'></span>

<h3>Description</h3>

<p>Export forcing data and discharge observation files from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteObs(
  x,
  filename,
  dt.format = "%Y-%m-%d",
  round = NULL,
  signif = NULL,
  obsid = NULL,
  append = FALSE
)

WritePTQobs(
  x,
  filename,
  dt.format = "%Y-%m-%d",
  round = NULL,
  signif = NULL,
  obsid = NULL,
  append = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteObs_+3A_x">x</code></td>
<td>
<p>The object to be written, a <code>dataframe</code> containing observation date-times in first and observations in SUBIDs or OBSIDs in
remaining columns. If argument <code>obsid</code> is not provided, <code>x</code> must have an additional attribute <code>obsid</code> containing
observation IDs/SUBIDs in column order.</p>
</td></tr>
<tr><td><code id="WriteObs_+3A_filename">filename</code></td>
<td>
<p>Path to and file name of the file to import. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteObs_+3A_dt.format">dt.format</code></td>
<td>
<p>Date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>.</p>
</td></tr>
<tr><td><code id="WriteObs_+3A_round">round</code>, <code id="WriteObs_+3A_signif">signif</code></td>
<td>
<p>Integer, number of decimal places and number of significant digits to export, respectively. See <code><a href="base.html#topic+round">round</a></code> and <code><a href="base.html#topic+signif">signif</a></code>. Applied in
sequence (<code>round</code> first and <code>signif</code> second). If <code>NULL</code> (default), the data to export is not touched.</p>
</td></tr>
<tr><td><code id="WriteObs_+3A_obsid">obsid</code></td>
<td>
<p>Integer vector containing observation IDs/SUBIDs in same order as columns in <code>x</code>. To be exported as header
in the obs file. Must contain the same number of IDs as observation series in <code>x</code>. If <code>NULL</code>, an attribute <code>obsid</code>
in <code>x</code> is mandatory. An existing <code>obsid</code> argument takes precedence over a <code>obsid</code> attribute.</p>
</td></tr>
<tr><td><code id="WriteObs_+3A_append">append</code></td>
<td>
<p>Logical, if <code>TRUE</code>, then table will be joined to the data in existing file and the output will be sorted by DATE (Rows will be added for any missing dates).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteObs</code> is a convenience wrapper function of <code><a href="data.table.html#topic+fwrite">fwrite</a></code> to export a HYPE-compliant observation file.
Headers are generated from attribute <code>obsid</code> on export (see <code><a href="base.html#topic+attr">attr</a></code> on how to create and access it).
</p>
<p>Observation IDs are SUBIDs or IDs connected to SUBIDs with a
<a href="http://www.smhi.net/hype/wiki/doku.php?id=start:hype_file_reference:forckey.txt">ForcKey.txt file</a>.
</p>
<p>If the first column in <code>x</code> contains dates of class <code>POSIXt</code>, then they will be formatted according to <code>dt.format</code> before writing the output file.
</p>
<p>If <code>round</code> is specified, then <code>WriteObs()</code> will use <code><a href="base.html#topic+round">round</a></code> to round the observation values to a specified number of decimal places.
Alternatively, <code>signif</code> can be used to round the observation values to a specified number of significant digits using <code><a href="base.html#topic+signif">signif</a></code>.
Finally, if both <code>round</code> and <code>signif</code> are specified, then the observation values will be first rounded to the number of decimal places specified
with <code>round</code> and then rounded to the number of significant digits specified with <code>signif</code>.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadObs">ReadObs</a></code>
<code><a href="#topic+WriteXobs">WriteXobs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadObs(filename = system.file("demo_model", "Tobs.txt", package = "HYPEtools"))
WriteObs(x = te, filename = tempfile())

</code></pre>

<hr>
<h2 id='WriteOptpar'>Write an 'optpar.txt' File</h2><span id='topic+WriteOptpar'></span>

<h3>Description</h3>

<p><code>WriteOptpar</code> prints a HYPE parameter optimization list to a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteOptpar(x, filename, digits = 10, nsmall = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteOptpar_+3A_x">x</code></td>
<td>
<p>The object to be written, a list with named elements, as an object returned from <code><a href="#topic+ReadOptpar">ReadOptpar</a></code>.</p>
</td></tr>
<tr><td><code id="WriteOptpar_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteOptpar_+3A_digits">digits</code></td>
<td>
<p>Integer, number of significant digits to export. See <code><a href="base.html#topic+format">format</a></code>.</p>
</td></tr>
<tr><td><code id="WriteOptpar_+3A_nsmall">nsmall</code></td>
<td>
<p>Integer, number of significant decimals to export. See <code><a href="base.html#topic+format">format</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadOptpar">ReadOptpar</a></code> with a description of the expected content of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadOptpar(filename = system.file("demo_model", "optpar.txt", package = "HYPEtools"))
WriteOptpar(x = te, filename = tempfile())

</code></pre>

<hr>
<h2 id='WritePar'>Write a 'par.txt' File</h2><span id='topic+WritePar'></span>

<h3>Description</h3>

<p><code>WritePar</code> prints its required argument <code>x</code> to a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WritePar(x, filename, digits = 10, nsmall = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WritePar_+3A_x">x</code></td>
<td>
<p>The object to be written, a list with named vector elements, as an object returned from <code><a href="#topic+ReadPar">ReadPar</a></code>.</p>
</td></tr>
<tr><td><code id="WritePar_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WritePar_+3A_digits">digits</code></td>
<td>
<p>Integer, number of significant digits to export. See <code><a href="base.html#topic+format">format</a></code>.</p>
</td></tr>
<tr><td><code id="WritePar_+3A_nsmall">nsmall</code></td>
<td>
<p>Integer, number of significant decimals to export. See <code><a href="base.html#topic+format">format</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WritePar</code> writes a 'par.txt' file, typically originating from an imported and modified 'par.txt'.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ReadPar">ReadPar</a></code> with a description of the expected content of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadPar(filename = system.file("demo_model", "par.txt", package = "HYPEtools"))
# Note that par files lose all comment rows on import
WritePar(x = te, filename = tempfile())


</code></pre>

<hr>
<h2 id='WritePmsf'>Write a 'pmsf.txt' file</h2><span id='topic+WritePmsf'></span>

<h3>Description</h3>

<p>This is a small convenience function to export a 'partial model setup file' from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WritePmsf(x, filename)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WritePmsf_+3A_x">x</code></td>
<td>
<p>The object to be written, an <code>integer</code> vector containing SUBIDs.</p>
</td></tr>
<tr><td><code id="WritePmsf_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pmsf files are represented as integer vectors in R. The total number of subcatchments in the file are added as first value on export.
pmsf.txt files need to be ordered as downstream sequence.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AllUpstreamSubids">AllUpstreamSubids</a></code>, which extracts upstream SUBIDs from a GeoData dataframe.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadGeoData(filename = system.file("demo_model", "GeoData.txt", package = "HYPEtools"))
WritePmsf(x = te$SUBID[te$SUBID %in% AllUpstreamSubids(3564, te)], filename = tempfile())

</code></pre>

<hr>
<h2 id='WriteTimeOutput'>Write a 'timeXXXX.txt' file</h2><span id='topic+WriteTimeOutput'></span>

<h3>Description</h3>

<p>Function to export a time output file from R.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteTimeOutput(x, filename, dt.format = "%Y-%m-%d")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteTimeOutput_+3A_x">x</code></td>
<td>
<p>The object to be written, a dataframe with <code>comment</code> and <code>subid</code> attributes, as an object returned from
<code><a href="#topic+ReadTimeOutput">ReadTimeOutput</a></code>.</p>
</td></tr>
<tr><td><code id="WriteTimeOutput_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteTimeOutput_+3A_dt.format">dt.format</code></td>
<td>
<p>Date-time <code>format</code> string as in <code><a href="base.html#topic+strptime">strptime</a></code>. Incomplete format strings for monthly
and annual values allowed, e.g. '\%Y'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteTimeOutput</code> exports a data frame with headers and formatting options adjusted to match HYPE's time output files.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadTimeOutput(filename = system.file("demo_model", "results", "timeCOUT.txt", 
                     package = "HYPEtools"), dt.format = "%Y-%m")
WriteTimeOutput(x = te, filename = tempfile(), dt.format = "%Y-%m")

</code></pre>

<hr>
<h2 id='WriteXobs'>Write an 'Xobs.txt' File</h2><span id='topic+WriteXobs'></span>

<h3>Description</h3>

<p><code>WriteXobs</code> writes or appends an observation data set to an Xobs file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WriteXobs(
  x,
  filename,
  append = FALSE,
  comment = NULL,
  variable = NULL,
  subid = NULL,
  last.date = NULL,
  timestep = "d"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="WriteXobs_+3A_x">x</code></td>
<td>
<p>A data frame, e.g. an object originally imported with <code><a href="#topic+ReadXobs">ReadXobs</a></code>. Date-time information in the first
column and measured values in the remaining columns. Column names are ignored on export, but if attributes <code>comment</code>,
<code>variable</code>, and <code>subid</code> are available, these can be exported as Xobs headers (see also arguments of the same names
below).</p>
</td></tr>
<tr><td><code id="WriteXobs_+3A_filename">filename</code></td>
<td>
<p>A character string naming a file to write to. Windows users: Note that
Paths are separated by '/', not '\'.</p>
</td></tr>
<tr><td><code id="WriteXobs_+3A_append">append</code></td>
<td>
<p>Logical. If <code>TRUE</code>, <code>x</code> will be appended to file <code>filename</code>. File must exist and
have an identical column structure as <code>x</code>. If <code>FALSE</code>, existing file in <code>filename</code> will be overwritten!</p>
</td></tr>
<tr><td><code id="WriteXobs_+3A_comment">comment</code></td>
<td>
<p>A character string to be exported as first row comment in the Xobs file. If provided, it takes precedence over
a <code>comment</code> attribute of <code>x</code>. Comments are only exported if <code>append</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="WriteXobs_+3A_variable">variable</code></td>
<td>
<p>A character vector to be exported as second row in the Xobs file. Must contain the same number of
variables as <code>x</code>. If omitted or <code>NULL</code>, an attribute <code>variable</code> in <code>x</code> is mandatory.
Will take precedence over a <code>variable</code> attribute of <code>x</code>. If <code>append</code> is <code>TRUE</code> the values are
used to test for consistency between export object and the existing file.</p>
</td></tr>
<tr><td><code id="WriteXobs_+3A_subid">subid</code></td>
<td>
<p>Third row in Xobs, containing SUBIDs (integer). Behavior otherwise as argument <code>variable</code>.</p>
</td></tr>
<tr><td><code id="WriteXobs_+3A_last.date">last.date</code></td>
<td>
<p>Optional date-time of last observation in existing Xobs file as text string. Only relevant with <code>append = TRUE</code>.
Formatting depending on time step, e.g. <code>'2000-01-01'</code> (day) or <code>'2000-01-01 00:00'</code> (hour). Will be automatically read
from file per default, but can be provided to reduce execution time when appending to large files.</p>
</td></tr>
<tr><td><code id="WriteXobs_+3A_timestep">timestep</code></td>
<td>
<p>Character string, either &quot;day&quot; or &quot;hour&quot;, giving the time step between observations. Can be
abbreviated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>WriteXobs</code> writes a 'Xobs.txt' file, typically originating from an imported and modified 'Xobs.txt'.
HYPE Xobs files contain a three-row header, with a comment line first, next a line of variables, and then a line of subids.
Objects imported with <code><a href="#topic+ReadXobs">ReadXobs</a></code> include attributes holding this information, and <code>WriteXobs</code> will use this
information. Otherwise, these attributes can be added to objects prior to calling <code>WriteXobs</code>, or passed as function
arguments.
</p>
<p>If argument <code>append</code> is <code>TRUE</code>, the function requires daily or hourly time steps as input.
The date-time column must be of class <code>POSIXct</code>, see <code><a href="base.html#topic+as.POSIXct">as.POSIXct</a></code>. Objects returned from
<code><a href="#topic+ReadXobs">ReadXobs</a></code> per default have the correct class for the date-time column. When appending to existing file, the
function adds new rows with '-9999' values in all data columns to fill any time gaps between existing and new data. If time
periods overlap, the export will stop with an error message. Argument <code>last.date</code> can be provided to speed up appending exports,
but per default, <code>WriteXobs</code> extracts the last observation in the existing file automatically.
</p>


<h3>Value</h3>

<p>No return value, called for export to text files.
</p>


<h3>Note</h3>

<p>Both <code>variable</code> and <code>subid</code> do not include elements for the first column in the Xobs file/object, in accordance
with <code><a href="#topic+ReadXobs">ReadXobs</a></code>. These elements will be added by the function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>te &lt;- ReadXobs(filename = system.file("demo_model", "Xobs.txt", package = "HYPEtools"))
WriteXobs(x = te, filename = tempfile())

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
