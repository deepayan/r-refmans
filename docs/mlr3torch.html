<!DOCTYPE html><html><head><title>Help for package mlr3torch</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlr3torch}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mlr3torch-package'><p>mlr3torch: Deep Learning with 'mlr3'</p></a></li>
<li><a href='#+3D+3D.lazy_tensor'><p>Compare lazy tensors</p></a></li>
<li><a href='#as_data_descriptor'><p>Convert to Data Descriptor</p></a></li>
<li><a href='#as_lazy_tensor'><p>Convert to Lazy Tensor</p></a></li>
<li><a href='#as_torch_callback'><p>Convert to a TorchCallback</p></a></li>
<li><a href='#as_torch_callbacks'><p>Convert to a list of Torch Callbacks</p></a></li>
<li><a href='#as_torch_loss'><p>Convert to TorchLoss</p></a></li>
<li><a href='#as_torch_optimizer'><p>Convert to TorchOptimizer</p></a></li>
<li><a href='#assert_lazy_tensor'><p>Assert Lazy Tensor</p></a></li>
<li><a href='#auto_device'><p>Auto Device</p></a></li>
<li><a href='#batchgetter_categ'><p>Batchgetter for Categorical data</p></a></li>
<li><a href='#batchgetter_num'><p>Batchgetter for Numeric Data</p></a></li>
<li><a href='#callback_set'><p>Create a Set of Callbacks for Torch</p></a></li>
<li><a href='#DataDescriptor'><p>Data Descriptor</p></a></li>
<li><a href='#is_lazy_tensor'><p>Check for lazy tensor</p></a></li>
<li><a href='#lazy_tensor'><p>Create a lazy tensor</p></a></li>
<li><a href='#materialize'><p>Materialize Lazy Tensor Columns</p></a></li>
<li><a href='#materialize_internal'><p>Materialize a Lazy Tensor</p></a></li>
<li><a href='#mlr_backends_lazy'><p>Lazy Data Backend</p></a></li>
<li><a href='#mlr_callback_set'><p>Base Class for Callbacks</p></a></li>
<li><a href='#mlr_callback_set.checkpoint'><p>Checkpoint Callback</p></a></li>
<li><a href='#mlr_callback_set.history'><p>History Callback</p></a></li>
<li><a href='#mlr_callback_set.progress'><p>Progress Callback</p></a></li>
<li><a href='#mlr_context_torch'><p>Context for Torch Learner</p></a></li>
<li><a href='#mlr_learners_torch'><p>Base Class for Torch Learners</p></a></li>
<li><a href='#mlr_learners_torch_image'><p>Image Learner</p></a></li>
<li><a href='#mlr_learners_torch_model'><p>Learner Torch Model</p></a></li>
<li><a href='#mlr_learners.mlp'><p>My Little Pony</p></a></li>
<li><a href='#mlr_learners.tab_resnet'><p>Tabular ResNet</p></a></li>
<li><a href='#mlr_learners.torch_featureless'><p>Featureless Torch Learner</p></a></li>
<li><a href='#mlr_learners.torchvision'><p>AlexNet Image Classifier</p></a></li>
<li><a href='#mlr_pipeops_module'><p>Class for Torch Module Wrappers</p></a></li>
<li><a href='#mlr_pipeops_nn_avg_pool1d'><p>1D Average Pooling</p></a></li>
<li><a href='#mlr_pipeops_nn_avg_pool2d'><p>2D Average Pooling</p></a></li>
<li><a href='#mlr_pipeops_nn_avg_pool3d'><p>3D Average Pooling</p></a></li>
<li><a href='#mlr_pipeops_nn_batch_norm1d'><p>1D Batch Normalization</p></a></li>
<li><a href='#mlr_pipeops_nn_batch_norm2d'><p>2D Batch Normalization</p></a></li>
<li><a href='#mlr_pipeops_nn_batch_norm3d'><p>3D Batch Normalization</p></a></li>
<li><a href='#mlr_pipeops_nn_block'><p>Block Repetition</p></a></li>
<li><a href='#mlr_pipeops_nn_celu'><p>CELU Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_conv_transpose1d'><p>Transpose 1D Convolution</p></a></li>
<li><a href='#mlr_pipeops_nn_conv_transpose2d'><p>Transpose 2D Convolution</p></a></li>
<li><a href='#mlr_pipeops_nn_conv_transpose3d'><p>Transpose 3D Convolution</p></a></li>
<li><a href='#mlr_pipeops_nn_conv1d'><p>1D Convolution</p></a></li>
<li><a href='#mlr_pipeops_nn_conv2d'><p>2D Convolution</p></a></li>
<li><a href='#mlr_pipeops_nn_conv3d'><p>3D Convolution</p></a></li>
<li><a href='#mlr_pipeops_nn_dropout'><p>Dropout</p></a></li>
<li><a href='#mlr_pipeops_nn_elu'><p>ELU Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_flatten'><p>Flattens a Tensor</p></a></li>
<li><a href='#mlr_pipeops_nn_gelu'><p>GELU Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_glu'><p>GLU Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_hardshrink'><p>Hard Shrink Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_hardsigmoid'><p>Hard Sigmoid Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_hardtanh'><p>Hard Tanh Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_head'><p>Output Head</p></a></li>
<li><a href='#mlr_pipeops_nn_layer_norm'><p>Layer Normalization</p></a></li>
<li><a href='#mlr_pipeops_nn_leaky_relu'><p>Leaky ReLU Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_linear'><p>Linear Layer</p></a></li>
<li><a href='#mlr_pipeops_nn_log_sigmoid'><p>Log Sigmoid Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_max_pool1d'><p>1D Max Pooling</p></a></li>
<li><a href='#mlr_pipeops_nn_max_pool2d'><p>2D Max Pooling</p></a></li>
<li><a href='#mlr_pipeops_nn_max_pool3d'><p>3D Max Pooling</p></a></li>
<li><a href='#mlr_pipeops_nn_merge'><p>Merge Operation</p></a></li>
<li><a href='#mlr_pipeops_nn_merge_cat'><p>Merge by Concatenation</p></a></li>
<li><a href='#mlr_pipeops_nn_merge_prod'><p>Merge by Product</p></a></li>
<li><a href='#mlr_pipeops_nn_merge_sum'><p>Merge by Summation</p></a></li>
<li><a href='#mlr_pipeops_nn_prelu'><p>PReLU Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_relu'><p>ReLU Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_relu6'><p>ReLU6 Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_reshape'><p>Reshape a Tensor</p></a></li>
<li><a href='#mlr_pipeops_nn_rrelu'><p>RReLU Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_selu'><p>SELU Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_sigmoid'><p>Sigmoid Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_softmax'><p>Softmax</p></a></li>
<li><a href='#mlr_pipeops_nn_softplus'><p>SoftPlus Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_softshrink'><p>Soft Shrink Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_softsign'><p>SoftSign Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_squeeze'><p>Squeeze a Tensor</p></a></li>
<li><a href='#mlr_pipeops_nn_tanh'><p>Tanh Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_tanhshrink'><p>Tanh Shrink Activation Function</p></a></li>
<li><a href='#mlr_pipeops_nn_threshold'><p>Treshold Activation Function</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch'><p>Base Class for Lazy Tensor Preprocessing</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_center_crop'><p>PipeOpPreprocTorchAugmentCenterCrop</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_color_jitter'><p>PipeOpPreprocTorchAugmentColorJitter</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_crop'><p>PipeOpPreprocTorchAugmentCrop</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_hflip'><p>PipeOpPreprocTorchAugmentHflip</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_random_affine'><p>PipeOpPreprocTorchAugmentRandomAffine</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_random_choice'><p>PipeOpPreprocTorchAugmentRandomChoice</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_random_crop'><p>PipeOpPreprocTorchAugmentRandomCrop</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_random_horizontal_flip'><p>PipeOpPreprocTorchAugmentRandomHorizontalFlip</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_random_order'><p>PipeOpPreprocTorchAugmentRandomOrder</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_random_resized_crop'><p>PipeOpPreprocTorchAugmentRandomResizedCrop</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_random_vertical_flip'><p>PipeOpPreprocTorchAugmentRandomVerticalFlip</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_resized_crop'><p>PipeOpPreprocTorchAugmentResizedCrop</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_rotate'><p>PipeOpPreprocTorchAugmentRotate</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.augment_vflip'><p>PipeOpPreprocTorchAugmentVflip</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_adjust_brightness'><p>PipeOpPreprocTorchTrafoAdjustBrightness</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_adjust_gamma'><p>PipeOpPreprocTorchTrafoAdjustGamma</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_adjust_hue'><p>PipeOpPreprocTorchTrafoAdjustHue</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_adjust_saturation'><p>PipeOpPreprocTorchTrafoAdjustSaturation</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_grayscale'><p>PipeOpPreprocTorchTrafoGrayscale</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_nop'><p>PipeOpPreprocTorchTrafoNop</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_normalize'><p>PipeOpPreprocTorchTrafoNormalize</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_pad'><p>PipeOpPreprocTorchTrafoPad</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_reshape'><p>PipeOpPreprocTorchTrafoReshape</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_resize'><p>PipeOpPreprocTorchTrafoResize</p></a></li>
<li><a href='#mlr_pipeops_preproc_torch.trafo_rgb_to_grayscale'><p>PipeOpPreprocTorchTrafoRgbToGrayscale</p></a></li>
<li><a href='#mlr_pipeops_torch'><p>Base Class for Torch Module Constructor Wrappers</p></a></li>
<li><a href='#mlr_pipeops_torch_callbacks'><p>Callback Configuration</p></a></li>
<li><a href='#mlr_pipeops_torch_ingress'><p>Entrypoint to Torch Network</p></a></li>
<li><a href='#mlr_pipeops_torch_ingress_categ'><p>Torch Entry Point for Categorical Features</p></a></li>
<li><a href='#mlr_pipeops_torch_ingress_ltnsr'><p>Ingress for Lazy Tensor</p></a></li>
<li><a href='#mlr_pipeops_torch_ingress_num'><p>Torch Entry Point for Numeric Features</p></a></li>
<li><a href='#mlr_pipeops_torch_loss'><p>Loss Configuration</p></a></li>
<li><a href='#mlr_pipeops_torch_model'><p>PipeOp Torch Model</p></a></li>
<li><a href='#mlr_pipeops_torch_model_classif'><p>PipeOp Torch Classifier</p></a></li>
<li><a href='#mlr_pipeops_torch_model_regr'><p>Torch Regression Model</p></a></li>
<li><a href='#mlr_pipeops_torch_optimizer'><p>Optimizer Configuration</p></a></li>
<li><a href='#mlr_tasks_lazy_iris'><p>Iris Classification Task</p></a></li>
<li><a href='#mlr_tasks_mnist'><p>MNIST Image classification</p></a></li>
<li><a href='#mlr_tasks_tiny_imagenet'><p>Tiny ImageNet Classification Task</p></a></li>
<li><a href='#mlr3torch_callbacks'><p>Dictionary of Torch Callbacks</p></a></li>
<li><a href='#mlr3torch_losses'><p>Loss Functions</p></a></li>
<li><a href='#mlr3torch_optimizers'><p>Optimizers</p></a></li>
<li><a href='#model_descriptor_to_learner'><p>Create a Torch Learner from a ModelDescriptor</p></a></li>
<li><a href='#model_descriptor_to_module'><p>Create a nn_graph from ModelDescriptor</p></a></li>
<li><a href='#model_descriptor_union'><p>Union of ModelDescriptors</p></a></li>
<li><a href='#ModelDescriptor'><p>Represent a Model with Meta-Info</p></a></li>
<li><a href='#nn_graph'><p>Graph Network</p></a></li>
<li><a href='#nn_merge_cat'><p>Concatenates multiple tensors</p></a></li>
<li><a href='#nn_merge_prod'><p>Product of multiple tensors</p></a></li>
<li><a href='#nn_merge_sum'><p>Sum of multiple tensors</p></a></li>
<li><a href='#nn_reshape'><p>Reshape</p></a></li>
<li><a href='#nn_squeeze'><p>Squeeze</p></a></li>
<li><a href='#nn_unsqueeze'><p>Unsqueeze</p></a></li>
<li><a href='#pipeop_preproc_torch'><p>Create Torch Preprocessing PipeOps</p></a></li>
<li><a href='#replace_head'><p>Replace the head of a network</p>
Replaces the head of the network with a linear layer with d_out classes.</a></li>
<li><a href='#t_clbk'><p>Sugar Function for Torch Callback</p></a></li>
<li><a href='#t_loss'><p>Loss Function Quick Access</p></a></li>
<li><a href='#t_opt'><p>Optimizers Quick Access</p></a></li>
<li><a href='#task_dataset'><p>Create a Dataset from a Task</p></a></li>
<li><a href='#torch_callback'><p>Create a Callback Desctiptor</p></a></li>
<li><a href='#TorchCallback'><p>Torch Callback</p></a></li>
<li><a href='#TorchDescriptor'><p>Base Class for Torch Descriptors</p></a></li>
<li><a href='#TorchIngressToken'><p>Torch Ingress Token</p></a></li>
<li><a href='#TorchLoss'><p>Torch Loss</p></a></li>
<li><a href='#TorchOptimizer'><p>Torch Optimizer</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Deep Learning with 'mlr3'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Deep Learning library that extends the mlr3 framework by building
  upon the 'torch' package. It allows to conveniently build, train,
  and evaluate deep learning models without having to worry about low level
  details. Custom architectures can be created using the graph language
  defined in 'mlr3pipelines'.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>mlr3 (&ge; 0.20.0), mlr3pipelines (&ge; 0.6.0), torch (&ge; 0.13.0),
R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>backports, checkmate (&ge; 2.2.0), data.table, lgr, methods,
mlr3misc (&ge; 0.14.0), paradox (&ge; 1.0.0), R6, withr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>callr, future, ggplot2, igraph, jsonlite, knitr, magick,
mlr3tuning (&ge; 1.0.0), progress, rmarkdown, rpart, viridis,
visNetwork, testthat (&ge; 3.0.0), torchvision (&ge; 0.6.0), waldo</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>no</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Collate:</td>
<td>'CallbackSet.R' 'zzz.R' 'TorchCallback.R'
'CallbackSetCheckpoint.R' 'CallbackSetEarlyStopping.R'
'CallbackSetHistory.R' 'CallbackSetProgress.R' 'ContextTorch.R'
'DataBackendLazy.R' 'utils.R' 'DataDescriptor.R'
'LearnerTorch.R' 'LearnerTorchFeatureless.R'
'LearnerTorchImage.R' 'LearnerTorchMLP.R' 'task_dataset.R'
'shape.R' 'PipeOpTorchIngress.R' 'LearnerTorchModel.R'
'LearnerTorchTabResNet.R' 'LearnerTorchVision.R'
'ModelDescriptor.R' 'PipeOpModule.R' 'PipeOpTorch.R'
'PipeOpTaskPreprocTorch.R' 'PipeOpTorchActivation.R'
'PipeOpTorchAvgPool.R' 'PipeOpTorchBatchNorm.R'
'PipeOpTorchBlock.R' 'PipeOpTorchCallbacks.R'
'PipeOpTorchConv.R' 'PipeOpTorchConvTranspose.R'
'PipeOpTorchDropout.R' 'PipeOpTorchHead.R'
'PipeOpTorchLayerNorm.R' 'PipeOpTorchLinear.R' 'TorchLoss.R'
'PipeOpTorchLoss.R' 'PipeOpTorchMaxPool.R' 'PipeOpTorchMerge.R'
'PipeOpTorchModel.R' 'PipeOpTorchOptimizer.R'
'PipeOpTorchReshape.R' 'PipeOpTorchSoftmax.R'
'TaskClassif_lazy_iris.R' 'TaskClassif_mnist.R'
'TaskClassif_tiny_imagenet.R' 'TorchDescriptor.R'
'TorchOptimizer.R' 'bibentries.R' 'cache.R' 'lazy_tensor.R'
'learner_torch_methods.R' 'materialize.R' 'merge_graphs.R'
'nn_graph.R' 'paramset_torchlearner.R' 'preprocess.R'
'rd_info.R' 'with_torch_settings.R'</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-06 07:40:01 UTC; sebi</td>
</tr>
<tr>
<td>Author:</td>
<td>Sebastian Fischer <a href="https://orcid.org/0000-0002-9609-3197"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [cre, aut],
  Bernd Bischl <a href="https://orcid.org/0000-0001-6002-6980"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Lukas Burk <a href="https://orcid.org/0000-0001-7528-3795"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Martin Binder [aut],
  Florian Pfisterer <a href="https://orcid.org/0000-0001-8867-762X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sebastian Fischer &lt;sebf.fischer@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-08 05:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mlr3torch-package'>mlr3torch: Deep Learning with 'mlr3'</h2><span id='topic+mlr3torch'></span><span id='topic+mlr3torch-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Deep Learning library that extends the mlr3 framework by building upon the 'torch' package. It allows to conveniently build, train, and evaluate deep learning models without having to worry about low level details. Custom architectures can be created using the graph language defined in 'mlr3pipelines'.
</p>


<h3>Options</h3>


<ul>
<li> <p><code>mlr3torch.cache</code>:
Whether to cache the downloaded data (<code>TRUE</code>) or not (<code>FALSE</code>, default).
This can also be set to a specific folder on the file system to be used as the cache directory.
</p>
</li></ul>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Sebastian Fischer <a href="mailto:sebf.fischer@gmail.com">sebf.fischer@gmail.com</a> (<a href="https://orcid.org/0000-0002-9609-3197">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Martin Binder <a href="mailto:mlr.developer@mb706.com">mlr.developer@mb706.com</a>
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Bernd Bischl <a href="mailto:bernd_bischl@gmx.net">bernd_bischl@gmx.net</a> (<a href="https://orcid.org/0000-0001-6002-6980">ORCID</a>) [contributor]
</p>
</li>
<li><p> Lukas Burk <a href="mailto:github@quantenbrot.de">github@quantenbrot.de</a> (<a href="https://orcid.org/0000-0001-7528-3795">ORCID</a>) [contributor]
</p>
</li>
<li><p> Florian Pfisterer <a href="mailto:pfistererf@googlemail.com">pfistererf@googlemail.com</a> (<a href="https://orcid.org/0000-0001-8867-762X">ORCID</a>) [contributor]
</p>
</li></ul>


<hr>
<h2 id='+3D+3D.lazy_tensor'>Compare lazy tensors</h2><span id='topic++3D+3D.lazy_tensor'></span>

<h3>Description</h3>

<p>Compares lazy tensors using their indices and the data descriptor's hash.
This means that if two <code><a href="#topic+lazy_tensor">lazy_tensor</a></code>s:
</p>

<ul>
<li><p> are equal: they will mateterialize to the same tensors.
</p>
</li>
<li><p> are unequal: they might materialize to the same tensors.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lazy_tensor'
x == y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B3D+2B3D.lazy_tensor_+3A_x">x</code>, <code id="+2B3D+2B3D.lazy_tensor_+3A_y">y</code></td>
<td>
<p>(<code><a href="#topic+lazy_tensor">lazy_tensor</a></code>)<br />
Values to compare.</p>
</td></tr>
</table>

<hr>
<h2 id='as_data_descriptor'>Convert to Data Descriptor</h2><span id='topic+as_data_descriptor'></span>

<h3>Description</h3>

<p>Converts the input to a <code><a href="#topic+DataDescriptor">DataDescriptor</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_data_descriptor(x, dataset_shapes, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_data_descriptor_+3A_x">x</code></td>
<td>
<p>(any)<br />
Object to convert.</p>
</td></tr>
<tr><td><code id="as_data_descriptor_+3A_dataset_shapes">dataset_shapes</code></td>
<td>
<p>(named <code>list()</code> of (<code>integer()</code> or <code>NULL</code>))<br />
The shapes of the output.
Names are the elements of the list returned by the dataset.
If the shape is not <code>NULL</code> (unknown, e.g. for images of different sizes) the first dimension must be <code>NA</code> to
indicate the batch dimension.</p>
</td></tr>
<tr><td><code id="as_data_descriptor_+3A_...">...</code></td>
<td>
<p>(any)<br />
Further arguments passed to the <code><a href="#topic+DataDescriptor">DataDescriptor</a></code> constructor.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
ds = dataset("example",
  initialize = function() self$iris = iris[, -5],
  .getitem = function(i) list(x = torch_tensor(as.numeric(self$iris[i, ]))),
  .length = function() nrow(self$iris)
)()
as_data_descriptor(ds, list(x = c(NA, 4L)))

# if the dataset has a .getbatch method, the shapes are inferred
ds2 = dataset("example",
  initialize = function() self$iris = iris[, -5],
  .getbatch = function(i) list(x = torch_tensor(as.matrix(self$iris[i, ]))),
  .length = function() nrow(self$iris)
)()
as_data_descriptor(ds2)

</code></pre>

<hr>
<h2 id='as_lazy_tensor'>Convert to Lazy Tensor</h2><span id='topic+as_lazy_tensor'></span><span id='topic+as_lazy_tensor.dataset'></span>

<h3>Description</h3>

<p>Convert a object to a <code><a href="#topic+lazy_tensor">lazy_tensor</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_lazy_tensor(x, ...)

## S3 method for class 'dataset'
as_lazy_tensor(x, dataset_shapes = NULL, ids = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_lazy_tensor_+3A_x">x</code></td>
<td>
<p>(any)<br />
Object to convert to a <code><a href="#topic+lazy_tensor">lazy_tensor</a></code></p>
</td></tr>
<tr><td><code id="as_lazy_tensor_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional arguments passed to the method.</p>
</td></tr>
<tr><td><code id="as_lazy_tensor_+3A_dataset_shapes">dataset_shapes</code></td>
<td>
<p>(named <code>list()</code> of (<code>integer()</code> or <code>NULL</code>))<br />
The shapes of the output.
Names are the elements of the list returned by the dataset.
If the shape is not <code>NULL</code> (unknown, e.g. for images of different sizes) the first dimension must be <code>NA</code> to
indicate the batch dimension.</p>
</td></tr>
<tr><td><code id="as_lazy_tensor_+3A_ids">ids</code></td>
<td>
<p>(<code>integer()</code>)<br />
Which ids to include in the lazy tensor.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
iris_ds = dataset("iris",
  initialize = function() {
    self$iris = iris[, -5]
  },
  .getbatch = function(i) {
    list(x = torch_tensor(as.matrix(self$iris[i, ])))
  },
  .length = function() nrow(self$iris)
)()
# no need to specify the dataset shapes as they can be inferred from the .getbatch method
# only first 5 observations
as_lazy_tensor(iris_ds, ids = 1:5)
# all observations
head(as_lazy_tensor(iris_ds))

iris_ds2 = dataset("iris",
  initialize = function() self$iris = iris[, -5],
  .getitem = function(i) list(x = torch_tensor(as.numeric(self$iris[i, ]))),
  .length = function() nrow(self$iris)
)()
# if .getitem is implemented we cannot infer the shapes as they might vary,
# so we have to annotate them explicitly
as_lazy_tensor(iris_ds2, dataset_shapes = list(x = c(NA, 4L)))[1:5]

# Convert a matrix
lt = as_lazy_tensor(matrix(rnorm(100), nrow = 20))
materialize(lt[1:5], rbind = TRUE)

</code></pre>

<hr>
<h2 id='as_torch_callback'>Convert to a TorchCallback</h2><span id='topic+as_torch_callback'></span>

<h3>Description</h3>

<p>Converts an object to a <code><a href="#topic+TorchCallback">TorchCallback</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_torch_callback(x, clone = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_torch_callback_+3A_x">x</code></td>
<td>
<p>(any)<br />
Object to be converted.</p>
</td></tr>
<tr><td><code id="as_torch_callback_+3A_clone">clone</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to make a deep clone.</p>
</td></tr>
<tr><td><code id="as_torch_callback_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+TorchCallback">TorchCallback</a></code>.
</p>


<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>

<hr>
<h2 id='as_torch_callbacks'>Convert to a list of Torch Callbacks</h2><span id='topic+as_torch_callbacks'></span>

<h3>Description</h3>

<p>Converts an object to a list of <code><a href="#topic+TorchCallback">TorchCallback</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_torch_callbacks(x, clone, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_torch_callbacks_+3A_x">x</code></td>
<td>
<p>(any)<br />
Object to convert.</p>
</td></tr>
<tr><td><code id="as_torch_callbacks_+3A_clone">clone</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to create a deep clone.</p>
</td></tr>
<tr><td><code id="as_torch_callbacks_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s
</p>


<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>
<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>

<hr>
<h2 id='as_torch_loss'>Convert to TorchLoss</h2><span id='topic+as_torch_loss'></span>

<h3>Description</h3>

<p>Converts an object to a <code><a href="#topic+TorchLoss">TorchLoss</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_torch_loss(x, clone = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_torch_loss_+3A_x">x</code></td>
<td>
<p>(any)<br />
Object to convert to a <code><a href="#topic+TorchLoss">TorchLoss</a></code>.</p>
</td></tr>
<tr><td><code id="as_torch_loss_+3A_clone">clone</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to make a deep clone.</p>
</td></tr>
<tr><td><code id="as_torch_loss_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional arguments.
Currently used to pass additional constructor arguments to <code><a href="#topic+TorchLoss">TorchLoss</a></code> for objects of type <code>nn_loss</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+TorchLoss">TorchLoss</a></code>.
</p>


<h3>See Also</h3>

<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>

<hr>
<h2 id='as_torch_optimizer'>Convert to TorchOptimizer</h2><span id='topic+as_torch_optimizer'></span>

<h3>Description</h3>

<p>Converts an object to a <code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_torch_optimizer(x, clone = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_torch_optimizer_+3A_x">x</code></td>
<td>
<p>(any)<br />
Object to convert to a <code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>.</p>
</td></tr>
<tr><td><code id="as_torch_optimizer_+3A_clone">clone</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to make a deep clone. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="as_torch_optimizer_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional arguments.
Currently used to pass additional constructor arguments to <code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code> for objects of type
<code>torch_optimizer_generator</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>
</p>


<h3>See Also</h3>

<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>

<hr>
<h2 id='assert_lazy_tensor'>Assert Lazy Tensor</h2><span id='topic+assert_lazy_tensor'></span>

<h3>Description</h3>

<p>Asserts whether something is a lazy tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assert_lazy_tensor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assert_lazy_tensor_+3A_x">x</code></td>
<td>
<p>(any)<br />
Object to check.</p>
</td></tr>
</table>

<hr>
<h2 id='auto_device'>Auto Device</h2><span id='topic+auto_device'></span>

<h3>Description</h3>

<p>First tries cuda, then cpu.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>auto_device(device = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="auto_device_+3A_device">device</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The device. If not <code>NULL</code>, is returned as is.</p>
</td></tr>
</table>

<hr>
<h2 id='batchgetter_categ'>Batchgetter for Categorical data</h2><span id='topic+batchgetter_categ'></span>

<h3>Description</h3>

<p>Converts a data frame of categorical data into a long tensor by converting the data to integers.
No input checks are performed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>batchgetter_categ(data, device, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="batchgetter_categ_+3A_data">data</code></td>
<td>
<p>(<code>data.table</code>)<br />
<code>data.table</code> to be converted to a <code>tensor</code>.</p>
</td></tr>
<tr><td><code id="batchgetter_categ_+3A_device">device</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The device.</p>
</td></tr>
<tr><td><code id="batchgetter_categ_+3A_...">...</code></td>
<td>
<p>(any)<br />
Unused.</p>
</td></tr>
</table>

<hr>
<h2 id='batchgetter_num'>Batchgetter for Numeric Data</h2><span id='topic+batchgetter_num'></span>

<h3>Description</h3>

<p>Converts a data frame of numeric data into a float tensor by calling <code>as.matrix()</code>.
No input checks are performed
</p>


<h3>Usage</h3>

<pre><code class='language-R'>batchgetter_num(data, device, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="batchgetter_num_+3A_data">data</code></td>
<td>
<p>(<code>data.table()</code>)<br />
<code>data.table</code> to be converted to a <code>tensor</code>.</p>
</td></tr>
<tr><td><code id="batchgetter_num_+3A_device">device</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The device on which the tensor should be created.</p>
</td></tr>
<tr><td><code id="batchgetter_num_+3A_...">...</code></td>
<td>
<p>(any)<br />
Unused.</p>
</td></tr>
</table>

<hr>
<h2 id='callback_set'>Create a Set of Callbacks for Torch</h2><span id='topic+callback_set'></span>

<h3>Description</h3>

<p>Creates an <code>R6ClassGenerator</code> inheriting from <code><a href="#topic+CallbackSet">CallbackSet</a></code>.
Additionally performs checks such as that the stages are not accidentally misspelled.
To create a <code><a href="#topic+TorchCallback">TorchCallback</a></code> use <code><a href="#topic+torch_callback">torch_callback()</a></code>.
</p>
<p>In order for the resulting class to be cloneable, the private method <code style="white-space: pre;">&#8288;$deep_clone()&#8288;</code> must be
provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>callback_set(
  classname,
  on_begin = NULL,
  on_end = NULL,
  on_exit = NULL,
  on_epoch_begin = NULL,
  on_before_valid = NULL,
  on_epoch_end = NULL,
  on_batch_begin = NULL,
  on_batch_end = NULL,
  on_after_backward = NULL,
  on_batch_valid_begin = NULL,
  on_batch_valid_end = NULL,
  on_valid_end = NULL,
  state_dict = NULL,
  load_state_dict = NULL,
  initialize = NULL,
  public = NULL,
  private = NULL,
  active = NULL,
  parent_env = parent.frame(),
  inherit = CallbackSet,
  lock_objects = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="callback_set_+3A_classname">classname</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The class name.</p>
</td></tr>
<tr><td><code id="callback_set_+3A_on_begin">on_begin</code>, <code id="callback_set_+3A_on_end">on_end</code>, <code id="callback_set_+3A_on_epoch_begin">on_epoch_begin</code>, <code id="callback_set_+3A_on_before_valid">on_before_valid</code>, <code id="callback_set_+3A_on_epoch_end">on_epoch_end</code>, <code id="callback_set_+3A_on_batch_begin">on_batch_begin</code>, <code id="callback_set_+3A_on_batch_end">on_batch_end</code>, <code id="callback_set_+3A_on_after_backward">on_after_backward</code>, <code id="callback_set_+3A_on_batch_valid_begin">on_batch_valid_begin</code>, <code id="callback_set_+3A_on_batch_valid_end">on_batch_valid_end</code>, <code id="callback_set_+3A_on_valid_end">on_valid_end</code>, <code id="callback_set_+3A_on_exit">on_exit</code></td>
<td>
<p>(<code>function</code>)<br />
Function to execute at the given stage, see section <em>Stages</em>.</p>
</td></tr>
<tr><td><code id="callback_set_+3A_state_dict">state_dict</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function()&#8288;</code>)<br />
The function that retrieves the state dict from the callback.
This is what will be available in the learner after training.</p>
</td></tr>
<tr><td><code id="callback_set_+3A_load_state_dict">load_state_dict</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(state_dict)&#8288;</code>)<br />
Function that loads a callback state.</p>
</td></tr>
<tr><td><code id="callback_set_+3A_initialize">initialize</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function()&#8288;</code>)<br />
The initialization method of the callback.</p>
</td></tr>
<tr><td><code id="callback_set_+3A_public">public</code>, <code id="callback_set_+3A_private">private</code>, <code id="callback_set_+3A_active">active</code></td>
<td>
<p>(<code>list()</code>)<br />
Additional public, private, and active fields to add to the callback.</p>
</td></tr>
<tr><td><code id="callback_set_+3A_parent_env">parent_env</code></td>
<td>
<p>(<code>environment()</code>)<br />
The parent environment for the <code><a href="R6.html#topic+R6Class">R6Class</a></code>.</p>
</td></tr>
<tr><td><code id="callback_set_+3A_inherit">inherit</code></td>
<td>
<p>(<code>R6ClassGenerator</code>)<br />
From which class to inherit.
This class must either be <code><a href="#topic+CallbackSet">CallbackSet</a></code> (default) or inherit from it.</p>
</td></tr>
<tr><td><code id="callback_set_+3A_lock_objects">lock_objects</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to lock the objects of the resulting <code><a href="R6.html#topic+R6Class">R6Class</a></code>.
If <code>FALSE</code> (default), values can be freely assigned to <code>self</code> without declaring them in the
class definition.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+CallbackSet">CallbackSet</a></code>
</p>


<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>

<hr>
<h2 id='DataDescriptor'>Data Descriptor</h2><span id='topic+DataDescriptor'></span>

<h3>Description</h3>

<p>A data descriptor is a rather internal data structure used in the <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> data type.
In essence it is an annotated <code><a href="torch.html#topic+dataset">torch::dataset</a></code> and a preprocessing graph (consisting mosty of <code><a href="#topic+PipeOpModule">PipeOpModule</a></code>
operators). The additional meta data (e.g. pointer, shapes) allows to preprocess <code><a href="#topic+lazy_tensor">lazy_tensor</a></code>s in an
<code><a href="mlr3pipelines.html#topic+Graph">mlr3pipelines::Graph</a></code> just like any (non-lazy) data types.
The preprocessing is applied when <code><a href="#topic+materialize">materialize()</a></code> is called on the <code><a href="#topic+lazy_tensor">lazy_tensor</a></code>.
</p>
<p>To create a data descriptor, you can also use the <code><a href="#topic+as_data_descriptor">as_data_descriptor()</a></code> function.
</p>


<h3>Details</h3>

<p>While it would be more natural to define this as an S3 class, we opted for an R6 class to avoid the usual
trouble of serializing S3 objects.
If each row contained a DataDescriptor as an S3 class, this would copy the object when serializing.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>dataset</code></dt><dd><p>(<code><a href="torch.html#topic+dataset">torch::dataset</a></code>)<br />
The dataset.</p>
</dd>
<dt><code>graph</code></dt><dd><p>(<code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code>)<br />
The preprocessing graph.</p>
</dd>
<dt><code>dataset_shapes</code></dt><dd><p>(named <code>list()</code> of (<code>integer()</code> or <code>NULL</code>))<br />
The shapes of the output.</p>
</dd>
<dt><code>input_map</code></dt><dd><p>(<code>character()</code>)<br />
The input map from the dataset to the preprocessing graph.</p>
</dd>
<dt><code>pointer</code></dt><dd><p>(<code>character(2)</code>)<br />
The output pointer.</p>
</dd>
<dt><code>pointer_shape</code></dt><dd><p>(<code>integer()</code> | <code>NULL</code>)<br />
The shape of the output indicated by <code>pointer</code>.</p>
</dd>
<dt><code>dataset_hash</code></dt><dd><p>(<code>character(1)</code>)<br />
Hash for the wrapped dataset.</p>
</dd>
<dt><code>hash</code></dt><dd><p>(<code>character(1)</code>)<br />
Hash for the data descriptor.</p>
</dd>
<dt><code>graph_input</code></dt><dd><p>(<code>character()</code>)<br />
The input channels of the preprocessing graph (cached to save time).</p>
</dd>
<dt><code>pointer_shape_predict</code></dt><dd><p>(<code>integer()</code> or <code>NULL</code>)<br />
Internal use only.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DataDescriptor-new"><code>DataDescriptor$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DataDescriptor-print"><code>DataDescriptor$print()</code></a>
</p>
</li>
<li> <p><a href="#method-DataDescriptor-clone"><code>DataDescriptor$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-DataDescriptor-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>DataDescriptor$new(
  dataset,
  dataset_shapes = NULL,
  graph = NULL,
  input_map = NULL,
  pointer = NULL,
  pointer_shape = NULL,
  pointer_shape_predict = NULL,
  clone_graph = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>dataset</code></dt><dd><p>(<code><a href="torch.html#topic+dataset">torch::dataset</a></code>)<br />
The torch dataset.
It should return a named <code>list()</code> of <code><a href="torch.html#topic+torch_tensor">torch_tensor</a></code> objects.</p>
</dd>
<dt><code>dataset_shapes</code></dt><dd><p>(named <code>list()</code> of (<code>integer()</code> or <code>NULL</code>))<br />
The shapes of the output.
Names are the elements of the list returned by the dataset.
If the shape is not <code>NULL</code> (unknown, e.g. for images of different sizes) the first dimension must be <code>NA</code> to
indicate the batch dimension.</p>
</dd>
<dt><code>graph</code></dt><dd><p>(<code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code>)<br />
The preprocessing graph.
If left <code>NULL</code>, no preprocessing is applied to the data and <code>input_map</code>, <code>pointer</code>, <code>pointer_shape</code>, and
<code>pointer_shape_predict</code> are inferred in case the dataset returns only one element.</p>
</dd>
<dt><code>input_map</code></dt><dd><p>(<code>character()</code>)<br />
Character vector that must have the same length as the input of the graph.
Specifies how the data from the <code>dataset</code> is fed into the preprocessing graph.</p>
</dd>
<dt><code>pointer</code></dt><dd><p>(<code>character(2)</code> | <code>NULL</code>)<br />
Points to an output channel within <code>graph</code>:
Element 1 is the <code>PipeOp</code>'s id and element 2 is that <code>PipeOp</code>'s output channel.</p>
</dd>
<dt><code>pointer_shape</code></dt><dd><p>(<code>integer()</code> | <code>NULL</code>)<br />
Shape of the output indicated by <code>pointer</code>.</p>
</dd>
<dt><code>pointer_shape_predict</code></dt><dd><p>(<code>integer()</code> or <code>NULL</code>)<br />
Internal use only.
Used in a <code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code> to anticipate possible mismatches between train and predict shapes.</p>
</dd>
<dt><code>clone_graph</code></dt><dd><p>(<code>logical(1)</code>)<br />
Whether to clone the preprocessing graph.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DataDescriptor-print"></a>



<h4>Method <code>print()</code></h4>

<p>Prints the object
</p>


<h5>Usage</h5>

<div class="r"><pre>DataDescriptor$print(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>(any)<br />
Unused</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DataDescriptor-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>DataDescriptor$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>ModelDescriptor, lazy_tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create a dataset
ds = dataset(
  initialize = function() self$x = torch_randn(10, 3, 3),
  .getitem = function(i) list(x = self$x[i, ]),
  .length = function() nrow(self$x)
)()
dd = DataDescriptor$new(ds, list(x = c(NA, 3, 3)))
dd
# is the same as using the converter:
as_data_descriptor(ds, list(x = c(NA, 3, 3)))

</code></pre>

<hr>
<h2 id='is_lazy_tensor'>Check for lazy tensor</h2><span id='topic+is_lazy_tensor'></span>

<h3>Description</h3>

<p>Checks whether an object is a lazy tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_lazy_tensor(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_lazy_tensor_+3A_x">x</code></td>
<td>
<p>(any)<br />
Object to check.</p>
</td></tr>
</table>

<hr>
<h2 id='lazy_tensor'>Create a lazy tensor</h2><span id='topic+lazy_tensor'></span>

<h3>Description</h3>

<p>Create a lazy tensor.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lazy_tensor(data_descriptor = NULL, ids = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lazy_tensor_+3A_data_descriptor">data_descriptor</code></td>
<td>
<p>(<code><a href="#topic+DataDescriptor">DataDescriptor</a></code> or <code>NULL</code>)<br />
The data descriptor or <code>NULL</code> for a lazy tensor of length 0.</p>
</td></tr>
<tr><td><code id="lazy_tensor_+3A_ids">ids</code></td>
<td>
<p>(<code>integer()</code>)<br />
The elements of the <code>data_descriptor</code> to be included in the lazy tensor.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
ds = dataset("example",
  initialize = function() self$iris = iris[, -5],
  .getitem = function(i) list(x = torch_tensor(as.numeric(self$iris[i, ]))),
  .length = function() nrow(self$iris)
)()
dd = as_data_descriptor(ds, list(x = c(NA, 4L)))
lt = as_lazy_tensor(dd)

</code></pre>

<hr>
<h2 id='materialize'>Materialize Lazy Tensor Columns</h2><span id='topic+materialize'></span><span id='topic+materialize.list'></span>

<h3>Description</h3>

<p>This will materialize a <code><a href="#topic+lazy_tensor">lazy_tensor()</a></code> or a <code>data.frame()</code> / <code>list()</code> containing &ndash; among other things &ndash;
<code><a href="#topic+lazy_tensor">lazy_tensor()</a></code> columns.
I.e. the data described in the underlying <code><a href="#topic+DataDescriptor">DataDescriptor</a></code>s is loaded for the indices in the <code><a href="#topic+lazy_tensor">lazy_tensor()</a></code>,
is preprocessed and then put unto the specified device.
Because not all elements in a lazy tensor must have the same shape, a list of tensors is returned by default.
If all elements have the same shape, these tensors can also be rbinded into a single tensor (parameter <code>rbind</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>materialize(x, device = "cpu", rbind = FALSE, ...)

## S3 method for class 'list'
materialize(x, device = "cpu", rbind = FALSE, cache = "auto", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="materialize_+3A_x">x</code></td>
<td>
<p>(any)<br />
The object to materialize.
Either a <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> or a <code>list()</code> / <code>data.frame()</code> containing <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> columns.</p>
</td></tr>
<tr><td><code id="materialize_+3A_device">device</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The torch device.</p>
</td></tr>
<tr><td><code id="materialize_+3A_rbind">rbind</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to rbind the lazy tensor columns (<code>TRUE</code>) or return them as a list of tensors (<code>FALSE</code>).
In the second case, there is no batch dimension.</p>
</td></tr>
<tr><td><code id="materialize_+3A_...">...</code></td>
<td>
<p>(any)<br />
Additional arguments.</p>
</td></tr>
<tr><td><code id="materialize_+3A_cache">cache</code></td>
<td>
<p>(<code>character(1)</code> or <code>environment()</code> or <code>NULL</code>)<br />
Optional cache for (intermediate) materialization results.
Per default, caching will be enabled when the same dataset or data descriptor (with different output pointer)
is used for more than one lazy tensor column.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Materializing a lazy tensor consists of:
</p>

<ol>
<li><p> Loading the data from the internal dataset of the <code><a href="#topic+DataDescriptor">DataDescriptor</a></code>.
</p>
</li>
<li><p> Processing these batches in the preprocessing <code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code>s.
</p>
</li>
<li><p> Returning the result of the <code><a href="mlr3pipelines.html#topic+PipeOp">PipeOp</a></code> pointed to by the <code><a href="#topic+DataDescriptor">DataDescriptor</a></code> (<code>pointer</code>).
</p>
</li></ol>

<p>With multiple <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> columns we can benefit from caching because:
a) Output(s) from the dataset might be input to multiple graphs.
b) Different lazy tensors might be outputs from the same graph.
</p>
<p>For this reason it is possible to provide a cache environment.
The hash key for a) is the hash of the indices and the dataset.
The hash key for b) is the hash of the indices, dataset and preprocessing graph.
</p>


<h3>Value</h3>

<p>(<code>list()</code> of <code><a href="#topic+lazy_tensor">lazy_tensor</a></code>s or a <code><a href="#topic+lazy_tensor">lazy_tensor</a></code>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
lt1 = as_lazy_tensor(torch_randn(10, 3))
materialize(lt1, rbind = TRUE)
materialize(lt1, rbind = FALSE)
lt2 = as_lazy_tensor(torch_randn(10, 4))
d = data.table::data.table(lt1 = lt1, lt2 = lt2)
materialize(d, rbind = TRUE)
materialize(d, rbind = FALSE)

</code></pre>

<hr>
<h2 id='materialize_internal'>Materialize a Lazy Tensor</h2><span id='topic+materialize_internal'></span>

<h3>Description</h3>

<p>Convert a <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> to a <code><a href="torch.html#topic+torch_tensor">torch_tensor</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>materialize_internal(x, device = "cpu", cache = NULL, rbind)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="materialize_internal_+3A_x">x</code></td>
<td>
<p>(<code><a href="#topic+lazy_tensor">lazy_tensor()</a></code>)<br />
The lazy tensor to materialize.</p>
</td></tr>
<tr><td><code id="materialize_internal_+3A_device">device</code></td>
<td>
<p>(<code>character(1L)</code>)<br />
The device to put the materialized tensor on (after running the preprocessing graph).</p>
</td></tr>
<tr><td><code id="materialize_internal_+3A_cache">cache</code></td>
<td>
<p>(<code>NULL</code> or <code>environment()</code>)<br />
Whether to cache the (intermediate) results of the materialization.
This can make data loading faster when multiple <code>lazy_tensor</code>s reference the same dataset or graph.</p>
</td></tr>
<tr><td><code id="materialize_internal_+3A_rbind">rbind</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whtether to rbind the resulting tensors (<code>TRUE</code>) or return them as a list of tensors (<code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Materializing a lazy tensor consists of:
</p>

<ol>
<li><p> Loading the data from the internal dataset of the <code><a href="#topic+DataDescriptor">DataDescriptor</a></code>.
</p>
</li>
<li><p> Processing these batches in the preprocessing <code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code>s.
</p>
</li>
<li><p> Returning the result of the <code><a href="mlr3pipelines.html#topic+PipeOp">PipeOp</a></code> pointed to by the <code><a href="#topic+DataDescriptor">DataDescriptor</a></code> (<code>pointer</code>).
</p>
</li></ol>

<p>When materializing multiple <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> columns, caching can be useful because:
a) Output(s) from the dataset might be input to multiple graphs.
(in task_dataset this is shoudl rarely be the case because because we try to merge them).
b) Different lazy tensors might be outputs from the same graph.
</p>
<p>For this reason it is possible to provide a cache environment.
The hash key for a) is the hash of the indices and the dataset.
The hash key for b) is the hash of the indices dataset and preprocessing graph.
</p>


<h3>Value</h3>

<p><code><a href="#topic+lazy_tensor">lazy_tensor()</a></code>
</p>

<hr>
<h2 id='mlr_backends_lazy'>Lazy Data Backend</h2><span id='topic+mlr_backends_lazy'></span><span id='topic+DataBackendLazy'></span>

<h3>Description</h3>

<p>This lazy data backend wraps a constructor that lazily creates another backend, e.g. by downloading
(and caching) some data from the internet.
This backend should be used, when some metadata of the backend is known in advance and should be accessible
before downloading the actual data.
When the backend is first constructed, it is verified that the provided metadata was correct, otherwise
an informative error message is thrown.
After the construction of the lazily constructed backend, calls like <code style="white-space: pre;">&#8288;$data()&#8288;</code>, <code style="white-space: pre;">&#8288;$missings()&#8288;</code>, <code style="white-space: pre;">&#8288;$distinct()&#8288;</code>,
or <code style="white-space: pre;">&#8288;$hash()&#8288;</code> are redirected to it.
</p>
<p>Information that is available before the backend is constructed is:
</p>

<ul>
<li> <p><code>nrow</code> - The number of rows (set as the length of the <code>rownames</code>).
</p>
</li>
<li> <p><code>ncol</code> - The number of columns (provided via the <code>id</code> column of <code>col_info</code>).
</p>
</li>
<li> <p><code>colnames</code> - The column names.
</p>
</li>
<li> <p><code>rownames</code> - The row names.
</p>
</li>
<li> <p><code>col_info</code> - The column information, which can be obtained via <code><a href="mlr3.html#topic+col_info">mlr3::col_info()</a></code>.
</p>
</li></ul>

<p>Beware that accessing the backend's hash also contructs the backend.
</p>
<p>Note that while in most cases the data contains <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> columns, this is not necessary and the naming
of this class has nothing to do with the <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> data type.
</p>
<p><strong>Important</strong>
</p>
<p>When the constructor generates <code>factor()</code> variables it is important that the ordering of the levels in data
corresponds to the ordering of the levels in the <code>col_info</code> argument.
</p>


<h3>Super class</h3>

<p><code><a href="mlr3.html#topic+DataBackend">mlr3::DataBackend</a></code> -&gt; <code>DataBackendLazy</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>backend</code></dt><dd><p>(<code>DataBackend</code>)<br />
The wrapped backend that is lazily constructed when first accessed.</p>
</dd>
<dt><code>nrow</code></dt><dd><p>(<code>integer(1)</code>)<br />
Number of rows (observations).</p>
</dd>
<dt><code>ncol</code></dt><dd><p>(<code>integer(1)</code>)<br />
Number of columns (variables), including the primary key column.</p>
</dd>
<dt><code>rownames</code></dt><dd><p>(<code>integer()</code>)<br />
Returns vector of all distinct row identifiers, i.e. the contents of the primary key column.</p>
</dd>
<dt><code>colnames</code></dt><dd><p>(<code>character()</code>)<br />
Returns vector of all column names, including the primary key column.</p>
</dd>
<dt><code>is_constructed</code></dt><dd><p>(<code>logical(1)</code>)<br />
Whether the backend has already been constructed.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DataBackendLazy-new"><code>DataBackendLazy$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DataBackendLazy-data"><code>DataBackendLazy$data()</code></a>
</p>
</li>
<li> <p><a href="#method-DataBackendLazy-head"><code>DataBackendLazy$head()</code></a>
</p>
</li>
<li> <p><a href="#method-DataBackendLazy-distinct"><code>DataBackendLazy$distinct()</code></a>
</p>
</li>
<li> <p><a href="#method-DataBackendLazy-missings"><code>DataBackendLazy$missings()</code></a>
</p>
</li>
<li> <p><a href="#method-DataBackendLazy-print"><code>DataBackendLazy$print()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="DataBackend" data-id="format"><a href='../../mlr3/html/DataBackend.html#method-DataBackend-format'><code>mlr3::DataBackend$format()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-DataBackendLazy-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>DataBackendLazy$new(constructor, rownames, col_info, primary_key, data_formats)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>constructor</code></dt><dd><p>(<code>function</code>)<br />
A function with argument <code>backend</code> (the lazy backend), whose return value must be the actual backend.
This function is called the first time the field <code style="white-space: pre;">&#8288;$backend&#8288;</code> is accessed.</p>
</dd>
<dt><code>rownames</code></dt><dd><p>(<code>integer()</code>)<br />
The row names. Must be a permutation of the rownames of the lazily constructed backend.</p>
</dd>
<dt><code>col_info</code></dt><dd><p>(<code><a href="data.table.html#topic+data.table">data.table::data.table()</a></code>)<br />
A data.table with columns <code>id</code>, <code>type</code> and <code>levels</code> containing the column id, type and levels.
Note that the levels must be provided in the correct order.</p>
</dd>
<dt><code>primary_key</code></dt><dd><p>(<code>character(1)</code>)<br />
Name of the primary key column.</p>
</dd>
<dt><code>data_formats</code></dt><dd><p>(<code>character()</code>)<br />
Set of supported data formats. E.g. <code>"data.table"</code>.
These must be a subset of the data formats of the lazily constructed backend.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DataBackendLazy-data"></a>



<h4>Method <code>data()</code></h4>

<p>Returns a slice of the data in the specified format.
The rows must be addressed as vector of primary key values, columns must be referred to via column names.
Queries for rows with no matching row id and queries for columns with no matching column name are silently ignored.
Rows are guaranteed to be returned in the same order as <code>rows</code>, columns may be returned in an arbitrary order.
Duplicated row ids result in duplicated rows, duplicated column names lead to an exception.
</p>
<p>Accessing the data triggers the construction of the backend.
</p>


<h5>Usage</h5>

<div class="r"><pre>DataBackendLazy$data(rows, cols, data_format = "data.table")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>rows</code></dt><dd><p>(<code>integer()</code>)<br />
Row indices.</p>
</dd>
<dt><code>cols</code></dt><dd><p>(<code>character()</code>)<br />
Column names.</p>
</dd>
<dt><code>data_format</code></dt><dd><p>(<code>character(1)</code>)<br />
Desired data format, e.g. <code>"data.table"</code> or <code>"Matrix"</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DataBackendLazy-head"></a>



<h4>Method <code>head()</code></h4>

<p>Retrieve the first <code>n</code> rows.
This triggers the construction of the backend.
</p>


<h5>Usage</h5>

<div class="r"><pre>DataBackendLazy$head(n = 6L)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>n</code></dt><dd><p>(<code>integer(1)</code>)<br />
Number of rows.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code><a href="data.table.html#topic+data.table">data.table::data.table()</a></code> of the first <code>n</code> rows.
</p>


<hr>
<a id="method-DataBackendLazy-distinct"></a>



<h4>Method <code>distinct()</code></h4>

<p>Returns a named list of vectors of distinct values for each column
specified. If <code>na_rm</code> is <code>TRUE</code>, missing values are removed from the
returned vectors of distinct values. Non-existing rows and columns are
silently ignored.
</p>
<p>This triggers the construction of the backend.
</p>


<h5>Usage</h5>

<div class="r"><pre>DataBackendLazy$distinct(rows, cols, na_rm = TRUE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>rows</code></dt><dd><p>(<code>integer()</code>)<br />
Row indices.</p>
</dd>
<dt><code>cols</code></dt><dd><p>(<code>character()</code>)<br />
Column names.</p>
</dd>
<dt><code>na_rm</code></dt><dd><p>(<code>logical(1)</code>)<br />
Whether to remove NAs or not.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Named <code>list()</code> of distinct values.
</p>


<hr>
<a id="method-DataBackendLazy-missings"></a>



<h4>Method <code>missings()</code></h4>

<p>Returns the number of missing values per column in the specified slice
of data. Non-existing rows and columns are silently ignored.
</p>
<p>This triggers the construction of the backend.
</p>


<h5>Usage</h5>

<div class="r"><pre>DataBackendLazy$missings(rows, cols)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>rows</code></dt><dd><p>(<code>integer()</code>)<br />
Row indices.</p>
</dd>
<dt><code>cols</code></dt><dd><p>(<code>character()</code>)<br />
Column names.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>Total of missing values per column (named <code>numeric()</code>).
</p>


<hr>
<a id="method-DataBackendLazy-print"></a>



<h4>Method <code>print()</code></h4>

<p>Printer.
</p>


<h5>Usage</h5>

<div class="r"><pre>DataBackendLazy$print()</pre></div>




<h3>Examples</h3>

<pre><code class='language-R'>
# We first define a backend constructor
constructor = function(backend) {
  cat("Data is constructed!\n")
  DataBackendDataTable$new(
    data.table(x = rnorm(10), y = rnorm(10), row_id = 1:10),
    primary_key = "row_id"
  )
}

# to wrap this backend constructor in a lazy backend, we need to provide the correct metadata for it
column_info = data.table(
  id = c("x", "y", "row_id"),
  type = c("numeric", "numeric", "integer"),
  levels = list(NULL, NULL, NULL)
)
backend_lazy = DataBackendLazy$new(
  constructor = constructor,
  rownames = 1:10,
  col_info = column_info,
  data_formats = "data.table",
  primary_key = "row_id"
)

# Note that the constructor is not called for the calls below
# as they can be read from the metadata
backend_lazy$nrow
backend_lazy$rownames
backend_lazy$ncol
backend_lazy$colnames
col_info(backend_lazy)

# Only now the backend is constructed
backend_lazy$data(1, "x")
# Is the same as:
backend_lazy$backend$data(1, "x")

</code></pre>

<hr>
<h2 id='mlr_callback_set'>Base Class for Callbacks</h2><span id='topic+mlr_callback_set'></span><span id='topic+CallbackSet'></span>

<h3>Description</h3>

<p>Base class from which callbacks should inherit (see section <em>Inheriting</em>).
A callback set is a collection of functions that are executed at different stages of the training loop.
They can be used to gain more control over the training process of a neural network without
having to write everything from scratch.
</p>
<p>When used a in torch learner, the <code>CallbackSet</code> is wrapped in a <code><a href="#topic+TorchCallback">TorchCallback</a></code>.
The latters parameter set represents the arguments of the <code><a href="#topic+CallbackSet">CallbackSet</a></code>'s <code style="white-space: pre;">&#8288;$initialize()&#8288;</code> method.
</p>


<h3>Inheriting</h3>

<p>For each available stage (see section <em>Stages</em>) a public method <code style="white-space: pre;">&#8288;$on_&lt;stage&gt;()&#8288;</code> can be defined.
The evaluation context (a <code><a href="#topic+ContextTorch">ContextTorch</a></code>) can be accessed via <code>self$ctx</code>, which contains
the current state of the training loop.
This context is assigned at the beginning of the training loop and removed afterwards.
Different stages of a callback can communicate with each other by assigning values to <code style="white-space: pre;">&#8288;$self&#8288;</code>.
</p>
<p><em>State</em>:
To be able to store information in the <code style="white-space: pre;">&#8288;$model&#8288;</code> slot of a <code><a href="#topic+LearnerTorch">LearnerTorch</a></code>, callbacks support a state API.
You can overload the <code style="white-space: pre;">&#8288;$state_dict()&#8288;</code> public method to define what will be stored in <code style="white-space: pre;">&#8288;learner$model$callbacks$&lt;id&gt;&#8288;</code>
after training finishes.
This then also requires to implement a <code style="white-space: pre;">&#8288;$load_state_dict(state_dict)&#8288;</code> method that defines how to load a previously saved
callback state into a different callback.
Note that the <code style="white-space: pre;">&#8288;$state_dict()&#8288;</code> should not include the parameter values that were used to initialize the callback.
</p>
<p>For creating custom callbacks, the function <code><a href="#topic+torch_callback">torch_callback()</a></code> is recommended, which creates a
<code>CallbackSet</code> and then wraps it in a <code><a href="#topic+TorchCallback">TorchCallback</a></code>.
To create a <code>CallbackSet</code> the convenience function <code><a href="#topic+callback_set">callback_set()</a></code> can be used.
These functions perform checks such as that the stages are not accidentally misspelled.
</p>


<h3>Stages</h3>


<ul>
<li> <p><code>begin</code> :: Run before the training loop begins.
</p>
</li>
<li> <p><code>epoch_begin</code> :: Run he beginning of each epoch.
</p>
</li>
<li> <p><code>batch_begin</code> :: Run before the forward call.
</p>
</li>
<li> <p><code>after_backward</code> :: Run after the backward call.
</p>
</li>
<li> <p><code>batch_end</code> :: Run after the optimizer step.
</p>
</li>
<li> <p><code>batch_valid_begin</code> :: Run before the forward call in the validation loop.
</p>
</li>
<li> <p><code>batch_valid_end</code> :: Run after the forward call in the validation loop.
</p>
</li>
<li> <p><code>valid_end</code> :: Run at the end of validation.
</p>
</li>
<li> <p><code>epoch_end</code> :: Run at the end of each epoch.
</p>
</li>
<li> <p><code>end</code> :: Run after last epoch.
</p>
</li>
<li> <p><code>exit</code> :: Run at last, using <code>on.exit()</code>.
</p>
</li></ul>



<h3>Terminate Training</h3>

<p>If training is to be stopped, it is possible to set the field <code style="white-space: pre;">&#8288;$terminate&#8288;</code> of <code><a href="#topic+ContextTorch">ContextTorch</a></code>.
At the end of every epoch this field is checked and if it is <code>TRUE</code>, training stops.
This can for example be used to implement custom early stopping.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>ctx</code></dt><dd><p>(<code><a href="#topic+ContextTorch">ContextTorch</a></code> or <code>NULL</code>)<br />
The evaluation context for the callback.
This field should always be <code>NULL</code> except during the <code style="white-space: pre;">&#8288;$train()&#8288;</code> call of the torch learner.</p>
</dd>
</dl>

</div>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>stages</code></dt><dd><p>(<code>character()</code>)<br />
The active stages of this callback set.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-CallbackSet-print"><code>CallbackSet$print()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSet-state_dict"><code>CallbackSet$state_dict()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSet-load_state_dict"><code>CallbackSet$load_state_dict()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSet-clone"><code>CallbackSet$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-CallbackSet-print"></a>



<h4>Method <code>print()</code></h4>

<p>Prints the object.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSet$print(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>(any)<br />
Currently unused.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-CallbackSet-state_dict"></a>



<h4>Method <code>state_dict()</code></h4>

<p>Returns information that is kept in the the <code><a href="#topic+LearnerTorch">LearnerTorch</a></code>'s state after training.
This information should be loadable into the callback using <code style="white-space: pre;">&#8288;$load_state_dict()&#8288;</code> to be able to continue training.
This returns <code>NULL</code> by default.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSet$state_dict()</pre></div>


<hr>
<a id="method-CallbackSet-load_state_dict"></a>



<h4>Method <code>load_state_dict()</code></h4>

<p>Loads the state dict into the callback to continue training.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSet$load_state_dict(state_dict)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>state_dict</code></dt><dd><p>(any)<br />
The state dict as retrieved via <code style="white-space: pre;">&#8288;$state_dict()&#8288;</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-CallbackSet-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSet$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>

<hr>
<h2 id='mlr_callback_set.checkpoint'>Checkpoint Callback</h2><span id='topic+mlr_callback_set.checkpoint'></span><span id='topic+CallbackSetCheckpoint'></span>

<h3>Description</h3>

<p>Saves the optimizer and network states during training.
The final network and optimizer are always stored.
</p>


<h3>Details</h3>

<p>Saving the learner itself in the callback with a trained model is impossible,
as the model slot is set <em>after</em> the last callback step is executed.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+CallbackSet">mlr3torch::CallbackSet</a></code> -&gt; <code>CallbackSetCheckpoint</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-CallbackSetCheckpoint-new"><code>CallbackSetCheckpoint$new()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetCheckpoint-on_epoch_end"><code>CallbackSetCheckpoint$on_epoch_end()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetCheckpoint-on_batch_end"><code>CallbackSetCheckpoint$on_batch_end()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetCheckpoint-on_exit"><code>CallbackSetCheckpoint$on_exit()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetCheckpoint-clone"><code>CallbackSetCheckpoint$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="CallbackSet" data-id="load_state_dict"><a href='../../mlr3torch/html/CallbackSet.html#method-CallbackSet-load_state_dict'><code>mlr3torch::CallbackSet$load_state_dict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="CallbackSet" data-id="print"><a href='../../mlr3torch/html/CallbackSet.html#method-CallbackSet-print'><code>mlr3torch::CallbackSet$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="CallbackSet" data-id="state_dict"><a href='../../mlr3torch/html/CallbackSet.html#method-CallbackSet-state_dict'><code>mlr3torch::CallbackSet$state_dict()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-CallbackSetCheckpoint-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetCheckpoint$new(path, freq, freq_type = "epoch")</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>path</code></dt><dd><p>(<code>character(1)</code>)<br />
The path to a folder where the models are saved.</p>
</dd>
<dt><code>freq</code></dt><dd><p>(<code>integer(1)</code>)<br />
The frequency how often the model is saved.
Frequency is either per step or epoch, which can be configured through the <code>freq_type</code> parameter.</p>
</dd>
<dt><code>freq_type</code></dt><dd><p>(<code>character(1)</code>)<br />
Can be be either <code>"epoch"</code> (default) or <code>"step"</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-CallbackSetCheckpoint-on_epoch_end"></a>



<h4>Method <code>on_epoch_end()</code></h4>

<p>Saves the network and optimizer state dict.
Does nothing if <code>freq_type</code> or <code>freq</code> are not met.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetCheckpoint$on_epoch_end()</pre></div>


<hr>
<a id="method-CallbackSetCheckpoint-on_batch_end"></a>



<h4>Method <code>on_batch_end()</code></h4>

<p>Saves the selected objects defined in <code>save</code>.
Does nothing if freq_type or freq are not met.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetCheckpoint$on_batch_end()</pre></div>


<hr>
<a id="method-CallbackSetCheckpoint-on_exit"></a>



<h4>Method <code>on_exit()</code></h4>

<p>Saves the learner.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetCheckpoint$on_exit()</pre></div>


<hr>
<a id="method-CallbackSetCheckpoint-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetCheckpoint$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>

<hr>
<h2 id='mlr_callback_set.history'>History Callback</h2><span id='topic+mlr_callback_set.history'></span><span id='topic+CallbackSetHistory'></span>

<h3>Description</h3>

<p>Saves the training and validation history during training.
The history is saved as a data.table in the <code style="white-space: pre;">&#8288;$train&#8288;</code> and <code style="white-space: pre;">&#8288;$valid&#8288;</code> slots.
The first column is always <code>epoch</code>.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+CallbackSet">mlr3torch::CallbackSet</a></code> -&gt; <code>CallbackSetHistory</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-CallbackSetHistory-on_begin"><code>CallbackSetHistory$on_begin()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetHistory-state_dict"><code>CallbackSetHistory$state_dict()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetHistory-load_state_dict"><code>CallbackSetHistory$load_state_dict()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetHistory-on_before_valid"><code>CallbackSetHistory$on_before_valid()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetHistory-on_epoch_end"><code>CallbackSetHistory$on_epoch_end()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetHistory-clone"><code>CallbackSetHistory$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="CallbackSet" data-id="print"><a href='../../mlr3torch/html/CallbackSet.html#method-CallbackSet-print'><code>mlr3torch::CallbackSet$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-CallbackSetHistory-on_begin"></a>



<h4>Method <code>on_begin()</code></h4>

<p>Initializes lists where the train and validation metrics are stored.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetHistory$on_begin()</pre></div>


<hr>
<a id="method-CallbackSetHistory-state_dict"></a>



<h4>Method <code>state_dict()</code></h4>

<p>Converts the lists to data.tables.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetHistory$state_dict()</pre></div>


<hr>
<a id="method-CallbackSetHistory-load_state_dict"></a>



<h4>Method <code>load_state_dict()</code></h4>

<p>Sets the field <code style="white-space: pre;">&#8288;$train&#8288;</code> and <code style="white-space: pre;">&#8288;$valid&#8288;</code> to those contained in the state dict.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetHistory$load_state_dict(state_dict)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>state_dict</code></dt><dd><p>(<code>callback_state_history</code>)<br />
The state dict as retrieved via <code style="white-space: pre;">&#8288;$state_dict()&#8288;</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-CallbackSetHistory-on_before_valid"></a>



<h4>Method <code>on_before_valid()</code></h4>

<p>Add the latest training scores to the history.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetHistory$on_before_valid()</pre></div>


<hr>
<a id="method-CallbackSetHistory-on_epoch_end"></a>



<h4>Method <code>on_epoch_end()</code></h4>

<p>Add the latest validation scores to the history.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetHistory$on_epoch_end()</pre></div>


<hr>
<a id="method-CallbackSetHistory-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetHistory$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='mlr_callback_set.progress'>Progress Callback</h2><span id='topic+mlr_callback_set.progress'></span><span id='topic+CallbackSetProgress'></span>

<h3>Description</h3>

<p>Prints a progress bar and the metrics for training and validation.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+CallbackSet">mlr3torch::CallbackSet</a></code> -&gt; <code>CallbackSetProgress</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-CallbackSetProgress-on_epoch_begin"><code>CallbackSetProgress$on_epoch_begin()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetProgress-on_batch_end"><code>CallbackSetProgress$on_batch_end()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetProgress-on_before_valid"><code>CallbackSetProgress$on_before_valid()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetProgress-on_batch_valid_end"><code>CallbackSetProgress$on_batch_valid_end()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetProgress-on_epoch_end"><code>CallbackSetProgress$on_epoch_end()</code></a>
</p>
</li>
<li> <p><a href="#method-CallbackSetProgress-clone"><code>CallbackSetProgress$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="CallbackSet" data-id="load_state_dict"><a href='../../mlr3torch/html/CallbackSet.html#method-CallbackSet-load_state_dict'><code>mlr3torch::CallbackSet$load_state_dict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="CallbackSet" data-id="print"><a href='../../mlr3torch/html/CallbackSet.html#method-CallbackSet-print'><code>mlr3torch::CallbackSet$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="CallbackSet" data-id="state_dict"><a href='../../mlr3torch/html/CallbackSet.html#method-CallbackSet-state_dict'><code>mlr3torch::CallbackSet$state_dict()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-CallbackSetProgress-on_epoch_begin"></a>



<h4>Method <code>on_epoch_begin()</code></h4>

<p>Initializes the progress bar for training.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetProgress$on_epoch_begin()</pre></div>


<hr>
<a id="method-CallbackSetProgress-on_batch_end"></a>



<h4>Method <code>on_batch_end()</code></h4>

<p>Increments the training progress bar.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetProgress$on_batch_end()</pre></div>


<hr>
<a id="method-CallbackSetProgress-on_before_valid"></a>



<h4>Method <code>on_before_valid()</code></h4>

<p>Creates the progress bar for validation.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetProgress$on_before_valid()</pre></div>


<hr>
<a id="method-CallbackSetProgress-on_batch_valid_end"></a>



<h4>Method <code>on_batch_valid_end()</code></h4>

<p>Increments the validation progress bar.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetProgress$on_batch_valid_end()</pre></div>


<hr>
<a id="method-CallbackSetProgress-on_epoch_end"></a>



<h4>Method <code>on_epoch_end()</code></h4>

<p>Prints a summary of the training and validation process.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetProgress$on_epoch_end()</pre></div>


<hr>
<a id="method-CallbackSetProgress-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>CallbackSetProgress$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>

<hr>
<h2 id='mlr_context_torch'>Context for Torch Learner</h2><span id='topic+mlr_context_torch'></span><span id='topic+ContextTorch'></span>

<h3>Description</h3>

<p>Context for training a torch learner.
This is the - mostly read-only - information callbacks have access to through the argument <code>ctx</code>.
For more information on callbacks, see <code><a href="#topic+CallbackSet">CallbackSet</a></code>.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>learner</code></dt><dd><p>(<code><a href="mlr3.html#topic+Learner">Learner</a></code>)<br />
The torch learner.</p>
</dd>
<dt><code>task_train</code></dt><dd><p>(<code><a href="mlr3.html#topic+Task">Task</a></code>)<br />
The training task.</p>
</dd>
<dt><code>task_valid</code></dt><dd><p>(<code><a href="mlr3.html#topic+Task">Task</a></code> or <code>NULL</code>)<br />
The validation task.</p>
</dd>
<dt><code>loader_train</code></dt><dd><p>(<code><a href="torch.html#topic+dataloader">torch::dataloader</a></code>)<br />
The data loader for training.</p>
</dd>
<dt><code>loader_valid</code></dt><dd><p>(<code><a href="torch.html#topic+dataloader">torch::dataloader</a></code>)<br />
The data loader for validation.</p>
</dd>
<dt><code>measures_train</code></dt><dd><p>(<code>list()</code> of <code><a href="mlr3.html#topic+Measure">Measure</a></code>s)<br />
Measures used for training.</p>
</dd>
<dt><code>measures_valid</code></dt><dd><p>(<code>list()</code> of <code><a href="mlr3.html#topic+Measure">Measure</a></code>s)<br />
Measures used for validation.</p>
</dd>
<dt><code>network</code></dt><dd><p>(<code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>)<br />
The torch network.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="torch.html#topic+optimizer">torch::optimizer</a></code>)<br />
The optimizer.</p>
</dd>
<dt><code>loss_fn</code></dt><dd><p>(<code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>)<br />
The loss function.</p>
</dd>
<dt><code>total_epochs</code></dt><dd><p>(<code>integer(1)</code>)<br />
The total number of epochs the learner is trained for.</p>
</dd>
<dt><code>last_scores_train</code></dt><dd><p>(named <code>list()</code> or <code>NULL</code>)<br />
The scores from the last training batch. Names are the ids of the training measures.
If <code><a href="#topic+LearnerTorch">LearnerTorch</a></code> sets <code>eval_freq</code> different from <code>1</code>, this is <code>NULL</code> in all epochs
that don't evaluate the model.</p>
</dd>
<dt><code>last_scores_valid</code></dt><dd><p>(<code>list()</code>)<br />
The scores from the last validation batch. Names are the ids of the validation measures.
If <code><a href="#topic+LearnerTorch">LearnerTorch</a></code> sets <code>eval_freq</code> different from <code>1</code>, this is <code>NULL</code> in all epochs
that don't evaluate the model.</p>
</dd>
<dt><code>epoch</code></dt><dd><p>(<code>integer(1)</code>)<br />
The current epoch.</p>
</dd>
<dt><code>step</code></dt><dd><p>(<code>integer(1)</code>)<br />
The current iteration.</p>
</dd>
<dt><code>prediction_encoder</code></dt><dd><p>(<code style="white-space: pre;">&#8288;function()&#8288;</code>)<br />
The learner's prediction encoder.</p>
</dd>
<dt><code>batch</code></dt><dd><p>(named <code>list()</code> of <code>torch_tensor</code>s)<br />
The current batch.</p>
</dd>
<dt><code>terminate</code></dt><dd><p>(<code>logical(1)</code>)<br />
If this field is set to <code>TRUE</code> at the end of an epoch, training stops.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-ContextTorch-new"><code>ContextTorch$new()</code></a>
</p>
</li>
<li> <p><a href="#method-ContextTorch-clone"><code>ContextTorch$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-ContextTorch-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>ContextTorch$new(
  learner,
  task_train,
  task_valid = NULL,
  loader_train,
  loader_valid = NULL,
  measures_train = NULL,
  measures_valid = NULL,
  network,
  optimizer,
  loss_fn,
  total_epochs,
  prediction_encoder,
  eval_freq = 1L
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt><dd><p>(<code><a href="mlr3.html#topic+Learner">Learner</a></code>)<br />
The torch learner.</p>
</dd>
<dt><code>task_train</code></dt><dd><p>(<code><a href="mlr3.html#topic+Task">Task</a></code>)<br />
The training task.</p>
</dd>
<dt><code>task_valid</code></dt><dd><p>(<code><a href="mlr3.html#topic+Task">Task</a></code> or <code>NULL</code>)<br />
The validation task.</p>
</dd>
<dt><code>loader_train</code></dt><dd><p>(<code><a href="torch.html#topic+dataloader">torch::dataloader</a></code>)<br />
The data loader for training.</p>
</dd>
<dt><code>loader_valid</code></dt><dd><p>(<code><a href="torch.html#topic+dataloader">torch::dataloader</a></code> or <code>NULL</code>)<br />
The data loader for validation.</p>
</dd>
<dt><code>measures_train</code></dt><dd><p>(<code>list()</code> of <code><a href="mlr3.html#topic+Measure">Measure</a></code>s or <code>NULL</code>)<br />
Measures used for training. Default is <code>NULL</code>.</p>
</dd>
<dt><code>measures_valid</code></dt><dd><p>(<code>list()</code> of <code><a href="mlr3.html#topic+Measure">Measure</a></code>s or <code>NULL</code>)<br />
Measures used for validation.</p>
</dd>
<dt><code>network</code></dt><dd><p>(<code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>)<br />
The torch network.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="torch.html#topic+optimizer">torch::optimizer</a></code>)<br />
The optimizer.</p>
</dd>
<dt><code>loss_fn</code></dt><dd><p>(<code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>)<br />
The loss function.</p>
</dd>
<dt><code>total_epochs</code></dt><dd><p>(<code>integer(1)</code>)<br />
The total number of epochs the learner is trained for.</p>
</dd>
<dt><code>prediction_encoder</code></dt><dd><p>(<code style="white-space: pre;">&#8288;function()&#8288;</code>)<br />
The learner's prediction encoder.</p>
</dd>
<dt><code>eval_freq</code></dt><dd><p>(<code>integer(1)</code>)<br />
The evaluation frequency.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-ContextTorch-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>ContextTorch$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>

<hr>
<h2 id='mlr_learners_torch'>Base Class for Torch Learners</h2><span id='topic+mlr_learners_torch'></span><span id='topic+LearnerTorch'></span>

<h3>Description</h3>

<p>This base class provides the basic functionality for training and prediction of a neural network.
All torch learners should inherit from this class.
</p>


<h3>Validation</h3>

<p>To specify the validation data, you can set the <code style="white-space: pre;">&#8288;$validate&#8288;</code> field of the Learner, which can be set to:
</p>

<ul>
<li> <p><code>NULL</code>: no validation
</p>
</li>
<li> <p><code>ratio</code>: only proportion <code>1 - ratio</code> of the task is used for training and <code>ratio</code> is used for validation.
</p>
</li>
<li> <p><code>"test"</code> means that the <code>"test"</code> task of a resampling is used and is not possible when calling <code style="white-space: pre;">&#8288;$train()&#8288;</code> manually.
</p>
</li>
<li> <p><code>"predefined"</code>: This will use the predefined <code style="white-space: pre;">&#8288;$internal_valid_task&#8288;</code> of a <code><a href="mlr3.html#topic+Task">mlr3::Task</a></code>, which can e.g.
be created using the <code style="white-space: pre;">&#8288;$divide()&#8288;</code> method  of <code>Task</code>.
</p>
</li></ul>

<p>This validation data can also be used for early stopping, see the description of the <code>Learner</code>'s parameters.
</p>


<h3>Saving a Learner</h3>

<p>In order to save a <code>LearnerTorch</code> for later usage, it is necessary to call the <code style="white-space: pre;">&#8288;$marshal()&#8288;</code> method on the <code>Learner</code>
before writing it to disk, as the object will otherwise not be saved correctly.
After loading a marshaled <code>LearnerTorch</code> into R again, you then need to call <code style="white-space: pre;">&#8288;$unmarshal()&#8288;</code> to transform it
into a useable state.
</p>


<h3>Early Stopping and Tuning</h3>

<p>In order to prevent overfitting, the <code>LearnerTorch</code> class allows to use early stopping via the <code>patience</code>
and <code>min_delta</code> parameters, see the <code>Learner</code>'s parameters.
When tuning a <code>LearnerTorch</code> it is also possible to combine the explicit tuning via <code>mlr3tuning</code>
and the <code>LearnerTorch</code>'s internal tuning of the epochs via early stopping.
To do so, you just need to include <code style="white-space: pre;">&#8288;epochs = to_tune(upper = &lt;upper&gt;, internal = TRUE)&#8288;</code> in the search space,
where <code style="white-space: pre;">&#8288;&lt;upper&gt;&#8288;</code> is the maximally allowed number of epochs, and configure the early stopping.
</p>


<h3>Model</h3>

<p>The Model is a list of class <code>"learner_torch_model"</code> with the following elements:
</p>

<ul>
<li> <p><code>network</code> :: The trained <a href="torch.html#topic+nn_module">network</a>.
</p>
</li>
<li> <p><code>optimizer</code> :: The <code style="white-space: pre;">&#8288;$state_dict()&#8288;</code> <a href="torch.html#topic+optimizer">optimizer</a> used to train the network.
</p>
</li>
<li> <p><code>loss_fn</code> :: The <code style="white-space: pre;">&#8288;$state_dict()&#8288;</code> of the <a href="torch.html#topic+nn_module">loss</a> used to train the network.
</p>
</li>
<li> <p><code>callbacks</code> :: The <a href="#topic+mlr_callback_set">callbacks</a> used to train the network.
</p>
</li>
<li> <p><code>seed</code> :: The seed that was / is used for training and prediction.
</p>
</li>
<li> <p><code>epochs</code> :: How many epochs the model was trained for (early stopping).
</p>
</li>
<li> <p><code>task_col_info</code> :: A <code>data.table()</code> containing information about the train-task.
</p>
</li></ul>



<h3>Parameters</h3>

<p><strong>General</strong>:
</p>
<p>The parameters of the optimizer, loss and callbacks,
prefixed with <code>"opt."</code>, <code>"loss."</code> and <code>"cb.&lt;callback id&gt;."</code> respectively, as well as:
</p>

<ul>
<li> <p><code>epochs</code> :: <code>integer(1)</code><br />
The number of epochs.
</p>
</li>
<li> <p><code>device</code> :: <code>character(1)</code><br />
The device. One of <code>"auto"</code>, <code>"cpu"</code>, or <code>"cuda"</code> or other values defined in <code>mlr_reflections$torch$devices</code>.
The value is initialized to <code>"auto"</code>, which will select <code>"cuda"</code> if possible, then try <code>"mps"</code> and otherwise
fall back to <code>"cpu"</code>.
</p>
</li>
<li> <p><code>num_threads</code> :: <code>integer(1)</code><br />
The number of threads for intraop pararallelization (if <code>device</code> is <code>"cpu"</code>).
This value is initialized to 1.
</p>
</li>
<li> <p><code>seed</code> :: <code>integer(1)</code> or <code>"random"</code><br />
The seed that is used during training and prediction.
This value is initialized to <code>"random"</code>, which means that a random seed will be sampled at the beginning of the
training phase. This seed (either set or randomly sampled) is available via <code style="white-space: pre;">&#8288;$model$seed&#8288;</code> after training
and used during prediction.
Note that by setting the seed during the training phase this will mean that by default (i.e. when <code>seed</code> is
<code>"random"</code>), clones of the learner will use a different seed.
</p>
</li></ul>

<p><strong>Evaluation</strong>:
</p>

<ul>
<li> <p><code>measures_train</code> :: <code><a href="mlr3.html#topic+Measure">Measure</a></code> or <code>list()</code> of <code><a href="mlr3.html#topic+Measure">Measure</a></code>s.<br />
Measures to be evaluated during training.
</p>
</li>
<li> <p><code>measures_valid</code> :: <code><a href="mlr3.html#topic+Measure">Measure</a></code> or <code>list()</code> of <code><a href="mlr3.html#topic+Measure">Measure</a></code>s.<br />
Measures to be evaluated during validation.
</p>
</li>
<li> <p><code>eval_freq</code> :: <code>integer(1)</code><br />
How often the train / validation predictions are evaluated using <code>measures_train</code> / <code>measures_valid</code>.
This is initialized to <code>1</code>.
Note that the final model is always evaluated.
</p>
</li></ul>

<p><strong>Early Stopping</strong>:
</p>

<ul>
<li> <p><code>patience</code> :: <code>integer(1)</code><br />
This activates early stopping using the validation scores.
If the performance of a model does not improve for <code>patience</code> evaluation steps, training is ended.
Note that the final model is stored in the learner, not the best model.
This is initialized to <code>0</code>, which means no early stopping.
The first entry from <code>measures_valid</code> is used as the metric.
This also requires to specify the <code style="white-space: pre;">&#8288;$validate&#8288;</code> field of the Learner, as well as <code>measures_valid</code>.
</p>
</li>
<li> <p><code>min_delta</code> :: <code>double(1)</code><br />
The minimum improvement threshold (<code>&gt;</code>) for early stopping.
Is initialized to 0.
</p>
</li></ul>

<p><strong>Dataloader</strong>:
</p>

<ul>
<li> <p><code>batch_size</code> :: <code>integer(1)</code><br />
The batch size (required).
</p>
</li>
<li> <p><code>shuffle</code> :: <code>logical(1)</code><br />
Whether to shuffle the instances in the dataset. Default is <code>FALSE</code>.
This does not impact validation.
</p>
</li>
<li> <p><code>sampler</code> :: <code><a href="torch.html#topic+sampler">torch::sampler</a></code><br />
Object that defines how the dataloader draw samples.
</p>
</li>
<li> <p><code>batch_sampler</code> :: <code><a href="torch.html#topic+sampler">torch::sampler</a></code><br />
Object that defines how the dataloader draws batches.
</p>
</li>
<li> <p><code>num_workers</code> :: <code>integer(1)</code><br />
The number of workers for data loading (batches are loaded in parallel).
The default is <code>0</code>, which means that data will be loaded in the main process.
</p>
</li>
<li> <p><code>collate_fn</code> :: <code>function</code><br />
How to merge a list of samples to form a batch.
</p>
</li>
<li> <p><code>pin_memory</code> :: <code>logical(1)</code><br />
Whether the dataloader copies tensors into CUDA pinned memory before returning them.
</p>
</li>
<li> <p><code>drop_last</code> :: <code>logical(1)</code><br />
Whether to drop the last training batch in each epoch during training. Default is <code>FALSE</code>.
</p>
</li>
<li> <p><code>timeout</code> :: <code>numeric(1)</code><br />
The timeout value for collecting a batch from workers.
Negative values mean no timeout and the default is <code>-1</code>.
</p>
</li>
<li> <p><code>worker_init_fn</code> :: <code style="white-space: pre;">&#8288;function(id)&#8288;</code><br />
A function that receives the worker id (in <code style="white-space: pre;">&#8288;[1, num_workers]&#8288;</code>) and is exectued after seeding
on the worker but before data loading.
</p>
</li>
<li> <p><code>worker_globals</code> :: <code>list()</code> | <code>character()</code><br />
When loading data in parallel, this allows to export globals to the workers.
If this is a character vector, the objects in the global environment with those names
are copied to the workers.
</p>
</li>
<li> <p><code>worker_packages</code> :: <code>character()</code><br />
Which packages to load on the workers.
</p>
</li></ul>

<p>Also see <code>torch::dataloder</code> for more information.
</p>


<h3>Inheriting</h3>

<p>There are no seperate classes for classification and regression to inherit from.
Instead, the <code>task_type</code> must be specified  as a construction argument.
Currently, only classification and regression are supported.
</p>
<p>When inheriting from this class, one should overload two private methods:
</p>

<ul>
<li> <p><code>.network(task, param_vals)</code><br />
(<code><a href="mlr3.html#topic+Task">Task</a></code>, <code>list()</code>) -&gt; <code><a href="torch.html#topic+nn_module">nn_module</a></code><br />
Construct a <code><a href="torch.html#topic+nn_module">torch::nn_module</a></code> object for the given task and parameter values, i.e. the neural network that
is trained by the learner.
For classification, the output of this network are expected to be the scores before the application of the
final softmax layer.
</p>
</li>
<li> <p><code>.dataset(task, param_vals)</code><br />
(<code><a href="mlr3.html#topic+Task">Task</a></code>, <code>list()</code>) -&gt; <code><a href="torch.html#topic+dataset">torch::dataset</a></code><br />
Create the dataset for the task.
Must respect the parameter value of the device.
Moreover, one needs to pay attention respect the row ids of the provided task.
</p>
</li></ul>

<p>It is also possible to overwrite the private <code>.dataloader()</code> method instead of the <code>.dataset()</code> method.
Per default, a dataloader is constructed using the output from the <code>.dataset()</code> method.
However, this should respect the dataloader parameters from the <code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>.
</p>

<ul>
<li> <p><code>.dataloader(task, param_vals)</code><br />
(<code><a href="mlr3.html#topic+Task">Task</a></code>, <code>list()</code>) -&gt; <code><a href="torch.html#topic+dataloader">torch::dataloader</a></code><br />
Create a dataloader from the task.
Needs to respect at least <code>batch_size</code> and <code>shuffle</code> (otherwise predictions can be permuted).
</p>
</li></ul>

<p>To change the predict types, the private <code>.encode_prediction()</code> method can be overwritten:
</p>

<ul>
<li> <p><code>.encode_prediction(predict_tensor, task, param_vals)</code><br />
(<code><a href="torch.html#topic+torch_tensor">torch_tensor</a></code>, <code><a href="mlr3.html#topic+Task">Task</a></code>, <code>list()</code>) -&gt; <code>list()</code><br />
Take in the raw predictions from <code>self$network</code> (<code>predict_tensor</code>) and encode them into a
format that can be converted to valid <code>mlr3</code> predictions using <code><a href="mlr3.html#topic+as_prediction_data">mlr3::as_prediction_data()</a></code>.
This method must take <code>self$predict_type</code> into account.
</p>
</li></ul>

<p>While it is possible to add parameters by specifying the <code>param_set</code> construction argument, it is currently
not possible to remove existing parameters, i.e. those listed in section <em>Parameters</em>.
None of the parameters provided in <code>param_set</code> can have an id that starts with <code>"loss."</code>, <code style="white-space: pre;">&#8288;"opt.", or &#8288;</code>&quot;cb.&quot;', as these are preserved for the dynamically constructed parameters of the optimizer, the loss function,
and the callbacks.
</p>
<p>To perform additional input checks on the task, the private <code>.verify_train_task(task, param_vals)</code> and
<code>.verify_predict_task(task, param_vals)</code> can be overwritten.
</p>
<p>For learners that have other construction arguments that should change the hash of a learner, it is required
to implement the private <code style="white-space: pre;">&#8288;$.additional_phash_input()&#8288;</code>.
</p>


<h3>Super class</h3>

<p><code><a href="mlr3.html#topic+Learner">mlr3::Learner</a></code> -&gt; <code>LearnerTorch</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>validate</code></dt><dd><p>How to construct the internal validation data. This parameter can be either <code>NULL</code>,
a ratio in $(0, 1)$, <code>"test"</code>, or <code>"predefined"</code>.</p>
</dd>
<dt><code>loss</code></dt><dd><p>(<code><a href="#topic+TorchLoss">TorchLoss</a></code>)<br />
The torch loss.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>)<br />
The torch optimizer.</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>(<code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s)<br />
List of torch callbacks.
The ids will be set as the names.</p>
</dd>
<dt><code>internal_valid_scores</code></dt><dd><p>Retrieves the internal validation scores as a named <code>list()</code>.
Specify the <code style="white-space: pre;">&#8288;$validate&#8288;</code> field and the <code>measures_valid</code> parameter to configure this.
Returns <code>NULL</code> if learner is not trained yet.</p>
</dd>
<dt><code>internal_tuned_values</code></dt><dd><p>When early stopping is activate, this returns a named list with the early-stopped epochs,
otherwise an empty list is returned.
Returns <code>NULL</code> if learner is not trained yet.</p>
</dd>
<dt><code>marshaled</code></dt><dd><p>(<code>logical(1)</code>)<br />
Whether the learner is marshaled.</p>
</dd>
<dt><code>network</code></dt><dd><p>(<code><a href="torch.html#topic+nn_module">nn_module()</a></code>)<br />
Shortcut for <code>learner$model$network</code>.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>)<br />
The parameter set</p>
</dd>
<dt><code>hash</code></dt><dd><p>(<code>character(1)</code>)<br />
Hash (unique identifier) for this object.</p>
</dd>
<dt><code>phash</code></dt><dd><p>(<code>character(1)</code>)<br />
Hash (unique identifier) for this partial object, excluding some components
which are varied systematically during tuning (parameter values).</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerTorch-new"><code>LearnerTorch$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorch-format"><code>LearnerTorch$format()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorch-print"><code>LearnerTorch$print()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorch-marshal"><code>LearnerTorch$marshal()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorch-unmarshal"><code>LearnerTorch$unmarshal()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorch-dataset"><code>LearnerTorch$dataset()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorch-clone"><code>LearnerTorch$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerTorch-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorch$new(
  id,
  task_type,
  param_set,
  properties,
  man,
  label,
  feature_types,
  optimizer = NULL,
  loss = NULL,
  packages = character(),
  predict_types = NULL,
  callbacks = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</dd>
<dt><code>task_type</code></dt><dd><p>(<code>character(1)</code>)<br />
The task type.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code> or <code>alist()</code>)<br />
Either a parameter set, or an <code>alist()</code> containing different values of self,
e.g. <code>alist(private$.param_set1, private$.param_set2)</code>, from which a <code><a href="paradox.html#topic+ParamSet">ParamSet</a></code> collection
should be created.</p>
</dd>
<dt><code>properties</code></dt><dd><p>(<code>character()</code>)<br />
The properties of the object.
See <code><a href="mlr3.html#topic+mlr_reflections">mlr_reflections$learner_properties</a></code> for available values.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for the new instance.</p>
</dd>
<dt><code>feature_types</code></dt><dd><p>(<code>character()</code>)<br />
The feature types.
See <code><a href="mlr3.html#topic+mlr_reflections">mlr_reflections$task_feature_types</a></code> for available values,
Additionally, <code>"lazy_tensor"</code> is supported.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code>NULL</code> or <code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>)<br />
The optimizer to use for training.
Defaults to adam.</p>
</dd>
<dt><code>loss</code></dt><dd><p>(<code>NULL</code> or <code><a href="#topic+TorchLoss">TorchLoss</a></code>)<br />
The loss to use for training.
Defaults to MSE for regression and cross entropy for classification.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
<dt><code>predict_types</code></dt><dd><p>(<code>character()</code>)<br />
The predict types.
See <code><a href="mlr3.html#topic+mlr_reflections">mlr_reflections$learner_predict_types</a></code> for available values.
For regression, the default is <code>"response"</code>.
For classification, this defaults to <code>"response"</code> and <code>"prob"</code>.
To deviate from the defaults, it is necessary to overwrite the private <code style="white-space: pre;">&#8288;$.encode_prediction()&#8288;</code>
method, see section <em>Inheriting</em>.</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>(<code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s)<br />
The callbacks to use for training.
Defaults to an empty<code> list()</code>, i.e. no callbacks.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LearnerTorch-format"></a>



<h4>Method <code>format()</code></h4>

<p>Helper for print outputs.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorch$format(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>(ignored).</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LearnerTorch-print"></a>



<h4>Method <code>print()</code></h4>

<p>Prints the object.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorch$print(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>(any)<br />
Currently unused.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LearnerTorch-marshal"></a>



<h4>Method <code>marshal()</code></h4>

<p>Marshal the learner.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorch$marshal(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>(any)<br />
Additional parameters.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-LearnerTorch-unmarshal"></a>



<h4>Method <code>unmarshal()</code></h4>

<p>Unmarshal the learner.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorch$unmarshal(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>(any)<br />
Additional parameters.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-LearnerTorch-dataset"></a>



<h4>Method <code>dataset()</code></h4>

<p>Create the dataset for a task.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorch$dataset(task)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>task</code></dt><dd><p><code><a href="mlr3.html#topic+Task">Task</a></code><br />
The task</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code><a href="torch.html#topic+dataset">dataset</a></code>
</p>


<hr>
<a id="method-LearnerTorch-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorch$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Learner: 
<code><a href="#topic+mlr_learners.mlp">mlr_learners.mlp</a></code>,
<code><a href="#topic+mlr_learners.tab_resnet">mlr_learners.tab_resnet</a></code>,
<code><a href="#topic+mlr_learners.torch_featureless">mlr_learners.torch_featureless</a></code>,
<code><a href="#topic+mlr_learners_torch_image">mlr_learners_torch_image</a></code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>
</p>

<hr>
<h2 id='mlr_learners_torch_image'>Image Learner</h2><span id='topic+mlr_learners_torch_image'></span><span id='topic+LearnerTorchImage'></span>

<h3>Description</h3>

<p>Base Class for Image Learners.
The features are assumed to be a single <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> column in RGB format.
</p>


<h3>Parameters</h3>

<p>Parameters include those inherited from <code><a href="#topic+LearnerTorch">LearnerTorch</a></code> and the <code>param_set</code> construction argument.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3.html#topic+Learner">mlr3::Learner</a></code> -&gt; <code><a href="#topic+LearnerTorch">mlr3torch::LearnerTorch</a></code> -&gt; <code>LearnerTorchImage</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerTorchImage-new"><code>LearnerTorchImage$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorchImage-clone"><code>LearnerTorchImage$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="dataset"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-dataset'><code>mlr3torch::LearnerTorch$dataset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="format"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-format'><code>mlr3torch::LearnerTorch$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="marshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-marshal'><code>mlr3torch::LearnerTorch$marshal()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="print"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-print'><code>mlr3torch::LearnerTorch$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="unmarshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-unmarshal'><code>mlr3torch::LearnerTorch$unmarshal()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerTorchImage-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchImage$new(
  id,
  task_type,
  param_set = ps(),
  label,
  optimizer = NULL,
  loss = NULL,
  callbacks = list(),
  packages = c("torchvision", "magick"),
  man,
  properties = NULL,
  predict_types = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</dd>
<dt><code>task_type</code></dt><dd><p>(<code>character(1)</code>)<br />
The task type.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>)<br />
The parameter set.</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for the new instance.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>)<br />
The torch optimizer.</p>
</dd>
<dt><code>loss</code></dt><dd><p>(<code><a href="#topic+TorchLoss">TorchLoss</a></code>)<br />
The loss to use for training.</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>(<code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s)<br />
The callbacks used during training.
Must have unique ids.
They are executed in the order in which they are provided</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.</p>
</dd>
<dt><code>properties</code></dt><dd><p>(<code>character()</code>)<br />
The properties of the object.
See <code><a href="mlr3.html#topic+mlr_reflections">mlr_reflections$learner_properties</a></code> for available values.</p>
</dd>
<dt><code>predict_types</code></dt><dd><p>(<code>character()</code>)<br />
The predict types.
See <code><a href="mlr3.html#topic+mlr_reflections">mlr_reflections$learner_predict_types</a></code> for available values.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LearnerTorchImage-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchImage$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Learner: 
<code><a href="#topic+mlr_learners.mlp">mlr_learners.mlp</a></code>,
<code><a href="#topic+mlr_learners.tab_resnet">mlr_learners.tab_resnet</a></code>,
<code><a href="#topic+mlr_learners.torch_featureless">mlr_learners.torch_featureless</a></code>,
<code><a href="#topic+mlr_learners_torch">mlr_learners_torch</a></code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>
</p>

<hr>
<h2 id='mlr_learners_torch_model'>Learner Torch Model</h2><span id='topic+mlr_learners_torch_model'></span><span id='topic+LearnerTorchModel'></span>

<h3>Description</h3>

<p>Create a torch learner from an instantiated <code><a href="torch.html#topic+nn_module">nn_module()</a></code>.
For classification, the output of the network must be the scores (before the softmax).
</p>


<h3>Parameters</h3>

<p>See <code><a href="#topic+LearnerTorch">LearnerTorch</a></code>
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3.html#topic+Learner">mlr3::Learner</a></code> -&gt; <code><a href="#topic+LearnerTorch">mlr3torch::LearnerTorch</a></code> -&gt; <code>LearnerTorchModel</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>network_stored</code></dt><dd><p>(<code>nn_module</code> or <code>NULL</code>)<br />
The network that will be trained.
After calling <code style="white-space: pre;">&#8288;$train()&#8288;</code>, this is <code>NULL</code>.</p>
</dd>
<dt><code>ingress_tokens</code></dt><dd><p>(named <code>list()</code> with <code>TorchIngressToken</code> or <code>NULL</code>)<br />
The ingress tokens. Must be non-<code>NULL</code> when calling <code style="white-space: pre;">&#8288;$train()&#8288;</code>.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerTorchModel-new"><code>LearnerTorchModel$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorchModel-clone"><code>LearnerTorchModel$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="dataset"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-dataset'><code>mlr3torch::LearnerTorch$dataset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="format"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-format'><code>mlr3torch::LearnerTorch$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="marshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-marshal'><code>mlr3torch::LearnerTorch$marshal()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="print"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-print'><code>mlr3torch::LearnerTorch$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="unmarshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-unmarshal'><code>mlr3torch::LearnerTorch$unmarshal()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerTorchModel-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchModel$new(
  network = NULL,
  ingress_tokens = NULL,
  task_type,
  properties = NULL,
  optimizer = NULL,
  loss = NULL,
  callbacks = list(),
  packages = character(0),
  feature_types = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>network</code></dt><dd><p>(<code><a href="torch.html#topic+nn_module">nn_module</a></code>)<br />
An instantiated <code><a href="torch.html#topic+nn_module">nn_module</a></code>. Is not cloned during construction.
For classification, outputs must be the scores (before the softmax).</p>
</dd>
<dt><code>ingress_tokens</code></dt><dd><p>(<code>list</code> of <code><a href="#topic+TorchIngressToken">TorchIngressToken()</a></code>)<br />
A list with ingress tokens that defines how the dataloader will be defined.</p>
</dd>
<dt><code>task_type</code></dt><dd><p>(<code>character(1)</code>)<br />
The task type.</p>
</dd>
<dt><code>properties</code></dt><dd><p>(<code>NULL</code> or <code>character()</code>)<br />
The properties of the learner.
Defaults to all available properties for the given task type.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>)<br />
The torch optimizer.</p>
</dd>
<dt><code>loss</code></dt><dd><p>(<code><a href="#topic+TorchLoss">TorchLoss</a></code>)<br />
The loss to use for training.</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>(<code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s)<br />
The callbacks used during training.
Must have unique ids.
They are executed in the order in which they are provided</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
<dt><code>feature_types</code></dt><dd><p>(<code>NULL</code> or <code>character()</code>)<br />
The feature types. Defaults to all available feature types.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LearnerTorchModel-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchModel$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Learner: 
<code><a href="#topic+mlr_learners.mlp">mlr_learners.mlp</a></code>,
<code><a href="#topic+mlr_learners.tab_resnet">mlr_learners.tab_resnet</a></code>,
<code><a href="#topic+mlr_learners.torch_featureless">mlr_learners.torch_featureless</a></code>,
<code><a href="#topic+mlr_learners_torch">mlr_learners_torch</a></code>,
<code><a href="#topic+mlr_learners_torch_image">mlr_learners_torch_image</a></code>
</p>
<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# We show the learner using a classification task

# The iris task has 4 features and 3 classes
network = nn_linear(4, 3)
task = tsk("iris")

# This defines the dataloader.
# It loads all 4 features, which are also numeric.
# The shape is (NA, 4) because the batch dimension is generally NA
ingress_tokens = list(
  input = TorchIngressToken(task$feature_names, batchgetter_num, c(NA, 4))
)

# Creating the learner and setting required parameters
learner = lrn("classif.torch_model",
  network = network,
  ingress_tokens = ingress_tokens,
  batch_size = 16,
  epochs = 1,
  device = "cpu"
)

# A simple train-predict
ids = partition(task)
learner$train(task, ids$train)
learner$predict(task, ids$test)

</code></pre>

<hr>
<h2 id='mlr_learners.mlp'>My Little Pony</h2><span id='topic+mlr_learners.mlp'></span><span id='topic+LearnerTorchMLP'></span>

<h3>Description</h3>

<p>Fully connected feed forward network with dropout after each activation function.
The features can either be a single <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> or one or more numeric columns (but not both).
</p>


<h3>Dictionary</h3>

<p>This <a href="mlr3.html#topic+Learner">Learner</a> can be instantiated using the sugar function <code><a href="mlr3.html#topic+mlr_sugar">lrn()</a></code>:
</p>
<div class="sourceCode"><pre>lrn("classif.mlp", ...)
lrn("regr.mlp", ...)
</pre></div>


<h3>Properties</h3>


<ul>
<li><p> Supported task types: 'classif', 'regr'
</p>
</li>
<li><p> Predict Types:
</p>

<ul>
<li><p> classif: 'response', 'prob'
</p>
</li>
<li><p> regr: 'response'
</p>
</li></ul>

</li>
<li><p> Feature Types: &ldquo;integer&rdquo;, &ldquo;numeric&rdquo;, &ldquo;lazy_tensor&rdquo;
</p>
</li>
<li><p> Required Packages: <a href="https://CRAN.R-project.org/package=mlr3"><span class="pkg">mlr3</span></a>, <a href="https://CRAN.R-project.org/package=mlr3torch"><span class="pkg">mlr3torch</span></a>, <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>
</p>
</li></ul>



<h3>Parameters</h3>

<p>Parameters from <code><a href="#topic+LearnerTorch">LearnerTorch</a></code>, as well as:
</p>

<ul>
<li> <p><code>activation</code> :: <code style="white-space: pre;">&#8288;[nn_module]&#8288;</code><br />
The activation function. Is initialized to <code><a href="torch.html#topic+nn_relu">nn_relu</a></code>.
</p>
</li>
<li> <p><code>activation_args</code> :: named <code>list()</code><br />
A named list with initialization arguments for the activation function.
This is intialized to an empty list.
</p>
</li>
<li> <p><code>neurons</code> :: <code>integer()</code><br />
The number of neurons per hidden layer. By default there is no hidden layer.
Setting this to <code>c(10, 20)</code> would have a the first hidden layer with 10 neurons and the second with 20.
</p>
</li>
<li> <p><code>p</code> :: <code>numeric(1)</code><br />
The dropout probability. Is initialized to <code>0.5</code>.
</p>
</li>
<li> <p><code>shape</code> :: <code>integer()</code> or <code>NULL</code><br />
The input shape of length 2, e.g. <code>c(NA, 5)</code>.
Only needs to be present when there is a lazy tensor input with unknown shape (<code>NULL</code>).
Otherwise the input shape is inferred from the number of numeric features.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3.html#topic+Learner">mlr3::Learner</a></code> -&gt; <code><a href="#topic+LearnerTorch">mlr3torch::LearnerTorch</a></code> -&gt; <code>LearnerTorchMLP</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerTorchMLP-new"><code>LearnerTorchMLP$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorchMLP-clone"><code>LearnerTorchMLP$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="dataset"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-dataset'><code>mlr3torch::LearnerTorch$dataset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="format"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-format'><code>mlr3torch::LearnerTorch$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="marshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-marshal'><code>mlr3torch::LearnerTorch$marshal()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="print"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-print'><code>mlr3torch::LearnerTorch$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="unmarshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-unmarshal'><code>mlr3torch::LearnerTorch$unmarshal()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerTorchMLP-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchMLP$new(
  task_type,
  optimizer = NULL,
  loss = NULL,
  callbacks = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>task_type</code></dt><dd><p>(<code>character(1)</code>)<br />
The task type, either <code style="white-space: pre;">&#8288;"classif&#8288;</code>&quot; or <code>"regr"</code>.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>)<br />
The optimizer to use for training.
Per default, <em>adam</em> is used.</p>
</dd>
<dt><code>loss</code></dt><dd><p>(<code><a href="#topic+TorchLoss">TorchLoss</a></code>)<br />
The loss used to train the network.
Per default, <em>mse</em> is used for regression and <em>cross_entropy</em> for classification.</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>(<code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s)<br />
The callbacks. Must have unique ids.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LearnerTorchMLP-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchMLP$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Learner: 
<code><a href="#topic+mlr_learners.tab_resnet">mlr_learners.tab_resnet</a></code>,
<code><a href="#topic+mlr_learners.torch_featureless">mlr_learners.torch_featureless</a></code>,
<code><a href="#topic+mlr_learners_torch">mlr_learners_torch</a></code>,
<code><a href="#topic+mlr_learners_torch_image">mlr_learners_torch_image</a></code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Define the Learner and set parameter values
learner = lrn("classif.mlp")
learner$param_set$set_values(
  epochs = 1, batch_size = 16, device = "cpu",
  neurons = 10
)

# Define a Task
task = tsk("iris")

# Create train and test set
ids = partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)

# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()

</code></pre>

<hr>
<h2 id='mlr_learners.tab_resnet'>Tabular ResNet</h2><span id='topic+mlr_learners.tab_resnet'></span><span id='topic+LearnerTorchTabResNet'></span>

<h3>Description</h3>

<p>Tabular resnet.
</p>


<h3>Dictionary</h3>

<p>This <a href="mlr3.html#topic+Learner">Learner</a> can be instantiated using the sugar function <code><a href="mlr3.html#topic+mlr_sugar">lrn()</a></code>:
</p>
<div class="sourceCode"><pre>lrn("classif.tab_resnet", ...)
lrn("regr.tab_resnet", ...)
</pre></div>


<h3>Properties</h3>


<ul>
<li><p> Supported task types: 'classif', 'regr'
</p>
</li>
<li><p> Predict Types:
</p>

<ul>
<li><p> classif: 'response', 'prob'
</p>
</li>
<li><p> regr: 'response'
</p>
</li></ul>

</li>
<li><p> Feature Types: &ldquo;integer&rdquo;, &ldquo;numeric&rdquo;
</p>
</li>
<li><p> Required Packages: <a href="https://CRAN.R-project.org/package=mlr3"><span class="pkg">mlr3</span></a>, <a href="https://CRAN.R-project.org/package=mlr3torch"><span class="pkg">mlr3torch</span></a>, <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>
</p>
</li></ul>



<h3>Parameters</h3>

<p>Parameters from <code><a href="#topic+LearnerTorch">LearnerTorch</a></code>, as well as:
</p>

<ul>
<li> <p><code>n_blocks</code> :: <code>integer(1)</code><br />
The number of blocks.
</p>
</li>
<li> <p><code>d_block</code> :: <code>integer(1)</code><br />
The input and output dimension of a block.
</p>
</li>
<li> <p><code>d_hidden</code> :: <code>integer(1)</code><br />
The latent dimension of a block.
</p>
</li>
<li> <p><code>d_hidden_multiplier</code> :: <code>integer(1)</code><br />
Alternative way to specify the latent dimension as <code>d_block * d_hidden_multiplier</code>.
</p>
</li>
<li> <p><code>dropout1</code> :: <code>numeric(1)</code><br />
First dropout ratio.
</p>
</li>
<li> <p><code>dropout2</code> :: <code>numeric(1)</code><br />
Second dropout ratio.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3.html#topic+Learner">mlr3::Learner</a></code> -&gt; <code><a href="#topic+LearnerTorch">mlr3torch::LearnerTorch</a></code> -&gt; <code>LearnerTorchTabResNet</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerTorchTabResNet-new"><code>LearnerTorchTabResNet$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorchTabResNet-clone"><code>LearnerTorchTabResNet$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="dataset"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-dataset'><code>mlr3torch::LearnerTorch$dataset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="format"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-format'><code>mlr3torch::LearnerTorch$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="marshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-marshal'><code>mlr3torch::LearnerTorch$marshal()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="print"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-print'><code>mlr3torch::LearnerTorch$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="unmarshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-unmarshal'><code>mlr3torch::LearnerTorch$unmarshal()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerTorchTabResNet-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchTabResNet$new(
  task_type,
  optimizer = NULL,
  loss = NULL,
  callbacks = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>task_type</code></dt><dd><p>(<code>character(1)</code>)<br />
The task type, either <code style="white-space: pre;">&#8288;"classif&#8288;</code>&quot; or <code>"regr"</code>.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>)<br />
The optimizer to use for training.
Per default, <em>adam</em> is used.</p>
</dd>
<dt><code>loss</code></dt><dd><p>(<code><a href="#topic+TorchLoss">TorchLoss</a></code>)<br />
The loss used to train the network.
Per default, <em>mse</em> is used for regression and <em>cross_entropy</em> for classification.</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>(<code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s)<br />
The callbacks. Must have unique ids.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LearnerTorchTabResNet-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchTabResNet$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>References</h3>

<p>Gorishniy Y, Rubachev I, Khrulkov V, Babenko A (2021).
&ldquo;Revisiting Deep Learning  for Tabular Data.&rdquo;
<em>arXiv</em>, <b>2106.11959</b>.
</p>


<h3>See Also</h3>

<p>Other Learner: 
<code><a href="#topic+mlr_learners.mlp">mlr_learners.mlp</a></code>,
<code><a href="#topic+mlr_learners.torch_featureless">mlr_learners.torch_featureless</a></code>,
<code><a href="#topic+mlr_learners_torch">mlr_learners_torch</a></code>,
<code><a href="#topic+mlr_learners_torch_image">mlr_learners_torch_image</a></code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Define the Learner and set parameter values
learner = lrn("classif.tab_resnet")
learner$param_set$set_values(
  epochs = 1, batch_size = 16, device = "cpu",
  n_blocks = 2, d_block = 10, d_hidden = 20, dropout1 = 0.3, dropout2 = 0.3
)

# Define a Task
task = tsk("iris")

# Create train and test set
ids = partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)

# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()

</code></pre>

<hr>
<h2 id='mlr_learners.torch_featureless'>Featureless Torch Learner</h2><span id='topic+mlr_learners.torch_featureless'></span><span id='topic+LearnerTorchFeatureless'></span>

<h3>Description</h3>

<p>Featureless torch learner.
Output is a constant weight that is learned during training.
For classification, this should (asymptoptically) result in a majority class prediction when using the standard cross-entropy loss.
For regression, this should result in the median for L1 loss and in the mean for L2 loss.
</p>


<h3>Dictionary</h3>

<p>This <a href="mlr3.html#topic+Learner">Learner</a> can be instantiated using the sugar function <code><a href="mlr3.html#topic+mlr_sugar">lrn()</a></code>:
</p>
<div class="sourceCode"><pre>lrn("classif.torch_featureless", ...)
lrn("regr.torch_featureless", ...)
</pre></div>


<h3>Properties</h3>


<ul>
<li><p> Supported task types: 'classif', 'regr'
</p>
</li>
<li><p> Predict Types:
</p>

<ul>
<li><p> classif: 'response', 'prob'
</p>
</li>
<li><p> regr: 'response'
</p>
</li></ul>

</li>
<li><p> Feature Types: &ldquo;logical&rdquo;, &ldquo;integer&rdquo;, &ldquo;numeric&rdquo;, &ldquo;character&rdquo;, &ldquo;factor&rdquo;, &ldquo;ordered&rdquo;, &ldquo;POSIXct&rdquo;, &ldquo;lazy_tensor&rdquo;
</p>
</li>
<li><p> Required Packages: <a href="https://CRAN.R-project.org/package=mlr3"><span class="pkg">mlr3</span></a>, <a href="https://CRAN.R-project.org/package=mlr3torch"><span class="pkg">mlr3torch</span></a>, <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>
</p>
</li></ul>



<h3>Parameters</h3>

<p>Only those from <code><a href="#topic+LearnerTorch">LearnerTorch</a></code>.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3.html#topic+Learner">mlr3::Learner</a></code> -&gt; <code><a href="#topic+LearnerTorch">mlr3torch::LearnerTorch</a></code> -&gt; <code>LearnerTorchFeatureless</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerTorchFeatureless-new"><code>LearnerTorchFeatureless$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorchFeatureless-clone"><code>LearnerTorchFeatureless$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="dataset"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-dataset'><code>mlr3torch::LearnerTorch$dataset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="format"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-format'><code>mlr3torch::LearnerTorch$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="marshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-marshal'><code>mlr3torch::LearnerTorch$marshal()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="print"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-print'><code>mlr3torch::LearnerTorch$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="unmarshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-unmarshal'><code>mlr3torch::LearnerTorch$unmarshal()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerTorchFeatureless-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchFeatureless$new(
  task_type,
  optimizer = NULL,
  loss = NULL,
  callbacks = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>task_type</code></dt><dd><p>(<code>character(1)</code>)<br />
The task type, either <code style="white-space: pre;">&#8288;"classif&#8288;</code>&quot; or <code>"regr"</code>.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>)<br />
The optimizer to use for training.
Per default, <em>adam</em> is used.</p>
</dd>
<dt><code>loss</code></dt><dd><p>(<code><a href="#topic+TorchLoss">TorchLoss</a></code>)<br />
The loss used to train the network.
Per default, <em>mse</em> is used for regression and <em>cross_entropy</em> for classification.</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>(<code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s)<br />
The callbacks. Must have unique ids.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LearnerTorchFeatureless-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchFeatureless$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Learner: 
<code><a href="#topic+mlr_learners.mlp">mlr_learners.mlp</a></code>,
<code><a href="#topic+mlr_learners.tab_resnet">mlr_learners.tab_resnet</a></code>,
<code><a href="#topic+mlr_learners_torch">mlr_learners_torch</a></code>,
<code><a href="#topic+mlr_learners_torch_image">mlr_learners_torch_image</a></code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Define the Learner and set parameter values
learner = lrn("classif.torch_featureless")
learner$param_set$set_values(
  epochs = 1, batch_size = 16, device = "cpu"
  
)

# Define a Task
task = tsk("iris")

# Create train and test set
ids = partition(task)

# Train the learner on the training ids
learner$train(task, row_ids = ids$train)

# Make predictions for the test rows
predictions = learner$predict(task, row_ids = ids$test)

# Score the predictions
predictions$score()

</code></pre>

<hr>
<h2 id='mlr_learners.torchvision'>AlexNet Image Classifier</h2><span id='topic+mlr_learners.torchvision'></span><span id='topic+LearnerTorchVision'></span>

<h3>Description</h3>

<p>Classic image classification networks from <code>torchvision</code>.
</p>


<h3>Parameters</h3>

<p>Parameters from <code><a href="#topic+LearnerTorchImage">LearnerTorchImage</a></code> and
</p>

<ul>
<li> <p><code>pretrained</code> :: <code>logical(1)</code><br />
Whether to use the pretrained model.
The final linear layer will be replaced with a new <code>nn_linear</code> with the
number of classes inferred from the <code><a href="mlr3.html#topic+Task">Task</a></code>.
</p>
</li></ul>



<h3>Properties</h3>


<ul>
<li><p> Supported task types: <code>"classif"</code>
</p>
</li>
<li><p> Predict Types: <code>"response"</code> and <code>"prob"</code>
</p>
</li>
<li><p> Feature Types: <code>"lazy_tensor"</code>
</p>
</li>
<li><p> Required packages: <code>"mlr3torch"</code>, <code>"torch"</code>, <code>"torchvision"</code>
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3.html#topic+Learner">mlr3::Learner</a></code> -&gt; <code><a href="#topic+LearnerTorch">mlr3torch::LearnerTorch</a></code> -&gt; <code><a href="#topic+LearnerTorchImage">mlr3torch::LearnerTorchImage</a></code> -&gt; <code>LearnerTorchVision</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-LearnerTorchVision-new"><code>LearnerTorchVision$new()</code></a>
</p>
</li>
<li> <p><a href="#method-LearnerTorchVision-clone"><code>LearnerTorchVision$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="base_learner"><a href='../../mlr3/html/Learner.html#method-Learner-base_learner'><code>mlr3::Learner$base_learner()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="help"><a href='../../mlr3/html/Learner.html#method-Learner-help'><code>mlr3::Learner$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict"><a href='../../mlr3/html/Learner.html#method-Learner-predict'><code>mlr3::Learner$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="predict_newdata"><a href='../../mlr3/html/Learner.html#method-Learner-predict_newdata'><code>mlr3::Learner$predict_newdata()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="reset"><a href='../../mlr3/html/Learner.html#method-Learner-reset'><code>mlr3::Learner$reset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3" data-topic="Learner" data-id="train"><a href='../../mlr3/html/Learner.html#method-Learner-train'><code>mlr3::Learner$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="dataset"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-dataset'><code>mlr3torch::LearnerTorch$dataset()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="format"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-format'><code>mlr3torch::LearnerTorch$format()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="marshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-marshal'><code>mlr3torch::LearnerTorch$marshal()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="print"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-print'><code>mlr3torch::LearnerTorch$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="LearnerTorch" data-id="unmarshal"><a href='../../mlr3torch/html/LearnerTorch.html#method-LearnerTorch-unmarshal'><code>mlr3torch::LearnerTorch$unmarshal()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-LearnerTorchVision-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchVision$new(
  name,
  module_generator,
  label,
  optimizer = NULL,
  loss = NULL,
  callbacks = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>name</code></dt><dd><p>(<code>character(1)</code>)<br />
The name of the network.</p>
</dd>
<dt><code>module_generator</code></dt><dd><p>(<code style="white-space: pre;">&#8288;function(pretrained, num_classes)&#8288;</code>)<br />
Function that generates the network.</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
The label of the network.
#' @references
Krizhevsky, Alex, Sutskever, Ilya, Hinton, E. G (2017).
&ldquo;Imagenet classification with deep convolutional neural networks.&rdquo;
<em>Communications of the ACM</em>, <b>60</b>(6), 84&ndash;90.
Sandler, Mark, Howard, Andrew, Zhu, Menglong, Zhmoginov, Andrey, Chen, Liang-Chieh (2018).
&ldquo;Mobilenetv2: Inverted residuals and linear bottlenecks.&rdquo;
In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 4510&ndash;4520.
He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, Sun, Jian (2016 ).
&ldquo;Deep residual learning for image recognition .&rdquo;
In <em>Proceedings of the IEEE conference on computer vision and pattern recognition </em>, 770&ndash;778 .
Simonyan, Karen, Zisserman, Andrew (2014).
&ldquo;Very deep convolutional networks for large-scale image recognition.&rdquo;
<em>arXiv preprint arXiv:1409.1556</em>.</p>
</dd>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>)<br />
The optimizer to use for training.
Per default, <em>adam</em> is used.</p>
</dd>
<dt><code>loss</code></dt><dd><p>(<code><a href="#topic+TorchLoss">TorchLoss</a></code>)<br />
The loss used to train the network.
Per default, <em>mse</em> is used for regression and <em>cross_entropy</em> for classification.</p>
</dd>
<dt><code>callbacks</code></dt><dd><p>(<code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s)<br />
The callbacks. Must have unique ids.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-LearnerTorchVision-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LearnerTorchVision$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>



<hr>
<h2 id='mlr_pipeops_module'>Class for Torch Module Wrappers</h2><span id='topic+mlr_pipeops_module'></span><span id='topic+PipeOpModule'></span>

<h3>Description</h3>

<p><code>PipeOpModule</code> wraps an <code><a href="torch.html#topic+nn_module">nn_module</a></code> or <code>function</code> that is being called during the <code>train</code> phase of this
<code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code>. By doing so, this allows to assemble <code>PipeOpModule</code>s in a computational
<code><a href="mlr3pipelines.html#topic+Graph">mlr3pipelines::Graph</a></code> that represents either a neural network or a preprocessing graph of a <code><a href="#topic+lazy_tensor">lazy_tensor</a></code>.
In most cases it is easier to create such a network by creating a graph that generates this graph.
</p>
<p>In most cases it is easier to create such a network by creating a structurally related graph consisting
of nodes of class <code><a href="#topic+PipeOpTorchIngress">PipeOpTorchIngress</a></code> and <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>. This graph will then generate the graph consisting
of <code>PipeOpModule</code>s as part of the <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>The number and names of the input and output channels can be set during construction. They input and output
<code>"torch_tensor"</code> during training, and <code>NULL</code> during prediction as the prediction phase currently serves no
meaningful purpose.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code>shapes_out()</code>.
</p>


<h3>Parameters</h3>

<p>No parameters.
</p>


<h3>Internals</h3>

<p>During training, the wrapped <code><a href="torch.html#topic+nn_module">nn_module</a></code> / <code>function</code> is called with the provided inputs in the order in which
the channels are defined. Arguments are <strong>not</strong> matched by name.
</p>


<h3>Super class</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code>PipeOpModule</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>module</code></dt><dd><p>(<code><a href="torch.html#topic+nn_module">nn_module</a></code>)<br />
The torch module that is called during the training phase.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpModule-new"><code>PipeOpModule$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpModule-clone"><code>PipeOpModule$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpModule-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpModule$new(
  id = "module",
  module = nn_identity(),
  inname = "input",
  outname = "output",
  param_vals = list(),
  packages = character(0)
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</dd>
<dt><code>module</code></dt><dd><p>(<code><a href="torch.html#topic+nn_module">nn_module</a></code> or <code style="white-space: pre;">&#8288;function()&#8288;</code>)<br />
The torch module or function that is being wrapped.</p>
</dd>
<dt><code>inname</code></dt><dd><p>(<code>character()</code>)<br />
The names of the input channels.</p>
</dd>
<dt><code>outname</code></dt><dd><p>(<code>character()</code>)<br />
The names of the output channels. If this parameter has length 1, the parameter <a href="torch.html#topic+nn_module">module</a> must
return a <a href="torch.html#topic+torch_tensor">tensor</a>. Otherwise it must return a <code>list()</code> of tensors of corresponding length.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(named <code>list()</code>)<br />
Parameter values to be set after construction.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpModule-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpModule$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>
<p>Other PipeOp: 
<code><a href="#topic+mlr_pipeops_torch_callbacks">mlr_pipeops_torch_callbacks</a></code>,
<code><a href="#topic+mlr_pipeops_torch_optimizer">mlr_pipeops_torch_optimizer</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## creating an PipeOpModule manually

# one input and output channel
po_module = po("module",
  id = "linear",
  module = torch::nn_linear(10, 20),
  inname = "input",
  outname = "output"
)
x = torch::torch_randn(16, 10)
# This calls the forward function of the wrapped module.
y = po_module$train(list(input = x))
str(y)

# multiple input and output channels
nn_custom = torch::nn_module("nn_custom",
  initialize = function(in_features, out_features) {
    self$lin1 = torch::nn_linear(in_features, out_features)
    self$lin2 = torch::nn_linear(in_features, out_features)
  },
  forward = function(x, z) {
    list(out1 = self$lin1(x), out2 = torch::nnf_relu(self$lin2(z)))
  }
)

module = nn_custom(3, 2)
po_module = po("module",
  id = "custom",
  module = module,
  inname = c("x", "z"),
  outname = c("out1", "out2")
)
x = torch::torch_randn(1, 3)
z = torch::torch_randn(1, 3)
out = po_module$train(list(x = x, z = z))
str(out)

# How such a PipeOpModule is usually generated
graph = po("torch_ingress_num") %&gt;&gt;% po("nn_linear", out_features = 10L)
result = graph$train(tsk("iris"))
# The PipeOpTorchLinear generates a PipeOpModule and adds it to a new (module) graph
result[[1]]$graph
linear_module = result[[1L]]$graph$pipeops$nn_linear
linear_module
formalArgs(linear_module$module)
linear_module$input$name

# Constructing a PipeOpModule using a simple function
po_add1 = po("module",
  id = "add_one",
  module = function(x) x + 1
)
input = list(torch_tensor(1))
po_add1$train(input)$output

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_avg_pool1d'>1D Average Pooling</h2><span id='topic+mlr_pipeops_nn_avg_pool1d'></span><span id='topic+PipeOpTorchAvgPool1D'></span>

<h3>Description</h3>

<p>Applies a 1D adaptive average pooling over an input signal composed of
several input planes.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>kernel_size</code> :: (<code>integer()</code>)<br />
The size of the window. Can be a single number or a vector.
</p>
</li>
<li> <p><code>stride</code> :: <code>integer()</code><br />
The stride of the window. Can be a single number or a vector. Default: <code>kernel_size</code>.
</p>
</li>
<li> <p><code>padding</code> :: <code>integer()</code><br />
Implicit zero paddings on both sides of the input. Can be a single number or a vector. Default: 0.
</p>
</li>
<li> <p><code>ceil_mode</code> :: <code>integer()</code><br />
When <code>TRUE</code>, will use ceil instead of floor to compute the output shape. Default: <code>FALSE</code>.
</p>
</li>
<li> <p><code>count_include_pad</code> :: <code>logical(1)</code><br />
When <code>TRUE</code>, will include the zero-padding in the averaging calculation. Default: <code>TRUE</code>.
</p>
</li>
<li> <p><code>divisor_override</code> :: <code>logical(1)</code><br />
If specified, it will be used as divisor, otherwise size of the pooling region will be used. Default: NULL.
Only available for dimension greater than 1.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_avg_pool1d">nn_avg_pool1d()</a></code> during training.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchAvgPool</code> -&gt; <code>PipeOpTorchAvgPool1D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchAvgPool1D-new"><code>PipeOpTorchAvgPool1D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchAvgPool1D-clone"><code>PipeOpTorchAvgPool1D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchAvgPool1D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchAvgPool1D$new(id = "nn_avg_pool1d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchAvgPool1D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchAvgPool1D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_avg_pool1d")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_avg_pool2d'>2D Average Pooling</h2><span id='topic+mlr_pipeops_nn_avg_pool2d'></span><span id='topic+PipeOpTorchAvgPool2D'></span>

<h3>Description</h3>

<p>Applies a 2D adaptive average pooling over an input signal composed of
several input planes.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_avg_pool2d">nn_avg_pool2d()</a></code> during training.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>kernel_size</code> :: (<code>integer()</code>)<br />
The size of the window. Can be a single number or a vector.
</p>
</li>
<li> <p><code>stride</code> :: <code>integer()</code><br />
The stride of the window. Can be a single number or a vector. Default: <code>kernel_size</code>.
</p>
</li>
<li> <p><code>padding</code> :: <code>integer()</code><br />
Implicit zero paddings on both sides of the input. Can be a single number or a vector. Default: 0.
</p>
</li>
<li> <p><code>ceil_mode</code> :: <code>integer()</code><br />
When <code>TRUE</code>, will use ceil instead of floor to compute the output shape. Default: <code>FALSE</code>.
</p>
</li>
<li> <p><code>count_include_pad</code> :: <code>logical(1)</code><br />
When <code>TRUE</code>, will include the zero-padding in the averaging calculation. Default: <code>TRUE</code>.
</p>
</li>
<li> <p><code>divisor_override</code> :: <code>logical(1)</code><br />
If specified, it will be used as divisor, otherwise size of the pooling region will be used. Default: NULL.
Only available for dimension greater than 1.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchAvgPool</code> -&gt; <code>PipeOpTorchAvgPool2D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchAvgPool2D-new"><code>PipeOpTorchAvgPool2D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchAvgPool2D-clone"><code>PipeOpTorchAvgPool2D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchAvgPool2D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchAvgPool2D$new(id = "nn_avg_pool2d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchAvgPool2D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchAvgPool2D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_avg_pool2d")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_avg_pool3d'>3D Average Pooling</h2><span id='topic+mlr_pipeops_nn_avg_pool3d'></span><span id='topic+PipeOpTorchAvgPool3D'></span>

<h3>Description</h3>

<p>Applies a 3D adaptive average pooling over an input signal composed of
several input planes.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_avg_pool3d">nn_avg_pool3d()</a></code> during training.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>kernel_size</code> :: (<code>integer()</code>)<br />
The size of the window. Can be a single number or a vector.
</p>
</li>
<li> <p><code>stride</code> :: <code>integer()</code><br />
The stride of the window. Can be a single number or a vector. Default: <code>kernel_size</code>.
</p>
</li>
<li> <p><code>padding</code> :: <code>integer()</code><br />
Implicit zero paddings on both sides of the input. Can be a single number or a vector. Default: 0.
</p>
</li>
<li> <p><code>ceil_mode</code> :: <code>integer()</code><br />
When <code>TRUE</code>, will use ceil instead of floor to compute the output shape. Default: <code>FALSE</code>.
</p>
</li>
<li> <p><code>count_include_pad</code> :: <code>logical(1)</code><br />
When <code>TRUE</code>, will include the zero-padding in the averaging calculation. Default: <code>TRUE</code>.
</p>
</li>
<li> <p><code>divisor_override</code> :: <code>logical(1)</code><br />
If specified, it will be used as divisor, otherwise size of the pooling region will be used. Default: NULL.
Only available for dimension greater than 1.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchAvgPool</code> -&gt; <code>PipeOpTorchAvgPool3D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchAvgPool3D-new"><code>PipeOpTorchAvgPool3D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchAvgPool3D-clone"><code>PipeOpTorchAvgPool3D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchAvgPool3D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchAvgPool3D$new(id = "nn_avg_pool3d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchAvgPool3D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchAvgPool3D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_avg_pool3d")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_batch_norm1d'>1D Batch Normalization</h2><span id='topic+mlr_pipeops_nn_batch_norm1d'></span><span id='topic+PipeOpTorchBatchNorm1D'></span>

<h3>Description</h3>

<p>Applies Batch Normalization for each channel across a batch of data.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>eps</code> :: <code>numeric(1)</code><br />
A value added to the denominator for numerical stability. Default: <code>1e-5</code>.
</p>
</li>
<li> <p><code>momentum</code> :: <code>numeric(1)</code><br />
The value used for the running_mean and running_var computation. Can be set to <code>NULL</code> for cumulative moving average
(i.e. simple average). Default: 0.1
</p>
</li>
<li> <p><code>affine</code> :: <code>logical(1)</code><br />
a boolean value that when set to <code>TRUE</code>, this module has learnable affine parameters. Default: <code>TRUE</code>
</p>
</li>
<li> <p><code>track_running_stats</code> :: <code>logical(1)</code><br />
a boolean value that when set to <code>TRUE</code>, this module tracks the running mean and variance, and when set to <code>FALSE</code>,
this module does not track such statistics and always uses batch statistics in both training and eval modes.
Default: <code>TRUE</code>
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_batch_norm1d">torch::nn_batch_norm1d()</a></code>.
The parameter <code>num_features</code> is inferred as the second dimension of the input shape.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchBatchNorm</code> -&gt; <code>PipeOpTorchBatchNorm1D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchBatchNorm1D-new"><code>PipeOpTorchBatchNorm1D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchBatchNorm1D-clone"><code>PipeOpTorchBatchNorm1D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchBatchNorm1D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchBatchNorm1D$new(id = "nn_batch_norm1d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchBatchNorm1D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchBatchNorm1D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_batch_norm1d")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_batch_norm2d'>2D Batch Normalization</h2><span id='topic+mlr_pipeops_nn_batch_norm2d'></span><span id='topic+PipeOpTorchBatchNorm2D'></span>

<h3>Description</h3>

<p>Applies Batch Normalization for each channel across a batch of data.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_batch_norm2d">torch::nn_batch_norm2d()</a></code>.
The parameter <code>num_features</code> is inferred as the second dimension of the input shape.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>eps</code> :: <code>numeric(1)</code><br />
A value added to the denominator for numerical stability. Default: <code>1e-5</code>.
</p>
</li>
<li> <p><code>momentum</code> :: <code>numeric(1)</code><br />
The value used for the running_mean and running_var computation. Can be set to <code>NULL</code> for cumulative moving average
(i.e. simple average). Default: 0.1
</p>
</li>
<li> <p><code>affine</code> :: <code>logical(1)</code><br />
a boolean value that when set to <code>TRUE</code>, this module has learnable affine parameters. Default: <code>TRUE</code>
</p>
</li>
<li> <p><code>track_running_stats</code> :: <code>logical(1)</code><br />
a boolean value that when set to <code>TRUE</code>, this module tracks the running mean and variance, and when set to <code>FALSE</code>,
this module does not track such statistics and always uses batch statistics in both training and eval modes.
Default: <code>TRUE</code>
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchBatchNorm</code> -&gt; <code>PipeOpTorchBatchNorm2D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchBatchNorm2D-new"><code>PipeOpTorchBatchNorm2D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchBatchNorm2D-clone"><code>PipeOpTorchBatchNorm2D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchBatchNorm2D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchBatchNorm2D$new(id = "nn_batch_norm2d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchBatchNorm2D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchBatchNorm2D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_batch_norm2d")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_batch_norm3d'>3D Batch Normalization</h2><span id='topic+mlr_pipeops_nn_batch_norm3d'></span><span id='topic+PipeOpTorchBatchNorm3D'></span>

<h3>Description</h3>

<p>Applies Batch Normalization for each channel across a batch of data.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_batch_norm3d">torch::nn_batch_norm3d()</a></code>.
The parameter <code>num_features</code> is inferred as the second dimension of the input shape.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>eps</code> :: <code>numeric(1)</code><br />
A value added to the denominator for numerical stability. Default: <code>1e-5</code>.
</p>
</li>
<li> <p><code>momentum</code> :: <code>numeric(1)</code><br />
The value used for the running_mean and running_var computation. Can be set to <code>NULL</code> for cumulative moving average
(i.e. simple average). Default: 0.1
</p>
</li>
<li> <p><code>affine</code> :: <code>logical(1)</code><br />
a boolean value that when set to <code>TRUE</code>, this module has learnable affine parameters. Default: <code>TRUE</code>
</p>
</li>
<li> <p><code>track_running_stats</code> :: <code>logical(1)</code><br />
a boolean value that when set to <code>TRUE</code>, this module tracks the running mean and variance, and when set to <code>FALSE</code>,
this module does not track such statistics and always uses batch statistics in both training and eval modes.
Default: <code>TRUE</code>
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchBatchNorm</code> -&gt; <code>PipeOpTorchBatchNorm3D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchBatchNorm3D-new"><code>PipeOpTorchBatchNorm3D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchBatchNorm3D-clone"><code>PipeOpTorchBatchNorm3D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchBatchNorm3D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchBatchNorm3D$new(id = "nn_batch_norm3d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchBatchNorm3D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchBatchNorm3D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_batch_norm3d")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_block'>Block Repetition</h2><span id='topic+mlr_pipeops_nn_block'></span><span id='topic+PipeOpTorchBlock'></span>

<h3>Description</h3>

<p>Repeat a block <code>n_blocks</code> times.
</p>


<h3>Parameters</h3>

<p>The parameters available for the block itself, as well as
</p>

<ul>
<li> <p><code>n_blocks</code> :: <code>integer(1)</code><br />
How often to repeat the block.
</p>
</li></ul>



<h3>Input and Output Channels</h3>

<p>The <code>PipeOp</code> sets its input and output channels to those from the <code>block</code> (Graph)
it received during construction.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchBlock</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>block</code></dt><dd><p>(<code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code>)<br />
The neural network segment that is repeated by this <code>PipeOp</code>.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchBlock-new"><code>PipeOpTorchBlock$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchBlock-clone"><code>PipeOpTorchBlock$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchBlock-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchBlock$new(block, id = "nn_block", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>block</code></dt><dd><p>(<code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code>)<br />
A graph consisting primarily of <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code> objects that is to be
repeated.</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(named <code>list()</code>)<br />
Parameter values to be set after construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchBlock-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchBlock$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
block = po("nn_linear") %&gt;&gt;% po("nn_relu")
po_block = po("nn_block", block,
nn_linear.out_features = 10L, n_blocks = 3)
network = po("torch_ingress_num") %&gt;&gt;%
po_block %&gt;&gt;%
po("nn_head") %&gt;&gt;%
po("torch_loss", t_loss("cross_entropy")) %&gt;&gt;%
po("torch_optimizer", t_opt("adam")) %&gt;&gt;%
po("torch_model_classif",
  batch_size = 50,
  epochs = 3)

task = tsk("iris")
network$train(task)

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_celu'>CELU Activation Function</h2><span id='topic+mlr_pipeops_nn_celu'></span><span id='topic+PipeOpTorchCELU'></span>

<h3>Description</h3>

<p>Applies element-wise, <code class="reqn">CELU(x) = max(0,x) + min(0, \alpha * (exp(x \alpha) - 1))</code>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>alpha</code> :: <code>numeric(1)</code><br />
The alpha value for the ELU formulation. Default: 1.0
</p>
</li>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
Whether to do the operation in-place. Default: <code>FALSE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_celu">torch::nn_celu()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchCELU</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchCELU-new"><code>PipeOpTorchCELU$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchCELU-clone"><code>PipeOpTorchCELU$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchCELU-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchCELU$new(id = "nn_celu", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchCELU-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchCELU$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_celu")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_conv_transpose1d'>Transpose 1D Convolution</h2><span id='topic+mlr_pipeops_nn_conv_transpose1d'></span><span id='topic+PipeOpTorchConvTranspose1D'></span>

<h3>Description</h3>

<p>Transpose 1D Convolution
</p>
<p>Transpose 1D Convolution
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>out_channels</code> :: <code>integer(1)</code><br />
Number of output channels produce by the convolution.
</p>
</li>
<li> <p><code>kernel_size</code> :: <code>integer()</code><br />
Size of the convolving kernel.
</p>
</li>
<li> <p><code>stride</code> :: <code>integer()</code><br />
Stride of the convolution. Default: 1.
</p>
</li>
<li> <p><code>padding</code> :: <code style="white-space: pre;">&#8288; &#8288;</code>integer()'<br />
‘dilation * (kernel_size - 1) - padding’ zero-padding will be added to both sides of the input. Default: 0.
</p>
</li>
<li> <p><code>output_padding</code> ::<code>integer()</code><br />
Additional size added to one side of the output shape. Default: 0.
</p>
</li>
<li> <p><code>groups</code> :: <code>integer()</code><br />
Number of blocked connections from input channels to output channels. Default: 1
</p>
</li>
<li> <p><code>bias</code> :: <code>logical(1)</code><br />
If ‘True’, adds a learnable bias to the output. Default: ‘TRUE’.
</p>
</li>
<li> <p><code>dilation</code> :: <code>integer()</code><br />
Spacing between kernel elements. Default: 1.
</p>
</li>
<li> <p><code>padding_mode</code> :: <code>character(1)</code><br />
The padding mode. One of <code>"zeros"</code>, <code>"reflect"</code>, <code>"replicate"</code>, or <code>"circular"</code>. Default is <code>"zeros"</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_conv_transpose1d">nn_conv_transpose1d</a></code>.
The parameter <code>in_channels</code> is inferred as the second dimension of the input tensor.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchConvTranspose</code> -&gt; <code>PipeOpTorchConvTranspose1D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchConvTranspose1D-new"><code>PipeOpTorchConvTranspose1D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchConvTranspose1D-clone"><code>PipeOpTorchConvTranspose1D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchConvTranspose1D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConvTranspose1D$new(id = "nn_conv_transpose1d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchConvTranspose1D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConvTranspose1D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_conv_transpose1d", kernel_size = 3, out_channels = 2)
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_conv_transpose2d'>Transpose 2D Convolution</h2><span id='topic+mlr_pipeops_nn_conv_transpose2d'></span><span id='topic+PipeOpTorchConvTranspose2D'></span>

<h3>Description</h3>

<p>Applies a 2D transposed convolution operator over an input image
composed of several input planes, sometimes also called &quot;deconvolution&quot;.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_conv_transpose2d">nn_conv_transpose2d</a></code>.
The parameter <code>in_channels</code> is inferred as the second dimension of the input tensor.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>out_channels</code> :: <code>integer(1)</code><br />
Number of output channels produce by the convolution.
</p>
</li>
<li> <p><code>kernel_size</code> :: <code>integer()</code><br />
Size of the convolving kernel.
</p>
</li>
<li> <p><code>stride</code> :: <code>integer()</code><br />
Stride of the convolution. Default: 1.
</p>
</li>
<li> <p><code>padding</code> :: <code style="white-space: pre;">&#8288; &#8288;</code>integer()'<br />
‘dilation * (kernel_size - 1) - padding’ zero-padding will be added to both sides of the input. Default: 0.
</p>
</li>
<li> <p><code>output_padding</code> ::<code>integer()</code><br />
Additional size added to one side of the output shape. Default: 0.
</p>
</li>
<li> <p><code>groups</code> :: <code>integer()</code><br />
Number of blocked connections from input channels to output channels. Default: 1
</p>
</li>
<li> <p><code>bias</code> :: <code>logical(1)</code><br />
If ‘True’, adds a learnable bias to the output. Default: ‘TRUE’.
</p>
</li>
<li> <p><code>dilation</code> :: <code>integer()</code><br />
Spacing between kernel elements. Default: 1.
</p>
</li>
<li> <p><code>padding_mode</code> :: <code>character(1)</code><br />
The padding mode. One of <code>"zeros"</code>, <code>"reflect"</code>, <code>"replicate"</code>, or <code>"circular"</code>. Default is <code>"zeros"</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchConvTranspose</code> -&gt; <code>PipeOpTorchConvTranspose2D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchConvTranspose2D-new"><code>PipeOpTorchConvTranspose2D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchConvTranspose2D-clone"><code>PipeOpTorchConvTranspose2D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchConvTranspose2D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConvTranspose2D$new(id = "nn_conv_transpose2d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchConvTranspose2D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConvTranspose2D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_conv_transpose2d", kernel_size = 3, out_channels = 2)
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_conv_transpose3d'>Transpose 3D Convolution</h2><span id='topic+mlr_pipeops_nn_conv_transpose3d'></span><span id='topic+PipeOpTorchConvTranspose3D'></span>

<h3>Description</h3>

<p>Applies a 3D transposed convolution operator over an input image
composed of several input planes, sometimes also called &quot;deconvolution&quot;
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_conv_transpose3d">nn_conv_transpose3d</a></code>.
The parameter <code>in_channels</code> is inferred as the second dimension of the input tensor.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>out_channels</code> :: <code>integer(1)</code><br />
Number of output channels produce by the convolution.
</p>
</li>
<li> <p><code>kernel_size</code> :: <code>integer()</code><br />
Size of the convolving kernel.
</p>
</li>
<li> <p><code>stride</code> :: <code>integer()</code><br />
Stride of the convolution. Default: 1.
</p>
</li>
<li> <p><code>padding</code> :: <code style="white-space: pre;">&#8288; &#8288;</code>integer()'<br />
‘dilation * (kernel_size - 1) - padding’ zero-padding will be added to both sides of the input. Default: 0.
</p>
</li>
<li> <p><code>output_padding</code> ::<code>integer()</code><br />
Additional size added to one side of the output shape. Default: 0.
</p>
</li>
<li> <p><code>groups</code> :: <code>integer()</code><br />
Number of blocked connections from input channels to output channels. Default: 1
</p>
</li>
<li> <p><code>bias</code> :: <code>logical(1)</code><br />
If ‘True’, adds a learnable bias to the output. Default: ‘TRUE’.
</p>
</li>
<li> <p><code>dilation</code> :: <code>integer()</code><br />
Spacing between kernel elements. Default: 1.
</p>
</li>
<li> <p><code>padding_mode</code> :: <code>character(1)</code><br />
The padding mode. One of <code>"zeros"</code>, <code>"reflect"</code>, <code>"replicate"</code>, or <code>"circular"</code>. Default is <code>"zeros"</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchConvTranspose</code> -&gt; <code>PipeOpTorchConvTranspose3D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchConvTranspose3D-new"><code>PipeOpTorchConvTranspose3D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchConvTranspose3D-clone"><code>PipeOpTorchConvTranspose3D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchConvTranspose3D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConvTranspose3D$new(id = "nn_conv_transpose3d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchConvTranspose3D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConvTranspose3D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_conv_transpose3d", kernel_size = 3, out_channels = 2)
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_conv1d'>1D Convolution</h2><span id='topic+mlr_pipeops_nn_conv1d'></span><span id='topic+PipeOpTorchConv1D'></span>

<h3>Description</h3>

<p>Applies a 1D convolution over an input signal composed of several input
planes.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>out_channels</code> :: <code>integer(1)</code><br />
Number of channels produced by the convolution.
</p>
</li>
<li> <p><code>kernel_size</code> :: <code>integer()</code><br />
Size of the convolving kernel.
</p>
</li>
<li> <p><code>stride</code> :: <code>integer()</code><br />
Stride of the convolution. The default is 1.
</p>
</li>
<li> <p><code>padding</code> :: <code>integer()</code><br />
‘dilation * (kernel_size - 1) - padding’ zero-padding will be added to both sides of the input. Default: 0.
</p>
</li>
<li> <p><code>groups</code> :: <code>integer()</code><br />
Number of blocked connections from input channels to output channels. Default: 1
</p>
</li>
<li> <p><code>bias</code> :: <code>logical(1)</code><br />
If ‘TRUE’, adds a learnable bias to the output. Default: ‘TRUE’.
</p>
</li>
<li> <p><code>dilation</code> :: <code>integer()</code><br />
Spacing between kernel elements. Default: 1.
</p>
</li>
<li> <p><code>padding_mode</code> :: <code>character(1)</code><br />
The padding mode. One of <code>"zeros"</code>, <code>"reflect"</code>, <code>"replicate"</code>, or <code>"circular"</code>. Default is <code>"zeros"</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_conv1d">torch::nn_conv1d()</a></code> when trained.
The paramter <code>in_channels</code> is inferred from the second dimension of the input tensor.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchConv</code> -&gt; <code>PipeOpTorchConv1D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchConv1D-new"><code>PipeOpTorchConv1D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchConv1D-clone"><code>PipeOpTorchConv1D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchConv1D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConv1D$new(id = "nn_conv1d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchConv1D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConv1D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_conv1d", kernel_size = 10, out_channels = 1)
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_conv2d'>2D Convolution</h2><span id='topic+mlr_pipeops_nn_conv2d'></span><span id='topic+PipeOpTorchConv2D'></span>

<h3>Description</h3>

<p>Applies a 2D convolution over an input image composed of several input
planes.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_conv2d">torch::nn_conv2d()</a></code> when trained.
The paramter <code>in_channels</code> is inferred from the second dimension of the input tensor.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>out_channels</code> :: <code>integer(1)</code><br />
Number of channels produced by the convolution.
</p>
</li>
<li> <p><code>kernel_size</code> :: <code>integer()</code><br />
Size of the convolving kernel.
</p>
</li>
<li> <p><code>stride</code> :: <code>integer()</code><br />
Stride of the convolution. The default is 1.
</p>
</li>
<li> <p><code>padding</code> :: <code>integer()</code><br />
‘dilation * (kernel_size - 1) - padding’ zero-padding will be added to both sides of the input. Default: 0.
</p>
</li>
<li> <p><code>groups</code> :: <code>integer()</code><br />
Number of blocked connections from input channels to output channels. Default: 1
</p>
</li>
<li> <p><code>bias</code> :: <code>logical(1)</code><br />
If ‘TRUE’, adds a learnable bias to the output. Default: ‘TRUE’.
</p>
</li>
<li> <p><code>dilation</code> :: <code>integer()</code><br />
Spacing between kernel elements. Default: 1.
</p>
</li>
<li> <p><code>padding_mode</code> :: <code>character(1)</code><br />
The padding mode. One of <code>"zeros"</code>, <code>"reflect"</code>, <code>"replicate"</code>, or <code>"circular"</code>. Default is <code>"zeros"</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchConv</code> -&gt; <code>PipeOpTorchConv2D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchConv2D-new"><code>PipeOpTorchConv2D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchConv2D-clone"><code>PipeOpTorchConv2D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchConv2D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConv2D$new(id = "nn_conv2d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchConv2D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConv2D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_conv2d", kernel_size = 10, out_channels = 1)
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_conv3d'>3D Convolution</h2><span id='topic+mlr_pipeops_nn_conv3d'></span><span id='topic+PipeOpTorchConv3D'></span>

<h3>Description</h3>

<p>Applies a 3D convolution over an input image composed of several input
planes.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_conv3d">torch::nn_conv3d()</a></code> when trained.
The paramter <code>in_channels</code> is inferred from the second dimension of the input tensor.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>out_channels</code> :: <code>integer(1)</code><br />
Number of channels produced by the convolution.
</p>
</li>
<li> <p><code>kernel_size</code> :: <code>integer()</code><br />
Size of the convolving kernel.
</p>
</li>
<li> <p><code>stride</code> :: <code>integer()</code><br />
Stride of the convolution. The default is 1.
</p>
</li>
<li> <p><code>padding</code> :: <code>integer()</code><br />
‘dilation * (kernel_size - 1) - padding’ zero-padding will be added to both sides of the input. Default: 0.
</p>
</li>
<li> <p><code>groups</code> :: <code>integer()</code><br />
Number of blocked connections from input channels to output channels. Default: 1
</p>
</li>
<li> <p><code>bias</code> :: <code>logical(1)</code><br />
If ‘TRUE’, adds a learnable bias to the output. Default: ‘TRUE’.
</p>
</li>
<li> <p><code>dilation</code> :: <code>integer()</code><br />
Spacing between kernel elements. Default: 1.
</p>
</li>
<li> <p><code>padding_mode</code> :: <code>character(1)</code><br />
The padding mode. One of <code>"zeros"</code>, <code>"reflect"</code>, <code>"replicate"</code>, or <code>"circular"</code>. Default is <code>"zeros"</code>.
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchConv</code> -&gt; <code>PipeOpTorchConv3D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchConv3D-new"><code>PipeOpTorchConv3D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchConv3D-clone"><code>PipeOpTorchConv3D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchConv3D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConv3D$new(id = "nn_conv3d", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchConv3D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchConv3D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_conv3d", kernel_size = 10, out_channels = 1)
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_dropout'>Dropout</h2><span id='topic+mlr_pipeops_nn_dropout'></span><span id='topic+PipeOpTorchDropout'></span>

<h3>Description</h3>

<p>During training, randomly zeroes some of the elements of the input
tensor with probability <code>p</code> using samples from a Bernoulli
distribution.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>p</code> :: <code>numeric(1)</code><br />
Probability of an element to be zeroed. Default: 0.5 inplace
</p>
</li>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
If set to <code>TRUE</code>, will do this operation in-place. Default: <code>FALSE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_dropout">torch::nn_dropout()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchDropout</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchDropout-new"><code>PipeOpTorchDropout$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchDropout-clone"><code>PipeOpTorchDropout$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchDropout-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchDropout$new(id = "nn_dropout", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchDropout-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchDropout$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_dropout")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_elu'>ELU Activation Function</h2><span id='topic+mlr_pipeops_nn_elu'></span><span id='topic+PipeOpTorchELU'></span>

<h3>Description</h3>

<p>Applies element-wise,
</p>
<p style="text-align: center;"><code class="reqn">ELU(x) = max(0,x) + min(0, \alpha * (exp(x) - 1))</code>
</p>
<p>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>alpha</code> :: <code>numeric(1)</code><br />
The alpha value for the ELU formulation. Default: 1.0
</p>
</li>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
Whether to do the operation in-place. Default: <code>FALSE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_elu">torch::nn_elu()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchELU</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchELU-new"><code>PipeOpTorchELU$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchELU-clone"><code>PipeOpTorchELU$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchELU-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchELU$new(id = "nn_elu", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchELU-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchELU$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_elu")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_flatten'>Flattens a Tensor</h2><span id='topic+mlr_pipeops_nn_flatten'></span><span id='topic+PipeOpTorchFlatten'></span>

<h3>Description</h3>

<p>For use with <a href="torch.html#topic+nn_sequential">nn_sequential</a>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>

<p><code>start_dim</code> :: <code>integer(1)</code><br />
At wich dimension to start flattening. Default is 2.
<code>end_dim</code> :: <code>integer(1)</code><br />
At wich dimension to stop flattening. Default is -1.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_flatten">torch::nn_flatten()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchFlatten</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchFlatten-new"><code>PipeOpTorchFlatten$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchFlatten-clone"><code>PipeOpTorchFlatten$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchFlatten-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchFlatten$new(id = "nn_flatten", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchFlatten-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchFlatten$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_flatten")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_gelu'>GELU Activation Function</h2><span id='topic+mlr_pipeops_nn_gelu'></span><span id='topic+PipeOpTorchGELU'></span>

<h3>Description</h3>

<p>Gelu
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>approximate</code> :: <code>character(1)</code><br />
Whether to use an approximation algorithm. Default is <code>"none"</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_gelu">torch::nn_gelu()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchGELU</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchGELU-new"><code>PipeOpTorchGELU$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchGELU-clone"><code>PipeOpTorchGELU$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchGELU-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchGELU$new(id = "nn_gelu", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchGELU-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchGELU$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_gelu")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_glu'>GLU Activation Function</h2><span id='topic+mlr_pipeops_nn_glu'></span><span id='topic+PipeOpTorchGLU'></span>

<h3>Description</h3>

<p>The gated linear unit. Computes:
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>dim</code> :: <code>integer(1)</code><br />
Dimension on which to split the input. Default: -1
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_glu">torch::nn_glu()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchGLU</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchGLU-new"><code>PipeOpTorchGLU$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchGLU-clone"><code>PipeOpTorchGLU$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchGLU-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchGLU$new(id = "nn_glu", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchGLU-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchGLU$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_glu")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_hardshrink'>Hard Shrink Activation Function</h2><span id='topic+mlr_pipeops_nn_hardshrink'></span><span id='topic+PipeOpTorchHardShrink'></span>

<h3>Description</h3>

<p>Applies the hard shrinkage function element-wise
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>lambd</code> :: <code>numeric(1)</code><br />
The lambda value for the Hardshrink formulation formulation. Default 0.5.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_hardshrink">torch::nn_hardshrink()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchHardShrink</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchHardShrink-new"><code>PipeOpTorchHardShrink$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchHardShrink-clone"><code>PipeOpTorchHardShrink$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchHardShrink-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchHardShrink$new(id = "nn_hardshrink", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchHardShrink-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchHardShrink$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_hardshrink")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_hardsigmoid'>Hard Sigmoid Activation Function</h2><span id='topic+mlr_pipeops_nn_hardsigmoid'></span><span id='topic+PipeOpTorchHardSigmoid'></span>

<h3>Description</h3>

<p>Applies the element-wise function <code class="reqn">\mbox{Hardsigmoid}(x) = \frac{ReLU6(x + 3)}{6}</code>
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>

<p>No parameters.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_hardsigmoid">torch::nn_hardsigmoid()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchHardSigmoid</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchHardSigmoid-new"><code>PipeOpTorchHardSigmoid$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchHardSigmoid-clone"><code>PipeOpTorchHardSigmoid$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchHardSigmoid-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchHardSigmoid$new(id = "nn_hardsigmoid", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchHardSigmoid-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchHardSigmoid$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_hardsigmoid")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_hardtanh'>Hard Tanh Activation Function</h2><span id='topic+mlr_pipeops_nn_hardtanh'></span><span id='topic+PipeOpTorchHardTanh'></span>

<h3>Description</h3>

<p>Applies the HardTanh function element-wise.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>min_val</code> :: <code>numeric(1)</code><br />
Minimum value of the linear region range. Default: -1.
</p>
</li>
<li> <p><code>max_val</code> :: <code>numeric(1)</code><br />
Maximum value of the linear region range. Default: 1.
</p>
</li>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
Can optionally do the operation in-place. Default: <code>FALSE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_hardtanh">torch::nn_hardtanh()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchHardTanh</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchHardTanh-new"><code>PipeOpTorchHardTanh$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchHardTanh-clone"><code>PipeOpTorchHardTanh$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchHardTanh-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchHardTanh$new(id = "nn_hardtanh", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchHardTanh-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchHardTanh$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_hardtanh")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_head'>Output Head</h2><span id='topic+mlr_pipeops_nn_head'></span><span id='topic+PipeOpTorchHead'></span>

<h3>Description</h3>

<p>Output head for classification and regresssion.
</p>
<p><strong>NOTE</strong>
Because the method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code> does not have access to the task, it returns <code>c(NA, NA)</code>.
When this <code><a href="mlr3pipelines.html#topic+PipeOp">PipeOp</a></code> is trained however, the model descriptor has the correct output shape.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>bias</code> :: <code>logical(1)</code><br />
Whether to use a bias. Default is <code>TRUE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_linear">torch::nn_linear()</a></code> with the input and output features inferred from the input shape / task.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchHead</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchHead-new"><code>PipeOpTorchHead$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchHead-clone"><code>PipeOpTorchHead$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchHead-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchHead$new(id = "nn_head", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchHead-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchHead$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_head")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_layer_norm'>Layer Normalization</h2><span id='topic+mlr_pipeops_nn_layer_norm'></span><span id='topic+PipeOpTorchLayerNorm'></span>

<h3>Description</h3>

<p>Applies Layer Normalization for last certain number of dimensions.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>dims</code> :: <code>integer(1)</code><br />
The number of dimensions over which will be normalized (starting from the last dimension).
</p>
</li>
<li> <p><code>elementwise_affine</code> :: <code>logical(1)</code><br />
Whether to learn affine-linear parameters initialized to <code>1</code> for weights and to <code>0</code> for biases.
The default is <code>TRUE</code>.
</p>
</li>
<li> <p><code>eps</code> :: <code>numeric(1)</code><br />
A value added to the denominator for numerical stability.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_layer_norm">torch::nn_layer_norm()</a></code> when trained.
The parameter <code>normalized_shape</code> is inferred as the dimensions of the last <code>dims</code> dimensions of the input shape.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchLayerNorm</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchLayerNorm-new"><code>PipeOpTorchLayerNorm$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchLayerNorm-clone"><code>PipeOpTorchLayerNorm$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchLayerNorm-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLayerNorm$new(id = "nn_layer_norm", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchLayerNorm-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLayerNorm$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_layer_norm", dims = 1)
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_leaky_relu'>Leaky ReLU Activation Function</h2><span id='topic+mlr_pipeops_nn_leaky_relu'></span><span id='topic+PipeOpTorchLeakyReLU'></span>

<h3>Description</h3>

<p>Applies element-wise,
<code class="reqn">LeakyReLU(x) = max(0, x) + negative_slope * min(0, x)</code>
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>negative_slope</code> :: <code>numeric(1)</code><br />
Controls the angle of the negative slope. Default: 1e-2.
</p>
</li>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
Can optionally do the operation in-place. Default: ‘FALSE’.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_hardswish">torch::nn_hardswish()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchLeakyReLU</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchLeakyReLU-new"><code>PipeOpTorchLeakyReLU$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchLeakyReLU-clone"><code>PipeOpTorchLeakyReLU$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchLeakyReLU-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLeakyReLU$new(id = "nn_leaky_relu", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchLeakyReLU-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLeakyReLU$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_leaky_relu")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_linear'>Linear Layer</h2><span id='topic+mlr_pipeops_nn_linear'></span><span id='topic+PipeOpTorchLinear'></span>

<h3>Description</h3>

<p>Applies a linear transformation to the incoming data: <code class="reqn">y = xA^T + b</code>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>out_features</code> :: <code>integer(1)</code><br />
The output features of the linear layer.
</p>
</li>
<li> <p><code>bias</code> :: <code>logical(1)</code><br />
Whether to use a bias.
Default is <code>TRUE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_linear">torch::nn_linear()</a></code> when trained where the parameter <code>in_features</code> is inferred as the second
to last dimension of the input tensor.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchLinear</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchLinear-new"><code>PipeOpTorchLinear$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchLinear-clone"><code>PipeOpTorchLinear$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchLinear-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLinear$new(id = "nn_linear", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchLinear-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLinear$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_linear", out_features = 10)
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_log_sigmoid'>Log Sigmoid Activation Function</h2><span id='topic+mlr_pipeops_nn_log_sigmoid'></span><span id='topic+PipeOpTorchLogSigmoid'></span>

<h3>Description</h3>

<p>Applies element-wise <code class="reqn">LogSigmoid(x_i) = log(\frac{1}{1 + exp(-x_i)})</code>
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>

<p>No parameters.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_log_sigmoid">torch::nn_log_sigmoid()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchLogSigmoid</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchLogSigmoid-new"><code>PipeOpTorchLogSigmoid$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchLogSigmoid-clone"><code>PipeOpTorchLogSigmoid$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchLogSigmoid-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLogSigmoid$new(id = "nn_log_sigmoid", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchLogSigmoid-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLogSigmoid$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_log_sigmoid")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_max_pool1d'>1D Max Pooling</h2><span id='topic+mlr_pipeops_nn_max_pool1d'></span><span id='topic+PipeOpTorchMaxPool1D'></span>

<h3>Description</h3>

<p>Applies a 1D max pooling over an input signal composed of several input
planes.
</p>


<h3>Input and Output Channels</h3>

<p>If <code>return_indices</code> is <code>FALSE</code> during construction, there is one input channel 'input' and one output channel 'output'.
If <code>return_indices</code> is <code>TRUE</code>, there are two output channels 'output' and 'indices'.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>kernel_size</code> :: <code>integer()</code><br />
The size of the window. Can be single number or a vector.
</p>
</li>
<li> <p><code>stride</code> :: (<code style="white-space: pre;">&#8288;integer(1))&#8288;</code><br />
The stride of the window. Can be a single number or a vector. Default: <code>kernel_size</code>
</p>
</li>
<li> <p><code>padding</code> :: <code>integer()</code><br />
Implicit zero paddings on both sides of the input. Can be a single number or a tuple (padW,). Default: 0
</p>
</li>
<li> <p><code>dilation</code> :: <code>integer()</code><br />
Controls the spacing between the kernel points; also known as the à trous algorithm. Default: 1
</p>
</li>
<li> <p><code>ceil_mode</code> :: <code>logical(1)</code><br />
When True, will use ceil instead of floor to compute the output shape. Default: <code>FALSE</code>
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_max_pool1d">torch::nn_max_pool1d()</a></code> during training.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchMaxPool</code> -&gt; <code>PipeOpTorchMaxPool1D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchMaxPool1D-new"><code>PipeOpTorchMaxPool1D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchMaxPool1D-clone"><code>PipeOpTorchMaxPool1D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchMaxPool1D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMaxPool1D$new(
  id = "nn_max_pool1d",
  return_indices = FALSE,
  param_vals = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>return_indices</code></dt><dd><p>(<code>logical(1)</code>)<br />
Whether to return the indices.
If this is <code>TRUE</code>, there are two output channels <code>"output"</code> and <code>"indices"</code>.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchMaxPool1D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMaxPool1D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_max_pool1d")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_max_pool2d'>2D Max Pooling</h2><span id='topic+mlr_pipeops_nn_max_pool2d'></span><span id='topic+PipeOpTorchMaxPool2D'></span>

<h3>Description</h3>

<p>Applies a 2D max pooling over an input signal composed of several input
planes.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_max_pool2d">torch::nn_max_pool2d()</a></code> during training.
</p>


<h3>Input and Output Channels</h3>

<p>If <code>return_indices</code> is <code>FALSE</code> during construction, there is one input channel 'input' and one output channel 'output'.
If <code>return_indices</code> is <code>TRUE</code>, there are two output channels 'output' and 'indices'.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>kernel_size</code> :: <code>integer()</code><br />
The size of the window. Can be single number or a vector.
</p>
</li>
<li> <p><code>stride</code> :: (<code style="white-space: pre;">&#8288;integer(1))&#8288;</code><br />
The stride of the window. Can be a single number or a vector. Default: <code>kernel_size</code>
</p>
</li>
<li> <p><code>padding</code> :: <code>integer()</code><br />
Implicit zero paddings on both sides of the input. Can be a single number or a tuple (padW,). Default: 0
</p>
</li>
<li> <p><code>dilation</code> :: <code>integer()</code><br />
Controls the spacing between the kernel points; also known as the à trous algorithm. Default: 1
</p>
</li>
<li> <p><code>ceil_mode</code> :: <code>logical(1)</code><br />
When True, will use ceil instead of floor to compute the output shape. Default: <code>FALSE</code>
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchMaxPool</code> -&gt; <code>PipeOpTorchMaxPool2D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchMaxPool2D-new"><code>PipeOpTorchMaxPool2D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchMaxPool2D-clone"><code>PipeOpTorchMaxPool2D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchMaxPool2D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMaxPool2D$new(
  id = "nn_max_pool2d",
  return_indices = FALSE,
  param_vals = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>return_indices</code></dt><dd><p>(<code>logical(1)</code>)<br />
Whether to return the indices.
If this is <code>TRUE</code>, there are two output channels <code>"output"</code> and <code>"indices"</code>.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchMaxPool2D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMaxPool2D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_max_pool2d")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_max_pool3d'>3D Max Pooling</h2><span id='topic+mlr_pipeops_nn_max_pool3d'></span><span id='topic+PipeOpTorchMaxPool3D'></span>

<h3>Description</h3>

<p>Applies a 3D max pooling over an input signal composed of several input
planes.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_max_pool3d">torch::nn_max_pool3d()</a></code> during training.
</p>


<h3>Input and Output Channels</h3>

<p>If <code>return_indices</code> is <code>FALSE</code> during construction, there is one input channel 'input' and one output channel 'output'.
If <code>return_indices</code> is <code>TRUE</code>, there are two output channels 'output' and 'indices'.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>kernel_size</code> :: <code>integer()</code><br />
The size of the window. Can be single number or a vector.
</p>
</li>
<li> <p><code>stride</code> :: (<code style="white-space: pre;">&#8288;integer(1))&#8288;</code><br />
The stride of the window. Can be a single number or a vector. Default: <code>kernel_size</code>
</p>
</li>
<li> <p><code>padding</code> :: <code>integer()</code><br />
Implicit zero paddings on both sides of the input. Can be a single number or a tuple (padW,). Default: 0
</p>
</li>
<li> <p><code>dilation</code> :: <code>integer()</code><br />
Controls the spacing between the kernel points; also known as the à trous algorithm. Default: 1
</p>
</li>
<li> <p><code>ceil_mode</code> :: <code>logical(1)</code><br />
When True, will use ceil instead of floor to compute the output shape. Default: <code>FALSE</code>
</p>
</li></ul>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>mlr3torch::PipeOpTorchMaxPool</code> -&gt; <code>PipeOpTorchMaxPool3D</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchMaxPool3D-new"><code>PipeOpTorchMaxPool3D$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchMaxPool3D-clone"><code>PipeOpTorchMaxPool3D$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchMaxPool3D-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMaxPool3D$new(
  id = "nn_max_pool3d",
  return_indices = FALSE,
  param_vals = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>return_indices</code></dt><dd><p>(<code>logical(1)</code>)<br />
Whether to return the indices.
If this is <code>TRUE</code>, there are two output channels <code>"output"</code> and <code>"indices"</code>.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchMaxPool3D-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMaxPool3D$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_max_pool3d")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_merge'>Merge Operation</h2><span id='topic+mlr_pipeops_nn_merge'></span><span id='topic+PipeOpTorchMerge'></span>

<h3>Description</h3>

<p>Base class for merge operations such as addition (<code><a href="#topic+PipeOpTorchMergeSum">PipeOpTorchMergeSum</a></code>), multiplication
(<code><a href="#topic+PipeOpTorchMergeProd">PipeOpTorchMergeProd</a></code> or concatenation (<code><a href="#topic+PipeOpTorchMergeCat">PipeOpTorchMergeCat</a></code>).
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code>shapes_out()</code>.
</p>


<h3>Input and Output Channels</h3>

<p><code>PipeOpTorchMerge</code>s has either a <em>vararg</em> input channel if the constructor argument <code>innum</code> is not set, or
input channels <code>"input1"</code>, ..., <code>"input&lt;innum&gt;"</code>. There is one output channel <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>Parameters</h3>

<p>See the respective child class.
</p>


<h3>Internals</h3>

<p>Per default, the <code>private$.shapes_out()</code> method outputs the broadcasted tensors. There are two things to be aware:
</p>

<ol>
<li> <p><code>NA</code>s are assumed to batch (this should almost always be the batch size in the first dimension).
</p>
</li>
<li><p> Tensors are expected to have the same number of dimensions, i.e. missing dimensions are not filled with 1s.
The reason is that again that the first dimension should be the batch dimension.
This private method can be overwritten by <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>s inheriting from this class.
</p>
</li></ol>



<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchMerge</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchMerge-new"><code>PipeOpTorchMerge$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchMerge-clone"><code>PipeOpTorchMerge$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchMerge-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMerge$new(
  id,
  module_generator,
  param_set = ps(),
  innum = 0,
  param_vals = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>module_generator</code></dt><dd><p>(<code>nn_module_generator</code>)<br />
The torch module generator.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>)<br />
The parameter set.</p>
</dd>
<dt><code>innum</code></dt><dd><p>(<code>integer(1)</code>)<br />
The number of inputs. Default is 0 which means there is one <em>vararg</em> input channel.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchMerge-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMerge$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>

<hr>
<h2 id='mlr_pipeops_nn_merge_cat'>Merge by Concatenation</h2><span id='topic+mlr_pipeops_nn_merge_cat'></span><span id='topic+PipeOpTorchMergeCat'></span>

<h3>Description</h3>

<p>Concatenates multiple tensors on a given dimension.
No broadcasting rules are applied here, you must reshape the tensors before to have the same shape.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>
<p><code>PipeOpTorchMerge</code>s has either a <em>vararg</em> input channel if the constructor argument <code>innum</code> is not set, or
input channels <code>"input1"</code>, ..., <code>"input&lt;innum&gt;"</code>. There is one output channel <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>dim</code> :: <code>integer(1)</code><br />
The dimension along which to concatenate the tensors.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="#topic+nn_merge_cat">nn_merge_cat()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code><a href="#topic+PipeOpTorchMerge">mlr3torch::PipeOpTorchMerge</a></code> -&gt; <code>PipeOpTorchMergeCat</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchMergeCat-new"><code>PipeOpTorchMergeCat$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchMergeCat-speak"><code>PipeOpTorchMergeCat$speak()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchMergeCat-clone"><code>PipeOpTorchMergeCat$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchMergeCat-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMergeCat$new(id = "nn_merge_cat", innum = 0, param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>innum</code></dt><dd><p>(<code>integer(1)</code>)<br />
The number of inputs. Default is 0 which means there is one <em>vararg</em> input channel.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchMergeCat-speak"></a>



<h4>Method <code>speak()</code></h4>

<p>What does the cat say?
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMergeCat$speak()</pre></div>


<hr>
<a id="method-PipeOpTorchMergeCat-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMergeCat$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_merge_cat")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_merge_prod'>Merge by Product</h2><span id='topic+mlr_pipeops_nn_merge_prod'></span><span id='topic+PipeOpTorchMergeProd'></span>

<h3>Description</h3>

<p>Calculates the product of all input tensors.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>
<p><code>PipeOpTorchMerge</code>s has either a <em>vararg</em> input channel if the constructor argument <code>innum</code> is not set, or
input channels <code>"input1"</code>, ..., <code>"input&lt;innum&gt;"</code>. There is one output channel <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>

<p>No parameters.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="#topic+nn_merge_prod">nn_merge_prod()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code><a href="#topic+PipeOpTorchMerge">mlr3torch::PipeOpTorchMerge</a></code> -&gt; <code>PipeOpTorchMergeProd</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchMergeProd-new"><code>PipeOpTorchMergeProd$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchMergeProd-clone"><code>PipeOpTorchMergeProd$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchMergeProd-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMergeProd$new(id = "nn_merge_prod", innum = 0, param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>innum</code></dt><dd><p>(<code>integer(1)</code>)<br />
The number of inputs. Default is 0 which means there is one <em>vararg</em> input channel.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchMergeProd-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMergeProd$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_merge_prod")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_merge_sum'>Merge by Summation</h2><span id='topic+mlr_pipeops_nn_merge_sum'></span><span id='topic+PipeOpTorchMergeSum'></span>

<h3>Description</h3>

<p>Calculates the sum of all input tensors.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>
<p><code>PipeOpTorchMerge</code>s has either a <em>vararg</em> input channel if the constructor argument <code>innum</code> is not set, or
input channels <code>"input1"</code>, ..., <code>"input&lt;innum&gt;"</code>. There is one output channel <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>

<p>No parameters.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="#topic+nn_merge_sum">nn_merge_sum()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code><a href="#topic+PipeOpTorchMerge">mlr3torch::PipeOpTorchMerge</a></code> -&gt; <code>PipeOpTorchMergeSum</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchMergeSum-new"><code>PipeOpTorchMergeSum$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchMergeSum-clone"><code>PipeOpTorchMergeSum$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchMergeSum-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMergeSum$new(id = "nn_merge_sum", innum = 0, param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>innum</code></dt><dd><p>(<code>integer(1)</code>)<br />
The number of inputs. Default is 0 which means there is one <em>vararg</em> input channel.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchMergeSum-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchMergeSum$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>
<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_merge_sum")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_prelu'>PReLU Activation Function</h2><span id='topic+mlr_pipeops_nn_prelu'></span><span id='topic+PipeOpTorchPReLU'></span>

<h3>Description</h3>

<p>Applies element-wise the function
<code class="reqn">PReLU(x) = max(0,x) + weight * min(0,x)</code>
where weight is a learnable parameter.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>num_parameters</code> :: <code>integer(1)</code>:
Number of a to learn. Although it takes an int as input, there is only two values are legitimate: 1, or the
number of channels at input. Default: 1.
</p>
</li>
<li> <p><code>init</code> :: <code>numeric(1)</code><br /> T
The initial value of a. Default: 0.25.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_prelu">torch::nn_prelu()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchPReLU</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchPReLU-new"><code>PipeOpTorchPReLU$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchPReLU-clone"><code>PipeOpTorchPReLU$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchPReLU-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchPReLU$new(id = "nn_prelu", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchPReLU-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchPReLU$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_prelu")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_relu'>ReLU Activation Function</h2><span id='topic+mlr_pipeops_nn_relu'></span><span id='topic+PipeOpTorchReLU'></span>

<h3>Description</h3>

<p>Applies the rectified linear unit function element-wise.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
Whether to do the operation in-place. Default: <code>FALSE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_relu">torch::nn_relu()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchReLU</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchReLU-new"><code>PipeOpTorchReLU$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchReLU-clone"><code>PipeOpTorchReLU$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchReLU-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchReLU$new(id = "nn_relu", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchReLU-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchReLU$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_relu")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_relu6'>ReLU6 Activation Function</h2><span id='topic+mlr_pipeops_nn_relu6'></span><span id='topic+PipeOpTorchReLU6'></span>

<h3>Description</h3>

<p>Applies the element-wise function <code class="reqn">ReLU6(x) = min(max(0,x), 6)</code>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
Whether to do the operation in-place. Default: <code>FALSE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_relu6">torch::nn_relu6()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchReLU6</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchReLU6-new"><code>PipeOpTorchReLU6$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchReLU6-clone"><code>PipeOpTorchReLU6$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchReLU6-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchReLU6$new(id = "nn_relu6", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchReLU6-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchReLU6$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_relu6")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_reshape'>Reshape a Tensor</h2><span id='topic+mlr_pipeops_nn_reshape'></span><span id='topic+PipeOpTorchReshape'></span>

<h3>Description</h3>

<p>Reshape a tensor to the given shape.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>shape</code> :: <code>integer(1)</code><br />
The desired output shape. Unknown dimension (one at most) can either be specified as <code>-1</code> or <code>NA</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="#topic+nn_reshape">nn_reshape()</a></code> when trained.
This internally calls <code><a href="torch.html#topic+torch_reshape">torch::torch_reshape()</a></code> with the given <code>shape</code>.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchReshape</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchReshape-new"><code>PipeOpTorchReshape$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchReshape-clone"><code>PipeOpTorchReshape$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchReshape-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchReshape$new(id = "nn_reshape", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchReshape-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchReshape$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_reshape")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_rrelu'>RReLU Activation Function</h2><span id='topic+mlr_pipeops_nn_rrelu'></span><span id='topic+PipeOpTorchRReLU'></span>

<h3>Description</h3>

<p>Randomized leaky ReLU.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>lower</code>:: <code>numeric(1)</code><br />
Lower bound of the uniform distribution. Default: 1/8.
</p>
</li>
<li> <p><code>upper</code>:: <code>numeric(1)</code><br />
Upper bound of the uniform distribution. Default: 1/3.
</p>
</li>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
Whether to do the operation in-place. Default: <code>FALSE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_rrelu">torch::nn_rrelu()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchRReLU</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchRReLU-new"><code>PipeOpTorchRReLU$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchRReLU-clone"><code>PipeOpTorchRReLU$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchRReLU-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchRReLU$new(id = "nn_rrelu", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchRReLU-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchRReLU$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_rrelu")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_selu'>SELU Activation Function</h2><span id='topic+mlr_pipeops_nn_selu'></span><span id='topic+PipeOpTorchSELU'></span>

<h3>Description</h3>

<p>Applies element-wise,
</p>
<p style="text-align: center;"><code class="reqn">SELU(x) = scale * (max(0,x) + min(0, \alpha * (exp(x) - 1)))</code>
</p>
<p>,
with <code class="reqn">\alpha=1.6732632423543772848170429916717</code> and
<code class="reqn">scale=1.0507009873554804934193349852946</code>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
Whether to do the operation in-place. Default: <code>FALSE</code>.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_selu">torch::nn_selu()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchSELU</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchSELU-new"><code>PipeOpTorchSELU$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchSELU-clone"><code>PipeOpTorchSELU$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchSELU-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSELU$new(id = "nn_selu", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchSELU-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSELU$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_selu")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_sigmoid'>Sigmoid Activation Function</h2><span id='topic+mlr_pipeops_nn_sigmoid'></span><span id='topic+PipeOpTorchSigmoid'></span>

<h3>Description</h3>

<p>Applies element-wise <code class="reqn">Sigmoid(x_i) = \frac{1}{1 + exp(-x_i)}</code>
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>

<p>No parameters.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_sigmoid">torch::nn_sigmoid()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchSigmoid</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchSigmoid-new"><code>PipeOpTorchSigmoid$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchSigmoid-clone"><code>PipeOpTorchSigmoid$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchSigmoid-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSigmoid$new(id = "nn_sigmoid", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchSigmoid-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSigmoid$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_sigmoid")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_softmax'>Softmax</h2><span id='topic+mlr_pipeops_nn_softmax'></span><span id='topic+PipeOpTorchSoftmax'></span>

<h3>Description</h3>

<p>Applies a softmax function.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>dim</code> :: <code>integer(1)</code><br />
A dimension along which Softmax will be computed (so every slice along dim will sum to 1).
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_softmax">torch::nn_softmax()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchSoftmax</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchSoftmax-new"><code>PipeOpTorchSoftmax$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchSoftmax-clone"><code>PipeOpTorchSoftmax$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchSoftmax-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSoftmax$new(id = "nn_softmax", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchSoftmax-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSoftmax$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_softmax")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_softplus'>SoftPlus Activation Function</h2><span id='topic+mlr_pipeops_nn_softplus'></span><span id='topic+PipeOpTorchSoftPlus'></span>

<h3>Description</h3>

<p>Applies element-wise, the function <code class="reqn">Softplus(x) = 1/\beta * log(1 + exp(\beta * x))</code>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>beta</code> :: <code>numeric(1)</code><br />
The beta value for the Softplus formulation. Default: 1
</p>
</li>
<li> <p><code>threshold</code> :: <code>numeric(1)</code><br />
Values above this revert to a linear function. Default: 20
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_softplus">torch::nn_softplus()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchSoftPlus</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchSoftPlus-new"><code>PipeOpTorchSoftPlus$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchSoftPlus-clone"><code>PipeOpTorchSoftPlus$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchSoftPlus-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSoftPlus$new(id = "nn_softplus", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchSoftPlus-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSoftPlus$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_softplus")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_softshrink'>Soft Shrink Activation Function</h2><span id='topic+mlr_pipeops_nn_softshrink'></span><span id='topic+PipeOpTorchSoftShrink'></span>

<h3>Description</h3>

<p>Applies the soft shrinkage function elementwise
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>lamd</code> :: <code>numeric(1)</code><br />
The lambda (must be no less than zero) value for the Softshrink formulation. Default: 0.5
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_softshrink">torch::nn_softshrink()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchSoftShrink</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchSoftShrink-new"><code>PipeOpTorchSoftShrink$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchSoftShrink-clone"><code>PipeOpTorchSoftShrink$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchSoftShrink-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSoftShrink$new(id = "nn_softshrink", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchSoftShrink-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSoftShrink$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_softshrink")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_softsign'>SoftSign Activation Function</h2><span id='topic+mlr_pipeops_nn_softsign'></span><span id='topic+PipeOpTorchSoftSign'></span>

<h3>Description</h3>

<p>Applies element-wise, the function <code class="reqn">SoftSign(x) = x/(1 + |x|</code>
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>

<p>No parameters.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_softsign">torch::nn_softsign()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchSoftSign</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchSoftSign-new"><code>PipeOpTorchSoftSign$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchSoftSign-clone"><code>PipeOpTorchSoftSign$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchSoftSign-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSoftSign$new(id = "nn_softsign", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchSoftSign-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSoftSign$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_softsign")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_squeeze'>Squeeze a Tensor</h2><span id='topic+mlr_pipeops_nn_squeeze'></span><span id='topic+PipeOpTorchSqueeze'></span><span id='topic+PipeOpTorchUnsqueeze'></span>

<h3>Description</h3>

<p>Squeezes a tensor by calling <code><a href="torch.html#topic+torch_squeeze">torch::torch_squeeze()</a></code> with the given dimension <code>dim</code>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>
<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>
<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>
<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>dim</code> :: <code>integer(1)</code><br />
The dimension to squeeze. If <code>NULL</code>, all dimensions of size 1 will be squeezed.
Negative values are interpreted downwards from the last dimension.
</p>
</li></ul>


<ul>
<li> <p><code>dim</code> :: <code>integer(1)</code><br />
The dimension which to unsqueeze. Negative values are interpreted downwards from the last dimension.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="#topic+nn_squeeze">nn_squeeze()</a></code> when trained.
</p>
<p>Calls <code><a href="#topic+nn_unsqueeze">nn_unsqueeze()</a></code> when trained.
This internally calls <code><a href="torch.html#topic+torch_unsqueeze">torch::torch_unsqueeze()</a></code>.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchSqueeze</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchSqueeze-new"><code>PipeOpTorchSqueeze$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchSqueeze-clone"><code>PipeOpTorchSqueeze$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchSqueeze-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSqueeze$new(id = "nn_squeeze", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchSqueeze-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchSqueeze$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchUnsqueeze</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchUnsqueeze-new"><code>PipeOpTorchUnsqueeze$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchUnsqueeze-clone"><code>PipeOpTorchUnsqueeze$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchUnsqueeze-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchUnsqueeze$new(id = "nn_unsqueeze", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchUnsqueeze-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchUnsqueeze$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>
<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_squeeze")
pipeop
# The available parameters
pipeop$param_set


# Construct the PipeOp
pipeop = po("nn_squeeze")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_tanh'>Tanh Activation Function</h2><span id='topic+mlr_pipeops_nn_tanh'></span><span id='topic+PipeOpTorchTanh'></span>

<h3>Description</h3>

<p>Applies the element-wise function:
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>

<p>No parameters.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_tanh">torch::nn_tanh()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchTanh</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchTanh-new"><code>PipeOpTorchTanh$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchTanh-clone"><code>PipeOpTorchTanh$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchTanh-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchTanh$new(id = "nn_tanh", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchTanh-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchTanh$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_tanh")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_tanhshrink'>Tanh Shrink Activation Function</h2><span id='topic+mlr_pipeops_nn_tanhshrink'></span><span id='topic+PipeOpTorchTanhShrink'></span>

<h3>Description</h3>

<p>Applies element-wise, <code class="reqn">Tanhshrink(x) = x - Tanh(x)</code>
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>

<p>No parameters.
</p>


<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_tanhshrink">torch::nn_tanhshrink()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchTanhShrink</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchTanhShrink-new"><code>PipeOpTorchTanhShrink$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchTanhShrink-clone"><code>PipeOpTorchTanhShrink$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchTanhShrink-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchTanhShrink$new(id = "nn_tanhshrink", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchTanhShrink-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchTanhShrink$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_tanhshrink")
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_nn_threshold'>Treshold Activation Function</h2><span id='topic+mlr_pipeops_nn_threshold'></span><span id='topic+PipeOpTorchThreshold'></span>

<h3>Description</h3>

<p>Thresholds each element of the input Tensor.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code style="white-space: pre;">&#8288;$shapes_out()&#8288;</code>.
</p>


<h3>Credit</h3>

<p>Part of this documentation have been copied or adapted from the documentation of <a href="https://CRAN.R-project.org/package=torch"><span class="pkg">torch</span></a>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>threshold</code> :: <code>numeric(1)</code><br />
The value to threshold at.
</p>
</li>
<li> <p><code>value</code> :: <code>numeric(1)</code><br />
The value to replace with.
</p>
</li>
<li> <p><code>inplace</code> :: <code>logical(1)</code><br />
Can optionally do the operation in-place. Default: ‘FALSE’.
</p>
</li></ul>



<h3>Internals</h3>

<p>Calls <code><a href="torch.html#topic+nn_threshold">torch::nn_threshold()</a></code> when trained.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorch">mlr3torch::PipeOpTorch</a></code> -&gt; <code>PipeOpTorchThreshold</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchThreshold-new"><code>PipeOpTorchThreshold$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchThreshold-clone"><code>PipeOpTorchThreshold$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="PipeOpTorch" data-id="shapes_out"><a href='../../mlr3torch/html/PipeOpTorch.html#method-PipeOpTorch-shapes_out'><code>mlr3torch::PipeOpTorch$shapes_out()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchThreshold-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchThreshold$new(id = "nn_threshold", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchThreshold-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchThreshold$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Construct the PipeOp
pipeop = po("nn_threshold", threshold = 1, value = 2)
pipeop
# The available parameters
pipeop$param_set

</code></pre>

<hr>
<h2 id='mlr_pipeops_preproc_torch'>Base Class for Lazy Tensor Preprocessing</h2><span id='topic+mlr_pipeops_preproc_torch'></span><span id='topic+PipeOpTaskPreprocTorch'></span>

<h3>Description</h3>

<p>This <code>PipeOp</code> can be used to preprocess (one or more) <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> columns contained in an <code><a href="mlr3.html#topic+Task">mlr3::Task</a></code>.
The preprocessing function is specified as construction argument <code>fn</code> and additional arguments to this
function can be defined through the <code>PipeOp</code>'s parameter set.
The preprocessing is done per column, i.e. the number of lazy tensor output columns is equal
to the number of lazy tensor input columns.
</p>
<p>To create custom preprocessing <code>PipeOp</code>s you can use <code><a href="#topic+pipeop_preproc_torch">pipeop_preproc_torch</a></code>.
</p>


<h3>Inheriting</h3>

<p>In addition to specifying the construction arguments, you can overwrite the private <code>.shapes_out()</code> method.
If you don't overwrite it, the output shapes are assumed to be unknown (<code>NULL</code>).
</p>

<ul>
<li> <p><code>.shapes_out(shapes_in, param_vals, task)</code><br />
(<code>list()</code>, <code style="white-space: pre;">&#8288;list(), &#8288;</code>Task<code>or</code>NULL<code style="white-space: pre;">&#8288;) -&gt; &#8288;</code>list()<code style="white-space: pre;">&#8288;\cr This private method calculates the output shapes of the lazy tensor columns that are created from applying the preprocessing function with the provided parameter values (&#8288;</code>param_vals<code style="white-space: pre;">&#8288;). The &#8288;</code>task<code style="white-space: pre;">&#8288;is very rarely needed, but if it is it should be checked that it is not&#8288;</code>NULL'.
</p>
<p>This private method only has the responsibility to calculate the output shapes for one input column, i.e. the
input <code>shapes_in</code> can be assumed to have exactly one shape vector for which it must calculate the output shapes
and return it as a <code>list()</code> of length 1.
It can also be assumed that the shape is not <code>NULL</code> (i.e. unknown).
Also, the first dimension can be <code>NA</code>, i.e. is unknown (as for the batch dimension).
</p>
</li></ul>



<h3>Input and Output Channels</h3>

<p>See <code><a href="mlr3pipelines.html#topic+PipeOpTaskPreproc">PipeOpTaskPreproc</a></code>.
</p>


<h3>State</h3>

<p>In addition to state elements from <code><a href="mlr3pipelines.html#topic+PipeOpTaskPreprocSimple">PipeOpTaskPreprocSimple</a></code>,
the state also contains the <code style="white-space: pre;">&#8288;$param_vals&#8288;</code> that were set during training.
</p>


<h3>Parameters</h3>

<p>In addition to the parameters inherited from <code><a href="mlr3pipelines.html#topic+PipeOpTaskPreproc">PipeOpTaskPreproc</a></code> as well as those specified during construction
as the argument <code>param_set</code> there are the following parameters:
</p>

<ul>
<li> <p><code>stages</code> :: <code>character(1)</code><br />
The stages during which to apply the preprocessing.
Can be one of <code>"train"</code>, <code>"predict"</code> or <code>"both"</code>.
The initial value of this parameter is set to <code>"train"</code> when the <code>PipeOp</code>'s id starts with <code>"augment_"</code> and
to <code>"both"</code> otherwise.
Note that the preprocessing that is applied during <code style="white-space: pre;">&#8288;$predict()&#8288;</code> uses the parameters that were set during
<code style="white-space: pre;">&#8288;$train()&#8288;</code> and not those that are set when performing the prediction.
</p>
</li></ul>



<h3>Internals</h3>

<p>During <code style="white-space: pre;">&#8288;$train()&#8288;</code> / <code style="white-space: pre;">&#8288;$predict()&#8288;</code>, a <code><a href="#topic+PipeOpModule">PipeOpModule</a></code> with one input and one output channel is created.
The pipeop applies the function <code>fn</code> to the input tensor while additionally
passing the parameter values (minus <code>stages</code> and <code>affect_columns</code>) to <code>fn</code>.
The preprocessing graph of the lazy tensor columns is shallowly cloned and the <code>PipeOpModule</code> is added.
This is done to avoid modifying user input and means that identical <code>PipeOpModule</code>s can be part of different
preprocessing graphs. This is only possible, because the created <code>PipeOpModule</code> is stateless.
</p>
<p>At a later point in the graph, preprocessing graphs will be merged if possible to avoid unnecessary computation.
This is best illustrated by example:
One lazy tensor column's preprocessing graph is <code>A -&gt; B</code>.
Then, two branches are created <code>B -&gt; C</code> and <code>B -&gt; D</code>, creating two preprocessing graphs
<code>A -&gt; B -&gt; C</code> and <code>A -&gt; B -&gt; D</code>. When loading the data, we want to run the preprocessing only once, i.e. we don't
want to run the <code>A -&gt; B</code> part twice. For this reason, <code><a href="#topic+task_dataset">task_dataset()</a></code> will try to merge graphs and cache
results from graphs. However, only graphs using the same dataset can currently be merged.
</p>
<p>Also, the shapes created during <code style="white-space: pre;">&#8288;$train()&#8288;</code> and <code style="white-space: pre;">&#8288;$predict()&#8288;</code> might differ.
To avoid the creation of graphs where the predict shapes are incompatible with the train shapes,
the hypothetical predict shapes are already calculated during <code style="white-space: pre;">&#8288;$train()&#8288;</code> (this is why the parameters that are set
during train are also used during predict) and the <code><a href="#topic+PipeOpTorchModel">PipeOpTorchModel</a></code> will check the train and predict shapes for
compatibility before starting the training.
</p>
<p>Otherwise, this mechanism is very similar to the <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code> construct.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpTaskPreproc">mlr3pipelines::PipeOpTaskPreproc</a></code> -&gt; <code>PipeOpTaskPreprocTorch</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>fn</code></dt><dd><p>The preprocessing function.</p>
</dd>
<dt><code>rowwise</code></dt><dd><p>Whether the preprocessing is applied rowwise.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTaskPreprocTorch-new"><code>PipeOpTaskPreprocTorch$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTaskPreprocTorch-shapes_out"><code>PipeOpTaskPreprocTorch$shapes_out()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTaskPreprocTorch-clone"><code>PipeOpTaskPreprocTorch$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTaskPreprocTorch-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <code><a href="R6.html#topic+R6Class">R6</a></code> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTaskPreprocTorch$new(
  fn,
  id = "preproc_torch",
  param_vals = list(),
  param_set = ps(),
  packages = character(0),
  rowwise = FALSE,
  stages_init = NULL,
  tags = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>fn</code></dt><dd><p>(<code>function</code> or <code>character(2)</code>)<br />
The preprocessing function. Must not modify its input in-place.
If it is a <code>character(2)</code>, the first element should be the namespace and the second element the name.
When the preprocessing function is applied to the tensor, the tensor will be passed by position as the first argument.
If the <code>param_set</code> is inferred (left as <code>NULL</code>) it is assumed that the first argument is the <code>torch_tensor</code>.</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(named <code>list()</code>)<br />
Parameter values to be set after construction.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>)<br />
In case the function <code>fn</code> takes additional parameter besides a <code><a href="torch.html#topic+torch_tensor">torch_tensor</a></code> they can be
specfied as parameters. None of the parameters can have the <code>"predict"</code> tag.
All tags should include <code>"train"</code>.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The packages the preprocessing function depends on.</p>
</dd>
<dt><code>rowwise</code></dt><dd><p>(<code>logical(1)</code>)<br />
Whether the preprocessing function is applied rowwise (and then concatenated by row) or directly to the whole
tensor. In the first case there is no batch dimension.</p>
</dd>
<dt><code>stages_init</code></dt><dd><p>(<code>character(1)</code>)<br />
Initial value for the <code>stages</code> parameter.</p>
</dd>
<dt><code>tags</code></dt><dd><p>(<code>character()</code>)<br />
Tags for the pipeop.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTaskPreprocTorch-shapes_out"></a>



<h4>Method <code>shapes_out()</code></h4>

<p>Calculates the output shapes that would result in applying the preprocessing to one or more
lazy tensor columns with the provided shape.
Names are ignored and only order matters.
It uses the parameter values that are currently set.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTaskPreprocTorch$shapes_out(shapes_in, stage = NULL, task = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>shapes_in</code></dt><dd><p>(<code>list()</code> of (<code>integer()</code> or <code>NULL</code>))<br />
The input input shapes of the lazy tensors.
<code>NULL</code> indicates that the shape is unknown.
First dimension must be <code>NA</code> (if it is not <code>NULL</code>).</p>
</dd>
<dt><code>stage</code></dt><dd><p>(<code>character(1)</code>)<br />
The stage: either <code>"train"</code> or <code>"predict"</code>.</p>
</dd>
<dt><code>task</code></dt><dd><p>(<code><a href="mlr3.html#topic+Task">Task</a></code> or <code>NULL</code>)<br />
The task, which is very rarely needed.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>list()</code> of (<code>integer()</code> or <code>NULL</code>)
</p>


<hr>
<a id="method-PipeOpTaskPreprocTorch-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTaskPreprocTorch$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>
# Creating a simple task
d = data.table(
  x1 = as_lazy_tensor(rnorm(10)),
  x2 = as_lazy_tensor(rnorm(10)),
  x3 = as_lazy_tensor(as.double(1:10)),
  y = rnorm(10)
)

taskin = as_task_regr(d, target = "y")

# Creating a simple preprocessing pipeop
po_simple = po("preproc_torch",
  # get rid of environment baggage
  fn = mlr3misc::crate(function(x, a) x + a),
  param_set = paradox::ps(a = paradox::p_int(tags = c("train", "required")))
)

po_simple$param_set$set_values(
  a = 100,
  affect_columns = selector_name(c("x1", "x2")),
  stages = "both" # use during train and predict
)

taskout_train = po_simple$train(list(taskin))[[1L]]
materialize(taskout_train$data(cols = c("x1", "x2")), rbind = TRUE)

taskout_predict_noaug = po_simple$predict(list(taskin))[[1L]]
materialize(taskout_predict_noaug$data(cols = c("x1", "x2")), rbind = TRUE)

po_simple$param_set$set_values(
  stages = "train"
)

# transformation is not applied
taskout_predict_aug = po_simple$predict(list(taskin))[[1L]]
materialize(taskout_predict_aug$data(cols = c("x1", "x2")), rbind = TRUE)

# Creating a more complex preprocessing PipeOp
PipeOpPreprocTorchPoly = R6::R6Class("PipeOpPreprocTorchPoly",
 inherit = PipeOpTaskPreprocTorch,
 public = list(
   initialize = function(id = "preproc_poly", param_vals = list()) {
     param_set = paradox::ps(
       n_degree = paradox::p_int(lower = 1L, tags = c("train", "required"))
     )
     param_set$set_values(
       n_degree = 1L
     )
     fn = mlr3misc::crate(function(x, n_degree) {
       torch::torch_cat(
         lapply(seq_len(n_degree), function(d) torch_pow(x, d)),
         dim = 2L
       )
     })

     super$initialize(
       fn = fn,
       id = id,
       packages = character(0),
       param_vals = param_vals,
       param_set = param_set,
       stages_init = "both"
     )
   }
 ),
 private = list(
   .shapes_out = function(shapes_in, param_vals, task) {
     # shapes_in is a list of length 1 containing the shapes
     checkmate::assert_true(length(shapes_in[[1L]]) == 2L)
     if (shapes_in[[1L]][2L] != 1L) {
       stop("Input shape must be (NA, 1)")
     }
     list(c(NA, param_vals$n_degree))
   }
 )
)

po_poly = PipeOpPreprocTorchPoly$new(
  param_vals = list(n_degree = 3L, affect_columns = selector_name("x3"))
)

po_poly$shapes_out(list(c(NA, 1L)), stage = "train")

taskout = po_poly$train(list(taskin))[[1L]]
materialize(taskout$data(cols = "x3"), rbind = TRUE)

</code></pre>

<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_center_crop'>PipeOpPreprocTorchAugmentCenterCrop</h2><span id='topic+mlr_pipeops_preproc_torch.augment_center_crop'></span><span id='topic+PipeOpPreprocTorchAugmentCenterCrop'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_center_crop">torchvision::transform_center_crop</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   size </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_color_jitter'>PipeOpPreprocTorchAugmentColorJitter</h2><span id='topic+mlr_pipeops_preproc_torch.augment_color_jitter'></span><span id='topic+PipeOpPreprocTorchAugmentColorJitter'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_color_jitter">torchvision::transform_color_jitter</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   brightness </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> 0 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   contrast </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> 0 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   saturation </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> 0 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   hue </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> 0 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_crop'>PipeOpPreprocTorchAugmentCrop</h2><span id='topic+mlr_pipeops_preproc_torch.augment_crop'></span><span id='topic+PipeOpPreprocTorchAugmentCrop'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_crop">torchvision::transform_crop</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   top </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   left </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   height </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   width </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_hflip'>PipeOpPreprocTorchAugmentHflip</h2><span id='topic+mlr_pipeops_preproc_torch.augment_hflip'></span><span id='topic+PipeOpPreprocTorchAugmentHflip'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_hflip">torchvision::transform_hflip</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_random_affine'>PipeOpPreprocTorchAugmentRandomAffine</h2><span id='topic+mlr_pipeops_preproc_torch.augment_random_affine'></span><span id='topic+PipeOpPreprocTorchAugmentRandomAffine'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_random_affine">torchvision::transform_random_affine</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   degrees </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   translate </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> NULL </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   scale </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> NULL </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   resample </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> 0 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   fillcolor </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> 0 </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_random_choice'>PipeOpPreprocTorchAugmentRandomChoice</h2><span id='topic+mlr_pipeops_preproc_torch.augment_random_choice'></span><span id='topic+PipeOpPreprocTorchAugmentRandomChoice'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_random_choice">torchvision::transform_random_choice</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   transforms </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_random_crop'>PipeOpPreprocTorchAugmentRandomCrop</h2><span id='topic+mlr_pipeops_preproc_torch.augment_random_crop'></span><span id='topic+PipeOpPreprocTorchAugmentRandomCrop'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_random_crop">torchvision::transform_random_crop</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   size </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   padding </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> NULL </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   pad_if_needed </td><td style="text-align: left;"> logical </td><td style="text-align: left;"> FALSE </td><td style="text-align: left;"> TRUE, FALSE </td>
</tr>
<tr>
 <td style="text-align: left;">
   fill </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> 0L </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   padding_mode </td><td style="text-align: left;"> character </td><td style="text-align: left;"> constant </td><td style="text-align: left;"> constant, edge, reflect, symmetric </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_random_horizontal_flip'>PipeOpPreprocTorchAugmentRandomHorizontalFlip</h2><span id='topic+mlr_pipeops_preproc_torch.augment_random_horizontal_flip'></span><span id='topic+PipeOpPreprocTorchAugmentRandomHorizontalFlip'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_random_horizontal_flip">torchvision::transform_random_horizontal_flip</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   p </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> 0.5 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, 1]</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_random_order'>PipeOpPreprocTorchAugmentRandomOrder</h2><span id='topic+mlr_pipeops_preproc_torch.augment_random_order'></span><span id='topic+PipeOpPreprocTorchAugmentRandomOrder'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_random_order">torchvision::transform_random_order</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   transforms </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_random_resized_crop'>PipeOpPreprocTorchAugmentRandomResizedCrop</h2><span id='topic+mlr_pipeops_preproc_torch.augment_random_resized_crop'></span><span id='topic+PipeOpPreprocTorchAugmentRandomResizedCrop'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_random_resized_crop">torchvision::transform_random_resized_crop</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   size </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   scale </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> c(0.08, 1) </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   ratio </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> c(3/4, 4/3) </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   interpolation </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> 2 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, 3]</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_random_vertical_flip'>PipeOpPreprocTorchAugmentRandomVerticalFlip</h2><span id='topic+mlr_pipeops_preproc_torch.augment_random_vertical_flip'></span><span id='topic+PipeOpPreprocTorchAugmentRandomVerticalFlip'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_random_vertical_flip">torchvision::transform_random_vertical_flip</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   p </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> 0.5 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, 1]</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_resized_crop'>PipeOpPreprocTorchAugmentResizedCrop</h2><span id='topic+mlr_pipeops_preproc_torch.augment_resized_crop'></span><span id='topic+PipeOpPreprocTorchAugmentResizedCrop'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_resized_crop">torchvision::transform_resized_crop</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   top </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   left </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   height </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   width </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   size </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   interpolation </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> 2 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, 3]</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_rotate'>PipeOpPreprocTorchAugmentRotate</h2><span id='topic+mlr_pipeops_preproc_torch.augment_rotate'></span><span id='topic+PipeOpPreprocTorchAugmentRotate'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_rotate">torchvision::transform_rotate</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   angle </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   resample </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> 0 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   expand </td><td style="text-align: left;"> logical </td><td style="text-align: left;"> FALSE </td><td style="text-align: left;"> TRUE, FALSE </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   center </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> NULL </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   fill </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> NULL </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.augment_vflip'>PipeOpPreprocTorchAugmentVflip</h2><span id='topic+mlr_pipeops_preproc_torch.augment_vflip'></span><span id='topic+PipeOpPreprocTorchAugmentVflip'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_vflip">torchvision::transform_vflip</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_adjust_brightness'>PipeOpPreprocTorchTrafoAdjustBrightness</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_adjust_brightness'></span><span id='topic+PipeOpPreprocTorchTrafoAdjustBrightness'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_adjust_brightness">torchvision::transform_adjust_brightness</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   brightness_factor </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_adjust_gamma'>PipeOpPreprocTorchTrafoAdjustGamma</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_adjust_gamma'></span><span id='topic+PipeOpPreprocTorchTrafoAdjustGamma'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_adjust_gamma">torchvision::transform_adjust_gamma</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   gamma </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[0, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   gain </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> 1 </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_adjust_hue'>PipeOpPreprocTorchTrafoAdjustHue</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_adjust_hue'></span><span id='topic+PipeOpPreprocTorchTrafoAdjustHue'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_adjust_hue">torchvision::transform_adjust_hue</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   hue_factor </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[-0.5, 0.5]</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_adjust_saturation'>PipeOpPreprocTorchTrafoAdjustSaturation</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_adjust_saturation'></span><span id='topic+PipeOpPreprocTorchTrafoAdjustSaturation'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_adjust_saturation">torchvision::transform_adjust_saturation</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   saturation_factor </td><td style="text-align: left;"> numeric </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">(-\infty, \infty)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_grayscale'>PipeOpPreprocTorchTrafoGrayscale</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_grayscale'></span><span id='topic+PipeOpPreprocTorchTrafoGrayscale'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_grayscale">torchvision::transform_grayscale</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td><td style="text-align: left;"> Range </td>
</tr>
<tr>
 <td style="text-align: left;">
   num_output_channels </td><td style="text-align: left;"> integer </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td><td style="text-align: left;"> <code class="reqn">[1, 3]</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td><td style="text-align: left;"> - </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_nop'>PipeOpPreprocTorchTrafoNop</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_nop'></span><span id='topic+PipeOpPreprocTorchTrafoNop'></span>

<h3>Description</h3>

<p>Does nothing.
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>

<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_normalize'>PipeOpPreprocTorchTrafoNormalize</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_normalize'></span><span id='topic+PipeOpPreprocTorchTrafoNormalize'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_normalize">torchvision::transform_normalize</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   mean </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   std </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_pad'>PipeOpPreprocTorchTrafoPad</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_pad'></span><span id='topic+PipeOpPreprocTorchTrafoPad'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_pad">torchvision::transform_pad</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   padding </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   fill </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> 0 </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   padding_mode </td><td style="text-align: left;"> character </td><td style="text-align: left;"> constant </td><td style="text-align: left;"> constant, edge, reflect, symmetric </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_reshape'>PipeOpPreprocTorchTrafoReshape</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_reshape'></span><span id='topic+PipeOpPreprocTorchTrafoReshape'></span>

<h3>Description</h3>

<p>Reshapes the tensor according to the parameter <code>shape</code>, by calling <code>torch_reshape()</code>.
This preprocessing function is applied batch-wise.
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>shape</code> :: <code>integer()</code><br />
The desired output shape. The first dimension is the batch dimension and should usually be <code>-1</code>.
</p>
</li></ul>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_resize'>PipeOpPreprocTorchTrafoResize</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_resize'></span><span id='topic+PipeOpPreprocTorchTrafoResize'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_resize">torchvision::transform_resize</a></code>,
see there for more information on the parameters.
The preprocessing is applied to the whole batch.
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   size </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> - </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
   interpolation </td><td style="text-align: left;"> character </td><td style="text-align: left;"> 2 </td><td style="text-align: left;"> Undefined, Bartlett, Blackman, Bohman, Box, Catrom, Cosine, Cubic, Gaussian, Hamming, <a href="base.html#topic+...">...</a> </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_preproc_torch.trafo_rgb_to_grayscale'>PipeOpPreprocTorchTrafoRgbToGrayscale</h2><span id='topic+mlr_pipeops_preproc_torch.trafo_rgb_to_grayscale'></span><span id='topic+PipeOpPreprocTorchTrafoRgbToGrayscale'></span>

<h3>Description</h3>

<p>Calls <code><a href="torchvision.html#topic+transform_rgb_to_grayscale">torchvision::transform_rgb_to_grayscale</a></code>,
see there for more information on the parameters.
The preprocessing is applied row wise (no batch dimension).
</p>


<h3>Format</h3>

<p><code><a href="R6.html#topic+R6Class">R6Class</a></code> inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Parameters</h3>


<table>
<tr>
 <td style="text-align: left;">
   Id </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Default </td><td style="text-align: left;"> Levels </td>
</tr>
<tr>
 <td style="text-align: left;">
   stages </td><td style="text-align: left;"> character </td><td style="text-align: left;"> - </td><td style="text-align: left;"> train, predict, both </td>
</tr>
<tr>
 <td style="text-align: left;">
   affect_columns </td><td style="text-align: left;"> untyped </td><td style="text-align: left;"> selector_all() </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='mlr_pipeops_torch'>Base Class for Torch Module Constructor Wrappers</h2><span id='topic+mlr_pipeops_torch'></span><span id='topic+PipeOpTorch'></span>

<h3>Description</h3>

<p><code>PipeOpTorch</code> is the base class for all <code><a href="mlr3pipelines.html#topic+PipeOp">PipeOp</a></code>s that represent
neural network layers in a <code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code>.
During <strong>training</strong>, it generates a <code><a href="#topic+PipeOpModule">PipeOpModule</a></code> that wraps an <code><a href="torch.html#topic+nn_module">nn_module</a></code> and attaches it
to the architecture, which is also represented as a <code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code> consisting mostly of <code><a href="#topic+PipeOpModule">PipeOpModule</a></code>s
an <code><a href="mlr3pipelines.html#topic+mlr_pipeops_nop">PipeOpNOP</a></code>s.
</p>
<p>While the former <code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code> operates on <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>s, the latter operates on <a href="torch.html#topic+torch_tensor">tensors</a>.
</p>
<p>The relationship between a <code>PipeOpTorch</code> and a <code><a href="#topic+PipeOpModule">PipeOpModule</a></code> is similar to the
relationshop between a <code>nn_module_generator</code> (like <code><a href="torch.html#topic+nn_linear">nn_linear</a></code>) and a
<code><a href="torch.html#topic+nn_module">nn_module</a></code> (like the output of <code>nn_linear(...)</code>).
A crucial difference is that the <code>PipeOpTorch</code> infers auxiliary parameters (like <code>in_features</code> for
<code>nn_linear</code>) automatically from the intermediate tensor shapes that are being communicated through the
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
</p>
<p>During <strong>prediction</strong>, <code>PipeOpTorch</code> takes in a <code><a href="mlr3.html#topic+Task">Task</a></code> in each channel and outputs the same new
<code><a href="mlr3.html#topic+Task">Task</a></code> resulting from their <a href="mlr3pipelines.html#topic+mlr_pipeops_featureunion">feature union</a> in each channel.
If there is only one input and output channel, the task is simply piped through.
</p>


<h3>Inheriting</h3>

<p>When inheriting from this class, one should overload either the <code>private$.shapes_out()</code> and the
<code>private$.shape_dependent_params()</code> methods, or overload <code>private$.make_module()</code>.
</p>

<ul>
<li> <p><code>.make_module(shapes_in, param_vals, task)</code><br />
(<code>list()</code>, <code>list()</code>) -&gt; <code>nn_module</code><br />
This private method is called to generated the <code>nn_module</code> that is passed as argument <code>module</code> to
<code><a href="#topic+PipeOpModule">PipeOpModule</a></code>. It must be overwritten, when no <code>module_generator</code> is provided.
If left as is, it calls the provided <code>module_generator</code> with the arguments obtained by
the private method <code>.shape_dependent_params()</code>.
</p>
</li>
<li> <p><code>.shapes_out(shapes_in, param_vals, task)</code><br />
(<code>list()</code>, <code>list()</code>, <code><a href="mlr3.html#topic+Task">Task</a></code> or <code>NULL</code>) -&gt; named <code>list()</code><br />
This private method gets a list of <code>numeric</code> vectors (<code>shapes_in</code>), the parameter values (<code>param_vals</code>),
as well as an (optional) <code><a href="mlr3.html#topic+Task">Task</a></code>.
The <code>shapes_in</code> can be assumed to be in the same order as the input names of the <code>PipeOp</code>.
The output shapes must be in the same order as the output names of the <code>PipeOp</code>.
In case the output shapes depends on the task (as is the case for <code><a href="#topic+PipeOpTorchHead">PipeOpTorchHead</a></code>), the function should return
valid output shapes (possibly containing <code>NA</code>s) if the <code>task</code> argument is provided or not.
</p>
</li>
<li> <p><code>.shape_dependent_params(shapes_in, param_vals, task)</code><br />
(<code>list()</code>, <code>list()</code>) -&gt; named <code>list()</code><br />
This private method has the same inputs as <code>.shapes_out</code>.
If <code>.make_module()</code> is not overwritten, it constructs the arguments passed to <code>module_generator</code>.
Usually this means that it must infer the auxiliary parameters that can be inferred from the input shapes
and add it to the user-supplied parameter values (<code>param_vals</code>).
</p>
</li></ul>



<h3>Input and Output Channels</h3>

<p>During <em>training</em>, all inputs and outputs are of class <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
During <em>prediction</em>, all input and output channels are of class <code><a href="mlr3.html#topic+Task">Task</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code>shapes_out()</code>.
</p>


<h3>Parameters</h3>

<p>The <code><a href="paradox.html#topic+ParamSet">ParamSet</a></code> is specified by the child class inheriting from <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
Usually the parameters are the arguments of the wrapped <code><a href="torch.html#topic+nn_module">nn_module</a></code> minus the auxiliary parameter that can
be automatically inferred from the shapes of the input tensors.
</p>


<h3>Internals</h3>

<p>During training, the <code>PipeOpTorch</code> creates a <code><a href="#topic+PipeOpModule">PipeOpModule</a></code> for the given parameter specification and the
input shapes from the incoming <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>s using the private method <code>.make_module()</code>.
The input shapes are provided by the slot <code>pointer_shape</code> of the incoming <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>s.
The channel names of this <code><a href="#topic+PipeOpModule">PipeOpModule</a></code> are identical to the channel names of the generating <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>
<p>A <a href="#topic+model_descriptor_union">model descriptor union</a> of all incoming <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>s is then created.
Note that this modifies the <code><a href="mlr3pipelines.html#topic+Graph">graph</a></code> of the first <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code> <strong>in place</strong> for efficiency.
The <code><a href="#topic+PipeOpModule">PipeOpModule</a></code> is added to the <code><a href="mlr3pipelines.html#topic+Graph">graph</a></code> slot of this union and the the edges that connect the
sending <code>PipeOpModule</code>s to the input channel of this <code>PipeOpModule</code> are addeded to the graph.
This is possible because every incoming <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code> contains the information about the
<code>id</code> and the <code>channel</code> name of the sending <code>PipeOp</code> in the slot <code>pointer</code>.
</p>
<p>The new graph in the <code><a href="#topic+model_descriptor_union">model_descriptor_union</a></code> represents the current state of the neural network
architecture. It is structurally similar to the subgraph that consists of all pipeops of class <code>PipeOpTorch</code> and
<code><a href="#topic+PipeOpTorchIngress">PipeOpTorchIngress</a></code> that are ancestors of this <code>PipeOpTorch</code>.
</p>
<p>For the output, a shallow copy of the <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code> is created and the <code>pointer</code> and
<code>pointer_shape</code> are updated accordingly. The shallow copy means that all <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>s point to the same
<code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code> which allows the graph to be modified by-reference in different parts of the code.
</p>


<h3>Super class</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code>PipeOpTorch</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>module_generator</code></dt><dd><p>(<code>nn_module_generator</code> or <code>NULL</code>)<br />
The module generator wrapped by this <code>PipeOpTorch</code>. If <code>NULL</code>, the private method
<code>private$.make_module(shapes_in, param_vals)</code> must be overwritte, see section 'Inheriting'.
Do not change this after construction.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorch-new"><code>PipeOpTorch$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorch-shapes_out"><code>PipeOpTorch$shapes_out()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorch-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorch$new(
  id,
  module_generator,
  param_set = ps(),
  param_vals = list(),
  inname = "input",
  outname = "output",
  packages = "torch",
  tags = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>module_generator</code></dt><dd><p>(<code>nn_module_generator</code>)<br />
The torch module generator.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>)<br />
The parameter set.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
<dt><code>inname</code></dt><dd><p>(<code>character()</code>)<br />
The names of the <code><a href="mlr3pipelines.html#topic+PipeOp">PipeOp</a></code>'s input channels. These will be the input channels of the generated <code><a href="#topic+PipeOpModule">PipeOpModule</a></code>.
Unless the wrapped <code>module_generator</code>'s forward method (if present) has the argument <code>...</code>, <code>inname</code> must be
identical to those argument names in order to avoid any ambiguity.<br />
If the forward method has the argument <code>...</code>, the order of the input channels determines how the tensors
will be passed to the wrapped <code>nn_module</code>.<br />
If left as <code>NULL</code> (default), the argument <code>module_generator</code> must be given and the argument names of the
<code>modue_generator</code>'s forward function are set as <code>inname</code>.</p>
</dd>
<dt><code>outname</code></dt><dd><p>(<code>character()</code>) <br />
The names of the output channels channels. These will be the ouput channels of the generated <code><a href="#topic+PipeOpModule">PipeOpModule</a></code>
and therefore also the names of the list returned by its <code style="white-space: pre;">&#8288;$train()&#8288;</code>.
In case there is more than one output channel, the <code>nn_module</code> that is constructed by this
<code><a href="mlr3pipelines.html#topic+PipeOp">PipeOp</a></code> during training must return a named <code>list()</code>, where the names of the list are the
names out the output channels. The default is <code>"output"</code>.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
<dt><code>tags</code></dt><dd><p>(<code>character()</code>)<br />
The tags of the <code><a href="mlr3pipelines.html#topic+PipeOp">PipeOp</a></code>. The tags <code>"torch"</code> is always added.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorch-shapes_out"></a>



<h4>Method <code>shapes_out()</code></h4>

<p>Calculates the output shapes for the given input shapes, parameters and task.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorch$shapes_out(shapes_in, task = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>shapes_in</code></dt><dd><p>(<code>list()</code> of <code>integer()</code>)<br />
The input input shapes, which must be in the same order as the input channel names of the <code>PipeOp</code>.</p>
</dd>
<dt><code>task</code></dt><dd><p>(<code><a href="mlr3.html#topic+Task">Task</a></code> or <code>NULL</code>)<br />
The task, which is very rarely used (default is <code>NULL</code>). An exception is <code><a href="#topic+PipeOpTorchHead">PipeOpTorchHead</a></code>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A named <code>list()</code> containing the output shapes. The names are the names of the output channels of
the <code>PipeOp</code>.
</p>




<h3>See Also</h3>

<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Creating a neural network
# In torch

task = tsk("iris")

network_generator = torch::nn_module(
  initialize = function(task, d_hidden) {
    d_in = length(task$feature_names)
    self$linear = torch::nn_linear(d_in, d_hidden)
    self$output = if (task$task_type == "regr") {
      torch::nn_linear(d_hidden, 1)
    } else if (task$task_type == "classif") {
      torch::nn_linear(d_hidden, length(task$class_names))
    }
  },
  forward = function(x) {
    x = self$linear(x)
    x = torch::nnf_relu(x)
    self$output(x)
  }
)

network = network_generator(task, d_hidden = 50)
x = torch::torch_tensor(as.matrix(task$data(1, task$feature_names)))
y = torch::with_no_grad(network(x))


# In mlr3torch
network_generator = po("torch_ingress_num") %&gt;&gt;%
  po("nn_linear", out_features = 50) %&gt;&gt;%
  po("nn_head")
md = network_generator$train(task)[[1L]]
network = model_descriptor_to_module(md)
y = torch::with_no_grad(network(torch_ingress_num.input = x))



## Implementing a custom PipeOpTorch

# defining a custom module
nn_custom = nn_module("nn_custom",
  initialize = function(d_in1, d_in2, d_out1, d_out2, bias = TRUE) {
    self$linear1 = nn_linear(d_in1, d_out1, bias)
    self$linear2 = nn_linear(d_in2, d_out2, bias)
  },
  forward = function(input1, input2) {
    output1 = self$linear1(input1)
    output2 = self$linear1(input2)

    list(output1 = output1, output2 = output2)
  }
)

# wrapping the module into a custom PipeOpTorch

library(paradox)

PipeOpTorchCustom = R6::R6Class("PipeOpTorchCustom",
  inherit = PipeOpTorch,
  public = list(
    initialize = function(id = "nn_custom", param_vals = list()) {
      param_set = ps(
        d_out1 = p_int(lower = 1, tags = c("required", "train")),
        d_out2 = p_int(lower = 1, tags = c("required", "train")),
        bias = p_lgl(default = TRUE, tags = "train")
      )
      super$initialize(
        id = id,
        param_vals = param_vals,
        param_set = param_set,
        inname = c("input1", "input2"),
        outname = c("output1", "output2"),
        module_generator = nn_custom
      )
    }
  ),
  private = list(
    .shape_dependent_params = function(shapes_in, param_vals, task) {
      c(param_vals,
        list(d_in1 = tail(shapes_in[["input1"]], 1)), d_in2 = tail(shapes_in[["input2"]], 1)
      )
    },
    .shapes_out = function(shapes_in, param_vals, task) {
      list(
        input1 = c(head(shapes_in[["input1"]], -1), param_vals$d_out1),
        input2 = c(head(shapes_in[["input2"]], -1), param_vals$d_out2)
      )
    }
  )
)

## Training

# generate input
task = tsk("iris")
task1 = task$clone()$select(paste0("Sepal.", c("Length", "Width")))
task2 = task$clone()$select(paste0("Petal.", c("Length", "Width")))
graph = gunion(list(po("torch_ingress_num_1"), po("torch_ingress_num_2")))
mds_in = graph$train(list(task1, task2), single_input = FALSE)

mds_in[[1L]][c("graph", "task", "ingress", "pointer", "pointer_shape")]
mds_in[[2L]][c("graph", "task", "ingress", "pointer", "pointer_shape")]

# creating the PipeOpTorch and training it
po_torch = PipeOpTorchCustom$new()
po_torch$param_set$values = list(d_out1 = 10, d_out2 = 20)
train_input = list(input1 = mds_in[[1L]], input2 = mds_in[[2L]])
mds_out = do.call(po_torch$train, args = list(input = train_input))
po_torch$state

# the new model descriptors

# the resulting graphs are identical
identical(mds_out[[1L]]$graph, mds_out[[2L]]$graph)
# not that as a side-effect, also one of the input graphs is modified in-place for efficiency
mds_in[[1L]]$graph$edges

# The new task has both Sepal and Petal features
identical(mds_out[[1L]]$task, mds_out[[2L]]$task)
mds_out[[2L]]$task

# The new ingress slot contains all ingressors
identical(mds_out[[1L]]$ingress, mds_out[[2L]]$ingress)
mds_out[[1L]]$ingress

# The pointer and pointer_shape slots are different
mds_out[[1L]]$pointer
mds_out[[2L]]$pointer

mds_out[[1L]]$pointer_shape
mds_out[[2L]]$pointer_shape

## Prediction
predict_input = list(input1 = task1, input2 = task2)
tasks_out = do.call(po_torch$predict, args = list(input = predict_input))
identical(tasks_out[[1L]], tasks_out[[2L]])

</code></pre>

<hr>
<h2 id='mlr_pipeops_torch_callbacks'>Callback Configuration</h2><span id='topic+mlr_pipeops_torch_callbacks'></span><span id='topic+PipeOpTorchCallbacks'></span>

<h3>Description</h3>

<p>Configures the callbacks of a deep learning model.
</p>


<h3>Input and Output Channels</h3>

<p>There is one input channel <code>"input"</code> and one output channel <code>"output"</code>.
During <em>training</em>, the channels are of class <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
During <em>prediction</em>, the channels are of class <code><a href="mlr3.html#topic+Task">Task</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code>shapes_out()</code>.
</p>


<h3>Parameters</h3>

<p>The parameters are defined dynamically from the callbacks, where the id of the respective callbacks is the
respective set id.
</p>


<h3>Internals</h3>

<p>During training the callbacks are cloned and added to the <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
</p>


<h3>Super class</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code>PipeOpTorchCallbacks</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchCallbacks-new"><code>PipeOpTorchCallbacks$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchCallbacks-clone"><code>PipeOpTorchCallbacks$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchCallbacks-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchCallbacks$new(
  callbacks = list(),
  id = "torch_callbacks",
  param_vals = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>callbacks</code></dt><dd><p>(<code>list</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s) <br />
The callbacks (or something convertible via <code><a href="#topic+as_torch_callbacks">as_torch_callbacks()</a></code>).
Must have unique ids.
All callbacks are cloned during construction.</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchCallbacks-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchCallbacks$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Model Configuration: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_optimizer">mlr_pipeops_torch_optimizer</a></code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>
</p>
<p>Other PipeOp: 
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch_optimizer">mlr_pipeops_torch_optimizer</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
po_cb = po("torch_callbacks", "checkpoint")
po_cb$param_set
mdin = po("torch_ingress_num")$train(list(tsk("iris")))
mdin[[1L]]$callbacks
mdout = po_cb$train(mdin)[[1L]]
mdout$callbacks
# Can be called again
po_cb1 = po("torch_callbacks", t_clbk("progress"))
mdout1 = po_cb1$train(list(mdout))[[1L]]
mdout1$callbacks

</code></pre>

<hr>
<h2 id='mlr_pipeops_torch_ingress'>Entrypoint to Torch Network</h2><span id='topic+mlr_pipeops_torch_ingress'></span><span id='topic+PipeOpTorchIngress'></span>

<h3>Description</h3>

<p>Use this as entry-point to mlr3torch-networks.
Unless you are an advanced user, you should not need to use this directly but <code><a href="#topic+PipeOpTorchIngressNumeric">PipeOpTorchIngressNumeric</a></code>,
<code><a href="#topic+PipeOpTorchIngressCategorical">PipeOpTorchIngressCategorical</a></code> or <code><a href="#topic+PipeOpTorchIngressLazyTensor">PipeOpTorchIngressLazyTensor</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is set to the input shape.
</p>


<h3>Parameters</h3>

<p>Defined by the construction argument <code>param_set</code>.
</p>


<h3>Internals</h3>

<p>Creates an object of class <code><a href="#topic+TorchIngressToken">TorchIngressToken</a></code> for the given task.
The purpuse of this is to store the information on how to construct the torch dataloader from the task for this
entry point of the network.
</p>


<h3>Super class</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code>PipeOpTorchIngress</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>feature_types</code></dt><dd><p>(<code>character(1)</code>)<br />
The features types that can be consumed by this <code>PipeOpTorchIngress</code>.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchIngress-new"><code>PipeOpTorchIngress$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchIngress-clone"><code>PipeOpTorchIngress$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchIngress-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchIngress$new(
  id,
  param_set = ps(),
  param_vals = list(),
  packages = character(0),
  feature_types
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>)<br />
The parameter set.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
<dt><code>feature_types</code></dt><dd><p>(<code>character()</code>)<br />
The feature types.
See <code><a href="mlr3.html#topic+mlr_reflections">mlr_reflections$task_feature_types</a></code> for available values,
Additionally, <code>"lazy_tensor"</code> is supported.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchIngress-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchIngress$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>
<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>

<hr>
<h2 id='mlr_pipeops_torch_ingress_categ'>Torch Entry Point for Categorical Features</h2><span id='topic+mlr_pipeops_torch_ingress_categ'></span><span id='topic+PipeOpTorchIngressCategorical'></span>

<h3>Description</h3>

<p>Ingress PipeOp that represents a categorical (<code>factor()</code>, <code>ordered()</code> and <code>logical()</code>) entry point to a torch network.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>select</code> :: <code>logical(1)</code><br />
Whether <code>PipeOp</code> should selected the supported feature types. Otherwise it will err on receiving tasks
with unsupported feature types.
</p>
</li></ul>



<h3>Internals</h3>

<p>Uses <code><a href="#topic+batchgetter_categ">batchgetter_categ()</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is set to the input shape.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorchIngress">mlr3torch::PipeOpTorchIngress</a></code> -&gt; <code>PipeOpTorchIngressCategorical</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchIngressCategorical-new"><code>PipeOpTorchIngressCategorical$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchIngressCategorical-clone"><code>PipeOpTorchIngressCategorical$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchIngressCategorical-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchIngressCategorical$new(
  id = "torch_ingress_categ",
  param_vals = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchIngressCategorical-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchIngressCategorical$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>
<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
graph = po("select", selector = selector_type("factor")) %&gt;&gt;%
  po("torch_ingress_categ")
task = tsk("german_credit")
# The output is a model descriptor
md = graph$train(task)[[1L]]
ingress = md$ingress[[1L]]
ingress$batchgetter(task$data(1, ingress$features), "cpu")

</code></pre>

<hr>
<h2 id='mlr_pipeops_torch_ingress_ltnsr'>Ingress for Lazy Tensor</h2><span id='topic+mlr_pipeops_torch_ingress_ltnsr'></span><span id='topic+PipeOpTorchIngressLazyTensor'></span>

<h3>Description</h3>

<p>Ingress for a single <code><a href="#topic+lazy_tensor">lazy_tensor</a></code> column.
</p>


<h3>Parameters</h3>


<ul>
<li> <p><code>shape</code> :: <code>integer()</code><br />
The shape of the tensor, where the first dimension (batch) must be <code>NA</code>.
When it is not specified, the lazy tensor input column needs to have a known shape.
</p>
</li></ul>



<h3>Internals</h3>

<p>The returned batchgetter materializes the lazy tensor column to a tensor.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is set to the input shape.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorchIngress">mlr3torch::PipeOpTorchIngress</a></code> -&gt; <code>PipeOpTorchIngressLazyTensor</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchIngressLazyTensor-new"><code>PipeOpTorchIngressLazyTensor$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchIngressLazyTensor-clone"><code>PipeOpTorchIngressLazyTensor$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchIngressLazyTensor-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchIngressLazyTensor$new(
  id = "torch_ingress_ltnsr",
  param_vals = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchIngressLazyTensor-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchIngressLazyTensor$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>
<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
po_ingress = po("torch_ingress_ltnsr")
task = tsk("lazy_iris")

md = po_ingress$train(list(task))[[1L]]

ingress = md$ingress
x_batch = ingress[[1L]]$batchgetter(data = task$data(1, "x"), device = "cpu", cache = NULL)
x_batch

# Now we try a lazy tensor with unknown shape, i.e. the shapes between the rows can differ

ds = dataset(
  initialize = function() self$x = list(torch_randn(3, 10, 10), torch_randn(3, 8, 8)),
  .getitem = function(i) list(x = self$x[[i]]),
  .length = function() 2)()

task_unknown = as_task_regr(data.table(
  x = as_lazy_tensor(ds, dataset_shapes = list(x = NULL)),
  y = rnorm(2)
), target = "y", id = "example2")

# this task (as it is) can NOT be processed by PipeOpTorchIngressLazyTensor
# It therefore needs to be preprocessed
po_resize = po("trafo_resize", size = c(6, 6))
task_unknown_resize = po_resize$train(list(task_unknown))[[1L]]

# printing the transformed column still shows unknown shapes,
# because the preprocessing pipeop cannot infer them,
# however we know that the shape is now (3, 10, 10) for all rows
task_unknown_resize$data(1:2, "x")
po_ingress$param_set$set_values(shape = c(NA, 3, 6, 6))

md2 = po_ingress$train(list(task_unknown_resize))[[1L]]

ingress2 = md2$ingress
x_batch2 = ingress2[[1L]]$batchgetter(
  data = task_unknown_resize$data(1:2, "x"),
  device = "cpu",
  cache = NULL
)

x_batch2

</code></pre>

<hr>
<h2 id='mlr_pipeops_torch_ingress_num'>Torch Entry Point for Numeric Features</h2><span id='topic+mlr_pipeops_torch_ingress_num'></span><span id='topic+PipeOpTorchIngressNumeric'></span>

<h3>Description</h3>

<p>Ingress PipeOp that represents a numeric (<code>integer()</code> and <code>numeric()</code>) entry point to a torch network.
</p>


<h3>Internals</h3>

<p>Uses <code><a href="#topic+batchgetter_num">batchgetter_num()</a></code>.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is set to the input shape.
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="#topic+PipeOpTorchIngress">mlr3torch::PipeOpTorchIngress</a></code> -&gt; <code>PipeOpTorchIngressNumeric</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchIngressNumeric-new"><code>PipeOpTorchIngressNumeric$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchIngressNumeric-clone"><code>PipeOpTorchIngressNumeric$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchIngressNumeric-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchIngressNumeric$new(id = "torch_ingress_num", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchIngressNumeric-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchIngressNumeric$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>
<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
graph = po("select", selector = selector_type(c("numeric", "integer"))) %&gt;&gt;%
  po("torch_ingress_num")
task = tsk("german_credit")
# The output is a model descriptor
md = graph$train(task)[[1L]]
ingress = md$ingress[[1L]]
ingress$batchgetter(task$data(1:5, ingress$features), "cpu")

</code></pre>

<hr>
<h2 id='mlr_pipeops_torch_loss'>Loss Configuration</h2><span id='topic+mlr_pipeops_torch_loss'></span><span id='topic+PipeOpTorchLoss'></span>

<h3>Description</h3>

<p>Configures the loss of a deep learning model.
</p>


<h3>Input and Output Channels</h3>

<p>One input channel called <code>"input"</code> and one output channel called <code>"output"</code>.
For an explanation see <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code>shapes_out()</code>.
</p>


<h3>Parameters</h3>

<p>The parameters are defined dynamically from the loss set during construction.
</p>


<h3>Internals</h3>

<p>During training the loss is cloned and added to the <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
</p>


<h3>Super class</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code>PipeOpTorchLoss</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchLoss-new"><code>PipeOpTorchLoss$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchLoss-clone"><code>PipeOpTorchLoss$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchLoss-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLoss$new(loss, id = "torch_loss", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>loss</code></dt><dd><p>(<code><a href="#topic+TorchLoss">TorchLoss</a></code> or <code>character(1)</code> or <code>nn_loss</code>)<br />
The loss (or something convertible via <code><a href="#topic+as_torch_loss">as_torch_loss()</a></code>).</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchLoss-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchLoss$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>
<p>Other Model Configuration: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+mlr_pipeops_torch_callbacks">mlr_pipeops_torch_callbacks</a></code>,
<code><a href="#topic+mlr_pipeops_torch_optimizer">mlr_pipeops_torch_optimizer</a></code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
po_loss = po("torch_loss", loss = t_loss("cross_entropy"))
po_loss$param_set
mdin = po("torch_ingress_num")$train(list(tsk("iris")))
mdin[[1L]]$loss
mdout = po_loss$train(mdin)[[1L]]
mdout$loss

</code></pre>

<hr>
<h2 id='mlr_pipeops_torch_model'>PipeOp Torch Model</h2><span id='topic+mlr_pipeops_torch_model'></span><span id='topic+PipeOpTorchModel'></span>

<h3>Description</h3>

<p>Builds a Torch Learner from a <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code> and trains it with the given parameter specification.
The task type must be specified during construction.
</p>


<h3>Input and Output Channels</h3>

<p>There is one input channel <code>"input"</code> that takes in <code>ModelDescriptor</code> during traing and a <code>Task</code> of the specified
<code>task_type</code> during prediction.
The output is <code>NULL</code> during training and a <code>Prediction</code> of given <code>task_type</code> during prediction.
</p>


<h3>State</h3>

<p>A trained <code><a href="#topic+LearnerTorchModel">LearnerTorchModel</a></code>.
</p>


<h3>Parameters</h3>

<p><strong>General</strong>:
</p>
<p>The parameters of the optimizer, loss and callbacks,
prefixed with <code>"opt."</code>, <code>"loss."</code> and <code>"cb.&lt;callback id&gt;."</code> respectively, as well as:
</p>

<ul>
<li> <p><code>epochs</code> :: <code>integer(1)</code><br />
The number of epochs.
</p>
</li>
<li> <p><code>device</code> :: <code>character(1)</code><br />
The device. One of <code>"auto"</code>, <code>"cpu"</code>, or <code>"cuda"</code> or other values defined in <code>mlr_reflections$torch$devices</code>.
The value is initialized to <code>"auto"</code>, which will select <code>"cuda"</code> if possible, then try <code>"mps"</code> and otherwise
fall back to <code>"cpu"</code>.
</p>
</li>
<li> <p><code>num_threads</code> :: <code>integer(1)</code><br />
The number of threads for intraop pararallelization (if <code>device</code> is <code>"cpu"</code>).
This value is initialized to 1.
</p>
</li>
<li> <p><code>seed</code> :: <code>integer(1)</code> or <code>"random"</code><br />
The seed that is used during training and prediction.
This value is initialized to <code>"random"</code>, which means that a random seed will be sampled at the beginning of the
training phase. This seed (either set or randomly sampled) is available via <code style="white-space: pre;">&#8288;$model$seed&#8288;</code> after training
and used during prediction.
Note that by setting the seed during the training phase this will mean that by default (i.e. when <code>seed</code> is
<code>"random"</code>), clones of the learner will use a different seed.
</p>
</li></ul>

<p><strong>Evaluation</strong>:
</p>

<ul>
<li> <p><code>measures_train</code> :: <code><a href="mlr3.html#topic+Measure">Measure</a></code> or <code>list()</code> of <code><a href="mlr3.html#topic+Measure">Measure</a></code>s.<br />
Measures to be evaluated during training.
</p>
</li>
<li> <p><code>measures_valid</code> :: <code><a href="mlr3.html#topic+Measure">Measure</a></code> or <code>list()</code> of <code><a href="mlr3.html#topic+Measure">Measure</a></code>s.<br />
Measures to be evaluated during validation.
</p>
</li>
<li> <p><code>eval_freq</code> :: <code>integer(1)</code><br />
How often the train / validation predictions are evaluated using <code>measures_train</code> / <code>measures_valid</code>.
This is initialized to <code>1</code>.
Note that the final model is always evaluated.
</p>
</li></ul>

<p><strong>Early Stopping</strong>:
</p>

<ul>
<li> <p><code>patience</code> :: <code>integer(1)</code><br />
This activates early stopping using the validation scores.
If the performance of a model does not improve for <code>patience</code> evaluation steps, training is ended.
Note that the final model is stored in the learner, not the best model.
This is initialized to <code>0</code>, which means no early stopping.
The first entry from <code>measures_valid</code> is used as the metric.
This also requires to specify the <code style="white-space: pre;">&#8288;$validate&#8288;</code> field of the Learner, as well as <code>measures_valid</code>.
</p>
</li>
<li> <p><code>min_delta</code> :: <code>double(1)</code><br />
The minimum improvement threshold (<code>&gt;</code>) for early stopping.
Is initialized to 0.
</p>
</li></ul>

<p><strong>Dataloader</strong>:
</p>

<ul>
<li> <p><code>batch_size</code> :: <code>integer(1)</code><br />
The batch size (required).
</p>
</li>
<li> <p><code>shuffle</code> :: <code>logical(1)</code><br />
Whether to shuffle the instances in the dataset. Default is <code>FALSE</code>.
This does not impact validation.
</p>
</li>
<li> <p><code>sampler</code> :: <code><a href="torch.html#topic+sampler">torch::sampler</a></code><br />
Object that defines how the dataloader draw samples.
</p>
</li>
<li> <p><code>batch_sampler</code> :: <code><a href="torch.html#topic+sampler">torch::sampler</a></code><br />
Object that defines how the dataloader draws batches.
</p>
</li>
<li> <p><code>num_workers</code> :: <code>integer(1)</code><br />
The number of workers for data loading (batches are loaded in parallel).
The default is <code>0</code>, which means that data will be loaded in the main process.
</p>
</li>
<li> <p><code>collate_fn</code> :: <code>function</code><br />
How to merge a list of samples to form a batch.
</p>
</li>
<li> <p><code>pin_memory</code> :: <code>logical(1)</code><br />
Whether the dataloader copies tensors into CUDA pinned memory before returning them.
</p>
</li>
<li> <p><code>drop_last</code> :: <code>logical(1)</code><br />
Whether to drop the last training batch in each epoch during training. Default is <code>FALSE</code>.
</p>
</li>
<li> <p><code>timeout</code> :: <code>numeric(1)</code><br />
The timeout value for collecting a batch from workers.
Negative values mean no timeout and the default is <code>-1</code>.
</p>
</li>
<li> <p><code>worker_init_fn</code> :: <code style="white-space: pre;">&#8288;function(id)&#8288;</code><br />
A function that receives the worker id (in <code style="white-space: pre;">&#8288;[1, num_workers]&#8288;</code>) and is exectued after seeding
on the worker but before data loading.
</p>
</li>
<li> <p><code>worker_globals</code> :: <code>list()</code> | <code>character()</code><br />
When loading data in parallel, this allows to export globals to the workers.
If this is a character vector, the objects in the global environment with those names
are copied to the workers.
</p>
</li>
<li> <p><code>worker_packages</code> :: <code>character()</code><br />
Which packages to load on the workers.
</p>
</li></ul>

<p>Also see <code>torch::dataloder</code> for more information.
</p>


<h3>Internals</h3>

<p>A <code><a href="#topic+LearnerTorchModel">LearnerTorchModel</a></code> is created by calling <code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner()</a></code> on the
provided <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code> that is received through the input channel.
Then the parameters are set according to the parameters specified in <code>PipeOpTorchModel</code> and
its '$train()<code style="white-space: pre;">&#8288; method is called on the [&#8288;</code>Task<code style="white-space: pre;">&#8288;][mlr3::Task] stored in the [&#8288;</code>ModelDescriptor'].
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpLearner">mlr3pipelines::PipeOpLearner</a></code> -&gt; <code>PipeOpTorchModel</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchModel-new"><code>PipeOpTorchModel$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchModel-clone"><code>PipeOpTorchModel$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchModel-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchModel$new(task_type, id = "torch_model", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>task_type</code></dt><dd><p>(<code>character(1)</code>)<br />
The task type of the model.</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchModel-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchModel$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>

<hr>
<h2 id='mlr_pipeops_torch_model_classif'>PipeOp Torch Classifier</h2><span id='topic+mlr_pipeops_torch_model_classif'></span><span id='topic+PipeOpTorchModelClassif'></span>

<h3>Description</h3>

<p>Builds a torch classifier and trains it.
</p>


<h3>Parameters</h3>

<p>See <code><a href="#topic+LearnerTorch">LearnerTorch</a></code>
</p>


<h3>Input and Output Channels</h3>

<p>There is one input channel <code>"input"</code> that takes in <code>ModelDescriptor</code> during traing and a <code>Task</code> of the specified
<code>task_type</code> during prediction.
The output is <code>NULL</code> during training and a <code>Prediction</code> of given <code>task_type</code> during prediction.
</p>


<h3>State</h3>

<p>A trained <code><a href="#topic+LearnerTorchModel">LearnerTorchModel</a></code>.
</p>


<h3>Internals</h3>

<p>A <code><a href="#topic+LearnerTorchModel">LearnerTorchModel</a></code> is created by calling <code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner()</a></code> on the
provided <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code> that is received through the input channel.
Then the parameters are set according to the parameters specified in <code>PipeOpTorchModel</code> and
its '$train()<code style="white-space: pre;">&#8288; method is called on the [&#8288;</code>Task<code style="white-space: pre;">&#8288;][mlr3::Task] stored in the [&#8288;</code>ModelDescriptor'].
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpLearner">mlr3pipelines::PipeOpLearner</a></code> -&gt; <code><a href="#topic+PipeOpTorchModel">mlr3torch::PipeOpTorchModel</a></code> -&gt; <code>PipeOpTorchModelClassif</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchModelClassif-new"><code>PipeOpTorchModelClassif$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchModelClassif-clone"><code>PipeOpTorchModelClassif$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchModelClassif-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchModelClassif$new(id = "torch_model_classif", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchModelClassif-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchModelClassif$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_regr">mlr_pipeops_torch_model_regr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# simple logistic regression

# configure the model descriptor
md = as_graph(po("torch_ingress_num") %&gt;&gt;%
  po("nn_head") %&gt;&gt;%
  po("torch_loss", "cross_entropy") %&gt;&gt;%
  po("torch_optimizer", "adam"))$train(tsk("iris"))[[1L]]

print(md)

# build the learner from the model descriptor and train it
po_model = po("torch_model_classif", batch_size = 50, epochs = 1)
po_model$train(list(md))
po_model$state

</code></pre>

<hr>
<h2 id='mlr_pipeops_torch_model_regr'>Torch Regression Model</h2><span id='topic+mlr_pipeops_torch_model_regr'></span><span id='topic+PipeOpTorchModelRegr'></span>

<h3>Description</h3>

<p>Builds a torch regression model and trains it.
</p>


<h3>Parameters</h3>

<p>See <code><a href="#topic+LearnerTorch">LearnerTorch</a></code>
</p>


<h3>Input and Output Channels</h3>

<p>There is one input channel <code>"input"</code> that takes in <code>ModelDescriptor</code> during traing and a <code>Task</code> of the specified
<code>task_type</code> during prediction.
The output is <code>NULL</code> during training and a <code>Prediction</code> of given <code>task_type</code> during prediction.
</p>


<h3>State</h3>

<p>A trained <code><a href="#topic+LearnerTorchModel">LearnerTorchModel</a></code>.
</p>


<h3>Internals</h3>

<p>A <code><a href="#topic+LearnerTorchModel">LearnerTorchModel</a></code> is created by calling <code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner()</a></code> on the
provided <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code> that is received through the input channel.
Then the parameters are set according to the parameters specified in <code>PipeOpTorchModel</code> and
its '$train()<code style="white-space: pre;">&#8288; method is called on the [&#8288;</code>Task<code style="white-space: pre;">&#8288;][mlr3::Task] stored in the [&#8288;</code>ModelDescriptor'].
</p>


<h3>Super classes</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code><a href="mlr3pipelines.html#topic+PipeOpLearner">mlr3pipelines::PipeOpLearner</a></code> -&gt; <code><a href="#topic+PipeOpTorchModel">mlr3torch::PipeOpTorchModel</a></code> -&gt; <code>PipeOpTorchModelRegr</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchModelRegr-new"><code>PipeOpTorchModelRegr$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchModelRegr-clone"><code>PipeOpTorchModelRegr$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchModelRegr-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchModelRegr$new(id = "torch_model_regr", param_vals = list())</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchModelRegr-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchModelRegr$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOps: 
<code><a href="#topic+mlr_pipeops_nn_avg_pool1d">mlr_pipeops_nn_avg_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool2d">mlr_pipeops_nn_avg_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_avg_pool3d">mlr_pipeops_nn_avg_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm1d">mlr_pipeops_nn_batch_norm1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm2d">mlr_pipeops_nn_batch_norm2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_batch_norm3d">mlr_pipeops_nn_batch_norm3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_block">mlr_pipeops_nn_block</a></code>,
<code><a href="#topic+mlr_pipeops_nn_celu">mlr_pipeops_nn_celu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv1d">mlr_pipeops_nn_conv1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv2d">mlr_pipeops_nn_conv2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv3d">mlr_pipeops_nn_conv3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose1d">mlr_pipeops_nn_conv_transpose1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose2d">mlr_pipeops_nn_conv_transpose2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_conv_transpose3d">mlr_pipeops_nn_conv_transpose3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_dropout">mlr_pipeops_nn_dropout</a></code>,
<code><a href="#topic+mlr_pipeops_nn_elu">mlr_pipeops_nn_elu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_flatten">mlr_pipeops_nn_flatten</a></code>,
<code><a href="#topic+mlr_pipeops_nn_gelu">mlr_pipeops_nn_gelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_glu">mlr_pipeops_nn_glu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardshrink">mlr_pipeops_nn_hardshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardsigmoid">mlr_pipeops_nn_hardsigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_hardtanh">mlr_pipeops_nn_hardtanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_head">mlr_pipeops_nn_head</a></code>,
<code><a href="#topic+mlr_pipeops_nn_layer_norm">mlr_pipeops_nn_layer_norm</a></code>,
<code><a href="#topic+mlr_pipeops_nn_leaky_relu">mlr_pipeops_nn_leaky_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_linear">mlr_pipeops_nn_linear</a></code>,
<code><a href="#topic+mlr_pipeops_nn_log_sigmoid">mlr_pipeops_nn_log_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool1d">mlr_pipeops_nn_max_pool1d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool2d">mlr_pipeops_nn_max_pool2d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_max_pool3d">mlr_pipeops_nn_max_pool3d</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge">mlr_pipeops_nn_merge</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_cat">mlr_pipeops_nn_merge_cat</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_prod">mlr_pipeops_nn_merge_prod</a></code>,
<code><a href="#topic+mlr_pipeops_nn_merge_sum">mlr_pipeops_nn_merge_sum</a></code>,
<code><a href="#topic+mlr_pipeops_nn_prelu">mlr_pipeops_nn_prelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu">mlr_pipeops_nn_relu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_relu6">mlr_pipeops_nn_relu6</a></code>,
<code><a href="#topic+mlr_pipeops_nn_reshape">mlr_pipeops_nn_reshape</a></code>,
<code><a href="#topic+mlr_pipeops_nn_rrelu">mlr_pipeops_nn_rrelu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_selu">mlr_pipeops_nn_selu</a></code>,
<code><a href="#topic+mlr_pipeops_nn_sigmoid">mlr_pipeops_nn_sigmoid</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softmax">mlr_pipeops_nn_softmax</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softplus">mlr_pipeops_nn_softplus</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softshrink">mlr_pipeops_nn_softshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_softsign">mlr_pipeops_nn_softsign</a></code>,
<code><a href="#topic+mlr_pipeops_nn_squeeze">mlr_pipeops_nn_squeeze</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanh">mlr_pipeops_nn_tanh</a></code>,
<code><a href="#topic+mlr_pipeops_nn_tanhshrink">mlr_pipeops_nn_tanhshrink</a></code>,
<code><a href="#topic+mlr_pipeops_nn_threshold">mlr_pipeops_nn_threshold</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model">mlr_pipeops_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_torch_model_classif">mlr_pipeops_torch_model_classif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# simple linear regression

# build the model descriptor
md = as_graph(po("torch_ingress_num") %&gt;&gt;%
  po("nn_head") %&gt;&gt;%
  po("torch_loss", "mse") %&gt;&gt;%
  po("torch_optimizer", "adam"))$train(tsk("mtcars"))[[1L]]

print(md)

# build the learner from the model descriptor and train it
po_model = po("torch_model_regr", batch_size = 20, epochs = 1)
po_model$train(list(md))
po_model$state

</code></pre>

<hr>
<h2 id='mlr_pipeops_torch_optimizer'>Optimizer Configuration</h2><span id='topic+mlr_pipeops_torch_optimizer'></span><span id='topic+PipeOpTorchOptimizer'></span>

<h3>Description</h3>

<p>Configures the optimizer of a deep learning model.
</p>


<h3>Input and Output Channels</h3>

<p>There is one input channel <code>"input"</code> and one output channel <code>"output"</code>.
During <em>training</em>, the channels are of class <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
During <em>prediction</em>, the channels are of class <code><a href="mlr3.html#topic+Task">Task</a></code>.
</p>


<h3>State</h3>

<p>The state is the value calculated by the public method <code>shapes_out()</code>.
</p>


<h3>Parameters</h3>

<p>The parameters are defined dynamically from the optimizer that is set during construction.
</p>


<h3>Internals</h3>

<p>During training, the optimizer is cloned and added to the <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
Note that the parameter set of the stored <code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code> is reference-identical to the parameter set of the
pipeop itself.
</p>


<h3>Super class</h3>

<p><code><a href="mlr3pipelines.html#topic+PipeOp">mlr3pipelines::PipeOp</a></code> -&gt; <code>PipeOpTorchOptimizer</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-PipeOpTorchOptimizer-new"><code>PipeOpTorchOptimizer$new()</code></a>
</p>
</li>
<li> <p><a href="#method-PipeOpTorchOptimizer-clone"><code>PipeOpTorchOptimizer$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-PipeOpTorchOptimizer-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchOptimizer$new(
  optimizer = t_opt("adam"),
  id = "torch_optimizer",
  param_vals = list()
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>optimizer</code></dt><dd><p>(<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code> or <code>character(1)</code> or <code>torch_optimizer_generator</code>)<br />
The optimizer (or something convertible via <code><a href="#topic+as_torch_optimizer">as_torch_optimizer()</a></code>).</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the resulting  object.</p>
</dd>
<dt><code>param_vals</code></dt><dd><p>(<code>list()</code>)<br />
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-PipeOpTorchOptimizer-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>PipeOpTorchOptimizer$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other PipeOp: 
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch_callbacks">mlr_pipeops_torch_callbacks</a></code>
</p>
<p>Other Model Configuration: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+mlr_pipeops_torch_callbacks">mlr_pipeops_torch_callbacks</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
po_opt = po("torch_optimizer", "sgd", lr = 0.01)
po_opt$param_set
mdin = po("torch_ingress_num")$train(list(tsk("iris")))
mdin[[1L]]$optimizer
mdout = po_opt$train(mdin)
mdout[[1L]]$optimizer

</code></pre>

<hr>
<h2 id='mlr_tasks_lazy_iris'>Iris Classification Task</h2><span id='topic+mlr_tasks_lazy_iris'></span>

<h3>Description</h3>

<p>A classification task for the popular <a href="datasets.html#topic+iris">datasets::iris</a> data set.
Just like the iris task, but the features are represented as one lazy tensor column.
</p>


<h3>Format</h3>

<p><a href="R6.html#topic+R6Class">R6::R6Class</a> inheriting from <a href="mlr3.html#topic+TaskClassif">mlr3::TaskClassif</a>.
</p>


<h3>Construction</h3>

<div class="sourceCode"><pre>tsk("lazy_iris")
</pre></div>


<h3>Properties</h3>


<ul>
<li><p> Task type: &ldquo;classif&rdquo;
</p>
</li>
<li><p> Properties: &ldquo;multiclass&rdquo;
</p>
</li>
<li><p> Has Missings: no
</p>
</li>
<li><p> Target: &ldquo;Species&rdquo;
</p>
</li>
<li><p> Features: &ldquo;x&rdquo;
</p>
</li>
<li><p> Data Dimension: 150x3
</p>
</li></ul>



<h3>Source</h3>

<p><a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>
</p>


<h3>References</h3>

<p>Anderson E (1936).
&ldquo;The Species Problem in Iris.&rdquo;
<em>Annals of the Missouri Botanical Garden</em>, <b>23</b>(3), 457.
<a href="https://doi.org/10.2307/2394164">doi:10.2307/2394164</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
task = tsk("lazy_iris")
task
df = task$data()
materialize(df$x[1:6], rbind = TRUE)

</code></pre>

<hr>
<h2 id='mlr_tasks_mnist'>MNIST Image classification</h2><span id='topic+mlr_tasks_mnist'></span>

<h3>Description</h3>

<p>Classic MNIST image classification.
</p>
<p>The underlying <code><a href="mlr3.html#topic+DataBackend">DataBackend</a></code> contains columns <code>"label"</code>, <code>"image"</code>, <code>"row_id"</code>, <code>"split"</code>, where the last column
indicates whether the row belongs to the train or test set.
</p>
<p>The first 60000 rows belong to the training set, the last 10000 rows to the test set.
</p>


<h3>Construction</h3>

<div class="sourceCode"><pre>tsk("mnist")
</pre></div>


<h3>Download</h3>

<p>The <a href="mlr3.html#topic+Task">task</a>'s backend is a <code><a href="#topic+DataBackendLazy">DataBackendLazy</a></code> which will download the data once it is requested.
Other meta-data is already available before that.
You can cache these datasets by setting the <code>mlr3torch.cache</code> option to <code>TRUE</code> or to a specific path to be used
as the cache directory.
</p>


<h3>Properties</h3>


<ul>
<li><p> Task type: &ldquo;classif&rdquo;
</p>
</li>
<li><p> Properties: &ldquo;multiclass&rdquo;
</p>
</li>
<li><p> Has Missings: no
</p>
</li>
<li><p> Target: &ldquo;label&rdquo;
</p>
</li>
<li><p> Features: &ldquo;image&rdquo;
</p>
</li>
<li><p> Data Dimension: 70000x4
</p>
</li></ul>



<h3>Source</h3>

<p><a href="https://torchvision.mlverse.org/reference/mnist_dataset.html">https://torchvision.mlverse.org/reference/mnist_dataset.html</a>
</p>


<h3>References</h3>

<p>Lecun, Y., Bottou, L., Bengio, Y., Haffner, P. (1998).
&ldquo;Gradient-based learning applied to document recognition.&rdquo;
<em>Proceedings of the IEEE</em>, <b>86</b>(11), 2278-2324.
<a href="https://doi.org/10.1109/5.726791">doi:10.1109/5.726791</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
task = tsk("mnist")
task

</code></pre>

<hr>
<h2 id='mlr_tasks_tiny_imagenet'>Tiny ImageNet Classification Task</h2><span id='topic+mlr_tasks_tiny_imagenet'></span>

<h3>Description</h3>

<p>Subset of the famous ImageNet dataset.
The data is obtained from <code><a href="torchvision.html#topic+tiny_imagenet_dataset">torchvision::tiny_imagenet_dataset()</a></code>.
</p>
<p>The underlying <code><a href="mlr3.html#topic+DataBackend">DataBackend</a></code> contains columns <code>"class"</code>, <code>"image"</code>, <code>"..row_id"</code>, <code>"split"</code>, where the last column
indicates whether the row belongs to the train, validation or test set that defined provided in torchvision.
</p>
<p>There are no labels for the test rows, so by default, these observations are inactive, which means that the task
uses only 110000 of the 120000 observations that are defined in the underlying data backend.
</p>


<h3>Construction</h3>

<div class="sourceCode"><pre>tsk("tiny_imagenet")
</pre></div>


<h3>Download</h3>

<p>The <a href="mlr3.html#topic+Task">task</a>'s backend is a <code><a href="#topic+DataBackendLazy">DataBackendLazy</a></code> which will download the data once it is requested.
Other meta-data is already available before that.
You can cache these datasets by setting the <code>mlr3torch.cache</code> option to <code>TRUE</code> or to a specific path to be used
as the cache directory.
</p>


<h3>Properties</h3>


<ul>
<li><p> Task type: &ldquo;classif&rdquo;
</p>
</li>
<li><p> Properties: &ldquo;multiclass&rdquo;
</p>
</li>
<li><p> Has Missings: no
</p>
</li>
<li><p> Target: &ldquo;class&rdquo;
</p>
</li>
<li><p> Features: &ldquo;image&rdquo;
</p>
</li>
<li><p> Data Dimension: 120000x4
</p>
</li></ul>



<h3>References</h3>

<p>Deng, Jia, Dong, Wei, Socher, Richard, Li, Li-Jia, Li, Kai, Fei-Fei, Li (2009).
&ldquo;Imagenet: A large-scale hierarchical image database.&rdquo;
In <em>2009 IEEE conference on computer vision and pattern recognition</em>, 248&ndash;255.
IEEE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
task = tsk("tiny_imagenet")
task

</code></pre>

<hr>
<h2 id='mlr3torch_callbacks'>Dictionary of Torch Callbacks</h2><span id='topic+mlr3torch_callbacks'></span>

<h3>Description</h3>

<p>A <code><a href="mlr3misc.html#topic+Dictionary">mlr3misc::Dictionary</a></code> of torch callbacks.
Use <code><a href="#topic+t_clbk">t_clbk()</a></code> to conveniently retrieve callbacks.
Can be converted to a <code><a href="data.table.html#topic+data.table">data.table</a></code> using
<code><a href="data.table.html#topic+as.data.table">as.data.table</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlr3torch_callbacks
</code></pre>


<h3>Format</h3>

<p>An object of class <code>DictionaryMlr3torchCallbacks</code> (inherits from <code>Dictionary</code>, <code>R6</code>) of length 13.
</p>


<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>
<p>Other Dictionary: 
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mlr3torch_callbacks$get("checkpoint")
# is the same as
t_clbk("checkpoint")
# convert to a data.table
as.data.table(mlr3torch_callbacks)

</code></pre>

<hr>
<h2 id='mlr3torch_losses'>Loss Functions</h2><span id='topic+mlr3torch_losses'></span>

<h3>Description</h3>

<p>Dictionary of torch loss descriptors.
See <code><a href="#topic+t_loss">t_loss()</a></code> for conveniently retrieving a loss function.
Can be converted to a <code><a href="data.table.html#topic+data.table">data.table</a></code> using
<code><a href="data.table.html#topic+as.data.table">as.data.table</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlr3torch_losses
</code></pre>


<h3>Format</h3>

<p>An object of class <code>DictionaryMlr3torchLosses</code> (inherits from <code>Dictionary</code>, <code>R6</code>) of length 13.
</p>


<h3>Available Loss Functions</h3>

<p>cross_entropy, l1, mse
</p>


<h3>See Also</h3>

<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>
<p>Other Dictionary: 
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mlr3torch_losses$get("mse")
# is equivalent to
t_loss("mse")
# convert to a data.table
as.data.table(mlr3torch_losses)

</code></pre>

<hr>
<h2 id='mlr3torch_optimizers'>Optimizers</h2><span id='topic+mlr3torch_optimizers'></span>

<h3>Description</h3>

<p>Dictionary of torch optimizers.
Use <code><a href="#topic+t_opt">t_opt</a></code> for conveniently retrieving optimizers.
Can be converted to a <code><a href="data.table.html#topic+data.table">data.table</a></code> using
<code><a href="data.table.html#topic+as.data.table">as.data.table</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlr3torch_optimizers
</code></pre>


<h3>Format</h3>

<p>An object of class <code>DictionaryMlr3torchOptimizers</code> (inherits from <code>Dictionary</code>, <code>R6</code>) of length 13.
</p>


<h3>Available Optimizers</h3>

<p>adadelta, adagrad, adam, asgd, rmsprop, rprop, sgd
</p>


<h3>See Also</h3>

<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>
<p>Other Dictionary: 
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mlr3torch_optimizers$get("adam")
# is equivalent to
t_opt("adam")
# convert to a data.table
as.data.table(mlr3torch_optimizers)

</code></pre>

<hr>
<h2 id='model_descriptor_to_learner'>Create a Torch Learner from a ModelDescriptor</h2><span id='topic+model_descriptor_to_learner'></span>

<h3>Description</h3>

<p>First a <code><a href="#topic+nn_graph">nn_graph</a></code> is created using <code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a></code> and then a learner is created from this
module and the remaining information from the model descriptor, which must include the optimizer and loss function
and optionally callbacks.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_descriptor_to_learner(model_descriptor)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_descriptor_to_learner_+3A_model_descriptor">model_descriptor</code></td>
<td>
<p>(<code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>)<br />
The model descriptor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="mlr3.html#topic+Learner">Learner</a></code>
</p>


<h3>See Also</h3>

<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>

<hr>
<h2 id='model_descriptor_to_module'>Create a nn_graph from ModelDescriptor</h2><span id='topic+model_descriptor_to_module'></span>

<h3>Description</h3>

<p>Creates the <code><a href="#topic+nn_graph">nn_graph</a></code> from a <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>. Mostly for internal use, since the <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code> is in
most circumstances harder to use than just creating <code><a href="#topic+nn_graph">nn_graph</a></code> directly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>model_descriptor_to_module(
  model_descriptor,
  output_pointers = NULL,
  list_output = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_descriptor_to_module_+3A_model_descriptor">model_descriptor</code></td>
<td>
<p>(<code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>)<br />
Model Descriptor. <code>pointer</code> is ignored, instead <code>output_pointer</code> values are used. <code style="white-space: pre;">&#8288;$graph&#8288;</code> member is
modified by-reference.</p>
</td></tr>
<tr><td><code id="model_descriptor_to_module_+3A_output_pointers">output_pointers</code></td>
<td>
<p>(<code>list</code> of <code>character</code>)<br />
Collection of <code>pointer</code>s that indicate what part of the <code>model_descriptor$graph</code> is being used for output.
Entries have the format of <code>ModelDescriptor$pointer</code>.</p>
</td></tr>
<tr><td><code id="model_descriptor_to_module_+3A_list_output">list_output</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether output should be a list of tensors. If <code>FALSE</code>, then <code>length(output_pointers)</code> must be 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+nn_graph">nn_graph</a></code>
</p>


<h3>See Also</h3>

<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>

<hr>
<h2 id='model_descriptor_union'>Union of ModelDescriptors</h2><span id='topic+model_descriptor_union'></span>

<h3>Description</h3>

<p>This is a mostly internal function that is used in <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>s with multiple input channels.
</p>
<p>It creates the union of multiple <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>s:
</p>

<ul>
<li> <p><code>graph</code>s are combinded (if they are not identical to begin with). The first entry's <code>graph</code> is modified by
reference.
</p>
</li>
<li> <p><code>PipeOp</code>s with the same ID must be identical. No new input edges may be added to <code>PipeOp</code>s.
</p>
</li>
<li><p> Drops <code>pointer</code> / <code>pointer_shape</code> entries.
</p>
</li>
<li><p> The new task is the <a href="mlr3pipelines.html#topic+mlr_pipeops_featureunion">feature union</a> of the two incoming tasks.
</p>
</li>
<li><p> The <code>optimizer</code> and <code>loss</code> of both <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>s must be identical.
</p>
</li>
<li><p> Ingress tokens and callbacks are merged, where objects with the same <code>"id"</code> must be identical.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>model_descriptor_union(md1, md2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model_descriptor_union_+3A_md1">md1</code></td>
<td>
<p>(<code>ModelDescriptor</code>)
The first <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.</p>
</td></tr>
<tr><td><code id="model_descriptor_union_+3A_md2">md2</code></td>
<td>
<p>(<code>ModelDescriptor</code>)
The second <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The requirement that no new input edgedes may be added to <code>PipeOp</code>s  is not theoretically necessary, but since
we assume that ModelDescriptor is being built from beginning to end (i.e. <code>PipeOp</code>s never get new ancestors) we
can make this assumption and simplify things. Otherwise we'd need to treat &quot;...&quot;-inputs special.)
</p>


<h3>Value</h3>

<p><code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>
</p>


<h3>See Also</h3>

<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>
<p>Other Model Configuration: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+mlr_pipeops_torch_callbacks">mlr_pipeops_torch_callbacks</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_optimizer">mlr_pipeops_torch_optimizer</a></code>
</p>

<hr>
<h2 id='ModelDescriptor'>Represent a Model with Meta-Info</h2><span id='topic+ModelDescriptor'></span>

<h3>Description</h3>

<p>Represents a <em>model</em>; possibly a complete model, possibly one in the process of being built up.
</p>
<p>This model takes input tensors of shapes <code>shapes_in</code> and
pipes them through <code>graph</code>. Input shapes get mapped to input channels of <code>graph</code>.
Output shapes are named by the output channels of <code>graph</code>; it is also possible
to represent no-ops on tensors, in which case names of input and output should be identical.
</p>
<p><code>ModelDescriptor</code> objects typically represent partial models being built up, in which case the <code>pointer</code> slot
indicates a specific point in the graph that produces a tensor of shape <code>pointer_shape</code>, on which the graph should
be extended.
It is allowed for the <code>graph</code> in this structure to be modified by-reference in different parts of the code.
However, these modifications may never add edges with elements of the <code>Graph</code> as destination. In particular, no
element of <code>graph$input</code> may be removed by reference, e.g. by adding an edge to the <code>Graph</code> that has the input
channel of a <code>PipeOp</code> that was previously without parent as its destination.
</p>
<p>In most cases it is better to create a specific <code>ModelDescriptor</code> by training a <code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code> consisting (mostly) of
operators <code><a href="#topic+PipeOpTorchIngress">PipeOpTorchIngress</a></code>, <code><a href="#topic+PipeOpTorch">PipeOpTorch</a></code>, <code><a href="#topic+PipeOpTorchLoss">PipeOpTorchLoss</a></code>, <code><a href="#topic+PipeOpTorchOptimizer">PipeOpTorchOptimizer</a></code>, and
<code><a href="#topic+PipeOpTorchCallbacks">PipeOpTorchCallbacks</a></code>.
</p>
<p>A <code>ModelDescriptor</code> can be converted to a <code><a href="#topic+nn_graph">nn_graph</a></code> via <code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ModelDescriptor(
  graph,
  ingress,
  task,
  optimizer = NULL,
  loss = NULL,
  callbacks = NULL,
  pointer = NULL,
  pointer_shape = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ModelDescriptor_+3A_graph">graph</code></td>
<td>
<p>(<code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code>)<br />
<code>Graph</code> of <code><a href="#topic+PipeOpModule">PipeOpModule</a></code> and <code><a href="mlr3pipelines.html#topic+mlr_pipeops_nop">PipeOpNOP</a></code> operators.</p>
</td></tr>
<tr><td><code id="ModelDescriptor_+3A_ingress">ingress</code></td>
<td>
<p>(uniquely named <code>list</code> of <code>TorchIngressToken</code>)<br />
List of inputs that go into <code>graph</code>. Names of this must be a subset of <code>graph$input$name</code>.</p>
</td></tr>
<tr><td><code id="ModelDescriptor_+3A_task">task</code></td>
<td>
<p>(<code><a href="mlr3.html#topic+Task">Task</a></code>)<br />
(Training)-Task for which the model is being built. May be necessary for for some aspects of what loss to use etc.</p>
</td></tr>
<tr><td><code id="ModelDescriptor_+3A_optimizer">optimizer</code></td>
<td>
<p>(<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code> | <code>NULL</code>)<br />
Additional info: what optimizer to use.</p>
</td></tr>
<tr><td><code id="ModelDescriptor_+3A_loss">loss</code></td>
<td>
<p>(<code><a href="#topic+TorchLoss">TorchLoss</a></code> | <code>NULL</code>)<br />
Additional info: what loss to use.</p>
</td></tr>
<tr><td><code id="ModelDescriptor_+3A_callbacks">callbacks</code></td>
<td>
<p>(A <code>list</code> of <code><a href="#topic+CallbackSet">CallbackSet</a></code> or <code>NULL</code>)<br />
Additional info: what callbacks to use.</p>
</td></tr>
<tr><td><code id="ModelDescriptor_+3A_pointer">pointer</code></td>
<td>
<p>(<code>character(2)</code> | <code>NULL</code>)<br />
Indicating an element on which a model is. Points to an output channel within <code>graph</code>:
Element 1 is the <code>PipeOp</code>'s id and element 2 is that <code>PipeOp</code>'s output channel.</p>
</td></tr>
<tr><td><code id="ModelDescriptor_+3A_pointer_shape">pointer_shape</code></td>
<td>
<p>(<code>integer</code> | <code>NULL</code>)<br />
Shape of the output indicated by <code>pointer</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(<code>ModelDescriptor</code>)
</p>


<h3>See Also</h3>

<p>Other Model Configuration: 
<code><a href="#topic+mlr_pipeops_torch_callbacks">mlr_pipeops_torch_callbacks</a></code>,
<code><a href="#topic+mlr_pipeops_torch_loss">mlr_pipeops_torch_loss</a></code>,
<code><a href="#topic+mlr_pipeops_torch_optimizer">mlr_pipeops_torch_optimizer</a></code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>
</p>
<p>Other Graph Network: 
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>

<hr>
<h2 id='nn_graph'>Graph Network</h2><span id='topic+nn_graph'></span>

<h3>Description</h3>

<p>Represents a neural network using a <code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code> that usually costains mostly <code><a href="#topic+PipeOpModule">PipeOpModule</a></code>s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_graph(graph, shapes_in, output_map = graph$output$name, list_output = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nn_graph_+3A_graph">graph</code></td>
<td>
<p>(<code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code>)<br />
The <code><a href="mlr3pipelines.html#topic+Graph">Graph</a></code> to wrap. Is <strong>not</strong> cloned.</p>
</td></tr>
<tr><td><code id="nn_graph_+3A_shapes_in">shapes_in</code></td>
<td>
<p>(named <code>integer</code>)<br />
Shape info of tensors that go into <code>graph</code>. Names must be <code>graph$input$name</code>, possibly in different order.</p>
</td></tr>
<tr><td><code id="nn_graph_+3A_output_map">output_map</code></td>
<td>
<p>(<code>character</code>)<br />
Which of <code>graph</code>'s outputs to use. Must be a subset of <code>graph$output$name</code>.</p>
</td></tr>
<tr><td><code id="nn_graph_+3A_list_output">list_output</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether output should be a list of tensors. If <code>FALSE</code> (default), then <code>length(output_map)</code> must be 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+nn_graph">nn_graph</a></code>
</p>


<h3>See Also</h3>

<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+TorchIngressToken">TorchIngressToken</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
graph = mlr3pipelines::Graph$new()
graph$add_pipeop(po("module_1", module = nn_linear(10, 20)), clone = FALSE)
graph$add_pipeop(po("module_2", module = nn_relu()), clone = FALSE)
graph$add_pipeop(po("module_3", module = nn_linear(20, 1)), clone = FALSE)
graph$add_edge("module_1", "module_2")
graph$add_edge("module_2", "module_3")

network = nn_graph(graph, shapes_in = list(module_1.input = c(NA, 10)))

x = torch_randn(16, 10)

network(module_1.input = x)

</code></pre>

<hr>
<h2 id='nn_merge_cat'>Concatenates multiple tensors</h2><span id='topic+nn_merge_cat'></span>

<h3>Description</h3>

<p>Concatenates multiple tensors on a given dimension.
No broadcasting rules are applied here, you must reshape the tensors before to have the same shape.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_merge_cat(dim = -1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nn_merge_cat_+3A_dim">dim</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The dimension for the concatenation.</p>
</td></tr>
</table>

<hr>
<h2 id='nn_merge_prod'>Product of multiple tensors</h2><span id='topic+nn_merge_prod'></span>

<h3>Description</h3>

<p>Calculates the product of all input tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_merge_prod()
</code></pre>

<hr>
<h2 id='nn_merge_sum'>Sum of multiple tensors</h2><span id='topic+nn_merge_sum'></span>

<h3>Description</h3>

<p>Calculates the sum of all input tensors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_merge_sum()
</code></pre>

<hr>
<h2 id='nn_reshape'>Reshape</h2><span id='topic+nn_reshape'></span>

<h3>Description</h3>

<p>Reshape a tensor to the given shape.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_reshape(shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nn_reshape_+3A_shape">shape</code></td>
<td>
<p>(<code>integer()</code>)<br />
The desired output shape.</p>
</td></tr>
</table>

<hr>
<h2 id='nn_squeeze'>Squeeze</h2><span id='topic+nn_squeeze'></span>

<h3>Description</h3>

<p>Squeezes a tensor by calling <code><a href="torch.html#topic+torch_squeeze">torch::torch_squeeze()</a></code> with the given dimension <code>dim</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_squeeze(dim)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nn_squeeze_+3A_dim">dim</code></td>
<td>
<p>(<code>integer()</code>)<br />
The dimension to squeeze.</p>
</td></tr>
</table>

<hr>
<h2 id='nn_unsqueeze'>Unsqueeze</h2><span id='topic+nn_unsqueeze'></span>

<h3>Description</h3>

<p>Unsqueezes a tensor by calling <code><a href="torch.html#topic+torch_unsqueeze">torch::torch_unsqueeze()</a></code> with the given dimension <code>dim</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nn_unsqueeze(dim)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nn_unsqueeze_+3A_dim">dim</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The dimension to unsqueeze.</p>
</td></tr>
</table>

<hr>
<h2 id='pipeop_preproc_torch'>Create Torch Preprocessing PipeOps</h2><span id='topic+pipeop_preproc_torch'></span>

<h3>Description</h3>

<p>Function to create objects of class <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code> in a more convenient way.
Start by reading the documentation of <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pipeop_preproc_torch(
  id,
  fn,
  shapes_out = NULL,
  param_set = NULL,
  packages = character(0),
  rowwise = FALSE,
  parent_env = parent.frame(),
  stages_init = NULL,
  tags = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pipeop_preproc_torch_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</td></tr>
<tr><td><code id="pipeop_preproc_torch_+3A_fn">fn</code></td>
<td>
<p>(<code>function</code>)<br />
The preprocessing function.</p>
</td></tr>
<tr><td><code id="pipeop_preproc_torch_+3A_shapes_out">shapes_out</code></td>
<td>
<p>(<code>function</code> or <code>NULL</code> or <code>"infer"</code>)<br />
The private <code>.shapes_out(shapes_in, param_vals, task)</code> method of <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>
(see section Inheriting).
Special values are <code>NULL</code> and <code>infer</code>:
If <code>NULL</code>, the output shapes are unknown.
If &quot;infer&quot;, the output shape function is inferred and calculates the output shapes as follows:
For an input shape of (NA, ...) a meta-tensor of shape (1, ...) is created and the preprocessing function is
applied. Afterwards the batch dimension (1) is replaced with NA and the shape is returned.
If the first dimension is not <code>NA</code>, the output shape of applying the preprocessing function is returned.
Method <code>"infer"</code> should be correct in most cases, but might fail in some edge cases.</p>
</td></tr>
<tr><td><code id="pipeop_preproc_torch_+3A_param_set">param_set</code></td>
<td>
<p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code> or <code>NULL</code>)<br />
The parameter set.
If this is left as <code>NULL</code> (default) the parameter set is inferred in the following way:
All parameters but the first and <code>...</code> of <code>fn</code> are set as untyped parameters with tags 'train' and those that
have no default value are tagged as 'required' as well.
Default values are not annotated.</p>
</td></tr>
<tr><td><code id="pipeop_preproc_torch_+3A_packages">packages</code></td>
<td>
<p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</td></tr>
<tr><td><code id="pipeop_preproc_torch_+3A_rowwise">rowwise</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether the preprocessing is applied row-wise.</p>
</td></tr>
<tr><td><code id="pipeop_preproc_torch_+3A_parent_env">parent_env</code></td>
<td>
<p>(<code>environment</code>)<br />
The parent environment for the R6 class.</p>
</td></tr>
<tr><td><code id="pipeop_preproc_torch_+3A_stages_init">stages_init</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Initial value for the <code>stages</code> parameter.
If <code>NULL</code> (default), will be set to <code>"both"</code> in case the <code>id</code> starts with <code>"trafo"</code> and to <code>"train"</code>
if it starts with <code>"augment"</code>. Otherwise it must specified.</p>
</td></tr>
<tr><td><code id="pipeop_preproc_torch_+3A_tags">tags</code></td>
<td>
<p>(<code>character()</code>)<br />
Tags for the pipeop</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <code><a href="R6.html#topic+R6Class">R6Class</a></code> instance inheriting from <code><a href="#topic+PipeOpTaskPreprocTorch">PipeOpTaskPreprocTorch</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
PipeOpPreprocExample = pipeop_preproc_torch("preproc_example", function(x, a) x + a)
po_example = PipeOpPreprocExample$new()
po_example$param_set

</code></pre>

<hr>
<h2 id='replace_head'>Replace the head of a network
Replaces the head of the network with a linear layer with d_out classes.</h2><span id='topic+replace_head'></span>

<h3>Description</h3>

<p>Replace the head of a network
Replaces the head of the network with a linear layer with d_out classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_head(network, d_out)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_head_+3A_network">network</code></td>
<td>
<p>(<code><a href="torch.html#topic+nn_module">torch::nn_module</a></code>)<br />
The network</p>
</td></tr>
<tr><td><code id="replace_head_+3A_d_out">d_out</code></td>
<td>
<p>(<code>integer(1)</code>)<br />
The number of output classes.</p>
</td></tr>
</table>

<hr>
<h2 id='t_clbk'>Sugar Function for Torch Callback</h2><span id='topic+t_clbk'></span><span id='topic+t_clbks'></span>

<h3>Description</h3>

<p>Retrieves one or more <code><a href="#topic+TorchCallback">TorchCallback</a></code>s from <code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>.
Works like <code><a href="mlr3.html#topic+mlr_sugar">mlr3::lrn()</a></code> and <code><a href="mlr3.html#topic+mlr_sugar">mlr3::lrns()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_clbk(.key, ...)

t_clbks(.keys)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="t_clbk_+3A_.key">.key</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The key of the torch callback.</p>
</td></tr>
<tr><td><code id="t_clbk_+3A_...">...</code></td>
<td>
<p>(any)<br />
See description of <code><a href="mlr3misc.html#topic+dictionary_sugar_get">dictionary_sugar_get()</a></code>.</p>
</td></tr>
<tr><td><code id="t_clbk_+3A_.keys">.keys</code></td>
<td>
<p>(<code>character()</code>)<br />
The keys of the callbacks.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+TorchCallback">TorchCallback</a></code>
</p>
<p><code>list()</code> of <code><a href="#topic+TorchCallback">TorchCallback</a></code>s
</p>


<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>
<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
t_clbk("progress")

</code></pre>

<hr>
<h2 id='t_loss'>Loss Function Quick Access</h2><span id='topic+t_loss'></span><span id='topic+t_losses'></span>

<h3>Description</h3>

<p>Retrieve one or more <code><a href="#topic+TorchLoss">TorchLoss</a></code>es from <code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>.
Works like <code><a href="mlr3.html#topic+mlr_sugar">mlr3::lrn()</a></code> and <code><a href="mlr3.html#topic+mlr_sugar">mlr3::lrns()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_loss(.key, ...)

t_losses(.keys, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="t_loss_+3A_.key">.key</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Key of the object to retrieve.</p>
</td></tr>
<tr><td><code id="t_loss_+3A_...">...</code></td>
<td>
<p>(any)<br />
See description of <code><a href="mlr3misc.html#topic+dictionary_sugar_get">dictionary_sugar_get</a></code>.</p>
</td></tr>
<tr><td><code id="t_loss_+3A_.keys">.keys</code></td>
<td>
<p>(<code>character()</code>)<br />
The keys of the losses.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="#topic+TorchLoss">TorchLoss</a></code>
</p>


<h3>See Also</h3>

<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
t_loss("mse", reduction = "mean")
# get the dictionary
t_loss()


t_losses(c("mse", "l1"))
# get the dictionary
t_losses()

</code></pre>

<hr>
<h2 id='t_opt'>Optimizers Quick Access</h2><span id='topic+t_opt'></span><span id='topic+t_opts'></span>

<h3>Description</h3>

<p>Retrieves one or more <code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>s from <code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>.
Works like <code><a href="mlr3.html#topic+mlr_sugar">mlr3::lrn()</a></code> and <code><a href="mlr3.html#topic+mlr_sugar">mlr3::lrns()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>t_opt(.key, ...)

t_opts(.keys, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="t_opt_+3A_.key">.key</code></td>
<td>
<p>(<code>character(1)</code>)<br />
Key of the object to retrieve.</p>
</td></tr>
<tr><td><code id="t_opt_+3A_...">...</code></td>
<td>
<p>(any)<br />
See description of <code><a href="mlr3misc.html#topic+dictionary_sugar_get">dictionary_sugar_get</a></code>.</p>
</td></tr>
<tr><td><code id="t_opt_+3A_.keys">.keys</code></td>
<td>
<p>(<code>character()</code>)<br />
The keys of the optimizers.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>
</p>


<h3>See Also</h3>

<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>
</p>
<p>Other Dictionary: 
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
t_opt("adam", lr = 0.1)
# get the dictionary
t_opt()


t_opts(c("adam", "sgd"))
# get the dictionary
t_opts()

</code></pre>

<hr>
<h2 id='task_dataset'>Create a Dataset from a Task</h2><span id='topic+task_dataset'></span>

<h3>Description</h3>

<p>Creates a torch <a href="torch.html#topic+dataset">dataset</a> from an mlr3 <code><a href="mlr3.html#topic+Task">Task</a></code>.
The resulting dataset's <code style="white-space: pre;">&#8288;$.get_batch()&#8288;</code> method returns a list with elements <code>x</code>, <code>y</code> and <code>index</code>:
</p>

<ul>
<li> <p><code>x</code> is a list with tensors, whose content is defined by the parameter <code>feature_ingress_tokens</code>.
</p>
</li>
<li> <p><code>y</code> is the target variable and its content is defined by the parameter <code>target_batchgetter</code>.
</p>
</li>
<li> <p><code>.index</code> is the index of the batch in the task's data.
</p>
</li></ul>

<p>The data is returned on the device specified by the parameter <code>device</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>task_dataset(task, feature_ingress_tokens, target_batchgetter = NULL, device)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="task_dataset_+3A_task">task</code></td>
<td>
<p>(<code><a href="mlr3.html#topic+Task">Task</a></code>)<br />
The task for which to build the <a href="torch.html#topic+dataset">dataset</a>.</p>
</td></tr>
<tr><td><code id="task_dataset_+3A_feature_ingress_tokens">feature_ingress_tokens</code></td>
<td>
<p>(named <code>list()</code> of <code><a href="#topic+TorchIngressToken">TorchIngressToken</a></code>)<br />
Each ingress token defines one item in the <code style="white-space: pre;">&#8288;$x&#8288;</code> value of a batch with corresponding names.</p>
</td></tr>
<tr><td><code id="task_dataset_+3A_target_batchgetter">target_batchgetter</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(data, device)&#8288;</code>)<br />
A function taking in arguments <code>data</code>, which is a <code>data.table</code> containing only the target variable, and <code>device</code>.
It must return the target as a torch <a href="torch.html#topic+torch_tensor">tensor</a> on the selected device.</p>
</td></tr>
<tr><td><code id="task_dataset_+3A_device">device</code></td>
<td>
<p>(<code>character()</code>)<br />
The device, e.g. <code>"cuda"</code> or <code>"cpu"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="torch.html#topic+dataset">torch::dataset</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
task = tsk("iris")
sepal_ingress = TorchIngressToken(
  features = c("Sepal.Length", "Sepal.Width"),
  batchgetter = batchgetter_num,
  shape = c(NA, 2)
)
petal_ingress = TorchIngressToken(
  features = c("Petal.Length", "Petal.Width"),
  batchgetter = batchgetter_num,
  shape = c(NA, 2)
)
ingress_tokens = list(sepal = sepal_ingress, petal = petal_ingress)

target_batchgetter = function(data, device) {
  torch_tensor(data = data[[1L]], dtype = torch_float32(), device)$unsqueeze(2)
}
dataset = task_dataset(task, ingress_tokens, target_batchgetter, "cpu")
batch = dataset$.getbatch(1:10)
batch

</code></pre>

<hr>
<h2 id='torch_callback'>Create a Callback Desctiptor</h2><span id='topic+torch_callback'></span>

<h3>Description</h3>

<p>Convenience function to create a custom <code><a href="#topic+TorchCallback">TorchCallback</a></code>.
All arguments that are available in <code><a href="#topic+callback_set">callback_set()</a></code> are also available here.
For more information on how to correctly implement a new callback, see <code><a href="#topic+CallbackSet">CallbackSet</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>torch_callback(
  id,
  classname = paste0("CallbackSet", capitalize(id)),
  param_set = NULL,
  packages = NULL,
  label = capitalize(id),
  man = NULL,
  on_begin = NULL,
  on_end = NULL,
  on_exit = NULL,
  on_epoch_begin = NULL,
  on_before_valid = NULL,
  on_epoch_end = NULL,
  on_batch_begin = NULL,
  on_batch_end = NULL,
  on_after_backward = NULL,
  on_batch_valid_begin = NULL,
  on_batch_valid_end = NULL,
  on_valid_end = NULL,
  state_dict = NULL,
  load_state_dict = NULL,
  initialize = NULL,
  public = NULL,
  private = NULL,
  active = NULL,
  parent_env = parent.frame(),
  inherit = CallbackSet,
  lock_objects = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="torch_callback_+3A_id">id</code></td>
<td>
<p>(<code>character(1)</code>)<br />'<br />
The id for the torch callback.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_classname">classname</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The class name.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_param_set">param_set</code></td>
<td>
<p>(<code>ParamSet</code>)<br />
The parameter set, if not present it is inferred from the <code style="white-space: pre;">&#8288;$initialize()&#8288;</code> method.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_packages">packages</code></td>
<td>
<p>(<code>character()</code>)<br /><code style="white-space: pre;">&#8288;The packages the callback depends on. Default is&#8288;</code>NULL'.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_label">label</code></td>
<td>
<p>(<code>character(1)</code>)<br />
The label for the torch callback.
Defaults to the capitalized <code>id</code>.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_man">man</code></td>
<td>
<p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.
The default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_on_begin">on_begin</code>, <code id="torch_callback_+3A_on_end">on_end</code>, <code id="torch_callback_+3A_on_epoch_begin">on_epoch_begin</code>, <code id="torch_callback_+3A_on_before_valid">on_before_valid</code>, <code id="torch_callback_+3A_on_epoch_end">on_epoch_end</code>, <code id="torch_callback_+3A_on_batch_begin">on_batch_begin</code>, <code id="torch_callback_+3A_on_batch_end">on_batch_end</code>, <code id="torch_callback_+3A_on_after_backward">on_after_backward</code>, <code id="torch_callback_+3A_on_batch_valid_begin">on_batch_valid_begin</code>, <code id="torch_callback_+3A_on_batch_valid_end">on_batch_valid_end</code>, <code id="torch_callback_+3A_on_valid_end">on_valid_end</code>, <code id="torch_callback_+3A_on_exit">on_exit</code></td>
<td>
<p>(<code>function</code>)<br />
Function to execute at the given stage, see section <em>Stages</em>.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_state_dict">state_dict</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function()&#8288;</code>)<br />
The function that retrieves the state dict from the callback.
This is what will be available in the learner after training.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_load_state_dict">load_state_dict</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function(state_dict)&#8288;</code>)<br />
Function that loads a callback state.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_initialize">initialize</code></td>
<td>
<p>(<code style="white-space: pre;">&#8288;function()&#8288;</code>)<br />
The initialization method of the callback.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_public">public</code>, <code id="torch_callback_+3A_private">private</code>, <code id="torch_callback_+3A_active">active</code></td>
<td>
<p>(<code>list()</code>)<br />
Additional public, private, and active fields to add to the callback.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_parent_env">parent_env</code></td>
<td>
<p>(<code>environment()</code>)<br />
The parent environment for the <code><a href="R6.html#topic+R6Class">R6Class</a></code>.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_inherit">inherit</code></td>
<td>
<p>(<code>R6ClassGenerator</code>)<br />
From which class to inherit.
This class must either be <code><a href="#topic+CallbackSet">CallbackSet</a></code> (default) or inherit from it.</p>
</td></tr>
<tr><td><code id="torch_callback_+3A_lock_objects">lock_objects</code></td>
<td>
<p>(<code>logical(1)</code>)<br />
Whether to lock the objects of the resulting <code><a href="R6.html#topic+R6Class">R6Class</a></code>.
If <code>FALSE</code> (default), values can be freely assigned to <code>self</code> without declaring them in the
class definition.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+TorchCallback">TorchCallback</a></code>
</p>


<h3>Internals</h3>

<p>It first creates an <code>R6</code> class inheriting from <code><a href="#topic+CallbackSet">CallbackSet</a></code> (using <code><a href="#topic+callback_set">callback_set()</a></code>) and
then wraps this generator in a <code><a href="#topic+TorchCallback">TorchCallback</a></code> that can be passed to a torch learner.
</p>


<h3>Stages</h3>


<ul>
<li> <p><code>begin</code> :: Run before the training loop begins.
</p>
</li>
<li> <p><code>epoch_begin</code> :: Run he beginning of each epoch.
</p>
</li>
<li> <p><code>batch_begin</code> :: Run before the forward call.
</p>
</li>
<li> <p><code>after_backward</code> :: Run after the backward call.
</p>
</li>
<li> <p><code>batch_end</code> :: Run after the optimizer step.
</p>
</li>
<li> <p><code>batch_valid_begin</code> :: Run before the forward call in the validation loop.
</p>
</li>
<li> <p><code>batch_valid_end</code> :: Run after the forward call in the validation loop.
</p>
</li>
<li> <p><code>valid_end</code> :: Run at the end of validation.
</p>
</li>
<li> <p><code>epoch_end</code> :: Run at the end of each epoch.
</p>
</li>
<li> <p><code>end</code> :: Run after last epoch.
</p>
</li>
<li> <p><code>exit</code> :: Run at last, using <code>on.exit()</code>.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
custom_tcb = torch_callback("custom",
  initialize = function(name) {
    self$name = name
  },
  on_begin = function() {
    cat("Hello", self$name, ", we will train for ", self$ctx$total_epochs, "epochs.\n")
  },
  on_end = function() {
    cat("Training is done.")
  }
)

learner = lrn("classif.torch_featureless",
  batch_size = 16,
  epochs = 1,
  callbacks = custom_tcb,
  cb.custom.name = "Marie",
  device = "cpu"
)
task = tsk("iris")
learner$train(task)

</code></pre>

<hr>
<h2 id='TorchCallback'>Torch Callback</h2><span id='topic+TorchCallback'></span>

<h3>Description</h3>

<p>This wraps a <code><a href="#topic+CallbackSet">CallbackSet</a></code> and annotates it with metadata, most importantly a <code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>.
The callback is created for the given parameter values by calling the <code style="white-space: pre;">&#8288;$generate()&#8288;</code> method.
</p>
<p>This class is usually used to configure the callback of a torch learner, e.g. when constructing
a learner of in a <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
</p>
<p>For a list of available callbacks, see <code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>.
To conveniently retrieve a <code><a href="#topic+TorchCallback">TorchCallback</a></code>, use <code><a href="#topic+t_clbk">t_clbk()</a></code>.
</p>


<h3>Parameters</h3>

<p>Defined by the constructor argument <code>param_set</code>.
If no parameter set is provided during construction, the parameter set is constructed by creating a parameter
for each argument of the wrapped loss function, where the parametes are then of type <code>ParamUty</code>.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+TorchDescriptor">mlr3torch::TorchDescriptor</a></code> -&gt; <code>TorchCallback</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TorchCallback-new"><code>TorchCallback$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TorchCallback-clone"><code>TorchCallback$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="TorchDescriptor" data-id="generate"><a href='../../mlr3torch/html/TorchDescriptor.html#method-TorchDescriptor-generate'><code>mlr3torch::TorchDescriptor$generate()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="TorchDescriptor" data-id="help"><a href='../../mlr3torch/html/TorchDescriptor.html#method-TorchDescriptor-help'><code>mlr3torch::TorchDescriptor$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="TorchDescriptor" data-id="print"><a href='../../mlr3torch/html/TorchDescriptor.html#method-TorchDescriptor-print'><code>mlr3torch::TorchDescriptor$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-TorchCallback-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchCallback$new(
  callback_generator,
  param_set = NULL,
  id = NULL,
  label = NULL,
  packages = NULL,
  man = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>callback_generator</code></dt><dd><p>(<code>R6ClassGenerator</code>)<br />
The class generator for the callback that is being wrapped.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code>ParamSet</code> or <code>NULL</code>)<br />
The parameter set. If <code>NULL</code> (default) it is inferred from <code>callback_generator</code>.</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for the new instance.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TorchCallback-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchCallback$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Callback: 
<code><a href="#topic+as_torch_callback">as_torch_callback</a>()</code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+callback_set">callback_set</a>()</code>,
<code><a href="#topic+mlr3torch_callbacks">mlr3torch_callbacks</a></code>,
<code><a href="#topic+mlr_callback_set">mlr_callback_set</a></code>,
<code><a href="#topic+mlr_callback_set.checkpoint">mlr_callback_set.checkpoint</a></code>,
<code><a href="#topic+mlr_callback_set.progress">mlr_callback_set.progress</a></code>,
<code><a href="#topic+mlr_context_torch">mlr_context_torch</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+torch_callback">torch_callback</a>()</code>
</p>
<p>Other Torch Descriptor: 
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create a new torch callback from an existing callback set
torch_callback = TorchCallback$new(CallbackSetCheckpoint)
# The parameters are inferred
torch_callback$param_set

# Retrieve a torch callback from the dictionary
torch_callback = t_clbk("checkpoint",
  path = tempfile(), freq = 1
)
torch_callback
torch_callback$label
torch_callback$id

# open the help page of the wrapped callback set
# torch_callback$help()

# Create the callback set
callback = torch_callback$generate()
callback
# is the same as
CallbackSetCheckpoint$new(
  path = tempfile(), freq = 1
)

# Use in a learner
learner = lrn("regr.mlp", callbacks = t_clbk("checkpoint"))
# the parameters of the callback are added to the learner's parameter set
learner$param_set

</code></pre>

<hr>
<h2 id='TorchDescriptor'>Base Class for Torch Descriptors</h2><span id='topic+TorchDescriptor'></span>

<h3>Description</h3>

<p>Abstract Base Class from which <code><a href="#topic+TorchLoss">TorchLoss</a></code>, <code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>, and <code><a href="#topic+TorchCallback">TorchCallback</a></code> inherit.
This class wraps a generator (R6Class Generator or the torch version of such a generator) and annotates it
with metadata such as a <code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>, a label, an ID, packages, or a manual page.
</p>
<p>The parameters are the construction arguments of the wrapped generator and the parameter <code style="white-space: pre;">&#8288;$values&#8288;</code> are passed
to the generator when calling the public method <code style="white-space: pre;">&#8288;$generate()&#8288;</code>.
</p>


<h3>Parameters</h3>

<p>Defined by the constructor argument <code>param_set</code>.
All parameters are tagged with <code>"train"</code>, but this is done automatically during initialize.
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for this object.
Can be used in tables, plot and text output instead of the ID.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>)<br />
Set of hyperparameters.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character(1)</code>)<br />
Set of required packages.
These packages are loaded, but not attached.</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
Identifier of the object.
Used in tables, plot and text output.</p>
</dd>
<dt><code>generator</code></dt><dd><p>The wrapped generator that is described.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.</p>
</dd>
</dl>

</div>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>phash</code></dt><dd><p>(<code>character(1)</code>)<br />
Hash (unique identifier) for this partial object, excluding some components
which are varied systematically (e.g. the parameter values).</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TorchDescriptor-new"><code>TorchDescriptor$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TorchDescriptor-print"><code>TorchDescriptor$print()</code></a>
</p>
</li>
<li> <p><a href="#method-TorchDescriptor-generate"><code>TorchDescriptor$generate()</code></a>
</p>
</li>
<li> <p><a href="#method-TorchDescriptor-help"><code>TorchDescriptor$help()</code></a>
</p>
</li>
<li> <p><a href="#method-TorchDescriptor-clone"><code>TorchDescriptor$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-TorchDescriptor-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchDescriptor$new(
  generator,
  id = NULL,
  param_set = NULL,
  packages = NULL,
  label = NULL,
  man = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>generator</code></dt><dd><p>The wrapped generator that is described.</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>)<br />
The parameter set.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for the new instance.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TorchDescriptor-print"></a>



<h4>Method <code>print()</code></h4>

<p>Prints the object
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchDescriptor$print(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>any</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TorchDescriptor-generate"></a>



<h4>Method <code>generate()</code></h4>

<p>Calls the generator with the given parameter values.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchDescriptor$generate()</pre></div>


<hr>
<a id="method-TorchDescriptor-help"></a>



<h4>Method <code>help()</code></h4>

<p>Displays the help file of the wrapped object.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchDescriptor$help()</pre></div>


<hr>
<a id="method-TorchDescriptor-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchDescriptor$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>

<hr>
<h2 id='TorchIngressToken'>Torch Ingress Token</h2><span id='topic+TorchIngressToken'></span>

<h3>Description</h3>

<p>This function creates an S3 class of class <code>"TorchIngressToken"</code>, which is an internal data structure.
It contains the (meta-)information of how a batch is generated from a <code><a href="mlr3.html#topic+Task">Task</a></code> and fed into an entry point
of the neural network. It is stored as the <code>ingress</code> field in a <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TorchIngressToken(features, batchgetter, shape)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TorchIngressToken_+3A_features">features</code></td>
<td>
<p>(<code>character</code>)<br />
Features on which the batchgetter will operate.</p>
</td></tr>
<tr><td><code id="TorchIngressToken_+3A_batchgetter">batchgetter</code></td>
<td>
<p>(<code>function</code>)<br />
Function with two arguments: <code>data</code> and <code>device</code>. This function is given
the output of <code>Task$data(rows = batch_indices, cols = features)</code>
and it should produce a tensor of shape <code>shape_out</code>.</p>
</td></tr>
<tr><td><code id="TorchIngressToken_+3A_shape">shape</code></td>
<td>
<p>(<code>integer</code>)<br />
Shape that <code>batchgetter</code> will produce. Batch-dimension should be included as <code>NA</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TorchIngressToken</code> object.
</p>


<h3>See Also</h3>

<p>Other Graph Network: 
<code><a href="#topic+ModelDescriptor">ModelDescriptor</a>()</code>,
<code><a href="#topic+mlr_learners_torch_model">mlr_learners_torch_model</a></code>,
<code><a href="#topic+mlr_pipeops_module">mlr_pipeops_module</a></code>,
<code><a href="#topic+mlr_pipeops_torch">mlr_pipeops_torch</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress">mlr_pipeops_torch_ingress</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_categ">mlr_pipeops_torch_ingress_categ</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_ltnsr">mlr_pipeops_torch_ingress_ltnsr</a></code>,
<code><a href="#topic+mlr_pipeops_torch_ingress_num">mlr_pipeops_torch_ingress_num</a></code>,
<code><a href="#topic+model_descriptor_to_learner">model_descriptor_to_learner</a>()</code>,
<code><a href="#topic+model_descriptor_to_module">model_descriptor_to_module</a>()</code>,
<code><a href="#topic+model_descriptor_union">model_descriptor_union</a>()</code>,
<code><a href="#topic+nn_graph">nn_graph</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Define a task for which we want to define an ingress token
task = tsk("iris")

# We create an ingress token for two feature Sepal.Length and Petal.Length:
# We have to specify the features, the batchgetter and the shape
features = c("Sepal.Length", "Petal.Length")
# As a batchgetter we use batchgetter_num

batch_dt = task$data(rows = 1:10, cols =features)
batch_dt
batch_tensor = batchgetter_num(batch_dt, "cpu")
batch_tensor

# The shape is unknown in the first dimension (batch dimension)

ingress_token = TorchIngressToken(
  features = features,
  batchgetter = batchgetter_num,
  shape = c(NA, 2)
)
ingress_token

</code></pre>

<hr>
<h2 id='TorchLoss'>Torch Loss</h2><span id='topic+TorchLoss'></span>

<h3>Description</h3>

<p>This wraps a <code>torch::nn_loss</code> and annotates it with metadata, most importantly a <code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>.
The loss function is created for the given parameter values by calling the <code style="white-space: pre;">&#8288;$generate()&#8288;</code> method.
</p>
<p>This class is usually used to configure the loss function of a torch learner, e.g.
when construcing a learner or in a <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
</p>
<p>For a list of available losses, see <code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>.
Items from this dictionary can be retrieved using <code><a href="#topic+t_loss">t_loss()</a></code>.
</p>


<h3>Parameters</h3>

<p>Defined by the constructor argument <code>param_set</code>.
If no parameter set is provided during construction, the parameter set is constructed by creating a parameter
for each argument of the wrapped loss function, where the parametes are then of type <code>ParamUty</code>.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+TorchDescriptor">mlr3torch::TorchDescriptor</a></code> -&gt; <code>TorchLoss</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>task_types</code></dt><dd><p>(<code>character()</code>)<br />
The task types this loss supports.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TorchLoss-new"><code>TorchLoss$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TorchLoss-print"><code>TorchLoss$print()</code></a>
</p>
</li>
<li> <p><a href="#method-TorchLoss-clone"><code>TorchLoss$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="TorchDescriptor" data-id="generate"><a href='../../mlr3torch/html/TorchDescriptor.html#method-TorchDescriptor-generate'><code>mlr3torch::TorchDescriptor$generate()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="TorchDescriptor" data-id="help"><a href='../../mlr3torch/html/TorchDescriptor.html#method-TorchDescriptor-help'><code>mlr3torch::TorchDescriptor$help()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-TorchLoss-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchLoss$new(
  torch_loss,
  task_types = NULL,
  param_set = NULL,
  id = NULL,
  label = NULL,
  packages = NULL,
  man = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>torch_loss</code></dt><dd><p>(<code>nn_loss</code>)<br />
The loss module.</p>
</dd>
<dt><code>task_types</code></dt><dd><p>(<code>character()</code>)<br />
The task types supported by this loss.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code><a href="paradox.html#topic+ParamSet">ParamSet</a></code> or <code>NULL</code>)<br />
The parameter set. If <code>NULL</code> (default) it is inferred from <code>torch_loss</code>.</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for the new instance.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TorchLoss-print"></a>



<h4>Method <code>print()</code></h4>

<p>Prints the object
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchLoss$print(...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>...</code></dt><dd><p>any</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TorchLoss-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchLoss$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchOptimizer">TorchOptimizer</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create a new torch loss
torch_loss = TorchLoss$new(torch_loss = nn_mse_loss, task_types = "regr")
torch_loss
# the parameters are inferred
torch_loss$param_set

# Retrieve a loss from the dictionary:
torch_loss = t_loss("mse", reduction = "mean")
# is the same as
torch_loss
torch_loss$param_set
torch_loss$label
torch_loss$task_types
torch_loss$id

# Create the loss function
loss_fn = torch_loss$generate()
loss_fn
# Is the same as
nn_mse_loss(reduction = "mean")

# open the help page of the wrapped loss function
# torch_loss$help()

# Use in a learner
learner = lrn("regr.mlp", loss = t_loss("mse"))
# The parameters of the loss are added to the learner's parameter set
learner$param_set

</code></pre>

<hr>
<h2 id='TorchOptimizer'>Torch Optimizer</h2><span id='topic+TorchOptimizer'></span>

<h3>Description</h3>

<p>This wraps a <code>torch::torch_optimizer_generator</code>a and annotates it with metadata, most importantly a <code><a href="paradox.html#topic+ParamSet">ParamSet</a></code>.
The optimizer is created for the given parameter values by calling the <code style="white-space: pre;">&#8288;$generate()&#8288;</code> method.
</p>
<p>This class is usually used to configure the optimizer of a torch learner, e.g.
when construcing a learner or in a <code><a href="#topic+ModelDescriptor">ModelDescriptor</a></code>.
</p>
<p>For a list of available optimizers, see <code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>.
Items from this dictionary can be retrieved using <code><a href="#topic+t_opt">t_opt()</a></code>.
</p>


<h3>Parameters</h3>

<p>Defined by the constructor argument <code>param_set</code>.
If no parameter set is provided during construction, the parameter set is constructed by creating a parameter
for each argument of the wrapped loss function, where the parametes are then of type <code><a href="paradox.html#topic+Domain">ParamUty</a></code>.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+TorchDescriptor">mlr3torch::TorchDescriptor</a></code> -&gt; <code>TorchOptimizer</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-TorchOptimizer-new"><code>TorchOptimizer$new()</code></a>
</p>
</li>
<li> <p><a href="#method-TorchOptimizer-generate"><code>TorchOptimizer$generate()</code></a>
</p>
</li>
<li> <p><a href="#method-TorchOptimizer-clone"><code>TorchOptimizer$clone()</code></a>
</p>
</li></ul>



<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="TorchDescriptor" data-id="help"><a href='../../mlr3torch/html/TorchDescriptor.html#method-TorchDescriptor-help'><code>mlr3torch::TorchDescriptor$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3torch" data-topic="TorchDescriptor" data-id="print"><a href='../../mlr3torch/html/TorchDescriptor.html#method-TorchDescriptor-print'><code>mlr3torch::TorchDescriptor$print()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-TorchOptimizer-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchOptimizer$new(
  torch_optimizer,
  param_set = NULL,
  id = NULL,
  label = NULL,
  packages = NULL,
  man = NULL
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>torch_optimizer</code></dt><dd><p>(<code>torch_optimizer_generator</code>)<br />
The torch optimizer.</p>
</dd>
<dt><code>param_set</code></dt><dd><p>(<code>ParamSet</code> or <code>NULL</code>)<br />
The parameter set. If <code>NULL</code> (default) it is inferred from <code>torch_optimizer</code>.</p>
</dd>
<dt><code>id</code></dt><dd><p>(<code>character(1)</code>)<br />
The id for of the new object.</p>
</dd>
<dt><code>label</code></dt><dd><p>(<code>character(1)</code>)<br />
Label for the new instance.</p>
</dd>
<dt><code>packages</code></dt><dd><p>(<code>character()</code>)<br />
The R packages this object depends on.</p>
</dd>
<dt><code>man</code></dt><dd><p>(<code>character(1)</code>)<br />
String in the format <code style="white-space: pre;">&#8288;[pkg]::[topic]&#8288;</code> pointing to a manual page for this object.
The referenced help package can be opened via method <code style="white-space: pre;">&#8288;$help()&#8288;</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-TorchOptimizer-generate"></a>



<h4>Method <code>generate()</code></h4>

<p>Instantiates the optimizer.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchOptimizer$generate(params)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>params</code></dt><dd><p>(named <code>list()</code> of <code><a href="torch.html#topic+torch_tensor">torch_tensor</a></code>s)<br />
The parameters of the network.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>torch_optimizer</code>
</p>


<hr>
<a id="method-TorchOptimizer-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>TorchOptimizer$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other Torch Descriptor: 
<code><a href="#topic+TorchCallback">TorchCallback</a></code>,
<code><a href="#topic+TorchDescriptor">TorchDescriptor</a></code>,
<code><a href="#topic+TorchLoss">TorchLoss</a></code>,
<code><a href="#topic+as_torch_callbacks">as_torch_callbacks</a>()</code>,
<code><a href="#topic+as_torch_loss">as_torch_loss</a>()</code>,
<code><a href="#topic+as_torch_optimizer">as_torch_optimizer</a>()</code>,
<code><a href="#topic+mlr3torch_losses">mlr3torch_losses</a></code>,
<code><a href="#topic+mlr3torch_optimizers">mlr3torch_optimizers</a></code>,
<code><a href="#topic+t_clbk">t_clbk</a>()</code>,
<code><a href="#topic+t_loss">t_loss</a>()</code>,
<code><a href="#topic+t_opt">t_opt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create a new torch loss
torch_opt = TorchOptimizer$new(optim_adam, label = "adam")
torch_opt
# If the param set is not specified, parameters are inferred but are of class ParamUty
torch_opt$param_set

# open the help page of the wrapped optimizer
# torch_opt$help()

# Retrieve an optimizer from the dictionary
torch_opt = t_opt("sgd", lr = 0.1)
torch_opt
torch_opt$param_set
torch_opt$label
torch_opt$id

# Create the optimizer for a network
net = nn_linear(10, 1)
opt = torch_opt$generate(net$parameters)

# is the same as
optim_sgd(net$parameters, lr = 0.1)

# Use in a learner
learner = lrn("regr.mlp", optimizer = t_opt("sgd"))
# The parameters of the optimizer are added to the learner's parameter set
learner$param_set

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
