<!DOCTYPE html><html lang="en"><head><title>Help for package sensR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sensR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#AnotA'><p>Analysis of A-not-A tests</p></a></li>
<li><a href='#AUC'><p> AUC computation</p></a></li>
<li><a href='#betabin'><p>Beta-binomial and chance-corrected beta-binomial models for</p>
over-dispersed binomial data</a></li>
<li><a href='#clls-deprecated'>
<p>Cumulative Link Location-Scale Models</p></a></li>
<li><a href='#clm2twoAC'><p>Extract 2-AC coefficient table from a cumulative link model</p></a></li>
<li><a href='#confint.twoAC'>
<p>Confidence intervals and profile likelihoods for parameters in</p>
2AC models</a></li>
<li><a href='#discrim'><p>Sensory discrimination analysis</p></a></li>
<li><a href='#discrimPwr'><p>Sensory discrimination power analysis</p></a></li>
<li><a href='#discrimR'><p>Replicated Thurstonian Model for discrimination analysis</p></a></li>
<li><a href='#discrimSim'><p>Simulates replicated difference tests</p></a></li>
<li><a href='#discrimSS'><p>Sensory discrimination sample size calculation</p></a></li>
<li><a href='#dod'><p>Thurstonian Degree-of-Difference (DOD) model</p></a></li>
<li><a href='#dod_fit'><p>Direct fitter of the Thurstonian Degree-of-Difference (DOD) model</p></a></li>
<li><a href='#dod_utils'><p>Utility functions for the Degree-of-Difference model</p></a></li>
<li><a href='#dodControl'><p>Control settings for the dod function</p></a></li>
<li><a href='#dodPwr'><p>Power of the Degree-of-Difference (DOD) method</p></a></li>
<li><a href='#dodSim'><p>Simulate data from the Degree-of-Difference model</p></a></li>
<li><a href='#dprime_compare'>
<p>Test the 'any-differences' hypothesis and estimate common d-prime</p></a></li>
<li><a href='#dprime_table'>
<p>Summary table of several discrimination experiments using the</p>
simple-binomial protocols (Duo-Trio, Triangle, Tetrad, 2-AFC and 3-AFC)</a></li>
<li><a href='#dprime_test'>
<p>Test of simple hypothesis with the common d-prime</p></a></li>
<li><a href='#duotrio'><p>Create duotrio binomial family</p></a></li>
<li><a href='#findcr'><p>Find the critical value of a one-tailed binomial test</p></a></li>
<li><a href='#hexad'><p>Create hexad binomial family</p></a></li>
<li><a href='#plot.discrim'><p> Plot function for discrim objects</p></a></li>
<li><a href='#plot.samediff'><p> Plot function for samediff objects</p></a></li>
<li><a href='#posthoc'>
<p>Post-hoc estimates and tests for multiple discrimination experiments.</p></a></li>
<li><a href='#profile.discrim'><p>Profile likelihood and confidence interval methods for discrim</p>
objects</a></li>
<li><a href='#profile.samediff'><p>Profile likelihood methods for samediff objects.</p></a></li>
<li><a href='#rescale'><p>Transform or rescale between pc, pd and d-prime for sensory</p>
discrimination protocols</a></li>
<li><a href='#ROC'><p>Plot the Receiver Operating Characteristic Curve</p></a></li>
<li><a href='#samediff'><p>Computation of tau and dprime for same different test</p></a></li>
<li><a href='#samediffPwr'><p>Power Analysis for Same-different Experiments</p></a></li>
<li><a href='#samediffSim'><p>Simulates data from a samediff test</p></a></li>
<li><a href='#SDT'><p>Signal Detection Theory Computation of d-prime</p></a></li>
<li><a href='#sensR-deprecated'><p>Deprecated Functions in sensR Package</p></a></li>
<li><a href='#summary.samediff'><p>Summary method for samediff objects.</p></a></li>
<li><a href='#tetrad'><p>Create tetrad binomial family</p></a></li>
<li><a href='#threeAFC'><p>Create 3-AFC binomial family</p></a></li>
<li><a href='#triangle'><p>Create triangle binomial family</p></a></li>
<li><a href='#twoAC'><p>2-AC Discrimination and Preference Protocol</p></a></li>
<li><a href='#twoACpwr'><p>Exact Power Computation for the 2-AC Discrimination Protocol</p></a></li>
<li><a href='#twoAFC'><p>Create 2-AFC binomial family</p></a></li>
<li><a href='#twofive'><p>Create twofive binomial family</p></a></li>
<li><a href='#twofiveF'><p>Create twofiveF binomial family</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Thurstonian Models for Sensory Discrimination</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-20</td>
</tr>
<tr>
<td>Imports:</td>
<td>multcomp, MASS, numDeriv</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ordinal, parallel, testthat (&ge; 0.8)</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides methods for sensory discrimination methods;
  duotrio, tetrad, triangle, 2-AFC, 3-AFC, A-not A, same-different,
  2-AC and degree-of-difference.
  This enables the calculation of d-primes, standard errors of
  d-primes, sample size and power computations, and
  comparisons of different d-primes. Methods for profile likelihood
  confidence intervals and plotting are included. Most methods are 
  described in Brockhoff, P.B. and Christensen, R.H.B. (2010) 
  &lt;<a href="https://doi.org/10.1016%2Fj.foodqual.2009.04.003">doi:10.1016/j.foodqual.2009.04.003</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/aigorahub/sensR">https://github.com/aigorahub/sensR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/aigorahub/sensR/issues">https://github.com/aigorahub/sensR/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-30 11:56:45 UTC; Dominik Rafacz</td>
</tr>
<tr>
<td>Author:</td>
<td>Rune Haubo Bojesen Christensen [aut],
  Per Bruun Brockhoff [aut],
  Alexandra Kuznetsova [ctb],
  Sophie Birot [ctb],
  Karolina Amelia Stachlewska [ctb],
  Dominik Rafacz [cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Dominik Rafacz &lt;dominik.rafacz@aigora.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-31 15:50:10 UTC</td>
</tr>
</table>
<hr>
<h2 id='AnotA'>Analysis of A-not-A tests</h2><span id='topic+AnotA'></span><span id='topic+confint.anota'></span><span id='topic+plot.anota'></span>

<h3>Description</h3>

<p>Computation of dprime and it's uncertainty for the monadic A-not-A test
together with the one-tailed P-value of the difference test
(Fisher's Exact test).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>AnotA(x1, n1, x2, n2, ...)

## S3 method for class 'anota'
confint(object, parm, level = 0.95, ...)

## S3 method for class 'anota'
plot(x, main = TRUE, length = 1000, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AnotA_+3A_x1">x1</code></td>
<td>
<p>the number of (correct) A-answers on A-samples</p>
</td></tr>
<tr><td><code id="AnotA_+3A_n1">n1</code></td>
<td>
<p>the total number of A-samples</p>
</td></tr>
<tr><td><code id="AnotA_+3A_x2">x2</code></td>
<td>
<p>the number of A-answers on not-A-samples</p>
</td></tr>
<tr><td><code id="AnotA_+3A_n2">n2</code></td>
<td>
<p>the number of not-A-samples</p>
</td></tr>
<tr><td><code id="AnotA_+3A_object">object</code></td>
<td>
<p>an <code>anota</code> object</p>
</td></tr>
<tr><td><code id="AnotA_+3A_parm">parm</code></td>
<td>
<p>currently not used</p>
</td></tr>
<tr><td><code id="AnotA_+3A_level">level</code></td>
<td>
<p>the desired confidence level</p>
</td></tr>
<tr><td><code id="AnotA_+3A_x">x</code></td>
<td>
<p>an <code>anota</code> object</p>
</td></tr>
<tr><td><code id="AnotA_+3A_main">main</code></td>
<td>
<p>should the plot have a main title?</p>
</td></tr>
<tr><td><code id="AnotA_+3A_length">length</code></td>
<td>
<p>the discretization of the curves</p>
</td></tr>
<tr><td><code id="AnotA_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>glm</code> for <code>AnotA</code>;
not used for <code>confint</code> and <code>plot</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>AnotA</code> function uses the <code>glm</code> and <code>fisher.test</code>
functions of the <code>stats</code> package. Note that all arguments have
to be positive integers.
</p>


<h3>Value</h3>

<p>For <code>AnotA</code> an object of class <code>anota</code> (which has a print
method). This is a list with elements
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p> named vector of coefficients (d-prime)</p>
</td></tr>
<tr><td><code>res.glm</code></td>
<td>
<p>the glm-object from the fitting process</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>variance-covariance matrix of the coefficients</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>named vector with standard error of the coefficients
(standard error of d-prime</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>a named vector with the data supplied to the function</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>one-sided p-value from Fisher's exact test
(<code>fisher.test</code>)</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>a string with the name of the test (<code>A-Not A</code>) for
the print method</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
</table>
<p>For <code>plot</code> a figure of the distributions of sensory intensity is
produced, and for <code>confint</code> a 2-by-2 matrix of confidence
intervals is returned.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen and Per Bruun Brockhoff</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen, R.H.B. (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.discrim">print.discrim</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+discrimSS">discrimSS</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'># data: 10 of the A-samples were judged to be A
#       20 A-samples in total
#       3 of the not-A samples were judged to be A
#       20 not-A-samples in total

AnotA(10, 20, 3, 20)
(m1 &lt;- AnotA(10, 20, 3, 20))

## plot distributions of sensory intensity:
plot(m1)

## likelihood based confidence intervals:
confint(m1)


## Extended example plotting the profile likelihood
xt &lt;- cbind(c(3, 10), c(20 - 3, 20 - 10))
lev &lt;- gl(2, 1)
summary(res &lt;- glm(xt ~ lev,
                   family = binomial(link = probit)))
N &lt;- 100
dev &lt;- double(N)
level &lt;- c(0.95, 0.99)
delta &lt;- seq(1e-4, 5, length = N)
for(i in 1:N)
  dev[i] &lt;- glm(xt ~ 1 + offset(c(0, delta[i])),
                family = binomial(probit))$deviance
plot(delta, exp(-dev/2), type = "l",
     xlab = expression(delta),
     ylab = "Normalized Profile Likelihood")
## Add Normal approximation:
lines(delta, exp(-(delta - coef(res)[2])^2 /
                 (2 * vcov(res)[2,2])), lty = 2)
## Add confidence limits:
lim &lt;- sapply(level, function(x)
              exp(-qchisq(x, df=1)/2) )
abline(h = lim, col = "grey")

</code></pre>

<hr>
<h2 id='AUC'> AUC computation</h2><span id='topic+AUC.default'></span><span id='topic+AUC.anota'></span><span id='topic+print.AUC'></span><span id='topic+AUC'></span>

<h3>Description</h3>

<p>This is the default AUC function for scalar d-primes, which will
compute Area Under the ROC curve (ROC is an acronym for receiver
operating characteristic) assuming a  normal distribution
for the underlying percepts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## Default S3 method:
AUC(d, se.d, scale = 1, CI.alpha = 0.05, ...)

## S3 method for class 'anota'
AUC(d, CI.alpha = 0.05, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="AUC_+3A_d">d</code></td>
<td>
<p>a unit lenght vector with the value of d-prime for which AUC
is to be computed or a <code>anota</code> object from the fitting of a
A-not A test with <code><a href="#topic+AnotA">AnotA</a></code></p>
</td></tr>
<tr><td><code id="AUC_+3A_scale">scale</code></td>
<td>
<p>a unit length vector giving the ratio of scale (ie. standard
deviation) of the latent distribution for the no-class items
relative to that of the yes-class items</p>
</td></tr>
<tr><td><code id="AUC_+3A_se.d">se.d</code></td>
<td>
<p>standard error of <code>d</code> (d-prime). If provided, the
function will compute confidence limits of value of AUC&mdash;cf. in
section value.</p>
</td></tr>
<tr><td><code id="AUC_+3A_ci.alpha">CI.alpha</code></td>
<td>
<p>the type I level of the confidence interval of AUC</p>
</td></tr>
<tr><td><code id="AUC_+3A_...">...</code></td>
<td>
<p>additional arguments passed <code>integrate</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The AUC is computed using the standard normal distribution function
<code><a href="stats.html#topic+pnorm">pnorm</a></code>.
</p>
<p>Confidence limits are based on a normal approximation of
<code>d</code> and not of AUC. The limits are computed,
if an estimate of the standard error of <code>d</code> is provided. Note
that the limits do not take the uncertainty in estimating the scale
nor that of estimating the standard error of <code>d</code> into account.
</p>
<p>A print method is implemented for objects of class <code>AUC</code>.
</p>


<h3>Value</h3>

<p>A list with components. If <code>se.d</code> is supplied to the default
method or if a discrim object is supplied, the object contains the
latter three additional elements.
</p>
<table role = "presentation">
<tr><td><code>value</code></td>
<td>
<p>the estimated value of AUC</p>
</td></tr>
<tr><td><code>res.int</code></td>
<td>
<p>the result from the call to <code>integrate</code></p>
</td></tr>
<tr><td><code>lower</code></td>
<td>
<p>the lower confidence limit</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>the upper confidence limit</p>
</td></tr>
<tr><td><code>CI.alpha</code></td>
<td>
<p>echoes the provided <code>CI.alpha</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Compute AUC from d-prime and confindence interval for the AUC:
fm1 &lt;- AnotA(8, 25, 1, 25)
AUC(d=fm1$coef, se.d=fm1$se)
## The AUC-method for AnotA-objects can be used for convenience:
AUC(fm1)



</code></pre>

<hr>
<h2 id='betabin'>Beta-binomial and chance-corrected beta-binomial models for
over-dispersed binomial data</h2><span id='topic+betabin'></span><span id='topic+summary.betabin'></span>

<h3>Description</h3>

<p>Fits the beta-binomial model and the chance-corrected beta-binomial
model to (over-dispersed) binomial data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>betabin(data, start = c(.5,.5),
        method = c("duotrio", "tetrad", "threeAFC", "twoAFC",
          "triangle", "hexad", "twofive", "twofiveF"),
        vcov = TRUE, corrected = TRUE, gradTol = 1e-4, ...)

## S3 method for class 'betabin'
summary(object, level = 0.95, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="betabin_+3A_data">data</code></td>
<td>
<p>matrix or data.frame with two columns; first column
contains the number of success and the second the total number of
cases. The number of rows should correspond to the number of
observations.</p>
</td></tr>
<tr><td><code id="betabin_+3A_start">start</code></td>
<td>
<p>starting values to be used in the optimization</p>
</td></tr>
<tr><td><code id="betabin_+3A_vcov">vcov</code></td>
<td>
<p>logical, should the variance-covariance matrix of the
parameters be computed?</p>
</td></tr>
<tr><td><code id="betabin_+3A_method">method</code></td>
<td>
<p>the sensory discrimination protocol for which d-prime
and its standard error should be computed</p>
</td></tr>
<tr><td><code id="betabin_+3A_corrected">corrected</code></td>
<td>
<p>should the chance corrected or the standard beta
binomial model be estimated?</p>
</td></tr>
<tr><td><code id="betabin_+3A_gradtol">gradTol</code></td>
<td>
<p>a warning is issued if max|gradient| &lt; gradTol, where
'gradient' is the gradient at the values at which the optimizer
terminates. This is not used as a termination or convergence
criterion during model fitting.</p>
</td></tr>
<tr><td><code id="betabin_+3A_object">object</code></td>
<td>
<p>an object of class &quot;betabin&quot;, i.e. the result of
<code>betabin()</code>.</p>
</td></tr>
<tr><td><code id="betabin_+3A_level">level</code></td>
<td>
<p>the confidence level of the confidence intervals computed
by the summary method</p>
</td></tr>
<tr><td><code id="betabin_+3A_...">...</code></td>
<td>
<p><code>betabin</code>: The only recognized (hidden) argument is
<code>doFit</code> (boolean) which by default is <code>TRUE</code>. When
<code>FALSE</code> <code>betabin</code> returns an environment which facilitates
examination of the likelihood surface via the (hidden) functions
<code>sensR:::getParBB</code> and <code>sensR:::setParBB</code>.
Not used in <code>summary.betabin</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The beta-binomial models are parameterized in terms of mu and gamma,
where mu corresponds to a probability parameter and gamma measures
over-dispersion. Both parameters are restricted to the interval (0, 1).
The parameters of the standard (i.e. corrected = FALSE) beta-binomial
model refers to the mean (i.e. probability) and dispersion on the scale
of the observations, i.e. on the scale where we talk of a probability of
a correct answer (Pc). The parameters of the chance corrected (i.e. corrected
= TRUE) beta-binomial model refers to the mean and dispersion on the
scale of the &quot;probability of discrimination&quot; (Pd).
The mean parameter (mu) is therefore restricted to the
interval from zero to one in both models, but they have different
interpretations.
</p>
<p>The summary method use the estimate of mu to infer the parameters of the
sensory experiment; Pc, Pd and d-prime. These are restricted to their
allowed ranges, e.g. Pc is always at least as large as the guessing
probability.
</p>
<p>Confidens intervals are computed as Wald (normal-based) intervals on the
mu-scale and the confidence limits are subsequently transformed to the
Pc, Pd and d-prime scales. Confidence limits are restricted to the
allowed ranges of the parameters, for example no confidence limits will
be less than zero.
</p>
<p>Standard errors, and therefore also confidence intervals, are only
available if the parameters are not at the boundary of their allowed
range (parameter space). If parameters are close to the boundaries of
their allowed range, standard errors, and also confidence intervals, may
be misleading. The likelihood ratio tests are more accurate. More
accurate confidence intervals such as profile likelihood intervals may
be implemented in the future.
</p>
<p>The summary method provides a likelihood ratio test of over-dispersion
on one degree of freedom and a likelihood ratio test of association
(i.e. where the null hypothesis is &quot;no difference&quot; and the alternative
hypothesis is &quot;any difference&quot;) on two degrees of
freedom (chi-square tests). Since the gamma parameter is tested on the
boundary of the
parameter space, the correct degree of freedom for the first test is
probably 1/2 rather than one, or somewhere in between, and the latter
test is probably also on less than two degrees of freedom. Research is
needed to determine the appropriate no. degrees of freedom to use in
each case. The choices used here are believed to be conservative, so the
stated p-values are probably a little too large.
</p>
<p>The log-likelihood of the standard beta-binomial model is
</p>
<p style="text-align: center;"><code class="reqn">\ell(\alpha, \beta; x, n) =
  \sum_{j=1}^N \left\{
  \log {n_j \choose x_j}
  - \log Beta(\alpha, \beta)
  + \log  Beta(\alpha + x_j, \beta - x_j + n_j) \right\}
  </code>
</p>

<p>and the log-likelihood of the chance corrected beta-binomial model is
</p>
<p style="text-align: center;"><code class="reqn">\ell(\alpha, \beta; x, n) =
  \sum_{j=1}^N \left\{ C
  + \log \left[ \sum_{i=0}^{x_j} {{x_j} \choose i}
  (1-p_g)^{n_j-x_j+i} p_g^{x_j-i}
  Beta(\alpha + i, n_j - x_j + \beta) \right] \right\}
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">C =
  \log {n_j \choose x_j}
  - \log Beta(\alpha, \beta)
</code>
</p>

<p>and where <code class="reqn">\mu = \alpha/(\alpha + \beta)</code>,
<code class="reqn">\gamma = 1/(\alpha + \beta + 1)</code>, <code class="reqn">Beta</code> is the Beta
function, cf. <code><a href="base.html#topic+beta">beta</a></code>,
<code class="reqn">N</code> is the number of independent binomial observations, i.e.~the
number of rows in <code>data</code>, and <code class="reqn">p_g</code> is the guessing
probability, <code>pGuess</code>.
</p>
<p>The variance-covariance matrix (and standard errors) is based on the
inverted Hessian at the optimum. The Hessian is obtained with the
<code>hessian</code> function from the numDeriv package.
</p>
<p>The gradient at the optimum is evaluated with <code>gradient</code> from the
numDeriv package.
</p>
<p>The bounded optimization is performed with the &quot;L-BFGS-B&quot; optimizer in
<code><a href="stats.html#topic+optim">optim</a></code>.
</p>
<p>The following additional methods are implemented objects of class
<code>betabin</code>: <code>print</code>, <code>vcov</code> and <code>logLik</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>betabin</code> with elements
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>named vector of coefficients</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>variance-covariance matrix of the parameter estimates if
<code>vcov = TRUE</code></p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the data supplied to the function</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>the value of the log-likelihood at the MLEs</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the method used for the fit</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>0 indicates convergence. For other error messages,
see <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
<tr><td><code>message</code></td>
<td>
<p>possible error message - see <code><a href="stats.html#topic+optim">optim</a></code> for
details</p>
</td></tr>
<tr><td><code>counts</code></td>
<td>
<p>the number of iterations used in the optimization - see
<code><a href="stats.html#topic+optim">optim</a></code> for details</p>
</td></tr>
<tr><td><code>corrected</code></td>
<td>
<p>is the chance corrected model estimated?</p>
</td></tr>
<tr><td><code>logLikNull</code></td>
<td>
<p>log-likelihood of the binomial model with
prop = pGuess</p>
</td></tr>
<tr><td><code>logLikMu</code></td>
<td>
<p>log-likelihood of a binomial model with
prop = sum(x)/sum(n)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Brockhoff, P.B. (2003). The statistical power of
replications in difference tests.
Food Quality and Preference, 14, pp. 405&ndash;417.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+duotrio">duotrio</a></code>, <code><a href="#topic+tetrad">tetrad</a></code>
<code><a href="#topic+twofive">twofive</a></code>, <code><a href="#topic+twofiveF">twofiveF</a></code>, <code><a href="#topic+hexad">hexad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create data:
x &lt;- c(3,2,6,8,3,4,6,0,9,9,0,2,1,2,8,9,5,7)
n &lt;- c(10,9,8,9,8,6,9,10,10,10,9,9,10,10,10,10,9,10)
dat &lt;- data.frame(x, n)

## Chance corrected beta-binomial model:
(bb0 &lt;- betabin(dat, method = "duotrio"))
summary(bb0)
## Un-corrected beta-binomial model:
(bb &lt;- betabin(dat, corrected = FALSE, method = "duotrio"))
summary(bb)
vcov(bb)
logLik(bb)
AIC(bb)
coef(bb)

</code></pre>

<hr>
<h2 id='clls-deprecated'>
Cumulative Link Location-Scale Models
</h2><span id='topic+clls-deprecated'></span><span id='topic+clls'></span>

<h3>Description</h3>

<p>IMPORTANT: This function and its methods are no longer supported. The
user is adviced to use clm() from package ordinal instead.
</p>
<p>Fits a cumulative link location-scale model to an ordered response
variable. When the scale part is left unspecified, the model reduces
to a cumulative link model assuming a constant scale. With the default
logistic link function, the model reduces to the famous <em>Proportional
Odds Model</em>. With the probit link and a single two-level factor in both
location and scale parts, the model is known as the <em>Binormal</em>
model in the Signal Detection Theory and the Psychometric
literature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  clls(location, scale, data, weights, start, ..., subset,
           na.action, contrasts = NULL, Hess = FALSE, model = TRUE,
           method = c("logistic", "probit", "cloglog", "cauchit"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clls-deprecated_+3A_location">location</code></td>
<td>

<p>a formula expression as for regression models, of the form
<code>response ~ predictors</code>. The response should be a factor
(preferably an ordered factor), which will be interpreted as an
ordinal response, with levels ordered as in the factor.
The model must have an intercept: attempts to remove one will
lead to a warning and be ignored. An offset may be used.  See the
documentation of <code><a href="stats.html#topic+formula">formula</a></code> for other details.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_scale">scale</code></td>
<td>

<p>a optional formula expression as for the location part, of the form
<code> ~ predictors</code>, ie. with an empty left hand side.
If left unspecified, the model assumes a constant scale and reduces
to the cumulative link model.
An offset may be used.  See the
documentation of <code><a href="stats.html#topic+formula">formula</a></code> for other details.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_data">data</code></td>
<td>

<p>an optional data frame in which to interpret the variables occurring
in <code>formula</code>.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_weights">weights</code></td>
<td>

<p>optional case weights in fitting.  Default to 1.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_start">start</code></td>
<td>

<p>initial values for the parameters.  This is in the format
<code>c(beta, theta, sigma)</code>: see the Values section.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_...">...</code></td>
<td>

<p>additional arguments to be passed to <code><a href="stats.html#topic+optim">optim</a></code>, most often a
<code>control</code> argument.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_subset">subset</code></td>
<td>

<p>expression saying which subset of the rows of the data should  be used
in the fit.  All observations are included by default.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_na.action">na.action</code></td>
<td>

<p>a function to filter missing data.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_contrasts">contrasts</code></td>
<td>

<p>a list of contrasts to be used for some or all of
the factors appearing as variables in the model formula.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_hess">Hess</code></td>
<td>

<p>logical for whether the Hessian (the observed information matrix)
should be returned.  Use this if you intend to call <code>summary</code> or
<code>vcov</code> on the fit.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_model">model</code></td>
<td>

<p>logical for whether the model matrix should be returned.
</p>
</td></tr>
<tr><td><code id="clls-deprecated_+3A_method">method</code></td>
<td>

<p>logistic or probit or complementary log-log or cauchit (corresponding
to a Cauchy latent variable).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation is highly inspired by <code><a href="MASS.html#topic+polr">polr</a></code> in
package MASS and should give compatible results, if <code>scale</code> is
left unspecified.
</p>
<p>Note that standard errors are appropriate for <code>tau</code> =
log <code>sigma</code> and not for <code>sigma</code>, because the profile
likelihood is usually more symmetric for <code>tau</code> than for
<code>sigma</code>. Therefore <code>vcov</code> will give the
variance-covariance matrix of the parameters with <code>tau</code> rather
than <code>sigma</code> and <code>summary.clls</code> will report standard errors
for log <code>sigma</code>. Notice also that a relevant test for
<code>sigma</code> is <code class="reqn">H_0: sigma = 1</code>, so the relevant test for log
<code>sigma</code> is <code class="reqn">H_0: log(sigma) = 0</code>. This is reflected in the z
value for <code>sigma</code> returned by <code>summary.clls</code>.
</p>
<p>There are methods for the standard model-fitting functions, including
<code><a href="base.html#topic+summary">summary</a></code>, <code><a href="stats.html#topic+vcov">vcov</a></code>,
<code><a href="stats.html#topic+anova">anova</a></code>, and an
<code>extractAIC</code> method.
</p>


<h3>Value</h3>

<p>A object of class <code>"clls"</code>. This has components
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>the coefficients of the location
(<code>beta</code>), the intercepts (<code>theta</code>) and the scale
(<code>sigma</code>).</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the parameter estimates of the location part.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>the intercepts/thresholds for the class boundaries.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the parameter estimates of the scale part.</p>
</td></tr>
<tr><td><code>tau</code></td>
<td>
<p>parameter estimates of the scale part on the log scale;
ie. <code>tau</code> = log <code>sigma</code>.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>the residual deviance.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>a matrix, with a column for each level of the
response with the fitted probabilities.</p>
</td></tr>
<tr><td><code>fitted.case</code></td>
<td>
<p>a vector of same length as <code>response</code>, with
the fitted probabilities on a case-by-case basis.</p>
</td></tr>
<tr><td><code>lev</code></td>
<td>
<p>the names of the response levels.</p>
</td></tr>
<tr><td><code>terms.location</code></td>
<td>
<p>a <code>terms</code> structure describing the location
part.</p>
</td></tr>
<tr><td><code>terms.scale</code></td>
<td>
<p>a <code>terms</code> structure describing the scale
part.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the number of residual degrees of freedoms,
calculated using the weights.</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>the (effective) number of degrees of freedom used by the
model</p>
</td></tr>
<tr><td><code>n</code>, <code>nobs</code></td>
<td>
<p>the (effective) number of observations, calculated
using the weights.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the matched method used.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>the convergence code returned by <code>optim</code>.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>the number of function and gradient evaluations used by
<code>optim</code>.</p>
</td></tr>
<tr><td><code>Hessian</code></td>
<td>
<p>if <code>Hess</code> is true, the observed Fisher information
matrix.</p>
</td></tr>
<tr><td><code>location</code></td>
<td>
<p>if <code>model</code> is true, the <code>model.frame</code> for
the location part.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>if <code>model</code> is true, the <code>model.frame</code> for
the scale part.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Agresti, A. (2002) <em>Categorical Data.</em> Second edition.  Wiley.
</p>
<p>Christensen, R.H.B., Cleaver, G. and Brockhoff, P.B. (2011). 
Statistical and Thurstonian models for the A-not A protocol
with and without sureness. <em>Food Quality and Preference</em>, 
22(6), pp.542-549.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Fourth edition.  Springer.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+polr">polr</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>, <code><a href="stats.html#topic+glm">glm</a></code>,
<code><a href="nnet.html#topic+multinom">multinom</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  old &lt;- options(contrasts = c("contr.treatment", "contr.poly"))
  ## Extend example from polr in package MASS:
  ## Fit model from polr example:
  data(housing, package = "MASS")
  fm1 &lt;- clls(Sat ~ Infl + Type + Cont, weights = Freq, data = housing)
  fm1
  summary(fm1)
  ## With probit link:
  summary(update(fm1, method = "probit"))

  ## Allow scale to depend on Cont-variable
  summary(fm2 &lt;- update(fm1, scale =~ Cont))
  anova(fm1, fm2)
  ## which seems to improve the fit
  options(old)

</code></pre>

<hr>
<h2 id='clm2twoAC'>Extract 2-AC coefficient table from a cumulative link model</h2><span id='topic+clm2twoAC'></span>

<h3>Description</h3>

<p>The Thurstonian model for the 2-AC protocol can be formulated as a
cumulative link model (see the references). This function extracts the
2-AC model parameter
estimates, standard errors, z-value and p-values from a cumulative
link (mixed) model fitted with <code><a href="ordinal.html#topic+clm">clm</a></code> or
<code><a href="ordinal.html#topic+clmm">clmm</a></code> from package <code>ordinal</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
clm2twoAC(object, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clm2twoAC_+3A_object">object</code></td>
<td>
<p> a <code><a href="ordinal.html#topic+clm">clm</a></code> or
<code><a href="ordinal.html#topic+clmm">clmm</a></code> object
</p>
</td></tr>
<tr><td><code id="clm2twoAC_+3A_...">...</code></td>
<td>
<p>not currently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> with the coefficient table. The two first rows
contain the estimates of <code>tau</code> and <code>d.prime</code> while the
remaining rows contain optional regression variables for
<code>d.prime</code>.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Christensen R.H.B., Lee H-S and Brockhoff P.B. (2012). Estimation of
the Thurstonian model for the 2-AC protocol. Food Quality
and Preference, 24(1), pp.119-128.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+twoAC">twoAC</a></code>, <code><a href="#topic+twoACpwr">twoACpwr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Example of a simple 2-AC model. First the conventional way:
twoAC(c(2, 2, 6))

## The using a cumulative link model (clm from package ordinal):
if(require(ordinal)) {
    response &lt;- gl(3,1)
    fit.clm &lt;- clm(response ~ 1, weights = c(2, 2, 6), link = "probit")
    clm2twoAC(fit.clm)
    ## Alternatively we could get estimates and standard errors "by hand":
    tab &lt;- coef(summary(fit.clm))
    theta &lt;- tab[,1]
    (tau &lt;- (theta[2] - theta[1])/sqrt(2))
    (d.prime &lt;- (-theta[2] - theta[1])/sqrt(2))
    VCOV &lt;- vcov(fit.clm)
    (se.tau &lt;- sqrt((VCOV[1,1] + VCOV[2,2] - 2*VCOV[2,1])/2))
    (se.d.prime &lt;- sqrt((VCOV[1,1] + VCOV[2,2] + 2*VCOV[2,1])/2))

    ## Extended example with a regression model for d.prime
    ## (see the referenced paper for details):
    n.women &lt;- c(2, 2, 6)*10
    n.men &lt;- c(1, 2, 7)*10
    wt &lt;- c(n.women, n.men)
    response &lt;- gl(3,1, length = 6)
    gender &lt;- gl(2, 3, labels = c("women", "men"))
    fm2 &lt;- clm(response ~ gender, weights = wt, link = "probit")
    clm2twoAC(fm2)
}


</code></pre>

<hr>
<h2 id='confint.twoAC'>
Confidence intervals and profile likelihoods for parameters in
2AC models
</h2><span id='topic+confint.twoAC'></span><span id='topic+confint.profile.twoAC'></span><span id='topic+profile.twoAC'></span><span id='topic+plot.profile.twoAC'></span>

<h3>Description</h3>

<p>Computes confidence intervals from the profiled likelihood and the
Wald approximation in the 2AC model, or plots the
profile likelihood function for d.prime.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'twoAC'
confint(object, parm, level = 0.95,
        type = c("likelihood", "Wald"), ...)

## S3 method for class 'profile.twoAC'
confint(object, parm = "d.prime", level = 0.95, ...)

## S3 method for class 'twoAC'
profile(fitted, alpha = 1e-3, nSteps = 1e2, range, ...)

## S3 method for class 'profile.twoAC'
plot(x, level = c(0.95, 0.99), Log = FALSE,
      relative = TRUE, fig = TRUE, n = 1e3, ..., ylim = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="confint.twoAC_+3A_object">object</code></td>
<td>

<p>a fitted <code><a href="#topic+twoAC">twoAC</a></code> object or a <code>profile.twoAC</code> object.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_fitted">fitted</code></td>
<td>

<p>a fitted <code><a href="#topic+twoAC">twoAC</a></code> object.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_x">x</code></td>
<td>
<p>a <code>profile.twoAC</code> object.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_type">type</code></td>
<td>

<p>the type of confidence interval required. <code>"profile"</code> is the
most accurate.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_parm">parm</code></td>
<td>

<p>For <code>confint.profile.twoAC</code>:
has to be <code>"d.prime"</code>.
</p>
<p>For <code>confint.twoAC</code>:
for <code>type = "Wald"</code> a specification of which parameters the
confidence interval is required for. Ignored for <code>type =
    "profile"</code>.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_level">level</code></td>
<td>

<p>the confidence level required.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_alpha">alpha</code></td>
<td>
<p>determines the range of profiling. By default the
likelihood is profiled in the 99.9% Wald confidence interval
region.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_range">range</code></td>
<td>

<p>if supplied, <code>d.prime</code> will be profiled between
<code>min(range)</code> and <code>max(range)</code>. This over-rules the
automatic range computation.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_nsteps">nSteps</code></td>
<td>
<p>the number of profile steps.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_log">Log</code></td>
<td>
<p>should the profile likelihood be plotted on the log-scale?
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_relative">relative</code></td>
<td>
<p>should the relative or the absolute likelihood be
plotted?
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_fig">fig</code></td>
<td>
<p>should the profile likelihood be plotted?
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_n">n</code></td>
<td>
<p>the no. points used in the spline interpolation of the
profile likelihood.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_ylim">ylim</code></td>
<td>
<p>overrules default y-limits on the plot of the profile
likelihood.
</p>
</td></tr>
<tr><td><code id="confint.twoAC_+3A_...">...</code></td>
<td>

<p>not currently used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These <code>confint</code> methods call
the appropriate profile method, then finds the
confidence intervals by interpolation of the profile traces.
If the profile object is already available, this should be used as the
main argument rather than the fitted model object itself.
</p>
<p>In <code>plot.profile.twoAC</code>: at least one of <code>Log</code> and
<code>relative</code> arguments have to be <code>TRUE</code>.
</p>


<h3>Value</h3>

<p><code>confint</code>:
A matrix (or vector) with columns giving lower and upper confidence
limits for each parameter. These will be labelled as (1-level)/2 and
1 - (1-level)/2 in % (by default 2.5% and 97.5%).
Profile likelihood confindence intervals are only available for
<code>d.prime</code> and not <code>tau</code>.
</p>
<p><code>profile.twoAC</code>: a <code>data.frame</code> with the profile of
<code>d.prime</code>.
</p>
<p><code>plot.profile.twoAC</code> invisibly returns the spline approcimation to
the profile.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Christensen R.H.B., lee H-S and Brockhoff P.B. (2012). Estimation of
the Thurstonian model for the 2-AC protocol. Food Quality
and Preference, 24(1), pp.119-128.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+profile">profile</a></code> and <code><a href="stats.html#topic+confint">confint</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
(fm1 &lt;- twoAC(c(2, 2, 6)))
confint(fm1)
confint(fm1, type = "Wald")

pr1 &lt;- profile(fm1)
confint(pr1)

pr1 &lt;- profile(fm1, alpha = 1e-5)
old &lt;- par(mfrow = c(2,2))
plot(pr1)
plot(pr1, Log = FALSE, relative = TRUE)
plot(pr1, Log = TRUE, relative = TRUE)
plot(pr1, Log = TRUE, relative = FALSE)
par(old)


</code></pre>

<hr>
<h2 id='discrim'>Sensory discrimination analysis</h2><span id='topic+discrim'></span><span id='topic+print.discrim'></span>

<h3>Description</h3>

<p>Computes the probability of a correct answer (Pc), the probability of
discrimination (Pd) and d-prime, their standard errors, confidence
intervals and a p-value of a difference or similarity test for one of
the four common discrimination protocols.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
discrim(correct, total, d.prime0, pd0, conf.level = 0.95,
           method = c("duotrio", "tetrad", "threeAFC", "twoAFC",
             "triangle", "hexad", "twofive", "twofiveF"),
           double = FALSE,
           statistic = c("exact", "likelihood", "score", "Wald"),
           test = c("difference", "similarity"), ...)

## S3 method for class 'discrim'
print(x, digits = max(3, getOption("digits")-3), ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discrim_+3A_correct">correct</code></td>
<td>
<p>the number of correct answers; non-negativescalar
integer</p>
</td></tr>
<tr><td><code id="discrim_+3A_total">total</code></td>
<td>
<p>the total number of answers (the sample size); positive
scalar integer</p>
</td></tr>
<tr><td><code id="discrim_+3A_d.prime0">d.prime0</code></td>
<td>
<p>The value of d-prime under the
null hypothesis; numerical non-zero scalar</p>
</td></tr>
<tr><td><code id="discrim_+3A_pd0">pd0</code></td>
<td>
<p>the probability of discrimination under the
null hypothesis; numerical scalar between zero and one</p>
</td></tr>
<tr><td><code id="discrim_+3A_conf.level">conf.level</code></td>
<td>
<p>the confidence level for the confidence intervals</p>
</td></tr>
<tr><td><code id="discrim_+3A_method">method</code></td>
<td>
<p>the discrimination protocol. Eight allowed values:
&quot;twoAFC&quot;, &quot;threeAFC&quot;, &quot;duotrio&quot;, &quot;tetrad&quot;, &quot;triangle&quot;, &quot;twofive&quot;,
&quot;twofiveF&quot;, &quot;hexad&quot;</p>
</td></tr>
<tr><td><code id="discrim_+3A_double">double</code></td>
<td>
<p>should the 'double' variant of the discrimination protocol
be used? Logical scalar. Currently not implemented for &quot;twofive&quot;,
&quot;twofiveF&quot;, and &quot;hexad&quot;.</p>
</td></tr>
<tr><td><code id="discrim_+3A_test">test</code></td>
<td>
<p>the type of test</p>
</td></tr>
<tr><td><code id="discrim_+3A_statistic">statistic</code></td>
<td>
<p>the statistic to be used for hypothesis testing and
confidence intervals</p>
</td></tr>
<tr><td><code id="discrim_+3A_x">x</code></td>
<td>
<p>an object of class <code>"discrim"</code></p>
</td></tr>
<tr><td><code id="discrim_+3A_digits">digits</code></td>
<td>
<p>number of digits in resulting table of results</p>
</td></tr>
<tr><td><code id="discrim_+3A_...">...</code></td>
<td>
<p>not currently used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The degree of product difference/discrimination under the null
hypothesis can be specified on <em>either</em> the d-prime scale or on
the pd (proportion of discriminators) scale. This is done by using
either the <code>d.prime0</code> <em>or</em> the <code>pd0</code> arguments.
If unspecified, they default to zero and the
conventional difference test of &quot;no difference&quot; is obtained.
</p>
<p>For a similarity test either <code>d.prime0</code> <em>or</em> <code>pd0</code> have
to be specified <em>and</em> and a non-zero, positive value should to be
given. Here, <code>d.prime0</code> or <code>pd0</code> define the <code>limit of
  similarity</code> or <code>equivalence</code>.
</p>
<p>The probability under the null hypothesis is
given by <code>pd0 + pg * (1 - pd0)</code> where <code>pg</code> is the guessing
probability which is defined by the discrimination protocol given in
the <code>method</code> argument.
</p>
<p>All estimates are restricted to their allowed ranges, e.g. Pc is
always as least as large as the guessing probability. Similarly
confidence limits are also restricted to the allowed range of the
parameters.
</p>
<p>Standard errors are not defined when the parameter estimates are at
the boundary of their allowed range, so these will be reported as
<code>NA</code> in such cases.
</p>
<p>If <code>double = "TRUE"</code>, the 'double' variants of the discrimination
methods is used. For example in a double-triangle test each participant
will perform two individual triangle tests and only obtain a correct
answer in the double-triangle test if both of the answers to the
individual triangle tests are correct. The guessing probability for
the double methods are lower than in the conventional discrimination
methods. If <code class="reqn">p_g</code> is the guessing probability of the conventional
discrimination method, then <code class="reqn">p_g^2</code> is the guessing probability of
the double variant of that discrimination method. All the double
discrimination methods have their own psychometric functions.
</p>
<p>The <code>"Wald"</code> statistic is *NOT* recommended for practical
use&mdash;it is included here for completeness and to allow comparisons.
</p>
<p>For <code>statistic = "score"</code>, the confidence interval is computed
from Wilson's score interval, and the p-value for the hypothesis
test is based on Pearson's chi-square test,
cf. <code><a href="stats.html#topic+prop.test">prop.test</a></code>.
</p>


<h3>Value</h3>

<p>An object of class <code>discrim</code> with elements
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>matrix of estimates, standard errors and
confidence intervals</p>
</td></tr>




<tr><td><code>data</code></td>
<td>
<p>a named vector with the data supplied to the function</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>the p-value of the hypothesis test</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>the type of test</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the discrimination protocol</p>
</td></tr>
<tr><td><code>double</code></td>
<td>
<p>logical scalar; <code>TRUE</code> if a double discrimination
method is used, otherwise <code>FALSE</code></p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>the statistic used for confidence intervals and
p-value</p>
</td></tr>
<tr><td><code>pd0</code></td>
<td>
<p>the probability of discrimination under the
null hypothesis</p>
</td></tr>
<tr><td><code>alt.scale</code></td>
<td>
<p>the scale for the alternative hypothesis,
e.g.~<code>"d.prime"</code> or <code>"pd"</code></p>
</td></tr>
<tr><td><code>conf.level</code></td>
<td>
<p>the confidence level</p>
</td></tr>
<tr><td><code>stat.value</code></td>
<td>
<p>for <code>statistic != "exact"</code> the value of the
test statistic used to calculate the p-value</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>for <code>statistic == "score"</code> the number of degrees of
freedom used for the Pearson chi-square test to calculate the
p-value</p>
</td></tr>
<tr><td><code>profile</code></td>
<td>
<p>for <code>statistic == "likelihood"</code> the profile
likelihood on the scale of Pc</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen and Per Bruun Brockhoff</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen, R.H.B (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.
</p>
<p>Bi, J. (2001) The double discrimination methods. Food Quality and
Preference, 12, pp. 507-513.
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+discrimSS">discrimSS</a></code>, <code><a href="#topic+samediff">samediff</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+findcr">findcr</a></code>,
<code><a href="#topic+profile.discrim">profile</a></code>,
<code><a href="#topic+profile.discrim">plot.profile</a></code>
<code><a href="#topic+profile.discrim">confint</a></code>
</p>
<p>Link functions / discrimination protocols: 
<code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+duotrio">duotrio</a></code>,
<code><a href="#topic+tetrad">tetrad</a></code>, <code><a href="#topic+twofive">twofive</a></code>,
<code><a href="#topic+twofiveF">twofiveF</a></code>, <code><a href="#topic+hexad">hexad</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Running the simple discrimination (difference) tests:
discrim(10, 15, method = "twoAFC")
discrim(10, 15, method = "threeAFC", statistic = "likelihood")
discrim(10, 15, method = "tetrad", statistic = "likelihood")
discrim(10, 15, method = "duotrio", conf.level = 0.90)
discrim(10, 15, method = "triangle", statistic = "score")

# Example of double duotrio discrimination test from Bi (2001):
discrim(35, 100, method = "duotrio", double=TRUE, statistic = "exact")
# Critical value for a sample size of 100 and a guessing probability of 1/4:
findcr(100, p0=1/4) # 33


## plot the distributions of sensory intensity:
m1 &lt;- discrim(10, 15, method = "twoAFC")
plot(m1)

## A similarity test where less than chance successes are obtained:
discrim(22, 75, method = "triangle", d.prime0 = 1, test = "similarity")

</code></pre>

<hr>
<h2 id='discrimPwr'>Sensory discrimination power analysis</h2><span id='topic+discrimPwr'></span><span id='topic+d.primePwr'></span>

<h3>Description</h3>

<p>Computes the power of a difference or similarity test for a sensory
discrimination experiment using the binomial distribution.
<code>d.primePwr</code> is a convenience function that calls
<code>discrimPwr</code> but has arguments in terms of d-prime rather than
pd, the probability of discrimination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discrimPwr(pdA, pd0 = 0, sample.size, alpha = 0.05, pGuess = 1/2,
           test = c("difference", "similarity"),
           statistic = c("exact", "normal", "cont.normal"))

d.primePwr(d.primeA, d.prime0 = 0, sample.size, alpha = 0.05,
           method = c("duotrio", "tetrad", "threeAFC", "twoAFC",
             "triangle", "hexad", "twofive", "twofiveF"),
           double = FALSE,
           test = c("difference", "similarity"),
           statistic = c("exact", "normal", "cont.normal"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discrimPwr_+3A_pda">pdA</code></td>
<td>
<p>the probability of discrimination for the model under the
alternative hypothesis; scalar between zero and one</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_d.primea">d.primeA</code></td>
<td>
<p>d-prime for the model under the
alternative hypothesis; non-negative numerical scalar</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_pd0">pd0</code></td>
<td>
<p>the probability of discrimination under the
null hypothesis; scalar between zero and one</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_d.prime0">d.prime0</code></td>
<td>
<p>d-prime under the null hypothesis; non-negative
numerical scalar</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_sample.size">sample.size</code></td>
<td>
<p>the sample size; a scalar positive integer</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_alpha">alpha</code></td>
<td>
<p>the type I level of the test; scalar between zero and
one</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_method">method</code></td>
<td>
<p>the discrimination protocol for which the power should
be computed</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_double">double</code></td>
<td>
<p>should the 'double' variant of the discrimination protocol
be used? Logical scalar. Currently not implemented for &quot;twofive&quot;,
&quot;twofiveF&quot;, and &quot;hexad&quot;.</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_pguess">pGuess</code></td>
<td>
<p>the guessing probability for the discrimination
protocol, e.g. 1/2 for duo-trio and 2-AFC, 1/3 for
triangle, tetrad and 3-AFC, 1/10 for two-out-of-five and hexad
and 2/5 for two-out-of-five with forgiveness; scalar between zero and one</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_test">test</code></td>
<td>
<p>the type of one-sided binomial test (direction of the
alternative hypothesis): &quot;difference&quot; corresponds &quot;greater&quot; and
&quot;similarity&quot; corresponds to &quot;less&quot;</p>
</td></tr>
<tr><td><code id="discrimPwr_+3A_statistic">statistic</code></td>
<td>
<p>should power determination be based on the 'exact'
binomial test, the normal approximation to this, or the
normal approximation with continuity correction?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power of the standard one-tailed difference test where the null
hypothesis is &quot;no difference&quot; is obtained with <code>pd0 = 0</code>.
</p>
<p>The probability under the null hypothesis is
given by <code>pd0 + pg * (1 - pd0)</code> where <code>pg</code> is the guessing
probability <code>pGuess</code>. Similarly, the probability of the
alternative hypothesis is given by <code>pdA + pg * (1 - pdA)</code>
</p>


<h3>Value</h3>

<p>The power; a numerical scalar.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen and Per Bruun Brockhoff</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen, R.H.B (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.
</p>
<p>Bi, J. (2001) The double discrimination methods. Food Quality and
Preference, 12, pp. 507-513.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+findcr">findcr</a></code>,
<code><a href="#topic+discrim">discrim</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Finding the power of a discrimination test with d-prime = 1,
## a sample of size 30 and a type I level of .05:
pd &lt;- coef(rescale(d.prime = 1, method = "twoAFC"))$pd
discrimPwr(pd, sample.size = 30)
d.primePwr(1, sample.size = 30, method = "twoAFC")
## Obtaining the equivalent normal approximation with and without
## continuity correction:
discrimPwr(pd, sample.size = 30, statistic = "cont.normal")
discrimPwr(pd, sample.size = 30, statistic = "normal")

# Example from Bi (2001) with n=100 and 35 correct answers in a 
# double duotrio test:
p1 &lt;- 0.35
# Estimate of d-prime quoted by Bi(2001) was 1.06:
dp &lt;- psyinv(p1, method="duotrio", double=TRUE) 
# Power using normal approximation w/o continuity adjustment quoted by Bi(2001):
d.primePwr(dp, sample.size = 100, method="duotrio", 
           double=TRUE, stat="normal") # 0.73
# d.primePwr(dp, sample.size = 100, method="duotrio", double=TRUE, 
#            stat="cont.normal")

# Power of exact test:
d.primePwr(dp, sample.size = 100, method="duotrio", 
           double=TRUE, stat="exact") # 0.697

## A similarity example:
discrimPwr(pdA = 0.1, pd0 = 0.2, sample.size = 100, pGuess = 1/3,
           test = "similarity")


</code></pre>

<hr>
<h2 id='discrimR'>Replicated Thurstonian Model for discrimination analysis</h2><span id='topic+discrimR'></span>

<h3>Description</h3>

<p>The model is a synthesis of a mixture and a mixed effect model. The
random effect distribution for the cluster term (often individuals) is
a point mass for delta = 0 and a continuous distribution for delta &gt;
0.
</p>
<p>The function fits the model and computes d-prime for an average
subject, 2) the variance among subjects, 3) the &quot;posterior&quot; probability
of a subject being a discriminator (with delta &gt; 0), 4) the
&quot;posterior&quot; expectation on the random effect (ie. the subject-specific
delta) and 5) the probability that a randomly chosen individual is a
discriminator (ie. the probability mass at delta = 0 in the random
effects distribution)
</p>
<p>Warning: This function is preliminary; see the details for further
information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discrimR(formula, data, weights, cluster, start, subset, na.action,
           contrasts = NULL, hess = FALSE, ranef = FALSE, zi = FALSE,
           method = c("duotrio", "probit", "threeAFC", "triangle",
             "twoAFC"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discrimR_+3A_formula">formula</code></td>
<td>
<p>A formula where the lhs is the binomial response. An
indicator vector or a matrix with two column; successes and failures
like in a call to <code><a href="stats.html#topic+glm">glm</a></code> with a binomial family. The rhs
should be <code>1</code>; no other predictors are currently allowed, but
extending this is ongoing work.</p>
</td></tr>
<tr><td><code id="discrimR_+3A_data">data</code></td>
<td>
<p>The <code>data.frame</code> in which to look for variables.</p>
</td></tr>
<tr><td><code id="discrimR_+3A_weights">weights</code></td>
<td>
<p>Possible weights</p>
</td></tr>
<tr><td><code id="discrimR_+3A_cluster">cluster</code></td>
<td>
<p>The clustering variable; should be a factor.</p>
</td></tr>
<tr><td><code id="discrimR_+3A_start">start</code></td>
<td>
<p>Optional starting values; recommended in the current
implementation</p>
</td></tr> 
<tr><td><code id="discrimR_+3A_subset">subset</code></td>
<td>
<p>...</p>
</td></tr>
<tr><td><code id="discrimR_+3A_na.action">na.action</code></td>
<td>
<p>...</p>
</td></tr>
<tr><td><code id="discrimR_+3A_contrasts">contrasts</code></td>
<td>
<p>...</p>
</td></tr>
<tr><td><code id="discrimR_+3A_hess">hess</code></td>
<td>
<p>Should the hessian of the parameters be computed?</p>
</td></tr>
<tr><td><code id="discrimR_+3A_ranef">ranef</code></td>
<td>
<p>Should the random effect estimates be computed?</p>
</td></tr>
<tr><td><code id="discrimR_+3A_zi">zi</code></td>
<td>
<p>Should the posterior probabilities of a subject being a
discriminator be computed? </p>
</td></tr>
<tr><td><code id="discrimR_+3A_method">method</code></td>
<td>
<p>Should correspond to the actual test applied.</p>
</td></tr>
<tr><td><code id="discrimR_+3A_...">...</code></td>
<td>
<p>Additional arguments to
<code><a href="stats.html#topic+optim">optim</a></code>. <code>control=list(trace=TRUE, REPORT=1)</code> is
recommended, so the reduction in deviance and convergence can be
followed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is preliminary and improving it is ongoing work. The
computational methods are expected to change completely. This will
hopefully facilitate methods for more general rhs-formulae with
additional predictors.
</p>
<p>Currently no methods or extractor functions have been written, so the
user will have to select the relevant elements from the fitted object
(see below). Implementation of methods and extractor functions will
occur in due course. 
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table role = "presentation">
<tr><td><code>fpar</code></td>
<td>
<p>The fixed effect parameter, ie. delta (for an average
individual)</p>
</td></tr> 
<tr><td><code>rpar</code></td>
<td>
<p>A vector with two elements: The first element is the
variance component (standard deviation) on the log-scale, where
optimization is performed. The second element is the variance
component (standard deviation) on the original scale.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>Deviance for the model</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>standard errors for 1) the fixed effect parameter and 2) the
variance component on the log-scale</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>Convergence message from <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code>lli</code></td>
<td>
<p>Log-likelihood contributions from each of the observations.</p>
</td></tr>
<tr><td><code>ranef</code></td>
<td>
<p>The random effect estimates for the levels of the
clustering factor (often individual)</p>
</td></tr>
<tr><td><code>zi</code></td>
<td>
<p>posterior probabilities of a subject being a
discriminator</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>The probability that a randomly chosen individual is a
discriminator (ie. the probability mass for delta &gt; 0 in the random
effects distribution)</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>Fitted values</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>The scaled response vector on which optimization is performed.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

 <p><code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+duotrio">duotrio</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+discrimSS">discrimSS</a></code>, <code><a href="#topic+samediff">samediff</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+findcr">findcr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
freq &lt;- c(10,8,10,9,8,9,9,1,10,10,8,2,6,7,6,7,6,4,5,5,3,3,9,9,5,5,8,8,9,9)
tmp &lt;- data.frame(id = factor(1:30), n = rep(10, 30), freq = freq)
head(tmp)
str(tmp)

fm &lt;- discrimR(cbind(freq, n - freq) ~ 1, tmp, cluster = id,
                    start = c(.5, .5), method = "twoAFC",
                    ranef = TRUE, zi = TRUE, hess = TRUE, 
                    control=list(trace=TRUE, REPORT=1))

names(fm)
fm[1:4]

</code></pre>

<hr>
<h2 id='discrimSim'>Simulates replicated difference tests</h2><span id='topic+discrimSim'></span>

<h3>Description</h3>

<p>Simulates the outcome of <code>sample.size</code> replicated sensory
difference tests (for any one of eight protocols: 2-AFC, 3-AFC,
duotrio, tetrad, triangle, two-out-of-five, two-out-of-five with
forgiveness and hexad tests)
for a given d-prime value and a given overdispersion (default 0).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discrimSim(sample.size, replicates, d.prime, sd.indiv = 0,
           method = c("duotrio", "halfprobit", "probit", "tetrad",
             "triangle", "twoAFC", "threeAFC", "hexad", "twofive", "twofiveF"),
           double = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discrimSim_+3A_sample.size">sample.size</code></td>
<td>
<p>the sample size - number of subjects</p>
</td></tr>
<tr><td><code id="discrimSim_+3A_replicates">replicates</code></td>
<td>
<p>number of replications per subject</p>
</td></tr>
<tr><td><code id="discrimSim_+3A_d.prime">d.prime</code></td>
<td>
<p>the value of d-prime</p>
</td></tr>
<tr><td><code id="discrimSim_+3A_method">method</code></td>
<td>
<p>the discrimination protocol</p>
</td></tr>
<tr><td><code id="discrimSim_+3A_sd.indiv">sd.indiv</code></td>
<td>
<p>the individual variability in d-prime values. A value
of 0 (default) corresponds to complete independence</p>
</td></tr>
<tr><td><code id="discrimSim_+3A_double">double</code></td>
<td>
<p>should the 'double' variant of the discrimination protocol
be used? Logical scalar. Currently not implemented for &quot;twofive&quot;,
&quot;twofiveF&quot;, and &quot;hexad&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The d-prime for each subject is a random draw from a normal
distribution with mean <code>d.prime</code> and standard deviation
<code>sd.indiv</code>. All negative values are set to zero.
</p>


<h3>Value</h3>

<p>A vector of length <code>sample.size</code> with the number of correct
answers for each subject.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen and Per Bruun Brockhoff</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen, R.H.B. (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+duotrio">duotrio</a></code>,
<code><a href="#topic+tetrad">tetrad</a></code>, <code><a href="#topic+twofive">twofive</a></code>,
<code><a href="#topic+twofiveF">twofiveF</a></code>, <code><a href="#topic+hexad">hexad</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Running simulations:
discrimSim(sample.size = 10, replicates = 3, d.prime = 2,
           method = "triangle", sd.indiv = 1)

</code></pre>

<hr>
<h2 id='discrimSS'>Sensory discrimination sample size calculation</h2><span id='topic+discrimSS'></span><span id='topic+d.primeSS'></span>

<h3>Description</h3>

<p>Computes the sample size for a difference or similarity test for a
sensory discrimination experiment using the binomial distribution.
<code>d.primeSS</code> is a convenience function that calls
<code>discrimSS</code> but has arguments in terms of d-prime rather than
pd, the expected proportion of discriminators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>discrimSS(pdA, pd0 = 0, target.power = 0.90, alpha = 0.05,
          pGuess = 1/2, test = c("difference", "similarity"),
          statistic = c("exact", "stable.exact", "both.exact",
           "normal", "cont.normal"))

d.primeSS(d.primeA, d.prime0 = 0, target.power = 0.90, alpha = 0.05,
          method = c("duotrio", "tetrad", "threeAFC", "twoAFC",
            "triangle", "hexad", "twofive", "twofiveF"),
          double = FALSE,
          test = c("difference", "similarity"),
          statistic = c("exact", "stable.exact", "both.exact",
           "normal", "cont.normal"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="discrimSS_+3A_pda">pdA</code></td>
<td>
<p>the probability of discrimination for the model under the
alternative hypothesis; scalar between zero and one</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_d.primea">d.primeA</code></td>
<td>
<p>d-prime for the model under the
alternative hypothesis; non-negative numerical scalar</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_pd0">pd0</code></td>
<td>
<p>the probability of discrimination under the
null hypothesis; scalar between zero and one</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_d.prime0">d.prime0</code></td>
<td>
<p>d-prime under the null hypothesis; non-negative
numerical scalar</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_target.power">target.power</code></td>
<td>
<p>the desired power for the test</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_alpha">alpha</code></td>
<td>
<p>the type I level of the test; scalar between zero and
one</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_method">method</code></td>
<td>
<p>the discrimination protocol for which the sample size
should be computed</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_double">double</code></td>
<td>
<p>should the 'double' variant of the discrimination protocol
be used? Logical scalar. Currently not implemented for &quot;twofive&quot;,
&quot;twofiveF&quot;, and &quot;hexad&quot;.</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_pguess">pGuess</code></td>
<td>
<p>the guessing probability for the discrimination
protocol, e.g. 1/2 for duo-trio and 2-AFC, 1/3 for
triangle, tetrad and 3-AFC, 1/10 for two-out-of-five and hexad
and 2/5 for two-out-of-five with forgiveness;; scalar between zero and one</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_test">test</code></td>
<td>
<p>the type of one-sided binomial test (direction of the
alternative hypothesis): &quot;difference&quot; corresponds &quot;greater&quot; and
&quot;similarity&quot; corresponds to &quot;less&quot;</p>
</td></tr>
<tr><td><code id="discrimSS_+3A_statistic">statistic</code></td>
<td>
<p>options are explained in the Details section below</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For difference tests <code>pdA</code> or <code>d.primeA</code> (the sensory
difference under the alternative hypothesis) has to be larger than
<code>pd0</code> or <code>d.prime0</code> (the sensory  difference under the null
hypothesis). The sample size of the standard one-tailed difference
test where the null hypothesis of &quot;no difference&quot; is obtained with
<code>pd0 = 0</code> or <code>d.prime0 = 0</code>.
</p>
<p>For similarity tests it is required that <code>pd0</code> &gt; <code>pdA</code> or
equivalently that <code>d.prime0</code> &gt; <code>d.primeA</code>. Here, the
interval [0, <code>pdA</code>] or [0, <code>d.primeA</code>]
is the similarity region covering sensory differences for which we
would say that the products are similar.
</p>
<p>The probability of a correct answer under the null hypothesis is
given by <code>pd0 + pGuess * (1 - pd0)</code>. Similarly, the probability
of a correct answer under the alternative hypothesis is given by
<code>pdA + pGuess * (1 - pdA)</code>.
</p>
<p>The <code>statistic</code> argument:
</p>

<ul>
<li> <p><code>"exact"</code>  
is the conventional sample size for the exact binomial test:
The smallest sample size that gives the desired power
(<code>target.power</code>) at the given
significance level. Ususally slightly higher sample sizes will not
have the desired power, however. This is due to the non-monotonic
behavior of power as a function of sample size.
</p>
</li>
<li> <p><code>"stable.exact"</code> 
is so-called stable exact sample size proposed by Ennis and
Jesionka (2011) which has the property that no larger sample sizes
has a power less than the <code>target.power</code>.
</p>
</li>
<li> <p><code>"both.exact"</code> 
returns both <code>exact</code> and <code>stable.exact</code>
sample sizes
</p>
</li>
<li> <p><code>"normal"</code> 
is the normal approximation to the exact binomial sample size
without any continuity adjustment. This usually provides a sample
size that is smaller than the sample size for the exact binomial
test.
</p>
</li>
<li> <p><code>"cont.normal"</code> 
is the continuity adjusted normal approximation to
the sample size for the exact binomial test. This sample size is
usually closer to the exact sample size than the unadjusted
approximation and usually higher than the unadjusted
approximation.
</p>
</li></ul>

<p>If the sample size based on the continuity adjusted normal
approximation is larger than 10,000, the function returns the normal
approximation and issues a warning.
</p>


<h3>Value</h3>

<p>The sample size; an integer.
</p>


<h3>Author(s)</h3>

<p>Per Bruun Brockhoff and Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen, R.H.B (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.
</p>
<p>Ennis, J.M. and V. Jesionka (2011). The power of sensory
discrimination methods revisited. Journal of Sensory Studies, 26,
pp. 371-382.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimPwr">discrimPwr</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Finding the smallest necessary sample size:
discrimSS(pdA = 0.5, pd0 = 0, target.power = 0.80, alpha = 0.05,
   pGuess = 1/2, test = "difference", statistic = "exact")
## The stable-exact sample size is larger:
discrimSS(pdA = 0.5, pd0 = 0, target.power = 0.80, alpha = 0.05,
   pGuess = 1/2, test = "difference", statistic = "stable.exact")

## Give identical results:
pd &lt;- coef(rescale(d.prime = 1, method = "twoAFC"))$pd
discrimSS(pdA = pd, pd0 = 0, target.power = 0.90, alpha = 0.05,
   pGuess = 1/2, test = "difference", statistic = "exact")
d.primeSS(1, target.power = 0.90, method = "twoAFC")

## A similarity example:
discrimSS(pdA = 0.1, pd0 = 0.2, target.power = 0.80, alpha = 0.05,
   pGuess = 1/2, test = "similarity", statistic = "exact")

</code></pre>

<hr>
<h2 id='dod'>Thurstonian Degree-of-Difference (DOD) model</h2><span id='topic+dod'></span><span id='topic+print.dod'></span>

<h3>Description</h3>

<p>Fits the Thurstonian Degree-of-Difference (DOD) model and performs
hypothesis/significance tests of d-prime (Thurstonian
delta). One-sided difference and similarity tests as well as two-sided
tests of d-prime are available. The user may choose from a number of
tests statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dod(same, diff, d.prime0 = 0, conf.level = 0.95,
    statistic = c("likelihood", "Pearson", "Wilcoxon", "Wald"),
    alternative = c("difference", "similarity", "two.sided",
    "less", "greater"), control=dodControl(), ...)

## S3 method for class 'dod'
print(x, digits = max(3, getOption("digits") - 3), ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dod_+3A_same">same</code></td>
<td>
<p>the answers to same-pairs; either 1) a numeric vector of
counts of length equal to the number of response categories
ordered appropriately or 2) a
factor where the levels indicate the response categories.</p>
</td></tr>
<tr><td><code id="dod_+3A_diff">diff</code></td>
<td>
<p>the answers to different-pairs in the same format as
<code>same</code>.</p>
</td></tr>
<tr><td><code id="dod_+3A_d.prime0">d.prime0</code></td>
<td>
<p>the value of d.prime under the null hypothesis. In the
standard no-difference test <code>d.prime0 = 0</code>, while it has to
be positive for similarity tests and two-sided tests.</p>
</td></tr>
<tr><td><code id="dod_+3A_conf.level">conf.level</code></td>
<td>
<p>the confidence level for the confidence intervals</p>
</td></tr>
<tr><td><code id="dod_+3A_statistic">statistic</code></td>
<td>
<p>the statistic to be used for hypothesis testing</p>
</td></tr>
<tr><td><code id="dod_+3A_alternative">alternative</code></td>
<td>
<p>the nature of the alternative hypothesis in the
hypothesis/significance test for d-prime. Note that
<code>"greater"</code> is an alias for <code>"difference"</code> and
<code>"less"</code> is an alias for <code>"similarity"</code></p>
</td></tr>
<tr><td><code id="dod_+3A_control">control</code></td>
<td>
<p>options to control the fitting process specfied via a
call to <code><a href="#topic+dodControl">dodControl</a></code>.</p>
</td></tr>
<tr><td><code id="dod_+3A_x">x</code></td>
<td>
<p>an object of class <code>"dod"</code>.</p>
</td></tr>
<tr><td><code id="dod_+3A_digits">digits</code></td>
<td>
<p>number of digits in resulting table of results.</p>
</td></tr>
<tr><td><code id="dod_+3A_...">...</code></td>
<td>
<p>not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>dod</code> will report the likelihood based confidence interval for
d.prime unless <code>statistic = "Wald"</code> in which case the
standard symmetric Wald type confidence interval is
reported. This interval can be highly inaccurate and so is not
recommened for practical use.
</p>
<p>The p-value for the standard one-tailed difference test of &quot;no
difference&quot; is obtained with <code>d.prime0 = 0</code> corresponding to the
default setting.
</p>
<p>The standard error of d-prime is not defined when the parameter
estimate is zero (or numerically close) and it will be reported as
<code>NA</code> in this case.
</p>
<p>The <code>"Wald"</code> statistic is *NOT* recommended for practical
use&mdash;it is only included here for completeness and to allow
comparisons with other software etc.
</p>


<h3>Value</h3>

<p>An object of class <code>dod</code>.
</p>
















<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Ennis, J.M. and R.H.B. Christensen (2015) A Thurstonian comparison
of the tetrad and degree of difference tests.
<em>Food Quality and Preference</em>, 40, pp.263-269.
</p>
<p>Christensen, R.H.B, J.M. Ennis, D.M. Ennis and P.B Brockhoff (2012)
A Thurstonian model for the Degree of Difference test
with extensions to unequal variance, sequence effects
and replicated data. Talk at Sensometrics conference, Rennes, France,
July 11th.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dodSim">dodSim</a></code>, 
<code><a href="#topic+dodPwr">dodPwr</a></code>,
<code><a href="#topic+dodControl">dodControl</a></code>, <code><a href="#topic+dod_fit">dod_fit</a></code>,
<code><a href="#topic+optimal_tau">optimal_tau</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## DOD example data:
same.pairs &lt;- c(25, 22, 33, 20)
diff.pairs &lt;- c(18, 22, 30, 30)

## Fit Thurstonian dod-model and perform difference test:
dod(same=same.pairs, diff=diff.pairs)

## Can choose another test statistic (e.g. Wilcoxon):
dod(same=same.pairs, diff=diff.pairs, statistic="Wilcox")

## A similarity test (with simulated data):
set.seed(121)
(Data2 &lt;- dodSim(d.prime=0, ncat=4, sample.size=200, method.tau="equi.prob"))
dod(same=Data2[1, ], diff=Data2[2, ], d.prime0=1.2,
    alternative="similarity")

## Extract parameters from a dod fit:
fm &lt;- dod(same=same.pairs, diff=diff.pairs)
coef(fm)


</code></pre>

<hr>
<h2 id='dod_fit'>Direct fitter of the Thurstonian Degree-of-Difference (DOD) model</h2><span id='topic+dod_fit'></span>

<h3>Description</h3>

<p>Fits the Thurstonian Degree-of-Difference (DOD) model.
This function is for programming use. The ordinary user probably wants
the <code><a href="#topic+dod">dod</a></code> function, which is for interactive use.
<code>dod_fit</code> only estimates the DOD model and performs no hypothesis
or significance tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dod_fit(same, diff, tau=NULL, d.prime=NULL, control=dodControl(),
        ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dod_fit_+3A_same">same</code></td>
<td>
<p>the answers to same-pairs; either 1) a numeric vector of
counts of length equal to the number of response categories
ordered appropriately or 2) a
factor where the levels indicate the response categories.</p>
</td></tr>
<tr><td><code id="dod_fit_+3A_diff">diff</code></td>
<td>
<p>the answers to different-pairs in the same format as
<code>same</code>.</p>
</td></tr>
<tr><td><code id="dod_fit_+3A_tau">tau</code></td>
<td>
<p>optional vector of boundary parameters. If specified,
<code>dod_fit</code> will not optimize over the <code>tau</code> parameters.</p>
</td></tr>
<tr><td><code id="dod_fit_+3A_d.prime">d.prime</code></td>
<td>
<p>optional d-prime value. If specified,
<code>dod_fit</code> will not optimize over <code>d.prime</code>.</p>
</td></tr>
<tr><td><code id="dod_fit_+3A_control">control</code></td>
<td>
<p>options to control the fitting process specfied via a
call to <code><a href="#topic+dodControl">dodControl</a></code>.</p>
</td></tr>
<tr><td><code id="dod_fit_+3A_...">...</code></td>
<td>
<p>not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard error of d-prime is not defined when the parameter
estimate is zero (or numerically close) and it will be reported as
<code>NA</code> in this case.
</p>


<h3>Value</h3>

<p>An object of class <code>dod_fit</code>.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+dod">dod</a></code>,
<code><a href="#topic+dodSim">dodSim</a></code>, <code><a href="#topic+optimal_tau">optimal_tau</a></code>,
<code><a href="#topic+dodPwr">dodPwr</a></code>,
<code><a href="#topic+dodControl">dodControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## DOD example data:
same.pairs &lt;- c(25, 22, 33, 20)
diff.pairs &lt;- c(18, 22, 30, 30)

## Fit Thurstonian dod-model and perform difference test:
fm &lt;- dod_fit(same=same.pairs, diff=diff.pairs)
names(fm)

## Estimate d-prime for given tau:
fm &lt;- dod_fit(same=same.pairs, diff=diff.pairs, tau=1:3)

## Estimate tau for given d-prime:
fm &lt;- dod_fit(same=same.pairs, diff=diff.pairs, d.prime=1)


</code></pre>

<hr>
<h2 id='dod_utils'>Utility functions for the Degree-of-Difference model</h2><span id='topic+optimal_tau'></span><span id='topic+par2prob_dod'></span><span id='topic+dod_nll'></span><span id='topic+dod_null'></span><span id='topic+dod_null_tau'></span>

<h3>Description</h3>

<p>Various utility functions supporting the Degree-of-Difference (DOD)
model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
optimal_tau(d.prime, d.prime0 = 0, ncat=3,
            method=c("equi.prob", "LR.max", "se.min"),
            tau.start=NULL, equi.tol = 1e-4, grad.tol = 1e-2,
            do.warn=TRUE)

par2prob_dod(tau, d.prime)

dod_nll(tau, d.prime, same, diff, integer.tol=1e-8)

dod_null(same, diff, integer.tol=1e-8)

dod_null_tau(same, diff)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dod_utils_+3A_d.prime">d.prime</code></td>
<td>
<p>the value of d-prime; non-negative numerical scalar.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_d.prime0">d.prime0</code></td>
<td>
<p>d-prime under the null hypothesis; only used in
<code>optimal_tau</code> when <code>method = "LR.max"</code>.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_ncat">ncat</code></td>
<td>
<p>the number of response categories in the DOD model.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_method">method</code></td>
<td>
<p>the method with which to choose the boundary
parameters &mdash; see <code><a href="#topic+dodSim">dodSim</a></code> for details on the methods.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_tau.start">tau.start</code></td>
<td>
<p>optional vector of starting values.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_equi.tol">equi.tol</code></td>
<td>
<p>convergence tolerence for the <code>"equi.prob"</code>
method.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_grad.tol">grad.tol</code></td>
<td>
<p>gradient convergence tolerence.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_do.warn">do.warn</code></td>
<td>
<p>issue warning if estimation of optimal tau does not
converge?</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_same">same</code></td>
<td>
<p>The answers to same-pairs; either 1) a numeric vector of
counts of length equal to the number of response categories
ordered appropriately or 2) a
factor where the levels indicate the response categories.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_diff">diff</code></td>
<td>
<p>the answers to different-pairs in the same format as
<code>same</code>.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_tau">tau</code></td>
<td>
<p>vector of boundary parameters in the DOD model.</p>
</td></tr>
<tr><td><code id="dod_utils_+3A_integer.tol">integer.tol</code></td>
<td>
<p>tolerence for when <code>same</code> or <code>diff</code>
arguments are considered non-integer counts: a warning is issued if
non-integer counts are encountered.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>optimal_tau</code></td>
<td>
<p>computes optimal boundary parameters (tau)
using various criteria.</p>
</td></tr>
<tr><td><code>par2prob_dod</code></td>
<td>
<p>computes the multinomial probability vectors from
DOD model parameters.</p>
</td></tr>
<tr><td><code>dod_nll</code></td>
<td>
<p>implements the negative log-likelihood function for the
DOD model.</p>
</td></tr>
<tr><td><code>dod_null</code></td>
<td>
<p>implements the negative log-likelihood function for
the DOD model where d-prime = 0.</p>
</td></tr>
<tr><td><code>dod_null_tau</code></td>
<td>
<p>Estimates tau for the DOD model where
d-prime = 0.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

 <p><code><a href="#topic+dod">dod</a></code>, <code><a href="#topic+dod_fit">dod_fit</a></code>,
<code><a href="#topic+dodSim">dodSim</a></code>, <code><a href="#topic+dodPwr">dodPwr</a></code>,
<code><a href="#topic+dodControl">dodControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Compute optimal boundary parameters using the LR.max criterion for
## d.prime=1 with 4 categories:
dp &lt;- 1
(Tau &lt;- optimal_tau(d.prime=dp, d.prime0 = 0, ncat=4,
                    method="LR.max")$tau)
##  [1] 1.244642 2.109140 3.098985
## This set of boundary parameters optimize the power of the DOD test
## with d.prime = 1 under the alternative hypothesis.

## Compute the probability that an observation will fall in each of
## the (here 2*4=8) response categories given values of tau and d.prime:
par2prob_dod(tau=Tau, d.prime=dp)
##              [,1]      [,2]      [,3]       [,4]
##  p.same 0.6211921 0.2429480 0.1074307 0.02842911
##  p.diff 0.5124361 0.2571691 0.1596425 0.07075227

## Compute the negative log-likelihood given data and parameters:
Same &lt;- c(10, 20, 30, 20)
Diff &lt;- c(10, 10, 20, 40)
dod_nll(tau=Tau, d.prime=dp, same=Same,
        diff=Diff)
##  [1] 334.0986

## Compute the negative log-likelihood under the null hypothesis
## (where d.prime = 0):
dod_null(same=Same, diff=Diff)
##  [1] 208.8154
##  ## The boundary parameters for this:
(Tau0 &lt;- dod_null_tau(same=Same, diff=Diff))
##  [1] 0.2224709 0.5688675 1.2546147

## Some equalities:
stopifnot(
    dod_nll(tau=Tau0, d.prime=0, same=Same, diff=Diff) ==
    dod_null(same=Same, diff=Diff))
stopifnot(
    dod_null(same=Same, diff=Diff) ==
    -dod_fit(same=Same, diff=Diff, d.prime=0)$logLik
    )
stopifnot(
    dod_nll(same=Same, diff=Diff, tau=Tau, d.prime=dp) ==
    -dod_fit(same=Same, diff=Diff, tau=Tau, d.prime=dp)$logLik
    )
stopifnot(all(
    dod_null_tau(same=Same, diff=Diff) ==
    dod_fit(Same, Diff, d.prime=0)$tau))


</code></pre>

<hr>
<h2 id='dodControl'>Control settings for the dod function</h2><span id='topic+dodControl'></span>

<h3>Description</h3>

<p>Specify control setting when fitting the the Thurstonian
Degree-of-Difference (DOD) model using <code><a href="#topic+dod">dod</a></code> and
<code><a href="#topic+dod_fit">dod_fit</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dodControl(grad.tol = 1e-4,
           integer.tol = 1e-8,
           get.vcov = TRUE,
           get.grad = TRUE,
           test.args = TRUE,
           do.warn=TRUE,
           optCtrl=list())


</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dodControl_+3A_grad.tol">grad.tol</code></td>
<td>
<p>tolerance for the maximum absolute gradient of the
parameters are convergence.</p>
</td></tr>
<tr><td><code id="dodControl_+3A_integer.tol">integer.tol</code></td>
<td>
<p>tolerance for when to give a warning about
non-integer counts in data.</p>
</td></tr>
<tr><td><code id="dodControl_+3A_get.vcov">get.vcov</code></td>
<td>
<p>compute the variance-covariance matrix of the
parameters (and the standard error of d-prime)?</p>
</td></tr>
<tr><td><code id="dodControl_+3A_get.grad">get.grad</code></td>
<td>
<p>compute the gradient of the parameters?</p>
</td></tr>
<tr><td><code id="dodControl_+3A_test.args">test.args</code></td>
<td>
<p>test admissibility of arguments to <code><a href="#topic+dod">dod</a></code>
and <code><a href="#topic+dod_fit">dod_fit</a></code>?</p>
</td></tr>
<tr><td><code id="dodControl_+3A_do.warn">do.warn</code></td>
<td>
<p>if <code>FALSE</code> warnings from the fitting process are
suppressed.</p>
</td></tr>
<tr><td><code id="dodControl_+3A_optctrl">optCtrl</code></td>
<td>
<p>control parameters passed on to the
<code><a href="stats.html#topic+nlminb">nlminb</a></code> optimizer.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An list of class <code>dodControl</code> with the appropriate control
settings for <code><a href="#topic+dod">dod</a></code> and <code><a href="#topic+dod_fit">dod_fit</a></code>.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

 <p><code><a href="#topic+dod">dod</a></code>, <code><a href="#topic+dod_fit">dod_fit</a></code>,
<code><a href="#topic+dodSim">dodSim</a></code>,
<code><a href="#topic+dodPwr">dodPwr</a></code>, <code><a href="#topic+optimal_tau">optimal_tau</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## DOD example data:
same.pairs &lt;- c(25, 22, 33, 20)
diff.pairs &lt;- c(18, 22, 30, 30)

## Fit Thurstonian dod-model and perform difference test:
dod(same=same.pairs, diff=diff.pairs)

## Display the fitting process using the trace argument to nlminb:
ctrl &lt;- dodControl(optCtrl=list(trace=TRUE))
dod(same=same.pairs, diff=diff.pairs, control=ctrl)


</code></pre>

<hr>
<h2 id='dodPwr'>Power of the Degree-of-Difference (DOD) method</h2><span id='topic+dodPwr'></span>

<h3>Description</h3>

<p>Computes the power of the Degree-of-Difference (DOD) method by
simulation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dodPwr(d.primeA, d.prime0=0, ncat = 4, sample.size, nsim = 1e3,
       alpha = 0.05,
       method.tau=c("LR.max", "equi.prob", "se.min", "user.defined"),
       statistic=c("likelihood", "Wilcoxon", "Pearson", "Wald"),
       alternative = c("difference", "similarity", "two.sided",
       "less", "greater"),
       tau=NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dodPwr_+3A_d.primea">d.primeA</code></td>
<td>
<p>the value of d-prime under the alternative hypothesis;
non-negative numerical scalar.</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_d.prime0">d.prime0</code></td>
<td>
<p>the value of d-prime under the null hypothesis.</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_ncat">ncat</code></td>
<td>
<p>the number of response categories in the DOD model</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_sample.size">sample.size</code></td>
<td>
<p>the sample size in each simulation for each of the
same-pairs and different pairs. Can be a single scalar value or a
2-vector.</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_nsim">nsim</code></td>
<td>
<p>the number of simulations.</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_alpha">alpha</code></td>
<td>
<p>the significance level.</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_method.tau">method.tau</code></td>
<td>
<p>the method with which to choose the boundary
parameters - see <code><a href="#topic+dodSim">dodSim</a></code> for details on the methods.</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_statistic">statistic</code></td>
<td>
<p>the statistic to be used for hypothesis testing.</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_alternative">alternative</code></td>
<td>
<p>the nature of the alternative hypothesis in the
hypothesis/significance test for d-prime. Note that
<code>"greater"</code> is an alias for <code>"difference"</code> and
<code>"less"</code> is an alias for <code>"similarity"</code>.</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_tau">tau</code></td>
<td>
<p>if <code>method.tau = "user.defined"</code> a vector of boundary
parameters in the DOD model, otherwise not used.</p>
</td></tr>
<tr><td><code id="dodPwr_+3A_...">...</code></td>
<td>
<p>parsed on to <code><a href="stats.html#topic+wilcox.test">wilcox.test</a></code> when appropriate.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The simulation based estimate of the power with the following
attributes:
</p>
<table role = "presentation">
<tr><td><code>se(power)</code></td>
<td>
<p>the estimated standard error of the estimated
power. This is based on the formula
<code>sqrt(pow * (1 - pow) / n)</code>, where <code>pow</code> is the estimated
power and <code>n</code> is the number of simulations used to estimate the
power.</p>
</td></tr>
<tr><td><code>n.used</code></td>
<td>
<p>the number of simulations used to estimate the
power. This is usually equal to nsim, but can sometimes be smaller
than nsim due to non-convergences to which the Wald test is
especially prone.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Ennis, J.M. and R.H.B. Christensen (2015) A Thurstonian comparison
of the tetrad and degree of difference tests.
<em>Food Quality and Preference</em>, 40, pp.263-269.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+dod">dod</a></code>, <code><a href="#topic+dod_fit">dod_fit</a></code>,
<code><a href="#topic+dodSim">dodSim</a></code>, <code><a href="#topic+optimal_tau">optimal_tau</a></code>,
<code><a href="#topic+dodControl">dodControl</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## NOTE: The number of simulations (nsim) is set unrealistically low in
## the examples below to reduce the computation time for automatic
## package checks. nsim between 1e3 and 1e4 is usually sufficient and
## the latter often on the safe side. The standard error of the
## estimated power ('se(power)') reported by dodPwr() measures the
## accuracy of the estimated power and indicates if nsim needs to be
## increased.

## Estimate power of the conventional difference test (no-difference
## under the null hypothesis):
set.seed(125)
dodPwr(d.primeA=1, d.prime0=0, ncat=4, sample.size=100, nsim=50,
       alpha=.05, method.tau="LR.max", statistic="likelihood")
##  [1] 0.62
##  attr(,"se(power)")
##  [1] 0.1825346
##  attr(,"n.used")
##  [1] 50
## Here the boundary parameters are chosen automatically so as to
## maximize the likelihood ratio test statistic, and so this setting
## amounts to a highest achievable power scenario given d-prime = 1.

## Using another (and faster) statistic:
dodPwr(d.primeA=1, d.prime0=0, ncat=4, sample.size=100, nsim=1e3,
       alpha=.05, method.tau="LR.max", statistic="Wilcox")


## Not automatically run to reduce computation time.

## Power of a similarity test:
set.seed(127)
dodPwr(d.primeA=0, d.prime0=1, ncat=4, sample.size=100, nsim=1e2,
       alpha=.05, method.tau="LR.max", statistic="Pearson",
       alternative="similarity")
##  [1] 0.71
##  attr(,"se(power)")
##  [1] 0.1434922
##  attr(,"n.used")
##  [1] 100

## Same as above, but with a given set of boundary parameters:
dodPwr(d.primeA=0, d.prime0=1, sample.size=100, nsim=1e2,
       alpha=.05, method.tau="user.defined", statistic="Pearson",
       alternative="similarity", tau=1:3)

## Using parallel computing to speed up computations:
if(require(parallel)) {
    ## Use detectCores() to get an appropriate number of cores for
    ## practical use - for the example here we fix it at 2:
    ## cl &lt;- makeCluster(detectCores())
    cl &lt;- makeCluster(getOption("cl.cores", 2))
    dvec &lt;- c(0, .2, .5, .7, 1, 1.2, 1.5, 1.75)
    system.time(
        res &lt;- parLapply(cl, dvec, fun=function(dp) {
            library(sensR)
            x &lt;- dodPwr(dp, 0, sample.size=100, nsim=1e4, stat="Wil")
            c("power"=x, "se"=attr(x, "se(power)"))
        })
        )
    stopCluster(cl)
    names(res) &lt;- dvec
    mat &lt;- do.call(cbind, res)
    round(mat[1:2, ], 3)
    ## Example output:
    ##            0   0.2   0.5   0.7     1   1.5  1.75     2
    ##  power 0.051 0.058 0.123 0.238 0.578 0.983 1.000 1.000
    ##  se    0.022 0.023 0.033 0.043 0.049 0.013 0.002 0.001
}

## Realistically one should use more simulations, e.g. nsim=1e4.


</code></pre>

<hr>
<h2 id='dodSim'>Simulate data from the Degree-of-Difference model</h2><span id='topic+dodSim'></span>

<h3>Description</h3>

<p>Simulate data from the Degree-of-Difference model for a given value of
d-prime. The boundary parameters can either be specified by the user,
or be chosen automatically so as to 1) maximize the likelihood ratio
statistic, 2) ensure responses in each category is equally probable
across same-pairs and different-pairs or 3) minimize the standard error of
d-prime.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
dodSim(d.prime, ncat=4, sample.size = c(100, 100),
       method.tau = c("equi.prob", "LR.max", "se.min", "user.defined"),
       tau = NULL, d.prime0 = 0, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dodSim_+3A_d.prime">d.prime</code></td>
<td>
<p>the value of d-prime.</p>
</td></tr>
<tr><td><code id="dodSim_+3A_ncat">ncat</code></td>
<td>
<p>the number of response categories.</p>
</td></tr>
<tr><td><code id="dodSim_+3A_sample.size">sample.size</code></td>
<td>
<p>the sample size for same-pairs and
different-pairs. The sample size can be a scalar number in which
case the sample sizes for both same-pairs and different-pairs are taken to
equal that number.</p>
</td></tr>
<tr><td><code id="dodSim_+3A_method.tau">method.tau</code></td>
<td>
<p>the method with which to choose the boundary
parameters. If <code>"user.defined"</code>, the user has to specify the
<code>tau</code> argument, otherwise the set of boundary parameters are
chosen automatically (see the Details section below).</p>
</td></tr>
<tr><td><code id="dodSim_+3A_tau">tau</code></td>
<td>
<p>if <code>method.tau = "user.defined"</code> the set of boundary
parameters, otherwise not used.</p>
</td></tr>
<tr><td><code id="dodSim_+3A_d.prime0">d.prime0</code></td>
<td>
<p>if <code>method.tau = "LR.max"</code> the value of d-prime
under the null hypothesis, otherwise not used.</p>
</td></tr>
<tr><td><code id="dodSim_+3A_...">...</code></td>
<td>
<p>passed on to <code><a href="#topic+optimal_tau">optimal_tau</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In principle both d-prime and all boundary parameters have to be
specified in order to be able to simulate from the DOD model.
However, since it
can be difficult to decide which boundary parameters to use for
simulation, <code>dodSim</code> offers ways to choose these parameters
automatically according to the following three criteria:
</p>

<dl>
<dt>equi.prob</dt><dd><p>the boundary parameters are chosen such that
responses in each category are equally probable across same-pairs
and different-pairs.</p>
</dd>
<dt>LR.max</dt><dd><p>the boundary parameters are chosen such that the
likelihood ratio statistic for the test of d-prime is
maximized. This choice maximizes the power of the likelihood ratio
test and is in a sense an optimal choice of boundary parameters.</p>
</dd>
<dt>se.min</dt><dd><p>the boundary parameters are chosen such that the
standard error of d-prime is minimized. This method also maximizes
the power of the Wald test of d-prime when the null hypothesis is
no-difference (d-prime = 0). This method can be numerical unstable
for small and large d-prime values (approximately d.prime &lt; 0.5 and
d.prime &gt; 5).</p>
</dd>
</dl>

<p>Experience shows that the asymptotic properties of the DOD model are
not too sensitive to the choice of boundary parameters: power,
standard error of d-prime and confidence intervals seem to be fairly
constant irrespectively which of the above three criteria are used to
choose the boundary parameters.
</p>


<h3>Value</h3>

<p>A 2-by-<code>ncat</code> matrix of counts with same-pairs in the first
row and different-pairs in the second row. First/last column
corresponds to &quot;same&quot;/&quot;different&quot; on the response scale.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

 <p><code><a href="#topic+dod">dod</a></code>, <code><a href="#topic+dod_fit">dod_fit</a></code>,
<code><a href="#topic+dodControl">dodControl</a></code>, <code><a href="#topic+optimal_tau">optimal_tau</a></code>,
<code><a href="#topic+dodPwr">dodPwr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Simulate data from the DOD model with the equi.prob method:
set.seed(125)
(Data &lt;- dodSim(d.prime=1, sample.size=100, method.tau="equi.prob"))

## Simulate data that maximizes the likelihood ratio statistic:
set.seed(125)
dodSim(d.prime=1, sample.size=100, method.tau="LR.max")

## Simulate with user-defined values for the boundary parameters:
dodSim(d.prime=1.5, sample.size=c(100, 100),
       method.tau="user.defined", tau=1:4)

## Simulate using different sample sizes for same-pairs and
## different-pairs:
dodSim(d.prime=1, ncat=3, sample.size=c(75, 125),
       method.tau="se.min")


</code></pre>

<hr>
<h2 id='dprime_compare'>
Test the 'any-differences' hypothesis and estimate common d-prime
</h2><span id='topic+dprime_compare'></span>

<h3>Description</h3>

<p>This function will test the 'any-differences' hypothesis (conceptually
a one-way ANOVA test for d-primes) with one of the Wald, Pearson or
likelihood ratio chi-square test statistics. The common d-prime is
estimated with ML or weighted average.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dprime_compare(correct, total, protocol, conf.level = 0.95,
   statistic = c("likelihood", "Pearson", "Wald.p", "Wald.d"),
   estim = c("ML", "weighted.avg"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dprime_compare_+3A_correct">correct</code></td>
<td>

<p>a numeric vector of the number of correct answers; one element for
each test.
</p>
</td></tr>
<tr><td><code id="dprime_compare_+3A_total">total</code></td>
<td>

<p>a numeric vector of the total number of trials; one element for each
test.
</p>
</td></tr>
<tr><td><code id="dprime_compare_+3A_protocol">protocol</code></td>
<td>

<p>a character vector or factor naming the protocol used; one element
for each test. Currently the following protocols are supported:
<code>"triangle", "duotrio", "threeAFC", "twoAFC", "tetrad"</code>.
</p>
</td></tr>
<tr><td><code id="dprime_compare_+3A_conf.level">conf.level</code></td>
<td>

<p>the confidence level for the estimated common d-prime.
</p>
</td></tr>
<tr><td><code id="dprime_compare_+3A_statistic">statistic</code></td>
<td>

<p>the test statistic for testing the 'any-differences' hypothesis.
</p>
</td></tr>
<tr><td><code id="dprime_compare_+3A_estim">estim</code></td>
<td>

<p>The estimation method for the common d-prime.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vectors <code>correct</code>, <code>total</code> and <code>protocol</code> have to
be of the same length.
</p>
<p>The function has a print method.
</p>


<h3>Value</h3>

<p>an object of class <code>"dprime_compare"</code> with the following elements
</p>
<table role = "presentation">
<tr><td><code>stat.value</code></td>
<td>

<p>the value of the (chi-square) test statistic for the
'any-differences' hypothesis.
</p>
</td></tr>
<tr><td><code>df</code></td>
<td>

<p>the degrees of freedom for the <code>stat.value</code> test statistic.
</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>

<p>the p-value for the 'any-differences' test.
</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>

<p>the name of the test statistic for the 'any-differences' test.
</p>
</td></tr>
<tr><td><code>data</code></td>
<td>

<p>the data table produced by <code><a href="#topic+dprime_table">dprime_table</a></code>.
</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>

<p>'table' with estimated common d-prime, standard error and confidence
limits storred as a one-row <code><a href="base.html#topic+data.frame">data.frame</a></code>.
</p>
</td></tr>
<tr><td><code>conf.level</code></td>
<td>

<p>confidence level for the common d-prime.
</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>

<p>the confidence interval for the common d-prime.
</p>
</td></tr>
<tr><td><code>estim</code></td>
<td>

<p>the estimation method for the common d-prime.
</p>
</td></tr>
<tr><td><code>conf.method</code></td>
<td>

<p>the statistical method/test statistic used to compute the confidence
interval for the common d-prime.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dprime_test">dprime_test</a></code>, <code><a href="#topic+dprime_table">dprime_table</a></code>,
<code><a href="#topic+posthoc.dprime_compare">posthoc.dprime_compare</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Make some fake data:
n &lt;- rep(40, 4)
x &lt;- c(25, 25, 30, 35)
protocol &lt;- c("triangle", "duotrio", "threeAFC", "twoAFC")
## Look at the data table with d-primes etc.:
dprime_table(x, n, protocol)

## 'any differences' test:
## ML estimation and test with likelihood statistic:
(dpc &lt;- dprime_compare(x, n, protocol))
## Other estimation/statistic options:
dprime_compare(x, n, protocol, estim="weighted.avg")
dprime_compare(x, n, protocol, statistic="Pearson")
dprime_compare(x, n, protocol, statistic="Wald.p")
dprime_compare(x, n, protocol, statistic="Wald.d")

</code></pre>

<hr>
<h2 id='dprime_table'>
Summary table of several discrimination experiments using the
simple-binomial protocols (Duo-Trio, Triangle, Tetrad, 2-AFC and 3-AFC)
</h2><span id='topic+dprime_table'></span>

<h3>Description</h3>

<p>This function provides a summary table with the following quantities:
no. correct trials (<code>correct</code>), total number of trials
(<code>total</code>), the
protocol (<code>protocol</code>), probability of a correct answer
(<code>pHat</code>), standard
error of pHat (<code>se.pHat</code>), d-prime (<code>dprime</code>), and standard
error of d-prime (<code>se.dprime</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dprime_table(correct, total, protocol, restrict.above.guess = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dprime_table_+3A_correct">correct</code></td>
<td>

<p>a numeric vector of the number of correct answers; one element for
each test.
</p>
</td></tr>
<tr><td><code id="dprime_table_+3A_total">total</code></td>
<td>

<p>a numeric vector of the total number of trials; one element for each
test.
</p>
</td></tr>
<tr><td><code id="dprime_table_+3A_protocol">protocol</code></td>
<td>

<p>a character vector or factor naming the protocol used; one element
for each test. Currently the following protocols are supported:
<code>"triangle", "duotrio", "threeAFC", "twoAFC", "tetrad"</code>.
</p>
</td></tr>
<tr><td><code id="dprime_table_+3A_restrict.above.guess">restrict.above.guess</code></td>
<td>

<p>controls if <code>pHat</code> should be restricted at or
above the guessing probability for the given protocol. This also
affects <code>se.pHat</code>. Note that <code>dprime</code> is zero and
<code>se.dprime</code> is <code>NA</code> when
<code>pHat</code> is at or below the guessing probability of the given
protocol.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vectors <code>correct</code>, <code>total</code> and <code>protocol</code> have to
be of the same length.
</p>


<h3>Value</h3>

<p>a data.frame with columns:
</p>
<table role = "presentation">
<tr><td><code>correct</code></td>
<td>

<p>numeric vector of no. correct.
</p>
</td></tr>
<tr><td><code>total</code></td>
<td>

<p>numeric vector of no. trials.
</p>
</td></tr>
<tr><td><code>protocol</code></td>
<td>

<p>character vector naming the protocols used.
</p>
</td></tr>
<tr><td><code>pHat</code></td>
<td>

<p>Estimate of the probability of correct answers.
</p>
</td></tr>
<tr><td><code>se.pHat</code></td>
<td>

<p>standard error of <code>pHat</code>.
</p>
</td></tr>
<tr><td><code>dprime</code></td>
<td>

<p>estimate of d-prime.
</p>
</td></tr>
<tr><td><code>se.dprime</code></td>
<td>

<p>standard error of <code>dprime</code>.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dprime_compare">dprime_compare</a></code>, <code><a href="#topic+dprime_test">dprime_test</a></code>,
<code><a href="#topic+posthoc.dprime_compare">posthoc.dprime_compare</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- rep(40, 4)
x &lt;- c(25, 25, 30, 35)
protocol &lt;- c("triangle", "duotrio", "threeAFC", "twoAFC")
dprime_table(x, n, protocol)

</code></pre>

<hr>
<h2 id='dprime_test'>
Test of simple hypothesis with the common d-prime
</h2><span id='topic+dprime_test'></span>

<h3>Description</h3>

<p>This function tests the hypothesis that the common d-prime is equal to
or greater/less than a certain value, e.g. zero in a Wald or
likelihood root test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dprime_test(correct, total, protocol, conf.level = 0.95, dprime0 = 0,
    statistic = c("likelihood", "Wald"),
    alternative = c("difference", "similarity", "two.sided", "less", "greater"),
    estim = c("ML", "weighted.avg"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dprime_test_+3A_correct">correct</code></td>
<td>

<p>a numeric vector of the number of correct answers; one element for
each test.
</p>
</td></tr>
<tr><td><code id="dprime_test_+3A_total">total</code></td>
<td>

<p>a numeric vector of the total number of trials; one element for each
test.
</p>
</td></tr>
<tr><td><code id="dprime_test_+3A_protocol">protocol</code></td>
<td>

<p>a character vector or factor naming the protocol used; one element
for each test. Currently the following protocols are supported:
<code>"triangle", "duotrio", "threeAFC", "twoAFC", "tetrad"</code>.
</p>
</td></tr>
<tr><td><code id="dprime_test_+3A_conf.level">conf.level</code></td>
<td>

<p>the confidence level for the confidence interval of the estimated
common d-prime.
</p>
</td></tr>
<tr><td><code id="dprime_test_+3A_dprime0">dprime0</code></td>
<td>

<p>Value of d-prime under the Null hypothesis. Non-negative numeric
scalar.
</p>
</td></tr>
<tr><td><code id="dprime_test_+3A_statistic">statistic</code></td>
<td>

<p>the test statistic for computing the confidence interval as well as
p-value.
</p>
</td></tr>
<tr><td><code id="dprime_test_+3A_alternative">alternative</code></td>
<td>

<p>the direction of the hypothesis test. <code>"difference"</code> and
<code>"similarity"</code> are just alternative ways of specifying
<code>"greater"</code> and <code>"less"</code> respectively.
</p>
</td></tr>
<tr><td><code id="dprime_test_+3A_estim">estim</code></td>
<td>

<p>The estimation method for the common d-prime.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The vectors <code>correct</code>, <code>total</code> and <code>protocol</code> have to
be of the same length.
</p>
<p>The function has a print method.
</p>


<h3>Value</h3>

<p>an object of class <code>"dprime_test"</code> with the following elements







</p>
<table role = "presentation">
<tr><td><code>p.value</code></td>
<td>

<p>the p-value for the 'any-differences' test.
</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>

<p>character naming the direction of the hypothesis test.
</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>

<p>the name of the test statistic.
</p>
</td></tr>
<tr><td><code>data</code></td>
<td>

<p>the data table produced by <code><a href="#topic+dprime_table">dprime_table</a></code>.
</p>
</td></tr>
<tr><td><code>conf.level</code></td>
<td>

<p>confidence level for the common d-prime.
</p>
</td></tr>
<tr><td><code>conf.int</code></td>
<td>

<p>the confidence interval for the common d-prime.
</p>
</td></tr>
<tr><td><code>estim</code></td>
<td>

<p>the estimation method for the common d-prime.
</p>
</td></tr>
<tr><td><code>conf.method</code></td>
<td>

<p>the statistical method/test statistic used to compute the confidence
interval for the common d-prime.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dprime_compare">dprime_compare</a></code>, <code><a href="#topic+dprime_table">dprime_table</a></code>,
<code><a href="#topic+posthoc.dprime_compare">posthoc.dprime_compare</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
n &lt;- rep(40, 4)
x &lt;- c(25, 25, 30, 35)
protocol &lt;- c("triangle", "duotrio", "threeAFC", "twoAFC")
## Look at the data table with d-primes etc.:
dprime_table(x, n, protocol)

## Test of common d':
dprime_test(x, n, protocol)

## Another setting:
dprime_test(x, n, protocol, dprime0=2, statistic="Wald",
            alternative="less", estim="weighted.avg")

</code></pre>

<hr>
<h2 id='duotrio'>Create duotrio binomial family</h2><span id='topic+duotrio'></span>

<h3>Description</h3>

<p>Creates af copy of the binomial family with the inverse link function changed to equal
the duotrio psychometric function and correspondingly changed link function and derivative of the
inverse link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>duotrio()
</code></pre>


<h3>Value</h3>

<p>A binomial family object for models. Among other things it inludes the psychometric function as
<code>linkinv</code> and the inverse psychometric function (for direct dprime computation) as
<code>linkfun</code>
</p>


<h3>Note</h3>

<p>Several functions in this package makes use of the function, but it
may also be used on its own&mdash;see the example below.
</p>


<h3>Author(s)</h3>

<p>Per Bruun Brockhoff</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen, R.H.B. (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.</p>


<h3>See Also</h3>

<p><code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+tetrad">tetrad</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Estimating d-prime using glm for a Duotrio test:
xt &lt;- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
res &lt;- glm(xt ~ 1, family = duotrio)
summary(res)
## Equivalent to (Estimate and Std. Error):
discrim(10, 15, method="duotrio")


## Extended example plotting the profile likelihood
## data: 10 correct answers, 5 incorrect
xt &lt;- matrix(c(10, 5), ncol = 2)
summary(res &lt;- glm(xt ~ 1, family = duotrio))
N &lt;- 100
dev &lt;- double(N)
delta &lt;- seq(1e-4, 5, length = N)
for(i in 1:N)
  dev[i] &lt;- glm(xt ~ -1 + offset(delta[i]),
                family = duotrio)$deviance
plot(delta, exp(-dev/2), type = "l",
     xlab = expression(delta),
     ylab = "Normalized Profile Likelihood")
## Add Normal approximation:
lines(delta, exp(-(delta - coef(res))^2 /
                 (2 * vcov(res))), lty = 2)
## Add confidence limits:
level &lt;- c(0.95, 0.99)
lim &lt;- sapply(level, function(x)
              exp(-qchisq(x, df=1)/2) )
abline(h = lim, col = "grey")
points(confint(res), rep(lim[1], 2), pch = 4)

</code></pre>

<hr>
<h2 id='findcr'>Find the critical value of a one-tailed binomial test</h2><span id='topic+findcr'></span>

<h3>Description</h3>

<p>Finds the critical value in a one-tailed binomial test</p>


<h3>Usage</h3>

<pre><code class='language-R'>findcr(sample.size, alpha = .05, p0 = .5, pd0 = 0,
              test = c("difference", "similarity"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="findcr_+3A_sample.size">sample.size</code></td>
<td>
<p>the sample size of the binomial test (must be a positve integer)</p>
</td></tr>
<tr><td><code id="findcr_+3A_alpha">alpha</code></td>
<td>
<p>the test I error-level of the test (must be between zero and one)</p>
</td></tr>
<tr><td><code id="findcr_+3A_p0">p0</code></td>
<td>
<p>the guessing probability under the null-hypothesis (must be
between zero and one); 1/2 for the duotrio and twoAFC tests and 1/3
for the triangle, tetrad and threeAFC tests</p>
</td></tr>
<tr><td><code id="findcr_+3A_pd0">pd0</code></td>
<td>
<p>the proportion of discriminators in the population of interest</p>
</td></tr>
<tr><td><code id="findcr_+3A_test">test</code></td>
<td>
<p>the type of test</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The critical value of the standard one-tailed difference test of &quot;no
difference&quot; is obtained with <code>pd0 = 0</code>.
</p>
<p>The probability of a correct answer under the null hypothesis is
given by <code>pd0 + p0 * (1 - pd0)</code>.
</p>


<h3>Value</h3>

<p>The critical value in a one-tailed binomial test, that is, the smallest
integer such that the null hypothesis binomial probability of being
larger (smaller for similarity hypotheses) than or equal to this number
is smaller than or equal to the type I error-level of the test.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen and Per Bruun Brockhoff</p>


<h3>See Also</h3>

<p><code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+duotrio">duotrio</a></code>, <code><a href="#topic+tetrad">tetrad</a></code>,
<code><a href="#topic+discrim">discrim</a></code>, <code><a href="#topic+discrimPwr">discrimPwr</a></code>,
<code><a href="#topic+discrimSim">discrimSim</a></code>, <code><a href="#topic+AnotA">AnotA</a></code>
<code><a href="#topic+discrimSS">discrimSS</a></code>, <code><a href="#topic+samediff">samediff</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Find the critical value for a triangle test for the level 0.05 test
## with 25 subjects:
findcr(sample.size = 25, , p0 = 1/3)

## Similarity example:
findcr(sample.size = 25, p0 = 1/3, pd0 = .2, test = "simil")
</code></pre>

<hr>
<h2 id='hexad'>Create hexad binomial family</h2><span id='topic+hexad'></span>

<h3>Description</h3>

<p>Creates af binomial family object with the inverse link function
equal to the psychometric function for the unspecified Hexad test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
hexad()

</code></pre>


<h3>Value</h3>

<p>A binomial family object for models. Among other things it inludes the
psychometric function as
<code>linkinv</code> and the inverse psychometric function (for direct
d-prime computation) as
<code>linkfun</code>.
</p>


<h3>Note</h3>

<p>Several functions in this package makes use of functions in the hexad
family object, but it may also be used on its own&mdash;see the example
below.
</p>


<h3>Author(s)</h3>

<p>Karolina Stachlewska</p>


<h3>References</h3>

<p>Eberhardt, K., Aubry, V., &amp; Robinson, K. (2008).
A thurstonian model for the unspecified hexad test.
In 2008 Sensometrics Meeting 'Discover a New World of Data' (E-5).
Kraft Foods.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+duotrio">duotrio</a></code>, <code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+tetrad">tetrad</a></code>, <code><a href="#topic+twofive">twofive</a></code>,
<code><a href="#topic+twofiveF">twofiveF</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Estimating d-prime using glm for an unspecified Hexad test:
xt &lt;- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
res &lt;- glm(xt ~ 1, family = hexad)
summary(res)
## Equivalent to (Estimate and Std. Error):
discrim(10, 15, method="hexad")


## Extended example plotting the profile likelihood
## data: 10 correct answers, 9 incorrect
xt &lt;- matrix(c(10, 9), ncol = 2)
summary(res &lt;- glm(xt ~ 1, family = hexad))
N &lt;- 100
dev &lt;- double(N)
delta &lt;- seq(1e-4, 3, length = N)
for(i in 1:N)
  dev[i] &lt;- glm(xt ~ -1 + offset(delta[i]),
                family = hexad)$deviance
plot(delta, exp(-dev/2), type = "l",
     xlab = expression(delta),
     ylab = "Normalized Profile Likelihood")
## Add Normal approximation:
lines(delta, exp(-(delta - coef(res))^2 /
                 (2 * vcov(res))), lty = 2)
## Add confidence limits:
level &lt;- c(0.95, 0.99)
lim &lt;- sapply(level, function(x) exp(-qchisq(x, df=1)/2) )
abline(h = lim, col = "grey")

</code></pre>

<hr>
<h2 id='plot.discrim'> Plot function for discrim objects</h2><span id='topic+plot.discrim'></span>

<h3>Description</h3>

<p>This function plots the latent distributions of sensory intensity
corresponding to the items or products tested in the discrimination
test.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'discrim'
plot(x, main = TRUE, length = 1000, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.discrim_+3A_x">x</code></td>
<td>
<p>The <code>discrim</code> object whose latent distributions are to
be plotted</p>
</td></tr>
<tr><td><code id="plot.discrim_+3A_main">main</code></td>
<td>
<p>include an automatically generated title on the plot?
Default is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="plot.discrim_+3A_length">length</code></td>
<td>
<p>the length of the vectors to be plotted. Longer vectors
gives more smooth curves.</p>
</td></tr>
<tr><td><code id="plot.discrim_+3A_...">...</code></td>
<td>
<p>additional arguments to <code>plot</code> and <code>lines</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function produces a plot and does not return any value.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate discrim objects to be plotted:
fm1 &lt;- discrim(10, 15, method = "threeAFC")
fm2 &lt;- discrim(10, 15, method = "triangle")
old &lt;- par(mfrow=c(2,1)) ## Split plotting window in two
## Plot the distributions of sensory intensity for the two objects
## and increase the line width
plot(fm1, lwd=2) 
plot(fm2, lwd=2)
par(old)
</code></pre>

<hr>
<h2 id='plot.samediff'> Plot function for samediff objects</h2><span id='topic+plot.samediff'></span>

<h3>Description</h3>

<p>This function plots the latent distributions of sensory intensity
corresponding to the items or products tested in the discrimination
test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'samediff'
plot(x, main = TRUE, length = 1000,
           limits, fig = TRUE, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.samediff_+3A_x">x</code></td>
<td>
<p>The <code>samediff</code> object whose latent distributions are to
be plotted</p>
</td></tr>
<tr><td><code id="plot.samediff_+3A_main">main</code></td>
<td>
<p>include an automatically generated title on the plot?
Default is <code>TRUE</code></p>
</td></tr>
<tr><td><code id="plot.samediff_+3A_length">length</code></td>
<td>
<p>the length of the vectors to be plotted. Longer vectors
gives more smooth curves, but can take a little time.</p>
</td></tr>
<tr><td><code id="plot.samediff_+3A_limits">limits</code></td>
<td>
<p>optional limits on the x-axis; vector of length two.</p>
</td></tr>
<tr><td><code id="plot.samediff_+3A_fig">fig</code></td>
<td>
<p>logical: Should the function create the plot? Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.samediff_+3A_...">...</code></td>
<td>
<p>additional arguments to <code>plot</code> and <code>lines</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>fig = TRUE</code>, the function will produce the plot. The function
invisibly returns a data.frame with elements
</p>
<table role = "presentation">
<tr><td><code>z</code></td>
<td>
<p>values for the x-axis of lenght <code>length</code>.</p>
</td></tr>
<tr><td><code>base.dist</code></td>
<td>
<p>y-values for the base distribution of same-samples,
ie. a standard normal distribution</p>
</td></tr>
<tr><td><code>delta.dist</code></td>
<td>
<p>y-values for the distribution of different-samples,
ie. a normal distribution centred at <code>delta</code> with unit
variance.</p>
</td></tr>
</table>
<p>This facilitates later plotting and changing the appearance of the
plot. 
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Make same-diff object:
sadi &lt;- samediff(8, 5, 4, 9)
## Plot distributions of sensory intensity:
plot(sadi)
</code></pre>

<hr>
<h2 id='posthoc'>
Post-hoc estimates and tests for multiple discrimination experiments.
</h2><span id='topic+posthoc'></span><span id='topic+posthoc.dprime_compare'></span><span id='topic+posthoc.dprime_test'></span>

<h3>Description</h3>

<p>This function provides estimates and p-values for post-hoc tests such
as pairwise comparisons. p-values are (by default) adjusted for multiplicity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
posthoc(x, ...)

## S3 method for class 'dprime_compare'
posthoc(x, alpha = 0.05,
    test = c("pairwise", "common", "base", "zero"), base = 1,
    alternative = c("two.sided", "less", "greater"),
    statistic = c("likelihood", "Wald"),
    padj.method = c("holm", "bonferroni", "none"), ...)

## S3 method for class 'dprime_test'
posthoc(x, alpha = 0.05,
    test = c("pairwise", "common", "base", "zero"), base = 1,
    alternative = c("two.sided", "less", "greater"),
    statistic = c("likelihood", "Wald"),
    padj.method = c("holm", "bonferroni", "none"), ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="posthoc_+3A_x">x</code></td>
<td>

<p>an object of class <code><a href="#topic+dprime_compare">dprime_compare</a></code> or
<code><a href="#topic+dprime_test">dprime_test</a></code>.
</p>
</td></tr>
<tr><td><code id="posthoc_+3A_alpha">alpha</code></td>
<td>

<p>the significance level for tests and confidence intervals.
</p>
</td></tr>
<tr><td><code id="posthoc_+3A_test">test</code></td>
<td>

<p>the type of post-hoc tests performed. Se the details section for
further details.
</p>
</td></tr>
<tr><td><code id="posthoc_+3A_base">base</code></td>
<td>

<p>when <code>test = "base"</code>, the experiment against which to provide
pairwise comparisons.
</p>
</td></tr>
<tr><td><code id="posthoc_+3A_alternative">alternative</code></td>
<td>

<p>direction of the hypothesis test.
</p>
</td></tr>
<tr><td><code id="posthoc_+3A_statistic">statistic</code></td>
<td>

<p>The test statistic used - currently there is only partial support
for <code>statistic = "likelihood"</code>.
</p>
</td></tr>
<tr><td><code id="posthoc_+3A_padj.method">padj.method</code></td>
<td>

<p>controls the method by which p-values are adjusted for
multiplicity. Any one of the values in <code>p.adjust.methods</code>
(currently &quot;holm&quot; &quot;hochberg&quot;
&quot;hommel&quot; &quot;bonferroni&quot; &quot;BH&quot; &quot;BY&quot; &quot;fdr&quot; &quot;none&quot;) may be specified,
cf. <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>.
</p>
</td></tr>
<tr><td><code id="posthoc_+3A_...">...</code></td>
<td>

<p>currently not used.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>test</code> argument specifies the type of test
performed. <code>"pairwise"</code> performs all pairwise comparisons and
produces a compact letter display indicating groups of experiments
that different/not-different. <code>"common"</code> tests, for each
experiment in turn, if the by-experiment d-prime is different from
a common d-prime computed from the remaining
experiments. <code>"base"</code> provides pairwise comparisons to a
single experiment indicated by the separate argument <code>base</code>. If
<code>test = "zero"</code> all d-primes are tested versus zero. As a final
option a numeric value can be supplied, e.g. <code>test = 1</code> in
which case all d-primes are tested versus one. Note that
<code>test = 0</code> gives the same test as <code>test = "zero"</code>.
</p>
<p>When <code>test = "pairwise"</code> a compact letter display is provided and
it is determined from the p-values <em>after</em> adjustment of these for
multiplicity.
</p>
<p>The <code>dprime_compare</code> and <code>dprime_test</code> methods a have
(common) print method.
</p>


<h3>Value</h3>

<p>an object of class <code>c(paste0("posthoc.", class(x)), class(x))</code>
with the following elements from the original object, <code>x</code> and :
</p>
<table role = "presentation">
<tr><td><code>posthoc</code></td>
<td>

<p>coefficient table for the post-hoc tests.
</p>
</td></tr>
<tr><td><code>test</code></td>
<td>

<p>the value of the <code>test</code> argument.
</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>

<p>the value of the <code>alternative</code> argument.
</p>
</td></tr>
<tr><td><code>padj.method</code></td>
<td>

<p>the method used to adjust p-values with.
</p>
</td></tr>
<tr><td><code>base</code></td>
<td>

<p>the value of the <code>base</code> argument.
</p>
</td></tr>
<tr><td><code>posthoc.stat</code></td>
<td>

<p>name of the statistic for the post-hoc tests.
</p>
</td></tr>
<tr><td><code>Letters</code></td>
<td>

<p>if <code>test = "pairwise"</code> the compact letter display, otherwise
<code>NULL</code>.
</p>
</td></tr>
<tr><td><code>dprime0</code></td>
<td>

<p>unless <code>test = "pairwise"</code> or <code>"common"</code> the value of
d-prime under the null hypothesis.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dprime_test">dprime_test</a></code>, <code><a href="#topic+dprime_table">dprime_table</a></code>,
<code><a href="#topic+dprime_compare">dprime_compare</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Make some fake data:
n &lt;- rep(40, 4)
x &lt;- c(25, 25, 30, 35)
protocol &lt;- c("triangle", "duotrio", "threeAFC", "twoAFC")
## Look at the data table with d-primes etc.:
dprime_table(x, n, protocol)

## 'any differences' test:
## ML estimation and test with likelihood statistic:
(dpc &lt;- dprime_compare(x, n, protocol))

posthoc(dpc, alpha=.1) ## test="pairwise"

## Test if each d' is different from the common d' estimated from the
## remaining experiments:
posthoc(dpc, test="common")

## Test if d' from experiment 2 is different from the others (with
## adjustment for multiplicity):
posthoc(dpc, test="base", base=2)

## Test if each d' is different from 2 (with Bonferroni adjustment for
## multiplicity) using the Wald statistic:
posthoc(dpc, test=2, stat="Wald", padj.method="bonferroni")

</code></pre>

<hr>
<h2 id='profile.discrim'>Profile likelihood and confidence interval methods for discrim
objects</h2><span id='topic+profile.discrim'></span><span id='topic+plot.profile.discrim'></span><span id='topic+confint.discrim'></span>

<h3>Description</h3>

<p>Computes the (normalized or relative) profile likelihood for the
parameters of a discrimination test, plots the normalized profile
likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'discrim'
profile(fitted, ...)

## S3 method for class 'profile.discrim'
plot(x, level = c(0.99, 0.95), fig = TRUE,
            method = "natural", n = 1e3, ...)

## S3 method for class 'discrim'
confint(object, parm, level = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="profile.discrim_+3A_fitted">fitted</code></td>
<td>
<p>a <code>discrim</code> object</p>
</td></tr>
<tr><td><code id="profile.discrim_+3A_x">x</code></td>
<td>
<p>a <code>profile.discrim</code> object</p>
</td></tr>
<tr><td><code id="profile.discrim_+3A_object">object</code></td>
<td>
<p>a <code>discrim</code> object</p>
</td></tr>
<tr><td><code id="profile.discrim_+3A_parm">parm</code></td>
<td>
<p>currently not used</p>
</td></tr>
<tr><td><code id="profile.discrim_+3A_method">method</code></td>
<td>
<p>the type of spline to be used in approximating the
profile likelhood curve (trace)&mdash;se <code><a href="stats.html#topic+spline">spline</a></code> for
details</p>
</td></tr>
<tr><td><code id="profile.discrim_+3A_n">n</code></td>
<td>
<p>the number of spline interpolations to use in plotting the
profile likelihood curve (trace)</p>
</td></tr>
<tr><td><code id="profile.discrim_+3A_level">level</code></td>
<td>
<p>for <code>plot</code>: At which levels to include horizontal lines to indicate
confidence levels in plots of the normalized profile
likelihoods. For <code>confint</code>: at which level to compute the
confidence interval</p>
</td></tr>
<tr><td><code id="profile.discrim_+3A_fig">fig</code></td>
<td>
<p>logical: should the normalized profile likelihoods be plotted?</p>
</td></tr>
<tr><td><code id="profile.discrim_+3A_...">...</code></td>
<td>
<p>For <code>plot</code>: additional arguments to
<code>plot</code>. Otherwise not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>confint</code> returns the confidence interval computed in
<code><a href="#topic+discrim">discrim</a></code> possibly at another level. The statistic used to
compute the confidence interval is therefore determined in the
<code><a href="#topic+discrim">discrim</a></code> call and may not be the likelihood root.
</p>
<p>The likelihood profile is extracted from the <code><a href="#topic+discrim">discrim</a></code>
object fitted with <code>statistic = "likelihood"</code>.
</p>


<h3>Value</h3>

<p>For <code>profile</code>:
An object of class <code>"profile.discrim", "data.frame"</code>&mdash;a
<code>data.frame</code> with two columns giving
the value of the parameter and the corresponding value of the profile
likelihood.
</p>
<p>For <code>plot</code>:
The profile object is returned invisibly.
</p>
<p>For <code>confint</code>:
</p>
<p>A 3x2 matrix with columns named <code>"lower", "upper"</code> giving the
lower and upper (100 * <code>level</code>)% confidence interval for the
parameters named in the rows.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen and Per Bruun Brockhoff</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen R.H.B. (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.</p>


<h3>See Also</h3>

<p><code><a href="#topic+discrim">discrim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 7 success out of 10 samples in a duo-trio experiment:
(dd &lt;- discrim(7, 10, method = "duotrio", statistic = "likelihood"))
confint(dd)
plot(profile(dd))
points(confint(dd)[3,], rep(.1465, 2), pch = 3, cex = 2, lwd=2)

</code></pre>

<hr>
<h2 id='profile.samediff'>Profile likelihood methods for samediff objects.</h2><span id='topic+profile.samediff'></span><span id='topic+plot.profile.samediff'></span><span id='topic+confint.samediff'></span>

<h3>Description</h3>

<p>Computes the (normalized or relative) profile likelihood for the
parameters of a same-different test, plots the normalized profile
likelihood and computes profile likelihood confidence intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'samediff'
profile(fitted, which = 1:2, max = 2, numpts = 100,
           max.delta = 10, max.tau = 10, ...)
## S3 method for class 'profile.samediff'
plot(x, which = 1:nc, level = c(0.99, 0.95),
           fig = TRUE, ...)
## S3 method for class 'samediff'
confint(object, parm = c("tau", "delta"), level = 0.95, max = c(10, 10)
           , ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="profile.samediff_+3A_fitted">fitted</code></td>
<td>
<p>a <code>samediff</code> object</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_x">x</code></td>
<td>
<p>a <code>profile.samediff</code> object</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_object">object</code></td>
<td>
<p>a <code>samediff</code> object</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_which">which</code></td>
<td>
<p>numeric: which parameters to profile or plot; either &quot;1&quot; or &quot;2&quot;
or &quot;1:2&quot; to mean &quot;tau&quot;, &quot;delta&quot; or both respectively.</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_parm">parm</code></td>
<td>
<p>the parameter(s) to compute the confidence interval for</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_max">max</code></td>
<td>
<p>for <code>profile</code>: control parameter to specify how many units beyond the MLE,
the profiling should proceed. For <code>confint</code>: control parameter,
that can control the convergence for especially very large <code>delta</code></p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_numpts">numpts</code></td>
<td>
<p>control parameter: At how many points should the profile
likelihood be evaluated?</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_max.delta">max.delta</code></td>
<td>
<p>control parameter: The maximum point at which to
evaluate the profile likelihood for delta</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_max.tau">max.tau</code></td>
<td>
<p>same as <code>max.delta</code> for &quot;tau&quot;.</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_level">level</code></td>
<td>
<p>for <code>plot</code>: At which levels to include horizontal lines to indicate
confidence levels in plots of the normalized profile
likelihoods. For <code>confint</code>: at which level to compute the
confidence interval.</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_fig">fig</code></td>
<td>
<p>logical: Should the normalized profile likelihoods be plotted?</p>
</td></tr>
<tr><td><code id="profile.samediff_+3A_...">...</code></td>
<td>
<p>not currently used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For <code>profile</code>:
An object of class <code>"profile.samediff", "data.frame"</code>&mdash;a
<code>data.frame</code> with two columns for each parameter profiled giving
the value of the parameter and the corresponding value of the profile
likelihood.
</p>
<p>For <code>plot</code>:
An object of class <code>"nProfile.samediff", "data.frame"</code>&mdash;the
<code>data.frame</code> from the <code>profile</code>-object with extra
columns corresponding to the <code>which</code> parameter containing the
normalized profile liklelihood.
</p>
<p>For <code>confint</code>:
A 2x2 matrix with columns named <code>"lower", "upper"</code> giving the
lower and upper (1 - <code>alpha</code>)% confidence interval for the
parameters named in the rows.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary.samediff">summary.samediff</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data: 8 of the same samples were judged to be same
#       5 of the same samples were judged to be different
#       4 of the different samples were judged to be same
#       9 of the different samples were judged to be different

sadi &lt;- samediff(8, 5, 4, 9)
confint(sadi)
plot(profile(sadi))

</code></pre>

<hr>
<h2 id='rescale'>Transform or rescale between pc, pd and d-prime for sensory
discrimination protocols</h2><span id='topic+rescale'></span><span id='topic+psyfun'></span><span id='topic+psyinv'></span><span id='topic+psyderiv'></span><span id='topic+pc2pd'></span><span id='topic+pd2pc'></span>

<h3>Description</h3>

<p>Transforms or rescales estimates and optionally standard
errors between the three levels at which a sensory difference is
measured: pc (proportion of correct answers), pd (proportion of
discriminators) and d-prime. <code>rescale</code> is the main function and
only one of pc, pd or d-prime should be given as argument &mdash; values
for the remaining two scales will be computed.
</p>
<p>A number of auxiliary functions are also provided:
</p>

<dl>
<dt><code>psyfun</code></dt><dd><p>implements the psychometric functions and maps
from d-prime to pc</p>
</dd>
<dt><code>psyinv</code></dt><dd><p>implements the inverse psychometric functions
and maps from pc to d-prime</p>
</dd>
<dt><code>psyderiv</code></dt><dd><p>implements the derivative of the psychometric
functions</p>
</dd>
<dt><code>pc2pd</code></dt><dd><p>maps from pc to pd</p>
</dd>
<dt><code>pd2pc</code></dt><dd><p>maps from pd to pc</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>
rescale(pc, pd, d.prime, std.err,
        method = c("duotrio", "tetrad", "threeAFC", "twoAFC",
        "triangle", "hexad", "twofive", "twofiveF"),
        double = FALSE)

psyfun(d.prime, method = c("duotrio", "tetrad", "threeAFC", "twoAFC",
       "triangle", "hexad", "twofive", "twofiveF"),
        double = FALSE)

psyinv(pc, method = c("duotrio", "tetrad", "threeAFC", "twoAFC",
       "triangle", "hexad", "twofive", "twofiveF"),
        double = FALSE)

psyderiv(d.prime, method = c("duotrio", "tetrad", "threeAFC", "twoAFC",
         "triangle", "hexad", "twofive", "twofiveF"),
        double = FALSE)

pc2pd(pc, Pguess)

pd2pc(pd, Pguess)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rescale_+3A_pc">pc</code></td>
<td>
<p>the proportion of correct answers; a numerical vector
between 0 and 1</p>
</td></tr>
<tr><td><code id="rescale_+3A_pd">pd</code></td>
<td>
<p>the proportion of discriminators; a numerical vector between
0 and 1</p>
</td></tr>
<tr><td><code id="rescale_+3A_d.prime">d.prime</code></td>
<td>
<p>the sensory difference on the d-prime scale; a
non-negative numerical vector.</p>
</td></tr>
<tr><td><code id="rescale_+3A_std.err">std.err</code></td>
<td>
<p>optional numerical vector of standard errors of the
same length as the either of <code>pc</code>, <code>pd</code> or
<code>d.prime</code>. Negative values are not allowed, but values may be
<code>NA</code></p>
</td></tr>
<tr><td><code id="rescale_+3A_method">method</code></td>
<td>
<p>the sensory discrimination protocol for which the
results should apply</p>
</td></tr>
<tr><td><code id="rescale_+3A_double">double</code></td>
<td>
<p>should the 'double' variant of the discrimination protocol
be used? Logical scalar.</p>
</td></tr>
<tr><td><code id="rescale_+3A_pguess">Pguess</code></td>
<td>
<p>the guessing probability implied by the protocol; a
numeric scalar between 0 and 1</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>rescale</code> function is based on the fact that once the
protocol and one of
pc, pd and d-prime is known, the other two can be computed. The same
applies to the standard errors of these parameters.
</p>
<p>Standard errors are optional, but if they are supplied, the length of
the <code>std.err</code> argument has to match the length of <code>pc</code>,
<code>pd</code> or <code>d.prime</code> whichever is given.
</p>
<p>A <code>print</code> method is implemented for <code>rescale</code> objects.
</p>


<h3>Value</h3>

<p>For <code>rescale</code> an object of class <code>rescale</code> with elements
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>
<p>a <code>data.frame</code> with values of <code>pc</code>,
<code>pd</code> and <code>d.prime</code> corresponding to the input</p>
</td></tr>
<tr><td><code>std.err</code></td>
<td>
<p>if standard errors are given trough the <code>std.err</code>
argument a <code>data.frame</code> of the same size and shape as
<code>coefficients</code> with standard errors. Otherwise missing.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the sensory discrimination protocol for which the
results apply</p>
</td></tr>
</table>
<p>For <code>psyfun</code>, <code>psyinv</code>, <code>psyderiv</code>, <code>pc2pd</code> and
<code>pd2pc</code> a numerical vector of the same length as the first
argument with appropriate contents.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## suppose 15 out of 20 are observed in a duo-trio experiment, then
## the estimated probability of correct a answer is
(pc &lt;- 15/20)
## The standard error of this estimate is
(se.pc &lt;- sqrt(pc * (1 - pc) / 20))
## The corresponding estimate of proportion of discriminators (pd) and
## d-prime with associated standard errors are:
rescale(pc = pc, std.err = se.pc, method = "duotrio")

## Can also do
rescale(pd = c(.6,.7), std.err = c(.2, NA))
psyfun(2, method = "triangle")
psyinv(0.8, method = "twoAFC")
psyderiv(2, method = "duotrio")
pc2pd(0.7, 1/2)
pd2pc(0.3, 1/3)

</code></pre>

<hr>
<h2 id='ROC'>Plot the Receiver Operating Characteristic Curve</h2><span id='topic+ROC.default'></span><span id='topic+ROC.anota'></span><span id='topic+ROC'></span>

<h3>Description</h3>

<p>The function computes and plots the empirical ROC (receiver operating
characteristic) curve.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ROC(object, ...)

## Default S3 method:
ROC(object, se.d, scale = 1, length = 1000,
fig = TRUE, se.type = c("CI", "SE"), CI.alpha = 0.05, ...)

## S3 method for class 'anota'
ROC(object, length = 1000, fig = TRUE,
se.type = c("CI", "SE"), CI.alpha = 0.05, ...) 
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ROC_+3A_object">object</code></td>
<td>
<p>the class of the object defines, which of the methods is
invoked. If obejct is a single element numeric vector it is taken as
a d-prime value and the default method is invoked. If the object is
of class <code>anota</code>, the method for <code>anota</code> objects is
invoked.</p>
</td></tr>  
<tr><td><code id="ROC_+3A_se.d">se.d</code></td>
<td>
<p>a unit length vector with the standard error of
d-prime. If supplied confidence intervals or standard errors are
plotted</p>
</td></tr> 
<tr><td><code id="ROC_+3A_scale">scale</code></td>
<td>
<p>a unit length vector giving the ratio of scale (ie. standard
deviation) of the latent distribution for the no-class items
relative to  that of the yes-class items</p>
</td></tr> 
<tr><td><code id="ROC_+3A_length">length</code></td>
<td>
<p>the length of the vectors to be plotted. Longer vectors
gives more smooth curves.</p>
</td></tr>
<tr><td><code id="ROC_+3A_fig">fig</code></td>
<td>
<p>Should a plot be produced?</p>
</td></tr>
<tr><td><code id="ROC_+3A_se.type">se.type</code></td>
<td>
<p>The type of band for the ROC curve, <code>"CI"</code> for
confidence interval and <code>"SE"</code> for standard error.</p>
</td></tr>
<tr><td><code id="ROC_+3A_ci.alpha">CI.alpha</code></td>
<td>
<p>the type I level of the confidence interval of AUC</p>
</td></tr>
<tr><td><code id="ROC_+3A_...">...</code></td>
<td>
<p>additional arguments to <code>plot</code> and <code>lines</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function currently ignores the variance of the scale in the
computation of the uncertainty of the ROC curve.
</p>


<h3>Value</h3>

<p>The function makes a plot of the ROC curve, and if <code>se.d</code> is
supplied, standard errors or confidence intervals for the curve are
added to the plot.
</p>
<p>The function also (invisibly) returns a list with the following
components 
</p>
<table role = "presentation">
<tr><td><code>ROCx</code></td>
<td>
<p>x-coordinates to the ROC curve</p>
</td></tr>
<tr><td><code>ROCy</code></td>
<td>
<p>y-coordinates to the ROC curve</p>
</td></tr>
</table>
<p>If <code>se.d</code> is supplied, the object also contains
</p>
<table role = "presentation">
<tr><td><code>lower</code></td>
<td>
<p>y-coordinates to the lower limit</p>
</td></tr>
<tr><td><code>upper</code></td>
<td>
<p>y-coordinates to the upper limit</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>Examples</h3>

<pre><code class='language-R'>## ROC.default:
(mat &lt;- matrix(c(8, 17, 1, 24), 2, byrow = TRUE))
(d.prime &lt;- SDT(mat, "probit")[3])
ROC(d.prime)
## ROC.anota:
fm1 &lt;- AnotA(8, 25, 1, 25)
ROC(fm1)
</code></pre>

<hr>
<h2 id='samediff'>Computation of tau and dprime for same different test</h2><span id='topic+samediff'></span>

<h3>Description</h3>

<p>Computation of tau and dprime and their uncertainties for the
same different test using maximum likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>samediff(nsamesame, ndiffsame, nsamediff, ndiffdiff, VCOV = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="samediff_+3A_nsamesame">nsamesame</code></td>
<td>
<p>The number of same-answers on same-samples</p>
</td></tr>
<tr><td><code id="samediff_+3A_ndiffsame">ndiffsame</code></td>
<td>
<p>The number of different-answers on same-samples</p>
</td></tr>
<tr><td><code id="samediff_+3A_nsamediff">nsamediff</code></td>
<td>
<p>The number of same-answers on different-samples</p>
</td></tr>
<tr><td><code id="samediff_+3A_ndiffdiff">ndiffdiff</code></td>
<td>
<p> The number of different-answers on
different-samples</p>
</td></tr>
<tr><td><code id="samediff_+3A_vcov">VCOV</code></td>
<td>
<p>Should the variance-covariance matrix of the parameters be
computed. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the maximum likelihood estimates of
<code>tau</code> and <code>delta</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>samediff</code> with elements
</p>
<table role = "presentation">
<tr><td><code>coef</code></td>
<td>
<p> named vector of coefficients (d-prime and tau)</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>variance-covariance matrix of the coefficients</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>named vector with standard error of the coefficients
(standard error of d-prime)</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>a named vector with the data supplied to the function</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>a string with the name of the test (<code>same-different</code>)</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>convergence indicater. 0 indicates convergence. For error
codes see <code><a href="stats.html#topic+optim">optim</a></code>.</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>Value of the log-likelhood at the MLE of the
parameters.</p>
</td></tr>
<tr><td><code>case</code></td>
<td>
<p>A case indicator for internal use</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Christensen, R.H.B., Brockhoff, P.B. (2009).
Estimation and inference in the same-different test.
Food, Quality and Preference, 20 pp. 514&ndash;520</p>


<h3>Examples</h3>

<pre><code class='language-R'># data: 8 of the same samples were judged to be same
#       5 of the same samples were judged to be different
#       4 of the different samples were judged to be same
#       9 of the different samples were judged to be different

samediff(8, 5, 4, 9)
</code></pre>

<hr>
<h2 id='samediffPwr'>Power Analysis for Same-different Experiments</h2><span id='topic+samediffPwr'></span>

<h3>Description</h3>

<p>Computes the power for at same-different discrimination experiment
with a no-difference null hypothesis via simulation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>samediffPwr(n = 1000, tau, delta, Ns, Nd, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="samediffPwr_+3A_n">n</code></td>
<td>
<p>the number of samples to use in the simulation. More samples
means higher precision, but takes longer to compute.</p>
</td></tr>
<tr><td><code id="samediffPwr_+3A_tau">tau</code></td>
<td>
<p>the value of tau</p>
</td></tr>
<tr><td><code id="samediffPwr_+3A_delta">delta</code></td>
<td>
<p>the underlying sensory difference under the <em>alternative</em>
hypothesis (non-negative)</p>
</td></tr>
<tr><td><code id="samediffPwr_+3A_ns">Ns</code></td>
<td>
<p>the number of same-samples (a positive integer)</p>
</td></tr>
<tr><td><code id="samediffPwr_+3A_nd">Nd</code></td>
<td>
<p>the number of different-samples (a positive integer)</p>
</td></tr>
<tr><td><code id="samediffPwr_+3A_alpha">alpha</code></td>
<td>
<p>the type I level of the test (must be between zero and
one)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The power is computed using simulations. <code>n</code> datasets is
simulated from the
Same Different model with specified parameters. The power is the
fraction of times the p-value is lower than <code>alpha</code>.
</p>
<p>Under some parameter combinations, there is a non-significant
probability that data will fall, so that the MLE of <code>delta</code> is
not defined and the p-value is not defined. All such undefined
p-values are silently ignored.
</p>
<p>The estimated power may change between runs and especially if the
power is either very large or very small (ie. close to 0 or 1). Using
more simulations will provide higher accuracy.
</p>
<p>It is often a good idea to run the power simulation a couple of times
to ensure that the variation in the result is acceptable.
</p>


<h3>Value</h3>

<p>A single numeric value giving the power of the specified test.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Christensen, R.H.B., Brockhoff, P.B. (2009).
Estimation and inference in the same-different test.
Food, Quality and Preference, 20 pp. 514&ndash;520</p>


<h3>See Also</h3>

<p><code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+samediffSim">samediffSim</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Finding the power of a discrimination test with a sensory delta of 2
## (alternative hypothesis) versus a null hypothesis of delta = 0 with
## a sample of size 2 x 10 and a type I level of .05. n should be higher
## for a reasonable precision:

samediffPwr(n = 100, tau = 1, delta = 2, Ns = 10, Nd = 10)

</code></pre>

<hr>
<h2 id='samediffSim'>Simulates data from a samediff test</h2><span id='topic+samediffSim'></span>

<h3>Description</h3>

<p>Simulates the outcome of <code>n</code> same-different experiments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>samediffSim(n, tau, delta, Ns, Nd)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="samediffSim_+3A_n">n</code></td>
<td>
<p>the number of experiments to simulate.</p>
</td></tr>
<tr><td><code id="samediffSim_+3A_tau">tau</code></td>
<td>
<p>the value of &quot;tau&quot;.</p>
</td></tr>
<tr><td><code id="samediffSim_+3A_delta">delta</code></td>
<td>
<p>the value of delta (d-prime).</p>
</td></tr>
<tr><td><code id="samediffSim_+3A_ns">Ns</code></td>
<td>
<p>number of same-samples</p>
</td></tr>
<tr><td><code id="samediffSim_+3A_nd">Nd</code></td>
<td>
<p>number of different-samples</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function makes two calls to <code><a href="stats.html#topic+rbinom">rbinom</a></code>.
</p>


<h3>Value</h3>

<p>A matrix of with <code>n</code> rows and four columns named <code>ss, ds,
    sd, dd</code> with the number of same-answers to same-samples,
different-answers to same-samples, same-answers to different-samples
and different-answers to different-samples respectively.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Christensen, R.H.B., Brockhoff, P.B. (2009).
Estimation and inference in the same-different test.
Food, Quality and Preference, 20 pp. 514&ndash;520</p>


<h3>See Also</h3>

 <p><code><a href="#topic+discrimSim">discrimSim</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Running simulations:
samediffSim(n = 10, tau = 1, delta = 1, Ns = 10, Nd = 10)

</code></pre>

<hr>
<h2 id='SDT'>Signal Detection Theory Computation of d-prime</h2><span id='topic+SDT'></span>

<h3>Description</h3>

<p>The function computes d-prime for any 2 x J table where J &gt;= 2 for the
&quot;yes&ndash;no&quot; or &quot;A-Not A&quot; experiment using the Signal Detection Theory
(SDT) algorithm to compute J-1 d-prime's. The algorithm is also called
the &quot;empirical probit transform&quot;. The function also provides the &quot;logit&quot;
counterpart.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SDT(tab, method = c("probit", "logit"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SDT_+3A_tab">tab</code></td>
<td>
<p>A 2 x J table with true class relation in rows (only two
true classes) and the J-class response in columns</p>
</td></tr>
<tr><td><code id="SDT_+3A_method">method</code></td>
<td>
<p>should the empirical probit or logit transform be computed?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A (J-1) x 3 matrix. The first two columns contains the z-transform of
the Hit rate and the False Alarm rate respectively&mdash;ready to plot
along with the empirical ROC curve. The third column contains the
estimated d-primes.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>MacMillan , A. N. and Creelman, C. D (2005) Detection Theory
A User's Guide. Lawrence Elbaum Associates, Inc. 2nd edition.</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Design table:
## 8  "yes"-responses to yes-samples
## 1  "yes"-responses to no-samples
## 17 "no"-response to yes-samples
## 24 "no"-responses to no-samples
## Note that response-class is columnwise and true-class is rowwise:
(mat &lt;- rbind(c(8, 17),
              c(1, 24)))
SDT(mat, "logit")
SDT(mat, "probit")

## compare to AnotA():
m1 &lt;- AnotA(8, 25, 1, 25)
m1

## Compute d-prime 'by hand':
## Hit rate and False alarm rates:
H &lt;- 8/(8+17)
FA &lt;- 1/(1+24)
zH &lt;- qnorm(H)
zFA &lt;- qnorm(FA)
## d-prime:
zH - zFA  # d'



## Multi-response-class example (odor example from MacMillan and
## Creelman, 2005)
(odor &lt;- matrix(c(112, 112, 72, 53, 22, 4, 7, 38, 50, 117, 101, 62), 2,
               byrow = TRUE))
obj &lt;- SDT(odor)
ROC(obj[3,3])

</code></pre>

<hr>
<h2 id='sensR-deprecated'>Deprecated Functions in sensR Package</h2><span id='topic+sensR-deprecated'></span>

<h3>Description</h3>

<p>These functions are provided for compatibility with older versions of
the <span class="pkg">sensR</span> package only, and may be removed eventually.
</p>


<h3>Details</h3>

<p>The <code>clls</code> function is deprecated and users encouraged to use
<code><a href="ordinal.html#topic+clm">clm</a></code> instead from the <span class="pkg">ordinal</span> package.
</p>

<hr>
<h2 id='summary.samediff'>Summary method for samediff objects.</h2><span id='topic+summary.samediff'></span>

<h3>Description</h3>

<p>Makes a summary of a <code>samediff</code> object with option to use profile
likelihood for confidence intervals and p-values or the assymptotic
variance-covariance matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'samediff'
summary(object, profile = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.samediff_+3A_object">object</code></td>
<td>
<p>a <code>samediff</code> object</p>
</td></tr>
<tr><td><code id="summary.samediff_+3A_profile">profile</code></td>
<td>
<p>logical: Should the profile likelihood be used for
confidence intervals and p-values for the parameters? Defaults to
<code>TRUE</code>. If <code>FALSE</code> the assymptotic variance-covariance
matrix derived from the observed Fisher information matrix will be
used. See Details for more information.</p>
</td></tr>
<tr><td><code id="summary.samediff_+3A_...">...</code></td>
<td>
<p>can be <code>level</code>, eg 0.95 to specify the confidence
level of the intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that the variance-covariance matrix does not always exist in
contrast to the profile likelihood. <code>profile = FALSE</code> may
therefore cause confidence intervals etc. to be <code>NA</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>summary.samediff</code> inheriting elements from the
<code>samediff</code> object and with the following additional elements
</p>
<table role = "presentation">
<tr><td><code>table</code></td>
<td>
<p>matrix with parameter estimates, standard errors,
confidence intervals and p-values.</p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>the AIC of the object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>See Also</h3>

<p><code><a href="#topic+confint.samediff">confint.samediff</a></code>,   <code><a href="#topic+profile.samediff">profile.samediff</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># data: 8 of the same samples were judged to be same
#       5 of the same samples were judged to be different
#       4 of the different samples were judged to be same
#       9 of the different samples were judged to be different

sadi &lt;- samediff(8, 5, 4, 9)
summary(sadi)
summary(sadi, FALSE)

</code></pre>

<hr>
<h2 id='tetrad'>Create tetrad binomial family</h2><span id='topic+tetrad'></span>

<h3>Description</h3>

<p>Creates a binomial family object with the inverse link function
equal to the psychometric function for the unspecified method of
tetrads.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
tetrad()

</code></pre>


<h3>Value</h3>

<p>A binomial family object for models. Among other things it inludes the
psychometric function as
<code>linkinv</code> and the inverse psychometric function (for direct
d-prime computation) as
<code>linkfun</code>.
</p>


<h3>Note</h3>

<p>Several functions in this package makes use of functions in the tetrad
family object, but it may also be used on its own&mdash;see the example
below.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Ennis, J. M., Ennis, D. M., Yip, D., &amp; O'Mahony, M. (1998).
Thurstonian models for variants of the method of tetrads.
British Journal of Mathematical and Statistical Psychology, 51,
pp. 205-215.
</p>
<p>Ennis, J. M., &amp; Jesionka, V. (2011). The power of sensory
discrimination methods revisited. Journal of Sensory Studies, 26,
pp. 371-382.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+duotrio">duotrio</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Estimating d-prime using glm for a Tetrad test:
xt &lt;- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
res &lt;- glm(xt ~ 1, family = tetrad)
summary(res)
## Equivalent to (Estimate and Std. Error):
discrim(10, 15, method="tetrad")


## Extended example plotting the profile likelihood
## data: 10 correct answers, 9 incorrect
xt &lt;- matrix(c(10, 9), ncol = 2)
summary(res &lt;- glm(xt ~ 1, family = tetrad))
N &lt;- 100
dev &lt;- double(N)
delta &lt;- seq(1e-4, 3, length = N)
for(i in 1:N)
  dev[i] &lt;- glm(xt ~ -1 + offset(delta[i]),
                family = tetrad)$deviance
plot(delta, exp(-dev/2), type = "l",
     xlab = expression(delta),
     ylab = "Normalized Profile Likelihood")
## Add Normal approximation:
lines(delta, exp(-(delta - coef(res))^2 /
                 (2 * vcov(res))), lty = 2)
## Add confidence limits:
level &lt;- c(0.95, 0.99)
lim &lt;- sapply(level, function(x) exp(-qchisq(x, df=1)/2) )
abline(h = lim, col = "grey")

</code></pre>

<hr>
<h2 id='threeAFC'>Create 3-AFC binomial family</h2><span id='topic+threeAFC'></span>

<h3>Description</h3>

<p>Creates a copy of the binomial family with the inverse link function changed to equal
the 3-AFC psychometric function and correspondingly changed link function and derivative of the
inverse link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>threeAFC()
</code></pre>


<h3>Value</h3>

<p>A binomial family object for models. Among other things it inludes the psychometric function as
<code>linkinv</code> and the inverse psychometric function (for direct dprime computation) as
<code>linkfun</code>.
</p>


<h3>Note</h3>

<p>Several functions in this package makes use of the function, but it
may also be used on its own&mdash;see the example below.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen and Per Bruun Brockhoff</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen, R.H.B. (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.</p>


<h3>See Also</h3>

<p><code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+tetrad">tetrad</a></code>, <code><a href="#topic+duotrio">duotrio</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Estimating d-prime using glm for a 3-AFC test:
xt &lt;- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
res &lt;- glm(xt ~ 1, family = threeAFC)
summary(res)
## Equivalent to (Estimate and Std. Error):
discrim(10, 15, method="threeAFC")


## Extended example plotting the profile likelihood
## data: 10 correct answers, 5 incorrect
xt &lt;- matrix(c(10, 2), ncol = 2)
summary(res &lt;- glm(xt ~ 1, family = threeAFC))#, etastart = etastart))
N &lt;- 100
dev &lt;- double(N)
level &lt;- c(0.95, 0.99)
delta &lt;- seq(1e-4, 5, length = N)
for(i in 1:N)
  dev[i] &lt;- glm(xt ~ -1 + offset(delta[i]),
                family = threeAFC)$deviance
plot(delta, exp(-dev/2), type = "l",
     xlab = expression(delta),
     ylab = "Normalized Profile Likelihood")
## Add Normal approximation:
lines(delta, exp(-(delta - coef(res))^2 /
                 (2 * vcov(res))), lty = 2)
## Add confidence limits:
lim &lt;- sapply(level, function(x)
              exp(-qchisq(x, df=1)/2) )
abline(h = lim, col = "grey")
</code></pre>

<hr>
<h2 id='triangle'>Create triangle binomial family</h2><span id='topic+triangle'></span>

<h3>Description</h3>

<p>Creates a copy of the binomial family with the inverse link function
changed to equal
the triangle psychometric function and correspondingly changed link
function and derivative of the
inverse link function.</p>


<h3>Usage</h3>

<pre><code class='language-R'>triangle()
</code></pre>


<h3>Value</h3>

<p>A binomial family object for models. Among other things it inludes the
psychometric function as
<code>linkinv</code> and the inverse psychometric function (for direct
dprime computation) as
<code>linkfun</code>.
</p>


<h3>Note</h3>

<p>Several functions in this package makes use of the function, but it
may also be used on its own&mdash;see the example below.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen and Per Bruun Brockhoff</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen, R.H.B. (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.</p>


<h3>See Also</h3>

<p><code><a href="#topic+duotrio">duotrio</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+tetrad">tetrad</a></code>, <code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Estimating d-prime using glm for a Triangle test:
xt &lt;- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
res &lt;- glm(xt ~ 1, family = triangle)
summary(res)
## Equivalent to (Estimate and Std. Error):
discrim(10, 15, method="triangle")


## Extended example plotting the profile likelihood
## data: 10 correct answers, 9 incorrect
xt &lt;- matrix(c(10, 9), ncol = 2)
summary(res &lt;- glm(xt ~ 1, family = triangle))
N &lt;- 100
dev &lt;- double(N)
delta &lt;- seq(1e-4, 3, length = N)
for(i in 1:N)
  dev[i] &lt;- glm(xt ~ -1 + offset(delta[i]),
                family = triangle)$deviance
plot(delta, exp(-dev/2), type = "l",
     xlab = expression(delta),
     ylab = "Normalized Profile Likelihood")
## Add Normal approximation:
lines(delta, exp(-(delta - coef(res))^2 /
                 (2 * vcov(res))), lty = 2)
## Add confidence limits:
level &lt;- c(0.95, 0.99)
lim &lt;- sapply(level, function(x) exp(-qchisq(x, df=1)/2) )
abline(h = lim, col = "grey")

</code></pre>

<hr>
<h2 id='twoAC'>2-AC Discrimination and Preference Protocol</h2><span id='topic+twoAC'></span><span id='topic+print.twoAC'></span>

<h3>Description</h3>

<p>Computes estimates and standard errors of d-prime and tau for the two
alternative (2-AC) protocol. A confidence interval and
significance test for d-prime is also provided. The 2-AC protocol is 
equivalent to a 2-AFC protocol with a &quot;no-difference&quot; option, and
equivalent to a paired preference test with an &quot;no-preference&quot; option. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
twoAC(data, d.prime0 = 0, conf.level = 0.95,
      statistic = c("likelihood", "Wald"),
      alternative = c("two.sided", "less", "greater"), ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="twoAC_+3A_data">data</code></td>
<td>

<p>a non-negative numeric vector of length 3 with the number of
observations in the three response categories in the form (&quot;prefer
A&quot;, &quot;no-preference&quot;, &quot;prefer B&quot;). If the third element
is larger than the first element, the estimate of d-prime is
positive.</p>
</td></tr> 
<tr><td><code id="twoAC_+3A_d.prime0">d.prime0</code></td>
<td>
<p>the value of d-prime under the null hypothesis for the
significance test.</p>
</td></tr>
<tr><td><code id="twoAC_+3A_conf.level">conf.level</code></td>
<td>
<p>the confidence level.</p>
</td></tr>
<tr><td><code id="twoAC_+3A_statistic">statistic</code></td>
<td>
<p>the statistic to use for confidence level and
significance test.</p>
</td></tr>
<tr><td><code id="twoAC_+3A_alternative">alternative</code></td>
<td>
<p>the type of alternative hypothesis.</p>
</td></tr>
<tr><td><code id="twoAC_+3A_...">...</code></td>
<td>
<p>not currently used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+confint.twoAC">confint</a></code>,
<code><a href="#topic+profile.twoAC">profile</a></code>,
<code>logLik</code>, <code>vcov</code>, and
<code>print</code> methods are implemented for <code>twoAC</code> objects.
</p>
<p>Power computations for the 2-AC protocol is implemented in
<code><a href="#topic+twoACpwr">twoACpwr</a></code>. 
</p>


<h3>Value</h3>

<p>An object of class <code>twoAC</code> with elements
</p>
<table role = "presentation">
<tr><td><code>coefficients</code></td>
<td>

<p>2 by 2 coefficient matrix with estimates and standard errors of
d-prime and tau. If the variance-covariance matrix of the parameters
is not defined, the standard errors are <code>NA</code>.
</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>

<p>variance-covariance matrix of the parameter estimates. Only present
if defined for the supplied data.
</p>
</td></tr>
<tr><td><code>data</code></td>
<td>

<p>the data supplied to the function.
</p>
</td></tr>
<tr><td><code>call</code></td>
<td>

<p>the matched call.
</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>

<p>the value of the log-likelihood at the maximum likelihood estimates.
</p>
</td></tr>
<tr><td><code>alternative</code></td>
<td>
<p>the name of the alternative hypothesis for the
significance test.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>the name of the test statistic used for the
significance test.</p>
</td></tr>
<tr><td><code>conf.level</code></td>
<td>
<p>the confidence level for the confidence interval for
d-prime.</p>
</td></tr>
<tr><td><code>d.prime0</code></td>
<td>
<p>the value of d-prime under the null hypothesis in the
significance test.</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value of the significance test.</p>
</td></tr>
<tr><td><code>confint</code></td>
<td>
<p>two-sided condfidence interval for d-prime. This is
only available if the standard errors are defined, which may happen
in boundary cases. Use <code>profile</code> and <code>confint</code> methods to
get confidence intervals instead; see the examples.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Christensen R.H.B., Lee H-S and Brockhoff P.B. (2012). Estimation of
the Thurstonian model for the 2-AC protocol. Food Quality
and Preference, 24(1), pp.119-128.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm2twoAC">clm2twoAC</a></code>, <code><a href="#topic+twoACpwr">twoACpwr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Simple:
fit &lt;- twoAC(c(2,2,6))
fit

## Typical discrimination-difference test: 
(fit &lt;- twoAC(data = c(2, 5, 8), d.prime0 = 0, alternative = "greater"))

## Typical discrimination-similarity test: 
(fit &lt;- twoAC(data = c(15, 15, 20), d.prime0 = .5, alternative = "less"))

## Typical preference-difference test:
(fit &lt;- twoAC(data = c(3, 5, 12), d.prime0 = 0,
              alternative = "two.sided"))

## Typical preference (non-)inferiority test:
(fit &lt;- twoAC(data = c(3, 5, 12), d.prime0 = 0,
              alternative = "greater"))

## For preference equivalence tests (two-sided) use CI with alpha/2:
## declare equivalence at the 5% level if 90% CI does not contain,
## e.g, -1 or 1: 
(fit &lt;- twoAC(data = c(15, 10, 10), d.prime0 = 0, conf.level = .90))

## The var-cov matrix and standard errors of the parameters are not
## defined in all situations. If standard errors are not
## defined, then confidence intervals are not provided directly:
(fit &lt;- twoAC(c(5, 0, 15)))
## We may use profile and confint methods to get confidence intervals
## never the less: 
pr &lt;- profile(fit, range = c(-1, 3))
confint(pr)
plot(pr)

</code></pre>

<hr>
<h2 id='twoACpwr'>Exact Power Computation for the 2-AC Discrimination Protocol</h2><span id='topic+twoACpwr'></span>

<h3>Description</h3>

<p>Computes the exact power for the 2-AC protocol using the (signed)
likelihood root statistic. Power is computed for a significance test
of d-prime. The <code>tol</code> argument specifies the
precision with which power should be computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
twoACpwr(tau, d.prime, size, d.prime0 = 0, alpha = 0.05, tol = 1e-5, 
         return.dist = FALSE, statistic = "likelihood",
         alternative = c("two.sided", "less", "greater"))

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="twoACpwr_+3A_tau">tau</code></td>
<td>
<p>the value of tau under the alternative hypothesis</p>
</td></tr>
<tr><td><code id="twoACpwr_+3A_d.prime">d.prime</code></td>
<td>
<p>the value of d.prime under the alternative hypothesis</p>
</td></tr>
<tr><td><code id="twoACpwr_+3A_size">size</code></td>
<td>
<p>the sample size</p>
</td></tr>
<tr><td><code id="twoACpwr_+3A_d.prime0">d.prime0</code></td>
<td>
<p>the value of d-prime under the null hypothesis in the
significance test for which power should be computed</p>
</td></tr>
<tr><td><code id="twoACpwr_+3A_alpha">alpha</code></td>
<td>
<p>the size of the test</p>
</td></tr>
<tr><td><code id="twoACpwr_+3A_tol">tol</code></td>
<td>
<p>specifies the precision with which power should be
computed, e.g., <code>1e-4</code> cause power to be computed correctly to
three significant digits. Lower values of <code>tau</code> gives higher
precision, but also longer computation times.</p>
</td></tr>
<tr><td><code id="twoACpwr_+3A_return.dist">return.dist</code></td>
<td>
<p>should the p-value distribution be returned rather
than the power be computed?</p>
</td></tr>
<tr><td><code id="twoACpwr_+3A_statistic">statistic</code></td>
<td>
<p>the statistic used in the significance test for which
the power should be computed. Currently only the (signed) likelihood
root statistic is available&mdash;se the details for more information.</p>
</td></tr>
<tr><td><code id="twoACpwr_+3A_alternative">alternative</code></td>
<td>
<p>the type of alternative hypothesis in the
significance test for which the power should be computed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main idea in this function is to compute all possible data
outcomes and then compute the p-value for the chosen significance test
for each of these outcomes. This gives the exact distribution of
p-values from which the exact power can be computed. This is basically
what happens if <code>tol = 0</code>.
</p>
<p>There is, however, a problem with this approach if <code>size</code> is
large, since the the number of possible outcomes increases very fast
with the <code>size</code>; the order is O(<code>n^2</code>). The solution to this
problem is to ignore those outcomes which will occur with very small
probability. Often, a large proportion of the outcomes, say 90% will
occur so rarely that they account for, say <code>1e-4</code> percent of the
probability mass; it is therefore safe to ignore those outcomes
without compromising the accuracy of the computed power by any
relevant amount. For more information see the referenced paper and the
package vignette Statistical Methodology. 
</p>
<p>The Wald statistic is not available here. The reason is that the Wald
statistic is not always defined and the problem is therefore what to
do with those cases where it is not defined?
On the other hand the likelihood root statistic
is defined in all cases, so theres is no problem here, and since the
likelihood root statistic is more accurate than the Wald statistic,
there is not much reason to use the Wald statistic after all.
</p>
<p>For the record; the Wald statistic is not defined, when the standard
error of d-prime is not defined. This happens when the
variance-covariance matrix of tau and d-prime is not defined, which
occurs in a number of boundary cases, i.e., when one or more cells
contain zero frequencies. Since these outcomes occur with positive
probability, the algorithm used by <code>twoACpwr</code> will always
encounter those cases and have to deal with them. This would be
cumbersome to implement.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> with one line and the following entries
</p>
<table role = "presentation">
<tr><td><code>power</code></td>
<td>
<p>the computed power</p>
</td></tr>
<tr><td><code>actual.alpha</code></td>
<td>
<p>the actual size of the test (different from the
nominal alpha given as argument due to the discreteness of the
observations). </p>
</td></tr>
<tr><td><code>samples</code></td>
<td>
<p>the number of possible outcomes for this <code>size</code></p>
</td></tr>
<tr><td><code>discarded</code></td>
<td>
<p>the number of outcomes for which the p-value is not
computed. This number is zero if <code>tol = 0</code></p>
</td></tr>
<tr><td><code>kept</code></td>
<td>
<p>the number of outcomes for which the p-value is computed
in. This number equals <code>samples</code> if <code>tol = 0</code></p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>the probability vector of the multinomial distribution
implied by the values of <code>tau</code> and <code>d.prime</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen</p>


<h3>References</h3>

<p>Christensen R.H.B., Lee H-S and Brockhoff P.B. (2012). Estimation of
the Thurstonian model for the 2-AC protocol. Food Quality
and Preference, 24(1), pp.119-128.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+clm2twoAC">clm2twoAC</a></code>, <code><a href="#topic+twoACpwr">twoACpwr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Exact power: 
twoACpwr(tau = .5, d.prime = .7, size = 50, tol = 0)

## Power exact to a reasonable number of digits
twoACpwr(tau = .5, d.prime = .7, size = 50, tol = 1e-5)

## Power for a similarity test in a discrimination setting where the
## true parameter values are expected to be tau = 0.4 and true d.prime
## = .5, while we want to show that d.prime &lt; 1, i.e., under the null
## hypothesis d.prime = 1:
twoACpwr(tau = .4, d.prime = .5, size = 100, d.prime0 = 1, tol = 1e-5, 
         alternative = "less")

## Power for a difference test in a preference setting where the true
## parameter values are expected to be tau = 0.4 and d.prime = -0.5,
## while we want to show that d.prime is different from zero:
twoACpwr(tau = 0.4, d.prime = -0.5, size = 100, d.prime0 = 0, tol = 1e-5, 
         alternative = "two.sided")

</code></pre>

<hr>
<h2 id='twoAFC'>Create 2-AFC binomial family</h2><span id='topic+twoAFC'></span>

<h3>Description</h3>

<p>Creates a copy of the binomial family with the inverse link function
changed to equal
the 2-AFC psychometric function and correspondingly changed link
function and derivative of the
inverse link function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twoAFC()
</code></pre>


<h3>Value</h3>

<p>A binomial family object for models. Among other things it inludes the
psychometric function as
<code>linkinv</code> and the inverse psychometric function (for direct
dprime computation) as
<code>linkfun</code>.
</p>


<h3>Note</h3>

<p>Several functions in this package makes use of the function, but it
may also be used on its own&mdash;see the example below.
</p>


<h3>Author(s)</h3>

<p>Rune Haubo B Christensen and Per Bruun Brockhoff</p>


<h3>References</h3>

<p>Brockhoff, P.B. and Christensen, R.H.B. (2010). Thurstonian
models for sensory discrimination tests as generalized linear models.
Food Quality and Preference, 21, pp. 330-338.</p>


<h3>See Also</h3>

<p><code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+threeAFC">threeAFC</a></code>,
<code><a href="#topic+tetrad">tetrad</a></code>, <code><a href="#topic+duotrio">duotrio</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Estimating d-prime using glm for a 2-AFC test:
xt &lt;- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
res &lt;- glm(xt ~ 1, family = twoAFC)
summary(res)
## Equivalent to (Estimate and Std. Error):
discrim(10, 15, method="twoAFC")


## Extended example plotting the profile likelihood
## data: 10 correct and 8 incorrect:
xt &lt;- matrix(c(10, 8), ncol = 2)
summary(res &lt;- glm(xt ~ 1, family = twoAFC))
N &lt;- 100
dev &lt;- double(N)
level &lt;- c(0.95, 0.99)
delta &lt;- seq(1e-4, 3, length = N)
for(i in 1:N)
  dev[i] &lt;- glm(xt ~ -1 + offset(delta[i]),
                family = twoAFC)$deviance
plot(delta, exp(-dev/2), type = "l",
     xlab = expression(delta),
     ylab = "Normalized Profile Likelihood")
## Add Normal approximation:
lines(delta, exp(-(delta - coef(res))^2 /
                 (2 * vcov(res))), lty = 2)
## Add confidence limits:
lim &lt;- sapply(level, function(x)
              exp(-qchisq(x, df=1)/2) )
abline(h = lim, col = "grey")

</code></pre>

<hr>
<h2 id='twofive'>Create twofive binomial family</h2><span id='topic+twofive'></span>

<h3>Description</h3>

<p>Creates af binomial family object with the inverse link function
equal to the psychometric function for the Two-Out-of-Five test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
twofive()

</code></pre>


<h3>Value</h3>

<p>A binomial family object for models. Among other things it inludes the
psychometric function as
<code>linkinv</code> and the inverse psychometric function (for direct
d-prime computation) as
<code>linkfun</code>.
</p>


<h3>Note</h3>

<p>Several functions in this package makes use of functions in the twofive
family object, but it may also be used on its own&mdash;see the example
below.
</p>


<h3>Author(s)</h3>

<p>Karolina Stachlewska</p>


<h3>References</h3>

<p>Ennis, J. M. (2013). 
A thurstonian analysis of the Two-Out-of-Five test.
Journal of Sensory Studies, 28(4),
pp. 297-310.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+duotrio">duotrio</a></code>, <code><a href="#topic+triangle">triangle</a></code>, 
<code><a href="#topic+twoAFC">twoAFC</a></code>, <code><a href="#topic+threeAFC">threeAFC</a></code>, 
<code><a href="#topic+tetrad">tetrad</a></code>, <code><a href="#topic+twofiveF">twofiveF</a></code>,
<code><a href="#topic+hexad">hexad</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Estimating d-prime using glm for a Two-Out-of-Five test:
xt &lt;- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
res &lt;- glm(xt ~ 1, family = twofive)
summary(res)
## Equivalent to (Estimate and Std. Error):
discrim(10, 15, method="twofive")


## Extended example plotting the profile likelihood
## data: 10 correct answers, 9 incorrect
xt &lt;- matrix(c(10, 9), ncol = 2)
summary(res &lt;- glm(xt ~ 1, family = twofive))
N &lt;- 100
dev &lt;- double(N)
delta &lt;- seq(1e-4, 3, length = N)
for(i in 1:N)
  dev[i] &lt;- glm(xt ~ -1 + offset(delta[i]),
                family = twofive)$deviance
plot(delta, exp(-dev/2), type = "l",
     xlab = expression(delta),
     ylab = "Normalized Profile Likelihood")
## Add Normal approximation:
lines(delta, exp(-(delta - coef(res))^2 /
                 (2 * vcov(res))), lty = 2)
## Add confidence limits:
level &lt;- c(0.95, 0.99)
lim &lt;- sapply(level, function(x) exp(-qchisq(x, df=1)/2) )
abline(h = lim, col = "grey")

</code></pre>

<hr>
<h2 id='twofiveF'>Create twofiveF binomial family</h2><span id='topic+twofiveF'></span>

<h3>Description</h3>

<p>Creates af binomial family object with the inverse link function
equal to the psychometric function for the Two-Out-of-Five with forgiveness test.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
twofiveF()

</code></pre>


<h3>Value</h3>

<p>A binomial family object for models. Among other things it inludes the
psychometric function as
<code>linkinv</code> and the inverse psychometric function (for direct
d-prime computation) as
<code>linkfun</code>.
</p>


<h3>Note</h3>

<p>Several functions in this package makes use of functions in the twofiveF
family object, but it may also be used on its own&mdash;see the example
below.
</p>


<h3>Author(s)</h3>

<p>Karolina Stachlewska</p>


<h3>References</h3>

<p>Ennis, J. M. (2013). 
A thurstonian analysis of the Two-Out-of-Five test.
Journal of Sensory Studies, 28(4),
pp. 297-310.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+duotrio">duotrio</a></code>, <code><a href="#topic+triangle">triangle</a></code>, <code><a href="#topic+twoAFC">twoAFC</a></code>,
<code><a href="#topic+threeAFC">threeAFC</a></code>, <code><a href="#topic+tetrad">tetrad</a></code>, <code><a href="#topic+twofive">twofive</a></code>,
<code><a href="#topic+hexad">hexad</a></code>, <code><a href="#topic+discrim">discrim</a></code>,
<code><a href="#topic+discrimPwr">discrimPwr</a></code>, <code><a href="#topic+discrimSim">discrimSim</a></code>,
<code><a href="#topic+AnotA">AnotA</a></code>, <code><a href="#topic+discrimSS">discrimSS</a></code>,
<code><a href="#topic+samediff">samediff</a></code>, <code><a href="#topic+findcr">findcr</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Estimating d-prime using glm for a Two-Out-of-Five with forgiveness test:
xt &lt;- matrix(c(10, 5), ncol = 2) ## data: 10 correct answers, 5 incorrect
res &lt;- glm(xt ~ 1, family = twofiveF)
summary(res)
## Equivalent to (Estimate and Std. Error):
discrim(10, 15, method="twofiveF")


## Extended example plotting the profile likelihood
## data: 10 correct answers, 9 incorrect
xt &lt;- matrix(c(10, 9), ncol = 2)
summary(res &lt;- glm(xt ~ 1, family = twofiveF))
N &lt;- 100
dev &lt;- double(N)
delta &lt;- seq(1e-4, 3, length = N)
for(i in 1:N)
  dev[i] &lt;- glm(xt ~ -1 + offset(delta[i]),
                family = twofiveF)$deviance
plot(delta, exp(-dev/2), type = "l",
     xlab = expression(delta),
     ylab = "Normalized Profile Likelihood")
## Add Normal approximation:
lines(delta, exp(-(delta - coef(res))^2 /
                 (2 * vcov(res))), lty = 2)
## Add confidence limits:
level &lt;- c(0.95, 0.99)
lim &lt;- sapply(level, function(x) exp(-qchisq(x, df=1)/2) )
abline(h = lim, col = "grey")

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
