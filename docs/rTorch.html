<!DOCTYPE html><html><head><title>Help for package rTorch</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {rTorch}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#-.torch.Tensor'><p>Subtract two tensors</p></a></li>
<li><a href='#+5B.torch.Tensor'><p>Subset tensors with <code>[</code></p></a></li>
<li><a href='#+2A.torch.Tensor'><p>Tensor multiplication</p></a></li>
<li><a href='#+2F.torch.Tensor'><p>Divide two tensors</p></a></li>
<li><a href='#+26gt+3B.torch.Tensor'><p>A tensor greater than another tensor</p></a></li>
<li><a href='#+26gt+3B+3D.torch.Tensor'><p>Is a tensor greater or equal than another tensor</p></a></li>
<li><a href='#+26lt+3B.torch.Tensor'><p>Is a tensor less than another tensor</p></a></li>
<li><a href='#+26lt+3B+3D.torch.Tensor'><p>Is a tensor less or equal than another tensor</p></a></li>
<li><a href='#+25.+2A+25'><p>#' @export</p>
&quot;round.torch.Tensor&quot; &lt;- function(input)
# round: Returns a new tensor with each of the elements of input rounded to the closest integer.
torch$round(input)

Dot product of two tensors</a></li>
<li><a href='#+25+2A+2A+25'><p>Matrix/Tensor multiplication of two tensors</p></a></li>
<li><a href='#+25+25.torch.Tensor'><p>Remainder</p></a></li>
<li><a href='#+2B.torch.Tensor'><p>Add two tensors</p></a></li>
<li><a href='#+3D+3D.torch.Tensor'><p>Compares two tensors if equal</p></a></li>
<li><a href='#all_dims'><p>All dims</p></a></li>
<li><a href='#all.torch.Tensor'><p>all</p></a></li>
<li><a href='#any.torch.Tensor'><p>any</p></a></li>
<li><a href='#as_boolean'><p>Convert tensor to boolean type</p></a></li>
<li><a href='#dataset_mnist_digits'><p>MNIST database of handwritten digits</p></a></li>
<li><a href='#dim.torch.Tensor'><p>Dimensions of a tensor</p></a></li>
<li><a href='#install_pytorch'><p>Install PyTorch and its dependencies</p></a></li>
<li><a href='#install_torch_extras'><p>Install additional Python packages alongside PyTorch</p></a></li>
<li><a href='#is_tensor'><p>Is the object a tensor</p></a></li>
<li><a href='#length.torch.Tensor'><p>Length of a tensor.</p></a></li>
<li><a href='#log.torch.Tensor'><p>Logarithm of a tensor given the tensor and the base</p></a></li>
<li><a href='#log10.torch.Tensor'><p>Logarithm of a tensor in base 10</p></a></li>
<li><a href='#log2.torch.Tensor'><p>Logarithm of a tensor in base 2</p></a></li>
<li><a href='#logical_and'><p>Logical AND of two tensors</p></a></li>
<li><a href='#logical_not'><p>Logical NOT of a tensor</p></a></li>
<li><a href='#logical_or'><p>Logical OR of two tensors</p></a></li>
<li><a href='#make_copy'><p>Make copy of tensor, numpy array or R array</p></a></li>
<li><a href='#not_equal_to'><p>Compare two tensors if not equal</p></a></li>
<li><a href='#one_tensor_op'><p>One tensor operation</p></a></li>
<li><a href='#reexports'><p>Objects exported from other packages</p></a></li>
<li><a href='#rTorch'><p>PyTorch for R</p></a></li>
<li><a href='#shape'><p>Tensor shape</p></a></li>
<li><a href='#tensor_ops'><p>Two tensor operations</p></a></li>
<li><a href='#torch'><p>Main PyTorch module</p></a></li>
<li><a href='#torch_config'><p>Torch configuration information</p></a></li>
<li><a href='#torch_extract_opts'><p>Tensor extract options</p></a></li>
<li><a href='#torch_size'><p>Size of a torch tensor object</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>R Bindings to 'PyTorch'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4.2</td>
</tr>
<tr>
<td>Description:</td>
<td>'R' implementation and interface of the Machine Learning platform 
    'PyTorch' <a href="https://pytorch.org/">https://pytorch.org/</a> developed in 'Python'. It requires a 'conda'
    environment with 'torch' and 'torchvision' Python packages to provide 
    'PyTorch' functions, methods and classes. The key object in 'PyTorch' is the 
    tensor which is in essence a multidimensional array. These tensors are fairly 
    flexible in performing calculations in CPUs as well as 'GPUs' to accelerate 
    tensor operations.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>reticulate (&ge; 1.10), jsonlite (&ge; 1.2), utils, methods,
rstudioapi (&ge; 0.7),</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>"conda (python&gt;=3.6 pytorch torchvision cpuonly
numpy ( &gt;= 1.14.0) matplotlib pandas -c pytorch);
python-minimal, pandoc pandoc-citeproc, qpdf; Python (&gt;=3.6),
pytorch (&gt;=1.4), torchvision, cpuonly, numpy ( &gt;= 1.14.0);
pandoc (&gt;= 2.0), qpdf ( &gt;= 7.0) on Solaris"</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/f0nzie/rTorch">https://github.com/f0nzie/rTorch</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/f0nzie/rTorch/issues">https://github.com/f0nzie/rTorch/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-10-12 13:37:55 UTC; msfz751</td>
</tr>
<tr>
<td>Author:</td>
<td>Alfonso R. Reyes [aut, cre, cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alfonso R. Reyes &lt;alfonso.reyes@oilgainsanalytics.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-10-12 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='-.torch.Tensor'>Subtract two tensors</h2><span id='topic+-.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is similar to applying <code>torch$sub(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a - b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="-.torch.Tensor_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="-.torch.Tensor_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Another tensor representing the subtraction of two tensors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
a &lt;- torch$Tensor(list(1, 1, 1))
b &lt;- torch$Tensor(list(2, 2, 2))
s &lt;- 2.0
a - b

## End(Not run)

</code></pre>

<hr>
<h2 id='+5B.torch.Tensor'>Subset tensors with <code>[</code></h2><span id='topic++5B.torch.Tensor'></span>

<h3>Description</h3>

<p>Subset tensors with <code>[</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'

  x[
  ...,
  drop = TRUE,
  style = getOption("torch.extract.style"),
  options = torch_extract_opts(style)
]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B.torch.Tensor_+3A_x">x</code></td>
<td>
<p>a tensor</p>
</td></tr>
<tr><td><code id="+2B5B.torch.Tensor_+3A_...">...</code></td>
<td>
<p>slicing specs. See examples and details.</p>
</td></tr>
<tr><td><code id="+2B5B.torch.Tensor_+3A_drop">drop</code></td>
<td>
<p>whether to drop scalar dimensions</p>
</td></tr>
<tr><td><code id="+2B5B.torch.Tensor_+3A_style">style</code></td>
<td>
<p>One of <code>"python"</code> or <code>"R"</code>.</p>
</td></tr>
<tr><td><code id="+2B5B.torch.Tensor_+3A_options">options</code></td>
<td>
<p>An object returned by <code>torch_extract_opts()</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x &lt;- torch$arange(0L, 15L)$view(3L, 5L)

# by default, numerics supplied to `...` are interpreted R style
x[,1]    # first column
x[1:2,]  # first two rows
x[,1, drop = FALSE]

# strided steps can be specified in R syntax or python syntax
x[, seq(1, 5, by = 2)]
x[, 1:5:2]

# if you are unfamiliar with python-style strided steps, see:
# https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#basic-slicing-and-indexing

# missing arguments for python syntax are valid, but they must by backticked
# or supplied as NULL
x[, `::2`]
x[, NULL:NULL:2]
x[, `2:`]

# Another Python feature that is available is a Python style ellipsis `...`
# (not to be confused with R dots `...`), that in R has been defined as
# all_dims() expands to the shape of the tensor

y &lt;- torch$arange(0L, 3L^5L)$view(3L, 3L, 3L, 3L, 3L)
as.logical((all(y[all_dims(), 1] == y[,,,,1]))$numpy()) == TRUE


# negative numbers are always interpreted Python style
# The first time a negative number is supplied to `[`, a warning is issued
# about the non-standard behavior.
x[-1,] # last row, with a warning
x[-1,] # the warning is only issued once

# specifying `style = 'python'` changes the following:
# +  zero-based indexing is used
# +  slice sequences in the form of `start:stop` do not include `stop`
#    in the returned value
# +  out-of-bounds indices in a slice are valid

# The style argument can be supplied to individual calls of `[` or set
# as a global option

# example of zero based  indexing
x[0, , style = 'python']   # first row
x[1, , style = 'python']   # second row

# example of slices with exclusive stop
# run the next options() line before the tensor operations

options(torch.extract.style = 'python')
x[, 0:1]   # just the first column
x[, 0:2]   # first and second column

# example of out-of-bounds index
x[, 0:10]
options(torch.extract.style = NULL)

# slicing with tensors is valid too, but note that tensors are never
# translated and are always interpreted Python-style.
# A warning is issued the first time a tensor is passed to `[`
# just as in Python, only scalar tensors are valid

# To silence the warnings about tensors being passed as-is and negative numbers
# being interpreted python-style, set
options(torch.extract.style = 'R')

# clean up from examples
options(torch.extract.style = NULL)

## End(Not run)
</code></pre>

<hr>
<h2 id='+2A.torch.Tensor'>Tensor multiplication</h2><span id='topic++2A.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is similar to <code>torch$mul(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a * b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B2A.torch.Tensor_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B2A.torch.Tensor_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Another tensor representing the multiplication of two tensors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
a &lt;- torch$Tensor(list(1, 1, 1))
b &lt;- torch$Tensor(list(2, 2, 2))
s &lt;- 2.0
a * b

## End(Not run)

</code></pre>

<hr>
<h2 id='+2F.torch.Tensor'>Divide two tensors</h2><span id='topic++2F.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is similar to <code>torch$div(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a / b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B2F.torch.Tensor_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B2F.torch.Tensor_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Another tensor representing the division of two tensors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
a &lt;- torch$Tensor(list(1, 1, 1))
b &lt;- torch$Tensor(list(2, 2, 2))
s &lt;- 2.0
a / b

## End(Not run)
</code></pre>

<hr>
<h2 id='+26gt+3B.torch.Tensor'>A tensor greater than another tensor</h2><span id='topic++3E.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is similar to <code>torch$gt(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a &gt; b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26gt+2B3B.torch.Tensor_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B26gt+2B3B.torch.Tensor_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of booleans representing the logical result of the comparison.
False to represent 0, and True to represent 1 in a tensor of data type <code>torch$uint8</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
A &lt;- torch$ones(5L, 5L)
C &lt;- torch$as_tensor(np$random$randint(2L, size=c(5L, 5L)), dtype=torch$float32)
A &gt; C
C &gt; A

## End(Not run)
</code></pre>

<hr>
<h2 id='+26gt+3B+3D.torch.Tensor'>Is a tensor greater or equal than another tensor</h2><span id='topic++3E+3D.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is similar to <code>torch$ge(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a &gt;= b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26gt+2B3B+2B3D.torch.Tensor_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B26gt+2B3B+2B3D.torch.Tensor_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of booleans representing the logical result of the comparison.
False to represent 0, and True to represent 1 in a tensor of data type <code>torch$uint8</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
A &lt;- torch$ones(5L, 5L)
C &lt;- torch$as_tensor(np$random$randint(2L, size=c(5L, 5L)), dtype=torch$float32)
A &gt;= C
C &gt;= A

## End(Not run)
</code></pre>

<hr>
<h2 id='+26lt+3B.torch.Tensor'>Is a tensor less than another tensor</h2><span id='topic++3C.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is similar to <code>torch$lt(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a &lt; b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26lt+2B3B.torch.Tensor_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B26lt+2B3B.torch.Tensor_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of booleans representing the logical result of the comparison.
False to represent 0, and True to represent 1 in a tensor of data type <code>torch$uint8</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
A &lt;- torch$ones(28L, 28L)
C &lt;- A * 0.5
A &lt; C


## End(Not run)
</code></pre>

<hr>
<h2 id='+26lt+3B+3D.torch.Tensor'>Is a tensor less or equal than another tensor</h2><span id='topic++3C+3D.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is similar to <code>torch$le(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a &lt;= b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B26lt+2B3B+2B3D.torch.Tensor_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B26lt+2B3B+2B3D.torch.Tensor_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of booleans representing the logical result of the comparison.
False to represent 0, and True to represent 1 in a tensor of data type <code>torch$uint8</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
A &lt;- torch$ones(5L, 5L)
C &lt;- torch$as_tensor(np$random$randint(2L, size=c(5L, 5L)), dtype=torch$float32)
A &lt;= C
C &lt;= A

## End(Not run)
</code></pre>

<hr>
<h2 id='+25.+2A+25'>#' @export
&quot;round.torch.Tensor&quot; &lt;- function(input) 
# round: Returns a new tensor with each of the elements of input rounded to the closest integer.
torch$round(input)

Dot product of two tensors</h2><span id='topic++25.+2A+25'></span>

<h3>Description</h3>

<p>This generic is similar to <code>torch$dot(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>a %.*% b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25.+2B2A+2B25_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B25.+2B2A+2B25_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a scalar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
p &lt;- torch$Tensor(list(2, 3))
q &lt;- torch$Tensor(list(2, 1))
p %.*% q

## End(Not run)

</code></pre>

<hr>
<h2 id='+25+2A+2A+25'>Matrix/Tensor multiplication of two tensors</h2><span id='topic++25+2A+2A+25'></span>

<h3>Description</h3>

<p>This generic is similar to <code>torch$matmul(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>a %**% b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B2A+2B2A+2B25_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B25+2B2A+2B2A+2B25_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a scalar or a tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
p &lt;- torch$randn(3L)
q &lt;- torch$randn(3L)
p %**% q

## End(Not run)

</code></pre>

<hr>
<h2 id='+25+25.torch.Tensor'>Remainder</h2><span id='topic++25+25.torch.Tensor'></span>

<h3>Description</h3>

<p>Computes the element-wise remainder of division.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a %% b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B25+2B25.torch.Tensor_+3A_a">a</code></td>
<td>
<p>a tensor</p>
</td></tr>
<tr><td><code id="+2B25+2B25.torch.Tensor_+3A_b">b</code></td>
<td>
<p>a scalar or a tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the reminder of the division between tensor by a scalar or tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- torch$Tensor(list(-3., -2, -1, 1, 2, 3))
y &lt;- torch$Tensor(list(1., 2, 3, 4, 5))
torch$remainder(x, 2)
torch$remainder(y, 1.5)

x %% 2
y %% 1.5

## End(Not run)
</code></pre>

<hr>
<h2 id='+2B.torch.Tensor'>Add two tensors</h2><span id='topic++2B.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is similar to applying <code>torch$add(a, b)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
a + b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B2B.torch.Tensor_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B2B.torch.Tensor_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Another tensor representing the addition of two tensors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
a &lt;- torch$Tensor(list(1, 1, 1))
b &lt;- torch$Tensor(list(2, 2, 2))
s &lt;- 2.0
a + b

## End(Not run)
</code></pre>

<hr>
<h2 id='+3D+3D.torch.Tensor'>Compares two tensors if equal</h2><span id='topic++3D+3D.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is approximately similar to <code>torch$eq(a, b)</code>, with the
difference that the generic returns a tensor of booleans instead of
a tensor of data type <code>torch$uint8</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
x == y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B3D+2B3D.torch.Tensor_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="+2B3D+2B3D.torch.Tensor_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of booleans, where False corresponds to 0, and 1 to True
in a tensor of data type <code>torch$bool</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
a &lt;- torch$Tensor(list(1, 1, 1))
b &lt;- torch$Tensor(list(2, 2, 2))
a == b

## End(Not run)

</code></pre>

<hr>
<h2 id='all_dims'>All dims</h2><span id='topic+all_dims'></span>

<h3>Description</h3>

<p>This function returns an object that can be used when subsetting tensors with
<code>[</code>. If you are familiar with Python, this is equivalent to the Python Ellipsis
<code>...</code>, (not to be confused with <code>...</code> in <code>R</code>). In Python, if <code>x</code> is a numpy
array or a torch tensor, in <code>x[..., i]</code> the ellipsis means &quot;expand to match number of
dimension of x&quot;.
To translate the above Python expression to R, write:
<code>x[all_dims(), i]</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>all_dims()
</code></pre>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Run this
d &lt;- torch$tensor(list(list(0, 0),
                       list(0, 0),
                       list(0, 1),
                       list(1, 1)), dtype=torch$uint8)
d[all_dims(), 1]

f &lt;- torch$arange(9L)$reshape(c(3L, 3L))
f
f[all_dims()]
f[all_dims(), 1L]

## End(Not run)
</code></pre>

<hr>
<h2 id='all.torch.Tensor'>all</h2><span id='topic+all.torch.Tensor'></span>

<h3>Description</h3>

<p>Returns True if all elements in the tensor are non-zero, False otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
all(x, dim, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="all.torch.Tensor_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="all.torch.Tensor_+3A_dim">dim</code></td>
<td>
<p>dimension to reduce</p>
</td></tr>
<tr><td><code id="all.torch.Tensor_+3A_...">...</code></td>
<td>
<p>other parameters (yet to be developed)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of type torch.uint8 representing the boolean result:
1 for TRUE and 0 for FALSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
a &lt;- torch$BoolTensor(list(TRUE, TRUE, TRUE, TRUE))
b &lt;- torch$BoolTensor(list(FALSE, TRUE, TRUE, TRUE))
c &lt;- torch$BoolTensor(list(TRUE, TRUE, TRUE, FALSE))
all(a)
all(b)
all(c)
d &lt;- torch$tensor(list(list(0, 0),
                       list(0, 0),
                       list(0, 1),
                       list(1, 1)), dtype=torch$uint8)
all(d)
all(d, dim=0L)
all(d, dim=1L)

## End(Not run)
</code></pre>

<hr>
<h2 id='any.torch.Tensor'>any</h2><span id='topic+any.torch.Tensor'></span>

<h3>Description</h3>

<p>Returns True if any elements in the tensor are non-zero, False otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
any(x, dim, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="any.torch.Tensor_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="any.torch.Tensor_+3A_dim">dim</code></td>
<td>
<p>dimension to reduce</p>
</td></tr>
<tr><td><code id="any.torch.Tensor_+3A_...">...</code></td>
<td>
<p>other params (yet to be developed)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of type torch.uint8 representing the boolean result:
1 for TRUE and 0 for FALSE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
a &lt;- torch$BoolTensor(list(TRUE, TRUE, TRUE, TRUE))
b &lt;- torch$BoolTensor(list(FALSE, TRUE, TRUE, TRUE))
c &lt;- torch$BoolTensor(list(TRUE, TRUE, TRUE, FALSE))
any(a)
any(b)
any(c)
d &lt;- torch$tensor(list(list(1, 0),
                       list(0, 0),
                       list(0, 1),
                       list(0, 0)), dtype=torch$uint8)
any(d)
any(d, dim=0L)
any(d, dim=1L)

## End(Not run)
</code></pre>

<hr>
<h2 id='as_boolean'>Convert tensor to boolean type</h2><span id='topic+as_boolean'></span>

<h3>Description</h3>

<p>Convert a tensor to a boolean equivalent tensor
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_boolean(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_boolean_+3A_x">x</code></td>
<td>
<p>a torch tensor</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
uo &lt;- torch$ones(3L)
as_boolean(uo)              # tensor([True, True, True], dtype=torch.bool)

## End(Not run)
</code></pre>

<hr>
<h2 id='dataset_mnist_digits'>MNIST database of handwritten digits</h2><span id='topic+dataset_mnist_digits'></span>

<h3>Description</h3>

<p>Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test
set of 10,000 images.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataset_mnist_digits(ntrain = 60000L, ntest = 10000L, onehot = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dataset_mnist_digits_+3A_ntrain">ntrain</code></td>
<td>
<p>number of training samples</p>
</td></tr>
<tr><td><code id="dataset_mnist_digits_+3A_ntest">ntest</code></td>
<td>
<p>number of test samples</p>
</td></tr>
<tr><td><code id="dataset_mnist_digits_+3A_onehot">onehot</code></td>
<td>
<p>boolean</p>
</td></tr>
</table>

<hr>
<h2 id='dim.torch.Tensor'>Dimensions of a tensor</h2><span id='topic+dim.torch.Tensor'></span>

<h3>Description</h3>

<p>Get the dimensions of a tensor displaying it as a vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
dim(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dim.torch.Tensor_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of integers with the dimensions of the tensor
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
uo = torch$ones(3L, 5L)  # it is a 3x5 tensor
dim(uo)

## End(Not run)

</code></pre>

<hr>
<h2 id='install_pytorch'>Install PyTorch and its dependencies</h2><span id='topic+install_pytorch'></span>

<h3>Description</h3>

<p>Install PyTorch and its dependencies
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_pytorch(
  method = c("conda", "virtualenv", "auto"),
  conda = "auto",
  version = "default",
  envname = "r-torch",
  extra_packages = NULL,
  restart_session = TRUE,
  conda_python_version = "3.6",
  pip = FALSE,
  channel = "stable",
  cuda_version = NULL,
  dry_run = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_pytorch_+3A_method">method</code></td>
<td>
<p>Installation method. By default, &quot;auto&quot; automatically finds a
method that will work in the local environment. Change the default to force
a specific installation method. Note that the &quot;virtualenv&quot; method is not
available on <em>Windows</em> (as this isn't supported by <em>PyTorch</em>). Note also
that since this command runs without privillege the &quot;system&quot; method is
available only on <em>Windows</em>.</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_conda">conda</code></td>
<td>
<p>The path to a <code>conda</code> executable. Use <code>"auto"</code> to allow <code>reticulate</code> to
automatically find an appropriate <code>conda</code> binary. See <strong>Finding Conda</strong> for more details.</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_version">version</code></td>
<td>
<p>PyTorch version to install. The &quot;default&quot; version is <strong>1.4</strong>.
You can specify a specific <strong>PyTorch</strong> version with <code>version="1.2"</code>,
or <code>version="1.6"</code>.</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_envname">envname</code></td>
<td>
<p>Name of Python or conda environment to install within.
The default environment name is <code>r-torch</code>.</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_extra_packages">extra_packages</code></td>
<td>
<p>Additional Python packages to install along with
PyTorch. If more than one package use a character vector:
<code>c("pandas", "matplotlib")</code>.</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_restart_session">restart_session</code></td>
<td>
<p>Restart R session after installing (note this will
only occur within RStudio).</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_conda_python_version">conda_python_version</code></td>
<td>
<p>the <em>Python</em> version installed in the created <em>conda</em>
environment. Python <strong>3.4</strong> is installed by default. But you could specify for instance:
<code>conda_python_version="3.7"</code>.</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_pip">pip</code></td>
<td>
<p>logical</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_channel">channel</code></td>
<td>
<p>conda channel. The default channel is <code>stable</code>.
The alternative channel is <code>nightly</code>.</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_cuda_version">cuda_version</code></td>
<td>
<p>string for the cuda toolkit version to install. For example,
to install a specific CUDA version use <code>cuda_version="10.2"</code>.</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_dry_run">dry_run</code></td>
<td>
<p>logical, set to TRUE for unit tests, otherwise will execute
the command.</p>
</td></tr>
<tr><td><code id="install_pytorch_+3A_...">...</code></td>
<td>
<p>other arguments passed to <code><a href="reticulate.html#topic+conda-tools">reticulate::conda_install()</a></code> or
<code><a href="reticulate.html#topic+virtualenv-tools">reticulate::virtualenv_install()</a></code>.</p>
</td></tr>
</table>

<hr>
<h2 id='install_torch_extras'>Install additional Python packages alongside PyTorch</h2><span id='topic+install_torch_extras'></span>

<h3>Description</h3>

<p>This function is deprecated. Use the <code>extra_packages</code> argument in function
<code>install_pytorch()</code> to install additional packages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>install_torch_extras(packages, conda = "auto")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="install_torch_extras_+3A_packages">packages</code></td>
<td>
<p>Python packages to install</p>
</td></tr>
<tr><td><code id="install_torch_extras_+3A_conda">conda</code></td>
<td>
<p>Path to conda executable (or &quot;auto&quot; to find conda using the PATH
and other conventional install locations). Only used when PyTorch is
installed within a conda environment.</p>
</td></tr>
</table>

<hr>
<h2 id='is_tensor'>Is the object a tensor</h2><span id='topic+is_tensor'></span>

<h3>Description</h3>

<p>Determine if the object is a tensor by looking inheritance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_tensor(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is_tensor_+3A_obj">obj</code></td>
<td>
<p>an object</p>
</td></tr>
</table>

<hr>
<h2 id='length.torch.Tensor'>Length of a tensor.</h2><span id='topic+length.torch.Tensor'></span>

<h3>Description</h3>

<p>This function is equivalent to torch$numel()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
length(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="length.torch.Tensor_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>the number of elements of a tensor as an integer
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
uo = torch$ones(3L, 5L)   # tensor with 15 elements
length(uo)

## End(Not run)

</code></pre>

<hr>
<h2 id='log.torch.Tensor'>Logarithm of a tensor given the tensor and the base</h2><span id='topic+log.torch.Tensor'></span>

<h3>Description</h3>

<p>Logarithm of a tensor given the tensor and the base
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
log(x, base = exp(1L))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log.torch.Tensor_+3A_x">x</code></td>
<td>
<p>a tensor</p>
</td></tr>
<tr><td><code id="log.torch.Tensor_+3A_base">base</code></td>
<td>
<p>the base of the logarithm</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- torch$tensor(c(512, 1024, 2048, 4096))   # tensor([ 9., 10., 11., 12.])
base &lt;- 2
log(x, base)

x &lt;- torch$tensor(c(1, 10, 100, 1000))         # tensor([0., 1., 2., 3.])
log(x, 10)

## End(Not run)
</code></pre>

<hr>
<h2 id='log10.torch.Tensor'>Logarithm of a tensor in base 10</h2><span id='topic+log10.torch.Tensor'></span>

<h3>Description</h3>

<p>Logarithm of a tensor in base 10
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
log10(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log10.torch.Tensor_+3A_x">x</code></td>
<td>
<p>a tensor</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- torch$tensor(c(1, 10, 100, 1000))     # tensor([0., 1., 2., 3.])

## End(Not run)
</code></pre>

<hr>
<h2 id='log2.torch.Tensor'>Logarithm of a tensor in base 2</h2><span id='topic+log2.torch.Tensor'></span>

<h3>Description</h3>

<p>Logarithm of a tensor in base 2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
log2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="log2.torch.Tensor_+3A_x">x</code></td>
<td>
<p>a tensor</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x &lt;- torch$tensor(c(512, 1024, 2048, 4096))   # tensor([ 9., 10., 11., 12.])

## End(Not run)
</code></pre>

<hr>
<h2 id='logical_and'>Logical AND of two tensors</h2><span id='topic+logical_and'></span><span id='topic++26.torch.Tensor'></span>

<h3>Description</h3>

<p>There is not equivalent function in PyTorch for this generic.
To generate this generic we use the function <code>np$logical_and()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
x &amp; y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logical_and_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="logical_and_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of booleans representing the logical result of the comparison.
False to represent 0, and True to represent 1 in a tensor of data type <code>torch$uint8</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
A &lt;- torch$BoolTensor(list(0L, 1L))
B &lt;- torch$BoolTensor(list(1L, 0L))
C &lt;- torch$BoolTensor(list(1L, 1L))
A &amp; B
C &amp; A
B &amp; C

## End(Not run)
</code></pre>

<hr>
<h2 id='logical_not'>Logical NOT of a tensor</h2><span id='topic+logical_not'></span><span id='topic++21.torch.Tensor'></span>

<h3>Description</h3>

<p>There is not equivalent function in PyTorch for this generic.
To generate This generic we use the function <code>np$logical_not(x)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
!x
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logical_not_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of booleans, where False corresponds to 0, and 1 to True
in a tensor of data type <code>torch$bool</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
A &lt;- torch$ones(5L)
!A

Z &lt;- torch$zeros(5L)
!Z

## End(Not run)
</code></pre>

<hr>
<h2 id='logical_or'>Logical OR of two tensors</h2><span id='topic+logical_or'></span><span id='topic++7C.torch.Tensor'></span>

<h3>Description</h3>

<p>There is not equivalent function in PyTorch for this generic.
To generate this generic we use the function <code>np$logical_or()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
x | y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logical_or_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="logical_or_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of booleans representing the logical result of the comparison.
False to represent 0, and True to represent 1 in a tensor of data type <code>torch$uint8</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
A &lt;- torch$BoolTensor(list(0L, 1L))
B &lt;- torch$BoolTensor(list(1L, 0L))
C &lt;- torch$BoolTensor(list(1L, 1L))
A | B
C | A
B | C

## End(Not run)
</code></pre>

<hr>
<h2 id='make_copy'>Make copy of tensor, numpy array or R array</h2><span id='topic+make_copy'></span>

<h3>Description</h3>

<p>A copy of an array or tensor might be needed to prevent warnings
by new PyTorch versions on overwriting the numpy object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_copy(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_copy_+3A_object">object</code></td>
<td>
<p>a torch tensor or numpy array or R array</p>
</td></tr>
<tr><td><code id="make_copy_+3A_...">...</code></td>
<td>
<p>additional parameters</p>
</td></tr>
</table>

<hr>
<h2 id='not_equal_to'>Compare two tensors if not equal</h2><span id='topic+not_equal_to'></span><span id='topic++21+3D.torch.Tensor'></span>

<h3>Description</h3>

<p>This generic is approximately similar to <code>torch$ne(a, b)</code>, with the
difference that the generic returns a tensor of booleans instead of
a tensor of data type <code>torch$uint8</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'torch.Tensor'
x != y
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="not_equal_to_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="not_equal_to_+3A_y">y</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A tensor of booleans, where False corresponds to 0, and 1 to True
in a tensor of data type <code>torch$bool</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
a &lt;- torch$Tensor(list(1, 1, 1))
b &lt;- torch$Tensor(list(2, 2, 2))
a != b

## End(Not run)
</code></pre>

<hr>
<h2 id='one_tensor_op'>One tensor operation</h2><span id='topic+one_tensor_op'></span><span id='topic+exp.torch.Tensor'></span>

<h3>Description</h3>

<p>One tensor operation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>one_tensor_op(x)

## S3 method for class 'torch.Tensor'
exp(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="one_tensor_op_+3A_x">x</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>torch.Tensor</code>: Exponential of a tensor
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
A &lt;- torch$ones(c(60000L, 1L, 28L, 28L))
dim(A)

## End(Not run)
</code></pre>

<hr>
<h2 id='reexports'>Objects exported from other packages</h2><span id='topic+reexports'></span><span id='topic+import'></span><span id='topic+import_builtins'></span><span id='topic+import_from_path'></span><span id='topic+dict'></span><span id='topic+tuple'></span><span id='topic+np_array'></span><span id='topic+array_reshape'></span><span id='topic+iterate'></span><span id='topic+py_len'></span><span id='topic++25as+25'></span><span id='topic+iter_next'></span><span id='topic+py_run_string'></span><span id='topic+py_eval'></span><span id='topic+r_to_py'></span><span id='topic+py_to_r'></span><span id='topic+py_get_item'></span><span id='topic+use_python'></span><span id='topic+use_virtualenv'></span><span id='topic+use_condaenv'></span>

<h3>Description</h3>

<p>These objects are imported from other packages. Follow the links
below to see their documentation.
</p>

<dl>
<dt>reticulate</dt><dd><p><code><a href="reticulate.html#topic+with-as-operator">%as%</a></code>, <code><a href="reticulate.html#topic+array_reshape">array_reshape</a></code>, <code><a href="reticulate.html#topic+dict">dict</a></code>, <code><a href="reticulate.html#topic+import">import</a></code>, <code><a href="reticulate.html#topic+import">import_builtins</a></code>, <code><a href="reticulate.html#topic+import">import_from_path</a></code>, <code><a href="reticulate.html#topic+iterate">iter_next</a></code>, <code><a href="reticulate.html#topic+iterate">iterate</a></code>, <code><a href="reticulate.html#topic+np_array">np_array</a></code>, <code><a href="reticulate.html#topic+py_run">py_eval</a></code>, <code><a href="reticulate.html#topic+py_get_item">py_get_item</a></code>, <code><a href="reticulate.html#topic+py_len">py_len</a></code>, <code><a href="reticulate.html#topic+py_run">py_run_string</a></code>, <code><a href="reticulate.html#topic+r-py-conversion">py_to_r</a></code>, <code><a href="reticulate.html#topic+r-py-conversion">r_to_py</a></code>, <code><a href="reticulate.html#topic+tuple">tuple</a></code>, <code><a href="reticulate.html#topic+use_python">use_condaenv</a></code>, <code><a href="reticulate.html#topic+use_python">use_python</a></code>, <code><a href="reticulate.html#topic+use_python">use_virtualenv</a></code></p>
</dd>
</dl>

<hr>
<h2 id='rTorch'>PyTorch for R</h2><span id='topic+rTorch'></span>

<h3>Description</h3>

<p>PyTorch bindings for R
</p>

<hr>
<h2 id='shape'>Tensor shape</h2><span id='topic+shape'></span>

<h3>Description</h3>

<p>Tensor shape
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shape(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shape_+3A_...">...</code></td>
<td>
<p>Tensor dimensions</p>
</td></tr>
</table>

<hr>
<h2 id='tensor_ops'>Two tensor operations</h2><span id='topic+tensor_ops'></span><span id='topic++5E.torch.Tensor'></span>

<h3>Description</h3>

<p>Two tensor operations
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tensor_ops(a, b)

## S3 method for class 'torch.Tensor'
a ^ b
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tensor_ops_+3A_a">a</code></td>
<td>
<p>tensor</p>
</td></tr>
<tr><td><code id="tensor_ops_+3A_b">b</code></td>
<td>
<p>tensor</p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>torch.Tensor</code>: A tensor 'a' to the power of 'b'
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
a &lt;- torch$Tensor(list(1, 1, 1))
b &lt;- torch$Tensor(list(2, 2, 2))
s &lt;- 2.0
a + b
b - a
a * b
a / s
a == b
a == a
a != a
x &lt;- torch$Tensor(list(list(2, 2, 2), list(4, 4, 4)))
y &lt;- torch$Tensor(list(list(1, 2, 1), list(3, 4, 5)))
x &gt; y
x &lt; y
x &gt;= y
y &lt;= x
diag &lt;- torch$eye(3L)
zeros &lt;- torch$zeros(c(3L, 3L))
diag &amp; zeros
diag &amp; diag
diag | diag
zeros | zeros
zeros &amp; zeros
diag &amp; zeros
diag | zeros

## End(Not run)
## Not run: 
x &lt;- torch$arange(1,11)
torch$pow(x, 2)      #     x^(2)
torch$pow(x, -2)     #     x^(1/2)

## End(Not run)

</code></pre>

<hr>
<h2 id='torch'>Main PyTorch module</h2><span id='topic+torch'></span><span id='topic+np'></span><span id='topic+torchvision'></span>

<h3>Description</h3>

<p>Interface to main PyTorch module. Provides access to top level classes
</p>
<p>Interface to numpy module.
</p>
<p>Interface to Torchvision module.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>torch

np

torchvision
</code></pre>


<h3>Format</h3>

<p>PyTorch module
</p>
<p>numpy module
</p>
<p>Torchvision module
</p>

<hr>
<h2 id='torch_config'>Torch configuration information</h2><span id='topic+torch_config'></span><span id='topic+torch_version'></span>

<h3>Description</h3>

<p>Torch configuration information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>torch_config()

torch_version()
</code></pre>


<h3>Value</h3>

<p>List with information on the current configuration of PyTorch.
You can determine whether PyTorch was found using the <code>available</code>
member (other members vary depending on whether <code>available</code> is <code>TRUE</code>
or <code>FALSE</code>)
</p>

<hr>
<h2 id='torch_extract_opts'>Tensor extract options</h2><span id='topic+torch_extract_opts'></span>

<h3>Description</h3>

<p>Tensor extract options
</p>


<h3>Usage</h3>

<pre><code class='language-R'>torch_extract_opts(
  style = getOption("torch.extract.style"),
  ...,
  one_based = getOption("torch.extract.one_based", TRUE),
  inclusive_stop = getOption("torch.extract.inclusive_stop", TRUE),
  disallow_out_of_bounds = getOption("torch.extract.dissallow_out_of_bounds", TRUE),
  warn_tensors_passed_asis = getOption("torch.extract.warn_tensors_passed_asis", TRUE),
  warn_negatives_pythonic = getOption("torch.extract.warn_negatives_pythonic", TRUE)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="torch_extract_opts_+3A_style">style</code></td>
<td>
<p>one of <code>NULL</code> (the default) <code>"R"</code> or <code>"python"</code>. If supplied,
this overrides all other options. <code>"python"</code> is equivalent to all the other
arguments being <code>FALSE</code>. <code>"R"</code> is equivalent to
<code>warn_tensors_passed_asis</code> and <code>warn_negatives_pythonic</code>
set to <code>FALSE</code></p>
</td></tr>
<tr><td><code id="torch_extract_opts_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="torch_extract_opts_+3A_one_based">one_based</code></td>
<td>
<p>TRUE or FALSE, if one-based indexing should be used</p>
</td></tr>
<tr><td><code id="torch_extract_opts_+3A_inclusive_stop">inclusive_stop</code></td>
<td>
<p>TRUE or FALSE, if slices like <code>start:stop</code> should be
inclusive of <code>stop</code></p>
</td></tr>
<tr><td><code id="torch_extract_opts_+3A_disallow_out_of_bounds">disallow_out_of_bounds</code></td>
<td>
<p>TRUE or FALSE, whether checks are performed on
the slicing index to ensure it is within bounds.</p>
</td></tr>
<tr><td><code id="torch_extract_opts_+3A_warn_tensors_passed_asis">warn_tensors_passed_asis</code></td>
<td>
<p>TRUE or FALSE, whether to emit a warning the
first time a tensor is supplied to <code>[</code> that tensors are passed as-is, with
no R to python translation</p>
</td></tr>
<tr><td><code id="torch_extract_opts_+3A_warn_negatives_pythonic">warn_negatives_pythonic</code></td>
<td>
<p>TRUE or FALSE, whether to emit
a warning the first time a negative number is supplied to <code>[</code> about the
non-standard (python-style) interpretation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an object with class &quot;torch_extract_opts&quot;, suitable for passing to
<code style="white-space: pre;">&#8288;[.torch.tensor()&#8288;</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

x &lt;- torch$arange(1L, 10L)

opts &lt;-  torch_extract_opts("R")
x[1, options = opts]

# or for more fine-grained control
opts &lt;- torch_extract_opts(
    one_based = FALSE,
    warn_tensors_passed_asis = FALSE,
    warn_negatives_pythonic = FALSE
)
x[0:2, options = opts]

## End(Not run)
</code></pre>

<hr>
<h2 id='torch_size'>Size of a torch tensor object</h2><span id='topic+torch_size'></span>

<h3>Description</h3>

<p>Get the size of a torch tensor or of torch.size object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>torch_size(obj)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="torch_size_+3A_obj">obj</code></td>
<td>
<p>a torch tensor object</p>
</td></tr>
</table>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
