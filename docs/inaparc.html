<!DOCTYPE html><html><head><title>Help for package inaparc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {inaparc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#inaparc-package'><p>Initialization Algorithms for Partitioning Cluster Analysis</p></a></li>
<li><a href='#aldaoud'>
<p>Initialization of cluster prototypes using Al-Daoud's algorithm</p></a></li>
<li><a href='#ballhall'>
<p>Initialization of cluster prototypes using Ball &amp; Hall's algorithm</p></a></li>
<li><a href='#crsamp'>
<p>Initialization of cluster prototypes using the centers of random samples</p></a></li>
<li><a href='#figen'>
<p>Initialization of membership degrees over class range of a selected feature</p></a></li>
<li><a href='#firstk'>
<p>Initialization of cluster prototypes using the first k objects</p></a></li>
<li><a href='#forgy'>
<p>Initialization of cluster prototypes using Forgy's algorithm</p></a></li>
<li><a href='#get.algorithms'>
<p>Get the names of algorithms in &lsquo;inaparc&rsquo;</p></a></li>
<li><a href='#hartiganwong'>
<p>Initialization of cluster prototypes using Hartigan-Wong's algorithm</p></a></li>
<li><a href='#imembones'>
<p>Initialization of a crisp membership matrix using a selected cluster</p></a></li>
<li><a href='#imembrand'>
<p>Initialization of membership matrix using simple random sampling</p></a></li>
<li><a href='#inofrep'>
<p>Initialization of cluster prototypes using Inofrep algorithm</p></a></li>
<li><a href='#inscsf'>
<p>Initialization cluster prototypes using Inscsf algorithm</p></a></li>
<li><a href='#insdev'>
<p>Initialization of cluster prototypes using Insdev algorithm</p></a></li>
<li><a href='#is.inaparc'>
<p>Checking the object class for &lsquo;inaparc&rsquo;</p></a></li>
<li><a href='#kkz'>
<p>Initialization of cluster prototypes using KKZ algorithm</p></a></li>
<li><a href='#kmpp'>
<p>Initialization of cluster prototypes using K-means++ algorithm</p></a></li>
<li><a href='#ksegments'>
<p>Initialization of cluster prototypes using the centers of <var>k</var> segments</p></a></li>
<li><a href='#ksteps'>
<p>Initialization of cluster prototypes using the centers of <var>k</var> blocks</p></a></li>
<li><a href='#lastk'>
<p>Initialization of cluster prototypes using the last <var>k</var> objects</p></a></li>
<li><a href='#lhsmaximin'>
<p>Initialization of cluster prototypes using Maximin LHS</p></a></li>
<li><a href='#lhsrandom'>
<p>Initialization of cluster prototypes using random LHS</p></a></li>
<li><a href='#maximin'>
<p>Initialization of cluster prototypes using Maximin algorithm</p></a></li>
<li><a href='#mscseek'>
<p>Initialization of cluster prototypes using the modified SCS algorithm</p></a></li>
<li><a href='#rsamp'>
<p>Initialization of cluster prototypes using simple random sampling</p></a></li>
<li><a href='#rsegment'>
<p>Initialization of cluster prototypes using a randomly selected segment</p></a></li>
<li><a href='#scseek'>
<p>Initialization of cluster prototypes using SCS algorithm</p></a></li>
<li><a href='#scseek2'>
<p>Initialization of cluster prototypes using SCS algorithm over a selected feature</p></a></li>
<li><a href='#spaeth'>
<p>Initialization of cluster prototypes using Spaeth's algorithm</p></a></li>
<li><a href='#ssamp'>
<p>Initialization of cluster prototypes using systematic random sampling</p></a></li>
<li><a href='#topbottom'>
<p>Initialization of cluster prototypes using the top and bottom objects</p></a></li>
<li><a href='#uniquek'>
<p>Initialization of cluster prototypes over the unique values</p></a></li>
<li><a href='#ursamp'>
<p>Initialization of cluster prototypes using random sampling on each future</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Initialization Algorithms for Partitioning Cluster Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-06-15</td>
</tr>
<tr>
<td>Author:</td>
<td>Zeynel Cebeci [aut, cre],
  Cagatay Cebeci [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Zeynel Cebeci &lt;zcebeci@cukurova.edu.tr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Partitioning clustering algorithms divide data sets into k subsets or partitions so-called clusters. They require some initialization procedures for starting the algorithms. Initialization of cluster prototypes is one of such kind of procedures for most of the partitioning algorithms. Cluster prototypes are the centers of clusters, i.e. centroids or medoids, representing the clusters in a data set. In order to initialize cluster prototypes, the package 'inaparc' contains a set of the functions that are the implementations of several linear time-complexity and loglinear time-complexity methods in addition to some novel techniques. Initialization of fuzzy membership degrees matrices is another important task for starting the probabilistic and possibilistic partitioning algorithms. In order to initialize membership degrees matrices required by these algorithms, a number of functions based on some traditional and novel initialization techniques are also available in the package 'inaparc'.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>kpeaks, lhs, stats, methods</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-06-16 12:41:30 UTC; user1</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-06-16 13:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='inaparc-package'>Initialization Algorithms for Partitioning Cluster Analysis</h2><span id='topic+inaparc-package'></span>

<h3>Description</h3>

<p>Partitioning clustering algorithms divide data sets into k subsets or partitions which are so-called clusters. They require some initialization procedures for starting to partition the data sets. Initialization of cluster prototypes is one of such kind of procedures for most of the partitioning algorithms. Cluster prototypes are the data elements, i.e. centroids or medoids, representing the clusters in a data set. In order to initialize cluster prototypes, the package &lsquo;<span class="pkg">inaparc</span>&rsquo; contains a set of the functions that are the implementations of widely-used algorithms in addition to some novel techniques. Initialization of fuzzy membership degrees matrices is another important task for starting the probabilistic and possibilistic partitioning algorithms. In order to initialize membership degrees matrices required by these algorithms, the package &lsquo;<span class="pkg">inaparc</span>&rsquo; contains a number of functions for most of the data independent and dependent initialization techniques (Borgelt, 2005) which are categorized as the linear time-complexity and loglinear time complexity-initialization methods in Celebi et al (2013). 
</p>


<h3>Details</h3>

<p>Clustering is one of the most widely used exploratory statistical analysis in data mining. Its goal is to explore the groups of objects that are similar to each other within the group but different from the objects in other groups. According to a common taxonomy, the existing clustering algorithms are classified in two groups: Hierarchical and Non-hierarchical (or flat) algorithms (Rokah &amp; Maimon, 2005). As a dominant subfamily of non-hierarchical algorithms, the partitioning clustering algorithms divide data objects into a pre-defined number of clusters, which are the non-overlapping subsets of data. Although the choice of an appropriate algorithm for any clustering task depends on many criteria or purposes. When data size and dimensions are the concerned criteria, the non-hierarchical algorithms may be more practical way of clustering the large size and high dimensional data sets because they quickly process the large data sets when compared to the hierarchical clustering algorithms.
</p>
<p>As the most crowded group of the partitioning clustering tools, the prototype-based algorithms partition data objects into clusters in which each data object is more similar to its prototype than the prototypes of other clusters. On clustering context, a prototype is a typical data item that represents or characterizes a cluster (Tan et al. 2006). Usually, it can be regarded as the most central data point in a data subspace so-called cluster. The prototype of a cluster is so often a centroid, i.e., the mean of all the objects in a cluster. On the other hand, centroids can not be computed for non-numeric data, i.e., on nominal or ordinal data. In such case, medoids can be used as the prototypes of clusters (Tan et al, 2006). 
</p>
<p>Initialization or seeding is a process for selecting the starting values of cluster prototypes matrix which serves the initial representatives of clusters. It is an important task in partitioning cluster analysis because it is known that the final clustering result is to be highly sensitive to the initial prototypes of the clusters (Khan, 2012). When the prototypes are chosen to be equal or close to the actual centers of clusters in a data set, the partitioning converges quickly and yields quality results. Contrarily, poor initializations of prototype matrix may result with no-good quality of final partitions. 
</p>
<p>In fuzzy and possibilistic clustering, an object is a member of all clusters in varying degrees of membership instead of being a member of only one cluster. A membership degrees matrix is required by the fuzzy clustering algorithms, i.e., Fuzzy C-means (FCM) (Bezdek, 1981). Initialization of membership degrees for starting FCM and its various variants must satisfy the following constraints:  
</p>
<p style="text-align: center;"><code class="reqn">u_{ij}\in[0,1]; 1\le i \le n, 1\le j \le k</code>
</p>

<p style="text-align: center;"><code class="reqn">\sum\limits_{j=1}^k u_{ij}=1; 1\le i \le n</code>
</p>

<p style="text-align: center;"><code class="reqn">0&lt;\sum\limits_{i=1}^n u_{ij} &lt; n ; 1\le j \le k</code>
</p>

<p>Membership degrees matrices are usually initialized with the techniques based on random number generating as the function <code><a href="#topic+imembrand">imembrand</a></code> does. In addition to these common techiques, a novel technique using the information from synthetically produced classes over a selected feature is provided in the package &lsquo;<span class="pkg">inaparc</span>&rsquo;. The novel technique which is implemented in <code><a href="#topic+figen">figen</a></code> may contribute to the fast convergence of the clustering algorithms when compared to the random sampling based techniques. The package also serves the functions for building hard or crisp membership degrees which can be used for testing purposes.
</p>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci</p>


<h3>References</h3>

<p>Bezdek J.C. (1981). Pattern recognition with fuzzy objective function algorithms. Plenum, NY, 256 p. &lt;ISBN:0306406713&gt;
</p>
<p>Borgelt, C., (2005). <em>Prototype-based classification and clustering</em>. Habilitationsschrift zur Erlangung der Venia legendi fuer Informatik, vorgelegt der Fakultaet fuer Informatik der Otto-von-Guericke-Universitaet Magdeburg, Magdeburg, 22 June 2005. url:<a href="https://borgelt.net/habil/pbcc.pdf">https://borgelt.net/habil/pbcc.pdf</a>
</p>
<p>Cebeci, Z. (2018). Initialization of Membership Degree Matrix for Fast Convergence of Fuzzy C-Means Clustering&quot;, In Proc. of <em>2018 International Conference on Artificial Intelligence and Data Processing (IDAP)</em>, IEEE, Sep. 2018, pp. 1-5., <a href="https://doi.org/10.1109/IDAP.2018.8620920">doi:10.1109/IDAP.2018.8620920</a>
</p>
<p>Cebeci, Z., Sahin, M. &amp; Cebeci, C. (2018). Data dependent techniques for initialization of cluster prototypes in partitioning cluster analysis. In Proc. of <em>4th International Conference on Engineering and Natural Science</em>, Kiev, Ukraine, May 2018. pp. 12-22. 
</p>
<p>Rokah, L. &amp; Maimon, O. (2005). Clustering methods. In <em>Data Mining and Knowledge Discovery Handbook (ed. O. Maimon)</em>, Springer US. pp. 321-352. <a href="https://doi.org/10.1.1.149.9326">doi:10.1.1.149.9326</a>
</p>
<p>Tan, P. N., Steinbach, M., &amp; Kumar, V. (2006). Cluster analysis: Basic concepts and algorithms. In <em>Introduction to Data Mining</em>. Pearson Addison Wesley. url:<a href="https://www-users.cse.umn.edu/~kumar/dmbook/ch8.pdf">https://www-users.cse.umn.edu/~kumar/dmbook/ch8.pdf</a>
</p>
<p>Khan, F. (2012). An initial seed selection algorithm for k-means clustering of georeferenced data to improve replicability of cluster assignments for mapping application. <em>Applied Soft Computing</em>, 12 (11) : 3698-3700. <a href="https://doi.org/10.1016/j.asoc.2012.07.021">doi:10.1016/j.asoc.2012.07.021</a>
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+imembones">imembones</a></code>,
<code><a href="#topic+imembrand">imembrand</a></code>,
<code><a href="#topic+figen">figen</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+is.inaparc">is.inaparc</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>

<hr>
<h2 id='aldaoud'>
Initialization of cluster prototypes using Al-Daoud's algorithm
</h2><span id='topic+aldaoud'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the variance-based algorithm proposed by Al-Daoud (Al-Daoud, 2005). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aldaoud(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="aldaoud_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="aldaoud_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>At first, the algorithm finds the feature having the greatest variance and sorts the data set on this feature in any order. Then it divides the data set into <code>n/k</code>-length <var>k</var> segments. The medians of the segments are assigned as the protoypes of clusters. Al-Daoud's algorithm is likely to be effective only for data sets in which the variability is mostly on one dimension because it considers only one feature with the highest variance (Celebi et al, 2013).
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>sfidx</code></td>
<td>
<p>an integer for the column index of the feature with the highest variance.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string for the type of used centroid to determine the cluster prototypes. It is &lsquo;med&rsquo; with this function.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Al-Daoud, M.B. (2005). A new algorithm for cluster initialization, in <em>Proc. of 2nd World Enformatika Conf.</em>, pp.74-76.
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- aldaoud(iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='ballhall'>
Initialization of cluster prototypes using Ball &amp; Hall's algorithm
</h2><span id='topic+ballhall'></span>

<h3>Description</h3>

<p>Initializes the prototypes of clusters by using the cluster seeding algorithm which has been proposed by Ball &amp; Hall (1967).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ballhall(x, k, tv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ballhall_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="ballhall_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
<tr><td><code id="ballhall_+3A_tv">tv</code></td>
<td>
<p>a number to be used as <var>T</var>, a threshold distance value. It is directly input by the user. Also it is possible to compute <var>T</var> with the following options of <code>tv</code> argument:
</p>

<ul>
<li> <p><var>T</var> is the mean of differences between the consecutive pairs of objects with the option <span class="option">cd1</span>.  
</p>
</li>
<li> <p><var>T</var> is the minimum of differences between the consecutive pairs of objects with the option <span class="option">cd2</span>.     </p>
</li>
<li> <p><var>T</var> is the mean of Euclidean distances between the consecutive pairs of objects divided into <var>k</var> with the option <span class="option">md</span>. This is the default if <code>tv</code> is not supplied by the user.
</p>
</li>
<li> <p><var>T</var> is the range of maximum and minimum of Euclidean distances between the consecutive pairs of objects divided into <var>k</var> with the option <span class="option">mm</span>.
</p>
</li></ul>

</td></tr>
</table>


<h3>Details</h3>

<p>In the Ball and Hall's algorithm (Ball &amp; Hall, 1967), the center of gravity of data is assigned as the prototype of first cluster. It then passes the data objects in arbitrary order and takes an object as the next prototype if it is <var>T</var> units far from the previously selected prototypes. The purpose of using <var>T</var>, the distance threshold, is to make the cluster protoypes at least <var>T</var> units away from each other. Ball &amp; Hall's method may be sensitive to the order of data, and moreover, deciding for an appropriate value of <var>T</var> is is also difficult (Celebi et al, 2013). As the solutions to this problem, the function <code>ballhall</code> in this package computes a <var>T</var> value using some distance measures, if it is not specified by the user (for details, see the section &lsquo;Arguments&rsquo; above.)
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string for the type of used centroid. It is &lsquo;obj&rsquo; with this function because the created cluster prototypes matrix contains the selected objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Ball, G.H. &amp; Hall, D.J. (1967). A clustering technique for summarizing multivariate data, <em>Systems Res. &amp; Behavioral Sci.</em>, 12 (2): 153-155.
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
# Run with a user described threshold value
v1 &lt;- ballhall(x=iris[,1:4], k=5, tv=0.6)$v
print(v1)

# Run with the internally computed default threshold value
v2 &lt;- ballhall(x=iris[,1:4], k=5)$v
print(v2)
</code></pre>

<hr>
<h2 id='crsamp'>
Initialization of cluster prototypes using the centers of random samples
</h2><span id='topic+crsamp'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the centers of <var>r</var> data objects. The options for centers are mean and median of the sampled objects in addition to the objects nearest to the mean of the sampled objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crsamp(x, k, r, ctype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crsamp_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="crsamp_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
<tr><td><code id="crsamp_+3A_r">r</code></td>
<td>
<p>an integer for the number of objects to be sampled from the data set. If missing, the default value is 2.</p>
</td></tr>
<tr><td><code id="crsamp_+3A_ctype">ctype</code></td>
<td>
<p>a string for the type of centroids to be computed. The options are &lsquo;avg&rsquo; for average, &lsquo;med&rsquo; for median or &lsquo;obj&rsquo; for the object nearest to the average. The default is &lsquo;obj&rsquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Instead of sampling only one random object as the function <code><a href="#topic+rsamp">rsamp</a></code> does, the function <code>arsamp</code> randomly samples <var>r</var> data objects, and then computes the average and median of these sampled objects. The nearest data object to the mean of sampled objects is also found. If <code>ctype</code> is <span class="option">avg</span> the mean of the sampled <var>r</var> objects is assigned as the prototype of first cluster. When <code>ctype</code> is <span class="option">med</span> the median of the sampled <var>r</var> objects is assigned as the prototype of first cluster. If the  <code>ctype</code> is <span class="option">obj</span>, the nearest object to the mean of sampled <var>r</var> objects is assigned as the the prototype of first cluster. The same process is repeated for all of the remaining clusters. The logic behind this novel technique is to avoid to select the outliers in the data set which may occur with random sampling for only one object.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string for the type of used centroid to build the cluster prototypes matrix.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
# Prototypes are the objects nearest to the mean of
# five randomly sampled objects for each cluster
res &lt;- crsamp(iris[,1:4], k=5, r=5, ctype="obj")
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='figen'>
Initialization of membership degrees over class range of a selected feature
</h2><span id='topic+figen'></span>

<h3>Description</h3>

<p>Initializes the membership degrees matrix by using the class range of the coefficient of variation of a selected feature in the data set being processed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>figen(x, k, mtype, sfidx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="figen_+3A_x">x</code></td>
<td>
<p>an data.frame or matrix for the data set.</p>
</td></tr>
<tr><td><code id="figen_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
<tr><td><code id="figen_+3A_mtype">mtype</code></td>
<td>
<p>a character representing the type of membership degrees to be generated. The default type is <span class="option">f</span> for generating fuzzy membership matrix. Use <span class="option">h</span> for creating an hard (crisp) membership matrix.</p>
</td></tr>
<tr><td><code id="figen_+3A_sfidx">sfidx</code></td>
<td>
<p>an integer for the column index of a selected feature. The default is the column index of a feature whose coefficient of variation is the maximum among all features in the data set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>figen</code> generates a numeric matrix containing the fuzzy initial membership degrees.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>a numeric matrix containing the initial membership degrees.</p>
</td></tr>
<tr><td><code>sfidx</code></td>
<td>
<p>an integer for the column index of the selected feature, which used for random sampling.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Cebeci, Z. (2018), &quot;Initialization of Membership Degree Matrix for Fast Convergence of Fuzzy C-Means Clustering&quot;, In Proc. of <em>2018 International Conference on Artificial Intelligence and Data Processing (IDAP)</em>, IEEE, Sep. 2018, pp. 1-5., doi: <a href="https:/doi.org/10.1109/IDAP.2018.8620920">10.1109/IDAP.2018.8620920</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imembrand">imembrand</a></code>,
<code><a href="#topic+imembones">imembones</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

# Generate a fuzzy membership matrix using the 1st feature
u &lt;- figen(iris[,1:4], k=5, sfidx=1)$u
head(u)
tail(u)

# Generate a fuzzy membership matrix using the internally determined feature
res &lt;- figen(iris[,1:4], k=5)
u &lt;- res$u
head(u)
tail(u)
</code></pre>

<hr>
<h2 id='firstk'>
Initialization of cluster prototypes using the first k objects
</h2><span id='topic+firstk'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the first <var>k</var> objects at the top of data set. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>firstk(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="firstk_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="firstk_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The technique so-called the <dfn>first method of MacQueen</dfn> (MacQueen, 1967) that simply selects the first <var>k</var> objects as the initial centroids. It is sensitive to the order of data (Celebi et al, 2013). If the data set is already sorted in any order it may result with no good initial prototypes because the data objects are close to each other in a sorted data set. Therefore, shuffling of the data set as a pre-processing step may improve the quality with this initialization technique.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of used centroid to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because it returns the selected objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates the object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>MacQueen, J.B. (1967). Some methods for classification and analysis of multivariate observations, in <em>Proc. of 5th Berkeley Symp. on Mathematical Statistics and Probability</em>, Berkeley, University of California Press, 1: 281-297. url:<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.308.8619&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.308.8619&amp;rep=rep1&amp;type=pdf</a>
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- firstk(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='forgy'>
Initialization of cluster prototypes using Forgy's algorithm
</h2><span id='topic+forgy'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes using the centers that are calculated with Forgy's algorithm (Forgy, 1965), which is the earliest algorithm for seeding the clusters in the standard K-means clustering. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>forgy(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="forgy_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="forgy_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this algorithm, each object in the data set is randomly assigned to one of <var>k</var> clusters, and then the mean of the objects assigned to the clusters are used as the initial cluster prototypes. The algorithm lacks of theoretical basis, and the clusters generated randomly may have no internal homogeneity (Celebi et al, 2013).
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;avg&rsquo; with this function because the cluster prototypes are the averages of sampled objects for each cluster.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates the object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Forgy, E.W. (1965). Cluster analysis of multivariate data: Efficiency vs interpretability of classification, <em>Biometrics</em>, 21 (3) : 768-769.
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- forgy(iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='get.algorithms'>
Get the names of algorithms in &lsquo;inaparc&rsquo;
</h2><span id='topic+get.algorithms'></span>

<h3>Description</h3>

<p>Gets the names of initialization algorithms which are available in the package &lsquo;<span class="pkg">inaparc</span>&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get.algorithms(atype="prototype")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get.algorithms_+3A_atype">atype</code></td>
<td>
<p>an string for the type of algorithms. The default value is <span class="option">prototype</span> for the names of algorithms for initialization of cluster prototypes. Use <span class="option">membership</span> for the names of algorithms for initialization of hard and fuzzy membership degrees.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector containing the names of algorithms.</p>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+inaparc-package">inaparc-package</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get.algorithms(atype="prototype")
get.algorithms(atype="membership")
</code></pre>

<hr>
<h2 id='hartiganwong'>
Initialization of cluster prototypes using Hartigan-Wong's algorithm
</h2><span id='topic+hartiganwong'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the Hartigan-Wong's algorithm (Hartigan &amp; Wong, 1979). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hartiganwong(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hartiganwong_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="hartiganwong_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Firstly, the algorithm computes the center of gravity of data and the distances of data objects to this center. Then, it sorts the data set in any order of the computed distances. The prototypes of <var>k</var> clusters are determined by using the formula (<code class="reqn">1 + (i-1) n/k)</code>), where <var>i</var> and <var>n</var> stand for the index of a cluster and the number of data rows, respectively. This algorithm leads to increase in the computational cost due to complexity of sorting, which is <code class="reqn">O(n\;log(n))</code> (Celebi et al, 2013).
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string for the type of used centroid to determine the cluster prototypes. It is &lsquo;obj&rsquo; with this function because the generated prototype matrix contains the selected objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Hartigan, J.A. &amp; Wong, W.A., (1979). Algorithm AS 136: A K-means clustering algorithm, <em>J of the Royal Statistical Society</em>, C 28 (1): 100-108.  
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- hartiganwong(iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='imembones'>
Initialization of a crisp membership matrix using a selected cluster
</h2><span id='topic+imembones'></span>

<h3>Description</h3>

<p>Initializes a crisp membership degrees matrix which is used to start a partitional clustering algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imembones(n, k, mtype, numseed)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imembones_+3A_n">n</code></td>
<td>
<p>an integer for the number of objects in the data set.</p>
</td></tr>
<tr><td><code id="imembones_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
<tr><td><code id="imembones_+3A_mtype">mtype</code></td>
<td>
<p>a string representing the type of crisp initialization for a selected cluster. The default is 'hrc'. The alternatives are 'hfc' in which all objects are assumed as the member of the first cluster, and 'hlc' in which all objects are assumed as the member of the last cluster.</p>
</td></tr>
<tr><td><code id="imembones_+3A_numseed">numseed</code></td>
<td>
<p>a number to be used for the seed of RNG.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>imembones</code> generates a numeric membership degrees matrix containing the crisp initial values for a selected cluster.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>a numeric matrix containing the crisp initial membership degrees of the objects to <var>k</var> clusters.</p>
</td></tr>
<tr><td><code>sfidx</code></td>
<td>
<p>an integer for the column index of the selected feature, which used for random sampling.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+imembrand">imembrand</a></code>,
<code><a href="#topic+figen">figen</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generate membership degrees matrix whose last column contains crisp
# membership degrees
u &lt;- imembones(n=10, k=5, mtype="hlc")$u
head(u)
tail(u)

# Generate membership degrees matrix using a seed number
u &lt;- imembones(n=10, k=5, mtype="hrc", numseed=123)$u
head(u)
tail(u)
</code></pre>

<hr>
<h2 id='imembrand'>
Initialization of membership matrix using simple random sampling
</h2><span id='topic+imembrand'></span>

<h3>Description</h3>

<p>Initializes the membership degrees matrix which is used to start a fuzzy and possibilistic partitioning clustering algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imembrand(n, k, mtype, numseed)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imembrand_+3A_n">n</code></td>
<td>
<p>an integer for the number of objects in the data set.</p>
</td></tr>
<tr><td><code id="imembrand_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
<tr><td><code id="imembrand_+3A_mtype">mtype</code></td>
<td>
<p>a string for any of three random initialization methods. The default method is <span class="option">f1</span> for fuzzy memberships. The options are <span class="option">f2</span> and <span class="option">f3</span> for fuzzy memberships and <span class="option">h</span> for hard (crisp) memberships.</p>
</td></tr>
<tr><td><code id="imembrand_+3A_numseed">numseed</code></td>
<td>
<p>a number to be used for the seed of RNG.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>imembrand</code> generates a numeric matrix containing the initial membership degrees by using simple random sampling technique.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>a numeric matrix containing the crisp initial membership degrees of <var>n</var> objects to <var>k</var> clusters.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+figen">figen</a></code>,
<code><a href="#topic+imembones">imembones</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
n &lt;- dim(iris)[1]

# Generate a fuzzy membership degrees matrix using default values
u &lt;- imembrand(n=n, k=5)$u
head(u)
tail(u)

# Generate a fuzzy membership degrees matrix using the method 3
u &lt;- imembrand(n=n, k=5, mtype="f3", numseed=123)$u
head(u)
tail(u)

# Generate a crisp membership degrees matrix 
u &lt;- imembrand(n=n, k=5, mtype="h")$u
head(u)
tail(u)
</code></pre>

<hr>
<h2 id='inofrep'>
Initialization of cluster prototypes using Inofrep algorithm
</h2><span id='topic+inofrep'></span>

<h3>Description</h3>

<p>Initializes cluster prototypes using Inofrep which is a novel prototypes initialization algorithm using the peaks of frequency polygon of a selected feature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inofrep(x, k, sfidx, sfpm, binrule, nbins, tcmethod, tc)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inofrep_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="inofrep_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
<tr><td><code id="inofrep_+3A_sfidx">sfidx</code></td>
<td>
<p>an integer specifying the column index of a selected feature which is used for determination of protoypes. If missing, it is internally determined by comparing the peak counts of all features in the data set, and the feature having maximum number of peaks is used as the selected feature.</p>
</td></tr>
<tr><td><code id="inofrep_+3A_sfpm">sfpm</code></td>
<td>
<p>a numeric two-column matrix containing the middle values and frequencies of the peaks of the selected feature, respectively.</p>
</td></tr>
<tr><td><code id="inofrep_+3A_binrule">binrule</code></td>
<td>
<p>a string containing the name of binning rule to generate the classes of frequency polygons of features in the data set. If missing, &lsquo;sqr&rsquo; rule is used as the default, and square root of the row number of data matrix is assigned as the number of classes to generate frequency polygons.</p>
</td></tr>
<tr><td><code id="inofrep_+3A_nbins">nbins</code></td>
<td>
<p>an integer for the number of classes of frequency polygons of features in the data set. It should be given if the binning rule &lsquo;usr&rsquo; is selected as the threshold computing method. If missing, it is internally assigned by the binning rule given as the input.</p>
</td></tr>
<tr><td><code id="inofrep_+3A_tcmethod">tcmethod</code></td>
<td>
<p>a string representing the threshold value computing method which is used to remove small peaks and empty classes. If missing, the defult method is 'min' which assigns the threshold value to the minimum frequency of the classes in a frequency polygon.</p>
</td></tr>
<tr><td><code id="inofrep_+3A_tc">tc</code></td>
<td>
<p>a numeric threshold value for removing the small peaks and empty classes. If missing, it is assigned internally by the used threshold computing method if it is described or 1 if it is not described.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Inofrep, <dfn>initialization on the frequency polygon</dfn> of a selected feature is a data dependent semi-deterministic initialization algorithm to improve the computational efficiency in prototype-based hard and fuzzy clustering. In the descriptive statistics, frequency polygons serve the structural information about the data. Since a cluster is a dense region of objects that is surrounded by a region of low density (Tan et al, 2006), the  peaks of a frequency polygon occur in the center of dense regions of data (Aitnouri et al, 1999). Based on this assumption, the algorithm Inofrep uses that the peak values in frequency polygons as the estimates of central tendency locations or the centres of different dense regions, namely the clusters in the data set. Thus, the peak values can be used as the prototypes of clusters.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>sfidx</code></td>
<td>
<p>an integer for the column index of the selected feature, which used for determination of cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string for the type of centroid, which used for assigning the cluster prototypes.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In order to supply the peak matrices directly, the functions <code><a href="kpeaks.html#topic+findpolypeaks">findpolypeaks</a></code> and <code><a href="kpeaks.html#topic+rmshoulders">rmshoulders</a></code> of the package &lsquo;<span class="pkg">kpeaks</span>&rsquo; can be used.
</p>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Aitnouri E.M., Wang, S., Ziou, D., Vaillancourt, J. &amp; Gagnon, L. (1999). An algorithm for determination of the number of modes for pdf estimation of multi-modal histograms, in <em>Proc. of Vision Interface '99</em>, Trois-Rivieres, Canada, May 1999, p. 368-374.  
</p>
<p>Tan, P. N., Steinbach, M., &amp; Kumar, V. (2006). Cluster analysis: Basic concepts and algorithms. In <em>Introduction to Data Mining</em>, Pearson Addison Wesley. <a href="https://www-users.cse.umn.edu/~kumar/dmbook/ch8.pdf">https://www-users.cse.umn.edu/~kumar/dmbook/ch8.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
# set 2nd feature as the selected feature
sfidx &lt;- 2

# generate frequency polygon for the selected feature with user-defined class number
hvals &lt;- kpeaks::genpolygon(iris[,sfidx], binrule="usr", nbins=20)

# Call findpolypeaks for calculating the peaks matrix for the peaks of frequency polygon
resfpp &lt;- kpeaks::findpolypeaks(hvals$mids, hvals$freqs, tcmethod="min")
sfpm &lt;- resfpp$pm

# Call inofrep with the peaks matrix calculated in previous step
v &lt;- inofrep(x=iris[,1:4], k=5, sfidx=sfidx, sfpm=sfpm)$v
print(v)
</code></pre>

<hr>
<h2 id='inscsf'>
Initialization cluster prototypes using Inscsf algorithm
</h2><span id='topic+inscsf'></span>

<h3>Description</h3>

<p>Initializes cluster prototypes with <code>Inscsf</code> which is a novel prototype initialization algorithm using a selected central tendency measure of a selected feature. For reducing the computational complexity and increasing the accuracy in initialization, the algorithm works on only one feature which can be selected according to its importance in clustering. Furthermore, with a selection mechanism using the distribution of data the algorithm also automatically decides what type of center measure should be used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inscsf(x, k, sfidx, ctype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="inscsf_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="inscsf_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
<tr><td><code id="inscsf_+3A_sfidx">sfidx</code></td>
<td>
<p>an integer specifying the column index of the selected feature. If missing, it is internally determined by comparing the number of unique values for all the features in the data set. The feature having the maximum number of unique values is used as the selected feature.</p>
</td></tr>
<tr><td><code id="inscsf_+3A_ctype">ctype</code></td>
<td>
<p>a string for the type of the selected center. The options are &lsquo;avg&rsquo; for average, &lsquo;med&rsquo; for median or &lsquo;mod&rsquo; for mode. The default value is &lsquo;avg&rsquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>inscsf</code> is based on a technique so-called &quot;<dfn>initialization using a selected center of a selected feature</dfn>&quot;. It resembles Ball and Hall's method (Ball and Hall, 1967) for assignment of the first cluster prototype but it differs by the use of two different interval values (<code class="reqn">R_1</code> and <code class="reqn">R_2</code>) instead of using only one fixed threshold value (<em>T</em>) for determining the prototypes of remaining clusters. The technique <code>inscsf</code> does not require to sort the data set. <code class="reqn">R_1</code> is an interval which is calculated by dividing the distance between the center and maximum of the selected feature (<code class="reqn">x_f</code>) by half of the number of clusters minus 1. 
</p>
<p style="text-align: center;"><code class="reqn">R_1=\frac{max(x_f)-center(x_f)}{(c-1)/2}</code>
</p>
 
<p>Similarly, <code class="reqn">R_2</code> is an interval which is calculated by dividing the distance between the maximum and center of the selected feature by half of the number of clusters minus 1. 
</p>
<p style="text-align: center;"><code class="reqn">R_2=\frac{center(x_f)-min(x_f)}{(k-1)/2}</code>
</p>
  
<p>These two intervals become equal to each other if the selected feature is normally distributed, and thus, cluster prototypes are located in equidistant positions from each other in the <var>p</var>-dimensional space of <var>n</var> data objects.
</p>
<p>Depending on the distribution of selected feature, the mean, median or mode of the selected feature can be used to determine the prototype of first cluster. If the type of center measure is not input by the user, it is internally determined according to the distribution of data. Then, the nearest data instance to the center of the selected feature is searched on the selected feature column, and assigned as the prototype of first cluster. 
</p>
<p style="text-align: center;"><code class="reqn">v_1=x_i ;  i = row \;index \;of \;the \;nearest  \;data \;object \;to \;center(x_f))</code>
</p>

<p>The prototype of an even-numbered cluster is determined by adding the value of <code class="reqn">R_1</code> times the cluster index minus 1 to the first cluster prototype.
</p>
<p style="text-align: center;"><code class="reqn">v_j={(x_{(i+(j-1)}\;R_1)}</code>
</p>

<p>On the other hand, <code class="reqn">R_2</code> is used to calculate the prototypes for the odd-numbered clusters. 
</p>
<p style="text-align: center;"><code class="reqn">v_j={(x_{(i+(j-1)}\; R_2)}</code>
</p>



<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>sfidx</code></td>
<td>
<p>an integer for the column index of the selected feature.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string for the type of centroid. It is &lsquo;obj&rsquo; with this function because the prototypes matrix contain contains the selected objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The selected feature can be determined in several ways. The feature with highest number of peaks among the others can be also utilized as the selected feature with this function. For determination of it, the function <code><a href="kpeaks.html#topic+findpolypeaks">findpolypeaks</a></code> of the package &lsquo;<span class="pkg">kpeaks</span>&rsquo; can be used.
</p>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Ball, G.H. &amp; Hall, D.J. (1967). A clustering technique for summarizing multivariate data, <em>Systems Res. &amp; Behavioral Sci.</em>, 12 (2): 153-155.
</p>
<p>Cebeci, Z., Sahin, M. &amp; Cebeci, C. (2018). Data dependent techniques for initialization of cluster prototypes in partitioning cluster analysis. In Proc. of <em>4th International Conference on Engineering and Natural Science</em>, Kiev, Ukraine, May 2018. pp. 12-22.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
# Use the 4th feature as the selected feature
v1 &lt;- inscsf(x=iris[,1:4], k=5, sfidx=4)$v
print(v1)

# Use the internally selected feature
v2 &lt;- inscsf(x=iris[,1:4], k=5)$v
print(v2)
</code></pre>

<hr>
<h2 id='insdev'>
Initialization of cluster prototypes using Insdev algorithm
</h2><span id='topic+insdev'></span>

<h3>Description</h3>

<p><code>Insdev</code> is a novel algorithm that initializes the cluster prototypes by using the standard deviation of a selected feature. The selected feature is the most important feature in regard of variation. For this purpose the coefficients of variation of the features are compared, and then the feature with highest coefficient of variation is selected for further processes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>insdev(x, k, sfidx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="insdev_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="insdev_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
<tr><td><code id="insdev_+3A_sfidx">sfidx</code></td>
<td>
<p>an integer specifying the column index of the selected feature. Here, in this function we use the feature with high variability as the selected feature because it dominates the clustering results (Khan, 2912). If missing, so it is internally determined by comparing the coefficents of variation for all the features in the data set. The feature having the maximum coefficient of variation is used as the selected feature.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>At first the algorithm computes the mean of the selected feature (<code class="reqn">\bar{x_{s}}</code>) and then seeks the object whose distance is minimum to <code class="reqn">\bar{x_{s}}</code> as the prototype of first cluster. The prototypes of remaining clusters are determined by using a stepping range (<em>R</em>), computed from the standard deviation of selected feature with the formula <code class="reqn">R=1/2\sigma_{x_{s}}/k</code>. The prototype of second cluster is the object whose distance is minimum to <code class="reqn">\bar{x_{s}} + (i-1)\; R</code>, where <em>i</em> is the cluster index. The prototype of third cluster is the object whose distance is minimum to <code class="reqn">\bar{x_{s}} - i \; R</code> in the opposite direction to previous prototype. The prototypes remaining clusters are cyclically determined in similar way.
</p>
<p>Since it produces the same prototypes in each run of it, <code>insdev</code> is a deterministic algorithm. Therefore, this characteristic of the algorithm provides replicability in  initialization procedure.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>sfidx</code></td>
<td>
<p>an integer for the column index of the selected feature, used in the calculations.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototypes are the objects sampled from the data set.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Khan, F. (2012). An initial seed selection algorithm for k-means clustering of georeferenced data to improve replicability of cluster assignments for mapping application. <em>Applied Soft Computing</em>, 12 (11) : 3698-3700. <a href="https://doi.org/10.1016/j.asoc.2012.07.021">doi:10.1016/j.asoc.2012.07.021</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- insdev(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='is.inaparc'>
Checking the object class for &lsquo;inaparc&rsquo;
</h2><span id='topic+is.inaparc'></span>

<h3>Description</h3>

<p>Checks whether the given object is an instance of the <code>inaparc</code> class. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.inaparc(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.inaparc_+3A_x">x</code></td>
<td>
<p>an object to check.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>TRUE</code> if <code>x</code> is a valid <code>inaparc</code> object and <code>FALSE</code> for the other type of object classes.
</p>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- firstk(x=iris[,1:4], k=5)
is.inaparc(res)

x &lt;- c(1,5,8)
is.inaparc(x)
</code></pre>

<hr>
<h2 id='kkz'>
Initialization of cluster prototypes using KKZ algorithm
</h2><span id='topic+kkz'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using &lsquo;KKZ&rsquo; algorithm proposed by Katsavounidis et al (1994).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kkz(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kkz_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="kkz_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>kkz</code> is an implementation of the cluster seeding algorithm which has been proposed by Katsavounidis et al (1994). As the first cluster prototype, the algorithm so-called &lsquo;KKZ&rsquo; selects one data object on the edges of data. It is the object having the greatest squared Euclidean norm in the function <code>kkz</code>. The second cluster prototype is the farthest object from the previously selected object. After assignment of the prototypes of first two clusters, the distances of all of the remaining objects to them are computed. The object which is the farthest from its nearest prototype is assigned as the third prototype. The above process is repeated for selecting the prototypes of remaining clusters in the same way. The algorithm &lsquo;KKZ&rsquo; is considered to be sensitive to the outliers in the data set.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototypes are the selected objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Katsavounidis, I., Kuo, C. &amp; Zhang, Z. (1994). A new initialization technique for generalized Lloyd iteration. <em>IEEE Signal Processing Letters</em>, 1 (10): 144-146. url:<a href="https://www.semanticscholar.org/paper/A-new-initialization-technique-for-generalized-Katsavounidis-Kuo/0103d3599757c77f6f3cbe3daf2470f13419cd90?p2df">https://www.semanticscholar.org/paper/A-new-initialization-technique-for-generalized-Katsavounidis-Kuo/0103d3599757c77f6f3cbe3daf2470f13419cd90?p2df</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- kkz(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='kmpp'>
Initialization of cluster prototypes using K-means++ algorithm
</h2><span id='topic+kmpp'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix by using K-means++ algorithm which has been proposed by Arthur and Vassilvitskii (2007).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kmpp(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kmpp_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="kmpp_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>K-means++ (Arthur &amp; Vassilvitskii, 2007) is usually reported as an efficient approximation algorithm in overcoming the poor clustering problem with the standard K-means algorithm. K-means++ is an algorithm that merges MacQueen's second method with the &lsquo;Maximin&rsquo; method to initialize the cluster prototypes (Ji et al, 2015). K-means++ initializes the cluster centroids by finding the data objects that are farther away from each other in a probabilistic manner. In K-means++, the first cluster protoype (center) is randomly assigned. The prototypes of remaining clusters are determined with a probability of <code class="reqn">{md(x')}^2/\sum_{k=1}^{n} md({x_k})^2</code>, where <code class="reqn">md(x)</code> is the minimum distance between a data object and the previously computed prototypes.
</p>
<p>The function <code>kmpp</code> is an implementation of the initialization algorithm of K-means++ that is based on the code&lsquo;k-meansp2.R&rsquo;, authored by M. Sugiyama. It needs less execution time due to its vectorized distance computations.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototypes are the objects selected by the algorithm.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this sQuoteinaparc object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Arthur, D. &amp; Vassilvitskii. S. (2007). K-means++: The advantages of careful seeding, in <em>Proc. of the 18th Annual ACM-SIAM Symposium on Discrete Algorithms</em>, p. 1027-1035. url:<a href="http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf">http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf</a>
</p>
<p>M. Sugiyama, &lsquo;mahito-sugiyama/k-meansp2.R&rsquo;. url:<a href="https://gist.github.com/mahito-sugiyama/ef54a3b17fff4629f106">https://gist.github.com/mahito-sugiyama/ef54a3b17fff4629f106</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- kmpp(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='ksegments'>
Initialization of cluster prototypes using the centers of <var>k</var> segments
</h2><span id='topic+ksegments'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the centers of <var>k</var> segments (subsets) of the data set. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ksegments(x, k, ctype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ksegments_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="ksegments_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
<tr><td><code id="ksegments_+3A_ctype">ctype</code></td>
<td>
<p>a string for the type of centroid. The options are &lsquo;avg&rsquo; for average and &lsquo;med&rsquo; for median of the objects in the segments. The default is &lsquo;avg&rsquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first segment consists of the first <code>n/k</code> objects. The second segment consists of <code>n/k</code> objects starting from the <code>n/k+1</code>-<em>th</em> object. The process is repeated for <var>k</var> segments. The centers of <var>k</var> segments are assigned as the cluster prototypes.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid. Its value is &lsquo;avg&rsquo; for average or &lsquo;med&rsquo; for median of the objects in the segments.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)

# Generate the prototypes matrix using the means of segments
res &lt;- ksegments(x=iris[,1:4], k=5, ctype="avg")
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='ksteps'>
Initialization of cluster prototypes using the centers of <var>k</var> blocks
</h2><span id='topic+ksteps'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the centers of objects in <var>k</var> blocks that are generated with a kind of systematic sampling method as described in the section &lsquo;Details&rsquo;. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ksteps(x, k, ctype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ksteps_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="ksteps_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
<tr><td><code id="ksteps_+3A_ctype">ctype</code></td>
<td>
<p>a string for the type of centroid. The options are &lsquo;avg&rsquo; for average and &lsquo;med&rsquo; for median of the objects in the blocks. The default is &lsquo;avg&rsquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm <code>ksteps</code> is similar to <code><a href="#topic+ksegments">ksegments</a></code> but it differs for the selection of the members of the segments or blocks. The objects whose row indexes are <code>1, 1+k, 1+2k,...</code> are assigned to the first segment, and then the objects whose row indexes are <code>2, 2+k, 2+2k,...</code> to the second block. In this way, <var>k</var> blocks of the objects are formed. The centers of these <var>k</var> blocks are assigned as the cluster prototypes.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- ksteps(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='lastk'>
Initialization of cluster prototypes using the last <var>k</var> objects
</h2><span id='topic+lastk'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the last <var>k</var> objects at the bottom of data set. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lastk(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lastk_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="lastk_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>lastk</code> simply uses the last <var>k</var> objects as the protoypes of clusters. If the data is already sorted in any order it may result with no good initial prototypes because the objects be close to each other in a sorted matrix. Therefore,  shuffling of the data set as a pre-processing step may improve the quality with this prototyping technique.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototype matrix contains the objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- lastk(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='lhsmaximin'>
Initialization of cluster prototypes using Maximin LHS
</h2><span id='topic+lhsmaximin'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the Maximin version of Latin Hypercube Sampling (LHS). A square grid containing possible sample points is a Latin Square (LS) if there is only one sample in each row and each column. LHS is a generalized version of LS, which has been developed to generate a distribution of collections of parameter values from a multidimensional distribution. LHS generates more efficient estimates of desired parameters than simple Monte Carlo sampling (Carnell, 2016). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhsmaximin(x, k, ncp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lhsmaximin_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="lhsmaximin_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
<tr><td><code id="lhsmaximin_+3A_ncp">ncp</code></td>
<td>
<p>an integer determining the number of candidate points used in the search by maximin LHS algorithm.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>LHS aims at initial cluster centers whose coordinates are well spread out in the individual dimensions (Borgelt, 2005). It is the generalization of Latin Square for an arbitrary number of dimensions (features).  When sampling a function of <var>p</var> features, the range of each feature is divided into <var>k</var> equally probable intervals. <var>k</var> samples are then drawn such that a Latin Hypercube is created. 
</p>
<p>The current version of the function <code>lhsmaximin</code> in this package uses the results from the <code><a href="lhs.html#topic+maximinLHS">maximinLHS</a></code> function from the &lsquo;<span class="pkg">lhs</span>&rsquo; library created by Carnell (2016). Once the uniform samples are created by the <code><a href="lhs.html#topic+maximinLHS">maximinLHS</a></code>, they are transformed to normal distribution samples by using the quantile functions. But all the features in the data set may not be normally distributed, instead they may fit to different distributions. In such cases, the transformation for any feature should be specisific to its distribution. Determination of the distribution types of features is planned in the future versions of the function &lsquo;<code>lhsmaximin</code>&rsquo;. 
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string for the type of used centroid to determine the cluster prototypes. It is &lsquo;obj&rsquo; with this function.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Borgelt, C., (2005). <em>Prototype-based classification and clustering</em>. Habilitationsschrift zur Erlangung der Venia legendi fuer Informatik, vorgelegt der Fakultaet fuer Informatik der Otto-von-Guericke-Universitaet Magdeburg, Magdeburg, 22 June 2005. url:<a href="https://borgelt.net/habil/pbcc.pdf">https://borgelt.net/habil/pbcc.pdf</a>
</p>
<p>Carnell, R., (2016). lhs: Latin Hypercube Samples. R package version 0.14. <a href="https://CRAN.R-project.org/package=lhs">https://CRAN.R-project.org/package=lhs</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- lhsmaximin(iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='lhsrandom'>
Initialization of cluster prototypes using random LHS
</h2><span id='topic+lhsrandom'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the random version of Latin Hypercube Sampling (LHS). A square grid containing possible sample points is a Latin Square (LS) if there is only one sample in each row and each column. LHS is a generalized version of LS, which has been developed to generate a distribution of collections of parameter values from a multidimensional distribution. LHS generates more efficient estimates of desired parameters than simple Monte Carlo sampling (Carnell, 2016). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhsrandom(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lhsrandom_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="lhsrandom_+3A_k">k</code></td>
<td>
<p>an integer for specifying the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>LHS aims at initial cluster centers whose coordinates are well spread out in the individual dimensions (Borgelt, 2005). LHS is the generalization of Latin Square for an arbitrary number of dimensions (features). When sampling a function of <var>p</var> features, the range of each feature is divided into <var>k</var> equally probable intervals. <var>k</var> samples are then drawn such that a Latin Hypercube is created. 
</p>
<p>The current version of the function <code>lhsrandom</code> in this package uses the results from the <code><a href="lhs.html#topic+randomLHS">randomLHS</a></code> function from the  R package &lsquo;<span class="pkg">lhs</span>&rsquo; (Carnell, 2016), which contains several variants of LHS. Once the uniform samples are created by the <code><a href="lhs.html#topic+randomLHS">randomLHS</a></code>, they are transformed to normal distributed samples by using the quantile functions. But all the features in the data set may not be normally distributed, instead they may have the different type of distributions. In such cases, the transformation of any feature should be specific to its distribution. Determination of the distribution types of features is planned in the future versions of the function &lsquo;<code>lhsrandom</code>&rsquo;. 
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string for the type of used centroid to determine the cluster prototypes. It is &lsquo;obj&rsquo; with this function.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Borgelt, C., (2005). <em>Prototype-based classification and clustering</em>. Habilitationsschrift zur Erlangung der Venia legendi fuer Informatik, vorgelegt der Fakultaet fuer Informatik der Otto-von-Guericke-Universitaet Magdeburg, Magdeburg, 22 June 2005. url:<a href="https://borgelt.net/habil/pbcc.pdf">https://borgelt.net/habil/pbcc.pdf</a>
</p>
<p>Carnell, R., (2016). lhs: Latin Hypercube Samples. R package version 0.14. <a href="https://CRAN.R-project.org/package=lhs">https://CRAN.R-project.org/package=lhs</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- lhsrandom(iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='maximin'>
Initialization of cluster prototypes using Maximin algorithm
</h2><span id='topic+maximin'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix by using the Maximin algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>maximin(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="maximin_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="maximin_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The main idea of the <dfn>Maximin</dfn> algorithm is to isolate the cluster prototypes that are farthest apart (Philpot, 2001). The algorithm randomly samples one data object from the data set and assigns it as the first cluster prototype. The prototype of second cluster is determined as the data object which is farthest from the first prototype. Then, the remaining part of data set is scanned for the data objects whose distances are minimum to the previously selected prototypes. The object having the maximum of minimum distances is assigned the prototype of third cluster. The same procedure is repeated for determining the prototypes of other clusters (Spaeth, 1997; Gonzales, 1985; Duda et al, 2000, Celebi et al, 2013).
</p>
<p>The algorithm generally works well with circular shaped clusters whose radius are smaller than the separation between clusters.  However, it is very sensitive to the order of object in data sets. Also it is computationally expensive because each time once a new cluster prototype is selected, the distances must be computed for every object from every cluster prototype (Philpot, 2001). In order to contribute to the solutions of this problem, the current implementation of <code>maximin</code> includes a simple control that if an object has the minimum distance of zero, the seeking procedure is no more continued to compute the distances for the remaining objects. This control may speed the algorithm up with the <code>maximin</code> function in this package.  
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix of the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototype matrix contains the objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates the object &lsquo;inaparc&rsquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Spaeth, H. (1977). Computational experiences with the exchange method: Applied to four commonly used partitioning cluster analysis criteria, <em>European Journal of Operational Research</em> 1 (1): 23-31. <a href="https://doi.org/10.1016/S0377-2217%2877%2981005-9">doi:10.1016/S0377-2217(77)81005-9</a>
</p>
<p>Gonzalez, T. (1985), Clustering to minimize the maximum intercluster distance, <em>Theoretical Computer Science</em> 38 (2-3): 293-306. url:<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.8183&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.8183&amp;rep=rep1&amp;type=pdf</a>
</p>
<p>Duda, R.O., Hart, P.E. &amp; Stork, D.G. (2000). <em>Pattern Classification</em>, Wiley-Interscience. &lt;ISBN:978-0-471-05669-0&gt;
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>
<p>Philpot, W. (2001). Topic 8: Clustering/Unsupervised Classification in <em>Lecture Notes, CEE 615: Digital Image Processing - Jan 2001, Cornell Univ.</em>, url:<a href="https://www-users.cse.umn.edu/~kumar/dmbook/ch8.pdf">https://www-users.cse.umn.edu/~kumar/dmbook/ch8.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;-maximin(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='mscseek'>
Initialization of cluster prototypes using the modified SCS algorithm
</h2><span id='topic+mscseek'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using a modified version of the Simple Cluster Seeking (SCS) algorithm proposed by Tou &amp; Gonzales(1974). While SCS uses a fixed threshold distance value <var>T</var> for selecting all candidates of clusters, the modified SCS recomputes <var>T</var> with the average Euclidean distances between the previously determined prototypes. This adjustment makes possible to select more cluster prototypes when compared to SCS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mscseek(x, k, tv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mscseek_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="mscseek_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
<tr><td><code id="mscseek_+3A_tv">tv</code></td>
<td>
<p>a number to be used as the threshold distance which is directly input by the user. Also it is possible to compute <var>T</var>, a threshold distance value with the following options of <code>tv</code> argument:
</p>

<ul>
<li> <p><var>T</var> is the mean of differences between the consecutive pairs of objects with the option <span class="option">cd1</span>.  
</p>
</li>
<li> <p><var>T</var> is the minimum of differences between the consecutive pairs of objects with the option <span class="option">cd2</span>.    
</p>
</li>
<li> <p><var>T</var> is the mean of Euclidean distances between the consecutive pairs of objects divided into <var>k</var> with the option <span class="option">md</span>. This is the default if <code>tv</code> is not supplied by the user.
</p>
</li>
<li> <p><var>T</var> is the range of maximum and minimum of Euclidean distances between the consecutive pairs of objects divided into <var>k</var> with the option <span class="option">mm</span>.
</p>
</li></ul>

</td></tr>
</table>


<h3>Details</h3>

<p>This is a modification of the Simple Cluster Seeking (SCS) algorithm (Tou &amp; Gonzalez, 1974). The algorithm selects the first object in the data set as the prototype of the first cluster. Then, next object whose distance to the first prototype is greater than a threshold distance value is searched and assigned as the second cluster prototype. Instead of using a fixed the <var>T</var>, threshold distance value as SCS does, the modified SCS recomputes the <var>T</var> by the average Euclidean distances between the previously determined prototypes of clusters. The next object whose distance to the previously selected object is greater than the adjusted <var>T</var> is searched and assigned as the third cluster prototype. The selection process is repeated for the remaining clusters in similar way. The method is sensitive to the order of the data, it may not yield good initializations with the ordered data. 
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix of the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototype matrix contains the objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates the object &lsquo;inaparc&rsquo;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Tou, J.T. &amp; Gonzalez, R.C. (1974). <em>Pattern Recognition Principles</em>. Addison-Wesley, Reading, MA. &lt;ISBN:9780201075861&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
# Run with the threshold value of 0.1
res &lt;- mscseek(x=iris[,1:4], k=5, tv=0.1)
v1 &lt;- res$v
print(v1)

# Run with the internally computed default threshold value 
res &lt;- mscseek(x=iris[,1:4], k=5)
v2 &lt;- res$v
print(v2)
</code></pre>

<hr>
<h2 id='rsamp'>
Initialization of cluster prototypes using simple random sampling
</h2><span id='topic+rsamp'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the randomly selected <var>k</var> objects from the data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsamp(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsamp_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="rsamp_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>rsamp</code> generates a protoype matrix using the <var>k</var> objects which are randomly sampled from the data set without replacement. Simple random sampling (SRS), also so-called the <dfn>second method of MacQueen</dfn> in the clustering context, assumes that cluster areas have a high density; in consequence, the good candidates of the cluster prototypes can be sampled from these dense regions of data with a higher chance (Celebi et al, 2013). SRS is probably the most common approach to initialize prototype matrices. So, it can be seen a <em>de facto standard</em> because it has been widely applied with the basic K-means algorithm for the years. Since SRS has no rule to avoid to select the outliers or the objects close to each other, it may result with no good initializations. Before initialization of SRS, multivariate outliers removal on the data set as a data pre-processing step may be helpful to avoid for selection of the outliers, but increases the computational cost.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because it samples the objects only.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>MacQueen, J.B. (1967). Some methods for classification and analysis of multivariate observations, in <em>Proc. of 5-th Berkeley Symp. on Mathematical Statistics and Probability</em>, Berkeley, University of California Press, 1: 281-297. url:<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.308.8619&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.308.8619&amp;rep=rep1&amp;type=pdf</a>
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- rsamp(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='rsegment'>
Initialization of cluster prototypes using a randomly selected segment
</h2><span id='topic+rsegment'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using using a <var>k</var>-length segment of data set consists of consecutive objects that starts with a randomly sampled data object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rsegment(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rsegment_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="rsegment_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>rsegment</code> randomly samples one data object as the prototype of first cluster, and then it assigns the next <var>k-1</var> data objects as the prototype of remaining clusters.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototype matrix contains the sampled objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- rsegment(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='scseek'>
Initialization of cluster prototypes using SCS algorithm
</h2><span id='topic+scseek'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix with the Simple Cluster Seeking (SCS) algorithm (Tou &amp; Gonzales, 1974).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scseek(x, k, tv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scseek_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="scseek_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
<tr><td><code id="scseek_+3A_tv">tv</code></td>
<td>
<p>a number to be used as the threshold distance which is directly input by the user. Also it is possible to compute <var>T</var>, a threshold distance value with the following options of <code>tv</code> argument:
</p>

<ul>
<li> <p><var>T</var> is the mean of differences between the consecutive pairs of objects with the option <span class="option">cd1</span>.  
</p>
</li>
<li> <p><var>T</var> is the minimum of differences between the consecutive pairs of objects with the option <span class="option">cd2</span>.     
</p>
</li>
<li> <p><var>T</var> is the mean of Euclidean distances between the consecutive pairs of objects divided into <var>k</var> with the option <span class="option">md</span>. This is the default if <code>tv</code> is not supplied by the user.
</p>
</li>
<li> <p><var>T</var> is the range of maximum and minimum of Euclidean distances between the consecutive pairs of objects divided into <var>k</var> with the option <span class="option">mm</span>.
</p>
</li></ul>

</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm Simple Cluster Seeking (SCS) (Tou &amp; Gonzales, 1974) is similar to Ball and Hall's algorithm (Ball &amp; Hall, 1967) with an exception for selection of the first object (Celebi et al, 2013). In SCS, the first object in the data set is selected as the prototype of the first cluster. Then, the next object whose distance to the first prototype is greater than <var>T</var>, a threshold distance value is seeked and assigned as the second cluster prototype, if found. Afterwards, the next object whose distance to already determined prototypes is greater than <var>T</var> is searched and assigned as the third cluster prototype. The selection process is repeated for determining the prototypes of remaining clusters in similar way. 
</p>
<p>Because SCS is sensitive to the order of the data (Celebi et al, 2013), it may not yield good initializations with the sorted data. On the other hand, the distance between the cluster prototypes can be controlled <var>T</var>, which is an arbitrary number specified by the user. But the problem is that how the user decides on this threshold value. As a solution to this problem in the function <code>scseek</code>, some internally computed distance measures can be used. (See the section&lsquo;Arguments&rsquo; above for the available options.)</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix of the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototype matrix contains the objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Ball, G.H. &amp; Hall, D.J. (1967). A clustering technique for summarizing multivariate data, <em>Systems Res. &amp; Behavioral Sci.</em>, 12 (2): 153-155.
</p>
<p>Tou, J.T. &amp; Gonzalez,R.C. (1974). <em>Pattern Recognition Principles</em>. Addison-Wesley, Reading, MA. &lt;ISBN:9780201075861&gt;
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
# Run with the threshold value of 0.5
res &lt;- scseek(x=iris[,1:4], k=5, tv=0.5)
v1 &lt;- res$v
print(v1)

# Run with the internally computed default threshold value 
res &lt;- scseek(x=iris[,1:4], k=5)
v2 &lt;- res$v
print(v2)
</code></pre>

<hr>
<h2 id='scseek2'>
Initialization of cluster prototypes using SCS algorithm over a selected feature
</h2><span id='topic+scseek2'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix with the Simple Cluster Seeking (SCS) algorithm (Tou &amp; Gonzales, 1974) over a selected feature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scseek2(x, k, sfidx, tv)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scseek2_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="scseek2_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
<tr><td><code id="scseek2_+3A_sfidx">sfidx</code></td>
<td>
<p>an integer specifying the column index of the selected feature for random sampling. If missing, it is internally determined by comparing the coefficients of variation of all features in the data set. The feature having the maximum coefficent of variation is used as the selected feature.</p>
</td></tr>
<tr><td><code id="scseek2_+3A_tv">tv</code></td>
<td>
<p>a number to be used as the threshold distance which is directly input by the user. Also it is possible to compute <var>T</var>, a threshold distance value with the following options of <code>tv</code> argument:
</p>

<ul>
<li> <p><var>T</var> is the mean of differences between the consecutive pairs of objects with the option <span class="option">cd1</span>.  
</p>
</li>
<li> <p><var>T</var> is the minimum of differences between the consecutive pairs of objects with the option <span class="option">cd2</span>.     
</p>
</li>
<li> <p><var>T</var> is the mean of Euclidean distances between the consecutive pairs of objects divided into <var>k</var> with the option <span class="option">md</span>. This is the default if <code>tv</code> is not supplied by the user.
</p>
</li>
<li> <p><var>T</var> is the range of maximum and minimum of Euclidean distances between the consecutive pairs of objects divided into <var>k</var> with the option <span class="option">mm</span>.
</p>
</li></ul>

</td></tr>
</table>


<h3>Details</h3>

<p>The <code>scseek2</code> is a novel variant of the function <code><a href="#topic+scseek">scseek</a></code> based on the Simple Cluster Seeking (SCS) algorithm (Tou &amp; Gonzales, 1974). It differs from SCS that the distances and threshold value are computed over a selected feature having the maximum coefficient of variation, instead of using all the features.  
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix of the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>sfidx</code></td>
<td>
<p>an integer for the column index of the selected feature, which used for random sampling.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototype matrix contains the sampled objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;proclus&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Tou, J.T. &amp; Gonzalez,R.C. (1974). <em>Pattern Recognition Principles</em>. Addison-Wesley, Reading, MA. &lt;ISBN:9780201075861&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
# Run over 4th feature with the threshold value of 0.5
res &lt;- scseek2(x=iris[,1:4], k=5, sfidx=4, tv=0.5)
v1 &lt;- res$v
print(v1)

# Run with the internally computed default threshold value 
res &lt;- scseek2(x=iris[,1:4], k=5)
v2 &lt;- res$v
print(v2)

</code></pre>

<hr>
<h2 id='spaeth'>
Initialization of cluster prototypes using Spaeth's algorithm
</h2><span id='topic+spaeth'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes using the centroids that are calculated with Spaeth's algorithm (Spaeth, 1977), which is similar to Forgy's algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>spaeth(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="spaeth_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="spaeth_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In this algorithm, each object in the data set is assigned to one of <var>k</var> clusters in cyclical fashion. The j-<em>th</em> <code class="reqn">(j \epsilon {1,2, \cdots, n}</code>) object is assigned to the <code class="reqn">(j-1 (mod k) + 1)</code><code class="reqn">(j-1 (mod\, k)+1)</code>-<em>th</em> cluster. In contrast to Forgy's method, this method is sensitive to order of data (Celebi et al, 2013).
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;avg&rsquo; with this function because the cluster prototypes are the averages of sampled objects for each feature.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates the &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>References</h3>

<p>Spaeth, H. (1977). Computational experiences with the exchange method: Applied to four commonly used partitioning cluster analysis criteria, <em>European J of Operational Rsch.</em>, 1(1):23-31. <a href="https://doi.org/10.1016/S0377-2217%2877%2981005-9">doi:10.1016/S0377-2217(77)81005-9</a>
</p>
<p>Celebi, M.E., Kingravi, H.A. &amp; Vela, P.A. (2013). A comparative study of efficient initialization methods for the K-means clustering algorithm, <em>Expert Systems with Applications</em>, 40 (1): 200-210. arXiv:<a href="https://arxiv.org/pdf/1209.1960.pdf">https://arxiv.org/pdf/1209.1960.pdf</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- spaeth(iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='ssamp'>
Initialization of cluster prototypes using systematic random sampling
</h2><span id='topic+ssamp'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the systemically sampled data objects. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ssamp(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ssamp_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="ssamp_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>ssamp</code> generates a prototype matrix using the sytematic random sampling technique. Since the data objects are enough away from each other with this technique it may provide better initializations than the simple random sampling. The first object is randomly sampled from the top <code>n/k</code> objects of data set and assigned as the prototype of first cluster. The prototypes of remaining clusters are the objects whose row indexes are <code class="reqn">v_{1} + i\;(n/k)</code>, where <var>v1</var> and <var>i</var> are the index of first selected object and index of cluster, respectively.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototype matrix contains the sampled objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- ssamp(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='topbottom'>
Initialization of cluster prototypes using the top and bottom objects
</h2><span id='topic+topbottom'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the alternately selected <var>k</var> objects from the top and bottom of the data set. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>topbottom(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="topbottom_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="topbottom_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function combines the <code><a href="#topic+firstk">firstk</a></code> and <code><a href="#topic+lastk">lastk</a></code> techniques. It takes the first object of the data set as the prototype of first cluster, and then the last object as the prototype of second cluster. This rotating assigment process continues until the prototypes of <var>k</var> clusters are assigned.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototype matrix contains the objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If the sorted data set is used, the function <code>topbottom</code> may yield better initializations when compared to the functions <code><a href="#topic+firstk">firstk</a></code> and <code><a href="#topic+lastk">lastk</a></code>.
</p>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- topbottom(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='uniquek'>
Initialization of cluster prototypes over the unique values
</h2><span id='topic+uniquek'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix using the randomly sampled data objects over the unique values of a selected feature. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uniquek(x, k, sfidx)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uniquek_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="uniquek_+3A_k">k</code></td>
<td>
<p>an integer specifying the number of clusters.</p>
</td></tr>
<tr><td><code id="uniquek_+3A_sfidx">sfidx</code></td>
<td>
<p>an integer specifying the column index of the selected feature for random sampling. If missing, it is internally determined by comparing the number of unique values for all the features in the data set. The feature having the maximum number of unique values is used as the selected feature.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The set of unique values of the selected feature is determined, and then <var>k</var> objects were randomly sampled from this set.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroid, which used to build prototype matrix. Its value is &lsquo;obj&rsquo; with this function because the cluster prototype matrix contains the sampled objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+ursamp">ursamp</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
# Run with the internally selected feature
res &lt;- uniquek(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)

# Run with the 1st feature
res &lt;- uniquek(x=iris[,1:4], k=5, sfidx=1)
v &lt;- res$v
print(v)
</code></pre>

<hr>
<h2 id='ursamp'>
Initialization of cluster prototypes using random sampling on each future
</h2><span id='topic+ursamp'></span>

<h3>Description</h3>

<p>Initializes the cluster prototypes matrix by using random uniform sampling for each of <var>p</var> features in the data set, independently.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ursamp(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ursamp_+3A_x">x</code></td>
<td>
<p>a numeric vector, data frame or matrix.</p>
</td></tr>
<tr><td><code id="ursamp_+3A_k">k</code></td>
<td>
<p>an integer for the number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>ursamp</code> generates the prototypes by binding randomly sampled values for each of <var>p</var> features, independently. In this novel approach proposed by the authors of the package, an object is randomly sampled from data set and the value of first feature is assigned as the value of first feature of the first prototype. Then next object is sampled and the value of second feature of the sampled object is assigned as the value of second feature of the first prototype. The sampling process is repeated for the other features in similar way. Afterwards the same sampling procedure is repeated for determining the prototypes of remaining clusters.
</p>


<h3>Value</h3>

<p>an object of class &lsquo;inaparc&rsquo;, which is a list consists of the following items:
</p>
<table>
<tr><td><code>v</code></td>
<td>
<p>a numeric matrix containing the initial cluster prototypes.</p>
</td></tr>
<tr><td><code>ctype</code></td>
<td>
<p>a string representing the type of centroids in the prototype matrix. Its value is &lsquo;obj&rsquo; with this function because it returns objects.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>a string containing the matched function call that generates this &lsquo;inaparc&rsquo; object.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Zeynel Cebeci, Cagatay Cebeci
</p>


<h3>See Also</h3>

<p><code><a href="#topic+aldaoud">aldaoud</a></code>,
<code><a href="#topic+ballhall">ballhall</a></code>,
<code><a href="#topic+crsamp">crsamp</a></code>,
<code><a href="#topic+firstk">firstk</a></code>,
<code><a href="#topic+forgy">forgy</a></code>,
<code><a href="#topic+hartiganwong">hartiganwong</a></code>,
<code><a href="#topic+inofrep">inofrep</a></code>,
<code><a href="#topic+inscsf">inscsf</a></code>,
<code><a href="#topic+insdev">insdev</a></code>,
<code><a href="#topic+kkz">kkz</a></code>,
<code><a href="#topic+kmpp">kmpp</a></code>,
<code><a href="#topic+ksegments">ksegments</a></code>,
<code><a href="#topic+ksteps">ksteps</a></code>,
<code><a href="#topic+lastk">lastk</a></code>,
<code><a href="#topic+lhsmaximin">lhsmaximin</a></code>,
<code><a href="#topic+lhsrandom">lhsrandom</a></code>,
<code><a href="#topic+maximin">maximin</a></code>,
<code><a href="#topic+mscseek">mscseek</a></code>,
<code><a href="#topic+rsamp">rsamp</a></code>,
<code><a href="#topic+rsegment">rsegment</a></code>,
<code><a href="#topic+scseek">scseek</a></code>,
<code><a href="#topic+scseek2">scseek2</a></code>,
<code><a href="#topic+ssamp">ssamp</a></code>,
<code><a href="#topic+spaeth">spaeth</a></code>,
<code><a href="#topic+topbottom">topbottom</a></code>,
<code><a href="#topic+uniquek">uniquek</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
res &lt;- ursamp(x=iris[,1:4], k=5)
v &lt;- res$v
print(v)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
