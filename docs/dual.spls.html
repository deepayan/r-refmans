<!DOCTYPE html><html><head><title>Help for package dual.spls</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dual.spls}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dual.spls-package'><p>dual.spls package</p></a></li>
<li><a href='#d.spls.calval'><p>Splits data into calibration and validation sets using the splitting method CalValXy that takes into account X and y</p></a></li>
<li><a href='#d.spls.cv'><p>Determination of the number of latent components to be used in a Dual-SPLS regression</p></a></li>
<li><a href='#d.spls.errorcv'><p>Computes the error of a cross validation iteration</p></a></li>
<li><a href='#d.spls.GL'><p>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the group lasso norms</p></a></li>
<li><a href='#d.spls.GLA'><p>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the group lasso norm A</p></a></li>
<li><a href='#d.spls.GLB'><p>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the group lasso norm B</p></a></li>
<li><a href='#d.spls.GLC'><p>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the group lasso norm C</p></a></li>
<li><a href='#d.spls.lasso'><p>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the lasso norm</p></a></li>
<li><a href='#d.spls.listecal'><p>Determine the number of observations to select from each cell</p></a></li>
<li><a href='#d.spls.LS'><p>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the least squares norm</p></a></li>
<li><a href='#d.spls.metric'><p>Computes predictions criterias</p></a></li>
<li><a href='#d.spls.NIR'><p>Dual Sparse Partial Least Squares (Dual-SPLS) Near Infrared data</p></a></li>
<li><a href='#d.spls.norm1'><p>Computing the l1 and l2 norm</p></a></li>
<li><a href='#d.spls.plot'><p>Plots the coefficient curve of a Dual-SPLS regression</p></a></li>
<li><a href='#d.spls.pls'><p>Univariate Partial Least Squares regression</p></a></li>
<li><a href='#d.spls.predict'><p>Makes predictions from a fitted Dual-SPLS model</p></a></li>
<li><a href='#d.spls.print'><p>Print function for Dual-SPLS models</p></a></li>
<li><a href='#d.spls.ridge'><p>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the ridge norm</p></a></li>
<li><a href='#d.spls.simulate'><p>Simulation of a data</p></a></li>
<li><a href='#d.spls.split'><p>Splits data into calibration and validation sets according to wich group belongs each observation</p></a></li>
<li><a href='#d.spls.type'><p>Splitting the observations into groups</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Dual Sparse Partial Least Squares Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.4</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides a series of functions for fitting a dual sparse partial least squares (Dual-SPLS) regression. These functions differ by the choice of the underlying norm. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, pdist, graphics</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-17 15:18:30 UTC; Louna</td>
</tr>
<tr>
<td>Author:</td>
<td>Louna Alsouki [aut, cre],
  François Wahl [aut],
  Ghislain Durif [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Louna Alsouki &lt;lounasouki@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-18 19:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='dual.spls-package'>dual.spls package</h2><span id='topic+dual.spls'></span><span id='topic+dual.spls-package'></span>

<h3>Description</h3>

<p>This package provides a series of functions that compute latent sparse components used in a regression model.
These components are based on a generalization of the classical PLS1 algorithm i.e. for a one dimensionnal response.
Denoting <code class="reqn">\Omega(w)=\|w\|_2</code> the euclidian norm, the PLS1 algorithm amounts to finding the vector <code class="reqn">w</code> involved in the evaluation of the dual norm
</p>
<p style="text-align: center;"><code class="reqn">\Omega^*(z)=\max_w(z^Tw) \textrm{ s.t. } \Omega(w)=1,</code>
</p>
<p> where <code class="reqn">z=X^Ty</code>,
<code class="reqn">X</code> is the matrix of predictors and <code class="reqn">y</code> is the response vector.
This problem is reformulated as follows
</p>
<p style="text-align: center;"><code class="reqn">\Omega^*(z)=\min_{w,\mu}(-z^Tw)+\mu(\Omega(w)-1),</code>
</p>

<p>where <code class="reqn">\mu</code> is the lagragian multiplier. The resulting solution <code class="reqn">w</code> is colinear to the coefficients vector.
</p>
<p>The PLS1 algorithm is then extended by varying the underlying norm <code class="reqn">\Omega(w)</code> and notably including some
penalization that leads to sparse regression coefficients for variable selection. For more details refer to (ref). The available norms considered are:
</p>

<ul>
<li><p> PLS1: <code class="reqn">\Omega(w)= \|w\|_2</code>,
</p>
</li>
<li><p> Lasso: <code class="reqn">\Omega(w)=\lambda \|w\|_1 + \|w\|_2</code> where <code class="reqn">\lambda</code> is a positive scalar,
</p>
</li>
<li><p> Group Lasso with 3 possible norms; for <code class="reqn">G</code> the number of groups and <code class="reqn">\alpha_g</code>, <code class="reqn">\lambda_g</code> and <code class="reqn">\gamma_g</code> all positive scalars,
</p>

<ul>
<li><p> Norm A <em>(generalized norm)</em>: <code class="reqn">\Omega_g(w)=\|w_g\|_2+ \lambda_g \|w_g\|_1</code> where
<code class="reqn">\Omega(w)=\sum_{g} \alpha_g \Omega_g(w)=1 \textrm{ and } \sum_{g=1}^G \alpha_g=1</code>,
</p>
</li>
<li><p> Norm B <em>(particular case)</em>: <code class="reqn">\Omega(w)=\|w\|_2+\sum_{g=1}^G \lambda_g\|w_g\|_1</code>,
</p>
</li>
<li><p> Norm C <em>(particular case)</em>: <code class="reqn">\Omega(w)=\sum_{g=1}^G \alpha_g \|w \|_2+\sum_{g=1}^G \lambda_g \|w_g \|_1</code>
where
<code class="reqn">\sum_{g=1}^G \alpha_g=\sum_{g=1}^G \gamma_g=1</code> <br /> and <code class="reqn">\Omega(w_g)=\gamma_g</code>.
</p>
</li></ul>

</li>
<li><p> Least Squares: <code class="reqn">\Omega(w)=\lambda \|N_1w\|_1 + \|Xw\|_2</code> where <code class="reqn">N_1</code> is a matrix and <code class="reqn">\lambda</code> is a positive scalar,
</p>
</li>
<li><p> Ridge: <code class="reqn">\Omega(w)=\lambda_1 \|w\|_1 +\lambda_2 \|Xw\|_2 + \|w\|_2</code> where <code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code> are both positive scalars.
</p>
</li></ul>

<p>This package also suggests </p>

<ul>
<li><p> a calibration and validation method called CalValXy based on a modified version of the Kennard
and Stone Algorithm (ref),
</p>
</li>
<li><p> a function that simulates data composed of Gaussian mixtures,
</p>
</li>
<li><p> a function that chooses the number of components according to the cross validation procedure,
</p>
</li>
<li><p> a series of functions that display results and help in the interpretations.
</p>
</li>
<li><p> a real data representing 208 near infrared spectra of refined petroleum sapmles with their density (ref).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.lasso">d.spls.lasso</a>, <a href="#topic+d.spls.LS">d.spls.LS</a>, <a href="#topic+d.spls.ridge">d.spls.ridge</a>,
<a href="#topic+d.spls.GL">d.spls.GL</a>
</p>

<hr>
<h2 id='d.spls.calval'>Splits data into calibration and validation sets using the splitting method CalValXy that takes into account X and y</h2><span id='topic+d.spls.calval'></span>

<h3>Description</h3>

<p>The function <code>d.spls.calval</code> divides the data <code>X</code> into a calibration and a validation.
It uses a variation on the Kennard and Stone strategy CalValXy by dividing observations into groups (see details for more explanations).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.calval(X,pcal=NULL,Datatype=NULL,y=NULL,ncells=10,Listecal=NULL,
center=TRUE,method="euclidean",pc=0.9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.calval_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values.</p>
</td></tr>
<tr><td><code id="d.spls.calval_+3A_pcal">pcal</code></td>
<td>
<p>a positive integer between 0 and 100. <code>pcal</code> is the percentage
of calibration samples to be selected. Default value is NULL, meaning as long as <code>Listecal</code> is
specified, <code>pcal</code> is not necessary.</p>
</td></tr>
<tr><td><code id="d.spls.calval_+3A_datatype">Datatype</code></td>
<td>
<p>A vector of index specifying each observation belonging to which group index.
Default value is <code>NULL</code>, meaning the function will use the internal function <code>type</code> to compute the vector for <code>ncells</code>.
If <code>NULL</code>, parameter <code>y</code> should be specified. (see details for more explanation)</p>
</td></tr>
<tr><td><code id="d.spls.calval_+3A_y">y</code></td>
<td>
<p>a numeric vector of responses. Default value is <code>NULL</code>, meaning as long as <code>Datatype</code> is specified,
<code>y</code> is not necessary.</p>
</td></tr>
<tr><td><code id="d.spls.calval_+3A_ncells">ncells</code></td>
<td>
<p>a positive integer. <code>ncells</code> is the number of groups dividing the observations. If
<code>Datatype</code> is not specified, the function divides the observations into <code>ncells</code> groups. Default value
is <code>10</code>.</p>
</td></tr>
<tr><td><code id="d.spls.calval_+3A_listecal">Listecal</code></td>
<td>
<p>a numeric vector specifying how many observations from each group should be selected as calibration.
Default value is <code>NULL</code>, meaning the function will consider a percentage of <code>pcal</code> from each group
to be in the calibration set. If <code>NULL</code>, parameter <code>pcal</code> should be specified.</p>
</td></tr>
<tr><td><code id="d.spls.calval_+3A_center">center</code></td>
<td>
<p>logical value indicating wether the matrix <code>X</code> should be centered. Default set to TRUE.</p>
</td></tr>
<tr><td><code id="d.spls.calval_+3A_method">method</code></td>
<td>
<p>the method and norm used for the distance computation. It is by default equal to &quot;euclidean&quot; which means
original <code>X</code> is used with euclidean norm. &quot;svd-euclidean&quot; means euclidean distance is used after a SVD transformation with <code>pc</code> components. &quot;pca-euclidean&quot; means
euclidean distance on PCA scores with <code>pc</code> components. For</p>
</td></tr>
<tr><td><code id="d.spls.calval_+3A_pc">pc</code></td>
<td>
<p>a positive real value indicating the number of component to consider when applying the SVD transformation or the PCA.
If <code>pc</code> <code class="reqn">&lt; 1</code>, the number of components kept corresponds to the number of components explaining at least
(<code>pc</code> <code class="reqn">&lt; 1</code>) percent of the total variance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm allows to select samples using the classical Kennard and Stone on
each group of observations one by one. It starts by selecting the point that is the furthest away from the centroid.
This point is assigned as the calibration set and is removed from the list of candidates. Then, it identifies to which
group belongs this first observation and considers the group <code class="reqn">g</code> that comes after.
It computes the distance <code class="reqn">\delta_{P_{i,g}}</code> between the remaining points
<code class="reqn">P_{i,g}</code> belonging to the group the group <code class="reqn">g</code> and the calibration point assigned. The point with the
largest <code class="reqn">\delta_{P_{i,g}}</code> is selected and removed from the set then the procedure moves on to the group that comes
after.
</p>
<p>When there is more than one calibration sample, the procedure computes the distance between each <code class="reqn">P_{i,g}</code> from
the concerned group and each <code class="reqn">P_{i,cal}</code> from the calibration set. The minimal distance for each <code class="reqn">P_{i,g}</code>
is noted <code class="reqn">distmin(P_{i,g})</code>. The selected final candidate verifies the following equation:
</p>
<p style="text-align: center;"><code class="reqn">P_{selected}=\{ P_{i,g} | max(distmin(P_{i,g}))\} </code>
</p>

<p>Once each of the vector <code>Listecal</code> elements are null; the procedure is done.
</p>
<p>The algorithm for only one group corresponds to the classical Kennard and Stone algorithm.
</p>
<p>If <code>Datatype</code> is not specified, the function devides the observations into <code>ncells</code> groups. First, the observations
are sorted according to the values of <code class="reqn">y</code>. Second, the observations is divided into equal <code>ncells</code> according to the
cumulative empirical probabilities.
Finally, each observation with a value of <code class="reqn">y</code> belonging to a sub interval is assigned the number of the corresponding cell.
</p>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>indcal</code></td>
<td>
<p>a numeric vector giving the row indices of the input data selected for calibration.</p>
</td></tr>
<tr><td><code>indval</code></td>
<td>
<p>a numeric vector giving the row indices of the remaining observations.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>References</h3>

<p>Kennard, Ronald W, and Larry A Stone. 1969. “Computer Aided Design of Experiments.” Technometrics 11 (1): 137–48.
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.split">d.spls.split</a>,<a href="#topic+d.spls.type">d.spls.type</a>,<a href="#topic+d.spls.listecal">d.spls.listecal</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### parameters
n &lt;- 100
p &lt;- 50
nondes &lt;- 20
sigmaondes &lt;- 0.5
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y

###calibration parameters for split1
pcal &lt;- 70
ncells &lt;- 3

split1 &lt;- d.spls.calval(X=X,pcal=pcal,y=y,ncells=ncells)

###plotting split1
plot(X[split1$indcal,1],X[split1$indcal,2],xlab="Variable 1",
ylab="Variable 2",pch=19,col="red",main="Calibration and validation split1")
points(X[split1$indval,1],X[split1$indval,2],pch=19,col="green")
legend("topright", legend = c("Calibration points", "Validation points"),
cex = 0.8, col = c("red","green"), pch = c(19,19))

###calibration parameters for split2
ncells &lt;- 3
dimtype=floor(n/3)
# type of observations
Datatype &lt;- c(rep(1,dimtype),rep(2,dimtype),rep(3,(n-dimtype*2)))
# how many observations of each type are to be selected in the calibration set
L1=floor(0.7*length(which(Datatype==1)))
L2=floor(0.8*length(which(Datatype==2)))
L3=floor(0.6*length(which(Datatype==3)))
Listecal &lt;- c(L1,L2,L3)

split2 &lt;- d.spls.calval(X=X,y=y,Datatype=Datatype,Listecal=Listecal)

###plotting split2
plot(X[split2$indcal,1],X[split2$indcal,2],xlab="Variable 1",
ylab="Variable 2",pch=19,col="red",main="Calibration and validation split2")
points(X[split2$indval,1],X[split2$indval,2],pch=19,col="green")
legend("topright", legend = c("Calibration points", "Validation points"),
cex = 0.8, col = c("red","green"), pch = c(19,19))

</code></pre>

<hr>
<h2 id='d.spls.cv'>Determination of the number of latent components to be used in a Dual-SPLS regression</h2><span id='topic+d.spls.cv'></span>

<h3>Description</h3>

<p>The function <code>d.spls.cv</code> uses the cross validation approach described in Boulesteix and Strimmer (2005) (see in references) in order to
choose the most adequat number of latent components for a Dual-SPLS regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.cv(X,Y,ncomp,dspls="lasso",ppnu,nu2,nrepcv=30,pctcv=70,indG,gamma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.cv_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values of dimension <code>(n,p)</code>. Each row represents one observation and each column one predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.cv_+3A_y">Y</code></td>
<td>
<p>a numeric vector or a one column matrix of responses. It represents the response variable for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.cv_+3A_ncomp">ncomp</code></td>
<td>
<p>a positive integer or a numeric vector of the number of Dual-SPLS components to choose from.</p>
</td></tr>
<tr><td><code id="d.spls.cv_+3A_dspls">dspls</code></td>
<td>
<p>the norm type of the Dual-SPLS regression applied. Default value is <code>lasso</code>. Options are <code>pls</code>, <code>LS</code>,
<code>ridge</code>, <code>GLA</code>, <code>GLB</code> and <code>GLC</code>.</p>
</td></tr>
<tr><td><code id="d.spls.cv_+3A_ppnu">ppnu</code></td>
<td>
<p>a positive real value, in <code class="reqn">[0,1]</code>. <code>ppnu</code> is the desired
proportion of variables to shrink to zero for each component (see Dual-SPLS methodology).</p>
</td></tr>
<tr><td><code id="d.spls.cv_+3A_nu2">nu2</code></td>
<td>
<p>a positive real value. <code>nu2</code> is a constraint parameter used in the ridge norm.</p>
</td></tr>
<tr><td><code id="d.spls.cv_+3A_nrepcv">nrepcv</code></td>
<td>
<p>a positive integer indicating the number of cross-validation iterations to be performed. Default value is 30.</p>
</td></tr>
<tr><td><code id="d.spls.cv_+3A_pctcv">pctcv</code></td>
<td>
<p>a positive real value in <code class="reqn">[0,100]</code> representing the percentage of observation to be considered in for the
calibration set at each CV iteration. Default value is 70.</p>
</td></tr>
<tr><td><code id="d.spls.cv_+3A_indg">indG</code></td>
<td>
<p>a numeric vector of group index for each observation. It is used in the cases of the group lasso norms.</p>
</td></tr>
<tr><td><code id="d.spls.cv_+3A_gamma">gamma</code></td>
<td>
<p>a numeric vector of the norm <code class="reqn">\Omega</code> of each <code class="reqn">w_g</code> in case <code>GLB</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The procedure is described in the Boulesteix and Strimmer. It is based on randomly selecting, <code>pctcv%</code> of calibration observations at each
cross validation iteration and performing the Dual-SPLS regression. The rest of the observation are used as a validation and the
errors are computed accordingly for each components. <code>nrepcv</code> iterations are done and the mean squared of each of the <code>nrepcv</code> errors for each
component are computed. The latent component with the smallest mean value is selected as the best.
</p>


<h3>Value</h3>

<p>A <code>integer</code> representing the best number of latent components to be used in the Dual-SPLS regression based on the cross validation procedure.
</p>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>References</h3>

<p>A. L. Boulesteix and K. Strimmer (2005). Predicting Transcription Factor Activities from Combined Analysis of Microarray and ChIP Data: A Partial Least Squares Approach. <br />
<br />
H. Wold. Path Models with Latent Variables: The NIPALS Approach. In H.M. Blalock et al., editor, Quantitative Sociology: International Perspectives on Mathematical and Statistical Model Building, pages 307–357. Academic Press, 1975.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### constructing the simulated example
oldpar &lt;- par(no.readonly = TRUE)
n &lt;- 100
p &lt;- 50
nondes &lt;- 20
sigmaondes &lt;- 0.5
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y

#fitting the PLS model
ncomp_PLS &lt;- d.spls.cv(X=X,Y=y,ncomp=10,dspls="pls",nrepcv=20,pctcv=75)
mod.dspls.pls &lt;- d.spls.pls(X=X,y=y,ncp=ncomp_PLS,verbose=TRUE)

str(mod.dspls.pls)

### plotting the observed values VS predicted values for ncomp components
plot(y,mod.dspls.pls$fitted.values[,ncomp_PLS], xlab="Observed values", ylab="Predicted values",
 main=paste("Observed VS Predicted for ", ncomp_PLS," components"))
points(-1000:1000,-1000:1000,type='l')

### plotting the regression coefficients
par(mfrow=c(3,1))

i=ncomp_PLS
plot(1:dim(X)[2],mod.dspls.pls$Bhat[,i],type='l',
    main=paste(" Dual-SPLS (PLS), ncp =", i,
    ylab='',xlab='' ))


#fitting the Dual-SPLS lasso model

ncomplasso &lt;- d.spls.cv(X=X,Y=y,ncomp=10,dspls="lasso",ppnu=0.9,nrepcv=20,pctcv=75)
mod.dspls.lasso &lt;- d.spls.lasso(X=X,y=y,ncp=ncomplasso,ppnu=0.9,verbose=TRUE)

str(mod.dspls.lasso)

### plotting the observed values VS predicted values for ncomp components
plot(y,mod.dspls.lasso$fitted.values[,ncomplasso], xlab="Observed values", ylab="Predicted values",
main=paste("Observed VS Predicted for ", ncomplasso," components"))
points(-1000:1000,-1000:1000,type='l')

### plotting the regression coefficients
par(mfrow=c(3,1))

i=ncomplasso
nz=mod.dspls.lasso$zerovar[i]
plot(1:dim(X)[2],mod.dspls.lasso$Bhat[,i],type='l',
    main=paste(" Dual-SPLS (lasso), ncp =", i, " #0coef =", nz, "/", dim(X)[2]),
    ylab='',xlab='' )
inonz=which(mod.dspls.lasso$Bhat[,i]!=0)
points(inonz,mod.dspls.lasso$Bhat[inonz,i],col='red',pch=19,cex=0.5)
legend("topright", legend ="non null values", bty = "n", cex = 0.8, col = "red",pch=19)
par(oldpar)
</code></pre>

<hr>
<h2 id='d.spls.errorcv'>Computes the error of a cross validation iteration</h2><span id='topic+d.spls.errorcv'></span>

<h3>Description</h3>

<p>The function <code>d.spls.errorcv</code> computes the sum of squared errors of a validation set according to a calibration set <code>cvcal</code> used
to fit the Dual-SPLS regression. This function is an internal function used in the cross validation procedure in order to determine
the best number of latent variables of any of the Dual-SPLS versions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.errorcv(
  cvcal,
  X,
  Y,
  ncomp,
  dspls = "lasso",
  ppnu = 0.9,
  nu2,
  indG,
  gamma
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.errorcv_+3A_cvcal">cvcal</code></td>
<td>
<p>a numeric vector representing the index of the calibration set to be used in the fitting.</p>
</td></tr>
<tr><td><code id="d.spls.errorcv_+3A_x">X</code></td>
<td>
<p>a numeric matrix.</p>
</td></tr>
<tr><td><code id="d.spls.errorcv_+3A_y">Y</code></td>
<td>
<p>a numeric vector representing the response values.</p>
</td></tr>
<tr><td><code id="d.spls.errorcv_+3A_ncomp">ncomp</code></td>
<td>
<p>a numeric vector of the number of latent numbers to use while computing the errors.</p>
</td></tr>
<tr><td><code id="d.spls.errorcv_+3A_dspls">dspls</code></td>
<td>
<p>the norm type of the Dual-SPLS regression applied. Default value is <code>lasso</code>. Options are <code>pls</code>, <code>LS</code>,
<code>ridge</code>, <code>GLA</code>, <code>GLB</code> and <code>GLC</code>.</p>
</td></tr>
<tr><td><code id="d.spls.errorcv_+3A_ppnu">ppnu</code></td>
<td>
<p>a positive real value, in <code class="reqn">[0,1]</code>. <code>ppnu</code> is the desired
proportion of variables to shrink to zero for each component (see Dual-SPLS methodology).</p>
</td></tr>
<tr><td><code id="d.spls.errorcv_+3A_nu2">nu2</code></td>
<td>
<p>a positive real value. <code>nu2</code> is a constraint parameter used in the ridge norm.</p>
</td></tr>
<tr><td><code id="d.spls.errorcv_+3A_indg">indG</code></td>
<td>
<p>a numeric vector of group index for each observation. It is used in the cases of the group lasso norms.</p>
</td></tr>
<tr><td><code id="d.spls.errorcv_+3A_gamma">gamma</code></td>
<td>
<p>a numeric vector of the norm <code class="reqn">\Omega</code> of each <code class="reqn">w_g</code> in the case of <code>GLB</code> norm.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector representing the errors for each fitted model
</p>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.cv">d.spls.cv</a>,<a href="#topic+d.spls.lasso">d.spls.lasso</a>
</p>

<hr>
<h2 id='d.spls.GL'>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the group lasso norms</h2><span id='topic+d.spls.GL'></span>

<h3>Description</h3>

<p>The function performs dimensional reduction with the group lasso norms. Three norms are available
where <code>G</code> is the number of groups, the vectors <code class="reqn">w_g</code> hold the coordinates of <code class="reqn">w</code>
for the observations belonging to the group <code class="reqn">g</code> and <code class="reqn">\alpha_g</code>, <code class="reqn">\lambda_g</code> and <code class="reqn">\gamma_g</code> are all positive scalars.
</p>

<ul>
<li><p> Norm A <em>(generalized norm)</em>: <code class="reqn">\Omega_g(w)=\|w_g\|_2+ \lambda_g \|w_g\|_1</code> where
<code class="reqn">\Omega(w)=\sum_{g} \alpha_g \Omega_g(w)=1 \textrm{ and } \sum_{g=1}^G \alpha_g=1</code>,
</p>
</li>
<li><p> Norm B <em>(particular case)</em>: <code class="reqn">\Omega(w)=\|w\|_2+\sum_{g=1}^G \lambda_g\|w_g\|_1</code>,
</p>
</li>
<li><p> Norm C <em>(particular case)</em>: <code class="reqn">\Omega(w)=\sum_{g=1}^G \alpha_g \|w \|_2+\sum_{g=1}^G \lambda_g \|w_g \|_1</code>
where
<code class="reqn">\sum_{g=1}^G \alpha_g=\sum_{g=1}^G \gamma_g=1</code> <br /> and <code class="reqn">\Omega(w_g)=\gamma_g</code>.
</p>
</li></ul>

<p>Dual-SPLS for the group lasso norms has been designed to confront the situations where the predictors
variables can be divided into distinct meaningful groups. Each group is constrained by an independent
threshold as in the dual sparse lasso methodology,
that is each <code class="reqn">w_g</code> will be collinear to a vector <code class="reqn">z_{\nu_g}</code> built from the coordinate of <code class="reqn">z</code>
and constrained by the threshold <code class="reqn">\nu_g</code>.
</p>
<p>Three variants are defined here depending on the groups combination in the global norm and the weights
assigned to each group. They all give the same result as the lasso norm for <code class="reqn">G=1</code>,
</p>

<ul>
<li><p> Norm A is the generalized norm of the group lasso. applies the lasso norm for each group individually while constraining the overall norm. Moreover,
the Euclidean norm of each <code class="reqn">w_g</code> is computed while minimizing the root mean squares error of prediction,
</p>
</li>
<li><p> Norm B is a particular case and a genuine alternative similar to the lasso-like norm,
</p>
</li>
<li><p> Norm C is another particular case that assigns user to define weights for each group.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>d.spls.GL(X,y,ncp,ppnu,indG,gamma=NULL,norm="A",verbose=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.GL_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values of dimension <code>(n,p)</code>. Each row represents one observation and each column one predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.GL_+3A_y">y</code></td>
<td>
<p>a numeric vector or a one column matrix of responses. It represents the response variable for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.GL_+3A_ncp">ncp</code></td>
<td>
<p>a positive integer. <code>ncp</code> is the number of Dual-SPLS components.</p>
</td></tr>
<tr><td><code id="d.spls.GL_+3A_ppnu">ppnu</code></td>
<td>
<p>a positive real value or a vector of length the number of groups, in <code class="reqn">[0,1]</code>.
<code>ppnu</code> is the desired proportion of variables to shrink to zero for each component and for each group.</p>
</td></tr>
<tr><td><code id="d.spls.GL_+3A_indg">indG</code></td>
<td>
<p>a numeric vector of group index for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.GL_+3A_gamma">gamma</code></td>
<td>
<p>a numeric vector of the norm <code class="reqn">\Omega</code> of each <code class="reqn">w_g</code> in case <code>norm="C"</code>.</p>
</td></tr>
<tr><td><code id="d.spls.GL_+3A_norm">norm</code></td>
<td>
<p>a character specifying the norm chosen between A, B and C. Default value is <code>A</code>.</p>
</td></tr>
<tr><td><code id="d.spls.GL_+3A_verbose">verbose</code></td>
<td>
<p>a Boolean value indicating whether or not to display the iterations steps. Default value is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The resulting solution for <code class="reqn">w</code> and hence for the coefficients vector, in the case of <code>d.spls.GL</code>, has
a simple closed form expression (ref) deriving from the fact that for each group <code class="reqn">g</code>, <code class="reqn">w_g</code>
is collinear to a vector
</p>
<p style="text-align: center;"><code class="reqn">z_{\nu,g}=\textrm{sign}({z_g})(|z_g|-\nu_g)_+.</code>
</p>

<p>Here, for each group <code class="reqn">g</code>, <code class="reqn">\nu_g</code> is the threshold for which <code>ppnu</code> of the group <code class="reqn">g</code> of
the absolute values of the coordinates of <code class="reqn">z_j</code> are greater than <code class="reqn">\nu_g</code>. The norms differ in the value of the threshold for each group,
that is the expression of <code class="reqn">\nu_g</code>. (see reference for detail)
</p>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>Xmean</code></td>
<td>
<p>the mean vector of the predictors matrix <code>X</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> where <code>n</code> is the number of observations. The <code>scores</code> represents
the observations in the new component basis computed by the compression step
of the Dual-SPLS.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that represents the Dual-SPLS components.</p>
</td></tr>
<tr><td><code>Bhat</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that regroups the regression coefficients for each component.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>the vector of length <code>ncp</code> representing the intercept values for each component.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the predicted values of <code>y</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the residuals corresponding
to the difference between the responses and the fitted values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> collecting the parameters of sparsity <code class="reqn">\lambda_g</code> used to fit the model at each iteration and for each group.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> collecting the constraint parameters <code class="reqn">\alpha_g</code>  used to fit the model at each iteration and for each group when the norm chosen is <code>B</code> or <code>C</code>.</p>
</td></tr>
<tr><td><code>zerovar</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> representing the number of variables shrank to zero per component and per group.</p>
</td></tr>
<tr><td><code>PP</code></td>
<td>
<p>the vector of length <code>G</code> specifying the number of variables in each group.</p>
</td></tr>
<tr><td><code>ind_diff0</code></td>
<td>
<p>the list of <code>ncp</code> elements representing the index of the none null regression coefficients elements.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a character specifying the Dual-SPLS norm used. In this case it is either <code>GLA</code>, <code>GLB</code> or <code>GLC</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.GLA">d.spls.GLA</a>, <a href="#topic+d.spls.GLB">d.spls.GLB</a>, <a href="#topic+d.spls.GLC">d.spls.GLC</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
oldpar &lt;- par(no.readonly = TRUE)

####two predictors matrix
### parameters
n &lt;- 100
p &lt;- c(50,100)
nondes &lt;- c(20,30)
sigmaondes &lt;- c(0.05,0.02)
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
X1 &lt;- X[,(1:p[1])]
X2 &lt;- X[,(p[1]+1):sum(p)]
y &lt;- data$y

indG &lt;-c(rep(1,p[1]),rep(2,p[2]))

#fitting the model
ncp &lt;- 10
ppnu &lt;- c(0.99,0.9)

# norm A
mod.dsplsA &lt;- d.spls.GL(X=X,y=y,ncp=ncp,ppnu=ppnu,indG=indG,norm="A",verbose=TRUE)
n &lt;- dim(X)[1]
p &lt;- dim(X)[2]

str(mod.dsplsA)

### plotting the observed values VS predicted values
plot(y,mod.dsplsA$fitted.values[,6], xlab="Observed values", ylab="Predicted values",
 main="Observed VS Predicted for 6 components")
points(-1000:1000,-1000:1000,type='l')

### plotting the regression coefficients

i=6
nz=mod.dsplsA$zerovar[,i]
plot(1:dim(X)[2],mod.dsplsA$Bhat[,i],type='l',
    main=paste(" Dual-SPLS (GLA), ncp =", i, " #0coef =", nz[1], "/", dim(X1)[2]
    , " #0coef =", nz[2], "/", dim(X2)[2]),
    ylab='',xlab='' )
inonz=which(mod.dsplsA$Bhat[,i]!=0)
points(inonz,mod.dsplsA$Bhat[inonz,i],col='red',pch=19,cex=0.5)
legend("topright", legend ="non null values", bty = "n", cex = 0.8, col = "red",pch=19)

# norm B
mod.dsplsB &lt;- d.spls.GL(X=X,y=y,ncp=ncp,ppnu=ppnu,indG=indG,norm="B",verbose=TRUE)

str(mod.dsplsB)

### plotting the observed values VS predicted values
plot(y,mod.dsplsB$fitted.values[,6], xlab="Observed values", ylab="Predicted values",
main="Observed VS Predicted for 6 components")
points(-1000:1000,-1000:1000,type='l')

### plotting the regression coefficients

i=6
nz=mod.dsplsB$zerovar[,i]
plot(1:dim(X)[2],mod.dsplsB$Bhat[,i],type='l',
    main=paste(" Dual-SPLS (GLB), ncp =", i, " #0coef =", nz[1], "/", dim(X1)[2]
    , " #0coef =", nz[2], "/", dim(X2)[2]),
    ylab='',xlab='' )
inonz=which(mod.dsplsB$Bhat[,i]!=0)
points(inonz,mod.dsplsB$Bhat[inonz,i],col='red',pch=19,cex=0.5)

legend("topright", legend ="non null values", bty = "n", cex = 0.8, col = "red",pch=19)

# norm C
mod.dsplsC &lt;- d.spls.GL(X=X,y=y,ncp=ncp,ppnu=ppnu,indG=indG,gamma=c(0.5,0.5),norm="C",verbose=TRUE)
n &lt;- dim(X)[1]
p &lt;- dim(X)[2]

str(mod.dsplsC)

### plotting the observed values VS predicted values
plot(y,mod.dsplsC$fitted.values[,6], xlab="Observed values", ylab="Predicted values",
main="Observed VS Predicted for 6 components")
points(-1000:1000,-1000:1000,type='l')

### plotting the regression coefficients

i=6
nz=mod.dsplsC$zerovar[,i]
plot(1:dim(X)[2],mod.dsplsC$Bhat[,i],type='l',
    main=paste(" Dual-SPLS (GLC), ncp =", i, " #0coef =", nz[1], "/", dim(X1)[2]
    , " #0coef =", nz[2], "/", dim(X2)[2]),
    ylab='',xlab='' )
inonz=which(mod.dsplsC$Bhat[,i]!=0)
points(inonz,mod.dsplsC$Bhat[inonz,i],col='red',pch=19,cex=0.5)
legend("topright", legend ="non null values", bty = "n", cex = 0.8, col = "red",pch=19)

par(oldpar)
</code></pre>

<hr>
<h2 id='d.spls.GLA'>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the group lasso norm A</h2><span id='topic+d.spls.GLA'></span>

<h3>Description</h3>

<p>The function <code>d.spls.GLA</code> performs dimensional reduction as in PLS methodology combined to variable selection using the
Dual-SPLS algorithm with the norm </p>
<p style="text-align: center;"><code class="reqn">\Omega_g(w)=\|w_g\|_2+ \lambda_g \|w_g\|_1</code>
</p>
<p> for combined data where
<code class="reqn">\Omega(w)=\sum_{g=1}{^G} \alpha_g \Omega_g(w)=1</code>;
<code class="reqn">\sum_{g=1}^G \alpha_g=1</code> and <code>G</code> is the number of groups.
Dual-SPLS for the group lasso norms has been designed to confront the situations where the predictors
variables can be divided in distinct meaningful groups. Each group is constrained by an independent
threshold as in the dual sparse lasso methodology,
that is each <code class="reqn">w_g</code> will be collinear to a vector <code class="reqn">z.\nu_g</code> built from the coordinate of <code class="reqn">z</code>
and constrained by the threshold <code class="reqn">\nu_g</code>. Norm A i a generalized group lasso-like norm that applies the lasso norm for each group individually while constraining the overall norm. Moreover,
the Euclidian norm of each <code class="reqn">w_g</code> is computed while minimizing the root mean squares error of prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.GLA(X, y, ncp, ppnu, indG, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.GLA_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values of dimension <code>(n,p)</code>. Each row represents one observation and each column one predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.GLA_+3A_y">y</code></td>
<td>
<p>a numeric vector or a one column matrix of responses. It represents the response variable for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.GLA_+3A_ncp">ncp</code></td>
<td>
<p>a positive integer. <code>ncp</code> is the number of Dual-SPLS components.</p>
</td></tr>
<tr><td><code id="d.spls.GLA_+3A_ppnu">ppnu</code></td>
<td>
<p>a positive real value or a vector of length the number of groups, in <code class="reqn">[0,1]</code>.
<code>ppnu</code> is the desired proportion of variables to shrink to zero for each component and for each group.</p>
</td></tr>
<tr><td><code id="d.spls.GLA_+3A_indg">indG</code></td>
<td>
<p>a numeric vector of group index for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.GLA_+3A_verbose">verbose</code></td>
<td>
<p>a Boolean value indicating whether or not to display the iterations steps.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>Xmean</code></td>
<td>
<p>the mean vector of the predictors matrix <code>X</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> where <code>n</code> is the number of observations. The <code>scores</code> represents
the observations in the new component basis computed by the compression step
of the Dual-SPLS.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that represents the Dual-SPLS components.</p>
</td></tr>
<tr><td><code>Bhat</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that regroups the regression coefficients for each component.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>the vector of length <code>ncp</code> representing the intercept values for each component.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the predicted values of <code>y</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the residuals corresponding
to the difference between the responses and the fitted values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> collecting the parameters of sparsity <code class="reqn">\lambda_g</code> used to fit the model at each iteration and for each group.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> collecting the constraint parameters <code class="reqn">\alpha_g</code>  used to fit the model at each iteration and for each group.</p>
</td></tr>
<tr><td><code>zerovar</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> representing the number of variables shrank to zero per component and per group.</p>
</td></tr>
<tr><td><code>PP</code></td>
<td>
<p>the vector of length <code>G</code> specifying the number of variables in each group.</p>
</td></tr>
<tr><td><code>ind_diff0</code></td>
<td>
<p>the list of <code>ncp</code> elements representing the index of the none null regression coefficients elements.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a character specifying the Dual-SPLS norm used. In this case it is <code>GLA</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.GLA">d.spls.GLA</a>,<a href="#topic+d.spls.GLB">d.spls.GLB</a>,<a href="#topic+d.spls.GL">d.spls.GL</a>
</p>

<hr>
<h2 id='d.spls.GLB'>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the group lasso norm B</h2><span id='topic+d.spls.GLB'></span>

<h3>Description</h3>

<p>The function <code>d.spls.GLB</code> performs dimensional reduction as in PLS methodology combined to variable selection using the
Dual-SPLS algorithm with the norm </p>
<p style="text-align: center;"><code class="reqn">\Omega(w)=\|w\|_2+\sum_{g=1}^G \lambda_g\|w_g\|_1</code>
</p>
<p> for combined data.
Where <code>G</code> is the number of groups.
Dual-SPLS for the group lasso norms has been designed to confront the situations where the predictors
variables can be divided in distinct meaningful groups. Each group is constrained by an independent
threshold as in the dual sparse lasso methodology,
that is each <code class="reqn">w_g</code> will be collinear to a vector <code class="reqn">z.\nu_g</code> built from the coordinate of <code class="reqn">z</code>
and constrained by the threshold <code class="reqn">\nu_g</code>. The Norm B is the genuine alternative and a particular case of the generalized norm A.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.GLB(X, y, ncp, ppnu, indG, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.GLB_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values of dimension <code>(n,p)</code>. Each row represents one observation and each column one predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.GLB_+3A_y">y</code></td>
<td>
<p>a numeric vector or a one column matrix of responses. It represents the response variable for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.GLB_+3A_ncp">ncp</code></td>
<td>
<p>a positive integer. <code>ncp</code> is the number of Dual-SPLS components.</p>
</td></tr>
<tr><td><code id="d.spls.GLB_+3A_ppnu">ppnu</code></td>
<td>
<p>a positive real value or a vector of length the number of groups, in <code class="reqn">[0,1]</code>.
<code>ppnu</code> is the desired proportion of variables to shrink to zero for each component and for each group.</p>
</td></tr>
<tr><td><code id="d.spls.GLB_+3A_indg">indG</code></td>
<td>
<p>a numeric vector of group index for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.GLB_+3A_verbose">verbose</code></td>
<td>
<p>a Boolean value indicating whether or not to display the iterations steps. Default value is <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>Xmean</code></td>
<td>
<p>the mean vector of the predictors matrix <code>X</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> where <code>n</code> is the number of observations. The <code>scores</code> represents
the observations in the new component basis computed by the compression step
of the Dual-SPLS.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that represents the Dual-SPLS components.</p>
</td></tr>
<tr><td><code>Bhat</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that regroups the regression coefficients for each component.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>the vector of length <code>ncp</code> representing the intercept values for each component.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the predicted values of <code>y</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the residuals corresponding
to the difference between the responses and the fitted values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> collecting the parameters of sparsity <code class="reqn">\lambda_g</code> used to fit the model at each iteration and for each group.</p>
</td></tr>
<tr><td><code>zerovar</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> representing the number of variables shrank to zero per component and per group.</p>
</td></tr>
<tr><td><code>PP</code></td>
<td>
<p>the vector of length <code>G</code> specifying the number of variables in each group.</p>
</td></tr>
<tr><td><code>ind_diff0</code></td>
<td>
<p>the list of <code>ncp</code> elements representing the index of the none null regression coefficients elements.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a character specifying the Dual-SPLS norm used. In this case it is <code>GLB</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.GLA">d.spls.GLA</a>, <a href="#topic+d.spls.GLC">d.spls.GLC</a>, <a href="#topic+d.spls.GL">d.spls.GL</a>
</p>

<hr>
<h2 id='d.spls.GLC'>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the group lasso norm C</h2><span id='topic+d.spls.GLC'></span>

<h3>Description</h3>

<p>The function <code>d.spls.GLC</code> performs dimensional reduction as in PLS methodology combined to variable selection using the
Dual-SPLS algorithm with the norm </p>
<p style="text-align: center;"><code class="reqn">\Omega(w)=\sum_{g=1}^G \alpha_g \|w \|_2+\sum_{g=1}^G \lambda_g \|w_g \|_1</code>
</p>
<p> for
<code class="reqn">\sum_{g=1}^G \alpha_g=1</code>;  <code class="reqn">\Omega(w_g)=\gamma_g</code> and <code class="reqn">\sum_{g=1}^G \gamma_g=1.</code> Where <code>G</code> is the number of groups.
Dual-SPLS for the group lasso norms has been designed to confront the situations where the predictors
variables can be divided in distinct meaningful groups. Each group is constrained by an independent
threshold as in the dual sparse lasso methodology,
that is each <code class="reqn">w_g</code> will be collinear to a vector <code class="reqn">z.\nu_g</code> built from the coordinate of <code class="reqn">z</code>
and constrained by the threshold <code class="reqn">\nu_g</code>. Norm C is a particular case of the generalized norm A that assigns user to define weights for each group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.GLC(X, y, ncp, ppnu, indG, gamma, verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.GLC_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values of dimension <code>(n,p)</code>. Each row represents one observation and each column one predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.GLC_+3A_y">y</code></td>
<td>
<p>a numeric vector or a one column matrix of responses. It represents the response variable for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.GLC_+3A_ncp">ncp</code></td>
<td>
<p>a positive integer. <code>ncp</code> is the number of Dual-SPLS components.</p>
</td></tr>
<tr><td><code id="d.spls.GLC_+3A_ppnu">ppnu</code></td>
<td>
<p>a positive real value or a vector of length the number of groups, in <code class="reqn">[0,1]</code>.
<code>ppnu</code> is the desired proportion of variables to shrink to zero for each component and for each group.</p>
</td></tr>
<tr><td><code id="d.spls.GLC_+3A_indg">indG</code></td>
<td>
<p>a numeric vector of group index for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.GLC_+3A_gamma">gamma</code></td>
<td>
<p>a numeric vector of the norm <code class="reqn">\Omega</code> for each <code class="reqn">w_g</code> verifying <code class="reqn">\sum_{g=1}^G \gamma_g=1</code>.</p>
</td></tr>
<tr><td><code id="d.spls.GLC_+3A_verbose">verbose</code></td>
<td>
<p>a Boolean value indicating whether or not to display the iterations steps.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>Xmean</code></td>
<td>
<p>the mean vector of the predictors matrix <code>X</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> where <code>n</code> is the number of observations. The <code>scores</code> represents
the observations in the new component basis computed by the compression step
of the Dual-SPLS.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that represents the Dual-SPLS components.</p>
</td></tr>
<tr><td><code>Bhat</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that regroups the regression coefficients for each component.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>the vector of length <code>ncp</code> representing the intercept values for each component.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the predicted values of <code>y</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the residuals corresponding
to the difference between the responses and the fitted values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> collecting the parameters of sparsity <code class="reqn">\lambda_g</code> used to fit the model at each iteration and for each group.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> collecting the constraint parameters <code class="reqn">\alpha_g</code>  used to fit the model at each iteration and for each group.</p>
</td></tr>
<tr><td><code>zerovar</code></td>
<td>
<p>the matrix of dimension <code>(G,ncp)</code> representing the number of variables shrank to zero per component and per group.</p>
</td></tr>
<tr><td><code>PP</code></td>
<td>
<p>the vector of length <code>G</code> specifying the number of variables in each group.</p>
</td></tr>
<tr><td><code>ind_diff0</code></td>
<td>
<p>the list of <code>ncp</code> elements representing the index of the none null regression coefficients elements.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a character specifying the Dual-SPLS norm used. In this case it is <code>GLC</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.GLA">d.spls.GLA</a>,<a href="#topic+d.spls.GLC">d.spls.GLC</a>,<a href="#topic+d.spls.GL">d.spls.GL</a>
</p>

<hr>
<h2 id='d.spls.lasso'>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the lasso norm</h2><span id='topic+d.spls.lasso'></span>

<h3>Description</h3>

<p>The function <code>d.spls.lasso</code> performs dimensional reduction as in the PLS1 methodology combined with variable selection via the
Dual-SPLS algorithm with the norm </p>
<p style="text-align: center;"><code class="reqn">\Omega(w)=\lambda \|w\|_1 + \|w\|_2.</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>d.spls.lasso(X,y,ncp,ppnu,verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.lasso_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values of dimension <code>(n,p)</code>. Each row represents one observation and each column one predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.lasso_+3A_y">y</code></td>
<td>
<p>a numeric vector or a one column matrix of responses. It represents the response variable for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.lasso_+3A_ncp">ncp</code></td>
<td>
<p>a positive integer. <code>ncp</code> is the number of Dual-SPLS components.</p>
</td></tr>
<tr><td><code id="d.spls.lasso_+3A_ppnu">ppnu</code></td>
<td>
<p>a positive real value, in <code class="reqn">[0,1]</code>. <code>ppnu</code> is the desired
proportion of variables to shrink to zero for each component (see Dual-SPLS methodology).</p>
</td></tr>
<tr><td><code id="d.spls.lasso_+3A_verbose">verbose</code></td>
<td>
<p>a Boolean value indicating whether or not to display the iterations steps. Default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The resulting solution for <code class="reqn">w</code> and hence for the coefficients vector, in the case of <code>d.spls.lasso</code>, has
a simple closed form expression (ref) deriving from the fact that <code class="reqn">w</code> is collinear to a vector <code class="reqn">z_{\nu}</code> of coordinates
</p>
<p style="text-align: center;"><code class="reqn">z_{\nu_j}=\textrm{sign}({z_j})(|z_j|-\nu)_+.</code>
</p>

<p>Here <code class="reqn">\nu</code> is the threshold for which <code>ppnu</code> of
the absolute values of the coordinates of <code class="reqn">z=X^Ty</code> are greater than <code class="reqn">\nu</code>.
</p>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>Xmean</code></td>
<td>
<p>the mean vector of the predictors matrix <code>X</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> where <code>n</code> is the number of observations. The <code>scores</code> represents
the observations in the new component basis computed by the compression step
of the Dual-SPLS.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that represents the Dual-SPLS components.</p>
</td></tr>
<tr><td><code>Bhat</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that regroups the regression coefficients for each component.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>the vector of intercept values for each component.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the predicted values of <code>y</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the residuals corresponding
to the difference between the responses and the fitted values.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>the vector of length <code>ncp</code> collecting the parameters of sparsity  used to fit the model at each iteration.</p>
</td></tr>
<tr><td><code>zerovar</code></td>
<td>
<p>the vector of length <code>ncp</code> representing the number of variables shrank to zero per component.</p>
</td></tr>
<tr><td><code>ind_diff0</code></td>
<td>
<p>the list of <code>ncp</code> elements representing the index of the none null regression coefficients elements.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a character specifying the Dual-SPLS norm used. In this case it is <code>lasso</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### constructing the simulated example
oldpar &lt;- par(no.readonly = TRUE)
n &lt;- 100
p &lt;- 50
nondes &lt;- 20
sigmaondes &lt;- 0.5
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y

#fitting the model
mod.dspls &lt;- d.spls.lasso(X=X,y=y,ncp=10,ppnu=0.9,verbose=TRUE)

str(mod.dspls)

### plotting the observed values VS predicted values for 6 components
plot(y,mod.dspls$fitted.values[,6], xlab="Observed values", ylab="Predicted values",
main="Observed VS Predicted for 6 components")
points(-1000:1000,-1000:1000,type='l')

### plotting the regression coefficients
par(mfrow=c(3,1))

i=6
nz=mod.dspls$zerovar[i]
plot(1:dim(X)[2],mod.dspls$Bhat[,i],type='l',
    main=paste(" Dual-SPLS (lasso), ncp =", i, " #0coef =", nz, "/", dim(X)[2]),
    ylab='',xlab='' )
inonz=which(mod.dspls$Bhat[,i]!=0)
points(inonz,mod.dspls$Bhat[inonz,i],col='red',pch=19,cex=0.5)
legend("topright", legend ="non null values", bty = "n", cex = 0.8, col = "red",pch=19)
par(oldpar)
</code></pre>

<hr>
<h2 id='d.spls.listecal'>Determine the number of observations to select from each cell</h2><span id='topic+d.spls.listecal'></span>

<h3>Description</h3>

<p>The function <code>d.spls.listecal</code> detemines the number of observations to select as calibration from
each cell.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.listecal(Xtype, pcal)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.listecal_+3A_xtype">Xtype</code></td>
<td>
<p>a vector of index specifying to which group belongs each observation.</p>
</td></tr>
<tr><td><code id="d.spls.listecal_+3A_pcal">pcal</code></td>
<td>
<p>a positive integer between 0 and 100. <code>pcal</code> is the percentage
of calibration samples to be selected.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector specifying how many observations from each group should be selected as calibration.
</p>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.type">d.spls.type</a>,<a href="#topic+d.spls.calval">d.spls.calval</a>,<a href="#topic+d.spls.split">d.spls.split</a>
</p>

<hr>
<h2 id='d.spls.LS'>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the least squares norm</h2><span id='topic+d.spls.LS'></span>

<h3>Description</h3>

<p>The function <code>d.spls.LS</code> performs dimensional reduction as in PLS1 methodology combined to variable selection via the
Dual-SPLS algorithm with the norm </p>
<p style="text-align: center;"><code class="reqn">\Omega(w)=\lambda \|N_1w\|_1 + \|Xw\|_2.</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>d.spls.LS(X,y,ncp,ppnu,verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.LS_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values of dimension <code>(n,p)</code>. Each row represents one observation and each column one predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.LS_+3A_y">y</code></td>
<td>
<p>a numeric vector or a one column matrix of responses. It represents the response variable for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.LS_+3A_ncp">ncp</code></td>
<td>
<p>a positive integer. <code>ncp</code> is the number of Dual-SPLS components.</p>
</td></tr>
<tr><td><code id="d.spls.LS_+3A_ppnu">ppnu</code></td>
<td>
<p>a positive real value, in <code class="reqn">[0,1]</code>. <code>ppnu</code> is the desired
proportion of variables to shrink to zero for each component (see Dual-SPLS methodology).</p>
</td></tr>
<tr><td><code id="d.spls.LS_+3A_verbose">verbose</code></td>
<td>
<p>a Boolean value indicating whether or not to display the iterations steps. Default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The resulting solution for <code class="reqn">w</code> and hence for the coefficients vector, in the case of <code>d.spls.LS</code>, has
a simple closed form expression (ref) deriving from the fact that <code class="reqn">w</code> is collinear to a vector <code class="reqn">z_{\nu}</code> of coordinates
</p>
<p style="text-align: center;"><code class="reqn">z_{\nu_j}=\textrm{sign}(\hat{\beta}_{LS_j})(|\hat{\beta}_{LS_j}|-\nu)_+.</code>
</p>

<p>Here <code class="reqn">\nu</code> is the threshold for which <code>ppnu</code> of
the absolute values of the coordinates of <code class="reqn">\hat{\beta}_{LS}</code> are greater than <code class="reqn">\nu</code> where <code class="reqn">\hat{\beta}_{LS}=(X^TX)^{-1}X^Ty</code>.
Therefore, the least squares norm is only adapted to the situation where XT X is invertible.
At each step the singularity of XT X is tested by computing its condition number.
A finite large ratio means that the matrix is close to being singular.
</p>
<p><code class="reqn">N_1</code> does not intervene in the resolution step. Whoever, <code class="reqn">z_{\nu_j}</code> is constructed according <code class="reqn">N_1</code>.
Therefore, proving that <code class="reqn">N_1</code> exists is enough. (see references for more details.)
If the singularity condition is not verified, one might choose to apply the Dual-SPLS for the ridge norm.
</p>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>Xmean</code></td>
<td>
<p>the mean vector of the predictors matrix <code>X</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> where <code>n</code> is the number of observations. The <code>scores</code> represents
the observations in the new component basis computed by the compression step
of the Dual-SPLS.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that represents the Dual-SPLS components.</p>
</td></tr>
<tr><td><code>Bhat</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that regroups the regression coefficients for each component.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>the vector of intercept values for each component.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the predicted values of <code>y</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the residuals corresponding
to the difference between the responses and the fitted values.</p>
</td></tr>
<tr><td><code>zerovar</code></td>
<td>
<p>the vector of length <code>ncp</code> representing the number of variables shrank to zero per component.</p>
</td></tr>
<tr><td><code>ind_diff0</code></td>
<td>
<p>the list of <code>ncp</code> elements representing the index of the none null regression coefficients elements.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a character specifying the Dual-SPLS norm used. In this case it is <code>LS</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.ridge">d.spls.ridge</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### parameters
oldpar &lt;- par(no.readonly = TRUE)
set.seed(14)
n &lt;- 1000
p &lt;- 40
nondes &lt;- 100
sigmaondes &lt;- 0.01
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y

#fitting the model
mod.dspls &lt;- d.spls.LS(X=X,y=y,ncp=3,ppnu=0.9,verbose=TRUE)

str(mod.dspls)

### plotting the observed values VS predicted values
plot(y,mod.dspls$fitted.values[,3], xlab="Observed values", ylab="Predicted values",
main="Observed VS Predicted for 3 components")
points(-1000:1000,-1000:1000,type='l')

### plotting the regression coefficients
par(mfrow=c(3,1))

i=3
nz=mod.dspls$zerovar[i]
plot(1:dim(X)[2],mod.dspls$Bhat[,i],type='l',
    main=paste(" Dual-SPLS (LS), ncp =", i, " #0coef =", nz, "/", dim(X)[2]),
    ylab='',xlab='' )
inonz=which(mod.dspls$Bhat[,i]!=0)
points(inonz,mod.dspls$Bhat[inonz,i],col='red',pch=19,cex=0.5)
legend("topright", legend ="non null values", bty = "n", cex = 0.8, col = "red",pch=19)
par(oldpar)
</code></pre>

<hr>
<h2 id='d.spls.metric'>Computes predictions criterias</h2><span id='topic+d.spls.metric'></span>

<h3>Description</h3>

<p>This function computes evaluation metrics commonly used in modelling. It provides the values of the root mean square
error (RMSE), the mean absolute error (MAE) and the Rsquared.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.metric(hat.y,real.y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.metric_+3A_hat.y">hat.y</code></td>
<td>
<p>a numeric vector. It represents the fitted response variable for each observation using a Dual-SPLS method.</p>
</td></tr>
<tr><td><code id="d.spls.metric_+3A_real.y">real.y</code></td>
<td>
<p>a numeric vector. It represents the response variable for each observation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Root Mean Square Error (RMSE) is the standard deviation of the residuals. It is computed as follows:
</p>
<p style="text-align: center;"><code class="reqn">RMSE=\sqrt{\sum_{i=1}^n \frac{(y_{fi}-y_{ri})^2}{n}}.</code>
</p>

<p>The Mean Absolute Error measures the average magnitude of the errors in a set of predictions,
without considering their direction. It is computed as follows:
</p>
<p style="text-align: center;"><code class="reqn">MAE=\frac{1}{n}\sum_{i=1}^n |y_{fi}-y_{ri}|.</code>
</p>

<p>The Rsquared represents the proportion of the variance for a dependent
variable that's explained by an independent variable in a regresison. It is computed as follows:
</p>
<p style="text-align: center;"><code class="reqn">R2=\frac{\sum_{i=1}^n (y_{fi}-\bar{y})^2}{\sum_{i=1}^n (y_{ri}-\bar{y})^2}.</code>
</p>

<p>Where <code class="reqn">\bar{y}=\frac{1}{n}\sum_{i=1}^n y_{fi}</code>. Note that <code class="reqn">y_f</code> are the fitted values and <code class="reqn">y_r</code> are the real ones.
</p>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>RMSE</code></td>
<td>
<p>the vector of the root mean square error values for each component.</p>
</td></tr>
<tr><td><code>MAE</code></td>
<td>
<p>the vector of the mean absolute error values for each component.</p>
</td></tr>
<tr><td><code>Rsquared</code></td>
<td>
<p>the vector of the Rsquared values for each component.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### constructing the simulated example
n &lt;- 100
p &lt;- 50
nondes &lt;- 20
sigmaondes &lt;- 0.5
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y

#fitting the Dual-SPLS lasso model

ncomplasso &lt;- d.spls.cv(X=X,Y=y,ncomp=10,dspls="lasso",ppnu=0.9,nrepcv=20,pctcv=75)
mod.dspls.lasso &lt;- d.spls.lasso(X=X,y=y,ncp=ncomplasso,ppnu=0.9,verbose=TRUE)

predmetric= d.spls.metric(mod.dspls.lasso$fitted.values,y)

#Error plots
plot(1:ncomplasso,predmetric$RMSE,
main=("Root mean squares error values"),xlab='Number of components',ylab='Errors',col='blue',pch=19)
lines(1:ncomplasso,predmetric$RMSE,col='blue')
points(1:ncomplasso,predmetric$MAE,col='red',pch=19)
lines(1:ncomplasso,predmetric$MAE,col='red')
points(1:ncomplasso,predmetric$R2,col='green',pch=19)
lines(1:ncomplasso,predmetric$R2,col='green')
legend("topright", legend = c("RMSE", "MAE", "R2"), bty = "n",
 cex = 0.8, col = c("blue", "red","green"), lty = c(1,1,1))
</code></pre>

<hr>
<h2 id='d.spls.NIR'>Dual Sparse Partial Least Squares (Dual-SPLS) Near Infrared data</h2><span id='topic+d.spls.NIR'></span>

<h3>Description</h3>

<p>This dataset contains near infra red spectra of refined petroleum samples, associated with the values of their density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(d.spls.NIR)
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> of 208 observations. The NIR data contains 1557 variables and the density is a one dimensional vector.
</p>


<h3>Details</h3>

<p>The NIR data is composed of 1557 variables that represent a regular sequence of the absorbance interval.
</p>
<p>This data is useful when building a Dual-SPLS regression with <code>NIR</code> data as the predictor and <code>density</code> as a response.
</p>

<hr>
<h2 id='d.spls.norm1'>Computing the l1 and l2 norm</h2><span id='topic+d.spls.norm1'></span>

<h3>Description</h3>

<p>The internal functions <code>norm1</code> and <code>norm2</code> computes the l1 and l2 norm of any vector
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.norm1(x)

d.spls.norm2(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.norm1_+3A_x">x</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A positive integer of the norm value.
</p>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>

<hr>
<h2 id='d.spls.plot'>Plots the coefficient curve of a Dual-SPLS regression</h2><span id='topic+d.spls.plot'></span>

<h3>Description</h3>

<p>The function <code>dual.spls.plot</code> provides the regression coefficient curves of a Dual-SPLS model for a specified number of components
and the mean of the original data plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.plot(mod.dspls,ncomp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.plot_+3A_mod.dspls">mod.dspls</code></td>
<td>
<p>is a fitted Dual-SPLS object.</p>
</td></tr>
<tr><td><code id="d.spls.plot_+3A_ncomp">ncomp</code></td>
<td>
<p>a positive integer or a numeric vector of the number of Dual-SPLS components to consider.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plots allow the visualization of the results by comparing the mean of the original data to the coefficients regression in the
case of a Dual-SPLS regression. The plots provided correspond to the Dual-SPLS coefficients for each <code>ncomp</code> desired.
</p>


<h3>Value</h3>

<p>no return value
</p>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### constructing the simulated example
n &lt;- 100
p &lt;- 50
nondes &lt;- 20
sigmaondes &lt;- 0.5
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y

#fitting the Dual-SPLS lasso model

mod.dspls.lasso &lt;- d.spls.lasso(X=X,y=y,ncp=10,ppnu=0.9,verbose=TRUE)

ncomp=c(5,6,7)
d.spls.plot(mod.dspls.lasso,ncomp)
</code></pre>

<hr>
<h2 id='d.spls.pls'>Univariate Partial Least Squares regression</h2><span id='topic+d.spls.pls'></span>

<h3>Description</h3>

<p>The function <code>d.spls.pls</code> performs the PLS1 dimensional reduction methodology using Wold's NIPALS algorithm. It is
a Dual-SPLS regression with the norm </p>
<p style="text-align: center;"><code class="reqn">\Omega(w)=||w||_2.</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>d.spls.pls(X,y,ncp,verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.pls_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values of dimension <code>(n,p)</code>. Each row represents one observation and each column one predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.pls_+3A_y">y</code></td>
<td>
<p>a numeric vector or a one column matrix of responses. It represents the response variable for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.pls_+3A_ncp">ncp</code></td>
<td>
<p>a positive integer. <code>ncp</code> is the number of Dual-SPLS components.</p>
</td></tr>
<tr><td><code id="d.spls.pls_+3A_verbose">verbose</code></td>
<td>
<p>a Boolean value indicating whether or not to display the iterations steps. Default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The resulting solution for <code class="reqn">w</code> and hence for the coefficients vector, in the PLS regression for one component is
<code class="reqn">w=X^Ty</code>. In order to compute the next components, a deflation step is performed only considering the parts of
<code class="reqn">X</code> that are orthogonal to the previous components.
</p>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>Xmean</code></td>
<td>
<p>the mean vector of the predictors matrix <code>X</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> where <code>n</code> is the number of observations.The <code>scores</code> represents
the observations in the new component basis computed by the compression step
of the Dual-SPLS.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that represents the Dual-SPLS components.</p>
</td></tr>
<tr><td><code>Bhat</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that regroups the regression coefficients for each component.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>the vector of intercept values for each component.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the predicted values of <code>y</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the residuals corresponding
to the difference between the responses and the fitted values.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a character specifying the Dual-SPLS norm used. In this case it is <code>ridge</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>References</h3>

<p>H. Wold. Path Models with Latent Variables: The NIPALS Approach. In H.M. Blalock et al., editor, Quantitative Sociology: International Perspectives on Mathematical and Statistical Model Building, pages 307–357. Academic Press, 1975.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### constructing the simulated example
oldpar &lt;- par(no.readonly = TRUE)
n &lt;- 100
p &lt;- 50
nondes &lt;- 20
sigmaondes &lt;- 0.5
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y

#fitting the model
mod.dspls &lt;- d.spls.pls(X=X,y=y,ncp=10,verbose=TRUE)

str(mod.dspls)

### plotting the observed values VS predicted values for 6 components
plot(y,mod.dspls$fitted.values[,6], xlab="Observed values", ylab="Predicted values",
 main="Observed VS Predicted for 6 components")
points(-1000:1000,-1000:1000,type='l')

### plotting the regression coefficients
par(mfrow=c(3,1))

i=6
plot(1:dim(X)[2],mod.dspls$Bhat[,i],type='l',
    main=paste(" PLS , ncp =", i),
    ylab='',xlab='' )
par(oldpar)

</code></pre>

<hr>
<h2 id='d.spls.predict'>Makes predictions from a fitted Dual-SPLS model</h2><span id='topic+d.spls.predict'></span>

<h3>Description</h3>

<p>The function <code>d.spls</code> makes predictions from a fitted Dual-SPLS model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.predict(mod.dspls,X,liste_cp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.predict_+3A_mod.dspls">mod.dspls</code></td>
<td>
<p>a fitted Dual-SPLS object.</p>
</td></tr>
<tr><td><code id="d.spls.predict_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values. Each row represents an observation and each column a predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.predict_+3A_liste_cp">liste_cp</code></td>
<td>
<p>a numeric vector of the components for which prediction is required.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The coefficients computed in the Dual-SPLS object are used to predict the fitted response values of new matrix <code>X</code>.
Users can choose how many Dual-SPLS components should be used.
</p>


<h3>Value</h3>

<p>Vector or matrix of estimated responses.
</p>


<h3>Author(s)</h3>

<p>François Wahl Louna Alsouki
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### parameters
n &lt;- 100
p &lt;- 50
nondes &lt;- 20
sigmaondes &lt;- 0.5
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y

pcal &lt;- 70
ncells &lt;- 3

split &lt;- d.spls.calval(X=X,pcal=pcal,y=y,ncells=ncells)

indcal= split$indcal
indval= split$indval

Xcal=X[indcal,]
Xval=X[indval,]
ycal=y[indcal]
yval=y[indval]

#fitting the model
ncp=10
mod.dspls &lt;- d.spls.lasso(X=Xcal,y=ycal,ncp=ncp,ppnu=0.9,verbose=TRUE)

ycalhat=mod.dspls$fitted.values
rescal=mod.dspls$residuals
# predictions on validation
yvalhat=d.spls.predict(mod.dspls,Xval, liste_cp=1:ncp)

#Computing RMSE error
RMSEcal.dspls=apply(rescal,2,function(u) sqrt(mean(u^2)) )
RMSEval.dspls=apply(yvalhat,2,function(u) sqrt(mean((yval-u)^2)) )



</code></pre>

<hr>
<h2 id='d.spls.print'>Print function for Dual-SPLS models</h2><span id='topic+d.spls.print'></span>

<h3>Description</h3>

<p>The function <code>d.spls.print</code> pisplays the values of a Dual-SPLS regression parameters of sparsity and the number of variables
shrinked to zero for a specified number of components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.print(mod.dspls,ncomp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.print_+3A_mod.dspls">mod.dspls</code></td>
<td>
<p>is a fitted Dual-SPLS object.</p>
</td></tr>
<tr><td><code id="d.spls.print_+3A_ncomp">ncomp</code></td>
<td>
<p>a positive integer of the number of Dual-SPLS components.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>no return value
</p>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### constructing the simulated example
n &lt;- 100
p &lt;- 50
nondes &lt;- 20
sigmaondes &lt;- 0.5
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y

#fitting the Dual-SPLS lasso model

ncomplasso &lt;- d.spls.cv(X=X,Y=y,ncomp=10,dspls="lasso",ppnu=0.9,nrepcv=20,pctcv=75)
mod.dspls.lasso &lt;- d.spls.lasso(X=X,y=y,ncp=ncomplasso,ppnu=0.9,verbose=TRUE)

d.spls.print(mod.dspls.lasso,ncomplasso)
</code></pre>

<hr>
<h2 id='d.spls.ridge'>Dual Sparse Partial Least Squares (Dual-SPLS) regression for the ridge norm</h2><span id='topic+d.spls.ridge'></span>

<h3>Description</h3>

<p>The function <code>d.spls.lasso</code> performs dimensional reduction as in PLS methodology combined to variable selection via the
Dual-SPLS algorithm with the norm </p>
<p style="text-align: center;"><code class="reqn">\Omega(w)=\lambda_1 \|w\|_1 +\lambda_2 \|Xw\|_2 + \|w\|_2.</code>
</p>

<p>In the algorithm, the parameters <code class="reqn">\lambda</code>, <code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code>are transformed into more meaningful values, <code>ppnu</code> and <code class="reqn">\nu_2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.ridge(X,y,ncp,ppnu,nu2,verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.ridge_+3A_x">X</code></td>
<td>
<p>a numeric matrix of predictors values of dimension <code>(n,p)</code>. Each row represents one observation and each column one predictor variable.</p>
</td></tr>
<tr><td><code id="d.spls.ridge_+3A_y">y</code></td>
<td>
<p>a numeric vector or a one column matrix of responses. It represents the response variable for each observation.</p>
</td></tr>
<tr><td><code id="d.spls.ridge_+3A_ncp">ncp</code></td>
<td>
<p>a positive integer. <code>ncp</code> is the number of Dual-SPLS components.</p>
</td></tr>
<tr><td><code id="d.spls.ridge_+3A_ppnu">ppnu</code></td>
<td>
<p>a positive real value, in <code class="reqn">[0,1]</code>. <code>ppnu</code> is the desired
proportion of variables to shrink to zero for each component (see Dual-SPLS methodology).</p>
</td></tr>
<tr><td><code id="d.spls.ridge_+3A_nu2">nu2</code></td>
<td>
<p>a positive real value. <code>nu2</code> is a regularization parameter on <code class="reqn">X^TX</code>.</p>
</td></tr>
<tr><td><code id="d.spls.ridge_+3A_verbose">verbose</code></td>
<td>
<p>a Boolean value indicating whether or not to display the iterations steps. Default value is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The resulting solution for <code class="reqn">w</code> and hence for the coefficients vector, in the case of <code>d.spls.ridge</code>, has
a simple closed form expression (ref) deriving from the fact that <code class="reqn">w</code> is collinear to a vector <code class="reqn">z_{\nu_1}</code> of coordinates
</p>
<p style="text-align: center;"><code class="reqn">z_{\nu_1,j}=\textrm{sign}(z_{X,\nu_2,j})(|z_{X,\nu_2,j}|-\nu_1)_+.</code>
</p>

<p>Here <code class="reqn">\nu_1</code> is the threshold for which <code>ppnu</code> of
the absolute values of the coordinates of <code class="reqn">z_{X,\nu_2}</code> are greater than <code class="reqn">\nu_1</code> and <code class="reqn">z_{X,\nu_2}=(\nu_2 X^TX + I_p)^{-1}X^Ty</code>.
Therefore, the ridge norm is beneficial to the situation where <code class="reqn">X^TX</code> is singular. If <code class="reqn">X^TX</code> is invertible, one
can choose to use the Dual-SPLS for the least squares norm instead.
</p>


<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>Xmean</code></td>
<td>
<p>the mean vector of the predictors matrix <code>X</code>.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> where <code>n</code> is the number of observations. The <code>scores</code> represents
the observations in the new component basis computed by the compression step
of the Dual-SPLS.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that represents the Dual-SPLS components.</p>
</td></tr>
<tr><td><code>Bhat</code></td>
<td>
<p>the matrix of dimension <code>(p,ncp)</code> that regroups the regression coefficients for each component.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>the vector of intercept values for each component.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the predicted values of <code>y</code></p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the matrix of dimension <code>(n,ncp)</code> that represents the residuals corresponding
to the difference between the responses and the fitted values.</p>
</td></tr>
<tr><td><code>lambda1</code></td>
<td>
<p>the vector of length <code>ncp</code> collecting the parameters of sparsity used to fit the model at each iteration.</p>
</td></tr>
<tr><td><code>zerovar</code></td>
<td>
<p>the vector of length <code>ncp</code> representing the number of variables shrank to zero per component.</p>
</td></tr>
<tr><td><code>ind_diff0</code></td>
<td>
<p>the list of <code>ncp</code> elements representing the index of the none null regression coefficients elements.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>a character specifying the Dual-SPLS norm used. In this case it is <code>ridge</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.LS">d.spls.LS</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
### parameters
oldpar &lt;- par(no.readonly = TRUE)
n &lt;- 200
p &lt;- 100
nondes &lt;- 150
sigmaondes &lt;- 0.01
data=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

X &lt;- data$X
y &lt;- data$y


#fitting the model
mod.dspls &lt;- d.spls.ridge(X=X,y=y,ncp=10,ppnu=0.9,nu2=100,verbose=TRUE)

str(mod.dspls)

### plotting the observed values VS predicted values
plot(y,mod.dspls$fitted.values[,6], xlab="Observed values", ylab="Predicted values",
main="Observed VS Predicted for 6 components")
points(-1000:1000,-1000:1000,type='l')

### plotting the regression coefficients
par(mfrow=c(3,1))
i=6
nz=mod.dspls$zerovar[i]
plot(1:dim(X)[2],mod.dspls$Bhat[,i],type='l',
    main=paste(" Dual-SPLS (ridge), ncp =", i, " #0coef =", nz, "/", dim(X)[2]),
    ylab='',xlab='' )
inonz=which(mod.dspls$Bhat[,i]!=0)
points(inonz,mod.dspls$Bhat[inonz,i],col='red',pch=19,cex=0.5)
legend("topright", legend ="non null values", bty = "n", cex = 0.8, col = "red",pch=19)
par(oldpar)
</code></pre>

<hr>
<h2 id='d.spls.simulate'>Simulation of a data</h2><span id='topic+d.spls.simulate'></span>

<h3>Description</h3>

<p>The function <code>d.spls.simulate</code> simulates <code>G</code> mixtures of <code>nondes</code> Gaussians from which it builds
a data set of predictors <code>X</code> and response <code>y</code> in a way that <code>X</code> can be divided into <code>G</code> groups and
the values of <code>y</code> depend on the values of <code>X</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.simulate(n=200,p=100,nondes=50,sigmaondes=0.05,sigmay=0.5,int.coef=1:5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.simulate_+3A_n">n</code></td>
<td>
<p>a positive integer. <code>n</code> is the number of observations. Default value is <code>200</code>.</p>
</td></tr>
<tr><td><code id="d.spls.simulate_+3A_p">p</code></td>
<td>
<p>a numeric vector of length <code>G</code> representing the number of variables. Default value is <code>100</code>.</p>
</td></tr>
<tr><td><code id="d.spls.simulate_+3A_nondes">nondes</code></td>
<td>
<p>a numeric vector of length <code>G</code>. <code>nondes</code> is the number of Guassians in each mixture. Default value is <code>50</code>.</p>
</td></tr>
<tr><td><code id="d.spls.simulate_+3A_sigmaondes">sigmaondes</code></td>
<td>
<p>a numeric vector of length <code>G</code>. <code>sigmaondes</code> is the standard deviation of the
Gaussians for each group <code class="reqn">g</code>. Default value is <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="d.spls.simulate_+3A_sigmay">sigmay</code></td>
<td>
<p>a real value. <code>sigmay</code> is the uncertainty on <code>y</code>. Default value is <code>0.5</code>.</p>
</td></tr>
<tr><td><code id="d.spls.simulate_+3A_int.coef">int.coef</code></td>
<td>
<p>a numeric vector of the coefficients of the linear combination in the construction of the response
vector <code>y</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The predictors matrix <code>X</code> is a concatenations of <code>G</code> predictors sub matrices. Each is computed using
a mixture of Gaussian i.e. summing the following Gaussians:
</p>
<p style="text-align: center;"><code class="reqn">A \exp{(-\frac{(\textrm{xech}-\mu)^2}{2 \sigma^2})}.</code>
</p>

<p>Where
</p>

<ul>
<li> <p><code class="reqn">A</code> is a numeric vector of random values between 0 and 1,
</p>
</li>
<li><p> xech is an element from the sequence of <code class="reqn">p(g)</code> equally spaced values from 0 to 1. <code class="reqn">p(g)</code> is the number
of variables of the sub matrix <code class="reqn">g</code>, for <code class="reqn">g \in \{1, \dots, G\}</code>,
</p>
</li>
<li> <p><code class="reqn">\mu</code> is a random value in <code class="reqn">[0,1]</code> representing the mean of the Gaussians,
</p>
</li>
<li> <p><code class="reqn">\sigma</code> is a positive real value specified by the user and representing the standard
deviation of the Gaussians.
</p>
</li></ul>

<p>The response vector <code>y</code> is a linear combination of the predictors to which we add a noise of uncertainty <code>sigmay</code>. It is computed as follows:
</p>
<p style="text-align: center;"><code class="reqn">y_i= \sigma_y \times V_i +\sum_{g=1}^G \sum_{k=1}^K \textrm{int.coeff}_k \times \textrm{sum}X^{g}_{ik}</code>
</p>

<p>Where
</p>

<ul>
<li> <p><code class="reqn">G</code> is the number of predictor sub matrices,
</p>
</li>
<li> <p><code class="reqn">i</code> is the index of the observation,
</p>
</li>
<li> <p><code class="reqn">V</code> is a normally distributed vector of 0 mean and unitary standard deviation,
</p>
</li>
<li> <p><code class="reqn">K</code> is the length of the vector <code>int.coeff</code>,
</p>
</li>
<li> <p><code class="reqn">\textrm{sum}X^{g}</code> is a matrix of <code class="reqn">n</code> rows and <code class="reqn">K</code> columns.
The values of the column <code class="reqn">k</code> are the sum of selected parts of each row of the sub matrix <code class="reqn">X^g</code>. The columns of <code class="reqn">X^g</code> are
separated equally and each part is used for the <code class="reqn">K</code> columns of <code class="reqn">\textrm{sum}X^{g}</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>A <code>list</code> of the following attributes
</p>
<table>
<tr><td><code>X</code></td>
<td>
<p>the concatenated predictors matrix.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>the response vector.</p>
</td></tr>
<tr><td><code>y0</code></td>
<td>
<p>the response vector without noise <code>sigmay</code>.</p>
</td></tr>
<tr><td><code>sigmay</code></td>
<td>
<p>the uncertainty on <code>y</code>.</p>
</td></tr>
<tr><td><code>sigmaondes</code></td>
<td>
<p>the standard deviation of the Gaussians.</p>
</td></tr>
<tr><td><code>G</code></td>
<td>
<p>the number of groups.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### load dual.spls library
library(dual.spls)
####one predictors matrix
### parameters
n &lt;- 100
p &lt;- 50
nondes &lt;- 20
sigmaondes &lt;- 0.5
data1=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

Xa &lt;- data1$X
ya &lt;- data1$y

###plotting the data
plot(Xa[1,],type='l',ylim=c(0,max(Xa)),main='Data', ylab='Xa',col=1)
for (i in 2:n){ lines(Xa[i,],col=i) }

####two predictors matrix
### parameters
n &lt;- 100
p &lt;- c(50,100)
nondes &lt;- c(20,30)
sigmaondes &lt;- c(0.05,0.02)
data2=d.spls.simulate(n=n,p=p,nondes=nondes,sigmaondes=sigmaondes)

Xb &lt;- data2$X
X1 &lt;- Xb[,(1:p[1])]
X2 &lt;- Xb[,(p[1]+1):(p[1]+p[2])]
yb &lt;- data2$y

###plotting the data
plot(Xb[1,],type='l',ylim=c(0,max(Xb)),main='Data', ylab='Xb',col=1)
for (i in 2:n){ lines(Xb[i,],col=i) }

###plotting the data
plot(X1[1,],type='l',ylim=c(0,max(X1)),main='Data X1', ylab='X1',col=1)
for (i in 2:n){ lines(X1[i,],col=i) }

###plotting the data
plot(X2[1,],type='l',ylim=c(0,max(X2)),main='Data X2', ylab='X2',col=1)
for (i in 2:n){ lines(X2[i,],col=i) }
</code></pre>

<hr>
<h2 id='d.spls.split'>Splits data into calibration and validation sets according to wich group belongs each observation</h2><span id='topic+d.spls.split'></span>

<h3>Description</h3>

<p>The function <code>d.spls.split</code> divides the data <code>X</code> into a calibration and a validation set using
the Kennard and Stone strategy for each group at a time and according to the number of calibration desired
from each group.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.split(X, Xtype, Listecal = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.split_+3A_x">X</code></td>
<td>
<p>a numeric matrix.</p>
</td></tr>
<tr><td><code id="d.spls.split_+3A_xtype">Xtype</code></td>
<td>
<p>a vector of index specifying to which group belongs each observation.</p>
</td></tr>
<tr><td><code id="d.spls.split_+3A_listecal">Listecal</code></td>
<td>
<p>a vector specifying how many observations from each group should be selected as calibration.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector giving the row indices of the input data selected for calibration
</p>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.type">d.spls.type</a>,<a href="#topic+d.spls.calval">d.spls.calval</a>
</p>

<hr>
<h2 id='d.spls.type'>Splitting the observations into groups</h2><span id='topic+d.spls.type'></span>

<h3>Description</h3>

<p>The internal function <code>type</code> divides the response vector <code>y</code> in <code>cells</code>
of equal range and attributes a index type to the observations according to the corresponding cell
</p>


<h3>Usage</h3>

<pre><code class='language-R'>d.spls.type(y, ncells)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="d.spls.type_+3A_y">y</code></td>
<td>
<p>a numeric vector.</p>
</td></tr>
<tr><td><code id="d.spls.type_+3A_ncells">ncells</code></td>
<td>
<p>a positive integer. <code>ncells</code> is the number of subsamples desired.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of index specifying each observation belonging to which group index.
</p>


<h3>Author(s)</h3>

<p>Louna Alsouki François Wahl
</p>


<h3>See Also</h3>

<p><a href="#topic+d.spls.split">d.spls.split</a>, <a href="#topic+d.spls.calval">d.spls.calval</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
