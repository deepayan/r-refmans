<!DOCTYPE html><html><head><title>Help for package Petersen</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Petersen}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cap_hist_to_n_m_u'><p>Convert capture history data to n, m and u for use in BTSPAS</p></a></li>
<li><a href='#data_btspas_diag1'><p>Estimating abundance of outgoing smolt - BTSPAS - diagonal case</p></a></li>
<li><a href='#data_btspas_nondiag1'><p>Estimating abundance of salmon - BTSPAS - non-diagonal case</p></a></li>
<li><a href='#data_kokanee_tagloss'><p>Capture-recapture on Kokanee in Metolius River with tag loss</p></a></li>
<li><a href='#data_NorthernPike'><p>Capture-recapture experiment on Northern Pike in Mille Lacs, MN, in 2005.</p></a></li>
<li><a href='#data_NorthernPike_tagloss'><p>Capture-recapture experiment on Northern Pike in Mille Lacs, MN, in 2005 with tagloss information.</p></a></li>
<li><a href='#data_rodli'><p>Capture-recapture experiment at Rodli Tarn.</p></a></li>
<li><a href='#data_sim_reward'><p>Simulated data for reward tags used to estimate reporting rate</p></a></li>
<li><a href='#data_sim_tagloss_t2perm'><p>Simulated data for tag loss with second permanent tag.</p></a></li>
<li><a href='#data_sim_tagloss_twoD'><p>Simulated data for tag loss with 2 distinguishable tags.</p></a></li>
<li><a href='#data_spas_harrison'><p>Estimating abundance of salmon - SPAS - Harrison River</p></a></li>
<li><a href='#data_wae_is_long'><p>Walleye data with incomplete stratification with length covariate</p></a></li>
<li><a href='#data_wae_is_short'><p>Walleye data with incomplete stratification with no covariates and condensed</p></a></li>
<li><a href='#data_yukon_reverse'><p>Yukon River data used for Reverse Capture-Recapture example.</p></a></li>
<li><a href='#fit_classes'><p><strong>LP_fit</strong>, <strong>LP_IS_fit</strong>, <strong>LP_SPAS_cit</strong>, <strong>CL_fit</strong>, <strong>LP_BTSPAS_fit_Diag</strong>, <strong>LP_BTSPAS_fit_NonDiag</strong>, <strong>LP_CL_fit</strong> classes.</p></a></li>
<li><a href='#logit'><p>Logit and anti-logit function.</p></a></li>
<li><a href='#LP_AICc'><p>Create an AIC table comparing multiple LP fits</p></a></li>
<li><a href='#LP_BTSPAS_est'><p>Extract estimates of abundance after BTSPAS fit</p></a></li>
<li><a href='#LP_BTSPAS_fit_Diag'><p>Wrapper (*_fit) to call the Time Stratified Petersen Estimator</p>
with Diagonal Entries function in BTSPAS.</a></li>
<li><a href='#LP_BTSPAS_fit_NonDiag'><p>Wrapper (*_fit) to call the Time Stratified Petersen Estimator</p>
with NON-Diagonal Entries function in BTSPAS.</a></li>
<li><a href='#LP_CL_fit'><p>Fit the Chen-Lloyd model to estimate abundance using a non-parametric smoother for a covariates</p></a></li>
<li><a href='#LP_est'><p>Estimate abundance after the LP conditional likelihood fit.</p></a></li>
<li><a href='#LP_est_adjust'><p>Estimate abundance after empirical adjustments for various factors.</p></a></li>
<li><a href='#LP_fit'><p>Fit a Lincoln-Petersen Model using conditional likelihood</p></a></li>
<li><a href='#LP_IS_est'><p>Estimate abundance after the LP_IS conditional likelihood fit.</p></a></li>
<li><a href='#LP_IS_fit'><p>Fit a Lincoln-Petersen Model with incomplete stratification</p></a></li>
<li><a href='#LP_IS_print'><p>Print the results from a fit a Lincoln-Petersen Model with incomplete stratification</p></a></li>
<li><a href='#LP_modavg'><p>Create an table of individual estimates and the model averaged values</p></a></li>
<li><a href='#LP_SPAS_est'><p>Extract estimates of abundance after SPAS fit</p></a></li>
<li><a href='#LP_SPAS_fit'><p>Fit a Stratified-Petersen SPAS model.</p></a></li>
<li><a href='#LP_summary_stats'><p>Compute summary statistics from the capture histories</p></a></li>
<li><a href='#LP_test_equal_mf'><p>Test for equal marked fractions in LP experiment</p></a></li>
<li><a href='#LP_test_equal_recap'><p>Test for equal recapture probability in LP experiment</p></a></li>
<li><a href='#LP_TL_est'><p>Estimate abundance after the LP_TL (tag loss) conditional likelihood fit.</p></a></li>
<li><a href='#LP_TL_fit'><p>Fit a Lincoln-Petersen Model with Tag Loss using conditional likelihood</p></a></li>
<li><a href='#LP_TL_simulate'><p>Simulate data from a Lincoln-Petersen Model with Tag Loss</p></a></li>
<li><a href='#split_cap_hist'><p>Split a vector of capture histories into a matrix with one column for each occasion</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Estimators for Two-Sample Capture-Recapture Studies</td>
</tr>
<tr>
<td>Version:</td>
<td>2023.12.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-12-01</td>
</tr>
<tr>
<td>Description:</td>
<td>A comprehensive implementation of Petersen-type estimators
    and its many variants for two-sample capture-recapture studies.
    A conditional likelihood approach is used that allows
    for tag loss; non reporting of tags; reward tags; categorical, geographical and temporal stratification;
    partial stratification; reverse capture-recapture;
    and continuous variables in modeling the probability of capture.
    Many examples from fisheries management are presented.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>AICcmodavg, bbmle, BTSPAS, formula.tools, ggplot2, MASS,
Matrix, msm, numDeriv, plyr, reshape2, rlang, SPAS, stats,
stringr, tidyr, utils</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, R.rsp</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown, R.rsp</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/cschwarz-stat-sfu-ca/Petersen">https://github.com/cschwarz-stat-sfu-ca/Petersen</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/cschwarz-stat-sfu-ca/Petersen/issues">https://github.com/cschwarz-stat-sfu-ca/Petersen/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-11 20:32:28 UTC; cschwarz</td>
</tr>
<tr>
<td>Author:</td>
<td>Carl Schwarz [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Carl Schwarz &lt;cschwarz.stat.sfu.ca@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-12 12:03:24 UTC</td>
</tr>
</table>
<hr>
<h2 id='cap_hist_to_n_m_u'>Convert capture history data to n, m and u for use in BTSPAS</h2><span id='topic+cap_hist_to_n_m_u'></span>

<h3>Description</h3>

<p>Convert capture history data to n, m and u for use in BTSPAS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cap_hist_to_n_m_u(data, sep = "..")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cap_hist_to_n_m_u_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
<tr><td><code id="cap_hist_to_n_m_u_+3A_sep">sep</code></td>
<td>
<p>Separator used between strata in cap_hit</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The frequency variable (<code>freq</code> in the <code>data</code> argument) is the number of animals with the corresponding capture history.
</p>
<p>Capture histories (<code>cap_hist</code> in the <code>data</code> argument) are character values of the format
<code>xx..yy</code> is a capture_history where <code>xx</code> and <code>yy</code> are the temporal stratum
(e.g., julian week) and <code>'..'</code> separates
the two temporal strata.
If a fish is released in temporal stratum and never captured again, then <code>yy</code> is set to 0;
if a fish is newly captured in temporal stratum <code>yy</code>, then <code>xx</code> is set to zero.
For example, a capture history of <code>23..23</code> indicates animals released in temporal stratum
23 and recaptured in temporal stratum 23; a capture history of <code>23..00</code>
indicates animals released in temporal stratum
23 and never seen again; a capture history of <code>00..23</code>
indicates animals newly captured in temporal stratum
23 at the second sampling event.
</p>
<p>. In the diagonal case, fish are only recovered in the same temporal stratum.
In the non-diagonal case, fish are allowed to move among temporal strata.
</p>
<p>It is not necessary to label the temporal strata starting at 1; BTSPAS will treat the smallest
value of the temporal strata seen as the first stratum and will interpolate for temporal strata
without any data. Temporal strata labels should be numeric, i.e., do NOT use A, B, C etc.
</p>


<h3>Value</h3>

<p>A list with entries for the stratum index, n (number released), m matrix
of recoveries in the current, next, etc stratum, and u (number of unmarked fish)
captured in this recovery stratum.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_btspas_diag1)
cap_hist_to_n_m_u(data_btspas_diag1)

data(data_btspas_nondiag1)
cap_hist_to_n_m_u(data_btspas_nondiag1)


</code></pre>

<hr>
<h2 id='data_btspas_diag1'>Estimating abundance of outgoing smolt - BTSPAS - diagonal case</h2><span id='topic+data_btspas_diag1'></span>

<h3>Description</h3>

<p>This is the first diagonal case dataset from BTSPAS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_btspas_diag1)
</code></pre>


<h3>Format</h3>



<h4><code>data_btspas_diag1</code></h4>

<p>A data frame with many rows and 3 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history of the form &lsquo;jweek..jweek&rsquo; for fish that are recaptured
in the same julian week; '0..jweek' for unmarked fish newly captured in that julian week ; 'jweek..0' for fish
released in the julian week but never recaptured.</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history.</p>
</dd>
<dt><code>logflow</code></dt><dd><p>log(flow) for this julian week</p>
</dd>
</dl>




<h3>Details</h3>

<p>Consider an experiment to estimate the number of outgoing smolts on a small river. The
run of smolts extends over several weeks. As smolts migrate, they are captured and marked
with individually numbered tags and released at the first capture location using, for example, a
fishwheel. The migration continues, and a second fishwheel takes a second sample several
kilometers down stream. At the second fishwheel, the captures consist of a mixture of marked
(from the first fishwheel) and unmarked fish.
</p>
<p>The efficiency of the fishwheels varies over time in response to stream flow, run size passing
the wheel and other uncontrollable events. So it is unlikely that the capture probabilities are
equal over time at either location, i.e. are heterogeneous over time.
</p>
<p>We suppose that we can temporally stratify the data into, for example, weeks, where the
capture-probabilities are (mostly) homogeneous at each wheel in each week. Furthermore, suppose that
fish captured and marked in each week tend to migrate together so that they are
captured in a single subsequent stratum. For example,
suppose that in each julian week <code class="reqn">j</code>, <code class="reqn">n1_j</code> fish are marked and released above the rotary screw trap.
Of these, <code class="reqn">m2_j</code> are recaptured. All recaptures take place in the week of release,
i.e. the matrix of releases and recoveries is diagonal.
The <code class="reqn">n1_j</code> and <code class="reqn">m2_j</code> establish the capture efficiency of the second trap in julian week <code class="reqn">j</code>.
</p>
<p>At the same time, <code class="reqn">u2_j</code> unmarked fish are captured at the screw trap.
</p>
<p>Capture-efficiency may be related to flow, so the log(flow) is also recorded.
</p>

<hr>
<h2 id='data_btspas_nondiag1'>Estimating abundance of salmon - BTSPAS - non-diagonal case</h2><span id='topic+data_btspas_nondiag1'></span>

<h3>Description</h3>

<p>This is the first non-diagonal case dataset from BTSPAS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_btspas_nondiag1)
</code></pre>


<h3>Format</h3>



<h4><code>data_btspas_nondiag1</code></h4>

<p>A data frame with many rows and 3 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history of the form &lsquo;week1..week2&rsquo; for fish that are released on
week 1 and recaptured
on week 2 ; '0..week22' for unmarked fish newly captured in week 2; 'week1..0' for fish
released in week 1 but never recaptured.</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history.</p>
</dd>
</dl>




<h3>Details</h3>

<p>Incoming sockeye salmon are captured on a first wheel, tagged with color tags
that vary by week, and recaptured on an upriver weir.
The upriver weir was not in operation for the first few weeks.
</p>

<hr>
<h2 id='data_kokanee_tagloss'>Capture-recapture on Kokanee in Metolius River with tag loss</h2><span id='topic+data_kokanee_tagloss'></span>

<h3>Description</h3>

<p>This is the data from  Hyun et al (2012).
In August and September 2007, the period just before the spawning run,
adult kokanee were collected by beach seining in the upper arm of the
lake near the confluence with the Metolius River.
Fish were tagged with nonpermanent, plastic T-bar anchor tags
and then were released back into the lake.
Randomly selected fish received single tags of one color,
while the other fish received two tags of a second color (i.e., the double tags were identical in color).
In late September through October, spawning ground surveys were conducted by 2–3 people walking
abreast in a downstream direction (or floating, in sections where the water depth and flow were too great to allow walking).
Instead of being physically recaptured, the fish were resighted as they swam freely in the clear,
relatively shallow water within the spawning areas of the river.
The total number of fish observed with or without a tag (or tags) was recorded for each section,
and information on the number and color of tags for each marked fish was also noted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_kokanee_tagloss)
</code></pre>


<h3>Format</h3>



<h4><code>data_kokanee_tagloss</code></h4>

<p>A data frame with many rows and 2 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history (1000, 1010, 1100, 1110, 1111).</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history. Always 1</p>
</dd>
</dl>




<h3>Details</h3>

<p>Because fish were not handled, it is not possible to know which of the double tags were lost, and so only
models with equal retention probabilities and non-distinguishable double tags should be fit. Note
that the capture history for a lost of 1 indistinguishable tag is 111X rather than 1110 or 1101 (both of
which are not allowed in the model with indistinguishable double tags)
</p>

<hr>
<h2 id='data_NorthernPike'>Capture-recapture experiment on Northern Pike in Mille Lacs, MN, in 2005.</h2><span id='topic+data_NorthernPike'></span>

<h3>Description</h3>

<p>Fish were tagged on the spawning grounds and recovered in the summer gillnet assessment.
Fish were double tagged, and a tag loss analysis
showed that tag loss was negligible. It will be ignored here.
Length was measured a both times and didn't not change
very much between the two sampling occasions. The value
recorded below is the average of the two lengths if both
lengths were present.
Fish that were not sexed or measured for length are ignored and not included
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_NorthernPike)
</code></pre>


<h3>Format</h3>



<h4><code>data_NorthernPike</code></h4>

<p>A data frame with many rows and 4 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history (10, 01, or 11). Note that
<code class="reqn">n_{10}=n_1-m_2</code>; <code class="reqn">n_{01}=n_2-m_2</code>; and <code class="reqn">n_{11}=m2</code></p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history. Always 1</p>
</dd>
<dt><code>Sex</code>.</dt><dd><p>Sex of the fish. M=Male; F=Female</p>
</dd>
<dt><code>Length</code></dt><dd><p>Length of the fish in inches.</p>
</dd>
</dl>



<hr>
<h2 id='data_NorthernPike_tagloss'>Capture-recapture experiment on Northern Pike in Mille Lacs, MN, in 2005 with tagloss information.</h2><span id='topic+data_NorthernPike_tagloss'></span>

<h3>Description</h3>

<p>Fish were tagged on the spawning grounds and recovered in the summer gillnet assessment.
Fish were double tagged and the double tagging information is included here.
Length was measured a both times and didn't not change
very much between the two sampling occasions. The value
recorded below is the average of the two lengths if both
lengths were present.
Fish that were not sexed or measured for length are ignored and not included
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_NorthernPike_tagloss)
</code></pre>


<h3>Format</h3>



<h4><code>data_NorthernPike_tagloss</code></h4>

<p>A data frame with many rows and 4 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history (10, 01, or 11). Note that
<code class="reqn">n_{10}=n_1-m_2</code>; <code class="reqn">n_{01}=n_2-m_2</code>; and <code class="reqn">n_{11}=m2</code></p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history. Always 1</p>
</dd>
<dt><code>Sex</code>.</dt><dd><p>Sex of the fish. M=Male; F=Female</p>
</dd>
<dt><code>Length</code></dt><dd><p>Length of the fish in inches.</p>
</dd>
</dl>



<hr>
<h2 id='data_rodli'>Capture-recapture experiment at Rodli Tarn.</h2><span id='topic+data_rodli'></span>

<h3>Description</h3>

<p>Ricker (1975) gives an example of work by Knut Dahl on estimating the number of brown trout
(<em>Salmo truitta</em>) in some small Norwegian tarns. Between 100 and 200 trout were caught by
seining, marked by removing a fin (an example of a batch mark) and distributed
in a systematic fashion around the tarn to encourage mixing.
A total of <code class="reqn">n_1</code>=109 fish were
captured, clipped and released,
<code class="reqn">n_2</code>=177 fish were captured at the second occasion, and <code class="reqn">m_2</code>=57
marked fish were recovered.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_rodli)
</code></pre>


<h3>Format</h3>



<h4><code>data_rodli</code></h4>

<p>A data frame with 3 rows and 2 columns:
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history (10, 01, or 11). Note that
<code class="reqn">n_{10}=n_1-m_2</code>; <code class="reqn">n_{01}=n_2-m_2</code>; and <code class="reqn">n_{11}=m_2</code></p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history</p>
</dd>
</dl>



<hr>
<h2 id='data_sim_reward'>Simulated data for reward tags used to estimate reporting rate</h2><span id='topic+data_sim_reward'></span>

<h3>Description</h3>

<p>This is simulated data with the parameter values given in details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_sim_reward)
</code></pre>


<h3>Format</h3>



<h4><code>data_sim_reward</code></h4>

<p>A data frame with many rows and 2 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history (1000, 1010, 0P00, 0P0P, 0010).</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history.</p>
</dd>
</dl>




<h3>Details</h3>

<pre>
 data_sim_reward &lt;-LP_TL_simulate(
      dt_type=dt_type,  #  permanent tag
      N=10000,
      cov1=function(N)         {rep(1,N)},
      cov2=function(cov1)      {rep(1,  length(cov1))},
      p1  =function(cov1, cov2){rep(.1, length(cov1))},
      pST =function(cov1, cov2){rep(.75,length(cov1))},
      rho1=function(cov1, cov2){rep(.70,length(cov1))},
      rho2=function(cov1, cov2){rep(1,  length(cov1))},  # permanent second tag
      p2  =function(cov1, cov2){rep(.1, length(cov1))},
      seed=45985, trace=FALSE)
# we don't have fish with both tags
data_sim_reward$cap_hist &lt;- gsub("1P", "0P", data_sim_reward$cap_hist)
</pre>

<hr>
<h2 id='data_sim_tagloss_t2perm'>Simulated data for tag loss with second permanent tag.</h2><span id='topic+data_sim_tagloss_t2perm'></span>

<h3>Description</h3>

<p>This is simulated data with the parameter values given in details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_sim_tagloss_t2perm)
</code></pre>


<h3>Format</h3>



<h4><code>data_sim_tagloss_t2perm</code></h4>

<p>A data frame with many rows and 2 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history (1000, 1010, 1P00, 1P0P, 1P1P, 0010).</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history.</p>
</dd>
</dl>




<h3>Details</h3>

<pre>data_sim_tagloss_t2perm &lt;-LPTL_simulate(
      dt_type="t2perm",         # second permanent
      N=10000,
      cov1=function(N)         {rep(1,N)},
      cov2=function(cov1)      {rep(1,  length(cov1))},
      p1  =function(cov1, cov2){rep(.1, length(cov1))},
      pST =function(cov1, cov2){rep(.25,length(cov1))},
      rho1=function(cov1, cov2){rep(.70,length(cov1))},
      rho2=function(cov1, cov2){rep(1,  length(cov1))}, # permanent tag
      p2  =function(cov1, cov2){rep(.1, length(cov1))},
      seed=234523, trace=FALSE)</pre>

<hr>
<h2 id='data_sim_tagloss_twoD'>Simulated data for tag loss with 2 distinguishable tags.</h2><span id='topic+data_sim_tagloss_twoD'></span>

<h3>Description</h3>

<p>This is simulated data with the parameter values given in the description.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_sim_tagloss_twoD)
</code></pre>


<h3>Format</h3>



<h4><code>data_sim_tagloss_twoD</code></h4>

<p>A data frame with many rows and 2 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history (1000, 1010, 1100, 1110, 1101, 1111).</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history.</p>
</dd>
</dl>




<h3>Details</h3>

<pre>data_sim_tagloss_twoD &lt;-LPTL_simulate(
      dt_type="twoD",         # two distinguishable tags
      N=10000,
      cov1=function(N)         {rep(1,N)},
      cov2=function(cov1)      {rep(1,  length(cov1))},
      p1  =function(cov1, cov2){rep(.1, length(cov1))},
      pST =function(cov1, cov2){rep(.25,length(cov1))},
      rho1=function(cov1, cov2){rep(.70,length(cov1))},
      rho2=function(cov1, cov2){rep(.80,length(cov1))},
      p2  =function(cov1, cov2){rep(.1, length(cov1))},
      seed=234523, trace=FALSE)</pre>

<hr>
<h2 id='data_spas_harrison'>Estimating abundance of salmon - SPAS - Harrison River</h2><span id='topic+data_spas_harrison'></span>

<h3>Description</h3>

<p>Incoming sockeye salmon are captured on a first wheel, tagged with color tags
that vary by week, and recaptured on several spawning areas.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_spas_harrison)
</code></pre>


<h3>Format</h3>



<h4><code style="white-space: pre;">&#8288;data_spas harrison&#8288;</code></h4>

<p>A data frame with many rows and 2 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history of the form &lsquo;week..area&rsquo; for fish that are released on
week and recaptured
area ; '0..area' for unmarked fish newly captured in area; 'week..0' for fish
released in week  but never recaptured.</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history.</p>
</dd>
</dl>



<hr>
<h2 id='data_wae_is_long'>Walleye data with incomplete stratification with length covariate</h2><span id='topic+data_wae_is_long'></span>

<h3>Description</h3>

<p>Data used in
Premarathna, W.A.L., Schwarz, C.J., Jones, T.S. (2018)
Partial stratification in two-sample capture–recapture experiments.
Environmetrics, 29:e2498. https://doi.org/10.1002/env.2498
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_wae_is_long)
</code></pre>


<h3>Format</h3>

<p><code>data_wae_is_long</code>
A data frame with many rows and 3 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history with possible histories as noted below</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history.</p>
</dd>
<dt><code>length</code></dt><dd><p>Length of fish (inches)</p>
</dd>
</dl>



<h3>Details</h3>

<p>Fish were tagged on the spawning grounds and
recovered in the summer gillnet assessment.
</p>
<p>Length was measured a both times and didn't not change
very much between the two sampling occasions. The value
recorded below is the average of the two lengths if both
lengths were present.
</p>
<p>Rather than sexing all of the fish, only a sub-sample of unmarked fish
is sexed at each sampling occasion. Possible capture histories are then
M0, F0, MM, FF, U0, UU, 0M, 0F
</p>

<hr>
<h2 id='data_wae_is_short'>Walleye data with incomplete stratification with no covariates and condensed</h2><span id='topic+data_wae_is_short'></span>

<h3>Description</h3>

<p>Data used in
Premarathna, W.A.L., Schwarz, C.J., Jones, T.S. (2018)
Partial stratification in two-sample capture–recapture experiments.
Environmetrics, 29:e2498. https://doi.org/10.1002/env.2498
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_wae_is_short)
</code></pre>


<h3>Format</h3>

<p><code>data_wae_is_short</code>
A data frame with many rows and 2 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history with possible histories as noted below</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Data is slightly different from that in paper above because some fish did not
have length measured and so were drop from data_wae_is_long and this is the
condensed version of data_wae_is_long.
</p>
<p>Fish were tagged on the spawning grounds and
recovered in the summer gillnet assessment.
</p>
<p>Rather than sexing all of the fish, only a sub-sample of unmarked fish
is sexed at each sampling occasion. Possible capture histories are then
M0, F0, MM, FF, U0, UU, 0M, 0F
</p>

<hr>
<h2 id='data_yukon_reverse'>Yukon River data used for Reverse Capture-Recapture example.</h2><span id='topic+data_yukon_reverse'></span>

<h3>Description</h3>

<p>Data from
Hamazaki, T. and DeCovich, N. (2014).
Application of the Genetic Mark–Recapture Technique for Run Size Estimation of Yukon River Chinook Salmon.
North American Journal of Fisheries Management, 34, 276-286.
DOI: 10.1080/02755947.2013.869283
This is the data from the 2011 data in Table 2 of the above paper.
Estimated that total escapement to Canada (plus  harvest)
was 66,225 (SE 1574)
Estimated that proportion of stock that was Canadian was .34644 (SE .030)
We converted this into a &quot;sample size&quot; and number of fish with Cdn genetics
that gave the same SE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(data_yukon_reverse)
</code></pre>


<h3>Format</h3>

<p><code>data_yukon_reverse</code>
A data frame with many rows and 4 columns
</p>

<dl>
<dt><code>cap_hist</code>.</dt><dd><p>Capture history with possible histories as noted below</p>
</dd>
<dt><code>freq</code>.</dt><dd><p>Number of fish with this history.</p>
</dd>
<dt><code>SE</code>.</dt><dd><p>SE of the number of fish with this history</p>
</dd>
</dl>


<hr>
<h2 id='fit_classes'><strong>LP_fit</strong>, <strong>LP_IS_fit</strong>, <strong>LP_SPAS_cit</strong>, <strong>CL_fit</strong>, <strong>LP_BTSPAS_fit_Diag</strong>, <strong>LP_BTSPAS_fit_NonDiag</strong>, <strong>LP_CL_fit</strong> classes.</h2><span id='topic+fit_classes'></span>

<h3>Description</h3>

<p>We assign a &quot;class&quot; (one of the classes above) to the results from one of the fitting methods. This class
designation is <strong>only used to ensure that estimation routines have the correct type of fit when finding estimates of abundace</strong>,
and <strong>model averaging only considers models of comparable class</strong> when creating the
model averaging results of abundance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_classes()
</code></pre>


<h3>Details</h3>

<p>The structure of an object of the above classes is roughly comparable across classes. The object should be a
list with the following objects
</p>

<ul>
<li> <p><strong>summary</strong> A data frame with the model for the parameters of the model;
the conditional log-likelihood; the number of parameters; the number of parameters, and method used to fit the model
</p>
</li>
<li> <p><strong>data</strong> A data frame with the raw data used in the fit
</p>
</li>
<li> <p><strong>fit</strong> Results of the fit including the estimates, SE, vcov, etc.
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the fit was done
</p>
</li></ul>

<p>Other objects may also be included in the list.
</p>
<p>After a fit performed, estimates of <strong>ABUNDANCE</strong> are extracted using the <strong>xxx_est()</strong> function corresponding to the <strong>xxx_fit()</strong> function
used to estimate parameters. This separation occurs because
</p>

<ul>
<li><p> abundance is a derived estimate; the fits are based on conditional likelihood (on
the observed data) and the abundance parameter does not appear in the conditional likelihood. Abundance is usually
estimated using a variation of a Horvitz-Thompson estimator.
</p>
</li>
<li><p> you can obtain estimates of overall abundance, subsets of the population (e.g., sex or other strata) from the same fit, and
so you don't need to do several fits to get several estimates of abundance.
</p>
</li></ul>



<h3>Value</h3>

<p>NOTHING. This is not a function, but ony documents how I use &quot;classes&quot;.
</p>

<hr>
<h2 id='logit'>Logit and anti-logit function.</h2><span id='topic+logit'></span><span id='topic+expit'></span>

<h3>Description</h3>

<p>Compute the logit or anti-logit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>logit(p)

expit(theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logit_+3A_p">p</code></td>
<td>
<p>probability between 0 and 1.</p>
</td></tr>
<tr><td><code id="logit_+3A_theta">theta</code></td>
<td>
<p>logit between -infinity and +infinity</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Computed logit or anti-logit
</p>


<h3>Author(s)</h3>

<p>C.J.Schwarz <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##---- compute the logit and its inverse
logitp &lt;- logit(.3)
p &lt;- expit(-.84)

</code></pre>

<hr>
<h2 id='LP_AICc'>Create an AIC table comparing multiple LP fits</h2><span id='topic+LP_AICc'></span>

<h3>Description</h3>

<p>This will take a series of LP fits and computes the usual AICc table and model weights
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_AICc(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_AICc_+3A_...">...</code></td>
<td>
<p>Series of LP fits</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An data frame with an AICc table and model weights etc
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_rodli)
mt &lt;- Petersen::LP_fit(data=data_rodli, p_model=~..time)
m0 &lt;- Petersen::LP_fit(data=data_rodli, p_model=~1)
Petersen::LP_AICc(m0,mt)

</code></pre>

<hr>
<h2 id='LP_BTSPAS_est'>Extract estimates of abundance after BTSPAS fit</h2><span id='topic+LP_BTSPAS_est'></span>

<h3>Description</h3>

<p>This will take a previous fit and return estimates of abundance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_BTSPAS_est(LP_BTSPAS_fit, parm = "Ntot", conf_level = 0.95, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_BTSPAS_est_+3A_lp_btspas_fit">LP_BTSPAS_fit</code></td>
<td>
<p>A result of an call to fitting at BTSPAS object.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_est_+3A_parm">parm</code></td>
<td>
<p>Which parameter from the BTSPAS fix is to be extracted?</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_est_+3A_conf_level">conf_level</code></td>
<td>
<p>The expected coverage for confidence intervals on N.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_est_+3A_trace">trace</code></td>
<td>
<p>If trace flag is set in call when estimating functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An list object of class <em>LP_BTSPAS_est</em> with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> A data frame  with the estimates of abundance, SE, and CI
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the fit was done
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Schwarz, C. J. <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# NOTE. To keep execution time to a small value as required by CRAN
# I've made a very small example.
# Additionally, I've set the number of MCMC chains, iterations, burning, simulation to save to
# small values. Proper mixing may not have occurred yet.
# When using this routine, you likely want to the use the default values
# for these MCMC parameters.

data(data_btspas_diag1)
# extract the strata of interest
temp&lt;- cbind(data_btspas_diag1,
             split_cap_hist( data_btspas_diag1$cap_hist,
                             sep="..", make.numeric=TRUE))
# only use data up to week 10 to keep example small
temp &lt;- temp[ temp$t1 %in% 0:10 &amp; temp$t2 %in% 0:10,]

fit &lt;- Petersen::LP_BTSPAS_fit_Diag(
  temp,
  p_model=~1,
  InitialSeed=23943242,
  # the number of chains and iterations are too small to be useful
  # they are set to a small number to pare execution time to &lt;5 seconds for an example
  n.chains=2, n.iter=20000, n.burnin=1000, n.sims=100,
  quietly=TRUE
)
fit$summary

# now get the estimates of abundance
est &lt;-  Petersen::LP_BTSPAS_est (fit)
est$summary



</code></pre>

<hr>
<h2 id='LP_BTSPAS_fit_Diag'>Wrapper (*_fit) to call the Time Stratified Petersen Estimator
with Diagonal Entries function in BTSPAS.</h2><span id='topic+LP_BTSPAS_fit_Diag'></span>

<h3>Description</h3>

<p>Takes the data structure as described below, and uses Bayesian methods to fit a fit a spline
through the population numbers and a hierarchical model for the trap
efficiencies over time.  An MCMC object
is also created with samples from the posterior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_BTSPAS_fit_Diag(
  data,
  p_model = ~1,
  p_model_cov = NULL,
  jump.after = NULL,
  logitP.fixed = NULL,
  logitP.fixed.values = NULL,
  InitialSeed = ceiling(stats::runif(1, min = 0, max = 1e+06)),
  n.chains = 3,
  n.iter = 2e+05,
  n.burnin = 1e+05,
  n.sims = 2000,
  trace = FALSE,
  remove_MCMC_files = TRUE,
  quietly = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_p_model">p_model</code></td>
<td>
<p>Model for the captured probabilities. This can reference
other variables in the data frame, plus a special reserved term <code>..time</code> to indicate
a time dependence in the capture probabilities. For example, <code>p_model=~1</code> would indicate
that the capture probabilities are equal across the sampling events;
<code>p_model=~..time</code> would indicate that the capture probabilities vary by sampling events;
<code>p_model=~sex*..time</code> would indicate that the capture probabilities vary across
all combination of sampling events (<code>..time</code>) and a stratification variable (<code>sex</code>). The <code>sex</code> variable
also needs to be in the data frame.
</p>
<p>For some models (e.g., tag loss models), the <code>..time</code> variable cannot be used because
the models only have one capture probability (e.g., only for event 1).</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_p_model_cov">p_model_cov</code></td>
<td>
<p>Data frame with covariates for the model for prob capture at second sampling event. If this
data frame is given, it requires one line for each of the temporal strata at the second sampling event (even
if missing in the <code>data</code> that has the capture histories) with one variable being <code>..time</code>
to represent
the second temporal stratum.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_jump.after">jump.after</code></td>
<td>
<p>A numeric vector with elements belonging to <code>time</code>.
In some cases, the spline fitting the population numbers should be allowed
to jump.  For example, the population size could take a jump when hatchery
released fish suddenly arrive at the trap.  The jumps occur AFTER the strata
listed in this argument.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_logitp.fixed">logitP.fixed</code></td>
<td>
<p>A numeric vector (could be null) of the time strata
where the logit(P) would be fixed. Typically, this is used when the capture
rates for some strata are 0 and logit(P) is set to -10 for these strata. The
fixed values are given in <code>logitP.fixed.values</code></p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_logitp.fixed.values">logitP.fixed.values</code></td>
<td>
<p>A numerical vector (could be null) of the fixed
values for logit(P) at strata given by logitP.fixed. Typically this is used
when certain strata have a 0 capture rate and the fixed value is set to -10
which on the logit scale gives $p_i$ essentially 0. Don't specify values such
as -50 because numerical problems could occur when this is converted to the 0-1 scale.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_initialseed">InitialSeed</code></td>
<td>
<p>Numeric value used to initialize the random numbers used
in the MCMC iterations.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_n.chains">n.chains</code></td>
<td>
<p>Number of chains to fit in the MCMC</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_n.iter">n.iter</code></td>
<td>
<p>Total number of iterations</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_n.burnin">n.burnin</code></td>
<td>
<p>Number of burnin iterations</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_n.sims">n.sims</code></td>
<td>
<p>Total number of simulations to keep in output (implies a thinning)</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_trace">trace</code></td>
<td>
<p>Internal tracing flag.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_remove_mcmc_files">remove_MCMC_files</code></td>
<td>
<p>Should the temporary MCMC files (init.txt, data.text, model.txt, CODA*txt) removed after the fit.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_Diag_+3A_quietly">quietly</code></td>
<td>
<p>Suppress all console messages that occur during the fit. This includes the progress bar
when a model that requires MCMC is fit (<em>LP_BTSPAS_fit_Diag</em> and <em>LP_BTSPAS_fit_NonDiag</em>), or
a trace of the likelihood during the fit (<em>LP_SPAS_fit</em>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use the <code>Petersen::LP_BTSPAS_fit_NonDiag</code> function for cases
where recaptures take place outside the stratum of release.
</p>
<p>The frequency variable (<code>freq</code> in the <code>data</code> argument) is the number of animals with the corresponding capture history.
</p>
<p>Capture histories (<code>cap_hist</code> in the <code>data</code> argument) are character values of the format
<code>xx..yy</code> is a capture_history where <code>xx</code> and <code>yy</code> are the temporal stratum
(e.g., julian week) and <code>'..'</code> separates
the two temporal strata.
If a fish is released in temporal stratum and never captured again, then <code>yy</code> is set to 0;
if a fish is newly captured in temporal stratum <code>yy</code>, then <code>xx</code> is set to zero.
For example, a capture history of <code>23..23</code> indicates animals released in temporal stratum
23 and recaptured in temporal stratum 23; a capture history of <code>23..00</code>
indicates animals released in temporal stratum
23 and never seen again; a capture history of <code>00..23</code>
indicates animals newly captured in temporal stratum
23 at the second sampling event.
</p>
<p>In the diagonal case, no fish should move between temporal strata.
</p>
<p>It is not necessary to label the temporal strata starting at 1; BTSPAS will treat the smallest
value of the temporal strata seen as the first stratum and will interpolate for temporal strata
without any data. Temporal strata labels should be numeric, i.e., do NOT use A, B, C etc.
</p>


<h3>Value</h3>

<p>An list object of class <em>LP_BTSPAS_fit_Diag</em> with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> A data frame  with the information on the number of observations in the fit
</p>
</li>
<li> <p><strong>data</strong> Data used in the fit
</p>
</li>
<li> <p><strong>p_model</strong>, <strong>p_model_cov</strong> Information on modelling the capture probabilities at the second occasion
</p>
</li>
<li> <p><strong>fit</strong> n MCMC object with samples from the posterior distribution. A
series of graphs and text file are also created with summary information. Refer to the BTSPAS package for more details.
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the fit was done
</p>
</li></ul>



<h3>References</h3>

<p>Bonner, S. J. and Schwarz, C. J. (2021). BTSPAS: Bayesian Time Stratified Petersen Analysis System.R package version 2021.11.2.
</p>
<p>Bonner, S. J., &amp; Schwarz, C. J. (2011).
Smoothing population size estimates for Time-Stratified Mark-Recapture experiments Using Bayesian P-Splines.
Biometrics, 67, 1498-1507.
<a href="https://doi.org/10.1111/j.1541-0420.2011.01599.x">doi:10.1111/j.1541-0420.2011.01599.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# NOTE. To keep execution time to a small value as required by CRAN
# I've made a very small example.
# Additionally, I've set the number of MCMC chains, iterations, burning, simulation to save to
# small values. Proper mixing may not have occurred yet.
# When using this routine, you likely want to the use the default values
# for these MCMC parameters.

data(data_btspas_diag1)
# extract the strata of interest
temp&lt;- cbind(data_btspas_diag1,
             split_cap_hist( data_btspas_diag1$cap_hist,
                             sep="..", make.numeric=TRUE))
# only use data up to week 10 to keep example small
temp &lt;- temp[ temp$t1 %in% 0:10 &amp; temp$t2 %in% 0:10,]

fit &lt;- Petersen::LP_BTSPAS_fit_Diag(
  temp,
  p_model=~1,
  InitialSeed=23943242,
  # the number of chains and iterations are too small to be useful
  # they are set to a small number to pare execution time to &lt;5 seconds for an example
  n.chains=2, n.iter=20000, n.burnin=1000, n.sims=100,
  quietly=TRUE
)
fit$summary

# now get the estimates of abundance
est &lt;-  Petersen::LP_BTSPAS_est (fit)
est$summary


</code></pre>

<hr>
<h2 id='LP_BTSPAS_fit_NonDiag'>Wrapper (*_fit) to call the Time Stratified Petersen Estimator
with NON-Diagonal Entries function in BTSPAS.</h2><span id='topic+LP_BTSPAS_fit_NonDiag'></span>

<h3>Description</h3>

<p>Takes the data structure as described below, and uses Bayesian methods to fit a fit a spline
through the population numbers and a hierarchical model for the trap
efficiency over time.  An MCMC object
is also created with samples from the posterior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_BTSPAS_fit_NonDiag(
  data,
  p_model = ~1,
  p_model_cov = NULL,
  jump.after = NULL,
  logitP.fixed = NULL,
  logitP.fixed.values = NULL,
  InitialSeed = ceiling(stats::runif(1, min = 0, max = 1e+06)),
  n.chains = 3,
  n.iter = 2e+05,
  n.burnin = 1e+05,
  n.sims = 2000,
  trace = FALSE,
  remove_MCMC_files = TRUE,
  quietly = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_p_model">p_model</code></td>
<td>
<p>Model for the captured probabilities. This can reference
other variables in the data frame, plus a special reserved term <code>..time</code> to indicate
a time dependence in the capture probabilities. For example, <code>p_model=~1</code> would indicate
that the capture probabilities are equal across the sampling events;
<code>p_model=~..time</code> would indicate that the capture probabilities vary by sampling events;
<code>p_model=~sex*..time</code> would indicate that the capture probabilities vary across
all combination of sampling events (<code>..time</code>) and a stratification variable (<code>sex</code>). The <code>sex</code> variable
also needs to be in the data frame.
</p>
<p>For some models (e.g., tag loss models), the <code>..time</code> variable cannot be used because
the models only have one capture probability (e.g., only for event 1).</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_p_model_cov">p_model_cov</code></td>
<td>
<p>Data frame with covariates for the model for prob capture at second sampling event. If this
data frame is given, it requires one line for each of the temporal strata at the second sampling event (even
if missing in the <code>data</code> that has the capture histories) with one variable being <code>..time</code>
to represent
the second temporal stratum.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_jump.after">jump.after</code></td>
<td>
<p>A numeric vector with elements belonging to <code>time</code>.
In some cases, the spline fitting the population numbers should be allowed
to jump.  For example, the population size could take a jump when hatchery
released fish suddenly arrive at the trap.  The jumps occur AFTER the strata
listed in this argument.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_logitp.fixed">logitP.fixed</code></td>
<td>
<p>A numeric vector (could be null) of the time strata
where the logit(P) would be fixed. Typically, this is used when the capture
rates for some strata are 0 and logit(P) is set to -10 for these strata. The
fixed values are given in <code>logitP.fixed.values</code></p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_logitp.fixed.values">logitP.fixed.values</code></td>
<td>
<p>A numerical vector (could be null) of the fixed
values for logit(P) at strata given by logitP.fixed. Typically this is used
when certain strata have a 0 capture rate and the fixed value is set to -10
which on the logit scale gives $p_i$ essentially 0. Don't specify values such
as -50 because numerical problems could occur when this is converted to the 0-1 scale.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_initialseed">InitialSeed</code></td>
<td>
<p>Numeric value used to initialize the random numbers used
in the MCMC iterations.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_n.chains">n.chains</code></td>
<td>
<p>Number of chains to fit in the MCMC</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_n.iter">n.iter</code></td>
<td>
<p>Total number of iterations</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_n.burnin">n.burnin</code></td>
<td>
<p>Number of burnin iterations</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_n.sims">n.sims</code></td>
<td>
<p>Total number of simulations to keep in output (implies a thinning)</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_trace">trace</code></td>
<td>
<p>Internal tracing flag.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_remove_mcmc_files">remove_MCMC_files</code></td>
<td>
<p>Should the temporary MCMC files (init.txt, data.text, model.txt, CODA*txt) removed after the fit.</p>
</td></tr>
<tr><td><code id="LP_BTSPAS_fit_NonDiag_+3A_quietly">quietly</code></td>
<td>
<p>Suppress all console messages that occur during the fit. This includes the progress bar
when a model that requires MCMC is fit (<em>LP_BTSPAS_fit_Diag</em> and <em>LP_BTSPAS_fit_NonDiag</em>), or
a trace of the likelihood during the fit (<em>LP_SPAS_fit</em>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Use the <code>Petersen::LP_BTSPAS_fit_Diag</code> function for cases
where recaptures take place in a single stratum (diagonal case).
</p>
<p>The frequency variable (<code>freq</code> in the <code>data</code> argument) is the number of animals with the corresponding capture history.
</p>
<p>Capture histories (<code>cap_hist</code> in the <code>data</code> argument) are character values of the format
<code>xx..yy</code> is a capture_history where <code>xx</code> and <code>yy</code> are the temporal stratum
(e.g., julian week) and <code>'..'</code> separates
the two temporal strata.
If a fish is released in temporal stratum and never captured again, then <code>yy</code> is set to 0;
if a fish is newly captured in temporal stratum <code>yy</code>, then <code>xx</code> is set to zero.
For example, a capture history of <code>23..23</code> indicates animals released in temporal stratum
23 and recaptured in temporal stratum 23; a capture history of <code>23..00</code>
indicates animals released in temporal stratum
23 and never seen again; a capture history of <code>00..23</code>
indicates animals newly captured in temporal stratum
23 at the second sampling event.
</p>
<p>In the non-diagonal case, fish are allowed to move among temporal strata.
</p>
<p>It is not necessary to label the temporal strata starting at 1; BTSPAS will treat the smallest
value of the temporal strata seen as the first stratum and will interpolate for temporal strata
without any data. Temporal strata labels should be numeric, i.e., do NOT use A, B, C etc.
</p>


<h3>Value</h3>

<p>An list object of class <em>LP_BTSPAS_fit_Diag</em> with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> A data frame  with the information on the number of observations in the fit
</p>
</li>
<li> <p><strong>data</strong> Data used in the fit
</p>
</li>
<li> <p><strong>p_model</strong>, <strong>p_model_cov</strong> Information on modelling the capture probabilities at the second occasion
</p>
</li>
<li> <p><strong>fit</strong> n MCMC object with samples from the posterior distribution. A
series of graphs and text file are also created with summary information. Refer to the BTSPAS package for more details.
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the fit was done
</p>
</li></ul>



<h3>References</h3>

<p>Bonner, S. J. and Schwarz, C. J. (2021). BTSPAS: Bayesian Time Stratified Petersen Analysis System.R package version 2021.11.2.
</p>
<p>Bonner, S. J., &amp; Schwarz, C. J. (2011).
Smoothing population size estimates for Time-Stratified Mark-Recapture experiments Using Bayesian P-Splines.
Biometrics, 67, 1498-1507.
<a href="https://doi.org/10.1111/j.1541-0420.2011.01599.x">doi:10.1111/j.1541-0420.2011.01599.x</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# NOTE. To keep execution time to a small value as required by CRAN
# I've made a very small example.
# Additionally, I've set the number of MCMC chains, iterations, burning, simulation to save to
# small values. Proper mixing may not have occurred yet.
# When using this routine, you likely want to the use the default values
# for these MCMC parameters.
data(data_btspas_nondiag1)
temp&lt;- cbind(data_btspas_nondiag1,
             split_cap_hist( data_btspas_nondiag1$cap_hist,
                             sep="..", make.numeric=TRUE))
xtabs(~t1, data=temp)

# only use data up to week 10 to keep example small
temp &lt;- temp[ temp$t1 %in% c(0, 27:32) &amp; temp$t2 %in% c(0, 27:32),]

fit &lt;- Petersen::LP_BTSPAS_fit_NonDiag(
  temp,
  p_model=~1,
  InitialSeed=23943242,
  # the number of chains and iterations are too small to be useful
  # they are set to a small number to pare execution time to &lt;5 seconds for an example
  n.chains=2, n.iter=20000, n.burnin=1000, n.sims=100,
  quietly=TRUE
)
fit$summary

# now get the estimates of abundance
est &lt;-  Petersen::LP_BTSPAS_est (fit)
est$summary

</code></pre>

<hr>
<h2 id='LP_CL_fit'>Fit the Chen-Lloyd model to estimate abundance using a non-parametric smoother for a covariates</h2><span id='topic+LP_CL_fit'></span>

<h3>Description</h3>

<p>This will take a data frame of capture histories, frequencies, and a covariates
and will do a non-parametric smoother for the detection probabilities as a function
of the covariates and use this to estimate the population size.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_CL_fit(
  data,
  covariate,
  centers = hist(data[, covariate, drop = TRUE], breaks = "Sturges", plot = FALSE)$mids,
  h1 = (centers[2] - centers[1]) * 0.75,
  h2 = (centers[2] - centers[1]) * 0.75,
  conf_level = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_CL_fit_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
<tr><td><code id="LP_CL_fit_+3A_covariate">covariate</code></td>
<td>
<p>Name of continuous covariate that influences capture probabilities at each event</p>
</td></tr>
<tr><td><code id="LP_CL_fit_+3A_centers">centers</code></td>
<td>
<p>Centers of bins to group the covariates. We suggest no more than 30 bins in total
with fewer bins with smaller sample sizes. Of course with smaller sample sizes, a simple stratified
estimator may be easier to use.</p>
</td></tr>
<tr><td><code id="LP_CL_fit_+3A_h1">h1</code>, <code id="LP_CL_fit_+3A_h2">h2</code></td>
<td>
<p>Standard deviation of normal kernel for first sampling event. This should be between 1/2 and the 1.5x the
bin width. Larger values imply more smoothing. Smaller values imply less smoothing.</p>
</td></tr>
<tr><td><code id="LP_CL_fit_+3A_conf_level">conf_level</code></td>
<td>
<p>The expected coverage for confidence intervals on N.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The frequency variable (<code>freq</code> in the <code>data</code> argument) is the number of animals with the corresponding capture history.
</p>
<p>Capture histories (<code>cap_hist</code> in the <code>data</code> argument) are character values of length 2.
</p>

<ul>
<li> <p><strong>10</strong>  Animals tagged but never seen again.
</p>
</li>
<li> <p><strong>11</strong>  Animals tagged and recaptured and tag present at event 2.
</p>
</li>
<li> <p><strong>01</strong>  Animals captured at event 2 that appear to be untagged.
</p>
</li></ul>



<h3>Value</h3>

<p>An list object of class <em>LP_CL_fit</em> with abundance estimates and other information with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> A data frame  with the estimates of abundance, SE, and CI
</p>
</li>
<li> <p><strong>fit</strong> Details on the Chen and Lloyd fit including the smoothed estimates of catchability, estimates abundance by category classes,
estimates of total abundance, plots of the estimated abundance curve and catchability curves, etc.
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the fit was done
</p>
</li></ul>



<h3>References</h3>

<p>SX Chen, CJ Lloyd (2000).
A nonparametric approach to the analysis of two-stage mark-recapture experiments.
Biometrika, 87, 633–649. <a href="https://doi.org/10.1093/biomet/87.3.633">doi:10.1093/biomet/87.3.633</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(Petersen)
data(data_NorthernPike)
res &lt;- LP_CL_fit(data_NorthernPike, "length")
res$summary
</code></pre>

<hr>
<h2 id='LP_est'>Estimate abundance after the LP conditional likelihood fit.</h2><span id='topic+LP_est'></span>

<h3>Description</h3>

<p>This will take a previous fit and return estimates of abundance.
The population abundance is estimated using
a Horvitz-Thompson type estimator and the user can request abundance
estimates for sub-sets of the population.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_est(LP_fit, N_hat = ~1, conf_level = 0.95, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_est_+3A_lp_fit">LP_fit</code></td>
<td>
<p>A result of an LP_fit() call.</p>
</td></tr>
<tr><td><code id="LP_est_+3A_n_hat">N_hat</code></td>
<td>
<p>A formula requesting which abundance estimates should be formed. The formula are
expanded against the data frame to determine which records form part of the abundance estimate.
The formula is evaluated against the <code>data</code> frame used in the fit using the <code>model.matrix()</code> function,
and each column of the model
matrix is used to form an estimate.
</p>
<p>Some familiarity on how <code>model.matrix()</code> generates the model matrix of coefficients used in the expansion
is needed.
For example <code>N_hat=~1</code> creates a model matrix with 1 column (representing the intercept) and
so requests abundance over the entire population;
Specifying <code>N_hat=~-1+Sex</code> creates a model matrix with 2 columns (one for each sex) consisting of 0/1 depending
if that row of the data frame is M/F. Hence, two abundance estimates (one for each sex) is computed.
On the other hand, <code>N_hat=Sex</code> generates a model matrix where the first column is all 1's, and
a second column which is 0/1 depending if the row in the data frame is the &quot;second&quot; sex. Hence, this will
request the overall abundance (over both sexes) and the estimate of abundance for the second sex.
</p>
<p>In addition to the variables in the <code>data</code> frame, special variables include <code>..EF</code> to allow access to the expansion
factor so you can request a &quot;truncated&quot; Horvitz-Thompson estimator using <code>N_hat=~-1+I(as.numeric(..EF&lt;1000))</code>
to only use those animals with expansion factors less than 1000 in forming the estimate.</p>
</td></tr>
<tr><td><code id="LP_est_+3A_conf_level">conf_level</code></td>
<td>
<p>The expected coverage for confidence intervals on N.</p>
</td></tr>
<tr><td><code id="LP_est_+3A_trace">trace</code></td>
<td>
<p>If trace flag is set in call when estimating functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An list object with abundance estimates and other information with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> Data frame with abundance estimates, their SE, and CIs as requested
</p>
</li>
<li> <p><strong>detail</strong> List with many components, including the rawdata, model fitting information, observed and expected values, residual plot, etc
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the estimation was done from the fit.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Schwarz, C. J. <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_rodli)
fit &lt;- Petersen::LP_fit(data=data_rodli, p_model=~..time)
fit$summary
est &lt;- Petersen::LP_est(fit, N_hat=~1)
est$summary
</code></pre>

<hr>
<h2 id='LP_est_adjust'>Estimate abundance after empirical adjustments for various factors.</h2><span id='topic+LP_est_adjust'></span>

<h3>Description</h3>

<p>This will take a previous fit and return estimates of abundance after making various empirical adjustments
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_est_adjust(
  N_hat,
  N_hat_SE,
  conf_level = 0.95,
  tag.retention.est = 1,
  tag.retention.se = 0,
  tag.reporting.est = 1,
  tag.reporting.se = 0,
  n1.adjust.est = 1,
  n1.adjust.se = 0,
  n2.adjust.est = 1,
  n2.adjust.se = 0,
  m2.adjust.est = 1,
  m2.adjust.se = 0,
  n.sim = 10000,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_est_adjust_+3A_n_hat">N_hat</code></td>
<td>
<p>Estimate of N that will be adjusted</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_n_hat_se">N_hat_SE</code></td>
<td>
<p>SE of the N_hat</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_conf_level">conf_level</code></td>
<td>
<p>The expected coverage for confidence intervals on N.</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_tag.retention.est">tag.retention.est</code></td>
<td>
<p>Estimated tag retention probability</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_tag.retention.se">tag.retention.se</code></td>
<td>
<p>Estimated SE of tag retention probability</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_tag.reporting.est">tag.reporting.est</code></td>
<td>
<p>Estimated tag reporting probability</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_tag.reporting.se">tag.reporting.se</code></td>
<td>
<p>Estimated SE of tag reporting probability</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_n1.adjust.est">n1.adjust.est</code></td>
<td>
<p>Adjustment to &quot;n1&quot;. This should typically be a ratio of new n1 to old n1</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_n1.adjust.se">n1.adjust.se</code></td>
<td>
<p>Adjustment to &quot;n1&quot; uncertainty</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_n2.adjust.est">n2.adjust.est</code></td>
<td>
<p>Adjustment to &quot;n2&quot;  This should typically be a ratio of new n2 to old n2</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_n2.adjust.se">n2.adjust.se</code></td>
<td>
<p>Adjustment to &quot;n2&quot; uncertainty</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_m2.adjust.est">m2.adjust.est</code></td>
<td>
<p>Adjustment to &quot;m2&quot;  This should typically be a ratio of new m2 to old m2</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_m2.adjust.se">m2.adjust.se</code></td>
<td>
<p>Adjustment to &quot;m2&quot; uncertainty</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_n.sim">n.sim</code></td>
<td>
<p>Number of simulation runs to make</p>
</td></tr>
<tr><td><code id="LP_est_adjust_+3A_trace">trace</code></td>
<td>
<p>If trace flag is set in call when estimating functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The estimate and SE are converted to a beta distribution for adjustment factors between 0 and 1 with equivalent
mean and SD as the estimate and se. The estimate and se are used in normal distribution for adjustment factors for n1, n2, and m2.
These adjustment factors are then simulated a large number of times and then multiplied together
to get the mean and sd of all adjustments applied together.
Then the abundance is simulated (on the log scale), the product taken, and
the mean, sd, ci estimated directly.
</p>


<h3>Value</h3>

<p>An list object with a summary data frame and a data frame with the adjustment factors with the following objects
<strong>summary</strong> A data frame with the adjusted abundance estimates, SE, and CI
<strong>adjustment</strong> a data frame showing the adjustment factors applied for tag retention, tag reporting, n1 n2 or m2.
<strong>datetime</strong> Date and time the adjustment was done
</p>


<h3>Author(s)</h3>

<p>Schwarz, C. J. <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_rodli)
rodli.fit &lt;- Petersen::LP_fit(data=data_rodli, p_model=~..time)
rodli.est &lt;- Petersen::LP_est(rodli.fit)
res &lt;- Petersen::LP_est_adjust(rodli.est$summary$N_hat, rodli.est$summary$N_hat_SE,
          tag.retention.est=.90, tag.retention.se=.05)
res$summary
</code></pre>

<hr>
<h2 id='LP_fit'>Fit a Lincoln-Petersen Model using conditional likelihood</h2><span id='topic+LP_fit'></span>

<h3>Description</h3>

<p>This will take a data frame of capture histories, frequencies, and
additional covariates (e.g., strata and/or continuous covariates) and the model
for the capture probabilities and will use conditional likelihood (Huggins, 1989)
to fit the model. The population abundance is estimated using
a Horvitz-Thompson type estimator and the user can request abundance
estimates for sub-sets of the population.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_fit(data, p_model, p_beta.start = NULL, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_fit_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
<tr><td><code id="LP_fit_+3A_p_model">p_model</code></td>
<td>
<p>Model for the captured probabilities. This can reference
other variables in the data frame, plus a special reserved term <code>..time</code> to indicate
a time dependence in the capture probabilities. For example, <code>p_model=~1</code> would indicate
that the capture probabilities are equal across the sampling events;
<code>p_model=~..time</code> would indicate that the capture probabilities vary by sampling events;
<code>p_model=~sex*..time</code> would indicate that the capture probabilities vary across
all combination of sampling events (<code>..time</code>) and a stratification variable (<code>sex</code>). The <code>sex</code> variable
also needs to be in the data frame.
</p>
<p>For some models (e.g., tag loss models), the <code>..time</code> variable cannot be used because
the models only have one capture probability (e.g., only for event 1).</p>
</td></tr>
<tr><td><code id="LP_fit_+3A_p_beta.start">p_beta.start</code></td>
<td>
<p>Initial values for call to optimization routine for the beta parameters (on the logit scale).
The values will be replicated to match
the number of initial beta parameters needed. Some care is needed here!</p>
</td></tr>
<tr><td><code id="LP_fit_+3A_trace">trace</code></td>
<td>
<p>If trace flag is set in call when estimating functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The frequency variable (<code>freq</code> in the <code>data</code> argument) is the number of animals with the corresponding capture history.
</p>
<p>Capture histories (<code>cap_hist</code> in the <code>data</code> argument) are character values of length 2.
</p>

<ul>
<li> <p><strong>10</strong>  Animals tagged but never seen again.
</p>
</li>
<li> <p><strong>11</strong>  Animals tagged and recaptured and tag present at event 2.
</p>
</li>
<li> <p><strong>01</strong>  Animals captured at event 2 that appear to be untagged.
</p>
</li></ul>



<h3>Value</h3>

<p>An list object of class <em>LP_fit</em> with abundance estimates and other information with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> A data frame with the model for the capture probabilities;
the conditional log-likelihood; the number of parameters; the number of parameters, and method used to fit the model
</p>
</li>
<li> <p><strong>data</strong> A data frame with the raw data used in the fit
</p>
</li>
<li> <p><strong>fit</strong> Results of the fit from the optimizer
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the fit was done
</p>
</li></ul>

<p>After the fit is done, use the <em>LP_est()</em> function to get estimates of abundance.
</p>


<h3>Author(s)</h3>

<p>Schwarz, C. J. <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>.
</p>


<h3>References</h3>

<p>Huggins, R. M. 1989. On the Statistical Analysis of Capture Experiments.
Biometrika 76: 133&ndash;40.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_rodli)
fit &lt;- Petersen::LP_fit(data=data_rodli, p_model=~..time)
fit$summary
res &lt;- Petersen::LP_est(fit, N_hat=~1)
res$summary

</code></pre>

<hr>
<h2 id='LP_IS_est'>Estimate abundance after the LP_IS conditional likelihood fit.</h2><span id='topic+LP_IS_est'></span>

<h3>Description</h3>

<p>This will take a previous fit and return estimates of abundance.
The population abundance is estimated using
a Horvitz-Thompson type estimator and the user can request abundance
estimates for sub-sets of the population
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_IS_est(LP_IS_fit, N_hat = ~1, conf_level = 0.95, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_IS_est_+3A_lp_is_fit">LP_IS_fit</code></td>
<td>
<p>A result of an LP_IS_fit() call.</p>
</td></tr>
<tr><td><code id="LP_IS_est_+3A_n_hat">N_hat</code></td>
<td>
<p>A formula requesting which abundance estimates should be formed. The formula are
expanded against the data frame to determine which records form part of the abundance estimate.
The formula is evaluated against the <code>data</code> frame used in the fit using the <code>model.matrix()</code> function,
and each column of the model
matrix is used to form an estimate.
</p>
<p>Some familiarity on how <code>model.matrix()</code> generates the model matrix of coefficients used in the expansion
is needed.
For example <code>N_hat=~1</code> creates a model matrix with 1 column (representing the intercept) and
so requests abundance over the entire population;
Specifying <code>N_hat=~-1+Sex</code> creates a model matrix with 2 columns (one for each sex) consisting of 0/1 depending
if that row of the data frame is M/F. Hence, two abundance estimates (one for each sex) is computed.
On the other hand, <code>N_hat=Sex</code> generates a model matrix where the first column is all 1's, and
a second column which is 0/1 depending if the row in the data frame is the &quot;second&quot; sex. Hence, this will
request the overall abundance (over both sexes) and the estimate of abundance for the second sex.
</p>
<p>In addition to the variables in the <code>data</code> frame, special variables include <code>..EF</code> to allow access to the expansion
factor so you can request a &quot;truncated&quot; Horvitz-Thompson estimator using <code>N_hat=~-1+I(as.numeric(..EF&lt;1000))</code>
to only use those animals with expansion factors less than 1000 in forming the estimate.</p>
</td></tr>
<tr><td><code id="LP_IS_est_+3A_conf_level">conf_level</code></td>
<td>
<p>The expected coverage for confidence intervals on N.</p>
</td></tr>
<tr><td><code id="LP_IS_est_+3A_trace">trace</code></td>
<td>
<p>If trace flag is set in call when estimating functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An list object with abundance estimates and other information with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> Data frame with abundance estimates, their SE, and CIs as requested
</p>
</li>
<li> <p><strong>detail</strong> List with many components, including the rawdata, model fitting information, observed and expected values, residual plot, etc
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the estimation was done from the fit.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Schwarz, C. J. <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_wae_is_short)
fit &lt;- Petersen::LP_IS_fit(data=data_wae_is_short, p_model=~..time)
fit$summary
est &lt;- LP_IS_est(fit, N_hat=~1)
est$summary
</code></pre>

<hr>
<h2 id='LP_IS_fit'>Fit a Lincoln-Petersen Model with incomplete stratification</h2><span id='topic+LP_IS_fit'></span>

<h3>Description</h3>

<p>In some LP studies, stratification is only done on a random sample of unmarked
fish, e.g., only a sample of fish is sexed. Is is known as incomplete stratification.
This is a wrapper to the published code for the case of stratification by a
discrete covariate. At the moment, no other covariates are allowed, but see
the published code.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_IS_fit(
  data,
  p_model,
  theta_model = ~-1 + ..time,
  lambda_model = ~-1 + ..cat,
  logit_p_offset = 0,
  logit_theta_offset = 0,
  logit_lambda_offset = 0,
  cat.unknown = "U",
  p_beta.start = NULL,
  trace = FALSE,
  control.optim = list(trace = 0, maxit = 1000)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_IS_fit_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting. At the moment, you are not allowed to use these covariates
to used in the modeling process, but see the published code for more details.</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_p_model">p_model</code></td>
<td>
<p>Model for the captured probabilities. This can reference
other variables in the data frame, plus a special reserved term <code>..time</code> to indicate
a time dependence in the capture probabilities. For example, <code>p_model=~1</code> would indicate
that the capture probabilities are equal across the sampling events;
<code>p_model=~..time</code> would indicate that the capture probabilities vary by sampling events;
<code>p_model=~sex*..time</code> would indicate that the capture probabilities vary across
all combination of sampling events (<code>..time</code>) and a stratification variable (<code>sex</code>). The <code>sex</code> variable
also needs to be in the data frame.
</p>
<p>For some models (e.g., tag loss models), the <code>..time</code> variable cannot be used because
the models only have one capture probability (e.g., only for event 1).</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_theta_model">theta_model</code></td>
<td>
<p>Model for theta (sampling fraction). Usually, this is set to be different
for the two sampling occasions, but you can constrain this to have equal sampling fractions at both occasions.</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_lambda_model">lambda_model</code></td>
<td>
<p>Model for lambda category proportions. Usually this is set to different for the categories
but you can constrain this with a null matrix and the <code>logit_lamba_offset</code> parameter</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_logit_p_offset">logit_p_offset</code></td>
<td>
<p>Used to fix capture probabilities at known values (seldom useful). Logit(p)=p_design %*% beta_p + logit_p_offset.</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_logit_theta_offset">logit_theta_offset</code></td>
<td>
<p>Used to fix sampling fractions at known values (seldom useful).
logit(theta) = theta_design %*% beta_theta + logit_theta_offset</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_logit_lambda_offset">logit_lambda_offset</code></td>
<td>
<p>Used to fix the sex ratio as a known value (e.g. .50) using
logit(lambda) = lambda_design %*% beta_lambda + logit_lambda_offset.
Set the design matrix to a matrix with all zeros. Notice that because the lambda proportions must sum to 1,
only specify an offset matrix that is number of categories -1.</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_cat.unknown">cat.unknown</code></td>
<td>
<p>Value of character used to indicate the unknown stratum in the capture histories. Currently, this
is fixed to &quot;U&quot; regardless of what is specified.</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_p_beta.start">p_beta.start</code></td>
<td>
<p>Initial values for call to optimization routine for the beta parameters (on the logit scale).
The values will be replicated to match
the number of initial beta parameters needed. Some care is needed here!</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_trace">trace</code></td>
<td>
<p>If trace flag is set in call when estimating functions</p>
</td></tr>
<tr><td><code id="LP_IS_fit_+3A_control.optim">control.optim</code></td>
<td>
<p>Control values passed to optim() optimizer.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The frequency variable (<code>freq</code> in the <code>data</code> argument) is the number of animals with the corresponding capture history.
</p>
<p>Capture histories (<code>cap_hist</code> in the <code>data</code> argument) are character values of length 2.
The strata values are single character values with &quot;U&quot; typically representing a fish not measured
for the stratification variable. For example, consider the case where only a sample of unmarked fish
are examined for sex (M or F). Possible capture histories are:
</p>

<ul>
<li> <p><strong>M0</strong>  Animals tagged and sexed as male but never seen again.
</p>
</li>
<li> <p><strong>MM</strong>  Animals tagged and sexed as male and recaptured and tag present at event 2.
</p>
</li>
<li> <p><strong>0M</strong>  Animals captured at event 2 that appears to be untagged and was sexed as male.
</p>
</li>
<li> <p><strong>F0</strong>  Animals tagged and sexed as female but never seen again.
</p>
</li>
<li> <p><strong>FF</strong>  Animals tagged and sexed as female and recaptured and tag present at event 2.
</p>
</li>
<li> <p><strong>0F</strong>  Animals captured at event 2 that appears to be untagged and was sexed as female.
</p>
</li>
<li> <p><strong>U0</strong>  Animals tagged and not sexed but never seen again.
</p>
</li>
<li> <p><strong>UU</strong>  Animals tagged and not sexed and recaptured and tag present at event 2.
</p>
</li>
<li> <p><strong>0U</strong>  Animals captured at event 2 that appears to be untagged and was not sexed.
</p>
</li></ul>

<p>Capture histories such as <strong>UF</strong> or <strong>UM</strong> are not allowed since only UNTAGGED animals
are examined and sexed. Similarly, capture histories such as <strong>FM</strong> or <strong>MF</strong> are not allowed.
</p>


<h3>Value</h3>

<p>An list object of class <em>LP_IS_fit</em> with abundance estimates and other information with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> A data frame with the model for the capture probabilities, the sampling fractions at each capture occasion, and the category proportions;
the conditional log-likelihood; the number of parameters; the number of parameters, and method used to fit the model
</p>
</li>
<li> <p><strong>data</strong> A data frame with the raw data used in the fit
</p>
</li>
<li> <p><strong>fit</strong> Results of the fit including the estimates, SE, vcov, etc.
</p>
</li>
<li> <p><strong>fit.call</strong> Arguments used in the fit
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the fit was done
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Schwarz, C. J. <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>.
</p>


<h3>References</h3>

<p>Premarathna, W.A.L., Schwarz, C.J., Jones, T.S. (2018)
Partial stratification in two-sample capture–recapture experiments.
Environmetrics, 29:e2498. <a href="https://doi.org/10.1002/env.2498">doi:10.1002/env.2498</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_wae_is_short)
fit &lt;- Petersen::LP_IS_fit(data=data_wae_is_short, p_model=~..time)
fit$summary
est &lt;- LP_IS_est(fit, N_hat=~1)
est$summary

</code></pre>

<hr>
<h2 id='LP_IS_print'>Print the results from a fit a Lincoln-Petersen Model with incomplete stratification</h2><span id='topic+LP_IS_print'></span>

<h3>Description</h3>

<p>Print the results from a fit a Lincoln-Petersen Model with incomplete stratification
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_IS_print(IS.results)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_IS_print_+3A_is.results">IS.results</code></td>
<td>
<p>Results from fitting an incomplete stratification model</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A nicely formatted report showing the results of the fit.
</p>

<ul>
<li><p> Model information (summary of arguments, model name, negative log-likelihood, number of parameters, AICc)
</p>
</li>
<li><p> Raw data used in the fit (history, frequency,categories)
</p>
</li>
<li><p> Initial values used in the optimization of the likelihood for the parameters
</p>
</li>
<li><p> Design matrix and offset values for the parameters
</p>
</li>
<li><p> Maximum likelihood estimates for the parameters and estimated abundance by category
</p>
</li>
<li><p> SE for the above
</p>
</li>
<li><p> Observed and expected counts for each capture history
</p>
</li>
<li><p> Residual plot constructed from the previous observed and expected counts
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
data(data_wae_is_short)
res &lt;- Petersen::LP_IS_fit(data=data_wae_is_short, p_model=~-1 + ..cat:..time)
LP_IS_print(res)

</code></pre>

<hr>
<h2 id='LP_modavg'>Create an table of individual estimates and the model averaged values</h2><span id='topic+LP_modavg'></span>

<h3>Description</h3>

<p>This will take a series of LP fits and computes the model averages for each set of N_hat
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_modavg(..., N_hat = ~1, conf_level = 0.95)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_modavg_+3A_...">...</code></td>
<td>
<p>Series of LP fits</p>
</td></tr>
<tr><td><code id="LP_modavg_+3A_n_hat">N_hat</code></td>
<td>
<p>A formula requesting which abundance estimates should be formed. The formula are
expanded against the data frame to determine which records form part of the abundance estimate.
The formula is evaluated against the <code>data</code> frame used in the fit using the <code>model.matrix()</code> function,
and each column of the model
matrix is used to form an estimate.
</p>
<p>Some familiarity on how <code>model.matrix()</code> generates the model matrix of coefficients used in the expansion
is needed.
For example <code>N_hat=~1</code> creates a model matrix with 1 column (representing the intercept) and
so requests abundance over the entire population;
Specifying <code>N_hat=~-1+Sex</code> creates a model matrix with 2 columns (one for each sex) consisting of 0/1 depending
if that row of the data frame is M/F. Hence, two abundance estimates (one for each sex) is computed.
On the other hand, <code>N_hat=Sex</code> generates a model matrix where the first column is all 1's, and
a second column which is 0/1 depending if the row in the data frame is the &quot;second&quot; sex. Hence, this will
request the overall abundance (over both sexes) and the estimate of abundance for the second sex.
</p>
<p>In addition to the variables in the <code>data</code> frame, special variables include <code>..EF</code> to allow access to the expansion
factor so you can request a &quot;truncated&quot; Horvitz-Thompson estimator using <code>N_hat=~-1+I(as.numeric(..EF&lt;1000))</code>
to only use those animals with expansion factors less than 1000 in forming the estimate.</p>
</td></tr>
<tr><td><code id="LP_modavg_+3A_conf_level">conf_level</code></td>
<td>
<p>The expected coverage for confidence intervals on N.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An data frame with model averaged values for abundance
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_rodli)
mt &lt;- Petersen::LP_fit(data=data_rodli, p_model=~..time)
m0 &lt;- Petersen::LP_fit(data=data_rodli, p_model=~1)
Petersen::LP_modavg(m0,mt)

</code></pre>

<hr>
<h2 id='LP_SPAS_est'>Extract estimates of abundance after SPAS fit</h2><span id='topic+LP_SPAS_est'></span>

<h3>Description</h3>

<p>This will take a previous fit and return estimates of abundance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_SPAS_est(LP_SPAS_fit, conf_level = 0.95, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_SPAS_est_+3A_lp_spas_fit">LP_SPAS_fit</code></td>
<td>
<p>A result of an call to fitting at SPAS object.</p>
</td></tr>
<tr><td><code id="LP_SPAS_est_+3A_conf_level">conf_level</code></td>
<td>
<p>The expected coverage for confidence intervals on N.</p>
</td></tr>
<tr><td><code id="LP_SPAS_est_+3A_trace">trace</code></td>
<td>
<p>If trace flag is set in call when estimating functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An list object with abundance estimates and other information with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> Data frame with abundance estimates, their SE, and CIs as requested
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the estimation was done from the fit.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Schwarz, C. J. <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_spas_harrison)
fit &lt;- Petersen::LP_SPAS_fit(data=data_spas_harrison,
                              model.id="Pooling rows 5/6",
                              row.pool.in=c(1,2,3,4,56,56),
                              col.pool.in=c(1,2,3,4,5,6))
fit$summary
est &lt;- Petersen::LP_SPAS_est(fit)
est$summary
</code></pre>

<hr>
<h2 id='LP_SPAS_fit'>Fit a Stratified-Petersen SPAS model.</h2><span id='topic+LP_SPAS_fit'></span>

<h3>Description</h3>

<p>This function is a wrapper to fits a SPAS model(Schwarz, 2023; Schwarz and Taylor, 1998). Consult the SPAS package for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_SPAS_fit(
  data,
  model.id = "Base model",
  autopool = FALSE,
  row.pool.in = NULL,
  col.pool.in = NULL,
  min.released = 100,
  min.inspected = 50,
  min.recaps = 50,
  min.rows = 1,
  min.cols = 1,
  quietly = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_SPAS_fit_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
<tr><td><code id="LP_SPAS_fit_+3A_model.id">model.id</code></td>
<td>
<p>Character string identifying the name of the model.</p>
</td></tr>
<tr><td><code id="LP_SPAS_fit_+3A_autopool">autopool</code></td>
<td>
<p>Should the automatic pooling algorithms be used.
Give more details here on these rule work.</p>
</td></tr>
<tr><td><code id="LP_SPAS_fit_+3A_row.pool.in">row.pool.in</code>, <code id="LP_SPAS_fit_+3A_col.pool.in">col.pool.in</code></td>
<td>
<p>Vectors (character/numeric) of length s and t respectively. These identify the rows/columns to be pooled before the analysis is done.
The vectors consists of entries where pooling takes place if the entries are the same. For example, if s=4, then
row.pool.in = c(1,2,3,4) implies no pooling because all entries are distinct; row.pool.in=c(&quot;a&quot;,&quot;a&quot;,&quot;b&quot;,&quot;b&quot;) implies that the
first two rows will be pooled and the last two rows will be pooled. It is not necessary that row/columns be continuous to be pooled, but
this is seldom sensible. A careful choice of pooling labels helps to remember what as done, e.g. row.pool.in=c(&quot;123&quot;,&quot;123&quot;,&quot;123&quot;,&quot;4&quot;) indicates
that the first 3 rows are pooled and the 4th row is not pooled. Character entries ensure that the resulting matrix is sorted properly (e.g. if
row.pool.in=c(123,123,123,4), then the same pooling is done, but the matrix rows are sorted rather strangely.</p>
</td></tr>
<tr><td><code id="LP_SPAS_fit_+3A_min.released">min.released</code></td>
<td>
<p>Minimum number of releases in a pooled row</p>
</td></tr>
<tr><td><code id="LP_SPAS_fit_+3A_min.inspected">min.inspected</code></td>
<td>
<p>Minimum number of inspections in a pooled column</p>
</td></tr>
<tr><td><code id="LP_SPAS_fit_+3A_min.recaps">min.recaps</code></td>
<td>
<p>Minimum number of recaptures before any rows can be pooled</p>
</td></tr>
<tr><td><code id="LP_SPAS_fit_+3A_min.rows">min.rows</code>, <code id="LP_SPAS_fit_+3A_min.cols">min.cols</code></td>
<td>
<p>Minimum number or rows and columns after pooling</p>
</td></tr>
<tr><td><code id="LP_SPAS_fit_+3A_quietly">quietly</code></td>
<td>
<p>Suppress all console messages that occur during the fit. This includes the progress bar
when a model that requires MCMC is fit (<em>LP_BTSPAS_fit_Diag</em> and <em>LP_BTSPAS_fit_NonDiag</em>), or
a trace of the likelihood during the fit (<em>LP_SPAS_fit</em>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An list object of class <em>LP_SPAS_fit</em> with abundance estimates and other information with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> A data frame with the model for the capture probabilities;
the conditional log-likelihood; the number of parameters; the number of parameters, condition factor of the data matrix, and method used to fit the model
</p>
</li>
<li> <p><strong>data</strong> A data frame with the raw data used in the fit
</p>
</li>
<li> <p><strong>fit</strong> Results of the fit including the estimates, SE, vcov, etc.
</p>
</li>
<li> <p><strong>row.pool.in</strong>, <strong>col.pool.in</strong>, <strong>autopool</strong> Arguments used in the fit to indicate row, column, or automatic pooling used in the fit.
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the fit was done
</p>
</li></ul>

<p>After the fit is complete, use the <em>LP_SPAS_est()</em> function to extract the estimates, and the SPAS::SPAS.print.model() function to get a nicely
formatted report on the fit.
</p>


<h3>References</h3>

<p>Schwarz CJ (2023). <em>SPAS: Stratified-Petersen Analysis System</em>.
R package version 2023.3.31, <a href="https://CRAN.R-project.org/package=SPAS">https://CRAN.R-project.org/package=SPAS</a>.
</p>
<p>Schwarz, C. J. and Taylor, C. G. (1998). The use of the
stratified-Petersen estimator in fisheries management: estimating the
number of pink salmon (Oncorhynchus gorbuscha) that spawn in the Fraser River.
Canadian Journal of Fisheries and Aquatic Sciences 55, 281-297.
https://doi.org/10.1139/f97-238
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data_spas_harrison)

fit &lt;- Petersen::LP_SPAS_fit(data=data_spas_harrison,
                              model.id="Pooling rows 5/6",
                              row.pool.in=c(1,2,3,4,56,56),
                              col.pool.in=c(1,2,3,4,5,6),quietly=TRUE)
fit$summary
est &lt;- Petersen::LP_SPAS_est(fit)
est$summary

# make a nice report using the SPAS package functions
SPAS::SPAS.print.model(fit$fit)

</code></pre>

<hr>
<h2 id='LP_summary_stats'>Compute summary statistics from the capture histories</h2><span id='topic+LP_summary_stats'></span>

<h3>Description</h3>

<p>This function takes the capture histories and computes $n_1$, $n_2$ and $m_2$.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_summary_stats(data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_summary_stats_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Summary statistics of <em>n1</em> (number observed at first occasion), <em>n2</em> (number observed at second occasion),
and <em>m2</em> number recaptured in second occasion.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_rodli)
LP_summary_stats(data_rodli)

</code></pre>

<hr>
<h2 id='LP_test_equal_mf'>Test for equal marked fractions in LP experiment</h2><span id='topic+LP_test_equal_mf'></span>

<h3>Description</h3>

<p>This function takes the capture histories and stratification variable and computes the test
for equal marked fractions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_test_equal_mf(data, strat_var, do.fisher.test = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_test_equal_mf_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
<tr><td><code id="LP_test_equal_mf_+3A_strat_var">strat_var</code></td>
<td>
<p>Variable in the dataframe that serves as a stratification variable for contingency table tests
of equal marked fraction or equal recapture probability</p>
</td></tr>
<tr><td><code id="LP_test_equal_mf_+3A_do.fisher.test">do.fisher.test</code></td>
<td>
<p>Do a fisher test?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing the contingency table and the chi-square test and fisher-exact test
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_NorthernPike)
LP_test_equal_mf(data_NorthernPike, "Sex")

</code></pre>

<hr>
<h2 id='LP_test_equal_recap'>Test for equal recapture probability in LP experiment</h2><span id='topic+LP_test_equal_recap'></span>

<h3>Description</h3>

<p>This function takes the capture histories and stratification variable and computes the test
for equal recapture probabilities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_test_equal_recap(data, strat_var, do.fisher.test = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_test_equal_recap_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
<tr><td><code id="LP_test_equal_recap_+3A_strat_var">strat_var</code></td>
<td>
<p>Variable in the dataframe that serves as a stratification variable for contingency table tests
of equal marked fraction or equal recapture probability</p>
</td></tr>
<tr><td><code id="LP_test_equal_recap_+3A_do.fisher.test">do.fisher.test</code></td>
<td>
<p>Should a fisher exact test be done?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List containing the contingency table and the chi-square test and fisher-exact test
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_NorthernPike)
LP_test_equal_recap(data_NorthernPike, "Sex")

</code></pre>

<hr>
<h2 id='LP_TL_est'>Estimate abundance after the LP_TL (tag loss) conditional likelihood fit.</h2><span id='topic+LP_TL_est'></span>

<h3>Description</h3>

<p>This will take a previous fit and return estimates of abundance.
The population abundance is estimated using
a Horvitz-Thompson type estimator based only on p1 and the user can request abundance
estimates for sub-sets of the population.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_TL_est(LP_TL_fit, N_hat = ~1, conf_level = 0.95, trace = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_TL_est_+3A_lp_tl_fit">LP_TL_fit</code></td>
<td>
<p>A result of an LP_TL_fit() call.</p>
</td></tr>
<tr><td><code id="LP_TL_est_+3A_n_hat">N_hat</code></td>
<td>
<p>A formula requesting which abundance estimates should be formed. The formula are
expanded against the data frame to determine which records form part of the abundance estimate.
The formula is evaluated against the <code>data</code> frame used in the fit using the <code>model.matrix()</code> function,
and each column of the model
matrix is used to form an estimate.
</p>
<p>Some familiarity on how <code>model.matrix()</code> generates the model matrix of coefficients used in the expansion
is needed.
For example <code>N_hat=~1</code> creates a model matrix with 1 column (representing the intercept) and
so requests abundance over the entire population;
Specifying <code>N_hat=~-1+Sex</code> creates a model matrix with 2 columns (one for each sex) consisting of 0/1 depending
if that row of the data frame is M/F. Hence, two abundance estimates (one for each sex) is computed.
On the other hand, <code>N_hat=Sex</code> generates a model matrix where the first column is all 1's, and
a second column which is 0/1 depending if the row in the data frame is the &quot;second&quot; sex. Hence, this will
request the overall abundance (over both sexes) and the estimate of abundance for the second sex.
</p>
<p>In addition to the variables in the <code>data</code> frame, special variables include <code>..EF</code> to allow access to the expansion
factor so you can request a &quot;truncated&quot; Horvitz-Thompson estimator using <code>N_hat=~-1+I(as.numeric(..EF&lt;1000))</code>
to only use those animals with expansion factors less than 1000 in forming the estimate.</p>
</td></tr>
<tr><td><code id="LP_TL_est_+3A_conf_level">conf_level</code></td>
<td>
<p>The expected coverage for confidence intervals on N.</p>
</td></tr>
<tr><td><code id="LP_TL_est_+3A_trace">trace</code></td>
<td>
<p>If trace flag is set in call when estimating functions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An list object with abundance estimates and other information with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> Data frame with abundance estimates, their SE, and CIs as requested
</p>
</li>
<li> <p><strong>detail</strong> List with many components, including the rawdata, model fitting information, etc
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the estimation was done from the fit.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Schwarz, C. J. <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_kokanee_tagloss)
fit &lt;- Petersen::LP_TL_fit(data=data_kokanee_tagloss, p_model=~1, rho_model=~1, dt_type="notD")
fit$summary
est &lt;- Petersen::LP_TL_est(fit, N_hat=~1)
est$summary
</code></pre>

<hr>
<h2 id='LP_TL_fit'>Fit a Lincoln-Petersen Model with Tag Loss using conditional likelihood</h2><span id='topic+LP_TL_fit'></span>

<h3>Description</h3>

<p>This will take a data frame of capture histories, frequencies, and
additional covariates (e.g., strata and/or continuous covariates) and the model
for p1 and the tag retention probabilities
and will use conditional likelihood (conditional on capture at time 2)
to fit the model. The population abundance is estimated using
a Horvitz-Thompson type estimator and the user can request abundance
estimates for sub-sets of the population. Refer to references and appendices in vignettes
for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_TL_fit(
  data,
  dt_type = NULL,
  p_model,
  rho_model,
  all_beta.start = NULL,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_TL_fit_+3A_data">data</code></td>
<td>
<p>Data frame containing the variables:
</p>

<ul>
<li> <p><strong>cap_hist</strong> Capture history (see details below)
</p>
</li>
<li> <p><strong>freq</strong> Number of times this capture history was observed
</p>
</li></ul>

<p>plus any other covariates (e.g. discrete strata and/or continuous covariates) to be used
in the model fitting.</p>
</td></tr>
<tr><td><code id="LP_TL_fit_+3A_dt_type">dt_type</code></td>
<td>
<p>Double Tag type. Valid values are
<code>notD</code>, <code>twoD</code>, and <code>t2perm</code>
for two indistinguishable tags; two distinguishable tags, when the second tag is a permanent tag and cannot be lost,
respectively.</p>
</td></tr>
<tr><td><code id="LP_TL_fit_+3A_p_model">p_model</code></td>
<td>
<p>Model for the captured probabilities. This can reference
other variables in the data frame, plus a special reserved term <code>..time</code> to indicate
a time dependence in the capture probabilities. For example, <code>p_model=~1</code> would indicate
that the capture probabilities are equal across the sampling events;
<code>p_model=~..time</code> would indicate that the capture probabilities vary by sampling events;
<code>p_model=~sex*..time</code> would indicate that the capture probabilities vary across
all combination of sampling events (<code>..time</code>) and a stratification variable (<code>sex</code>). The <code>sex</code> variable
also needs to be in the data frame.
</p>
<p>For some models (e.g., tag loss models), the <code>..time</code> variable cannot be used because
the models only have one capture probability (e.g., only for event 1).</p>
</td></tr>
<tr><td><code id="LP_TL_fit_+3A_rho_model">rho_model</code></td>
<td>
<p>Model for retention probabilities</p>
</td></tr>
<tr><td><code id="LP_TL_fit_+3A_all_beta.start">all_beta.start</code></td>
<td>
<p>Initial values for call to optimization routine for the beta parameters (on the logit scale).
The values will be replicated to match
the number of initial beta parameters needed. Some care is needed here since the parameter order are for the p1 probabilities
and then for the rho probabilities</p>
</td></tr>
<tr><td><code id="LP_TL_fit_+3A_trace">trace</code></td>
<td>
<p>If trace flag is set in call when estimating functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The frequency variable (<code>freq</code> in the <code>data</code> argument) is the number of animals with the corresponding capture history.
</p>
<p>Capture histories (<code>cap_hist</code> in the <code>data</code> argument) are character values of length 4.
</p>
<p>If the tag loss model is two indistinguishable tags (<code>dt_type="notD"</code>), then valid capture histories are:
</p>

<ul>
<li> <p><strong>1100</strong>  Animals double tagged but never seen again.
</p>
</li>
<li> <p><strong>111X</strong>  Animals double tagged, but only 1 tag was present when animal recaptured at second event.
</p>
</li>
<li> <p><strong>1111</strong>  Animals double tagged and both tags present when animal recaptured at second event.
</p>
</li>
<li> <p><strong>1000</strong>  Animals single tagged and never seen again.
</p>
</li>
<li> <p><strong>0100</strong>  Animals single tagged and never seen again.
</p>
</li>
<li> <p><strong>1010</strong>  Animals single tagged and recaptured with the single tag.
</p>
</li>
<li> <p><strong>0101</strong>  Animals single tagged and recaptured with the single tag.
</p>
</li>
<li> <p><strong>0010</strong>  Animals APPARENTLY captured for the first time at event 2. This includes animals that are
newly captured, plus fish that were tagged and lost all their tags, and were captured again
</p>
</li></ul>

<p>If the tag loss model is two distinguishable tags (<code>dt_type="twoD"</code>), then valid capture histories are the same
as above except the history <code>111X</code> is replaced by:
</p>

<ul>
<li> <p><strong>1110</strong> Animals double tagged, but only the first of the double tags applied  was present when animal recaptured at event 2,
</p>
</li>
<li> <p><strong>1101</strong> Animals double tagged, but only the second of the double tags applied was present when animal recaptured at event 2.
</p>
</li></ul>

<p>If the second tag is a permanent batch mark (<code>dt_type="t2perm"</code>), then valid capture histories are:
</p>

<ul>
<li> <p><strong>1P00</strong>  Animals double tagged but never seen again.
</p>
</li>
<li> <p><strong>1P0P</strong>  Animals double tagged,but non-permanent tag missing when animal recaptured at second event.
</p>
</li>
<li> <p><strong>1P1P</strong>  Animals double tagged and both tags present when animal recaptured at second event.
</p>
</li>
<li> <p><strong>1000</strong>  Animals single tagged and never seen again.
</p>
</li>
<li> <p><strong>0P00</strong>  Animals single tagged with a permanent batch mark only and never seen again.
</p>
</li>
<li> <p><strong>1010</strong>  Animals single tagged and recaptured with the single tag.
</p>
</li>
<li> <p><strong>0P0P</strong>  Animals single tagged with the permanent batch mark and recaptured with the permanent tag.
</p>
</li>
<li> <p><strong>0010</strong>  Animals APPARENTLY captured for the first time at event 2. This includes animals that are
newly captured, plus fish that were tagged and lost all their tags, and were captured again
</p>
</li></ul>



<h3>Value</h3>

<p>An list object of class <em>LP_TL_fit-notD</em> or <em>LP_TL_fit-twoD</em>, or <em>LP_TL_fit-t2per</em>
(depending on the type of double tag) with abundance estimates and other information with the following elements
</p>

<ul>
<li> <p><strong>summary</strong> A data frame with the model for the capture probabilities, and tag retention probabilities;
the conditional log-likelihood; the number of parameters; the number of parameters, and method used to fit the model
</p>
</li>
<li> <p><strong>data</strong> A data frame with the raw data used in the fit
</p>
</li>
<li> <p><strong>fit</strong> Results of the fit including the estimates, SE, vcov, etc.
</p>
</li>
<li> <p><strong>datetime</strong> Date and time the fit was done
</p>
</li></ul>

<p>After the fit is complete, use the <em>LP_TL_est()</em> function to obtain estimates.
</p>


<h3>Author(s)</h3>

<p>Schwarz, C. J. <a href="mailto:cschwarz.stat.sfu.ca@gmail.com">cschwarz.stat.sfu.ca@gmail.com</a>.
</p>


<h3>References</h3>

<p>Seber, G. A. F., and R. Felton. (1981). Tag Loss and the Petersen
Mark-Recapture Experiment. Biometrika 68, 211&ndash;19.
</p>
<p>Hyun, S.-Y., Reynolds.J.H., and Galbreath, P.F. (2012). Accounting for
Tag Loss and Its Uncertainty in a Mark&ndash;Recapture Study with a Mixture
of Single and Double Tags. Transactions of the American Fisheries
Society, 141, 11-25 http://dx.doi.org/10.1080/00028487.2011.639263
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_kokanee_tagloss)
fit &lt;- Petersen::LP_TL_fit(data=data_kokanee_tagloss, p_model=~1, rho_model=~1, dt_type="notD")
fit$summary
est &lt;- Petersen::LP_TL_est(fit, N_hat=~1)
est$summary

</code></pre>

<hr>
<h2 id='LP_TL_simulate'>Simulate data from a Lincoln-Petersen Model with Tag Loss</h2><span id='topic+LP_TL_simulate'></span>

<h3>Description</h3>

<p>This function creates simulated capture histories for the Lincoln-Petersen
model with tag loss.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LP_TL_simulate(
  dt_type = NULL,
  N = 1000,
  cov1 = function(N) {
     rep(1, N)
 },
  cov2 = function(cov1) {
     rep(1, length(cov1))
 },
  p1 = function(cov1, cov2) {
     rep(0.1, length(cov1))
 },
  pST = function(cov1, cov2) {
     rep(0.5, length(cov1))
 },
  pST.1 = function(cov1, cov2) {
     rep(1, length(cov1))
 },
  rho1 = function(cov1, cov2) {
     rep(0.8, length(cov1))
 },
  rho2 = function(cov1, cov2) {
     rep(0.8, length(cov1))
 },
  p2 = function(cov1, cov2) {
     rep(0.1, length(cov1))
 },
  seed = round(1e+08 * runif(1)),
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="LP_TL_simulate_+3A_dt_type">dt_type</code></td>
<td>
<p>Double Tag type. Valid values are
<code>notD</code>, <code>twoD</code>, and <code>t2perm</code>
for two indistinguishable tags; two distinguishable tags, when the second tag is a permanent tag and cannot be lost,
respectively.</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_n">N</code></td>
<td>
<p>Population size</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_cov1">cov1</code></td>
<td>
<p>Function to generate first covariate for each member of population as function of <code>N</code></p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_cov2">cov2</code></td>
<td>
<p>Function to generate second covariate for each member of population as function of <code>cov1</code>.</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_p1">p1</code></td>
<td>
<p>Function to generate P(capture) at event 1 for each member of population as function of <code>cov1,cov2</code>.</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_pst">pST</code></td>
<td>
<p>Function to generate P(single tag) if captured at event 1 as function of <code>cov1,cov2</code>.</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_pst.1">pST.1</code></td>
<td>
<p>Function to generate p(apply single tag to first position at event 1) as function of <code>cov1,cov2</code>.</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_rho1">rho1</code></td>
<td>
<p>Function to generate P(tag1 retained) as function of <code>cov1,cov2</code>.</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_rho2">rho2</code></td>
<td>
<p>Function to generate P(tag2 retained) as function of <code>cov1,cov2</code>.</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_p2">p2</code></td>
<td>
<p>Function to generate P(capture) at event 2 for each member of population as function of <code>cov1,cov2</code>.</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_seed">seed</code></td>
<td>
<p>Initial value of random seed</p>
</td></tr>
<tr><td><code id="LP_TL_simulate_+3A_trace">trace</code></td>
<td>
<p>Trace flag to help debug if things fail.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>cov1</code> function takes the value <code>N</code> and returns N covariate values. For example these could be
simulated length, or sex of each fish. The <code>cov2</code> function takes the <code>cov1</code> values and generates
a second covariate. Two covariates should be sufficient for most capture-recapture simulations.
If generating continuous covariates, you should round the covariate to
about 100 distinct values to speed up your simulation.
</p>
<p>The remaining functions take the two covariate values and generate capture probabilities, single tag probabilities,
placing tags on fish, and tag retention probabilities. These should all be in the range of 0 to 1.
</p>
<p>After generating capture histories for the entire population, animals never seen are &quot;discarded&quot; and the
data set is compress to unique combinations of the two covariates and the capture history with the frequency
variable set accordingly.
</p>


<h3>Value</h3>

<p>Data frame with observed capture histories
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sim_data &lt;-LP_TL_simulate(
      dt_type="t2perm",  # permanent tag
      N=1000,
      cov1=function(N)         {rep(1,N)},
      cov2=function(cov1)      {rep(1,  length(cov1))},
      p1  =function(cov1, cov2){rep(.1, length(cov1))},
      pST =function(cov1, cov2){rep(.25,length(cov1))},
      rho1=function(cov1, cov2){rep(.70,length(cov1))},
      rho2=function(cov1, cov2){rep(1,  length(cov1))},  # permanent second tag
      p2  =function(cov1, cov2){rep(.1, length(cov1))},
      seed=round(1000000*runif(1)))
sim_data

</code></pre>

<hr>
<h2 id='split_cap_hist'>Split a vector of capture histories into a matrix with one column for each occasion</h2><span id='topic+split_cap_hist'></span>

<h3>Description</h3>

<p>Split a vector of capture histories into a matrix with one column for each occasion
</p>


<h3>Usage</h3>

<pre><code class='language-R'>split_cap_hist(cap_hist, sep = "", n = 2, prefix = "t", make.numeric = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="split_cap_hist_+3A_cap_hist">cap_hist</code></td>
<td>
<p>A vector of capture histories.</p>
</td></tr>
<tr><td><code id="split_cap_hist_+3A_sep">sep</code></td>
<td>
<p>What separates the individual history values</p>
</td></tr>
<tr><td><code id="split_cap_hist_+3A_n">n</code></td>
<td>
<p>Number of sampling events in each history</p>
</td></tr>
<tr><td><code id="split_cap_hist_+3A_prefix">prefix</code></td>
<td>
<p>Prefix for labeling columns of matrix</p>
</td></tr>
<tr><td><code id="split_cap_hist_+3A_make.numeric">make.numeric</code></td>
<td>
<p>Change the expanded columns to numeric from character?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>@template data.cap_hist
</p>


<h3>Value</h3>

<p>A matrix of capture histories with 1 column per sampling event
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# standard 2 character capture histor
data(data_rodli)
Petersen::split_cap_hist(data_rodli$cap_hist)

# history vector with ".." separating the fields
test &lt;- c("1..1","1..0")
split_cap_hist(test, sep=stringr::fixed(".."))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
