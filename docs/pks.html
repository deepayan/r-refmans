<!DOCTYPE html><html><head><title>Help for package pks</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pks}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#blim'><p>Basic Local Independence Models (BLIMs)</p></a></li>
<li><a href='#blimit'><p>Basic Local Independence Model Identification Analysis</p></a></li>
<li><a href='#chess'><p>Responses to Chess Problems and Knowledge Structures</p></a></li>
<li><a href='#conversion'><p>Conversion between Representations of Responses or States</p></a></li>
<li><a href='#delineate'><p>Delineate a Knowledge Structure by a Skill Function</p></a></li>
<li><a href='#DoignonFalmagne7'><p>Artificial Responses from Doignon and Falmagne (1999)</p></a></li>
<li><a href='#endm'><p>Responses and Knowledge Structures from Heller and Wickelmaier (2013)</p></a></li>
<li><a href='#getKFringe'><p>Outer and Inner Fringes of a Knowledge Structure</p></a></li>
<li><a href='#gradedness'><p>Forward-/Backward-Gradedness and Downgradability of a Knowledge</p>
Structure</a></li>
<li><a href='#ita'><p>Item Tree Analysis (ITA)</p></a></li>
<li><a href='#jacobian'><p>Jacobian Matrix for Basic Local Independence Model</p></a></li>
<li><a href='#plot.blim'><p>Diagnostic Plot for Basic Local Independence Models</p></a></li>
<li><a href='#print.blim'><p>Print a blim Object</p></a></li>
<li><a href='#probability'><p>Problems in Elementary Probability Theory</p></a></li>
<li><a href='#residuals.blim'><p>Residuals for Basic Local Independence Models</p></a></li>
<li><a href='#schoolarithm'><p>Arithmetic Problems for Elementary and Middle School Students</p></a></li>
<li><a href='#simulate.blim'><p>Simulate Responses from Basic Local Independence Models (BLIMs)</p></a></li>
<li><a href='#slm'><p>Simple Learning Models (SLMs)</p></a></li>
<li><a href='#Taagepera'><p>Responses and Knowledge Structures from Taagepera et al. (1997)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.6-0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-07-07</td>
</tr>
<tr>
<td>Title:</td>
<td>Probabilistic Knowledge Structures</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), stats, sets</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics</td>
</tr>
<tr>
<td>Suggests:</td>
<td>relations, Rgraphviz</td>
</tr>
<tr>
<td>Description:</td>
<td>Fitting and testing probabilistic knowledge structures,
  especially the basic local independence model (BLIM, Doignon &amp; Flamagne,
  1999) and the simple learning model (SLM), using the minimum discrepancy
  maximum likelihood (MDML) method (Heller &amp; Wickelmaier, 2013
  &lt;<a href="https://doi.org/10.1016%2Fj.endm.2013.05.145">doi:10.1016/j.endm.2013.05.145</a>&gt;).</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://www.mathpsy.uni-tuebingen.de/wickelmaier/">http://www.mathpsy.uni-tuebingen.de/wickelmaier/</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-07 10:18:52 UTC; siifw01</td>
</tr>
<tr>
<td>Author:</td>
<td>Florian Wickelmaier [aut, cre],
  Juergen Heller [aut],
  Julian Mollenhauer [aut],
  Pasquale Anselmi [ctb],
  Debora de Chiusole [ctb],
  Andrea Brancaccio [ctb],
  Luca Stefanutti [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Florian Wickelmaier &lt;wickelmaier@web.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-07 12:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='blim'>Basic Local Independence Models (BLIMs)</h2><span id='topic+blim'></span><span id='topic+blimMD'></span><span id='topic+anova.blim'></span><span id='topic+coef.blim'></span><span id='topic+deviance.blim'></span><span id='topic+logLik.blim'></span><span id='topic+nobs.blim'></span>

<h3>Description</h3>

<p>Fits a basic local independence model (BLIM) for probabilistic
knowledge structures by minimum discrepancy maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blim(K, N.R, method = c("MD", "ML", "MDML"), R = as.binmat(N.R),
     P.K = rep(1/nstates, nstates),
     beta = rep(0.1, nitems), eta = rep(0.1, nitems),
     betafix = rep(NA, nitems), etafix = rep(NA, nitems),
     betaequal = NULL, etaequal = NULL,
     randinit = FALSE, incradius = 0,
     tol = 1e-07, maxiter = 10000, zeropad = 16)

blimMD(K, N.R, R = as.binmat(N.R),
       betafix = rep(NA, nitems), etafix = rep(NA, nitems),
       incrule = c("minimum", "hypblc1", "hypblc2"), m = 1)

## S3 method for class 'blim'
anova(object, ..., test = c("Chisq", "none"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blim_+3A_k">K</code></td>
<td>
<p>a state-by-problem indicator matrix representing the knowledge
structure.  An element is one if the problem is contained in the state,
and else zero.</p>
</td></tr>
<tr><td><code id="blim_+3A_n.r">N.R</code></td>
<td>
<p>a (named) vector of absolute frequencies of response patterns.</p>
</td></tr>
<tr><td><code id="blim_+3A_method">method</code></td>
<td>
<p><code>MD</code> for minimum discrepancy estimation, <code>ML</code> for
maximum likelihood estimation, <code>MDML</code> for minimum discrepancy
maximum likelihood estimation.</p>
</td></tr>
<tr><td><code id="blim_+3A_r">R</code></td>
<td>
<p>a person-by-problem indicator matrix of unique response patterns.
Per default inferred from the names of <code>N.R</code>.</p>
</td></tr>
<tr><td><code id="blim_+3A_p.k">P.K</code></td>
<td>
<p>the vector of initial parameter values for probabilities of
knowledge states.</p>
</td></tr>
<tr><td><code id="blim_+3A_beta">beta</code>, <code id="blim_+3A_eta">eta</code></td>
<td>
<p>vectors of initial parameter values for probabilities of a
careless error and a lucky guess, respectively.</p>
</td></tr>
<tr><td><code id="blim_+3A_betafix">betafix</code>, <code id="blim_+3A_etafix">etafix</code></td>
<td>
<p>vectors of fixed error and guessing parameter values;
<code>NA</code> indicates a free parameter.</p>
</td></tr>
<tr><td><code id="blim_+3A_betaequal">betaequal</code>, <code id="blim_+3A_etaequal">etaequal</code></td>
<td>
<p>lists of vectors of problem indices; each vector
represents an equivalence class: it contains the indices of problems for
which the error or guessing parameters are constrained to be equal.  (See
Examples.)</p>
</td></tr>
<tr><td><code id="blim_+3A_randinit">randinit</code></td>
<td>
<p>logical, if <code>TRUE</code> then initial parameter values are
sampled uniformly with constraints.  (See Details.)</p>
</td></tr>
<tr><td><code id="blim_+3A_incradius">incradius</code></td>
<td>
<p>include knowledge states of distance from the minimum
discrepant states less than or equal to <code>incradius</code>.</p>
</td></tr>
<tr><td><code id="blim_+3A_tol">tol</code></td>
<td>
<p>tolerance, stopping criterion for iteration.</p>
</td></tr>
<tr><td><code id="blim_+3A_maxiter">maxiter</code></td>
<td>
<p>the maximum number of iterations.</p>
</td></tr>
<tr><td><code id="blim_+3A_zeropad">zeropad</code></td>
<td>
<p>the maximum number of items for which an incomplete
<code>N.R</code> vector is completed and padded with zeros.</p>
</td></tr>
<tr><td><code id="blim_+3A_incrule">incrule</code></td>
<td>
<p>inclusion rule for knowledge states.  (See Details.)</p>
</td></tr>
<tr><td><code id="blim_+3A_m">m</code></td>
<td>
<p>exponent for hyperbolic inclusion rules.</p>
</td></tr>
<tr><td><code id="blim_+3A_object">object</code></td>
<td>
<p>an object of class <code>blim</code>, typically the result of a
call to <code>blim</code>.</p>
</td></tr>
<tr><td><code id="blim_+3A_test">test</code></td>
<td>
<p>should the p-values of the chi-square distributions be
reported?</p>
</td></tr>
<tr><td><code id="blim_+3A_...">...</code></td>
<td>
<p>additional arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Doignon and Falmagne (1999) for details on the basic local independence
model (BLIM) for probabilistic knowledge structures.
</p>
<p>Minimum discrepancy (MD) minimizes the number of expected response errors
(careless errors or lucky guesses). Maximum likelihood maximizes the
likelihood, possibly at the expense of inflating the error and guessing
parameters.  Minimum discrepancy maximum likelihood (MDML) maximizes the
likelihood subject to the constraint of minimum response errors.  See Heller
and Wickelmaier (2013) for details on the parameter estimation methods.
</p>
<p>If <code>randinit</code> is <code>TRUE</code>, initial parameter values are sampled
uniformly with the constraint <code>beta + eta &lt; 1</code> (Weisstein, 2013) for
the error parameters, and with <code>sum(P.K) == 1</code> (Rubin, 1981) for the
probabilities of knowledge states. Setting <code>randinit</code> to <code>TRUE</code>
overrides any values given in the <code>P.K</code>, <code>beta</code>, and <code>eta</code>
arguments.
</p>
<p>The degrees of freedom in the goodness-of-fit test are calculated as number
of possible response patterns minus one or number of respondents, whichever
is smaller, minus number of parameters.
</p>
<p><code>blimMD</code> uses minimum discrepancy estimation only.  Apart from the
hyperbolic inclusion rules, all of its functionality is also provided by
<code>blim</code>.  It may be removed in the future.
</p>


<h3>Value</h3>

<p>An object of class <code>blim</code> having the following components:
</p>
<table>
<tr><td><code>discrepancy</code></td>
<td>
<p>the mean minimum discrepancy between response patterns
and knowledge states.</p>
</td></tr>
<tr><td><code>P.K</code></td>
<td>
<p>the vector of estimated parameter values for probabilities of
knowledge states.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>the vector of estimated parameter values for probabilities of
a careless error.</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>
<p>the vector of estimated parameter values for probabilities of a
lucky guess.</p>
</td></tr>
<tr><td><code>disc.tab</code></td>
<td>
<p>the minimum discrepancy distribution.</p>
</td></tr>
<tr><td><code>K</code></td>
<td>
<p>the knowledge structure.</p>
</td></tr>
<tr><td><code>N.R</code></td>
<td>
<p>the vector of frequencies of response patterns.</p>
</td></tr>
<tr><td><code>nitems</code></td>
<td>
<p>the number of items.</p>
</td></tr>
<tr><td><code>nstates</code></td>
<td>
<p>the number of knowledge states.</p>
</td></tr>
<tr><td><code>npatterns</code></td>
<td>
<p>the number of response patterns.</p>
</td></tr>
<tr><td><code>ntotal</code></td>
<td>
<p>the number of respondents.</p>
</td></tr>
<tr><td><code>nerror</code></td>
<td>
<p>the number of response errors.</p>
</td></tr>
<tr><td><code>npar</code></td>
<td>
<p>the number of parameters.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the parameter estimation method.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>the number of iterations needed.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>the log-likelihood.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted response frequencies.</p>
</td></tr>
<tr><td><code>goodness.of.fit</code></td>
<td>
<p>the goodness of fit statistic including the
likelihood ratio fitted vs. saturated model (G2), the degrees of
freedom, and the p-value of the corresponding chi-square distribution.
(See Details.)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Doignon, J.-P., &amp; Falmagne, J.-C. (1999).
<em>Knowledge spaces</em>. Berlin: Springer.
</p>
<p>Heller, J., &amp; Wickelmaier, F. (2013).
Minimum discrepancy estimation in probabilistic knowledge structures.
<em>Electronic Notes in Discrete Mathematics</em>, <b>42</b>, 49&ndash;56.
<a href="https://doi.org/10.1016/j.endm.2013.05.145">doi:10.1016/j.endm.2013.05.145</a>
</p>
<p>Rubin, D.B. (1981). The Bayesian bootstrap.
<em>The Annals of Statistics</em>, <b>9</b>(1), 130&ndash;134.
<a href="https://doi.org/10.1214/aos/1176345338">doi:10.1214/aos/1176345338</a>
</p>
<p>Weisstein, E.W. (2013, August 29). Triangle point picking.
In <em>MathWorld &ndash; A Wolfram Web Resource</em>.
Retrieved from
<a href="https://mathworld.wolfram.com/TrianglePointPicking.html">https://mathworld.wolfram.com/TrianglePointPicking.html</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+simulate.blim">simulate.blim</a></code>, <code><a href="#topic+plot.blim">plot.blim</a></code>,
<code><a href="#topic+residuals.blim">residuals.blim</a></code>, <code><a href="#topic+logLik.blim">logLik.blim</a></code>,
<code><a href="#topic+delineate">delineate</a></code>, <code><a href="#topic+jacobian">jacobian</a></code>, <code><a href="#topic+endm">endm</a></code>,
<code><a href="#topic+probability">probability</a></code>, <code><a href="#topic+chess">chess</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DoignonFalmagne7)
K   &lt;- DoignonFalmagne7$K    # knowledge structure
N.R &lt;- DoignonFalmagne7$N.R  # frequencies of response patterns

## Fit basic local independence model (BLIM) by different methods
blim(K, N.R, method = "MD")    # minimum discrepancy estimation
blim(K, N.R, method = "ML")    # maximum likelihood estimation by EM
blim(K, N.R, method = "MDML")  # MDML estimation

## Parameter restrictions: beta_a = beta_b = beta_d, beta_c = beta_e
##                          eta_a =  eta_b = 0.1
m1 &lt;- blim(K, N.R, method = "ML",
           betaequal = list(c(1, 2, 4), c(3, 5)),
              etafix = c(0.1, 0.1, NA, NA, NA))
m2 &lt;- blim(K, N.R, method = "ML")
anova(m1, m2)

## See ?endm, ?probability, and ?chess for further examples.
</code></pre>

<hr>
<h2 id='blimit'>Basic Local Independence Model Identification Analysis</h2><span id='topic+blimit'></span>

<h3>Description</h3>

<p>Tests the local identifiability of a basic local independence
model (BLIM).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blimit(K, beta = NULL, eta = NULL, pi = NULL, file_name = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blimit_+3A_k">K</code></td>
<td>
<p>a state-by-problem indicator matrix representing the knowledge
structure.  An element is one if the problem is contained in the state,
and else zero.</p>
</td></tr>
<tr><td><code id="blimit_+3A_beta">beta</code>, <code id="blimit_+3A_eta">eta</code>, <code id="blimit_+3A_pi">pi</code></td>
<td>
<p>vectors of parameter values for probabilities of
careless errors, lucky guesses, and knowledge states, respectively.</p>
</td></tr>
<tr><td><code id="blimit_+3A_file_name">file_name</code></td>
<td>
<p>name of an output file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Stefanutti et al. (2012) for details.
</p>
<p>The <code>blimit</code> function has been adapted from code provided by Andrea
Brancaccio, Debora de Chiusole, and Luca Stefanutti. It contains a function
to compute the reduced row echelon form based on an implementation in the
pracma package.
</p>


<h3>Value</h3>

<p>A list having the following components:
</p>
<table>
<tr><td><code>NItems</code></td>
<td>
<p>the number of items.</p>
</td></tr>
<tr><td><code>NStates</code></td>
<td>
<p>the number of knowledge states.</p>
</td></tr>
<tr><td><code>NPar</code></td>
<td>
<p>the number of parameters.</p>
</td></tr>
<tr><td><code>Rank</code></td>
<td>
<p>the rank of the Jacobian matrix.</p>
</td></tr>
<tr><td><code>NSD</code></td>
<td>
<p>the null space dimension.</p>
</td></tr>
<tr><td><code>RankBeta</code>, <code>RankEta</code>, <code>RankPi</code>, <code>RankBetaEta</code>, <code>RankBetaPi</code>, <code>RankEtaPi</code></td>
<td>
<p>the
rank of submatrices of the Jacobian.</p>
</td></tr>
<tr><td><code>DiagBetaEta</code>, <code>DiagBetaPi</code>, <code>DiagEtaPi</code>, <code>DiagBetaEtaPi</code></td>
<td>
<p>diagnostic
information about specific parameter trade-offs.</p>
</td></tr>
<tr><td><code>Jacobian</code></td>
<td>
<p>the Jacobian matrix.</p>
</td></tr>
<tr><td><code>beta</code>, <code>eta</code>, <code>pi</code></td>
<td>
<p>the parameter values used in the analysis.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Stefanutti, L., Heller, J., Anselmi, P., &amp; Robusto, E. (2012).
Assessing the local identifiability of probabilistic knowledge structures.
<em>Behavior Research Methods</em>, <b>44</b>(4), 1197&ndash;1211.
<a href="https://doi.org/10.3758/s13428-012-0187-z">doi:10.3758/s13428-012-0187-z</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>, <code><a href="#topic+jacobian">jacobian</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>K &lt;- as.binmat(c("0000", "1000", "0100", "1110", "1101", "1111"))

set.seed(1234)
info &lt;- blimit(K)
</code></pre>

<hr>
<h2 id='chess'>Responses to Chess Problems and Knowledge Structures</h2><span id='topic+chess'></span>

<h3>Description</h3>

<p>Held, Schrepp and Fries (1995) derive several knowledge structures for the
representation of 92 responses to 16 chess problems.  See Schrepp, Held and
Albert (1999) for a detailed description of these problems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(chess)</code></pre>


<h3>Format</h3>

<p>A list consisting of five components:
</p>

<dl>
<dt><code>dst1</code></dt><dd><p>a state-by-problem indicator matrix representing the
knowledge structure DST1.</p>
</dd>
<dt><code>dst3</code></dt><dd><p>the knowledge structure DST3.</p>
</dd>
<dt><code>dst4</code></dt><dd><p>the knowledge structure DST4.</p>
</dd>
<dt><code>N.R</code></dt><dd><p>a named integer vector.  The names denote response
patterns, the values denote their frequencies.</p>
</dd>
<dt><code>R</code></dt><dd><p>a person-by-problem indicator matrix representing the
responses.  Column names <code>hdbgXX</code> and <code>grazYY</code> identify
responses collected in Heidelberg and Graz, respectively.</p>
</dd>
</dl>



<h3>Note</h3>

<p>The graphs of the precedence relations for DST1 and DST4 in Held et. al
(1995) contain mistakes that have been corrected.  See examples.
</p>


<h3>Source</h3>

<p>Held, T., Schrepp, M., &amp; Fries, S. (1995).
Methoden zur Bestimmung von Wissensstrukturen &ndash; eine Vergleichsstudie.
<em>Zeitschrift fuer Experimentelle Psychologie</em>,
<b>42</b>(2), 205&ndash;236.
</p>


<h3>References</h3>

<p>Schrepp, M., Held, T., &amp; Albert, D. (1999).
Component-based construction of surmise relations for chess problems.
In D. Albert &amp; J. Lukas (Eds.),
<em>Knowledge spaces: Theories, empirical research, and applications</em>
(pp. 41&ndash;66).  Mahwah, NJ: Erlbaum.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(chess)
chess$dst1  # knowledge structure DST1

## Precedence relation (Held et al., 1995, p. 215) and knowledge space
P &lt;- as.binmat(c("1111011101111001",   # s
               # "0100000000000000",   # gs   mistake in Abb. 3
                 "0111010100111000",   # gs   correction
                 "0011010000011000",   # egs
                 "0011010000011000",   # eegs
                 "0000110000000000",   # cs
                 "0000010000000000",   # gcs
                 "0011011100111000",   # ts
                 "0011010100011000",   # ges
                 "1111111111111111",   # f
                 "0111010101111000",   # gf
                 "0011010000111000",   # gff
                 "0000000000010000",   # ggff
                 "0000000000001000",   # ggf
                 "0111011101111101",   # ff
                 "0111011101111011",   # tf
                 "0011010100111001"),  # tff
               as.logical = TRUE)
dimnames(P) &lt;- list("&lt;" = colnames(chess$R), "&gt;" = colnames(chess$R))
K &lt;- rbind(0L, binary_closure(t(P)))
identical(sort(as.pattern(K)),
          sort(as.pattern(chess$dst1)))

blim(chess$dst1, chess$N.R)  # Tab. 1
</code></pre>

<hr>
<h2 id='conversion'>Conversion between Representations of Responses or States</h2><span id='topic+conversion'></span><span id='topic+as.pattern'></span><span id='topic+as.binmat'></span><span id='topic+is.subset'></span>

<h3>Description</h3>

<p>Converts between binary matrix and pattern representations of response
patterns or knowledge states.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.pattern(R, freq = FALSE, useNames = FALSE, as.set = FALSE,
           sep = "", emptyset = "{}", as.letters = NULL)

as.binmat(N.R, uniq = TRUE, col.names = NULL, as.logical = FALSE)

is.subset(R)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conversion_+3A_r">R</code></td>
<td>
<p>an indicator matrix of response patterns or knowledge states.</p>
</td></tr>
<tr><td><code id="conversion_+3A_n.r">N.R</code></td>
<td>
<p>either a (named) vector of absolute frequencies of response
patterns; or a character vector of response patterns or knowledge states;
or a <code>set</code> of sets representing the knowledge structure.</p>
</td></tr>
<tr><td><code id="conversion_+3A_freq">freq</code></td>
<td>
<p>logical, should the frequencies of response patterns be
reported?</p>
</td></tr>
<tr><td><code id="conversion_+3A_uniq">uniq</code></td>
<td>
<p>logical, if <code>TRUE</code>, only the unique response patterns are
returned.</p>
</td></tr>
<tr><td><code id="conversion_+3A_usenames">useNames</code></td>
<td>
<p>logical, return response patterns as combinations of
item names.</p>
</td></tr>
<tr><td><code id="conversion_+3A_as.set">as.set</code></td>
<td>
<p>logical, return response patterns as set of sets.</p>
</td></tr>
<tr><td><code id="conversion_+3A_sep">sep</code></td>
<td>
<p>character to separate the item names.</p>
</td></tr>
<tr><td><code id="conversion_+3A_emptyset">emptyset</code></td>
<td>
<p>string representing the empty set if <code>useNames</code>
is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="conversion_+3A_as.letters">as.letters</code></td>
<td>
<p>deprecated, use <code>useNames</code> instead.</p>
</td></tr>
<tr><td><code id="conversion_+3A_col.names">col.names</code></td>
<td>
<p>column names for the state or response matrix.</p>
</td></tr>
<tr><td><code id="conversion_+3A_as.logical">as.logical</code></td>
<td>
<p>logical, return logical matrix of states.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>as.pattern</code> returns a vector of integers named by the response
patterns if <code>freq</code> is <code>TRUE</code>, else a character vector. If
<code>as.set</code> is <code>TRUE</code>, the return value is of class <code>set</code>.
</p>
<p><code>as.binmat</code> returns an indicator matrix. If <code>as.logical</code> is
<code>TRUE</code>, it returns a logical matrix.
</p>
<p><code>is.subset</code> returns a logical incidence matrix of the subset relation
among states.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>, <code>set</code> in package <code>sets</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DoignonFalmagne7)
K &lt;- DoignonFalmagne7$K
as.pattern(K, freq = TRUE)
as.pattern(K)
as.pattern(K, useNames = TRUE)
as.pattern(K, as.set = TRUE)

N.R &lt;- DoignonFalmagne7$N.R
dim(as.binmat(N.R))
dim(as.binmat(N.R, uniq = FALSE))

## Knowledge structure as binary matrix
as.binmat(c("000", "100", "101", "111"))
as.binmat(set(set(), set("a"), set("a", "c"), set("a", "b", "c")))
as.binmat(c("000", "100", "101", "111"), as.logical = TRUE)

## Subset relation incidence matrix
is.subset(K)

## Plotting the knowledge structure
if(requireNamespace("relations") &amp;&amp;
   requireNamespace("Rgraphviz")) {
  rownames(K) &lt;- as.pattern(K, useNames = TRUE)
  plot(relations::as.relation(is.subset(K)), main = "")
}
</code></pre>

<hr>
<h2 id='delineate'>Delineate a Knowledge Structure by a Skill Function</h2><span id='topic+delineate'></span>

<h3>Description</h3>

<p>Computes the knowledge structure delineated by a skill function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delineate(skillfun, itemID = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="delineate_+3A_skillfun">skillfun</code></td>
<td>
<p>a data frame or a matrix representing the skill function.
It consists of an item indicator and a problem-by-skill indicator matrix.</p>
</td></tr>
<tr><td><code id="delineate_+3A_itemid">itemID</code></td>
<td>
<p>index of the column in <code>skillfun</code> that holds the item
indicator.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The skill function <code class="reqn">(Q, S, \mu)</code> indicates for each item in <code class="reqn">Q</code>
which subsets of skills in <code class="reqn">S</code> are required to solve the item.  Thus,
<code class="reqn">\mu(q)</code> is a set containing sets of skills.  An item may have multiple
entries in <code>skillfun</code>, each in a separate row identified by the same
<code>itemID</code>.
</p>
<p>See Doignon and Falmagne (1999, Chap. 4).
</p>


<h3>Value</h3>

<p>A list of two components:
</p>
<table>
<tr><td><code>K</code></td>
<td>
<p>the knowledge structure delineated by the skill function.</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>a list of equivalence classes of competence states; the
members of these classes are mapped onto the same knowledge state by the
problem function induced by the skill function <code class="reqn">\mu</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Doignon, J.-P., &amp; Falmagne, J.-C. (1999).
<em>Knowledge spaces</em>. Berlin: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Skill function
# mu(e) = {{s, t}, {s, u}},  mu(f) = {{u}}
# mu(g) = {{s}, {t}},        mu(h) = {{t}}
sf &lt;- read.table(header = TRUE, text = "
  item s t u
     e 1 1 0
     e 1 0 1
     f 0 0 1
     g 1 0 0
     g 0 1 0
     h 0 1 0
")
delineate(sf)

## See ?probability for further examples.
</code></pre>

<hr>
<h2 id='DoignonFalmagne7'>Artificial Responses from Doignon and Falmagne (1999)</h2><span id='topic+DoignonFalmagne7'></span>

<h3>Description</h3>

<p>Fictitious data set from Doignon and Falmagne (1999, chap. 7).
Response patterns of 1000 respondents to five problems.  Each
respondent is assumed to be in one of nine possible states of
the knowledge structure <code>K</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DoignonFalmagne7)</code></pre>


<h3>Format</h3>

<p>A list consisting of two components:
</p>

<dl>
<dt><code>K</code></dt><dd><p>a state-by-problem indicator matrix representing the
hypothetical knowledge structure.  An element is one if the problem
is contained in the state, and else zero.</p>
</dd>
<dt><code>N.R</code></dt><dd><p>a named numeric vector.  The names denote response
patterns, the values denote their frequencies.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Doignon, J.-P., &amp; Falmagne, J.-C. (1999).
<em>Knowledge spaces</em>. Berlin: Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DoignonFalmagne7)
DoignonFalmagne7$K    # knowledge structure
DoignonFalmagne7$N.R  # response patterns
</code></pre>

<hr>
<h2 id='endm'>Responses and Knowledge Structures from Heller and Wickelmaier (2013)</h2><span id='topic+endm'></span>

<h3>Description</h3>

<p>Knowledge structures and 200 artificial responses to four problems are used
to illustrate parameter estimation in Heller and Wickelmaier (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(endm)</code></pre>


<h3>Format</h3>

<p>A list consisting of three components:
</p>

<dl>
<dt><code>K</code></dt><dd><p>a state-by-problem indicator matrix representing the
true knowledge structure that underlies the model that generated the
data.</p>
</dd>
<dt><code>K2</code></dt><dd><p>a slightly misspecified knowledge structure.</p>
</dd>
<dt><code>N.R</code></dt><dd><p>a named numeric vector.  The names denote response
patterns, the values denote their frequencies.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Heller, J., &amp; Wickelmaier, F. (2013).
Minimum discrepancy estimation in probabilistic knowledge structures.
<em>Electronic Notes in Discrete Mathematics</em>, <b>42</b>, 49&ndash;56.
<a href="https://doi.org/10.1016/j.endm.2013.05.145">doi:10.1016/j.endm.2013.05.145</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(endm)
endm$K    # true knowledge structure
endm$K2   # misspecified knowledge structure
endm$N.R  # response patterns

## Generate data from BLIM based on K
blim0 &lt;- list(
     P.K = setNames(c(.1, .15, .15, .2, .2, .1, .1), as.pattern(endm$K)),
    beta = rep(.1, 4),
     eta = rep(.1, 4),
       K = endm$K,
  ntotal = 200)
class(blim0) &lt;- "blim"
simulate(blim0)

## Fit BLIM based on K2
blim1 &lt;- blim(endm$K2, endm$N.R, "MD")
</code></pre>

<hr>
<h2 id='getKFringe'>Outer and Inner Fringes of a Knowledge Structure</h2><span id='topic+getKFringe'></span>

<h3>Description</h3>

<p>Returns the outer or inner fringe for each state in a knowledge structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getKFringe(K, nstates = nrow(K), nitems = ncol(K), outer = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getKFringe_+3A_k">K</code></td>
<td>
<p>a state-by-problem indicator matrix representing the knowledge
structure.  An element is one if the problem is contained in the state,
and else zero.</p>
</td></tr>
<tr><td><code id="getKFringe_+3A_nstates">nstates</code></td>
<td>
<p>the number of knowledge states in <code>K</code>.</p>
</td></tr>
<tr><td><code id="getKFringe_+3A_nitems">nitems</code></td>
<td>
<p>the number of items in <code>K</code>.</p>
</td></tr>
<tr><td><code id="getKFringe_+3A_outer">outer</code></td>
<td>
<p>logical. If <code>TRUE</code> return outer fringe, else return inner
fringe.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The outer fringe of a knowledge state is the set of all items that can be
learned from that state, such that adding an outer-fringe item to the state
results in another state in <code>K</code>,
</p>
<p style="text-align: center;"><code class="reqn">K^O = \{q \notin K | K \cup \{q\} \in \mathcal{K}\}.</code>
</p>

<p>The inner fringe of a knowledge state is the set of all items that have been
learned most recently to reach that state, such that deleting an
inner-fringe item from the state results in another state in <code>K</code>,
</p>
<p style="text-align: center;"><code class="reqn">K^I = \{q \in K | K - \{q\} \in \mathcal{K}\}.</code>
</p>



<h3>Value</h3>

<p>A state-by-problem indicator matrix representing the outer or inner fringe
for each knowledge state in <code>K</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+slm">slm</a></code>, <code><a href="#topic+simulate.blim">simulate.blim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DoignonFalmagne7)

## Which items can be learned from each state?
getKFringe(DoignonFalmagne7$K)

## Which items in each state have been recently learned?
getKFringe(DoignonFalmagne7$K, outer = FALSE)
</code></pre>

<hr>
<h2 id='gradedness'>Forward-/Backward-Gradedness and Downgradability of a Knowledge
Structure</h2><span id='topic+gradedness'></span><span id='topic+is.forward.graded'></span><span id='topic+is.backward.graded'></span><span id='topic+is.downgradable'></span>

<h3>Description</h3>

<p>Checks if a knowledge structure is
</p>

<ul>
<li><p>forward- or backward-graded in any item;
</p>
</li>
<li><p>downgradable.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>is.forward.graded(K)

is.backward.graded(K)

is.downgradable(K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gradedness_+3A_k">K</code></td>
<td>
<p>a state-by-problem indicator matrix representing the knowledge
structure.  An element is one if the problem is contained in the state,
and else zero.  <code>K</code> should have non-empty <code>colnames</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A knowledge structure <code class="reqn">K</code> is forward-graded in item <code class="reqn">q</code>, if
<code class="reqn">S \cup \{q\}</code> is in <code class="reqn">K</code> for every state <code class="reqn">S \in K</code>.
A knowledge structure <code class="reqn">K</code> is backward-graded in item <code class="reqn">q</code>, if
<code class="reqn">S - \{q\}</code> is in <code class="reqn">K</code> for every state <code class="reqn">S \in K</code>.
See Spoto, Stefanutti, and Vidotto (2012).
</p>
<p>A knowledge structure <code class="reqn">K</code> is downgradable, if its inner fringe is empty
only for a single state (the empty set).  See Doignon and Falmagne (2015).
</p>


<h3>Value</h3>

<p>For forward- and backward-gradedness, a named logical vector with as many
elements as columns in <code>K</code>.
</p>
<p>For downgradability, a single logical value.
</p>


<h3>References</h3>

<p>Doignon, J.-P., &amp; Falmagne, J.-C. (2015).
Knowledge spaces and learning spaces.
<em>arXiv</em>.
<a href="https://doi.org/10.48550/arXiv.1511.06757">doi:10.48550/arXiv.1511.06757</a>
</p>
<p>Spoto, A., Stefanutti, L., &amp; Vidotto, G. (2012).
On the unidentifiability of a certain class of skill multi map based
probabilistic knowledge structures.
<em>Journal of Mathematical Psychology</em>, <b>56</b>(4), 248&ndash;255.
<a href="https://doi.org/10.1016/j.jmp.2012.05.001">doi:10.1016/j.jmp.2012.05.001</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>, <code><a href="#topic+jacobian">jacobian</a></code>, <code><a href="#topic+getKFringe">getKFringe</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>K &lt;- as.binmat(c("0000", "1000", "1100", "1010", "0110", "1110", "1111"))
is.forward.graded(K)                  # forward-graded in a
is.backward.graded(K)                 # not backward-graded in a
is.downgradable(K)                    # not downgradable
all(K[, "a"] | getKFringe(K)[, "a"])  # every K or outer fringe contains a
</code></pre>

<hr>
<h2 id='ita'>Item Tree Analysis (ITA)</h2><span id='topic+ita'></span><span id='topic+print.ita'></span>

<h3>Description</h3>

<p>Item tree analysis (ITA) on a set of binary responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ita(R, L = NULL, makeK = FALSE, search = c("local", "global"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ita_+3A_r">R</code></td>
<td>
<p>a subject-by-problem indicator matrix representing the responses.</p>
</td></tr>
<tr><td><code id="ita_+3A_l">L</code></td>
<td>
<p>the threshold of violations acceptable for the precedence relation.
If <code>NULL</code> (default), an optimal threshold is searched for.</p>
</td></tr>
<tr><td><code id="ita_+3A_makek">makeK</code></td>
<td>
<p>should the corresponding knowledge structure be returned?</p>
</td></tr>
<tr><td><code id="ita_+3A_search">search</code></td>
<td>
<p>local (default) or global threshold search.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ITA seeks to establish a precedence relation among a set of binary items.
For each pair of items <code class="reqn">(p, q)</code>, it counts how often <code class="reqn">p</code> is not
solved if <code class="reqn">q</code> is solved, which constitutes a violation of the relation.
ITA searches for a threshold <code>L</code> for the maximum number of violations
consistent with a (transitive) precedence relation.  Its attempts to
minimize the total discrepancy between <code>R</code> and <code>K</code>.
</p>
<p>See van Leeuwe (1974) and Schrepp (1999) for details.
</p>


<h3>Value</h3>

<p>An object of class <code>ita</code> having the following components:
</p>
<table>
<tr><td><code>K</code></td>
<td>
<p>the knowledge structure corresponding to the precedence relation.</p>
</td></tr>
<tr><td><code>discrepancy</code></td>
<td>
<p>the discrepancy between <code>R</code> and <code>K</code> (fit),
between <code>K</code> and <code>R</code> (complexity), and their sum (total).</p>
</td></tr>
<tr><td><code>transitiveL</code></td>
<td>
<p>the vector of transitive thresholds.</p>
</td></tr>
<tr><td><code>searchL</code></td>
<td>
<p>either <code>NULL</code> or the method used for threshold search.</p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>the selected or requested threshold.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>the precedence matrix containing the number of violations.</p>
</td></tr>
<tr><td><code>I</code></td>
<td>
<p>the precedence relation as a logical incidence matrix at threshold
<code>L</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Schrepp, M. (1999).
On the empirical construction of implications between bi-valued test items.
<em>Mathematical Social Sciences</em>,
<b>38</b>(3), 361&ndash;375.
<a href="https://doi.org/10.1016/S0165-4896%2899%2900025-6">doi:10.1016/S0165-4896(99)00025-6</a>
</p>
<p>Van Leeuwe, J.F. (1974).
Item tree analysis.
<em>Nederlands Tijdschrift voor de Psychologie en haar Grensgebieden</em>,
<b>29</b>(6), 475&ndash;483.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(chess)

ita(chess$R)  # find (locally) optimal threshold L

i &lt;- ita(chess$R, L = 6, makeK = TRUE)
identical(sort(as.pattern(i$K)),
          sort(as.pattern(chess$dst1)))

## Plotting the precedence relation
if(requireNamespace("relations") &amp;&amp;
   requireNamespace("Rgraphviz")) {
  plot(relations::as.relation(i$I))
}
</code></pre>

<hr>
<h2 id='jacobian'>Jacobian Matrix for Basic Local Independence Model</h2><span id='topic+jacobian'></span>

<h3>Description</h3>

<p>Computes the Jacobian matrix for a basic local independence model
(BLIM).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>jacobian(object, P.K = rep(1/nstates, nstates),
         beta = rep(0.1, nitems), eta = rep(0.1, nitems),
         betafix = rep(NA, nitems), etafix = rep(NA, nitems))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="jacobian_+3A_object">object</code></td>
<td>
<p>an object of class <code>blim</code>, typically the result of a call
to <code><a href="#topic+blim">blim</a></code>.</p>
</td></tr>
<tr><td><code id="jacobian_+3A_p.k">P.K</code></td>
<td>
<p>the vector of parameter values for probabilities of knowledge
states.</p>
</td></tr>
<tr><td><code id="jacobian_+3A_beta">beta</code></td>
<td>
<p>the vector of parameter values for probabilities of a careless
error.</p>
</td></tr>
<tr><td><code id="jacobian_+3A_eta">eta</code></td>
<td>
<p>the vector of parameter values for probabilities of a lucky
guess.</p>
</td></tr>
<tr><td><code id="jacobian_+3A_betafix">betafix</code>, <code id="jacobian_+3A_etafix">etafix</code></td>
<td>
<p>vectors of fixed error and guessing parameter values;
<code>NA</code> indicates a free parameter.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a draft version.  It may change in future releases.
</p>


<h3>Value</h3>

<p>The Jacobian matrix.  The number of rows equals 2^(number of items) - 1,
the number of columns equals the number of independent parameters in the
model.
</p>


<h3>References</h3>

<p>Heller, J. (2017).
Identifiability in probabilistic knowledge structures.
<em>Journal of Mathematical Psychology</em>, <b>77</b>, 46&ndash;57.
<a href="https://doi.org/10.1016/j.jmp.2016.07.008">doi:10.1016/j.jmp.2016.07.008</a>
</p>
<p>Stefanutti, L., Heller, J., Anselmi, P., &amp; Robusto, E. (2012).
Assessing the local identifiability of probabilistic knowledge structures.
<em>Behavior Research Methods</em>, <b>44</b>(4), 1197&ndash;1211.
<a href="https://doi.org/10.3758/s13428-012-0187-z">doi:10.3758/s13428-012-0187-z</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>, <code><a href="#topic+simulate.blim">simulate.blim</a></code>,
<code><a href="#topic+gradedness">gradedness</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(endm)
m &lt;- blim(endm$K2, endm$N.R)

## Test of identifiability
J &lt;- jacobian(m)
dim(J)
qr(J)$rank
</code></pre>

<hr>
<h2 id='plot.blim'>Diagnostic Plot for Basic Local Independence Models</h2><span id='topic+plot.blim'></span>

<h3>Description</h3>

<p>Plots BLIM residuals against fitted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blim'
plot(x, xlab = "Predicted response probabilities",
     ylab = "Deviance residuals", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.blim_+3A_x">x</code></td>
<td>
<p>an object of class <code>blim</code>, typically the result of a
call to <code><a href="#topic+blim">blim</a></code>.</p>
</td></tr>
<tr><td><code id="plot.blim_+3A_xlab">xlab</code>, <code id="plot.blim_+3A_ylab">ylab</code>, <code id="plot.blim_+3A_...">...</code></td>
<td>
<p>graphical parameters passed to plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The deviance residuals are plotted against the predicted response
probabilities for each response pattern.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>, <code><a href="#topic+residuals.blim">residuals.blim</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Compare MD and MDML estimation

data(DoignonFalmagne7)
blim1 &lt;- blim(DoignonFalmagne7$K, DoignonFalmagne7$N.R, method="MD")
blim2 &lt;- blim(DoignonFalmagne7$K, DoignonFalmagne7$N.R, method="MDML")

par(mfrow = 1:2)      # residuals versus fitted values
plot(blim1, main = "MD estimation",   ylim = c(-4, 4))
plot(blim2, main = "MDML estimation", ylim = c(-4, 4))
</code></pre>

<hr>
<h2 id='print.blim'>Print a blim Object</h2><span id='topic+print.blim'></span>

<h3>Description</h3>

<p>Prints the output of a <code>blim</code> model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blim'
print(x, P.Kshow = FALSE, errshow = TRUE,
      digits=max(3, getOption("digits") - 2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.blim_+3A_x">x</code></td>
<td>
<p>an object of class <code>blim</code>, typically the result of a call to
<code><a href="#topic+blim">blim</a></code>.</p>
</td></tr>
<tr><td><code id="print.blim_+3A_p.kshow">P.Kshow</code></td>
<td>
<p>logical, should the estimated distribution of knowledge
states be printed?</p>
</td></tr>
<tr><td><code id="print.blim_+3A_errshow">errshow</code></td>
<td>
<p>logical, should the estimates of careless error and lucky
guess parameters be printed?</p>
</td></tr>
<tr><td><code id="print.blim_+3A_digits">digits</code></td>
<td>
<p>a non-null value for <code>digits</code> specifies the minimum
number of significant digits to be printed in values.</p>
</td></tr>
<tr><td><code id="print.blim_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.
None are used in this method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the <code>blim</code> object invisibly.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DoignonFalmagne7)
 
blim1 &lt;- blim(DoignonFalmagne7$K, DoignonFalmagne7$N.R)
print(blim1, showP.K = TRUE)
</code></pre>

<hr>
<h2 id='probability'>Problems in Elementary Probability Theory</h2><span id='topic+probability'></span>

<h3>Description</h3>

<p>This data set contains responses to problems in elementary probability
theory observed before and after some instructions (the so-called learning
object) were given.  Data were collected both in the lab and via an online
questionnaire.  Of the 1127 participants eligible in the online study, 649
were excluded because they did not complete the first set of problems
(p101, ..., p112) or they responded too quickly or too slowly.  Based on
similar criteria, further participants were excluded for the second set of
problems, indicated by missing values in the variables b201, ..., b212.
Problems were presented in random order.
</p>
<p>Participants were randomized to two conditions: an enhanced learning object
including instructions with examples and a basic learning object without
examples.  Instructions were given on four concepts: how to calculate the
classic probability of an event (pb), the probability of the complement of
an event (cp), of the union of two disjoint events (un), and of two
independent events (id).
</p>
<p>The questionnaire was organized as follows:
</p>

<dl>
<dt>Page 1</dt><dd><p>Welcome page.</p>
</dd>
<dt>Page 2</dt><dd><p>Demographic data.</p>
</dd>
<dt>Page 3</dt><dd><p>First set of problems.</p>
</dd>
<dt>Page 4 to 8</dt><dd><p>Instructions (learning object).</p>
</dd>
<dt>Page 9</dt><dd><p>Second set of problems.</p>
</dd>
<dt>Page 10</dt><dd><p>Feedback about number of correctly solved problems.</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>data(probability)</code></pre>


<h3>Format</h3>

<p>A data frame with 504 cases and 68 variables:
</p>

<ul>
<li><p><code>case</code> a factor giving the case id, a five-digits code
the fist digit denoting lab or online branch of the study, the last
four digits being the case number.
</p>
</li>
<li><p><code>lastpage</code> Which page of the questionnaire was reached
before quitting?  The questionnaire consisted of ten pages.
</p>
</li>
<li><p><code>mode</code> a factor; <code>lab</code> or <code>online</code> branch of
study.
</p>
</li>
<li><p><code>started</code> a timestamp of class POSIXlt.  When did participant
start working on the questionnaire?
</p>
</li>
<li><p><code>sex</code> a factor coding sex of participant.
</p>
</li>
<li><p><code>age</code> age of participant.
</p>
</li>
<li><p><code>educat</code> education as a factor with three levels:
<code>1</code> secondary school or below; <code>2</code> higher education entrance
qualification; <code>3</code> university degree.
</p>
</li>
<li><p><code>fos</code> field of study.  Factor with eight levels:
<code>ecla</code> economics, business, law; <code>else</code> miscellaneous;
<code>hipo</code> history, politics; <code>lang</code> languages; <code>mabi</code>
mathematics, physics, biology; <code>medi</code> medical science;
<code>phth</code> philosophy, theology; <code>psco</code> psychology,
computer science, cognitive science.
</p>
</li>
<li><p><code>semester</code> ordered factor.  What semester are you in?
</p>
</li>
<li><p><code>learnobj</code> a factor with two levels:
<code>enhan</code> learning object enhanced with examples;
<code>basic</code> learning object without examples.
</p>
</li></ul>

<p>The twelve problems of the first part (before the learning object):
</p>

<ul>
<li><p><code>p101</code> A box contains 30 marbles in the following colors:
8 red, 10 black, 12 yellow.  What is the probability that a randomly
drawn marble is yellow?  (Correct: 0.40)
</p>
</li>
<li><p><code>p102</code> A bag contains 5-cent, 10-cent, and 20-cent coins.
The probability of drawing a 5-cent coin is 0.35, that of drawing a
10-cent coin is 0.25, and that of drawing a 20-cent coin is 0.40.  What
is the probability that the coin randomly drawn is not a 5-cent
coin?  (0.65)
</p>
</li>
<li><p><code>p103</code> A bag contains 5-cent, 10-cent, and 20-cent coins.
The probability of drawing a 5-cent coin is 0.20, that of drawing a
10-cent coin is 0.45, and that of drawing a 20-cent coin is 0.35.  What
is the probability that the coin randomly drawn is a 5-cent coin or
a 20-cent coin?  (0.55)
</p>
</li>
<li><p><code>p104</code> In a school, 40% of the pupils are boys and 80% of
the pupils are right-handed.  Suppose that gender and handedness are
independent.  What is the probability of randomly selecting a
right-handed boy?  (0.32)
</p>
</li>
<li><p><code>p105</code> Given a standard deck containing 32 different cards,
what is the probability of not drawing a heart?  (0.75)
</p>
</li>
<li><p><code>p106</code> A box contains 20 marbles in the following colors:
4 white, 14 green, 2 red.  What is the probability that a randomly
drawn marble is not white?  (0.80)
</p>
</li>
<li><p><code>p107</code> A box contains 10 marbles in the following colors:
2 yellow, 5 blue, 3 red.  What is the probability that a randomly
drawn marble is yellow or blue?  (0.70)
</p>
</li>
<li><p><code>p108</code> What is the probability of obtaining an even number
by throwing a dice?  (0.50)
</p>
</li>
<li><p><code>p109</code> Given a standard deck containing 32 different cards,
what is the probability of drawing a 4 in a black suit?  (Responses
that round to 0.06 were considered correct.)
</p>
</li>
<li><p><code>p110</code> A box contains marbles that are red or yellow, small
or large.  The probability of drawing a red marble is 0.70 (lab: 0.30),
the probability of drawing a small marble is 0.40.  Suppose that the
color of the marbles is independent of their size.  What is the
probability of randomly drawing a small marble that is not red?  (0.12,
lab: 0.28)
</p>
</li>
<li><p><code>p111</code> In a garage there are 50 cars.  20 are black and 10 are
diesel powered.  Suppose that the color of the cars is independent of
the kind of fuel.  What is the probability that a randomly selected car
is not black and it is diesel powered?  (0.12)
</p>
</li>
<li><p><code>p112</code> A box contains 20 marbles.  10 marbles are red, 6 are
yellow and 4 are black.  12 marbles are small and 8 are large.  Suppose
that the color of the marbles is independent of their size.  What is the
probability of randomly drawing a small marble that is yellow or
red?  (0.48)
</p>
</li></ul>

<p>The twelve problems of the second part (after the learning object):
</p>

<ul>
<li><p><code>p201</code> A box contains 30 marbles in the following colors:
10 red, 14 yellow, 6 green.  What is the probability that a randomly
drawn marble is green?  (0.20)
</p>
</li>
<li><p><code>p202</code> A bag contains 5-cent, 10-cent, and 20-cent coins.
The probability of drawing a 5-cent coin is 0.25, that of drawing a
10-cent coin is 0.60, and that of drawing a 20-cent coin is 0.15.  What
is the probability that the coin randomly drawn is not a 5-cent
coin?  (0.75)
</p>
</li>
<li><p><code>p203</code> A bag contains 5-cent, 10-cent, and 20-cent coins.
The probability of drawing a 5-cent coin is 0.35, that of drawing a
10-cent coin is 0.20, and that of drawing a 20-cent coin is 0.45.  What
is the probability that the coin randomly drawn is a 5-cent coin or
a 20-cent coin?  (0.80)
</p>
</li>
<li><p><code>p204</code> In a school, 70% of the pupils are girls and 10% of
the pupils are left-handed.  Suppose that gender and handedness are
independent. What is the probability of randomly selecting a
left-handed girl?  (0.07)
</p>
</li>
<li><p><code>p205</code> Given a standard deck containing 32 different cards,
what is the probability of not drawing a club?  (0.75)
</p>
</li>
<li><p><code>p206</code> A box contains 20 marbles in the following colors:
6 yellow, 10 red, 4 green.  What is the probability that a randomly
drawn marble is not yellow?  (0.70)
</p>
</li>
<li><p><code>p207</code> A box contains 10 marbles in the following colors:
5 blue, 3 red, 2 green.  What is the probability that a randomly
drawn marble is blue or red?  (0.80)
</p>
</li>
<li><p><code>p208</code> What is the probability of obtaining an odd number
by throwing a dice?  (0.50)
</p>
</li>
<li><p><code>p209</code> Given a standard deck containing 32 different cards,
what is the probability of drawing a 10 in a red suit?  (Responses
that round to 0.06 were considered correct.)
</p>
</li>
<li><p><code>p210</code> A box contains marbles that are green or red, large
or small The probability of drawing a green marble is 0.40,
the probability of drawing a large marble is 0.20.  Suppose that the
color of the marbles is independent of their size.  What is the
probability of randomly drawing a large marble that is not
green?  (0.12)
</p>
</li>
<li><p><code>p211</code> In a garage there are 50 cars.  15 are white and 20 are
diesel powered. Suppose that the color of the cars is independent of
the kind of fuel.  What is the probability that a randomly selected car
is not white and it is diesel powered?  (0.28)
</p>
</li>
<li><p><code>p212</code> A box contains 20 marbles.  8 marbles are white, 4 are
green and 8 are red.  15 marbles are small and 5 are large.  Suppose
that the color of the marbles is independent of their size.  What is the
probability of randomly drawing a large marble that is white or
green?  (0.15)
</p>
</li></ul>

<p>Further variables:
</p>

<ul>
<li><p><code>time01</code>, ..., <code>time10</code> the time (in s) spent on each
page of the questionnaire.  In the lab branch of the study, participants
started directly on Page 2.
</p>
</li>
<li><p><code>b101</code>, ..., <code>b112</code> the twelve problems of the first
part coded as correct (1) or error (0).
</p>
</li>
<li><p><code>b201</code>, ..., <code>b212</code> the twelve problems of the second
part coded as correct (1) or error (0).
</p>
</li></ul>



<h3>Source</h3>

<p>Data were collected by Pasquale Anselmi and Florian Wickelmaier at the
Department of Psychology, University of Tuebingen, in February and March
2010.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(probability)

## "Completer" sample
pb &lt;- probability[!is.na(probability$b201), ]

## Response frequencies for first and second part
N.R1 &lt;- as.pattern(pb[, sprintf("b1%.2i", 1:12)], freq = TRUE)
N.R2 &lt;- as.pattern(pb[, sprintf("b2%.2i", 1:12)], freq = TRUE)

## Conjunctive skill function, one-to-one problem function
sf1 &lt;- read.table(header = TRUE, text = "
  item cp id pb un
     1  0  0  1  0
     2  1  0  0  0
     3  0  0  0  1
     4  0  1  0  0
     5  1  0  1  0
     6  1  0  1  0
     7  0  0  1  1
     8  0  0  1  1
     9  0  1  1  0
    10  1  1  0  0
    11  1  1  1  0
    12  0  1  1  1
")

## Extended skill function
sf2 &lt;- rbind(sf1, read.table(header = TRUE, text = "
  item cp id pb un
     2  0  0  0  1
     3  1  0  0  0
     6  0  0  1  1
     7  1  0  1  0
    12  1  1  1  0
"))

## Delineated knowledge structures
K1 &lt;- delineate(sf1)$K
K2 &lt;- delineate(sf2)$K

## After instructions, fit of knowledge structures improves
sapply(list(N.R1, N.R2), function(n) blim(K1, n)$discrepancy)
sapply(list(N.R1, N.R2), function(n) blim(K2, n)$discrepancy)
</code></pre>

<hr>
<h2 id='residuals.blim'>Residuals for Basic Local Independence Models</h2><span id='topic+residuals.blim'></span>

<h3>Description</h3>

<p>Computes deviance and Pearson residuals for <code>blim</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blim'
residuals(object, type = c("deviance", "pearson"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.blim_+3A_object">object</code></td>
<td>
<p>an object of class <code>blim</code>, typically the result of a
call to <code><a href="#topic+blim">blim</a></code>.</p>
</td></tr>
<tr><td><code id="residuals.blim_+3A_type">type</code></td>
<td>
<p>the type of residuals which should be returned; the
alternatives are: <code>"deviance"</code> (default) and <code>"pearson"</code>.</p>
</td></tr>
<tr><td><code id="residuals.blim_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.
None are used in this method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="stats.html#topic+residuals.glm">residuals.glm</a></code> for details.
</p>


<h3>Value</h3>

<p>A named vector of residuals having as many elements as response patterns.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>, <code><a href="stats.html#topic+residuals.glm">residuals.glm</a></code>,
<code><a href="#topic+plot.blim">plot.blim</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DoignonFalmagne7)
blim1 &lt;- blim(DoignonFalmagne7$K, DoignonFalmagne7$N.R)

sum( resid(blim1)^2 )                # likelihood ratio G2
sum( resid(blim1, "pearson")^2 )     # Pearson X2
</code></pre>

<hr>
<h2 id='schoolarithm'>Arithmetic Problems for Elementary and Middle School Students</h2><span id='topic+schoolarithm'></span><span id='topic+fraction17'></span><span id='topic+subtraction13'></span>

<h3>Description</h3>

<p>The 23 fraction problems were presented to 191 first-level middle school
students (about 11 to 12 years old).  A subset of 13 problems is included in
Stefanutti and de Chiusole (2017).
</p>
<p>The eight subtraction problems were presented to 294 elementary school
students and are described in de Chiusole and Stefanutti (2013).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(schoolarithm)</code></pre>


<h3>Format</h3>


<dl>
<dt><code>fraction17</code></dt><dd><p>a person-by-problem indicator matrix representing
the responses of 191 persons to 23 problems.  The responses are
classified as correct (0) or incorrect (1).</p>
</dd>
</dl>

<p>The 23 problems were:
</p>

<ul>
<li><p><code>p01</code> <code class="reqn">%
      \big(\frac{1}{3} + \frac{1}{12}\big) : \frac{2}{9} = ?</code>
</p>
</li>
<li><p><code>p02</code> <code class="reqn">%
      \big(\frac{3}{2} + \frac{3}{4}\big) \times \frac{5}{3} - 2 = ?</code>
</p>
</li>
<li><p><code>p03</code> <code class="reqn">%
      \big(\frac{5}{6} + \frac{3}{14}\big) \times
           \big(\frac{19}{8} - \frac{3}{2}\big) = ?</code>
</p>
</li>
<li><p><code>p04</code> <code class="reqn">%
      \big(\frac{1}{6} + \frac{2}{9}\big) - \frac{7}{36} = ?</code>
</p>
</li>
<li><p><code>p05</code> <code class="reqn">%
      \frac{7}{10} + \frac{9}{10} = ?</code>
</p>
</li>
<li><p><code>p06</code> <code class="reqn">%
      \frac{8}{13} + \frac{5}{2} = ?</code>
</p>
</li>
<li><p><code>p07</code> <code class="reqn">%
      \frac{8}{12} + \frac{4}{15} = ?</code>
</p>
</li>
<li><p><code>p08</code> <code class="reqn">%
      \frac{2}{9} + \frac{5}{6} = ?</code>
</p>
</li>
<li><p><code>p09</code> <code class="reqn">%
      \frac{7}{5} + \frac{1}{5} = ?</code>
</p>
</li>
<li><p><code>p10</code> <code class="reqn">%
      \frac{2}{7} + \frac{3}{14} = ?</code>
</p>
</li>
<li><p><code>p11</code> <code class="reqn">%
      \frac{5}{9} + \frac{1}{6} = ?</code>
</p>
</li>
<li><p><code>p12</code> <code class="reqn">%
      \big(\frac{1}{12} + \frac{1}{3}\big) \times \frac{24}{15} = ?</code>
</p>
</li>
<li><p><code>p13</code> <code class="reqn">%
      2 - \frac{3}{4} = ?</code>
</p>
</li>
<li><p><code>p14</code> <code class="reqn">%
      \big(4 + \frac{3}{4} - \frac{1}{2}\big) \times \frac{8}{6} = ?</code>
</p>
</li>
<li><p><code>p15</code> <code class="reqn">%
      \frac{4}{7} + \frac{3}{4} = \frac{?}{28}</code>
</p>
</li>
<li><p><code>p16</code> <code class="reqn">%
      \frac{5}{8} - \frac{3}{16} = \frac{? - ?}{16}</code>
</p>
</li>
<li><p><code>p17</code> <code class="reqn">%
      \frac{3}{8} + \frac{5}{12} = \frac{? \times 3 + ? \times 5}{24}</code>
</p>
</li>
<li><p><code>p18</code> <code class="reqn">%
      \frac{2}{7} + \frac{3}{5} = \frac{5 \times ? + 7 \times ?}{35}</code>
</p>
</li>
<li><p><code>p19</code> <code class="reqn">%
      \frac{2}{3} + \frac{6}{9} = \frac{?}{9} = \frac{?}{?}</code>
</p>
</li>
<li><p><code>p20</code> Least common multiple <code class="reqn">lcm(6, 8) = ?</code>
</p>
</li>
<li><p><code>p21</code> <code class="reqn">%
      \frac{7}{11} \times \frac{2}{3} = ?</code>
</p>
</li>
<li><p><code>p22</code> <code class="reqn">%
      \frac{2}{5} \times \frac{15}{4} = ?</code>
</p>
</li>
<li><p><code>p23</code> <code class="reqn">%
      \frac{9}{7} : \frac{2}{3} = ?</code>
</p>
</li></ul>

<p><code>subtraction13</code> is a data frame consisting of the following components:
</p>

<dl>
<dt><code>School</code></dt><dd><p>factor; school id.</p>
</dd>
<dt><code>Classroom</code></dt><dd><p>factor; class room id.</p>
</dd>
<dt><code>Gender</code></dt><dd><p>factor; participant gender.</p>
</dd>
<dt><code>Age</code></dt><dd><p>participant age.</p>
</dd>
<dt><code>R</code></dt><dd><p>a person-by-problem indicator matrix representing the
responses of 294 persons to eight problems.</p>
</dd>
</dl>

<p>The eight problems were:
</p>

<ul>
<li><p><code>p1</code> <code class="reqn">73 - 58</code>
</p>
</li>
<li><p><code>p2</code> <code class="reqn">317 - 94</code>
</p>
</li>
<li><p><code>p3</code> <code class="reqn">784 - 693</code>
</p>
</li>
<li><p><code>p4</code> <code class="reqn">507 - 49</code>
</p>
</li>
<li><p><code>p5</code> <code class="reqn">253 - 178</code>
</p>
</li>
<li><p><code>p6</code> <code class="reqn">2245 - 418</code>
</p>
</li>
<li><p><code>p7</code> <code class="reqn">156 - 68</code>
</p>
</li>
<li><p><code>p8</code> <code class="reqn">3642 - 753</code>
</p>
</li></ul>



<h3>Source</h3>

<p>The data were made available by Debora de Chiusole, Andrea Brancaccio, and
Luca Stefanutti.
</p>


<h3>References</h3>

<p>de Chiusole, D., &amp; Stefanutti, L. (2013).
Modeling skill dependence in probabilistic competence structures.
<em>Electronic Notes in Discrete Mathematics</em>,
<b>42</b>, 41&ndash;48.
<a href="https://doi.org/10.1016/j.endm.2013.05.144">doi:10.1016/j.endm.2013.05.144</a>
</p>
<p>Stefanutti, L., &amp; de Chiusole, D. (2017).
On the assessment of learning in competence based knowledge space theory.
<em>Journal of Mathematical Psychology</em>,
<b>80</b>, 22&ndash;32.
<a href="https://doi.org/10.1016/j.jmp.2017.08.003">doi:10.1016/j.jmp.2017.08.003</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(schoolarithm)

## Fraction problems used in Sefanutti and de Chiusole (2017)
R &lt;- fraction17[, c(4:8, 10:11, 15:20)]
colnames(R) &lt;- 1:13
N.R &lt;- as.pattern(R, freq = TRUE)

## Conjunctive skill function in Table 1
sf &lt;- read.table(header = TRUE, text = "
  item  a  b  c  d  e  f  g  h
     1  1  1  1  0  1  1  0  0
     2  1  0  0  0  0  0  1  1
     3  1  1  0  1  1  0  0  0
     4  1  1  0  0  1  1  1  1
     5  1  1  0  0  1  1  0  0
     6  1  1  1  0  1  0  1  1
     7  1  1  0  0  1  1  0  0
     8  1  1  0  0  1  0  1  1
     9  0  1  0  0  1  0  0  0
    10  0  1  0  0  0  0  0  0
    11  0  0  0  0  1  0  0  0
    12  1  1  0  0  1  0  1  1
    13  0  0  0  0  0  1  0  0
")
K &lt;- delineate(sf)$K  # delineated knowledge structure
blim(K, N.R)

## Subtraction problems used in de Chiusole and Stefanutti (2013)
N.R &lt;- as.pattern(subtraction13$R, freq = TRUE)

# Skill function in Table 1
# (f) mastering tens and hundreds; (g) mastering thousands; (h1) one borrow;
# (h2) two borrows; (h3) three borrows; (i) mastering the proximity of
# borrows; (j) mastering the presence of the zero; (k) mental calculation
sf &lt;- read.table(header = TRUE, text = "
  item  f  g h1 h2 h3  i  j  k
     1  0  0  1  0  0  0  0  0
     2  1  0  1  0  0  0  0  0
     3  1  0  1  0  0  1  0  0
     4  1  0  1  1  1  0  1  0
     4  0  0  0  0  0  0  0  1
     5  1  0  1  1  1  1  0  0
     6  1  1  1  1  0  0  0  0
     7  1  0  1  1  1  1  0  0
     8  1  1  1  1  1  0  0  0
")
K &lt;- delineate(sf)$K
blim(K, N.R)
</code></pre>

<hr>
<h2 id='simulate.blim'>Simulate Responses from Basic Local Independence Models (BLIMs)</h2><span id='topic+simulate.blim'></span>

<h3>Description</h3>

<p>Simulates responses from the distribution corresponding to a fitted
<code>blim</code> model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blim'
simulate(object, nsim = 1, seed = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulate.blim_+3A_object">object</code></td>
<td>
<p>an object of class <code>blim</code>, typically the result of a
call to <code><a href="#topic+blim">blim</a></code>.</p>
</td></tr>
<tr><td><code id="simulate.blim_+3A_nsim">nsim</code></td>
<td>
<p>currently not used.</p>
</td></tr>
<tr><td><code id="simulate.blim_+3A_seed">seed</code></td>
<td>
<p>currently not used.</p>
</td></tr>
<tr><td><code id="simulate.blim_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.
None are used in this method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Responses are simulated in two steps:  First, a knowledge state is drawn
with probability <code>P.K</code>.  Second, responses are generated by applying
<code><a href="stats.html#topic+rbinom">rbinom</a></code> with probabilities computed from the model
object's <code>beta</code> and <code>eta</code> components.
</p>


<h3>Value</h3>

<p>A named vector of frequencies of response patterns.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>, <code><a href="#topic+endm">endm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DoignonFalmagne7)
 
m1 &lt;- blim(DoignonFalmagne7$K, DoignonFalmagne7$N.R)
simulate(m1)

## Parametric bootstrap for the BLIM
disc &lt;- replicate(200, blim(m1$K, simulate(m1))$discrepancy)

hist(disc, col = "lightgray", border = "white", freq = FALSE, breaks = 20,
     main = "BLIM parametric bootstrap", xlim = c(.05, .3))
abline(v = m1$discrepancy, lty = 2)

## Parameter recovery for the SLM
m0 &lt;- list( P.K = getSlmPK( g = rep(.8, 5),
                            K = DoignonFalmagne7$K,
                           Ko = getKFringe(DoignonFalmagne7$K)),
           beta = rep(.1, 5),
            eta = rep(.1, 5),
              K = DoignonFalmagne7$K,
         ntotal = 800)
class(m0) &lt;- c("slm", "blim")

pars &lt;- replicate(20, coef(slm(m0$K, simulate(m0), method = "ML")))
boxplot(t(pars), horizontal = TRUE, las = 1,
        main = "SLM parameter recovery")

## See ?endm for further examples.
</code></pre>

<hr>
<h2 id='slm'>Simple Learning Models (SLMs)</h2><span id='topic+slm'></span><span id='topic+getSlmPK'></span><span id='topic+coef.slm'></span><span id='topic+print.slm'></span>

<h3>Description</h3>

<p>Fits a simple learning model (SLM) for probabilistic knowledge
structures by minimum discrepancy maximum likelihood estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slm(K, N.R, method = c("MD", "ML", "MDML"), R = as.binmat(N.R),
    beta = rep(0.1, nitems), eta = rep(0.1, nitems),
    g = rep(0.1, nitems),
    betafix = rep(NA, nitems), etafix = rep(NA, nitems),
    betaequal = NULL, etaequal = NULL,
    randinit = FALSE, incradius = 0,
    tol = 1e-07, maxiter = 10000, zeropad = 16,
    checkK = TRUE)

getSlmPK(g, K, Ko)

## S3 method for class 'slm'
print(x, P.Kshow = FALSE, parshow = TRUE,
      digits=max(3, getOption("digits") - 2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="slm_+3A_k">K</code></td>
<td>
<p>a state-by-problem indicator matrix representing the knowledge
space.  An element is one if the problem is contained in the state,
and else zero.</p>
</td></tr>
<tr><td><code id="slm_+3A_n.r">N.R</code></td>
<td>
<p>a (named) vector of absolute frequencies of response patterns.</p>
</td></tr>
<tr><td><code id="slm_+3A_method">method</code></td>
<td>
<p><code>MD</code> for minimum discrepancy estimation, <code>ML</code> for
maximum likelihood estimation, <code>MDML</code> for minimum discrepancy
maximum likelihood estimation.</p>
</td></tr>
<tr><td><code id="slm_+3A_r">R</code></td>
<td>
<p>a person-by-problem indicator matrix of unique response patterns.
Per default inferred from the names of <code>N.R</code>.</p>
</td></tr>
<tr><td><code id="slm_+3A_beta">beta</code>, <code id="slm_+3A_eta">eta</code>, <code id="slm_+3A_g">g</code></td>
<td>
<p>vectors of initial values for the error, guessing, and
solvability parameters.</p>
</td></tr>
<tr><td><code id="slm_+3A_betafix">betafix</code>, <code id="slm_+3A_etafix">etafix</code></td>
<td>
<p>vectors of fixed error and guessing parameter values;
<code>NA</code> indicates a free parameter.</p>
</td></tr>
<tr><td><code id="slm_+3A_betaequal">betaequal</code>, <code id="slm_+3A_etaequal">etaequal</code></td>
<td>
<p>lists of vectors of problem indices; each vector
represents an equivalence class: it contains the indices of problems for
which the error or guessing parameters are constrained to be equal.  (See
Examples.)</p>
</td></tr>
<tr><td><code id="slm_+3A_randinit">randinit</code></td>
<td>
<p>logical, if <code>TRUE</code> then initial parameter values are
sampled uniformly with constraints.  (See Details.)</p>
</td></tr>
<tr><td><code id="slm_+3A_incradius">incradius</code></td>
<td>
<p>include knowledge states of distance from the minimum
discrepant states less than or equal to <code>incradius</code>.</p>
</td></tr>
<tr><td><code id="slm_+3A_tol">tol</code></td>
<td>
<p>tolerance, stopping criterion for iteration.</p>
</td></tr>
<tr><td><code id="slm_+3A_maxiter">maxiter</code></td>
<td>
<p>the maximum number of iterations.</p>
</td></tr>
<tr><td><code id="slm_+3A_zeropad">zeropad</code></td>
<td>
<p>the maximum number of items for which an incomplete
<code>N.R</code> vector is completed and padded with zeros.</p>
</td></tr>
<tr><td><code id="slm_+3A_checkk">checkK</code></td>
<td>
<p>logical, if <code>TRUE</code> K is checked for well-gradedness.</p>
</td></tr>
<tr><td><code id="slm_+3A_ko">Ko</code></td>
<td>
<p>a state-by-problem indicator matrix representing the outer fringe
for each knowledge state in <code>K</code>; typically the result of a call to
<code>getKFringe</code>.</p>
</td></tr>
<tr><td><code id="slm_+3A_x">x</code></td>
<td>
<p>an object of class <code>slm</code>, typically the result of a call to
<code>slm</code>.</p>
</td></tr>
<tr><td><code id="slm_+3A_p.kshow">P.Kshow</code></td>
<td>
<p>logical, should the estimated distribution of knowledge
states be printed?</p>
</td></tr>
<tr><td><code id="slm_+3A_parshow">parshow</code></td>
<td>
<p>logical, should the estimates of error, guessing, and
solvability parameters be printed?</p>
</td></tr>
<tr><td><code id="slm_+3A_digits">digits</code></td>
<td>
<p>a non-null value for <code>digits</code> specifies the minimum
number of significant digits to be printed in values.</p>
</td></tr>
<tr><td><code id="slm_+3A_...">...</code></td>
<td>
<p>additional arguments passed to other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Doignon and Falmagne (1999) for details on the simple learning model
(SLM) for probabilistic knowledge structures. The model requires a
well-graded knowledge space <code>K</code>.
</p>
<p>An <code>slm</code> object inherits from class <code>blim</code>.  See <code>blim</code> for
details on the function arguments.  The helper function <code>getSlmPK</code>
returns the distribution of knowledge states <code>P.K</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>slm</code> and <code>blim</code>.  It contains all components
of a <code>blim</code> object.  In addition, it includes:
</p>
<table>
<tr><td><code>g</code></td>
<td>
<p>the vector of estimates of the solvability parameters.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Doignon, J.-P., &amp; Falmagne, J.-C. (1999).
<em>Knowledge spaces</em>. Berlin: Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blim">blim</a></code>, <code><a href="#topic+simulate.blim">simulate.blim</a></code>, <code><a href="#topic+getKFringe">getKFringe</a></code>,
<code><a href="#topic+is.downgradable">is.downgradable</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DoignonFalmagne7)
K   &lt;- DoignonFalmagne7$K     # well-graded knowledge space
N.R &lt;- DoignonFalmagne7$N.R   # frequencies of response patterns

## Fit simple learning model (SLM) by different methods
slm(K, N.R, method = "MD")    # minimum discrepancy estimation
slm(K, N.R, method = "ML")    # maximum likelihood estimation by EM
slm(K, N.R, method = "MDML")  # MDML estimation

## Compare SLM and BLIM
m1 &lt;-  slm(K, N.R, method = "ML")
m2 &lt;- blim(K, N.R, method = "ML")
anova(m1, m2)
</code></pre>

<hr>
<h2 id='Taagepera'>Responses and Knowledge Structures from Taagepera et al. (1997)</h2><span id='topic+Taagepera'></span><span id='topic+density97'></span><span id='topic+matter97'></span>

<h3>Description</h3>

<p>Taagepera et al. (1997) applied knowledge space theory to specific science
problems.  The density test was administered to 2060 students, the
conservation of matter test to 1620 students.  A subtest of five items each
is included here.  The response frequencies were reconstructed from
histograms in the paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Taagepera)</code></pre>


<h3>Format</h3>

<p>Two lists, each consisting of two components:
</p>

<dl>
<dt><code>density97</code></dt><dd><p>a list with components <code>K</code> and <code>N.R</code> for
the density test.</p>
</dd>
<dt><code>matter97</code></dt><dd><p>a list with components <code>K</code> and <code>N.R</code> for
the conservation of matter test.</p>
</dd>
<dt><code>K</code></dt><dd><p>a state-by-problem indicator matrix representing the
hypothetical knowledge structure.  An element is one if the problem
is contained in the state, and else zero.</p>
</dd>
<dt><code>N.R</code></dt><dd><p>a named numeric vector.  The names denote response
patterns, the values denote their frequencies.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Taagepera, M., Potter, F., Miller, G.E., &amp; Lakshminarayan, K. (1997).
Mapping students' thinking patterns by the use of knowledge space theory.
<em>International Journal of Science Education</em>,
<b>19</b>(3), 283&ndash;302.
<a href="https://doi.org/10.1080/0950069970190303">doi:10.1080/0950069970190303</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Taagepera)
density97$K     # density test knowledge structure
density97$N.R   # density test response patterns
matter97$K      # conservation of matter knowledge structure
matter97$N.R    # conservation of matter response patterns
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
