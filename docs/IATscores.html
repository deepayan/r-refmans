<!DOCTYPE html><html><head><title>Help for package IATscores</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {IATscores}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#alg2param'>
<p>Convert the algorithm names to the generating parameters</p></a></li>
<li><a href='#IATdescriptives'>
<p>Summary statistics of reaction time and error</p></a></li>
<li><a href='#IATscores-package'>
<p>Compute Robust IAT scores</p></a></li>
<li><a href='#Pretreatment'>
<p>Pretreat the IAT data in input.</p></a></li>
<li><a href='#RobustScores'>
<p>Compute the Robust IAT scores</p></a></li>
<li><a href='#SplitHalf'>
<p>Split half reliability</p></a></li>
<li><a href='#TestRetest'>
<p>Test-retest reliability</p></a></li>
<li><a href='#Tgraph'>
<p>Layout <code>qgraph</code> for multiple comparisons by package <code>nparcomp</code></p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Implicit Association Test Scores Using Robust Statistics</td>
</tr>
<tr>
<td>Description:</td>
<td>Compute several variations of the Implicit Association Test (IAT) scores, including the D scores (Greenwald, Nosek, Banaji, 2003, &lt;<a href="https://doi.org/10.1037%2F0022-3514.85.2.197">doi:10.1037/0022-3514.85.2.197</a>&gt;) and the new scores that were developed using robust statistics (Richetin, Costantini, Perugini, and Schonbrodt, 2015, &lt;<a href="https://doi.org/10.1371%2Fjournal.pone.0129601">doi:10.1371/journal.pone.0129601</a>&gt;). </td>
</tr>
<tr>
<td>Author:</td>
<td>Giulio Costantini</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Giulio Costantini &lt;costantinigiulio@gmail.com&gt;</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-05-09</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.7</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stringr (&ge; 1.4.0), dplyr (&ge; 0.8.5), reshape2 (&ge; 1.4.4),
qgraph (&ge; 1.6.5), methods (&ge; 3.4.1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>nparcomp (&ge; 2.6)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-05-09 16:59:32 UTC; Giulio</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-05-09 17:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='alg2param'>
Convert the algorithm names to the generating parameters
</h2><span id='topic+alg2param'></span>

<h3>Description</h3>

<p>Starting from the algorithm names, gives the parameters that generated each algorithm as output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>alg2param(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="alg2param_+3A_x">x</code></td>
<td>
<p>The name of an algorithm (string) or the name of many algorithms (vector of strings).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm names in this package follow a precise convention and are in the form <code>"pxxxx"</code>, (where each <code>x</code> stands for a numbers). The first number corresponds to the value of the parameter <code>P1</code> in RobustScores, the second number corresponds to the value of <code>P2</code> and so on. This function allows to know the values of the parameters that generated an algorithm from the algorithm's name. Also a vector of algorithm's names can be given as input.
</p>


<h3>Value</h3>

<p>A dataframe with four columns.
</p>
<table>
<tr><td><code>algorithm</code></td>
<td>
<p>(string). The algorithm's name given as input</p>
</td></tr>
<tr><td><code>P1</code></td>
<td>
<p>(string). Parameter P1, see <code><a href="#topic+RobustScores">RobustScores</a></code></p>
</td></tr>
<tr><td><code>P2</code></td>
<td>
<p>(string). Parameter P2, see <code><a href="#topic+RobustScores">RobustScores</a></code></p>
</td></tr>
<tr><td><code>P3</code></td>
<td>
<p>(string). Parameter P3, see <code><a href="#topic+RobustScores">RobustScores</a></code></p>
</td></tr>
<tr><td><code>P4</code></td>
<td>
<p>(string). Parameter P4, see <code><a href="#topic+RobustScores">RobustScores</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giulio Costantini</p>


<h3>Examples</h3>

<pre><code class='language-R'>alg2param("p1231")
</code></pre>

<hr>
<h2 id='IATdescriptives'>
Summary statistics of reaction time and error
</h2><span id='topic+IATdescriptives'></span>

<h3>Description</h3>

<p>Provides several summary statistics for reaction times and errors, by subject and by block. If by block, only two critical blocks, pair1 and pair2, are considered. See function <code>Pretreatment</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IATdescriptives(IATdata, byblock = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IATdescriptives_+3A_iatdata">IATdata</code></td>
<td>

<p>a dataframe with the following columns:
</p>

<ul>
<li> <p><code>subject</code>: (factor or coercible to factor). Univocally identifies a participant.
</p>
</li>
<li> <p><code>correct</code>: (logical). has value <code>TRUE</code> or <code>1</code> if the trial was answered correctly, <code>FALSE</code> or <code>0</code> otherwise.
</p>
</li>
<li> <p><code>latency</code>: (numeric). Response latency, in ms. 
</p>
</li>
<li> <p><code>blockcode</code>: (factor or string). Can assume only two values, <code>"pair1"</code> and <code>"pair2"</code>. <code>"pair1"</code> is for one critical block and <code>"pair2"</code> is the other critical block.
</p>
</li>
<li> <p><code>praccrit</code>. (factor, optional). Can assume only two values, <code>"prac"</code> is for practice combined categorization block and <code>"crit"</code> is for critical combined categorization block. In a IAT with 60 trials for each double categorization block, the first 20 are sometimes administered as practice block, the other 40 as critical.
</p>
</li></ul>

</td></tr>
<tr><td><code id="IATdescriptives_+3A_byblock">byblock</code></td>
<td>

<p>If <code>TRUE</code>, summary statistics are returned separately for the two critical blocks, pair1 and pair2</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These summary statistics are used sometimes to define exclusion criteria. For example, Greenwald, Nosek, &amp; Banaji's (2003) improved algorithm suggests to eliminate subjects for whom more than 10 percent trials have latency less than 300ms.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Ntrials</code></td>
<td>
<p>number of trials</p>
</td></tr>
<tr><td><code>Nmissing_latency</code></td>
<td>
<p>number of trials in which latency information is missing</p>
</td></tr>
<tr><td><code>Nmissing_accuracy</code></td>
<td>
<p>number of trials in which accuracy information is missing</p>
</td></tr>
<tr><td><code>Prop_error</code></td>
<td>
<p>proportion of error trials</p>
</td></tr>
<tr><td><code>M_latency</code></td>
<td>
<p>mean latency</p>
</td></tr>
<tr><td><code>SD_latency</code></td>
<td>
<p>SD of latency</p>
</td></tr>
<tr><td><code>min_latency</code></td>
<td>
<p>minimum value of latency</p>
</td></tr>
<tr><td><code>max_latency</code></td>
<td>
<p>maximum value of latency</p>
</td></tr>
<tr><td><code>Prop_latency300</code></td>
<td>
<p>proportion of latencies faster than 300 ms</p>
</td></tr>
<tr><td><code>Prop_latency400</code></td>
<td>
<p>proportion of latencies faster than 400 ms</p>
</td></tr>
<tr><td><code>Prop_latency10s</code></td>
<td>
<p>proportion of latencies slower than 10 seconds</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giulio Costantini</p>


<h3>References</h3>

<p>Greenwald, A. G., Nosek, B. A., &amp; Banaji, M. R. (2003). Understanding and using the Implicit Association Test: I. An improved scoring algorithm. Journal of Personality and Social Psychology, 85(2), 197-216. doi:10.1037/0022-3514.85.2.197 <br /> <br />
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Pretreatment">Pretreatment</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### generate random IAT data ####
set.seed(1234)
rawIATdata &lt;- data.frame(
  # ID of each participant (N = 10)
  ID = rep(1:10, each = 180), 
  # seven-block structure, as in Greenwald, Nosek &amp; Banaji (2003)
  # block 1 = target discrimination (e.g., Bush vs. Gore items)
  # block 2 = attribute discrimination (e.g., Pleasant words vs. unpleasant)
  # block 3 = combined practice (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 4 = combined critical  (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 5 = reversed target discrimination (e.g., Gore vs. Bush)
  # block 6 = reversed combined practice (e.g., Gore + pleasant vs. Bush + unpleasant)
  # block 7 = reversed combined critical (e.g., Gore + pleasant vs. Bush + unpleasant)
  block = rep(c(rep(1:3, each = 20),
                rep(4, 40),
                rep(5:6, each = 20),
                rep(7, 40)), 10),
  # expected proportion of errors = 10 percent
  correct = sample(c(0, 1), size = 1800, replace = TRUE, prob = c(.2, .8)),
  # reaction times are generated from a mix of two chi2 distributions,
  # one centered on 550ms and one on 100ms to simulate fast latencies
  latency = round(sample(c(rchisq(1500, df = 1, ncp = 550),
                           rchisq(300, df = 1, ncp = 100)), 1800)))

# add some IAT effect by making trials longer in block 6 and 7
rawIATdata[rawIATdata$block &gt;= 6, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6, "latency"] + 100
  
# add some more effect for subjects 1 to 5
rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] + 100
               
#### pretreat IAT data using function Pretreatment ####
IATdata &lt;- Pretreatment(rawIATdata,
                             label_subject = "ID",
                          label_latency = "latency",
                          label_accuracy = "correct",
                          label_block = "block",
                          block_pair1 = c(3, 4),
                          block_pair2 = c(6, 7),
                          label_praccrit = "block",
                          block_prac = c(3, 6),
                          block_crit = c(4, 7))
IATdescriptives(IATdata)
</code></pre>

<hr>
<h2 id='IATscores-package'>
Compute Robust IAT scores
</h2><span id='topic+IATscores-package'></span><span id='topic+IATscores'></span>

<h3>Description</h3>

<p>The function <code><a href="#topic+RobustScores">RobustScores</a></code> computes variants of the robust IAT
scores according to four main parameters.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> IATscores</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 0.2.3</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2019-07-05</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2 </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>


<hr>
<h2 id='Pretreatment'>
Pretreat the IAT data in input.
</h2><span id='topic+Pretreatment'></span>

<h3>Description</h3>

<p>Convert the initial dataframe of the IAT in a simpler dataframe, which is the input
of subsequent functions in this package.</p>


<h3>Usage</h3>

<pre><code class='language-R'>Pretreatment(IATdata,
  label_subject = "subject",
  label_latency = "latency",
  label_accuracy = "correct",
  label_block = "blockcode",
  block_pair1 = c("pair1_left", "pair1_right"),
  block_pair2 = c("pair2_left", "pair2_right"),
  label_trial = NA,
  trial_left = NA,
  trial_right = NA,
  label_praccrit=NA,
  block_prac=NA,
  block_crit=NA,
  label_stimulus=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Pretreatment_+3A_iatdata">IATdata</code></td>
<td>
<p>The input dataframe. I consider the the output of the IAT implemented in Inquisit (a row by trial). Only 7 columns are important for computation.<br />
- a column with subject numbers<br />
- a column with latencies<br />
- a column with accuracy (1 = correct, 0 = incorrect)<br />
- a column including the block codes, i.e. one or more strings that describe the kind of block (e.g., &quot;compatible&quot; vs. &quot;incompatible&quot;)<br />
- a column including the trial codes, i.e. one or more strings that describe the kind of trial (e.g., &quot;response_left&quot; vs. &quot;response_right&quot;)<br />
- a column including information about which are the practice and which the critical combined categorization blocks.<br />
- a column with the original stimuli (optional)
</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_label_subject">label_subject</code></td>
<td>
<p>String. Name of the column in <code>IATdata</code> with the subject numbers</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_label_latency">label_latency</code></td>
<td>
<p>String. Name of the column in <code>IATdata</code> with the latencies</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_label_accuracy">label_accuracy</code></td>
<td>
<p>String. Name of the column in <code>IATdata</code> with the accuracy</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_label_block">label_block</code></td>
<td>
<p>String. Name of the column in <code>IATdata</code> with the block names</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_block_pair1">block_pair1</code></td>
<td>
<p>Vector of strings. Elements of the column indicated in <code>label_block</code> that correspond the one of the critical blocks of the IAT</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_block_pair2">block_pair2</code></td>
<td>
<p>Vector of strings. Elements of the column indicated in <code>label_block</code> that correspond the the other critical block of the IAT (with respect to the one indicated by <code>block_pair1</code>)</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_label_trial">label_trial</code></td>
<td>
<p>String (optional). Name of the column in <code>IATdata</code> with the trial names</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_trial_left">trial_left</code></td>
<td>
<p>Vector of strings(optional). Elements of the column indicated in <code>label_trial</code> that correspond to trials that required to to press the left button to give the correct response.</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_trial_right">trial_right</code></td>
<td>
<p>Vector of strings(optional). Elements of the column indicated in <code>label_trial</code> that correspond to trials that required to to press the right button to give the correct response.</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_label_praccrit">label_praccrit</code></td>
<td>
<p>String (optional). The column in which the information about practice and critical trials is stored.</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_block_prac">block_prac</code></td>
<td>
<p>Vector of strings (optional). The elements of the column indicated in <code>label_praccrit</code> that correspond to the practice combined blocks</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_block_crit">block_crit</code></td>
<td>
<p>Vector of strings (optional). The elements of the column indicated in <code>label_praccrit</code> that correspond to the critical combined blocks</p>
</td></tr>
<tr><td><code id="Pretreatment_+3A_label_stimulus">label_stimulus</code></td>
<td>
<p>(optional) The variable name in <code>IATdata</code> that keeps information about the stimulus presented in each trial</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a dataframe with the following columns:
</p>
<table>
<tr><td><code>subject</code></td>
<td>
<p>Univocally identifies a participant.</p>
</td></tr>
<tr><td><code>correct</code></td>
<td>
<p>(logical). has value TRUE or 1 if the trial was answered correctly, FALSE or 0 otherwise.</p>
</td></tr>
<tr><td><code>latency</code></td>
<td>
<p>(numeric). Response latency.</p>
</td></tr>
<tr><td><code>blockcode</code></td>
<td>
<p>(factor). Can assume only two values, <code>"pair1"</code> and <code>"pair2"</code>. <code>"pair1"</code> is for one critical block and <code>"pair2"</code> is the other critical block.</p>
</td></tr>
<tr><td><code>praccrit</code></td>
<td>
<p>(factor, optional). Can assume only two values, <code>"prac"</code> is for practice combined categorization block and <code>"crit"</code> is for critical combined categorization block. In a IAT with 60 trials for each double categorization block, the first 20 are sometimes administered as practice block, the other 40 as critical.</p>
</td></tr>
<tr><td><code>trialcode</code></td>
<td>
<p>(factor, optional). Code for the trial, has value <code>"left"</code> if the correct response required to press the left button, <code>"right"</code> if it required to press the right button.</p>
</td></tr>
<tr><td><code>stimulus</code></td>
<td>
<p>(character, optional). The stimulus item.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giulio Costantini
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### generate random IAT data ####
set.seed(1234)
rawIATdata &lt;- data.frame(
  # ID of each participant (N = 10)
  ID = rep(1:10, each = 180), 
  # seven-block structure, as in Greenwald, Nosek &amp; Banaji (2003)
  # block 1 = target discrimination (e.g., Bush vs. Gore items)
  # block 2 = attribute discrimination (e.g., Pleasant words vs. unpleasant)
  # block 3 = combined practice (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 4 = combined critical  (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 5 = reversed target discrimination (e.g., Gore vs. Bush)
  # block 6 = reversed combined practice (e.g., Gore + pleasant vs. Bush + unpleasant)
  # block 7 = reversed combined critical (e.g., Gore + pleasant vs. Bush + unpleasant)
  block = rep(c(rep(1:3, each = 20),
                rep(4, 40),
                rep(5:6, each = 20),
                rep(7, 40)), 10),
# expected proportion of errors = 10 percent
  correct = sample(c(0, 1), size = 1800, replace = TRUE, prob = c(.2, .8)),
  # reaction times are generated from a mix of two chi2 distributions,
  # one centered on 550ms and one on 100ms to simulate fast latencies
  latency = round(sample(c(rchisq(1500, df = 1, ncp = 550),
                           rchisq(300, df = 1, ncp = 100)), 1800)))

# add some IAT effect by making trials longer in block 6 and 7
rawIATdata[rawIATdata$block &gt;= 6, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6, "latency"] + 100
  
# add some more effect for subjects 1 to 5
rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] + 100
               
head(rawIATdata)
               
#### pretreat IAT data using function Pretreatment ####
IATdata &lt;- Pretreatment(rawIATdata,
                             label_subject = "ID",
                          label_latency = "latency",
                          label_accuracy = "correct",
                          label_block = "block",
                          block_pair1 = c(3, 4),
                          block_pair2 = c(6, 7),
                          label_praccrit = "block",
                          block_prac = c(3, 6),
                          block_crit = c(4, 7))
# data are now in the correct format
head(IATdata)
</code></pre>

<hr>
<h2 id='RobustScores'>
Compute the Robust IAT scores
</h2><span id='topic+RobustScores'></span><span id='topic+D2'></span><span id='topic+D5'></span><span id='topic+D6'></span><span id='topic+D2SWND'></span><span id='topic+D5SWND'></span><span id='topic+D6SWND'></span>

<h3>Description</h3>

<p>This is the main function of the package. It allows to compute many variants of the robust IAT scores all with a single command.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RobustScores(IATdata,
P1 = c("none", "fxtrim", "fxwins", "trim10", "wins10", "inve10"),
P2 = c("ignore", "exclude", "recode", "separate", "recode600"),
P3 = c("dscore", "gscore", "wpr90", "minid", "minid_t10", "minid_w10",
"minid_i10"),
P4 = c("nodist", "dist"), maxMemory = 1000,
verbose = TRUE,
autoremove = TRUE)

D2(IATdata, ...)
D5(IATdata, ...)
D6(IATdata, ...)
D2SWND(IATdata, ...)
D5SWND(IATdata, ...)
D6SWND(IATdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RobustScores_+3A_iatdata">IATdata</code></td>
<td>

<p>a dataframe with the following columns:
</p>

<ul>
<li> <p><code>subject</code>: (factor or coercible to factor). Univocally identifies a participant.
</p>
</li>
<li> <p><code>correct</code>: (logical). has value <code>TRUE</code> or <code>1</code> if the trial was answered correctly, <code>FALSE</code> or <code>0</code> otherwise.
</p>
</li>
<li> <p><code>latency</code>: (numeric). Response latency, in ms. 
</p>
</li>
<li> <p><code>blockcode</code>: (factor or string). Can assume only two values, <code>"pair1"</code> and <code>"pair2"</code>. <code>"pair1"</code> is for one critical block and <code>"pair2"</code> is the other critical block.
</p>
</li>
<li> <p><code>praccrit</code>. (factor, optional). Can assume only two values, <code>"prac"</code> is for practice combined categorization block and <code>"crit"</code> is for critical combined categorization block. In a IAT with 60 trials for each double categorization block, the first 20 are sometimes administered as practice block, the other 40 as critical.
</p>
</li></ul>

</td></tr>
<tr><td><code id="RobustScores_+3A_p1">P1</code></td>
<td>
<p>(Vector of strings). Determines how the latencies are treated for computing the scores. Can include one or more of the following strings. It is worth noticing that latencies &gt; 10s are excluded by default, independent of P1.
</p>

<ol>
<li> <p><code>"none"</code>: Do nothing.
</p>
</li>
<li> <p><code>"fxtrim"</code>: Trim values &lt; 400ms
</p>
</li>
<li><p>&quot;fxwins&quot;: Values &lt; 300ms assume the value 300ms and values &gt; 3000ms assume the value 3000ms
</p>
</li>
<li> <p><code>"trim10"</code>: 10% trimming
</p>
</li>
<li> <p><code>"wins10"</code>: 10% winsorizing
</p>
</li>
<li> <p><code>"inve10"</code>: 10% inverse trimming (i.e., trim central values)
</p>
</li></ol>

</td></tr>
<tr><td><code id="RobustScores_+3A_p2">P2</code></td>
<td>
<p>(Vector of strings). Determines how the error latencies are treated. Can include one or more of the following strings.
</p>

<ol>
<li> <p><code>"ignore"</code>: Disregard the correct-error distinction, treat all the latencies as if they were correct latencies.
</p>
</li>
<li> <p><code>"exclude"</code>: Remove error latencies and consider only the correct ones.
</p>
</li>
<li> <p><code>"recode"</code>: Recode the error latencies with the M+2SD of correct latencies. In the computation of the M and of the SD, all correct latencies are considered that are &lt; 10s.
</p>
</li>
<li> <p><code>"separate"</code>: Apply parameter P1 separately for correct and error latencies. Notice that for parameter 1 equal to &quot;none&quot;, &quot;fxtrim&quot;, and &quot;fxwins&quot;, if P4 = &quot;ignore&quot; and P4 = &quot;separate&quot;, the result is the same.)
</p>
</li>
<li> <p><code>"recode600"</code>: Recode the error latencies with the the mean of correct latencies + 600ms. In the computation of the Mean, all correct latencies are considered that are &lt; 10s.
</p>
</li></ol>

</td></tr>
<tr><td><code id="RobustScores_+3A_p3">P3</code></td>
<td>
<p>The algorithm for computing the Dscores. Can include one or more of the following strings.
</p>

<ol>
<li> <p><code>"dscore"</code>. Compute the Dscores as M pair2 - Mpair1 / pooled SD.
</p>
</li>
<li> <p><code>"gscore"</code>. Compute the Gscores, as shown in Nosek, Bar-Anan, Sriram, &amp; Greenwald (2013).
</p>
</li>
<li> <p><code>"wpr90"</code>. Compute the scores based on the worst-performance-rule, which are the same as the Dscores, but instead of the mean, the 90th percentile is used in the numerator.
</p>
</li>
<li> <p><code>minid</code>. Compute the minidifferences, i.e., the differences between any latency in pair2 and any latency in pair1. Then compute the IAT scores as the Mean of the minidifferences, divided by their SD.
</p>
</li>
<li> <p><code>minid_t10</code>. Compute the 10% trimmed minidifferences, which are identical to the minidiffernces, but instead of the mean, the 10% trimmed mean is used.
</p>
</li>
<li> <p><code>"minid_w10"</code> Compute the 10% winsorized minidifferences, which are as the minidifferences, but instead of the mean, the 10% winsorized mean is used.
</p>
</li>
<li> <p><code>"minid_i10"</code> Compute the 10% inverse_trimmed minidifferences, which are as the minidifferences, but instead of the mean, the 10% inverse trimmed mean is used.
</p>
</li></ol>

</td></tr>
<tr><td><code id="RobustScores_+3A_p4">P4</code></td>
<td>
<p>Distinguish the practice and the critical blocks, as specified by column <code>praccrit</code> in the <code>IATdata</code>, or do not.
</p>

<ol>
<li> <p><code>"nodist"</code> no distinction between practice and critical blocks. no distinction is made between practice and critical blocks and the IAT scores are computed using all trials together.
</p>
</li>
<li> <p><code>"dist"</code> compute the IAT scores as the average IAT score computed. the scores are computed on practice and critical blocks separately: the total score is then computedc as the average of the two IAT scores.
</p>
</li></ol>

</td></tr>
<tr><td><code id="RobustScores_+3A_maxmemory">maxMemory</code></td>
<td>

<p>In computing the minidifferences, a very large dataframe is required. <code>maxMemory</code> specifies the maximum size of this dataframe, in MB. This limit is respected by &quot;slicing&quot; the dataset and computing the scores separately for many subsets of participants. This can slow the computation a bit, but prevents RAM overflows.
</p>
</td></tr>
<tr><td><code id="RobustScores_+3A_verbose">verbose</code></td>
<td>
<p>if <code>TRUE</code>, Print the time at which several operations are performed.
</p>
</td></tr>
<tr><td><code id="RobustScores_+3A_autoremove">autoremove</code></td>
<td>
<p>if <code>TRUE</code> (the default), participants with less than 3 correct responses with latency between 400ms and 10s in each block are excluded from the analyses. Disabling this option can result in computing some variants of IAT scores on too few trials and it can lead to errors and missing values. Change this parameter to <code>FALSE</code> only if you know what you are doing.
</p>
</td></tr>
<tr><td><code id="RobustScores_+3A_...">...</code></td>
<td>
<p>Additional arguments for <code>RobustScores</code>.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A precise description of the parameters can be found in Richetin et al. (2015, Table 1).
The procedure for computing the scores is the following.
</p>

<ol>
<li><p> First parameter P4 is applied: for <code>"nodist"</code> the whole dataset is given as input, for <code>"dist"</code> the dataset is first split in two parts according to column <code>praccrit</code> and then given in input.
</p>
</li>
<li><p> Second, the parameter P1 and P2 are applied: correct and error latencies are treated for each combinations of P1 and P2 and a new column is internally created.
</p>
</li>
<li><p> Third, parameter P3 is applied. On each and every vector of latencies defined by a combination of P1 and P2, the IAT scores are computed using all the methods specified in P3.
</p>
</li>
<li><p> Finally, for P4 = <code>"dist"</code>, the scores computed i the practice and critical blocks are averaged.
</p>
</li></ol>

<p>Functions <code>D2</code>, <code>D5</code>, and <code>D6</code> are simple wrappers around RobustScores that allow computing the D2, D5, and D6 scores shown in Greenwald et al. (2003).
Similarly, <code>D2SWND</code>, <code>D5SWND</code>, and <code>D6SWND</code> allow computing the same D2, D5, and D6 scores with the improvements proposed by Richetin et al. (2015): use of statistical winsorizing (SW) and no distinction (ND) between practice and critical blocks.
</p>


<h3>Value</h3>

<p>A dataframe with as many columns as subjects, and as many rows as the possible combinations of the parameters P1, P2, P3 and P4.
</p>
<table>
<tr><td><code>subject</code></td>
<td>
<p>The identifier of the participant</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code>p1342</code></td>
<td>
<p>The IAT score variants computed. Each number after the p indicates the value of the parameter corresponding to the position. For instance <code>p1342</code> indicates that parameter P1 has value 1 (i.e. <code>"none"</code>), parameter P2 has value 3, i.e., <code>recode</code>, parameter P3 has value 4 (i.e., <code>"minid"</code>) and parameter P4 has value 2 (i.e. <code>"dist"</code>). This naming convention was adopted to allow to immediately and precisely know what has been done by reading the name of the score.</p>
</td></tr>
<tr><td><code>...</code></td>
<td>
<p>other columns in the form <code>pxxxx</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giulio Costantini
</p>


<h3>References</h3>

<p>Greenwald, A. G., Nosek, B. A., &amp; Banaji, M. R. (2003). Understanding and using the Implicit Association Test: I. An improved scoring algorithm. Journal of Personality and Social Psychology, 85(2), 197-216. doi:10.1037/0022-3514.85.2.197 <br /> <br />
Nosek, B. A., Bar-Anan, Y., Sriram, N., &amp; Greenwald, A. G. (2013). Understanding and Using the Brief Implicit Association Test: I. Recommended Scoring Procedures. SSRN Electronic Journal. doi:10.2139/ssrn.2196002 <br /> <br />
Richetin, J., Costantini, G., Perugini, M., Schonbrodt, F. (in press). Should we stop looking for a better scoring algorithm for handling Implicit Association Test data? Test of the role of errors, extreme latencies treatment, scoring formula, and practice trials on reliability and validity. PLoS ONE.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SplitHalf">SplitHalf</a></code>, <code><a href="#topic+alg2param">alg2param</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### generate random IAT data ####
set.seed(1234)
rawIATdata &lt;- data.frame(
  # ID of each participant (N = 10)
  ID = rep(1:10, each = 180), 
  # seven-block structure, as in Greenwald, Nosek &amp; Banaji (2003)
  # block 1 = target discrimination (e.g., Bush vs. Gore items)
  # block 2 = attribute discrimination (e.g., Pleasant words vs. unpleasant)
  # block 3 = combined practice (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 4 = combined critical  (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 5 = reversed target discrimination (e.g., Gore vs. Bush)
  # block 6 = reversed combined practice (e.g., Gore + pleasant vs. Bush + unpleasant)
  # block 7 = reversed combined critical (e.g., Gore + pleasant vs. Bush + unpleasant)
  block = rep(c(rep(1:3, each = 20),
                rep(4, 40),
                rep(5:6, each = 20),
                rep(7, 40)), 10),
  # expected proportion of errors = 10 percent
  correct = sample(c(0, 1), size = 1800, replace = TRUE, prob = c(.2, .8)),
  # reaction times are generated from a mix of two chi2 distributions,
  # one centered on 550ms and one on 100ms to simulate fast latencies
  latency = round(sample(c(rchisq(1500, df = 1, ncp = 550),
                           rchisq(300, df = 1, ncp = 100)), 1800)))

# add some IAT effect by making trials longer in block 6 and 7
rawIATdata[rawIATdata$block &gt;= 6, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6, "latency"] + 100
  
# add some more effect for subjects 1 to 5
rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] + 100
               
#### pretreat IAT data using function Pretreatment ####
IATdata &lt;- Pretreatment(rawIATdata,
                             label_subject = "ID",
                          label_latency = "latency",
                          label_accuracy = "correct",
                          label_block = "block",
                          block_pair1 = c(3, 4),
                          block_pair2 = c(6, 7),
                          label_praccrit = "block",
                          block_prac = c(3, 6),
                          block_crit = c(4, 7))


#### Compute Greenwald et al.'s (2003, Table 3) D2, D5, and D6 measures ####
# All scores are computed both with the RobustScores and with
# the wrappers D2, D5, and D6. Results are identical

# D2 scores
D2(IATdata, verbose = FALSE)
RobustScores(IATdata = IATdata,
             P1 = "fxtrim",
             P2 = "ignore",
             P3 = "dscore",
             P4 = "dist",
             verbose = FALSE)

# D5 scores
D5(IATdata, verbose = FALSE)
RobustScores(IATdata = IATdata,
             P1 = "fxtrim",
             P2 = "recode",
             P3 = "dscore",
             P4 = "dist",
             verbose = FALSE)

# D6 scores
D6(IATdata, verbose = FALSE)
RobustScores(IATdata = IATdata,
             P1 = "fxtrim",
             P2 = "recode600",
             P3 = "dscore",
             P4 = "dist",
             verbose = FALSE)

#### Compute D scores with improvements by Richetin et al. (2015, p. 20) ####
# "In this perspective, we examined whether the D2 for built-in penalty and the
# D5 and D6 for no built-in penalty could benefit from the inclusion of two
# elements that stand out from the results. Within their respective parameter,
# the Statistical Winsorizing as a treatment for extreme latencies and No 
# distinction between practice and test trials when computing the difference
# between the two critical blocks seem to lead to the best performances". 

# All scores are computed both with the RobustScores and with
# the wrappers D2SWND, D5SWND, and D6SWND. Results are identical


# D2SWND scores
D2SWND(IATdata, verbose = FALSE)
RobustScores(IATdata = IATdata,
             P1 = "wins10",
             P2 = "ignore",
             P3 = "dscore",
             P4 = "nodist",
             verbose = FALSE)

# D5_SWND scores
D5SWND(IATdata, verbose = FALSE)
RobustScores(IATdata = IATdata,
             P1 = "wins10",
             P2 = "recode",
             P3 = "dscore",
             P4 = "nodist",
             verbose = FALSE)

# D6_SWND scores
D6SWND(IATdata, verbose = FALSE)
RobustScores(IATdata = IATdata,
             P1 = "wins10",
             P2 = "recode600",
             P3 = "dscore",
             P4 = "nodist",
             verbose = FALSE)



  #### Compute all 421 combinations of IAT scores ####
  # 421 are the combinations given by parameters P1, P2, P3, and P4. For
  # details, see Richetin et al. (2015)
  allIATscores &lt;- RobustScores(IATdata = IATdata)

</code></pre>

<hr>
<h2 id='SplitHalf'>
Split half reliability</h2><span id='topic+SplitHalf'></span><span id='topic+SplitHalf.D2'></span><span id='topic+SplitHalf.D5'></span><span id='topic+SplitHalf.D6'></span><span id='topic+SplitHalf.D2SWND'></span><span id='topic+SplitHalf.D5SWND'></span><span id='topic+SplitHalf.D6SWND'></span>

<h3>Description</h3>

<p>Compute split half reliability for the algorithms defined by all the
combinations of parameters P1, P2, P3, and P4.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SplitHalf(IATdata, ...)
SplitHalf.D2(IATdata, ...)
SplitHalf.D5(IATdata, ...)
SplitHalf.D6(IATdata, ...)
SplitHalf.D2SWND(IATdata, ...)
SplitHalf.D5SWND(IATdata, ...)
SplitHalf.D6SWND(IATdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SplitHalf_+3A_iatdata">IATdata</code></td>
<td>

<p>same as <code><a href="#topic+RobustScores">RobustScores</a></code></p>
</td></tr>
<tr><td><code id="SplitHalf_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to RobustScores</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The split-half reliability is computed by splitting the dataframe IATdata in
two halves and then calling function <code><a href="#topic+RobustScores">RobustScores</a></code>
Functions SplitHalf.D2 etc. are wrappers that allow computing reliability for some common types of scores. See <code><a href="#topic+RobustScores">RobustScores</a></code>.
</p>


<h3>Value</h3>

<p>A vector of split-half reliabilities.
</p>


<h3>Author(s)</h3>

<p>Giulio Costantini
</p>


<h3>See Also</h3>

<p><code><a href="#topic+RobustScores">RobustScores</a></code>, <code><a href="#topic+alg2param">alg2param</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### generate random IAT data ####
set.seed(1234)
rawIATdata &lt;- data.frame(
  # ID of each participant (N = 10)
  ID = rep(1:10, each = 180), 
  # seven-block structure, as in Greenwald, Nosek &amp; Banaji (2003)
  # block 1 = target discrimination (e.g., Bush vs. Gore items)
  # block 2 = attribute discrimination (e.g., Pleasant words vs. unpleasant)
  # block 3 = combined practice (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 4 = combined critical  (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 5 = reversed target discrimination (e.g., Gore vs. Bush)
  # block 6 = reversed combined practice (e.g., Gore + pleasant vs. Bush + unpleasant)
  # block 7 = reversed combined critical (e.g., Gore + pleasant vs. Bush + unpleasant)
  block = rep(c(rep(1:3, each = 20),
                rep(4, 40),
                rep(5:6, each = 20),
                rep(7, 40)), 10),
 # expected proportion of errors = 10 percent
  correct = sample(c(0, 1), size = 1800, replace = TRUE, prob = c(.2, .8)),
  # reaction times are generated from a mix of two chi2 distributions,
  # one centered on 550ms and one on 100ms to simulate fast latencies
  latency = round(sample(c(rchisq(1500, df = 1, ncp = 550),
                           rchisq(300, df = 1, ncp = 100)), 1800)))

# add some IAT effect by making trials longer in block 6 and 7
rawIATdata[rawIATdata$block &gt;= 6, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6, "latency"] + 100
  
# add some more effect for subjects 1 to 5
rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] + 100
  

#### pretreat IAT data using function Pretreatment ####
IATdata &lt;- Pretreatment(rawIATdata,
                             label_subject = "ID",
                          label_latency = "latency",
                          label_accuracy = "correct",
                          label_block = "block",
                          block_pair1 = c(3, 4),
                          block_pair2 = c(6, 7),
                          label_praccrit = "block",
                          block_prac = c(3, 6),
                          block_crit = c(4, 7))


#### Compute reliability for Greenwald et al.'s (2003) D2, D5, and D6 ####
# All scores are computed both with the SplitHalf and with
# the wrappers SplitHalf.D2, SplitHalf.D5, and SplitHalf.D6.


# D2 scores
SplitHalf.D2(IATdata, verbose = FALSE)
SplitHalf(IATdata = IATdata,
             P1 = "fxtrim",
             P2 = "ignore",
             P3 = "dscore",
             P4 = "dist",
             verbose = FALSE)

# D5 scores
SplitHalf.D5(IATdata,
             verbose = FALSE)
SplitHalf(IATdata = IATdata,
             P1 = "fxtrim",
             P2 = "recode",
             P3 = "dscore",
             P4 = "dist",
             verbose = FALSE)

# D6 scores
SplitHalf.D6(IATdata, verbose = FALSE)
SplitHalf(IATdata = IATdata,
             P1 = "fxtrim",
             P2 = "recode600",
             P3 = "dscore",
             P4 = "dist",
             verbose = FALSE)

#### Compute reliability for improved scores by Richetin et al. (2015, p. 20) ####
# All scores are computed both with the SplitHalf and with
# the wrappers SplitHalf.D2SWND, SplitHalf.D5SWND, and SplitHalf.D6SWND.
# Results are identical

# D2SWND scores
SplitHalf.D2SWND(IATdata, verbose = FALSE)
SplitHalf(IATdata = IATdata,
             P1 = "wins10",
             P2 = "ignore",
             P3 = "dscore",
             P4 = "nodist",
             verbose = FALSE)

# D5_SWND scores
SplitHalf.D5SWND(IATdata, verbose = FALSE)
SplitHalf(IATdata = IATdata,
             P1 = "wins10",
             P2 = "recode",
             P3 = "dscore",
             P4 = "nodist",
             verbose = FALSE)

# D6_SWND scores
SplitHalf.D6SWND(IATdata, verbose = FALSE)
SplitHalf(IATdata = IATdata,
             P1 = "wins10",
             P2 = "recode600",
             P3 = "dscore",
             P4 = "nodist",
             verbose = FALSE)

</code></pre>

<hr>
<h2 id='TestRetest'>
Test-retest reliability</h2><span id='topic+TestRetest'></span><span id='topic+TestRetest.D2'></span><span id='topic+TestRetest.D5'></span><span id='topic+TestRetest.D6'></span><span id='topic+TestRetest.D2SWND'></span><span id='topic+TestRetest.D5SWND'></span><span id='topic+TestRetest.D6SWND'></span>

<h3>Description</h3>

<p>Compute test-retest reliability for IAT with 2 observations for each subject
</p>


<h3>Usage</h3>

<pre><code class='language-R'>TestRetest(IATdata, ...)
TestRetest.D2(IATdata, ...)
TestRetest.D5(IATdata, ...)
TestRetest.D6(IATdata, ...)
TestRetest.D2SWND(IATdata, ...)
TestRetest.D5SWND(IATdata, ...)
TestRetest.D6SWND(IATdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="TestRetest_+3A_iatdata">IATdata</code></td>
<td>

<p>same as <code><a href="#topic+RobustScores">RobustScores</a></code>, but with the additional column
<code>"session"</code>. <code>session</code> distinguishes the trials of the first session
and those of the second session. It is typically numerical, having value <code>1</code>
for the first session and <code>2</code> for the second.
Functions TestRetest.D2 etc. are wrappers that allow computing reliability for some common types of scores. See <code><a href="#topic+RobustScores">RobustScores</a></code>.
</p>
</td></tr>
<tr><td><code id="TestRetest_+3A_...">...</code></td>
<td>
<p>other parameters to be passed to RobustScores</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It computes the scores for the test and for the retest using RobustScores, 
the output is just the correlation among the scores in the two sessions.
</p>


<h3>Value</h3>

<table>
<tr><td><code>algorithm</code></td>
<td>
<p>The name of the algorithm, see <code><a href="#topic+RobustScores">RobustScores</a></code> for
the convention adopted for naming the algorithms</p>
</td></tr>
<tr><td><code>testretest</code></td>
<td>
<p>The test-retest reliability for each algorithm</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giulio Costantini</p>


<h3>See Also</h3>

<p><code><a href="#topic+RobustScores">RobustScores</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### generate random IAT data ####
set.seed(1234)
rawIATdata &lt;- data.frame(
  # ID of each participant (N = 10)
  ID = rep(1:10, each = 180), 
  # seven-block structure, as in Greenwald, Nosek &amp; Banaji (2003)
  # block 1 = target discrimination (e.g., Bush vs. Gore items)
  # block 2 = attribute discrimination (e.g., Pleasant words vs. unpleasant)
  # block 3 = combined practice (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 4 = combined critical  (e.g., Bush + pleasant vs. Gore + unpleasant)
  # block 5 = reversed target discrimination (e.g., Gore vs. Bush)
  # block 6 = reversed combined practice (e.g., Gore + pleasant vs. Bush + unpleasant)
  # block 7 = reversed combined critical (e.g., Gore + pleasant vs. Bush + unpleasant)
  block = rep(c(rep(1:3, each = 20),
                rep(4, 40),
                rep(5:6, each = 20),
                rep(7, 40)), 10),
 # expected proportion of errors = 10 percent
  correct = sample(c(0, 1), size = 1800, replace = TRUE, prob = c(.2, .8)),
  # reaction times are generated from a mix of two chi2 distributions,
  # one centered on 550ms and one on 100ms to simulate fast latencies
  latency = round(sample(c(rchisq(1500, df = 1, ncp = 550),
                           rchisq(300, df = 1, ncp = 100)), 1800)))

# add some IAT effect by making trials longer in block 6 and 7
rawIATdata[rawIATdata$block &gt;= 6, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6, "latency"] + 100
  
# add some more effect for subjects 1 to 5
rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] &lt;- 
  rawIATdata[rawIATdata$block &gt;= 6 &amp;
             rawIATdata$ID &lt;= 5, "latency"] + 100
  
#### pretreat IAT data using function Pretreatment ####
IATdata &lt;- Pretreatment(rawIATdata,
                             label_subject = "ID",
                          label_latency = "latency",
                          label_accuracy = "correct",
                          label_block = "block",
                          block_pair1 = c(3, 4),
                          block_pair2 = c(6, 7),
                          label_praccrit = "block",
                          block_prac = c(3, 6),
                          block_crit = c(4, 7))
                          
# Add a column representing the session in IATdata                    
IATdata$session &lt;- rep(c(1,2), nrow(IATdata)/2)
                          

#### Compute reliability for Greenwald et al.'s (2003) D2, D5, and D6 ####
# All scores are computed both with the TestRetest and with
# the wrappers TestRetest.D2, TestRetest.D5, and TestRetest.D6.


# D2 scores
TestRetest.D2(IATdata, verbose = FALSE)
TestRetest(IATdata = IATdata,
             P1 = "fxtrim",
             P2 = "ignore",
             P3 = "dscore",
             P4 = "dist",
             verbose = FALSE)

# D5 scores
TestRetest.D5(IATdata,
             verbose = FALSE)
TestRetest(IATdata = IATdata,
             P1 = "fxtrim",
             P2 = "recode",
             P3 = "dscore",
             P4 = "dist",
             verbose = FALSE)

# D6 scores
TestRetest.D6(IATdata, verbose = FALSE)
TestRetest(IATdata = IATdata,
             P1 = "fxtrim",
             P2 = "recode600",
             P3 = "dscore",
             P4 = "dist",
             verbose = FALSE)

#### Compute reliability for improved scores by Richetin et al. (2015, p. 20) ####
# All scores are computed both with the TestRetest and with
# the wrappers TestRetest.D2SWND, TestRetest.D5SWND, and TestRetest.D6SWND.
# Results are identical

# D2SWND scores
TestRetest.D2SWND(IATdata, verbose = FALSE)
TestRetest(IATdata = IATdata,
             P1 = "wins10",
             P2 = "ignore",
             P3 = "dscore",
             P4 = "nodist",
             verbose = FALSE)

# D5_SWND scores
TestRetest.D5SWND(IATdata, verbose = FALSE)
TestRetest(IATdata = IATdata,
             P1 = "wins10",
             P2 = "recode",
             P3 = "dscore",
             P4 = "nodist",
             verbose = FALSE)

# D6_SWND scores
TestRetest.D6SWND(IATdata, verbose = FALSE)
TestRetest(IATdata = IATdata,
             P1 = "wins10",
             P2 = "recode600",
             P3 = "dscore",
             P4 = "nodist",
             verbose = FALSE)

</code></pre>

<hr>
<h2 id='Tgraph'>
Layout <code><a href="ggraph.html#topic+qgraph">qgraph</a></code> for multiple comparisons by package <code>nparcomp</code>
</h2><span id='topic+Tgraph'></span>

<h3>Description</h3>

<p>Implements the T-graph layout proposed by Vasilescu et al. (2014), using the robust nonparametric contrasts proposed by Konietschke et al. (2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Tgraph(mcmp, alpha = 0.05, horizorder = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Tgraph_+3A_mcmp">mcmp</code></td>
<td>

<p>The output of a robust post-hoc, as obtained with function <code>mcmp</code> from package  <code>nparcomp</code></p>
</td></tr>
<tr><td><code id="Tgraph_+3A_alpha">alpha</code></td>
<td>
<p>The alpha level, by convention = .05. Effects with p.values lower than <code>alpha</code> are represented as arrows in the network layout.</p>
</td></tr>
<tr><td><code id="Tgraph_+3A_horizorder">horizorder</code></td>
<td>
<p>Optional, vector of strings. While the vertical order of the variables in the Tgraph is determined by the multiple comparisons, the horizontal ordering is not. If specified, parameter horizorder allows to determine the horizontal order. It must be a vector with the names of the variables in the preferred horizontal order.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A T-graph is a simple graphical representation of a series of pairwise comparison proposed by Vasilescu et al. (2014). The nodes of the graph represent the levels of the factor, the arrows represent their pairwise comparisons. An arrow points from one option to another if the dependent variable is significantly higher for the first level compared to the second level of the factor. The robust contrasts defined by Konietschke et al. (2012) have the transitive property, therefore if an option X outperforms another option Y and Y outperforms Z, this implies that X outperforms Z. For sake of a clear graphical representation we followed Vasilescu et al. and omitted the direct edges when two nodes could be connected using an indirect path travelling through other nodes.</p>


<h3>Value</h3>

<table>
<tr><td><code>wmat</code></td>
<td>
<p>The weights matrix, for each pair of options the weights represent the value of the estimated relative effect, see <code>mcmp</code>. A value is present in <code>wmat</code> only if the associated p.value is less than <code>alpha</code> and it is zero otherwise.</p>
</td></tr>
<tr><td><code>amat</code></td>
<td>
<p>The adjacency matrix, for each pair of options, it has value 1 if an edge is present in <code>wmat</code> and 0 otherwise. This should be given as the main <code>input</code> to <code>link{qgraph}</code></p>
</td></tr>
<tr><td><code>layout</code></td>
<td>
<p>The layout to give in input to qgraph's parameter <code>layout</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Giulio Costantini</p>


<h3>References</h3>

<p>Epskamp, S., Cramer, A. O. J., Waldorp, L. J., Schmittmann, V. D., &amp; Borsboom, D. (2012). qgraph: network visualizations of relationships in psychometric data. Journal of Statistical Software, 48(4).
</p>
<p>Konietschke, F., Hothorn, L. a., &amp; Brunner, E. (2012). Rank-based multiple test procedures and simultaneous confidence intervals. Electronic Journal of Statistics, 6, 738-759. doi:10.1214/12-EJS691
</p>
<p>Vasilescu, B., Serebrenik, A., Goeminne, M., &amp; Mens, T. (2014). On the variation and specialization of workload-A case study of the Gnome ecosystem community. Empirical Software Engineering, 19, 955-1008. doi:10.1007/s10664-013-9244-1
</p>
<p>Richetin, J., Costantini, G., Perugini, M., Schonbrodt, F. (in press). Should we stop looking for a better scoring algorithm for handling Implicit Association Test data? Test of the role of errors, extreme latencies treatment, scoring formula, and practice trials on reliability and validity. PLoS ONE.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(nparcomp)
library(qgraph)

dat &lt;- data.frame(matrix(nrow = 300, ncol = 0))

dat$DV &lt;- c(rnorm(100, 1, 1),
       rnorm(100, 0, 1),
       rnorm(100, 0, 1))

dat$IV &lt;- c(rep("A", 100),
        rep("B", 100),
        rep("D", 100))

mcmp &lt;- mctp(formula = DV~IV, data = dat, type = "Tukey")
tg &lt;- Tgraph(mcmp)
qgraph(tg$amat, layout = tg$layout)

tg2 &lt;- Tgraph(mcmp,  horizorder = c("A", "D", "B"))
qgraph(tg2$amat, layout = tg2$layout)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
