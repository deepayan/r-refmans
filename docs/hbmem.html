<!DOCTYPE html><html><head><title>Help for package hbmem</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hbmem}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dpsdPosSample'><p>Function dpsdPosSample</p></a></li>
<li><a href='#dpsdPosSim'><p>Function dpsdPosSim</p></a></li>
<li><a href='#dpsdSample'><p>Function to fit hierarchical DPSD model to data.</p></a></li>
<li><a href='#dpsdSim'><p>Function dpsdSim</p></a></li>
<li><a href='#gammaLikeSample'><p>Function gammaLikeSample</p></a></li>
<li><a href='#gammaSample'><p>Function gammaSample</p></a></li>
<li><a href='#gammaSim'><p>Function gammaSim</p></a></li>
<li><a href='#hbmem-package'><p>Hierarchical Models of Recognition Memory</p></a></li>
<li><a href='#prm09'><p>PRM09 Data</p></a></li>
<li><a href='#rtgamma'><p>Function rtgamma</p></a></li>
<li><a href='#sampleGamma'><p>Function sampleGamma</p></a></li>
<li><a href='#sd10'><p>Pratte and Rouder Exp. 2</p></a></li>
<li><a href='#sd13'><p>As of yet unpublished dataset</p></a></li>
<li><a href='#sd2'><p>Data from Pratte, Morey and Rouder (2010)</p></a></li>
<li><a href='#sd6'><p>As of yet unpublished dataset</p></a></li>
<li><a href='#uvsdSample'><p>Function uvsdSample</p></a></li>
<li><a href='#uvsdSim'><p>Function uvsdSim</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Hierarchical Bayesian Analysis of Recognition Memory</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3-4</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-08-21</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael S. Pratte</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mike Pratte &lt;prattems@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 1.8.0), methods</td>
</tr>
<tr>
<td>Description:</td>
<td>Contains functions for fitting hierarchical versions of
        EVSD, UVSD, DPSD, DPSD with d' restricted to be positive, and
        our gamma signal detection model to recognition memory
        confidence-ratings data.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-2">LGPL-2</a> | <a href="https://www.r-project.org/Licenses/LGPL-2.1">LGPL-2.1</a> | <a href="https://www.r-project.org/Licenses/LGPL-3">LGPL-3</a> [expanded from: LGPL (&ge; 2.0)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://pcn.psychology.msstate.edu/">https://pcn.psychology.msstate.edu/</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-22 17:34:15 UTC; mike</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-22 18:30:06 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
</table>
<hr>
<h2 id='dpsdPosSample'>Function dpsdPosSample</h2><span id='topic+dpsdPosSample'></span>

<h3>Description</h3>

<p>Function to sample posterior of DPSD model with positive d'</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpsdPosSample(dat, M = 5000, keep = (M/10):M, getDIC = TRUE, jump = 0.01)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpsdPosSample_+3A_dat">dat</code></td>
<td>
<p>Data frame that must include variables
Scond,cond,sub,item,lag,resp.  Scond indexes studied/new, whereas
cond indexes conditions nested within the studied or new
conditions.  Indexes for Scond,cond, sub, item, and respone must
start at zero and have no gaps (i.e., no skipped subject numbers). Lags
must be zero-centered.</p>
</td></tr>
<tr><td><code id="dpsdPosSample_+3A_m">M</code></td>
<td>
<p>Number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="dpsdPosSample_+3A_keep">keep</code></td>
<td>
<p>Which MCMC iterations should be included in estimates and
returned.  Use keep to both get ride of burn-in, and thin chains if
necessary.</p>
</td></tr>
<tr><td><code id="dpsdPosSample_+3A_getdic">getDIC</code></td>
<td>
<p>Logical. Should the function compute DIC value?  This
takes a while if M is large.</p>
</td></tr>
<tr><td><code id="dpsdPosSample_+3A_jump">jump</code></td>
<td>
<p>The criteria and decorrelating steps utilize
Matropolis-Hastings sampling routines, which require tuning.  All
MCMC functions should self-tune during the burnin period (iterations
before keep), and they will alert you to the success of tuning.  If
acceptance rates are too low, &quot;jump&quot; should be decreased, if they
are too hight, &quot;jump&quot; should be increased.  Alternatively, or in
addition to adjusting &quot;jump&quot;, simply increase the burnin period
which will allow the function more time to self-tune.</p>
</td></tr>
</table>

<hr>
<h2 id='dpsdPosSim'>Function dpsdPosSim</h2><span id='topic+dpsdPosSim'></span>

<h3>Description</h3>

<p>Function to simulate data from DPSD model with positive d'</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpsdPosSim(NN = 1, NS = 2, I = 30, J = 200, K = 6, muN = -0.7,
                 s2aN = 0.2, s2bN = 0.2, muD = c(0, 0.5), s2aD = 0.2,
                 s2bD = 0.2, muR = qnorm(c(0.2, 0.4)), s2aR = 0.2, s2bR
                 = 0.2, crit = matrix(rep(c(-1.6, -0.5, 0, 0.5, 1.6),
                 each = I), ncol = (K - 1)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpsdPosSim_+3A_nn">NN</code></td>
<td>
<p>Number of new-item conditions.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_ns">NS</code></td>
<td>
<p>Number of studied-item conditions.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_i">I</code></td>
<td>
<p>Number of participants.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_j">J</code></td>
<td>
<p>Number of items.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_k">K</code></td>
<td>
<p>Number of response options.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_mun">muN</code></td>
<td>
<p>Mean of new-item distribution.  If there are more than one new-item conditions this is a vector of means with length equal to NN.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_s2an">s2aN</code></td>
<td>
<p>Variance of participant effects on mean of new-item distribution.</p>
</td></tr>  
<tr><td><code id="dpsdPosSim_+3A_s2bn">s2bN</code></td>
<td>
<p>Variance of item effects on mean of new-item distribution.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_mud">muD</code></td>
<td>
<p>Mean of dprime distribution.  If there are more than
new-item conditions this is a vector of means with length equal to NNone studied-item conditions this is a vector of means with length equal to NS.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_s2ad">s2aD</code></td>
<td>
<p>Variance of participant effects on mean of dprime distribution.</p>
</td></tr>  
<tr><td><code id="dpsdPosSim_+3A_s2bd">s2bD</code></td>
<td>
<p>Variance of item effects on mean of dprime distribution.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_mur">muR</code></td>
<td>
<p>Mean recollection, on probit space.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_s2ar">s2aR</code></td>
<td>
<p>Variance of participant effects recollection.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_s2br">s2bR</code></td>
<td>
<p>Variance of item effects on recollection.</p>
</td></tr>
<tr><td><code id="dpsdPosSim_+3A_crit">crit</code></td>
<td>
<p>Matrix of criteria (not including -Inf or Inf).  Columns
correspond to criteria, rows correspond to participants.</p>
</td></tr>
</table>

<hr>
<h2 id='dpsdSample'>Function to fit hierarchical DPSD model to data.</h2><span id='topic+dpsdSample'></span>

<h3>Description</h3>

<p>Runs MCMC estimation for the hierarchical DPSD model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpsdSample(dat, M = 5000, keep = (M/10):M, getDIC = TRUE,
freeCrit=TRUE,Hier=TRUE, jump=.01)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpsdSample_+3A_dat">dat</code></td>
<td>
<p>Data frame that must include variables
Scond,cond,sub,item,lag,resp.  Scond indexes studied/new, whereas
cond indexes conditions nested within the studied or new
conditions.  Indexes for Scond,cond, sub, item, and respone must
start at zero and have no gaps (i.e., no skipped subject numbers). Lags
must be zero-centered.</p>
</td></tr>
<tr><td><code id="dpsdSample_+3A_m">M</code></td>
<td>
<p>Number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="dpsdSample_+3A_keep">keep</code></td>
<td>
<p>Which MCMC iterations should be included in estimates and
returned.  Use keep to both get ride of burn-in, and thin chains if
necessary.</p>
</td></tr>
<tr><td><code id="dpsdSample_+3A_getdic">getDIC</code></td>
<td>
<p>Logical. Should the function compute DIC value?  This
takes a while if M is large.</p>
</td></tr>
<tr><td><code id="dpsdSample_+3A_freecrit">freeCrit</code></td>
<td>
<p>Logical.  If true then criteria are estimated
separately
for each participant.  Should be set to false if analizing only one
participant (e.g., if averaging over subjects).</p>
</td></tr> 
<tr><td><code id="dpsdSample_+3A_hier">Hier</code></td>
<td>
<p>Logical. If true then the variances of effects
(e.g., item effects) are estimated from the data, i.e., effects are
treated as random.  If false then these variances are fixed to
2.0 (.5 for recollection effects), thus treating these effects as
fixed.  This option is there to allow for compairson with more
traditional approaches, and to see the effects of imposing
hierarcical structure.  It should always be set to TRUE in real
analysis, and is not even guaranteed to work if set to false.</p>
</td></tr>
<tr><td><code id="dpsdSample_+3A_jump">jump</code></td>
<td>
<p>The criteria and decorrelating steps utilize
Matropolis-Hastings sampling routines, which require tuning.  All
MCMC functions should self-tune during the burnin period (iterations
before keep), and they will alert you to the success of tuning.  If
acceptance rates are too low, &quot;jump&quot; should be decreased, if they
are too hight, &quot;jump&quot; should be increased.  Alternatively, or in
addition to adjusting &quot;jump&quot;, simply increase the burnin period
which will allow the function more time to self-tune.</p>
</td></tr>  
</table>


<h3>Value</h3>

<p>The function returns an internally defined &quot;uvsd&quot; structure that
includes the following components
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>Indexes which element of blocks contain mu</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Indexes which element of blocks contain participant
effects, alpha</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Indexes which element of blocks contain item effects, beta</p>
</td></tr>
<tr><td><code>s2alpha</code></td>
<td>
<p>Indexes which element of blocks contain variance of
participant effects (alpha).</p>
</td></tr>
<tr><td><code>s2beta</code></td>
<td>
<p>Indexes which element of blocks contain variance of
item effects (beta).</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Indexes which element of blocks contain theta, the slope of
the lag effect</p>
</td></tr>
<tr><td><code>estN</code></td>
<td>
<p>Posterior means of block parameters for new-item means</p>
</td></tr>
<tr><td><code>estS</code></td>
<td>
<p>Posterior means of block parameters for studied-item means</p>
</td></tr>
<tr><td><code>estR</code></td>
<td>
<p>Posterior means of block for Recollection means.</p>
</td></tr>
<tr><td><code>estCrit</code></td>
<td>
<p>Posterior means of criteria</p>
</td></tr>
<tr><td><code>blockN</code></td>
<td>
<p>Each iteration for each parameter in the new-item mean
block.  Rows index iteration, columns index parameter.</p>
</td></tr>
<tr><td><code>blockS</code></td>
<td>
<p>Same as blockN, but for the studied-item means</p>
</td></tr>
<tr><td><code>blockR</code></td>
<td>
<p>Same as blockN, but for the recollection-parameter
means.</p>
</td></tr>
<tr><td><code>s.crit</code></td>
<td>
<p>Samples of each criteria.</p>
</td></tr>
<tr><td><code>pD</code></td>
<td>
<p>Number of effective parameters used in DIC.  Note that this
should be smaller than the actual number of parameters, as
constraint from the hierarchical structure decreases the number of
effective parameters.</p>
</td></tr>
<tr><td><code>DIC</code></td>
<td>
<p>DIC value.  Smaller values indicate better fits.  Note that
DIC is notably biased toward complexity.</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>Number of MCMC iterations run</p>
</td></tr>
<tr><td><code>keep</code></td>
<td>
<p>MCMC iterations that were used for estimation and
returned</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>Metropolis-Hastings acceptance rates for decorrelating
steps.  These should be between .2 and .6.  If they are not, the M,
keep, or jump arguments need to be adjusted.</p>
</td></tr>
<tr><td><code>b0Crit</code></td>
<td>
<p>acceptance rates for criteria.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael S. Pratte</p>


<h3>References</h3>

<p>See Pratte, Rouder, &amp; Morey (2009)</p>


<h3>See Also</h3>

<p>hbmem</p>


<h3>Examples</h3>

<pre><code class='language-R'>#In this example we generate data from EVSD, then fit it with both
#hierarchical DPSD and DPSD assuming no participant or item effects.
library(hbmem)
sim=dpsdSim(I=30,J=200)
dat=as.data.frame(cbind(sim@subj,sim@item,sim@cond,sim@Scond,sim@lag,sim@resp))
colnames(dat)=c("sub","item","cond","Scond","lag","resp")
dat$lag[dat$Scond==1]=dat$lag[dat$Scond==1]-mean(dat$lag[dat$Scond==1])

M=10 #Too low for real analysis!
keep=2:M
DPSD=dpsdSample(dat,M=M)

#Look at all parameters
par(mfrow=c(3,3),pch=19,pty='s')

matplot(DPSD@blockN[,DPSD@muN],t='l',
ylab="muN")
abline(h=sim@muN,col="blue")
plot(DPSD@estN[DPSD@alphaN]~sim@alphaN)
abline(0,1,col="blue")
plot(DPSD@estN[DPSD@betaN]~sim@betaN)
abline(0,1,col="blue")

matplot(DPSD@blockS[,DPSD@muS],t='l',
ylab="muS")
abline(h=sim@muS,col="blue")
plot(DPSD@estS[DPSD@alphaS]~sim@alphaS)
abline(0,1,col="blue")
plot(DPSD@estS[DPSD@betaS]~sim@betaS)
abline(0,1,col="blue")

matplot(pnorm(DPSD@blockR[,DPSD@muS]),t='l',
ylab="P(recollection)")
abline(h=pnorm(sim@muR),col="blue")
plot(DPSD@estR[DPSD@alphaS]~sim@alphaR)
abline(0,1,col="blue")
plot(DPSD@estR[DPSD@betaS]~sim@betaR)
abline(0,1,col="blue")
</code></pre>

<hr>
<h2 id='dpsdSim'>Function dpsdSim</h2><span id='topic+dpsdSim'></span>

<h3>Description</h3>

<p>Simulates data from a hierarchical DPSD model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>dpsdSim(NN=2,NS=1,I=30,J=200,K=6,muN=c(-.7,-.5),s2aN=.2,s2bN=.2,
muS=0,s2aS=.2,s2bS=.2,muR=qnorm(.25),s2aR=.2,s2bR=.2,
crit=matrix(rep(c(-1.6,-.5,0,.5,1.6),each=I),ncol=(K-1)))</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dpsdSim_+3A_nn">NN</code></td>
<td>
<p>Number of new-item conditions.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_ns">NS</code></td>
<td>
<p>Number of studied-item conditions.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_i">I</code></td>
<td>
<p>Number of participants.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_j">J</code></td>
<td>
<p>Number of items.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_k">K</code></td>
<td>
<p>Number of response options.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_mun">muN</code></td>
<td>
<p>Mean of new-item distribution.  If there are more than one new-item conditions this is a vector of means with length equal to NN.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_s2an">s2aN</code></td>
<td>
<p>Variance of participant effects on mean of new-item distribution.</p>
</td></tr>  
<tr><td><code id="dpsdSim_+3A_s2bn">s2bN</code></td>
<td>
<p>Variance of item effects on mean of new-item distribution.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_mus">muS</code></td>
<td>
<p>Mean of studied-item distribution.  If there are more than
new-item conditions this is a vector of means with length equal to NNone studied-item conditions this is a vector of means with length equal to NS.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_s2as">s2aS</code></td>
<td>
<p>Variance of participant effects on mean of studied-item distribution.</p>
</td></tr>  
<tr><td><code id="dpsdSim_+3A_s2bs">s2bS</code></td>
<td>
<p>Variance of item effects on mean of studied-item distribution.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_mur">muR</code></td>
<td>
<p>Mean recollection, on probit space.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_s2ar">s2aR</code></td>
<td>
<p>Variance of participant effects recollection.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_s2br">s2bR</code></td>
<td>
<p>Variance of item effects on recollection.</p>
</td></tr>
<tr><td><code id="dpsdSim_+3A_crit">crit</code></td>
<td>
<p>Matrix of criteria (not including -Inf or Inf).  Columns
correspond to criteria, rows correspond to participants.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an internally defined &quot;dpsdSim&quot; structure.</p>


<h3>Author(s)</h3>

<p>Michael S. Pratte</p>


<h3>References</h3>

<p>See Pratte, Rouder, &amp; Morey (2009)</p>


<h3>See Also</h3>

<p>hbmem</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(hbmem)
#Data from hiererchial model
sim=dpsdSim()
slotNames(sim)
#Scond indicates studied/new
#cond indicates which condition (e.g., deep/shallow)

table(sim@resp,sim@Scond,sim@cond)

#Usefull to make data.frame for passing to functions
dat=as.data.frame(cbind(sim@subj,sim@item,sim@Scond,sim@cond,sim@lag,sim@resp))
colnames(dat)=c("sub","item","Scond","cond","lag","resp")

table(dat$resp,dat$Scond,dat$cond)
</code></pre>

<hr>
<h2 id='gammaLikeSample'>Function gammaLikeSample</h2><span id='topic+gammaLikeSample'></span>

<h3>Description</h3>

<p>Runs MCMC for the hierarchical Gamma Likelihood model</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammaLikeSample(dat, M = 10000, keep = (M/10):M, getDIC = TRUE,
shape=2,jump=.005)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gammaLikeSample_+3A_dat">dat</code></td>
<td>
<p>Data frame that must include variables
cond,sub,item,lag,resp.  Indexes for cond, sub, item, and respone
must start at zero and have no gapes (i.e., no skipped subject
numbers). Lags must be zero-centered.</p>
</td></tr>
<tr><td><code id="gammaLikeSample_+3A_m">M</code></td>
<td>
<p>Number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="gammaLikeSample_+3A_keep">keep</code></td>
<td>
<p>Which MCMC iterations should be included in estimates and
returned.  Use keep to both get ride of burn-in, and thin chains if
necessary</p>
</td></tr>
<tr><td><code id="gammaLikeSample_+3A_getdic">getDIC</code></td>
<td>
<p>Logical. should the function compute DIC value?  This
takes a while if M is large.</p>
</td></tr>
<tr><td><code id="gammaLikeSample_+3A_shape">shape</code></td>
<td>
<p>Fixed shape across both new and studied distributuions.</p>
</td></tr>
<tr><td><code id="gammaLikeSample_+3A_jump">jump</code></td>
<td>
<p>The criteria and decorrelating steps utilize
Matropolis-Hastings sampling routines, which require tuning.  All
MCMC functions should self tune during the burnin perior (iterations
before keep), and they will alert you to the success of tuning.  If
acceptance rates are too low, &quot;jump&quot; should be decreased, if they
are too hight, &quot;jump&quot; should be increased.  Alternatively, or in
addition to adjusting &quot;jump&quot;, simply increase the burnin period
which will allow the function more time to self-tune.</p>
</td></tr>  
</table>


<h3>Value</h3>

<p>The function returns an internally defined &quot;uvsd&quot; S4 class that
includes the following components
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>Indexes which element of blocks contain grand means, mu</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Indexes which element of blocks contain participant
effects, alpha</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Indexes which element of blocks contain item effects, beta</p>
</td></tr>
<tr><td><code>s2alpha</code></td>
<td>
<p>Indexes which element of blocks contain variance of
participant effects (alpha).</p>
</td></tr>
<tr><td><code>s2beta</code></td>
<td>
<p>Indexes which element of blocks contain variance of
item effects (beta).</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Indexes which element of blocks contain theta, the slope of
the lag effect</p>
</td></tr>
<tr><td><code>estN</code></td>
<td>
<p>Posterior means of block parameters for new-item means</p>
</td></tr>
<tr><td><code>estS</code></td>
<td>
<p>Posterior means of block parameters for studied-item means</p>
</td></tr>
<tr><td><code>estS2</code></td>
<td>
<p>Not used for gamma model.</p>
</td></tr>
<tr><td><code>estCrit</code></td>
<td>
<p>Posterior means of criteria</p>
</td></tr>
<tr><td><code>blockN</code></td>
<td>
<p>Each iteration for each parameter in the new-item mean
block.  Rows index iteration, columns index parameter.</p>
</td></tr>
<tr><td><code>blockS</code></td>
<td>
<p>Same as blockN, but for the studied-item means</p>
</td></tr>
<tr><td><code>blockS2</code></td>
<td>
<p>Not used for gamma model.</p>
</td></tr>
<tr><td><code>s.crit</code></td>
<td>
<p>Samples of each criteria.</p>
</td></tr>
<tr><td><code>pD</code></td>
<td>
<p>Number of effective parameters used in DIC.  Note that this
should be smaller than the actual number of parameters, as
constraint from the hierarchical structure decreases the number of
effective parameters.</p>
</td></tr>
<tr><td><code>DIC</code></td>
<td>
<p>DIC value.  Smaller values indicate better fits.  Note that
DIC is notably biased toward complexity.</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>Number of MCMC iterations run</p>
</td></tr>
<tr><td><code>keep</code></td>
<td>
<p>MCMC iterations that were used for estimation and
returned</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>Metropolis-Hastings acceptance rates for new-item
distribution parameters.  These should be between .2 and .6.  If
they are not, the M, keep, or jump need to be adjusted.</p>
</td></tr>
<tr><td><code>b0S2</code></td>
<td>
<p>Metropolis-Hastings acceptance rates for studied-item
distribution parameters. </p>
</td></tr>
<tr><td><code>b0Crit</code></td>
<td>
<p>Metropolis-Hastings acceptance rates for criteria. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael S. Pratte</p>


<h3>See Also</h3>

<p>hbmem</p>


<h3>Examples</h3>

<pre><code class='language-R'>#This function is broken, so
#no example that works.
#make data from gamma model
if(1==0)
{
library(hbmem)
sim=gammaLikeSim(I=50,J=400,muS=log(.5),s2aS=0,s2bS=0)
dat=as.data.frame(cbind(sim@subj,sim@item,sim@cond,sim@Scond,sim@lag,sim@resp))
colnames(dat)=c("sub","item","cond","Scond","lag","resp")
dat$lag=0

table(dat$resp,dat$Scond)
M=5000
keep=500:M
gamma=gammaLikeSample(dat,M=M,keep=keep,jump=.001)

par(mfrow=c(2,3),pch=19,pty='s')
matplot(exp(gamma@blockS[,gamma@muS]),t='l',xlab="Iteration",ylab="Mu-S")
abline(h=exp(sim@muS),col="blue")
#Estimates of Alpha as function of true values
plot(gamma@estS[gamma@alphaS]~sim@alphaS,xlab="True
Alpha-S",ylab="Est. Alpha-S");abline(0,1,col="blue")
#Estimates of Beta as function of true values
plot(gamma@estS[gamma@betaS]~sim@betaS,xlab="True
Beta-S",ylab="Est. Beta-S");abline(0,1,col="blue")

#Look at some criteria
for(i in 1:3){
matplot(t(exp(gamma@s.crit[i,2:7,])),t='l')
abline(h=sim@crit[i,])
}

gamma@estS[c(gamma@s2alphaS,gamma@s2betaS)]
}

</code></pre>

<hr>
<h2 id='gammaSample'>Function gammaSample</h2><span id='topic+gammaSample'></span>

<h3>Description</h3>

<p>Runs MCMC for the hierarchical Gamma model</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammaSample(dat, M = 10000, keep = (M/10):M, getDIC = TRUE,
freeCrit=TRUE,shape=2,jump=.005)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gammaSample_+3A_dat">dat</code></td>
<td>
<p>Data frame that must include variables
cond,sub,item,lag,resp.  Indexes for cond, sub, item, and respone
must start at zero and have no gapes (i.e., no skipped subject
numbers). Lags must be zero-centered.</p>
</td></tr>
<tr><td><code id="gammaSample_+3A_m">M</code></td>
<td>
<p>Number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="gammaSample_+3A_keep">keep</code></td>
<td>
<p>Which MCMC iterations should be included in estimates and
returned.  Use keep to both get ride of burn-in, and thin chains if necessary</p>
</td></tr>
<tr><td><code id="gammaSample_+3A_getdic">getDIC</code></td>
<td>
<p>Logical. should the function compute DIC value?  This
takes a while if M is large.</p>
</td></tr>
<tr><td><code id="gammaSample_+3A_freecrit">freeCrit</code></td>
<td>
<p>Logical.  If TRUE (default) individual criteria vary
across people.  If false, all participants have the same criteria
(but note that overall response biases are still modeled in the
means)</p>
</td></tr>
<tr><td><code id="gammaSample_+3A_shape">shape</code></td>
<td>
<p>Fixed shape across both new and studied distributuions.</p>
</td></tr>
<tr><td><code id="gammaSample_+3A_jump">jump</code></td>
<td>
<p>The criteria and decorrelating steps utilize
Matropolis-Hastings sampling routines, which require tuning.  All
MCMC functions should self tune during the burnin perior (iterations
before keep), and they will alert you to the success of tuning.  If
acceptance rates are too low, &quot;jump&quot; should be decreased, if they
are too hight, &quot;jump&quot; should be increased.  Alternatively, or in
addition to adjusting &quot;jump&quot;, simply increase the burnin period
which will allow the function more time to self-tune.</p>
</td></tr>  
</table>


<h3>Value</h3>

<p>The function returns an internally defined &quot;uvsd&quot; S4 class that
includes the following components
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>Indexes which element of blocks contain grand means, mu</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Indexes which element of blocks contain participant
effects, alpha</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Indexes which element of blocks contain item effects, beta</p>
</td></tr>
<tr><td><code>s2alpha</code></td>
<td>
<p>Indexes which element of blocks contain variance of
participant effects (alpha).</p>
</td></tr>
<tr><td><code>s2beta</code></td>
<td>
<p>Indexes which element of blocks contain variance of
item effects (beta).</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Indexes which element of blocks contain theta, the slope of
the lag effect</p>
</td></tr>
<tr><td><code>estN</code></td>
<td>
<p>Posterior means of block parameters for new-item means</p>
</td></tr>
<tr><td><code>estS</code></td>
<td>
<p>Posterior means of block parameters for studied-item means</p>
</td></tr>
<tr><td><code>estS2</code></td>
<td>
<p>Not used for gamma model.</p>
</td></tr>
<tr><td><code>estCrit</code></td>
<td>
<p>Posterior means of criteria</p>
</td></tr>
<tr><td><code>blockN</code></td>
<td>
<p>Each iteration for each parameter in the new-item mean
block.  Rows index iteration, columns index parameter.</p>
</td></tr>
<tr><td><code>blockS</code></td>
<td>
<p>Same as blockN, but for the studied-item means</p>
</td></tr>
<tr><td><code>blockS2</code></td>
<td>
<p>Not used for gamma model.</p>
</td></tr>
<tr><td><code>s.crit</code></td>
<td>
<p>Samples of each criteria.</p>
</td></tr>
<tr><td><code>pD</code></td>
<td>
<p>Number of effective parameters used in DIC.  Note that this
should be smaller than the actual number of parameters, as
constraint from the hierarchical structure decreases the number of
effective parameters.</p>
</td></tr>
<tr><td><code>DIC</code></td>
<td>
<p>DIC value.  Smaller values indicate better fits.  Note that
DIC is notably biased toward complexity.</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>Number of MCMC iterations run</p>
</td></tr>
<tr><td><code>keep</code></td>
<td>
<p>MCMC iterations that were used for estimation and
returned</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>Metropolis-Hastings acceptance rates for new-item
distribution parameters.  These should be between .2 and .6.  If
they are not, the M, keep, or jump need to be adjusted.</p>
</td></tr>
<tr><td><code>b0S2</code></td>
<td>
<p>Metropolis-Hastings acceptance rates for studied-item
distribution parameters. </p>
</td></tr>
<tr><td><code>b0Crit</code></td>
<td>
<p>Metropolis-Hastings acceptance rates for criteria. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael S. Pratte</p>


<h3>See Also</h3>

<p>hbmem</p>


<h3>Examples</h3>

<pre><code class='language-R'>#make data from gamma model
library(hbmem)
sim=gammaSim(I=30,J=200)
dat=as.data.frame(cbind(sim@subj,sim@item,sim@cond,sim@Scond,sim@lag,sim@resp))
colnames(dat)=c("sub","item","cond","Scond","lag","resp")

M=10 #set very small for demo speed
keep=2:M
gamma=gammaSample(dat,M=M,keep=keep,jump=.01)

par(mfrow=c(3,2),pch=19,pty='s')
#Look at chains of MuN and MuS
matplot(gamma@blockN[,gamma@muN],t='l',xlab="Iteration",ylab="Mu-N")
abline(h=sim@muN,col="blue")
matplot(gamma@blockS[,gamma@muS],t='l',xlab="Iteration",ylab="Mu-S")
abline(h=sim@muS,col="blue")

#Estimates of Alpha as function of true values
plot(gamma@estN[gamma@alphaN]~sim@alphaN,xlab="True
Alpha-N",ylab="Est. Alpha-N");abline(0,1,col="blue")
plot(gamma@estS[gamma@alphaS]~sim@alphaS,xlab="True
Alpha-S",ylab="Est. Alpha-S");abline(0,1,col="blue")
#Estimates of Beta as function of true values
plot(gamma@estN[gamma@betaN]~sim@betaN,xlab="True
Beta-N",ylab="Est. Beta-N");abline(0,1,col="blue")
plot(gamma@estS[gamma@betaS]~sim@betaS,xlab="True
Beta-S",ylab="Est. Beta-S");abline(0,1,col="blue")

gamma@estN[c(gamma@s2alphaN,gamma@s2betaN)]
gamma@estS[c(gamma@s2alphaS,gamma@s2betaS)]


#Look at some criteria
par(mfrow=c(2,2))
for(i in 1:4)
matplot(t(gamma@s.crit[i,,]),t='l')
</code></pre>

<hr>
<h2 id='gammaSim'>Function gammaSim</h2><span id='topic+gammaSim'></span>

<h3>Description</h3>

<p>Simulates data from a hierarchical Gamma model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>gammaSim(NN=1,NS=2,I=30,J=200,K=6,muN=log(.65),s2aN=.2,s2bN=.2,
muS=log(c(.8,1.2)),s2aS=.2,s2bS=.2,lagEffect=-.001,shape=2,
crit=matrix(rep(c(.3,.6,1,1.2,1.6),each=I),ncol=(K-1)))</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gammaSim_+3A_nn">NN</code></td>
<td>
<p>Number of conditions for new words.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_ns">NS</code></td>
<td>
<p>Number of conditions for studied words.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_i">I</code></td>
<td>
<p>Number of participants.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_j">J</code></td>
<td>
<p>Number of items.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_k">K</code></td>
<td>
<p>Number of response options.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_mun">muN</code></td>
<td>
<p>Mean of new-item distribution.  If NN is greater than 1, then muN must be a vector of length NN.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_s2an">s2aN</code></td>
<td>
<p>Variance of participant effects on mean of new-item distribution.</p>
</td></tr>  <tr><td><code id="gammaSim_+3A_s2bn">s2bN</code></td>
<td>
<p>Variance of item effects on mean of new-item distribution.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_mus">muS</code></td>
<td>
<p>Mean of studied-item distribution.  If NS is greater than 1, then muS must be a vector of length NS.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_s2as">s2aS</code></td>
<td>
<p>Variance of participant effects on mean of studied-item
distribution.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_s2bs">s2bS</code></td>
<td>
<p>Variance of item effects on mean of studied-item distribution.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_lageffect">lagEffect</code></td>
<td>
<p>Linear slope of lag effect on log of studied-item scale.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_shape">shape</code></td>
<td>
<p>Common shape for both new and studied distributuions.</p>
</td></tr>
<tr><td><code id="gammaSim_+3A_crit">crit</code></td>
<td>
<p>Matrix of criteria (not including -Inf or Inf).  Columns
correspond to criteria, rows correspond to participants.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an internally defined &quot;uvsdSim&quot; structure.</p>


<h3>Author(s)</h3>

<p>Michael S. Pratte</p>


<h3>References</h3>

<p>See Pratte, Rouder, &amp; Morey (2009)</p>


<h3>See Also</h3>

<p>hbmem</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(hbmem)
#Data from hiererchial model
sim=gammaSim() 
slotNames(sim) 
table(sim@resp,sim@cond,sim@Scond)

#Usefull to make data.frame for passing to model-fitting functions
dat=as.data.frame(cbind(sim@subj,sim@item,sim@cond,sim@Scond,sim@lag,sim@resp))
colnames(dat)=c("sub","item","cond","Scond","lag","resp")

table(dat$resp,dat$cond,dat$Scond)
</code></pre>

<hr>
<h2 id='hbmem-package'>Hierarchical Models of Recognition Memory</h2><span id='topic+hbmem-package'></span><span id='topic+hbmem'></span>

<h3>Description</h3>

<p>Contains functions for fitting hierarchical versions of EVSD, UVSD, DPSD, and our gamma signal detection model to recognition memory confidence-ratings data.</p>


<h3>Author(s)</h3>

<p>Michael S. Pratte &lt;prattems@gmail.com&gt;</p>


<h3>References</h3>

<p>Morey, Pratte, and Rouder (2008); Pratte, Rouder, and Morey
(2009); Pratte and Rouder (2012).</p>


<h3>See Also</h3>

<p>'uvsdSample' to fit hierarchical UVSD model, 'uvsdSim' to
simulate data from the hierarchical UVSD model, 'dpsdSample' to fit the
hierarchial DPSD model, 'dpsdSim' to simulate data from the
hierarchial DPSD model, 'dpsdPosSim' and 'dpsdPosSample' for the DPSD model 
with positive sensitivity, and datasets from our publications.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#In this example data are simulated from EVSD
#They are then fit by both UVSD and DPSD

library(hbmem)
sim=uvsdSim(s2aS2=0,s2bS2=0) #Simulate data from hierarchical EVSD
dat=as.data.frame(cbind(sim@subj,sim@item,sim@Scond,sim@cond,sim@lag,sim@resp))
colnames(dat)=c("sub","item","Scond","cond","lag","resp")

M=10 #Set way low for speed
keep=2:M
#For real analysis we run 105000 iterations
#with the first 5000 serving as burnin, and
#only keep every 10th iteration for analysis,
#i.e., thinning the chanins to mitgate autocorrelation.
evsd=uvsdSample(dat,M=M,keep=keep,equalVar=TRUE) #Fit EVSD
uvsd=uvsdSample(dat,M=M,keep=keep,freeSig2=TRUE) #Fit UVSD w/1 Sigma2
dpsd=dpsdSample(dat,M=M,keep=keep) #Fit DPSD 

#Look at available information
slotNames(uvsd)
slotNames(dpsd)

#Compare DIC; smaller is better
evsd@DIC
uvsd@DIC
dpsd@DIC

#Effective parameters.  Because there are no
#real effects on studied-item variance, the
#hierarchical models are drastically shrinking these
#effect parameters to zero, so that they do not
#count as full parameters.
evsd@pD
uvsd@pD
dpsd@pD

#PLOTS FROM UVSD FIT
par(mfrow=c(3,2),pch=19,pty='s')
#Make sure chains look OK
matplot(uvsd@blockN[,uvsd@muN],t='l',xlab="Iteration",ylab="Mu-N")
abline(h=sim@muN,col="blue")
matplot(uvsd@blockS[,uvsd@muS],t='l',xlab="Iteration",ylab="Mu-S")
abline(h=sim@muS,col="blue")

#Estimates of Alpha as function of true values
plot(uvsd@estN[uvsd@alphaN]~sim@alphaN,xlab="True
Alpha-N",ylab="Est. Alpha-N");abline(0,1,col="blue")
plot(uvsd@estS[uvsd@alphaS]~sim@alphaS,xlab="True
Alpha-S",ylab="Est. Alpha-S");abline(0,1,col="blue")
#Estimates of Beta as function of true values
plot(uvsd@estN[uvsd@betaN]~sim@betaN,xlab="True
Beta-N",ylab="Est. Beta-N");abline(0,1,col="blue")
plot(uvsd@estS[uvsd@betaS]~sim@betaS,xlab="True
Beta-S",ylab="Est. Beta-S");abline(0,1,col="blue")

###Look at Sigma2 and Recollection from UVSD and DPSD###
par(mfrow=c(2,3),pch=19,pty='s')
plot(sqrt(exp(uvsd@blockS2[,uvsd@muS])),
t='l',ylab="Sigma",main="Grand Mean")
abline(h=1,col="blue")
hist(uvsd@blockS2[,uvsd@s2alphaS],main="Participant Effect")
hist(uvsd@blockS2[,uvsd@s2betaS],main="Item Effect")

plot(pnorm(dpsd@blockR[,dpsd@muS]),
t='l',ylab="P(Recollection)",main="Grand Mean")
abline(h=0,col="blue")
hist(dpsd@blockR[,dpsd@s2alphaS],main="Participant Effect")
hist(dpsd@blockR[,dpsd@s2betaS],main="Item Effect")


#See what DPSD does with EVSD effects
par(mfrow=c(2,3))
plot(dpsd@estN[dpsd@alphaN]~sim@alphaN,xlab="True
Alpha-N",ylab="DPSD Alpha-N");abline(0,1,col="blue")
plot(dpsd@estS[dpsd@alphaS]~sim@alphaS,xlab="True
Alpha-S",ylab="DPSD Alpha-S");abline(0,1,col="blue")
plot(dpsd@estR[dpsd@alphaS]~sim@alphaS,xlab="True
Alpha-S",ylab="DPSD Alpha-R");abline(0,1,col="blue")

plot(dpsd@estN[dpsd@betaN]~sim@betaN,xlab="True
Beta-N",ylab="DPSD Beta-N");abline(0,1,col="blue")
plot(dpsd@estS[dpsd@betaS]~sim@betaS,xlab="True
Beta-S",ylab="DPSD Beta-S");abline(0,1,col="blue")
plot(dpsd@estR[dpsd@betaS]~sim@betaS,xlab="True
Beta-S",ylab="DPSD Beta-R");abline(0,1,col="blue")
</code></pre>

<hr>
<h2 id='prm09'>PRM09 Data</h2><span id='topic+prm09'></span>

<h3>Description</h3>

<p>Confidence ratings data from Pratte, Rouder, and Morey
(2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(prm09)</code></pre>


<h3>Format</h3>

<p>A flat-field data frame (each row is a trial) with the following variables
</p>

<dl>
<dt><code>cond</code></dt><dd><p>0=new; 1=studied</p>
</dd>
<dt><code>sub</code></dt><dd><p>index of subject starting at 0</p>
</dd>
<dt><code>item</code></dt><dd><p>index of item starting at 0</p>
</dd>
<dt><code>lag</code></dt><dd><p>index of lag, zero-centered</p>
</dd>
<dt><code>resp</code></dt><dd><p>which response was made; 0=&quot;sure new&quot;</p>
</dd>    
</dl>



<h3>Details</h3>

<p>Participants studied a list of 240 words, and were then tested
on the 240 studied and on 240 new words.  At test, participants made
one of six confidence ratings ranging from &quot;sure new&quot; to &quot;sure
studied&quot;.  Note that to apply the models to these data the &quot;Scond&quot;
variable should be set to &ldquo;cond&quot;, and the &quot;cond&quot; variable should
be all zeros.  This is a backwards-compatibility issue.</p>


<h3>Source</h3>

<p>Pratte, Rouder, and Morey (2009).  Separating Mnemonic Process
from Participant and Item Effects in the Assessment of ROC
Asymmetries.  Journal of Experimental Psychology: Learning, Memory,
and Cognition.</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(hbmem)
data(prm09)
table(prm09$resp,prm09$cond)
#Turn it into data suitable for
#analysis with HBMEM functions:
newdat=prm09
newdat$Scond=newdat$cond
newdat$cond=0
summary(newdat)
</code></pre>

<hr>
<h2 id='rtgamma'>Function rtgamma</h2><span id='topic+rtgamma'></span>

<h3>Description</h3>

<p>Returns random draws from truncated gamma distributuion.</p>


<h3>Usage</h3>

<pre><code class='language-R'>rtgamma(N, shape, scale, a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rtgamma_+3A_n">N</code></td>
<td>
<p>Number of samples.</p>
</td></tr>
<tr><td><code id="rtgamma_+3A_shape">shape</code></td>
<td>
<p>Shape of gamma distribution.</p>
</td></tr>
<tr><td><code id="rtgamma_+3A_scale">scale</code></td>
<td>
<p>Scale of gamma distributuion.</p>
</td></tr>
<tr><td><code id="rtgamma_+3A_a">a</code></td>
<td>
<p>Lower truncation point.</p>
</td></tr>
<tr><td><code id="rtgamma_+3A_b">b</code></td>
<td>
<p>Upper truncation point.</p>
</td></tr>
</table>

<hr>
<h2 id='sampleGamma'>Function sampleGamma</h2><span id='topic+sampleGamma'></span>

<h3>Description</h3>

<p>Samples posterior of mean parameters of the hierarchical
linear model on the log scale parameter of a gamma distributuion. Usually 
used within an MCMC loop.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sampleGamma(sample, y, cond,subj, item,
lag,N,I,J,R,ncond,nsub,nitem,s2mu, s2a, s2b, met, shape,
sampLag,pos=FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sampleGamma_+3A_sample">sample</code></td>
<td>
<p>Block of linear model parameters from previous iteration.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_y">y</code></td>
<td>
<p>Vector of data</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_cond">cond</code></td>
<td>
<p>Vector fo condition index,starting at zero.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_subj">subj</code></td>
<td>
<p>Vector of subject index, starting at zero.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_item">item</code></td>
<td>
<p>Vector of item index, starting at zero.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_lag">lag</code></td>
<td>
<p>Vector of lag index, zero-centered.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_n">N</code></td>
<td>
<p>Numer of conditions.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_i">I</code></td>
<td>
<p>Number of subjects.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_j">J</code></td>
<td>
<p>Number of items.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_r">R</code></td>
<td>
<p>Total number of trials.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_ncond">ncond</code></td>
<td>
<p>Vector of length (N) containing number of trials per 
condition.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_nsub">nsub</code></td>
<td>
<p>Vector of length (I) containing number of trials per each
subject.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_nitem">nitem</code></td>
<td>
<p>Vector of length (J) containing number of trials per each
item.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_s2mu">s2mu</code></td>
<td>
<p>Prior variance on the grand mean mu; usually set to some
large number.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_s2a">s2a</code></td>
<td>
<p>Shape parameter of inverse gamma prior placed on effect 
variances.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_s2b">s2b</code></td>
<td>
<p>Rate parameter of inverse gamma prior
placed on effect variances.  Setting both s2a AND s2b to be small
(e.g., .01, .01) makes this an uninformative prior.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_met">met</code></td>
<td>
<p>Vector of tuning parameter for metropolis-hastings 
steps.  Here, all sampling (except variances of alpha and beta) and 
decorrelating steps utilize the M-H sampling algorithm.  This hould 
be adjusted so that .2 &lt; b0 &lt; .6.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_shape">shape</code></td>
<td>
<p>Single shape of Gamma distribution.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_samplag">sampLag</code></td>
<td>
<p>Logical.  Whether or not to sample the lag effect.</p>
</td></tr>
<tr><td><code id="sampleGamma_+3A_pos">pos</code></td>
<td>
<p>Logical.  If true, the model on scale is 1+exp(mu + alpha + beta).  That is, the scale is always greater than one. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list.  The first element of the list is the
newly sampled block of parameters.  The second element contains a
vector of 0s and 1s indicating which of the decorrelating steps were accepted.</p>


<h3>Author(s)</h3>

<p>Michael S. Pratte</p>


<h3>See Also</h3>

<p>hbmem</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(hbmem)
N=2
shape=2
I=30
J=50
R=I*J
#make some data
mu=log(c(1,2))
alpha=rnorm(I,0,.2)
beta=rnorm(J,0,.2)
theta=-.001
cond=sample(0:(N-1),R,replace=TRUE)
subj=rep(0:(I-1),each=J)
item=NULL
for(i in 1:I)
item=c(item,sample(0:(J-1),J,replace=FALSE))
lag=rnorm(R,0,100)
lag=lag-mean(lag)
resp=1:R
for(r in 1:R)
{
  scale=1+exp(mu[cond[r]+1]+alpha[subj[r]+1]+beta[item[r]+1]+theta*lag[r])
  resp[r]=rgamma(1,shape=shape,scale=scale)
}

ncond=table(cond)
nsub=table(subj)
nitem=table(item)

M=10
keep=2:M
B=N+I+J+3
s.block=matrix(0,nrow=M,ncol=B)
met=rep(.08,B)
b0=rep(0,B)
jump=.0005
for(m in 2:M)
{
tmp=sampleGamma(s.block[m-1,],resp,cond,subj,item,lag,
N,I,J,R,ncond,nsub,nitem,5,.01,.01,met,2,1,pos=TRUE)
s.block[m,]=tmp[[1]]
b0=b0 + tmp[[2]]
#Auto-tuning of metropolis decorrelating steps 
if(m&gt;20 &amp; m&lt;min(keep))
  {
    met=met+(b0/m&lt;.4)*rep(-jump,B) +(b0/m&gt;.6)*rep(jump,B)
    met[met&lt;jump]=jump 
  }
if(m==min(keep)) b0=rep(0,B)
}

b0/length(keep) #check acceptance rate

hbest=colMeans(s.block[keep,])

par(mfrow=c(2,2),pch=19,pty='s')
matplot(s.block[keep,1:N],t='l')
abline(h=mu,col="green")
acf(s.block[keep,1])
plot(hbest[(N+1):(I+N)]~alpha)
abline(0,1,col="green")
plot(hbest[(I+N+1):(I+J+N)]~beta)
abline(0,1,col="green")



#variance of participant effect
mean(s.block[keep,(N+I+J+1)])
#variance of item effect
mean(s.block[keep,(N+I+J+2)])
#estimate of lag effect
mean(s.block[keep,(N+I+J+3)])

</code></pre>

<hr>
<h2 id='sd10'>Pratte and Rouder Exp. 2</h2><span id='topic+sd10'></span>

<h3>Description</h3>

<p>Signal detection dataset that hasn't been published yet. Please do not use.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sd10)</code></pre>


<h3>Format</h3>

<p>A data frame with observations on the following 6 variables.
</p>

<dl>
<dt><code>cond</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Scond</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>sub</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>item</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>lag</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>resp</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>


<hr>
<h2 id='sd13'>As of yet unpublished dataset</h2><span id='topic+sd13'></span>

<h3>Description</h3>

<p>Signal detection dataset from Pratte and Rouder Exp. 3. Please do not use.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sd13)</code></pre>


<h3>Format</h3>

<p>A data frame with observations on the following 6 variables.
</p>

<dl>
<dt><code>cond</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Scond</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>sub</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>item</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>lag</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>resp</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>


<hr>
<h2 id='sd2'>Data from Pratte, Morey and Rouder (2010)</h2><span id='topic+sd2'></span>

<h3>Description</h3>

<p>Signal detection dataset that hasn't been published yet. Please do not use.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sd2)</code></pre>


<h3>Format</h3>

<p>A data frame with observations on the following 6 variables.
</p>

<dl>
<dt><code>cond</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Scond</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>sub</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>item</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>lag</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>resp</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>


<hr>
<h2 id='sd6'>As of yet unpublished dataset</h2><span id='topic+sd6'></span>

<h3>Description</h3>

<p>Signal detection dataset that hasn't been published yet. Please do not use.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sd6)</code></pre>


<h3>Format</h3>

<p>A data frame with 23984 observations on the following 6 variables.
</p>

<dl>
<dt><code>cond</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Scond</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>sub</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>item</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>lag</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>resp</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>


<hr>
<h2 id='uvsdSample'>Function uvsdSample</h2><span id='topic+uvsdSample'></span>

<h3>Description</h3>

<p>Runs MCMC estimation for the hierarchical UVSD model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>uvsdSample(dat, M = 10000, keep = (M/10):M, getDIC = TRUE,
freeCrit=TRUE, equalVar=FALSE, freeSig2=FALSE, Hier=TRUE,jump=.0001)</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uvsdSample_+3A_dat">dat</code></td>
<td>
<p>Data frame that must include variables
Scond,cond,sub,item,lag,resp.  Scond indexes studied/new, whereas
cond indexes conditions nested within the studied or new
conditions.  Indexes for Scond,cond, sub, item, and response must
start at zero and have no gaps (i.e., no skipped subject numbers). Lags
must be zero-centered.</p>
</td></tr>
<tr><td><code id="uvsdSample_+3A_m">M</code></td>
<td>
<p>Number of MCMC iterations.</p>
</td></tr>
<tr><td><code id="uvsdSample_+3A_keep">keep</code></td>
<td>
<p>Which MCMC iterations should be included in estimates and
returned.  Use keep to both get ride of burn-in, and thin chains if necessary</p>
</td></tr>
<tr><td><code id="uvsdSample_+3A_getdic">getDIC</code></td>
<td>
<p>Logical. should the function compute DIC value?  This
takes a while if M is large.</p>
</td></tr>
<tr><td><code id="uvsdSample_+3A_freecrit">freeCrit</code></td>
<td>
<p>Logical.  If TRUE (default) individual criteria vary
across people.  If false, all participants have the same criteria.
This should be set to false if there is only one participant, e.g.,
if averaging data over subjects.</p>
</td></tr>
<tr><td><code id="uvsdSample_+3A_equalvar">equalVar</code></td>
<td>
<p>Logical. If FALSE (default), unequal-variance model
is fit.  If TRUE, equal-variance model is fit.</p>
</td></tr>
<tr><td><code id="uvsdSample_+3A_freesig2">freeSig2</code></td>
<td>
<p>Logical.  If FALSE (default), one sigma is fit
for all participants and items (as in Pratte, et al., 2009).  If TRUE,
then an additive model is placed on the log of sigma2 (as in Pratte
and Rouder (2010).</p>
</td></tr>
<tr><td><code id="uvsdSample_+3A_hier">Hier</code></td>
<td>
<p>Logical. If TRUE then the variances of effects
(e.g., item effects) are estimated from the data, i.e., effects are
treated as random.  If FALSE then these variances are fixed to
2.0 (.5 for recollection effects), thus treating these effects as
fixed.  This option is there to allow for compairson with more
traditional approaches, and to see the effects of imposing
hierarcical structure.  It should always be set to TRUE in real
analysis, and is not even guaranteed to work if set to false.</p>
</td></tr>
<tr><td><code id="uvsdSample_+3A_jump">jump</code></td>
<td>
<p>The criteria and decorrelating steps utilize
Matropolis-Hastings sampling routines, which require tuning.  All
MCMC functions should self tune during the burnin perior (iterations
before keep), and they will alert you to the success of tuning.  If
acceptance rates are too low, &quot;jump&quot; should be decreased, if they
are too hight, &quot;jump&quot; should be increased.  Alternatively, or in
addition to adjusting &quot;jump&quot;, simply increase the burnin period
which will allow the function more time to self-tune.</p>
</td></tr>  
</table>


<h3>Value</h3>

<p>The function returns an internally defined &quot;uvsd&quot; S4 class that
includes the following components
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>Indexes which element of blocks contain grand means, mu</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>Indexes which element of blocks contain participant
effects, alpha</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Indexes which element of blocks contain item effects, beta</p>
</td></tr>
<tr><td><code>s2alpha</code></td>
<td>
<p>Indexes which element of blocks contain variance of
participant effects (alpha).</p>
</td></tr>
<tr><td><code>s2beta</code></td>
<td>
<p>Indexes which element of blocks contain variance of
item effects (beta).</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Indexes which element of blocks contain theta, the slope of
the lag effect</p>
</td></tr>
<tr><td><code>estN</code></td>
<td>
<p>Posterior means of block parameters for new-item means</p>
</td></tr>
<tr><td><code>estS</code></td>
<td>
<p>Posterior means of block parameters for studied-item means</p>
</td></tr>
<tr><td><code>estS2</code></td>
<td>
<p>Posterior means of block for studied-item variances.</p>
</td></tr>
<tr><td><code>estCrit</code></td>
<td>
<p>Posterior means of criteria</p>
</td></tr>
<tr><td><code>blockN</code></td>
<td>
<p>Each iteration for each parameter in the new-item mean
block.  Rows index iteration, columns index parameter.</p>
</td></tr>
<tr><td><code>blockS</code></td>
<td>
<p>Same as blockN, but for the studied-item means</p>
</td></tr>
<tr><td><code>blockS2</code></td>
<td>
<p>Same as blockN, but for variances of studied-item
distribution.  If equalVar=TRUE, then these values are all zero.  If
UVSD is fit but freeSig2=FALSE, then only the first element is
non-zero (mu).</p>
</td></tr>
<tr><td><code>s.crit</code></td>
<td>
<p>Samples of each criteria.</p>
</td></tr>
<tr><td><code>pD</code></td>
<td>
<p>Number of effective parameters used in DIC.  Note that this
should be smaller than the actual number of parameters, as
constraint from the hierarchical structure decreases the number of
effective parameters.</p>
</td></tr>
<tr><td><code>DIC</code></td>
<td>
<p>DIC value.  Smaller values indicate better fits.  Note that
DIC is notably biased toward complexity.</p>
</td></tr>
<tr><td><code>M</code></td>
<td>
<p>Number of MCMC iterations run</p>
</td></tr>
<tr><td><code>keep</code></td>
<td>
<p>MCMC iterations that were used for estimation and
returned</p>
</td></tr>
<tr><td><code>b0</code></td>
<td>
<p>Metropolis-Hastings acceptance rates for decorrelating
steps.  These should be between .2 and .6.  If they are not, the M,
keep, or jump need to be adjusted.</p>
</td></tr>
<tr><td><code>b0S2</code></td>
<td>
<p>If additive model is placed on Sigma2 (i.e.,
freeSigma2=TRUE),  then all parameters on S2 must be tuned.  b0S2 are
the acceptance probabilities for these parameters.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michael S. Pratte</p>


<h3>References</h3>

<p>See Pratte, Rouder, &amp; Morey (2009)</p>


<h3>See Also</h3>

<p>hbmem</p>


<h3>Examples</h3>

<pre><code class='language-R'>#In this example we generate data from UVSD with a different muN,muS,and
#Sigma2 for every person and item. These data are then fit with 
#hierarchical UVSD allowing participant or item effects on log(sigma2).

library(hbmem)
sim=uvsdSim(NN=1,muN=-.5,NS=2,muS=c(.5,1),I=30,J=300,s2aN = .2, s2bN = .2,
muS2=log(c(1.3,1.5)),s2aS=.2,s2bS=.2,s2aS2=.2,s2bS2=.2)
dat=as.data.frame(cbind(sim@subj,sim@item,sim@cond,sim@Scond,sim@lag,sim@resp))
colnames(dat)=c("sub","item","cond","Scond","lag","resp")

M=10 #Way too low for real analysis
keep=2:M
uvsd=uvsdSample(dat,M=M,keep=keep,equalVar=FALSE,freeSig2=TRUE,jump=.0001,Hier=1)

par(mfrow=c(3,2),pch=19,pty='s')
#Look at chains of MuN and MuS
matplot(uvsd@blockN[,uvsd@muN],t='l',xlab="Iteration",ylab="Mu-N")
abline(h=sim@muN,col="blue")
matplot(uvsd@blockS[,uvsd@muS],t='l',xlab="Iteration",ylab="Mu-S")
abline(h=sim@muS,col="blue")

#Estimates of strength effects as function of true values
plot(uvsd@estN[uvsd@alphaN]~sim@alphaN,xlab="True
Alpha-N",ylab="Est. Alpha-N");abline(0,1,col="blue")
plot(uvsd@estS[uvsd@alphaS]~sim@alphaS,xlab="True
Alpha-S",ylab="Est. Alpha-S");abline(0,1,col="blue")
plot(uvsd@estN[uvsd@betaN]~sim@betaN,xlab="True
Beta-N",ylab="Est. Beta-N");abline(0,1,col="blue")
plot(uvsd@estS[uvsd@betaS]~sim@betaS,xlab="True
Beta-S",ylab="Est. Beta-S");abline(0,1,col="blue")

#Sigma^2 effects
#Note that Sigma^2 is biased high with
#few participants and items.  This bias
#goes away with larger sample sizes.
par(mfrow=c(2,2),pch=19,pty='s')
matplot(sqrt(exp(uvsd@blockS2[,uvsd@muS])),t='l',xlab="Iteration",ylab="Mu-Sigma2")
abline(h=sqrt(exp(sim@muS2)),col="blue")
plot(uvsd@blockS2[,uvsd@thetaS],t='l')

plot(uvsd@estS2[uvsd@alphaS]~sim@alphaS2,xlab="True
Alpha-Sigma2",ylab="Est. Alpha-Sigma2");abline(0,1,col="blue")
plot(uvsd@estS2[uvsd@betaS]~sim@betaS2,xlab="True
Beta-Sigma2",ylab="Est. Beta-Sigma2");abline(0,1,col="blue")

#Look at some criteria
par(mfrow=c(2,2))
for(i in 1:4)
matplot(t(uvsd@s.crit[i,,]),t='l')
</code></pre>

<hr>
<h2 id='uvsdSim'>Function uvsdSim</h2><span id='topic+uvsdSim'></span>

<h3>Description</h3>

<p>Simulates data from a hierarchical UVSD model.</p>


<h3>Usage</h3>

<pre><code class='language-R'>uvsdSim(NN = 2, NS = 1, I = 30, J = 200, K = 6, muN = c(-0.5, 
    -0.2), s2aN = 0.2, s2bN = 0.2, muS = 0.5, s2aS = 0.2, s2bS = 0.2, 
    muS2 = log(1), s2aS2 = 0, s2bS2 = 0,lagEffect = -0.001,
crit = matrix(rep(c(-1.5,-0.5, 0, 0.5, 1.5), each = I), ncol = (K - 1)))</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="uvsdSim_+3A_nn">NN</code></td>
<td>
<p>Number of conditions for new words.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_ns">NS</code></td>
<td>
<p>Number of conditions for studied words.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_i">I</code></td>
<td>
<p>Number of participants.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_j">J</code></td>
<td>
<p>Number of items.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_k">K</code></td>
<td>
<p>Number of response options.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_mun">muN</code></td>
<td>
<p>Mean of new-item distribution.  If NN is greater than 1,
then muN must be a vector of length NN.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_s2an">s2aN</code></td>
<td>
<p>Variance of participant effects on mean of new-item
distribution.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_s2bn">s2bN</code></td>
<td>
<p>Variance of item effects on mean of new-item distribution.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_mus">muS</code></td>
<td>
<p>Mean of studied-item distribution.  If NS is greater than
1, then muS must be a vector of length NS.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_s2as">s2aS</code></td>
<td>
<p>Variance of participant effects on mean of studied-item
distribution.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_s2bs">s2bS</code></td>
<td>
<p>Variance of item effects on mean of studied-item distribution.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_lageffect">lagEffect</code></td>
<td>
<p>Magnitude of linear lag effect on both studied-item
distribution and log(sigma2).</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_mus2">muS2</code></td>
<td>
<p>Mean variance of studied-item distribution, sigma2</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_s2as2">s2aS2</code></td>
<td>
<p>Variance of participant effects sigma2.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_s2bs2">s2bS2</code></td>
<td>
<p>Variance of item effects on sigma2.</p>
</td></tr>
<tr><td><code id="uvsdSim_+3A_crit">crit</code></td>
<td>
<p>Matrix of criteria (not including -Inf or Inf).  Columns
correspond to criteria, rows correspond to participants.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns an internally defined &quot;uvsdSim&quot; structure.</p>


<h3>Author(s)</h3>

<p>Michael S. Pratte</p>


<h3>References</h3>

<p>See Pratte, Rouder, &amp; Morey (2009)</p>


<h3>See Also</h3>

<p>hbmem</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(hbmem)
#Data from hiererchial model
sim=uvsdSim() 
slotNames(sim) 
table(sim@resp,sim@Scond,sim@cond)

#Usefull to make data.frame for passing to model-fitting functions
dat=as.data.frame(cbind(sim@subj,sim@item,sim@cond,sim@Scond,sim@lag,sim@resp))
colnames(dat)=c("sub","item","cond","Scond","lag","resp")

table(dat$resp,dat$Scond,dat$cond)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
