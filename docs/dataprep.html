<!DOCTYPE html><html lang="en"><head><title>Help for package dataprep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dataprep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#condextr'>
<p>Remove outliers using point-by-point weighed outlier removal by conditional extremum</p></a></li>
<li><a href='#data'>
<p>Example data (particle number concentrations in SMEAR I Varrio forest)</p></a></li>
<li><a href='#data1'>
<p>Example data (data1, particle number concentrations in SMEAR I Varrio forest)</p></a></li>
<li><a href='#dataprep'>
<p>Data preprocessing with multiple steps in one function</p></a></li>
<li><a href='#descdata'>
<p>Fast descriptive statistics</p></a></li>
<li><a href='#descplot'>
<p>View the descriptive statistics via plot</p></a></li>
<li><a href='#melt'>
<p>Turn variable names and values into two columns</p></a></li>
<li><a href='#obsedele'>
<p>Delete observations with variable(s) containing too many consecutive missing values (NA) in time series</p></a></li>
<li><a href='#optisolu'>
<p>Find an optimal combination of <code>interval</code> and <code>times</code> for <code>condextr</code></p></a></li>
<li><a href='#percdata'>
<p>Calculate the top and bottom percentiles of each selected variable</p></a></li>
<li><a href='#percoutl'>
<p>Traditional percentile-based outlier removal</p></a></li>
<li><a href='#percplot'>
<p>Plot the top and bottom percentiles of each selected variable</p></a></li>
<li><a href='#shorvalu'>
<p>Interpolation with values to refer to within short periods</p></a></li>
<li><a href='#varidele'>
<p>Delete variables containing too many missing values (NA)</p></a></li>
<li><a href='#zerona'>
<p>Turn zeros to missing values</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Efficient and Flexible Data Preprocessing Tools</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.5</td>
</tr>
<tr>
<td>Author:</td>
<td>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;, Hao Wu, Hai-Yan Li, Qiang Zhang, Zhanqing Li, Ke-Bin He, Lanzhou University, Tsinghua University</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficiently and flexibly preprocess data using a set of data filtering, deletion, and interpolation tools.
    These data preprocessing methods are developed based on the principles of completeness, accuracy, threshold method, and linear interpolation and through the setting of constraint conditions, time completion &amp; recovery, and fast &amp; efficient calculation and grouping.
    Key preprocessing steps include deletions of variables and observations, outlier removal, and missing values (NA) interpolation, which are dependent on the incomplete and dispersed degrees of raw data.
    They clean data more accurately, keep more samples, and add no outliers after interpolation, compared with ordinary methods.
    Auto-identification of consecutive NA via run-length based grouping is used in observation deletion, outlier removal, and NA interpolation;
    thus, new outliers are not generated in interpolation. Conditional extremum is proposed to realize point-by-point weighed outlier removal that saves non-outliers from being removed.
    Plus, time series interpolation with values to refer to within short periods further ensures reliable interpolation.
    These methods are based on and improved from the reference: Liang, C.-S., Wu, H., Li, H.-Y., Zhang, Q., Li, Z. &amp; He, K.-B. (2020) &lt;<a href="https://doi.org/10.1016%2Fj.scitotenv.2020.140923">doi:10.1016/j.scitotenv.2020.140923</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, scales, foreach, doParallel, dplyr, reshape2,
data.table, zoo</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-15 11:42:46 UTC; 92576</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-15 13:32:42 UTC</td>
</tr>
</table>
<hr>
<h2 id='condextr'>
Remove outliers using point-by-point weighed outlier removal by conditional extremum
</h2><span id='topic+condextr'></span>

<h3>Description</h3>

<p>Care is needed when dealing with outliers that are common real-life phenomena besides missing values in data. Unfortunately, many non-outliers may be removed by a one-for-all threshold method, which will be largely avoided if a one-by-one considered way is developed and applied. The <code>condextr</code> proposed here considers every value (point) that will potentially be removed, combining constraint conditions and extremum (maximum and minimum). Therefore, it is a function of point-by-point weighed outlier removal by conditional extremum. Observation deletion is combined in the process of outlier removal since large gaps consisted of excessive missing values may be formed in time series after removing certain outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>condextr(data, start = NULL, end = NULL, group = NULL, top = 0.995,
top.error = 0.1, top.magnitude = 0.2, bottom = 0.0025, bottom.error = 0.2,
bottom.magnitude = 0.4, interval = 10, by = "min", half = 30,
times = 10, cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="condextr_+3A_data">data</code></td>
<td>

<p>A data frame containing outliers (and missing values). Its columns from <code>start</code> to <code>end</code> will be checked.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_start">start</code></td>
<td>

<p>The column number of the first selected variable.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_end">end</code></td>
<td>

<p>The column number of the last selected variable.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_group">group</code></td>
<td>

<p>The column number of the grouping variable. It can be selected according to whether the data needs to be processed in groups. If grouping is not required, leave it default (NULL); if grouping is required, set <code>group</code> as the column number (position) where the grouping variable is located. If there are more than one grouping variable, it can be turned into a longer group through combination and transformation in advance.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_top">top</code></td>
<td>

<p>The top percentile is 0.995 by default.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_top.error">top.error</code></td>
<td>

<p>The top allowable error coefficient is 0.1 by default.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_top.magnitude">top.magnitude</code></td>
<td>

<p>The order of magnitude coefficient of the top error is 0.2 by default.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_bottom">bottom</code></td>
<td>

<p>The bottom percentile is 0.0025 by default.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_bottom.error">bottom.error</code></td>
<td>

<p>The bottom allowable error coefficient is 0.2 by default.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_bottom.magnitude">bottom.magnitude</code></td>
<td>

<p>The order of magnitude coefficient of the bottom error is 0.4 by default.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_interval">interval</code></td>
<td>

<p>The interval of observation deletion, i.e. the number of outlier deletions before each observation deletion, is 10 by default.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_by">by</code></td>
<td>

<p>The time extension unit by is a minute (&quot;min&quot;) by default. The user can specify other time units. For example, &quot;5 min&quot; means that the time extension unit is 5 minutes.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_half">half</code></td>
<td>

<p>Half window size of hourly moving average. It is 30 (minutes) by default, which is determined by the time expansion unit minute (&quot;min&quot;).
</p>
</td></tr>
<tr><td><code id="condextr_+3A_times">times</code></td>
<td>

<p>The number of observation deletions in outlier removal is 10 by default.
</p>
</td></tr>
<tr><td><code id="condextr_+3A_cores">cores</code></td>
<td>

<p>The number of CPU cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A point-by-point constraint (consideration) outlier removal method based on conditional extremum is proposed, which is more advantageous than the traditional &quot;one size fits all&quot; percentile deletion method in deleting outliers. Moreover, it emphasizes that the outlier removal should be grouped if there are groups such as month because of the value difference among different groups.
</p>


<h3>Value</h3>

<p>A data frame after removing outliers.
</p>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>
<p>2. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2017. dplyr: A Grammar of Data Manipulation. 0.7.4 ed. http://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr.
</p>
<p>3. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2019. dplyr: A Grammar of Data Manipulation. R package version 0.8.3. https://CRAN.R-project.org/package=dplyr.
</p>
<p>4. Dowle, M., Srinivasan, A., Gorecki, J., Short, T., Lianoglou, S., Antonyan, E., 2017. data.table: Extension of 'data.frame', 1.10.4-3 ed, http://r-datatable.com.
</p>
<p>5. Dowle, M., Srinivasan, A., 2021. data.table: Extension of 'data.frame'. R package version 1.14.0. https://CRAN.R-project.org/package=data.table.
</p>
<p>6. Wallig, M., Microsoft &amp; Weston, S. 2020. foreach: Provides Foreach Looping Construct. R package version 1.5.0. https://CRAN.R-project.org/package=foreach.
</p>
<p>7. Ooi, H., Corporation, M. &amp; Weston, S. 2019. doParallel: Foreach Parallel Adaptor for the 'parallel' Package. R package version 1.0.15. https://CRAN.R-project.org/package=doParallel.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Remove outliers by condextr after deleting observations by obsedele
# 337 observations will be deleted in obsedele(data[,c(1:4,27:61)],5,39,4).
# Further, 362 observations will be deleted in condextr by obsedele
# Here, for executing time reason, a smaller example is used to show.
# Besides, only 2 cores are used for submission test.
condextr(obsedele(data[1:500,c(1,4,17:19)],3,5,2,cores=2),3,5,2,cores=2)
</code></pre>

<hr>
<h2 id='data'>
Example data (particle number concentrations in SMEAR I Varrio forest)
</h2><span id='topic+data'></span>

<h3>Description</h3>

<p>The raw data is downloaded from https://smear.avaa.csc.fi/download.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data</code></pre>


<h3>Format</h3>

<p>A data frame with 7640 observations on the following 65 variables.
</p>

<dl>
<dt><code>date</code></dt><dd><p>a POSIXct</p>
</dd>
<dt><code>tconc</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TPNC</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>monthyear</code></dt><dd><p>a character vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;1&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;1.12&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;1.26&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;1.41&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;1.58&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;1.78&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;2&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;2.24&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;2.51&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;2.82&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;3.16&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;3.55&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;3.98&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;4.47&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;5.01&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;5.62&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;6.31&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;7.08&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;7.94&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;8.91&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;10&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;11.2&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;12.6&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;14.1&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;15.8&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;17.8&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;20&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;22.4&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;25.1&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;28.2&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;31.6&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;35.5&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;39.8&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;44.7&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;50.1&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;56.2&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;63.1&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;70.8&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;79.4&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;89.1&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;100&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;112&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;126&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;141&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;158&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;178&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;200&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;224&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;251&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;282&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;316&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;355&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;398&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;447&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;501&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;562&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;631&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;708&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;794&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;891&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
<dt>&lsquo;<span class="samp">&#8288;1000&#8288;</span>&rsquo;</dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>https://smear.avaa.csc.fi/download
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data
## maybe str(data)
</code></pre>

<hr>
<h2 id='data1'>
Example data (data1, particle number concentrations in SMEAR I Varrio forest)
</h2><span id='topic+data1'></span>

<h3>Description</h3>

<p>Calculated from the raw data that is downloaded from https://smear.avaa.csc.fi/download.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data1</code></pre>


<h3>Format</h3>

<p>A data frame with 7640 observations on the following 7 variables.
</p>

<dl>
<dt><code>date</code></dt><dd><p>a POSIXct</p>
</dd>
<dt><code>monthyear</code></dt><dd><p>a character vector</p>
</dd>
<dt><code>Nucleation</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Aitken</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Accumulation</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>tconc</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>TPNC</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>https://smear.avaa.csc.fi/download
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data1
## maybe str(data1)
</code></pre>

<hr>
<h2 id='dataprep'>
Data preprocessing with multiple steps in one function
</h2><span id='topic+dataprep'></span>

<h3>Description</h3>

<p>The four steps, i.e., variable deletion by <code>varidele</code>, observation deletion by <code>obsedele</code>, outlier removal by <code>condextr</code>, and missing value interpolation by <code>shorvalu</code> can be finished in <code>dataprep</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dataprep(data, start = NULL, end = NULL, group = NULL, optimal = FALSE,
interval = 10, times = 10, fraction = 0.25,
top = 0.995, top.error = 0.1, top.magnitude = 0.2,
bottom = 0.0025, bottom.error = 0.2, bottom.magnitude = 0.4, by = "min",
half = 30, intervals = 30, cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dataprep_+3A_data">data</code></td>
<td>

<p>A data frame containing outliers (and missing values). Its columns from <code>start</code> to <code>end</code> will be checked.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_start">start</code></td>
<td>

<p>The column number of the first selected variable.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_end">end</code></td>
<td>

<p>The column number of the last selected variable.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_group">group</code></td>
<td>

<p>The column number of the grouping variable. It can be selected according to whether the data needs to be processed in groups. If grouping is not required, leave it default (NULL); if grouping is required, set <code>group</code> as the column number (position) where the grouping variable is located. If there are more than one grouping variable, it can be turned into a longer group through combination and transformation in advance.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_optimal">optimal</code></td>
<td>

<p>A Boolean to decide whether the <code>optisolu</code> should be used to find optimal <code>interval</code> and <code>times</code> for <code>condextr</code>.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_interval">interval</code></td>
<td>

<p>The interval of observation deletion, i.e. the number of outlier deletions before each observation deletion, is 10 by default.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_times">times</code></td>
<td>

<p>The number of observation deletions in outlier removal is 10 by default.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_fraction">fraction</code></td>
<td>

<p>The proportion of missing values of variables. Default is 0.25.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_top">top</code></td>
<td>

<p>The top percentile is 0.995 by default.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_top.error">top.error</code></td>
<td>

<p>The top allowable error coefficient is 0.1 by default.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_top.magnitude">top.magnitude</code></td>
<td>

<p>The order of magnitude coefficient of the top error is 0.2 by default.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_bottom">bottom</code></td>
<td>

<p>The bottom percentile is 0.0025 by default.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_bottom.error">bottom.error</code></td>
<td>

<p>The bottom allowable error coefficient is 0.2 by default.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_bottom.magnitude">bottom.magnitude</code></td>
<td>

<p>The order of magnitude coefficient of the bottom error is 0.4 by default.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_by">by</code></td>
<td>

<p>The time extension unit by is a minute (&quot;min&quot;) by default. The user can specify other time units. For example, &quot;5 min&quot; means that the time extension unit is 5 minutes.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_half">half</code></td>
<td>

<p>Half window size of hourly moving average. It is 30 (minutes) by default, which is determined by the time expansion unit minute (&quot;min&quot;).
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_intervals">intervals</code></td>
<td>

<p>The time gap of dividing periods as groups, is 30 (minutes) by default. This confines the interpolation inside short periods so that each interpolation has observed value(s) to refer to within every half an hour.
</p>
</td></tr>
<tr><td><code id="dataprep_+3A_cores">cores</code></td>
<td>

<p>The number of CPU cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If optimal = T, relatively much more time will be needed to finish the data preprocessing, but it gets better final result.
</p>


<h3>Value</h3>

<p>A preprocessed data frame after variable deletion, observation deletion, outlier removal, and missing value interpolation.
</p>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>
<p>2. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2017. dplyr: A Grammar of Data Manipulation. 0.7.4 ed. http://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr.
</p>
<p>3. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2019. dplyr: A Grammar of Data Manipulation. R package version 0.8.3. https://CRAN.R-project.org/package=dplyr.
</p>
<p>4. Dowle, M., Srinivasan, A., Gorecki, J., Short, T., Lianoglou, S., Antonyan, E., 2017. data.table: Extension of 'data.frame', 1.10.4-3 ed, http://r-datatable.com.
</p>
<p>5. Dowle, M., Srinivasan, A., 2021. data.table: Extension of 'data.frame'. R package version 1.14.0. https://CRAN.R-project.org/package=data.table.
</p>
<p>6. Wallig, M., Microsoft &amp; Weston, S. 2020. foreach: Provides Foreach Looping Construct. R package version 1.5.0. https://CRAN.R-project.org/package=foreach.
</p>
<p>7. Ooi, H., Corporation, M. &amp; Weston, S. 2019. doParallel: Foreach Parallel Adaptor for the 'parallel' Package. R package version 1.0.15. https://CRAN.R-project.org/package=doParallel.
</p>
<p>8. Zeileis, A. &amp; Grothendieck, G. 2005. zoo: S3 infrastructure for regular and irregular time series. Journal of Statistical Software, 14(6):1-27.
</p>
<p>9. Zeileis, A., Grothendieck, G. &amp; Ryan, J.A. 2019. zoo: S3 Infrastructure for Regular and Irregular Time Series (Z's Ordered Observations). R package version 1.8-6. https://cran.r-project.org/web/packages/zoo/.
</p>


<h3>See Also</h3>

<p><code>dataprep::varidele</code>, <code>dataprep::obsedele</code>, <code>dataprep::condextr</code>, <code>dataprep::shorvalu</code> and <code>dataprep::optisolu</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Combine 4 steps in one function
# In dataprep(data,5,65,4), 26 variables, 1097 outliers and 699 observations will be deleted
# Besides, 6012 missing values will be replaced
# Setting optimal=T will get optimized result
# Here, for executing time reason, a smaller example is used to show
dataprep(data[1:60,c(1,4,18:19)],3,4,2,
interval=2,times=1,cores=2)

# Check if results are the same
identical(shorvalu(condextr(obsedele(varidele(
data[1:60,c(1,4,18:19)],3,4),3,4,2,cores=2),3,4,2,
interval=2,times=1,cores=2),3,4),
dataprep(data[1:60,c(1,4,18:19)],3,4,2,
interval=2,times=1,cores=2))
</code></pre>

<hr>
<h2 id='descdata'>
Fast descriptive statistics
</h2><span id='topic+descdata'></span>

<h3>Description</h3>

<p>It describes data using R basic functions, without calling other packages to avoid redundant calculations, which is faster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>descdata(data, start = NULL, end = NULL, stats= 1:9, first = "variables")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="descdata_+3A_data">data</code></td>
<td>

<p>A data frame to describe, from the column <code>start</code> to the column <code>end</code>.
</p>
</td></tr>
<tr><td><code id="descdata_+3A_start">start</code></td>
<td>

<p>The column number of the first variable to describe.
</p>
</td></tr>
<tr><td><code id="descdata_+3A_end">end</code></td>
<td>

<p>The column number of the last variable to describe.
</p>
</td></tr>
<tr><td><code id="descdata_+3A_stats">stats</code></td>
<td>

<p>Selecting or rearranging the items from the 9 statistics, i.e., n, na, mean, sd, median, trimmed, min, max, and IQR. It can be a vector or a single value, in 'character' or 'numeric' class.
</p>
</td></tr>
<tr><td><code id="descdata_+3A_first">first</code></td>
<td>

<p>The name of the first column of the output. It is the general name of the items (variables).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function can be used for different types of data, as long as the variables are numeric. Because it describes the data frame from the column <code>start</code> to the column <code>end</code>, the variables need to be linked together instead of being scattered.
</p>


<h3>Value</h3>

<p>A data frame of descriptive statistics:
</p>
<table role = "presentation">
<tr><td><code>size</code></td>
<td>
<p>default general name of items (variables). Users can define it via the parameter first.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of valid cases</p>
</td></tr>
<tr><td><code>na</code></td>
<td>
<p>number of invalid cases</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>mean of each item</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>standard deviation</p>
</td></tr>
<tr><td><code>median</code></td>
<td>
<p>median of each item</p>
</td></tr>
<tr><td><code>trimmed</code></td>
<td>
<p>trimmed mean (with trim defaulting to .1)</p>
</td></tr>
<tr><td><code>min</code></td>
<td>
<p>minimum of each item</p>
</td></tr>
<tr><td><code>max</code></td>
<td>
<p>maximum of each item</p>
</td></tr>
<tr><td><code>IQR</code></td>
<td>
<p>interquartile range of each item</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>


<h3>See Also</h3>

<p><code>dataprep::descplot</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Variable names are essentially numeric
descdata(data,5,65)
# Use numbers to select statistics
descdata(data,5,65,c(2,7:9))
# Use characters to select statistics
descdata(data,5,65,c('na','min','max','IQR'))

# When type of variable names is character
descdata(data1,3,7)
# Use numbers to select statistics
descdata(data1,3,7,c(2,7:9))
# Use characters to select statistics
descdata(data1,3,7,c('na','min','max','IQR'))
</code></pre>

<hr>
<h2 id='descplot'>
View the descriptive statistics via plot
</h2><span id='topic+descplot'></span>

<h3>Description</h3>

<p>It applies to an original (a raw) data and produces a plot to describe the data with 9 statistics including n, na, mean, sd, median, trimmed, min, max, and IQR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>descplot(data, start = NULL, end = NULL, stats= 1:9, first = "variables")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="descplot_+3A_data">data</code></td>
<td>

<p>A data frame to describe, from the column <code>start</code> to the column <code>end</code>.
</p>
</td></tr>
<tr><td><code id="descplot_+3A_start">start</code></td>
<td>

<p>The column number of the first variable to describe.
</p>
</td></tr>
<tr><td><code id="descplot_+3A_end">end</code></td>
<td>

<p>The column number of the last variable to describe.
</p>
</td></tr>
<tr><td><code id="descplot_+3A_stats">stats</code></td>
<td>

<p>Selecting or rearranging the items from the 9 statistics, i.e., n, na, mean, sd, median, trimmed, min, max, and IQR. It can be a vector or a single value, in 'character' or 'numeric' class.
</p>
</td></tr>
<tr><td><code id="descplot_+3A_first">first</code></td>
<td>

<p>The name of the first column of the output. It is the general name of the items (variables).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function will describe the data first using descdata. Then, A plot to show the result will be produced using the package <code>ggplot2</code> (coupled with self-defined <code>melt</code> or <code>reshape2::melt</code> to melt the intermediate data). The variables from <code>start</code> to <code>end</code> need to be linked together instead of being scattered.
</p>


<h3>Value</h3>

<p>A plot to show the descriptive result of the data, including:
</p>
<table role = "presentation">
<tr><td><code>size</code></td>
<td>
<p>default general name of items (variables). Users can define it via the parameter <code>first</code>.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>number of valid cases</p>
</td></tr>
<tr><td><code>na</code></td>
<td>
<p>number of invalid cases</p>
</td></tr>
<tr><td><code>mean</code></td>
<td>
<p>mean of each item</p>
</td></tr>
<tr><td><code>sd</code></td>
<td>
<p>standard deviation</p>
</td></tr>
<tr><td><code>median</code></td>
<td>
<p>median of each item</p>
</td></tr>
<tr><td><code>trimmed</code></td>
<td>
<p>trimmed mean (with trim defaulting to .1)</p>
</td></tr>
<tr><td><code>min</code></td>
<td>
<p>minimum of each item</p>
</td></tr>
<tr><td><code>max</code></td>
<td>
<p>maximum of each item</p>
</td></tr>
<tr><td><code>IQR</code></td>
<td>
<p>interquartile range of each item</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>
<p>2. Wickham, H. 2007. Reshaping data with the reshape package. Journal of Statistical Software, 21(12):1-20.
</p>
<p>3. Wickham, H. 2009. ggplot2: Elegant Graphics for Data Analysis. http://ggplot2.org: Springer-Verlag New York.
</p>
<p>4. Wickham, H. 2016. ggplot2: elegant graphics for data analysis. Springer-Verlag New York.
</p>


<h3>See Also</h3>

<p><code>dataprep::descdata</code> and <code>dataprep::melt</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Line plots for variable names that are essentially numeric
descplot(data,5,65)
# Use numbers to select statistics
descplot(data,5,65,c(2,7:9))
# Use characters to select statistics
descplot(data,5,65,c('na','min','max','IQR'))

# Bar charts for type of variable names that is character
descplot(data1,3,7)
# Use numbers to select statistics
descplot(data1,3,7,7:9)
# Use characters to select statistics
descplot(data1,3,7,c('min','max','IQR'))
</code></pre>

<hr>
<h2 id='melt'>
Turn variable names and values into two columns
</h2><span id='topic+melt'></span>

<h3>Description</h3>

<p>Turn the names and values of all pending variables into two columns. These variables are inversely selected inside function (<code>cols</code>) and waiting to be melted. After melting, the data format changes from wide to long.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>melt(data, cols = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="melt_+3A_data">data</code></td>
<td>

<p>A data frame to melt, from the column <code>start</code> to the column <code>end</code>.
</p>
</td></tr>
<tr><td><code id="melt_+3A_cols">cols</code></td>
<td>

<p>Inversely selected columns inside function, except which are columns waiting to be melted.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function (<code>dataprep::melt</code>) will be used when <code>reshape2</code> is not installed.
</p>


<h3>Value</h3>

<p>A long-format data frame from its original wide format.
</p>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>
<p>2. Wickham, H. 2007. Reshaping data with the reshape package. Journal of Statistical Software, 21(12):1-20.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># The first pending variable contains only NA
melt(data,1:4)

# Number concentrations of modes and total particles are not NA
melt(data1,1:2)
</code></pre>

<hr>
<h2 id='obsedele'>
Delete observations with variable(s) containing too many consecutive missing values (NA) in time series
</h2><span id='topic+obsedele'></span>

<h3>Description</h3>

<p>The description of varidele mentions that missing values are common in real data but excessive missing values would led to inaccurate information and conclusions about the data. To control and improve the quality of original data, besides deleting the variables with too many missing values, the observations with one or more variables containing excessive consecutive missing values in time series should further be deleted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>obsedele(data, start = NULL, end = NULL, group = NULL, by = "min",
half = 30, cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="obsedele_+3A_data">data</code></td>
<td>

<p>A data frame containing variables with too many consecutive missing values (NA) in time series. Its columns from <code>start</code> to <code>end</code> will be checked.
</p>
</td></tr>
<tr><td><code id="obsedele_+3A_start">start</code></td>
<td>

<p>The column number of the first selected variable.
</p>
</td></tr>
<tr><td><code id="obsedele_+3A_end">end</code></td>
<td>

<p>The column number of the last selected variable.
</p>
</td></tr>
<tr><td><code id="obsedele_+3A_group">group</code></td>
<td>

<p>The column number of the grouping variable. It can be selected according to whether the data needs to be processed in groups. If grouping is not required, leave it default (NULL); if grouping is required, set <code>group</code> as the column number (position) where the grouping variable is located. If there are more than one grouping variable, it can be turned into a longer group through combination and transformation in advance.
</p>
</td></tr>
<tr><td><code id="obsedele_+3A_by">by</code></td>
<td>

<p>The time extension unit <code>by</code> is a minute (&quot;min&quot;) by default. The user can specify other time units. For example, &quot;5 min&quot; means that the time extension unit is 5 minutes.
</p>
</td></tr>
<tr><td><code id="obsedele_+3A_half">half</code></td>
<td>

<p>Half window size of hourly moving average. It is 30 (minutes) by default, which is determined by the time expansion unit minute (&quot;min&quot;). Users can set its value as required.
</p>
</td></tr>
<tr><td><code id="obsedele_+3A_cores">cores</code></td>
<td>

<p>The number of CPU cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>How to delete observations based on consecutive missing value? The idea here is to remove the observations with incomplete half-hour averages, that is, the observations with at least one variable missing more than half an hour. Besides the design of flexible constraints, fast and efficient algorithm is also used, which saves much more time. Using  basic functions such <code>merge</code> and <code>seq</code> (in loop) temporarily to extend the full time period and using the fast and efficient  <code>data.table::rleid</code>, <code>data.table::rowid</code>, and <code>data.table::setorder</code> to realize run-length based grouping (even faster than calculating moving average by C++ optimized algorithm) are very important to quickly detect consecutive missing values. For the loop, parallel computing can be conducted using packages <code>parallel</code>, <code>doParallel</code>, and <code>foreach</code>. Further, this method will also be used to delete outliers. In this way, it ensures that the observations with excessive consecutive missing values are deleted completely and the interpolation in time series is reasonable.
</p>


<h3>Value</h3>

<p>A data frame after deleting observations with too many consecutive missing values in time series.
</p>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>
<p>2. Dowle, M., Srinivasan, A., Gorecki, J., Short, T., Lianoglou, S., Antonyan, E., 2017. data.table: Extension of 'data.frame', 1.10.4-3 ed, http://r-datatable.com.
</p>
<p>3. Dowle, M., Srinivasan, A., 2021. data.table: Extension of 'data.frame'. R package version 1.14.0. https://CRAN.R-project.org/package=data.table.
</p>
<p>4. Wallig, M., Microsoft &amp; Weston, S. 2020. foreach: Provides Foreach Looping Construct. R package version 1.5.0. https://CRAN.R-project.org/package=foreach.
</p>
<p>5. Ooi, H., Corporation, M. &amp; Weston, S. 2019. doParallel: Foreach Parallel Adaptor for the 'parallel' Package. R package version 1.0.15. https://CRAN.R-project.org/package=doParallel.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Select start as 27 and end as 61 according to varidele
# This selection ignores the first 22 and the last 4 variables
# Not show the first 22 variables dropped by varidele
# A total of 39 variables left (65 - 22 - 4)
# Here, a smaller example is used for saving time.
# Besides, only 2 cores are used for submission test.

obsedele(data[c(1:200,3255:3454),c(1:4,27:61)],5,39,4,cores=2)

</code></pre>

<hr>
<h2 id='optisolu'>
Find an optimal combination of <code>interval</code> and <code>times</code> for <code>condextr</code>
</h2><span id='topic+optisolu'></span>

<h3>Description</h3>

<p>Optimal values of <code>interval</code> and <code>times</code> in the proposed conditional extremum based outlier removal method, i.e., <code>condextr</code> can be searched out after comparing with the traditional &quot;one size fits all&quot; percentile deletion method in deleting outliers. Three parameters are used for this comparison, including sample deletion ratio (SDR), outlier removal ratio (ORR), and signal-to-noise ratio (SNR).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optisolu(data, start = NULL, end = NULL, group = NULL, interval = 35, times = 10,
top = 0.995, top.error = 0.1, top.magnitude = 0.2,
bottom = 0.0025, bottom.error = 0.2, bottom.magnitude = 0.4,
by = "min", half = 30, cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optisolu_+3A_data">data</code></td>
<td>

<p>A data frame containing outliers (and missing values). Its columns from <code>start</code> to <code>end</code> will be checked.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_start">start</code></td>
<td>

<p>The column number of the first selected variable.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_end">end</code></td>
<td>

<p>The column number of the last selected variable.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_group">group</code></td>
<td>

<p>The column number of the grouping variable. It can be selected according to whether the data needs to be processed in groups. If grouping is not required, leave it default (NULL); if grouping is required, set <code>group</code> as the column number (position) where the grouping variable is located. If there are more than one grouping variable, it can be turned into a longer group through combination and transformation in advance.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_interval">interval</code></td>
<td>

<p>The interval of observation deletion, i.e., the number of outlier deletions before each observation deletion, is 35 by default. Its values from 1 to <code>interval</code> will be tested for optimal solution.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_times">times</code></td>
<td>

<p>The number of observation deletions in outlier removal is 10 by default. The values from 1 to <code>times</code> will be tested for optimal solution.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_top">top</code></td>
<td>

<p>The top percentile is 0.995 by default.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_top.error">top.error</code></td>
<td>

<p>The top allowable error coefficient is 0.1 by default.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_top.magnitude">top.magnitude</code></td>
<td>

<p>The order of magnitude coefficient of the top error is 0.2 by default.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_bottom">bottom</code></td>
<td>

<p>The bottom percentile is 0.0025 by default.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_bottom.error">bottom.error</code></td>
<td>

<p>The bottom allowable error coefficient is 0.2 by default.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_bottom.magnitude">bottom.magnitude</code></td>
<td>

<p>The order of magnitude coefficient of the bottom error is 0.4 by default.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_by">by</code></td>
<td>

<p>The time extension unit by is a minute (&quot;min&quot;) by default. The user can specify other time units. For example, &quot;5 min&quot; means that the time extension unit is 5 minutes.
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_half">half</code></td>
<td>

<p>Half window size of hourly moving average. It is 30 (minutes) by default, which is determined by the time expansion unit minute (&quot;min&quot;).
</p>
</td></tr>
<tr><td><code id="optisolu_+3A_cores">cores</code></td>
<td>

<p>The number of CPU cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The three ratios offer indices to show the quality of outlier removal methods. Besides, other parameters such as new outlier production (NOP) are also important. Since the preprocessing roadmap is based on the ideas of grouping, both flexible and strict constraints for outliers, and interpolation within short period and with effective observed values, the new outlier production is greatly restricted.
</p>


<h3>Value</h3>

<p>A data frame indicating the quality of outlier remove by <code>condextr</code> with different values of <code>interval</code> and <code>times</code>. A total of 9 columns are listed in it.
</p>
<table role = "presentation">
<tr><td><code>case</code></td>
<td>
<p>Order of combination of <code>interval</code> and <code>times</code></p>
</td></tr>
<tr><td><code>interval</code></td>
<td>

<p>The interval of observation deletion, i.e., the number of outlier deletions before each observation deletion</p>
</td></tr>
<tr><td><code>times</code></td>
<td>
<p>The number of observation deletions in outlier removal</p>
</td></tr>
<tr><td><code>sdr</code></td>
<td>
<p>Sample deletion ratio (SDR)</p>
</td></tr>
<tr><td><code>orr</code></td>
<td>
<p>Outlier removal ratio (ORR)</p>
</td></tr>
<tr><td><code>snr</code></td>
<td>
<p>Signal-to-noise ratio (SNR)</p>
</td></tr>
<tr><td><code>index</code></td>
<td>
<p>Quality level of outlier removal based on the three parameters</p>
</td></tr>
<tr><td><code>relaindex</code></td>
<td>
<p>A relative form of the index</p>
</td></tr>
<tr><td><code>optimal</code></td>
<td>
<p>A Boolean variable to show if the result of conditional extremum is better, in terms of all the three parameters, than the traditional &quot;one size fits all&quot; percentile deletion method in deleting outliers.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>
<p>2. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2017. dplyr: A Grammar of Data Manipulation. 0.7.4 ed. http://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr.
</p>
<p>3. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2019. dplyr: A Grammar of Data Manipulation. R package version 0.8.3. https://CRAN.R-project.org/package=dplyr.
</p>
<p>4. Dowle, M., Srinivasan, A., Gorecki, J., Short, T., Lianoglou, S., Antonyan, E., 2017. data.table: Extension of 'data.frame', 1.10.4-3 ed, http://r-datatable.com.
</p>
<p>5. Dowle, M., Srinivasan, A., 2021. data.table: Extension of 'data.frame'. R package version 1.14.0. https://CRAN.R-project.org/package=data.table.
</p>
<p>6. Wallig, M., Microsoft &amp; Weston, S. 2020. foreach: Provides Foreach Looping Construct. R package version 1.5.0. https://CRAN.R-project.org/package=foreach.
</p>
<p>7. Ooi, H., Corporation, M. &amp; Weston, S. 2019. doParallel: Foreach Parallel Adaptor for the 'parallel' Package. R package version 1.0.15. https://CRAN.R-project.org/package=doParallel.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Setting interval as 35 and times as 10 can find optimal solutions
# optisolu(obsedele(data[c(1:4,27:61)],5,39,4),5,39,4,35,10)
# Here, for executing time reason, a smaller example is used to show
# But too small interval and times will not get optimal solutions

optisolu(data[1:50,c(1,4,18:19)],3,4,2,2,1,cores=2)

</code></pre>

<hr>
<h2 id='percdata'>
Calculate the top and bottom percentiles of each selected variable
</h2><span id='topic+percdata'></span>

<h3>Description</h3>

<p>Outliers can be preliminarily checked by the calculated top and bottom percentiles. Basic R functions in packages from system library are used to get these percentiles of selected variables in data frames, instead of calling other packages. It saves time.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percdata(data, start = NULL, end = NULL, group = NULL, diff = 0.1, part = 'both')
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="percdata_+3A_data">data</code></td>
<td>

<p>A data frame to calculate percentiles, from the column <code>start</code> to the column <code>end</code>.
</p>
</td></tr>
<tr><td><code id="percdata_+3A_start">start</code></td>
<td>

<p>The column number of the first variable to calculate percentiles for.
</p>
</td></tr>
<tr><td><code id="percdata_+3A_end">end</code></td>
<td>

<p>The column number of the last variable to calculate percentiles for.
</p>
</td></tr>
<tr><td><code id="percdata_+3A_group">group</code></td>
<td>

<p>The column number of the grouping variable. It can be selected according to whether the data needs to be processed in groups. If grouping is not required, leave it default (NULL); if grouping is required, set <code>group</code> as the column number (position) where the grouping variable is located. If there are more than one grouping variable, it can be turned into a longer group through combination and transformation in advance.
</p>
</td></tr>
<tr><td><code id="percdata_+3A_diff">diff</code></td>
<td>

<p>The common difference between <code>quantile</code>'s <code>probs</code>. Default is 0.1.
</p>
</td></tr>
<tr><td><code id="percdata_+3A_part">part</code></td>
<td>

<p>The option of calculating bottom and/or top percentiles (parts). Default is 'both', or 2 for both bottom and top parts. Setting it as 'bottom' or 0 for bottom part and 'top' or 1 for top part.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data to be processed ranges from the column <code>start</code> to the last column <code>end</code>. The column numbers of these two columns are needed for the arguments. This requires that the variables of the data to be processed are arranged continuously in the database or table. Or else, it is necessary to move the columns in advance to make a continuous arrangement.
</p>


<h3>Value</h3>

<p>Top (highest or greatest) and bottom (lowest or smallest) percentiles are calculated. According to the default <code>diff</code> (=0.1), the calculated values are as follows.
</p>
<table role = "presentation">
<tr><td><code>0th</code></td>
<td>
<p>Quantile with <code>probs = 0</code></p>
</td></tr>
<tr><td><code>0.1th</code></td>
<td>
<p>Quantile with <code>probs = 0.001</code></p>
</td></tr>
<tr><td><code>0.2th</code></td>
<td>
<p>Quantile with <code>probs = 0.002</code></p>
</td></tr>
<tr><td><code>0.3th</code></td>
<td>
<p>Quantile with <code>probs = 0.003</code></p>
</td></tr>
<tr><td><code>0.4th</code></td>
<td>
<p>Quantile with <code>probs = 0.004</code></p>
</td></tr>
<tr><td><code>0.5th</code></td>
<td>
<p>Quantile with <code>probs = 0.005</code></p>
</td></tr>
<tr><td><code>99.5th</code></td>
<td>
<p>Quantile with <code>probs = 0.995</code></p>
</td></tr>
<tr><td><code>99.6th</code></td>
<td>
<p>Quantile with <code>probs = 0.996</code></p>
</td></tr>
<tr><td><code>99.7th</code></td>
<td>
<p>Quantile with <code>probs = 0.997</code></p>
</td></tr>
<tr><td><code>99.8th</code></td>
<td>
<p>Quantile with <code>probs = 0.998</code></p>
</td></tr>
<tr><td><code>99.9th</code></td>
<td>
<p>Quantile with <code>probs = 0.999</code></p>
</td></tr>
<tr><td><code>100th</code></td>
<td>
<p>Quantile with <code>probs = 1</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>


<h3>See Also</h3>

<p><code>dataprep::percplot</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Select the grouping variable and remaining variables after deletion by varidele.
# Column 4 ('monthyear') is the group and the fraction for varidele is 0.25.
# After extracting according to the result by varidele, the group is in the first column.
percdata(data[,c(4,27:61)],2,36,1)
</code></pre>

<hr>
<h2 id='percoutl'>
Traditional percentile-based outlier removal
</h2><span id='topic+percoutl'></span>

<h3>Description</h3>

<p>The percentile-based outlier removal methods usually take a quantile as a threshold and values above it will be deleted. Here, two quantiles are used for both the top and the bottom. For the bottom, accordingly, values below the quantile threshold will be removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percoutl(data, start = NULL, end = NULL, group = NULL,
top = 0.995, bottom = 0.0025, by = "min", half = 30, cores = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="percoutl_+3A_data">data</code></td>
<td>

<p>A data frame containing outliers (and missing values). Its columns from <code>start</code> to <code>end</code> will be checked.
</p>
</td></tr>
<tr><td><code id="percoutl_+3A_start">start</code></td>
<td>

<p>The column number of the first selected variable.
</p>
</td></tr>
<tr><td><code id="percoutl_+3A_end">end</code></td>
<td>

<p>The column number of the last selected variable.
</p>
</td></tr>
<tr><td><code id="percoutl_+3A_group">group</code></td>
<td>

<p>The column number of the grouping variable. It can be selected according to whether the data needs to be processed in groups. If grouping is not required, leave it default (NULL); if grouping is required, set <code>group</code> as the column number (position) where the grouping variable is located. If there are more than one grouping variable, it can be turned into a longer group through combination and transformation in advance.
</p>
</td></tr>
<tr><td><code id="percoutl_+3A_top">top</code></td>
<td>

<p>The top percentile is 0.995 by default.
</p>
</td></tr>
<tr><td><code id="percoutl_+3A_bottom">bottom</code></td>
<td>

<p>The bottom percentile is 0.0025 by default.
</p>
</td></tr>
<tr><td><code id="percoutl_+3A_by">by</code></td>
<td>

<p>The time extension unit by is a minute (&quot;min&quot;) by default. The user can specify other time units. For example, &quot;5 min&quot; means that the time extension unit is 5 minutes.
</p>
</td></tr>
<tr><td><code id="percoutl_+3A_half">half</code></td>
<td>

<p>Half window size of hourly moving average. It is 30 (minutes) by default, which is determined by the time expansion unit minute (&quot;min&quot;).
</p>
</td></tr>
<tr><td><code id="percoutl_+3A_cores">cores</code></td>
<td>

<p>The number of CPU cores.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike <code>condextr</code>, a point-by-point considered outlier removal method, the traditional percentile-based <code>percoutl</code> is a &quot;one size fits all&quot; outlier deletion method. It may delete too many or too few values that are non-outliers or outliers respectively.
</p>


<h3>Value</h3>

<p>A data frame after deleting outliers.
</p>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>
<p>2. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2017. dplyr: A Grammar of Data Manipulation. 0.7.4 ed. http://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr.
</p>
<p>3. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2019. dplyr: A Grammar of Data Manipulation. R package version 0.8.3. https://CRAN.R-project.org/package=dplyr.
</p>
<p>4. Dowle, M., Srinivasan, A., Gorecki, J., Short, T., Lianoglou, S., Antonyan, E., 2017. data.table: Extension of 'data.frame', 1.10.4-3 ed, http://r-datatable.com.
</p>
<p>5. Dowle, M., Srinivasan, A., 2021. data.table: Extension of 'data.frame'. R package version 1.14.0. https://CRAN.R-project.org/package=data.table.
</p>
<p>6. Wallig, M., Microsoft &amp; Weston, S. 2020. foreach: Provides Foreach Looping Construct. R package version 1.5.0. https://CRAN.R-project.org/package=foreach.
</p>
<p>7. Ooi, H., Corporation, M. &amp; Weston, S. 2019. doParallel: Foreach Parallel Adaptor for the 'parallel' Package. R package version 1.0.15. https://CRAN.R-project.org/package=doParallel.
</p>


<h3>See Also</h3>

<p><code>dataprep::condextr</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>percoutl(obsedele(data[c(1:200,3255:3454),c(1:4,27:61)],5,39,4,cores=2),5,39,4,cores=2)
# Result
</code></pre>

<hr>
<h2 id='percplot'>
Plot the top and bottom percentiles of each selected variable
</h2><span id='topic+percplot'></span>

<h3>Description</h3>

<p>The top and bottom percentiles of selected variables calculated by <code>percdata</code> can be plotted by <code>percplot</code> that offers a vivid check of possible outliers. It uses <code>reshape2::melt</code> or <code>dataprep::melt</code> to melt the data and uses <code>ggplot2</code> and <code>scales</code> to plot the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>percplot(data, start = NULL, end = NULL, group = NULL, ncol = NULL,
diff = 0.1, part = 'both')
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="percplot_+3A_data">data</code></td>
<td>

<p>A data frame to calculate percentiles, from the column <code>start</code> to the column <code>end</code>.
</p>
</td></tr>
<tr><td><code id="percplot_+3A_start">start</code></td>
<td>

<p>The column number of the first variable to calculate percentiles for.
</p>
</td></tr>
<tr><td><code id="percplot_+3A_end">end</code></td>
<td>

<p>The column number of the last variable to calculate percentiles for.
</p>
</td></tr>
<tr><td><code id="percplot_+3A_group">group</code></td>
<td>

<p>The column number of the grouping variable. It can be selected according to whether the data needs to be processed in groups. If grouping is not required, leave it default (NULL); if grouping is required, set <code>group</code> as the column number (position) where the grouping variable is located. If there are more than one grouping variable, it can be turned into a longer group through combination and transformation in advance.
</p>
</td></tr>
<tr><td><code id="percplot_+3A_ncol">ncol</code></td>
<td>

<p>The total columns of the plot.
</p>
</td></tr>
<tr><td><code id="percplot_+3A_diff">diff</code></td>
<td>

<p>The common difference between <code>quantile</code>'s <code>probs</code>. Default is 0.1.
</p>
</td></tr>
<tr><td><code id="percplot_+3A_part">part</code></td>
<td>

<p>The option of plotting bottom and/or top percentiles (parts). Default is 'both', or 2 for both bottom and top parts. Setting it as 'bottom' or 0 for bottom part and 'top' or 1 for top part.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Four scenes are considered according to the scales of x and y axes, namely the ranges of x and y values. For example, the code, <code>sd(diff(log(as.numeric(as.character(names(data[, start:end])))))) / mean(diff(log(as.numeric(as.character(names(data[, start:end])))))) &lt; 0.1 &amp; max(data[, start:end], na.rm = T) / min(data[, start:end], na.rm = T) &gt; = 10^3</code>, means that the coefficient of variation of the lagged differences of <code>log(x)</code> is below 0.1 and meanwhile the maximum y is 1000 times greater than or equal to the minimum y.
</p>


<h3>Value</h3>

<p>Top (highest or greatest) and bottom (lowest or smallest) percentiles are plotted.
</p>
<table role = "presentation">
<tr><td><code>0th</code></td>
<td>
<p>Quantile with <code>probs = 0</code></p>
</td></tr>
<tr><td><code>0.1th</code></td>
<td>
<p>Quantile with <code>probs = 0.001</code></p>
</td></tr>
<tr><td><code>0.2th</code></td>
<td>
<p>Quantile with <code>probs = 0.002</code></p>
</td></tr>
<tr><td><code>0.3th</code></td>
<td>
<p>Quantile with <code>probs = 0.003</code></p>
</td></tr>
<tr><td><code>0.4th</code></td>
<td>
<p>Quantile with <code>probs = 0.004</code></p>
</td></tr>
<tr><td><code>0.5th</code></td>
<td>
<p>Quantile with <code>probs = 0.005</code></p>
</td></tr>
<tr><td><code>99.5th</code></td>
<td>
<p>Quantile with <code>probs = 0.995</code></p>
</td></tr>
<tr><td><code>99.6th</code></td>
<td>
<p>Quantile with <code>probs = 0.996</code></p>
</td></tr>
<tr><td><code>99.7th</code></td>
<td>
<p>Quantile with <code>probs = 0.997</code></p>
</td></tr>
<tr><td><code>99.8th</code></td>
<td>
<p>Quantile with <code>probs = 0.998</code></p>
</td></tr>
<tr><td><code>99.9th</code></td>
<td>
<p>Quantile with <code>probs = 0.999</code></p>
</td></tr>
<tr><td><code>100th</code></td>
<td>
<p>Quantile with <code>probs = 1</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>
<p>2. Wickham, H. 2007. Reshaping data with the reshape package. Journal of Statistical Software, 21(12):1-20.
</p>
<p>3. Wickham, H. 2009. ggplot2: Elegant Graphics for Data Analysis. http://ggplot2.org: Springer-Verlag New York.
</p>
<p>4. Wickham, H. 2016. ggplot2: elegant graphics for data analysis. Springer-Verlag New York.
</p>
<p>5. Wickham, H. 2017. scales: Scale Functions for Visualization. 0.5.0 ed. https://github.com/hadley/scales.
</p>
<p>6. Wickham, H. &amp; Seidel, D. 2019. scales: Scale Functions for Visualization. R package version 1.1.0. https://CRAN.R-project.org/package=scales.
</p>


<h3>See Also</h3>

<p><code>dataprep::percdata</code> and <code>dataprep::melt</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot
percplot(data,5,65,4)

# Plot
percplot(data1,3,7,2)
</code></pre>

<hr>
<h2 id='shorvalu'>
Interpolation with values to refer to within short periods
</h2><span id='topic+shorvalu'></span>

<h3>Description</h3>

<p>Time gaps and available values are considered in NA interpolation by <code>shorvalu</code>. Thus, more reliable interpolation is realized with these constraints and the successive using of <code>obsedele</code> in the preceding outlier removal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shorvalu(data, start, end, intervals = 30, units = 'mins')
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shorvalu_+3A_data">data</code></td>
<td>

<p>A data frame containing outliers. Its columns from <code>start</code> to <code>end</code> will be checked.
</p>
</td></tr>
<tr><td><code id="shorvalu_+3A_start">start</code></td>
<td>

<p>The column number of the first selected variable.
</p>
</td></tr>
<tr><td><code id="shorvalu_+3A_end">end</code></td>
<td>

<p>The column number of the last selected variable.
</p>
</td></tr>
<tr><td><code id="shorvalu_+3A_intervals">intervals</code></td>
<td>

<p>The time gap of dividing periods as groups, is 30 (minutes) by default. This confines the interpolation inside short periods so that each interpolation has observed value(s) to refer to within every half an hour.
</p>
</td></tr>
<tr><td><code id="shorvalu_+3A_units">units</code></td>
<td>

<p>Units in time intervals/differences. It can be one of &quot;secs&quot;, &quot;mins&quot;, &quot;hours&quot;, &quot;days&quot;, or &quot;weeks&quot;. The default is 'mins'.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It offers a robust interpolation method based on considering time gaps and available values.
</p>


<h3>Value</h3>

<p>A data frame with missing values being replaced linearly within short periods and with values to refer to.
</p>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>
<p>2. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2017. dplyr: A Grammar of Data Manipulation. 0.7.4 ed. http://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr.
</p>
<p>3. Wickham, H., Francois, R., Henry, L. &amp; Muller, K. 2019. dplyr: A Grammar of Data Manipulation. R package version 0.8.3. https://CRAN.R-project.org/package=dplyr.
</p>
<p>4. Zeileis, A. &amp; Grothendieck, G. 2005. zoo: S3 infrastructure for regular and irregular time series. Journal of Statistical Software, 14(6):1-27.
</p>
<p>5. Zeileis, A., Grothendieck, G. &amp; Ryan, J.A. 2019. zoo: S3 Infrastructure for Regular and Irregular Time Series (Z's Ordered Observations). R package version 1.8-6. https://cran.r-project.org/web/packages/zoo/.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>shorvalu(condextr(obsedele(data[1:250,c(1,4,17:19)],3,5,2,cores=2),
3,5,2,cores=2),3,5)
</code></pre>

<hr>
<h2 id='varidele'>
Delete variables containing too many missing values (NA)
</h2><span id='topic+varidele'></span>

<h3>Description</h3>

<p>Missing values often exist in real data. However, excessive missing values would lead to information distortion and inappropriate handling of them may end up coming to inaccurate conclusions about the data. Therefore, to control and improve the quality of original data that have already been produced by instruments in the first beginning, the data preprocessing method in this package introduces the deletion of variables to filter out and delete the variables with too many missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>varidele(data, start = NULL, end = NULL, fraction = 0.25)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="varidele_+3A_data">data</code></td>
<td>

<p>A data frame containing variables with excessive missing values. Its columns from <code>start</code> to <code>end</code> will be checked.
</p>
</td></tr>
<tr><td><code id="varidele_+3A_start">start</code></td>
<td>

<p>The column number of the first selected variable.
</p>
</td></tr>
<tr><td><code id="varidele_+3A_end">end</code></td>
<td>

<p>The column number of the last selected variable.
</p>
</td></tr>
<tr><td><code id="varidele_+3A_fraction">fraction</code></td>
<td>

<p>The proportion of missing values of variables. Default is 0.25.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It operates only at the beginning and the end variables, so as to ensure that the remaining variables after deleting are continuous without breaks. The deletion of variables with excessive missing values is mainly based on the proportion of missing values of variables, excluding blank observations. The default proportion is 0.25, which can be adjusted according to practical needs.
</p>


<h3>Value</h3>

<p>A data frame after deleting variables with too many missing values.
</p>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>References</h3>

<p>1. Example data is from https://smear.avaa.csc.fi/download. It includes particle number concentrations in SMEAR I Varrio forest.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Show the first 5 and last 5 rows and columns besides the date column.
varidele(data,5,65)[c(1:5,(nrow(data)-4):nrow(data)),c(1,5:9,35:39)]
# The first 22 variables and last 4 variables are deleted with the NA proportion of 0.25.


# Increasing the NA proportion can keep more variables.
# Proportions 0.4 and 0.5 have the same result for this example data.
# Namely 2 more variables in the beginning and 1 more variable in the end are kept.
varidele(data,5,65,.5)[c(1:5,(nrow(data)-4):nrow(data)),c(1,5:9,38:42)]

# Setting proportion as 0.6, then 3 more variables in the beginning are kept
# than that of proportions 0.4 and 0.5.
varidele(data,5,65,.6)[c(1:5,(nrow(data)-4):nrow(data)),c(1,5:9,41:45)]
</code></pre>

<hr>
<h2 id='zerona'>
Turn zeros to missing values
</h2><span id='topic+zerona'></span>

<h3>Description</h3>

<p>Zeros are suitable in logarithmic scale and should be removed for plots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zerona(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="zerona_+3A_x">x</code></td>
<td>

<p>A dataframe, matrix, or vector containing zeros.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A dataframe, matrix, or vector with zeros being turned into missing values.
</p>


<h3>Author(s)</h3>

<p>Chun-Sheng Liang &lt;liangchunsheng@lzu.edu.cn&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>zerona(0:5)
zerona(cbind(a=0:5,b=c(6:10,0)))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
