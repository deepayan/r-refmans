<!DOCTYPE html><html lang="en"><head><title>Help for package assessor</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {assessor}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bballHR'><p>MLB Players' Home Run and Batted Ball Statistics with Red Zone Metrics (2017-2019)</p></a></li>
<li><a href='#MEPS'><p>Healthcare expenditure data</p></a></li>
<li><a href='#ord_curve'><p>Ordered curve for assessing mean structures</p></a></li>
<li><a href='#qqresid'><p>QQ-plots of DPIT residuals</p></a></li>
<li><a href='#resid_2pm'><p>Residuals for regression models with two-part outcomes</p></a></li>
<li><a href='#resid_disc'><p>Residuals for regression models with discrete outcomes</p></a></li>
<li><a href='#resid_quasi'><p>Quasi Emprical residuals functions</p></a></li>
<li><a href='#resid_semiconti'><p>Residuals for regression models with semicontinuous outcomes</p></a></li>
<li><a href='#resid_zeroinfl'><p>Residuals for regression models with zero-inflated outcomes</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Assessment Tools for Regression Models with Discrete and
Semicontinuous Outcomes</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Provides assessment tools for regression models with discrete and semicontinuous outcomes proposed in Yang (2023) &lt;<a href="https://doi.org/10.48550%2FarXiv.2308.15596">doi:10.48550/arXiv.2308.15596</a>&gt;. It calculates the double probability integral transform (DPIT) residuals, constructs QQ plots of residuals and the ordered curve for assessing mean structures.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://jhlee1408.github.io/assessor/">https://jhlee1408.github.io/assessor/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/jhlee1408/assessor/issues">https://github.com/jhlee1408/assessor/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>tweedie, MASS, VGAM, np</td>
</tr>
<tr>
<td>Suggests:</td>
<td>pscl, statmod, rmarkdown, knitr, AER, faraway, testthat (&ge;
3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-16 21:33:32 UTC; jeonghwanlee</td>
</tr>
<tr>
<td>Author:</td>
<td>Lu Yang [aut],
  Jeonghwan Lee [cre, aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jeonghwan Lee &lt;lee03938@umn.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-17 00:10:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='bballHR'>MLB Players' Home Run and Batted Ball Statistics with Red Zone Metrics (2017-2019)</h2><span id='topic+bballHR'></span>

<h3>Description</h3>

<p>This dataset provides annual statistics for Major League Baseball (MLB) players, including home run counts, at-bats, mean exit velocities, launch angles, quantile statistics of exit velocities and launch angles, and red zone metrics. It is intended for analyzing batted ball performance, with additional variables on the red zone, which is defined as balls in play with a launch angle between 20 and 35 degrees and an exit velocity of at least 95 mph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bballHR
</code></pre>


<h3>Format</h3>

<p>A data frame with the following columns:
</p>

<dl>
<dt>name</dt><dd><p>Player's full name (character).</p>
</dd>
<dt>playerID</dt><dd><p>Player's unique identifier in the Lahman database (character).</p>
</dd>
<dt>teamID</dt><dd><p>Team abbreviation (character).</p>
</dd>
<dt>year</dt><dd><p>Season year (numeric).</p>
</dd>
<dt>HR</dt><dd><p>Home runs hit during the season (integer).</p>
</dd>
<dt>AB</dt><dd><p>At-bats during the season (integer).</p>
</dd>
<dt>mean_exit_velo</dt><dd><p>Average exit velocity (mph) over the season (numeric).</p>
</dd>
<dt>mean_launch_angle</dt><dd><p>Average launch angle (degrees) over the season (numeric).</p>
</dd>
<dt>launch_angle_75</dt><dd><p>Launch angle at the 75th percentile of the player's distribution (numeric).</p>
</dd>
<dt>launch_angle_70</dt><dd><p>Launch angle at the 70th percentile of the player's distribution (numeric).</p>
</dd>
<dt>launch_angle_65</dt><dd><p>Launch angle at the 65th percentile of the player's distribution (numeric).</p>
</dd>
<dt>exit_velo_75</dt><dd><p>Exit velocity at the 75th percentile of the player's distribution (numeric).</p>
</dd>
<dt>exit_velo_80</dt><dd><p>Exit velocity at the 80th percentile of the player's distribution (numeric).</p>
</dd>
<dt>exit_velo_85</dt><dd><p>Exit velocity at the 85th percentile of the player's distribution (numeric).</p>
</dd>
<dt>count_red_zone</dt><dd><p>Seasonal count of batted balls in the red zone, defined as a launch angle between 20 and 35 degrees and an exit velocity greater than or equal to 95 mph (integer).</p>
</dd>
<dt>prop_red_zone</dt><dd><p>Proportion of batted balls that fall into the red zone (numeric).</p>
</dd>
<dt>BPF</dt><dd><p>Ballpark factor, indicating the effect of the player's home ballpark on offensive statistics (integer).</p>
</dd>
</dl>



<h3>Details</h3>


<dl>
<dt>Mean Metrics</dt><dd><p><code>mean_exit_velo</code> and <code>mean_launch_angle</code> represent the player's average exit velocities and launch angles, respectively, over the course of a season.</p>
</dd>
<dt>Quantile Metrics</dt><dd><p>The <code>launch_angle_xx</code> and <code>exit_velo_xx</code> columns denote the upper <code class="reqn">x</code>-percentiles (e.g., 75th percentile) of the player's launch angle and exit velocity distributions for that year.</p>
</dd>
<dt>Red Zone Metrics</dt><dd><p><code>count_red_zone</code> gives the number of balls in play that fall into the red zone, while <code>prop_red_zone</code> represents the proportion of balls in play in this category.</p>
</dd>
<dt>BPF</dt><dd><p>The Ballpark Factor (BPF) quantifies the influence of the player's home ballpark on offensive performance, with values above 100 indicating a hitter-friendly environment.</p>
</dd>
</dl>



<h3>Source</h3>


<ul>
<li><p> Player statistics: <a href="https://CRAN.R-project.org/package=Lahman">Lahman R Package</a>
</p>
</li>
<li><p> Batted ball data: <a href="https://baseballsavant.mlb.com/">Baseball Savant</a>
</p>
</li>
<li><p> Additional analysis: <a href="https://bayesball.github.io/BLOG/homeruns.html">Patterns of Home Run Hitting in the Statcast Era</a> by Jim Albert
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>data(bballHR)
head(bballHR)

</code></pre>

<hr>
<h2 id='MEPS'>Healthcare expenditure data</h2><span id='topic+MEPS'></span>

<h3>Description</h3>

<p>Healthcare expenditure data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MEPS
</code></pre>


<h3>Format</h3>

<p>A data frame with 29784 rows and 29 variables:
</p>

<dl>
<dt><code>EXP</code></dt><dd><p>the aggregate annual office based expenditure per participants, semicontinuous outcomes</p>
</dd>
<dt><code>AGE</code></dt><dd><p>Age</p>
</dd>
<dt><code>GENDER</code></dt><dd><p>1 if female</p>
</dd>
<dt><code>ASIAN</code></dt><dd><p>1 if Asian</p>
</dd>
<dt><code>BLACK</code></dt><dd><p>1 if Black</p>
</dd>
<dt><code>NORTHEAST</code></dt><dd><p>1 if Northeast</p>
</dd>
<dt><code>MIDWEST</code></dt><dd><p>1 if Midwest</p>
</dd>
<dt><code>SOUTH</code></dt><dd><p>1 if South</p>
</dd>
<dt><code>USC</code></dt><dd><p>1 if have usual source of care</p>
</dd>
<dt><code>COLLEGE</code></dt><dd><p>1 if colleage or higher degrees</p>
</dd>
<dt><code>HIGHSCH</code></dt><dd><p>1 if high school degree</p>
</dd>
<dt><code>MARRIED</code></dt><dd><p>1 if married</p>
</dd>
<dt><code>WIDIVSEP</code></dt><dd><p>1 if widowed or divorced or separated</p>
</dd>
<dt><code>FAMSIZE</code></dt><dd><p>Family Size</p>
</dd>
<dt><code>HINCOME</code></dt><dd><p>1 if high income</p>
</dd>
<dt><code>MINCOME</code></dt><dd><p>1 if middle income</p>
</dd>
<dt><code>LINCOME</code></dt><dd><p>1 if low income</p>
</dd>
<dt><code>NPOOR</code></dt><dd><p>1 if near poor</p>
</dd>
<dt><code>POOR</code></dt><dd><p>1 if poor</p>
</dd>
<dt><code>FAIR</code></dt><dd><p>1 if fair</p>
</dd>
<dt><code>GOOD</code></dt><dd><p>1 if good</p>
</dd>
<dt><code>VGOOD</code></dt><dd><p>1 if very good</p>
</dd>
<dt><code>MNHPOOR</code></dt><dd><p>1 if poor or fair mental health</p>
</dd>
<dt><code>ANYLIMIT</code></dt><dd><p>1 if any functional or activity limitation</p>
</dd>
<dt><code>unemployed</code></dt><dd><p>1 if unemployed at the beginning of 2006</p>
</dd>
<dt><code>EDUCHEALTH</code></dt><dd><p>1 if education, health and social services</p>
</dd>
<dt><code>PUBADMIN</code></dt><dd><p>1 if public administration</p>
</dd>
<dt><code>insured</code></dt><dd><p>1 if is insured at the beginning of the year 2006</p>
</dd>
<dt><code>MANAGEDCARE</code></dt><dd><p>if enrolled in an HMO or a gatekeeper plan</p>
</dd>
</dl>



<h3>Source</h3>

<p>http://www.meps.ahrq.gov/mepsweb/
</p>

<hr>
<h2 id='ord_curve'>Ordered curve for assessing mean structures</h2><span id='topic+ord_curve'></span>

<h3>Description</h3>

<p>Creates a plot to assess the mean structure of regression models. The
plot compares the cumulative sum of the response variable and its hypothesized value.
Deviation from the diagonal suggests the possibility that the mean structure of the model is incorrect.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ord_curve(model, thr)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ord_curve_+3A_model">model</code></td>
<td>
<p>Regression model object (e.g.,<code>lm</code>, <code>glm</code>, <code>glm.nb</code>, <code>polr</code>, <code>lm</code>)</p>
</td></tr>
<tr><td><code id="ord_curve_+3A_thr">thr</code></td>
<td>
<p>Threshold variable (e.g., predictor, fitted values, or variable to be included as a covariate)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The ordered curve plots </p>
<p style="text-align: center;"><code class="reqn">\hat{L}_1(t)=\frac{\sum_{i=1}^n\left[Y_i1(Z_i\leq t)\right]}{\sum_{i=1}^nY_i}</code>
</p>
<p> against
</p>
<p style="text-align: center;"><code class="reqn">\hat{L}_2(t)=\frac{\sum_{i=1}^n\left[\hat{\lambda}_i1(Z_i\leq t)\right]}{\sum_{i=1}^n\hat{\lambda}_i},</code>
</p>

<p>where <code class="reqn">\hat{\lambda}_i</code> is the fitted mean, and <code class="reqn">Z_i</code> is the threshold variable. <br />
</p>
<p>If the mean structure is correctly specified in the model,
<code class="reqn">\hat L_1(t)</code> and <code class="reqn">\hat L_2(t)</code> should be close to each other.
</p>
<p>If the curve is distant from the diagonal, it suggests incorrectness in the mean structure.
Moreover, if the curve is above the diagonal, the summation of the response is larger than
the fitted mean, which implies that the mean is underestimated, and vice versa. <br />
</p>
<p>The role of <code>thr</code> (threshold variable <code class="reqn">Z</code>) is to determine the rule  for accumulating <code class="reqn">\hat{\lambda}_i</code> and <code class="reqn">Y_i</code>, <code class="reqn">i=1,\ldots,n</code>
for the ordered curve.
The candidate for <code>thr</code> could be any function of predictors such as a single predictor (e.g., <code>x1</code>),
a linear combination of predictor (e.g., <code>x1+x2</code>), or fitted values (e.g., <code>fitted(model)</code>).
It can also be a variable being considered to be included in the mean function.
If a variable  leads to a large discrepancy between the ordered curve and the diagonal,
including this variable in the mean function should be considered.
</p>
<p>For more details, see the reference paper.
</p>


<h3>Value</h3>


<ul>
<li><p> x-axis: <code class="reqn">\hat L_1(t)</code>
</p>
</li>
<li><p> y-axis: <code class="reqn">\hat L_2(t)</code>
</p>
</li></ul>

<p>which are defined in Details.
</p>


<h3>References</h3>

<p>Yang, Lu. &quot;Double Probability Integral Transform Residuals for Regression Models with Discrete Outcomes.&quot; arXiv preprint arXiv:2308.15596 (2023).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Binary example of ordered curve
n &lt;- 500
set.seed(1234)
x1 &lt;- rnorm(n, 1, 1)
x2 &lt;- rbinom(n, 1, 0.7)
beta0 &lt;- -5
beta1 &lt;- 2
beta2 &lt;- 1
beta3 &lt;- 3
q1 &lt;- 1 / (1 + exp(beta0 + beta1 * x1 + beta2 * x2 + beta3 * x1 * x2))
y1 &lt;- rbinom(n, size = 1, prob = 1 - q1)

## True Model
model0 &lt;- glm(y1 ~ x1 * x2, family = binomial(link = "logit"))
ord_curve(model0, thr = model0$fitted.values) # set the threshold as fitted values

## Missing a covariate
model1 &lt;- glm(y1 ~ x1, family = binomial(link = "logit"))
ord_curve(model1, thr = x2) # set the threshold as a covariate

## Poisson example of ordered curve
n &lt;- 500
set.seed(1234)
x1 &lt;- rnorm(n)
x2 &lt;- rnorm(n)
beta0 &lt;- 0
beta1 &lt;- 2
beta2 &lt;- 1
lambda1 &lt;- exp(beta0 + beta1 * x1 + beta2 * x2)

y &lt;- rpois(n, lambda1)

## True Model
poismodel1 &lt;- glm(y ~ x1 + x2, family = poisson(link = "log"))
ord_curve(poismodel1, thr = poismodel1$fitted.values)

## Missing a covariate
poismodel2 &lt;- glm(y ~ x1, family = poisson(link = "log"))
ord_curve(poismodel2, thr = poismodel2$fitted.values)
ord_curve(poismodel2, thr = x2)

</code></pre>

<hr>
<h2 id='qqresid'>QQ-plots of DPIT residuals</h2><span id='topic+qqresid'></span>

<h3>Description</h3>

<p>Makes a QQ-plot of the DPIT residuals calculated from <code><a href="#topic+resid_disc">resid_disc()</a></code>, <code><a href="#topic+resid_semiconti">resid_semiconti()</a></code> or <code><a href="#topic+resid_zeroinfl">resid_zeroinfl()</a></code>.
The plot should be close to the diagonal if the model is correctly specified.
Note that this function does not return residuals. To get both residuals and QQ-plot,
use <code><a href="#topic+resid_disc">resid_disc()</a></code>, <code><a href="#topic+resid_semiconti">resid_semiconti()</a></code> and <code><a href="#topic+resid_zeroinfl">resid_zeroinfl()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qqresid(model, scale="normal")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qqresid_+3A_model">model</code></td>
<td>
<p>Fitted model object (e.g., <code>glm()</code>, <code>glm.nb()</code>, <code>zeroinfl()</code>, and <code>polr()</code>)</p>
</td></tr>
<tr><td><code id="qqresid_+3A_scale">scale</code></td>
<td>
<p>You can choose the scale of the residuals between <code>normal</code> and <code>uniform</code> scales.
The sample quantiles of the residuals are plotted against
the theoretical quantiles of a standard normal distribution under the normal scale,
and against the theoretical quantiles of a uniform (0,1) distribution under the uniform scale.
The defalut scale is <code>normal</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A QQ plot.
</p>

<ul>
<li><p> x-axis: Theoretical quantiles
</p>
</li>
<li><p> y-axis: Sample quantiles generated by DPIT residuals
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+resid_disc">resid_disc()</a></code>, <code><a href="#topic+resid_semiconti">resid_semiconti()</a></code>, <code><a href="#topic+resid_zeroinfl">resid_zeroinfl()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
b &lt;- c(2, 1, -2)
x1 &lt;- rnorm(n)
x2 &lt;- rbinom(n, 1, 0.7)
y &lt;- rpois(n, exp(b[1] + b[2] * x1 + b[3] * x2))

m1 &lt;- glm(y ~ x1 + x2, family = poisson)
qqresid(m1, scale = "normal")
qqresid(m1, scale = "uniform")
</code></pre>

<hr>
<h2 id='resid_2pm'>Residuals for regression models with two-part outcomes</h2><span id='topic+resid_2pm'></span>

<h3>Description</h3>

<p>Calculates DPIT proposed residuals for model for semi-continuous outcomes.
<code>resid_2pm</code> can be used either with <code>model0</code> and <code>model1</code> or with <code>part0</code> and <code>part1</code> as arguments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resid_2pm(model0, model1, y, part0, part1, plot=TRUE, scale = "normal")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resid_2pm_+3A_model0">model0</code></td>
<td>
<p>Model object for 0 outcomes (e.g., logistic regression)</p>
</td></tr>
<tr><td><code id="resid_2pm_+3A_model1">model1</code></td>
<td>
<p>Model object for the continuous part (gamma regression)</p>
</td></tr>
<tr><td><code id="resid_2pm_+3A_y">y</code></td>
<td>
<p>Semicontinuous outcome variables</p>
</td></tr>
<tr><td><code id="resid_2pm_+3A_part0">part0</code></td>
<td>
<p>Alternative argument to <code>model0</code>. One can supply the sequence of probabilities <code class="reqn">P(Y_i=0),~i=1,\ldots,n</code>.</p>
</td></tr>
<tr><td><code id="resid_2pm_+3A_part1">part1</code></td>
<td>
<p>Alternative argument to <code>model1</code>. One can fit a regression model on the positive data and supply their probability integral transform. Note that the length of <code>part1</code> is the number of positive values in <code>y</code> and can be shorter than <code>part0</code>.</p>
</td></tr>
<tr><td><code id="resid_2pm_+3A_plot">plot</code></td>
<td>
<p>A logical value indicating whether or not to return QQ-plot</p>
</td></tr>
<tr><td><code id="resid_2pm_+3A_scale">scale</code></td>
<td>
<p>You can choose the scale of the residuals among <code>normal</code> and <code>uniform</code> scales. The default scale is <code>normal</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The DPIT residuals for regression models with semi-continuous outcomes are </p>
<p style="text-align: center;"><code class="reqn">\hat{r}_i=\frac{\hat{F}(Y_i|\mathbf{X}_i)}{n}\sum_{j=1}^n1\left(\hat{p}_0(\mathbf{X}_j)\leq \hat{F}(Y_i|\mathbf{X}_i)\right), i=1,\ldots,n,</code>
</p>

<p>where <code class="reqn">\hat{p}_0(\mathbf{X}_i)</code> is the fitted probability of zero, and <code class="reqn">\hat{F}(\cdot|\mathbf{X}_i)</code> is the  fitted cumulative distribution function for the <code class="reqn">i</code>th observation. Furthermore, </p>
<p style="text-align: center;"><code class="reqn">\hat{F}(y|\mathbf{x})=\hat{p}_0(\mathbf{x})+\left(1-\hat{p}_0(\mathbf{x})\right)\hat{G}(y|\mathbf{x})</code>
</p>

<p>where <code class="reqn">\hat{G}</code> is the fitted cumulative distribution for the positive data.
</p>
<p>In two-part models, the probability of zero can be modeled using a logistic regression, <code>model0</code>,
while the positive observations can be modeled using a gamma regression, <code>model1.</code>
Users can choose to use different models and supply the resulting probability transforms.
<code>part0</code> should be the sequence of fitted probabilities of zeros <code class="reqn">\hat{p}_0(\mathbf{X}_i) ,~i=1,\ldots,n</code>.
<code>part1</code> should be the probability integral transform of the positive part <code class="reqn">\hat{G}(Y_i|\mathbf{X}_i)</code>.
Note that the length of <code>part1</code> is the number of positive values in <code>y</code> and can be shorter than <code>part0</code>.
</p>


<h3>Value</h3>

<p>Residuals. If plot=TRUE, also produces a QQ plot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resid_semiconti">resid_semiconti()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
n &lt;- 500
beta10 &lt;- 1
beta11 &lt;- -2
beta12 &lt;- -1
beta13 &lt;- -1
beta14 &lt;- -1
beta15 &lt;- -2
x11 &lt;- rnorm(n)
x12 &lt;- rbinom(n, size = 1, prob = 0.4)

p1 &lt;- 1 / (1 + exp(-(beta10 + x11 * beta11 + x12 * beta12)))
lambda1 &lt;- exp(beta13 + beta14 * x11 + beta15 * x12)
y2 &lt;- rgamma(n, scale = lambda1 / 2, shape = 2)
y &lt;- rep(0, n)
u &lt;- runif(n, 0, 1)
ind1 &lt;- which(u &gt;= p1)
y[ind1] &lt;- y2[ind1]

# models as input
mgamma &lt;- glm(y[ind1] ~ x11[ind1] + x12[ind1], family = Gamma(link = "log"))
m10 &lt;- glm(y == 0 ~ x12 + x11, family = binomial(link = "logit"))
resid.model &lt;- resid_2pm(model0 = m10, model1 = mgamma, y = y)

# PIT as input
cdfgamma &lt;- pgamma(y[ind1],
  scale = mgamma$fitted.values * gamma.dispersion(mgamma),
  shape = 1 / gamma.dispersion(mgamma)
)
p1f &lt;- m10$fitted.values
resid.pit &lt;- resid_2pm(y = y, part0 = p1f, part1 = cdfgamma)
</code></pre>

<hr>
<h2 id='resid_disc'>Residuals for regression models with discrete outcomes</h2><span id='topic+resid_disc'></span>

<h3>Description</h3>

<p>Calculates the DPIT residuals for regression models with discrete outcomes.
Specifically, the model assumption of GLMs with binary, ordinal, Poisson,
and negative binomial outcomes
can be assessed using <code>resid_disc()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resid_disc(model, plot=TRUE, scale="normal")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resid_disc_+3A_model">model</code></td>
<td>
<p>Model object (e.g., <code>glm</code>, <code>glm.nb</code>, <code>polr</code>)</p>
</td></tr>
<tr><td><code id="resid_disc_+3A_plot">plot</code></td>
<td>
<p>A logical value indicating whether or not to return QQ-plot</p>
</td></tr>
<tr><td><code id="resid_disc_+3A_scale">scale</code></td>
<td>
<p>You can choose the scale of the residuals among <code>normal</code> and <code>uniform</code> scales.
The sample quantiles of the residuals are plotted against
the theoretical quantiles of a standard normal distribution under the normal scale,
and against the theoretical quantiles of a uniform (0,1) distribution under the uniform scale.
The defalut scale is <code>normal</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The DPIT residual for the <code class="reqn">i</code>th observation is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">\hat{r}(Y_i|X_i) = \hat{G}\bigg(\hat{F}(Y_i|\mathbf{X}_i)\bigg)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\hat{G}(s) = \frac{1}{n-1}\sum_{j=1, j \neq i}^{n}\hat{F}\bigg(\hat{F}^{(-1)}(\mathbf{X}_j)\bigg|\mathbf{X}_j\bigg)</code>
</p>

<p>and <code class="reqn">\hat{F}</code> refers to the fitted cumulative distribution function.
When <code>scale="uniform"</code>, DPIT residuals should closely follow a uniform distribution, otherwise it implies model deficiency.
When <code>scale="normal"</code>, it applies the normal quantile transformation to the DPIT residuals
</p>
<p style="text-align: center;"><code class="reqn">\Phi^{-1}\left[\hat{r}(Y_i|\mathbf{X}_i)\right],i=1,\ldots,n.</code>
</p>
<p> The null pattern is the standard normal distribution in this case.
<br />
</p>
<p>Check reference for more details.
</p>


<h3>Value</h3>

<p>DPIT residuals. If <code>plot=TRUE</code>, also produces a QQ plot.
</p>


<h3>References</h3>

<p>Yang, Lu. &quot;Double Probability Integral Transform Residuals for Regression Models with Discrete Outcomes.&quot; arXiv preprint arXiv:2308.15596 (2023).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
n &lt;- 500
set.seed(1234)
## Negative Binomial example
# Covariates
x1 &lt;- rnorm(n)
x2 &lt;- rbinom(n, 1, 0.7)
### Parameters
beta0 &lt;- -2
beta1 &lt;- 2
beta2 &lt;- 1
size1 &lt;- 2
lambda1 &lt;- exp(beta0 + beta1 * x1 + beta2 * x2)
# generate outcomes
y &lt;- rnbinom(n, mu = lambda1, size = size1)

# True model
model1 &lt;- glm.nb(y ~ x1 + x2)
resid.nb1 &lt;- resid_disc(model1, plot = TRUE, scale = "uniform")

# Overdispersion
model2 &lt;- glm(y ~ x1 + x2, family = poisson(link = "log"))
resid.nb2 &lt;- resid_disc(model2, plot = TRUE, scale = "normal")

## Binary example
n &lt;- 500
set.seed(1234)
# Covariates
x1 &lt;- rnorm(n, 1, 1)
x2 &lt;- rbinom(n, 1, 0.7)
# Coefficients
beta0 &lt;- -5
beta1 &lt;- 2
beta2 &lt;- 1
beta3 &lt;- 3
q1 &lt;- 1 / (1 + exp(beta0 + beta1 * x1 + beta2 * x2 + beta3 * x1 * x2))
y1 &lt;- rbinom(n, size = 1, prob = 1 - q1)

# True model
model01 &lt;- glm(y1 ~ x1 * x2, family = binomial(link = "logit"))
resid.bin1 &lt;- resid_disc(model01, plot = TRUE)

# Missing covariates
model02 &lt;- glm(y1 ~ x1, family = binomial(link = "logit"))
resid.bin2 &lt;- resid_disc(model02, plot = TRUE)

## Poisson example
n &lt;- 500
set.seed(1234)
# Covariates
x1 &lt;- rnorm(n)
x2 &lt;- rbinom(n, 1, 0.7)
# Coefficients
beta0 &lt;- -2
beta1 &lt;- 2
beta2 &lt;- 1
lambda1 &lt;- exp(beta0 + beta1 * x1 + beta2 * x2)
y &lt;- rpois(n, lambda1)

# True model
poismodel1 &lt;- glm(y ~ x1 + x2, family = poisson(link = "log"))
resid.poi1 &lt;- resid_disc(poismodel1, plot = TRUE)

# Enlarge three outcomes
y &lt;- rpois(n, lambda1) + c(rep(0, (n - 3)), c(10, 15, 20))
poismodel2 &lt;- glm(y ~ x1 + x2, family = poisson(link = "log"))
resid.poi2 &lt;- resid_disc(poismodel2, plot = TRUE)

## Ordinal example
n &lt;- 500
set.seed(1234)
# Covariates
x1 &lt;- rnorm(n, mean = 2)
# Coefficient
beta1 &lt;- 3

# True model
p0 &lt;- plogis(1, location = beta1 * x1)
p1 &lt;- plogis(4, location = beta1 * x1) - p0
p2 &lt;- 1 - p0 - p1
genemult &lt;- function(p) {
  rmultinom(1, size = 1, prob = c(p[1], p[2], p[3]))
}
test &lt;- apply(cbind(p0, p1, p2), 1, genemult)
y1 &lt;- rep(0, n)
y1[which(test[1, ] == 1)] &lt;- 0
y1[which(test[2, ] == 1)] &lt;- 1
y1[which(test[3, ] == 1)] &lt;- 2
multimodel &lt;- polr(as.factor(y1) ~ x1, method = "logistic")
resid.ord1 &lt;- resid_disc(multimodel, plot = TRUE)

## Non-Proportionality
n &lt;- 500
set.seed(1234)
x1 &lt;- rnorm(n, mean = 2)
beta1 &lt;- 3
beta2 &lt;- 1
p0 &lt;- plogis(1, location = beta1 * x1)
p1 &lt;- plogis(4, location = beta2 * x1) - p0
p2 &lt;- 1 - p0 - p1
genemult &lt;- function(p) {
  rmultinom(1, size = 1, prob = c(p[1], p[2], p[3]))
}
test &lt;- apply(cbind(p0, p1, p2), 1, genemult)
y1 &lt;- rep(0, n)
y1[which(test[1, ] == 1)] &lt;- 0
y1[which(test[2, ] == 1)] &lt;- 1
y1[which(test[3, ] == 1)] &lt;- 2
multimodel &lt;- polr(as.factor(y1) ~ x1, method = "logistic")
resid.ord2 &lt;- resid_disc(multimodel, plot = TRUE)
</code></pre>

<hr>
<h2 id='resid_quasi'>Quasi Emprical residuals functions</h2><span id='topic+resid_quasi'></span>

<h3>Description</h3>

<p>Draw the QQ-plot for regression models with discrete outcomes using the quasi-empirical residual distribution functions.
Specifically, the model assumption of GLMs with binary, ordinal, Poisson, negative binomial,
zero-inlated Poisson, and zero-inflated negative binomial outcomes can be applicable to <code>resid_quasi()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resid_quasi(model)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resid_quasi_+3A_model">model</code></td>
<td>
<p>Model object (e.g., <code>glm</code>, <code>glm.nb</code>, <code>polr</code>, <code>zeroinfl</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The quasi-empirical residual distribution function is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">\hat{U}(s; \beta) = \sum_{i=1}^{n} W_{n}(s;\mathbf{X}_{i},\beta) 1[F(Y_{i}| X_{i}) &lt; H(s;X_{i})]</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">W_n(s; \mathbf{X}_i, \beta) = \frac{K[(H(s; \mathbf{X}_i)-s)/ \epsilon_n]}{\sum_{j=1}^{n} K[(H(s; \mathbf{X}_j)-s)/ \epsilon_n]}</code>
</p>

<p>and <code class="reqn">K</code> is a bounded, symmetric, and Lipschitz continuous kernel.
</p>


<h3>Value</h3>

<p>A QQ plot.
</p>

<ul>
<li><p> x-axis: Theoretical quantiles
</p>
</li>
<li><p> y-axis: Sample quantiles
</p>
</li></ul>



<h3>References</h3>

<p>Lu Yang (2021). Assessment of Regression Models with Discrete Outcomes Using Quasi-Empirical Residual Distribution Functions, Journal of Computational and Graphical Statistics, 30(4), 1019-1035.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Negative Binomial example
library(MASS)
# Covariates
n &lt;- 500
x1 &lt;- rnorm(n)
x2 &lt;- rbinom(n, 1, 0.7)
### Parameters
beta0 &lt;- -2
beta1 &lt;- 2
beta2 &lt;- 1
size1 &lt;- 2
lambda1 &lt;- exp(beta0 + beta1 * x1 + beta2 * x2)
# generate outcomes
y &lt;- rnbinom(n, mu = lambda1, size = size1)

# True model
model1 &lt;- glm.nb(y ~ x1 + x2)
resid.nb1 &lt;- resid_quasi(model1)

# Overdispersion
model2 &lt;- glm(y ~ x1 + x2, family = poisson(link = "log"))
resid.nb2 &lt;- resid_quasi(model2)

## Zero inflated Poisson example
library(pscl)
n &lt;- 500
set.seed(1234)
# Covariates
x1 &lt;- rnorm(n)
x2 &lt;- rbinom(n, 1, 0.7)
# Coefficients
beta0 &lt;- -2
beta1 &lt;- 2
beta2 &lt;- 1
beta00 &lt;- -2
beta10 &lt;- 2

# Mean of Poisson part
lambda1 &lt;- exp(beta0 + beta1 * x1 + beta2 * x2)
# Excess zero probability
p0 &lt;- 1 / (1 + exp(-(beta00 + beta10 * x1)))
## simulate outcomes
y0 &lt;- rbinom(n, size = 1, prob = 1 - p0)
y1 &lt;- rpois(n, lambda1)
y &lt;- ifelse(y0 == 0, 0, y1)
## True model
modelzero1 &lt;- zeroinfl(y ~ x1 + x2 | x1, dist = "poisson", link = "logit")
resid.zero1 &lt;- resid_quasi(modelzero1)
</code></pre>

<hr>
<h2 id='resid_semiconti'>Residuals for regression models with semicontinuous outcomes</h2><span id='topic+resid_semiconti'></span>

<h3>Description</h3>

<p>Calculates the DPIT residuals for regression models with semi-continuous outcomes.
The semi-continuous regression model such as
a Tweedie regression model from <code>tweedie</code> package or a Tobit regression model
from <code>VGAM</code>, <code>AER</code> packages is used in this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resid_semiconti(model, plot=TRUE, scale = "normal")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resid_semiconti_+3A_model">model</code></td>
<td>
<p>Model object (e.g., <code>tweedie</code>, <code>vglm</code>, and <code>tobit</code>)</p>
</td></tr>
<tr><td><code id="resid_semiconti_+3A_plot">plot</code></td>
<td>
<p>A logical value indicating whether or not to return QQ-plot</p>
</td></tr>
<tr><td><code id="resid_semiconti_+3A_scale">scale</code></td>
<td>
<p>You can choose the scale of the residuals between <code>normal</code> and <code>uniform</code> scales. The default scale is <code>normal</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The DPIT residual for the <code class="reqn">i</code>th semicontinuous observation is defined as follows:
</p>
<p style="text-align: center;"><code class="reqn">\hat{r}_i = \frac{\hat{F}(Y_i|X_i)}{n}\sum_{j=1}^{n}I\bigg(\hat{p}_0(X_j) \leq \hat{F}(Y_i|X_i)\bigg),</code>
</p>

<p>which has a null distribution of uniformity.
<code class="reqn">\hat{F}</code> refers to the fitted cumulative distribution function,
and <code class="reqn">\hat{p}_0</code> refers to the fitted probability of being zero.
</p>


<h3>Value</h3>

<p>Residuals. If plot=TRUE, also produces a QQ plot.
</p>


<h3>References</h3>

<p>Lu Yang (2024). Diagnostics for Regression Models with Semicontinuous Outcomes, Biometrics, https://arxiv.org/abs/2401.06347
</p>


<h3>See Also</h3>

<p><code><a href="#topic+resid_2pm">resid_2pm()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Tweedie model
library(tweedie)
library(statmod)
n &lt;- 500
x11 &lt;- rnorm(n)
x12 &lt;- rnorm(n)
beta0 &lt;- 5
beta1 &lt;- 1
beta2 &lt;- 1
lambda1 &lt;- exp(beta0 + beta1 * x11 + beta2 * x12)
y1 &lt;- rtweedie(n, mu = lambda1, xi = 1.6, phi = 10)
# Choose parameter p
# True model
model1 &lt;-
  glm(y1 ~ x11 + x12,
    family = tweedie(var.power = 1.6, link.power = 0)
  )
resid.tweedie &lt;- resid_semiconti(model1)

## Tobit regression model
library(VGAM)
beta13 &lt;- 1
beta14 &lt;- -3
beta15 &lt;- 3

set.seed(1234)
x11 &lt;- runif(n)
x12 &lt;- runif(n)
lambda1 &lt;- beta13 + beta14 * x11 + beta15 * x12
sd0 &lt;- 0.3
yun &lt;- rnorm(n, mean = lambda1, sd = sd0)
y &lt;- ifelse(yun &gt;= 0, yun, 0)

# Using VGAM package
# True model
fit1 &lt;- vglm(formula = y ~ x11 + x12, tobit(Upper = Inf, Lower = 0, lmu = "identitylink"))
# Missing covariate
fit1miss &lt;- vglm(formula = y ~ x11, tobit(Upper = Inf, Lower = 0, lmu = "identitylink"))

resid.tobit1 &lt;- resid_semiconti(fit1, plot = TRUE)
resid.tobit2 &lt;- resid_semiconti(fit1miss, plot = TRUE)

# Using AER package
library(AER)
# True model
fit2 &lt;- tobit(y ~ x11 + x12, left = 0, right = Inf, dist = "gaussian")
# Missing covariate
fit2miss &lt;- tobit(y ~ x11, left = 0, right = Inf, dist = "gaussian")
resid.aer1 &lt;- resid_semiconti(fit2, plot = TRUE)
resid.aer2 &lt;- resid_semiconti(fit2miss, plot = TRUE)
</code></pre>

<hr>
<h2 id='resid_zeroinfl'>Residuals for regression models with zero-inflated outcomes</h2><span id='topic+resid_zeroinfl'></span>

<h3>Description</h3>

<p>Caluates the DPIT residuals for a regression model with zero-inflated discrete outcome.
A zero-inflated model from <code>pscl</code> is used in this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>resid_zeroinfl(model, plot=TRUE, scale='normal')
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="resid_zeroinfl_+3A_model">model</code></td>
<td>
<p>Model object, which is the output of <code>pscl::zeroinfl</code>.</p>
</td></tr>
<tr><td><code id="resid_zeroinfl_+3A_plot">plot</code></td>
<td>
<p>A logical value indicating whether or not to return QQ-plot.</p>
</td></tr>
<tr><td><code id="resid_zeroinfl_+3A_scale">scale</code></td>
<td>
<p>You can choose the scale of the residuals among <code>normal</code> and <code>uniform</code> scales. The default scale is <code>normal</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>DPIT residuals. If <code>plot=TRUE</code>, also produces a QQ plot.
</p>


<h3>References</h3>

<p>Yang, Lu. &quot;Double Probability Integral Transform Residuals for Regression Models with Discrete Outcomes.&quot; arXiv preprint arXiv:2308.15596 (2023).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Zero-Inflated Poisson
library(pscl)
n &lt;- 500
set.seed(1234)
# Covariates
x1 &lt;- rnorm(n)
x2 &lt;- rbinom(n, 1, 0.7)
# Coefficients
beta0 &lt;- -2
beta1 &lt;- 2
beta2 &lt;- 1
beta00 &lt;- -2
beta10 &lt;- 2

# Mean of Poisson part
lambda1 &lt;- exp(beta0 + beta1 * x1 + beta2 * x2)
# Excess zero probability
p0 &lt;- 1 / (1 + exp(-(beta00 + beta10 * x1)))
## simulate outcomes
y0 &lt;- rbinom(n, size = 1, prob = 1 - p0)
y1 &lt;- rpois(n, lambda1)
y &lt;- ifelse(y0 == 0, 0, y1)
## True model
modelzero1 &lt;- zeroinfl(y ~ x1 + x2 | x1, dist = "poisson", link = "logit")
resid.zero1 &lt;- resid_zeroinfl(modelzero1, plot = TRUE, scale = "uniform")

## Zero inflation
modelzero2 &lt;- glm(y ~ x1 + x2, family = poisson(link = "log"))
resid.zero2 &lt;- resid_disc(modelzero2, plot = TRUE, scale = "normal")
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
