<!DOCTYPE html><html><head><title>Help for package mclm</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mclm}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mclm-package'><p>Mastering Corpus Linguistic Methods</p></a></li>
<li><a href='#as_character'><p>Coerce object to character</p></a></li>
<li><a href='#as_conc'><p>Coerce data frame to a concordance object</p></a></li>
<li><a href='#as_data_frame'><p>Coerce object to a data frame</p></a></li>
<li><a href='#as_fnames'><p>Coerce object to 'fnames'</p></a></li>
<li><a href='#as_freqlist'><p>Coerce table to a frequency list</p></a></li>
<li><a href='#as_numeric'><p>Coerce object to a numeric vector</p></a></li>
<li><a href='#as_tokens'><p>Coerce object to class <code>tokens</code></p></a></li>
<li><a href='#as_types'><p>Coerce object to a vector of types</p></a></li>
<li><a href='#assoc_scores'><p>Association scores used in collocation analysis and keyword analysis</p></a></li>
<li><a href='#brackets'><p>Subset an object by different criteria</p></a></li>
<li><a href='#ca_help'><p>Helpers for plotting <code>ca</code> objects</p></a></li>
<li><a href='#cat_re'><p>Print a regular expression to the console</p></a></li>
<li><a href='#chisq1_to_p'><p>Proportion of chi-squared distribution with one degree of freedom that sits to the right of x</p></a></li>
<li><a href='#cleanup_spaces'><p>Clean up the use of whitespace in a character vector</p></a></li>
<li><a href='#conc'><p>Build a concordance for the matches of a regex</p></a></li>
<li><a href='#create_cooc'><p>Build collocation frequencies.</p></a></li>
<li><a href='#details'><p>Details on a specific item</p></a></li>
<li><a href='#drop_empty_rc'><p>Drop empty rows and columns from a matrix</p></a></li>
<li><a href='#drop_tags'><p>Drop XML tags from character string</p></a></li>
<li><a href='#explore'><p>Interactively navigate through an object</p></a></li>
<li><a href='#find_xpath'><p>Run XPath query</p></a></li>
<li><a href='#fnames'><p>Retrieve the names of files in a given path</p></a></li>
<li><a href='#freqlist'><p>Build the frequency list of a corpus</p></a></li>
<li><a href='#freqlist_diff'><p>Subtract frequency lists</p></a></li>
<li><a href='#import_conc'><p>Import a concordance</p></a></li>
<li><a href='#keep_bool'><p>Subset an object based on logical criteria</p></a></li>
<li><a href='#keep_fnames'><p>Filter collection of filenames by name</p></a></li>
<li><a href='#keep_pos'><p>Subset an object by index</p></a></li>
<li><a href='#keep_re'><p>Subset an object based on regular expressions</p></a></li>
<li><a href='#keep_types'><p>Subset an object based on a selection of types</p></a></li>
<li><a href='#mclm_xml_text'><p>Get text from xml node</p></a></li>
<li><a href='#merge_conc'><p>Merge concordances</p></a></li>
<li><a href='#merge_fnames'><p>Merge filenames collections</p></a></li>
<li><a href='#merge_freqlist'><p>Merge frequency lists</p></a></li>
<li><a href='#merge_tokens'><p>Merge <code>tokens</code> objects</p></a></li>
<li><a href='#merge_types'><p>Merge 'types' objects</p></a></li>
<li><a href='#n_fnames'><p>Count number of items in an 'fnames' object</p></a></li>
<li><a href='#n_tokens'><p>Count tokens</p></a></li>
<li><a href='#n_types'><p>Count types</p></a></li>
<li><a href='#orig_ranks'><p>Retrieve or set original ranks</p></a></li>
<li><a href='#p_to_chisq1'><p>P right quantile in chi-squared distribution with 1 degree of freedom</p></a></li>
<li><a href='#perl_flavor'><p>Retrieve or set the flavor of a regular expression</p></a></li>
<li><a href='#print_kwic'><p>Print a concordance in KWIC format</p></a></li>
<li><a href='#print.assoc_scores'><p>Print an object</p></a></li>
<li><a href='#ranks'><p>Retrieve the current ranks for frequency counts.</p></a></li>
<li><a href='#re'><p>Build a regular expression</p></a></li>
<li><a href='#re_convenience'><p>Convenience functions in support of regular expressions</p></a></li>
<li><a href='#read_assoc'><p>Read association scores from file</p></a></li>
<li><a href='#read_conc'><p>Read a concordance from a file</p></a></li>
<li><a href='#read_fnames'><p>Read a collection of filenames from a text file</p></a></li>
<li><a href='#read_freqlist'><p>Read a frequency list from a csv file</p></a></li>
<li><a href='#read_tokens'><p>Read a <code>tokens</code> object from a text file</p></a></li>
<li><a href='#read_txt'><p>Read a text file into a character vector</p></a></li>
<li><a href='#read_types'><p>Read a vector of types from a text file</p></a></li>
<li><a href='#scan_re'><p>Scan a regular expression from console</p></a></li>
<li><a href='#scan_txt'><p>Scan a character string from console</p></a></li>
<li><a href='#short_names'><p>Shorten filenames</p></a></li>
<li><a href='#slma'><p>Stable lexical marker analysis</p></a></li>
<li><a href='#sort.assoc_scores'><p>Sort an 'assoc_scores' object</p></a></li>
<li><a href='#sort.freqlist'><p>Sort a frequency list</p></a></li>
<li><a href='#tokens'><p>Create or coerce an object into class <code>tokens</code></p></a></li>
<li><a href='#tot_n_tokens'><p>Retrieve or set the total number of tokens</p></a></li>
<li><a href='#trunc_at'><p>Truncate a sequence of character data</p></a></li>
<li><a href='#type_freqs'><p>Retrieve frequencies from 'freqlist' object</p></a></li>
<li><a href='#type_names'><p>Return the names of the types in an object</p></a></li>
<li><a href='#types'><p>Build a 'types' object</p></a></li>
<li><a href='#write_assoc'><p>Write association scores to file</p></a></li>
<li><a href='#write_conc'><p>Write a concordance to file.</p></a></li>
<li><a href='#write_fnames'><p>Write a collection of filenames to a text file</p></a></li>
<li><a href='#write_freqlist'><p>Write a frequency list to a csv file</p></a></li>
<li><a href='#write_tokens'><p>Write a <code>tokens</code> object to a text file</p></a></li>
<li><a href='#write_txt'><p>Write a character vector to a text file</p></a></li>
<li><a href='#write_types'><p>Write a vector of types to a text file</p></a></li>
<li><a href='#zero_plus'><p>Make all values strictly higher than zero</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Mastering Corpus Linguistics Methods</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.7</td>
</tr>
<tr>
<td>Description:</td>
<td>Read, inspect and process corpus files for quantitative corpus linguistics.
  Obtain concordances via regular expressions, tokenize texts,
  and compute frequencies and association measures. Useful for collocation analysis,
  keywords analysis and variationist studies (comparison of linguistic variants
  and of linguistic varieties).</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>ca, tibble</td>
</tr>
<tr>
<td>Imports:</td>
<td>crayon, dplyr, Rcpp, readr, stringi, stringr, tm, xml2, yaml</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp</td>
</tr>
<tr>
<td>Suggests:</td>
<td>MASS, tidyr, purrr, testthat (&ge; 3.0.0), covr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/masterclm/mclm">https://github.com/masterclm/mclm</a>,
<a href="https://masterclm.github.io/mclm/">https://masterclm.github.io/mclm/</a></td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-02 16:08:44 UTC; u0118974</td>
</tr>
<tr>
<td>Author:</td>
<td>Dirk Speelman [aut],
  Mariana Montes [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mariana Montes &lt;mariana.montes@kuleuven.be&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-03 07:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='mclm-package'>Mastering Corpus Linguistic Methods</h2><span id='topic+mclm'></span><span id='topic+mclm-package'></span>

<h3>Description</h3>

<p><img src="../help/figures/logo.png" style='float: right' alt='logo' width='120' />
</p>
<p>Read, inspect and process corpus files for quantitative corpus linguistics. Obtain concordances via regular expressions, tokenize texts, and compute frequencies and association measures. Useful for collocation analysis, keywords analysis and variationist studies (comparison of linguistic variants and of linguistic varieties).
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Mariana Montes <a href="mailto:mariana.montes@kuleuven.be">mariana.montes@kuleuven.be</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Dirk Speelman <a href="mailto:dirk.speelman@kuleuven.be">dirk.speelman@kuleuven.be</a>
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/masterclm/mclm">https://github.com/masterclm/mclm</a>
</p>
</li>
<li> <p><a href="https://masterclm.github.io/mclm/">https://masterclm.github.io/mclm/</a>
</p>
</li></ul>


<hr>
<h2 id='as_character'>Coerce object to character</h2><span id='topic+as_character'></span><span id='topic+as_character.default'></span><span id='topic+as_character.re'></span><span id='topic+as_character.tokens'></span>

<h3>Description</h3>

<p>This method turns its argument <code>x</code>, or at least part of the information in it,
into a character vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_character(x, ...)

## Default S3 method:
as_character(x, ...)

## S3 method for class 're'
as_character(x, ...)

## S3 method for class 'tokens'
as_character(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_character_+3A_x">x</code></td>
<td>
<p>Object to coerce to character</p>
</td></tr>
<tr><td><code id="as_character_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class character
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tks &lt;- tokenize("The old man and the sea."))
as_character(tks) # turn 'tokens' object into character vector
as.character(tks) # alternative approach

as_character(1:10)
as.character(1:10)

regex &lt;- re("(?xi) ^ .*")
as_character(regex) # turn 're' object into character vector
as.character(regex) # alternative approach
</code></pre>

<hr>
<h2 id='as_conc'>Coerce data frame to a concordance object</h2><span id='topic+as_conc'></span>

<h3>Description</h3>

<p>This function coerces a data frame to an object of the class <code><a href="#topic+conc">conc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_conc(x, left = NA, match = NA, right = NA, keep_original = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_conc_+3A_x">x</code></td>
<td>
<p>A data frame.</p>
</td></tr>
<tr><td><code id="as_conc_+3A_left">left</code></td>
<td>
<p>The name of the column in <code>x</code> that contains the left co-text
of the concordance. Is <code>is.na(left)</code>, then this column is assumed
to have the name <code>"left"</code>.</p>
</td></tr>
<tr><td><code id="as_conc_+3A_match">match</code></td>
<td>
<p>The name of the column in <code>x</code> that contains the match
of the concordance. Is <code>is.na(match)</code>, then this column is assumed
to have the name <code>"match"</code>.</p>
</td></tr>
<tr><td><code id="as_conc_+3A_right">right</code></td>
<td>
<p>The name of the column in <code>x</code> that contains the right co-text
of the concordance. Is <code>is.na(right)</code>, then this column is assumed
to have the name <code>"right"</code>.</p>
</td></tr>
<tr><td><code id="as_conc_+3A_keep_original">keep_original</code></td>
<td>
<p>Logical. If the values of
<code>left</code>, <code>match</code> or <code>right</code> are not <code>NA</code>, should
the original names of those columns be kept in the <code><a href="#topic+conc">conc</a></code> object.</p>
</td></tr>
<tr><td><code id="as_conc_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code>conc</code>, a kind of data frame with as its rows
the matches and with the following columns:
</p>

<ul>
<li> <p><code>glob_id</code>: Number indicating the position of the match in the
overall list of matches.
</p>
</li>
<li> <p><code>id</code>: Number indicating the position of the match in the list of matches
for one specific query.
</p>
</li>
<li> <p><code>source</code>: Either the filename of the file in which the match was found
(in case of the setting <code>as_text = FALSE</code>), or the string '-'
(in case of the setting <code>as_text = TRUE</code>).
</p>
</li>
<li> <p><code>left</code>: The left-hand side co-text of each match.
</p>
</li>
<li> <p><code>match</code>: The actual match.
</p>
</li>
<li> <p><code>right</code>: The right-hand side co-text of each match.
</p>
</li></ul>

<p>It also has additional attributes and methods such as:
</p>

<ul>
<li><p> base <code><a href="#topic+as_data_frame">as_data_frame()</a></code> and <code><a href="#topic+print.types">print()</a></code> methods, as well as
a <code><a href="#topic+print_kwic">print_kwic()</a></code> function,
</p>
</li>
<li><p> an <code><a href="#topic+explore">explore()</a></code> method.
</p>
</li></ul>

<p>An object of class <code>conc</code> can be merged with another by means of <code><a href="#topic+merge_conc">merge_conc()</a></code>.
It can be written to file with <code><a href="#topic+write_conc">write_conc()</a></code> and then
read with <code><a href="#topic+read_conc">read_conc()</a></code>. It is also possible to import concordances created
by means other than <code><a href="#topic+write_conc">write_conc()</a></code> with <code><a href="#topic+import_conc">import_conc()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(conc_data &lt;- conc('A very small corpus.', '\\w+', as_text = TRUE))
df &lt;- as.data.frame(conc_data)
as_conc(df)
</code></pre>

<hr>
<h2 id='as_data_frame'>Coerce object to a data frame</h2><span id='topic+as_data_frame'></span><span id='topic+as_data_frame.default'></span><span id='topic+as.data.frame.assoc_scores'></span><span id='topic+as.data.frame.conc'></span><span id='topic+as.data.frame.fnames'></span><span id='topic+as.data.frame.freqlist'></span><span id='topic+as.data.frame.details.slma'></span><span id='topic+as.data.frame.slma'></span><span id='topic+as.data.frame.tokens'></span><span id='topic+as.data.frame.types'></span>

<h3>Description</h3>

<p><code>as_data_frame()</code> is an alternative to <code><a href="base.html#topic+as.data.frame">as.data.frame()</a></code>. A number of objects
in mclm can be turned into dataframes with one of these functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_data_frame(x, row.names = NULL, optional = FALSE, ...)

## Default S3 method:
as_data_frame(x, row.names = NULL, optional = FALSE, ...)

## S3 method for class 'assoc_scores'
as.data.frame(x, ...)

## S3 method for class 'conc'
as.data.frame(x, ...)

## S3 method for class 'fnames'
as.data.frame(x, ...)

## S3 method for class 'freqlist'
as.data.frame(x, row.names = NULL, optional = FALSE, ...)

## S3 method for class 'details.slma'
as.data.frame(x, ...)

## S3 method for class 'slma'
as.data.frame(x, ...)

## S3 method for class 'tokens'
as.data.frame(x, ...)

## S3 method for class 'types'
as.data.frame(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_data_frame_+3A_x">x</code></td>
<td>
<p>Object to coerce to <a href="base.html#topic+data.frame">data.frame</a>.</p>
</td></tr>
<tr><td><code id="as_data_frame_+3A_row.names">row.names</code></td>
<td>
<p><code>NULL</code> or a character vector giving the rownames for the
dataframe.</p>
</td></tr>
<tr><td><code id="as_data_frame_+3A_optional">optional</code></td>
<td>
<p>Logical. If <code>TRUE</code>, setting rownames and converting column
names is optional (see <code><a href="base.html#topic+as.data.frame">as.data.frame()</a></code>).</p>
</td></tr>
<tr><td><code id="as_data_frame_+3A_...">...</code></td>
<td>
<p>Additional arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code><a href="base.html#topic+data.frame">data.frame</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for an assoc_scores object ---------------------
a &lt;- c(10,    30,    15,    1)
b &lt;- c(200, 1000,  5000,  300)
c &lt;- c(100,   14,    16,    4)
d &lt;- c(300, 5000, 10000, 6000)
types &lt;- c("four", "fictitious", "toy", "examples")
(scores &lt;- assoc_abcd(a, b, c, d, types = types))

as.data.frame(scores)
as_data_frame(scores)

# for a conc object ------------------------------
(conc_data &lt;- conc('A very small corpus.', '\\w+', as_text = TRUE))
as.data.frame(conc_data)

# for an fnames object ---------------------------
cwd_fnames &lt;- as_fnames(c('file1', 'file2'))
as.data.frame(cwd_fnames)

# for a freqlist, types or tokens object ---------
toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
  It consisted of three sentences. And it lived happily ever after."
(flist &lt;- freqlist(toy_corpus, as_text = TRUE))
as.data.frame(flist)

(flist2 &lt;- keep_re(flist, "^..?$"))
as.data.frame

(toks &lt;- tokenize(toy_corpus))
as.data.frame(toks)

(toks &lt;- tokenize(toy_corpus))
as.data.frame(toks)
</code></pre>

<hr>
<h2 id='as_fnames'>Coerce object to 'fnames'</h2><span id='topic+as_fnames'></span>

<h3>Description</h3>

<p>This function coerces a character vector into an object of class <code><a href="#topic+fnames">fnames</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_fnames(x, remove_duplicates = TRUE, sort = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_fnames_+3A_x">x</code></td>
<td>
<p>A character vector (or a <code><a href="#topic+freqlist">freqlist</a></code> object!)</p>
</td></tr>
<tr><td><code id="as_fnames_+3A_remove_duplicates">remove_duplicates</code></td>
<td>
<p>Boolean. Whether duplicates should be removed.</p>
</td></tr>
<tr><td><code id="as_fnames_+3A_sort">sort</code></td>
<td>
<p>Boolean. Whether the output should be sorted.</p>
</td></tr>
<tr><td><code id="as_fnames_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+fnames">fnames</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>as_fnames("path/to/my/corpus_file")
</code></pre>

<hr>
<h2 id='as_freqlist'>Coerce table to a frequency list</h2><span id='topic+as_freqlist'></span>

<h3>Description</h3>

<p>This function coerces an object of class <code><a href="base.html#topic+table">table</a></code> to an object of class <code><a href="#topic+freqlist">freqlist</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_freqlist(x, tot_n_tokens = NULL, sort_by_ranks = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_freqlist_+3A_x">x</code></td>
<td>
<p>Object of class <code>table</code> or named numeric vector that will be
interpreted as such.</p>
</td></tr>
<tr><td><code id="as_freqlist_+3A_tot_n_tokens">tot_n_tokens</code></td>
<td>
<p>Number representing the total number of tokens in the
corpus from which the frequency list is derived. When <code>tot_n_tokens</code>
is <code>NULL</code>, this total number of tokens will be taken to be the sum
of the frequencies in <code>x</code>.</p>
</td></tr>
<tr><td><code id="as_freqlist_+3A_sort_by_ranks">sort_by_ranks</code></td>
<td>
<p>Logical.
If <code>TRUE</code>, the items in the frequency list are sorted by frequency
rank. If <code>FALSE</code>, the items in the frequency list, depending on the
input type, either are sorted alphabetically or are not sorted at all.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>freqlist</code>, which is based on the class <code>table</code>.
It has additional attributes and methods such as:
</p>

<ul>
<li><p> base <code><a href="#topic+print.freqlist">print()</a></code>, <code><a href="#topic+as_data_frame">as_data_frame()</a></code>,
<code><a href="base.html#topic+summary">summary()</a></code> and <code><a href="#topic+sort.freqlist">sort</a></code>,
</p>
</li>
<li> <p><code><a href="tibble.html#topic+as_tibble">tibble::as_tibble()</a></code>,
</p>
</li>
<li><p> an interactive <code><a href="#topic+explore">explore()</a></code> method,
</p>
</li>
<li><p> various getters, including <code><a href="#topic+tot_n_tokens">tot_n_tokens()</a></code>, <code><a href="#topic+n_types">n_types()</a></code>, <code><a href="#topic+n_tokens">n_tokens()</a></code>,
values that are also returned by <code><a href="base.html#topic+summary">summary()</a></code>, and more,
</p>
</li>
<li><p> subsetting methods such as <code><a href="#topic+keep_types">keep_types()</a></code>, <code><a href="#topic+keep_pos">keep_pos()</a></code>, etc. including <code style="white-space: pre;">&#8288;[]&#8288;</code>
subsetting (see <a href="#topic+brackets">brackets</a>).
</p>
</li></ul>

<p>Additional manipulation functions include <code><a href="#topic+type_freqs">type_freqs()</a></code> to extract the frequencies
of different items, <code><a href="#topic+freqlist_merge">freqlist_merge()</a></code> to combine frequency lists, and
<code><a href="#topic+freqlist_diff">freqlist_diff()</a></code> to subtract a frequency list from another.
</p>
<p>Objects of class <code>freqlist</code> can be saved to file with <code><a href="#topic+write_freqlist">write_freqlist()</a></code>;
these files can be read with <code><a href="#topic+read_freqlist">read_freqlist()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+freqlist">freqlist()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
It consisted of three sentences. And it lived happily ever after."

## make frequency list in a roundabout way
tokens &lt;- tokenize(toy_corpus)
flist &lt;- as_freqlist(table(tokens))
flist

## more direct procedure
freqlist(toy_corpus, as_text = TRUE)

## build frequency list from scratch: example 1
flist &lt;- as_freqlist(c("a" = 12, "toy" = 53, "example" = 20))
flist

## build frequency list from scratch: example 2
flist &lt;- as_freqlist(c("a" = 12, "toy" = 53, "example" = 20),
                     tot_n_tokens = 1300)
flist
</code></pre>

<hr>
<h2 id='as_numeric'>Coerce object to a numeric vector</h2><span id='topic+as_numeric'></span><span id='topic+as_numeric.default'></span>

<h3>Description</h3>

<p>This generic method turns its first argument <code>x</code> or at least part of the information
in it into a numeric object. It is an alternative notation for <code><a href="base.html#topic+numeric">base::as.numeric()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_numeric(x, ...)

## Default S3 method:
as_numeric(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_numeric_+3A_x">x</code></td>
<td>
<p>An object to coerce.</p>
</td></tr>
<tr><td><code id="as_numeric_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(flist &lt;- freqlist(tokenize("The old story of the old man and the sea.")))

# extract frequency counts from a frequency list
as_numeric(flist)
as.numeric(flist)

# preferable alternative
type_freqs(flist)
</code></pre>

<hr>
<h2 id='as_tokens'>Coerce object to class <code>tokens</code></h2><span id='topic+as_tokens'></span>

<h3>Description</h3>

<p>This function coerces a character object or another object that can be coerced
to a character into an object of class <code><a href="#topic+tokens">tokens</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_tokens(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_tokens_+3A_x">x</code></td>
<td>
<p>Object to coerce.</p>
</td></tr>
<tr><td><code id="as_tokens_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+tokens">tokens</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
It consisted of three sentences. And it lived happily ever after."

tks &lt;- tokenize(toy_corpus)
print(tks, n = 1000)

tks[3:12]
print(as_tokens(tks[3:12]), n = 1000)
as_tokens(tail(tks))
</code></pre>

<hr>
<h2 id='as_types'>Coerce object to a vector of types</h2><span id='topic+as_types'></span>

<h3>Description</h3>

<p>This function coerces an object, such as a character vector, to an object of
class <code><a href="#topic+types">types</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as_types(x, remove_duplicates = TRUE, sort = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as_types_+3A_x">x</code></td>
<td>
<p>Object to coerce</p>
</td></tr>
<tr><td><code id="as_types_+3A_remove_duplicates">remove_duplicates</code></td>
<td>
<p>Logical. Should duplicates be removed from <code>x</code>
prior to coercing to a vector of types.</p>
</td></tr>
<tr><td><code id="as_types_+3A_sort">sort</code></td>
<td>
<p>Logical. Should <code>x</code> be
alphabetically sorted prior to coercing to a vector of types;
this argument is ignored if <code>remove_duplicates</code> is <code>TRUE</code>,
because the result of removing duplicates is always sorted.</p>
</td></tr>
<tr><td><code id="as_types_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code>types</code>, which is based on a character vector.
It has additional attributes and methods such as:
</p>

<ul>
<li><p> base <code><a href="#topic+print.types">print()</a></code>, <code><a href="#topic+as_data_frame">as_data_frame()</a></code>, <code><a href="base.html#topic+sort">sort()</a></code> and
<code><a href="base.html#topic+summary">base::summary()</a></code> (which returns the number of items and of unique items),
</p>
</li>
<li> <p><code><a href="tibble.html#topic+as_tibble">tibble::as_tibble()</a></code>,
</p>
</li>
<li><p> the <code><a href="#topic+n_types">n_types()</a></code> getter and the <code><a href="#topic+explore">explore()</a></code> method,
</p>
</li>
<li><p> subsetting methods such as <code><a href="#topic+keep_types">keep_types()</a></code>, <code><a href="#topic+keep_pos">keep_pos()</a></code>, etc. including <code style="white-space: pre;">&#8288;[]&#8288;</code>
subsetting (see <a href="#topic+brackets">brackets</a>).
</p>
</li></ul>

<p>An object of class <code>types</code> can be merged with another by means of <code><a href="#topic+types_merge">types_merge()</a></code>,
written to file with <code><a href="#topic+write_types">write_types()</a></code> and read from file with <code><a href="#topic+write_types">write_types()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+types">types()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
It consisted of three sentences. And it lived happily ever after."

flist &lt;- freqlist(toy_corpus, re_token_splitter = "\\W+", as_text = TRUE)
print(flist, n = 1000)
(sel_types &lt;- as_types(c("happily", "lived", "once")))
keep_types(flist, sel_types)
tks &lt;- tokenize(toy_corpus, re_token_splitter = "\\W+")
print(tks, n = 1000)
tks[3:12] # idx is relative to selection
head(tks) # idx is relative to selection
tail(tks) # idx is relative to selection
</code></pre>

<hr>
<h2 id='assoc_scores'>Association scores used in collocation analysis and keyword analysis</h2><span id='topic+assoc_scores'></span><span id='topic+assoc_abcd'></span>

<h3>Description</h3>

<p><code>assoc_scores</code> and <code>assoc_abcd</code> take as their arguments co-occurrence
frequencies of a number of items and return a range of association scores used
in collocation analysis, collostruction analysis and keyword analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assoc_scores(
  x,
  y = NULL,
  min_freq = 3,
  measures = NULL,
  with_variants = FALSE,
  show_dots = FALSE,
  p_fisher_2 = FALSE,
  haldane = TRUE,
  small_pos = 1e-05
)

assoc_abcd(
  a,
  b,
  c,
  d,
  types = NULL,
  measures = NULL,
  with_variants = FALSE,
  show_dots = FALSE,
  p_fisher_2 = FALSE,
  haldane = TRUE,
  small_pos = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="assoc_scores_+3A_x">x</code></td>
<td>
<p>Either an object of class <code><a href="#topic+freqlist">freqlist</a></code>
or an object of class <code><a href="#topic+create_cooc">cooc_info</a></code>.
</p>
<p>If <code>x</code> is a <code><a href="#topic+freqlist">freqlist</a></code>, it is interpreted as the target frequency
list (i.e. the list with the frequency of items in the target context) and
<code>y</code> must be a <code><a href="#topic+freqlist">freqlist</a></code> with the frequency of items in the
reference context.
</p>
<p>If <code>x</code> is an object of class <code><a href="#topic+create_cooc">cooc_info</a></code> instead, it is interpreted
as containing target frequency information, reference frequency information
and corpus size information.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_y">y</code></td>
<td>
<p>An object of class <code><a href="#topic+freqlist">freqlist</a></code> with the frequencies of the
reference context if <code>x</code> is also a <code><a href="#topic+freqlist">freqlist</a></code>. If <code>x</code> is an
object of class <code><a href="#topic+create_cooc">cooc_info</a></code>, this argument is ignored.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_min_freq">min_freq</code></td>
<td>
<p>Minimum value for <code>a[[i]]</code> (or for the frequency of an
item in the target frequency list) needed for its corresponding item to be
included in the output.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_measures">measures</code></td>
<td>
<p>Character vector containing the association measures (or related
quantities) for which scores are requested. Supported measure names (and
related quantities) are described in <code>Value</code> below.
</p>
<p>If <code>measures</code> is <code>NULL</code>, it is interpreted as short for the default selection,
i.e. <code>c("exp_a", "DP_rows", "RR_rows", "OR", "MS", "Dice", "PMI", "chi2_signed", "G_signed", "t", "fisher")</code>.
</p>
<p>If <code>measures</code> is <code>"ALL"</code>, all supported measures are calculated (but not
necessarily all the variants; see <code>with_variants</code>).</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_with_variants">with_variants</code></td>
<td>
<p>Logical. Whether, for the requested <code>measures</code>, all
variants should be included in the output (<code>TRUE</code>) or only the main
version (<code>FALSE</code>). See also <code>p_fisher_2</code>.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_show_dots">show_dots</code></td>
<td>
<p>Logical. Whether a dot should be shown in console each time
calculations for a measure are finished.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_p_fisher_2">p_fisher_2</code></td>
<td>
<p>Logical. only relevant if <code>"fisher"</code> is included in
<code>measures</code>. If <code>TRUE</code>, the p-value for a two-sided test (testing
for either attraction or repulsion) is also calculated. By default, only
the (computationally less demanding) p-value for a one-sided test is
calculated. See <code>Value</code> for more details.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_haldane">haldane</code></td>
<td>
<p>Logical. Should the Haldane-Anscombe correction be used?
(See the Details section.)
</p>
<p>If <code>haldane</code> is <code>TRUE</code>, and there is at least one zero frequency
in a contingency table, the correction is used for all measures calculated
for that table, not just for measures that need this to be done.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_small_pos">small_pos</code></td>
<td>
<p>Alternative (but sometimes inferior) approach to dealing with
zero frequencies, compared to <code>haldane</code>. The argument <code>small_pos</code>
only applies when <code>haldane</code> is set to <code>FALSE</code>.
(See the Details section.)
</p>
<p>If <code>haldane</code> is <code>FALSE</code>, and there is at least one zero frequency
in a contingency table, adding small positive values to the zero frequency
cells is done systematically for all measures calculated for that table,
not just for measures that need this to be done.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_a">a</code></td>
<td>
<p>Numeric vector expressing how many times some tested item
occurs in the target context.
More specifically, <code>a[[i]]</code>, with <code>i</code> an integer, expresses
how many times the <code>i</code>-th tested item occurs in the target context.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_b">b</code></td>
<td>
<p>Numeric vector expressing how many times other items than the tested
item occur in the target context.
More specifically, <code>b[[i]]</code>, with <code>i</code> an integer, expresses
how many times <em>other</em> items than the <code>i</code>-th tested item
occur in the target context.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_c">c</code></td>
<td>
<p>Numeric vector expressing how many times some tested
item occurs in the reference context.
More specifically, <code>c[[i]]</code>, with <code>i</code> an integer, expresses
how many times the <code>i</code>-th tested item occurs in the reference context.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_d">d</code></td>
<td>
<p>Numeric vector expressing how many times items other than the tested
item occur in the reference context.
More specifically, <code>d[[i]]</code>, with <code>i</code> an integer, expresses
how many times <em>other</em> items than the <code>i</code>-th tested item occur
in the reference context.</p>
</td></tr>
<tr><td><code id="assoc_scores_+3A_types">types</code></td>
<td>
<p>A character vector containing the names of the linguistic items
of which the association scores are to be calculated, or <code>NULL</code>. If
<code>NULL</code>, <code><a href="#topic+assoc_abcd">assoc_abcd()</a></code> creates dummy types such as <code>"t001"</code>,
<code>"t002"</code>, etc.</p>
</td></tr>
</table>


<h3>Details</h3>



<h4>Input and output</h4>

<p><code><a href="#topic+assoc_scores">assoc_scores()</a></code> takes as its arguments a target frequency list and a reference
frequency lists (either as two <code><a href="#topic+freqlist">freqlist</a></code> objects or as a
<code><a href="#topic+create_cooc">cooc_info</a></code> object) and returns a number of popular measures
expressing, for (almost) every item in either one of these lists, the extent
to which the item is attracted to the target context, when compared to the
reference context. The &quot;almost&quot; is added between parentheses because, with
the default settings, some items are automatically excluded from the output
(see <code>min_freq</code>).
</p>
<p><code><a href="#topic+assoc_abcd">assoc_abcd()</a></code> takes as its arguments four vectors <code>a</code>, <code>b</code>, <code>c</code>, and <code>d</code>, of
equal length. Each tuple of values <code style="white-space: pre;">&#8288;(a[i], b[i], c[i], d[i])&#8288;</code>, with <code>i</code> some
integer number between 1 and the length of the vectors, is assumed to represent
the four numbers <em>a</em>, <em>b</em>, <em>c</em>, <em>d</em> in a contingency table of the type:</p>

<table>
<tr>
 <td style="text-align: right;">
    </td><td style="text-align: right;"> <strong>tested item</strong> </td><td style="text-align: right;"> <strong>any other item</strong> </td><td style="text-align: right;"> <strong>total</strong> </td>
</tr>
<tr>
 <td style="text-align: right;">
   target context </td><td style="text-align: right;"> <em>a</em> </td><td style="text-align: right;"> <em>b</em> </td><td style="text-align: right;"> <em>m</em> </td>
</tr>
<tr>
 <td style="text-align: right;">
   reference context </td><td style="text-align: right;"> <em>c</em> </td><td style="text-align: right;"> <em>d</em> </td><td style="text-align: right;"> <em>n</em> </td>
</tr>
<tr>
 <td style="text-align: right;">
   total </td><td style="text-align: right;"> <em>k</em> </td><td style="text-align: right;"> <em>l</em> </td><td style="text-align: right;"> <em>N</em> </td>
</tr>
<tr>
 <td style="text-align: right;">
</td>
</tr>

</table>

<p>In the above table <em>m</em>, <em>n</em>, <em>k</em>, <em>l</em> and <em>N</em> are marginal frequencies.
More specifically, <em>m = a + b</em>, <em>n = c + d</em>, <em>k = a + c</em>, <em>l = b + d</em> and <em>N = m + n</em>.
</p>



<h4>Dealing with zeros</h4>

<p>Several of the association measures break down when one or more of the values
<code>a</code>, <code>b</code>, <code>c</code>, and <code>d</code> are zero (for instance, because this would lead to
division by zero or taking the log of zero). This can be dealt with in different
ways, such as the Haldane-Anscombe correction.
</p>
<p>Strictly speaking, Haldane-Anscombe correction specifically applies to the
context of (log) odds ratios for two-by-two tables and boils down to adding
<code>0.5</code> to each of the four values <code>a</code>, <code>b</code>, <code>c</code>, and <code>d</code>
in every two-by-two contingency table for which the original values
<code>a</code>, <code>b</code>, <code>c</code>, and <code>d</code> would not allow us to calculate
the (log) odds ratio, which happens when one (or more than one) of the four
cells is zero.
Using the Haldane-Anscombe correction, the (log) odds ratio is then calculated
on the bases of these 'corrected' values for <code>a</code>, <code>b</code>, <code>c</code>, and <code>d</code>.
</p>
<p>However, because other measures that do not compute (log) odds ratios might
also break down when some value is zero, all measures will be computed on the
'corrected' contingency matrix.
</p>
<p>If the <code>haldane</code> argument is set to <code>FALSE</code>, division by zero or taking the
log of zero is avoided by systematically adding a small positive value to all
zero values for <code>a</code>, <code>b</code>, <code>c</code>, and <code>d</code>. The argument <code>small_pos</code>
determines which small positive value is added in such cases. Its default value is <code>0.00001</code>.
</p>



<h3>Value</h3>

<p>An object of class <code>assoc_scores</code>. This is a kind of data frame with
as its rows all items from either the target frequency list or the reference
frequency list with a frequency larger than <code>min_freq</code> in the target list,
and as its columns a range of measures that express the extent to which
the items are attracted to the target context (when compared to the reference
context).
Some columns don't contain actual measures but rather additional information
that is useful for interpreting other measures.
</p>


<h4>Possible columns</h4>

<p>The following sections describe the (possible) columns in the output. All
of these measures are reported if <code>measures</code> is set to <code>"ALL"</code>. Alternatively,
each measure can be requested by specifying its name in a character vector
given to the <code>measures</code> argument. Exceptions are described in the sections
below.
</p>


<h5>Observed and expected frequencies</h5>


<ul>
<li> <p><code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>: The frequencies in cells <em>a</em>, <em>b</em>, <em>c</em> and <em>d</em>,
respectively. If one of them is <code>0</code>, they will be augmented by 0.5 or <code>small_pos</code>
(see <code>Details</code>). These output columns are always present.
</p>
</li>
<li> <p><code>dir</code>: The direction of the association: <code>1</code> in case of relative attraction
between the tested item and the target context (if <code class="reqn">\frac{a}{m} \ge \frac{c}{n}</code>) and
<code>-1</code> in case of relative repulsion between the target item and the target
context (if <code class="reqn">\frac{a}{m} &lt; {c}{n}</code>).
</p>
</li>
<li> <p><code>exp_a</code>, <code>exp_b</code>, <code>exp_c</code>, <code>exp_d</code>: The expected values for cells <em>a</em>, <em>b</em>,
<em>c</em> and <em>d</em>, respectively. All these columns will be included if <code>"expected"</code>
is in <code>measures</code>. <code>exp_a</code> is also one of the default measures and is therefore included
if <code>measures</code> is <code>NULL</code>. The values of these columns are computed as follows:
</p>

<ul>
<li> <p><code>exp_a</code> = <code class="reqn">\frac{m \times k}{N}</code>
</p>
</li>
<li> <p><code>exp_b</code> = <code class="reqn">\frac{m \times l}{N}</code>
</p>
</li>
<li> <p><code>exp_c</code> = <code class="reqn">\frac{n \times k}{N}</code>
</p>
</li>
<li> <p><code>exp_d</code> = <code class="reqn">\frac{n \times l}{N}</code>
</p>
</li></ul>

</li></ul>




<h5>Effect size measures</h5>

<p>Some of these measures are based on proportions and can therefore be
computed either on the rows or on the columns of the contingency table. Each
measure can be requested on its own, but pairs of measures can also be
requested with the first part of their name, as indicated in their corresponding
descriptions.
</p>

<ul>
<li> <p><code>DP_rows</code> and <code>DP_cols</code>: The difference of proportions, sometimes also
called Delta-p (<code class="reqn">\Delta p</code>), between rows and columns respectively.
Both columns are present if <code>"DP"</code> is included in <code>measures</code>. <code>DP_rows</code>
is also included if <code>measures</code> is <code>NULL</code>.
They are calculated as follows:
</p>

<ul>
<li> <p><code>DP_rows</code> = <code class="reqn">\frac{a}{m} - \frac{c}{n}</code>
</p>
</li>
<li> <p><code>DP_cols</code> = <code class="reqn">\frac{a}{k} - \frac{b}{l}</code>
</p>
</li></ul>

</li>
<li> <p><code>perc_DIFF_rows</code> and <code>perc_DIFF_cols</code>: These measures can be seen as
normalized versions of Delta-p, i.e. essentially the same measures divided
by the denominator and multiplied by <code>100</code>. They therefore express how large
the difference of proportions is, relative to the reference proportion.
The multiplication by <code>100</code> turns the resulting 'relative difference of
proportion' into a percentage.
Both columns are present if <code>"perc_DIFF"</code> is included in <code>measures</code>.
They are calculated as follows:
</p>

<ul>
<li> <p><code>perc_DIFF_rows</code> = <code class="reqn">100 * \frac{(a / m) - (c / n)}{c / n}</code>
</p>
</li>
<li> <p><code>perc_DIFF_cols</code> = <code class="reqn">100 * \frac{(a / k) - (b / l)}{c / n}</code>
</p>
</li></ul>

</li>
<li> <p><code>DC_rows</code> and <code>DC_cols</code>: The difference coefficient can be seen as a
normalized version of Delta-p, i.e. essentially dividing the difference of
proportions by the sum of proportions.
Both columns are present if <code>"DC"</code> is included in <code>measures</code>.
They are calculated as follows:
</p>

<ul>
<li> <p><code>DC_rows</code> = <code class="reqn">\frac{(a / m) - (c / n)}{(a / m) + (c / n)}</code>
</p>
</li>
<li> <p><code>DC_cols</code> = <code class="reqn">\frac{(a / k) - (b / l)}{(a / k) + (b / l)}</code>
</p>
</li></ul>

</li>
<li> <p><code>RR_rows</code> and <code>RR_cols</code>: Relative risk for the rows and columns
respectively. <code>RR_rows</code> represents then how large the proportion in the
target context is, relative to the proportion in the reference context.
Both columns are present if <code>"RR"</code> is included in <code>measures</code>.
<code>RR_rows</code> is also included if <code>measures</code> is <code>NULL</code>.
They are calculated as follows:
</p>

<ul>
<li> <p><code>RR_rows</code> = <code class="reqn">\frac{a / m}{c / n}</code>
</p>
</li>
<li> <p><code>RR_cols</code> = <code class="reqn">\frac{a / k}{b / l}</code>
</p>
</li></ul>

</li>
<li> <p><code>LR_rows</code> and <code>LR_cols</code>: The so-called 'log ratio' of the rows and
columns, respectively. It can be seen as a transformed version of the relative
risk, viz. its binary log.
Both columns are present if <code>"LR"</code> is included in <code>measures</code>.
They are calculated as follows:
</p>

<ul>
<li> <p><code>LR_rows</code> = <code class="reqn">\log_2\left(\frac{a / m}{c / n}\right)</code>
</p>
</li>
<li> <p><code>LR_cols</code> = <code class="reqn">\log_2\left(\frac{a / k}{b / l}\right)</code>
</p>
</li></ul>

</li></ul>

<p>Other measures use the contingency table in a different way and therefore
don't have a complementary row/column pair. In order to retrieve these columns,
if <code>measures</code> is not <code>"ALL"</code>, their name must be in the <code>measures</code> vector.
Some of them are included by default, i.e. if <code>measures</code> is <code>NULL</code>.
</p>

<ul>
<li> <p><code>OR</code>: The odds ratio, which can be calculated either as
<code class="reqn">\frac{a/b}{c/d}</code> or as <code class="reqn">\frac{a/c}{b/d}</code>.
This column is present <code>measures</code> is <code>NULL</code>.
</p>
</li>
<li> <p><code>log_OR</code>: The log odds ratio, which can be calculated either as
<code class="reqn">\log\left(\frac{a/b}{c/d}\right)</code> or as <code class="reqn">\log\left(\frac{a/c}{b/d}\right)</code>.
In other words, it is the natural log of the odds ratio.
</p>
</li>
<li> <p><code>MS</code>: The minimum sensitivity, which is calculated as
<code class="reqn">\min(\frac{a}{m}, \frac{a}{k})</code>.
In other words, it is either <code class="reqn">\frac{a}{m}</code> or <code class="reqn">\frac{a}{k}</code>, whichever is lowest.
This column is present <code>measures</code> is <code>NULL</code>.
</p>
</li>
<li> <p><code>Jaccard</code>: The Jaccard index, which is calculated as
<code class="reqn">\frac{a}{a + b + c}</code>. It expresses <em>a</em>, which is the frequency of the
test item in the target context, relative to <em>b + c + d</em>, i.e. the frequency
of all other contexts.
</p>
</li>
<li> <p><code>Dice</code>: The Dice coefficient, which is calculated as
<code class="reqn">\frac{2a}{m + k}</code>. It expresses the harmonic mean of <code class="reqn">\frac{a}{m}</code> and <code class="reqn">\frac{a}{k}</code>
This column is present <code>measures</code> is <code>NULL</code>.
</p>
</li>
<li> <p><code>logDice</code>: An adapted version of the Dice coefficient. It is calculated as
<code class="reqn">14 + \log_2\left(\frac{2a}{m + k}\right)</code>. In other words, it is <code>14</code>
plus the binary log of the Dice coefficient.
</p>
</li>
<li> <p><code>phi</code>: The phi coefficient (<code class="reqn">\phi</code>), which is calculated as
<code class="reqn">\frac{(a \times d) - (b \times c)}{ \sqrt{m \times n \times k \times l}}</code>.
</p>
</li>
<li> <p><code>Q</code>: Yule's Q, which is calculated as
<code class="reqn">\frac{(a \times d) - (b \times c)}{(a \times d)(b \times c)}</code>.
</p>
</li>
<li> <p><code>mu</code>: The measure mu (<code class="reqn">\mu</code>), which is calculated as
<code class="reqn">\frac{a}{\mathrm{exp\_a}}</code> (see <code>exp_a</code>).
</p>
</li>
<li> <p><code>PMI</code> and <code>pos_PMI</code>: (Positive) pointwise mutual information,
which can be seen as a modification of the mu measure and is calculated as
<code class="reqn">\log_2\left(\frac{a}{\mathrm{exp\_a}}\right)</code>. In <code>pos_PMI</code>, negative
values are set to <code>0</code>.
The <code>PMI</code> column is present <code>measures</code> is <code>NULL</code>.
</p>
</li>
<li> <p><code>PMI2</code> and <code>PMI3</code>: Modified versions of <code>PMI</code> that aim to give relatively
more weight to cases with relatively higher <em>a</em>. However, because of this
modification, they are not pure effect size measures any more.
</p>

<ul>
<li> <p><code>PMI2</code> = <code class="reqn">\log_2\left(\frac{a^2}{\mathrm{exp\_a}}\right)</code>
</p>
</li>
<li> <p><code>PMI3</code> = <code class="reqn">\log_2\left(\frac{a^3}{\mathrm{exp\_a}}\right)</code>
</p>
</li></ul>

</li></ul>




<h5>Strength of evidence measures</h5>

<p>The first measures in this section tend to come in triples: a test statistic,
its p-value (preceded by <code>p_</code>) and its signed version (followed by <code style="white-space: pre;">&#8288;_signed&#8288;</code>).
The test statistics indicate evidence of either attraction or repulsion.
Thus, in order to indicate the direction of the relationship, a negative
sign is added in the &quot;signed&quot; version when <code class="reqn">\frac{a}{k} &lt; \frac{c}{l}</code>.
</p>
<p>In each of these cases, the name of the main measure (e.g. <code>"chi2"</code>)
and/or its signed counterpart (e.g. <code>"chi2_signed"</code>) must be in the <code>measures</code>
argument, or <code>measures</code> must be <code>"ALL"</code>, for the columns to be included in
the output. If the main function is requested, the signed counterpart will
also be included, but if only the signed counterpart is requested, the non-signed
version will be excluded.
For the p-value to be retrieved, either the main measure or its signed version
must be requested and, <em>additionally</em>, the <code>with_variants</code> argument must be
set to <code>TRUE</code>.
</p>

<ul>
<li> <p><code>chi2</code>, <code>p_chi2</code> and <code>chi2_signed</code>: The chi-squared test statistic
(<code class="reqn">\chi^2</code>) as used in a chi-squared test of independence or in a
chi-squared test of homogeneity for a two-by-two contingency table.
Scores of this measure are high when there is strong evidence for attraction,
but also when there is strong evidence for repulsion.
The <code>chi2_signed</code> column is present if <code>measures</code> is <code>NULL</code>.
<code>chi2</code> is calculated as follows: </p>
<p style="text-align: center;"><code class="reqn">
                        \frac{(a-\mathrm{exp\_a})^2}{\mathrm{exp\_a}} +
                        \frac{(b-\mathrm{exp\_b})^2}{\mathrm{exp\_b}} +
                        \frac{(c-\mathrm{exp\_c})^2}{\mathrm{exp\_c}} +
                        \frac{(d-\mathrm{exp\_d})^2}{\mathrm{exp\_d}}
                       </code>
</p>
<p>.
</p>
</li>
<li> <p><code>chi2_Y</code>, <code>p_chi2_Y</code> and <code>chi2_Y_signed</code>: The chi-squared test statistic
(<code class="reqn">\chi^2</code>) as used in a chi-squared test with Yates correction
for a two-by-two contingency table.
<code>chi2_Y</code> is calculated as follows: </p>
<p style="text-align: center;"><code class="reqn">
                        \frac{(|a-\mathrm{exp\_a}| - 0.5)^2}{\mathrm{exp\_a}} +
                        \frac{(|b-\mathrm{exp\_b}| - 0.5)^2}{\mathrm{exp\_b}} +
                        \frac{(|c-\mathrm{exp\_c}| - 0.5)^2}{\mathrm{exp\_c}} +
                        \frac{(|d-\mathrm{exp\_d}| - 0.5)^2}{\mathrm{exp\_d}}
                       </code>
</p>
<p>.
</p>
</li>
<li> <p><code>chi2_2T</code>, <code>p_chi2_2T</code> and <code>chi2_2T_signed</code>: The chi-squared test statistic
(<code class="reqn">\chi^2</code>) as used in a chi-squared goodness-of-fit test applied to the
first column of the contingency table. The <code>"2T"</code> in the name stands for
'two terms' (as opposed to <code>chi2</code>, which is sometimes the 'four terms' version).
<code>chi2_2T</code> is calculated as follows: </p>
<p style="text-align: center;"><code class="reqn">
                        \frac{(a-\mathrm{exp\_a})^2}{\mathrm{exp\_a}} +
                        \frac{(c-\mathrm{exp\_c})^2}{\mathrm{exp\_c}}
                       </code>
</p>
<p>.
</p>
</li>
<li> <p><code>chi2_2T_Y</code>, <code>p_chi2_2T_Y</code> and <code>chi2_2T_Y_signed</code>: The chi-squared test statistic
(<code class="reqn">\chi^2</code>) as used in a chi-squared goodness-of-fit test with Yates correction, applied to the
first column of the contingency table.
<code>chi2_2T_Y</code> is calculated as follows: </p>
<p style="text-align: center;"><code class="reqn">
                          \frac{(|a-\mathrm{exp\_a}| - 0.5)^2}{\mathrm{exp\_a}} +
                          \frac{(|c-\mathrm{exp\_c}| - 0.5)^2}{\mathrm{exp\_c}}
                         </code>
</p>
<p>.
</p>
</li>
<li> <p><code>G</code>, <code>p_G</code> and <code>G_signed</code>: G test statistic, which is also sometimes
called log-likelihood ratio (LLR) and, somewhat confusingly, G-squared.
This is the test statistic as used in a log-likelihood ratio test for independence
or homogeneity in a two-by-two contingency table.
Scores are high in case of strong evidence for attraction, but also in case
of strong evidence of repulsion.
The <code>G_signed</code> column is present if <code>measures</code> is <code>NULL</code>.
<code>G</code> is calculated as follows: </p>
<p style="text-align: center;"><code class="reqn">
                  2 \left(
                  a \times \log(\frac{a}{\mathrm{exp\_a}}) +
                  b \times \log(\frac{b}{\mathrm{exp\_b}}) +
                  c \times \log(\frac{c}{\mathrm{exp\_c}}) +
                  d \times \log(\frac{d}{\mathrm{exp\_d}})
                  \right)
                 </code>
</p>

</li>
<li> <p><code>G_2T</code>, <code>p_G_2T</code> and <code>G_2T_signed</code>: The test statistic
used in a log-likelihood ratio test for goodness-of-fit applied to the first
column of the contingency table.
The <code>"2T"</code> stands for 'two terms'.
<code>G_2T</code> is calculated as follows: </p>
<p style="text-align: center;"><code class="reqn">
                  2 \left(
                  a \times \log(\frac{a}{\mathrm{exp\_a}}) +
                  c \times \log(\frac{c}{\mathrm{exp\_c}})
                  \right)
                 </code>
</p>

</li></ul>

<p>The final two groups of measures take a different shape. The
<code style="white-space: pre;">&#8288;_as_chisq1&#8288;</code> columns compute <code>qchisq(1 - p, 1)</code>, with <code>p</code> being the p-values
they are transforming, i.e. the <code>p</code> right quantile in a <code class="reqn">\chi^2</code>
distribution with one degree of freedom (see <code><a href="#topic+p_to_chisq1">p_to_chisq1()</a></code>).
</p>

<ul>
<li> <p><code>t</code>, <code>p_t_1</code>, <code>t_1_as_chisq1</code>, <code>p_t_2</code> and <code>t_2_as_chisq1</code>:
The t-test statistic, used for a t-test for the proportion <code class="reqn">\frac{a}{N}</code>
in which the null hypothesis is based on <code class="reqn">\frac{k}{N}\times\frac{m}{N}</code>.
Column <code>t</code> is present if <code>"t"</code> is included in <code>measures</code> or if <code>measures</code> is
<code>"ALL"</code> or <code>NULL</code>. The other four columns are present if <code>t</code> is requested and if,
additionally, <code>with_variants</code> is <code>TRUE</code>.
</p>

<ul>
<li> <p><code>t</code> = <code class="reqn">
                   \frac{
                   a/N + k/N + m/N
                   }{
                   \sqrt{((a/N)\times (1-a/N))/N}
                   }
                    </code>
</p>
</li>
<li> <p><code>p_t_1</code> is the p-value that corresponds to <code>t</code> when assuming a one-tailed
test that only looks at attraction; <code>t_1_as_chisq1</code> is its transformation.
</p>
</li>
<li> <p><code>p_t_2</code> is the p-value that corresponds to <code>t</code> when assuming a two-tailed
test, viz. that looks at both attraction and repulsion; <code>t_2_as_chisq1</code> is
its transformation.
</p>
</li></ul>

</li>
<li> <p><code>p_fisher_1</code>, <code>fisher_1_as_chisq1</code>, <code>p_fisher_1r</code>, <code>fisher_1r_as_chisq1</code>:
The p-value of a one-sided Fisher exact test.
The column <code>p_fisher_1</code> is present if either <code>"fisher"</code> or <code>"p_fisher"</code> are in <code>measures</code>
or if <code>measures</code> is <code>"ALL"</code> or <code>NULL</code>. The other columns are present if <code>p_fisher_1</code> as
been requested and if, additionally, <code>with_variants</code> is <code>TRUE</code>.
</p>

<ul>
<li> <p><code>p_fisher_1</code> and <code>p_fisher_1r</code> are the p-values of the Fisher exact test
that look at attraction and repulsion respectively.
</p>
</li>
<li> <p><code>fisher_1_as_chisq1</code> and <code>fisher_1r_as_chisq1</code> are their respective transformations..
</p>
</li></ul>

</li>
<li> <p><code>p_fisher_2</code> and <code>fisher_2_as_chisq1</code>: p-value for a two-sided Fisher
exact test, viz. looking at both attraction and repulsion. <code>p_fisher_2</code>
returns the p-value and <code>fisher_2_as_chisq1</code> is its transformation.
The <code>p_fisher_2</code> column is present if either <code>"fisher"</code> or <code>"p_fisher_1"</code> are
in <code>measures</code> or if <code>measures</code> is <code>"ALL"</code> or <code>NULL</code> and if, additionally, <code>p_fisher_2</code> is
<code>TRUE</code>. <code>fisher_2_as_chisq1</code> is present if <code>p_fisher_2</code> was requested and,
additionally, <code>with_variants</code> is <code>TRUE</code>.
</p>
</li></ul>





<h4>Properties of the class</h4>

<p>An object of class <code>assoc_scores</code> has:
</p>

<ul>
<li><p> associated <code><a href="base.html#topic+as.data.frame">as.data.frame()</a></code>, <code><a href="#topic+print.assoc_scores">print()</a></code>,
<code><a href="#topic+sort.assoc_scores">sort()</a></code> and <code><a href="tibble.html#topic+as_tibble">tibble::as_tibble()</a></code> methods,
</p>
</li>
<li><p> an interactive <code><a href="#topic+explore">explore()</a></code> method and useful getters, viz. <code><a href="#topic+n_types">n_types()</a></code> and
<code><a href="#topic+type_names">type_names()</a></code>.
</p>
</li></ul>

<p>An object of this class can be saved to file with <code><a href="#topic+write_assoc">write_assoc()</a></code> and read
with <code><a href="#topic+read_assoc">read_assoc()</a></code>.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>assoc_abcd(10 , 200, 100,  300, types = "four")
assoc_abcd(30, 1000,  14, 5000, types = "fictitious")
assoc_abcd(15, 5000,  16, 1000, types = "toy")
assoc_abcd( 1,  300,   4, 6000, types = "examples")

a &lt;- c(10,    30,    15,    1)
b &lt;- c(200, 1000,  5000,  300)
c &lt;- c(100,   14,    16,    4)
d &lt;- c(300, 5000, 10000, 6000)
types &lt;- c("four", "fictitious", "toy", "examples")
(scores &lt;- assoc_abcd(a, b, c, d, types = types))

as_data_frame(scores)
as_tibble(scores)

print(scores, sort_order = "PMI")
print(scores, sort_order = "alpha")
print(scores, sort_order = "none")
print(scores, sort_order = "nonsense")

print(scores, sort_order = "PMI",
      keep_cols = c("a", "exp_a", "PMI", "G_signed"))
print(scores, sort_order = "PMI",
      keep_cols = c("a", "b", "c", "d", "exp_a", "G_signed"))
print(scores, sort_order = "PMI",
     drop_cols = c("a", "b", "c", "d", "exp_a", "G_signed",
                    "RR_rows", "chi2_signed", "t"))
</code></pre>

<hr>
<h2 id='brackets'>Subset an object by different criteria</h2><span id='topic+brackets'></span><span id='topic++5B.fnames'></span><span id='topic++5B+3C-.fnames'></span><span id='topic++5B.freqlist'></span><span id='topic++5B.tokens'></span><span id='topic++5B+3C-.tokens'></span><span id='topic++5B.types'></span><span id='topic++5B+3C-.types'></span>

<h3>Description</h3>

<p>This method can be used to subset objects based on different criteria.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fnames'
x[i, invert = FALSE, ...]

## S3 replacement method for class 'fnames'
x[i, invert = FALSE] &lt;- value

## S3 method for class 'freqlist'
x[i, invert = FALSE, ...]

## S3 method for class 'tokens'
x[i, invert = FALSE, ...]

## S3 replacement method for class 'tokens'
x[i, invert = FALSE, ...] &lt;- value

## S3 method for class 'types'
x[i, invert = FALSE, ...]

## S3 replacement method for class 'types'
x[i, invert = FALSE] &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brackets_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="brackets_+3A_i">i</code></td>
<td>
<p>Selection criterion; depending on its class, it behaves differently.</p>
</td></tr>
<tr><td><code id="brackets_+3A_invert">invert</code></td>
<td>
<p>Logical. Whether the matches should be selected rather than the
non-matches.</p>
</td></tr>
<tr><td><code id="brackets_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
<tr><td><code id="brackets_+3A_value">value</code></td>
<td>
<p>Value to assign.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The subsetting method with the notation <code style="white-space: pre;">&#8288;[]&#8288;</code>, applied to mclm objects,
is part of a family of subsetting methods: see <code><a href="#topic+keep_pos">keep_pos()</a></code>, <code><a href="#topic+keep_re">keep_re()</a></code>,
<code><a href="#topic+keep_types">keep_types()</a></code> and <code><a href="#topic+keep_bool">keep_bool()</a></code>. In this case, the argument <code>i</code> is the selection
criterion and, depending on its class, the method behaves different:
</p>

<ul>
<li><p> providing a <code><a href="#topic+re">re</a></code> object is equivalent to calling <code><a href="#topic+keep_re">keep_re()</a></code>,
</p>
</li>
<li><p> providing a numeric vector is equivalent to calling <code><a href="#topic+keep_pos">keep_pos()</a></code>,
</p>
</li>
<li><p> providing a logical vector is equivalent to calling <code><a href="#topic+keep_bool">keep_bool()</a></code>,
</p>
</li>
<li><p> providing a <code><a href="#topic+types">types</a></code> object or a character vector is equivalent to calling <code><a href="#topic+keep_types">keep_types()</a></code>.
</p>
</li></ul>

<p>When the notation <code>x[i, ...]</code> is used, it is also possible to set the <code>invert</code>
argument to <code>TRUE</code> (which then is one of the additional arguments in <code>...</code>).
This <code>invert</code> argument then serves the same purpose as the <code>invert</code> argument
in the <code>keep_</code> methods, turning it into a <code>drop_</code> method.
</p>


<h3>Value</h3>

<p>Object of the same class as <code>x</code> with the selected elements only.
</p>


<h3>See Also</h3>

<p>Other subsetters: 
<code><a href="#topic+keep_bool">keep_bool</a>()</code>,
<code><a href="#topic+keep_pos">keep_pos</a>()</code>,
<code><a href="#topic+keep_re">keep_re</a>()</code>,
<code><a href="#topic+keep_types">keep_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For a 'freqlist' object --------------------
(flist &lt;- freqlist("The man and the mouse.", as_text = TRUE))

## like keep_re()
flist[re("[ao]")]
flist[re("[ao]"), invert = TRUE]

## like keep_pos()
flist[type_freqs(flist) &lt; 2]
flist[ranks(flist) &lt;= 3]
flist[ranks(flist) &lt;= 3, invert = TRUE]
flist[2:3]

## like keep_bool()
(flist2 &lt;- keep_bool(flist, type_freqs(flist) &lt; 2))
flist2[orig_ranks(flist2) &gt; 2]

## like keep_types()
flist[c("man", "and")]
flist[as_types(c("man", "and"))]

# For a 'types' object -----------------------
(tps &lt;- as_types(letters[1:10]))

tps[c(1, 3, 5, 7, 9)]
tps[c(TRUE, FALSE)]
tps[c("a", "c", "e", "g", "i")]

tps[c(1, 3, 5, 7, 9), invert = TRUE]
tps[c(TRUE, FALSE), invert = TRUE]
tps[c("a", "c", "e", "g", "i"), invert = TRUE]

# For a 'tokens' object ----------------------
(tks &lt;- as_tokens(letters[1:10]))

tks[re("[acegi]"), invert = TRUE]
tks[c(1, 3, 5, 7, 9), invert = TRUE]
tks[c(TRUE, FALSE), invert = TRUE]
tks[c("a", "c", "e", "g", "i"), invert = TRUE]
</code></pre>

<hr>
<h2 id='ca_help'>Helpers for plotting <code>ca</code> objects</h2><span id='topic+ca_help'></span><span id='topic+row_pcoord'></span><span id='topic+col_pcoord'></span><span id='topic+xlim4ca'></span><span id='topic+ylim4ca'></span>

<h3>Description</h3>

<p>The functions <code>row_pcoord()</code> and <code>col_pcoord()</code> retrieve the coordinates of
the rows and columns of a <code><a href="ca.html#topic+ca">ca</a></code> object across all dimensions.
The functions <code>xlim4ca()</code> and <code>ylim4ca()</code> return the range of values for the
first and second dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>row_pcoord(x, ...)

col_pcoord(x, ...)

xlim4ca(x, ...)

ylim4ca(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ca_help_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="ca.html#topic+ca">ca</a></code>.</p>
</td></tr>
<tr><td><code id="ca_help_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the output of <code>row_pcoord()</code>, each row corresponds to a row from the dataframe
that <code><a href="ca.html#topic+ca">ca::ca()</a></code> was applied to, and each column corresponds to a principal component.
In the output of <code>col_pcoord()</code>, each row corresponds to a column from the dataframe
that <code><a href="ca.html#topic+ca">ca::ca()</a></code> was applied to, and each column corresponds to a principal component.
</p>


<h3>Value</h3>

<p>A matrix (for <code>row_pcoord()</code> and <code>col_pcoord()</code>) or a numeric vector
(for <code>xlim4ca()</code> and <code>ylim4ca()</code>).
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>row_pcoord()</code>: Retrieve row principal coordinates for all dimensions
</p>
</li>
<li> <p><code>col_pcoord()</code>: Retrieve column principal coordinates for all dimensions
</p>
</li>
<li> <p><code>xlim4ca()</code>: Return range of first dimension for plotting
</p>
</li>
<li> <p><code>ylim4ca()</code>: Return range of second dimension for plotting
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>
# traditional biplot from {ca}

library(ca)
data("author")
author_ca &lt;- ca(author)
plot(author_ca)

# alternative plot with {mclm} tools
r_pc &lt;- row_pcoord(author_ca)
c_pc &lt;- col_pcoord(author_ca)
xlim &lt;- xlim4ca(author_ca)
ylim &lt;- ylim4ca(author_ca)
author_names &lt;- as.factor(gsub(
                              "^.*?\\((.*?)\\)$", "\\1",
                             rownames(author), perl = TRUE))
plot(r_pc[,1], r_pc[,2], pch = 18,
    xlim = xlim, ylim = ylim, xlab = "", ylab = "",
    main = "authors and their alphabet",
    col = as.numeric(author_names))
abline(h = 0, col = "gray", lty = 3)
abline(v = 0, col = "gray", lty = 3)
text(c_pc[,1], c_pc[,2], colnames(author), col = "gray")
legend("topright",
       legend = levels(author_names),
       pch = rep(18, length(levels(author_names))),
       col = 1:length(levels(author_names)),
       title = "authors")
</code></pre>

<hr>
<h2 id='cat_re'>Print a regular expression to the console</h2><span id='topic+cat_re'></span>

<h3>Description</h3>

<p>The function <code><a href="#topic+cat_re">cat_re()</a></code> prints a regular expression to the console.
By default, the regular expression is not printed as an R string,
but as a &lsquo;plain regular expression&rsquo;. More specifically, the regular expression
is printed without surrounding quotation marks, and characters that are
special characters in R strings (such as quotation marks and backslashes)
are not escaped with a backslash. Also, by default, multi-line regular expressions are
printed as single-line regular expressions with all regular expression comments removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cat_re(x, format = c("plain", "R"), as_single_line = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cat_re_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+re">re</a></code> or a character vector containing a regular
expression. If <code>x</code> is a character vector of length higher than 1, only its
first element will be used.</p>
</td></tr>
<tr><td><code id="cat_re_+3A_format">format</code></td>
<td>
<p>Character vector describing the requested format (as a <code>"plain"</code>
regular expression or as an <code>"R"</code> string). If its length is higher than 1,
only its first element will be used.</p>
</td></tr>
<tr><td><code id="cat_re_+3A_as_single_line">as_single_line</code></td>
<td>
<p>Logical. Whether <code>x</code> should be converted to a single line
regular expression, therefore also removing all comments, prior to printing.
If the length of this vector is larger than 1, only its first item will be used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>WARNING: In the current implementation, the way the character <code style="white-space: pre;">&#8288;#&#8288;</code> is handled is
not guaranteed to be correct. More specifically, the code is not guaranteed
to correctly distinguish between a <code style="white-space: pre;">&#8288;#&#8288;</code> symbol that introduces a regular
expression comment and a <code style="white-space: pre;">&#8288;#&#8288;</code> symbol that doesn't do so. Firstly,
there is no testing whether at the point of encountering <code style="white-space: pre;">&#8288;#&#8288;</code> we're in
free-spacing mode. Second, there is no thorough testing whether or not
the <code style="white-space: pre;">&#8288;#&#8288;</code> symbol is part of a character class.
However, <code style="white-space: pre;">&#8288;#&#8288;</code> is processed correctly as long as any 'literal #' is
immediately preceded by either a backslash or an opening square bracket,
and any &lsquo;comment-introducing #&rsquo; is not immediately preceded by
a backslash or an opening square bracket.
</p>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scan_re">scan_re()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># single-line regular expression
x &lt;- "(?xi)  \\b \\w* willing \\w* \\b"
cat_re(x)
y &lt;- "(?xi)  
       \\b        # word boundary 
       \\w*       # optional prefix
       willing   # stem
       \\w*       # optional suffix
       \\b        # word boundary"
cat_re(y)
cat_re(y, as_single_line = FALSE)
cat_re(y, format = "R")
cat_re(y, format = "R", as_single_line = FALSE)

regex &lt;- re("(?xi)  
                \\b        # word boundary 
                \\w*       # optional prefix
                willing   # stem
                \\w*       # optional suffix
                \\b        # word boundary")
cat_re(regex)
cat_re(regex, as_single_line = FALSE)
</code></pre>

<hr>
<h2 id='chisq1_to_p'>Proportion of chi-squared distribution with one degree of freedom that sits to the right of x</h2><span id='topic+chisq1_to_p'></span>

<h3>Description</h3>

<p>Helper function that takes as its argument a numerical value <code>x</code> and
that returns the proportion <em>p</em> of the chi-squared
distribution with one degree of freedom that sits to the right of the
value 'x.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chisq1_to_p(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="chisq1_to_p_+3A_x">x</code></td>
<td>
<p>A number.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The proportion <em>p</em> of the chi-squared distribution with one
degree of freedom that sits to the right of the value <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+p_to_chisq1">p_to_chisq1()</a></code>
</p>

<hr>
<h2 id='cleanup_spaces'>Clean up the use of whitespace in a character vector</h2><span id='topic+cleanup_spaces'></span>

<h3>Description</h3>

<p>The function <code><a href="#topic+cleanup_spaces">cleanup_spaces()</a></code> takes a character vector and input and turns
any uninterrupted stretch of whitespace characters into one single space character.
Moreover, it can also <em>remove</em> leading whitespace and trailing whitespace.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cleanup_spaces(x, remove_leading = TRUE, remove_trailing = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cleanup_spaces_+3A_x">x</code></td>
<td>
<p>Character vector.</p>
</td></tr>
<tr><td><code id="cleanup_spaces_+3A_remove_leading">remove_leading</code></td>
<td>
<p>Logical. If <code>TRUE</code>, leading whitespace will be removed.</p>
</td></tr>
<tr><td><code id="cleanup_spaces_+3A_remove_trailing">remove_trailing</code></td>
<td>
<p>Logical. If <code>TRUE</code>, trailing whitespace will be removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>txt &lt;- "  A \\t  small      example \\n with redundant whitespace    "
cleanup_spaces(txt)
cleanup_spaces(txt, remove_leading = FALSE, remove_trailing = FALSE)
</code></pre>

<hr>
<h2 id='conc'>Build a concordance for the matches of a regex</h2><span id='topic+conc'></span>

<h3>Description</h3>

<p>This function builds a concordance for the matches of a regular expression. The result is a
dataset that can be written to a file with the function <code><a href="#topic+write_conc">write_conc()</a></code>.
It mimics the behavior of the concordance tool in the program AntConc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>conc(
  x,
  pattern,
  c_left = 200,
  c_right = 200,
  perl = TRUE,
  re_drop_line = NULL,
  line_glue = "\n",
  re_cut_area = NULL,
  file_encoding = "UTF-8",
  as_text = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="conc_+3A_x">x</code></td>
<td>
<p>A character vector determining which text is to be used as corpus.
</p>
<p>If <code>as_text = TRUE</code>, <code>x</code> is treated as the actual text to be used
as corpus.
</p>
<p>If <code>as_text = FALSE</code> (the default), <code>x</code> is treated as a vector of
filenames, interpreted as the names of the corpus files that contain the
actual corpus data.</p>
</td></tr>
<tr><td><code id="conc_+3A_pattern">pattern</code></td>
<td>
<p>Character string containing the regular expression that serves
as search term for the concordancer.</p>
</td></tr>
<tr><td><code id="conc_+3A_c_left">c_left</code></td>
<td>
<p>Number. How many characters to the left of each match must be
included in the result as left co-text of the match.</p>
</td></tr>
<tr><td><code id="conc_+3A_c_right">c_right</code></td>
<td>
<p>Number. How many characters to the right of each match must be
included in the result as right co-text of the match.</p>
</td></tr>
<tr><td><code id="conc_+3A_perl">perl</code></td>
<td>
<p>If <code>TRUE</code>, <code>pattern</code> is treated as a PCRE flavor regular
expression. Otherwise, <code>pattern</code> is treated as a regular expression in R's
default flavor of regular expression.</p>
</td></tr>
<tr><td><code id="conc_+3A_re_drop_line">re_drop_line</code></td>
<td>
<p>Character vector or <code>NULL</code>. If <code>NULL</code>, the argument
is ignored.
Otherwise, lines in <code>x</code> containing a match for <code>re_drop_line</code> are
treated as not belonging to the corpus and are excluded from the results.</p>
</td></tr>
<tr><td><code id="conc_+3A_line_glue">line_glue</code></td>
<td>
<p>Character vector or <code>NULL</code>. If <code>NULL</code>, the argument
is ignored.
Otherwise, all lines in the corpus are glued together in one character
vector of length 1, with the string <code>line_glue</code> pasted in between
consecutive lines.
The value of <code>line_glue</code> can also be equal to the empty string (<code>""</code>).
The 'line_glue' operation is conducted immediately after the 'drop line' operation.</p>
</td></tr>
<tr><td><code id="conc_+3A_re_cut_area">re_cut_area</code></td>
<td>
<p>Character vector or <code>NULL</code>. If <code>NULL</code>, the argument
is ignored.
Otherwise, all matches in the corpus are 'cut out' of the text prior to the
identification of the tokens in the text (and are therefore not taken into
account when identifying tokens).
The 'cut area' operation is conducted immediately after the 'line glue' operation.</p>
</td></tr>
<tr><td><code id="conc_+3A_file_encoding">file_encoding</code></td>
<td>
<p>File encoding for reading each corpus file. Ignored if
<code>as_text = TRUE</code>. Otherwise, it must be a character vector of length one
(in which case the same encoding is used for all files) or with the same
length as <code>x</code> (in which case each file can have a different encoding).</p>
</td></tr>
<tr><td><code id="conc_+3A_as_text">as_text</code></td>
<td>
<p>Logical.
If <code>TRUE</code>, the content of <code>x</code> is treated
as the actual text of the corpus (with each item within <code>x</code> treated as
a separate 'document in RAM').
</p>
<p>If <code>FALSE</code>, <code>x</code> is treated as a vector of filenames, interpreted
as the names of the corpus files with the actual corpus data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to make sure that the columns <code>left</code>, <code>match</code>,
and <code>right</code> in the output of <code>conc</code> do not contain any TAB or NEWLINE
characters, whitespace in these items is being 'normalized'.
More particularly, each stretch of whitespace, i.e. each  uninterrupted
sequences of whitespace characters, is replaced by  a single SPACE character.
</p>
<p>The values in the items the <code>glob_id</code> and <code>id</code> in the output
of <code>conc</code> are always identical in a dataset that is the output of the
function <code>conc</code>. The item <code>glob_id</code> only becomes useful when later,
for instance, one wants to merge two datasets.#'
</p>


<h3>Value</h3>

<p>Object of class <code>conc</code>, a kind of data frame with as its rows
the matches and with the following columns:
</p>

<ul>
<li> <p><code>glob_id</code>: Number indicating the position of the match in the
overall list of matches.
</p>
</li>
<li> <p><code>id</code>: Number indicating the position of the match in the list of matches
for one specific query.
</p>
</li>
<li> <p><code>source</code>: Either the filename of the file in which the match was found
(in case of the setting <code>as_text = FALSE</code>), or the string '-'
(in case of the setting <code>as_text = TRUE</code>).
</p>
</li>
<li> <p><code>left</code>: The left-hand side co-text of each match.
</p>
</li>
<li> <p><code>match</code>: The actual match.
</p>
</li>
<li> <p><code>right</code>: The right-hand side co-text of each match.
</p>
</li></ul>

<p>It also has additional attributes and methods such as:
</p>

<ul>
<li><p> base <code><a href="#topic+as_data_frame">as_data_frame()</a></code> and <code><a href="#topic+print.types">print()</a></code> methods, as well as
a <code><a href="#topic+print_kwic">print_kwic()</a></code> function,
</p>
</li>
<li><p> an <code><a href="#topic+explore">explore()</a></code> method.
</p>
</li></ul>

<p>An object of class <code>conc</code> can be merged with another by means of <code><a href="#topic+merge_conc">merge_conc()</a></code>.
It can be written to file with <code><a href="#topic+write_conc">write_conc()</a></code> and then
read with <code><a href="#topic+read_conc">read_conc()</a></code>. It is also possible to import concordances created
by means other than <code><a href="#topic+write_conc">write_conc()</a></code> with <code><a href="#topic+import_conc">import_conc()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(conc_data &lt;- conc('A very small corpus.', '\\w+', as_text = TRUE))
print(conc_data)
print_kwic(conc_data)
</code></pre>

<hr>
<h2 id='create_cooc'>Build collocation frequencies.</h2><span id='topic+create_cooc'></span><span id='topic+surf_cooc'></span><span id='topic+text_cooc'></span>

<h3>Description</h3>

<p>These functions builds a surface or textual collocation frequency for a specific node.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>surf_cooc(
  x,
  re_node,
  w_left = 3,
  w_right = 3,
  re_boundary = NULL,
  re_drop_line = NULL,
  line_glue = NULL,
  re_cut_area = NULL,
  re_token_splitter = re("[^_\\p{L}\\p{N}\\p{M}'-]+"),
  re_token_extractor = re("[_\\p{L}\\p{N}\\p{M}'-]+"),
  re_drop_token = NULL,
  re_token_transf_in = NULL,
  token_transf_out = NULL,
  token_to_lower = TRUE,
  perl = TRUE,
  blocksize = 300,
  verbose = FALSE,
  dot_blocksize = 10,
  file_encoding = "UTF-8"
)

text_cooc(
  x,
  re_node,
  re_boundary = NULL,
  re_drop_line = NULL,
  line_glue = NULL,
  re_cut_area = NULL,
  re_token_splitter = re("[^_\\p{L}\\p{N}\\p{M}'-]+"),
  re_token_extractor = re("[_\\p{L}\\p{N}\\p{M}'-]+"),
  re_drop_token = NULL,
  re_token_transf_in = NULL,
  token_transf_out = NULL,
  token_to_lower = TRUE,
  perl = TRUE,
  blocksize = 300,
  verbose = FALSE,
  dot_blocksize = 10,
  file_encoding = "UTF-8"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_cooc_+3A_x">x</code></td>
<td>
<p>List of filenames of the corpus files.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_re_node">re_node</code></td>
<td>
<p>Regular expression used for identifying instances of the 'node',
i.e. the target item for which collocation information is collected.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_w_left">w_left</code></td>
<td>
<p>Number of tokens to the left of the 'node' that are treated as
belonging to the co-text of the 'node'. (But also see <code>re_boundary</code>.)</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_w_right">w_right</code></td>
<td>
<p>Number of tokens to the right of the 'node' that are treated as
belonging to the co-text of the 'node'. (But also see <code>re_boundary</code>.)</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_re_boundary">re_boundary</code></td>
<td>
<p>Regular expression.
</p>
<p>For <code>text_cooc()</code>, it identifies boundaries between 'textual units'.
</p>
<p>For <code>surf_cooc()</code>, it identifies 'cut-off' points for the co-text of
the 'node'. If it is not <code>NULL</code>, the maximum length of the left and right
co-texts are still given by <code>w_left</code> and <code>w_right</code>, but if a match
for <code>re_boundary</code> is found within the co-text, both the 'boundary token'
and all tokens beyond it are excluded.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_re_drop_line">re_drop_line</code></td>
<td>
<p>Regular expression or <code>NULL</code>. if <code>NULL</code>, the
argument  is ignored. Otherwise, lines in the corpus that match it are
treated as not belonging to the corpus and excluded from the results.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_line_glue">line_glue</code></td>
<td>
<p>Character vector or <code>NULL</code>. if <code>NULL</code>, the argument
is ignored.
Otherwise, all the lines in the corpus are glued together in one character
vector of length 1, with the string <code>line_glue</code> pasted in between
consecutive lines.
</p>
<p>This value can also be equal to an empty string <code>""</code>.
</p>
<p>The 'line glue' operation is conducted immediately after the 'drop line' operation.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_re_cut_area">re_cut_area</code></td>
<td>
<p>Regular expression or <code>NULL</code>. if <code>NULL</code>, the
argument  is ignored.
Otherwise, all matches in the corpus are 'cut out' from the text
prior to the identification of the tokens and are therefore not taken into
account when identifying the tokens.
</p>
<p>The 'cut area' operation is conducted immediately after the 'line glue' operation.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_re_token_splitter">re_token_splitter</code></td>
<td>
<p>Regular expression or <code>NULL</code>. if <code>NULL</code>,
the argument is ignored and <code>re_token_extractor</code> is used instead.
Otherwise, it identifies the areas between the tokens within a line of the corpus.
</p>
<p>The 'token identification' operation is conducted immediately after the
'cut area' operation.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_re_token_extractor">re_token_extractor</code></td>
<td>
<p>Regular expression that identifies the locations of
the actual tokens. It is only used if <code>re_token_splitter</code> is <code>NULL</code>.
Currently the implementation of this argument is a lot less time-efficient
than that of <code>re_token_splitter</code>.
</p>
<p>The 'token identification' operation is conducted immediately after the
'cut area' operation.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_re_drop_token">re_drop_token</code></td>
<td>
<p>Regular expression or <code>NULL</code>. if <code>NULL</code>, the
argument is ignored. Otherwise, it identifies tokens to be excluded from the results.
</p>
<p>The 'drop token' operation is conducted immediately after the 'token
identification' operation.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_re_token_transf_in">re_token_transf_in</code></td>
<td>
<p>A regular expression that identifies areas in the
tokens that are to be transformed. This argument works together with
<code>token_transf_out</code>. If either of them is <code>NULL</code>, they are both ignored.
</p>
<p>Otherwise, all matches in the tokens for <code>re_token_transf_in</code> are
replaced with the replacement string <code>token_transf_out</code>.
</p>
<p>The 'token transformation' operation is conducted immediately after the
'drop token' transformation.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_token_transf_out">token_transf_out</code></td>
<td>
<p>A 'replacement string'. This argument works together
with <code>re_token_transf_in</code> and is ignored if either argument is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_token_to_lower">token_to_lower</code></td>
<td>
<p>Logical. Whether tokens should be converted to
lowercase before returning the results.
</p>
<p>The 'token to lower' operation is conducted immediately after the 'token
transformation' operation.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_perl">perl</code></td>
<td>
<p>Logical. Whether the PCRE flavor of regular expressions
should be used in the arguments that contain regular expressions.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_blocksize">blocksize</code></td>
<td>
<p>Number indicating how many corpus files are read to memory
'at each individual step' during the steps in the procedure. Normally the
default value of <code>300</code> should not be changed, but when one works with
exceptionally small corpus files, it may be worthwhile to use a higher
number, and when one works with exceptionally large corpus files, it may be
worthwhile to use a lower number.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If <code>TRUE</code>, messages are printed to the
console to indicate progress.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_dot_blocksize">dot_blocksize</code></td>
<td>
<p>Logical. If <code>TRUE</code>, dots are printed to the
console to indicate progress.</p>
</td></tr>
<tr><td><code id="create_cooc_+3A_file_encoding">file_encoding</code></td>
<td>
<p>Encoding of the input files.
</p>
<p>Either a character vector of length 1, in which case all files are assumed
to be in the same encoding, or a character vector with the same length as
<code>x</code>, which allows for different encodings for different files.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two major steps can be distinguished in the procedure conducted by these functions.
The first major step is the <em>identification of the (sequence of) tokens</em> that,
for the purpose of this analysis, will be considered to be the content of the corpus.
</p>
<p>The function arguments that jointly determine the details of this step are
<code>re_drop_line</code>, <code>line_glue</code>, <code>re_cut_area</code>, <code>re_token_splitter</code>,
<code>re_token_extractor</code>, <code>re_drop_token</code>, <code>re_token_transf_in</code>,
<code>token_transf_out</code>, and <code>token_to_lower</code>.
The sequence of tokens that is the ultimate outcome of this step is then
handed over to the second major step of the procedure.
</p>
<p>The second major step is the <em>establishment of the co-occurrence frequencies</em>.
The function arguments that jointly determine the details of this step are
<code>re_node</code> and <code>re_boundary</code> for both functions,
and <code>w_left</code> and <code>w_right</code> for <code>surf_cooc()</code> only.
It is important to know that this second step is conducted after the tokens
of the corpus have been identified, and that it is applied to a sequence of
tokens, not to the original text. More specifically the regular expressions
<code>re_node</code> and <code>re_boundary</code> are tested against individual tokens,
as they are identified by the token identification procedure.
Moreover, in <code>surf_cooc()</code>, the numbers <code>w_left</code> and <code>w_right</code>
also apply to tokens a they are identified by the token identification procedure.
</p>


<h3>Value</h3>

<p>An object of class <code>cooc_info</code>, containing information on
co-occurrence frequencies.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>surf_cooc()</code>: Build surface collocation frequencies
</p>
</li>
<li> <p><code>text_cooc()</code>: Build textual collocation frequencies
</p>
</li></ul>

<hr>
<h2 id='details'>Details on a specific item</h2><span id='topic+details'></span><span id='topic+details.slma'></span>

<h3>Description</h3>

<p>This method zooms in on details of an object <code>x</code> based on an item <code>y</code>.
When <code>x</code> is of class <code><a href="#topic+slma">slma</a></code> (currently the only supported class),
<code>y</code> must be one of the lexical markers described in it.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>details(x, y, ...)

## S3 method for class 'slma'
details(x, y, shorten_names = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="details_+3A_x">x</code></td>
<td>
<p>An object containing global statistics for a collection of linguistic units,
such as an object of class <code><a href="#topic+slma">slma</a></code>.</p>
</td></tr>
<tr><td><code id="details_+3A_y">y</code></td>
<td>
<p>A character vector of length one representing one linguistic item.</p>
</td></tr>
<tr><td><code id="details_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
<tr><td><code id="details_+3A_shorten_names">shorten_names</code></td>
<td>
<p>Logical. If <code>TRUE</code>, filenames in the rownames are
shortened with <code><a href="#topic+short_names">short_names()</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with details. When <code>x</code> is of class <code><a href="#topic+slma">slma</a></code>,
the class of the output is <code>details.slma</code>, namely a list with the following items:
</p>

<ul>
<li> <p><code>summary</code>: The row of <code>x$scores</code> corresponding to <code>y</code>.
</p>
</li>
<li> <p><code>scores</code> (what is printed by default), a dataframe with one row per
pair of documents in the <code><a href="#topic+slma">slma</a></code> and the frequencies and association scores of
the chosen item as columns.
</p>
</li>
<li> <p><code>item</code>: the value of <code>y</code>.
</p>
</li>
<li> <p><code>sig_cutoff</code> and <code>small_pos</code>, as defined in <code><a href="#topic+slma">slma</a></code>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>a_corp &lt;- get_fnames(system.file("extdata", "cleveland", package = "mclm"))
b_corp &lt;- get_fnames(system.file("extdata", "roosevelt", package = "mclm"))
slma_ex &lt;- slma(a_corp, b_corp, keep_intermediate = TRUE)

gov &lt;- details(slma_ex, "government")
gov$summary

# A bit of tidy manipulation to shorten filenames
if (require("dplyr") &amp;&amp; require("tidyr")) {
  as_tibble(gov, rownames = "files") %&gt;% 
     tidyr::separate(files, into = c("file_A", "file_B"), sep = "--") %&gt;% 
     dplyr::mutate(dplyr::across(dplyr::starts_with("file"), short_names))
} 
</code></pre>

<hr>
<h2 id='drop_empty_rc'>Drop empty rows and columns from a matrix</h2><span id='topic+drop_empty_rc'></span>

<h3>Description</h3>

<p>With <code>x</code> a matrix containing frequency counts, <code>drop_empty_rc</code> makes
a copy of <code>x</code> from which the all-zero rows and all-zero columns are removed.
No checks are performed by this function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop_empty_rc(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drop_empty_rc_+3A_x">x</code></td>
<td>
<p>A matrix, assumed to contain frequency counts.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is just a convenience function. It is identical to, and implemented as,
<code>x[rowSums(x) &gt; 0, colSums(x) &gt; 0, drop = FALSE]</code>.
</p>


<h3>Value</h3>

<p>Matrix, with all-zero rows and columns removed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># first example
m &lt;- matrix(nrow = 3, byrow = TRUE,
            dimnames = list(c('r1','r2','r3'),
                           c('c1','c2','c3')),
           c(10, 0, 4,
             0, 0, 0,
             5, 0, 7))

m
m2 &lt;- drop_empty_rc(m)
m2

## second example
m &lt;- matrix(nrow = 3, byrow = TRUE,
           dimnames = list(c('r1','r2','r3'),
                          c('c1','c2','c3')),
           c(0, 0, 4,
             0, 0, 0,
             0, 0, 7))
m
m2 &lt;- drop_empty_rc(m)
m2

## third example
m &lt;- matrix(nrow = 3, byrow = TRUE,
            dimnames = list(c('r1','r2','r3'),
                            c('c1','c2','c3')),
           c(0, 0, 0,
             0, 0, 0,
             0, 0, 0))
m
m2 &lt;- drop_empty_rc(m)
m2 
</code></pre>

<hr>
<h2 id='drop_tags'>Drop XML tags from character string</h2><span id='topic+drop_tags'></span>

<h3>Description</h3>

<p>This function takes a character vector and returns a copy from which all
XML-like tags have been removed. Moreover, if <code>half_tags_too = TRUE</code>
any half tag at the beginning or end of <code>x</code> is also removed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop_tags(x, half_tags_too = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drop_tags_+3A_x">x</code></td>
<td>
<p>String with XML tag</p>
</td></tr>
<tr><td><code id="drop_tags_+3A_half_tags_too">half_tags_too</code></td>
<td>
<p>Logical. Whether tags with only opening/closing
bracket should also be removed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is not XML-aware. It uses a very simple definition of what
counts as a tag. More specifically, any character sequence starting with
<code>&lt;</code> and ending with <code>&gt;</code> is considered a 'tag'; inside such a tag, between
<code>&lt;</code> and <code>&gt;</code>, <code>drop_tags()</code> accepts any sequence of zero or more characters.
</p>


<h3>Value</h3>

<p>Character string
</p>


<h3>Examples</h3>

<pre><code class='language-R'>xml_snippet &lt;- "id='3'/&gt;&lt;w pos='Det'&gt;An&lt;/w&gt; &lt;w pos='N'&gt;example&lt;/w&gt; &lt;w"
drop_tags(xml_snippet)
drop_tags(xml_snippet, half_tags_too = FALSE)
</code></pre>

<hr>
<h2 id='explore'>Interactively navigate through an object</h2><span id='topic+explore'></span><span id='topic+explore.assoc_scores'></span><span id='topic+explore.conc'></span><span id='topic+explore.fnames'></span><span id='topic+explore.freqlist'></span><span id='topic+explore.tokens'></span><span id='topic+explore.types'></span>

<h3>Description</h3>

<p>This method only works in an interactive R session to open
'exploration mode', in which the user can navigate through the
object <code>x</code> by means of brief commands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>explore(x, ...)

## S3 method for class 'assoc_scores'
explore(
  x,
  n = 20,
  from = 1,
  from_col = 1,
  perl = TRUE,
  sort_order = c("none", "G_signed", "PMI", "alpha"),
  use_clear = TRUE,
  ...
)

## S3 method for class 'conc'
explore(x, n = 20, from = 1, use_clear = TRUE, ...)

## S3 method for class 'fnames'
explore(x, n = 20, from = 1, perl = TRUE, use_clear = TRUE, ...)

## S3 method for class 'freqlist'
explore(x, n = 20, from = 1, perl = TRUE, use_clear = TRUE, ...)

## S3 method for class 'tokens'
explore(x, n = 20, from = 1, perl = TRUE, use_clear = TRUE, ...)

## S3 method for class 'types'
explore(x, n = 20, from = 1, perl = TRUE, use_clear = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="explore_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="explore_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
<tr><td><code id="explore_+3A_n">n</code></td>
<td>
<p>Maximum number of items in the object to be printed at once.</p>
</td></tr>
<tr><td><code id="explore_+3A_from">from</code></td>
<td>
<p>Index of the first item to be printed.</p>
</td></tr>
<tr><td><code id="explore_+3A_from_col">from_col</code></td>
<td>
<p>Index of the first column to be displayed in the regular area
(among all selected columns, including frozen columns). If <code>from_col</code> points</p>
</td></tr>
<tr><td><code id="explore_+3A_perl">perl</code></td>
<td>
<p>Logical. Whether or not the regular expressions used in the
exploration session use the PERL flavor of regular expression.</p>
</td></tr>
<tr><td><code id="explore_+3A_sort_order">sort_order</code></td>
<td>
<p>Order in which the items are to be printed. In general, possible values
are <code>"alpha"</code> (meaning that the items are to be sorted alphabetically),
and <code>"none"</code> (meaning that the items are not to be sorted).
If <code>x</code> is an object of class <code><a href="#topic+assoc_scores">assoc_scores</a></code>, a column name
or vector of column names may be provided instead.</p>
</td></tr>
<tr><td><code id="explore_+3A_use_clear">use_clear</code></td>
<td>
<p>Logical. If <code>TRUE</code>, and if the feature is supported by the R
environment, the console will be cleared in between all interactive steps
in the exploration session.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>explore()</code> is different from other R instructions because it does not
automatically stop executing and show a new regular prompt (<code>&gt;</code>) in the console.
Instead it shows a special prompt (<code style="white-space: pre;">&#8288;&gt;&gt;&#8288;</code>) at which you can use <code>explore()</code>-specific
commands. Note that at the special prompt <code style="white-space: pre;">&#8288;&gt;&gt;&#8288;</code> none of the regular R instructions
will work. The instructions that do work at this prompt, for <code>explore()</code>, are
listed below. After each instruction the user must press <code>ENTER</code>.
</p>

<ul>
<li> <p><code>b</code> (begin): The first items in <code>x</code> are shown.
</p>
</li>
<li> <p><code>e</code> (end): The last items in <code>x</code> are shown.
</p>
</li>
<li> <p><code>d</code> (down <em>n</em> items): The 'next page' of items is shown.
</p>
</li>
<li> <p><code>u</code> (up <em>n</em> items): The 'previous page' of items is shown.
</p>
</li>
<li> <p><code>n</code> (next item): The list/table shifts one item down the list.
</p>
</li>
<li> <p><code>p</code> (previous item): The list/table shifts one item up the list.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;g {linenumber}&#8288;</code> (go to...): Jump to line <code>{linenumber}</code>.
</p>
<p>E.g. <code style="white-space: pre;">&#8288;g 1000&#8288;</code> will jump to the 1000th line.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;f {regex}&#8288;</code> (find...): Jump to the next item matching the regular expression <code>{regex}</code>.
</p>
<p>E.g. <code style="white-space: pre;">&#8288;f (?xi) astic $&#8288;</code> will jump to the next item ending in <code>"astic"</code>.
The software starts searching from the <em>second item</em> presently visible onward.
</p>
<p><code>f</code> will jump to the next item matching the last regular expression used with
<code style="white-space: pre;">&#8288;f {regex}&#8288;</code>.
</p>
<p>This command is <strong>not</strong> available when <code>x</code> is a <code><a href="#topic+conc">conc</a></code> object.
</p>
</li>
<li> <p><code>l</code> (left): In <code><a href="#topic+assoc_scores">assoc_scores</a></code> objects, move one column to the left.
</p>
</li>
<li> <p><code>r</code> (right): In <code><a href="#topic+assoc_scores">assoc_scores</a></code> objects, move one column to the right.
</p>
</li>
<li> <p><code style="white-space: pre;">&#8288;?&#8288;</code>: A help page is displayed, showing all possible commands.
</p>
</li>
<li> <p><code>q</code> (quit): Terminate interactive session.
</p>
</li></ul>



<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>

<hr>
<h2 id='find_xpath'>Run XPath query</h2><span id='topic+find_xpath'></span>

<h3>Description</h3>

<p>This function finds matches for an XPath query in a corpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_xpath(x, pattern, fun = NULL, final_fun = NULL, namespaces = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_xpath_+3A_x">x</code></td>
<td>
<p>A corpus: an <code><a href="#topic+fnames">fnames</a></code> object, a character vector of an XML source,
or a document parsed with <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code>.</p>
</td></tr>
<tr><td><code id="find_xpath_+3A_pattern">pattern</code></td>
<td>
<p>An XPath query.</p>
</td></tr>
<tr><td><code id="find_xpath_+3A_fun">fun</code></td>
<td>
<p>Function to be applied to the individual nodes prior
to returning the result.</p>
</td></tr>
<tr><td><code id="find_xpath_+3A_final_fun">final_fun</code></td>
<td>
<p>Function to be applied to the complete list
of matches prior to returning the result.</p>
</td></tr>
<tr><td><code id="find_xpath_+3A_namespaces">namespaces</code></td>
<td>
<p>A namespace as generated by <code><a href="xml2.html#topic+xml_ns">xml2::xml_ns()</a></code>.</p>
</td></tr>
<tr><td><code id="find_xpath_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A nodeset or the output of applying <code>fun</code> to a nodeset.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_xml &lt;- '
&lt;p&gt;
  &lt;w pos="at"&gt;The&lt;/w&gt;
  &lt;w pos="nn"&gt;example&lt;/w&gt;
  &lt;punct&gt;.&lt;/punct&gt;
&lt;/p&gt;'

find_xpath(test_xml, "//w")
find_xpath(test_xml, "//@pos")
find_xpath(test_xml, "//w[@pos='nn']")

find_xpath(test_xml, "//w", fun = xml2::xml_text)
find_xpath(test_xml, "//w", fun = xml2::xml_attr, attr = "pos")
</code></pre>

<hr>
<h2 id='fnames'>Retrieve the names of files in a given path</h2><span id='topic+fnames'></span><span id='topic+get_fnames'></span>

<h3>Description</h3>

<p>Build an object of class <code>fnames</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_fnames(
  path = ".",
  re_pattern = NULL,
  recursive = TRUE,
  perl = TRUE,
  invert = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fnames_+3A_path">path</code></td>
<td>
<p>The location of the files to be listed.</p>
</td></tr>
<tr><td><code id="fnames_+3A_re_pattern">re_pattern</code></td>
<td>
<p>Optional regular expression. If present, then only the
filenames that match it are retrieved (unless <code>invert = TRUE</code>, in which
case those filenames are excluded). The match is done over the absolute
path of the files.</p>
</td></tr>
<tr><td><code id="fnames_+3A_recursive">recursive</code></td>
<td>
<p>Boolean value. Should the subdirectories of <code>path</code> also be
searched?</p>
</td></tr>
<tr><td><code id="fnames_+3A_perl">perl</code></td>
<td>
<p>Boolean value. Whether <code>re_pattern</code> should be interpreted as a
PERL flavor of regular expression.</p>
</td></tr>
<tr><td><code id="fnames_+3A_invert">invert</code></td>
<td>
<p>Boolean value. If <code>TRUE</code>, filenames matching <code>re_pattern</code> are
the only ones retrieved. If <code>FALSE</code>, filenames matching <code>re_pattern</code> are
excluded.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>fnames</code>, which is a special kind of character
vector storing the absolute paths of the corpus files.
It has additional attributes and methods such as:
</p>

<ul>
<li><p> base <code><a href="#topic+print.freqlist">print()</a></code>, <code><a href="#topic+as_data_frame">as_data_frame()</a></code>,
<code><a href="base.html#topic+sort">sort()</a></code> and <code><a href="base.html#topic+summary">summary()</a></code> (which returns the number of items and of unique items),
</p>
</li>
<li> <p><code><a href="tibble.html#topic+as_tibble">tibble::as_tibble()</a></code>,
</p>
</li>
<li><p> an interactive <code><a href="#topic+explore">explore()</a></code> method,
</p>
</li>
<li><p> a function to get the number of items <code><a href="#topic+n_fnames">n_fnames()</a></code>,
</p>
</li>
<li><p> subsetting methods such as <code><a href="#topic+keep_types">keep_types()</a></code>, <code><a href="#topic+keep_pos">keep_pos()</a></code>, etc. including <code style="white-space: pre;">&#8288;[]&#8288;</code>
subsetting (see <a href="#topic+brackets">brackets</a>), as well as the specific functions <code><a href="#topic+keep_fnames">keep_fnames()</a></code>
and <code><a href="#topic+drop_fnames">drop_fnames()</a></code>.
</p>
</li></ul>

<p>Additional manipulation functions includes <code><a href="#topic+fnames_merge">fnames_merge()</a></code> to combine
filenames collections and the <code><a href="#topic+short_names">short_names()</a></code> family of functions to shorten
the names.
</p>
<p>Objects of class <code>fnames</code> can be saved to file with <code><a href="#topic+write_fnames">write_fnames()</a></code>;
these files can be read with <code><a href="#topic+read_fnames">read_fnames()</a></code>.
</p>
<p>It is possible to coerce a character vector into an <code>fnames</code> object with <code><a href="#topic+as_fnames">as_fnames()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cwd_fnames &lt;- get_fnames(recursive = FALSE)

cwd_fnames &lt;- as_fnames(c("file1", "file2", "file3"))
cwd_fnames
print(cwd_fnames)
as_data_frame(cwd_fnames)
as_tibble(cwd_fnames)

sort(cwd_fnames)

summary(cwd_fnames)
</code></pre>

<hr>
<h2 id='freqlist'>Build the frequency list of a corpus</h2><span id='topic+freqlist'></span>

<h3>Description</h3>

<p>This function builds the word frequency list from a corpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freqlist(
  x,
  re_drop_line = NULL,
  line_glue = NULL,
  re_cut_area = NULL,
  re_token_splitter = re("[^_\\p{L}\\p{N}\\p{M}'-]+"),
  re_token_extractor = re("[_\\p{L}\\p{N}\\p{M}'-]+"),
  re_drop_token = NULL,
  re_token_transf_in = NULL,
  token_transf_out = NULL,
  token_to_lower = TRUE,
  perl = TRUE,
  blocksize = 300,
  verbose = FALSE,
  show_dots = FALSE,
  dot_blocksize = 10,
  file_encoding = "UTF-8",
  ngram_size = NULL,
  max_skip = 0,
  ngram_sep = "_",
  ngram_n_open = 0,
  ngram_open = "[]",
  as_text = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freqlist_+3A_x">x</code></td>
<td>
<p>Either a list of filenames of the corpus files
(if <code>as_text</code> is <code>TRUE</code>) or the actual text of the corpus
(if <code>as_text</code> is <code>FALSE</code>).
</p>
<p>If <code>as_text</code> is <code>TRUE</code> and the length of the vector <code>x</code>
is higher than one, then each item in <code>x</code> is treated as a separate
line (or a separate series of lines) in the corpus text. Within each
item of <code>x</code>, the character <code>"\\n"</code> is also treated as
a line separator.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_re_drop_line">re_drop_line</code></td>
<td>
<p><code>NULL</code> or character vector. If <code>NULL</code>, it is ignored.
Otherwise, a character vector (assumed to be of length 1)
containing a regular expression. Lines in <code>x</code>
that contain a match for <code>re_drop_line</code> are
treated as not belonging to the corpus and are excluded from the results.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_line_glue">line_glue</code></td>
<td>
<p><code>NULL</code> or character vector. If <code>NULL</code>, it is ignored.
Otherwise, all lines in a corpus file (or in <code>x</code>, if
<code>as_text</code> is <code>TRUE</code>), are glued together in one
character vector of length 1, with the string <code>line_glue</code>
pasted in between consecutive lines.
The value of <code>line_glue</code> can also be equal to the empty string <code>""</code>.
The 'line glue' operation is conducted immediately after the 'drop line' operation.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_re_cut_area">re_cut_area</code></td>
<td>
<p><code>NULL</code> or character vector. If <code>NULL</code>, it is ignored.
Otherwise, all matches in a corpus file (or in <code>x</code>,
if <code>as_text</code> is <code>TRUE</code>), are 'cut out' of the text prior
to the identification of the tokens in the text (and are therefore
not taken into account when identifying the tokens).
The 'cut area' operation is conducted immediately after the 'line glue' operation.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_re_token_splitter">re_token_splitter</code></td>
<td>
<p>Regular expression or <code>NULL</code>.
Regular expression that identifies the locations where lines in the corpus
files are split into tokens. (See Details.)
</p>
<p>The 'token identification' operation is conducted immediately after the
'cut area' operation.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_re_token_extractor">re_token_extractor</code></td>
<td>
<p>Regular expression that identifies the locations of the
actual tokens. This argument is only used if <code>re_token_splitter</code> is <code>NULL</code>.
(See Details.)
</p>
<p>The 'token identification' operation is conducted immediately after the
'cut area' operation.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_re_drop_token">re_drop_token</code></td>
<td>
<p>Regular expression or <code>NULL</code>. If <code>NULL</code>, it is ignored.
Otherwise, it identifies tokens that are to
be excluded from the results. Any token that contains a match for
<code>re_drop_token</code> is removed from the results.
The 'drop token' operation is conducted immediately after the 'token identification' operation.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_re_token_transf_in">re_token_transf_in</code></td>
<td>
<p>Regular expression that identifies areas in the
tokens that are to be transformed. This argument works together with the argument
<code>token_transf_out</code>.
</p>
<p>If both <code>re_token_transf_in</code> and <code>token_transf_out</code> differ
from <code>NA</code>, then all matches, in the tokens, for the
regular expression  <code>re_token_transf_in</code> are replaced with
the replacement string <code>token_transf_out</code>.
</p>
<p>The 'token transformation' operation is conducted immediately after the
'drop token' operation.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_token_transf_out">token_transf_out</code></td>
<td>
<p>Replacement string. This argument works together with
<code>re_token_transf_in</code> and is ignored if <code>re_token_transf_in</code>
is <code>NULL</code> or <code>NA</code>.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_token_to_lower">token_to_lower</code></td>
<td>
<p>Logical. Whether tokens must be converted
to lowercase before returning the result.
The 'token to lower' operation is conducted immediately after the
'token transformation' operation.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_perl">perl</code></td>
<td>
<p>Logical. Whether the PCRE regular expression
flavor is being used in the arguments that contain regular expressions.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_blocksize">blocksize</code></td>
<td>
<p>Number that indicates how many corpus files are read to memory
<code style="white-space: pre;">&#8288;at each individual step' during the steps in the procedure; normally the default value of &#8288;</code>300' should not
be changed, but when one works with exceptionally small corpus files,
it may be worthwhile to use a higher number, and when one works with
exceptionally large corpus files, it may be worthwhile to use a lower number.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_verbose">verbose</code></td>
<td>
<p>If<code>TRUE</code>, messages are printed to the console to
indicate progress.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_show_dots">show_dots</code>, <code id="freqlist_+3A_dot_blocksize">dot_blocksize</code></td>
<td>
<p>If <code>TRUE</code>, dots are printed to the console to
indicate progress.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_file_encoding">file_encoding</code></td>
<td>
<p>File encoding that is assumed in the corpus files.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_ngram_size">ngram_size</code></td>
<td>
<p>Argument in support of ngrams/skipgrams (see also <code>max_skip</code>).
</p>
<p>If one wants to identify individual tokens, the value of <code>ngram_size</code>
should be <code>NULL</code> or <code>1</code>. If one wants to retrieve
token ngrams/skipgrams, <code>ngram_size</code> should be an integer indicating
the size of the ngrams/skipgrams. E.g. <code>2</code> for bigrams, or <code>3</code> for
trigrams, etc.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_max_skip">max_skip</code></td>
<td>
<p>Argument in support of skipgrams. This argument is ignored if
<code>ngram_size</code> is <code>NULL</code> or is <code>1</code>.
</p>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and <code>max_skip</code>
is <code>0</code>, then regular ngrams are being retrieved (albeit that they
may contain open slots; see <code>ngram_n_open</code>).
</p>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and <code>max_skip</code>
is <code>1</code> or higher, then skipgrams are being retrieved (which in the
current implementation cannot contain open slots; see <code>ngram_n_open</code>).
</p>
<p>For instance, if <code>ngram_size</code> is <code>3</code> and <code>max_skip</code> is
<code>2</code>, then 2-skip trigrams are being retrieved.
Or if <code>ngram_size</code> is <code>5</code> and <code>max_skip</code> is
<code>3</code>, then 3-skip 5-grams are being retrieved.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_ngram_sep">ngram_sep</code></td>
<td>
<p>Character vector of length 1 containing the string that is used to
separate/link tokens in the representation of ngrams/skipgrams
in the output of this function.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_ngram_n_open">ngram_n_open</code></td>
<td>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and moreover
<code>ngram_n_open</code> is a number higher than <code>0</code>, then
ngrams with 'open slots' in them are retrieved. These
ngrams with 'open slots' are generalizations of fully lexically specific
ngrams (with the generalization being that one or more of the items
in the ngram are replaced by a notation that stands for 'any arbitrary token').
</p>
<p>For instance, if <code>ngram_size</code> is <code>4</code> and <code>ngram_n_open</code> is
<code>1</code>, and if moreover the input contains a
4-gram <code>"it_is_widely_accepted"</code>, then the output will contain
all modifications of <code>"it_is_widely_accepted"</code> in which one (since
<code>ngram_n_open</code> is <code>1</code>) of the items in this n-gram is
replaced by an open slot. The first and the last item inside
an ngram are never turned into an open slot; only the items in between
are candidates for being turned into open slots. Therefore, in the
example, the output will contain <code>"it_[]_widely_accepted"</code> and
<code>"it_is_[]_accepted"</code>.
</p>
<p>As a second example, if <code>ngram_size</code> is <code>5</code> and
<code>ngram_n_open</code> is <code>2</code>, and if moreover the input contains a
5-gram <code>"it_is_widely_accepted_that"</code>, then the output will contain
<code>"it_[]_[]_accepted_that"</code>, <code>"it_[]_widely_[]_that"</code>, and
<code>"it_is_[]_[]_that"</code>.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_ngram_open">ngram_open</code></td>
<td>
<p>Character string used to represent open slots in ngrams in the
output of this function.</p>
</td></tr>
<tr><td><code id="freqlist_+3A_as_text">as_text</code></td>
<td>
<p>Logical.
Whether <code>x</code> is to be interpreted as a character vector containing the
actual contents of the corpus (if <code>as_text</code> is <code>TRUE</code>)
or as a character vector containing the names of the corpus files
(if <code>as_text</code> is <code>FALSE</code>).
If if <code>as_text</code> is <code>TRUE</code>, then the arguments
<code>blocksize</code>, <code>verbose</code>, <code>show_dots</code>, <code>dot_blocksize</code>,
and <code>file_encoding</code> are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The actual token identification is either based on the <code>re_token_splitter</code>
argument, a regular expression that identifies the areas between the tokens,
or on <code>re_token_extractor</code>, a regular expression that identifies the area
that are the tokens.
The first mechanism is the default mechanism: the argument <code>re_token_extractor</code>
is only used if <code>re_token_splitter</code> is <code>NULL</code>.
Currently the implementation of
<code>re_token_extractor</code> is a lot less time-efficient than that of <code>re_token_splitter</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>freqlist</code>, which is based on the class <code>table</code>.
It has additional attributes and methods such as:
</p>

<ul>
<li><p> base <code><a href="#topic+print.freqlist">print()</a></code>, <code><a href="#topic+as_data_frame">as_data_frame()</a></code>,
<code><a href="base.html#topic+summary">summary()</a></code> and <code><a href="#topic+sort.freqlist">sort</a></code>,
</p>
</li>
<li> <p><code><a href="tibble.html#topic+as_tibble">tibble::as_tibble()</a></code>,
</p>
</li>
<li><p> an interactive <code><a href="#topic+explore">explore()</a></code> method,
</p>
</li>
<li><p> various getters, including <code><a href="#topic+tot_n_tokens">tot_n_tokens()</a></code>, <code><a href="#topic+n_types">n_types()</a></code>, <code><a href="#topic+n_tokens">n_tokens()</a></code>,
values that are also returned by <code><a href="base.html#topic+summary">summary()</a></code>, and more,
</p>
</li>
<li><p> subsetting methods such as <code><a href="#topic+keep_types">keep_types()</a></code>, <code><a href="#topic+keep_pos">keep_pos()</a></code>, etc. including <code style="white-space: pre;">&#8288;[]&#8288;</code>
subsetting (see <a href="#topic+brackets">brackets</a>).
</p>
</li></ul>

<p>Additional manipulation functions include <code><a href="#topic+type_freqs">type_freqs()</a></code> to extract the frequencies
of different items, <code><a href="#topic+freqlist_merge">freqlist_merge()</a></code> to combine frequency lists, and
<code><a href="#topic+freqlist_diff">freqlist_diff()</a></code> to subtract a frequency list from another.
</p>
<p>Objects of class <code>freqlist</code> can be saved to file with <code><a href="#topic+write_freqlist">write_freqlist()</a></code>;
these files can be read with <code><a href="#topic+read_freqlist">read_freqlist()</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
It consisted of three sentences. And it lived happily ever after."

(flist &lt;- freqlist(toy_corpus, as_text = TRUE))
print(flist, n = 20)
as.data.frame(flist)
as_tibble(flist)
summary(flist) 
print(summary(flist))

t_splitter &lt;- "(?xi) [:\\s.;,?!\"]+"
freqlist(toy_corpus,
         re_token_splitter = t_splitter,
         as_text = TRUE)
         
freqlist(toy_corpus,
         re_token_splitter = t_splitter,
         token_to_lower = FALSE,
         as_text = TRUE)

t_extractor &lt;- "(?xi) ( [:;?!] | [.]+ | [\\w'-]+ )"
freqlist(toy_corpus,
        re_token_splitter = NA,
        re_token_extractor = t_extractor,
        as_text = TRUE)

freqlist(letters, ngram_size = 3, as_text = TRUE)

freqlist(letters, ngram_size = 2, ngram_sep = " ", as_text = TRUE)
</code></pre>

<hr>
<h2 id='freqlist_diff'>Subtract frequency lists</h2><span id='topic+freqlist_diff'></span>

<h3>Description</h3>

<p>This function merges information from two frequency lists, subtracting the frequencies found
in the second frequency lists from the frequencies found in the first list.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freqlist_diff(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="freqlist_diff_+3A_x">x</code>, <code id="freqlist_diff_+3A_y">y</code></td>
<td>
<p>Objects of class <code><a href="#topic+freqlist">freqlist</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+freqlist">freqlist</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(flist1 &lt;- freqlist("A first toy corpus.", as_text = TRUE))
(flist2 &lt;- freqlist("A second toy corpus.", as_text = TRUE))

freqlist_diff(flist1, flist2)
</code></pre>

<hr>
<h2 id='import_conc'>Import a concordance</h2><span id='topic+import_conc'></span>

<h3>Description</h3>

<p>This function imports a concordance from files generated by other means than
<code><a href="#topic+write_conc">write_conc()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>import_conc(x, file_encoding = "UTF-8", source_type = c("corpuseye"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="import_conc_+3A_x">x</code></td>
<td>
<p>A vector of input filenames.</p>
</td></tr>
<tr><td><code id="import_conc_+3A_file_encoding">file_encoding</code></td>
<td>
<p>Encoding of the file(s).</p>
</td></tr>
<tr><td><code id="import_conc_+3A_source_type">source_type</code></td>
<td>
<p>Character string. How the file is read. Currently only
<code>"corpuseye"</code> is supported.</p>
</td></tr>
<tr><td><code id="import_conc_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+conc">conc</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_conc">read_conc()</a></code> for files written with <code><a href="#topic+write_conc">write_conc()</a></code>.
</p>

<hr>
<h2 id='keep_bool'>Subset an object based on logical criteria</h2><span id='topic+keep_bool'></span><span id='topic+drop_bool'></span><span id='topic+drop_bool.fnames'></span><span id='topic+keep_bool.fnames'></span><span id='topic+drop_bool.freqlist'></span><span id='topic+keep_bool.freqlist'></span><span id='topic+drop_bool.tokens'></span><span id='topic+keep_bool.tokens'></span><span id='topic+drop_bool.types'></span><span id='topic+keep_bool.types'></span>

<h3>Description</h3>

<p>These methods can be used to subset objects based on a logical vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keep_bool(x, bool, invert = FALSE, ...)

drop_bool(x, bool, ...)

## S3 method for class 'fnames'
drop_bool(x, bool, ...)

## S3 method for class 'fnames'
keep_bool(x, bool, invert = FALSE, ...)

## S3 method for class 'freqlist'
drop_bool(x, bool, ...)

## S3 method for class 'freqlist'
keep_bool(x, bool, invert = FALSE, ...)

## S3 method for class 'tokens'
drop_bool(x, bool, ...)

## S3 method for class 'tokens'
keep_bool(x, bool, invert = FALSE, ...)

## S3 method for class 'types'
drop_bool(x, bool, ...)

## S3 method for class 'types'
keep_bool(x, bool, invert = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keep_bool_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="keep_bool_+3A_bool">bool</code></td>
<td>
<p>A logical vector of the same length as <code>x</code>. If <code>bool</code> is not
of the correct length, it is <em>recycled</em>. Assuming <code>invert</code> is
<code>FALSE</code>, those items are selected for which <code>bool</code> is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="keep_bool_+3A_invert">invert</code></td>
<td>
<p>Logical. Whether the matches should be selected rather than the
non-matches.</p>
</td></tr>
<tr><td><code id="keep_bool_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods <code><a href="#topic+keep_pos">keep_pos()</a></code> and <code><a href="#topic+drop_pos">drop_pos()</a></code> are part of a family of methods of
the mclm package used to subset different objects. The methods
starting with <code>keep_</code> extract the items in <code>x</code> based on the criterion specified
by the second argument. In contrast, the methods starting with <code>drop_</code> <em>exclude</em>
the items that match the criterion in the same argument.
</p>
<p>Calling a <code>drop_</code> method is equivalent to calling its <code>keep_</code> counterpart when
the <code>invert</code> argument is <code>TRUE</code>.
</p>


<h3>Value</h3>

<p>Object of the same class as <code>x</code> with the selected elements only.
</p>


<h3>See Also</h3>

<p>Other subsetters: 
<code><a href="#topic+brackets">brackets</a></code>,
<code><a href="#topic+keep_pos">keep_pos</a>()</code>,
<code><a href="#topic+keep_re">keep_re</a>()</code>,
<code><a href="#topic+keep_types">keep_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For a 'freqlist' object---------------------
(flist &lt;- freqlist("The man and the mouse.", as_text = TRUE))

keep_bool(flist, type_freqs(flist) &lt; 2)
drop_bool(flist, type_freqs(flist) &gt;= 2)
keep_bool(flist, ranks(flist) &lt;= 3)

keep_bool(flist, c(FALSE, TRUE, TRUE, FALSE)) 

(flist2 &lt;- keep_bool(flist, type_freqs(flist) &lt; 2))
keep_bool(flist2, orig_ranks(flist2) &gt; 2)

# For a 'types' object ----------------------
(tps &lt;- as_types(letters[1:10]))

keep_bool(tps, c(TRUE, FALSE))
drop_bool(tps, c(TRUE, FALSE))

# For a 'tokens' object ----------------------
(tks &lt;- as_tokens(letters[1:10]))

keep_bool(tks, c(TRUE, FALSE))
drop_bool(tks, c(TRUE, FALSE))
</code></pre>

<hr>
<h2 id='keep_fnames'>Filter collection of filenames by name</h2><span id='topic+keep_fnames'></span><span id='topic+drop_fnames'></span>

<h3>Description</h3>

<p>The functions build a subset of an object of class <code><a href="#topic+fnames">fnames</a></code> based on a vector
of characters, either including them (with <code>keep_fnames(invert = FALSE)</code>) or
excluding them (with <code>keep_fnames(invert = FALSE)</code> or <code>drop_fnames()</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keep_fnames(x, y, invert = FALSE, ...)

drop_fnames(x, y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keep_fnames_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+fnames">fnames</a></code>, to be filtered.</p>
</td></tr>
<tr><td><code id="keep_fnames_+3A_y">y</code></td>
<td>
<p>An object of class <code><a href="#topic+fnames">fnames</a></code> or class <code><a href="#topic+types">types</a></code> or a character vector.
This is the filtering criterion.</p>
</td></tr>
<tr><td><code id="keep_fnames_+3A_invert">invert</code></td>
<td>
<p>Boolean value. If <code>TRUE</code>, the elements in <code>y</code> are excluded rather
than kept (and <code>keep_fnames()</code> behaves like <code>drop_fnames()</code>)</p>
</td></tr>
<tr><td><code id="keep_fnames_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+fnames">fnames</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>all_fnames &lt;- as_fnames(c("file1", "file2", "file3",
                          "file4", "file5", "file6"))

unwanted_fnames &lt;- as_fnames(c("file1", "file4"))
keep_fnames(all_fnames, unwanted_fnames, invert = TRUE)
drop_fnames(all_fnames, unwanted_fnames)

wanted_fnames &lt;- as_fnames(c("file3", "file5"))
keep_fnames(all_fnames, wanted_fnames)
</code></pre>

<hr>
<h2 id='keep_pos'>Subset an object by index</h2><span id='topic+keep_pos'></span><span id='topic+drop_pos.fnames'></span><span id='topic+keep_pos.fnames'></span><span id='topic+drop_pos.freqlist'></span><span id='topic+keep_pos.freqlist'></span><span id='topic+drop_pos'></span><span id='topic+drop_pos.tokens'></span><span id='topic+keep_pos.tokens'></span><span id='topic+drop_pos.types'></span><span id='topic+keep_pos.types'></span>

<h3>Description</h3>

<p>These methods can be used to subset objects based on a numeric vector of indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keep_pos(x, pos, invert = FALSE, ...)

## S3 method for class 'fnames'
drop_pos(x, pos, ...)

## S3 method for class 'fnames'
keep_pos(x, pos, invert = FALSE, ...)

## S3 method for class 'freqlist'
drop_pos(x, pos, ...)

## S3 method for class 'freqlist'
keep_pos(x, pos, invert = FALSE, ...)

drop_pos(x, pos, ...)

## S3 method for class 'tokens'
drop_pos(x, pos, ...)

## S3 method for class 'tokens'
keep_pos(x, pos, invert = FALSE, ...)

## S3 method for class 'types'
drop_pos(x, pos, ...)

## S3 method for class 'types'
keep_pos(x, pos, invert = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keep_pos_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="keep_pos_+3A_pos">pos</code></td>
<td>
<p>A numeric vector, the numbers in which identify positions (= indices)
of items in <code>x</code>.
</p>
<p>If the numbers are positive, then their values point
to the items that are to be selected.
</p>
<p>If the numbers are negative,
then their absolute values point to the items that are not to be selected.
Positive and negative numbers must not be mixed.</p>
</td></tr>
<tr><td><code id="keep_pos_+3A_invert">invert</code></td>
<td>
<p>Logical. Whether the matches should be selected rather than the
non-matches.</p>
</td></tr>
<tr><td><code id="keep_pos_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods <code><a href="#topic+keep_pos">keep_pos()</a></code> and <code><a href="#topic+drop_pos">drop_pos()</a></code> are part of a family of methods of
the mclm package used to subset different objects. The methods
starting with <code>keep_</code> extract the items in <code>x</code> based on the criterion specified
by the second argument. In contrast, the methods starting with <code>drop_</code> <em>exclude</em>
the items that match the criterion in the same argument.
</p>
<p>Calling a <code>drop_</code> method is equivalent to calling its <code>keep_</code> counterpart when
the <code>invert</code> argument is <code>TRUE</code>.
</p>


<h3>Value</h3>

<p>Object of the same class as <code>x</code> with the selected elements only.
</p>


<h3>See Also</h3>

<p>Other subsetters: 
<code><a href="#topic+brackets">brackets</a></code>,
<code><a href="#topic+keep_bool">keep_bool</a>()</code>,
<code><a href="#topic+keep_re">keep_re</a>()</code>,
<code><a href="#topic+keep_types">keep_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For a 'freqlist' object --------------------
(flist &lt;- freqlist("The man and the mouse.", as_text = TRUE))

keep_pos(flist, c(2, 3))

# For a 'types' object -----------------------
(tps &lt;- as_types(letters[1:10]))

keep_pos(tps, c(1, 3, 5, 7, 9))
drop_pos(tps, c(1, 3, 5, 7, 9))

# For a 'tokens' object ----------------------
(tks &lt;- as_tokens(letters[1:10]))

keep_pos(tks, c(1, 3, 5, 7, 9))
drop_pos(tks, c(1, 3, 5, 7, 9))
</code></pre>

<hr>
<h2 id='keep_re'>Subset an object based on regular expressions</h2><span id='topic+keep_re'></span><span id='topic+drop_re'></span><span id='topic+drop_re.fnames'></span><span id='topic+keep_re.fnames'></span><span id='topic+drop_re.freqlist'></span><span id='topic+keep_re.freqlist'></span><span id='topic+drop_re.tokens'></span><span id='topic+keep_re.tokens'></span><span id='topic+drop_re.types'></span><span id='topic+keep_re.types'></span>

<h3>Description</h3>

<p>These methods can be used to subset objects based on a regular expression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)

drop_re(x, pattern, perl = TRUE, ...)

## S3 method for class 'fnames'
drop_re(x, pattern, perl = TRUE, ...)

## S3 method for class 'fnames'
keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)

## S3 method for class 'freqlist'
drop_re(x, pattern, perl = TRUE, ...)

## S3 method for class 'freqlist'
keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)

## S3 method for class 'tokens'
drop_re(x, pattern, perl = TRUE, ...)

## S3 method for class 'tokens'
keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)

## S3 method for class 'types'
drop_re(x, pattern, perl = TRUE, ...)

## S3 method for class 'types'
keep_re(x, pattern, perl = TRUE, invert = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keep_re_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="keep_re_+3A_pattern">pattern</code></td>
<td>
<p>Either an object of the class <code><a href="#topic+re">re</a></code>
or a character vector of length one containing a regular expression.</p>
</td></tr>
<tr><td><code id="keep_re_+3A_perl">perl</code></td>
<td>
<p>Logical.
Whether <code>pattern</code> is treated as a PCRE flavor regular expression.
The <code>perl</code> argument is only used if <code>pattern</code> is a regular character vector.
If <code>pattern</code> is an object of the class <code><a href="#topic+re">re</a></code>, then the
<code>perl</code> argument is ignored, and the relevant information in the
<code><a href="#topic+re">re</a></code> object <code>pattern</code>, viz. the value of <code>pattern$perl</code>, is
used instead.</p>
</td></tr>
<tr><td><code id="keep_re_+3A_invert">invert</code></td>
<td>
<p>Logical. Whether the matches should be selected rather than the
non-matches.</p>
</td></tr>
<tr><td><code id="keep_re_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods <code><a href="#topic+keep_pos">keep_pos()</a></code> and <code><a href="#topic+drop_pos">drop_pos()</a></code> are part of a family of methods of
the mclm package used to subset different objects. The methods
starting with <code>keep_</code> extract the items in <code>x</code> based on the criterion specified
by the second argument. In contrast, the methods starting with <code>drop_</code> <em>exclude</em>
the items that match the criterion in the same argument.
</p>
<p>Calling a <code>drop_</code> method is equivalent to calling its <code>keep_</code> counterpart when
the <code>invert</code> argument is <code>TRUE</code>.
</p>


<h3>Value</h3>

<p>Object of the same class as <code>x</code> with the selected elements only.
</p>


<h3>See Also</h3>

<p>Other subsetters: 
<code><a href="#topic+brackets">brackets</a></code>,
<code><a href="#topic+keep_bool">keep_bool</a>()</code>,
<code><a href="#topic+keep_pos">keep_pos</a>()</code>,
<code><a href="#topic+keep_types">keep_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For a 'freqlist' object --------------------
(flist &lt;- freqlist("The man and the mouse.", as_text = TRUE))

keep_re(flist, "[ao]")
drop_re(flist, "[ao]")
keep_re(flist, "[ao]", invert = TRUE) # same as drop_re()

# For a 'types' object -----------------------
(tps &lt;- as_types(letters[1:10]))

keep_re(tps, "[acegi]")
drop_re(tps, "[acegi]")

# For a 'tokens' object ----------------------
(tks &lt;- as_tokens(letters[1:10]))

keep_re(tks, "[acegi]")
drop_re(tks, "[acegi]")
</code></pre>

<hr>
<h2 id='keep_types'>Subset an object based on a selection of types</h2><span id='topic+keep_types'></span><span id='topic+drop_types'></span><span id='topic+drop_types.fnames'></span><span id='topic+keep_types.fnames'></span><span id='topic+drop_types.freqlist'></span><span id='topic+keep_types.freqlist'></span><span id='topic+drop_types.tokens'></span><span id='topic+keep_types.tokens'></span><span id='topic+drop_types.types'></span><span id='topic+keep_types.types'></span>

<h3>Description</h3>

<p>These methods can be used to subset objects based on a list of types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>keep_types(x, types, invert = FALSE, ...)

drop_types(x, types, ...)

## S3 method for class 'fnames'
drop_types(x, types, ...)

## S3 method for class 'fnames'
keep_types(x, types, invert = FALSE, ...)

## S3 method for class 'freqlist'
drop_types(x, types, ...)

## S3 method for class 'freqlist'
keep_types(x, types, invert = FALSE, ...)

## S3 method for class 'tokens'
drop_types(x, types, ...)

## S3 method for class 'tokens'
keep_types(x, types, invert = FALSE, ...)

## S3 method for class 'types'
drop_types(x, types, ...)

## S3 method for class 'types'
keep_types(x, types, invert = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="keep_types_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="keep_types_+3A_types">types</code></td>
<td>
<p>Either an object of the class <code><a href="#topic+types">types</a></code>
or a character vector.</p>
</td></tr>
<tr><td><code id="keep_types_+3A_invert">invert</code></td>
<td>
<p>Logical. Whether the matches should be selected rather than the
non-matches.</p>
</td></tr>
<tr><td><code id="keep_types_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The methods <code><a href="#topic+keep_pos">keep_pos()</a></code> and <code><a href="#topic+drop_pos">drop_pos()</a></code> are part of a family of methods of
the mclm package used to subset different objects. The methods
starting with <code>keep_</code> extract the items in <code>x</code> based on the criterion specified
by the second argument. In contrast, the methods starting with <code>drop_</code> <em>exclude</em>
the items that match the criterion in the same argument.
</p>
<p>Calling a <code>drop_</code> method is equivalent to calling its <code>keep_</code> counterpart when
the <code>invert</code> argument is <code>TRUE</code>.
</p>


<h3>Value</h3>

<p>Object of the same class as <code>x</code> with the selected elements only.
</p>


<h3>See Also</h3>

<p>Other subsetters: 
<code><a href="#topic+brackets">brackets</a></code>,
<code><a href="#topic+keep_bool">keep_bool</a>()</code>,
<code><a href="#topic+keep_pos">keep_pos</a>()</code>,
<code><a href="#topic+keep_re">keep_re</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># For a 'freqlist' object ------------------------
(flist &lt;- freqlist("The man and the mouse.", as_text = TRUE))
keep_types(flist, c("man", "and"))
drop_types(flist, c("man", "and"))
keep_types(flist, c("man", "and"), invert = TRUE) # same as drop_types()

# For a 'types' object ---------------------------
(tps &lt;- as_types(letters[1:10]))

keep_types(tps, c("a", "c", "e", "g", "i"))
drop_types(tps,  c("a", "c", "e", "g", "i"))

# For a 'tokens' object --------------------------
(tks &lt;- as_tokens(letters[1:10]))

keep_types(tks, c("a", "c", "e", "g", "i"))
drop_types(tks,  c("a", "c", "e", "g", "i"))
</code></pre>

<hr>
<h2 id='mclm_xml_text'>Get text from xml node</h2><span id='topic+mclm_xml_text'></span>

<h3>Description</h3>

<p>Get text from xml node
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mclm_xml_text(node, trim = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mclm_xml_text_+3A_node">node</code></td>
<td>
<p>XML node as read with <code><a href="xml2.html#topic+read_xml">xml2::read_xml()</a></code>.</p>
</td></tr>
<tr><td><code id="mclm_xml_text_+3A_trim">trim</code></td>
<td>
<p>If <code>TRUE</code> will trim leading and trailing spaces.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character vector: The text value of the (elements of the) node,
concatenated with spaces in between.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_xml &lt;- '
&lt;p&gt;
  &lt;w pos="at"&gt;The&lt;/w&gt;
  &lt;w pos="nn"&gt;example&lt;/w&gt;
  &lt;punct&gt;.&lt;/punct&gt;
&lt;/p&gt;'

test_xml_parsed &lt;- xml2::read_xml(test_xml)

# xml2 output
xml2::xml_text(test_xml_parsed)

# mclm version
mclm_xml_text(test_xml_parsed)
</code></pre>

<hr>
<h2 id='merge_conc'>Merge concordances</h2><span id='topic+merge_conc'></span>

<h3>Description</h3>

<p>This function merges multiple objects of class <code><a href="#topic+conc">conc</a></code> into one <code><a href="#topic+conc">conc</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>merge_conc(..., show_warnings = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_conc_+3A_...">...</code></td>
<td>
<p>Two or more objects of class <code><a href="#topic+conc">conc</a></code>.</p>
</td></tr>
<tr><td><code id="merge_conc_+3A_show_warnings">show_warnings</code></td>
<td>
<p>Logical. If <code>FALSE</code>, warnings are suppressed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+conc">conc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(cd_1 &lt;- conc('A first very small corpus.', '\\w+', as_text = TRUE))
as.data.frame(cd_1)

(cd_2 &lt;- conc('A second very small corpus.', '\\w+', as_text = TRUE))
(cd_3 &lt;- conc('A third very small corpus.', '\\w+', as_text = TRUE))
(cd &lt;- merge_conc(cd_1, cd_2, cd_3))
as.data.frame(cd)
</code></pre>

<hr>
<h2 id='merge_fnames'>Merge filenames collections</h2><span id='topic+merge_fnames'></span><span id='topic+fnames_merge'></span><span id='topic+fnames_merge_all'></span>

<h3>Description</h3>

<p>These functions merge two or more <code><a href="#topic+fnames">fnames</a></code> objects into one larger <code><a href="#topic+fnames">fnames</a></code>
object, removing duplicates (keeping only the first appearance) and only
resorting the items if <code>sort = TRUE</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fnames_merge(x, y, sort = FALSE)

fnames_merge_all(..., sort = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_fnames_+3A_x">x</code>, <code id="merge_fnames_+3A_y">y</code></td>
<td>
<p>An object of class <code><a href="#topic+fnames">fnames</a></code>.</p>
</td></tr>
<tr><td><code id="merge_fnames_+3A_sort">sort</code></td>
<td>
<p>Boolean value. Should the items in the output be sorted?</p>
</td></tr>
<tr><td><code id="merge_fnames_+3A_...">...</code></td>
<td>
<p>Various objects of class <code><a href="#topic+fnames">fnames</a></code> or a list of
objects of class <code><a href="#topic+fnames">fnames</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+fnames">fnames</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cwd_fnames &lt;- as_fnames(c("file1.txt", "file2.txt"))
cwd_fnames2 &lt;- as_fnames(c("dir1/file3.txt", "dir1/file4.txt"))
cwd_fnames3 &lt;- as_fnames(c("dir2/file5.txt", "dir2/file6.txt"))
fnames_merge(cwd_fnames, cwd_fnames2)
fnames_merge_all(cwd_fnames, cwd_fnames2, cwd_fnames3)
</code></pre>

<hr>
<h2 id='merge_freqlist'>Merge frequency lists</h2><span id='topic+merge_freqlist'></span><span id='topic+freqlist_merge'></span><span id='topic+freqlist_merge_all'></span>

<h3>Description</h3>

<p>These functions merge two or more frequency lists, adding up the frequencies.
In the current implementation, original ranks are lost when merging.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>freqlist_merge(x, y)

freqlist_merge_all(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_freqlist_+3A_x">x</code>, <code id="merge_freqlist_+3A_y">y</code></td>
<td>
<p>An object of class <code><a href="#topic+freqlist">freqlist</a></code>.</p>
</td></tr>
<tr><td><code id="merge_freqlist_+3A_...">...</code></td>
<td>
<p>Various objects of class <code><a href="#topic+freqlist">freqlist</a></code> or a list of
objects of class <code><a href="#topic+freqlist">freqlist</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+freqlist">freqlist</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(flist1 &lt;- freqlist("A first toy corpus.", as_text = TRUE))
(flist2 &lt;- freqlist("A second toy corpus.", as_text = TRUE))
(flist3 &lt;- freqlist("A third toy corpus.", as_text = TRUE))

freqlist_merge(flist1, flist2)

freqlist_merge_all(flist1, flist2, flist3)
freqlist_merge_all(list(flist1, flist2, flist3)) # same result
</code></pre>

<hr>
<h2 id='merge_tokens'>Merge <code>tokens</code> objects</h2><span id='topic+merge_tokens'></span><span id='topic+tokens_merge'></span><span id='topic+tokens_merge_all'></span>

<h3>Description</h3>

<p><code>tokens_merge()</code> merges two <code><a href="#topic+tokens">tokens</a></code> objects <code>x</code> and <code>y</code> into a larger
<code><a href="#topic+tokens">tokens</a></code> object. <code>tokens_merge_all()</code> merge all the arguments into one
<code><a href="#topic+tokens">tokens</a></code> object. The result is a concatenation of the tokens, in which the
order of the items in the input is preserved.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokens_merge(x, y)

tokens_merge_all(...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_tokens_+3A_x">x</code>, <code id="merge_tokens_+3A_y">y</code></td>
<td>
<p>An object of class <code><a href="#topic+tokens">tokens</a></code></p>
</td></tr>
<tr><td><code id="merge_tokens_+3A_...">...</code></td>
<td>
<p>Objects of class <code><a href="#topic+tokens">tokens</a></code> or a list with objects of class <code><a href="#topic+tokens">tokens</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+tokens">tokens</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tks1 &lt;- tokenize(c("This is a first sentence.")))
(tks2 &lt;- tokenize(c("It is followed by a second one.")))
(tks3 &lt;- tokenize(c("Then a third one follows.")))

tokens_merge(tks1, tks2)
tokens_merge_all(tks1, tks2, tks3)
tokens_merge_all(list(tks1, tks2, tks3))
</code></pre>

<hr>
<h2 id='merge_types'>Merge 'types' objects</h2><span id='topic+merge_types'></span><span id='topic+types_merge'></span><span id='topic+types_merge_all'></span>

<h3>Description</h3>

<p>These methods merge two or more objects of class <code><a href="#topic+types">types</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>types_merge(x, y, sort = FALSE)

types_merge_all(..., sort = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_types_+3A_x">x</code>, <code id="merge_types_+3A_y">y</code></td>
<td>
<p>An object of class <code><a href="#topic+types">types</a></code>.</p>
</td></tr>
<tr><td><code id="merge_types_+3A_sort">sort</code></td>
<td>
<p>Logical. Should the results be sorted.</p>
</td></tr>
<tr><td><code id="merge_types_+3A_...">...</code></td>
<td>
<p>Either objects of the class <code><a href="#topic+types">types</a></code> or lists containing such objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the class <code><a href="#topic+types">types</a></code>.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>types_merge()</code>: Merge two types
</p>
</li>
<li> <p><code>types_merge_all()</code>: Merge multiple types
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>(tps1 &lt;- as_types(c("a", "simple", "simple", "example")))
(tps2 &lt;- as_types(c("with", "a", "few", "words")))
(tps3 &lt;- as_types(c("just", "for", "testing")))
types_merge(tps1, tps2)       # always removes duplicates, but doesn't sort
sort(types_merge(tps1, tps2)) # same, but with sorting
types_merge_all(tps1, tps2, tps3)
types_merge_all(list(tps1, tps2, tps3))
</code></pre>

<hr>
<h2 id='n_fnames'>Count number of items in an 'fnames' object</h2><span id='topic+n_fnames'></span>

<h3>Description</h3>

<p>This function counts the number of items, duplicated or not, in an <code><a href="#topic+fnames">fnames</a></code>
object. If there are duplicated items, it will return a warning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_fnames(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n_fnames_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+fnames">fnames</a></code>.</p>
</td></tr>
<tr><td><code id="n_fnames_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>cwd_fnames &lt;- as_fnames(c("folder/file1.txt", "folder/file2.txt", "folder/file3.txt"))
n_fnames(cwd_fnames)
</code></pre>

<hr>
<h2 id='n_tokens'>Count tokens</h2><span id='topic+n_tokens'></span><span id='topic+n_tokens.freqlist'></span><span id='topic+n_tokens.tokens'></span>

<h3>Description</h3>

<p>This method returns the number of tokens in an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_tokens(x, ...)

## S3 method for class 'freqlist'
n_tokens(x, ...)

## S3 method for class 'tokens'
n_tokens(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n_tokens_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="n_tokens_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number.
</p>


<h3>See Also</h3>

<p>Other getters and setters: 
<code><a href="#topic+n_types">n_types</a>()</code>,
<code><a href="#topic+orig_ranks">orig_ranks</a>()</code>,
<code><a href="#topic+ranks">ranks</a>()</code>,
<code><a href="#topic+tot_n_tokens">tot_n_tokens</a>()</code>,
<code><a href="#topic+type_names">type_names</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tks &lt;- tokenize("The old man and the sea."))
n_tokens(tks)

(flist &lt;- freqlist(tks))
n_tokens(flist)
n_types(flist)
</code></pre>

<hr>
<h2 id='n_types'>Count types</h2><span id='topic+n_types'></span><span id='topic+n_types.assoc_scores'></span><span id='topic+n_types.freqlist'></span><span id='topic+n_types.tokens'></span><span id='topic+n_types.types'></span>

<h3>Description</h3>

<p>This method returns the number of types in an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>n_types(x, ...)

## S3 method for class 'assoc_scores'
n_types(x, ...)

## S3 method for class 'freqlist'
n_types(x, ...)

## S3 method for class 'tokens'
n_types(x, ...)

## S3 method for class 'types'
n_types(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="n_types_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="n_types_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number.
</p>


<h3>See Also</h3>

<p>Other getters and setters: 
<code><a href="#topic+n_tokens">n_tokens</a>()</code>,
<code><a href="#topic+orig_ranks">orig_ranks</a>()</code>,
<code><a href="#topic+ranks">ranks</a>()</code>,
<code><a href="#topic+tot_n_tokens">tot_n_tokens</a>()</code>,
<code><a href="#topic+type_names">type_names</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(tks &lt;- tokenize("The old man and the sea."))

# for a types object ----------
(tps &lt;- types(tks))
n_types(tps)

# for a freqlist object -------
(flist &lt;- freqlist(tks))
n_tokens(flist)
n_types(flist)

# for an assoc_scores object --
a &lt;- c(10,    30,    15,    1)
b &lt;- c(200, 1000,  5000,  300)
c &lt;- c(100,   14,    16,    4)
d &lt;- c(300, 5000, 10000, 6000)
types &lt;- c("four", "fictitious", "toy", "examples")

(scores &lt;- assoc_abcd(a, b, c, d, types = types))
n_types(scores)
</code></pre>

<hr>
<h2 id='orig_ranks'>Retrieve or set original ranks</h2><span id='topic+orig_ranks'></span><span id='topic+orig_ranks+3C-'></span><span id='topic+orig_ranks+3C-.freqlist'></span><span id='topic+orig_ranks.freqlist'></span><span id='topic+orig_ranks+3C-.default'></span>

<h3>Description</h3>

<p>These methods retrieve or set, for a the original ranks for the frequency
counts of an object.
These original ranks are only defined if <code>x</code> is the result of a selection
procedure (i.e. if <code>x</code> contains frequency counts for a selection of items
only, and not for all tokens in the corpus).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orig_ranks(x, ...)

orig_ranks(x) &lt;- value

## S3 replacement method for class 'freqlist'
orig_ranks(x) &lt;- value

## S3 method for class 'freqlist'
orig_ranks(x, with_names = FALSE, ...)

## Default S3 replacement method:
orig_ranks(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orig_ranks_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="orig_ranks_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
<tr><td><code id="orig_ranks_+3A_value">value</code></td>
<td>
<p>Currently it can only be <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="orig_ranks_+3A_with_names">with_names</code></td>
<td>
<p>Logical. Whether or not the items in the output should
be given names. If <code>TRUE</code>, then the names
of the types in the frequency list are used as names.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Either <code>NULL</code> or a numeric vector, representing the
original ranks, with as its names the types to which these ranks apply.
</p>


<h3>See Also</h3>

<p>Other getters and setters: 
<code><a href="#topic+n_tokens">n_tokens</a>()</code>,
<code><a href="#topic+n_types">n_types</a>()</code>,
<code><a href="#topic+ranks">ranks</a>()</code>,
<code><a href="#topic+tot_n_tokens">tot_n_tokens</a>()</code>,
<code><a href="#topic+type_names">type_names</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- freqlist("The man and the mouse.",
              as_text = TRUE)
x
orig_ranks(x)
orig_ranks(x, with_names = TRUE)

y &lt;- keep_types(x, c("man", "and"))
orig_ranks(y)
y

orig_ranks(y) &lt;- NULL
y
orig_ranks(y)

tot_n_tokens(y) &lt;- sum(y)
y
</code></pre>

<hr>
<h2 id='p_to_chisq1'>P right quantile in chi-squared distribution with 1 degree of freedom</h2><span id='topic+p_to_chisq1'></span>

<h3>Description</h3>

<p>P right quantile that takes as its argument a probability <code>p</code> and that returns
the <code>p</code> <em>right quantile</em> in the <code class="reqn">\chi^2</code> distribution with one degree of
freedom. In other words, it returns a value <em>q</em> such that a proportion <code>p</code>
<code class="reqn">\chi^2</code> distribution with one degree of freedom lies above <em>q</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>p_to_chisq1(p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="p_to_chisq1_+3A_p">p</code></td>
<td>
<p>A proportion.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>p</code> <em>right quantile</em> in the <code class="reqn">\chi^2</code> distribution with
one degree of freedom.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+chisq1_to_p">chisq1_to_p()</a></code>
</p>

<hr>
<h2 id='perl_flavor'>Retrieve or set the flavor of a regular expression</h2><span id='topic+perl_flavor'></span><span id='topic+perl_flavor+3C-'></span>

<h3>Description</h3>

<p>These functions retrieve or set the <code>perl</code> property of an object of class <code><a href="#topic+re">re</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>perl_flavor(x)

perl_flavor(x) &lt;- value
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="perl_flavor_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+re">re</a></code>.</p>
</td></tr>
<tr><td><code id="perl_flavor_+3A_value">value</code></td>
<td>
<p>Logical.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The assignment function merely sets the <code>perl</code> property so that the <code>x</code>
attribute is read as an expression using the PCRE flavor of regular expression
(when <code>perl = TRUE</code>) or not (when <code>perl = FALSE</code>).
The regular expression itself is not modified: if <code>perl</code> is set to an
inappropriate value, the regular expression will no longer function properly in
any of the functions that support <code><a href="#topic+re">re</a></code> objects.
</p>


<h3>Value</h3>

<p>A logical vector of length 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(regex &lt;- re("^.{3,}"))
perl_flavor(regex)

perl_flavor(regex) &lt;- FALSE
perl_flavor(regex)
regex

perl_flavor(regex) &lt;- TRUE
perl_flavor(regex)
regex
</code></pre>

<hr>
<h2 id='print_kwic'>Print a concordance in KWIC format</h2><span id='topic+print_kwic'></span>

<h3>Description</h3>

<p>This function prints a concordance in KWIC format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>print_kwic(
  x,
  min_c_left = NA,
  max_c_left = NA,
  min_c_match = NA,
  max_c_match = NA,
  min_c_right = NA,
  max_c_right = NA,
  from = 1,
  n = 30,
  drop_tags = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print_kwic_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+conc">conc</a></code>.</p>
</td></tr>
<tr><td><code id="print_kwic_+3A_min_c_left">min_c_left</code>, <code id="print_kwic_+3A_max_c_left">max_c_left</code></td>
<td>
<p>Minimum and maximum size, expressed in number of
characters, of the left co-text in the KWIC display.</p>
</td></tr>
<tr><td><code id="print_kwic_+3A_min_c_match">min_c_match</code>, <code id="print_kwic_+3A_max_c_match">max_c_match</code></td>
<td>
<p>Minimum and maximum size, expressed in number of
characters, of the match in the KWIC display.</p>
</td></tr>
<tr><td><code id="print_kwic_+3A_min_c_right">min_c_right</code>, <code id="print_kwic_+3A_max_c_right">max_c_right</code></td>
<td>
<p>Minimum and maximum size, expressed in number of
characters, of the right co-text in the KWIC display.</p>
</td></tr>
<tr><td><code id="print_kwic_+3A_from">from</code></td>
<td>
<p>Index of the first item of <code>x</code> to be displayed.</p>
</td></tr>
<tr><td><code id="print_kwic_+3A_n">n</code></td>
<td>
<p>Number of consecutive items in <code>x</code> to be displayed.</p>
</td></tr>
<tr><td><code id="print_kwic_+3A_drop_tags">drop_tags</code></td>
<td>
<p>Logical. Should tags be hidden?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+print.conc">print</a>
</p>

<hr>
<h2 id='print.assoc_scores'>Print an object</h2><span id='topic+print.assoc_scores'></span><span id='topic+print.conc'></span><span id='topic+print.fnames'></span><span id='topic+print.freqlist'></span><span id='topic+mclm_print'></span><span id='topic+print.slma'></span><span id='topic+print.tokens'></span><span id='topic+print.types'></span>

<h3>Description</h3>

<p>This base method prints objects; here the arguments specific to mclm
implementations are described.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'assoc_scores'
print(
  x,
  n = 20,
  from = 1,
  freeze_cols = NULL,
  keep_cols = NULL,
  drop_cols = NULL,
  from_col = 1,
  sort_order = c("none", "G_signed", "PMI", "alpha"),
  extra = NULL,
  ...
)

## S3 method for class 'conc'
print(x, n = 30, ...)

## S3 method for class 'fnames'
print(
  x,
  n = 20,
  from = 1,
  sort_order = c("none", "alpha"),
  extra = NULL,
  hide_path = NULL,
  ...
)

## S3 method for class 'freqlist'
print(x, n = 20, from = 1, extra = NULL, ...)

## S3 method for class 'slma'
print(x, n = 20, from = 1, ...)

## S3 method for class 'tokens'
print(x, n = 20, from = 1, extra = NULL, ...)

## S3 method for class 'types'
print(x, n = 20, from = 1, sort_order = c("none", "alpha"), extra = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.assoc_scores_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="print.assoc_scores_+3A_n">n</code></td>
<td>
<p>Maximum number of items in the object to be printed at once.</p>
</td></tr>
<tr><td><code id="print.assoc_scores_+3A_from">from</code></td>
<td>
<p>Index of the first item to be printed.</p>
</td></tr>
<tr><td><code id="print.assoc_scores_+3A_freeze_cols">freeze_cols</code></td>
<td>
<p>Names of columns that should not be affected by the argument
<code>from_col</code>. Frozen columns are always printed to the left of non-frozen
columns, even if in their original order was different. The names of the types
are always and unavoidably printed as the leftmost column.
</p>
<p>If this argument is <code>NULL</code>, then the default setting applies, meaning that
the following columns, if present, are displayed in the &quot;frozen area&quot;: <code>a</code>,
<code>PMI</code> and <code>G_signed</code>.
</p>
<p>To avoid any columns for being frozen, <code>freeze_cols</code> should be <code>NA</code> or
<code>character(0)</code>.</p>
</td></tr>
<tr><td><code id="print.assoc_scores_+3A_keep_cols">keep_cols</code>, <code id="print.assoc_scores_+3A_drop_cols">drop_cols</code></td>
<td>
<p>A vector of column names or <code>NULL</code>. If both arguments
are <code>NULL</code>, all columns are printed (or as many as fit on the screen). If
<code>keep_cols</code> is not <code>NULL</code>, it indicates the columns that should be printed.
If it is <code>NULL</code> but <code>drop_cols</code> is not, then <code>drop_cols</code> indicates the columns
that should <em>not</em> be printed. Note that they have <strong>no effect</strong> on the frozen area.
</p>
<p>Columns that are blocked from printing by these arguments are still available
to <code>sort_order</code>.</p>
</td></tr>
<tr><td><code id="print.assoc_scores_+3A_from_col">from_col</code></td>
<td>
<p>Index of the first column to be displayed in the regular area
(among all selected columns, including frozen columns). If <code>from_col</code> points</p>
</td></tr>
<tr><td><code id="print.assoc_scores_+3A_sort_order">sort_order</code></td>
<td>
<p>Order in which the items are to be printed. In general, possible values
are <code>"alpha"</code> (meaning that the items are to be sorted alphabetically),
and <code>"none"</code> (meaning that the items are not to be sorted).
If <code>x</code> is an object of class <code><a href="#topic+assoc_scores">assoc_scores</a></code>, a column name
or vector of column names may be provided instead.</p>
</td></tr>
<tr><td><code id="print.assoc_scores_+3A_extra">extra</code></td>
<td>
<p>Extra settings, as an <a href="base.html#topic+environment">environment</a>. Arguments defined here
take precedence over other arguments. For instance, if <code>extra$from_col</code> is
not <code>NULL</code>, it will overrule the <code>from_col</code> argument.</p>
</td></tr>
<tr><td><code id="print.assoc_scores_+3A_...">...</code></td>
<td>
<p>Additional printing arguments.</p>
</td></tr>
<tr><td><code id="print.assoc_scores_+3A_hide_path">hide_path</code></td>
<td>
<p>A character string with a regular expression or <code>NULL</code>. If it is
not <code>NULL</code>, the character string will be removed from the paths when printing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
For objects of class <code>assoc_scores</code>, the output consists of two areas:
the 'frozen area' on the left and the 'regular area' on the right. Both
areas are visually separated by a vertical line (<code>|</code>). The distinction between
them is more intuitive in <code><a href="#topic+explore">explore()</a></code>, where the frozen columns do not respond
to horizontal movements (with the <code>r</code> and <code>l</code> commands). The equivalent in
this method is the <code>from_col</code> argument.
</p>

<hr>
<h2 id='ranks'>Retrieve the current ranks for frequency counts.</h2><span id='topic+ranks'></span><span id='topic+ranks.freqlist'></span>

<h3>Description</h3>

<p><code>ranks</code> retrieves from the ranks of its items in an object.
These ranks are integer values running from one up to the number of items
in <code>x</code>. Each items receives a unique rank.
Items are first ranked by frequency in descending order. Items with
identical frequency are further ranked by alphabetic order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ranks(x, ...)

## S3 method for class 'freqlist'
ranks(x, with_names = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ranks_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="ranks_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
<tr><td><code id="ranks_+3A_with_names">with_names</code></td>
<td>
<p>Logical. Whether or not the items in the output should
be given names. If <code>TRUE</code>, then the names
of the types in the frequency list are used as names.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mclm method <code><a href="#topic+ranks">ranks()</a></code> is not
to be confused with <code><a href="base.html#topic+rank">base::rank()</a></code>. There are two
important differences.
</p>
<p>First,<code><a href="base.html#topic+rank">base::rank()</a></code> always ranks items from low values to
high values and <code><a href="#topic+ranks">ranks()</a></code> ranks from high
frequency items to low frequency items.
</p>
<p>Second, <code><a href="base.html#topic+rank">base::rank()</a></code> allows the user to choose among
a number of different ways to handle ties.
In contrast, <code><a href="#topic+ranks">ranks()</a></code> always handles ties
in the same way. More specifically, items with identical frequencies
are always ranked in alphabetical order.
</p>
<p>In other words, <code><a href="base.html#topic+rank">base::rank()</a></code> is a flexible tool that
supports a number of different ranking methods that are commonly used in
statistics. In contrast, <code><a href="#topic+ranks">ranks()</a></code> is a
rigid tool that supports only one type of ranking, which is a type of
ranking that is atypical from a statistics point of view, but is commonly
used in linguistic frequency lists. Also, it is designed to be unaffected
by the order of the items in the frequency list.
</p>


<h3>Value</h3>

<p>Numeric vector representing the current ranks, with as its names
the types to which the ranks apply.
</p>


<h3>See Also</h3>

<p>Other getters and setters: 
<code><a href="#topic+n_tokens">n_tokens</a>()</code>,
<code><a href="#topic+n_types">n_types</a>()</code>,
<code><a href="#topic+orig_ranks">orig_ranks</a>()</code>,
<code><a href="#topic+tot_n_tokens">tot_n_tokens</a>()</code>,
<code><a href="#topic+type_names">type_names</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(flist &lt;- freqlist("The man and the mouse.", as_text = TRUE))

orig_ranks(flist)
ranks(flist)
ranks(flist, with_names = TRUE)

(flist2 &lt;- keep_types(flist, c("man", "and")))

orig_ranks(flist2)
ranks(flist2)
</code></pre>

<hr>
<h2 id='re'>Build a regular expression</h2><span id='topic+re'></span><span id='topic+as_re'></span><span id='topic+as.re'></span>

<h3>Description</h3>

<p>Create an object of class <code>re</code> or coerce a character vector to an object of
class <code>re</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>re(x, perl = TRUE, ...)

as_re(x, perl = TRUE, ...)

as.re(x, perl = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="re_+3A_x">x</code></td>
<td>
<p>Character vector of length one. The value of this character vector
is assumed to be a well-formed regular expression. In the current implementation
this is assumed, not checked.</p>
</td></tr>
<tr><td><code id="re_+3A_perl">perl</code></td>
<td>
<p>Logical. If <code>TRUE</code>, <code>x</code> is assumed to use PCRE (i.e. Perl
Compatible Regular Expressions) notation. If <code>FALSE</code>, <code>x</code> is assumed to use
base R's default regular expression notation.
Contrary to base R's regular expression functions, <code><a href="#topic+re">re()</a></code> assumes that the
PCRE regular expression flavor is used by default.</p>
</td></tr>
<tr><td><code id="re_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This class exists because some functions in the mclm package
require their arguments to be marked as being regular expressions.
For example, <code><a href="#topic+keep_re">keep_re()</a></code> does not need its <code>pattern</code> argument to be a <code><a href="#topic+re">re</a></code>
object, but if the user wants to subset items with <a href="#topic+brackets">brackets</a> using
a regular expression, they must use a <code><a href="#topic+re">re</a></code> object.
</p>


<h3>Value</h3>

<p>An object of class <code>re</code>, which is a wrapper around a character vector
flagging it as containing a regular expression. In essence it is a named
list: the <code>x</code> item contains the <code>x</code> input and the <code>perl</code> item contains
the value of the <code>perl</code> argument (<code>TRUE</code> by default).
</p>
<p>It has basic methods such as <code><a href="base.html#topic+print">print()</a></code>, <code><a href="base.html#topic+summary">summary()</a></code> and <code><a href="base.html#topic+as.character">as.character()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+perl_flavor">perl_flavor()</a></code>, <code><a href="#topic+scan_re">scan_re()</a></code>, <code><a href="#topic+cat_re">cat_re()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
  It consisted of three sentences. And it lived happily ever after."

(tks &lt;- tokenize(toy_corpus))

# In `keep_re()`, the use of `re()` is optional
keep_re(tks, re("^.{3,}"))
keep_re(tks, "^.{3,}")

# When using brackets notation, `re()` is necessary
tks[re("^.{3,}")]
tks["^.{3,}"]

# build and print a `re` object
re("^.{3,}")
as_re("^.{3,}")
as.re("^.{3,}")
print(re("^.{3,}"))
</code></pre>

<hr>
<h2 id='re_convenience'>Convenience functions in support of regular expressions</h2><span id='topic+re_convenience'></span><span id='topic+re_retrieve_first'></span><span id='topic+re_retrieve_last'></span><span id='topic+re_retrieve_all'></span><span id='topic+re_has_matches'></span><span id='topic+re_which'></span><span id='topic+re_replace_first'></span><span id='topic+re_replace_all'></span>

<h3>Description</h3>

<p>These functions are essentially simple wrappers around base R functions such as
<code><a href="base.html#topic+regexpr">regexpr()</a></code>, <code><a href="base.html#topic+gregexpr">gregexpr()</a></code>, <code><a href="base.html#topic+grepl">grepl()</a></code>, <code><a href="base.html#topic+grep">grep()</a></code>, <code><a href="base.html#topic+sub">sub()</a></code> and <code><a href="base.html#topic+gsub">gsub()</a></code>.
The most important differences between the functions documented here and the
R base functions is the order of the arguments (<code>x</code> before <code>pattern</code>) and the
fact that the argument <code>perl</code> is set to <code>TRUE</code> by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>re_retrieve_first(
  x,
  pattern,
  ignore.case = FALSE,
  perl = TRUE,
  fixed = FALSE,
  useBytes = FALSE,
  requested_group = NULL,
  drop_NA = FALSE,
  ...
)

re_retrieve_last(
  x,
  pattern,
  ignore.case = FALSE,
  perl = TRUE,
  fixed = FALSE,
  useBytes = FALSE,
  requested_group = NULL,
  drop_NA = FALSE,
  ...
)

re_retrieve_all(
  x,
  pattern,
  ignore.case = FALSE,
  perl = TRUE,
  fixed = FALSE,
  useBytes = FALSE,
  requested_group = NULL,
  unlist = TRUE,
  ...
)

re_has_matches(
  x,
  pattern,
  ignore.case = FALSE,
  perl = TRUE,
  fixed = FALSE,
  useBytes = FALSE,
  ...
)

re_which(
  x,
  pattern,
  ignore.case = FALSE,
  perl = TRUE,
  fixed = FALSE,
  useBytes = FALSE,
  ...
)

re_replace_first(
  x,
  pattern,
  replacement,
  ignore.case = FALSE,
  perl = TRUE,
  fixed = FALSE,
  useBytes = FALSE,
  ...
)

re_replace_all(
  x,
  pattern,
  replacement,
  ignore.case = FALSE,
  perl = TRUE,
  fixed = FALSE,
  useBytes = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="re_convenience_+3A_x">x</code></td>
<td>
<p>Character vector to be searched or modified.</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_pattern">pattern</code></td>
<td>
<p>Regular expression specifying what is to be searched.</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_ignore.case">ignore.case</code></td>
<td>
<p>Logical. Should the search be case insensitive?</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_perl">perl</code></td>
<td>
<p>Logical. Whether the regular expressions use the PCRE flavor
of regular expression. Unlike in base R functions, the default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_fixed">fixed</code></td>
<td>
<p>Logical. If <code>TRUE</code>, <code>pattern</code> is a string to be matched as is,
i.e. wildcards and special characters are not interpreted.</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_usebytes">useBytes</code></td>
<td>
<p>Logical. If <code>TRUE</code> the matching is done byte-by-byte rather than
character-by-character. See 'Details' in <code><a href="base.html#topic+grep">grep()</a></code>.</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_requested_group">requested_group</code></td>
<td>
<p>Numeric.
If <code>NULL</code> or <code>0</code>, the output will contain matches for <code>pattern</code> as a whole.
If another number <code>n</code> is provided, then the output will not contain matches
for <code>pattern</code> but instead will only contain the matches for the <code>n</code>th capturing
group in <code>pattern</code> (the first if <code>requested_group = 1</code>, the second if
<code>requested_group = 2</code>...).</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_drop_na">drop_NA</code></td>
<td>
<p>Logical. If <code>FALSE</code>, the output always has the same length as
the input <code>x</code> and items that do not contain a match for <code>pattern</code> yield <code>NA</code>.
If <code>TRUE</code>, such <code>NA</code> values are removed and therefore the result might contain
fewer items than <code>x</code>.</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_unlist">unlist</code></td>
<td>
<p>Logical. If <code>FALSE</code>, the output always has the same length as
the input <code>x</code>. More specifically, the result will be a list in which input
items that do not contain a match for <code>pattern</code> yield an empty vector, whereas
input items that do match will yield a vector of at least length one (depending
on the number of matches). If <code>TRUE</code>, the output is a single vector the length
of which may be shorter or longer than <code>x</code>.</p>
</td></tr>
<tr><td><code id="re_convenience_+3A_replacement">replacement</code></td>
<td>
<p>Character vector of length one specifying the replacement
string. It is to be taken literally, except that the notation <code style="white-space: pre;">&#8288;\\1&#8288;</code>, <code style="white-space: pre;">&#8288;\\2&#8288;</code>, etc.
can be used to refer to groups in <code>pattern</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For some of the arguments (e.g. <code>perl</code>, <code>fixed</code>) the reader is directed to
<a href="base.html#topic+regex">base R's regex documentation</a>.
</p>


<h3>Value</h3>

<p><code>re_retrieve_first()</code>, <code>re_retrieve_last()</code> and <code>re_retrieve_all()</code> return
either a single vector of character data or a list containing such vectors.
<code>re_replace_first()</code> and <code>re_replace_all()</code> return the same type of character
vector as <code>x</code>.
</p>
<p><code>re_has_matches()</code> returns a logical vector indicating whether a match was
found in each of the elements in <code>x</code>; <code>re_which()</code> returns a numeric
vector indicating the indices of the elements of <code>x</code> for which a match was
found.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>re_retrieve_first()</code>: Retrieve from each item in <code>x</code> the first match
of <code>pattern</code>.
</p>
</li>
<li> <p><code>re_retrieve_last()</code>: Retrieve from each item in <code>x</code>
the last match of <code>pattern</code>.
</p>
</li>
<li> <p><code>re_retrieve_all()</code>: Retrieve from each item in <code>x</code>
all matches of <code>pattern</code>.
</p>
</li>
<li> <p><code>re_has_matches()</code>: Simple wrapper around <code><a href="base.html#topic+grepl">grepl()</a></code>.
</p>
</li>
<li> <p><code>re_which()</code>: Simple wrapper around <code><a href="base.html#topic+grep">grep()</a></code>.
</p>
</li>
<li> <p><code>re_replace_first()</code>: Simple wrapper around <code><a href="base.html#topic+sub">sub()</a></code>.
</p>
</li>
<li> <p><code>re_replace_all()</code>: Simple wrapper around <code><a href="base.html#topic+gsub">gsub()</a></code>.
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- tokenize("This is a sentence with a couple of words in it.")
pattern &lt;- "[oe](.)(.)"

re_retrieve_first(x, pattern)
re_retrieve_first(x, pattern, drop_NA = TRUE)
re_retrieve_first(x, pattern, requested_group = 1)
re_retrieve_first(x, pattern, drop_NA = TRUE, requested_group = 1)
re_retrieve_first(x, pattern, requested_group = 2)

re_retrieve_last(x, pattern)
re_retrieve_last(x, pattern, drop_NA = TRUE)
re_retrieve_last(x, pattern, requested_group = 1)
re_retrieve_last(x, pattern, drop_NA = TRUE, requested_group = 1)
re_retrieve_last(x, pattern, requested_group = 2)

re_retrieve_all(x, pattern)
re_retrieve_all(x, pattern, unlist = FALSE)
re_retrieve_all(x, pattern, requested_group = 1)
re_retrieve_all(x, pattern, unlist = FALSE, requested_group = 1)
re_retrieve_all(x, pattern, requested_group = 2)

re_replace_first(x, "([oe].)", "{\\1}")
re_replace_all(x, "([oe].)", "{\\1}")
</code></pre>

<hr>
<h2 id='read_assoc'>Read association scores from file</h2><span id='topic+read_assoc'></span>

<h3>Description</h3>

<p>This function reads a file written by <code><a href="#topic+write_assoc">write_assoc()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_assoc(file, sep = "\t", file_encoding = "UTF-8", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_assoc_+3A_file">file</code></td>
<td>
<p>Path of the input file.</p>
</td></tr>
<tr><td><code id="read_assoc_+3A_sep">sep</code></td>
<td>
<p>Field separator in the input file.</p>
</td></tr>
<tr><td><code id="read_assoc_+3A_file_encoding">file_encoding</code></td>
<td>
<p>Encoding of the input file.</p>
</td></tr>
<tr><td><code id="read_assoc_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+assoc_scores">assoc_scores</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write_assoc">write_assoc()</a></code>
</p>
<p>Other reading functions: 
<code><a href="#topic+read_conc">read_conc</a>()</code>,
<code><a href="#topic+read_fnames">read_fnames</a>()</code>,
<code><a href="#topic+read_freqlist">read_freqlist</a>()</code>,
<code><a href="#topic+read_tokens">read_tokens</a>()</code>,
<code><a href="#topic+read_txt">read_txt</a>()</code>,
<code><a href="#topic+read_types">read_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>txt1 &lt;- "we're just two lost souls swimming in a fish bowl,
year after year, running over the same old ground,
what have we found? the same old fears.
wish you were here."
flist1 &lt;- freqlist(txt1, as_text = TRUE)
txt2 &lt;- "picture yourself in a boat on a river
with tangerine dreams and marmelade skies
somebody calls you, you answer quite slowly
a girl with kaleidoscope eyes"
flist2 &lt;- freqlist(txt2, as_text = TRUE)
(scores &lt;- assoc_scores(flist1, flist2, min_freq = 0))

write_assoc(scores, "example_scores.tab")
(scores2 &lt;- read_assoc("example_scores.tab"))

</code></pre>

<hr>
<h2 id='read_conc'>Read a concordance from a file</h2><span id='topic+read_conc'></span>

<h3>Description</h3>

<p>This function reads concordance-based data frames that are written to file
with the function <code><a href="#topic+write_conc">write_conc()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_conc(
  file,
  sep = "\t",
  file_encoding = "UTF-8",
  stringsAsFactors = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_conc_+3A_file">file</code></td>
<td>
<p>Name of the input file.</p>
</td></tr>
<tr><td><code id="read_conc_+3A_sep">sep</code></td>
<td>
<p>Field separator used in the input file.</p>
</td></tr>
<tr><td><code id="read_conc_+3A_file_encoding">file_encoding</code></td>
<td>
<p>Encoding of the input file.</p>
</td></tr>
<tr><td><code id="read_conc_+3A_stringsasfactors">stringsAsFactors</code></td>
<td>
<p>Logical. Whether character data should automatically
be converted to factors. It applies to all columns except for <code>"source"</code>,
<code>"left"</code>, <code>"match"</code> and <code>"right"</code>, which are never converted.</p>
</td></tr>
<tr><td><code id="read_conc_+3A_...">...</code></td>
<td>
<p>Additional arguments, not implemented.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code><a href="#topic+conc">conc</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+import_conc">import_conc()</a></code> for reading files not generated with <code><a href="#topic+write_conc">write_conc()</a></code>.
</p>
<p>Other reading functions: 
<code><a href="#topic+read_assoc">read_assoc</a>()</code>,
<code><a href="#topic+read_fnames">read_fnames</a>()</code>,
<code><a href="#topic+read_freqlist">read_freqlist</a>()</code>,
<code><a href="#topic+read_tokens">read_tokens</a>()</code>,
<code><a href="#topic+read_txt">read_txt</a>()</code>,
<code><a href="#topic+read_types">read_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(d &lt;- conc('A very small corpus.', '\\w+', as_text = TRUE))

write_conc(d, "example_data.tab")
(d2 &lt;- read_conc("example_data.tab"))

</code></pre>

<hr>
<h2 id='read_fnames'>Read a collection of filenames from a text file</h2><span id='topic+read_fnames'></span>

<h3>Description</h3>

<p>This function reads an object of class <code><a href="#topic+fnames">fnames</a></code> from a text file, which is
assumed to contain one filename on each line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_fnames(file, sep = NA, file_encoding = "UTF-8", trim_fnames = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_fnames_+3A_file">file</code></td>
<td>
<p>Path to input file.</p>
</td></tr>
<tr><td><code id="read_fnames_+3A_sep">sep</code></td>
<td>
<p>Character vector of length 1 or <code>NA</code>. If it is a character, it
indicates a separator between input files, in addition to the new line.</p>
</td></tr>
<tr><td><code id="read_fnames_+3A_file_encoding">file_encoding</code></td>
<td>
<p>Encoding used in the input file.</p>
</td></tr>
<tr><td><code id="read_fnames_+3A_trim_fnames">trim_fnames</code></td>
<td>
<p>Boolean. Should leading and trailing whitespace be stripped
from the filenames?</p>
</td></tr>
<tr><td><code id="read_fnames_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+fnames">fnames</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write_fnames">write_fnames()</a></code>
</p>
<p>Other reading functions: 
<code><a href="#topic+read_assoc">read_assoc</a>()</code>,
<code><a href="#topic+read_conc">read_conc</a>()</code>,
<code><a href="#topic+read_freqlist">read_freqlist</a>()</code>,
<code><a href="#topic+read_tokens">read_tokens</a>()</code>,
<code><a href="#topic+read_txt">read_txt</a>()</code>,
<code><a href="#topic+read_types">read_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cwd_fnames &lt;- as_fnames(c("file1.txt", "file2.txt"))
write_fnames(cwd_fnames, "file_with_filenames.txt")
cwd_fnames_2 &lt;- read_fnames("file_with_filenames.txt")

</code></pre>

<hr>
<h2 id='read_freqlist'>Read a frequency list from a csv file</h2><span id='topic+read_freqlist'></span>

<h3>Description</h3>

<p>This function reads an object of the class <code><a href="#topic+freqlist">freqlist</a></code> from a csv file. The csv
file is assumed to contain two columns, the first being the type and the
second being the frequency of that type. The file is also assumed to
have a header line with the names of both columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_freqlist(file, sep = "\t", file_encoding = "UTF-8", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_freqlist_+3A_file">file</code></td>
<td>
<p>Character vector of length 1. Path to the input file.</p>
</td></tr>
<tr><td><code id="read_freqlist_+3A_sep">sep</code></td>
<td>
<p>Character vector of length 1. Column separator.</p>
</td></tr>
<tr><td><code id="read_freqlist_+3A_file_encoding">file_encoding</code></td>
<td>
<p>File encoding used in the input file.</p>
</td></tr>
<tr><td><code id="read_freqlist_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>read_freqlist</code> not only reads the file <code>file</code>,
but also checks whether a configuration file exists with a name that
is identical to <code>file</code>, except that it has the filename extension
<code>".yaml"</code>.
</p>
<p>If such a file exists, then that configuration file
is taken to 'belong' to <code>file</code> and is also read and the frequency list attributes
<code>"tot_n_tokens"</code> and <code>"tot_n_types"</code> are retrieved from it.
</p>
<p>If no such configuration file exists,
then the values for <code>"tot_n_tokens"</code> and <code>"tot_n_types"</code> are
calculated on the basis of the frequencies in the frequency list.
</p>


<h3>Value</h3>

<p>Object of class <code><a href="#topic+freqlist">freqlist</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write_freqlist">write_freqlist()</a></code>
</p>
<p>Other reading functions: 
<code><a href="#topic+read_assoc">read_assoc</a>()</code>,
<code><a href="#topic+read_conc">read_conc</a>()</code>,
<code><a href="#topic+read_fnames">read_fnames</a>()</code>,
<code><a href="#topic+read_tokens">read_tokens</a>()</code>,
<code><a href="#topic+read_txt">read_txt</a>()</code>,
<code><a href="#topic+read_types">read_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
It consisted of three sentences. And it lived happily ever after."
freqs &lt;- freqlist(toy_corpus, as_text = TRUE)

print(freqs, n = 1000)

write_freqlist(freqs, "example_freqlist.csv")
freqs2 &lt;- read_freqlist("example_freqlist.csv")
print(freqs2, n = 1000)

</code></pre>

<hr>
<h2 id='read_tokens'>Read a <code>tokens</code> object from a text file</h2><span id='topic+read_tokens'></span>

<h3>Description</h3>

<p>This function reads an object of the class <code><a href="#topic+tokens">tokens</a></code> from a text file, typically
stored with <code><a href="#topic+write_tokens">write_tokens()</a></code>. The text file is assumed to contain one token on
each line and not to have a header.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_tokens(file, file_encoding = "UTF-8", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_tokens_+3A_file">file</code></td>
<td>
<p>Name of the input file.</p>
</td></tr>
<tr><td><code id="read_tokens_+3A_file_encoding">file_encoding</code></td>
<td>
<p>Encoding to read the input file.</p>
</td></tr>
<tr><td><code id="read_tokens_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+tokens">tokens</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write_tokens">write_tokens()</a></code>
</p>
<p>Other reading functions: 
<code><a href="#topic+read_assoc">read_assoc</a>()</code>,
<code><a href="#topic+read_conc">read_conc</a>()</code>,
<code><a href="#topic+read_fnames">read_fnames</a>()</code>,
<code><a href="#topic+read_freqlist">read_freqlist</a>()</code>,
<code><a href="#topic+read_txt">read_txt</a>()</code>,
<code><a href="#topic+read_types">read_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
(tks &lt;- tokenize("The old man and the sea."))
write_tokens(tks, "file_with_tokens.txt")
(tks2 &lt;- read_tokens("file_with_tokens.txt"))

</code></pre>

<hr>
<h2 id='read_txt'>Read a text file into a character vector</h2><span id='topic+read_txt'></span>

<h3>Description</h3>

<p>This function reads a text file and returns a character vector containing
the lines in the text file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_txt(file, file_encoding = "UTF-8", line_glue = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_txt_+3A_file">file</code></td>
<td>
<p>Name of the input file.</p>
</td></tr>
<tr><td><code id="read_txt_+3A_file_encoding">file_encoding</code></td>
<td>
<p>Encoding of the input file.</p>
</td></tr>
<tr><td><code id="read_txt_+3A_line_glue">line_glue</code></td>
<td>
<p>A character vector or <code>NA</code>. If <code>NA</code>, the output is a character
vector in which each input line is a separate item, as in <code><a href="readr.html#topic+read_lines">readr::read_lines()</a></code>.
Otherwise, the output is a character vector of length 1 in which all input lines
are concatenated, using the value of <code>line_glue[1]</code> as line separator and as
end-of-last-line marker.</p>
</td></tr>
<tr><td><code id="read_txt_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write_txt">write_txt()</a></code>
</p>
<p>Other reading functions: 
<code><a href="#topic+read_assoc">read_assoc</a>()</code>,
<code><a href="#topic+read_conc">read_conc</a>()</code>,
<code><a href="#topic+read_fnames">read_fnames</a>()</code>,
<code><a href="#topic+read_freqlist">read_freqlist</a>()</code>,
<code><a href="#topic+read_tokens">read_tokens</a>()</code>,
<code><a href="#topic+read_types">read_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- "This is
a small
text."

# write the text to a text file
write_txt(x, "example-text-file.txt")
# read a text from file
y &lt;- read_txt("example-text-file.txt")
y

</code></pre>

<hr>
<h2 id='read_types'>Read a vector of types from a text file</h2><span id='topic+read_types'></span>

<h3>Description</h3>

<p>This function read an object of the class <code><a href="#topic+types">types</a></code> from a text file. By default,
the text file is assumed to contain one type on each line.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_types(
  file,
  sep = NA,
  file_encoding = "UTF-8",
  trim_types = FALSE,
  remove_duplicates = FALSE,
  sort = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_types_+3A_file">file</code></td>
<td>
<p>Name of the input file.</p>
</td></tr>
<tr><td><code id="read_types_+3A_sep">sep</code></td>
<td>
<p>If not <code>is.na(sep)</code>, then <code>sep</code> must be a character vector
of length one. In that case, <code>sep</code> is interpreted as a
type separator in the input file. This separator the serves as an
additional type separator, next to the end of each line.
The end of a line always indicated a separator between types (in other
words, types cannot cross lines).</p>
</td></tr>
<tr><td><code id="read_types_+3A_file_encoding">file_encoding</code></td>
<td>
<p>The file encoding used in the input file.</p>
</td></tr>
<tr><td><code id="read_types_+3A_trim_types">trim_types</code></td>
<td>
<p>Logical. Should leading and trailing
white space should be stripped from the types.</p>
</td></tr>
<tr><td><code id="read_types_+3A_remove_duplicates">remove_duplicates</code></td>
<td>
<p>Logical. Should duplicates be removed from <code>x</code>
prior to coercing to a vector of types.</p>
</td></tr>
<tr><td><code id="read_types_+3A_sort">sort</code></td>
<td>
<p>Logical. Should <code>x</code> be
alphabetically sorted prior to coercing to a vector of types;
this argument is ignored if <code>remove_duplicates</code> is <code>TRUE</code>,
because the result of removing duplicates is always sorted.</p>
</td></tr>
<tr><td><code id="read_types_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Object of class <code><a href="#topic+types">types</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+write_types">write_types()</a></code>
</p>
<p>Other reading functions: 
<code><a href="#topic+read_assoc">read_assoc</a>()</code>,
<code><a href="#topic+read_conc">read_conc</a>()</code>,
<code><a href="#topic+read_fnames">read_fnames</a>()</code>,
<code><a href="#topic+read_freqlist">read_freqlist</a>()</code>,
<code><a href="#topic+read_tokens">read_tokens</a>()</code>,
<code><a href="#topic+read_txt">read_txt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
types &lt;- as_types(c("first", "second", "third"))
write_types(types, "file_with_types.txt")
types_2 &lt;- read_types("file_with_types.txt")

</code></pre>

<hr>
<h2 id='scan_re'>Scan a regular expression from console</h2><span id='topic+scan_re'></span><span id='topic+scan_re2'></span>

<h3>Description</h3>

<p>The functions <code><a href="#topic+scan_re">scan_re()</a></code> and <code><a href="#topic+scan_re2">scan_re2()</a></code> can be used to scan a regular
expression from the console.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scan_re(perl = TRUE, ...)

scan_re2(perl = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scan_re_+3A_perl">perl</code></td>
<td>
<p>Logical. If <code>TRUE</code>, the regular expression being scanned is assumed
to use PCRE (Perl Compatible Regular Expressions) notation. If <code>FALSE</code>, it
is assumed to use base R's default regular expression notation (see <a href="base.html#topic+regex">base::regex</a>).
Contrary to base R's regular expression functions, the default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="scan_re_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After the function call, R will continue scanning your input until it
encounters an empty input line, i.e. until it encounters two consecutive
newline symbols (or until it encounters a line with nothing but whitespace
characters). In other words, press ENTER twice in a row if you want to stop
inputting characters. The function will then return your input as a character vector
of length one.
</p>
<p>These functions are designed to allow you to input complex text, in particular
regular expressions, without dealing with the restrictions of string literals,
such as having to use <code style="white-space: pre;">&#8288;\\&#8288;</code> for <code style="white-space: pre;">&#8288;\&#8288;</code>.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+re">re</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scan_txt">scan_txt()</a></code>, <code><a href="#topic+cat_re">cat_re()</a></code>
</p>

<hr>
<h2 id='scan_txt'>Scan a character string from console</h2><span id='topic+scan_txt'></span><span id='topic+scan_txt2'></span>

<h3>Description</h3>

<p>The functions <code><a href="#topic+scan_txt">scan_txt()</a></code> and <code><a href="#topic+scan_txt2">scan_txt2()</a></code>, which take no arguments,
can be used to scan a text string from the console.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scan_txt()

scan_txt2()
</code></pre>


<h3>Details</h3>

<p>After the function call, R will continue scanning your input until it
encounters an empty input line, i.e. until it encounters two consecutive
newline symbols (or until it encounters a line with nothing but whitespace
characters). In other words, press ENTER twice in a row if you want to stop
inputting characters. The function will then return your input as a character vector
of length one.
</p>
<p>These functions are designed to allow you to input complex text, in particular
regular expressions, without dealing with the restrictions of string literals,
such as having to use <code style="white-space: pre;">&#8288;\\&#8288;</code> for <code style="white-space: pre;">&#8288;\&#8288;</code>.
</p>


<h3>Value</h3>

<p>A character vector of length one that contains the string that has
been scanned from the console.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scan_re">scan_re()</a></code>
</p>

<hr>
<h2 id='short_names'>Shorten filenames</h2><span id='topic+short_names'></span><span id='topic+drop_path'></span><span id='topic+drop_extension'></span>

<h3>Description</h3>

<p>Helper functions that make the paths to a file shorter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drop_path(x, ...)

drop_extension(x, ...)

short_names(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="short_names_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+fnames">fnames</a></code> or a character vector.</p>
</td></tr>
<tr><td><code id="short_names_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of the same class as <code>x</code>.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>drop_path()</code>: Extract the base name of a path, removing the paths leading to it.
</p>
</li>
<li> <p><code>drop_extension()</code>: Remove extension from a filename.
</p>
</li>
<li> <p><code>short_names()</code>: Remove both paths leading to a file and its extension.
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>cwd_fnames &lt;- as_fnames(c("folder/file1.txt", "folder/file2.txt", "folder/file3.txt"))
drop_path(cwd_fnames)
drop_extension(cwd_fnames)
short_names(cwd_fnames) # same as drop_path(drop_extension(cwd_fnames))
</code></pre>

<hr>
<h2 id='slma'>Stable lexical marker analysis</h2><span id='topic+slma'></span>

<h3>Description</h3>

<p>This function conducts a stable lexical marker analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slma(
  x,
  y,
  file_encoding = "UTF-8",
  sig_cutoff = qchisq(0.95, df = 1),
  small_pos = 1e-05,
  keep_intermediate = FALSE,
  verbose = TRUE,
  min_rank = 1,
  max_rank = 5000,
  keeplist = NULL,
  stoplist = NULL,
  ngram_size = NULL,
  max_skip = 0,
  ngram_sep = "_",
  ngram_n_open = 0,
  ngram_open = "[]",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="slma_+3A_x">x</code>, <code id="slma_+3A_y">y</code></td>
<td>
<p>Character vector or <code><a href="#topic+fnames">fnames</a></code> object with filenames for the two
sets of documents.</p>
</td></tr>
<tr><td><code id="slma_+3A_file_encoding">file_encoding</code></td>
<td>
<p>Encoding of all the files to read.</p>
</td></tr>
<tr><td><code id="slma_+3A_sig_cutoff">sig_cutoff</code></td>
<td>
<p>Numeric value indicating the cutoff value for 'significance
in the stable lexical marker analysis. The default value is <code>qchist(.95, df = 1)</code>,
which is about 3.84.</p>
</td></tr>
<tr><td><code id="slma_+3A_small_pos">small_pos</code></td>
<td>
<p>Alternative (but sometimes inferior) approach to dealing with
zero frequencies, compared to <code>haldane</code>. The argument <code>small_pos</code>
only applies when <code>haldane</code> is set to <code>FALSE</code>.
(See the Details section.)
</p>
<p>If <code>haldane</code> is <code>FALSE</code>, and there is at least one zero frequency
in a contingency table, adding small positive values to the zero frequency
cells is done systematically for all measures calculated for that table,
not just for measures that need this to be done.</p>
</td></tr>
<tr><td><code id="slma_+3A_keep_intermediate">keep_intermediate</code></td>
<td>
<p>Logical. If <code>TRUE</code>, results from intermediate
calculations are kept in the output as the &quot;intermediate&quot; element. This is
necessary if you want to inspect the object with the <code><a href="#topic+details">details()</a></code> method.</p>
</td></tr>
<tr><td><code id="slma_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Whether progress should be printed to the console
during analysis.</p>
</td></tr>
<tr><td><code id="slma_+3A_min_rank">min_rank</code>, <code id="slma_+3A_max_rank">max_rank</code></td>
<td>
<p>Minimum and maximum frequency rank in the first
corpus (<code>x</code>) of the items to take into consideration as candidate stable
markers. Only tokens or token n-grams with a frequency rank greater than or
equal to <code>min_rank</code> and lower than or equal to <code>max_rank</code> will be included.</p>
</td></tr>
<tr><td><code id="slma_+3A_keeplist">keeplist</code></td>
<td>
<p>List of types that must certainly be included in the list of
candidate markers regardless of their frequency rank and of <code>stoplist</code>.</p>
</td></tr>
<tr><td><code id="slma_+3A_stoplist">stoplist</code></td>
<td>
<p>List of types that must not be included in the list of candidate
markers, although, if a type is included in <code>keeplist</code>, its inclusion in
<code>stoplist</code> is disregarded.</p>
</td></tr>
<tr><td><code id="slma_+3A_ngram_size">ngram_size</code></td>
<td>
<p>Argument in support of ngrams/skipgrams (see also <code>max_skip</code>).
</p>
<p>If one wants to identify individual tokens, the value of <code>ngram_size</code>
should be <code>NULL</code> or <code>1</code>. If one wants to retrieve
token ngrams/skipgrams, <code>ngram_size</code> should be an integer indicating
the size of the ngrams/skipgrams. E.g. <code>2</code> for bigrams, or <code>3</code> for
trigrams, etc.</p>
</td></tr>
<tr><td><code id="slma_+3A_max_skip">max_skip</code></td>
<td>
<p>Argument in support of skipgrams. This argument is ignored if
<code>ngram_size</code> is <code>NULL</code> or is <code>1</code>.
</p>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and <code>max_skip</code>
is <code>0</code>, then regular ngrams are being retrieved (albeit that they
may contain open slots; see <code>ngram_n_open</code>).
</p>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and <code>max_skip</code>
is <code>1</code> or higher, then skipgrams are being retrieved (which in the
current implementation cannot contain open slots; see <code>ngram_n_open</code>).
</p>
<p>For instance, if <code>ngram_size</code> is <code>3</code> and <code>max_skip</code> is
<code>2</code>, then 2-skip trigrams are being retrieved.
Or if <code>ngram_size</code> is <code>5</code> and <code>max_skip</code> is
<code>3</code>, then 3-skip 5-grams are being retrieved.</p>
</td></tr>
<tr><td><code id="slma_+3A_ngram_sep">ngram_sep</code></td>
<td>
<p>Character vector of length 1 containing the string that is used to
separate/link tokens in the representation of ngrams/skipgrams
in the output of this function.</p>
</td></tr>
<tr><td><code id="slma_+3A_ngram_n_open">ngram_n_open</code></td>
<td>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and moreover
<code>ngram_n_open</code> is a number higher than <code>0</code>, then
ngrams with 'open slots' in them are retrieved. These
ngrams with 'open slots' are generalizations of fully lexically specific
ngrams (with the generalization being that one or more of the items
in the ngram are replaced by a notation that stands for 'any arbitrary token').
</p>
<p>For instance, if <code>ngram_size</code> is <code>4</code> and <code>ngram_n_open</code> is
<code>1</code>, and if moreover the input contains a
4-gram <code>"it_is_widely_accepted"</code>, then the output will contain
all modifications of <code>"it_is_widely_accepted"</code> in which one (since
<code>ngram_n_open</code> is <code>1</code>) of the items in this n-gram is
replaced by an open slot. The first and the last item inside
an ngram are never turned into an open slot; only the items in between
are candidates for being turned into open slots. Therefore, in the
example, the output will contain <code>"it_[]_widely_accepted"</code> and
<code>"it_is_[]_accepted"</code>.
</p>
<p>As a second example, if <code>ngram_size</code> is <code>5</code> and
<code>ngram_n_open</code> is <code>2</code>, and if moreover the input contains a
5-gram <code>"it_is_widely_accepted_that"</code>, then the output will contain
<code>"it_[]_[]_accepted_that"</code>, <code>"it_[]_widely_[]_that"</code>, and
<code>"it_is_[]_[]_that"</code>.</p>
</td></tr>
<tr><td><code id="slma_+3A_ngram_open">ngram_open</code></td>
<td>
<p>Character string used to represent open slots in ngrams in the
output of this function.</p>
</td></tr>
<tr><td><code id="slma_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A stable lexical marker analysis of the <em>A</em>-documents in <code>x</code> versus the <em>B</em>-documents
in <code>y</code> starts from a separate keyword analysis for all possible document couples
<code class="reqn">(a,b)</code>, with <em>a</em> an <em>A</em>-document and <em>b</em> a <em>B</em>-document. If there are <em>n</em>
<em>A</em>-documents and <em>m</em> <em>B</em>-documents, then <code class="reqn">n*m</code> keyword analyses are
conducted. The 'stability' of a linguistic item <em>x</em>, as a marker for the
collection of <em>A</em>-documents (when compared to the <em>B</em>-documents) corresponds
to the frequency and consistency with which <em>x</em> is found to be a keyword for
the <em>A</em>-documents across all aforementioned keyword analyses.
</p>
<p>In any specific keyword analysis, <em>x</em> is considered a keyword for an <em>A</em>-document
if <code>G_signed</code> is positive and moreover <code>p_G</code> is less than <code>sig_cutoff</code>
(see <code><a href="#topic+assoc_scores">assoc_scores()</a></code> for more information on the measures). Item <em>x</em> is
considered a keyword for the <em>B</em>-document if <code>G_signed</code> is negative and moreover
<code>p_G</code> is less than <code>sig_cutoff</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>slma</code>, which is a named list with at least the following
elements:
</p>

<ul>
<li><p> A <code>scores</code> dataframe with information about the stability of the chosen
lexical items. (See below.)
</p>
</li>
<li><p> An <code>intermediate</code> list with a register of intermediate values if
<code>keep_intermediate</code> was <code>TRUE</code>.
</p>
</li>
<li><p> Named items registering the values of the arguments with the same name,
namely <code>sig_cutoff</code>, <code>small_pos</code>, <code>x</code>, and <code>y</code>.
</p>
</li></ul>

<p>The <code>slma</code> object has <code><a href="#topic+as_data_frame">as_data_frame()</a></code> and <code><a href="#topic+print.slma">print</a></code> methods
as well as an ad-hoc <code><a href="#topic+details">details()</a></code> method. Note that the <code><a href="#topic+print.slma">print</a></code>
method simply prints the main dataframe.
</p>


<h4>Contents of the <code>scores</code> element</h4>

<p>The <code>scores</code> element is a dataframe of which the rows are linguistic items
for which a stable lexical marker analysis was conducted and the columns are
different 'stability measures' and related statistics. By default, the
linguistic items are sorted by decreasing 'stability' according to the <code>S_lor</code>
measure.</p>

<table>
<tr>
 <td style="text-align: left;">
   Column </td><td style="text-align: left;"> Name </td><td style="text-align: left;"> Computation </td><td style="text-align: left;"> Range of values </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>S_abs</code> </td><td style="text-align: left;"> Absolute stability </td><td style="text-align: left;"> <code>S_att</code> - <code>S_rep</code> </td><td style="text-align: left;"> <code class="reqn">-(n*m)</code> -- <code class="reqn">(n*m)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>S_nrm</code> </td><td style="text-align: left;"> Normalized stability </td><td style="text-align: left;"> <code>S_abs</code> / <code class="reqn">n*m</code> </td><td style="text-align: left;"> -1 -- 1 </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>S_att</code> </td><td style="text-align: left;"> Stability of attraction </td><td style="text-align: left;"> Number of <code class="reqn">(a,b)</code> couples in which the linguistic item is a keyword for the <em>A</em>-documents </td><td style="text-align: left;"> 0 -- <code class="reqn">n*m</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>S_rep</code> </td><td style="text-align: left;"> Stability of repulsion </td><td style="text-align: left;"> Number of <code class="reqn">(a,b)</code> couples in which the linguistic item is a keyword for the <em>B</em>-documents </td><td style="text-align: left;"> 0 -- <code class="reqn">n*m</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
   <code>S_lor</code> </td><td style="text-align: left;"> Log of odds ratio stability </td><td style="text-align: left;"> Mean of <code>log_OR</code> across all <code class="reqn">(a,b)</code> couples but setting to 0 the value when <code>p_G</code> is larger than <code>sig_cutoff</code> </td><td style="text-align: left;">  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>

<p><code>S_lor</code> is then computed as a fraction with as its numerator the sum of all
<code>log_OR</code> values across all <code class="reqn">(a,b)</code> couples for which <code>p_G</code> is lower than
<code>sig_cutoff</code> and as its denominator <code class="reqn">n*m</code>.
For more on <code>log_OR</code>, see the Value section on on <code><a href="#topic+assoc_scores">assoc_scores()</a></code>. The final
three columns on the output are meant as a tool in support of the interpretation
of the <code>log_OR</code> column. Considering all <code class="reqn">(a,b)</code> couples for which
<code>p_G</code> is smaller than <code>sig_cutoff</code>, <code>lor_min</code>, <code>lor_max</code> and <code>lor_sd</code>
are their minimum, maximum and standard deviation for each element.
</p>



<h3>Examples</h3>

<pre><code class='language-R'>a_corp &lt;- get_fnames(system.file("extdata", "cleveland", package = "mclm"))
b_corp &lt;- get_fnames(system.file("extdata", "roosevelt", package = "mclm"))
slma_ex &lt;- slma(a_corp, b_corp)
</code></pre>

<hr>
<h2 id='sort.assoc_scores'>Sort an 'assoc_scores' object</h2><span id='topic+sort.assoc_scores'></span>

<h3>Description</h3>

<p>Sort a full object of class <code><a href="#topic+assoc_scores">assoc_scores</a></code> based on some criterion. It's the
same that <code><a href="#topic+print.assoc_scores">print</a></code> does but with a bit more flexibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'assoc_scores'
sort(x, decreasing = TRUE, sort_order = "none", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sort.assoc_scores_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+assoc_scores">assoc_scores</a></code>.</p>
</td></tr>
<tr><td><code id="sort.assoc_scores_+3A_decreasing">decreasing</code></td>
<td>
<p>Boolean value.
</p>
<p>If <code>sort_order = "alpha"</code> and <code>decreasing = FALSE</code>, the rows will follow the
alphabetic order of the types. If <code>decreasing = TRUE</code> instead, it will follow
an inverted alphabetic order (from Z to A). This follows the behavior of
applying <code>sort()</code> to a character vector: note that the default value is
probably not what you would want.
</p>
<p>If <code>sort_order</code> is a column for which a <em>lower</em> value indicates a higher association,
i.e. it's a form of p-value, <code>decreasing = TRUE</code> will place lower values on top
and higher values at the bottom.
</p>
<p>For any other column, <code>decreasing = TRUE</code> will place higher values on top and
lower values at the bottom.</p>
</td></tr>
<tr><td><code id="sort.assoc_scores_+3A_sort_order">sort_order</code></td>
<td>
<p>Criterion to order the rows. Possible values
are <code>"alpha"</code> (meaning that the items are to be sorted alphabetically),
<code>"none"</code> (meaning that the items are not to be sorted) and any present
column name.</p>
</td></tr>
<tr><td><code id="sort.assoc_scores_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+assoc_scores">assoc_scores</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a &lt;- c(10,    30,    15,    1)
b &lt;- c(200, 1000,  5000,  300)
c &lt;- c(100,   14,    16,    4)
d &lt;- c(300, 5000, 10000, 6000)
types &lt;- c("four", "fictitious", "toy", "examples")
(scores &lt;- assoc_abcd(a, b, c, d, types = types))

print(scores, sort_order = "PMI")
sorted_scores &lt;- sort(scores, sort_order = "PMI")
sorted_scores

sort(scores, decreasing = FALSE, sort_order = "PMI")
</code></pre>

<hr>
<h2 id='sort.freqlist'>Sort a frequency list</h2><span id='topic+sort.freqlist'></span>

<h3>Description</h3>

<p>This method sorts an object of class <code><a href="#topic+freqlist">freqlist</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'freqlist'
sort(
  x,
  decreasing = FALSE,
  sort_crit = c("ranks", "names", "orig_ranks", "freqs"),
  na_last = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sort.freqlist_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+freqlist">freqlist</a></code>.</p>
</td></tr>
<tr><td><code id="sort.freqlist_+3A_decreasing">decreasing</code></td>
<td>
<p>Logical. If <code>TRUE</code> items are sorted from large
to small; if <code>FALSE</code>, from small to large.
</p>
<p>Note, however, that ranking in frequency lists is such that lower ranks
correspond to higher frequencies. Therefore, sorting by rank (either
<code>"ranks"</code> or <code>"orig_ranks"</code>) with <code>decreasing</code> set
to its default value <code>FALSE</code> results in the highest frequencies
ending up at the beginning of the sorted list.</p>
</td></tr>
<tr><td><code id="sort.freqlist_+3A_sort_crit">sort_crit</code></td>
<td>
<p>Character string determining the sorting criterion.
</p>
<p>If <code>sort_crit</code> is <code>"ranks"</code>, then the items in the frequency list
are sorted by their current frequency rank.
</p>
<p>If <code>sort_crit</code> is <code>"names"</code>, then the items in the frequency
list are sorted alphabetically their name.
</p>
<p>If <code>sort_crit</code> is <code>"orig_ranks"</code>, then the items in the frequency
list are sorted by their original ranks (if those are present),
or by their current frequency ranks (if no original ranks are present).
</p>
<p>Finally, sorting with <code>sort_crit</code> set to <code>"freqs"</code> is identical
to sorting by frequency ranks, but with the meaning of the argument
<code>decreasing</code> being reversed.
In other words, sorting by frequencies (<code>"freqs"</code>) with <code>decreasing</code> set
to its default value <code>FALSE</code> results in the lowest frequencies
ending up at the beginning of the sorted list.</p>
</td></tr>
<tr><td><code id="sort.freqlist_+3A_na_last">na_last</code></td>
<td>
<p>Logical defining the behavior of <code>NA</code> elements.
</p>
<p>This argument is only relevant when <code>sort_crit</code> is <code>"orig_ranks"</code>
because currently names and frequencies are not allowed to be <code>NA</code>
in frequency lists.
</p>
<p>If <code>na_last</code> is <code>TRUE</code>, then items with a sorting criterion of
<code>NA</code> end up at the end of the sorted frequency list.
If <code>na_last</code> is <code>FALSE</code>, then items with a sorting criterion
of <code>NA</code> end up at the start of the sorted frequency list.
If <code>na_last</code> is <code>NA</code>, then items with a sorting criterion of
<code>NA</code> are removed from the sorted frequency list.</p>
</td></tr>
<tr><td><code id="sort.freqlist_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Because of the way ranks are calculated for ties (with lower ranks being
assigned to ties earlier in the list), sorting the list may affect the
ranks of ties.
More specifically, ranks among ties may differ depending on the criterion
that is used to sort the frequency list.
</p>


<h3>Value</h3>

<p>Object of class <code><a href="#topic+freqlist">freqlist</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(flist &lt;- freqlist(tokenize("the old story of the old man and the sea.")))
sort(flist)
sort(flist, decreasing = TRUE)
</code></pre>

<hr>
<h2 id='tokens'>Create or coerce an object into class <code>tokens</code></h2><span id='topic+tokens'></span><span id='topic+tokenize'></span>

<h3>Description</h3>

<p><code>tokenize()</code> splits a text into a sequence of tokens, using regular expressions
to identify them, and returns an object of the class <code><a href="#topic+tokens">tokens</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tokenize(
  x,
  re_drop_line = NULL,
  line_glue = NULL,
  re_cut_area = NULL,
  re_token_splitter = re("[^_\\p{L}\\p{N}\\p{M}'-]+"),
  re_token_extractor = re("[_\\p{L}\\p{N}\\p{M}'-]+"),
  re_drop_token = NULL,
  re_token_transf_in = NULL,
  token_transf_out = NULL,
  token_to_lower = TRUE,
  perl = TRUE,
  ngram_size = NULL,
  max_skip = 0,
  ngram_sep = "_",
  ngram_n_open = 0,
  ngram_open = "[]"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tokens_+3A_x">x</code></td>
<td>
<p>Either a character vector or an object of class
<a href="NLP.html#topic+TextDocument">NLP::TextDocument</a> that contains the text to be tokenized.</p>
</td></tr>
<tr><td><code id="tokens_+3A_re_drop_line">re_drop_line</code></td>
<td>
<p><code>NULL</code> or character vector. If <code>NULL</code>, it is ignored.
Otherwise, a character vector (assumed to be of length 1)
containing a regular expression. Lines in <code>x</code>
that contain a match for <code>re_drop_line</code> are
treated as not belonging to the corpus and are excluded from the results.</p>
</td></tr>
<tr><td><code id="tokens_+3A_line_glue">line_glue</code></td>
<td>
<p><code>NULL</code> or character vector. If <code>NULL</code>, it is ignored.
Otherwise, all lines in a corpus file (or in <code>x</code>, if
<code>as_text</code> is <code>TRUE</code>), are glued together in one
character vector of length 1, with the string <code>line_glue</code>
pasted in between consecutive lines.
The value of <code>line_glue</code> can also be equal to the empty string <code>""</code>.
The 'line glue' operation is conducted immediately after the 'drop line' operation.</p>
</td></tr>
<tr><td><code id="tokens_+3A_re_cut_area">re_cut_area</code></td>
<td>
<p><code>NULL</code> or character vector. If <code>NULL</code>, it is ignored.
Otherwise, all matches in a corpus file (or in <code>x</code>,
if <code>as_text</code> is <code>TRUE</code>), are 'cut out' of the text prior
to the identification of the tokens in the text (and are therefore
not taken into account when identifying the tokens).
The 'cut area' operation is conducted immediately after the 'line glue' operation.</p>
</td></tr>
<tr><td><code id="tokens_+3A_re_token_splitter">re_token_splitter</code></td>
<td>
<p>Regular expression or <code>NULL</code>.
Regular expression that identifies the locations where lines in the corpus
files are split into tokens. (See Details.)
</p>
<p>The 'token identification' operation is conducted immediately after the
'cut area' operation.</p>
</td></tr>
<tr><td><code id="tokens_+3A_re_token_extractor">re_token_extractor</code></td>
<td>
<p>Regular expression that identifies the locations of the
actual tokens. This argument is only used if <code>re_token_splitter</code> is <code>NULL</code>.
(See Details.)
</p>
<p>The 'token identification' operation is conducted immediately after the
'cut area' operation.</p>
</td></tr>
<tr><td><code id="tokens_+3A_re_drop_token">re_drop_token</code></td>
<td>
<p>Regular expression or <code>NULL</code>. If <code>NULL</code>, it is ignored.
Otherwise, it identifies tokens that are to
be excluded from the results. Any token that contains a match for
<code>re_drop_token</code> is removed from the results.
The 'drop token' operation is conducted immediately after the 'token identification' operation.</p>
</td></tr>
<tr><td><code id="tokens_+3A_re_token_transf_in">re_token_transf_in</code></td>
<td>
<p>Regular expression that identifies areas in the
tokens that are to be transformed. This argument works together with the argument
<code>token_transf_out</code>.
</p>
<p>If both <code>re_token_transf_in</code> and <code>token_transf_out</code> differ
from <code>NA</code>, then all matches, in the tokens, for the
regular expression  <code>re_token_transf_in</code> are replaced with
the replacement string <code>token_transf_out</code>.
</p>
<p>The 'token transformation' operation is conducted immediately after the
'drop token' operation.</p>
</td></tr>
<tr><td><code id="tokens_+3A_token_transf_out">token_transf_out</code></td>
<td>
<p>Replacement string. This argument works together with
<code>re_token_transf_in</code> and is ignored if <code>re_token_transf_in</code>
is <code>NULL</code> or <code>NA</code>.</p>
</td></tr>
<tr><td><code id="tokens_+3A_token_to_lower">token_to_lower</code></td>
<td>
<p>Logical. Whether tokens must be converted
to lowercase before returning the result.
The 'token to lower' operation is conducted immediately after the
'token transformation' operation.</p>
</td></tr>
<tr><td><code id="tokens_+3A_perl">perl</code></td>
<td>
<p>Logical. Whether the PCRE regular expression
flavor is being used in the arguments that contain regular expressions.</p>
</td></tr>
<tr><td><code id="tokens_+3A_ngram_size">ngram_size</code></td>
<td>
<p>Argument in support of ngrams/skipgrams (see also <code>max_skip</code>).
</p>
<p>If one wants to identify individual tokens, the value of <code>ngram_size</code>
should be <code>NULL</code> or <code>1</code>. If one wants to retrieve
token ngrams/skipgrams, <code>ngram_size</code> should be an integer indicating
the size of the ngrams/skipgrams. E.g. <code>2</code> for bigrams, or <code>3</code> for
trigrams, etc.</p>
</td></tr>
<tr><td><code id="tokens_+3A_max_skip">max_skip</code></td>
<td>
<p>Argument in support of skipgrams. This argument is ignored if
<code>ngram_size</code> is <code>NULL</code> or is <code>1</code>.
</p>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and <code>max_skip</code>
is <code>0</code>, then regular ngrams are being retrieved (albeit that they
may contain open slots; see <code>ngram_n_open</code>).
</p>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and <code>max_skip</code>
is <code>1</code> or higher, then skipgrams are being retrieved (which in the
current implementation cannot contain open slots; see <code>ngram_n_open</code>).
</p>
<p>For instance, if <code>ngram_size</code> is <code>3</code> and <code>max_skip</code> is
<code>2</code>, then 2-skip trigrams are being retrieved.
Or if <code>ngram_size</code> is <code>5</code> and <code>max_skip</code> is
<code>3</code>, then 3-skip 5-grams are being retrieved.</p>
</td></tr>
<tr><td><code id="tokens_+3A_ngram_sep">ngram_sep</code></td>
<td>
<p>Character vector of length 1 containing the string that is used to
separate/link tokens in the representation of ngrams/skipgrams
in the output of this function.</p>
</td></tr>
<tr><td><code id="tokens_+3A_ngram_n_open">ngram_n_open</code></td>
<td>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and moreover
<code>ngram_n_open</code> is a number higher than <code>0</code>, then
ngrams with 'open slots' in them are retrieved. These
ngrams with 'open slots' are generalizations of fully lexically specific
ngrams (with the generalization being that one or more of the items
in the ngram are replaced by a notation that stands for 'any arbitrary token').
</p>
<p>For instance, if <code>ngram_size</code> is <code>4</code> and <code>ngram_n_open</code> is
<code>1</code>, and if moreover the input contains a
4-gram <code>"it_is_widely_accepted"</code>, then the output will contain
all modifications of <code>"it_is_widely_accepted"</code> in which one (since
<code>ngram_n_open</code> is <code>1</code>) of the items in this n-gram is
replaced by an open slot. The first and the last item inside
an ngram are never turned into an open slot; only the items in between
are candidates for being turned into open slots. Therefore, in the
example, the output will contain <code>"it_[]_widely_accepted"</code> and
<code>"it_is_[]_accepted"</code>.
</p>
<p>As a second example, if <code>ngram_size</code> is <code>5</code> and
<code>ngram_n_open</code> is <code>2</code>, and if moreover the input contains a
5-gram <code>"it_is_widely_accepted_that"</code>, then the output will contain
<code>"it_[]_[]_accepted_that"</code>, <code>"it_[]_widely_[]_that"</code>, and
<code>"it_is_[]_[]_that"</code>.</p>
</td></tr>
<tr><td><code id="tokens_+3A_ngram_open">ngram_open</code></td>
<td>
<p>Character string used to represent open slots in ngrams in the
output of this function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the output contains ngrams with open slots, then the order
of the items in the output is no longer meaningful. For instance, let's imagine
a case where <code>ngram_size</code> is <code>5</code> and <code>ngram_n_open</code> is <code>2</code>.
If the input contains a 5-gram <code>"it_is_widely_accepted_that"</code>, then the output
will contain <code>"it_[]_[]_accepted_that"</code>, <code>"it_[]_widely_[]_that"</code> and
<code>"it_is_[]_[]_that"</code>. The relative order of these three items in the output
must be considered arbitrary.
</p>


<h3>Value</h3>

<p>An object of class <code><a href="#topic+tokens">tokens</a></code>, i.e. a sequence of tokens.
It has a number of attributes and method such as:
</p>

<ul>
<li><p> base <code><a href="#topic+print.types">print</a></code>, <code><a href="#topic+as_data_frame">as_data_frame()</a></code>, <code><a href="base.html#topic+summary">summary()</a></code>
(which returns the number of items), <code><a href="base.html#topic+sort">sort()</a></code> and <code><a href="base.html#topic+rev">rev()</a></code>,
</p>
</li>
<li> <p><code><a href="tibble.html#topic+as_tibble">tibble::as_tibble()</a></code>,
</p>
</li>
<li><p> an interactive <code><a href="#topic+explore">explore()</a></code> method,
</p>
</li>
<li><p> some getters, namely <code><a href="#topic+n_tokens">n_tokens()</a></code> and <code><a href="#topic+n_types">n_types()</a></code>,
</p>
</li>
<li><p> subsetting methods such as <code><a href="#topic+keep_types">keep_types()</a></code>, <code><a href="#topic+keep_pos">keep_pos()</a></code>, etc. including <code style="white-space: pre;">&#8288;[]&#8288;</code>
subsetting (see <a href="#topic+brackets">brackets</a>).
</p>
</li></ul>

<p>Additional manipulation functions include the <code><a href="#topic+trunc_at">trunc_at()</a></code> method to ??,
<code><a href="#topic+tokens_merge">tokens_merge()</a></code> and <code><a href="#topic+tokens_merge_all">tokens_merge_all()</a></code> to combine token lists and an
<code><a href="#topic+as_character">as_character()</a></code> method to convert to a character vector.
</p>
<p>Objects of class <code>tokens</code> can be saved to file with <code><a href="#topic+write_tokens">write_tokens()</a></code>;
these files can be read with <code><a href="#topic+read_freqlist">read_freqlist()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as_tokens">as_tokens()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
It consisted of three sentences. And it lived happily ever after."

tks &lt;- tokenize(toy_corpus)
print(tks, n = 1000)

tks &lt;- tokenize(toy_corpus, re_token_splitter = "\\W+")
print(tks, n = 1000)
sort(tks)
summary(tks)

tokenize(toy_corpus, ngram_size = 3)

tokenize(toy_corpus, ngram_size = 3, max_skip = 2)

tokenize(toy_corpus, ngram_size = 3, ngram_n_open = 1)
</code></pre>

<hr>
<h2 id='tot_n_tokens'>Retrieve or set the total number of tokens</h2><span id='topic+tot_n_tokens'></span><span id='topic+tot_n_tokens+3C-'></span><span id='topic+tot_n_tokens+3C-.freqlist'></span><span id='topic+tot_n_tokens.freqlist'></span>

<h3>Description</h3>

<p>These methods retrieve or set the total number of tokens in
the corpus on which the frequency counts are based.
This total number of tokens may be higher than the sum of all frequency
counts in <code>x</code>, for instance, if <code>x</code> contains frequency counts
for a selection of items only, and not for all tokens in the corpus.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tot_n_tokens(x)

tot_n_tokens(x) &lt;- value

## S3 replacement method for class 'freqlist'
tot_n_tokens(x) &lt;- value

## S3 method for class 'freqlist'
tot_n_tokens(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tot_n_tokens_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="tot_n_tokens_+3A_value">value</code></td>
<td>
<p>Numerical value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A number.
</p>


<h3>See Also</h3>

<p>Other getters and setters: 
<code><a href="#topic+n_tokens">n_tokens</a>()</code>,
<code><a href="#topic+n_types">n_types</a>()</code>,
<code><a href="#topic+orig_ranks">orig_ranks</a>()</code>,
<code><a href="#topic+ranks">ranks</a>()</code>,
<code><a href="#topic+type_names">type_names</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- freqlist("The man and the mouse.",
              re_token_splitter = "(?xi) [:\\s.;,?!\"]+",
              as_text = TRUE)
x
tot_n_tokens(x)

y &lt;- keep_types(x, c("man", "and"))
tot_n_tokens(y)
y

tot_n_tokens(y) &lt;- sum(y)
y
tot_n_tokens(y)
</code></pre>

<hr>
<h2 id='trunc_at'>Truncate a sequence of character data</h2><span id='topic+trunc_at'></span><span id='topic+trunc_at.tokens'></span>

<h3>Description</h3>

<p>This method takes as its argument <code>x</code> an object that represents a sequence of
character data, such as an object of class <code><a href="#topic+tokens">tokens</a></code>, and truncates it at the
position where a match for the argument <code>pattern</code> is found. Currently it is
only implemented for <code><a href="#topic+tokens">tokens</a></code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trunc_at(x, pattern, ...)

## S3 method for class 'tokens'
trunc_at(
  x,
  pattern,
  keep_this = FALSE,
  last_match = FALSE,
  from_end = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="trunc_at_+3A_x">x</code></td>
<td>
<p>An object that represents a sequence of character data.</p>
</td></tr>
<tr><td><code id="trunc_at_+3A_pattern">pattern</code></td>
<td>
<p>A regular expression.</p>
</td></tr>
<tr><td><code id="trunc_at_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
<tr><td><code id="trunc_at_+3A_keep_this">keep_this</code></td>
<td>
<p>Logical. Whether the matching token itself should be kept.
If <code>TRUE</code>, the truncating happens right after the matching token; if <code>FALSE</code>,
right before.</p>
</td></tr>
<tr><td><code id="trunc_at_+3A_last_match">last_match</code></td>
<td>
<p>Logical. In case there are several matching tokens, if
<code>last_match</code> is <code>TRUE</code>, the last match will be used as truncating point;
otherwise, the first match will.</p>
</td></tr>
<tr><td><code id="trunc_at_+3A_from_end">from_end</code></td>
<td>
<p>Logical. If <code>FALSE</code>, the match starts from the first token progressing
forward; if <code>TRUE</code>, it starts from the last token progressing backward.
</p>
<p>If <code>from_end</code> is <code>FALSE</code>, the part of <code>x</code> that is kept after truncation is
the head of <code>x</code>. If it is <code>TRUE</code> instead, the part that is kept after truncation
is the tail of <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A truncated version of <code>x</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(toks &lt;- tokenize('This is a first sentence . This is a second sentence .',
re_token_splitter = '\\s+'))

trunc_at(toks, re("[.]"))

trunc_at(toks, re("[.]"), last_match = TRUE)

trunc_at(toks, re("[.]"), last_match = TRUE, from_end = TRUE)
</code></pre>

<hr>
<h2 id='type_freqs'>Retrieve frequencies from 'freqlist' object</h2><span id='topic+type_freqs'></span><span id='topic+type_freq'></span>

<h3>Description</h3>

<p><code>type_freq</code> and <code>type_freqs</code> retrieve the frequency of all or
some of the items of a <code><a href="#topic+freqlist">freqlist</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>type_freqs(x, types = NULL, with_names = FALSE, ...)

type_freq(x, types = NULL, with_names = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="type_freqs_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+freqlist">freqlist</a></code>.</p>
</td></tr>
<tr><td><code id="type_freqs_+3A_types">types</code></td>
<td>
<p><code>NULL</code> or a character vector or an object of the class
<code><a href="#topic+types">types</a></code>.
</p>
<p>If the argument <code>types</code> is <code>NULL</code>, then the frequencies of all
the items in <code>x</code> are returned, in the order in which
these items appear in <code>x</code>.
</p>
<p>If the argument <code>types</code> is a character vector or an object of the
class <code><a href="#topic+types">types</a></code>, then only the frequencies (in <code>x</code>)
of the items in <code>types</code> are given,
in the order in which these items appear in <code>types</code>.
For all items in <code>types</code> that do not occur in <code>x</code>,
a frequency of zero is returned.</p>
</td></tr>
<tr><td><code id="type_freqs_+3A_with_names">with_names</code></td>
<td>
<p>Logical. Whether or not the items in the output should
be given names. If <code>with_names</code> is <code>TRUE</code>, then the names
of the types in the frequency list are used as names.</p>
</td></tr>
<tr><td><code id="type_freqs_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numeric vector representing the frequencies of the items.
</p>


<h3>See Also</h3>

<p>type_names
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(flist &lt;- freqlist("The man and the mouse.", as_text = TRUE))

type_freqs(flist) # frequencies of all items
type_names(flist) # names of all items

type_freqs(flist, with_names = TRUE) # frequencies of all types, with names
type_freqs(flist, c("man", "the")) # frequencies of specific items ...
type_freqs(flist, c("the", "man")) # ... in the requested order
type_freq(flist, "the")            # frequency of one item

# frequencies of specific items can also be printed using subsetting
flist[c("the", "man")] 
flist["the"]
</code></pre>

<hr>
<h2 id='type_names'>Return the names of the types in an object</h2><span id='topic+type_names'></span><span id='topic+type_names.assoc_scores'></span><span id='topic+type_names.freqlist'></span>

<h3>Description</h3>

<p>This method returns the names of the types represented in an object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>type_names(x, ...)

## S3 method for class 'assoc_scores'
type_names(x, ...)

## S3 method for class 'freqlist'
type_names(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="type_names_+3A_x">x</code></td>
<td>
<p>An object of any of the classes for which the method is implemented.</p>
</td></tr>
<tr><td><code id="type_names_+3A_...">...</code></td>
<td>
<p>Additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Character vector.
</p>


<h3>See Also</h3>

<p>Other getters and setters: 
<code><a href="#topic+n_tokens">n_tokens</a>()</code>,
<code><a href="#topic+n_types">n_types</a>()</code>,
<code><a href="#topic+orig_ranks">orig_ranks</a>()</code>,
<code><a href="#topic+ranks">ranks</a>()</code>,
<code><a href="#topic+tot_n_tokens">tot_n_tokens</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># for a freqlist object
(flist &lt;- freqlist("The man and the mouse.", as_text = TRUE))

type_names(flist)

# for an assoc_scores object
a &lt;- c(10,    30,    15,    1)
b &lt;- c(200, 1000,  5000,  300)
c &lt;- c(100,   14,    16,    4)
d &lt;- c(300, 5000, 10000, 6000)
types &lt;- c("four", "fictitious", "toy", "examples")

(scores &lt;- assoc_abcd(a, b, c, d, types = types))
type_names(scores)
</code></pre>

<hr>
<h2 id='types'>Build a 'types' object</h2><span id='topic+types'></span>

<h3>Description</h3>

<p>This function builds an object of the class <code><a href="#topic+types">types</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>types(
  x,
  re_drop_line = NULL,
  line_glue = NULL,
  re_cut_area = NULL,
  re_token_splitter = re("[^_\\p{L}\\p{N}\\p{M}'-]+"),
  re_token_extractor = re("[_\\p{L}\\p{N}\\p{M}'-]+"),
  re_drop_token = NULL,
  re_token_transf_in = NULL,
  token_transf_out = NULL,
  token_to_lower = TRUE,
  perl = TRUE,
  blocksize = 300,
  verbose = FALSE,
  show_dots = FALSE,
  dot_blocksize = 10,
  file_encoding = "UTF-8",
  ngram_size = NULL,
  ngram_sep = "_",
  ngram_n_open = 0,
  ngram_open = "[]",
  as_text = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="types_+3A_x">x</code></td>
<td>
<p>Either a list of filenames of the corpus files
(if <code>as_text</code> is <code>TRUE</code>) or the actual text of the corpus
(if <code>as_text</code> is <code>FALSE</code>).
</p>
<p>If <code>as_text</code> is <code>TRUE</code> and the length of the vector <code>x</code>
is higher than one, then each item in <code>x</code> is treated as a separate
line (or a separate series of lines) in the corpus text. Within each
item of <code>x</code>, the character <code>"\\n"</code> is also treated as
a line separator.</p>
</td></tr>
<tr><td><code id="types_+3A_re_drop_line">re_drop_line</code></td>
<td>
<p><code>NULL</code> or character vector. If <code>NULL</code>, it is ignored.
Otherwise, a character vector (assumed to be of length 1)
containing a regular expression. Lines in <code>x</code>
that contain a match for <code>re_drop_line</code> are
treated as not belonging to the corpus and are excluded from the results.</p>
</td></tr>
<tr><td><code id="types_+3A_line_glue">line_glue</code></td>
<td>
<p><code>NULL</code> or character vector. If <code>NULL</code>, it is ignored.
Otherwise, all lines in a corpus file (or in <code>x</code>, if
<code>as_text</code> is <code>TRUE</code>), are glued together in one
character vector of length 1, with the string <code>line_glue</code>
pasted in between consecutive lines.
The value of <code>line_glue</code> can also be equal to the empty string <code>""</code>.
The 'line glue' operation is conducted immediately after the 'drop line' operation.</p>
</td></tr>
<tr><td><code id="types_+3A_re_cut_area">re_cut_area</code></td>
<td>
<p><code>NULL</code> or character vector. If <code>NULL</code>, it is ignored.
Otherwise, all matches in a corpus file (or in <code>x</code>,
if <code>as_text</code> is <code>TRUE</code>), are 'cut out' of the text prior
to the identification of the tokens in the text (and are therefore
not taken into account when identifying the tokens).
The 'cut area' operation is conducted immediately after the 'line glue' operation.</p>
</td></tr>
<tr><td><code id="types_+3A_re_token_splitter">re_token_splitter</code></td>
<td>
<p>Regular expression or <code>NULL</code>.
Regular expression that identifies the locations where lines in the corpus
files are split into tokens. (See Details.)
</p>
<p>The 'token identification' operation is conducted immediately after the
'cut area' operation.</p>
</td></tr>
<tr><td><code id="types_+3A_re_token_extractor">re_token_extractor</code></td>
<td>
<p>Regular expression that identifies the locations of the
actual tokens. This argument is only used if <code>re_token_splitter</code> is <code>NULL</code>.
(See Details.)
</p>
<p>The 'token identification' operation is conducted immediately after the
'cut area' operation.</p>
</td></tr>
<tr><td><code id="types_+3A_re_drop_token">re_drop_token</code></td>
<td>
<p>Regular expression or <code>NULL</code>. If <code>NULL</code>, it is ignored.
Otherwise, it identifies tokens that are to
be excluded from the results. Any token that contains a match for
<code>re_drop_token</code> is removed from the results.
The 'drop token' operation is conducted immediately after the 'token identification' operation.</p>
</td></tr>
<tr><td><code id="types_+3A_re_token_transf_in">re_token_transf_in</code></td>
<td>
<p>Regular expression that identifies areas in the
tokens that are to be transformed. This argument works together with the argument
<code>token_transf_out</code>.
</p>
<p>If both <code>re_token_transf_in</code> and <code>token_transf_out</code> differ
from <code>NA</code>, then all matches, in the tokens, for the
regular expression  <code>re_token_transf_in</code> are replaced with
the replacement string <code>token_transf_out</code>.
</p>
<p>The 'token transformation' operation is conducted immediately after the
'drop token' operation.</p>
</td></tr>
<tr><td><code id="types_+3A_token_transf_out">token_transf_out</code></td>
<td>
<p>Replacement string. This argument works together with
<code>re_token_transf_in</code> and is ignored if <code>re_token_transf_in</code>
is <code>NULL</code> or <code>NA</code>.</p>
</td></tr>
<tr><td><code id="types_+3A_token_to_lower">token_to_lower</code></td>
<td>
<p>Logical. Whether tokens must be converted
to lowercase before returning the result.
The 'token to lower' operation is conducted immediately after the
'token transformation' operation.</p>
</td></tr>
<tr><td><code id="types_+3A_perl">perl</code></td>
<td>
<p>Logical. Whether the PCRE regular expression
flavor is being used in the arguments that contain regular expressions.</p>
</td></tr>
<tr><td><code id="types_+3A_blocksize">blocksize</code></td>
<td>
<p>Number that indicates how many corpus files are read to memory
<code style="white-space: pre;">&#8288;at each individual step' during the steps in the procedure; normally the default value of &#8288;</code>300' should not
be changed, but when one works with exceptionally small corpus files,
it may be worthwhile to use a higher number, and when one works with
exceptionally large corpus files, it may be worthwhile to use a lower number.</p>
</td></tr>
<tr><td><code id="types_+3A_verbose">verbose</code></td>
<td>
<p>If<code>TRUE</code>, messages are printed to the console to
indicate progress.</p>
</td></tr>
<tr><td><code id="types_+3A_show_dots">show_dots</code>, <code id="types_+3A_dot_blocksize">dot_blocksize</code></td>
<td>
<p>If <code>TRUE</code>, dots are printed to the console to
indicate progress.</p>
</td></tr>
<tr><td><code id="types_+3A_file_encoding">file_encoding</code></td>
<td>
<p>File encoding that is assumed in the corpus files.</p>
</td></tr>
<tr><td><code id="types_+3A_ngram_size">ngram_size</code></td>
<td>
<p>Argument in support of ngrams/skipgrams (see also <code>max_skip</code>).
</p>
<p>If one wants to identify individual tokens, the value of <code>ngram_size</code>
should be <code>NULL</code> or <code>1</code>. If one wants to retrieve
token ngrams/skipgrams, <code>ngram_size</code> should be an integer indicating
the size of the ngrams/skipgrams. E.g. <code>2</code> for bigrams, or <code>3</code> for
trigrams, etc.</p>
</td></tr>
<tr><td><code id="types_+3A_ngram_sep">ngram_sep</code></td>
<td>
<p>Character vector of length 1 containing the string that is used to
separate/link tokens in the representation of ngrams/skipgrams
in the output of this function.</p>
</td></tr>
<tr><td><code id="types_+3A_ngram_n_open">ngram_n_open</code></td>
<td>
<p>If <code>ngram_size</code> is <code>2</code> or higher, and moreover
<code>ngram_n_open</code> is a number higher than <code>0</code>, then
ngrams with 'open slots' in them are retrieved. These
ngrams with 'open slots' are generalizations of fully lexically specific
ngrams (with the generalization being that one or more of the items
in the ngram are replaced by a notation that stands for 'any arbitrary token').
</p>
<p>For instance, if <code>ngram_size</code> is <code>4</code> and <code>ngram_n_open</code> is
<code>1</code>, and if moreover the input contains a
4-gram <code>"it_is_widely_accepted"</code>, then the output will contain
all modifications of <code>"it_is_widely_accepted"</code> in which one (since
<code>ngram_n_open</code> is <code>1</code>) of the items in this n-gram is
replaced by an open slot. The first and the last item inside
an ngram are never turned into an open slot; only the items in between
are candidates for being turned into open slots. Therefore, in the
example, the output will contain <code>"it_[]_widely_accepted"</code> and
<code>"it_is_[]_accepted"</code>.
</p>
<p>As a second example, if <code>ngram_size</code> is <code>5</code> and
<code>ngram_n_open</code> is <code>2</code>, and if moreover the input contains a
5-gram <code>"it_is_widely_accepted_that"</code>, then the output will contain
<code>"it_[]_[]_accepted_that"</code>, <code>"it_[]_widely_[]_that"</code>, and
<code>"it_is_[]_[]_that"</code>.</p>
</td></tr>
<tr><td><code id="types_+3A_ngram_open">ngram_open</code></td>
<td>
<p>Character string used to represent open slots in ngrams in the
output of this function.</p>
</td></tr>
<tr><td><code id="types_+3A_as_text">as_text</code></td>
<td>
<p>Logical.
Whether <code>x</code> is to be interpreted as a character vector containing the
actual contents of the corpus (if <code>as_text</code> is <code>TRUE</code>)
or as a character vector containing the names of the corpus files
(if <code>as_text</code> is <code>FALSE</code>).
If if <code>as_text</code> is <code>TRUE</code>, then the arguments
<code>blocksize</code>, <code>verbose</code>, <code>show_dots</code>, <code>dot_blocksize</code>,
and <code>file_encoding</code> are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The actual token identification is either based on the <code>re_token_splitter</code>
argument, a regular expression that identifies the areas between the tokens,
or on <code>re_token_extractor</code>, a regular expression that identifies the area
that are the tokens.
The first mechanism is the default mechanism: the argument <code>re_token_extractor</code>
is only used if <code>re_token_splitter</code> is <code>NULL</code>.
Currently the implementation of
<code>re_token_extractor</code> is a lot less time-efficient than that of <code>re_token_splitter</code>.
</p>


<h3>Value</h3>

<p>An object of the class <code>types</code>, which is based on a character vector.
It has additional attributes and methods such as:
</p>

<ul>
<li><p> base <code><a href="#topic+print.types">print()</a></code>, <code><a href="#topic+as_data_frame">as_data_frame()</a></code>, <code><a href="base.html#topic+sort">sort()</a></code> and
<code><a href="base.html#topic+summary">base::summary()</a></code> (which returns the number of items and of unique items),
</p>
</li>
<li> <p><code><a href="tibble.html#topic+as_tibble">tibble::as_tibble()</a></code>,
</p>
</li>
<li><p> the <code><a href="#topic+n_types">n_types()</a></code> getter and the <code><a href="#topic+explore">explore()</a></code> method,
</p>
</li>
<li><p> subsetting methods such as <code><a href="#topic+keep_types">keep_types()</a></code>, <code><a href="#topic+keep_pos">keep_pos()</a></code>, etc. including <code style="white-space: pre;">&#8288;[]&#8288;</code>
subsetting (see <a href="#topic+brackets">brackets</a>).
</p>
</li></ul>

<p>An object of class <code>types</code> can be merged with another by means of <code><a href="#topic+types_merge">types_merge()</a></code>,
written to file with <code><a href="#topic+write_types">write_types()</a></code> and read from file with <code><a href="#topic+write_types">write_types()</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+as_types">as_types()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
It consisted of three sentences. And it lived happily ever after."
(tps &lt;- types(toy_corpus, as_text = TRUE))
print(tps)

as.data.frame(tps)
as_tibble(tps)

sort(tps)
sort(tps, decreasing = TRUE)
</code></pre>

<hr>
<h2 id='write_assoc'>Write association scores to file</h2><span id='topic+write_assoc'></span>

<h3>Description</h3>

<p>This function writes an object of class <code><a href="#topic+assoc_scores">assoc_scores</a></code> to a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_assoc(x, file = "", sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_assoc_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+assoc_scores">assoc_scores</a></code>.</p>
</td></tr>
<tr><td><code id="write_assoc_+3A_file">file</code></td>
<td>
<p>Name of the output file.</p>
</td></tr>
<tr><td><code id="write_assoc_+3A_sep">sep</code></td>
<td>
<p>Field separator for the output file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_assoc">read_assoc()</a></code>
</p>
<p>Other writing functions: 
<code><a href="#topic+write_conc">write_conc</a>()</code>,
<code><a href="#topic+write_fnames">write_fnames</a>()</code>,
<code><a href="#topic+write_freqlist">write_freqlist</a>()</code>,
<code><a href="#topic+write_tokens">write_tokens</a>()</code>,
<code><a href="#topic+write_txt">write_txt</a>()</code>,
<code><a href="#topic+write_types">write_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>txt1 &lt;- "we're just two lost souls swimming in a fish bowl,
year after year, running over the same old ground,
what have we found? the same old fears.
wish you were here."
flist1 &lt;- freqlist(txt1, as_text = TRUE)
txt2 &lt;- "picture yourself in a boat on a river
with tangerine dreams and marmelade skies
somebody calls you, you answer quite slowly
a girl with kaleidoscope eyes"
flist2 &lt;- freqlist(txt2, as_text = TRUE)
(scores &lt;- assoc_scores(flist1, flist2, min_freq = 0))

write_assoc(scores, "example_scores.tab")
(scores2 &lt;- read_assoc("example_scores.tab"))

</code></pre>

<hr>
<h2 id='write_conc'>Write a concordance to file.</h2><span id='topic+write_conc'></span>

<h3>Description</h3>

<p>This function writes an object of class <code><a href="#topic+conc">conc</a></code> to a file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_conc(x, file = "", sep = "\t")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_conc_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+conc">conc</a></code>.</p>
</td></tr>
<tr><td><code id="write_conc_+3A_file">file</code></td>
<td>
<p>Path to output file.</p>
</td></tr>
<tr><td><code id="write_conc_+3A_sep">sep</code></td>
<td>
<p>Field separator for the columns in the output file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_conc">read_conc()</a></code>
</p>
<p>Other writing functions: 
<code><a href="#topic+write_assoc">write_assoc</a>()</code>,
<code><a href="#topic+write_fnames">write_fnames</a>()</code>,
<code><a href="#topic+write_freqlist">write_freqlist</a>()</code>,
<code><a href="#topic+write_tokens">write_tokens</a>()</code>,
<code><a href="#topic+write_txt">write_txt</a>()</code>,
<code><a href="#topic+write_types">write_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(d &lt;- conc('A very small corpus.', '\\w+', as_text = TRUE))

write_conc(d, "example_data.tab")
(d2 &lt;- read_conc("example_data.tab"))

</code></pre>

<hr>
<h2 id='write_fnames'>Write a collection of filenames to a text file</h2><span id='topic+write_fnames'></span>

<h3>Description</h3>

<p>This function writes an object of class <code><a href="#topic+fnames">fnames</a></code> to a text file. Each filename
is written in a separate line. The file encoding is always <code>"UTF-8"</code>.
In addition, it can store metadata in an additional configuration file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_fnames(x, file, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_fnames_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+fnames">fnames</a></code>.</p>
</td></tr>
<tr><td><code id="write_fnames_+3A_file">file</code></td>
<td>
<p>Path to output file.</p>
</td></tr>
<tr><td><code id="write_fnames_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_fnames">read_fnames()</a></code>
</p>
<p>Other writing functions: 
<code><a href="#topic+write_assoc">write_assoc</a>()</code>,
<code><a href="#topic+write_conc">write_conc</a>()</code>,
<code><a href="#topic+write_freqlist">write_freqlist</a>()</code>,
<code><a href="#topic+write_tokens">write_tokens</a>()</code>,
<code><a href="#topic+write_txt">write_txt</a>()</code>,
<code><a href="#topic+write_types">write_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
cwd_fnames &lt;- as_fnames(c("file1.txt", "file2.txt"))
write_fnames(cwd_fnames, "file_with_filenames.txt")
cwd_fnames_2 &lt;- read_fnames("file_with_filenames.txt")

</code></pre>

<hr>
<h2 id='write_freqlist'>Write a frequency list to a csv file</h2><span id='topic+write_freqlist'></span>

<h3>Description</h3>

<p>This function writes an object of the class <code><a href="#topic+freqlist">freqlist</a></code> to a csv file. The
resulting csv file contains two columns, the first being the type and the
second being the frequency of that type. The file also contains
a header line with the names of both columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_freqlist(x, file, sep = "\t", make_config_file = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_freqlist_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+freqlist">freqlist</a></code>.</p>
</td></tr>
<tr><td><code id="write_freqlist_+3A_file">file</code></td>
<td>
<p>Character vector of length 1. Path to the output file.</p>
</td></tr>
<tr><td><code id="write_freqlist_+3A_sep">sep</code></td>
<td>
<p>Character vector of length 1. Column separator.</p>
</td></tr>
<tr><td><code id="write_freqlist_+3A_make_config_file">make_config_file</code></td>
<td>
<p>Logical. Whether or not a configuration file
needs to be created. In most circumstances, this should be set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="write_freqlist_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>write_freqlist</code> not only writes to the file <code>file</code>,
but also creates a configuration file with a name that
is identical to <code>file</code>, except that it has the filename extension
<code>".yaml"</code>. The frequency list attributes <code>"tot_n_tokens"</code>
and <code>"tot_n_types"</code> are stored to that configuration file.
</p>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_freqlist">read_freqlist()</a></code>
</p>
<p>Other writing functions: 
<code><a href="#topic+write_assoc">write_assoc</a>()</code>,
<code><a href="#topic+write_conc">write_conc</a>()</code>,
<code><a href="#topic+write_fnames">write_fnames</a>()</code>,
<code><a href="#topic+write_tokens">write_tokens</a>()</code>,
<code><a href="#topic+write_txt">write_txt</a>()</code>,
<code><a href="#topic+write_types">write_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toy_corpus &lt;- "Once upon a time there was a tiny toy corpus.
It consisted of three sentences. And it lived happily ever after."
freqs &lt;- freqlist(toy_corpus, as_text = TRUE)

print(freqs, n = 1000)

write_freqlist(freqs, "example_freqlist.csv")
freqs2 &lt;- read_freqlist("example_freqlist.csv")
print(freqs2, n = 1000)

</code></pre>

<hr>
<h2 id='write_tokens'>Write a <code>tokens</code> object to a text file</h2><span id='topic+write_tokens'></span>

<h3>Description</h3>

<p>This function writes an object of the class <code><a href="#topic+tokens">tokens</a></code> to a text file. Each
token is written to a separate line. The file encoding is always &quot;UTF-8&quot;.
This file can later be read with <code><a href="#topic+read_tokens">read_tokens()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_tokens(x, file, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_tokens_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+tokens">tokens</a></code>.</p>
</td></tr>
<tr><td><code id="write_tokens_+3A_file">file</code></td>
<td>
<p>Name of the output file.</p>
</td></tr>
<tr><td><code id="write_tokens_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_tokens">read_tokens()</a></code>
</p>
<p>Other writing functions: 
<code><a href="#topic+write_assoc">write_assoc</a>()</code>,
<code><a href="#topic+write_conc">write_conc</a>()</code>,
<code><a href="#topic+write_fnames">write_fnames</a>()</code>,
<code><a href="#topic+write_freqlist">write_freqlist</a>()</code>,
<code><a href="#topic+write_txt">write_txt</a>()</code>,
<code><a href="#topic+write_types">write_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
(tks &lt;- tokenize("The old man and the sea."))
write_tokens(tks, "file_with_tokens.txt")
(tks2 &lt;- read_tokens("file_with_tokens.txt"))

</code></pre>

<hr>
<h2 id='write_txt'>Write a character vector to a text file</h2><span id='topic+write_txt'></span>

<h3>Description</h3>

<p>This function writes a character vector to a text file. By default, each
item in the character vector becomes a line in the text file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_txt(x, file = "", line_glue = "\n")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_txt_+3A_x">x</code></td>
<td>
<p>A character vector.</p>
</td></tr>
<tr><td><code id="write_txt_+3A_file">file</code></td>
<td>
<p>Name of the output file.</p>
</td></tr>
<tr><td><code id="write_txt_+3A_line_glue">line_glue</code></td>
<td>
<p>Character string to be used as end-of-line marker on disk
or <code>NA</code> for no end-of-line marker (so that <code>x</code> becomes a single line).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_txt">read_txt()</a></code>
</p>
<p>Other writing functions: 
<code><a href="#topic+write_assoc">write_assoc</a>()</code>,
<code><a href="#topic+write_conc">write_conc</a>()</code>,
<code><a href="#topic+write_fnames">write_fnames</a>()</code>,
<code><a href="#topic+write_freqlist">write_freqlist</a>()</code>,
<code><a href="#topic+write_tokens">write_tokens</a>()</code>,
<code><a href="#topic+write_types">write_types</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
x &lt;- "This is
a small
text."

# write the text to a text file
write_txt(x, "example-text-file.txt")
# read a text from file
y &lt;- read_txt("example-text-file.txt")
y

</code></pre>

<hr>
<h2 id='write_types'>Write a vector of types to a text file</h2><span id='topic+write_types'></span>

<h3>Description</h3>

<p>This function writes an object of the class <code><a href="#topic+types">types</a></code> to a text file. Each type
is written to a separate line. The file encoding that is used is
<code>"UTF-8"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_types(x, file, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_types_+3A_x">x</code></td>
<td>
<p>Object of class <code><a href="#topic+types">types</a></code>.</p>
</td></tr>
<tr><td><code id="write_types_+3A_file">file</code></td>
<td>
<p>Name of the output file</p>
</td></tr>
<tr><td><code id="write_types_+3A_...">...</code></td>
<td>
<p>Additional arguments (not implemented).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Invisibly, <code>x</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+read_types">read_types()</a></code>
</p>
<p>Other writing functions: 
<code><a href="#topic+write_assoc">write_assoc</a>()</code>,
<code><a href="#topic+write_conc">write_conc</a>()</code>,
<code><a href="#topic+write_fnames">write_fnames</a>()</code>,
<code><a href="#topic+write_freqlist">write_freqlist</a>()</code>,
<code><a href="#topic+write_tokens">write_tokens</a>()</code>,
<code><a href="#topic+write_txt">write_txt</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
types &lt;- as_types(c("first", "second", "third"))
write_types(types, "file_with_types.txt")
types_2 &lt;- read_types("file_with_types.txt")

</code></pre>

<hr>
<h2 id='zero_plus'>Make all values strictly higher than zero</h2><span id='topic+zero_plus'></span>

<h3>Description</h3>

<p>This is an auxiliary function that makes all values in numeric vector x strictly
positive by replacing all values equal to or lower than zero with
the values in <code>small.pos</code>. <code>small_pos</code> stands for 'small positive constant'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zero_plus(x, small_pos = 1e-05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zero_plus_+3A_x">x</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="zero_plus_+3A_small_pos">small_pos</code></td>
<td>
<p>A (small) positive number to replace negative values and 0s.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A copy of <code>x</code> in which all values equal to or lower than zero are
replaced by <code>small_pos</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(x &lt;- rnorm(30))
zero_plus(x)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
