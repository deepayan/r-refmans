<!DOCTYPE html><html><head><title>Help for package irtQ</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {irtQ}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#irtQ-package'><p>irtQ: Unidimensional Item Response Theory Modeling</p></a></li>
<li><a href='#bind.fill'><p>Bind Fill</p></a></li>
<li><a href='#bisection'><p>The bisection method to find a root</p></a></li>
<li><a href='#bring.flexmirt'><p>Import Item and Ability Parameters from IRT Software</p></a></li>
<li><a href='#cac_lee'><p>Classification accuracy and consistency using Lee's (2010) approach.</p></a></li>
<li><a href='#cac_rud'><p>Classification accuracy and consistency using Rudner's (2001, 2005) approach.</p></a></li>
<li><a href='#catsib'><p>CATSIB DIF detection procedure</p></a></li>
<li><a href='#covirt'><p>Asymptotic variance-covariance matrices of item parameter estimates</p></a></li>
<li><a href='#drm'><p>Dichotomous Response Model (DRM) Probabilities</p></a></li>
<li><a href='#est_irt'><p>Item parameter estimation using MMLE-EM algorithm</p></a></li>
<li><a href='#est_item'><p>Fixed ability parameter calibration</p></a></li>
<li><a href='#est_mg'><p>Multiple-group item calibration using MMLE-EM algorithm</p></a></li>
<li><a href='#est_score'><p>Estimate examinees' ability (proficiency) parameters</p></a></li>
<li><a href='#gen.weight'><p>Generate Weights</p></a></li>
<li><a href='#getirt'><p>Extract various elements from 'est_irt', 'est_mg', and 'est_item' objects</p></a></li>
<li><a href='#grdif'><p>Generalized IRT residual-based DIF detection framework for multiple groups (GRDIF)</p></a></li>
<li><a href='#info'><p>Item and Test Information Function</p></a></li>
<li><a href='#irtfit'><p>Traditional IRT item fit statistics</p></a></li>
<li><a href='#llike_score'><p>Loglikelihood of Ability Parameters</p></a></li>
<li><a href='#LSAT6'><p>LSAT6 data</p></a></li>
<li><a href='#lwrc'><p>Lord-Wingersky Recursion Formula</p></a></li>
<li><a href='#plot.info'><p>Plot Item and Test Information Functions</p></a></li>
<li><a href='#plot.irtfit'><p>Draw raw and standardized residual plots</p></a></li>
<li><a href='#plot.traceline'><p>Plot ICC and TCC</p></a></li>
<li><a href='#prm'><p>Polytomous Response Model (PRM) Probabilities (GRM and GPCM)</p></a></li>
<li><a href='#rdif'><p>IRT residual-based differential item functioning (RDIF) detection framework</p></a></li>
<li><a href='#run_flexmirt'><p>Run flexMIRT through R</p></a></li>
<li><a href='#shape_df'><p>Create a data frame of item metadata</p></a></li>
<li><a href='#simCAT_DC'><p>Simulated single-item format CAT Data</p></a></li>
<li><a href='#simCAT_MX'><p>Simulated mixed-item format CAT Data</p></a></li>
<li><a href='#simdat'><p>Simulated Response Data</p></a></li>
<li><a href='#simMG'><p>Simulated multiple-group data</p></a></li>
<li><a href='#summary'><p>Summary of item calibration</p></a></li>
<li><a href='#sx2_fit'><p>S-X2 fit statistic</p></a></li>
<li><a href='#traceline'><p>Compute Item/Test Characteristic Functions</p></a></li>
<li><a href='#write.flexmirt'><p>Write a &quot;-prm.txt&quot; file for flexMIRT</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Unidimensional Item Response Theory Modeling</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Fit unidimensional item response theory (IRT) models to a mixture 
    of dichotomous and polytomous data, calibrate online item parameters 
    (i.e., pretest and operational items), estimate examinees' abilities, 
    and examine the IRT model-data fit on item-level in different ways 
    as well as provide useful functions related to IRT analyses such as 
    IRT model-data fit evaluation and differential item functioning analysis.
    The bring.flexmirt() and write.flexmirt() functions were written by modifying 
    the read.flexmirt() function (Pritikin &amp; Falk (2022) &lt;<a href="https://doi.org/10.1177%2F0146621620929431">doi:10.1177/0146621620929431</a>&gt;).
    The bring.bilog() and bring.parscale() functions were written by modifying the read.bilog() 
    and read.parscale() functions, respectively (Weeks (2010) &lt;<a href="https://doi.org/10.18637%2Fjss.v035.i12">doi:10.18637/jss.v035.i12</a>&gt;).
    The bisection() function was written by modifying the bisection() function 
    (Howard (2017, ISBN:9780367657918)). The code of the inverse test characteristic curve 
    scoring in the est_score() function was written by modifying the irt.eq.tse() function 
    (González (2014) &lt;<a href="https://doi.org/10.18637%2Fjss.v059.i07">doi:10.18637/jss.v059.i07</a>&gt;). In est_score() function, the code of weighted 
    likelihood estimation method was written by referring to the Pi(), Ji(), and Ii() functions
    of the catR package (Magis &amp; Barrada (2017) &lt;<a href="https://doi.org/10.18637%2Fjss.v076.c01">doi:10.18637/jss.v076.c01</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.2)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, statmod, utils, tibble, dplyr, purrr, rlang, reshape2,
janitor, ggplot2, gridExtra, parallel, Matrix, Rfast, mirt</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-06 01:31:12 UTC; hlim</td>
</tr>
<tr>
<td>Author:</td>
<td>Hwanggyu Lim [aut, cre],
  Craig S. Wells [ctb],
  James Howard [ctb],
  Joshua Pritikin [ctb],
  Jonathan P Weeks [ctb],
  Jorge González [ctb],
  David Magis [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hwanggyu Lim &lt;hglim83@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-06 12:20:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='irtQ-package'>irtQ: Unidimensional Item Response Theory Modeling</h2><span id='topic+irtQ-package'></span>

<h3>Description</h3>

<p>Fit unidimensional item response theory (IRT) models to a mixture of dichotomous and polytomous data,
calibrate online item parameters (i.e., pretest and operational items), estimate examinees' abilities,
and  provide useful functions related to unidimensional IRT such as IRT model-data fit evaluation and
differential item functioning analysis.
</p>
<p>For the item parameter estimation, the marginal maximum likelihood estimation via the expectation-maximization (MMLE-EM) algorithm
(Bock &amp; Aitkin, 1981) is used. Also, the fixed item parameter calibration (FIPC) method (Kim, 2006) and
the fixed ability parameter calibration (FAPC) method, (Ban, Hanson, Wang, Yi, &amp; Harris, 2001; stocking, 1988),
often called Stocking's Method A, are provided. For the ability estimation, several popular scoring methods (e.g., ML, EAP, and MAP)
are implemented.
</p>
<p>In addition, there are many useful functions related to IRT analyses such as evaluating IRT model-data fit,
analyzing differential item functioning (DIF), importing item and/or ability parameters from popular IRT software,
running flexMIRT (Cai, 2017) through R, generating simulated data, computing the conditional distribution of observed scores
using the Lord-Wingersky recursion formula, computing item and test information functions, computing item and test characteristic
curve functions, and plotting item and test characteristic curves and item and test information functions.
</p>

<table>
<tr>
 <td style="text-align: left;"> Package: </td><td style="text-align: left;"> irtQ</td>
</tr>
<tr>
 <td style="text-align: left;"> Version: </td><td style="text-align: left;"> 0.2.0</td>
</tr>
<tr>
 <td style="text-align: left;"> Date: </td><td style="text-align: left;">
2023-07-05</td>
</tr>
<tr>
 <td style="text-align: left;"> Depends: </td><td style="text-align: left;"> R (&gt;= 4.1)</td>
</tr>
<tr>
 <td style="text-align: left;"> License: </td><td style="text-align: left;"> GPL (&gt;= 2)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Details</h3>

<p>Following five sections describe a) how to implement the online item calibration using FIPC, a) how to implement the online item
calibration using Method A, b) two illustrations of the online calibration, and c) IRT Models used in <span class="pkg">irtQ</span> package.
</p>


<h3>Online item calibration with the fixed item parameter calibration method (e.g., Kim, 2006)</h3>

<p>The fixed item parameter calibration (FIPC) is one of useful online item calibration methods for computerized adaptive testing (CAT)
to put the parameter estimates of pretest items on the same scale of operational item parameter estimates without post hoc
linking/scaling (Ban, Hanson, Wang, Yi, &amp; Harris, 2001; Chen &amp; Wang, 2016). In FIPC, the operational item parameters are fixed to
estimate the characteristic of the underlying latent variable prior distribution when calibrating the pretest items. More specifically,
the underlying latent variable prior distribution of the operational items is estimated during the calibration of the pretest
items to put the item parameters of the pretest items on the scale of the operational item parameters (Kim, 2006). In the <span class="pkg">irtQ</span>
package, FIPC is implemented with two main steps:
</p>

<ol>
<li><p> Prepare a response data set and the item metadata of the fixed (or operational) items.
</p>
</li>
<li><p> Implement FIPC to estimate the item parameters of pretest items using the <code><a href="#topic+est_irt">est_irt</a></code> function.
</p>
</li></ol>


<dl>
<dt>1. Preparing a data set</dt><dd>
<p>To run the <code><a href="#topic+est_irt">est_irt</a></code> function, it requires two data sets:
</p>

<ol>
<li><p> Item metadata set (i.e., model, score category, and item parameters. see the desciption of the argument <code>x</code> in the function <code><a href="#topic+est_irt">est_irt</a></code>).
</p>
</li>
<li><p> Examinees' response data set for the items. It should be a matrix format where a row and column indicate the examinees and the items, respectively.
The order of the columns in the response data set must be exactly the same as the order of rows of the item metadata.
</p>
</li></ol>

</dd>
<dt>2. Estimating the pretest item parameters</dt><dd>
<p>When FIPC is implemented in <code><a href="#topic+est_irt">est_irt</a></code> function, the pretest item parameters are estimated by fixing the operational item parameters. To estimate the item
parameters, you need to provide the item metadata in the argument <code>x</code> and the response data in the argument <code>data</code>.
</p>
<p>It is worthwhile to explain about how to prepare the item metadata set in the argument <code>x</code>. A specific form of a data frame should be used for
the argument <code>x</code>. The first column should have item IDs, the second column should contain the number of score categories of the items, and the third
column should include IRT models. The available IRT models are &quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for dichotomous items, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous
items. Note that &quot;DRM&quot; covers all dichotomous IRT models (i.e, &quot;1PLM&quot;, &quot;2PLM&quot;, and &quot;3PLM&quot;) and &quot;GRM&quot; and &quot;GPCM&quot; represent the graded response model and
(generalized) partial credit model, respectively. From the fourth column, item parameters should be included. For dichotomous items, the fourth, fifth,
and sixth columns represent the item discrimination (or slope), item difficulty, and item guessing parameters, respectively. When &quot;1PLM&quot; or &quot;2PLM&quot; is
specified for any items in the third column, NAs should be inserted for the item guessing parameters. For polytomous items, the item discrimination (or slope)
parameters should be contained in the fourth column and the item threshold (or step) parameters should be included from the fifth to the last columns.
When the number of categories differs between items, the empty cells of item parameters should be filled with NAs. See 'est_irt' for more details about
the item metadata.
</p>
<p>Also, you should specify in the argument <code>fipc = TRUE</code> and a specific FIPC method in the argument <code>fipc.method</code>. Finally, you should provide
a vector of the location of the items to be fixed in the argument <code>fix.loc</code>. For more details about implementing FIPC, see the
description of the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
<p>When implementing FIPC, you can estimate both the emprical histogram and the scale of latent variable prior distribution by setting <code>EmpHist = TRUE</code>.
If <code>EmpHist = FALSE</code>, the normal prior distribution is used during the item parameter estimation and the scale of the normal prior distribution is
updated during the EM cycle.
</p>
<p>The <code><a href="#topic+est_item">est_item</a></code> function requires a vector of the number of score categories for the items in the argument <code>cats</code>. For example, a dichotomous item has
two score categories. If a single numeric value is specified, that value will be recycled across all items. If NULL and all items are binary items
(i.e., dichotomous items), it assumes that all items have two score categories.
</p>
<p>If necessary, you need to specify whether prior distributions of item slope and guessing parameters (only for the IRT 3PL model) are used in the arguments of
<code>use.aprior</code> and <code>use.gprior</code>, respectively. If you decide to use the prior distributions, you should specify what distributions will be used for the prior
distributions in the arguments of <code>aprior</code> and <code>gprior</code>, respectively. Currently three probability distributions of Beta, Log-normal, and Normal
distributions are available.
</p>
<p>In addition, if the response data include missing values, you must indicate the missing value in argument <code>missing</code>.
</p>
<p>Once the <code><a href="#topic+est_irt">est_irt</a></code> function has been implemented, you'll get a list of several internal objects such as the item parameter estimates,
standard error of the parameter estimates.
</p>
</dd>
</dl>



<h3>Online item calibration with the fixed ability parameter calibration method (e.g., Stocking, 1988)</h3>

<p>In CAT, the fixed ability parameter calibration (FAPC), often called Stocking's Method A, is the relatively simplest
and most straightforward online calibration method, which is the maximum likelihood estimation of the item parameters
given the proficiency estimates. In CAT, FAPC can be used to put the parameter estimates of pretest items on
the same scale of operational item parameter estimates and recalibrate the operational items to evaluate the parameter
drifts of the operational items (Chen &amp; Wang, 2016; Stocking, 1988). Also, FAPC is known to result in accurate, unbiased
item parameters calibration when items are randomly rather than adaptively administered to examinees, which occurs most
commonly with pretest items (Ban, Hanson, Wang, Yi, &amp; Harris, 2001; Chen &amp; Wang, 2016). Using <span class="pkg">irtQ</span> package,
the FAPC is implemented to calibrate the items with two main steps:
</p>

<ol>
<li><p> Prepare a data set for the calibration of item parameters (i.e., item response data and ability estimates).
</p>
</li>
<li><p> Implement the FAPC to estimate the item parameters using the <code><a href="#topic+est_item">est_item</a></code> function.
</p>
</li></ol>


<dl>
<dt>1. Preparing a data set</dt><dd>
<p>To run the <code><a href="#topic+est_item">est_item</a></code> function, it requires two data sets:
</p>

<ol>
<li><p> Examinees' ability (or proficiency) estimates. It should be in the format of a numeric vector.
</p>
</li>
<li><p> response data set for the items. It should be in the format of matrix where a row and column indicate
the examinees and the items, respectively. The order of the examinees in the response data set must be exactly the same as that of the examinees' ability estimates.
</p>
</li></ol>

</dd>
<dt>2. Estimating the pretest item parameters</dt><dd>
<p>The <code><a href="#topic+est_item">est_item</a></code> function estimates the pretest item parameters given the proficiency estimates. To estimate the item parameters,
you need to provide the response data in the argument <code>data</code> and the ability estimates in the argument <code>score</code>.
</p>
<p>Also, you should provide a string vector of the IRT models in the argument <code>model</code> to indicate what IRT model is used to calibrate each item.
Available IRT models are &quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for dichotomous items, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous items. &quot;GRM&quot; and &quot;GPCM&quot; represent
the graded response model and (generalized) partial credit model, respectively. Note that &quot;DRM&quot; is considered as &quot;3PLM&quot; in this function. If a single
character of the IRT model is specified, that model will be recycled across all items.
</p>
<p>The <code><a href="#topic+est_item">est_item</a></code> function requires a vector of the number of score categories for the items in the argument <code>cats</code>. For example, a dichotomous item has
two score categories. If a single numeric value is specified, that value will be recycled across all items. If NULL and all items are binary items
(i.e., dichotomous items), it assumes that all items have two score categories.
</p>
<p>If necessary, you need to specify whether prior distributions of item slope and guessing parameters (only for the IRT 3PL model) are used in the arguments of
<code>use.aprior</code> and <code>use.gprior</code>, respectively. If you decide to use the prior distributions, you should specify what distributions will be used for the prior
distributions in the arguments of <code>aprior</code> and <code>gprior</code>, respectively. Currently three probability distributions of Beta, Log-normal, and Normal
distributions are available.
</p>
<p>In addition, if the response data include missing values, you must indicate the missing value in argument <code>missing</code>.
</p>
<p>Once the <code><a href="#topic+est_item">est_item</a></code> function has been implemented, you'll get a list of several internal objects such as the item parameter estimates,
standard error of the parameter estimates.
</p>
</dd>
</dl>



<h3>Three examples of R script</h3>

<p>The example code below shows how to implement the online calibration and how to evaluate the IRT model-data fit:</p>
<pre>
##---------------------------------------------------------------
# Attach the packages
library(irtQ)

##----------------------------------------------------------------------------
# 1. The example code below shows how to prepare the data sets and how to
#    implement the fixed item parameter calibration (FIPC):
##----------------------------------------------------------------------------

## Step 1: prepare a data set
## In this example, we generated examinees' true proficiency parameters and simulated
## the item response data using the function "simdat".

## import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select the item metadata
x &lt;- bring.flexmirt(file=flex_sam, "par")$Group1$full_df

# generate 1,000 examinees' latent abilities from N(0.4, 1.3)
set.seed(20)
score &lt;- rnorm(1000, mean=0.4, sd=1.3)

# simulate the response data
sim.dat &lt;- simdat(x=x, theta=score, D=1)

## Step 2: Estimate the item parameters
# fit the 3PL model to all dichotmous items, fit the GRM model to all polytomous data,
# fix the five 3PL items (1st - 5th items) and three GRM items (53th to 55th items)
# also, estimate the empirical histogram of latent variable
fix.loc &lt;- c(1:5, 53:55)
(mod.fix1 &lt;- est_irt(x=x, data=sim.dat, D=1, use.gprior=TRUE,
                    gprior=list(dist="beta", params=c(5, 16)), EmpHist=TRUE, Etol=1e-3,
                    fipc=TRUE, fipc.method="MEM", fix.loc=fix.loc))
summary(mod.fix1)

# plot the estimated empirical histogram of latent variable prior distribution
(emphist &lt;- getirt(mod.fix1, what="weights"))
plot(emphist$weight ~ emphist$theta, xlab="Theta", ylab="Density")


##----------------------------------------------------------------------------
# 2. The example code below shows how to prepare the data sets and how to estimate
#    the item parameters using the fixed abilit parameter calibration (FAPC):
##----------------------------------------------------------------------------

## Step 1: prepare a data set
## In this example, we generated examinees' true proficiency parameters and simulated
## the item response data using the function "simdat". Because, the true
## proficiency parameters are not known in reality, however, the true proficiencies
## would be replaced with the proficiency estimates for the calibration.

# import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select the item metadata
x &lt;- bring.flexmirt(file=flex_sam, "par")$Group1$full_df

# modify the item metadata so that some items follow 1PLM, 2PLM and GPCM
x[c(1:3, 5), 3] &lt;- "1PLM"
x[c(1:3, 5), 4] &lt;- 1
x[c(1:3, 5), 6] &lt;- 0
x[c(4, 8:12), 3] &lt;- "2PLM"
x[c(4, 8:12), 6] &lt;- 0
x[54:55, 3] &lt;- "GPCM"

# generate examinees' abilities from N(0, 1)
set.seed(23)
score &lt;- rnorm(500, mean=0, sd=1)

# simulate the response data
data &lt;- simdat(x=x, theta=score, D=1)

## Step 2: Estimate the item parameters
# 1) item parameter estimation: constrain the slope parameters of the 1PLM to be equal
(mod1 &lt;- est_item(x, data, score, D=1, fix.a.1pl=FALSE, use.gprior=TRUE,
                 gprior=list(dist="beta", params=c(5, 17)), use.startval=FALSE))
summary(mod1)

# 2) item parameter estimation: fix the slope parameters of the 1PLM to 1
(mod2 &lt;- est_item(x, data, score, D=1, fix.a.1pl=TRUE, a.val.1pl=1, use.gprior=TRUE,
                 gprior=list(dist="beta", params=c(5, 17)), use.startval=FALSE))
summary(mod2)

# 3) item parameter estimation: fix the guessing parameters of the 3PLM to 0.2
(mod3 &lt;- est_item(x, data, score, D=1, fix.a.1pl=TRUE, fix.g=TRUE, a.val.1pl=1, g.val=.2,
                 use.startval=FALSE))
summary(mod3)


</pre>


<h3>IRT Models</h3>

<p>In the <span class="pkg">irtQ</span> package, both dichotomous and polytomous IRT models are available.
For dichotomous items, IRT one-, two-, and three-parameter logistic models (1PLM, 2PLM, and 3PLM) are used.
For polytomous items, the graded response model (GRM) and the (generalized) partial credit model (GPCM) are used.
Note that the item discrimination (or slope) parameters should be fixed to 1 when the partial credit model is fit to data.
</p>
<p>In the following, let <code class="reqn">Y</code> be the response of an examinee with latent ability <code class="reqn">\theta</code> on an item and suppose that there
are <code class="reqn">K</code> unique score categories for each polytomous item.
</p>

<dl>
<dt>IRT 1-3PL models</dt><dd>
<p>For the IRT 1-3PL models, the probability that an examinee with <code class="reqn">\theta</code> provides a correct answer for an item is given by,
</p>
<p style="text-align: center;"><code class="reqn">P(Y = 1|\theta) = g + \frac{(1 - g)}{1 + exp(-Da(\theta - b))},</code>
</p>

<p>where <code class="reqn">a</code> is the item discrimination (or slope) parameter, <code class="reqn">b</code> represents the item difficulty parameter,
<code class="reqn">g</code> refers to the item guessing parameter. <code class="reqn">D</code> is a scaling factor in IRT models to make the logistic function
as close as possible to the normal ogive function when <code class="reqn">D = 1.702</code>. When the 1PLM is used, <code class="reqn">a</code> is either fixed to a constant
value (e.g., <code class="reqn">a=1</code>) or constrained to have the same value across all 1PLM item data. When the IRT 1PLM or 2PLM is fit to data,
<code class="reqn">g = 0</code> is set to 0.
</p>
</dd>
<dt>GRM</dt><dd>
<p>For the GRM, the probability that an examinee with latent ability <code class="reqn">\theta</code> responds to score category <code class="reqn">k</code> (<code class="reqn">k=0,1,...,K-1</code>)
of an item is a given by,
</p>
<p style="text-align: center;"><code class="reqn">P(Y = k | \theta) = P^{*}(Y \ge k | \theta) - P^{*}(Y \ge k + 1 | \theta),</code>
</p>

<p style="text-align: center;"><code class="reqn">P^{*}(Y \ge k | \theta) = \frac{1}{1 + exp(-Da(\theta - b_{k}))}, and</code>
</p>

<p style="text-align: center;"><code class="reqn">P^{*}(Y \ge k + 1 | \theta) = \frac{1}{1 + exp(-Da(\theta - b_{k+1}))}, </code>
</p>

<p>where <code class="reqn">P^{*}(Y \ge k | \theta</code> refers to the category boundary (threshold) function for score category <code class="reqn">k</code> of an item
and its formula is analogous to that of 2PLM. <code class="reqn">b_{k}</code> is the difficulty (or threshold) parameter for category boundary
<code class="reqn">k</code> of an item. Note that <code class="reqn">P(Y = 0 | \theta) = 1 - P^{*}(Y \ge 1 | \theta)</code>
and <code class="reqn">P(Y = K-1 | \theta) = P^{*}(Y \ge K-1 | \theta)</code>.
</p>
</dd>
<dt>GPCM</dt><dd>
<p>For the GPCM, the probability that an examinee with latent ability <code class="reqn">\theta</code> responds to score category <code class="reqn">k</code> (<code class="reqn">k=0,1,...,K-1</code>)
of an item is a given by,
</p>
<p style="text-align: center;"><code class="reqn">P(Y = k | \theta) = \frac{exp(\sum_{v=0}^{k}{Da(\theta - b_{v})})}{\sum_{h=0}^{K-1}{exp(\sum_{v=0}^{h}{Da(\theta - b_{v})})}},</code>
</p>

<p>where <code class="reqn">b_{v}</code> is the difficulty parameter for category boundary <code class="reqn">v</code> of an item. In other contexts, the difficulty parameter <code class="reqn">b_{v}</code>
can also be parameterized as <code class="reqn">b_{v} = \beta - \tau_{v}</code>, where <code class="reqn">\beta</code> refers to the location (or overall difficulty) parameter
and <code class="reqn">\tau_{jv}</code> represents a threshold parameter for score category <code class="reqn">v</code> of an item. In the <span class="pkg">irtQ</span> package, <code class="reqn">K-1</code> difficulty
parameters are necessary when an item has <code class="reqn">K</code> unique score categories because <code class="reqn">b_{0}=0</code>. When a partial credit model is fit to data, <code class="reqn">a</code>
is fixed to 1.
</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Ames, A. J., &amp; Penfield, R. D. (2015). An NCME Instructional Module on Item-Fit Statistics for Item Response Theory Models.
<em>Educational Measurement: Issues and Practice, 34</em>(3), 39-48.
</p>
<p>Baker, F. B., &amp; Kim, S. H. (2004). <em>Item response theory: Parameter estimation techniques.</em> CRC Press.
</p>
<p>Ban, J. C., Hanson, B. A., Wang, T., Yi, Q., &amp; Harris, D., J. (2001) A comparative study of on-line pretest item calibration/scaling methods
in computerized adaptive testing. <em>Journal of Educational Measurement, 38</em>(3), 191-212.
</p>
<p>Birnbaum, A. (1968). Some latent trait models and their use in inferring an examinee's ability. In F. M. Lord &amp; M. R. Novick (Eds.),
<em>Statistical theories of mental test scores</em> (pp. 397-479). Reading, MA: Addison-Wesley.
</p>
<p>Bock, R.D. (1960), <em>Methods and applications of optimal scaling</em>. Chapel Hill, NC: L.L. Thurstone Psychometric Laboratory.
</p>
<p>Bock, R. D., &amp; Aitkin, M. (1981). Marginal maximum likelihood estimation of item parameters: Application of an EM algorithm.
<em>Psychometrika, 46</em>, 443-459.
</p>
<p>Bock, R. D., &amp; Mislevy, R. J. (1982). Adaptive EAP estimation of ability in a microcomputer environment. <em>Psychometrika, 35</em>, 179-198.
</p>
<p>Cai, L. (2017). flexMIRT 3.5 Flexible multilevel multidimensional item analysis and test scoring [Computer software].
Chapel Hill, NC: Vector Psychometric Group.
</p>
<p>Chalmers, R. P. (2012). mirt: A multidimensional item response theory package for the R environment.
<em>Journal of Statistical Software, 48</em>(6), 1-29.
</p>
<p>Chen, P., &amp; Wang, C. (2016). A new online calibration method for multidimensional computerized adaptive testing.
<em>Psychometrika, 81</em>(3), 674-701.
</p>
<p>González, J. (2014). SNSequate: Standard and nonstandard statistical models and methods for test equating.
<em>Journal of Statistical Software, 59</em>, 1-30.
</p>
<p>Hambleton, R. K., &amp; Swaminathan, H. (1985) <em>Item response theory: Principles and applications</em>.
Boston, MA: Kluwer.
</p>
<p>Hambleton, R. K., Swaminathan, H., &amp; Rogers, H. J. (1991) <em>Fundamentals of item response theory</em>.
Newbury Park, CA: Sage.
</p>
<p>Han, K. T. (2016). Maximum likelihood score estimation method with fences for short-length tests and computerized adaptive tests.
<em>Applied psychological measurement, 40</em>(4), 289-301.
</p>
<p>Howard, J. P. (2017). <em>Computational methods for numerical analysis with R</em>. New York:
Chapman and Hall/CRC.
</p>
<p>Kang, T., &amp; Chen, T. T. (2008). Performance of the generalized S-X2 item fit index for polytomous IRT models.
<em>Journal of Educational Measurement, 45</em>(4), 391-406.
</p>
<p>Kim, S. (2006). A comparative study of IRT fixed parameter calibration methods.
<em>Journal of Educational Measurement, 43</em>(4), 355-381.
</p>
<p>Kolen, M. J. &amp; Brennan, R. L. (2004) <em>Test Equating, Scaling, and Linking</em> (2nd ed.). New York:
Springer.
</p>
<p>Kolen, M. J. &amp; Tong, Y. (2010). Psychometric properties of IRT proficiency estimates.
<em>Educational Measurement: Issues and Practice, 29</em>(3), 8-14.
</p>
<p>Laplace, P. S. (1820).<em>Theorie analytique des probabilites</em> (in French). Courcier.
</p>
<p>Li, Y. &amp; Lissitz, R. (2004). Applications of the analytically derived asymptotic standard errors of item response theory
item parameter estimates. <em>Journal of educational measurement, 41</em>(2), 85-117.
</p>
<p>Lim, H., &amp; Choe, E. M. (2023). Detecting differential item functioning in CAT using IRT residual DIF approach.
<em>Journal of Educational Measurement</em>. <a href="https://doi.org/10.1111/jedm.12366">doi:10.1111/jedm.12366</a>.
</p>
<p>Lim, H., Choe, E. M., &amp; Han, K. T. (2022). A residual-based differential item functioning detection framework in
item response theory. <em>Journal of Educational Measurement, 59</em>(1), 80-104. <a href="https://doi.org/10.1111/jedm.12313">doi:10.1111/jedm.12313</a>.
</p>
<p>Lim, H., Zhu, D., Choe, E. M., &amp; Han, K. T. (2023, April). <em>Detecting differential item functioning among multiple groups
using IRT residual DIF framework</em>. Paper presented at the Annual Meeting of the National Council on Measurement
in Education. Chicago, IL.
</p>
<p>Lim, H., Davey, T., &amp; Wells, C. S. (2020). A recursion-based analytical approach to evaluate the performance of MST.
<em>Journal of Educational Measurement</em>. DOI: 10.1111/jedm.12276.
</p>
<p>Lord, F. &amp; Wingersky, M. (1984). Comparison of IRT true score and equipercentile observed score equatings.
<em>Applied Psychological Measurement, 8</em>(4), 453-461.
</p>
<p>Magis, D., &amp; Barrada, J. R. (2017). Computerized adaptive testing with R: Recent updates of the package catR.
<em>Journal of Statistical Software, 76</em>, 1-19.
</p>
<p>McKinley, R., &amp; Mills, C. (1985). A comparison of several goodness-of-fit statistics.
<em>Applied Psychological Measurement, 9</em>, 49-57.
</p>
<p>Meilijson, I. (1989). A fast improvement to the EM algorithm on its own terms.
<em>Journal of the Royal Statistical Society: Series B (Methodological), 51</em>, 127-138.
</p>
<p>Muraki, E. &amp; Bock, R. D. (2003). PARSCALE 4: IRT item analysis and test scoring for rating
scale data [Computer Program]. Chicago, IL: Scientific Software International. URL http://www.ssicentral.com
</p>
<p>Newcombe, R. G. (1998). Two-sided confidence intervals for the single proportion: comparison of seven methods.
<em>Statistics in medicine, 17</em>(8), 857-872.
</p>
<p>Orlando, M., &amp; Thissen, D. (2000). Likelihood-based item-fit indices for dichotomous item response theory models.
<em>Applied Psychological Measurement, 24</em>(1), 50-64.
</p>
<p>Orlando, M., &amp; Thissen, D. (2003). Further investigation of the performance of S-X2: An item fit index for use with
dichotomous item response theory models. <em>Applied Psychological Measurement, 27</em>(4), 289-298.
</p>
<p>Pritikin, J. (2018). <em>rpf: Response Probability Functions</em>. R package version 0.59.
https://CRAN.R-project.org/package=rpf.
</p>
<p>Pritikin, J. N., &amp; Falk, C. F. (2020). OpenMx: A modular research environment for item response theory method development.
Applied Psychological Measurement, 44(7-8), 561-562.
</p>
<p>Stocking, M. L. (1996). An alternative method for scoring adaptive tests.
<em>Journal of Educational and Behavioral Statistics, 21</em>(4), 365-389.
</p>
<p>Stocking, M. L. (1988). <em>Scale drift in on-line calibration</em> (Research Rep. 88-28). Princeton, NJ: ETS.
</p>
<p>Thissen, D. (1982). Marginal maximum likelihood estimation for the one-parameter logistic model.
<em>Psychometrika, 47</em>, 175-186.
</p>
<p>Thissen, D. &amp; Wainer, H. (1982). Weighted likelihood estimation of ability in item response theory.
<em>Psychometrika, 54</em>(3), 427-450.
</p>
<p>Thissen, D., Pommerich, M., Billeaud, K., &amp; Williams, V. S. (1995). Item Response Theory
for Scores on Tests Including Polytomous Items with Ordered Responses. <em>Applied Psychological
Measurement, 19</em>(1), 39-49.
</p>
<p>Thissen, D. &amp; Orlando, M. (2001). Item response theory for items scored in two categories. In D. Thissen &amp; H. Wainer (Eds.),
<em>Test scoring</em> (pp.73-140). Mahwah, NJ: Lawrence Erlbaum.
</p>
<p>Wainer, H., &amp; Mislevy, R. J. (1990). Item response theory, item calibration, and proficiency estimation. In H. Wainer (Ed.),
<em>Computer adaptive testing: A primer</em> (Chap. 4, pp.65-102). Hillsdale, NJ: Lawrence Erlbaum.
</p>
<p>Warm, T. A. (1989). Weighted likelihood estimation of ability in item response theory. <em>Psychometrika, 54</em>(3),
427-450.
</p>
<p>Weeks, J. P. (2010). plink: An R Package for Linking Mixed-Format Tests Using IRT-Based Methods.
<em>Journal of Statistical Software, 35</em>(12), 1-33. URL http://www.jstatsoft.org/v35/i12/.
</p>
<p>Wells, C. S., &amp; Bolt, D. M. (2008). Investigation of a nonparametric procedure for assessing goodness-of-fit in
item response theory. <em>Applied Measurement in Education, 21</em>(1), 22-40.
</p>
<p>Wilson, E. B. (1927). Probable inference, the law of succession, and statistical inference.
<em>Journal of the American Statistical Association, 22</em>(158), 209-212.
</p>
<p>Woods, C. M. (2007). Empirical histograms in item response theory with ordinal data. <em>Educational and Psychological Measurement, 67</em>(1), 73-87.
</p>
<p>Yen, W. M. (1981). Using simulation results to choose a latent trait model. <em>Applied Psychological Measurement, 5</em>, 245-262.
</p>
<p>Zimowski, M. F., Muraki, E., Mislevy, R. J., &amp; Bock, R. D. (2003). BILOG-MG 3: Multiple-group
IRT analysis and test maintenance for binary items [Computer Program]. Chicago, IL: Scientific
Software International. URL http://www.ssicentral.com
</p>

<hr>
<h2 id='bind.fill'>Bind Fill</h2><span id='topic+bind.fill'></span>

<h3>Description</h3>

<p>This function creates a cbind matrix or rbind matrix using a list containing different length
of numeric vectors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bind.fill(List, type = c("rbind", "cbind"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bind.fill_+3A_list">List</code></td>
<td>
<p>A list containing different length of numeric vectors</p>
</td></tr>
<tr><td><code id="bind.fill_+3A_type">type</code></td>
<td>
<p>A character string specifying whether rbind is used or cbind is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># sample list
score_list &lt;- list(item1=c(0:3), item2=c(0:2), item3=c(0:5), item3=c(0:4))

# examples
# 1) create a rbind with the sample score list
bind.fill(score_list, type="rbind")

# 2) create a cbind with the sample score list
bind.fill(score_list, type="cbind")

</code></pre>

<hr>
<h2 id='bisection'>The bisection method to find a root</h2><span id='topic+bisection'></span>

<h3>Description</h3>

<p>This function is a modified version of the <code>bisetion</code> function
in the <span class="pkg">cmna</span> R package  (Howard, 2017) to find a root of the function <code>.funs</code>
with respect to its first argument. Unlike the <code>bisetion</code> of the <span class="pkg">cmna</span>,
this <code>bisetion</code> function accepts additional arguments of the function <code>.fun</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bisection(.fun, ..., lb, ub, tol = 1e-04, max.it = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bisection_+3A_.fun">.fun</code></td>
<td>
<p>A function for which the root is searched.</p>
</td></tr>
<tr><td><code id="bisection_+3A_...">...</code></td>
<td>
<p>Additional arguments to be passed to <code>.fun</code>.</p>
</td></tr>
<tr><td><code id="bisection_+3A_lb">lb</code></td>
<td>
<p>A lower bound of the interval to be searched.</p>
</td></tr>
<tr><td><code id="bisection_+3A_ub">ub</code></td>
<td>
<p>An upper bound of the interval to be searched.</p>
</td></tr>
<tr><td><code id="bisection_+3A_tol">tol</code></td>
<td>
<p>The tolerance of error. Default is 1e-4.</p>
</td></tr>
<tr><td><code id="bisection_+3A_max.it">max.it</code></td>
<td>
<p>The maximum number of iterations. Default is 100.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bisection method is a well-known root finding numerical algorithm that works for any continuous
function when the lower (<code>lb</code>) and upper (<code>ub</code>) bounds with opposite signs are provided.
This method repeatedly bisects the defined interval by two values with opposite signs until the absolute
difference of two values becomes less than the error tolerance (<code>tol</code>) or the maximum
number of iterations (<code>max.it</code>) is reached.
</p>


<h3>Value</h3>

<p>A list with three internal objects. The first object is the root found, the second object is
the number of iterations used, and the third object is the approximate accuracy of the root
(i.e., absolute difference between the final two values with opposite signs).
</p>


<h3>References</h3>

<p>Howard, J. P. (2017). <em>Computational methods for numerical analysis with R</em>. New York:
Chapman and Hall/CRC.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+est_score">est_score</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example: find a theta corresponding to the probability of
## correct answer using the item response function of 2PLM
## (a = 1, b = 0.2)

# set a function of theta
find.th &lt;- function(theta, p) {p - drm(theta=theta, a=1, b=0.2, D=1)}

# find the theta corresponding to p = 0.2
bisection(.fun=find.th, p=0.2, lb=-10, ub=10)$root

# find the theta corresponding to p = 0.8
bisection(.fun=find.th, p=0.8, lb=-10, ub=10)$root

</code></pre>

<hr>
<h2 id='bring.flexmirt'>Import Item and Ability Parameters from IRT Software</h2><span id='topic+bring.flexmirt'></span><span id='topic+bring.bilog'></span><span id='topic+bring.parscale'></span><span id='topic+bring.mirt'></span>

<h3>Description</h3>

<p>These functions import item and/or ability parameters from BILOG-MG 3, PARSCALE 4, flexMIRT, and
mirt (R package).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bring.flexmirt(
  file,
  type = c("par", "sco"),
  rePar = TRUE,
  rePar.gpc = TRUE,
  n.factor = 1
)

bring.bilog(file, type = c("par", "sco"))

bring.parscale(file, type = c("par", "sco"))

bring.mirt(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bring.flexmirt_+3A_file">file</code></td>
<td>
<p>A file name (including a directory) containing the item or ability parameters.</p>
</td></tr>
<tr><td><code id="bring.flexmirt_+3A_type">type</code></td>
<td>
<p>A character string indicating a type of output file. Available types are &quot;par&quot; for a file
containing item parameter estimates and &quot;sco&quot; for a file containing ability parameter estimates.</p>
</td></tr>
<tr><td><code id="bring.flexmirt_+3A_repar">rePar</code></td>
<td>
<p>A logical value. If TRUE and when the IRT dichotomous model (e.g., 3PLM) or GRM is fit to data,
the item intercept and logit of item guessing parameters are reparameterized into the item difficulty
and item guessing parameters, respectively. Default is TRUE.</p>
</td></tr>
<tr><td><code id="bring.flexmirt_+3A_repar.gpc">rePar.gpc</code></td>
<td>
<p>A logical value. If TRUE and when (G)PCM is fit to data, the nominal model
parameters in the flexMIRT parameter output file are reparameterized into the (G)PCM slope/difficulty parameters.
Default is TRUE.</p>
</td></tr>
<tr><td><code id="bring.flexmirt_+3A_n.factor">n.factor</code></td>
<td>
<p>A numeric value indicating the number of estimated factors. This argument should be specified
when <code>type = "sco"</code>. Default is 1.</p>
</td></tr>
<tr><td><code id="bring.flexmirt_+3A_x">x</code></td>
<td>
<p>An output object obtained from the function <code><a href="mirt.html#topic+mirt">mirt</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+bring.flexmirt">bring.flexmirt</a></code> was written by modifying the function <code>read.flexmirt</code>
(Pritikin &amp; Falk, 2020). The functions <code><a href="#topic+bring.bilog">bring.bilog</a></code> and <code><a href="#topic+bring.parscale">bring.parscale</a></code>
were written by modifying the functions <code>read.bilog</code> and <code>read.parscale</code>
(Weeks, 2010), respectively.
</p>
<p>The file extensions for item parameter and ability files, respectively, are: &quot;.par&quot; and &quot;.sco&quot;
for BILOG-MG and PARSCALE, and &quot;-prm.txt&quot; and &quot;-sco.txt&quot; for flexMIRT. For mirt, the name of the output
object is specified by the user.
</p>
<p>Although <code><a href="#topic+bring.flexmirt">bring.flexmirt</a></code> is able to extract multidimensional item and ability parameter estimates,
this package only deals with unidimensional IRT methods.
</p>
<p>For polytomous item parameters, <code><a href="#topic+bring.flexmirt">bring.flexmirt</a></code> and <code><a href="#topic+bring.mirt">bring.mirt</a></code> are able to import
the item parameters of the graded response model and the (generalized) partial credit model.
</p>


<h3>Value</h3>

<p>These functions return a list including several objects. Only for the output of flexMIRT, the results of
multiple group analysis can be returned. In that case, each element of the list contains the estimation results for
each group.
</p>


<h3>Sample Output Files of IRT software</h3>

<p>To illustrate how to import the item parameter estimate files of PARSCALE 4 and flexMIRT
using <code><a href="#topic+bring.parscale">bring.parscale</a></code> and <code><a href="#topic+bring.flexmirt">bring.flexmirt</a></code>, two item parameter
estimate output files are included in this package.
</p>
<p>Among the two output files, one of them is from PARSCALE 4 with a file extension of &quot;.PAR&quot;
(i.e., &quot;parscale_sample.PAR&quot;) and another one is from flexMIRT
with a file extension of &quot;-prm.txt&quot; (i.e., &quot;flexmirt_sample-prm.txt&quot;).
</p>
<p>For the two item parameter estimate output files, both are mixed-format tests with 55 items
consisting of fifty dichotomous items following the IRT 3PL model and five polytomous items with five
categories following the graded response model. The examples below show how to import those output files.
</p>


<h3>Note</h3>

<p>Regarding the item parameter files for any IRT software, only the internal object &quot;full_df&quot; in the returned list is
necessary for the IRT linking. The object &quot;full_df&quot; is a data frame containing the item metadata
in a test form (e.g., item parameters, number of categories, models). See <code><a href="#topic+info">info</a></code>
or <code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata.
</p>
<p>Also, when item parameters are estimated using the partial credit or the generalized partial credit model,
item step parameters are returned in the object &quot;full_df&quot;. Item step parameters are the overall item difficulty (or location)
parameter subtracted by the difficulty (or threshold) parameter for each category. See <code><a href="#topic+irtfit">irtfit</a></code> for more details
about the parameterization of the (generalized) partial credit model.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Cai, L. (2017). flexMIRT 3.5 Flexible multilevel multidimensional item analysis and test scoring [Computer software].
Chapel Hill, NC: Vector Psychometric Group.
</p>
<p>Chalmers, R. P. (2012). mirt: A multidimensional item response theory package for the R environment.
<em>Journal of Statistical Software, 48</em>(6), 1-29.
</p>
<p>Weeks, J. P. (2010). plink: An R Package for Linking Mixed-Format Tests Using IRT-Based Methods.
<em>Journal of Statistical Software, 35</em>(12), 1-33. URL http://www.jstatsoft.org/v35/i12/.
</p>
<p>Pritikin, J. (2018). <em>rpf: Response Probability Functions</em>. R package version 0.59.
https://CRAN.R-project.org/package=rpf.
</p>
<p>Pritikin, J. N., &amp; Falk, C. F. (2020). OpenMx: A modular research environment for item response theory
method development. <em>Applied Psychological Measurement, 44</em>(7-8), 561-562.
</p>
<p>Muraki, E. &amp; Bock, R. D. (2003). PARSCALE 4: IRT item analysis and test scoring for rating
scale data [Computer Program]. Chicago, IL: Scientific Software International. URL http://www.ssicentral.com
</p>
<p>Zimowski, M. F., Muraki, E., Mislevy, R. J., &amp; Bock, R. D. (2003). BILOG-MG 3: Multiple-group
IRT analysis and test maintenance for binary items [Computer Program]. Chicago, IL: Scientific
Software International. URL http://www.ssicentral.com
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irtfit">irtfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1
# import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameters and transform them to item meta data
bring.flexmirt(file=flex_sam, "par")$Group1$full_df

## example 2
## import the ".par" output file from PARSCALE
pscale_sam &lt;- system.file("extdata", "parscale_sample.PAR", package = "irtQ")

# read item parameters and transform them to item meta data
bring.parscale(file=pscale_sam, "par")$full_df

</code></pre>

<hr>
<h2 id='cac_lee'>Classification accuracy and consistency using Lee's (2010) approach.</h2><span id='topic+cac_lee'></span>

<h3>Description</h3>

<p>This function computes the classification accuracy and consistency indices
for complex assessments using the method proposed by Lee (2010). The function
can handle both dichotomous and polytomous item response theory (IRT) models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cac_lee(x, cutscore, theta = NULL, weights = NULL, D = 1, cut.obs = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cac_lee_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of
score categories, models ...). See <code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>
or <code><a href="#topic+simdat">simdat</a></code> for more detail about the item metadata.</p>
</td></tr>
<tr><td><code id="cac_lee_+3A_cutscore">cutscore</code></td>
<td>
<p>A numeric vector specifying the cut scores for classification.
Cut scores are the points that separate different performance categories
(e.g., pass vs. fail, or different grades).</p>
</td></tr>
<tr><td><code id="cac_lee_+3A_theta">theta</code></td>
<td>
<p>A numeric vector of ability estimates. Ability estimates (theta values)
are the individual proficiency estimates obtained from the IRT model. The theta
parameter is optional and can be NULL.</p>
</td></tr>
<tr><td><code id="cac_lee_+3A_weights">weights</code></td>
<td>
<p>An optional two-column data frame or matrix where the first column
is the quadrature points (nodes) and the second column is the corresponding weights.
This is typically used in quadrature-based IRT analysis.</p>
</td></tr>
<tr><td><code id="cac_lee_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible
to the normal ogive function (if set to 1.7). Default is 1.</p>
</td></tr>
<tr><td><code id="cac_lee_+3A_cut.obs">cut.obs</code></td>
<td>
<p>A logical value. If TRUE, it indicates the cutscores on the observed-summed score
metric. If FALSE, it indicates they are on the IRT theta score metric. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function works by first checking the provided inputs. If both theta and weights are NULL,
the function will stop and return an error message. Depending on the provided inputs, the function
will then compute the classification accuracy and consistency indices using either the quadrature
points and corresponding weights (D method) or individual ability estimates (P method). The function
returns a list containing the confusion matrix, marginal and conditional classification accuracy and
consistency indices, probabilities of being assigned to each level category, and cut scores.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>

<ul>
<li><p> confusion: A confusion matrix showing the cross table between true and expected levels.
</p>
</li>
<li><p> marginal: A data frame showing the marginal classification accuracy and consistency indices.
</p>
</li>
<li><p> conditional: A data frame showing the conditional classification accuracy and consistency indices.
</p>
</li>
<li><p> prob.level: A data frame showing the probability of being assigned to each level category.
</p>
</li>
<li><p> cutscore: A numeric vector showing the cut scores used in the analysis.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Lee, W. C. (2010). Classification consistency and accuracy for complex assessments
using item response theory. <em>Journal of Educational Measurement, 47</em>(1), 1-17.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gen.weight">gen.weight</a></code>, <code><a href="#topic+est_score">est_score</a></code>, <code><a href="#topic+cac_rud">cac_rud</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##------------------------------------------------------------------------------
# 1. When the empirical ability distribution of the population is available
#    (D method)
##------------------------------------------------------------------------------
## import the "-prm.txt" output file from flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameter data and transform it to item metadata
x &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df

# set the cut scores on the observed-summed score metric
cutscore &lt;- c(10, 20, 30, 50)

# create the data frame including the quadrature points
# and the corresponding weights
node &lt;- seq(-4, 4, 0.25)
weights &lt;- gen.weight(dist = "norm", mu = 0, sigma = 1, theta = node)

# calculate the classification accuracy and consistency
cac_1 &lt;- cac_lee(x=x, cutscore=cutscore, weights=weights, D=1)
print(cac_1)

##------------------------------------------------------------------------------
# 2. When individual ability estimates are available (P method)
##------------------------------------------------------------------------------
# randomly select the true abilities from N(0, 1)
set.seed(12)
theta &lt;- rnorm(n = 1000, mean = 0, sd = 1)

# simulate the item response data
data &lt;- simdat(x = x, theta = theta, D = 1)

# estimate the ability parameters using the ML estimation
est_th &lt;- est_score(x = x, data = data, D = 1, method = "ML",
                    range=c(-4, 4), se = FALSE)$est.theta

# calculate the classification accuracy and consistency
cac_2 &lt;- cac_lee(x = x, cutscore = cutscore, theta = est_th, D = 1)
print(cac_2)

##------------------------------------------------------------------------------
# 3. When individual ability estimates are available,
#    but, the cutscores are on the IRT theta score metric
##------------------------------------------------------------------------------
# set the theta cut scures
cutscore &lt;- c(-2, -0.4, 0.2, 1.0)

# calculate the classification accuracy and consistency
cac_3 &lt;- cac_lee(x = x, cutscore = cutscore, theta = est_th, D = 1,
                 cut.obs = FALSE)
print(cac_3)



</code></pre>

<hr>
<h2 id='cac_rud'>Classification accuracy and consistency using Rudner's (2001, 2005) approach.</h2><span id='topic+cac_rud'></span>

<h3>Description</h3>

<p>This function computes the classification accuracy and consistency based on the methods
proposed by Rudner (2001, 2005). It can handle both situations where the empirical ability
distribution of the population is available and when individual ability estimates are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cac_rud(cutscore, theta = NULL, se, weights = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cac_rud_+3A_cutscore">cutscore</code></td>
<td>
<p>A numeric vector specifying the cut scores for classification.
Cut scores are the points that separate different performance categories
(e.g., pass vs. fail, or different grades).</p>
</td></tr>
<tr><td><code id="cac_rud_+3A_theta">theta</code></td>
<td>
<p>A numeric vector of ability estimates. Ability estimates (theta values)
are the individual proficiency estimates obtained from the IRT model. The theta
parameter is optional and can be NULL.</p>
</td></tr>
<tr><td><code id="cac_rud_+3A_se">se</code></td>
<td>
<p>A numeric vector of the same length as theta indicating the standard
errors of the ability estimates.</p>
</td></tr>
<tr><td><code id="cac_rud_+3A_weights">weights</code></td>
<td>
<p>An optional two-column data frame or matrix where the first column
is the quadrature points (nodes) and the second column is the corresponding weights.
This is typically used in quadrature-based IRT analysis.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function first checks the provided inputs for correctness. It then computes the
probabilities that an examinee with a specific ability is assigned to each level category,
and calculates the conditional classification accuracy and consistency for each theta value.
Finally, it computes the marginal accuracy and consistency.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>

<ul>
<li><p> confusion: A confusion matrix showing the cross table between true and expected levels.
</p>
</li>
<li><p> marginal: A data frame showing the marginal classification accuracy and consistency indices.
</p>
</li>
<li><p> conditional: A data frame showing the conditional classification accuracy and consistency indices.
</p>
</li>
<li><p> prob.level: A data frame showing the probability of being assigned to each level category.
</p>
</li>
<li><p> cutscore: A numeric vector showing the cut scores used in the analysis.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Rudner, L. M. (2001). Computing the expected proportions of misclassified examinees.
<em>Practical Assessment, Research, and Evaluation, 7</em>(1), 14.
</p>
<p>Rudner, L. M. (2005). Expected classification accuracy. <em>Practical Assessment,
Research, and Evaluation, 10</em>(1), 13.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+gen.weight">gen.weight</a></code>, <code><a href="#topic+est_score">est_score</a></code>, <code><a href="#topic+cac_lee">cac_lee</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##------------------------------------------------------------------------------
# 1. When the empirical ability distribution of the population is available
##------------------------------------------------------------------------------
## import the "-prm.txt" output file from flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameter data and transform it to item metadata
x &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df

# set the cut scores on the theta score metric
cutscore &lt;- c(-2, -0.5, 0.8)

# create the data frame including the quadrature points
# and the corresponding weights
node &lt;- seq(-4, 4, 0.25)
weights &lt;- gen.weight(dist = "norm", mu = 0, sigma = 1, theta = node)

# compute the conditional standard errors across all quadrature points
tif &lt;- info(x=x, theta=node, D=1, tif=TRUE)$tif
se &lt;- 1 / sqrt(tif)

# calculate the classification accuracy and consistency
cac_1 &lt;- cac_rud(cutscore=cutscore, se=se, weights=weights)
print(cac_1)

##------------------------------------------------------------------------------
# 2. When individual ability estimates are available
##------------------------------------------------------------------------------
# randomly select the true abilities from N(0, 1)
set.seed(12)
theta &lt;- rnorm(n = 1000, mean = 0, sd = 1)

# simulate the item response data
data &lt;- simdat(x = x, theta = theta, D = 1)

# estimate the ability parameters and standard errors using the ML estimation
est_theta &lt;- est_score(x = x, data = data, D = 1, method = "ML",
                       range=c(-4, 4), se = TRUE)
theta_hat &lt;- est_theta$est.theta
se &lt;- est_theta$se.theta

# calculate the classification accuracy and consistency
cac_2 &lt;- cac_rud(cutscore=cutscore, theta=theta_hat, se=se)
print(cac_2)


</code></pre>

<hr>
<h2 id='catsib'>CATSIB DIF detection procedure</h2><span id='topic+catsib'></span>

<h3>Description</h3>

<p>This function analyzes DIF on an item using CATSIB procedure (Nandakumar &amp; Roussos, 2004), which is a modified
version of SIBTEST (Shealy &amp; Stout, 1993). The CATSIB procedure can be applied to a computerized adaptive testing (CAT)
environment for differential item functioning (DIF) detection. In CATSIB, examinees are matched on IRT-based ability
estimates adjusted by employing a regression correction method (Shealy &amp; Stout, 1993) to reduce a statistical bias of
the CATSIB statistic due to impact.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>catsib(
  x = NULL,
  data,
  score = NULL,
  se = NULL,
  group,
  focal.name,
  D = 1,
  n.bin = c(80, 10),
  min.binsize = 3,
  max.del = 0.075,
  weight.group = c("comb", "foc", "ref"),
  alpha = 0.05,
  missing = NA,
  purify = FALSE,
  max.iter = 10,
  min.resp = NULL,
  method = "ML",
  range = c(-5, 5),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  ncore = 1,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="catsib_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...).
<code>x</code> should to be provided to estimate latent ability parameters when <code>score = NULL</code> or <code>purify = TRUE</code>. Default is NULL.
See <code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code> or <code><a href="#topic+simdat">simdat</a></code> for more detail about the item metadata.</p>
</td></tr>
<tr><td><code id="catsib_+3A_data">data</code></td>
<td>
<p>A matrix containing examinees' response data of the items in the argument <code>x</code>. A row and column indicate
the examinees and items, respectively.</p>
</td></tr>
<tr><td><code id="catsib_+3A_score">score</code></td>
<td>
<p>A vector of examinees' ability estimates. If the abilities are not provided (i.e., <code>score  = NULL</code>),
<code><a href="#topic+catsib">catsib</a></code> computes the ability estimates before computing the CATSIB statistics. See <code><a href="#topic+est_score">est_score</a></code>
for more detail about scoring methods. Default is NULL.</p>
</td></tr>
<tr><td><code id="catsib_+3A_se">se</code></td>
<td>
<p>A vector of the standard errors of the ability estimates. The standard errors should be ordered in accordance with the order of
the ability estimates specified in the <code>score</code> argument. Default is NULL.</p>
</td></tr>
<tr><td><code id="catsib_+3A_group">group</code></td>
<td>
<p>A numeric or character vector indicating group membership of examinees. The length of vector should be the same with the number of rows
in the response data matrix.</p>
</td></tr>
<tr><td><code id="catsib_+3A_focal.name">focal.name</code></td>
<td>
<p>A single numeric or character scalar representing the level associated with the focal group. For instance,
given <code>group = c(0, 1, 0, 1, 1)</code> and '1' indicating the focal group, set <code>focal.name = 1</code>.</p>
</td></tr>
<tr><td><code id="catsib_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="catsib_+3A_n.bin">n.bin</code></td>
<td>
<p>A vector of two positive integers to set the maximum and minimum numbers of bins (or intervals) on the ability scale.
The first and second values indicate the maximum and minimum numbers of the bins, respectively. See below for more detail.</p>
</td></tr>
<tr><td><code id="catsib_+3A_min.binsize">min.binsize</code></td>
<td>
<p>A positive integer value to set the minimum size of each bin. To ensure stable statistical estimation, each bin is required
to have a certain number of examinees (e.g, 3), at least, from both reference and focal groups if it was to be included in calculation of <code class="reqn">\hat{\beta}</code>.
All bins with fewer than the minimum number are not used for the computation. Default is 3. See below for more detail.</p>
</td></tr>
<tr><td><code id="catsib_+3A_max.del">max.del</code></td>
<td>
<p>A numerical value to set the maximum permissible proportion of examinees to be deleted from either reference group or focal group
when automatically determining the number of bins on the ability scale. Default is 0.075. See below for more detail.</p>
</td></tr>
<tr><td><code id="catsib_+3A_weight.group">weight.group</code></td>
<td>
<p>A single character string to specify a target ability distribution over which the expectation of DIF measure, called <code class="reqn">\hat{\beta}</code>,
and the corresponding standard error are computed. Available options are &quot;comb&quot; for the combined ability distribution from both the reference and focal groups,
&quot;foc&quot; for the ability distribution of the focal group, and &quot;ref&quot; for the ability distribution of the reference group. Defulat is &quot;comb&quot;. See below for more detail.</p>
</td></tr>
<tr><td><code id="catsib_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value to specify significance <code class="reqn">\alpha</code>-level of the hypothesis test using the CATSIB statistics.
Default is .05.</p>
</td></tr>
<tr><td><code id="catsib_+3A_missing">missing</code></td>
<td>
<p>A value indicating missing values in the response data set. Default is NA.</p>
</td></tr>
<tr><td><code id="catsib_+3A_purify">purify</code></td>
<td>
<p>A logical value indicating whether a purification process will be implemented or not. Default is FALSE. See below for more detail.</p>
</td></tr>
<tr><td><code id="catsib_+3A_max.iter">max.iter</code></td>
<td>
<p>A positive integer value specifying the maximum number of iterations for
the purification process. Default is 10.</p>
</td></tr>
<tr><td><code id="catsib_+3A_min.resp">min.resp</code></td>
<td>
<p>A positive integer value specifying the minimum number of item responses for an examinee
required to compute the ability estimate. Default is NULL. See details below for more information.</p>
</td></tr>
<tr><td><code id="catsib_+3A_method">method</code></td>
<td>
<p>A character string indicating a scoring method. Available methods are &quot;ML&quot; for the maximum likelihood estimation,
&quot;WL&quot; for the weighted likelihood estimation, &quot;MAP&quot; for the maximum a posteriori estimation, and &quot;EAP&quot; for the expected a posteriori
estimation. Default method is &quot;ML&quot;.</p>
</td></tr>
<tr><td><code id="catsib_+3A_range">range</code></td>
<td>
<p>A numeric vector of two components to restrict the range of ability scale for the ML, WL, MLF, and MAP scoring methods. Default is c(-5, 5).</p>
</td></tr>
<tr><td><code id="catsib_+3A_norm.prior">norm.prior</code></td>
<td>
<p>A numeric vector of two components specifying a mean and standard deviation of the normal prior distribution.
These two parameters are used to obtain the gaussian quadrature points and the corresponding weights from the normal distribution. Default is
c(0,1). Ignored if <code>method</code> is &quot;ML&quot; or &quot;WL&quot;.</p>
</td></tr>
<tr><td><code id="catsib_+3A_nquad">nquad</code></td>
<td>
<p>An integer value specifying the number of gaussian quadrature points from the normal prior distribution. Default is 41.
Ignored if <code>method</code> is &quot;ML&quot;, &quot;WL&quot;, or &quot;MAP&quot;.</p>
</td></tr>
<tr><td><code id="catsib_+3A_weights">weights</code></td>
<td>
<p>A two-column matrix or data frame containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the latent variable prior distribution. The weights and quadrature points can be easily obtained
using the function <code><a href="#topic+gen.weight">gen.weight</a></code>. If NULL and <code>method</code> is &quot;EAP&quot;, default values are used (see the arguments
of <code>norm.prior</code> and <code>nquad</code>). Ignored if <code>method</code> is &quot;ML&quot;, &quot;WL&quot;, or &quot;MAP&quot;.</p>
</td></tr>
<tr><td><code id="catsib_+3A_ncore">ncore</code></td>
<td>
<p>The number of logical CPU cores to use. Default is 1. See <code><a href="#topic+est_score">est_score</a></code> for details.</p>
</td></tr>
<tr><td><code id="catsib_+3A_verbose">verbose</code></td>
<td>
<p>A logical value. If TRUE, the progress messages of purification procedure are suppressed. Default is TRUE.</p>
</td></tr>
<tr><td><code id="catsib_+3A_...">...</code></td>
<td>
<p>Additional arguments that will be forwarded to the <code><a href="#topic+est_score">est_score</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In CATSIB procedure (Nandakumar &amp; Roussos, 2004), because <code class="reqn">\hat{\beta}^{\ast}</code>, which is the expected <code class="reqn">\theta</code> regressed on <code class="reqn">\hat{\beta}</code>,
is a continuous variable, the range of <code class="reqn">\hat{\beta}^{\ast}</code> is divided into K equal intervals and examinees are classified into one of K intervals
on the basis of their <code class="reqn">\hat{\beta}^{\ast}</code>.Then, any intervals that contain less than three examinees in either reference or focal groups were
excluded from the computation of <code class="reqn">\hat{\beta}</code>, which is a measure of the amount of DIF, to ensure stable statistical estimation. According to
Nandakumar and Roussos (2004), a default minimum size of each bin is set to 3 in <code>min.binsize</code>.
</p>
<p>To carefully choose the number of intervals (K), the <code><a href="#topic+catsib">catsib</a></code> automatically determines it by gradually decreasing K from a larger to
smaller numbers based the rule used in Nandakumar and Roussos (2004). Specifically, beginning with an arbitrary large number (e.g., 80),
if more than a certain permissible percentage, let's say 7.5%, of examinees in either the reference or focal groups were removed, the <code><a href="#topic+catsib">catsib</a></code>
automatically decreases the number of bins by one unit until a total number of examinees in each group reaches to more than or equal to 92.5%.
However, Nandakumar and Roussos (2004) recommended setting the minimum K to 10 to avoid a situation that extremely a few intervals are left,
even if the number of remaining examinees in each group is less than 92.5%. Thus, the maximum and minimum number of bins are set to 80 and 10, respectively,
as default in <code>n.bin</code>. Also, a default maximum permissible proportion of examinees to be deleted from either reference group or focal group is
set to 0.075 in <code>max.del</code>.
</p>
<p>When it comes to the target ability distribution used to compute <code class="reqn">\hat{\beta}</code>, Li and Stout (1996) and Nandakumar and Roussos (2004) used the combined-group
target ability distribution, which is a default option in <code>weight.group</code>. See Nandakumar and Roussos (2004) for more detail about the CATSIB method.
</p>
<p>Although Nandakumar and Roussos (2004) did not propose a purification procedure for DIF analysis using CATSIB, the <code><a href="#topic+catsib">catsib</a></code> can implement an iterative
purification process in a similar way as in Lim, Choe, and Han (2022). Simply, at each iterative purification, examinees' latent abilities are computed using
purified items and scoring method specified in the <code>method</code> argument. The iterative purification process stops when no further DIF items are found or
the process reaches a predetermined limit of iteration, which can be specified in the <code>max.iter</code> argument. See Lim et al. (2022)
for more details about the purification procedure.
</p>
<p>Scoring with a limited number of items can result in large standard errors, which may impact the effectiveness of DIF detection within
the CATSIB procedure. The <code>min.resp</code> argument can be employed to avoid using scores with significant standard errors when calculating
the CATSIB statistic, particularly during the purification process. For instance, if <code>min.resp</code> is not NULL (e.g., <code>min.resp=5</code>),
item responses from examinees whose total item responses fall below the specified minimum number are treated as missing values (i.e., NA).
Consequently, their ability estimates become missing values and are not utilized in computing the CATSIB statistic. If <code>min.resp=NULL</code>,
an examinee's score will be computed as long as there is at least one item response for the examinee.
</p>


<h3>Value</h3>

<p>This function returns a list of four internal objects. The four objects are:
</p>
<table>
<tr><td><code>no_purify</code></td>
<td>
<p>A list of several sub-objects containing the results of DIF analysis without a purification procedure. The sub-objects are:
</p>

<dl>
<dt>dif_stat</dt><dd><p>A data frame containing the results of CATSIB statistics across all evaluated items. From the first column, each column
indicates item's ID, CATSIB (<em>beta</em>) statistic, standard error of the <em>beta</em>, standardized <em>beta</em>, p-value of the <em>beta</em>,
sample size of the reference group, sample size of the focal group, and total sample size, respectively.</p>
</dd>
<dt>dif_item</dt><dd><p>A numeric vector showing potential DIF items flagged by CATSIB statistic.</p>
</dd>
<dt>contingency</dt><dd><p>A contingency table of each item used to compute CATSIB statistic.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>purify</code></td>
<td>
<p>A logical value indicating whether the purification process was used.</p>
</td></tr>
<tr><td><code>with_purify</code></td>
<td>
<p>A list of several sub-objects containing the results of DIF analysis with a purification procedure. The sub-objects are:
</p>

<dl>
<dt>dif_stat</dt><dd><p>A data frame containing the results of CATSIB statistics across all evaluated items. From the first column, each column
indicates item's ID, CATSIB (<em>beta</em>) statistic, standard error of the <em>beta</em>, standardized <em>beta</em>, p-value of the <em>beta</em>,
sample size of the reference group, sample size of the focal group, and total sample size, and <em>n</em>th iteration where the CATSIB statistic
was computed, respectively.</p>
</dd>
<dt>dif_item</dt><dd><p>A numeric vector showing potential DIF items flagged by CATSIB statistic.</p>
</dd>
<dt>n.iter</dt><dd><p>A total number of iterations implemented for the purification.</p>
</dd>
<dt>complete</dt><dd><p>A logical value indicating whether the purification process was completed. If FALSE, it means that the purification process
reached the maximum iteration number but it was not complete.</p>
</dd>
<dt>contingency</dt><dd><p>A contingency table of each item used to compute CATSIB statistic.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>A significance <code class="reqn">\alpha</code>-level used to compute the p-values of RDIF statistics.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Li, H. H., &amp; Stout, W. (1996). A new procedure for detection of crossing DIF. <em>Psychometrika, 61</em>(4), 647-677.
</p>
<p>Lim, H., Choe, E. M., &amp; Han, K. T. (2022). A residual-based differential item functioning detection framework in
item response theory. <em>Journal of Educational Measurement</em>.
</p>
<p>Nandakumar, R., &amp; Roussos, L. (2004). Evaluation of the CATSIB DIF procedure in a pretest setting.
<em>Journal of Educational and Behavioral Statistics, 29</em>(2), 177-199.
</p>
<p>Shealy, R. T., &amp; Stout, W. F. (1993). A model-based standardization approach that separates true bias/DIF
from group ability differences and detects test bias/DIF as well as item bias/DIF. <em>Psychometrika, 58</em>, 159–194.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rdif">rdif</a></code>, <code><a href="#topic+est_item">est_item</a></code>, <code><a href="#topic+info">info</a></code>, <code><a href="#topic+simdat">simdat</a></code>,
<code><a href="#topic+shape_df">shape_df</a></code>, <code><a href="#topic+gen.weight">gen.weight</a></code>, <code><a href="#topic+est_score">est_score</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# call library
library("dplyr")

## Uniform DIF detection
###############################################
# (1) manipulate true uniform DIF data
###############################################
# import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select 36 of 3PLM items which are non-DIF items
par_nstd &lt;-
  bring.flexmirt(file=flex_sam, "par")$Group1$full_df %&gt;%
  dplyr::filter(.data$model == "3PLM") %&gt;%
  dplyr::filter(dplyr::row_number() %in% 1:36) %&gt;%
  dplyr::select(1:6)
par_nstd$id &lt;- paste0("nondif", 1:36)

# generate four new items to inject uniform DIF
difpar_ref &lt;-
  shape_df(par.drm=list(a=c(0.8, 1.5, 0.8, 1.5), b=c(0.0, 0.0, -0.5, -0.5), g=0.15),
           item.id=paste0("dif", 1:4), cats=2, model="3PLM")

# manipulate uniform DIF on the four new items by adding constants to b-parameters
# for the focal group
difpar_foc &lt;-
  difpar_ref %&gt;%
  dplyr::mutate_at(.vars="par.2", .funs=function(x) x + rep(0.7, 4))

# combine the 4 DIF and 36 non-DIF items for both reference and focal groups
# thus, the first four items have uniform DIF
par_ref &lt;- rbind(difpar_ref, par_nstd)
par_foc &lt;- rbind(difpar_foc, par_nstd)

# generate the true thetas
set.seed(123)
theta_ref &lt;- rnorm(500, 0.0, 1.0)
theta_foc &lt;- rnorm(500, 0.0, 1.0)

# generate the response data
resp_ref &lt;- simdat(par_ref, theta=theta_ref, D=1)
resp_foc &lt;- simdat(par_foc, theta=theta_foc, D=1)
data &lt;- rbind(resp_ref, resp_foc)

###############################################
# (2) estimate the item and ability parameters
#     using the aggregate data
###############################################
# estimate the item parameters
est_mod &lt;- est_irt(data=data, D=1, model="3PLM")
est_par &lt;- est_mod$par.est

# estimate the ability parameters using ML
theta_est &lt;- est_score(x=est_par, data=data, method="ML")
score &lt;- theta_est$est.theta
se &lt;- theta_est$se.theta

###############################################
# (3) conduct DIF analysis
###############################################
# create a vector of group membership indicators
# where '1' indicates the focal group
group &lt;- c(rep(0, 500), rep(1, 500))

# (a)-1 compute SIBTEST statistic by providing scores,
#       and without a purification
dif_1 &lt;- catsib(x=NULL, data=data, D=1, score=score, se=se, group=group, focal.name=1,
 weight.group="comb", alpha=0.05, missing=NA, purify=FALSE)
print(dif_1)

# (a)-2 compute SIBTEST statistic by providing scores,
#       and with a purification
dif_2 &lt;- catsib(x=est_par, data=data, D=1, score=score, se=se, group=group, focal.name=1,
 weight.group="comb", alpha=0.05, missing=NA, purify=TRUE)
print(dif_2)



</code></pre>

<hr>
<h2 id='covirt'>Asymptotic variance-covariance matrices of item parameter estimates</h2><span id='topic+covirt'></span>

<h3>Description</h3>

<p>This function calculates the analytical asymptotic variance-covariance matrices (e.g., Li &amp; Lissitz, 2004; Thissen &amp; Wainer, 1982)
of item parameter estimates for dichotomous and polytomous IRT Models without examinee's responses to test items,
given a set of item parameter estimates and sample size. The square roots of variance terms in the matrices can be used as the asymptotic
standard errors of maximum likelihood item parameter estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covirt(
  x,
  D = 1,
  nstd = 1000,
  pcm.loc = NULL,
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covirt_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...).
See <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>, or <code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata.
This data frame can be easily obtained using the function <code><a href="#topic+shape_df">shape_df</a></code>.</p>
</td></tr>
<tr><td><code id="covirt_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="covirt_+3A_nstd">nstd</code></td>
<td>
<p>An integer value or a vector of integer values indicating a sample size. When a vector is specified, length of the vector must be
the same as the number of test items in the argument <code>x</code>. Default is 1,000. See below for details.</p>
</td></tr>
<tr><td><code id="covirt_+3A_pcm.loc">pcm.loc</code></td>
<td>
<p>A vector of integer values indicating the locations of partial credit model (PCM) items. For the PCM items,
the variance-covariance matrices are computed only for the item category difficulty parameters. Default is NULL. See below for details.</p>
</td></tr>
<tr><td><code id="covirt_+3A_norm.prior">norm.prior</code></td>
<td>
<p>A numeric vector of two components specifying a mean and standard deviation of the normal prior distribution.
These two parameters are used to obtain the gaussian quadrature points and the corresponding weights from the normal distribution.
Default is c(0,1).</p>
</td></tr>
<tr><td><code id="covirt_+3A_nquad">nquad</code></td>
<td>
<p>An integer value specifying the number of gaussian quadrature points from the normal prior distribution. Default is 41.</p>
</td></tr>
<tr><td><code id="covirt_+3A_weights">weights</code></td>
<td>
<p>A two-column matrix or data frame containing the theta values (in the first column) and the weights (in the second column)
for the prior distribution. The weights and theta values can be easily obtained using the function <code><a href="#topic+gen.weight">gen.weight</a></code>.
If NULL, default values are used for the prior distribution (see the arguments of <code>norm.prior</code> and <code>nquad</code>). Default is NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard errors obtained from the analytical approach are likely to represent lower bounds for the actual standard errors (Thissen &amp; Wainer, 1982).
Therefore, they may be useful for assessing the degree of precision of a set of item parameter estimates when the corresponding standard errors of
the estimates are not presented in literature or research reports.
</p>
<p>Sometimes item parameters need to be estimated using different sample size. If the item parameters in the argument <code>x</code> were
calibrated with different number of examinees, a vector of different sample sizes should be specified in the argument <code>nstd</code>. Suppose
that you want to compute the variance-covariance matrices of five IRT 3PLM items and the five items were calibrated with 500, 600, 1,000, 2,000,
and 700 examinees, respectively. Then, <code>nstd = c(500, 600, 1000, 2000, 700)</code> must be specified.
</p>
<p>Because you can specify only &quot;GPCM&quot; for both the partial credit model (PCM) or the generalized partial credit model (GPCM) in the item metadata,
you must indicate which items are the PCM items through the argument <code>pcm.loc</code>. This is because the item category difficulty parameters are estimated
from the PCM, meaning that the variance-covariance of item parameter estimates must be computed for the item category difficulty parameters. Suppose
that you want to compute the variance-covariance matrices of five polytomous items and the last two items were calibrated with the PCM. Then,
<code>pcm.loc = c(4, 5)</code> must be specified.
</p>


<h3>Value</h3>

<p>A list of two internal objects. The first internal object contains a list of the variance-covariance matrices of item parameter estimates.
The second internal object contains a list of the standard errors of item parameter estimates.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Li, Y. &amp; Lissitz, R. (2004). Applications of the analytically derived asymptotic standard errors of item response theory
item parameter estimates. <em>Journal of educational measurement, 41</em>(2), 85-117.
</p>
<p>Thissen, D. &amp; Wainer, H. (1982). Weighted likelihood estimation of ability in item response theory.
<em>Psychometrika, 54</em>(3), 427-450.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>, <code><a href="#topic+simdat">simdat</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>, <code><a href="#topic+gen.weight">gen.weight</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## the use of a "-prm.txt" file obtained sfrom a flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select the first two dichotomous items and last polytomous item
x &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df[c(1:2, 55), ]

# compute the var-covariance matrices with sample size of 2,000
covirt(x, D=1, nstd=2000, norm.prior=c(0, 1), nquad=41)

</code></pre>

<hr>
<h2 id='drm'>Dichotomous Response Model (DRM) Probabilities</h2><span id='topic+drm'></span>

<h3>Description</h3>

<p>This function computes the probability of correct answers for multiple items
for a given set of theta values using the IRT 1PL, 2PL, and 3PL models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>drm(theta, a, b, g = NULL, D = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="drm_+3A_theta">theta</code></td>
<td>
<p>A vector of ability values.</p>
</td></tr>
<tr><td><code id="drm_+3A_a">a</code></td>
<td>
<p>A vector of item discrimination (or slope) parameters.</p>
</td></tr>
<tr><td><code id="drm_+3A_b">b</code></td>
<td>
<p>A vector of item difficulty (or threshold) parameters.</p>
</td></tr>
<tr><td><code id="drm_+3A_g">g</code></td>
<td>
<p>A vector of item guessing parameters.</p>
</td></tr>
<tr><td><code id="drm_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible
to the normal ogive function (if set to 1.7). Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>g</code> does not need to be specified when the response probabilities of
the 1PL and 2PL models are computed.
</p>


<h3>Value</h3>

<p>This function returns a matrix where a row indicates the ability and a column
represents the item.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prm">prm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## when vectors are used for both theta values and item parameters (3PLM)
drm(c(-0.1, 0.0, 1.5), a=c(1, 2), b=c(0, 1), g=c(0.2, 0.1), D=1)

## when vectors are only used for item parameters (2PLM)
drm(0.0, a=c(1, 2), b=c(0, 1), D=1)

## when vectors are only used for theta values (3PLM)
drm(c(-0.1, 0.0, 1.5), a=1, b=1, g=0.2, D=1)

</code></pre>

<hr>
<h2 id='est_irt'>Item parameter estimation using MMLE-EM algorithm</h2><span id='topic+est_irt'></span>

<h3>Description</h3>

<p>This function fits unidimensional item response (IRT) models to a mixture of dichotomous and polytomous data using the
marginal maximum likelihood estimation via the expectation-maximization (MMLE-EM) algorithm (Bock &amp; Aitkin, 1981). This function also
implements the fixed item parameter calibration (FIPC; Kim, 2006). As Method A (Stocking, 1988), FIPC is one of useful online item
calibration methods for computerized adaptive testing (CAT) to put the parameter estimates of pretest items on the same scale of
operational item parameter estimates (Ban, Hanson, Wang, Yi, &amp; Harris, 2001). For dichotomous items, IRT one-, two-, and three-parameter
logistic models are available. For polytomous items, the graded response model (GRM) and the (generalized) partial credit model (GPCM)
are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_irt(
  x = NULL,
  data,
  D = 1,
  model = NULL,
  cats = NULL,
  item.id = NULL,
  fix.a.1pl = FALSE,
  fix.a.gpcm = FALSE,
  fix.g = FALSE,
  a.val.1pl = 1,
  a.val.gpcm = 1,
  g.val = 0.2,
  use.aprior = FALSE,
  use.bprior = FALSE,
  use.gprior = TRUE,
  aprior = list(dist = "lnorm", params = c(0, 0.5)),
  bprior = list(dist = "norm", params = c(0, 1)),
  gprior = list(dist = "beta", params = c(5, 16)),
  missing = NA,
  Quadrature = c(49, 6),
  weights = NULL,
  group.mean = 0,
  group.var = 1,
  EmpHist = FALSE,
  use.startval = FALSE,
  Etol = 1e-04,
  MaxE = 500,
  control = list(iter.max = 200),
  fipc = FALSE,
  fipc.method = "MEM",
  fix.loc = NULL,
  fix.id = NULL,
  se = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est_irt_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata. This metadata is necessary to obtain the information of
each item (i.e., number of score categories and IRT model) to be calibrated. You can easily create an empty
item metadata using the function <code><a href="#topic+shape_df">shape_df</a></code>. When <code>use.startval = TRUE</code>, the item parameters
specified in the item metadata are used as the starting values for the item parameter estimation.
If <code>x = NULL</code>, the arguments of <code>model</code> and <code>cats</code> must be specified. Note that when <code>fipc = TRUE</code>
to implement the FIPC method, the item metadata of a test form must be provided in the argument <code>x</code>.
See below for details. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_data">data</code></td>
<td>
<p>A matrix containing examinees' response data for the items in the argument <code>x</code>. A row and column indicate
the examinees and items, respectively.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_model">model</code></td>
<td>
<p>A vector of character strings indicating what IRT model is used to calibrate each item. Available IRT models are
&quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for dichotomous items, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous items. &quot;GRM&quot; and &quot;GPCM&quot; represent the graded
response model and (generalized) partial credit model, respectively. Note that &quot;DRM&quot; is considered as &quot;3PLM&quot; in this function.
If a single character of the IRT model is specified, that model will be recycled across all items. The provided information in the <code>model</code>
argument is used only when <code>x = NULL</code> and <code>fipc = FALSE</code>. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_cats">cats</code></td>
<td>
<p>A numeric vector specifying the number of score categories for each item. For example, a dichotomous
item has two score categories. If a single numeric value is specified, that value will be recycled across all items. If <code>cats = NULL</code>
and all specified models in the <code>model</code> argument are the dichotomous models (i.e., 1PLM, 2PLM, 3PLM, or DRM), it assumes
that all items have two score categories. The provided information in the <code>cats</code> argument is used only
when <code>x = NULL</code> and <code>fipc = FALSE</code>. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_item.id">item.id</code></td>
<td>
<p>A character vector of item IDs. If NULL, the item IDs are generated automatically. When <code>fipc = TRUE</code> and the Item IDs
are given by the <code>item.id</code> argument, the Item IDs in the <code>x</code> argument are overridden. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_fix.a.1pl">fix.a.1pl</code></td>
<td>
<p>A logical value. If TRUE, the slope parameters of the 1PLM items are fixed to a specific value specified in the argument
<code>a.val.1pl</code>. Otherwise, the slope parameters of all 1PLM items are constrained to be equal and estimated. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_fix.a.gpcm">fix.a.gpcm</code></td>
<td>
<p>A logical value. If TRUE, the GPCM items are calibrated with the partial credit model and the slope parameters of
the GPCM items are fixed to a specific value specified in the argument <code>a.val.gpcm</code>. Otherwise, the slope parameter of each GPCM item
is estimated. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_fix.g">fix.g</code></td>
<td>
<p>A logical value. If TRUE, the guessing parameters of the 3PLM items are fixed to a specific value specified in the argument
<code>g.val</code>. Otherwise, the guessing parameter of each 3PLM item is estimated. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_a.val.1pl">a.val.1pl</code></td>
<td>
<p>A numeric value. This value is used to fixed the slope parameters of the 1PLM items.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_a.val.gpcm">a.val.gpcm</code></td>
<td>
<p>A numeric value. This value is used to fixed the slope parameters of the GPCM items.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_g.val">g.val</code></td>
<td>
<p>A numeric value. This value is used to fixed the guessing parameters of the 3PLM items.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_use.aprior">use.aprior</code></td>
<td>
<p>A logical value. If TRUE, a prior distribution for the slope parameters is used for the parameter calibration
across all items. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_use.bprior">use.bprior</code></td>
<td>
<p>A logical value. If TRUE, a prior distribution for the difficulty (or threshold) parameters is used for the parameter calibration
across all items. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_use.gprior">use.gprior</code></td>
<td>
<p>A logical value. If TRUE, a prior distribution for the guessing parameters is used for the parameter calibration
across all 3PLM items. Default is TRUE.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_aprior">aprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item slope parameters. Three probability distributions
of Beta, Log-normal, and Normal distributions are available. In the list, a character string of the distribution name must be specified
in the first internal argument and a vector of two numeric values for the two parameters of the distribution must be specified in the
second internal argument. Specifically, when Beta distribution is used, &quot;beta&quot; should be specified in the first argument. When Log-normal
distribution is used, &quot;lnorm&quot; should be specified in the first argument. When Normal distribution is used, &quot;norm&quot; should be specified
in the first argument. In terms of the two parameters of the three distributions, see <code>dbeta()</code>, <code>dlnorm()</code>,
and <code>dnorm()</code> in the <span class="pkg">stats</span> package for more details.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_bprior">bprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item difficulty (or threshold) parameters. Three probability distributions
of Beta, Log-normal, and Normal distributions are available. In the list, a character string of the distribution name must be specified
in the first internal argument and a vector of two numeric values for the two parameters of the distribution must be specified in the
second internal argument. Specifically, when Beta distribution is used, &quot;beta&quot; should be specified in the first argument. When Log-normal
distribution is used, &quot;lnorm&quot; should be specified in the first argument. When Normal distribution is used, &quot;norm&quot; should be specified
in the first argument. In terms of the two parameters of the three distributions, see <code>dbeta()</code>, <code>dlnorm()</code>,
and <code>dnorm()</code> in the <span class="pkg">stats</span> package for more details.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_gprior">gprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item guessing parameters. Three probability distributions
of Beta, Log-normal, and Normal distributions are available. In the list, a character string of the distribution name must be specified
in the first internal argument and a vector of two numeric values for the two parameters of the distribution must be specified in the
second internal argument. Specifically, when Beta distribution is used, &quot;beta&quot; should be specified in the first argument. When Log-normal
distribution is used, &quot;lnorm&quot; should be specified in the first argument. When Normal distribution is used, &quot;norm&quot; should be specified
in the first argument. In terms of the two parameters of the three distributions, see <code>dbeta()</code>, <code>dlnorm()</code>,
and <code>dnorm()</code> in the <span class="pkg">stats</span> package for more details.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_missing">missing</code></td>
<td>
<p>A value indicating missing values in the response data set. Default is NA.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_quadrature">Quadrature</code></td>
<td>
<p>A numeric vector of two components specifying the number of quadrature points (in the first component) and
the symmetric minimum and maximum values of these points (in the second component). For example, a vector of c(49, 6) indicates 49 rectangular
quadrature points over -6 and 6. The quadrature points are used in the E step of the EM algorithm. Default is c(49, 6).</p>
</td></tr>
<tr><td><code id="est_irt_+3A_weights">weights</code></td>
<td>
<p>A two-column matrix or data frame containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the latent variable prior distribution. If not NULL, the scale of the latent ability distribution will be will be fixed
to the scale of the provided quadrature points and weights. The weights and quadrature points can be easily obtained
using the function <code><a href="#topic+gen.weight">gen.weight</a></code>. If NULL, a normal prior density is used based on the information provided in the arguments
of <code>Quadrature</code>, <code>group.mean</code>, and <code>group.var</code>). Default is NULL.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_group.mean">group.mean</code></td>
<td>
<p>A numeric value to set the mean of latent variable prior distribution when <code>weights = NULL</code>. Default is 0.
This value is fixed to remove the indeterminancy of item parameter scale when calibrating items. However, the scale of prior distribution
is updated when FIPC is implemented.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_group.var">group.var</code></td>
<td>
<p>A positive numeric value to set the variance of latent variable prior distribution when <code>weights = NULL</code>. Default is 1.
This value is fixed to remove the indeterminancy of item parameter scale when calibrating items. However, the scale of prior distribution
is updated when FIPC is implemented.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_emphist">EmpHist</code></td>
<td>
<p>A logical value. If TRUE, the empirical histogram of the latent variable prior distribution is simultaneously estimated with
the item parameters using Woods's (2007) approach. The items are calibrated against the estimated empirical prior distributions.
See below for details.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_use.startval">use.startval</code></td>
<td>
<p>A logical value. If TRUE, the item parameters provided in the item metadata (i.e., the argument <code>x</code>) are used as
the starting values for the item parameter estimation. Otherwise, internal starting values of this function are used. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_etol">Etol</code></td>
<td>
<p>A positive numeric value. This value sets the convergence criterion for E steps of the EM algorithm. Default is 1e-4.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_maxe">MaxE</code></td>
<td>
<p>A positive integer value. This value determines the maximum number of the E steps in the EM algorithm. Default is 500.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_control">control</code></td>
<td>
<p>A list of control parameters to be passed to the optimization function of <code>nlminb()</code> in the <span class="pkg">stats</span> package. The control parameters
set the conditions of M steps of the EM algorithm. For example, the maximum number of iterations in each of the iterative M steps can
be set by <code>control = list(iter.max=200)</code>. Default maximum number of iterations in each M step is 200. See <code>nlminb()</code> in the <span class="pkg">stats</span> package
for other control parameters.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_fipc">fipc</code></td>
<td>
<p>A logical value. If TRUE, FIPC is implemented for item parameter estimation. When <code>fipc = TRUE</code>, the information of which items
are fixed needs to be provided via either <code>fix.loc</code> or <code>fix.id</code>. See below for details.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_fipc.method">fipc.method</code></td>
<td>
<p>A character string specifying the FIPC method. Available methods include &quot;OEM&quot; for &quot;No Prior Weights Updating and One EM Cycle
(NWU-OEM; Wainer &amp; Mislevy, 1990)&quot; and &quot;MEM&quot; for &quot;Multiple Prior Weights Updating and Multiple EM Cycles (MWU-MEM; Kim, 2006).&quot;
When <code>fipc.method = "OEM"</code>, the maximum number of the E steps of the EM algorithm is set to 1 no matter what number is specified
in the argument <code>MaxE</code>.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_fix.loc">fix.loc</code></td>
<td>
<p>A vector of positive integer values specifying the locations of the items to be fixed in the item metadata (i.e., <code>x</code>)
when the FIPC is implemented (i.e., <code>fipc = TRUE</code>). For example, suppose that five items located in the 1st, 2nd, 4th, 7th, and 9th rows
of the item metadata <code>x</code> should be fixed. Then <code>fix.loc = c(1, 2, 4, 7, 9)</code>. Note that when the <code>fix.id</code> argument is not NULL,
the information provided into the <code>fix.loc</code> argument is ignored. See below for details.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_fix.id">fix.id</code></td>
<td>
<p>A vector of character strings specifying IDs of the items to be fixed when the FIPC is implemented (i.e., <code>fipc = TRUE</code>).
For example, suppose that five items in which IDs are CMC1, CMC2, CMC3, CMC4, and CMC5 should be fixed and all item IDs are provided in the <code>X</code>
argument or <code>item.id</code> argument. Then <code>fix.id = c("CMC1", "CMC2", "CMC3", "CMC4", "CMC5")</code>. Note that when the <code>fix.id</code> argument is not NULL,
the information provided into the <code>fix.loc</code> argument is ignored. See below for details.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_se">se</code></td>
<td>
<p>A logical value. If FALSE, the standard errors of the item parameter estimates are not computed. Default is TRUE.</p>
</td></tr>
<tr><td><code id="est_irt_+3A_verbose">verbose</code></td>
<td>
<p>A logical value. If FALSE, all progress messages including the process information on the EM algorithm are suppressed.
Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A specific form of a data frame should be used for the argument <code>x</code>. The first column should have item IDs,
the second column should contain unique score category numbers of the items, and the third column should include IRT models being fit to the items.
The available IRT models are &quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for dichotomous item data, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous item data.
Note that &quot;DRM&quot; covers all dichotomous IRT models (i.e, &quot;1PLM&quot;, &quot;2PLM&quot;, and &quot;3PLM&quot;) and &quot;GRM&quot; and &quot;GPCM&quot; represent the graded
response model and (generalized) partial credit model, respectively. The next columns should include the item parameters of the fitted IRT models.
For dichotomous items, the fourth, fifth, and sixth columns represent the item discrimination (or slope), item difficulty, and
item guessing parameters, respectively. When &quot;1PLM&quot; and &quot;2PLM&quot; are specified in the third column, NAs should be inserted in the sixth column
for the item guessing parameters. For polytomous items, the item discrimination (or slope) parameters should be included in the
fourth column and the item difficulty (or threshold) parameters of category boundaries should be contained from the fifth to the last columns.
When the number of unique score categories differs between items, the empty cells of item parameters should be filled with NAs.
In the <span class="pkg">irtQ</span> package, the item difficulty (or threshold) parameters of category boundaries for GPCM are expressed as
the item location (or overall difficulty) parameter subtracted by the threshold parameter for unique score categories of the item.
Note that when an GPCM item has <em>K</em> unique score categories, <em>K-1</em> item difficulty parameters are necessary because
the item difficulty parameter for the first category boundary is always 0. For example, if an GPCM item has five score categories,
four item difficulty parameters should be specified. An example of a data frame with a single-format test is as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
  ITEM1  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 1PLM </td><td style="text-align: right;"> 1.000 </td><td style="text-align: right;">  1.461 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM2  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 2PLM </td><td style="text-align: right;"> 1.921 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM3  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 1.736 </td><td style="text-align: right;">  1.501 </td><td style="text-align: right;">  0.203 </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM4  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 0.835 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">  0.182 </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM5  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> DRM </td><td style="text-align: right;"> 0.926 </td><td style="text-align: right;">  0.394 </td><td style="text-align: right;">  0.099
</td>
</tr>

</table>

<p>And an example of a data frame for a mixed-format test is as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
  ITEM1  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 1PLM </td><td style="text-align: right;"> 1.000 </td><td style="text-align: right;">  1.461 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM2  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 2PLM </td><td style="text-align: right;"> 1.921 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM3  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 0.926 </td><td style="text-align: right;">  0.394 </td><td style="text-align: right;">  0.099 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM4  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> DRM </td><td style="text-align: right;"> 1.052 </td><td style="text-align: right;"> -0.407 </td><td style="text-align: right;">  0.201 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM5  </td><td style="text-align: right;"> 4 </td><td style="text-align: left;"> GRM  </td><td style="text-align: right;"> 1.913 </td><td style="text-align: right;"> -1.869 </td><td style="text-align: right;"> -1.238 </td><td style="text-align: right;"> -0.714 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM6  </td><td style="text-align: right;"> 5 </td><td style="text-align: left;"> GRM  </td><td style="text-align: right;"> 1.278 </td><td style="text-align: right;"> -0.724 </td><td style="text-align: right;"> -0.068 </td><td style="text-align: right;">  0.568 </td><td style="text-align: right;">  1.072</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM7  </td><td style="text-align: right;"> 4 </td><td style="text-align: left;"> GPCM  </td><td style="text-align: right;"> 1.137 </td><td style="text-align: right;"> -0.374 </td><td style="text-align: right;">  0.215 </td><td style="text-align: right;">  0.848 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM8  </td><td style="text-align: right;"> 5 </td><td style="text-align: left;"> GPCM  </td><td style="text-align: right;"> 1.233 </td><td style="text-align: right;"> -2.078 </td><td style="text-align: right;"> -1.347 </td><td style="text-align: right;"> -0.705 </td><td style="text-align: right;"> -0.116
</td>
</tr>

</table>

<p>See <code>IRT Models</code> section in the page of <code><a href="#topic+irtQ-package">irtQ-package</a></code> for more details about the IRT models used in the <span class="pkg">irtQ</span> package.
An easier way to create a data frame for the argument <code>x</code> is by using the function <code><a href="#topic+shape_df">shape_df</a></code>.
</p>
<p>To fit the IRT models to data, the IRT model and the number of score category information for the estimated items must be provided as well as
the item response data. There are two way to provide the IRT model and score category information. The first way is to provide the item metadata
to the argument <code>x</code>. As explained above, the item metadata can be easily created by the function <code><a href="#topic+shape_df">shape_df</a></code>. The second way is
specify the IRT models and the score category information into the arguments of <code>model</code> and <code>cats</code>. Thus, if <code>x=NULL</code>, the specified
information in <code>model</code> and <code>cats</code> are used.
</p>
<p>To implement FIPC, however, the item metadata must be provided in the argument <code>x</code>. This is because the item parameters of the fixed items
in the item metadata are used to estimate the characteristic of the underlying latent variable prior distribution when calibrating the rest of freely estimated items.
More specifically, the underlying latent variable prior distribution of the fixed items is estimated during the calibration of the freely estimated items
to put the item parameters of the freely estimated items on the scale of the fixed item parameters (Kim, 2006).
</p>
<p>In terms of approaches for FIPC, Kim (2006) described five different methods. Among them, two methods are available in the
function <code><a href="#topic+est_irt">est_irt</a></code>. The first method is &quot;NWU-OEM&quot; where uses just one E step in the EM algorithm, involving data from only the fixed items, and
just one M step, involving data from only non-fixed items. This method is suggested by Wainer and Mislevy (1990) in the context of online calibration. This method
can be implemented by setting <code>fipc.method = "OEM"</code>. The second method is &quot;MWU-MEM&quot; which iteratively updates the latent variable prior distribution and
finds the parameter estimates of the non-fixed items. In this method, the same procedure of NWU-OEM method is applied to the first EM cycle. From the second
EM cycle, both the parameters of non-fixed items and the weights of the prior distribution are concurrently updated. This method can be implemented by
setting <code>fipc.method = "MEM"</code>. See Kim (2006) for more details.
</p>
<p>When <code>fipc = TRUE</code>, the information of which items are fixed needs to be provided via either <code>fix.loc</code> or <code>fix.id</code>. For example, suppose that
five items in which IDs are CMC1, CMC2, CMC3, CMC4, and CMC5 should be fixed and all item IDs are provided in <code>X</code> or <code>item.id</code>. Also, the five items are
located in the 1st through 5th rows of the item metadata (i.e., <code>x</code>). Then the item parameters of the five items can be fixed by setting
<code>fix.loc = c(1, 2, 3, 4, 5)</code> or <code>fix.id = c("CMC1", "CMC2", "CMC3", "CMC4", "CMC5")</code>. Note that if both arguments are not NULL, the information
provided into the <code>fix.loc</code> argument is ignored.
</p>
<p>When <code>EmpHist = TRUE</code>, the empirical histogram (i.e., densities at the quadrature points) of latent variable prior distribution is simultaneously estimated
with the item parameters. If <code>fipc = TRUE</code> given <code>EmpHist = TRUE</code>, the scale parameters (e.g., mean and variance) of the empirical prior distribution
are estimated as well. If <code>fipc = FALSE</code> given <code>EmpHist = TRUE</code>, the scale parameters of the empirical prior distribution are fixed to the values specified
in the arguments of <code>group.mean</code> and <code>group.var</code>. When <code>EmpHist = FALSE</code>, the normal prior distribution is used during the item parameter estimation.
If <code>fipc = TRUE</code> given <code>EmpHist = FALSE</code>, the scale parameters of the normal prior distribution are estimated as well as the item parameters.
If <code>fipc = FALSE</code> given <code>EmpHist = FALSE</code>, the scale parameters of the normal prior distribution are fixed to the values specified in the arguments
of <code>group.mean</code> and <code>group.var</code>.
</p>


<h3>Value</h3>

<p>This function returns an object of class <code><a href="#topic+est_irt">est_irt</a></code>. Within this object, several internal objects are contained such as:
</p>
<table>
<tr><td><code>estimates</code></td>
<td>
<p>A data frame containing both the item parameter estimates and the corresponding standard errors of estimates.</p>
</td></tr>
<tr><td><code>par.est</code></td>
<td>
<p>A data frame containing the item parameter estimates.</p>
</td></tr>
<tr><td><code>se.est</code></td>
<td>
<p>A data frame containing the standard errors of the item parameter estimates. Note that the standard errors are estimated
using the cross-production approximation method (Meilijson, 1989).</p>
</td></tr>
<tr><td><code>pos.par</code></td>
<td>
<p>A data frame containing the position number of each item parameter being estimated. The position information is useful
when interpreting the variance-covariance matrix of item parameter estimates.</p>
</td></tr>
<tr><td><code>covariance</code></td>
<td>
<p>A matrix of variance-covariance matrix of item parameter estimates.</p>
</td></tr>
<tr><td><code>loglikelihood</code></td>
<td>
<p>A sum of the log-likelihood values of the observed data set (marginal log-likelihood) across all items in the data set</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>A model fit statistic of Akaike information criterion based on the loglikelihood.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>A model fit statistic of Bayesian information criterion based on the loglikelihood.</p>
</td></tr>
<tr><td><code>group.par</code></td>
<td>
<p>A data frame containing the mean, variance, and standard deviation of latent variable prior distribution.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>A two-column data frame containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the (updated) latent variable prior distribution.</p>
</td></tr>
<tr><td><code>posterior.dist</code></td>
<td>
<p>A matrix of normalized posterior densities for all the response patterns at each of the quadrature points.
The row and column indicate each individual's response pattern and the quadrature point, respectively.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>A data.frame of the examinees' response data set.</p>
</td></tr>
<tr><td><code>scale.D</code></td>
<td>
<p>A scaling factor in IRT models.</p>
</td></tr>
<tr><td><code>ncase</code></td>
<td>
<p>A total number of response patterns.</p>
</td></tr>
<tr><td><code>nitem</code></td>
<td>
<p>A total number of items included in the response data.</p>
</td></tr>
<tr><td><code>Etol</code></td>
<td>
<p>A convergence criteria for E steps of the EM algorithm.</p>
</td></tr>
<tr><td><code>MaxE</code></td>
<td>
<p>The maximum number of E steps in the EM algorithm.</p>
</td></tr>
<tr><td><code>aprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item slope parameters.</p>
</td></tr>
<tr><td><code>gprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item guessing parameters.</p>
</td></tr>
<tr><td><code>npar.est</code></td>
<td>
<p>A total number of the estimated parameters.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>The number of EM cycles completed.</p>
</td></tr>
<tr><td><code>maxpar.diff</code></td>
<td>
<p>A maximum item parameter change when the EM cycles were completed.</p>
</td></tr>
<tr><td><code>EMtime</code></td>
<td>
<p>Time (in seconds) spent for the EM cycles.</p>
</td></tr>
<tr><td><code>SEtime</code></td>
<td>
<p>Time (in seconds) spent for computing the standard errors of the item parameter estimates.</p>
</td></tr>
<tr><td><code>TotalTime</code></td>
<td>
<p>Time (in seconds) spent for total compuatation.</p>
</td></tr>
<tr><td><code>test.1</code></td>
<td>
<p>Status of the first-order test to report if the gradients has vanished sufficiently for the solution to be stable.</p>
</td></tr>
<tr><td><code>test.2</code></td>
<td>
<p>Status of the second-order test to report if the information matrix is positive definite, which is a prerequisite
for the solution to be a possible maximum.</p>
</td></tr>
<tr><td><code>var.note</code></td>
<td>
<p>A note to report if the variance-covariance matrix of item parameter estimates is obtainable from the information matrix.</p>
</td></tr>
<tr><td><code>fipc</code></td>
<td>
<p>A logical value to indicate if FIPC was used.</p>
</td></tr>
<tr><td><code>fipc.method</code></td>
<td>
<p>A method used for the FIPC.</p>
</td></tr>
<tr><td><code>fix.loc</code></td>
<td>
<p>A vector of integer values specifying the locations of the fixed items when the FIPC was implemented.</p>
</td></tr>
</table>
<p>The internal objects can be easily extracted using the function <code><a href="#topic+getirt">getirt</a></code>.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Ban, J. C., Hanson, B. A., Wang, T., Yi, Q., &amp; Harris, D., J. (2001) A comparative study of on-line pretest item calibration/scaling methods
in computerized adaptive testing. <em>Journal of Educational Measurement, 38</em>(3), 191-212.
</p>
<p>Bock, R. D., &amp; Aitkin, M. (1981). Marginal maximum likelihood estimation of item parameters: Application of an EM algorithm.
<em>Psychometrika, 46</em>, 443-459.
</p>
<p>Kim, S. (2006). A comparative study of IRT fixed parameter calibration methods.
<em>Journal of Educational Measurement, 43</em>(4), 355-381.
</p>
<p>Meilijson, I. (1989). A fast improvement to the EM algorithm on its own terms.
<em>Journal of the Royal Statistical Society: Series B (Methodological), 51</em>, 127-138.
</p>
<p>Stocking, M. L. (1988). <em>Scale drift in on-line calibration</em> (Research Rep. 88-28). Princeton, NJ: ETS.
</p>
<p>Wainer, H., &amp; Mislevy, R. J. (1990). Item response theory, item calibration, and proficiency estimation. In H. Wainer (Ed.),
<em>Computer adaptive testing: A primer</em> (Chap. 4, pp.65-102). Hillsdale, NJ: Lawrence Erlbaum.
</p>
<p>Woods, C. M. (2007). Empirical histograms in item response theory with ordinal data. <em>Educational and Psychological Measurement, 67</em>(1), 73-87.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+est_item">est_item</a></code>, <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>, <code><a href="#topic+simdat">simdat</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>, <code><a href="#topic+sx2_fit">sx2_fit</a></code>,
<code><a href="#topic+traceline.est_irt">traceline.est_irt</a></code>, <code><a href="#topic+getirt">getirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

##------------------------------------------------------------------------------
# 1. item parameter estimation for the dichotomous item data (LSAT6)
##------------------------------------------------------------------------------
# fit the 1PL model to LSAT6 data and constrain the slope parameters to be equal
(mod.1pl.c &lt;- est_irt(data=LSAT6, D=1, model="1PLM", cats=2, fix.a.1pl=FALSE))

# summary of the estimation
summary(mod.1pl.c)

# extract the item parameter estimates
getirt(mod.1pl.c, what="par.est")

# extract the standard error estimates
getirt(mod.1pl.c, what="se.est")

# fit the 1PL model to LSAT6 data and fix the slope parameters to 1.0
(mod.1pl.f &lt;- est_irt(data=LSAT6, D=1, model="1PLM", cats=2, fix.a.1pl=TRUE, a.val.1pl=1))

# summary of the estimation
summary(mod.1pl.f)

# fit the 2PL model to LSAT6 data
(mod.2pl &lt;- est_irt(data=LSAT6, D=1, model="2PLM", cats=2))

# summary of the estimation
summary(mod.2pl)

# assess the fit of the 2PL model to the LSAT5 data using S-X2 fit statistic
(sx2fit.2pl &lt;- sx2_fit(x=mod.2pl))

# compute the item and test information at several theta points
theta &lt;- seq(-4, 4, 0.1)
(info.2pl &lt;- info(x=mod.2pl, theta=theta))

# draw the test characteristic curve plot
(trace.2pl &lt;- traceline(x=mod.2pl, theta=theta))
plot(trace.2pl)

# draw the item characteristic curve for the 1st item
plot(trace.2pl, item.loc=1)

# fit the 2PL model to LSAT6 data and
# estimate the empirical histogram of latent variable prior distribution
# also use a less stringent convergence criterion for E-step
(mod.2pl.hist &lt;- est_irt(data=LSAT6, D=1, model="2PLM", cats=2, EmpHist=TRUE, Etol=0.001))
(emphist &lt;- getirt(mod.2pl.hist, what="weights"))
plot(emphist$weight ~ emphist$theta, type="h")

# fit the 3PL model to LSAT6 data and use the Beta prior distribution for
# the guessing parameters
(mod.3pl &lt;- est_irt(data=LSAT6, D=1, model="3PLM", cats=2, use.gprior=TRUE,
                    gprior=list(dist="beta", params=c(5, 16))))

# summary of the estimation
summary(mod.3pl)

# fit the 3PL model to LSAT6 data, but fix the guessing parameters to be 0.2
(mod.3pl.f &lt;- est_irt(data=LSAT6, D=1, model="3PLM", cats=2, fix.g=TRUE, g.val=0.2))

# summary of the estimation
summary(mod.3pl.f)

# fit the different dichotomous models to each item of LSAT6 data
# fit the constrained 1PL model to the 1st, 2nd, and 3rd items, fit the 2PL model to
# the 4th item, and fit the 3PL model to the 5th item with the Beta prior of
# the guessing parameter
(mod.drm.mix &lt;- est_irt(data=LSAT6, D=1, model=c("1PLM", "1PLM", "1PLM", "2PLM", "3PLM"),
                        cats=2, fix.a.1pl=FALSE, use.gprior=TRUE,
                        gprior=list(dist="beta", params=c(5, 16))))
# summary of the estimation
summary(mod.drm.mix)

##------------------------------------------------------------------------------
# 2. item parameter estimation for the mixed-item format data (simulation data)
##------------------------------------------------------------------------------
## import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select the item metadata
x &lt;- bring.flexmirt(file=flex_sam, "par")$Group1$full_df

# modify the item metadata so that the 39th and 40th items follow GPCM
x[39:40, 3] &lt;- "GPCM"

# generate 1,000 examinees' latent abilities from N(0, 1)
set.seed(37)
score1 &lt;- rnorm(1000, mean=0, sd=1)

# simulate the response data
sim.dat1 &lt;- simdat(x=x, theta=score1, D=1)

# fit the 3PL model to all dichotomous items, fit the GPCM model to 39th and 40th items,
# and fit the GRM model to the 53th, 54th, 55th items.
# use the beta prior distribution for the guessing parameters, use the log-normal
# prior distribution for the slope parameters, and use the normal prior distribution
# for the difficulty (or threshold) parameters.
# also, specify the argument 'x' to provide the IRT model and score category information
# for items
item.meta &lt;- shape_df(item.id=x$id, cats=x$cats, model=x$model, default.par=TRUE)
(mod.mix1 &lt;- est_irt(x=item.meta, data=sim.dat1, D=1, use.aprior=TRUE, use.bprior=TRUE,
                     use.gprior=TRUE,
                     aprior=list(dist="lnorm", params=c(0.0, 0.5)),
                     bprior=list(dist="norm", params=c(0.0, 2.0)),
                     gprior=list(dist="beta", params=c(5, 16))))

# summary of the estimation
summary(mod.mix1)

# estimate examinees' latent scores given the item parameter estimates using the MLE
(score.mle &lt;- est_score(x=mod.mix1, method = "ML", range = c(-4, 4), ncore=2))

# compute the traditional fit statistics
(fit.mix1 &lt;- irtfit(x=mod.mix1, score=score.mle$est.theta, group.method="equal.width",
                    n.width=10, loc.theta="middle"))

# residual plots for the first item (dichotomous item)
plot(x=fit.mix1, item.loc=1, type = "both", ci.method = "wald",
     show.table=TRUE, ylim.sr.adjust=TRUE)

# residual plots for the last item (polytomous item)
plot(x=fit.mix1, item.loc=55, type = "both", ci.method = "wald",
     show.table=FALSE, ylim.sr.adjust=TRUE)

# fit the 2PL model to all dichotomous items, fit the GPCM model to 39th and 40th items,
# and fit the GRM model to the 53th, 54th, 55th items.
# also, specify the arguments of 'model' and 'cats' to provide the IRT model and
# score category information for items
(mod.mix2 &lt;- est_irt(data=sim.dat1, D=1,
                     model=c(rep("2PLM", 38), rep("GPCM", 2), rep("2PLM", 12), rep("GRM", 3)),
                     cats=c(rep(2, 38), rep(5, 2), rep(2, 12), rep(5, 3))))

# summary of the estimation
summary(mod.mix2)

# fit the 2PL model to all dichotomous items, fit the GPCM model to 39th and 40th items,
# fit the GRM model to the 53th, 54th, 55th items, and estimate the empirical histogram
# of latent variable prior distribution.
# also, specify the arguments of 'model' and 'cats' to provide the IRT model and
# score category information for items
(mod.mix3 &lt;- est_irt(data=sim.dat1, D=1,
                     model=c(rep("2PLM", 38), rep("GPCM", 2), rep("2PLM", 12), rep("GRM", 3)),
                     cats=c(rep(2, 38), rep(5, 2), rep(2, 12), rep(5, 3)), EmpHist=TRUE))
(emphist &lt;- getirt(mod.mix3, what="weights"))
plot(emphist$weight ~ emphist$theta, type="h")

# fit the 2PL model to all dichotomous items,
# fit the PCM model to 39th and 40th items by fixing the slope parameters to 1,
# and fit the GRM model to the 53th, 54th, 55th items.
# also, specify the arguments of 'model' and 'cats' to provide the IRT model and
# score category information for items
(mod.mix4 &lt;- est_irt(data=sim.dat1, D=1,
                     model=c(rep("2PLM", 38), rep("GPCM", 2), rep("2PLM", 12), rep("GRM", 3)),
                     cats=c(rep(2, 38), rep(5, 2), rep(2, 12), rep(5, 3)),
                     fix.a.gpcm=TRUE, a.val.gpcm=1))

# summary of the estimation
summary(mod.mix4)

##------------------------------------------------------------------------------
# 3. fixed item parameter calibration (FIPC) for the mixed-item format data
#    (simulation data)
##------------------------------------------------------------------------------
## import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select the item metadata
x &lt;- bring.flexmirt(file=flex_sam, "par")$Group1$full_df

# generate 1,000 examinees' latent abilities from N(0.4, 1.3)
set.seed(20)
score2 &lt;- rnorm(1000, mean=0.4, sd=1.3)

# simulate the response data
sim.dat2 &lt;- simdat(x=x, theta=score2, D=1)

# fit the 3PL model to all dichotomous items, fit the GRM model to all polytomous data,
# fix the five 3PL items (1st - 5th items) and three GRM items (53rd to 55th items)
# also, estimate the empirical histogram of latent variable
# use the MEM method.
fix.loc &lt;- c(1:5, 53:55)
(mod.fix1 &lt;- est_irt(x=x, data=sim.dat2, D=1, use.gprior=TRUE,
                     gprior=list(dist="beta", params=c(5, 16)), EmpHist=TRUE,
                     Etol=1e-3, fipc=TRUE, fipc.method="MEM", fix.loc=fix.loc))
(prior.par &lt;- mod.fix1$group.par)
(emphist &lt;- getirt(mod.fix1, what="weights"))
plot(emphist$weight ~ emphist$theta, type="h")

# summary of the estimation
summary(mod.fix1)

# or the same five items can be fixed by providing their item IDs to the 'fix.id' argument
# in this case, set fix.loc = NULL
fix.id &lt;- c(x$id[1:5], x$id[53:55])
(mod.fix1 &lt;- est_irt(x=x, data=sim.dat2, D=1, use.gprior=TRUE,
                     gprior=list(dist="beta", params=c(5, 16)), EmpHist=TRUE,
                     Etol=1e-3, fipc=TRUE, fipc.method="MEM", fix.loc=NULL,
                     fix.id=fix.id))

# summary of the estimation
summary(mod.fix1)

# fit the 3PL model to all dichotomous items, fit the GRM model to all polytomous data,
# fix the five 3PL items (1st - 5th items) and three GRM items (53rd to 55th items)
# at this moment, do estimate the empirical histogram of latent variable.
# instead, estimate the scale of normal prior distribution of latent variable
# use the MEM method.
fix.loc &lt;- c(1:5, 53:55)
(mod.fix2 &lt;- est_irt(x=x, data=sim.dat2, D=1, use.gprior=TRUE,
                     gprior=list(dist="beta", params=c(5, 16)), EmpHist=FALSE,
                     Etol=1e-3, fipc=TRUE, fipc.method="MEM", fix.loc=fix.loc))
(prior.par &lt;- mod.fix2$group.par)
(emphist &lt;- getirt(mod.fix2, what="weights"))
plot(emphist$weight ~ emphist$theta, type="h")

# fit the 3PL model to all dichotomous items, fit the GRM model to all polytomous data,
# at this moment fix only the five 3PL items (1st - 5th items)
# and estimate the empirical histogram of latent variable.
# use the OEM method. Thus, only 1 EM cycle is used.
fix.loc &lt;- c(1:5)
(mod.fix3 &lt;- est_irt(x=x, data=sim.dat2, D=1, use.gprior=TRUE,
                     gprior=list(dist="beta", params=c(5, 16)), EmpHist=TRUE,
                     Etol=1e-3, fipc=TRUE, fipc.method="OEM", fix.loc=fix.loc))
(prior.par &lt;- mod.fix3$group.par)
(emphist &lt;- getirt(mod.fix3, what="weights"))
plot(emphist$weight ~ emphist$theta, type="h")

# summary of the estimation
summary(mod.fix3)

# fit the 3PL model to all dichotomous items, fit the GRM model to all polytomous data,
# at this moment fix all 55 items and estimate only the latent ability distribution
# using the MEM method.
fix.loc &lt;- c(1:55)
(mod.fix4 &lt;- est_irt(x=x, data=sim.dat2, D=1, EmpHist=TRUE,
                     Etol=1e-3, fipc=TRUE, fipc.method="MEM", fix.loc=fix.loc))
(prior.par &lt;- mod.fix4$group.par)
(emphist &lt;- getirt(mod.fix4, what="weights"))
plot(emphist$weight ~ emphist$theta, type="h")

# summary of the estimation
summary(mod.fix4)

# or all 55 items can be fixed by providing their item IDs to the 'fix.id' argument
# in this case, set fix.loc = NULL
fix.id &lt;- x$id
(mod.fix4 &lt;- est_irt(x=x, data=sim.dat2, D=1, EmpHist=TRUE,
                     Etol=1e-3, fipc=TRUE, fipc.method="MEM", fix.loc=NULL,
                     fix.id=fix.id))

# summary of the estimation
summary(mod.fix4)



</code></pre>

<hr>
<h2 id='est_item'>Fixed ability parameter calibration</h2><span id='topic+est_item'></span>

<h3>Description</h3>

<p>This function performs the fixed ability parameter calibration (FAPC), often called
Method A, which is the maximum likelihood estimation of item parameters given the ability
estimates (Baker &amp; Kim, 2004; Ban, Hanson, Wang, Yi, &amp; Harris, 2001; Stocking, 1988). Also, this could be
considered as a special type of the joint maximum likelihood estimation where only one cycle of parameter
estimation is implemented given the ability estimates (Birnbaum, 1968). FAPC is one of potentially useful
online item calibration methods for computerized adaptive testing (CAT) to put the parameter estimates of
pretest items on the same scale of operational item parameter estimates and recalibrate the operational
items to evaluate the parameter drifts of the operational items (Chen &amp; Wang, 2016; Stocking, 1988).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_item(
  x = NULL,
  data,
  score,
  D = 1,
  model = NULL,
  cats = NULL,
  item.id = NULL,
  fix.a.1pl = FALSE,
  fix.a.gpcm = FALSE,
  fix.g = FALSE,
  a.val.1pl = 1,
  a.val.gpcm = 1,
  g.val = 0.2,
  use.aprior = FALSE,
  use.bprior = FALSE,
  use.gprior = TRUE,
  aprior = list(dist = "lnorm", params = c(0, 0.5)),
  bprior = list(dist = "norm", params = c(0, 1)),
  gprior = list(dist = "beta", params = c(5, 17)),
  missing = NA,
  use.startval = FALSE,
  control = list(eval.max = 500, iter.max = 500),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est_item_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata. This metadata is necessary to obtain the information of
each item (i.e., number of score categories and IRT model) to be calibrated. You can easily create an empty
item metadata using the function <code><a href="#topic+shape_df">shape_df</a></code>. When <code>use.startval = TRUE</code>, the item parameters
specified in the item metadata are used as the starting values for the item parameter estimation.
If <code>x = NULL</code>, the arguments of <code>model</code> and <code>cats</code> must be specified. See <code><a href="#topic+irtfit">irtfit</a></code>,
<code><a href="#topic+info">info</a></code> or <code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_item_+3A_data">data</code></td>
<td>
<p>A matrix containing examinees' response data for the items in the argument <code>x</code>. A row and column indicate
the examinees and items, respectively.</p>
</td></tr>
<tr><td><code id="est_item_+3A_score">score</code></td>
<td>
<p>A vector of examinees' ability estimates. Length of the vector must be the same as the number of rows in the
response data set.</p>
</td></tr>
<tr><td><code id="est_item_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="est_item_+3A_model">model</code></td>
<td>
<p>A vector of character strings indicating what IRT model is used to calibrate each item. Available IRT models are
&quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for dichotomous items, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous items. &quot;GRM&quot; and &quot;GPCM&quot; represent the graded
response model and (generalized) partial credit model, respectively. Note that &quot;DRM&quot; is considered as &quot;3PLM&quot; in this function.
If a single character of the IRT model is specified, that model will be recycled across all items. The provided information in the <code>model</code>
argument is used only when <code>x = NULL</code>. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_item_+3A_cats">cats</code></td>
<td>
<p>A numeric vector specifying the number of score categories for each item. For example, a dichotomous
item has two score categories. If a single numeric value is specified, that value will be recycled across all items. If <code>cats = NULL</code>
and all specified models in the <code>model</code> argument are the dichotomous models (i.e., 1PLM, 2PLM, 3PLM, or DRM), it assumes
that all items have two score categories. The provided information in the <code>cats</code> argument is used only when <code>x = NULL</code>.
Default is NULL.</p>
</td></tr>
<tr><td><code id="est_item_+3A_item.id">item.id</code></td>
<td>
<p>A character vector of item IDs. If NULL, the item IDs are generated automatically. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_item_+3A_fix.a.1pl">fix.a.1pl</code></td>
<td>
<p>A logical value. If TRUE, the slope parameters of the 1PLM items are fixed to a specific value specified in the argument
<code>a.val.1pl</code>. Otherwise, the slope parameters of all 1PLM items are constrained to be equal and estimated. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_item_+3A_fix.a.gpcm">fix.a.gpcm</code></td>
<td>
<p>A logical value. If TRUE, the GPCM items are calibrated with the partial credit model and the slope parameters of
the GPCM items are fixed to a specific value specified in the argument <code>a.val.gpcm</code>. Otherwise, the slope parameter of each GPCM item
is estimated. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_item_+3A_fix.g">fix.g</code></td>
<td>
<p>A logical value. If TRUE, the guessing parameters of the 3PLM items are fixed to a specific value specified in the argument
<code>g.val</code>. Otherwise, the guessing parameter of each 3PLM item is estimated. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_item_+3A_a.val.1pl">a.val.1pl</code></td>
<td>
<p>A numeric value. This value is used to fixed the slope parameters of the 1PLM items.</p>
</td></tr>
<tr><td><code id="est_item_+3A_a.val.gpcm">a.val.gpcm</code></td>
<td>
<p>A numeric value. This value is used to fixed the slope parameters of the GPCM items.</p>
</td></tr>
<tr><td><code id="est_item_+3A_g.val">g.val</code></td>
<td>
<p>A numeric value. This value is used to fixed the guessing parameters of the 3PLM items.</p>
</td></tr>
<tr><td><code id="est_item_+3A_use.aprior">use.aprior</code></td>
<td>
<p>A logical value. If TRUE, a prior distribution for the slope parameters is used for the parameter calibration
across all items. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_item_+3A_use.bprior">use.bprior</code></td>
<td>
<p>A logical value. If TRUE, a prior distribution for the difficulty (or threshold) parameters is used for the parameter calibration
across all items. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_item_+3A_use.gprior">use.gprior</code></td>
<td>
<p>A logical value. If TRUE, a prior distribution for the guessing parameters is used for the parameter calibration
across all 3PLM items. Default is TRUE.</p>
</td></tr>
<tr><td><code id="est_item_+3A_aprior">aprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item slope parameters. Three probability distributions
of Beta, Log-normal, and Normal distributions are available. In the list, a character string of the distribution name must be specified
in the first internal argument and a vector of two numeric values for the two parameters of the distribution must be specified in the
second internal argument. Specifically, when Beta distribution is used, &quot;beta&quot; should be specified in the first argument. When Log-normal
distribution is used, &quot;lnorm&quot; should be specified in the first argument. When Normal distribution is used, &quot;norm&quot; should be specified
in the first argument. In terms of the two parameters of the three distributions, see <code>dbeta()</code>, <code>dlnorm()</code>,
and <code>dnorm()</code> in the <span class="pkg">stats</span> package for more details.</p>
</td></tr>
<tr><td><code id="est_item_+3A_bprior">bprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item difficulty (or threshold) parameters. Three probability distributions
of Beta, Log-normal, and Normal distributions are available. In the list, a character string of the distribution name must be specified
in the first internal argument and a vector of two numeric values for the two parameters of the distribution must be specified in the
second internal argument. Specifically, when Beta distribution is used, &quot;beta&quot; should be specified in the first argument. When Log-normal
distribution is used, &quot;lnorm&quot; should be specified in the first argument. When Normal distribution is used, &quot;norm&quot; should be specified
in the first argument. In terms of the two parameters of the three distributions, see <code>dbeta()</code>, <code>dlnorm()</code>,
and <code>dnorm()</code> in the <span class="pkg">stats</span> package for more details.</p>
</td></tr>
<tr><td><code id="est_item_+3A_gprior">gprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item guessing parameters. Three probability distributions
of Beta, Log-normal, and Normal distributions are available. In the list, a character string of the distribution name must be specified
in the first internal argument and a vector of two numeric values for the two parameters of the distribution must be specified in the
second internal argument. Specifically, when Beta distribution is used, &quot;beta&quot; should be specified in the first argument. When Log-normal
distribution is used, &quot;lnorm&quot; should be specified in the first argument. When Normal distribution is used, &quot;norm&quot; should be specified
in the first argument. In terms of the two parameters of the three distributions, see <code>dbeta()</code>, <code>dlnorm()</code>,
and <code>dnorm()</code> in the <span class="pkg">stats</span> package for more details.</p>
</td></tr>
<tr><td><code id="est_item_+3A_missing">missing</code></td>
<td>
<p>A value indicating missing values in the response data set. Default is NA.</p>
</td></tr>
<tr><td><code id="est_item_+3A_use.startval">use.startval</code></td>
<td>
<p>A logical value. If TRUE, the item parameters provided in the item metadata (i.e., the argument <code>x</code>) are used as
the starting values for the item parameter estimation. Otherwise, internal starting values of this function are used. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_item_+3A_control">control</code></td>
<td>
<p>A list of control parameters to be passed to the optimization function of <code>nlminb()</code> in the <span class="pkg">stats</span> package. The control parameters
set the conditions of the item parameter estimation process such as the maximum number of iterations. See <code>nlminb()</code> in the <span class="pkg">stats</span> package for details.</p>
</td></tr>
<tr><td><code id="est_item_+3A_verbose">verbose</code></td>
<td>
<p>A logical value. If FALSE, all progress messages are suppressed. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In most cases, the function <code><a href="#topic+est_item">est_item</a></code> will return successfully converged item parameter estimates using
the default internal starting values. However, if there is a convergence problem in the calibration, one possible solution is using
different starting values. When the item parameter values are specified in the item metadata (i.e., the argument <code>x</code>), those values
can be used as the starting values for the item parameter calibration by setting <code>use.startval = TRUE</code>.
</p>


<h3>Value</h3>

<p>This function returns an object of class <code><a href="#topic+est_item">est_item</a></code>. Within this object, several internal objects are contained such as:
</p>
<table>
<tr><td><code>estimates</code></td>
<td>
<p>A data frame containing both the item parameter estimates and the corresponding standard errors of estimates.</p>
</td></tr>
<tr><td><code>par.est</code></td>
<td>
<p>A data frame containing the item parameter estimates.</p>
</td></tr>
<tr><td><code>se.est</code></td>
<td>
<p>A data frame containing the standard errors of the item parameter estimates. Note that the standard errors are estimated using
observed information functions.</p>
</td></tr>
<tr><td><code>pos.par</code></td>
<td>
<p>A data frame containing the position number of item parameters being estimated. The position information is useful
when interpreting the variance-covariance matrix of item parameter estimates.</p>
</td></tr>
<tr><td><code>covariance</code></td>
<td>
<p>A matrix of variance-covariance matrix of item parameter estimates.</p>
</td></tr>
<tr><td><code>loglikelihood</code></td>
<td>
<p>A sum of the log-likelihood values of the complete data set across all estimated items.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>A data frame of the examinees' response data set.</p>
</td></tr>
<tr><td><code>score</code></td>
<td>
<p>A vector of the examinees' ability values used as the fixed effects.</p>
</td></tr>
<tr><td><code>scale.D</code></td>
<td>
<p>A scaling factor in IRT models.</p>
</td></tr>
<tr><td><code>convergence</code></td>
<td>
<p>A string indicating the convergence status of the item parameter estimation.</p>
</td></tr>
<tr><td><code>nitem</code></td>
<td>
<p>A total number of items included in the response data.</p>
</td></tr>
<tr><td><code>deleted.item</code></td>
<td>
<p>The items which have no item response data. Those items are excluded from the item parameter estimation.</p>
</td></tr>
<tr><td><code>npar.est</code></td>
<td>
<p>A total number of the estimated parameters.</p>
</td></tr>
<tr><td><code>n.response</code></td>
<td>
<p>An integer vector indicating the number of item responses for each item used to estimate the item parameters.</p>
</td></tr>
<tr><td><code>TotalTime</code></td>
<td>
<p>Time (in seconds) spent for total compuatation.</p>
</td></tr>
</table>
<p>The internal objects can be easily extracted using the function <code><a href="#topic+getirt">getirt</a></code>.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Baker, F. B., &amp; Kim, S. H. (2004). <em>Item response theory: Parameter estimation techniques.</em> CRC Press.
</p>
<p>Ban, J. C., Hanson, B. A., Wang, T., Yi, Q., &amp; Harris, D., J. (2001) A comparative study of on-line pretest item calibration/scaling methods
in computerized adaptive testing. <em>Journal of Educational Measurement, 38</em>(3), 191-212.
</p>
<p>Birnbaum, A. (1968). Some latent trait models and their use in inferring an examinee's ability. In F. M. Lord &amp; M. R. Novick (Eds.),
<em>Statistical theories of mental test scores</em> (pp. 397-479). Reading, MA: Addison-Wesley.
</p>
<p>Chen, P., &amp; Wang, C. (2016). A new online calibration method for multidimensional computerized adaptive testing.
<em>Psychometrika, 81</em>(3), 674-701.
</p>
<p>Stocking, M. L. (1988). <em>Scale drift in on-line calibration</em> (Research Rep. 88-28). Princeton, NJ: ETS.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>, <code><a href="#topic+simdat">simdat</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>, <code><a href="#topic+sx2_fit">sx2_fit</a></code>,
<code><a href="#topic+traceline.est_item">traceline.est_item</a></code>, <code><a href="#topic+getirt">getirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select the item metadata
x &lt;- bring.flexmirt(file=flex_sam, "par")$Group1$full_df

# modify the item metadata so that some items follow 1PLM, 2PLM and GPCM
x[c(1:3, 5), 3] &lt;- "1PLM"
x[c(1:3, 5), 4] &lt;- 1
x[c(1:3, 5), 6] &lt;- 0
x[c(4, 8:12), 3] &lt;- "2PLM"
x[c(4, 8:12), 6] &lt;- 0
x[54:55, 3] &lt;- "GPCM"

# generate examinees' abilities from N(0, 1)
set.seed(23)
score &lt;- rnorm(500, mean=0, sd=1)

# simulate the response data
data &lt;- simdat(x=x, theta=score, D=1)


# 1) item parameter estimation: constrain the slope parameters of the 1PLM to be equal
(mod1 &lt;- est_item(x, data, score, D=1, fix.a.1pl=FALSE, use.gprior=TRUE,
                  gprior=list(dist="beta", params=c(5, 17)), use.startval=FALSE))
summary(mod1)

# extract the item parameter estimates
getirt(mod1, what="par.est")

# 2) item parameter estimation: fix the slope parameters of the 1PLM to 1
(mod2 &lt;- est_item(x, data, score, D=1, fix.a.1pl=TRUE, a.val.1pl=1, use.gprior=TRUE,
                  gprior=list(dist="beta", params=c(5, 17)), use.startval=FALSE))
summary(mod2)

# extract the standard error estimates
getirt(mod2, what="se.est")

# 3) item parameter estimation: fix the guessing parameters of the 3PLM to 0.2
(mod3 &lt;- est_item(x, data, score, D=1, fix.a.1pl=TRUE, fix.g=TRUE, a.val.1pl=1, g.val=.2,
                  use.startval=FALSE))
summary(mod3)

# extract both item parameter and standard error estimates
getirt(mod2, what="estimates")



</code></pre>

<hr>
<h2 id='est_mg'>Multiple-group item calibration using MMLE-EM algorithm</h2><span id='topic+est_mg'></span>

<h3>Description</h3>

<p>This function conducts a multiple-group item calibration (Bock &amp; Zimowski, 1997) using the marginal maximum likelihood estimation via
the expectation-maximization (MMLE-EM) algorithm (Bock &amp; Aitkin, 1981). This function also implements the multiple-group fixed item parameter
calibration (MG-FIPC; e.g., Kim &amp; Kolen, 2016). The MG-FIPC is an extension of the single-group FIPC method (Kim, 2006) to multiple-group data.
For dichotomous items, IRT one-, two-, and three-parameter logistic models are available. For polytomous items, the graded response
model (GRM) and the (generalized) partial credit model (GPCM) are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_mg(
  x = NULL,
  data,
  group.name = NULL,
  D = 1,
  model = NULL,
  cats = NULL,
  item.id = NULL,
  free.group = NULL,
  fix.a.1pl = FALSE,
  fix.a.gpcm = FALSE,
  fix.g = FALSE,
  a.val.1pl = 1,
  a.val.gpcm = 1,
  g.val = 0.2,
  use.aprior = FALSE,
  use.bprior = FALSE,
  use.gprior = TRUE,
  aprior = list(dist = "lnorm", params = c(0, 0.5)),
  bprior = list(dist = "norm", params = c(0, 1)),
  gprior = list(dist = "beta", params = c(5, 16)),
  missing = NA,
  Quadrature = c(49, 6),
  weights = NULL,
  group.mean = 0,
  group.var = 1,
  EmpHist = FALSE,
  use.startval = FALSE,
  Etol = 0.001,
  MaxE = 500,
  control = list(eval.max = 200, iter.max = 200),
  fipc = FALSE,
  fipc.method = "MEM",
  fix.loc = NULL,
  fix.id = NULL,
  se = TRUE,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est_mg_+3A_x">x</code></td>
<td>
<p>A list containing item metadata across all groups to be analyzed. For example, if five group data are analyzed, the list should include
five internal objects of the item metadata for the five groups. The internal objects of the list should be ordered in accordance with the order of the group names
specified in the <code>group.name</code> argument. An item metadata of each group test from contains the meta information about items (i.e., number
of score categories and IRT model) to be calibrated. See <code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>
or <code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata. When <code>use.startval = TRUE</code>, the item parameters specified in
the item metadata are used as the starting values for the item parameter estimation. If <code>x = NULL</code>, the <code>model</code> and <code>cats</code> arguments
must be specified. Note that when <code>fipc = TRUE</code> to implement the MG-FIPC method, a list of item metadata must be provided into <code>x</code>. In other words,
<code>x</code> cannot be NULL in that case. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_data">data</code></td>
<td>
<p>A list containing item response matrices across all groups to be analyzed. For example, if five group data are analyzed, the list should include
five internal objects of the response data matrices for the five groups. The internal objects of the list should be ordered in accordance with the order of the group names
specified in the <code>group.name</code> argument. An item response matrix for each group includes examinees' response data corresponding to
the items in the item metadata of that group. In a response data matrix, a row and column indicate the examinees and items, respectively.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_group.name">group.name</code></td>
<td>
<p>A vector of character strings indicating group names. For example, if five group data are analyzed, <code>group.names = c("G1", "G2", "G3", "G4", "G5")</code>.
Any group names can be used.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_d">D</code></td>
<td>
<p>D A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_model">model</code></td>
<td>
<p>A list containing character vectors of the IRT models used to calibrate items across all groups' data. For example,
if five group data are analyzed, the list should include five internal objects of the character vectors for the five groups.
The internal objects of the list should be ordered in accordance with the order of the group names specified in the <code>group.name</code> argument.
Available IRT models are &quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for dichotomous items, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous items. &quot;GRM&quot; and &quot;GPCM&quot;
represent the graded response model and (generalized) partial credit model, respectively. Note that &quot;DRM&quot; is considered as &quot;3PLM&quot; in this function. If a single
character of the IRT model is provided in the internal objects of the list, that model will be recycled across all items in the corresponding groups.
The provided information in the <code>model</code> argument is used only when <code>x = NULL</code> and <code>fipc = FALSE</code>. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_cats">cats</code></td>
<td>
<p>A list containing numeric vectors specifying the number of score categories of items across all groups' data to be analyzed. For example,
if five group data are analyzed, the list should include five internal objects of the numeric vectors for the five groups. The internal objects of the list
should be ordered in accordance with the order of the group names specified in the <code>group.name</code> argument. If a single numeric value is specified in the internal
objects of the list, that value will be recycled across all items in the corresponding groups. If <code>cats = NULL</code> and all specified models in
the <code>model</code> argument are the dichotomous models (i.e., 1PLM, 2PLM, 3PLM, or DRM), the function assumes that all items have two score categories
across all groups. The provided information in the <code>cats</code> argument is used only when <code>x = NULL</code> and <code>fipc = FALSE</code>. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_item.id">item.id</code></td>
<td>
<p>A list containing character vectors of item IDs across all groups' data to be analyzed. For example,
if five group data are analyzed, the list should include five internal objects of the character vectors of item IDs for the five groups.
The internal objects of the list should be ordered in accordance with the order of the group names specified in the <code>group.name</code> argument.
When <code>fipc = TRUE</code> and the Item IDs are given by the <code>item.id</code> argument, the Item IDs in the <code>x</code> argument are overridden.
Default is NULL.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_free.group">free.group</code></td>
<td>
<p>A numeric or character vector indicating groups in which scales (i.e., a mean and standard deviation) of the latent ability
distributions are freely estimated. The scales of other groups not specified in this argument are fixed based on the information provided in
the <code>group.mean</code> and <code>group.var</code> arguments, or the <code>weights</code> argument. For example, suppose that five group data are analyzed
and the corresponding group names are &quot;G1&quot;, &quot;G2&quot;, &quot;G3&quot;, &quot;G4&quot;, and &quot;G5&quot;, respectively. If the scales of the 2nd through 5th groups are freely estimated,
then <code>free.group = c(2, 3, 4, 5)</code> or <code>free.group = c("G3", "G4", "G4","G5")</code>. Also, the first group (i.e., &quot;G1&quot;) will have
the fixed scale (e.g., a mean of 0 and variance of 1 when <code>group.mean = 0</code>, <code>group.var = 1</code>, and <code>weights = NULL</code>).</p>
</td></tr>
<tr><td><code id="est_mg_+3A_fix.a.1pl">fix.a.1pl</code></td>
<td>
<p>A logical value. If TRUE, the slope parameters of the 1PLM items are fixed to a specific value specified in the argument
<code>a.val.1pl</code>. Otherwise, the slope parameters of all 1PLM items are constrained to be equal and estimated. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_fix.a.gpcm">fix.a.gpcm</code></td>
<td>
<p>A logical value. If TRUE, the GPCM items are calibrated with the partial credit model and the slope parameters of
the GPCM items are fixed to a specific value specified in the argument <code>a.val.gpcm</code>. Otherwise, the slope parameter of each GPCM item
is estimated. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_fix.g">fix.g</code></td>
<td>
<p>A logical value. If TRUE, the guessing parameters of the 3PLM items are fixed to a specific value specified in the argument
<code>g.val</code>. Otherwise, the guessing parameter of each 3PLM item is estimated. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_a.val.1pl">a.val.1pl</code></td>
<td>
<p>A numeric value. This value is used to fixed the slope parameters of the 1PLM items.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_a.val.gpcm">a.val.gpcm</code></td>
<td>
<p>A numeric value. This value is used to fixed the slope parameters of the GPCM items.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_g.val">g.val</code></td>
<td>
<p>A numeric value. This value is used to fixed the guessing parameters of the 3PLM items.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_use.aprior">use.aprior</code></td>
<td>
<p>A logical value. If TRUE, a prior distribution for the slope parameters is used for the parameter calibration
across all items. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_use.bprior">use.bprior</code></td>
<td>
<p>A logical value. If TRUE, a prior distribution for the difficulty (or threshold) parameters is used for the parameter calibration
across all items. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_use.gprior">use.gprior</code></td>
<td>
<p>A logical value. If TRUE, a prior distribution for the guessing parameters is used for the parameter calibration
across all 3PLM items. Default is TRUE.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_aprior">aprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item slope parameters. Three probability distributions
of Beta, Log-normal, and Normal distributions are available. In the list, a character string of the distribution name must be specified
in the first internal argument and a vector of two numeric values for the two parameters of the distribution must be specified in the
second internal argument. Specifically, when Beta distribution is used, &quot;beta&quot; should be specified in the first argument. When Log-normal
distribution is used, &quot;lnorm&quot; should be specified in the first argument. When Normal distribution is used, &quot;norm&quot; should be specified
in the first argument. In terms of the two parameters of the three distributions, see <code>dbeta()</code>, <code>dlnorm()</code>,
and <code>dnorm()</code> in the <span class="pkg">stats</span> package for more details.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_bprior">bprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item difficulty (or threshold) parameters. Three probability distributions
of Beta, Log-normal, and Normal distributions are available. In the list, a character string of the distribution name must be specified
in the first internal argument and a vector of two numeric values for the two parameters of the distribution must be specified in the
second internal argument. Specifically, when Beta distribution is used, &quot;beta&quot; should be specified in the first argument. When Log-normal
distribution is used, &quot;lnorm&quot; should be specified in the first argument. When Normal distribution is used, &quot;norm&quot; should be specified
in the first argument. In terms of the two parameters of the three distributions, see <code>dbeta()</code>, <code>dlnorm()</code>,
and <code>dnorm()</code> in the <span class="pkg">stats</span> package for more details.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_gprior">gprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item guessing parameters. Three probability distributions
of Beta, Log-normal, and Normal distributions are available. In the list, a character string of the distribution name must be specified
in the first internal argument and a vector of two numeric values for the two parameters of the distribution must be specified in the
second internal argument. Specifically, when Beta distribution is used, &quot;beta&quot; should be specified in the first argument. When Log-normal
distribution is used, &quot;lnorm&quot; should be specified in the first argument. When Normal distribution is used, &quot;norm&quot; should be specified
in the first argument. In terms of the two parameters of the three distributions, see <code>dbeta()</code>, <code>dlnorm()</code>,
and <code>dnorm()</code> in the <span class="pkg">stats</span> package for more details.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_missing">missing</code></td>
<td>
<p>A value indicating missing values in the response data set. Default is NA.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_quadrature">Quadrature</code></td>
<td>
<p>A numeric vector of two components specifying the number of quadrature points (in the first component) and
the symmetric minimum and maximum values of these points (in the second component). For example, a vector of c(49, 6) indicates 49 rectangular
quadrature points over -6 and 6. The quadrature points are used in the E step of the EM algorithm. Default is c(49, 6).</p>
</td></tr>
<tr><td><code id="est_mg_+3A_weights">weights</code></td>
<td>
<p>A two-column matrix or data frame containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the latent variable prior distribution. If not NULL, the scale of the latent ability distributions of the groups that
are not freely estimated (i.e., the groups not specified in the <code>free.group</code> argument) are fixed to the scale of the provided quadrature
points and weights. The weights and quadrature points can be easily obtained using the function <code><a href="#topic+gen.weight">gen.weight</a></code>. If NULL, a normal prior
density is used based on the information provided in the arguments of <code>Quadrature</code>, <code>group.mean</code>, and <code>group.var</code>). Default is NULL.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_group.mean">group.mean</code></td>
<td>
<p>A numeric value to set the mean of latent variable prior distribution when <code>weights = NULL</code>. Default is 0.
The means of the distributions of the groups that are not specified in the <code>free.group</code> are fixed to the value provided in this argument
to remove the indeterminancy of item parameter scales.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_group.var">group.var</code></td>
<td>
<p>A positive numeric value to set the variance of latent variable prior distribution when <code>weights = NULL</code>. Default is 1.
The variances of the distributions of the groups that are not specified in the <code>free.group</code> are fixed to the value provided in this argument
to remove the indeterminancy of item parameter scales.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_emphist">EmpHist</code></td>
<td>
<p>A logical value. If TRUE, the empirical histograms of the latent variable prior distributions across all groups are simultaneously
estimated with the item parameters using Woods's (2007) approach. The items are calibrated against the estimated empirical prior distributions.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_use.startval">use.startval</code></td>
<td>
<p>A logical value. If TRUE, the item parameters provided in the item metadata (i.e., the argument <code>x</code>) are used as
the starting values for the item parameter estimation. Otherwise, internal starting values of this function are used. Default is FALSE.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_etol">Etol</code></td>
<td>
<p>A positive numeric value. This value sets the convergence criterion for E steps of the EM algorithm. Default is 1e-3.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_maxe">MaxE</code></td>
<td>
<p>A positive integer value. This value determines the maximum number of the E steps in the EM algorithm. Default is 500.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_control">control</code></td>
<td>
<p>A list of control parameters to be passed to the optimization function of <code>nlminb()</code> in the <span class="pkg">stats</span> package. The control parameters
set the conditions of M steps of the EM algorithm. For example, the maximum number of iterations in each of the iterative M steps can
be set by <code>control = list(iter.max=200)</code>. Default maximum number of iterations in each M step is 200. See <code>nlminb()</code> in the <span class="pkg">stats</span> package
for other control parameters.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_fipc">fipc</code></td>
<td>
<p>A logical value. If TRUE, the MG-FIPC is implemented for item parameter estimation. When <code>fipc = TRUE</code>, the information of which items
are fixed needs to be provided via either of <code>fix.loc</code> or <code>fix.id</code>. See below for details.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_fipc.method">fipc.method</code></td>
<td>
<p>A character string specifying the FIPC method. Available methods include &quot;OEM&quot; for &quot;No Prior Weights Updating and One EM Cycle
(NWU-OEM; Wainer &amp; Mislevy, 1990)&quot; and &quot;MEM&quot; for &quot;Multiple Prior Weights Updating and Multiple EM Cycles (MWU-MEM; Kim, 2006).&quot;
When <code>fipc.method = "OEM"</code>, the maximum number of the E steps of the EM algorithm is set to 1 no matter what number is specified
in the argument <code>MaxE</code>.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_fix.loc">fix.loc</code></td>
<td>
<p>A list of positive integer vectors. Each internal integer vector indicates the locations of the items to be fixed in the item metadata
(i.e., <code>x</code>) for each group when the MG-FIPC is implemented (i.e., <code>fipc = TRUE</code>). The internal objects of the list should be ordered in accordance
with the order of group names specified in the <code>group.name</code> argument. For example, suppose that three group data are analyzed. For the first group data,
the 1st, 3rd, and 5th items are fixed, for the second group data, the 2nd, 3rd, 4th, and 7th items are fixed, and for the third group data, the 1st, 2nd,
and 6th items are fixed. Then <code>fix.loc = list(c(1, 3, 5), c(2, 3, 4, 7), c(1, 2, 6))</code>. Note that when the <code>fix.id</code> argument is not NULL,
the information provided into the <code>fix.loc</code> argument is ignored. See below for details.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_fix.id">fix.id</code></td>
<td>
<p>A vector of character strings specifying IDs of the items to be fixed when the MG-FIPC is implemented (i.e., <code>fipc = TRUE</code>).
For example, suppose that three group data are analyzed. For the first group data, three items in which IDs are G1I1, C1I1, are C1I2 are fixed.
For the second group data, four items in which IDs are C1I1, C1I2, C2I1, and C2I2 are fixed. For the third group data, three items in which IDs are
C2I1, C2I2, and G3I1 are fixed. Then there are six unique items to be fixed across the three groups (i.e., G1I1, C1I1, C1I2, C2I1, C2I2, and G3I1)
because C1I1 and C1I2 are common items between the first and the second groups, and C2I1 and C2I2 are common items between the second and the third
groups. Thus, <code>fix.id = c("G1I1", "C1I1", "C1I2", "C2I1", "C2I2", "G3I1")</code> should be specified. Note that when the <code>fix.id</code> argument is not NULL,
the information provided into the <code>fix.loc</code> argument is ignored. See below for details.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_se">se</code></td>
<td>
<p>A logical value. If FALSE, the standard errors of the item parameter estimates are not computed. Default is TRUE.</p>
</td></tr>
<tr><td><code id="est_mg_+3A_verbose">verbose</code></td>
<td>
<p>A logical value. If FALSE, all progress messages including the process information on the EM algorithm are suppressed.
Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The multiple-group (MG) item calibration (Bock &amp; Zimowski, 1996) provides a unified approach to the testing situations or
problems involving multiple groups such as nonequivalent groups equating, vertical scaling, and identification of differential
item functioning (DIF). In such contexts, typically there exist test takers from different groups responding to the same test
form or to the common items shared between different test forms.
</p>
<p>The goal of the MG item calibration is to estimate the item parameters and the latent ability distributions of the multiple groups
simultaneously (Bock &amp; Zimowski, 1996). In the <span class="pkg">irtQ</span> package, the <code><a href="#topic+est_mg">est_mg</a></code> function supports the MG item calibration
using the marginal maximum likelihood estimation via the expectation-maximization (MMLE-EM) algorithm (Bock &amp; Aitkin, 1981). In addition,
The function also supports the MG fixed item parameter calibration (MG-FIPC; e.g., Kim &amp; Kolen, 2016) if the parameters of certain items
need to be fixed across multiple test forms,
</p>
<p>In MG IRT analyses, it is commonly seen that the test forms of multiple groups share some common (or anchor) items between the groups.
By default the common items that have the same item IDs between different groups are automatically constrained so that they can have the same
item parameter estimates across the groups in the code<a href="#topic+est_mg">est_mg</a> function.
</p>
<p>Most of the features of the <code><a href="#topic+est_mg">est_mg</a></code> function are similar with those of the <code><a href="#topic+est_irt">est_irt</a></code> function. The main difference is
that several arguments in the <code><a href="#topic+est_mg">est_mg</a></code> functions take an object of a list format which contains several internal objects
corresponding to the groups to be analyzed. Those arguments include <code>x</code>, <code>data</code>, <code>model</code>, <code>cats</code>, <code>item.id</code>,
and <code>fix.loc</code>.
</p>
<p>Also, the <code><a href="#topic+est_mg">est_mg</a></code> has two new arguments, the <code>group.name</code> and <code>free.group</code>. The <code>group.name</code> is required to
assign a unique group name to each group. The order of internal objects in the lists provided in the <code>x</code>, <code>data</code>, <code>model</code>, <code>cats</code>,
<code>item.id</code>, and <code>fix.loc</code> arguments must match that of the group names supplied to the <code>group.name</code> argument.
</p>
<p>The <code>free.group</code> argument is necessary to indicate the freed groups in which scales (i.e., a mean and standard deviation) of the latent ability
distributions are estimated. When no item parameters are fixed (i.e., <code>fipc = FALSE</code>), at least one group should have a fixed scale
(e.g., a mean of 0 and variance of 1) of the latent ability distribution among the multiple groups that shares common items in order to
solve the scale indeterminancy in IRT estimation. By providing which are the freed groups into the <code>free.group</code> argument, the scales
of the groups specified in the <code>free.group</code> argument are freely estimated while the scales of all other groups not specified
in the argument are fixed based on the information provided in the <code>group.mean</code> and <code>group.var</code> arguments or
the <code>weights</code> argument.
</p>
<p>The situations where the implementation of MG-FIPC is necessary arise when the new latent ability scales from MG test data are linked
to the established scale (e.g., the scale of an item bank). In a single run of MG-FIPC method, all the parameters of freed items across multiple test
forms and the density of the latent ability distributions for multiple groups can be estimated on the scale of the fixed items (Kim &amp; Kolen, 2016).
Suppose that three different test forms, Form 1, Form 2, and Form 3, are administered to three nonequivalent groups, Group1, Group2, and Group3.
Form 1 and Form 2 share 12 common items, C1I1 to C1I12, and Form 2 and Form 3 share 10 common items, C2I1 to C2I10, while there is no common item
between Form 1 and Form 3. Also, suppose that all unique items of Form 1 came from an item bank, which were already calibrated on the scale of
the item bank. In this case, the goal of the MG-FIPC is to estimate the parameters of all the items across the three test forms, except the unique
items in Form 1, and the latent ability distributions of the three groups on the same scale of the item bank. To accomplish this task, the unique items in
Form 1 need to be fixed during the MG-FIPC to link the current MG test data and the item bank.
</p>
<p>The <code><a href="#topic+est_mg">est_mg</a></code> function can implement the MG-FIPC by setting <code>fipc = TRUE</code>. Then, the information of which items are fixed needs
to be supplied via either of <code>fix.loc</code> or <code>fix.id</code>. When utilizing the <code>fix.loc</code> argument, a list of the locations of the items that are
fixed in each group test form should be prepared. For example, suppose that three group data are analyzed. For the first group test form,
the 1st, 3rd, and 5th items are fixed, for the second group test form, the 2nd, 3rd, 4th, and 7th items are fixed, and for the third group test form,
the 1st, 2nd, and 6th items are fixed. Then <code>fix.loc = list(c(1, 3, 5), c(2, 3, 4, 7), c(1, 2, 6))</code>. Instead of using the <code>fix.loc</code>, the <code>fix.id</code>
argument can be used by providing a vector of the IDs of the items to be fixed. Again suppose that the three group data are analyzed. For the first group
test form, the three items in which IDs are G1I1, C1I1, are C1I2 are fixed. For the second group test form, the four items in which IDs are C1I1, C1I2, C2I1,
and C2I2 are fixed. For the third group test form, the three items in which IDs are C2I1, C2I2, and G3I1 are fixed. Then there are six unique items to
be fixed across the three groups (i.e., G1I1, C1I1, C1I2, C2I1, C2I2, and G3I1) because C1I1 and C1I2 are common items between the first and the second groups,
and C2I1 and C2I2 are common items between the second and the third groups. Thus, <code>fix.id = c("G1I1", "C1I1", "C1I2", "C2I1", "C2I2", "G3I1")</code> should be
set. Note that when the information of item IDs supplied in the <code>fix.id</code> argument overrides the information provided into the <code>fix.loc</code> argument.
</p>


<h3>Value</h3>

<p>This function returns an object of class <code><a href="#topic+est_mg">est_mg</a></code>. Within this object, several internal objects are contained such as:
</p>
<table>
<tr><td><code>estimates</code></td>
<td>
<p>A list containing two internal objects (i.e., overall and group) of the item parameter estimates and the corresponding standard errors
of estimates. The first internal object (overall) is a data frame of the item parameter and standard error estimates for the combined data set across
all groups. Accordingly, the data frame includes unique items across all groups. The second internal object (group) is a list of group specific
data frames containing item parameter and standard error estimates</p>
</td></tr>
<tr><td><code>par.est</code></td>
<td>
<p>A list containing two internal objects (i.e., overall and group) of the item parameter estimates. The format of the list is the same with
the internal object of 'estimates'</p>
</td></tr>
<tr><td><code>se.est</code></td>
<td>
<p>A list containing two internal objects (i.e., overall and group) of the standard errors of item parameter estimates. The format of the
list is the same with the internal object of 'estimates'. Note that the standard errors are estimated using the cross-production approximation
method (Meilijson, 1989).</p>
</td></tr>
<tr><td><code>pos.par</code></td>
<td>
<p>A data frame containing the position number of each item parameter being estimated. This item position data frame was created based on
the combined data sets across all groups (see the first internal object of 'estimates'). The position information is useful when interpreting
the variance-covariance matrix of item parameter estimates.</p>
</td></tr>
<tr><td><code>covariance</code></td>
<td>
<p>A matrix of variance-covariance matrix of item parameter estimates. This matrix was created based on the combined data sets
across all groups (see the first internal object of 'estimates')</p>
</td></tr>
<tr><td><code>loglikelihood</code></td>
<td>
<p>A list containing two internal objects (i.e., overall and group) of the log-likelihood values of observed data set
(marginal log-likelihood). The format of the list is the same with the internal object of 'estimates'. Specifically, the first internal
object (overall) contains a sum of the log-likelihood values of the observed data set across all unique items of all groups. The second
internal object (group) shows the group specific log-likelihood values.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>A model fit statistic of Akaike information criterion based on the loglikelihood of all unique items..</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>A model fit statistic of Bayesian information criterion based on the loglikelihood of all unique items.</p>
</td></tr>
<tr><td><code>group.par</code></td>
<td>
<p>A list containing the summary statistics (i.e., a mean, variance, and standard deviation) of latent
variable prior distributions across all groups.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>a list of the two-column data frames containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the (updated) latent variable prior distributions for all groups.</p>
</td></tr>
<tr><td><code>posterior.dist</code></td>
<td>
<p>A matrix of normalized posterior densities for all the response patterns at each of the quadrature points.
The row and column indicate each individual's response pattern and the quadrature point, respectively.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>A list containing two internal objects (i.e., overall and group) of the examinees' response data sets. The format of the list
is the same with the internal object of 'estimates'.</p>
</td></tr>
<tr><td><code>scale.D</code></td>
<td>
<p>A scaling factor in IRT models.</p>
</td></tr>
<tr><td><code>ncase</code></td>
<td>
<p>A list containing two internal objects (i.e., overall and group) with the total number of response patterns. The format of the list
is the same with the internal object of 'estimates'.</p>
</td></tr>
<tr><td><code>nitem</code></td>
<td>
<p>A list containing two internal objects (i.e., overall and group) with the total number of items included in the response data set.
The format of the list is the same with the internal object of 'estimates'.</p>
</td></tr>
<tr><td><code>Etol</code></td>
<td>
<p>A convergence criteria for E steps of the EM algorithm.</p>
</td></tr>
<tr><td><code>MaxE</code></td>
<td>
<p>The maximum number of E steps in the EM algorithm.</p>
</td></tr>
<tr><td><code>aprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item slope parameters.</p>
</td></tr>
<tr><td><code>gprior</code></td>
<td>
<p>A list containing the information of the prior distribution for item guessing parameters.</p>
</td></tr>
<tr><td><code>npar.est</code></td>
<td>
<p>A total number of the estimated parameters across all unique items.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>The number of EM cycles completed.</p>
</td></tr>
<tr><td><code>maxpar.diff</code></td>
<td>
<p>A maximum item parameter change when the EM cycles were completed.</p>
</td></tr>
<tr><td><code>EMtime</code></td>
<td>
<p>Time (in seconds) spent for the EM cycles.</p>
</td></tr>
<tr><td><code>SEtime</code></td>
<td>
<p>Time (in seconds) spent for computing the standard errors of the item parameter estimates.</p>
</td></tr>
<tr><td><code>TotalTime</code></td>
<td>
<p>Time (in seconds) spent for total compuatation.</p>
</td></tr>
<tr><td><code>test.1</code></td>
<td>
<p>Status of the first-order test to report if the gradients has vanished sufficiently for the solution to be stable.</p>
</td></tr>
<tr><td><code>test.2</code></td>
<td>
<p>Status of the second-order test to report if the information matrix is positive definite, which is a prerequisite
for the solution to be a possible maximum.</p>
</td></tr>
<tr><td><code>var.note</code></td>
<td>
<p>A note to report if the variance-covariance matrix of item parameter estimates is obtainable from the information matrix.</p>
</td></tr>
<tr><td><code>fipc</code></td>
<td>
<p>A logical value to indicate if FIPC was used.</p>
</td></tr>
<tr><td><code>fipc.method</code></td>
<td>
<p>A method used for the FIPC.</p>
</td></tr>
<tr><td><code>fix.loc</code></td>
<td>
<p>A list containing two internal objects (i.e., overall and group) with the locations of the fixed items when the FIPC was implemented.
The format of the list is the same with the internal object of 'estimates'.</p>
</td></tr>
</table>
<p>The internal objects can be easily extracted using the function <code><a href="#topic+getirt">getirt</a></code>.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Bock, R. D., &amp; Aitkin, M. (1981). Marginal maximum likelihood estimation of item parameters: Application of an EM algorithm.
<em>Psychometrika, 46</em>, 443-459.
</p>
<p>Bock, R. D., &amp; Zimowski, M. F. (1997). Multiple group IRT. In W. J. van der Linden &amp; R. K. Hambleton (Eds.), <em>Handbook
of modern item response theory</em> (pp. 433-448). New York: Springer.
</p>
<p>Kim, S. (2006). A comparative study of IRT fixed parameter calibration methods.
<em>Journal of Educational Measurement, 43</em>(4), 355-381.
</p>
<p>Kim, S., &amp; Kolen, M. J. (2016). Multiple group IRT fixed-parameter estimation for maintaining an extablished ability scale.
<em>Center for Advanced Studies in Measurement and Assessment Report, 49.</em>
</p>
<p>Meilijson, I. (1989). A fast improvement to the EM algorithm on its own terms.
<em>Journal of the Royal Statistical Society: Series B (Methodological), 51</em>, 127-138.
</p>
<p>Woods, C. M. (2007). Empirical histograms in item response theory with ordinal data. <em>Educational and Psychological Measurement, 67</em>(1), 73-87.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>, <code><a href="#topic+getirt">getirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##------------------------------------------------------------------------------
# 1. MG-calibration using simMG data
#  - Details :
#    (a) constrain the common items between the groups to have
#        the same item parameters (i.e., items C1I1 - C1I12 between
#        Groups 1 and 2, and items C2I1 - C2I10 between Groups 2 and 3)
#    (b) freely estimate the means and variances of ability
#        distributions except the reference group in which mean
#        and variance are fixed to 0 and 1, respectively.
##------------------------------------------------------------------------------
# 1-(1). freely estimates the means and variances of groups 2 and 3
# import the true item metadata of the three groups
x &lt;- simMG$item.prm

# extract model, score category, and item ID information from
# the item metadata for the three groups
model &lt;- list(x$Group1$model, x$Group2$model, x$Group3$model)
cats &lt;- list(x$Group1$cats, x$Group2$cats, x$Group3$cats)
item.id &lt;- list(x$Group1$id, x$Group2$id, x$Group3$id)

# import the simulated response data sets of the three groups
data &lt;- simMG$res.dat

# import the group names of the three groups
group.name &lt;- simMG$group.name

# set the groups 2 and 3 as the free groups in which scale
# of the ability distributions will be freely estimated.
# then, the group 1 will be a reference group in which the scale
# of the ability distribution will be fixed to the values specified
# in the 'group.mean' and 'group.var' arguments
free.group &lt;- c(2, 3) # or use 'free.group &lt;- group.name[2:3]'

# estimate the IRT parameters:
# as long as the common items between any groups have the same item IDs,
# their item parameters will be constrained to be the same between
# the groups unless the FIPC is not implemented
fit.1 &lt;-
 est_mg(data=data, group.name=group.name, model=model,
 cats=cats, item.id=item.id, D=1, free.group=free.group,
 use.gprior=TRUE, gprior=list(dist="beta", params=c(5, 16)),
 group.mean=0, group.var=1, EmpHist=TRUE, Etol=0.001, MaxE=500)

# summary of the estimation
summary(fit.1)

# extract the item parameter estimates
getirt(fit.1, what="par.est")

# extract the standard error estimates
getirt(fit.1, what="se.est")

# extract the group parameter estimates (i.e., scale parameters)
getirt(fit.1, what="group.par")

# extract the posterior latent ability distributions of the groups
getirt(fit.1, what="weights")

# 1-(2). or the same parameter estimation can be implemented by
# inserting a list of item metadata for the groups into the 'x'
# argument. if the item metadata contains the item parameters
# which you want to use as starting values for the estimation,
# you can set 'use.startval = TRUE'.
# also set the groups in which scales of ability distributions
# will be freely estimated using the group names
free.group &lt;- group.name[2:3]
fit.2 &lt;-
 est_mg(x=x, data=data, group.name=group.name, D=1,
 free.group=free.group, use.gprior=TRUE,
 gprior=list(dist="beta", params=c(5, 16)),
 group.mean=0, group.var=1, EmpHist=TRUE, use.startval=TRUE,
 Etol=0.001, MaxE=500)

# summary of the estimation
summary(fit.2)

##------------------------------------------------------------------------------
# 2. MG-calibration with the FIPC using simMG data
#  - Details :
#    (a) fix the parameters of the common items between the groups
#        (i.e., items C1I1 - C1I12 between Groups 1 and 2, and
#        items C2I1 - C2I10 between Groups 2 and 3)
#    (b) freely estimate the means and variances of ability
#        distributions of all three groups
##------------------------------------------------------------------------------
# 2-(1). freely estimates the means and variances of all three groups
# set all three groups as the free groups in which scale
# of the ability distributions will be freely estimated.
free.group &lt;- 1:3 # or use 'free.group &lt;- group.name'

# specify the locations of items to be fixed in each group data
# note that for the first group, the common items C1I1 - C1I12 are located
# in the 1st - 10th and 11th to 12th rows of the first group's item metadata
# for the second group, the common items C1I1 - C1I12 are located
# in the 1st - 12th rows of the second group's item metadata
# also, for the second group, the common items C2I1 - C2I10 are located
# in the 41st - 50th rows of the second group's item metadata
# for the third group, the common items C2I1 - C2I10 are located
# in the 1st - 10th rows of the third group's item metadata
fix.loc &lt;- list(c(1:10, 49:50),
                c(1:12, 41:50),
                c(1:10))

# estimate the IRT parameters using FIPC:
# when the FIPC is implemented, a list of the item metadata for all
# groups must be provided into the 'x' argument.
# for the fixed items, their item parameters must be specified
# in the item metadata
# for other non-fixed items, any parameter values can be provided
# in the item metadata
# also, set fipc = TRUE and fipc.method = "MEM"
fit.3 &lt;-
 est_mg(x=x, data=data, group.name=group.name, D=1,
 free.group=free.group, use.gprior=TRUE,
 gprior=list(dist="beta", params=c(5, 16)),
 EmpHist=TRUE, Etol=0.001, MaxE=500, fipc=TRUE,
 fipc.method="MEM", fix.loc=fix.loc)

# summary of the estimation
summary(fit.3)

# extract the item parameter estimates
getirt(fit.3, what="par.est")

# extract the standard error estimates
getirt(fit.3, what="se.est")

# extract the group parameter estimates (i.e., scale parameters)
getirt(fit.3, what="group.par")

# extract the posterior latent ability distributions of the groups
getirt(fit.3, what="weights")

# 2-(2). or the FIPC can be implemented by providing which items
# will be fixed in a different way using the 'fix.id' argument.
# a vector of the fixed item IDs needs to be provided into the
# 'fix.id' argument as such.
fix.id &lt;- c(paste0("C1I", 1:12), paste0("C2I", 1:10))
fit.4 &lt;-
 est_mg(x=x, data=data, group.name=group.name, D=1,
 free.group=free.group, use.gprior=TRUE,
 gprior=list(dist="beta", params=c(5, 16)),
 EmpHist=TRUE, Etol=0.001, MaxE=500, fipc=TRUE,
 fipc.method="MEM", fix.id=fix.id)

# summary of the estimation
summary(fit.4)

##------------------------------------------------------------------------------
# 3. MG-calibration with the FIPC using simMG data
#    (estimate the group parameters only)
#  - Details :
#    (a) fix all item parameters across all three groups
#    (b) freely estimate the means and variances of ability
#        distributions of all three groups
##------------------------------------------------------------------------------
# 3-(1). freely estimates the means and variances of all three groups
# set all three groups as the free groups in which scale
# of the ability distributions will be freely estimated.
free.group &lt;- 1:3 # or use 'free.group &lt;- group.name'

# specify the locations of all item parameters to be fixed
# in each item metadata
fix.loc &lt;- list(1:50, 1:50, 1:38)

# estimate the group parameters only using FIPC:
fit.5 &lt;-
 est_mg(x=x, data=data, group.name=group.name, D=1,
 free.group=free.group, use.gprior=TRUE,
 gprior=list(dist="beta", params=c(5, 16)),
 EmpHist=TRUE, Etol=0.001, MaxE=500, fipc=TRUE,
 fipc.method="MEM", fix.loc=fix.loc)

# summary of the estimation
summary(fit.5)

# extract the group parameter estimates (i.e., scale parameters)
getirt(fit.5, what="group.par")

##------------------------------------------------------------------------------
# 4. MG-calibration with the FIPC using simMG data
#    (fix the unique items of the group 1 only)
#  - Details :
#    (a) fix item parameters of unique items in the group 1 only
#    (b) constrain the common items between the groups to have
#        the same item parameters (i.e., items C1I1 - C1I12 between
#        Groups 1 and 2, and items C2I1 - C2I10 between Groups 2 and 3)
#    (c) freely estimate the means and variances of ability
#        distributions of all three groups
##------------------------------------------------------------------------------
# 4-(1). freely estimates the means and variances of all three groups
# set all three groups as the free groups in which scale
# of the ability distributions will be freely estimated.
free.group &lt;- group.name # or use 'free.group &lt;- 1:3'

# specify the item IDs of the unique items in the group 1 to be fixed
# in each item metadata using the 'fix.id' argument or
# you can use the 'fix.loc' argument by setting
# 'fix.loc = list(11:48, NULL, NULL)'
fix.id &lt;- paste0("G1I", 1:38)

# estimate the IRT parameters using FIPC:
fit.6 &lt;-
 est_mg(x=x, data=data, group.name=group.name, D=1,
 free.group=free.group, use.gprior=TRUE,
 gprior=list(dist="beta", params=c(5, 16)),
 EmpHist=TRUE, Etol=0.001, MaxE=500, fipc=TRUE,
 fipc.method="MEM", fix.loc=NULL, fix.id=fix.id)

# summary of the estimation
summary(fit.6)

# extract the group parameter estimates (i.e., scale parameters)
getirt(fit.6, what="group.par")



</code></pre>

<hr>
<h2 id='est_score'>Estimate examinees' ability (proficiency) parameters</h2><span id='topic+est_score'></span><span id='topic+est_score.default'></span><span id='topic+est_score.est_irt'></span>

<h3>Description</h3>

<p>This function estimates examinees' latent ability parameters. Available scoring methods are maximum likelihood estimation (ML),
maximum likelihood estimation with fences (MLF; Han, 2016), weighted likelihood estimation (Warm, 1989), maximum a posteriori estimation
(MAP; Hambleton et al., 1991), expected a posteriori estimation (EAP; Bock &amp; Mislevy, 1982), EAP summed scoring
(Thissen et al., 1995; Thissen &amp; Orlando, 2001), and inverse test characteristic curve (TCC) scoring
(e.g., Kolen &amp; Brennan, 2004; Kolen &amp; Tong, 2010; Stocking, 1996).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>est_score(x, ...)

## Default S3 method:
est_score(
  x,
  data,
  D = 1,
  method = "ML",
  range = c(-5, 5),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  fence.a = 3,
  fence.b = NULL,
  tol = 1e-04,
  max.iter = 100,
  se = TRUE,
  stval.opt = 1,
  intpol = TRUE,
  range.tcc = c(-7, 7),
  missing = NA,
  ncore = 1,
  ...
)

## S3 method for class 'est_irt'
est_score(
  x,
  method = "ML",
  range = c(-5, 5),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  fence.a = 3,
  fence.b = NULL,
  tol = 1e-04,
  max.iter = 100,
  se = TRUE,
  stval.opt = 1,
  intpol = TRUE,
  range.tcc = c(-7, 7),
  missing = NA,
  ncore = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="est_score_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...) or an object of
class <code><a href="#topic+est_irt">est_irt</a></code> obtained from the function <code><a href="#topic+est_irt">est_irt</a></code>. See <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>,
or <code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata. This data frame can be easily obtained using the function <code><a href="#topic+shape_df">shape_df</a></code>.</p>
</td></tr>
<tr><td><code id="est_score_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code>parallel::makeCluster</code>.</p>
</td></tr>
<tr><td><code id="est_score_+3A_data">data</code></td>
<td>
<p>A matrix or vector containing examinees' response data for the items in the argument <code>x</code>. When a matrix is used, a row and column indicate
the examinees and items, respectively. When a vector is used, it should contains the item response data for an examinee.</p>
</td></tr>
<tr><td><code id="est_score_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="est_score_+3A_method">method</code></td>
<td>
<p>A character string indicating a scoring method. Available methods are &quot;ML&quot; for the maximum likelihood estimation,
&quot;MLF&quot; for the maximum likelihood estimation with fences, &quot;WL&quot; for the weighted likelihood estimation, &quot;MAP&quot; for the maximum a posteriori estimation,
&quot;EAP&quot; for the expected a posteriori estimation, &quot;EAP.SUM&quot; for the expected a posteriori summed scoring, and &quot;INV.TCC&quot; for the inverse TCC scoring.
Default method is &quot;ML&quot;.</p>
</td></tr>
<tr><td><code id="est_score_+3A_range">range</code></td>
<td>
<p>A numeric vector of two components to restrict the range of ability scale for the ML, MLF, WL, and MAP scoring methods. Default is c(-5, 5).</p>
</td></tr>
<tr><td><code id="est_score_+3A_norm.prior">norm.prior</code></td>
<td>
<p>A numeric vector of two components specifying a mean and standard deviation of the normal prior distribution.
These two parameters are used to obtain the gaussian quadrature points and the corresponding weights from the normal distribution. Default is
c(0,1). Ignored if <code>method</code> is &quot;ML&quot;, &quot;MLF&quot;, &quot;WL&quot;, or &quot;INV.TCC&quot;.</p>
</td></tr>
<tr><td><code id="est_score_+3A_nquad">nquad</code></td>
<td>
<p>An integer value specifying the number of gaussian quadrature points from the normal prior distribution. Default is 41.
Ignored if <code>method</code> is &quot;ML&quot;, &quot;MLF&quot;, &quot;WL&quot;, &quot;MAP&quot;, or &quot;INV.TCC&quot;.</p>
</td></tr>
<tr><td><code id="est_score_+3A_weights">weights</code></td>
<td>
<p>A two-column matrix or data frame containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the latent variable prior distribution. The weights and quadrature points can be easily obtained
using the function <code><a href="#topic+gen.weight">gen.weight</a></code>. If NULL and <code>method</code> is &quot;EAP&quot; or &quot;EAP.SUM&quot;, default values are used (see the arguments
of <code>norm.prior</code> and <code>nquad</code>). Ignored if <code>method</code> is &quot;ML&quot;, &quot;MLF&quot;, &quot;WL&quot;, &quot;MAP&quot;, or &quot;INV.TCC&quot;.</p>
</td></tr>
<tr><td><code id="est_score_+3A_fence.a">fence.a</code></td>
<td>
<p>A numeric value specifying the item slope parameter (i.e., <em>a</em>-parameter) for the two imaginary items in MLF. See below for details.
Default is 3.0.</p>
</td></tr>
<tr><td><code id="est_score_+3A_fence.b">fence.b</code></td>
<td>
<p>A numeric vector of two components specifying the lower and upper fences of item difficulty parameters (i.e., <em>b</em>-parameters)
for the two imaginary items, respectively, in MLF. When <code>fence.b = NULL</code>, the <code>range</code> values were used to set the lower and upper fences of
item difficulty parameters. Default is NULL.</p>
</td></tr>
<tr><td><code id="est_score_+3A_tol">tol</code></td>
<td>
<p>A numeric value of the convergent tolerance for the ML, MLF, WL, MAP, and inverse TCC scoring methods. For the ML, MLF, WL, and MAP,
Newton Raphson method is implemented for optimization. For the inverse TCC scoring, the bisection method is used. Default is 1e-4.</p>
</td></tr>
<tr><td><code id="est_score_+3A_max.iter">max.iter</code></td>
<td>
<p>An positive integer value specifying the maximum number of iterations of Newton Raphson method. Default is 100.</p>
</td></tr>
<tr><td><code id="est_score_+3A_se">se</code></td>
<td>
<p>A logical value. If TRUE, the standard errors of ability estimates are computed. However, if <code>method</code> is &quot;EAP.SUM&quot; or &quot;INV.TCC&quot;, the standard
errors are always returned. Default is TRUE.</p>
</td></tr>
<tr><td><code id="est_score_+3A_stval.opt">stval.opt</code></td>
<td>
<p>An positive integer value specifying the starting value option for the ML, MLF, WL, and MAP scoring methods.
Available options are 1 for the brute-force method, 2 for the observed sum score-based method, and 3 for setting to 0. Default is 1.
See below for details.</p>
</td></tr>
<tr><td><code id="est_score_+3A_intpol">intpol</code></td>
<td>
<p>A logical value. If TRUE and <code>method = "INV.TCC"</code>, linear interpolation method is used to approximate the ability estimates
corresponding to the observed sum scores in which ability estimates cannot be obtained using the TCC (e.g., observed sum scores less than
the sum of item guessing parameters). Default is TRUE. See below for details.</p>
</td></tr>
<tr><td><code id="est_score_+3A_range.tcc">range.tcc</code></td>
<td>
<p>A numeric vector of two components to be used as the lower and upper bounds of ability estimates when <code>method = "INV.TCC"</code>.
Default is c(-7, 7).</p>
</td></tr>
<tr><td><code id="est_score_+3A_missing">missing</code></td>
<td>
<p>A value indicating missing values in the response data set. Default is NA. See below for details.</p>
</td></tr>
<tr><td><code id="est_score_+3A_ncore">ncore</code></td>
<td>
<p>The number of logical CPU cores to use. Default is 1. See below for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For MAP scoring method, only the normal prior distribution is available for the population distribution.
</p>
<p>When there are missing data in the response data set, the missing value must be specified in <code>missing</code>. The missing data are taken into account
when either of ML, MLF, WL, MAP, and EAP is used. When &quot;EAP.SUM&quot; or &quot;INV.TCC&quot; is used, however, any missing responses are replaced with incorrect
responses (i.e., 0s).
</p>
<p>In the maximum likelihood estimation with fences (MLF; Han, 2016), two 2PLM imaginary items are necessary. The first imaginary item serves as the lower
fence and its difficulty parameter (i.e., <em>b</em>-parameters) should be lower than any difficulty parameter values in the test form. Likewise, the second
imaginary item serves as the upper fence and its difficulty parameter should be greater than any difficulty parameter values in the test form. Also, the two
imaginary items should have a very high item slope parameter (i.e., <em>a</em>-parameter) value. See Han (2016) for more details. When <code>fence.b = NULL</code> in MLF,
the function automatically sets the lower and upper fences of item difficulty parameters using the values
in the <code>range</code> argument.
</p>
<p>When &quot;INV.TCC&quot; method is used employing the IRT 3-parameter logistic model (3PLM) in a test, ability estimates for the observed sum scores less than the
sum of item guessing parameters are not attainable. In this case, linear interpolation can be applied by setting <code>intpol = TRUE</code>.
Let <code class="reqn">\theta_{min}</code> and <code class="reqn">\theta_{max}</code> be the minimum and maximum ability estimates and <code class="reqn">\theta_{X}</code> be the ability estimate for
the smallest observed sum score, X, but greater than or equal to the sum of item guessing parameters. When linear interpolation method is used,
the first value of the <code>range.tcc</code> is set to <code class="reqn">\theta_{min}</code>. Then, a linear line is constructed between two points of
(x=<code class="reqn">\theta_{min}</code>, y=0) and (x=<code class="reqn">\theta_{X}</code>, y=X). Also, the first value of the <code>range.tcc</code> is set to <code class="reqn">\theta_{max}</code>, which is
the ability estimates corresponding to the maximum observed sum score. When it comes to the scoring method of &quot;INV.TCC&quot;, the standard errors of ability
estimates are computed using an approach suggested by Lim, Davey, and Wells (2020). The code for the inverse TCC scoring was written by modifying
the function <code>irt.eq.tse</code> of the <span class="pkg">SNSequate</span> R package (González, 2014).
</p>
<p>In terms of the starting value to be used for ML, MLF, WL, and MAP scoring methods, the brute-force method is used when <code>stval.opt = 1</code>. With this option,
the log-likelihood values were evaluated at the discrete theta values with increments of 0.1 given <code>range</code>. The theta node that has the largest
log-likelihood is used as the starting value. when <code>stval.opt = 2</code>, the starting value is obtained based on the observed sum score. For example,
if the maximum observed sum score (max.score) is 30 for a test and an examinee has an observed sum score of 20 (obs.score), then the starting value
is &quot;log(obs.score / (max.score - obs.score))&quot;. For all incorrect response, the starting value is &quot;log(1 / max.score)&quot; and for all correct responses,
it is &quot;log(max.score / 1)&quot;.
</p>
<p>To speed up the ability estimation for ML, MLF, WL, MAP, and EAP methods, this function applies a parallel process using multiple logical CPU cores.
You can set the number of logical CPU cores by specifying a positive integer value in the argument <code>ncore</code>. Default value is 1.
</p>
<p>Note that the standard errors of ability estimates are computed using the Fisher expected information for ML, MLF, WL, and MAP methods.
</p>
<p>To implement WL method, the <code>Pi</code>, <code>Ji</code>, and <code>Ii</code> functions of <span class="pkg">catR</span>
(Magis &amp; Barrada, 2017) were referred.
</p>


<h3>Value</h3>

<p>When <code>method</code> is either of &quot;ML&quot;, &quot;MLF&quot;, &quot;WL&quot;, &quot;MAP&quot;, or &quot;EAP&quot;, a two column data frame including the ability estimates (1st column)
and the standard errors of ability estimates (2nd column) is returned. When <code>method</code> is &quot;EAP.SUM&quot; or &quot;INV.TCC&quot;, a list of two internal
objects are returned. The first object is a three column data frame including the observed sum scores (1st column), the ability estimates (2nd column),
and the standard errors of ability estimates (3rd column). The second object is a score table including the possible raw sum scores
and corresponding ability and standard error estimates.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default method to estimate examinees' latent ability parameters using a data frame <code>x</code> containing the item metadata.
</p>
</li>
<li> <p><code>est_irt</code>: An object created by the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Bock, R. D., &amp; Mislevy, R. J. (1982). Adaptive EAP estimation of ability in a microcomputer environment. <em>Psychometrika, 35</em>, 179-198.
</p>
<p>González, J. (2014). SNSequate: Standard and nonstandard statistical models and methods for test equating.
<em>Journal of Statistical Software, 59</em>, 1-30.
</p>
<p>Hambleton, R. K., Swaminathan, H., &amp; Rogers, H. J. (1991).<em>Fundamentals of item response theory</em>. Newbury Park, CA: Sage.
</p>
<p>Han, K. T. (2016). Maximum likelihood score estimation method with fences for short-length tests and computerized adaptive tests.
<em>Applied psychological measurement, 40</em>(4), 289-301.
</p>
<p>Howard, J. P. (2017). <em>Computational methods for numerical analysis with R</em>. New York:
Chapman and Hall/CRC.
</p>
<p>Kolen, M. J. &amp; Brennan, R. L. (2004). <em>Test Equating, Scaling, and Linking</em> (2nd ed.). New York:
Springer
</p>
<p>Kolen, M. J. &amp; Tong, Y. (2010). Psychometric properties of IRT proficiency estimates.
<em>Educational Measurement: Issues and Practice, 29</em>(3), 8-14.
</p>
<p>Lim, H., Davey, T., &amp; Wells, C. S. (2020). A recursion-based analytical approach to evaluate the performance of MST.
<em>Journal of Educational Measurement</em>. DOI: 10.1111/jedm.12276.
</p>
<p>Magis, D., &amp; Barrada, J. R. (2017). Computerized adaptive testing with R: Recent updates of the package catR.
<em>Journal of Statistical Software, 76</em>, 1-19.
</p>
<p>Stocking, M. L. (1996). An alternative method for scoring adaptive tests.
<em>Journal of Educational and Behavioral Statistics, 21</em>(4), 365-389.
</p>
<p>Thissen, D. &amp; Orlando, M. (2001). Item response theory for items scored in two categories. In D. Thissen &amp; H. Wainer (Eds.),
<em>Test scoring</em> (pp.73-140). Mahwah, NJ: Lawrence Erlbaum.
</p>
<p>Thissen, D., Pommerich, M., Billeaud, K., &amp; Williams, V. S. (1995). Item Response Theory
for Scores on Tests Including Polytomous Items with Ordered Responses. <em>Applied Psychological
Measurement, 19</em>(1), 39-49.
</p>
<p>Warm, T. A. (1989). Weighted likelihood estimation of ability in item response theory. <em>Psychometrika, 54</em>(3),
427-450.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>, <code><a href="#topic+simdat">simdat</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>, <code><a href="#topic+gen.weight">gen.weight</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## the use of a "-prm.txt" file obtained from a flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameters and transform them to item metadata
x &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df

# generate examinees abilities
set.seed(12)
theta &lt;- rnorm(10)

# simulate the item response data
data &lt;- simdat(x, theta, D=1)


# estimate the abilities using ML
est_score(x, data, D=1, method="ML", range=c(-4, 4), se=TRUE)

# estimate the abilities using WL
est_score(x, data, D=1, method="WL", range=c(-4, 4), se=TRUE)

# estimate the abilities using MLF with default fences of item difficulty parameters
est_score(x, data, D=1, method="MLF", fence.a=3.0, fence.b=NULL, se=TRUE)

# estimate the abilities using MLF with different fences of item difficulty parameters
est_score(x, data, D=1, method="MLF", fence.a=3.0, fence.b=c(-7, 7), se=TRUE)

# estimate the abilities using MAP
est_score(x, data, D=1, method="MAP", norm.prior=c(0, 1), nquad=30, se=TRUE)

# estimate the abilities using EAP
est_score(x, data, D=1, method="EAP", norm.prior=c(0, 1), nquad=30, se=TRUE)

# estimate the abilities using EAP summed scoring
est_score(x, data, D=1, method="EAP.SUM", norm.prior=c(0, 1), nquad=30)

# estimate the abilities using inverse TCC scoring
est_score(x, data, D=1, method="INV.TCC", intpol=TRUE, range.tcc=c(-7, 7))



</code></pre>

<hr>
<h2 id='gen.weight'>Generate Weights</h2><span id='topic+gen.weight'></span>

<h3>Description</h3>

<p>This function generates a set of weights based on a set of theta values to be used in the functions <code><a href="#topic+est_score">est_score</a></code>
and <code><a href="#topic+sx2_fit">sx2_fit</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.weight(n = 41, dist = "norm", mu = 0, sigma = 1, l = -4, u = 4, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.weight_+3A_n">n</code></td>
<td>
<p>An integer identifying the number of theta (or node) values for which weights are generated. Default is 41.</p>
</td></tr>
<tr><td><code id="gen.weight_+3A_dist">dist</code></td>
<td>
<p>A character string specifying a probability distribution from which the weights are generated. Available distributions are
&quot;norm&quot; for a normal distribution, &quot;unif&quot; for a uniform distribution, and &quot;emp&quot; for an empirical distribution.
When <code>dist = "norm"</code>, either <code>n</code> or <code>theta</code> can be specified, when <code>dist = "unif"</code>,
only <code>n</code> can be used, and when <code>dist = "emp"</code>, only <code>theta</code> can be used.</p>
</td></tr>
<tr><td><code id="gen.weight_+3A_mu">mu</code>, <code id="gen.weight_+3A_sigma">sigma</code></td>
<td>
<p>A mean and standard deviation of a normal distribution.</p>
</td></tr>
<tr><td><code id="gen.weight_+3A_l">l</code>, <code id="gen.weight_+3A_u">u</code></td>
<td>
<p>Lower and upper limits of a uniform distribution.</p>
</td></tr>
<tr><td><code id="gen.weight_+3A_theta">theta</code></td>
<td>
<p>A vector of empirical theta (or node) values for which weights are generated.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the argument <code>theta</code> is missing, <em>n</em> weights can be generated from either the normal distribution or the uniform distribution.
Note that if <code>dist = "norm"</code>, gaussian quadrature points and weights from the normal distribution are generated. See
<code>gauss.quad.prob()</code> in the <span class="pkg">statmod</span> package for more details.
</p>
<p>When the argument <code>theta</code> is not missing, the weights corresponding to the provided theta values are generated. Specifically, if
<code>dist = "norm"</code>, normalized weights from the normal distribution are returned. If <code>dist = "emp"</code>, every specified theta value has the equal
values of normalized weights.
</p>


<h3>Value</h3>

<p>This function returns a data frame with two columns, where the first column has theta values (nodes) and the second column provides weights.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+est_score">est_score</a></code>, <code><a href="#topic+sx2_fit">sx2_fit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1
## generate 41 gaussian quadrature points and weights of normal distribution
gen.weight(n=41, dist = "norm", mu = 0, sigma = 1)

## example 2
## generate 41 theta values and weights from the uniform normal distribution,
## given the mininum value of -4 and the maximum value of 4
gen.weight(n=41, dist = "unif", l = -4, u = 4)

## example 3
## generate the normalized weights from the standardized normal distribution,
## given a set of theta values
theta &lt;- seq(-4, 4, by=0.1)
gen.weight(dist = "norm", mu = 0, sigma = 1, theta = theta)

## example 4
## generate the same values of normalized weights for the theta values that are
## randomly sampled from the standardized normal distribution
theta &lt;- rnorm(100)
gen.weight(dist = "emp", theta = theta)

</code></pre>

<hr>
<h2 id='getirt'>Extract various elements from 'est_irt', 'est_mg', and 'est_item' objects</h2><span id='topic+getirt'></span><span id='topic+getirt.est_irt'></span><span id='topic+getirt.est_mg'></span><span id='topic+getirt.est_item'></span>

<h3>Description</h3>

<p>This method extracts various internal objects from an object of class <code><a href="#topic+est_irt">est_irt</a></code>,
<code><a href="#topic+est_mg">est_mg</a></code>, or <code><a href="#topic+est_item">est_item</a></code>
.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getirt(x, ...)

## S3 method for class 'est_irt'
getirt(x, what, ...)

## S3 method for class 'est_mg'
getirt(x, what, ...)

## S3 method for class 'est_item'
getirt(x, what, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getirt_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+est_mg">est_mg</a></code>, or <code><a href="#topic+est_item">est_item</a></code>.</p>
</td></tr>
<tr><td><code id="getirt_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="getirt_+3A_what">what</code></td>
<td>
<p>A character string indicating what to extract.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Objects which can be extracted from the object of class <code><a href="#topic+est_irt">est_irt</a></code> include:
</p>

<dl>
<dt>estimates</dt><dd><p>A data frame containing both the item parameter estimates and the corresponding standard errors of estimates.</p>
</dd>
<dt>par.est</dt><dd><p>A data frame containing the item parameter estimates.</p>
</dd>
<dt>se.est</dt><dd><p>A data frame containing the standard errors of the item parameter estimates. Note that the standard errors are
estimated using the cross-production approximation method (Meilijson, 1989).</p>
</dd>
<dt>pos.par</dt><dd><p>A data frame containing the position number of each item parameter being estimated. The position information is useful
when interpreting the variance-covariance matrix of item parameter estimates.</p>
</dd>
<dt>covariance</dt><dd><p>A matrix of variance-covariance matrix of item parameter estimates.</p>
</dd>
<dt>loglikelihood</dt><dd><p>A sum of the log-likelihood values of the observed data set (marginal log-likelihood) across all items in the data set.</p>
</dd>
<dt>aic</dt><dd><p>A model fit statistic of Akaike information criterion based on the loglikelihood.</p>
</dd>
<dt>bic</dt><dd><p>A model fit statistic of Bayesian information criterion based on the loglikelihood.</p>
</dd>
<dt>group.par</dt><dd><p>A data frame containing the mean, variance, and standard deviation of latent variable prior distribution.</p>
</dd>
<dt>weights</dt><dd><p>A two-column data frame containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the (updated) latent variable prior distribution.</p>
</dd>
<dt>posterior.dist</dt><dd><p>A matrix of normalized posterior densities for all the response patterns at each of the quadrature points.
The row and column indicate each individual's response pattern and the quadrature point, respectively.</p>
</dd>
<dt>data</dt><dd><p>A data frame of the examinees' response data set.</p>
</dd>
<dt>scale.D</dt><dd><p>A scaling factor in IRT models.</p>
</dd>
<dt>ncase</dt><dd><p>A total number of response patterns.</p>
</dd>
<dt>nitem</dt><dd><p>A total number of items included in the response data.</p>
</dd>
<dt>Etol</dt><dd><p>A convergence criteria for E steps of the EM algorithm.</p>
</dd>
<dt>MaxE</dt><dd><p>The maximum number of E steps in the EM algorithm.</p>
</dd>
<dt>aprior</dt><dd><p>A list containing the information of the prior distribution for item slope parameters.</p>
</dd>
<dt>bprior</dt><dd><p>A list containing the information of the prior distribution for item difficulty (or threshold) parameters.</p>
</dd>
<dt>gprior</dt><dd><p>A list containing the information of the prior distribution for item guessing parameters.</p>
</dd>
<dt>npar.est</dt><dd><p>A total number of the estimated parameters.</p>
</dd>
<dt>niter</dt><dd><p>The number of EM cycles completed.</p>
</dd>
<dt>maxpar.diff</dt><dd><p>A maximum item parameter change when the EM cycles were completed.</p>
</dd>
<dt>EMtime</dt><dd><p>Time (in seconds) spent for the EM cycles.</p>
</dd>
<dt>SEtime</dt><dd><p>Time (in seconds) spent for computing the standard errors of the item parameter estimates.</p>
</dd>
<dt>TotalTime</dt><dd><p>Time (in seconds) spent for total compuatation.</p>
</dd>
<dt>test.1</dt><dd><p>Status of the first-order test to report if the gradients has vanished sufficiently for the solution to be stable.</p>
</dd>
<dt>test.2</dt><dd><p>Status of the second-order test to report if the information matrix is positive definite, which is a prerequisite
for the solution to be a possible maximum.</p>
</dd>
<dt>var.note</dt><dd><p>A note to report if the variance-covariance matrix of item parameter estimates is obtainable from the information matrix.</p>
</dd>
<dt>fipc</dt><dd><p>A logical value to indicate if FIPC was used.</p>
</dd>
<dt>fipc.method</dt><dd><p>A method used for the FIPC.</p>
</dd>
<dt>fix.loc</dt><dd><p>A vector of integer values specifying the locations of the fixed items when the FIPC was implemented.</p>
</dd>
</dl>

<p>Objects which can be extracted from the object of class <code><a href="#topic+est_mg">est_mg</a></code> include:
</p>

<dl>
<dt>estimates</dt><dd><p>A list containing two internal objects (i.e., overall and group) of the item parameter estimates and the corresponding standard errors
of estimates. The first internal object (overall) is a data frame of the item parameter and standard error estimates for the combined data set across
all groups. Accordingly, the data frame includes unique items across all groups. The second internal object (group) is a list of group specific
data frames containing item parameter and standard error estimates</p>
</dd>
<dt>par.est</dt><dd><p>A list containing two internal objects (i.e., overall and group) of the item parameter estimates. The format of the list is the same with
the internal object of 'estimates'</p>
</dd>
<dt>se.est</dt><dd><p>A list containing two internal objects (i.e., overall and group) of the standard errors of item parameter estimates. The format of the
list is the same with the internal object of 'estimates'. Note that the standard errors are estimated using the cross-production approximation
method (Meilijson, 1989).</p>
</dd>
<dt>pos.par</dt><dd><p>A data frame containing the position number of each item parameter being estimated. This item position data frame was created based on
the combined data sets across all groups (see the first internal object of 'estimates'). The position information is useful when interpreting
the variance-covariance matrix of item parameter estimates.</p>
</dd>
<dt>covariance</dt><dd><p>A matrix of variance-covariance matrix of item parameter estimates. This matrix was created based on the combined data sets
across all groups (see the first internal object of 'estimates')</p>
</dd>
<dt>loglikelihood</dt><dd><p>A list containing two internal objects (i.e., overall and group) of the log-likelihood values of observed data set
(marginal log-likelihood). The format of the list is the same with the internal object of 'estimates'. Specifically, the first internal
object (overall) contains a sum of the log-likelihood values of the observed data set across all unique items of all groups. The second
internal object (group) shows the group specific log-likelihood values.</p>
</dd>
<dt>aic</dt><dd><p>A model fit statistic of Akaike information criterion based on the loglikelihood of all unique items..</p>
</dd>
<dt>bic</dt><dd><p>A model fit statistic of Bayesian information criterion based on the loglikelihood of all unique items.</p>
</dd>
<dt>group.par</dt><dd><p>A list containing the summary statistics (i.e., a mean, variance, and standard deviation) of latent
variable prior distributions across all groups.</p>
</dd>
<dt>weights</dt><dd><p>a list of the two-column data frames containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the (updated) latent variable prior distributions for all groups.</p>
</dd>
<dt>posterior.dist</dt><dd><p>A matrix of normalized posterior densities for all the response patterns at each of the quadrature points.
The row and column indicate each individual's response pattern and the quadrature point, respectively.</p>
</dd>
<dt>data</dt><dd><p>A list containing two internal objects (i.e., overall and group) of the examinees' response data sets. The format of the list
is the same with the internal object of 'estimates'.</p>
</dd>
<dt>scale.D</dt><dd><p>A scaling factor in IRT models.</p>
</dd>
<dt>ncase</dt><dd><p>A list containing two internal objects (i.e., overall and group) with the total number of response patterns. The format of the list
is the same with the internal object of 'estimates'.</p>
</dd>
<dt>nitem</dt><dd><p>A list containing two internal objects (i.e., overall and group) with the total number of items included in the response data set.
The format of the list is the same with the internal object of 'estimates'.</p>
</dd>
<dt>Etol</dt><dd><p>A convergence criteria for E steps of the EM algorithm.</p>
</dd>
<dt>MaxE</dt><dd><p>The maximum number of E steps in the EM algorithm.</p>
</dd>
<dt>aprior</dt><dd><p>A list containing the information of the prior distribution for item slope parameters.</p>
</dd>
<dt>gprior</dt><dd><p>A list containing the information of the prior distribution for item guessing parameters.</p>
</dd>
<dt>npar.est</dt><dd><p>A total number of the estimated parameters across all unique items.</p>
</dd>
<dt>niter</dt><dd><p>The number of EM cycles completed.</p>
</dd>
<dt>maxpar.diff</dt><dd><p>A maximum item parameter change when the EM cycles were completed.</p>
</dd>
<dt>EMtime</dt><dd><p>Time (in seconds) spent for the EM cycles.</p>
</dd>
<dt>SEtime</dt><dd><p>Time (in seconds) spent for computing the standard errors of the item parameter estimates.</p>
</dd>
<dt>TotalTime</dt><dd><p>Time (in seconds) spent for total compuatation.</p>
</dd>
<dt>test.1</dt><dd><p>Status of the first-order test to report if the gradients has vanished sufficiently for the solution to be stable.</p>
</dd>
<dt>test.2</dt><dd><p>Status of the second-order test to report if the information matrix is positive definite, which is a prerequisite
for the solution to be a possible maximum.</p>
</dd>
<dt>var.note</dt><dd><p>A note to report if the variance-covariance matrix of item parameter estimates is obtainable from the information matrix.</p>
</dd>
<dt>fipc</dt><dd><p>A logical value to indicate if FIPC was used.</p>
</dd>
<dt>fipc.method</dt><dd><p>A method used for the FIPC.</p>
</dd>
<dt>fix.loc</dt><dd><p>A list containing two internal objects (i.e., overall and group) with the locations of the fixed items when the FIPC was implemented.
The format of the list is the same with the internal object of 'estimates'.</p>
</dd>
</dl>

<p>Objects which can be extracted from the object of class <code><a href="#topic+est_item">est_item</a></code> include:
</p>

<dl>
<dt>estimates</dt><dd><p>A data frame containing both the item parameter estimates and the corresponding standard errors of estimates.</p>
</dd>
<dt>par.est</dt><dd><p>A data frame containing the item parameter estimates.</p>
</dd>
<dt>se.est</dt><dd><p>A data frame containing the standard errors of the item parameter estimates. Note that the standard errors are estimated using
observed information functions.</p>
</dd>
<dt>pos.par</dt><dd><p>A data frame containing the position number of each item parameter being estimated. The position information is useful
when interpreting the variance-covariance matrix of item parameter estimates.</p>
</dd>
<dt>covariance</dt><dd><p>A matrix of variance-covariance matrix of item parameter estimates.</p>
</dd>
<dt>loglikelihood</dt><dd><p>A sum of the log-likelihood values of the complete data set across all estimated items.</p>
</dd>
<dt>data</dt><dd><p>A data frame of the examinees' response data set.</p>
</dd>
<dt>score</dt><dd><p>A vector of the examinees' ability values used as the fixed effects.</p>
</dd>
<dt>scale.D</dt><dd><p>A scaling factor in IRT models.</p>
</dd>
<dt>convergence</dt><dd><p>A string indicating the convergence status of the item parameter estimation.</p>
</dd>
<dt>nitem</dt><dd><p>A total number of items included in the response data.</p>
</dd>
<dt>deleted.item</dt><dd><p>The items which have no item response data. Those items are excluded from the item parameter estimation.</p>
</dd>
<dt>npar.est</dt><dd><p>A total number of the estimated parameters.</p>
</dd>
<dt>n.response</dt><dd><p>An integer vector indicating the number of item responses for each item used to estimate the item parameters.</p>
</dd>
<dt>TotalTime</dt><dd><p>Time (in seconds) spent for total compuatation.</p>
</dd>
</dl>

<p>See <code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+est_mg">est_mg</a></code>, and <code><a href="#topic+est_item">est_item</a></code> for more details.
</p>


<h3>Value</h3>

<p>The internal objects extracted from an object of class <code><a href="#topic+est_irt">est_irt</a></code>,
<code><a href="#topic+est_mg">est_mg</a></code>, or <code><a href="#topic+est_item">est_item</a></code>.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>est_irt</code>: An object created by the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
</li>
<li> <p><code>est_mg</code>: An object created by the function <code><a href="#topic+est_mg">est_mg</a></code>.
</p>
</li>
<li> <p><code>est_item</code>: An object created by the function <code><a href="#topic+est_item">est_item</a></code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+est_item">est_item</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# fit the 2PL model to LSAT6 data
mod.2pl &lt;- est_irt(data=LSAT6, D=1, model="2PLM", cats=2)

# extract the item parameter estimates
(est.par &lt;- getirt(mod.2pl, what="par.est"))

# extract the standard error estimates
(est.se &lt;- getirt(mod.2pl, what="se.est"))

# extract the variance-covariance matrix of item parameter estimates
(cov.mat &lt;- getirt(mod.2pl, what="covariance"))


</code></pre>

<hr>
<h2 id='grdif'>Generalized IRT residual-based DIF detection framework for multiple groups (GRDIF)</h2><span id='topic+grdif'></span><span id='topic+grdif.default'></span><span id='topic+grdif.est_irt'></span><span id='topic+grdif.est_item'></span>

<h3>Description</h3>

<p>This function computes three GRDIF statistics, <code class="reqn">GRDIF_{R}</code>, <code class="reqn">GRDIF_{S}</code>,
and <code class="reqn">GRDIF_{RS}</code>, for analyzing differential item functioning (DIF) among multiple groups
(Lim, Zhu, Choe, &amp; Han, 2023). They are specialized to capture uniform DIF, nonuniform DIF, and
mixed DIF, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>grdif(x, ...)

## Default S3 method:
grdif(
  x,
  data,
  score = NULL,
  group,
  focal.name,
  D = 1,
  alpha = 0.05,
  missing = NA,
  purify = FALSE,
  purify.by = c("grdifrs", "grdifr", "grdifs"),
  max.iter = 10,
  min.resp = NULL,
  post.hoc = TRUE,
  method = "ML",
  range = c(-4, 4),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  ncore = 1,
  verbose = TRUE,
  ...
)

## S3 method for class 'est_irt'
grdif(
  x,
  score = NULL,
  group,
  focal.name,
  alpha = 0.05,
  missing = NA,
  purify = FALSE,
  purify.by = c("grdifrs", "grdifr", "grdifs"),
  max.iter = 10,
  min.resp = NULL,
  post.hoc = TRUE,
  method = "ML",
  range = c(-4, 4),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  ncore = 1,
  verbose = TRUE,
  ...
)

## S3 method for class 'est_item'
grdif(
  x,
  group,
  focal.name,
  alpha = 0.05,
  missing = NA,
  purify = FALSE,
  purify.by = c("grdifrs", "grdifr", "grdifs"),
  max.iter = 10,
  min.resp = NULL,
  post.hoc = TRUE,
  method = "ML",
  range = c(-4, 4),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  ncore = 1,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="grdif_+3A_x">x</code></td>
<td>
<p>A data frame containing item metadata (e.g., item parameters, number of categories, models, etc.),
an object of class <code><a href="#topic+est_item">est_item</a></code> obtained from the function <code><a href="#topic+est_item">est_item</a></code>, or an object of class
<code><a href="#topic+est_irt">est_irt</a></code> obtained from the function <code><a href="#topic+est_irt">est_irt</a></code>. The item metadata can be easily created
using the function <code><a href="#topic+shape_df">shape_df</a></code>. See <code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code> or
<code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata.</p>
</td></tr>
<tr><td><code id="grdif_+3A_...">...</code></td>
<td>
<p>Additional arguments that will be forwarded to the <code><a href="#topic+est_score">est_score</a></code> function.</p>
</td></tr>
<tr><td><code id="grdif_+3A_data">data</code></td>
<td>
<p>A matrix containing examinees' response data for items in <code>x</code>. Rows and columns represent
examinees and items, respectively.</p>
</td></tr>
<tr><td><code id="grdif_+3A_score">score</code></td>
<td>
<p>A vector of examinees' ability estimates. If abilities are not provided, <code><a href="#topic+grdif">grdif</a></code>
estimates abilities before computing GRDIF statistics. See <code><a href="#topic+est_score">est_score</a></code> for more details
about scoring methods. Default is NULL.</p>
</td></tr>
<tr><td><code id="grdif_+3A_group">group</code></td>
<td>
<p>A numeric or character vector indicating group membership of examinees. The length of the vector
should be the same as the number of rows in the response data matrix.</p>
</td></tr>
<tr><td><code id="grdif_+3A_focal.name">focal.name</code></td>
<td>
<p>A character or numeric vector representing levels associated with focal groups.
For instance, consider <code>group = c(0, 0, 1, 2, 2, 3, 3)</code> where '1', '2', and '3' indicate three distinct
focal groups, and '0' represents the reference group. In this case, set <code>focal.name = c(1, 2, 3)</code>.</p>
</td></tr>
<tr><td><code id="grdif_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal
ogive function (if set to 1.7). Default is 1.</p>
</td></tr>
<tr><td><code id="grdif_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value to specify the significance <code class="reqn">\alpha</code>-level of the hypothesis test using
GRDIF statistics. Default is .05.</p>
</td></tr>
<tr><td><code id="grdif_+3A_missing">missing</code></td>
<td>
<p>A value indicating missing values in the response data set. Default is NA.</p>
</td></tr>
<tr><td><code id="grdif_+3A_purify">purify</code></td>
<td>
<p>A logical value indicating whether a purification process will be implemented or not.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="grdif_+3A_purify.by">purify.by</code></td>
<td>
<p>A character string specifying a GRDIF statistic with which the purification
is implemented. Available statistics are &quot;grdifrs&quot; for <code class="reqn">GRDIF_{RS}</code>, &quot;grdifr&quot; for
<code class="reqn">GRDIF_{R}</code>, and &quot;grdifs&quot; for <code class="reqn">GRDIF_{S}</code>.</p>
</td></tr>
<tr><td><code id="grdif_+3A_max.iter">max.iter</code></td>
<td>
<p>A positive integer value specifying the maximum number of iterations for
the purification process. Default is 10.</p>
</td></tr>
<tr><td><code id="grdif_+3A_min.resp">min.resp</code></td>
<td>
<p>A positive integer value specifying the minimum number of item responses for an examinee
required to compute the ability estimate. Default is NULL. See details below for more information.</p>
</td></tr>
<tr><td><code id="grdif_+3A_post.hoc">post.hoc</code></td>
<td>
<p>A logical value indicating whether to conduct a post-hoc RDIF analysis for
all possible combinations of paired groups for statistically flagged items. The default is TRUE.
See below for more details.</p>
</td></tr>
<tr><td><code id="grdif_+3A_method">method</code></td>
<td>
<p>A character string indicating a scoring method. Available methods are &quot;ML&quot; for maximum
likelihood estimation, &quot;WL&quot; for the weighted likelihood estimation, &quot;MAP&quot; for maximum a posteriori estimation,
and &quot;EAP&quot; for expected a posteriori estimation. The default method is &quot;ML&quot;.</p>
</td></tr>
<tr><td><code id="grdif_+3A_range">range</code></td>
<td>
<p>A numeric vector with two components to restrict the ability scale range for ML, WL, EAP,
and MAP scoring methods. The default is c(-5, 5).</p>
</td></tr>
<tr><td><code id="grdif_+3A_norm.prior">norm.prior</code></td>
<td>
<p>A numeric vector with two components specifying the mean and standard deviation of
the normal prior distribution. These parameters are used to obtain Gaussian quadrature points
and their corresponding weights from the normal distribution. The default is c(0,1). Ignored if <code>method</code> is
&quot;ML&quot; or &quot;WL&quot;.</p>
</td></tr>
<tr><td><code id="grdif_+3A_nquad">nquad</code></td>
<td>
<p>An integer value specifying the number of Gaussian quadrature points from the normal
prior distribution. The default is 41. Ignored if <code>method</code> is &quot;ML&quot;, &quot;WL&quot;, or &quot;MAP&quot;.</p>
</td></tr>
<tr><td><code id="grdif_+3A_weights">weights</code></td>
<td>
<p>A two-column matrix or data frame containing the quadrature points (in the first column)
and their corresponding weights (in the second column) for the latent variable prior distribution.
The weights and quadrature points can be obtained using the <code><a href="#topic+gen.weight">gen.weight</a></code> function.
If NULL and <code>method</code> is &quot;EAP&quot;, default values are used (see the <code>norm.prior</code>
and <code>nquad</code> arguments). Ignored if <code>method</code> is &quot;ML&quot;, &quot;WL&quot;, or &quot;MAP&quot;.</p>
</td></tr>
<tr><td><code id="grdif_+3A_ncore">ncore</code></td>
<td>
<p>The number of logical CPU cores to use. The default is 1. See <code><a href="#topic+est_score">est_score</a></code> for details.</p>
</td></tr>
<tr><td><code id="grdif_+3A_verbose">verbose</code></td>
<td>
<p>A logical value. If TRUE, progress messages for the purification procedure are suppressed.
The default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GRDIF framework (Lim et al., 2023) is a generalized version of the RDIF detection framework,
designed to assess DIF for multiple groups. The GRDIF framework comprises three statistics: <code class="reqn">GRDIF_{R}</code>, <code class="reqn">GRDIF_{S}</code>,
and <code class="reqn">GRDIF_{RS}</code>, which focus on detecting uniform, nonuniform, and mixed DIF, respectively.
Under the null hypothesis that a test contains no DIF items, <code class="reqn">GRDIF_{R}</code>, <code class="reqn">GRDIF_{S}</code>, and <code class="reqn">GRDIF_{RS}</code>
asymptotically follow the <code class="reqn">\chi^{2}</code> distributions with G-1, G-1, and 2(G-1) degrees of freedom, respectively,
where G represents the total number of groups being compared. For more information on the GRDIF framework, see Lim et al. (2023).
</p>
<p>The <code><a href="#topic+grdif">grdif</a></code> function calculates all three GRDIF statistics: <code class="reqn">GRDIF_{R}</code>, <code class="reqn">GRDIF_{S}</code>, and <code class="reqn">GRDIF_{RS}</code>. The current
version of the <code><a href="#topic+grdif">grdif</a></code> function supports both dichotomous and polytomous item response data. To compute these statistics, the <code><a href="#topic+grdif">grdif</a></code>
function requires (1) item parameter estimates obtained from aggregate data, regardless of group membership, (2) examinees' ability estimates
(e.g., MLE), and (3) examinees' item response data. Note that the ability estimates must be computed using the aggregate data-based
item parameter estimates. The item parameter estimates should be provided in the <code>x</code> argument, the ability estimates in the
<code>score</code> argument, and the response data in the <code>data</code> argument. When abilities are not given in the <code>score</code> argument
(i.e., <code>score = NULL</code>), the <code><a href="#topic+grdif">grdif</a></code> function estimates examinees' abilities automatically using the scoring method
specified in the <code>method</code> argument (e.g., <code>method = "ML"</code>).
</p>
<p>The <code>group</code> argument accepts a vector with numeric or character values, indicating the group membership of examinees.
The vector may include multiple distinct values, where one value represents the reference group and the others represent the focal groups.
The length of the vector should be the same as the number of rows in the response data, with each value indicating the group membership
of each examinee. After specifying the <code>group</code>, a numeric or character vector should be provided in the <code>focal.name</code> argument
to define which group values in the <code>group</code> argument represent the focal groups. The reference group will be the group not included
in the <code>focal.name</code> vector.
</p>
<p>Similar to the original RDIF framework for two-groups comparison, the GRDIF framework can implement an iterative purification process.
When <code>purify = TRUE</code>, the purification process is executed based on one of the GRDIF statistics specified in the <code>purify.by</code>
argument (e.g., <code>purify.by="grdifrs"</code>). During each iterative purification, examinees' latent abilities are calculated using purified
items and the scoring method specified in the <code>method</code> argument. The iterative purification process stops when no additional DIF items
are identified or when the process reaches a predetermined limit of iterations, which can be set in the <code>max.iter</code> argument.
For more information about the purification procedure, refer to Lim et al. (2022).
</p>
<p>Scoring with a limited number of items can result in large standard errors, which may impact the effectiveness of DIF detection within
the GRDIF framework. The <code>min.resp</code> argument can be employed to avoid using scores with significant standard errors when calculating
the GRDIF statistics, particularly during the purification process. For instance, if <code>min.resp</code> is not NULL (e.g., <code>min.resp=5</code>),
item responses from examinees whose total item responses fall below the specified minimum number are treated as missing values (i.e., NA).
Consequently, their ability estimates become missing values and are not utilized in computing the GRDIF statistics. If <code>min.resp=NULL</code>,
an examinee's score will be computed as long as there is at least one item response for the examinee.
</p>
<p>The <code>post.hoc</code> argument allows you to perform a post-hoc RDIF analysis for all possible combinations of paired groups
for items flagged as statistically significant. For example, consider four groups of examinees: A, B, C, and D. If <code>post.hoc = TRUE</code>,
the <code><a href="#topic+grdif">grdif</a></code> function will perform a post-hoc RDIF analysis for all possible pairs of groups
(A-B, A-C, A-D, B-C, B-D, and C-D) for each flagged item. This helps to identify which specific pairs of groups
have DIF for each item, providing a more detailed understanding of the DIF patterns in the data. Note that when purification is implemented
(i.e., <code>purify = TRUE</code>), the post-hoc RDIF analysis is conducted for each flagged item during each single iteration of
the purification process.
</p>


<h3>Value</h3>

<p>This function returns a list of four internal objects. The four objects are:
</p>
<table>
<tr><td><code>no_purify</code></td>
<td>
<p>A list of several sub-objects containing the results of DIF analysis without
a purification procedure. The sub-objects are:
</p>

<dl>
<dt>dif_stat</dt><dd><p>A data frame containing the results of three RDIF statistics for
all evaluated items. Starting from the first column, each column represents the item's ID,
<code class="reqn">GRDIF_{R}</code> statistic, <code class="reqn">GRDIF_{S}</code> statistic, <code class="reqn">GRDIF_{RS}</code> statistic,
p-value of <code class="reqn">GRDIF_{R}</code>, p-value of <code class="reqn">GRDIF_{S}</code>, p-value of <code class="reqn">GRDIF_{RS}</code>,
sample size of the reference group, sample sizes of the focal groups, and
the total sample size, respectively.</p>
</dd>
<dt>moments</dt><dd><p>A list of three data frames detailing the moments of mean raw residuals (MRRs)
and mean squared residuals (MSRs) across all compared groups. The first data frame contains
the means of MRR and MSR, the second data frame includes the variances of MRR and MSR,
and the last one displays the covariances of MRR and MSR for all groups.</p>
</dd>
<dt>dif_item</dt><dd><p>A list of three numeric vectors indicating potential DIF items flagged
by each of the GRDIF statistics. Each numeric vector corresponds to the items identified by
<code class="reqn">GRDIF_{R}</code>, <code class="reqn">GRDIF_{S}</code>, and <code class="reqn">GRDIF_{RS}</code>, respectively.</p>
</dd>
<dt>score</dt><dd><p>A vector of ability estimates used to compute the GRDIF statistics.</p>
</dd>
<dt>post.hoc</dt><dd><p>A list of three data frames containing the post-hoc RDIF analysis results of all possible
combinations of paired groups. The first, second, and third data frames present the post-hoc analysis outcomes
for the items identified by the <code class="reqn">RDIF_{R}</code>, <code class="reqn">RDIF_{S}</code>, and <code class="reqn">RDIF_{RS}</code> statistics, respectively.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>purify</code></td>
<td>
<p>A logical value indicating whether the purification process was used.</p>
</td></tr>
<tr><td><code>with_purify</code></td>
<td>
<p>A list of several sub-objects containing the results of DIF analysis with a purification procedure. The sub-objects are:
</p>

<dl>
<dt>purify.by</dt><dd><p>A character string indicating which GRDIF statistic is used for the purification.
&quot;grdifr&quot;, &quot;grdifs&quot;, and &quot;grdifrs&quot; refers to <code class="reqn">GRDIF_{R}</code>, <code class="reqn">GRDIF_{S}</code>, and
<code class="reqn">GRDIF_{RS}</code>, respectively.</p>
</dd>
<dt>dif_stat</dt><dd><p>A data frame containing the results of three GRDIF statistics for
all evaluated items. Starting from the first column, each column represents the item's ID,
<code class="reqn">GRDIF_{R}</code> statistic, <code class="reqn">GRDIF_{S}</code> statistic, <code class="reqn">GRDIF_{RS}</code> statistic,
p-value of <code class="reqn">GRDIF_{R}</code>, p-value of <code class="reqn">GRDIF_{S}</code>, p-value of <code class="reqn">GRDIF_{RS}</code>,
sample size of the reference group, sample sizes of the focal groups, total sample size,
and <em>n</em>th iteration where the GRDIF statistics were computed, respectively.</p>
</dd>
<dt>moments</dt><dd><p>A list of three data frames detailing the moments of mean raw residuals (MRRs)
and mean squared residuals (MSRs) across all compared groups. The first data frame contains
the means of MRR and MSR, the second data frame includes the variances of MRR and MSR,
and the last one displays the covariances of MRR and MSR for all groups. In each data frame,
the last column indicates the <em>n</em>th iteration where the GRDIF statistics were computed.</p>
</dd>
<dt>n.iter</dt><dd><p>The total number of iterations implemented for the purification.</p>
</dd>
<dt>score</dt><dd><p>A vector of final purified ability estimates used to compute the GRDIF statistics.</p>
</dd>
<dt>post.hoc</dt><dd><p>A data frame containing the post-hoc RDIF analysis results for the flagged items
across all possible combinations of paired groups. The post-hoc RDIF analysis is conducted
for each flagged item at every iteration.</p>
</dd>
<dt>complete</dt><dd><p>A logical value indicating whether the purification process was completed.
If FALSE, it means that the purification process reached the maximum iteration number
but was not completed.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>A significance <code class="reqn">\alpha</code>-level used to compute the p-values of RDIF statistics.</p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default method to computes three GRDIF statistics with multiple group data
using a data frame <code>x</code> containing the item metadata.
</p>
</li>
<li> <p><code>est_irt</code>: An object created by the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
</li>
<li> <p><code>est_item</code>: An object created by the function <code><a href="#topic+est_item">est_item</a></code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Lim, H., &amp; Choe, E. M. (2023). Detecting differential item functioning in CAT using IRT residual DIF approach.
<em>Journal of Educational Measurement</em>. <a href="https://doi.org/10.1111/jedm.12366">doi:10.1111/jedm.12366</a>.
</p>
<p>Lim, H., Choe, E. M., &amp; Han, K. T. (2022). A residual-based differential item functioning detection framework in
item response theory. <em>Journal of Educational Measurement, 59</em>(1), 80-104. <a href="https://doi.org/10.1111/jedm.12313">doi:10.1111/jedm.12313</a>.
</p>
<p>Lim, H., Zhu, D., Choe, E. M., &amp; Han, K. T. (2023, April). <em>Detecting differential item functioning among multiple groups
using IRT residual DIF framework</em>. Paper presented at the Annual Meeting of the National Council on Measurement
in Education. Chicago, IL.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rdif">rdif</a></code> <code><a href="#topic+est_item">est_item</a></code>, <code><a href="#topic+info">info</a></code>, <code><a href="#topic+simdat">simdat</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>,
<code><a href="#topic+gen.weight">gen.weight</a></code>, <code><a href="#topic+est_score">est_score</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load library
library("dplyr")

## Uniform DIF detection for four groups (1R/3F)
########################################################
# (1) Manipulate uniform DIF for all three focal groups
########################################################
# Import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# Select 36 of 3PLM items which are non-DIF items
par_nstd &lt;-
  bring.flexmirt(file=flex_sam, "par")$Group1$full_df %&gt;%
  dplyr::filter(.data$model == "3PLM") %&gt;%
  dplyr::filter(dplyr::row_number() %in% 1:36) %&gt;%
  dplyr::select(1:6)
par_nstd$id &lt;- paste0("nondif", 1:36)

# Generate four new items where uniform DIF will be manipulated
difpar_ref &lt;-
  shape_df(par.drm=list(a=c(0.8, 1.5, 0.8, 1.5), b=c(0.0, 0.0, -0.5, -0.5), g=.15),
           item.id=paste0("dif", 1:4), cats=2, model="3PLM")

# Manipulate uniform DIF on the four new items by adjusting the b-parameters
# for the three focal groups
difpar_foc1 &lt;-
  difpar_ref %&gt;%
  dplyr::mutate_at(.vars="par.2", .funs=function(x) x + c(0.7, 0.7, 0, 0))
difpar_foc2 &lt;-
  difpar_ref %&gt;%
  dplyr::mutate_at(.vars="par.2", .funs=function(x) x + c(0, 0, 0.7, 0.7))
difpar_foc3 &lt;-
  difpar_ref %&gt;%
  dplyr::mutate_at(.vars="par.2", .funs=function(x) x + c(-0.4, -0.4, -0.5, -0.5))

# Combine the 4 DIF and 36 non-DIF item data for both reference and focal groups.
# Thus, the first four items have uniform DIF for thee three focal groups
par_ref &lt;- rbind(difpar_ref, par_nstd)
par_foc1 &lt;- rbind(difpar_foc1, par_nstd)
par_foc2 &lt;- rbind(difpar_foc2, par_nstd)
par_foc3 &lt;- rbind(difpar_foc3, par_nstd)

# Generate the true thetas from the different ability distributions
set.seed(128)
theta_ref &lt;- rnorm(500, 0.0, 1.0)
theta_foc1 &lt;- rnorm(500, -1.0, 1.0)
theta_foc2 &lt;- rnorm(500, 1.0, 1.0)
theta_foc3 &lt;- rnorm(500, 0.5, 1.0)

# Generate the response data
resp_ref &lt;- irtQ::simdat(par_ref, theta=theta_ref, D=1)
resp_foc1 &lt;- irtQ::simdat(par_foc1, theta=theta_foc1, D=1)
resp_foc2 &lt;- irtQ::simdat(par_foc2, theta=theta_foc2, D=1)
resp_foc3 &lt;- irtQ::simdat(par_foc3, theta=theta_foc3, D=1)
data &lt;- rbind(resp_ref, resp_foc1, resp_foc2, resp_foc3)

########################################################
# (2) Estimate the item and ability parameters
#     using the aggregate data
########################################################
# Estimate the item parameters
est_mod &lt;- irtQ::est_irt(data=data, D=1, model="3PLM")
est_par &lt;- est_mod$par.est

# Estimate the ability parameters using MLE
score &lt;- irtQ::est_score(x=est_par, data=data, method="ML")$est.theta

########################################################
# (3) Conduct DIF analysis
########################################################
# Create a vector of group membership indicators,
# where 1, 2 and 3 indicate the three focal groups
group &lt;- c(rep(0, 500), rep(1, 500), rep(2, 500), rep(3, 500))

# (a) Compute GRDIF statistics without purification
#     and implement the post-hoc two-groups comparison analysis for
#     the flagged items
dif_nopuri &lt;- grdif(x=est_par, data=data, score=score, group=group,
                    focal.name=c(1, 2, 3), D=1, alpha=0.05,
                    purify=FALSE, post.hoc=TRUE)
print(dif_nopuri)

# Print the post-hoc analysis results for the fagged items
print(dif_nopuri$no_purify$post.hoc)

# (b) Compute GRDIF statistics with purification
#     based on \eqn{GRDIF_{R}} and implement the post-hoc
#     two-groups comparison analysis for flagged items
dif_puri_r &lt;- grdif(x=est_par, data=data, score=score, group=group,
                    focal.name=c(1, 2, 3), D=1, alpha=0.05,
                    purify=TRUE, purify.by = "grdifr", post.hoc=TRUE)
print(dif_puri_r)

# Print the post-hoc analysis results without purification
print(dif_puri_r$no_purify$post.hoc)

# Print the post-hoc analysis results with purification
print(dif_puri_r$with_purify$post.hoc)



</code></pre>

<hr>
<h2 id='info'>Item and Test Information Function</h2><span id='topic+info'></span><span id='topic+info.default'></span><span id='topic+info.est_item'></span><span id='topic+info.est_irt'></span>

<h3>Description</h3>

<p>This function computes both item and test information functions (Hambleton et al., 1991) given a set of theta values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>info(x, ...)

## Default S3 method:
info(x, theta, D = 1, tif = TRUE, ...)

## S3 method for class 'est_item'
info(x, theta, tif = TRUE, ...)

## S3 method for class 'est_irt'
info(x, theta, tif = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="info_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...), an object of class <code><a href="#topic+est_item">est_item</a></code>
obtained from the function <code><a href="#topic+est_item">est_item</a></code>, or an object of class <code><a href="#topic+est_irt">est_irt</a></code> obtained from the function <code><a href="#topic+est_irt">est_irt</a></code>.
The data frame of item metadata can be easily obtained using the function <code><a href="#topic+shape_df">shape_df</a></code>. See below for details.</p>
</td></tr>
<tr><td><code id="info_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="info_+3A_theta">theta</code></td>
<td>
<p>A vector of theta values where item and test information values are computed.</p>
</td></tr>
<tr><td><code id="info_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="info_+3A_tif">tif</code></td>
<td>
<p>A logical value. If TRUE, the test information function is computed. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A specific form of a data frame should be used for the argument <code>x</code>. The first column should have item IDs,
the second column should contain unique score category numbers of the items, and the third column should include IRT models being fit to the items.
The available IRT models are &quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for dichotomous item data, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous item data.
Note that &quot;DRM&quot; covers all dichotomous IRT models (i.e, &quot;1PLM&quot;, &quot;2PLM&quot;, and &quot;3PLM&quot;) and &quot;GRM&quot; and &quot;GPCM&quot; represent the graded
response model and (generalized) partial credit model, respectively. The next columns should include the item parameters of the fitted IRT models.
For dichotomous items, the fourth, fifth, and sixth columns represent the item discrimination (or slope), item difficulty, and
item guessing parameters, respectively. When &quot;1PLM&quot; and &quot;2PLM&quot; are specified in the third column, NAs should be inserted in the sixth column
for the item guessing parameters. For polytomous items, the item discrimination (or slope) parameters should be included in the
fourth column and the item difficulty (or threshold) parameters of category boundaries should be contained from the fifth to the last columns.
When the number of unique score categories differs between items, the empty cells of item parameters should be filled with NAs.
In the <span class="pkg">irtQ</span> package, the item difficulty (or threshold) parameters of category boundaries for GPCM are expressed as
the item location (or overall difficulty) parameter subtracted by the threshold parameter for unique score categories of the item.
Note that when an GPCM item has <em>K</em> unique score categories, <em>K-1</em> item difficulty parameters are necessary because
the item difficulty parameter for the first category boundary is always 0. For example, if an GPCM item has five score categories,
four item difficulty parameters should be specified. An example of a data frame with a single-format test is as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
  ITEM1  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 1PLM </td><td style="text-align: right;"> 1.000 </td><td style="text-align: right;">  1.461 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM2  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 2PLM </td><td style="text-align: right;"> 1.921 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM3  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 1.736 </td><td style="text-align: right;">  1.501 </td><td style="text-align: right;">  0.203 </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM4  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 0.835 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">  0.182 </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM5  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> DRM </td><td style="text-align: right;"> 0.926 </td><td style="text-align: right;">  0.394 </td><td style="text-align: right;">  0.099
</td>
</tr>

</table>

<p>And an example of a data frame for a mixed-format test is as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
  ITEM1  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 1PLM </td><td style="text-align: right;"> 1.000 </td><td style="text-align: right;">  1.461 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM2  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 2PLM </td><td style="text-align: right;"> 1.921 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM3  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 0.926 </td><td style="text-align: right;">  0.394 </td><td style="text-align: right;">  0.099 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM4  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> DRM </td><td style="text-align: right;"> 1.052 </td><td style="text-align: right;"> -0.407 </td><td style="text-align: right;">  0.201 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM5  </td><td style="text-align: right;"> 4 </td><td style="text-align: left;"> GRM  </td><td style="text-align: right;"> 1.913 </td><td style="text-align: right;"> -1.869 </td><td style="text-align: right;"> -1.238 </td><td style="text-align: right;"> -0.714 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM6  </td><td style="text-align: right;"> 5 </td><td style="text-align: left;"> GRM  </td><td style="text-align: right;"> 1.278 </td><td style="text-align: right;"> -0.724 </td><td style="text-align: right;"> -0.068 </td><td style="text-align: right;">  0.568 </td><td style="text-align: right;">  1.072</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM7  </td><td style="text-align: right;"> 4 </td><td style="text-align: left;"> GPCM  </td><td style="text-align: right;"> 1.137 </td><td style="text-align: right;"> -0.374 </td><td style="text-align: right;">  0.215 </td><td style="text-align: right;">  0.848 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM8  </td><td style="text-align: right;"> 5 </td><td style="text-align: left;"> GPCM  </td><td style="text-align: right;"> 1.233 </td><td style="text-align: right;"> -2.078 </td><td style="text-align: right;"> -1.347 </td><td style="text-align: right;"> -0.705 </td><td style="text-align: right;"> -0.116
</td>
</tr>

</table>

<p>See <code>IRT Models</code> section in the page of <code><a href="#topic+irtQ-package">irtQ-package</a></code> for more details about the IRT models used in the <span class="pkg">irtQ</span> package.
An easier way to create a data frame for the argument <code>x</code> is by using the function <code><a href="#topic+shape_df">shape_df</a></code>.
</p>


<h3>Value</h3>

<p>This function returns an object of class <code><a href="#topic+info">info</a></code>. This object contains item and test information values
given the specified theta values.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default method to compute item and test information functions for
a data frame <code>x</code> containing the item metadata.
</p>
</li>
<li> <p><code>est_item</code>: An object created by the function <code><a href="#topic+est_item">est_item</a></code>.
</p>
</li>
<li> <p><code>est_irt</code>: An object created by the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Hambleton, R. K., &amp; Swaminathan, H. (1985) <em>Item response theory: Principles and applications</em>.
Boston, MA: Kluwer.
</p>
<p>Hambleton, R. K., Swaminathan, H., &amp; Rogers, H. J. (1991) <em>Fundamentals of item response theory</em>.
Newbury Park, CA: Sage.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.info">plot.info</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>, <code><a href="#topic+est_item">est_item</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1.
## using the function "shape_df" to create a data frame of test metadata
# create a list containing the dichotomous item parameters
par.drm &lt;- list(a=c(1.1, 1.2, 0.9, 1.8, 1.4),
               b=c(0.1, -1.6, -0.2, 1.0, 1.2),
               g=rep(0.2, 5))

# create a list containing the polytomous item parameters
par.prm &lt;- list(a=c(1.4, 0.6),
               d=list(c(-1.9, 0.0, 1.2), c(0.4, -1.1, 1.5, 0.2)))

# create a numeric vector of score categories for the items
cats &lt;- c(2, 4, 2, 2, 5, 2, 2)

# create a character vector of IRT models for the items
model &lt;- c("DRM", "GRM", "DRM", "DRM", "GPCM", "DRM", "DRM")

# create an item metadata set
test &lt;- shape_df(par.drm=par.drm, par.prm=par.prm,
                 cats=cats, model=model) # create a data frame

# set theta values
theta &lt;- seq(-2, 2, 0.1)

# compute item and test information values given the theta values
info(x=test, theta=theta, D=1, tif=TRUE)


## example 2.
## using a "-prm.txt" file obtained from a flexMIRT
# import the "-prm.txt" output file from flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt",
                        package = "irtQ")

# read item parameters and transform them to item metadata
test_flex &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df

# set theta values
theta &lt;- seq(-2, 2, 0.1)

# compute item and test information values given the theta values
info(x=test_flex, theta=theta, D=1, tif=TRUE)


</code></pre>

<hr>
<h2 id='irtfit'>Traditional IRT item fit statistics</h2><span id='topic+irtfit'></span><span id='topic+irtfit.default'></span><span id='topic+irtfit.est_item'></span><span id='topic+irtfit.est_irt'></span>

<h3>Description</h3>

<p>This function computes traditional IRT item fit statistics (i.e., <code class="reqn">\chi^{2}</code> fit statistic (e.g., Bock, 1960; Yen, 1981),
loglikelihood ratio <code class="reqn">\chi^{2}</code> fit statistic (<code class="reqn">G^{2}</code>; McKinley &amp; Mills, 1985), and infit and outfit statistics (Ames et al., 2015)) and returns
contingency tables to compute the <code class="reqn">\chi^{2}</code> and <code class="reqn">G^{2}</code> fit statistics. Note that caution is needed in interpreting the infit and
outfit statistics for non-Rasch models. The saved object of this function, especially the object of contingency tables,
is used in the function of <code><a href="#topic+plot.irtfit">plot.irtfit</a></code> to draw a raw and standardized residual plots (Hambleton et al., 1991).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>irtfit(x, ...)

## Default S3 method:
irtfit(
  x,
  score,
  data,
  group.method = c("equal.width", "equal.freq"),
  n.width = 10,
  loc.theta = "average",
  range.score = NULL,
  D = 1,
  alpha = 0.05,
  missing = NA,
  overSR = 2,
  min.collapse = 1,
  pcm.loc = NULL,
  ...
)

## S3 method for class 'est_item'
irtfit(
  x,
  group.method = c("equal.width", "equal.freq"),
  n.width = 10,
  loc.theta = "average",
  range.score = NULL,
  alpha = 0.05,
  missing = NA,
  overSR = 2,
  min.collapse = 1,
  pcm.loc = NULL,
  ...
)

## S3 method for class 'est_irt'
irtfit(
  x,
  score,
  group.method = c("equal.width", "equal.freq"),
  n.width = 10,
  loc.theta = "average",
  range.score = NULL,
  alpha = 0.05,
  missing = NA,
  overSR = 2,
  min.collapse = 1,
  pcm.loc = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="irtfit_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...), an object of class <code><a href="#topic+est_item">est_item</a></code>
obtained from the function <code><a href="#topic+est_item">est_item</a></code>, or an object of class <code><a href="#topic+est_irt">est_irt</a></code> obtained from the function <code><a href="#topic+est_irt">est_irt</a></code>.
The data frame of item metadata can be easily obtained using the function <code><a href="#topic+shape_df">shape_df</a></code>. See below for more detail.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_score">score</code></td>
<td>
<p>A vector of examinees' ability estimates.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_data">data</code></td>
<td>
<p>A matrix containing examinees' response data for the items in the argument <code>x</code>. A row and column indicate
the examinees and items, respectively.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_group.method">group.method</code></td>
<td>
<p>A character string indicating how to group examinees along the ability scale for computing the <code class="reqn">\chi^{2}</code> and <code class="reqn">G^{2}</code> fit statistics.
Available methods are &quot;equal.width&quot; for grouping examinees by dividing the ability scale into intervals of equal width and &quot;equal.freq&quot;
for grouping examinees by dividing the ability scale into intervals with equal frequencies of examinees. However, &quot;equal.freq&quot; does not
always guarantee exactly the same frequency of examinees for all groups. Default is &quot;equal.width&quot;. To divide the ability scale, the range
of ability scale and the number of divided groups must be specified in the arguments of <code>range.score</code> and <code>n.width</code>, respectively.
See below for details.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_n.width">n.width</code></td>
<td>
<p>An integer value to specify the number of divided groups along the ability scale. Default is 10. See below for more detail.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_loc.theta">loc.theta</code></td>
<td>
<p>A character string to indicate the location of ability point at each group (or interval) where the expected probabilities
of score categories are calculated using the IRT models. Available locations are &quot;average&quot; for computing the expected probability
at the average point of examinees' ability estimates in each group and &quot;middle&quot; for computing the expected probability at the midpoint of each group.
Default is &quot;average&quot;.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_range.score">range.score</code></td>
<td>
<p>A vector of two numeric values to restrict the range of ability scale. All ability estimates less than
the first value are transformed to the first value. All ability estimates greater than the second value are transformed to the second value.
If NULL, the minimum and maximum values of ability estimates in the argument <code>score</code> is used as the range of ability scale. Note that
selection of grouping method in the argument <code>group.method</code> has nothing to do with the range of ability scale. Default is NULL.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value to specify significance <code class="reqn">\alpha</code>-level of the hypothesis test for the <code class="reqn">\chi^{2}</code> and <code class="reqn">G^{2}</code> fit statistics.
Default is .05.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_missing">missing</code></td>
<td>
<p>A value indicating missing values in the response data set. Default is NA.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_oversr">overSR</code></td>
<td>
<p>A numeric value to specify a criterion to find ability groups (or intervals) which have standardized residuals
greater than the specified value. Default is 2.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_min.collapse">min.collapse</code></td>
<td>
<p>An integer value to indicate the minimum frequency of cells to be collapsed when computing the <code class="reqn">\chi^{2}</code> and <code class="reqn">G^{2}</code>
fit statistics. Neighboring interval groups will be collapsed to avoid expected interval frequencies less than the specified minimum cell frequency.
Default is 1.</p>
</td></tr>
<tr><td><code id="irtfit_+3A_pcm.loc">pcm.loc</code></td>
<td>
<p>A vector of integer values indicating the locations of partial credit model (PCM) items whose slope parameters are fixed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A specific form of a data frame should be used for the argument <code>x</code>. The first column should have item IDs,
the second column should contain unique score category numbers of the items, and the third column should include IRT models being fit to the items.
The available IRT models are &quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for dichotomous item data, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous item data.
Note that &quot;DRM&quot; covers all dichotomous IRT models (i.e, &quot;1PLM&quot;, &quot;2PLM&quot;, and &quot;3PLM&quot;) and &quot;GRM&quot; and &quot;GPCM&quot; represent the graded
response model and (generalized) partial credit model, respectively. The next columns should include the item parameters of the fitted IRT models.
For dichotomous items, the fourth, fifth, and sixth columns represent the item discrimination (or slope), item difficulty, and
item guessing parameters, respectively. When &quot;1PLM&quot; and &quot;2PLM&quot; are specified in the third column, NAs should be inserted in the sixth column
for the item guessing parameters. For polytomous items, the item discrimination (or slope) parameters should be included in the
fourth column and the item difficulty (or threshold) parameters of category boundaries should be contained from the fifth to the last columns.
When the number of unique score categories differs between items, the empty cells of item parameters should be filled with NAs.
In the <span class="pkg">irtQ</span> package, the item difficulty (or threshold) parameters of category boundaries for GPCM are expressed as
the item location (or overall difficulty) parameter subtracted by the threshold parameter for unique score categories of the item.
Note that when an GPCM item has <em>K</em> unique score categories, <em>K-1</em> item difficulty parameters are necessary because
the item difficulty parameter for the first category boundary is always 0. For example, if an GPCM item has five score categories,
four item difficulty parameters should be specified. An example of a data frame with a single-format test is as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
  ITEM1  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 1PLM </td><td style="text-align: right;"> 1.000 </td><td style="text-align: right;">  1.461 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM2  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 2PLM </td><td style="text-align: right;"> 1.921 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM3  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 1.736 </td><td style="text-align: right;">  1.501 </td><td style="text-align: right;">  0.203 </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM4  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 0.835 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">  0.182 </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM5  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> DRM </td><td style="text-align: right;"> 0.926 </td><td style="text-align: right;">  0.394 </td><td style="text-align: right;">  0.099
</td>
</tr>

</table>

<p>And an example of a data frame for a mixed-format test is as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
  ITEM1  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 1PLM </td><td style="text-align: right;"> 1.000 </td><td style="text-align: right;">  1.461 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM2  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 2PLM </td><td style="text-align: right;"> 1.921 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM3  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 0.926 </td><td style="text-align: right;">  0.394 </td><td style="text-align: right;">  0.099 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM4  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> DRM </td><td style="text-align: right;"> 1.052 </td><td style="text-align: right;"> -0.407 </td><td style="text-align: right;">  0.201 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM5  </td><td style="text-align: right;"> 4 </td><td style="text-align: left;"> GRM  </td><td style="text-align: right;"> 1.913 </td><td style="text-align: right;"> -1.869 </td><td style="text-align: right;"> -1.238 </td><td style="text-align: right;"> -0.714 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM6  </td><td style="text-align: right;"> 5 </td><td style="text-align: left;"> GRM  </td><td style="text-align: right;"> 1.278 </td><td style="text-align: right;"> -0.724 </td><td style="text-align: right;"> -0.068 </td><td style="text-align: right;">  0.568 </td><td style="text-align: right;">  1.072</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM7  </td><td style="text-align: right;"> 4 </td><td style="text-align: left;"> GPCM  </td><td style="text-align: right;"> 1.137 </td><td style="text-align: right;"> -0.374 </td><td style="text-align: right;">  0.215 </td><td style="text-align: right;">  0.848 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM8  </td><td style="text-align: right;"> 5 </td><td style="text-align: left;"> GPCM  </td><td style="text-align: right;"> 1.233 </td><td style="text-align: right;"> -2.078 </td><td style="text-align: right;"> -1.347 </td><td style="text-align: right;"> -0.705 </td><td style="text-align: right;"> -0.116
</td>
</tr>

</table>

<p>See <code>IRT Models</code> section in the page of <code><a href="#topic+irtQ-package">irtQ-package</a></code> for more detail about the IRT models used in the <span class="pkg">irtQ</span> package.
An easier way to create a data frame for the argument <code>x</code> is by using the function <code><a href="#topic+shape_df">shape_df</a></code>.
</p>
<p>To calculate the <code class="reqn">\chi^{2}</code> and <code class="reqn">G^{2}</code> fit statistics, two methods are used in the argument <code>group.method</code> to divide the ability scale
into several groups. If <code>group.method = "equal.width"</code>, the examinees are grouped based on equal length of intervals.
If <code>group.method = "equal.freq"</code>, the examinees are grouped so that all groups have equal frequencies. However, the grouping method
of &quot;equal.freq&quot; does guarantee that every group has the exactly same frequency of examinees. This is because the examinees are divided by
the same size of quantile.
</p>
<p>When dividing the ability scale into intervals to compute the <code class="reqn">\chi^{2}</code> and <code class="reqn">G^{2}</code> fit statistics, the intervals should be wide enough not to include
too small number of examinees. On the other hand, the interval should be narrow enough to include homogeneous examinees in terms of ability
(Hambleton et al, 1991). Thus, if you want to divide the ability scale into other than ten groups, you need to specify the number of groups
in the argument <code>n.width</code>. Yen (1981) fixed the number of groups to 10, whereas Bock (1960) allowed for any number of groups.
</p>
<p>Regarding degrees of freedom (<em>df</em>), the <code class="reqn">\chi^{2}</code> is assumed to be distributed approximately as a chi-square with <em>df</em> equal to
the number of groups less the number of the IRT model parameters (Ames et al., 2015) whereas the <code class="reqn">G^{2}</code> is assumed to be distributed approximately
as a chi-square with <em>df</em> equal to the number of groups (Ames et al., 2015; Muraki &amp; Bock, 2003)
</p>
<p>Note that if &quot;DRM&quot; is specified for an item in the item metadata set, the item is considered as &quot;3PLM&quot; to compute degrees of freedom of
the <code class="reqn">\chi^{2}</code> fit statistic.
</p>


<h3>Value</h3>

<p>This function returns an object of class <code><a href="#topic+irtfit">irtfit</a></code>. Within this object, several internal objects are contained such as:
</p>
<table>
<tr><td><code>fit_stat</code></td>
<td>
<p>A data frame containing the results of three IRT fit statistics (i.e., <code class="reqn">\chi^{2}</code> and <code class="reqn">G^{2}</code>, infit, outfit statistics) across
all evaluated items. In the data frame, the columns indicate item's ID, <code class="reqn">\chi^{2}</code> fit statistic, <code class="reqn">G^{2}</code> fit statistic, degrees of freedom for the <code class="reqn">\chi^{2}</code>,
degrees of freedom for the <code class="reqn">G^{2}</code>, critical value for the <code class="reqn">\chi^{2}</code>, critical value for the <code class="reqn">G^{2}</code>, p-value for the <code class="reqn">\chi^{2}</code>,
p-value for the <code class="reqn">G^{2}</code>, outfit statistic, infit statistic, the number of examinees used to compute the five fit statistics, and the proportion of
ability groups (or intervals), before collapsing the cells, that have standardized residuals greater than the specified criterion in the argument <code>overSR</code>,
respectively.</p>
</td></tr>
<tr><td><code>contingency.fitstat</code></td>
<td>
<p>A list of contingency tables used to compute the <code class="reqn">\chi^{2}</code> and <code class="reqn">G^{2}</code> fit statistics for all items.
Note that the collapsing cell strategy is implemented to these contingency tables.</p>
</td></tr>
<tr><td><code>contingency.plot</code></td>
<td>
<p>A list of contingency tables used to draw a raw and standardized residual plots (Hambleton et al., 1991) in the function of
<code><a href="#topic+plot.irtfit">plot.irtfit</a></code>. Note that the collapsing cell strategy is <em>not</em> implemented to these contingency tables.</p>
</td></tr>
<tr><td><code>individual.info</code></td>
<td>
<p>A list of data frames including individual residual and variance values. Those information are used to compute
infit and outfit statistics.</p>
</td></tr>
<tr><td><code>item_df</code></td>
<td>
<p>The item metadata specified in the argument <code>x</code>.</p>
</td></tr>
<tr><td><code>ancillary</code></td>
<td>
<p>A list of ancillary information used in the item fit analysis.</p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default method to compute the traditional IRT item fit statistics for a data frame <code>x</code> containing the item metadata.
</p>
</li>
<li> <p><code>est_item</code>: An object created by the function <code><a href="#topic+est_item">est_item</a></code>.
</p>
</li>
<li> <p><code>est_irt</code>: An object created by the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Ames, A. J., &amp; Penfield, R. D. (2015). An NCME Instructional Module on Item-Fit Statistics for Item Response Theory Models.
<em>Educational Measurement: Issues and Practice, 34</em>(3), 39-48.
</p>
<p>Bock, R.D. (1960), <em>Methods and applications of optimal scaling</em>. Chapel Hill, NC: L.L. Thurstone Psychometric Laboratory.
</p>
<p>Hambleton, R. K., Swaminathan, H., &amp; Rogers, H. J. (1991).<em>Fundamentals of item response theory</em>. Newbury Park, CA: Sage.
</p>
<p>McKinley, R., &amp; Mills, C. (1985). A comparison of several goodness-of-fit statistics.
<em>Applied Psychological Measurement, 9</em>, 49-57.
</p>
<p>Muraki, E. &amp; Bock, R. D. (2003). PARSCALE 4: IRT item analysis and test scoring for rating
scale data [Computer Program]. Chicago, IL: Scientific Software International. URL http://www.ssicentral.com
</p>
<p>Wells, C. S., &amp; Bolt, D. M. (2008). Investigation of a nonparametric procedure for assessing goodness-of-fit in
item response theory. <em>Applied Measurement in Education, 21</em>(1), 22-40.
</p>
<p>Yen, W. M. (1981). Using simulation results to choose a latent trait model. <em>Applied Psychological Measurement, 5</em>, 245-262.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.irtfit">plot.irtfit</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>, <code><a href="#topic+est_item">est_item</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## example 1
## use the simulated CAT data
# find the location of items that have more than 10,000 responses
over10000 &lt;- which(colSums(simCAT_MX$res.dat, na.rm=TRUE) &gt; 10000)

# select the items that have more than 10,000 responses
x &lt;- simCAT_MX$item.prm[over10000, ]

# select the response data for the items
data &lt;- simCAT_MX$res.dat[, over10000]

# select the examinees' abilities
score &lt;- simCAT_MX$score

# compute fit statistics
fit1 &lt;- irtfit(x=x, score=score, data=data, group.method="equal.width",
               n.width=10, loc.theta="average", range.score=NULL, D=1, alpha=0.05,
               missing=NA, overSR=2)

# fit statistics
fit1$fit_stat

# contingency tables
fit1$contingency.fitstat


## example 2
## import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select the first two dichotomous items and last polytomous item
x &lt;- bring.flexmirt(file=flex_sam, "par")$Group1$full_df[c(1:2, 55), ]

# generate examinees' abilities from N(0, 1)
set.seed(10)
score &lt;- rnorm(1000, mean=0, sd=1)

# simulate the response data
data &lt;- simdat(x=x, theta=score, D=1)

# compute fit statistics
fit2 &lt;- irtfit(x=x, score=score, data=data, group.method="equal.freq",
               n.width=11, loc.theta="average", range.score=c(-4, 4), D=1, alpha=0.05)

# fit statistics
fit2$fit_stat

# contingency tables
fit2$contingency.fitstat

# residual plots for the first item (dichotomous item)
plot(x=fit2, item.loc=1, type = "both", ci.method = "wald", show.table=TRUE, ylim.sr.adjust=TRUE)

# residual plots for the third item (polytomous item)
plot(x=fit2, item.loc=3, type = "both", ci.method = "wald", show.table=FALSE, ylim.sr.adjust=TRUE)



</code></pre>

<hr>
<h2 id='llike_score'>Loglikelihood of Ability Parameters</h2><span id='topic+llike_score'></span>

<h3>Description</h3>

<p>This function computes the loglikelihood of ability parameters
given the item parameters and response data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>llike_score(
  x,
  data,
  theta,
  D = 1,
  method = "ML",
  norm.prior = c(0, 1),
  fence.a = 3,
  fence.b = NULL,
  missing = NA
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="llike_score_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number
of score categories, models). This can be created easily using the <code><a href="#topic+shape_df">shape_df</a></code>
function. See <code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+irtfit">irtfit</a></code>, \code<a href="#topic+info">info</a>,
or <code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata.</p>
</td></tr>
<tr><td><code id="llike_score_+3A_data">data</code></td>
<td>
<p>A matrix representing examinees' response data for the items in <code>x</code>.
Each row and column corresponds to an examinee and an item, respectively.</p>
</td></tr>
<tr><td><code id="llike_score_+3A_theta">theta</code></td>
<td>
<p>A numeric vector of ability parameters for which the loglikelihood
values will be computed.</p>
</td></tr>
<tr><td><code id="llike_score_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models that adjusts the logistic function to
approximate the normal ogive function (set to 1.7). The default is 1.</p>
</td></tr>
<tr><td><code id="llike_score_+3A_method">method</code></td>
<td>
<p>A character string specifying the scoring method. Options include
&quot;ML&quot; for maximum likelihood estimation,  &quot;MLF&quot; for maximum likelihood estimation
with fences, and &quot;MAP&quot; for maximum a posteriori estimation. The default method is &quot;MLE&quot;.</p>
</td></tr>
<tr><td><code id="llike_score_+3A_norm.prior">norm.prior</code></td>
<td>
<p>A numeric vector of two elements indicating the mean and standard
deviation of the normal prior distribution. These parameters are used to obtain
the Gaussian quadrature points and corresponding weights from the normal distribution.
Default is c(0,1). This parameter is ignored if <code>method</code> is &quot;ML&quot; or &quot;MLF&quot;.</p>
</td></tr>
<tr><td><code id="llike_score_+3A_fence.a">fence.a</code></td>
<td>
<p>A numeric value defining the item slope parameter (a-parameter) for
the two imaginary items in the MLF method. Default is 3.0.</p>
</td></tr>
<tr><td><code id="llike_score_+3A_fence.b">fence.b</code></td>
<td>
<p>A numeric vector of two elements specifying the lower and upper fences
of item difficulty parameters (b-parameters) for the two imaginary items in the MLF method.
If <code>fence.b = NULL</code>, the <code>range</code> values are used to set the fences.
The default is NULL.</p>
</td></tr>
<tr><td><code id="llike_score_+3A_missing">missing</code></td>
<td>
<p>A value used to denote missing values in the response data set. Default is NA.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the loglikelihood value of the ability parameter given
the item parameters and response data for each item. As an example, to assess the loglikelihoods
of abilities for two examinees who have taken the same test items specified in <code>x</code>, supply
their item response data matrix with two rows in <code>data</code> and a vector of ability values
for which loglikelihood needs to be computed in <code>theta</code>.
</p>


<h3>Value</h3>

<p>A data frame of loglikelihood values. Each row indicates the ability parameter
for which the loglikelihood was computed, and each column represents a response pattern.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#'
## Import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# Read item parameters and transform them into item metadata
x &lt;- bring.flexmirt(file=flex_sam, "par")$Group1$full_df

# Generate examinees' abilities from N(0, 1)
set.seed(10)
score &lt;- rnorm(5, mean=0, sd=1)

# Simulate the response data
data &lt;- simdat(x=x, theta=score, D=1)

# Specify the ability values for which the loglikelihood values will be computed
theta &lt;- seq(-3, 3, 0.5)

# Compute the loglikelihood values (using the MLE method)
llike_score(x=x, data=data, theta=theta, D=1, method="ML")

</code></pre>

<hr>
<h2 id='LSAT6'>LSAT6 data</h2><span id='topic+LSAT6'></span>

<h3>Description</h3>

<p>Well-known LSAT6 dichotomous response data set from Thissen (1982).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LSAT6
</code></pre>


<h3>Format</h3>

<p>This data contains 1,000 dichotomous response patterns of five items obtained from
the Law School Admissions Test, section 6.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Thissen, D. (1982). Marginal maximum likelihood estimation for the one-parameter logistic model.
<em>Psychometrika, 47</em>, 175-186.
</p>

<hr>
<h2 id='lwrc'>Lord-Wingersky Recursion Formula</h2><span id='topic+lwrc'></span>

<h3>Description</h3>

<p>This function computes the conditional distributions of number-correct (or observed) scores
given probabilities of category responses to items or given a set of theta values using Lord and
Wingersky recursion formula (1984).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lwrc(x = NULL, theta, prob = NULL, cats, D = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lwrc_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...).
See <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code> or <code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata.
This data frame can be easily obtained using the function <code><a href="#topic+shape_df">shape_df</a></code>. If <code>prob = NULL</code>, this data frame is
used in the recursion formula. See below for details.</p>
</td></tr>
<tr><td><code id="lwrc_+3A_theta">theta</code></td>
<td>
<p>A vector of theta values where the conditional distribution of observed scores are computed.
The theta values are only required when a data frame is specified in the argument <code>x</code>.</p>
</td></tr>
<tr><td><code id="lwrc_+3A_prob">prob</code></td>
<td>
<p>A matrix containing the probability of answering each category of an item. Each row indicates an item and
each column represents each category of the item. When the number of categories differs between items, the empty cells
should be filled with zeros or NA values. If <code>x = NULL</code>, this probability matrix is used in the recursion Formula.</p>
</td></tr>
<tr><td><code id="lwrc_+3A_cats">cats</code></td>
<td>
<p>A numeric vector specifying the number of categories for each item. For example, a dichotomous
item has two categories. This information is only required when a probability matrix is specified in the argument
<code>prob</code>.</p>
</td></tr>
<tr><td><code id="lwrc_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function
(if set to 1.7). Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Lord and Wingersky recursive algorithm is an efficient way of calculating the compound probabilities
of any number-correct scores on a test based on IRT models. This algorithm is particularly useful when computing
the IRT model-based observed score distribution for a test.
</p>
<p>To compute the conditional distributions of observed scores, either the item metadata set specified in <code>x</code> or
the probability matrix specified in <code>prob</code> can be used.
</p>


<h3>Value</h3>

<p>When the <code>prob</code> argument is provided, this function returns a vector of the probabilities of obtaining every
observed score on a test. When the <code>x</code> argument is specified, the function returns a matrix of conditional probabilities
across all possible observed scores and theta values.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Kolen, M. J. &amp; Brennan, R. L. (2004) <em>Test Equating, Scaling, and Linking</em> (2nd ed.). New York:
Springer.
</p>
<p>Lord, F. &amp; Wingersky, M. (1984). Comparison of IRT true score and equipercentile observed score equatings.
<em>Applied Psychological Measurement, 8</em>(4), 453-461.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1: when a matrix of probabilities is used as a data set
## this is an example from Kolen and Brennan (2004, p. 183)
# create a matrix of probabilities of getting correct and incorrect answers for three items
probs &lt;- matrix(c(.74, .73, .82, .26, .27, .18), nrow=3, ncol=2, byrow = FALSE)

# create a vector of score categories for the three items
cats &lt;- c(2,2,2)

# compute the conditional distributions of observed scores
lwrc(prob=probs, cats=cats)

## example 2: when a matrix of probabilities is used as a data set
## with a mixed-format test
# category probabilities for a dichotomous item
p1 &lt;- c(0.2, 0.8, 0, 0, 0)
# category probabilities for a dichotomous item
p2 &lt;- c(0.4, 0.6, NA, NA, NA)
# category probabilities for a polytomous item with five categories
p3 &lt;- c(0.1, 0.2, 0.2, 0.4, 0.1)
# category probabilities for a polytomous item with three categories
p4 &lt;- c(0.5, 0.3, 0.2, NA, NA)

# rbind the probability vectors
p &lt;- rbind(p1, p2, p3, p4)

# create a vector of score categories for the four items
cats &lt;- c(2, 2, 5, 3)

# compute the conditional distributions of observed scores
lwrc(prob=p, cats=cats)

## example 3: when a data frame for the item metadata of
## a mixed-format test is used.
# import the "-prm.txt" output file from flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameters and transform them to item metadata
x &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df

# compute the conditional distributions of observed scores
lwrc(x=x, theta=seq(-4, 4, 0.2), D=1)

</code></pre>

<hr>
<h2 id='plot.info'>Plot Item and Test Information Functions</h2><span id='topic+plot.info'></span>

<h3>Description</h3>

<p>This method function plots item or test information function given a specified theta values. In addition,
it displays the conditional standard errors at a test level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'info'
plot(
  x,
  item.loc = NULL,
  overlap = FALSE,
  csee = FALSE,
  xlab.text,
  ylab.text,
  main.text,
  lab.size = 15,
  main.size = 15,
  axis.size = 15,
  line.color,
  line.size = 1,
  layout.col = 4,
  strip.size = 12,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.info_+3A_x">x</code></td>
<td>
<p>x An object of class <code><a href="#topic+info">info</a></code>.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_item.loc">item.loc</code></td>
<td>
<p>A vector of numeric values indicating that the item information functions of the <em>n</em>th items
(or the location of items in a test form) are plotted. If NULL, the test information function for the total test form is drawn.
Default is NULL.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_overlap">overlap</code></td>
<td>
<p>Logical value indicating whether multiple item information functions are plotted in one panel.
If FALSE, multiple item information functions are displayed in multiple panels, one for each.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_csee">csee</code></td>
<td>
<p>Logical value indicating whether the function displays the conditional standard error of estimation (CSEE) at a test level.
If FALSE, item/test information function is plotted. Note that the CSEE plot is displayed only at a test level.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_xlab.text">xlab.text</code>, <code id="plot.info_+3A_ylab.text">ylab.text</code></td>
<td>
<p>A title for the x and y axes.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_main.text">main.text</code></td>
<td>
<p>An overall title for the plot.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_lab.size">lab.size</code></td>
<td>
<p>The size of xlab and ylab. Default is 15.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_main.size">main.size</code></td>
<td>
<p>The size of <code>main.text</code>. Default is 15.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_axis.size">axis.size</code></td>
<td>
<p>The size of labels along the x and y axes. Default is 15.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_line.color">line.color</code></td>
<td>
<p>A character string specifying a color for the line. See <a href="http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/">http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/</a>
for more details about colors used in ggplot2.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_line.size">line.size</code></td>
<td>
<p>The size of lines. Default is 1.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_layout.col">layout.col</code></td>
<td>
<p>An integer value indicating the number of columns in the panel when displaying the item information functions of
the multiple items. Default is 4.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_strip.size">strip.size</code></td>
<td>
<p>The size of facet labels when the item information functions of the multiple items are drawn.</p>
</td></tr>
<tr><td><code id="plot.info_+3A_...">...</code></td>
<td>
<p>Further arguments passed from the function <code>geom_line()</code> in the <span class="pkg">ggplot2</span> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All of the plots are drawn using the ggplot2 package.
The object of class <code><a href="#topic+info">info</a></code> can be obtained from the function <code><a href="#topic+info">info</a></code>.
</p>


<h3>Value</h3>

<p>This method function displays the item or test information function plot. When <code>csee = TRUE</code>,
the conditional standard error is returned at the test level.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+info">info</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## the use of a "-prm.txt" file obtained from a flexMIRT
# import the "-prm.txt" output file from flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameters and transform them to item metadata
test_flex &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df

# set theta values
theta &lt;- seq(-4, 4, 0.1)

# compute item and test information values given the theta values
x &lt;- info(x=test_flex, theta=theta, D=1, tif=TRUE)

# draw a plot of the test information function
plot(x)

# draw a plot of the item information function for the second item
plot(x, item.loc=2)

# draw a plot of multiple item information functions across the multiple panels
plot(x, item.loc=1:8, overlap=FALSE)

# draw a plot of multiple item information functions in one panel
plot(x, item.loc=1:8, overlap=TRUE)

# draw a plot of conditional standard error at a test level
plot(x, csee=TRUE)

</code></pre>

<hr>
<h2 id='plot.irtfit'>Draw raw and standardized residual plots</h2><span id='topic+plot.irtfit'></span>

<h3>Description</h3>

<p>This method function provides graphical displays to look at residuals between the observed data
and model-based predictions (Hambleton, Swaminathan, &amp; Rogers, 1991). This function gives two residual plots for
each score category of an item: (a) the raw residual plot and (b) the standardized residual plot. Note that
for dichotomous items the residual plots are drawn only for the score category of 1.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'irtfit'
plot(
  x,
  item.loc = NULL,
  type = "both",
  ci.method = c("wald", "wilson", "wilson.cr"),
  show.table = TRUE,
  layout.col = 2,
  xlab.text,
  ylab.text,
  main.text,
  lab.size = 15,
  main.size = 15,
  axis.size = 15,
  line.size = 1,
  point.size = 2.5,
  strip.size = 12,
  ylim.icc = c(0, 1),
  ylim.sr.adjust = FALSE,
  ylim.sr = c(-4, 4),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.irtfit_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+irtfit">irtfit</a></code>.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_item.loc">item.loc</code></td>
<td>
<p>An integer value indicating that the <em>n</em>th item (or the location of the item) is plotted. See below for
details.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_type">type</code></td>
<td>
<p>A character string indicating what type of residual plot is returned. Available options
are &quot;icc&quot; for the raw residual plot, &quot;sr&quot; for the standardized residual plot, and &quot;both&quot; for both of them.
Default is &quot;both&quot;.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_ci.method">ci.method</code></td>
<td>
<p>A character string indicating what method is used to estimate the confidence interval for the raw residual plot.
Available options are &quot;wald&quot; for Wald method, &quot;wilson&quot; for Wilson score interval, and
&quot;wilson.cr&quot; for Wilson score interval with continuity correction. Default is &quot;wald&quot;. See below for details.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_show.table">show.table</code></td>
<td>
<p>A logical value. If TRUE, a contingency table containing the information used to draw the residual
plots for the studied item is returned. This contingency table is the same as one contained in the internal object of <code>contingency.plot</code>
in the object of class <code><a href="#topic+irtfit">irtfit</a></code>. Default is TRUE.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_layout.col">layout.col</code></td>
<td>
<p>An integer value indicating the number of columns in the panel when a polytomous item is used.
Default is 2.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_xlab.text">xlab.text</code></td>
<td>
<p>A title for the x axis. If missing, the default string is used.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_ylab.text">ylab.text</code></td>
<td>
<p>A title for the y axis. If <code>type = "both"</code>, two character strings can be
specified for the raw residual and standardized residual plots, respectively. If missing,
the default strings are used.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_main.text">main.text</code></td>
<td>
<p>An overall title for the plot. If <code>type = "both"</code>, two character strings
can be specified for the raw residual and standardized residual plots, respectively. If missing,
the default strings are used.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_lab.size">lab.size</code></td>
<td>
<p>The size of xlab and ylab. Default is 15.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_main.size">main.size</code></td>
<td>
<p>The size of <code>main.text</code>. Default is 15.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_axis.size">axis.size</code></td>
<td>
<p>The size of labels along the x and y axes. Default is 15.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_line.size">line.size</code></td>
<td>
<p>The size of lines. Default is 1.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_point.size">point.size</code></td>
<td>
<p>The size of points. Default is 2.5.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_strip.size">strip.size</code></td>
<td>
<p>The size of facet labels. Default is 12.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_ylim.icc">ylim.icc</code></td>
<td>
<p>A vector of two numeric values specifying the range of y axis for the raw residual plot. Default is c(0, 1).</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_ylim.sr.adjust">ylim.sr.adjust</code></td>
<td>
<p>A logical value. If TRUE, the range of y axis for the standardized residual plot is adjusted for each item.
If FALSE, the range of y axis for the standardized residual plot is fixed to the values specified in the argument <code>ylim.sr</code>.</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_ylim.sr">ylim.sr</code></td>
<td>
<p>A vector of two numeric values specifying the range of y axis for the standardized residual plot.
Default is c(-4, 4).</p>
</td></tr>
<tr><td><code id="plot.irtfit_+3A_...">...</code></td>
<td>
<p>Further arguments passed from the function <code>ggplot()</code> in the <span class="pkg">ggplot2</span> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All of the plots are drawn using the ggplot2 package.
</p>
<p>Once the results of the IRT model fit analysis are obtained from the function <code><a href="#topic+irtfit">irtfit</a></code>,
an object of class <code><a href="#topic+irtfit">irtfit</a></code> can be used to draw the IRT raw residual and standardized residual plots. Especially, the information
contained in an internal object of <code>contingency.plot</code> are mainly used to draw the residual plots.
</p>
<p>Because the residual plots are drawn for an item at a time, you have to indicate which item will be evaluated. For this,
you should specify an integer value, which is the location of the studied item, in the argument <code>item.loc</code>.
For example, if you want to draw the residual plots for the third item, then <code>item.loc = 3</code>.
</p>
<p>In terms of the raw residual plot, the argument <code>ci.method</code> is used to select a method to estimate the confidence intervals
among four methods. Those methods are &quot;wald&quot; for the Wald interval, which is based on the normal approximation (Laplace, 1812),
&quot;wilson&quot; for Wilson score interval (Wilson, 1927), and &quot;wilson.cr&quot; for Wilson score interval with continuity correction (Newcombe, 1998).
See <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval">https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval</a> for more details about
the binomial proportion confidence intervals. Note that the width of confidence interval is determined by the <code class="reqn">\alpha</code>-level
specified in the argument <code>alpha</code> of the function <code><a href="#topic+irtfit">irtfit</a></code>.
</p>
<p>Regarding the standardized residual plot, any standardized residuals greater than the specified criterion value
in the argument <code>overSR</code> of the function <code><a href="#topic+irtfit">irtfit</a></code> are displayed with circles. Otherwise,
they are displayed with crosses.
</p>


<h3>Value</h3>

<p>This method function displays the IRT raw residual plot, the standard residual plot, or both of the studied item.
when <code>show.table = TRUE</code>, a contingency table used to draw the residual plots is also returned. See <code><a href="#topic+irtfit">irtfit</a></code>
for more detail about the contingency table.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Hambleton, R. K., Swaminathan, H., &amp; Rogers, H. J. (1991).<em>Fundamentals of item response theory</em>. Newbury Park, CA: Sage.
</p>
<p>Laplace, P. S. (1820).<em>Theorie analytique des probabilites</em> (in French). Courcier.
</p>
<p>Newcombe, R. G. (1998). Two-sided confidence intervals for the single proportion: comparison of seven methods.
<em>Statistics in medicine, 17</em>(8), 857-872.
</p>
<p>Wilson, E. B. (1927). Probable inference, the law of succession, and statistical inference.
<em>Journal of the American Statistical Association, 22</em>(158), 209-212.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irtfit">irtfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select the first two dichotomous items and last polytomous item
x &lt;- bring.flexmirt(file=flex_sam, "par")$Group1$full_df[c(1:2, 55), ]

# generate examinees' abilities from N(0, 1)
set.seed(23)
score &lt;- rnorm(1000, mean=0, sd=1)

# simulate the response data
data &lt;- simdat(x=x, theta=score, D=1)


# compute fit statistics
fit &lt;- irtfit(x=x, score=score, data=data, group.method="equal.freq",
               n.width=11, loc.theta="average", range.score=c(-4, 4), D=1, alpha=0.05, overSR=1.5)

# residual plots for the first item (dichotomous item)
plot(x=fit, item.loc=1, type = "both", ci.method = "wald", show.table=TRUE, ylim.sr.adjust=TRUE)

# residual plots for the third item (polytomous item)
plot(x=fit, item.loc=3, type = "both", ci.method = "wald", show.table=FALSE, ylim.sr.adjust=TRUE)

# raw residual plot for the third item (polytomous item)
plot(x=fit, item.loc=3, type = "icc", ci.method = "wald", show.table=TRUE, ylim.sr.adjust=TRUE)

# standardized residual plot for the third item (polytomous item)
plot(x=fit, item.loc=3, type = "sr", ci.method = "wald", show.table=TRUE, ylim.sr.adjust=TRUE)


</code></pre>

<hr>
<h2 id='plot.traceline'>Plot ICC and TCC</h2><span id='topic+plot.traceline'></span>

<h3>Description</h3>

<p>This method function plots item or test characteristic curve using the ggplot2 package. The item characteristic
(or category) curve (ICC) or item score curve is drawn for an individual item. The test characteristic curve (TCC) is drawn
based on a total test form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'traceline'
plot(
  x,
  item.loc = NULL,
  score.curve = FALSE,
  overlap = FALSE,
  layout.col = 2,
  xlab.text,
  ylab.text,
  main.text,
  lab.size = 15,
  main.size = 15,
  axis.size = 15,
  line.color,
  line.size = 1,
  strip.size = 12,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.traceline_+3A_x">x</code></td>
<td>
<p>An object of class <code><a href="#topic+traceline">traceline</a></code>.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_item.loc">item.loc</code></td>
<td>
<p>A numeric value indicating that the <em>n</em>th item (or the location of item) is plotted.
If NULL, the TCC based on a total test form is drawn. Default is NULL.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_score.curve">score.curve</code></td>
<td>
<p>Logical value. If TRUE, item score curve (i.e., a weighted sum of item category probabilities over the item scores) is plotted
in a panel. Otherwise, ICCs for all score categories are plotted in separate panels. For a dichotomous item, the item score curve is the same as
the ICC of score category 1. Ignored when <code>item.loc = NULL</code>. Default is FALSE.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_overlap">overlap</code></td>
<td>
<p>Logical value indicating whether multiple item score curves are plotted in one panel.
If FALSE, the multiple item score curves are displayed with multiple panels, one for each.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_layout.col">layout.col</code></td>
<td>
<p>An integer value indicating the number of columns in the panel when displaying ICCs for an item or
when displaying multiple item scores with multiple panels.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_xlab.text">xlab.text</code>, <code id="plot.traceline_+3A_ylab.text">ylab.text</code></td>
<td>
<p>A title for the x and y axes.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_main.text">main.text</code></td>
<td>
<p>An overall title for the plot.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_lab.size">lab.size</code></td>
<td>
<p>The size of xlab and ylab. Default is 15.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_main.size">main.size</code></td>
<td>
<p>The size of <code>main.text</code>. Default is 15.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_axis.size">axis.size</code></td>
<td>
<p>The size of labels along the x and y axes. Default is 15.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_line.color">line.color</code></td>
<td>
<p>A character string specifying the color for a line. See <a href="http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/">http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/</a> for more details
about colors used in ggplot2.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_line.size">line.size</code></td>
<td>
<p>The size of lines. Default is 1.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_strip.size">strip.size</code></td>
<td>
<p>The size of facet labels when ICCs for an item are plotted.</p>
</td></tr>
<tr><td><code id="plot.traceline_+3A_...">...</code></td>
<td>
<p>Further arguments passed from the function <code>geom_line()</code> in the <span class="pkg">ggplot2</span> package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All of the plots are drawn using the ggplot2 package.
If <code>item.loc = NULL</code>, the TCC based on the total test form is plotted. In the argument <code>item.loc</code>,
a vector of positive integer values should be specified to indicate the <em>n</em>th items among the total test form. For example,
if there are ten items in the test form and the score curves of the 1st, 2nd, and 3rd items should be plotted, then <code>item.loc = 1:3</code>.
</p>


<h3>Value</h3>

<p>This method function displays ICC or TCC plots of the studied item(s).
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+traceline">traceline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example
## using a "-prm.txt" file obtained from a flexMIRT
# import the "-prm.txt" output file from flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameters and transform them to item metadata
test_flex &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df

# set theta values
theta &lt;- seq(-3, 3, 0.1)

# compute the item category probabilities and item/test
# characteristic functions given the theta values
x &lt;- traceline(x=test_flex, theta, D=1)

# plot TCC based on the total test form
plot(x, item.loc=NULL)

# plot ICCs for the first item (dichotomous item)
plot(x, item.loc=1, score.curve=FALSE, layout.col=2)

# plot item score curve for the first item (dichotomous item)
plot(x, item.loc=1, score.curve=TRUE)

# plot item score curves for the first six dichotomous items
# with multiple panels
plot(x, item.loc=1:6, score.curve=TRUE, overlap=FALSE)

# plot item score curve for the first six dichotomous items
# in one panel
plot(x, item.loc=1:6, score.curve=TRUE, overlap=TRUE)

# plot ICCs for the last item (polytomous item)
plot(x, item.loc=55, score.curve=FALSE, layout.col=2)

# plot item score curve for the last item (polytomous item)
plot(x, item.loc=55, score.curve=TRUE)

# plot item score curves for the last three polytomous items
# with multiple panels
plot(x, item.loc=53:55, score.curve=TRUE, overlap=FALSE)

# plot item score curves for the last three polytomous items
# in one panel
plot(x, item.loc=53:55, score.curve=TRUE, overlap=TRUE)

</code></pre>

<hr>
<h2 id='prm'>Polytomous Response Model (PRM) Probabilities (GRM and GPCM)</h2><span id='topic+prm'></span>

<h3>Description</h3>

<p>This function computes the probability of selecting a specific category for an item
for a given set of theta values using the graded response model and (generalized) partial credit model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prm(theta, a, d, D = 1, pr.model = c("GRM", "GPCM"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prm_+3A_theta">theta</code></td>
<td>
<p>A vector of ability values.</p>
</td></tr>
<tr><td><code id="prm_+3A_a">a</code></td>
<td>
<p>A numeric value of item discrimination (or slope) parameter.</p>
</td></tr>
<tr><td><code id="prm_+3A_d">d</code></td>
<td>
<p>A vector of item difficulty (or threshold) parameters.</p>
</td></tr>
<tr><td><code id="prm_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal
ogive function  (if set to 1.7). Default is 1.</p>
</td></tr>
<tr><td><code id="prm_+3A_pr.model">pr.model</code></td>
<td>
<p>A character string indicating the polytomous model being used. Available models are &quot;GRM&quot; for
the the graded response model and &quot;GPCM&quot; for the (generalized) partial credit model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the category probabilities are computed for an item with the partial credit model, provide <code>a = 1</code> for that item.
When <code>model = "GPCM"</code>, <code>d</code> should include the item difficulty (or threshold) parameters. In the <span class="pkg">irtQ</span> package,
the item difficulty (or threshold) parameters of category boundaries for GPCM are expressed as the item location (or overall difficulty)
parameter subtracted by the threshold parameter for unique score categories of the item. Note that when an GPCM item has <em>K</em>
unique score categories, <em>K-1</em> item difficulty parameters are necessary because the item difficulty parameter for the first category
boundary is always 0. For example, if an GPCM item has five score categories, four item difficulty parameters should be specified.
For more details about the parameterization of the (generalized) partial credit model, See <code>IRT Models</code> section
in the page of <code><a href="#topic+irtQ-package">irtQ-package</a></code>.
</p>


<h3>Value</h3>

<p>This function returns a matrix where a row indicates the ability and a column represents
score categories of the item.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+drm">drm</a></code>, <code><a href="#topic+irtfit">irtfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Category probabilities for an item with four categories
## using a generalized partial credit model
prm(theta=c(-0.2, 0, 0.5), a=1.4, d=c(-0.2, 0, 0.5), D=1, pr.model='GPCM')

## Category probabilities for an item with five categories
## using a graded response model
prm(theta=c(-0.2, 0, 0.5), a=1.2, d=c(-0.4, -0.2, 0.4, 1.5), D=1, pr.model='GRM')


</code></pre>

<hr>
<h2 id='rdif'>IRT residual-based differential item functioning (RDIF) detection framework</h2><span id='topic+rdif'></span><span id='topic+rdif.default'></span><span id='topic+rdif.est_irt'></span><span id='topic+rdif.est_item'></span>

<h3>Description</h3>

<p>This function computes three RDIF statistics (Lim &amp; Choe, In press; Lim, Choe, &amp; Han, 2022),
which are <code class="reqn">RDIF_{R}</code>, <code class="reqn">RDIF_{S}</code>, and <code class="reqn">RDIF_{RS}</code>, for each item. <code class="reqn">RDIF_{R}</code> primarily
captures the typical contrast in raw residual pattern between two groups caused by uniform DIF whereas
<code class="reqn">RDIF_{S}</code> primarily captures the typical contrast in squared residual pattern between two groups caused
by nonuniform DIF. <code class="reqn">RDIF_{RS}</code> can reasonably capture both types of DIF.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdif(x, ...)

## Default S3 method:
rdif(
  x,
  data,
  score = NULL,
  group,
  focal.name,
  D = 1,
  alpha = 0.05,
  missing = NA,
  purify = FALSE,
  purify.by = c("rdifrs", "rdifr", "rdifs"),
  max.iter = 10,
  min.resp = NULL,
  method = "ML",
  range = c(-5, 5),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  ncore = 1,
  verbose = TRUE,
  ...
)

## S3 method for class 'est_irt'
rdif(
  x,
  score = NULL,
  group,
  focal.name,
  alpha = 0.05,
  missing = NA,
  purify = FALSE,
  purify.by = c("rdifrs", "rdifr", "rdifs"),
  max.iter = 10,
  min.resp = NULL,
  method = "ML",
  range = c(-5, 5),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  ncore = 1,
  verbose = TRUE,
  ...
)

## S3 method for class 'est_item'
rdif(
  x,
  group,
  focal.name,
  alpha = 0.05,
  missing = NA,
  purify = FALSE,
  purify.by = c("rdifrs", "rdifr", "rdifs"),
  max.iter = 10,
  min.resp = NULL,
  method = "ML",
  range = c(-5, 5),
  norm.prior = c(0, 1),
  nquad = 41,
  weights = NULL,
  ncore = 1,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rdif_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...), an object of class <code><a href="#topic+est_item">est_item</a></code>
obtained from the function <code><a href="#topic+est_item">est_item</a></code>, or an object of class <code><a href="#topic+est_irt">est_irt</a></code> obtained from the function <code><a href="#topic+est_irt">est_irt</a></code>.
The item metadata can be easily created using the function <code><a href="#topic+shape_df">shape_df</a></code>. See <code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+irtfit">irtfit</a></code>,
<code><a href="#topic+info">info</a></code> or <code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata.</p>
</td></tr>
<tr><td><code id="rdif_+3A_...">...</code></td>
<td>
<p>Additional arguments that will be forwarded to the <code><a href="#topic+est_score">est_score</a></code> function.</p>
</td></tr>
<tr><td><code id="rdif_+3A_data">data</code></td>
<td>
<p>A matrix containing examinees' response data for the items in the argument <code>x</code>. A row and column indicate
the examinees and items, respectively.</p>
</td></tr>
<tr><td><code id="rdif_+3A_score">score</code></td>
<td>
<p>A vector of examinees' ability estimates. If the abilities are not provided, <code><a href="#topic+rdif">rdif</a></code> estimates the abilities before
computing the RDIF statistics. See <code><a href="#topic+est_score">est_score</a></code> for more details about scoring methods. Default is NULL.</p>
</td></tr>
<tr><td><code id="rdif_+3A_group">group</code></td>
<td>
<p>A numeric or character vector indicating group membership of examinees. The length of the vector should be the same
with the number of rows in the response data matrix.</p>
</td></tr>
<tr><td><code id="rdif_+3A_focal.name">focal.name</code></td>
<td>
<p>A single numeric or character scalar representing the level associated with the focal group. For instance,
given <code>group = c(0, 1, 0, 1, 1)</code> and '1' indicating the focal group, set <code>focal.name = 1</code>.</p>
</td></tr>
<tr><td><code id="rdif_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="rdif_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value to specify significance <code class="reqn">\alpha</code>-level of the hypothesis test using the RDIF statistics.
Default is .05.</p>
</td></tr>
<tr><td><code id="rdif_+3A_missing">missing</code></td>
<td>
<p>A value indicating missing values in the response data set. Default is NA.</p>
</td></tr>
<tr><td><code id="rdif_+3A_purify">purify</code></td>
<td>
<p>A logical value indicating whether a purification process will be implemented or not. Default is FALSE.</p>
</td></tr>
<tr><td><code id="rdif_+3A_purify.by">purify.by</code></td>
<td>
<p>A character string specifying a RDIF statistic with which the purification is implemented. Available statistics
are &quot;rdifrs&quot; for <code class="reqn">RDIF_{RS}</code>, &quot;rdifr&quot; for <code class="reqn">RDIF_{R}</code>, and &quot;rdifs&quot; for <code class="reqn">RDIF_{S}</code>.</p>
</td></tr>
<tr><td><code id="rdif_+3A_max.iter">max.iter</code></td>
<td>
<p>A positive integer value specifying the maximum number of iterations for
the purification process. Default is 10.</p>
</td></tr>
<tr><td><code id="rdif_+3A_min.resp">min.resp</code></td>
<td>
<p>A positive integer value specifying the minimum number of item responses for an examinee
required to compute the ability estimate. Default is NULL. See details below for more information.</p>
</td></tr>
<tr><td><code id="rdif_+3A_method">method</code></td>
<td>
<p>A character string indicating a scoring method. Available methods are &quot;ML&quot; for the maximum likelihood estimation,
&quot;WL&quot; for the weighted likelihood estimation, &quot;MAP&quot; for the maximum a posteriori estimation, and &quot;EAP&quot; for the expected
a posteriori estimation. Default method is &quot;ML&quot;.</p>
</td></tr>
<tr><td><code id="rdif_+3A_range">range</code></td>
<td>
<p>A numeric vector of two components to restrict the range of ability scale for the ML, WL, EAP, and MAP scoring methods.
Default is c(-5, 5).</p>
</td></tr>
<tr><td><code id="rdif_+3A_norm.prior">norm.prior</code></td>
<td>
<p>A numeric vector of two components specifying a mean and standard deviation of the normal prior distribution.
These two parameters are used to obtain the gaussian quadrature points and the corresponding weights from the normal distribution. Default is
c(0,1). Ignored if <code>method</code> is &quot;ML&quot; or &quot;WL&quot;.</p>
</td></tr>
<tr><td><code id="rdif_+3A_nquad">nquad</code></td>
<td>
<p>An integer value specifying the number of gaussian quadrature points from the normal prior distribution. Default is 41.
Ignored if <code>method</code> is &quot;ML&quot;, &quot;WL&quot;, or &quot;MAP&quot;.</p>
</td></tr>
<tr><td><code id="rdif_+3A_weights">weights</code></td>
<td>
<p>A two-column matrix or data frame containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the latent variable prior distribution. The weights and quadrature points can be easily obtained
using the function <code><a href="#topic+gen.weight">gen.weight</a></code>. If NULL and <code>method</code> is &quot;EAP&quot;, default values are used (see the arguments
of <code>norm.prior</code> and <code>nquad</code>). Ignored if <code>method</code> is &quot;ML&quot;, &quot;WL&quot; or &quot;MAP&quot;.</p>
</td></tr>
<tr><td><code id="rdif_+3A_ncore">ncore</code></td>
<td>
<p>The number of logical CPU cores to use. Default is 1. See <code><a href="#topic+est_score">est_score</a></code> for details.</p>
</td></tr>
<tr><td><code id="rdif_+3A_verbose">verbose</code></td>
<td>
<p>A logical value. If TRUE, the progress messages of purification procedure are suppressed. Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The RDIF framework (Lim et al., 2022) consists of three IRT residual-based statistics: <code class="reqn">RDIF_{R}</code>, <code class="reqn">RDIF_{S}</code>,
and <code class="reqn">RDIF_{RS}</code>. Under the null hypothesis that a test contains no DIF items, <code class="reqn">RDIF_{R}</code> and <code class="reqn">RDIF_{S}</code> follow
normal distributions asymptotically. <code class="reqn">RDIF_{RS}</code> is a based on a bivariate normal distribution of <code class="reqn">RDIF_{R}</code> and
<code class="reqn">RDIF_{S}</code> statistics. Under the null hypothesis of no DIF items, it follows a <code class="reqn">\chi^{2}</code> distribution asymptotically
with 2 degrees of freedom. See Lim et al. (2022) for more details about RDIF framework.
</p>
<p>The <code><a href="#topic+rdif">rdif</a></code> function computes all three RDIF statistics of <code class="reqn">RDIF_{R}</code>, <code class="reqn">RDIF_{S}</code>, and <code class="reqn">RDIF_{RS}</code>. The current
version of <code><a href="#topic+rdif">rdif</a></code> function supports both dichotomous and polytomous item response data. To compute the three statistics, the <code><a href="#topic+rdif">rdif</a></code> function
requires (1) item parameter estimates obtained from aggregate data regardless of group membership, (2) examinees' ability estimates
(e.g., ML), and (3) examinees' item response data. Note that the ability estimates need to be computed using the aggregate data-based
item parameter estimates. The item parameter estimates should be provided in the <code>x</code> argument, the ability estimates should
be provided in the <code>score</code> argument, and the response data should be provided in the <code>data</code> argument. When the abilities
are not given in the <code>score</code> argument (i.e., <code>score = NULL</code>), the <code><a href="#topic+rdif">rdif</a></code> function estimates examinees' abilities
automatically using the scoring method specified in the <code>method</code> argument (e.g., <code>method = "ML"</code>).
</p>
<p>The <code>group</code> argument accepts a vector of either two distinct numeric or character variables. Between two distinct variable, one is to
represent the reference group and another one is to represent the focal group. The length of the vector should be the same with the number
of rows in the response data and each value in the vector should indicate each examinee of the response data. Once the <code>gruop</code> is
specified, a single numeric or character value needs to be provided in the <code>focal.name</code> argument to define which group variable in
the <code>group</code> argument represents the focal group.
</p>
<p>As other DIF detection approaches, an iterative purification process can be implemented for the RDIF framework.
When <code>purify = TRUE</code>, the purification process is implemented based on one of RDIF statistics specified in the <code>purify.by</code>
argument (e.g, <code>purify.by="rdifrs"</code>). At each iterative purification, examinees' latent abilities are computed using purified items and
scoring method specified in the <code>method</code> argument. The iterative purification process stops when no further DIF items are found or
the process reaches a predetermined limit of iteration, which can be specified in the <code>max.iter</code> argument. See Lim et al. (2022)
for more details about the purification procedure.
</p>
<p>Scoring with a limited number of items can result in large standard errors, which may impact the effectiveness of DIF detection within
the RDIF framework. The <code>min.resp</code> argument can be employed to avoid using scores with significant standard errors when calculating
the RDIF statistics, particularly during the purification process. For instance, if <code>min.resp</code> is not NULL (e.g., <code>min.resp=5</code>),
item responses from examinees whose total item responses fall below the specified minimum number are treated as missing values (i.e., NA).
Consequently, their ability estimates become missing values and are not utilized in computing the RDIF statistics. If <code>min.resp=NULL</code>,
an examinee's score will be computed as long as there is at least one item response for the examinee.
</p>


<h3>Value</h3>

<p>This function returns a list of four internal objects. The four objects are:
</p>
<table>
<tr><td><code>no_purify</code></td>
<td>
<p>A list of several sub-objects containing the results of DIF analysis without a purification procedure. The sub-objects are:
</p>

<dl>
<dt>dif_stat</dt><dd><p>A data frame containing the results of three RDIF statistics across all evaluated items. From the first column, each column
indicates item's ID, <code class="reqn">RDIF_{R}</code> statistic, standardized <code class="reqn">RDIF_{R}</code>, <code class="reqn">RDIF_{S}</code> statistic, standardized <code class="reqn">RDIF_{S}</code>,
<code class="reqn">RDIF_{RS}</code> statistic, p-value of the <code class="reqn">RDIF_{R}</code>, p-value of the <code class="reqn">RDIF_{S}</code>, p-value of the <code class="reqn">RDIF_{RS}</code>, sample size of
the reference group, sample size of the focal group, and total sample size, respectively. Note that <code class="reqn">RDIF_{RS}</code> does not have its standardized
value because it is a <code class="reqn">\chi^{2}</code> statistic.</p>
</dd>
<dt>moments</dt><dd><p>A data frame containing the moments of three RDIF statistics. From the first column, each column indicates item's ID,
mean of <code class="reqn">RDIF_{R}</code>, standard deviation of <code class="reqn">RDIF_{R}</code>, mean of <code class="reqn">RDIF_{S}</code>, standard deviation of <code class="reqn">RDIF_{S}</code>, and
covariance of <code class="reqn">RDIF_{R}</code> and <code class="reqn">RDIF_{S}</code>, respectively.</p>
</dd>
<dt>dif_item</dt><dd><p>A list of three numeric vectors showing potential DIF items flagged by each of the RDIF statistics. Each of the numeric vector
means the items flagged by <code class="reqn">RDIF_{R}</code>, <code class="reqn">RDIF_{S}</code>, and <code class="reqn">RDIF_{RS}</code>, respectively.</p>
</dd>
<dt>score</dt><dd><p>A vector of ability estimates used to compute the RDIF statistics.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>purify</code></td>
<td>
<p>A logical value indicating whether the purification process was used.</p>
</td></tr>
<tr><td><code>with_purify</code></td>
<td>
<p>A list of several sub-objects containing the results of DIF analysis with a purification procedure. The sub-objects are:
</p>

<dl>
<dt>purify.by</dt><dd><p>A character string indicating which RDIF statistic is used for the purification. &quot;rdifr&quot;, &quot;rdifs&quot;, and &quot;rdifrs&quot; refers to
<code class="reqn">RDIF_{R}</code>, <code class="reqn">RDIF_{S}</code>, and <code class="reqn">RDIF_{RS}</code>, respectively.</p>
</dd>
<dt>dif_stat</dt><dd><p>A data frame containing the results of three RDIF statistics across all evaluated items. From the first column, each column
indicates item's ID, <code class="reqn">RDIF_{R}</code> statistic, standardized <code class="reqn">RDIF_{R}</code>, <code class="reqn">RDIF_{S}</code> statistic, standardized <code class="reqn">RDIF_{S}</code>,
<code class="reqn">RDIF_{RS}</code> statistic, p-value of the <code class="reqn">RDIF_{R}</code>, p-value of the <code class="reqn">RDIF_{S}</code>, p-value of the <code class="reqn">RDIF_{RS}</code>, sample size of
the reference group, sample size of the focal group, total sample size, and <em>n</em>th iteration where the RDIF statistics were computed,
respectively.</p>
</dd>
<dt>moments</dt><dd><p>A data frame containing the moments of three RDIF statistics. From the first column, each column indicates item's ID,
mean of <code class="reqn">RDIF_{R}</code>, standard deviation of <code class="reqn">RDIF_{R}</code>, mean of <code class="reqn">RDIF_{S}</code>, standard deviation of <code class="reqn">RDIF_{S}</code>, covariance
of <code class="reqn">RDIF_{R}</code> and <code class="reqn">RDIF_{S}</code>, and <em>n</em>th iteration where the RDIF statistics were computed, respectively.</p>
</dd>
<dt>dif_item</dt><dd><p>A list of three numeric vectors showing potential DIF items flagged by each of the RDIF statistics. Each of the numeric vector
means the items flagged by <code class="reqn">RDIF_{R}</code>, <code class="reqn">RDIF_{S}</code>, and <code class="reqn">RDIF_{RS}</code>, respectively.</p>
</dd>
<dt>n.iter</dt><dd><p>A total number of iterations implemented for the purification.</p>
</dd>
<dt>score</dt><dd><p>A vector of final purified ability estimates used to compute the RDIF statistics.</p>
</dd>
<dt>complete</dt><dd><p>A logical value indicating whether the purification process was completed. If FALSE, it means that the purification process
reached the maximum iteration number but it was not complete.</p>
</dd>
</dl>

</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>A significance <code class="reqn">\alpha</code>-level used to compute the p-values of RDIF statistics.</p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default method to computes three RDIF statistics using a data frame <code>x</code> containing the item metadata.
</p>
</li>
<li> <p><code>est_irt</code>: An object created by the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
</li>
<li> <p><code>est_item</code>: An object created by the function <code><a href="#topic+est_item">est_item</a></code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Lim, H., &amp; Choe, E. M. (2023). Detecting differential item functioning in CAT using IRT residual DIF approach.
<em>Journal of Educational Measurement</em>. <a href="https://doi.org/10.1111/jedm.12366">doi:10.1111/jedm.12366</a>.
</p>
<p>Lim, H., Choe, E. M., &amp; Han, K. T. (2022). A residual-based differential item functioning detection framework in
item response theory. <em>Journal of Educational Measurement, 59</em>(1), 80-104. <a href="https://doi.org/10.1111/jedm.12313">doi:10.1111/jedm.12313</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+est_item">est_item</a></code>, <code><a href="#topic+info">info</a></code>, <code><a href="#topic+simdat">simdat</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>,
<code><a href="#topic+gen.weight">gen.weight</a></code>, <code><a href="#topic+est_score">est_score</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# call library
library("dplyr")

## Uniform DIF detection
###############################################
# (1) manipulate true uniform DIF data
###############################################
# import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select 36 of 3PLM items which are non-DIF items
par_nstd &lt;-
  bring.flexmirt(file=flex_sam, "par")$Group1$full_df %&gt;%
  dplyr::filter(.data$model == "3PLM") %&gt;%
  dplyr::filter(dplyr::row_number() %in% 1:36) %&gt;%
  dplyr::select(1:6)
par_nstd$id &lt;- paste0("nondif", 1:36)

# generate four new items to inject uniform DIF
difpar_ref &lt;-
  shape_df(par.drm=list(a=c(0.8, 1.5, 0.8, 1.5), b=c(0.0, 0.0, -0.5, -0.5), g=0.15),
           item.id=paste0("dif", 1:4), cats=2, model="3PLM")

# manipulate uniform DIF on the four new items by adding constants to b-parameters
# for the focal group
difpar_foc &lt;-
  difpar_ref %&gt;%
  dplyr::mutate_at(.vars="par.2", .funs=function(x) x + rep(0.7, 4))

# combine the 4 DIF and 36 non-DIF items for both reference and focal groups
# thus, the first four items have uniform DIF
par_ref &lt;- rbind(difpar_ref, par_nstd)
par_foc &lt;- rbind(difpar_foc, par_nstd)

# generate the true thetas
set.seed(123)
theta_ref &lt;- rnorm(500, 0.0, 1.0)
theta_foc &lt;- rnorm(500, 0.0, 1.0)

# generate the response data
resp_ref &lt;- simdat(par_ref, theta=theta_ref, D=1)
resp_foc &lt;- simdat(par_foc, theta=theta_foc, D=1)
data &lt;- rbind(resp_ref, resp_foc)

###############################################
# (2) estimate the item and ability parameters
#     using the aggregate data
###############################################
# estimate the item parameters
est_mod &lt;- est_irt(data=data, D=1, model="3PLM")
est_par &lt;- est_mod$par.est

# estimate the ability parameters using ML
score &lt;- est_score(x=est_par, data=data, method="ML")$est.theta

###############################################
# (3) conduct DIF analysis
###############################################
# create a vector of group membership indicators
# where '1' indicates the focal group
group &lt;- c(rep(0, 500), rep(1, 500))

# (a)-1 compute RDIF statistics by providing scores,
#       and without a purification
dif_nopuri_1 &lt;- rdif(x=est_par, data=data, score=score,
                     group=group, focal.name=1, D=1, alpha=0.05)
print(dif_nopuri_1)

# (a)-2 compute RDIF statistics by not providing scores
#       and without a purification
dif_nopuri_2 &lt;- rdif(x=est_par, data=data, score=NULL,
                     group=group, focal.name=1, D=1, alpha=0.05,
                     method="ML")
print(dif_nopuri_2)

# (b)-1 compute RDIF statistics with a purification
#       based on RDIF(R)
dif_puri_r &lt;- rdif(x=est_par, data=data, score=score,
                   group=group, focal.name=1, D=1, alpha=0.05,
                   purify=TRUE, purify.by="rdifr")
print(dif_puri_r)

# (b)-2 compute RDIF statistics with a purification
#       based on RDIF(S)
dif_puri_s &lt;- rdif(x=est_par, data=data, score=score,
                   group=group, focal.name=1, D=1, alpha=0.05,
                   purify=TRUE, purify.by="rdifs")
print(dif_puri_s)

# (b)-3 compute RDIF statistics with a purification
#       based on RDIF(RS)
dif_puri_rs &lt;- rdif(x=est_par, data=data, score=score,
                    group=group, focal.name=1, D=1, alpha=0.05,
                    purify=TRUE, purify.by="rdifrs")
print(dif_puri_rs)


</code></pre>

<hr>
<h2 id='run_flexmirt'>Run flexMIRT through R</h2><span id='topic+run_flexmirt'></span>

<h3>Description</h3>

<p>This function implements flexMIRT (Cai, 2017) to run a model specified in the syntax file of
flexMIRT (i.e., *.flexmirt) through R. To run this function, flexMIRT software must be installed in advance.
This function will be useful especially when conducting a simulation study using flexMIRT.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_flexmirt(file.syntax, dir.flex = NULL, show.output.on.console = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="run_flexmirt_+3A_file.syntax">file.syntax</code></td>
<td>
<p>A single string or vector containing the file path(s) of a flexmirt syntax file(s) to be run.
An example is “C:/Users/Data/irtmodel.flexmirt&quot;.</p>
</td></tr>
<tr><td><code id="run_flexmirt_+3A_dir.flex">dir.flex</code></td>
<td>
<p>A path of directory where flexMIRT is installed. The path may include a folder name with &quot;flexMIRT&quot;
(e.g, flexMIRT3, flexMIRT 3.6). If NULL, a path where flexMIRT is installed will be searched in &quot;C:/Program Files&quot; and
it will be used as a default path (e.g., &quot;C:/Program Files/flexMIRT3&quot;, &quot;C:/Program Files/flexMIRT 3.6&quot;).</p>
</td></tr>
<tr><td><code id="run_flexmirt_+3A_show.output.on.console">show.output.on.console</code></td>
<td>
<p>A logical value to indicate whether to capture the output of the command and show it on the R console.
Default is FALSE. See <code><a href="base.html#topic+system">system</a></code>.</p>
</td></tr>
<tr><td><code id="run_flexmirt_+3A_...">...</code></td>
<td>
<p>Further arguments passed from the function <code><a href="base.html#topic+system">system</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When a path of directory where flexMIRT (with a version &lt; 3.6) is installed is provided
in the argument <code>dir.flex</code>, the directory must include following six file of
</p>

<ul>
<li><p> WinFlexMIRT.exe
</p>
</li>
<li><p> FlexMIRT_x64.exe
</p>
</li>
<li><p> FlexMIRT_x86.exe
</p>
</li>
<li><p> vpg.dll
</p>
</li>
<li><p> vpg.licensing.client.dll
</p>
</li>
<li><p> vpg.licensing.dll
</p>
</li></ul>

<p>When a path of directory where flexMIRT (with a version &gt;= 3.6) is installed is provided
in the argument <code>dir.flex</code>, the directory must include following six files of
</p>

<ul>
<li><p> WinFlexMIRT.exe
</p>
</li>
<li><p> vpg.dll
</p>
</li>
<li><p> vpg.licensing.client.dll
</p>
</li>
<li><p> vpg.licensing.dll
</p>
</li>
<li><p> VPGLicenseClientNet.dll
</p>
</li></ul>

<p>and an additional directory of &quot;Resources&quot; that contains two files which are
</p>

<ul>
<li><p> flexMIRT_x64_AVX.exe
</p>
</li>
<li><p> flexMIRT_x86_AVX.exe
</p>
</li></ul>



<h3>Value</h3>

<p>output files of flexMIRT
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Cai, L. (2017). flexMIRT 3.5 Flexible multilevel multidimensional item analysis and test scoring [Computer software].
Chapel Hill, NC: Vector Psychometric Group.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Emxaples below will run when flexMIRT software is installed
# in a default path of "C:/Program Files/flexMIRT3".
# Otherwise provide a path where flexMIRT software is installed
# in the argument 'dir.flex'.

## Not run: 
# (1) run a single syntax file
# import an example of flexMIRT syntax file to run the item parameter estimation of IRT 3PL model
file.syntax &lt;- system.file("extdata", "2PLM_example.flexmirt", package = "irtQ")

# run flexMIRT to estimate the item parameters of IRT 3PL model
run_flexmirt(file.syntax=file.syntax, dir.flex=NULL, show.output=TRUE)

# check the output file
out.file &lt;- system.file("extdata", "2PLM_example-prm.txt", package = "irtQ")
bring.flexmirt(out.file, type="par")

# (2) run multiple syntax files
# import two examples of flexMIRT syntax files
file.syntax1 &lt;- system.file("extdata", "2PLM_example.flexmirt", package = "irtQ")
file.syntax2 &lt;- system.file("extdata", "3PLM_example.flexmirt", package = "irtQ")

# run flexMIRT to estimate the item parameters
run_flexmirt(file.syntax=c(file.syntax1, file.syntax2), dir.flex=NULL, show.output=FALSE)

# check the output file
out.file1 &lt;- system.file("extdata", "2PLM_example-prm.txt", package = "irtQ")
out.file2 &lt;- system.file("extdata", "3PLM_example-prm.txt", package = "irtQ")
bring.flexmirt(out.file1, type="par")
bring.flexmirt(out.file2, type="par")

## End(Not run)


</code></pre>

<hr>
<h2 id='shape_df'>Create a data frame of item metadata</h2><span id='topic+shape_df'></span>

<h3>Description</h3>

<p>This function creates a data frame which includes item meta (e.g., item parameter, categories, models ...) to be
used for the IRT model-data fit analysis as well as other analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shape_df(
  par.drm = list(a = NULL, b = NULL, g = NULL),
  par.prm = list(a = NULL, d = NULL),
  item.id = NULL,
  cats,
  model,
  default.par = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="shape_df_+3A_par.drm">par.drm</code></td>
<td>
<p>A list containing three vectors of dichotomous item parameters. Namely, the item discrimination (a), item difficulty (b),
and item guessing parameters.</p>
</td></tr>
<tr><td><code id="shape_df_+3A_par.prm">par.prm</code></td>
<td>
<p>A list containing a vector of polytomous item discrimination (or slope) parameters and a list of polytomous item threshold
(or step) parameters. In this list, the argument <code>a</code> should have a vector of slope parameters and the argument <code>d</code> should include
a list of threshold (or step) parameters. See below for more details.</p>
</td></tr>
<tr><td><code id="shape_df_+3A_item.id">item.id</code></td>
<td>
<p>A character vector of item IDs. If NULL, an ID is automatically given to each item.</p>
</td></tr>
<tr><td><code id="shape_df_+3A_cats">cats</code></td>
<td>
<p>A vector containing the number of score categories for items.</p>
</td></tr>
<tr><td><code id="shape_df_+3A_model">model</code></td>
<td>
<p>A character vector of IRT models corresponding to items. The available IRT models are &quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for
dichotomous items, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous items. Note that &quot;DRM&quot; covers all dichotomous IRT models (i.e, &quot;1PLM&quot;, &quot;2PLM&quot;, and
&quot;3PLM&quot;) and &quot;GRM&quot; and &quot;GPCM&quot; represent the graded response model and (generalized) partial credit model, respectively.</p>
</td></tr>
<tr><td><code id="shape_df_+3A_default.par">default.par</code></td>
<td>
<p>A logical value to create an item meta with default item parameters. If TRUE, the number of score categories
and corresponding IRT models should be specified in the arguments of <code>cats</code> and <code>model</code>, respectively. In the default
item meta, the item slope parameter has a fixed value of 1, the item difficulty (or threshold) parameter(s) has(have) a fixed value of 0,
and the item guessing parameter has a fixed value of .2. Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For any item where &quot;1PLM&quot; or &quot;2PLM&quot; is specified in <code>model</code>, the item guessing parameter will be NA. If <code>model</code> is
a vector of <code class="reqn">length = 1</code>, the specified model is replicated across all items. As in the function <code><a href="#topic+simdat">simdat</a></code>, it is important
to clearly specify <code>cats</code> according to the order of items in the test form when a data frame for a mixed-format test needs to be created.
See <code><a href="#topic+simdat">simdat</a></code> for more details about how to specify <code>cats</code>.
</p>
<p>When specifying item parameters in <code>par.drm</code> and/or <code>par.prm</code>, keep the order of item parameter types. For example,
in the <code>par.drm</code> argument, the first argument <code>a</code> should contain the slope parameter vector, the second argument <code>b</code>
should contain the difficulty vector, and the third argument <code>g</code> should contain the guessing parameter vector.
In the <code>par.drm</code> argument, the first argument <code>a</code> should contain the slope parameter vector and the second argument <code>d</code>
should contain a list including vectors of item threshold (or step) parameters for polytomous response IRT models. Note that when an item follows
the (generalized) partial credit model, the item step parameters are the overall item difficulty (or location) parameter subtracted by
the difficulty (or threshold) parameter for each category. Thus, the number of step parameters for item with m categories is m-1 because
a step parameter for the first category does not affect the category probabilities.
</p>


<h3>Value</h3>

<p>This function returns a data frame.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+info">info</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## a mixed-item format test form
## with five dichotomous and two polytomous items
# create a list containing the dichotomous item parameters
par.drm &lt;- list(a=c(1.1, 1.2, 0.9, 1.8, 1.4),
                b=c(0.1, -1.6, -0.2, 1.0, 1.2),
                g=rep(0.2, 5))

# create a list containing the polytomous item parameters
par.prm &lt;- list(a=c(1.4, 0.6),
                d=list(c(0.0, -1.9, 1.2),
                       c(0.4, -1.1, 1.5, 0.2)))

# create a numeric vector of score categories for the items
cats &lt;- c(2, 4, 2, 2, 5, 2, 2)

# create a character vector of IRT models for the items
model &lt;- c("DRM", "GRM", "DRM", "DRM", "GPCM", "DRM", "DRM")

# create an item meta set
shape_df(par.drm=par.drm, par.prm=par.prm, cats=cats, model=model)

## an empty item meta with five dichotomous and two polytomous items
# create a numeric vector of score categories for the items
cats &lt;- c(2, 4, 3, 2, 5, 2, 2)

# create a character vector of IRT models for the items
model &lt;- c("1PLM", "GRM", "GRM", "2PLM", "GPCM", "DRM", "3PLM")

# create an empty item meta set
shape_df(cats=cats, model=model, default.par=TRUE)

## an item meta for a single-item format test form with five dichotomous
shape_df(par.drm=par.drm, cats=rep(2, 5), model="DRM")


</code></pre>

<hr>
<h2 id='simCAT_DC'>Simulated single-item format CAT Data</h2><span id='topic+simCAT_DC'></span>

<h3>Description</h3>

<p>This data set contains an item pool information, response data, and examinee's ability estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simCAT_DC
</code></pre>


<h3>Format</h3>

<p>This data includes a list of length three. The first internal object is a data.frame of
the item pool consisting of 100 dichotomous items. The item parameters of the first 90 items were generated with
the IRT 2PL model and calibrated with the same model. However, the item parameters of the last 10 items were
generated with the IRT 3PL model but calibrated with the IRT 2PL model. The second internal object is the response
data set including a sparse response data set of 10,000 examinees for the items in the item pool.
The third internal object is the examinee's ability estimates for 10,000 examinees.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>

<hr>
<h2 id='simCAT_MX'>Simulated mixed-item format CAT Data</h2><span id='topic+simCAT_MX'></span>

<h3>Description</h3>

<p>This data set contains an item pool information, response data, and examinee's ability estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simCAT_MX
</code></pre>


<h3>Format</h3>

<p>This data includes a list of length three. The first internal object is a data.frame of
the item pool consisting of 200 dichotomous items and 30 polytomous items. The dichotomous items were
calibrated with the IRT 3PL model and the polytomous items were calibrated with the generalized
partial credit model. All polytomous items have three score categories (i.e., 0, 1, 2). The second
internal object is the response data set including a sparse response data set of 30,000 examinees
for the items in the item pool. The third internal object is the examinee's ability estimates
for 30,000 examinees.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>

<hr>
<h2 id='simdat'>Simulated Response Data</h2><span id='topic+simdat'></span>

<h3>Description</h3>

<p>This function generates a simulated response data for a single- or a mixed-format test forms. For dichotomous
item response data, the IRT 1PL, 2PL, and 3PL models are available. For polytomous item response data, the graded response model,
the partial credit model, and the generalized partial credit model are available.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simdat(
  x = NULL,
  theta,
  a.drm,
  b.drm,
  g.drm = NULL,
  a.prm,
  d.prm,
  cats,
  pr.model,
  D = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simdat_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...). This data frame
can be easily obtained using the function <code><a href="#topic+shape_df">shape_df</a></code>. See below for details.</p>
</td></tr>
<tr><td><code id="simdat_+3A_theta">theta</code></td>
<td>
<p>A vector of theta values.</p>
</td></tr>
<tr><td><code id="simdat_+3A_a.drm">a.drm</code></td>
<td>
<p>A vector of item discrimination (or slope) parameters for dichotomous response IRT models.</p>
</td></tr>
<tr><td><code id="simdat_+3A_b.drm">b.drm</code></td>
<td>
<p>A vector of item difficulty (or threshold) parameters for dichotomous response IRT models.</p>
</td></tr>
<tr><td><code id="simdat_+3A_g.drm">g.drm</code></td>
<td>
<p>A vector of item guessing parameters for dichotomous IRT models.</p>
</td></tr>
<tr><td><code id="simdat_+3A_a.prm">a.prm</code></td>
<td>
<p>A vector of item discrimination (or slope) parameters for polytomous response IRT models.</p>
</td></tr>
<tr><td><code id="simdat_+3A_d.prm">d.prm</code></td>
<td>
<p>A list containing vectors of item threshold (or step) parameters for polytomous response IRT models.</p>
</td></tr>
<tr><td><code id="simdat_+3A_cats">cats</code></td>
<td>
<p>A vector containing the number of score categories for items.</p>
</td></tr>
<tr><td><code id="simdat_+3A_pr.model">pr.model</code></td>
<td>
<p>A vector of character strings specifying the polytomous model with which response data are simulated.
For each polytomous model, &quot;GRM&quot; for the graded response model or &quot;GPCM&quot; for the (generalized) partial credit model can be
specified.</p>
</td></tr>
<tr><td><code id="simdat_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>There are two ways of generating the simulated response data.
The first way is by using the argument <code>x</code> to read in a data frame of item metadata. In the data frame, the first column should have item IDs,
the second column should contain unique score category numbers of the items, and the third column should include IRT models being fit to the items.
The available IRT models are &quot;1PLM&quot;, &quot;2PLM&quot;, &quot;3PLM&quot;, and &quot;DRM&quot; for dichotomous item data, and &quot;GRM&quot; and &quot;GPCM&quot; for polytomous item data.
Note that &quot;DRM&quot; covers all dichotomous IRT models (i.e, &quot;1PLM&quot;, &quot;2PLM&quot;, and &quot;3PLM&quot;) and &quot;GRM&quot; and &quot;GPCM&quot; represent the graded
response model and (generalized) partial credit model, respectively. The next columns should include the item parameters of the fitted IRT models.
For dichotomous items, the fourth, fifth, and sixth columns represent the item discrimination (or slope), item difficulty, and
item guessing parameters, respectively. When &quot;1PLM&quot; and &quot;2PLM&quot; are specified in the third column, NAs should be inserted in the sixth column
for the item guessing parameters. For polytomous items, the item discrimination (or slope) parameters should be included in the
fourth column and the item difficulty (or threshold) parameters of category boundaries should be contained from the fifth to the last columns.
When the number of unique score categories differs between items, the empty cells of item parameters should be filled with NAs.
In the <span class="pkg">irtQ</span> package, the item difficulty (or threshold) parameters of category boundaries for GPCM are expressed as
the item location (or overall difficulty) parameter subtracted by the threshold parameter for unique score categories of the item.
Note that when an GPCM item has <em>K</em> unique score categories, <em>K-1</em> item difficulty parameters are necessary because
the item difficulty parameter for the first category boundary is always 0. For example, if an GPCM item has five score categories,
four item difficulty parameters should be specified. An example of a data frame with a single-format test is as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
  ITEM1  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 1PLM </td><td style="text-align: right;"> 1.000 </td><td style="text-align: right;">  1.461 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM2  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 2PLM </td><td style="text-align: right;"> 1.921 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM3  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 1.736 </td><td style="text-align: right;">  1.501 </td><td style="text-align: right;">  0.203 </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM4  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 0.835 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">  0.182 </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM5  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> DRM </td><td style="text-align: right;"> 0.926 </td><td style="text-align: right;">  0.394 </td><td style="text-align: right;">  0.099
</td>
</tr>

</table>

<p>And an example of a data frame for a mixed-format test is as follows:
</p>

<table>
<tr>
 <td style="text-align: left;">
  ITEM1  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 1PLM </td><td style="text-align: right;"> 1.000 </td><td style="text-align: right;">  1.461 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM2  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 2PLM </td><td style="text-align: right;"> 1.921 </td><td style="text-align: right;"> -1.049 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM3  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> 3PLM </td><td style="text-align: right;"> 0.926 </td><td style="text-align: right;">  0.394 </td><td style="text-align: right;">  0.099 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM4  </td><td style="text-align: right;"> 2 </td><td style="text-align: left;"> DRM </td><td style="text-align: right;"> 1.052 </td><td style="text-align: right;"> -0.407 </td><td style="text-align: right;">  0.201 </td><td style="text-align: right;">         NA </td><td style="text-align: right;">         NA</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM5  </td><td style="text-align: right;"> 4 </td><td style="text-align: left;"> GRM  </td><td style="text-align: right;"> 1.913 </td><td style="text-align: right;"> -1.869 </td><td style="text-align: right;"> -1.238 </td><td style="text-align: right;"> -0.714 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM6  </td><td style="text-align: right;"> 5 </td><td style="text-align: left;"> GRM  </td><td style="text-align: right;"> 1.278 </td><td style="text-align: right;"> -0.724 </td><td style="text-align: right;"> -0.068 </td><td style="text-align: right;">  0.568 </td><td style="text-align: right;">  1.072</td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM7  </td><td style="text-align: right;"> 4 </td><td style="text-align: left;"> GPCM  </td><td style="text-align: right;"> 1.137 </td><td style="text-align: right;"> -0.374 </td><td style="text-align: right;">  0.215 </td><td style="text-align: right;">  0.848 </td><td style="text-align: right;">         NA </td>
</tr>
<tr>
 <td style="text-align: left;">
  ITEM8  </td><td style="text-align: right;"> 5 </td><td style="text-align: left;"> GPCM  </td><td style="text-align: right;"> 1.233 </td><td style="text-align: right;"> -2.078 </td><td style="text-align: right;"> -1.347 </td><td style="text-align: right;"> -0.705 </td><td style="text-align: right;"> -0.116
</td>
</tr>

</table>

<p>See <code>IRT Models</code> section in the page of <code><a href="#topic+irtQ-package">irtQ-package</a></code> for more details about the IRT models used in the <span class="pkg">irtQ</span> package.
An easier way to create a data frame for the argument <code>x</code> is by using the function <code><a href="#topic+shape_df">shape_df</a></code>.
</p>
<p>The second way is by directly specifying item parameters for each item for which response data should be simulated
(i.e., without using a data frame, as shown in the examples that follow). In addition to item parameters,
<code>theta</code>, <code>cats</code>, <code>pr.model</code>, and  <code>D</code> should be specified as well. <code>g.drm</code> does not need to be specified when only
the 1PL and 2PL models are used for dichotomous item response data. For dichotomous items, 2s should be specified in <code>cats</code>.
For polytomous items, the number of unique score categories should be specified in <code>cats</code>. When a response data set is generated with
a mixed-format test, it is important to clearly specify <code>cats</code> according to the order of items in the test form. Suppose that the response
data of ten examinees are simulated with five items, including three dichotomous items and two polytomous items with three categories.
Also, suppose that the second and the forth items are the polytomous items. Then, <code>cats = c(2, 3, 2, 3, 2)</code> should be used.
Additionally, among those two polytomous items, if the first and second item response data are simulated from the graded response model
and generalized partial credit model, respectively, then <code>pr.model = c('GRM', 'GPCM')</code>.
</p>


<h3>Value</h3>

<p>This function returns a vector or a matrix. When a matrix is returned, rows indicate theta values and columns represent items.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+drm">drm</a></code>, <code><a href="#topic+prm">prm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1.
## simulates response data with a mixed-format test.
## for the first two polytomous items, the generalized partial credit model is used
## for the last polytomous item, the graded response model is used
# 100 examinees are sampled
theta &lt;- rnorm(100)

# set item parameters for three dichotomous items with the 3PL model
a.drm &lt;- c(1, 1.2, 1.3); b.drm &lt;- c(-1, 0, 1); g.drm &lt;- rep(0.2, 3)

# set item parameters for three polytomous item parameters
# note that 4, 4, and 5 categories are used for polytomous items
a.prm &lt;- c(1.3, 1.2, 1.7)
d.prm &lt;- list(c(-1.2, -0.3, 0.4), c(-0.2, 0.5, 1.6), c(-1.7, 0.2, 1.1, 2.0))

# create a numeric vector of score categories for both dichotomous and polytomous item data
# this score category vector is used to specify the location of the polytomous items
cats &lt;- c(2, 2, 4, 4, 5, 2)

# create a character vector of the IRT model for the polytomous items
pr.model &lt;- c('GPCM', 'GPCM', 'GRM')

# simulate the response data
simdat(theta=theta, a.drm=a.drm, b.drm=b.drm, g.drm=NULL,
       a.prm=a.prm, d.prm=d.prm, cats=cats, pr.model=pr.model, D=1)


## example 2.
## simulates response data with a single-format test with the 2PL model.
# create a numeric vector of score categories for the three 2PL model items
cats &lt;- rep(2, 3)

# simulate the response data
simdat(theta=theta, a.drm=a.drm, b.drm=b.drm, cats=cats, D=1)

## example 3.
## the use of a "-prm.txt" file obtained from a flexMIRT
# import the "-prm.txt" output file from flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameters and transform them to item metadata
test_flex &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df

# simulate the response data
simdat(x=test_flex, theta=theta, D=1) # use a data.frame of item meta information

</code></pre>

<hr>
<h2 id='simMG'>Simulated multiple-group data</h2><span id='topic+simMG'></span>

<h3>Description</h3>

<p>This data set has a list consisting of item metadata, item response data, and group names of three simulated groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simMG
</code></pre>


<h3>Format</h3>

<p>This data set includes a list of three internal objects: (1) a list of item metadata (item.prm) for three groups,
(2) a list of item response data (res.dat) for the three groups, and (3) a vector of group names (group.name) for
the three groups.
</p>
<p>The first internal object (item.prm) contains a list of item metadata of three test forms for the three
groups. In terms of test forms, the test forms for the first and second groups have fifty items consisting of forty seven 3PLM
items and three GRM items. The test form for the third group has thirty eight items consisting of thirty seven 3PLM items and
one GRM item. Among the three forms, the first and second test forms share twelve common items (C1I1 through C1I12) and
the second and third test forms share ten common items (C2I1 through c2I10). There is no common item between the first and third forms.
The item parameters in the item metadata were used to simulate the item response data sets for the three groups (see the second
object of the list).
</p>
<p>Regrading the second internal object, all three response data sets were simulated with 2,000 latent abilities randomly sampled
from <code class="reqn">N(0, 1)</code> (Group 1), <code class="reqn">N(0.5, 0.8^{2})</code> (Group 2), and <code class="reqn">N(-0.3, 1.3^{2})</code> (Group 3), respectively, using the
true item parameters provided in the item metadata.
</p>
<p>The third internal object is a vector of three group names which are &quot;Group1&quot;, &quot;Group2&quot;, and &quot;Group3&quot;.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>

<hr>
<h2 id='summary'>Summary of item calibration</h2><span id='topic+summary'></span><span id='topic+summary.est_irt'></span><span id='topic+summary.est_mg'></span><span id='topic+summary.est_item'></span>

<h3>Description</h3>

<p>This method function summarizes the IRT calibration results of <code><a href="#topic+est_irt">est_irt</a></code>
or <code><a href="#topic+est_item">est_item</a></code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary(object, ...)

## S3 method for class 'est_irt'
summary(object, ...)

## S3 method for class 'est_mg'
summary(object, ...)

## S3 method for class 'est_item'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>An object of class <code><a href="#topic+est_irt">est_irt</a></code> or <code><a href="#topic+est_item">est_item</a></code>.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The method function returns a list of internal objects extracted from
<code><a href="#topic+est_irt">est_irt</a></code> or <code><a href="#topic+est_item">est_item</a></code> object and displays a summary of
the IRT calibration results on the console panel.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>est_irt</code>: An object created by the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
</li>
<li> <p><code>est_mg</code>: An object created by the function <code><a href="#topic+est_mg">est_mg</a></code>.
</p>
</li>
<li> <p><code>est_item</code>: An object created by the function <code><a href="#topic+est_item">est_item</a></code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+est_item">est_item</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# fit the 1PL model to LSAT6 data and constrain the slope parameters to be equal
fit.1pl &lt;- est_irt(data=LSAT6, D=1, model="1PLM", cats=2, fix.a.1pl=FALSE)

# summary of the estimation
summary(fit.1pl)


</code></pre>

<hr>
<h2 id='sx2_fit'>S-X2 fit statistic</h2><span id='topic+sx2_fit'></span><span id='topic+sx2_fit.default'></span><span id='topic+sx2_fit.est_item'></span><span id='topic+sx2_fit.est_irt'></span>

<h3>Description</h3>

<p>This function computes <code class="reqn">S-X^{2}</code> (Orlando &amp; Thissen, 2000, 2003) item fit statistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sx2_fit(x, ...)

## Default S3 method:
sx2_fit(
  x,
  data,
  D = 1,
  alpha = 0.05,
  min.collapse = 1,
  norm.prior = c(0, 1),
  nquad = 30,
  weights,
  pcm.loc = NULL,
  ...
)

## S3 method for class 'est_item'
sx2_fit(
  x,
  alpha = 0.05,
  min.collapse = 1,
  norm.prior = c(0, 1),
  nquad = 30,
  weights,
  pcm.loc = NULL,
  ...
)

## S3 method for class 'est_irt'
sx2_fit(
  x,
  alpha = 0.05,
  min.collapse = 1,
  norm.prior = c(0, 1),
  nquad = 30,
  weights,
  pcm.loc = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sx2_fit_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...), an object
of class <code><a href="#topic+est_item">est_item</a></code> obtained from the function <code><a href="#topic+est_item">est_item</a></code>, or an object of class <code><a href="#topic+est_irt">est_irt</a></code>
obtained from the function <code><a href="#topic+est_irt">est_irt</a></code>. See <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>, or <code><a href="#topic+simdat">simdat</a></code>
for more details about the item metadata. The data frame of item metadata can be easily obtained using the function <code><a href="#topic+shape_df">shape_df</a></code>.</p>
</td></tr>
<tr><td><code id="sx2_fit_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="sx2_fit_+3A_data">data</code></td>
<td>
<p>A matrix containing examinees' response data for the items in the argument <code>x</code>. A row and column indicate
the examinees and items, respectively.</p>
</td></tr>
<tr><td><code id="sx2_fit_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
<tr><td><code id="sx2_fit_+3A_alpha">alpha</code></td>
<td>
<p>A numeric value to specify significance <code class="reqn">\alpha</code>-level of the hypothesis test for <code class="reqn">S-X^{2}</code> fit statistic. Default is .05.</p>
</td></tr>
<tr><td><code id="sx2_fit_+3A_min.collapse">min.collapse</code></td>
<td>
<p>An integer value to indicate the minimum frequency of cells to be collapsed. Default is 1. See below for details.</p>
</td></tr>
<tr><td><code id="sx2_fit_+3A_norm.prior">norm.prior</code></td>
<td>
<p>A numeric vector of two components specifying a mean and standard deviation of the normal prior distribution.
These two parameters are used to obtain the gaussian quadrature points and the corresponding weights from the normal distribution. Default is
c(0,1).</p>
</td></tr>
<tr><td><code id="sx2_fit_+3A_nquad">nquad</code></td>
<td>
<p>An integer value specifying the number of gaussian quadrature points from the normal prior distribution. Default is 30.</p>
</td></tr>
<tr><td><code id="sx2_fit_+3A_weights">weights</code></td>
<td>
<p>A two-column matrix or data frame containing the quadrature points (in the first column) and the corresponding weights
(in the second column) of the latent variable prior distribution. The weights and quadrature points can be easily obtained
using the function <code><a href="#topic+gen.weight">gen.weight</a></code>. If missing, default values are used (see the arguments of <code>norm.prior</code> and <code>nquad</code>).</p>
</td></tr>
<tr><td><code id="sx2_fit_+3A_pcm.loc">pcm.loc</code></td>
<td>
<p>A vector of integer values indicating the locations of partial credit model (PCM) items whose slope parameters are fixed
to certain values. Default is NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Often, very small expected frequencies in the contingency tables used to compute <code class="reqn">\chi^{2}</code> fit statistics could
compromise the accuracy of the <code class="reqn">\chi^{2}</code> approximation for their distribution (Orlando &amp; Thissen, 2000).
To avoid this problem, Orlando and Thissen (2000) used an algorithm of collapsing adjacent test score groups to maintain
a minimum expected category frequency of 1. However, if Orlando and Thissen's cell collapsing approach is applied to polytomous data,
too much information would be lost (Kang &amp; Chen, 2008). Thus, Kang and Chen (2008) collapsed adjacent cells of item score categories
for a specific score group to ensure a minimum expected category frequency of 1. The same collapsing strategies were applied
in the function <code><a href="#topic+sx2_fit">sx2_fit</a></code>. If a minimum expected category frequency needs to be set to different number, you can specify
the minimum value in the argument <code>min.collapse</code>.
</p>
<p>Note that if &quot;DRM&quot; is specified for an item in the item metadata set, the item is considered as &quot;3PLM&quot; to compute degree of freedom of
the <code class="reqn">S-X^{2}</code> fit statistic.
</p>
<p>Also, any missing responses in <code>data</code> are replaced with incorrect responses (i.e., 0s).
</p>


<h3>Value</h3>

<p>This function returns a list. Within a list, several internal objects are contained such as:
</p>
<table>
<tr><td><code>fit_stat</code></td>
<td>
<p>A data frame containing the results of <code class="reqn">S-X^{2}</code> fit statistics for all items.</p>
</td></tr>
<tr><td><code>item_df</code></td>
<td>
<p>The item metadata specified in the argument <code>x</code>.</p>
</td></tr>
<tr><td><code>exp_freq</code></td>
<td>
<p>A list containing the collapsed expected frequency tables for all items.</p>
</td></tr>
<tr><td><code>obs_freq</code></td>
<td>
<p>A list containing the collapsed observed frequency tables for all items.</p>
</td></tr>
<tr><td><code>exp_prob</code></td>
<td>
<p>A list containing the collapsed expected probability tables for all items.</p>
</td></tr>
<tr><td><code>obs_prop</code></td>
<td>
<p>A list containing the collapsed observed proportion tables for all items.</p>
</td></tr>
</table>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default method to compute <code class="reqn">S-X^{2}</code> fit statistics for a data frame <code>x</code> containing the item metadata.
</p>
</li>
<li> <p><code>est_item</code>: An object created by the function <code><a href="#topic+est_item">est_item</a></code>.
</p>
</li>
<li> <p><code>est_irt</code>: An object created by the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Kang, T., &amp; Chen, T. T. (2008). Performance of the generalized S-X2 item fit index for polytomous IRT models.
<em>Journal of Educational Measurement, 45</em>(4), 391-406.
</p>
<p>Orlando, M., &amp; Thissen, D. (2000). Likelihood-based item-fit indices for dichotomous item response theory models.
<em>Applied Psychological Measurement, 24</em>(1), 50-64.
</p>
<p>Orlando, M., &amp; Thissen, D. (2003). Further investigation of the performance of S-X2: An item fit index for use with
dichotomous item response theory models. <em>Applied Psychological Measurement, 27</em>(4), 289-298.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>, <code><a href="#topic+simdat">simdat</a></code>, <code><a href="#topic+shape_df">shape_df</a></code>, <code><a href="#topic+est_item">est_item</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## example 1: all five polytomous IRT models are GRM
## import the "-prm.txt" output file from flexMIRT
flex_sam &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# select the item metadata
x &lt;- bring.flexmirt(file=flex_sam, "par")$Group1$full_df

# generate examinees' abilities from N(0, 1)
set.seed(23)
score &lt;- rnorm(500, mean=0, sd=1)

# simulate the response data
data &lt;- simdat(x=x, theta=score, D=1)


# compute fit statistics
fit1 &lt;- sx2_fit(x=x, data=data, nquad=30)

# fit statistics
fit1$fit_stat


## example 2: first 39th and 40th items follows GRM and 53rd, 54th, and 55th items
##            follow PCM (thus, the slope parameters are fixed to 1)
# replace the model names with GPCM and
# assign 1 to the slope parameters for the 53rd, 54th, and 55th items
x[53:55, 3] &lt;- "GPCM"
x[53:55, 4] &lt;- 1

# generate examinees' abilities from N(0, 1)
set.seed(25)
score &lt;- rnorm(1000, mean=0, sd=1)

# simulate the response data
data &lt;- simdat(x=x, theta=score, D=1)


# compute fit statistics
fit2 &lt;- sx2_fit(x=x, data=data, nquad=30, pcm.loc=53:55)

# fit statistics
fit2$fit_stat


</code></pre>

<hr>
<h2 id='traceline'>Compute Item/Test Characteristic Functions</h2><span id='topic+traceline'></span><span id='topic+traceline.default'></span><span id='topic+traceline.est_item'></span><span id='topic+traceline.est_irt'></span>

<h3>Description</h3>

<p>This function computes the item category probabilities, item characteristic function, and
test characteristic function given a set of theta values. The returned object of this function can be used
to draw the item or test characteristic curve using the function <code><a href="#topic+plot.traceline">plot.traceline</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>traceline(x, ...)

## Default S3 method:
traceline(x, theta, D = 1, ...)

## S3 method for class 'est_item'
traceline(x, theta, ...)

## S3 method for class 'est_irt'
traceline(x, theta, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="traceline_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...), an object
of class <code><a href="#topic+est_item">est_item</a></code> obtained from the function <code><a href="#topic+est_item">est_item</a></code>, or an object of class <code><a href="#topic+est_irt">est_irt</a></code>
obtained from the function <code><a href="#topic+est_irt">est_irt</a></code>. See <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>, or <code><a href="#topic+simdat">simdat</a></code>
for more details about the item metadata. The data frame of item metadata can be easily obtained using the function <code><a href="#topic+shape_df">shape_df</a></code>.</p>
</td></tr>
<tr><td><code id="traceline_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="traceline_+3A_theta">theta</code></td>
<td>
<p>A vector of theta values.</p>
</td></tr>
<tr><td><code id="traceline_+3A_d">D</code></td>
<td>
<p>A scaling factor in IRT models to make the logistic function as close as possible to the normal ogive function (if set to 1.7).
Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function returns an object of class <code><a href="#topic+traceline">traceline</a></code>. This object contains a list containing
the item category probabilities, item characteristic function, and test characteristic function.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default method to compute the item category probabilities, item characteristic function, and
test characteristic function for a data frame <code>x</code> containing the item metadata.
</p>
</li>
<li> <p><code>est_item</code>: An object created by the function <code><a href="#topic+est_item">est_item</a></code>.
</p>
</li>
<li> <p><code>est_irt</code>: An object created by the function <code><a href="#topic+est_irt">est_irt</a></code>.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.traceline">plot.traceline</a></code>, <code><a href="#topic+est_item">est_item</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example
## using a "-prm.txt" file obtained from a flexMIRT
# import the "-prm.txt" output file from flexMIRT
flex_prm &lt;- system.file("extdata", "flexmirt_sample-prm.txt", package = "irtQ")

# read item parameters and transform them to item metadata
test_flex &lt;- bring.flexmirt(file=flex_prm, "par")$Group1$full_df

# set theta values
theta &lt;- seq(-3, 3, 0.5)

# compute the item category probabilities and item/test
# characteristic functions given the theta values
traceline(x=test_flex, theta, D=1)

</code></pre>

<hr>
<h2 id='write.flexmirt'>Write a &quot;-prm.txt&quot; file for flexMIRT</h2><span id='topic+write.flexmirt'></span>

<h3>Description</h3>

<p>This function writes an output file of &quot;-prm.txt&quot; for flexMIRT (Cai, 2017). The current version of this function
can be used only for the unidimensional IRT models. This function was written by modifying the function <code>read.flexmirt</code>
(Pritikin &amp; Falk, 2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write.flexmirt(
  x,
  file = NULL,
  norm.pop = c(0, 1),
  rePar = TRUE,
  mgroup = FALSE,
  group.name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write.flexmirt_+3A_x">x</code></td>
<td>
<p>A data frame containing the item metadata (e.g., item parameters, number of categories, models ...) for a single group or
a list of the item metadata for multiple groups. See <code><a href="#topic+est_irt">est_irt</a></code>, <code><a href="#topic+irtfit">irtfit</a></code>, <code><a href="#topic+info">info</a></code>,
or <code><a href="#topic+simdat">simdat</a></code> for more details about the item metadata. The item metadata can be easily created using the function
<code><a href="#topic+shape_df">shape_df</a></code>.</p>
</td></tr>
<tr><td><code id="write.flexmirt_+3A_file">file</code></td>
<td>
<p>The destination file name.</p>
</td></tr>
<tr><td><code id="write.flexmirt_+3A_norm.pop">norm.pop</code></td>
<td>
<p>A numeric vector of two components specifying a mean and standard deviation of the normal
population ability distribution for a single group or a list of the numeric vectors of length two for multiple groups.
When a list is provided, each internal numeric vector should contain a mean and standard deviation of the ability
distribution of each group (e.g., <code>norm.pop = list(c(0, 1), c(0, 0.8), c(0.5, 1.2)</code>) for three groups). When <code>mgroup = TRUE</code>
and a single vector of length two is provided (e.g., <code>norm.pop = c(0, 1)</code>), the same vector will be recycled across all groups.
Default is c(0,1).</p>
</td></tr>
<tr><td><code id="write.flexmirt_+3A_repar">rePar</code></td>
<td>
<p>A logical value indicating whether the item parameters in the item metadata
are the reparameterized item parameters. If TRUE, the item intercepts and logits of item guessing parameters
should be included in the item metadata. If FALSE, the item difficulty and item guessing parameters
should be included in the item metadata.</p>
</td></tr>
<tr><td><code id="write.flexmirt_+3A_mgroup">mgroup</code></td>
<td>
<p>A logical value indicating whether a &quot;-prm.txt&quot; file is created for a single group or multiple groups.
Default is FALSE.</p>
</td></tr>
<tr><td><code id="write.flexmirt_+3A_group.name">group.name</code></td>
<td>
<p>A character vector of group names. If NULL, the group names are automatically generated (e.g., Group1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;-prm.txt&quot; file.
</p>


<h3>Author(s)</h3>

<p>Hwanggyu Lim <a href="mailto:hglim83@gmail.com">hglim83@gmail.com</a>
</p>


<h3>References</h3>

<p>Cai, L. (2017). flexMIRT 3.5 Flexible multilevel multidimensional item analysis and test scoring [Computer software].
Chapel Hill, NC: Vector Psychometric Group.
</p>
<p>Pritikin, J. N., &amp; Falk, C. F. (2020). OpenMx: A modular research environment for item response theory
method development. <em>Applied Psychological Measurement, 44</em>(7-8), 561-562.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## 1. Create "-prm.txt" file for a single group
##    using the simulated CAT data
# 1-(1) extract the item metadata
x &lt;- simCAT_MX$item.prm

# 1-(2) set a name of "-prm.txt" file
temp_prm &lt;- file.path(tempdir(), "single_group_temp-prm.txt")

# 1-(3) write out the "-prm.txt" file
write.flexmirt(x, file=temp_prm, norm.pop=c(0, 1), rePar=FALSE)

## 2. Create "-prm.txt" file for multiple groups
##    using the simulated three multiple group data
# 2-(1) extract the item metadata
x &lt;- simMG$item.prm

# set a name of "-prm.txt" file
temp_prm &lt;- file.path(tempdir(), "mg_group_temp-prm1.txt")

# write out the "-prm.txt" file
write.flexmirt(x, file=temp_prm, norm.pop=list(c(0, 1), c(0.5, 0.8), c(-0.3, 1.3)),
               rePar=FALSE, mgroup=TRUE, group.name=c("GR1", "GR2", "GR3"))

# or write out the "-prm.txt" file so that
# all groups have the same ability distributions
# and the group names are generate autoumatically
temp_prm &lt;- file.path(tempdir(), "mg_group_temp-prm2.txt")
write.flexmirt(x, file=temp_prm, norm.pop=c(0, 1),
               rePar=FALSE, mgroup=TRUE, group.name=NULL)



</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
