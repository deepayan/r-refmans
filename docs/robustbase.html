<!DOCTYPE html><html><head><title>Help for package robustbase</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {robustbase}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#adjbox'><p>Plot an Adjusted Boxplot for Skew Distributions</p></a></li>
<li><a href='#adjboxStats'><p>Statistics for Skewness-adjusted Boxplots</p></a></li>
<li><a href='#adjOutlyingness'><p>Compute (Skewness-adjusted) Multivariate Outlyingness</p></a></li>
<li><a href='#aircraft'><p>Aircraft Data</p></a></li>
<li><a href='#airmay'><p>Air Quality Data</p></a></li>
<li><a href='#alcohol'><p>Alcohol Solubility in Water Data</p></a></li>
<li><a href='#ambientNOxCH'><p> Daily Means of NOx (mono-nitrogen oxides) in air</p></a></li>
<li><a href='#Animals2'><p>Brain and Body Weights for 65 Species of Land Animals</p></a></li>
<li><a href='#anova.glmrob'><p>Analysis of Robust Quasi-Deviance for &quot;glmrob&quot; Objects</p></a></li>
<li><a href='#anova.lmrob'><p>Analysis of Robust Deviances ('anova') for &quot;lmrob&quot; Objects</p></a></li>
<li><a href='#biomassTill'><p>Biomass Tillage Data</p></a></li>
<li><a href='#bushfire'><p> Campbell Bushfire Data</p></a></li>
<li><a href='#BYlogreg'><p>Bianco-Yohai Estimator for Robust Logistic Regression</p></a></li>
<li><a href='#carrots'><p>Insect Damages on Carrots</p></a></li>
<li><a href='#chgDefaults-methods'><p>Change Defaults (Parameters) of &quot;Psi Function&quot; Objects</p></a></li>
<li><a href='#classPC'><p>Compute Classical Principal Components via SVD or Eigen</p></a></li>
<li><a href='#cloud'><p>Cloud point of a Liquid</p></a></li>
<li><a href='#coleman'><p>Coleman Data Set</p></a></li>
<li><a href='#colMedians'><p>Fast Row or Column-wise Medians of a Matrix</p></a></li>
<li><a href='#condroz'><p> Condroz Data</p></a></li>
<li><a href='#covComed'><p>Co-Median Location and Scatter &quot;Covariance&quot; Estimator</p></a></li>
<li><a href='#covMcd'><p>Robust Location and Scatter Estimation via MCD</p></a></li>
<li><a href='#covOGK'><p>Orthogonalized Gnanadesikan-Kettenring (OGK) Covariance Matrix Estimation</p></a></li>
<li><a href='#CrohnD'><p>Crohn's Disease Adverse Events Data</p></a></li>
<li><a href='#cushny'><p>Cushny and Peebles Prolongation of Sleep Data</p></a></li>
<li><a href='#delivery'><p>Delivery Time Data</p></a></li>
<li><a href='#education'><p>Education Expenditure Data</p></a></li>
<li><a href='#epilepsy'><p>Epilepsy Attacks Data Set</p></a></li>
<li><a href='#estimethod'><p>Extract the Estimation Method 'Estimethod' from a Fitted Model</p></a></li>
<li><a href='#exAM'><p>Example Data of Antille and May - for Simple Regression</p></a></li>
<li><a href='#foodstamp'><p>Food Stamp Program Participation</p></a></li>
<li><a href='#fullRank'><p>Remove Columns (or Rows) From a Matrix to Make It Full Rank</p></a></li>
<li><a href='#functionX-class'><p>Class &quot;functionX&quot; of Psi-like Vectorized Functions</p></a></li>
<li><a href='#functionXal-class'><p>Class &quot;functionXal&quot; of Functionals (of Psi-like functions)</p></a></li>
<li><a href='#glmrob'><p>Robust Fitting of Generalized Linear Models</p></a></li>
<li><a href='#glmrob..control'><p>Controlling Robust GLM Fitting by Different Methods</p></a></li>
<li><a href='#h.alpha.n'><p>Compute h, the subsample size for MCD and LTS</p></a></li>
<li><a href='#hbk'><p>Hawkins, Bradu, Kass's Artificial Data</p></a></li>
<li><a href='#heart'><p>Heart Catherization Data</p></a></li>
<li><a href='#huberize'><p>Huberization &ndash; Bringing Outliers In</p></a></li>
<li><a href='#huberM'><p>Safe (generalized) Huber M-Estimator of Location</p></a></li>
<li><a href='#kootenay'><p>Waterflow Measurements of Kootenay River in Libby and Newgate</p></a></li>
<li><a href='#lactic'><p>Lactic Acid Concentration Measurement Data</p></a></li>
<li><a href='#lmc'><p>Left and Right Medcouple, Robust Measures of Tail Weight</p></a></li>
<li><a href='#lmrob'><p>MM-type Estimators for Linear Regression</p></a></li>
<li><a href='#lmrob..D..fit'><p>Compute Design Adaptive Scale estimate</p></a></li>
<li><a href='#lmrob..M..fit'><p>Compute M-estimators of regression</p></a></li>
<li><a href='#lmrob.control'><p>Tuning Parameters for lmrob() and Auxiliaries</p></a></li>
<li><a href='#lmrob.fit'><p> MM-type estimator for regression</p></a></li>
<li><a href='#lmrob.lar'><p>Least Absolute Residuals / L1 Regression</p></a></li>
<li><a href='#lmrob.M.S'><p> M-S regression estimators</p></a></li>
<li><a href='#lmrob.S'><p> S-regression estimators</p></a></li>
<li><a href='#los'><p> Length of Stay Data</p></a></li>
<li><a href='#ltsReg'><p>Least Trimmed Squares Robust (High Breakdown) Regression</p></a></li>
<li><a href='#mc'><p>Medcouple, a Robust Measure of Skewness</p></a></li>
<li><a href='#milk'><p>Daudin's Milk Composition Data</p></a></li>
<li><a href='#Mpsi'><p>Psi / Chi / Wgt / Rho Functions for *M-Estimation</p></a></li>
<li><a href='#nlrob'><p>Robust Fitting of Nonlinear Regression Models</p></a></li>
<li><a href='#nlrob-algorithms'><p>MM-, Tau-, CM-, and MTL- Estimators for Nonlinear Robust Regression</p></a></li>
<li><a href='#nlrob.control'><p>Control Nonlinear Robust Regression Algorithms</p></a></li>
<li><a href='#NOxEmissions'><p>NOx Air Pollution Data</p></a></li>
<li><a href='#outlierStats'><p>Robust Regression Outlier Statistics</p></a></li>
<li><a href='#pension'><p>Pension Funds Data</p></a></li>
<li><a href='#phosphor'><p>Phosphorus Content Data</p></a></li>
<li><a href='#pilot'><p>Pilot-Plant Data</p></a></li>
<li><a href='#plot-methods'><p>Plot an Object of the &quot;Psi Function&quot; Class</p></a></li>
<li><a href='#plot.lmrob'><p>Plot Method for &quot;lmrob&quot; Objects</p></a></li>
<li><a href='#plot.lts'><p>Robust LTS Regression Diagnostic Plots</p></a></li>
<li><a href='#plot.mcd'><p>Robust Distance Plots</p></a></li>
<li><a href='#possumDiv'><p>Possum Diversity Data</p></a></li>
<li><a href='#predict.glmrob'><p>Predict Method for Robust GLM (&quot;glmrob&quot;) Fits</p></a></li>
<li><a href='#predict.lmrob'><p>Predict method for Robust Linear Model (&quot;lmrob&quot;) Fits</p></a></li>
<li><a href='#print.lmrob'><p>Print Method for Objects of Class &quot;lmrob&quot;</p></a></li>
<li><a href='#psi_func-class'><p>Class of &quot;Psi Functions&quot; for M-Estimation</p></a></li>
<li><a href='#psi.findc'><p>Find Tuning Constant(s) for &quot;lqq&quot; and &quot;ggw&quot; Psi Functions</p></a></li>
<li><a href='#psiFunc'><p>Constructor for Objects &quot;Psi Function&quot; Class</p></a></li>
<li><a href='#pulpfiber'><p>Pulp Fiber and Paper Data</p></a></li>
<li><a href='#Qn'><p>Robust Location-Free Scale Estimate More Efficient than MAD</p></a></li>
<li><a href='#r6pack'><p>Robust Distance based observation orderings based on robust &quot;Six pack&quot;</p></a></li>
<li><a href='#radarImage'><p>Satellite Radar Image Data from near Munich</p></a></li>
<li><a href='#rankMM'><p>Simple Matrix Rank</p></a></li>
<li><a href='#residuals.glmrob'><p>Residuals of Robust Generalized Linear Model Fits</p></a></li>
<li><a href='#robustbase-internals'><p>Internal Functions of Package 'robustbase'</p></a></li>
<li><a href='#rrcov.control'><p>Control Settings for covMcd and ltsReg</p></a></li>
<li><a href='#salinity'><p>Salinity Data</p></a></li>
<li><a href='#scaleTau2'><p>Robust Tau-Estimate of Scale</p></a></li>
<li><a href='#SiegelsEx'><p>Siegel's Exact Fit Example Data</p></a></li>
<li><a href='#sigma'><p>Extract 'Sigma' - Standard Deviation of Errors for Robust Models</p></a></li>
<li><a href='#smoothWgt'><p>Smooth Weighting Function - Generalized Biweight</p></a></li>
<li><a href='#Sn'><p>Robust Location-Free Scale Estimate More Efficient than MAD</p></a></li>
<li><a href='#splitFrame'>
<p>Split Continuous and Categorical Predictors</p></a></li>
<li><a href='#starsCYG'><p>Hertzsprung-Russell Diagram Data of Star Cluster CYG OB1</p></a></li>
<li><a href='#steamUse'><p>Steam Usage Data (Excerpt)</p></a></li>
<li><a href='#summarizeRobWeights'><p>Print a Nice &quot;summary&quot; of Robustness Weights</p></a></li>
<li><a href='#summary.glmrob'><p>Summarizing Robust Fits of Generalized Linear Models</p></a></li>
<li><a href='#summary.lmrob'><p>Summary Method for &quot;lmrob&quot; Objects</p></a></li>
<li><a href='#summary.lts'><p>Summary Method for LTS objects</p></a></li>
<li><a href='#summary.mcd'><p>Summary Method for MCD objects</p></a></li>
<li><a href='#summary.nlrob'><p>Summarizing Robust Fits of Nonlinear Regression Models</p></a></li>
<li><a href='#telef'><p>Number of International Calls from Belgium</p></a></li>
<li><a href='#tolEllipsePlot'><p>Tolerance Ellipse Plot</p></a></li>
<li><a href='#toxicity'><p>Toxicity of Carboxylic Acids Data</p></a></li>
<li><a href='#tukeyPsi1'><p>Tukey's Bi-square Score (Psi) and &quot;Chi&quot; (Rho) Functions and Derivatives</p></a></li>
<li><a href='#vaso'><p>Vaso Constriction Skin Data Set</p></a></li>
<li><a href='#wagnerGrowth'>
<p>Wagner's Hannover Employment Growth Data</p></a></li>
<li><a href='#weights.lmrob'><p>Extract Robustness and Model Weights</p></a></li>
<li><a href='#wgt.himedian'><p>Weighted Hi-Median</p></a></li>
<li><a href='#wood'><p>Modified Data on Wood Specific Gravity</p></a></li>
<li><a href='#xtrData'><p>Extreme Data examples</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>0.99-2</td>
</tr>
<tr>
<td>VersionNote:</td>
<td>Released 0.99-1 on 2023-11-28 to CRAN</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-01-27</td>
</tr>
<tr>
<td>Title:</td>
<td>Basic Robust Statistics</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://robustbase.R-forge.R-project.org/">https://robustbase.R-forge.R-project.org/</a>,
<a href="https://R-forge.R-project.org/R/?group_id=59">https://R-forge.R-project.org/R/?group_id=59</a>,
<a href="https://R-forge.R-project.org/scm/viewvc.php/pkg/robustbase/?root=robustbase">https://R-forge.R-project.org/scm/viewvc.php/pkg/robustbase/?root=robustbase</a>,
svn://svn.r-forge.r-project.org/svnroot/robustbase/pkg/robustbase</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://R-forge.R-project.org/tracker/?atid=302&amp;group_id=59">https://R-forge.R-project.org/tracker/?atid=302&amp;group_id=59</a></td>
</tr>
<tr>
<td>Description:</td>
<td>"Essential" Robust Statistics.
 Tools allowing to analyze data with robust methods.  This includes
 regression methodology including model selections and multivariate
 statistics where we strive to cover the book "Robust Statistics,
 Theory and Methods" by 'Maronna, Martin and Yohai'; Wiley 2006.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, graphics, utils, methods, DEoptimR</td>
</tr>
<tr>
<td>Suggests:</td>
<td>grid, MASS, lattice, boot, cluster, Matrix, robust,
fit.models, MPV, xtable, ggplot2, GGally, RColorBrewer,
reshape2, sfsmisc, catdata, doParallel, foreach, skewt</td>
</tr>
<tr>
<td>SuggestsNote:</td>
<td>mostly only because of vignette graphics and simulation</td>
</tr>
<tr>
<td>Enhances:</td>
<td>robustX, rrcov, matrixStats, quantreg, Hmisc</td>
</tr>
<tr>
<td>EnhancesNote:</td>
<td>linked to in man/*.Rd</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-01-27 14:39:19 UTC; maechler</td>
</tr>
<tr>
<td>Author:</td>
<td>Martin Maechler <a href="https://orcid.org/0000-0002-8685-9910"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Peter Rousseeuw [ctb] (Qn and Sn),
  Christophe Croux [ctb] (Qn and Sn),
  Valentin Todorov [aut] (most robust Cov),
  Andreas Ruckstuhl [aut] (nlrob, anova, glmrob),
  Matias Salibian-Barrera [aut] (lmrob orig.),
  Tobias Verbeke [ctb, fnd] (mc, adjbox),
  Manuel Koller [aut] (mc, lmrob, psi-func.),
  Eduardo L. T. Conceicao [aut] (MM-, tau-, CM-, and MTL- nlrob),
  Maria Anna di Palma [ctb] (initial version of Comedian)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Martin Maechler &lt;maechler@stat.math.ethz.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-01-27 16:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='adjbox'>Plot an Adjusted Boxplot for Skew Distributions</h2><span id='topic+adjbox'></span><span id='topic+adjbox.default'></span><span id='topic+adjbox.formula'></span>

<h3>Description</h3>

<p>Produces boxplots adjusted for skewed distributions as proposed in
Hubert and Vandervieren (2008).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjbox(x, ...)

## S3 method for class 'formula'
adjbox(formula, data = NULL, ..., subset, na.action = NULL)

## Default S3 method:
adjbox(x, ..., range = 1.5, doReflect = FALSE,
        width = NULL, varwidth = FALSE,
        notch = FALSE, outline = TRUE, names, plot = TRUE,
        border = par("fg"), col = NULL, log = "",
        pars = list(boxwex = 0.8, staplewex = 0.5, outwex = 0.5),
        horizontal = FALSE, add = FALSE, at = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjbox_+3A_formula">formula</code></td>
<td>
<p>a formula, such as <code>y ~ grp</code>, where <code>y</code> is a
numeric vector of data values to be split into groups according to
the grouping variable <code>grp</code> (usually a factor).</p>
</td></tr>
<tr><td><code id="adjbox_+3A_data">data</code></td>
<td>
<p>a data.frame (or list) from which the variables in
<code>formula</code> should be taken.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used for plotting.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is to ignore missing
values in either the response or the group.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_x">x</code></td>
<td>
<p>for specifying data from which the boxplots are to be
produced. Either a numeric vector, or a single list containing such
vectors. Additional unnamed arguments specify further data
as separate vectors (each corresponding to a component boxplot).
<code><a href="base.html#topic+NA">NA</a></code>s are allowed in the data.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_...">...</code></td>
<td>
<p>For the <code>formula</code> method, named arguments to be passed to
the default method.
</p>
<p>For the default method, unnamed arguments are additional data
vectors (unless <code>x</code> is a list when they are ignored),
and named arguments are arguments and graphical parameters to be
passed to <code><a href="graphics.html#topic+bxp">bxp</a></code> in addition to the ones
given by argument <code>pars</code> (and override those in <code>pars</code>).
</p>
</td></tr>
<tr><td><code id="adjbox_+3A_range">range</code></td>
<td>
<p>this determines how far the plot whiskers extend out
from the box, and is simply passed as argument <code>coef</code> to
<code><a href="#topic+adjboxStats">adjboxStats</a>()</code>.  If <code>range</code> is positive, the
whiskers extend to the most extreme data point which is no more than
<code>range</code> times the interquartile range from the box.  A value
of zero causes the whiskers to extend to the data extremes.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_doreflect">doReflect</code></td>
<td>
<p>logical indicating if the MC should also be
computed on the <em>reflected</em> sample <code>-x</code>, and be averaged,
see <code><a href="#topic+mc">mc</a></code>.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_width">width</code></td>
<td>
<p>a vector giving the relative widths of the boxes making
up the plot.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_varwidth">varwidth</code></td>
<td>
<p>if <code>varwidth</code> is <code>TRUE</code>, the boxes are
drawn with widths proportional to the square-roots of the number
of observations in the groups.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_notch">notch</code></td>
<td>
<p>if <code>notch</code> is <code>TRUE</code>, a notch is drawn in
each side of the boxes.  If the notches of two plots do not
overlap this is &lsquo;strong evidence&rsquo; that the two medians differ
(Chambers <em>et al.</em>, 1983, p. 62).  See <code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>
for the calculations used.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_outline">outline</code></td>
<td>
<p>if <code>outline</code> is not true, the outliers are
not drawn (as points whereas S+ uses lines).</p>
</td></tr>
<tr><td><code id="adjbox_+3A_names">names</code></td>
<td>
<p>group labels which will be printed under each boxplot.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_boxwex">boxwex</code></td>
<td>
<p>a scale factor to be applied to all boxes.  When there
are only a few groups, the appearance of the plot can be improved
by making the boxes narrower.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_staplewex">staplewex</code></td>
<td>
<p>staple line width expansion, proportional to box
width.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_outwex">outwex</code></td>
<td>
<p>outlier line width expansion, proportional to box
width.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code> (the default) then a boxplot is
produced.  If not, the summaries which the boxplots are based on
are returned.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_border">border</code></td>
<td>
<p>an optional vector of colors for the outlines of the
boxplots.  The values in <code>border</code> are recycled if the
length of <code>border</code> is less than the number of plots.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_col">col</code></td>
<td>
<p>if <code>col</code> is non-null it is assumed to contain colors
to be used to colour the bodies of the box plots. By default they
are in the background colour.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_log">log</code></td>
<td>
<p>character indicating if x or y or both coordinates should
be plotted in log scale.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_pars">pars</code></td>
<td>
<p>a list of (potentially many) more graphical parameters,
e.g., <code>boxwex</code> or <code>outpch</code>; these are passed to
<code><a href="graphics.html#topic+bxp">bxp</a></code> (if <code>plot</code> is true); for details, see there.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_horizontal">horizontal</code></td>
<td>
<p>logical indicating if the boxplots should be
horizontal; default <code>FALSE</code> means vertical boxes.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_add">add</code></td>
<td>
<p>logical, if true <em>add</em> boxplot to current plot.</p>
</td></tr>
<tr><td><code id="adjbox_+3A_at">at</code></td>
<td>
<p>numeric vector giving the locations where the boxplots should
be drawn, particularly when <code>add = TRUE</code>;
defaults to <code>1:n</code> where <code>n</code> is the number of boxes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The generic function <code>adjbox</code> currently has a default method
(<code>adjbox.default</code>) and a formula interface (<code>adjbox.formula</code>).
</p>
<p>If multiple groups are supplied either as multiple arguments or via a
formula, parallel boxplots will be plotted, in the order of the
arguments or the order of the levels of the factor (see
<code><a href="base.html#topic+factor">factor</a></code>).
</p>
<p>Missing values are ignored when forming boxplots.
</p>
<p>Extremes of the upper and whiskers of the adjusted boxplots are
computed using the medcouple (<code><a href="#topic+mc">mc</a>()</code>), a robust measure of
skewness. For details, cf. TODO 
</p>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+list">list</a></code> with the following components:
</p>
<table>
<tr><td><code>stats</code></td>
<td>
<p>a matrix, each column contains the extreme of the lower
whisker, the lower hinge, the median, the upper hinge and the extreme of
the upper whisker for one group/plot.  If all the inputs have the same
class attribute, so will this component.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>a vector with the number of observations in each group.</p>
</td></tr>
<tr><td><code>coef</code></td>
<td>
<p>a matrix where each column contains the lower and upper
extremes of the notch.</p>
</td></tr>
<tr><td><code>out</code></td>
<td>
<p>the values of any data points which lie beyond the extremes
of the whiskers.</p>
</td></tr>
<tr><td><code>group</code></td>
<td>
<p>a vector of the same length as out whose elements
indicate to which group the outlier belongs.</p>
</td></tr>
<tr><td><code>names</code></td>
<td>
<p>a vector of names for the groups.</p>
</td></tr>
</table>


<h3>Note</h3>

<p> The code and documentation only slightly modifies the code of
<code><a href="graphics.html#topic+boxplot.default">boxplot.default</a></code>, <code>boxplot.formula</code> and
<code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>
</p>


<h3>Author(s)</h3>

<p> R Core Development Team, slightly adapted by Tobias Verbeke </p>


<h3>References</h3>





<p>Hubert, M. and Vandervieren, E. (2008).
An adjusted boxplot for skewed distributions,
<em>Computational Statistics and Data Analysis</em> <b>52</b>, 5186&ndash;5201.
<a href="https://doi.org/10.1016/j.csda.2007.11.008">doi:10.1016/j.csda.2007.11.008</a>
</p>


<h3>See Also</h3>

<p>The medcouple, <code><a href="#topic+mc">mc</a></code>; <code><a href="graphics.html#topic+boxplot">boxplot</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(require("boot")) {
 ### Hubert and Vandervieren (2008), Fig. 5.%(2006): p. 10, Fig. 4.
 data(coal, package = "boot")
 coaldiff &lt;- diff(coal$date)
 op &lt;- par(mfrow = c(1,2))
 boxplot(coaldiff, main = "Original Boxplot")
 adjbox(coaldiff, main  = "Adjusted Boxplot")
 par(op)
}

### Hubert and Vandervieren (2008), p. 11, Fig. 7a -- enhanced
op &lt;- par(mfrow = c(2,2), mar = c(1,3,3,1), oma = c(0,0,3,0))
with(condroz, {
 boxplot(Ca, main = "Original Boxplot")
 adjbox (Ca, main = "Adjusted Boxplot")
 boxplot(Ca, main = "Original Boxplot [log]", log = "y")
 adjbox (Ca, main = "Adjusted Boxplot [log]", log = "y")
})
mtext("'Ca' from data(condroz)",
      outer=TRUE, font = par("font.main"), cex = 2)
par(op)
</code></pre>

<hr>
<h2 id='adjboxStats'>Statistics for Skewness-adjusted Boxplots</h2><span id='topic+adjboxStats'></span>

<h3>Description</h3>

<p>Computes the &ldquo;statistics&rdquo; for producing boxplots adjusted for
skewed distributions as proposed in Hubert and Vandervieren (2008),
see <code><a href="#topic+adjbox">adjbox</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjboxStats(x, coef = 1.5, a = -4, b = 3, do.conf = TRUE, do.out = TRUE,
            ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjboxStats_+3A_x">x</code></td>
<td>
<p>a numeric vector for which adjusted boxplot statistics are computed.</p>
</td></tr>
<tr><td><code id="adjboxStats_+3A_coef">coef</code></td>
<td>
<p>number determining how far &lsquo;whiskers&rsquo; extend out
from the box, see <code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>.</p>
</td></tr>
<tr><td><code id="adjboxStats_+3A_a">a</code>, <code id="adjboxStats_+3A_b">b</code></td>
<td>
<p>scaling factors multiplied by the medcouple
<code><a href="#topic+mc">mc</a>()</code> to determine outlyer boundaries; see the references.</p>
</td></tr>
<tr><td><code id="adjboxStats_+3A_do.conf">do.conf</code>, <code id="adjboxStats_+3A_do.out">do.out</code></td>
<td>
<p>logicals; if <code>FALSE</code>, the <code>conf</code> or
<code>out</code> component respectively will be empty in the result.</p>
</td></tr>
<tr><td><code id="adjboxStats_+3A_...">...</code></td>
<td>
<p>further optional arguments to be passed to
<code><a href="#topic+mc">mc</a>()</code>, such as <code>doReflect</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given the quartiles <code class="reqn">Q_1</code>, <code class="reqn">Q_3</code>, the interquartile
range <code class="reqn">\Delta Q := Q_3 - Q_1</code>, and the medcouple
<code class="reqn">M :=</code><code>mc(x)</code>, <code class="reqn">c =</code><code>coef</code>,
the &ldquo;fence&rdquo; is defined,
for <code class="reqn">M \ge 0</code> as
</p>
<p style="text-align: center;"><code class="reqn">[Q_1 - c e^{a \cdot M}\Delta Q, Q_3 + c e^{b \cdot M}\Delta Q],%
  </code>
</p>

<p>and for <code class="reqn">M &lt; 0</code> as
</p>
<p style="text-align: center;"><code class="reqn">[Q_1 - c e^{-b \cdot M}\Delta Q, Q_3 + c e^{-a \cdot M}\Delta Q],%
  </code>
</p>

<p>and all observations <code>x</code> outside the fence, the &ldquo;potential
outliers&rdquo;, are returned in <code>out</code>.
</p>
<p>Note that a typo in robustbase version up to 0.7-8,
for the (rare left-skewed) case where <a href="#topic+mc">mc</a>(x) &lt; 0, lead to a
&ldquo;fence&rdquo; not wide enough in the upper part, and hence
<em>less</em> outliers there.
</p>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+list">list</a></code> with the components
</p>
<table>
<tr><td><code>stats</code></td>
<td>
<p>a vector of length 5, containing the extreme of the lower
whisker, the lower hinge, the median, the upper hinge and the extreme of
the upper whisker.</p>
</td></tr>
<tr><td><code>n</code></td>
<td>
<p>the number of observations</p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>the lower and upper extremes of the &lsquo;notch&rsquo;
(<code>if(do.conf)</code>). See <code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>.</p>
</td></tr>
<tr><td><code>fence</code></td>
<td>
<p>length 2 vector of interval boundaries which
define the non-outliers, and hence the whiskers of the plot.</p>
</td></tr>
<tr><td><code>out</code></td>
<td>
<p>the values of any data points which lie beyond the fence,
and hence beyond the extremes of the whiskers.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The code only slightly modifies the code of <span class="rlang"><b>R</b></span>'s
<code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>.
</p>


<h3>Author(s)</h3>

<p>R Core Development Team (<code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>); adapted
by Tobias Verbeke and Martin Maechler.</p>


<h3>See Also</h3>

<p><code><a href="#topic+adjbox">adjbox</a>()</code>, also for references,
the function which mainly uses this one;
further <code><a href="grDevices.html#topic+boxplot.stats">boxplot.stats</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(condroz)
adjboxStats(ccA &lt;- condroz[,"Ca"])
adjboxStats(ccA, doReflect = TRUE)# small difference in fence

## Test reflection invariance [was not ok, up to and including robustbase_0.7-8]
a1 &lt;- adjboxStats( ccA, doReflect = TRUE)
a2 &lt;- adjboxStats(-ccA, doReflect = TRUE)

nm1 &lt;- c("stats", "conf", "fence")
stopifnot(all.equal(       a1[nm1],
                    lapply(a2[nm1], function(u) rev(-u))),
          all.equal(a1[["out"]], -a2[["out"]]))
</code></pre>

<hr>
<h2 id='adjOutlyingness'>Compute (Skewness-adjusted) Multivariate Outlyingness</h2><span id='topic+adjOutlyingness'></span>

<h3>Description</h3>

<p>For an <code class="reqn">n \times p</code> data matrix (or data frame) <code>x</code>,
compute the &ldquo;<em>outlyingness</em>&rdquo; of all <code class="reqn">n</code> observations.
Outlyingness here is a generalization of the Donoho-Stahel
outlyingness measure, where skewness is taken into account via the
medcouple, <code><a href="#topic+mc">mc</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adjOutlyingness(x, ndir = 250, p.samp = p, clower = 4, cupper = 3,
                IQRtype = 7,
                alpha.cutoff = 0.75, coef = 1.5,
                qr.tol = 1e-12, keep.tol = 1e-12,
                only.outlyingness = FALSE, maxit.mult = max(100, p),
                trace.lev = 0,
                mcReflect = n &lt;= 100, mcScale = TRUE, mcMaxit = 2*maxit.mult,
                mcEps1 = 1e-12, mcEps2 = 1e-15,
                mcTrace = max(0, trace.lev-1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="adjOutlyingness_+3A_x">x</code></td>
<td>
<p>a numeric <code class="reqn">n \times p</code> <code><a href="base.html#topic+matrix">matrix</a></code> or
<code><a href="base.html#topic+data.frame">data.frame</a></code>,
which must be of full rank <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_ndir">ndir</code></td>
<td>
<p>positive integer specifying the number of directions that
should be searched.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_p.samp">p.samp</code></td>
<td>
<p>the sample size to use for finding good random
directions, must be at least <code>p</code>.  The default, <code>p</code> had
been hard coded previously.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_clower">clower</code>, <code id="adjOutlyingness_+3A_cupper">cupper</code></td>
<td>
<p>the constant to be used for the lower and upper
tails, in order to transform the data towards symmetry.  You can set
<code>clower = 0, cupper = 0</code> to get the <em>non</em>-adjusted,
i.e., classical (&ldquo;central&rdquo; or &ldquo;symmetric&rdquo;)
outlyingness.  In that case, <code><a href="#topic+mc">mc</a>()</code> is not used.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_iqrtype">IQRtype</code></td>
<td>
<p>a number from <code>1:9</code>, denoting type of empirical
quantile computation for the <code><a href="stats.html#topic+IQR">IQR</a>()</code>.  The default 7
corresponds to <code><a href="stats.html#topic+quantile">quantile</a></code>'s and <code><a href="stats.html#topic+IQR">IQR</a></code>'s
default.  MM has evidence that <code>type=6</code> would be a bit more stable
for small sample size.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_alpha.cutoff">alpha.cutoff</code></td>
<td>
<p>number in (0,1) specifying the quantiles
<code class="reqn">(\alpha, 1-\alpha)</code> which determine the &ldquo;outlier&rdquo;
cutoff.  The default, using quartiles, corresponds to the definition
of the medcouple (<code><a href="#topic+mc">mc</a></code>), but there is no stringent
reason for using the same alpha for the outlier cutoff.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_coef">coef</code></td>
<td>
<p>positive number specifying the factor with which the
interquartile range (<code><a href="stats.html#topic+IQR">IQR</a></code>) is multiplied to determine
&lsquo;boxplot hinges&rsquo;-like upper and lower bounds.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_qr.tol">qr.tol</code></td>
<td>
<p>positive tolerance to be used for <code><a href="Matrix.html#topic+qr">qr</a></code> and
<code><a href="base.html#topic+solve.qr">solve.qr</a></code> for determining the <code>ndir</code> directions,
each determined by a random sample of <code class="reqn">p</code> (out of <code class="reqn">n</code>)
observations.  Note that the default <code class="reqn">10^{-12}</code> is rather small,
and <code><a href="Matrix.html#topic+qr">qr</a></code>'s default <code>= 1e-7</code> may be more appropriate.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_keep.tol">keep.tol</code></td>
<td>
<p>positive tolerance to determine which of the sample
direction should be kept, namely only those for which
<code class="reqn">\|x\| \cdot \|B\|</code> is larger than <code>keep.tol</code>.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_only.outlyingness">only.outlyingness</code></td>
<td>
<p>logical indicating if the final outlier
determination should be skipped.  In that case, a vector is
returned, see &lsquo;Value:&rsquo; below.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_maxit.mult">maxit.mult</code></td>
<td>
<p>integer factor; <code>maxit &lt;- maxit.mult * ndir</code>
will determine the maximal number of direction searching
iterations.  May need to be increased for higher dimensional data,
though increasing <code>ndir</code> may be more important.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_trace.lev">trace.lev</code></td>
<td>
<p>an integer, if positive allows to monitor the
direction search.</p>
</td></tr>

<tr><td><code id="adjOutlyingness_+3A_mcreflect">mcReflect</code></td>
<td>
<p>passed as <code>doReflect</code> to <code><a href="#topic+mc">mc</a>()</code>.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_mcscale">mcScale</code></td>
<td>
<p>passed as <code>doScale</code> to <code><a href="#topic+mc">mc</a>()</code>.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_mcmaxit">mcMaxit</code></td>
<td>
<p>passed as <code>maxit</code> to <code><a href="#topic+mc">mc</a>()</code>.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_mceps1">mcEps1</code></td>
<td>
<p>passed as <code>eps1</code> to <code><a href="#topic+mc">mc</a>()</code>; the default is slightly
looser (100 larger) than the default for <code>mc</code>().</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_mceps2">mcEps2</code></td>
<td>
<p>passed as <code>eps2</code> to <code><a href="#topic+mc">mc</a>()</code>.</p>
</td></tr>
<tr><td><code id="adjOutlyingness_+3A_mctrace">mcTrace</code></td>
<td>
<p>passed as <code>trace.lev</code> to <code><a href="#topic+mc">mc</a>()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>FIXME</b>:  Details in the comment of the Matlab code;
also in the reference(s).



</p>
<p>The method as described can be useful as preprocessing in
FASTICA (<a href="http://research.ics.aalto.fi/ica/fastica/">http://research.ics.aalto.fi/ica/fastica/</a>
see also the <span class="rlang"><b>R</b></span> package <a href="https://CRAN.R-project.org/package=fastICA"><span class="pkg">fastICA</span></a>.
</p>


<h3>Value</h3>

<p>If <code>only.outlyingness</code> is true, a vector <code>adjout</code>,
otherwise, as by default, a list with components
</p>
<table>
<tr><td><code>adjout</code></td>
<td>
<p>numeric of <code>length(n)</code> giving the adjusted
outlyingness of each observation.</p>
</td></tr>
<tr><td><code>cutoff</code></td>
<td>
<p>cutoff for &ldquo;outlier&rdquo; with respect to the adjusted
outlyingnesses, and depending on <code>alpha.cutoff</code>.</p>
</td></tr>
<tr><td><code>nonOut</code></td>
<td>
<p>logical of <code>length(n)</code>, <code>TRUE</code> when the
corresponding observation is <b>non</b>-outlying with respect to the
cutoff and the adjusted outlyingnesses.</p>
</td></tr>
</table>


<h3>Note</h3>


<p>If there are too many degrees of freedom for the projections, i.e., when
<code class="reqn">n \le 4p</code>, the current definition of adjusted outlyingness
is ill-posed, as one of the projections may lead to a denominator
(quartile difference) of zero, and hence formally an adjusted
outlyingness of infinity.
The current implementation avoids <code>Inf</code> results, but will return
seemingly random <code>adjout</code> values of around <code class="reqn">10^{14} -- 10^{15}</code> which may
be completely misleading, see, e.g., the <code>longley</code> data example.
</p>
<p>The result is <em>random</em> as it depends on the sample of
<code>ndir</code> directions chosen; specifically, to get sub samples the algorithm uses
<code><a href="base.html#topic+sample.int">sample.int</a>(n, p.samp)</code>
which from <span class="rlang"><b>R</b></span> version 3.6.0 depends on
<code><a href="base.html#topic+RNGkind">RNGkind</a>(*, sample.kind)</code>.  Exact reproducibility of results
from <span class="rlang"><b>R</b></span> versions 3.5.3 and earlier, requires setting
<code><a href="base.html#topic+RNGversion">RNGversion</a>("3.5.0")</code>.
In any case, do use <code><a href="base.html#topic+set.seed">set.seed</a>()</code> yourself
for reproducibility!
</p>
<p>Till Aug/Oct. 2014, the default values for <code>clower</code> and <code>cupper</code> were
accidentally reversed, and the signs inside <code>exp(.)</code> where swapped
in the (now corrected) two expressions </p>
<pre>
 tup &lt;- Q3 + coef * IQR * exp(.... + clower * tmc * (tmc &lt; 0))
 tlo &lt;- Q1 - coef * IQR * exp(.... - cupper * tmc * (tmc &lt; 0))
</pre>
<p>already in the code from Antwerpen (&lsquo;<span class="file">mcrsoft/adjoutlingness.R</span>&rsquo;),
contrary to the published reference.
</p>
<p>Further, the original algorithm had not been scale-equivariant in the
direction construction, which has been amended in 2014-10 as well.
</p>
<p>The results, including diagnosed outliers, therefore have changed,
typically slightly, since <span class="pkg">robustbase</span> version 0.92-0.
</p>


<h3>Author(s)</h3>

<p>Guy Brys; help page and improvements by Martin Maechler</p>


<h3>References</h3>

<p>Brys, G., Hubert, M., and Rousseeuw, P.J. (2005)
A Robustification of Independent Component Analysis;
<em>Journal of Chemometrics</em>, <b>19</b>, 1&ndash;12.
</p>
<p>Hubert, M., Van der Veeken, S. (2008)
Outlier detection for skewed data;
<em>Journal of Chemometrics</em> <b>22</b>, 235&ndash;246;
<a href="https://doi.org/10.1002/cem.1123">doi:10.1002/cem.1123</a>.





</p>
<p>For the up-to-date reference, please consult

<a href="https://wis.kuleuven.be/statdatascience/robust">https://wis.kuleuven.be/statdatascience/robust</a>
</p>


<h3>See Also</h3>

<p>the adjusted boxplot, <code><a href="#topic+adjbox">adjbox</a></code> and the medcouple,
<code><a href="#topic+mc">mc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## An Example with bad condition number and "border case" outliers

dim(longley) # 16 x 7  // set seed, as result is random :
set.seed(31)
ao1 &lt;- adjOutlyingness(longley, mcScale=FALSE)
## which are outlying ?
which(!ao1$nonOut) ## for this seed, two: "1956", "1957"; (often: none)
## For seeds 1:100, we observe (Linux 64b)
if(FALSE) {
  adjO &lt;- sapply(1:100, function(iSeed) {
            set.seed(iSeed); adjOutlyingness(longley)$nonOut })
  table(nrow(longley) - colSums(adjO))
}
## #{outl.}:  0  1  2  3
## #{cases}: 74 17  6  3


## An Example with outliers :

dim(hbk)
set.seed(1)
ao.hbk &lt;- adjOutlyingness(hbk)
str(ao.hbk)
hist(ao.hbk $adjout)## really two groups
table(ao.hbk$nonOut)## 14 outliers, 61 non-outliers:
## outliers are :
which(! ao.hbk$nonOut) # 1 .. 14   --- but not for all random seeds!

## here, they are(*) the same as found by (much faster) MCD:
## *) only "almost", since the 2023-05 change to covMcd() 
cc &lt;- covMcd(hbk)
table(cc = cc$mcd.wt, ao = ao.hbk$nonOut)# one differ..:
stopifnot(sum(cc$mcd.wt != ao.hbk$nonOut) &lt;= 1)

## This is revealing: About 1--2 cases, where outliers are *not* == 1:14
## (2023: ~ 1/8 [sec] per call)
if(interactive()) {
  for(i in 1:30) {
    print(system.time(ao.hbk &lt;- adjOutlyingness(hbk)))
    if(!identical(iout &lt;- which(!ao.hbk$nonOut), 1:14)) {
	 cat("Outliers:\n"); print(iout)
    }
  }
}

## "Central" outlyingness: *not* calling mc()  anymore, since 2014-12-11:
trace(mc)
out &lt;- capture.output(
  oo &lt;- adjOutlyingness(hbk, clower=0, cupper=0)
)
untrace(mc)
stopifnot(length(out) == 0)

## A rank-deficient case
T &lt;- tcrossprod(data.matrix(toxicity))
try(adjOutlyingness(T, maxit. = 20, trace.lev = 2)) # fails and recommends:
T. &lt;- fullRank(T)
aT &lt;- adjOutlyingness(T.)
plot(sort(aT$adjout, decreasing=TRUE), log="y")
plot(T.[,9:10], col = (1:2)[1 + (aT$adjout &gt; 10000)])
## .. (not conclusive; directions are random, more 'ndir' makes a difference!)
</code></pre>

<hr>
<h2 id='aircraft'>Aircraft Data</h2><span id='topic+aircraft'></span>

<h3>Description</h3>

<p>Aircraft Data, deals with 23 single-engine aircraft built
over the years 1947-1979, from Office of Naval Research.
The dependent variable is cost  (in units of $100,000)
and the explanatory variables are aspect ratio, lift-to-drag ratio,
weight of plane (in pounds) and maximal thrust.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(aircraft, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 23 observations on the following 5 variables.
</p>

<dl>
<dt><code>X1</code></dt><dd><p>Aspect Ratio</p>
</dd>
<dt><code>X2</code></dt><dd><p>Lift-to-Drag Ratio</p>
</dd>
<dt><code>X3</code></dt><dd><p>Weight</p>
</dd>
<dt><code>X4</code></dt><dd><p>Thrust</p>
</dd>
<dt><code>Y</code></dt><dd><p>Cost</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, page 154, table 22.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(aircraft)
summary( lm.airc &lt;-        lm(Y ~ ., data = aircraft))
summary(rlm.airc &lt;- MASS::rlm(Y ~ ., data = aircraft))

aircraft.x &lt;- data.matrix(aircraft[,1:4])
c_air &lt;- covMcd(aircraft.x)
c_air
</code></pre>

<hr>
<h2 id='airmay'>Air Quality Data</h2><span id='topic+airmay'></span>

<h3>Description</h3>

<p>Air Quality Data Set for May 1973, from Chambers et al. (1983).
The whole data set consists of daily readings of air quality
values from May 1, 1973 to September 30, 1973,
but here are included only the values for May. This data set
is an example of the special treatment of the missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(airmay, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 31 observations on the following 4 variables.
</p>

<dl>
<dt><code>X1</code></dt><dd><p>Solar Radiation in Longleys in the frequency
band 4000-7700 from 0800 to 1200 hours at Central Park</p>
</dd>
<dt><code>X2</code></dt><dd><p>Average windspeed (in miles per hour) between 7000
and 1000 hours at La Guardia Airport</p>
</dd>
<dt><code>X3</code></dt><dd><p>Maximum daily temperature (in degrees Fahrenheit)
at La Guardia Airport</p>
</dd>
<dt><code>Y</code></dt><dd><p>Mean ozone concentration (in parts per billion)
from 1300 to 1500 hours at Roosevelt Island</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, p.86, table 6.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(airmay)
summary(lm.airmay &lt;- lm(Y ~ ., data=airmay))


airmay.x &lt;- data.matrix(airmay[,1:3])

</code></pre>

<hr>
<h2 id='alcohol'>Alcohol Solubility in Water Data</h2><span id='topic+alcohol'></span>

<h3>Description</h3>

<p>The solubility of alcohols in water is important in understanding
alcohol transport in living organisms.  This dataset from (Romanelli
et al., 2001) contains physicochemical characteristics of 44 aliphatic
alcohols.  The aim of the experiment was the prediction of the
solubility on the basis of molecular descriptors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(alcohol, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 44 observations on the following 7 numeric variables.
</p>

<dl>
<dt><code>SAG</code></dt><dd><p>solvent accessible surface-bounded molecular volume.</p>
</dd>
<dt><code>V</code></dt><dd><p>volume</p>
</dd>
<dt><code>logPC</code></dt><dd><p>Log(PC); PC = octanol-water partitions coefficient</p>
</dd>
<dt><code>P</code></dt><dd><p>polarizability</p>
</dd>
<dt><code>RM</code></dt><dd><p>molar refractivity</p>
</dd>
<dt><code>Mass</code></dt><dd><p>the mass</p>
</dd>
<dt><code>logSolubility</code></dt><dd><p>ln(Solubility), the response.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The website accompanying the MMY-book:
<a href="https://www.wiley.com/legacy/wileychi/robust_statistics/">https://www.wiley.com/legacy/wileychi/robust_statistics/</a>
</p>


<h3>References</h3>





<p>Maronna, R.A., Martin, R.D. and Yohai, V.J. (2006)
<em>Robust Statistics, Theory and Methods</em>, Wiley.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(alcohol)
## version of data set with trivial names, as
s.alcohol &lt;- alcohol
names(s.alcohol) &lt;- paste("Col", 1:7, sep='')
</code></pre>

<hr>
<h2 id='ambientNOxCH'> Daily Means of NOx (mono-nitrogen oxides) in air</h2><span id='topic+ambientNOxCH'></span>

<h3>Description</h3>

<p>This dataset contains daily means (from midnight to midnight) of NOx,
i.e., mono-nitrogen oxides, in [ppb] at 13 sites in central
Switzerland and Aarau for the year 2004.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ambientNOxCH, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 366 observations on the following 14 variables.
</p>

<dl>
<dt><code>date</code></dt><dd><p>date of day, of class <code>"Date"</code>.</p>
</dd>
<dt><code>ad</code></dt><dd><p>Site is located north of Altdorf 100 meters east of
motorway A2, on an open field at the beginning of a more than
2000m deep valley (690.175, 193.55; 438; inLuft)</p>
</dd>
<dt><code>ba</code></dt><dd><p>Site is located in the centre of the little town of
Baden in a residential area.  Baden has 34'000
inhabitants and is situated on the swiss plateau (666.075,
257.972; 377; inLuft).</p>
</dd>
<dt><code>ef</code></dt><dd><p>Site is located 6 km south of altdorf and 800 m
north of the village of Erstfeld. The motorway A2 passes 5 m west
of the measuring site. Over 8 million vehicles have passed
Erstfeld in 2004 where 13% of the counts were
attributed to trucks (691.43, 187.69; 457; MFM-U).</p>
</dd>
<dt><code>la</code></dt><dd><p>Site is located on a wooded hill in a rural area
called Laegern, about 190 m above Baden, which is about 5 km away
(669.8, 259; 690; NABEL).</p>
</dd>
<dt><code>lu</code></dt><dd><p>Site is located in the center of town of Lucerne,
which has 57'000 inhabitants (666.19, 211.975; 460; inLuft).</p>
</dd>
<dt><code>re</code></dt><dd><p>Site is located 1 km west of Reiden on the Swiss
plateau. The motorway A2 passes 5 m west of the measuring site
(639.56, 232.11; 462; MFM-U).</p>
</dd>
<dt><code>ri</code></dt><dd><p>Site is located at Rigi Seebodenalp, 649 m above
the lake of Lucerne on an alp with half a dozen small houses
(677.9, 213.5; 1030; NABEL).</p>
</dd>
<dt><code>se</code></dt><dd><p>Site is located in Sedel next to town of Lucerne
35m above and 250m south of motorway A14 from Zug to Lucerne on a
low hill with free 360Â° panorama (665.5, 213.41; 484; inLuft).</p>
</dd>
<dt><code>si</code></dt><dd><p>Site is located at the border of a small industrial
area in Sisseln, 300 m east of a main road (640.725, 266.25; 305;
inLuft).</p>
</dd>
<dt><code>st</code></dt><dd><p>Site is located at the south east border of Stans
with 7'000 inhabitants (670.85, 201.025; 438; inLuft).</p>
</dd>
<dt><code>su</code></dt><dd><p>Site is located in the center of Suhr (8700
inhabitants), 10 m from the main road (648.49, 246.985; 403; inLuft).</p>
</dd>
<dt><code>sz</code></dt><dd><p>Site is located in Schwyz (14'200 inhabitants) near
a shopping center (691.92, 208.03; 470; inLuft).</p>
</dd>
<dt><code>zg</code></dt><dd><p>Site is located in the centre of Zug with 22'000
inhabitants, 24 m from the main road (681.625, 224.625; 420;
inLuft).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The 13 sites are part of one of the three air quality monitoring networks:
inLuft (regional authorities of central Switzerland and canton Aargau)
<br />
NABEL (Swiss federal network)
<br />
MFM-U (Monitoring flankierende Massnahmen Umwelt), special Swiss
federal network along transit motorways A2 and A13 from Germany to
Italy through Switzerland
<br />
The information within the brackets means: Swiss
coordinates km east, km north; m above sea level; network
</p>
<p>When the measuring sites are exposed to the same atmospheric condition
and when there is no singular emission event at any site,
<code>log(mean(NOx) of a specific day at each site)</code> is a linear
function of <code>log(yearly.mean(NOx) at the corresponding site)</code>. The
offset and the slope of the straight
line reflects the atmospheric conditions at this specific day. During
winter time, often an inversion prevents the emissions from being
diluted vertically, so that there evolve two separate atmospheric
compartements: One below the inversion boundary with polluted air and one
above with relatively clean air. In our example below, Rigi Seebodenalp
is above the inversion boundary between December 10th and 12th.
</p>


<h3>Source</h3>

<p>http://www.in-luft.ch/ <br />
http://www.empa.ch/plugin/template/empa/*/6794 <br />
http://www.bafu.admin.ch/umweltbeobachtung/02272/02280
</p>


<h3>See Also</h3>

<p>another NOx dataset, <code><a href="#topic+NOxEmissions">NOxEmissions</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ambientNOxCH)
str (ambientNOxCH)

yearly &lt;- log(colMeans(ambientNOxCH[,-1], na.rm=TRUE))
xlim &lt;- range(yearly)
lNOx &lt;- log(ambientNOxCH[, -1])
days &lt;-     ambientNOxCH[, "date"]

## Subset of 9 days starting at April 4:
idays &lt;- seq(which(ambientNOxCH$date=="2004-12-04"), length=9)
ylim &lt;- range(lNOx[idays,],na.rm=TRUE)
op &lt;- par(mfrow=c(3,3),mar=rep(1,4), oma = c(0,0,2,0))

for (id in idays) {
  daily &lt;- unlist(lNOx[id,])
  plot(NA, xlim=xlim,ylim=ylim, ann=FALSE, type = "n")
  abline(0:1, col="light gray")
  abline(lmrob(daily~yearly, na.action=na.exclude),
         col="red", lwd=2)
  text(yearly, daily, names(yearly), col="blue")
  mtext(days[id], side=1, line=-1.2, cex=.75, adj=.98)
}
mtext("Daily ~ Yearly  log( NOx mean values ) at 13 Swiss locations",
      outer=TRUE)
par(op)

## do all 366 regressions:  Least Squares and Robust:
LS &lt;- lapply(1:nrow(ambientNOxCH), function(id)
             lm(unlist(lNOx[id,]) ~ yearly,
                na.action = na.exclude))
R &lt;- lapply(1:nrow(ambientNOxCH),
            function(id) lmrob(unlist(lNOx[id,]) ~ yearly,
                               na.action = na.exclude))
## currently 4 warnings about non-convergence;
## which ones?
days[notOk &lt;- ! sapply(R, `[[`, "converged") ]
## "2004-01-10" "2004-05-12" "2004-05-16" "2004-11-16"

## first problematic case:
daily &lt;- unlist(lNOx[which(notOk)[1],])
plot(daily ~ yearly,
     main = paste("lmrob() non-convergent:",days[notOk[1]]))
rr &lt;- lmrob(daily ~ yearly, na.action = na.exclude,
            control = lmrob.control(trace=3, max.it = 100))
##-&gt; 53 iter.

## Look at all coefficients:
R.cf &lt;- t(sapply(R, coef))
C.cf &lt;- t(sapply(LS, coef))
plot(C.cf, xlim=range(C.cf[,1],R.cf[,1]),
           ylim=range(C.cf[,2],R.cf[,2]))
mD1 &lt;- rowMeans(abs(C.cf - R.cf))
lrg &lt;- mD1 &gt; quantile(mD1, 0.80)
arrows(C.cf[lrg,1], C.cf[lrg,2],
       R.cf[lrg,1], R.cf[lrg,2], length=.1, col="light gray")
points(R.cf, col=2)

## All robustness weights
aW &lt;- t(sapply(R, weights, type="robustness"))
colnames(aW) &lt;- names(yearly)
summary(aW)
sort(colSums(aW &lt; 0.05, na.rm = TRUE)) # how often "clear outlier":
# lu st zg ba se sz su si re la ef ad ri
#  0  0  0  1  1  1  2  3  4 10 14 17 48

lattice::levelplot(aW, asp=1/2, main="Robustness weights",
                   xlab= "day", ylab= "site")
</code></pre>

<hr>
<h2 id='Animals2'>Brain and Body Weights for 65 Species of Land Animals</h2><span id='topic+Animals2'></span>

<h3>Description</h3>

<p>A data frame with average brain and body weights for 62 species
of land mammals and three others.
</p>
<p>Note that this is simply the union of <code><a href="MASS.html#topic+Animals">Animals</a></code>
and <code><a href="MASS.html#topic+mammals">mammals</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Animals2
</code></pre>


<h3>Format</h3>


<dl>
<dt><code>body</code></dt><dd><p>body weight in kg</p>
</dd>
<dt><code>brain</code></dt><dd><p>brain weight in g</p>
</dd>
</dl>



<h3>Note</h3>

<p>After loading the <a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a> package, the data set is simply constructed by
<code>Animals2 &lt;- local({D &lt;- rbind(Animals, mammals);
      unique(D[order(D$body,D$brain),])})</code>.
</p>
<p>Rousseeuw and Leroy (1987)'s &lsquo;brain&rsquo; data is the same as
<a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a>'s <code>Animals</code> (with Rat and Brachiosaurus interchanged,
see the example below).
</p>


<h3>Source</h3>

<p>Weisberg, S. (1985)
<em>Applied Linear Regression.</em>
2nd edition.
Wiley, pp. 144&ndash;5.
</p>
<p>P. J. Rousseeuw  and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection.</em>
Wiley, p. 57.
</p>


<h3>References</h3>

<p>Venables, W. N. and Ripley, B. D. (2002)
<em>Modern Applied Statistics with S.</em> Forth Edition. Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Animals2)
## Sensible Plot needs doubly logarithmic scale
plot(Animals2, log = "xy")

## Regression example plot:
plotbb &lt;- function(bbdat) {
  d.name &lt;- deparse(substitute(bbdat))
  plot(log(brain) ~ log(body), data = bbdat, main = d.name)
  abline(       lm(log(brain) ~ log(body), data = bbdat))
  abline(MASS::rlm(log(brain) ~ log(body), data = bbdat), col = 2)
  legend("bottomright", leg = c("lm", "rlm"), col=1:2, lwd=1, inset = 1/20)
}
plotbb(bbdat = Animals2)

## The `same' plot for Rousseeuw's subset:
data(Animals, package = "MASS")
brain &lt;- Animals[c(1:24, 26:25, 27:28),]
plotbb(bbdat = brain)

lbrain &lt;- log(brain)
plot(mahalanobis(lbrain, colMeans(lbrain), var(lbrain)),
     main = "Classical Mahalanobis Distances")
mcd &lt;- covMcd(lbrain)
plot(mahalanobis(lbrain,mcd$center,mcd$cov),
     main = "Robust (MCD) Mahalanobis Distances")
</code></pre>

<hr>
<h2 id='anova.glmrob'>Analysis of Robust Quasi-Deviance for &quot;glmrob&quot; Objects</h2><span id='topic+anova.glmrob'></span>

<h3>Description</h3>

<p>Compute an analysis of robust quasi-deviance table for one or more
generalized linear models fitted by <code><a href="#topic+glmrob">glmrob</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmrob'
anova(object, ..., test = c("Wald", "QD", "QDapprox"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.glmrob_+3A_object">object</code>, <code id="anova.glmrob_+3A_...">...</code></td>
<td>
<p>objects of class <code>glmrob</code>, typically
the result of a call to <code><a href="#topic+glmrob">glmrob</a></code>.</p>
</td></tr>
<tr><td><code id="anova.glmrob_+3A_test">test</code></td>
<td>
<p>a character string specifying the test statistic to be
used.  (Partially) matching one of <code>"Wald"</code>, <code>"QD"</code> or
<code>"QDapprox"</code>. See Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Specifying a single object gives a sequential analysis of robust
quasi-deviance table for that fit.  That is, the reductions in the
robust residual quasi-deviance as each term of the formula is added in
turn are given in as the rows of a table. <em>(Currently not yet
implemented.)</em>
</p>
<p>If more than one object is specified, the table has a row for the
residual quasi-degrees of freedom (However, this information is never used in
the asymptotic tests).  For all but the first model, the
change in degrees of freedom and robust quasi-deviance is also
given.  (This only makes statistical sense if the models are nested.)
It is conventional to list the models from smallest to largest, but
this is up to the user.
</p>
<p>In addition, the table will contain test statistics and P values
comparing the reduction in robust quasi-deviance for the model on the
row to that on top of it.  For all robust fitting methods, the
&ldquo;Wald&rdquo;-type test between two models can be applied (<code>test
    = "Wald"</code>).
</p>
<p>When using Mallows or Huber type robust estimators
(<code>method="Mqle"</code> in <code><a href="#topic+glmrob">glmrob</a></code>), then there are
additional test methods.  One is the robust quasi-deviance test
(<code>test = "QD"</code>), as described by Cantoni and Ronchetti (2001).
The asymptotic distribution is approximated by a chi-square
distibution.  Another test (<code>test = "QDapprox"</code>) is based on a
quadratic approximation of the robust quasi-deviance test
statistic.  Its asymptotic distribution is chi-square (see the reference).
</p>
<p>The comparison between two or more models by <code>anova.glmrob</code>
will only be valid if they are fitted to the same dataset and by the same
robust fitting method using the same tuning constant <code class="reqn">c</code> (<code>tcc</code> in
<code><a href="#topic+glmrob">glmrob</a></code>).
</p>


<h3>Value</h3>

<p>Basically, an object of class <code><a href="stats.html#topic+anova">anova</a></code> inheriting from class
<code><a href="base.html#topic+data.frame">data.frame</a></code>.
</p>


<h3>Author(s)</h3>

<p> Andreas Ruckstuhl </p>


<h3>References</h3>

<p>E. Cantoni and E. Ronchetti (2001)
Robust Inference for Generalized Linear Models.
<em>JASA</em> <b>96</b> (455), 1022&ndash;1030.
</p>
<p>E.Cantoni (2004)
Analysis of Robust Quasi-deviances for Generalized Linear Models.
<em>Journal of Statistical Software</em> <b>10</b>,
<a href="https://www.jstatsoft.org/article/view/v010i04">https://www.jstatsoft.org/article/view/v010i04</a>
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+glmrob">glmrob</a></code>, <code><a href="stats.html#topic+anova">anova</a></code>.




</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Binomial response -----------
data(carrots)
Cfit2 &lt;- glmrob(cbind(success, total-success) ~ logdose + block,
                family=binomial, data=carrots, method="Mqle",
                control=glmrobMqle.control(tcc=1.2))
summary(Cfit2)

Cfit4 &lt;- glmrob(cbind(success, total-success) ~ logdose * block,
                family=binomial, data=carrots, method="Mqle",
                control=glmrobMqle.control(tcc=1.2))

anova(Cfit2, Cfit4, test="Wald")

anova(Cfit2, Cfit4, test="QD")

anova(Cfit2, Cfit4, test="QDapprox")

## Poisson response ------------
data(epilepsy)

Efit2 &lt;- glmrob(Ysum ~ Age10 + Base4*Trt, family=poisson, data=epilepsy,
               method="Mqle", control=glmrobMqle.control(tcc=1.2,maxit=100))
summary(Efit2)

Efit3 &lt;- glmrob(Ysum ~ Age10 + Base4 + Trt, family=poisson, data=epilepsy,
               method="Mqle", control=glmrobMqle.control(tcc=1.2,maxit=100))

anova(Efit3, Efit2, test = "Wald")

anova(Efit3, Efit2, test = "QD")

## trivial intercept-only-model:
E0 &lt;- update(Efit3, . ~ 1)
anova(E0, Efit3, Efit2, test = "QDapprox")

</code></pre>

<hr>
<h2 id='anova.lmrob'>Analysis of Robust Deviances ('anova') for &quot;lmrob&quot; Objects</h2><span id='topic+anova.lmrob'></span>

<h3>Description</h3>

<p>Compute an analysis of robust Wald-type or deviance-type test tables
for one or more linear regression models fitted by <code><a href="#topic+lmrob">lmrob</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lmrob'
anova(object, ..., test = c("Wald", "Deviance"),
      verbose = getOption("verbose"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova.lmrob_+3A_object">object</code>, <code id="anova.lmrob_+3A_...">...</code></td>
<td>
<p>objects of class <code>"lmrob"</code>, typically
the result of a call to <code><a href="#topic+lmrob">lmrob</a></code>. <code>...</code> arguments
may also be symbolic descriptions of the reduced models
(cf. argument <code>formula</code> in <code><a href="stats.html#topic+lm">lm</a></code>).
</p>
</td></tr>
<tr><td><code id="anova.lmrob_+3A_test">test</code></td>
<td>
<p>a character string specifying the test statistic to be used.
Can be one of <code>"Wald"</code> or <code>"Deviance"</code>,
with partial matching allowed, for specifying a <code>"Wald"</code>-type
test or <code>"Deviance"</code>-type test.</p>
</td></tr>
<tr><td><code id="anova.lmrob_+3A_verbose">verbose</code></td>
<td>
<p>logical; if true some informative messages are printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Specifying a single object gives a sequential analysis of a robust
quasi-deviance table for that fit.  That is, the reductions in the
robust residual deviance as each term of the formula is added in turn
are given in as the rows of a table. (Currently not yet implemented.)
</p>
<p>If more than one object is specified, the table has a row for the
residual quasi-degrees of freedom (however, this information is never
used in the asymptotic tests).  For all but the first model, the
change in degrees of freedom and robust deviance is also given.  (This
only makes statistical sense if the models are nested.)  As opposed to
the convention, the models are forced to be listed from largest to
smallest due to computational reasons.
</p>
<p>In addition, the table will contain test statistics and P values
comparing the reduction in robust deviances for the model on the row
to that on top of it.  There are two different robust tests available:
The &quot;Wald&quot;-type test (<code>test = "Wald"</code>) and the Deviance-type test
(<code>test = "Deviance"</code>).  When using formula description of the
nested models in the dot arguments and <code>test = "Deviance"</code>, you
may be urged to supply a <code><a href="#topic+lmrob">lmrob</a></code> fit for these models by
an error message.  This happens when the coefficients of the largest
model reduced to the nested models result in invalid initial estimates
for the nested models (indicated by robustness weights which are all 0).
</p>
<p>The comparison between two or more models by <code><a href="#topic+anova.lmrob">anova.lmrob</a></code>
will only be valid if they are fitted to the same dataset.
</p>


<h3>Value</h3>

<p>Basically, an object of class <code><a href="stats.html#topic+anova">anova</a></code> inheriting from class
<code><a href="base.html#topic+data.frame">data.frame</a></code>.
</p>


<h3>Author(s)</h3>

<p>Andreas Ruckstuhl</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob">lmrob</a></code>, <code><a href="stats.html#topic+anova">anova</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(salinity)
summary(m0.sali  &lt;- lmrob(Y ~ . , data = salinity))
anova(m0.sali, Y ~ X1 + X3)
## -&gt; X2 is not needed
(m1.sali  &lt;- lmrob(Y ~ X1 + X3, data = salinity))
anova(m0.sali, m1.sali) # the same as before
anova(m0.sali, m1.sali, test = "Deviance")
## whereas 'X3' is highly significant:
m2 &lt;- update(m0.sali, ~ . -X3)
anova(m0.sali, m2)
anova(m0.sali, m2,  test = "Deviance")
## Global test [often not interesting]:
anova(m0.sali, update(m0.sali, . ~ 1), test = "Wald")
anova(m0.sali, update(m0.sali, . ~ 1), test = "Deviance")

if(require("MPV")) { ## Montgomery, Peck &amp; Vining  datasets
  Jet &lt;- table.b13
  Jet.rflm1 &lt;- lmrob(y ~ ., data=Jet,
                     control = lmrob.control(max.it = 500))
  summary(Jet.rflm1)

  anova(Jet.rflm1, y ~ x1 + x5 + x6, test="Wald")

  try( anova(Jet.rflm1, y ~ x1 + x5 + x6, test="Deviance") )
  ## -&gt; Error in anovaLm....  Please fit the nested models by lmrob

  ## {{ since  all robustness weights become 0 in the nested model ! }}

  ## Ok: Do as the error message told us:
  ##    test by comparing the two *fitted* models:

  Jet.rflm2 &lt;- lmrob(y ~ x1 + x5 + x6, data=Jet,
                     control=lmrob.control(max.it=100))
  anova(Jet.rflm1, Jet.rflm2, test="Deviance")

} # end{"MPV" data}

</code></pre>

<hr>
<h2 id='biomassTill'>Biomass Tillage Data</h2><span id='topic+biomassTill'></span>

<h3>Description</h3>

<p>An agricultural experiment in which different tillage methods were
implemented. The effects of tillage on plant (maize) biomass were
subsequently determined by modeling biomass accumulation for each
tillage treatment using a 3 parameter Weibull function.
</p>
<p>A datset where the total biomass is modeled conditional on a
three value factor, and hence <em>vector</em> parameters are used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("biomassTill", package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 58 observations on the following 3 variables.
</p>

<dl>
<dt><code>Tillage</code></dt><dd><p>Tillage treatments, a <code><a href="base.html#topic+factor">factor</a></code>
with levels </p>

<dl>
<dt><code>CA-</code>:</dt><dd><p>a no-tillage system with plant residues removed</p>
</dd>
<dt><code>CA+</code>:</dt><dd><p>a no-tillage system with plant residues retained</p>
</dd>
<dt><code>CT</code>:</dt><dd><p>a conventionally tilled system with residues incorporated</p>
</dd>
</dl>

</dd>
<dt><code>DVS</code></dt><dd><p>the development stage of the maize crop.  A DVS of
<code>1</code> represents maize anthesis (flowering), and a DVS of <code>2</code>
represents physiological maturity.   For the data, numeric vector with
5 different values between 0.5 and 2.</p>
</dd>
<dt><code>Biomass</code></dt><dd><p>accumulated biomass of maize plants from each
tillage treatment.</p>
</dd>
<dt><code>Biom.2</code></dt><dd><p>the same as <code>Biomass</code>, but with three
values replaced by &ldquo;gross errors&rdquo;.</p>
</dd>
</dl>



<h3>Source</h3>

<p>From Strahinja Stepanovic and John Laborde, Department of Agronomy &amp;
Horticulture, University of Nebraska-Lincoln, USA
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(biomassTill)
str(biomassTill)
require(lattice)
## With long tailed errors
xyplot(Biomass ~ DVS | Tillage, data = biomassTill, type=c("p","smooth"))
## With additional 2 outliers:
xyplot(Biom.2 ~ DVS | Tillage, data = biomassTill, type=c("p","smooth"))

### Fit nonlinear Regression models: -----------------------------------

## simple starting values, needed:
m00st &lt;- list(Wm = rep(300,  3),
               a = rep( 1.5, 3),
               b = rep( 2.2, 3))

robm &lt;- nlrob(Biomass ~ Wm[Tillage] * (-expm1(-(DVS/a[Tillage])^b[Tillage])),
              data = biomassTill, start = m00st, maxit = 200)
##                                               -----------
summary(robm) ## ... 103 IRWLS iterations
plot(sort(robm$rweights), log = "y",
     main = "ordered robustness weights (log scale)")
mtext(getCall(robm))

## the classical (only works for the mild outliers):
cl.m &lt;- nls(Biomass ~ Wm[Tillage] * (-expm1(-(DVS/a[Tillage])^b[Tillage])),
            data = biomassTill, start = m00st)

## now for the extra-outlier data: -- fails with singular gradient !!
try(
rob2 &lt;- nlrob(Biom.2 ~ Wm[Tillage] * (-expm1(-(DVS/a[Tillage])^b[Tillage])),
              data = biomassTill, start = m00st)
)
## use better starting values:
m1st &lt;- setNames(as.list(as.data.frame(matrix(
                coef(robm), 3))),
                c("Wm", "a","b"))
try(# just breaks a bit later!
rob2 &lt;- nlrob(Biom.2 ~ Wm[Tillage] * (-expm1(-(DVS/a[Tillage])^b[Tillage])),
              data = biomassTill, start = m1st, maxit= 200, trace=TRUE)
)

## Comparison  {more to come} % once we have  "MM" working...
rbind(start = unlist(m00st),
      class = coef(cl.m),
      rob   = coef(robm))
</code></pre>

<hr>
<h2 id='bushfire'> Campbell Bushfire Data </h2><span id='topic+bushfire'></span>

<h3>Description</h3>

<p>This data set was used by Campbell (1984) to locate bushfire scars.
The dataset contains satelite measurements on five frequency bands,
corresponding to each of 38 pixels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(bushfire, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 38 observations on 5 variables.

</p>


<h3>Source</h3>

<p>Maronna, R.A. and Yohai, V.J. (1995)
The Behavoiur of the Stahel-Donoho Robust Multivariate Estimator.
<em>Journal of the American Statistical Association</em> <b>90</b>, 330&ndash;341.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(bushfire)
plot(bushfire)
covMcd(bushfire)
</code></pre>

<hr>
<h2 id='BYlogreg'>Bianco-Yohai Estimator for Robust Logistic Regression</h2><span id='topic+BYlogreg'></span>

<h3>Description</h3>

<p>Computation of the estimator of Bianco and Yohai (1996) in logistic regression.
Now provides both the <em>weighted</em> and regular (unweighted) BY-estimator.
</p>
<p>By default, an intercept term is included and p parameters are estimated.
For more details, see the reference.
</p>
<p>Note: This function is for &ldquo;back-compatibility&rdquo; with the
<code>BYlogreg()</code> code web-published at KU Leuven, Belgium,





and also available as file &lsquo;<span class="file">FunctionsRob/BYlogreg.ssc</span>&rsquo; from
<a href="https://www.wiley.com/legacy/wileychi/robust_statistics/robust.html">https://www.wiley.com/legacy/wileychi/robust_statistics/robust.html</a>.
</p>
<p>However instead of using this function, the recommended interface is
<code><a href="#topic+glmrob">glmrob</a>(*, method = "BY")</code> or <code>... method = "WBY" ..</code>,
see <code><a href="#topic+glmrob">glmrob</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BYlogreg(x0, y, initwml = TRUE, addIntercept = TRUE,
         const = 0.5, kmax = 1000, maxhalf = 10, sigma.min = 1e-4,
         trace.lev = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BYlogreg_+3A_x0">x0</code></td>
<td>
<p>a numeric <code class="reqn">n \times (p-1)</code> matrix containing
the explanatory variables.</p>
</td></tr>
<tr><td><code id="BYlogreg_+3A_y">y</code></td>
<td>
<p>numeric <code class="reqn">n</code>-vector of binomial (0 - 1) responses.</p>
</td></tr>
<tr><td><code id="BYlogreg_+3A_initwml">initwml</code></td>
<td>
<p>logical for selecting one of the two possible methods
for computing the initial value of the optimization process.
</p>
<p>If <code>initwml</code> is true (default), a weighted ML estimator is
computed with weights derived from the MCD estimator
computed on the explanatory variables.
</p>
<p>If <code>initwml</code> is false, a classical ML fit is perfomed.  When
the explanatory variables contain binary observations, it is
recommended to set initwml to FALSE or to modify the code of the
algorithm to compute the weights only on the continuous variables.
</p>
</td></tr>
<tr><td><code id="BYlogreg_+3A_addintercept">addIntercept</code></td>
<td>
<p>logical indicating that a column of <code>1</code> must be
added the <code class="reqn">x</code> matrix.</p>
</td></tr>
<tr><td><code id="BYlogreg_+3A_const">const</code></td>
<td>
<p>tuning constant used in the computation of the estimator
(default=0.5).</p>
</td></tr>
<tr><td><code id="BYlogreg_+3A_kmax">kmax</code></td>
<td>
<p>maximum number of iterations before convergence (default=1000).</p>
</td></tr>
<tr><td><code id="BYlogreg_+3A_maxhalf">maxhalf</code></td>
<td>
<p>max number of step-halving (default=10).</p>
</td></tr>
<tr><td><code id="BYlogreg_+3A_sigma.min">sigma.min</code></td>
<td>
<p>smallest value of the scale parameter before
implosion (and hence non-convergence) is assumed.</p>
</td></tr>
<tr><td><code id="BYlogreg_+3A_trace.lev">trace.lev</code></td>
<td>
<p>logical (or integer) indicating if intermediate results
should be printed; defaults to <code>0</code> (the same as <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with components
</p>
<table>
<tr><td><code>convergence</code></td>
<td>
<p>logical indicating if convergence was achieved</p>
</td></tr>
<tr><td><code>objective</code></td>
<td>
<p>the value of the objective function at the minimum</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>vector of parameter estimates</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>variance-covariance matrix of the coefficients (if convergence is TRUE).</p>
</td></tr>
<tr><td><code>sterror</code></td>
<td>
<p>standard errors, i.e., simply <code>sqrt(diag(.$vcov))</code>, if convergence.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Originally, Christophe Croux and Gentiane Haesbroeck, with
thanks to Kristel Joossens and Valentin Todorov for improvements.
</p>
<p>Speedup, tweaks, more &ldquo;control&rdquo; arguments: Martin Maechler.
</p>


<h3>References</h3>

<p>Croux, C., and Haesbroeck, G. (2003)
Implementing the Bianco and Yohai estimator for Logistic Regression,
<em>Computational Statistics and Data Analysis</em> <b>44</b>, 273&ndash;295.
</p>
<p>Ana M. Bianco and VÃ­ctor J. Yohai (1996)
Robust estimation in the logistic regression model.
In Helmut Rieder, <em>Robust Statistics, Data Analysis, and
Computer Intensive Methods</em>, Lecture Notes in Statistics <b>109</b>,
pages 17&ndash;34.
</p>


<h3>See Also</h3>

<p>The more typical way to compute BY-estimates (via
<code><a href="stats.html#topic+formula">formula</a></code> and methods):
<code><a href="#topic+glmrob">glmrob</a>(*, method = "WBY")</code> and <code>.. method = "BY"</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(17)
x0 &lt;- matrix(rnorm(100,1))
y  &lt;- rbinom(100, size=1, prob= 0.5) # ~= as.numeric(runif(100) &gt; 0.5)
BY &lt;- BYlogreg(x0,y)
BY &lt;- BYlogreg(x0,y, trace.lev=TRUE)

## The "Vaso Constriction"  aka "skin" data:
data(vaso)
vX &lt;- model.matrix( ~ log(Volume) + log(Rate), data=vaso)
vY &lt;- vaso[,"Y"]
head(cbind(vX, vY))# 'X' does include the intercept

vWBY &lt;- BYlogreg(x0 = vX, y = vY, addIntercept=FALSE) # as 'vX' has it already
v.BY &lt;- BYlogreg(x0 = vX, y = vY, addIntercept=FALSE, initwml=FALSE)
## they are relatively close, well used to be closer than now,
## with the (2023-05, VT) change of covMcd() scale-correction
stopifnot( all.equal(vWBY, v.BY, tolerance = 0.008) ) # was ~ 1e-4 till 2023-05
</code></pre>

<hr>
<h2 id='carrots'>Insect Damages on Carrots</h2><span id='topic+carrots'></span>

<h3>Description</h3>

<p>The damage carrots data set from Phelps (1982) was used by McCullagh
and Nelder (1989) in order to illustrate diagnostic techniques because
of the presence of an outlier. In a soil experiment trial with three
blocks, eight levels of insecticide were applied and the carrots were
tested for insect damage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(carrots, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 4 variables.
</p>

<dl>
<dt>success</dt><dd><p> integer giving the number of carrots with insect damage.</p>
</dd>
<dt>total</dt><dd><p> integer giving the total number of carrots per
experimental unit.</p>
</dd>
<dt>logdose</dt><dd><p>a numeric vector giving log(dose) values (eight
different levels only).</p>
</dd>
<dt>block</dt><dd><p>factor with levels <code>B1</code> to <code>B3</code></p>
</dd>
</dl>



<h3>Source</h3>

<p>Phelps, K. (1982).
Use of the complementary log-log function to describe doseresponse
relationships in insecticide evaluation field trials.
<br />
In R. Gilchrist (Ed.), <em>Lecture Notes in Statistics, No. 14.
GLIM.82: Proceedings of the International Conference on Generalized
Linear Models</em>; Springer-Verlag.
</p>


<h3>References</h3>

<p>McCullagh P. and Nelder, J. A. (1989)
<em>Generalized Linear Models.</em>
London: Chapman and Hall.
</p>
<p>Eva Cantoni and Elvezio Ronchetti (2001); JASA,  and <br />
Eva Cantoni (2004); JSS, see <code><a href="#topic+glmrob">glmrob</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(carrots)
str(carrots)
plot(success/total ~ logdose, data = carrots, col = as.integer(block))
coplot(success/total ~ logdose | block, data = carrots)

## Classical glm
Cfit0 &lt;- glm(cbind(success, total-success) ~ logdose + block,
             data=carrots, family=binomial)
summary(Cfit0)

## Robust Fit (see help(glmrob)) ....
</code></pre>

<hr>
<h2 id='chgDefaults-methods'>Change Defaults (Parameters) of &quot;Psi Function&quot; Objects</h2><span id='topic+chgDefaults'></span><span id='topic+chgDefaults-methods'></span><span id='topic+chgDefaults+2CANY-method'></span><span id='topic+chgDefaults+2Cpsi_func-method'></span>

<h3>Description</h3>

<p>To modify an object of class <code><a href="#topic+psi_func-class">psi_func</a></code>,
i.e. typically change the tuning parameters, the generic function
<code>chgDefaults()</code> is called and works via the corresponding method.
</p>


<h3>Methods</h3>


<dl>
<dt><code>object = "psi_func"</code></dt><dd><p>The method is used to change the default
values for the tuning parameters, and returns an object of class
<code><a href="#topic+psi_func-class">psi_func</a></code>, a copy of input <code>object</code>
with the slot <code>tDefs</code> possibly changed;.
</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+psiFunc">psiFunc</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Hampel's psi and rho:
H.38 &lt;- chgDefaults(hampelPsi, k = c(1.5, 3.5, 8))
H.38
plot(H.38)
## for more see  ?psiFunc
</code></pre>

<hr>
<h2 id='classPC'>Compute Classical Principal Components via SVD or Eigen</h2><span id='topic+classPC'></span>

<h3>Description</h3>

<p>Compute classical principal components (PC) via SVD (<code><a href="base.html#topic+svd">svd</a></code>
or eigenvalue decomposition (<code><a href="base.html#topic+eigen">eigen</a></code>) with non-trivial
rank determination.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classPC(x, scale = FALSE, center = TRUE, signflip = TRUE,
        via.svd = n &gt; p, scores = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classPC_+3A_x">x</code></td>
<td>
<p>a numeric <code><a href="base.html#topic+matrix">matrix</a></code>.</p>
</td></tr>
<tr><td><code id="classPC_+3A_scale">scale</code></td>
<td>
<p>logical indicating if the matrix should be scaled; it is
mean centered in any case (via
<code><a href="base.html#topic+scale">scale</a>(*, scale=scale)</code>c</p>
</td></tr>
<tr><td><code id="classPC_+3A_center">center</code></td>
<td>
<p>logical or numeric vector for &ldquo;centering&rdquo; the matrix.</p>
</td></tr>
<tr><td><code id="classPC_+3A_signflip">signflip</code></td>
<td>
<p>logical indicating if the sign(.) of the loadings
should be determined should flipped such that the absolutely largest
value is always positive.</p>
</td></tr>
<tr><td><code id="classPC_+3A_via.svd">via.svd</code></td>
<td>
<p>logical indicating if the computation is
via SVD or Eigen decomposition; the latter makes sense
typically only for n &lt;= p.</p>
</td></tr>
<tr><td><code id="classPC_+3A_scores">scores</code></td>
<td>
<p>logical indicating</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+list">list</a></code> with components
</p>
<table>
<tr><td><code>rank</code></td>
<td>
<p>the (numerical) matrix rank of <code>x</code>; an integer
number, say <code class="reqn">k</code>, from <code>0:min(dim(x))</code>.  In the <code class="reqn">n &gt; p</code> case,
it is <code><a href="#topic+rankMM">rankMM</a>(x)</code>.</p>
</td></tr>
<tr><td><code>eigenvalues</code></td>
<td>
<p>the <code class="reqn">k</code> eigenvalues, in the <code class="reqn">n &gt; p</code> case,
proportional to the variances.</p>
</td></tr>
<tr><td><code>loadings</code></td>
<td>
<p>the loadings, a <code class="reqn">p \times k</code> matrix.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>if the <code>scores</code> argument was true, the <code class="reqn">n \times
      k</code> matrix of scores, where <code class="reqn">k</code> is the <code>rank</code> above.</p>
</td></tr>
<tr><td><code>center</code></td>
<td>
<p>a numeric <code class="reqn">p</code>-vector of means, unless the
<code>center</code> argument was false.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>if the <code>scale</code> argument was not false, the
<code>scale</code> used, a <code class="reqn">p</code>-vector.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Valentin Todorov; efficiency tweaks by Martin Maechler
</p>


<h3>See Also</h3>

<p>In spirit very similar to <span class="rlang"><b>R</b></span>'s standard <code><a href="stats.html#topic+prcomp">prcomp</a></code> and
<code><a href="stats.html#topic+princomp">princomp</a></code>, one of the main differences being how the
<em>rank</em> is determined via a non-trivial tolerance.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(17)
x &lt;- matrix(rnorm(120), 10, 12) # n &lt; p {the unusual case}
pcx  &lt;- classPC(x)
(k &lt;- pcx$rank) # = 9  [after centering!]
pc2  &lt;- classPC(x, scores=TRUE)
pcS  &lt;- classPC(x, via.svd=TRUE)
all.equal(pcx, pcS, tol = 1e-8)
## TRUE: eigen() &amp; svd() based PC are close here
pc0 &lt;- classPC(x, center=FALSE, scale=TRUE)
pc0$rank # = 10  here *no* centering (as E[.] = 0)

## Loadings are orthnormal:
zapsmall( crossprod( pcx$loadings ) )

## PC Scores are roughly orthogonal:
S.S &lt;- crossprod(pc2$scores)
print.table(signif(zapsmall(S.S), 3), zero.print=".")
stopifnot(all.equal(pcx$eigenvalues, diag(S.S)/k))

## the usual n &gt; p case :
pc.x &lt;- classPC(t(x))
pc.x$rank # = 10, full rank in the n &gt; p case

cpc1 &lt;- classPC(cbind(1:3)) # 1-D matrix
stopifnot(cpc1$rank == 1,
          all.equal(cpc1$eigenvalues, 1),
          all.equal(cpc1$loadings, 1))

</code></pre>

<hr>
<h2 id='cloud'>Cloud point of a Liquid</h2><span id='topic+cloud'></span>

<h3>Description</h3>

<p>This data set contains the measurements concerning the
cloud point of a Liquid, from Draper and Smith (1969).
The cloud point is a measure of the degree of crystallization in a
stock.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cloud, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 19 observations on the following 2 variables.
</p>

<dl>
<dt><code>Percentage</code></dt><dd><p>Percentage of I-8</p>
</dd>
<dt><code>CloudPoint</code></dt><dd><p>Cloud point</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, p.96, table 10.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cloud)
summary(lm.cloud &lt;- lm(CloudPoint ~., data=cloud))

</code></pre>

<hr>
<h2 id='coleman'>Coleman Data Set</h2><span id='topic+coleman'></span>

<h3>Description</h3>

<p>Contains information on 20 Schools from the Mid-Atlantic and New
England States, drawn from a population studied by Coleman et
al. (1966). Mosteller and Tukey (1977) analyze this sample consisting
of measurements on six different variables, one of which will be
treated as a responce.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(coleman, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 6 variables.
</p>

<dl>
<dt><code>salaryP</code></dt><dd><p>staff salaries per pupil</p>
</dd>
<dt><code>fatherWc</code></dt><dd><p>percent of white-collar fathers</p>
</dd>
<dt><code>sstatus</code></dt><dd><p>socioeconomic status composite deviation: means for
family size, family intactness, father's education, mother's
education, and home items</p>
</dd>
<dt><code>teacherSc</code></dt><dd><p>mean teacher's verbal test score</p>
</dd>
<dt><code>motherLev</code></dt><dd><p>mean mother's educational level, one unit is equal
to two school years</p>
</dd>
<dt><code>Y</code></dt><dd><p>verbal mean test score (y, all sixth graders)</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Valentin Todorov</p>


<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em> Wiley, p.79, table 2.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(coleman)
pairs(coleman)
summary( lm.coleman &lt;-     lm(Y ~ . , data = coleman))
summary(lts.coleman &lt;- ltsReg(Y ~ . , data = coleman))

coleman.x &lt;- data.matrix(coleman[, 1:6])
(Cc &lt;- covMcd(coleman.x))
</code></pre>

<hr>
<h2 id='colMedians'>Fast Row or Column-wise Medians of a Matrix</h2><span id='topic+colMedians'></span><span id='topic+rowMedians'></span>

<h3>Description</h3>

<p>Calculates the median for each row (column) of a matrix <code>x</code>.
This is the same as but more efficient than <code>apply(x, MM, median)</code>
for MM=2 or MM=1, respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>colMedians(x, na.rm = FALSE, hasNA = TRUE, keep.names=TRUE)
rowMedians(x, na.rm = FALSE, hasNA = TRUE, keep.names=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="colMedians_+3A_x">x</code></td>
<td>
<p>a <code><a href="base.html#topic+numeric">numeric</a></code> <code class="reqn">n \times p</code> <code><a href="base.html#topic+matrix">matrix</a></code>.</p>
</td></tr>
<tr><td><code id="colMedians_+3A_na.rm">na.rm</code></td>
<td>
<p>if <code><a href="base.html#topic+TRUE">TRUE</a></code>, <code><a href="base.html#topic+NA">NA</a></code>s are excluded
first, otherwise not.</p>
</td></tr>
<tr><td><code id="colMedians_+3A_hasna">hasNA</code></td>
<td>
<p>logical indicating if <code>x</code> may contain <code><a href="base.html#topic+NA">NA</a></code>s.
If set to <code>FALSE</code>, no internal NA handling is performed which
typically is faster.</p>
</td></tr>
<tr><td><code id="colMedians_+3A_keep.names">keep.names</code></td>
<td>
<p>logical indicating if row or column names of <code>x</code>
should become <code><a href="base.html#topic+names">names</a></code> of the result - as is the case for
<code><a href="base.html#topic+apply">apply</a>(x, MM, median)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The implementation of <code>rowMedians()</code> and <code>colMedians()</code>
is optimized for both speed and memory.
To avoid coercing to <code><a href="base.html#topic+double">double</a></code>s (and hence memory allocation), there
is a special implementation for <code><a href="base.html#topic+integer">integer</a></code> matrices.
That is, if <code>x</code> is an <code><a href="base.html#topic+integer">integer</a></code> <code><a href="base.html#topic+matrix">matrix</a></code>, then
<code>rowMedians(as.double(x))</code> (<code>rowMedians(as.double(x))</code>)
would require three times the memory of <code>rowMedians(x)</code>
(<code>colMedians(x)</code>), but all this is avoided.
</p>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+numeric">numeric</a></code> vector of length <code class="reqn">n</code> or <code class="reqn">p</code>, respectively.
</p>


<h3>Missing values</h3>

<p>Missing values are excluded before calculating the medians
<em>unless</em> <code>hasNA</code> is false.  Note that <code>na.rm</code> has no
effect and is automatically false when <code>hasNA</code> is false, i.e.,
internally, before computations start, the following is executed:
</p>
<pre>if (!hasNA)        ## If there are no NAs, don't try to remove them
     narm &lt;- FALSE</pre>


<h3>Author(s)</h3>

<p>Henrik Bengtsson, Harris Jaffee, Martin Maechler</p>


<h3>See Also</h3>

<p>See <code><a href="#topic+wgt.himedian">wgt.himedian</a>()</code> for a weighted hi-median, and
<code><a href="matrixStats.html#topic+colWeightedMedians">colWeightedMedians</a>()</code> etc from package
<a href="https://CRAN.R-project.org/package=matrixStats"><span class="pkg">matrixStats</span></a> for <em>weighted</em> medians.<br />
For mean estimates, see <code>rowMeans()</code> in <code><a href="Matrix.html#topic+colSums">colSums</a></code>().
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1); n &lt;- 234; p &lt;- 543 # n*p = 127'062
x &lt;- matrix(rnorm(n*p), n, p)
x[sample(seq_along(x), size= n*p / 256)] &lt;- NA
R1 &lt;- system.time(r1 &lt;- rowMedians(x, na.rm=TRUE))
C1 &lt;- system.time(y1 &lt;- colMedians(x, na.rm=TRUE))
R2 &lt;- system.time(r2 &lt;- apply(x, 1, median, na.rm=TRUE))
C2 &lt;- system.time(y2 &lt;- apply(x, 2, median, na.rm=TRUE))
R2 / R1 # speedup factor: ~= 4   {platform dependent}
C2 / C1 # speedup factor: ~= 5.8 {platform dependent}
stopifnot(all.equal(y1, y2, tol=1e-15),
          all.equal(r1, r2, tol=1e-15))

(m &lt;- cbind(x1=3, x2=c(4:1, 3:4,4)))
stopifnot(colMedians(m) == 3,
          all.equal(colMeans(m), colMedians(m)),# &lt;- including names !
          all.equal(rowMeans(m), rowMedians(m)))
</code></pre>

<hr>
<h2 id='condroz'> Condroz Data </h2><span id='topic+condroz'></span>

<h3>Description</h3>

<p>Dataset with pH-value and Calcium content in soil samples, collected in different
communities of the Condroz region in Belgium. The data pertain to a
subset of 428 samples with a pH-value between 7.0 and 7.5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(condroz, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 428 observations on the following 2 variables.
</p>

<dl>
<dt><code>Ca</code></dt><dd><p>Calcium content of the soil sample</p>
</dd>
<dt><code>pH</code></dt><dd><p>pH value of the soil sample</p>
</dd>
</dl>



<h3>Details</h3>

<p>For more information on the dataset, cf. Goegebeur et al. (2005).
</p>


<h3>Source</h3>

<p>Hubert and Vandervieren (2006), p. 10.
This dataset is also studied in Vandewalle et al. (2004).
</p>


<h3>References</h3>

<p>See also those for <code><a href="#topic+adjbox">adjbox</a></code>.
</p>
<p>Goegebeur, Y., Planchon, V., Beirlant, J., Oger, R. (2005). Quality
Assesment of Pedochemical Data Using Extreme Value Methodology,
Journal of Applied Science, 5, p. 1092-1102.
</p>
<p>Vandewalle, B., Beirlant, J., Hubert, M. (2004). A robust estimator of
the tail index based on an exponential regression model, in Hubert,
M., Pison G., Struyf, A. and S. Van Aelst, ed., Theory and
Applications of Recent Robust Methods, BirkhÃ¤user, Basel, p. 367-376.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  adjbox(condroz$Ca)
</code></pre>

<hr>
<h2 id='covComed'>Co-Median Location and Scatter &quot;Covariance&quot; Estimator</h2><span id='topic+covComed'></span><span id='topic+comedian'></span><span id='topic+COM'></span><span id='topic+.wgtFUN.covComed'></span>

<h3>Description</h3>

<p>Compute (versions of) the (multivariate) &ldquo;Comedian&rdquo; covariance,
i.e., multivariate location and scatter estimator
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covComed(X, n.iter = 2, reweight = FALSE, tolSolve = control$tolSolve,
         trace = control$trace, wgtFUN = control$wgtFUN,
         control = rrcov.control())


</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covComed_+3A_x">X</code></td>
<td>
<p>data matrix of dimension, say <code class="reqn">n \times p</code>.</p>
</td></tr>
<tr><td><code id="covComed_+3A_n.iter">n.iter</code></td>
<td>
<p>number of comedian() iterations.  Can be as low as zero.</p>
</td></tr>
<tr><td><code id="covComed_+3A_reweight">reweight</code></td>
<td>
<p>logical indicating if the final distances and weights
should be recomputed from the final <code>cov</code> and <code>center</code>.
The default is currently <code>FALSE</code> because that was implicit in
the first version of the <span class="rlang"><b>R</b></span> code.</p>
</td></tr>
<tr><td><code id="covComed_+3A_tolsolve">tolSolve</code></td>
<td>
<p>a numerical tolerance passed to <code><a href="Matrix.html#topic+solve">solve</a></code>.</p>
</td></tr>
<tr><td><code id="covComed_+3A_trace">trace</code></td>
<td>
<p>logical (or integer) indicating if intermediate results
should be printed; defaults to <code>FALSE</code>; values <code class="reqn">\ge 2</code>
also produce print from the internal (Fortran) code.</p>
</td></tr>
<tr><td><code id="covComed_+3A_wgtfun">wgtFUN</code></td>
<td>
<p>a character string or <code><a href="base.html#topic+function">function</a></code>, specifying
how the weights for the reweighting step should be computed.  The default,
<code>wgtFUN = "01.original"</code> corresponds to 0-1 weights as proposed
originally.  Other predefined string options are available, though
experimental, see the experimental <code>.wgtFUN.covComed</code> object.</p>
</td></tr>
<tr><td><code id="covComed_+3A_control">control</code></td>
<td>
<p>a list with estimation options - this includes those
above provided in the function specification, see
<code><a href="#topic+rrcov.control">rrcov.control</a></code> for the defaults.  If <code>control</code> is
supplied, the parameters from it will be used.  If parameters are
passed also in the invocation statement, they will override the
corresponding elements of the control object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>.. not yet ..
</p>


<h3>Value</h3>

<p>an object of class <code>"covComed"</code> which is basically a list with components
</p>
<table>
<tr><td><code>comp1</code></td>
<td>
<p>Description of 'comp1'</p>
</td></tr>
<tr><td><code>comp2</code></td>
<td>
<p>Description of 'comp2'</p>
</td></tr>
</table>
<p>... FIXME ...
</p>


<h3>Author(s)</h3>

<p>Maria Anna di Palma (initial), Valentin Todorov and Martin Maechler
</p>


<h3>References</h3>

<p>Falk, M. (1997)
On mad and comedians.
<em>Annals of the Institute of Statistical Mathematics</em> <b>49</b>, 615&ndash;644.
</p>
<p>Falk, M. (1998).
A note on the comedian for elliptical distributions.
<em>Journal of Multivariate Analysis</em> <b>67</b>, 306&ndash;317.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covMcd">covMcd</a></code>, etc
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hbk)
hbk.x &lt;- data.matrix(hbk[, 1:3])
(cc1 &lt;- covComed(hbk.x))
(ccW &lt;- covComed(hbk.x, reweight=TRUE))
cc0  &lt;- covComed(hbk.x, n.iter=0)
cc0W &lt;- covComed(hbk.x, n.iter=0, reweight=TRUE)

stopifnot(all.equal(unclass(cc0), # here, the 0-1 weights don't change:
                    cc0W[names(cc0)], tol=1e-12, check.environment = FALSE),
          which(cc1$weights == 0) == 1:14,
          which(ccW$weights == 0) == 1:14,
          which(cc0$weights == 0) == 1:14)


## Martin's smooth reweighting:

## List of experimental pre-specified wgtFUN() creators:
## Cutoffs may depend on  (n, p, control$beta) :
str(.wgtFUN.covComed)
</code></pre>

<hr>
<h2 id='covMcd'>Robust Location and Scatter Estimation via MCD</h2><span id='topic+covMcd'></span><span id='topic+print.mcd'></span><span id='topic+.MCDcons'></span><span id='topic+.MCDcnp2'></span><span id='topic+.MCDcnp2.rew'></span><span id='topic+.MCDsingularityMsg'></span><span id='topic+.wgtFUN.covMcd'></span>

<h3>Description</h3>

<p>Compute the Minimum Covariance Determinant (MCD) estimator,
a robust multivariate location and scale estimate with a high
breakdown point, via the &lsquo;Fast MCD&rsquo; or &lsquo;Deterministic
MCD&rsquo; (&ldquo;DetMcd&rdquo;) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covMcd(x, cor = FALSE, raw.only = FALSE,
       alpha =, nsamp =, nmini =, kmini =,
       scalefn =, maxcsteps =,
       initHsets = NULL, save.hsets = FALSE, names = TRUE, 
       seed =, tolSolve =, trace =,
       use.correction =, wgtFUN =, control = rrcov.control())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covMcd_+3A_x">x</code></td>
<td>
<p>a matrix or data frame.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_cor">cor</code></td>
<td>
<p>should the returned result include a correlation matrix?
Default is <code>cor = FALSE</code>.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_raw.only">raw.only</code></td>
<td>
<p>should only the &ldquo;raw&rdquo; estimate be returned,
i.e., no (re)weighting step be performed; default is false.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_alpha">alpha</code></td>
<td>
<p>numeric parameter controlling the size of the subsets
over which the determinant is minimized; roughly <code>alpha*n</code>,
(see &lsquo;Details&rsquo; below)
observations are used for computing the determinant.  Allowed values
are between 0.5 and 1 and the default is 0.5.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_nsamp">nsamp</code></td>
<td>
<p>number of subsets used for initial estimates or <code>"best"</code>,
<code>"exact"</code>, or <code>"deterministic"</code>.  Default is <code>nsamp = 500</code>.
For <code>nsamp = "best"</code> exhaustive enumeration is done, as long as
the number of trials does not exceed 100'000 (<code>= nLarge</code>).
For <code>"exact"</code>, exhaustive enumeration will be attempted however
many samples are needed.  In this case a warning message may be
displayed saying that the computation can take a very long time.
</p>
<p>For <code>"deterministic"</code>, the <em>deterministic</em> MCD is computed; as
proposed by Hubert et al. (2012) it starts from the <code class="reqn">h</code> most
central observations of <em>six</em> (deterministic) estimators.
</p>
</td></tr>
<tr><td><code id="covMcd_+3A_nmini">nmini</code>, <code id="covMcd_+3A_kmini">kmini</code></td>
<td>
<p>for <code class="reqn">n \ge 2 \times n_0</code>,
<code class="reqn">n_0 := \code{nmini}</code>, the algorithm splits the data into
maximally <code>kmini</code> (by default 5) subsets, of size
approximately, but at least <code>nmini</code>.  When <code>nmini*kmini &lt; n</code>,
the initial search uses only a <em>subsample</em> of size <code>nmini*kmini</code>.

The original algorithm had <code>nmini = 300</code> and <code>kmini = 5</code>
hard coded.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_scalefn">scalefn</code></td>
<td>
<p>for the deterministic MCD: <code><a href="base.html#topic+function">function</a></code> to
compute a robust scale estimate or character string specifying a
rule determining such a function.  The default, currently
<code>"hrv2012"</code>, uses the recommendation of Hubert, Rousseeuw and
Verdonck (2012) who recommend <code><a href="#topic+Qn">Qn</a></code>
for <code class="reqn">n &lt; 1000</code> and <code><a href="#topic+scaleTau2">scaleTau2</a></code> for larger n.  Alternatively,
<code>scalefn = "v2014"</code>, uses that rule with cutoff <code class="reqn">n = 5000</code>.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_maxcsteps">maxcsteps</code></td>
<td>
<p>maximal number of concentration steps in the
deterministic MCD; should not be reached.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_inithsets">initHsets</code></td>
<td>
<p>NULL or a <code class="reqn">K x h</code> integer matrix of initial
subsets of observations of size <code class="reqn">h</code> (specified by the indices in
<code>1:n</code>).</p>
</td></tr>
<tr><td><code id="covMcd_+3A_save.hsets">save.hsets</code></td>
<td>
<p>(for deterministic MCD) logical indicating if the
initial subsets should be returned as <code>initHsets</code>.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_names">names</code></td>
<td>
<p>logical; if true (as by default), several parts of the
result have a <code><a href="base.html#topic+names">names</a></code> or <code><a href="base.html#topic+dimnames">dimnames</a></code>
respectively, derived from data matrix <code>x</code>.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_seed">seed</code></td>
<td>
<p>initial seed for random generator, like
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>, see <code><a href="#topic+rrcov.control">rrcov.control</a></code>.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_tolsolve">tolSolve</code></td>
<td>
<p>numeric tolerance to be used for inversion
(<code><a href="Matrix.html#topic+solve">solve</a></code>) of the covariance matrix in <code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code>.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_trace">trace</code></td>
<td>
<p>logical (or integer) indicating if intermediate results
should be printed; defaults to <code>FALSE</code>; values <code class="reqn">\ge 2</code>
also produce print from the internal (Fortran) code.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_use.correction">use.correction</code></td>
<td>
<p> whether to use finite sample correction
factors; defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_wgtfun">wgtFUN</code></td>
<td>
<p>a character string or <code><a href="base.html#topic+function">function</a></code>, specifying
how the weights for the reweighting step should be computed.  Up to
April 2013, the only option has been the original proposal in (1999),
now specified by <code>wgtFUN = "01.original"</code> (or via
<code>control</code>).  Since <span class="pkg">robustbase</span> version 0.92-3, Dec.2014,
other predefined string options are available, though experimental,
see the experimental <code>.wgtFUN.covMcd</code> object.</p>
</td></tr>
<tr><td><code id="covMcd_+3A_control">control</code></td>
<td>
<p>a list with estimation options - this includes those
above provided in the function specification, see
<code><a href="#topic+rrcov.control">rrcov.control</a></code> for the defaults.  If <code>control</code> is
supplied, the parameters from it will be used.  If parameters are
passed also in the invocation statement, they will override the
corresponding elements of the control object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The minimum covariance determinant estimator of location and scatter
implemented in <code>covMcd()</code> is similar to <span class="rlang"><b>R</b></span> function
<code><a href="MASS.html#topic+cov.mcd">cov.mcd</a>()</code> in <a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a>.  The MCD method looks for
the <code class="reqn">h (&gt; n/2)</code> (<code class="reqn">h = h(\alpha,n,p) =</code>
<code><a href="#topic+h.alpha.n">h.alpha.n</a>(alpha,n,p)</code>) observations (out of <code class="reqn">n</code>)
whose classical covariance matrix has the lowest possible determinant.
</p>
<p>The raw MCD estimate of location is then the average of these <code class="reqn">h</code> points,
whereas the raw MCD estimate of scatter is their covariance matrix,
multiplied by a consistency factor (<code>.MCDcons(p, h/n)</code>) and (if
<code>use.correction</code> is true) a finite sample correction factor
(<code>.MCDcnp2(p, n, alpha)</code>), to make it consistent at the
normal model and unbiased at small samples.  Both rescaling factors
(consistency and finite sample) are returned in the length-2 vector
<code>raw.cnp2</code>.
</p>
<p>The implementation of <code>covMcd</code> uses the Fast MCD algorithm of
Rousseeuw and Van Driessen (1999) to approximate the minimum
covariance determinant estimator.
</p>
<p>Based on these raw MCD estimates, (unless argument <code>raw.only</code> is
true), a reweighting step is performed, i.e., <code>V &lt;- <a href="stats.html#topic+cov.wt">cov.wt</a>(x,w)</code>,
where <code>w</code> are weights determined by &ldquo;outlyingness&rdquo; with
respect to the scaled raw MCD.  Again, a consistency factor and
(if <code>use.correction</code> is true) a finite sample correction factor
(<code>.MCDcnp2.rew(p, n, alpha)</code>) are applied.
The reweighted covariance is typically considerably more efficient
than the raw one, see Pison et al. (2002).
</p>
<p>The two rescaling factors for the reweighted estimates are returned in
<code>cnp2</code>.  Details for the computation of the finite sample
correction factors can be found in Pison et al. (2002).
</p>


<h3>Value</h3>

<p>An object of class <code>"mcd"</code> which is basically a
<code><a href="base.html#topic+list">list</a></code> with components
</p>
<table>
<tr><td><code>center</code></td>
<td>
<p>the final estimate of location.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>the final estimate of scatter.</p>
</td></tr>
<tr><td><code>cor</code></td>
<td>
<p>the (final) estimate of the correlation matrix (only if
<code>cor = TRUE</code>).</p>
</td></tr>
<tr><td><code>crit</code></td>
<td>
<p>the value of the criterion, i.e., the logarithm of the
determinant.  Previous to Nov.2014, it contained the determinant
itself which can under- or overflow relatively easily.</p>
</td></tr>
<tr><td><code>best</code></td>
<td>
<p>the best subset found and used for computing the raw
estimates, with <code><a href="base.html#topic+length">length</a>(best) == quan =
      <a href="#topic+h.alpha.n">h.alpha.n</a>(alpha,n,p)</code>.</p>
</td></tr>
<tr><td><code>mah</code></td>
<td>
<p>mahalanobis distances of the observations using the final
estimate of the location and scatter.</p>
</td></tr>
<tr><td><code>mcd.wt</code></td>
<td>
<p>weights of the observations using the final estimate of
the location and scatter.</p>
</td></tr>
<tr><td><code>cnp2</code></td>
<td>
<p>a vector of length two containing the consistency
correction factor and the finite sample correction factor of
the final estimate of the covariance matrix.</p>
</td></tr>
<tr><td><code>raw.center</code></td>
<td>
<p>the raw (not reweighted) estimate of location.</p>
</td></tr>
<tr><td><code>raw.cov</code></td>
<td>
<p>the raw (not reweighted) estimate of scatter.</p>
</td></tr>
<tr><td><code>raw.mah</code></td>
<td>
<p>mahalanobis distances of the observations based on the
raw estimate of the location and scatter.</p>
</td></tr>
<tr><td><code>raw.weights</code></td>
<td>
<p>weights of the observations based on the raw
estimate of the location and scatter.</p>
</td></tr>
<tr><td><code>raw.cnp2</code></td>
<td>
<p>a vector of length two containing the consistency
correction factor and the finite sample correction factor of
the raw estimate of the covariance matrix.</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>the input data as numeric matrix, without <code><a href="base.html#topic+NA">NA</a></code>s.</p>
</td></tr>
<tr><td><code>n.obs</code></td>
<td>
<p>total number of observations.</p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>the size of the subsets over which the determinant is
minimized (the default is <code class="reqn">(n+p+1)/2</code>).</p>
</td></tr>
<tr><td><code>quan</code></td>
<td>
<p>the number of observations, <code class="reqn">h</code>, on which the MCD is
based.  If <code>quan</code> equals <code>n.obs</code>, the MCD is the classical
covariance matrix.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>character string naming the method (Minimum Covariance
Determinant), starting with <code>"Deterministic"</code> when
<code>nsamp="deterministic"</code>.</p>
</td></tr>
<tr><td><code>iBest</code></td>
<td>
<p>(for the deterministic MCD) contains indices from 1:6
denoting which of the (six) initial subsets lead to the best set found.</p>
</td></tr>
<tr><td><code>n.csteps</code></td>
<td>
<p>(for the deterministic MCD) for each of the initial
subsets, the number of C-steps executed till convergence.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the call used (see <code><a href="base.html#topic+match.call">match.call</a></code>).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Valentin Todorov <a href="mailto:valentin.todorov@chello.at">valentin.todorov@chello.at</a>, based on
work written for S-plus by Peter Rousseeuw and Katrien van Driessen
from University of Antwerp.
</p>
<p>Visibility of (formerly internal) tuning parameters, notably
<code>wgtFUN()</code>: Martin Maechler
</p>


<h3>References</h3>

<p>Rousseeuw, P. J. and Leroy, A. M. (1987)
<em>Robust Regression and Outlier Detection.</em> Wiley.
</p>
<p>Rousseeuw, P. J. and van Driessen, K. (1999)
A fast algorithm for the minimum covariance determinant estimator.
<em>Technometrics</em> <b>41</b>, 212&ndash;223.
</p>
<p>Pison, G., Van Aelst, S., and Willems, G. (2002)
Small Sample Corrections for LTS and MCD,
<em>Metrika</em> <b>55</b>, 111&ndash;123.
</p>
<p>Hubert, M., Rousseeuw, P. J. and Verdonck, T. (2012)
A deterministic algorithm for robust location and scatter.
Journal of Computational and Graphical Statistics <b>21</b>, 618&ndash;637.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+cov.mcd">cov.mcd</a></code> from package <a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a>;
<code><a href="#topic+covOGK">covOGK</a></code> as cheaper alternative for larger dimensions.
</p>
<p><code><a href="robustX.html#topic+BACON">BACON</a></code> and <code><a href="robustX.html#topic+covNNC">covNNC</a></code>,
from package <a href="https://CRAN.R-project.org/package=robustX"><span class="pkg">robustX</span></a>;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hbk)
hbk.x &lt;- data.matrix(hbk[, 1:3])
set.seed(17)
(cH &lt;- covMcd(hbk.x))
cH0 &lt;- covMcd(hbk.x, nsamp = "deterministic")
with(cH0, stopifnot(quan == 39,
     iBest == c(1:4,6), # 5 out of 6 gave the same
     identical(raw.weights, mcd.wt),
     identical(which(mcd.wt == 0), 1:14), all.equal(crit, -1.045500594135)))

## the following three statements are equivalent
c1 &lt;- covMcd(hbk.x, alpha = 0.75)
c2 &lt;- covMcd(hbk.x, control = rrcov.control(alpha = 0.75))
## direct specification overrides control one:
c3 &lt;- covMcd(hbk.x, alpha = 0.75,
             control = rrcov.control(alpha=0.95))
c1

## Martin's smooth reweighting:

## List of experimental pre-specified wgtFUN() creators:
## Cutoffs may depend on  (n, p, control$beta) :
str(.wgtFUN.covMcd)

cMM &lt;- covMcd(hbk.x, wgtFUN = "sm1.adaptive")

ina &lt;- which(names(cH) == "call")
all.equal(cMM[-ina], cH[-ina]) # *some* differences, not huge (same 'best'):
stopifnot(all.equal(cMM[-ina], cH[-ina], tol = 0.2))
</code></pre>

<hr>
<h2 id='covOGK'>Orthogonalized Gnanadesikan-Kettenring (OGK) Covariance Matrix Estimation</h2><span id='topic+covOGK'></span><span id='topic+covGK'></span><span id='topic+s_mad'></span><span id='topic+s_IQR'></span><span id='topic+hard.rejection'></span>

<h3>Description</h3>

<p>Computes the orthogonalized pairwise covariance matrix estimate described in
in Maronna and Zamar (2002).  The pairwise proposal goes back to
Gnanadesikan and Kettenring (1972).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>covOGK(X, n.iter = 2, sigmamu, rcov = covGK, weight.fn = hard.rejection,
       keep.data = FALSE, ...)

covGK (x, y, scalefn = scaleTau2, ...)
s_mad(x, mu.too = FALSE, na.rm = FALSE)
s_IQR(x, mu.too = FALSE, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="covOGK_+3A_x">X</code></td>
<td>
<p>data in something that can be coerced into a numeric matrix.</p>
</td></tr>
<tr><td><code id="covOGK_+3A_n.iter">n.iter</code></td>
<td>
<p>number of orthogonalization iterations.  Usually 1 or 2;
values greater than 2 are unlikely to have any significant effect on
the estimate (other than increasing the computing time).</p>
</td></tr>
<tr><td><code id="covOGK_+3A_sigmamu">sigmamu</code>, <code id="covOGK_+3A_scalefn">scalefn</code></td>
<td>
<p>a function that computes univariate robust
location and scale estimates.  By default it should return a single
numeric value containing the robust scale (standard deviation)
estimate.  When <code>mu.too</code> is true, <code>sigmamu()</code> should
return a numeric vector of length 2 containing robust location and
scale estimates.  See <code><a href="#topic+scaleTau2">scaleTau2</a></code>, <code><a href="#topic+s_Qn">s_Qn</a></code>,
<code><a href="#topic+s_Sn">s_Sn</a></code>, <code>s_mad</code> or <code>s_IQR</code> for examples to be
used as <code>sigmamu</code> argument.</p>
</td></tr>
<tr><td><code id="covOGK_+3A_rcov">rcov</code></td>
<td>
<p>function that computes a robust covariance estimate
between two vectors.  The default, Gnanadesikan-Kettenring's
<code>covGK</code>, is simply <code class="reqn">(s^2(X+Y) - s^2(X-Y))/4</code> where
<code class="reqn">s()</code> is the scale estimate <code>sigmamu()</code>.</p>
</td></tr>
<tr><td><code id="covOGK_+3A_weight.fn">weight.fn</code></td>
<td>
<p>a function of the robust distances and the number of
variables <code class="reqn">p</code> to compute the weights used in the reweighting step.</p>
</td></tr>
<tr><td><code id="covOGK_+3A_keep.data">keep.data</code></td>
<td>
<p>logical indicating if the (untransformed) data matrix
<code>X</code> should be kept as part of the result.</p>
</td></tr>
<tr><td><code id="covOGK_+3A_...">...</code></td>
<td>
<p>additional arguments; for <code>covOGK</code> to be passed to
<code>sigmamu()</code> and <code>weight.fn()</code>; for <code>covGK</code> passed to <code>scalefn</code>.</p>
</td></tr>

<tr><td><code id="covOGK_+3A_x">x</code>, <code id="covOGK_+3A_y">y</code></td>
<td>
<p>numeric vectors of the same length, the covariance of which
is sought in <code>covGK</code> (or the scale, in <code>s_mad</code> or
<code>s_IQR</code>).</p>
</td></tr>

<tr><td><code id="covOGK_+3A_mu.too">mu.too</code></td>
<td>
<p>logical indicating if both location and scale should be
returned or just the scale (when <code>mu.too=FALSE</code> as by default).</p>
</td></tr>
<tr><td><code id="covOGK_+3A_na.rm">na.rm</code></td>
<td>
<p>if <code>TRUE</code> then <code><a href="base.html#topic+NA">NA</a></code> values are stripped
from <code>x</code> before computation takes place.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Typical default values for the <em>function</em> arguments
<code>sigmamu</code>, <code>rcov</code>, and <code>weight.fn</code>, are
available as well, see the <em>Examples</em> below,
<b>but</b> their names and calling sequences are
still subject to discussion and may be changed in the future.
</p>
<p>The current default, <code>weight.fn = hard.rejection</code> corresponds to
the proposition in the litterature, but Martin Maechler strongly
believes that the hard threshold currently in use is too arbitrary,
and further that <em>soft</em> thresholding should be used instead, anyway.
</p>


<h3>Value</h3>

<p><code>covOGK()</code> currently returns a list with components
</p>
<table>
<tr><td><code>center</code></td>
<td>
<p>robust location: numeric vector of length <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>robust covariance matrix estimate: <code class="reqn">p\times p</code>
matrix.</p>
</td></tr>
<tr><td><code>wcenter</code>, <code>wcov</code></td>
<td>
<p>re-<b>w</b>eighted versions of <code>center</code> and
<code>cov</code>.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>the robustness weights used.</p>
</td></tr>
<tr><td><code>distances</code></td>
<td>
<p>the mahalanobis distances computed using
<code>center</code> and <code>cov</code>.</p>
</td></tr>
</table>
<p>......
<br />
<b>but note that this might be radically changed to returning an
S4 classed object!</b>
</p>
<p><code>covGK()</code> is a trivial 1-line function returning the covariance
estimate
</p>
<p style="text-align: center;"><code class="reqn">\hat c(x,y) = \left(\hat \sigma(x+y)^2 - \hat \sigma(x-y)^2 \right)/4,%
        </code>
</p>

<p>where <code class="reqn">\hat \sigma(u)</code> is the scale estimate of <code class="reqn">u</code>
specified by <code>scalefn</code>.
</p>
<p><code>s_mad()</code>, and <code>s_IQR()</code> return the
scale estimates <code><a href="stats.html#topic+mad">mad</a></code> or <code><a href="stats.html#topic+IQR">IQR</a></code>
respectively, where the <code>s_*</code> functions return a length-2 vector
(mu, sig) when <code>mu.too = TRUE</code>, see also <code><a href="#topic+scaleTau2">scaleTau2</a></code>.
</p>


<h3>Author(s)</h3>

<p>Kjell Konis <a href="mailto:konis@stats.ox.ac.uk">konis@stats.ox.ac.uk</a>, with modifications by
Martin Maechler.</p>


<h3>References</h3>

<p>Maronna, R.A. and Zamar, R.H. (2002)
Robust estimates of location and dispersion of high-dimensional datasets;
<em>Technometrics</em> <b>44</b>(4), 307&ndash;317.
</p>
<p>Gnanadesikan, R. and John R. Kettenring (1972)
Robust estimates, residuals, and outlier detection with multiresponse data.
<em>Biometrics</em> <b>28</b>, 81&ndash;124.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scaleTau2">scaleTau2</a></code>,
<code><a href="#topic+covMcd">covMcd</a></code>, <code><a href="MASS.html#topic+cov.rob">cov.rob</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hbk)
hbk.x &lt;- data.matrix(hbk[, 1:3])

cO1 &lt;- covOGK(hbk.x, sigmamu = scaleTau2)
cO2 &lt;- covOGK(hbk.x, sigmamu = s_Qn)
cO3 &lt;- covOGK(hbk.x, sigmamu = s_Sn)
cO4 &lt;- covOGK(hbk.x, sigmamu = s_mad)
cO5 &lt;- covOGK(hbk.x, sigmamu = s_IQR)



data(toxicity)
cO1tox &lt;- covOGK(toxicity, sigmamu = scaleTau2)
cO2tox &lt;- covOGK(toxicity, sigmamu = s_Qn)

## nice formatting of correlation matrices:
as.dist(round(cov2cor(cO1tox$cov), 2))
as.dist(round(cov2cor(cO2tox$cov), 2))

## "graphical"
symnum(cov2cor(cO1tox$cov))
symnum(cov2cor(cO2tox$cov), legend=FALSE)
</code></pre>

<hr>
<h2 id='CrohnD'>Crohn's Disease Adverse Events Data</h2><span id='topic+CrohnD'></span>

<h3>Description</h3>

<p>Data set issued from a study of the adverse events of a drug on
117 patients affected by Crohn's disease (a chronic inflammatory
disease of the intestines).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(CrohnD, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 117 observations on the following 9 variables.
</p>


<dl>
<dt><code>ID</code></dt><dd><p>the numeric patient IDs</p>
</dd>
<dt><code>nrAdvE</code></dt><dd><p>the number of adverse events</p>
</dd>
<dt><code>BMI</code></dt><dd><p>Body MASS Index, i.e., <code class="reqn">weight[kg] / (height[m])^2</code>.</p>
</dd>
<dt><code>height</code></dt><dd><p>in cm</p>
</dd>
<dt><code>country</code></dt><dd><p>a factor with levels <code>0</code> and <code>1</code></p>
</dd>
<dt><code>sex</code></dt><dd><p>the person's gender, a binary factor with levels
<code>M</code> <code>F</code></p>
</dd>
<dt><code>age</code></dt><dd><p>in years, a numeric vector</p>
</dd>
<dt><code>weight</code></dt><dd><p>in kilograms, a numeric vector</p>
</dd>
<dt><code>treat</code></dt><dd><p>how CD was treated: a factor with levels
<code>0</code>, <code>1</code> and <code>2</code>, meaning placebo, drug 1 and drug 2.</p>
</dd>
</dl>



<h3>Source</h3>

<p>form the authors of the reference, with permission by the original
data collecting agency.
</p>


<h3>References</h3>

<p>Serigne N. LÃ´ and Elvezio Ronchetti (2006).
Robust Second Order Accurate Inference for Generalized Linear Models.
Technical report, University of Geneva, Switzerland.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(CrohnD)
str(CrohnD)
with(CrohnD, ftable(table(sex,country, treat)))
</code></pre>

<hr>
<h2 id='cushny'>Cushny and Peebles Prolongation of Sleep Data</h2><span id='topic+cushny'></span>

<h3>Description</h3>

<p>The original data set was bivariate and recorded for ten subjects the
prolongation of sleep caused by two different drugs.  These data were
used by Student as the first illustration of the paired t-test which
only needs the <em>differences</em> of the two measurements.  These
differences are the values of <code>cushny</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(cushny, package="robustbase")</code></pre>


<h3>Format</h3>

<p>numeric vector, sorted increasingly:<br />
0 0.8 1 1.2 1.3 1.3 1.4 1.8 2.4 4.6
</p>


<h3>Source</h3>

<p>Cushny, A.R. and Peebles, A.R. (1905)
The action of optical isomers. II. Hyoscines.
<em>J. Physiol.</em> <b>32</b>, 501&ndash;510.
</p>
<p>These data were used by Student(1908) as the first illustration of the
paired t-test, see also <code><a href="datasets.html#topic+sleep">sleep</a></code>; then cited by
Fisher (1925) and thereforth copied in numerous books as an example of
a normally distributed sample, see, e.g., Anderson (1958).
</p>


<h3>References</h3>

<p>Student (1908)
The probable error of a mean.
<em>Biometrika</em> <b>6</b>, 1&ndash;25.
</p>
<p>Fisher, R.A. (1925)
<em>Statistical Methods for Research Workers</em>;
Oliver &amp; Boyd, Edinburgh.
</p>
<p>Anderson, T.W. (1958)
<em>An Introduction to Multivariate Statistical Analysis</em>;
Wiley, N.Y.
</p>
<p>Hampel, F., Ronchetti, E., Rousseeuw, P. and Stahel, W.  (1986)
<em>Robust Statistics: The Approach Based on Influence Functions</em>;
Wiley, N.Y.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(cushny)

plot(cushny,  rep(0, 10), pch = 3, cex = 3,
     ylab = "", yaxt = "n")
plot(jitter(cushny),  rep(0, 10), pch = 3, cex = 2,
     main = "'cushny' data (n= 10)", ylab = "", yaxt = "n")
abline(h=0, col="gray", lty=3)
myPt &lt;- function(m, lwd = 2, ..., e = 1.5*par("cxy")[2])
  segments(m, +e, m, -e, lwd = lwd, ...)
myPt(  mean(cushny), col = "pink3")
myPt(median(cushny), col = "light blue")
legend("topright", c("mean", "median"), lwd = 2,
       col = c("pink3", "light blue"), inset = .01)

## The 'sleep' data from the standard 'datasets' package:
d.sleep &lt;- local({ gr &lt;- with(datasets::sleep, split(extra, group))
                   gr[[2]] - gr[[1]] })
stopifnot(all.equal(cushny,
                    sort(d.sleep), tolerance=1e-15))
</code></pre>

<hr>
<h2 id='delivery'>Delivery Time Data</h2><span id='topic+delivery'></span>

<h3>Description</h3>

<p>Delivery Time Data, from Montgomery and Peck (1982).
The aim is to explain the time required to service a vending
machine (Y) by means of the number of products stocked (X1) and the
distance walked by the route driver (X2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(delivery, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 3 variables.
</p>

<dl>
<dt><code>n.prod</code></dt><dd><p>Number of Products</p>
</dd>
<dt><code>distance</code></dt><dd><p>Distance</p>
</dd>
<dt><code>delTime</code></dt><dd><p>Delivery time</p>
</dd>
</dl>



<h3>Source</h3>

<p>Montgomery and Peck (1982, p.116)
</p>


<h3>References</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, page 155, table 23.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(delivery)
summary(lm.deli &lt;- lm(delTime ~ ., data = delivery))

delivery.x &lt;- as.matrix(delivery[, 1:2])
c_deli &lt;- covMcd(delivery.x)
c_deli
</code></pre>

<hr>
<h2 id='education'>Education Expenditure Data</h2><span id='topic+education'></span>

<h3>Description</h3>

<p>Education Expenditure Data, from Chatterjee and Price (1977,
p.108).  This data set, representing the education expenditure
variables in the 50 US states, providing an interesting example of
heteroscedacity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(education, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 50 observations on the following 6 variables.
</p>

<dl>
<dt><code>State</code></dt><dd><p>State</p>
</dd>
<dt><code>Region</code></dt><dd><p>Region (1=Northeastern, 2=North central, 3=Southern, 4=Western)</p>
</dd>
<dt><code>X1</code></dt><dd><p>Number of residents per thousand residing in urban areas in 1970</p>
</dd>
<dt><code>X2</code></dt><dd><p>Per capita personal income in 1973</p>
</dd>
<dt><code>X3</code></dt><dd><p>Number of residents per thousand under 18 years of age in 1974</p>
</dd>
<dt><code>Y</code></dt><dd><p>Per capita expenditure on public education in a
state, projected for 1975</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, p.110, table 16.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(education)
education.x &lt;- data.matrix(education[, 3:5])


summary(lm.education &lt;- lm(Y ~ Region + X1+X2+X3, data=education))


## See  example(lmrob.M.S) # for how robust regression is used
</code></pre>

<hr>
<h2 id='epilepsy'>Epilepsy Attacks Data Set</h2><span id='topic+epilepsy'></span>

<h3>Description</h3>

<p>Data from a clinical trial of 59 patients with epilepsy
(Breslow, 1996) in order to illustrate diagnostic techniques in
Poisson regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(epilepsy, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 59 observations on the following 11 variables.
</p>

<dl>
<dt><code>ID</code></dt><dd><p>Patient identification number</p>
</dd>
<dt><code>Y1</code></dt><dd><p>Number of epilepsy attacks patients have during the
first follow-up period</p>
</dd>
<dt><code>Y2</code></dt><dd><p>Number of epilepsy attacks patients have during the
second follow-up period</p>
</dd>
<dt><code>Y3</code></dt><dd><p>Number of epilepsy attacks patients have during the
third follow-up period</p>
</dd>
<dt><code>Y4</code></dt><dd><p>Number of epilepsy attacks patients have during the
forth follow-up period</p>
</dd>
<dt><code>Base</code></dt><dd><p>Number of epileptic attacks
recorded during 8 week period prior to randomization</p>
</dd>
<dt><code>Age</code></dt><dd><p>Age of the patients</p>
</dd>
<dt><code>Trt</code></dt><dd><p>a factor with levels <code>placebo</code>
<code>progabide</code> indicating whether the anti-epilepsy
drug Progabide has been applied or not</p>
</dd>
<dt><code>Ysum</code></dt><dd><p>Total number of epilepsy attacks patients have
during the four follow-up periods  </p>
</dd>
<dt><code>Age10</code></dt><dd><p>Age of the patients devided by 10</p>
</dd>
<dt><code>Base4</code></dt><dd><p>Variable <code>Base</code> devided by 4</p>
</dd>
</dl>



<h3>Details</h3>

<p>Thall and Vail reported data from  a clinical trial of 59 patients
with epilepsy, 31 of whom were randomized to receive the anti-epilepsy
drug Progabide and 28 of whom received a placebo. Baseline data
consisted of the patient's age and the number of epileptic seizures
recorded during 8 week period prior to randomization. The response
consisted of counts of seizures occuring during the four consecutive
follow-up periods of two weeks each.
</p>


<h3>Source</h3>

<p>Thall, P.F. and Vail S.C. (1990)
Some covariance models for longitudinal count data with overdispersion.
<em>Biometrics</em> <b>46</b>, 657&ndash;671.
</p>


<h3>References</h3>

<p>Diggle, P.J., Liang, K.Y., and Zeger, S.L. (1994)
<em>Analysis of Longitudinal Data</em>; Clarendon Press.
</p>
<p>Breslow N. E. (1996)
Generalized linear models: Checking assumptions and strengthening
conclusions.
<em>Statistica Applicata</em> <b>8</b>, 23&ndash;41.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(epilepsy)
str(epilepsy)
pairs(epilepsy[,c("Ysum","Base4","Trt","Age10")])

Efit1 &lt;- glm(Ysum ~ Age10 + Base4*Trt, family=poisson, data=epilepsy)
summary(Efit1)

## Robust Fit :
Efit2 &lt;- glmrob(Ysum ~ Age10 + Base4*Trt, family=poisson, data=epilepsy,
                method = "Mqle",
                tcc=1.2, maxit=100)
summary(Efit2)
</code></pre>

<hr>
<h2 id='estimethod'>Extract the Estimation Method 'Estimethod' from a Fitted Model</h2><span id='topic+estimethod'></span>

<h3>Description</h3>

<p>Extract the estimation method as a <code><a href="base.html#topic+character">character</a></code> string from a fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  estimethod(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estimethod_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>
<tr><td><code id="estimethod_+3A_...">...</code></td>
<td>
<p>additional, optional arguments.  (None are
used in our methods)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a (S3) generic function for which we provide methods,
currently for <code><a href="#topic+nlrob">nlrob</a></code> only.



</p>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+character">character</a></code> string, the estimation method used.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nlrob">nlrob</a></code>, and <code><a href="#topic+nlrob.MM">nlrob.MM</a></code>, notably for examples.
</p>

<hr>
<h2 id='exAM'>Example Data of Antille and May - for Simple Regression</h2><span id='topic+exAM'></span>

<h3>Description</h3>

<p>This is an artificial data set, cleverly construced and used by
Antille and May to demonstrate &lsquo;problems&rsquo; with LMS and LTS.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(exAM, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 12 observations on 2 variables, <code>x</code> and <code>y</code>.
</p>


<h3>Details</h3>

<p>Because the points are not in general position, both LMS and LTS
typically <em>fail</em>; however, e.g., <code><a href="MASS.html#topic+rlm">rlm</a>(*,
    method="MM")</code> &ldquo;works&rdquo;.
</p>


<h3>Source</h3>

<p>Antille, G. and El May, H. (1992)
The use of slices in the LMS and the method of density slices:
Foundation and comparison.<br />
In Yadolah Dodge and Joe Whittaker, editors, <em>COMPSTAT:
Proc. 10th Symp. Computat. Statist., Neuchatel</em>, <b>1</b>, 441&ndash;445;
Physica-Verlag.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(exAM)
plot(exAM)
summary(ls &lt;- lm(y ~ x, data=exAM))
abline(ls)
</code></pre>

<hr>
<h2 id='foodstamp'>Food Stamp Program Participation</h2><span id='topic+foodstamp'></span>

<h3>Description</h3>

<p>This data consists of 150 randomly selected persons from a survey
with information on over 2000 elderly US citizens, where the response,
indicates participation in the U.S. Food Stamp Program.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(foodstamp, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 150 observations on the following 4 variables.
</p>

<dl>
<dt><code>participation</code></dt><dd><p>participation in U.S. Food Stamp Program; yes = 1, no = 0</p>
</dd>
<dt><code>tenancy</code></dt><dd><p>tenancy, indicating home ownership; yes = 1, no = 0</p>
</dd>
<dt><code>suppl.income</code></dt><dd><p>supplemental income, indicating whether
some form of supplemental security income is received; yes = 1, no = 0</p>
</dd>
<dt><code>income</code></dt><dd><p>monthly income (in US dollars)</p>
</dd>
</dl>



<h3>Source</h3>

<p>Data description and first analysis: Stefanski et al.(1986) who
indicate Rizek(1978) as original source of the larger study.
</p>
<p>Electronic version from CRAN package <a href="https://CRAN.R-project.org/package=catdata"><span class="pkg">catdata</span></a>.

</p>


<h3>References</h3>

<p>Rizek, R. L. (1978)
The 1977-78 Nationwide Food Consumption Survey.
<em>Family Econ. Rev.</em>, Fall, 3&ndash;7.
</p>

<p>Stefanski, L. A., Carroll, R. J. and Ruppert, D. (1986)
Optimally bounded score functions for generalized linear models with
applications to logistic regression.
<em>Biometrika</em> <b>73</b>, 413&ndash;424.
</p>
<p>KÃ¼nsch, H. R., Stefanski, L. A., Carroll, R. J. (1989)
Conditionally unbiased bounded-influence estimation in general
regression models, with applications to generalized linear models.
<em>J. American Statistical Association</em> <b>84</b>, 460&ndash;466.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(foodstamp)

(T123 &lt;- xtabs(~ participation+ tenancy+ suppl.income, data=foodstamp))
summary(T123) ## ==&gt; the binary var's are clearly not independent

foodSt &lt;- within(foodstamp, {
   logInc &lt;- log(1 + income)
   rm(income)
})

m1 &lt;- glm(participation ~ ., family=binomial, data=foodSt)
summary(m1)
rm1 &lt;- glmrob(participation ~ ., family=binomial, data=foodSt)
summary(rm1)
## Now use robust weights.on.x :
rm2 &lt;- glmrob(participation ~ ., family=binomial, data=foodSt,
              weights.on.x = "robCov")
summary(rm2)## aha, now the weights are different:
which( weights(rm2, type="robust") &lt; 0.5)
</code></pre>

<hr>
<h2 id='fullRank'>Remove Columns (or Rows) From a Matrix to Make It Full Rank</h2><span id='topic+fullRank'></span>

<h3>Description</h3>

<p>From the QR decomposition with pivoting, (<code><a href="Matrix.html#topic+qr">qr</a>(x, tol)</code> if
<code class="reqn">n \ge p</code>), if
the matrix is not of full rank, the corresponding columns (<code class="reqn">n \ge
    p</code>) or rows (<code class="reqn">n &lt; p</code>) are omitted to form a full rank matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
fullRank(x, tol = 1e-7, qrx = qr(x, tol=tol))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fullRank_+3A_x">x</code></td>
<td>
<p>a numeric matrix of dimension <code class="reqn">n \times p</code>, or a
similar object for which <code><a href="Matrix.html#topic+qr">qr</a>()</code> works.</p>
</td></tr>
<tr><td><code id="fullRank_+3A_tol">tol</code></td>
<td>
<p>tolerance for determining rank (deficiency).  Currently is
simply passed to <code><a href="Matrix.html#topic+qr">qr</a></code>.</p>
</td></tr>
<tr><td><code id="fullRank_+3A_qrx">qrx</code></td>
<td>
<p>optionally may be used to pass a <code><a href="Matrix.html#topic+qr">qr</a>(x, ..)</code>;
only used when <code>p &lt;= n</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a version of the matrix <code>x</code>, with less columns or rows if
<code>x</code>'s rank was smaller than <code>min(n,p)</code>.
</p>
<p>If <code>x</code> is of full rank, it is returned unchanged.
</p>


<h3>Note</h3>

<p>This is useful for robustness algorithms that rely on <code class="reqn">X</code> matrices
of full rank, e.g., <code><a href="#topic+adjOutlyingness">adjOutlyingness</a></code>.
</p>
<p>This also works for numeric data frames and whenever <code>qr()</code> works correctly.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="Matrix.html#topic+qr">qr</a></code>; for more sophisticated rank determination,
<code><a href="Matrix.html#topic+rankMatrix">rankMatrix</a></code> from package <a href="https://CRAN.R-project.org/package=Matrix"><span class="pkg">Matrix</span></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>stopifnot(identical(fullRank(wood), wood))

## More sophisticated and delicate
dim(T &lt;- tcrossprod(data.matrix(toxicity))) # 38 x 38
dim(T. &lt;- fullRank(T)) # 38 x 10
if(requireNamespace("Matrix")) {
  rMmeths &lt;- eval(formals(Matrix::rankMatrix)$method)
  rT. &lt;- sapply(rMmeths, function(.m.) Matrix::rankMatrix(T., method = .m.))
  print(rT.) # "qr" (= "qrLinpack"): 13,  others rather 10
}
dim(T.2 &lt;- fullRank(T, tol = 1e-15))# 38 x 18
dim(T.3 &lt;- fullRank(T, tol = 1e-12))# 38 x 13
dim(T.3 &lt;- fullRank(T, tol = 1e-10))# 38 x 13
dim(T.3 &lt;- fullRank(T, tol = 1e-8 ))# 38 x 12
dim(T.) # default from above          38 x 10
dim(T.3 &lt;- fullRank(T, tol = 1e-5 ))# 38 x 10 -- still

plot(svd(T, 0,0)$d, log="y", main = "singular values of T", yaxt="n")
axis(2, at=10^(-14:5), las=1)
## pretty clearly indicates that  rank 10  is "correct" here.
</code></pre>

<hr>
<h2 id='functionX-class'>Class &quot;functionX&quot; of Psi-like Vectorized Functions</h2><span id='topic+functionX-class'></span>

<h3>Description</h3>

<p>The class <code>"functionX"</code> of vectorized functions of one argument
<code>x</code> and typically further tuning parameters.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("functionX", ...)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>.Data</code>:</dt><dd><p>Directly extends class <code>"function"</code>.</p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"function"</code>, from data part.
Class <code>"OptionalFunction"</code>, by class <code>"function"</code>.
Class <code>"PossibleMethod"</code>, by class <code>"function"</code>.
</p>


<h3>Methods</h3>

<p>No methods defined with class &quot;functionX&quot; in the signature.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+psiFunc">psiFunc</a>()</code>, and class descriptions of
<code><a href="#topic+functionXal-class">functionXal</a></code> for <em>functionals</em> of
<code>"functionX"</code>, and <code><a href="#topic+psi_func-class">psi_func</a></code> which has
several <code>functionX</code> slots.
</p>

<hr>
<h2 id='functionXal-class'>Class &quot;functionXal&quot; of Functionals (of Psi-like functions)</h2><span id='topic+functionXal-class'></span>

<h3>Description</h3>

<p>The class <code>"functionXal"</code> is a class of functionals (typically
integrals) typically of <code><a href="#topic+functionX-class">functionX</a></code> functions.
</p>
<p>Since the <code>functionX</code> functions typically also depend on tuning
parameters, objects of this class (<code>"functionXal"</code>) are functions
of these tuning parameters.
</p>


<h3>Slots</h3>


<dl>
<dt><code>.Data</code>:</dt><dd><p>Directly extends class <code>"function"</code>.</p>
</dd>
</dl>



<h3>Extends</h3>

<p>Class <code>"function"</code>, from data part.
Class <code>"OptionalFunction"</code>, by class <code>"function"</code>.
Class <code>"PossibleMethod"</code>, by class <code>"function"</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psiFunc">psiFunc</a>()</code> and the class definitions of
<code><a href="#topic+functionX-class">functionX</a></code> and
<code><a href="#topic+psi_func-class">psi_func</a></code> which has several <code>functionXal</code>
slots.
</p>

<hr>
<h2 id='glmrob'>Robust Fitting of Generalized Linear Models</h2><span id='topic+glmrob'></span>

<h3>Description</h3>

<p><code>glmrob</code> is used to fit generalized linear models by robust
methods.  The models are specified by giving a symbolic description of
the linear predictor and a description of the error distribution.
Currently, robust methods are implemented for <code><a href="stats.html#topic+family">family</a> =
  binomial</code>,  <code> = poisson</code>, <code> = Gamma</code> and <code> = gaussian</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmrob(formula, family, data, weights, subset, na.action,
       start = NULL, offset, method = c("Mqle", "BY", "WBY", "MT"),
       weights.on.x = c("none", "hat", "robCov", "covMcd"), control = NULL,
       model = TRUE, x = FALSE, y = TRUE, contrasts = NULL, trace.lev = 0, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmrob_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code>, i.e., a symbolic description
of the model to be fit (cf. <code><a href="stats.html#topic+glm">glm</a></code> or <code><a href="stats.html#topic+lm">lm</a></code>).</p>
</td></tr>
<tr><td><code id="glmrob_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model.  This can be a character string naming a
family function, a family <code><a href="base.html#topic+function">function</a></code> or the result of a
call to a family function.  (See <code><a href="stats.html#topic+family">family</a></code> for details of
family functions.)</p>
</td></tr>
<tr><td><code id="glmrob_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables
in the model.  If not found in <code>data</code>, the variables are taken
from <code>environment(formula)</code>, typically the environment from
which <code>glmrob</code> is called.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is set by
the <code>na.action</code> setting in <code><a href="base.html#topic+options">options</a></code>. The
&ldquo;factory-fresh&rdquo; default is <code><a href="stats.html#topic+na.omit">na.omit</a></code>.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_start">start</code></td>
<td>
<p>starting values for the parameters in the linear
predictor.  Note that specifying <code>start</code> has somewhat different
meaning for the different <code>method</code>s.  Notably, for <code>"MT"</code>,
this skips the expensive computation of initial estimates via sub
samples, but needs to be <em>robust</em> itself.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an <em>a priori</em>
known component to be included in the linear predictor
during fitting.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_method">method</code></td>
<td>
<p>a character string specifying the robust fitting
method.  The details of method specification are given below.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_weights.on.x">weights.on.x</code></td>
<td>

<p>a character string (can be abbreviated), a <code><a href="base.html#topic+function">function</a></code> or
<code><a href="base.html#topic+list">list</a></code> (see below), or a numeric vector of length
<code>n</code>, specifying how points (potential outliers) in x-space are
downweighted.  If <code>"hat"</code>,
weights on the design of the form <code class="reqn">\sqrt{1-h_{ii}}</code> are used,
where <code class="reqn">h_{ii}</code> are the diagonal elements of the hat matrix.  If
<code>"robCov"</code>, weights based on the robust Mahalanobis distance of the
design matrix (intercept excluded) are used where the covariance
matrix and the centre is estimated by <code><a href="MASS.html#topic+cov.rob">cov.rob</a></code>
from the package <a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a>.<br />
Similarly,  if <code>"covMcd"</code>, robust weights are computed using
<code><a href="#topic+covMcd">covMcd</a></code>.  The default is <code>"none"</code>.
</p>
<p>If <code>weights.on.x</code> is a <code><a href="base.html#topic+function">function</a></code>, it is called
with arguments <code>(X, intercept)</code> and must return an n-vector of
non-negative weights.
</p>
<p>If it is a <code><a href="base.html#topic+list">list</a></code>, it must be of length one, and as
element contain a function much like <code><a href="#topic+covMcd">covMcd</a>()</code> or
<code><a href="MASS.html#topic+cov.rob">cov.rob</a>()</code> (package <a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a>), which computes
multivariate location and &ldquo;scatter&rdquo; of a data matrix <code>X</code>.
</p>
</td></tr>
<tr><td><code id="glmrob_+3A_control">control</code></td>
<td>
<p>a list of parameters for controlling the fitting process.
See the documentation for <code><a href="#topic+glmrobMqle.control">glmrobMqle.control</a></code> for
details.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_model">model</code></td>
<td>
<p>a logical value indicating whether <em>model frame</em>
should be included as a component of the returned value.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_x">x</code>, <code id="glmrob_+3A_y">y</code></td>
<td>
<p>logical values indicating whether the response
vector and model matrix used in the fitting process should be
returned as components of the returned value.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list. See the <code>contrasts.arg</code>
of <code>model.matrix.default</code>.</p>
</td></tr>
<tr><td><code id="glmrob_+3A_trace.lev">trace.lev</code></td>
<td>
<p>logical (or integer) indicating if intermediate results
should be printed; defaults to <code>0</code> (the same as <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="glmrob_+3A_...">...</code></td>
<td>
<p>arguments passed to <code><a href="#topic+glmrobMqle.control">glmrobMqle.control</a></code> when
<code>control</code> is <code>NULL</code> (as per default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>method="model.frame"</code> returns the <code><a href="stats.html#topic+model.frame">model.frame</a>()</code>,
the same as <code><a href="stats.html#topic+glm">glm</a>()</code>.
<br />
<code>method="Mqle"</code> fits a generalized linear
model using Mallows or Huber type robust estimators, as described in
Cantoni and Ronchetti (2001) and Cantoni and Ronchetti (2006).  In
contrast to the implementation
described in Cantoni (2004), the pure influence algorithm is
implemented.
<br />
<code>method="WBY"</code> and <code>method="BY"</code>,
available for logistic regression (<code>family = binomial</code>) only, call
<code><a href="#topic+BYlogreg">BYlogreg</a>(*, initwml= . )</code> for the (weighted) Bianco-Yohai
estimator, where <code>initwml</code> is true for <code>"WBY"</code>, and false
for <code>"BY"</code>.
<br />
<code>method="MT"</code>, currently only implemented for <code>family = poisson</code>,
computes an &ldquo;[M]-Estimator based on [T]ransformation&rdquo;, 
by Valdora and Yohai (2013), via (hidden internal) <code>glmrobMT()</code>; as
that uses <code><a href="base.html#topic+sample">sample</a>()</code>, from <span class="rlang"><b>R</b></span> version 3.6.0 it depends on
<code><a href="base.html#topic+RNGkind">RNGkind</a>(*, sample.kind)</code>.  Exact reproducibility of results
from <span class="rlang"><b>R</b></span> versions 3.5.3 and earlier, requires setting
<code><a href="base.html#topic+RNGversion">RNGversion</a>("3.5.0")</code>.
</p>
<p><code>weights.on.x= "robCov"</code> makes sense if all explanatory variables
are continuous.
</p>
<p>In the cases,where <code>weights.on.x</code> is <code>"covMcd"</code> or
<code>"robCov"</code>, or list with a &ldquo;robCov&rdquo; function, the
mahalanobis distances <code>D^2</code> are computed with respect to the
covariance (location and scatter) estimate, and the weights are
<code>1/sqrt(1+ pmax.int(0, 8*(D2 - p)/sqrt(2*p)))</code>,
where <code>D2 = D^2</code> and <code>p = ncol(X)</code>.
</p>


<h3>Value</h3>

<p><code>glmrob</code> returns an object of class <code>"glmrob"</code> and is also
inheriting from <code><a href="stats.html#topic+glm">glm</a></code>.
<br />
The <code><a href="base.html#topic+summary">summary</a></code> method, see <code><a href="#topic+summary.glmrob">summary.glmrob</a></code>, can
be used to obtain or print a summary of the results.
<br />
The generic accessor functions <code><a href="stats.html#topic+coefficients">coefficients</a></code>,
<code>effects</code>, <code>fitted.values</code> and <code>residuals</code> (see
<code><a href="#topic+residuals.glmrob">residuals.glmrob</a></code>) can be used to extract various useful
features of the value returned by <code>glmrob()</code>.
</p>
<p>An object of class <code>"glmrob"</code> is a list with at least the
following components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>a named vector of coefficients</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the <em>working</em> residuals, that is the (robustly
&ldquo;huberized&rdquo;) residuals in the final iteration of the IWLS fit.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted mean values, obtained by transforming
the linear predictors by the inverse of the link function.</p>
</td></tr>
<tr><td><code>w.r</code></td>
<td>
<p>robustness weights for each observations; i.e.,
<code>residuals</code> <code class="reqn">\times</code> <code>w.r</code> equals the psi-function of the
Preason's residuals.</p>
</td></tr>
<tr><td><code>w.x</code></td>
<td>
<p>weights used to down-weight observations based on the
position of the observation in the design space.</p>
</td></tr>
<tr><td><code>dispersion</code></td>
<td>
<p>robust estimation of dispersion paramter if appropriate</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>the estimated asymptotic covariance matrix of the estimated
coefficients.</p>
</td></tr>
<tr><td><code>tcc</code></td>
<td>
<p>the tuning constant c in Huber's psi-function.</p>
</td></tr>
<tr><td><code>family</code></td>
<td>
<p>the <code><a href="stats.html#topic+family">family</a></code> object used.</p>
</td></tr>
<tr><td><code>linear.predictors</code></td>
<td>
<p>the linear fit on link scale.</p>
</td></tr>
<tr><td><code>deviance</code></td>
<td>
<p>NULL; Exists because of compatipility reasons.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>the number of iterations used by the influence algorithm.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>logical. Was the IWLS algorithm judged to have converged?</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>the formula supplied.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the <code><a href="stats.html#topic+terms">terms</a></code> object used.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>the <code>data argument</code>.</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>the offset vector used.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>the value of the <code>control</code> argument used.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>the name of the robust fitter function used.</p>
</td></tr>
<tr><td><code>contrasts</code></td>
<td>
<p>(where relevant) the contrasts used.</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>(where relevant) a record of the levels of the factors
used in fitting.</p>
</td></tr>






</table>


<h3>Author(s)</h3>

<p>Andreas Ruckstuhl (&quot;Mqle&quot;) and Martin Maechler</p>


<h3>References</h3>

<p>Eva Cantoni and Elvezio Ronchetti (2001)
Robust Inference for Generalized Linear Models.
<em>JASA</em> <b>96</b> (455), 1022&ndash;1030.
</p>
<p>Eva Cantoni (2004)
Analysis of Robust Quasi-deviances for Generalized Linear Models.
<em>Journal of Statistical Software</em>, <b>10</b>,
<a href="https://www.jstatsoft.org/article/view/v010i04">https://www.jstatsoft.org/article/view/v010i04</a>
Eva Cantoni and Elvezio Ronchetti (2006)
A robust approach for skewed and heavy-tailed outcomes in the analysis
of health care expenditures.
<em>Journal of Health Economics</em> <b>25</b>, 198&ndash;213.
</p>
<p>S. Heritier, E. Cantoni, S. Copt, M.-P. Victoria-Feser (2009)
<em>Robust Methods in Biostatistics</em>. Wiley Series in Probability
and Statistics.
</p>
<p>Marina Valdora and VÃ­ctor J. Yohai (2013)
Robust estimators for Generalized Linear Models.  In progress.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.glmrob">predict.glmrob</a></code> for prediction;
<code><a href="#topic+glmrobMqle.control">glmrobMqle.control</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Binomial response --------------
data(carrots)

Cfit1 &lt;- glm(cbind(success, total-success) ~ logdose + block,
             data = carrots, family = binomial)
summary(Cfit1)

Rfit1 &lt;- glmrob(cbind(success, total-success) ~ logdose + block,
                family = binomial, data = carrots, method= "Mqle",
                control= glmrobMqle.control(tcc=1.2))
summary(Rfit1)

Rfit2 &lt;- glmrob(success/total ~ logdose + block, weights = total,
                family = binomial, data = carrots, method= "Mqle",
                control= glmrobMqle.control(tcc=1.2))
coef(Rfit2)  ## The same as Rfit1


## Binary response --------------
data(vaso)

Vfit1 &lt;- glm(Y ~ log(Volume) + log(Rate), family=binomial, data=vaso)
coef(Vfit1)

Vfit2 &lt;- glmrob(Y ~ log(Volume) + log(Rate), family=binomial, data=vaso,
                method="Mqle", control = glmrobMqle.control(tcc=3.5))
coef(Vfit2) # c = 3.5 ==&gt; not much different from classical
## Note the problems with  tcc &lt;= 3 %% FIXME algorithm ???

Vfit3 &lt;- glmrob(Y ~ log(Volume) + log(Rate), family=binomial, data=vaso,
                method= "BY")
coef(Vfit3)## note that results differ much.
## That's not unreasonable however, see Kuensch et al.(1989), p.465

## Poisson response --------------
data(epilepsy)

Efit1 &lt;- glm(Ysum ~ Age10 + Base4*Trt, family=poisson, data=epilepsy)
summary(Efit1)

Efit2 &lt;- glmrob(Ysum ~ Age10 + Base4*Trt, family = poisson,
                data = epilepsy, method= "Mqle",
                control = glmrobMqle.control(tcc= 1.2))
summary(Efit2)

## 'x' weighting:
(Efit3 &lt;- glmrob(Ysum ~ Age10 + Base4*Trt, family = poisson,
 	         data = epilepsy, method= "Mqle", weights.on.x = "hat",
		 control = glmrobMqle.control(tcc= 1.2)))

try( # gives singular cov matrix: 'Trt' is binary factor --&gt;
     # affine equivariance and subsampling are problematic
Efit4 &lt;- glmrob(Ysum ~ Age10 + Base4*Trt, family = poisson,
                data = epilepsy, method= "Mqle", weights.on.x = "covMcd",
                control = glmrobMqle.control(tcc=1.2, maxit=100))
)

##--&gt; See  example(possumDiv)  for another  Poisson-regression


### -------- Gamma family -- data from example(glm) ---

clotting &lt;- data.frame(
            u = c(5,10,15,20,30,40,60,80,100),
         lot1 = c(118,58,42,35,27,25,21,19,18),
         lot2 = c(69,35,26,21,18,16,13,12,12))
summary(cl &lt;- glm   (lot1 ~ log(u), data=clotting, family=Gamma))
summary(ro &lt;- glmrob(lot1 ~ log(u), data=clotting, family=Gamma))

clotM5.high &lt;- within(clotting, { lot1[5] &lt;- 60 })
op &lt;- par(mfrow=2:1, mgp = c(1.6, 0.8, 0), mar = c(3,3:1))
plot( lot1  ~ log(u), data=clotM5.high)
plot(1/lot1 ~ log(u), data=clotM5.high)
par(op)
## Obviously, there the first observation is an outlier with respect to both
## representations!

cl5.high &lt;- glm   (lot1 ~ log(u), data=clotM5.high, family=Gamma)
ro5.high &lt;- glmrob(lot1 ~ log(u), data=clotM5.high, family=Gamma)
with(ro5.high, cbind(w.x, w.r))## the 5th obs. is downweighted heavily!

plot(1/lot1 ~ log(u), data=clotM5.high)
abline(cl5.high, lty=2, col="red")
abline(ro5.high, lwd=2, col="blue") ## result is ok (but not "perfect")



















</code></pre>

<hr>
<h2 id='glmrob..control'>Controlling Robust GLM Fitting by Different Methods</h2><span id='topic+glmrobMqle.control'></span><span id='topic+glmrobMT.control'></span><span id='topic+glmrobBY.control'></span>

<h3>Description</h3>

<p>These are auxiliary functions as user interface for <code><a href="#topic+glmrob">glmrob</a></code> fitting
when the different methods, <code>"Mqle"</code>, <code>"BY"</code>, or
<code>"MT"</code> are used.  Typically only used when calling <code><a href="#topic+glmrob">glmrob</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glmrobMqle.control(acc = 1e-04, test.acc = "coef", maxit = 50, tcc = 1.345)
glmrobBY.control  (maxit = 1000, const = 0.5, maxhalf = 10)
glmrobMT.control  (cw = 2.1, nsubm = 500, acc = 1e-06, maxit = 200)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="glmrob..control_+3A_acc">acc</code></td>
<td>
<p>positive convergence tolerance;
the iterations converge when ???</p>
</td></tr>
<tr><td><code id="glmrob..control_+3A_test.acc">test.acc</code></td>
<td>
<p>Only &quot;coef&quot; is currently implemented</p>
</td></tr>
<tr><td><code id="glmrob..control_+3A_maxit">maxit</code></td>
<td>
<p>integer giving the maximum number of iterations. </p>
</td></tr>
<tr><td><code id="glmrob..control_+3A_tcc">tcc</code></td>
<td>
<p>tuning constant c for Huber's psi-function</p>
</td></tr>
<tr><td><code id="glmrob..control_+3A_const">const</code></td>
<td>
<p>for &quot;BY&quot;, the normalizing constant ..</p>
</td></tr>
<tr><td><code id="glmrob..control_+3A_maxhalf">maxhalf</code></td>
<td>
<p>for &quot;BY&quot;; the number of halving steps when the gradient
itself no longer improves.  We have seen examples when increasing
<code>maxhalf</code> was of relevance.</p>
</td></tr>
<tr><td><code id="glmrob..control_+3A_cw">cw</code></td>
<td>
<p>tuning constant c for Tukey's biweight psi-function</p>
</td></tr>
<tr><td><code id="glmrob..control_+3A_nsubm">nsubm</code></td>
<td>
<p>the number of subsamples to take for finding an initial
estimate for <code>method = "MT"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="base.html#topic+list">list</a></code> with the arguments as components.
</p>


<h3>Author(s)</h3>

<p>Andreas Ruckstuhl and Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmrob">glmrob</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>str(glmrobMqle.control())
str(glmrobBY.control())
str(glmrobMT.control())
</code></pre>

<hr>
<h2 id='h.alpha.n'>Compute h, the subsample size for MCD and LTS</h2><span id='topic+h.alpha.n'></span>

<h3>Description</h3>

<p>Compute h(alpha) which is the size of the subsamples to be used
for MCD and LTS.  Given <code class="reqn">\alpha = alpha</code>, <code class="reqn">n</code> and
<code class="reqn">p</code>, <code class="reqn">h</code> is an <em>integer</em>, <code class="reqn">h \approx \alpha n</code>, where the exact formula also depends on <code class="reqn">p</code>.
</p>
<p>For <code class="reqn">\alpha = 1/2</code>, <code>h == floor(n+p+1)/2</code>; for the general
case, it's simply
<code>n2 &lt;- (n+p+1) %/% 2; floor(2*n2 - n + 2*(n-n2)*alpha)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h.alpha.n(alpha, n, p)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="h.alpha.n_+3A_alpha">alpha</code></td>
<td>
<p>fraction, numeric (vector) in [0.5, 1], see, e.g.,
<code><a href="#topic+covMcd">covMcd</a></code>.</p>
</td></tr>
<tr><td><code id="h.alpha.n_+3A_n">n</code></td>
<td>
<p>integer (valued vector), the sample size.</p>
</td></tr>
<tr><td><code id="h.alpha.n_+3A_p">p</code></td>
<td>
<p>integer (valued vector), the dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>numeric vector of <code class="reqn">h(\alpha, n,p)</code>; when any of the arguments of
length greater than one, the usual <span class="rlang"><b>R</b></span> arithmetic (recycling) rules are
used.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covMcd">covMcd</a></code> and <code><a href="#topic+ltsReg">ltsReg</a></code> which are
<em>defined</em> by <code class="reqn">h = h(\alpha,n,p)</code> and hence both use
<code>h.alpha.n</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- c(10:20,50,100)
p &lt;- 5
## show the simple "alpha = 1/2" case:
cbind(n=n, h= h.alpha.n(1/2, n, p), n2p = floor((n+p+1)/2))

## alpha = 3/4 is recommended by some authors :
n &lt;- c(15, 20, 25, 30, 50, 100)
cbind(n=n, h= h.alpha.n(3/4, n, p = 6))
</code></pre>

<hr>
<h2 id='hbk'>Hawkins, Bradu, Kass's Artificial Data</h2><span id='topic+hbk'></span>

<h3>Description</h3>

<p>Artificial Data Set generated by Hawkins, Bradu, and Kass (1984).  The
data set consists of 75 observations in four dimensions (one response
and three explanatory variables).  It provides a good example of the
masking effect.  The first 14 observations are outliers, created in
two groups: 1&ndash;10 and 11&ndash;14.
Only observations 12, 13 and 14 appear as outliers when using
classical methods, but can be easily unmasked using robust
distances computed by, e.g., MCD - covMcd().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(hbk, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 75 observations on 4 variables, where the last
variable is the dependent one.
</p>

<dl>
<dt>X1</dt><dd><p>x[,1]</p>
</dd>
<dt>X2</dt><dd><p>x[,2]</p>
</dd>
<dt>X3</dt><dd><p>x[,3]</p>
</dd>
<dt>Y</dt><dd><p>y</p>
</dd>
</dl>



<h3>Note</h3>

<p>This data set is also available in package <a href="https://CRAN.R-project.org/package=wle"><span class="pkg">wle</span></a> as
<code>artificial</code>.
</p>


<h3>Source</h3>

<p>Hawkins, D.M., Bradu, D., and Kass, G.V. (1984)
Location of several outliers in multiple regression data using
elemental sets.
<em>Technometrics</em> <b>26</b>, 197&ndash;208.
</p>
<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, p.94.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hbk)
plot(hbk)
summary(lm.hbk &lt;- lm(Y ~ ., data = hbk))

hbk.x &lt;- data.matrix(hbk[, 1:3])
(cHBK &lt;- covMcd(hbk.x))
</code></pre>

<hr>
<h2 id='heart'>Heart Catherization Data</h2><span id='topic+heart'></span>

<h3>Description</h3>

<p>This data set was analyzed by Weisberg (1980) and Chambers et
al. (1983).  A catheter is passed into a major vein or artery at the
femoral region and moved into the heart.  The proper length of the
introduced catheter has to be guessed by the physician. The aim of the
data set is to describe the relation between the catheter length and
the patient's height (X1) and weight (X2).
</p>
<p>This data sets is used to demonstrate the effects caused by collinearity.
The correlation between height and weight is so high that either
variable almost completely determines the other.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(heart)



</code></pre>


<h3>Format</h3>

<p>A data frame with 12 observations on the following 3 variables.
</p>

<dl>
<dt><code>height</code></dt><dd><p>Patient's height in inches</p>
</dd>
<dt><code>weight</code></dt><dd><p>Patient's weights in pounds</p>
</dd>
<dt><code>clength</code></dt><dd><p>Y: Catheter Length (in centimeters)</p>
</dd>
</dl>



<h3>Note</h3>

<p>There are other <code>heart</code> datasets in other <span class="rlang"><b>R</b></span> packages,
notably <a href="https://CRAN.R-project.org/package=survival"><span class="pkg">survival</span></a>, hence considering using
<code>package = "robustbase"</code>, see examples.
</p>


<h3>Source</h3>

<p>Weisberg (1980)
</p>
<p>Chambers et al. (1983)
</p>
<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, p.103, table 13.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(heart, package="robustbase")
heart.x &lt;- data.matrix(heart[, 1:2]) # the X-variables
plot(heart.x)
covMcd(heart.x)
summary( lm.heart &lt;-     lm(clength ~ . , data = heart))
summary(lts.heart &lt;- ltsReg(clength ~ . , data = heart))
</code></pre>

<hr>
<h2 id='huberize'>Huberization &ndash; Bringing Outliers In</h2><span id='topic+huberize'></span>

<h3>Description</h3>

<p>Huberization (named after Peter Huber's M-estimation algorithm for
location originally) replaces outlying values in a sample <code>x</code> by
their respective boundary: when <code class="reqn">x_j &lt; c_1</code> it is replaced by <code class="reqn">c_1</code>
and when <code class="reqn">x_j &gt; c_2</code>  it is replaced by <code class="reqn">c_2</code>.  Consequently,
values inside the interval <code class="reqn">[c_1, c_2]</code> remain unchanged.
</p>
<p>Here, <code class="reqn">c_j = M \pm c\cdot s</code> where <code class="reqn">s := s(x)</code> is
the <em>robust</em> scale estimate <code><a href="#topic+Qn">Qn</a>(x)</code> if that is positive,
and by default, <code class="reqn">M</code> is the robust huber estimate of location
<code class="reqn">\mu</code> (with tuning constant <code class="reqn">k</code>).
</p>
<p>In the degenerate case where <code><a href="#topic+Qn">Qn</a>(x) == 0</code>, trimmed means of
<code>abs(x - M)</code> are tried as scale estimate <code class="reqn">s</code>, with decreasing
trimming proportions specified by the decreasing <code>trim</code> vector.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huberize(x, M = huberM(x, k = k)$mu, c = k,
         trim = (5:1)/16,
         k = 1.5,
         warn0 = getOption("verbose"), saveTrim = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="huberize_+3A_x">x</code></td>
<td>
<p>numeric vector which is to be huberized.</p>
</td></tr>
<tr><td><code id="huberize_+3A_m">M</code></td>
<td>
<p>a number; defaulting to <code><a href="#topic+huberM">huberM</a>(x, k)</code>, the robust
Huber M-estimator of location.</p>
</td></tr>
<tr><td><code id="huberize_+3A_c">c</code></td>
<td>
<p>a positive number, the tuning constant for huberization of the
sample <code>x</code>.</p>
</td></tr>
<tr><td><code id="huberize_+3A_trim">trim</code></td>
<td>
<p>a <em>decreasing</em> vector of trimming proportions in
<code class="reqn">[0, 0.5]</code>, only used to trim the absolute deviations from <code>M</code>
in case <code><a href="#topic+Qn">Qn</a>(x)</code> is zero.
</p>
</td></tr>
<tr><td><code id="huberize_+3A_k">k</code></td>
<td>
<p>used if <code>M</code> is not specified as huberization center
<code>M</code>, and so, by default is taken as Huber's M-estimate
<code><a href="#topic+huberM">huberM</a>(x, k)</code>.</p>
</td></tr>
<tr><td><code id="huberize_+3A_warn0">warn0</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if a warning should be
signalled in case <code><a href="#topic+Qn">Qn</a>(x)</code> is zero and the trimmed means for
all trimming proportions <code>trim</code> are zero as well.</p>
</td></tr>
<tr><td><code id="huberize_+3A_savetrim">saveTrim</code></td>
<td>
<p>a <code><a href="base.html#topic+logical">logical</a></code> indicating if the last tried
<code>trim[j]</code> value should be stored if <code><a href="#topic+Qn">Qn</a>(x)</code> was zero.</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li><p> In regular cases, <code>s = <a href="#topic+Qn">Qn</a>(x)</code> is positive and used to
huberize values of <code>x</code> outside <code>[M - c*s, M + c*s]</code>.
</p>
</li>
<li><p> In degenerate cases where <code><a href="#topic+Qn">Qn</a>(x) == 0</code>, we search for
an <code class="reqn">s &gt; 0</code> by trying the trimmed mean <code>s := mean(abs(x-M), trim =
      trim[j])</code> with less and less trimming (as the trimming
proportions <code>trim[]</code> must decrease).
If even the last, <code>trim[length(trim)]</code>, leads to <code class="reqn">s = 0</code>, a
warning is printed when <code>warn0</code> is true.
</p>
</li></ul>



<h3>Value</h3>

<p>a numeric vector as <code>x</code>; in case <code><a href="#topic+Qn">Qn</a>(x)</code> was zero and
<code>saveTrim</code> is true, also containing the (last) <code>trim</code>
proportion used (to compute the scale <code class="reqn">s</code>) as attribute <code>"trim"</code>
(see <code><a href="base.html#topic+attr">attr</a>()</code>, <code><a href="base.html#topic+attributes">attributes</a></code>).
</p>


<h3>Note</h3>

<p>For the use in <code><a href="#topic+mc">mc</a>()</code> and similar cases where mainly numerical
stabilization is necessary, a large <code>c = 1e12</code> will lead to <em>no</em>
huberization, i.e., all <code>y == x</code> for <code>y &lt;- huberize(x, c)</code>
for typical non-degenerate samples.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+huberM">huberM</a></code> and <code><a href="#topic+mc">mc</a></code> which is now stabilized by
default via something like <code>huberize(*, c=1e11)</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## For non-degenerate data and large c, nothing is huberized,
## as there are *no* really extreme outliers :
set.seed(101)
x &lt;- rnorm(1000)
stopifnot(all.equal(x, huberize(x, c=100)))
## OTOH, the "extremes" are shrunken towards the boundaries for smaller c:
xh &lt;- huberize(x, c = 2)
table(x != xh)
## 45 out of a 1000:
table(xh[x != xh])# 26 on the left boundary -2.098 and 19 on the right = 2.081
## vizualization:
stripchart(x); text(0,1, "x {original}", pos=3); yh &lt;- 0.9
stripchart(xh, at = yh, add=TRUE, col=2)
text(0, yh, "huberize(x, c=2)",   col=2, pos=1)
arrows( x[x!=xh], 1,
       xh[x!=xh], yh, length=1/8, col=adjustcolor("pink", 1/2))
</code></pre>

<hr>
<h2 id='huberM'>Safe (generalized) Huber M-Estimator of Location</h2><span id='topic+huberM'></span>

<h3>Description</h3>

<p>(Generalized) Huber M-estimator of location with MAD scale, being
sensible also when the scale is zero where <code><a href="MASS.html#topic+huber">huber</a>()</code>
returns an error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>huberM(x, k = 1.5, weights = NULL, tol = 1e-06,
       mu = if(is.null(weights)) median(x) else wgt.himedian(x, weights),
       s =  if(is.null(weights)) mad(x, center=mu)
	    else wgt.himedian(abs(x - mu), weights),
       se = FALSE,
       warn0scale = getOption("verbose"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="huberM_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="huberM_+3A_k">k</code></td>
<td>
<p>positive factor; the algorithm winsorizes at <code>k</code>
standard deviations.</p>
</td></tr>
<tr><td><code id="huberM_+3A_weights">weights</code></td>
<td>
<p>numeric vector of non-negative weights of same length
as <code>x</code>, or <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="huberM_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance.</p>
</td></tr>
<tr><td><code id="huberM_+3A_mu">mu</code></td>
<td>
<p>initial location estimator.</p>
</td></tr>
<tr><td><code id="huberM_+3A_s">s</code></td>
<td>
<p>scale estimator held constant through the iterations.</p>
</td></tr>
<tr><td><code id="huberM_+3A_se">se</code></td>
<td>
<p>logical indicating if the standard error should be computed
and returned (as <code>SE</code> component).  Currently only available
when <code>weights</code> is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="huberM_+3A_warn0scale">warn0scale</code></td>
<td>
<p>logical; if true, and <code>s</code> is 0 and
<code>length(x) &gt; 1</code>, this will be warned about.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that currently, when non-<code>NULL</code> <code>weights</code> are
specified, the default for initial location <code>mu</code> and scale
<code>s</code> is <code><a href="#topic+wgt.himedian">wgt.himedian</a></code>, where strictly speaking a
weighted &ldquo;non-hi&rdquo; median should be used for consistency.
Since <code>s</code> is not updated, the results slightly differ, see the
examples below.
</p>
<p>When <code>se = TRUE</code>, the standard error is computed using the
<code class="reqn">\tau</code> correction factor but no finite sample correction.

</p>


<h3>Value</h3>

<p>list of location and scale parameters, and number of iterations used.
</p>
<table>
<tr><td><code>mu</code></td>
<td>
<p>location estimate</p>
</td></tr>
<tr><td><code>s</code></td>
<td>
<p>the <code>s</code> argument, typically the <code><a href="stats.html#topic+mad">mad</a></code>.</p>
</td></tr>
<tr><td><code>it</code></td>
<td>
<p>the number of &ldquo;Huber iterations&rdquo; used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Martin Maechler, building on the MASS code mentioned.</p>


<h3>References</h3>

<p>Huber, P. J. (1981)
<em>Robust Statistics.</em>
Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="MASS.html#topic+hubers">hubers</a></code> (and <code>huber</code>) in package <a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a>;
<code><a href="stats.html#topic+mad">mad</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>huberM(c(1:9, 1000))
mad   (c(1:9, 1000))
mad   (rep(9, 100))
huberM(rep(9, 100))

## When you have "binned" aka replicated observations:
set.seed(7)
x &lt;- c(round(rnorm(1000),1), round(rnorm(50, m=10, sd = 10)))
t.x &lt;- table(x) # -&gt; unique values and multiplicities
x.uniq &lt;- as.numeric(names(t.x)) ## == sort(unique(x))
x.mult &lt;- unname(t.x)
str(Hx  &lt;- huberM(x.uniq, weights = x.mult), digits = 7)
str(Hx. &lt;- huberM(x, s = Hx$s, se=TRUE), digits = 7) ## should be ~= Hx
stopifnot(all.equal(Hx[-4], Hx.[-4]))
str(Hx2 &lt;- huberM(x, se=TRUE), digits = 7)## somewhat different, since 's' differs

## Confirm correctness of std.error :

system.time(
SS &lt;- replicate(10000, vapply(huberM(rnorm(400), se=TRUE), as.double, 1.))
) # ~ 12.2 seconds
rbind(mean(SS["SE",]), sd(SS["mu",]))# both ~ 0.0508
stopifnot(all.equal(mean(SS["SE",]),
                    sd ( SS["mu",]), tolerance= 0.002))

</code></pre>

<hr>
<h2 id='kootenay'>Waterflow Measurements of Kootenay River in Libby and Newgate</h2><span id='topic+kootenay'></span>

<h3>Description</h3>

<p>The original data set is the waterflow in January of the Kootenay
river, measured at two locations, namely, Libby (Montana) and Newgate
(British Columbia) for 13 consecutive years, 1931&ndash;1943.
</p>
<p>The data set is of mostly interest because it has been used as example
in innumerous didactical situations about robust regression.
To this end, one number (in observation 4) has been modified from the
original data from originally 44.9 to 15.7 (here).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(kootenay, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 13 observations on the following 2 variables.
</p>

<dl>
<dt><code>Libby</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Newgate</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Details</h3>

<p>The original (unmodified) version of the data is easily obtainable
as <code>kootenay0</code> from the examples; other modified versions of the
data sets are also used in different places, see the examples below.
</p>


<h3>Source</h3>

<p>Original Data, p.58f of
Ezekiel and Fox (1959),
<em>Methods of Correlation and Regression Analysis</em>. Wiley, N.Y.
</p>


<h3>References</h3>

<p>Hampel, F., Ronchetti, E., Rousseeuw, P. and Stahel, W.  (1986)
<em>Robust Statistics: The Approach Based on Influence Functions</em>;
Wiley, N.Y.
</p>
<p>Rousseeuw, P. J. and Leroy, A. M. (1987)
<em>Robust Regression &amp; Outlier Detection</em>, Wiley, N. Y.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(kootenay)
plot(kootenay, main = "'kootenay' data")
points(kootenay[4,], col = 2, cex =2, pch = 3)

abline(lm   (Newgate ~ Libby, data = kootenay), col = "pink")
abline(lmrob(Newgate ~ Libby, data = kootenay), col = "blue")

## The original version of Ezekiel &amp; Fox:
kootenay0 &lt;- kootenay
kootenay0[4, "Newgate"] &lt;- 44.9
plot(kootenay0, main = "'kootenay0': the original data")
abline(lm   (Newgate ~ Libby, data = kootenay0), col = "pink")
abline(lmrob(Newgate ~ Libby, data = kootenay0), col = "blue")

## The version with "milder" outlier -- Hampel et al., p.310
kootenay2 &lt;- kootenay0
kootenay2[4, "Libby"] &lt;- 20.0 # instead of 77.6
plot(kootenay2, main = "The 'kootenay2' data",
     xlim = range(kootenay[,"Libby"]))
points(kootenay2[4,], col = 2, cex =2, pch = 3)
abline(lm   (Newgate ~ Libby, data = kootenay2), col = "pink")
abline(lmrob(Newgate ~ Libby, data = kootenay2), col = "blue")
</code></pre>

<hr>
<h2 id='lactic'>Lactic Acid Concentration Measurement Data</h2><span id='topic+lactic'></span>

<h3>Description</h3>

<p>Data on the Calibration of an Instrument that Measures
Lactic Acid Concentration in Blood, from Afifi and Azen (1979) -
comparing the true concentration X with the measured value Y.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(lactic, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 2 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>True Concentration</p>
</dd>
<dt><code>Y</code></dt><dd><p>Instrument</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, p.62, table 10.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(lactic)
summary(lm.lactic &lt;- lm(Y ~., data=lactic))

</code></pre>

<hr>
<h2 id='lmc'>Left and Right Medcouple, Robust Measures of Tail Weight</h2><span id='topic+lmc'></span><span id='topic+rmc'></span>

<h3>Description</h3>

<p>Compute the left and right &lsquo;medcouple&rsquo;, <em>robust</em> estimators
of tail weight, in some sense robust versions of the kurtosis, the very
unrobust centralized 4th moment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmc(x, mx = median(x, na.rm=na.rm), na.rm = FALSE, doReflect = FALSE, ...)
rmc(x, mx = median(x, na.rm=na.rm), na.rm = FALSE, doReflect = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmc_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
<tr><td><code id="lmc_+3A_mx">mx</code></td>
<td>
<p>number, the &ldquo;center&rdquo; of <code>x</code> wrt which the left and
right parts of <code>x</code> are defined: </p>
<pre>
    lmc(x, mx, *) :=  mc(x[x &lt;= mx], *)
    rmc(x, mx, *) :=  mc(x[x &gt;= mx], *)</pre>
</td></tr>
<tr><td><code id="lmc_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating how missing values (<code><a href="base.html#topic+NA">NA</a></code>s)
should be dealt with.</p>
</td></tr>
<tr><td><code id="lmc_+3A_doreflect">doReflect</code></td>
<td>
<p>logical indicating if <code><a href="#topic+mc">mc</a></code> should also be
computed on the <em>reflected</em> sample <code>-x</code>.  Setting
<code>doReflect=TRUE</code> makes sense for mathematical strictness reasons,
as the internal MC computes the himedian() which can differ slightly from
the median.
Note that <code><a href="#topic+mc">mc</a>()</code>'s own default is true iff <code>length(x) &lt;= 100</code>.
</p>
</td></tr>
<tr><td><code id="lmc_+3A_...">...</code></td>
<td>
<p>further arguments to <code><a href="#topic+mc">mc</a>()</code>, see its help page.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>each a number (unless <code>...</code> contains <code>full.result = TRUE</code>).
</p>


<h3>References</h3>

<p>Brys, G., Hubert, M. and Struyf, A. (2006).
Robust measures of tail weight,
<em>Computational Statistics and Data Analysis</em> <b>50(3)</b>, 733&ndash;759.
</p>
<p>and those in &lsquo;References&rsquo; of <code><a href="#topic+mc">mc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mc(1:5)  # 0 for a symmetric sample
lmc(1:5) # 0
rmc(1:5) # 0

x1 &lt;- c(1, 2, 7, 9, 10)
mc(x1) # = -1/3
c( lmc( x1),  lmc( x1, doReflect=TRUE))#   0  -1/3
c( rmc( x1),  rmc( x1, doReflect=TRUE))# -1/3 -1/6
c(-rmc(-x1), -rmc(-x1, doReflect=TRUE)) # 2/3  1/3

data(cushny)
lmc(cushny) # 0.2
rmc(cushny) # 0.45

isSym_LRmc &lt;- function(x, tol = 1e-14)
    all.equal(lmc(-x, doReflect=TRUE),
              rmc( x, doReflect=TRUE), tolerance = tol)

sym &lt;- c(-20, -5, -2:2, 5, 20)
stopifnot(exprs = {
    lmc(sym) == 0.5
    rmc(sym) == 0.5
    isSym_LRmc(cushny)
    isSym_LRmc(x1)
})

## Susceptibility to large outliers:
## "Sensitivity Curve" := empirical influence function
dX10 &lt;- function(X) c(1:5,7,10,15,25, X) # generate skewed size-10 with 'X'
x &lt;- c(26:40, 45, 50, 60, 75, 100)
(lmc10N &lt;- vapply(x, function(X) lmc(dX10(X)), 1))
(rmc10N &lt;- vapply(x, function(X) rmc(dX10(X)), 1))
cols &lt;- adjustcolor(2:3, 3/4)

plot(x, lmc10N, type="o", cex=1/2, main = "lmc &amp; rmc( c(1:5,7,10,15,25, X) )",
     xlab=quote(X), log="x", col=cols[1])
lines(x, rmc10N, col=cols[2], lwd=3)
legend("top", paste0(c("lmc", "rmc"), "(X)"), col=cols, lty=1, lwd=c(1,3), pch = c(1, NA), bty="n")

n &lt;- length(x)
stopifnot(exprs = {
    all.equal(current = lmc10N, target = rep(0, n))
    all.equal(current = rmc10N, target = c(3/19, 1/5, 5/21, 3/11, 7/23, rep(1/3, n-5)))
    ## and it stays stable with outlier  X --&gt; oo :
    lmc(dX10(1e300)) == 0
    rmc(dX10(1e300)) == rmc10N[6]
})
</code></pre>

<hr>
<h2 id='lmrob'>MM-type Estimators for Linear Regression</h2><span id='topic+lmrob'></span><span id='topic+.vcov.avar1'></span><span id='topic+.vcov.w'></span>

<h3>Description</h3>

<p>Computes fast MM-type estimators for linear (regression) models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrob(formula, data, subset, weights, na.action, method = "MM",
      model = TRUE, x = !control$compute.rd, y = FALSE,
      singular.ok = TRUE, contrasts = NULL, offset = NULL,
      control = NULL, init = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrob_+3A_formula">formula</code></td>
<td>
<p>a symbolic description of the model to be fit.  See
<code><a href="stats.html#topic+lm">lm</a></code> and <code><a href="stats.html#topic+formula">formula</a></code> for more details.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment (or object
coercible by <code><a href="base.html#topic+as.data.frame">as.data.frame</a></code> to a data frame) containing
the variables in the model.  If not found in <code>data</code>, the
variables are taken from <code>environment(formula)</code>,
typically the environment from which <code>lmrob</code> is called.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process (in addition to the robustness weights computed in the
fitting process).</p>
</td></tr>
<tr><td><code id="lmrob_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is set by
the <code>na.action</code> setting of <code><a href="base.html#topic+options">options</a></code>, and is
<code><a href="stats.html#topic+na.fail">na.fail</a></code> if that is unset.  The &ldquo;factory-fresh&rdquo;
default is <code><a href="stats.html#topic+na.omit">na.omit</a></code>.  Another possible value is
<code>NULL</code>, no action.  Value <code><a href="stats.html#topic+na.exclude">na.exclude</a></code> can be useful.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_method">method</code></td>
<td>
<p>string specifying the estimator-chain. <code>MM</code>
is interpreted as <code>SM</code>.  See <em>Details</em>, notably the
currently recommended <code>setting = "KS2014"</code>.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_model">model</code>, <code id="lmrob_+3A_x">x</code>, <code id="lmrob_+3A_y">y</code></td>
<td>
<p>logicals.  If <code>TRUE</code> the corresponding
components of the fit (the model frame, the model matrix, the
response) are returned.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_singular.ok">singular.ok</code></td>
<td>
<p>logical.  If <code>FALSE</code> (the default in S but
not in <span class="rlang"><b>R</b></span>) a singular fit is an error.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list.  See the <code>contrasts.arg</code>
of <code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an <em>a priori</em>
known component to be included in the linear predictor
during fitting.  An <code><a href="stats.html#topic+offset">offset</a></code> term can be included in the
formula instead or as well, and if both are specified their sum is used.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_control">control</code></td>
<td>
<p>a <code><a href="base.html#topic+list">list</a></code> specifying control parameters; use
the function <code><a href="#topic+lmrob.control">lmrob.control</a>(.)</code> and see its help page.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_init">init</code></td>
<td>
<p>an optional argument to specify or supply the initial
estimate. See <em>Details</em>.</p>
</td></tr>
<tr><td><code id="lmrob_+3A_...">...</code></td>
<td>
<p>additional arguments can be used to specify control
parameters directly instead of (but not in addition to!) via <code>control</code>.</p>
</td></tr>
</table>


<h3>Details</h3>


<dl>
<dt>Overview:</dt><dd>
<p>This function computes an MM-type regression estimator as
described in Yohai (1987) and Koller and Stahel (2011).  By
default it uses a bi-square redescending score function, and it
returns a highly robust and highly efficient estimator (with 50%
breakdown point and 95% asymptotic efficiency for normal errors).
The computation is carried out by a call to <code><a href="#topic+lmrob.fit">lmrob.fit</a>()</code>.
</p>
<p>The argument <code>setting</code> of <code><a href="#topic+lmrob.control">lmrob.control</a></code> is provided
to set alternative defaults as suggested in Koller and Stahel (2011)
(<code>setting="KS2011"</code>; now do use its extension
<code>setting="KS2014"</code>).  For further details, see <code><a href="#topic+lmrob.control">lmrob.control</a></code>.
</p>
</dd>
<dt>Initial Estimator <code>init</code>:</dt><dd>
<p>The initial estimator may be specified using the argument
<code>init</code>.  This can either be
</p>

<ul>
<li><p> a <em>string</em> used to specify built in internal
estimators (currently <code>"S"</code> and <code>"M-S"</code>, see <em>See also</em>
below);
</p>
</li>
<li><p> a <code><a href="base.html#topic+function">function</a></code> taking arguments <code>x, y,
	  control, mf</code> (where <code>mf</code> stands for <code>model.frame</code>) and
returning a <code><a href="base.html#topic+list">list</a></code> containing at least the initial coefficients as
component <code>"coefficients"</code> and the initial scale estimate as
<code>"scale"</code>.
</p>
</li>
<li><p> Or a <code><a href="base.html#topic+list">list</a></code> giving the initial coefficients and
scale as components <code>"coefficients"</code> and <code>"scale"</code>.  See also
<em>Examples</em>.
</p>
</li></ul>

<p>Note that when <code>init</code> is a function or list, the
<code>method</code> argument must <em>not</em> contain the initial estimator, e.g.,
use <code>MDM</code> instead of <code>SMDM</code>.
</p>
<p>The default, equivalent to <code>init = "S"</code>, uses as initial
estimator an S-estimator (Rousseeuw and Yohai, 1984) which is
computed using the Fast-S algorithm of Salibian-Barrera and Yohai
(2006), calling <code><a href="#topic+lmrob.S">lmrob.S</a>()</code>.  That function, since
March 2012, by default uses <em>nonsingular</em> subsampling which
makes the Fast-S algorithm feasible for categorical data as well,
see Koller (2012).  Note that convergence problems may still show
up as warnings, e.g., </p>
<pre>
  S refinements did not converge (to refine.tol=1e-07) in 200 (= k.max) steps
</pre>
<p>and often can simply be remedied by increasing (i.e. weakening)
<code>refine.tol</code> or increasing the allowed number of iterations
<code>k.max</code>, see <code><a href="#topic+lmrob.control">lmrob.control</a></code>.
</p>
</dd>
<dt>Method <code>method</code>:</dt><dd>
<p>The following chain of estimates is customizable via the
<code>method</code> argument. 
There are currently two types of estimates available,
</p>

<dl>
<dt><code>"M"</code>:</dt><dd><p>corresponds to the standard M-regression
estimate.</p>
</dd>
<dt><code>"D"</code>:</dt><dd><p>stands for the Design Adaptive Scale estimate
as proposed in Koller and Stahel (2011).</p>
</dd>
</dl>

<p>The <code>method</code> argument takes a string that specifies the
estimates to be calculated as a chain.  Setting
<code>method='SMDM'</code> will result in an intial S-estimate, followed
by an M-estimate, a Design Adaptive Scale estimate and a final
M-step.  For methods involving a <code>D</code>-step, the default value
of <code>psi</code> (see <code><a href="#topic+lmrob.control">lmrob.control</a></code>) is changed to
<code>"lqq"</code>.
</p>
<p>By default, standard errors are computed using the formulas of
Croux, Dhaene and Hoorelbeke (2003) (<code><a href="#topic+lmrob.control">lmrob.control</a></code>
option <code>cov=".vcov.avar1"</code>).  This method, however, works only
for MM-estimates (i.e., <code>method = "MM"</code> or <code> = "SM"</code>).  For other
<code>method</code> arguments, the covariance matrix estimate used is based on the asymptotic
normality of the estimated coefficients (<code>cov=".vcov.w"</code>) as
described in Koller and Stahel (2011).
The var-cov computation can be skipped by <code>cov = "none"</code> and
(re)done later by e.g., <code>vcov(&lt;obj&gt;, cov = ".vcov.w")</code>.
</p>
<p>As of robustbase version 0.91-0 (April 2014), the computation of
robust standard errors for <code>method="SMDM"</code> has been changed.
The old behaviour can be restored by setting the control parameter
<code>cov.corrfact = "tauold"</code>.
</p>
</dd>
</dl>



<h3>Value</h3>

<p>An object of class <code>lmrob</code>; a list including the following
components:
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>The estimate of the coefficient vector</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>The scale as used in the M estimator.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>Residuals associated with the estimator.</p>
</td></tr>

<tr><td><code>converged</code></td>
<td>
<p><code>TRUE</code> if the IRWLS iterations have converged.</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of IRWLS iterations</p>
</td></tr>
<tr><td><code>rweights</code></td>
<td>
<p>the &ldquo;robustness weights&rdquo; <code class="reqn">\psi(r_i/S) / (r_i/S)</code>.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>Fitted values associated with the estimator.</p>
</td></tr>

<tr><td><code>init.S</code></td>
<td>
<p>The <code><a href="base.html#topic+list">list</a></code> returned by <code><a href="#topic+lmrob.S">lmrob.S</a>()</code> or
<code><a href="#topic+lmrob.M.S">lmrob.M.S</a>()</code> (for MM-estimates, i.e., <code>method="MM"</code> or <code>"SM"</code> only)</p>
</td></tr>
<tr><td><code>init</code></td>
<td>
<p>A similar list that contains the results of intermediate
estimates (<em>not</em> for MM-estimates).</p>
</td></tr>

<tr><td><code>rank</code></td>
<td>
<p>the numeric rank of the fitted linear model.</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>The estimated covariance matrix of the regression
coefficients</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>

<tr><td><code>weights</code></td>
<td>
<p>the specified weights (missing if none were used).</p>
</td></tr>
<tr><td><code>na.action</code></td>
<td>
<p>(where relevant) information returned by
<code><a href="stats.html#topic+model.frame">model.frame</a></code> on the special handling of <code>NA</code>s.</p>
</td></tr>
<tr><td><code>offset</code></td>
<td>
<p>the offset used (missing if none were used).</p>
</td></tr>
<tr><td><code>contrasts</code></td>
<td>
<p>(only where relevant) the contrasts used.</p>
</td></tr>
<tr><td><code>xlevels</code></td>
<td>
<p>(only where relevant) a record of the levels of the factors
used in fitting.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>terms</code></td>
<td>
<p>the <code>terms</code> object used.</p>
</td></tr>

<tr><td><code>model</code></td>
<td>
<p>if requested (the default), the model frame used.</p>
</td></tr>
<tr><td><code>x</code></td>
<td>
<p>if requested, the model matrix used.</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>if requested, the response used.</p>
</td></tr>
</table>
<p>In addition, non-null fits will have components <code>assign</code>,
and <code>qr</code> relating to the linear fit, for use by extractor
functions such as <code>summary</code>.
</p>


<h3>Author(s)</h3>

<p>(mainly:) Matias Salibian-Barrera and Manuel Koller</p>


<h3>References</h3>

<p>Croux, C., Dhaene, G. and Hoorelbeke, D. (2003)
<em>Robust standard errors for robust estimators</em>,
Discussion Papers Series 03.16, K.U. Leuven, CES.
</p>
<p>Koller, M. (2012)
Nonsingular subsampling for S-estimators with categorical predictors,
<em>ArXiv e-prints</em> <a href="https://arxiv.org/abs/1208.5595">https://arxiv.org/abs/1208.5595</a>;
extended version published as Koller and Stahel (2017), see
<code><a href="#topic+lmrob.control">lmrob.control</a></code>.
</p>
<p>Koller, M. and Stahel, W.A. (2011)
Sharpening Wald-type inference in robust regression for small samples.
<em>Computational Statistics &amp; Data Analysis</em> <b>55</b>(8), 2504&ndash;2515.
</p>
<p>Maronna, R. A., and Yohai, V. J. (2000)
Robust regression with both continuous and categorical predictors.
<em>Journal of Statistical Planning and Inference</em> <b>89</b>, 197&ndash;214.
</p>
<p>Rousseeuw, P.J. and Yohai, V.J. (1984)
Robust regression by means of S-estimators,
In <em>Robust and Nonlinear Time Series</em>,
J. Franke, W. HÃ¤rdle and R. D. Martin (eds.).
Lectures Notes in Statistics 26, 256&ndash;272,
Springer Verlag, New York.
</p>
<p>Salibian-Barrera, M. and Yohai, V.J. (2006)
A fast algorithm for S-regression estimates,
<em>Journal of Computational and Graphical Statistics</em> <b>15</b>(2), 414&ndash;427.
<a href="https://doi.org/10.1198/106186006X113629">doi:10.1198/106186006X113629</a>
</p>
<p>Yohai, V.J. (1987)
High breakdown-point and high efficiency estimates for regression.
<em>The Annals of Statistics</em> <b>15</b>, 642&ndash;65.
</p>
<p>Yohai, V., Stahel, W.~A. and Zamar, R. (1991)
A procedure for robust estimation and inference in linear regression;
in Stahel and Weisberg (eds), <em>Directions in Robust Statistics
and Diagnostics</em>, Part II, Springer, New York, 365&ndash;374;
<a href="https://doi.org/10.1007/978-1-4612-4444-8_20">doi:10.1007/978-1-4612-4444-8_20</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob.control">lmrob.control</a></code>;
for the algorithms <code><a href="#topic+lmrob.S">lmrob.S</a></code>, <code><a href="#topic+lmrob.M.S">lmrob.M.S</a></code> and
<code><a href="#topic+lmrob.fit">lmrob.fit</a></code>;
and for methods,
<code><a href="#topic+summary.lmrob">summary.lmrob</a></code>, for the extra &ldquo;statistics&rdquo;,
notably <code class="reqn">R^2</code> (&ldquo;R squared&rdquo;);
<code><a href="#topic+predict.lmrob">predict.lmrob</a></code>,
<code><a href="#topic+print.lmrob">print.lmrob</a></code>, <code><a href="#topic+plot.lmrob">plot.lmrob</a></code>, and
<code><a href="#topic+weights.lmrob">weights.lmrob</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(coleman)
set.seed(0)
## Default for a very long time:
summary( m1 &lt;- lmrob(Y ~ ., data=coleman) )

## Nowadays **strongly recommended** for routine use:
summary(m2 &lt;- lmrob(Y ~ ., data=coleman, setting = "KS2014") )
##                                       ------------------

plot(residuals(m2) ~ weights(m2, type="robustness")) ##-&gt; weights.lmrob()
abline(h=0, lty=3)

data(starsCYG, package = "robustbase")
## Plot simple data and fitted lines
plot(starsCYG)
  lmST &lt;-    lm(log.light ~ log.Te, data = starsCYG)
(RlmST &lt;- lmrob(log.light ~ log.Te, data = starsCYG))
abline(lmST, col = "red")
abline(RlmST, col = "blue")
## --&gt; Least Sq.:/ negative slope  \ robust: slope ~= 2.2 % checked in ../tests/lmrob-data.R
summary(RlmST) # -&gt; 4 outliers; rest perfect
vcov(RlmST)
stopifnot(all.equal(fitted(RlmST),
                    predict(RlmST, newdata = starsCYG), tol = 1e-14))
## FIXME: setting = "KS2011"  or  setting = "KS2014"  **FAIL** here

##--- 'init' argument -----------------------------------
## 1)  string
set.seed(0)
m3 &lt;- lmrob(Y ~ ., data=coleman, init = "S")
stopifnot(all.equal(m1[-18], m3[-18]))
## 2) function
initFun &lt;- function(x, y, control, ...) { # no 'mf' needed
    init.S &lt;- lmrob.S(x, y, control)
    list(coefficients=init.S$coef, scale = init.S$scale)
}
set.seed(0)
m4 &lt;- lmrob(Y ~ ., data=coleman, method = "M", init = initFun)
## list
m5 &lt;- lmrob(Y ~ ., data=coleman, method = "M",
            init = list(coefficients = m3$init$coef, scale = m3$scale))
stopifnot(all.equal(m4[-17], m5[-17]))
</code></pre>

<hr>
<h2 id='lmrob..D..fit'>Compute Design Adaptive Scale estimate</h2><span id='topic+lmrob..D..fit'></span>

<h3>Description</h3>

<p>This function calculates a Design Adaptive Scale estimate
for a given MM-estimate. This is supposed to be a part of a chain of
estimates like <code>SMD</code> or <code>SMDM</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrob..D..fit(obj, x=obj$x, control = obj$control,
              mf,
              method = obj$control$method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrob..D..fit_+3A_obj">obj</code></td>
<td>
<p><code>lmrob</code>-object based on which the estimate is to be
calculated.</p>
</td></tr>
<tr><td><code id="lmrob..D..fit_+3A_x">x</code></td>
<td>
<p>the design matrix; if <code><a href="base.html#topic+missing">missing</a></code>, the method tries
to get it from <code>obj$x</code> and if this fails from <code>obj$model</code>.</p>
</td></tr>
<tr><td><code id="lmrob..D..fit_+3A_control">control</code></td>
<td>
<p>list of control parameters, as returned
by <code><a href="#topic+lmrob.control">lmrob.control</a></code>.</p>
</td></tr>
<tr><td><code id="lmrob..D..fit_+3A_mf">mf</code></td>
<td>
<p>defunct.</p>
</td></tr>
<tr><td><code id="lmrob..D..fit_+3A_method">method</code></td>
<td>
<p>optional; the <code>method</code> used for <em>obj</em> computation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used by <code><a href="#topic+lmrob.fit">lmrob.fit</a></code> and typically not to
be used on its own.  Note that <code>lmrob.fit()</code> specifies
<code>control</code> potentially differently than the default, but does use
the default for <code>method</code>.
</p>


<h3>Value</h3>

<p>The given <code>lmrob</code>-object with the following elements updated:
</p>
<table>
<tr><td><code>scale</code></td>
<td>
<p>The Design Adaptive Scale estimate</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
 <p><code>TRUE</code> if the scale calculation converged,
<code>FALSE</code> other.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Koller</p>


<h3>References</h3>

<p>Koller, M. and Stahel, W.A. (2011), Sharpening Wald-type inference in
robust regression for small samples, <em>Computational Statistics &amp;
Data Analysis</em> <b>55</b>(8), 2504&ndash;2515.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob.fit">lmrob.fit</a></code>, <code><a href="#topic+lmrob">lmrob</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stackloss)
## Compute manual SMD-estimate:
## 1) MM-estimate
m1 &lt;- lmrob(stack.loss ~ ., data = stackloss)
## 2) Add Design Adaptive Scale estimate
m2 &lt;- lmrob..D..fit(m1)
print(c(m1$scale, m2$scale))

summary(m1)
summary(m2) ## the covariance matrix estimate is also updated
</code></pre>

<hr>
<h2 id='lmrob..M..fit'>Compute M-estimators of regression</h2><span id='topic+lmrob..M..fit'></span>

<h3>Description</h3>

<p>This function performs RWLS iterations to find an
M-estimator of regression.  When started from an S-estimated
<code>beta.initial</code>, this results in an MM-estimator.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrob..M..fit(x = obj$x, y = obj$y,
              beta.initial = obj$coef, scale = obj$scale, control = obj$control,
              obj,
              mf,
              method = obj$control$method)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrob..M..fit_+3A_x">x</code></td>
<td>
<p>design matrix (<code class="reqn">n \times p</code>) typically including a
column of <code>1</code>s for the intercept.</p>
</td></tr>
<tr><td><code id="lmrob..M..fit_+3A_y">y</code></td>
<td>
<p>numeric response vector (of length <code class="reqn">n</code>).</p>
</td></tr>
<tr><td><code id="lmrob..M..fit_+3A_beta.initial">beta.initial</code></td>
<td>
<p>numeric vector (of length <code class="reqn">p</code>) of initial
estimate.  Usually the result of an S-regression estimator.</p>
</td></tr>
<tr><td><code id="lmrob..M..fit_+3A_scale">scale</code></td>
<td>
<p>robust residual scale estimate. Usually
an S-scale estimator.</p>
</td></tr>
<tr><td><code id="lmrob..M..fit_+3A_control">control</code></td>
<td>
<p>list of control parameters, as returned
by <code><a href="#topic+lmrob.control">lmrob.control</a></code>.  Currently, the components
<code>c("max.it", "rel.tol","trace.lev", "psi", "tuning.psi", "mts", "subsampling")</code>
are accessed.</p>
</td></tr>
<tr><td><code id="lmrob..M..fit_+3A_obj">obj</code></td>
<td>
<p>an optional <code>lmrob</code>-object.  If specified, this is
typically used to set values for the other arguments.</p>
</td></tr>
<tr><td><code id="lmrob..M..fit_+3A_mf">mf</code></td>
<td>
<p>defunct.</p>
</td></tr>
<tr><td><code id="lmrob..M..fit_+3A_method">method</code></td>
<td>
<p>optional; the <code>method</code> used for <em>obj</em> computation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used by <code><a href="#topic+lmrob.fit">lmrob.fit</a></code> (and
<code>anova(&lt;lmrob&gt;, type = "Deviance")</code>) and typically not to be used
on its own.
</p>


<h3>Value</h3>

<p>A list with the following elements:
</p>
<table>
<tr><td><code>coef</code></td>
<td>
<p>the M-estimator (or MM-estim.) of regression</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>the <code>control</code> list input used</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p> The residual scale estimate</p>
</td></tr>
<tr><td><code>seed</code></td>
<td>
<p> The random number generator seed</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
 <p><code>TRUE</code> if the RWLS iterations converged,
<code>FALSE</code> otherwise</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Matias Salibian-Barrera and Martin Maechler</p>


<h3>References</h3>

<p>Yohai, 1987
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob.fit">lmrob.fit</a></code>, <code><a href="#topic+lmrob">lmrob</a></code>;
<code><a href="MASS.html#topic+rlm">rlm</a></code> from package <a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stackloss)
X &lt;- model.matrix(stack.loss ~ . , data = stackloss)
y &lt;- stack.loss
## Compute manual MM-estimate:
## 1) initial LTS:
m0 &lt;- ltsReg(X[,-1], y)
## 2) M-estimate started from LTS:
m1 &lt;- lmrob..M..fit(X, y, beta.initial = coef(m0), scale = m0$scale, method = "SM",
                    control = lmrob.control(tuning.psi = 1.6, psi = 'bisquare'))
## no 'method' (nor 'obj'):
m1. &lt;- lmrob..M..fit(X, y, beta.initial = coef(m0), scale = m0$scale,
                     control = m1$control)
stopifnot(all.equal(m1, m1., tol = 1e-15)) # identical {call *not* stored!}

cbind(m0$coef, m1$coef)
## the scale is kept fixed:
stopifnot(identical(unname(m0$scale), m1$scale))

##  robustness weights: are
r.s &lt;- with(m1, residuals/scale) # scaled residuals
m1.wts &lt;- Mpsi(r.s, cc = 1.6, psi="tukey") / r.s
summarizeRobWeights(m1.wts)
##--&gt; outliers 1,3,4,13,21
which(m0$lts.wt == 0) # 1,3,4,21 but not 13

## Manually add M-step to SMD-estimate (=&gt; equivalent to "SMDM"):
m2 &lt;- lmrob(stack.loss ~ ., data = stackloss, method = 'SMD')
m3 &lt;- lmrob..M..fit(obj = m2)

## Simple function that allows custom initial estimates
## (Deprecated; use init argument to lmrob() instead.) %% MM: why deprecated?
lmrob.custom &lt;- function(x, y, beta.initial, scale, terms) {
  ## initialize object
  obj &lt;- list(control = lmrob.control("KS2011"),
              terms = terms) ## terms is needed for summary()
  ## M-step
  obj &lt;- lmrob..M..fit(x, y, beta.initial, scale, obj = obj)
  ## D-step
  obj &lt;- lmrob..D..fit(obj, x)
  ## Add some missing elements
  obj$cov &lt;- TRUE ## enables calculation of cov matrix
  obj$p &lt;- obj$qr$rank
  obj$degree.freedom &lt;- length(y) - obj$p
  ## M-step
  obj &lt;- lmrob..M..fit(x, y, obj=obj)
  obj$control$method &lt;- ".MDM"
  obj
}

m4 &lt;- lmrob.custom(X, y, m2$init$init.S$coef,
                   m2$init$scale, m2$terms)
stopifnot(all.equal(m4$coef, m3$coef))

## Start from ltsReg:
m5 &lt;- ltsReg(stack.loss ~ ., data = stackloss)
m6 &lt;- lmrob.custom(m5$X, m5$Y, coef(m5), m5$scale, m5$terms)
</code></pre>

<hr>
<h2 id='lmrob.control'>Tuning Parameters for lmrob() and Auxiliaries</h2><span id='topic+lmrob.control'></span><span id='topic+update.lmrobCtrl'></span><span id='topic+.Mchi.tuning.default'></span><span id='topic+.Mpsi.tuning.default'></span><span id='topic+.Mchi.tuning.defaults'></span><span id='topic+.Mpsi.tuning.defaults'></span>

<h3>Description</h3>

<p>Tuning parameters for <code><a href="#topic+lmrob">lmrob</a></code>, the MM-type regression
estimator and the associated S-, M- and D-estimators.  Using
<code>setting="KS2011"</code> sets the defaults as suggested by
Koller and Stahel (2011) and analogously for <code>"KS2014"</code>.
</p>
<p>The <code>.M*.default</code> <code><a href="base.html#topic+function">function</a></code>s and
<code>.M*.defaults</code> <code><a href="base.html#topic+list">list</a></code>s contain default tuning
parameters for all the predefined <code class="reqn">\psi</code> functions, see also
<code><a href="#topic+Mpsi">Mpsi</a></code>, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrob.control(setting, seed = NULL, nResample = 500,
              tuning.chi = NULL, bb = 0.5, tuning.psi = NULL,
              max.it = 50, groups = 5, n.group = 400,
              k.fast.s = 1, best.r.s = 2,
              k.max = 200, maxit.scale = 200, k.m_s = 20,
              refine.tol = 1e-7, rel.tol = 1e-7, scale.tol = 1e-10, solve.tol = 1e-7,
              zero.tol = 1e-10,
              trace.lev = 0,
              mts = 1000, subsampling = c("nonsingular", "simple"),
              compute.rd = FALSE, method = "MM", psi = "bisquare",
              numpoints = 10, cov = NULL,
              split.type = c("f", "fi", "fii"), fast.s.large.n = 2000,
              # only for outlierStats() :
              eps.outlier = function(nobs) 0.1 / nobs,
              eps.x = function(maxx) .Machine$double.eps^(.75)*maxx,
              compute.outlier.stats = method,
              warn.limit.reject = 0.5,
              warn.limit.meanrw = 0.5, ...)

## S3 method for class 'lmrobCtrl'
update(object, ...)

.Mchi.tuning.defaults
.Mchi.tuning.default(psi)
.Mpsi.tuning.defaults
.Mpsi.tuning.default(psi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrob.control_+3A_setting">setting</code></td>
<td>
<p>a string specifying alternative default values.  Leave
empty for the defaults or use <code>"KS2011"</code> or <code>"KS2014"</code>
for the defaults suggested by Koller and Stahel (2011, 2017).
See <em>Details</em>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_seed">seed</code></td>
<td>
<p><code>NULL</code> or an integer vector compatible with
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>: the seed to be used for random
re-sampling used in obtaining candidates for the initial
S-estimator.  The current value of <code>.Random.seed</code> will be
preserved if <code>seed</code> is set, i.e. non-<code>NULL</code>;
otherwise, as by default, <code>.Random.seed</code> will be used and
modified as usual from calls to <code><a href="stats.html#topic+runif">runif</a>()</code> etc.
</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_nresample">nResample</code></td>
<td>
<p>number of re-sampling candidates to be
used to find the initial S-estimator.  Currently defaults to 500
which works well in most situations (see references).</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_tuning.chi">tuning.chi</code></td>
<td>
<p>tuning constant vector for the S-estimator.  If
<code>NULL</code>, as by default, sensible defaults are set (depending on
<code>psi</code>) to yield a 50% breakdown estimator.  See <em>Details</em>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_bb">bb</code></td>
<td>
<p>expected value under the normal model of the
&ldquo;chi&rdquo; (rather <code class="reqn">\rho (rho)</code>) function with tuning
constant equal to <code>tuning.chi</code>.  This is used to compute the
S-estimator.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_tuning.psi">tuning.psi</code></td>
<td>
<p>tuning constant vector for the redescending
M-estimator.  If <code>NULL</code>, as by default, this is set (depending
on <code>psi</code>) to yield an estimator with asymptotic efficiency of
95% for normal errors.  See <em>Details</em>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_max.it">max.it</code></td>
<td>
<p>integer specifying the maximum number of IRWLS iterations.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_groups">groups</code></td>
<td>
<p>(for the fast-S algorithm): Number of
random subsets to use when the data set is large.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_n.group">n.group</code></td>
<td>
<p>(for the fast-S algorithm): Size of each of the
<code>groups</code> above.  Note that this must be at least <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_k.fast.s">k.fast.s</code></td>
<td>
<p>(for the fast-S algorithm): Number of
local improvement steps (&ldquo;<em>I-steps</em>&rdquo;) for each
re-sampling candidate.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_k.m_s">k.m_s</code></td>
<td>
<p>(for the M-S algorithm): specifies after how many
unsuccessful refinement steps the algorithm stops.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_best.r.s">best.r.s</code></td>
<td>
<p>(for the fast-S algorithm): Number of
of best candidates to be iterated further (i.e.,
&ldquo;<em><b>r</b>efined</em>&rdquo;); is denoted <code class="reqn">t</code> in
Salibian-Barrera &amp; Yohai(2006).</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_k.max">k.max</code></td>
<td>
<p>(for the fast-S algorithm): maximal number of
refinement steps for the &ldquo;fully&rdquo; iterated best candidates.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_maxit.scale">maxit.scale</code></td>
<td>
<p>integer specifying the maximum number of C level
<code>find_scale()</code> iterations (in fast-S and M-S algorithms).</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_refine.tol">refine.tol</code></td>
<td>
<p>(for the fast-S algorithm): relative convergence
tolerance for the fully iterated best candidates.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_rel.tol">rel.tol</code></td>
<td>
<p>(for the RWLS iterations of the MM algorithm): relative
convergence tolerance for the parameter vector.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_scale.tol">scale.tol</code></td>
<td>
<p>(for the scale estimation iterations of the S algorithm): relative
convergence tolerance for the <code>scale</code> <code class="reqn">\sigma(.)</code>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_solve.tol">solve.tol</code></td>
<td>
<p>(for the S algorithm): relative
tolerance for inversion.  Hence, this corresponds to
<code><a href="base.html#topic+solve.default">solve.default</a>()</code>'s <code>tol</code>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_zero.tol">zero.tol</code></td>
<td>
<p>for checking 0-residuals in the S algorithm, non-negative number
<code class="reqn">\epsilon_z</code> such that
<code class="reqn">\{i; \left|\tilde{R}_i\right| \le \epsilon_z\}</code>
correspond to <code class="reqn">0</code>-residuals, where <code class="reqn">\tilde{R}_i</code> are standardized residuals,
<code class="reqn">\tilde{R}_i = R_i/s_y</code> and
<code class="reqn">s_y = \frac{1}{n} \sum_{i=1}^n \left|y_i\right|</code>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_trace.lev">trace.lev</code></td>
<td>
<p>integer indicating if the progress of the MM-algorithm
and the fast-S algorithms, see <code><a href="#topic+lmrob.S">lmrob.S</a></code>,
should be traced (increasingly); default <code>trace.lev = 0</code> does
no tracing.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_mts">mts</code></td>
<td>
<p>maximum number of samples to try in subsampling
algorithm.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_subsampling">subsampling</code></td>
<td>
<p>type of subsampling to be used, a string:
<code>"simple"</code> for simple subsampling (default prior to version 0.9),
<code>"nonsingular"</code> for nonsingular subsampling.  See also
<code><a href="#topic+lmrob.S">lmrob.S</a></code>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_compute.rd">compute.rd</code></td>
<td>
<p>logical indicating if robust distances (based on
the MCD robust covariance estimator <code><a href="#topic+covMcd">covMcd</a></code>) are to be
computed for the robust diagnostic plots.  This may take some
time to finish, particularly for large data sets, and can lead to
singularity problems when there are <code><a href="base.html#topic+factor">factor</a></code> explanatory
variables (with many levels, or levels with &ldquo;few&rdquo;
observations).  Hence, is <code>FALSE</code> by default.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_method">method</code></td>
<td>
<p>string specifying the estimator-chain. <code>MM</code>
is interpreted as <code>SM</code>.  See <em>Details</em> of
<code><a href="#topic+lmrob">lmrob</a></code> for a description of the possible values.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_psi">psi</code></td>
<td>
<p>string specifying the type <code class="reqn">\psi</code>-function
used.  See <em>Details</em> of <code><a href="#topic+lmrob">lmrob</a></code>.  Defaults to
<code>"bisquare"</code> for S and MM-estimates, otherwise <code>"lqq"</code>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_numpoints">numpoints</code></td>
<td>
<p>number of points used in Gauss quadrature.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_cov">cov</code></td>
<td>
<p>function or string with function name to be used to
calculate covariance matrix estimate.  The default is
<code>if(method %in% c('SM', 'MM')) ".vcov.avar1" else ".vcov.w"</code>.
See <em>Details</em> of <code><a href="#topic+lmrob">lmrob</a></code>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_split.type">split.type</code></td>
<td>
<p>determines how categorical and continuous variables
are split.  See <code><a href="#topic+splitFrame">splitFrame</a></code>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_fast.s.large.n">fast.s.large.n</code></td>
<td>
<p>minimum number of observations required to
switch from ordinary &ldquo;fast S&rdquo; algorithm to an efficient
&ldquo;large n&rdquo; strategy.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_eps.outlier">eps.outlier</code></td>
<td>
<p>limit on the robustness weight below which an observation
is considered to be an outlier.
Either a <code>numeric(1)</code> or a function that takes the number of observations as
an argument.  Used only in <code><a href="#topic+summary.lmrob">summary.lmrob</a></code> and
<code><a href="#topic+outlierStats">outlierStats</a></code>.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_eps.x">eps.x</code></td>
<td>
<p>limit on the absolute value of the elements of the design matrix
below which an element is considered zero.
Either a <code>numeric(1)</code> or a function that takes the maximum absolute value in
the design matrix as an argument.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_compute.outlier.stats">compute.outlier.stats</code></td>
<td>
<p>vector of <code><a href="base.html#topic+character">character</a></code>
strings, each valid to be used as <code>method</code> argument.  Used to
specify for which estimators outlier statistics (and warnings)
should be produced.  Set to empty (<code>NULL</code> or <code>character(0)</code>)
if none are required.
<br /> Note that the default is <code>method</code> which by default is either
<code>"MM"</code>, <code>"SM"</code>, or <code>"SMDM"</code>; hence using
<code>compute.outlier.stats = "S"</code> provides <code><a href="#topic+outlierStats">outlierStats</a>()</code>
to a <code><a href="#topic+lmrob.S">lmrob.S</a>()</code> result.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_warn.limit.reject">warn.limit.reject</code></td>
<td>
<p>limit of ratio
<code class="reqn">\#\mbox{rejected} / \#\mbox{obs in level}</code>
above (<code class="reqn">\geq</code>) which a warning is produced.
Set to <code>NULL</code> to disable warning.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_warn.limit.meanrw">warn.limit.meanrw</code></td>
<td>
<p>limit of the mean robustness per factor level
below which (<code class="reqn">\leq</code>) a warning is produced.
Set to <code>NULL</code> to disable warning.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_object">object</code></td>
<td>
<p>an <code>"lmrobCtrl"</code> object, as resulting from a
<code>lmrob.control(*)</code> or an <code>update(&lt;lmrobCtrl&gt;, *)</code> call.</p>
</td></tr>
<tr><td><code id="lmrob.control_+3A_...">...</code></td>
<td>
<p>for </p>

<dl>
<dt><code>lmrob.control()</code>:</dt><dd><p>further arguments to be added as
<code><a href="base.html#topic+list">list</a></code> components to the result, e.g., those to be used in
<code>.vcov.w()</code>.</p>
</dd>
<dt><code>update(object, *)</code>:</dt><dd><p>(named) components from
<code>object</code>, to be <em>modified</em>, <b>not</b> <code>setting = *</code>.</p>
</dd>
</dl>
</td></tr>
</table>


<h3>Details</h3>

<p>The option <code>setting="KS2011"</code> alters the default
arguments.  They are changed to <code>method = "SMDM"</code>, <code>psi = "lqq"</code>,
<code>max.it = 500</code>, <code>k.max = 2000</code>, <code>cov = ".vcov.w"</code>.
The defaults of all the remaining arguments are not changed.
</p>
<p>The option <code>setting="KS2014"</code> builds upon <code>setting="KS2011"</code>.
More arguments are changed to <code>best.r.s = 20, k.fast.s = 2,
  nResample = 1000</code>.  This setting should produce more stable estimates
for designs with <code><a href="base.html#topic+factor">factor</a></code>s.
</p>
<p>By default, and in <code>.Mpsi.tuning.default()</code> and <code>.Mchi.tuning.default()</code>,
<code>tuning.chi</code> and <code>tuning.psi</code> are set to yield an
MM-estimate with breakdown point <code class="reqn">0.5</code> and efficiency of 95% at
the normal.
</p>
<p>If numeric <code>tuning.chi</code> or <code>tuning.psi</code> are specified, say
<code>cc</code>, for <code>psi = "ggw"</code> or <code>"lqq"</code>,
<code><a href="#topic+.psi.const">.psi.const</a>(cc, psi)</code> is used, see its help page.
</p>
<p>To get the defaults, e.g., <code>.Mpsi.tuning.default(psi)</code> is
equivalent to but more efficient than the formerly widely used
<code>lmrob.control(psi = psi)$tuning.psi</code>.
</p>
<p>These defaults are:
</p>

<table>
<tr>
 <td style="text-align: right;">
    <code>psi</code>     </td><td style="text-align: left;"><code>tuning.chi</code>               </td><td style="text-align: left;"><code>tuning.psi</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>bisquare</code></td><td style="text-align: left;"><code>1.54764</code>                  </td><td style="text-align: left;"><code>4.685061</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>welsh</code>   </td><td style="text-align: left;"><code>0.5773502</code>                </td><td style="text-align: left;"><code>2.11</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>ggw</code> 	   </td><td style="text-align: left;"><code>c(-0.5, 1.5, NA, 0.5)</code>    </td><td style="text-align: left;"><code>c(-0.5, 1.5, 0.95, NA)</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>lqq</code>     </td><td style="text-align: left;"><code>c(-0.5, 1.5, NA, 0.5)</code>    </td><td style="text-align: left;"><code>c(-0.5, 1.5, 0.95, NA)</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>optimal</code> </td><td style="text-align: left;"><code>0.4047</code>                   </td><td style="text-align: left;"><code>1.060158</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>hampel</code>  </td><td style="text-align: left;"><code>c(1.5, 3.5, 8)*0.2119163</code> </td><td style="text-align: left;"><code>c(1.5, 3.5, 8)*0.9014</code>
  </td>
</tr>

</table>

<p>The values for the tuning constant for the <code>ggw</code> and <code>lqq</code>
psi functions are specified differently here by a vector with four
elements: minimal slope, b (controlling the bend at the maximum of the curve),
efficiency, breakdown point.
Use <code>NA</code> for an unspecified value of either efficiency or
breakdown point, see examples in the tables (above and below).
For these table examples, the respective &ldquo;inner constants&rdquo; are
stored precomputed, see <code><a href="#topic+.psi.lqq.findc">.psi.lqq.findc</a></code> for more.
</p>
<p>The constants for the <code>"hampel"</code> psi function are chosen to have a
redescending slope of <code class="reqn">-1/3</code>.  Constants for a slope of <code class="reqn">-1/2</code>
would be
</p>

<table>
<tr>
 <td style="text-align: right;">
    <code>psi</code>     </td><td style="text-align: left;"><code>tuning.chi</code>             </td><td style="text-align: left;"><code>tuning.psi</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>"hampel"</code></td><td style="text-align: left;"><code>c(2, 4, 8) * 0.1981319</code> </td><td style="text-align: left;"><code>c(2, 4, 8) * 0.690794</code>
  </td>
</tr>

</table>

<p>Alternative coefficients for an efficiency of 85%
at the normal are given in the table below.
</p>

<table>
<tr>
 <td style="text-align: right;">
    <code>psi</code>		  </td><td style="text-align: left;"><code>tuning.psi</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>bisquare</code>	  </td><td style="text-align: left;"><code>3.443689</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>welsh</code>	  </td><td style="text-align: left;"><code>1.456</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>ggw</code>, <code>lqq</code></td><td style="text-align: left;"><code>c(-0.5, 1.5, 0.85, NA)</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>optimal</code>        </td><td style="text-align: left;"><code>0.8684</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>hampel</code> (-1/3)  </td><td style="text-align: left;"><code>c(1.5, 3.5, 8)* 0.5704545</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
    <code>hampel</code> (-1/2)  </td><td style="text-align: left;"><code>c( 2,  4,  8) * 0.4769578</code>
  </td>
</tr>

</table>



<h3>Value</h3>

<p><code>.Mchi.tuning.default(psi)</code> and <code>.Mpsi.tuning.default(psi)</code>
return a short <code><a href="base.html#topic+numeric">numeric</a></code> vector of tuning constants which
are defaults for the corresponding psi-function, see the <em>Details</em>.
They are based on the named <code><a href="base.html#topic+list">list</a></code>s
<code>.Mchi.tuning.defaults</code> and <code>.Mpsi.tuning.defaults</code>,
respectively.
</p>
<p><code>lmrob.control()</code> returns a named <code><a href="base.html#topic+list">list</a></code> with over
twenty components, corresponding to the arguments, where
<code>tuning.psi</code> and <code>tuning.chi</code> are typically computed, as
<code>.Mpsi.tuning.default(psi)</code> or <code>.Mchi.tuning.default(psi)</code>,
respectively.
It is of <code><a href="base.html#topic+class">class</a></code> <code>"lmrobCtrl"</code> and we provide
<code>print()</code>, <code><a href="stats.html#topic+update">update</a>()</code> and <code><a href="base.html#topic+within">within</a></code> methods.
</p>
<p><code>update(&lt;lmrobCtrl&gt;, ....)</code> does <em>not</em> allow a
<code>setting="&lt;...&gt;"</code> in <code>....</code>.
</p>


<h3>Author(s)</h3>

<p>Matias Salibian-Barrera, Martin Maechler and Manuel Koller</p>


<h3>References</h3>

<p>Koller, M. and Stahel, W.A. (2011)
Sharpening Wald-type inference in robust regression for small samples.
<em>Computational Statistics &amp; Data Analysis</em> <b>55</b>(8), 2504&ndash;2515.
</p>
<p>Koller, M. and Stahel, W.A. (2017)
Nonsingular subsampling for regression S estimators with categorical predictors,
<em>Computational Statistics</em> <b>32</b>(2): 631&ndash;646.
<a href="https://doi.org/10.1007/s00180-016-0679-x">doi:10.1007/s00180-016-0679-x</a>.
Referred as <code>"KS2014"</code> everywhere in <span class="pkg">robustbase</span>;  A shorter first
version, Koller (2012) has been available from <a href="https://arxiv.org/abs/1208.5595">https://arxiv.org/abs/1208.5595</a>.
</p>


<h3>See Also</h3>

  <p><code><a href="#topic+Mpsi">Mpsi</a></code>, etc, for the (fast!) psi function computations;
<code><a href="#topic+lmrob">lmrob</a></code>, also for references and examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Show the default settings:
str(lmrob.control())

## Artificial data for a  simple  "robust t test":
set.seed(17)
y &lt;- y0 &lt;- rnorm(200)
y[sample(200,20)] &lt;- 100*rnorm(20)
gr &lt;- as.factor(rbinom(200, 1, prob = 1/8))
lmrob(y0 ~ 0+gr)

## Use  Koller &amp; Stahel(2011)'s recommendation but a larger  'max.it':
str(ctrl &lt;- lmrob.control("KS2011", max.it = 1000))

str(.Mpsi.tuning.defaults)
stopifnot(identical(.Mpsi.tuning.defaults,
                   sapply(names(.Mpsi.tuning.defaults),
                          .Mpsi.tuning.default)))
## Containing (names!) all our (pre-defined) redescenders:
str(.Mchi.tuning.defaults)

## Difference between settings:
Cdef &lt;- lmrob.control()
C11 &lt;- lmrob.control("KS2011")
C14 &lt;- lmrob.control("KS2014")
str(C14)
## Differences:
diffD &lt;- names(which(!mapply(identical, Cdef,C11, ignore.environment=TRUE)))
diffC &lt;- names(which(!mapply(identical, C11, C14, ignore.environment=TRUE)))
## KS2011 vs KS2014:  Apart from `setting` itself, they only differ in three places:
cbind(KS11 = unlist(C11[diffC[-1]]),
      KS14 = unlist(C14[diffC[-1]]))
##           KS11 KS14
## nResample  500 1000
## best.r.s     2   20
## k.fast.s     1    2
## default vs KS2011: a bit more: setting + 8
str2simpLang &lt;-  function(x) {
    r &lt;- if(is.null(x)) quote((NULL)) else str2lang(deparse(x))
    if(is.call(r)) format(r) else r
}
cbind(deflt= lapply(Cdef[diffD], str2simpLang),
      KS11 = lapply(C11 [diffD], str2simpLang))

## update()ing a lmrob.control() , e.g.,
C14mod &lt;- update(C14, trace.lev = 2) # the same as
C14m.d &lt;- C14; C14m.d$trace.lev &lt;- 2
stopifnot(identical(C14mod, C14m.d))
## changing psi --&gt; updates tuning.{psi,chi}:
C14mp &lt;- update(C14, psi = "hampel", seed=101)
## updating 'method' is "smart" :
C.SMDM &lt;- update(Cdef, method="SMDM")
all.equal(Cdef, C.SMDM) # changed also psi, tuning.{psi,chi} and cov !
chgd &lt;- c("method", "psi", "tuning.chi",  "tuning.psi", "cov")
str(Cdef  [chgd])
str(C.SMDM[chgd])
C14m &lt;- update(C14, method="SMM")
(ae &lt;- all.equal(C14, C14mp))# changed tuning.psi &amp; tuning.chi, too
stopifnot(exprs = {
    identical(C14, update(C14, method="SMDM")) # no change!
    identical(c("psi", "seed", "tuning.chi", "tuning.psi"),
              sort(gsub("[^.[:alpha:]]", "", sub(":.*", "", sub("^Component ", "", ae)))))
    identical(C14m, local({C &lt;- C14; C$method &lt;- "SMM"; C}))
})
##
try( update(C14, setting="KS2011") ) #--&gt; Error: .. not allowed

</code></pre>

<hr>
<h2 id='lmrob.fit'> MM-type estimator for regression </h2><span id='topic+lmrob.fit'></span><span id='topic+lmrob.fit.MM'></span>

<h3>Description</h3>

<p>Compute MM-type estimators of regression:  An S-estimator is
used as starting value, and an M-estimator with fixed scale and
redescending psi-function is used from there. Optionally a D-step
(Design Adaptive Scale estimate) as well as a second M-step is
calculated.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrob.fit(x, y, control, init = NULL, mf = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrob.fit_+3A_x">x</code></td>
<td>
<p>design matrix (<code class="reqn">n \times p</code>) typically including a
column of <code>1</code>s for the intercept.</p>
</td></tr>
<tr><td><code id="lmrob.fit_+3A_y">y</code></td>
<td>
<p>numeric response vector (of length <code class="reqn">n</code>).</p>
</td></tr>
<tr><td><code id="lmrob.fit_+3A_control">control</code></td>
<td>
<p>a list of control parameters as returned
by <code><a href="#topic+lmrob.control">lmrob.control</a></code>, used for both the initial S-estimate
and the subsequent M- and D-estimates.</p>
</td></tr>
<tr><td><code id="lmrob.fit_+3A_init">init</code></td>
<td>
<p>optional <code><a href="base.html#topic+list">list</a></code> of initial estimates.  See
<em>Details</em>.</p>
</td></tr>
<tr><td><code id="lmrob.fit_+3A_mf">mf</code></td>
<td>
<p>defunct.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is the basic fitting function for MM-type estimation,
called by <code><a href="#topic+lmrob">lmrob</a></code> and typically not to be used on its own.
</p>
<p>If given, <code>init</code> must be a list of initial estimates containing
at least the initial coefficients and scale as <code>coefficients</code> and
<code>scale</code>.  Otherwise it calls <code><a href="#topic+lmrob.S">lmrob.S</a>(..)</code> and uses it
as initial estimator.
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>fitted.values</code></td>
<td>
<p><code class="reqn">X \beta</code>, i.e., <code>X %*% coefficients</code>.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the raw residuals, <code>y - fitted.values</code></p>
</td></tr>
<tr><td><code>rweights</code></td>
<td>
<p>robustness weights derived from the final M-estimator
residuals (even when not converged).</p>
</td></tr>
<tr><td><code>rank</code></td>
<td>
</td></tr>
<tr><td><code>degree.freedom</code></td>
<td>
<p><code>n - rank</code></p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>estimated regression coefficient vector</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>the robustly estimated error standard deviation</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>variance-covariance matrix of <code>coefficients</code>, if the
RWLS iterations have converged (and <code>control$cov</code> is not <code>"none"</code>).</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
</td></tr>
<tr><td><code>iter</code></td>
<td>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>logical indicating if the RWLS iterations have converged.</p>
</td></tr>
<tr><td><code>init.S</code></td>
<td>
<p>the whole initial S-estimator result, including its own
<code>converged</code> flag, see <code><a href="#topic+lmrob.S">lmrob.S</a></code> (only for MM-estimates).</p>
</td></tr>
<tr><td><code>init</code></td>
<td>
<p>A similar list that contains the results of intermediate
estimates (not for MM-estimates).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Matias Salibian-Barrera, Martin Maechler and Manuel Koller</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob">lmrob</a></code>,
<code><a href="#topic+lmrob..M..fit">lmrob..M..fit</a></code>,
<code><a href="#topic+lmrob..D..fit">lmrob..D..fit</a></code>,
<code><a href="#topic+lmrob.S">lmrob.S</a></code>
</p>

<hr>
<h2 id='lmrob.lar'>Least Absolute Residuals / L1 Regression</h2><span id='topic+lmrob.lar'></span>

<h3>Description</h3>

<p>To compute least absolute residuals (LAR) or  &ldquo;L1&rdquo; regression,
<code>lmrob.lar</code> implements the routine L1 in Barrodale and Roberts (1974),
which is based on the simplex method of linear programming.  It is a
copy of <code>lmRob.lar</code> (in early 2012) from the <a href="https://CRAN.R-project.org/package=robust"><span class="pkg">robust</span></a> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrob.lar(x, y, control, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrob.lar_+3A_x">x</code></td>
<td>
<p>numeric matrix for the predictors.</p>
</td></tr>
<tr><td><code id="lmrob.lar_+3A_y">y</code></td>
<td>
<p>numeric vector for the response.</p>
</td></tr>
<tr><td><code id="lmrob.lar_+3A_control">control</code></td>
<td>
<p><code><a href="base.html#topic+list">list</a></code> as returned by
<code><a href="#topic+lmrob.control">lmrob.control</a>()</code> .</p>
</td></tr>
<tr><td><code id="lmrob.lar_+3A_...">...</code></td>
<td>
<p>(unused but needed when called as <code>init(x,y,ctrl, mf)</code>
from <code><a href="#topic+lmrob">lmrob</a>()</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method is used for computing the M-S estimate and typically not
to be used on its own.
</p>
<p>A description of the Fortran subroutines used can be found in Marazzi
(1993).  In the book, the main method is named <code>RILARS</code>.
</p>


<h3>Value</h3>

<p>A list that includes the following components:
</p>
<table>
<tr><td><code>coef</code></td>
<td>
<p>The L1-estimate of the coefficient vector</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>The residual scale estimate (mad)</p>
</td></tr>
<tr><td><code>resid</code></td>
<td>
<p>The residuals</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>The number of iterations required by the simplex
algorithm</p>
</td></tr>
<tr><td><code>status</code></td>
<td>
<p>Return status (0: optimal, but non unique solution, 1:
optimal unique solution)</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Convergence status (always <code>TRUE</code>), needed for
<code><a href="#topic+lmrob.fit">lmrob.fit</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Koller
</p>


<h3>References</h3>

<p>Marazzi, A. (1993).
<em>Algorithms, routines, and S functions for robust statistics</em>.
Wadsworth &amp; Brooks/Cole, Pacific Grove, CA.
</p>


<h3>See Also</h3>

<p><code><a href="quantreg.html#topic+rq">rq</a></code> from CRAN package <a href="https://CRAN.R-project.org/package=quantreg"><span class="pkg">quantreg</span></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(stackloss)
X &lt;- model.matrix(stack.loss ~ . , data = stackloss)
y &lt;- stack.loss
(fm.L1 &lt;- lmrob.lar(X, y))
with(fm.L1, stopifnot(converged
  , status == 1L
  , all.equal(scale, 1.5291576438)
  , sum(abs(residuals) &lt; 1e-15) == 4 # p=4 exactly fitted obs.
))
</code></pre>

<hr>
<h2 id='lmrob.M.S'> M-S regression estimators </h2><span id='topic+lmrob.M.S'></span>

<h3>Description</h3>

<p>Computes an M-S-estimator for linear regression using the
&ldquo;M-S&rdquo; algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrob.M.S(x, y, control, mf,
          split = splitFrame(mf, x, control$split.type))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrob.M.S_+3A_x">x</code></td>
<td>
<p>numeric matrix (a <code><a href="stats.html#topic+model.matrix">model.matrix</a></code>) of the
predictors.</p>
</td></tr>
<tr><td><code id="lmrob.M.S_+3A_y">y</code></td>
<td>
<p>numeric vector for the response </p>
</td></tr>
<tr><td><code id="lmrob.M.S_+3A_control">control</code></td>
<td>
<p><code><a href="base.html#topic+list">list</a></code> as returned by <code><a href="#topic+lmrob.control">lmrob.control</a></code>.</p>
</td></tr>
<tr><td><code id="lmrob.M.S_+3A_mf">mf</code></td>
<td>
<p>a model frame as returned by <code><a href="stats.html#topic+model.frame">model.frame</a></code>.</p>
</td></tr>
<tr><td><code id="lmrob.M.S_+3A_split">split</code></td>
<td>
<p>(optional) list as returned by <code><a href="#topic+splitFrame">splitFrame</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used by <code><a href="#topic+lmrob">lmrob</a></code> and not intended to be
used on its own (because an M-S-estimator has too low efficiency
&lsquo;on its own&rsquo;).
</p>
<p>An M-S estimator is a combination of an S-estimator for the
continuous variables and an L1-estimator (i.e. an M-estimator with
<code class="reqn">\psi(t) = sign(t)</code>) for the categorical variables.
</p>
<p>The S-estimator is estimated using a subsampling algorithm.  If the
model includes interactions between categorical (<code><a href="base.html#topic+factor">factor</a></code>)
and continuous variables, the subsampling algorithm might fail.  In
this case, one can choose to assign the interaction to the categorical
side of variables rather than to the continuous side.  This can be
accomplished via the control argument <code>split.type</code> or by
specifying <code>split</code>, see <code><a href="#topic+splitFrame">splitFrame</a></code>.
</p>
<p>Note that the return status <code>converged</code> does not refer to the
actual convergence status.  The algorithm used does not guarantee
convergence and thus true convergence is almost never reached. This
is, however, not a problem if the estimate is only used as initial
estimate part of an MM or SMDM estimate.
</p>
<p>The algorithm sometimes produces the warning message &ldquo;Skipping
design matrix equilibration (dgeequ): row ?? is exactly zero.&rdquo;. This
is just an artifact of the algorithm and can be ignored safely.
</p>


<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>numeric vector (length <code class="reqn">p</code>) of M-S-regression
coefficient estimates.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>the M-S-scale residual estimate</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>numeric vector (legnth <code class="reqn">n</code>) of the residuals.</p>
</td></tr>
<tr><td><code>rweights</code></td>
<td>
<p>numeric vector (length <code class="reqn">n</code>) of the robustness weights.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>the same list as the <code>control</code> argument.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>Convergence status (always <code>TRUE</code>), needed for
<code><a href="#topic+lmrob.fit">lmrob.fit</a></code>.</p>
</td></tr>
<tr><td><code>descent.cov</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> with the true <code>m_s_descent</code>
convergence status.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Koller
</p>


<h3>References</h3>

<p>Maronna, R. A., and Yohai, V. J. (2000).
Robust regression with both continuous and categorical predictors.
<em>Journal of Statistical Planning and Inference</em> <b>89</b>, 197&ndash;214.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob">lmrob</a></code>; for a description of the available split types, see
<code><a href="#topic+splitFrame">splitFrame</a></code>.
</p>
<p><code><a href="robust.html#topic+lmRob">lmRob</a></code> in package <a href="https://CRAN.R-project.org/package=robust"><span class="pkg">robust</span></a> uses a version of
the M-S algorithm automatically when the formula contains factors.
Our version however follows Maronna and Yohai (2000) more closely.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(education)
education &lt;- within(education, Region &lt;- factor(Region))
flm &lt;- lm(Y ~ Region + X1 + X2 + X3, education)
x &lt;- model.matrix(flm)
y &lt;- education$Y # == model.response(model.frame(flm))
set.seed(17)
f.MS &lt;- lmrob.M.S(x, y, control = lmrob.control(),
                  mf = model.frame(flm))

## The typical use of the "M-S" estimator -- as initial estimate :
fmMS &lt;- lmrob(Y ~ Region + X1 + X2 + X3, education,
              init = "M-S")
</code></pre>

<hr>
<h2 id='lmrob.S'> S-regression estimators </h2><span id='topic+lmrob.S'></span>

<h3>Description</h3>

<p>Computes an S-estimator for linear regression,
using the &ldquo;fast S&rdquo; algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lmrob.S(x, y, control,
        trace.lev = control$trace.lev,
        only.scale = FALSE, mf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lmrob.S_+3A_x">x</code></td>
<td>
<p>design matrix (<code class="reqn">n \times p</code>)</p>
</td></tr>
<tr><td><code id="lmrob.S_+3A_y">y</code></td>
<td>
<p>numeric vector of responses (or residuals for <code>only.scale=TRUE</code>).</p>
</td></tr>
<tr><td><code id="lmrob.S_+3A_control">control</code></td>
<td>
<p> list as returned by <code><a href="#topic+lmrob.control">lmrob.control</a></code>; the
following components are used for <code>lmrob.S()</code>:
<code>"trace.lev"</code>, 
<code>"nResample"</code>,
<code>"groups"</code>,
<code>"n.group"</code>,
<code>"fast.s.large.n"</code>,
<code>"seed"</code>,
<code>"bb"</code>,
<code>"psi"</code>, <code>"tuning.chi"</code>,
<code>"best.r.s"</code>,
<code>"k.fast.s"</code>,
<code>"k.max"</code>,
<code>"maxit.scale"</code>,
<code>"refine.tol"</code>, <code>"solve.tol"</code>, <code>"scale.tol"</code>,
<code>"mts"</code>,
<code>"subsampling"</code>.
</p>
</td></tr>
<tr><td><code id="lmrob.S_+3A_trace.lev">trace.lev</code></td>
<td>
<p>integer indicating if the progress of the algorithm
should be traced (increasingly); default <code>trace.lev = 0</code> does
no tracing.</p>
</td></tr>
<tr><td><code id="lmrob.S_+3A_only.scale">only.scale</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code> indicating if only the scale
of <code>y</code> should be computed.  In this case, <code>y</code> will
typically contain <em>residuals</em>.</p>
</td></tr>

<tr><td><code id="lmrob.S_+3A_mf">mf</code></td>
<td>
<p>defunct.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is used by <code><a href="#topic+lmrob.fit">lmrob.fit</a></code> and typically not
to be used on its own (because an S-estimator has too low
efficiency &lsquo;on its own&rsquo;).
</p>
<p>By default, the subsampling algorithm uses a customized LU
decomposition which ensures a non singular subsample (if this is at
all possible). This makes the Fast-S algorithm also feasible for
categorical and mixed continuous-categorical data.
</p>
<p>One can revert to the old subsampling scheme by setting the parameter
<code>subsampling</code> in <code>control</code> to <code>"simple"</code>.
</p>


<h3>Value</h3>

<p>By default (when <code>only.scale</code> is false), a list with components
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>numeric vector (length <code class="reqn">p</code>) of S-regression coefficient estimates.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>the S-scale residual estimate</p>
</td></tr>


<tr><td><code>fitted.values</code></td>
<td>
<p>numeric vector (length <code class="reqn">n</code>) of the fitted
values.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>numeric vector (length <code class="reqn">n</code>) of the residuals.</p>
</td></tr>
<tr><td><code>rweights</code></td>
<td>
<p>numeric vector (length <code class="reqn">n</code>) of the robustness weights.</p>
</td></tr>
<tr><td><code>k.iter</code></td>
<td>
<p>(maximal) number of refinement iterations used.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>logical indicating if <b>all</b> refinement
iterations had converged.</p>
</td></tr>
<tr><td><code>control</code></td>
<td>
<p>the same list as the <code>control</code> argument.</p>
</td></tr>
</table>
<p>If <code>only.scale</code> is true, the computed scale (a number) is returned.
</p>


<h3>Author(s)</h3>

<p> Matias Salibian-Barrera and Manuel Koller; Martin Maechler for
minor new options and more documentation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob">lmrob</a></code>, also for references.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(33)
x1 &lt;- sort(rnorm(30)); x2 &lt;- sort(rnorm(30)); x3 &lt;- sort(rnorm(30))
X. &lt;- cbind(x1, x2, x3)
y &lt;-  10 + X. %*% (10*(2:4)) + rnorm(30)/10
y[1] &lt;- 500   # a moderate outlier
X.[2,1] &lt;- 20 # an X outlier
X1  &lt;- cbind(1, X.)

(m.lm &lt;- lm(y ~ X.))
set.seed(12)
m.lmS &lt;- lmrob.S(x=X1, y=y,
                 control = lmrob.control(nRes = 20), trace.lev=1)
m.lmS[c("coefficients","scale")]
all.equal(unname(m.lmS$coef), 10 * (1:4), tolerance = 0.005)
stopifnot(all.equal(unname(m.lmS$coef), 10 * (1:4), tolerance = 0.005),
          all.equal(m.lmS$scale, 1/10, tolerance = 0.09))

## only.scale = TRUE:  Compute the S scale, given residuals;
s.lmS &lt;- lmrob.S(X1, y=residuals(m.lmS), only.scale = TRUE,
                 control = lmrob.control(trace.lev = 3))
all.equal(s.lmS, m.lmS$scale) # close: 1.89e-6 [64b Lnx]
</code></pre>

<hr>
<h2 id='los'> Length of Stay Data </h2><span id='topic+los'></span>

<h3>Description</h3>

<p>Length of stay for 201 patients that stayed at the University Hospital
of Lausanne during the year 2000.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(los, package="robustbase")</code></pre>


<h3>Format</h3>

<p>Vector of integer values giving the length of stay (days):
</p>
<p>int [1:201] 16 13 17 4 15 24 59 18 33 8 ...
</p>


<h3>Details</h3>

<p>These data may be used to estimate and predict the total resource
consumption of this group of patients.
</p>
<p>Cf. Ruffieux, Paccaud and Marazzi (2000).
</p>


<h3>Source</h3>

<p>The data were kindly provided by A. Marazzi.
</p>
<p>Cf. Hubert, M. and Vandervieren, E. (2006), p. 13&ndash;15.
</p>


<h3>References</h3>

<p>Ruffieux, C., Paccaud, F. and A. Marazzi (2000)
Comparing rules for truncating hospital length of stay;
<em>Casemix Quarterly</em> <b>2</b>, n. 1.
</p>
<p>See also those for <code><a href="#topic+adjbox">adjbox</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> summary(los) # quite skewed, with median(.) = 8
 plot(table(los))
 boxplot(los, horizontal=TRUE, add=TRUE, col = "red", axes=FALSE)
 ##-&gt; "outliers" instead of "just skewed"

 hist(log(los))
 boxplot(log(los), add=TRUE, col=2, border=2, horizontal = TRUE, at = -1)

 ## Hubert and Vandervieren (2006), p. 15, Fig. 11.
 adjbox(los, col = "gray", staplecol="red", outcol = "red",
        main = "(Skewness-)Adjusted and original boxplot for 'los' data")
 boxplot(los, add = TRUE, staplewex= 0.2, outcex= 0.5, outpch= 4,
         staplecol = "blue", outcol = "blue", staplelwd=2)
 legend("topright", c("adjbox(los)", "boxplot(los)"),
        col=c("red","blue"), lwd = 1:2, bty="n")
</code></pre>

<hr>
<h2 id='ltsReg'>Least Trimmed Squares Robust (High Breakdown) Regression</h2><span id='topic+ltsReg'></span><span id='topic+ltsReg.default'></span><span id='topic+ltsReg.formula'></span><span id='topic+print.lts'></span>

<h3>Description</h3>

<p>Carries out least trimmed squares (LTS) robust (high breakdown point)
regression.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ltsReg(x, ...)

## S3 method for class 'formula'
ltsReg(formula, data, subset, weights, na.action,
       model = TRUE, x.ret = FALSE, y.ret = FALSE,
       contrasts = NULL, offset, ...)

## Default S3 method:
ltsReg(x, y, intercept = TRUE, alpha = , nsamp = , adjust = ,
       mcd = TRUE, qr.out = FALSE, yname = NULL,
       seed = , trace = , use.correction = , wgtFUN = , control = rrcov.control(),
       ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ltsReg_+3A_formula">formula</code></td>
<td>
<p>a <code><a href="stats.html#topic+formula">formula</a></code> of the form <code>y ~ x1 + x2 + ...</code>.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_data">data</code></td>
<td>
<p>data frame from which variables specified in
<code>formula</code> are to be taken.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations
to be used in the fitting process.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used
in the fitting process. <b>NOT USED YET</b>.



</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen
when the data contain <code>NA</code>s.  The default is set by
the <code>na.action</code> setting of <code><a href="base.html#topic+options">options</a></code>, and is
<code><a href="stats.html#topic+na.fail">na.fail</a></code> if that is unset.  The &ldquo;factory-fresh&rdquo;
default is <code><a href="stats.html#topic+na.omit">na.omit</a></code>.  Another possible value is
<code>NULL</code>, no action.  Value <code><a href="stats.html#topic+na.exclude">na.exclude</a></code> can be useful.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_model">model</code>, <code id="ltsReg_+3A_x.ret">x.ret</code>, <code id="ltsReg_+3A_y.ret">y.ret</code></td>
<td>
<p><code><a href="base.html#topic+logical">logical</a></code>s indicating if the
model frame, the model matrix and the response are to be returned,
respectively.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_contrasts">contrasts</code></td>
<td>
<p>an optional list.  See the <code>contrasts.arg</code>
of <code><a href="stats.html#topic+model.matrix.default">model.matrix.default</a></code>.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an <em>a priori</em>
known component to be included in the linear predictor
during fitting.  An <code><a href="stats.html#topic+offset">offset</a></code> term can be included in the
formula instead or as well, and if both are specified their sum is used.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_x">x</code></td>
<td>
<p>a matrix or data frame containing the explanatory variables.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_y">y</code></td>
<td>
<p>the response: a vector of length the number of rows of <code>x</code>.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="ltsReg_+3A_intercept">intercept</code></td>
<td>
<p>if true, a model with constant term will be
estimated; otherwise no constant term will be included.  Default is
<code>intercept = TRUE</code>  </p>
</td></tr>
<tr><td><code id="ltsReg_+3A_alpha">alpha</code></td>
<td>
<p>the percentage (roughly) of squared residuals whose sum will be
minimized, by default 0.5.  In general, <code>alpha</code> must between
0.5 and 1.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_nsamp">nsamp</code></td>
<td>
<p>number of subsets used for initial estimates or
<code>"best"</code> or <code>"exact"</code>.  Default is <code>nsamp = 500</code>.  For
<code>nsamp="best"</code> exhaustive enumeration is done, as long as the
number of trials does not exceed 5000.  For <code>"exact"</code>,
exhaustive enumeration will be attempted however many samples are needed.
In this case a warning message will be displayed saying that the
computation can take a very long time. </p>
</td></tr>
<tr><td><code id="ltsReg_+3A_adjust">adjust</code></td>
<td>
<p>whether to perform intercept adjustment at each step.
Since this can be time consuming, the default is <code>adjust = FALSE</code>.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_mcd">mcd</code></td>
<td>
<p>whether to compute robust distances using Fast-MCD.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_qr.out">qr.out</code></td>
<td>
<p>whether to return the QR decomposition (see
<code><a href="Matrix.html#topic+qr">qr</a></code>); defaults to false.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_yname">yname</code></td>
<td>
<p>the name of the dependent variable.  Default is <code>yname = NULL</code></p>
</td></tr>
<tr><td><code id="ltsReg_+3A_seed">seed</code></td>
<td>
<p>initial seed for random generator, like
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code>, see <code><a href="#topic+rrcov.control">rrcov.control</a></code>.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_trace">trace</code></td>
<td>
<p>logical (or integer) indicating if intermediate results
should be printed; defaults to <code>FALSE</code>; values <code class="reqn">\ge 2</code>
also produce print from the internal (Fortran) code.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_use.correction">use.correction</code></td>
<td>
<p> whether to use finite sample correction factors.
Default is <code>use.correction=TRUE</code></p>
</td></tr>
<tr><td><code id="ltsReg_+3A_wgtfun">wgtFUN</code></td>
<td>
<p>a character string or <code><a href="base.html#topic+function">function</a></code>, specifying
how the weights for the reweighting step should be computed.
Up to April 2013, the only option has been the original proposal in
(1999), now specified by <code>wgtFUN = "01.original"</code> (or via <code>control</code>).</p>
</td></tr>

<tr><td><code id="ltsReg_+3A_control">control</code></td>
<td>
<p>a list with estimation options - same as these provided
in the function specification.  If the control object is supplied, the
parameters from it will be used.  If parameters are passed also in the
invocation statement, they will override the corresponding elements of
the control object.</p>
</td></tr>
<tr><td><code id="ltsReg_+3A_...">...</code></td>
<td>
<p>arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The LTS regression method minimizes the sum of the <code class="reqn">h</code> smallest
squared residuals, where <code class="reqn">h &gt; n/2</code>, i.e. at least half the number of
observations must be used.  The default value of <code class="reqn">h</code> (when
<code>alpha=1/2</code>) is roughly <code class="reqn">n / 2</code>, more precisely,
<code>(n+p+1) %/% 2</code> where <code class="reqn">n</code> is the
total number of observations, but by setting <code>alpha</code>, the user
may choose higher values up to n, where
<code class="reqn">h = h(\alpha,n,p) =</code> <code><a href="#topic+h.alpha.n">h.alpha.n</a>(alpha,n,p)</code>.  The LTS
estimate of the error scale is given by the minimum of the objective
function multiplied by a consistency factor
and a finite sample correction factor &ndash; see Pison et al. (2002)
for details.  The rescaling factors for the raw and final estimates are
returned also in the vectors <code>raw.cnp2</code> and <code>cnp2</code> of
length 2 respectively.  The finite sample corrections can be suppressed
by setting <code>use.correction=FALSE</code>.  The computations are performed
using the Fast LTS algorithm proposed by Rousseeuw and Van Driessen (1999).
</p>
<p>As always, the formula interface has an implied intercept term which can be
removed either by <code>y ~ x - 1</code> or <code>y ~ 0 + x</code>.  See
<code><a href="stats.html#topic+formula">formula</a></code> for more details.
</p>


<h3>Value</h3>

<p>The function <code>ltsReg</code> returns an object of class <code>"lts"</code>.
The <code><a href="base.html#topic+summary">summary</a></code> method function is used to obtain (and
print) a summary table of the results, and <code><a href="#topic+ltsPlot">plot</a>()</code>
can be used to plot them, see the the specific help pages.
</p>
<p>The generic accessor functions <code><a href="stats.html#topic+coefficients">coefficients</a></code>,
<code><a href="stats.html#topic+fitted.values">fitted.values</a></code> and <code><a href="stats.html#topic+residuals">residuals</a></code>
extract various useful features of the value returned by
<code>ltsReg</code>.
</p>
<p>An object of class <code>lts</code> is a <code><a href="base.html#topic+list">list</a></code> containing at
least the following components:
</p>
<table>
<tr><td><code>crit</code></td>
<td>

<p>the value of the objective function of the LTS regression method,
i.e., the sum of the <code class="reqn">h</code> smallest squared raw residuals.
</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>

<p>vector of coefficient estimates (including the intercept by default when
<code>intercept=TRUE</code>), obtained after reweighting.
</p>
</td></tr>
<tr><td><code>best</code></td>
<td>

<p>the best subset found and used for computing the raw estimates, with
<code><a href="base.html#topic+length">length</a>(best) == quan = <a href="#topic+h.alpha.n">h.alpha.n</a>(alpha,n,p)</code>.
</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>vector like <code>y</code> containing the fitted values
of the response after reweighting.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>vector like <code>y</code> containing the residuals from
the weighted least squares regression.</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>scale estimate of the reweighted residuals.  </p>
</td></tr>
<tr><td><code>alpha</code></td>
<td>
<p>same as the input parameter <code>alpha</code>.</p>
</td></tr>
<tr><td><code>quan</code></td>
<td>
<p>the number <code class="reqn">h</code> of observations which have determined
the least trimmed squares estimator.</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>same as the input parameter <code>intercept</code>.</p>
</td></tr>
<tr><td><code>cnp2</code></td>
<td>
<p>a vector of length two containing the consistency
correction factor and the finite sample correction factor of
the final estimate of the error scale.</p>
</td></tr>
<tr><td><code>raw.coefficients</code></td>
<td>
<p>vector of raw coefficient estimates (including
the intercept, when <code>intercept=TRUE</code>).</p>
</td></tr>
<tr><td><code>raw.scale</code></td>
<td>
<p>scale estimate of the raw residuals.</p>
</td></tr>
<tr><td><code>raw.resid</code></td>
<td>
<p>vector like <code>y</code> containing the raw residuals
from the regression.</p>
</td></tr>
<tr><td><code>raw.cnp2</code></td>
<td>
<p>a vector of length two containing the consistency
correction factor and the finite sample correction factor of the
raw estimate of the error scale.</p>
</td></tr>
<tr><td><code>lts.wt</code></td>
<td>

<p>vector like y containing weights that can be used in a weighted
least squares.  These weights are 1 for points with reasonably
small residuals, and 0 for points with large residuals.
</p>
</td></tr>
<tr><td><code>raw.weights</code></td>
<td>

<p>vector containing the raw weights based on the raw residuals and raw scale.
</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>character string naming the method (Least Trimmed Squares).</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>the input data as a matrix (including intercept column if
applicable).</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the response variable as a vector.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Valentin Todorov <a href="mailto:valentin.todorov@chello.at">valentin.todorov@chello.at</a>, based on
work written for S-plus by Peter Rousseeuw and Katrien van Driessen
from University of Antwerp.
</p>


<h3>References</h3>

<p>Peter J. Rousseeuw (1984), Least Median of Squares Regression.
<em>Journal of the American Statistical Association</em> <b>79</b>, 871&ndash;881.
</p>
<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection.</em> Wiley.
</p>
<p>P. J. Rousseeuw and K. van Driessen (1999)
A fast algorithm for the minimum covariance determinant estimator.
<em>Technometrics</em> <b>41</b>, 212&ndash;223.
</p>
<p>Pison, G., Van Aelst, S., and Willems, G. (2002)
Small Sample Corrections for LTS and MCD.
<em>Metrika</em> <b>55</b>, 111-123.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covMcd">covMcd</a></code>;
<code><a href="#topic+summary.lts">summary.lts</a></code> for summaries,
<code><a href="#topic+lmrob">lmrob</a>()</code> for alternative robust estimator with HBDP.
</p>
<p>The generic functions <code><a href="stats.html#topic+coef">coef</a></code>, <code><a href="stats.html#topic+residuals">residuals</a></code>,
<code><a href="stats.html#topic+fitted">fitted</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(heart)
## Default method works with 'x'-matrix and y-var:
heart.x &lt;- data.matrix(heart[, 1:2]) # the X-variables
heart.y &lt;- heart[,"clength"]
ltsReg(heart.x, heart.y)

data(stackloss)
ltsReg(stack.loss ~ ., data = stackloss)
</code></pre>

<hr>
<h2 id='mc'>Medcouple, a Robust Measure of Skewness</h2><span id='topic+mc'></span>

<h3>Description</h3>

<p>Compute the &lsquo;medcouple&rsquo;, a <em>robust</em> concept and estimator
of skewness.  The medcouple is defined as a scaled median difference
of the left and right half of distribution, and hence <em>not</em> based
on the third moment as the classical skewness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mc(x, na.rm = FALSE, doReflect = (length(x) &lt;= 100),
   doScale = FALSE,     # was hardwired=TRUE, then default=TRUE
   c.huberize = 1e11,   # was implicitly = Inf originally
   eps1 = 1e-14, eps2 = 1e-15,   # &lt;&lt; new in 0.93-2 (2018-07..)
   maxit = 100, trace.lev = 0, full.result = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mc_+3A_x">x</code></td>
<td>
<p>a numeric vector</p>
</td></tr>
<tr><td><code id="mc_+3A_na.rm">na.rm</code></td>
<td>
<p>logical indicating how missing values (<code><a href="base.html#topic+NA">NA</a></code>s)
should be dealt with.</p>
</td></tr>
<tr><td><code id="mc_+3A_doreflect">doReflect</code></td>
<td>
<p>logical indicating if the internal MC should also be
computed on the <em>reflected</em> sample <code>-x</code>, with final result
<code>(mc.(x) - mc.(-x))/2</code>.  This makes sense since the internal
MC, <code>mc.()</code> computes the himedian() which can differ slightly from
the median.</p>
</td></tr>
<tr><td><code id="mc_+3A_doscale">doScale</code></td>
<td>
<p>logical indicating if the internal algorithm should
also <em>scale</em> the data (using the most distant value from the
median which is unrobust and numerically dangerous); scaling has been
hardwired in the original algorithm and <span class="rlang"><b>R</b></span>'s <code>mc()</code> till summer
2018, where it became the default.  Since <span class="pkg">robustbase</span> version 0.95-0,
March 2022, the default is <code>FALSE</code>.  As this may change the
result, a message is printed about the new default, once per <span class="rlang"><b>R</b></span>
session.  You can suppress the message by specifying <code>doScale = *</code>
explicitly, or, by setting <code><a href="base.html#topic+options">options</a>(mc_doScale_quiet=TRUE)</code>.</p>
</td></tr>
<tr><td><code id="mc_+3A_c.huberize">c.huberize</code></td>
<td>
<p>a positive number (default: <code>1e11</code>) used to
stabilize the sample via <code>x &lt;- <a href="#topic+huberize">huberize</a>(x, c = c.huberize)</code>
for the <code>mc()</code> computations in the case of a nearly degenerate
sample (many observations practically equal to the median) or very
extreme outliers.  In previous versions of <span class="pkg">robustbase</span> no such
huberization was applied which is equivalent to <code>c.huberize = Inf</code>.</p>
</td></tr>
<tr><td><code id="mc_+3A_eps1">eps1</code>, <code id="mc_+3A_eps2">eps2</code></td>
<td>
<p>tolerance in the algorithm; <code>eps1</code> is used as a  for
convergence tolerance, where <code>eps2</code> is only used in the internal
<code>h_kern()</code> function to prevent underflow to zero, so could be
considerably smaller.  The original code implicitly <em>hard
coded</em> in C <code>eps1 := eps2 := 1e-13</code>;  only change with care!</p>
</td></tr>
<tr><td><code id="mc_+3A_maxit">maxit</code></td>
<td>
<p>maximal number of iterations; typically a few should be
sufficient.</p>
</td></tr>
<tr><td><code id="mc_+3A_trace.lev">trace.lev</code></td>
<td>
<p>integer specifying how much diagnostic output the
algorithm (in C) should produce.  No output by default, most output
for <code>trace.lev = 5</code>.</p>
</td></tr>
<tr><td><code id="mc_+3A_full.result">full.result</code></td>
<td>
<p>logical indicating if the full return values (from
C) should be returned as a list via <code>attr(*, "mcComp")</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a number between -1 and 1, which is the medcouple, <code class="reqn">MC(x)</code>.
For <code>r &lt;- mc(x, full.result = TRUE, ....)</code>, then
<code>attr(r, "mcComp")</code> is a list with components
</p>
<table>
<tr><td><code>medc</code></td>
<td>
<p>the medcouple  <code class="reqn">mc.(x)</code>.</p>
</td></tr>
<tr><td><code>medc2</code></td>
<td>
<p>the medcouple <code class="reqn">mc.(-x)</code> if <code>doReflect=TRUE</code>.</p>
</td></tr>
<tr><td><code>eps</code></td>
<td>
<p>tolerances used.</p>
</td></tr>
<tr><td><code>iter</code>, <code>iter2</code></td>
<td>
<p>number of iterations used.</p>
</td></tr>
<tr><td><code>converged</code>, <code>converged2</code></td>
<td>
<p>logical specifying &ldquo;convergence&rdquo;.</p>
</td></tr>
</table>


<h3>Convergence Problems</h3>

<p>For extreme cases there were convergence problems which should not
happen anymore as we now use <code>doScale=FALSE</code> and huberization (when
<code>c.huberize &lt; Inf</code>).
</p>



<p>The original algorithm and <code>mc(*, doScale=TRUE)</code> not only centers
the data around the median but
also scales them by the extremes which may have a negative effect
e.g., when changing an extreme outlier to even more extreme, the
result changes wrongly; see the 'mc10x' example.
</p>


<h3>Author(s)</h3>

<p>Guy Brys; modifications by Tobias Verbeke and bug fixes and
extensions by Manuel Koller and Martin Maechler.
</p>
<p>The new default <code>doScale=FALSE</code>, and the new <code>c.huberize</code> were
introduced as consequence of Lukas Graz' BSc thesis.
</p>


<h3>References</h3>

<p>Guy Brys, Mia Hubert and Anja Struyf (2004)
A Robust Measure of Skewness;
<em>JCGS</em> <b>13</b> (4), 996&ndash;1017.
</p>
<p>Hubert, M. and Vandervieren, E. (2008).
An adjusted boxplot for skewed distributions,
<em>Computational Statistics and Data Analysis</em> <b>52</b>, 5186&ndash;5201.
</p>
<p>Lukas Graz (2021). Improvement of the Algorithms for the Medcoule and the
Adjusted Outlyingness; unpublished BSc thesis, supervised by M.Maechler, ETH Zurich.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Qn">Qn</a></code> for a robust measure of scale (aka
&ldquo;dispersion&rdquo;), ....
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mc(1:5) # 0 for a symmetric sample

x1 &lt;- c(1, 2, 7, 9, 10)
mc(x1) # = -1/3

data(cushny)
mc(cushny) # 0.125

stopifnot(mc(c(-20, -5, -2:2, 5, 20)) == 0,
          mc(x1, doReflect=FALSE) ==  -mc(-x1, doReflect=FALSE),
          all.equal(mc(x1, doReflect=FALSE), -1/3, tolerance = 1e-12))

## Susceptibility of the current algorithm to large outliers :
dX10 &lt;- function(X) c(1:5,7,10,15,25, X) # generate skewed size-10 with 'X'
x &lt;- c(10,20,30, 100^(1:20))
## (doScale=TRUE, c.huberize=Inf)  were (implicit) defaults in earlier {robustbase}:
(mc10x &lt;- vapply(x, function(X) mc(dX10(X), doScale=TRUE, c.huberize=Inf), 1))
## limit X -&gt; Inf  should be 7/12 = 0.58333...  but that "breaks down a bit" :
plot(x, mc10x, type="b", main = "mc( c(1:5,7,10,15,25, X) )", xlab="X", log="x")
## The new behavior is much preferable {shows message about new 'doScale=FALSE'}:
(mc10N &lt;- vapply(x, function(X) mc(dX10(X)), 1))
lines(x, mc10N, col=adjustcolor(2, 3/4), lwd=3)
mtext("mc(*, c.huberize=1e11)",  col=2)
stopifnot(all.equal(c(4, 6, rep(7, length(x)-2))/12, mc10N))
## Here, huberization already solves the issue:
mc10NS &lt;- vapply(x, function(X) mc(dX10(X), doScale=TRUE), 1)
stopifnot(all.equal(mc10N, mc10NS))
</code></pre>

<hr>
<h2 id='milk'>Daudin's Milk Composition Data</h2><span id='topic+milk'></span>

<h3>Description</h3>

<p>Daudin et al.(1988) give 8 readings on the composition of 86
containers of milk.  They speak about 85 observations, but this
can be explained with the fact that observations 63 and 64 are
identical (as noted by Rocke (1996)).
</p>
<p>The data set was used for analysing the stability of principal
component analysis by the bootstrap method.  In the same context, but
using high breakdown point robust PCA, these data were analysed by
Todorov et al. (1994).  Atkinson (1994) used these data for ilustration
of the forward search algorithm for identifying of multiple outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(milk, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 86 observations on the following 8 variables, all
but the first measure units in <em>grams / liter</em>.
</p>

<dl>
<dt><code>X1</code></dt><dd><p>density</p>
</dd>
<dt><code>X2</code></dt><dd><p>fat content</p>
</dd>
<dt><code>X3</code></dt><dd><p>protein content</p>
</dd>
<dt><code>X4</code></dt><dd><p>casein content</p>
</dd>
<dt><code>X5</code></dt><dd><p>cheese dry substance measured in the factory</p>
</dd>
<dt><code>X6</code></dt><dd><p>cheese dry substance measured in the laboratory</p>
</dd>
<dt><code>X7</code></dt><dd><p>milk dry substance</p>
</dd>
<dt><code>X8</code></dt><dd><p>cheese product</p>
</dd>
</dl>



<h3>Source</h3>

<p>Daudin, J.J. Duby, C. and Trecourt, P. (1988)
Stability of Principal Component Analysis Studied by the Bootstrap Method;
<em>Statistics</em> <b>19</b>, 241&ndash;258.
</p>


<h3>References</h3>

<p>Todorov, V., Neyko, N., Neytchev, P. (1994)
Stability of High Breakdown Point Robust PCA,
in <em>Short Communications, COMPSTAT'94</em>; Physica Verlag, Heidelberg.
</p>
<p>Atkinson, A.C. (1994)
Fast Very Robust Methods for the Detection of Multiple Outliers.
<em>J. Amer. Statist. Assoc.</em> <b>89</b> 1329&ndash;1339.
</p>
<p>Rocke, D. M. and Woodruff, D. L. (1996)
Identification of Outliers in Multivariate Data;
<em>J. Amer. Statist. Assoc.</em> <b>91</b> (435), 1047&ndash;1061.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(milk)
(c.milk &lt;- covMcd(milk))
summarizeRobWeights(c.milk $ mcd.wt)# 19..20 outliers
umilk &lt;- unique(milk) # dropping obs.64 (== obs.63)
summary(cumilk &lt;- covMcd(umilk, nsamp = "deterministic")) # 20 outliers

</code></pre>

<hr>
<h2 id='Mpsi'>Psi / Chi / Wgt / Rho Functions for *M-Estimation</h2><span id='topic+Mchi'></span><span id='topic+Mpsi'></span><span id='topic+Mwgt'></span><span id='topic+MrhoInf'></span><span id='topic+.Mchi'></span><span id='topic+.Mpsi'></span><span id='topic+.Mwgt'></span><span id='topic+.Mwgt.psi1'></span><span id='topic+.MrhoInf'></span><span id='topic+.psi2ipsi'></span><span id='topic+.regularize.Mpsi'></span>

<h3>Description</h3>

<p>Compute Psi / Chi / Wgt / Rho functions for M-estimation,
i.e., including MM, etc.  For definitions and details, please use the
vignette <a href="https://cran.r-project.org/package=robustbase/vignettes/psi_functions.pdf">
&ldquo;<code class="reqn">\psi</code>-Functions Available in Robustbase&rdquo;</a>.
</p>
<p><code>MrhoInf(x)</code> computes <code class="reqn">\rho(\infty)</code>, i.e., the
normalizing or scaling constant for the transformation
from <code class="reqn">\rho(\cdot)</code> to
<code class="reqn">\tilde\rho(\cdot)</code>, where the latter, aka as
<code class="reqn">\chi()</code> fulfills <code class="reqn">\tilde\rho(\infty) = 1</code>
which makes only sense for &ldquo;redescending&rdquo; psi functions, i.e.,
not for <code>"huber"</code>.
</p>
<p><code>Mwgt(x, *)</code> computes <code class="reqn">\psi(x)/x</code>  (fast and numerically accurately).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mpsi(x, cc, psi, deriv = 0)
Mchi(x, cc, psi, deriv = 0)
Mwgt(x, cc, psi)
MrhoInf(cc, psi)

.Mwgt.psi1(psi, cc = .Mpsi.tuning.default(psi))
.regularize.Mpsi(psi, redescending = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Mpsi_+3A_x">x</code></td>
<td>
<p>numeric (&ldquo;abscissa&rdquo; values) vector, possibly with
<code><a href="base.html#topic+attributes">attributes</a></code> such as <code><a href="base.html#topic+dim">dim</a></code> or
<code><a href="base.html#topic+names">names</a></code>, etc.  These are preserved for the
<code>M*()</code> functions (but not the <code>.M()</code> ones).</p>
</td></tr>
<tr><td><code id="Mpsi_+3A_cc">cc</code></td>
<td>
<p>numeric tuning constant, for some <code>psi</code> of length
<code class="reqn">&gt; 1</code>.</p>
</td></tr>
<tr><td><code id="Mpsi_+3A_psi">psi</code></td>
<td>
<p>a string specifying the psi / chi / rho / wgt function;
either <code>"huber"</code>, or one of the same possible specifiers as for
<code>psi</code> in <code><a href="#topic+lmrob.control">lmrob.control</a></code>, i.e. currently,
<code>"bisquare"</code>, <code>"lqq"</code>, <code>"welsh"</code>, <code>"optimal"</code>,
<code>"hampel"</code>, or <code>"ggw"</code>.</p>
</td></tr>
<tr><td><code id="Mpsi_+3A_deriv">deriv</code></td>
<td>
<p>an integer, specifying the <em>order</em> of derivative to
consider; particularly, <code>Mpsi(x, *, deriv = -1)</code> is the
principal function of <code class="reqn">\psi()</code>, typically denoted
<code class="reqn">\rho()</code> in the literature.  For some psi functions,
currently <code>"huber"</code>, <code>"bisquare"</code>, <code>"hampel"</code>, and <code>"lqq"</code>,
<code>deriv = 2</code> is implemented, for the other psi's only
<code class="reqn">d \in \{-1,0,1\}</code></p>
</td></tr>
<tr><td><code id="Mpsi_+3A_redescending">redescending</code></td>
<td>
<p>logical indicating in <code>.regularize.Mpsi(psi,.)</code>
if the <code>psi</code> function is redescending.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Theoretically, <code>Mchi()</code> would not be needed explicitly as it can be computed
from <code>Mpsi()</code> and <code>MrhoInf()</code>, namely, by
</p>
<pre>Mchi(x, *, deriv = d)  ==  Mpsi(x, *, deriv = d-1) / MrhoInf(*)</pre>
<p>for <code class="reqn">d = 0, 1, 2</code>  (and &lsquo;*&rsquo; containing <code>par, psi</code>, and
equality is in the sense of <code><a href="Matrix.html#topic+all.equal">all.equal</a>(x,y, tol)</code> with a
small <code>tol</code>.
</p>
<p>Similarly, <code>Mwgt</code> would not be needed strictly, as it could be
defined via <code>Mpsi</code>), but the explicit definition takes care of
0/0 and typically is of a more simple form.
</p>
<p>For experts, there are slightly even faster versions,
<code>.Mpsi()</code>, <code>.Mwgt()</code>, etc.
</p>
<p><code>.Mwgt.psi1()</code> mainly a utility for <code><a href="#topic+nlrob">nlrob</a>()</code>,
returns a <em><code><a href="base.html#topic+function">function</a></code></em> with similar semantics as
<code><a href="MASS.html#topic+psi.hampel">psi.hampel</a></code>, <code><a href="MASS.html#topic+psi.huber">psi.huber</a></code>, or
<code><a href="MASS.html#topic+psi.bisquare">psi.bisquare</a></code> from package <a href="https://CRAN.R-project.org/package=MASS"><span class="pkg">MASS</span></a>.  Namely,
a function with arguments <code>(x, deriv=0)</code>, which for
<code>deriv=0</code> computes <code>Mwgt(x, cc, psi)</code> and otherwise computes
<code>Mpsi(x, cc, psi, deriv=deriv)</code>.
</p>
<p><code>.Mpsi()</code>, <code>.Mchi()</code>, <code>.Mwgt()</code>, and <code>.MrhoInf()</code> are
low-level versions of
<code>Mpsi()</code>,  <code>Mchi()</code>,  <code>Mwgt()</code>, and  <code>MrhoInf()</code>, respectively,
and <code>.psi2ipsi()</code> provides the psi-function integer codes needed
for <code>ipsi</code> argument of the <code>.M*()</code> functions.
</p>
<p>For <code>psi = "ggw"</code>, the <code class="reqn">\rho()</code> function has no closed
form and must be computed via numerical integration, apart from 6
special cases including the defaults, see the &lsquo;Details&rsquo; in
<code>help(<a href="#topic+.psi.ggw.findc">.psi.ggw.findc</a>)</code>.
</p>
<p><code>.Mpsi.regularize()</code> may (rarely) be used to regularize a psi function.
</p>


<h3>Value</h3>

<p>a numeric vector of the same length as <code>x</code>, with corresponding
function (or derivative) values.
</p>


<h3>Author(s)</h3>

<p>Manuel Koller, notably for the original C implementation;
tweaks and speedup via <code><a href="base.html#topic+.Call">.Call</a></code> and <code>.M*()</code> etc by
Martin Maechler.
</p>


<h3>References</h3>

<p>See the vignette about  
&ldquo;<code class="reqn">\psi</code>-Functions Available in Robustbase&rdquo;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psiFunc">psiFunc</a></code> and the <code><a href="#topic+psi_func-class">psi_func</a></code> class, both
of which provide considerably more on the <span class="rlang"><b>R</b></span> side, but are less
optimized for speed.
</p>
<p><code><a href="#topic+.Mpsi.tuning.defaults">.Mpsi.tuning.defaults</a></code>, etc, for tuning constants'
defaults for<code>lmrob()</code>, and <code><a href="#topic+.psi.ggw.findc">.psi.ggw.findc</a>()</code>
utilities to construct such constants' vectors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- seq(-5,7, by=1/8)
matplot(x, cbind(Mpsi(x, 4, "biweight"),
                 Mchi(x, 4, "biweight"),
                 Mwgt(x, 4, "biweight")), type = "l")
abline(h=0, v=0, lty=2, col=adjustcolor("gray", 0.6))

hampelPsi
(ccHa &lt;- hampelPsi @ xtras $ tuningP $ k)
psHa &lt;- hampelPsi@psi(x)

## using Mpsi():
Mp.Ha &lt;- Mpsi(x, cc = ccHa, psi = "hampel")
stopifnot(all.equal(Mp.Ha, psHa, tolerance = 1e-15))

psi.huber &lt;- .Mwgt.psi1("huber")
if(getRversion() &gt;= "3.0.0")
stopifnot(identical(psi.huber, .Mwgt.psi1("huber", 1.345),
                    ignore.env=TRUE))
curve(psi.huber(x), -3, 5, col=2, ylim = 0:1)
curve(psi.huber(x, deriv=1), add=TRUE, col=3)

## and show that this is indeed the same as  MASS::psi.huber() :
x &lt;- runif(256, -2,3)
stopifnot(all.equal(psi.huber(x), MASS::psi.huber(x)),
          all.equal(                 psi.huber(x, deriv=1),
                    as.numeric(MASS::psi.huber(x, deriv=1))))

## and how to get  MASS::psi.hampel():
psi.hampel &lt;- .Mwgt.psi1("Hampel", c(2,4,8))
x &lt;- runif(256, -4, 10)
stopifnot(all.equal(psi.hampel(x), MASS::psi.hampel(x)),
          all.equal(                 psi.hampel(x, deriv=1),
                    as.numeric(MASS::psi.hampel(x, deriv=1))))

## "lqq" / "LQQ" and its tuning constants:
ctl0 &lt;- lmrob.control(psi = "lqq", tuning.psi=c(-0.5, 1.5, 0.95, NA))
ctl  &lt;- lmrob.control(psi = "lqq", tuning.psi=c(-0.5, 1.5, 0.90, NA))
ctl0$tuning.psi  ## keeps the vector _and_ has "constants" attribute:
## [1] -0.50  1.50  0.95    NA
## attr(,"constants")
## [1] 1.4734061 0.9822707 1.5000000
ctl$tuning.psi ## ditto:
## [1] -0.5  1.5  0.9  NA \  .."constants"   1.213726 0.809151 1.500000
stopifnot(all.equal(Mpsi(0:2, cc = ctl$tuning.psi, psi = ctl$psi),
                    c(0, 0.977493, 1.1237), tol = 6e-6))
x &lt;- seq(-4,8, by = 1/16)
## Show how you can use .Mpsi() equivalently to Mpsi()
stopifnot(all.equal( Mpsi(x, cc = ctl$tuning.psi, psi = ctl$psi),
                    .Mpsi(x, ccc = attr(ctl$tuning.psi, "constants"),
                             ipsi = .psi2ipsi("lqq"))))
stopifnot(all.equal( Mpsi(x, cc = ctl0$tuning.psi, psi = ctl0$psi, deriv=1),
                    .Mpsi(x, ccc = attr(ctl0$tuning.psi, "constants"),
                             ipsi = .psi2ipsi("lqq"),              deriv=1)))


## M*() preserving attributes :
x &lt;- matrix(x, 32, 8, dimnames=list(paste0("r",1:32), col=letters[1:8]))
comment(x) &lt;- "a vector which is a matrix"
px &lt;- Mpsi(x, cc = ccHa, psi = "hampel")
stopifnot(identical(attributes(x), attributes(px)))

## The "optimal" psi exists in two versions "in the litterature": ---
## Maronna et al. 2006, 5.9.1, p.144f:
psi.M2006 &lt;- function(x, c = 0.013)
  sign(x) * pmax(0, abs(x) - c/dnorm(abs(x)))
## and the other is the one in robustbase from 'robust': via Mpsi(.., "optimal")
## Here are both for 95% efficiency:
(c106 &lt;- .Mpsi.tuning.default("optimal"))
c1 &lt;- curve(Mpsi(x, cc = c106, psi="optimal"), -5, 7, n=1001)
c2 &lt;- curve(psi.M2006(x), add=TRUE, n=1001, col=adjustcolor(2,0.4), lwd=2)
abline(0,1, v=0, h=0, lty=3)
## the two psi's are similar, but really quite different

## a zoom into Maronna et al's:
c3 &lt;- curve(psi.M2006(x), -.5, 1, n=1001); abline(h=0,v=0, lty=3);abline(0,1, lty=2)
</code></pre>

<hr>
<h2 id='nlrob'>Robust Fitting of Nonlinear Regression Models</h2><span id='topic+nlrob'></span><span id='topic+fitted.nlrob'></span><span id='topic+residuals.nlrob'></span><span id='topic+predict.nlrob'></span><span id='topic+vcov.nlrob'></span>

<h3>Description</h3>

<p><code>nlrob</code> fits a nonlinear regression model by robust methods.
Per default, by an M-estimator, using iterated reweighted least
squares (called &ldquo;IRLS&rdquo; or also &ldquo;IWLS&rdquo;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlrob(formula, data, start, lower, upper,
      weights = NULL, na.action = na.fail,
      method = c("M", "MM", "tau", "CM", "mtl"),
      psi = .Mwgt.psi1("huber", cc=1.345), scale = NULL,
      test.vec = c("resid", "coef", "w"), maxit = 20,
      tol = 1e-06, acc, algorithm = "default", doCov = FALSE, model = FALSE,
      control = if(method == "M") nls.control() else
		nlrob.control(method, optArgs = list(trace=trace), ...),
      trace = FALSE, ...)

## S3 method for class 'nlrob'
fitted(object, ...)
## S3 method for class 'nlrob'
residuals(object, type = , ...)
## S3 method for class 'nlrob'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlrob_+3A_formula">formula</code></td>
<td>
<p>a nonlinear <code><a href="stats.html#topic+formula">formula</a></code> including variables
and parameters of the model, such as <code>y ~ f(x, theta)</code> (cf. <code><a href="stats.html#topic+nls">nls</a></code>).
(For some checks: if <code class="reqn">f(.)</code> is linear, then we need
parentheses, e.g., <code>y ~ (a + b * x)</code>;
(note that <code>._nlrob.w</code> is not allowed as variable or parameter name))



</p>
</td></tr>
<tr><td><code id="nlrob_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables
in the model.  If not found in <code>data</code>, the variables are taken
from <code>environment(formula)</code>, typically the environment from
which <code>nlrob</code> is called.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_start">start</code></td>
<td>
<p>a named numeric vector of starting parameters estimates,
only for <code>method = "M"</code>.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_lower">lower</code>, <code id="nlrob_+3A_upper">upper</code></td>
<td>
<p>numeric vectors of lower and upper bounds; if
needed, will be replicated to be as long as the longest of <code>start</code>,
<code>lower</code> or <code>upper</code>.  For (the default) <code>method = "M"</code>,
if the bounds are unspecified all parameters are assumed to be
unconstrained; also, for method <code>"M"</code>, bounds can only be used
with the <code>"port"</code> algorithm.  They are ignored, with a warning,
in cases they have no effect.
</p>
<p>For all other methods, currently these bounds <em>must</em> be
specified as finite values, and one of them must have
<code><a href="base.html#topic+names">names</a></code> matching the parameter names in <code>formula</code>.
</p>
<p>For methods <code>"CM"</code> and <code>"mtl"</code>, the bounds must
<em>additionally</em> have an entry named <code>"sigma"</code> as that is
determined simultaneously in the same optimization, and hence its
<code>lower</code> bound must not be negative.
</p>
</td></tr>
<tr><td><code id="nlrob_+3A_weights">weights</code></td>
<td>
<p>an optional vector of weights to be used in the fitting
process (for intrinsic weights, not the weights <code>w</code> used in the
iterative (robust) fit). I.e.,
<code>sum(w * e^2)</code> is minimized with <code>e</code> = residuals,
<code class="reqn">e_i = y_i - f(xreg_i, \theta)</code>,
where <code class="reqn">f(x,\theta)</code> is the nonlinear function,
and <code>w</code> are the robust weights from <code>resid * weights</code>.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_na.action">na.action</code></td>
<td>
<p>a function which indicates what should happen when the data
contain <code>NA</code>s.  The default action is for the procedure to
fail.  If NAs are present, use <code>na.exclude</code> to have residuals with
<code>length == nrow(data) == length(w)</code>, where <code>w</code> are the
weights used in the iterative robust loop.  This is better if the
explanatory variables in
<code>formula</code> are time series (and so the NA location is important).
For this reason, <code>na.omit</code>, which leads to omission of cases
with missing values on any required variable, is not suitable
here since the residuals length is different from
<code>nrow(data) == length(w)</code>.
</p>
</td></tr>
<tr><td><code id="nlrob_+3A_method">method</code></td>
<td>
<p>a character string specifying which method to use.  The
default is <code>"M"</code>, for historical and back-compatibility
reasons.  For the other methods, primarily see
<code><a href="#topic+nlrob.algorithms">nlrob.algorithms</a></code>. 
</p>

<dl>
<dt>&quot;M&quot;</dt><dd><p>Computes an M-estimator, using <code><a href="stats.html#topic+nls">nls</a>(*,
	  weights=*)</code> iteratively (hence, IRLS) with weights equal to
<code class="reqn">\psi(r_i) / r_i</code>, where <code class="reqn">r_i</code> is the i-the residual
from the previous fit.</p>
</dd>
<dt>&quot;MM&quot;</dt><dd><p>Computes an MM-estimator, starting from <code>init</code>,
either &quot;S&quot; or &quot;lts&quot;.</p>
</dd>
<dt>&quot;tau&quot;</dt><dd><p>Computes a Tau-estimator.</p>
</dd>
<dt>&quot;CM&quot;</dt><dd><p>Computes a &ldquo;Constrained M&rdquo; (=: CM) estimator.</p>
</dd>
<dt>&quot;mtl&quot;</dt><dd><p>Compute as &ldquo;Maximum Trimmed Likelihood&rdquo; (=: MTL)
estimator.</p>
</dd>
</dl>

<p>Note that all methods but <code>"M"</code> are &ldquo;random&rdquo;, hence
typically to be preceded by <code><a href="base.html#topic+set.seed">set.seed</a>()</code> in usage, see
also <code><a href="#topic+nlrob.algorithms">nlrob.algorithms</a></code>. 
</p>
</td></tr>
<tr><td><code id="nlrob_+3A_psi">psi</code></td>
<td>
<p>a function (possibly by name) of the form <code>g(x, 'tuning
      constant(s)', deriv)</code> that for <code>deriv=0</code> returns
<code class="reqn">\psi(x)/x</code> and for <code>deriv=1</code> returns
<code class="reqn">\psi'(x)</code>.  Note that tuning constants can <em>not</em>
be passed separately, but directly via the specification of <code>psi</code>,
typically via a simple <code><a href="#topic+.Mwgt.psi1">.Mwgt.psi1</a>()</code> call as per
default.
</p>
<p>Note that this has been a deliberately non-backcompatible change
for robustbase version 0.90-0 (summer 2013 &ndash; early 2014).
</p>
</td></tr>
<tr><td><code id="nlrob_+3A_scale">scale</code></td>
<td>
<p>when not <code>NULL</code> (default), a positive number
specifying a scale kept <em>fixed</em> during the iterations (and
returned as <code>Scale</code> component).</p>
</td></tr>
<tr><td><code id="nlrob_+3A_test.vec">test.vec</code></td>
<td>
<p>character string specifying the convergence
criterion. The relative change is tested for residuals with a value
of <code>"resid"</code> (the default), for coefficients with
<code>"coef"</code>, and for weights with <code>"w"</code>.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations in the robust loop.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_tol">tol</code></td>
<td>
<p>non-negative convergence tolerance for the robust fit.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_acc">acc</code></td>
<td>
<p>previous name for <code>tol</code>, now deprecated.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_algorithm">algorithm</code></td>
<td>
<p>character string specifying the algorithm to use for
<code><a href="stats.html#topic+nls">nls</a></code>, see there, only when <code>method = "M"</code>.  The
default algorithm is a Gauss-Newton algorithm.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_docov">doCov</code></td>
<td>
<p>a logical specifying if <code>nlrob()</code> should compute the
asymptotic variance-covariance matrix (see <code><a href="stats.html#topic+vcov">vcov</a></code>)
already.  This used to be hard-wired to <code>TRUE</code>; however, the
default has been set to <code>FALSE</code>, as <code><a href="stats.html#topic+vcov">vcov</a>(obj)</code> and
<code><a href="base.html#topic+summary">summary</a>(obj)</code> can easily compute it when needed.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_model">model</code></td>
<td>
<p>a <code><a href="base.html#topic+logical">logical</a></code> indicating if the
<code><a href="stats.html#topic+model.frame">model.frame</a></code> should be returned as well.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_control">control</code></td>
<td>
<p>an optional list of control settings.
</p>

<dl>
<dt>for <code>method = "M"</code>:</dt><dd><p>settings for <code><a href="stats.html#topic+nls">nls</a>()</code>.
See <code><a href="stats.html#topic+nls.control">nls.control</a></code> for the names of the settable control
values and their effect.</p>
</dd>
<dt>for all <code>method</code>s but <code>"M"</code>:</dt><dd><p>a list, typically
resulting from <code><a href="#topic+nlrob.control">nlrob.control</a>(method, *)</code>.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="nlrob_+3A_trace">trace</code></td>
<td>
<p>logical value indicating if a &ldquo;trace&rdquo; of
the <code>nls</code> iteration progress should be printed.  Default is
<code>FALSE</code>. <br />
If <code>TRUE</code>, in each robust iteration, the residual
sum-of-squares and the parameter values are printed at the
conclusion of each <code>nls</code> iteration.
When the <code>"plinear"</code> algorithm is used, the conditional
estimates of the linear parameters are printed after the nonlinear
parameters.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code>"nlrob"</code>, typically
resulting from <code>nlrob(..)</code>.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_...">...</code></td>
<td>
<p>for <code>nlrob</code>: only when <code>method</code> is <em>not</em> <code>"M"</code>,
optional arguments for <code><a href="#topic+nlrob.control">nlrob.control</a></code>;
<br />
for other functions: potentially optional arguments passed to the
extractor methods.</p>
</td></tr>
<tr><td><code id="nlrob_+3A_type">type</code></td>
<td>
<p>a string specifying the <em>type</em> of residuals desired.
Currently, <code>"response"</code> and <code>"working"</code> are supported.

</p>
</td></tr>
<tr><td><code id="nlrob_+3A_newdata">newdata</code></td>
<td>
<p>a data frame (or list) with the same names as the
original <code>data</code>, see e.g., <code><a href="stats.html#topic+predict.nls">predict.nls</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>method = "M"</code>, iterated reweighted least squares
(&ldquo;IRLS&rdquo; or &ldquo;IWLS&rdquo;) is used, calling <code><a href="stats.html#topic+nls">nls</a>(*,
    weights= .)</code> where <code>weights</code> <code class="reqn">w_i</code> are proportional to
<code class="reqn">\psi(r_i/ \hat{\sigma})</code>.
</p>
<p>All other methods minimize differently, and work <b>without</b>
<code><a href="stats.html#topic+nls">nls</a></code>.  See <a href="#topic+nlrob.algorithms">nlrob.algorithms</a> 
for details.
</p>


<h3>Value</h3>

<p><code>nlrob()</code> returns an object of S3 class <code>"nlrob"</code>,
for <code>method = "M"</code> also inheriting from class <code>"nls"</code>, (see
<code><a href="stats.html#topic+nls">nls</a></code>).
</p>
<p>It is a list with several components; they are not documented yet,
as some of them will probably change.
Instead, rather use &ldquo;accessor&rdquo; methods, where possible:
There are methods (at least) for the generic accessor functions
<code><a href="base.html#topic+summary">summary</a>()</code>, <code><a href="stats.html#topic+coefficients">coefficients</a>()</code> (aka <code>coef()</code>)
<code>fitted.values()</code>, <code>residuals()</code>, <code><a href="#topic+sigma">sigma</a>()</code> and
<code><a href="stats.html#topic+vcov">vcov</a>()</code>, the latter for the variance-covariance matrix of
the estimated parameters, as returned by <code>coef()</code>, i.e., not
including the variance of the errors.
For <code>nlrob()</code> results, <code><a href="#topic+estimethod">estimethod</a>()</code> returns the
&ldquo;estimation method&rdquo;, which coincides with the <code>method</code>
argument used.
</p>
<p><code>residuals(.)</code>, by default <code>type = "response"</code>, returns
the residuals <code class="reqn">e_i</code>, defined above as
<code class="reqn">e_i = Y_i - f_(x_i, \hat\theta)</code>.
These differ from the standardized or weighted residuals which, e.g.,
are assumed to be normally distributed, and a version of which is
returned in <code>working.residuals</code> component.

</p>


<h3>Note</h3>

<p>This function (with the only method <code>"M"</code>) used to be named
<code>rnls</code> and has been in package <a href="https://CRAN.R-project.org/package=sfsmisc"><span class="pkg">sfsmisc</span></a> in the past, but
been dropped there.
</p>


<h3>Author(s)</h3>


<dl>
<dt><code>method = "M"</code>:</dt><dd>
<p>Andreas Ruckstuhl (inspired by <code><a href="MASS.html#topic+rlm">rlm</a></code>() and
<code><a href="stats.html#topic+nls">nls</a></code>()), in July 1994 for S-plus.<br />
Christian Sangiorgio did the update to <span class="rlang"><b>R</b></span> and corrected some errors,
from June 2002 to January 2005, and Andreas contributed slight changes
and the first methods in August 2005.</p>
</dd>
<dt><code>method = "MM"</code>, etc:</dt><dd><p>Originally all by Eduardo
L. T. Conceicao, see <code><a href="#topic+nlrob.algorithms">nlrob.algorithms</a></code>:</p>
</dd> 
</dl>

<p>Since then, the help page, testing, more cleanup, new methods: Martin
Maechler.
</p>


<h3>See Also</h3>

 <p><code><a href="stats.html#topic+nls">nls</a></code>, <code><a href="MASS.html#topic+rlm">rlm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>DNase1 &lt;- DNase[ DNase$Run == 1, ]

## note that selfstarting models don't work yet % &lt;&lt;&lt; FIXME !!!

##--- without conditional linearity ---

## classical
fmNase1 &lt;- nls( density ~ Asym/(1 + exp(( xmid - log(conc) )/scal ) ),
                data = DNase1,
                start = list( Asym = 3, xmid = 0, scal = 1 ),
                trace = TRUE )
summary( fmNase1 )

## robust
RmN1  &lt;- nlrob( density ~ Asym/(1 + exp(( xmid - log(conc) )/scal ) ),
                data = DNase1, trace = TRUE,
                start = list( Asym = 3, xmid = 0, scal = 1 ))
summary( RmN1 )

##--- using conditional linearity ---

## classical
fm2DNase1 &lt;- nls( density ~ 1/(1 + exp(( xmid - log(conc) )/scal ) ),
                  data = DNase1,
                  start = c( xmid = 0, scal = 1 ),
                  alg = "plinear", trace = TRUE )
summary( fm2DNase1 )

## robust
frm2DNase1 &lt;- nlrob(density ~ 1/(1 + exp(( xmid - log(conc) )/scal ) ),
                  data = DNase1, start = c( xmid = 0, scal = 1 ),
                  alg = "plinear", trace = TRUE )
summary( frm2DNase1 )
## Confidence for linear parameter is quite smaller than "Asym" above
c1 &lt;- coef(summary(RmN1))
c2 &lt;- coef(summary(frm2DNase1))
rownames(c2)[rownames(c2) == ".lin"] &lt;- "Asym"
stopifnot(all.equal(c1[,1:2], c2[rownames(c1), 1:2], tol = 0.09)) # 0.07315

### -- new examples -- "moderate outlier":
DN2 &lt;- DNase1
DN2[10,"density"] &lt;- 2*DN2[10,"density"]

fm3DN2 &lt;- nls(density ~  Asym/(1 + exp(( xmid - log(conc) )/scal ) ),
              data = DN2, trace = TRUE,
              start = list( Asym = 3, xmid = 0, scal = 1 ))

## robust
Rm3DN2 &lt;- nlrob(density ~  Asym/(1 + exp(( xmid - log(conc) )/scal ) ),
                data = DN2, trace = TRUE,
                start = list( Asym = 3, xmid = 0, scal = 1 ))
Rm3DN2
summary(Rm3DN2) # -&gt; robustness weight of obs. 10 ~= 0.037
confint(Rm3DN2, method = "Wald")
stopifnot(identical(Rm3DN2$dataClasses,
                    c(density = "numeric", conc = "numeric")))

## utility function sfsmisc::lseq() :
lseq &lt;- function (from, to, length)
  2^seq(log2(from), log2(to), length.out = length)
## predict() {and plot}:
h.x &lt;- lseq(min(DN2$conc), max(DN2$conc), length = 100)
nDat &lt;- data.frame(conc = h.x)

h.p  &lt;- predict(fm3DN2, newdata = nDat)# classical
h.rp &lt;- predict(Rm3DN2, newdata = nDat)# robust

plot(density ~ conc, data=DN2, log="x",
     main = format(formula(Rm3DN2)))
lines(h.x, h.p,  col="blue")
lines(h.x, h.rp, col="magenta")
legend("topleft", c("classical nls()", "robust nlrob()"),
       lwd = 1, col= c("blue", "magenta"), inset = 0.05)

## See  ?nlrob.algorithms for examples

DNase1 &lt;- DNase[DNase$Run == 1,]
form &lt;- density ~ Asym/(1 + exp(( xmid -log(conc) )/scal ))
gMM  &lt;- nlrob(form, data = DNase1, method = "MM",
              lower = c(Asym = 0, xmid = 0, scal = 0),
              upper = 3, trace = TRUE)

## "CM" (and "mtl") additionally need bounds for "sigma" :
gCM  &lt;- nlrob(form, data = DNase1, method = "CM",
              lower = c(Asym = 0, xmid = 0, scal = 0, sigma = 0),
              upper = c(3,3,3, sigma = 0.8))
summary(gCM)# did fail; note it has  NA NA NA (std.err, t val, P val)
stopifnot(identical(Rm3DN2$dataClasses, gMM$dataClasses),
          identical(   gCM$dataClasses, gMM$dataClasses))

</code></pre>

<hr>
<h2 id='nlrob-algorithms'>MM-, Tau-, CM-, and MTL- Estimators for Nonlinear Robust Regression</h2><span id='topic+nlrob.algorithms'></span><span id='topic+nlrob.MM'></span><span id='topic+nlrob.tau'></span><span id='topic+nlrob.CM'></span><span id='topic+nlrob.mtl'></span>

<h3>Description</h3>


<dl>
<dt>&quot;MM&quot;:</dt><dd><p>Compute an MM-estimator for nonlinear robust (constrained)
regression.</p>
</dd>
<dt>&quot;tau&quot;:</dt><dd><p>Compute a Tau-estimator for nonlinear robust (constrained)
regression.</p>
</dd>
<dt>&quot;CM&quot;:</dt><dd><p>Compute a &ldquo;Constrained M&rdquo; (=: CM) estimator for
nonlinear robust (constrained) regression.</p>
</dd>
<dt>&quot;MTL&quot;:</dt><dd><p>Compute a &ldquo;Maximum Trimmed Likelihood&rdquo; (=: MTL)
estimator for nonlinear robust (constrained) regression.</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>## You can *not* call the  nlrob(*, method = &lt;M&gt;) like this ==&gt; see  help(nlrob)
## ------- ===== ------------------------------------------

nlrob.MM(formula, data, lower, upper,
	 tol = 1e-06,
	 psi = c("bisquare", "lqq", "optimal", "hampel"),
         init = c("S", "lts"),
	 ctrl = nlrob.control("MM", psi = psi, init = init, fnscale = NULL,
		       tuning.chi.scale = .psi.conv.cc(psi, .Mchi.tuning.defaults[[psi]]),
		       tuning.psi.M     = .psi.conv.cc(psi, .Mpsi.tuning.defaults[[psi]]),
		       optim.control = list(), optArgs = list(...)),
	 ...)

nlrob.tau(formula, data, lower, upper,
	  tol = 1e-06, psi = c("bisquare", "optimal"),
	  ctrl = nlrob.control("tau", psi = psi, fnscale = NULL,
			tuning.chi.scale = NULL, tuning.chi.tau = NULL,
			optArgs = list(...)),
	  ...)

nlrob.CM(formula, data, lower, upper,
	 tol = 1e-06,
	 psi = c("bisquare", "lqq", "welsh", "optimal", "hampel", "ggw"),
	 ctrl = nlrob.control("CM", psi = psi, fnscale = NULL,
                        tuning.chi = NULL, optArgs = list(...)),
	 ...)

nlrob.mtl(formula, data, lower, upper,
	  tol = 1e-06,
	  ctrl = nlrob.control("mtl", cutoff = 2.5, optArgs = list(...)),
	  ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlrob-algorithms_+3A_formula">formula</code></td>
<td>
<p>nonlinear regression <code><a href="stats.html#topic+formula">formula</a></code>, using both
variable names from <code>data</code> and parameter names from either
<code>lower</code> or <code>upper</code>.</p>
</td></tr>
<tr><td><code id="nlrob-algorithms_+3A_data">data</code></td>
<td>
<p>data to be used, a <code><a href="base.html#topic+data.frame">data.frame</a></code></p>
</td></tr>
<tr><td><code id="nlrob-algorithms_+3A_lower">lower</code>, <code id="nlrob-algorithms_+3A_upper">upper</code></td>
<td>
<p>bounds aka &ldquo;box constraints&rdquo; for all the
parameters, in the case &quot;CM&quot; and &quot;mtl&quot; these must include the error
standard deviation as <code>"sigma"</code>, see <code><a href="#topic+nlrob">nlrob</a>()</code>
about its <code><a href="base.html#topic+names">names</a></code>, etc.
</p>
<p>Note that one of these two must be a properly &ldquo;named&rdquo;, e.g.,
<code>names(lower)</code> being a <code><a href="base.html#topic+character">character</a></code> vector of parameter names
(used in <code>formula</code> above).
</p>
</td></tr>
<tr><td><code id="nlrob-algorithms_+3A_tol">tol</code></td>
<td>
<p>numerical convergence tolerance.</p>
</td></tr>
<tr><td><code id="nlrob-algorithms_+3A_psi">psi</code>, <code id="nlrob-algorithms_+3A_init">init</code></td>
<td>
<p>see <code><a href="#topic+nlrob.control">nlrob.control</a></code>.</p>
</td></tr>
<tr><td><code id="nlrob-algorithms_+3A_ctrl">ctrl</code></td>
<td>
<p>a <code><a href="base.html#topic+list">list</a></code>, typically the result of a call to
<code><a href="#topic+nlrob.control">nlrob.control</a></code>.</p>
</td></tr>
<tr><td><code id="nlrob-algorithms_+3A_tuning.psi.m">tuning.psi.M</code></td>
<td>
<p>..</p>
</td></tr>
<tr><td><code id="nlrob-algorithms_+3A_optim.control">optim.control</code></td>
<td>
<p>..</p>
</td></tr>
<tr><td><code id="nlrob-algorithms_+3A_optargs">optArgs</code></td>
<td>
<p>a <code><a href="base.html#topic+list">list</a></code> of optional arguments for
optimization, e.g., <code>trace = TRUE</code>, passed to to the optimizer,
which currently must be <code><a href="DEoptimR.html#topic+JDEoptim">JDEoptim</a>(.)</code>.</p>
</td></tr>
<tr><td><code id="nlrob-algorithms_+3A_...">...</code></td>
<td>
<p>alternative way to pass the <code>optArgs</code> above.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Copyright 2013, Eduardo L. T. Conceicao.  Available under
the GPL (&gt;= 2)
</p>
<p>Currently, all four methods use <code><a href="DEoptimR.html#topic+JDEoptim">JDEoptim</a>()</code>
from <a href="https://CRAN.R-project.org/package=DEoptimR"><span class="pkg">DEoptimR</span></a>, which subsamples using <code><a href="base.html#topic+sample">sample</a>()</code>.
From <span class="rlang"><b>R</b></span> version 3.6.0, <code><a href="base.html#topic+sample">sample</a></code> depends on
<code><a href="base.html#topic+RNGkind">RNGkind</a>(*, sample.kind)</code>, such that exact reproducibility of
results from <span class="rlang"><b>R</b></span> versions 3.5.3 and earlier requires setting
<code><a href="base.html#topic+RNGversion">RNGversion</a>("3.5.0")</code>.
In any case, do use <code><a href="base.html#topic+set.seed">set.seed</a>()</code> additionally for reproducibility!
</p>


<h3>Value</h3>

<p>an <span class="rlang"><b>R</b></span> object of <code><a href="base.html#topic+class">class</a></code> <code>"nlrob.&lt;meth&gt;"</code>, basically a
list with components

</p>


<h3>Author(s)</h3>

<p>Eduardo L. T. Conceicao; compatibility (to <code><a href="#topic+nlrob">nlrob</a></code>)
tweaks and generalizations, inference, by Martin Maechler.
</p>


<h3>Source</h3>

<p>For <code>"MTL"</code>:
Maronna, Ricardo A., Martin, R. Douglas, and Yohai, Victor J. (2006).
<em>Robust Statistics: Theory and Methods</em> Wiley, Chichester, p. 133.
</p>


<h3>References</h3>


<dl>
<dt>&quot;MM&quot;:</dt><dd>
<p>Yohai, V.J. (1987)
High breakdown-point and high efficiency robust estimates for
regression.
<em>The Annals of Statistics</em> <b>15</b>, 642&ndash;656.
</p>
</dd>
<dt>&quot;tau&quot;:</dt><dd>
<p>Yohai, V.J., and Zamar, R.H. (1988).
High breakdown-point estimates of regression by means of the
minimization of an efficient scale.
<em>Journal of the American Statistical Association</em> <b>83</b>,
406&ndash;413.
</p>
</dd>
<dt>&quot;CM&quot;:</dt><dd>
<p>Mendes, B.V.M., and Tyler, D.E. (1996)
Constrained M-estimation for regression.
</p>
<p>In: <em>Robust Statistics, Data Analysis and Computer Intensive
Methods</em>, Lecture Notes in Statistics 109, Springer, New York, 299&ndash;320.




</p>
</dd>
<dt>&quot;MTL&quot;:</dt><dd>
<p>Hadi, Ali S., and Luceno, Alberto (1997).
Maximum trimmed likelihood estimators: a unified approach,
examples, and algorithms.
Computational Statistics &amp; Data Analysis <b>25</b>, 251&ndash;272.
</p>
<p>Gervini, Daniel, and Yohai, Victor J. (2002).
A class of robust and fully efficient regression estimators.
The Annals of Statistics <b>30</b>, 583&ndash;616.
</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>
DNase1 &lt;- DNase[DNase$Run == 1,]
form &lt;- density ~ Asym/(1 + exp(( xmid -log(conc) )/scal ))
pnms &lt;- c("Asym", "xmid", "scal")
set.seed(47) # as these by default use randomized optimization:

fMM &lt;- robustbase:::nlrob.MM(form, data = DNase1,
           lower = setNames(c(0,0,0), pnms), upper = 3,
           ## call to nlrob.control to pass 'optim.control':
           ctrl = nlrob.control("MM", optim.control = list(trace = 1),
                                optArgs = list(trace = TRUE)))

## The same via nlrob() {recommended; same random seed to necessarily give the same}:
set.seed(47)
gMM  &lt;- nlrob(form, data = DNase1, method = "MM",
              lower = setNames(c(0,0,0), pnms), upper = 3, trace = TRUE)
gMM
summary(gMM)
## and they are the same {apart from 'call' and 'ctrl' and new stuff in gMM}:
ni &lt;- names(fMM); ni &lt;- ni[is.na(match(ni, c("call","ctrl")))]
stopifnot(all.equal(fMM[ni], gMM[ni]))

</code></pre>

<hr>
<h2 id='nlrob.control'>Control Nonlinear Robust Regression Algorithms</h2><span id='topic+nlrob.control'></span>

<h3>Description</h3>

<p>Allow the user to specify details for the different nonlinear robust
regression algorithms in <code><a href="#topic+nlrob">nlrob</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nlrob.control(method,
              psi = c("bisquare", "lqq", "welsh", "optimal", "hampel", "ggw"),
              init = c("S", "lts"),
              optimizer = "JDEoptim", optArgs  = list(),
              ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nlrob.control_+3A_method">method</code></td>
<td>
<p><code><a href="base.html#topic+character">character</a></code> string specifying the method</p>
</td></tr>
<tr><td><code id="nlrob.control_+3A_psi">psi</code></td>
<td>
<p>string specifying the psi-function which defines the estimator.</p>
</td></tr>
<tr><td><code id="nlrob.control_+3A_init">init</code></td>
<td>
<p>for some methods, currently, <code>"MM"</code> only, a string
specifying the initial estimator.
</p>
</td></tr>
<tr><td><code id="nlrob.control_+3A_optimizer">optimizer</code></td>
<td>
<p>currently only <code>"JDEoptim"</code> from package <a href="https://CRAN.R-project.org/package=DEoptimR"><span class="pkg">DEoptimR</span></a>.</p>
</td></tr>
<tr><td><code id="nlrob.control_+3A_optargs">optArgs</code></td>
<td>

<p>a <code><a href="base.html#topic+list">list</a></code> of optional arguments to the optimizer.
Currently, that is <code><a href="DEoptimR.html#topic+JDEoptim">JDEoptim</a></code> from package
<a href="https://CRAN.R-project.org/package=DEoptimR"><span class="pkg">DEoptimR</span></a>.
</p>
</td></tr>
<tr><td><code id="nlrob.control_+3A_...">...</code></td>
<td>
<p>optional arguments depending on <code>method</code>, such as
<code>fnscale</code>, <code>tuning.chi</code> or both <code>tuning.chi.tau</code>  and
<code>tuning.chi.scale</code>; for <code>method = "MM"</code> also <code>optim.control</code>
to be passed to the <code><a href="stats.html#topic+optim">optim</a>(.., hessian=TRUE)</code> call.

Internally, <code>nlrob.control()</code> will choose (or check) defaults for
the psi/rho/chi related tuning parameters, also depending on the <code>method</code>
chosen; see e.g., the &lsquo;Examples&rsquo;.
</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+list">list</a></code> with several named components.
The contents depend quite a bit on the <code>method</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nlrob">nlrob</a></code>; for some details, <code><a href="#topic+nlrob.algorithms">nlrob.algorithms</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Show how the different 'method's  have different smart defaults :
str(nlrob.control("MM"))
str(nlrob.control("MM", psi = "hampel"))# -&gt; other tuning.psi.M and tuning.chi.scale defaults
str(nlrob.control("MM", psi = "lqq", tol = 1e-10))# other tuning.psi.M &amp; tuning.chi.scale defaults
str(nlrob.control("tau"))
str(nlrob.control("tau",psi= "lqq"))
str(nlrob.control("CM")) # tuning.chi undefined, unneeded
str(nlrob.control("CM", psi= "optimal"))
str(nlrob.control("mtl"))
</code></pre>

<hr>
<h2 id='NOxEmissions'>NOx Air Pollution Data</h2><span id='topic+NOxEmissions'></span>

<h3>Description</h3>

<p>A typical medium sized environmental data set with hourly measurements
of <code class="reqn">NOx</code> pollution content in the ambient air.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(NOxEmissions, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 8088 observations on the following 4 variables.
</p>

<dl>
<dt><code>julday</code></dt><dd><p>day number, a factor with levels <code>373</code>
... <code>730</code>, typically with 24 hourly measurements.</p>
</dd>
<dt><code>LNOx</code></dt><dd><p><code class="reqn">\log</code> of hourly mean of NOx concentration in
ambient air [ppb] next to a highly frequented motorway.</p>
</dd>
<dt><code>LNOxEm</code></dt><dd><p><code class="reqn">\log</code> of hourly sum of NOx emission of
cars on this motorway in arbitrary units.</p>
</dd>
<dt><code>sqrtWS</code></dt><dd><p>Square root of wind speed [m/s].</p>
</dd>
</dl>



<h3>Details</h3>

<p>The original data set had more observations, but with missing values.
Here, all cases with missing values were omitted
(<code><a href="stats.html#topic+na.omit">na.omit</a>(.)</code>), and then only those were retained that
belonged to days with at least 20 (fully) observed hourly
measurements.
</p>


<h3>Source</h3>

<p>RenÃ© Locher (at ZHAW, Switzerland).

</p>


<h3>See Also</h3>

<p>another NOx dataset, <code><a href="#topic+ambientNOxCH">ambientNOxCH</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(NOxEmissions)
plot(LNOx ~ LNOxEm, data = NOxEmissions, cex = 0.25, col = "gray30")

## Not run: ## these take too much time --
 ## p = 340  ==&gt; already Least Squares is not fast
 (lmNOx &lt;- lm(LNOx ~ . ,data = NOxEmissions))
 plot(lmNOx) #-&gt;  indication of 1 outlier

 M.NOx &lt;- MASS::rlm(LNOx ~ . , data = NOxEmissions)
 ## M-estimation works
 ## whereas  MM-estimation fails:
 try(MM.NOx &lt;- MASS::rlm(LNOx ~ . , data = NOxEmissions, method = "MM"))
 ## namely because S-estimation fails:
 try(lts.NOx &lt;- ltsReg(LNOx ~ . , data = NOxEmissions))
 try(lmR.NOx &lt;- lmrob (LNOx ~ . , data = NOxEmissions))

## End(Not run)
</code></pre>

<hr>
<h2 id='outlierStats'>Robust Regression Outlier Statistics</h2><span id='topic+outlierStats'></span>

<h3>Description</h3>

<p>Simple statistics about observations with robustness
weight of almost zero for models that include factor
terms.  The number of rejected observations and the mean
robustness weights are computed for each level of each
factor included in the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outlierStats(object, x = object$x, control = object$control
           , epsw = control$eps.outlier
           , epsx = control$eps.x
           , warn.limit.reject = control$warn.limit.reject
           , warn.limit.meanrw = control$warn.limit.meanrw
           , shout = NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outlierStats_+3A_object">object</code></td>
<td>
<p>object of class <code>"lmrob"</code>, typically the result of a call
to <code><a href="#topic+lmrob">lmrob</a></code>.</p>
</td></tr>
<tr><td><code id="outlierStats_+3A_x">x</code></td>
<td>
<p>design matrix</p>
</td></tr>
<tr><td><code id="outlierStats_+3A_control">control</code></td>
<td>
<p>list as returned by <code><a href="#topic+lmrob.control">lmrob.control</a>()</code>.</p>
</td></tr>
<tr><td><code id="outlierStats_+3A_epsw">epsw</code></td>
<td>
<p>limit on the robustness weight below which an observation is considered
to be an outlier.  Either a <code>numeric(1)</code> or a
<code><a href="base.html#topic+function">function</a></code> that takes the number of observations as an argument.</p>
</td></tr>
<tr><td><code id="outlierStats_+3A_epsx">epsx</code></td>
<td>
<p>limit on the absolute value of the elements of the design matrix
below which an element is considered zero.  Either a numeric(1) or a
function that takes the maximum absolute value in the design matrix
as an argument.</p>
</td></tr>
<tr><td><code id="outlierStats_+3A_warn.limit.reject">warn.limit.reject</code></td>
<td>
<p>limit of ratio
<code class="reqn">\#\mbox{rejected} / \#\mbox{obs in level}</code>
above (<code class="reqn">\geq</code>) which a warning is produced.  Set to
<code>NULL</code> to disable warning.</p>
</td></tr>
<tr><td><code id="outlierStats_+3A_warn.limit.meanrw">warn.limit.meanrw</code></td>
<td>
<p>limit of the mean robustness per factor level
below which (<code class="reqn">\leq</code>) a warning is produced.  Set to
<code>NULL</code> to disable warning.</p>
</td></tr>
<tr><td><code id="outlierStats_+3A_shout">shout</code></td>
<td>
<p>a <code><a href="base.html#topic+logical">logical</a></code> (scalar) indicating if large
<code>"Ratio"</code> or small <code>"Mean.RobWeight"</code> should lead to
corresponding <code><a href="base.html#topic+warning">warning</a>()</code>s; cutoffs are determined by
<code>warn.limit.reject</code> and <code>warn.limit.meanrw</code>, above.  By
default, <code>NA</code>; setting it to <code>FALSE</code> or <code>TRUE</code> disables
or unconditionally enables &ldquo;shouting&rdquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For models that include factors, the fast S-algorithm used by
<code><a href="#topic+lmrob">lmrob</a></code> can produce &ldquo;bad&rdquo; fits for some of the
factor levels, especially if there are many levels with only a
few observations. Such a &ldquo;bad&rdquo; fit is characterized as a
fit where most of the observations in a level of a factor are
rejected, i.e., are assigned robustness weights of zero or nearly
zero. We call such a fit a &ldquo;local exact fit&rdquo;.
</p>
<p>If a local exact fit is detected, then we recommend to increase some
of the control parameters of the &ldquo;fast S&rdquo;-algorithm. As a first
aid solution in such cases, one can use <code>setting="KS2014"</code>, see also
<code><a href="#topic+lmrob.control">lmrob.control</a></code>.
</p>
<p>This function is called internally by <code><a href="#topic+lmrob">lmrob</a></code> to issue a
warning if a local exact fit is detected. The output is available as
<code>ostats</code> in objects of class <code>"lmrob"</code> (only if the statistic
is computed).
</p>


<h3>Value</h3>

<p>A data frame for each column with any zero elements as well as an
overall statistic.  The data frame consist of the names of the
coefficients in question, the number of non-zero observations in that
level (<code>N.nonzero</code>), the number of rejected observations
(<code>N.rejected</code>), the ratio of rejected observations to the
number of observations in that level (<code>Ratio</code>) and the mean
robustness weight of all the observations in the corresponding level
(<code>Mean.RobWeight</code>).
</p>


<h3>Author(s)</h3>

<p>Manuel Koller</p>


<h3>References</h3>

<p>Koller, M. and Stahel, W.A. (2017)
Nonsingular subsampling for regression S estimators with categorical predictors,
<em>Computational Statistics</em> <b>32</b>(2): 631&ndash;646.
<a href="https://doi.org/10.1007/s00180-016-0679-x">doi:10.1007/s00180-016-0679-x</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob.control">lmrob.control</a></code> for the default values of the control
parameters;  <code><a href="#topic+summarizeRobWeights">summarizeRobWeights</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## artificial data example
data &lt;- expand.grid(grp1 = letters[1:5], grp2 = letters[1:5], rep=1:3)
set.seed(101)
data$y &lt;- c(rt(nrow(data), 1))
## compute outlier statistics for all the estimators
control &lt;- lmrob.control(method = "SMDM",
                         compute.outlier.stats = c("S", "MM", "SMD", "SMDM"))
## warning is only issued for some seeds
set.seed(2)
fit1 &lt;- lmrob(y ~ grp1*grp2, data, control = control)
## do as suggested:
fit2 &lt;- lmrob(y ~ grp1*grp2, data, setting = "KS2014")

## the plot function should work for such models as well
plot(fit1)

## Not run: 
  ## access statistics:
  fit1$ostats ## SMDM
  fit1$init$ostats ## SMD
  fit1$init$init$ostats ## SM
  fit1$init$init$init.S$ostats ## S

## End(Not run)
</code></pre>

<hr>
<h2 id='pension'>Pension Funds Data</h2><span id='topic+pension'></span>

<h3>Description</h3>

<p>The total 1981 premium income of pension funds of Dutch firms,
for 18 Professional Branches, from de Wit (1982).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pension, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 18 observations on the following 2 variables.
</p>

<dl>
<dt><code>Income</code></dt><dd><p>Premium Income (in millions of guilders)</p>
</dd>
<dt><code>Reserves</code></dt><dd><p>Premium Reserves (in millions of guilders)</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, p.76, table 13.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pension)
plot(pension)

summary(lm.p  &lt;-    lm(Reserves ~., data=pension))
summary(lmR.p &lt;- lmrob(Reserves ~., data=pension))
summary(lts.p &lt;- ltsReg(Reserves ~., data=pension))
abline( lm.p)
abline(lmR.p, col=2)
abline(lts.p, col=2, lty=2)

## MM: "the" solution is much simpler:
plot(pension, log = "xy")
lm.lp  &lt;-    lm(log(Reserves) ~ log(Income), data=pension)
lmR.lp &lt;- lmrob(log(Reserves) ~ log(Income), data=pension)
plot(log(Reserves) ~ log(Income), data=pension)
## no difference between LS and robust:
abline( lm.lp)
abline(lmR.lp, col=2)
</code></pre>

<hr>
<h2 id='phosphor'>Phosphorus Content Data</h2><span id='topic+phosphor'></span>

<h3>Description</h3>

<p>This dataset investigates the effect from inorganic and organic
Phosphorus in the soil upon the phosphorus content of the corn grown
in this soil, from Prescott (1975).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(phosphor, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 18 observations on the following 3 variables.
</p>

<dl>
<dt><code>inorg</code></dt><dd><p>Inorganic soil Phosphorus</p>
</dd>
<dt><code>organic</code></dt><dd><p>Organic soil Phosphorus</p>
</dd>
<dt><code>plant</code></dt><dd><p>Plant Phosphorus content</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection.</em> Wiley, p.156, table 24.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(phosphor)
plot(phosphor)
summary(lm.phosphor &lt;- lm(plant ~ ., data = phosphor))
summary(lts.phosphor &lt;- ltsReg(plant ~ ., data = phosphor))

phosphor.x &lt;- data.matrix(phosphor[, 1:2])
cPh &lt;- covMcd(phosphor.x)
plot(cPh, "dd")
</code></pre>

<hr>
<h2 id='pilot'>Pilot-Plant Data</h2><span id='topic+pilot'></span>

<h3>Description</h3>

<p>Pilot-Plant data from Daniel and Wood (1971). The response variable
corresponds to the acid content determined by titration and the
explanatory variable is the organic acid content determined by
extraction and weighing. This data set was analyzed also by Yale and
Forsythe (1976).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pilot, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 2 variables.
</p>

<dl>
<dt><code>X</code></dt><dd><p>Organic acid content - extraction</p>
</dd>
<dt><code>Y</code></dt><dd><p>Acid content - titration </p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, page 21, table 1.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pilot)
summary(lm.pilot &lt;- lm(Y ~.,data=pilot))

</code></pre>

<hr>
<h2 id='plot-methods'>Plot an Object of the &quot;Psi Function&quot; Class</h2><span id='topic+plot-methods'></span><span id='topic+plot+2Cpsi_func-method'></span>

<h3>Description</h3>

<p>The <code><a href="graphics.html#topic+plot">plot</a></code> method objects of class
<code><a href="#topic+psi_func-class">psi_func</a></code> simply visualizes the
<code class="reqn">\rho()</code>, <code class="reqn">\psi()</code>, and weight functions and their
derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'psi_func'
plot(x, y,
     which = c("rho", "psi", "Dpsi", "wgt", "Dwgt"),
     main = "full", 
     col = c("black", "red3", "blue3", "dark green", "light green"),
     leg.loc = "right", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot-methods_+3A_x">x</code></td>
<td>
<p>object of class <code><a href="#topic+psi_func-class">psi_func</a></code> to be plotted</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_y">y</code></td>
<td>
<p>(optional) vector of abscissa values (to plot object at).</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_which">which</code></td>
<td>
<p><code><a href="base.html#topic+character">character</a></code> vector of slots to be included in
plot; by default, all of the slots are included</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_main">main</code></td>
<td>
<p>string or logical indicating the kind of plot title;
either <code>"full"</code>, <code>"short"</code> or <code>FALSE</code> which chooses a
full, a short or no main title at all.</p>
</td></tr>

<tr><td><code id="plot-methods_+3A_col">col</code></td>
<td>
<p>colors to be used for the different slots</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_leg.loc">leg.loc</code></td>
<td>
<p>legend placement, see also <code>x</code> argument
of <code><a href="graphics.html#topic+legend">legend</a></code></p>
</td></tr>
<tr><td><code id="plot-methods_+3A_...">...</code></td>
<td>
<p>passed to <code><a href="graphics.html#topic+matplot">matplot</a></code></p>
</td></tr>
</table>


<h3>Note</h3>

<p>An earlier version had argument <code>shortMain</code> which is deprecated
now. Use <code>main = "short"</code> instead of <code>shortMain = TRUE</code>.
</p>
<p>If you want to specify your own title, use <code>main=FALSE</code>, and a
subsequent <code><a href="graphics.html#topic+title">title</a>(...)</code> call.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+psiFunc">psiFunc</a>()</code> and the <code><a href="base.html#topic+class">class</a></code>
<code><a href="#topic+psi_func-class">psi_func</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(huberPsi)
plot(huberPsi, which=c("psi", "Dpsi", "wgt"),
     main="short", leg = "topleft")

plot(hampelPsi)
## Plotting aspect ratio = 1:1 :
plot(hampelPsi, asp=1, main="short",
     which = c("psi", "Dpsi", "wgt", "Dwgt"))
</code></pre>

<hr>
<h2 id='plot.lmrob'>Plot Method for &quot;lmrob&quot; Objects</h2><span id='topic+plot.lmrob'></span>

<h3>Description</h3>

<p>Diagnostic plots for elements of class lmrob
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lmrob'
plot(x, which = 1:5,
     caption = c("Standardized residuals vs. Robust Distances",
   "Normal Q-Q vs. Residuals", "Response vs. Fitted Values",
   "Residuals vs. Fitted Values" , "Sqrt of abs(Residuals) vs. Fitted Values"),
   panel = if(add.smooth) panel.smooth else points,
   sub.caption = deparse(x$call), main = "",
   compute.MD = TRUE,
   ask = prod(par("mfcol")) &lt; length(which) &amp;&amp; dev.interactive(),
   id.n = 3, labels.id = names(residuals(x)), cex.id = 0.75,
   label.pos = c(4,2), qqline = TRUE, add.smooth = getOption("add.smooth"),
   ..., p=0.025)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lmrob_+3A_x">x</code></td>
<td>
<p> an object as created by <code>lmrob</code> </p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_which">which</code></td>
<td>
<p> integer number between 1 and 5 to specify which
plot is desired </p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_caption">caption</code></td>
<td>
<p>Caption for the different plots</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_panel">panel</code></td>
<td>
<p>panel function.  The useful alternative to
<code><a href="graphics.html#topic+points">points</a></code>, <code><a href="graphics.html#topic+panel.smooth">panel.smooth</a></code> can be chosen
by <code>add.smooth = TRUE</code>.</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_main">main</code></td>
<td>
<p>main title</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_sub.caption">sub.caption</code></td>
<td>
<p>sub titles</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_compute.md">compute.MD</code></td>
<td>
<p>logical indicating if the robust Mahalanobis
distances should be recomputed, using <code><a href="#topic+covMcd">covMcd</a>()</code> when
needed, i.e., if <code>which</code> contains <code>1</code>.</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_ask">ask</code></td>
<td>
<p>waits for user input before displaying each plot </p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_id.n">id.n</code></td>
<td>
<p>number of points to be labelled in each plot, starting
with the most extreme.</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_labels.id">labels.id</code></td>
<td>
<p>vector of labels, from which the labels for extreme
points will be chosen.  <code>NULL</code> uses observation numbers.</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_cex.id">cex.id</code></td>
<td>
<p>magnification of point labels.</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_label.pos">label.pos</code></td>
<td>
<p>positioning of labels, for the left half and right
half of the graph respectively.</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_qqline">qqline</code></td>
<td>
<p>logical indicating if a <code><a href="stats.html#topic+qqline">qqline</a>()</code> should be
added to the normal Q-Q plot.</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_add.smooth">add.smooth</code></td>
<td>
<p>logical indicating if a smoother should be added to
most plots; see also <code>panel</code> above.</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_...">...</code></td>
<td>
<p>optional arguments for <code><a href="graphics.html#topic+par">par</a></code>,
<code><a href="graphics.html#topic+title">title</a></code>, etc.</p>
</td></tr>
<tr><td><code id="plot.lmrob_+3A_p">p</code></td>
<td>
<p>threshold for distance-distance plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>if <code>compute.MD = TRUE</code> and the robust Mahalanobis distances need
to be computed, they are stored (&ldquo;cached&rdquo;) with the object
<code>x</code> when this function has been called from top-level.
</p>


<h3>References</h3>

<p>Robust diagnostic plots as in Rousseeuw and van Zomeren (1990), see
&lsquo;References&rsquo; in <code><a href="#topic+ltsPlot">ltsPlot</a></code>.
</p>


<h3>See Also</h3>

 <p><code><a href="#topic+lmrob">lmrob</a></code>, also for examples, <code><a href="stats.html#topic+plot.lm">plot.lm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(starsCYG)
## Plot simple data and fitted lines
plot(starsCYG)
 lmST &lt;-    lm(log.light ~ log.Te, data = starsCYG)
RlmST &lt;- lmrob(log.light ~ log.Te, data = starsCYG)
RlmST
abline(lmST, col = "red")
abline(RlmST, col = "blue")

op &lt;- par(mfrow = c(2,2), mgp = c(1.5, 0.6, 0), mar= .1+c(3,3,3,1))
plot(RlmST, which = c(1:2, 4:5))
par(op)
</code></pre>

<hr>
<h2 id='plot.lts'>Robust LTS Regression Diagnostic Plots</h2><span id='topic+plot.lts'></span><span id='topic+ltsPlot'></span>

<h3>Description</h3>

<p>Four plots (selectable by <code>which</code>) are currently provided:
</p>

<ol>
<li><p> a plot of the standardized residuals versus their index,
</p>
</li>
<li><p> a plot of the standardized residuals versus fitted values,
</p>
</li>
<li><p> a Normal Q-Q plot of the standardized residuals, and
</p>
</li>
<li><p> a regression diagnostic plot (standardized residuals versus
robust distances of the predictor variables).
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lts'
plot(x, which = c("all","rqq","rindex","rfit","rdiag"),
     classic=FALSE, ask = (which[1] == "all" &amp;&amp; dev.interactive()),
     id.n, ...)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lts_+3A_x">x</code></td>
<td>
<p>a <code>lts</code> object, typically result of <code>ltsReg</code>.</p>
</td></tr>
<tr><td><code id="plot.lts_+3A_which">which</code></td>
<td>
<p>string indicating which plot to show.  See the
<em>Details</em> section for a description of the options.  Defaults
to <code>"all"</code>.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="plot.lts_+3A_classic">classic</code></td>
<td>
<p>whether to plot the classical distances too. Default is
<code>FALSE</code>.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="plot.lts_+3A_ask">ask</code></td>
<td>
<p>logical indicating if the user should be <em>ask</em>ed
before each plot, see <code><a href="graphics.html#topic+par">par</a>(ask=.)</code>.  Defaults to
<code>which == "all" &amp;&amp; <a href="grDevices.html#topic+dev.interactive">dev.interactive</a>()</code>.
</p>
</td></tr>
<tr><td><code id="plot.lts_+3A_id.n">id.n</code></td>
<td>
<p>number of observations to be identified by a label starting
with the most extreme.  Default is the number of identified outliers
(can be different for the different plots - see Details).</p>
</td></tr>
<tr><td><code id="plot.lts_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function produces several plots based on the robust and classical
regression estimates.
Which of them to select is specified by the attribute  <code>which</code>.
The possible options are:
</p>

<dl>
<dt><code>rqq</code>:</dt><dd><p>Normal Q-Q plot of the standardized residuals;</p>
</dd>
<dt><code>rindex</code>:</dt><dd><p>plot of the standardized residuals versus their
index;</p>
</dd>
<dt><code>rfit</code>:</dt><dd><p>plot of the standardized residuals versus fitted
values;</p>
</dd>
<dt><code>rdiag</code>:</dt><dd><p>regression diagnostic plot.</p>
</dd>
</dl>

<p>The normal quantile plot produces a normal Q-Q plot of the
standardized residuals.
A line is drawn which passes through the first and third quantile.
The <code>id.n</code> residuals with largest distances from this line are
identified by labels (the observation number).  The default for
<code>id.n</code> is the number of regression outliers (lts.wt==0).
</p>
<p>In the Index plot and in the Fitted values plot the standardized
residuals are displayed against the observation number or the fitted
value respectively.
A horizontal dashed line is drawn at 0 and two solid horizontal lines are
located at +2.5 and -2.5. The id.n residuals with largest absolute values are
identified by labels (the observation number).  The default for id.n is the
number regression outliers (lts.wt==0).
</p>
<p>The regression diagnostic plot, introduced by Rousseeuw and van
Zomeren (1990), displays the standardized residuals versus robust
distances. Following Rousseeuw and van Zomeren (1990), the
horizontal dashed lines are located at +2.5 and -2.5  and the
vertical line is located at the upper 0.975 percent point of the
chi-squared distribution with p degrees of freedom. The id.n residuals
with largest absolute values and/or largest robust Mahalanobis distances are
identified by labels (the observation number). The default for id.n is
the number of all outliers: regression outliers (lts.wt==0) + leverage
(bad and good) points (RD &gt; 0.975 percent point of the chi-squared
distribution with p degrees of freedom).
</p>


<h3>References</h3>

<p>P. J. Rousseeuw and van Zomeren, B. C. (1990).
Unmasking Multivariate Outliers and Leverage Points.
<em>Journal of the American Statistical Association</em> <b>85</b>, 633&ndash;639.
</p>
<p>P. J. Rousseeuw and K. van Driessen (1999)
A fast algorithm for the minimum covariance determinant estimator.
<em>Technometrics</em> <b>41</b>, 212&ndash;223.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covPlot">covPlot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hbk)
lts &lt;- ltsReg(Y ~ ., data = hbk)
lts
plot(lts, which = "rqq") 
</code></pre>

<hr>
<h2 id='plot.mcd'>Robust Distance Plots</h2><span id='topic+covPlot'></span><span id='topic+plot.mcd'></span>

<h3>Description</h3>

<p>Shows the Mahalanobis distances based on robust and classical estimates
of the location and the covariance matrix in different plots.
The following plots are available:
</p>

<ul>
<li><p> index plot of the robust and mahalanobis distances
</p>
</li>
<li><p> distance-distance plot
</p>
</li>
<li><p> Chisquare QQ-plot of the robust and mahalanobis distances
</p>
</li>
<li><p> plot of the tolerance ellipses (robust and classic)
</p>
</li>
<li><p> Scree plot - Eigenvalues comparison plot
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mcd'
plot(x,
     which = c("all", "dd", "distance", "qqchi2",
               "tolEllipsePlot", "screeplot"),
     classic = FALSE, ask = (which[1] == "all" &amp;&amp; dev.interactive()),
     cutoff, id.n, labels.id = rownames(x$X), cex.id = 0.75,
     label.pos = c(4,2), tol = 1e-7, ...)

covPlot(x,
     which = c("all", "dd", "distance", "qqchi2",
               "tolEllipsePlot", "screeplot"),
     classic = FALSE, ask = (which[1] == "all" &amp;&amp; dev.interactive()),
     m.cov = covMcd(x),
     cutoff = NULL, id.n, labels.id = rownames(x), cex.id = 0.75,
     label.pos = c(4,2), tol = 1e-07, ...)




</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mcd_+3A_x">x</code></td>
<td>
<p>For the <code>plot()</code> method, a <code>mcd</code> object, typically
result of <code><a href="#topic+covMcd">covMcd</a></code>.<br />
For <code>covPlot()</code>, the numeric data matrix such as the <code>X</code>
component as returned from <code><a href="#topic+covMcd">covMcd</a></code>.</p>
</td></tr>
<tr><td><code id="plot.mcd_+3A_which">which</code></td>
<td>
<p>string indicating which plot to show.  See the
<em>Details</em> section for a description of the options.  Defaults to <code>"all"</code>.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="plot.mcd_+3A_classic">classic</code></td>
<td>
<p>whether to plot the classical distances too.
Defaults to <code>FALSE</code>.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="plot.mcd_+3A_ask">ask</code></td>
<td>
<p>logical indicating if the user should be <em>ask</em>ed
before each plot, see <code><a href="graphics.html#topic+par">par</a>(ask=.)</code>.  Defaults to
<code>which == "all" &amp;&amp; <a href="grDevices.html#topic+dev.interactive">dev.interactive</a>()</code>.
</p>
</td></tr>
<tr><td><code id="plot.mcd_+3A_cutoff">cutoff</code></td>
<td>
<p>the cutoff value for the distances.</p>
</td></tr>
<tr><td><code id="plot.mcd_+3A_id.n">id.n</code></td>
<td>
<p>number of observations to be identified by a label.  If
not supplied, the number of observations with distance larger than
<code>cutoff</code> is used.</p>
</td></tr>
<tr><td><code id="plot.mcd_+3A_labels.id">labels.id</code></td>
<td>
<p>vector of labels, from which the labels for extreme
points will be chosen.  <code>NULL</code> uses observation numbers.</p>
</td></tr>
<tr><td><code id="plot.mcd_+3A_cex.id">cex.id</code></td>
<td>
<p>magnification of point labels.</p>
</td></tr>
<tr><td><code id="plot.mcd_+3A_label.pos">label.pos</code></td>
<td>
<p>positioning of labels, for the left half and right
half of the graph respectively (used as <code><a href="graphics.html#topic+text">text</a>(.., pos=*)</code>).</p>
</td></tr>
<tr><td><code id="plot.mcd_+3A_tol">tol</code></td>
<td>
<p>tolerance to be used for computing the inverse, see
<code><a href="Matrix.html#topic+solve">solve</a></code>.  Defaults to <code>tol = 1e-7</code>.</p>
</td></tr>
<tr><td><code id="plot.mcd_+3A_m.cov">m.cov</code></td>
<td>
<p>an object similar to those of class <code>"mcd"</code>; however
only its components <code>center</code> and <code>cov</code> will be used.  If
missing, the MCD will be computed (via <code><a href="#topic+covMcd">covMcd</a>()</code>).</p>
</td></tr>
<tr><td><code id="plot.mcd_+3A_...">...</code></td>
<td>
<p>other parameters to be passed through to plotting functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions produce several plots based on the robust and classical
location and covariance matrix.  Which of them to select is specified
by the attribute  <code>which</code>.  The <code>plot</code> method for
<code>"mcd"</code> objects is calling <code>covPlot()</code> directly, whereas
<code>covPlot()</code> should also be useful for plotting other (robust)
covariance estimates.  The possible options are:
</p>

<dl>
<dt><code>distance</code></dt><dd><p>index plot of the robust distances</p>
</dd>
<dt><code>dd</code></dt><dd><p>distance-distance plot</p>
</dd>
<dt><code>qqchi2</code></dt><dd><p>a qq-plot of the robust distances versus the
quantiles of the chi-squared distribution</p>
</dd>
<dt><code>tolEllipsePlot</code></dt><dd><p>a tolerance ellipse plot, via
<code><a href="#topic+tolEllipsePlot">tolEllipsePlot</a>()</code></p>
</dd>
<dt><code>screeplot</code></dt><dd><p>an eigenvalues comparison plot - screeplot</p>
</dd>
</dl>

<p>The Distance-Distance Plot, introduced by
Rousseeuw and van Zomeren (1990), displays the robust distances
versus the classical Mahalanobis distances.  The dashed line is the set of
points where the robust distance is equal to the classical distance.
The horizontal and vertical lines are drawn at values equal to the cutoff
which defaults to square root of the 97.5% quantile of a chi-squared
distribution with p degrees of freedom.  Points beyond these lines can
be considered outliers.
</p>


<h3>References</h3>

<p>P. J. Rousseeuw and van Zomeren, B. C. (1990).
Unmasking Multivariate Outliers and Leverage Points.
<em>Journal of the American Statistical Association</em> <b>85</b>, 633&ndash;639.
</p>
<p>P. J. Rousseeuw and K. van Driessen (1999)
A fast algorithm for the minimum covariance determinant estimator.
<em>Technometrics</em> <b>41</b>, 212&ndash;223.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+tolEllipsePlot">tolEllipsePlot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Animals, package ="MASS")
brain &lt;- Animals[c(1:24, 26:25, 27:28),]
mcd &lt;- covMcd(log(brain))

plot(mcd, which = "distance", classic = TRUE)# 2 plots
plot(mcd, which = "dd")
plot(mcd, which = "tolEllipsePlot", classic = TRUE)
op &lt;- par(mfrow = c(2,3))
plot(mcd) ## -&gt; which = "all" (5 plots)
par(op)

## same plots for another robust Cov estimate:
data(hbk)
hbk.x &lt;- data.matrix(hbk[, 1:3])
cOGK &lt;- covOGK(hbk.x, n.iter = 2, sigmamu = scaleTau2,
               weight.fn = hard.rejection)
covPlot(hbk.x, m.cov = cOGK, classic = TRUE)



</code></pre>

<hr>
<h2 id='possumDiv'>Possum Diversity Data</h2><span id='topic+possumDiv'></span><span id='topic+possum.mat'></span>

<h3>Description</h3>

<p>Possum diversity data: As issued from a study of the diversity
of possum (arboreal marsupials) in the Montane ash forest (Australia),
this dataset was collected in view of the management of hardwood
forest to take conservation and recreation values, as well as wood
production, into account.
</p>
<p>The study is fully described in the two references.
The number of different species of arboreal marsupials (possum) was
observed on 151 different 3ha sites with uniform vegetation. For each
site the nine variable measures (see below) were recorded.
The problem is to model the relationship between <code>diversity</code> and these
other variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(possumDiv, package="robustbase")</code></pre>


<h3>Format</h3>

<p>Two different representations of the same data are available:
</p>
<p><code>possumDiv</code> is a data frame of 151 observations
of 9 variables, where the last two are factors, <code>eucalyptus</code> with
3 levels and <code>aspect</code> with 4 levels.
</p>
<p><code>possum.mat</code> is a numeric (integer) matrix of 151 rows
(observations) and 14 columns (variables) where the last seven ones
are 0-1 dummy variables, three (<code>E.*</code>) are coding for the kind of
<code>eucalyptus</code> and the last four are 0-1 coding for the
<code>aspect</code> factor.
</p>
<p>The variables have the following meaning:
</p>

<dl>
<dt>Diversity</dt><dd><p>main variable of interest is the number of
different species of arboreal marsupial (possum) observed, with
values in 0:5.</p>
</dd>
<dt>Shrubs</dt><dd><p>the number of shrubs.</p>
</dd>
<dt>Stumps</dt><dd><p>the number of cut stumps from past logging operations.</p>
</dd>
<dt>Stags</dt><dd><p>the number of stags (hollow-bearing trees).</p>
</dd>
<dt>Bark</dt><dd><p>bark index (integer) vector reflecting the quantity of
decorticating bark.</p>
</dd>
<dt>Habitat</dt><dd><p>an integer score indicating the suitability of
nesting and foraging habitat for Leadbeater's possum.</p>
</dd>
<dt>BAcacia</dt><dd><p>a numeric vector giving the basal area of acacia species.</p>
</dd>
</dl>
<p><br />
</p>
<dl>
<dt>eucalyptus</dt><dd><p>a 3-level <code><a href="base.html#topic+factor">factor</a></code>
specifying the species of eucalypt with the greatest stand basal
area.  This has the same information as the following three variables</p>
</dd>
<dt>E.regnans</dt><dd><p>0-1 indicator for Eucalyptus regnans</p>
</dd>
<dt>E.delegatensis</dt><dd><p>0-1 indicator for Eucalyptus deleg.</p>
</dd>
<dt>E.nitens</dt><dd><p>0-1 indicator for Eucalyptus nitens</p>
</dd>
</dl>
<p><br />
</p>
<dl>
<dt>aspect</dt><dd><p>a 4-level <code><a href="base.html#topic+factor">factor</a></code> specifying the aspect
of the site.  It is the same information as the following four
variables.</p>
</dd>
<dt>NW-NE</dt><dd><p>0-1 indicator</p>
</dd>
<dt>NW-SE</dt><dd><p>0-1 indicator</p>
</dd>
<dt>SE-SW</dt><dd><p>0-1 indicator</p>
</dd>
<dt>SW-NW</dt><dd><p>0-1 indicator</p>
</dd>
</dl>



<h3>Source</h3>

<p>Eva Cantoni (2004)
Analysis of Robust Quasi-deviances for Generalized Linear Models.
<em>Journal of Statistical Software</em> <b>10</b>, 04,
<a href="https://www.jstatsoft.org/article/view/v010i04">https://www.jstatsoft.org/article/view/v010i04</a>
</p>


<h3>References</h3>

<p>Lindenmayer, D. B., Cunningham, R. B., Tanton, M. T., Nix, H. A. and
Smith, A. P. (1991)
The conservation of arboreal marsupials in the montane ash forests of
the central highlands of victoria, south-east australia: III. The habitat
requirements of leadbeater's possum <em>gymnobelideus leadbeateri</em> and
models of the diversity and abundance of arboreal marsupials.
<em>Biological Conservation</em> <b>56</b>, 295&ndash;315.
</p>
<p>Lindenmayer, D. B., Cunningham, R. B., Tanton, M. T., Smith, A. P. and
Nix, H. A. (1990)
The conservation of arboreal marsupials in the montane ash forests of
the victoria, south-east australia, I. Factors influencing the occupancy of
trees with hollows, <em>Biological Conservation</em> <b>54</b>, 111&ndash;131.
</p>
<p>See also the references in <code><a href="#topic+glmrob">glmrob</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(possumDiv)
head(possum.mat)

str(possumDiv)
## summarize all variables as multilevel factors:
summary(as.data.frame(lapply(possumDiv, function(v)
                             if(is.integer(v)) factor(v) else v)))

## Following Cantoni &amp; Ronchetti (2001), JASA, p.1026 f.:% cf. ../tests/poisson-ex.R
pdFit &lt;- glmrob(Diversity ~ . , data = possumDiv,
                family=poisson, tcc = 1.6, weights.on.x = "hat", acc = 1e-15)
summary(pdFit)
summary(pdF2 &lt;- update(pdFit, ~ . -Shrubs))
summary(pdF3 &lt;- update(pdF2,  ~ . -eucalyptus))
summary(pdF4 &lt;- update(pdF3,  ~ . -Stumps))
summary(pdF5 &lt;- update(pdF4,  ~ . -BAcacia))
summary(pdF6 &lt;- update(pdF5,  ~ . -aspect))# too much ..
anova(pdFit, pdF3, pdF4, pdF5, pdF6, test = "QD") # indeed,
## indeed, the last simplification is too much
possumD.2 &lt;- within(possumDiv, levels(aspect)[1:3] &lt;- rep("other", 3))
## and use this binary 'aspect' instead of the 4-level one:
summary(pdF5.1 &lt;- update(pdF5, data = possumD.2))

if(FALSE) # not ok, as formually not nested.
anova(pdF5, pdF5.1)

summarizeRobWeights(weights(pdF5.1, type="rob"), eps = 0.73)
##-&gt;  "outliers"  (1, 59, 110)
wrob &lt;- setNames(weights(pdF5.1, type="rob"), rownames(possumDiv))
head(sort(wrob))
</code></pre>

<hr>
<h2 id='predict.glmrob'>Predict Method for Robust GLM (&quot;glmrob&quot;) Fits</h2><span id='topic+predict.glmrob'></span>

<h3>Description</h3>

<p>Obtains predictions and optionally estimates standard errors of those
predictions from a fitted <em>robust</em> generalized linear model (GLM)
object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmrob'
predict(object, newdata = NULL,
       type = c("link", "response", "terms"), se.fit = FALSE,
       dispersion = NULL, terms = NULL, na.action = na.pass, ...)
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="predict.glmrob_+3A_object">object</code></td>
<td>
<p>a fitted object of class inheriting from <code>"glmrob"</code>.</p>
</td></tr>
<tr><td><code id="predict.glmrob_+3A_newdata">newdata</code></td>
<td>
<p>optionally, a data frame in which to look for variables with
which to predict.  If omitted, the fitted linear predictors are used.</p>
</td></tr>
<tr><td><code id="predict.glmrob_+3A_type">type</code></td>
<td>
<p>the type of prediction required.  The default is on the
scale of the linear predictors; the alternative <code>"response"</code>
is on the scale of the response variable.  Thus for a default
binomial model the default predictions are of log-odds (probabilities
on logit scale) and <code>type = "response"</code> gives the predicted
probabilities.  The <code>"terms"</code> option returns a matrix giving the
fitted values of each term in the model formula on the linear predictor
scale.
</p>
<p>The value of this argument can be abbreviated.
</p>
</td></tr>
<tr><td><code id="predict.glmrob_+3A_se.fit">se.fit</code></td>
<td>
<p>logical switch indicating if standard errors are required.</p>
</td></tr>
<tr><td><code id="predict.glmrob_+3A_dispersion">dispersion</code></td>
<td>
<p>the dispersion of the GLM fit to be assumed in
computing the standard errors.  If omitted, that returned by
<code>summary</code> applied to the object is used.</p>
</td></tr>
<tr><td><code id="predict.glmrob_+3A_terms">terms</code></td>
<td>
<p>with <code>type="terms"</code> by default all terms are returned.
A character vector specifies which terms are to be returned</p>
</td></tr>
<tr><td><code id="predict.glmrob_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values in <code>newdata</code>.  The default is to predict <code>NA</code>.</p>
</td></tr>
<tr><td><code id="predict.glmrob_+3A_...">...</code></td>
<td>
<p>optional further arguments, currently simply passed to
<code><a href="#topic+predict.lmrob">predict.lmrob</a>()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>



<p>If <code>se = FALSE</code>, a vector or matrix of predictions.
If <code>se = TRUE</code>, a list with components
</p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>Predictions</p>
</td></tr>
<tr><td><code>se.fit</code></td>
<td>
<p>Estimated standard errors</p>
</td></tr>
<tr><td><code>residual.scale</code></td>
<td>
<p>A scalar giving the square root of the
dispersion used in computing the standard errors.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andreas Ruckstuhl</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmrob">glmrob</a>()</code> to fit these robust GLM models,
<code><a href="#topic+residuals.glmrob">residuals.glmrob</a>()</code> and other methods;
<code><a href="stats.html#topic+predict.lm">predict.lm</a>()</code>, the method used for a non-robust fit.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(carrots)
## simplistic testing &amp; training:
i.tr &lt;- sample(24, 20)
fm1 &lt;- glmrob(cbind(success, total-success) ~ logdose + block,
              family = binomial, data = carrots, subset = i.tr)
fm1
predict(fm1, carrots[-i.tr, ]) # --&gt; numeric vector
predict(fm1, carrots[-i.tr, ],
        type="response", se = TRUE)# -&gt; a list





data(vaso)
Vfit &lt;- glmrob(Y ~ log(Volume) + log(Rate), family=binomial, data=vaso)
newd &lt;- expand.grid(Volume = (V. &lt;- seq(.5, 4, by = 0.5)),
                    Rate   = (R. &lt;- seq(.25,4, by = 0.25)))
p &lt;- predict(Vfit, newd)
filled.contour(V., R., matrix(p, length(V.), length(R.)),
      main = "predict(glmrob(., data=vaso))", xlab="Volume", ylab="Rate")
</code></pre>

<hr>
<h2 id='predict.lmrob'>Predict method for Robust Linear Model (&quot;lmrob&quot;) Fits</h2><span id='topic+predict.lmrob'></span>

<h3>Description</h3>

<p>Predicted values based on robust linear model object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lmrob'
predict(object, newdata, se.fit = FALSE,
       scale = NULL, df = NULL,
       interval = c("none", "confidence", "prediction"), level = 0.95,
       type = c("response", "terms"), terms = NULL,
       na.action = na.pass, pred.var = res.var/weights, weights = 1, ...)
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="predict.lmrob_+3A_object">object</code></td>
<td>
<p>object of class inheriting from <code>"lmrob"</code></p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame in which to look for variables with
which to predict.  If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_se.fit">se.fit</code></td>
<td>
<p>a switch indicating if standard errors are required.</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_scale">scale</code></td>
<td>
<p>scale parameter for std.err. calculation</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_df">df</code></td>
<td>
<p>degrees of freedom for scale</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_interval">interval</code></td>
<td>
<p>type of interval calculation.</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_level">level</code></td>
<td>
<p>tolerance/confidence level</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_type">type</code></td>
<td>
<p>Type of prediction (response or model term).</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_terms">terms</code></td>
<td>
<p>if <code>type="terms"</code>, which terms (default is all terms)</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_na.action">na.action</code></td>
<td>
<p>function determining what should be done with missing
values in <code>newdata</code>.  The default is to predict <code>NA</code>.</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_pred.var">pred.var</code></td>
<td>
<p>the variance(s) for future observations to be assumed
for prediction intervals.  See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_weights">weights</code></td>
<td>
<p>variance weights for prediction. This can be a numeric
vector or a one-sided model formula. In the latter case, it is
interpreted as an expression evaluated in <code>newdata</code></p>
</td></tr>
<tr><td><code id="predict.lmrob_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that this <code>lmrob</code> method for <code><a href="stats.html#topic+predict">predict</a></code> is
closely modeled after the method for <code>lm()</code>,
<code><a href="stats.html#topic+predict.lm">predict.lm</a></code>, maybe see there for caveats with missing
value treatment.

The prediction intervals are for a single observation at each case in
<code>newdata</code> (or by default, the data used for the fit) with error
variance(s) <code>pred.var</code>.  This can be a multiple of <code>res.var</code>,
the estimated value of <code class="reqn">\sigma^2</code>: the default is to assume that
future observations have the same error variance as those
used for fitting.  If <code>weights</code> is supplied, the inverse of this
is used as a scale factor.  For a weighted fit, if the prediction
is for the original data frame, <code>weights</code> defaults to the weights
used for the  model fit, with a warning since it might not be the
intended result.  If the fit was weighted and <code>newdata</code> is given, the
default is to assume constant prediction variance, with a warning.
</p>


<h3>Value</h3>


<p><code>predict.lmrob</code> produces a vector of predictions or a matrix of
predictions and bounds with column names <code>fit</code>, <code>lwr</code>, and
<code>upr</code> if <code>interval</code> is set.  If <code>se.fit</code> is
<code>TRUE</code>, a list with the following components is returned:
</p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>vector or matrix as above</p>
</td></tr>
<tr><td><code>se.fit</code></td>
<td>
<p>standard error of predicted means</p>
</td></tr>
<tr><td><code>residual.scale</code></td>
<td>
<p>residual standard deviations</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom for residual</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Andreas Ruckstuhl</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob">lmrob</a></code> and the (non-robust) traditional
<code><a href="stats.html#topic+predict.lm">predict.lm</a></code> method.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Predictions --- artificial example -- closely following  example(predict.lm)

set.seed(5)
n &lt;- length(x &lt;- sort(c(round(rnorm(25), 1), 20)))
y &lt;- x + rnorm(n)
iO &lt;- c(sample(n-1, 3), n)
y[iO] &lt;- y[iO] + 10*rcauchy(iO)

p.ex &lt;- function(...) {
  plot(y ~ x, ...); abline(0,1, col="sky blue")
  points(y ~ x, subset=iO, col="red", pch=2)
  abline(lm   (y ~ x), col = "gray40")
  abline(lmrob(y ~ x), col = "forest green")
  legend("topleft", c("true", "Least Squares", "robust"),
         col = c("sky blue", "gray40", "forest green"), lwd=1.5, bty="n")
}
p.ex()

fm &lt;- lmrob(y ~ x)
predict(fm)
new &lt;- data.frame(x = seq(-3, 10, 0.25))
str(predict(fm, new, se.fit = TRUE))
pred.w.plim &lt;- predict(fm, new, interval = "prediction")
pred.w.clim &lt;- predict(fm, new, interval = "confidence")
pmat &lt;- cbind(pred.w.clim, pred.w.plim[,-1])

matlines(new$x, pmat, lty = c(1,2,2,3,3))# add to first plot
## show zoom-in region :
rect(xleft = -3, ybottom = -20, xright = 10, ytop = 40,
     lty = 3, border="orange4")

## now zoom in :
p.ex(xlim = c(-3,10), ylim = c(-20, 40))
matlines(new$x, pmat, lty = c(1,2,2,3,3))
box(lty = 3, col="orange4", lwd=3)
legend("bottom", c("fit", "lwr CI", "upr CI", "lwr Pred.I", "upr Pred.I"),
       col = 1:5, lty=c(1,2,2,3,3), bty="n")

## Prediction intervals, special cases
##  The first three of these throw warnings
w &lt;- 1 + x^2
fit &lt;- lmrob(y ~ x)
wfit &lt;- lmrob(y ~ x, weights = w)
predict(fit,       interval = "prediction")
predict(wfit,      interval = "prediction")
predict(wfit, new, interval = "prediction")
predict(wfit, new, interval = "prediction", weights = (new$x)^2) -&gt; p.w2
p.w2
stopifnot(identical(p.w2, ## the same as using formula:
     predict(wfit, new, interval = "prediction", weights = ~x^2)))
</code></pre>

<hr>
<h2 id='print.lmrob'>Print Method for Objects of Class &quot;lmrob&quot;</h2><span id='topic+print.lmrob'></span>

<h3>Description</h3>

<p>Print method for elements of class <code>"lmrob"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lmrob'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.lmrob_+3A_x">x</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code>lmrob</code>, typically created by
<code><a href="#topic+lmrob">lmrob</a></code>.</p>
</td></tr>
<tr><td><code id="print.lmrob_+3A_digits">digits</code></td>
<td>
<p>number of digits for printing, see <code>digits</code> in
<code><a href="base.html#topic+options">options</a></code>.</p>
</td></tr>
<tr><td><code id="print.lmrob_+3A_...">...</code></td>
<td>
<p>potentially more arguments passed to methods.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob">lmrob</a></code>, <code><a href="#topic+summary.lmrob">summary.lmrob</a></code>,
<code><a href="base.html#topic+print">print</a></code> and <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(coleman)
( m1 &lt;- lmrob(Y ~ ., data=coleman) ) # -&gt; print.lmrob() method
</code></pre>

<hr>
<h2 id='psi_func-class'>Class of &quot;Psi Functions&quot; for M-Estimation</h2><span id='topic+psi_func-class'></span>

<h3>Description</h3>

<p>The class <code>"psi_func"</code> is used to store <code class="reqn">\psi \ (psi)</code>
functions for M-estimation.  In particular, an object of the class
contains <code class="reqn">\rho(x) \ (\code{rho})</code>, its derivative
<code class="reqn">\psi(x) \ (psi)</code>, the weight function <code class="reqn">\psi(x)/x</code>, and
first derivative of <code class="reqn">\psi</code>, <code>Dpsi = </code> <code class="reqn">\psi'(x)</code>.
</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>new("psi_func", ...)</code>,
but preferably by <code><a href="#topic+psiFunc">psiFunc</a>(...)</code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>rho</code>:</dt><dd><p>the <code class="reqn">\rho()</code> function, an object of
class <code>"functionX"</code>. This is used to formulate the
objective function; <code class="reqn">\rho()</code> can be regarded as generalized
negative log-likelihood.</p>
</dd>
<dt><code>psi</code>:</dt><dd><p><code class="reqn">\psi()</code> is the derivative of <code class="reqn">\rho</code>,
<code class="reqn">\psi(x) = \frac{d}{dx} \rho(x)</code>;
also of class <code>"functionX"</code>.</p>
</dd>
<dt><code>wgt</code>:</dt><dd><p>The weight function <code class="reqn">\psi(x)/x</code>,
of class <code>"functionX"</code>.</p>
</dd>
<dt><code>Dpsi</code>:</dt><dd><p>the derivative of <code class="reqn">\psi</code>,
<code class="reqn">Dpsi(x) = psi'(x)</code>; of class <code>"functionX"</code>.</p>
</dd>
<dt><code>Dwgt</code>:</dt><dd><p>the derivative of the weight function,
of class <code>"functionX"</code>, is generated automatically if
<code><a href="#topic+psiFunc">psiFunc</a></code> constructor is used.</p>
</dd>
<dt><code>tDefs</code>:</dt><dd><p><em>named</em> numeric vector of <b>t</b>uning
parameter <b>Def</b>ault values.</p>
</dd>

<dt><code>Erho</code>:</dt><dd><p>A function of class <code>"functionXal"</code> for
computing <code class="reqn">E[\rho(X)]</code> when <code class="reqn">X</code> is standard normal
<code class="reqn">\mathcal{N}(0,1)</code>.</p>
</dd>
<dt><code>Epsi2</code>:</dt><dd><p>A function of class <code>"functionXal"</code> for
computing <code class="reqn">E[\psi^2(X)]</code> when <code class="reqn">X</code> is standard normal.</p>
</dd>
<dt><code>EDpsi</code>:</dt><dd><p>A function of class <code>"functionXal"</code> for
computing <code class="reqn">E[\psi'(X)]</code> when <code class="reqn">X</code> is standard normal.</p>
</dd>
<dt><code>name</code>:</dt><dd><p>Name of <code class="reqn">\psi</code>-function used for printing.</p>
</dd>
<dt><code>xtras</code>:</dt><dd><p>Potentially further information.</p>
</dd>
</dl>



<h3>Methods</h3>

<p>Currently, only <code><a href="#topic+chgDefaults">chgDefaults</a>()</code>, <code><a href="#topic+plot-methods">plot</a>()</code>
and <code>show()</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+psiFunc">psiFunc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>str(huberPsi, give.attr = FALSE)

plot(hampelPsi)# calling the plot method (nicely showing "all" !)
</code></pre>

<hr>
<h2 id='psi.findc'>Find Tuning Constant(s) for &quot;lqq&quot; and &quot;ggw&quot; Psi Functions</h2><span id='topic+.psi.ggw.findc'></span><span id='topic+.psi.lqq.findc'></span><span id='topic+.psi.const'></span>

<h3>Description</h3>

<p>Find psi function tuning constant sets for <code>"LQQ"</code> and <code>"GGW"</code>
psi (<code class="reqn">\psi</code>) functions by specifying largest descent (minimal
slope), efficiency and or breakdown point.
</p>
<p><code>.psi.const()</code> is called from <code><a href="#topic+lmrob.control">lmrob.control</a>()</code> to
set the tuning constants for psi and chi for <code>"LQQ"</code> and
<code>"GGW"</code> psi.  Unless  the specified tuning constants are from
fixed small set where the computations are stored precomputed,
<code>.psi.const()</code> calls the corresponding <code>.psi.&lt;psi&gt;.findc()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>.psi.ggw.findc(ms, b, eff = NA, bp = NA,
               subdivisions = 100L,
               rel.tol = .Machine$double.eps^0.25, abs.tol = rel.tol,
               tol = .Machine$double.eps^0.25, ms.tol = tol/64, maxiter = 1000)

.psi.lqq.findc(ms, b.c, eff = NA, bp = NA,
               interval = c(0.1, 4), subdivisions = 100L,
               rel.tol = .Machine$double.eps^0.25, abs.tol = rel.tol,
               tol = .Machine$double.eps^0.25, maxiter = 1000)
.psi.const(cc, psi)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psi.findc_+3A_ms">ms</code></td>
<td>
<p>number, the minimal slope, typically negative.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_b">b</code>, <code id="psi.findc_+3A_b.c">b.c</code></td>
<td>
<p>number, specifying <code class="reqn">b</code> or <code class="reqn">b/c</code> for <code>"ggw"</code>
or <code>"lqq"</code> respectively.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_eff">eff</code></td>
<td>
<p>a number (or <code><a href="base.html#topic+NA">NA</a></code>), the desired
<em>efficiency</em>, in <code class="reqn">[0,1]</code> of the estimator.  If <code>NA</code>,
<code>bp</code> must be specified as valid number.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_bp">bp</code></td>
<td>
<p>a number (or <code><a href="base.html#topic+NA">NA</a></code>), the desired
<em><b>b</b>reakdown <b>p</b>oint</em> of the estimator, in <code class="reqn">[0,1]</code>.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_interval">interval</code></td>
<td>
<p>for finding <code class="reqn">c</code> via <code><a href="stats.html#topic+uniroot">uniroot</a>()</code>.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_subdivisions">subdivisions</code></td>
<td>
<p>passed to <code><a href="stats.html#topic+integrate">integrate</a>()</code>.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_rel.tol">rel.tol</code>, <code id="psi.findc_+3A_abs.tol">abs.tol</code></td>
<td>
<p>relative and absolute tolerance for
<code><a href="stats.html#topic+integrate">integrate</a>()</code>.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_tol">tol</code></td>
<td>
<p>relative tolerance for <code><a href="stats.html#topic+uniroot">uniroot</a>()</code>.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_ms.tol">ms.tol</code></td>
<td>
<p>relative tolerance for the internal
<code>.psi.ggw.finda()</code>, eventually passed to <code><a href="stats.html#topic+optimize">optimize</a></code>
inside (internal) <code>.psi.ggw.mxs()</code>.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_maxiter">maxiter</code></td>
<td>
<p>maximal number of iterations for
<code><a href="stats.html#topic+uniroot">uniroot</a>()</code>.</p>
</td></tr>

<tr><td><code id="psi.findc_+3A_cc">cc</code></td>
<td>
<p>(for <code>.psi.const()</code>:) numeric vector of length 4,
containing all constants <code>c(ms, b*, eff, bp)</code>, where
<code>b* = b</code>   for <code>"ggw"</code> and
<code>b* = b.c</code> for <code>"lqq"</code>, and one of <code>(eff, bp)</code>
is <code>NA</code>.</p>
</td></tr>
<tr><td><code id="psi.findc_+3A_psi">psi</code></td>
<td>
<p>a string, either <code>"ggw"</code> or <code>"lqq"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For some important special cases, the result of <code>.psi.*.findc()</code>
are stored precomputed for efficiency reasons.  These cases are (the
defaults for <code>tuning.chi</code> and <code>tuning.psi</code> respectively in
<code><a href="#topic+lmrob.control">lmrob.control</a>()</code>s result,
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>tuning.chi</code>               </td><td style="text-align: left;"><code>tuning.psi</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>c(-0.5, 1.5, NA, 0.5)</code>    </td><td style="text-align: left;"><code>c(-0.5, 1.5, 0.95, NA)</code>
  </td>
</tr>

</table>

<p>and for <code>"ggw"</code> additionally, these four cases:
</p>

<table>
<tr>
 <td style="text-align: left;">
    <code>tuning.chi</code>               </td><td style="text-align: left;"><code>tuning.psi</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
                                  </td><td style="text-align: left;"><code>c(-0.5, 1.5, 0.85, NA)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
    <code>c(-0.5, 1,   NA,  0.5)</code>   </td><td style="text-align: left;"><code>c(-0.5, 1,   0.95, NA)</code> </td>
</tr>
<tr>
 <td style="text-align: left;">
                                  </td><td style="text-align: left;"><code>c(-0.5, 1,   0.85, NA)</code>
  </td>
</tr>

</table>
 
<p>Note that for <code>"ggw"</code>, exactly these <code class="reqn">2+4 = 6</code> cases also
allow fast <code class="reqn">\rho</code> and <code class="reqn">\chi</code> (aka
<code class="reqn">\tilde\rho(\cdot)</code>, see <code><a href="#topic+Mchi">Mchi</a></code>),
function evaluations.  For all other tuning constant settings, rho()
evaluations are based on numerical integration via <span class="rlang"><b>R</b></span>'s own
<code>Rdqags()</code> C function (part of R's official API).
</p>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+numeric">numeric</a></code> vector of constants, for <code>"lqq"</code> or
<code>"ggw"</code> psi functions, respectively:
</p>

<dl>
<dt><code>"lqq"</code>:</dt><dd><p><code class="reqn">(b, c, s) = (b/c * c, c, s = 1 - min_slope)</code>,</p>
</dd>
<dt><code>"ggw"</code>:</dt><dd><p><code class="reqn">(0, a, b, c, \rho(\infty))</code>.</p>
</dd>
</dl>

<p><code>.psi.const(cc, psi)</code> returns the argument <code>cc</code> with the
above constant vectors as attribute <code>"constants"</code>, in the case of
<code>psi = "lqq"</code> in all cases (since <span class="pkg">robustbase</span> version &gt;=
0.93), for <code>psi = "ggw"</code> only in the non-standard cases.
</p>


<h3>Author(s)</h3>

<p>Manuel Koller (original) and Martin Maechler (arguments, export, docs).
</p>


<h3>References</h3>

<p>See the vignette about  
&ldquo;<code class="reqn">\psi</code>-Functions Available in Robustbase&rdquo;.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mpsi">Mpsi</a>()</code> etc for the psi function definitions;
<code><a href="#topic+.Mpsi.tuning.defaults">.Mpsi.tuning.defaults</a></code>, etc, for tuning constants'
defaults for <code><a href="#topic+lmrob">lmrob</a>()</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>(c.ge95 &lt;- .psi.ggw.findc(ms = -0.5, b = 1.5, eff = 0.95))
(c.ge90 &lt;- .psi.ggw.findc(ms = -0.5, b = 1.5, eff = 0.90))
(c.gb50 &lt;- .psi.ggw.findc(ms = -0.5, b = 1.5,  bp = 0.50))
stopifnot(all.equal(c.ge95, c(0, 1.386362,   1.5, 1.0628199,  4.7773893), tol = 1e-5),
          all.equal(c.ge90, c(0, 1.0282811,  1.5, 0.87086259, 3.2075233), tol = 1e-5),
          all.equal(c.gb50, c(0, 0.20367394, 1.5, 0.29591308, 0.37033962),tol = 1e-5))

(cl.e.95 &lt;- .psi.lqq.findc(ms = -0.5, b.c = 1.5, eff = .95))
(cl.b.50 &lt;- .psi.lqq.findc(ms = -0.5, b.c = 1.5,  bp = .50))
stopifnot(all.equal(cl.e.95, c(1.4734061,  0.98227073, 1.5), tol = 1e-5),
          all.equal(cl.b.50, c(0.40154568, 0.26769712, 1.5), tol = 1e-5))
</code></pre>

<hr>
<h2 id='psiFunc'>Constructor for Objects &quot;Psi Function&quot; Class</h2><span id='topic+psiFunc'></span><span id='topic+huberPsi'></span><span id='topic+hampelPsi'></span>

<h3>Description</h3>

<p><code>psiFunc(..)</code> is a convenience interface to
<code>new("psi_func",..)</code>, i.e. for constructing objects of class
<code>"psi_func"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>psiFunc(rho, psi, wgt, Dpsi,Dwgt, Erho = NULL, Epsi2 = NULL, EDpsi = NULL, name, ...)

huberPsi
hampelPsi
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="psiFunc_+3A_rho">rho</code>, <code id="psiFunc_+3A_psi">psi</code>, <code id="psiFunc_+3A_wgt">wgt</code>, <code id="psiFunc_+3A_dpsi">Dpsi</code>, <code id="psiFunc_+3A_dwgt">Dwgt</code></td>
<td>
<p>each a <code><a href="base.html#topic+function">function</a></code> of <code>x</code> and
tuning parameters typically. Specification of Dwgt is optional.</p>
</td></tr>
<tr><td><code id="psiFunc_+3A_erho">Erho</code>, <code id="psiFunc_+3A_epsi2">Epsi2</code>, <code id="psiFunc_+3A_edpsi">EDpsi</code></td>
<td>
<p>see <code><a href="#topic+psi_func-class">psi_func</a></code>, and note
that these may change in the future.</p>
</td></tr>
<tr><td><code id="psiFunc_+3A_name">name</code></td>
<td>
<p>Name of <code class="reqn">\psi</code>-function used for printing.</p>
</td></tr>
<tr><td><code id="psiFunc_+3A_...">...</code></td>
<td>
<p>potential further arguments for specifying tuning
parameter names and defaults.</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p>The description of class <code><a href="#topic+psi_func-class">psi_func</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(huberPsi) # =&gt; shows "all" {as an object with a smart plot() method}

## classical (Gaussian / "least-squares") psi {trivial}:
F1 &lt;- function(x, .) rep.int(1, length(x))
FF &lt;- function(.) rep.int(1, length(.))
cPsi &lt;- psiFunc(rho = function(x,.) x^2 / 2, psi = function(x, .) x,
                wgt = F1, Dpsi = F1,
                Erho = function(.) rep.int(1/2, length(.)),
                Epsi2 = FF, EDpsi = FF, name = "classic", . = Inf)
show(cPsi)
plot(cPsi)
## is the same as the limit of Huber's:
plot(chgDefaults(huberPsi, k = Inf))

## Hampel's psi and rho:
H.38 &lt;- chgDefaults(hampelPsi, k = c(1.5, 3.5, 8))
k. &lt;- H.38@xtras$tuningP$k ; k.. &lt;- as.vector(outer(c(-1,1), k.))
c.t &lt;- adjustcolor("skyblue3", .8)
.ax.k &lt;- function(side) { abline(h=0, v=0, lty=2)
  axis(side, at = k.., labels=formatC(k..), pos=0, col=c.t, col.axis=c.t) }
op &lt;- par(mfrow=c(2,1), mgp = c(1.5, .6, 0), mar = .6+c(2,2,1,.5))
curve(H.38@psi(x), -10, 10, col=2, lwd=2, n=512)
lines(k.., H.38@psi(k..), type = "h", lty=3, col=c.t); .ax.k(1)
curve(H.38@rho(x), -10, 10, col=2, lwd=2, n=512); abline(h=0, v=0, lty=2)
lines(k.., H.38@rho(k..), type = "h", lty=3, col=c.t); .ax.k(1)
title(expression("Hampel's " ~~~ psi(x) ~~ "and" ~~ rho(x) ~~~ " functions"))
par(op)

## Not the same, but similar, directly using the plot() method:
plot(H.38)
</code></pre>

<hr>
<h2 id='pulpfiber'>Pulp Fiber and Paper Data</h2><span id='topic+pulpfiber'></span>

<h3>Description</h3>

<p>Measurements of aspects pulp fibers and the paper produced from them.
Four properties of each are measured in sixty-two samples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(pulpfiber, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 62 observations on the following 8 variables.
</p>

<dl>
<dt><code>X1</code></dt><dd><p>numeric vector of arithmetic fiber length</p>
</dd>
<dt><code>X2</code></dt><dd><p>numeric vector of long fiber fraction</p>
</dd>
<dt><code>X3</code></dt><dd><p>numeric vector of fine fiber fraction</p>
</dd>
<dt><code>X4</code></dt><dd><p>numeric vector of zero span tensile</p>
</dd>

<dt><code>Y1</code></dt><dd><p>numeric vector of breaking length</p>
</dd>
<dt><code>Y2</code></dt><dd><p>numeric vector of elastic modulus</p>
</dd>
<dt><code>Y3</code></dt><dd><p>numeric vector of stress at failure</p>
</dd>
<dt><code>Y4</code></dt><dd><p>numeric vector of burst strength</p>
</dd>
</dl>



<h3>Details</h3>

<p>Cited from the reference article:
<em>The dataset contains measurements of properties of pulp fibers and the
paper made from them.  The aim is to investigate relations between pulp
fiber properties and the resulting paper properties.  The dataset
contains <code class="reqn">n = 62</code> measurements of the following four pulp fiber
characteristics: arithmetic fiber length, long fiber fraction, fine
fiber fraction, and zero span tensile.  The four paper properties that
have been measured are breaking length, elastic modulus, stress at
failure, and burst strength.</em>
</p>
<p>The goal is to predict the <code class="reqn">q = 4</code> paper properties from the
<code class="reqn">p = 4</code> fiber characteristics.
</p>


<h3>Author(s)</h3>

<p>port to <span class="rlang"><b>R</b></span> and this help page: Martin Maechler
</p>


<h3>Source</h3>

<p>Rousseeuw, P. J., Van Aelst, S., Van Driessen, K., and AgullÃ³, J. (2004)
Robust multivariate regression;
<em>Technometrics</em> <b>46</b>, 293&ndash;305.
</p>
<p>Till 2016 available from <code>http://users.ugent.be/~svaelst/data/pulpfiber.txt</code>
</p>


<h3>References</h3>

<p>Lee, J. (1992)
<em>Relationships Between Properties of Pulp-Fibre and Paper</em>,
unpublished doctoral thesis, U. Toronto, Faculty of Forestry.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pulpfiber)
str(pulpfiber)

pairs(pulpfiber, gap=.1)
## 2 blocks of 4 ..
c1 &lt;- cov(pulpfiber)
cR &lt;- covMcd(pulpfiber)
## how different are they: The robust estimate has more clear high correlations:
symnum(cov2cor(c1))
symnum(cov2cor(cR$cov))
</code></pre>

<hr>
<h2 id='Qn'>Robust Location-Free Scale Estimate More Efficient than MAD</h2><span id='topic+Qn'></span><span id='topic+Qn.old'></span><span id='topic+s_Qn'></span>

<h3>Description</h3>

<p>Compute the robust scale estimator <code class="reqn">Q_n</code>, an efficient
alternative to the MAD.
</p>
<p>By default, <code class="reqn">Q_n(x_1, \ldots, x_n)</code> is the <code class="reqn">k</code>-th
order statistic (a quantile) of the <code>choose(n, 2)</code> absolute
differences <code class="reqn">|x_i - x_j|</code>,
(for <code class="reqn">1 \le i &lt; j \le n</code>),
where by default (originally only possible value) <code class="reqn">k = choose(n\%/\% 2 + 1, 2)</code>
which is about the first quartile (25% quantile) of these
pairwise differences.  See the references for more.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Qn(x, constant = NULL, finite.corr = is.null(constant) &amp;&amp; missing(k),
   na.rm = FALSE, k = choose(n %/% 2 + 1, 2), warn.finite.corr = TRUE)

s_Qn(x, mu.too = FALSE, ...)
</code></pre>


<h3>Arguments</h3>


<table>
<tr><td><code id="Qn_+3A_x">x</code></td>
<td>
<p>numeric vector of observations.</p>
</td></tr>
<tr><td><code id="Qn_+3A_constant">constant</code></td>
<td>
<p>number by which the result is multiplied; the default
achieves consistency for normally distributed data.  Note that until
Nov. 2010, &ldquo;thanks&rdquo; to a typo in the very first papers, a slightly
wrong default constant, 2.2219, was used instead of the correct one
which is equal to <code>1 / (sqrt(2) * qnorm(5/8))</code> (as mentioned
already on p.1277, after (3.7) in Rousseeuw and Croux (1993)).
</p>
<p>If you need the old slightly off version for historical
reproducibility, you can use <code>Qn.old()</code>.
</p>
<p>Note that the relative difference is only about 1 in 1000, and that
the correction should not affect the finite sample corrections for
<code class="reqn">n \le 9</code>.
</p>
</td></tr>
<tr><td><code id="Qn_+3A_finite.corr">finite.corr</code></td>
<td>
<p>logical indicating if the finite sample bias
correction factor should be applied.  Defaults to <code>TRUE</code> unless
<code>constant</code> is specified.  Note the for non-default <code>k</code>, the
consistency <code>constant</code> already depends on <code>n</code> leading to
<em>some</em> finite sample correction, but no simulation-based
small-<code>n</code> correction factors are available.</p>
</td></tr>
<tr><td><code id="Qn_+3A_na.rm">na.rm</code></td>
<td>
<p>logical specifying if missing values (<code><a href="base.html#topic+NA">NA</a></code>)
should be removed from <code>x</code> before further computation.  If false
as by default, and if there are <code>NA</code>s, i.e., <code>if(anyNA(x))</code>,
the result will be <code>NA</code>.</p>
</td></tr>
<tr><td><code id="Qn_+3A_k">k</code></td>
<td>
<p>integer, typically half of n, specifying the &ldquo;quantile&rdquo;, i.e., rather the
order statistic that <code>Qn()</code> should return; for the Qn() proper,
this has been hard wired to <code>choose(n%/%2 +1, 2)</code>, i.e.,
<code class="reqn">\lfloor\frac{n}{2}\rfloor +1</code>.  Choosing a large <code>k</code> is less robust but
allows to get non-zero results in case the default <code>Qn()</code> is zero.</p>
</td></tr>
<tr><td><code id="Qn_+3A_warn.finite.corr">warn.finite.corr</code></td>
<td>
<p>logical indicating if a <code><a href="base.html#topic+warning">warning</a></code>
should be signalled when <code>k</code> is non-default, in which case specific
small-<code class="reqn">n</code> correction is not yet provided.</p>
</td></tr>
<tr><td><code id="Qn_+3A_mu.too">mu.too</code></td>
<td>
<p>logical indicating if the <code><a href="stats.html#topic+median">median</a>(x)</code> should
also be returned for <code>s_Qn()</code>.</p>
</td></tr>
<tr><td><code id="Qn_+3A_...">...</code></td>
<td>
<p>potentially further arguments for <code>s_Qn()</code> passed to
<code>Qn()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As the (default, consistency) constant needed to be corrected,
the finite sample correction has been based on a much more extensive
simulation, and on a 3rd or 4th degree polynomial model in <code class="reqn">1/n</code>
for odd or even n, respectively.
</p>


<h3>Value</h3>

<p><code>Qn()</code> returns a number, the <code class="reqn">Q_n</code> robust scale
estimator, scaled to be consistent for <code class="reqn">\sigma^2</code> and
i.i.d. Gaussian observations, optionally bias corrected for finite
samples.
</p>
<p><code>s_Qn(x, mu.too=TRUE)</code> returns a length-2 vector with location
(<code class="reqn">\mu</code>) and scale; this is typically only useful for
<code><a href="#topic+covOGK">covOGK</a>(*, sigmamu = s_Qn)</code>.
</p>


<h3>Author(s)</h3>

<p>Original Fortran code:
Christophe Croux and Peter Rousseeuw <a href="mailto:rousse@wins.uia.ac.be">rousse@wins.uia.ac.be</a>.
<br />
Port to C and R: Martin Maechler, <a href="mailto:maechler@R-project.org">maechler@R-project.org</a>
</p>


<h3>References</h3>

<p>Rousseeuw, P.J. and Croux, C. (1993)
Alternatives to the Median Absolute Deviation,
<em>Journal of the American Statistical Association</em> <b>88</b>, 1273&ndash;1283.
<a href="https://doi.org/10.2307/2291267">doi:10.2307/2291267</a>

</p>
<p>Christophe Croux and Peter J. Rousseeuw (1992)
A class of high-breakdown scale estimators based on subranges ,
<em>Communications in Statistics - Theory and Methods</em> <b>21</b>, 1935&ndash;1951;
<a href="https://doi.org/10.1080/03610929208830889">doi:10.1080/03610929208830889</a>
</p>
<p>Christophe Croux and Peter J. Rousseeuw (1992)
Time-Efficient Algorithms for Two Highly Robust Estimators of Scale,
<em>Computational Statistics, Vol. 1</em>, ed. Dodge and Whittaker,
Physica-Verlag Heidelberg, 411&ndash;428; available via Springer Link.


</p>
<p>About the typo in the <code>constant</code>:<br />
Christophe Croux (2010)
Private e-mail, Fri Jul 16, w/ Subject
<em>Re: Slight inaccuracy of Qn implementation ......</em>.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+mad">mad</a></code> for the &lsquo;most robust&rsquo; but much less efficient
scale estimator; <code><a href="#topic+Sn">Sn</a></code> for a similar faster but less
efficient alternative.  Finally, <code><a href="#topic+scaleTau2">scaleTau2</a></code> which some
consider &ldquo;uniformly&rdquo; better than Qn or competitors.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(153)
x &lt;- sort(c(rnorm(80), rt(20, df = 1)))
s_Qn(x, mu.too = TRUE)
Qn(x, finite.corr = FALSE)

## A simple pure-R version of Qn() -- slow and memory-rich for large n: O(n^2)
Qn0R &lt;- function(x, k = choose(n %/% 2 + 1, 2)) { 
    n &lt;- length(x &lt;- sort(x))
    if(n == 0) return(NA) else if(n == 1) return(0.)
    stopifnot(is.numeric(k), k == as.integer(k), 1 &lt;= k, k &lt;= n*(n-1)/2)
    m &lt;- outer(x,x,"-")# abs not needed as x[] is sorted
    sort(m[lower.tri(m)], partial = k)[k]
}
(Qx1 &lt;- Qn(x, constant=1)) # 0.5498463
## the C-algorithm "rounds" to 'float' single precision ..
stopifnot(all.equal(Qx1, Qn0R(x), tol = 1e-6))


(qn &lt;- Qn(c(1:4, 10, Inf, NA), na.rm=TRUE))
stopifnot(is.finite(qn), all.equal(4.075672524, qn, tol=1e-10))

## -- compute for different 'k' :

n &lt;- length(x) # = 100 here
(k0 &lt;- choose(floor(n/2) + 1, 2)) # 51*50/2 == 1275
stopifnot(identical(Qx1, Qn(x, constant=1, k=k0)))
nn2 &lt;- n*(n-1)/2
all.k &lt;- 1:nn2
system.time(Qss &lt;- sapply(all.k, function(k) Qn(x, 1, k=k)))
system.time(Qs  &lt;- Qn  (x, 1, k = all.k))
system.time(Qs0 &lt;- Qn0R(x,    k = all.k) )
stopifnot(exprs = {
   Qs[1]   == min(diff(x))
   Qs[nn2] == diff(range(x))
   all.equal(Qs,  Qss, tol = 1e-15) # even exactly
   all.equal(Qs0, Qs, tol = 1e-7) # see 2.68e-8, as Qn() C-code rounds to (float)
})

plot(2:nn2, Qs[-1], type="b", log="y", main = "Qn(*, k),  k = 2..n(n-1)/2")
</code></pre>

<hr>
<h2 id='r6pack'>Robust Distance based observation orderings based on robust &quot;Six pack&quot;</h2><span id='topic+r6pack'></span>

<h3>Description</h3>

<p>Compute six initial robust estimators of multivariate location and
&ldquo;scatter&rdquo; (scale); then, for each, compute the distances
<code class="reqn">d_{ij}</code> and take the <code>h</code> (<code class="reqn">h &gt; n/2</code>) observations
with smallest distances.  Then compute the statistical distances based
on these h observations.
</p>
<p>Return the indices of the observations sorted in increasing order.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r6pack(x, h, full.h, scaled = TRUE, scalefn = rrcov.control()$scalefn)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="r6pack_+3A_x">x</code></td>
<td>
<p>n x p data matrix</p>
</td></tr>
<tr><td><code id="r6pack_+3A_h">h</code></td>
<td>
<p>integer, typically around (and slightly larger than) <code class="reqn">n/2</code>.</p>
</td></tr>
<tr><td><code id="r6pack_+3A_full.h">full.h</code></td>
<td>
<p>logical specifying if the full (length n) observation
ordering should be returned; otherwise only the first <code>h</code> are.
For <code>.detmcd()</code>, <code>full.h=FALSE</code> is typical.</p>
</td></tr>
<tr><td><code id="r6pack_+3A_scaled">scaled</code></td>
<td>
<p>logical indicating if the data <code>x</code> is
already scaled; if false, we apply <code>x &lt;- doScale(x, median,
      scalefn)</code>.</p>
</td></tr>
<tr><td><code id="r6pack_+3A_scalefn">scalefn</code></td>
<td>
<p>a <code><a href="base.html#topic+function">function</a>(u)</code> to compute a robust
univariate scale of u.</p>
</td></tr>
</table>


<h3>Details</h3>


<p>The six initial estimators are
</p>

<ol>
<li><p> Hyperbolic tangent of standardized data
</p>
</li>
<li><p> Spearmann correlation matrix
</p>
</li>
<li><p> Tukey normal scores
</p>
</li>
<li><p> Spatial sign covariance matrix
</p>
</li>
<li><p> BACON
</p>
</li>
<li><p> Raw OGK estimate for scatter
</p>
</li></ol>



<h3>Value</h3>

<p>a <code class="reqn">h' \times 6</code> <code><a href="base.html#topic+matrix">matrix</a></code> of observation
indices, i.e., with values from <code class="reqn">1,\dots,n</code>.  If
<code>full.h</code> is true, <code class="reqn">h' = n</code>, otherwise <code class="reqn">h' = h</code>.
</p>


<h3>Author(s)</h3>

<p>Valentin Todorov, based on the original Matlab code by
Tim Verdonck and Mia Hubert.  Martin Maechler for tweaks
(performance etc), and <code>full.h</code>.
</p>


<h3>References</h3>

<p>Hubert, M., Rousseeuw, P. J. and Verdonck, T. (2012)
A deterministic algorithm for robust location and scatter.
Journal of Computational and Graphical Statistics <b>21</b>, 618&ndash;637.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covMcd">covMcd</a>(*, nsamp = "deterministic")</code>;
<code><a href="rrcov.html#topic+CovSest">CovSest</a>(*, nsamp = "sdet")</code> from package <a href="https://CRAN.R-project.org/package=rrcov"><span class="pkg">rrcov</span></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(pulpfiber)
dim(m.pulp &lt;- data.matrix(pulpfiber)) #  62 x 8
dim(fr6  &lt;- r6pack(m.pulp, h = 40, full.h= FALSE)) #  h x 6  = 40 x 6
dim(fr6F &lt;- r6pack(m.pulp, h = 40, full.h= TRUE )) #  n x 6  = 62 x 6
stopifnot(identical(fr6, fr6F[1:40,]))

</code></pre>

<hr>
<h2 id='radarImage'>Satellite Radar Image Data from near Munich</h2><span id='topic+radarImage'></span>

<h3>Description</h3>

<p>The data were supplied by A. Frery.  They are a part of a synthetic aperture
satellite radar image corresponding to a suburb of Munich.  Provided
are coordinates and values corresponding to three frequency bands for
each of 1573 pixels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(radarImage, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 1573 observations on the following 5 variables.
</p>

<dl>
<dt><code>X.coord</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Y.coord</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Band.1</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Band.2</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Band.3</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>The website accompanying the MMY-book:
<a href="https://www.wiley.com/legacy/wileychi/robust_statistics/">https://www.wiley.com/legacy/wileychi/robust_statistics/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(radarImage)
plot(Y.coord ~ X.coord, data = radarImage)

## The 8 "clear" outliers (see also below)
ii8 &lt;- c(1548:1549, 1553:1554, 1565:1566, 1570:1571)
outF &lt;- 1+(seq_len(nrow(radarImage)) %in% ii8)
pairs(radarImage[, 3:5], main = "radarImage (n = 1573)",
      col = outF, pch=outF)

## Finding outliers -----------------------------------------

set.seed(1)
system.time(cc.ri &lt;- covMcd(radarImage))# ~ 0.1 sec
## check for covMcd() consistency:
iiO &lt;- as.integer(
 c(262, 450:451, 480:481, 509, 535, 542, 597, 643, 669, 697, 803:804, 832:834,
   862:864, 892, 989, 1123, 1145, 1223:1224, 1232:1233, 1249:1250, 1267, 1303,
   1347, 1357, 1375, 1411, 1419:1420, 1443, 1453, 1504, 1510:1512,
   1518:1521, 1525:1526, 1543:1544, 1546:1555, 1557:1558, 1561:1562, 1564:1566,
   1569:1571, 1573))
length(iiO) # 73 -- other seeds sometimes give 72, rarely 71 "outliers"
table(isO &lt;- cc.ri$mcd.wt == 0) # 2023-05: 118
stopifnot(exprs = {
    ## identical(iiO, which(isO)) -- TRUE before 2023-05  covMcd() change
    ii8 %in% which(isO) # ii8 is subset of isO
    identical(ii8, which(cc.ri$mah &gt; 200))
    length(intersect(cc.ri$best, iiO)) == 0
})

cc &lt;- c(adjustcolor("black", 0.4), adjustcolor("tomato", 0.8))
pairs(radarImage, main = "radarImage (n = 1573) + Outliers", gap=0,
      col = cc[1+isO], pch = c(1,8)[1+isO], cex = 0.8)
</code></pre>

<hr>
<h2 id='rankMM'>Simple Matrix Rank</h2><span id='topic+rankMM'></span>

<h3>Description</h3>

<p>Compute the rank of a matrix <code>A</code> in simple way, based on the SVD,
<code><a href="base.html#topic+svd">svd</a>()</code>, and &ldquo;the same as Matlab&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rankMM(A, tol = NULL, sv = svd(A, 0, 0)$d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rankMM_+3A_a">A</code></td>
<td>
<p>a numerical matrix, maybe non-square.  When <code>sv</code> is
specified, only <code>dim(A)</code> is made use of.</p>
</td></tr>
<tr><td><code id="rankMM_+3A_tol">tol</code></td>
<td>
<p>numerical tolerance (compared to singular values).  By
default, when <code>NULL</code>, the tolerance is determined from the
maximal value of <code>sv</code> and the computer epsilon.</p>
</td></tr>
<tr><td><code id="rankMM_+3A_sv">sv</code></td>
<td>
<p>vector of <em>non-increasing</em> singular values of <code>A</code>, (to be
passed if already known).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>an integer from the set <code>0:min(dim(A))</code>.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler, Date: 7 Apr 2007
</p>


<h3>See Also</h3>

<p>There are more sophisticated proposals for computing the rank of a
matrix; for a couple of those, see <code><a href="Matrix.html#topic+rankMatrix">rankMatrix</a></code> in the
<a href="https://CRAN.R-project.org/package=Matrix"><span class="pkg">Matrix</span></a> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rankMM # - note the simple function definition

hilbert &lt;- function(n) { i &lt;- seq_len(n); 1/outer(i - 1L, i, "+") }
hilbert(4)
H12 &lt;- hilbert(12)
rankMM(H12)        # 11 - numerically more realistic
rankMM(H12, tol=0) # -&gt; 12
## explanation :
round(log10(svd(H12, 0,0)$d), 1)
</code></pre>

<hr>
<h2 id='residuals.glmrob'>Residuals of Robust Generalized Linear Model Fits</h2><span id='topic+residuals.glmrob'></span>

<h3>Description</h3>

<p>Compute residuals of a fitted <code><a href="#topic+glmrob">glmrob</a></code> model, i.e., robust
generalized linear model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmrob'
residuals(object,
          type = c("deviance", "pearson", "working",
                   "response", "partial"),
          ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.glmrob_+3A_object">object</code></td>
<td>
<p>an object of class <code>glmrob</code>, typically the result of
a call to <code><a href="#topic+glmrob">glmrob</a></code>.</p>
</td></tr>
<tr><td><code id="residuals.glmrob_+3A_type">type</code></td>
<td>
<p>the type of residuals which should be returned.
The alternatives are: <code>"deviance"</code> (default), <code>"pearson"</code>,
<code>"working"</code>, <code>"response"</code>, and <code>"partial"</code>.</p>
</td></tr>
<tr><td><code id="residuals.glmrob_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The references in <code><a href="stats.html#topic+glm">glm</a></code> define the types of residuals:
Davison &amp; Snell is a good reference for the usages of each.
</p>
<p>The partial residuals are a matrix of working residuals, with each
column formed by omitting a term from the model.
</p>
<p>The <code>residuals</code> (S3) method (see <code><a href="utils.html#topic+methods">methods</a></code>) for
<code><a href="#topic+glmrob">glmrob</a></code> models has been modeled to follow closely the
method for classical (non-robust) <code><a href="stats.html#topic+glm">glm</a></code> fitted models.
Possibly, see its documentation, i.e., <a href="stats.html#topic+residuals.glm">residuals.glm</a>, for
further details.
</p>


<h3>References</h3>

<p>See those for the classical GLM's, <code><a href="stats.html#topic+glm">glm</a></code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmrob">glmrob</a></code> for computing <code>object</code>, <code><a href="#topic+anova.glmrob">anova.glmrob</a></code>;
the corresponding <em>generic</em> functions, <code><a href="#topic+summary.glmrob">summary.glmrob</a></code>,
<code><a href="stats.html#topic+coef">coef</a></code>,

<code><a href="stats.html#topic+fitted">fitted</a></code>,
<code><a href="stats.html#topic+residuals">residuals</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### -------- Gamma family -- data from example(glm) ---
clotting &lt;- data.frame(
            u = c(5,10,15,20,30,40,60,80,100),
         lot1 = c(118,58,42,35,27,25,21,19,18),
         lot2 = c(69,35,26,21,18,16,13,12,12))
summary(cl &lt;- glm   (lot1 ~ log(u), data=clotting, family=Gamma))
summary(ro &lt;- glmrob(lot1 ~ log(u), data=clotting, family=Gamma))
clotM5.high &lt;- within(clotting, { lot1[5] &lt;- 60 })
cl5.high &lt;- glm   (lot1 ~ log(u), data=clotM5.high, family=Gamma)
ro5.high &lt;- glmrob(lot1 ~ log(u), data=clotM5.high, family=Gamma)
rr &lt;- range(residuals(ro), residuals(cl), residuals(ro5.high))
plot(residuals(ro5.high) ~ residuals(cl5.high), xlim = rr, ylim = rr, asp = 1)
abline(0,1, col=2, lty=3)
points(residuals(ro) ~ residuals(cl), col = "gray", pch=3)

## Show all kinds of residuals:
r.types &lt;- c("deviance", "pearson", "working", "response")
sapply(r.types, residuals, object = ro5.high)
</code></pre>

<hr>
<h2 id='robustbase-internals'>Internal Functions of Package 'robustbase'</h2><span id='topic+internals'></span><span id='topic+print.glmrob'></span><span id='topic+glmrobMqle'></span><span id='topic+glmrobMqleDiffQuasiDevB'></span><span id='topic+glmrobMqleDiffQuasiDevPois'></span><span id='topic+robMD'></span><span id='topic+mahalanobisD'></span><span id='topic+doScale'></span><span id='topic+.signflip'></span>

<h3>Description</h3>

<p>These functions are for internal use <em>or</em> not yet documented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmrob'
print(x, digits = max(3, getOption("digits") - 3), ...)



glmrobMqle(X, y, weights = NULL, start = NULL, offset = NULL,
           family, weights.on.x = "none",
           control = glmrobMqle.control(), intercept = TRUE, trace = FALSE)

glmrobMqleDiffQuasiDevB   (mu, mu0, y, ni, w.x, phi, tcc)
glmrobMqleDiffQuasiDevPois(mu, mu0, y, ni, w.x, phi, tcc)

robMD(x, intercept, wqr, ...)
mahalanobisD(x, center, sd)

## Utilities currently for the deterministic MCD only:
## subject to change / be renamed ?
doScale(x, center, scale)
.signflip(loadings)
</code></pre>

<hr>
<h2 id='rrcov.control'>Control Settings for covMcd and ltsReg</h2><span id='topic+rrcov.control'></span>

<h3>Description</h3>

<p>Auxiliary function for passing the estimation options as parameters to the
estimation functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rrcov.control(alpha = 1/2, method = c("covMcd", "covComed", "ltsReg"),
              nsamp = 500, nmini = 300, kmini = 5,
              seed = NULL, tolSolve = 1e-14,
              scalefn = "hrv2012", maxcsteps = 200,
              trace = FALSE,
              wgtFUN = "01.original", beta,
              use.correction = identical(wgtFUN, "01.original"),
              adjust = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rrcov.control_+3A_alpha">alpha</code></td>
<td>
<p>This parameter controls the size of the subsets over
which the determinant is minimized, i.e., <code>alpha*n</code> observations
are used for computing the determinant.  Allowed values are between 0.5
and 1 and the default is 0.5. </p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_method">method</code></td>
<td>
<p>a string specifying the &ldquo;main&rdquo; function for which
<code>rrcov.control()</code> is used.  This currently only makes a
difference to determine the default for <code>beta</code>.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_nsamp">nsamp</code></td>
<td>
<p>number of subsets used for initial estimates or <code>"best"</code>
or <code>"exact"</code>. Default is <code>nsamp = 500</code>.
If <code>nsamp="best"</code> exhaustive enumeration is done, as far as
the number of trials do not exceed 5000. If <code>nsamp="exact"</code>
exhaustive enumeration will be attempted however many samples
are needed. In this case a warning message will be displayed
saying that the computation can take a very long time. </p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_nmini">nmini</code>, <code id="rrcov.control_+3A_kmini">kmini</code></td>
<td>
<p>for <code><a href="#topic+covMcd">covMcd</a></code>: For large <code class="reqn">n</code>, the algorithm
splits the data into maximally <code class="reqn">kmini</code> subsets of targetted size
<code>nmini</code>.  See <code><a href="#topic+covMcd">covMcd</a></code> for more details.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_seed">seed</code></td>
<td>
<p>initial seed for R's random number generator; see
<code><a href="base.html#topic+.Random.seed">.Random.seed</a></code> and the description of the <code>seed</code>
argument in <code><a href="#topic+lmrob.control">lmrob.control</a></code>.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_tolsolve">tolSolve</code></td>
<td>
<p>numeric tolerance to be used for inversion
(<code><a href="Matrix.html#topic+solve">solve</a></code>) of the covariance matrix in <code><a href="stats.html#topic+mahalanobis">mahalanobis</a></code>.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_scalefn">scalefn</code></td>
<td>
<p>(for deterministic <code><a href="#topic+covMcd">covMcd</a>()</code>:) a character
string or <code><a href="base.html#topic+function">function</a></code> for computing a robust scale
estimate.  The current default <code>"hrv2012"</code> uses the recommendation
of Hubert et al (2012); see <code><a href="#topic+covMcd">covMcd</a></code> for more.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_maxcsteps">maxcsteps</code></td>
<td>
<p>integer specifying the maximal number of
concentration steps for the deterministic MCD.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_trace">trace</code></td>
<td>
<p>logical or integer indicating whether to print
intermediate results.  Default is <code>trace = FALSE</code>.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_wgtfun">wgtFUN</code></td>
<td>
<p>a character string or <code><a href="base.html#topic+function">function</a></code>, specifying
how the weights for the reweighting step should be computed, see
<code><a href="#topic+ltsReg">ltsReg</a></code>, <code><a href="#topic+covMcd">covMcd</a></code> or
<code><a href="#topic+covComed">covComed</a></code>, respectively.  The default is specified by
<code>"01.original"</code>, as the resulting weights are 0 or 1.  Alternative
string specifications need to match <code>names(.wgtFUN.covComed)</code> -
which currently is experimental.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_beta">beta</code></td>
<td>
<p>a quantile, experimentally used for some of the prespecified
<code>wgtFUN</code>s, see e.g., <code><a href="#topic+.wgtFUN.covMcd">.wgtFUN.covMcd</a></code> and
<code><a href="#topic+.wgtFUN.covComed">.wgtFUN.covComed</a></code>.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_use.correction">use.correction</code></td>
<td>
<p>whether to use finite sample correction factors.
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="rrcov.control_+3A_adjust">adjust</code></td>
<td>
<p>(for <code><a href="#topic+ltsReg">ltsReg</a>()</code>:) whether to perform
intercept adjustment at each step.  Because this can be quite time
consuming, the default is <code>adjust = FALSE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components, as the parameters passed by the invocation
</p>


<h3>Author(s)</h3>

<p>Valentin Todorov</p>


<h3>See Also</h3>

<p>For details, see the documentation about <code><a href="#topic+ltsReg">ltsReg</a></code> and
<code><a href="#topic+covMcd">covMcd</a></code>, respectively.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Animals, package = "MASS")
brain &lt;- Animals[c(1:24, 26:25, 27:28),]
data(hbk)
hbk.x &lt;- data.matrix(hbk[, 1:3])

ctrl &lt;- rrcov.control(alpha=0.75, trace=TRUE)
covMcd(hbk.x,      control = ctrl)
covMcd(log(brain), control = ctrl)
</code></pre>

<hr>
<h2 id='salinity'>Salinity Data</h2><span id='topic+salinity'></span>

<h3>Description</h3>

<p>This is a data set consisting of measurements of water salinity (i.e.,
its salt concentration) and river discharge taken in North Carolina's
Pamlico Sound, recording some bi-weekly averages in March, April,
and May from 1972 to 1977.  This dataset was listed by Ruppert and
Carroll (1980).  In Carrol and Ruppert (1985) the physical background of the
data is described.  They indicated that observations 5 and 16
correspond to periods of very heavy discharge and showed that the
discrepant observation 5 was masked by observations 3 and 16, i.e.,
only after deletion of these observations it was possible to identify
the influential observation 5.
</p>
<p>This data set is a prime example of the <em>masking effect</em>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(salinity, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 28 observations on the following 4 variables
(in parentheses are the names used in the 1980 reference).
</p>

<dl>
<dt><code>X1</code>:</dt><dd><p>Lagged Salinity  (&lsquo;SALLAG&rsquo;)</p>
</dd>
<dt><code>X2</code>:</dt><dd><p>Trend  (&lsquo;TREND&rsquo;)</p>
</dd>
<dt><code>X3</code>:</dt><dd><p>Discharge  (&lsquo;H2OFLOW&rsquo;)</p>
</dd>
<dt><code>Y</code>:</dt><dd><p>Salinity   (&lsquo;SALINITY&rsquo;)</p>
</dd>
</dl>



<h3>Note</h3>

<p>The <a href="https://CRAN.R-project.org/package=boot"><span class="pkg">boot</span></a> package contains another version of this salinity
data set, also attributed to Ruppert and Carroll (1980), but with two
clear transcription errors, see the examples.
</p>


<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, p.82, table 5.
</p>
<p>Ruppert, D. and Carroll, R.J. (1980)
Trimmed least squares estimation in the  linear model.
<em>JASA</em> <b>75</b>, 828&ndash;838; table 3, p.835.
</p>
<p>Carroll, R.J. and Ruppert, D. (1985)
Transformations in regression: A robust analysis.
<em>Technometrics</em> <b>27</b>, 1&ndash;12
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(salinity)
summary(lm.sali  &lt;-        lm(Y ~ . , data = salinity))
summary(rlm.sali &lt;- MASS::rlm(Y ~ . , data = salinity))
summary(lts.sali &lt;-    ltsReg(Y ~ . , data = salinity))

salinity.x &lt;- data.matrix(salinity[, 1:3])
c_sal &lt;- covMcd(salinity.x)
plot(c_sal, "tolEllipsePlot")

## Connection with boot package's version :
if(requireNamespace("boot")) { ## 'always'
 print( head(boot.sal &lt;- boot::salinity        ) )
 print( head(robb.sal &lt;- salinity [, c(4, 1:3)]) ) # difference: has one digit more
 ## Otherwise the same ?
 dimnames(robb.sal) &lt;- dimnames(boot.sal)
 ## apart from the 4th column, they are "identical":
 stopifnot( all.equal(boot.sal[, -4], robb.sal[, -4], tol = 1e-15) )

 ## But the discharge ('X3', 'dis' or 'H2OFLOW')  __differs__ in two places:
 plot(cbind(robustbase = robb.sal[,4], boot = boot.sal[,4]))
 abline(0,1, lwd=3, col=adjustcolor("red", 1/4))
 D.sal &lt;- robb.sal[,4] - boot.sal[,4]
 stem(robb.sal[,4] - boot.sal[,4])
 which(abs(D.sal) &gt; 0.01) ## 2 8
 ## *two* typos (=&gt; difference ~= 1) in the version of 'boot': obs. 2 &amp; 8 !!!
 cbind(robb = robb.sal[,4], boot = boot.sal[,4], D.sal)
}# boot
</code></pre>

<hr>
<h2 id='scaleTau2'>Robust Tau-Estimate of Scale</h2><span id='topic+scaleTau2'></span>

<h3>Description</h3>

<p>Computes the robust <code class="reqn">\tau</code>-estimate of univariate scale, as
proposed by Maronna and Zamar (2002); improved by a consistency factor,


</p>


<h3>Usage</h3>

<pre><code class='language-R'>
scaleTau2(x, c1 = 4.5, c2 = 3.0, na.rm = FALSE, consistency = TRUE,
          mu0 = median(x),
          sigma0 = median(x.), mu.too = FALSE, iter = 1, tol.iter = 1e-7)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scaleTau2_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="scaleTau2_+3A_c1">c1</code>, <code id="scaleTau2_+3A_c2">c2</code></td>
<td>
<p>non-negative numbers, specifying cutoff values for the
biweighting of the mean and the rho function respectively.</p>
</td></tr>
<tr><td><code id="scaleTau2_+3A_na.rm">na.rm</code></td>
<td>
<p>a logical value indicating whether <code>NA</code>
values should be stripped before the computation proceeds.</p>
</td></tr>
<tr><td><code id="scaleTau2_+3A_consistency">consistency</code></td>
<td>
<p>logical indicating if the consistency correction
factor (for the scale) should be applied.</p>
</td></tr>
<tr><td><code id="scaleTau2_+3A_mu0">mu0</code></td>
<td>
<p>the initial location estimate <code class="reqn">\mu_0</code>, defaulting to
the <code><a href="stats.html#topic+median">median</a></code>.</p>
</td></tr>
<tr><td><code id="scaleTau2_+3A_sigma0">sigma0</code></td>
<td>
<p>the initial scale estimate <code class="reqn">s_0</code>, defaulting to
the MAD; may be set to a positive value when the MAD is zero.</p>
</td></tr>
<tr><td><code id="scaleTau2_+3A_mu.too">mu.too</code></td>
<td>
<p>logical indicating if both location and scale should be
returned or just the scale (when <code>mu.too=FALSE</code> as by default).</p>
</td></tr>
<tr><td><code id="scaleTau2_+3A_iter">iter</code></td>
<td>
<p>positive integer or logical indicating if and how many
iterations should be done.  The default, <code>iter = 1</code> computes the
&ldquo;traditional&rdquo; tau-estimate of scale.</p>
</td></tr>
<tr><td><code id="scaleTau2_+3A_tol.iter">tol.iter</code></td>
<td>
<p>if <code>iter</code> is true, or <code>iter &gt; 1</code>, stop the
iterations when <code class="reqn">|s_n - s_o| \le \epsilon s_n</code>, where
<code class="reqn">\epsilon :=</code><code>tol.iter</code>, and  <code class="reqn">s_o</code> and <code class="reqn">s_n</code> are the
previous and current estimates of <code class="reqn">\sigma</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First, <code class="reqn">s_0</code> := MAD, i.e. the equivalent of <code><a href="stats.html#topic+mad">mad</a>(x,
    constant=1)</code> is computed.  Robustness weights
<code class="reqn">w_i := w_{c1}((x_i - med(X))/ s_0)</code> are computed, where
<code class="reqn">w_c(u) = max(0, (1 - (u/c)^2)^2)</code>.  The robust location
measure is defined as <code class="reqn">\mu(X) := (\sum_i w_i x_i)/(\sum_i w_i)</code>,
and the robust <code class="reqn">\tau (tau)</code>-estimate is <code class="reqn">s(X)^2 :=
    s_0^2 * (1/n) \sum_i \rho_{c2}((x_i - \mu(X))/s_0)</code>,
where <code class="reqn">\rho_c(u) = min(c^2, u^2)</code>.
<br />
When <code>iter=TRUE</code> or <code>iter &gt; 1</code>, the above estimate is
<em>iterated</em> in a fixpoint iteration, setting <code class="reqn">s_0</code> to the current
estimate <code class="reqn">s(X)</code> and iterating until the number of iterations is
larger than <code>iter</code> or the fixpoint is found in the sense that
\
<br />
<code>scaleTau2(*, consistency=FALSE)</code> returns <code class="reqn">s(X)</code>, whereas
this value is divided by its asymptotic limit when <code>consistency =
    TRUE</code> as by default.
</p>
<p>Note that for <code>n = length(x) == 2</code>, all equivariant scale estimates are
proportional, and specifically, <code>scaleTau2(x, consistency=FALSE)
    == mad(x, constant=1)</code>.  See also the reference.
</p>


<h3>Value</h3>

<p>numeric vector of length one (if <code>mu.too</code> is <code>FALSE</code> as by
default) or two (when <code>mu.too = TRUE</code>) with robust scale or
(location,scale) estimators
<code class="reqn">\hat\sigma(x)</code> or
<code class="reqn">(\hat\mu(x),\hat\sigma(x))</code>.
</p>


<h3>Author(s)</h3>

<p>Original by Kjell Konis with substantial modifications by
Martin Maechler.
</p>


<h3>References</h3>

<p>Maronna, R.A. and Zamar, R.H. (2002)
Robust estimates of location and dispersion of high-dimensional datasets;
<em>Technometrics</em> <b>44</b>(4), 307&ndash;317.

</p>
<p>Yohai, V.J., and Zamar, R.H. (1988).
High breakdown-point estimates of regression by means of the
minimization of an efficient scale.
<em>Journal of the American Statistical Association</em> <b>83</b>, 406&ndash;413.

</p>


<h3>See Also</h3>

<p><code><a href="#topic+Sn">Sn</a></code>, <code><a href="#topic+Qn">Qn</a></code>, <code><a href="stats.html#topic+mad">mad</a></code>;
further <code><a href="#topic+covOGK">covOGK</a></code> for which <code>scaleTau2</code> was designed.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1:7, 1000)
sd(x) # non-robust std.deviation
scaleTau2(x)
scaleTau2(x, mu.too = TRUE)
(sI  &lt;- scaleTau2(c(x,Inf), mu.too = TRUE))
(sIN &lt;- scaleTau2(c(x,Inf,NA), mu.too = TRUE, na.rm=TRUE))
stopifnot({
  identical(sI, sIN)
  all.equal(scaleTau2(c(x, 999), mu.too = TRUE), sIN,
            tol = 1e-15)
})

if(doExtras &lt;- robustbase:::doExtras()) {
 set.seed(11)
 ## show how much faster this is, compared to Qn
 x &lt;- sample(c(rnorm(1e6), rt(5e5, df=3)))
 (system.time(Qx &lt;- Qn(x)))         ## 2.04 [2017-09, lynne]
 (system.time(S2x &lt;- scaleTau2(x))) ## 0.25    (ditto)
 cbind(Qn = Qx, sTau2 = S2x)
}##       Qn    sTau2
##  1.072556 1.071258
</code></pre>

<hr>
<h2 id='SiegelsEx'>Siegel's Exact Fit Example Data</h2><span id='topic+SiegelsEx'></span>

<h3>Description</h3>

<p>A small counterexample data set devised by Andrew Siegel.
Six (out of nine) data points lie on the line <code class="reqn">y = 0</code> such that
some robust regression estimators exhibit the &ldquo;<em>exact fit</em>&rdquo;
property.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(SiegelsEx, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 9 observations on the following 2 variables.
</p>

<dl>
<dt><code>x</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y</code></dt><dd><p>a numeric vector</p>
</dd>
</dl>



<h3>Source</h3>

<p>Emerson and Hoaglin (1983, p.139)
</p>


<h3>References</h3>

<p>Peter J. Rousseeuw and Annick M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em> Wiley, p.60&ndash;61
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(SiegelsEx)
plot(SiegelsEx, main = "Siegel's example for 'exact fit'")
abline(          lm(y ~ x, data = SiegelsEx))
abline(MASS::lqs(y ~ x, data = SiegelsEx, method = "lms"), col = 2)
legend("topright", leg = c("lm", "LMS"), col=1:2, lwd=1, inset = 1/20)
</code></pre>

<hr>
<h2 id='sigma'>Extract 'Sigma' - Standard Deviation of Errors for Robust Models</h2><span id='topic+sigma'></span><span id='topic+sigma.lmrob'></span>

<h3>Description</h3>

<p>Extract the estimated standard deviation of the errors, the
&ldquo;residual standard deviation&rdquo; (misnomed also
&ldquo;residual standard error&rdquo;) from a fitted model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'lmrob'
sigma(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sigma_+3A_object">object</code></td>
<td>
<p>a fitted model.</p>
</td></tr>
<tr><td><code id="sigma_+3A_...">...</code></td>
<td>
<p>additional, optional arguments.  (None are
used in our methods)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <span class="rlang"><b>R</b></span> <code>&lt;= 3.2.x</code>, we provide an (S3) generic function (as e.g.,
package <a href="https://CRAN.R-project.org/package=lme4"><span class="pkg">lme4</span></a>) and methods for <code><a href="#topic+lmrob">lmrob</a></code>,
<code><a href="#topic+nlrob">nlrob</a></code>, and <code><a href="stats.html#topic+nls">nls</a></code>.
</p>
<p>From <span class="rlang"><b>R</b></span> <code>&gt;= 3.3.0</code>, we provide methods for our
<code><a href="#topic+lmrob">lmrob</a></code> and <code><a href="#topic+nlrob">nlrob</a></code> models.
</p>


<h3>Value</h3>

<p>the residual standard error as a scalar
</p>


<h3>Examples</h3>

<pre><code class='language-R'>      m.cl &lt;-   lm (Y ~ ., data=coleman)
if(getRversion() &gt;= "3.3.0")  sigma(m.cl)  else  summary(m.cl)$sigma
sigma( m1  &lt;- lmrob(Y ~ ., data=coleman) )
sigma( m2  &lt;- lmrob(Y ~ ., data=coleman, setting = "KS2014") )
</code></pre>

<hr>
<h2 id='smoothWgt'>Smooth Weighting Function - Generalized Biweight</h2><span id='topic+smoothWgt'></span>

<h3>Description</h3>

<p>&ldquo;The Biweight on a Stick&rdquo; &mdash;
Compute a smooth (when <code class="reqn">h &gt; 0</code>) weight function typically for
computing weights from large (robust) &ldquo;distances&rdquo; using a
piecewise polynomial function which in fact is a
2-parameter generalization of Tukey's 1-parameter &ldquo;biweight&rdquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>smoothWgt(x, c, h)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smoothWgt_+3A_x">x</code></td>
<td>
<p>numeric vector of abscissa values</p>
</td></tr>
<tr><td><code id="smoothWgt_+3A_c">c</code></td>
<td>
<p>&ldquo;cutoff&rdquo;, a typically positive number.</p>
</td></tr>
<tr><td><code id="smoothWgt_+3A_h">h</code></td>
<td>
<p>&ldquo;bandwidth&rdquo;, a positive number.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">w(x;c,h) := </code><code>smoothWgt(x, c, h)</code>.  Then,
</p>
<p style="text-align: center;"><code class="reqn">% "FIXME": rather use amsmath package \cases{.}
    w(x; c,h) := 0 \ \ \ \ \ \mathrm{if}\ |x| \ge c + h/2,</code>
</p>

<p style="text-align: center;"><code class="reqn">
    w(x; c,h) := 1 \ \ \ \ \ \mathrm{if}\ |x| \le c - h/2,</code>
</p>

<p style="text-align: center;"><code class="reqn">
    w(x; c,h) := \bigl((1 - |x| - (c-h/2))^2\bigr)^2 \ \mathrm{if}\ c-h/2 &lt; |x| &lt; c+h/2,</code>
</p>

<p><code>smoothWgt()</code> is <em>scale invariant</em> in the sense that
</p>
<p style="text-align: center;"><code class="reqn">w(\sigma x; \sigma c, \sigma h) = w(x; c, h),</code>
</p>
<p> when <code class="reqn">\sigma &gt; 0</code>.
</p>


<h3>Value</h3>

<p>a numeric vector of the same length as <code>x</code> with weights between
zero and one.  Currently all <code><a href="base.html#topic+attributes">attributes</a></code> including
<code><a href="base.html#topic+dim">dim</a></code> and <code><a href="base.html#topic+names">names</a></code> are dropped.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mwgt">Mwgt</a>(.., psi = "bisquare")</code> of which <code>smoothWgt()</code>
is a generalization, and
<code><a href="#topic+Mwgt">Mwgt</a>(.., psi = "optimal")</code> which looks similar for larger
<code>c</code> with its constant one part around zero, but also has only
one parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## a somewhat typical picture:
curve(smoothWgt(x, c=3, h=1), -5,7, n = 1000)

csW &lt;- curve(smoothWgt(x, c=1/2, h=1), -2,2) # cutoff 1/2, bandwidth 1
## Show that the above is the same as
## Tukey's "biweight" or "bi-square" weight function:
bw &lt;- function(x) pmax(0, (1 - x^2))^2
cbw &lt;- curve(bw,                     col=adjustcolor(2, 1/2), lwd=2, add=TRUE)
cMw &lt;- curve(Mwgt(x,c=1,"biweight"), col=adjustcolor(3, 1/2), lwd=2, add=TRUE)
stopifnot(## proving they are all the same:
   all.equal(csW, cbw, tol=1e-15),
   all.equal(csW, cMw, tol=1e-15))
</code></pre>

<hr>
<h2 id='Sn'>Robust Location-Free Scale Estimate More Efficient than MAD</h2><span id='topic+Sn'></span><span id='topic+s_Sn'></span>

<h3>Description</h3>

<p>Compute the robust scale estimator <code class="reqn">S_n</code>, an efficient
alternative to the MAD.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Sn(x, constant = 1.1926, finite.corr = missing(constant), na.rm = FALSE)

s_Sn(x, mu.too = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Sn_+3A_x">x</code></td>
<td>
<p>numeric vector of observations.</p>
</td></tr>
<tr><td><code id="Sn_+3A_constant">constant</code></td>
<td>
<p>number by which the result is multiplied; the default
achieves consisteny for normally distributed data.</p>
</td></tr>
<tr><td><code id="Sn_+3A_finite.corr">finite.corr</code></td>
<td>
<p>logical indicating if the finite sample bias
correction factor should be applied.  Default to <code>TRUE</code> unless
<code>constant</code> is specified.</p>
</td></tr>
<tr><td><code id="Sn_+3A_na.rm">na.rm</code></td>
<td>
<p>logical specifying if missing values (<code><a href="base.html#topic+NA">NA</a></code>)
should be removed from <code>x</code> before further computation.  If false
as by default, and if there are <code>NA</code>s, i.e., <code>if(anyNA(x))</code>,
the result will be <code>NA</code>.</p>
</td></tr>
<tr><td><code id="Sn_+3A_mu.too">mu.too</code></td>
<td>
<p>logical indicating if the <code><a href="stats.html#topic+median">median</a>(x)</code> should
also be returned for <code>s_Sn()</code>.</p>
</td></tr>
<tr><td><code id="Sn_+3A_...">...</code></td>
<td>
<p>potentially further arguments for <code>s_Sn()</code> passed to
<code>Sn()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>............  FIXME ........
</p>


<h3>Value</h3>

<p><code>Sn()</code> returns a number, the <code class="reqn">S_n</code> robust scale estimator, scaled to be
consistent for <code class="reqn">\sigma^2</code> and i.i.d. Gaussian observations,
optionally bias corrected for finite samples.
</p>
<p><code>s_Sn(x, mu.too=TRUE)</code> returns a length-2 vector with location
(<code class="reqn">\mu</code>) and scale; this is typically only useful for
<code><a href="#topic+covOGK">covOGK</a>(*, sigmamu = s_Sn)</code>.
</p>


<h3>Author(s)</h3>

<p>Original Fortran code:
Christophe Croux and Peter Rousseeuw <a href="mailto:rousse@wins.uia.ac.be">rousse@wins.uia.ac.be</a>.
<br />
Port to C and R: Martin Maechler, <a href="mailto:maechler@R-project.org">maechler@R-project.org</a>
</p>


<h3>References</h3>

<p>Rousseeuw, P.J. and Croux, C. (1993)
Alternatives to the Median Absolute Deviation,
<em>Journal of the American Statistical Association</em> <b>88</b>, 1273&ndash;1283.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+mad">mad</a></code> for the &lsquo;most robust&rsquo; but much
less efficient scale estimator;
<code><a href="#topic+Qn">Qn</a></code> for a similar more efficient but slower alternative;
<code><a href="#topic+scaleTau2">scaleTau2</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1:10, 100+1:9)# 9 outliers out of 19
Sn(x)
Sn(x, c=1)# 9
Sn(x[1:18], c=1)# 9
set.seed(153)
x &lt;- sort(c(rnorm(80), rt(20, df = 1)))
s_Sn(x, mu.too=TRUE)

(s &lt;- Sn(c(1:4, 10, Inf, NA), na.rm=TRUE))
stopifnot(is.finite(s), all.equal(3.5527554, s, tol=1e-10))
</code></pre>

<hr>
<h2 id='splitFrame'>
Split Continuous and Categorical Predictors
</h2><span id='topic+splitFrame'></span>

<h3>Description</h3>

<p>Splits the design matrix into categorical and continuous
predictors.  Categorical variables are variables that are <code><a href="base.html#topic+factor">factor</a></code>s,
<code><a href="base.html#topic+ordered">ordered</a></code> factors, <em>or</em> <code><a href="base.html#topic+character">character</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splitFrame(mf, x = model.matrix(mt, mf),
 	   type = c("f","fi", "fii"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splitFrame_+3A_mf">mf</code></td>
<td>
<p>model frame (as returned by <code><a href="stats.html#topic+model.frame">model.frame</a></code>).</p>
</td></tr>
<tr><td><code id="splitFrame_+3A_x">x</code></td>
<td>
<p>(optional) design matrix, defaulting to the derived
<code><a href="stats.html#topic+model.matrix">model.matrix</a></code>.</p>
</td></tr>
<tr><td><code id="splitFrame_+3A_type">type</code></td>
<td>
<p>a character string specifying the split type (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Which split type is used can be controlled with the setting
<code>split.type</code> in <code><a href="#topic+lmrob.control">lmrob.control</a></code>.
</p>
<p>There are three split types. The only differences between the types
are how interactions between categorical and continuous variables are
handled. The extra types of splitting can be used to avoid
<em>Too many singular resamples</em> errors.
</p>
<p>Type <code>"f"</code>, the default, assigns only the intercept, categorical and
interactions of categorical variables to <code>x1</code>.  Interactions of
categorical and continuous variables are assigned to <code>x2</code>.
</p>
<p>Type <code>"fi"</code> assigns also interactions between categorical and
continuous variables to <code>x1</code>.
</p>
<p>Type <code>"fii"</code> assigns not only interactions between categorical and
continuous variables to <code>x1</code>,  but also the (corresponding)
continuous variables themselves.
</p>


<h3>Value</h3>

<p>A list that includes the following components:
</p>
<table>
<tr><td><code>x1</code></td>
<td>
<p>design matrix containing only categorical variables</p>
</td></tr>
<tr><td><code>x1.idx</code></td>
<td>
<p>logical vectors of the variables considered
categorical in the original design matrix</p>
</td></tr>
<tr><td><code>x2</code></td>
<td>
<p>design matrix containing the continuous variables</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Koller
</p>


<h3>References</h3>

<p>Maronna, R. A., and Yohai, V. J. (2000).
Robust regression with both continuous and categorical predictors.
<em>Journal of Statistical Planning and Inference</em> <b>89</b>, 197&ndash;214.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob.M.S">lmrob.M.S</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(education)
education &lt;- within(education, Region &lt;- factor(Region))
educaCh   &lt;- within(education, Region &lt;- as.character(Region))

## no interactions -- same split for all types:
fm1 &lt;- lm(Y ~ Region + X1 + X2 + X3, education)
fmC &lt;- lm(Y ~ Region + X1 + X2 + X3, educaCh  )
splt &lt;- splitFrame(fm1$model) ; str(splt)
splC &lt;- splitFrame(fmC$model)
stopifnot(identical(splt, splC))

## with interactions:
fm2 &lt;- lm(Y ~ Region:X1:X2 + X1*X2, education)
s1 &lt;- splitFrame(fm2$model, type="f"  )
s2 &lt;- splitFrame(fm2$model, type="fi" )
s3 &lt;- splitFrame(fm2$model, type="fii")
cbind(s1$x1.idx,
      s2$x1.idx,
      s3$x1.idx)
rbind(p.x1 = c(ncol(s1$x1), ncol(s2$x1), ncol(s3$x1)),
      p.x2 = c(ncol(s1$x2), ncol(s2$x2), ncol(s3$x2)))
</code></pre>

<hr>
<h2 id='starsCYG'>Hertzsprung-Russell Diagram Data of Star Cluster CYG OB1</h2><span id='topic+starsCYG'></span>

<h3>Description</h3>

<p>Data for the Hertzsprung-Russell Diagram of the Star Cluster CYG OB1,
which contains 47 stars in the direction of Cygnus, from C.Doom.  The
first variable is the logarithm of the effective temperature at the
surface of the star (Te) and the second one is the logarithm of its
light intencity (<code class="reqn">L/L_0</code>).
</p>
<p>In the Hertzsprung-Russell diagram, which is the scatterplot of these
data points, where the log temperature is plotted from left to right,
two groups of points are seen:<br />
the majority which tend to follow a steep band and four stars in the
upper corner.  In the astronomy the 43 stars are said to lie on the
main sequence and the four remaining stars are called &ldquo;giants&rdquo; (the
points 11, 20, 30, 34).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(starsCYG, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 47 observations on the following 2 variables
</p>

<dl>
<dt><code>log.Te</code></dt><dd><p>Logarithm of the effective temperature at the
surface of the star (Te).</p>
</dd>
<dt><code>log.light</code></dt><dd><p>Logarithm of its light intencity (<code class="reqn">L/L_0</code>)</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, p.27, table 3.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(starsCYG)
plot(starsCYG)
cst &lt;- covMcd(starsCYG)
lm.stars &lt;- lm(log.light ~ log.Te, data = starsCYG)
summary(lm.stars)
plot(lm.stars)
lts.stars &lt;- ltsReg(log.light ~ log.Te, data = starsCYG)
plot(lts.stars)
</code></pre>

<hr>
<h2 id='steamUse'>Steam Usage Data (Excerpt)</h2><span id='topic+steamUse'></span>

<h3>Description</h3>

<p>The monthly use of steam (<code>Steam</code>) in a factory may be
modeled and described as function of the
operating days per month (<code>Operating.Days</code>) and
mean outside temperature per month (<code>Temperature</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("steamUse", package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 9 variables.
</p>

<dl>
<dt><code>Steam</code>:</dt><dd><p>regression response <code class="reqn">Y</code>, the poinds of
steam used monthly.</p>
</dd>
<dt><code>fattyAcid</code>:</dt><dd><p>pounds of Real Fatty Acid in storage per month.</p>
</dd>
<dt><code>glycerine</code>:</dt><dd><p>pounds of crude glycerine made.</p>
</dd>
<dt><code>wind</code>:</dt><dd><p>average wind velocity in miles per hour (a numeric vector).</p>
</dd>
<dt><code>days</code>:</dt><dd><p>an integer vector with number of days of that
month, i.e., in <code class="reqn">28..31</code>.</p>
</dd>
<dt><code>op.days</code>:</dt><dd><p>the number of operating days for the given
month (integer).</p>
</dd>
<dt><code>freeze.d</code>:</dt><dd><p>the number of days below
32 degrees Fahrenheit (<code class="reqn">= 0</code>Â°C (C=Celsius) <code class="reqn">=</code>
freezing temperature of water).</p>
</dd>
<dt><code>temperature</code>:</dt><dd><p>a numeric vector of average outside temperature in
Fahrenheit (F).</p>
</dd>
<dt><code>startups</code>:</dt><dd><p>the number of startups (of production in that month).</p>
</dd>
</dl>



<h3>Details</h3>

<p>Nor further information is given in Draper and Smith, about the place
and exacts years of the measurements, though some educated guesses
should be possible, see the examples.
</p>


<h3>Source</h3>

<p>Data from Draper and Smith, 1st ed, 1966; appendix A.
</p>
<p>A version of this has been used in teaching at SfS ETH Zurich, since at least 1996,
<a href="https://stat.ethz.ch/Teaching/Datasets/NDK/dsteam.dat">https://stat.ethz.ch/Teaching/Datasets/NDK/dsteam.dat</a>
</p>
<p>The package <a href="https://CRAN.R-project.org/package=aprean3"><span class="pkg">aprean3</span></a> contains all data sets from the 3rd
edition of Draper and Smith (1998), and this data set with variable
names <code>x1 .. x10</code> (<code>x9</code> being <code>wind^2</code>, hence extraneous).
</p>


<h3>References</h3>

<p>Draper and Smith (1981) Applied Regression Analysis (2nd ed., p. 615 ff)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
if(require("aprean3")) { # show how  'steamUse'  is related to 'dsa01a'
  stm &lt;- dsa01a
  names(stm) &lt;- c("Steam", "fattyAcid", "glycerine", "wind",
		  "days", "op.days", "freeze.d",
		  "temperature", "wind.2", "startups")
  ## prove that wind.2 is  wind^2, "traditionally" rounded to 1 digit:
  stopifnot(all.equal(floor(0.5 + 10*stm[,"wind"]^2)/10,
                      stm[,"wind.2"], tol = 1e-14))
  ## hence drop it
  steamUse &lt;- stm[, names(stm) != "wind.2"]
}

## End(Not run)
data(steamUse)
str(steamUse)
## Looking at this,
cbind(M=rep_len(month.abb, 25), steamUse[,5:8, drop=FALSE])
## one will conjecture that these were 25 months, Jan--Jan in a row,
## starting in a leap year (perhaps 1960 ?).

plot(steamUse)

summary(fm1 &lt;- lmrob(Steam ~ temperature + op.days, data=steamUse))
## diagnoses 2 outliers: month of July, maybe company-wide summer vacations

## KS2014 alone seems not robust enough:
summary(fm.14 &lt;- lmrob(Steam ~ temperature + op.days, data=steamUse,
         setting="KS2014"))
pairs(Steam ~ temperature+op.days, steamUse)
</code></pre>

<hr>
<h2 id='summarizeRobWeights'>Print a Nice &quot;summary&quot; of Robustness Weights</h2><span id='topic+summarizeRobWeights'></span>

<h3>Description</h3>

<p>Print a nice &ldquo;summary&rdquo; about a numeric vector of robustness
weights.  Observations with weights around zero are marked as outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summarizeRobWeights(w, digits = getOption("digits"),
                    header = "Robustness weights:",
 	            eps = 0.1 / length(w), eps1 = 1e-3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summarizeRobWeights_+3A_w">w</code></td>
<td>
<p>numeric vector of robustness weigths.</p>
</td></tr>
<tr><td><code id="summarizeRobWeights_+3A_digits">digits</code></td>
<td>
<p>digits to be used for <code><a href="base.html#topic+print">print</a></code>ing.</p>
</td></tr>
<tr><td><code id="summarizeRobWeights_+3A_header">header</code></td>
<td>
<p>string to be printed as header line.</p>
</td></tr>
<tr><td><code id="summarizeRobWeights_+3A_eps">eps</code></td>
<td>
<p>numeric tolerance <code class="reqn">\epsilon</code>: values of <code>w</code>
with <code class="reqn">\left|w_i\right| &lt; \epsilon/n</code> are said to
be outliers.</p>
</td></tr>
<tr><td><code id="summarizeRobWeights_+3A_eps1">eps1</code></td>
<td>
<p>numeric tolerance: values of <code>w</code> with
<code class="reqn">\left|1 - w_i\right| &lt; eps1</code> are said to
have weight &lsquo;<code>~= 1</code>&rsquo;.</p>
</td></tr>
<tr><td><code id="summarizeRobWeights_+3A_...">...</code></td>
<td>
<p>potential further arguments, passed to
<code><a href="base.html#topic+print">print</a>()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>none; the function is used for its side effect of printing.
</p>


<h3>Author(s)</h3>

<p>Martin Maechler</p>


<h3>See Also</h3>

<p>The <code><a href="base.html#topic+summary">summary</a></code> methods for <code><a href="#topic+lmrob">lmrob</a></code>
and <code><a href="#topic+glmrob">glmrob</a></code> make use of <code>summarizeRobWeights()</code>.
</p>
<p>Our methods for <code><a href="stats.html#topic+weights">weights</a>()</code>,
<code><a href="#topic+weights.lmrob">weights.lmrob</a>(*, type="robustness")</code> and
<code><a href="#topic+weights.glmrob">weights.glmrob</a>(*, type="robustness")</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>w &lt;- c(1,1,1,1,0,1,1,1,1,0,1,1,.9999,.99999, .5,.6,1e-12)
summarizeRobWeights(w) # two outside ~= {0,1}
summarizeRobWeights(w, eps1 = 5e-5)# now three outside {0,1}

## See the summary(&lt;lmrob&gt;) outputs
</code></pre>

<hr>
<h2 id='summary.glmrob'>Summarizing Robust Fits of Generalized Linear Models</h2><span id='topic+summary.glmrob'></span><span id='topic+vcov.glmrob'></span><span id='topic+print.summary.glmrob'></span>

<h3>Description</h3>

<p>The <code>summary</code> method for class <code>"<a href="#topic+glmrob">glmrob</a>"</code>
summarizes robust fits of (currently only discrete) generalized linear
models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'glmrob'
summary(object, correlation = FALSE, symbolic.cor = FALSE, ...)
## S3 method for class 'glmrob'
vcov(object, ...)

## S3 method for class 'summary.glmrob'
print(x, digits = max(3, getOption("digits") - 3),
      symbolic.cor = x$symbolic.cor,
      signif.stars = getOption("show.signif.stars"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.glmrob_+3A_object">object</code></td>
<td>
<p>an object of class <code>"glmrob"</code>, usually, a result of
a call to <code><a href="#topic+glmrob">glmrob</a></code>.</p>
</td></tr>
<tr><td><code id="summary.glmrob_+3A_correlation">correlation</code></td>
<td>
<p>logical; if <code>TRUE</code>, the correlation matrix of
the estimated parameters is returned and printed.</p>
</td></tr>
<tr><td><code id="summary.glmrob_+3A_symbolic.cor">symbolic.cor</code></td>
<td>
<p>logical. If <code>TRUE</code>, print the correlations in
a symbolic form (see <code><a href="stats.html#topic+symnum">symnum</a></code>) rather than as numbers.</p>
</td></tr>
<tr><td><code id="summary.glmrob_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="summary.glmrob_+3A_x">x</code></td>
<td>
<p>an object of class <code>"summary.glrob"</code>.</p>
</td></tr>
<tr><td><code id="summary.glmrob_+3A_digits">digits</code></td>
<td>
<p>the number of digits to use for printing.</p>
</td></tr>
<tr><td><code id="summary.glmrob_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical indicating if the P-values should be
visualized by so called &ldquo;significance stars&rdquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+summary.glmrob">summary.glmrob</a></code> returns an object of <code><a href="base.html#topic+class">class</a></code>
<code>"summary.glmrob"</code>.
</p>
<p>Its <code><a href="base.html#topic+print">print</a>()</code> method tries to be smart about formatting the
coefficients, standard errors, etc, and gives
&ldquo;significance stars&rdquo; if <code>signif.stars</code> is <code>TRUE</code>
(as per default when <code><a href="base.html#topic+options">options</a></code> where not changed).
</p>


<h3>Value</h3>

<p>The function <code><a href="#topic+summary.glmrob">summary.glmrob</a></code> computes and returns a list
of summary statistics of the robustly fitted linear model given in
<code>object</code>. The following elements are in the list:
</p>
<table>
<tr><td><code>...</code></td>
<td>
<p> FIXME </p>
</td></tr>


</table>


<h3>Author(s)</h3>

<p>Andreas Ruckstuhl</p>


<h3>See Also</h3>

<p><code><a href="#topic+glmrob">glmrob</a></code>; the generic <code><a href="base.html#topic+summary">summary</a></code> and
also <code><a href="stats.html#topic+summary.glm">summary.glm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(epilepsy)
Rmod &lt;- glmrob(Ysum ~ Age10 + Base4*Trt, family = poisson,
               data = epilepsy, method= "Mqle")
ss &lt;- summary(Rmod)
ss ## calls print.summary.glmrob()
str(ss) ## internal STRucture of summary object
</code></pre>

<hr>
<h2 id='summary.lmrob'>Summary Method for &quot;lmrob&quot; Objects</h2><span id='topic+summary.lmrob'></span><span id='topic+hatvalues.lmrob'></span><span id='topic+.lmrob.hat'></span><span id='topic+vcov.lmrob'></span><span id='topic+print.summary.lmrob'></span><span id='topic+model.matrix.lmrob'></span>

<h3>Description</h3>

<p>Summary method for <span class="rlang"><b>R</b></span> object of class <code>"lmrob"</code> and
<code><a href="base.html#topic+print">print</a></code> method for the summary object.
</p>
<p>Further, methods <code><a href="stats.html#topic+fitted">fitted</a>()</code>, <code><a href="stats.html#topic+residuals">residuals</a>()</code>
work (via the default methods), and
<code><a href="stats.html#topic+predict">predict</a>()</code> (see <code><a href="#topic+predict.lmrob">predict.lmrob</a></code>,
<code><a href="stats.html#topic+vcov">vcov</a>()</code>, <code><a href="stats.html#topic+weights">weights</a>()</code> (see
<code><a href="#topic+weights.lmrob">weights.lmrob</a></code>), <code><a href="stats.html#topic+model.matrix">model.matrix</a>()</code>,
<code><a href="stats.html#topic+confint">confint</a>()</code>, <code><a href="stats.html#topic+dummy.coef">dummy.coef</a>()</code>,
<code><a href="stats.html#topic+hatvalues">hatvalues</a>()</code>, etc.,
have explicitly defined <code>lmrob</code> methods.  <code>.lmrob.hat()</code> is
the lower level &ldquo;work horse&rdquo; of the <code>hatvalues()</code> method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'lmrob'
summary(object, correlation = FALSE,
        symbolic.cor = FALSE, ...)
## S3 method for class 'summary.lmrob'
print(x, digits = max(3, getOption("digits") - 3),
      symbolic.cor= x$symbolic.cor,
      signif.stars = getOption("show.signif.stars"),
      showAlgo = TRUE, ...)

## S3 method for class 'lmrob'
vcov(object, cov = object$control$cov, complete = TRUE, ...)
## S3 method for class 'lmrob'
model.matrix(object, ...)



</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.lmrob_+3A_object">object</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code>lmrob</code>, typically created by
<code><a href="#topic+lmrob">lmrob</a></code>.</p>
</td></tr>
<tr><td><code id="summary.lmrob_+3A_correlation">correlation</code></td>
<td>
<p>logical variable indicating whether
to compute the correlation matrix of the estimated coefficients.</p>
</td></tr>
<tr><td><code id="summary.lmrob_+3A_symbolic.cor">symbolic.cor</code></td>
<td>
<p>logical indicating whether
to use symbols to display the above correlation matrix.</p>
</td></tr>
<tr><td><code id="summary.lmrob_+3A_x">x</code></td>
<td>
<p>an <span class="rlang"><b>R</b></span> object of class <code>summary.lmrob</code>, typically
resulting from <code>summary(<a href="#topic+lmrob">lmrob</a>(..),..)</code>.</p>
</td></tr>
<tr><td><code id="summary.lmrob_+3A_digits">digits</code></td>
<td>
<p>number of digits for printing, see <code>digits</code> in
<code><a href="base.html#topic+options">options</a></code>.</p>
</td></tr>
<tr><td><code id="summary.lmrob_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical variable indicating
whether to use stars to display different levels of
significance in the individual t-tests.</p>
</td></tr>
<tr><td><code id="summary.lmrob_+3A_showalgo">showAlgo</code></td>
<td>
<p>optional <code><a href="base.html#topic+logical">logical</a></code> indicating if the
algorithmic parameters (as mostly inside the <code>control</code> part)
should be shown.</p>
</td></tr>
<tr><td><code id="summary.lmrob_+3A_cov">cov</code></td>
<td>
<p>covariance estimation function to use, a
<code><a href="base.html#topic+function">function</a></code> or <a href="base.html#topic+character">character</a> string naming the
function; <span class="pkg">robustbase</span> currently provides <code>".vcov.w"</code> and
<code>".vcov.avar1"</code>, see <em>Details</em> of <code><a href="#topic+lmrob">lmrob</a></code>.
Particularly useful when <code>object</code> is the result of
<code>lmrob(.., cov = "none")</code>, where </p>
<pre>  object$cov &lt;- vcov(object, cov = ".vcov.w")</pre>
<p>allows to <em>update</em> the fitted object.</p>
</td></tr>
<tr><td><code id="summary.lmrob_+3A_complete">complete</code></td>
<td>
<p>(mainly for <span class="rlang"><b>R</b></span> <code>&gt;= 3.5.0</code>:)
<code><a href="base.html#topic+logical">logical</a></code> indicating if the
full variance-covariance matrix should be returned also in case of
an over-determined system where some coefficients are undefined and
<code><a href="stats.html#topic+coef">coef</a>(.)</code> contains <code>NA</code>s correspondingly.   When
<code>complete = TRUE</code>,  <code>vcov()</code> is compatible with
<code>coef()</code> also in this singular case.</p>
</td></tr>
<tr><td><code id="summary.lmrob_+3A_...">...</code></td>
<td>
<p>potentially more arguments passed to methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary(object)</code> returns an object of S3 class
<code>"summary.lmrob"</code>, basically a <code><a href="base.html#topic+list">list</a></code> with components
&quot;call&quot;, &quot;terms&quot;, &quot;residuals&quot;, &quot;scale&quot;, &quot;rweights&quot;, &quot;converged&quot;,
&quot;iter&quot;, &quot;control&quot; all copied from <code>object</code>, and further
components, partly for compatibility with <code><a href="stats.html#topic+summary.lm">summary.lm</a></code>,
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>a <code><a href="base.html#topic+matrix">matrix</a></code> with columns <code>"Estimate"</code>,
<code>"Std. Error"</code>, <code>"t value"</code>, and <code>"PR(&gt;|t|)"</code>, where
&quot;Estimate&quot; is identical to <code><a href="stats.html#topic+coef">coef</a>(object)</code>. Note that
<code><a href="stats.html#topic+coef">coef</a>(&lt;summary.obj&gt;)</code> is slightly preferred to access
this matrix.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom, in an <code><a href="stats.html#topic+lm">lm</a></code> compatible way.</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>identical to <code><a href="#topic+sigma">sigma</a>(object)</code>.</p>
</td></tr>
<tr><td><code>aliased</code></td>
<td>
<p>..</p>
</td></tr>
<tr><td><code>cov</code></td>
<td>
<p>derived from <code>object$cov</code>.</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>robust &ldquo;R squared&rdquo; or <code class="reqn">R^2</code>, a coefficient
of determination:  This is the consistency corrected robust
coefficient of determination by Renaud and Victoria-Feser (2010).</p>
</td></tr>
<tr><td><code>adj.r.squared</code></td>
<td>
<p>an adjusted R squared, see <code>r.squared</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Renaud, O. and Victoria-Feser, M.-P. (2010).
A robust coefficient of determination for regression,
<em>Journal of Statistical Planning and Inference</em> <b>140</b>, 1852-1862.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob">lmrob</a></code>, <code><a href="#topic+predict.lmrob">predict.lmrob</a></code>,
<code><a href="#topic+weights.lmrob">weights.lmrob</a></code>, <code><a href="stats.html#topic+summary.lm">summary.lm</a></code>,
<code><a href="base.html#topic+print">print</a></code>, <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>mod1 &lt;- lmrob(stack.loss ~ ., data = stackloss)
sa &lt;- summary(mod1)  # calls summary.lmrob(....)
sa                   # dispatches to call print.summary.lmrob(....)

## correlation between estimated coefficients:
cov2cor(vcov(mod1))

cbind(fit = fitted(mod1), resid = residuals(mod1),
      wgts= weights(mod1, type="robustness"),
      predict(mod1, interval="prediction"))

data(heart)
sm2 &lt;- summary( m2 &lt;- lmrob(clength ~ ., data = heart) )
sm2
</code></pre>

<hr>
<h2 id='summary.lts'>Summary Method for LTS objects</h2><span id='topic+summary.lts'></span><span id='topic+print.summary.lts'></span>

<h3>Description</h3>

<p><code>summary</code> method for class <code>"lts"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lts'
summary(object, correlation = FALSE, ...)

## S3 method for class 'summary.lts'
print(x, digits = max(3, getOption("digits") - 3),
     signif.stars = getOption("show.signif.stars"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.lts_+3A_object">object</code></td>
<td>
<p>an object of class <code>"lts"</code>, usually, a result of a call to <code><a href="#topic+ltsReg">ltsReg</a></code>.</p>
</td></tr>
<tr><td><code id="summary.lts_+3A_correlation">correlation</code></td>
<td>
<p>logical; if <code>TRUE</code>, the correlation matrix of the estimated parameters is returned and printed.</p>
</td></tr>
<tr><td><code id="summary.lts_+3A_x">x</code></td>
<td>
<p>an object of class <code>"summary.lts"</code>, usually, a result of a call to <code>summary.lts</code>.</p>
</td></tr>
<tr><td><code id="summary.lts_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="summary.lts_+3A_signif.stars">signif.stars</code></td>
<td>
<p>logical indicating if &ldquo;significance stars&rdquo;
should be printer, see <code><a href="stats.html#topic+printCoefmat">printCoefmat</a></code>.</p>
</td></tr>
<tr><td><code id="summary.lts_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions compute and print summary statistics for weighted
least square estimates with weights based on LTS estimates.  Therefore
the statistics are similar to those for LS but all terms are
multiplied by the corresponding weight.
</p>
<p>Correlations are printed to two decimal places: to see the actual correlations
print <code>summary(object)$correlation</code> directly.
</p>


<h3>Value</h3>

<p>The function <code>summary.lts</code> computes and returns a list of summary
statistics of the fitted linear model given in <code>object</code>, using
the components of this object (list elements).
</p>
<table>
<tr><td><code>residuals</code></td>
<td>
<p>the residuals - a vector like the response <code>y</code>
containing the residuals from the weighted least squares regression.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a <code class="reqn">p \times 4</code> matrix with columns for
the estimated coefficient, its standard error, t-statistic and
corresponding (two-sided) p-value. </p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>the estimated scale of the reweighted residuals
</p>
<p style="text-align: center;"><code class="reqn">\hat\sigma^2 = \frac{1}{n-p}\sum_i{R_i^2},</code>
</p>

<p>where <code class="reqn">R_i</code> is the <code class="reqn">i</code>-th residual, <code>residuals[i]</code>.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>degrees of freedom, a 3-vector <code class="reqn">(p, n-p, p*)</code>, the last
being the number of non-aliased coefficients.</p>
</td></tr>
<tr><td><code>fstatistic</code></td>
<td>
<p>(for models including non-intercept terms)
a 3-vector with the value of the F-statistic with
its numerator and denominator degrees of freedom.</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p><code class="reqn">R^2</code>, the &ldquo;fraction of variance explained by
the model&rdquo;,
</p>
<p style="text-align: center;"><code class="reqn">R^2 = 1 - \frac{\sum_i{R_i^2}}{\sum_i(y_i- y^*)^2},</code>
</p>

<p>where <code class="reqn">y^*</code> is the mean of <code class="reqn">y_i</code> if there is an
intercept and zero otherwise.</p>
</td></tr>
<tr><td><code>adj.r.squared</code></td>
<td>
<p>the above <code class="reqn">R^2</code> statistic
&ldquo;<em>adjusted</em>&rdquo;, penalizing for higher <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code>cov.unscaled</code></td>
<td>
<p>a <code class="reqn">p \times p</code> matrix of (unscaled)
covariances of the <code class="reqn">\hat\beta_j</code>, <code class="reqn">j=1, \dots, p</code>.</p>
</td></tr>
<tr><td><code>correlation</code></td>
<td>
<p>the correlation matrix corresponding to the above
<code>cov.unscaled</code>, if <code>correlation = TRUE</code> is specified.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+ltsReg">ltsReg</a></code>; the generic <code><a href="base.html#topic+summary">summary</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Animals2)
ltsA &lt;- ltsReg(log(brain) ~ log(body), data = Animals2)
(slts &lt;- summary(ltsA))
## non-default options for printing the summary:
print(slts, digits = 5, signif.stars = FALSE)
</code></pre>

<hr>
<h2 id='summary.mcd'>Summary Method for MCD objects</h2><span id='topic+summary.mcd'></span><span id='topic+print.summary.mcd'></span>

<h3>Description</h3>

<p><code><a href="base.html#topic+summary">summary</a></code> method for class <code>"mcd"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mcd'
summary(object, ...)
## S3 method for class 'summary.mcd'
print(x, digits = max(3, getOption("digits") - 3),
     print.gap = 2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.mcd_+3A_object">object</code>, <code id="summary.mcd_+3A_x">x</code></td>
<td>
<p>an object of class <code>"mcd"</code> (or <code>"summary.mcd"</code>);
usually, a result of a call to <code><a href="#topic+covMcd">covMcd</a></code>.</p>
</td></tr>
<tr><td><code id="summary.mcd_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="summary.mcd_+3A_print.gap">print.gap</code></td>
<td>
<p>number of horizontal spaces between numbers; see also
<code><a href="base.html#topic+print.default">print.default</a></code>.</p>
</td></tr>
<tr><td><code id="summary.mcd_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>summary.mcd()</code>, the S3 method, simply returns an (S3) object of
<code><a href="base.html#topic+class">class</a> "summary.mcd"</code> for which there's a
<code><a href="base.html#topic+print">print</a></code> method:
</p>
<p><code>print.summary.mcd</code> prints summary statistics for the weighted covariance
matrix and location estimates with weights based on MCD estimates.
While the function <code><a href="#topic+print.mcd">print.mcd</a></code> prints only the robust estimates
of the location and the covariance matrix, <code>print.summary.mcd</code> will
print also the correlation matrix (if requested in the call to
<code>covMcd</code> with <code>cor=TRUE</code>), the eigenvalues of the covariance
or the correlation matrix and the robust (&ldquo;Mahalanobis&rdquo;) distances.
</p>


<h3>Value</h3>

<p><code>summary.mcd</code> returns an <code>summary.mcd</code> object, whereas the
<code>print</code> methods returns its first argument via
<code><a href="base.html#topic+invisible">invisible</a></code>, as all <code>print</code> methods do.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+covMcd">covMcd</a></code>, <code><a href="base.html#topic+summary">summary</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Animals, package = "MASS")
brain &lt;- Animals[c(1:24, 26:25, 27:28),]
lbrain &lt;- log(brain)
summary(cLB &lt;- covMcd(lbrain))
</code></pre>

<hr>
<h2 id='summary.nlrob'>Summarizing Robust Fits of Nonlinear Regression Models </h2><span id='topic+summary.nlrob'></span>

<h3>Description</h3>

<p><code>summary</code> method for objects of class <code>"nlrob"</code>, i.e.,
<code><a href="#topic+nlrob">nlrob</a>()</code> results.  Currently it only works for
<code>nlrob(*, method="M")</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'nlrob'
summary(object, correlation = FALSE, symbolic.cor = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.nlrob_+3A_object">object</code></td>
<td>
<p>an object of class <code>"nlrob"</code>, usually, a result of
a call to <code><a href="#topic+nlrob">nlrob</a></code>.</p>
</td></tr>
<tr><td><code id="summary.nlrob_+3A_correlation">correlation</code></td>
<td>
<p>logical variable indicating whether
to compute the correlation matrix of the estimated coefficients.</p>
</td></tr>
<tr><td><code id="summary.nlrob_+3A_symbolic.cor">symbolic.cor</code></td>
<td>
<p>logical indicating whether
to use symbols to display the above correlation matrix.</p>
</td></tr>
<tr><td><code id="summary.nlrob_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function <code><a href="#topic+summary.nlrob">summary.nlrob</a></code> computes and returns an
object of class <code>"summary.nlrob"</code> of summary statistics of the
robustly fitted linear model given in <code>object</code>.
There is a print method, <code>print.summary.lmrob()</code>, which nicely
formats the output.
</p>
<p>The result keeps a large part of <code>object</code>'s components such as
<code>residuals</code>, <code>cov</code> or <code>w</code>, and additionally contains
</p>
<table>
<tr><td><code>coefficients</code></td>
<td>
<p>the matrix of coefficients, standard errors and
p-values.</p>
</td></tr>
<tr><td><code>correlation</code></td>
<td>
<p>if the <code>correlation</code> argument was true, the
correlation matrix of the parameters.</p>
</td></tr>

</table>


<h3>Author(s)</h3>

<p>Andreas Ruckstuhl</p>


<h3>See Also</h3>

<p><code><a href="#topic+nlrob">nlrob</a>()</code>, also for examples.
</p>

<hr>
<h2 id='telef'>Number of International Calls from Belgium</h2><span id='topic+telef'></span>

<h3>Description</h3>

<p>Number of international calls from Belgium, taken from the Belgian
Statistical Survey, published by the Ministry of Economy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(telef, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 24 observations on the following 2 variables.
</p>

<dl>
<dt><code>Calls</code></dt><dd><p>Number of Calls (in tens of millions) </p>
</dd>
<dt><code>Year</code></dt><dd><p>Year (1950 - 1973)</p>
</dd>
</dl>



<h3>Source</h3>

<p>P. J. Rousseeuw and A. M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em>;
Wiley, page 26, table 2.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(telef)
summary(lm.telef &lt;- lm(Year~., data=telef))

</code></pre>

<hr>
<h2 id='tolEllipsePlot'>Tolerance Ellipse Plot</h2><span id='topic+tolEllipsePlot'></span>

<h3>Description</h3>

<p>Plots the 0.975 tolerance ellipse of the bivariate data set <code>x</code>.
The ellipse is defined by those data points whose distance
is equal to the squareroot of the 0.975 chisquare quantile
with 2 degrees of freedom.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tolEllipsePlot(x, m.cov = covMcd(x), cutoff = NULL, id.n = NULL,
               classic = FALSE, tol = 1e-07,
               xlab = "", ylab = "",
               main = "Tolerance ellipse (97.5%)",
               txt.leg = c("robust", "classical"),
               col.leg = c("red", "blue"),
               lty.leg = c("solid","dashed"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tolEllipsePlot_+3A_x">x</code></td>
<td>
<p>a two dimensional matrix or data frame. </p>
</td></tr>
<tr><td><code id="tolEllipsePlot_+3A_m.cov">m.cov</code></td>
<td>
<p>an object similar to those of class <code>"mcd"</code>; however
only its components <code>center</code> and <code>cov</code> will be used.  If
missing, the MCD will be computed (via <code><a href="#topic+covMcd">covMcd</a>()</code>).</p>
</td></tr>
<tr><td><code id="tolEllipsePlot_+3A_cutoff">cutoff</code></td>
<td>
<p>numeric distance needed to flag data points outside the
ellipse.</p>
</td></tr>
<tr><td><code id="tolEllipsePlot_+3A_id.n">id.n</code></td>
<td>
<p>number of observations to be identified by a label.  If
not supplied, the number of observations with distance larger than
<code>cutoff</code> is used.</p>
</td></tr>
<tr><td><code id="tolEllipsePlot_+3A_classic">classic</code></td>
<td>
<p>whether to plot the classical distances as well,
<code>FALSE</code> by default.</p>
</td></tr>
<tr><td><code id="tolEllipsePlot_+3A_tol">tol</code></td>
<td>
<p>tolerance to be used for computing the inverse, see
<code><a href="Matrix.html#topic+solve">solve</a></code>.  Defaults to <code>1e-7</code>.</p>
</td></tr>
<tr><td><code id="tolEllipsePlot_+3A_xlab">xlab</code>, <code id="tolEllipsePlot_+3A_ylab">ylab</code>, <code id="tolEllipsePlot_+3A_main">main</code></td>
<td>
<p>passed to <code><a href="graphics.html#topic+plot.default">plot.default</a></code>.</p>
</td></tr>
<tr><td><code id="tolEllipsePlot_+3A_txt.leg">txt.leg</code>, <code id="tolEllipsePlot_+3A_col.leg">col.leg</code>, <code id="tolEllipsePlot_+3A_lty.leg">lty.leg</code></td>
<td>
<p>character vectors of length 2 for the
legend, only used if <code>classic = TRUE</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Peter Filzmoser, Valentin Todorov and Martin Maechler</p>


<h3>See Also</h3>

<p><code><a href="#topic+covPlot">covPlot</a></code> which calls <code>tolEllipsePlot()</code> when
desired.
<code><a href="cluster.html#topic+ellipsoidhull">ellipsoidhull</a></code> and
<code><a href="cluster.html#topic+predict.ellipsoid">predict.ellipsoid</a></code> from package <a href="https://CRAN.R-project.org/package=cluster"><span class="pkg">cluster</span></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(hbk)
hbk.x &lt;- data.matrix(hbk[, 1:3])
mcd &lt;- covMcd(hbk.x)       # compute mcd in advance
## must be a 2-dimensional data set: take the first two columns :
tolEllipsePlot(hbk.x[,1:2])

## an "impressive" example:
data(telef)
tolEllipsePlot(telef, classic=TRUE)
</code></pre>

<hr>
<h2 id='toxicity'>Toxicity of Carboxylic Acids Data</h2><span id='topic+toxicity'></span>

<h3>Description</h3>

<p>The aim of the experiment was to predict the toxicity of carboxylic acids on
the basis of several molecular descriptors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(toxicity, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 38 observations on the following 10 variables which are
attributes for carboxylic acids:
</p>

<dl>
<dt><code>toxicity</code></dt><dd><p>aquatic toxicity, defined as
<code class="reqn">\log(IGC_{50}^{-1})</code>; typically the &ldquo;response&rdquo;.</p>
</dd>
<dt><code>logKow</code></dt><dd><p><code class="reqn">log Kow</code>, the partition coefficient</p>
</dd>
<dt><code>pKa</code></dt><dd><p>pKa: the dissociation constant</p>
</dd>
<dt><code>ELUMO</code></dt><dd><p><b>E</b>nergy of the <b>l</b>owest
<b>u</b>noccupied <b>m</b>olecular <b>o</b>rbital</p>
</dd>
<dt><code>Ecarb</code></dt><dd><p>Electrotopological state of the <b>carb</b>oxylic group</p>
</dd>
<dt><code>Emet</code></dt><dd><p>Electrotopological state of the <b>met</b>hyl group</p>
</dd>
<dt><code>RM</code></dt><dd><p>Molar refractivity</p>
</dd>
<dt><code>IR</code></dt><dd><p>Refraction index</p>
</dd>
<dt><code>Ts</code></dt><dd><p>Surface tension</p>
</dd>
<dt><code>P</code></dt><dd><p>Polarizability</p>
</dd>
</dl>



<h3>Source</h3>

<p>The website accompanying the MMY-book:
<a href="https://www.wiley.com/legacy/wileychi/robust_statistics/">https://www.wiley.com/legacy/wileychi/robust_statistics/</a>
</p>


<h3>References</h3>

<p>Maguna, F.P., NÃºÃ±ez, M.B., Okulik, N.B. and Castro, E.A. (2003)
Improved QSAR analysis of the toxicity of aliphatic carboxylic acids;
<em>Russian Journal of General Chemistry</em> <b>73</b>, 1792&ndash;1798.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(toxicity)
summary(toxicity)
plot(toxicity)
plot(toxicity ~ pKa, data = toxicity)

## robustly scale the data (to scale 1) using Qn
(scQ.tox &lt;- sapply(toxicity, Qn))
scTox &lt;- scale(toxicity, center = FALSE, scale = scQ.tox)
csT &lt;- covOGK(scTox, n.iter = 2,
              sigmamu = s_Qn, weight.fn = hard.rejection)
as.dist(round(cov2cor(csT$cov), 2))
</code></pre>

<hr>
<h2 id='tukeyPsi1'>Tukey's Bi-square Score (Psi) and &quot;Chi&quot; (Rho) Functions and Derivatives</h2><span id='topic+robustbase-deprecated'></span><span id='topic+tukeyPsi1'></span><span id='topic+tukeyChi'></span>

<h3>Description</h3>

<p>These are <b>deprecated</b>, replaced by
<code><a href="#topic+Mchi">Mchi</a>(*, psi="tukey")</code>, <code><a href="#topic+Mpsi">Mpsi</a>(*, psi="tukey")</code>
</p>
<p><code>tukeyPsi1()</code> computes Tukey's bi-square score (psi) function, its first
derivative or it's integral/&ldquo;principal function&rdquo;.  This is
scaled such that <code class="reqn">\psi'(0) = 1</code>, i.e.,
<code class="reqn">\psi(x) \approx x</code> around 0.
</p>
<p><code>tukeyChi()</code> computes Tukey's bi-square loss function,
<code>chi(x)</code> and its first two derivatives.  Note that in the general
context of <code class="reqn">M</code>-estimators, these loss functions are called
<code class="reqn">\rho (rho)</code>-functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>tukeyPsi1(x, cc, deriv = 0)
tukeyChi (x, cc, deriv = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tukeyPsi1_+3A_x">x</code></td>
<td>
<p>numeric vector.</p>
</td></tr>
<tr><td><code id="tukeyPsi1_+3A_cc">cc</code></td>
<td>
<p> tuning constant </p>
</td></tr>
<tr><td><code id="tukeyPsi1_+3A_deriv">deriv</code></td>
<td>
<p>integer in <code class="reqn">\{-1,0,1,2\}</code> specifying the order of the
derivative; the default, <code>deriv = 0</code> computes the psi-, or
chi- (&quot;rho&quot;-)function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a numeric vector of the same length as <code>x</code>.
</p>


<h3>Note</h3>

<p><code>tukeyPsi1(x, d)</code> and <code><a href="#topic+tukeyChi">tukeyChi</a>(x, d+1)</code> are just
re-scaled versions of each other (for <code>d in -1:1</code>), i.e.,
</p>
<p style="text-align: center;"><code class="reqn">\chi^{(\nu)}(x, c) = (6/c^2) \psi^{(\nu-1)}(x,c),</code>
</p>

<p>for <code class="reqn">\nu = 0,1,2</code>.
</p>
<p>We use the name &lsquo;tukeyPsi<b>1</b>&rsquo;, because <code>tukeyPsi</code> is
reserved for a future &ldquo;Psi Function&rdquo; class object, see
<code><a href="#topic+psiFunc">psiFunc</a></code>.
</p>


<h3>Author(s)</h3>

<p>Matias Salibian-Barrera, Martin Maechler and Andreas Ruckstuhl</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob">lmrob</a></code> and <code><a href="#topic+Mpsi">Mpsi</a></code>; further
<code><a href="#topic+anova.lmrob">anova.lmrob</a></code> which needs the <code>deriv = -1</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
op &lt;- par(mfrow = c(3,1), oma = c(0,0, 2, 0),
          mgp = c(1.5, 0.6, 0), mar= .1+c(3,4,3,2))
x &lt;- seq(-2.5, 2.5, length = 201)
cc &lt;- 1.55 # as set by default in lmrob.control()
plot. &lt;- function(...) { plot(...); abline(h=0,v=0, col="gray", lty=3)}
plot.(x, tukeyChi(x, cc), type = "l", col = 2)
plot.(x, tukeyChi(x, cc, deriv = 1), type = "l", col = 2)
plot.(x, tukeyChi(x, cc, deriv = 2), type = "l", col = 2)

mtext(sprintf("tukeyChi(x, c = %g, deriv),  deriv = 0,1,2", cc),
      outer = TRUE, font = par("font.main"), cex = par("cex.main"))
par(op)

op &lt;- par(mfrow = c(3,1), oma = c(0,0, 2, 0),
          mgp = c(1.5, 0.6, 0), mar= .1+c(3,4,1,1))
x &lt;- seq(-5, 5, length = 201)
cc &lt;- 4.69 # as set by default in lmrob.control()
plot. &lt;- function(...) { plot(..., asp = 1); abline(h=0,v=0, col="gray", lty=3)}
plot.(x, tukeyPsi1(x, cc), type = "l", col = 2)
abline(0:1, lty = 3, col = "light blue")
plot.(x, tukeyPsi1(x, cc, deriv = -1), type = "l", col = 2)
plot.(x, tukeyPsi1(x, cc, deriv =  1), type = "l", col = 2); abline(h=1,lty=3)

mtext(sprintf("tukeyPsi1(x, c = %g, deriv),  deriv = 0, -1, 1", cc),
      outer = TRUE, font = par("font.main"), cex = par("cex.main"))
par(op)

</code></pre>

<hr>
<h2 id='vaso'>Vaso Constriction Skin Data Set</h2><span id='topic+vaso'></span>

<h3>Description</h3>

<p>Finney's data on vaso constriction in the skin of the digits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(vaso, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 39 observations on the following 3 variables.
</p>

<dl>
<dt><code>Volume</code></dt><dd><p>Inhaled volume of air</p>
</dd>
<dt><code>Rate</code></dt><dd><p>Rate of inhalation</p>
</dd>
<dt><code>Y</code></dt><dd><p>vector of 0 or 1 values.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data taken from Finney (1947) were obtained in a carefully
controlled study in human physiology where a reflex
&ldquo;vaso constriction&rdquo; may occur in the skin of the digits after taking a
single deep breath.  The response y is the occurence (y = 1) or
non-occurence (y = 0) of vaso constriction in the skin of the digits
of a subject after he or she inhaled a certain volume of air at a certain
rate.  The responses of three subjects are available.  The first
contributed 9 responses, the second contributed 8 responses, and the
third contributed 22 responses.
</p>
<p>Although the data represent repeated measurements, an analysis that
assumes independent observations may be applied, as claimed by Pregibon
(1981).
</p>


<h3>Source</h3>

<p>Finney, D.J. (1947)
The estimation from individual records of the relationship between
dose and quantal response.
<em>Biometrika</em> <b>34</b>, 320&ndash;334
</p>


<h3>References</h3>

<p>Atkinson, A.C. and Riani, M. (2000)
<em>Robust Diagnostic Regression Analysis</em>,
First Edition. New York: Springer, Table A.23.
</p>
<p>Fahrmeir, L. and Tutz, G. (2001)
<em>Multivariate Statistical Modelling Based on Generalized Linear Models</em>,
Springer, Table 4.2.
</p>
<p>Kuensch, H.R., Stefanski, A. and Carrol, R.J. (1989)
Conditionally unbiased bounded influence estimation in general
regression models, with applications to generalized linear models,
<em>JASA</em> <b>84</b>, 460&ndash;466.
</p>
<p>Pregibon, D. (1981)
Logistic regression diagnostics,
<em>Annals of Statistics</em> <b>9</b>, 705&ndash;724.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(vaso)
str(vaso)
pairs(vaso)

glmV &lt;- glm(Y ~ log(Volume) + log(Rate), family=binomial, data=vaso)
summary(glmV)
## --&gt;  example(glmrob)  showing classical &amp; robust GLM
</code></pre>

<hr>
<h2 id='wagnerGrowth'>
Wagner's Hannover Employment Growth Data
</h2><span id='topic+wagnerGrowth'></span>

<h3>Description</h3>

<p>Wagner (1994) investigates the rate of employment growth (<code>y</code>) as
function of percentage of people engaged in <b>p</b>roducation
<b>a</b>ctivities (<code>PA</code>) and <b>h</b>igher <b>s</b>ervices
(<code>HS</code>) and of the <b>g</b>rowth of these percentages (<code>GPA</code>,
<code>GHS</code>) during three time periods in 21 geographical regions of
the greater Hannover area.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wagnerGrowth, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with <code class="reqn">21 \times 3 = 63</code> observations
(one per <code>Region x Period</code>) on the following 7 variables.
</p>

<dl>
<dt><code>Region</code></dt><dd><p>a <code><a href="base.html#topic+factor">factor</a></code> with 21 levels, denoting
the corresponding region in Hannover (conceptually a &ldquo;block
factor&rdquo;).</p>
</dd>
<dt><code>PA</code></dt><dd><p>numeric: percent of people involved in production activities.</p>
</dd>
<dt><code>GPA</code></dt><dd><p><b>g</b>rowth of <code>PA</code>.</p>
</dd>
<dt><code>HS</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>GHS</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>y</code></dt><dd><p>a numeric vector</p>
</dd>
<dt><code>Period</code></dt><dd><p>a <code><a href="base.html#topic+factor">factor</a></code> with levels <code>1:3</code>,
denoting the time period, 1 = 1979-1982, 2 = 1983-1988, 3 = 1989-1992.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Hubert, M. and Rousseeuw, P. J.  (1997).
Robust regression with both continuous and binary regressors,
<em>Journal of Statistical Planning and Inference</em> <b>57</b>, 153&ndash;163.
</p>


<h3>References</h3>

<p>Wagner J. (1994).
Regionale BeschÃ¤ftigungsdynamik und hÃ¶herwertige
Produktionsdienste: Ergebnisse fÃ¼r den Grossraum Hannover (1979-1992).
<em>Raumforschung und Raumordnung</em> <b>52</b>, 146&ndash;150.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(wagnerGrowth)
## maybe
str(wagnerGrowth)


require(lattice)
(xyplot(y ~ Period | Region, data = wagnerGrowth,
         main = "wagnerGrowth: 21 regions @ Hannover"))

(dotplot(y ~ reorder(Region,y,median), data = wagnerGrowth,
         main = "wagnerGrowth",
         xlab = "Region [ordered by  median(y | Region) ]"))
</code></pre>

<hr>
<h2 id='weights.lmrob'>Extract Robustness and Model Weights</h2><span id='topic+weights.lmrob'></span><span id='topic+weights.glmrob'></span>

<h3>Description</h3>

<p><code>weights()</code> extracts robustness weights or fitting
(or prior) weights from a <code>lmrob</code> or <code>glmrob</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lmrob'
weights(object, type = c("prior", "robustness"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="weights.lmrob_+3A_object">object</code></td>
<td>

<p>an object of class <code>"lmrob"</code> or <code>"glmrob"</code>, typically the
result of a call to <code><a href="#topic+lmrob">lmrob</a></code>, or <code><a href="#topic+glmrob">glmrob</a></code>,
respectively.</p>
</td></tr>
<tr><td><code id="weights.lmrob_+3A_type">type</code></td>
<td>
<p>the type of weights to be returned.  Either
<code>"prior"</code> (default), or  <code>"robustness"</code>.</p>
</td></tr>
<tr><td><code id="weights.lmrob_+3A_...">...</code></td>
<td>
<p>not used currently.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &ldquo;prior weights&rdquo; correspond to the weights specified using
the &ldquo;weights&rdquo; argument when calling <code>lmrob</code>. The
&ldquo;robustness weights&rdquo; are the weights assigned by the
M-estimator of regression, <code class="reqn">\psi(r_i/S) / (r_i/S)</code>. The robust
coefficient estimate then numericarlly corresponds to a weighted least
squares fit using the product of both types of weights as weights.
</p>


<h3>Value</h3>

<p>Weights extracted from the object <code>object</code>.
</p>


<h3>Author(s)</h3>

<p>Manuel Koller and Martin Maechler.</p>


<h3>See Also</h3>

<p><code><a href="#topic+lmrob">lmrob</a></code>, <code><a href="#topic+glmrob">glmrob</a></code> and <code><a href="stats.html#topic+weights">weights</a></code>
</p>

<hr>
<h2 id='wgt.himedian'>Weighted Hi-Median</h2><span id='topic+wgt.himedian'></span>

<h3>Description</h3>

<p>Compute the weighted Hi-Median of <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wgt.himedian(x, weights = rep(1, n))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wgt.himedian_+3A_x">x</code></td>
<td>
<p>numeric vector</p>
</td></tr>
<tr><td><code id="wgt.himedian_+3A_weights">weights</code></td>
<td>
<p>numeric vector of weights; of the same length as <code>x</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>this is rather a by-product of the code used in <code><a href="#topic+Sn">Sn</a></code> and
<code><a href="#topic+Qn">Qn</a></code>.  We currently plan to replace it with more general
weighted quantiles.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+median">median</a></code>; 
also <code><a href="Hmisc.html#topic+wtd.quantile">wtd.quantile</a></code> from package <a href="https://CRAN.R-project.org/package=Hmisc"><span class="pkg">Hmisc</span></a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(1:6, 20)
median(x) ## 4
stopifnot(all.equal(4, wgt.himedian(x)),
          all.equal(6, wgt.himedian(x, c(rep(1,6), 5))))
</code></pre>

<hr>
<h2 id='wood'>Modified Data on Wood Specific Gravity</h2><span id='topic+wood'></span>

<h3>Description</h3>

<p>The original data are from Draper and Smith (1966) and
were used to determine the influence of anatomical factors on wood
specific gravity, with five explanatory variables and an
intercept. These data were contaminated by replacing a few
observations with outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(wood, package="robustbase")</code></pre>


<h3>Format</h3>

<p>A data frame with 20 observations on the following 6 variables.
</p>

<dl>
<dt>x1, x2, x3, x4, x5</dt><dd><p>explanatory &ldquo;anatomical&rdquo; wood
variables.</p>
</dd>
<dt>y</dt><dd><p>wood specific gravity, the target variable.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Draper and Smith (1966, p.227)
</p>
<p>Peter J. Rousseeuw and Annick M. Leroy (1987)
<em>Robust Regression and Outlier Detection</em> Wiley, p.243, table 8.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(wood)
plot(wood)
summary( lm.wood &lt;-        lm(y ~ ., data = wood))
summary(rlm.wood &lt;- MASS::rlm(y ~ ., data = wood))
summary(lts.wood &lt;-    ltsReg(y ~ ., data = wood))

wood.x &lt;- as.matrix(wood)[,1:5]
c_wood &lt;- covMcd(wood.x)
c_wood
</code></pre>

<hr>
<h2 id='xtrData'>Extreme Data examples</h2><span id='topic+x30o50'></span>

<h3>Description</h3>

<p><code>x30o50</code>, called &lsquo;'XX'&rsquo; in the thesis, has been a running
case for which <code>mc()</code> had failed to converge.
A numeric vector of 50 values, 30 of which are very close to zero,
specifically, their absolute values are less than <code>1.5e-15</code>.
</p>
<p>The remaining 20 values (11 negative, 9 positive) have absolute values
between 0.0022 and 1.66.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(x30o50, package="robustbase")
</code></pre>


<h3>Format</h3>

<p>A summary is </p>
<pre>
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.
-1.66006  0.00000  0.00000 -0.04155  0.00000  1.29768
  </pre>
<p>notably the 1st to 3rd quartiles are all very close to zero.
</p>


<h3>Details</h3>

<p>a good robust method will treat the 60% &ldquo;almost zero&rdquo; values as
&ldquo;good&rdquo; data and all other as outliers.
</p>
<p>This is somewhat counter intuitive to typical human perception where the
30 almost-zero numbers would be considered as inliers and the remaining
20 as &ldquo;good&rdquo; data.
</p>
<p>The original <code>mc()</code> algorithm and also the amendments up to 2022
(<span class="pkg">robustbase</span> versions before 0.95) would fail to converge unless (in
newer versions) <code>eps1</code> was increased, e.g., only by a factor of 10,
to <code>eps1 = 1e-13</code>.
</p>


<h3>References</h3>

<p>Lukas Graz (2021); unpublished BSc thesis, see <code><a href="#topic+mc">mc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(x30o50)
## have 4  duplicated values :
table(dX &lt;- duplicated(x30o50))
     x30o50[dX] # 0 2.77e-17 4.16e-17 2.08e-16
sort(x30o50[dX]) * 2^56 #  0  2  3 15
## and they are  c(0,2,3,15)*2^-56

table(sml &lt;- abs(x30o50) &lt; 1e-11)# 20 30
summary(x30o50[ sml]) # -1.082e-15 ... 1.499e-15 ; mean = 9.2e-19 ~~ 0
summary(x30o50[!sml])
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
## -1.6601 -0.4689 -0.0550 -0.1039  0.3986  1.2977

op &lt;- par(mfrow=c(3,1), mgp=c(1.5, .6, 0), mar = .3+c(2,3:1))
(Fn. &lt;- ecdf(x30o50)) # &lt;- only 46 knots (as have 4 duplications)
plot(Fn.) ## and zoom in (*drastically*) to around x=0 :
for(f in c(1e-13, 1.5e-15)) {
  plot(Fn., xval=f*seq(-1,1, length.out = 1001), ylim=c(0,1), main="[zoomed in]")
  if(f == 1e-13) rect(-1e-15,0, +1e-15, 1, col="thistle", border=1)
  plot(Fn., add=TRUE)
}
par(op)

mcOld &lt;- function(x, ..., doScale=TRUE)  mc(x, doScale=doScale, c.huberize=Inf, ...)
try( mcOld(x30o50) ) # Error: .. not 'converged' in 100 iteration
mcOld(x30o50, eps1 = 1e-12) # -0.152
(mcX &lt;- mc(x30o50)) # -7.10849e-13
stopifnot(exprs = {
    all.equal(-7.10848988e-13, mcX, tol = 1e-9)
    all.equal(mcX, mc(1e30*x30o50), tol = 4e-4) # not so close
})
table(sml &lt;- abs(x30o50) &lt; 1e-8)# 20 30
range(x30o50[sml])
x0o50 &lt;- x30o50; x0o50[sml] &lt;- 0
(mcX0 &lt;- mc(x0o50))
stopifnot(exprs = {
    all.equal(-0.378445401788, mcX0, tol=1e-12)
    all.equal(-0.099275805349, mc(x30o50[!sml]) -&gt; mcL, tol=2e-11)
    all.equal(mcL, mcOld(x30o50[!sml]))
})
## -- some instability also wrt c.huberize:
mcHubc &lt;- function(dat, ...)
    function(cc) vapply(cc, function(c) mc(dat, c.huberize = c, ...), -1.)
mcH50 &lt;- mcHubc(x30o50)
head(cHs &lt;- c(sort(outer(c(1, 2, 5), 10^(2:15))), Inf), 9)
mcXc &lt;- mcH50(cHs)
plot(  mcXc  ~ cHs, type="b", log="x" , xlab=quote(c[huberize]))
plot((-mcXc) ~ cHs, type="b", log="xy", xlab=quote(c[huberize]))
## but for "regular" outlier skew data, there's no such dependency:
mcXcu &lt;- mcHubc(cushny)(cHs)
stopifnot( abs(mcXcu - mcXcu[1]) &lt; 1e-15)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
