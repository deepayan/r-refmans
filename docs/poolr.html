<!DOCTYPE html><html><head><title>Help for package poolr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {poolr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#poolr-package'><p>Methods for Pooling P-Values from (Dependent) Tests</p></a></li>
<li><a href='#binomtest'><p>Binomial Test</p></a></li>
<li><a href='#bonferroni'><p>Bonferroni Method</p></a></li>
<li><a href='#empirical'><p>Simulate Empirically-Derived Null Distributions</p></a></li>
<li><a href='#fisher'><p>Fisher's Method</p></a></li>
<li><a href='#grid2ip'><p>Results from testing the association between depressive symptoms and 23 SNPs in the GRID2IP gene</p></a></li>
<li><a href='#invchisq'><p>Inverse Chi-Square Method</p></a></li>
<li><a href='#meff'><p>Estimate the Effective Number of Tests</p></a></li>
<li><a href='#mvnconv'><p>Convert Correlations Among Multivariate Normal Test Statistics to Covariances for Various Target Statistics</p></a></li>
<li><a href='#mvnlookup'><p>Lookup Table for the mvnconv() Function</p></a></li>
<li><a href='#print.poolr'><p>Print Method for 'poolr' Objects</p></a></li>
<li><a href='#stouffer'><p>Stouffer's Method</p></a></li>
<li><a href='#tippett'><p>Tippett's Method</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.1-1</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-01-26</td>
</tr>
<tr>
<td>Title:</td>
<td>Methods for Pooling P-Values from (Dependent) Tests</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, stats, utils, mathjaxr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>mathjaxr</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for pooling/combining the results (i.e., p-values) from (dependent) hypothesis tests. Included are Fisher's method, Stouffer's method, the inverse chi-square method, the Bonferroni method, Tippett's method, and the binomial test. Each method can be adjusted based on an estimate of the effective number of tests or using empirically derived null distribution using pseudo replicates. For Fisher's, Stouffer's, and the inverse chi-square method, direct generalizations based on multivariate theory are also available (leading to Brown's method, Strube's method, and the generalized inverse chi-square method). An introduction can be found in Cinar and Viechtbauer (2022) &lt;<a href="https://doi.org/10.18637%2Fjss.v101.i01">doi:10.18637/jss.v101.i01</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>TRUE</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-01-26 16:02:16 UTC; ozan</td>
</tr>
<tr>
<td>Author:</td>
<td>Ozan Cinar <a href="https://orcid.org/0000-0003-0329-1977"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre],
  Wolfgang Viechtbauer
    <a href="https://orcid.org/0000-0003-3463-4063"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ozan Cinar &lt;ozancinar86@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-01-26 16:42:42 UTC</td>
</tr>
</table>
<hr>
<h2 id='poolr-package'>Methods for Pooling P-Values from (Dependent) Tests</h2><span id='topic+poolr-package'></span><span id='topic+poolr'></span>

<h3>Description</h3>

<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script><p> The <span class="pkg">poolr</span> package contains functions for pooling/combining the results (i.e., \(p\)-values) from (dependent) hypothesis tests. Included are Fisher's method, Stouffer's method, the inverse chi-square method, the Bonferroni method, Tippett's method, and the binomial test. Each method can be adjusted based on an estimate of the effective number of tests or using empirically-derived null distribution using pseudo replicates. For Fisher's, Stouffer's, and the inverse chi-square method, direct generalizations based on multivariate theory are also available (leading to Brown's method, Strube's method, and the generalized inverse chi-square method). For more details, see:
</p>

<ul>
<li> <p><code><a href="#topic+fisher">fisher</a></code>: for Fisher's method (and Brown's method)
</p>
</li>
<li> <p><code><a href="#topic+stouffer">stouffer</a></code>: for Stouffer's method (and Strube's method)
</p>
</li>
<li> <p><code><a href="#topic+invchisq">invchisq</a></code>: for the inverse chi-square method
</p>
</li>
<li> <p><code><a href="#topic+bonferroni">bonferroni</a></code>: for the Bonferroni method
</p>
</li>
<li> <p><code><a href="#topic+tippett">tippett</a></code>: for Tippett's method
</p>
</li>
<li> <p><code><a href="#topic+binomtest">binomtest</a></code>: for the binomial test
</p>
</li></ul>

<p>Note that you can also read the documentation of the package online at <a href="https://ozancinar.github.io/poolr/">https://ozancinar.github.io/poolr/</a> (where it is nicely formatted and the output from all examples is provided).
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Brown, M. B. (1975). 400: A method for combining non-independent, one-sided tests of significance. <em>Biometrics, 31</em>(4), 987&ndash;992.
</p>
<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>
<p>Fisher, R. A. (1932). <em>Statistical Methods for Research Workers</em> (4th ed.). Edinburgh: Oliver and Boyd.
</p>
<p>Lancaster, H. O. (1961). The combination of probabilities: An application of orthonormal functions. <em>Australian Journal of Statistics, 3</em>(1), 20&ndash;33.
</p>
<p>Strube, M. J. (1985). Combining and comparing significance levels from nonindependent hypothesis tests. <em>Psychological Bulletin, 97</em>(2), 334&ndash;341.
</p>
<p>Tippett, L. H. C. (1931). <em>Methods of Statistics</em>. London: Williams Norgate.
</p>
<p>Wilkinson, B. (1951). A statistical consideration in psychological research. <em>Psychological Bulletin, 48</em>(2), 156&ndash;158.
</p>

<hr>
<h2 id='binomtest'>Binomial Test</h2><span id='topic+binomtest'></span>

<h3>Description</h3>

<p>Function to carry out the binomial test.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>binomtest(p, adjust = "none", R, m,
         size = 10000, threshold, side = 2, batchsize, nearpd = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="binomtest_+3A_p">p</code></td>
<td>
<p>vector of length \(k\) with the (one- or two-sided) p-values to be combined.</p>
</td></tr>
<tr><td><code id="binomtest_+3A_adjust">adjust</code></td>
<td>
<p>character string to specify an adjustment method to account for dependence. The default is <code>"none"</code>, in which case no adjustment is applied. Methods <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code>, or <code>"galwey"</code> are adjustments based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code>). Adjustment method <code>"empirical"</code> uses an empirically-derived null distribution using pseudo replicates. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="binomtest_+3A_r">R</code></td>
<td>
<p>a \(k \times k\) symmetric matrix that reflects the dependence structure among the tests. Must be specified if <code>adjust</code> is set to something other than <code>"none"</code>. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="binomtest_+3A_m">m</code></td>
<td>
<p>optional scalar (between 1 and \(k\)) to manually specify the effective number of tests (instead of estimating it via one of the methods described above).</p>
</td></tr>
<tr><td><code id="binomtest_+3A_size">size</code></td>
<td>
<p>size of the empirically-derived null distribution. Can also be a numeric vector of sizes, in which case a stepwise algorithm is used. This (and the following arguments) are only relevant when <code>adjust = "empirical"</code>.</p>
</td></tr>
<tr><td><code id="binomtest_+3A_threshold">threshold</code></td>
<td>
<p>numeric vector to specify the significance thresholds for the stepwise algorithm (only relevant when <code>size</code> is a vector).</p>
</td></tr>
<tr><td><code id="binomtest_+3A_side">side</code></td>
<td>
<p>scalar to specify the sidedness of the \(p\)-values that are used to simulate the null distribution (2, by default, for two-sided tests; 1 for one-sided tests).</p>
</td></tr>
<tr><td><code id="binomtest_+3A_batchsize">batchsize</code></td>
<td>
<p>optional scalar to specify the batch size for generating the null distribution. When unspecified (the default), this is done in a single batch.</p>
</td></tr>
<tr><td><code id="binomtest_+3A_nearpd">nearpd</code></td>
<td>
<p>logical indicating if a negative definite <code>R</code> matrix should be turned into the nearest positive definite matrix (only relevant when <code>adjust = "empirical"</code>).</p>
</td></tr>
<tr><td><code id="binomtest_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Binomial Test</b>
</p>
<p>By default (i.e., when <code>adjust = "none"</code>), the function applies the binomial test to the \(p\)-values (Wilkinson, 1951). Letting \(p_1, p_2, \ldots, p_k\) denote the individual (one- or two-sided) \(p\)-values of the \(k\) hypothesis tests to be combined, the combined \(p\)-value is then computed with \[p_c = \sum_{x = r}^k {k \choose x} \alpha^x (1 - \alpha)^{k - x}\] where \[r = \sum_{i = 1}^k I(p_i \le \alpha)\] denotes the number of hypothesis tests that are significant at \(\alpha\).
</p>
<p>The binomial test assumes that the \(p\)-values to be combined are independent. If this is not the case, the method can either be conservative (not reject often enough) or liberal (reject too often), depending on the dependence structure among the tests. In this case, one can adjust the method to account for such dependence (to bring the Type I error rate closer to some desired nominal significance level).
</p>
<p><b>Adjustment Based on the Effective Number of Tests</b>
</p>
<p>When <code>adjust</code> is set to <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>, the binomial test is adjusted based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code> for details on these methods for estimating the effective number of tests). In this case, argument <code>R</code> needs to be set to a matrix that reflects the dependence structure among the tests.
</p>
<p>There is no general solution for constructing such a matrix, as this depends on the type of test that generated the \(p\)-values and the sidedness of these tests. If the \(p\)-values are obtained from tests whose test statistics can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics, then the <code><a href="#topic+mvnconv">mvnconv</a></code> function can be used to convert this correlation matrix into the correlations among the (one- or two-sided) \(p\)-values, which can then be passed to the <code>R</code> argument. See &lsquo;Examples&rsquo;.
</p>
<p>Once the effective number of tests, \(m\), is estimated based on <code>R</code> using one of the four methods described above, the combined \(p\)-value is then computed with \[p_c = \sum_{x = \tilde{r}}^m {m \choose x} \alpha^x (1 - \alpha)^{m - x}\] where \[\tilde{r} = \lfloor r \times m / k \rfloor\] and \(\lfloor \cdot \rfloor\) is the floor function.
</p>
<p>Alternatively, one can also directly specify the effective number of tests via the <code>m</code> argument (e.g., if some other method not implemented in the <span class="pkg">poolr</span> package is used to estimate the effective number of tests). Argument <code>R</code> is then irrelevant and doesn't need to be specified.
</p>
<p><b>Adjustment Based on an Empirically-Derived Null Distribution</b>
</p>
<p>When <code>adjust = "empirical"</code>, the combined \(p\)-value is computed based on an empirically-derived null distribution using pseudo replicates (using the <code><a href="#topic+empirical">empirical</a></code> function). This is appropriate if the test statistics that generated the \(p\)-values to be combined can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics (which is specified via the <code>R</code> argument). In this case, test statistics are repeatedly simulated from a multivariate normal distribution under the joint null hypothesis, converted into one- or two-sided \(p\)-values (depending on the <code>side</code> argument), and the binomial test is applied. Repeating this process <code>size</code> times yields a null distribution based on which the combined \(p\)-value can be computed, or more precisely, estimated, since repeated applications of this method will yield (slightly) different results. To obtain a stable estimate of the combined \(p\)-value, <code>size</code> should be set to a large value (the default is <code>10000</code>, but this can be increased for a more precise estimate). If we consider the combined \(p\)-value an estimate of the &lsquo;true&rsquo; combined \(p\)-value that would be obtained for a null distribution of infinite size, we can also construct a 95% (pseudo) confidence interval based on a binomial distribution.
</p>
<p>If <code>batchsize</code> is unspecified, the null distribution is simulated in a single batch, which requires temporarily storing a matrix with dimensions <code>[size,k]</code>. When <code>size*k</code> is large, allocating the memory for this matrix might not be possible. Instead, one can specify a <code>batchsize</code> value, in which case a matrix with dimensions <code>[batchsize,k]</code> is repeatedly simulated until the desired size of the null distribution has been obtained.
</p>
<p>One can also specify a vector for the <code>size</code> argument, in which case one must also specify a corresponding vector for the <code>threshold</code> argument. In that case, a stepwise algorithm is used that proceeds as follows. For <code>j = 1, ..., length(size)</code>,
</p>

<ol>
<li><p> estimate the combined \(p\)-value based on <code>size[j]</code>
</p>
</li>
<li><p> if the combined \(p\)-value is \(\ge\) than <code>threshold[j]</code>, stop (and report the combined \(p\)-value), otherwise go back to 1.
</p>
</li></ol>

<p>By setting <code>size</code> to increasing values (e.g., <code>size = c(1000, 10000, 100000)</code>) and <code>threshold</code> to decreasing values (e.g., <code>threshold = c(.10, .01, 0)</code>), one can quickly obtain a fairly accurate estimate of the combined \(p\)-value if it is far from significant (e.g., \(\ge\) .10), but hone in on a more accurate estimate for a combined \(p\)-value that is closer to 0. Note that the last value of <code>threshold</code> should be 0 (and is forced to be inside of the function), so that the algorithm is guaranteed to terminate (hence, one can also leave out the last value of <code>threshold</code>, so <code>threshold = c(.10, .01)</code> would also work in the example above). One can also specify a single <code>threshold</code> (which is replicated as often as necessary depending on the length of <code>size</code>).
</p>


<h3>Value</h3>

<p>An object of class <code>"poolr"</code>. The object is a list containing the following components:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>combined \(p\)-value.</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>confidence interval for the combined \(p\)-value (only when <code>adjust = "empirical"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of \(p\)-values that were combined.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>estimate of the effective number of tests (only when <code>adjust</code> is one of <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>adjust</code></td>
<td>
<p>chosen adjustment method.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>value of the (adjusted) test statistic.</p>
</td></tr>
<tr><td><code>fun</code></td>
<td>
<p>name of calling function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The method underlying <code>adjust = "empirical"</code> assumes that the test statistics that generated the \(p\)-values to be combined follow a multivariate normal distribution. Hence, the matrix specified via <code>R</code> must be positive definite. If it is not and <code>nearpd = TRUE</code>, it will be turned into one (based on Higham, 2002, and a slightly simplified version of <code><a href="Matrix.html#topic+nearPD">nearPD</a></code> from the <span class="pkg">Matrix</span> package).
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>
<p>Higham, N. J. (2002). Computing the nearest correlation matrix: A problem from finance. <em>IMA Journal of Numerical Analysis, 22</em>(3), 329&ndash;343.
</p>
<p>Wilkinson, B. (1951). A statistical consideration in psychological research. <em>Psychological Bulletin, 48</em>(2), 156&ndash;158.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># copy p-values and LD correlation matrix into p and r
# (see help(grid2ip) for details on these data)
p &lt;- grid2ip.p
r &lt;- grid2ip.ld

# apply the binomial test
binomtest(p)

# use mvnconv() to convert the LD correlation matrix into a matrix with the
# correlations among the (two-sided) p-values assuming that the test
# statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "p", cov2cor = TRUE)[1:5,1:5] # show only rows/columns 1-5

# adjustment based on estimates of the effective number of tests
binomtest(p, adjust = "nyholt", R = mvnconv(r, target = "p", cov2cor = TRUE))
binomtest(p, adjust = "liji",   R = mvnconv(r, target = "p", cov2cor = TRUE))
binomtest(p, adjust = "gao",    R = mvnconv(r, target = "p", cov2cor = TRUE))
binomtest(p, adjust = "galwey", R = mvnconv(r, target = "p", cov2cor = TRUE))

# setting argument 'm' manually
binomtest(p, m = 12)

# adjustment based on an empirically-derived null distribution (setting the
# seed for reproducibility)
set.seed(1234)
binomtest(p, adjust = "empirical", R = r)

# generate the empirical distribution in batches of size 100
binomtest(p, adjust = "empirical", R = r, batchsize = 100)

# using the stepwise algorithm
binomtest(p, adjust = "empirical", R = r, size = c(1000, 10000, 100000), threshold = c(.10, .01))
</code></pre>

<hr>
<h2 id='bonferroni'>Bonferroni Method</h2><span id='topic+bonferroni'></span>

<h3>Description</h3>

<p>Function to carry out the Bonferroni method.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>bonferroni(p, adjust = "none", R, m,
           size = 10000, threshold, side = 2, batchsize, nearpd = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bonferroni_+3A_p">p</code></td>
<td>
<p>vector of length \(k\) with the (one- or two-sided) p-values to be combined.</p>
</td></tr>
<tr><td><code id="bonferroni_+3A_adjust">adjust</code></td>
<td>
<p>character string to specify an adjustment method to account for dependence. The default is <code>"none"</code>, in which case no adjustment is applied. Methods <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code>, or <code>"galwey"</code> are adjustments based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code>). Adjustment method <code>"empirical"</code> uses an empirically-derived null distribution using pseudo replicates. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="bonferroni_+3A_r">R</code></td>
<td>
<p>a \(k \times k\) symmetric matrix that reflects the dependence structure among the tests. Must be specified if <code>adjust</code> is set to something other than <code>"none"</code>. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="bonferroni_+3A_m">m</code></td>
<td>
<p>optional scalar (between 1 and \(k\)) to manually specify the effective number of tests (instead of estimating it via one of the methods described above).</p>
</td></tr>
<tr><td><code id="bonferroni_+3A_size">size</code></td>
<td>
<p>size of the empirically-derived null distribution. Can also be a numeric vector of sizes, in which case a stepwise algorithm is used. This (and the following arguments) are only relevant when <code>adjust = "empirical"</code>.</p>
</td></tr>
<tr><td><code id="bonferroni_+3A_threshold">threshold</code></td>
<td>
<p>numeric vector to specify the significance thresholds for the stepwise algorithm (only relevant when <code>size</code> is a vector).</p>
</td></tr>
<tr><td><code id="bonferroni_+3A_side">side</code></td>
<td>
<p>scalar to specify the sidedness of the \(p\)-values that are used to simulate the null distribution (2, by default, for two-sided tests; 1 for one-sided tests).</p>
</td></tr>
<tr><td><code id="bonferroni_+3A_batchsize">batchsize</code></td>
<td>
<p>optional scalar to specify the batch size for generating the null distribution. When unspecified (the default), this is done in a single batch.</p>
</td></tr>
<tr><td><code id="bonferroni_+3A_nearpd">nearpd</code></td>
<td>
<p>logical indicating if a negative definite <code>R</code> matrix should be turned into the nearest positive definite matrix (only relevant when <code>adjust = "empirical"</code>).</p>
</td></tr>
<tr><td><code id="bonferroni_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Bonferroni Method</b>
</p>
<p>By default (i.e., when <code>adjust = "none"</code>), the function applies the Bonferroni method to the \(p\)-values. Letting \(p_1, p_2, \ldots, p_k\) denote the individual (one- or two-sided) \(p\)-values of the \(k\) hypothesis tests to be combined, the combined \(p\)-value is then computed with \[p_c = \min(1, \min(p_1, p_2, \ldots, p_k) \times k).\]
</p>
<p>The Bonferroni method does not assume that the \(p\)-values to be combined are independent. However, if the \(p\)-values are not independent, the method can become quite conservative (not reject often enough), depending on the dependence structure among the tests. In this case, one can adjust the method to account for such dependence (to bring the Type I error rate closer to some desired nominal significance level).
</p>
<p><b>Adjustment Based on the Effective Number of Tests</b>
</p>
<p>When <code>adjust</code> is set to <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>, the Bonferroni method is adjusted based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code> for details on these methods for estimating the effective number of tests). In this case, argument <code>R</code> needs to be set to a matrix that reflects the dependence structure among the tests.
</p>
<p>There is no general solution for constructing such a matrix, as this depends on the type of test that generated the \(p\)-values and the sidedness of these tests. If the \(p\)-values are obtained from tests whose test statistics can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics, then the <code><a href="#topic+mvnconv">mvnconv</a></code> function can be used to convert this correlation matrix into the correlations among the (one- or two-sided) \(p\)-values, which can then be passed to the <code>R</code> argument. See &lsquo;Examples&rsquo;.
</p>
<p>Once the effective number of tests, \(m\), is estimated based on <code>R</code> using one of the four methods described above, the combined \(p\)-value is then computed with \[p_c = \min(1, \min(p_1, p_2, \ldots, p_k) \times m).\]
</p>
<p>Alternatively, one can also directly specify the effective number of tests via the <code>m</code> argument (e.g., if some other method not implemented in the <span class="pkg">poolr</span> package is used to estimate the effective number of tests). Argument <code>R</code> is then irrelevant and doesn't need to be specified.
</p>
<p><b>Adjustment Based on an Empirically-Derived Null Distribution</b>
</p>
<p>When <code>adjust = "empirical"</code>, the combined \(p\)-value is computed based on an empirically-derived null distribution using pseudo replicates (using the <code><a href="#topic+empirical">empirical</a></code> function). This is appropriate if the test statistics that generated the \(p\)-values to be combined can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics (which is specified via the <code>R</code> argument). In this case, test statistics are repeatedly simulated from a multivariate normal distribution under the joint null hypothesis, converted into one- or two-sided \(p\)-values (depending on the <code>side</code> argument), and the Bonferroni method is applied. Repeating this process <code>size</code> times yields a null distribution based on which the combined \(p\)-value can be computed, or more precisely, estimated, since repeated applications of this method will yield (slightly) different results. To obtain a stable estimate of the combined \(p\)-value, <code>size</code> should be set to a large value (the default is <code>10000</code>, but this can be increased for a more precise estimate). If we consider the combined \(p\)-value an estimate of the &lsquo;true&rsquo; combined \(p\)-value that would be obtained for a null distribution of infinite size, we can also construct a 95% (pseudo) confidence interval based on a binomial distribution.
</p>
<p>If <code>batchsize</code> is unspecified, the null distribution is simulated in a single batch, which requires temporarily storing a matrix with dimensions <code>[size,k]</code>. When <code>size*k</code> is large, allocating the memory for this matrix might not be possible. Instead, one can specify a <code>batchsize</code> value, in which case a matrix with dimensions <code>[batchsize,k]</code> is repeatedly simulated until the desired size of the null distribution has been obtained.
</p>
<p>One can also specify a vector for the <code>size</code> argument, in which case one must also specify a corresponding vector for the <code>threshold</code> argument. In that case, a stepwise algorithm is used that proceeds as follows. For <code>j = 1, ..., length(size)</code>,
</p>

<ol>
<li><p> estimate the combined \(p\)-value based on <code>size[j]</code>
</p>
</li>
<li><p> if the combined \(p\)-value is \(\ge\) than <code>threshold[j]</code>, stop (and report the combined \(p\)-value), otherwise go back to 1.
</p>
</li></ol>

<p>By setting <code>size</code> to increasing values (e.g., <code>size = c(1000, 10000, 100000)</code>) and <code>threshold</code> to decreasing values (e.g., <code>threshold = c(.10, .01, 0)</code>), one can quickly obtain a fairly accurate estimate of the combined \(p\)-value if it is far from significant (e.g., \(\ge\) .10), but hone in on a more accurate estimate for a combined \(p\)-value that is closer to 0. Note that the last value of <code>threshold</code> should be 0 (and is forced to be inside of the function), so that the algorithm is guaranteed to terminate (hence, one can also leave out the last value of <code>threshold</code>, so <code>threshold = c(.10, .01)</code> would also work in the example above). One can also specify a single <code>threshold</code> (which is replicated as often as necessary depending on the length of <code>size</code>).
</p>


<h3>Value</h3>

<p>An object of class <code>"poolr"</code>. The object is a list containing the following components:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>combined \(p\)-value.</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>confidence interval for the combined \(p\)-value (only when <code>adjust = "empirical"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of \(p\)-values that were combined.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>estimate of the effective number of tests (only when <code>adjust</code> is one of <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>adjust</code></td>
<td>
<p>chosen adjustment method.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>value of the (adjusted) test statistic.</p>
</td></tr>
<tr><td><code>fun</code></td>
<td>
<p>name of calling function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The method underlying <code>adjust = "empirical"</code> assumes that the test statistics that generated the \(p\)-values to be combined follow a multivariate normal distribution. Hence, the matrix specified via <code>R</code> must be positive definite. If it is not and <code>nearpd = TRUE</code>, it will be turned into one (based on Higham, 2002, and a slightly simplified version of <code><a href="Matrix.html#topic+nearPD">nearPD</a></code> from the <span class="pkg">Matrix</span> package).
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Bland, J. M., &amp; Altman, D. G. (1995). Multiple significance tests: The Bonferroni method. <em>British Medical Journal, 310</em>(6973), 170.
</p>
<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>
<p>Higham, N. J. (2002). Computing the nearest correlation matrix: A problem from finance. <em>IMA Journal of Numerical Analysis, 22</em>(3), 329&ndash;343.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># copy p-values and LD correlation matrix into p and r
# (see help(grid2ip) for details on these data)
p &lt;- grid2ip.p
r &lt;- grid2ip.ld

# apply the Bonferroni method
bonferroni(p)

# use mvnconv() to convert the LD correlation matrix into a matrix with the
# correlations among the (two-sided) p-values assuming that the test
# statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "p", cov2cor = TRUE)[1:5,1:5] # show only rows/columns 1-5

# adjustment based on estimates of the effective number of tests
bonferroni(p, adjust = "nyholt", R = mvnconv(r, target = "p", cov2cor = TRUE))
bonferroni(p, adjust = "liji",   R = mvnconv(r, target = "p", cov2cor = TRUE))
bonferroni(p, adjust = "gao",    R = mvnconv(r, target = "p", cov2cor = TRUE))
bonferroni(p, adjust = "galwey", R = mvnconv(r, target = "p", cov2cor = TRUE))

# setting argument 'm' manually
bonferroni(p, m = 12)

# adjustment based on an empirically-derived null distribution (setting the
# seed for reproducibility)
set.seed(1234)
bonferroni(p, adjust = "empirical", R = r)

# generate the empirical distribution in batches of size 100
bonferroni(p, adjust = "empirical", R = r, batchsize = 100)

# using the stepwise algorithm
bonferroni(p, adjust = "empirical", R = r, size = c(1000, 10000, 100000), threshold = c(.10, .01))
</code></pre>

<hr>
<h2 id='empirical'>Simulate Empirically-Derived Null Distributions</h2><span id='topic+empirical'></span>

<h3>Description</h3>

<p>Function to simulate empirically-derived null distributions of various methods for combining \(p\)-values using pseudo replicates.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>empirical(R, method, side = 2, size = 10000, batchsize, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="empirical_+3A_r">R</code></td>
<td>
<p>a \(k \times k\) symmetric matrix that contains the correlations among the test statistics.</p>
</td></tr>
<tr><td><code id="empirical_+3A_method">method</code></td>
<td>
<p>character string to specify for which method to simulate the null distribution (either <code>"fisher"</code>, <code>"stouffer"</code>, <code>"invchisq"</code>, <code>"binomtest"</code>, <code>"bonferroni"</code>, or <code>"tippett"</code>).</p>
</td></tr>
<tr><td><code id="empirical_+3A_side">side</code></td>
<td>
<p>scalar to specify the sidedness of the \(p\)-values that are used to simulate the null distribution (2, by default, for two-sided tests; 1 for one-sided tests).</p>
</td></tr>
<tr><td><code id="empirical_+3A_size">size</code></td>
<td>
<p>size of the empirically-derived null distribution that should be generated.</p>
</td></tr>
<tr><td><code id="empirical_+3A_batchsize">batchsize</code></td>
<td>
<p>optional scalar to specify the batch size for generating the null distribution. When unspecified (the default), this is done in a single batch.</p>
</td></tr>
<tr><td><code id="empirical_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function simulates the null distribution of a particular method for combining \(p\)-values when the test statistics that generate the \(p\)-values to be combined can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics (which is specified via the <code>R</code> argument). In this case, test statistics are repeatedly simulated from a multivariate normal distribution under the joint null hypothesis, converted into one- or two-sided \(p\)-values (depending on the <code>side</code> argument), and the chosen method is applied. Repeating this process <code>size</code> times yields the null distribution.
</p>
<p>If <code>batchsize</code> is unspecified, the null distribution is simulated in a single batch, which requires temporarily storing a matrix with dimensions <code>[size,k]</code>. When <code>size*k</code> is large, allocating the memory for this matrix might not be possible. Instead, one can specify a <code>batchsize</code> value, in which case a matrix with dimensions <code>[batchsize,k]</code> is repeatedly simulated until the desired size of the null distribution has been obtained.
</p>


<h3>Value</h3>

<p>A vector of combined \(p\)-values as simulated under the joint null hypothesis for a given method.
</p>


<h3>Note</h3>

<p>The <code>R</code> matrix must be positive definite. If it is not, the function uses <code><a href="Matrix.html#topic+nearPD">nearPD</a></code> to find the nearest positive definite matrix (Higham, 2002) before simulating the null distribution.
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>
<p>Higham, N. J. (2002). Computing the nearest correlation matrix: A problem from finance. <em>IMA Journal of Numerical Analysis, 22</em>(3), 329&ndash;343.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># create an example correlation matrix with constant positive correlations
R &lt;- matrix(0.6, nrow = 10, ncol = 10)
diag(R) &lt;- 1

# generate null distribution for Fisher's method (setting the seed for reproducibility)
set.seed(1234)
psim &lt;- empirical(R, method = "fisher")

# Fisher's method is liberal in this scenario (i.e., its actual Type I error
# rate is around .14 instead of the nominal significance level of .05)
mean(psim &lt;= .05)

# estimate the actual Type I error rate of the other methods in this scenario
psim &lt;- empirical(R, method = "stouffer")
mean(psim &lt;= .05)
psim &lt;- empirical(R, method = "invchisq")
mean(psim &lt;= .05)
psim &lt;- empirical(R, method = "binomtest")
mean(psim &lt;= .05)
psim &lt;- empirical(R, method = "bonferroni")
mean(psim &lt;= .05)
psim &lt;- empirical(R, method = "tippett")
mean(psim &lt;= .05)

# Stouffer's and the inverse chi-square method also have clearly inflated
# Type I error rates and the binomial test just barely. As expected, the
# Bonferroni method is overly conservative and so is Tippett's method.
</code></pre>

<hr>
<h2 id='fisher'>Fisher's Method</h2><span id='topic+fisher'></span>

<h3>Description</h3>

<p>Function to carry out Fisher's method.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>fisher(p, adjust = "none", R, m,
       size = 10000, threshold, side = 2, batchsize, nearpd = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fisher_+3A_p">p</code></td>
<td>
<p>vector of length \(k\) with the (one- or two-sided) p-values to be combined.</p>
</td></tr>
<tr><td><code id="fisher_+3A_adjust">adjust</code></td>
<td>
<p>character string to specify an adjustment method to account for dependence. The default is <code>"none"</code>, in which case no adjustment is applied. Methods <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code>, or <code>"galwey"</code> are adjustments based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code>). Adjustment method <code>"empirical"</code> uses an empirically-derived null distribution using pseudo replicates. Finally, method <code>"generalized"</code> uses a generalization of Fisher's method based on multivariate theory. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="fisher_+3A_r">R</code></td>
<td>
<p>a \(k \times k\) symmetric matrix that reflects the dependence structure among the tests. Must be specified if <code>adjust</code> is set to something other than <code>"none"</code>. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="fisher_+3A_m">m</code></td>
<td>
<p>optional scalar (between 1 and \(k\)) to manually specify the effective number of tests (instead of estimating it via one of the methods described above).</p>
</td></tr>
<tr><td><code id="fisher_+3A_size">size</code></td>
<td>
<p>size of the empirically-derived null distribution. Can also be a numeric vector of sizes, in which case a stepwise algorithm is used. This (and the following arguments) are only relevant when <code>adjust = "empirical"</code>.</p>
</td></tr>
<tr><td><code id="fisher_+3A_threshold">threshold</code></td>
<td>
<p>numeric vector to specify the significance thresholds for the stepwise algorithm (only relevant when <code>size</code> is a vector).</p>
</td></tr>
<tr><td><code id="fisher_+3A_side">side</code></td>
<td>
<p>scalar to specify the sidedness of the \(p\)-values that are used to simulate the null distribution (2, by default, for two-sided tests; 1 for one-sided tests).</p>
</td></tr>
<tr><td><code id="fisher_+3A_batchsize">batchsize</code></td>
<td>
<p>optional scalar to specify the batch size for generating the null distribution. When unspecified (the default), this is done in a single batch.</p>
</td></tr>
<tr><td><code id="fisher_+3A_nearpd">nearpd</code></td>
<td>
<p>logical indicating if a negative definite <code>R</code> matrix should be turned into the nearest positive definite matrix (only relevant when <code>adjust = "empirical"</code> or <code>adjust = "generalized"</code>).</p>
</td></tr>
<tr><td><code id="fisher_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Fisher's Method</b>
</p>
<p>By default (i.e., when <code>adjust = "none"</code>), the function applies Fisher's method to the \(p\)-values (Fisher, 1932). Letting \(p_1, p_2, \ldots, p_k\) denote the individual (one- or two-sided) \(p\)-values of the \(k\) hypothesis tests to be combined, the test statistic is then computed with \[X^2 = -2 \sum_{i = 1}^k \ln(p_i).\] Under the joint null hypothesis, the test statistic follows a chi-square distribution with \(2k\) degrees of freedom which is used to compute the combined \(p\)-value.
</p>
<p>Fisher's method assumes that the \(p\)-values to be combined are independent. If this is not the case, the method can either be conservative (not reject often enough) or liberal (reject too often), depending on the dependence structure among the tests. In this case, one can adjust the method to account for such dependence (to bring the Type I error rate closer to some desired nominal significance level).
</p>
<p><b>Adjustment Based on the Effective Number of Tests</b>
</p>
<p>When <code>adjust</code> is set to <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>, Fisher's method is adjusted based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code> for details on these methods for estimating the effective number of tests). In this case, argument <code>R</code> needs to be set to a matrix that reflects the dependence structure among the tests.
</p>
<p>There is no general solution for constructing such a matrix, as this depends on the type of test that generated the \(p\)-values and the sidedness of these tests. If the \(p\)-values are obtained from tests whose test statistics can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics, then the <code><a href="#topic+mvnconv">mvnconv</a></code> function can be used to convert this correlation matrix into the correlations among the (one- or two-sided) \(p\)-values, which can then be passed to the <code>R</code> argument. See &lsquo;Examples&rsquo;.
</p>
<p>Once the effective number of tests, \(m\), is estimated based on <code>R</code> using one of the four methods described above, the test statistic of Fisher's method can be modified with \[\tilde{X}^2 = \frac{m}{k} \times X^2\] which is then assumed to follow a chi-square distribution with \(2m\) degrees of freedom.
</p>
<p>Alternatively, one can also directly specify the effective number of tests via the <code>m</code> argument (e.g., if some other method not implemented in the <span class="pkg">poolr</span> package is used to estimate the effective number of tests). Argument <code>R</code> is then irrelevant and doesn't need to be specified.
</p>
<p><b>Adjustment Based on an Empirically-Derived Null Distribution</b>
</p>
<p>When <code>adjust = "empirical"</code>, the combined \(p\)-value is computed based on an empirically-derived null distribution using pseudo replicates (using the <code><a href="#topic+empirical">empirical</a></code> function). This is appropriate if the test statistics that generated the \(p\)-values to be combined can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics (which is specified via the <code>R</code> argument). In this case, test statistics are repeatedly simulated from a multivariate normal distribution under the joint null hypothesis, converted into one- or two-sided \(p\)-values (depending on the <code>side</code> argument), and Fisher's method is applied. Repeating this process <code>size</code> times yields a null distribution based on which the combined \(p\)-value can be computed, or more precisely, estimated, since repeated applications of this method will yield (slightly) different results. To obtain a stable estimate of the combined \(p\)-value, <code>size</code> should be set to a large value (the default is <code>10000</code>, but this can be increased for a more precise estimate). If we consider the combined \(p\)-value an estimate of the &lsquo;true&rsquo; combined \(p\)-value that would be obtained for a null distribution of infinite size, we can also construct a 95% (pseudo) confidence interval based on a binomial distribution.
</p>
<p>If <code>batchsize</code> is unspecified, the null distribution is simulated in a single batch, which requires temporarily storing a matrix with dimensions <code>[size,k]</code>. When <code>size*k</code> is large, allocating the memory for this matrix might not be possible. Instead, one can specify a <code>batchsize</code> value, in which case a matrix with dimensions <code>[batchsize,k]</code> is repeatedly simulated until the desired size of the null distribution has been obtained.
</p>
<p>One can also specify a vector for the <code>size</code> argument, in which case one must also specify a corresponding vector for the <code>threshold</code> argument. In that case, a stepwise algorithm is used that proceeds as follows. For <code>j = 1, ..., length(size)</code>,
</p>

<ol>
<li><p> estimate the combined \(p\)-value based on <code>size[j]</code>
</p>
</li>
<li><p> if the combined \(p\)-value is \(\ge\) than <code>threshold[j]</code>, stop (and report the combined \(p\)-value), otherwise go back to 1.
</p>
</li></ol>

<p>By setting <code>size</code> to increasing values (e.g., <code>size = c(1000, 10000, 100000)</code>) and <code>threshold</code> to decreasing values (e.g., <code>threshold = c(.10, .01, 0)</code>), one can quickly obtain a fairly accurate estimate of the combined \(p\)-value if it is far from significant (e.g., \(\ge\) .10), but hone in on a more accurate estimate for a combined \(p\)-value that is closer to 0. Note that the last value of <code>threshold</code> should be 0 (and is forced to be inside of the function), so that the algorithm is guaranteed to terminate (hence, one can also leave out the last value of <code>threshold</code>, so <code>threshold = c(.10, .01)</code> would also work in the example above). One can also specify a single <code>threshold</code> (which is replicated as often as necessary depending on the length of <code>size</code>).
</p>
<p><b>Adjustment Based on Multivariate Theory</b>
</p>
<p>When <code>adjust = "generalized"</code>, Fisher's method is computed based on a Satterthwaite approximation that accounts for the dependence among the tests, assuming that the test statistics that generated the \(p\)-values follow a multivariate normal distribution. In that case, <code>R</code> needs to be set equal to a matrix that contains the covariances among the \(-2 \ln(p_i)\) values. If a matrix is available that reflects the correlations among the test statistics, this can be converted into the required covariance matrix using the <code><a href="#topic+mvnconv">mvnconv</a></code> function. See &lsquo;Examples&rsquo;.
</p>
<p>This generalization of Fisher's method is sometimes called Brown's method, based on Brown (1975), although the paper only describes the method for combining one-sided p-values. Both one- and two-sided versions of Brown's method are implemented in <span class="pkg">poolr</span>.
</p>


<h3>Value</h3>

<p>An object of class <code>"poolr"</code>. The object is a list containing the following components:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>combined \(p\)-value.</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>confidence interval for the combined \(p\)-value (only when <code>adjust = "empirical"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of \(p\)-values that were combined.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>estimate of the effective number of tests (only when <code>adjust</code> is one of <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>adjust</code></td>
<td>
<p>chosen adjustment method.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>value of the (adjusted) test statistic.</p>
</td></tr>
<tr><td><code>fun</code></td>
<td>
<p>name of calling function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The methods underlying <code>adjust = "empirical"</code> and <code>adjust = "generalized"</code> assume that the test statistics that generated the \(p\)-values to be combined follow a multivariate normal distribution. Hence, the matrix specified via <code>R</code> must be positive definite. If it is not and <code>nearpd = TRUE</code>, it will be turned into one (based on Higham, 2002, and a slightly simplified version of <code><a href="Matrix.html#topic+nearPD">nearPD</a></code> from the <span class="pkg">Matrix</span> package).
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Brown, M. B. (1975). 400: A method for combining non-independent, one-sided tests of significance. <em>Biometrics, 31</em>(4), 987&ndash;992.
</p>
<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>
<p>Fisher, R. A. (1932). <em>Statistical Methods for Research Workers</em> (4th ed.). Edinburgh: Oliver and Boyd.
</p>
<p>Higham, N. J. (2002). Computing the nearest correlation matrix: A problem from finance. <em>IMA Journal of Numerical Analysis, 22</em>(3), 329&ndash;343.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># copy p-values and LD correlation matrix into p and r
# (see help(grid2ip) for details on these data)
p &lt;- grid2ip.p
r &lt;- grid2ip.ld

# apply Fisher's method
fisher(p)

# use mvnconv() to convert the LD correlation matrix into a matrix with the
# correlations among the (two-sided) p-values assuming that the test
# statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "p", cov2cor = TRUE)[1:5,1:5] # show only rows/columns 1-5

# adjustment based on estimates of the effective number of tests
fisher(p, adjust = "nyholt", R = mvnconv(r, target = "p", cov2cor = TRUE))
fisher(p, adjust = "liji",   R = mvnconv(r, target = "p", cov2cor = TRUE))
fisher(p, adjust = "gao",    R = mvnconv(r, target = "p", cov2cor = TRUE))
fisher(p, adjust = "galwey", R = mvnconv(r, target = "p", cov2cor = TRUE))

# setting argument 'm' manually
fisher(p, m = 12)

# adjustment based on an empirically-derived null distribution (setting the
# seed for reproducibility)
set.seed(1234)
fisher(p, adjust = "empirical", R = r)

# generate the empirical distribution in batches of size 100
fisher(p, adjust = "empirical", R = r, batchsize = 100)

# using the stepwise algorithm
fisher(p, adjust = "empirical", R = r, size = c(1000, 10000, 100000), threshold = c(.10, .01))

# use mvnconv() to convert the LD correlation matrix into a matrix with the
# covariances among the (two-sided) '-2ln(p_i)' values assuming that the
# test statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "m2lp")[1:5,1:5] # show only rows/columns 1-5

# adjustment based on generalized method
fisher(p, adjust = "generalized", R = mvnconv(r, target = "m2lp"))

# when using mvnconv() inside fisher() with adjust = "generalized", the
# 'target' argument is automatically set and doesn't need to be specified
fisher(p, adjust = "generalized", R = mvnconv(r))
</code></pre>

<hr>
<h2 id='grid2ip'>Results from testing the association between depressive symptoms and 23 SNPs in the GRID2IP gene</h2><span id='topic+grid2ip.p'></span><span id='topic+grid2ip.ld'></span><span id='topic+grid2ip.geno'></span><span id='topic+grid2ip.pheno'></span><span id='topic+grid2ip'></span>

<h3>Description</h3>

<p>Results from testing the association between depressive symptoms (as measured with the CES-D scale) and 23 single-nucleotide polymorphisms (SNPs) in the GRID2IP gene based on a sample of 886 adolescents (Van Assche et al., 2017).</p>


<h3>Usage</h3>

<pre><code class='language-R'>grid2ip.p
grid2ip.ld
grid2ip.geno
grid2ip.pheno</code></pre>


<h3>Format</h3>

<p>Object <code>grid2ip.p</code> is a vector with the 23 <code class="reqn">p</code>-values of the tests (two-sided). Object <code>grid2ip.ld</code> contains a matrix with the linkage disequilibrium (LD) correlations among the 23 SNPs. <code>grid2ip.geno</code> is a matrix that contains the genotypes of the adoloscents for the 23 SNPs. <code>grid2ip.pheno</code> is a vector with the phenotype for the adoloscents (the log-transformed CES-D scale values).</p>


<h3>References</h3>

<p>Van Assche, E., Moons, T., Cinar, O., Viechtbauer, W., Oldehinkel, A. J., Van Leeuwen, K., Verschueren, K., Colpin, H., Lambrechts, D., Van den Noortgate, W., Goossens, L., Claes, S., &amp; van Winkel, R. (2017). Gene-based interaction analysis shows GABAergic genes interacting with parenting in adolescent depressive symptoms. <em>Journal of Child Psychology and Psychiatry, 58</em>(12), 1301&ndash;1309.
</p>

<hr>
<h2 id='invchisq'>Inverse Chi-Square Method</h2><span id='topic+invchisq'></span>

<h3>Description</h3>

<p>Function to carry out the inverse chi-square method.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>invchisq(p, adjust = "none", R, m,
         size = 10000, threshold, side = 2, batchsize, nearpd = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="invchisq_+3A_p">p</code></td>
<td>
<p>vector of length \(k\) with the (one- or two-sided) p-values to be combined.</p>
</td></tr>
<tr><td><code id="invchisq_+3A_adjust">adjust</code></td>
<td>
<p>character string to specify an adjustment method to account for dependence. The default is <code>"none"</code>, in which case no adjustment is applied. Methods <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code>, or <code>"galwey"</code> are adjustments based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code>). Adjustment method <code>"empirical"</code> uses an empirically-derived null distribution using pseudo replicates. Finally, method <code>"generalized"</code> uses a generalization of the inverse chi-square method based on multivariate theory. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="invchisq_+3A_r">R</code></td>
<td>
<p>a \(k \times k\) symmetric matrix that reflects the dependence structure among the tests. Must be specified if <code>adjust</code> is set to something other than <code>"none"</code>. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="invchisq_+3A_m">m</code></td>
<td>
<p>optional scalar (between 1 and \(k\)) to manually specify the effective number of tests (instead of estimating it via one of the methods described above).</p>
</td></tr>
<tr><td><code id="invchisq_+3A_size">size</code></td>
<td>
<p>size of the empirically-derived null distribution. Can also be a numeric vector of sizes, in which case a stepwise algorithm is used. This (and the following arguments) are only relevant when <code>adjust = "empirical"</code>.</p>
</td></tr>
<tr><td><code id="invchisq_+3A_threshold">threshold</code></td>
<td>
<p>numeric vector to specify the significance thresholds for the stepwise algorithm (only relevant when <code>size</code> is a vector).</p>
</td></tr>
<tr><td><code id="invchisq_+3A_side">side</code></td>
<td>
<p>scalar to specify the sidedness of the \(p\)-values that are used to simulate the null distribution (2, by default, for two-sided tests; 1 for one-sided tests).</p>
</td></tr>
<tr><td><code id="invchisq_+3A_batchsize">batchsize</code></td>
<td>
<p>optional scalar to specify the batch size for generating the null distribution. When unspecified (the default), this is done in a single batch.</p>
</td></tr>
<tr><td><code id="invchisq_+3A_nearpd">nearpd</code></td>
<td>
<p>logical indicating if a negative definite <code>R</code> matrix should be turned into the nearest positive definite matrix (only relevant when <code>adjust = "empirical"</code> or <code>adjust = "generalized"</code>).</p>
</td></tr>
<tr><td><code id="invchisq_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Inverse Chi-Square Method</b>
</p>
<p>By default (i.e., when <code>adjust = "none"</code>), the function applies the inverse chi-square method to the \(p\)-values. Letting \(p_1, p_2, \ldots, p_k\) denote the individual (one- or two-sided) \(p\)-values of the \(k\) hypothesis tests to be combined, the test statistic is then computed with \[X^2 = \sum_{i = 1}^k F^{-1}(1 - p_i, 1)\] where \(F^{-1}(\cdot,1)\) denotes the inverse of the cumulative distribution function of a chi-square distribution with one degree of freedom. Under the joint null hypothesis, the test statistic follows a chi-square distribution with \(k\) degrees of freedom which is used to compute the combined \(p\)-value.
</p>
<p>The inverse chi-square method assumes that the \(p\)-values to be combined are independent. If this is not the case, the method can either be conservative (not reject often enough) or liberal (reject too often), depending on the dependence structure among the tests. In this case, one can adjust the method to account for such dependence (to bring the Type I error rate closer to some desired nominal significance level).
</p>
<p><b>Adjustment Based on the Effective Number of Tests</b>
</p>
<p>When <code>adjust</code> is set to <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>, the inverse chi-square method is adjusted based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code> for details on these methods for estimating the effective number of tests). In this case, argument <code>R</code> needs to be set to a matrix that reflects the dependence structure among the tests.
</p>
<p>There is no general solution for constructing such a matrix, as this depends on the type of test that generated the \(p\)-values and the sidedness of these tests. If the \(p\)-values are obtained from tests whose test statistics can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics, then the <code><a href="#topic+mvnconv">mvnconv</a></code> function can be used to convert this correlation matrix into the correlations among the (one- or two-sided) \(p\)-values, which can then be passed to the <code>R</code> argument. See &lsquo;Examples&rsquo;.
</p>
<p>Once the effective number of tests, \(m\), is estimated based on <code>R</code> using one of the four methods described above, the test statistic of the inverse chi-square method can be modified with \[\tilde{X}^2 = \frac{m}{k} \times X^2\] which is then assumed to follow a chi-square distribution with \(m\) degrees of freedom.
</p>
<p>Alternatively, one can also directly specify the effective number of tests via the <code>m</code> argument (e.g., if some other method not implemented in the <span class="pkg">poolr</span> package is used to estimate the effective number of tests). Argument <code>R</code> is then irrelevant and doesn't need to be specified.
</p>
<p><b>Adjustment Based on an Empirically-Derived Null Distribution</b>
</p>
<p>When <code>adjust = "empirical"</code>, the combined \(p\)-value is computed based on an empirically-derived null distribution using pseudo replicates (using the <code><a href="#topic+empirical">empirical</a></code> function). This is appropriate if the test statistics that generated the \(p\)-values to be combined can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics (which is specified via the <code>R</code> argument). In this case, test statistics are repeatedly simulated from a multivariate normal distribution under the joint null hypothesis, converted into one- or two-sided \(p\)-values (depending on the <code>side</code> argument), and the inverse chi-square method is applied. Repeating this process <code>size</code> times yields a null distribution based on which the combined \(p\)-value can be computed, or more precisely, estimated, since repeated applications of this method will yield (slightly) different results. To obtain a stable estimate of the combined \(p\)-value, <code>size</code> should be set to a large value (the default is <code>10000</code>, but this can be increased for a more precise estimate). If we consider the combined \(p\)-value an estimate of the &lsquo;true&rsquo; combined \(p\)-value that would be obtained for a null distribution of infinite size, we can also construct a 95% (pseudo) confidence interval based on a binomial distribution.
</p>
<p>If <code>batchsize</code> is unspecified, the null distribution is simulated in a single batch, which requires temporarily storing a matrix with dimensions <code>[size,k]</code>. When <code>size*k</code> is large, allocating the memory for this matrix might not be possible. Instead, one can specify a <code>batchsize</code> value, in which case a matrix with dimensions <code>[batchsize,k]</code> is repeatedly simulated until the desired size of the null distribution has been obtained.
</p>
<p>One can also specify a vector for the <code>size</code> argument, in which case one must also specify a corresponding vector for the <code>threshold</code> argument. In that case, a stepwise algorithm is used that proceeds as follows. For <code>j = 1, ..., length(size)</code>,
</p>

<ol>
<li><p> estimate the combined \(p\)-value based on <code>size[j]</code>
</p>
</li>
<li><p> if the combined \(p\)-value is \(\ge\) than <code>threshold[j]</code>, stop (and report the combined \(p\)-value), otherwise go back to 1.
</p>
</li></ol>

<p>By setting <code>size</code> to increasing values (e.g., <code>size = c(1000, 10000, 100000)</code>) and <code>threshold</code> to decreasing values (e.g., <code>threshold = c(.10, .01, 0)</code>), one can quickly obtain a fairly accurate estimate of the combined \(p\)-value if it is far from significant (e.g., \(\ge\) .10), but hone in on a more accurate estimate for a combined \(p\)-value that is closer to 0. Note that the last value of <code>threshold</code> should be 0 (and is forced to be inside of the function), so that the algorithm is guaranteed to terminate (hence, one can also leave out the last value of <code>threshold</code>, so <code>threshold = c(.10, .01)</code> would also work in the example above). One can also specify a single <code>threshold</code> (which is replicated as often as necessary depending on the length of <code>size</code>).
</p>
<p><b>Adjustment Based on Multivariate Theory</b>
</p>
<p>When <code>adjust = "generalized"</code>, the inverse chi-square method is computed based on a Satterthwaite approximation that accounts for the dependence among the tests, assuming that the test statistics that generated the \(p\)-values follow a multivariate normal distribution. In that case, <code>R</code> needs to be set equal to a matrix that contains the covariances among the \(F^{-1}(1 - p_i, 1)\) values. If a matrix is available that reflects the correlations among the test statistics, this can be converted into the required covariance matrix using the <code><a href="#topic+mvnconv">mvnconv</a></code> function. See &lsquo;Examples&rsquo;.
</p>


<h3>Value</h3>

<p>An object of class <code>"poolr"</code>. The object is a list containing the following components:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>combined \(p\)-value.</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>confidence interval for the combined \(p\)-value (only when <code>adjust = "empirical"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of \(p\)-values that were combined.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>estimate of the effective number of tests (only when <code>adjust</code> is one of <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>adjust</code></td>
<td>
<p>chosen adjustment method.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>value of the (adjusted) test statistic.</p>
</td></tr>
<tr><td><code>fun</code></td>
<td>
<p>name of calling function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The methods underlying <code>adjust = "empirical"</code> and <code>adjust = "generalized"</code> assume that the test statistics that generated the \(p\)-values to be combined follow a multivariate normal distribution. Hence, the matrix specified via <code>R</code> must be positive definite. If it is not and <code>nearpd = TRUE</code>, it will be turned into one (based on Higham, 2002, and a slightly simplified version of <code><a href="Matrix.html#topic+nearPD">nearPD</a></code> from the <span class="pkg">Matrix</span> package).
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>
<p>Higham, N. J. (2002). Computing the nearest correlation matrix: A problem from finance. <em>IMA Journal of Numerical Analysis, 22</em>(3), 329&ndash;343.
</p>
<p>Lancaster, H. O. (1961). The combination of probabilities: An application of orthonormal functions. <em>Australian Journal of Statistics, 3</em>(1), 20&ndash;33.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># copy p-values and LD correlation matrix into p and r
# (see help(grid2ip) for details on these data)
p &lt;- grid2ip.p
r &lt;- grid2ip.ld

# apply the inverse chi-square method
invchisq(p)

# use mvnconv() to convert the LD correlation matrix into a matrix with the
# correlations among the (two-sided) p-values assuming that the test
# statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "p", cov2cor = TRUE)[1:5,1:5] # show only rows/columns 1-5

# adjustment based on estimates of the effective number of tests
invchisq(p, adjust = "nyholt", R = mvnconv(r, target = "p", cov2cor = TRUE))
invchisq(p, adjust = "liji",   R = mvnconv(r, target = "p", cov2cor = TRUE))
invchisq(p, adjust = "gao",    R = mvnconv(r, target = "p", cov2cor = TRUE))
invchisq(p, adjust = "galwey", R = mvnconv(r, target = "p", cov2cor = TRUE))

# setting argument 'm' manually
invchisq(p, m = 12)

# adjustment based on an empirically-derived null distribution (setting the
# seed for reproducibility)
set.seed(1234)
invchisq(p, adjust = "empirical", R = r)

# generate the empirical distribution in batches of size 100
invchisq(p, adjust = "empirical", R = r, batchsize = 100)

# using the stepwise algorithm (not run, because this takes slightly longer
# and can lead to a note when running the standard package checks)

invchisq(p, adjust = "empirical", R = r, size = c(1000, 10000, 100000), threshold = c(.10, .01))


# use mvnconv() to convert the LD correlation matrix into a matrix with the
# covariances among the (two-sided) 'F(1-p_i,1)' values assuming that the
# test statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "chisq1")[1:5,1:5] # show only rows/columns 1-5

# adjustment based on generalized method
invchisq(p, adjust = "generalized", R = mvnconv(r, target = "chisq1"))

# when using mvnconv() inside invchisq() with adjust = "generalized", the
# 'target' argument is automatically set and doesn't need to be specified
invchisq(p, adjust = "generalized", R = mvnconv(r))
</code></pre>

<hr>
<h2 id='meff'>Estimate the Effective Number of Tests</h2><span id='topic+meff'></span>

<h3>Description</h3>

<p>Estimate the effective number of tests.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>meff(R, eigen, method, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meff_+3A_r">R</code></td>
<td>
<p>a \(k \times k\) symmetric matrix that reflects the correlation structure among the tests.</p>
</td></tr>
<tr><td><code id="meff_+3A_eigen">eigen</code></td>
<td>
<p>optional vector to directly supply the eigenvalues to the function (instead of computing them from the matrix given via <code>R</code>).</p>
</td></tr>
<tr><td><code id="meff_+3A_method">method</code></td>
<td>
<p>character string to specify the method to be used to estimate the effective number of tests (either <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code>, or <code>"galwey"</code>). See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="meff_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function estimates the effective number of tests based on one of four different methods. All methods work by extracting the eigenvalues from the \(R\) matrix supplied via the <code>R</code> argument (or from the eigenvalues directly passed via the <code>eigen</code> argument). Letting \(\lambda_i\) denote the \(i\)th eigenvalue of this matrix (with \(i = 1, \ldots, k\)) in decreasing order, the effective number of tests (\(m\)) is estimated as follows.
</p>
<p><b>Method by Nyholt (2004)</b>
</p>
\[m = 1 + (k - 1) \left(1 - \frac{\mbox{Var}(\lambda)}{k}\right)\]<p> where \(\mbox{Var}(\lambda)\) is the observed sample variance of the \(k\) eigenvalues.
</p>
<p><b>Method by Li &amp; Ji (2005)</b>
</p>
\[m = \sum_{i = 1}^k f(|\lambda_i|)\]<p> where \(f(x) = I(x \ge 1) + (x - \lfloor x \rfloor)\) and \(\lfloor \cdot \rfloor\) is the floor function.
</p>
<p><b>Method by Gao et al. (2008)</b>
</p>
\[m = \min(x) \; \mbox{such that} \; \frac{\sum_{i = 1}^x \lambda_{i}}{\sum_{i = 1}^k \lambda_{i}} > C\]<p> where \(C\) is a pre-defined parameter which is set to 0.995 by default.
</p>
<p><b>Method by Galwey (2009)</b>
</p>
\[m = \frac{\left(\sum_{i = 1}^k \sqrt{\lambda_i'}\right)^2}{\sum_{i = 1}^k \lambda_i'}\]<p> where \(\lambda_i' = \max[0, \lambda_i]\).
</p>
<p><b>Note:</b> For all methods that can yield a non-integer estimate (all but the method by Gao et al., 2008), the resulting estimate \(m\) is rounded down to the nearest integer.
</p>
<p><b>Specifying the R Matrix</b>
</p>
<p>The \(R\) matrix should reflect the dependence structure among the tests. There is no general solution on how such a matrix should be constructed, as this depends on the type of test and the sidedness of these tests. For example, we can use the correlations among related but changing elements across the analyses/tests, or a function thereof, as a proxy for the dependence structure. For example, when conducting \(k\) analyses with the same dependent variable and \(k\) different independent variables, the correlations among the independent variables could serve as such a proxy. Analogously, if analyses are conducted for \(k\) dependent variables with the same set of independent variables, the correlations among the dependent variables could be used instead.
</p>
<p>If the tests of interest have test statistics that can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics (which might be approximated by the correlations among the interchanging independent or dependent variables), then the <code><a href="#topic+mvnconv">mvnconv</a></code> function can be used to convert this correlation matrix into the correlations among the (one- or two-sided) \(p\)-values, which in turn can then be passed to the <code>R</code> argument. See &lsquo;Examples&rsquo;.
</p>
<p><b>Not Positive Semi-Definite R</b>
</p>
<p>Depending on the way \(R\) was constructed, it may happen that this matrix is not positive semi-definite, leading to negative eigenvalues. The methods given above can all still be carried out in this case. However, another possibility is to handle such a case by using an algorithm that finds the nearest positive (semi-)definite matrix (e.g., Higham 2002) before passing this matrix to the function (see <code><a href="Matrix.html#topic+nearPD">nearPD</a></code> from the <span class="pkg">Matrix</span> package for a corresponding implementation).
</p>


<h3>Value</h3>

<p>A scalar giving the estimate of the effective number of tests.
</p>


<h3>Note</h3>

<p>For <code>method = "gao"</code>, <code>C = 0.995</code> by default, but a different value of <code>C</code> can be passed to the function via <code>...</code> (e.g., <code>meff(R, method = "gao", C = 0.95)</code>).
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>
<p>Gao, X., Starmer, J., &amp; Martin, E. R. (2008). A multiple testing correction method for genetic association studies using correlated single nucleotide polymorphisms. <em>Genetic Epidemiology, 32</em>(4), 361&ndash;369.
</p>
<p>Galwey, N. W. (2009). A new measure of the effective number of tests, a practical tool for comparing families of non-independent significance tests. <em>Genetic Epidemiology, 33</em>(7), 559&ndash;568.
</p>
<p>Higham, N. J. (2002). Computing the nearest correlation matrix: A problem from finance. <em>IMA Journal of Numerical Analysis, 22</em>(3), 329&ndash;343.
</p>
<p>Li, J., &amp; Ji, L. (2005). Adjusting multiple testing in multilocus analyses using the eigenvalues of a correlation matrix. <em>Heredity, 95</em>(3), 221&ndash;227.
</p>
<p>Nyholt, D. R. (2004). A simple correction for multiple testing for single-nucleotide polymorphisms in linkage disequilibrium with each other. <em>American Journal of Human Genetics, 74</em>(4), 765&ndash;769.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># copy LD correlation matrix into r (see help(grid2ip) for details on these data)
r &lt;- grid2ip.ld

# estimate the effective number of tests based on the LD correlation matrix
meff(r, method = "nyholt")
meff(r, method = "liji")
meff(r, method = "gao")
meff(r, method = "galwey")

# use mvnconv() to convert the LD correlation matrix into a matrix with the
# correlations among the (two-sided) p-values assuming that the test
# statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "p", cov2cor = TRUE)[1:5,1:5] # show only rows/columns 1-5

# use this matrix instead for estimating the effective number of tests
meff(mvnconv(r, target = "p", cov2cor = TRUE), method = "nyholt")
meff(mvnconv(r, target = "p", cov2cor = TRUE), method = "liji")
meff(mvnconv(r, target = "p", cov2cor = TRUE), method = "gao")
meff(mvnconv(r, target = "p", cov2cor = TRUE), method = "galwey")
</code></pre>

<hr>
<h2 id='mvnconv'>Convert Correlations Among Multivariate Normal Test Statistics to Covariances for Various Target Statistics</h2><span id='topic+mvnconv'></span>

<h3>Description</h3>

<p>Function to convert a matrix with the correlations among multivariate normal test statistics to a matrix with the covariances among various target statistics.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnconv(R, side = 2, target, cov2cor = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mvnconv_+3A_r">R</code></td>
<td>
<p>a \(k \times k\) symmetric matrix that contains the correlations among the test statistics.</p>
</td></tr>
<tr><td><code id="mvnconv_+3A_side">side</code></td>
<td>
<p>scalar to specify the sidedness of the \(p\)-values that are obtained from the test statistics (2, by default, for two-sided tests; 1 for one-sided tests).</p>
</td></tr>
<tr><td><code id="mvnconv_+3A_target">target</code></td>
<td>
<p>the target statistic for which the covariances are calculated (either <code>"p"</code>, <code>"m2lp"</code>, <code>"chisq1"</code>, or <code>"z"</code>). See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="mvnconv_+3A_cov2cor">cov2cor</code></td>
<td>
<p>logical to indicate whether to convert the covariance matrix to a correlation matrix (default is <code>FALSE</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function converts a matrix with the correlations among multivariate normal test statistics to a matrix with the covariances among various target statistics. In particular, assume \[\begin{bmatrix} t_i \\ t_j \end{bmatrix} \sim \mbox{MVN} \left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 1 & \rho_{ij} \\ \rho_{ij} & 1 \end{bmatrix} \right)\] is the joint distribution for test statistics \(t_i\) and \(t_j\). For <code>side = 1</code>, let \(p_i = 1 - \Phi(t_i)\) and \(p_j = 1 - \Phi(t_j)\) where \(\Phi(\cdot)\) denotes the cumulative distribution function of a standard normal distribution. For <code>side = 2</code>, let \(p_i = 2(1 - \Phi(|t_i|))\) and \(p_j = 2(1 - \Phi(|t_j|))\). These are simply the one- and two-sided \(p\)-values corresponding to \(t_i\) and \(t_j\).
</p>
<p>If <code>target = "p"</code>, the function computes \(\mbox{Cov}[p_i, p_j]\).
</p>
<p>If <code>target = "m2lp"</code>, the function computes \(\mbox{Cov}[-2 \ln(p_i), -2 \ln(p_j)]\).
</p>
<p>If <code>target = "chisq1"</code>, the function computes \(\mbox{Cov}[F^{-1}(1 - p_i, 1), F^{-1}(1 - p_j, 1)]\), where \(F^{-1}(\cdot,1)\) denotes the inverse of the cumulative distribution function of a chi-square distribution with one degree of freedom.
</p>
<p>If <code>target = "z"</code>, the function computes \(\mbox{Cov}[\Phi^{-1}(1 - p_i), \Phi^{-1}(1 - p_j)]\), where \(\Phi^{-1}(\cdot)\) denotes the inverse of the cumulative distribution function of a standard normal distribution.
</p>


<h3>Value</h3>

<p>The function returns the covariance matrix (or the correlation matrix if <code>cov2cor = TRUE</code>).
</p>


<h3>Note</h3>

<p>Since computation of the covariances requires numerical integration, the function doesn't actually compute these covariances on the fly. Instead, it uses the <code><a href="#topic+mvnlookup">mvnlookup</a></code> lookup table, which contains the covariances.
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># illustrative correlation matrix
R &lt;- matrix(c(   1,  0.8,  0.5,  0.3,
               0.8,    1,  0.2,  0.4,
               0.5,  0.2,    1,  0.7,
               0.3,  0.4,  0.7,    1), nrow = 4, ncol = 4)

# convert R into covariance matrices for the chosen targets
mvnconv(R, target = "p")
mvnconv(R, target = "m2lp")
mvnconv(R, target = "chisq1")
mvnconv(R, target = "z")

# convert R into correlation matrices for the chosen targets
mvnconv(R, target = "p",      cov2cor = TRUE)
mvnconv(R, target = "m2lp",   cov2cor = TRUE)
mvnconv(R, target = "chisq1", cov2cor = TRUE)
mvnconv(R, target = "z",      cov2cor = TRUE)
</code></pre>

<hr>
<h2 id='mvnlookup'>Lookup Table for the mvnconv() Function</h2><span id='topic+mvnlookup'></span>

<h3>Description</h3>

<p>Lookup table for the <code><a href="#topic+mvnconv">mvnconv</a></code> function.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>mvnlookup</code></pre>


<h3>Format</h3>

<p>The data frame contains the following columns:
</p>

<table>
<tr>
 <td style="text-align: left;">
   <b>rhos</b>     </td><td style="text-align: left;"> <code>numeric</code> </td><td style="text-align: left;"> correlations among the test statistics </td>
</tr>
<tr>
 <td style="text-align: left;">
   <b>m2lp_1</b>   </td><td style="text-align: left;"> <code>numeric</code> </td><td style="text-align: left;"> \(\mbox{Cov}[-2 \ln(p_i), -2 \ln(p_j)]\) (for one-sided tests) </td>
</tr>
<tr>
 <td style="text-align: left;">
   <b>m2lp_2</b>   </td><td style="text-align: left;"> <code>numeric</code> </td><td style="text-align: left;"> \(\mbox{Cov}[-2 \ln(p_i), -2 \ln(p_j)]\) (for two-sided tests) </td>
</tr>
<tr>
 <td style="text-align: left;">
   <b>z_1</b>      </td><td style="text-align: left;"> <code>numeric</code> </td><td style="text-align: left;"> \(\mbox{Cov}[\Phi^{-1}(1 - p_i), \Phi^{-1}(1 - p_j)]\) (for one-sided tests) </td>
</tr>
<tr>
 <td style="text-align: left;">
   <b>z_2</b>      </td><td style="text-align: left;"> <code>numeric</code> </td><td style="text-align: left;"> \(\mbox{Cov}[\Phi^{-1}(1 - p_i), \Phi^{-1}(1 - p_j)]\) (for two-sided tests) </td>
</tr>
<tr>
 <td style="text-align: left;">
   <b>chisq1_1</b> </td><td style="text-align: left;"> <code>numeric</code> </td><td style="text-align: left;"> \(\mbox{Cov}[F^{-1}(1 - p_i, 1), F^{-1}(1 - p_j, 1)]\) (for one-sided tests) </td>
</tr>
<tr>
 <td style="text-align: left;">
   <b>chisq1_2</b> </td><td style="text-align: left;"> <code>numeric</code> </td><td style="text-align: left;"> \(\mbox{Cov}[F^{-1}(1 - p_i, 1), F^{-1}(1 - p_j, 1)]\) (for two-sided tests) </td>
</tr>
<tr>
 <td style="text-align: left;">
   <b>p_1</b>      </td><td style="text-align: left;"> <code>numeric</code> </td><td style="text-align: left;"> \(\mbox{Cov}[p_i, p_j]\) (for one-sided tests) </td>
</tr>
<tr>
 <td style="text-align: left;">
   <b>p_2</b>      </td><td style="text-align: left;"> <code>numeric</code> </td><td style="text-align: left;"> \(\mbox{Cov}[p_i, p_j]\) (for two-sided tests) </td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Details</h3>

<p>Assume \[\begin{bmatrix} t_i \\ t_j \end{bmatrix} \sim \mbox{MVN} \left(\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} 1 & \rho_{ij} \\ \rho_{ij} & 1 \end{bmatrix} \right)\] is the joint distribution for test statistics \(t_i\) and \(t_j\). For one-sided tests, let \(p_i = 1 - \Phi(t_i)\) and \(p_j = 1 - \Phi(t_j)\) where \(\Phi(\cdot)\) denotes the cumulative distribution function of a standard normal distribution. For two-sided tests, let \(p_i = 2(1 - \Phi(|t_i|))\) and \(p_j = 2(1 - \Phi(|t_j|))\). These are simply the one- and two-sided \(p\)-values corresponding to \(t_i\) and \(t_j\).
</p>
<p>Columns <code>p_1</code> and <code>p_2</code> contain the values for \(\mbox{Cov}[p_i, p_j]\).
</p>
<p>Columns <code>m2lp_1</code> and <code>m2lp_2</code> contain the values for \(\mbox{Cov}[-2 \ln(p_i), -2 \ln(p_j)]\).
</p>
<p>Columns <code>chisq1_1</code> and <code>chisq1_2</code> contain the values for \(\mbox{Cov}[F^{-1}(1 - p_i, 1), F^{-1}(1 - p_j, 1)]\), where \(F^{-1}(\cdot,1)\) denotes the inverse of the cumulative distribution function of a chi-square distribution with one degree of freedom.
</p>
<p>Columns <code>z_1</code> and <code>z_2</code> contain the values for \(\mbox{Cov}[\Phi^{-1}(1 - p_i), \Phi^{-1}(1 - p_j)]\), where \(\Phi^{-1}(\cdot)\) denotes the inverse of the cumulative distribution function of a standard normal distribution.
</p>
<p>Computation of these covariances required numerical integration. The values in this table were precomputed.
</p>

<hr>
<h2 id='print.poolr'>Print Method for 'poolr' Objects</h2><span id='topic+print.poolr'></span>

<h3>Description</h3>

<p>Print method for objects of class <code>"poolr"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'poolr'
print(x, digits=3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.poolr_+3A_x">x</code></td>
<td>
<p>an object of class <code>"poolr"</code>.</p>
</td></tr>
<tr><td><code id="print.poolr_+3A_digits">digits</code></td>
<td>
<p>integer specifying the number of (significant) digits for rounding/presenting the results.</p>
</td></tr>
<tr><td><code id="print.poolr_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The output shows the combined \(p\)-value (with the specified number of significant digits), the test statistic (and its assumed null distribution), and the adjustment method that was applied.
</p>


<h3>Value</h3>

<p>The function does not return an object.
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>

<hr>
<h2 id='stouffer'>Stouffer's Method</h2><span id='topic+stouffer'></span>

<h3>Description</h3>

<p>Function to carry out Stouffer's method.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>stouffer(p, adjust = "none", R, m,
         size = 10000, threshold, side = 2, batchsize, nearpd = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stouffer_+3A_p">p</code></td>
<td>
<p>vector of length \(k\) with the (one- or two-sided) p-values to be combined.</p>
</td></tr>
<tr><td><code id="stouffer_+3A_adjust">adjust</code></td>
<td>
<p>character string to specify an adjustment method to account for dependence. The default is <code>"none"</code>, in which case no adjustment is applied. Methods <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code>, or <code>"galwey"</code> are adjustments based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code>). Adjustment method <code>"empirical"</code> uses an empirically-derived null distribution using pseudo replicates. Finally, method <code>"generalized"</code> uses a generalization of Stouffer's method based on multivariate theory. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="stouffer_+3A_r">R</code></td>
<td>
<p>a \(k \times k\) symmetric matrix that reflects the dependence structure among the tests. Must be specified if <code>adjust</code> is set to something other than <code>"none"</code>. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="stouffer_+3A_m">m</code></td>
<td>
<p>optional scalar (between 1 and \(k\)) to manually specify the effective number of tests (instead of estimating it via one of the methods described above).</p>
</td></tr>
<tr><td><code id="stouffer_+3A_size">size</code></td>
<td>
<p>size of the empirically-derived null distribution. Can also be a numeric vector of sizes, in which case a stepwise algorithm is used. This (and the following arguments) are only relevant when <code>adjust = "empirical"</code>.</p>
</td></tr>
<tr><td><code id="stouffer_+3A_threshold">threshold</code></td>
<td>
<p>numeric vector to specify the significance thresholds for the stepwise algorithm (only relevant when <code>size</code> is a vector).</p>
</td></tr>
<tr><td><code id="stouffer_+3A_side">side</code></td>
<td>
<p>scalar to specify the sidedness of the \(p\)-values that are used to simulate the null distribution (2, by default, for two-sided tests; 1 for one-sided tests).</p>
</td></tr>
<tr><td><code id="stouffer_+3A_batchsize">batchsize</code></td>
<td>
<p>optional scalar to specify the batch size for generating the null distribution. When unspecified (the default), this is done in a single batch.</p>
</td></tr>
<tr><td><code id="stouffer_+3A_nearpd">nearpd</code></td>
<td>
<p>logical indicating if a negative definite <code>R</code> matrix should be turned into the nearest positive definite matrix (only relevant when <code>adjust = "empirical"</code> or <code>adjust = "generalized"</code>).</p>
</td></tr>
<tr><td><code id="stouffer_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Stouffer's Method</b>
</p>
<p>By default (i.e., when <code>adjust = "none"</code>), the function applies Stouffer's method to the \(p\)-values (Stouffer et al., 1949). Letting \(p_1, p_2, \ldots, p_k\) denote the individual (one- or two-sided) \(p\)-values of the \(k\) hypothesis tests to be combined, the test statistic is then computed with \[z = \sum_{i = 1}^k z_i / \sqrt{k}\] where \(z_i = \Phi^{-1}(1 - p_i)\) and \(\Phi^{-1}(\cdot)\) denotes the inverse of the cumulative distribution function of a standard normal distribution. Under the joint null hypothesis, the test statistic follows a standard normal distibution which is used to compute the combined \(p\)-value.
</p>
<p>Stouffer's method assumes that the \(p\)-values to be combined are independent. If this is not the case, the method can either be conservative (not reject often enough) or liberal (reject too often), depending on the dependence structure among the tests. In this case, one can adjust the method to account for such dependence (to bring the Type I error rate closer to some desired nominal significance level).
</p>
<p><b>Adjustment Based on the Effective Number of Tests</b>
</p>
<p>When <code>adjust</code> is set to <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>, Stouffer's method is adjusted based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code> for details on these methods for estimating the effective number of tests). In this case, argument <code>R</code> needs to be set to a matrix that reflects the dependence structure among the tests.
</p>
<p>There is no general solution for constructing such a matrix, as this depends on the type of test that generated the \(p\)-values and the sidedness of these tests. If the \(p\)-values are obtained from tests whose test statistics can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics, then the <code><a href="#topic+mvnconv">mvnconv</a></code> function can be used to convert this correlation matrix into the correlations among the (one- or two-sided) \(p\)-values, which can then be passed to the <code>R</code> argument. See &lsquo;Examples&rsquo;.
</p>
<p>Once the effective number of tests, \(m\), is estimated based on <code>R</code> using one of the four methods described above, the test statistic of Stouffer's method can be modified with \[\tilde{z} = \sqrt{\frac{m}{k}} \times z\] which is then assumed to follow a standard normal distibution.
</p>
<p>Alternatively, one can also directly specify the effective number of tests via the <code>m</code> argument (e.g., if some other method not implemented in the <span class="pkg">poolr</span> package is used to estimate the effective number of tests). Argument <code>R</code> is then irrelevant and doesn't need to be specified.
</p>
<p><b>Adjustment Based on an Empirically-Derived Null Distribution</b>
</p>
<p>When <code>adjust = "empirical"</code>, the combined \(p\)-value is computed based on an empirically-derived null distribution using pseudo replicates (using the <code><a href="#topic+empirical">empirical</a></code> function). This is appropriate if the test statistics that generated the \(p\)-values to be combined can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics (which is specified via the <code>R</code> argument). In this case, test statistics are repeatedly simulated from a multivariate normal distribution under the joint null hypothesis, converted into one- or two-sided \(p\)-values (depending on the <code>side</code> argument), and Stouffer's method is applied. Repeating this process <code>size</code> times yields a null distribution based on which the combined \(p\)-value can be computed, or more precisely, estimated, since repeated applications of this method will yield (slightly) different results. To obtain a stable estimate of the combined \(p\)-value, <code>size</code> should be set to a large value (the default is <code>10000</code>, but this can be increased for a more precise estimate). If we consider the combined \(p\)-value an estimate of the &lsquo;true&rsquo; combined \(p\)-value that would be obtained for a null distribution of infinite size, we can also construct a 95% (pseudo) confidence interval based on a binomial distribution.
</p>
<p>If <code>batchsize</code> is unspecified, the null distribution is simulated in a single batch, which requires temporarily storing a matrix with dimensions <code>[size,k]</code>. When <code>size*k</code> is large, allocating the memory for this matrix might not be possible. Instead, one can specify a <code>batchsize</code> value, in which case a matrix with dimensions <code>[batchsize,k]</code> is repeatedly simulated until the desired size of the null distribution has been obtained.
</p>
<p>One can also specify a vector for the <code>size</code> argument, in which case one must also specify a corresponding vector for the <code>threshold</code> argument. In that case, a stepwise algorithm is used that proceeds as follows. For <code>j = 1, ..., length(size)</code>,
</p>

<ol>
<li><p> estimate the combined \(p\)-value based on <code>size[j]</code>
</p>
</li>
<li><p> if the combined \(p\)-value is \(\ge\) than <code>threshold[j]</code>, stop (and report the combined \(p\)-value), otherwise go back to 1.
</p>
</li></ol>

<p>By setting <code>size</code> to increasing values (e.g., <code>size = c(1000, 10000, 100000)</code>) and <code>threshold</code> to decreasing values (e.g., <code>threshold = c(.10, .01, 0)</code>), one can quickly obtain a fairly accurate estimate of the combined \(p\)-value if it is far from significant (e.g., \(\ge\) .10), but hone in on a more accurate estimate for a combined \(p\)-value that is closer to 0. Note that the last value of <code>threshold</code> should be 0 (and is forced to be inside of the function), so that the algorithm is guaranteed to terminate (hence, one can also leave out the last value of <code>threshold</code>, so <code>threshold = c(.10, .01)</code> would also work in the example above). One can also specify a single <code>threshold</code> (which is replicated as often as necessary depending on the length of <code>size</code>).
</p>
<p><b>Adjustment Based on Multivariate Theory</b>
</p>
<p>When <code>adjust = "generalized"</code>, Stouffer's method is computed based on a multivariate normal distribution that accounts for the dependence among the tests, assuming that the test statistics that generated the \(p\)-values follow a multivariate normal distribution. In that case, <code>R</code> needs to be set equal to a matrix that contains the covariances among the \(z_i\) values. If a matrix is available that reflects the correlations among the test statistics, this can be converted into the required covariance matrix using the <code><a href="#topic+mvnconv">mvnconv</a></code> function. See &lsquo;Examples&rsquo;.
</p>
<p>This generalization of Stouffer's method is sometimes called Strube's method, based on Strube (1986), although the paper only describes the method for combining one-sided \(p\)-values. Both one- and two-sided versions of Strube's method are implemented in <span class="pkg">poolr</span>, but caution must be exercised when applying it to two-sided \(p\)-values (even if the test statistics follow a multivariate normal distribution, \([z_1, z_2, \ldots, z_k]\) is then not multivariate normal, but this is implicitly assumed by the method).
</p>


<h3>Value</h3>

<p>An object of class <code>"poolr"</code>. The object is a list containing the following components:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>combined \(p\)-value.</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>confidence interval for the combined \(p\)-value (only when <code>adjust = "empirical"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of \(p\)-values that were combined.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>estimate of the effective number of tests (only when <code>adjust</code> is one of <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>adjust</code></td>
<td>
<p>chosen adjustment method.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>value of the (adjusted) test statistic.</p>
</td></tr>
<tr><td><code>fun</code></td>
<td>
<p>name of calling function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The methods underlying <code>adjust = "empirical"</code> and <code>adjust = "generalized"</code> assume that the test statistics that generated the \(p\)-values to be combined follow a multivariate normal distribution. Hence, the matrix specified via <code>R</code> must be positive definite. If it is not and <code>nearpd = TRUE</code>, it will be turned into one (based on Higham, 2002, and a slightly simplified version of <code><a href="Matrix.html#topic+nearPD">nearPD</a></code> from the <span class="pkg">Matrix</span> package).
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>
<p>Higham, N. J. (2002). Computing the nearest correlation matrix: A problem from finance. <em>IMA Journal of Numerical Analysis, 22</em>(3), 329&ndash;343.
</p>
<p>Stouffer, S. A., Suchman, E. A., DeVinney, L. C., Star, S. A., &amp; Williams, R. M., Jr. (1949). <em>The American Soldier: Adjustment During Army Life (Vol. 1)</em>. Princeton, NJ: Princeton University Press.
</p>
<p>Strube, M. J. (1985). Combining and comparing significance levels from nonindependent hypothesis tests. <em>Psychological Bulletin, 97</em>(2), 334&ndash;341.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># copy p-values and LD correlation matrix into p and r
# (see help(grid2ip) for details on these data)
p &lt;- grid2ip.p
r &lt;- grid2ip.ld

# apply Stouffer's method
stouffer(p)

# use mvnconv() to convert the LD correlation matrix into a matrix with the
# correlations among the (two-sided) p-values assuming that the test
# statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "p", cov2cor = TRUE)[1:5,1:5] # show only rows/columns 1-5

# adjustment based on estimates of the effective number of tests
stouffer(p, adjust = "nyholt", R = mvnconv(r, target = "p", cov2cor = TRUE))
stouffer(p, adjust = "liji",   R = mvnconv(r, target = "p", cov2cor = TRUE))
stouffer(p, adjust = "gao",    R = mvnconv(r, target = "p", cov2cor = TRUE))
stouffer(p, adjust = "galwey", R = mvnconv(r, target = "p", cov2cor = TRUE))

# setting argument 'm' manually
stouffer(p, m = 12)

# adjustment based on an empirically-derived null distribution (setting the
# seed for reproducibility)
set.seed(1234)
stouffer(p, adjust = "empirical", R = r)

# generate the empirical distribution in batches of size 100
stouffer(p, adjust = "empirical", R = r, batchsize = 100)

# using the stepwise algorithm
stouffer(p, adjust = "empirical", R = r, size = c(1000, 10000, 100000), threshold = c(.10, .01))

# use mvnconv() to convert the LD correlation matrix into a matrix with the
# covariances among the (two-sided) 'z_i' values assuming that the
# test statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "z")[1:5,1:5] # show only rows/columns 1-5

# adjustment based on generalized method
stouffer(p, adjust = "generalized", R = mvnconv(r, target = "z"))

# when using mvnconv() inside stouffer() with adjust = "generalized", the
# 'target' argument is automatically set and doesn't need to be specified
stouffer(p, adjust = "generalized", R = mvnconv(r))
</code></pre>

<hr>
<h2 id='tippett'>Tippett's Method</h2><span id='topic+tippett'></span>

<h3>Description</h3>

<p>Function to carry out Tippett's method.<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script></p>


<h3>Usage</h3>

<pre><code class='language-R'>tippett(p, adjust = "none", R, m,
        size = 10000, threshold, side = 2, batchsize, nearpd = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="tippett_+3A_p">p</code></td>
<td>
<p>vector of length \(k\) with the (one- or two-sided) p-values to be combined.</p>
</td></tr>
<tr><td><code id="tippett_+3A_adjust">adjust</code></td>
<td>
<p>character string to specify an adjustment method to account for dependence. The default is <code>"none"</code>, in which case no adjustment is applied. Methods <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code>, or <code>"galwey"</code> are adjustments based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code>). Adjustment method <code>"empirical"</code> uses an empirically-derived null distribution using pseudo replicates. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="tippett_+3A_r">R</code></td>
<td>
<p>a \(k \times k\) symmetric matrix that reflects the dependence structure among the tests. Must be specified if <code>adjust</code> is set to something other than <code>"none"</code>. See &lsquo;Details&rsquo;.</p>
</td></tr>
<tr><td><code id="tippett_+3A_m">m</code></td>
<td>
<p>optional scalar (between 1 and \(k\)) to manually specify the effective number of tests (instead of estimating it via one of the methods described above).</p>
</td></tr>
<tr><td><code id="tippett_+3A_size">size</code></td>
<td>
<p>size of the empirically-derived null distribution. Can also be a numeric vector of sizes, in which case a stepwise algorithm is used. This (and the following arguments) are only relevant when <code>adjust = "empirical"</code>.</p>
</td></tr>
<tr><td><code id="tippett_+3A_threshold">threshold</code></td>
<td>
<p>numeric vector to specify the significance thresholds for the stepwise algorithm (only relevant when <code>size</code> is a vector).</p>
</td></tr>
<tr><td><code id="tippett_+3A_side">side</code></td>
<td>
<p>scalar to specify the sidedness of the \(p\)-values that are used to simulate the null distribution (2, by default, for two-sided tests; 1 for one-sided tests).</p>
</td></tr>
<tr><td><code id="tippett_+3A_batchsize">batchsize</code></td>
<td>
<p>optional scalar to specify the batch size for generating the null distribution. When unspecified (the default), this is done in a single batch.</p>
</td></tr>
<tr><td><code id="tippett_+3A_nearpd">nearpd</code></td>
<td>
<p>logical indicating if a negative definite <code>R</code> matrix should be turned into the nearest positive definite matrix (only relevant when <code>adjust = "empirical"</code>).</p>
</td></tr>
<tr><td><code id="tippett_+3A_...">...</code></td>
<td>
<p>other arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><b>Tippett's Method</b>
</p>
<p>By default (i.e., when <code>adjust = "none"</code>), the function applies the Tippett's method to the \(p\)-values (Tippett, 1931). Letting \(p_1, p_2, \ldots, p_k\) denote the individual (one- or two-sided) \(p\)-values of the \(k\) hypothesis tests to be combined, the combined \(p\)-value is then computed with \[p_c = 1 - (1 - \min(p_1, p_2, \ldots, p_k))^k.\]
</p>
<p>Tippett's method asumes that the \(p\)-values to be combined are independent. If this is not the case, the method can either be conservative (not reject often enough) or liberal (reject too often), depending on the dependence structure among the tests. In this case, one can adjust the method to account for such dependence (to bring the Type I error rate closer to some desired nominal significance level).
</p>
<p><b>Adjustment Based on the Effective Number of Tests</b>
</p>
<p>When <code>adjust</code> is set to <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>, Tippett's method is adjusted based on an estimate of the effective number of tests (see <code><a href="#topic+meff">meff</a></code> for details on these methods for estimating the effective number of tests). In this case, argument <code>R</code> needs to be set to a matrix that reflects the dependence structure among the tests.
</p>
<p>There is no general solution for constructing such a matrix, as this depends on the type of test that generated the \(p\)-values and the sidedness of these tests. If the \(p\)-values are obtained from tests whose test statistics can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics, then the <code><a href="#topic+mvnconv">mvnconv</a></code> function can be used to convert this correlation matrix into the correlations among the (one- or two-sided) \(p\)-values, which can then be passed to the <code>R</code> argument. See &lsquo;Examples&rsquo;.
</p>
<p>Once the effective number of tests, \(m\), is estimated based on <code>R</code> using one of the four methods described above, the combined \(p\)-value is then computed with \[p_c = 1 - (1 - \min(p_1, p_2, \ldots, p_k))^m.\]
</p>
<p>Alternatively, one can also directly specify the effective number of tests via the <code>m</code> argument (e.g., if some other method not implemented in the <span class="pkg">poolr</span> package is used to estimate the effective number of tests). Argument <code>R</code> is then irrelevant and doesn't need to be specified.
</p>
<p><b>Adjustment Based on an Empirically-Derived Null Distribution</b>
</p>
<p>When <code>adjust = "empirical"</code>, the combined \(p\)-value is computed based on an empirically-derived null distribution using pseudo replicates (using the <code><a href="#topic+empirical">empirical</a></code> function). This is appropriate if the test statistics that generated the \(p\)-values to be combined can be assumed to follow a multivariate normal distribution and a matrix is available that reflects the correlations among the test statistics (which is specified via the <code>R</code> argument). In this case, test statistics are repeatedly simulated from a multivariate normal distribution under the joint null hypothesis, converted into one- or two-sided \(p\)-values (depending on the <code>side</code> argument), and Tippett's method is applied. Repeating this process <code>size</code> times yields a null distribution based on which the combined \(p\)-value can be computed, or more precisely, estimated, since repeated applications of this method will yield (slightly) different results. To obtain a stable estimate of the combined \(p\)-value, <code>size</code> should be set to a large value (the default is <code>10000</code>, but this can be increased for a more precise estimate). If we consider the combined \(p\)-value an estimate of the &lsquo;true&rsquo; combined \(p\)-value that would be obtained for a null distribution of infinite size, we can also construct a 95% (pseudo) confidence interval based on a binomial distribution.
</p>
<p>If <code>batchsize</code> is unspecified, the null distribution is simulated in a single batch, which requires temporarily storing a matrix with dimensions <code>[size,k]</code>. When <code>size*k</code> is large, allocating the memory for this matrix might not be possible. Instead, one can specify a <code>batchsize</code> value, in which case a matrix with dimensions <code>[batchsize,k]</code> is repeatedly simulated until the desired size of the null distribution has been obtained.
</p>
<p>One can also specify a vector for the <code>size</code> argument, in which case one must also specify a corresponding vector for the <code>threshold</code> argument. In that case, a stepwise algorithm is used that proceeds as follows. For <code>j = 1, ..., length(size)</code>,
</p>

<ol>
<li><p> estimate the combined \(p\)-value based on <code>size[j]</code>
</p>
</li>
<li><p> if the combined \(p\)-value is \(\ge\) than <code>threshold[j]</code>, stop (and report the combined \(p\)-value), otherwise go back to 1.
</p>
</li></ol>

<p>By setting <code>size</code> to increasing values (e.g., <code>size = c(1000, 10000, 100000)</code>) and <code>threshold</code> to decreasing values (e.g., <code>threshold = c(.10, .01, 0)</code>), one can quickly obtain a fairly accurate estimate of the combined \(p\)-value if it is far from significant (e.g., \(\ge\) .10), but hone in on a more accurate estimate for a combined \(p\)-value that is closer to 0. Note that the last value of <code>threshold</code> should be 0 (and is forced to be inside of the function), so that the algorithm is guaranteed to terminate (hence, one can also leave out the last value of <code>threshold</code>, so <code>threshold = c(.10, .01)</code> would also work in the example above). One can also specify a single <code>threshold</code> (which is replicated as often as necessary depending on the length of <code>size</code>).
</p>


<h3>Value</h3>

<p>An object of class <code>"poolr"</code>. The object is a list containing the following components:
</p>
<table>
<tr><td><code>p</code></td>
<td>
<p>combined \(p\)-value.</p>
</td></tr>
<tr><td><code>ci</code></td>
<td>
<p>confidence interval for the combined \(p\)-value (only when <code>adjust = "empirical"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>number of \(p\)-values that were combined.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>estimate of the effective number of tests (only when <code>adjust</code> is one of <code>"nyholt"</code>, <code>"liji"</code>, <code>"gao"</code> or <code>"galwey"</code>; otherwise <code>NULL</code>).</p>
</td></tr>
<tr><td><code>adjust</code></td>
<td>
<p>chosen adjustment method.</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>value of the (adjusted) test statistic.</p>
</td></tr>
<tr><td><code>fun</code></td>
<td>
<p>name of calling function.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The method underlying <code>adjust = "empirical"</code> assumes that the test statistics that generated the \(p\)-values to be combined follow a multivariate normal distribution. Hence, the matrix specified via <code>R</code> must be positive definite. If it is not and <code>nearpd = TRUE</code>, it will be turned into one (based on Higham, 2002, and a slightly simplified version of <code><a href="Matrix.html#topic+nearPD">nearPD</a></code> from the <span class="pkg">Matrix</span> package).
</p>


<h3>Author(s)</h3>

<p>Ozan Cinar <a href="mailto:ozancinar86@gmail.com">ozancinar86@gmail.com</a> <br />
Wolfgang Viechtbauer <a href="mailto:wvb@wvbauer.com">wvb@wvbauer.com</a> <br />
</p>


<h3>References</h3>

<p>Cinar, O. &amp; Viechtbauer, W. (2022). The poolr package for combining independent and dependent p values. <em>Journal of Statistical Software</em>, <b>101</b>(1), 1&ndash;42. <code style="white-space: pre;">&#8288;https://doi.org/10.18637/jss.v101.i01&#8288;</code>
</p>
<p>Higham, N. J. (2002). Computing the nearest correlation matrix: A problem from finance. <em>IMA Journal of Numerical Analysis, 22</em>(3), 329&ndash;343.
</p>
<p>Tippett, L. H. C. (1931). <em>Methods of Statistics</em>. London: Williams Norgate.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># copy p-values and LD correlation matrix into p and r
# (see help(grid2ip) for details on these data)
p &lt;- grid2ip.p
r &lt;- grid2ip.ld

# apply Tippett's method
tippett(p)

# use mvnconv() to convert the LD correlation matrix into a matrix with the
# correlations among the (two-sided) p-values assuming that the test
# statistics follow a multivariate normal distribution with correlation
# matrix r (note: 'side = 2' by default in mvnconv())
mvnconv(r, target = "p", cov2cor = TRUE)[1:5,1:5] # show only rows/columns 1-5

# adjustment based on estimates of the effective number of tests
tippett(p, adjust = "nyholt", R = mvnconv(r, target = "p", cov2cor = TRUE))
tippett(p, adjust = "liji",   R = mvnconv(r, target = "p", cov2cor = TRUE))
tippett(p, adjust = "gao",    R = mvnconv(r, target = "p", cov2cor = TRUE))
tippett(p, adjust = "galwey", R = mvnconv(r, target = "p", cov2cor = TRUE))

# setting argument 'm' manually
tippett(p, m = 12)

# adjustment based on an empirically-derived null distribution (setting the
# seed for reproducibility)
set.seed(1234)
tippett(p, adjust = "empirical", R = r)

# generate the empirical distribution in batches of size 100
tippett(p, adjust = "empirical", R = r, batchsize = 100)

# using the stepwise algorithm
tippett(p, adjust = "empirical", R = r, size = c(1000, 10000, 100000), threshold = c(.10, .01))
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
