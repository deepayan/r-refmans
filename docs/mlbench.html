<!DOCTYPE html><html><head><title>Help for package mlbench</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mlbench}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#as.data.frame.mlbench'><p>Convert an mlbench object to a dataframe</p></a></li>
<li><a href='#bayesclass'><p>Bayes classifier</p></a></li>
<li><a href='#BostonHousing'><p>Boston Housing Data</p></a></li>
<li><a href='#BreastCancer'><p>Wisconsin Breast Cancer Database</p></a></li>
<li><a href='#DNA'><p>Primate splice-junction gene sequences (DNA)</p></a></li>
<li><a href='#Glass'><p>Glass Identification Database</p></a></li>
<li><a href='#HouseVotes84'><p>United States Congressional Voting Records 1984</p></a></li>
<li><a href='#Ionosphere'><p>Johns Hopkins University Ionosphere database</p></a></li>
<li><a href='#LetterRecognition'><p>Letter Image Recognition Data</p></a></li>
<li><a href='#mlbench.2dnormals'><p>2-dimensional Gaussian Problem</p></a></li>
<li><a href='#mlbench.cassini'><p>Cassini: A 2 Dimensional Problem</p></a></li>
<li><a href='#mlbench.circle'><p>Circle in a Square Problem</p></a></li>
<li><a href='#mlbench.cuboids'><p>Cuboids: A 3 Dimensional Problem</p></a></li>
<li><a href='#mlbench.friedman1'><p>Benchmark Problem Friedman 1</p></a></li>
<li><a href='#mlbench.friedman2'><p>Benchmark Problem Friedman 2</p></a></li>
<li><a href='#mlbench.friedman3'><p>Benchmark Problem Friedman 3</p></a></li>
<li><a href='#mlbench.hypercube'><p>Corners of Hypercube</p></a></li>
<li><a href='#mlbench.peak'><p>Peak Benchmark Problem</p></a></li>
<li><a href='#mlbench.ringnorm'><p>Ringnorm Benchmark Problem</p></a></li>
<li><a href='#mlbench.shapes'><p>Shapes in 2d</p></a></li>
<li><a href='#mlbench.simplex'><p>Corners of d-dimensional Simplex</p></a></li>
<li><a href='#mlbench.smiley'><p>The Smiley</p></a></li>
<li><a href='#mlbench.spirals'><p>Two Spirals Benchmark Problem</p></a></li>
<li><a href='#mlbench.threenorm'><p>Threenorm Benchmark Problem</p></a></li>
<li><a href='#mlbench.twonorm'><p>Twonorm Benchmark Problem</p></a></li>
<li><a href='#mlbench.waveform'><p>Waveform Database Generator</p></a></li>
<li><a href='#mlbench.xor'><p>Continuous XOR Benchmark Problem</p></a></li>
<li><a href='#Ozone'><p>Los Angeles ozone pollution data, 1976</p></a></li>
<li><a href='#PimaIndiansDiabetes'><p>Pima Indians Diabetes Database</p></a></li>
<li><a href='#plot.mlbench'><p>Plot mlbench objects</p></a></li>
<li><a href='#Satellite'><p>Landsat Multi-Spectral Scanner Image Data</p></a></li>
<li><a href='#Servo'><p>Servo Data</p></a></li>
<li><a href='#Shuttle'><p>Shuttle Dataset (Statlog version)</p></a></li>
<li><a href='#Sonar'><p>Sonar, Mines vs. Rocks</p></a></li>
<li><a href='#Soybean'><p>Soybean Database</p></a></li>
<li><a href='#Vehicle'><p>Vehicle Silhouettes</p></a></li>
<li><a href='#Vowel'><p>Vowel Recognition (Deterding data)</p></a></li>
<li><a href='#Zoo'><p>Zoo Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>2.1-3.1</td>
</tr>
<tr>
<td>Title:</td>
<td>Machine Learning Benchmark Problems</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-01-21</td>
</tr>
<tr>
<td>Author:</td>
<td>Friedrich Leisch and Evgenia Dimitriadou.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Friedrich Leisch &lt;Friedrich.Leisch@R-project.org&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A collection of artificial and real-world machine learning
        benchmark problems, including, e.g., several
        data sets from the UCI repository.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Suggests:</td>
<td>lattice</td>
</tr>
<tr>
<td>ZipData:</td>
<td>No</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-05 08:49:59 UTC; ripley</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-05 08:51:59 UTC</td>
</tr>
</table>
<hr>
<h2 id='as.data.frame.mlbench'>Convert an mlbench object to a dataframe</h2><span id='topic+as.data.frame.mlbench'></span>

<h3>Description</h3>

<p>Converts <code>x</code> (which is basically a list) to a dataframe.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlbench'
as.data.frame(x, row.names=NULL, optional=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.data.frame.mlbench_+3A_x">x</code></td>
<td>
<p>Object of class <code>"mlbench"</code>.</p>
</td></tr>
<tr><td><code id="as.data.frame.mlbench_+3A_row.names">row.names</code>, <code id="as.data.frame.mlbench_+3A_optional">optional</code>, <code id="as.data.frame.mlbench_+3A_...">...</code></td>
<td>
<p>currently ignored.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- mlbench.xor(5)
p
as.data.frame(p)
</code></pre>

<hr>
<h2 id='bayesclass'>Bayes classifier</h2><span id='topic+bayesclass'></span><span id='topic+bayesclass.noerr'></span><span id='topic+bayesclass.mlbench.2dnormals'></span><span id='topic+bayesclass.mlbench.circle'></span><span id='topic+bayesclass.mlbench.xor'></span><span id='topic+bayesclass.mlbench.cassini'></span><span id='topic+bayesclass.mlbench.cuboids'></span><span id='topic+bayesclass.mlbench.twonorm'></span><span id='topic+bayesclass.mlbench.threenorm'></span><span id='topic+bayesclass.mlbench.ringnorm'></span>

<h3>Description</h3>

<p>Returns the decision of the (optimal) Bayes classifier for a given
data set. This is a generic function, i.e., there are different
methods for the various mlbench problems.
</p>
<p>If the classes of the problem do not overlap, then the Bayes
decision is identical to the true classification, which is
implemented as the dummy function <code>bayesclass.noerr</code> (which
simply returns <code>z$classes</code> and is used for all problems with
disjunct classes).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayesclass(z)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bayesclass_+3A_z">z</code></td>
<td>
<p>An object of class <code>"mlbench"</code>.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># 6 overlapping classes
p &lt;- mlbench.2dnormals(500,6)
plot(p)

plot(p$x, col=as.numeric(bayesclass(p)))
</code></pre>

<hr>
<h2 id='BostonHousing'>Boston Housing Data</h2><span id='topic+BostonHousing'></span><span id='topic+BostonHousing2'></span>

<h3>Description</h3>

<p>Housing data for 506 census tracts of Boston from the 1970
census. The dataframe
<code>BostonHousing</code> contains the original data by Harrison and
Rubinfeld (1979), the dataframe <code>BostonHousing2</code> the corrected
version with additional spatial information (see references below).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BostonHousing)
data(BostonHousing2)
</code></pre>


<h3>Format</h3>

<p>The original data are 506 observations on 14 variables,
<code>medv</code> being the target variable:
</p>

<table>
<tr>
 <td style="text-align: left;">
      crim </td><td style="text-align: left;"> per capita crime rate by town </td>
</tr>
<tr>
 <td style="text-align: left;">
      zn </td><td style="text-align: left;"> proportion of residential land zoned for lots over 25,000 sq.ft </td>
</tr>
<tr>
 <td style="text-align: left;">
      indus </td><td style="text-align: left;"> proportion of non-retail business acres per town </td>
</tr>
<tr>
 <td style="text-align: left;">
      chas </td><td style="text-align: left;"> Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) </td>
</tr>
<tr>
 <td style="text-align: left;">
      nox </td><td style="text-align: left;"> nitric oxides concentration (parts per 10 million) </td>
</tr>
<tr>
 <td style="text-align: left;">
      rm </td><td style="text-align: left;"> average number of rooms per dwelling </td>
</tr>
<tr>
 <td style="text-align: left;">
      age </td><td style="text-align: left;"> proportion of owner-occupied units built prior to 1940 </td>
</tr>
<tr>
 <td style="text-align: left;">
      dis </td><td style="text-align: left;"> weighted distances to five Boston employment centres </td>
</tr>
<tr>
 <td style="text-align: left;">
      rad </td><td style="text-align: left;"> index of accessibility to radial highways </td>
</tr>
<tr>
 <td style="text-align: left;">
      tax </td><td style="text-align: left;"> full-value property-tax rate per USD 10,000 </td>
</tr>
<tr>
 <td style="text-align: left;">
      ptratio </td><td style="text-align: left;"> pupil-teacher ratio by town </td>
</tr>
<tr>
 <td style="text-align: left;">
      b </td><td style="text-align: left;"> <code class="reqn">1000(B - 0.63)^2</code> where <code class="reqn">B</code> is the proportion of blacks by town</td>
</tr>
<tr>
 <td style="text-align: left;">
      lstat </td><td style="text-align: left;"> percentage of lower status of the population </td>
</tr>
<tr>
 <td style="text-align: left;">
      medv </td><td style="text-align: left;"> median value of owner-occupied homes in USD 1000's
    </td>
</tr>

</table>

<p>The corrected data set has the following additional columns:
</p>

<table>
<tr>
 <td style="text-align: left;">
      cmedv </td><td style="text-align: left;"> corrected median value of owner-occupied homes in USD 1000's </td>
</tr>
<tr>
 <td style="text-align: left;">
      town </td><td style="text-align: left;"> name of town </td>
</tr>
<tr>
 <td style="text-align: left;">
      tract </td><td style="text-align: left;"> census tract </td>
</tr>
<tr>
 <td style="text-align: left;">
      lon </td><td style="text-align: left;"> longitude of census tract </td>
</tr>
<tr>
 <td style="text-align: left;">
      lat </td><td style="text-align: left;"> latitude of census tract </td>
</tr>
<tr>
 <td style="text-align: left;">
    </td>
</tr>

</table>



<h3>Source</h3>

<p>The original data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>,
</p>
</li></ul>

<p>the corrected data have been taken from Statlib at
</p>

<ul>
<li> <p><a href="http://lib.stat.cmu.edu/datasets/">http://lib.stat.cmu.edu/datasets/</a>
</p>
</li></ul>

<p>See Statlib and references there for details on the corrections.
Both were converted to R format by Friedrich Leisch.
</p>


<h3>References</h3>

  
<p>Harrison, D. and Rubinfeld, D.L. (1978).
Hedonic prices and the demand for clean air.
<em>Journal of Environmental Economics and Management</em>, <b>5</b>,
81&ndash;102.
</p>
<p>Gilley, O.W., and R. Kelley Pace (1996). On the Harrison and Rubinfeld  
Data. <em>Journal of Environmental Economics and Management</em>, <b>31</b>,  
403&ndash;405. [Provided corrections and examined censoring.]
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>
<p>Pace, R. Kelley, and O.W. Gilley (1997). Using the Spatial Configuration of  
the Data to Improve Estimation. <em>Journal of the Real Estate Finance  
and Economics</em>, <b>14</b>, 333&ndash;340. [Added georeferencing and spatial
estimation.]
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BostonHousing)
summary(BostonHousing)

data(BostonHousing2)
summary(BostonHousing2)
</code></pre>

<hr>
<h2 id='BreastCancer'>Wisconsin Breast Cancer Database</h2><span id='topic+BreastCancer'></span>

<h3>Description</h3>

<p>The objective is to identify each of a number of benign or malignant
classes. Samples arrive periodically as
Dr. Wolberg reports his clinical cases.
The database therefore reflects this chronological grouping of the
data.  This grouping information appears immediately below, having been
removed from the data itself.  Each variable except for the first was
converted into 11 primitive numerical attributes with values ranging
from 0 through 10.  There are 16 missing attribute values. See cited
below for more details.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(BreastCancer)</code></pre>


<h3>Format</h3>

<p>A data frame with 699 observations on 11 variables, one being a
character variable, 9 being ordered or nominal, and 1 target class.
</p>

<table>
<tr>
 <td style="text-align: center;"> 
 [,1] </td><td style="text-align: left;"> Id </td><td style="text-align: left;"> Sample code number</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,2] </td><td style="text-align: left;"> Cl.thickness </td><td style="text-align: left;"> Clump Thickness</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,3] </td><td style="text-align: left;"> Cell.size </td><td style="text-align: left;"> Uniformity of Cell Size</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,4] </td><td style="text-align: left;"> Cell.shape </td><td style="text-align: left;"> Uniformity of Cell Shape</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,5] </td><td style="text-align: left;"> Marg.adhesion  </td><td style="text-align: left;"> Marginal Adhesion</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,6] </td><td style="text-align: left;"> Epith.c.size </td><td style="text-align: left;"> Single Epithelial Cell Size</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,7] </td><td style="text-align: left;"> Bare.nuclei </td><td style="text-align: left;"> Bare Nuclei</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,8] </td><td style="text-align: left;"> Bl.cromatin </td><td style="text-align: left;"> Bland Chromatin</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,9] </td><td style="text-align: left;"> Normal.nucleoli </td><td style="text-align: left;"> Normal Nucleoli</td>
</tr>
<tr>
 <td style="text-align: center;">
[,10] </td><td style="text-align: left;"> Mitoses </td><td style="text-align: left;"> Mitoses</td>
</tr>
<tr>
 <td style="text-align: center;">
[,11] </td><td style="text-align: left;"> Class </td><td style="text-align: left;"> Class
</td>
</tr>

</table>



<h3>Source</h3>


<ul>
<li><p> Creator: Dr. WIlliam H. Wolberg (physician); University of
Wisconsin Hospital ;Madison; Wisconsin; USA 
</p>
</li>
<li><p> Donor: Olvi Mangasarian (mangasarian@cs.wisc.edu)
</p>
</li>
<li><p> Received: David W. Aha (aha@cs.jhu.edu)
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

   
<p>1. Wolberg,W.H., &amp; Mangasarian,O.L. (1990). Multisurface method of 
pattern separation for medical diagnosis applied to breast cytology. In
Proceedings of the National Academy of Sciences, 87,
9193-9196.<br />
- Size of data set: only 369 instances (at that point in time)<br />
- Collected classification results: 1 trial only<br />
- Two pairs of parallel hyperplanes were found to be consistent with
50% of the data<br />
- Accuracy on remaining 50% of dataset: 93.5%<br />
- Three pairs of parallel hyperplanes were found to be consistent with
67% of data<br />
- Accuracy on remaining 33% of dataset: 95.9%
</p>
<p>2. Zhang,J. (1992). Selecting typical instances in instance-based
learning.  In Proceedings of the Ninth International Machine
Learning Conference (pp. 470-479).  Aberdeen, Scotland: Morgan
Kaufmann.<br />
- Size of data set: only 369 instances (at that point in time)<br />
- Applied 4 instance-based learning algorithms<br />
- Collected classification results averaged over 10 trials<br />
- Best accuracy result: <br />
- 1-nearest neighbor: 93.7%<br />
- trained on 200 instances, tested on the other 169<br />
- Also of interest:<br />
- Using only typical instances: 92.2% (storing only 23.1 instances)<br />
- trained on 200 instances, tested on the other 169
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(BreastCancer)
summary(BreastCancer)
</code></pre>

<hr>
<h2 id='DNA'>Primate splice-junction gene sequences (DNA)</h2><span id='topic+DNA'></span>

<h3>Description</h3>

<p>It consists of 3,186 data points (splice junctions). The
data points are described by 180 indicator binary
variables and the problem is to recognize the 3 classes (ei, ie,
neither), i.e., the boundaries between exons (the parts of the DNA
sequence retained after splicing) and introns (the parts of the DNA
sequence that are spliced out).
</p>
<p>The StaLog dna dataset is a processed version of the Irvine 
database described below. The main difference is that the 
symbolic variables representing the nucleotides (only A,G,T,C) 
were replaced by 3 binary indicator variables. Thus the original 
60 symbolic attributes were changed into 180 binary attributes.  
The names of the examples were removed. The examples with 
ambiguities were removed (there was very few of them, 4).   
The StatLog version of this dataset was produced by Ross King
at Strathclyde University. For original details see the Irvine 
database documentation.
</p>
<p>The nucleotides A,C,G,T were given indicator values as follows:
</p>

<table>
<tr>
 <td style="text-align: center;">
    	</td><td style="text-align: left;"> A -&gt; 1 0 0</td>
</tr>
<tr>
 <td style="text-align: center;">
    	</td><td style="text-align: left;"> C -&gt; 0 1 0</td>
</tr>
<tr>
 <td style="text-align: center;">
    	</td><td style="text-align: left;"> G -&gt; 0 0 1</td>
</tr>
<tr>
 <td style="text-align: center;">
    	</td><td style="text-align: left;"> T -&gt; 0 0 0</td>
</tr>
<tr>
 <td style="text-align: center;">
    </td>
</tr>

</table>

<p>Hint. Much better performance is generally observed if attributes
closest to the junction are used. In the StatLog version, this
means using attributes A61 to A120 only.   
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(DNA)</code></pre>


<h3>Format</h3>

<p>A data frame with 3,186 observations on 180 variables, all
nominal and a target class.</p>


<h3>Source</h3>


<ul>
<li><p> Source:<br />
- all examples taken from Genbank 64.1 (ftp site:
genbank.bio.net)<br />
- categories &quot;ei&quot; and &quot;ie&quot; include every &quot;split-gene&quot; 
for primates in Genbank 64.1<br />
- non-splice examples taken from sequences known not to include
a splicing site<br />
</p>
</li>
<li><p> Donor: G. Towell, M. Noordewier, and J. Shavlik, 
towell,shavlik@cs.wisc.edu, noordewi@cs.rutgers.edu
</p>
</li></ul>

<p>These data have been taken from: 
</p>

<ul>
<li><p> ftp.stams.strath.ac.uk/pub/Statlog
</p>
</li></ul>

<p>and were converted to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

<p>machine learning:<br />
&ndash; M. O. Noordewier and G. G. Towell and J. W. Shavlik, 1991; 
&quot;Training Knowledge-Based Neural Networks to Recognize Genes in 
DNA Sequences&quot;.  Advances in Neural Information Processing Systems,
volume 3, Morgan Kaufmann.
</p>
<p>&ndash; G. G. Towell and J. W. Shavlik and M. W. Craven, 1991;  
&quot;Constructive Induction in Knowledge-Based Neural Networks&quot;,  
In Proceedings of the Eighth International Machine Learning
Workshop, Morgan Kaufmann.
</p>
<p>&ndash; G. G. Towell, 1991;
&quot;Symbolic Knowledge and Neural Networks: Insertion, Refinement, and
Extraction&quot;, PhD Thesis, University of Wisconsin - Madison.
</p>
<p>&ndash; G. G. Towell and J. W. Shavlik, 1992;
&quot;Interpretation of Artificial Neural Networks: Mapping 
Knowledge-based Neural Networks into Rules&quot;, In Advances in Neural
Information Processing Systems, volume 4, Morgan Kaufmann.  
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DNA)
summary(DNA)
</code></pre>

<hr>
<h2 id='Glass'>Glass Identification Database</h2><span id='topic+Glass'></span>

<h3>Description</h3>

<p>A data frame with 214 observation containing examples of
the chemical analysis of 7 different types of glass. The problem is to
forecast the type of class on basis of the chemical analysis.  The
study of classification of types of glass was motivated by
criminological investigation.  At the scene of the crime, the glass left
can be used as evidence (if it is correctly identified!).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Glass)</code></pre>


<h3>Format</h3>

<p>A data frame with 214 observations on 10 variables:
</p>

<table>
<tr>
 <td style="text-align: center;">
 [,1] </td><td style="text-align: left;"> RI </td><td style="text-align: left;"> refractive index</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,2] </td><td style="text-align: left;"> Na </td><td style="text-align: left;"> Sodium</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,3] </td><td style="text-align: left;"> Mg </td><td style="text-align: left;"> Magnesium</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,4] </td><td style="text-align: left;"> Al </td><td style="text-align: left;"> Aluminum</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,5] </td><td style="text-align: left;"> Si </td><td style="text-align: left;"> Silicon</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,6] </td><td style="text-align: left;"> K  </td><td style="text-align: left;"> Potassium</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,7] </td><td style="text-align: left;"> Ca </td><td style="text-align: left;"> Calcium</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,8] </td><td style="text-align: left;"> Ba </td><td style="text-align: left;"> Barium</td>
</tr>
<tr>
 <td style="text-align: center;">
 [,9] </td><td style="text-align: left;"> Fe </td><td style="text-align: left;"> Iron </td>
</tr>
<tr>
 <td style="text-align: center;">
[,10] </td><td style="text-align: left;"> Type </td><td style="text-align: left;"> Type of glass (class attribute) </td>
</tr>
<tr>
 <td style="text-align: center;"> 
</td>
</tr>

</table>



<h3>Source</h3>


<ul>
<li><p> Creator: B. German, Central Research Establishment, Home
Office Forensic Science Service, Aldermaston, Reading, Berkshire
RG7 4PN 
</p>
</li>
<li><p> Donor: Vina Spiehler, Ph.D., DABFT, Diagnostic Products
Corporation
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Friedrich Leisch.
</p>


<h3>References</h3>

  
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Glass)
summary(Glass)
</code></pre>

<hr>
<h2 id='HouseVotes84'>United States Congressional Voting Records 1984</h2><span id='topic+HouseVotes84'></span>

<h3>Description</h3>

<p>This data set includes votes for each of the U.S. House of
Representatives Congressmen on the 16 key votes identified by the
CQA.  The CQA lists nine different types of votes: voted for, paired
for, and announced for (these three simplified to yea), voted
against, paired against, and announced against (these three
simplified to nay), voted present, voted present to avoid conflict
of interest, and did not vote or otherwise make a position known
(these three simplified to an unknown disposition).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(HouseVotes84)</code></pre>


<h3>Format</h3>

<p>A data frame with 435 observations on 17 variables:
</p>

<table>
<tr>
 <td style="text-align: right;">
   1 </td><td style="text-align: left;"> Class Name: 2 (democrat, republican)</td>
</tr>
<tr>
 <td style="text-align: right;">
   2 </td><td style="text-align: left;"> handicapped-infants: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
   3 </td><td style="text-align: left;"> water-project-cost-sharing: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
   4 </td><td style="text-align: left;"> adoption-of-the-budget-resolution: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
   5 </td><td style="text-align: left;"> physician-fee-freeze: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
   6 </td><td style="text-align: left;"> el-salvador-aid: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
   7 </td><td style="text-align: left;"> religious-groups-in-schools: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
   8 </td><td style="text-align: left;"> anti-satellite-test-ban: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
   9 </td><td style="text-align: left;"> aid-to-nicaraguan-contras: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
  10 </td><td style="text-align: left;"> mx-missile: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
  11 </td><td style="text-align: left;"> immigration: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
  12 </td><td style="text-align: left;"> synfuels-corporation-cutback: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
  13 </td><td style="text-align: left;"> education-spending: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
  14 </td><td style="text-align: left;"> superfund-right-to-sue: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
  15 </td><td style="text-align: left;"> crime: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
  16 </td><td style="text-align: left;"> duty-free-exports: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
  17 </td><td style="text-align: left;"> export-administration-act-south-africa: 2 (y,n)</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td>
</tr>

</table>



<h3>Source</h3>


<ul>
<li><p> Source: Congressional Quarterly Almanac, 98th Congress,
2nd session 1984, Volume XL: Congressional Quarterly Inc.,
ington, D.C., 1985
</p>
</li>
<li><p> Donor: Jeff Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Friedrich Leisch.
</p>


<h3>References</h3>

  
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(HouseVotes84)
summary(HouseVotes84)
</code></pre>

<hr>
<h2 id='Ionosphere'>Johns Hopkins University Ionosphere database</h2><span id='topic+Ionosphere'></span>

<h3>Description</h3>

<p>This radar data was collected by a system in Goose Bay, Labrador.  This
system consists of a phased array of 16 high-frequency antennas with a
total transmitted power on the order of 6.4 kilowatts.  See the paper
for more details.  The targets were free electrons in the ionosphere.
&quot;good&quot; radar returns are those showing evidence of some type of structure 
in the ionosphere.  &quot;bad&quot; returns are those that do not; their signals pass
through the ionosphere.  
</p>
<p>Received signals were processed using an autocorrelation function whose
arguments are the time of a pulse and the pulse number.  There were 17
pulse numbers for the Goose Bay system.  Instances in this databse are
described by 2 attributes per pulse number, corresponding to the complex
values returned by the function resulting from the complex electromagnetic
signal. See cited below for more details.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Ionosphere)</code></pre>


<h3>Format</h3>

<p>A data frame with 351 observations on 35 independent variables, some 
numerical and 2 nominal, and one last defining the class.</p>


<h3>Source</h3>


<ul>
<li><p> Source: Space Physics Group; Applied Physics Laboratory;
Johns Hopkins University; Johns Hopkins Road; Laurel; MD 20723 
</p>
</li>
<li><p> Donor: Vince Sigillito (vgs@aplcen.apl.jhu.edu)
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

<p>Sigillito, V. G., Wing, S. P., Hutton, L. V., &amp; Baker, K. B. (1989).
Classification of radar returns from the ionosphere using neural 
networks. Johns Hopkins APL Technical Digest, 10, 262-266.
</p>
<p>They investigated using backprop and the perceptron training algorithm
on this database.  Using the first 200 instances for training, which
were carefully split almost 50% positive and 50% negative, they found
that a &quot;linear&quot; perceptron attained 90.7%, a &quot;non-linear&quot; perceptron
attained 92%, and backprop an average of over 96% accuracy on the 
remaining 150 test instances, consisting of 123 &quot;good&quot; and only 24 &quot;bad&quot;
instances.  (There was a counting error or some mistake somewhere; there
are a total of 351 rather than 350 instances in this domain.) Accuracy
on &quot;good&quot; instances was much higher than for &quot;bad&quot; instances.  Backprop
was tested with several different numbers of hidden units (in [0,15])
and incremental results were also reported (corresponding to how well
the different variants of backprop did after a periodic number of 
epochs).
</p>
<p>David Aha (aha@ics.uci.edu) briefly investigated this database.
He found that nearest neighbor attains an accuracy of 92.1%, that
Ross Quinlan's C4 algorithm attains 94.0% (no windowing), and that
IB3 (Aha &amp; Kibler, IJCAI-1989) attained 96.7% (parameter settings:
70% and 80% for acceptance and dropping respectively).
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Ionosphere)
summary(Ionosphere)
</code></pre>

<hr>
<h2 id='LetterRecognition'>Letter Image Recognition Data</h2><span id='topic+LetterRecognition'></span>

<h3>Description</h3>

<p>The objective is to identify each of a large number of black-and-white
rectangular pixel displays as one of the 26 capital letters in the English
alphabet.  The character images were based on 20 different fonts and each
letter within these 20 fonts was randomly distorted to produce a file of
20,000 unique stimuli.  Each stimulus was converted into 16 primitive
numerical attributes (statistical moments and edge counts) which were then
scaled to fit into a range of integer values from 0 through 15.  We
typically train on the first 16000 items and then use the resulting model
to predict the letter category for the remaining 4000.  See the article
cited below for more details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(LetterRecognition)</code></pre>


<h3>Format</h3>

<p>A data frame with 20,000 observations on 17 variables, the first
is a factor with levels A-Z, the remaining 16 are numeric.
</p>

<table>
<tr>
 <td style="text-align: right;">
 [,1] </td><td style="text-align: left;"> lettr </td><td style="text-align: left;">  capital letter</td>
</tr>
<tr>
 <td style="text-align: right;">
 [,2] </td><td style="text-align: left;"> x.box </td><td style="text-align: left;">  horizontal position of box</td>
</tr>
<tr>
 <td style="text-align: right;">
 [,3] </td><td style="text-align: left;"> y.box </td><td style="text-align: left;">  vertical position of box</td>
</tr>
<tr>
 <td style="text-align: right;">
 [,4] </td><td style="text-align: left;"> width </td><td style="text-align: left;">  width of box</td>
</tr>
<tr>
 <td style="text-align: right;">
 [,5] </td><td style="text-align: left;"> high  </td><td style="text-align: left;">  height of box</td>
</tr>
<tr>
 <td style="text-align: right;">
 [,6] </td><td style="text-align: left;"> onpix </td><td style="text-align: left;">  total number of on pixels</td>
</tr>
<tr>
 <td style="text-align: right;">
 [,7] </td><td style="text-align: left;"> x.bar </td><td style="text-align: left;">  mean x of on pixels in box</td>
</tr>
<tr>
 <td style="text-align: right;">
 [,8] </td><td style="text-align: left;"> y.bar </td><td style="text-align: left;">  mean y of on pixels in box</td>
</tr>
<tr>
 <td style="text-align: right;">
 [,9] </td><td style="text-align: left;"> x2bar </td><td style="text-align: left;">  mean x variance</td>
</tr>
<tr>
 <td style="text-align: right;">
[,10] </td><td style="text-align: left;"> y2bar </td><td style="text-align: left;">  mean y variance</td>
</tr>
<tr>
 <td style="text-align: right;">
[,11] </td><td style="text-align: left;"> xybar </td><td style="text-align: left;">  mean x y correlation</td>
</tr>
<tr>
 <td style="text-align: right;">
[,12] </td><td style="text-align: left;"> x2ybr </td><td style="text-align: left;">  mean of <code class="reqn">x^2 y</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
[,13] </td><td style="text-align: left;"> xy2br </td><td style="text-align: left;">  mean of <code class="reqn">x y^2</code> </td>
</tr>
<tr>
 <td style="text-align: right;">
[,14] </td><td style="text-align: left;"> x.ege </td><td style="text-align: left;">  mean edge count left to right</td>
</tr>
<tr>
 <td style="text-align: right;">
[,15] </td><td style="text-align: left;"> xegvy </td><td style="text-align: left;">  correlation of x.ege with y</td>
</tr>
<tr>
 <td style="text-align: right;">
[,16] </td><td style="text-align: left;"> y.ege </td><td style="text-align: left;">  mean edge count bottom to top</td>
</tr>
<tr>
 <td style="text-align: right;">
[,17] </td><td style="text-align: left;"> yegvx </td><td style="text-align: left;">  correlation of y.ege with x</td>
</tr>
<tr>
 <td style="text-align: right;">
    </td>
</tr>

</table>



<h3>Source</h3>


<ul>
<li><p> Creator: David J. Slate
</p>
</li>
<li><p> Odesta Corporation; 1890 Maple Ave; Suite 115; Evanston, IL 60201
</p>
</li>
<li><p> Donor: David J. Slate (dave@math.nwu.edu) (708) 491-3867   
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Friedrich Leisch.
</p>


<h3>References</h3>

<p>P. W. Frey and D. J. Slate (Machine Learning Vol 6/2 March 91):
&quot;Letter Recognition Using Holland-style Adaptive Classifiers&quot;.
</p>
<p>The research for this article investigated the ability of several
variations of Holland-style adaptive classifier systems to learn to
correctly guess the letter categories associated with vectors of 16
integer attributes extracted from raster scan images of the letters.
The best accuracy obtained was a little over 80%.  It would be
interesting to see how well other methods do with the same data.
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(LetterRecognition)
summary(LetterRecognition)
</code></pre>

<hr>
<h2 id='mlbench.2dnormals'>2-dimensional Gaussian Problem</h2><span id='topic+mlbench.2dnormals'></span>

<h3>Description</h3>

<p>Each of the <code>cl</code> classes consists of a 2-dimensional
Gaussian. The centers are equally spaced on a circle around the
origin with radius <code>r</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.2dnormals(n, cl=2, r=sqrt(cl), sd=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.2dnormals_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.2dnormals_+3A_cl">cl</code></td>
<td>
<p>number of classes</p>
</td></tr>
<tr><td><code id="mlbench.2dnormals_+3A_r">r</code></td>
<td>
<p>radius at which the centers of the classes are located</p>
</td></tr>
<tr><td><code id="mlbench.2dnormals_+3A_sd">sd</code></td>
<td>
<p>standard deviation of the Gaussians</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"bayes.2dnormals"</code> with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>Examples</h3>

<pre><code class='language-R'># 2 classes
p &lt;- mlbench.2dnormals(500,2)
plot(p)
# 6 classes
p &lt;- mlbench.2dnormals(500,6)
plot(p)
</code></pre>

<hr>
<h2 id='mlbench.cassini'>Cassini: A 2 Dimensional Problem</h2><span id='topic+mlbench.cassini'></span>

<h3>Description</h3>

<p>The inputs of the cassini problem are uniformly distributed on
a <code>2</code>-dimensional space within 3 structures. The 2 external
structures (classes) are banana-shaped structures and in between them, the
middle structure (class) is a circle.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.cassini(n, relsize=c(2,2,1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.cassini_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.cassini_+3A_relsize">relsize</code></td>
<td>
<p>relative size of the classes (vector of length 3)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.cassini"</code>  with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Evgenia Dimitriadou and Andreas Weingessel</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- mlbench.cassini(5000)
plot(p)
</code></pre>

<hr>
<h2 id='mlbench.circle'>Circle in a Square Problem</h2><span id='topic+mlbench.circle'></span>

<h3>Description</h3>

<p>The inputs of the circle problem are uniformly distributed on
the <code>d</code>-dimensional cube with corners <code class="reqn">\{\pm 1\}</code>. 
This is a 2-class problem: The first class is a <code>d</code>-dimensional
ball in the middle of the cube, the remainder forms the second
class. The size of the ball is chosen such that both classes have equal
prior probability 0.5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.circle(n, d=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.circle_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.circle_+3A_d">d</code></td>
<td>
<p>dimension of the circle problem</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.circle"</code>  with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>Examples</h3>

<pre><code class='language-R'># 2d example
p&lt;-mlbench.circle(300,2)
plot(p)
#
# 3d example
p&lt;-mlbench.circle(300,3)
plot(p)
</code></pre>

<hr>
<h2 id='mlbench.cuboids'>Cuboids: A 3 Dimensional Problem</h2><span id='topic+mlbench.cuboids'></span>

<h3>Description</h3>

<p>The inputs of the cuboids problem are uniformly distributed on
a <code>3</code>-dimensional space within 3 cuboids and a small
cube in the middle of them. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.cuboids(n, relsize=c(2,2,2,1))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.cuboids_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.cuboids_+3A_relsize">relsize</code></td>
<td>
<p>relative size of the classes (vector of length 4)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.cuboids"</code>  with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>Author(s)</h3>

<p>Evgenia Dimitriadou, and Andreas Weingessel</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- mlbench.cuboids(7000)
plot(p)
## Not run: 
library(Rggobi)
g &lt;- ggobi(p$x)
g$setColors(p$class)
g$setMode("2D Tour")

## End(Not run)</code></pre>

<hr>
<h2 id='mlbench.friedman1'>Benchmark Problem Friedman 1</h2><span id='topic+mlbench.friedman1'></span>

<h3>Description</h3>

<p>The regression problem Friedman 1 as described in Friedman (1991) and
Breiman (1996). Inputs are 10 independent variables uniformly
distributed on the interval <code class="reqn">[0,1]</code>, only 5 out of these 10 are actually
used. Outputs are created according to
the formula
</p>
<p style="text-align: center;"><code class="reqn">y = 10 \sin(\pi x1 x2) + 20 (x3 - 0.5)^2 + 10 x4 + 5 x5 + e</code>
</p>

<p>where e is N(0,sd).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.friedman1(n, sd=1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.friedman1_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.friedman1_+3A_sd">sd</code></td>
<td>
<p>Standard deviation of noise</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values (independent variables)</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>output values (dependent variable)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages
123-140.
</p>
<p>Friedman, Jerome H. (1991) Multivariate adaptive regression
splines. The Annals of Statistics 19 (1), pages 1-67. 
</p>

<hr>
<h2 id='mlbench.friedman2'>Benchmark Problem Friedman 2</h2><span id='topic+mlbench.friedman2'></span>

<h3>Description</h3>

<p>The regression problem Friedman 2 as described in Friedman (1991) and
Breiman (1996). Inputs are 4 independent variables uniformly
distrtibuted over the ranges
</p>
<p style="text-align: center;"><code class="reqn">0 \le x1 \le 100</code>
</p>

<p style="text-align: center;"><code class="reqn">40 \pi \le x2 \le 560 \pi</code>
</p>

<p style="text-align: center;"><code class="reqn">0 \le x3 \le 1</code>
</p>

<p style="text-align: center;"><code class="reqn">1 \le x4 \le 11</code>
</p>

<p>The outputs are created according to the formula
</p>
<p style="text-align: center;"><code class="reqn">y = (x1^2 + (x2 x3 - (1/(x2 x4)))^2)^{0.5} + e</code>
</p>

<p>where e is N(0,sd).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.friedman2(n, sd=125)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.friedman2_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.friedman2_+3A_sd">sd</code></td>
<td>
<p>Standard deviation of noise. The default value of 125 gives
a signal to noise ratio (i.e., the ratio of the standard deviations) of
3:1. Thus, the variance of the function itself (without noise)
accounts for 90% of the total variance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values (independent variables)</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>output values (dependent variable)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages
123-140.
</p>
<p>Friedman, Jerome H. (1991) Multivariate adaptive regression
splines. The Annals of Statistics 19 (1), pages 1-67. 
</p>

<hr>
<h2 id='mlbench.friedman3'>Benchmark Problem Friedman 3</h2><span id='topic+mlbench.friedman3'></span>

<h3>Description</h3>

<p>The regression problem Friedman 3 as described in Friedman (1991) and
Breiman (1996). Inputs are 4 independent variables uniformly
distrtibuted over the ranges
</p>
<p style="text-align: center;"><code class="reqn">0 \le x1 \le 100</code>
</p>

<p style="text-align: center;"><code class="reqn">40 \pi \le x2 \le 560 \pi</code>
</p>

<p style="text-align: center;"><code class="reqn">0 \le x3 \le 1</code>
</p>

<p style="text-align: center;"><code class="reqn">1 \le x4 \le 11</code>
</p>

<p>The outputs are created according to the formula
</p>
<p style="text-align: center;"><code class="reqn">y = \mbox{atan}((x2 x3 - (1/(x2 x4)))/x1) + e</code>
</p>

<p>where e is N(0,sd).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.friedman3(n, sd=0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.friedman3_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.friedman3_+3A_sd">sd</code></td>
<td>
<p>Standard deviation of noise. The default value of 0.1 gives
a signal to noise ratio (i.e., the ratio of the standard deviations) of
3:1. Thus, the variance of the function itself (without noise)
accounts for 90% of the total variance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values (independent variables)</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>output values (dependent variable)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Breiman, Leo (1996) Bagging predictors. Machine Learning 24, pages
123-140.
</p>
<p>Friedman, Jerome H. (1991) Multivariate adaptive regression
splines. The Annals of Statistics 19 (1), pages 1-67. 
</p>

<hr>
<h2 id='mlbench.hypercube'>Corners of Hypercube</h2><span id='topic+mlbench.corners'></span><span id='topic+mlbench.hypercube'></span><span id='topic+hypercube'></span>

<h3>Description</h3>

<p>The created data are <code>d</code>-dimensional spherical Gaussians with standard
deviation <code>sd</code> and means at the corners of a
<code>d</code>-dimensional hypercube. The number of classes is <code class="reqn">2^d</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.hypercube(n=800, d=3, sides=rep(1,d), sd=0.1)
hypercube(d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.hypercube_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.hypercube_+3A_d">d</code></td>
<td>
<p>dimensionality of hypercube, default is 3</p>
</td></tr>
<tr><td><code id="mlbench.hypercube_+3A_sides">sides</code></td>
<td>
<p>lengths of the sides of the hypercube, default is to
create a unit hypercube</p>
</td></tr>
<tr><td><code id="mlbench.hypercube_+3A_sd">sd</code></td>
<td>
<p>standard deviation</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.hypercube"</code>  with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor of length <code>n</code> with target classes</p>
</td></tr> </table>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- mlbench.hypercube()
plot(p)

library("lattice")
cloud(x.3~x.1+x.2, groups=classes, data=as.data.frame(p))
</code></pre>

<hr>
<h2 id='mlbench.peak'>Peak Benchmark Problem</h2><span id='topic+mlbench.peak'></span>

<h3>Description</h3>

<p>Let <code class="reqn">r=3u</code> where u is uniform on
[0,1]. Take x to be uniformly distributed on the d-dimensional
sphere of radius r. Let <code class="reqn">y=25exp(-.5r^2)</code>. This data set is not a
classification problem but a regression problem where y is the
dependent variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.peak(n, d=20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.peak_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.peak_+3A_d">d</code></td>
<td>
<p>dimension of the problem</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values (independent variables)</p>
</td></tr>
<tr><td><code>y</code></td>
<td>
<p>output values (dependent variable)</p>
</td></tr>
</table>

<hr>
<h2 id='mlbench.ringnorm'>Ringnorm Benchmark Problem</h2><span id='topic+mlbench.ringnorm'></span>

<h3>Description</h3>

<p>The inputs of the ringnorm problem are points from two Gaussian
distributions. Class 1 is multivariate normal with mean 0 and
covariance 4 times the identity matrix. Class 2 has unit covariance
and mean <code class="reqn">(a,a,\ldots,a)</code>, <code class="reqn">a=d^{-0.5}</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.ringnorm(n, d=20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.ringnorm_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.ringnorm_+3A_d">d</code></td>
<td>
<p>dimension of the ringnorm problem</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.ringnorm"</code> with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>References</h3>

<p>Breiman, L. (1996). Bias, variance, and arcing classifiers.
Tech. Rep. 460, Statistics Department, University of California,
Berkeley, CA, USA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p&lt;-mlbench.ringnorm(1000, d=2)
plot(p)
</code></pre>

<hr>
<h2 id='mlbench.shapes'>Shapes in 2d</h2><span id='topic+mlbench.shapes'></span>

<h3>Description</h3>

<p>A Gaussian, square, triangle and wave in 2 dimensions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.shapes(n=500)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.shapes_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.shapes"</code>  with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>Examples</h3>

<pre><code class='language-R'>p&lt;-mlbench.shapes()
plot(p)
</code></pre>

<hr>
<h2 id='mlbench.simplex'>Corners of d-dimensional Simplex</h2><span id='topic+mlbench.simplex'></span><span id='topic+simplex'></span>

<h3>Description</h3>

<p>The created data are <code>d</code>-dimensional spherical Gaussians with standard
deviation <code>sd</code> and means at the corners of a
<code>d</code>-dimensional simplex. The number of classes is <code>d+1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.simplex(n = 800, d = 3, sides = 1, sd = 0.1, center=TRUE)
simplex(d, sides, center=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.simplex_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.simplex_+3A_d">d</code></td>
<td>
<p>dimensionality of simplex, default is 3</p>
</td></tr>
<tr><td><code id="mlbench.simplex_+3A_sides">sides</code></td>
<td>
<p>lengths of the sides of the simplex, default is to
create a unit simplex</p>
</td></tr>
<tr><td><code id="mlbench.simplex_+3A_sd">sd</code></td>
<td>
<p>standard deviation</p>
</td></tr>
<tr><td><code id="mlbench.simplex_+3A_center">center</code></td>
<td>
<p>If <code>TRUE</code>, the origin is the center of gravity of
the simplex. If <code>FALSE</code>, the origin is a corner of the
simplex and all coordinates of the simplex are positive.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.simplex"</code>  with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor of length <code>n</code> with target classes</p>
</td></tr> </table>


<h3>Author(s)</h3>

<p>Manuel Eugster and Sebastian Kaiser 
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p &lt;- mlbench.simplex()
plot(p)

library("lattice")
cloud(x.3~x.1+x.2, groups=classes, data=as.data.frame(p))
</code></pre>

<hr>
<h2 id='mlbench.smiley'>The Smiley</h2><span id='topic+mlbench.smiley'></span>

<h3>Description</h3>

<p>The smiley consists of 2 Gaussian eyes, a trapezoid nose and a
parabula mouth (with vertical Gaussian noise).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.smiley(n=500, sd1 = 0.1, sd2 = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.smiley_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.smiley_+3A_sd1">sd1</code></td>
<td>
<p>standard deviation for eyes</p>
</td></tr>
<tr><td><code id="mlbench.smiley_+3A_sd2">sd2</code></td>
<td>
<p>standard deviation for mouth</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.smiley"</code>  with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>Examples</h3>

<pre><code class='language-R'>p&lt;-mlbench.smiley()
plot(p)
</code></pre>

<hr>
<h2 id='mlbench.spirals'>Two Spirals Benchmark Problem</h2><span id='topic+mlbench.spirals'></span><span id='topic+mlbench.1spiral'></span>

<h3>Description</h3>

<p>The inputs of the spirals problem are points on two entangled spirals. If
<code>sd&gt;0</code>, then Gaussian noise is added to each data
point. <code>mlbench.1spiral</code> creates a single spiral.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.spirals(n, cycles=1, sd=0)
mlbench.1spiral(n, cycles=1, sd=0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.spirals_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.spirals_+3A_cycles">cycles</code></td>
<td>
<p>the number of cycles each spiral makes</p>
</td></tr>
<tr><td><code id="mlbench.spirals_+3A_sd">sd</code></td>
<td>
<p>standard deviation of data points around the spirals</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.spirals"</code> with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>Examples</h3>

<pre><code class='language-R'># 1 cycle each, no noise
p&lt;-mlbench.spirals(300)
plot(p)
#
# 1.5 cycles each, with noise
p&lt;-mlbench.spirals(300,1.5,0.05)
plot(p)
</code></pre>

<hr>
<h2 id='mlbench.threenorm'>Threenorm Benchmark Problem</h2><span id='topic+mlbench.threenorm'></span>

<h3>Description</h3>

<p>The inputs of the threenorm problem are points from two Gaussian
distributions with unit covariance matrix. Class 1 is drawn with
equal probability from a unit multivariate normal with mean
<code class="reqn">(a,a,\ldots,a)</code> and from a unit multivariate normal with mean 
<code class="reqn">(-a,-a,\ldots,-a)</code>. Class 2 is drawn from a multivariate normal
with mean at <code class="reqn">(a,-a,a, \ldots,-a)</code>, <code class="reqn">a=2/d^{0.5}</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.threenorm(n, d=20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.threenorm_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.threenorm_+3A_d">d</code></td>
<td>
<p>dimension of the threenorm problem</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.threenorm"</code> with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>References</h3>

<p>Breiman, L. (1996). Bias, variance, and arcing classifiers.
Tech. Rep. 460, Statistics Department, University of California,
Berkeley, CA, USA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p&lt;-mlbench.threenorm(1000, d=2)
plot(p)
</code></pre>

<hr>
<h2 id='mlbench.twonorm'>Twonorm Benchmark Problem</h2><span id='topic+mlbench.twonorm'></span>

<h3>Description</h3>

<p>The inputs of the twonorm problem are points from two Gaussian
distributions with unit covariance matrix. Class 1 is multivariate
normal with mean <code class="reqn">(a,a,\ldots,a)</code> and class 2 with mean
<code class="reqn">(-a,-a,\ldots,-a)</code>, <code class="reqn">a=2/d^{0.5}</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.twonorm(n, d=20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.twonorm_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.twonorm_+3A_d">d</code></td>
<td>
<p>dimension of the twonorm problem</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.twonorm"</code> with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>References</h3>

<p>Breiman, L. (1996). Bias, variance, and arcing classifiers.
Tech. Rep. 460, Statistics Department, University of California,
Berkeley, CA, USA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p&lt;-mlbench.twonorm(1000, d=2)
plot(p)
</code></pre>

<hr>
<h2 id='mlbench.waveform'>Waveform Database Generator</h2><span id='topic+mlbench.waveform'></span>

<h3>Description</h3>

<p>The generated data set consists of 21 attributes with continuous
values and a variable showing the 3 classes (33% for each of 3
classes). Each class is generated from a combination of 2 of 3
&quot;base&quot; waves. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  mlbench.waveform(n)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.waveform_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.waveform"</code> with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor vector of length <code>n</code> with target classes</p>
</td></tr>
</table>


<h3>Source</h3>

<p>The original C code for the waveform generator hase been taken
from the UCI Repository
of Machine Learning Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>The C code has been modified to use R's random number generator
by Friedrich Leisch, who also wrote the R interface.
</p>


<h3>References</h3>

<p>Breiman, L. (1996). Bias, variance, and arcing
classifiers. Tech. Rep. 460, Statistics Department, University of
California, Berkeley, CA, USA.
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  p&lt;-mlbench.waveform(100)
  plot(p)
</code></pre>

<hr>
<h2 id='mlbench.xor'>Continuous XOR Benchmark Problem</h2><span id='topic+mlbench.xor'></span>

<h3>Description</h3>

<p>The inputs of the XOR problem are uniformly distributed on
the <code>d</code>-dimensional cube with corners <code class="reqn">\{\pm 1\}</code>. Each pair of
opposite corners form one class, hence the total number of classes is
<code class="reqn">2^(d-1)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlbench.xor(n, d=2)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlbench.xor_+3A_n">n</code></td>
<td>
<p>number of patterns to create</p>
</td></tr>
<tr><td><code id="mlbench.xor_+3A_d">d</code></td>
<td>
<p>dimension of the XOR problem</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>"mlbench.xor"</code> with components
</p>
<table>
<tr><td><code>x</code></td>
<td>
<p>input values</p>
</td></tr>
<tr><td><code>classes</code></td>
<td>
<p>factor vector of length <code>n</code> with target classes</p>
</td></tr> 
</table>


<h3>Examples</h3>

<pre><code class='language-R'># 2d example
p&lt;-mlbench.xor(300,2)
plot(p)
#
# 3d example
p&lt;-mlbench.xor(300,3)
plot(p)
</code></pre>

<hr>
<h2 id='Ozone'>Los Angeles ozone pollution data, 1976</h2><span id='topic+Ozone'></span>

<h3>Description</h3>

<p>A data frame with 366 observations on 13 variables, each
observation is one day</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Ozone)</code></pre>


<h3>Format</h3>


<table>
<tr>
 <td style="text-align: right;">
   1 </td><td style="text-align: left;"> Month: 1 = January, ..., 12 = December</td>
</tr>
<tr>
 <td style="text-align: right;">
   2 </td><td style="text-align: left;"> Day of month</td>
</tr>
<tr>
 <td style="text-align: right;">
   3 </td><td style="text-align: left;"> Day of week: 1 = Monday, ..., 7 = Sunday</td>
</tr>
<tr>
 <td style="text-align: right;">
   4 </td><td style="text-align: left;"> Daily maximum one-hour-average ozone reading</td>
</tr>
<tr>
 <td style="text-align: right;">
   5 </td><td style="text-align: left;"> 500 millibar pressure height (m) measured at Vandenberg AFB</td>
</tr>
<tr>
 <td style="text-align: right;">
   6 </td><td style="text-align: left;"> Wind speed (mph) at Los Angeles International Airport (LAX)</td>
</tr>
<tr>
 <td style="text-align: right;">
   7 </td><td style="text-align: left;"> Humidity (%) at LAX</td>
</tr>
<tr>
 <td style="text-align: right;">
   8 </td><td style="text-align: left;"> Temperature (degrees F) measured at Sandburg, CA</td>
</tr>
<tr>
 <td style="text-align: right;">
   9 </td><td style="text-align: left;"> Temperature (degrees F) measured at El Monte, CA</td>
</tr>
<tr>
 <td style="text-align: right;">
  10 </td><td style="text-align: left;"> Inversion base height (feet) at LAX</td>
</tr>
<tr>
 <td style="text-align: right;">
  11 </td><td style="text-align: left;"> Pressure gradient (mm Hg) from LAX to Daggett, CA</td>
</tr>
<tr>
 <td style="text-align: right;">
  12 </td><td style="text-align: left;"> Inversion base temperature (degrees F) at LAX</td>
</tr>
<tr>
 <td style="text-align: right;">
  13 </td><td style="text-align: left;"> Visibility (miles) measured at LAX</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td>
</tr>

</table>



<h3>Details</h3>

<p>The problem is to predict the daily maximum one-hour-average
ozone reading (V4).
</p>


<h3>Source</h3>

<p>Leo Breiman, Department of Statistics, UC Berkeley.  Data used in
Leo Breiman and Jerome H. Friedman (1985), Estimating optimal
transformations for multiple regression and correlation, JASA, 80, pp.
580-598.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Ozone)
summary(Ozone)
</code></pre>

<hr>
<h2 id='PimaIndiansDiabetes'>Pima Indians Diabetes Database</h2><span id='topic+PimaIndiansDiabetes'></span><span id='topic+PimaIndiansDiabetes2'></span>

<h3>Description</h3>

<p>A data frame with 768 observations on 9 variables.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(PimaIndiansDiabetes)
  data(PimaIndiansDiabetes2)
</code></pre>


<h3>Format</h3>


<table>
<tr>
 <td style="text-align: right;">
      pregnant </td><td style="text-align: left;"> Number of times pregnant</td>
</tr>
<tr>
 <td style="text-align: right;">
      glucose </td><td style="text-align: left;"> Plasma glucose concentration (glucose tolerance test)</td>
</tr>
<tr>
 <td style="text-align: right;">
      pressure </td><td style="text-align: left;"> Diastolic blood pressure (mm Hg)</td>
</tr>
<tr>
 <td style="text-align: right;">
      triceps </td><td style="text-align: left;"> Triceps skin fold thickness (mm)</td>
</tr>
<tr>
 <td style="text-align: right;">
      insulin </td><td style="text-align: left;"> 2-Hour serum insulin (mu U/ml)</td>
</tr>
<tr>
 <td style="text-align: right;">
      mass </td><td style="text-align: left;"> Body mass index (weight in kg/(height in m)^2)</td>
</tr>
<tr>
 <td style="text-align: right;">
      pedigree </td><td style="text-align: left;"> Diabetes pedigree function</td>
</tr>
<tr>
 <td style="text-align: right;">
      age </td><td style="text-align: left;"> Age (years)</td>
</tr>
<tr>
 <td style="text-align: right;">
      diabetes </td><td style="text-align: left;"> Class variable (test for diabetes)</td>
</tr>
<tr>
 <td style="text-align: right;">
  </td>
</tr>

</table>



<h3>Details</h3>

<p>The data set <code>PimaIndiansDiabetes2</code> contains a corrected
version of the original data set. While the UCI repository index
claims that there are no missing values, closer inspection of the data
shows several physical impossibilities, e.g., blood pressure or body
mass index of 0. In <code>PimaIndiansDiabetes2</code>, all zero values of
<code>glucose</code>, <code>pressure</code>, <code>triceps</code>, <code>insulin</code> and
<code>mass</code> have been set to <code>NA</code>, see also Wahba et al (1995)
and Ripley (1996).
</p>


<h3>Source</h3>


<ul>
<li><p> Original owners: National Institute of Diabetes and Digestive and
Kidney Diseases
</p>
</li>
<li><p> Donor of database: Vincent Sigillito
(vgs@aplcen.apl.jhu.edu)
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Friedrich Leisch.
</p>


<h3>References</h3>

<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>
<p>Brian D. Ripley (1996), Pattern Recognition and Neural Networks,
Cambridge University Press, Cambridge.
</p>
<p>Grace Whaba, Chong Gu, Yuedong Wang, and Richard Chappell (1995),
Soft Classification a.k.a. Risk Estimation via Penalized Log
Likelihood and Smoothing Spline Analysis of Variance, in D. H.
Wolpert (1995), The Mathematics of Generalization, 331-359,
Addison-Wesley, Reading, MA.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(PimaIndiansDiabetes)
  summary(PimaIndiansDiabetes)

  data(PimaIndiansDiabetes2)
  summary(PimaIndiansDiabetes2)
</code></pre>

<hr>
<h2 id='plot.mlbench'>Plot mlbench objects</h2><span id='topic+plot.mlbench'></span>

<h3>Description</h3>

<p>Plots the data of an mlbench object using different colors for each
class. If the dimension of the input space is larger that 2, a
scatter plot matrix is used.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlbench'
plot(x, xlab="", ylab="", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mlbench_+3A_x">x</code></td>
<td>
<p>Object of class <code>"mlbench"</code>.</p>
</td></tr>
<tr><td><code id="plot.mlbench_+3A_xlab">xlab</code></td>
<td>
<p>Label for x-axis.</p>
</td></tr>
<tr><td><code id="plot.mlbench_+3A_ylab">ylab</code></td>
<td>
<p>Label for y-axis.</p>
</td></tr>
<tr><td><code id="plot.mlbench_+3A_...">...</code></td>
<td>
<p>Further plotting options.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># 6 normal classes
p &lt;- mlbench.2dnormals(500,6)
plot(p)

# 4-dimensiona XOR
p &lt;- mlbench.xor(500,4)
plot(p)
</code></pre>

<hr>
<h2 id='Satellite'>Landsat Multi-Spectral Scanner Image Data</h2><span id='topic+Satellite'></span>

<h3>Description</h3>

<p>The database consists of the multi-spectral values of pixels in 3x3
neighbourhoods in a satellite image, and the classification associated
with the central pixel in each neighbourhood.  The aim is to predict
this classification, given the multi-spectral values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Satellite)</code></pre>


<h3>Format</h3>

<p>A data frame with 36 inputs (<code>x.1 ... x.36</code>) and one target
(<code>classes</code>).
</p>


<h3>Details</h3>

<p>One frame of Landsat MSS imagery consists of four digital images of
the same scene in different spectral bands.  Two of these are in the
visible region (corresponding approximately to green and red regions
of the visible spectrum) and two are in the (near) infra-red.  Each
pixel is a 8-bit binary word, with 0 corresponding to black and 255 to
white. The spatial resolution of a pixel is about 80m x 80m.  Each
image contains 2340 x 3380 such pixels.
</p>
<p>The database is a (tiny) sub-area of a scene, consisting of 82 x 100
pixels. Each line of data corresponds to a 3x3 square neighbourhood of
pixels completely contained within the 82x100 sub-area.  Each line
contains the pixel values in the four spectral bands (converted to
ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number
indicating the classification label of the central pixel.
</p>
<p>The classes are
</p>

<table>
<tr>
 <td style="text-align: left;">
    red soil</td>
</tr>
<tr>
 <td style="text-align: left;">
    cotton crop</td>
</tr>
<tr>
 <td style="text-align: left;">
    grey soil</td>
</tr>
<tr>
 <td style="text-align: left;">
    damp grey soil</td>
</tr>
<tr>
 <td style="text-align: left;">
    soil with vegetation stubble</td>
</tr>
<tr>
 <td style="text-align: left;">
    very damp grey soil</td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>The data is given in random order and certain lines of data have been
removed so you cannot reconstruct the original image from this
dataset.
</p>
<p>In each line of data the four spectral values for the top-left pixel
are given first followed by the four spectral values for the
top-middle pixel and then those for the top-right pixel, and so on
with the pixels read out in sequence left-to-right and top-to-bottom.
Thus, the four spectral values for the central pixel are given by
attributes 17,18,19 and 20.  If you like you can use only these four
attributes, while ignoring the others.  This avoids the problem which
arises when a 3x3 neighbourhood straddles a boundary.
</p>


<h3>Origin</h3>

<p>The original Landsat data for this database was generated from data
purchased from NASA by the Australian Centre for Remote Sensing, and
used for research at: The Centre for Remote Sensing, University of New
South Wales, Kensington, PO Box 1, NSW 2033, Australia.
</p>
<p>The sample database was generated taking a small section (82 rows and
100 columns) from the original data.  The binary values were converted
to their present ASCII form by Ashwin Srinivasan.  The classification
for each pixel was performed on the basis of an actual site visit by
Ms. Karen Hall, when working for Professor John A. Richards, at the
Centre for Remote Sensing at the University of New South Wales,
Australia. Conversion to 3x3 neighbourhoods and splitting into test
and training sets was done by Alistair Sutherland.
</p>


<h3>History</h3>

<p>The Landsat satellite data is one of the many sources of information
available for a scene. The interpretation of a scene by integrating
spatial data of diverse types and resolutions including multispectral
and radar data, maps indicating topography, land use etc. is expected
to assume significant importance with the onset of an era characterised
by integrative approaches to remote sensing (for example, NASA's Earth
Observing System commencing this decade). Existing statistical methods 
are ill-equipped for handling such diverse data types. Note that this
is not true for Landsat MSS data considered in isolation (as in
this sample database). This data satisfies the important requirements
of being numerical and at a single resolution, and standard
maximum-likelihood classification performs very well. Consequently,
for this data, it should be interesting to compare the performance
of other methods against the statistical approach.
</p>


<h3>Source</h3>

<p>Ashwin Srinivasan,
Department of Statistics and Data Modeling,
University of Strathclyde,
Glasgow,
Scotland,
UK,
<a href="mailto:ross@uk.ac.turing">ross@uk.ac.turing</a>
</p>
<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Friedrich Leisch.
</p>


<h3>References</h3>

  
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Satellite)
summary(Satellite)
</code></pre>

<hr>
<h2 id='Servo'>Servo Data</h2><span id='topic+Servo'></span>

<h3>Description</h3>

<p>This data set is from a simulation of a servo system
involving a servo amplifier, a motor, a lead screw/nut, and a
sliding carriage of some sort. It may have been on of the
translational axes of a robot on the 9th floor of the AI lab. In any
case, the output value is almost certainly a rise time, or the time
required for the system to respond to a step change in a position
set point. The variables that describe the data set and their values
are the following:
</p>

<table>
<tr>
 <td style="text-align: center;">
	[,1] </td><td style="text-align: left;"> Motor </td><td style="text-align: left;"> A,B,C,D,E</td>
</tr>
<tr>
 <td style="text-align: center;">
	[,2] </td><td style="text-align: left;"> Screw </td><td style="text-align: left;"> A,B,C,D,E</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,3] </td><td style="text-align: left;"> Pgain </td><td style="text-align: left;"> 3,4,5,6</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,4] </td><td style="text-align: left;"> Vgain </td><td style="text-align: left;"> 1,2,3,4,5</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,5] </td><td style="text-align: left;"> Class </td><td style="text-align: left;"> 0.13 to 7.10
    </td>
</tr>

</table>



<h3>Usage</h3>

<pre><code class='language-R'>data(Servo)</code></pre>


<h3>Format</h3>

<p>A data frame with 167 observations on 5 variables, 4 nominal and
1 as the target class.</p>


<h3>Source</h3>


<ul>
<li><p> Creator: Karl Ulrich (MIT) in 1986
</p>
</li>
<li><p> Donor: Ross Quinlan 
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

<p>1. Quinlan, J.R., &quot;Learning with continuous classes&quot;, Proc. 5th
Australian Joint Conference on AI (eds A. Adams and L. Sterling),
Singapore: World Scientific, 1992 
2. Quinlan, J.R., &quot;Combining instance-based and model-based
learning&quot;, Proc. ML'93 (ed P.E. Utgoff), San Mateo: Morgan Kaufmann
1993
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Servo)
summary(Servo)
</code></pre>

<hr>
<h2 id='Shuttle'>Shuttle Dataset (Statlog version)</h2><span id='topic+Shuttle'></span>

<h3>Description</h3>

<p>The shuttle dataset contains 9 attributes all of which are
numerical with the first one being time.  The last column is the class
with the following 7 levels: Rad.Flow, Fpv.Close, Fpv.Open, High, Bypass,
Bpv.Close, Bpv.Open.
</p>
<p>Approximately 80% of the data belongs to class 1. Therefore the
default accuracy is about 80%. The aim here is to obtain an
accuracy of 99 - 99.9%.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Shuttle)</code></pre>


<h3>Format</h3>

<p>A data frame with 58,000 observations on 9 numerical independent
variables and 1 target class.</p>


<h3>Source</h3>


<ul>
<li><p> Source: Jason Catlett of Basser Department of Computer
Science; University of Sydney; N.S.W.; Australia.
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

  
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Shuttle)
summary(Shuttle)
</code></pre>

<hr>
<h2 id='Sonar'>Sonar, Mines vs. Rocks</h2><span id='topic+Sonar'></span>

<h3>Description</h3>

<p>This is the data set used by Gorman and Sejnowski in their
study of the classification of sonar signals using a neural network
[1]. The task is to train a network to discriminate between sonar
signals bounced off a metal cylinder and those bounced off a roughly
cylindrical rock.  
</p>
<p>Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each
number represents the energy within a particular frequency band,
integrated over a certain period of time. The integration aperture
for higher frequencies occur later in time, since these frequencies
are transmitted later during the chirp.
</p>
<p>The label associated with each record contains the letter &quot;R&quot; if the
object is a rock and &quot;M&quot; if it is a mine (metal cylinder). The
numbers in the labels are in increasing order of aspect angle, but
they do not encode the angle directly. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Sonar)</code></pre>


<h3>Format</h3>

<p>A data frame with 208 observations on 61 variables, all numerical and one (the Class) nominal.</p>


<h3>Source</h3>


<ul>
<li><p> Contribution: Terry Sejnowski, Salk Institute and
University of California, San Deigo.
</p>
</li>
<li><p> Development: R. Paul Gorman, Allied-Signal Aerospace
Technology Center. 
</p>
</li>
<li><p> Maintainer: Scott E. Fahlman 
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

<p>Gorman, R. P., and Sejnowski, T. J. (1988). &quot;Analysis of Hidden
Units in a Layered Network Trained to Classify Sonar Targets&quot; in
Neural Networks, Vol. 1, pp. 75-89.
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Sonar)
summary(Sonar)
</code></pre>

<hr>
<h2 id='Soybean'>Soybean Database</h2><span id='topic+Soybean'></span>

<h3>Description</h3>

<p>There are 19 classes, only the first 15 of which have been used in prior
work.  The folklore seems to be that the last four classes are
unjustified by the data since they have so few examples.
There are 35 categorical attributes, some nominal and some ordered.  The
value &ldquo;dna&rdquo; means does not apply.  The values for attributes are
encoded numerically, with the first value encoded as &ldquo;0,&rdquo; the second as
&ldquo;1,&rdquo; and so forth. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Soybean)</code></pre>


<h3>Format</h3>

<p>A data frame with 683 observations on 36 variables. There are 35
categorical attributes, all numerical and a nominal denoting the
class.
</p>

<table>
<tr>
 <td style="text-align: center;">
	[,1] </td><td style="text-align: left;"> Class </td><td style="text-align: left;"> the 19 classes</td>
</tr>
<tr>
 <td style="text-align: center;">
	[,2] </td><td style="text-align: left;"> date </td><td style="text-align: left;">
	apr(0),may(1),june(2),july(3),aug(4),sept(5),oct(6).</td>
</tr>
<tr>
 <td style="text-align: center;">
	[,3] </td><td style="text-align: left;"> plant.stand </td><td style="text-align: left;"> normal(0),lt-normal(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,4] </td><td style="text-align: left;"> precip </td><td style="text-align: left;"> lt-norm(0),norm(1),gt-norm(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,5] </td><td style="text-align: left;"> temp </td><td style="text-align: left;"> lt-norm(0),norm(1),gt-norm(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,6] </td><td style="text-align: left;"> hail </td><td style="text-align: left;"> yes(0),no(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,7] </td><td style="text-align: left;"> crop.hist </td><td style="text-align: left;"> dif-lst-yr(0),s-l-y(1),s-l-2-y(2),
	s-l-7-y(3).</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,8] </td><td style="text-align: left;"> area.dam </td><td style="text-align: left;">
	scatter(0),low-area(1),upper-ar(2),whole-field(3).</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,9] </td><td style="text-align: left;"> sever </td><td style="text-align: left;"> minor(0),pot-severe(1),severe(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
    	[,10] </td><td style="text-align: left;"> seed.tmt </td><td style="text-align: left;"> none(0),fungicide(1),other(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,11] </td><td style="text-align: left;"> germ </td><td style="text-align: left;"> 90-100%(0),80-89%(1),lt-80%(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,12] </td><td style="text-align: left;"> plant.growth </td><td style="text-align: left;"> norm(0),abnorm(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,13] </td><td style="text-align: left;"> leaves </td><td style="text-align: left;"> norm(0),abnorm(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,14] </td><td style="text-align: left;"> leaf.halo </td><td style="text-align: left;">
	absent(0),yellow-halos(1),no-yellow-halos(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,15] </td><td style="text-align: left;"> leaf.marg </td><td style="text-align: left;"> w-s-marg(0),no-w-s-marg(1),dna(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,16] </td><td style="text-align: left;"> leaf.size </td><td style="text-align: left;"> lt-1/8(0),gt-1/8(1),dna(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,17] </td><td style="text-align: left;"> leaf.shread </td><td style="text-align: left;"> absent(0),present(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,18] </td><td style="text-align: left;"> leaf.malf </td><td style="text-align: left;"> absent(0),present(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,19] </td><td style="text-align: left;"> leaf.mild </td><td style="text-align: left;"> absent(0),upper-surf(1),lower-surf(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,20] </td><td style="text-align: left;"> stem </td><td style="text-align: left;"> norm(0),abnorm(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,21] </td><td style="text-align: left;"> lodging </td><td style="text-align: left;">	yes(0),no(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,22] </td><td style="text-align: left;"> stem.cankers </td><td style="text-align: left;">
	absent(0),below-soil(1),above-s(2),ab-sec-nde(3).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,23] </td><td style="text-align: left;"> canker.lesion </td><td style="text-align: left;"> dna(0),brown(1),dk-brown-blk(2),tan(3).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,24] </td><td style="text-align: left;"> fruiting.bodies </td><td style="text-align: left;"> absent(0),present(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,25] </td><td style="text-align: left;"> ext.decay </td><td style="text-align: left;"> absent(0),firm-and-dry(1),watery(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,26] </td><td style="text-align: left;"> mycelium </td><td style="text-align: left;"> absent(0),present(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,27] </td><td style="text-align: left;"> int.discolor </td><td style="text-align: left;"> none(0),brown(1),black(2).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,28] </td><td style="text-align: left;"> sclerotia </td><td style="text-align: left;"> absent(0),present(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,29] </td><td style="text-align: left;"> fruit.pods </td><td style="text-align: left;"> norm(0),diseased(1),few-present(2),dna(3).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,30] </td><td style="text-align: left;"> fruit.spots </td><td style="text-align: left;">
	absent(0),col(1),br-w/blk-speck(2),distort(3),dna(4).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,31] </td><td style="text-align: left;"> seed </td><td style="text-align: left;"> norm(0),abnorm(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,32] </td><td style="text-align: left;"> mold.growth </td><td style="text-align: left;"> absent(0),present(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,33] </td><td style="text-align: left;"> seed.discolor </td><td style="text-align: left;"> absent(0),present(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,34] </td><td style="text-align: left;"> seed.size </td><td style="text-align: left;"> norm(0),lt-norm(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,35] </td><td style="text-align: left;"> shriveling </td><td style="text-align: left;"> absent(0),present(1).</td>
</tr>
<tr>
 <td style="text-align: center;">
   	[,36] </td><td style="text-align: left;"> roots </td><td style="text-align: left;"> norm(0),rotted(1),galls-cysts(2).

</td>
</tr>

</table>



<h3>Source</h3>


<ul>
<li><p> Source: R.S. Michalski and R.L. Chilausky &quot;Learning by
Being Told and Learning from Examples: An Experimental
Comparison of the Two Methods of Knowledge Acquisition in the
Context of Developing an Expert System for Soybean Disease
Diagnosis&quot;, International Journal of Policy Analysis and
Information Systems, Vol. 4, No. 2, 1980.
</p>
</li>
<li><p> Donor: Ming Tan &amp; Jeff Schlimmer (Jeff.Schlimmer%cs.cmu.edu)
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

<p>Tan, M., &amp; Eshelman, L. (1988). Using weighted networks to represent
classification knowledge in noisy domains.  Proceedings of the Fifth
International Conference on Machine Learning (pp. 121-134). Ann Arbor,
Michigan: Morgan Kaufmann.
&ndash; IWN recorded a 97.1% classification accuracy 
&ndash; 290 training and 340 test instances
</p>
<p>Fisher,D.H. &amp; Schlimmer,J.C. (1988). Concept Simplification and
Predictive Accuracy. Proceedings of the Fifth
International Conference on Machine Learning (pp. 22-28). Ann Arbor,
Michigan: Morgan Kaufmann.
&ndash; Notes why this database is highly predictable
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.    
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Soybean)
summary(Soybean)
</code></pre>

<hr>
<h2 id='Vehicle'>Vehicle Silhouettes</h2><span id='topic+Vehicle'></span>

<h3>Description</h3>

<p>The purpose is to classify a given silhouette as one of four types
of vehicle, using a set of features extracted from the
silhouette. The vehicle may be viewed from one of many different
angles. The features were extracted from the silhouettes by the HIPS
(Hierarchical Image Processing System) extension BINATTS, which
extracts a combination of scale independent features utilising both
classical moments based measures such as scaled variance, skewness
and kurtosis about the major/minor axes and heuristic measures such
as hollows, circularity, rectangularity and compactness. 
</p>
<p>Four &quot;Corgie&quot; model vehicles were used for the experiment: a double
decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400. This
particular combination of vehicles was chosen with the expectation
that the bus, van and either one of the cars would be readily
distinguishable, but it would be more difficult to distinguish
between the cars. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Vehicle)</code></pre>


<h3>Format</h3>

<p>A data frame with 846 observations on 19 variables, all numerical
and one nominal defining the class of the objects.
</p>

<table>
<tr>
 <td style="text-align: center;">
   [,1] </td><td style="text-align: left;"> Comp </td><td style="text-align: left;"> Compactness</td>
</tr>
<tr>
 <td style="text-align: center;">
   [,2] </td><td style="text-align: left;"> Circ </td><td style="text-align: left;"> Circularity</td>
</tr>
<tr>
 <td style="text-align: center;">
   [,3] </td><td style="text-align: left;"> D.Circ </td><td style="text-align: left;"> Distance Circularity</td>
</tr>
<tr>
 <td style="text-align: center;">
   [,4] </td><td style="text-align: left;"> Rad.Ra </td><td style="text-align: left;"> Radius ratio</td>
</tr>
<tr>
 <td style="text-align: center;">
   [,5] </td><td style="text-align: left;"> Pr.Axis.Ra </td><td style="text-align: left;"> pr.axis aspect ratio</td>
</tr>
<tr>
 <td style="text-align: center;">
   [,6] </td><td style="text-align: left;"> Max.L.Ra </td><td style="text-align: left;"> max.length aspect ratio</td>
</tr>
<tr>
 <td style="text-align: center;">
   [,7] </td><td style="text-align: left;"> Scat.Ra </td><td style="text-align: left;"> scatter ratio</td>
</tr>
<tr>
 <td style="text-align: center;">
   [,8] </td><td style="text-align: left;"> Elong </td><td style="text-align: left;"> elongatedness</td>
</tr>
<tr>
 <td style="text-align: center;">
   [,9] </td><td style="text-align: left;"> Pr.Axis.Rect </td><td style="text-align: left;"> pr.axis rectangularity</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,10] </td><td style="text-align: left;"> Max.L.Rect </td><td style="text-align: left;"> max.length rectangularity</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,11] </td><td style="text-align: left;"> Sc.Var.Maxis </td><td style="text-align: left;"> scaled variance along major axis</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,12] </td><td style="text-align: left;"> Sc.Var.maxis </td><td style="text-align: left;"> scaled variance along minor axis</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,13] </td><td style="text-align: left;"> Ra.Gyr </td><td style="text-align: left;"> scaled radius of gyration</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,14] </td><td style="text-align: left;"> Skew.Maxis </td><td style="text-align: left;"> skewness about major axis</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,15] </td><td style="text-align: left;"> Skew.maxis </td><td style="text-align: left;"> skewness about minor axis</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,16] </td><td style="text-align: left;"> Kurt.maxis </td><td style="text-align: left;"> kurtosis about minor axis</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,17] </td><td style="text-align: left;"> Kurt.Maxis </td><td style="text-align: left;"> kurtosis about major axis</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,18] </td><td style="text-align: left;"> Holl.Ra </td><td style="text-align: left;"> hollows ratio</td>
</tr>
<tr>
 <td style="text-align: center;">
  [,19] </td><td style="text-align: left;"> Class </td><td style="text-align: left;"> type
  </td>
</tr>

</table>



<h3>Source</h3>


<ul>
<li><p> Creator: Drs.Pete Mowforth and Barry Shepherd, Turing
Institute, Glasgow, Scotland.   
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

<p>Turing Institute Research Memorandum TIRM-87-018 &quot;Vehicle
Recognition Using Rule Based Methods&quot; by Siebert,JP (March 1987)
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Vehicle)
summary(Vehicle)
</code></pre>

<hr>
<h2 id='Vowel'>Vowel Recognition (Deterding data)</h2><span id='topic+Vowel'></span>

<h3>Description</h3>

<p>Speaker independent recognition of the eleven steady state
vowels of British English using a specified training set of lpc
derived log area ratios. The vowels are indexed by integers
0-10. For each utterance, there are ten floating-point input values,
with array indices 0-9. The vowels are the following: hid, hId, hEd,
hAd, hYd, had, hOd, hod, hUd, hud, hed. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Vowel)</code></pre>


<h3>Format</h3>

<p>A data frame with 990 observations on 10 independent variables, one
nominal and the other numerical, and 1 as the target class.</p>


<h3>Source</h3>


<ul>
<li><p> Creator: Tony Robinson 
</p>
</li>
<li><p> Maintainer: Scott E. Fahlman, CMU
</p>
</li></ul>

<p>These data have been taken from the UCI Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="ftp://ftp.ics.uci.edu/pub/machine-learning-databases">ftp://ftp.ics.uci.edu/pub/machine-learning-databases</a>
</p>
</li>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>
</p>
</li></ul>

<p>and were converted to R format by Evgenia Dimitriadou.
</p>


<h3>References</h3>

<p>D. H. Deterding, 1989, University of Cambridge, &quot;Speaker
Normalisation for Automatic Speech Recognition&quot;, submitted for PhD.
</p>
<p>M. Niranjan and F. Fallside, 1988, Cambridge University Engineering
Department, &quot;Neural Networks and Radial Basis Functions in
Classifying Static Speech Patterns&quot;, CUED/F-INFENG/TR.22.
</p>
<p>Steve Renals and Richard Rohwer, &quot;Phoneme Classification Experiments
Using Radial Basis Functions&quot;, Submitted to the International Joint
Conference on Neural Networks, Washington, 1989.
</p>
<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Vowel)
summary(Vowel)
</code></pre>

<hr>
<h2 id='Zoo'>Zoo Data</h2><span id='topic+Zoo'></span>

<h3>Description</h3>

<p>A simple dataset containing 17 (mostly logical) variables
on 101 animals.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Zoo)
</code></pre>


<h3>Format</h3>

<p>A data frame with 17 columns: hair, feathers, eggs, milk,
airborne, aquatic, predator, toothed, backbone, breathes, venomous,
fins, legs, tail, domestic, catsize, type.
</p>
<p>Most variables are logical and indicate whether the corresponding
animal has the corresponsing characteristic or not. The only 2
exceptions are: <code>legs</code> takes
values 0, 2, 4, 5, 6, and 8. <code>type</code> is a grouping of the animals
into 7 groups, see the example section for the detailed list.
</p>


<h3>Details</h3>

<p>Ask the original donor of the data why <em>girl</em> is an animal.
</p>


<h3>Source</h3>

<p>The original data have been donated by Richard S. Forsyth to the UCI
Repository Of Machine Learning
Databases at
</p>

<ul>
<li> <p><a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">http://www.ics.uci.edu/~mlearn/MLRepository.html</a>.
</p>
</li></ul>

<p>and were converted to R format by Friedrich Leisch.
</p>


<h3>References</h3>

<p>Newman, D.J. &amp; Hettich, S. &amp; Blake, C.L. &amp; Merz, C.J. (1998).
UCI Repository of machine learning databases
[http://www.ics.uci.edu/~mlearn/MLRepository.html]. Irvine, CA:
University of California, Department of Information and Computer
Science.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Zoo)
summary(Zoo)

## see the annimals grouped by type
tapply(rownames(Zoo), Zoo$type, function(x) x)

## which animals have fins?
rownames(Zoo)[Zoo$fins]
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
