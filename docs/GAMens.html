<!DOCTYPE html><html lang="en"><head><title>Help for package GAMens</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {GAMens}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#GAMens'><p>Applies the GAMbag, GAMrsm or GAMens ensemble classifier to a data set</p></a></li>
<li><a href='#GAMens.cv'><p>Runs v-fold cross validation with GAMbag, GAMrsm or GAMens ensemble</p>
classifier</a></li>
<li><a href='#predict.GAMens'><p>Predicts from a fitted GAMens object (i.e., GAMbag, GAMrsm or GAMens</p>
classifier).</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Applies GAMbag, GAMrsm and GAMens Ensemble Classifiers for
Binary Classification</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Author:</td>
<td>Koen W. De Bock, Kristof Coussement and Dirk Van den Poel</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Koen W. De Bock &lt;kdebock@audencia.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.4.0), splines, gam, mlbench, caTools</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the GAMbag, GAMrsm and GAMens ensemble
    classifiers for binary classification (De Bock et al., 2010) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2009.12.013">doi:10.1016/j.csda.2009.12.013</a>&gt;. The ensembles
    implement Bagging (Breiman, 1996) &lt;<a href="https://doi.org/10.1023%2FA%3A1010933404324">doi:10.1023/A:1010933404324</a>&gt;, the Random Subspace Method (Ho, 1998) &lt;<a href="https://doi.org/10.1109%2F34.709601">doi:10.1109/34.709601</a>&gt;
    , or both, and use Hastie and Tibshirani's (1990, ISBN:978-0412343902) generalized additive models (GAMs)
    as base classifiers. Once an ensemble classifier has been trained, it can
    be used for predictions on new data. A function for cross validation is also
    included.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-04-05 14:33:36 UTC; kdebock</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-04-05 17:12:34 UTC</td>
</tr>
</table>
<hr>
<h2 id='GAMens'>Applies the GAMbag, GAMrsm or GAMens ensemble classifier to a data set</h2><span id='topic+GAMens'></span>

<h3>Description</h3>

<p>Fits the GAMbag, GAMrsm or GAMens ensemble algorithms for binary
classification using generalized additive models as base classifiers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GAMens(formula, data, rsm_size = 2, autoform = FALSE, iter = 10, df = 4,
  bagging = TRUE, rsm = TRUE, fusion = "avgagg")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GAMens_+3A_formula">formula</code></td>
<td>
<p>a formula, as in the <code>gam</code> function. Smoothing splines
are supported as nonparametric smoothing terms, and should be indicated by
<code>s</code>. See the documentation of <code>s</code> in the <code>gam</code> package for
its arguments. The <code>GAMens</code> function also provides the possibility for
automatic <code>formula</code> specification. See 'details' for more information.</p>
</td></tr>
<tr><td><code id="GAMens_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables named in
<code>formula</code>.</p>
</td></tr>
<tr><td><code id="GAMens_+3A_rsm_size">rsm_size</code></td>
<td>
<p>an integer, the number of variables to use for random
feature subsets used in the Random Subspace Method. Default is 2.  If
<code>rsm=FALSE</code>, the value of <code>rsm_size</code> is ignored.</p>
</td></tr>
<tr><td><code id="GAMens_+3A_autoform">autoform</code></td>
<td>
<p>if <code>FALSE</code> (default), the model specification in
<code>formula</code> is used. If <code>TRUE</code>, the function triggers automatic
<code>formula</code> specification. See 'details' for more information.</p>
</td></tr>
<tr><td><code id="GAMens_+3A_iter">iter</code></td>
<td>
<p>an integer, the number of base classifiers (GAMs) in the
ensemble. Defaults to <code>iter=10</code> base classifiers.</p>
</td></tr>
<tr><td><code id="GAMens_+3A_df">df</code></td>
<td>
<p>an integer, the number of degrees of freedom (df) used for
smoothing spline estimation. Its value is only used when <code>autoform =
TRUE</code>. Defaults to <code>df=4</code>. Its value is ignored if a formula is
specified and <code>autoform</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="GAMens_+3A_bagging">bagging</code></td>
<td>
<p>enables Bagging if value is <code>TRUE</code> (default). If
<code>FALSE</code>, Bagging is disabled. Either <code>bagging</code>, <code>rsm</code> or both
should be <code>TRUE</code></p>
</td></tr>
<tr><td><code id="GAMens_+3A_rsm">rsm</code></td>
<td>
<p>enables Random Subspace Method (RSM) if value is <code>TRUE</code>
(default). If <code>FALSE</code>, RSM is disabled. Either <code>bagging</code>,
<code>rsm</code> or both should be <code>TRUE</code></p>
</td></tr>
<tr><td><code id="GAMens_+3A_fusion">fusion</code></td>
<td>
<p>specifies the fusion rule for the aggregation of member
classifier outputs in the ensemble. Possible values are <code>'avgagg'</code>
(default), <code>'majvote'</code>, <code>'w.avgagg'</code> or <code>'w.majvote'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>GAMens</code> function applies the GAMbag, GAMrsm or GAMens ensemble
classifiers (De Bock et al., 2010) to a data set. GAMens is the default with
(<code>bagging=TRUE</code> and <code>rsm=TRUE</code>. For GAMbag, <code>rsm</code> should be
specified as <code>FALSE</code>.  For GAMrsm, <code>bagging</code> should be
<code>FALSE</code>.
</p>
<p>The <code>GAMens</code> function provides the possibility for automatic formula
specification. In this case, dichotomous variables in <code>data</code> are
included as linear terms, and other variables are assumed continuous,
included as nonparametric terms, and estimated by means of smoothing
splines. To enable automatic formula specification, use the generic formula
<code>[response variable name]~.</code> in combination with <code>autoform =
TRUE</code>. Note that in this case, all variables available in <code>data</code> are
used in the model. If a formula other than <code>[response variable name]~.</code>
is specified then the <code>autoform</code> option is automatically overridden. If
<code>autoform=FALSE</code> and the generic formula <code>[response variable
name]~.</code> is specified then the GAMs in the ensemble will not contain
nonparametric terms (i.e., will only consist of linear terms).
</p>
<p>Four alternative fusion rules for member classifier outputs can be
specified. Possible values are <code>'avgagg'</code> for average aggregation
(default), <code>'majvote'</code> for majority voting, <code>'w.avgagg'</code> for
weighted average aggregation, or <code>'w.majvote'</code> for weighted majority
voting.  Weighted approaches are based on member classifier error rates.
</p>


<h3>Value</h3>

<p>An object of class <code>GAMens</code>, which is a list with the following
components: </p>
<table role = "presentation">
<tr><td><code>GAMs</code></td>
<td>
<p>the member GAMs in the ensemble.</p>
</td></tr> <tr><td><code>formula</code></td>
<td>
<p>the
formula used tot create the <code>GAMens</code> object.  </p>
</td></tr> <tr><td><code>iter</code></td>
<td>
<p>the
ensemble size. </p>
</td></tr> <tr><td><code>df</code></td>
<td>
<p>number of degrees of freedom (df) used for
smoothing spline estimation. </p>
</td></tr> <tr><td><code>rsm</code></td>
<td>
<p>indicates whether the Random
Subspace Method was used to create the <code>GAMens</code> object. </p>
</td></tr>
<tr><td><code>bagging</code></td>
<td>
<p>indicates whether bagging was used to create the
<code>GAMens</code> object. </p>
</td></tr> <tr><td><code>rsm_size</code></td>
<td>
<p>the number of variables used for
random feature subsets. </p>
</td></tr> <tr><td><code>fusion_method</code></td>
<td>
<p>the fusion rule that was used
to combine member classifier outputs in the ensemble. </p>
</td></tr> <tr><td><code>probs</code></td>
<td>
<p>the
class membership probabilities, predicted by the ensemble classifier.  </p>
</td></tr>
<tr><td><code>class</code></td>
<td>
<p>the class predicted by the ensemble classifier. </p>
</td></tr>
<tr><td><code>samples</code></td>
<td>
<p>an array indicating, for every base classifier in the
ensemble, which observations were used for training. </p>
</td></tr> <tr><td><code>weights</code></td>
<td>
<p>a
vector with weights defined as (1 - error rate). Usage depends upon
specification of <code>fusion_method</code>. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Koen W. De Bock <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>, Kristof Coussement
<a href="mailto:K.Coussement@ieseg.fr">K.Coussement@ieseg.fr</a> and Dirk Van den Poel
<a href="mailto:Dirk.VandenPoel@ugent.be">Dirk.VandenPoel@ugent.be</a>
</p>


<h3>References</h3>

<p>De Bock, K.W. and Van den Poel, D. (2012):
&quot;Reconciling Performance and Interpretability in Customer Churn Prediction Modeling
Using Ensemble Learning Based on Generalized Additive Models&quot;.
Expert Systems With Applications, Vol 39, 8, pp. 6816&ndash;6826.
</p>
<p>De Bock, K. W., Coussement, K. and Van den Poel, D. (2010):
&quot;Ensemble Classification based on generalized additive models&quot;.
Computational Statistics &amp; Data Analysis, Vol 54, 6, pp. 1535&ndash;1546.
</p>
<p>Breiman, L. (1996): &quot;Bagging predictors&quot;. Machine Learning, Vol 24, 2, pp.
123&ndash;140.
</p>
<p>Hastie, T. and Tibshirani, R. (1990): &quot;Generalized Additive Models&quot;, Chapman
and Hall, London.
</p>
<p>Ho, T. K. (1998): &quot;The random subspace method for constructing decision
forests&quot;. IEEE Transactions on Pattern Analysis and Machine Intelligence,
Vol 20, 8, pp. 832&ndash;844.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.GAMens">predict.GAMens</a></code>, <code><a href="#topic+GAMens.cv">GAMens.cv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

## Load data (mlbench library should be loaded)
library(mlbench)
data(Ionosphere)
IonosphereSub&lt;-Ionosphere[,c("V1","V2","V3","V4","V5","Class")]

## Train GAMens using all variables in Ionosphere dataset
Ionosphere.GAMens &lt;- GAMens(Class~., IonosphereSub ,4 , autoform=TRUE,
iter=10 )

## Compare classification performance of GAMens, GAMrsm and GAMbag ensembles,
## using 4 nonparametric terms and 2 linear terms
Ionosphere.GAMens &lt;- GAMens(Class~s(V3,4)+s(V4,4)+s(V5,3)+s(V6,5)+V7+V8,
Ionosphere ,3 , autoform=FALSE, iter=10 )

Ionosphere.GAMrsm &lt;- GAMens(Class~s(V3,4)+s(V4,4)+s(V5,3)+s(V6,5)+V7+V8,
Ionosphere ,3 , autoform=FALSE, iter=10, bagging=FALSE, rsm=TRUE )

Ionosphere.GAMbag &lt;- GAMens(Class~s(V3,4)+s(V4,4)+s(V5,3)+s(V6,5)+V7+V8,
Ionosphere ,3 , autoform=FALSE, iter=10, bagging=TRUE, rsm=FALSE )

## Calculate AUCs (for function colAUC, load caTools library)
library(caTools)
GAMens.auc &lt;- colAUC(Ionosphere.GAMens[[9]], Ionosphere["Class"]=="good",
plotROC=FALSE)
GAMrsm.auc &lt;- colAUC(Ionosphere.GAMrsm[[9]], Ionosphere["Class"]=="good",
plotROC=FALSE)
GAMbag.auc &lt;- colAUC(Ionosphere.GAMbag[[9]], Ionosphere["Class"]=="good",
plotROC=FALSE)

</code></pre>

<hr>
<h2 id='GAMens.cv'>Runs v-fold cross validation with GAMbag, GAMrsm or GAMens ensemble
classifier</h2><span id='topic+GAMens.cv'></span>

<h3>Description</h3>

<p>In v-fold cross validation, the data are divided into <code>v</code> subsets of
approximately equal size. Subsequently, one of the <code>v</code> data parts is
excluded while the remainder of the data is used to create a <code>GAMens</code>
object.  Predictions are generated for the excluded data part. The process
is repeated <code>v</code> times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GAMens.cv(formula, data, cv, rsm_size = 2, autoform = FALSE, iter = 10,
  df = 4, bagging = TRUE, rsm = TRUE, fusion = "avgagg")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GAMens.cv_+3A_formula">formula</code></td>
<td>
<p>a formula, as in the <code>gam</code> function. Smoothing splines
are supported as nonparametric smoothing terms, and should be indicated by
<code>s</code>. See the documentation of <code>s</code> in the <code>gam</code> package for
its arguments. The <code>GAMens</code> function also provides the possibility for
automatic <code>formula</code> specification. See 'details' for more information.</p>
</td></tr>
<tr><td><code id="GAMens.cv_+3A_data">data</code></td>
<td>
<p>a data frame in which to interpret the variables named in
<code>formula</code>.</p>
</td></tr>
<tr><td><code id="GAMens.cv_+3A_cv">cv</code></td>
<td>
<p>An integer specifying the number of folds in the cross-validation.</p>
</td></tr>
<tr><td><code id="GAMens.cv_+3A_rsm_size">rsm_size</code></td>
<td>
<p>an integer, the number of variables to use for random
feature subsets used in the Random Subspace Method. Default is 2.  If
<code>rsm=FALSE</code>, the value of <code>rsm_size</code> is ignored.</p>
</td></tr>
<tr><td><code id="GAMens.cv_+3A_autoform">autoform</code></td>
<td>
<p>if <code>FALSE</code> (by default), the model specification in
<code>formula</code> is used. If <code>TRUE</code>, the function triggers automatic
<code>formula</code> specification. See 'details' for more information.</p>
</td></tr>
<tr><td><code id="GAMens.cv_+3A_iter">iter</code></td>
<td>
<p>an integer, the number of base (member) classifiers (GAMs) in
the ensemble. Defaults to <code>iter=10</code> base classifiers.</p>
</td></tr>
<tr><td><code id="GAMens.cv_+3A_df">df</code></td>
<td>
<p>an integer, the number of degrees of freedom (df) used for
smoothing spline estimation. Its value is only used when <code>autoform =
TRUE</code>. Defaults to <code>df=4</code>. Its value is ignored if a formula is
specified and <code>autoform</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="GAMens.cv_+3A_bagging">bagging</code></td>
<td>
<p>enables Bagging if value is <code>TRUE</code> (default). If
<code>FALSE</code>, Bagging is disabled. Either <code>bagging</code>, <code>rsm</code> or both
should be <code>TRUE</code></p>
</td></tr>
<tr><td><code id="GAMens.cv_+3A_rsm">rsm</code></td>
<td>
<p>enables Random Subspace Method (RSM) if value is <code>TRUE</code>
(default). If <code>FALSE</code>, rsm is disabled. Either <code>bagging</code>,
<code>rsm</code> or both should be <code>TRUE</code></p>
</td></tr>
<tr><td><code id="GAMens.cv_+3A_fusion">fusion</code></td>
<td>
<p>specifies the fusion rule for the aggregation of member
classifier outputs in the ensemble. Possible values are <code>'avgagg'</code> for
average aggregation (default), <code>'majvote'</code> for majority voting,
<code>'w.avgagg'</code> for weighted average aggregation based on base classifier
error rates, or <code>'w.majvote'</code> for weighted majority voting.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>GAMens.cv</code>, which is a list with the
following components: </p>
<table role = "presentation">
<tr><td><code>foldpred</code></td>
<td>
<p>a data frame with, per fold, predicted
class membership probabilities for the left-out observations. </p>
</td></tr>
<tr><td><code>pred</code></td>
<td>
<p>a data frame with predicted class membership probabilities. </p>
</td></tr>
<tr><td><code>foldclass</code></td>
<td>
<p>a data frame with, per fold, predicted classes for the
left-out observations. </p>
</td></tr> <tr><td><code>class</code></td>
<td>
<p>a data frame with predicted classes. </p>
</td></tr>
<tr><td><code>conf</code></td>
<td>
<p>the confusion matrix which compares the real versus predicted
class memberships, based on the <code>class</code> object. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Koen W. De Bock <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>, Kristof Coussement
<a href="mailto:K.Coussement@ieseg.fr">K.Coussement@ieseg.fr</a> and Dirk Van den Poel
<a href="mailto:Dirk.VandenPoel@ugent.be">Dirk.VandenPoel@ugent.be</a>
</p>


<h3>References</h3>

<p>De Bock, K.W. and Van den Poel, D. (2012):
&quot;Reconciling Performance and Interpretability in Customer Churn Prediction Modeling
Using Ensemble Learning Based on Generalized Additive Models&quot;.
Expert Systems With Applications, Vol 39, 8, pp. 6816&ndash;6826.
</p>
<p>De Bock, K. W., Coussement, K. and Van den Poel, D. (2010):
&quot;Ensemble Classification based on generalized additive models&quot;.
Computational Statistics &amp; Data Analysis, Vol 54, 6, pp. 1535&ndash;1546.
</p>
<p>Breiman, L. (1996): &quot;Bagging predictors&quot;. Machine Learning, Vol 24, 2, pp.
123&ndash;140.
</p>
<p>Hastie, T. and Tibshirani, R. (1990): &quot;Generalized Additive Models&quot;, Chapman
and Hall, London.
</p>
<p>Ho, T. K. (1998): &quot;The random subspace method for constructing decision
forests&quot;. IEEE Transactions on Pattern Analysis and Machine Intelligence,
Vol 20, 8, pp. 832&ndash;844.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+predict.GAMens">predict.GAMens</a></code>, <code><a href="#topic+GAMens">GAMens</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Load data: mlbench library should be loaded!)
library(mlbench)
data(Sonar)
SonarSub&lt;-Sonar[,c("V1","V2","V3","V4","V5","V6","Class")]

## Obtain cross-validated classification performance of GAMrsm
## ensembles, using all variables in the Sonar dataset, based on 5-fold
## cross validation runs

Sonar.cv.GAMrsm &lt;- GAMens.cv(Class~s(V1,4)+s(V2,3)+s(V3,4)+V4+V5+V6,
SonarSub ,5, 4 , autoform=FALSE, iter=10, bagging=FALSE, rsm=TRUE )

## Calculate AUCs (for function colAUC, load caTools library)
library(caTools)

GAMrsm.cv.auc &lt;- colAUC(Sonar.cv.GAMrsm[[2]], SonarSub["Class"]=="R",
plotROC=FALSE)


</code></pre>

<hr>
<h2 id='predict.GAMens'>Predicts from a fitted GAMens object (i.e., GAMbag, GAMrsm or GAMens
classifier).</h2><span id='topic+predict.GAMens'></span>

<h3>Description</h3>

<p>Generates predictions (classes and class membership probabilities) for
observations in a dataframe using a GAMens object (i.e., GAMens, GAMrsm or
GAMbag classifier).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'GAMens'
predict(object, data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.GAMens_+3A_object">object</code></td>
<td>
<p>fitted model object of <code>GAMens</code> class.</p>
</td></tr>
<tr><td><code id="predict.GAMens_+3A_data">data</code></td>
<td>
<p>data frame with observations to genenerate predictions for.</p>
</td></tr>
<tr><td><code id="predict.GAMens_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>predict.GAMens</code>, which is a list with the
following components: </p>
<table role = "presentation">
<tr><td><code>pred</code></td>
<td>
<p>the class membership probabilities
generated by the ensemble classifier. </p>
</td></tr> <tr><td><code>class</code></td>
<td>
<p>the classes predicted
by the ensemble classifier. </p>
</td></tr> <tr><td><code>conf</code></td>
<td>
<p>the confusion matrix which
compares the real versus predicted class memberships, based on the
<code>class</code> object. Obtains value <code>NULL</code> if the testdata is unlabeled.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Koen W. De Bock <a href="mailto:kdebock@audencia.com">kdebock@audencia.com</a>, Kristof Coussement
<a href="mailto:K.Coussement@ieseg.fr">K.Coussement@ieseg.fr</a> and Dirk Van den Poel
<a href="mailto:Dirk.VandenPoel@ugent.be">Dirk.VandenPoel@ugent.be</a>
</p>


<h3>References</h3>

<p>De Bock, K.W. and Van den Poel, D. (2012):
&quot;Reconciling Performance and Interpretability in Customer Churn Prediction Modeling
Using Ensemble Learning Based on Generalized Additive Models&quot;.
Expert Systems With Applications, Vol 39, 8, pp. 6816&ndash;6826.
</p>
<p>De Bock, K. W., Coussement, K. and Van den Poel, D. (2010):
&quot;Ensemble Classification based on generalized additive models&quot;.
Computational Statistics &amp; Data Analysis, Vol 54, 6, pp. 1535&ndash;1546.
</p>
<p>Breiman, L. (1996): &quot;Bagging predictors&quot;. Machine Learning, Vol 24, 2, pp.
123&ndash;140.
</p>
<p>Hastie, T. and Tibshirani, R. (1990): &quot;Generalized Additive Models&quot;, Chapman
and Hall, London.
</p>
<p>Ho, T. K. (1998): &quot;The random subspace method for constructing decision
forests&quot;. IEEE Transactions on Pattern Analysis and Machine Intelligence,
Vol 20, 8, pp. 832&ndash;844.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+GAMens">GAMens</a></code>, <code><a href="#topic+GAMens.cv">GAMens.cv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Load data, mlbench library should be loaded!)
library(mlbench)
data(Sonar)
SonarSub&lt;-Sonar[,c("V1","V2","V3","V4","V5","V6","Class")]

## Select indexes for training set observations
idx &lt;- c(sample(1:97,60),sample(98:208,70))

## Train GAMrsm using all variables in Sonar dataset. Generate predictions
## for test set observations.
Sonar.GAMrsm &lt;- GAMens(Class~.,SonarSub[idx,], autoform=TRUE, iter=10,
bagging=FALSE, rsm=TRUE)
Sonar.GAMrsm.predict &lt;- predict(Sonar.GAMrsm,SonarSub[-idx,])


## Load data mlbench library should be loaded!)
library(mlbench)
data(Ionosphere)
IonosphereSub&lt;-Ionosphere[,c("V1","V2","V3","V4","V5","V6","V7","V8","Class")]
Ionosphere_s &lt;- IonosphereSub[order(IonosphereSub$Class),]

## Select indexes for training set observations
idx &lt;- c(sample(1:97,60),sample(98:208,70))


## Compare test set classification performance of GAMens, GAMrsm and
## GAMbag ensembles, using using 4 nonparametric terms and 2 linear terms in the
## Ionosphere dataset
Ionosphere.GAMens &lt;- GAMens(Class~s(V3,4)+s(V4,4)+s(V5,3)+s(V6,5)+V7+V8,
IonosphereSub[idx,], autoform=FALSE, iter=10, bagging=TRUE, rsm=TRUE)

Ionosphere.GAMens.predict &lt;- predict(Ionosphere.GAMens,
IonosphereSub[-idx,])

Ionosphere.GAMrsm &lt;- GAMens(Class~s(V3,4)+s(V4,4)+s(V5,3)+s(V6,5)+V7+V8,
IonosphereSub[idx,], autoform=FALSE, iter=10, bagging=FALSE, rsm=TRUE)

Ionosphere.GAMrsm.predict &lt;- predict(Ionosphere.GAMrsm,
IonosphereSub[-idx,])

Ionosphere.GAMbag &lt;- GAMens(Class~s(V3,4)+s(V4,4)+s(V5,3)+s(V6,5)+V7+V8,
IonosphereSub[idx,], autoform=FALSE, iter=10, bagging=TRUE, rsm=FALSE)

Ionosphere.GAMbag.predict &lt;- predict(Ionosphere.GAMbag,
IonosphereSub[-idx,])

## Calculate AUCs(for function colAUC, load caTools library)
library(caTools)
GAMens.auc &lt;- colAUC(Ionosphere.GAMens.predict[[1]],
IonosphereSub[-idx,"Class"]=="good", plotROC=FALSE)

GAMrsm.auc &lt;- colAUC(Ionosphere.GAMrsm.predict[[1]],
Ionosphere[-idx,"Class"]=="good", plotROC=FALSE)

GAMbag.auc &lt;- colAUC(Ionosphere.GAMbag.predict[[1]],
IonosphereSub[-idx,"Class"]=="good", plotROC=FALSE)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
