<!DOCTYPE html><html lang="en"><head><title>Help for package soundecology</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {soundecology}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#acoustic_complexity'><p>Acoustic Complexity Index</p></a></li>
<li><a href='#acoustic_diversity'><p>Acoustic Diversity Index</p></a></li>
<li><a href='#acoustic_evenness'><p>Acoustic Evenness Index</p></a></li>
<li><a href='#bioacoustic_index'><p>Bioacoustic Index</p></a></li>
<li><a href='#measure_signals'><p>Measure a signal or song in a wavefile</p></a></li>
<li><a href='#multiple_sounds'><p>Multiple sound files</p></a></li>
<li><a href='#ndsi'><p>Normalized Difference Soundscape Index</p></a></li>
<li><a href='#sound_raster'><p>ASCII raster from sound file</p></a></li>
<li><a href='#soundecology'><p>Soundscape Ecology</p></a></li>
<li><a href='#tropicalsound'><p>tropicalsound sound example</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Soundscape Ecology</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-03-04</td>
</tr>
<tr>
<td>Author:</td>
<td>Luis J. Villanueva-Rivera and Bryan C. Pijanowski</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Luis J. Villanueva-Rivera &lt;ljvillanueva@coquipr.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions to calculate indices for soundscape ecology and other ecology research that uses audio recordings.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 2.14.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr</td>
</tr>
<tr>
<td>Imports:</td>
<td>parallel, pracma, oce, ineq, vegan, tuneR, seewave</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://ljvillanueva.github.io/soundecology/">http://ljvillanueva.github.io/soundecology/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="http://github.com/ljvillanueva/soundecology/issues">http://github.com/ljvillanueva/soundecology/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-03-05 00:22:52 UTC; ljvillanueva</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-03-05 04:10:15 UTC</td>
</tr>
</table>
<hr>
<h2 id='acoustic_complexity'>Acoustic Complexity Index</h2><span id='topic+acoustic_complexity'></span>

<h3>Description</h3>

<p>Acoustic Complexity Index (ACI) from Pieretti, <em>et al.</em> 2011. 
The ACI is based on the &quot;observation that many biotic sounds, such as bird songs, are 
characterized by an intrinsic variability of intensities, while some types
of human generated noise (such as car passing or airplane transit)
present very constant intensity values&quot; (Pieretti, <em>et al.</em> 2011).
</p>
<p>The index was tested to the ACItot calculated using SoundscapeMeter v 1.0.14.05.2012, courtesy of A. Farina.
</p>
<p>The results given are accumulative. Very long samples will return very large values for ACI. I recommend to divide by number of minutes to get a range of values easier to compare.</p>


<h3>Usage</h3>

<pre><code class='language-R'>	acoustic_complexity(soundfile, min_freq = NA, max_freq = NA, j = 5, fft_w = 512)
	</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="acoustic_complexity_+3A_soundfile">soundfile</code></td>
<td>
<p> an object of class <code>Wave</code> loaded with the function readWave of the <code>tuneR</code> package. </p>
</td></tr>
<tr><td><code id="acoustic_complexity_+3A_min_freq">min_freq</code></td>
<td>
<p> miminum frequency to use when calculating the value, in Hertz. The default is <code>NA</code>. </p>
</td></tr>
<tr><td><code id="acoustic_complexity_+3A_max_freq">max_freq</code></td>
<td>
<p> maximum frequency to use when calculating the value, in Hertz. The default is the maximum for the file. </p>
</td></tr>
<tr><td><code id="acoustic_complexity_+3A_j">j</code></td>
<td>
<p> the cluster size, in seconds. </p>
</td></tr>
<tr><td><code id="acoustic_complexity_+3A_fft_w">fft_w</code></td>
<td>
<p> FFT window to use. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with three objects per channel
</p>
<table role = "presentation">
<tr><td><code>AciTotAll_left</code></td>
<td>
<p> the ACI total for the left channel </p>
</td></tr>
<tr><td><code>AciTotAll_right</code></td>
<td>
<p> the ACI total for the right channel </p>
</td></tr>
<tr><td><code>AciTotAll_left_bymin</code></td>
<td>
<p> the ACI total for the left channel divided by the number of minutes </p>
</td></tr>
<tr><td><code>AciTotAll_right_bymin</code></td>
<td>
<p> the ACI total for the right channel divided by the number of minutes </p>
</td></tr>
<tr><td><code>aci_fl_left_vals</code></td>
<td>
<p> values of ACI(fl) for the left channel </p>
</td></tr>
<tr><td><code>aci_fl_right_vals</code></td>
<td>
<p> values of ACI(fl) for the right channel </p>
</td></tr>
<tr><td><code>aci_left_matrix</code></td>
<td>
<p> Matrix of all values before calculating ACI(fl) for the left channel </p>
</td></tr>
<tr><td><code>aci_right_matrix</code></td>
<td>
<p> Matrix of all values before calculating ACI(fl) for the right channel </p>
</td></tr>
</table>


<h3>References</h3>

<p>Pieretti, N., A. Farina, and D. Morri. 2011. A new methodology to infer the singing activity of an avian community: The Acoustic Complexity Index (ACI). Ecological Indicators 11: 868-873. doi: 10.1016/j.ecolind.2010.11.005</p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(tropicalsound)
	ACI &lt;- acoustic_complexity(tropicalsound)
	print(ACI$AciTotAll_left)
	
	summary(ACI)
	</code></pre>

<hr>
<h2 id='acoustic_diversity'>Acoustic Diversity Index</h2><span id='topic+acoustic_diversity'></span>

<h3>Description</h3>

<p>Acoustic Diversity Index from Villanueva-Rivera <em>et al.</em> 2011. 
The ADI is calculated by dividing the spectrogram into bins (default 10) and taking the proportion of the signals in each bin above a threshold (default -50 dBFS). The ADI is the result of the Shannon index applied to these bins.</p>


<h3>Usage</h3>

<pre><code class='language-R'>acoustic_diversity(soundfile, max_freq = 10000, db_threshold = -50, 
freq_step = 1000, shannon = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="acoustic_diversity_+3A_soundfile">soundfile</code></td>
<td>
<p> an object of class <code>Wave</code> loaded with the function readWave of the <code>tuneR</code> package. </p>
</td></tr>
<tr><td><code id="acoustic_diversity_+3A_max_freq">max_freq</code></td>
<td>
<p> maximum frequency to use when calculating the value, in Hertz. </p>
</td></tr>
<tr><td><code id="acoustic_diversity_+3A_db_threshold">db_threshold</code></td>
<td>
<p> threshold to use in the calculation. </p>
</td></tr>
<tr><td><code id="acoustic_diversity_+3A_freq_step">freq_step</code></td>
<td>
<p> size of frequency bands. </p>
</td></tr>
<tr><td><code id="acoustic_diversity_+3A_shannon">shannon</code></td>
<td>
<p> TRUE to use the Shannon's diversity index to calculate the ADI (default). </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with five objects per channel
</p>
<table role = "presentation">
<tr><td><code>adi_left</code></td>
<td>
<p> ADI value for the left channel </p>
</td></tr>
<tr><td><code>adi_right</code></td>
<td>
<p> ADI value for the right channel </p>
</td></tr>
<tr><td><code>left_band_values</code></td>
<td>
<p> vector of proportion values for each band for the left channel </p>
</td></tr>
<tr><td><code>right_band_values</code></td>
<td>
<p> vector of proportion values for each band for the right channel </p>
</td></tr>
<tr><td><code>left_bandrange_values</code></td>
<td>
<p> vector of frequency values for each band for the left channel </p>
</td></tr>
<tr><td><code>right_bandrange_values</code></td>
<td>
<p> vector of frequency values for each band for the right channel </p>
</td></tr>
</table>


<h3>Note</h3>

<p>The code to calculate the ADI has changed due to an error we detected in the original scripts in which the value was calculated using a different equation. In a test of ~38k files, both ways to calculate were highly correlated. This version of the function uses the Shannon's Diversity Index. To obtain a result using the old calculation, set the argument <code>shannon</code> to <code>FALSE</code>. Please check the vignette &quot;Changes in the Acoustic Diversity Index&quot;, included in the package, for more details.
</p>
<p>For audio files with one channel, the results are showed as the left channel, the right channel returns <code>NA</code>.</p>


<h3>References</h3>

<p>Villanueva-Rivera, L. J., B. C. Pijanowski, J. Doucette, and B. Pekin. 2011. A primer of acoustic analysis for landscape ecologists. Landscape Ecology 26: 1233-1246. doi: 10.1007/s10980-011-9636-9.</p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(tropicalsound)
	result &lt;- acoustic_diversity(tropicalsound)
	
	print(result$adi_left)
	
	summary(result)
	</code></pre>

<hr>
<h2 id='acoustic_evenness'>Acoustic Evenness Index</h2><span id='topic+acoustic_evenness'></span>

<h3>Description</h3>

<p>Acoustic Evenness Index from Villanueva-Rivera <em>et al.</em> 2011 (band evenness using the Gini index). 
The AEI is calculated by dividing the spectrogram into bins (default 10) and taking the proportion of the signals in each bin above a threshold (default -50 dBFS). The AEI is the result of the Gini index applied to these bins.</p>


<h3>Usage</h3>

<pre><code class='language-R'>acoustic_evenness(soundfile, max_freq = 10000, db_threshold = -50, freq_step = 1000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="acoustic_evenness_+3A_soundfile">soundfile</code></td>
<td>
<p> an object of class <code>Wave</code> loaded with the function readWave of the <code>tuneR</code> package. </p>
</td></tr>
<tr><td><code id="acoustic_evenness_+3A_max_freq">max_freq</code></td>
<td>
<p> maximum frequency to use when calculating the value, in Hertz. </p>
</td></tr>
<tr><td><code id="acoustic_evenness_+3A_db_threshold">db_threshold</code></td>
<td>
<p> threshold to use in the calculation. </p>
</td></tr>
<tr><td><code id="acoustic_evenness_+3A_freq_step">freq_step</code></td>
<td>
<p> size of frequency bands. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with five objects per channel
</p>
<table role = "presentation">
<tr><td><code>aei_left</code></td>
<td>
<p> AEI for the left channel </p>
</td></tr>
<tr><td><code>aei_right</code></td>
<td>
<p> AEI for the right channel </p>
</td></tr>
</table>


<h3>Note</h3>

<p>For audio files with one channel, the results are showed as the left channel, the right channel returns <code>NA</code>.</p>


<h3>References</h3>

<p>Villanueva-Rivera, L. J., B. C. Pijanowski, J. Doucette, and B. Pekin. 2011. A primer of acoustic analysis for landscape ecologists. Landscape Ecology 26: 1233-1246. doi: 10.1007/s10980-011-9636-9.</p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(tropicalsound)
	result &lt;- acoustic_evenness(tropicalsound)
	print(result$aei_left)
	
	summary(result)
	</code></pre>

<hr>
<h2 id='bioacoustic_index'>Bioacoustic Index</h2><span id='topic+bioacoustic_index'></span>

<h3>Description</h3>

<p>Bioacoustic Index from Boelman, <em>et al.</em> 2007. 
Inspired on Matlab code courtesy of NT Boelman.
Several parts where changed, in particular log math, so this won't be
directly comparable to the original code in the paper.
</p>
<p>The Bioacoustic Index is calculated as the &quot;area under each curve included all frequency bands associated
with the dB value that was greater than the minimum dB value for each curve. The area values are thus a
function of both the sound level and the number of frequency bands used by the avifauna&quot; (Boelman, <em>et al.</em> 2007).</p>


<h3>Usage</h3>

<pre><code class='language-R'>bioacoustic_index(soundfile, min_freq = 2000, max_freq = 8000, fft_w = 512)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bioacoustic_index_+3A_soundfile">soundfile</code></td>
<td>
<p> an object of class <code>Wave</code> loaded with the function readWave of the <code>tuneR</code> package. </p>
</td></tr>
<tr><td><code id="bioacoustic_index_+3A_min_freq">min_freq</code></td>
<td>
<p> minimum frequency to use when calculating the value, in Hertz. </p>
</td></tr>
<tr><td><code id="bioacoustic_index_+3A_max_freq">max_freq</code></td>
<td>
<p> maximum frequency to use when calculating the value, in Hertz. </p>
</td></tr>
<tr><td><code id="bioacoustic_index_+3A_fft_w">fft_w</code></td>
<td>
<p> FFT window size. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list with one object per channel
</p>
<table role = "presentation">
<tr><td><code>left_area</code></td>
<td>
<p> area under the curve for the left channel </p>
</td></tr>
<tr><td><code>right_area</code></td>
<td>
<p> area under the curve for the right channel </p>
</td></tr>
</table>


<h3>References</h3>

<p>Boelman NT, Asner GP, Hart PJ, Martin RE. 2007. Multi-trophic invasion resistance in Hawaii: bioacoustics, field surveys, and airborne remote sensing. Ecological Applications 17: 2137-2144.</p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(tropicalsound)
	bioindex &lt;- bioacoustic_index(tropicalsound)
	print(bioindex$left_area)
	
	summary(bioindex)
	</code></pre>

<hr>
<h2 id='measure_signals'>Measure a signal or song in a wavefile</h2><span id='topic+measure_signals'></span>

<h3>Description</h3>

<p>This function lets the user select bounding boxes to get statistics of the signals of interest in a sound file. </p>


<h3>Usage</h3>

<pre><code class='language-R'>measure_signals(wavfile, wl = 512, min_freq = NA, max_freq = NA, min_time = NA,
  max_time = NA, plot_range = 50, dBFS_range = 30, sample_size = 1,
  resultfile = NA, channel = "left")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="measure_signals_+3A_wavfile">wavfile</code></td>
<td>
<p> a sound file in wav format. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_wl">wl</code></td>
<td>
<p> window length for the spectrogram. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_min_freq">min_freq</code></td>
<td>
<p> minimum frequency to draw the spectrogram, in kiloHertz. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_max_freq">max_freq</code></td>
<td>
<p> maximum frequency to draw the spectrogram, in kiloHertz. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_min_time">min_time</code></td>
<td>
<p> minimum time to draw the spectrogram, in seconds. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_max_time">max_time</code></td>
<td>
<p> maximum time to draw the spectrogram, in seconds. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_plot_range">plot_range</code></td>
<td>
<p> lower limit of values to plot the spectrogram. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_dbfs_range">dBFS_range</code></td>
<td>
<p> range of values that is considered a signal, based on the maximum that is calculated. See notes below. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_sample_size">sample_size</code></td>
<td>
<p> number of samples to measure in the spectrogram. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_resultfile">resultfile</code></td>
<td>
<p> name of the file to save the results. </p>
</td></tr>
<tr><td><code id="measure_signals_+3A_channel">channel</code></td>
<td>
<p> which channel to plot. </p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function will open a spectrogram plot to allow the user to click on the regions of interest. Once all the samples are selected, the function saves a file with the values measured in each sample. In addition, the results of the function <code>dfreq</code> of the package <code>seewave</code> are saved on a folder named the same as the wavfile, without the .wav extension. </p>


<h3>Note</h3>

<p> For the <code>dBFS_range</code> argument, the code uses the maximum of the values inside the selected region and saves as a resulting signal the values that fall between <code>(maximum - dBFS_range)</code> and the maximum. A selected region with a maximum value of -5 and <code>dBFS_range</code> set to 30 will consider the area with values between -35 and -5 dBFS as a signal. 
</p>
<p>The function creates a folder <code>dfreq</code> where it saves csv files with the results of the function <code>dfreq</code> from <code>seewave</code>. The name of each file is coded as: wavfile.samplenumber.csv
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Take 5 samples of the file file.wav between 1 - 4 kHz, from 10 to 30 seconds.
measure_signals(wavfile="file.wav", wl=2048, min_freq=1, max_freq=4,
  dBFS_range=30, min_time=10, max_time=30, sample_size=5,
  resultfile="results.csv", plot_range=70)
	
## End(Not run)
	</code></pre>

<hr>
<h2 id='multiple_sounds'>Multiple sound files</h2><span id='topic+multiple_sounds'></span>

<h3>Description</h3>

<p>Function to extract the specified index from all the wav or flac files in a directory. The results, including the filename and wave technical details, are saved to a csv file. If the computer has multiple cores, it can run files in parallel.</p>


<h3>Usage</h3>

<pre><code class='language-R'>multiple_sounds(directory, resultfile, soundindex, no_cores = 1, 
flac = FALSE, from = NA, to = NA, units = NA, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="multiple_sounds_+3A_directory">directory</code></td>
<td>
<p> a valid directory, readable by the user, that contains the wav files. </p>
</td></tr>
<tr><td><code id="multiple_sounds_+3A_resultfile">resultfile</code></td>
<td>
<p> name of the text file to which write the results in comma-separated values format.</p>
</td></tr>
<tr><td><code id="multiple_sounds_+3A_soundindex">soundindex</code></td>
<td>
<p> which index to calculate: 
</p>

<ul>
<li> <p><code>ndsi</code>
</p>
</li>
<li> <p><code>acoustic_complexity</code>
</p>
</li>
<li> <p><code>acoustic_diversity</code>
</p>
</li>
<li> <p><code>acoustic_evenness</code>
</p>
</li>
<li> <p><code>bioacoustic_index</code>
</p>
</li>
<li> <p><code>H</code> from the <code>seewave</code> package
</p>
</li></ul>

</td></tr>
<tr><td><code id="multiple_sounds_+3A_no_cores">no_cores</code></td>
<td>
<p> number of cores to use when calculating the indices. Can be <code>max</code> to use all cores, <code>-1</code> to use all but one core, or any positive integer. Default is 1. Uses the <code>parallel</code> package.</p>
</td></tr>
<tr><td><code id="multiple_sounds_+3A_flac">flac</code></td>
<td>
<p> logical variable to indicate that the files are in FLAC format. FLAC must be installed in the system (see note below). Uses the function <code>wav2flac</code> of <code>seewave</code>.</p>
</td></tr>
<tr><td><code id="multiple_sounds_+3A_from">from</code></td>
<td>
<p> tells <code>readWave</code> where to start loading the files. All three arguments <code>from</code>, <code>to</code>, and <code>units</code> must be specified at the same time, if used.</p>
</td></tr>
<tr><td><code id="multiple_sounds_+3A_to">to</code></td>
<td>
<p> tells <code>readWave</code> where to stop loading the files. All three arguments <code>from</code>, <code>to</code>, and <code>units</code> must be specified at the same time, if used.</p>
</td></tr>
<tr><td><code id="multiple_sounds_+3A_units">units</code></td>
<td>
<p> tells <code>readWave</code> which units to use to determine the start and stop points to load the files. The options are <code>"samples"</code>, <code>"seconds"</code>, <code>"minutes"</code>, or <code>"hours"</code>. All three arguments <code>from</code>, <code>to</code>, and <code>units</code> must be specified at the same time, if used.</p>
</td></tr>
<tr><td><code id="multiple_sounds_+3A_...">...</code></td>
<td>
<p> additional variables to pass to the selected function. See each function's help for details.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>FLAC stands for Free Lossless Audio Codec. Files in FLAC format have been compressed without destruction of data, which happens in lossy compression codecs like the popular MP3. Files can be between 40-60% of the size of the original wav file, although this value depends on the contents. For more information and to download FLAC, visit http://xiph.org/flac/</p>


<h3>Examples</h3>

<pre><code class='language-R'>	## Not run: 
		#Calculate the ACI of all the wav
		# files in the directory "/home/user/wavs/"
		# using the function acoustic_complexity
		multiple_sounds(directory = "/home/user/wavs/", 
			resultfile = "/home/user/results.csv", 
			soundindex = "acoustic_complexity")
		
		#Calculate the same as above using 12000Hz as the
		# maximum frequency instead of the default.
		multiple_sounds(directory = "/home/user/wavs/", 
			resultfile = "/home/user/results.csv", 
			soundindex = "acoustic_complexity", max_freq = 12000)
			
		#Calculate the same as above using two cores
		multiple_sounds(directory = "/home/user/wavs/", 
			resultfile = "/home/user/results.csv", 
			soundindex = "acoustic_complexity", no_cores = 2)
			
		#Calculate the same as above using all the cores
		# the computer has
		multiple_sounds(directory="/home/user/wavs/", 
			resultfile = "/home/user/results.csv", 
			soundindex = "acoustic_complexity", no_cores = "max")
			
		#Calculate the same as above using all but one cores
		multiple_sounds(directory = "/home/user/wavs/", 
			resultfile = "/home/user/results.csv", 
			soundindex = "acoustic_complexity", no_cores = -1)
		
## End(Not run)
	</code></pre>

<hr>
<h2 id='ndsi'>Normalized Difference Soundscape Index</h2><span id='topic+ndsi'></span>

<h3>Description</h3>

<p>Normalized Difference Soundscape Index (NDSI) from REAL and Kasten, <em>et al.</em> 2012. The NDSI
seeks to &quot;estimate the level of anthropogenic disturbance on the soundscape by
computing the ratio of human-generated (anthrophony) to biological
(biophony) acoustic components found in field collected sound samples&quot; (Kasten, <em>et al.</em> 2012).
</p>
<p>Tested with Matlab code courtesy of S. Gage.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ndsi(soundfile, fft_w = 1024, anthro_min = 1000, anthro_max = 2000, 
	bio_min = 2000, bio_max = 11000)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ndsi_+3A_soundfile">soundfile</code></td>
<td>
<p> an object of class <code>Wave</code> loaded with the function readWave of the <code>tuneR</code> package. </p>
</td></tr>
<tr><td><code id="ndsi_+3A_fft_w">fft_w</code></td>
<td>
<p> FFT window size.</p>
</td></tr>
<tr><td><code id="ndsi_+3A_anthro_min">anthro_min</code></td>
<td>
<p> minimum value of the range of frequencies of the anthrophony.</p>
</td></tr>
<tr><td><code id="ndsi_+3A_anthro_max">anthro_max</code></td>
<td>
<p> maximum value of the range of frequencies of the anthrophony.</p>
</td></tr>
<tr><td><code id="ndsi_+3A_bio_min">bio_min</code></td>
<td>
<p> minimum value of the range of frequencies of the biophony.</p>
</td></tr>
<tr><td><code id="ndsi_+3A_bio_max">bio_max</code></td>
<td>
<p> maximum value of the range of frequencies of the biophony.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The bin size is determined as the difference between anthro_max and anthro_min, by default 1000 Hz.
</p>


<h3>Value</h3>

<p>Returns a list with one object per channel
</p>
<table role = "presentation">
<tr><td><code>ndsi_left</code></td>
<td>
<p> NDSI value for the left channel </p>
</td></tr>
<tr><td><code>ndsi_right</code></td>
<td>
<p> NDSI value for the right channel </p>
</td></tr>
<tr><td><code>biophony_left</code></td>
<td>
<p> value for the biophony for the left channel </p>
</td></tr>
<tr><td><code>anthrophony_left</code></td>
<td>
<p> value for the anthrophony for the left channel </p>
</td></tr>
<tr><td><code>biophony_right</code></td>
<td>
<p> value for the biophony for the right channel </p>
</td></tr>
<tr><td><code>anthrophony_right</code></td>
<td>
<p> value for the anthrophony for the right channel </p>
</td></tr>
</table>


<h3>References</h3>

<p>Remote Environmental Assessment Laboratory. http://www.real.msu.edu
</p>
<p>Kasten, Eric P., Stuart H. Gage, Jordan Fox, and Wooyeong Joo. 2012.
The Remote Environmental Assessment Laboratory's Acoustic Library: An Archive for 
Studying Soundscape Ecology. Ecological Informatics 12: 50-67. doi: 10.1016/j.ecoinf.2012.08.001
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(tropicalsound)
	NDSI &lt;- ndsi(tropicalsound)
	print(NDSI$ndsi_left)
	
	summary(NDSI)
	</code></pre>

<hr>
<h2 id='sound_raster'>ASCII raster from sound file</h2><span id='topic+sound_raster'></span>

<h3>Description</h3>

<p>This function creates a raster file in ASCII format from the spectrogram of a soundfile. This file can be opened in ArcGIS or any other GIS software. For more details see the tutorial of Villanueva-Rivera <em>et al.</em> 2011.</p>


<h3>Usage</h3>

<pre><code class='language-R'>sound_raster(wavfile = NA, wav_directory = NA, max_freq = 10000, no_cores = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sound_raster_+3A_wavfile">wavfile</code></td>
<td>
<p> a single sound file in wav format. </p>
</td></tr>
<tr><td><code id="sound_raster_+3A_max_freq">max_freq</code></td>
<td>
<p> maximum frequency to draw the spectrogram, in Hertz. </p>
</td></tr>
<tr><td><code id="sound_raster_+3A_wav_directory">wav_directory</code></td>
<td>
<p> a directory that contains wav files. To specify the working directory, use <code>wav_directory="."</code> </p>
</td></tr>
<tr><td><code id="sound_raster_+3A_no_cores">no_cores</code></td>
<td>
<p> number of cores to use when working in a directory. Can be <code>max</code> to use all cores, <code>-1</code> to use all but one core, or any positive integer. Default is 1. Uses the <code>parallel</code> package.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function will save a file for each channel, in the same directory where the files are at, with the extension .asc.</p>


<h3>Note</h3>

<p> To get a raster file for a single file, use the argument <code>wavfile</code>. For many files, use the argument <code>wav_directory</code>. Do not use both at the same time or the function will return an error. 
</p>
<p>This function was released with the version 1.3 of the tutorial of the primer paper, available at:
</p>
<p>http://ltm.agriculture.purdue.edu/soundscapes/primer/
</p>
<p>and at the website of the package:
</p>
<p>http://ljvillanueva.github.io/soundecology/</p>


<h3>References</h3>

<p>Villanueva-Rivera, L. J., B. C. Pijanowski, J. Doucette, and B. Pekin. 2011. A primer of acoustic analysis for landscape ecologists. Landscape Ecology 26: 1233-1246. doi: 10.1007/s10980-011-9636-9.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
sound_raster(wavfile = "file1.wav")

sound_raster(wav_directory = "/home/user/wavdirectory")

sound_raster(wav_directory = "/home/user/wavdirectory", no_cores = 4)
	
## End(Not run)
	</code></pre>

<hr>
<h2 id='soundecology'>Soundscape Ecology</h2><span id='topic+soundecology'></span>

<h3>Description</h3>

<p>Functions to calculate indices for soundscape ecology and other ecology research that uses audio recordings.</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
		Package: </td><td style="text-align: left;"> soundecology</td>
</tr>
<tr>
 <td style="text-align: left;">
		Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
		Version: </td><td style="text-align: left;"> 1.3.3</td>
</tr>
<tr>
 <td style="text-align: left;">
		Date: </td><td style="text-align: left;"> 2018-03-04</td>
</tr>
<tr>
 <td style="text-align: left;">
		License: </td><td style="text-align: left;"> GPLv3</td>
</tr>
<tr>
 <td style="text-align: left;">
		</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Luis J. Villanueva-Rivera and Bryan C. Pijanowski
</p>

<hr>
<h2 id='tropicalsound'>tropicalsound sound example</h2><span id='topic+tropicalsound'></span>

<h3>Description</h3>

<p>Sample sound of a digital recording of a chorus of tropical frogs.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(tropicalsound)
</code></pre>


<h3>Format</h3>

<p>A <code>Wave</code> object.</p>


<h3>Details</h3>

<p>Duration = 20 sec. Sampling rate = 22050 Hz.
</p>


<h3>Source</h3>

<p>Recording made at a tropical rainforest in Puerto Rico by Luis J. Villanueva-Rivera.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>	data(tropicalsound)
	
	tropicalsound
	</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
