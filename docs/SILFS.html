<!DOCTYPE html><html><head><title>Help for package SILFS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SILFS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#BIC_PFP'><p>Selecting Tuning Parameter for Factor Adjusted-Pairwise Fusion Penalty (FA-PFP) Method via corresponding BIC</p></a></li>
<li><a href='#BIC_SILFS'><p>Selecting Tuning Parameter for SILFS Method via corresponding BIC</p></a></li>
<li><a href='#DCADMM_iter_l1'><p>SILFS-Based Subgroup Identification and Variable Selection Optimized by DC-ADMM under the L1 Distance</p></a></li>
<li><a href='#DCADMM_iter_l2'><p>SILFS-Based Subgroup Identification and Variable Selection Optimized by DC-ADMM under the L2 Distance</p></a></li>
<li><a href='#FA_PFP'><p>Factor Adjusted-Pairwise Fusion Penalty (FA-PFP) Method for Subgroup Identification and Variable Selection</p></a></li>
<li><a href='#INIT'><p>Initialization Function for the Intercept Parameter</p></a></li>
<li><a href='#SCAR'><p>Standard Center Augmented Regularization (S-CAR) Method for Subgroup Identification and Variable Selection</p></a></li>
<li><a href='#SILFS'><p>SILFS-Based Subgroup Identification and Variable Selection Optimized by Coordinate Descent under the L2 Distance</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Subgroup Identification with Latent Factor Structure</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Yong He [aut],
  Dong Liu [aut],
  Fuxin Wang [aut, cre],
  Mingjuan Zhang [aut],
  Wenxin Zhou [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fuxin Wang &lt;wangfuxin2001@163.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>In various domains, many datasets exhibit both high variable dependency and group structures, which necessitates their simultaneous estimation. This package provides functions for two subgroup identification methods based on penalized functions, both of which utilize factor model structures to adapt to data with cross-sectional dependency. The first method is the Subgroup Identification with Latent Factor Structure Method (SILFSM) we proposed. By employing Center-Augmented Regularization and factor structures, the SILFSM effectively eliminates data dependencies while identifying subgroups within datasets. For this model, we offer optimization functions based on two different methods: Coordinate Descent and our newly developed Difference of Convex-Alternating Direction Method of Multipliers (DC-ADMM) algorithms; the latter can be applied to cases where the distance function in Center-Augmented Regularization takes L1 and L2 forms. The other method is the Factor-Adjusted Pairwise Fusion Penalty (FA-PFP) model, which incorporates factor augmentation into the Pairwise Fusion Penalty (PFP) developed by Ma, S. and Huang, J. (2017) &lt;<a href="https://doi.org/10.1080%2F01621459.2016.1148039">doi:10.1080/01621459.2016.1148039</a>&gt;. Additionally, we provide a function for the Standard CAR (S-CAR) method, which does not consider the dependency and is for comparative analysis with other approaches. Furthermore, functions based on the Bayesian Information Criterion (BIC) of the SILFSM and the FA-PFP method are also included in 'SILFS' for selecting tuning parameters. For more details of Subgroup Identification with Latent Factor Structure Method, please refer to He et al. (2024) &lt;<a href="https://doi.org/10.48550%2FarXiv.2407.00882">doi:10.48550/arXiv.2407.00882</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, glmnet, stats, Ckmeans.1d.dp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-03 07:37:39 UTC; 王福鑫</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-07-03 16:20:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='BIC_PFP'>Selecting Tuning Parameter for Factor Adjusted-Pairwise Fusion Penalty (FA-PFP) Method via corresponding BIC</h2><span id='topic+BIC_PFP'></span>

<h3>Description</h3>

<p>This function is to select tuning parameters simultaneously for FA-PFP method via minimizing the BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BIC_PFP(
  Y,
  Fhat,
  Uhat,
  alpha_init,
  lasso_start,
  lasso_stop,
  lam_start,
  lam_stop,
  grid_1,
  grid_2,
  epsilon
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BIC_PFP_+3A_y">Y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_fhat">Fhat</code></td>
<td>
<p>The estimated common factors matrix of size <code class="reqn">n \times r</code>.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_uhat">Uhat</code></td>
<td>
<p>The estimated idiosyncratic factors matrix of size <code class="reqn">n \times p</code>.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_alpha_init">alpha_init</code></td>
<td>
<p>The initialization of intercept parameter.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_lasso_start">lasso_start</code></td>
<td>
<p>The user-supplied start search value of the tuning parameters for LASSO.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_lasso_stop">lasso_stop</code></td>
<td>
<p>The user-supplied stop search value of the tuning parameters for LASSO.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_lam_start">lam_start</code></td>
<td>
<p>The user-supplied start search value of the tuning parameters for Pairwise Fusion Penalty.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_lam_stop">lam_stop</code></td>
<td>
<p>The user-supplied stop search value of the tuning parameters for Pairwise Fusion Penalty.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_grid_1">grid_1</code></td>
<td>
<p>The user-supplied number of search grid points corresponding to the LASSO tuning parameter.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_grid_2">grid_2</code></td>
<td>
<p>The user-supplied number of search grid points corresponding to the tuning parameter for Pairwise Fusion Penalty.</p>
</td></tr>
<tr><td><code id="BIC_PFP_+3A_epsilon">epsilon</code></td>
<td>
<p>The user-supplied stopping tolerance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>lasso</code></td>
<td>
<p>The tuning parameter of the LASSO penalty selected using BIC.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The tuning parameter of the Pairwise Concave Fusion Penalty selected using BIC.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yong He, Liu Dong, Fuxin Wang, Mingjuan Zhang, Wenxin Zhou.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 50
p &lt;- 50
r &lt;- 3
lasso_start &lt;- sqrt(log(p)/n)*0.1
lasso_stop &lt;- sqrt(log(p)/n)
lam_start &lt;- 0.3
lam_stop &lt;- 1
grid_1 &lt;- 5
grid_2 &lt;- 5
alpha &lt;- sample(c(-3,3),n,replace=TRUE,prob=c(1/2,1/2))
beta &lt;- c(rep(1,2),rep(0,48))
B &lt;- matrix((rnorm(p*r,1,1)),p,r)
F_1 &lt;- matrix((rnorm(n*r,0,1)),n,r)
U &lt;- matrix(rnorm(p*n,0,0.1),n,p)
X &lt;- F_1%*%t(B)+U
Y &lt;- alpha + X%*%beta + rnorm(n,0,0.5)
alpha_init &lt;- INIT(Y,F_1,0.1)

BIC_PFP(Y,F_1,U,alpha_init,lasso_start,lasso_stop,lam_start,lam_stop,grid_1,grid_2,0.3)

</code></pre>

<hr>
<h2 id='BIC_SILFS'>Selecting Tuning Parameter for SILFS Method via corresponding BIC</h2><span id='topic+BIC_SILFS'></span>

<h3>Description</h3>

<p>This function is to select tuning parameters simultaneously for SILFS method via minimizing the BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BIC_SILFS(
  Y,
  Fhat,
  Uhat,
  K,
  alpha_init,
  lasso_start,
  lasso_stop,
  CAR_start,
  CAR_stop,
  grid_1,
  grid_2,
  epsilon
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="BIC_SILFS_+3A_y">Y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_fhat">Fhat</code></td>
<td>
<p>The estimated common factors matrix of size <code class="reqn">n \times r</code>.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_uhat">Uhat</code></td>
<td>
<p>The estimated idiosyncratic factors matrix of size <code class="reqn">n \times p</code>.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_k">K</code></td>
<td>
<p>The estimated subgroup number.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_alpha_init">alpha_init</code></td>
<td>
<p>The initialization of intercept parameter.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_lasso_start">lasso_start</code></td>
<td>
<p>The user-supplied start search value of the tuning parameters for LASSO.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_lasso_stop">lasso_stop</code></td>
<td>
<p>The user-supplied stop search value of the tuning parameters for LASSO.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_car_start">CAR_start</code></td>
<td>
<p>The user-supplied start search value of the tuning parameters for Center-Augmented Regularization.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_car_stop">CAR_stop</code></td>
<td>
<p>The user-supplied stop search value of the tuning parameters for Center-Augmented Regularization.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_grid_1">grid_1</code></td>
<td>
<p>The user-supplied number of search grid points corresponding to the LASSO tuning parameter.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_grid_2">grid_2</code></td>
<td>
<p>The user-supplied number of search grid points corresponding to the tuning parameter for Center-Augmented Regularization.</p>
</td></tr>
<tr><td><code id="BIC_SILFS_+3A_epsilon">epsilon</code></td>
<td>
<p>The user-supplied stopping tolerance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>lasso</code></td>
<td>
<p>The tuning parameter of the LASSO penalty selected using BIC.</p>
</td></tr>
<tr><td><code>CAR</code></td>
<td>
<p>The tuning parameter of the Center Augmented Regularization selected using BIC.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 50
p &lt;- 50
r &lt;- 3
K &lt;- 2
lasso_start &lt;- sqrt(log(p)/n)*0.01
lasso_stop &lt;- sqrt(log(p)/n)*10^(0.5)
CAR_start &lt;- 0.001
CAR_stop &lt;- 0.1
grid_1 &lt;- 5
grid_2 &lt;- 5
alpha &lt;- sample(c(-3,3),n,replace=TRUE,prob=c(1/2,1/2))
beta &lt;- c(rep(1,2),rep(0,48))
B &lt;- matrix((rnorm(p*r,1,1)),p,r)
F_1 &lt;- matrix((rnorm(n*r,0,1)),n,r)
U &lt;- matrix(rnorm(p*n,0,0.1),n,p)
X &lt;- F_1%*%t(B)+U
Y &lt;- alpha + X%*%beta + rnorm(n,0,0.5)
alpha_init &lt;- INIT(Y,F_1,0.1)

BIC_SILFS(Y,F_1,U,K,alpha_init,lasso_start,lasso_stop,CAR_start,CAR_stop,grid_1,grid_2,0.3)

</code></pre>

<hr>
<h2 id='DCADMM_iter_l1'>SILFS-Based Subgroup Identification and Variable Selection Optimized by DC-ADMM under the L1 Distance</h2><span id='topic+DCADMM_iter_l1'></span>

<h3>Description</h3>

<p>This function employs SILFS method and uses the corresponding Difference of Convex functions-Alternating Direction Method of Multipliers (DC-ADMM) algorithm for optimization to identify subgroup structures and conduct variable selection under the L1 Distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DCADMM_iter_l1(
  Y,
  F_hat,
  U_hat,
  r_1,
  r_2,
  r_3,
  lambda_1,
  lambda_2,
  K,
  alpha_init,
  epsilon_1,
  epsilon_2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DCADMM_iter_l1_+3A_y">Y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_f_hat">F_hat</code></td>
<td>
<p>The estimated factor matrix of size <code class="reqn">n \times r</code>.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_u_hat">U_hat</code></td>
<td>
<p>The estimated idiosyncratic factors matrix of size <code class="reqn">n \times p</code>.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_r_1">r_1</code></td>
<td>
<p>The Lagrangian augmentation parameter for constraints of intercepts.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_r_2">r_2</code></td>
<td>
<p>The Lagrangian augmentation parameter for constraints of group centers.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_r_3">r_3</code></td>
<td>
<p>The Lagrangian augmentation parameter for constraints of coefficients.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_lambda_1">lambda_1</code></td>
<td>
<p>The tuning parameter for Center-Augmented Regularization.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_lambda_2">lambda_2</code></td>
<td>
<p>The tuning parameter for LASSO.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_k">K</code></td>
<td>
<p>The estimated group number.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_alpha_init">alpha_init</code></td>
<td>
<p>The initialization of intercept parameter.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_epsilon_1">epsilon_1</code></td>
<td>
<p>The user-supplied stopping error for outer loop.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l1_+3A_epsilon_2">epsilon_2</code></td>
<td>
<p>The user-supplied stopping error for inner loop.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>alpha_curr</code></td>
<td>
<p>The estimated intercept parameter vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code>gamma_curr</code></td>
<td>
<p>The estimated vector of subgroup centers of length <code class="reqn">K</code>.</p>
</td></tr>
<tr><td><code>theta_curr</code></td>
<td>
<p>The estimated regression coefficient vector, matched with common factor terms, with a dimension of <code class="reqn">r</code>.</p>
</td></tr>
<tr><td><code>beta_curr</code></td>
<td>
<p>The estimated regression coefficients matched with idiosyncratic factors, with a dimension of <code class="reqn">p</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yong He, Liu Dong, Fuxin Wang, Mingjuan Zhang, Wenxin Zhou.
</p>


<h3>References</h3>

<p>He, Y., Liu, D., Wang, F., Zhang, M., Zhou, W., 2024. High-Dimensional Subgroup Identification under Latent Factor Structures.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 50
p &lt;- 50
r &lt;- 3
K &lt;- 2
alpha &lt;- sample(c(-3,3),n,replace=TRUE,prob=c(1/2,1/2))
beta &lt;- c(rep(1,2),rep(0,48))
B &lt;- matrix((rnorm(p*r,1,1)),p,r)
F_1 &lt;- matrix((rnorm(n*r,0,1)),n,r)
U &lt;- matrix(rnorm(p*n,0,0.1),n,p)
X &lt;- F_1%*%t(B)+U
Y &lt;- alpha + X%*%beta + rnorm(n,0,0.5)
alpha_init &lt;- INIT(Y,F_1,0.1)
DCADMM_iter_l1(Y,F_1,U,0.5,0.5,0.5,0.01,0.05,K,alpha_init,1,0.3)
</code></pre>

<hr>
<h2 id='DCADMM_iter_l2'>SILFS-Based Subgroup Identification and Variable Selection Optimized by DC-ADMM under the L2 Distance</h2><span id='topic+DCADMM_iter_l2'></span>

<h3>Description</h3>

<p>This function employs SILFS method and uses the corresponding Difference of Convex functions-Alternating Direction Method of Multipliers (DC-ADMM) algorithm for optimization to identify subgroup structures and conduct variable selection under the L2 Distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DCADMM_iter_l2(
  Y,
  F_hat,
  U_hat,
  r_1,
  r_2,
  r_3,
  lambda_1,
  lambda_2,
  K,
  alpha_init,
  epsilon_1,
  epsilon_2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DCADMM_iter_l2_+3A_y">Y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_f_hat">F_hat</code></td>
<td>
<p>The estimated factor matrix of size <code class="reqn">n \times r</code>.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_u_hat">U_hat</code></td>
<td>
<p>The estimated idiosyncratic factors matrix of size <code class="reqn">n \times p</code>.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_r_1">r_1</code></td>
<td>
<p>The Lagrangian augmentation parameter for constraints of intercepts.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_r_2">r_2</code></td>
<td>
<p>The Lagrangian augmentation parameter for constraints of group centers.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_r_3">r_3</code></td>
<td>
<p>The Lagrangian augmentation parameter for constraints of coefficients.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_lambda_1">lambda_1</code></td>
<td>
<p>The tuning parameter for Center-Augmented Regularization.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_lambda_2">lambda_2</code></td>
<td>
<p>The tuning parameter for LASSO.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_k">K</code></td>
<td>
<p>The estimated group number.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_alpha_init">alpha_init</code></td>
<td>
<p>The initialization of intercept parameter.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_epsilon_1">epsilon_1</code></td>
<td>
<p>The user-supplied stopping error for outer loop.</p>
</td></tr>
<tr><td><code id="DCADMM_iter_l2_+3A_epsilon_2">epsilon_2</code></td>
<td>
<p>The user-supplied stopping error for inner loop.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>alpha_curr</code></td>
<td>
<p>The estimated intercept parameter vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code>gamma_curr</code></td>
<td>
<p>The estimated vector of subgroup centers of length <code class="reqn">K</code>.</p>
</td></tr>
<tr><td><code>theta_curr</code></td>
<td>
<p>The estimated regression coefficient vector, matched with common factor terms, with a dimension of <code class="reqn">r</code>.</p>
</td></tr>
<tr><td><code>beta_curr</code></td>
<td>
<p>The estimated regression coefficients matched with idiosyncratic factors, with a dimension of <code class="reqn">p</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yong He, Liu Dong, Fuxin Wang, Mingjuan Zhang, Wenxin Zhou.
</p>


<h3>References</h3>

<p>He, Y., Liu, D., Wang, F., Zhang, M., Zhou, W., 2024. High-Dimensional Subgroup Identification under Latent Factor Structures.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 50
p &lt;- 50
r &lt;- 3
K &lt;- 2
alpha &lt;- sample(c(-3,3),n,replace=TRUE,prob=c(1/2,1/2))
beta &lt;- c(rep(1,2),rep(0,48))
B &lt;- matrix((rnorm(p*r,1,1)),p,r)
F_1 &lt;- matrix((rnorm(n*r,0,1)),n,r)
U &lt;- matrix(rnorm(p*n,0,0.1),n,p)
X &lt;- F_1%*%t(B)+U
Y &lt;- alpha + X%*%beta + rnorm(n,0,0.5)
alpha_init &lt;- INIT(Y,F_1,0.1)
DCADMM_iter_l2(Y,F_1,U,0.5,0.5,0.5,0.01,0.05,K,alpha_init,1,0.3)
</code></pre>

<hr>
<h2 id='FA_PFP'>Factor Adjusted-Pairwise Fusion Penalty (FA-PFP) Method for Subgroup Identification and Variable Selection</h2><span id='topic+FA_PFP'></span>

<h3>Description</h3>

<p>This function utilizes the FA-PFP method implemented via the Alternating Direction Method of Multipliers (ADMM) algorithm to identify subgroup structures and conduct variable selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FA_PFP(Y, Fhat, Uhat, vartheta, lam, gam, alpha_init, lam_lasso, epsilon)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="FA_PFP_+3A_y">Y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="FA_PFP_+3A_fhat">Fhat</code></td>
<td>
<p>The estimated common factors matrix of size <code class="reqn">n \times r</code>.</p>
</td></tr>
<tr><td><code id="FA_PFP_+3A_uhat">Uhat</code></td>
<td>
<p>The estimated idiosyncratic factors matrix of size <code class="reqn">n \times p</code>.</p>
</td></tr>
<tr><td><code id="FA_PFP_+3A_vartheta">vartheta</code></td>
<td>
<p>The Lagrangian augmentation parameter for intercepts.</p>
</td></tr>
<tr><td><code id="FA_PFP_+3A_lam">lam</code></td>
<td>
<p>The tuning parameter for Pairwise Fusion Penalty.</p>
</td></tr>
<tr><td><code id="FA_PFP_+3A_gam">gam</code></td>
<td>
<p>The user-supplied parameter for Alternating Direction Method of Multipliers (ADMM) algorithm.</p>
</td></tr>
<tr><td><code id="FA_PFP_+3A_alpha_init">alpha_init</code></td>
<td>
<p>The initialization of intercept parameter.</p>
</td></tr>
<tr><td><code id="FA_PFP_+3A_lam_lasso">lam_lasso</code></td>
<td>
<p>The tuning parameter for LASSO.</p>
</td></tr>
<tr><td><code id="FA_PFP_+3A_epsilon">epsilon</code></td>
<td>
<p>The user-supplied stopping tolerance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>alpha_m</code></td>
<td>
<p>The estimated intercept parameter vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code>theta_m</code></td>
<td>
<p>The estimated regression coefficient vector, matched with common factor terms, with a dimension of <code class="reqn">r</code>.</p>
</td></tr>
<tr><td><code>beta_m</code></td>
<td>
<p>The estimated regression coefficients matched with idiosyncratic factors, with a dimension of <code class="reqn">p</code>.</p>
</td></tr>
<tr><td><code>eta_m</code></td>
<td>
<p>A numeric matrix storing the pairwise differences of the estimated intercepts, with size of <code class="reqn">n \times (n\times(n-1)/2)</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yong He, Liu Dong, Fuxin Wang, Mingjuan Zhang, Wenxin Zhou.
</p>


<h3>References</h3>

<p>Ma, S., Huang, J., 2017. A concave pairwise fusion approach to subgroup analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 50
p &lt;- 50
r &lt;- 3
alpha &lt;- sample(c(-3,3),n,replace=TRUE,prob=c(1/2,1/2))
beta &lt;- c(rep(1,2),rep(0,48))
B &lt;- matrix((rnorm(p*r,1,1)),p,r)
F_1 &lt;- matrix((rnorm(n*r,0,1)),n,r)
U &lt;- matrix(rnorm(p*n,0,0.1),n,p)
X &lt;- F_1%*%t(B)+U
Y &lt;- alpha + X%*%beta + rnorm(n,0,0.5)
alpha_init &lt;- INIT(Y,F_1,0.1)
FA_PFP(Y,F_1,U,1,0.67,3,alpha_init,0.05,0.3)
</code></pre>

<hr>
<h2 id='INIT'>Initialization Function for the Intercept Parameter</h2><span id='topic+INIT'></span>

<h3>Description</h3>

<p>This function computes initial values for intercept parameter by solving a ridge regression problem.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>INIT(Y, X, lam_ridge)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="INIT_+3A_y">Y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="INIT_+3A_x">X</code></td>
<td>
<p>The design matrix of size <code class="reqn">n\times p</code>.</p>
</td></tr>
<tr><td><code id="INIT_+3A_lam_ridge">lam_ridge</code></td>
<td>
<p>The tuning parameter for ridge regression.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A numeric vector of length <code class="reqn">n</code>, representing the initial estimation for intercept parameter.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 100
p &lt;- 100
beta &lt;- rep(1,p)
X &lt;- matrix(rnorm(100*100), n, p)
Y &lt;- sample(c(-3,3),n,replace=TRUE,prob=c(1/2,1/2)) +  X%*%beta
lam_ridge &lt;- 0.1
alpha_init &lt;- INIT(Y, X, lam_ridge)
</code></pre>

<hr>
<h2 id='SCAR'>Standard Center Augmented Regularization (S-CAR) Method for Subgroup Identification and Variable Selection</h2><span id='topic+SCAR'></span>

<h3>Description</h3>

<p>This function employs the S-CAR method under L2 distance and uses the Coordinate Descent Algorithm for optimization to identify subgroup structures and execute variable selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SCAR(Y, X, lam_CAR, lam_lasso, alpha_init, K, epsilon)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SCAR_+3A_y">Y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="SCAR_+3A_x">X</code></td>
<td>
<p>The design matrix of size <code class="reqn">n \times p</code>.</p>
</td></tr>
<tr><td><code id="SCAR_+3A_lam_car">lam_CAR</code></td>
<td>
<p>The tuning parameter for Center-Augmented Regularization.</p>
</td></tr>
<tr><td><code id="SCAR_+3A_lam_lasso">lam_lasso</code></td>
<td>
<p>The tuning parameter for lasso.</p>
</td></tr>
<tr><td><code id="SCAR_+3A_alpha_init">alpha_init</code></td>
<td>
<p>The initialization of intercept parameter.</p>
</td></tr>
<tr><td><code id="SCAR_+3A_k">K</code></td>
<td>
<p>The estimated group number.</p>
</td></tr>
<tr><td><code id="SCAR_+3A_epsilon">epsilon</code></td>
<td>
<p>The user-supplied stopping tolerance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following components:
</p>
<table>
<tr><td><code>alpha_m</code></td>
<td>
<p>The estimated intercept parameter vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>The estimated vector of subgroup centers of length <code class="reqn">K</code>.</p>
</td></tr>
<tr><td><code>beta_m</code></td>
<td>
<p>The estimated regression coefficient vector of dimension <code class="reqn">p</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yong He, Liu Dong, Fuxin Wang, Mingjuan Zhang, Wenxin Zhou.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 50
p &lt;- 50
r &lt;- 3
K &lt;- 2
alpha &lt;- sample(c(-3,3),n,replace=TRUE,prob=c(1/2,1/2))
beta &lt;- c(rep(1,2),rep(0,48))
B &lt;- matrix((rnorm(p*r,1,1)),p,r)
F_1 &lt;- matrix((rnorm(n*r,0,1)),n,r)
U &lt;- matrix(rnorm(p*n,0,0.1),n,p)
X &lt;- F_1%*%t(B)+U
Y &lt;- alpha + X%*%beta + rnorm(n,0,0.5)
alpha_init &lt;- INIT(Y,X,0.1)
SCAR(Y,X,0.01,0.05,alpha_init,K,0.3)
</code></pre>

<hr>
<h2 id='SILFS'>SILFS-Based Subgroup Identification and Variable Selection Optimized by Coordinate Descent under the L2 Distance</h2><span id='topic+SILFS'></span>

<h3>Description</h3>

<p>This function employs SILFS method under L2 distance and uses the Coordinate Descent Algorithm for optimization to effectively identify subgroup structures and perform variable selection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SILFS(Y, X_aug, r, lam_CAR, lam_lasso, alpha_init, K, epsilon)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SILFS_+3A_y">Y</code></td>
<td>
<p>The response vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="SILFS_+3A_x_aug">X_aug</code></td>
<td>
<p>The augmented design matrix created by row concatenation of common and idiosyncratic factor matrices, with a size of <code class="reqn">n \times (r+p)</code>.</p>
</td></tr>
<tr><td><code id="SILFS_+3A_r">r</code></td>
<td>
<p>The user supplied number of common factors.</p>
</td></tr>
<tr><td><code id="SILFS_+3A_lam_car">lam_CAR</code></td>
<td>
<p>The tuning parameter for Center-Augmented Regularization.</p>
</td></tr>
<tr><td><code id="SILFS_+3A_lam_lasso">lam_lasso</code></td>
<td>
<p>The tuning parameter for LASSO.</p>
</td></tr>
<tr><td><code id="SILFS_+3A_alpha_init">alpha_init</code></td>
<td>
<p>The initialization of intercept parameter.</p>
</td></tr>
<tr><td><code id="SILFS_+3A_k">K</code></td>
<td>
<p>The user-supplied group number.</p>
</td></tr>
<tr><td><code id="SILFS_+3A_epsilon">epsilon</code></td>
<td>
<p>The user-supplied stopping tolerance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the following components:
</p>
<table>
<tr><td><code>alpha_m</code></td>
<td>
<p>The estimated intercept parameter vector of length <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>The estimated vector of subgroup centers of length <code class="reqn">K</code>.</p>
</td></tr>
<tr><td><code>theta_m</code></td>
<td>
<p>The estimated regression coefficient vector, matched with common factor terms, with a dimension of <code class="reqn">r</code>.</p>
</td></tr>
<tr><td><code>beta_m</code></td>
<td>
<p>The estimated regression coefficients matched with idiosyncratic factors, with a dimension of <code class="reqn">p</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yong He, Liu Dong, Fuxin Wang, Mingjuan Zhang, Wenxin Zhou.
</p>


<h3>References</h3>

<p>He, Y., Liu, D., Wang, F., Zhang, M., Zhou, W., 2024. High-Dimensional Subgroup Identification under Latent Factor Structures.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n &lt;- 50
p &lt;- 50
r &lt;- 3
K &lt;- 2
alpha &lt;- sample(c(-3,3),n,replace=TRUE,prob=c(1/2,1/2))
beta &lt;- c(rep(1,2),rep(0,48))
B &lt;- matrix((rnorm(p*r,1,1)),p,r)
F_1 &lt;- matrix((rnorm(n*r,0,1)),n,r)
U &lt;- matrix(rnorm(p*n,0,0.1),n,p)
X &lt;- F_1%*%t(B)+U
Y &lt;- alpha + X%*%beta + rnorm(n,0,0.5)
alpha_init &lt;- INIT(Y,F_1,0.1)
SILFS(Y,cbind(F_1,U),3,0.01,0.05,alpha_init,K,0.3)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
