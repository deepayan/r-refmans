<!DOCTYPE html><html><head><title>Help for package MLPUGS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MLPUGS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ecc'><p>Fit an Ensemble of Classifier Chains (ECC)</p></a></li>
<li><a href='#MLPUGS-package'><p>MLPUGS: Multi-Label Prediction Using Gibbs Sampling (and Classifier Chains)</p></a></li>
<li><a href='#movies'><p>FiveThirtyEight's Movie Scores</p></a></li>
<li><a href='#predict.ECC'><p>Classify new samples using an Ensemble of Classifier Chains</p></a></li>
<li><a href='#summary.PUGS'><p>Gather samples of predictions</p></a></li>
<li><a href='#validate_pugs'><p>Assess multi-label prediction accuracy</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multi-Label Prediction Using Gibbs Sampling (and Classifier
Chains)</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2016-07-05</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mikhail Popov &lt;mikhail@mpopov.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of classifier chains (CC's) for multi-label
    prediction. Users can employ an external package (e.g. 'randomForest',
    'C50'), or supply their own. The package can train a single set of CC's or
    train an ensemble of CC's &ndash; in parallel if running in a multi-core
    environment. New observations are classified using a Gibbs sampler since
    each unobserved label is conditioned on the others. The package includes
    methods for evaluating the predictions for accuracy and aggregating across
    iterations and models to produce binary or probabilistic classifications.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bearloga/MLPUGS">https://github.com/bearloga/MLPUGS</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bearloga/MLPUGS/issues">https://github.com/bearloga/MLPUGS/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1.2)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, progress, C50, randomForest</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2016-07-06 00:24:49 UTC; mpopov</td>
</tr>
<tr>
<td>Author:</td>
<td>Mikhail Popov [aut, cre] (@bearloga on Twitter)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2016-07-06 09:43:54</td>
</tr>
</table>
<hr>
<h2 id='ecc'>Fit an Ensemble of Classifier Chains (ECC)</h2><span id='topic+ecc'></span>

<h3>Description</h3>

<p>Constructs an ensemble of classifier chains, each chain using a
user-supplied base classifier.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecc(x, y, m = 5, prop_subset = 0.95, run_parallel = FALSE,
  silent = TRUE, .f = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecc_+3A_x">x</code></td>
<td>
<p>A data frame or matrix of features.</p>
</td></tr>
<tr><td><code id="ecc_+3A_y">y</code></td>
<td>
<p>A data frame or matrix of labels. Each label must be its own column
and each instance (observation) must be a row of 0s and 1s, indicating which
labels belong to the instance.</p>
</td></tr>
<tr><td><code id="ecc_+3A_m">m</code></td>
<td>
<p>Number of classifier chains (models) to train. Recommended:
<code>m = 3</code> and <code>m = 7</code> for 4-core and 8-core systems, respectively.</p>
</td></tr>
<tr><td><code id="ecc_+3A_prop_subset">prop_subset</code></td>
<td>
<p>The proportion of the training data to utilize when
<code>m</code> is greater than 1. Each set of classifier chains in the ensemble
will use a random subset (95% by default) of the supplied training data.</p>
</td></tr>
<tr><td><code id="ecc_+3A_run_parallel">run_parallel</code></td>
<td>
<p>Whether to utilize multicore capabilities of the system.</p>
</td></tr>
<tr><td><code id="ecc_+3A_silent">silent</code></td>
<td>
<p>Whether to print progress messages to console. Recommended.</p>
</td></tr>
<tr><td><code id="ecc_+3A_.f">.f</code></td>
<td>
<p>User-supplied classifier training function. If not supplied, the
trainer will use the built-in classifier. See Details for more information.</p>
</td></tr>
<tr><td><code id="ecc_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code>.f</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>ECC</code> containing: </p>

<ul>
<li> <p><code>y_labels</code> : names of the columns of <code>y</code>
</p>
</li>
<li> <p><code>fits</code> : An list of length <code>m</code>, each element being a set of
classifier chains - a list of length <code>L = ncol(y)</code> where each element
is a fitted model object trained to predict each of the <code>L</code> labels.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- movies_train[, -(1:3)]
y &lt;- movies_train[, 1:3]

fit &lt;- ecc(x, y, m = 1, .f = glm.fit, family = binomial(link = "logit"))

## Not run: 

fit &lt;- ecc(x, y, .f = randomForest::randomForest)

fit &lt;- ecc(x, y, m = 7, .f = C50::C5.0, trials = 10)

## End(Not run)
</code></pre>

<hr>
<h2 id='MLPUGS-package'>MLPUGS: Multi-Label Prediction Using Gibbs Sampling (and Classifier Chains)</h2><span id='topic+MLPUGS'></span><span id='topic+MLPUGS-package'></span>

<h3>Description</h3>

<p>An implementation of classifier chains for binary and probabilistic
multi-label prediction. The classification pipeline consists of:
</p>

<ol>
<li><p> Training an ensemble of classifier chains. Each chain is a binary
classifier (built-in, supplied from an external package or user-coded).
</p>
</li>
<li><p> Making predictions using a Gibbs sampler since each unobserved
label is conditioned on the others.
</p>
</li>
<li><p> (Optional) Evaluating the ECC.
</p>
</li>
<li><p> Gathering predictions (aggregating across iterations &amp; models).
</p>
</li></ol>

<p>To learn more about MLPUGS, start with the vignettes: <code>browseVignettes(package = "MLPUGS")</code>
</p>

<hr>
<h2 id='movies'>FiveThirtyEight's Movie Scores</h2><span id='topic+movies'></span><span id='topic+movies_test'></span><span id='topic+movies_train'></span>

<h3>Description</h3>

<p>This dataset contains every film that has a Rotten Tomatoes
rating, a RT User rating, a Metacritic score, a Metacritic User score,
and IMDb score, and at least 30 fan reviews on Fandango. The data from
Fandango was pulled on Aug. 24, 2015. It is licensed under CC BY 4.0
</p>


<h3>Usage</h3>

<pre><code class='language-R'>movies

movies_train

movies_test
</code></pre>


<h3>Format</h3>

<p>A <code>data.frame</code> with 146 rows and 9 columns. The training data
contains 87 movies, while the test set contains 59 movies. The first three
columns of the training and test sets indicate the multiple labels: 1 if
the movie got a rating equal to or greater than 80% on Metacritic,
Rotten Tomatoes, and Fandango; and 0 otherwise.</p>


<h3>Author(s)</h3>

<p>FiveThirtyEight
</p>


<h3>Source</h3>

<p><a href="https://github.com/fivethirtyeight/data/tree/master/fandango">https://github.com/fivethirtyeight/data/tree/master/fandango</a>
</p>

<hr>
<h2 id='predict.ECC'>Classify new samples using an Ensemble of Classifier Chains</h2><span id='topic+predict.ECC'></span>

<h3>Description</h3>

<p>Uses a trained ECC and Gibbs sampling to predict labels for new
samples. <code>.f</code> must return a matrix of probabilities, one row for each
observation in <code>newdata</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ECC'
predict(object, newdata, n.iters = 300, burn.in = 100,
  thin = 2, run_parallel = FALSE, silent = TRUE, .f = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ECC_+3A_object">object</code></td>
<td>
<p>An object of type <code>ECC</code> returned by <code><a href="#topic+ecc">ecc</a>()</code>.</p>
</td></tr>
<tr><td><code id="predict.ECC_+3A_newdata">newdata</code></td>
<td>
<p>A data frame or matrix of features. Must be the same form as
the one used with <code><a href="#topic+ecc">ecc</a>()</code>.</p>
</td></tr>
<tr><td><code id="predict.ECC_+3A_n.iters">n.iters</code></td>
<td>
<p>Number of iterations of the Gibbs sampler.</p>
</td></tr>
<tr><td><code id="predict.ECC_+3A_burn.in">burn.in</code></td>
<td>
<p>Number of iterations for adaptation (burn-in).</p>
</td></tr>
<tr><td><code id="predict.ECC_+3A_thin">thin</code></td>
<td>
<p>Thinning interval.</p>
</td></tr>
<tr><td><code id="predict.ECC_+3A_run_parallel">run_parallel</code></td>
<td>
<p>Logical flag for utilizing multicore capabilities of the
system.</p>
</td></tr>
<tr><td><code id="predict.ECC_+3A_silent">silent</code></td>
<td>
<p>Logical flag indicating whether to have a progress bar (if
the 'progress' package is installed) or print progress messages to console.</p>
</td></tr>
<tr><td><code id="predict.ECC_+3A_.f">.f</code></td>
<td>
<p>User-supplied prediction function that corresponds to the type of
classifier that was trained in the <code><a href="#topic+ecc">ecc</a>()</code> step. See Details.</p>
</td></tr>
<tr><td><code id="predict.ECC_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code>.f</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Getting the prediction function correct is very important here.
Since this package is a wrapper that can use any classification algorithm
as its base classifier, certain assumptions have been made. We assume that
the prediction function can return a data.frame or matrix of probabilities
with two columns: &quot;0&quot; and &quot;1&quot; because <code><a href="#topic+ecc">ecc</a>()</code> trains on a
factor of &quot;0&quot;s and &quot;1&quot;s for more universal consistency.
</p>


<h3>Value</h3>

<p>An object of class <code>PUGS</code> containing: </p>

<ul>
<li> <p><code>y_labels</code> : inherited from <code>object</code>
</p>
</li>
<li> <p><code>preds</code> : A burnt-in, thinned multi-dimensional array of predictions.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- movies_train[, -(1:3)]
y &lt;- movies_train[, 1:3]

model_glm &lt;- ecc(x, y, m = 1, .f = glm.fit, family = binomial(link = "logit"))

predictions_glm &lt;- predict(model_glm, movies_test[, -(1:3)],
.f = function(glm_fit, newdata) {

  # Credit for writing the prediction function that works
  # with objects created through glm.fit goes to Thomas Lumley
  
  eta &lt;- as.matrix(newdata) %*% glm_fit$coef
  output &lt;- glm_fit$family$linkinv(eta)
  colnames(output) &lt;- "1"
  return(output)
  
}, n.iters = 10, burn.in = 0, thin = 1)

## Not run: 

model_c50 &lt;- ecc(x, y, .f = C50::C5.0)
predictions_c50 &lt;- predict(model_c50, movies_test[, -(1:3)],
                           n.iters = 10, burn.in = 0, thin = 1,
                           .f = C50::predict.C5.0, type = "prob")
  
model_rf &lt;- ecc(x, y, .f = randomForest::randomForest)
predictions_rf &lt;- predict(model_rf, movies_test[, -(1:3)],
                          n.iters = 1000, burn.in = 100, thin = 10,
                          .f = function(rF, newdata) {
                            randomForest:::predict.randomForest(rF, newdata, type = "prob")
                          })

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.PUGS'>Gather samples of predictions</h2><span id='topic+summary.PUGS'></span>

<h3>Description</h3>

<p>Collapses the multi-label predictions across sets of classifier
chains and iterations into a single set of predictions, either binary or
probabilistic.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PUGS'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.PUGS_+3A_object">object</code></td>
<td>
<p>A <code>pugs</code> object generated by <code><a href="#topic+predict.ECC">predict.ECC</a></code>.</p>
</td></tr>
<tr><td><code id="summary.PUGS_+3A_...">...</code></td>
<td>
<p><code>type = "prob"</code> for probabilistic predictions,
<code>type = "class"</code> for binary (0/1) predictions</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of predictions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- movies_train[, -(1:3)]
y &lt;- movies_train[, 1:3]

model_glm &lt;- ecc(x, y, m = 1, .f = glm.fit, family = binomial(link = "logit"))

predictions_glm &lt;- predict(model_glm, movies_test[, -(1:3)],
.f = function(glm_fit, newdata) {

  # Credit for writing the prediction function that works
  # with objects created through glm.fit goes to Thomas Lumley
  
  eta &lt;- as.matrix(newdata) %*% glm_fit$coef
  output &lt;- glm_fit$family$linkinv(eta)
  colnames(output) &lt;- "1"
  return(output)
  
}, n.iters = 10, burn.in = 0, thin = 1)

summary(predictions_glm, movies_test[, 1:3])

## Not run: 

model_c50 &lt;- ecc(x, y, .f = C50::C5.0)
predictions_c50 &lt;- predict(model_c50, movies_test[, -(1:3)],
                           n.iters = 10, burn.in = 0, thin = 1,
                           .f = C50::predict.C5.0, type = "prob")
summary(predictions_c50, movies_test[, 1:3])
  
model_rf &lt;- ecc(x, y, .f = randomForest::randomForest)
predictions_rf &lt;- predict(model_rf, movies_test[, -(1:3)],
                          n.iters = 10, burn.in = 0, thin = 1,
                          .f = function(rF, newdata){
                            randomForest:::predict.randomForest(rF, newdata, type = "prob")
                          })
summary(predictions_rf, movies_test[, 1:3])

## End(Not run)
</code></pre>

<hr>
<h2 id='validate_pugs'>Assess multi-label prediction accuracy</h2><span id='topic+validate_pugs'></span>

<h3>Description</h3>

<p>Computes a variety of accuracy metrics for multi-label
predictions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_pugs(object, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validate_pugs_+3A_object">object</code></td>
<td>
<p>A <code>PUGS</code> object generated by <code><a href="#topic+predict.ECC">predict.ECC</a></code>.</p>
</td></tr>
<tr><td><code id="validate_pugs_+3A_y">y</code></td>
<td>
<p>A matrix of the same form as the one used with
<code><a href="#topic+ecc">ecc</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A variety of multi-label classification accuracy measurements.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- movies_train[, -(1:3)]
y &lt;- movies_train[, 1:3]

model_glm &lt;- ecc(x, y, m = 1, .f = glm.fit, family = binomial(link = "logit"))

predictions_glm &lt;- predict(model_glm, movies_test[, -(1:3)],
.f = function(glm_fit, newdata) {

  # Credit for writing the prediction function that works
  # with objects created through glm.fit goes to Thomas Lumley
  
  eta &lt;- as.matrix(newdata) %*% glm_fit$coef
  output &lt;- glm_fit$family$linkinv(eta)
  colnames(output) &lt;- "1"
  return(output)
  
}, n.iters = 10, burn.in = 0, thin = 1)

validate_pugs(predictions_glm, movies_test[, 1:3])

## Not run: 

model_c50 &lt;- ecc(x, y, .f = C50::C5.0)
predictions_c50 &lt;- predict(model_c50, movies_test[, -(1:3)],
                           n.iters = 10, burn.in = 0, thin = 1,
                           .f = C50::predict.C5.0, type = "prob")
validate_pugs(predictions_c50, movies_test[, 1:3])
  
model_rf &lt;- ecc(x, y, .f = randomForest::randomForest)
predictions_rf &lt;- predict(model_rf, movies_test[, -(1:3)],
                          n.iters = 10, burn.in = 0, thin = 1,
                          .f = function(rF, newdata){
                            randomForest:::predict.randomForest(rF, newdata, type = "prob")
                          })
validate_pugs(predictions_rf, movies_test[, 1:3])

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
