<!DOCTYPE html><html><head><title>Help for package HTRX</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {HTRX}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#HTRX-package'><p>HTRX: Haplotype Trend Regression with eXtra flexibility</p></a></li>
<li><a href='#computeR2'><p>Compute variance explained by models</p></a></li>
<li><a href='#data_split'><p>Data split</p></a></li>
<li><a href='#do_cumulative_htrx'><p>Cumulative HTRX on long haplotypes</p></a></li>
<li><a href='#do_cv'><p>Two-stage HTRX: Model selection on short haplotypes</p></a></li>
<li><a href='#do_cv_direct'><p>Direct HTRX: k-fold cross-validation on short haplotypes</p></a></li>
<li><a href='#example_data_nosnp'>
<p>Example covariate data</p></a></li>
<li><a href='#example_hap1'><p>Example genotype data for the first genome</p></a></li>
<li><a href='#example_hap2'><p>Example genotype data for the second genome</p></a></li>
<li><a href='#htrx_max'><p>Maximum independent features for HTRX</p></a></li>
<li><a href='#htrx_nfeatures'><p>Total number of features for HTRX</p></a></li>
<li><a href='#make_htrx'><p>Generate haplotype data</p></a></li>
<li><a href='#themodel'><p>Model fitting</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Haplotype Trend Regression with eXtra Flexibility (HTRX)</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yaoling Yang &lt;yaoling.yang@bristol.ac.uk&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Detection of haplotype patterns that include single nucleotide polymorphisms (SNPs) and non-contiguous haplotypes that are associated with a phenotype. Methods for implementing HTRX are described in Yang Y, Lawson DJ (2023) &lt;<a href="https://doi.org/10.1093%2Fbioadv%2Fvbad038">doi:10.1093/bioadv/vbad038</a>&gt; and Barrie W, Yang Y, Irving-Pease E.K, et al (2024) &lt;<a href="https://doi.org/10.1038%2Fs41586-023-06618-z">doi:10.1038/s41586-023-06618-z</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>fastglm, caret, parallel, methods, stats, glmnet, tune,
recipes</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-09 00:48:07 UTC; yyl19</td>
</tr>
<tr>
<td>Author:</td>
<td>Yaoling Yang <a href="https://orcid.org/0000-0003-4905-8097"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Daniel Lawson <a href="https://orcid.org/0000-0002-5311-6213"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-09 08:00:14 UTC</td>
</tr>
</table>
<hr>
<h2 id='HTRX-package'>HTRX: Haplotype Trend Regression with eXtra flexibility</h2><span id='topic+HTRX'></span><span id='topic+HTRX-package'></span>

<h3>Description</h3>

<p>This is the software for &quot;HTRX - Haplotype Trend Regression with eXtra flexibility (HTRX)&quot;
based on the papar Genetic risk for Multiple Sclerosis originated in Pastoralist Steppe populations, Barrie W, Yang Y, Attfield K E, et al (2022).
</p>
<p>HTRX searches for haplotype patterns that include single nucleotide polymorphisms (SNPs) and non-contiguous haplotypes.
</p>
<p>HTRX is a template gives a value for each SNP taking values of ‘0’ or ‘1’, reflecting
whether the reference allele of each SNP is present or absent, or an ‘X’ meaning either value is allowed.
</p>
<p>We used a two-step procedure to select the best HTRX model: <code><a href="#topic+do_cv">do_cv</a></code>.
</p>
<p>Step 1: select candidate models using AIC, BIC or lasso;
</p>
<p>Step 2: select the best model using 10-fold cross-validation.
</p>
<p>There is also an option to directly perform 10-fold cross-validation: <code><a href="#topic+do_cv_direct">do_cv_direct</a></code>.
This method loses some accuracy and doesn't return the fixed features selected, but saves computational time.
</p>
<p>Longer haplotypes are important for discovering interactions.
However, too many haplotypes make original HTRX unrealistic for regions with large numbers of SNPs.
We proposed &quot;cumulative HTRX&quot; that enables HTRX to run on longer haplotypes: <code><a href="#topic+do_cumulative_htrx">do_cumulative_htrx</a></code>.
</p>
<p>The code for HTRX is hosted at <a href="https://github.com/YaolingYang/HTRX">https://github.com/YaolingYang/HTRX</a>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Yaoling Yang <a href="mailto:yaoling.yang@bristol.ac.uk">yaoling.yang@bristol.ac.uk</a> (<a href="https://orcid.org/0000-0003-4905-8097">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Daniel Lawson <a href="mailto:Dan.Lawson@bristol.ac.uk">Dan.Lawson@bristol.ac.uk</a> (<a href="https://orcid.org/0000-0002-5311-6213">ORCID</a>)
</p>
</li></ul>



<h3>References</h3>

<p>Yang Y, Lawson DJ. HTRX: an R package for learning non-contiguous haplotypes associated with a phenotype. Bioinformatics Advances 3(1) (2023): vbad038.
</p>
<p>Barrie, W., Yang, Y., Irving-Pease, E.K. et al. Elevated genetic risk for multiple sclerosis emerged in steppe pastoralist populations. Nature 625, 321–328 (2024).
</p>
<p>Eforn, B. &quot;Bootstrap methods: another look at the jackknife.&quot; The Annals of Statistics 7 (1979): 1-26.
</p>
<p>Schwarz, Gideon. &quot;Estimating the dimension of a model.&quot; The annals of statistics (1978): 461-464.
</p>
<p>McFadden, Daniel. &quot;Conditional logit analysis of qualitative choice behavior.&quot; (1973).
</p>
<p>Akaike, Hirotugu. &quot;A new look at the statistical model identification.&quot; IEEE transactions on automatic control 19.6 (1974): 716-723.
</p>
<p>Tibshirani, Robert. &quot;Regression shrinkage and selection via the lasso.&quot; Journal of the Royal Statistical Society: Series B (Methodological) 58.1 (1996): 267-288.
</p>

<hr>
<h2 id='computeR2'>Compute variance explained by models</h2><span id='topic+computeR2'></span><span id='topic+mypredict'></span>

<h3>Description</h3>

<p>Compute the variance explained by a linear or
generalized linear model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mypredict(model, newdata)

computeR2(pred, outcome, usebinary = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="computeR2_+3A_model">model</code></td>
<td>
<p>a fitted model, which is the output of <code>themodel</code>.</p>
</td></tr>
<tr><td><code id="computeR2_+3A_newdata">newdata</code></td>
<td>
<p>a data frame which contains all the variables included in the model.
This data frame is used to make prediction on.</p>
</td></tr>
<tr><td><code id="computeR2_+3A_pred">pred</code></td>
<td>
<p>a vector of the predicted outcome.</p>
</td></tr>
<tr><td><code id="computeR2_+3A_outcome">outcome</code></td>
<td>
<p>a vector of the actual outcome.</p>
</td></tr>
<tr><td><code id="computeR2_+3A_usebinary">usebinary</code></td>
<td>
<p>a non-negative number representing different models.
Use linear model if <code>usebinary=0</code>,
use logistic regression model via <code>fastglm</code> if <code>usebinary=1</code> (by default),
and use logistic regression model via <code>glm</code> if <code>usebinary&gt;1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance explained by a linear model is based on the conventional R<sup>2</sup>.
As for logistic regression, we use McFadden's R<sup>2</sup>.
</p>


<h3>Value</h3>

<p><code>mypredict</code> returns a vector of the predicted outcome.
</p>
<p><code>computeR2</code> returns a positive number of the variance explained by the
linear model (conventional R<sup>2</sup>) or
the generalized linear model (McFadden's R<sup>2</sup>).
</p>


<h3>References</h3>

<p>McFadden, Daniel. &quot;Conditional logit analysis of qualitative choice behavior.&quot; (1973).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## create datasets
x=matrix(runif(100,-2,2),ncol=5)
outcome=(0.5*x[,2] - 0.8*x[,4] + 0.3*x[,5])&gt;runif(100,-2,2)

## create binary outcome
outcome[outcome]=1
data=data.frame(outcome,x)

## compute the variance explained by features
model=themodel(outcome~.,data[1:80,],usebinary=1)
outcome_predict=mypredict(model,data[81:100,])
computeR2(outcome_predict,data[81:100,'outcome'],usebinary=1)
</code></pre>

<hr>
<h2 id='data_split'>Data split</h2><span id='topic+data_split'></span><span id='topic+kfold_split'></span><span id='topic+twofold_split'></span>

<h3>Description</h3>

<p><code>kfold_split</code> splits data into k folds with equal sizes, which is used for cross-validation.
<code>twofold_split</code> splits data into two folds, which samples the training set.
Both stratified sampling and simple sampling are allowed.
The details can be found in function <code><a href="#topic+do_cv">do_cv</a></code> and <code><a href="#topic+do_cumulative_htrx">do_cumulative_htrx</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfold_split(outcome, fold, method = "simple")

twofold_split(outcome, train_proportion = 0.5, method = "simple")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data_split_+3A_outcome">outcome</code></td>
<td>
<p>a vector of the variable (usually the outcome)
based on which the data is going to be stratified.
This only works when <code>method="stratified"</code>.</p>
</td></tr>
<tr><td><code id="data_split_+3A_fold">fold</code></td>
<td>
<p>a positive integer specifying how many folds the data should be split into.</p>
</td></tr>
<tr><td><code id="data_split_+3A_method">method</code></td>
<td>
<p>the method to be used for data split, either <code>"simple"</code> (default) or <code>"stratified"</code>.</p>
</td></tr>
<tr><td><code id="data_split_+3A_train_proportion">train_proportion</code></td>
<td>
<p>a positive number between 0 and 1 giving
the proportion of the training dataset when splitting data into 2 folds.
By default, <code>train_proportion=0.5</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Stratified sampling works only when the <code>outcome</code> variable is binary (either 0 or 1),
and it ensures each fold has almost the same number of <code>outcome=0</code> and <code>outcome=1</code>.
</p>
<p>Simple sampling randomly splits the data into k folds.
</p>
<p>Two-fold data split is used to select candidate models in Step 1 of HTRX or cumulative HTRX,
while k-fold data split is used for 10-fold cross-validation in Step 2 which aims at selecting the best model.
</p>


<h3>Value</h3>

<p>Both functions return a list containing the indexes of different folds.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## create the binary outcome (20% prevalence)
outcome=rbinom(200,1,0.2)

## simple sampling (10 folds)
kfold_split(outcome,10)

## stratified sampling (10 folds)
kfold_split(outcome,10,"stratified")

## stratified sampling (2 folds, with 50% training data)
twofold_split(outcome,0.5,"stratified")
</code></pre>

<hr>
<h2 id='do_cumulative_htrx'>Cumulative HTRX on long haplotypes</h2><span id='topic+do_cumulative_htrx'></span><span id='topic+do_cumulative_htrx_step1'></span><span id='topic+extend_haps'></span><span id='topic+make_cumulative_htrx'></span>

<h3>Description</h3>

<p>Two-step cross-validation used to select the best HTRX model for longer haplotypes,
i.e. include at least 7 single nucleotide polymorphisms (SNPs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do_cumulative_htrx(
  data_nosnp,
  hap1,
  hap2 = hap1,
  train_proportion = 0.5,
  sim_times = 5,
  featurecap = 40,
  usebinary = 1,
  randomorder = TRUE,
  fixorder = NULL,
  method = "simple",
  criteria = "BIC",
  gain = TRUE,
  nmodel = 3,
  runparallel = FALSE,
  mc.cores = 6,
  rareremove = FALSE,
  rare_threshold = 0.001,
  L = 6,
  dataseed = 1:sim_times,
  fold = 10,
  kfoldseed = 123,
  htronly = FALSE,
  max_int = NULL,
  returnwork = FALSE,
  verbose = FALSE
)

do_cumulative_htrx_step1(
  data_nosnp,
  hap1,
  hap2 = hap1,
  train_proportion = 0.5,
  featurecap = 40,
  usebinary = 1,
  randomorder = TRUE,
  fixorder = NULL,
  method = "simple",
  criteria = "BIC",
  nmodel = 3,
  splitseed = 123,
  gain = TRUE,
  runparallel = FALSE,
  mc.cores = 6,
  rareremove = FALSE,
  rare_threshold = 0.001,
  L = 6,
  htronly = FALSE,
  max_int = NULL,
  verbose = FALSE
)

extend_haps(
  data_nosnp,
  featuredata,
  train,
  featurecap = dim(featuredata)[2],
  usebinary = 1,
  gain = TRUE,
  runparallel = FALSE,
  mc.cores = 6,
  verbose = FALSE
)

make_cumulative_htrx(
  hap1,
  hap2 = hap1,
  featurename,
  rareremove = FALSE,
  rare_threshold = 0.001,
  htronly = FALSE,
  max_int = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do_cumulative_htrx_+3A_data_nosnp">data_nosnp</code></td>
<td>
<p>a data frame with outcome (the outcome must be the first column with colnames(data_nosnp)[1]=&quot;outcome&quot;),
fixed covariates (for example, sex, age and the first 18 PCs) if there are,
and without SNPs or haplotypes.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_hap1">hap1</code></td>
<td>
<p>a data frame of the SNPs' genotype of the first genome. The genotype of a SNP for each individual is either 0 (reference allele) or 1 (alternative allele).</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_hap2">hap2</code></td>
<td>
<p>a data frame of the SNPs' genotype of the second genome.
The genotype of a SNP for each individual is either 0 (reference allele) or 1 (alternative allele).
By default, <code>hap2=hap1</code> representing haploid.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_train_proportion">train_proportion</code></td>
<td>
<p>a positive number between 0 and 1 giving
the proportion of the training dataset when splitting data into 2 folds.
By default, <code>train_proportion=0.5</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_sim_times">sim_times</code></td>
<td>
<p>an integer giving the number of simulations in Step 1 (see details).
By default, <code>sim_times=5</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_featurecap">featurecap</code></td>
<td>
<p>a positive integer which manually sets the maximum number of independent features.
By default, <code>featurecap=40</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_usebinary">usebinary</code></td>
<td>
<p>a non-negative number representing different models.
Use linear model if <code>usebinary=0</code>,
use logistic regression model via <code>fastglm</code> if <code>usebinary=1</code> (by default),
and use logistic regression model via <code>glm</code> if <code>usebinary&gt;1</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_randomorder">randomorder</code></td>
<td>
<p>logical. If <code>randomorder=TRUE</code> (default),
use random order of all the SNPs to add SNPs in cumulative HTRX.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_fixorder">fixorder</code></td>
<td>
<p>a vector of the fixed order of SNPs to be added in cumulative HTRX.
This only works by setting <code>randomorder=FALSE</code>. Otherwise, <code>fixorder=NULL</code> (default).
The length of <code>fixorder</code> can be smaller than the total number of SNPs,
i.e. users can specify the order of some instead of all of the SNPs.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_method">method</code></td>
<td>
<p>the method used for data splitting, either <code>"simple"</code> (default) or <code>"stratified"</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_criteria">criteria</code></td>
<td>
<p>the criteria for model selection, either <code>"BIC"</code> (default), <code>"AIC"</code> or <code>"lasso"</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_gain">gain</code></td>
<td>
<p>logical. If <code>gain=TRUE</code> (default), report the variance explained in addition to fixed covariates;
otherwise, report the total variance explained by all the variables.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_nmodel">nmodel</code></td>
<td>
<p>a positive integer specifying the number of candidate models
that the criterion selects. By default, <code>nmodel=3</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_runparallel">runparallel</code></td>
<td>
<p>logical. Use parallel programming based on <code>mclapply</code> function from R package <code>"parallel"</code> or not.
Note that for Windows users, <code>mclapply</code> doesn't work, so please set <code>runparallel=FALSE</code> (default).</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_mc.cores">mc.cores</code></td>
<td>
<p>an integer giving the number of cores used for parallel programming.
By default, <code>mc.cores=6</code>.
This only works when <code>runparallel=TRUE</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_rareremove">rareremove</code></td>
<td>
<p>logical. Remove rare SNPs and haplotypes or not. By default, <code>rareremove=FALSE</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_rare_threshold">rare_threshold</code></td>
<td>
<p>a numeric number below which the haplotype or SNP is removed.
This only works when <code>rareremove=TRUE</code>. By default, <code>rare_threshold=0.001</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_l">L</code></td>
<td>
<p>a positive integer. The cumulative HTRX starts with haplotypes templates comtaining L SNPs.
By default, <code>L=6</code>. Let nsnp be the number of SNPs in total, <code>L</code> must be smaller than nsnp-1.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_dataseed">dataseed</code></td>
<td>
<p>a vector of the seed that each simulation in Step 1 (see details) uses.
The length of <code>dataseed</code> must be the same as <code>sim_times</code>.
By default, <code>dataseed=1:sim_times</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_fold">fold</code></td>
<td>
<p>a positive integer specifying how many folds
the data should be split into for cross-validation.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_kfoldseed">kfoldseed</code></td>
<td>
<p>a positive integer specifying the seed used to
split data for k-fold cross validation. By default, <code>kfoldseed=123</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_htronly">htronly</code></td>
<td>
<p>logical. If <code>htronly=TRUE</code>, only haplotypes with interaction
between all the SNPs will be selected. Please set <code>max_int=NULL</code> when <code>htronly=TRUE</code>.
By default, <code>htronly=FALSE</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_max_int">max_int</code></td>
<td>
<p>a positive integer which specifies the maximum number of SNPs that can interact.
If no value is given, interactions between all the SNPs will be considered.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_returnwork">returnwork</code></td>
<td>
<p>logical. If <code>returnwork=TRUE</code>, return a vector of the maximum number
of features that are assessed in each simulation, excluding the fixed covariates.
This is used to assess how much computational 'work' is done in Step 1(2) of HTRX (see details).
By default, <code>returnwork=FALSE</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>verbose=TRUE</code>, print out the inference steps. By default, <code>verbose=FALSE</code>.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_splitseed">splitseed</code></td>
<td>
<p>a positive integer giving the seed that a single simulation in Step 1 (see details) uses.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_featuredata">featuredata</code></td>
<td>
<p>a data frame of the feature data, e.g. haplotype data created by HTRX or SNPs.
These features exclude all the data in <code>data_nosnp</code>, and will be selected using 2-step cross-validation.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_train">train</code></td>
<td>
<p>a vector of the indexes of the training data.</p>
</td></tr>
<tr><td><code id="do_cumulative_htrx_+3A_featurename">featurename</code></td>
<td>
<p>a character giving the names of features (haplotypes).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Longer haplotypes are important for discovering interactions.
However, there are 3<sup>k</sup>-1 haplotypes in HTRX
if the region contains k SNPs,
making HTRX (<code>do_cv</code>) unrealistic to apply on for regions with large numbers of SNPs.
To address this issue, we proposed &quot;cumulative HTRX&quot; (<code>do_cumulative_htrx</code>)
that enables HTRX to run on longer haplotypes,
i.e. haplotypes which include at least 7 SNPs (we recommend).
There are 2 steps to implement cumulative HTRX.
</p>
<p>Step 1: extend haplotypes and select candidate models.
</p>
<p>(1) Randomly sample a subset (50
use stratified sampling when the outcome is binary.
This subset is used for all the analysis in (2) and (3);
</p>
<p>(2) Start with L randomly chosen SNPs from the entire k SNPs,
and keep the top M haplotypes that are chosen from the forward regression.
Then add another SNP to the M  haplotypes to create 3M+2 haplotypes.
There are 3M haplotypes obtained by adding &quot;0&quot;, &quot;1&quot; or &quot;X&quot; to the previous M haplotypes,
as well as 2 bases of the added SNP, i.e. &quot;XX...X0&quot; and &quot;XX...X1&quot;
(as &quot;X&quot; was implicitly used in the previous step).
The top M haplotypes from them are then selected using forward regression.
Repeat this process until obtaining M haplotypes which include k-1 SNPs;
</p>
<p>(3) Add the last SNP to create 3M+2 haplotypes.
Afterwards, if <code>criteria="AIC"</code> or <code>criteria="BIC"</code>,
start from a model with fixed covariates (e.g. 18 PCs, sex and age),
and perform forward regression on the subset,
i.e. iteratively choose a feature (in addition to the fixed covariates)
to add whose inclusion enables the model to explain the largest variance,
and select s models with the lowest Akaike information criterion (AIC) or
Bayesian Information Criteria (BIC)
to enter the candidate model pool;
If <code>criteria="lasso"</code>, using least absolute shrinkage and selection operator (lasso)
to directly select the best s models to enter the candidate model pool;
</p>
<p>(4) repeat (1)-(3) B times, and select all the different models
in the candidate model pool as the candidate models.
</p>
<p>Step 2: select the best model using k-fold cross-validation.
</p>
<p>(1) Randomly split the whole data into k groups with approximately equal sizes,
using stratified sampling when the outcome is binary;
</p>
<p>(2) In each of the k folds, use a fold as the validation dataset, a fold as the test dataset,
and the remaining folds as the training dataset.
Then, fit all the candidate models on the training dataset,
and use these fitted models to compute the additional variance explained by features
(out-of-sample variance explained) in the validation and test dataset.
Finally, select the candidate model with the biggest
average out-of-sample variance explained in the validation set as the best model,
and report the out-of-sample variance explained in the test set.
</p>
<p>Function <code>do_cumulative_htrx_step1</code> is the Step 1 (1)-(3) described above.
Function <code>extend_haps</code> is used to select haplotypes in the Step 1 (2) described above.
Function <code>make_cumulative_htrx</code> is used to generate the haplotype data
(by adding a new SNP into the haplotypes) from M haplotypes to 3M+2 haplotypes,
which is also described in the Step 1 (2)-(3).
</p>
<p>When investigating haplotypes with interactions between at most 2 SNPs, L is suggested
to be no bigger than 10. When investigating haplotypes with interactions between at most 3 SNPs,
L should not be bigger than 9. If haplotypes with interactions between more than 4 SNPs
are investigated, L is suggested to be 6 (which is the default value).
</p>


<h3>Value</h3>

<p><code>do_cumulative_htrx</code> returns a list containing the best model selected,
and the out-of-sample variance explained in each test set.
</p>
<p><code>do_cv_step1</code> returns a list of three candidate models selected by a single simulation.
</p>
<p><code>extend_haps</code> returns a character of the names of the selected features.
</p>
<p><code>make_cumulative_htrx</code> returns a data frame of the haplotype matrix.
</p>


<h3>References</h3>

<p>Yang Y, Lawson DJ. HTRX: an R package for learning non-contiguous haplotypes associated with a phenotype. Bioinformatics Advances 3.1 (2023): vbad038.
</p>
<p>Barrie, W., Yang, Y., Irving-Pease, E.K. et al. Elevated genetic risk for multiple sclerosis emerged in steppe pastoralist populations. Nature 625, 321–328 (2024).
</p>
<p>Eforn, B. &quot;Bootstrap methods: another look at the jackknife.&quot; The Annals of Statistics 7 (1979): 1-26.
</p>
<p>Schwarz, Gideon. &quot;Estimating the dimension of a model.&quot; The annals of statistics (1978): 461-464.
</p>
<p>McFadden, Daniel. &quot;Conditional logit analysis of qualitative choice behavior.&quot; (1973).
</p>
<p>Akaike, Hirotugu. &quot;A new look at the statistical model identification.&quot; IEEE transactions on automatic control 19.6 (1974): 716-723.
</p>
<p>Tibshirani, Robert. &quot;Regression shrinkage and selection via the lasso.&quot; Journal of the Royal Statistical Society: Series B (Methodological) 58.1 (1996): 267-288.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## use dataset "example_hap1", "example_hap2" and "example_data_nosnp"
## "example_hap1" and "example_hap2" are
## both genomes of 8 SNPs for 5,000 individuals (diploid data)
## "example_data_nosnp" is a simulated dataset
## which contains the outcome (binary), sex, age and 18 PCs

## visualise the covariates data
## we will use only the first two covariates: sex and age in the example
head(HTRX::example_data_nosnp)

## visualise the genotype data for the first genome
head(HTRX::example_hap1)

## we perform cumulative HTRX on all the 8 SNPs using 2-step cross-validation
## to compute additional variance explained by haplotypes
## If the data is haploid, please set hap2=HTRX::example_hap1
## If you want to compute total variance explained, please set gain=FALSE
## For Linux/MAC users, we recommend setting runparallel=TRUE

cumu_CV_results &lt;- do_cumulative_htrx(HTRX::example_data_nosnp[1:500,1:3],
                                      HTRX::example_hap1[1:500,],
                                      HTRX::example_hap2[1:500,],
                                      train_proportion=0.5,sim_times=1,
                                      featurecap=10,usebinary=1,
                                      randomorder=TRUE,method="stratified",
                                      criteria="BIC",gain=TRUE,
                                      runparallel=FALSE,verbose=TRUE)

#This result would be more precise when setting larger sim_times and featurecap
</code></pre>

<hr>
<h2 id='do_cv'>Two-stage HTRX: Model selection on short haplotypes</h2><span id='topic+do_cv'></span><span id='topic+do_cv_step1'></span><span id='topic+infer_step1'></span><span id='topic+infer_fixedfeatures'></span>

<h3>Description</h3>

<p>Two-step cross-validation used to select the best HTRX model.
It can be applied to select haplotypes based on HTR, or select single nucleotide polymorphisms (SNPs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do_cv(
  data_nosnp,
  featuredata,
  train_proportion = 0.5,
  sim_times = 5,
  featurecap = dim(featuredata)[2],
  usebinary = 1,
  method = "simple",
  criteria = "BIC",
  gain = TRUE,
  nmodel = 3,
  dataseed = 1:sim_times,
  runparallel = FALSE,
  mc.cores = 6,
  fold = 10,
  kfoldseed = 123,
  returnwork = FALSE,
  verbose = FALSE
)

do_cv_step1(
  data_nosnp,
  featuredata,
  train_proportion = 0.5,
  featurecap = dim(featuredata)[2],
  usebinary = 1,
  method = "simple",
  criteria = "BIC",
  nmodel = 3,
  splitseed = 123,
  runparallel = FALSE,
  mc.cores = 6,
  verbose = FALSE
)

infer_step1(
  data_nosnp,
  featuredata,
  train,
  criteria = "BIC",
  featurecap = dim(featuredata)[2],
  usebinary = 1,
  nmodel = nmodel,
  runparallel = FALSE,
  mc.cores = 6,
  verbose = FALSE
)

infer_fixedfeatures(
  data_nosnp,
  featuredata,
  train = (1:nrow(data_nosnp))[-test],
  test,
  features,
  coefficients = NULL,
  gain = TRUE,
  usebinary = 1,
  R2only = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do_cv_+3A_data_nosnp">data_nosnp</code></td>
<td>
<p>a data frame with outcome (the outcome must be the first column with colnames(data_nosnp)[1]=&quot;outcome&quot;),
fixed covariates (for example, sex, age and the first 18 PCs) if there are,
and without SNPs or haplotypes.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_featuredata">featuredata</code></td>
<td>
<p>a data frame of the feature data, e.g. haplotype data created by HTRX or SNPs.
These features exclude all the data in <code>data_nosnp</code>, and will be selected using 2-step cross-validation.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_train_proportion">train_proportion</code></td>
<td>
<p>a positive number between 0 and 1 giving
the proportion of the training dataset when splitting data into 2 folds.
By default, <code>train_proportion=0.5</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_sim_times">sim_times</code></td>
<td>
<p>an integer giving the number of simulations in Step 1 (see details).
By default, <code>sim_times=5</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_featurecap">featurecap</code></td>
<td>
<p>a positive integer which manually sets the maximum number of independent features.
By default, <code>featurecap=40</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_usebinary">usebinary</code></td>
<td>
<p>a non-negative number representing different models.
Use linear model if <code>usebinary=0</code>,
use logistic regression model via <code>fastglm</code> if <code>usebinary=1</code> (by default),
and use logistic regression model via <code>glm</code> if <code>usebinary&gt;1</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_method">method</code></td>
<td>
<p>the method used for data splitting, either <code>"simple"</code> (default) or <code>"stratified"</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_criteria">criteria</code></td>
<td>
<p>the criteria for model selection, either <code>"BIC"</code> (default), <code>"AIC"</code> or <code>"lasso"</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_gain">gain</code></td>
<td>
<p>logical. If <code>gain=TRUE</code> (default), report the variance explained in addition to fixed covariates;
otherwise, report the total variance explained by all the variables.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_nmodel">nmodel</code></td>
<td>
<p>a positive integer specifying the number of candidate models
that the criterion selects. By default, <code>nmodel=3</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_dataseed">dataseed</code></td>
<td>
<p>a vector of the seed that each simulation in Step 1 (see details) uses.
The length of <code>dataseed</code> must be the same as <code>sim_times</code>.
By default, <code>dataseed=1:sim_times</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_runparallel">runparallel</code></td>
<td>
<p>logical. Use parallel programming based on <code>mclapply</code> function from R package <code>"parallel"</code> or not.
Note that for Windows users, <code>mclapply</code> doesn't work, so please set <code>runparallel=FALSE</code> (default).</p>
</td></tr>
<tr><td><code id="do_cv_+3A_mc.cores">mc.cores</code></td>
<td>
<p>an integer giving the number of cores used for parallel programming.
By default, <code>mc.cores=6</code>.
This only works when <code>runparallel=TRUE</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_fold">fold</code></td>
<td>
<p>a positive integer specifying how many folds
the data should be split into for cross-validation.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_kfoldseed">kfoldseed</code></td>
<td>
<p>a positive integer specifying the seed used to
split data for k-fold cross validation. By default, <code>kfoldseed=123</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_returnwork">returnwork</code></td>
<td>
<p>logical. If <code>returnwork=TRUE</code>, return a vector of the maximum number
of features that are assessed in each simulation, excluding the fixed covariates.
This is used to assess how much computational 'work' is done in Step 1(2) of HTRX (see details).
By default, <code>returnwork=FALSE</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>verbose=TRUE</code>, print out the inference steps. By default, <code>verbose=FALSE</code>.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_splitseed">splitseed</code></td>
<td>
<p>a positive integer giving the seed of data split.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_train">train</code></td>
<td>
<p>a vector of the indexes of the training data.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_test">test</code></td>
<td>
<p>a vector of the indexes of the test data.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_features">features</code></td>
<td>
<p>a character of the names of the fixed features, excluding the intercept.</p>
</td></tr>
<tr><td><code id="do_cv_+3A_coefficients">coefficients</code></td>
<td>
<p>a vector giving the coefficients of the fixed features, including the intercept.
If the fixed features don't have fixed coefficients, set <code>coefficients=NULL</code> (default).</p>
</td></tr>
<tr><td><code id="do_cv_+3A_r2only">R2only</code></td>
<td>
<p>logical. If <code>R2only=TRUE</code>, function <code>infer_fixedfeatures</code> only
returns the variance explained in the test data.
By default, <code>R2only=FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>do_cv</code> is the main function used for selecting haplotypes from HTRX or SNPs.
It is a two-step algorithm and is used for alleviating overfitting.
</p>
<p>Step 1: select candidate models. This is to address the model search problem,
and is chosen to obtain a set of models more diverse than
traditional bootstrap resampling.
</p>
<p>(1) Randomly sample a subset (50
Specifically, when the outcome is binary,
stratified sampling is used to ensure the subset has approximately
the same proportion of cases and controls as the whole data;
</p>
<p>(2) If <code>criteria="AIC"</code> or <code>criteria="BIC"</code>,
start from a model with fixed covariates (e.g. 18 PCs, sex and age),
and perform forward regression on the subset,
i.e. iteratively choose a feature (in addition to the fixed covariates)
to add whose inclusion enables the model to explain the largest variance,
and select s models with the lowest Akaike information criterion (AIC) or
Bayesian Information Criteria (BIC)
to enter the candidate model pool;
If <code>criteria="lasso"</code>, using least absolute shrinkage and selection operator (lasso)
to directly select the best s models to enter the candidate model pool;
</p>
<p>(3) repeat (1)-(2) B times, and select all the different models in the candidate model pool
as the candidate models.
</p>
<p>Step 2: select the best model using k-fold cross-validation.
</p>
<p>(1) Randomly split the whole data into k groups with approximately equal sizes,
using stratified sampling when the outcome is binary;
</p>
<p>(2) In each of the k folds, use a fold as the validation dataset, a fold as the test dataset,
and the remaining folds as the training dataset.
Then, fit all the candidate models on the training dataset,
and use these fitted models to compute the additional variance explained by features
(out-of-sample variance explained) in the validation and test dataset.
Finally, select the candidate model with the biggest
average out-of-sample variance explained in the validation set as the best model,
and report the out-of-sample variance explained in the test set.
</p>
<p>Function <code>do_cv_step1</code> is the Step 1 (1)-(2) described above.
Function <code>infer_step1</code> is the Step 1 (2) described above.
Function <code>infer_fixedfeatures</code> is used to fit all the candidate models on the training dataset,
and compute the additional variance explained by features (out-of-sample R2) in the test dataset,
as described in the Step 2 (2) above.
</p>


<h3>Value</h3>

<p><code>do_cv</code> returns a list containing the best model selected,
and the out-of-sample variance explained in each test set.
</p>
<p><code>do_cv_step1</code> and <code>infer_step1</code> return a list of three candidate models selected by a single simulation.
</p>
<p><code>infer_fixedfeatures</code> returns a list of the variance explained in the test set if <code>R2only=TRUE</code>,
otherwise, it returns a list of the variance explained in the test set, the model including all the variables,
and the null model, i.e. the model with outcome and fixed covariates only.
</p>


<h3>References</h3>

<p>Yang Y, Lawson DJ. HTRX: an R package for learning non-contiguous haplotypes associated with a phenotype. Bioinformatics Advances 3.1 (2023): vbad038.
</p>
<p>Barrie, W., Yang, Y., Irving-Pease, E.K. et al. Elevated genetic risk for multiple sclerosis emerged in steppe pastoralist populations. Nature 625, 321–328 (2024).
</p>
<p>Eforn, B. &quot;Bootstrap methods: another look at the jackknife.&quot; The Annals of Statistics 7 (1979): 1-26.
</p>
<p>Schwarz, Gideon. &quot;Estimating the dimension of a model.&quot; The annals of statistics (1978): 461-464.
</p>
<p>McFadden, Daniel. &quot;Conditional logit analysis of qualitative choice behavior.&quot; (1973).
</p>
<p>Akaike, Hirotugu. &quot;A new look at the statistical model identification.&quot; IEEE transactions on automatic control 19.6 (1974): 716-723.
</p>
<p>Tibshirani, Robert. &quot;Regression shrinkage and selection via the lasso.&quot; Journal of the Royal Statistical Society: Series B (Methodological) 58.1 (1996): 267-288.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## use dataset "example_hap1", "example_hap2" and "example_data_nosnp"
## "example_hap1" and "example_hap2" are
## both genomes of 8 SNPs for 5,000 individuals (diploid data)
## "example_data_nosnp" is an example dataset
## which contains the outcome (binary), sex, age and 18 PCs

## visualise the covariates data
## we will use only the first two covariates: sex and age in the example
head(HTRX::example_data_nosnp)

## visualise the genotype data for the first genome
head(HTRX::example_hap1)

## we perform HTRX on the first 4 SNPs
## we first generate all the haplotype data, as defined by HTRX
HTRX_matrix=make_htrx(HTRX::example_hap1[1:300,1:4],
                      HTRX::example_hap2[1:300,1:4])

## If the data is haploid, please set
## HTRX_matrix=make_htrx(HTRX::example_hap1[1:300,1:4],
##                       HTRX::example_hap1[1:300,1:4])

## then perform HTRX using 2-step cross-validation in a single small example
## to compute additional variance explained by haplotypes
## If you want to compute total variance explained, please set gain=FALSE
CV_results &lt;- do_cv(HTRX::example_data_nosnp[1:300,1:2],
                    HTRX_matrix,train_proportion=0.5,
                    sim_times=1,featurecap=4,usebinary=1,
                    method="simple",criteria="BIC",
                    gain=TRUE,runparallel=FALSE,verbose=TRUE)

#This result would be more precise when setting larger sim_times and featurecap
</code></pre>

<hr>
<h2 id='do_cv_direct'>Direct HTRX: k-fold cross-validation on short haplotypes</h2><span id='topic+do_cv_direct'></span>

<h3>Description</h3>

<p>Direct k-fold cross-validation used to compute the out-of-sample variance explained by selected features from HTRX.
It can be applied to select haplotypes based on HTR, or select single nucleotide polymorphisms (SNPs).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do_cv_direct(
  data_nosnp,
  featuredata,
  featurecap = dim(featuredata)[2],
  usebinary = 1,
  method = "simple",
  criteria = "BIC",
  gain = TRUE,
  runparallel = FALSE,
  mc.cores = 6,
  fold = 10,
  kfoldseed = 123,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="do_cv_direct_+3A_data_nosnp">data_nosnp</code></td>
<td>
<p>a data frame with outcome (the outcome must be the first column),
fixed covariates (for example, sex, age and the first 18 PCs) if there are,
and without SNPs or haplotypes.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_featuredata">featuredata</code></td>
<td>
<p>a data frame of the feature data, e.g. haplotype data created by HTRX or SNPs.
These features exclude all the data in <code>data_nosnp</code>, and will be selected using 2-step cross-validation.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_featurecap">featurecap</code></td>
<td>
<p>a positive integer which manually sets the maximum number of independent features.
By default, <code>featurecap=40</code>.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_usebinary">usebinary</code></td>
<td>
<p>a non-negative number representing different models.
Use linear model if <code>usebinary=0</code>,
use logistic regression model via <code>fastglm</code> if <code>usebinary=1</code> (by default),
and use logistic regression model via <code>glm</code> if <code>usebinary&gt;1</code>.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_method">method</code></td>
<td>
<p>the method used for data splitting, either <code>"simple"</code> (default) or <code>"stratified"</code>.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_criteria">criteria</code></td>
<td>
<p>the criteria for model selection, either <code>"BIC"</code> (default), <code>"AIC"</code> or <code>"lasso"</code>.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_gain">gain</code></td>
<td>
<p>logical. If <code>gain=TRUE</code> (default), report the variance explained in addition to fixed covariates;
otherwise, report the total variance explained by all the variables.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_runparallel">runparallel</code></td>
<td>
<p>logical. Use parallel programming based on <code>mclapply</code> function from R package <code>"parallel"</code> or not.
Note that for Windows users, <code>mclapply</code> doesn't work, so please set <code>runparallel=FALSE</code> (default).</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_mc.cores">mc.cores</code></td>
<td>
<p>an integer giving the number of cores used for parallel programming.
By default, <code>mc.cores=6</code>.
This only works when <code>runparallel=TRUE</code>.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_fold">fold</code></td>
<td>
<p>a positive integer specifying how many folds
the data should be split into for cross-validation.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_kfoldseed">kfoldseed</code></td>
<td>
<p>a positive integer specifying the seed used to
split data for k-fold cross validation. By default, <code>kfoldseed=123</code>.</p>
</td></tr>
<tr><td><code id="do_cv_direct_+3A_verbose">verbose</code></td>
<td>
<p>logical. If <code>verbose=TRUE</code>, print out the inference steps. By default, <code>verbose=FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>do_cv_direct</code> directly performs k-fold cross-validation: features are
selected from the training set using a specified <code>criteria</code>,
and the out-of-sample variance explained by the selected features are computed on the test set.
This function runs faster than <code><a href="#topic+do_cv">do_cv</a></code> with large <code>sim_times</code>, but may lose
some accuracy, and it doesn't return a fixed set of features.
</p>


<h3>Value</h3>

<p><code>do_cv_direct</code> returns a list of the out-of-sample variance explained in each of the test set,
and the features selected in each of the k training sets.
</p>


<h3>References</h3>

<p>Yang Y, Lawson DJ. HTRX: an R package for learning non-contiguous haplotypes associated with a phenotype. Bioinformatics Advances 3.1 (2023): vbad038.
</p>
<p>Barrie, W., Yang, Y., Irving-Pease, E.K. et al. Elevated genetic risk for multiple sclerosis emerged in steppe pastoralist populations. Nature 625, 321–328 (2024).
</p>
<p>Eforn, B. &quot;Bootstrap methods: another look at the jackknife.&quot; The Annals of Statistics 7 (1979): 1-26.
</p>
<p>Schwarz, Gideon. &quot;Estimating the dimension of a model.&quot; The annals of statistics (1978): 461-464.
</p>
<p>McFadden, Daniel. &quot;Conditional logit analysis of qualitative choice behavior.&quot; (1973).
</p>
<p>Akaike, Hirotugu. &quot;A new look at the statistical model identification.&quot; IEEE transactions on automatic control 19.6 (1974): 716-723.
</p>
<p>Tibshirani, Robert. &quot;Regression shrinkage and selection via the lasso.&quot; Journal of the Royal Statistical Society: Series B (Methodological) 58.1 (1996): 267-288.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## use dataset "example_hap1", "example_hap2" and "example_data_nosnp"
## "example_hap1" and "example_hap2" are
## both genomes of 8 SNPs for 5,000 individuals (diploid data)
## "example_data_nosnp" is an example dataset
## which contains the outcome (binary), sex, age and 18 PCs

## visualise the covariates data
## we will use only the first two covariates: sex and age in the example
head(HTRX::example_data_nosnp)

## visualise the genotype data for the first genome
head(HTRX::example_hap1)

## we perform HTRX on the first 4 SNPs
## we first generate all the haplotype data, as defined by HTRX
HTRX_matrix=make_htrx(HTRX::example_hap1[,1:4],
                      HTRX::example_hap2[,1:4])

## If the data is haploid, please set
## HTRX_matrix=make_htrx(HTRX::example_hap1[,1:4],
##                       HTRX::example_hap1[,1:4])

## next compute the maximum number of independent features
featurecap=htrx_max(nsnp=4,cap=10)
## then perform HTRX using direct cross-validation
## If we want to compute the total variance explained
## we can set gain=FALSE in the above example

htrx_results &lt;- do_cv_direct(HTRX::example_data_nosnp[,1:3],
                             HTRX_matrix,featurecap=featurecap,
                             usebinary=1,method="stratified",
                             criteria="lasso",gain=TRUE,
                             runparallel=FALSE,verbose=TRUE)

</code></pre>

<hr>
<h2 id='example_data_nosnp'>
Example covariate data
</h2><span id='topic+example_data_nosnp'></span>

<h3>Description</h3>

<p>Example covariate data including outcome (binary), sex, age and 18 PCs for 5,000 individuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("example_data_nosnp")</code></pre>


<h3>Format</h3>

<p>A data frame with 5,000 observations on a binary outcome named <code>outcome</code>
and 20 numeric covariates named <code>sex</code>, <code>age</code> and <code>PC1</code>-<code>PC18</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_data_nosnp)
</code></pre>

<hr>
<h2 id='example_hap1'>Example genotype data for the first genome</h2><span id='topic+example_hap1'></span>

<h3>Description</h3>

<p>Example genotype data for the first genome of 8 SNPs for 5,000 individuals.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("example_hap1")</code></pre>


<h3>Format</h3>

<p>A data frame with 5,000 observations on 8 binary variables named <code>SNP1</code>-<code>SNP8</code>
(&quot;0&quot; denotes the reference allele while &quot;1&quot; denotes the alternative allele).</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_hap1)
</code></pre>

<hr>
<h2 id='example_hap2'>Example genotype data for the second genome</h2><span id='topic+example_hap2'></span>

<h3>Description</h3>

<p>Example genotype data for the second genome of 8 SNPs for 5,000 individuals.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("example_hap2")</code></pre>


<h3>Format</h3>

<p>A data frame with 5,000 observations on 8 binary variables named <code>SNP1</code>-<code>SNP8</code>
(&quot;0&quot; denotes the reference allele while &quot;1&quot; denotes the alternative allele).</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(example_hap2)
</code></pre>

<hr>
<h2 id='htrx_max'>Maximum independent features for HTRX</h2><span id='topic+htrx_max'></span>

<h3>Description</h3>

<p>The maximum number of independent features in principle from
haplotypes (i.e. interactions between SNPs) generated by Haplotype Trend Regression with eXtra flexibility (HTRX).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>htrx_max(nsnp, n_haps = NULL, cap = 40, max_int = NULL, htr = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="htrx_max_+3A_nsnp">nsnp</code></td>
<td>
<p>a positive integer giving the number of single nucleotide polymorphisms (SNPs) included in the haplotypes.</p>
</td></tr>
<tr><td><code id="htrx_max_+3A_n_haps">n_haps</code></td>
<td>
<p>a positive integer giving the number of haplotypes,
which is also the number of columns of the HTRX or HTR matrix.</p>
</td></tr>
<tr><td><code id="htrx_max_+3A_cap">cap</code></td>
<td>
<p>a positive integer which manually sets the maximum number of independent features.
By default, <code>cap=40</code>.</p>
</td></tr>
<tr><td><code id="htrx_max_+3A_max_int">max_int</code></td>
<td>
<p>a positive integer which specifies the maximum number of SNPs that can interact.
If no value is given (by default), interactions between all the SNPs will be considered.</p>
</td></tr>
<tr><td><code id="htrx_max_+3A_htr">htr</code></td>
<td>
<p>logical. If <code>htr=TRUE</code>, the functions returns the maximum number of independent
features for HTR. By default, <code>htr=FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The maximum number of independent features in principle is 2<sup>nsnp</sup>-1
for haplotypes containing interactions between all different numbers of SNPs.
However, if <code>max_int &lt; nsnp</code>, i.e. only the interactions between at most <code>max_int</code> SNPs are investigated,
there will be fewer maximum number of independent features.
You can also manually set the upper limit of independent features (by setting <code>cap</code>) that can be included in the final HTRX or HTR model.
</p>


<h3>Value</h3>

<p><code>htrx_max</code> returns a positive integer giving the maximum
number of independent features to be included in the analysis.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## the maximum number of independent haplotypes consisted of 4 SNPs from HTRX
htrx_max(nsnp=4,n_haps=(3^4-1))
</code></pre>

<hr>
<h2 id='htrx_nfeatures'>Total number of features for HTRX</h2><span id='topic+htrx_nfeatures'></span>

<h3>Description</h3>

<p>The total number of features in principle from haplotypes (i.e. interactions between SNPs)
generated by Haplotype Trend Regression with eXtra flexibility (HTRX) .
</p>


<h3>Usage</h3>

<pre><code class='language-R'>htrx_nfeatures(nsnp, max_int = NULL, htr = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="htrx_nfeatures_+3A_nsnp">nsnp</code></td>
<td>
<p>a positive integer giving the number of single nucleotide polymorphisms (SNPs) included in the haplotypes.</p>
</td></tr>
<tr><td><code id="htrx_nfeatures_+3A_max_int">max_int</code></td>
<td>
<p>a positive integer which specifies the maximum number of SNPs that can interact.
If no value is given (by default), interactions between all the SNPs will be considered.</p>
</td></tr>
<tr><td><code id="htrx_nfeatures_+3A_htr">htr</code></td>
<td>
<p>logical. If <code>htr=TRUE</code>, the function returns the total number of
features for HTR. By default, <code>htr=FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The total number of features in principle is 3<sup>nsnp</sup>-1
for haplotypes containing interactions between all different numbers of SNPs.
However, if <code>max_int &lt; nsnp</code>, i.e. only the interactions between at most <code>max_int</code> SNPs are investigated,
there will be fewer total number of features.
</p>


<h3>Value</h3>

<p><code>htrx_nfeatures</code> returns a positive integer giving the total number
of features that each analysis includes.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## the total number of haplotypes consisted of 6 SNPs
## for at most 3-SNP interactions
htrx_nfeatures(nsnp=6,max_int=3)
</code></pre>

<hr>
<h2 id='make_htrx'>Generate haplotype data</h2><span id='topic+make_htrx'></span><span id='topic+make_htr'></span><span id='topic+make_snp'></span>

<h3>Description</h3>

<p>Generate the feature data, either the genotype data for single nucleotide polymorphisms (SNPs) (<code>make_snp</code>),
the feature data for Haplotype Trend Regression (HTR) (<code>make_htr</code>), or
the feature data for Haplotype Trend Regression with eXtra flexibility (HTRX) (<code>make_htrx</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_htrx(
  hap1,
  hap2 = hap1,
  rareremove = FALSE,
  rare_threshold = 0.001,
  fixedfeature = NULL,
  max_int = NULL
)

make_htr(hap1, hap2 = hap1, rareremove = FALSE, rare_threshold = 0.001)

make_snp(hap1, hap2 = hap1, rareremove = FALSE, rare_threshold = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_htrx_+3A_hap1">hap1</code></td>
<td>
<p>a data frame of the SNPs' genotype of the first genome. The genotype of a SNP for each individual is either 0 (reference allele) or 1 (alternative allele).</p>
</td></tr>
<tr><td><code id="make_htrx_+3A_hap2">hap2</code></td>
<td>
<p>a data frame of the SNPs' genotype of the second genome.
The genotype of a SNP for each individual is either 0 (reference allele) or 1 (alternative allele).
By default, <code>hap2=hap1</code> representing haploid.</p>
</td></tr>
<tr><td><code id="make_htrx_+3A_rareremove">rareremove</code></td>
<td>
<p>logical. Remove rare SNPs and haplotypes or not. By default, <code>rareremove=FALSE</code>.</p>
</td></tr>
<tr><td><code id="make_htrx_+3A_rare_threshold">rare_threshold</code></td>
<td>
<p>a numeric number below which the haplotype or SNP is removed.
This only works when <code>rareremove=TRUE</code>. By default, <code>rare_threshold=0.001</code>.</p>
</td></tr>
<tr><td><code id="make_htrx_+3A_fixedfeature">fixedfeature</code></td>
<td>
<p>a character consisted of the names of haplotypes.
This parameter can be <code>NULL</code> (by default) if all the haplotypes are used as variables.</p>
</td></tr>
<tr><td><code id="make_htrx_+3A_max_int">max_int</code></td>
<td>
<p>a positive integer which specifies the maximum number of SNPs that can interact.
If no value is given, interactions between all the SNPs will be considered.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are n SNPs, there are 2<sup>n</sup> different haplotypes created by HTR,
and 3<sup>n</sup>-1 different haplotypes created by HTRX.
</p>
<p>When the data is haploid, please use the default setting <code>hap2=hap1</code>.
</p>


<h3>Value</h3>

<p>a data frame of the feature data (either for SNPs, HTR or HTRX).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## create SNP data for both genomes (diploid data)
hap1=as.data.frame(matrix(0,nrow=100,ncol=4))
hap2=as.data.frame(matrix(0,nrow=100,ncol=4))
colnames(hap1)=colnames(hap2)=c('a','b','c','d')
p=runif(4,0.01,0.99)
for(j in 1:4){
  hap1[,j]=rbinom(100,1,p[j])
  hap2[,j]=rbinom(100,1,p[j])
}

## create the SNP data without removing rare SNPs
make_snp(hap1,hap2)

## create feature data for "HTR" removing haplotypes rarer than 0.5%
make_htr(hap1,hap2,rareremove=TRUE,0.005)

## create feature data for "HTRX"
## retaining haplotypes with interaction across at most 3 SNPs
make_htrx(hap1,hap2,max_int=3)

## create feature data for feature "01XX" and "X101"
## without removing haplotypes
make_htrx(hap1,hap2,fixedfeature=c("01XX","X101"))

## If the data is haploid instead of diploid
## create feature data for "HTRX" without removing haplotypes
make_htrx(hap1,hap1)
</code></pre>

<hr>
<h2 id='themodel'>Model fitting</h2><span id='topic+themodel'></span>

<h3>Description</h3>

<p>Model-agnostic functions for model fitting (both linear and generalized linear models).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>themodel(formula, data, usebinary = 1, clean = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="themodel_+3A_formula">formula</code></td>
<td>
<p>a formula for model-fitting, starting with outcome~.</p>
</td></tr>
<tr><td><code id="themodel_+3A_data">data</code></td>
<td>
<p>a data frame contains all the variables included in the formula.
The outcome must be the first column with colnames(data)[1]=&quot;outcome&quot;.</p>
</td></tr>
<tr><td><code id="themodel_+3A_usebinary">usebinary</code></td>
<td>
<p>a non-negative number representing different models.
Use linear model if <code>usebinary=0</code>,
use logistic regression model via <code>fastglm</code> if <code>usebinary=1</code> (by default),
and use logistic regression model via <code>glm</code> if <code>usebinary&gt;1</code>.</p>
</td></tr>
<tr><td><code id="themodel_+3A_clean">clean</code></td>
<td>
<p>logical. If <code>clean=TRUE</code> (by default), remove additional storages that
the <code>predict</code> function, <code>"AIC"</code> and <code>"BIC"</code> criteria do not need.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns a fitted model (either linear model or logistic regression model).
For logistic regression, we use function <code>fastglm</code> from <code>fastglm</code> package, which is much faster than <code>glm</code>.
</p>


<h3>Value</h3>

<p>a fitted model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## create the dataset for variables and outcome
x=matrix(runif(100,-2,2),ncol=5)
outcome=0.5*x[,2] - 0.8*x[,4] + 0.3*x[,5]
data1=data.frame(outcome,x)

## fit a linear model
themodel(outcome~.,data1,usebinary=0)

## create binary outcome
outcome=outcome&gt;runif(100,-2,2)
outcome[outcome]=1
data2=data.frame(outcome,x)

## fit a logistic regression model
themodel(outcome~.,data2,usebinary=1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
