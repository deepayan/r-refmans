<!DOCTYPE html><html><head><title>Help for package sns</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sns}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ess'><p>Effective Sample Size Calculator</p></a></li>
<li><a href='#plot.sns'>
<p>Plotting &quot;sns&quot; Objects</p></a></li>
<li><a href='#predict.sns'>
<p>Sample-based prediction using &quot;sns&quot; Objects</p></a></li>
<li><a href='#sns'><p>Stochastic Newton Sampler (SNS)</p></a></li>
<li><a href='#sns.check.logdensity'>
<p>Utility function for validating log-density</p></a></li>
<li><a href='#sns.fghEval.numaug'>
<p>Utility function for augmentation of a log-density function with numerical gradient and Hessian as needed</p></a></li>
<li><a href='#sns.make.part'>
<p>Utility Functions for Creating and Validating State Space Partitions</p></a></li>
<li><a href='#sns.run'>
<p>Drawing multiple samples using Stochastic Newton Sampler</p></a></li>
<li><a href='#summary.sns'>
<p>Summarizing &quot;sns&quot; Objects</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Stochastic Newton Sampler (SNS)</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-11-01</td>
</tr>
<tr>
<td>Author:</td>
<td>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani </td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Alireza Mahani &lt;alireza.s.mahani@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Stochastic Newton Sampler (SNS) is a Metropolis-Hastings-based, Markov Chain Monte Carlo sampler for twice differentiable, log-concave probability density functions (PDFs) where the proposal density function is a multivariate Gaussian resulting from a second-order Taylor-series expansion of log-density around the current point. The mean of the Gaussian proposal is the full Newton-Raphson step from the current point. A Boolean flag allows for switching from SNS to Newton-Raphson optimization (by choosing the mean of proposal function as next point). This can be used during burn-in to get close to the mode of the PDF (which is unique due to concavity). For high-dimensional densities, mixing can be improved via 'state space partitioning' strategy, in which SNS is applied to disjoint subsets of state space, wrapped in a Gibbs cycle. Numerical differentiation is available when analytical expressions for gradient and Hessian are not available. Facilities for validation and numerical differentiation of log-density are provided. Note: Formerly available versions of the MfUSampler can be obtained from the archive <a href="https://cran.r-project.org/src/contrib/Archive/MfUSampler/">https://cran.r-project.org/src/contrib/Archive/MfUSampler/</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>mvtnorm, coda, numDeriv</td>
</tr>
<tr>
<td>Suggests:</td>
<td>RegressionFactory, MfUSampler</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-11-01 19:30:51 UTC; ec2-user</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-11-02 11:02:22 UTC</td>
</tr>
</table>
<hr>
<h2 id='ess'>Effective Sample Size Calculator</h2><span id='topic+ess'></span>

<h3>Description</h3>

<p>Computes the effective sample size of MCMC chains, using the algorithm in Section 2.3 of the paper by Madeline Thompson. The algorithm is taken from earlier work on &lsquo;Initial Sequence Estimators&rsquo; by multiple authors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ess(x, method = c("coda", "ise"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ess_+3A_x">x</code></td>
<td>
<p>Matrix object with each sample (possibly multivariate) as a row. Effective sample size calculation is done independently for each column of <code>x</code>.</p>
</td></tr>
<tr><td><code id="ess_+3A_method">method</code></td>
<td>
<p>Method of calculating effective size. Current options are &quot;coda&quot; which calls <code>effectiveSize</code> function in <code>coda</code> package, and &quot;ise&quot; which uses the 'Initial Sequence Estimators' method described in Section 2.3 of Thompson (2010).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Vector with effective sample sizes for the time series in each column of <code>x</code>.
</p>


<h3>Author(s)</h3>

<p>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani
</p>


<h3>References</h3>

<p>Thompson, Madeleine (2010) 
<em>A Comparison of Methods for Computing Autocorrelation Time</em>
<a href="https://arxiv.org/pdf/1011.0175v1.pdf">https://arxiv.org/pdf/1011.0175v1.pdf</a>
</p>

<hr>
<h2 id='plot.sns'>
Plotting &quot;sns&quot; Objects
</h2><span id='topic+plot.sns'></span>

<h3>Description</h3>

<p>Method for visualizing the output of <code><a href="#topic+sns.run">sns.run</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sns'
plot(x, nburnin = max(nrow(x)/2, attr(x, "nnr"))
  , select = if (length(x) &lt;= 10) 1:5 else 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sns_+3A_x">x</code></td>
<td>
<p>Object of class &quot;sns&quot;, typically the output of <code><a href="#topic+sns.run">sns.run</a></code>.</p>
</td></tr>
<tr><td><code id="plot.sns_+3A_nburnin">nburnin</code></td>
<td>
<p>Number of burn-in iterations to discard before generating effective sample size, histograms, and autocorrelation plots.</p>
</td></tr>
<tr><td><code id="plot.sns_+3A_select">select</code></td>
<td>
<p>Which plot types must be generated. See below for description.</p>
</td></tr>
<tr><td><code id="plot.sns_+3A_...">...</code></td>
<td>
<p>Arguments passed to/from other functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>plot.sns</code> produces the following types of plots: 1) log-probability trace plot (vertical line, if present, indicates transition from nr to mcmc mode), 2) trace plot of state variables (one per coordinate; vertical line has same meaning as 1), 3) effective sample size by coordinate (horizontal line indicates maximum effective size possible, equal to number of samples after discarding nburnin initial iterations), 4) post-burnin state vector histograms (one per coordinate, vertical line indicates post-burnin average, 5) autocorrelation plots, one per coordinate.
</p>


<h3>Author(s)</h3>

<p>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani
</p>


<h3>References</h3>

<p>Mahani A.S., Hasan A., Jiang M. &amp;  Sharabiani M.T.A. (2016). Stochastic Newton Sampler: The R Package sns. Journal of Statistical Software, Code Snippets, 74(2), 1-33. doi:10.18637/jss.v074.c02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sns.run">sns.run</a></code>
</p>

<hr>
<h2 id='predict.sns'>
Sample-based prediction using &quot;sns&quot; Objects
</h2><span id='topic+predict.sns'></span><span id='topic+summary.predict.sns'></span><span id='topic+print.summary.predict.sns'></span>

<h3>Description</h3>

<p>Method for sample-based prediction using the output of <code><a href="#topic+sns.run">sns.run</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sns'
predict(object, fpred
  , nburnin = max(nrow(object)/2, attr(object, "nnr"))
  , end = nrow(object), thin = 1, ...)
## S3 method for class 'predict.sns'
summary(object
  , quantiles = c(0.025, 0.5, 0.975)
  , ess.method = c("coda", "ise"), ...)
## S3 method for class 'summary.predict.sns'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.sns_+3A_object">object</code></td>
<td>
<p>Object of class &quot;sns&quot; (output of <code><a href="#topic+sns.run">sns.run</a></code>) or &quot;predict.sns&quot; (output of <code>predict.sns</code>).</p>
</td></tr>
<tr><td><code id="predict.sns_+3A_fpred">fpred</code></td>
<td>
<p>Prediction function, accepting a single value for the state vector and producing a vector of outputs.</p>
</td></tr>
<tr><td><code id="predict.sns_+3A_nburnin">nburnin</code></td>
<td>
<p>Number of burn-in iterations discarded for sample-based prediction.</p>
</td></tr>
<tr><td><code id="predict.sns_+3A_end">end</code></td>
<td>
<p>Last iteration used in sample-based prediction.</p>
</td></tr>
<tr><td><code id="predict.sns_+3A_thin">thin</code></td>
<td>
<p>One out of <code>thin</code> iterations within the specified range are used for sample-based prediction.</p>
</td></tr>
<tr><td><code id="predict.sns_+3A_quantiles">quantiles</code></td>
<td>
<p>Values for which sample-based quantiles are calculated.</p>
</td></tr>
<tr><td><code id="predict.sns_+3A_ess.method">ess.method</code></td>
<td>
<p>Method used for calculating effective sample size. Default is to call <code>effectiveSize</code> from package <code>coda</code>.</p>
</td></tr>
<tr><td><code id="predict.sns_+3A_x">x</code></td>
<td>
<p>An object of class &quot;summary.predict.sns&quot;.</p>
</td></tr>
<tr><td><code id="predict.sns_+3A_...">...</code></td>
<td>
<p>Arguments passed to/from other functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>predict.sns</code> produces a matrix with number of rows equal to the length of prediction vector produces by <code>fpred</code>. Its numnber of columns is equal to the number of samples used within the user-specified range, and after thinning (if any). <code>summary.predict.sns</code> produces sample-based prediction mean, standard deviation, quantiles, and effective sample size.
</p>


<h3>Note</h3>

<p>See package vignette for more details on SNS theory, software, examples, and performance.
</p>


<h3>Author(s)</h3>

<p>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani
</p>


<h3>References</h3>

<p>Mahani A.S., Hasan A., Jiang M. &amp;  Sharabiani M.T.A. (2016). Stochastic Newton Sampler: The R Package sns. Journal of Statistical Software, Code Snippets, 74(2), 1-33. doi:10.18637/jss.v074.c02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sns.run">sns.run</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# using RegressionFactory for generating log-likelihood and derivatives
library("RegressionFactory")

loglike.poisson &lt;- function(beta, X, y) {
  regfac.expand.1par(beta, X = X, y = y,
    fbase1 = fbase1.poisson.log)
}

# simulating data
K &lt;- 5
N &lt;- 1000
X &lt;- matrix(runif(N * K, -0.5, +0.5), ncol = K)
beta &lt;- runif(K, -0.5, +0.5)
y &lt;- rpois(N, exp(X %*% beta))

beta.init &lt;- rep(0.0, K)
beta.smp &lt;- sns.run(beta.init, loglike.poisson,
  niter = 1000, nnr = 20, mh.diag = TRUE, X = X, y = y)

# prediction function for mean response
predmean.poisson &lt;- function(beta, Xnew) exp(Xnew %*% beta)
ymean.new &lt;- predict(beta.smp, predmean.poisson,
                     nburnin = 100, Xnew = X)
summary(ymean.new)

# (stochastic) prediction function for response
predsmp.poisson &lt;- function(beta, Xnew)
  rpois(nrow(Xnew), exp(Xnew %*% beta))
ysmp.new &lt;- predict(beta.smp, predsmp.poisson
                    , nburnin = 100, Xnew = X)
summary(ysmp.new)


## End(Not run)

</code></pre>

<hr>
<h2 id='sns'>Stochastic Newton Sampler (SNS)</h2><span id='topic+sns'></span>

<h3>Description</h3>

<p>SNS is a Metropolis-Hastings MCMC sampler with a multivariate Gaussian proposal function resulting from a local, second-order Taylor series expansion of log-density. The mean of the Gaussian proposal is identical to the full Newton-Raphson step from the current point. During burn-in, Newton-Raphson optimization can be performed to get close to the mode of the pdf which is unique due to convexity, resulting in faster convergence. For high dimensional densities, state space partitioning can be used to improve mixing. Support for numerical differentiation is provided using <span class="pkg">numDeriv</span> package. <code>sns</code> is the low-level function for drawing one sample from the distribution. For drawing multiple samples from a (fixed) distribution, consider using <code>sns.run</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sns(x, fghEval, rnd = TRUE, gfit = NULL, mh.diag = FALSE
  , part = NULL, numderiv = 0
  , numderiv.method = c("Richardson", "simple")
  , numderiv.args = list(), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sns_+3A_x">x</code></td>
<td>
<p>Current state vector.</p>
</td></tr>
<tr><td><code id="sns_+3A_fgheval">fghEval</code></td>
<td>
<p>Log-density to be sampled from. A valid log-density can have one of 3 forms: 1) return log-density, but no gradient or Hessian, 2) return a list of <code>f</code> and <code>g</code> for log-density and its gradient vector, respectively, 3) return a list of <code>f</code>, <code>g</code>, and <code>h</code> for log-density, gradient vector, and Hessian matrix. Missing derivatives are computed numerically.</p>
</td></tr>
<tr><td><code id="sns_+3A_rnd">rnd</code></td>
<td>
<p>Runs 1 iteration of Newton-Raphson optimization method (non-stochastic or 'nr' mode) when <code>FALSE</code>. Runs Metropolis-Hastings (stochastic or 'mcmc' mode) for drawing a sample when <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="sns_+3A_gfit">gfit</code></td>
<td>
<p>Gaussian fit at point <code>init</code>. If <code>NULL</code> then <code>sns</code> will compute a Gaussian fit at <code>x</code>.</p>
</td></tr>
<tr><td><code id="sns_+3A_mh.diag">mh.diag</code></td>
<td>
<p>Boolean flag, indicating whether detailed MH diagnostics such as components of acceptance test must be returned or not.</p>
</td></tr>
<tr><td><code id="sns_+3A_part">part</code></td>
<td>
<p>List describing partitioning of state space into subsets. Each element of the list must be an integer vector containing a set of indexes (between <code>1</code> and <code>length(x)</code> or <code>length(init)</code>) indicating which subset of all dimensions to jointly sample. These integer vectors must be mutually exclusive and collectively exhaustive, i.e. cover the entire state space and have no duplicates, in order for the partitioning to represent a valid Gibbs sampling approach. See <code>sns.make.part</code> and <code>sns.check.part</code>.</p>
</td></tr>
<tr><td><code id="sns_+3A_numderiv">numderiv</code></td>
<td>
<p>Integer with value from the set <code>0,1,2</code>. If <code>0</code>, no numerical differentiation is performed, and thus <code>fghEval</code> is expected to supply <code>f</code>, <code>g</code> and <code>h</code>. If <code>1</code>, we expect <code>fghEval</code> to provide <code>f</code> amd <code>g</code>, and Hessian will be calculated numerically. If <code>2</code>, <code>fghEval</code> only returns log-density, and numerical differentiation is needed to calculate gradient and Hessian.</p>
</td></tr>
<tr><td><code id="sns_+3A_numderiv.method">numderiv.method</code></td>
<td>
<p>Method used for numeric differentiation. This is passed to the <code>grad</code> and <code>hessian</code> functions in <span class="pkg">numDeriv</span> package. See the package documentation for details.</p>
</td></tr>
<tr><td><code id="sns_+3A_numderiv.args">numderiv.args</code></td>
<td>
<p>Arguments to the numeric differentiation method chosen in <code>numderiv.method</code>, passed to <code>grad</code> and <code>hessian</code> functions in <span class="pkg">numDeriv</span>. See package documentation for details.</p>
</td></tr>
<tr><td><code id="sns_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code>fghEval</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>sns</code> returns the sample drawn as a vector, with attributes:
</p>
<table>
<tr><td><code>accept</code></td>
<td>
<p>A boolean indicating whether the proposed point was accepted.</p>
</td></tr>
<tr><td><code>ll</code></td>
<td>
<p>Value of the log-density at the sampled point.</p>
</td></tr>
<tr><td><code>gfit</code></td>
<td>
<p>List containing Gaussian fit to pdf at the sampled point.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>1. Since SNS makes local Gaussian approximations to the density with the covariance matrix of the Gaussian proposal being the log-density Hessian, there is a strict requirement for the log-density to be concave.  
</p>
<p>2. Proving log-concavity for arbitrary probability distributions is non-trvial. However, distributions <em>generated</em> by replacing parameters of a concave distribution with linear expressions are known to be log-concave. This negative-definiteness invariance as well as expressions for full gradient and Hessian in terms of derivatives of low-dimensional base distributions are discussed in the vignette. The GLM expansion framework is available in the R package <span class="pkg">RegressionFactory</span>.
</p>
<p>3. See package vignette for more details on SNS theory, software, examples, and performance.
</p>


<h3>Author(s)</h3>

<p>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani
</p>


<h3>References</h3>

<p>Mahani A.S., Hasan A., Jiang M. &amp;  Sharabiani M.T.A. (2016). Stochastic Newton Sampler: The R Package sns. Journal of Statistical Software, Code Snippets, 74(2), 1-33. doi:10.18637/jss.v074.c02
</p>
<p>Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applications. Biometrika, 57(1), 97-109.
</p>
<p>Qi, Y., &amp; Minka, T. P. (2002). Hessian-based markov chain monte-carlo algorithms. 1st Cape Cod Workshop on Monte Carlo Methods.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sns.run">sns.run</a></code>, <code><a href="#topic+sns.fghEval.numaug">sns.fghEval.numaug</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# using RegressionFactory for generating log-likelihood and its derivatives
library(RegressionFactory)

loglike.poisson &lt;- function(beta, X, y) {
  regfac.expand.1par(beta, X = X, y = y,
                     fbase1 = fbase1.poisson.log)
}

# simulating data
K &lt;- 5
N &lt;- 1000
X &lt;- matrix(runif(N * K, -0.5, +0.5), ncol = K)
beta &lt;- runif(K, -0.5, +0.5)
y &lt;- rpois(N, exp(X %*% beta))

beta.init &lt;- rep(0.0, K)

# glm estimate, for reference
beta.glm &lt;- glm(y ~ X - 1, family = "poisson",
                start = beta.init)$coefficients

# running SNS in non-stochastic mode
# this should produce results very close to glm
beta.sns &lt;- beta.init
for (i in 1:20)
  beta.sns &lt;- sns(beta.sns, loglike.poisson, X = X, y = y, rnd = F)

# comparison
all.equal(as.numeric(beta.glm), as.numeric(beta.sns))

# trying numerical differentiation
loglike.poisson.fonly &lt;- function(beta, X, y) {
  regfac.expand.1par(beta, X = X, y = y, fgh = 0,
                     fbase1 = fbase1.poisson.log)
}

beta.sns.numderiv &lt;- beta.init
for (i in 1:20)
  beta.sns.numderiv &lt;- sns(beta.sns.numderiv, loglike.poisson.fonly
                  , X = X, y = y, rnd = F, numderiv = 2)
all.equal(as.numeric(beta.glm), as.numeric(beta.sns.numderiv))

# add numerical derivatives to fghEval outside sns
loglike.poisson.numaug &lt;- sns.fghEval.numaug(loglike.poisson.fonly
  , numderiv = 2)

beta.sns.numaug &lt;- beta.init
for (i in 1:20)
  # set numderiv to 0 to avoid repeating 
  # numerical augmentation inside sns
  beta.sns.numaug &lt;- sns(beta.sns.numaug, loglike.poisson.numaug
                           , X = X, y = y, rnd = F, numderiv = 0)
all.equal(as.numeric(beta.glm), as.numeric(beta.sns.numaug))


## End(Not run)
</code></pre>

<hr>
<h2 id='sns.check.logdensity'>
Utility function for validating log-density
</h2><span id='topic+sns.check.logdensity'></span><span id='topic+print.sns.check.logdensity'></span>

<h3>Description</h3>

<p>Utility function for validating log-density: 1) dimensional consistency of function argument, gradient and Hessian, 2) finiteness of function, gradient and Hessian, 3) closeness of analytical and numerical derivatives, and 4) negative definiteness of Hessian.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sns.check.logdensity(x, fghEval
  , numderiv.method = c("Richardson", "complex")
  , numderiv.args = list()
  , blocks = append(list(1:length(x)), as.list(1:length(x)))
  , dx = rep(1, length(x)), nevals = 100, negdef.tol = 1e-08, ...)
## S3 method for class 'sns.check.logdensity'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sns.check.logdensity_+3A_x">x</code></td>
<td>
<p>For <code>sns.check.logdensity</code>, initial point, around which a random collection of points are generated to perform validation tests. For <code>print.sns.check.logdensity</code>, an object of class <code>sns.check.logdensity</code>, typically the output of <code>sns.check.logdensity</code> function.</p>
</td></tr>
<tr><td><code id="sns.check.logdensity_+3A_fgheval">fghEval</code></td>
<td>
<p>Log-density to be validated. A valid log-density can have one of 3 forms: 1) return log-density, but no gradient or Hessian, 2) return a list of <code>f</code> and <code>g</code> for log-density and its gradient vector, respectively, 3) return a list of <code>f</code>, <code>g</code>, and <code>h</code> for log-density, gradient vector, and Hessian matrix.</p>
</td></tr>
<tr><td><code id="sns.check.logdensity_+3A_numderiv.method">numderiv.method</code></td>
<td>
<p>Method used for numeric differentiation. This is passed to the <code>grad</code> and <code>hessian</code> functions in <span class="pkg">numDeriv</span> package. See the package documentation for details.</p>
</td></tr>
<tr><td><code id="sns.check.logdensity_+3A_numderiv.args">numderiv.args</code></td>
<td>
<p>Arguments to the numeric differentiation method chosen in <code>numderiv.method</code>, passed to <code>grad</code> and <code>hessian</code> functions in <span class="pkg">numDeriv</span>. See package documentation for details.</p>
</td></tr>
<tr><td><code id="sns.check.logdensity_+3A_blocks">blocks</code></td>
<td>
<p>A list of state space subsets (identified by their positional indexes), for which negative-definiteness of Hessian blocks are to be tested. The default is to test for 1) entire state space, and 2) each dimension individually.</p>
</td></tr>
<tr><td><code id="sns.check.logdensity_+3A_dx">dx</code></td>
<td>
<p>A vector of same length as <code>x</code>. For <code>i</code>'th dimension, <code>nevals</code> values are sampled from a uniform distribution with min/max values equal to <code>x[i]-0.5*dx[i]</code> and <code>x[i]+0.5*dx[i]</code>, respectively. Vectors smaller than <code>length(x)</code> are extended as needed by recycling the provided values for <code>dx</code>.</p>
</td></tr>
<tr><td><code id="sns.check.logdensity_+3A_nevals">nevals</code></td>
<td>
<p>Number of points in state space, for which validation tests will be performed.</p>
</td></tr>
<tr><td><code id="sns.check.logdensity_+3A_negdef.tol">negdef.tol</code></td>
<td>
<p>Lower bound for absolute value of (negative) eigenvalues of Hessian, evaluated at each of the <code>nevals</code> points in the state space. If one or more eigenvalues have absolute values smaller than <code>ngdef.tol</code>, log-density is declared non-log-concave at that point.</p>
</td></tr>
<tr><td><code id="sns.check.logdensity_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to <code>fghEval</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>sns.check.logdensity</code> returns a list of class <code>sns.check.logdensity</code>, with the following elements:
</p>
<table>
<tr><td><code>check.ld.struct</code></td>
<td>
<p>Boolean flag, indicating whether log-density <code>fghEval</code> has one of the 3 forms of output, described above.</p>
</td></tr>
<tr><td><code>numderiv</code></td>
<td>
<p>Integer with values of <code>0,1,2</code>. A value of <code>0</code> means analytical gradient and Hessian have been provided, and thus there is no need for numerical differentiation. <code>1</code> means analytical gradient is provided, but Hessian must be calculated numerically. <code>2</code> means both gradient and Hessian must be numerically calculated. Users can pass this value to subsequent <code>sns</code> or <code>sns.run</code> calls.</p>
</td></tr>
<tr><td><code>check.length.g</code></td>
<td>
<p>Boolean flag, indicating whether length of gradient vector (element <code>g</code>) returned by <code>fghEval</code> equals <code>length(x)</code>.</p>
</td></tr>
<tr><td><code>check.dim.h</code></td>
<td>
<p>Boolean flag, indicating whether number of rows and columns of the Hessian matrix (element <code>h</code>) returned by <code>fghEval</code> equal <code>length(x)</code>.</p>
</td></tr>
<tr><td><code>x.mat</code></td>
<td>
<p>Collection of state space vectors (one per row), for which validation tests are performed. It has <code>nevals</code> rows and <code>length(x)</code> columns.</p>
</td></tr>
<tr><td><code>t.evals</code></td>
<td>
<p>Time spent on evaluating <code>fghEval</code> on <code>nevals</code> points chosen randomly in the neighborhood of <code>x</code>, as specified by <code>dx</code>. This includes log-density and, if provided, analytical evaluations of gradient and Hessian.</p>
</td></tr>
<tr><td><code>t.num.evals</code></td>
<td>
<p>Time spent on evaluating the numeric version of <code>fghEval</code>, in which gradient and Hessian are computed numerically, using <code>grad</code> and <code>hessian</code> functions in the <span class="pkg">numDeriv</span> package. Comparison of this number with <code>t.evals</code> provides the user with insight into the relative speed of numerical differentiation compared to analytical versions.</p>
</td></tr>
<tr><td><code>f.vec</code></td>
<td>
<p>Vector of log-density values for state space vectors listed in <code>x.mat</code>.</p>
</td></tr>
<tr><td><code>g.mat.num</code></td>
<td>
<p>Collection of numerically-computed gradient vectors for state space values listed in <code>x.mat</code>, with the same dimension conventions.</p>
</td></tr>
<tr><td><code>is.g.num.finite</code></td>
<td>
<p>Boolean flag, indicating whether all numerically-computed gradient vectors have finite values.</p>
</td></tr>
<tr><td><code>h.array.num</code></td>
<td>
<p>Collection of numerically-computed Hessian matrices at points listed in <code>x.mat</code>. First dimension is of length <code>nevals</code>, and the remaining two dimensions equal <code>length(x)</code>.</p>
</td></tr>
<tr><td><code>is.h.num.finite</code></td>
<td>
<p>Boolean flag, indicating whether all numerically-computed Hessian matrices have finite values.</p>
</td></tr>
<tr><td><code>g.mat</code></td>
<td>
<p>Collection of analytically-computed gradient vectors for state space values listed in <code>x.mat</code>, with the same dimension conventions. This is only available if <code>fghEval</code> has a <code>g</code> field; otherwise <code>NA</code>.</p>
</td></tr>
<tr><td><code>is.g.finite</code></td>
<td>
<p>Boolean flag (if available), indicating whether all analytically-computed gradient vectors have finite values (if available).</p>
</td></tr>
<tr><td><code>g.diff.max</code></td>
<td>
<p>If available, maximum relative difference between analytical and numerical gradient vectors, over all <code>nevals</code> points in <code>x.mat</code>. Relative diference is defined as L2 norm of difference between the two gradient vectors, divided by the L2 norm of the analytical gradient vector.</p>
</td></tr>
<tr><td><code>h.array</code></td>
<td>
<p>If available, collection of analytically-computed Hessian matrices at points listed in <code>x.mat</code>. Dimensional conventions are the same as <code>h.array.num</code>.</p>
</td></tr>
<tr><td><code>is.h.finite</code></td>
<td>
<p>Boolean flag (if available), indicating whether all analytically-computed Hessian matrices have finite values.</p>
</td></tr>
<tr><td><code>h.diff.max</code></td>
<td>
<p>If available, maximum relative difference between analytical and numerical Hessian matrices, over all <code>nevals</code> points in <code>x.mat</code>. Relative difference is defined as the Frobenius norm of difference of analytical and numerical Hessian matrices, divided by the Frobenius norm of analytical Hessian.</p>
</td></tr>
<tr><td><code>is.negdef.num</code></td>
<td>
<p>Boolean flag, indicating whether numerical Hessian is negative-definite at all state space points indicated in <code>x.mat</code>.</p>
</td></tr>
<tr><td><code>is.negdef</code></td>
<td>
<p>Boolean flag, indicating whether analytical Hessian is negative-definite at all state space points indicated in <code>x.mat</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>1. Validation tests performed in <code>sns.check.logdensity</code> cannot prove that a log-density is twice-differentiable, or globally concave. However, when e.g. log-density Hessian is seen to be non-negative-definite at one of the points tested, we can definitively say that the Hessian is not globally negative-definite, and therefore <code>sns</code> should not be used for sampling from this distribution. Users must generally consider this function as a supplement to analytical work.
</p>
<p>2. See package vignette for more details on SNS theory, software, examples, and performance.
</p>


<h3>Author(s)</h3>

<p>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani
</p>


<h3>References</h3>

<p>Mahani A.S., Hasan A., Jiang M. &amp;  Sharabiani M.T.A. (2016). Stochastic Newton Sampler: The R Package sns. Journal of Statistical Software, Code Snippets, 74(2), 1-33. doi:10.18637/jss.v074.c02
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# using RegressionFactory for generating log-likelihood and its derivatives
library(RegressionFactory)

loglike.poisson &lt;- function(beta, X, y) {
  regfac.expand.1par(beta, X = X, y = y,
                     fbase1 = fbase1.poisson.log)
}

# simulating data
K &lt;- 5
N &lt;- 1000
X &lt;- matrix(runif(N * K, -0.5, +0.5), ncol = K)
beta &lt;- runif(K, -0.5, +0.5)
y &lt;- rpois(N, exp(X %*% beta))

beta.init &lt;- rep(0.0, K)

my.check &lt;- sns.check.logdensity(beta.init, loglike.poisson
  , X = X, y = y, blocks = list(1:K))
my.check

# mistake in log-likelihood gradient
loglike.poisson.wrong &lt;- function(beta, X, y) {
  ret &lt;- regfac.expand.1par(beta, X = X, y = y,
                            fbase1 = fbase1.poisson.log)
  ret$g &lt;- 1.2 * ret$g
  return (ret)
}
# maximum relative diff in gradient is now much larger
my.check.wrong &lt;- sns.check.logdensity(beta.init
  , loglike.poisson.wrong, X = X, y = y, blocks = list(1:K))
my.check.wrong

# mistake in log-likelihood Hessian
loglike.poisson.wrong.2 &lt;- function(beta, X, y) {
  ret &lt;- regfac.expand.1par(beta, X = X, y = y,
                            fbase1 = fbase1.poisson.log)
  ret$h &lt;- 1.2 * ret$h
  return (ret)
}
# maximum relative diff in Hessian is now much larger
my.check.wrong.2 &lt;- sns.check.logdensity(beta.init
  , loglike.poisson.wrong.2, X = X, y = y, blocks = list(1:K))
my.check.wrong.2


## End(Not run)
</code></pre>

<hr>
<h2 id='sns.fghEval.numaug'>
Utility function for augmentation of a log-density function with numerical gradient and Hessian as needed
</h2><span id='topic+sns.fghEval.numaug'></span>

<h3>Description</h3>

<p>Augmenting a log-density with numerical gradient and Hessian, so it can be used by <code>sns</code> or <code>sns.run</code>. This augmentation will also be done inside the function, if the value of <code>numderiv</code> parameter passed to <code>sns</code> and <code>sns.run</code> is <code>1</code> or <code>2</code>. The advantage of using <code>sns.fghEval.numaug</code> outside these functions is efficiency, since the agumentation code will not have to be executed in every function call. Users must set <code>numderiv</code> to <code>0</code> when calling <code>sns</code> or <code>sns.run</code> if calling <code>sns.fghEval.numaug</code> first. See example.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sns.fghEval.numaug(fghEval, numderiv = 0
  , numderiv.method = c("Richardson", "simple")
  , numderiv.args = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sns.fghEval.numaug_+3A_fgheval">fghEval</code></td>
<td>
<p>Log-density to be sampled from. A valid log-density can have one of 3 forms: 1) return log-density, but no gradient or Hessian, 2) return a list of <code>f</code> and <code>g</code> for log-density and its gradient vector, respectively, 3) return a list of <code>f</code>, <code>g</code>, and <code>h</code> for log-density, gradient vector, and Hessian matrix. Missing derivatives are computed numerically.</p>
</td></tr>
<tr><td><code id="sns.fghEval.numaug_+3A_numderiv">numderiv</code></td>
<td>
<p>This must be matched with <code>fghEval</code>: Integer with value from the set <code>0,1,2</code>. If <code>0</code>, no numerical differentiation is performed, and thus <code>fghEval</code> is expected to supply <code>f</code>, <code>g</code> and <code>h</code>. If <code>1</code>, we expect <code>fghEval</code> to provide <code>f</code> amd <code>g</code>, and Hessian will be calculated numerically. If <code>2</code>, <code>fghEval</code> only returns log-density, and numerical differentiation is needed to calculate gradient and Hessian.</p>
</td></tr>
<tr><td><code id="sns.fghEval.numaug_+3A_numderiv.method">numderiv.method</code></td>
<td>
<p>Method used for numeric differentiation. This is passed to the <code>grad</code> and <code>hessian</code> functions in <span class="pkg">numDeriv</span> package. See the package documentation for details.</p>
</td></tr>
<tr><td><code id="sns.fghEval.numaug_+3A_numderiv.args">numderiv.args</code></td>
<td>
<p>Arguments to the numeric differentiation method chosen in <code>numderiv.method</code>, passed to <code>grad</code> and <code>hessian</code> functions in <span class="pkg">numDeriv</span>. See package documentation for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A function, accepting same arguments as <code>fghEval</code>, but guaranteed to return the original log-density, plus gradient and Hessian (both of which could possibly by numerically calculated). If <code>numderiv=0</code>, <code>fghEval</code> is returned without change. The function will return log-density, gradient and Hessian as elements <code>f</code>, <code>g</code> and <code>h</code> of a list.
</p>


<h3>Note</h3>

<p>See package vignette for more details on SNS theory, software, examples, and performance.
</p>


<h3>Author(s)</h3>

<p>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani
</p>


<h3>References</h3>

<p>Mahani A.S., Hasan A., Jiang M. &amp;  Sharabiani M.T.A. (2016). Stochastic Newton Sampler: The R Package sns. Journal of Statistical Software, Code Snippets, 74(2), 1-33. doi:10.18637/jss.v074.c02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sns">sns</a></code>, <code><a href="#topic+sns.run">sns.run</a></code>
</p>

<hr>
<h2 id='sns.make.part'>
Utility Functions for Creating and Validating State Space Partitions
</h2><span id='topic+sns.make.part'></span><span id='topic+sns.check.part'></span>

<h3>Description</h3>

<p>Utility functions for creating and validating state space partitions, to be used in SNS for improving the mixing of sampled chains for high-dimensional posteriors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sns.make.part(K, nsubset, method = "naive")
sns.check.part(part, K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sns.make.part_+3A_k">K</code></td>
<td>
<p>Dimensionality of state space.</p>
</td></tr>
<tr><td><code id="sns.make.part_+3A_nsubset">nsubset</code></td>
<td>
<p>Number of subsets to partition the state space dimensions into.</p>
</td></tr>
<tr><td><code id="sns.make.part_+3A_method">method</code></td>
<td>
<p>Method used for state space partitioning. Currently, only <code>naive</code> method is implemented, where coordinates are distributed evenly (or as evenly as possible) across subsets.</p>
</td></tr>
<tr><td><code id="sns.make.part_+3A_part">part</code></td>
<td>
<p>A list of length <code>nsubset</code>, with each element a vector of integer values, representing the coordinates belonging to a subset. This list is the output of <code>sns.make.part</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>sns.make.part</code> produces a list of integer vectors, each containing coordinates belonging to the same subset. <code>sns.check.part</code> produces a boolean flag, indicating whether or not the partition list is valid or not. The subset members must constitute a mutually-exclusive, collectively-exhaustive set relative to <code>1:K</code>.
</p>


<h3>Author(s)</h3>

<p>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani
</p>


<h3>References</h3>

<p>Mahani A.S., Hasan A., Jiang M. &amp;  Sharabiani M.T.A. (2016). Stochastic Newton Sampler: The R Package sns. Journal of Statistical Software, Code Snippets, 74(2), 1-33. doi:10.18637/jss.v074.c02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sns">sns</a></code>, <code><a href="#topic+sns.run">sns.run</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># creating a valid partition of a 6-dimensional state space
my.part.valid &lt;- list(c(1,2,3), c(4,5,6))
is.valid.1 &lt;- sns.check.part(my.part.valid, 6)
cat("is partition valid: ", is.valid.1, "\n")

# creating an invalid partition of a 6-dimensional state space
# (coordinate 4 is missing)
my.part.invalid &lt;- list(c(1,2,3), c(5,6))
is.valid.2 &lt;- sns.check.part(my.part.invalid, 6)
cat("is partition valid: ", is.valid.2, "\n")

</code></pre>

<hr>
<h2 id='sns.run'>
Drawing multiple samples using Stochastic Newton Sampler
</h2><span id='topic+sns.run'></span>

<h3>Description</h3>

<p>This is a wrapper around <code>sns</code>, allowing one to draw multiple samples from a distribution while collecting diagnostic information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sns.run(init, fghEval, niter = 100, nnr = min(10, round(niter/4))
  , mh.diag = FALSE, part = NULL, print.level = 0
  , report.progress = ceiling(niter/10)
  , numderiv = 0, numderiv.method = c("Richardson", "simple")
  , numderiv.args = list()
  , ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sns.run_+3A_init">init</code></td>
<td>
<p>Initial value for the MCMC chain.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_fgheval">fghEval</code></td>
<td>
<p>Log-density to be sampled from. A valid log-density can have one of 3 forms: 1) return log-density, but no gradient or Hessian, 2) return a list of <code>f</code> and <code>g</code> for log-density and its gradient vector, respectively, 3) return a list of <code>f</code>, <code>g</code>, and <code>h</code> for log-density, gradient vector, and Hessian matrix. Missing derivatives are computed numerically.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_niter">niter</code></td>
<td>
<p>Number of iterations to perform (in &lsquo;nr&rsquo; and &lsquo;mcmc&rsquo; mode combined).</p>
</td></tr>
<tr><td><code id="sns.run_+3A_nnr">nnr</code></td>
<td>
<p>Number of initial iterations to spend in &lsquo;nr&rsquo; mode.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_mh.diag">mh.diag</code></td>
<td>
<p>Boolean flag, indicating whether detailed MH diagnostics such as components of acceptance test must be returned or not.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_part">part</code></td>
<td>
<p>List describing partitioning of state space into subsets. Each element of the list must be an integer vector containing a set of indexes (between <code>1</code> and <code>length(x)</code> or <code>length(init)</code>) indicating which subset of all dimensions to jointly sample. These integer vectors must be mutually exclusive and collectively exhaustive, i.e. cover the entire state space and have no duplicates, in order for the partitioning to represent a valid Gibbs sampling approach. See <code>sns.make.part</code> and <code>sns.check.part</code>.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_print.level">print.level</code></td>
<td>
<p>If greater than 0, print sampling progress report.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_report.progress">report.progress</code></td>
<td>
<p>Number of sampling iterations to wait before printing progress reports.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_numderiv">numderiv</code></td>
<td>
<p>Integer with value from the set <code>0,1,2</code>. If <code>0</code>, no numerical differentiation is performed, and thus <code>fghEval</code> is expected to supply <code>f</code>, <code>g</code> and <code>h</code>. If <code>1</code>, we expect <code>fghEval</code> to provide <code>f</code> amd <code>g</code>, and Hessian will be calculated numerically. If <code>2</code>, <code>fghEval</code> only returns log-density, and numerical differentiation is needed to calculate gradient and Hessian.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_numderiv.method">numderiv.method</code></td>
<td>
<p>Method used for numeric differentiation. This is passed to the <code>grad</code> and <code>hessian</code> functions in <span class="pkg">numDeriv</span> package. See the package documentation for details.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_numderiv.args">numderiv.args</code></td>
<td>
<p>Arguments to the numeric differentiation method chosen in <code>numderiv.method</code>, passed to <code>grad</code> and <code>hessian</code> functions in <span class="pkg">numDeriv</span>. See package documentation for details.</p>
</td></tr>
<tr><td><code id="sns.run_+3A_...">...</code></td>
<td>
<p>Other parameters to be passed to <code>fghEval</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>sns.run</code> returns an object of class <code>sns</code> with elements:
</p>
<table>
<tr><td><code>samplesMat</code></td>
<td>
<p>A matrix object with <code>nsample</code> rows and <code>K</code> cols.</p>
</td></tr>
<tr><td><code>acceptance</code></td>
<td>
<p>Metropolis proposal percentage acceptance.</p>
</td></tr>
<tr><td><code>burn.iters</code></td>
<td>
<p>Number of burn-in ierations.</p>
</td></tr>
<tr><td><code>sample.time</code></td>
<td>
<p>Time in seconds spent in sampling.</p>
</td></tr>
<tr><td><code>burnin.time</code></td>
<td>
<p>Time in seconds spent in burn-in.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>1. <code>sns.run</code> cannot be used if SNS is being run as part of a Gibbs cycle, such that the conditional distribution being sampled by SNS changes from one iteration to next. In such cases, <code>sns</code> must be used instead, inside an explicit Gibbs-cycle <code>for</code> loop.
</p>
<p>2. See package vignette for more details on SNS theory, software, examples, and performance.
</p>


<h3>Author(s)</h3>

<p>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani
</p>


<h3>References</h3>

<p>Mahani A.S., Hasan A., Jiang M. &amp;  Sharabiani M.T.A. (2016). Stochastic Newton Sampler: The R Package sns. Journal of Statistical Software, Code Snippets, 74(2), 1-33. doi:10.18637/jss.v074.c02
</p>


<h3>See Also</h3>

<p><code>sns</code>, <code><a href="#topic+summary.sns">summary.sns</a></code>, <code><a href="#topic+plot.sns">plot.sns</a></code>, <code><a href="#topic+predict.sns">predict.sns</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# using RegressionFactory for generating log-likelihood and its derivatives
library(RegressionFactory)

loglike.poisson &lt;- function(beta, X, y) {
  regfac.expand.1par(beta, X = X, y = y,
    fbase1 = fbase1.poisson.log)
}

# simulating data
K &lt;- 5
N &lt;- 1000
X &lt;- matrix(runif(N * K, -0.5, +0.5), ncol = K)
beta &lt;- runif(K, -0.5, +0.5)
y &lt;- rpois(N, exp(X 

beta.init &lt;- rep(0.0, K)

# glm estimate (ML), for reference
beta.glm &lt;- glm(y ~ X - 1, family = "poisson",
                start = beta.init)$coefficients

# sampling of likelihood
beta.smp &lt;- sns.run(init = beta.init
  , fghEval = loglike.poisson, niter = 1000
  , nnr = 20, X = X, y = y)
smp.summ &lt;- summary(beta.smp)

# compare mean of samples against ML estimate (from glm)
cbind(beta.glm, smp.summ$smp$mean)

# trying numerical differentiation
loglike.poisson.fonly &lt;- function(beta, X, y) {
  regfac.expand.1par(beta, X = X, y = y, fgh = 0,
                     fbase1 = fbase1.poisson.log)
}
beta.smp &lt;- sns.run(init = beta.init
  , fghEval = loglike.poisson.fonly, niter = 1000, nnr = 20
  , X = X, y = y, numderiv = 2)
smp.summ &lt;- summary(beta.smp)
cbind(beta.glm, smp.summ$smp$mean)


## End(Not run)
</code></pre>

<hr>
<h2 id='summary.sns'>
Summarizing &quot;sns&quot; Objects
</h2><span id='topic+summary.sns'></span><span id='topic+print.summary.sns'></span>

<h3>Description</h3>

<p>Methods for summarizing the output of <code><a href="#topic+sns.run">sns.run</a></code>, and for printing the summary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sns'
summary(object, quantiles = c(0.025, 0.5, 0.975)
  , pval.ref = 0.0, nburnin = max(nrow(object)/2, attr(object, "nnr"))
  , end = nrow(object), thin = 1, ess.method = c("coda", "ise"), ...)
## S3 method for class 'summary.sns'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.sns_+3A_object">object</code></td>
<td>
<p>An object of class &quot;sns&quot;, typically the output of <code><a href="#topic+sns.run">sns.run</a></code>.</p>
</td></tr>
<tr><td><code id="summary.sns_+3A_quantiles">quantiles</code></td>
<td>
<p>Values for which sample-based quantiles are calculated.</p>
</td></tr>
<tr><td><code id="summary.sns_+3A_pval.ref">pval.ref</code></td>
<td>
<p>Reference value for state space variables, used for calculating sample-based p-values.</p>
</td></tr>
<tr><td><code id="summary.sns_+3A_nburnin">nburnin</code></td>
<td>
<p>Number of initial iterations to discard before calculating the sample statistics. A warning is issued if this number is smaller than the initial iterations run in NR mode.</p>
</td></tr>
<tr><td><code id="summary.sns_+3A_end">end</code></td>
<td>
<p>Last iteration to use for calculating sample statistics. Defaults to last iteration.</p>
</td></tr>
<tr><td><code id="summary.sns_+3A_thin">thin</code></td>
<td>
<p>One out of <code>thin</code> samples are kept for calculating sample statistics. Default is <code>1</code>, using all samples within specified range.</p>
</td></tr>
<tr><td><code id="summary.sns_+3A_ess.method">ess.method</code></td>
<td>
<p>Method used for calculating effective sample size. Default is to call <code>effectiveSize</code> from package <code>coda</code>.</p>
</td></tr>
<tr><td><code id="summary.sns_+3A_x">x</code></td>
<td>
<p>An object of class &quot;summary.sns&quot;, typically the output of <code>summary.sns</code>.</p>
</td></tr>
<tr><td><code id="summary.sns_+3A_...">...</code></td>
<td>
<p>Arguments passed to/from other functions.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>summary.sns</code> returns a list with these elements:
</p>
<table>
<tr><td><code>K</code></td>
<td>
<p>Dimensionality of state space.</p>
</td></tr>
<tr><td><code>nnr</code></td>
<td>
<p>Number of NR (Newton-Raphson) iterations performed at the beginning.</p>
</td></tr>
<tr><td><code>nburnin</code></td>
<td>
<p>Number of burn-in iterations. These are discarded before calculating sample statistics.</p>
</td></tr>
<tr><td><code>end</code></td>
<td>
<p>Last iteration to use for calculating sample statistics.</p>
</td></tr>
<tr><td><code>thin</code></td>
<td>
<p>One out of every <code>thin</code> iterations within the specified range is used for calculating sample statistics.</p>
</td></tr>
<tr><td><code>niter</code></td>
<td>
<p>Total iterations, including NR and MCMC modes.</p>
</td></tr>
<tr><td><code>nsmp</code></td>
<td>
<p>Number of samples within specified range (before applying thinning).</p>
</td></tr>
<tr><td><code>nseq</code></td>
<td>
<p>Number of samples used for calculating sample statistics (after applying thinning).</p>
</td></tr>
<tr><td><code>npart</code></td>
<td>
<p>Number of subsets used in state space partitioning. If no partitioning is done, the value is <code>1</code>.</p>
</td></tr>
<tr><td><code>accept.rate</code></td>
<td>
<p>Acceptance rate for the MH transition proposals, calculated over <code>nsmp</code> iterations.</p>
</td></tr>
<tr><td><code>reldev.mean</code></td>
<td>
<p>Mean relative deviation from quadratic approximation, defined as difference between actual log-density change and the value predicted from quadratic fit at density maximum, divided by the actual change. The location of density maximum is assumed to be the value at the end of the last NR iteration. Therefore, for this measure to be accurate, users must ensure <code>nnr</code> is sufficiently large to allow for convegrence of the optimization phase.</p>
</td></tr>
<tr><td><code>pval.ref</code></td>
<td>
<p>Same as input.</p>
</td></tr>
<tr><td><code>ess.method</code></td>
<td>
<p>Same as input.</p>
</td></tr>
<tr><td><code>smp</code></td>
<td>
<p>A list with elements <code>mean</code>, <code>sd</code>, <code>ess</code>, <code>quantiles</code>, <code>pval</code> representing sample-based mean, standard deviation, effective size, quantiles and sample-based p-values, based on specified range and using thinning (if specified).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Alireza S. Mahani, Asad Hasan, Marshall Jiang, Mansour T.A. Sharabiani
</p>


<h3>References</h3>

<p>Mahani A.S., Hasan A., Jiang M. &amp;  Sharabiani M.T.A. (2016). Stochastic Newton Sampler: The R Package sns. Journal of Statistical Software, Code Snippets, 74(2), 1-33. doi:10.18637/jss.v074.c02
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sns.run">sns.run</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
