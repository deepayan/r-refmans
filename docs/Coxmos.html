<!DOCTYPE html><html><head><title>Help for package Coxmos</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Coxmos}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Beran'><p>Estimation of the conditional distribution function of the response, given</p>
the covariate under random censoring.</a></li>
<li><a href='#cenROC'><p>Estimation of the time-dependent ROC curve for right censored survival data</p></a></li>
<li><a href='#cox'><p>cox</p></a></li>
<li><a href='#cox.prediction'><p>cox.prediction</p></a></li>
<li><a href='#coxEN'><p>coxEN</p></a></li>
<li><a href='#coxSW'><p>coxSW</p></a></li>
<li><a href='#Csurv'><p>Survival probability conditional to the observed data estimation for right censored data.</p></a></li>
<li><a href='#CV'><p>The cross-validation bandwidth selection for weighted data</p></a></li>
<li><a href='#cv.coxEN'><p>coxEN Cross-Validation</p></a></li>
<li><a href='#cv.isb.splsdrcox'><p>Cross validation cv.isb.splsdrcox</p></a></li>
<li><a href='#cv.isb.splsicox'><p>Cross validation cv.isb.splsicox</p></a></li>
<li><a href='#cv.mb.splsdacox'><p>MB.sPLS-DACOX Cross-Validation</p></a></li>
<li><a href='#cv.mb.splsdrcox'><p>MB.sPLS-DRCOX Cross-Validation</p></a></li>
<li><a href='#cv.sb.splsdrcox'><p>SB.sPLS-DRCOX Cross-Validation</p></a></li>
<li><a href='#cv.sb.splsicox'><p>Cross validation cv.sb.splsicox</p></a></li>
<li><a href='#cv.splsdacox_dynamic'><p>Cross validation splsdacox_dynamic</p></a></li>
<li><a href='#cv.splsdrcox'><p>sPLS-DRCOX Cross-Validation</p></a></li>
<li><a href='#cv.splsdrcox_dynamic'><p>Cross validation sPLS-DRCOX</p></a></li>
<li><a href='#cv.splsicox'><p>sPLS-ICOX Cross-Validation</p></a></li>
<li><a href='#deleteNearZeroCoefficientOfVariation'><p>deleteNearZeroCoefficientOfVariation</p></a></li>
<li><a href='#deleteNearZeroCoefficientOfVariation.mb'><p>deleteNearZeroCoefficientOfVariation.mb</p></a></li>
<li><a href='#deleteZeroOrNearZeroVariance'><p>deleteZeroOrNearZeroVariance</p></a></li>
<li><a href='#deleteZeroOrNearZeroVariance.mb'><p>deleteZeroOrNearZeroVariance.mb</p></a></li>
<li><a href='#dnorkernel'><p>Derivative of normal distribution</p></a></li>
<li><a href='#eval_Coxmos_model_per_variable'><p>eval_Coxmos_model_per_variable</p></a></li>
<li><a href='#eval_Coxmos_models'><p>eval_Coxmos_models</p></a></li>
<li><a href='#factorToBinary'><p>factorToBinary</p></a></li>
<li><a href='#getAutoKM'><p>getAutoKM</p></a></li>
<li><a href='#getAutoKM.list'><p>getAutoKM.list</p></a></li>
<li><a href='#getCutoffAutoKM'><p>getCutoffAutoKM</p></a></li>
<li><a href='#getCutoffAutoKM.list'><p>getCutoffAutoKM.list</p></a></li>
<li><a href='#getEPV'><p>getEPV</p></a></li>
<li><a href='#getEPV.mb'><p>getEPV.mb</p></a></li>
<li><a href='#getTestKM'><p>getTestKM</p></a></li>
<li><a href='#getTestKM.list'><p>getTestKM.list</p></a></li>
<li><a href='#integ'><p>Numerical Integral function using Simpson's rule</p></a></li>
<li><a href='#ker_dis_i'><p>Distribution function without the ith observation</p></a></li>
<li><a href='#kfunc'><p>Function to evaluate the matrix of data vector minus the grid points divided by the bandwidth value.</p></a></li>
<li><a href='#kfunction'><p>Kernel distribution function</p></a></li>
<li><a href='#loadingplot.Coxmos'><p>loadingplot.Coxmos</p></a></li>
<li><a href='#loadingplot.fromVector.Coxmos'><p>loadingplot.fromVector.Coxmos</p></a></li>
<li><a href='#mb.splsdacox'><p>MB.sPLS-DACOX</p></a></li>
<li><a href='#mb.splsdrcox'><p>MB.sPLS-DRCOX</p></a></li>
<li><a href='#muro'><p>The value of squared integral x^2 k(x) dx and integral x k(x) K(x) dx</p></a></li>
<li><a href='#norm01'><p>norm01</p></a></li>
<li><a href='#NR'><p>The normal reference bandwidth selection for weighted data</p></a></li>
<li><a href='#PI'><p>The plug-in bandwidth selection for weighted data</p></a></li>
<li><a href='#plot_cox.event'><p>plot_cox.event</p></a></li>
<li><a href='#plot_cox.event.list'><p>plot_cox.event.list</p></a></li>
<li><a href='#plot_Coxmos.MB.PLS.model'><p>plot_Coxmos.MB.PLS.model</p></a></li>
<li><a href='#plot_Coxmos.PLS.model'><p>plot_Coxmos.PLS.model</p></a></li>
<li><a href='#plot_divergent.biplot'><p>plot_divergent.biplot</p></a></li>
<li><a href='#plot_evaluation'><p>plot_evaluation</p></a></li>
<li><a href='#plot_evaluation.list'><p>plot_evaluation.list</p></a></li>
<li><a href='#plot_events'><p>plot_events</p></a></li>
<li><a href='#plot_forest'><p>plot_forest</p></a></li>
<li><a href='#plot_forest.list'><p>plot_forest.list</p></a></li>
<li><a href='#plot_LP.multipleObservations'><p>plot_LP.multipleObservations</p></a></li>
<li><a href='#plot_LP.multipleObservations.list'><p>plot_LP.multipleObservations.list</p></a></li>
<li><a href='#plot_observation.eventDensity'><p>plot_observation.eventDensity</p></a></li>
<li><a href='#plot_observation.eventHistogram'><p>plot_observation.eventHistogram</p></a></li>
<li><a href='#plot_PLS_Coxmos'><p>plot_PLS_Coxmos</p></a></li>
<li><a href='#plot_proportionalHazard'><p>plot_proportionalHazard</p></a></li>
<li><a href='#plot_proportionalHazard.list'><p>plot_proportionalHazard.list</p></a></li>
<li><a href='#plot_pseudobeta'><p>plot_pseudobeta</p></a></li>
<li><a href='#plot_pseudobeta_newObservation'><p>plot_pseudobeta.newObservation</p></a></li>
<li><a href='#plot_pseudobeta_newObservation.list'><p>plot_pseudobeta_newObservation.list</p></a></li>
<li><a href='#plot_pseudobeta.list'><p>plot_pseudobeta.list</p></a></li>
<li><a href='#plot_time.list'><p>Time consuming plot.</p></a></li>
<li><a href='#predict.Coxmos'><p>predict.Coxmos</p></a></li>
<li><a href='#print.Coxmos'><p>print.Coxmos</p></a></li>
<li><a href='#RocFun'><p>ROC estimation function</p></a></li>
<li><a href='#save_ggplot'><p>save_ggplot</p></a></li>
<li><a href='#save_ggplot_lst'><p>save_ggplot_lst</p></a></li>
<li><a href='#save_ggplot_lst.svg'><p>save_ggplot_lst.svg</p></a></li>
<li><a href='#save_ggplot.svg'><p>save_ggplot.svg</p></a></li>
<li><a href='#sb.splsdrcox'><p>SB.sPLS-DRCOX</p></a></li>
<li><a href='#sb.splsicox'><p>SB.sPLS-ICOX</p></a></li>
<li><a href='#splsdacox_dynamic'><p>sPLSDA-COX Dynamic</p></a></li>
<li><a href='#splsdrcox'><p>sPLS-DRCOX</p></a></li>
<li><a href='#splsdrcox_dynamic'><p>sPLS-DRCOX Dynamic</p></a></li>
<li><a href='#splsicox'><p>sPLS-ICOX</p></a></li>
<li><a href='#w.starplot.Coxmos'><p>w.starplot.Coxmos</p></a></li>
<li><a href='#wbw'><p>Function to select the bandwidth parameter needed for smoothing the time-dependent ROC curve.</p></a></li>
<li><a href='#wIQR'><p>Weighted inter-quartile range estimation</p></a></li>
<li><a href='#wquantile'><p>Weighted quartile estimation</p></a></li>
<li><a href='#wvar'><p>Weighted variance estimation</p></a></li>
<li><a href='#X_multiomic'><p>X_multiomic Data</p></a></li>
<li><a href='#X_proteomic'><p>X_proteomic Data</p></a></li>
<li><a href='#Y_multiomic'><p>Y_multiomic Data</p></a></li>
<li><a href='#Y_proteomic'><p>Y_proteomic Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Cox MultiBlock Survival</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.2</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Pedro Salguero Garc√≠a &lt;pedrosalguerog@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>This software package provides Cox survival analysis for high-dimensional and multiblock datasets. 
             It encompasses a suite of functions dedicated from the classical Cox regression to newest analysis,
             including Cox proportional hazards model, Stepwise Cox regression, and Elastic-Net Cox regression, 
             Sparse Partial Least Squares Cox regression (sPLS-COX) incorporating three distinct strategies, 
             and two Multiblock-PLS Cox regression (MB-sPLS-COX) methods. This tool is designed to adeptly handle 
             high-dimensional data, and provides tools for cross-validation, plot generation, and additional resources 
             for interpreting results. While references are available within the corresponding functions, 
             key literature is mentioned below.
             Terry M Therneau (2024) <a href="https://CRAN.R-project.org/package=survival">https://CRAN.R-project.org/package=survival</a>,
             Noah Simon et al. (2011) &lt;<a href="https://doi.org/10.18637%2Fjss.v039.i05">doi:10.18637/jss.v039.i05</a>&gt;,
             Philippe Bastien et al. (2005) &lt;<a href="https://doi.org/10.1016%2Fj.csda.2004.02.005">doi:10.1016/j.csda.2004.02.005</a>&gt;,
             Philippe Bastien (2008) &lt;<a href="https://doi.org/10.1016%2Fj.chemolab.2007.09.009">doi:10.1016/j.chemolab.2007.09.009</a>&gt;,
             Philippe Bastien et al. (2014) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtu660">doi:10.1093/bioinformatics/btu660</a>&gt;,
             Kassu Mehari Beyene and Anouar El Ghouch (2020) &lt;<a href="https://doi.org/10.1002%2Fsim.8671">doi:10.1002/sim.8671</a>&gt;,
             Florian Rohart et al. (2017) &lt;<a href="https://doi.org/10.1371%2Fjournal.pcbi.1005752">doi:10.1371/journal.pcbi.1005752</a>&gt;.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/BiostatOmics/Coxmos">https://github.com/BiostatOmics/Coxmos</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/BiostatOmics/Coxmos/issues">https://github.com/BiostatOmics/Coxmos/issues</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0),</td>
</tr>
<tr>
<td>Imports:</td>
<td>caret, cowplot, furrr, future, ggrepel, ggplot2, ggpubr,
glmnet, MASS, mixOmics, progress, purrr, Rdpack, scattermore,
stats, survcomp, survival, survminer, svglite, tidyr, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>nsROC, smoothROCtime, survivalROC, risksetROC, ggforce,
knitr, RColorConesa, rmarkdown</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-22 18:01:35 UTC; Ps</td>
</tr>
<tr>
<td>Author:</td>
<td>Pedro Salguero Garc√≠a
    <a href="https://orcid.org/0000-0002-1879-3374"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre,
    rev],
  Sonia Tarazona Campos [ths],
  Ana Conesa Cegarra [ths],
  Kassu Mehari Beyene [ctb],
  Luis Meira Machado [ctb],
  Marta Sestelo [ctb],
  Artur Ara√∫jo [ctb]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-25 20:32:38 UTC</td>
</tr>
</table>
<hr>
<h2 id='Beran'>Estimation of the conditional distribution function of the response, given
the covariate under random censoring.</h2><span id='topic+Beran'></span>

<h3>Description</h3>

<p>Computes the conditional survival probability P(T &gt; y|Z = z)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Beran(
  time,
  status,
  covariate,
  delta,
  x,
  y,
  kernel = "gaussian",
  bw,
  lower.tail = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Beran_+3A_time">time</code></td>
<td>
<p>The survival time of the process.</p>
</td></tr>
<tr><td><code id="Beran_+3A_status">status</code></td>
<td>
<p>Censoring indicator of the total time of the process; 0 if the
total time is censored and 1 otherwise.</p>
</td></tr>
<tr><td><code id="Beran_+3A_covariate">covariate</code></td>
<td>
<p>Covariate values for obtaining estimates for the
conditional probabilities.</p>
</td></tr>
<tr><td><code id="Beran_+3A_delta">delta</code></td>
<td>
<p>Censoring indicator of the covariate.</p>
</td></tr>
<tr><td><code id="Beran_+3A_x">x</code></td>
<td>
<p>The first time (or covariate value) for obtaining estimates for the
conditional probabilities. If missing, 0 will be used.</p>
</td></tr>
<tr><td><code id="Beran_+3A_y">y</code></td>
<td>
<p>The total time for obtaining estimates for the conditional
probabilities.</p>
</td></tr>
<tr><td><code id="Beran_+3A_kernel">kernel</code></td>
<td>
<p>A character string specifying the desired kernel. See details
below for possible options. Defaults to &quot;gaussian&quot; where the gaussian
density kernel will be used.</p>
</td></tr>
<tr><td><code id="Beran_+3A_bw">bw</code></td>
<td>
<p>A single numeric value to compute a kernel density bandwidth.</p>
</td></tr>
<tr><td><code id="Beran_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if FALSE (default), probabilities are P(T &gt; y|Z =
z) otherwise, P(T &lt;= y|Z = z).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Possible options for argument window are &quot;gaussian&quot;, &quot;epanechnikov&quot;,
&quot;tricube&quot;, &quot;boxcar&quot;, &quot;triangular&quot;, &quot;quartic&quot; or &quot;cosine&quot;.
</p>


<h3>Author(s)</h3>

<p>Luis Meira-Machado and Marta Sestelo
</p>


<h3>References</h3>

<p>R. Beran. Nonparametric regression with randomly censored
survival data. Technical report, University of California, Berkeley, 1981.
</p>

<hr>
<h2 id='cenROC'>Estimation of the time-dependent ROC curve for right censored survival data</h2><span id='topic+cenROC'></span>

<h3>Description</h3>

<p>This function computes the time-dependent ROC curve for right censored survival data using the cumulative sensitivity and dynamic specificity definitions.
The ROC curves can be either empirical (non-smoothed) or smoothed with/wtihout boundary correction. It also calculates the time-dependent area under the ROC curve (AUC).
Edited by Pedro Salguero to remove the PLOT argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cenROC(Y, M, censor, t, U = NULL, h = NULL, bw = "NR", method = "tra",
    ktype = "normal", ktype1 = "normal", B = 0, alpha = 0.05, plot = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cenROC_+3A_y">Y</code></td>
<td>
<p>The numeric vector of event-times or observed times.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_m">M</code></td>
<td>
<p>The numeric vector of marker values for which the time-dependent ROC curves is computed.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_censor">censor</code></td>
<td>
<p>The censoring indicator, <code>1</code> if event, <code>0</code> otherwise.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_t">t</code></td>
<td>
<p>A scaler time point at which the time-dependent ROC curve is computed.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_u">U</code></td>
<td>
<p>The vector of grid points where the ROC curve is estimated. The default is a sequence of <code>151</code> numbers between <code>0</code> and <code>1</code>.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_h">h</code></td>
<td>
<p>A scaler for the bandwidth of Beran's weight calculaions. The default is the value obtained by using the method of Sheather and Jones (1991).</p>
</td></tr>
<tr><td><code id="cenROC_+3A_bw">bw</code></td>
<td>
<p>A character string specifying the bandwidth estimation method for the ROC itself. The possible options are &quot;<code>NR</code>&quot; for the normal reference, the plug-in &quot;<code>PI</code>&quot; and the cross-validation &quot;<code>CV</code>&quot;. The default is the &quot;<code>NR</code>&quot; normal reference method. The user can also introduce a numerical value.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_method">method</code></td>
<td>
<p>The method of ROC curve estimation. The possible options are &quot;<code>emp</code>&quot; emperical method; &quot;<code>untra</code>&quot; smooth without boundary correction and &quot;<code>tra</code>&quot; is smooth ROC curve estimation with boundary correction. The default is the &quot;<code>tra</code>&quot; smooth ROC curve estimate with boundary correction.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_ktype">ktype</code></td>
<td>
<p>A character string giving the type kernel distribution to be used for smoothing the ROC curve: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;. By default, the &quot;<code>normal</code>&quot; kernel is used.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_ktype1">ktype1</code></td>
<td>
<p>A character string specifying the desired kernel needed for Beran weight calculation. The possible options are &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>tricube</code>&quot;, &quot;<code>boxcar</code>&quot;, &quot;<code>triangular</code>&quot;, or &quot;<code>quartic</code>&quot;. The defaults is &quot;<code>normal</code>&quot; kernel density.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_b">B</code></td>
<td>
<p>The number of bootstrap samples to be used for variance estimation. The default is <code>0</code>, no variance estimation.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_alpha">alpha</code></td>
<td>
<p>The significance level. The default is <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="cenROC_+3A_plot">plot</code></td>
<td>
<p>The logical parameter to see the ROC curve plot. The default is <code>TRUE</code>. Currently disabled.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The empirical (non-smoothed) ROC estimate and the smoothed ROC estimate with/without boundary correction can be obtained using this function.
The smoothed ROC curve estimators require selecting two bandwidth parametrs: one for Beran‚Äôs weight calculation and one for smoothing the ROC curve.
For the latter, three data-driven methods: the normal reference &quot;<code>NR</code>&quot;, the plug-in &quot;<code>PI</code>&quot; and the cross-validation &quot;<code>CV</code>&quot; were implemented.
To select the bandwidth parameter needed for Beran‚Äôs weight calculation, by default, the plug-in method of Sheather and Jones (1991) is used but it is also possible introduce a numeric value.
See Beyene and El Ghouch (2020) for details.
</p>


<h3>Value</h3>

<p>Returns the following items:
</p>
<p><code>ROC     </code> The vector of estimated ROC values. These will be numeric numbers between zero
</p>
<p> and one.
</p>
<p><code>U       </code> The vector of grid points used.
</p>
<p><code>AUC      </code> A data frame of dimension <code class="reqn">1 \times 4</code>. The columns are: AUC, standard error of AUC, the lower
</p>
<p>               and upper limits of bootstrap CI.
</p>
<p><code>bw       </code> The computed value of bandwidth. For the empirical method this is always <code>NA</code>.
</p>
<p><code>Dt      </code> The vector of estimated event status.
</p>
<p><code>M       </code> The vector of Marker values.
</p>


<h3>Author(s)</h3>

<p>Kassu Mehari Beyene, Catholic University of Louvain. <code>&lt;kasu.beyene@uclouvain.be&gt;</code>
</p>
<p>Anouar El Ghouch, Catholic University of Louvain. <code>&lt;anouar.elghouch@uclouvain.be&gt;</code>
</p>


<h3>References</h3>

<p>Beyene, K. M. and El Ghouch A. (2020). Smoothed time-dependent ROC curves for right-censored survival data. <em>submitted</em>.
</p>
<p>Sheather, S. J. and Jones, M. C. (1991). A Reliable data-based bandwidth selection method for kernel density estimation. <em>Journal of the Royal Statistical Society</em>. Series B (Methodological) 53(3): 683‚Äì690.
</p>

<hr>
<h2 id='cox'>cox</h2><span id='topic+cox'></span>

<h3>Description</h3>

<p>The <code>cox</code> function conducts a Cox proportional hazards regression analysis, a type of survival
analysis. It is designed to handle right-censored data and is built upon the <code>coxph</code> function from
the <code>survival</code> package. The function returns an object of class &quot;Coxmos&quot; with the attribute model
labeled as &quot;cox&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cox(
  X,
  Y,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = FALSE,
  toKeep.zv = NULL,
  remove_non_significant = FALSE,
  alpha = 0.05,
  MIN_EPV = 5,
  FORCE = FALSE,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="cox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the threshold
(default: 0.05).</p>
</td></tr>
<tr><td><code id="cox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cox_+3A_force">FORCE</code></td>
<td>
<p>Logical. In case the MIN_EPV is not meet, it allows to compute the model (default: FALSE).</p>
</td></tr>
<tr><td><code id="cox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Cox proportional hazards regression model is a linear model that describes the relationship
between the hazard rate and one or more predictor variables. The function provided here offers
several preprocessing steps to ensure the quality and robustness of the model.
</p>
<p>The function allows for the centering and scaling of predictor variables, which can be essential
for the stability and interpretability of the model. It also provides options to remove variables
with near-zero or zero variance, which can be problematic in regression analyses. Such variables
offer little to no information and can lead to overfitting.
</p>
<p>Another notable feature is the ability to remove non-significant predictors from the final model
through a backward selection process. This ensures that only variables that contribute significantly
to the model are retained.
</p>
<p>The function also checks for the minimum number of events per variable (EPV) to ensure the
robustness of the model. If the specified EPV is not met, the function can either halt the
computation or proceed based on user preference.
</p>
<p>It's important to note that while this function is tailored for standard Cox regression, it might
not be suitable for high-dimensional data. In such cases, users are advised to consider alternative
methods like <code>coxEN()</code> or PLS-based Cox methods.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cox&quot;. The class contains the following elements:
</p>
<p><code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized Y matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>nsv</code>: Variables removed by remove_non_significant if any.
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>removed_variables_correlation</code>: Variables removed by being high correlated with other
variables.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Cox D (1972).
&ldquo;Regression models and life tables (with discussion.&rdquo;
<em>Royal Statistical Society</em>.
<a href="https://doi.org/10.1111/j.2517-6161.1972.tb00899.x">https://doi.org/10.1111/j.2517-6161.1972.tb00899.x</a>.
Concato J, Peduzzi P, Holford TR, Feinstein AR (1995).
&ldquo;Importance of events per independent variable in proportional hazards analysis I. Background, goals, and general strategy.&rdquo;
<em>Journal of Clinical Epidemiology</em>.
<a href="https://doi.org/10.1016/0895-4356%2895%2900510-2">doi:10.1016/0895-4356(95)00510-2</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/8543963/">https://pubmed.ncbi.nlm.nih.gov/8543963/</a>.
Therneau TM (2024).
<em>A Package for Survival Analysis in R</em>.
R package version 3.5-8, <a href="https://CRAN.R-project.org/package=survival">https://CRAN.R-project.org/package=survival</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:10]
Y &lt;- Y_proteomic
cox(X, Y, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='cox.prediction'>cox.prediction</h2><span id='topic+cox.prediction'></span>

<h3>Description</h3>

<p>The <code>cox.prediction</code> function facilitates Cox predictions based on a given Coxmos model,
specifically tailored for raw data input. It seamlessly integrates the generation of a score
matrix, especially when a PLS Survival analysis has been executed, and subsequently conducts the
Cox prediction. The function offers flexibility in prediction types and methods, catering to
diverse analytical requirements.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cox.prediction(model, new_data, time = NULL, type = "lp", method = "cox")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cox.prediction_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="cox.prediction_+3A_new_data">new_data</code></td>
<td>
<p>Numeric matrix or data.frame. New explanatory variables (raw data). Qualitative
variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="cox.prediction_+3A_time">time</code></td>
<td>
<p>Numeric. Time point where the AUC will be evaluated (default: NULL).</p>
</td></tr>
<tr><td><code id="cox.prediction_+3A_type">type</code></td>
<td>
<p>Character. Prediction type: &quot;lp&quot;, &quot;risk&quot;, &quot;expected&quot; or &quot;survival&quot; (default: &quot;lp&quot;).</p>
</td></tr>
<tr><td><code id="cox.prediction_+3A_method">method</code></td>
<td>
<p>Character. Prediction method. It can be compute by using the cox model &quot;cox&quot; or by
using W.star &quot;W.star&quot; (default: &quot;cox&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function initiates by determining the prediction method specified by the user. If the &quot;cox&quot;
method is chosen, the function computes the score matrix using the <code>predict.Coxmos</code> function.
This score matrix serves as a foundation for subsequent predictions. It's imperative to note that
for prediction types &quot;expected&quot; and &quot;survival&quot;, a specific time point must be provided to ensure
accurate predictions. The function then leverages the <code>predict</code> function from the Cox model to
compute the desired prediction metric.
</p>
<p>Alternatively, if the &quot;W.star&quot; method is selected, the function computes the prediction values
based on the W* matrix and the Cox model's coefficients. This involves normalization of the input
data, ensuring it aligns with the training data's distribution. The normalization process considers
mean and standard deviation values from the model, ensuring consistency in predictions. The
resultant prediction values are then computed as a linear combination of the normalized data and
the derived coefficients.
</p>
<p>It's worth noting that the function is meticulously designed to handle potential inconsistencies
or missing components in the model, ensuring robustness in predictions and minimizing potential
errors during execution.
</p>


<h3>Value</h3>

<p>Return the &quot;lp&quot;, &quot;risk&quot;, &quot;expected&quot; or &quot;survival&quot; metric for test data using the specific
Coxmos model.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]

X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]

model_icox &lt;- splsicox(X_train, Y_train, n.comp = 2)
cox.prediction(model = model_icox, new_data = X_test, type = "lp")
</code></pre>

<hr>
<h2 id='coxEN'>coxEN</h2><span id='topic+coxEN'></span>

<h3>Description</h3>

<p>This function performs a cox elastic net model (based on glmnet R package).
The function returns a Coxmos model with the attribute model as &quot;coxEN&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coxEN(
  X,
  Y,
  EN.alpha = 0.5,
  max.variables = 15,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = FALSE,
  toKeep.zv = NULL,
  remove_non_significant = FALSE,
  alpha = 0.05,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coxEN_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="coxEN_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="coxEN_+3A_en.alpha">EN.alpha</code></td>
<td>
<p>Numeric. Elastic net mixing parameter. If EN.alpha = 1 is the lasso penalty, and
EN.alpha = 0 the ridge penalty (default: 0.5). NOTE: When ridge penalty is used, EVP and
max.variables will not be used.</p>
</td></tr>
<tr><td><code id="coxEN_+3A_max.variables">max.variables</code></td>
<td>
<p>Numeric. Maximum number of variables you want to keep in the cox model. If
MIN_EPV is not meet, the value will be change automatically (default: 20).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="coxEN_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The coxEN function is designed to handle survival data using the elastic net regularization. The
function is particularly useful when dealing with high-dimensional datasets where the number of
predictors exceeds the number of observations.
The elastic net regularization combines the strengths of both lasso and ridge regression. The
<code>EN.alpha</code> parameter controls the balance between lasso and ridge penalties.
It's important to note that when using the ridge penalty (<code>EN.alpha = 0</code>), the EVP and
<code>max.variables</code> parameters will not be considered.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;coxEN&quot;. The class contains the following elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>opt.lambda</code>: Optimal lambda computed by the model with maximum % Var from glmnet function.
</p>
<p><code>EN.alpha</code>: EN.alpha selected
</p>
<p><code>n.var</code>: Number of variables selected
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>convergence_issue</code>: If any convergence issue has been found.
</p>
<p><code>alpha</code>: alpha value selected
</p>
<p><code>selected_variables_cox</code>: Variables selected to enter the cox model.
</p>
<p><code>nsv</code>: Variables removed by cox alpha cutoff.
</p>
<p><code>removed_variables_correlation</code>: Variables removed by being high correlated with other
variables.
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Simon N, Friedman JH, Friedman JH, Hastie T, Tibshirani R (2011).
&ldquo;Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent.&rdquo;
<em>Journal of Statistical Software</em>.
<a href="https://doi.org/10.18637/jss.v039.i05">doi:10.18637/jss.v039.i05</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/27065756/">https://pubmed.ncbi.nlm.nih.gov/27065756/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
coxEN(X, Y, EN.alpha = 0.75, x.center = TRUE, x.scale = TRUE, remove_non_significant = TRUE)
</code></pre>

<hr>
<h2 id='coxSW'>coxSW</h2><span id='topic+coxSW'></span>

<h3>Description</h3>

<p>The <code>coxSW</code> function conducts a stepwise Cox regression analysis on survival data,
leveraging the capabilities of the <code>My.stepwise</code> R package. The primary objective of this function
is to identify the most significant predictors for survival data by iteratively adding or removing
predictors based on their statistical significance in the model. The resulting model is of class
&quot;Coxmos&quot; with an attribute model labeled as &quot;coxSW&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coxSW(
  X,
  Y,
  max.variables = 20,
  BACKWARDS = TRUE,
  alpha_ENT = 0.1,
  alpha_OUT = 0.15,
  toKeep.sw = NULL,
  initialModel = NULL,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = FALSE,
  toKeep.zv = NULL,
  remove_non_significant = FALSE,
  alpha = 0.05,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coxSW_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="coxSW_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="coxSW_+3A_max.variables">max.variables</code></td>
<td>
<p>Numeric. Maximum number of variables you want to keep in the cox model. If
MIN_EPV is not meet, the value will be change automatically (default: 20).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_backwards">BACKWARDS</code></td>
<td>
<p>Logical. If BACKWARDS = TRUE, backward strategy is performed (default: TRUE).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_alpha_ent">alpha_ENT</code></td>
<td>
<p>Numeric. Maximum P-Value for a variable to enter the model (default: 0.10).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_alpha_out">alpha_OUT</code></td>
<td>
<p>Numeric. Minimum P-Value for a variable to leave the model (default: 0.15).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_tokeep.sw">toKeep.sw</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by Step-wise
selection (default: NULL).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_initialmodel">initialModel</code></td>
<td>
<p>Character vector. Name of variables in X to include in the initial model
(default: NULL).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="coxSW_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>coxSW</code> function employs a stepwise regression technique tailored for survival data. This
method is particularly beneficial when dealing with a plethora of predictors, and there's a
necessity to distill the model to its most impactful variables. The stepwise procedure can be
configured to operate in forward, backward, or a hybrid mode, contingent on the parameters
specified by the user.
</p>
<p>During the iterative process, variables are evaluated for inclusion or exclusion based on
predefined significance levels (<code>alpha_ENT</code> for entry and <code>alpha_OUT</code> for removal). This ensures
that the model retains only those predictors that meet the significance criteria, thereby
enhancing the model's interpretability and predictive power.
</p>
<p>Additionally, the function offers several preprocessing options, such as centering and scaling of
the predictor matrix, removal of variables with near-zero or zero variance, and the ability to
enforce the inclusion of specific variables in the model. These preprocessing steps are crucial
for ensuring the robustness and stability of the resulting Cox regression model.
</p>
<p>It's worth noting that the function is equipped to handle both numeric and binary categorical
predictors. However, it's imperative that categorical variables are appropriately transformed
into binary format before analysis. The outcome or response variable should comprise two columns:
&quot;time&quot; representing the survival time and &quot;event&quot; indicating the occurrence of the event of interest.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;coxSW&quot;. The class contains the following elements:
</p>
<p><code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized Y matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>nsv</code>: Variables removed by remove_non_significant if any.
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>removed_variables_correlation</code>: Variables removed by being high correlated with other
variables.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Efroymson MA (1960).
&ldquo;Multiple Regression Analysis.&rdquo;
<em>Mathematical Methods for Digital Computers</em>.
Company ISC (2017).
&ldquo;My.stepwise: Stepwise Variable Selection Procedures for Regression Analysis.&rdquo;
<a href="https://cran.r-project.org/package=My.stepwise">https://cran.r-project.org/package=My.stepwise</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:10]
Y &lt;- Y_proteomic
coxSW(X, Y, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='Csurv'>Survival probability conditional to the observed data estimation for right censored data.</h2><span id='topic+Csurv'></span>

<h3>Description</h3>

<p>Survival probability conditional to the observed data estimation for right censored data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Csurv(Y, M, censor, t, h = NULL, kernel = "normal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Csurv_+3A_y">Y</code></td>
<td>
<p>The numeric vector of event-times or observed times.</p>
</td></tr>
<tr><td><code id="Csurv_+3A_m">M</code></td>
<td>
<p>The numeric vector of marker values for which we want to compute the time-dependent ROC curves.</p>
</td></tr>
<tr><td><code id="Csurv_+3A_censor">censor</code></td>
<td>
<p>The censoring indicator, <code>1</code> if event, <code>0</code> otherwise.</p>
</td></tr>
<tr><td><code id="Csurv_+3A_t">t</code></td>
<td>
<p>A scaler time point at which we want to compute the time-dependent ROC curve.</p>
</td></tr>
<tr><td><code id="Csurv_+3A_h">h</code></td>
<td>
<p>A scaler for the bandwidth of Beran's weight calculaions. The default is using the method of Sheather and Jones (1991).</p>
</td></tr>
<tr><td><code id="Csurv_+3A_kernel">kernel</code></td>
<td>
<p>A character string giving the type kernel to be used: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, , &quot;<code>tricube</code>&quot;, &quot;<code>boxcar</code>&quot;, &quot;<code>triangular</code>&quot;, or &quot;<code>quartic</code>&quot;. The defaults is &quot;<code>normal</code>&quot; kernel density.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return a vectors:
</p>
<p><code>positive    </code>    <code>P(T&lt;t|Y,censor,M)</code>.
</p>
<p><code>negative    </code>     <code>P(T&gt;t|Y,censor,M)</code>.
</p>


<h3>References</h3>

<p>Beyene, K. M. and El Ghouch A. (2019). Smoothed time-dependent ROC curves for right-censored survival data. <a href="https://dial.uclouvain.be/pr/boreal/object/boreal:219643">https://dial.uclouvain.be/pr/boreal/object/boreal:219643</a>.
</p>
<p>Li, Liang, Bo Hu and Tom Greene (2018).  A simple method to estimate the time-dependent receiver operating characteristic curve and the area under the curve with right censored data, Statistical Methods in Medical Research, 27(8): 2264-2278.
</p>
<p>Pablo Mart√≠nez-Camblor and Gustavo F. Bay√≥n and Sonia P√©rez-Fern√°ndez (2016). Cumulative/dynamic roc curve estimation, Journal of Statistical Computation and Simulation, 86(17): 3582-3594.
</p>

<hr>
<h2 id='CV'>The cross-validation bandwidth selection for weighted data</h2><span id='topic+CV'></span>

<h3>Description</h3>

<p>This function computes the data-driven bandwidth for smoothing the ROC (or distribution) function using the CV method of Beyene and El Ghouch (2020). This is an extension of the classical (unweighted) cross-validation bandwith selection method to the case of weighted data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV(X, wt, ktype = "normal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CV_+3A_x">X</code></td>
<td>
<p>The numeric data vector.</p>
</td></tr>
<tr><td><code id="CV_+3A_wt">wt</code></td>
<td>
<p>The non-negative weight vector.</p>
</td></tr>
<tr><td><code id="CV_+3A_ktype">ktype</code></td>
<td>
<p>A character string giving the type kernel to be used: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;. By default, the &quot;<code>normal</code>&quot; kernel is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Bowman et al (1998) proposed the cross-validation bandwidth selection method for unweighted kernal smoothed distribution function. This method is implemented in the <code>R</code> package <code>kerdiest</code>.
We adapted this for the case of weighted data by incorporating the weight variable into the cross-validation function of Bowman's method. See Beyene and El Ghouch (2020) for details.
</p>


<h3>Value</h3>

<p>Returns the computed value for the bandwith parameter.
</p>


<h3>Author(s)</h3>

<p>Kassu Mehari Beyene, Catholic University of Louvain. <code>&lt;kasu.beyene@uclouvain.be&gt;</code>
</p>
<p>Anouar El Ghouch, Catholic University of Louvain. <code>&lt;anouar.elghouch@uclouvain.be&gt;</code>
</p>


<h3>References</h3>

<p>Beyene, K. M. and El Ghouch A. (2020). Smoothed time-dependent ROC curves for right-censored survival data. <em>submitted</em>.
</p>
<p>Bowman A., Hall P. and Trvan T.(1998). Bandwidth selection for the smoothing of distribution functions. <em>Biometrika</em> 85:799-808.
</p>
<p>Quintela-del-Rio, A. and Estevez-Perez, G. (2015). <code>kerdiest:</code> Nonparametric kernel estimation of the distribution function, bandwidth selection and estimation of related functions. <code>R</code> package version 1.2.
</p>

<hr>
<h2 id='cv.coxEN'>coxEN Cross-Validation</h2><span id='topic+cv.coxEN'></span>

<h3>Description</h3>

<p>This function performs cross-validated CoxEN (coxEN).
The function returns the optimal number of EN penalty value based on cross-validation.
The performance could be based on multiple metrics as Area Under the Curve (AUC), Brier Score or
C-Index. Furthermore, the user could establish more than one metric simultaneously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.coxEN(
  X,
  Y,
  EN.alpha.list = seq(0, 1, 0.1),
  max.variables = 15,
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC_INCREASE = 0.01,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  fast_mode = FALSE,
  MIN_EPV = 5,
  return_models = FALSE,
  returnData = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.coxEN_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_en.alpha.list">EN.alpha.list</code></td>
<td>
<p>Numeric vector. Elastic net mixing parameter values to test in cross
validation. EN.alpha = 1 is the lasso penalty, and EN.alpha = 0 the ridge penalty
(default: seq(0,1,0.1)).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_max.variables">max.variables</code></td>
<td>
<p>Numeric. Maximum number of variables you want to keep in the cox model. If
MIN_EPV is not meet, the value will be change automatically (default: 20).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near) zero
variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation. A non-significant model is a
model with at least one component/variable with a P-Value higher than the alpha cutoff.</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the threshold
(default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding the
'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet, the
evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.coxEN_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code style="white-space: pre;">&#8288;coxEN Cross-Validation&#8288;</code> function provides a robust mechanism to optimize the hyperparameters
of the cox elastic net model through cross-validation. By systematically evaluating a range of
elastic net mixing parameters (<code>EN.alpha.list</code>), this function identifies the optimal balance
between lasso and ridge penalties for survival analysis.
</p>
<p>The cross-validation process is structured across multiple runs (<code>n_run</code>) and folds (<code>k_folds</code>),
ensuring a comprehensive assessment of model performance. Users can prioritize specific evaluation
metrics, such as AUC, Brier Score, or C-Index, by assigning weights (<code>w_AIC</code>, <code>w_c.index</code>, <code>w_AUC</code>,
<code>w_BRIER</code>). The function also offers flexibility in the AUC evaluation method (<code>pred.method</code>) and
the attribute for metric evaluation (<code>pred.attr</code>).
</p>
<p>One of the distinguishing features of this function is its adaptive evaluation process. The
function can terminate the cross-validation early if the improvement in AUC does not exceed the
<code>MIN_AUC_INCREASE</code> threshold or if a predefined AUC (<code>MIN_AUC</code>) is achieved. This adaptive approach
ensures computational efficiency without compromising the quality of the results.
</p>
<p>Data preprocessing options are integrated into the function, emphasizing the significance of data
quality. Options to remove near-zero and zero variance variables, either globally or at the fold
level, are available. The function also supports multicore processing (<code>PARALLEL</code> option) to
expedite the cross-validation process.
</p>
<p>Upon execution, the function returns a detailed output, encompassing information about the best
model, performance metrics at various granularities (fold, run, component), and if desired, all
cross-validated models.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cv.coxEN&quot;. The class contains the following elements:
<code>best_model_info</code>: A data.frame with the information for the best model.
<code>df_results_folds</code>: A data.frame with fold-level information.
<code>df_results_runs</code>: A data.frame with run-level information.
<code>df_results_comps</code>: A data.frame with component-level information (for cv.coxEN, EN.alpha
information).
</p>
<p><code>lst_models</code>: If return_models = TRUE, return a the list of all cross-validated models.
<code>pred.method</code>: AUC evaluation algorithm method for evaluate the model performance.
</p>
<p><code>opt.EN.alpha</code>: Optimal EN.alpha value selected by the best_model.
<code>opt.nvar</code>: Optimal number of variables selected by the best_model.
</p>
<p><code>plot_AIC</code>: AIC plot by each hyper-parameter.
<code>plot_c_index</code>: C-Index plot by each hyper-parameter.
<code>plot_BRIER</code>: Brier Score plot by each hyper-parameter.
<code>plot_AUC</code>: AUC plot by each hyper-parameter.
</p>
<p><code>class</code>: Cross-Validated model class.
</p>
<p><code>lst_train_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for train the models.
<code>lst_test_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for test the models.
</p>
<p><code>time</code>: time consumed for running the cross-validated function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
cv.coxEN_model &lt;- cv.coxEN(X_train, Y_train, EN.alpha.list = c(0.1,0.5),
x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='cv.isb.splsdrcox'>Cross validation cv.isb.splsdrcox</h2><span id='topic+cv.isb.splsdrcox'></span>

<h3>Description</h3>

<p>This function performs cross-validated sparse partial least squares iterative single
block for splsdrcox. The function returns the optimal number of components and the optimal sparsity
penalty value based on cross-validation. The performance could be based on multiple metrics as
Area Under the Curve (AUC), Brier Score or C-Index. Furthermore, the user could establish more
than one metric simultaneously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.isb.splsdrcox(
  X,
  Y,
  max.ncomp = 8,
  penalty.list = seq(0.1, 0.9, 0.2),
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC_INCREASE = 0.01,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  fast_mode = FALSE,
  MIN_EPV = 5,
  returnData = TRUE,
  return_models = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.isb.splsdrcox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_penalty.list">penalty.list</code></td>
<td>
<p>Numeric vector. Vector of penalty values. Penalty for sPLS-DRCOX. If
penalty = 0 no penalty is applied, when penalty = 1 maximum penalty (no variables are selected)
based on 'plsRcox' penalty. Equal or greater than 1 cannot be selected (default: seq(0.1,0.9,0.2)).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near) zero
variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation. A non-significant model is a
model with at least one component/variable with a P-Value higher than the alpha cutoff.</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding
the 'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet,
the evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsdrcox_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>cv.isb.splsdrcox</code> function performs cross-validation for the integrative single-block sparse
partial least squares deviance residual Cox analysis. Unlike the single-block (SB) approach, the
integrative single-block (ISB) method allows for the consideration of multiple blocks of data,
potentially from different sources or types, to be integrated into a single model. A key distinction
of the ISB approach is its ability to compute and optimize hyperparameters individually for each
block, rather than applying a uniform set of hyperparameters across all blocks. This ensures that
each block's unique characteristics are taken into account, leading to a more tailored and
potentially more accurate model.
</p>
<p>Cross-validation is essential for assessing the generalizability of the model and avoiding
overfitting. By partitioning the original dataset into training and test sets multiple times, the
function evaluates the model's performance across different subsets of the data. This iterative
process ensures that the model's performance is robust and not overly reliant on a specific
partition of the data.
</p>
<p>The function evaluates a range of hyperparameters, including the number of latent components
(<code>max.ncomp</code>) and the penalty for variable selection (<code>penalty.list</code>). For each combination of
hyperparameters, the dataset is divided into training and test sets based on the specified number
of folds (<code>k_folds</code>). The model is then trained on the training set and its performance is assessed
on the test set. This process is repeated for the specified number of runs (<code>n_run</code>), providing a
comprehensive evaluation of the model's performance.
</p>
<p>Various evaluation metrics, such as AIC, C-Index, Brier Score, and AUC, are computed for each
combination of hyperparameters. These metrics provide insights into the model's accuracy,
discriminative ability, and calibration. The function then identifies the optimal hyperparameters
that yield the best performance based on these metrics.
</p>
<p>In summary, the <code>cv.isb.splsdrcox</code> function offers a robust and integrative approach for
hyperparameter tuning and model evaluation for the sparse partial least squares deviance residual
Cox analysis. By allowing individualized hyperparameter optimization for each block, the ISB
approach ensures a more nuanced and potentially more accurate model compared to the traditional
SB method.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;sb.splscox&quot;. The class contains the following
elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: PLS weights
</p>
</li>
<li> <p><code>(weightings_norm)</code>: PLS normalize weights
</p>
</li>
<li> <p><code>(W.star)</code>: PLS W* vector
</p>
</li>
<li> <p><code>(scores)</code>: PLS scores/variates
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(deviance_residuals)</code>: deviance residual vector used as Y matrix in the sPLS.
</p>
</li>
<li> <p><code>(dr.mean)</code>: mean values for deviance residuals Y matrix
</p>
</li>
<li> <p><code>(dr.sd)</code>: standard deviation for deviance residuals Y matrix'
</p>
</li>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>list_spls_models</code>: List of sPLS-DRCOX models computed for each block.
</p>
<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>penalty</code> Penalty applied.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_multiomic")
data("Y_multiomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_multiomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_multiomic
X_train$mirna &lt;- X_train$mirna[index_train,1:50]
X_train$proteomic &lt;- X_train$proteomic[index_train,1:50]
Y_train &lt;- Y_multiomic[index_train,]
isb.splsdrcox_model &lt;- cv.isb.splsdrcox(X_train, Y_train, max.ncomp = 2, penalty.list = c(0.5),
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='cv.isb.splsicox'>Cross validation cv.isb.splsicox</h2><span id='topic+cv.isb.splsicox'></span>

<h3>Description</h3>

<p>This function performs cross-validated sparse partial least squares iterative single
block for splsicox. The function returns the optimal number of components and the optimal sparsity
penalty value based on cross-validation. The performance could be based on multiple metrics as
Area Under the Curve (AUC), Brier Score or C-Index. Furthermore, the user could establish more
than one metric simultaneously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.isb.splsicox(
  X,
  Y,
  max.ncomp = 8,
  penalty.list = seq(0.1, 0.9, 0.2),
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC_INCREASE = 0.01,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  fast_mode = FALSE,
  MIN_EPV = 5,
  returnData = TRUE,
  return_models = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.isb.splsicox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_penalty.list">penalty.list</code></td>
<td>
<p>Numeric vector. Penalty for variable selection for the individual cox models.
Variables with a lower P-Value than 1- &quot;penalty&quot; in the individual cox analysis will be keep
for the sPLS-ICOX approach (default: seq(0.1,0.9,0.2)).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near) zero
variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation.</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding the
'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet, the
evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.isb.splsicox_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>cv.isb.splsicox</code> function performs cross-validation for the iterative single-block sparse
partial least squares individual Cox analysis. Unlike the single-block (<code>sb</code>) approach, where
each block is analyzed with the same number of components and penalties, the iterative
single-block (<code>isb</code>) approach allows for the specification of different numbers of components and
penalties for each block. This provides a more tailored analysis for each block, recognizing that
different blocks may have varying complexities and relationships with the outcome.
</p>
<p>The function is designed to handle datasets with multiple blocks, processing each block
individually in an iterative manner. This ensures a detailed examination of each block's
contribution to the survival outcome without the interference of other blocks. This approach is
distinct from multiblock methods where all blocks are analyzed simultaneously.
</p>
<p>The cross-validation process involves partitioning the dataset into multiple subsets (folds) and
then iteratively training the model on a subset of the data while validating it on the remaining
data. This helps in determining the optimal hyperparameters for the model, such as the number of
latent components and the penalty for variable selection.
</p>
<p>Unlike the <code>sb</code> approach, which returns the optimal hyperparameters for further model training,
the <code>isb</code> approach directly returns the final model. This model is constructed using the
best-performing hyperparameters for each block, ensuring a more customized and potentially more
accurate model.
</p>
<p>The function offers flexibility in specifying various hyperparameters and options for data
preprocessing. The output provides a comprehensive overview of the cross-validation results,
including metrics like AIC, C-Index, Brier Score, and AUC for each hyper-parameter combination.
Visualization tools are also provided to aid in understanding the model's performance across
different hyperparameters.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;sb.splsicox&quot;. The class contains the following
elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: PLS weights
</p>
</li>
<li> <p><code>(weightings_norm)</code>: PLS normalize weights
</p>
</li>
<li> <p><code>(W.star)</code>: PLS W* vector
</p>
</li>
<li> <p><code>(scores)</code>: PLS scores/variates
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(deviance_residuals)</code>: deviance residual vector used as Y matrix in the sPLS.
</p>
</li>
<li> <p><code>(dr.mean)</code>: mean values for deviance residuals Y matrix
</p>
</li>
<li> <p><code>(dr.sd)</code>: standard deviation for deviance residuals Y matrix'
</p>
</li>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>list_spls_models</code>: List of sPLS-ICOX models computed for each block.
</p>
<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>penalty</code> Penalty applied.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_multiomic")
data("Y_multiomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_multiomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_multiomic
X_train$mirna &lt;- X_train$mirna[index_train,1:20]
X_train$proteomic &lt;- X_train$proteomic[index_train,1:20]
Y_train &lt;- Y_multiomic[index_train,]
isb.splsicox_model &lt;- cv.isb.splsicox(X_train, Y_train, max.ncomp = 1, penalty.list = c(0.5),
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='cv.mb.splsdacox'>MB.sPLS-DACOX Cross-Validation</h2><span id='topic+cv.mb.splsdacox'></span>

<h3>Description</h3>

<p>The cv.mb.splsdacox function performs cross-validation for the MB.sPLS-DACOX model,
a specialized model tailored for survival analysis with high-dimensional data. This function
systematically evaluates the performance of the model across different hyperparameters and
configurations to determine the optimal settings for the given data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.mb.splsdacox(
  X,
  Y,
  max.ncomp = 8,
  vector = NULL,
  MIN_NVAR = 10,
  MAX_NVAR = 10000,
  n.cut_points = 5,
  EVAL_METHOD = "AUC",
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC_INCREASE = 0.01,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  max.iter = 200,
  fast_mode = FALSE,
  MIN_EPV = 5,
  return_models = FALSE,
  returnData = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.mb.splsdacox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_vector">vector</code></td>
<td>
<p>Numeric vector. Used for computing best number of variables. As many values as
components have to be provided. If vector = NULL, an automatic detection is perform (default: NULL). If
vector is a list, must be named as the names of X param followed by the number of variables to select.</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_min_nvar">MIN_NVAR</code></td>
<td>
<p>Numeric. Minimum range size for computing cut points to select the best number of
variables to use (default: 10).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_max_nvar">MAX_NVAR</code></td>
<td>
<p>Numeric. Maximum range size for computing cut points to select the best number of
variables to use (default: 1000).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_n.cut_points">n.cut_points</code></td>
<td>
<p>Numeric. Number of cut points for searching the optimal number of variables.
If only two cut points are selected, minimum and maximum size are used (default: 5).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_eval_method">EVAL_METHOD</code></td>
<td>
<p>Character. If EVAL_METHOD = &quot;AUC&quot;, AUC metric will be use to compute the best
number of variables. In other case, c-index metric will be used (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near) zero
variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation. A non-significant model is a
model with at least one component/variable with a P-Value higher than the alpha cutoff.</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding the
'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet, the
evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_max.iter">max.iter</code></td>
<td>
<p>Numeric. Maximum number of iterations for PLS convergence (default: 200).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdacox_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function operates by partitioning the data into multiple subsets (folds) and
iteratively holding out one subset for validation while training on the remaining subsets. The
cross-validation process is repeated for a specified number of runs, ensuring a robust assessment
of the model's performance. The function offers flexibility in terms of the number of PLS components,
the range of variables considered, and the evaluation metrics used.
</p>
<p>The function provides an option to center and scale the explanatory variables, which can be crucial
for ensuring consistent performance, especially when the variables are measured on different scales.
Additionally, the function incorporates features to handle near-zero and zero variance variables,
which can be problematic in high-dimensional datasets.
</p>
<p>For model evaluation, users can choose between various metrics, including AUC, c-index, and Brier
Score. The function also allows for the specification of weights for these metrics, enabling users
to prioritize certain metrics over others based on the research context.
</p>
<p>The function's design also emphasizes computational efficiency. It offers a parallel processing
option to expedite the cross-validation process, especially beneficial for large datasets. However,
users should be cautious about potential high RAM consumption when using this option.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cv.MB.sPLS-DACOX&quot;.
<code>best_model_info</code>: A data.frame with the information for the best model.
<code>df_results_folds</code>: A data.frame with fold-level information.
<code>df_results_runs</code>: A data.frame with run-level information.
<code>df_results_comps</code>: A data.frame with component-level information (for cv.coxEN, EN.alpha
information).
</p>
<p><code>lst_models</code>: If return_models = TRUE, return a the list of all cross-validated models.
<code>pred.method</code>: AUC evaluation algorithm method for evaluate the model performance.
</p>
<p><code>opt.comp</code>: Optimal component selected by the best_model.
<code>opt.nvar</code>: Optimal number of variables selected by the best_model.
</p>
<p><code>plot_AIC</code>: AIC plot by each hyper-parameter.
<code>plot_c_index</code>: C-Index plot by each hyper-parameter.
<code>plot_BRIER</code>: Brier Score plot by each hyper-parameter.
<code>plot_AUC</code>: AUC plot by each hyper-parameter.
</p>
<p><code>class</code>: Cross-Validated model class.
</p>
<p><code>lst_train_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for train the models.
<code>lst_test_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for test the models.
</p>
<p><code>time</code>: time consumed for running the cross-validated function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("X_multiomic")
data("Y_multiomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_multiomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_multiomic
X_train$mirna &lt;- X_train$mirna[index_train,1:50]
X_train$proteomic &lt;- X_train$proteomic[index_train,1:50]
Y_train &lt;- Y_multiomic[index_train,]
cv.mb.splsdacox_model &lt;- cv.mb.splsdacox(X_train, Y_train, max.ncomp = 2, vector = NULL,
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)

</code></pre>

<hr>
<h2 id='cv.mb.splsdrcox'>MB.sPLS-DRCOX Cross-Validation</h2><span id='topic+cv.mb.splsdrcox'></span>

<h3>Description</h3>

<p>The cv.mb.splsdrcox function performs cross-validation for the MB.sPLS-DRCOX model,
a specialized model for survival analysis with high-dimensional data. This function
systematically evaluates the performance of the model across different hyperparameters and
configurations to determine the optimal settings for the given data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.mb.splsdrcox(
  X,
  Y,
  max.ncomp = 8,
  vector = NULL,
  MIN_NVAR = 10,
  MAX_NVAR = 10000,
  n.cut_points = 5,
  EVAL_METHOD = "AUC",
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC_INCREASE = 0.01,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  max.iter = 200,
  fast_mode = FALSE,
  MIN_EPV = 5,
  return_models = FALSE,
  returnData = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.mb.splsdrcox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_vector">vector</code></td>
<td>
<p>Numeric vector. Used for computing best number of variables. As many values as
components have to be provided. If vector = NULL, an automatic detection is perform (default: NULL). If
vector is a list, must be named as the names of X param followed by the number of variables to select.</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_min_nvar">MIN_NVAR</code></td>
<td>
<p>Numeric. Minimum range size for computing cut points to select the best number of
variables to use (default: 10).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_max_nvar">MAX_NVAR</code></td>
<td>
<p>Numeric. Maximum range size for computing cut points to select the best number of
variables to use (default: 1000).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_n.cut_points">n.cut_points</code></td>
<td>
<p>Numeric. Number of cut points for searching the optimal number of variables.
If only two cut points are selected, minimum and maximum size are used. For MB approaches as many
as n.cut_points^n.blocks models will be computed as minimum (default: 5).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_eval_method">EVAL_METHOD</code></td>
<td>
<p>Character. If EVAL_METHOD = &quot;AUC&quot;, AUC metric will be use to compute the best
number of variables. In other case, c-index metric will be used (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near)
zero variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation. A non-significant model is a
model with at least one component/variable with a P-Value higher than the alpha cutoff.</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding the
'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet, the
evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_max.iter">max.iter</code></td>
<td>
<p>Numeric. Maximum number of iterations for PLS convergence (default: 200).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.mb.splsdrcox_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function operates by partitioning the data into multiple subsets (folds) and
iteratively holding out one subset for validation while training on the remaining subsets. The
cross-validation process is repeated for a specified number of runs, ensuring a robust assessment
of the model's performance. The function offers flexibility in terms of the number of PLS components,
the range of variables considered, and the evaluation metrics used.
</p>
<p>The function provides an option to center and scale the explanatory variables, which can be crucial
for ensuring consistent performance, especially when the variables are measured on different scales.
Additionally, the function incorporates features to handle near-zero and zero variance variables,
which can be problematic in high-dimensional datasets.
</p>
<p>For model evaluation, users can choose between various metrics, including AUC, c-index, and Brier
Score. The function also allows for the specification of weights for these metrics, enabling users
to prioritize certain metrics over others based on the research context.
</p>
<p>The function's design also emphasizes computational efficiency. It offers a parallel processing
option to expedite the cross-validation process, especially beneficial for large datasets. However,
users should be cautious about potential high RAM consumption when using this option.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cv.MB.sPLS-DRCOX&quot;.
<code>best_model_info</code>: A data.frame with the information for the best model.
<code>df_results_folds</code>: A data.frame with fold-level information.
<code>df_results_runs</code>: A data.frame with run-level information.
<code>df_results_comps</code>: A data.frame with component-level information (for cv.coxEN, EN.alpha
information).
</p>
<p><code>lst_models</code>: If return_models = TRUE, return a the list of all cross-validated models.
<code>pred.method</code>: AUC evaluation algorithm method for evaluate the model performance.
</p>
<p><code>opt.comp</code>: Optimal component selected by the best_model.
<code>opt.nvar</code>: Optimal number of variables selected by the best_model.
</p>
<p><code>plot_AIC</code>: AIC plot by each hyper-parameter.
<code>plot_c_index</code>: C-Index plot by each hyper-parameter.
<code>plot_BRIER</code>: Brier Score plot by each hyper-parameter.
<code>plot_AUC</code>: AUC plot by each hyper-parameter.
</p>
<p><code>class</code>: Cross-Validated model class.
</p>
<p><code>lst_train_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for train the models.
<code>lst_test_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for test the models.
</p>
<p><code>time</code>: time consumed for running the cross-validated function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("X_multiomic")
data("Y_multiomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_multiomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_multiomic
X_train$mirna &lt;- X_train$mirna[index_train,1:50]
X_train$proteomic &lt;- X_train$proteomic[index_train,1:50]
Y_train &lt;- Y_multiomic[index_train,]
cv.mb.splsdrcox_model &lt;- cv.mb.splsdrcox(X_train, Y_train, max.ncomp = 2, vector = NULL,
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)

</code></pre>

<hr>
<h2 id='cv.sb.splsdrcox'>SB.sPLS-DRCOX Cross-Validation</h2><span id='topic+cv.sb.splsdrcox'></span>

<h3>Description</h3>

<p>This function performs cross-validated sparse partial least squares single block for splsdrcox.
The function returns the optimal number of components and the optimal sparsity penalty value based
on cross-validation. The performance could be based on multiple metrics as Area Under the Curve
(AUC), Brier Score or C-Index. Furthermore, the user could establish more than one metric
simultaneously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.sb.splsdrcox(
  X,
  Y,
  max.ncomp = 8,
  penalty.list = seq(0.1, 0.9, 0.2),
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC_INCREASE = 0.01,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  fast_mode = FALSE,
  MIN_EPV = 5,
  return_models = FALSE,
  returnData = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.sb.splsdrcox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_penalty.list">penalty.list</code></td>
<td>
<p>Numeric vector. Vector of penalty values. Penalty for sPLS-DRCOX. If
penalty = 0 no penalty is applied, when penalty = 1 maximum penalty (no variables are selected)
based on 'plsRcox' penalty. Equal or greater than 1 cannot be selected (default: seq(0.1,0.9,0.2)).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near) zero
variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation. A non-significant model is a
model with at least one component/variable with a P-Value higher than the alpha cutoff.</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding the
'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet, the
evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsdrcox_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>cv.sb.splsdrcox</code> function performs cross-validation for the single-block sparse partial least
squares deviance residual Cox analysis. Cross-validation is a robust method to evaluate the
performance of a statistical model by partitioning the original sample into a training set to train
the model, and a test set to evaluate it. This helps in selecting the optimal hyperparameters for
the model, such as the number of latent components (<code>max.ncomp</code>) and the penalty for variable
selection (<code>penalty.list</code>).
</p>
<p>The function systematically evaluates different combinations of hyperparameters by performing
multiple runs and folds. For each combination, the dataset is divided into training and test sets
based on the specified number of folds (<code>k_folds</code>). The model is then trained on the training set
and evaluated on the test set. This process is repeated for the specified number of runs (<code>n_run</code>),
ensuring a comprehensive evaluation of the model's performance across different partitions of the
data.
</p>
<p>Various evaluation metrics, such as AIC, C-Index, Brier Score, and AUC, are computed for each
combination of hyperparameters. These metrics provide insights into the model's accuracy,
discriminative ability, and calibration. The function then identifies the optimal hyperparameters
that yield the best performance based on the specified evaluation metrics.
</p>
<p>The function also offers flexibility in data preprocessing, such as centering and scaling of the
explanatory variables, removal of near-zero variance variables, and more. Additionally, users can
specify the AUC evaluation algorithm method (<code>pred.method</code>) and control the verbosity of the
output (<code>verbose</code>).
</p>
<p>The output provides a comprehensive overview of the cross-validation results, including detailed
information at the fold, run, and component levels. Visualization tools, such as plots for AIC,
C-Index, Brier Score, and AUC, are also provided to aid in understanding the model's performance
across different hyperparameters.
</p>
<p>In summary, the <code>cv.sb.splsdrcox</code> function offers a robust approach for hyperparameter tuning and
model evaluation for the single-block sparse partial least squares deviance residual Cox analysis.
It ensures that the final model is both accurate and generalizable to new data.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cv.SB.sPLS-DRCOX&quot;.
<code>best_model_info</code>: A data.frame with the information for the best model.
<code>df_results_folds</code>: A data.frame with fold-level information.
<code>df_results_runs</code>: A data.frame with run-level information.
<code>df_results_comps</code>: A data.frame with component-level information (for cv.coxEN, EN.alpha
information).
</p>
<p><code>lst_models</code>: If return_models = TRUE, return a the list of all cross-validated models.
<code>pred.method</code>: AUC evaluation algorithm method for evaluate the model performance.
</p>
<p><code>opt.comp</code>: Optimal component selected by the best_model.
<code>opt.penalty</code>: Optimal penalty/penalty selected by the best_model.
<code>opt.nvar</code>: Optimal number of variables selected by the best_model.
</p>
<p><code>plot_AIC</code>: AIC plot by each hyper-parameter.
<code>plot_c_index</code>: C-Index plot by each hyper-parameter.
<code>plot_BRIER</code>: Brier Score plot by each hyper-parameter.
<code>plot_AUC</code>: AUC plot by each hyper-parameter.
</p>
<p><code>class</code>: Cross-Validated model class.
</p>
<p><code>lst_train_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for train the models.
<code>lst_test_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for test the models.
</p>
<p><code>time</code>: time consumed for running the cross-validated function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_multiomic")
data("Y_multiomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_multiomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_multiomic
X_train$mirna &lt;- X_train$mirna[index_train,1:50]
X_train$proteomic &lt;- X_train$proteomic[index_train,1:50]
Y_train &lt;- Y_multiomic[index_train,]
cv.sb.splsdrcox_model &lt;- cv.sb.splsdrcox(X_train, Y_train, max.ncomp = 2, penalty.list = c(0.5),
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='cv.sb.splsicox'>Cross validation cv.sb.splsicox</h2><span id='topic+cv.sb.splsicox'></span>

<h3>Description</h3>

<p>This function performs cross-validated sparse partial least squares single block for splsicox.
The function returns the optimal number of components and the optimal sparsity penalty value based
on cross-validation. The performance could be based on multiple metrics as Area Under the Curve
(AUC), Brier Score or C-Index. Furthermore, the user could establish more than one metric
simultaneously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.sb.splsicox(
  X,
  Y,
  max.ncomp = 8,
  penalty.list = seq(0.1, 0.9, 0.2),
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC_INCREASE = 0.01,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  fast_mode = FALSE,
  MIN_EPV = 5,
  return_models = FALSE,
  returnData = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.sb.splsicox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_penalty.list">penalty.list</code></td>
<td>
<p>Numeric vector. Penalty for variable selection for the individual cox
models. Variables with a lower P-Value than 1 - &quot;penalty&quot; in the individual cox analysis will
be keep for the sPLS-ICOX approach (default: seq(0.1,0.9,0.2)).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near) zero
variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation.</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding
the 'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet,
the evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.sb.splsicox_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>cv.sb.splsicox</code> function performs cross-validation for the single-block sparse partial least
squares individual Cox analysis. While the function can handle datasets with multiple blocks, it
processes each block individually, ensuring a detailed examination of each block's contribution to
the survival outcome. This is distinct from multiblock methods where all blocks are analyzed
simultaneously.
</p>
<p>In the context of this function, &quot;single-block&quot; means that each block of data is analyzed
separately, one at a time. This approach is beneficial when different blocks represent distinct
types or sources of data, allowing for a granular understanding of each block's significance
without the interference of other blocks.
</p>
<p>The cross-validation process involves partitioning the dataset into multiple subsets (folds) and
then iteratively training the model on a subset of the data while validating it on the remaining
data. This helps in determining the optimal hyperparameters for the model, such as the number of
latent components and the penalty for variable selection.
</p>
<p>The function offers flexibility in specifying various hyperparameters and options for data
preprocessing. The output provides a comprehensive overview of the cross-validation results,
including metrics like AIC, C-Index, Brier Score, and AUC for each hyper-parameter combination.
Visualization tools are also provided to aid in understanding the model's performance across
different hyperparameters.
</p>
<p>In summary, the <code>cv.sb.splsicox</code> function offers a robust approach for determining the optimal
parameters for the single-block sparse partial least squares individual Cox analysis, ensuring
optimal feature selection, dimensionality reduction, and predictive modeling for each individual
block in the dataset.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cv.SB.sPLS-ICOX&quot;.
<code>best_model_info</code>: A data.frame with the information for the best model.
<code>df_results_folds</code>: A data.frame with fold-level information.
<code>df_results_runs</code>: A data.frame with run-level information.
<code>df_results_comps</code>: A data.frame with component-level information (for cv.coxEN, EN.alpha
information).
</p>
<p><code>lst_models</code>: If return_models = TRUE, return a the list of all cross-validated models.
<code>pred.method</code>: AUC evaluation algorithm method for evaluate the model performance.
</p>
<p><code>opt.comp</code>: Optimal component selected by the best_model.
<code>opt.penalty</code>: Optimal penalty value selected by the best_model.
</p>
<p><code>plot_AIC</code>: AIC plot by each hyper-parameter.
<code>plot_c_index</code>: C-Index plot by each hyper-parameter.
<code>plot_BRIER</code>: Brier Score plot by each hyper-parameter.
<code>plot_AUC</code>: AUC plot by each hyper-parameter.
</p>
<p><code>class</code>: Cross-Validated model class.
</p>
<p><code>lst_train_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for train the models.
<code>lst_test_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for test the models.
</p>
<p><code>time</code>: time consumed for running the cross-validated function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_multiomic")
data("Y_multiomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_multiomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_multiomic
X_train$mirna &lt;- X_train$mirna[index_train,1:50]
X_train$proteomic &lt;- X_train$proteomic[index_train,1:50]
Y_train &lt;- Y_multiomic[index_train,]
cv.sb.splsicox_model &lt;- cv.sb.splsicox(X_train, Y_train, max.ncomp = 2, penalty.list = c(0.5),
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='cv.splsdacox_dynamic'>Cross validation splsdacox_dynamic</h2><span id='topic+cv.splsdacox_dynamic'></span>

<h3>Description</h3>

<p>The cv.splsdacox_dynamic function performs cross-validation for the sPLS-DA-COX-Dynamic model.
This model is designed to handle survival data, where the response variables are time-to-event
and event/censoring indicators. The function offers a comprehensive set of parameters to fine-tune
the cross-validation process, including options for data preprocessing, model evaluation, and
parallel processing.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.splsdacox_dynamic(
  X,
  Y,
  max.ncomp = 8,
  vector = NULL,
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  MIN_NVAR = 10,
  MAX_NVAR = 1000,
  n.cut_points = 5,
  MIN_AUC_INCREASE = 0.01,
  EVAL_METHOD = "AUC",
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  fast_mode = FALSE,
  max.iter = 200,
  MIN_EPV = 5,
  return_models = FALSE,
  returnData = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.splsdacox_dynamic_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and event
observations.</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_vector">vector</code></td>
<td>
<p>Numeric vector. Used for computing best number of variables. As many values as
components have to be provided. If vector = NULL, an automatic detection is perform (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero
variance filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near)
zero variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation.</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_min_nvar">MIN_NVAR</code></td>
<td>
<p>Numeric. Minimum range size for computing cut points to select the best number of
variables to use (default: 10).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_max_nvar">MAX_NVAR</code></td>
<td>
<p>Numeric. Maximum range size for computing cut points to select the best number of
variables to use (default: 1000).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_n.cut_points">n.cut_points</code></td>
<td>
<p>Numeric. Number of cut points for searching the optimal number of variables.
If only two cut points are selected, minimum and maximum size are used. For MB approaches as many
as n.cut_points^n.blocks models will be computed as minimum (default: 5).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_eval_method">EVAL_METHOD</code></td>
<td>
<p>Character. If EVAL_METHOD = &quot;AUC&quot;, AUC metric will be use to compute the best
number of variables. In other case, c-index metric will be used (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding the
'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet, the
evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_max.iter">max.iter</code></td>
<td>
<p>Numeric. Maximum number of iterations for PLS convergence (default: 200).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdacox_dynamic_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function begins by ensuring that the required libraries for evaluation metrics are installed.
It then checks the validity of the input parameters, such as ensuring that the response variables
have the appropriate column names (&quot;time&quot; and &quot;event&quot;) and that the evaluation weights sum to 1.
</p>
<p>Data preprocessing steps include the potential removal of variables with zero or near-zero variance,
and the transformation of explanatory variables to ensure they are centered or scaled as specified.
The function also provides an option to remove variables based on their coefficient of variation.
</p>
<p>The core of the function revolves around the cross-validation process. Data is split into training
and test sets for each run and fold. For each combination of run, fold, and specified number of PLS
components, a sPLS-DA-COX-Dynamic model is trained. The performance of these models is then evaluated
using a combination of metrics, including the Akaike Information Criterion (AIC), C-index, Brier Score,
and Area Under the Curve (AUC). The function provides flexibility in choosing the evaluation metric
and its method.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cv.sPLS-DACOX-Dynamic&quot;.
<code>best_model_info</code>: A data.frame with the information for the best model.
<code>df_results_folds</code>: A data.frame with fold-level information.
<code>df_results_runs</code>: A data.frame with run-level information.
<code>df_results_comps</code>: A data.frame with component-level information (for cv.coxEN, EN.alpha
information).
</p>
<p><code>lst_models</code>: If return_models = TRUE, return a the list of all cross-validated models.
<code>pred.method</code>: AUC evaluation algorithm method for evaluate the model performance.
</p>
<p><code>opt.comp</code>: Optimal component selected by the best_model.
<code>opt.nvar</code>: Optimal number of variables selected by the best_model.
</p>
<p><code>plot_AIC</code>: AIC plot by each hyper-parameter.
<code>plot_c_index</code>: C-Index plot by each hyper-parameter.
<code>plot_BRIER</code>: Brier Score plot by each hyper-parameter.
<code>plot_AUC</code>: AUC plot by each hyper-parameter.
</p>
<p><code>class</code>: Cross-Validated model class.
</p>
<p><code>lst_train_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for train the models.
<code>lst_test_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for test the models.
</p>
<p><code>time</code>: time consumed for running the cross-validated function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
cv.splsdacox_dynamic_model &lt;- cv.splsdacox_dynamic(X_train, Y_train, max.ncomp = 2, vector = NULL,
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='cv.splsdrcox'>sPLS-DRCOX Cross-Validation</h2><span id='topic+cv.splsdrcox'></span>

<h3>Description</h3>

<p>This function performs cross-validated sparse partial least squares DRCox (sPLS-DRCOX).
The function returns the optimal number of components and the optimal sparsity penalty value based
on cross-validation. The performance could be based on multiple metrics as Area Under the Curve
(AUC), Brier Score or C-Index. Furthermore, the user could establish more than one metric
simultaneously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.splsdrcox(
  X,
  Y,
  max.ncomp = 8,
  penalty.list = seq(0.1, 0.9, 0.2),
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC_INCREASE = 0.01,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  fast_mode = FALSE,
  MIN_EPV = 5,
  return_models = FALSE,
  returnData = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.splsdrcox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_penalty.list">penalty.list</code></td>
<td>
<p>Numeric vector. Vector of penalty values. Penalty for sPLS-DRCOX. If
penalty = 0 no penalty is applied, when penalty = 1 maximum penalty (no variables are selected)
based on 'plsRcox' penalty. Equal or greater than 1 cannot be selected (default: seq(0.1,0.9,0.2)).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near) zero
variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation. A non-significant model is a
model with at least one component/variable with a P-Value higher than the alpha cutoff.</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models
to continue evaluating higher values in the multiple tested parameters. If it is not reached for
next 'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding
the 'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet,
the evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code style="white-space: pre;">&#8288;sPLS-DRCOX Cross-Validation&#8288;</code> function offers a robust approach to fine-tune the hyperparameters
of the sPLS-DRCOX model, ensuring optimal performance in survival analysis tasks. By systematically
evaluating different combinations of hyperparameters, this function identifies the best model
configuration that minimizes prediction error.
</p>
<p>Cross-validation is a crucial step in survival analysis, especially when dealing with
high-dimensional datasets. It provides an unbiased assessment of the model's generalization
capability, safeguarding against overfitting. This function employs a k-fold cross-validation
strategy, partitioning the data into multiple subsets (folds) and iteratively using each fold as
a test set while the remaining folds serve as training data.
</p>
<p>One of the primary strengths of this function is its flexibility. Users can specify a range of
values for the number of PLS components and the penalty parameter <code>penalty</code>. The function then
evaluates all possible combinations, returning the optimal configuration that yields the best
predictive performance.
</p>
<p>Additionally, the function offers advanced features like parallel processing for faster computation,
and the ability to return all models from the cross-validation process. This is particularly
useful for in-depth analysis and comparisons.
</p>
<p>The output provides comprehensive insights, including performance metrics for each fold, run, and
hyperparameter combination. Visualization plots like AIC, C-Index, Brier Score, and AUC plots
further aid in understanding the model's performance across different configurations.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cv.sPLS-DRCOX&quot;.
<code>best_model_info</code>: A data.frame with the information for the best model.
<code>df_results_folds</code>: A data.frame with fold-level information.
<code>df_results_runs</code>: A data.frame with run-level information.
<code>df_results_comps</code>: A data.frame with component-level information (for cv.coxEN, EN.alpha
information).
</p>
<p><code>lst_models</code>: If return_models = TRUE, return a the list of all cross-validated models.
<code>pred.method</code>: AUC evaluation algorithm method for evaluate the model performance.
</p>
<p><code>opt.comp</code>: Optimal component selected by the best_model.
<code>opt.penalty</code>: Optimal penalty/penalty selected by the best_model.
<code>opt.nvar</code>: Optimal number of variables selected by the best_model.
</p>
<p><code>plot_AIC</code>: AIC plot by each hyper-parameter.
<code>plot_c_index</code>: C-Index plot by each hyper-parameter.
<code>plot_BRIER</code>: Brier Score plot by each hyper-parameter.
<code>plot_AUC</code>: AUC plot by each hyper-parameter.
</p>
<p><code>class</code>: Cross-Validated model class.
</p>
<p><code>lst_train_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for train the models.
<code>lst_test_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for test the models.
</p>
<p><code>time</code>: time consumed for running the cross-validated function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
cv.splsdrcox_model &lt;- cv.splsdrcox(X_train, Y_train, max.ncomp = 2, penalty.list = c(0.1),
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='cv.splsdrcox_dynamic'>Cross validation sPLS-DRCOX</h2><span id='topic+cv.splsdrcox_dynamic'></span>

<h3>Description</h3>

<p>The function cv.splsdrcox_dynamic conducts a cross-validation for the sPLS-DRCOX model,
which is a specialized model tailored for survival analysis. The function aims to optimize the model's
performance by determining the best number of PLS components and variables through cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.splsdrcox_dynamic(
  X,
  Y,
  max.ncomp = 8,
  vector = NULL,
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  MIN_NVAR = 10,
  MAX_NVAR = 1000,
  n.cut_points = 5,
  MIN_AUC_INCREASE = 0.01,
  EVAL_METHOD = "AUC",
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  fast_mode = FALSE,
  max.iter = 200,
  MIN_EPV = 5,
  return_models = FALSE,
  returnData = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and event
observations.</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_vector">vector</code></td>
<td>
<p>Numeric vector. Used for computing best number of variables. As many values as
components have to be provided. If vector = NULL, an automatic detection is perform (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near) zero
variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation. A non-significant model is a
model with at least one component/variable with a P-Value higher than the alpha cutoff.</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_min_nvar">MIN_NVAR</code></td>
<td>
<p>Numeric. Minimum range size for computing cut points to select the best number of
variables to use (default: 10).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_max_nvar">MAX_NVAR</code></td>
<td>
<p>Numeric. Maximum range size for computing cut points to select the best number of
variables to use (default: 1000).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_n.cut_points">n.cut_points</code></td>
<td>
<p>Numeric. Number of cut points for searching the optimal number of variables.
If only two cut points are selected, minimum and maximum size are used. For MB approaches as many
as n.cut_points^n.blocks models will be computed as minimum (default: 5).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops (default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_eval_method">EVAL_METHOD</code></td>
<td>
<p>Character. If EVAL_METHOD = &quot;AUC&quot;, AUC metric will be use to compute the best
number of variables. In other case, c-index metric will be used (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding the
'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet, the
evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated simultaneously.
If fast_mode = FALSE, for each run, all linear predictors are computed for test observations. Once
all have their linear predictors, the evaluation is perform across all the observations together
(default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_max.iter">max.iter</code></td>
<td>
<p>Numeric. Maximum number of iterations for PLS convergence (default: 200).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsdrcox_dynamic_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The cv.splsdrcox_dynamic function is designed to perform cross-validation for the sPLS-DRCOX model,
a specialized model for survival analysis. The function's primary objective is to identify the
optimal number of PLS components and variables that yield the best model performance.
</p>
<p>The function accepts both numeric matrices and data frames for explanatory (X) and response (Y)
variables. It is essential to ensure that qualitative variables in X are transformed into binary
format. The response variable Y should have two columns: &quot;time&quot; and &quot;event&quot;. The event column
should contain binary values, where 0/1 or FALSE/TRUE represent censored and event observations,
respectively.
</p>
<p>The cross-validation process is controlled by several parameters, including the maximum number of
PLS components (max.ncomp), the number of runs (n_run), and the number of folds (k_folds). The
function also provides options for data preprocessing, such as centering and scaling of the X matrix,
and removal of variables with near-zero or zero variance.
</p>
<p>Significance testing is incorporated into the model evaluation process. Users can specify the alpha
threshold (alpha) for determining significance. Non-significant models or variables can be optionally
removed from the evaluation based on user-defined criteria.
</p>
<p>The function also offers flexibility in model evaluation metrics. Users can choose between different
metrics such as AUC, AIC, C-Index, and Brier Score. The importance of each metric in the evaluation
can be controlled using weights (w_AIC, w_c.index, w_AUC, w_BRIER).
</p>
<p>For computational efficiency, the function provides an option to run the cross-validation in parallel
(PARALLEL). Additionally, verbose logging can be enabled to display extra messages during the execution.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cv.sPLS-DRCOX-Dynamic&quot;.
<code>best_model_info</code>: A data.frame with the information for the best model.
<code>df_results_folds</code>: A data.frame with fold-level information.
<code>df_results_runs</code>: A data.frame with run-level information.
<code>df_results_comps</code>: A data.frame with component-level information (for cv.coxEN, EN.alpha
information).
</p>
<p><code>lst_models</code>: If return_models = TRUE, return a the list of all cross-validated models.
<code>pred.method</code>: AUC evaluation algorithm method for evaluate the model performance.
</p>
<p><code>opt.comp</code>: Optimal component selected by the best_model.
<code>opt.nvar</code>: Optimal number of variables selected by the best_model.
</p>
<p><code>plot_AIC</code>: AIC plot by each hyper-parameter.
<code>plot_c_index</code>: C-Index plot by each hyper-parameter.
<code>plot_BRIER</code>: Brier Score plot by each hyper-parameter.
<code>plot_AUC</code>: AUC plot by each hyper-parameter.
</p>
<p><code>class</code>: Cross-Validated model class.
</p>
<p><code>lst_train_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for train the models.
<code>lst_test_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for test the models.
</p>
<p><code>time</code>: time consumed for running the cross-validated function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:20]
Y_train &lt;- Y_proteomic[index_train,]
cv.splsdrcox_dynamic_model &lt;- cv.splsdrcox_dynamic(X_train, Y_train, max.ncomp = 1, vector = NULL,
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='cv.splsicox'>sPLS-ICOX Cross-Validation</h2><span id='topic+cv.splsicox'></span>

<h3>Description</h3>

<p>This function performs cross-validated sparse partial least squares Cox (sPLS-ICOX).
The function returns the optimal number of components and the optimal sparsity penalty value based
on cross-validation. The performance could be based on multiple metrics as Area Under the Curve
(AUC), Brier Score or C-Index. Furthermore, the user could establish more than one metric
simultaneously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.splsicox(
  X,
  Y,
  max.ncomp = 8,
  penalty.list = seq(0, 0.9, 0.1),
  n_run = 3,
  k_folds = 10,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_variance_at_fold_level = FALSE,
  remove_non_significant_models = FALSE,
  remove_non_significant = FALSE,
  alpha = 0.05,
  w_AIC = 0,
  w_c.index = 0,
  w_AUC = 1,
  w_BRIER = 0,
  times = NULL,
  max_time_points = 15,
  MIN_AUC_INCREASE = 0.05,
  MIN_AUC = 0.8,
  MIN_COMP_TO_CHECK = 3,
  pred.attr = "mean",
  pred.method = "cenROC",
  fast_mode = FALSE,
  MIN_EPV = 5,
  return_models = FALSE,
  returnData = FALSE,
  PARALLEL = FALSE,
  verbose = FALSE,
  seed = 123
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv.splsicox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be transform
into binary variables.</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and event
observations.</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_max.ncomp">max.ncomp</code></td>
<td>
<p>Numeric. Maximum number of PLS components to compute for the cross validation
(default: 8).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_penalty.list">penalty.list</code></td>
<td>
<p>Numeric vector. Penalty for variable selection for the individual cox models.
Variables with a lower P-Value than 1 - &quot;penalty&quot; in the individual cox analysis will be keep
for the sPLS-ICOX approach (default: seq(0.1,0.9,0.2)).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_n_run">n_run</code></td>
<td>
<p>Numeric. Number of runs for cross validation (default: 3).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_k_folds">k_folds</code></td>
<td>
<p>Numeric. Number of folds for cross validation (default: 10).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_remove_variance_at_fold_level">remove_variance_at_fold_level</code></td>
<td>
<p>Logical. If remove_variance_at_fold_level = TRUE, (near) zero
variance will be removed at fold level (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_remove_non_significant_models">remove_non_significant_models</code></td>
<td>
<p>Logical. If remove_non_significant_models = TRUE,
non-significant models are removed before computing the evaluation. A non-significant model is a
model with at least one component/variable with a P-Value higher than the alpha cutoff.</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_w_aic">w_AIC</code></td>
<td>
<p>Numeric. Weight for AIC evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_w_c.index">w_c.index</code></td>
<td>
<p>Numeric. Weight for C-Index evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_w_auc">w_AUC</code></td>
<td>
<p>Numeric. Weight for AUC evaluator. All weights must sum 1 (default: 1).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_w_brier">w_BRIER</code></td>
<td>
<p>Numeric. Weight for BRIER SCORE evaluator. All weights must sum 1 (default: 0).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_min_auc">MIN_AUC</code></td>
<td>
<p>Numeric. Minimum AUC desire to reach cross-validation models. If the minimum is
reached, the evaluation could stop if the improvement does not reach an AUC higher than adding the
'MIN_AUC_INCREASE' value (default: 0.8).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_min_comp_to_check">MIN_COMP_TO_CHECK</code></td>
<td>
<p>Numeric. Number of penalties/components to evaluate to check if the AUC
improves. If for the next 'MIN_COMP_TO_CHECK' the AUC is not better and the 'MIN_AUC' is meet, the
evaluation could stop (default: 3).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_fast_mode">fast_mode</code></td>
<td>
<p>Logical. If fast_mode = TRUE, for each run, only one fold is evaluated
simultaneously. If fast_mode = FALSE, for each run, all linear predictors are computed for test
observations. Once all have their linear predictors, the evaluation is perform across all the
observations together (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_return_models">return_models</code></td>
<td>
<p>Logical. Return all models computed in cross validation (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="cv.splsicox_+3A_seed">seed</code></td>
<td>
<p>Number. Seed value for performing runs/folds divisions (default: 123).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code style="white-space: pre;">&#8288;sPLS-ICOX Cross-Validation&#8288;</code> function offers a systematic approach to determine the optimal
hyperparameters for the sparse partial least squares Cox (sPLS-ICOX) model through cross-validation.
This function aims to identify the best combination of the number of PLS components (<code>max.ncomp</code>)
and the sparsity penalty (<code>penalty.list</code>) by evaluating model performance across multiple
metrics such as Area Under the Curve (AUC), Brier Score, and C-Index.
</p>
<p>Cross-validation is executed through a series of runs (<code>n_run</code>) and folds (<code>k_folds</code>), ensuring a
robust assessment of model performance. The function provides flexibility in defining the
evaluation criteria, allowing users to set weights for different metrics (<code>w_AIC</code>, <code>w_c.index</code>,
<code>w_AUC</code>, <code>w_BRIER</code>) and to specify the desired evaluation method (<code>pred.method</code>).
</p>
<p>An essential feature of this function is its ability to halt the evaluation process based on
predefined conditions. If the improvement in AUC across successive models does not surpass the
<code>MIN_AUC_INCREASE</code> threshold or if the desired AUC (<code>MIN_AUC</code>) is achieved, the evaluation can be
terminated early, optimizing computational efficiency.
</p>
<p>The function also incorporates various data preprocessing options, emphasizing the importance of
data quality in model performance. For instance, near-zero and zero variance variables can be
removed either globally or at the fold level. Additionally, the function can handle multicore
processing (<code>PARALLEL</code> option) to expedite the cross-validation process.
</p>
<p>Upon completion, the function returns a comprehensive output, including detailed information about
the best model, performance metrics at various levels (fold, run, component), and optionally, all
cross-validated models.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;cv.sPLS-ICOX&quot;.
<code>best_model_info</code>: A data.frame with the information for the best model.
<code>df_results_folds</code>: A data.frame with fold-level information.
<code>df_results_runs</code>: A data.frame with run-level information.
<code>df_results_comps</code>: A data.frame with component-level information (for cv.coxEN, EN.alpha
information).
</p>
<p><code>lst_models</code>: If return_models = TRUE, return a the list of all cross-validated models.
<code>pred.method</code>: AUC evaluation algorithm method for evaluate the model performance.
</p>
<p><code>opt.comp</code>: Optimal component selected by the best_model.
<code>opt.penalty</code>: Optimal penalty value selected by the best_model.
</p>
<p><code>plot_AIC</code>: AIC plot by each hyper-parameter.
<code>plot_c_index</code>: C-Index plot by each hyper-parameter.
<code>plot_BRIER</code>: Brier Score plot by each hyper-parameter.
<code>plot_AUC</code>: AUC plot by each hyper-parameter.
</p>
<p><code>class</code>: Cross-Validated model class.
</p>
<p><code>lst_train_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for train the models.
<code>lst_test_indexes</code>: List (of lists) of indexes for the observations used in each run/fold
for test the models.
</p>
<p><code>time</code>: time consumed for running the cross-validated function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
cv.splsicox_model &lt;- cv.splsicox(X_train, Y_train, max.ncomp = 2, penalty.list = c(0.1),
n_run = 1, k_folds = 2, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='deleteNearZeroCoefficientOfVariation'>deleteNearZeroCoefficientOfVariation</h2><span id='topic+deleteNearZeroCoefficientOfVariation'></span>

<h3>Description</h3>

<p>Filters out variables from a dataset that exhibit a coefficient of variation below a
specified threshold, ensuring the retention of variables with meaningful variability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deleteNearZeroCoefficientOfVariation(X, LIMIT = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deleteNearZeroCoefficientOfVariation_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be transform
into binary variables.</p>
</td></tr>
<tr><td><code id="deleteNearZeroCoefficientOfVariation_+3A_limit">LIMIT</code></td>
<td>
<p>Numeric. Cutoff for minimum variation. If coefficient is lesser than the limit, the
variables are removed because not vary enough (default: 0.1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>deleteNearZeroCoefficientOfVariation</code> function is a pivotal tool in data preprocessing,
especially when dealing with high-dimensional datasets. The coefficient of variation (CoV) is a
normalized measure of data dispersion, calculated as the ratio of the standard deviation to the mean.
In many scientific investigations, variables with a low CoV might be considered as offering
limited discriminative information, potentially leading to noise in subsequent statistical analyses.
By setting a threshold through the <code>LIMIT</code> parameter, this function provides a systematic approach
to identify and exclude variables that do not meet the desired variability criteria. The underlying
rationale is that variables with a CoV below the set threshold might not contribute significantly
to the variability of the dataset and could be redundant or even detrimental for certain analyses.
The function returns a modified dataset, a list of deleted variables, and the computed coefficients
of variation for each variable. This comprehensive output ensures that researchers are well-informed
about the preprocessing steps and can make subsequent analytical decisions with confidence.
</p>


<h3>Value</h3>

<p>Return a list of two objects:
<code>X</code>: The new data.frame X filtered.
<code>variablesDeleted</code>: The variables that have been removed by the filter.
<code>coeff_variation</code>: The coefficient variables per each variable tested.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
X &lt;- X_proteomic
filter &lt;- deleteNearZeroCoefficientOfVariation(X, LIMIT = 0.1)
</code></pre>

<hr>
<h2 id='deleteNearZeroCoefficientOfVariation.mb'>deleteNearZeroCoefficientOfVariation.mb</h2><span id='topic+deleteNearZeroCoefficientOfVariation.mb'></span>

<h3>Description</h3>

<p>Filters out variables from a dataset that exhibit a coefficient of variation below a
specified threshold, ensuring the retention of variables with meaningful variability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deleteNearZeroCoefficientOfVariation.mb(X, LIMIT = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deleteNearZeroCoefficientOfVariation.mb_+3A_x">X</code></td>
<td>
<p>List of numeric matrices or data.frames. Explanatory variables. Qualitative variables must
be transform into binary variables.</p>
</td></tr>
<tr><td><code id="deleteNearZeroCoefficientOfVariation.mb_+3A_limit">LIMIT</code></td>
<td>
<p>Numeric. Cutoff for minimum variation. If coefficient is lesser than the limit, the
variables are removed because not vary enough (default: 0.1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>deleteNearZeroCoefficientOfVariation</code> function is a pivotal tool in data preprocessing,
especially when dealing with high-dimensional datasets. The coefficient of variation (CoV) is a
normalized measure of data dispersion, calculated as the ratio of the standard deviation to the mean.
In many scientific investigations, variables with a low CoV might be considered as offering limited
discriminative information, potentially leading to noise in subsequent statistical analyses. By
setting a threshold through the <code>LIMIT</code> parameter, this function provides a systematic approach to
identify and exclude variables that do not meet the desired variability criteria. The underlying
rationale is that variables with a CoV below the set threshold might not contribute significantly
to the variability of the dataset and could be redundant or even detrimental for certain analyses.
The function returns a modified dataset, a list of deleted variables, and the computed coefficients
of variation for each variable. This comprehensive output ensures that researchers are well-informed
about the preprocessing steps and can make subsequent analytical decisions with confidence.
</p>


<h3>Value</h3>

<p>A list of three objects.
<code>X</code>: A list with as many blocks as X input, but with the variables filtered.
<code>variablesDeleted</code>: A list with as many blocks as X input, with the name of the variables that have been removed.
<code>coeff_variation</code>: A list with as many blocks as X input, with the coefficient of variation per variable.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_multiomic")
X &lt;- X_multiomic
filter &lt;- deleteNearZeroCoefficientOfVariation.mb(X, LIMIT = 0.1)

</code></pre>

<hr>
<h2 id='deleteZeroOrNearZeroVariance'>deleteZeroOrNearZeroVariance</h2><span id='topic+deleteZeroOrNearZeroVariance'></span>

<h3>Description</h3>

<p>Provides a robust mechanism to filter out variables from a dataset that exhibit zero
or near-zero variance, thereby enhancing the quality and interpretability of subsequent statistical
analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deleteZeroOrNearZeroVariance(
  X,
  remove_near_zero_variance = FALSE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  freqCut = 95/5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deleteZeroOrNearZeroVariance_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="deleteZeroOrNearZeroVariance_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="deleteZeroOrNearZeroVariance_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="deleteZeroOrNearZeroVariance_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="deleteZeroOrNearZeroVariance_+3A_freqcut">freqCut</code></td>
<td>
<p>Numeric. Cutoff for the ratio of the most common value to the second most common
value (default: 95/5).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>deleteZeroOrNearZeroVariance</code> function is an indispensable tool in the preprocessing
phase of statistical modeling. In many datasets, especially high-dimensional ones, certain variables
might exhibit zero or near-zero variance. Such variables can be problematic as they offer limited
information variance and can potentially distort the results of statistical models, leading to
issues like overfitting. By leveraging the <code>caret::nearZeroVar()</code> function, this tool offers a
rigorous method to identify and exclude these variables. Users are afforded flexibility in their
choices, with options to remove only zero variance variables, near-zero variance variables, or
both. The function also provides the capability to set a frequency cutoff, <code>freqCut</code>, which
determines the threshold for near-zero variance based on the ratio of the most frequent value to
the second most frequent value. For scenarios where certain variables are deemed essential and
should not be removed regardless of their variance, the <code>toKeep.zv</code> parameter allows users to
specify a list of such variables.
</p>


<h3>Value</h3>

<p>Return a list of two objects:
<code>X</code>: The new data.frame X filtered.
<code>variablesDeleted</code>: The variables that have been removed by the filter.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
X &lt;- X_proteomic
filter &lt;- deleteZeroOrNearZeroVariance(X, remove_near_zero_variance = TRUE)
</code></pre>

<hr>
<h2 id='deleteZeroOrNearZeroVariance.mb'>deleteZeroOrNearZeroVariance.mb</h2><span id='topic+deleteZeroOrNearZeroVariance.mb'></span>

<h3>Description</h3>

<p>Provides a robust mechanism to filter out variables from a dataset that exhibit zero
or near-zero variance, thereby enhancing the quality and interpretability of subsequent statistical
analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deleteZeroOrNearZeroVariance.mb(
  X,
  remove_near_zero_variance = FALSE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  freqCut = 95/5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deleteZeroOrNearZeroVariance.mb_+3A_x">X</code></td>
<td>
<p>List of numeric matrices or data.frame. Explanatory variables. Qualitative variables must
be transform into binary variables.</p>
</td></tr>
<tr><td><code id="deleteZeroOrNearZeroVariance.mb_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="deleteZeroOrNearZeroVariance.mb_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="deleteZeroOrNearZeroVariance.mb_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="deleteZeroOrNearZeroVariance.mb_+3A_freqcut">freqCut</code></td>
<td>
<p>Numeric. Cutoff for the ratio of the most common value to the second most common
value (default: 95/5).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>deleteZeroOrNearZeroVariance</code> function is an indispensable tool in the preprocessing
phase of statistical modeling. In many datasets, especially high-dimensional ones, certain variables
might exhibit zero or near-zero variance. Such variables can be problematic as they offer limited
information variance and can potentially distort the results of statistical models, leading to
issues like overfitting. By leveraging the <code>caret::nearZeroVar()</code> function, this tool offers a
rigorous method to identify and exclude these variables. Users are afforded flexibility in their
choices, with options to remove only zero variance variables, near-zero variance variables, or
both. The function also provides the capability to set a frequency cutoff, <code>freqCut</code>, which
determines the threshold for near-zero variance based on the ratio of the most frequent value to
the second most frequent value. For scenarios where certain variables are deemed essential and
should not be removed regardless of their variance, the <code>toKeep.zv</code> parameter allows users to specify
a list of such variables.
</p>


<h3>Value</h3>

<p>A list of two objects.
<code>X</code>: A list with as many blocks as X input, but with the variables filtered.
<code>variablesDeleted</code>: A list with as many blocks as X input, with the name of the variables
that have been removed.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_multiomic")
X &lt;- X_multiomic
filter &lt;- deleteZeroOrNearZeroVariance.mb(X, remove_near_zero_variance = TRUE)
</code></pre>

<hr>
<h2 id='dnorkernel'>Derivative of normal distribution</h2><span id='topic+dnorkernel'></span>

<h3>Description</h3>

<p>Derivative of normal distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dnorkernel(ord, X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dnorkernel_+3A_ord">ord</code></td>
<td>
<p>The order of derivative.</p>
</td></tr>
<tr><td><code id="dnorkernel_+3A_x">X</code></td>
<td>
<p>The numeric data vector.</p>
</td></tr>
</table>

<hr>
<h2 id='eval_Coxmos_model_per_variable'>eval_Coxmos_model_per_variable</h2><span id='topic+eval_Coxmos_model_per_variable'></span>

<h3>Description</h3>

<p>The <code>eval_Coxmos_model_per_variable</code> function offers a granular evaluation of a specific Coxmos
model, focusing on the influence of individual variables or components on the model's predictive
performance. It computes the Area Under the Curve (AUC) for each variable at designated time
points, providing insights into the relative importance of each variable in the model's predictions.
For a visual representation of the results, it is advisable to utilize the <code>plot_evaluation()</code>
function post-evaluation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eval_Coxmos_model_per_variable(
  model,
  X_test,
  Y_test,
  pred.method = "cenROC",
  pred.attr = "mean",
  times = NULL,
  max_time_points = 15,
  PARALLEL = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eval_Coxmos_model_per_variable_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="eval_Coxmos_model_per_variable_+3A_x_test">X_test</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables for test data (raw format).
Qualitative variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="eval_Coxmos_model_per_variable_+3A_y_test">Y_test</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables for test data. Object must have two
columns named as &quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for
censored and event observations.</p>
</td></tr>
<tr><td><code id="eval_Coxmos_model_per_variable_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_model_per_variable_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_model_per_variable_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_model_per_variable_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_model_per_variable_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_model_per_variable_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Upon invocation, the function initiates by verifying the consistency between test times and the
training times of the provided model. Subsequently, linear predictors for each variable are derived
using the <code>predict.Coxmos</code> function. These linear predictors serve as the foundation for the AUC
computation, which is executed for each variable across the specified time points.
</p>
<p>The function employs various evaluation methods, as determined by the <code>pred.method</code> parameter, to
calculate the AUC values. These methods encompass options such as &quot;risksetROC&quot;, &quot;survivalROC&quot;, and
&quot;cenROC&quot;, among others. The results are systematically organized into a structured data frame,
segregating AUC values for each variable at different time points. This structured output not only
facilitates easy interpretation but also sets the stage for subsequent visualization or further analysis.
</p>
<p>It's noteworthy that the function is equipped to handle parallel processing, contingent on the user's
preference, which can expedite the evaluation process, especially when dealing with extensive datasets
or multiple time points.
</p>


<h3>Value</h3>

<p>A list of two objects:
<code>df</code>: A data.frame which the predictions for the specific model split into the full model (LP)
and each component individually. This data.frame is used to plot the information by the
function <code>plot_evaluation()</code>.
<code>lst_AUC</code>: A list of the full model prediction and its components where the user can check
the linear predictors used, the global AUC, the AUC per time point and the predicted time points
selected.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]

X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]

model_icox &lt;- splsicox(X_train, Y_train, n.comp = 2)
eval_Coxmos_model_per_variable(model_icox, X_test, Y_test, pred.method = "cenROC")
</code></pre>

<hr>
<h2 id='eval_Coxmos_models'>eval_Coxmos_models</h2><span id='topic+eval_Coxmos_models'></span>

<h3>Description</h3>

<p>The <code>eval_Coxmos_models</code> function facilitates the comprehensive evaluation of multiple Coxmos
models in a concurrent manner. It is designed to provide a detailed assessment of the models'
performance by calculating the Area Under the Curve (AUC) for each model at specified time points.
The results generated by this function are primed for visualization using the <code>plot_evaluation()</code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eval_Coxmos_models(
  lst_models,
  X_test,
  Y_test,
  pred.method = "cenROC",
  pred.attr = "mean",
  times = NULL,
  PARALLEL = FALSE,
  max_time_points = 15,
  verbose = FALSE,
  progress_bar = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eval_Coxmos_models_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos models. Each object of the list must be named.</p>
</td></tr>
<tr><td><code id="eval_Coxmos_models_+3A_x_test">X_test</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables for test data (raw format).
Qualitative variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="eval_Coxmos_models_+3A_y_test">Y_test</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables for test data. Object must have
two columns named as &quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE
for censored and event observations.</p>
</td></tr>
<tr><td><code id="eval_Coxmos_models_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_models_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_models_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_models_+3A_parallel">PARALLEL</code></td>
<td>
<p>Logical. Run the cross validation with multicore option. As many cores as your
total cores - 1 will be used. It could lead to higher RAM consumption (default: FALSE).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_models_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_models_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
<tr><td><code id="eval_Coxmos_models_+3A_progress_bar">progress_bar</code></td>
<td>
<p>Logical. If progress_bar = TRUE, progress bar is shown (default = TRUE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function begins by validating the names of the models provided in the <code>lst_models</code> list and
ensures that there are at least two events present in the dataset. It then checks for the
availability of the specified evaluation method and ensures that the test times are consistent
with the training times of the models.
</p>
<p>The core of the function revolves around the evaluation of each model. Depending on the user's
preference, the evaluations can be executed in parallel, which can significantly expedite the
process, especially when dealing with a large number of models. The function employs various
evaluation methods, as specified by the <code>pred.method</code> parameter, to compute the AUC values. These
methods include but are not limited to &quot;risksetROC&quot;, &quot;survivalROC&quot;, and &quot;cenROC&quot;.
</p>
<p>Post-evaluation, the function collates the results, including training times, AIC values, c-index,
Brier scores, and AUC values for each time point. The results are then transformed into a
structured data frame, making it conducive for further analysis and visualization. It's worth
noting that potential issues in AUC computation, often arising from sparse samples, are flagged
to the user for further inspection.
</p>


<h3>Value</h3>

<p>A list of four objects.
<code>df</code>: A data.frame which the global predictions for all models. This data.frame is used to
plot the information by the function <code>plot_evaluation()</code>.
<code>lst_AUC</code>: A list of models where the user can check the linear predictors computed, the
global AUC, the AUC per time point and the predicted time points selected.
<code>lst_BRIER</code>: A list of models where the user can check the predicted time points selected,
the Brier Score per time point and the Integrative Brier score (computed by <code>survcomp::sbrier.score2proba</code>).
<code>time</code>: Time used for evaluation process.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Harrell FE, Califf RM, Pryor DB, Lee KL, Rosati RA (1982).
&ldquo;Evaluating the Yield of Medical Tests.&rdquo;
<em>JAMA</em>, <b>247</b>.
<a href="https://doi.org/10.1001/jama.1982.03320430047030">doi:10.1001/jama.1982.03320430047030</a>, <a href="https://jamanetwork.com/journals/jama">https://jamanetwork.com/journals/jama</a>.
MS S, AC C, J Q, B H (2011).
&ldquo;survcomp: an R/Bioconductor package for performance assessment and comparison of survival models.&rdquo;
<em>Bioinformatics</em>, <b>27(22)</b>, 3206-3208.
Heagerty PJ, Lumley T, Pepe MS (2000).
&ldquo;Time-Dependent ROC Curves for Censored Survival Data and a Diagnostic Marker.&rdquo;
<em>Biometrics</em>.
Heagerty PJ, Zheng Y (2005).
&ldquo;Survival Model Predictive Accuracy and ROC Curves.&rdquo;
<em>Biometrics</em>, <b>61</b>, 92-105.
<a href="https://doi.org/10.1111/j.0006-341x.2005.030814.x">doi:10.1111/j.0006-341x.2005.030814.x</a>.
Beyene KM, Ghouch AE (2020).
&ldquo;Smoothed time-dependent receiver operating characteristic curve for right censored survival data.&rdquo;
<em>Statistics in Medicine</em>, <b>39</b>(24), 3373-3396.
ISSN 10970258, <a href="https://pubmed.ncbi.nlm.nih.gov/32687225/">https://pubmed.ncbi.nlm.nih.gov/32687225/</a>.
P√©rez-Fern√°ndez S, Mart√≠nez-Camblor P, Filzmoser P, Corral N (2018).
&ldquo;nsROC: An R package for Non-Standard ROC Curve Analysis.&rdquo;
<em>The R Journal</em>.
<a href="https://doi.org/10.1007/s00180-020-00955-7">doi:10.1007/s00180-020-00955-7</a>.
D√≠az-Coto S, Mart√≠nez-Camblor P, P√©rez-Fern√°ndez S (2020).
&ldquo;smoothROCtime: an R package for time-dependent ROC curve estimation.&rdquo;
<em>Computational Statistics</em>, <b>35</b>(3), 1231-1251.
ISSN 16139658, <a href="https://doi.org/10.1007/s00180-020-00955-7">doi:10.1007/s00180-020-00955-7</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]

X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]

model_icox &lt;- splsicox(X_train, Y_train, n.comp = 2)
model_drcox &lt;- splsdrcox(X_train, Y_train, n.comp = 2)
lst_models &lt;- list("splsicox" = model_icox, "splsdrcox" = model_drcox)
eval_Coxmos_models(lst_models, X_test, Y_test, pred.method = "cenROC")
</code></pre>

<hr>
<h2 id='factorToBinary'>factorToBinary</h2><span id='topic+factorToBinary'></span>

<h3>Description</h3>

<p>Transforms factor variables within a matrix or data frame into binary dummy variables,
facilitating numerical representation for subsequent statistical analyses. The function provides
an option to generate either k or k-1 dummy variables for each factor, contingent on its levels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>factorToBinary(X, all = TRUE, sep = "_")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="factorToBinary_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Only qualitative variables (factor class) will be
transformed into binary variables.</p>
</td></tr>
<tr><td><code id="factorToBinary_+3A_all">all</code></td>
<td>
<p>Logical. If all = TRUE, as many variables as levels will be returned in the new matrix.
Otherwise, k-1 variables will be used where the first level will be use as &quot;default&quot; state
(default: TRUE).</p>
</td></tr>
<tr><td><code id="factorToBinary_+3A_sep">sep</code></td>
<td>
<p>Character. Character symbol to generate new colnames. Ex. If variable name is &quot;sex&quot; and
sep = &quot;_&quot;. Dummy variables will be &quot;sex_male&quot; and &quot;sex_female&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>factorToBinary</code> function addresses a recurrent challenge in data preprocessing: the
conversion of factor variables into a numerical format suitable for a plethora of statistical and
machine learning algorithms. Factors, inherently categorical in nature, often necessitate
transformation into a binary format, commonly referred to as dummy or one-hot encoding. This
function adeptly performs this transformation, iterating over each column of the provided matrix
or data frame. When encountering factor variables, it employs the <code>model.matrix</code> function to
generate the requisite dummy variables. The user's discretion is paramount in determining the
number of dummy variables: either k, equivalent to the number of levels for the factor, or k-1,
where the omitted level serves as a reference or &quot;default&quot; state. This choice is particularly
salient in regression contexts to circumvent multicollinearity issues. The naming convention for
the resultant dummy variables amalgamates the original factor's name with its respective level,
separated by a user-defined character, ensuring clarity and interpretability. Non-factor variables
remain unaltered, preserving the integrity of the original data structure.
</p>


<h3>Value</h3>

<p>A matrix or data.frame with k-1 or k dummy variables for categorical/factor data.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
X &lt;- X_proteomic
X.dummy &lt;- factorToBinary(X, all = FALSE, sep = "_")
X.pls &lt;- factorToBinary(X, all = TRUE, sep = "_")
</code></pre>

<hr>
<h2 id='getAutoKM'>getAutoKM</h2><span id='topic+getAutoKM'></span>

<h3>Description</h3>

<p>Generates a Kaplan-Meier plot for the specified Coxmos model. The plot can be
constructed based on the model's Linear Predictor value, the PLS-COX component, or the original
variable level.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAutoKM(
  type = "LP",
  model,
  comp = 1:2,
  top = 10,
  ori_data = TRUE,
  BREAKTIME = NULL,
  n.breaks = 20,
  only_sig = FALSE,
  alpha = 0.05,
  title = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getAutoKM_+3A_type">type</code></td>
<td>
<p>Character. Kaplan Meier for complete model linear predictor (&quot;LP&quot;), for PLS components
(&quot;COMP&quot;) or for original variables (&quot;VAR&quot;) (default: LP).</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_comp">comp</code></td>
<td>
<p>Numeric vector. Vector of length two. Select which components to plot (default: c(1,2)).</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: 10).</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_ori_data">ori_data</code></td>
<td>
<p>Logical. Compute the Kaplan-Meier plot with the raw-data or the normalize-data to
compute the best cut-point for splitting the data into two groups. Only used when type = &quot;VAR&quot;
(default: TRUE).</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_breaktime">BREAKTIME</code></td>
<td>
<p>Numeric. Size of time to split the data into &quot;total_time / BREAKTIME + 1&quot; points.
If BREAKTIME = NULL, &quot;n.breaks&quot; is used (default: NULL).</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_n.breaks">n.breaks</code></td>
<td>
<p>Numeric. If BREAKTIME is NULL, &quot;n.breaks&quot; is the number of time-break points to
compute (default: 20).</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_only_sig">only_sig</code></td>
<td>
<p>Logical. If &quot;only_sig&quot; = TRUE, then only significant log-rank test variables are
returned (default: FALSE).</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_title">title</code></td>
<td>
<p>Character. Kaplan-Meier plot title (default: NULL).</p>
</td></tr>
<tr><td><code id="getAutoKM_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>getAutoKM</code> function offers a flexible approach to visualize survival analysis
results using the Kaplan-Meier method. Depending on the <code>type</code> parameter, the function can
generate plots based on different aspects of the Coxmos model:
</p>

<ul>
<li><p> &quot;LP&quot;: Uses the Linear Predictor value of the model.
</p>
</li>
<li><p> &quot;COMP&quot;: Utilizes the PLS-COX component.
</p>
</li>
<li><p> &quot;VAR&quot;: Operates at the original variable level.
</p>
</li></ul>

<p>The function provides options to customize the number of components (<code>comp</code>), the number of top
variables (<code>top</code>), and whether to use raw or normalized data (<code>ori_data</code>). Additionally, users can
specify the time intervals (<code>BREAKTIME</code> and <code>n.breaks</code>) for the Kaplan-Meier plot. If significance
testing is desired, the function can filter out non-significant variables based on the log-rank
test (<code>only_sig</code> and <code>alpha</code> parameters).
</p>
<p>It's essential to ensure that the provided <code>model</code> is of the correct class (<code>Coxmos</code>). The function
will return an error message if an incompatible model is supplied.
</p>


<h3>Value</h3>

<p>A list of two elements per each model in the list:
<code>info_logrank_num</code>: A list of two data.frames with the numerical variables categorize as
qualitative and the cutpoint to divide the data into two groups.
<code>LST_PLOTS</code>: A list with the Kaplan-Meier Plots.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Kaplan EL, Kaplan EL, Meier P (1958).
&ldquo;Nonparametric Estimation from Incomplete Observations.&rdquo;
<em>Journal of the American Statistical Association</em>.
<a href="https://doi.org/10.1007/978-1-4612-4380-9_25">doi:10.1007/978-1-4612-4380-9_25</a>, <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25">https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
getAutoKM(type = "LP", model = splsicox.model)
</code></pre>

<hr>
<h2 id='getAutoKM.list'>getAutoKM.list</h2><span id='topic+getAutoKM.list'></span>

<h3>Description</h3>

<p>Run the function &quot;getAutoKM&quot; for a list of models. More information in &quot;?getAutoKM&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getAutoKM.list(
  type = "LP",
  lst_models,
  comp = 1:2,
  top = NULL,
  ori_data = TRUE,
  BREAKTIME = NULL,
  n.breaks = 20,
  only_sig = FALSE,
  alpha = 0.05,
  title = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getAutoKM.list_+3A_type">type</code></td>
<td>
<p>Character. Kaplan Meier for complete model linear predictor (&quot;LP&quot;), for PLS
components (&quot;COMP&quot;) or for original variables (&quot;VAR&quot;) (default: LP).</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos models.</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_comp">comp</code></td>
<td>
<p>Numeric vector. Vector of length two. Select which components to plot (default: c(1,2)).</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: 10).</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_ori_data">ori_data</code></td>
<td>
<p>Logical. Compute the Kaplan-Meier plot with the raw-data or the normalize-data to
compute the best cut-point for splitting the data into two groups. Only used when type = &quot;VAR&quot;
(default: TRUE).</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_breaktime">BREAKTIME</code></td>
<td>
<p>Numeric. Size of time to split the data into &quot;total_time / BREAKTIME + 1&quot; points.
If BREAKTIME = NULL, &quot;n.breaks&quot; is used (default: NULL).</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_n.breaks">n.breaks</code></td>
<td>
<p>Numeric. If BREAKTIME is NULL, &quot;n.breaks&quot; is the number of time-break points to
compute (default: 20).</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_only_sig">only_sig</code></td>
<td>
<p>Logical. If &quot;only_sig&quot; = TRUE, then only significant log-rank test variables are
returned (default: FALSE).</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_title">title</code></td>
<td>
<p>Character. Kaplan-Meier plot title (default: NULL).</p>
</td></tr>
<tr><td><code id="getAutoKM.list_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of two elements per each model in the list:
<code>info_logrank_num</code>: A list of two data.frames with the numerical variables categorize as
qualitative and the cutpoint to divide the data into two groups.
<code>LST_PLOTS</code>: A list with the Kaplan-Meier Plots.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Kaplan EL, Kaplan EL, Meier P (1958).
&ldquo;Nonparametric Estimation from Incomplete Observations.&rdquo;
<em>Journal of the American Statistical Association</em>.
<a href="https://doi.org/10.1007/978-1-4612-4380-9_25">doi:10.1007/978-1-4612-4380-9_25</a>, <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25">https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:20]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:20]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 1, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
splsdrcox.model &lt;- splsdrcox(X_train, Y_train, n.comp = 1, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
lst_models = list("sPLSICOX" = splsicox.model, "sPLSDRCOX" = splsdrcox.model)
getAutoKM.list(type = "LP", lst_models)
</code></pre>

<hr>
<h2 id='getCutoffAutoKM'>getCutoffAutoKM</h2><span id='topic+getCutoffAutoKM'></span>

<h3>Description</h3>

<p>Gets the cutoff value from the results of getAutoKM() functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCutoffAutoKM(result)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getCutoffAutoKM_+3A_result">result</code></td>
<td>
<p>List. Result of getAutoKM() function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A named numeric vector where each element represents the cutoff value.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Kaplan EL, Kaplan EL, Meier P (1958).
&ldquo;Nonparametric Estimation from Incomplete Observations.&rdquo;
<em>Journal of the American Statistical Association</em>.
<a href="https://doi.org/10.1007/978-1-4612-4380-9_25">doi:10.1007/978-1-4612-4380-9_25</a>, <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25">https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
KMresult = getAutoKM(type = "LP", model = splsicox.model)
getCutoffAutoKM(result = KMresult)
</code></pre>

<hr>
<h2 id='getCutoffAutoKM.list'>getCutoffAutoKM.list</h2><span id='topic+getCutoffAutoKM.list'></span>

<h3>Description</h3>

<p>Run the function &quot;getCutoffAutoKM&quot; for a list of models. More information in
&quot;?getCutoffAutoKM&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getCutoffAutoKM.list(lst_results)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getCutoffAutoKM.list_+3A_lst_results">lst_results</code></td>
<td>
<p>List of lists. Result of getAutoKM.list() function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list where each element corresponds to the result of the
<code>getCutoffAutoKM</code> function applied to each model in the input list. The structure and
content of each element will be consistent with the output of the
<code>getCutoffAutoKM</code> function.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Kaplan EL, Kaplan EL, Meier P (1958).
&ldquo;Nonparametric Estimation from Incomplete Observations.&rdquo;
<em>Journal of the American Statistical Association</em>.
<a href="https://doi.org/10.1007/978-1-4612-4380-9_25">doi:10.1007/978-1-4612-4380-9_25</a>, <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25">https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
splsdrcox.model &lt;- splsdrcox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
lst_models = list("sPLSICOX" = splsicox.model, "sPLSDRCOX" = splsdrcox.model)
lst_results = getAutoKM.list(type = "LP", lst_models)
getCutoffAutoKM.list(lst_results)
</code></pre>

<hr>
<h2 id='getEPV'>getEPV</h2><span id='topic+getEPV'></span>

<h3>Description</h3>

<p>Provides a quantitative assessment of the dataset by computing the Events per Variable
(EPV) metric, which gauges the proportionality between observed events and the number of explanatory
variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEPV(X, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getEPV_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="getEPV_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the realm of survival analysis, the balance between observed events and explanatory
variables is paramount. The <code>getEPV</code> function serves as a tool for researchers to ascertain this
balance, which can be pivotal in determining the robustness and interpretability of subsequent
statistical models. By evaluating the ratio of events in the <code>Y</code> matrix to the variables in the <code>X</code>
matrix, the function yields the EPV metric. It is of utmost importance that the <code>Y</code> matrix
encompasses two distinct columns, namely &quot;time&quot; and &quot;event&quot;. The latter, &quot;event&quot;, should strictly
encapsulate binary values, delineating censored (either 0 or FALSE) and event (either 1 or TRUE)
observations. To ensure the integrity of the data and the precision of the computation, the function
is equipped with an error mechanism that activates if the &quot;event&quot; column remains undetected.
</p>


<h3>Value</h3>

<p>Return the EPV value for a specific X (explanatory variables) and Y (time and censored variables) data.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic
Y &lt;- Y_proteomic
getEPV(X,Y)
</code></pre>

<hr>
<h2 id='getEPV.mb'>getEPV.mb</h2><span id='topic+getEPV.mb'></span>

<h3>Description</h3>

<p>Provides a quantitative assessment of the dataset by computing the Events per Variable
(EPV) metric for multi-block data, which gauges the proportionality between observed events and the
number of explanatory variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getEPV.mb(X, Y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getEPV.mb_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be transform
into binary variables.</p>
</td></tr>
<tr><td><code id="getEPV.mb_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and event
observations.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the realm of survival analysis, the balance between observed events and explanatory
variables is paramount. The <code>getEPV</code> function serves as a tool for researchers to ascertain this
balance, which can be pivotal in determining the robustness and interpretability of subsequent
statistical models. By evaluating the ratio of events in the <code>Y</code> matrix to the variables in the <code>X</code>
matrix, the function yields the EPV metric. It is of utmost importance that the <code>Y</code> matrix encompasses
two distinct columns, namely &quot;time&quot; and &quot;event&quot;. The latter, &quot;event&quot;, should strictly encapsulate
binary values, delineating censored (either 0 or FALSE) and event (either 1 or TRUE) observations.
To ensure the integrity of the data and the precision of the computation, the function is equipped
with an error mechanism that activates if the &quot;event&quot; column remains undetected.
</p>


<h3>Value</h3>

<p>Return the EPV value for a specific X (explanatory variables) and Y (time and censored variables) data.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_multiomic")
data("Y_multiomic")
X &lt;- X_multiomic
Y &lt;- Y_multiomic
getEPV.mb(X,Y)
</code></pre>

<hr>
<h2 id='getTestKM'>getTestKM</h2><span id='topic+getTestKM'></span>

<h3>Description</h3>

<p>This function computes and visualizes the Kaplan-Meier survival curve for a given
test dataset, utilizing the cutoff derived from the original model. The function offers
flexibility in terms of the type of Kaplan-Meier estimation, whether it's based on the linear
predictor, PLS components, or original variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTestKM(
  model,
  X_test,
  Y_test,
  cutoff,
  type = "LP",
  ori_data = TRUE,
  BREAKTIME = NULL,
  n.breaks = 20,
  title = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTestKM_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="getTestKM_+3A_x_test">X_test</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables for test data (raw format).
Qualitative variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="getTestKM_+3A_y_test">Y_test</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables for test data. Object must have two
columns named as &quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for
censored and event observations.</p>
</td></tr>
<tr><td><code id="getTestKM_+3A_cutoff">cutoff</code></td>
<td>
<p>Numeric. Cutoff value to split the observations into two groups. Recommended to
compute optimal cutoff value with getAutoKM() function.</p>
</td></tr>
<tr><td><code id="getTestKM_+3A_type">type</code></td>
<td>
<p>Character. Kaplan Meier for complete model linear predictor (&quot;LP&quot;), for PLS components
(&quot;COMP&quot;) or for original variables (&quot;VAR&quot;) (default: LP).</p>
</td></tr>
<tr><td><code id="getTestKM_+3A_ori_data">ori_data</code></td>
<td>
<p>Logical. Compute the Kaplan-Meier plot with the raw-data or the normalize-data to
compute the best cut-point for splitting the data into two groups. Only used when type = &quot;VAR&quot;
(default: TRUE).</p>
</td></tr>
<tr><td><code id="getTestKM_+3A_breaktime">BREAKTIME</code></td>
<td>
<p>Numeric. Size of time to split the data into &quot;total_time / BREAKTIME + 1&quot; points.
If BREAKTIME = NULL, &quot;n.breaks&quot; is used (default: NULL).</p>
</td></tr>
<tr><td><code id="getTestKM_+3A_n.breaks">n.breaks</code></td>
<td>
<p>Numeric. If BREAKTIME is NULL, &quot;n.breaks&quot; is the number of time-break points to
compute (default: 20).</p>
</td></tr>
<tr><td><code id="getTestKM_+3A_title">title</code></td>
<td>
<p>Character. Kaplan-Meier plot title (default: NULL).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>getTestKM</code> function is designed to evaluate the survival probabilities of a test dataset
based on a pre-trained Coxmos model. The function ensures that the test times are consistent with
the training times. Depending on the specified <code>type</code>, the function can compute the Kaplan-Meier
curve using:
</p>

<ul>
<li><p> The complete model's linear predictor (<code>LP</code>).
</p>
</li>
<li><p> The PLS components (<code>COMP</code>).
</p>
</li>
<li><p> The original variables (<code>VAR</code>).
</p>
</li></ul>

<p>For the <code>LP</code> type, the function predicts scores for the <code>X_test</code> and subsequently predicts the
linear predictor using these scores. For the <code>COMP</code> type, the function predicts scores for each
component in the model and computes the Kaplan-Meier curve for each. For the <code>VAR</code> type, the
function computes the Kaplan-Meier curve for each variable in the test dataset.
</p>
<p>The function also provides the flexibility to compute the Kaplan-Meier plot using raw data or
normalized data, which can be useful for determining the optimal cut-point for data segmentation.
The time intervals for the Kaplan-Meier estimation can be defined using either the <code>BREAKTIME</code> or
<code>n.breaks</code> parameters.
</p>
<p>The resulting Kaplan-Meier plot provides a visual representation of the survival probabilities
over time, segmented based on the specified cutoff. This allows for a comprehensive evaluation of
the test dataset's survival characteristics in the context of the original model.
</p>


<h3>Value</h3>

<p>Depending on the specified <code>type</code> parameter, the function returns:
</p>

<ul>
<li> <p><code>LP</code>: A ggplot object visualizing the Kaplan-Meier survival curve based on the linear predictor, segmented by the specified cutoff.
</p>
</li>
<li> <p><code>COMP</code>: A list of ggplot objects, where each plot represents the Kaplan-Meier survival curve for a specific PLS component in the model, segmented by the respective cutoffs.
</p>
</li>
<li> <p><code>VAR</code>: A list of ggplot objects, where each plot visualizes the Kaplan-Meier survival curve for a specific variable in the test dataset, segmented by the respective cutoffs.
</p>
</li></ul>

<p>Each plot provides a visual representation of the survival probabilities over time, allowing for a comprehensive evaluation of the test dataset's survival characteristics in the context of the original model.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Kaplan EL, Kaplan EL, Meier P (1958).
&ldquo;Nonparametric Estimation from Incomplete Observations.&rdquo;
<em>Journal of the American Statistical Association</em>.
<a href="https://doi.org/10.1007/978-1-4612-4380-9_25">doi:10.1007/978-1-4612-4380-9_25</a>, <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25">https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
KMresult = getAutoKM(type = "LP", model = splsicox.model)
cutoff &lt;- getCutoffAutoKM(result = KMresult)
getTestKM(splsicox.model, X_test, Y_test, cutoff)
</code></pre>

<hr>
<h2 id='getTestKM.list'>getTestKM.list</h2><span id='topic+getTestKM.list'></span>

<h3>Description</h3>

<p>Run the function &quot;getTestKM&quot; for a list of models. More information in &quot;?getTestKM&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTestKM.list(
  lst_models,
  X_test,
  Y_test,
  lst_cutoff,
  type = "LP",
  ori_data = TRUE,
  BREAKTIME = NULL,
  n.breaks = 20,
  title = NULL,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="getTestKM.list_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos model</p>
</td></tr>
<tr><td><code id="getTestKM.list_+3A_x_test">X_test</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables for test data (raw format).
Qualitative variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="getTestKM.list_+3A_y_test">Y_test</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables for test data. Object must have
two columns named as &quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE
for censored and event observations.</p>
</td></tr>
<tr><td><code id="getTestKM.list_+3A_lst_cutoff">lst_cutoff</code></td>
<td>
<p>Numeric vector. Cutoff vector to split the observations into two groups for each
model. Recommended to compute optimal cutoff value with getAutoKM() or getAutoKM.list() functions.</p>
</td></tr>
<tr><td><code id="getTestKM.list_+3A_type">type</code></td>
<td>
<p>Character. Kaplan Meier for complete model linear predictor (&quot;LP&quot;), for PLS components
(&quot;COMP&quot;) or for original variables (&quot;VAR&quot;) (default: LP).</p>
</td></tr>
<tr><td><code id="getTestKM.list_+3A_ori_data">ori_data</code></td>
<td>
<p>Logical. Compute the Kaplan-Meier plot with the raw-data or the normalize-data to
compute the best cut-point for splitting the data into two groups. Only used when type = &quot;VAR&quot;
(default: TRUE).</p>
</td></tr>
<tr><td><code id="getTestKM.list_+3A_breaktime">BREAKTIME</code></td>
<td>
<p>Numeric. Size of time to split the data into &quot;total_time / BREAKTIME + 1&quot; points.
If BREAKTIME = NULL, &quot;n.breaks&quot; is used (default: NULL).</p>
</td></tr>
<tr><td><code id="getTestKM.list_+3A_n.breaks">n.breaks</code></td>
<td>
<p>Numeric. If BREAKTIME is NULL, &quot;n.breaks&quot; is the number of time-break points to
compute (default: 20).</p>
</td></tr>
<tr><td><code id="getTestKM.list_+3A_title">title</code></td>
<td>
<p>Character. Kaplan-Meier plot title (default: NULL).</p>
</td></tr>
<tr><td><code id="getTestKM.list_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list where each element corresponds to a Kaplan-Meier plot generated for each model in
the input list. Each plot visualizes the survival probabilities based on the specified cutoff
values for the respective model. The list's names correspond to the names of the models provided
in the input list.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Kaplan EL, Kaplan EL, Meier P (1958).
&ldquo;Nonparametric Estimation from Incomplete Observations.&rdquo;
<em>Journal of the American Statistical Association</em>.
<a href="https://doi.org/10.1007/978-1-4612-4380-9_25">doi:10.1007/978-1-4612-4380-9_25</a>, <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25">https://link.springer.com/chapter/10.1007/978-1-4612-4380-9_25</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X_proteomic &lt;- X_proteomic[1:50,]
Y_proteomic &lt;- Y_proteomic[1:50,]
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:20]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:20]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 1, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
splsdrcox.model &lt;- splsdrcox(X_train, Y_train, n.comp = 1, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
lst_models = list("sPLSICOX" = splsicox.model, "sPLSDRCOX" = splsdrcox.model)
lst_results = getAutoKM.list(type = "LP", lst_models)
lst_cutoff &lt;- getCutoffAutoKM.list(lst_results)
getTestKM.list(lst_models, X_test, Y_test, lst_cutoff)
</code></pre>

<hr>
<h2 id='integ'>Numerical Integral function using Simpson's rule</h2><span id='topic+integ'></span>

<h3>Description</h3>

<p>Numerical Integral function using Simpson's rule
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integ(x, fx, method, n.pts = 256)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integ_+3A_x">x</code></td>
<td>
<p>The numeric data vector.</p>
</td></tr>
<tr><td><code id="integ_+3A_fx">fx</code></td>
<td>
<p>The function.</p>
</td></tr>
<tr><td><code id="integ_+3A_method">method</code></td>
<td>
<p>The character string specifying method of numerical integration. The possible options are <code>trap</code> for trapezoidal rule and <code>simps</code> for simpson'r rule.</p>
</td></tr>
<tr><td><code id="integ_+3A_n.pts">n.pts</code></td>
<td>
<p>Number of points.</p>
</td></tr>
</table>

<hr>
<h2 id='ker_dis_i'>Distribution function without the ith observation</h2><span id='topic+ker_dis_i'></span>

<h3>Description</h3>

<p>Distribution function without the ith observation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ker_dis_i(X, y, wt, ktype, bw)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ker_dis_i_+3A_x">X</code></td>
<td>
<p>The numeric data vector.</p>
</td></tr>
<tr><td><code id="ker_dis_i_+3A_y">y</code></td>
<td>
<p>The vector where the kernel estimation is computed.</p>
</td></tr>
<tr><td><code id="ker_dis_i_+3A_wt">wt</code></td>
<td>
<p>The non-negative weight vector.</p>
</td></tr>
<tr><td><code id="ker_dis_i_+3A_ktype">ktype</code></td>
<td>
<p>A character string giving the type kernel to be used: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;.</p>
</td></tr>
<tr><td><code id="ker_dis_i_+3A_bw">bw</code></td>
<td>
<p>A numeric bandwidth value.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the estimated value for the bandwith parameter.
</p>


<h3>Author(s)</h3>

<p>Kassu Mehari Beyene  and Anouar El Ghouch
</p>

<hr>
<h2 id='kfunc'>Function to evaluate the matrix of data vector minus the grid points divided by the bandwidth value.</h2><span id='topic+kfunc'></span>

<h3>Description</h3>

<p>Function to evaluate the matrix of data vector minus the grid points divided by the bandwidth value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfunc(ktype = "normal", difmat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kfunc_+3A_ktype">ktype</code></td>
<td>
<p>A character string giving the type kernel to be used: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;. By default, the &quot;<code>normal</code>&quot; kernel is used.</p>
</td></tr>
<tr><td><code id="kfunc_+3A_difmat">difmat</code></td>
<td>
<p>A numeric matrix of sample data (X) minus evaluation points (x0) divided by bandwidth value (bw).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the matrix resulting from evaluating <code>difmat</code>.
</p>

<hr>
<h2 id='kfunction'>Kernel distribution function</h2><span id='topic+kfunction'></span>

<h3>Description</h3>

<p>Kernel distribution function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kfunction(ktype, X)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kfunction_+3A_ktype">ktype</code></td>
<td>
<p>A character string giving the type kernel to be used: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;.</p>
</td></tr>
<tr><td><code id="kfunction_+3A_x">X</code></td>
<td>
<p>A numeric vector of sample data.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector resulting from evaluating X.
</p>

<hr>
<h2 id='loadingplot.Coxmos'>loadingplot.Coxmos</h2><span id='topic+loadingplot.Coxmos'></span>

<h3>Description</h3>

<p>The <code>loadingplot.Coxmos</code> function visualizes the loading values of a given Coxmos model. The
function produces a series of bar plots for each component's loading values, offering a
comprehensive view of the model's variable contributions. The plots can be customized to exclude
zero loadings, display only the top variables, and automatically adjust the color scale limits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadingplot.Coxmos(model, zero.rm = TRUE, top = NULL, auto.limits = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadingplot.Coxmos_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="loadingplot.Coxmos_+3A_zero.rm">zero.rm</code></td>
<td>
<p>Logical. Remove variables equal to 0 (default: TRUE).</p>
</td></tr>
<tr><td><code id="loadingplot.Coxmos_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="loadingplot.Coxmos_+3A_auto.limits">auto.limits</code></td>
<td>
<p>Logical. If &quot;auto.limits&quot; = TRUE, limits are detected automatically (default: TRUE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The primary objective of the <code>loadingplot.Coxmos</code> function is to facilitate the interpretation of
Coxmos models by visualizing the loading values of each component. The function first verifies the
class of the provided model to ensure it is a valid Coxmos model.
</p>
<p>The loading values are extracted from the model and processed based on the user's specifications.
If the <code>zero.rm</code> parameter is set to TRUE, variables with zero loadings are excluded from the
visualization. Additionally, if the <code>top</code> parameter is specified, only the top variables, ranked
by their absolute loading values, are displayed.
</p>
<p>The function employs the 'ggplot2' framework for visualization. The color scale of the plots can be
automatically adjusted based on the maximum absolute loading value when <code>auto.limits</code> is set to
TRUE. If the <code>RColorConesa</code> package is available, it utilizes its color palettes for enhanced
visualization; otherwise, default colors are applied.
</p>


<h3>Value</h3>

<p>A list of <code>ggplot2</code> objects, each representing the loading values for a component of
the Coxmos model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
loadingplot.Coxmos(model = splsicox.model)
</code></pre>

<hr>
<h2 id='loadingplot.fromVector.Coxmos'>loadingplot.fromVector.Coxmos</h2><span id='topic+loadingplot.fromVector.Coxmos'></span>

<h3>Description</h3>

<p>loadingplot.fromVector.Coxmos
</p>


<h3>Usage</h3>

<pre><code class='language-R'>loadingplot.fromVector.Coxmos(
  model,
  vector,
  zero.rm = FALSE,
  top = NULL,
  auto.limits = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="loadingplot.fromVector.Coxmos_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="loadingplot.fromVector.Coxmos_+3A_vector">vector</code></td>
<td>
<p>Vector of loading</p>
</td></tr>
<tr><td><code id="loadingplot.fromVector.Coxmos_+3A_zero.rm">zero.rm</code></td>
<td>
<p>Logical. Remove variables equal to 0 (default: FALSE).</p>
</td></tr>
<tr><td><code id="loadingplot.fromVector.Coxmos_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="loadingplot.fromVector.Coxmos_+3A_auto.limits">auto.limits</code></td>
<td>
<p>Logical. If &quot;auto.limits&quot; = TRUE, limits are detected automatically (default: TRUE).</p>
</td></tr>
</table>

<hr>
<h2 id='mb.splsdacox'>MB.sPLS-DACOX</h2><span id='topic+mb.splsdacox'></span>

<h3>Description</h3>

<p>The MB.sPLS-DACOX function conducts a multi-block sparse partial least squares discriminant
analysis Cox (MB.sPLS-DACOX) using a dynamic variable selection approach. This analysis is
particularly suited for high-dimensional datasets where the goal is to identify the relationship
between explanatory variables and survival outcomes. The function outputs a model of class
&quot;Coxmos&quot; with an attribute labeled &quot;MB.sPLS-DACOX&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mb.splsdacox(
  X,
  Y,
  n.comp = 4,
  vector = NULL,
  MIN_NVAR = 10,
  MAX_NVAR = 10000,
  n.cut_points = 5,
  EVAL_METHOD = "AUC",
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_non_significant = TRUE,
  alpha = 0.05,
  MIN_AUC_INCREASE = 0.01,
  pred.method = "cenROC",
  max.iter = 200,
  times = NULL,
  max_time_points = 15,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mb.splsdacox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and event
observations.</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_n.comp">n.comp</code></td>
<td>
<p>Numeric. Number of latent components to compute for the (s)PLS model (default: 10).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_vector">vector</code></td>
<td>
<p>Numeric vector or list. Used for computing best number of variables. As many values as
components have to be provided. If vector = NULL, an automatic detection is perform (default: NULL). If
vector is a list, must be named as the names of X param followed by the number of variables to select.</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_min_nvar">MIN_NVAR</code></td>
<td>
<p>Numeric. Minimum range size for computing cut points to select the best number of
variables to use (default: 10).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_max_nvar">MAX_NVAR</code></td>
<td>
<p>Numeric. Maximum range size for computing cut points to select the best number of
variables to use (default: 1000).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_n.cut_points">n.cut_points</code></td>
<td>
<p>Numeric. Number of cut points for searching the optimal number of variables.
If only two cut points are selected, minimum and maximum size are used. For MB approaches as many
as n.cut_points^n.blocks models will be computed as minimum (default: 5).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_eval_method">EVAL_METHOD</code></td>
<td>
<p>Character. If EVAL_METHOD = &quot;AUC&quot;, AUC metric will be use to compute the best
number of variables. In other case, c-index metric will be used (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_max.iter">max.iter</code></td>
<td>
<p>Numeric. Maximum number of iterations for PLS convergence (default: 200).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="mb.splsdacox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MB.sPLS-DACOX methodology is designed to handle multi-block datasets, where each block
represents a set of related variables. By employing a sparse partial least squares approach, the
function efficiently selects relevant variables from each block, ensuring that the final model is
both interpretable and predictive. The Cox proportional hazards model is then applied to the
selected variables to assess their association with survival outcomes.
</p>
<p>The function offers flexibility in terms of parameter tuning. For instance, users can specify the
number of latent components to compute, the range of variables to consider for optimal selection,
and the evaluation metric (either AUC or c-index). Additionally, data preprocessing options are
available, such as centering and scaling of the explanatory variables, and removal of variables
with near-zero or zero variance.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;MB.sPLS-DACOX&quot;. The class contains the following
elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: PLS weights
</p>
</li>
<li> <p><code>(weightings_norm)</code>: PLS normalize weights
</p>
</li>
<li> <p><code>(W.star)</code>: PLS W* vector
</p>
</li>
<li> <p><code>(scores)</code>: PLS scores/variates
</p>
</li>
<li> <p><code>(E)</code>: error matrices
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(deviance_residuals)</code>: deviance residual vector used as Y matrix in the sPLS.
</p>
</li>
<li> <p><code>(dr.mean)</code>: mean values for deviance residuals Y matrix
</p>
</li>
<li> <p><code>(dr.sd)</code>: standard deviation for deviance residuals Y matrix'
</p>
</li>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>mb.model</code>: List of sPLS models computed for each block.
</p>
<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>n.varX</code>: Number of variables selected for each block.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>B.hat</code>: PLS beta matrix
</p>
<p><code>R2</code>: PLS R2
</p>
<p><code>SCR</code>: PLS SCR
</p>
<p><code>SCT</code>: PLS SCT
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Rohart F, Gautier B, Singh A, Cao KAL (2017).
&ldquo;mixOmics: An R package for ‚Äòomics feature selection and multiple data integration.&rdquo;
<em>PLoS Computational Biology</em>, <b>13</b>(11).
ISSN 15537358, <a href="https://pubmed.ncbi.nlm.nih.gov/29099853/">https://pubmed.ncbi.nlm.nih.gov/29099853/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("X_multiomic")
data("Y_multiomic")
X &lt;- X_multiomic
X$mirna &lt;- X$mirna[,1:50]
X$proteomic &lt;- X$proteomic[,1:50]
Y &lt;- Y_multiomic
mb.splsdacox(X, Y, n.comp = 2, vector = NULL, x.center = TRUE, x.scale = TRUE)

</code></pre>

<hr>
<h2 id='mb.splsdrcox'>MB.sPLS-DRCOX</h2><span id='topic+mb.splsdrcox'></span>

<h3>Description</h3>

<p>The MB.sPLS-DRCOX function conducts a multi-block sparse partial least squares deviant residuals
Cox (MB.sPLS-DRCOX) using a dynamic variable selection approach. This analysis is particularly
suited for high-dimensional datasets where the goal is to identify the relationship between
explanatory variables and survival outcomes. The function outputs a model of class &quot;Coxmos&quot; with
an attribute labeled &quot;MB.sPLS-DRCOX&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mb.splsdrcox(
  X,
  Y,
  n.comp = 4,
  vector = NULL,
  MIN_NVAR = 10,
  MAX_NVAR = 10000,
  n.cut_points = 5,
  EVAL_METHOD = "AUC",
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_non_significant = TRUE,
  alpha = 0.05,
  MIN_AUC_INCREASE = 0.01,
  pred.method = "cenROC",
  max.iter = 200,
  times = NULL,
  max_time_points = 15,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mb.splsdrcox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_n.comp">n.comp</code></td>
<td>
<p>Numeric. Number of latent components to compute for the (s)PLS model (default: 10).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_vector">vector</code></td>
<td>
<p>Numeric vector. Used for computing best number of variables. As many values as
components have to be provided. If vector = NULL, an automatic detection is perform (default: NULL). If
vector is a list, must be named as the names of X param followed by the number of variables to select.</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_min_nvar">MIN_NVAR</code></td>
<td>
<p>Numeric. Minimum range size for computing cut points to select the best number of
variables to use (default: 10).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_max_nvar">MAX_NVAR</code></td>
<td>
<p>Numeric. Maximum range size for computing cut points to select the best number of
variables to use (default: 1000).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_n.cut_points">n.cut_points</code></td>
<td>
<p>Numeric. Number of cut points for searching the optimal number of variables.
If only two cut points are selected, minimum and maximum size are used. For MB approaches as many
as n.cut_points^n.blocks models will be computed as minimum (default: 5).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_eval_method">EVAL_METHOD</code></td>
<td>
<p>Character. If EVAL_METHOD = &quot;AUC&quot;, AUC metric will be use to compute the best
number of variables. In other case, c-index metric will be used (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_max.iter">max.iter</code></td>
<td>
<p>Numeric. Maximum number of iterations for PLS convergence (default: 200).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="mb.splsdrcox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The MB.sPLS-DRCOX methodology is designed to handle multi-block datasets, where each block
represents a set of related variables. By employing a sparse partial least squares approach,
the function efficiently selects relevant variables from each block, ensuring that the final
model is both interpretable and predictive. The Cox proportional hazards model is then applied to
the selected variables to assess their association with survival outcomes.
</p>
<p>The function offers flexibility in terms of parameter tuning. For instance, users can specify the
number of latent components to compute, the range of variables to consider for optimal selection,
and the evaluation metric (either AUC or c-index). Additionally, data preprocessing options are
available, such as centering and scaling of the explanatory variables, and removal of variables
with near-zero or zero variance.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;MB.sPLS-DRCOX&quot;. The class contains the following
elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: PLS weights
</p>
</li>
<li> <p><code>(weightings_norm)</code>: PLS normalize weights
</p>
</li>
<li> <p><code>(W.star)</code>: PLS W* vector
</p>
</li>
<li> <p><code>(scores)</code>: PLS scores/variates
</p>
</li>
<li> <p><code>(E)</code>: error matrices
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(deviance_residuals)</code>: deviance residual vector used as Y matrix in the sPLS.
</p>
</li>
<li> <p><code>(dr.mean)</code>: mean values for deviance residuals Y matrix
</p>
</li>
<li> <p><code>(dr.sd)</code>: standard deviation for deviance residuals Y matrix'
</p>
</li>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>mb.model</code>: List of sPLS models computed for each block.
</p>
<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>n.varX</code>: Number of variables selected for each block.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>B.hat</code>: PLS beta matrix
</p>
<p><code>R2</code>: PLS R2
</p>
<p><code>SCR</code>: PLS SCR
</p>
<p><code>SCT</code>: PLS SCT
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Rohart F, Gautier B, Singh A, Cao KAL (2017).
&ldquo;mixOmics: An R package for ‚Äòomics feature selection and multiple data integration.&rdquo;
<em>PLoS Computational Biology</em>, <b>13</b>(11).
ISSN 15537358, <a href="https://pubmed.ncbi.nlm.nih.gov/29099853/">https://pubmed.ncbi.nlm.nih.gov/29099853/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data("X_multiomic")
data("Y_multiomic")
X &lt;- X_multiomic
X$mirna &lt;- X$mirna[,1:50]
X$proteomic &lt;- X$proteomic[,1:50]
Y &lt;- Y_multiomic
mb.splsdrcox(X, Y, n.comp = 2, vector = NULL, x.center = TRUE, x.scale = TRUE)

</code></pre>

<hr>
<h2 id='muro'>The value of squared integral x^2 k(x) dx and integral x k(x) K(x) dx</h2><span id='topic+muro'></span>

<h3>Description</h3>

<p>The value of squared integral x^2 k(x) dx and integral x k(x) K(x) dx
</p>


<h3>Usage</h3>

<pre><code class='language-R'>muro(ktype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="muro_+3A_ktype">ktype</code></td>
<td>
<p>A character string giving the type kernel to be used: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;.</p>
</td></tr>
</table>

<hr>
<h2 id='norm01'>norm01</h2><span id='topic+norm01'></span>

<h3>Description</h3>

<p>Normalize all values into 0-1 range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm01(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="norm01_+3A_x">x</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Only qualitative variables will be
transformed into binary variables.</p>
</td></tr>
</table>

<hr>
<h2 id='NR'>The normal reference bandwidth selection for weighted data</h2><span id='topic+NR'></span>

<h3>Description</h3>

<p>This function computes the data-driven bandwidth for smoothing the ROC (or distribution) function using the NR method of Beyene and El Ghouch (2020). This is an extension of the classical (unweighted) normal reference bandwith selection method to the case of weighted data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>NR(X, wt, ktype = "normal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="NR_+3A_x">X</code></td>
<td>
<p>The numeric data vector.</p>
</td></tr>
<tr><td><code id="NR_+3A_wt">wt</code></td>
<td>
<p>The non-negative weight vector.</p>
</td></tr>
<tr><td><code id="NR_+3A_ktype">ktype</code></td>
<td>
<p>A character string giving the type kernel to be used: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;. By default, the &quot;<code>normal</code>&quot; kernel is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Beyene and El Ghouch (2020) for details.
</p>


<h3>Value</h3>

<p>Returns the computed value for the bandwith parameter.
</p>


<h3>Author(s)</h3>

<p>Kassu Mehari Beyene, Catholic University of Louvain. <code>&lt;kasu.beyene@uclouvain.be&gt;</code>
</p>
<p>Anouar El Ghouch, Catholic University of Louvain. <code>&lt;anouar.elghouch@uclouvain.be&gt;</code>
</p>


<h3>References</h3>

<p>Beyene, K. M. and El Ghouch A. (2020). Smoothed time-dependent ROC curves for right-censored survival data. <em>submitted</em>.
</p>

<hr>
<h2 id='PI'>The plug-in bandwidth selection for weighted data</h2><span id='topic+PI'></span>

<h3>Description</h3>

<p>This function computes the data-driven bandwidth for smoothing the ROC (or distribution) function using the PI method of Beyene and El Ghouch (2020). This is an extension of the classical (unweighted) direct plug-in bandwith selection method to the case of weighted data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PI(X, wt, ktype = "normal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PI_+3A_x">X</code></td>
<td>
<p>The numeric vector of random variable.</p>
</td></tr>
<tr><td><code id="PI_+3A_wt">wt</code></td>
<td>
<p>The non-negative weight vector.</p>
</td></tr>
<tr><td><code id="PI_+3A_ktype">ktype</code></td>
<td>
<p>A character string giving the type kernel to be used: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;. By default, the &quot;<code>normal</code>&quot; kernel is used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Beyene and El Ghouch (2020) for details.
</p>


<h3>Value</h3>

<p>Returns the computed value for the bandwith parameter.
</p>


<h3>Author(s)</h3>

<p>Kassu Mehari Beyene, Catholic University of Louvain. <code>&lt;kasu.beyene@uclouvain.be&gt;</code>
</p>
<p>Anouar El Ghouch, Catholic University of Louvain. <code>&lt;anouar.elghouch@uclouvain.be&gt;</code>
</p>


<h3>References</h3>

<p>Beyene, K. M. and El Ghouch A. (2020). Smoothed time-dependent ROC curves for right-censored survival data. <em>submitted</em>.
</p>

<hr>
<h2 id='plot_cox.event'>plot_cox.event</h2><span id='topic+plot_cox.event'></span>

<h3>Description</h3>

<p>Visualizes the distribution of events based on a Coxmos model's predictions. The function provides
both density and histogram plots to elucidate the event distribution, which can be instrumental in
understanding the model's behavior across different prediction types.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_cox.event(model, type = "lp", n.breaks = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_cox.event_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_cox.event_+3A_type">type</code></td>
<td>
<p>Character. Prediction type: &quot;lp&quot;, &quot;risk&quot;, &quot;expected&quot; or &quot;survival&quot; (default: &quot;lp&quot;).</p>
</td></tr>
<tr><td><code id="plot_cox.event_+3A_n.breaks">n.breaks</code></td>
<td>
<p>Numeric. If BREAKTIME is NULL, &quot;n.breaks&quot; is the number of time-break points to
compute (default: 20).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function takes in a Coxmos model and, based on the specified prediction type (<code>lp</code>, <code>risk</code>,
<code>expected</code>, or <code>survival</code>), computes the respective predictions. The <code>lp</code> (linear predictor) is the
default prediction type. The density and histogram plots are then generated to represent the
distribution of events (censored or occurred) concerning these predictions.
</p>
<p>The density plot provides a smoothed representation of the event distribution, with separate curves
for censored and occurred events. This visualization can be particularly useful to discern the
overall distribution and overlap between the two event types.
</p>
<p>The histogram, on the other hand, offers a binned representation of the event distribution. Each
bin's height represents the count of observations falling within that prediction range, stacked by
event type. This visualization provides a more granular view of the event distribution across
different prediction values.
</p>
<p>It's imperative to note that the models should be run with the <code>returnData = TRUE</code> option to ensure
the necessary data is available for plotting.
</p>


<h3>Value</h3>

<p>A list containing three elements:
<code>df</code>: A data.frame with the computed predictions based on the specified type and the
corresponding event status.
<code>plot.density</code>: A ggplot object representing the density plot of the event distribution,
with separate curves for censored and occurred events.
<code>plot.histogram</code>: A ggplot object representing the histogram of the event distribution,
with bins stacked by event type.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
plot_cox.event(splsicox.model)
</code></pre>

<hr>
<h2 id='plot_cox.event.list'>plot_cox.event.list</h2><span id='topic+plot_cox.event.list'></span>

<h3>Description</h3>

<p>Run the function &quot;plot_cox.event&quot; for a list of models. More information in
&quot;?plot_cox.event&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_cox.event.list(lst_models, type = "lp", n.breaks = 20)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_cox.event.list_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos models.</p>
</td></tr>
<tr><td><code id="plot_cox.event.list_+3A_type">type</code></td>
<td>
<p>Character. Prediction type: &quot;lp&quot;, &quot;risk&quot;, &quot;expected&quot; or &quot;survival&quot; (default: &quot;lp&quot;).</p>
</td></tr>
<tr><td><code id="plot_cox.event.list_+3A_n.breaks">n.breaks</code></td>
<td>
<p>Numeric. Number of time-break points to compute (default: 20).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing three elements per each model:
<code>df</code>: A data.frame with the computed predictions based on the specified type and the
corresponding event status.
<code>plot.density</code>: A ggplot object representing the density plot of the event distribution,
with separate curves for censored and occurred events.
<code>plot.histogram</code>: A ggplot object representing the histogram of the event distribution,
with bins stacked by event type.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
splsdrcox.model &lt;- splsdrcox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
lst_models = list("sPLSICOX" = splsicox.model, "sPLSDRCOX" = splsdrcox.model)
plot_cox.event.list(lst_models)
</code></pre>

<hr>
<h2 id='plot_Coxmos.MB.PLS.model'>plot_Coxmos.MB.PLS.model</h2><span id='topic+plot_Coxmos.MB.PLS.model'></span>

<h3>Description</h3>

<p>Visualizes the Coxmos model using multiblock partial least squares (MB-PLS) approach. This
function offers various plotting modes, including scores, loadings, and biplot visualizations, to
provide insights into the model's structure and relationships.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_Coxmos.MB.PLS.model(
  model,
  comp = c(1, 2),
  mode = "scores",
  factor = NULL,
  legend_title = NULL,
  top = NULL,
  only_top = FALSE,
  radius = NULL,
  names = TRUE,
  colorReverse = FALSE,
  text.size = 2,
  overlaps = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_comp">comp</code></td>
<td>
<p>Numeric vector. Vector of length two. Select which components to plot (default: c(1,2)).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_mode">mode</code></td>
<td>
<p>Character. Choose one of the following plots: &quot;scores&quot;, &quot;loadings&quot; o &quot;biplot&quot;
(default: &quot;scores&quot;).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_factor">factor</code></td>
<td>
<p>Factor. Factor variable to color the observations. If factor = NULL, event will be
used (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_legend_title">legend_title</code></td>
<td>
<p>Character. Legend title (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_only_top">only_top</code></td>
<td>
<p>Logical. If &quot;only_top&quot; = TRUE, then only top/radius loading variables will be shown
in loading or biplot graph (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_radius">radius</code></td>
<td>
<p>Numeric. Radius size (loading/scale value) to plot variable names that are greater
than the radius value (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_names">names</code></td>
<td>
<p>Logical. Show loading names for top variables or for those that are outside the radius
size (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_colorreverse">colorReverse</code></td>
<td>
<p>Logical. Reverse palette colors (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_text.size">text.size</code></td>
<td>
<p>Numeric. Text size (default: 2).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.MB.PLS.model_+3A_overlaps">overlaps</code></td>
<td>
<p>Numeric. Number of overlaps to show when plotting loading names (default: 10).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot_Coxmos.MB.PLS.model function is designed to generate comprehensive visualizations of the
Coxmos model, specifically tailored for multiblock PLS. It leverages the inherent structure of the
model to produce plots that can aid in the interpretation of the model's components and their relationships.
</p>
<p>Depending on the chosen mode, the function can display:
</p>

<ul>
<li><p> Scores: This mode visualizes the scores of the model, which represent the projections of the
original data onto the PLS components. The scores can be colored by a factor variable, and ellipses
can be added to represent the distribution of the scores.
</p>
</li>
<li><p> Loadings: This mode displays the loadings of the model, which indicate the contribution of each
variable to the PLS components. The loadings can be filtered by a specified threshold (top or radius),
and arrows can be added to represent the direction and magnitude of the loadings.
</p>
</li>
<li><p> Biplot: A biplot combines both scores and loadings in a single plot, providing a comprehensive view
of the relationships between the observations and variables in the model.
</p>
</li></ul>

<p>The function also offers various customization options, such as adjusting the text size, reversing
the color palette, and specifying the number of overlaps for loading names. It ensures that the
visualizations are informative and tailored to the user's preferences and the specific characteristics
of the data.
</p>
<p>It's important to note that the function performs checks to ensure the input model is of the correct
class and provides informative messages for any inconsistencies detected.
</p>

<hr>
<h2 id='plot_Coxmos.PLS.model'>plot_Coxmos.PLS.model</h2><span id='topic+plot_Coxmos.PLS.model'></span>

<h3>Description</h3>

<p>Visualizes the Coxmos model using partial least squares (PLS) approach. This function offers
various plotting modes, including scores, loadings, and biplot visualizations, to provide insights
into the model's structure and relationships.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_Coxmos.PLS.model(
  model,
  comp = c(1, 2),
  mode = "scores",
  factor = NULL,
  legend_title = NULL,
  top = NULL,
  only_top = FALSE,
  radius = NULL,
  names = TRUE,
  colorReverse = FALSE,
  text.size = 2,
  overlaps = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_comp">comp</code></td>
<td>
<p>Numeric vector. Vector of length two. Select which components to plot (default: c(1,2)).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_mode">mode</code></td>
<td>
<p>Character. Choose one of the following plots: &quot;scores&quot;, &quot;loadings&quot; o &quot;biplot&quot;
(default: &quot;scores&quot;).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_factor">factor</code></td>
<td>
<p>Factor. Factor variable to color the observations. If factor = NULL, event will be
used (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_legend_title">legend_title</code></td>
<td>
<p>Character. Legend title (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_only_top">only_top</code></td>
<td>
<p>Logical. If &quot;only_top&quot; = TRUE, then only top/radius loading variables will be shown
in loading or biplot graph (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_radius">radius</code></td>
<td>
<p>Numeric. Radius size (loading/scale value) to plot variable names that are greater
than the radius value (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_names">names</code></td>
<td>
<p>Logical. Show loading names for top variables or for those that are outside the
radius size (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_colorreverse">colorReverse</code></td>
<td>
<p>Logical. Reverse palette colors (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_text.size">text.size</code></td>
<td>
<p>Numeric. Text size (default: 2).</p>
</td></tr>
<tr><td><code id="plot_Coxmos.PLS.model_+3A_overlaps">overlaps</code></td>
<td>
<p>Numeric. Number of overlaps to show when plotting loading names (default: 10).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot_Coxmos.PLS.model function is designed to generate comprehensive visualizations of the
Coxmos model, specifically tailored for PLS. It leverages the inherent structure of the model to
produce plots that can aid in the interpretation of the model's components and their relationships.
</p>
<p>Depending on the chosen mode, the function can display:
</p>

<ul>
<li><p> Scores: This mode visualizes the scores of the model, which represent the projections of the
original data onto the PLS components. The scores can be colored by a factor variable, and ellipses
can be added to represent the distribution of the scores.
</p>
</li>
<li><p> Loadings: This mode displays the loadings of the model, which indicate the contribution of each
variable to the PLS components. The loadings can be filtered by a specified threshold (top or radius),
and arrows can be added to represent the direction and magnitude of the loadings.
</p>
</li>
<li><p> Biplot: A biplot combines both scores and loadings in a single plot, providing a comprehensive
view of the relationships between the observations and variables in the model.
</p>
</li></ul>

<p>The function also offers various customization options, such as adjusting the text size, reversing
the color palette, and specifying the number of overlaps for loading names. It ensures that the
visualizations are informative and tailored to the user's preferences and the specific characteristics
of the data.
</p>
<p>It's important to note that the function performs checks to ensure the input model is of the correct
class and provides informative messages for any inconsistencies detected.
</p>

<hr>
<h2 id='plot_divergent.biplot'>plot_divergent.biplot</h2><span id='topic+plot_divergent.biplot'></span>

<h3>Description</h3>

<p>Generates a divergent biplot visualizing the distribution of a qualitative variable
against a quantitative variable, further categorized by an event matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_divergent.biplot(
  X,
  Y,
  NAMEVAR1,
  NAMEVAR2,
  BREAKTIME,
  x.text = "N. of Samples"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_divergent.biplot_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables with &quot;NAMEVAR1&quot; and &quot;NAMEVAR2&quot;
variables. &quot;NAMEVAR1&quot; must be a factor variable.</p>
</td></tr>
<tr><td><code id="plot_divergent.biplot_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="plot_divergent.biplot_+3A_namevar1">NAMEVAR1</code></td>
<td>
<p>Character. Factor variable name (must be located in colnames(X) and have to have
two levels).</p>
</td></tr>
<tr><td><code id="plot_divergent.biplot_+3A_namevar2">NAMEVAR2</code></td>
<td>
<p>Character. Numerical variable name (must be located in colnames(X)).</p>
</td></tr>
<tr><td><code id="plot_divergent.biplot_+3A_breaktime">BREAKTIME</code></td>
<td>
<p>Numeric. Size of time to split the data into &quot;total_time / BREAKTIME + 1&quot; points.
If BREAKTIME = NULL, &quot;n.breaks&quot; is used (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_divergent.biplot_+3A_x.text">x.text</code></td>
<td>
<p>Character. Title for X axis.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>plot_divergent.biplot</code> is designed to offer a comprehensive visualization
of the relationship between a qualitative and a quantitative variable, while also taking into
account an associated event matrix. The qualitative variable, denoted by &quot;NAMEVAR1&quot;, is expected
to be a factor with two levels, and the quantitative variable, &quot;NAMEVAR2&quot;, is numerically
represented. The event matrix, &quot;Y&quot;, consists of two columns: &quot;time&quot; and &quot;event&quot;. The &quot;event&quot;
column indicates whether an observation is censored or an event, represented by binary values
(0/1 or FALSE/TRUE).
</p>
<p>The function processes the input data to categorize the quantitative variable into groups based
on the specified &quot;BREAKTIME&quot; parameter. Each group represents a range of values for the quantitative
variable. The resulting plot displays the number of samples for each level of the qualitative
variable on the X-axis, while the Y-axis represents the categorized groups of the quantitative
variable. The bars in the plot are further colored based on the event type, providing a clear
distinction between censored and event observations.
</p>


<h3>Value</h3>

<p>A 'ggplot2' two side bar plot. X axis represent the number of samples per each NAMEVAR1
factor levels and Y axis, the X NAMEVAR2 numerical variables categorize in groups of breaks.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>X &lt;- data.frame(sex = factor(c("M","M","F","F","F","M","F","M","M")),
age = as.numeric(c(22,23,25,28,32,30,29,33,32)))

Y = data.frame(time = c(24,25,28,29,22,26,22,23,24),
event = c(TRUE,TRUE,FALSE,TRUE,FALSE,TRUE,TRUE,FALSE,FALSE))

NAMEVAR1 = "sex"
NAMEVAR2 = "age"
plot_divergent.biplot(X, Y, NAMEVAR1, NAMEVAR2, BREAKTIME = 5, x.text = "N. of Patients")
</code></pre>

<hr>
<h2 id='plot_evaluation'>plot_evaluation</h2><span id='topic+plot_evaluation'></span>

<h3>Description</h3>

<p>Generates a comprehensive evaluation of the performance of a given Coxmos evaluation
object from <code>eval_Coxmos_models()</code>, offering both statistical tests and visual plots for assessment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_evaluation(
  eval_results,
  evaluation = "AUC",
  pred.attr = "mean",
  y.min = NULL,
  type = "both",
  round_times = FALSE,
  decimals = 2,
  title = NULL,
  title_size_text = 15,
  legend_title = "Method",
  legend_size_text = 12,
  x_axis_size_text = 10,
  y_axis_size_text = 10,
  label_x_axis_size = 10,
  label_y_axis_size = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_evaluation_+3A_eval_results">eval_results</code></td>
<td>
<p>Coxmos evaluation object from <code>eval_Coxmos_models()</code>.</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_evaluation">evaluation</code></td>
<td>
<p>Character. Perform the evaluation using the &quot;AUC&quot; or &quot;Brier&quot; metric (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_y.min">y.min</code></td>
<td>
<p>Numeric. Minimum Y value for establish the Y axis value. If y.min = NULL, automatic
detection is performed (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_type">type</code></td>
<td>
<p>Character. Plot type. Must be one of the following: &quot;both&quot;, &quot;line&quot; or &quot;mean&quot;. In other
case, &quot;both&quot; will be selected (default: &quot;both&quot;).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_round_times">round_times</code></td>
<td>
<p>Logical. Whether times x value should be rounded (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_decimals">decimals</code></td>
<td>
<p>Numeric. Number of decimals to use in round times. Must be a value greater or equal
zero (default = 2).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_title">title</code></td>
<td>
<p>Character. Plot title (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_title_size_text">title_size_text</code></td>
<td>
<p>Numeric. Text size for legend title (default: 15).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_legend_title">legend_title</code></td>
<td>
<p>Character. Legend title (default: &quot;Method&quot;).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_legend_size_text">legend_size_text</code></td>
<td>
<p>Numeric. Text size for legend title (default: 12).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_x_axis_size_text">x_axis_size_text</code></td>
<td>
<p>Numeric. Text size for x axis (default: 10).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_y_axis_size_text">y_axis_size_text</code></td>
<td>
<p>Numeric. Text size for y axis (default: 10).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_label_x_axis_size">label_x_axis_size</code></td>
<td>
<p>Numeric. Text size for x label axis (default: 10).</p>
</td></tr>
<tr><td><code id="plot_evaluation_+3A_label_y_axis_size">label_y_axis_size</code></td>
<td>
<p>Numeric. Text size for y label axis (default: 10).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot_evaluation</code> function is designed to facilitate a rigorous evaluation of the
performance of models, specifically in the context of survival analysis. This function is tailored
to work with a Coxmos evaluation object, which encapsulates the results of survival models. The
primary objective is to provide both statistical and visual insights into the model's performance.
</p>
<p>The function offers flexibility in the evaluation metric, allowing users to choose between the
Area Under the Curve (AUC) and the Brier score. The chosen metric is then evaluated based on either
its mean or median value, as specified by the &quot;pred.attr&quot; parameter. The resulting plots can be
tailored to display continuous performance over time or aggregated mean performance, based on the
&quot;type&quot; parameter.
</p>
<p>A salient feature of this function is its ability to conduct statistical tests to compare the
performance across different methods. Supported tests include the t-test, ANOVA, Wilcoxon rank-sum
test, and Kruskal-Wallis test. These tests provide a quantitative measure of the differences in
performance, aiding in the objective assessment of the models.
</p>
<p>The visual outputs are generated using the 'ggplot2' package, ensuring high-quality and interpretable
plots. The function also offers extensive customization options for the plots, including axis
labels, title, and text sizes, ensuring that the outputs align with the user's preferences and the
intended audience's expectations.
</p>


<h3>Value</h3>

<p>A list of lst_eval_results length. Each element is a list of three elements.
<code>lst_plots</code>: A list of two plots. The evaluation over the time, and the extension adding the
mean or median on the right.
<code>lst_plot_comparisons</code>: A list of comparative boxplots by t.test, anova, wilcoxon, kruscal.
<code>df</code>: Data.frame of evaluation result.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
coxEN.model &lt;- coxEN(X_train, Y_train, x.center = TRUE, x.scale = TRUE)
eval_results &lt;- eval_Coxmos_models(lst_models = list("coxEN" = coxEN.model), X_test = X_test,
Y_test = Y_test)
plot_eval_results &lt;- plot_evaluation(eval_results)
</code></pre>

<hr>
<h2 id='plot_evaluation.list'>plot_evaluation.list</h2><span id='topic+plot_evaluation.list'></span>

<h3>Description</h3>

<p>Run the function &quot;plot_evaluation&quot; for a list of results. More information in
&quot;?plot_evaluation&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_evaluation.list(
  lst_eval_results,
  evaluation = "AUC",
  pred.attr = "mean",
  y.min = NULL,
  type = "both",
  round_times = FALSE,
  decimals = 2,
  title = NULL,
  title_size_text = 15,
  legend_title = "Method",
  legend_size_text = 12,
  x_axis_size_text = 10,
  y_axis_size_text = 10,
  label_x_axis_size = 10,
  label_y_axis_size = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_evaluation.list_+3A_lst_eval_results">lst_eval_results</code></td>
<td>
<p>List (named) of Coxmos evaluation results from <code>eval_Coxmos_models()</code>.</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_evaluation">evaluation</code></td>
<td>
<p>Character. Perform the evaluation using the &quot;AUC&quot; or &quot;Brier&quot; metric (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_pred.attr">pred.attr</code></td>
<td>
<p>Character. Way to evaluate the metric selected. Must be one of the following:
&quot;mean&quot; or &quot;median&quot; (default: &quot;mean&quot;).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_y.min">y.min</code></td>
<td>
<p>Numeric. Minimum Y value for establish the Y axis value. If y.min = NULL, automatic
detection is performed (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_type">type</code></td>
<td>
<p>Character. Plot type. Must be one of the following: &quot;both&quot;, &quot;line&quot; or &quot;mean&quot;. In other
case, &quot;both&quot; will be selected (default: &quot;both&quot;).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_round_times">round_times</code></td>
<td>
<p>Logical. Whether times x value should be rounded (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_decimals">decimals</code></td>
<td>
<p>Numeric. Number of decimals to use in round times. Must be a value greater or
equal zero (default = 2).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_title">title</code></td>
<td>
<p>Character. Plot title (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_title_size_text">title_size_text</code></td>
<td>
<p>Numeric. Text size for legend title (default: 15).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_legend_title">legend_title</code></td>
<td>
<p>Character. Legend title (default: &quot;Method&quot;).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_legend_size_text">legend_size_text</code></td>
<td>
<p>Numeric. Text size for legend title (default: 12).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_x_axis_size_text">x_axis_size_text</code></td>
<td>
<p>Numeric. Text size for x axis (default: 10).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_y_axis_size_text">y_axis_size_text</code></td>
<td>
<p>Numeric. Text size for y axis (default: 10).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_label_x_axis_size">label_x_axis_size</code></td>
<td>
<p>Numeric. Text size for x label axis (default: 10).</p>
</td></tr>
<tr><td><code id="plot_evaluation.list_+3A_label_y_axis_size">label_y_axis_size</code></td>
<td>
<p>Numeric. Text size for y label axis (default: 10).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of lst_eval_results length. Each element is a list of three elements.
<code>lst_plots</code>: A list of two plots. The evaluation over the time, and the extension adding the
mean or median on the right.
<code>lst_plot_comparisons</code>: A list of comparative boxplots by t.test, anova, wilcoxon, kruscal.
<code>df</code>: Data.frame of evaluation result.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
coxEN.model &lt;- coxEN(X_train, Y_train, x.center = TRUE, x.scale = TRUE)
eval_results &lt;- list()
eval_results[["cenROC"]] &lt;- eval_Coxmos_models(lst_models = list("coxEN" = coxEN.model),
X_test = X_test, Y_test = Y_test, pred.method = "cenROC")
eval_results[["survivalROC"]] &lt;- eval_Coxmos_models(lst_models = list("coxEN" = coxEN.model),
X_test = X_test, Y_test = Y_test, pred.method = "survivalROC")
plot_eval_results &lt;- plot_evaluation.list(eval_results)
</code></pre>

<hr>
<h2 id='plot_events'>plot_events</h2><span id='topic+plot_events'></span>

<h3>Description</h3>

<p>Generates a bar plot visualizing the distribution of events over time, categorizing
observations as either censored or non-censored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_events(
  Y,
  max.breaks = 20,
  roundTo = 0.1,
  categories = c("Censored", "Death"),
  y.text = "Number of observations",
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_events_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="plot_events_+3A_max.breaks">max.breaks</code></td>
<td>
<p>Numeric. Maximum number of breaks in X axis (default: 20).</p>
</td></tr>
<tr><td><code id="plot_events_+3A_roundto">roundTo</code></td>
<td>
<p>Numeric. Value to round time. If roundTo = 0.1, the results will be rounded to the
tenths (default: 0.1).</p>
</td></tr>
<tr><td><code id="plot_events_+3A_categories">categories</code></td>
<td>
<p>Character vector. Vector of length two to name both categories for censored and
non-censored observations (default: c(&quot;Censored&quot;,&quot;Death&quot;)).</p>
</td></tr>
<tr><td><code id="plot_events_+3A_y.text">y.text</code></td>
<td>
<p>Character. Y axis title (default: &quot;Number of observations&quot;).</p>
</td></tr>
<tr><td><code id="plot_events_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot_events</code> function is meticulously crafted to provide a visualization of event
occurrences over a specified time frame. The primary objective of this function is to elucidate
the distribution of events, distinguishing between censored and non-censored observations. The
input response matrix, &quot;Y&quot;, is expected to encompass two pivotal columns: &quot;time&quot; and &quot;event&quot;.
The &quot;time&quot; column delineates the temporal occurrence of each observation, while the &quot;event&quot;
column demarcates whether an observation is censored or an event, with accepted binary
representations being 0/1 or FALSE/TRUE.
</p>
<p>The function employs a systematic approach to categorize the time variable into distinct intervals
or &quot;breaks&quot;. The number of these intervals is determined by the &quot;max.breaks&quot; parameter, and their
size is influenced by the &quot;roundTo&quot; parameter. Each interval represents a range of time values,
and the resulting plot showcases the number of censored and non-censored observations within each
interval. The bars in the plot are color-coded based on the event type, offering a clear visual
distinction between the two categories.
</p>


<h3>Value</h3>

<p>A list of two elements.
<code>plot</code>: Barplot.
<code>df</code>: Data.frame used for the plotting.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
Y_train &lt;- Y_proteomic
plot_events(Y_train, categories = c("Censored","Death"))
</code></pre>

<hr>
<h2 id='plot_forest'>plot_forest</h2><span id='topic+plot_forest'></span>

<h3>Description</h3>

<p>Generates a forest plot for Coxmos models, visualizing the hazard ratios and their confidence
intervals. The function leverages the capabilities of the <code>survminer::ggforest</code> function to
produce a comprehensive representation of the model's coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_forest(
  model,
  title = "Hazard Ratio",
  cpositions = c(0.02, 0.22, 0.4),
  fontsize = 0.7,
  refLabel = "reference",
  noDigits = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_forest_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_forest_+3A_title">title</code></td>
<td>
<p>Character. Forest plot title (default: &quot;Hazard Ratio&quot;).</p>
</td></tr>
<tr><td><code id="plot_forest_+3A_cpositions">cpositions</code></td>
<td>
<p>Numeric vector. Relative positions of first three columns in the OX scale
(default: c(0.02, 0.22, 0.4)).</p>
</td></tr>
<tr><td><code id="plot_forest_+3A_fontsize">fontsize</code></td>
<td>
<p>Numeric. Elative size of annotations in the plot (default: 0.7).</p>
</td></tr>
<tr><td><code id="plot_forest_+3A_reflabel">refLabel</code></td>
<td>
<p>Character. Label for reference levels of factor variables (default: &quot;reference&quot;).</p>
</td></tr>
<tr><td><code id="plot_forest_+3A_nodigits">noDigits</code></td>
<td>
<p>Numeric. Number of digits for estimates and p-values in the plot (default: 2).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The forest plot is a graphical representation of the point estimates and confidence intervals of
the hazard ratios derived from a Coxmos model. Each row in the plot corresponds to a variable or
component from the model, with a point representing the hazard ratio and horizontal lines
indicating the confidence intervals. The plot provides a visual assessment of the significance and
magnitude of each variable's effect on the outcome.
</p>
<p>The function starts by validating the provided model to ensure it belongs to the Coxmos class and
is among the recognized Coxmos models. If the model is valid, the function then proceeds to
generate the forest plot using the <code>survminer::ggforest</code> function. Several customization options
are available, including adjusting the title, column positions, font size, reference label, and
the number of digits displayed for estimates and p-values.
</p>
<p>Forest plots are instrumental in the field of survival analysis, offering a concise visualization
of the model's results, making them easier to interpret and communicate.
</p>


<h3>Value</h3>

<p>A ggplot object representing the forest plot. The plot visualizes the hazard ratios and
their confidence intervals for each variable or component from the Coxmos model.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
plot_forest(splsicox.model)
</code></pre>

<hr>
<h2 id='plot_forest.list'>plot_forest.list</h2><span id='topic+plot_forest.list'></span>

<h3>Description</h3>

<p>Run the function &quot;plot_forest&quot; for a list of models. More information in &quot;?plot_forest&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_forest.list(
  lst_models,
  title = "Hazard Ratio",
  cpositions = c(0.02, 0.22, 0.4),
  fontsize = 0.7,
  refLabel = "reference",
  noDigits = 2
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_forest.list_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos models.</p>
</td></tr>
<tr><td><code id="plot_forest.list_+3A_title">title</code></td>
<td>
<p>Character. Forest plot title (default: &quot;Hazard Ratio&quot;).</p>
</td></tr>
<tr><td><code id="plot_forest.list_+3A_cpositions">cpositions</code></td>
<td>
<p>Numeric vector. Relative positions of first three columns in the OX scale
(default: c(0.02, 0.22, 0.4)).</p>
</td></tr>
<tr><td><code id="plot_forest.list_+3A_fontsize">fontsize</code></td>
<td>
<p>Numeric. Elative size of annotations in the plot (default: 0.7).</p>
</td></tr>
<tr><td><code id="plot_forest.list_+3A_reflabel">refLabel</code></td>
<td>
<p>Character. Label for reference levels of factor variables (default: &quot;reference&quot;).</p>
</td></tr>
<tr><td><code id="plot_forest.list_+3A_nodigits">noDigits</code></td>
<td>
<p>Numeric. Number of digits for estimates and p-values in the plot (default: 2).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A ggplot object per model representing the forest plot. The plot visualizes the hazard ratios and
their confidence intervals for each variable or component from the Coxmos model.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
splsdrcox.model &lt;- splsdrcox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
lst_models = list("sPLSICOX" = splsicox.model, "sPLSDRCOX" = splsdrcox.model)
plot_forest.list(lst_models)
</code></pre>

<hr>
<h2 id='plot_LP.multipleObservations'>plot_LP.multipleObservations</h2><span id='topic+plot_LP.multipleObservations'></span>

<h3>Description</h3>

<p>Visualizes the linear predictors for multiple patients based on a given Coxmos model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_LP.multipleObservations(
  model,
  new_observations,
  error.bar = FALSE,
  onlySig = TRUE,
  alpha = 0.05,
  zero.rm = TRUE,
  auto.limits = TRUE,
  top = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_LP.multipleObservations_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations_+3A_new_observations">new_observations</code></td>
<td>
<p>Numeric matrix or data.frame. New explanatory variables (raw data). Qualitative
variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations_+3A_error.bar">error.bar</code></td>
<td>
<p>Logical. Show error bar (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations_+3A_onlysig">onlySig</code></td>
<td>
<p>Logical. Compute plot using only significant components (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations_+3A_zero.rm">zero.rm</code></td>
<td>
<p>Logical. Remove variables equal to 0 (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations_+3A_auto.limits">auto.limits</code></td>
<td>
<p>Logical. If &quot;auto.limits&quot; = TRUE, limits are detected automatically (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>plot_LP.multipleObservations</code> is designed to visualize the linear predictors for multiple
patients based on the provided Coxmos model. The function takes into account various parameters to
customize the visualization, such as the significance level, error bars, and the number of top
variables to display.
</p>
<p>The function works by first checking the class of the provided model. Depending on the model type,
it delegates the plotting task to one of the three methods: classical models, PLS models, or
multi-block PLS models. Each of these methods is tailored to handle specific model types and
produce the desired plots.
</p>


<h3>Value</h3>

<p>A ggplot object visualizing the linear predictors for multiple patients based on the
provided Coxmos model.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
plot_LP.multipleObservations(model = splsicox.model, new_observations = X_test[1:5,])
</code></pre>

<hr>
<h2 id='plot_LP.multipleObservations.list'>plot_LP.multipleObservations.list</h2><span id='topic+plot_LP.multipleObservations.list'></span>

<h3>Description</h3>

<p>Run the function &quot;plot_LP.multipleObservations&quot; for a list of models. More information
in &quot;?plot_LP.multipleObservations&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_LP.multipleObservations.list(
  lst_models,
  new_observations,
  error.bar = FALSE,
  onlySig = TRUE,
  alpha = 0.05,
  zero.rm = TRUE,
  auto.limits = TRUE,
  top = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_LP.multipleObservations.list_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos models.</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations.list_+3A_new_observations">new_observations</code></td>
<td>
<p>Numeric matrix or data.frame. New explanatory variables (raw data). Qualitative
variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations.list_+3A_error.bar">error.bar</code></td>
<td>
<p>Logical. Show error bar (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations.list_+3A_onlysig">onlySig</code></td>
<td>
<p>Logical. Compute plot using only significant components (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations.list_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations.list_+3A_zero.rm">zero.rm</code></td>
<td>
<p>Logical. Remove variables equal to 0 (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations.list_+3A_auto.limits">auto.limits</code></td>
<td>
<p>Logical. If &quot;auto.limits&quot; = TRUE, limits are detected automatically (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_LP.multipleObservations.list_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of ggplot objects for each model in the <code>lst_models</code>. Each plot visualizes
the linear predictor values for multiple patients based on the specified Coxmos model. The plots
can optionally display error bars, consider only significant components, and can be limited to a
specified number of top variables. The visualization aids in understanding the influence of
explanatory variables on the survival prediction for each patient in the context of the provided
models.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
splsdrcox.model &lt;- splsdrcox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
lst_models = list("sPLSICOX" = splsicox.model, "sPLSDRCOX" = splsdrcox.model)
plot_LP.multipleObservations.list(lst_models = lst_models, X_test[1:5,])
</code></pre>

<hr>
<h2 id='plot_observation.eventDensity'>plot_observation.eventDensity</h2><span id='topic+plot_observation.eventDensity'></span>

<h3>Description</h3>

<p>Visualizes the event density for a given observation's data using the Coxmos model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_observation.eventDensity(
  observation,
  model,
  time = NULL,
  type = "lp",
  size = 3,
  color = "red"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_observation.eventDensity_+3A_observation">observation</code></td>
<td>
<p>Numeric matrix or data.frame. New explanatory variables (raw data) for one observation.
Qualitative variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="plot_observation.eventDensity_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_observation.eventDensity_+3A_time">time</code></td>
<td>
<p>Numeric. Time point where the AUC will be evaluated (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_observation.eventDensity_+3A_type">type</code></td>
<td>
<p>Character. Prediction type: &quot;lp&quot;, &quot;risk&quot;, &quot;expected&quot; or &quot;survival&quot; (default: &quot;lp&quot;).</p>
</td></tr>
<tr><td><code id="plot_observation.eventDensity_+3A_size">size</code></td>
<td>
<p>Numeric. Point size (default: 3).</p>
</td></tr>
<tr><td><code id="plot_observation.eventDensity_+3A_color">color</code></td>
<td>
<p>String. R Color.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot_observation.eventDensity</code> function provides a graphical representation of the event
density for a specific observation's data, based on the Coxmos model. The function computes the density
of events and non-events and plots them, highlighting the predicted value for the given observation's
data. The density is determined using density estimation, and the predicted value is obtained from
the Coxmos model. The function allows customization of the plot aesthetics, such as point size and
color. The resulting plot provides a visual comparison of the observation's predicted event density
against the overall event density distribution, aiding in the interpretation of the observation's risk
profile.
</p>


<h3>Value</h3>

<p>A ggplot object representing a density of the predicted event values based on the
provided Coxmos model.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
coxEN.model &lt;- coxEN(X_train, Y_train, x.center = TRUE, x.scale = TRUE)
observation = X_test[1,,drop=FALSE]
plot_observation.eventDensity(observation = observation, model = coxEN.model, time = NULL)
</code></pre>

<hr>
<h2 id='plot_observation.eventHistogram'>plot_observation.eventHistogram</h2><span id='topic+plot_observation.eventHistogram'></span>

<h3>Description</h3>

<p>Generates a histogram plot for observation event data based on a given Coxmos model. The
function visualizes the distribution of predicted values and highlights the prediction for a
specific observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_observation.eventHistogram(
  observation,
  model,
  time = NULL,
  type = "lp",
  size = 3,
  color = "red"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_observation.eventHistogram_+3A_observation">observation</code></td>
<td>
<p>Numeric matrix or data.frame. New explanatory variables (raw data) for one
observation. Qualitative variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="plot_observation.eventHistogram_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_observation.eventHistogram_+3A_time">time</code></td>
<td>
<p>Numeric. Time point where the AUC will be evaluated (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_observation.eventHistogram_+3A_type">type</code></td>
<td>
<p>Character. Prediction type: &quot;lp&quot;, &quot;risk&quot;, &quot;expected&quot; or &quot;survival&quot; (default: &quot;lp&quot;).</p>
</td></tr>
<tr><td><code id="plot_observation.eventHistogram_+3A_size">size</code></td>
<td>
<p>Numeric. Point size (default: 3).</p>
</td></tr>
<tr><td><code id="plot_observation.eventHistogram_+3A_color">color</code></td>
<td>
<p>String. R Color.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot_observation.eventHistogram</code> function is designed to provide a visual representation
of the distribution of predicted event values based on a Coxmos model. The function takes in observation
data, a specified time point, and a Coxmos model to compute the prediction. The resulting histogram
plot displays the distribution of these predictions, with a specific emphasis on the prediction
for the provided observation data. The prediction is represented as a point on the histogram, allowing
for easy comparison between the specific observation's prediction and the overall distribution of
predictions. The type of prediction (&quot;lp&quot;, &quot;risk&quot;, &quot;expected&quot;, or &quot;survival&quot;) can be specified,
offering flexibility in the kind of insights one wishes to derive from the visualization. The
appearance of the point representing the observation's prediction can be customized using the <code>size</code>
and <code>color</code> parameters.
</p>


<h3>Value</h3>

<p>A ggplot object representing a histogram of the predicted event values based on the
provided Coxmos model.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
coxEN.model &lt;- coxEN(X_train, Y_train, x.center = TRUE, x.scale = TRUE)
observation = X_test[1,,drop=FALSE]
plot_observation.eventHistogram(observation = observation, model = coxEN.model, time = NULL)
</code></pre>

<hr>
<h2 id='plot_PLS_Coxmos'>plot_PLS_Coxmos</h2><span id='topic+plot_PLS_Coxmos'></span>

<h3>Description</h3>

<p>Visualizes the Coxmos models based on partial least squares (PLS) or Multi-block PLS approaches.
This function offers various plotting modes, including scores, loadings, and biplot visualizations,
to provide insights into the model's structure and relationships.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_PLS_Coxmos(
  model,
  comp = c(1, 2),
  mode = "scores",
  factor = NULL,
  legend_title = NULL,
  top = NULL,
  only_top = FALSE,
  radius = NULL,
  names = TRUE,
  colorReverse = FALSE,
  text.size = 2,
  overlaps = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_PLS_Coxmos_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_comp">comp</code></td>
<td>
<p>Numeric vector. Vector of length two. Select which components to plot (default: c(1,2)).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_mode">mode</code></td>
<td>
<p>Character. Choose one of the following plots: &quot;scores&quot;, &quot;loadings&quot; o &quot;biplot&quot;
(default: &quot;scores&quot;).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_factor">factor</code></td>
<td>
<p>Factor. Factor variable to color the observations. If factor = NULL, event will be
used (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_legend_title">legend_title</code></td>
<td>
<p>Character. Legend title (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_only_top">only_top</code></td>
<td>
<p>Logical. If &quot;only_top&quot; = TRUE, then only top/radius loading variables will be
shown in loading or biplot graph (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_radius">radius</code></td>
<td>
<p>Numeric. Radius size (loading/scale value) to plot variable names that are greater
than the radius value (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_names">names</code></td>
<td>
<p>Logical. Show loading names for top variables or for those that are outside the radius
size (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_colorreverse">colorReverse</code></td>
<td>
<p>Logical. Reverse palette colors (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_text.size">text.size</code></td>
<td>
<p>Numeric. Text size (default: 2).</p>
</td></tr>
<tr><td><code id="plot_PLS_Coxmos_+3A_overlaps">overlaps</code></td>
<td>
<p>Numeric. Number of overlaps to show when plotting loading names (default: 10).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot_Coxmos.PLS.model function is designed to generate comprehensive visualizations of the
Coxmos models. It leverages the inherent structure of the model to produce plots that can aid in
the interpretation of the model's components and their relationships.
</p>
<p>Depending on the chosen mode, the function can display:
</p>

<ul>
<li><p> Scores: This mode visualizes the scores of the model, which represent the projections of the
original data onto the PLS components. The scores can be colored by a factor variable, and
ellipses can be added to represent the distribution of the scores.
</p>
</li>
<li><p> Loadings: This mode displays the loadings of the model, which indicate the contribution of each
variable to the PLS components. The loadings can be filtered by a specified threshold
(top or radius), and arrows can be added to represent the direction and magnitude of the loadings.
</p>
</li>
<li><p> Biplot: A biplot combines both scores and loadings in a single plot, providing a comprehensive
view of the relationships between the observations and variables in the model.
</p>
</li></ul>

<p>The function also offers various customization options, such as adjusting the text size, reversing
the color palette, and specifying the number of overlaps for loading names. It ensures that the
visualizations are informative and tailored to the user's preferences and the specific
characteristics of the data.
</p>
<p>It's important to note that the function performs checks to ensure the input model is of the
correct class and provides informative messages for any inconsistencies detected.
</p>


<h3>Value</h3>

<p>A list of two elements.
<code>plot</code>: Score, Loading or Biplot graph in 'ggplot2' format.
<code>outliers</code>: Data.frame of outliers detected in the plot.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
plot_PLS_Coxmos(splsicox.model, comp = c(1,2), mode = "scores")
</code></pre>

<hr>
<h2 id='plot_proportionalHazard'>plot_proportionalHazard</h2><span id='topic+plot_proportionalHazard'></span>

<h3>Description</h3>

<p>Generates a visual assessment of the proportional hazards assumption for a given Coxmos model.
The function integrates the capabilities of the <code>survival::cox.zph</code> and <code>survminer::ggcoxzph</code>
functions to produce a <code>ggplot2</code> graph that visualizes the validity of the proportional hazards
assumption.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_proportionalHazard(model)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_proportionalHazard_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The proportional hazards assumption is a fundamental tenet of the Cox proportional hazards
regression model. It posits that the hazard ratios between groups remain constant over time.
Violations of this assumption can lead to biased or misleading results. Thus, assessing the validity
of this assumption is crucial in survival analysis.
</p>
<p>The function begins by validating the provided model to ensure it belongs to the Coxmos class. If
the model is valid, the function then evaluates the proportional hazards assumption using the
<code>survival::cox.zph</code> function. The results of this evaluation are then visualized using the
<code>survminer::ggcoxzph</code> function, producing a <code>ggplot2</code> graph.
</p>
<p>The resulting plot provides a visual representation of the Schoenfeld residuals against time,
allowing for an intuitive assessment of the proportional hazards assumption. Each variable or
factor level from the model is represented in the plot, and the global test for the proportional
hazards assumption is also provided.
</p>
<p>This function is instrumental in ensuring the robustness and validity of survival analysis results,
offering a comprehensive visualization that aids in the interpretation and validation of the Coxmos
model's assumptions.
</p>


<h3>Value</h3>

<p>A <code>ggplot2</code> object visualizing the assessment of the proportional hazards assumption
for the given Coxmos model. The plot displays the Schoenfeld residuals against time for each
variable or factor level from the model. A line is fitted to these residuals to indicate any trend,
which can suggest a violation of the proportional hazards assumption.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Therneau TM (2024).
<em>A Package for Survival Analysis in R</em>.
R package version 3.5-8, <a href="https://CRAN.R-project.org/package=survival">https://CRAN.R-project.org/package=survival</a>.
Kassambara A, Kosinski M, Biecek P (2021).
<em>survminer: Drawing Survival Curves using 'ggplot2'</em>.
R package version 0.4.9, <a href="https://CRAN.R-project.org/package=survminer">https://CRAN.R-project.org/package=survminer</a>.
Grambsch PM, Therneau TM (1994).
&ldquo;Proportional hazards tests and diagnostics based on weighted residuals.&rdquo;
<em>Biometrika</em>.
<a href="https://doi.org/10.1093/biomet/81.3.515">doi:10.1093/biomet/81.3.515</a>, <a href="https://academic.oup.com/biomet/article-abstract/81/3/515/257037?redirectedFrom=fulltext">https://academic.oup.com/biomet/article-abstract/81/3/515/257037?redirectedFrom=fulltext</a>.
Schoenfeld DA (1982).
&ldquo;Partial residuals for the proportional hazards regression model.&rdquo;
<em>Biometrika</em>.
<a href="https://doi.org/10.1093/biomet/69.1.239">doi:10.1093/biomet/69.1.239</a>, <a href="https://academic.oup.com/biomet/article-abstract/69/1/239/243012?redirectedFrom=fulltext">https://academic.oup.com/biomet/article-abstract/69/1/239/243012?redirectedFrom=fulltext</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
plot_proportionalHazard(splsicox.model)
</code></pre>

<hr>
<h2 id='plot_proportionalHazard.list'>plot_proportionalHazard.list</h2><span id='topic+plot_proportionalHazard.list'></span>

<h3>Description</h3>

<p>Run the function &quot;plot_proportionalHazard&quot; for a list of models. More information in
&quot;?plot_proportionalHazard&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_proportionalHazard.list(lst_models)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_proportionalHazard.list_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos models.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>ggplot2</code> object per model visualizing the assessment of the proportional hazards assumption
for the given Coxmos model. The plot displays the Schoenfeld residuals against time for each
variable or factor level from the model. A line is fitted to these residuals to indicate any trend,
which can suggest a violation of the proportional hazards assumption.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
splsdrcox.model &lt;- splsdrcox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
lst_models = list("sPLSICOX" = splsicox.model, "sPLSDRCOX" = splsdrcox.model)
plot_proportionalHazard.list(lst_models)
</code></pre>

<hr>
<h2 id='plot_pseudobeta'>plot_pseudobeta</h2><span id='topic+plot_pseudobeta'></span>

<h3>Description</h3>

<p>This function decomposes a PLS-Cox model, translating it into a pseudo-beta
interpretation with respect to the original variables. The decomposition is based on the
relationship between the Cox coefficients associated with each component and the weights
corresponding to the original variables. The final Cox formula is thus expressed in terms of
these original variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_pseudobeta(
  model,
  error.bar = TRUE,
  onlySig = FALSE,
  alpha = 0.05,
  zero.rm = TRUE,
  top = NULL,
  auto.limits = TRUE,
  show_percentage = TRUE,
  size_percentage = 3,
  title_size_text = 15,
  legend_size_text = 12,
  x_axis_size_text = 10,
  y_axis_size_text = 10,
  label_x_axis_size = 10,
  label_y_axis_size = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_pseudobeta_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_error.bar">error.bar</code></td>
<td>
<p>Logical. Show error bar (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_onlysig">onlySig</code></td>
<td>
<p>Logical. Compute pseudobetas using only significant components (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the threshold
(default: 0.05).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_zero.rm">zero.rm</code></td>
<td>
<p>Logical. Remove variables with a pseudobeta equal to 0 (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables with the higher pseudobetas in absolute value. If
top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_auto.limits">auto.limits</code></td>
<td>
<p>Logical. If &quot;auto.limits&quot; = TRUE, limits are detected automatically (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_show_percentage">show_percentage</code></td>
<td>
<p>Logical. If show_percentage = TRUE, it shows the contribution percentage
for each variable to the full model (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_size_percentage">size_percentage</code></td>
<td>
<p>Numeric. Size of percentage text (default: 3).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_title_size_text">title_size_text</code></td>
<td>
<p>Numeric. Text size for legend title (default: 15).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_legend_size_text">legend_size_text</code></td>
<td>
<p>Numeric. Text size for legend title (default: 12).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_x_axis_size_text">x_axis_size_text</code></td>
<td>
<p>Numeric. Text size for x axis (default: 10).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_y_axis_size_text">y_axis_size_text</code></td>
<td>
<p>Numeric. Text size for y axis (default: 10).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_label_x_axis_size">label_x_axis_size</code></td>
<td>
<p>Numeric. Text size for x label axis (default: 10).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_+3A_label_y_axis_size">label_y_axis_size</code></td>
<td>
<p>Numeric. Text size for y label axis (default: 10).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot_pseudobeta</code> function offers a comprehensive visualization and interpretation
of a PLS-Cox model in terms of the original variables. The function begins by validating the model's
class and type. For single block models, the function computes the pseudo-betas by multiplying
the loading weights (<code>W.star</code>) with the Cox coefficients. For multiblock models, this computation
is performed for each block separately.
</p>
<p>The function provides flexibility in terms of visualization. Users can opt to display error bars,
filter out non-significant components based on a significance threshold (<code>alpha</code>), and remove
variables with a pseudo-beta of zero. Additionally, the function allows for automatic limit
detection for the plot and displays the contribution percentage of each variable to the full model.
The resulting plot can be customized further with various text size parameters for different plot
elements.
</p>
<p>It's worth noting that the function supports both single block and multiblock PLS-Cox models. For
multiblock models, the function returns a list of plots, one for each block, whereas for single
block models, a single plot is returned.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
<code>plot</code>: Depending on the model type, this can either be a single ggplot object visualizing the pseudo-beta coefficients for the original variables in a single block PLS-Cox model, or a list of ggplot objects for each block in a multiblock PLS-Cox model. Each plot provides a comprehensive visualization of the pseudo-beta coefficients, potentially including error bars, significance filtering, and variable contribution percentages.
<code>beta</code>: A matrix or list of matrices (for multiblock models) containing the computed pseudo-beta coefficients for the original variables. These coefficients represent the influence of each original variable on the survival prediction.
<code>sd.min</code>: A matrix or list of matrices (for multiblock models) representing the lower bounds of the error bars for the pseudo-beta coefficients.
<code>sd.max</code>: A matrix or list of matrices (for multiblock models) representing the upper bounds of the error bars for the pseudo-beta coefficients.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
plot_pseudobeta(model = splsicox.model)
</code></pre>

<hr>
<h2 id='plot_pseudobeta_newObservation'>plot_pseudobeta.newObservation</h2><span id='topic+plot_pseudobeta_newObservation'></span>

<h3>Description</h3>

<p>Generates a visual representation comparing the pseudobeta values derived from the Coxmos model
with the values of a new observation. This function provides insights into how the new observation
aligns with the established model, offering a graphical comparison of the pseudobeta directions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_pseudobeta_newObservation(
  model,
  new_observation,
  error.bar = TRUE,
  onlySig = TRUE,
  alpha = 0.05,
  zero.rm = TRUE,
  top = NULL,
  auto.limits = TRUE,
  show.betas = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_pseudobeta_newObservation_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation_+3A_new_observation">new_observation</code></td>
<td>
<p>Numeric matrix or data.frame. New explanatory variables (raw data) for one
observation. Qualitative variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation_+3A_error.bar">error.bar</code></td>
<td>
<p>Logical. Show error bar (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation_+3A_onlysig">onlySig</code></td>
<td>
<p>Logical. Compute pseudobetas using only significant components (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation_+3A_zero.rm">zero.rm</code></td>
<td>
<p>Logical. Remove variables with a pseudobeta equal to 0 (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables with the higher pseudobetas in absolute value. If
top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation_+3A_auto.limits">auto.limits</code></td>
<td>
<p>Logical. If &quot;auto.limits&quot; = TRUE, limits are detected automatically (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation_+3A_show.betas">show.betas</code></td>
<td>
<p>Logical. Show original betas (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>plot_pseudobeta.newObservation</code> is designed to visually compare the pseudobeta values
from the Coxmos model with those of a new observation. The generated plot is based on the ggplot2
framework and offers a comprehensive view of the relationship between the model's pseudobeta values
and the new observation's values.
</p>
<p>The function first checks the validity of the provided model and ensures that it belongs to the
appropriate class. Depending on the type of the model (either PLS or MB Coxmos methods).
</p>
<p>For the actual plotting, the function computes the linear predictor values for the new observation
and juxtaposes them with the pseudobeta values from the model. If the <code>show.betas</code> parameter is
set to TRUE, the original beta values are also displayed on the plot. Error bars can be included
to represent the variability in the pseudobeta values, providing a more comprehensive view of the
data's distribution.
</p>
<p>The resulting plot serves as a valuable tool for researchers and statisticians to visually assess
the alignment of a new observation with an established Coxmos model, facilitating better
interpretation and understanding of the data in the context of the model.
</p>


<h3>Value</h3>

<p>A list of four elements:
<code>plot</code>: Linear prediction per variable.
<code>lp.var</code>: Value of each linear prediction per variable.
<code>norm_observation</code>: Observation normalized using the model information.
<code>observation</code>: Observation used.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
plot_pseudobeta_newObservation(model = splsicox.model, new_observation = X_test[1,,drop=FALSE])
</code></pre>

<hr>
<h2 id='plot_pseudobeta_newObservation.list'>plot_pseudobeta_newObservation.list</h2><span id='topic+plot_pseudobeta_newObservation.list'></span>

<h3>Description</h3>

<p>Run the function &quot;plot_pseudobeta_newObservation&quot; for a list of models. More information
in &quot;?plot_pseudobeta_newObservation&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_pseudobeta_newObservation.list(
  lst_models,
  new_observation,
  error.bar = TRUE,
  onlySig = TRUE,
  alpha = 0.05,
  zero.rm = TRUE,
  top = NULL,
  auto.limits = TRUE,
  show.betas = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos models.</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_new_observation">new_observation</code></td>
<td>
<p>Numeric matrix or data.frame. New explanatory variables (raw data) for one
observation. Qualitative variables must be transform into binary variables.</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_error.bar">error.bar</code></td>
<td>
<p>Logical. Show error bar (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_onlysig">onlySig</code></td>
<td>
<p>Logical. Compute pseudobetas using only significant components (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_zero.rm">zero.rm</code></td>
<td>
<p>Logical. Remove variables with a pseudobeta equal to 0 (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables with the higher pseudobetas in absolute value. If
top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_auto.limits">auto.limits</code></td>
<td>
<p>Logical. If &quot;auto.limits&quot; = TRUE, limits are detected automatically (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_show.betas">show.betas</code></td>
<td>
<p>Logical. Show original betas (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta_newObservation.list_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of lst_models length with a list of four elements per each model:
<code>plot</code>: Linear prediction per variable.
<code>lp.var</code>: Value of each linear prediction per variable.
<code>norm_observation</code>: Observation normalized using the model information.
<code>observation</code>: Observation used.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]
X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
splsicox.model &lt;- splsicox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
splsdrcox.model &lt;- splsdrcox(X_train, Y_train, n.comp = 2, penalty = 0.5, x.center = TRUE,
x.scale = TRUE)
lst_models = list("sPLSICOX" = splsicox.model, "sPLSDRCOX" = splsdrcox.model)
plot_pseudobeta_newObservation.list(lst_models, new_observation = X_test[1,,drop=FALSE])
</code></pre>

<hr>
<h2 id='plot_pseudobeta.list'>plot_pseudobeta.list</h2><span id='topic+plot_pseudobeta.list'></span>

<h3>Description</h3>

<p>Run the function &quot;plot_pseudobeta&quot; for a list of models. More information in
&quot;?plot_pseudobeta&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_pseudobeta.list(
  lst_models,
  error.bar = TRUE,
  onlySig = FALSE,
  alpha = 0.05,
  zero.rm = TRUE,
  top = NULL,
  auto.limits = TRUE,
  show_percentage = TRUE,
  size_percentage = 3,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_pseudobeta.list_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos models.</p>
</td></tr>
<tr><td><code id="plot_pseudobeta.list_+3A_error.bar">error.bar</code></td>
<td>
<p>Logical. Show error bar (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta.list_+3A_onlysig">onlySig</code></td>
<td>
<p>Logical. Compute pseudobetas using only significant components (default: FALSE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta.list_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta.list_+3A_zero.rm">zero.rm</code></td>
<td>
<p>Logical. Remove variables with a pseudobeta equal to 0 (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta.list_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables with the higher pseudobetas in absolute value.
If top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta.list_+3A_auto.limits">auto.limits</code></td>
<td>
<p>Logical. If &quot;auto.limits&quot; = TRUE, limits are detected automatically
(default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta.list_+3A_show_percentage">show_percentage</code></td>
<td>
<p>Logical. If show_percentage = TRUE, it shows the contribution percentage
for each variable to the full model (default: TRUE).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta.list_+3A_size_percentage">size_percentage</code></td>
<td>
<p>Numeric. Size of percentage text (default: 3).</p>
</td></tr>
<tr><td><code id="plot_pseudobeta.list_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following elements per model:
<code>plot</code>: Depending on the model type, this can either be a single ggplot object visualizing the pseudo-beta coefficients for the original variables in a single block PLS-Cox model, or a list of ggplot objects for each block in a multiblock PLS-Cox model. Each plot provides a comprehensive visualization of the pseudo-beta coefficients, potentially including error bars, significance filtering, and variable contribution percentages.
<code>beta</code>: A matrix or list of matrices (for multiblock models) containing the computed pseudo-beta coefficients for the original variables. These coefficients represent the influence of each original variable on the survival prediction.
<code>sd.min</code>: A matrix or list of matrices (for multiblock models) representing the lower bounds of the error bars for the pseudo-beta coefficients.
<code>sd.max</code>: A matrix or list of matrices (for multiblock models) representing the upper bounds of the error bars for the pseudo-beta coefficients.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
splsdrcox.model &lt;- splsdrcox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
lst_models = list("sPLSICOX" = splsicox.model, "sPLSDRCOX" = splsdrcox.model)
plot_pseudobeta.list(lst_models = lst_models)
</code></pre>

<hr>
<h2 id='plot_time.list'>Time consuming plot.</h2><span id='topic+plot_time.list'></span>

<h3>Description</h3>

<p>Produces a visual representation, using ggplot2, of the computational time consumed
by each model encapsulated within the provided list of Coxmos models. This visualization aids in
the comparative assessment of computational efficiency across different models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_time.list(lst_models, x.text = "Method", y.text = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_time.list_+3A_lst_models">lst_models</code></td>
<td>
<p>List of Coxmos models. Each Coxmos object has the attribute time measured in
minutes (cross-validation models could be also added to this function).</p>
</td></tr>
<tr><td><code id="plot_time.list_+3A_x.text">x.text</code></td>
<td>
<p>Character. X axis title.</p>
</td></tr>
<tr><td><code id="plot_time.list_+3A_y.text">y.text</code></td>
<td>
<p>Character. Y axis title. If y.text = NULL, then y.text = &quot;Time (mins)&quot; (default: NULL).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot_time.list</code> function objective is to offer a clear and concise visual
representation of the computational time expended by each model during its execution.
</p>
<p>The function expects a list of Coxmos models, each of which should inherently possess a time
attribute indicating the computational time it consumed. This time attribute is then extracted,
aggregated, and visualized in a bar plot format. The function is versatile enough to handle both
individual models and cross-validation models, summing up the computational times in the latter
case to provide an aggregate view.
</p>
<p>The resultant plot is generated using the 'ggplot2' package, ensuring a high-quality and interpretable
visualization. The Y-axis of the plot represents the computational time, typically in minutes, while
the X-axis enumerates the different models. The function also offers customization options for axis
labels, ensuring that the resultant plot aligns with the user's preferences and the intended audience's
expectations.
</p>


<h3>Value</h3>

<p>A 'ggplot2' bar plot object.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
coxSW.model &lt;- coxSW(X, Y, x.center = TRUE, x.scale = TRUE)
coxEN.model &lt;- coxEN(X, Y, x.center = TRUE, x.scale = TRUE)
lst_models = list("coxSW" = coxSW.model, "coxEN" = coxEN.model)
plot_time.list(lst_models, x.text = "Method")
</code></pre>

<hr>
<h2 id='predict.Coxmos'>predict.Coxmos</h2><span id='topic+predict.Coxmos'></span>

<h3>Description</h3>

<p>Generates the prediction score matrix for Partial Least Squares (PLS) Survival models,
facilitating the transformation of high-dimensional data into a reduced space while preserving the
most relevant information for survival analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Coxmos'
predict(object, ..., newdata = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.Coxmos_+3A_object">object</code></td>
<td>
<p>Coxmos model</p>
</td></tr>
<tr><td><code id="predict.Coxmos_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the predictions produced.</p>
</td></tr>
<tr><td><code id="predict.Coxmos_+3A_newdata">newdata</code></td>
<td>
<p>Numeric matrix or data.frame. New data for explanatory variables (raw data).
Qualitative variables must be transform into binary variables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>predict.Coxmos</code> function is designed to compute the prediction scores for new data
based on a previously trained PLS Survival model. The function leverages the dimensional reduction
capabilities of PLS to project the new data into a lower-dimensional space, which is particularly
beneficial when dealing with high-dimensional datasets in survival analysis. The score matrix
obtained serves as a compact representation of the original data, capturing the most salient
features that influence survival outcomes.
</p>


<h3>Value</h3>

<p>Score values data.frame for new data using the Coxmos model selected.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
set.seed(123)
index_train &lt;- caret::createDataPartition(Y_proteomic$event, p = .5, list = FALSE, times = 1)
X_train &lt;- X_proteomic[index_train,1:50]
Y_train &lt;- Y_proteomic[index_train,]

X_test &lt;- X_proteomic[-index_train,1:50]
Y_test &lt;- Y_proteomic[-index_train,]
model &lt;- splsicox(X_train, Y_train, n.comp = 2) #after CV
predict(object = model, newdata = X_test)
</code></pre>

<hr>
<h2 id='print.Coxmos'>print.Coxmos</h2><span id='topic+print.Coxmos'></span>

<h3>Description</h3>

<p>Provides a structured print output for objects of class Coxmos, detailing either the
final Cox survival model or the attributes of the optimal model from cross-validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'Coxmos'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.Coxmos_+3A_x">x</code></td>
<td>
<p>Coxmos object</p>
</td></tr>
<tr><td><code id="print.Coxmos_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>print.Coxmos</code> function serves as a diagnostic tool, offering a comprehensive display
of the Coxmos object's attributes. Depending on the nature of the Coxmos object‚Äîwhether it's derived
from a survival model or a cross-validated model‚Äîthe function tailors its output accordingly. For
survival models, it elucidates the method employed, any variables removed due to high correlation,
zero or near-zero variance, or non-significance within the Cox model, and presents a summary of
the survival model itself. In the context of cross-validated models, the function delineates the
cross-validation method utilized and, if ascertainable, details of the best model. For evaluation
objects, it systematically enumerates the methods evaluated and provides a summary of metrics for
each method.
</p>


<h3>Value</h3>

<p>Print information relative to a Coxmos object.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
model &lt;- splsicox(X, Y, x.center = TRUE, x.scale = TRUE)
print(model)
</code></pre>

<hr>
<h2 id='RocFun'>ROC estimation function</h2><span id='topic+RocFun'></span>

<h3>Description</h3>

<p>ROC estimation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RocFun(U, D, M, bw = "NR", method, ktype)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RocFun_+3A_u">U</code></td>
<td>
<p>The vector of grid points where the ROC curve is estimated.</p>
</td></tr>
<tr><td><code id="RocFun_+3A_d">D</code></td>
<td>
<p>The event indicator.</p>
</td></tr>
<tr><td><code id="RocFun_+3A_m">M</code></td>
<td>
<p>The numeric vector of marker values for which the time-dependent ROC curves is computed.</p>
</td></tr>
<tr><td><code id="RocFun_+3A_bw">bw</code></td>
<td>
<p>The bandwidth parameter for smoothing the ROC function. The possible options are <code>NR</code> normal reference method; <code>PI</code> plug-in method and <code>CV</code> cross-validation method. The default is the <code>NR</code> normal reference method.</p>
</td></tr>
<tr><td><code id="RocFun_+3A_method">method</code></td>
<td>
<p>is the method of ROC curve estimation. The possible options are <code>emp</code> emperical method; <code>untra</code> smooth without boundary correction and <code>tra</code> is smooth ROC curve estimation with boundary correction.</p>
</td></tr>
<tr><td><code id="RocFun_+3A_ktype">ktype</code></td>
<td>
<p>A character string giving the type kernel to be used: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Beyene K. Mehari and El Ghouch Anouar
</p>


<h3>References</h3>

<p>Beyene, K. M. and El Ghouch A. (2019). Smoothed time-dependent ROC curves for right-censored survival data. <a href="https://dial.uclouvain.be/pr/boreal/object/boreal:219643">https://dial.uclouvain.be/pr/boreal/object/boreal:219643</a>.
</p>

<hr>
<h2 id='save_ggplot'>save_ggplot</h2><span id='topic+save_ggplot'></span>

<h3>Description</h3>

<p>Allows to save 'ggplot2' objects in .tiff format based on an specific resolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_ggplot(
  plot,
  folder,
  name = "plot",
  wide = TRUE,
  quality = "4K",
  dpi = 80,
  custom = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_ggplot_+3A_plot">plot</code></td>
<td>
<p>'ggplot2' object. Object to plot and save.</p>
</td></tr>
<tr><td><code id="save_ggplot_+3A_folder">folder</code></td>
<td>
<p>Character. Folder path as character type.</p>
</td></tr>
<tr><td><code id="save_ggplot_+3A_name">name</code></td>
<td>
<p>Character. File name.</p>
</td></tr>
<tr><td><code id="save_ggplot_+3A_wide">wide</code></td>
<td>
<p>Logical. If TRUE, widescreen format (16:9) is used, in other case (4:3) format.</p>
</td></tr>
<tr><td><code id="save_ggplot_+3A_quality">quality</code></td>
<td>
<p>Character. One of: &quot;HD&quot;, &quot;FHD&quot;, &quot;2K&quot;, &quot;4K&quot;, &quot;8K&quot;</p>
</td></tr>
<tr><td><code id="save_ggplot_+3A_dpi">dpi</code></td>
<td>
<p>Numeric. Dpi value for the image.</p>
</td></tr>
<tr><td><code id="save_ggplot_+3A_custom">custom</code></td>
<td>
<p>Numeric vector. Custom size of the image. Numeric vector of width and height.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generate a plot image in the specific folder or working directory.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(requireNamespace("ggplot2", quietly = TRUE)){
library(ggplot2)
data(iris)
g &lt;- ggplot(iris, aes(Sepal.Width, Sepal.Length, color = Species))
g &lt;- g + geom_point(size = 4)
save_ggplot(g, folder = tempdir())
}

</code></pre>

<hr>
<h2 id='save_ggplot_lst'>save_ggplot_lst</h2><span id='topic+save_ggplot_lst'></span>

<h3>Description</h3>

<p>Allows to save a list of 'ggplot2' objects in .tiff format based on an specific resolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_ggplot_lst(
  lst_plots,
  folder,
  prefix = NULL,
  suffix = NULL,
  wide = TRUE,
  quality = "4K",
  dpi = 80,
  custom = NULL,
  object_name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_ggplot_lst_+3A_lst_plots">lst_plots</code></td>
<td>
<p>List of 'ggplot2'.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst_+3A_folder">folder</code></td>
<td>
<p>Character. Folder path as character type.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst_+3A_prefix">prefix</code></td>
<td>
<p>Character. Prefix for file name.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst_+3A_suffix">suffix</code></td>
<td>
<p>Character. Sufix for file name.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst_+3A_wide">wide</code></td>
<td>
<p>Logical. If TRUE, widescreen format (16:9) is used, in other case (4:3) format.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst_+3A_quality">quality</code></td>
<td>
<p>Character. One of: &quot;HD&quot;, &quot;FHD&quot;, &quot;2K&quot;, &quot;4K&quot;, &quot;8K&quot;</p>
</td></tr>
<tr><td><code id="save_ggplot_lst_+3A_dpi">dpi</code></td>
<td>
<p>Numeric. Dpi value for the image.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst_+3A_custom">custom</code></td>
<td>
<p>Numeric vector. Custom size of the image. Numeric vector of width and height.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst_+3A_object_name">object_name</code></td>
<td>
<p>Character. If the file to plot it is inside of a list, name of the object to save.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generate a plot image in the specific folder or working directory.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(requireNamespace("ggplot2", quietly = TRUE)){
library(ggplot2)
data(iris)
g &lt;- ggplot(iris, aes(Sepal.Width, Sepal.Length, color = Species))
g &lt;- g + geom_point(size = 4)
g2 &lt;- ggplot(iris, aes(Petal.Width, Petal.Length, color = Species))
g2 &lt;- g2 + geom_point(size = 4)
lst_plots &lt;- list("Sepal" = g, "Petal" = g2)
save_ggplot_lst(lst_plots, folder = tempdir())
}

</code></pre>

<hr>
<h2 id='save_ggplot_lst.svg'>save_ggplot_lst.svg</h2><span id='topic+save_ggplot_lst.svg'></span>

<h3>Description</h3>

<p>Allows to save a list of 'ggplot2' objects in .svg format based on an specific resolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_ggplot_lst.svg(
  lst_plots,
  folder,
  prefix = NULL,
  suffix = NULL,
  wide = TRUE,
  quality = "4K",
  dpi = 80,
  custom = NULL,
  object_name = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_ggplot_lst.svg_+3A_lst_plots">lst_plots</code></td>
<td>
<p>List of 'ggplot2'.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst.svg_+3A_folder">folder</code></td>
<td>
<p>Character. Folder path as character type.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst.svg_+3A_prefix">prefix</code></td>
<td>
<p>Character. Prefix for file name.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst.svg_+3A_suffix">suffix</code></td>
<td>
<p>Character. Sufix for file name.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst.svg_+3A_wide">wide</code></td>
<td>
<p>Logical. If TRUE, widescreen format (16:9) is used, in other case (4:3) format.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst.svg_+3A_quality">quality</code></td>
<td>
<p>Character. One of: &quot;HD&quot;, &quot;FHD&quot;, &quot;2K&quot;, &quot;4K&quot;, &quot;8K&quot;</p>
</td></tr>
<tr><td><code id="save_ggplot_lst.svg_+3A_dpi">dpi</code></td>
<td>
<p>Numeric. Dpi value for the image.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst.svg_+3A_custom">custom</code></td>
<td>
<p>Numeric vector. Custom size of the image. Numeric vector of width and height.</p>
</td></tr>
<tr><td><code id="save_ggplot_lst.svg_+3A_object_name">object_name</code></td>
<td>
<p>Character. If the file to plot it is inside of a list, name of the object to save.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generate as many plot images as list objects in the specific folder or working directory.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(requireNamespace("ggplot2", quietly = TRUE)){
library(ggplot2)
data(iris)
g &lt;- ggplot(iris, aes(Sepal.Width, Sepal.Length, color = Species))
g &lt;- g + geom_point(size = 4)
g2 &lt;- ggplot(iris, aes(Petal.Width, Petal.Length, color = Species))
g2 &lt;- g2 + geom_point(size = 4)
lst_plots &lt;- list("Sepal" = g, "Petal" = g2)
save_ggplot_lst.svg(lst_plots, folder = tempdir())
}

</code></pre>

<hr>
<h2 id='save_ggplot.svg'>save_ggplot.svg</h2><span id='topic+save_ggplot.svg'></span>

<h3>Description</h3>

<p>Allows to save 'ggplot2' objects in .svg format based on an specific resolution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_ggplot.svg(
  plot,
  folder,
  name = "plot",
  wide = TRUE,
  quality = "4K",
  dpi = 80,
  custom = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="save_ggplot.svg_+3A_plot">plot</code></td>
<td>
<p>'ggplot2' object. Object to plot and save.</p>
</td></tr>
<tr><td><code id="save_ggplot.svg_+3A_folder">folder</code></td>
<td>
<p>Character. Folder path as character type.</p>
</td></tr>
<tr><td><code id="save_ggplot.svg_+3A_name">name</code></td>
<td>
<p>Character. File name.</p>
</td></tr>
<tr><td><code id="save_ggplot.svg_+3A_wide">wide</code></td>
<td>
<p>Logical. If TRUE, widescreen format (16:9) is used, in other case (4:3) format.</p>
</td></tr>
<tr><td><code id="save_ggplot.svg_+3A_quality">quality</code></td>
<td>
<p>Character. One of: &quot;HD&quot;, &quot;FHD&quot;, &quot;2K&quot;, &quot;4K&quot;, &quot;8K&quot;</p>
</td></tr>
<tr><td><code id="save_ggplot.svg_+3A_dpi">dpi</code></td>
<td>
<p>Numeric. Dpi value for the image.</p>
</td></tr>
<tr><td><code id="save_ggplot.svg_+3A_custom">custom</code></td>
<td>
<p>Numeric vector. Custom size of the image. Numeric vector of width and height.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Generate as many plot images as list objects in the specific folder or working directory.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if(requireNamespace("ggplot2", quietly = TRUE)){
library(ggplot2)
data(iris)
g &lt;- ggplot(iris, aes(Sepal.Width, Sepal.Length, color = Species))
g &lt;- g + geom_point(size = 4)
save_ggplot.svg(g, folder = tempdir())
}

</code></pre>

<hr>
<h2 id='sb.splsdrcox'>SB.sPLS-DRCOX</h2><span id='topic+sb.splsdrcox'></span>

<h3>Description</h3>

<p>This function performs a single-block sparse partial least squares deviance residual
Cox (SB.sPLS-DRCOX). The function returns a Coxmos model with the attribute model as &quot;SB.sPLS-DRCOX&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sb.splsdrcox(
  X,
  Y,
  n.comp = 4,
  penalty = 0.5,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_non_significant = FALSE,
  alpha = 0.05,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sb.splsdrcox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_n.comp">n.comp</code></td>
<td>
<p>Numeric. Number of latent components to compute for the (s)PLS model (default: 10).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_penalty">penalty</code></td>
<td>
<p>Numeric. Penalty for sPLS-DRCOX. If penalty = 0 no penalty is applied, when
penalty = 1 maximum penalty (no variables are selected) based on 'plsRcox' penalty. Equal or greater
than 1 cannot be selected (default: 0.5).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="sb.splsdrcox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>SB.sPLS-DRCOX</code> function performs a single-block sparse partial least squares deviance residual
Cox analysis. This method is designed to handle datasets with a single block of explanatory variables
and aims to identify the most relevant features that contribute to the survival outcome. The method
combines the strengths of sparse partial least squares (sPLS) with Cox regression, allowing for
dimensionality reduction, feature selection, and survival analysis in a unified framework.
</p>
<p>The key feature of this function is the use of deviance residuals as the response in the sPLS model.
Deviance residuals are derived from a preliminary Cox model and capture the discrepancies between
the observed and expected number of events. By using these residuals as the response, the sPLS model
can focus on identifying the explanatory variables that have the most significant impact on the
survival outcome.
</p>
<p>The function offers flexibility in specifying various hyperparameters, such as the number of latent
components (<code>n.comp</code>) and the penalty for variable selection (<code>penalty</code>). The penalty parameter, <code>penalty</code>,
controls the sparsity of the model, with higher values leading to more variables being excluded from
the model. This allows for a balance between model complexity and interpretability.
</p>
<p>Data preprocessing options, such as centering and scaling of the explanatory variables and removal
of near-zero variance variables, are also provided. These preprocessing steps ensure that the data
is in a suitable format for the sPLS model and can help improve the stability and performance of
the analysis.
</p>
<p>The output of the function provides a comprehensive overview of the sPLS-DRCOX model, including the
normalized data, PLS weights and scores, and the final Cox model. Visualization tools and metrics
such as AIC and BIC are also provided to aid in understanding the model's performance and
significance of the selected features.
</p>
<p>In summary, the <code>SB.sPLS-DRCOX</code> function offers a robust approach for survival analysis with
high-dimensional data, combining feature selection, dimensionality reduction, and Cox regression
in a single-block framework. The method is particularly useful for datasets where the number of
variables exceeds the number of observations, and there's a need to identify the most relevant
features for predicting survival outcomes.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;sb.splscox&quot;. The class contains the following
elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: PLS weights
</p>
</li>
<li> <p><code>(weightings_norm)</code>: PLS normalize weights
</p>
</li>
<li> <p><code>(W.star)</code>: PLS W* vector
</p>
</li>
<li> <p><code>(scores)</code>: PLS scores/variates
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(deviance_residuals)</code>: deviance residual vector used as Y matrix in the sPLS.
</p>
</li>
<li> <p><code>(dr.mean)</code>: mean values for deviance residuals Y matrix
</p>
</li>
<li> <p><code>(dr.sd)</code>: standard deviation for deviance residuals Y matrix'
</p>
</li>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>list_spls_models</code>: List of sPLS-DRCOX models computed for each block.
</p>
<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>penalty</code> Penalty applied.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_multiomic")
data("Y_multiomic")
X &lt;- X_multiomic
X$mirna &lt;- X$mirna[,1:50]
X$proteomic &lt;- X$proteomic[,1:50]
Y &lt;- Y_multiomic
sb.splsdrcox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='sb.splsicox'>SB.sPLS-ICOX</h2><span id='topic+sb.splsicox'></span>

<h3>Description</h3>

<p>This function performs a single-block sparse partial least squares individual Cox
(SB.sPLS-ICOX). The function returns a Coxmos model with the attribute model as &quot;SB.sPLS-ICOX&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sb.splsicox(
  X,
  Y,
  n.comp = 4,
  penalty = 1,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_non_significant = FALSE,
  alpha = 0.05,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sb.splsicox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_n.comp">n.comp</code></td>
<td>
<p>Numeric. Number of latent components to compute for the (s)PLS model (default: 10).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_penalty">penalty</code></td>
<td>
<p>Numeric. Penalty for variable selection for the individual cox models. Variables
with a lower P-Value than 1 - &quot;penalty&quot; in the individual cox analysis will be keep for the
sPLS-ICOX approach (default: 1).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="sb.splsicox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>SB.sPLS-ICOX</code> function is designed to perform a single-block sparse partial least squares
individual Cox analysis. This method is particularly suited for high-dimensional datasets where
the number of variables (features) significantly exceeds the number of observations. The
&quot;single-block&quot; in its name indicates that while the function can handle datasets with multiple
blocks, it processes each block individually rather than in a multiblock manner where all blocks
are analyzed simultaneously.
</p>
<p>By analyzing one block at a time, the function ensures a focused and detailed examination of each
block's contribution to the survival outcome. This approach is especially beneficial when different
blocks represent distinct types or sources of data, allowing for a granular understanding of each
block's significance.
</p>
<p>The analysis begins by applying a penalty to select significant variables based on individual Cox
models. This step ensures that only the most relevant features from the current block contribute
to the subsequent sPLS analysis. The sPLS method then identifies latent components that capture
the maximum covariance between the explanatory variables (X) from the block and the response (Y),
which are the deviance residuals from the Cox models.
</p>
<p>Users have the flexibility to specify various hyperparameters, including the number of latent
components and the penalty for variable selection. The function also offers options for data
preprocessing, such as centering, scaling, and removing variables with near-zero or zero variance.
</p>
<p>The output provides a comprehensive overview of the analysis for the processed block, including
normalized data information, survival model details, and the sPLS-ICOX model. Visualization tools
and metrics such as AIC and BIC further aid in understanding the model's performance and
significance for the given block.
</p>
<p>In summary, the <code>SB.sPLS-ICOX</code> function offers a powerful approach for survival analysis in
high-dimensional settings, ensuring optimal feature selection, dimensionality reduction, and
predictive modeling for each individual block in the dataset.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;sb.splsicox&quot;. The class contains the following
elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: PLS weights
</p>
</li>
<li> <p><code>(weightings_norm)</code>: PLS normalize weights
</p>
</li>
<li> <p><code>(W.star)</code>: PLS W* vector
</p>
</li>
<li> <p><code>(scores)</code>: PLS scores/variates
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(deviance_residuals)</code>: deviance residual vector used as Y matrix in the sPLS.
</p>
</li>
<li> <p><code>(dr.mean)</code>: mean values for deviance residuals Y matrix
</p>
</li>
<li> <p><code>(dr.sd)</code>: standard deviation for deviance residuals Y matrix'
</p>
</li>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>list_spls_models</code>: List of sPLS-ICOX models computed for each block.
</p>
<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>penalty</code> Penalty applied.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_multiomic")
data("Y_multiomic")
X &lt;- X_multiomic
X$mirna &lt;- X$mirna[,1:50]
X$proteomic &lt;- X$proteomic[,1:50]
Y &lt;- Y_multiomic
sb.splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='splsdacox_dynamic'>sPLSDA-COX Dynamic</h2><span id='topic+splsdacox_dynamic'></span>

<h3>Description</h3>

<p>The splsdacox_dynamic function conducts a sparse partial least squares discriminant analysis Cox
(sPLSDA-COX) using dynamic variable selection methodology. This method is particularly useful for
high-dimensional survival data where the goal is to identify a subset of variables that are most
predictive of survival outcomes. The function integrates the power of sPLSDA with the Cox
proportional hazards model to provide a robust tool for survival analysis in the context of large
datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splsdacox_dynamic(
  X,
  Y,
  n.comp = 4,
  vector = NULL,
  MIN_NVAR = 10,
  MAX_NVAR = 1000,
  n.cut_points = 5,
  MIN_AUC_INCREASE = 0.01,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_non_significant = FALSE,
  alpha = 0.05,
  EVAL_METHOD = "AUC",
  pred.method = "cenROC",
  max.iter = 200,
  times = NULL,
  max_time_points = 15,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splsdacox_dynamic_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_n.comp">n.comp</code></td>
<td>
<p>Numeric. Number of latent components to compute for the (s)PLS model (default: 10).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_vector">vector</code></td>
<td>
<p>Numeric vector. Used for computing best number of variables. As many values as
components have to be provided. If vector = NULL, an automatic detection is perform (default: NULL).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_min_nvar">MIN_NVAR</code></td>
<td>
<p>Numeric. Minimum range size for computing cut points to select the best number of
variables to use (default: 10).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_max_nvar">MAX_NVAR</code></td>
<td>
<p>Numeric. Maximum range size for computing cut points to select the best number of
variables to use (default: 1000).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_n.cut_points">n.cut_points</code></td>
<td>
<p>Numeric. Number of cut points for searching the optimal number of variables.
If only two cut points are selected, minimum and maximum size are used. For MB approaches as many
as n.cut_points^n.blocks models will be computed as minimum (default: 5).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_eval_method">EVAL_METHOD</code></td>
<td>
<p>Character. If EVAL_METHOD = &quot;AUC&quot;, AUC metric will be use to compute the best
number of variables. In other case, c-index metric will be used (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_max.iter">max.iter</code></td>
<td>
<p>Numeric. Maximum number of iterations for PLS convergence (default: 200).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdacox_dynamic_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function begins by checking the input parameters for consistency and ensuring that the response
variable Y has the required columns &quot;time&quot; and &quot;event&quot;. It then preprocesses the data by centering
and scaling (if specified), and removing variables with zero or near-zero variance. The function
also checks for multicollinearity in the data and addresses it if detected.
</p>
<p>The core of the function involves determining the optimal number of variables to retain in the model.
If the vector parameter is not provided, the function employs a strategy to identify the best number
of variables for each latent component. This is achieved by evaluating different combinations of
variables and selecting the one that maximizes the model's performance, as determined by the
specified evaluation metric (EVAL_METHOD).
</p>
<p>Once the optimal number of variables is determined, the function proceeds to compute the sPLSDA-COX
model. It employs the mixOmics::splsda function to compute the sPLSDA model, which is then
integrated with the Cox proportional hazards model. The resulting model provides insights into the
relationship between the predictor variables and survival outcomes.
</p>
<p>The function also offers the flexibility to refine the model further by removing non-significant
variables based on a specified alpha threshold.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;sPLS-DACOX-Dynamic&quot;. The class contains the
following elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: sPLS weights
</p>
</li>
<li> <p><code>(W.star)</code>: sPLS W* vector
</p>
</li>
<li> <p><code>(loadings)</code>: sPLS loadings
</p>
</li>
<li> <p><code>(scores)</code>: sPLS scores/variates
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>n.varX</code>: Number of Variables selected in each PLS component.
</p>
<p><code>var_by_component</code>: Variables selected in each PLS component.
</p>
<p><code>plot_accuracyPerVariable</code>: If NULL vector is selected, return a plot for understanding the
number of variable selection.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>alpha</code>: alpha value selected
</p>
<p><code>nsv</code>: Variables removed by cox alpha cutoff.
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Rohart F, Gautier B, Singh A, Cao KAL (2017).
&ldquo;mixOmics: An R package for ‚Äòomics feature selection and multiple data integration.&rdquo;
<em>PLoS Computational Biology</em>, <b>13</b>(11).
ISSN 15537358, <a href="https://pubmed.ncbi.nlm.nih.gov/29099853/">https://pubmed.ncbi.nlm.nih.gov/29099853/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:20]
Y &lt;- Y_proteomic
splsdacox_dynamic(X, Y, n.comp = 2, vector = NULL, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='splsdrcox'>sPLS-DRCOX</h2><span id='topic+splsdrcox'></span>

<h3>Description</h3>

<p>This function performs a sparse partial least squares deviance residual Cox (sPLS-DRCOX)
(based on plsRcox R package). The function returns a Coxmos model with the attribute model as
&quot;sPLS-DRCOX&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splsdrcox(
  X,
  Y,
  n.comp = 4,
  penalty = 0.5,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = FALSE,
  toKeep.zv = NULL,
  remove_non_significant = FALSE,
  alpha = 0.05,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splsdrcox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and event
observations.</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_n.comp">n.comp</code></td>
<td>
<p>Numeric. Number of latent components to compute for the (s)PLS model (default: 10).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_penalty">penalty</code></td>
<td>
<p>Numeric. Penalty for sPLS-DRCOX. If penalty = 0 no penalty is applied, when
penalty = 1 maximum penalty (no variables are selected) based on 'plsRcox' penalty. Equal or greater
than 1 cannot be selected (default: 0.5).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero
variance filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdrcox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>sPLS-DRCOX</code> function implements the sparse partial least squares deviance residual Cox
(sPLS-DRCOX) model, a specialized approach tailored for survival analysis. This method integrates
the strengths of the sparse partial least squares (sPLS) technique with the Cox proportional hazards
model, leveraging deviance residuals as a bridge.
</p>
<p>The function's core lies in its ability to handle high-dimensional data, often encountered in
genomics or other omics studies. By incorporating the <code>penalty</code> parameter, which governs the sparsity
level, the function offers a fine-grained control over variable selection. This ensures that only
the most informative predictors contribute to the model, enhancing interpretability and reducing
overfitting.
</p>
<p>Data preprocessing is seamlessly integrated, with options to center and scale the predictors, and
to remove variables exhibiting near-zero or zero variance. The function also provides a mechanism
to retain specific variables, regardless of their variance, ensuring that domain-specific knowledge
can be incorporated.
</p>
<p>The output is comprehensive, detailing both the sPLS and Cox model components. It provides insights
into the selected variables, their contributions across latent components, and the overall fit of
the survival model. This rich output aids in understanding the underlying relationships between
predictors and survival outcomes.
</p>
<p>The <code>sPLS-DRCOX</code> function is grounded in established methodologies and is a valuable tool for
researchers aiming to unravel complex survival associations in high-dimensional datasets.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;sPLS-DRCOX&quot;. The class contains the following
elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: sPLS weights
</p>
</li>
<li> <p><code>(weightings_norm)</code>: sPLS normalize weights
</p>
</li>
<li> <p><code>(W.star)</code>: sPLS W* vector
</p>
</li>
<li> <p><code>(loadings)</code>: sPLS loadings
</p>
</li>
<li> <p><code>(scores)</code>: sPLS scores/variates
</p>
</li>
<li> <p><code>(E)</code>: error matrices
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(deviance_residuals)</code>: deviance residual vector used as Y matrix in the sPLS.
</p>
</li>
<li> <p><code>(dr.mean)</code>: mean values for deviance residuals Y matrix
</p>
</li>
<li> <p><code>(dr.sd)</code>: standard deviation for deviance residuals Y matrix'
</p>
</li>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: sPLS weights
</p>
</li>
<li> <p><code>(loadings)</code>: sPLS loadings
</p>
</li>
<li> <p><code>(scores)</code>: sPLS scores/variates
</p>
</li>
<li> <p><code>(ratio)</code>: r value for the sPLS model (used to perform predictions)
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>penalty</code>: Penalty value selected.
</p>
<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>var_by_component</code>: Variables selected in each PLS component.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>B.hat</code>: sPLS beta matrix
</p>
<p><code>R2</code>: sPLS R2
</p>
<p><code>SCR</code>: sPLS SCR
</p>
<p><code>SCT</code>: sPLS SCT
</p>
<p><code>alpha</code>: alpha value selected
</p>
<p><code>nsv</code>: Variables removed by cox alpha cutoff.
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Bastien P (2008).
&ldquo;Deviance residuals based PLS regression for censored data in high dimensional setting.&rdquo;
<em>Chemometrics and Intelligent Laboratory Systems</em>.
<a href="https://doi.org/10.1016/j.chemolab.2007.09.009">doi:10.1016/j.chemolab.2007.09.009</a>, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0169743907001931?via%3Dihub">https://www.sciencedirect.com/science/article/abs/pii/S0169743907001931?via%3Dihub</a>.
Bastien P, Bastien P, Bertrand F, Meyer N, Meyer N, Meyer N, Maumy-Bertrand M (2015).
&ldquo;Deviance residuals-based sparse PLS and sparse kernel PLS regression for censored data.&rdquo;
<em>Bioinformatics</em>.
<a href="https://academic.oup.com/bioinformatics/article/31/3/397/2366078">https://academic.oup.com/bioinformatics/article/31/3/397/2366078</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsdrcox(X, Y, n.comp = 3, penalty = 0.25, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='splsdrcox_dynamic'>sPLS-DRCOX Dynamic</h2><span id='topic+splsdrcox_dynamic'></span>

<h3>Description</h3>

<p>The sPLS-DRCOX Dynamic function conducts a sparse partial least squares deviance residual Cox
regression analysis using a dynamic variable selection approach. This method is particularly
useful for high-dimensional survival data where variable selection is crucial. The function returns
a model of class &quot;Coxmos&quot; with the attribute model specified as &quot;sPLS-DRCOX&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splsdrcox_dynamic(
  X,
  Y,
  n.comp = 4,
  vector = NULL,
  MIN_NVAR = 10,
  MAX_NVAR = 1000,
  n.cut_points = 5,
  MIN_AUC_INCREASE = 0.01,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = TRUE,
  toKeep.zv = NULL,
  remove_non_significant = FALSE,
  alpha = 0.05,
  EVAL_METHOD = "AUC",
  pred.method = "cenROC",
  max.iter = 200,
  times = NULL,
  max_time_points = 15,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splsdrcox_dynamic_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_n.comp">n.comp</code></td>
<td>
<p>Numeric. Number of latent components to compute for the (s)PLS model (default: 10).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_vector">vector</code></td>
<td>
<p>Numeric vector. Used for computing best number of variables. As many values as
components have to be provided. If vector = NULL, an automatic detection is perform (default: NULL).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_min_nvar">MIN_NVAR</code></td>
<td>
<p>Numeric. Minimum range size for computing cut points to select the best number of
variables to use (default: 10).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_max_nvar">MAX_NVAR</code></td>
<td>
<p>Numeric. Maximum range size for computing cut points to select the best number of
variables to use (default: 1000).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_n.cut_points">n.cut_points</code></td>
<td>
<p>Numeric. Number of cut points for searching the optimal number of variables.
If only two cut points are selected, minimum and maximum size are used. For MB approaches as many
as n.cut_points^n.blocks models will be computed as minimum (default: 5).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_min_auc_increase">MIN_AUC_INCREASE</code></td>
<td>
<p>Numeric. Minimum improvement between different cross validation models to
continue evaluating higher values in the multiple tested parameters. If it is not reached for next
'MIN_COMP_TO_CHECK' models and the minimum 'MIN_AUC' value is reached, the evaluation stops
(default: 0.01).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_eval_method">EVAL_METHOD</code></td>
<td>
<p>Character. If EVAL_METHOD = &quot;AUC&quot;, AUC metric will be use to compute the best
number of variables. In other case, c-index metric will be used (default: &quot;AUC&quot;).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_pred.method">pred.method</code></td>
<td>
<p>Character. AUC evaluation algorithm method for evaluate the model performance.
Must be one of the following: &quot;risksetROC&quot;, &quot;survivalROC&quot;, &quot;cenROC&quot;, &quot;nsROC&quot;, &quot;smoothROCtime_C&quot;,
&quot;smoothROCtime_I&quot; (default: &quot;cenROC&quot;).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_max.iter">max.iter</code></td>
<td>
<p>Numeric. Maximum number of iterations for PLS convergence (default: 200).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_times">times</code></td>
<td>
<p>Numeric vector. Time points where the AUC will be evaluated. If NULL, a maximum of
'max_time_points' points will be selected equally distributed (default: NULL).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_max_time_points">max_time_points</code></td>
<td>
<p>Numeric. Maximum number of time points to use for evaluating the model
(default: 15).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsdrcox_dynamic_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function employs a sparse partial least squares (sPLS) approach combined with deviance
residuals from a Cox model to handle survival data. The dynamic variable selection methodology
ensures that only the most relevant predictors are included in the model, enhancing interpretability
and potentially improving predictive performance.
</p>
<p>The input matrices X and Y represent the explanatory and response variables, respectively. It is
essential to note that qualitative variables in X should be transformed into binary format. The
response matrix Y should have two columns named &quot;time&quot; and &quot;event&quot;, where the &quot;event&quot; column can
take values 0/1 or FALSE/TRUE, representing censored and event observations.
</p>
<p>Several parameters allow users to fine-tune the model. For instance, n.comp determines the number
of latent components for the PLS model, and vector aids in computing the optimal number of variables.
Parameters like MIN_NVAR and MAX_NVAR define the range for computing cut points to select the best
number of variables. The function also provides options for data preprocessing, such as centering
and scaling the X matrix and removing variables with near-zero or zero variance.
</p>
<p>The evaluation metric for determining the best number of variables can be specified using the
EVAL_METHOD parameter. The function supports various evaluation algorithms for assessing model
performance, as indicated by the pred.method parameter.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;sPLS-DRCOX-Dynamic&quot;. The class contains the following
elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: PLS weights
</p>
</li>
<li> <p><code>(W.star)</code>: PLS W* vector
</p>
</li>
<li> <p><code>(loadings)</code>: sPLS loadings
</p>
</li>
<li> <p><code>(scores)</code>: PLS scores/variates
</p>
</li>
<li> <p><code>(E)</code>: error matrices
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(deviance_residuals)</code>: deviance residual vector used as Y matrix in the sPLS.
</p>
</li>
<li> <p><code>(dr.mean)</code>: mean values for deviance residuals Y matrix
</p>
</li>
<li> <p><code>(dr.sd)</code>: standard deviation for deviance residuals Y matrix'
</p>
</li>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>n.varX</code>: Number of Variables selected in each PLS component.
</p>
<p><code>var_by_component</code>: Variables selected in each PLS component.
</p>
<p><code>plot_accuracyPerVariable</code>: If NULL vector is selected, return a plot for understanding the
number of variable selection.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>beta_matrix</code>: PLS beta matrix
</p>
<p><code>R2</code>: PLS R2
</p>
<p><code>SCR</code>: PLS SCR
</p>
<p><code>SCT</code>: PLS SCT
</p>
<p><code>alpha</code>: alpha value selected
</p>
<p><code>nsv</code>: Variables removed by cox alpha cutoff.
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Bastien P (2008).
&ldquo;Deviance residuals based PLS regression for censored data in high dimensional setting.&rdquo;
<em>Chemometrics and Intelligent Laboratory Systems</em>.
<a href="https://doi.org/10.1016/j.chemolab.2007.09.009">doi:10.1016/j.chemolab.2007.09.009</a>, <a href="https://www.sciencedirect.com/science/article/abs/pii/S0169743907001931?via%3Dihub">https://www.sciencedirect.com/science/article/abs/pii/S0169743907001931?via%3Dihub</a>.
Bastien P, Bastien P, Bertrand F, Meyer N, Meyer N, Meyer N, Maumy-Bertrand M (2015).
&ldquo;Deviance residuals-based sparse PLS and sparse kernel PLS regression for censored data.&rdquo;
<em>Bioinformatics</em>.
<a href="https://academic.oup.com/bioinformatics/article/31/3/397/2366078">https://academic.oup.com/bioinformatics/article/31/3/397/2366078</a>.
Rohart F, Gautier B, Singh A, Cao KAL (2017).
&ldquo;mixOmics: An R package for ‚Äòomics feature selection and multiple data integration.&rdquo;
<em>PLoS Computational Biology</em>, <b>13</b>(11).
ISSN 15537358, <a href="https://pubmed.ncbi.nlm.nih.gov/29099853/">https://pubmed.ncbi.nlm.nih.gov/29099853/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsdrcox_dynamic(X, Y, n.comp = 3, vector = NULL, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='splsicox'>sPLS-ICOX</h2><span id='topic+splsicox'></span>

<h3>Description</h3>

<p>This function performs a sparse partial least squares individual Cox (sPLS-ICOX)
(based on plsRcox R package). The function returns a Coxmos model with the attribute model as
&quot;sPLS-ICOX&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>splsicox(
  X,
  Y,
  n.comp = 4,
  penalty = 0,
  x.center = TRUE,
  x.scale = FALSE,
  remove_near_zero_variance = TRUE,
  remove_zero_variance = FALSE,
  toKeep.zv = NULL,
  remove_non_significant = FALSE,
  alpha = 0.05,
  MIN_EPV = 5,
  returnData = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="splsicox_+3A_x">X</code></td>
<td>
<p>Numeric matrix or data.frame. Explanatory variables. Qualitative variables must be
transform into binary variables.</p>
</td></tr>
<tr><td><code id="splsicox_+3A_y">Y</code></td>
<td>
<p>Numeric matrix or data.frame. Response variables. Object must have two columns named as
&quot;time&quot; and &quot;event&quot;. For event column, accepted values are: 0/1 or FALSE/TRUE for censored and
event observations.</p>
</td></tr>
<tr><td><code id="splsicox_+3A_n.comp">n.comp</code></td>
<td>
<p>Numeric. Number of latent components to compute for the (s)PLS model (default: 10).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_penalty">penalty</code></td>
<td>
<p>Numeric. Penalty for variable selection for the individual cox models. Variables
with a lower P-Value than 1 - &quot;penalty&quot; in the individual cox analysis will be keep for the
sPLS-ICOX approach (default: 0).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_x.center">x.center</code></td>
<td>
<p>Logical. If x.center = TRUE, X matrix is centered to zero means (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_x.scale">x.scale</code></td>
<td>
<p>Logical. If x.scale = TRUE, X matrix is scaled to unit variances (default: FALSE).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_remove_near_zero_variance">remove_near_zero_variance</code></td>
<td>
<p>Logical. If remove_near_zero_variance = TRUE, near zero variance
variables will be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_remove_zero_variance">remove_zero_variance</code></td>
<td>
<p>Logical. If remove_zero_variance = TRUE, zero variance variables will
be removed (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_tokeep.zv">toKeep.zv</code></td>
<td>
<p>Character vector. Name of variables in X to not be deleted by (near) zero variance
filtering (default: NULL).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_remove_non_significant">remove_non_significant</code></td>
<td>
<p>Logical. If remove_non_significant = TRUE, non-significant
variables/components in final cox model will be removed until all variables are significant by
forward selection (default: FALSE).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_alpha">alpha</code></td>
<td>
<p>Numeric. Numerical values are regarded as significant if they fall below the
threshold (default: 0.05).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_min_epv">MIN_EPV</code></td>
<td>
<p>Numeric. Minimum number of Events Per Variable (EPV) you want reach for the final
cox model. Used to restrict the number of variables/components can be computed in final cox models.
If the minimum is not meet, the model cannot be computed (default: 5).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_returndata">returnData</code></td>
<td>
<p>Logical. Return original and normalized X and Y matrices (default: TRUE).</p>
</td></tr>
<tr><td><code id="splsicox_+3A_verbose">verbose</code></td>
<td>
<p>Logical. If verbose = TRUE, extra messages could be displayed (default: FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>sPLS-ICOX</code> function is an advanced analytical tool tailored for the elucidation of
high-dimensional survival data. It amalgamates the principles of sparse partial least squares
(sPLS) regression with individual Cox regression, thereby offering a robust mechanism for both
dimension reduction and variable selection in the context of survival analysis.
Rooted in the methodologies of the <code>plsRcox</code> R package, this function operationalizes the
sPLS-ICOX model by leveraging the inherent sparsity introduced via the <code>penalty</code> parameter.
This parameter delineates a stringent criterion for variable retention, wherein only those
variables that manifest a P-Value inferior to the threshold defined by <code>1 - penalty</code> in the
individual Cox analysis are assimilated into the sPLS-ICOX model framework.
The parameter <code>n.comp</code> demarcates the number of latent components to be computed for the sPLS
model. These latent components, which encapsulate salient patterns within the data, subsequently
underpin the Cox regression analysis. It is imperative to underscore the necessity of meticulous
data preprocessing, especially in the context of qualitative variables. Such variables necessitate
binary transformation prior to their integration into the function. Moreover, the function is
equipped with options for data centering and scaling, pivotal operations that can significantly
influence model performance.
Designed with a predilection for right-censored survival data, the function mandates the structuring
of the outcome or response variable <code>Y</code> into two distinct columns: &quot;time&quot;, which chronicles the
survival time, and &quot;event&quot;, which catalogues the occurrence or non-occurrence of the event of interest.
</p>
<p>Upon execution, the function yields a comprehensive list encapsulating a plethora of elements
germane to the sPLS-ICOX model, inclusive of the normalized data matrices, sPLS weight vectors,
loadings, scores, and an exhaustive compilation of survival model metrics.
</p>


<h3>Value</h3>

<p>Instance of class &quot;Coxmos&quot; and model &quot;sPLS-ICOX&quot;. The class contains the following elements:
<code>X</code>: List of normalized X data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(weightings)</code>: sPLS weights
</p>
</li>
<li> <p><code>(weightings_norm)</code>: sPLS normalize weights
</p>
</li>
<li> <p><code>(W.star)</code>: sPLS W* vector
</p>
</li>
<li> <p><code>(loadings)</code>: sPLS loadings
</p>
</li>
<li> <p><code>(scores)</code>: sPLS scores/variates
</p>
</li>
<li> <p><code>(E)</code>: error matrices
</p>
</li>
<li> <p><code>(x.mean)</code>: mean values for X matrix
</p>
</li>
<li> <p><code>(x.sd)</code>: standard deviation for X matrix
</p>
</li></ul>

<p><code>Y</code>: List of normalized Y data information.
</p>

<ul>
<li> <p><code>(data)</code>: normalized X matrix
</p>
</li>
<li> <p><code>(y.mean)</code>: mean values for Y matrix
</p>
</li>
<li> <p><code>(y.sd)</code>: standard deviation for Y matrix'
</p>
</li></ul>

<p><code>survival_model</code>: List of survival model information.
</p>

<ul>
<li> <p><code>fit</code>: coxph object.
</p>
</li>
<li> <p><code>AIC</code>: AIC of cox model.
</p>
</li>
<li> <p><code>BIC</code>: BIC of cox model.
</p>
</li>
<li> <p><code>lp</code>: linear predictors for train data.
</p>
</li>
<li> <p><code>coef</code>: Coefficients for cox model.
</p>
</li>
<li> <p><code>YChapeau</code>: Y Chapeau residuals.
</p>
</li>
<li> <p><code>Yresidus</code>: Y residuals.
</p>
</li></ul>

<p><code>n.comp</code>: Number of components selected.
</p>
<p><code>var_by_component</code>: Variables selected by each component.
</p>
<p><code>call</code>: call function
</p>
<p><code>X_input</code>: X input matrix
</p>
<p><code>Y_input</code>: Y input matrix
</p>
<p><code>alpha</code>: alpha value selected
</p>
<p><code>nsv</code>: Variables removed by cox alpha cutoff.
</p>
<p><code>nzv</code>: Variables removed by remove_near_zero_variance or remove_zero_variance.
</p>
<p><code>nz_coeffvar</code>: Variables removed by coefficient variation near zero.
</p>
<p><code>class</code>: Model class.
</p>
<p><code>time</code>: time consumed for running the cox analysis.
</p>


<h3>Author(s)</h3>

<p>Pedro Salguero Garcia. Maintainer: pedsalga@upv.edu.es
</p>


<h3>References</h3>

<p>Bastien P, Vinzi VE, Tenenhaus M (2005).
&ldquo;PLS generalised linear regression.&rdquo;
<em>Computational Statistics &amp; Data Analysis</em>.
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0167947304000271?via%3Dihub">https://www.sciencedirect.com/science/article/abs/pii/S0167947304000271?via%3Dihub</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
</code></pre>

<hr>
<h2 id='w.starplot.Coxmos'>w.starplot.Coxmos</h2><span id='topic+w.starplot.Coxmos'></span>

<h3>Description</h3>

<p>The <code>w.starplot.Coxmos</code> function offers a graphical representation of the W* (W star) values from
a given Coxmos model. Through this visualization, users can gain insights into the variable
contributions and their significance in the model. The function provides options for customization,
allowing users to focus on specific variables, exclude zero values, and adjust the visual limits.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>w.starplot.Coxmos(model, zero.rm = FALSE, top = NULL, auto.limits = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="w.starplot.Coxmos_+3A_model">model</code></td>
<td>
<p>Coxmos model.</p>
</td></tr>
<tr><td><code id="w.starplot.Coxmos_+3A_zero.rm">zero.rm</code></td>
<td>
<p>Logical. Remove variables equal to 0 (default: FALSE).</p>
</td></tr>
<tr><td><code id="w.starplot.Coxmos_+3A_top">top</code></td>
<td>
<p>Numeric. Show &quot;top&quot; first variables. If top = NULL, all variables are shown (default: NULL).</p>
</td></tr>
<tr><td><code id="w.starplot.Coxmos_+3A_auto.limits">auto.limits</code></td>
<td>
<p>Logical. If &quot;auto.limits&quot; = TRUE, limits are detected automatically (default: TRUE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>w.starplot.Coxmos</code> function is tailored to visualize the W* values, which are indicative of
the variable contributions in a Coxmos model. Initially, the function checks the class of the
provided model to ensure its compatibility with the Coxmos framework.
</p>
<p>The W* values are extracted from the model and subsequently processed based on user-defined
parameters. The <code>zero.rm</code> option allows users to exclude variables with zero W* values, ensuring
a more concise visualization. If the <code>top</code> parameter is specified, the function focuses on
displaying only the top-ranked variables based on their absolute W* values.
</p>
<p>The visualization is constructed using the 'ggplot2' framework. The color scale can be automatically
adjusted to the maximum absolute W* value when the <code>auto.limits</code> parameter is set to TRUE. The
function also checks for the availability of the <code>RColorConesa</code> package. If present, it leverages
its color palettes for a more refined visualization; in its absence, default color schemes are applied.
</p>


<h3>Value</h3>

<p>A list of <code>ggplot2</code> objects, each representing the W* values for a component of
the Coxmos model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("X_proteomic")
data("Y_proteomic")
X &lt;- X_proteomic[,1:50]
Y &lt;- Y_proteomic
splsicox.model &lt;- splsicox(X, Y, n.comp = 2, penalty = 0.5, x.center = TRUE, x.scale = TRUE)
w.starplot.Coxmos(model = splsicox.model)
</code></pre>

<hr>
<h2 id='wbw'>Function to select the bandwidth parameter needed for smoothing the time-dependent ROC curve.</h2><span id='topic+wbw'></span>

<h3>Description</h3>

<p>This function computes the data-driven bandwidth value for smoothing the ROC curve.
It contains three methods: the normal refrence, the plug-in and the cross-validation methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wbw(X, wt, bw = "NR", ktype = "normal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wbw_+3A_x">X</code></td>
<td>
<p>The numeric data vector.</p>
</td></tr>
<tr><td><code id="wbw_+3A_wt">wt</code></td>
<td>
<p>The non-negative weight vector.</p>
</td></tr>
<tr><td><code id="wbw_+3A_bw">bw</code></td>
<td>
<p>A character string specifying the bandwidth selection method. The possible options are &quot;<code>NR</code>&quot; for the normal reference, the plug-in &quot;<code>PI</code>&quot; and cross-validation &quot;<code>CV</code>&quot;.</p>
</td></tr>
<tr><td><code id="wbw_+3A_ktype">ktype</code></td>
<td>
<p>A character string indicating the type of kernel function: &quot;<code>normal</code>&quot;, &quot;<code>epanechnikov</code>&quot;, &quot;<code>biweight</code>&quot;, or &quot;<code>triweight</code>&quot;. Default is &quot;<code>normal</code>&quot; kernel.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the estimated value for the bandwith parameter.
</p>


<h3>Author(s)</h3>

<p>Kassu Mehari Beyene, Catholic University of Louvain. <code>&lt;kasu.beyene@uclouvain.be&gt;</code>
</p>
<p>Anouar El Ghouch, Catholic University of Louvain. <code>&lt;anouar.elghouch@uclouvain.be&gt;</code>
</p>


<h3>References</h3>

<p>Beyene, K. M. and El Ghouch A. (2020). Smoothed time-dependent ROC curves for right-censored survival data. <em>submitted</em>.
</p>

<hr>
<h2 id='wIQR'>Weighted inter-quartile range estimation</h2><span id='topic+wIQR'></span>

<h3>Description</h3>

<p>Weighted inter-quartile range estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wIQR(X, wt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wIQR_+3A_x">X</code></td>
<td>
<p>The numeric data vector.</p>
</td></tr>
<tr><td><code id="wIQR_+3A_wt">wt</code></td>
<td>
<p>The non-negative weight vector.</p>
</td></tr>
</table>

<hr>
<h2 id='wquantile'>Weighted quartile estimation</h2><span id='topic+wquantile'></span>

<h3>Description</h3>

<p>Weighted quartile estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wquantile(X, wt, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wquantile_+3A_x">X</code></td>
<td>
<p>The numeric data vector.</p>
</td></tr>
<tr><td><code id="wquantile_+3A_wt">wt</code></td>
<td>
<p>The non-negative weight vector.</p>
</td></tr>
<tr><td><code id="wquantile_+3A_p">p</code></td>
<td>
<p>The percentile value. The default is 0.5.</p>
</td></tr>
</table>

<hr>
<h2 id='wvar'>Weighted variance estimation</h2><span id='topic+wvar'></span>

<h3>Description</h3>

<p>Weighted variance estimation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wvar(X, wt, na.rm = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wvar_+3A_x">X</code></td>
<td>
<p>The numeric data vector.</p>
</td></tr>
<tr><td><code id="wvar_+3A_wt">wt</code></td>
<td>
<p>The non-negative weight vector.</p>
</td></tr>
<tr><td><code id="wvar_+3A_na.rm">na.rm</code></td>
<td>
<p>The character indicator wether to consider missing value(s) or not. The default is FALSE.</p>
</td></tr>
</table>

<hr>
<h2 id='X_multiomic'>X_multiomic Data</h2><span id='topic+X_multiomic'></span>

<h3>Description</h3>

<p>Toy dataset from BREAST CANCER. miRNA and Protein data. (https://github.com/pilargmarch/multiomics2.0/tree/main)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X_multiomic
</code></pre>


<h3>Format</h3>

<p>A data frame with 150 observations and two omics (miRNA and proteomic):
</p>
<p>642 miRNAs, 369 proteins
</p>


<h3>Source</h3>

<p>TCGA-BRCA data
</p>

<hr>
<h2 id='X_proteomic'>X_proteomic Data</h2><span id='topic+X_proteomic'></span>

<h3>Description</h3>

<p>Toy dataset from BREAST CANCER. Protein data. (https://github.com/pilargmarch/multiomics2.0/tree/main)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>X_proteomic
</code></pre>


<h3>Format</h3>

<p>A data frame with 150 observations and 369 features:
</p>
<p>Small data set from original data (585 observations).
</p>


<h3>Source</h3>

<p>TCGA-BRCA data
</p>

<hr>
<h2 id='Y_multiomic'>Y_multiomic Data</h2><span id='topic+Y_multiomic'></span>

<h3>Description</h3>

<p>Toy dataset from BREAST CANCER. miRNA and Protein data. (https://github.com/pilargmarch/multiomics2.0/tree/main)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Y_multiomic
</code></pre>


<h3>Format</h3>

<p>A data frame with 150 observations and 2 features:
</p>

<dl>
<dt>time</dt><dd><p>Global survival time in years. Time to the event of to the last patient information.</p>
</dd>
<dt>event</dt><dd><p>Numeric. FALSE/0 for censored and TRUE/1 for event observations.</p>
</dd>
</dl>



<h3>Source</h3>

<p>TCGA-BRCA data
</p>

<hr>
<h2 id='Y_proteomic'>Y_proteomic Data</h2><span id='topic+Y_proteomic'></span>

<h3>Description</h3>

<p>Toy dataset from BREAST CANCER. Protein data. (https://github.com/pilargmarch/multiomics2.0/tree/main)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Y_proteomic
</code></pre>


<h3>Format</h3>

<p>A data frame with 150 observations and 2 features:
</p>

<dl>
<dt>time</dt><dd><p>Global survival time in years. Time to the event of to the last patient information.</p>
</dd>
<dt>event</dt><dd><p>Numeric. FALSE/0 for censored and TRUE/1 for event observations.</p>
</dd>
</dl>



<h3>Source</h3>

<p>TCGA-BRCA data
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
