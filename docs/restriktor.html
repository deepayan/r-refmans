<!DOCTYPE html><html lang="en"><head><title>Help for package restriktor</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {restriktor}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#restriktor-package'><p>Package for equality and inequality restricted estimation, model selection and hypothesis testing</p></a></li>
<li><a href='#AngerManagement'>
<p>Reduction of aggression levels Dataset (4 treatment groups)</p></a></li>
<li><a href='#benchmark_functions'><p>Benchmark Functions for GORIC(A) Analysis</p></a></li>
<li><a href='#bootstrapD'><p>Bootstrapping a Lavaan Model</p></a></li>
<li><a href='#Burns'>
<p>Relation between the response variable PTSS and gender, age, TBSA, guilt and anger.</p></a></li>
<li><a href='#calculate_IC_weights'><p>Calculating IC weights based on IC values (AIC, ORIC, GORIC(A), BIC, SIC, ...)</p></a></li>
<li><a href='#con_weights_boot'><p>function for computing the chi-bar-square weights based on</p>
Monte Carlo simulation.</a></li>
<li><a href='#conTest_ceq'><p>Tests for iht with equality constraints only</p></a></li>
<li><a href='#conTest_summary'><p>function for computing all available hypothesis tests</p>
</p></a></li>
<li><a href='#conTestC'><p>one-sided t-test for iht</p></a></li>
<li><a href='#conTestF'><p>F-bar test for iht</p></a></li>
<li><a href='#conTestLRT'><p>Likelihood-ratio-bar test for iht</p></a></li>
<li><a href='#conTestScore'><p>Score-bar test for iht</p></a></li>
<li><a href='#conTestWald'><p>Wald-bar test for robust iht</p></a></li>
<li><a href='#evSyn'><p>GORIC(A) Evidence synthesis</p></a></li>
<li><a href='#Exam'>
<p>Relation between exam scores and study hours, anxiety scores and average point scores.</p></a></li>
<li><a href='#FacialBurns'><p>Dataset for illustrating the conTest_conLavaan function.</p></a></li>
<li><a href='#goric'><p>Generalized Order-Restricted Information Criterion (Approximation) Weights</p></a></li>
<li><a href='#Hurricanes'>
<p>The Hurricanes Dataset</p></a></li>
<li><a href='#iht'><p>function for informative hypothesis testing (iht)</p></a></li>
<li><a href='#iht-methods'><p>Methods for iht</p></a></li>
<li><a href='#myGORICs'><p>An example of IC values</p></a></li>
<li><a href='#myLLs'><p>An example of log-likelihood (LL) values</p></a></li>
<li><a href='#myPTs'><p>An example of penalty (PT) values</p></a></li>
<li><a href='#restriktor'><p>Estimating linear regression models with (in)equality restrictions</p></a></li>
<li><a href='#restriktor-methods'><p>Methods for restriktor</p></a></li>
<li><a href='#ZelazoKolb1972'>
<p>&quot;Walking&quot; in the newborn (4 treatment groups)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Restricted Statistical Estimation and Inference for Linear
Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.6-10</td>
</tr>
<tr>
<td>Description:</td>
<td>Allow for easy-to-use testing or evaluating of linear equality and inequality restrictions about parameters and effects in (generalized) linear statistical models.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R(&ge; 4.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>boot, lavaan(&ge; 0.6-10), MASS, mvtnorm, tmvtnorm, quadprog,
norm, ggplot2, future, future.apply, progressr, scales,
gridExtra</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://restriktor.org">https://restriktor.org</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-12-19 14:54:59 UTC; l.vanbrabant</td>
</tr>
<tr>
<td>Author:</td>
<td>Leonard Vanbrabant [aut, cre],
  Rebecca Kuiper [aut],
  Yves Rosseel [ctb],
  Aleksandra Dacko [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Leonard Vanbrabant &lt;info@restriktor.org&gt;</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, bain, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-12-19 15:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='restriktor-package'>Package for equality and inequality restricted estimation, model selection and hypothesis testing</h2><span id='topic+restriktor-package'></span>

<h3>Description</h3>

<p>Package <code>restriktor</code> implements estimation, testing and evaluating of linear equality and 
inequality restriktions about parameters and effects for univariate and multivariate 
normal models and generalized linear models.</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
  Package: </td><td style="text-align: left;"> restriktor</td>
</tr>
<tr>
 <td style="text-align: left;">
  Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
  Version: </td><td style="text-align: left;"> 0.6-10</td>
</tr>
<tr>
 <td style="text-align: left;">
  Date: </td><td style="text-align: left;"> 2024-12-19</td>
</tr>
<tr>
 <td style="text-align: left;">
  License: </td><td style="text-align: left;"> GPL (&gt;=2)</td>
</tr>
<tr>
 <td style="text-align: left;">
  LazyLoad: </td><td style="text-align: left;"> yes</td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>

<p>Function <code>restriktor</code> estimates the parameters of an univariate
and multivariate linear model (<code>lm</code>), robust estimation of the 
linear model (<code>rlm</code>) or a generalized linear model (<code>glm</code>) 
subject to linear equality and/or inequality restriktions. The real 
work horses are the <code>conLM</code>, <code>conMLM</code>, the <code>conRLM</code>, 
and the <code>conGLM</code> functions. A major advantage of <span class="pkg">restriktor</span> 
is that the constraints can be specified by a text-based description. 
This means that users do not have to specify the complex constraint matrix 
(comparable with a contrast matrix) themselves. 
</p>
<p>The function <code>restriktor</code> offers the possibility to compute 
(model robust) standard errors under the restriktions. The 
parameter estimates can also be bootstrapped, where bootstrapped 
standard errors and confidence intervals are available via the 
summary function. Moreover, the function computes the Generalized 
Order-restricted Information Criterion (GORIC), which is a 
modification of the AIC and a generalization of the ORIC.
</p>
<p>The function <code>iht</code> (alias <code>conTest</code>) conducts restricted 
hypothesis tests. F, Wald/LRT and score test-statistics are available. 
The null-distribution of these test-statistics takes the form of a 
mixture of F-distributions. The mixing weights (a.k.a. chi-bar-square 
weights or level probabilities) can be computed using the multivariate 
normal distribution function with additional Monte Carlo steps or via 
a simulation approach. Bootstrap methods are available to calculate the 
mixing weights and to compute the p-value directly. Parameters estimates 
under the null- and alternative-hypothesis are available from the 
summary function. 
</p>
<p>The function <code>goric</code> (generalized order-restricted information
criterion) computes GORIC values, weights and relative-weights or GORICA
(generalized order-restricted information crittion approximation) values,
weights and relative weights. The GORIC(A) values are comparable to the AIC 
values. The function offers the possibility to evaluate an order-restricted 
hypothesis against its complement, the unconstrained hypothesis or against
a set of hypotheses. For now, only one order-restricted hypothesis can be 
evaluated against its complement but work is in progress to evaluate a set 
of order-restricted hypothesis against its complement. 
</p>
<p>The package makes use of various other R packages: <span class="pkg">quadprog</span> 
is used for restricted estimation, <span class="pkg">boot</span> for bootstrapping, 
<span class="pkg">ic.infer</span> for computing the mixing weights based on the 
multivariate normal distribution, <span class="pkg">lavaan</span> for parsing the 
constraint syntax. 
</p>


<h3>Value</h3>

<p>The output of function <code>restriktor</code> belongs to S3 class 
<code>conLM</code>, <code>conMLM</code>, <code>conRLM</code> or <code>conGLM</code>.  
</p>
<p>The output of function <code>conTest</code> belongs to S3 class <code>conTest</code>. 
</p>
<p>These classes offer print and summary methods. 
</p>


<h3>Acknowledgements</h3>

<p>This package uses as an internal function the function 
<code>nchoosek</code> from <span class="pkg">ic.infer</span>, which is originally from 
<span class="pkg">vsn</span>, authored by Wolfgang Huber, available under LGPL. 
</p>
<p>The output style of the <code>iht</code> print function is strongly 
inspired on the summary of the <code>ic.test</code> function from the 
<span class="pkg">ic.infer</span> package.
</p>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel - Ghent University</p>


<h3>References</h3>

<p>Groemping, U. (2010). Inference With Linear Equality And Inequality
Constraints Using R: The Package ic.infer. <em>Journal of Statistical 
Software</em>, Forthcoming. 
</p>
<p>Kuiper R.M., Hoijtink H., Silvapulle M.J. (2011). An Akaike-type Information
Criterion for Model Selection Under Inequality Constraints. <em>Biometrika</em>, 
<b>98</b>, 495&ndash;501.
</p>
<p>Kuiper R.M., Hoijtink H., Silvapulle M.J. (2012). Generalization of the 
Order-Restricted Information Criterion for Multivariate Normal Linear Models. 
<em>Journal of Statistical Planning and Inference</em>, <b>142</b>, 2454&ndash;2463. 
doi:10.1016/j.jspi.2012.03.007.
</p>
<p>Robertson T, Wright F, Dykstra R (1988). <em>Order-Restricted Inference</em>. 
Wiley, New York.
</p>
<p>Schoenberg, R. (1997). Constrained Maximum Likelihood. <em>Computational 
Economics</em>, <b>10</b>, 251&ndash;266.
</p>
<p>Shapiro, A. (1988). Towards a unified theory of inequality-constrained 
testing in multivariate analysis. <em>International Statistical Review</em> 
<b>56</b>, 49&ndash;62.
</p>
<p>Silvapulle, M. (1992a). Robust tests of inequality constraints and one-sided 
hypotheses in the linear model. <em>Biometrika</em>, <b>79</b>, 621&ndash;630.
</p>
<p>Silvapulle, M. (1992b). Robust wald-type tests of one-sided hypotheses in 
the linear model. <em>Journal of the American Statistical Association</em>, 
<b>87</b>, 156&ndash;161.
</p>
<p>Silvapulle, M. (1996). Robust bounded influence tests against one-sided 
hypotheses in general parametric models. <em>Statistics and probability 
letters</em>, <b>31</b>, 45&ndash;50.
</p>
<p>Silvapulle, M.J. and Sen, P.K. (2005). <em>Constrained Statistical Inference</em>. 
Wiley, New York
</p>
<p>Vanbrabant, L., Van Loey, N., and Kuiper, R.M. (2020). Evaluating a theory-based 
hypothesis against its complement using an AIC-type information criterion with 
an application to facial burn injury. <em>Psychological methods</em>, <b>25(2)</b>,
129-142. https://doi.org/10.1037/met0000238.
</p>


<h3>See Also</h3>

 
<p>See also <code><a href="#topic+restriktor">restriktor</a></code>, <code><a href="#topic+iht">iht</a></code>, 
packages <span class="pkg">boot</span>, <span class="pkg">goric</span>, <span class="pkg">ic.infer</span>, 
<span class="pkg">mvtnorm</span>, and <span class="pkg">quadprog</span>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Data preparation
## Ages (in months) at which an infant starts to walk alone.
DATA &lt;- ZelazoKolb1972
DATA &lt;- subset(DATA, Group != "Control")

## unrestricted linear model 
fit.lm &lt;- lm(Age ~ -1 + Group, data = DATA)
summary(fit.lm)

## restricted linear model with restrictions that the walking 
## exercises would not have a negative effect of increasing the 
## mean age at which a child starts to walk. 

myConstraints &lt;- ' GroupActive  &lt; GroupPassive; 
                   GroupPassive &lt; GroupNo '
                   
fit.con &lt;- restriktor(fit.lm, constraints = myConstraints)
summary(fit.con)

</code></pre>

<hr>
<h2 id='AngerManagement'>
Reduction of aggression levels Dataset (4 treatment groups)
</h2><span id='topic+AngerManagement'></span>

<h3>Description</h3>

<p>The anger management dataset consists of reduction of aggression levels
between week 1 (intake) and week 8 (end of training) from four 
different treatment groups (No-exercises, Physical-exercises, 
Behavioral-exercises, combination of physical and behavioral
exercises). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(AngerManagement)</code></pre>


<h3>Format</h3>

<p>A data frame of 40 observations of 4 treatment variables and covariate age.
</p>

<dl>
<dt><code>Anger</code></dt><dd><p>reduction in aggression levels</p>
</dd>
<dt><code>Group</code></dt><dd><p>No, Physical, Behavioral, Both</p>
</dd>
<dt><code>Age</code></dt><dd><p>persons' age</p>
</dd>
</dl>



<h3>References</h3>

<p>Hoijtink, H. Informative Hypotheses: Theory and Practice 
for Behavioral and Social Scientists Boca Raton, FL: Taylor &amp; Francis, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  head(AngerManagement)
</code></pre>

<hr>
<h2 id='benchmark_functions'>Benchmark Functions for GORIC(A) Analysis</h2><span id='topic+benchmark'></span><span id='topic+benchmark_means'></span><span id='topic+benchmark_asymp'></span><span id='topic+print.benchmark'></span><span id='topic+plot.benchmark'></span>

<h3>Description</h3>

<p>The 'benchmark' functions perform benchmarking for models using the 
Generalized Order-Restricted Information Criterion (Approximation) (GORIC(A)). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  benchmark(object, model_type = c("asymp", "means"), ...)
  
  benchmark_means(object, pop_es = NULL, ratio_pop_means = NULL, 
                  group_size = NULL, alt_group_size = NULL, 
                  quant = NULL, iter = 1000, 
                  control = list(), 
                  ncpus = 1, seed = NULL, ...)

  benchmark_asymp(object, pop_est = NULL, sample_size = NULL, 
                  alt_sample_size = NULL, quant = NULL, iter = 1000, 
                  control = list(), 
                  ncpus = 1, seed = NULL, ...)
  
  ## S3 method for class 'benchmark'
print(x, output_type = c("rgw", "gw", "rlw", "ld", "all"), 
                            hypo_rate_threshold = 1, color = TRUE, ...)
  
  ## S3 method for class 'benchmark'
plot(x, output_type = c("rgw", "rlw", "gw", "ld"), 
                           percentiles = NULL, x_lim = c(), log_scale = FALSE,
                           alpha = 0.50, nrow_grid = NULL, ncol_grid = 1, 
                           distr_grid = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="benchmark_functions_+3A_object">object</code></td>
<td>
<p>An object of class <code>con_goric</code> (a GORIC(A) object from the <code>goric</code> function).</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_model_type">model_type</code></td>
<td>
<p>If &quot;means&quot;, the model parameters reflect (adjusted) means, else
model_type = &quot;asymp&quot; (default). See details for more information about <code>asymp</code>.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_x">x</code></td>
<td>
<p>An object of class <code>benchmark</code> or <code>benchmark</code>.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_pop_es">pop_es</code></td>
<td>
<p>A scalar or a vector of population Cohen's f (effect-size) values. 
By default, it benchmarks ES = 0 (no-effect) and the observed Cohen's f.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_pop_est">pop_est</code></td>
<td>
<p>A 1 x k vector or an n x k matrix of population 
estimates to benchmark. By default, all estimates are set to zero (no-effect) 
and the observed estimates from the sample are used.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_ratio_pop_means">ratio_pop_means</code></td>
<td>
<p>A 1 x k vector denoting the relative difference
between the k group means. Note that a ratio of <code>c(3, 2, 1)</code> gives the 
same as <code>c(1, 0, -1)</code>, as the consecutive relative differences are 1 in 
both ratios. By default, the relative differences from the data are used.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_group_size">group_size</code></td>
<td>
<p>If the GORICA object is based on estimates and their covariance 
matrix (instead of on a model/fit object), this should be a 1 x k vector 
or a scalar to denote the group sizes. If a scalar is specified, it is assumed 
that each group is of that size.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_alt_group_size">alt_group_size</code></td>
<td>
<p>An 1 x k vector or a scalar to denote alternative 
group sizes, if you want to use sizes different from those in the data. This 
can be used, for example, to see the values to which the GORIC(A) weights will 
converge (and thus to see the maximum value of the weights). If a scalar is 
specified, it is assumed that each group is of that size. By default, the group 
sizes from the data are used.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_sample_size">sample_size</code></td>
<td>
<p>A scalar to denote the (total) sample sizes. Only used if 
the GORIC object is based on estimates and their covariance matrix (instead 
of on a model/fit object) or <code>alt_sample_size</code> is not <code>NULL</code>. </p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_alt_sample_size">alt_sample_size</code></td>
<td>
<p>A scalar to denote an alternative sample size if you 
want to use a different sample size from the one in the data. This can be used, 
for example, to see the values to which the GORIC(A) weights will converge 
(and thus to see the maximum value of the weights).</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_quant">quant</code></td>
<td>
<p>Quantiles for benchmarking results. Defaults 5%, 35%, 50%, 65%, 95%.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_iter">iter</code></td>
<td>
<p>The number of iterations for benchmarking. Defaults to <code>1000</code>.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_hypo_rate_threshold">hypo_rate_threshold</code></td>
<td>
<p>A numeric value specifying the threshold for the 
hypothesis rate. The function calculates the proportion of ratio-of-goric-weights 
that exceeds this threshold. Defaults to 1.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_control">control</code></td>
<td>
<p>A list of control parameters.For more information, see details <a href="#topic+goric">goric</a>.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_ncpus">ncpus</code></td>
<td>
<p>Number of CPUs to use for parallel processing. Defaults to <code>1</code>.
See details for more information.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_seed">seed</code></td>
<td>
<p>A seed for random number generation.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_output_type">output_type</code></td>
<td>
<p>A character vector specifying the type of output to print 
or plot. Options are <code>"all"</code>, <code>"gw"</code> (goric(a) weights), 
<code>"rgw"</code> (ratio of goric(a) weights), <code>"rlw"</code> (ratio of log-likelihood values), 
and <code>"ld"</code> (log-likelihood difference). Defaults to <code>"rgw"</code> for print 
and <code>"rgw"</code> for plot.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_color">color</code></td>
<td>
<p>If TRUE, the output will include ANSI color coding. Set <code>color = FALSE</code> 
when using this function in R Markdown documents to avoid rendering issues with color codes.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_alpha">alpha</code></td>
<td>
<p>Alpha refers to the opacity of a geom. Values of alpha range from 0 to 1, with lower values corresponding to more transparent colors.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_nrow_grid">nrow_grid</code></td>
<td>
<p>An integer value representing the number of rows in the grid layout.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_ncol_grid">ncol_grid</code></td>
<td>
<p>An integer value representing the number of columns in the grid layout.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_distr_grid">distr_grid</code></td>
<td>
<p>If TRUE, the facet_grid function is used to create a grid of separate plots for each effect-size (estimates).</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_percentiles">percentiles</code></td>
<td>
<p>A numeric vector specifying the percentiles to be shown. By default 
the percentiles are inherited from the quantiles used for benchmarking, see <code>quant</code>.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_x_lim">x_lim</code></td>
<td>
<p>A numeric vector of length 2 specifying the x-axis limits. Defaults to <code>c()</code>.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_log_scale">log_scale</code></td>
<td>
<p>logical, If TRUE, The x-axis is transformed using a base-10 logarithmic scale.
This transformation adjusts the way the data is visualized on the x-axis, but does not 
alter the underlying data values themselves.</p>
</td></tr>
<tr><td><code id="benchmark_functions_+3A_...">...</code></td>
<td>
<p>See <a href="#topic+goric">goric</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>benchmark_asymp</code> is named as such because it generates data from a 
multivariate normal distribution with means equal to the population parameter 
estimates and a covariance matrix derived from the original data. This is based 
on the assumption that parameter estimates are asymptotically normally distributed. 
This assumption is valid for many statistical models, including parameters from 
a generalized linear model (GLM). In such models, as the sample size increases, 
the distribution of the parameter estimates tends to a normal distribution, 
allowing us to utilize the multivariate normal distribution for benchmarking.
</p>
<p><code>benchmark_means</code> benchmarks the group means of a given GORIC(A) object 
by evaluating various population effect sizes and comparing the observed 
group means against these benchmarks.
<code>benchmark_asymp</code> benchmarks the population estimates of a given 
GORIC(A) object by evaluating various population estimates and comparing them 
against the observed estimates.
</p>
<p><code>print.benchmark</code> prints the results of benchmark analyses performed on 
objects of class <code>benchmark</code>.
</p>
<p><code>plot.benchmark</code> generates density plots for benchmark analyses of objects 
of class <code>benchmark</code>. 
</p>
<p>The benchmark function leverages the <span class="pkg">future</span> package for parallel processing, 
allowing users to speed up computations by distributing tasks across multiple 
cores or machines. If the user does not specify a parallelization plan using 
<code>future::plan()</code>, the package will choose an appropriate strategy based 
on the user's operating system. Specifically, on Windows, the package defaults 
to using <code>multisession</code>, which creates separate R sessions for each 
parallel task. On Unix-like systems (such as Linux and macOS), the package 
defaults to <code>multicore</code>, which uses forked R processes to avoid the 
overhead of setting up separate R sessions.
</p>
<p>The <code>plan()</code> must be specified before running the benchmark function, e.g.,
<code>future::plan(future::multisession, workers = ncpus)</code>
</p>


<h3>Value</h3>

<p><code>benchmark_means</code> and <code>benchmark_asymp</code> return a list of 
class <code>benchmark_means</code>, <code>benchmark</code>, and <code>list</code> or 
<code>benchmark_asymp</code>, <code>benchmark</code>, and <code>list</code> containing the 
results of the benchmark analysis.
</p>
<p><code>print.benchmark</code> does not return a value. It prints formatted benchmark 
analysis results to the console.
</p>
<p><code>plot.benchmark</code> returns a gtable object that can be displayed or further 
customized using various functions from the gridExtra and grid packages. This 
allows for flexible and detailed adjustments to the appearance and layout of the plot.
</p>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Rebecca Kuiper</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1234)
# Generate data for 4 groups with different group sizes
group1 &lt;- rnorm(10, mean = 5, sd = 0.1)
group2 &lt;- rnorm(20, mean = 5.5, sd = 1)
group3 &lt;- rnorm(30, mean = 6, sd = 0.5)
group4 &lt;- rnorm(40, mean = 6.5, sd = 0.8)

# Combine data into a data frame
data &lt;- data.frame(
  value = c(group1, group2, group3, group4),
  group = factor(rep(1:4, times = c(10,20,30,40)))
)

# Perform ANOVA
anova_result &lt;- aov(value ~ -1 + group, data = data)

# model/hypothesis
h1 &lt;- 'group1 &lt; group2 &lt; group3 &lt; group4'
h2 &lt;- 'group1 &gt; group2 &lt; group3 &lt; group4'

# fit h1 and h2 model against the unconstrained model (i.e., failsafe to avoid
# selecting a weak hypothesis)
fit_goric &lt;- goric(anova_result, hypotheses = list(H1 = h1, H2 = h2), 
                   comparison = "unconstrained", type = "goric")

# by default: ES = 0 \&amp; ES = observed ES
# In practice you want to increase the number of iterations (default = 1000).

# multisession supports windows machines
# future::plan(future::multisession, workers = ncpus)
benchmark_results_mean &lt;- benchmark(fit_goric, iter = 10, model_type = "means")
print(benchmark_results_mean)


# by default the ratio of GORIC weights for the preferred hypothesis (here h1) is
# plotted against its competitors (i.e., h2 and the unconstrained). To improve
# the readability of the plot, the argument hypothesis_comparison can be used to
# focus on a specif competitor. Further readability can be achieved by setting
# the x_lim option. 
plot(benchmark_results_mean, output_type = "rgw")

# specify custom effect-sizes

benchmark_results_mean_es &lt;- benchmark(fit_goric, iter = 10,
                                       pop_es = c(0, 0.1),
                                       model_type = "means")
print(benchmark_results_mean_es)  
  

# Benchmark asymptotic estimates

fit_gorica &lt;- goric(anova_result, hypotheses = list(h1=h1), 
                    comparison = "complement", type = "gorica")

# by default: no-effect \&amp; estimates from the sample are used
benchmark_results_asymp &lt;- benchmark(fit_gorica, sample_size = 30, iter = 5,
                                     model_type = "asymp")
print(benchmark_results_asymp)



# specify custom population estimates
my_pop_est &lt;- rbind("no" = c(0,0,0,0), "observed"= coef(anova_result))

benchmark_results_asymp &lt;- benchmark(fit_gorica, sample_size = 30, 
                                     iter = 5, pop_est = my_pop_est,
                                     model_type = "asymp")
print(benchmark_results_asymp)
plot(benchmark_results_asymp, x_lim = c(0, 75))

</code></pre>

<hr>
<h2 id='bootstrapD'>Bootstrapping a Lavaan Model</h2><span id='topic+bootstrapD'></span><span id='topic+print.conTestLavaan'></span>

<h3>Description</h3>

<p>Bootstrap the D statistic.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  bootstrapD(h0 = NULL, h1 = NULL, constraints, type = "A", 
             bootstrap.type = "bollen.stine", R = 1000L,  
             return.D = FALSE, double.bootstrap = "no", 
             double.bootstrap.R = 500L, double.bootstrap.alpha = 0.05, 
             verbose = FALSE, warn = -1L, 
             parallel = c("no", "multicore", "snow"), ncpus = 1L, cl = NULL, 
             seed = NULL)
             
  ## S3 method for class 'conTestLavaan'
print(x, digits = max(3, getOption("digits") - 2), ...)
</code></pre>


<h3>Arguments</h3>

 
<table role = "presentation">
<tr><td><code id="bootstrapD_+3A_h0">h0</code></td>
<td>
<p>An object of class <code>lavaan</code>. The restricted model.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_h1">h1</code></td>
<td>
<p>An object of class <code>lavaan</code>. The unrestricted model.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_x">x</code></td>
<td>
<p>an object of class <code>conTestLavaan</code>.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_constraints">constraints</code></td>
<td>
<p>The imposed (in)equality constraints on the model.</p>
</td></tr>  
<tr><td><code id="bootstrapD_+3A_type">type</code></td>
<td>
<p>hypothesis test type &quot;A&quot;, &quot;B&quot;.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_bootstrap.type">bootstrap.type</code></td>
<td>
<p>If <code>"parametric"</code>, the parametric bootstrap is used. 
If <code>"bollen.stine"</code>, the semi-nonparametric Bollen-Stine bootstrap 
is used. The default is set to <code>"bollen.stine"</code>.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_r">R</code></td>
<td>
<p>Integer. The number of bootstrap draws.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_return.d">return.D</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the function returns bootstrapped         
D-values.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_double.bootstrap">double.bootstrap</code></td>
<td>
<p>If <code>"standard"</code> (default) the genuine double bootstrap is 
used to compute an additional set of plug-in p-values for each bootstrap       
sample. If <code>"no"</code>, no double bootstrap is used. If <code>"FDB"</code>, 
the fast double bootstrap is used to compute second level LRT-values for 
each bootstrap sample. Note that the <code>"FDB"</code> is experimental and should 
not be used by inexperienced users.</p>
</td></tr>    
<tr><td><code id="bootstrapD_+3A_double.bootstrap.r">double.bootstrap.R</code></td>
<td>
<p>Integer; number of double bootstrap draws. The default 
value is set to 249.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_double.bootstrap.alpha">double.bootstrap.alpha</code></td>
<td>
<p>The significance level to compute the adjusted 
alpha based on the plugin p-values. Only used if <code>double.bootstrap = "standard"</code>. 
The default value is set to 0.05.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, show information for each bootstrap draw.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_warn">warn</code></td>
<td>
<p>Sets the handling of warning messages. See <code><a href="base.html#topic+options">options</a></code>.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_parallel">parallel</code></td>
<td>
<p>The type of parallel operation to be used (if any).  If
missing, the default is <code>"no"</code>.  </p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_ncpus">ncpus</code></td>
<td>
<p>Integer: number of processes to be used in parallel operation:
typically one would chose this to the number of available CPUs.  </p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_cl">cl</code></td>
<td>
<p>An optional <span class="pkg">parallel</span> or <span class="pkg">snow</span> cluster for use if
<code>parallel = "snow"</code>.  If not supplied, a cluster on the local machine is
created for the duration of the <code>bootstrapLavaan</code> or <code>bootstrapLRT</code>
call.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>  
<tr><td><code id="bootstrapD_+3A_...">...</code></td>
<td>
<p>no additional arguments for now.</p>
</td></tr>
<tr><td><code id="bootstrapD_+3A_seed">seed</code></td>
<td>
<p>An integer to set the seed. Or NULL if no reproducible seeds are
needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A bootstrap p value, calculated as the proportion of bootstrap samples with a D statistic at least as large as the D statistic for the original data.
</p>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant</p>


<h3>References</h3>

<p>Bollen, K. and Stine, R. (1992) Bootstrapping Goodness of Fit Measures in
Structural Equation Models. Sociological Methods and Research, 21,
205&ndash;229.
</p>
<p>Silvapulle, M.J. and Sen, P.K. (2005). <em>Constrained 
Statistical Inference</em>. Wiley, New York
</p>
<p>Yuan, K.-H., Hayashi, K., and Yanagihara, H. (2007). A class of population
covariance matrices in the bootstrap approach to covariance structure analysis.
Multivariate Behavioral Research, 42, 261&ndash;281.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#########################
### real data example ###
#########################
# Multiple group path model for facial burns example.

# model syntax with starting values.
burns.model &lt;- 'Selfesteem ~ Age + c(m1, f1)*TBSA + HADS +
                           start(-.10, -.20)*TBSA  
             HADS ~ Age + c(m2, f2)*TBSA + RUM +
                    start(.10, .20)*TBSA '


# constraints syntax
burns.constraints &lt;- 'f2 &gt; 0  ; m1 &lt; 0
                      m2 &gt; 0  ; f1 &lt; 0
                      f2 &gt; m2 ; f1 &lt; m1'

# we only generate 2 bootstrap samples in this example; in practice
# you may wish to use a much higher number. 
# the double bootstrap was switched off; in practice you probably 
# want to set it to "standard".
example1 &lt;- conTestD(model = burns.model, data = FacialBurns,
                     R = 2, constraints = burns.constraints,
                     double.bootstrap = "no", group = "Sex")

example1

##########################
### artificial example ###
##########################

# Simple ANOVA model with 3 groups (N = 20 per group)
set.seed(1234)
Y &lt;- cbind(c(rnorm(20,0,1), rnorm(20,0.5,1), rnorm(20,1,1)))
grp &lt;- c(rep("1", 20), rep("2", 20), rep("3", 20))
Data &lt;- data.frame(Y, grp)

#create model matrix
fit.lm &lt;- lm(Y ~ grp, data = Data)
mfit &lt;- fit.lm$model
mm &lt;- model.matrix(mfit)

Y &lt;- model.response(mfit)
X &lt;- data.frame(mm[,2:3])
names(X) &lt;- c("d1", "d2")
Data.new &lt;- data.frame(Y, X)

# model
model &lt;- 'Y ~ 1 + a1*d1 + a2*d2'

# fit without constraints
fit &lt;- lavaan::sem(model, data = Data.new)

# constraints syntax: mu1 &lt; mu2 &lt; mu3
constraints &lt;- ' a1 &gt; 0
                 a1 &lt; a2 '

# we only generate 10 bootstrap samples in this example; in practice
# you may wish to use a much higher number, say &gt; 1000. The double 
# bootstrap is not necessary in case of an univariate ANOVA model.
example2 &lt;- conTestD(model = model, data = Data.new, 
                     start = lavaan::parTable(fit),
                     R = 10L, double.bootstrap = "no",
                     constraints = constraints)
example2

</code></pre>

<hr>
<h2 id='Burns'> 
Relation between the response variable PTSS and gender, age, TBSA, guilt and anger.
</h2><span id='topic+Burns'></span>

<h3>Description</h3>

<p>Simulated dataset based on the original model parameters. The original 
data are based on two cohort studies in children from 0 to 4 and 8 
to 18 years old with burns and their mother. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Burns)</code></pre>


<h3>Format</h3>

<p>A data frame of 278 observations of 4 variables.
</p>

<dl>
<dt><code>PTSS</code></dt><dd><p>post-traumatic stress symptoms</p>
</dd>
<dt><code>gender</code></dt><dd><p>gender</p>
</dd>
<dt><code>age</code></dt><dd><p>age in years</p>
</dd>
<dt><code>TBSA</code></dt><dd><p>estimated percentage total body surface area affected by second and third degree burns</p>
</dd>
<dt><code>guilt</code></dt><dd><p>parental guilt feelings in relation to the burn event</p>
</dd>
<dt><code>anger</code></dt><dd><p>parental anger feelings in relation to the burn event</p>
</dd>
</dl>



<h3>References</h3>

<p>Bakker A, Van der Heijden PG, Van Son MJ, Van Loey NE. Course of traumatic stress reactions in couples after a burn event to their young child. Health Psychology 2013; 10(32):1076-1083, doi:10.1037/a0033983.
</p>
<p>Egberts MR, van de Schoot R, Boekelaar A, Hendrickx H, Geenen R, NEE V. Child and adolescent internalizing and externalizing problems 12 months postburn: the potential role of preburn functioning, parental posttraumatic stress, and informant bias. Child and Adolescent Psychiatry 2016; 25:791-803.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(Burns)
</code></pre>

<hr>
<h2 id='calculate_IC_weights'>Calculating IC weights based on IC values (AIC, ORIC, GORIC(A), BIC, SIC, ...)</h2><span id='topic+calculate_IC_weights'></span><span id='topic+calc_ICweights'></span><span id='topic+IC_weights'></span><span id='topic+print.goric_ICw'></span>

<h3>Description</h3>

<p>This function transforms IC values into IC weights: IC values denote the ordering 
of hypotheses/models, while IC weights quantify the relative strength of hypotheses/models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate_IC_weights(IC, hypo_names = NULL, use_scientific = TRUE)
calc_ICweights(IC, hypo_names = NULL, use_scientific = TRUE)

## S3 method for class 'goric_ICw'
print(x, digits = max(3, getOption("digits") - 4), ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calculate_IC_weights_+3A_ic">IC</code></td>
<td>
<p>A vector or one-column matrix with information criteria (AIC, ORIC, GORIC(A), BIC, SIC,
...) values of length 'NrHypos', where 'NrHypos' stands for the number of hypotheses/
models.</p>
</td></tr>
<tr><td><code id="calculate_IC_weights_+3A_x">x</code></td>
<td>
<p>an object of class <code>con_goric</code>.</p>
</td></tr>
<tr><td><code id="calculate_IC_weights_+3A_hypo_names">hypo_names</code></td>
<td>
<p>Optional. Vector containing 'NrHypos' characters which will be used for labeling the
hypothesis. Default: H1, H2, ...</p>
</td></tr>
<tr><td><code id="calculate_IC_weights_+3A_use_scientific">use_scientific</code></td>
<td>
<p>If TRUE (default), the IC weights and ratio of IC weights 
will be formatted using scientific notation. If FALSE, standard numeric formatting is used.</p>
</td></tr>                  
<tr><td><code id="calculate_IC_weights_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="calculate_IC_weights_+3A_...">...</code></td>
<td>
<p>no additional arguments for now.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>IC weights, which quantify the relative strength of hypotheses/models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>IC &lt;- c(1,2,3)
calculate_IC_weights(IC)


## PT weights 
# This examples shows how to calculate PT weights.
# Notably, one is interested in PT weights when the log-likelihood for two or more
# hypotheses are (approximately) equal.
# Then, the comparison between those hypotheses is solely based on the PT values.
# The IC weights will then equal the PT weights.
# In that case, there is support for the overlap (boundary) of these hypotheses.
# Thus, when the IC weights equal the PT weights for a (sub)set of hypotheses,
# then there is support for the overlap (boundary) of these hypotheses.

y &lt;- rnorm(30)
group &lt;- factor(rep(c("A","B","C"), each = 10))
fit.lm &lt;- lm(y ~ -1 + group)
est &lt;- coef(fit.lm)
VCOV_est &lt;- vcov(fit.lm)
H1 &lt;- "groupA &lt; groupB &lt; groupC"
results &lt;- goric(est, VCOV = VCOV_est, hypotheses = list(H1), 
                 comparison = "complement", type = "gorica")
calculate_IC_weights(results$result[,3])
</code></pre>

<hr>
<h2 id='con_weights_boot'>function for computing the chi-bar-square weights based on 
Monte Carlo simulation.</h2><span id='topic+con_weights_boot'></span>

<h3>Description</h3>

<p>The null-distribution of the test statistics under 
inequality constraints takes the form of mixtures of F-distributions. 
This function computes these mixing weights (a.k.a chi-bar-square weights
and level probabilities). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>con_weights_boot(VCOV, Amat, meq, R = 1e5L, 
                 chunk_size = 5000L, convergence_crit = 1e-03, 
                 seed = NULL, verbose = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="con_weights_boot_+3A_vcov">VCOV</code></td>
<td>
<p>variance-covariance matrix of the data for which
the weights are to be calculated.</p>
</td></tr>
<tr><td><code id="con_weights_boot_+3A_amat">Amat</code></td>
<td>
<p>constraints matrix <code class="reqn">R</code> (or a vector in 
case of one constraint) and defines the left-hand side of the 
constraint <code class="reqn">R\theta \ge rhs</code>, where each row represents one 
constraint. The number of columns needs to correspond to the 
number of parameters estimated (<code class="reqn">\theta</code>). The rows should 
be linear independent, otherwise the function gives an 
error. For more information about constructing the matrix <code class="reqn">R</code> 
and <code class="reqn">rhs</code> see <code><a href="#topic+restriktor">restriktor</a></code>.</p>
</td></tr>
<tr><td><code id="con_weights_boot_+3A_meq">meq</code></td>
<td>
<p>integer (default = 0) treating the number of 
constraints rows as equality constraints instead of inequality 
constraints. For example, if <code>meq = 2</code>, this means that the 
first two rows of the constraints matrix <code class="reqn">R</code> are treated as 
equality constraints. </p>
</td></tr>
<tr><td><code id="con_weights_boot_+3A_r">R</code></td>
<td>
<p>integer; the maximum number of bootstrap draws for 
<code>mix_weights_bootstrap_limit</code>. 
The default value is set to 1e5. See details for more information.</p>
</td></tr>
<tr><td><code id="con_weights_boot_+3A_chunk_size">chunk_size</code></td>
<td>
<p>integer; the chi-bar-square weights are computed for samples of
size <code>chunk_size = 5000L</code>. This process is repeated iteratively until the 
weights converges (see <code>convergenge_crit</code>) or the maximum is reached, i.e.,
mix_weights_bootstrap_limit.</p>
</td></tr>
<tr><td><code id="con_weights_boot_+3A_convergence_crit">convergence_crit</code></td>
<td>
<p>the convergence criterion for the iterative process. 
The default is 1e-03. See details for more information.</p>
</td></tr>
<tr><td><code id="con_weights_boot_+3A_seed">seed</code></td>
<td>
<p>seed value.</p>
</td></tr>
<tr><td><code id="con_weights_boot_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, information is shown at each 
bootstrap draw.</p>
</td></tr>
<tr><td><code id="con_weights_boot_+3A_...">...</code></td>
<td>
<p>additional parameters for the <code>rtmvnorm</code> function. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>## Iterative Weight Updating and Convergence Checking ##
The function adds in each run chunks of 5000 samples (default) to compute 
the chi-bar-square weights. After each iteration, the function checks if the 
weights have converged. This is determined by the convergence_crit parameter.
</p>
<p>Convergence is assessed by comparing the absolute difference between the 
current and previous iteration's weights against the convergence_crit. If the 
change in weights is smaller than the convergence criterion, it indicates that 
the weights have stabilized, suggesting convergence.
</p>
<p>If the weights have not converged and the <code>mix_weights_bootstrap_limit</code> has 
not been reached, the function proceeds with adding another set of 5000 samples 
and updates the weights accordingly.If the maximum number of iterations is 
reached without convergence, the function returns the (non-converged) weights. 
In this situation, it is advisible to increase the number of 
<code>mix_weights_bootstrap_limit</code>.
</p>


<h3>Value</h3>

<p>If convergence is reached, the function returns a vector with the mixing 
weights with the following attributes:
</p>
<table role = "presentation">
<tr><td><code>total_bootstrap_draws</code></td>
<td>
<p>total number of bootstrap draws</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>have the chi-bar-square weights converged</p>
</td></tr>
<tr><td><code>convergence_crit</code></td>
<td>
<p>convergence criterium</p>
</td></tr>
<tr><td><code>wt_bar_chunk</code></td>
<td>
<p>matrix with the chi-bar-square weights for each iteration</p>
</td></tr>
<tr><td><code>chunk_size</code></td>
<td>
<p>how many samples are added in each iteration</p>
</td></tr>
<tr><td><code>total_chunks</code></td>
<td>
<p>what is the maximum number of chunks based on 
<code>mix_weights_bootstrap_limit</code> and <code>chunk_size</code></p>
</td></tr>
<tr><td><code>chunk_iter</code></td>
<td>
<p>number of iterations run</p>
</td></tr>
<tr><td><code>error.idx</code></td>
<td>
<p>which bootstrap samples were not succesful</p>
</td></tr>
<tr><td><code>mix_weights_bootstrap_limit</code></td>
<td>
<p>the maximum number of bootstrap draws</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Silvapulle, M.J. and Sen, P.K. (2005, p.79). <em>Constrained 
Statistical Inference</em>. Wiley, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
W &lt;- matrix(c(1,0.5,0.5,1),2,2)
Amat &lt;- rbind(c(0,1))
meq &lt;- 0L
wt.bar &lt;- con_weights_boot(W, Amat, meq, R = 99999)
wt.bar

# in practice you want to use are more conservative convergence criterion
wt.bar2 &lt;- con_weights_boot(W, Amat, meq, R = 99999, convergence_crit = 1e-02)
wt.bar2

</code></pre>

<hr>
<h2 id='conTest_ceq'>Tests for iht with equality constraints only</h2><span id='topic+conTest_ceq'></span><span id='topic+conTest_ceq.conLM'></span><span id='topic+conTest_ceq.conRLM'></span><span id='topic+conTest_ceq.conGLM'></span>

<h3>Description</h3>

<p><code>conTest_ceq</code> tests linear equality restricted hypotheses for
(robust) linear models by F-, Wald-, and score-tests. It can be used directly 
and is called by the <code>conTest</code> function if all restrictions are equalities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'conLM'
conTest_ceq(object, test = "F", boot = "no", 
            R = 9999, p.distr = rnorm, parallel = "no", 
            ncpus = 1L, cl = NULL, seed = 1234, verbose = FALSE, ...)

## S3 method for class 'conRLM'
conTest_ceq(object, test = "F", boot = "no", 
            R = 9999, p.distr = rnorm, parallel = "no", 
            ncpus = 1L, cl = NULL, seed = 1234, verbose = FALSE, ...)
            
## S3 method for class 'conGLM'
conTest_ceq(object, test = "F", boot = "no", 
            R = 9999, p.distr = rnorm, parallel = "no", 
            ncpus = 1L, cl = NULL, seed = 1234, verbose = FALSE, ...)            
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conTest_ceq_+3A_object">object</code></td>
<td>
<p>an object of class <code>conLM</code>, <code>conRLM</code> or <code>conGLM</code>.</p>
</td></tr> 
<tr><td><code id="conTest_ceq_+3A_test">test</code></td>
<td>
<p>test statistic; for information about the 
null-distribution see details.
</p>

<ul>
<li><p> for object of class lm and glm; if &quot;F&quot; (default), the 
classical F-statistic is computed. If &quot;Wald&quot;, the classical 
Wald-statistic is computed. If &quot;score&quot;, the classical score 
test statistic is computed. 
</p>
</li>
<li><p> for object of class rlm; if &quot;F&quot; (default), a robust 
likelihood ratio type test statistic (Silvapulle, 1992a) is 
computed. If &quot;Wald&quot;, a robust Wald test statistic 
(Silvapulle, 1992b) is computed. If &quot;score&quot;, a score test 
statistic (Silvapulle, 1996) is computed.
</p>
</li></ul>

</td></tr>
<tr><td><code id="conTest_ceq_+3A_boot">boot</code></td>
<td>
<p>if <code>"parametric"</code>, the p-value is computed based on the 
parametric bootstrap. See <code>p.distr</code> for available distributions.
If <code>"model.based"</code>, a model-based bootstrap method is used. 
Model-based bootstrapping is not supported for the <code>conGLM</code> object yet.
</p>
</td></tr>
<tr><td><code id="conTest_ceq_+3A_r">R</code></td>
<td>
<p>integer; number of bootstrap draws for <code>boot</code>. 
The default value is set to 9999.</p>
</td></tr>
<tr><td><code id="conTest_ceq_+3A_p.distr">p.distr</code></td>
<td>
<p>the p.distr function is specified by this function. For 
all available distributions see <code>?distributions</code>. For example, 
if <code>rnorm</code>, samples are drawn from the normal distribution (default) 
with mean zero and variance one. If <code>rt</code>, samples are drawn from 
a t-distribution. If <code>rchisq</code>, samples are drawn from a chi-square 
distribution. The distributional parameters will be passed in via ....</p>
</td></tr>
<tr><td><code id="conTest_ceq_+3A_parallel">parallel</code></td>
<td>
<p>the type of parallel operation to be used 
(if any). If missing, the default is set &quot;no&quot;.</p>
</td></tr>
<tr><td><code id="conTest_ceq_+3A_ncpus">ncpus</code></td>
<td>
<p>integer: number of processes to be used in parallel 
operation: typically one would chose this to the number of 
available CPUs.</p>
</td></tr>
<tr><td><code id="conTest_ceq_+3A_cl">cl</code></td>
<td>
<p>an optional parallel or snow cluster for use if 
parallel = &quot;snow&quot;. If not supplied, a cluster on the local 
machine is created for the duration of the conTest call.</p>
</td></tr>
<tr><td><code id="conTest_ceq_+3A_seed">seed</code></td>
<td>
<p>seed value. The default value is set to 1234.</p>
</td></tr>
<tr><td><code id="conTest_ceq_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, information is shown at each 
bootstrap draw.</p>
</td></tr>
<tr><td><code id="conTest_ceq_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the p.distr function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class conTest, for which a print is available. 
More specifically, it is a list with the following items:
</p>
<table role = "presentation">
<tr><td><code>CON</code></td>
<td>
<p>a list with useful information about the constraints.</p>
</td></tr>
<tr><td><code>Amat</code></td>
<td>
<p>constraints matrix.</p>
</td></tr>
<tr><td><code>bvec</code></td>
<td>
<p>vector of right-hand side elements.</p>
</td></tr>
<tr><td><code>meq</code></td>
<td>
<p>number of equality constraints.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>Ts</code></td>
<td>
<p>test-statistic value.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>tail probability for <code>Ts</code>.</p>
</td></tr>
<tr><td><code>b_unrestr</code></td>
<td>
<p>unrestricted regression coefficients.</p>
</td></tr>
<tr><td><code>b_restr</code></td>
<td>
<p>restricted regression coefficients.</p>
</td></tr>
<tr><td><code>R2_org</code></td>
<td>
<p>unrestricted R-squared.</p>
</td></tr>
<tr><td><code>R2_reduced</code></td>
<td>
<p>restricted R-squared.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Silvapulle, M. (1992a). Robust tests of inequality constraints and 
one-sided hypotheses in the linear model. <em>Biometrika</em>, 
<b>79</b>, 621&ndash;630.
</p>
<p>Silvapulle, M. (1996) Robust bounded influence tests against 
one-sided hypotheses in general parametric models. 
<em>Statistics and probability letters</em>, <b>31</b>, 45&ndash;50.
</p>
<p>Silvapulle, M. (1992b). Robust Wald-Type Tests of One-Sided Hypotheses 
in the Linear Model. <em>Journal of the American Statistical Association</em>, 
<b>87</b>, 156&ndash;161.
</p>
<p>Silvapulle, M. (1996) Robust bounded influence tests against one-sided hypotheses
in general parametric models. <em>Statistics and probability letters</em>, 
<b>31</b>, 45&ndash;50.
</p>


<h3>See Also</h3>

 
<p><a href="quadprog.html#topic+solve.QP">quadprog</a>, 
<code><a href="#topic+iht">iht</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1:
# the data consist of ages (in months) at which an 
# infant starts to walk alone.

# prepare data
DATA1 &lt;- subset(ZelazoKolb1972, Group != "Control")

# fit unrestricted linear model
fit1.lm &lt;- lm(Age ~ -1 + Group, data = DATA1)

# the variable names can be used to impose constraints on
# the corresponding regression parameters.
coef(fit1.lm)

# constraint syntax: assuming that the walking 
# exercises would not have a negative effect of increasing the 
# mean age at which a child starts to walk. 
myConstraints1 &lt;- ' GroupActive = GroupPassive = GroupNo '

iht(fit1.lm, myConstraints1)


# another way is to first fit the restricted model
fit_restr1 &lt;- restriktor(fit1.lm, constraints = myConstraints1)

iht(fit_restr1)

 
# Or in matrix notation.
Amat1 &lt;- rbind(c(-1, 0,  1),
               c( 0, 1, -1))
myRhs1 &lt;- rep(0L, nrow(Amat1)) 
myNeq1 &lt;- 2

iht(fit1.lm, constraints = Amat1,
    rhs = myRhs1, neq = myNeq1)

</code></pre>

<hr>
<h2 id='conTest_summary'>function for computing all available hypothesis tests
</h2><span id='topic+conTest_summary'></span><span id='topic+iht_summary'></span><span id='topic+conTest_summary.restriktor'></span>

<h3>Description</h3>

<p>conTest_summary computes all available hypothesis tests and returns
and object of class <code>conTest</code> for which a print function is available. The 
<code>conTest_summary</code> can be used directly and is called by the <code>conTest</code> 
function if <code>type = "summary"</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'restriktor'
conTest_summary(object, test = "F", ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conTest_summary_+3A_object">object</code></td>
<td>
<p>an object of class <code>restriktor</code>.</p>
</td></tr> 
<tr><td><code id="conTest_summary_+3A_test">test</code></td>
<td>
<p>test statistic; for information about the 
null-distribution see details.
</p>

<ul>
<li><p> for object of class lm; if &quot;F&quot; (default), the classical F-statistic
is computed. If &quot;Wald&quot;, the classical Wald-statistic is computed. If &quot;score&quot;, 
the classical score test statistic is computed. 
</p>
</li>
<li><p> for object of class rlm; if &quot;F&quot; (default), a robust 
likelihood ratio type test statistic (Silvapulle, 1992a) is 
computed. If &quot;Wald&quot;, a robust Wald test statistic (Silvapulle, 1992b) 
is computed. If &quot;score&quot;, a score test statistic (Silvapulle, 1996) is 
computed. 
</p>
</li></ul>

</td></tr>
<tr><td><code id="conTest_summary_+3A_...">...</code></td>
<td>
<p>the same arguments as passed to the <code><a href="#topic+iht">iht</a></code> function,
except for <code>type</code>, of course.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class conTest, for which a print is available. 
More specifically, it is a list with the following items:
</p>
<table role = "presentation">
<tr><td><code>CON</code></td>
<td>
<p>a list with useful information about the constraints.</p>
</td></tr>
<tr><td><code>Amat</code></td>
<td>
<p>constraints matrix.</p>
</td></tr>
<tr><td><code>bvec</code></td>
<td>
<p>vector of right-hand side elements.</p>
</td></tr>
<tr><td><code>meq</code></td>
<td>
<p>number of equality constraints.</p>
</td></tr>
<tr><td><code>meq.alt</code></td>
<td>
<p>same as input neq.alt.</p>
</td></tr>
<tr><td><code>iact</code></td>
<td>
<p>number of active constraints.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>Ts</code></td>
<td>
<p>test-statistic value.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>tail probability for <code>Ts</code>.</p>
</td></tr>
<tr><td><code>b.eqrestr</code></td>
<td>
<p>equality restricted regression coefficients. 
Only available for <code>type = "A"</code> and <code>type = "global"</code>, 
else <code>b.eqrestr = NULL</code>.</p>
</td></tr>
<tr><td><code>b.unrestr</code></td>
<td>
<p>unrestricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr</code></td>
<td>
<p>restricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr.alt</code></td>
<td>
<p>restricted regression coefficients under HA 
if some equality constraints are maintained.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>variance-covariance matrix of unrestricted model.</p>
</td></tr>
<tr><td><code>R2.org</code></td>
<td>
<p>unrestricted R-squared.</p>
</td></tr>
<tr><td><code>R2.reduced</code></td>
<td>
<p>restricted R-squared.</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>model.org</code></td>
<td>
<p>original model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Shapiro, A. (1988). Towards a unified theory of inequality-constrained 
testing in multivariate analysis. <em>International Statistical 
Review</em> <b>56</b>, 49&ndash;62.
</p>
<p>Silvapulle, M. (1992a). Robust tests of inequality constraints and 
one-sided hypotheses in the linear model. <em>Biometrika</em>, 
<b>79</b>, 621&ndash;630.
</p>
<p>Silvapulle, M. (1992b). Robust Wald-Type Tests of One-Sided Hypotheses 
in the Linear Model. <em>Journal of the American Statistical Association</em>, 
<b>87</b>, 156&ndash;161.
</p>
<p>Silvapulle, M. and Silvapulle, P. (1995). A score test against 
one-sided alternatives. <em>American statistical association</em>, 
<b>90</b>, 342&ndash;349.
</p>
<p>Silvapulle, M. (1996) On an F-type statistic for testing one-sided 
hypotheses and computation of chi-bar-squared weights. 
<em>Statistics and probability letters</em>, <b>28</b>, 137&ndash;141.
</p>
<p>Silvapulle, M. (1996) Robust bounded influence tests against 
one-sided hypotheses in general parametric models. 
<em>Statistics and probability letters</em>, <b>31</b>, 45&ndash;50.
</p>
<p>Silvapulle, M.J. and Sen, P.K. (2005). <em>Constrained 
Statistical Inference</em>. Wiley, New York
</p>
<p>Wolak, F. (1987). An exact test for multiple inequality and 
equality constraints in the linear regression model. 
<em>Journal of the American statistical association</em>, 
<b>82</b>, 782&ndash;793.
</p>


<h3>See Also</h3>

 
<p><a href="quadprog.html#topic+solve.QP">quadprog</a>, 
<code><a href="#topic+iht">iht</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1:
# the data consist of ages (in months) at which an 
# infant starts to walk alone.

# prepare data
DATA1 &lt;- subset(ZelazoKolb1972, Group != "Control")

# fit unrestricted linear model
fit1.lm &lt;- lm(Age ~ -1 + Group, data = DATA1)

# the variable names can be used to impose constraints on
# the corresponding regression parameters.
coef(fit1.lm)

# constraint syntax: assuming that the walking 
# exercises would not have a negative effect of increasing the 
# mean age at which a child starts to walk. 
myConstraints1 &lt;- ' GroupActive  &lt; GroupPassive &lt; GroupNo '

iht(fit1.lm, myConstraints1)


# another way is to first fit the restricted model
fit.restr1 &lt;- restriktor(fit1.lm, constraints = myConstraints1)

iht(fit.restr1)

# Or in matrix notation.
Amat1 &lt;- rbind(c(-1, 0,  1),
               c( 0, 1, -1))
myRhs1 &lt;- rep(0L, nrow(Amat1)) 
myNeq1 &lt;- 0

fit1.con &lt;- restriktor(fit1.lm, constraints = Amat1,
                       rhs = myRhs1, neq = myNeq1)
iht(fit1.con)

</code></pre>

<hr>
<h2 id='conTestC'>one-sided t-test for iht</h2><span id='topic+conTestC'></span><span id='topic+conTestC.restriktor'></span>

<h3>Description</h3>

<p><code>conTestC</code> tests linear inequality restricted 
hypotheses for (robust) linear models by a one-sided t-test. This 
method is based on the union-intersection principle. It is called 
by the <code>conTest</code> function if all restrictions are equalities.
For more information see details. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'restriktor'
conTestC(object, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conTestC_+3A_object">object</code></td>
<td>
<p>an object of class <code>restriktor</code>.</p>
</td></tr> 
<tr><td><code id="conTestC_+3A_...">...</code></td>
<td>
<p>no additional arguments for now.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Hypothesis test Type C:
</p>

<ul>
<li><p> Test H0: at least one restriction false (&quot;&lt;&quot;) 
against HA: all constraints strikty true (&quot;&gt;&quot;). This test is 
based on the intersection-union principle. Note that, this test only makes 
sense in case of no equality constraints.
</p>
</li></ul>

<p>The null-distribution of hypothesis test Type C is based on a 
t-distribution (one-sided). Its power can be poor in case of many 
inequalty constraints. Its main role is to prevent wrong 
conclusions from significant results from hypothesis test Type A.
</p>


<h3>Value</h3>

<p>An object of class conTest, for which a print is available. 
More specifically, it is a list with the following items:
</p>
<table role = "presentation">
<tr><td><code>CON</code></td>
<td>
<p>a list with useful information about the constraints.</p>
</td></tr>
<tr><td><code>Amat</code></td>
<td>
<p>constraints matrix.</p>
</td></tr>
<tr><td><code>bvec</code></td>
<td>
<p>vector of right-hand side elements.</p>
</td></tr>
<tr><td><code>meq</code></td>
<td>
<p>number of equality constraints.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>Ts</code></td>
<td>
<p>test-statistic value.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>tail probability for <code>Ts</code>.</p>
</td></tr>
<tr><td><code>b.unrestr</code></td>
<td>
<p>unrestricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr</code></td>
<td>
<p>restricted regression coefficients.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>variance-covariance matrix of unrestricted model.</p>
</td></tr>
<tr><td><code>R2.org</code></td>
<td>
<p>unrestricted R-squared.</p>
</td></tr>
<tr><td><code>R2.reduced</code></td>
<td>
<p>restricted R-squared.</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>&quot;no&quot;, not used (yet).</p>
</td></tr>
<tr><td><code>model.org</code></td>
<td>
<p>original model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Silvapulle, M.J. and Sen, P.K. (2005, chapter 5.). <em>Constrained 
Statistical Inference</em>. Wiley, New York
</p>


<h3>See Also</h3>

 
<p><a href="quadprog.html#topic+solve.QP">quadprog</a>, 
<code><a href="#topic+iht">iht</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1:
# the data consist of ages (in months) at which an 
# infant starts to walk alone.

# prepare data
DATA1 &lt;- subset(ZelazoKolb1972, Group != "Control")

# fit unrestricted linear model
fit1.lm &lt;- lm(Age ~ -1 + Group, data = DATA1)

# the variable names can be used to impose constraints on
# the corresponding regression parameters.
coef(fit1.lm)

# constraint syntax: assuming that the walking 
# exercises would not have a negative effect of increasing the 
# mean age at which a child starts to walk. 
myConstraints1 &lt;- ' GroupActive  &lt; GroupPassive &lt; GroupNo '

iht(fit1.lm, myConstraints1, type = "C")


# another way is to first fit the restricted model
fit.restr1 &lt;- restriktor(fit1.lm, constraints = myConstraints1)

iht(fit.restr1, type = "C")


# Or in matrix notation.
Amat1 &lt;- rbind(c(-1, 0,  1),
               c( 0, 1, -1))
myRhs1 &lt;- rep(0L, nrow(Amat1)) 
myNeq1 &lt;- 0

fit1.con &lt;- restriktor(fit1.lm, constraints = Amat1,
                       rhs = myRhs1, neq = myNeq1)
iht(fit1.con, type = "C")
</code></pre>

<hr>
<h2 id='conTestF'>F-bar test for iht</h2><span id='topic+conTestF'></span><span id='topic+conTestF.conLM'></span><span id='topic+conTestF.conRLM'></span><span id='topic+conTestF.conGLM'></span>

<h3>Description</h3>

<p><code>conTestF</code> tests linear equality and/or 
inequality restricted hypotheses for linear models by F-tests. It can be 
used directly and is called by the <code>conTest</code> function if <code>test = "F"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'conLM'
conTestF(object, type = "A", neq.alt = 0, 
         boot = "no", R = 9999, p.distr = rnorm, 
         parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
         verbose = FALSE, control = NULL, ...)

## S3 method for class 'conRLM'
conTestF(object, type = "A", neq.alt = 0, 
         boot = "no", R = 9999, p.distr = rnorm, 
         parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
         verbose = FALSE, control = NULL, ...)

## S3 method for class 'conGLM'
conTestF(object, type = "A", neq.alt = 0, 
         boot = "no", R = 9999, p.distr = rnorm, 
         parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
         verbose = FALSE, control = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conTestF_+3A_object">object</code></td>
<td>
<p>an object of class <code>conLM</code>, <code>conRLM</code> or <code>conGLM</code>.</p>
</td></tr> 
<tr><td><code id="conTestF_+3A_type">type</code></td>
<td>
<p>hypothesis test type &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;global&quot;, or 
&quot;summary&quot; (default). See details for more information.</p>
</td></tr>
<tr><td><code id="conTestF_+3A_neq.alt">neq.alt</code></td>
<td>
<p>integer: number of equality constraints that 
are maintained under the alternative hypothesis (for hypothesis 
test type &quot;B&quot;), see example 3.</p>
</td></tr>
<tr><td><code id="conTestF_+3A_boot">boot</code></td>
<td>
<p>the null-distribution of these test-statistics 
(except under type &quot;C&quot;) takes the form of a mixture of 
F-distributions. The tail probabilities can be computed directly 
via bootstrapping; if <code>"parametric"</code>, the p-value is 
computed based on the parametric bootstrap. By default, samples 
are drawn from a normal distribution with mean zero and varance 
one. See <code>p.distr</code> for other distributional options. If 
<code>"model.based"</code>, a model-based bootstrap method is used. 
Instead of computing the p-value via simulation, the p-value
can also be computed using the chi-bar-square weights. If 
<code>"no"</code>, the p-value is computed based on the weights 
obtained via simulation (<code>mix_weights = "boot"</code>) or using the 
multivariate normal distribution function (<code>mix_weights = "pmvnorm"</code>).
Note that, these weights are already available in the restriktor objected and
do not need to be estimated again. However, there are two exception for objects 
of class <code>conRLM</code>, namely for computing the p-value for the robust 
<code>test</code> = <code>"Wald"</code> and the robust <code>"score"</code>. In these cases 
the weights need to be recalculated.
</p>
</td></tr>
<tr><td><code id="conTestF_+3A_r">R</code></td>
<td>
<p>integer; number of bootstrap draws for <code>boot</code>. 
The default value is set to 9999.</p>
</td></tr>
<tr><td><code id="conTestF_+3A_p.distr">p.distr</code></td>
<td>
<p>random generation distribution for the parametric bootstrap. For 
all available distributions see <code>?distributions</code>. For example, 
if <code>rnorm</code>, samples are drawn from the normal distribution (default) 
with mean zero and variance one. If <code>rt</code>, samples are drawn from 
a t-distribution. If <code>rchisq</code>, samples are drawn from a chi-square 
distribution. The distributional parameters will be passed in via ....</p>
</td></tr>
<tr><td><code id="conTestF_+3A_parallel">parallel</code></td>
<td>
<p>the type of parallel operation to be used 
(if any). If missing, the default is set &quot;no&quot;.</p>
</td></tr>
<tr><td><code id="conTestF_+3A_ncpus">ncpus</code></td>
<td>
<p>integer: number of processes to be used in parallel 
operation: typically one would chose this to the number of 
available CPUs.</p>
</td></tr>
<tr><td><code id="conTestF_+3A_cl">cl</code></td>
<td>
<p>an optional parallel or snow cluster for use if 
parallel = &quot;snow&quot;. If not supplied, a cluster on the local 
machine is created for the duration of the conTest call.</p>
</td></tr>
<tr><td><code id="conTestF_+3A_seed">seed</code></td>
<td>
<p>seed value. The default value is set to 1234.</p>
</td></tr>
<tr><td><code id="conTestF_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, information is shown at each 
bootstrap draw.</p>
</td></tr>
<tr><td><code id="conTestF_+3A_control">control</code></td>
<td>
<p>a list of control arguments: 
</p>

<ul>
<li> <p><code>absval</code> tolerance criterion for convergence 
(default = sqrt(.Machine$double.eps)). Only used for model 
of class lm.
</p>
</li>
<li> <p><code>maxit</code> the maximum number of iterations for the 
optimizer (default = 10000). Only used for model of class 
mlm (not yet supported). 
</p>
</li>
<li> <p><code>tol</code> numerical tolerance value. Estimates 
smaller than <code>tol</code> are set to 0.
</p>
</li>
<li> <p><code>chunk_size</code> the chi-bar-square weights are computed for samples 
of size <code>chunk_size = 5000L</code>. This process is repeated iteratively 
until the weights converges (see <code>convergenge_crit</code>) or the maximum 
is reached, i.e., mix_weights_bootstrap_limit.
</p>
</li>
<li> <p><code>convergence_crit</code> the convergence criterion for the iterative 
process. The default is 1e-03.</p>
</li></ul>

</td></tr>
<tr><td><code id="conTestF_+3A_...">...</code></td>
<td>
<p>Additional arguments that can be passed to the p.distr function, 
or arguments for the restriktor or iht function. Consider, for example, the 
mix_weights_bootstrap_limit control argument, which specifies the maximum number of 
bootstrap draws (default is 100.000) used to compute the chi-bar-square weights. 
If mix_weights_bootstrap_limit is set to 100.000, then in each iteration, a 
sample of size 5000 is added until the weights converge, or the maximum limit 
is reached.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following hypothesis tests are available:
</p>

<ul>
<li><p> Type A: Test H0: all constraints with equalities (&quot;=&quot;) 
active against HA: at least one inequality restriction (&quot;&gt;&quot;) 
strictly true.
</p>
</li>
<li><p> Type B: Test H0: all constraints with inequalities (&quot;&gt;&quot;) 
(including some equalities (&quot;=&quot;)) active against HA: at least 
one restriction false (some equality constraints may be 
maintained).
</p>
</li>
<li><p> Type C: Test H0: at least one restriction false (&quot;&lt;&quot;) 
against HA: all constraints strikty true (&quot;&gt;&quot;). This test is 
based on the intersection-union principle (Silvapulle and Sen, 
2005, chp 5.3). Note that, this test only makes sense in case 
of no equality constraints.
</p>
</li>
<li><p> Type global: equal to Type A but H0 contains additional 
equality constraints. This test is analogue to the global 
F-test in lm, where all coefficients but the intercept equal 0.
</p>
</li></ul>

<p>The null-distribution of hypothesis test Type C is based on a 
t-distribution (one-sided). Its power can be poor in case of many 
inequalty constraints. Its main role is to prevent wrong 
conclusions from significant results from hypothesis test Type A.
</p>
<p>The exact finite sample distributions of the non-robust F-, 
score- and LR-test statistics based on restricted OLS estimates 
and normally distributed errors, are a mixture of F-distributions 
under the null hypothesis (Wolak, 1987). In agreement with 
Silvapulle (1992), we found that the results based on these 
mixtures of F-distributions approximate the tail probabilities of 
the robust tests better than their asymptotic distributions. 
Therefore, all p-values for hypothesis test Type <code>"A"</code>, 
<code>"B"</code> and <code>"global"</code> are computed based on mixtures of 
F-distributions. 
</p>
<p>Note that, in case of equality constraints only, the 
null-distribution of the (robust) F-test statistics is based on 
an F-distribution. The (robust) Wald- and (robust) score-test 
statistics are based on chi-square distributions.
</p>


<h3>Value</h3>

<p>An object of class conTest, for which a print is available. 
More specifically, it is a list with the following items:
</p>
<table role = "presentation">
<tr><td><code>CON</code></td>
<td>
<p>a list with useful information about the constraints.</p>
</td></tr>
<tr><td><code>Amat</code></td>
<td>
<p>constraints matrix.</p>
</td></tr>
<tr><td><code>bvec</code></td>
<td>
<p>vector of right-hand side elements.</p>
</td></tr>
<tr><td><code>meq</code></td>
<td>
<p>number of equality constraints.</p>
</td></tr>
<tr><td><code>meq.alt</code></td>
<td>
<p>same as input neq.alt.</p>
</td></tr>
<tr><td><code>iact</code></td>
<td>
<p>number of active constraints.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>Ts</code></td>
<td>
<p>test-statistic value.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>tail probability for <code>Ts</code>.</p>
</td></tr>
<tr><td><code>b.eqrestr</code></td>
<td>
<p>equality restricted regression coefficients. 
Only available for <code>type = "A"</code> and <code>type = "global"</code>, 
else <code>b.eqrestr = NULL</code>.</p>
</td></tr>
<tr><td><code>b.unrestr</code></td>
<td>
<p>unrestricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr</code></td>
<td>
<p>restricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr.alt</code></td>
<td>
<p>restricted regression coefficients under HA 
if some equality constraints are maintained. Only available for 
<code>type = "B"</code> else <code>b.restr.alt = NULL</code>.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>variance-covariance matrix of unrestricted model.</p>
</td></tr>
<tr><td><code>R2.org</code></td>
<td>
<p>unrestricted R-squared, not available for objects of class <code>conGLM</code>.</p>
</td></tr>
<tr><td><code>R2.reduced</code></td>
<td>
<p>restricted R-squared, not available for objects of class <code>conGLM</code>.</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>model.org</code></td>
<td>
<p>original model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Kudo, A. (1963) A multivariate analogue of the one-sided test. 
<em>Biometrika</em>, <b>50</b>, 403&ndash;418.
</p>
<p>Silvapulle, M. (1992a). Robust tests of inequality constraints and 
one-sided hypotheses in the linear model. <em>Biometrika</em>, 
<b>79</b>, 621&ndash;630.
</p>
<p>Silvapulle, M. (1996) On an F-type statistic for testing one-sided 
hypotheses and computation of chi-bar-squared weights. 
<em>Statistics and probability letters</em>, <b>28</b>, 137&ndash;141.
</p>
<p>Silvapulle, M.J. and Sen, P.K. (2005). <em>Constrained 
Statistical Inference</em>. Wiley, New York
</p>
<p>Wolak, F. (1987). An exact test for multiple inequality and 
equality constraints in the linear regression model. 
<em>Journal of the American statistical association</em>, 
<b>82</b>, 782&ndash;793.
</p>


<h3>See Also</h3>

 
<p><a href="quadprog.html#topic+solve.QP">quadprog</a>, 
<code><a href="#topic+iht">iht</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1:
# the data consist of ages (in months) at which an 
# infant starts to walk alone.

# prepare data
DATA1 &lt;- subset(ZelazoKolb1972, Group != "Control")

# fit unrestricted linear model
fit1.lm &lt;- lm(Age ~ -1 + Group, data = DATA1)

# the variable names can be used to impose constraints on
# the corresponding regression parameters.
coef(fit1.lm)

# constraint syntax: assuming that the walking 
# exercises would not have a negative effect of increasing the 
# mean age at which a child starts to walk. 
myConstraints1 &lt;- ' GroupActive  &lt; GroupPassive &lt; GroupNo '

iht(fit1.lm, myConstraints1)


# another way is to first fit the restricted model
fit.restr1 &lt;- restriktor(fit1.lm, constraints = myConstraints1)

iht(fit.restr1)

 
  # Or in matrix notation.
  Amat1 &lt;- rbind(c(-1, 0,  1),
                 c( 0, 1, -1))
  myRhs1 &lt;- rep(0L, nrow(Amat1)) 
  myNeq1 &lt;- 0
  
  iht(fit1.lm, constraints = Amat1,
      rhs = myRhs1, neq = myNeq1)
            

#########################
## Artificial examples ##
#########################
# generate data
n &lt;- 10
means &lt;- c(1,2,1,3)
nm &lt;- length(means)
group &lt;- as.factor(rep(1:nm, each = n))
y &lt;- rnorm(n * nm, rep(means, each = n))
DATA2 &lt;- data.frame(y, group)

# fit unrestricted linear model
fit2.lm &lt;- lm(y ~ -1 + group, data = DATA2)
coef(fit2.lm)

## example 2: increasing means
myConstraints2 &lt;- ' group1 &lt; group2 &lt; group3 &lt; group4 '

# compute F-test for hypothesis test Type A and compute the tail 
# probability based on the parametric bootstrap. We only generate 9 
# bootstrap samples in this example; in practice you may wish to 
# use a much higher number.
iht(fit2.lm, constraints = myConstraints2, type = "A", 
    boot = "parametric", R = 9)


# or fit restricted linear model
fit2.con &lt;- restriktor(fit2.lm, constraints = myConstraints2)

iht(fit2.con)

# increasing means in matrix notation.
Amat2 &lt;- rbind(c(-1, 1, 0, 0),
               c( 0,-1, 1, 0),
               c( 0, 0,-1, 1))
myRhs2 &lt;- rep(0L, nrow(Amat2)) 
myNeq2 &lt;- 0

iht(fit2.con, constraints = Amat2, rhs = myRhs2, neq = myNeq2, 
    type = "A", boot = "parametric", R = 9)

## example 3:
# combination of equality and inequality constraints.
myConstraints3 &lt;- ' group1  = group2
                    group3  &lt; group4 '

iht(fit2.lm, constraints = myConstraints3, type = "B", neq.alt = 1)

# fit resticted model and compute model-based bootstrapped 
# standard errors. We only generate 9 bootstrap samples in this 
# example; in practice you may wish to use a much higher number.
# Note that, a warning message may be thrown because the number of 
# bootstrap samples is too low.
fit3.con &lt;- restriktor(fit2.lm, constraints = myConstraints3, 
                       se = "boot.model.based", B = 9)
iht(fit3.con, type = "B", neq.alt = 1)


## example 4:
# restriktor can also be used to define effects using the := operator 
# and impose constraints on them. For example, is the 
# average effect (AVE) larger than zero?
# generate data
n &lt;- 30
b0 &lt;- 10; b1 = 0.5; b2 = 1; b3 = 1.5
X &lt;- c(rep(c(0), n/2), rep(c(1), n/2))
set.seed(90) 
Z &lt;- rnorm(n, 16, 5)
y &lt;- b0 + b1*X + b2*Z + b3*X*Z + rnorm(n, 0, sd = 10) 
DATA3 = data.frame(cbind(y, X, Z))

# fit linear model with interaction
fit4.lm &lt;- lm(y ~ X*Z, data = DATA3)

# constraint syntax
myConstraints4 &lt;- ' AVE := X + 16.86137*X.Z; 
                    AVE &gt; 0 '

iht(fit4.lm, constraints = myConstraints4)

# or
fit4.con &lt;- restriktor(fit4.lm, constraints = ' AVE := X + 16.86137*X.Z; 
                                                AVE &gt; 0 ')
iht(fit4.con)
</code></pre>

<hr>
<h2 id='conTestLRT'>Likelihood-ratio-bar test for iht</h2><span id='topic+conTestLRT'></span><span id='topic+conTestLRT.conLM'></span><span id='topic+conTestLRT.conGLM'></span><span id='topic+conTestLRT.conMLM'></span>

<h3>Description</h3>

<p><code>conTestLRT</code> tests linear equality and/or 
inequality restricted hypotheses for linear models by LR-tests. It can be 
used directly and is called by the <code>conTest</code> function if <code>test = "LRT"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'conLM'
conTestLRT(object, type = "A", neq.alt = 0, 
           boot = "no", R = 9999, p.distr = rnorm,  
           parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
           verbose = FALSE, control = NULL, ...)
           
## S3 method for class 'conGLM'
conTestLRT(object, type = "A", neq.alt = 0, 
            boot = "no", R = 9999, p.distr = rnorm,  
            parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
            verbose = FALSE, control = NULL, ...)           

## S3 method for class 'conMLM'
conTestLRT(object, type = "A", neq.alt = 0, 
            boot = "no", R = 9999, p.distr = rnorm,  
            parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
            verbose = FALSE, control = NULL, ...)                     
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conTestLRT_+3A_object">object</code></td>
<td>
<p>an object of class <code>conLM</code>, <code>conMLM</code> or <code>conGLM</code>.</p>
</td></tr>  
<tr><td><code id="conTestLRT_+3A_type">type</code></td>
<td>
<p>hypothesis test type &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;global&quot;, or 
&quot;summary&quot; (default). See details for more information.</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_neq.alt">neq.alt</code></td>
<td>
<p>integer: number of equality constraints that 
are maintained under the alternative hypothesis (for hypothesis 
test type &quot;B&quot;), see example 3.</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_boot">boot</code></td>
<td>
<p>the null-distribution of these test-statistics 
(except under type &quot;C&quot;, see details) takes the form of a mixture of 
F-distributions. The tail probabilities can be computed directly 
via bootstrapping; if <code>"parametric"</code>, the p-value is 
computed based on the parametric bootstrap. By default, samples 
are drawn from a normal distribution with mean zero and varance 
one. See <code>p.distr</code> for other distributional options. If 
<code>"model.based"</code>, a model-based bootstrap method is used. 
Instead of computing the p-value via simulation, the p-value
can also be computed using the chi-bar-square weights. If 
<code>"no"</code>, the p-value is computed based on the weights 
obtained via simulation (<code>mix_weights = "boot"</code>) or using the 
multivariate normal distribution function (<code>mix_weights = "pmvnorm"</code>).
Note that, these weights are already available in the restriktor objected and
do not need to be estimated again. However, there are two exception for objects 
of class <code>conRLM</code>, namely for computing the p-value for the robust 
<code>test</code> = <code>"Wald"</code> and the robust <code>"score"</code>. In these cases 
the weights need to be recalculated.
</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_r">R</code></td>
<td>
<p>integer; number of bootstrap draws for <code>boot</code>. 
The default value is set to 9999.</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_p.distr">p.distr</code></td>
<td>
<p>random generation distribution for the parametric bootstrap. For 
all available distributions see <code>?distributions</code>. For example, 
if <code>rnorm</code>, samples are drawn from the normal distribution (default) 
with mean zero and variance one. If <code>rt</code>, samples are drawn from 
a t-distribution. If <code>rchisq</code>, samples are drawn from a chi-square 
distribution. The random generation distributional parameters will 
be passed in via ....</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_parallel">parallel</code></td>
<td>
<p>the type of parallel operation to be used 
(if any). If missing, the default is set &quot;no&quot;.</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_ncpus">ncpus</code></td>
<td>
<p>integer: number of processes to be used in parallel 
operation: typically one would chose this to the number of 
available CPUs.</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_cl">cl</code></td>
<td>
<p>an optional parallel or snow cluster for use if 
parallel = &quot;snow&quot;. If not supplied, a cluster on the local 
machine is created for the duration of the conTest call.</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_seed">seed</code></td>
<td>
<p>seed value. The default value is set to 1234.</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, information is shown at each 
bootstrap draw.</p>
</td></tr>
<tr><td><code id="conTestLRT_+3A_control">control</code></td>
<td>
<p>a list of control arguments: 
</p>

<ul>
<li> <p><code>absval</code> tolerance criterion for convergence 
(default = sqrt(.Machine$double.eps)). Only used for model 
of class lm.
</p>
</li>
<li> <p><code>maxit</code> the maximum number of iterations for the 
optimizer (default = 10000). Only used for model of class 
mlm (not yet supported). 
</p>
</li>
<li> <p><code>tol</code> numerical tolerance value. Estimates 
smaller than <code>tol</code> are set to 0.
</p>
</li>
<li> <p><code>chunk_size</code> the chi-bar-square weights are computed for samples 
of size <code>chunk_size = 5000L</code>. This process is repeated iteratively 
until the weights converges (see <code>convergenge_crit</code>) or the maximum 
is reached, i.e., mix_weights_bootstrap_limit.
</p>
</li>
<li> <p><code>convergence_crit</code> the convergence criterion for the iterative 
process. The default is 1e-03.</p>
</li></ul>

</td></tr>
<tr><td><code id="conTestLRT_+3A_...">...</code></td>
<td>
<p>Additional arguments that can be passed to the p.distr function, 
or arguments for the restriktor or iht function. Consider, for example, the 
mix_weights_bootstrap_limit argument, which specifies the maximum number of 
bootstrap draws (default is 100.000) used to compute the chi-bar-square weights. 
If mix_weights_bootstrap_limit is set to 100.000, then in each iteration, a 
sample of size 5000 is added until the weights converge, or the maximum limit 
is reached.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following hypothesis tests are available:
</p>

<ul>
<li><p> Type A: Test H0: all constraints with equalities (&quot;=&quot;) 
active against HA: at least one inequality restriction (&quot;&gt;&quot;) 
strictly true.
</p>
</li>
<li><p> Type B: Test H0: all constraints with inequalities (&quot;&gt;&quot;) 
(including some equalities (&quot;=&quot;)) active against HA: at least 
one restriction false (some equality constraints may be 
maintained).
</p>
</li>
<li><p> Type C: Test H0: at least one restriction false (&quot;&lt;&quot;) 
against HA: all constraints strikty true (&quot;&gt;&quot;). This test is 
based on the intersection-union principle (Silvapulle and Sen, 
2005, chp 5.3). Note that, this test only makes sense in case 
of no equality constraints.
</p>
</li>
<li><p> Type global: equal to Type A but H0 contains additional 
equality constraints. This test is analogue to the global 
F-test in lm, where all coefficients but the intercept equal 0.
</p>
</li></ul>

<p>The null-distribution of hypothesis test Type C is based on a 
t-distribution (one-sided). Its power can be poor in case of many 
inequalty constraints. Its main role is to prevent wrong 
conclusions from significant results from hypothesis test Type A.
</p>
<p>The exact finite sample distributions of the non-robust F-, 
score- and LR-test statistics based on restricted OLS estimates 
and normally distributed errors, are a mixture of F-distributions 
under the null hypothesis (Wolak, 1987). In agreement with 
Silvapulle (1992), we found that the results based on these 
mixtures of F-distributions approximate the tail probabilities of 
the robust tests better than their asymptotic distributions. 
Therefore, all p-values for hypothesis test Type <code>"A"</code>, 
<code>"B"</code> and <code>"global"</code> are computed based on mixtures of 
F-distributions. 
</p>


<h3>Value</h3>

<p>An object of class conTest, for which a print is available. 
More specifically, it is a list with the following items:
</p>
<table role = "presentation">
<tr><td><code>CON</code></td>
<td>
<p>a list with useful information about the constraints.</p>
</td></tr>
<tr><td><code>Amat</code></td>
<td>
<p>constraints matrix.</p>
</td></tr>
<tr><td><code>bvec</code></td>
<td>
<p>vector of right-hand side elements.</p>
</td></tr>
<tr><td><code>meq</code></td>
<td>
<p>number of equality constraints.</p>
</td></tr>
<tr><td><code>meq_alt</code></td>
<td>
<p>same as input neq.alt.</p>
</td></tr>
<tr><td><code>iact</code></td>
<td>
<p>number of active constraints.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>Ts</code></td>
<td>
<p>test-statistic value.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>tail probability for <code>Ts</code>.</p>
</td></tr>
<tr><td><code>b_eqrestr</code></td>
<td>
<p>equality restricted regression coefficients. 
Only available for <code>type = "A"</code> and <code>type = "global"</code>, 
else <code>b.eqrestr = NULL</code>.</p>
</td></tr>
<tr><td><code>b_unrestr</code></td>
<td>
<p>unrestricted regression coefficients.</p>
</td></tr>
<tr><td><code>b_restr</code></td>
<td>
<p>restricted regression coefficients.</p>
</td></tr>
<tr><td><code>b_restr_alt</code></td>
<td>
<p>restricted regression coefficients under HA 
if some equality constraints are maintained. Only available for 
<code>type = "B"</code> else <code>b_restr_alt = NULL</code>.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>variance-covariance matrix of unrestricted model.</p>
</td></tr>
<tr><td><code>R2_org</code></td>
<td>
<p>unrestricted R-squared, not available for objects of class <code>conGLM</code>.</p>
</td></tr>
<tr><td><code>R2_reduced</code></td>
<td>
<p>restricted R-squared, not available for objects of class <code>conGLM</code>.</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>model_org</code></td>
<td>
<p>original model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Silvapulle, M.J. and Sen, P.K. (2005). <em>Constrained 
Statistical Inference</em>. Wiley, New York
</p>


<h3>See Also</h3>

 
<p><a href="quadprog.html#topic+solve.QP">quadprog</a>, 
<code><a href="#topic+conTest">conTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1:
# the data consist of ages (in months) at which an 
# infant starts to walk alone.

# prepare data
DATA1 &lt;- subset(ZelazoKolb1972, Group != "Control")

# fit unrestricted linear model
fit1_lm &lt;- lm(Age ~ -1 + Group, data = DATA1)

# the variable names can be used to impose constraints on
# the corresponding regression parameters.
coef(fit1_lm)

# constraint syntax: assuming that the walking 
# exercises would not have a negative effect of increasing the 
# mean age at which a child starts to walk. 
myConstraints1 &lt;- ' GroupActive  &lt; GroupPassive &lt; GroupNo '

iht(fit1_lm, myConstraints1, test = "LRT")


# another way is to first fit the restricted model
fit_restr1 &lt;- restriktor(fit1_lm, constraints = myConstraints1)

iht(fit_restr1, test = "LRT")


# Or in matrix notation.
Amat1 &lt;- rbind(c(-1, 0,  1),
               c( 0, 1, -1))
myRhs1 &lt;- rep(0L, nrow(Amat1)) 
myNeq1 &lt;- 0

iht(fit1_lm, constraints = Amat1, test = "LRT",
    rhs = myRhs1, neq = myNeq1)

#########################
## Artificial examples ##
#########################
# generate data
n &lt;- 10
means &lt;- c(1,2,1,3)
nm &lt;- length(means)
group &lt;- as.factor(rep(1:nm, each = n))
y &lt;- rnorm(n * nm, rep(means, each = n))
DATA2 &lt;- data.frame(y, group)

# fit unrestricted linear model
fit2_lm &lt;- lm(y ~ -1 + group, data = DATA2)
coef(fit2_lm)

## example 2: increasing means
myConstraints2 &lt;- ' group1 &lt; group2 &lt; group3 &lt; group4 '

# compute F-test for hypothesis test Type A and compute the tail 
# probability based on the parametric bootstrap. We only generate 9 
# bootstrap samples in this example; in practice you may wish to 
# use a much higher number.
iht(fit2_lm, constraints = myConstraints2, type = "A", test = "LRT",
    boot = "parametric", R = 9)

# or fit restricted linear model
fit2_con &lt;- restriktor(fit2_lm, constraints = myConstraints2)

iht(fit2_con, test = "LRT")


# increasing means in matrix notation.
Amat2 &lt;- rbind(c(-1, 1, 0, 0),
               c( 0,-1, 1, 0),
               c( 0, 0,-1, 1))
myRhs2 &lt;- rep(0L, nrow(Amat2)) 
myNeq2 &lt;- 0

iht(fit2_con, constraints = Amat2, rhs = myRhs2, neq = myNeq2, 
    type = "A", test = "LRT", boot = "parametric", R = 9)

## example 3:
# combination of equality and inequality constraints.
myConstraints3 &lt;- ' group1  = group2
                    group3  &lt; group4 '

iht(fit2_lm, constraints = myConstraints3, type = "B", 
    test = "LRT", neq.alt = 1)

# fit resticted model and compute model-based bootstrapped 
# standard errors. We only generate 9 bootstrap samples in this 
# example; in practice you may wish to use a much higher number.
# Note that, a warning message may be thrown because the number of 
# bootstrap samples is too low.
fit3_con &lt;- restriktor(fit2_lm, constraints = myConstraints3, 
                       se = "boot.model.based", B = 9)
iht(fit3_con, type = "B", test = "LRT", neq.alt = 1)


## example 4:
# restriktor can also be used to define effects using the := operator 
# and impose constraints on them. For example, is the 
# average effect (AVE) larger than zero?
# generate data
n &lt;- 30
b0 &lt;- 10; b1 = 0.5; b2 = 1; b3 = 1.5
X &lt;- c(rep(c(0), n/2), rep(c(1), n/2))
set.seed(90) 
Z &lt;- rnorm(n, 16, 5)
y &lt;- b0 + b1*X + b2*Z + b3*X*Z + rnorm(n, 0, sd = 10) 
DATA3 = data.frame(cbind(y, X, Z))

# fit linear model with interaction
fit4_lm &lt;- lm(y ~ X*Z, data = DATA3)

# constraint syntax
myConstraints4 &lt;- ' AVE := X + 16.86137*X.Z; 
                    AVE &gt; 0 '

iht(fit4_lm, constraints = myConstraints4, test = "LRT")

# or
fit4_con &lt;- restriktor(fit4_lm, constraints = ' AVE := X + 16.86137*X.Z; 
                                                AVE &gt; 0 ')
iht(fit4_con, test = "LRT")
</code></pre>

<hr>
<h2 id='conTestScore'>Score-bar test for iht</h2><span id='topic+conTestScore'></span><span id='topic+conTestScore.conLM'></span><span id='topic+conTestScore.conRLM'></span><span id='topic+conTestScore.conGLM'></span>

<h3>Description</h3>

<p><code>conTestScore</code> tests linear equality and/or 
inequality restricted hypotheses for (robust) linear models by score-tests. It can be 
used directly and is called by the <code>conTest</code> function if <code>test = "score"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'conLM'
conTestScore(object, type = "A", neq.alt = 0, 
           boot = "no", R = 9999, p.distr = rnorm, 
           parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
           verbose = FALSE, control = NULL, ...)

## S3 method for class 'conRLM'
conTestScore(object, type = "A", neq.alt = 0, 
           boot = "no", R = 9999, p.distr = rnorm,  
           parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
           verbose = FALSE, control = NULL, ...)

## S3 method for class 'conGLM'
conTestScore(object, type = "A", neq.alt = 0, 
           boot = "no", R = 9999, p.distr = rnorm,  
           parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
           verbose = FALSE, control = NULL, ...)

</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conTestScore_+3A_object">object</code></td>
<td>
<p>an object of class <code>conLM</code>, <code>conRLM</code> or <code>conGLM</code>.</p>
</td></tr> 
<tr><td><code id="conTestScore_+3A_type">type</code></td>
<td>
<p>hypothesis test type &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;global&quot;, or 
&quot;summary&quot; (default). See details for more information.</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_neq.alt">neq.alt</code></td>
<td>
<p>integer: number of equality constraints that 
are maintained under the alternative hypothesis (for hypothesis 
test type &quot;B&quot;), see example 3.</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_boot">boot</code></td>
<td>
<p>the null-distribution of these test-statistics 
(except under type &quot;C&quot;, see details) takes the form of a mixture of 
F-distributions. The tail probabilities can be computed directly 
via bootstrapping; if <code>"parametric"</code>, the p-value is 
computed based on the parametric bootstrap. By default, samples 
are drawn from a normal distribution with mean zero and varance 
one. See <code>p.distr</code> for other distributional options. If 
<code>"model.based"</code>, a model-based bootstrap method is used. 
Instead of computing the p-value via simulation, the p-value
can also be computed using the chi-bar-square weights. If 
<code>"no"</code>, the p-value is computed based on the weights 
obtained via simulation (<code>mix_weights = "boot"</code>) or using the 
multivariate normal distribution function (<code>mix_weights = "pmvnorm"</code>).
Note that, these weights are already available in the restriktor objected and
do not need to be estimated again. However, there are two exception for objects 
of class <code>conRLM</code>, namely for computing the p-value for the robust 
<code>test</code> = <code>"Wald"</code> and the robust <code>"score"</code>. In these cases 
the weights need to be recalculated.
</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_r">R</code></td>
<td>
<p>integer; number of bootstrap draws for <code>boot</code>. 
The default value is set to 9999.</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_p.distr">p.distr</code></td>
<td>
<p>random generation distribution for the parametric bootstrap. For 
all available distributions see <code>?distributions</code>. For example, 
if <code>rnorm</code>, samples are drawn from the normal distribution (default) 
with mean zero and variance one. If <code>rt</code>, samples are drawn from 
a t-distribution. If <code>rchisq</code>, samples are drawn from a chi-square 
distribution. The random generation distributional parameters will 
be passed in via ....</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_parallel">parallel</code></td>
<td>
<p>the type of parallel operation to be used 
(if any). If missing, the default is set &quot;no&quot;.</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_ncpus">ncpus</code></td>
<td>
<p>integer: number of processes to be used in parallel 
operation: typically one would chose this to the number of 
available CPUs.</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_cl">cl</code></td>
<td>
<p>an optional parallel or snow cluster for use if 
parallel = &quot;snow&quot;. If not supplied, a cluster on the local 
machine is created for the duration of the conTest call.</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_seed">seed</code></td>
<td>
<p>seed value. The default value is set to 1234.</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, information is shown at each 
bootstrap draw.</p>
</td></tr>
<tr><td><code id="conTestScore_+3A_control">control</code></td>
<td>
<p>a list of control arguments: 
</p>

<ul>
<li> <p><code>absval</code> tolerance criterion for convergence 
(default = sqrt(.Machine$double.eps)). Only used for model 
of class lm.
</p>
</li>
<li> <p><code>maxit</code> the maximum number of iterations for the 
optimizer (default = 10000). Only used for model of class 
mlm (not yet supported). 
</p>
</li>
<li> <p><code>tol</code> numerical tolerance value. Estimates 
smaller than <code>tol</code> are set to 0.
</p>
</li>
<li> <p><code>chunk_size</code> the chi-bar-square weights are computed for samples 
of size <code>chunk_size = 5000L</code>. This process is repeated iteratively 
until the weights converges (see <code>convergenge_crit</code>) or the maximum 
is reached, i.e., mix_weights_bootstrap_limit.
</p>
</li>
<li> <p><code>convergence_crit</code> the convergence criterion for the iterative 
process. The default is 1e-03.
</p>
</li></ul>

</td></tr>
<tr><td><code id="conTestScore_+3A_...">...</code></td>
<td>
<p>Additional arguments that can be passed to the p.distr function, 
or arguments for the restriktor or iht function. Consider, for example, the 
mix_weights_bootstrap_limit argument, which specifies the maximum number of 
bootstrap draws (default is 100.000) used to compute the chi-bar-square weights. 
If mix_weights_bootstrap_limit is set to 100.000, then in each iteration, a 
sample of size 5000 is added until the weights converge, or the maximum limit 
is reached.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following hypothesis tests are available:
</p>

<ul>
<li><p> Type A: Test H0: all constraints with equalities (&quot;=&quot;) 
active against HA: at least one inequality restriction (&quot;&gt;&quot;) 
strictly true.
</p>
</li>
<li><p> Type B: Test H0: all constraints with inequalities (&quot;&gt;&quot;) 
(including some equalities (&quot;=&quot;)) active against HA: at least 
one restriction false (some equality constraints may be 
maintained).
</p>
</li>
<li><p> Type C: Test H0: at least one restriction false (&quot;&lt;&quot;) 
against HA: all constraints strikty true (&quot;&gt;&quot;). This test is 
based on the intersection-union principle (Silvapulle and Sen, 
2005, chp 5.3). Note that, this test only makes sense in case 
of no equality constraints.
</p>
</li>
<li><p> Type global: equal to Type A but H0 contains additional 
equality constraints. This test is analogue to the global 
F-test in lm, where all coefficients but the intercept equal 0.
</p>
</li></ul>

<p>The null-distribution of hypothesis test Type C is based on a 
t-distribution (one-sided). Its power can be poor in case of many 
inequalty constraints. Its main role is to prevent wrong 
conclusions from significant results from hypothesis test Type A.
</p>
<p>The exact finite sample distributions of the non-robust F-, 
score- and LR-test statistics based on restricted OLS estimates 
and normally distributed errors, are a mixture of F-distributions 
under the null hypothesis (Wolak, 1987). In agreement with 
Silvapulle (1992), we found that the results based on these 
mixtures of F-distributions approximate the tail probabilities of 
the robust tests better than their asymptotic distributions. 
Therefore, all p-values for hypothesis test Type <code>"A"</code>, 
<code>"B"</code> and <code>"global"</code> are computed based on mixtures of 
F-distributions. 
</p>


<h3>Value</h3>

<p>An object of class conTest, for which a print is available. 
More specifically, it is a list with the following items:
</p>
<table role = "presentation">
<tr><td><code>CON</code></td>
<td>
<p>a list with useful information about the constraints.</p>
</td></tr>
<tr><td><code>Amat</code></td>
<td>
<p>constraints matrix.</p>
</td></tr>
<tr><td><code>bvec</code></td>
<td>
<p>vector of right-hand side elements.</p>
</td></tr>
<tr><td><code>meq</code></td>
<td>
<p>number of equality constraints.</p>
</td></tr>
<tr><td><code>meq.alt</code></td>
<td>
<p>same as input neq.alt.</p>
</td></tr>
<tr><td><code>iact</code></td>
<td>
<p>number of active constraints.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>Ts</code></td>
<td>
<p>test-statistic value.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>tail probability for <code>Ts</code>.</p>
</td></tr>
<tr><td><code>b.eqrestr</code></td>
<td>
<p>equality restricted regression coefficients. 
Only available for <code>type = "A"</code> and <code>type = "global"</code>, 
else <code>b.eqrestr = NULL</code>.</p>
</td></tr>
<tr><td><code>b.unrestr</code></td>
<td>
<p>unrestricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr</code></td>
<td>
<p>restricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr.alt</code></td>
<td>
<p>restricted regression coefficients under HA 
if some equality constraints are maintained. Only available for 
<code>type = "B"</code> else <code>b.restr.alt = NULL</code>.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>variance-covariance matrix of unrestricted model.</p>
</td></tr>
<tr><td><code>R2.org</code></td>
<td>
<p>unrestricted R-squared, not available for objects of class <code>conGLM</code>.</p>
</td></tr>
<tr><td><code>R2.reduced</code></td>
<td>
<p>restricted R-squared, not available for objects of class <code>conGLM</code>.</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>model.org</code></td>
<td>
<p>original model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Silvapulle, M. and Silvapulle, P. (1995). A score test against 
one-sided alternatives. <em>American statistical association</em>, 
<b>90</b>, 342&ndash;349.
</p>
<p>Silvapulle, M. (1996) Robust bounded influence tests against 
one-sided hypotheses in general parametric models. 
<em>Statistics and probability letters</em>, <b>31</b>, 45&ndash;50.
</p>
<p>Silvapulle, M.J. and Sen, P.K. (2005). <em>Constrained 
Statistical Inference</em>. Wiley, New York
</p>


<h3>See Also</h3>

 
<p><a href="quadprog.html#topic+solve.QP">quadprog</a>, 
<code><a href="#topic+conTest">conTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1:
# the data consist of ages (in months) at which an 
# infant starts to walk alone.

# prepare data
DATA1 &lt;- subset(ZelazoKolb1972, Group != "Control")

# fit unrestricted linear model
fit1.lm &lt;- lm(Age ~ -1 + Group, data = DATA1)

# the variable names can be used to impose constraints on
# the corresponding regression parameters.
coef(fit1.lm)

# constraint syntax: assuming that the walking 
# exercises would not have a negative effect of increasing the 
# mean age at which a child starts to walk. 
myConstraints1 &lt;- ' GroupActive  &lt; GroupPassive; 
                    GroupPassive &lt; GroupNo '

iht(fit1.lm, myConstraints1, test = "score")


# another way is to first fit the restricted model
fit.restr1 &lt;- restriktor(fit1.lm, constraints = myConstraints1)

iht(fit.restr1, test = "score")


# Or in matrix notation.
Amat1 &lt;- rbind(c(-1, 0,  1),
               c( 0, 1, -1))
myRhs1 &lt;- rep(0L, nrow(Amat1)) 
myNeq1 &lt;- 0

iht(fit1.lm, constraints = Amat1, test = "score", rhs = myRhs1, neq = myNeq1)


#########################
## Artificial examples ##
#########################
# generate data
n &lt;- 10
means &lt;- c(1,2,1,3)
nm &lt;- length(means)
group &lt;- as.factor(rep(1:nm, each = n))
y &lt;- rnorm(n * nm, rep(means, each = n))
DATA2 &lt;- data.frame(y, group)

# fit unrestricted linear model
fit2.lm &lt;- lm(y ~ -1 + group, data = DATA2)
coef(fit2.lm)

## example 2: increasing means
myConstraints2 &lt;- ' group1 &lt; group2 &lt; group3 &lt; group4 '

# compute F-test for hypothesis test Type A and compute the tail 
# probability based on the parametric bootstrap. We only generate 9 
# bootstrap samples in this example; in practice you may wish to 
# use a much higher number.
iht(fit2.lm, constraints = myConstraints2, type = "A", test = "score",
    boot = "parametric", R = 9)


# or fit restricted linear model
fit2.con &lt;- restriktor(fit2.lm, constraints = myConstraints2)

conTest(fit2.con, test = "score")


# increasing means in matrix notation.
Amat2 &lt;- rbind(c(-1, 1, 0, 0),
               c( 0,-1, 1, 0),
               c( 0, 0,-1, 1))
myRhs2 &lt;- rep(0L, nrow(Amat2)) 
myNeq2 &lt;- 0

iht(fit2.con, constraints = Amat2, rhs = myRhs2, neq = myNeq2, 
    type = "A", test = "score", boot = "parametric", R = 9)

## example 3:
# combination of equality and inequality constraints.
myConstraints3 &lt;- ' group1  = group2
                    group3  &lt; group4 '

iht(fit2.lm, constraints = myConstraints3, type = "B", test = "score", neq.alt = 1)

# fit resticted model and compute model-based bootstrapped 
# standard errors. We only generate 9 bootstrap samples in this 
# example; in practice you may wish to use a much higher number.
# Note that, a warning message may be thrown because the number of 
# bootstrap samples is too low.
fit3.con &lt;- restriktor(fit2.lm, constraints = myConstraints3, 
                       se = "boot.model.based", B = 9)
iht(fit3.con, type = "B", test = "score", neq.alt = 1)


## example 4:
# restriktor can also be used to define effects using the := operator 
# and impose constraints on them. For example, is the 
# average effect (AVE) larger than zero?
# generate data
n &lt;- 30
b0 &lt;- 10; b1 = 0.5; b2 = 1; b3 = 1.5
X &lt;- c(rep(c(0), n/2), rep(c(1), n/2))
set.seed(90) 
Z &lt;- rnorm(n, 16, 5)
y &lt;- b0 + b1*X + b2*Z + b3*X*Z + rnorm(n, 0, sd = 10) 
DATA3 = data.frame(cbind(y, X, Z))

# fit linear model with interaction
fit4.lm &lt;- lm(y ~ X*Z, data = DATA3)

# constraint syntax
myConstraints4 &lt;- ' AVE := X + 16.86137*X.Z; 
                    AVE &gt; 0 '

iht(fit4.lm, constraints = myConstraints4, test = "score")

# or
fit4.con &lt;- restriktor(fit4.lm, constraints = ' AVE := X + 16.86137*X.Z; 
                                                AVE &gt; 0 ')
iht(fit4.con, test = "score")
</code></pre>

<hr>
<h2 id='conTestWald'>Wald-bar test for robust iht</h2><span id='topic+conTestWald'></span><span id='topic+conTestWald.conRLM'></span>

<h3>Description</h3>

<p><code>conTestWald</code> tests linear equality and/or 
inequality restricted hypotheses for linear models by Wald-tests. 
It can be used directly and is called by the <code>conTest</code> function 
if <code>test = "Wald"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'conRLM'
conTestWald(object, type = "A", neq.alt = 0, 
           boot = "no", R = 9999, p.distr = rnorm,  
           parallel = "no", ncpus = 1L, cl = NULL, seed = 1234, 
           verbose = FALSE, control = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conTestWald_+3A_object">object</code></td>
<td>
<p>an object of class <code>conRLM</code>.</p>
</td></tr> 
<tr><td><code id="conTestWald_+3A_type">type</code></td>
<td>
<p>hypothesis test type &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;global&quot;, or 
&quot;summary&quot; (default). See details for more information.</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_neq.alt">neq.alt</code></td>
<td>
<p>integer: number of equality constraints that 
are maintained under the alternative hypothesis (for hypothesis 
test type &quot;B&quot;), see example 3.</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_boot">boot</code></td>
<td>
<p>the null-distribution of these test-statistics 
(except under type &quot;C&quot;, see details) takes the form of a mixture of 
F-distributions. The tail probabilities can be computed directly 
via bootstrapping; if <code>"parametric"</code>, the p-value is 
computed based on the parametric bootstrap. By default, samples 
are drawn from a normal distribution with mean zero and varance 
one. See <code>p.distr</code> for other distributional options. If 
<code>"model.based"</code>, a model-based bootstrap method is used. 
Instead of computing the p-value via simulation, the p-value
can also be computed using the chi-bar-square weights. If 
<code>"no"</code>, the p-value is computed based on the weights 
obtained via simulation (<code>mix_weights = "boot"</code>) or using the 
multivariate normal distribution function (<code>mix_weights = "pmvnorm"</code>).
Note that, these weights are already available in the restriktor objected and
do not need to be estimated again. However, there are two exception for objects 
of class <code>conRLM</code>, namely for computing the p-value for the robust 
<code>test</code> = <code>"Wald"</code> and the robust <code>"score"</code>. In these cases 
the weights need to be recalculated.
</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_r">R</code></td>
<td>
<p>integer; number of bootstrap draws for <code>boot</code>. 
The default value is set to 9999.</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_p.distr">p.distr</code></td>
<td>
<p>random generation distribution for the parametric bootstrap. For 
all available distributions see <code>?distributions</code>. For example, 
if <code>rnorm</code>, samples are drawn from the normal distribution (default) 
with mean zero and variance one. If <code>rt</code>, samples are drawn from 
a t-distribution. If <code>rchisq</code>, samples are drawn from a chi-square 
distribution. The random generation distributional parameters will 
be passed in via ....</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_parallel">parallel</code></td>
<td>
<p>the type of parallel operation to be used 
(if any). If missing, the default is set &quot;no&quot;.</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_ncpus">ncpus</code></td>
<td>
<p>integer: number of processes to be used in parallel 
operation: typically one would chose this to the number of 
available CPUs.</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_cl">cl</code></td>
<td>
<p>an optional parallel or snow cluster for use if 
parallel = &quot;snow&quot;. If not supplied, a cluster on the local 
machine is created for the duration of the conTest call.</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_seed">seed</code></td>
<td>
<p>seed value. The default value is set to 1234.</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, information is shown at each 
bootstrap draw.</p>
</td></tr>
<tr><td><code id="conTestWald_+3A_control">control</code></td>
<td>
<p>a list of control arguments: 
</p>

<ul>
<li> <p><code>absval</code> tolerance criterion for convergence 
(default = sqrt(.Machine$double.eps)). Only used for model 
of class lm.
</p>
</li>
<li> <p><code>maxit</code> the maximum number of iterations for the 
optimizer (default = 10000). Only used for model of class 
mlm (not yet supported). 
</p>
</li>
<li> <p><code>tol</code> numerical tolerance value. Estimates 
smaller than <code>tol</code> are set to 0.
</p>
</li>
<li> <p><code>chunk_size</code> the chi-bar-square weights are computed for samples 
of size <code>chunk_size = 5000L</code>. This process is repeated iteratively 
until the weights converges (see <code>convergenge_crit</code>) or the maximum 
is reached, i.e., mix_weights_bootstrap_limit.
</p>
</li>
<li> <p><code>convergence_crit</code> the convergence criterion for the iterative 
process. The default is 1e-03.</p>
</li></ul>

</td></tr>
<tr><td><code id="conTestWald_+3A_...">...</code></td>
<td>
<p>Additional arguments that can be passed to the p.distr function, 
or arguments for the restriktor or iht function. Consider, for example, the 
mix_weights_bootstrap_limit argument, which specifies the maximum number of 
bootstrap draws (default is 100.000) used to compute the chi-bar-square weights. 
If mix_weights_bootstrap_limit is set to 100.000, then in each iteration, a 
sample of size 5000 is added until the weights converge, or the maximum limit 
is reached.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following hypothesis tests are available:
</p>

<ul>
<li><p> Type A: Test H0: all constraints with equalities (&quot;=&quot;) 
active against HA: at least one inequality restriction (&quot;&gt;&quot;) 
strictly true.
</p>
</li>
<li><p> Type B: Test H0: all constraints with inequalities (&quot;&gt;&quot;) 
(including some equalities (&quot;=&quot;)) active against HA: at least 
one restriction false (some equality constraints may be 
maintained).
</p>
</li>
<li><p> Type C: Test H0: at least one restriction false (&quot;&lt;&quot;) 
against HA: all constraints strikty true (&quot;&gt;&quot;). This test is 
based on the intersection-union principle (Silvapulle and Sen, 
2005, chp 5.3). Note that, this test only makes sense in case 
of no equality constraints.
</p>
</li>
<li><p> Type global: equal to Type A but H0 contains additional 
equality constraints. This test is analogue to the global 
F-test in lm, where all coefficients but the intercept equal 0.
</p>
</li></ul>

<p>The null-distribution of hypothesis test Type C is based on a 
t-distribution (one-sided). Its power can be poor in case of many 
inequalty constraints. Its main role is to prevent wrong 
conclusions from significant results from hypothesis test Type A.
</p>
<p>The exact finite sample distributions of the non-robust F-, 
score- and LR-test statistics based on restricted OLS estimates 
and normally distributed errors, are a mixture of F-distributions 
under the null hypothesis (Wolak, 1987). In agreement with 
Silvapulle (1992), we found that the results based on these 
mixtures of F-distributions approximate the tail probabilities of 
the robust tests better than their asymptotic distributions. 
Therefore, all p-values for hypothesis test Type <code>"A"</code>, 
<code>"B"</code> and <code>"global"</code> are computed based on mixtures of 
F-distributions. 
</p>


<h3>Value</h3>

<p>An object of class conTest, for which a print is available. 
More specifically, it is a list with the following items:
</p>
<table role = "presentation">
<tr><td><code>CON</code></td>
<td>
<p>a list with useful information about the constraints.</p>
</td></tr>
<tr><td><code>Amat</code></td>
<td>
<p>constraints matrix.</p>
</td></tr>
<tr><td><code>bvec</code></td>
<td>
<p>vector of right-hand side elements.</p>
</td></tr>
<tr><td><code>meq</code></td>
<td>
<p>number of equality constraints.</p>
</td></tr>
<tr><td><code>meq.alt</code></td>
<td>
<p>same as input neq.alt.</p>
</td></tr>
<tr><td><code>iact</code></td>
<td>
<p>number of active constraints.</p>
</td></tr>
<tr><td><code>type</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>test</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>Ts</code></td>
<td>
<p>test-statistic value.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom.</p>
</td></tr>
<tr><td><code>pvalue</code></td>
<td>
<p>tail probability for <code>Ts</code>.</p>
</td></tr>
<tr><td><code>b.eqrestr</code></td>
<td>
<p>equality restricted regression coefficients. 
Only available for <code>type = "A"</code> and <code>type = "global"</code>, 
else <code>b.eqrestr = NULL</code>.</p>
</td></tr>
<tr><td><code>b.unrestr</code></td>
<td>
<p>unrestricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr</code></td>
<td>
<p>restricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr.alt</code></td>
<td>
<p>restricted regression coefficients under HA 
if some equality constraints are maintained. Only available for 
<code>type = "B"</code> else <code>b.restr.alt = NULL</code>.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>variance-covariance matrix of unrestricted model.</p>
</td></tr>
<tr><td><code>R2.org</code></td>
<td>
<p>unrestricted R-squared, not available for objects of class <code>conGLM</code>.</p>
</td></tr>
<tr><td><code>R2.reduced</code></td>
<td>
<p>restricted R-squared, not available for objects of class <code>conGLM</code>.</p>
</td></tr>
<tr><td><code>boot</code></td>
<td>
<p>same as input.</p>
</td></tr>
<tr><td><code>model.org</code></td>
<td>
<p>original model.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Silvapulle, M. (1992b). Robust Wald-Type Tests of One-Sided Hypotheses 
in the Linear Model. <em>Journal of the American Statistical Association</em>, 
<b>87</b>, 156&ndash;161.
</p>
<p>Silvapulle, M. (1996) Robust bounded influence tests against one-sided hypotheses
in general parametric models. <em>Statistics and probability letters</em>, 
<b>31</b>, 45&ndash;50.
</p>
<p>Silvapulle, M.J. and Sen, P.K. (2005). <em>Constrained 
Statistical Inference</em>. Wiley, New York
</p>


<h3>See Also</h3>

 
<p><a href="quadprog.html#topic+solve.QP">quadprog</a>, 
<code><a href="#topic+conTest">conTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(MASS)
## example 1:
# the data consist of ages (in months) at which an 
# infant starts to walk alone.

# prepare data
DATA1 &lt;- subset(ZelazoKolb1972, Group != "Control")

# fit unrestricted robust linear model
fit1.rlm &lt;- rlm(Age ~ -1 + Group, data = DATA1, method = "MM")

# the variable names can be used to impose constraints on
# the corresponding regression parameters.
coef(fit1.rlm)

# constraint syntax: assuming that the walking 
# exercises would not have a negative effect of increasing the 
# mean age at which a child starts to walk. 
myConstraints1 &lt;- ' GroupActive  &lt; GroupPassive; 
                    GroupPassive &lt; GroupNo '

iht(fit1.rlm, myConstraints1, test = "Wald")


# another way is to first fit the restricted model
fit.restr1 &lt;- restriktor(fit1.rlm, constraints = myConstraints1)

iht(fit.restr1, test = "Wald")


# Or in matrix notation.
Amat1 &lt;- rbind(c(-1, 0,  1),
               c( 0, 1, -1))
myRhs1 &lt;- rep(0L, nrow(Amat1)) 
myNeq1 &lt;- 0

iht(fit1.rlm, constraints = Amat1, test = "Wald", rhs = myRhs1, neq = myNeq1)


#########################
## Artificial examples ##
#########################
# generate data
n &lt;- 30
means &lt;- c(1,2,1,3)
nm &lt;- length(means)
group &lt;- as.factor(rep(1:nm, each = n))
y &lt;- rnorm(n * nm, rep(means, each = n))
DATA2 &lt;- data.frame(y, group)

# fit unrestricted robust linear model
fit2.rlm &lt;- rlm(y ~ -1 + group, data = DATA2, method = "MM")
coef(fit2.rlm)

## example 2: increasing means
myConstraints2 &lt;- ' group1 &lt; group2 &lt; group3 &lt; group4 '

# compute Wald-test for hypothesis test Type A and compute the tail 
# probability based on the parametric bootstrap. We only generate 9 
# bootstrap samples in this example; in practice you may wish to 
# use a much higher number.
iht(fit2.rlm, constraints = myConstraints2, type = "A", 
    test = "Wald", boot = "parametric", R = 9)


# or fit restricted robust linear model
fit2.con &lt;- restriktor(fit2.rlm, constraints = myConstraints2)

iht(fit2.con, test = "Wald")

# increasing means in matrix notation.
Amat2 &lt;- rbind(c(-1, 1, 0, 0),
               c( 0,-1, 1, 0),
               c( 0, 0,-1, 1))
myRhs2 &lt;- rep(0L, nrow(Amat2)) 
myNeq2 &lt;- 0

iht(fit2.con, constraints = Amat2, rhs = myRhs2, neq = myNeq2, 
    type = "A", test = "Wald", boot = "parametric", R = 9)
            

## example 3:
# combination of equality and inequality constraints.
myConstraints3 &lt;- ' group1  = group2
                    group3  &lt; group4 '

iht(fit2.rlm, constraints = myConstraints3, type = "B", test = "Wald", neq.alt = 1)

# fit robust resticted model and compute model-based bootstrapped 
# standard errors. We only generate 9 bootstrap samples in this 
# example; in practice you may wish to use a much higher number.
# Note that, a warning message may be thrown because the number of 
# bootstrap samples is too low.
fit3.con &lt;- restriktor(fit2.rlm, constraints = myConstraints3, 
                       se = "boot.model.based", B = 9)
iht(fit3.con, type = "B", test = "Wald", neq.alt = 1)


## example 4:
# restriktor can also be used to define effects using the := operator 
# and impose constraints on them. For example, is the 
# average effect (AVE) larger than zero?
# generate data
n &lt;- 30
b0 &lt;- 10; b1 = 0.5; b2 = 1; b3 = 1.5
X &lt;- c(rep(c(0), n/2), rep(c(1), n/2))
set.seed(90) 
Z &lt;- rnorm(n, 16, 5)
y &lt;- b0 + b1*X + b2*Z + b3*X*Z + rnorm(n, 0, sd = 10) 
DATA3 = data.frame(cbind(y, X, Z))

# fit linear model with interaction
fit3.rlm &lt;- rlm(y ~ X*Z, data = DATA3, method = "MM")

# constraint syntax
myConstraints4 &lt;- ' AVE := X + 16.86137*X.Z; 
                    AVE &gt; 0 '

iht(fit3.rlm, constraints = myConstraints4, test = "Wald")

# or
fit3.con &lt;- restriktor(fit3.rlm, constraints = ' AVE := X + 16.86137*X.Z; 
                                                 AVE &gt; 0 ')
iht(fit3.con, test = "Wald")
</code></pre>

<hr>
<h2 id='evSyn'>GORIC(A) Evidence synthesis</h2><span id='topic+evSyn'></span><span id='topic+evsyn'></span><span id='topic+evSyn_est'></span><span id='topic+evSyn_LL'></span><span id='topic+evSyn_ICvalues'></span><span id='topic+evSyn_ICweights'></span><span id='topic+evSyn_ICratios'></span><span id='topic+evSyn_gorica'></span><span id='topic+evSyn_escalc'></span><span id='topic+print.evSyn'></span><span id='topic+print.summary.evSyn'></span><span id='topic+summary.evSyn'></span><span id='topic+plot.evSyn'></span>

<h3>Description</h3>

<p>GORIC(A) evidence synthesis aggregates the evidence for theory-based 
hypotheses from multiple studies that may use diverse designs to investigate the 
same central theory.</p>


<h3>Usage</h3>

<pre><code class='language-R'># I try to guess the input type.
evSyn(object, input_type = NULL, ...)

# input: Parameter estimates and covariance matrix
evSyn_est(object, ..., VCOV = list(), hypotheses = list(),
          type = c("added", "equal", "average"), 
          comparison = c("unconstrained", "complement", "none"),
          hypo_names = c())

# input: Log-likelihood and penalty values
evSyn_LL(object, ..., PT = list(), type = c("added", "equal", "average"),
         hypo_names = c())

# input: GORIC(A), ORIC, AIC values
evSyn_ICvalues(object, ..., hypo_names = c())

# input: AIC or ORIC or GORIC or GORICA weights or (Bayesian) posterior 
# model probabilities
evSyn_ICweights(object, ..., priorWeights = NULL, hypo_names = c())

# input: Ratio of AIC or ORIC or GORIC or GORICA weights or 
# (Bayesian) posterior model probabilities
evSyn_ICratios(object, ..., priorWeights = NULL, hypo_names = c())

# input: result from the goric() function
# Note that this is a wrapper function for evSyn_LL.
evSyn_gorica(object, ..., type = c("added", "equal", "average"), hypo_names = c())

# input: Result from the escalc() function from the metafor package. 
# Note that this is a wrapper function for evSyn_est.
evSyn_escalc(data, yi_col = "yi", vi_cols = "vi", cluster_col, outcome_col, ...)

## S3 method for class 'evSyn'
print(x, digits = max(3, getOption("digits") - 4), ...)

## S3 method for class 'evSyn'
summary(object, ...)

## S3 method for class 'summary.evSyn'
print(x, digits = max(3, getOption("digits") - 4), ...)  

## S3 method for class 'evSyn'
plot(x, output_type = "gorica_weights", xlab = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="evSyn_+3A_object">object</code></td>
<td>
<p>Currently, the following objects can be processed:
</p>

<ul>
<li><p> a list of vectors with (standardized) parameter estimates (the <code>VCOV</code> argument is required);   
</p>
</li>
<li><p> a list of vectors with log-likelihood values (the <code>PT</code> argument is required);
</p>
</li>
<li><p> a list of vectors with GORIC(A) weights;
</p>
</li>
<li><p> a list of vectors with ratio of GORIC(A) weights;
</p>
</li>
<li><p> a list of vectors with GORIC(A) values;
</p>
</li>
<li><p> a list of objects of class goric;
</p>
</li>
<li><p> a data.frame of class escalc from the <span class="pkg">metafore</span> package;
</p>
</li></ul>

</td></tr>
<tr><td><code id="evSyn_+3A_input_type">input_type</code></td>
<td>

<p><code>character</code> Specifies the type of input provided to the function. Valid options are:
</p>

<dl>
<dt><code>"est_vcov"</code></dt><dd><p>Indicates that the input consists of estimates and covariance matrices. Invokes the <code>evSyn_est()</code> function.</p>
</dd>
<dt><code>"ll_pt"</code></dt><dd><p>Indicates that the input consists of log-likelihoods and penalty values. Invokes the <code>evSyn_LL()</code> function.</p>
</dd>
<dt><code>"icweights"</code></dt><dd><p>Indicates that the input consists of information criterion (IC) weights. Invokes the <code>evSyn_ICweights()</code> function.</p>
</dd>
<dt><code>"icratios"</code></dt><dd><p>Indicates that the input consists of IC weights ratios. Invokes the <code>evSyn_ICratios()</code> function.</p>
</dd>
<dt><code>"icvalues"</code></dt><dd><p>Indicates that the input consists of IC values. Invokes the <code>evSyn_ICvalues()</code> function.</p>
</dd>
<dt><code>"gorica"</code></dt><dd><p>Indicates that the input is of class goric from the <code>goric</code> function. Invokes the <code>evSyn_gorica()</code> function.</p>
</dd>
<dt><code>"escalc"</code></dt><dd><p>Indicates that the input is of class escalc from the <span class="pkg">metafor</span> package. Invokes the <code>evSyn_escalc()</code> function.</p>
</dd>
</dl>

<p>If <code>input_type</code> is <code>NULL</code>, the function attempts to infer the input type based on the structure of the <code>object</code> and other arguments.
</p>
</td></tr>
<tr><td><code id="evSyn_+3A_vcov">VCOV</code></td>
<td>
<p>a list of covariance matrices of the (standardized) parameter estimates 
of interest.</p>
</td></tr> 
<tr><td><code id="evSyn_+3A_pt">PT</code></td>
<td>
<p>a list of vectors with penalty values.</p>
</td></tr>
<tr><td><code id="evSyn_+3A_x">x</code></td>
<td>
<p>an object of class <code>evSyn</code></p>
</td></tr>
<tr><td><code id="evSyn_+3A_type">type</code></td>
<td>
<p>type of evidence-synthesis approach: Equal-evidence approach 
(<code>type = "equal"</code>), Added-evidence approach (<code>type = "added"</code>), or
Average-evidence approach (<code>type = "average"</code>). See details for more 
information.</p>
</td></tr>
<tr><td><code id="evSyn_+3A_hypotheses">hypotheses</code></td>
<td>
<p>When applying the same set of hypotheses to each study, 
the syntax structure should be as follows: &quot;hypotheses = list(H1, H2, ...)&quot;. 
However, if a different set of hypotheses is applied to each study, the syntax 
structure should be as follows: hypotheses = list(set1 = list(H11, H12), set2 = list(H21, H22)).
See <code><a href="#topic+goric">goric</a></code> how to specify the hypotheses syntax or see the example 
section below.</p>
</td></tr>
<tr><td><code id="evSyn_+3A_comparison">comparison</code></td>
<td>
<p>if &quot;<code>unconstrained</code>&quot; (default) the unconstrained model is 
included in the set of models. If &quot;<code>complement</code>&quot; then the restricted object 
is compared against its complement. Note that the complement can only be computed 
for one model/hypothesis at a time (for now). If &quot;<code>none</code>&quot; the model is only 
compared against the models provided by the user.</p>
</td></tr> 
<tr><td><code id="evSyn_+3A_priorweights">priorWeights</code></td>
<td>
<p>vector that represents the prior belief for this model. By default,
equal prior weights are used (i.e., 1/(#hypotheses)). Notably, in case the prior
weights do not sum to 1, it will be rescaled such that it does; which implies that
relative importance can be used and not per se weights.</p>
</td></tr>
<tr><td><code id="evSyn_+3A_hypo_names">hypo_names</code></td>
<td>
<p>character vector for labelling the hypotheses. By default the
names are set to H1, H2, ...</p>
</td></tr>
<tr><td><code id="evSyn_+3A_output_type">output_type</code></td>
<td>
<p>if &quot;<code>gorica_weights</code>&quot;, a plot with the cumulative goric(a)
weights and goric(a) weights per study is displayed. If &quot;<code>ll_weights</code>&quot;
a plot with the cumulative log-likelihood weights and log-likelihood weights 
per study is displayed.</p>
</td></tr>
<tr><td><code id="evSyn_+3A_xlab">xlab</code></td>
<td>
<p>a vector specifying custom labels for the x-axis. The length of 
the vector must match the number of studies in the dataset. If not provided, 
the x-axis labels default to a sequence from 1 to the number of studies.</p>
</td></tr>
<tr><td><code id="evSyn_+3A_data">data</code></td>
<td>
<p>an object of class &quot;escalc&quot; from the <span class="pkg">metafor</span> package.</p>
</td></tr>
<tr><td><code id="evSyn_+3A_outcome_col">outcome_col</code></td>
<td>
<p>an optional column name in <code>data</code> containing the outcome 
identifiers for each observation within a cluster. If <code>NULL</code>, the function 
assumes the outcome identifier is &quot;yi&quot; (one outcome variable).</p>
</td></tr>
<tr><td><code id="evSyn_+3A_yi_col">yi_col</code></td>
<td>
<p>a character string specifying the column in <code>data</code> that 
contains the outcome values for each observation. The default is <code>"yi"</code> 
(one outcome variable).</p>
</td></tr>
<tr><td><code id="evSyn_+3A_vi_cols">vi_cols</code></td>
<td>
<p>a character vector specifying the columns in <code>data</code> that 
contain the variance and covariance values for each observation. The default is 
<code>"vi"</code> (one outcome variable).</p>
</td></tr>
<tr><td><code id="evSyn_+3A_cluster_col">cluster_col</code></td>
<td>
<p>a character string specifying the column in <code>data</code> that 
contains the cluster identifier. Observations within the same cluster should 
share the same value in this column. The default is <code>"trial"</code>, other usual
suspects are <code>"study"</code> and <code>"author"</code>.</p>
</td></tr>
<tr><td><code id="evSyn_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="evSyn_+3A_...">...</code></td>
<td>
<p>This depends on the class of the object.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the <strong>added-evidence</strong> approach, evidence from each study or dataset is 
cumulatively aggregated. This means that for every new study, the log-likelihood 
and the penalty term are added to the cumulative totals. The strength of the 
aggregated evidence in this approach depends on the nature of the evidence itself. 
Simply having more studies doesn't necessarily mean stronger evidence if those 
studies provide weak or contradictory evidence.<br /> 
Opt for this approach when you anticipate each new piece of evidence to provide an 
incremental contribution to the overall evidence, without the need to normalize or 
average across datasets. It's especially suitable when you believe that the 
aggregated evidence from multiple studies is stronger than if the data were combined 
into a single study.
</p>
<p>The <strong>equal-evidence</strong> approach aggregates the cumulative evidence in the same 
manner as the added-evidence approach. However, when calculating the GORICA, the 
cumulative evidence is divided by the number of studies. This ensures that the 
contribution from each study or dataset remains equal, regardless of the total count. 
Conceptually, aggregating evidence from multiple studies in this approach can be 
likened to obtaining evidence from a single larger study, similar to how a 
meta-analysis treats combined evidence.<br />
Choose this method when you want each study to contribute equally to the overall 
evidence, irrespective of the size or scope of each individual dataset. It's ideal 
for situations where you view the combined evidence from multiple studies as 
equivalent to that from a single, larger study.
</p>
<p>The <strong>average-evidence</strong> method can be conceptualized as a form of multiverse 
analysis. When faced with a single dataset, there are often numerous analytical 
choices available, such as handling missing data, selecting variables, or choosing 
statistical methods. Each choice can lead to a different analysis or model, creating 
a &quot;multiverse&quot; of possible outcomes.<br />
For each of these analyses, an &quot;evidence&quot; score can be calculated, indicating how 
well the model fits the data. Some models might offer a superior fit, while others 
might not align as closely with the data. The average-evidence method aggregates 
these scores, providing an average measure of fit across all considered models.
This approach offers an overarching perspective on the general trend across all 
analyses. If the average evidence suggests a good fit, it indicates that the 
majority of the chosen analyses align well with the data. This method is invaluable 
for assessing the robustness of results, ensuring that findings are not merely 
artifacts of a specific analytical choice but are consistent across various model 
specifications on the same dataset.<br />
Opt for the average-evidence approach when you wish to gauge the central tendency 
of evidence across multiple analytical choices. It's especially beneficial when 
aiming to determine the robustness of results across various model specifications 
applied to the same dataset.
</p>


<h3>Value</h3>

<p>An object of class evSyn for which a print, summary and plot function is available. 
The output comprises, among other things, the cumulative and final evidence 
for the theory-based hypotheses.</p>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Rebecca Kuiper</p>


<h3>Examples</h3>

<pre><code class='language-R'>## By following these examples, you can appropriately specify hypotheses based on 
## your research questions and analytical framework.

# The hypotheses (i.e., constraints) have to be in a list. It is recommended to name
# each hypothesis in the list. Otherwise the hypotheses are named accordingly 'H1', 'H2', \ldots

# text-based syntax (the labels x1, x2, and x2 are the names of coef(model) or names(vector))
h1 &lt;- '(x1, x2, x3) &gt; 0'
h2 &lt;- '(x1, x3) &gt; 0; x2 = 0'
h3 &lt;- 'x1 &gt; 0; x2 &lt; 0; x3 = 0'
hypotheses = list(hypo1 = h1, hypo2 = h2, hypo3 = h3)

# mixed syntax:  
hypotheses = list(Ha = h1, Hb = 'x1 = x2 &gt; x3')

# the same set of hypotheses for each study:
# hypotheses = list(H1, H2, \ldots)

# a different set of hypotheses for each study: 
# note that the list names set1 and set2 are redundant and can be left out. 
# It is crucial to ensure that the hypotheses across each set are ordered in a similar manner.

H11 &lt;- 'group1 = group2 &gt; group3' 
H12 &lt;- 'group2 &gt; group1 &gt; group3'   

H21 &lt;- 'gr1 = gr2 &gt; gr3'
H22 &lt;- 'gr2 &gt; gr1 &gt; gr3'

# correct
hypotheses = list(set1 = list(H11, H12), set2 = list(H21, H22))

# NOT correct
hypotheses = list(set1 = list(H12, H11), set2 = list(H21, H22))

## Example 1 - 4 studies
est_1 &lt;- c(beta1 = 0.09)
est_2 &lt;- c(beta1 = 0.14)
est_3 &lt;- c(beta1 = 1.09)
est_4 &lt;- c(beta1 = 1.781)
Param_studies &lt;- list(est_1, est_2, est_3, est_4)

# standard error of the beta's (from the primary studies)
vcov_est_1 &lt;- matrix(c(0.029^2), nrow = 1)
vcov_est_2 &lt;- matrix(c(0.054^2), nrow = 1)
vcov_est_3 &lt;- matrix(c(0.093^2), nrow = 1)
vcov_est_4 &lt;- matrix(c(0.179^2), nrow = 1)
CovMx_studies &lt;- list(vcov_est_1, vcov_est_2, vcov_est_3, vcov_est_4)

# Set of hypotheses for each study
# Note: in this case the same for each study
H0   &lt;- "beta1 = 0"
Hpos &lt;- "beta1 &gt; 0"
Hneg &lt;- "beta1 &lt; 0"
hypotheses &lt;- list(H0 = H0, Hpos = Hpos, Hneg = Hneg)

# Since this covers the whole space / covers all theories, we do not need a safeguard-hypothesis:
comparison &lt;- "none"

evS4_added &lt;- evSyn(object = Param_studies, VCOV = CovMx_studies, 
                    hypotheses = hypotheses,
                    type = "added", 
                    comparison = "none")
evS4_added
summary(evS4_added)

plot(evS4_added)

evS4_equal &lt;- evSyn(object = Param_studies, VCOV = CovMx_studies, 
                    hypotheses = hypotheses,
                    type = "equal", 
                    comparison = "none")

evS4_equal
summary(evS4_equal)
plot(evS4_equal)

## Example 2 - 2 studies
est_1 &lt;- c(1.88, 2.54, 0.02)
names(est_1) &lt;- c("group1", "group2", "group3")
vcov_est_1 &lt;- diag(c(0.2149074, 0.2149074, 0.1408014))

est_2 &lt;- c(0.98, 0.02, 0.27)
names(est_2) &lt;- c("gr1", "gr2", "gr3") 
vcov_est_2 &lt;- diag(c(0.1382856, 0.1024337, 0.0987754))

# beta values from the analyses
object &lt;- list(est_1, est_2)
# standard error of the beta's (from the S primary studies)
VCOV &lt;- CovMx_studies &lt;- list(vcov_est_1, vcov_est_2)

# names(est_1) # Specify restrictions using those names
H11 &lt;- 'group1 = group2 &gt; group3'
H12 &lt;- 'group2 &gt; group1 &gt; group3'

# names(est_2) # Specify restrictions using those names
H21 &lt;- 'gr1 = gr2 &gt; gr3'
H22 &lt;- 'gr2 &gt; gr1 &gt; gr3' 

# hypotheses
hypotheses &lt;- list(H1 = list(H11, H12), H2 = list(H21, H22))

evS2_added &lt;- evSyn(object, VCOV = VCOV, hypotheses = hypotheses,
                    type = "added", comparison = "unconstrained") 
evS2_added
plot(evS2_added)

## Example 3 - 3 studies

# generate data
ratio &lt;- c(1,1.1,1.2)
n &lt;- c(30, 50, 100)

# Generate data1
n1 &lt;- n[1]
x11 &lt;- rnorm(n1)
x12 &lt;- rnorm(n1)
x13 &lt;- rnorm(n1)
data &lt;- cbind(x11, x12, x13)
# Standardize data - since parameters for continuous variables will be compared
data1 &lt;- as.data.frame(scale(data))
y1 &lt;- ratio[1]*data1$x11 + ratio[2]*data1$x12 + ratio[3]*data1$x13 + rnorm(n1)
# Note: since there is one outcome, the outcome does not need to be standardized.

fit.lm1 &lt;- lm(y1 ~ 1 + x11 + x12 + x13, data = data1)

n2 &lt;- n[2]
x21 &lt;- rnorm(n2)
x22 &lt;- rnorm(n2)
x23 &lt;- rnorm(n2)
data &lt;- cbind(x21, x22, x23)
data2 &lt;- as.data.frame(scale(data))
y2 &lt;- ratio[1]*data2$x21 + ratio[2]*data2$x22 + ratio[3]*data2$x23 + rnorm(n2)
fit.lm2 &lt;- lm(y2 ~ 1 + x21 + x22 + x23, data = data2)

# Generate data3
n3 &lt;- n[3]
x31 &lt;- rnorm(n3)
x32 &lt;- rnorm(n3)
x33 &lt;- rnorm(n3)
data &lt;- cbind(x31, x32, x33)
data3 &lt;- as.data.frame(scale(data))
y3 &lt;- ratio[1]*data3$x31 + ratio[2]*data3$x32 + ratio[3]*data3$x33 + rnorm(n3)
fit.lm3 &lt;- lm(y3 ~ 1 + x31 + x32 + x33, data = data3)

# Extract estimates and their covariance matrix (per study)
est_1 &lt;- coef(fit.lm1)
est_2 &lt;- coef(fit.lm2)
est_3 &lt;- coef(fit.lm3)
vcov_est_1 &lt;- vcov(fit.lm1)
vcov_est_2 &lt;- vcov(fit.lm2)
vcov_est_3 &lt;- vcov(fit.lm3)

names(est_1) &lt;- names(est_2) &lt;- names(est_3) &lt;- c("intercept", "x1", "x2", "x3")

# Parameter estimate values from the primary studies
Param_studies &lt;- list(est_1, est_2, est_3)

# standard error of the beta's
CovMx_studies &lt;- list(vcov_est_1, vcov_est_2, vcov_est_3)

# Set of hypotheses for each study. Note: in this case the same for each study
hypothesis &lt;- 'x1 &lt; x2 &lt; x3'  

# In our theory, we compare estimates of continuous variables, so we standardized 
# the data beforehand to ensure comparability. In 'Param_studies' and 'CovMx_studies', 
# the intercept can be omitted without affecting the GORIC(A) weights, as there are 
# no restrictions on it. Since we have only one theory-based hypothesis, we will 
# utilize the more powerful complement of the hypothesis (Vanbrabant, Van Loey, Kuiper, 2019). 
# The complement represents the remaining 11 theories, while the unconstrained 
# scenario includes all 12 possible theories, including H1.

# Evidence synthesis
evS3 &lt;- evSyn(object = Param_studies, VCOV = CovMx_studies, 
              hypotheses = list(H1 = hypothesis),
              type = "added", 
              comparison = "complement") 
evS3
plot(evS3)

## Example 4 - loglikelihood values and penalty values
# make it a list
LL &lt;- as.list(data.frame(t(myLLs)))
penalty.values &lt;- as.list(data.frame(t(myPTs)))

evS_LL_added &lt;- evSyn(object = LL, PT = penalty.values, type = "added")
evS_LL_equal &lt;- evSyn(object = LL, PT = penalty.values, type = "equal")

evS_LL_added
evS_LL_equal


## Example 5 - AIC, ORIC, GORIC(A) values
goric.values &lt;- as.list(data.frame(t(myGORICs)))

evS_Gv &lt;- evSyn(goric.values)
evS_Gv
</code></pre>

<hr>
<h2 id='Exam'>
Relation between exam scores and study hours, anxiety scores and average point scores.
</h2><span id='topic+Exam'></span>

<h3>Description</h3>

<p>The data provide information about students' exam scores, average point score,
the amount of study hours and anxiety scores. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Exam)</code></pre>


<h3>Format</h3>

<p>A data frame of 20 observations of 4 variables.
</p>

<dl>
<dt><code>Scores</code></dt><dd><p>exam scores</p>
</dd>
<dt><code>Hours</code></dt><dd><p>study hours</p>
</dd>
<dt><code>Anxiety</code></dt><dd><p>anxiety scores</p>
</dd>
<dt><code>APS</code></dt><dd><p>average point score</p>
</dd>
</dl>



<h3>References</h3>

<p>The original source of these data is http://staff.bath.ac.uk/pssiw/stats2/examrevision.sav.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(Exam)
</code></pre>

<hr>
<h2 id='FacialBurns'>Dataset for illustrating the conTest_conLavaan function.</h2><span id='topic+FacialBurns'></span>

<h3>Description</h3>

<p>A dataset from the Dutch burn center (http://www.adbc.nl). 
The data were used to examine psychosocial functioning in patients with 
facial burn wounds. Psychosocial functioning was measured by 
Anxiety and depression symptoms (HADS), and self-esteem 
(Rosenberg's self-esteem scale).</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(FacialBurns)</code></pre>


<h3>Format</h3>

<p>A data frame of 77 observations of 6 variables.
</p>

<dl>
<dt><code>Selfesteem</code></dt><dd><p>Rosenberg's self-esteem scale</p>
</dd>
<dt><code>HADS</code></dt><dd><p>Anxiety and depression scale</p>
</dd>
<dt><code>Age</code></dt><dd><p>Age measured in years, control variable</p>
</dd>
<dt><code>TBSA</code></dt><dd><p>Total Burned Surface Area</p>
</dd>
<dt><code>RUM</code></dt><dd><p>Rumination, control variable</p>
</dd>
<dt><code>Sex</code></dt><dd><p>Gender, grouping variable</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>  head(FacialBurns)
</code></pre>

<hr>
<h2 id='goric'>Generalized Order-Restricted Information Criterion (Approximation) Weights</h2><span id='topic+goric'></span><span id='topic+goric.default'></span><span id='topic+goric.lm'></span><span id='topic+goric.numeric'></span><span id='topic+goric.lavaan'></span><span id='topic+goric.CTmeta'></span><span id='topic+goric.rma'></span><span id='topic+print.con_goric'></span><span id='topic+summary.con_goric'></span><span id='topic+coef.con_goric'></span>

<h3>Description</h3>

<p>The <code>goric</code> function computes GORIC(A) weights, which are 
comparable to the Akaike weights. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>goric(object, ...)

## Default S3 method:
goric(object, ..., hypotheses = NULL,
      comparison = NULL, 
      VCOV = NULL, sample_nobs = NULL, type = "goric",
      penalty_factor = 2, Heq = FALSE, control = list(), debug = FALSE)

## S3 method for class 'lm'
goric(object, ..., hypotheses = NULL,
      comparison = NULL, type = "goric",
      missing = "none", auxiliary = c(), emControl = list(),
      debug = FALSE)

## S3 method for class 'numeric'
goric(object, ..., hypotheses = NULL,
      VCOV = NULL, comparison = NULL,
      type = "gorica", sample_nobs = NULL,
      debug = FALSE)

## S3 method for class 'lavaan'
goric(object, ..., hypotheses = NULL,
      comparison = NULL, type = "gorica",
      standardized = FALSE, debug = FALSE)

## S3 method for class 'CTmeta'
goric(object, ..., hypotheses = NULL,
      comparison = NULL, type = "gorica", 
      sample_nobs = NULL, debug = FALSE)

## S3 method for class 'rma'
goric(object, ..., hypotheses = NULL,
      VCOV = NULL, comparison = NULL, type = "gorica", 
      sample_nobs = NULL, debug = FALSE)


## S3 method for class 'con_goric'
print(x, digits = max(3, getOption("digits") - 4), ...)

## S3 method for class 'con_goric'
summary(object, brief = TRUE, digits = max(3, getOption("digits") - 4), ...)
      
## S3 method for class 'con_goric'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="goric_+3A_object">object</code></td>
<td>
<p>an object containing the outcome of an unconstrained statistical analysis.
Currently, the following objects can be processed:
</p>

<ul>
<li><p> a fitted unconstrained object of class <code>lm</code>, <code>rlm</code> or <code>glm</code>. 
</p>
</li>
<li><p> a numeric vector containing the unconstrained estimates resulting from any 
statistical analysis.
</p>
</li>
<li><p> a fitted object of class <code>lavaan</code>. See examples on how to specify the hypotheses.
</p>
</li>
<li><p> a fitted object of class <code>CTmeta</code>.
</p>
</li>
<li><p> a fitted object of class <code>rma</code>.
</p>
</li>
<li><p> a fitted object of class <code>nlmerMod</code>.
</p>
</li>
<li><p> a fitted object of class <code>glmerMod</code>.
</p>
</li>
<li><p> a fitted object of class <code>lmerMod</code>.
</p>
</li></ul>

</td></tr>
<tr><td><code id="goric_+3A_x">x</code></td>
<td>
<p>an object of class <code>con_goric</code>.</p>
</td></tr>
<tr><td><code id="goric_+3A_...">...</code></td>
<td>
<p>this depends on the class of the object. If object is of class 
<code>lavaan</code>, the standardized or unstandardized vcov can be used, using 
setting <code>standardized = TRUE</code>. See details for more information.
</p>
<p><em>Options for calculating the chi-bar-square weights:</em>
</p>
<p>Parameters passed to the truncated multivariate normal distribution. By default, 
restriktor (i.e. <code>con_weights_boot</code> function) uses no truncation points 
for calculating the chi-bar-square weights, which renders to the multivariate 
normal distribution. See the manual page of the <code>rtmvnorm</code> function from 
the <span class="pkg">rtmvnorm</span> to see how to specify a truncated mvnorm distribution and 
the possible arguments.</p>
</td></tr>
<tr><td><code id="goric_+3A_hypotheses">hypotheses</code></td>
<td>
<p>a named list; Please note that the hypotheses argument in the given 
context serves the same purpose as the constraints argument utilized in the 
restriktor function. The distinction between them is solely semantic.
</p>
<p>There are two ways to constrain parameters. 
First, the hypothesis syntax consists of one or more text-based
descriptions, where the syntax can be specified as a literal 
string enclosed by single quotes. Only the names of <code>coef(model)</code> or
<code>names(vector)</code> can be used as names. See details for more information. 
Note that objects of class &quot;mlm&quot; do not (yet) support this method. 
</p>
<p>Second, the hypothesis syntax consists of a matrix <code class="reqn">R</code> (or a vector in 
case of one constraint) and defines the left-hand side of the constraint 
<code class="reqn">R\theta \ge rhs</code>, where each row represents one constraint. The number of 
columns needs to correspond to the number of parameters estimated (<code class="reqn">\theta</code>) 
by model. The rows should be linear independent, otherwise the function gives an 
error. For more information about constructing the matrix <code class="reqn">R</code> and <code class="reqn">rhs</code> 
see details.</p>
</td></tr>
<tr><td><code id="goric_+3A_comparison">comparison</code></td>
<td>
<p>The default behavior depends on the number of user-specified 
order-restricted hypotheses. If a single hypothesis is specified, it is compared 
against its complement by default. When multiple order-restricted hypotheses are 
specified, the unconstrained model is added as a safeguard to the set of hypotheses.
</p>
<p>These default settings can be overridden. Use &quot;<code>unconstrained</code>&quot; to include 
the unconstrained model in the set of models. Use &quot;<code>complement</code>&quot; to compare 
the order-restricted object against its complement; note that the complement can 
only be computed for one model/hypothesis at a time for now. If &quot;<code>none</code>&quot; 
is chosen, the model is compared only against those provided by the user.</p>
</td></tr>
<tr><td><code id="goric_+3A_vcov">VCOV</code></td>
<td>
<p>variance-coviance matrix. Only needed if object is of class numeric and
<code>type = "gorica"</code> or <code>type = "goricac"</code>.</p>
</td></tr>
<tr><td><code id="goric_+3A_sample_nobs">sample_nobs</code></td>
<td>
<p>the number of observations if <code>type = "goricac"</code>. Note that, 
if <code>type = "goricc"</code>, the number of observations are inherited from the fitted
object.</p>
</td></tr>
<tr><td><code id="goric_+3A_type">type</code></td>
<td>
<p>if <code>"goric"</code>, the generalized order-restricted 
information criterion value is computed. If <code>"gorica"</code> the 
log-likihood is computed using the multivariate normal distribution 
function.</p>
</td></tr>
<tr><td><code id="goric_+3A_penalty_factor">penalty_factor</code></td>
<td>
<p>The penalty factor adjusts the penalty in the GORIC(A) formula
(GORIC(A) = -2 x log-likelihood + penalty_factor x penalty). 
By default, GORIC(A) uses a penalty factor of 2, but penalty factor allows this 
to be customized. Higher values of penalty factor place a stronger emphasis on 
model simplicity, helping to prevent overfitting by penalizing complex models 
more heavily.</p>
</td></tr>
<tr><td><code id="goric_+3A_heq">Heq</code></td>
<td>
<p>If <code>TRUE</code>, the null hypothesis is added to the set of models. 
This means that all inequality constraints are replaced with equality constraints, 
effectively testing the hypothesis that the parameters satisfy exact equality 
rather than inequality. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="goric_+3A_missing">missing</code></td>
<td>
<p>the default setting for objects of class &quot;lm&quot; is listwise:
all cases with missing values are removed from the data before the analysis. This
is only valid if the data are missing completely at random (MCAR). Another 
option is to use &quot;two.stage&quot;. In this approach, missing data are imputed using 
an EM algorithm. However, we cannot use the complete data as input for futher 
analyses, because the resulting complete data variance-covariance matrix will 
not be correct. Therefore, we compute the correct aymptotic covariance (Savalei and Bentler, 2009)
and use it as input for the <code>goric.numeric</code> function to compute a GORICA(C)
value. Note that, the parameter estimates are also recomputed using the complete data.</p>
</td></tr> 
<tr><td><code id="goric_+3A_auxiliary">auxiliary</code></td>
<td>
<p>Vector. The inclusion of auxiliary variables can improve the
imputation model. These auxiliary variables are not part of the target model.</p>
</td></tr>
<tr><td><code id="goric_+3A_emcontrol">emControl</code></td>
<td>
<p>a list of control arguments for the <code>emnorm</code> function
from the <span class="pkg">norm</span> package.</p>
</td></tr>
<tr><td><code id="goric_+3A_standardized">standardized</code></td>
<td>
<p>if TRUE, standardized parameter estimates are used.</p>
</td></tr>
<tr><td><code id="goric_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="goric_+3A_debug">debug</code></td>
<td>
<p>if TRUE, debugging information is printed out.</p>
</td></tr>
</table>
<p>Control options for calculating the chi-bar-square weights:
</p>
<table role = "presentation">
<tr><td><code id="goric_+3A_control">control</code></td>
<td>


<ul>
<li> <p><code>chunk_size</code> integer; the chi-bar-square weights are computed for samples
of size <code>chunk_size = 5000L</code>. This process is repeated iteratively until the 
weights converges (see <code>convergenge_crit</code>) or the maximum is reached, i.e., 
<code>mix_weights_bootstrap_limit</code>.
</p>
</li>
<li> <p><code>mix_weights_bootstrap_limit</code> integer; maximum number of bootstrap draws.
The default value is set to 1e5.
</p>
</li>
<li> <p><code>convergence_crit</code> the convergence criterion for the iterative bootstrap
process. Default is 1e-03.
</p>
</li></ul>

</td></tr>
<tr><td><code id="goric_+3A_brief">brief</code></td>
<td>
<p>if TRUE, a short overview is printed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GORIC(A) values themselves are not interpretable and 
the interest lie in their differences. The GORIC(A) weights reflect 
the support of each hypothesis in the set. To compare two hypotheses 
(and not one to the whole set), one can examine the ratio of the 
two corresponding GORIC(A) weights. To avoid selecting a weakly supported 
hypothesis as the best one, the unconstrained hypothesis is usually 
included as safeguard.
</p>
<p>In case of one order-constrained hypothesis, say H1, the complement 
Hc can be computed as competing hypothesis. The complement is defined 
as Hc = not H1.
</p>
<p>The hypothesis syntax can be parsed via the hypotheses argument. 
If the object is an unconstrained model of class <code>lm</code>, <code>rlm</code> or <code>glm</code>, 
then the hypotheses can be specified in two ways, see <code><a href="#topic+restriktor">restriktor</a></code>. Note 
that if the hypotheses are written in matrix notation, then the hypotheses
for each model/hypothesis is put in a named list with specific names constraints, rhs, 
and neq. For example with three parameters x1, x2, x3, and x1 &gt; 0: 
list(model1 = list(constraints = rbind(c(1, 0, 0)), rhs = 0, neq = 0))). The <code>rhs</code> 
and <code>neq</code> are not required if they are equal to 0. If <code>type = "gorica"</code>,
then the object might be a (named) numeric vector. The hypotheses can again be 
specified in two ways, see <code><a href="#topic+restriktor">restriktor</a></code>. For examples, see below.
</p>
<p>To determine the penalty term values, the chi-bar-square weights (a.k.a. level
probabilities) must be computed. If <code>"mix_weights = "pmvnorm" "</code> (default), 
the chi-bar-square weights are computed based on the multivariate normal distribution 
function with additional Monte Carlo steps. If <code>"mix_weights = "boot" "</code>, the 
chi-bar-square weights are computed using parametric bootstrapping (see <code><a href="#topic+restriktor">restriktor</a></code>).
</p>
<p>The &quot;two.stage&quot; approach for missing data uses the EM algorithm from the 
<code>norm</code> package. The response variables are assumed to be jointly 
normal. In practice, missing-data procedures designed for variables that are 
normal are sometimes applied to variables that are not. Binary and ordinal 
variables are sometimes imputed under a normal model, and the imputed values 
may be classified or rounded. This is also how restriktor handles (ordered)
factors for now. 
</p>
<p>A better strategy (not implemented yet) would be to convert (ordered) factors 
into a pair of dummy variables. If the (ordered) factors have missing values, 
the dummy variables could be included as columns of Y and imputed, but then you 
have to decide how to convert the continuously distributed imputed values for 
these dummy codes back into categories. 
</p>
<p>### Note on not full row-rank ###
</p>
<p>If the restriction matrix is not of full row-rank, this means one of the following:
</p>

<ul>
<li><p> There is at least one redundant restriction specified in the hypothesis. Then, either 
</p>

<ul>
<li><p>[a] Leave the redundant one out 
</p>
</li>
<li><p>[b] Use another (more time-consuming) way of obtaining the level probabilities 
for the penalty term (goric function does this by default): Bootstrapping, as discussed above.
</p>
</li></ul>

</li>
<li><p> There is at least one range restriction (e.g., -2 &lt; group1 &lt; 2). 
Such a restriction can be evaluated but there is a sensitivity (of a scaling 
factor in the covariance matrix, like with a prior in a Bayes factor) which 
currently cannot be checked for.
</p>
</li>
<li><p> There is at least one conflicting restriction (e.g., 2 &lt; group1 &lt; -2).
</p>
</li></ul>

<p>Such a restriction can evidently never hold and is thus impossible to evaluate. 
To prevent this type of error delete the one that is incorrect.
</p>


<h3>Value</h3>

<p>The function returns a dataframe with the log-likelihood,
penalty term, GORIC(A) values and the GORIC(A) weights. Furthermore, a dataframe
is returned with the relative GORIC(A) weights. 
</p>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Rebecca Kuiper</p>


<h3>References</h3>

<p>Kuiper, R.M., Hoijtink, H., and Silvapulle, M.J. (2011). An Akaike-type
information criterion for model selection under inequality constraints.
<em>Biometrika</em>, <b>98</b>, 2, 495&ndash;501.
</p>
<p>Vanbrabant, L. and Kuiper, R. (2020). Evaluating a theory-based hypothesis against 
its complement using an AIC-type information criterion with an application to 
facial burn injury. Psychological Methods. 
</p>
<p>Victoria Savalei and Peter M. Bentler (2009) A Two-Stage Approach to
Missing Data: Theory and Application to Auxiliary Variables, Structural Equation 
Modeling: A Multidisciplinary Journal, 16:3, 477-497, DOI: 10.1080/10705510903008238
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## By following these examples, you can appropriately specify hypotheses based on 
## your research questions and analytical framework.

# The hypotheses (i.e., constraints) have to be in a list. It is recommended to name
# each hypothesis in the list. Otherwise the hypotheses are named accordingly 'H1', 'H2', \ldots.
# Another option is to use the \code{llist()} function from the \pkg{Hmisc} package, where.

# text-based syntax (the labels x1, x2, and x2 are the names of coef(model) or names(vector))
h1 &lt;- '(x1, x2, x3) &gt; 0'
h2 &lt;- '(x1, x3) &gt; 0; x2 = 0'
h3 &lt;- 'x1 &gt; 0; x2 &lt; 0; x3 = 0'
hypotheses = list(hypo1 = h1, hypo2 = h2, hypo3 = h3)

# define constraints matrix directly (note that the constraints have to be specified pairwise).
# the element names (i.e., constraints, rhs, neq) must be used. 
h1 &lt;- list(constraints = c(0,1,0)) 
h2 &lt;- list(constraints = rbind(c(0,1,0), c(0,0,1)), rhs = c(0.5, 1), neq = 0) 
hypotheses = list(H1 = h1, H2 = h2)

# mixed syntax:  
hypotheses = list(Ha = h1, Hb = 'x1 = x2 &gt; x3')

# lavaan object syntax:
# the recommended option for objects of class lavaan is to use labels (here a, b and c) 
# to define our hypothesis.
model.lav &lt;- "y ~ 1 + a*x1 + b*x2 + c*x3 + x4"
# fit lavaan model, for example
# library(lavaan)
# fit.lav &lt;- sem(model, data = DATA)
# define hypothesis syntax
hypotheses = list(h1 = 'a &gt; b &gt; c')
# if needed absolute values can be used.
hypotheses = list(h1 = 'abs(a) &gt; abs(b) &gt; abs(c)')

library(MASS)
## lm
## unrestricted linear model for ages (in months) at which an 
## infant starts to walk alone.

# prepare data
DATA &lt;- subset(ZelazoKolb1972, Group != "Control")
  
# fit unrestrikted linear model
fit1.lm &lt;- lm(Age ~ Group, data = DATA)

# some artificial restrictions
H1 &lt;- "GroupPassive &gt; 0; GroupPassive &lt; GroupNo"
H2 &lt;- "GroupPassive &gt; 0; GroupPassive &gt; GroupNo"
H3 &lt;- "GroupPassive = 0; GroupPassive &lt; GroupNo"


# object is of class lm
goric(fit1.lm, hypotheses = list(H1 = H1, H2 = H2, H3 = H3))

# same result, but using the parameter estimates and covariance matrix as input
# Note, that in case of a numeric input only the gorica(c) can be computed. 
goric(coef(fit1.lm), VCOV = vcov(fit1.lm), hypotheses = list(H1 = H1, H2 = H2, H3 = H3))


# hypothesis H1 versus the complement (i.e., not H1)
goric(fit1.lm, hypotheses = list(H1 = H1), comparison = "complement")


## GORICA
# generate data
n &lt;- 10
x1 &lt;- rnorm(n)
x2 &lt;- rnorm(n)
y &lt;- 1 + x1 + x2 + rnorm(n)
# fit unconstrained linear model
fit.lm &lt;- lm(y ~ x1 + x2)

# extract unconstrained estimates
est &lt;- coef(fit.lm)
# unconstrained variance-covariance matrix
VCOV &lt;- vcov(fit.lm)

## constraint syntax (character)
h1 &lt;- "x1 &gt; 0"
h2 &lt;- "x1 &gt; 0; x2 &gt; 0"
# use fitted unconstrained linear model
goric(fit.lm, hypotheses = list(h1 = h1, h2 = h2), type = "gorica")
# use unconstrained estimates
goric(est, VCOV = VCOV, hypotheses = list(h1 = h1, h2 = h2), type = "gorica")

## constraint syntax (matrix notation)
h1 &lt;- list(constraints = c(0,1,0))
h2 &lt;- list(constraints = rbind(c(0,1,0), c(0,0,1)), rhs = c(0.5, 1), neq = 0)
goric(fit.lm, hypotheses = list(h1 = h1, h2 = h2), type = "gorica")
goric(est, VCOV = VCOV, hypotheses = list(h1 = h1, h2 = h2), type = "gorica")

</code></pre>

<hr>
<h2 id='Hurricanes'>
The Hurricanes Dataset
</h2><span id='topic+Hurricanes'></span>

<h3>Description</h3>

<p>The data provide information on the effect of El Nino (Cold, Neutral, 
Warm) on the number of hurricanes from 1950 to 1995. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Hurricanes)</code></pre>


<h3>Format</h3>

<p>A data frame of 46 observations of 3 variables.
</p>

<dl>
<dt><code>Year</code></dt><dd></dd>
<dt><code>Hurricanes</code></dt><dd><p>Number of Hurricanes</p>
</dd>
<dt><code>ElNino</code></dt><dd><p>1=Cold, 2=Neutral, 3=Warm</p>
</dd>
</dl>



<h3>References</h3>

<p>The original source of these data is the National Hurricane Center
in Australia. The dataset was extracted from the table on page 5 in Silvapulle 
and Sen (2005).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(Hurricanes)
</code></pre>

<hr>
<h2 id='iht'>function for informative hypothesis testing (iht)</h2><span id='topic+iht'></span><span id='topic+conTest'></span><span id='topic+contest'></span><span id='topic+conTestD'></span><span id='topic+contestD'></span>

<h3>Description</h3>

<p><code>iht</code> tests linear equality and/or inequality 
restricted hypotheses for linear models. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iht(...)

conTest(object, constraints = NULL, type = "summary", test = "F", 
        rhs = NULL, neq = 0, ...)

conTestD(model = NULL, data = NULL, constraints = NULL, 
         type = c("A","B"), R = 1000L, bootstrap.type = "bollen.stine", 
         return.test = TRUE, neq.alt = 0, 
         double.bootstrap = "standard", double.bootstrap.R = 249, 
         double.bootstrap.alpha = 0.05, 
         parallel = c("no", "multicore", "snow"), 
         ncpus = 1L, cl = NULL, verbose = FALSE, ...)        
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iht_+3A_object">object</code></td>
<td>
<p>an object of class <code>lm</code> or <code>rlm</code>. In this 
case, the constraint syntax needs to be specified
</p>
<p>OR
</p>
<p>an object of class <code>restriktor</code>. The constraints are inherited 
from the fitted restriktor object and do not to be specified again.
</p>
</td></tr> 
<tr><td><code id="iht_+3A_model">model</code></td>
<td>
<p>lavaan model syntax specifying the model. See <code><a href="lavaan.html#topic+model.syntax">model.syntax</a></code> 
for more information. </p>
</td></tr>
<tr><td><code id="iht_+3A_constraints">constraints</code></td>
<td>
<p>there are two ways to constrain parameters. 
First, the constraint syntax consists of one or more text-based
descriptions, where the syntax can be specified as a literal 
string enclosed by single quotes. Only the names of <code>coef(model)</code>
can be used as names. See details <code><a href="#topic+restriktor">restriktor</a></code> for more information. 
</p>
<p>Second, the constraint syntax consists of a matrix <code class="reqn">R</code> (or a vector in 
case of one constraint) and defines the left-hand side of the 
constraint <code class="reqn">R\theta \ge rhs</code>, where each row represents one 
constraint. The number of columns needs to correspond to the 
number of parameters estimated (<code class="reqn">\theta</code>) by model. The rows 
should be linear independent, otherwise the function gives an 
error. For more information about constructing the matrix <code class="reqn">R</code> and 
<code class="reqn">rhs</code> see the details in the <code><a href="#topic+restriktor">restriktor</a></code> function.</p>
</td></tr>
<tr><td><code id="iht_+3A_data">data</code></td>
<td>
<p>the data frame containing the observed variables being used to 
fit the lavaan model.</p>
</td></tr>
<tr><td><code id="iht_+3A_type">type</code></td>
<td>
<p>hypothesis test type &quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;global&quot;, or 
&quot;summary&quot; (default). See details for more information.</p>
</td></tr>
<tr><td><code id="iht_+3A_test">test</code></td>
<td>
<p>test statistic; for information about the 
null-distribution see details.
</p>

<ul>
<li><p> for object of class lm; if &quot;F&quot; (default), the F-bar 
statistic (Silvapulle, 1996) is computed. If &quot;LRT&quot;, a 
likelihood ratio test statistic (Silvapulle and Sen, 2005, 
chp 3.) is computed. If &quot;score&quot;, a global score test 
statistic (Silvapulle and Silvapulle, 1995) is 
computed. Note that, in case of equality constraints only, 
the usual unconstrained F-, Wald-, LR- and score-test 
statistic is computed. 
</p>
</li>
<li><p> for object of class rlm; if &quot;F&quot; (default), a robust 
likelihood ratio type test statistic (Silvapulle, 1992a) is 
computed. If &quot;Wald&quot;, a robust Wald test statistic (Silvapulle, 1992b) 
is computed. If &quot;score&quot;, a global score test statistic (Silvapulle, 
and Silvapulle, 1995) is computed. Note that, in case of equality 
constraints only, unconstrained robust F-, Wald-, score-test 
statistics are computed.
</p>
</li>
<li><p> for object of class glm; if &quot;F&quot; (default), the F-bar 
statistic (Silvapulle, 1996) is computed. If &quot;LRT&quot;, a 
likelihood ratio test statistic (Silvapulle and Sen, 2005, 
chp 4.) is computed. If &quot;score&quot;, a global score test 
statistic (Silvapulle and Silvapulle, 1995) is 
computed. Note that, in case of equality constraints only, 
the usual unconstrained F-, Wald-, LR- and score-test 
statistic is computed. 
</p>
</li></ul>

</td></tr>
<tr><td><code id="iht_+3A_rhs">rhs</code></td>
<td>
<p>vector on the right-hand side of the constraints; 
<code class="reqn">R\theta \ge rhs</code>. The length of this vector equals the 
number of rows of the constraints matrix <code class="reqn">R</code> and consists of 
zeros by default. Note: only used if constraints input is a 
matrix or vector.</p>
</td></tr>
<tr><td><code id="iht_+3A_neq">neq</code></td>
<td>
<p>integer (default = 0) treating the number of 
constraints rows as equality constraints instead of inequality 
constraints. For example, if <code>neq = 2</code>, this means that the 
first two rows of the constraints matrix <code class="reqn">R</code> are treated as 
equality constraints. Note: only used if constraints input is a 
matrix or vector.</p>
</td></tr>
<tr><td><code id="iht_+3A_neq.alt">neq.alt</code></td>
<td>
<p>integer: number of equality constraints that are maintained under 
the alternative hypothesis (for hypothesis test type &quot;B&quot;).</p>
</td></tr>
<tr><td><code id="iht_+3A_r">R</code></td>
<td>
<p>Integer; number of bootstrap draws. The default value is set to 1000.</p>
</td></tr>
<tr><td><code id="iht_+3A_bootstrap.type">bootstrap.type</code></td>
<td>
<p>If <code>"parametric"</code>, the parametric bootstrap is used. 
If <code>"bollen.stine"</code>, the semi-nonparametric Bollen-Stine bootstrap 
is used. The default is set to <code>"bollen.stine"</code>.</p>
</td></tr>
<tr><td><code id="iht_+3A_return.test">return.test</code></td>
<td>
<p>Logical; if <code>TRUE</code>, the function returns bootstrapped         
test-values.</p>
</td></tr>
<tr><td><code id="iht_+3A_double.bootstrap">double.bootstrap</code></td>
<td>
<p>If <code>"standard"</code> (default) the genuine double bootstrap is 
used to compute an additional set of plug-in p-values for each bootstrap       
sample. If <code>"no"</code>, no double bootstrap is used. If <code>"FDB"</code>, 
the fast double bootstrap is used to compute second level LRT-values for 
each bootstrap sample. Note that the <code>"FDB"</code> is experimental and should 
not be used by inexperienced users.</p>
</td></tr>    
<tr><td><code id="iht_+3A_double.bootstrap.r">double.bootstrap.R</code></td>
<td>
<p>Integer; number of double bootstrap draws. The default 
value is set to 249.</p>
</td></tr>
<tr><td><code id="iht_+3A_double.bootstrap.alpha">double.bootstrap.alpha</code></td>
<td>
<p>The significance level to compute the adjusted 
alpha based on the plugin p-values. Only used if <code>double.bootstrap = "standard"</code>. 
The default value is set to 0.05.</p>
</td></tr>
<tr><td><code id="iht_+3A_parallel">parallel</code></td>
<td>
<p>The type of parallel operation to be used (if any). If missing, 
the default is set &quot;no&quot;.</p>
</td></tr>
<tr><td><code id="iht_+3A_ncpus">ncpus</code></td>
<td>
<p>Integer: number of processes to be used in parallel operation: 
typically one would chose this to the number of available CPUs.</p>
</td></tr> 
<tr><td><code id="iht_+3A_cl">cl</code></td>
<td>
<p>An optional parallel or snow cluster for use if 
<code>parallel = "snow"</code>. If not supplied, a cluster on the local machine 
is created for the duration of the <code>InformativeTesting</code> call.</p>
</td></tr>
<tr><td><code id="iht_+3A_verbose">verbose</code></td>
<td>
<p>Logical; if <code>TRUE</code>, information is shown at each bootstrap         
draw.</p>
</td></tr>
<tr><td><code id="iht_+3A_...">...</code></td>
<td>
<p>futher options for the <code>iht</code> and/or 
<code>restriktor</code> function. See details for more information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following hypothesis tests are available:
</p>

<ul>
<li><p> Type A: Test H0: all constraints with equalities (&quot;=&quot;) 
active against HA: at least one inequality restriction (&quot;&gt;&quot;) 
strictly true.
</p>
</li>
<li><p> Type B: Test H0: all constraints with inequalities (&quot;&gt;&quot;) 
(including some equalities (&quot;=&quot;)) active against HA: at least 
one restriction false (some equality constraints may be 
maintained).
</p>
</li>
<li><p> Type C: Test H0: at least one restriction false (&quot;&lt;&quot;) 
against HA: all constraints strikty true (&quot;&gt;&quot;). This test is 
based on the intersection-union principle (Silvapulle and Sen, 
2005, chp 5.3). Note that, this test only makes sense in case 
of no equality constraints.
</p>
</li>
<li><p> Type global: equal to Type A but H0 contains additional 
equality constraints. This test is analogue to the global 
F-test in lm, where all coefficients but the intercept equal 0.
</p>
</li></ul>

<p>The null-distribution of hypothesis test Type C is based on a 
t-distribution (one-sided). Its power can be poor in case of many 
inequalty constraints. Its main role is to prevent wrong 
conclusions from significant results from hypothesis test Type A.
</p>
<p>The exact finite sample distributions of the non-robust F-, 
score- and LR-test statistics based on restricted OLS estimates 
and normally distributed errors, are a mixture of F-distributions 
under the null hypothesis (Wolak, 1987). For the robust tests, we 
found that the results based on these mixtures of F-distributions 
approximate the tail probabilities better than their asymptotic 
distributions. 
</p>
<p>Note that, in case of equality constraints only, the 
null-distribution of the (non-)robust F-test statistics are 
based on an F-distribution. The (non-)robust Wald- and (non-)robust 
score-test statistics are based on chi-square distributions.
</p>
<p>If object is of class <code>lm</code> or <code>rlm</code>, the <code>conTest</code> function
internally calls the <code>restriktor</code> function. Arguments for the 
<code><a href="#topic+restriktor">restriktor</a></code> function can be passed on via the <code>...</code>. Additional
arguments for the <code>conTest</code> function can also passed on via the <code>...</code>.
See for example <code><a href="#topic+conTestF">conTestF</a></code> for all available arguments.
</p>


<h3>Value</h3>

<p>An object of class conTest or conTestLavaan for which a print is available. 
</p>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Robertson, T., Wright, F.T. and Dykstra, R.L. (1988). <em>Order Restricted 
Statistical Inference</em> New York: Wiley.
</p>
<p>Shapiro, A. (1988). Towards a unified theory of inequality-constrained 
testing in multivariate analysis. <em>International Statistical 
Review</em> <b>56</b>, 49&ndash;62.
</p>
<p>Silvapulle, M. (1992a). Robust tests of inequality constraints and 
one-sided hypotheses in the linear model. <em>Biometrika</em>, 
<b>79</b>, 621&ndash;630.
</p>
<p>Silvapulle, M. (1992b). Robust Wald-Type Tests of One-Sided Hypotheses 
in the Linear Model. <em>Journal of the American Statistical Association</em>, 
<b>87</b>, 156&ndash;161.
</p>
<p>Silvapulle, M. and Silvapulle, P. (1995). A score test against 
one-sided alternatives. <em>American statistical association</em>, 
<b>90</b>, 342&ndash;349.
</p>
<p>Silvapulle, M. (1996) On an F-type statistic for testing one-sided 
hypotheses and computation of chi-bar-squared weights. 
<em>Statistics and probability letters</em>, <b>28</b>, 137&ndash;141.
</p>
<p>Silvapulle, M. (1996) Robust bounded influence tests against 
one-sided hypotheses in general parametric models. 
<em>Statistics and probability letters</em>, <b>31</b>, 45&ndash;50.
</p>
<p>Silvapulle, M.J. and Sen, P.K. (2005). <em>Constrained 
Statistical Inference</em>. Wiley, New York
</p>
<p>Vanbrabant, L., Van de Schoot, R., Van Loey, N.E.E. and Rosseel, Y. (2017). 
A General Procedure for Testing Inequality Constrained Hypotheses in SEM.
<em>Methodology European Journal of Research Methods for the Behavioral and Social Sciences</em>,
<b>13</b>, 61-70.
</p>
<p>Van de Schoot, R., Hoijtink, H., and Dekovic, M. (2010). 
Testing inequality constrained hypotheses in SEM models. 
<em>Structural Equation Modeling</em>, <b>17</b>, 443-463.
</p>
<p>Van de Schoot, R., Strohmeier, D. (2011). 
Testing informative hypotheses in SEM increases power: An 
illustration contrasting classical. <em>International Journal 
of Behavioral Development</em>, <b>35</b>, 180-190.
</p>
<p>Wolak, F. (1987). An exact test for multiple inequality and 
equality constraints in the linear regression model. 
<em>Journal of the American statistical association</em>, 
<b>82</b>, 782&ndash;793.
</p>


<h3>See Also</h3>

 
<p><a href="quadprog.html#topic+solve.QP">quadprog</a>, 
<code><a href="#topic+conTest">conTest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## example 1:
# the data consist of ages (in months) at which an 
# infant starts to walk alone.

# prepare data
DATA1 &lt;- subset(ZelazoKolb1972, Group != "Control")

# fit unrestricted linear model
fit1.lm &lt;- lm(Age ~ -1 + Group, data = DATA1)

# the variable names can be used to impose constraints on
# the corresponding regression parameters.
coef(fit1.lm)

# constraint syntax: assuming that the walking 
# exercises would not have a negative effect of increasing the 
# mean age at which a child starts to walk. 
myConstraints1 &lt;- ' GroupActive &lt; GroupPassive &lt; GroupNo '

iht(fit1.lm, myConstraints1)


# another way is to first fit the restricted model
fit.restr1 &lt;- restriktor(fit1.lm, constraints = myConstraints1)

iht(fit.restr1)


# Or in matrix notation.
Amat1 &lt;- rbind(c(-1, 0,  1),
               c( 0, 1, -1))
myRhs1 &lt;- rep(0L, nrow(Amat1)) 
myNeq1 &lt;- 0

iht(fit1.lm, constraints = Amat1, rhs = myRhs1, neq = myNeq1)

#########################
## Artificial examples ##
#########################
# generate data
n &lt;- 10
means &lt;- c(1,2,1,3)
nm &lt;- length(means)
group &lt;- as.factor(rep(1:nm, each = n))
y &lt;- rnorm(n * nm, rep(means, each = n))
DATA2 &lt;- data.frame(y, group)

# fit unrestricted linear model
fit2.lm &lt;- lm(y ~ -1 + group, data = DATA2)
coef(fit2.lm)

## example 2: increasing means
myConstraints2 &lt;- ' group1 &lt; group2 &lt; group3 &lt; group4 '

# compute F-test for hypothesis test Type A and compute the tail 
# probability based on the parametric bootstrap. We only generate 9 
# bootstrap samples in this example; in practice you may wish to 
# use a much higher number.
iht(fit2.lm, constraints = myConstraints2, type = "A", 
    boot = "parametric", R = 9)


# or fit restricted linear model
fit2.con &lt;- restriktor(fit2.lm, constraints = myConstraints2)

iht(fit2.con)

# increasing means in matrix notation.
Amat2 &lt;- rbind(c(-1, 1, 0, 0),
               c( 0,-1, 1, 0),
               c( 0, 0,-1, 1))
myRhs2 &lt;- rep(0L, nrow(Amat2)) 
myNeq2 &lt;- 0

iht(fit2.con, constraints = Amat2, rhs = myRhs2, neq = myNeq2, 
    type = "A", boot = "parametric", R = 9)

## example 3: equality constraints only.
myConstraints3 &lt;- ' group1 = group2 = group3 = group4 '

iht(fit2.lm, constraints = myConstraints3)

# or
fit3.con &lt;- restriktor(fit2.lm, constraints = myConstraints3)
iht(fit3.con)


## example 4:
# combination of equality and inequality constraints.
myConstraints4 &lt;- ' group1 = group2
                    group3 &lt; group4 '

iht(fit2.lm, constraints = myConstraints4, type = "B", neq.alt = 1)

# fit resticted model and compute model-based bootstrapped 
# standard errors. We only generate 9 bootstrap samples in this 
# example; in practice you may wish to use a much higher number.
# Note that, a warning message may be thrown because the number of 
# bootstrap samples is too low.
fit4.con &lt;- restriktor(fit2.lm, constraints = myConstraints4, 
                       se = "boot.model.based", B = 9)
iht(fit4.con, type = "B", neq.alt = 1)


## example 5:
# restriktor can also be used to define effects using the := operator 
# and impose constraints on them. For example, is the 
# average effect (AVE) larger than zero?
# generate data
n &lt;- 30
b0 &lt;- 10; b1 = 0.5; b2 = 1; b3 = 1.5
X &lt;- c(rep(c(0), n/2), rep(c(1), n/2))
set.seed(90) 
Z &lt;- rnorm(n, 16, 5)
y &lt;- b0 + b1*X + b2*Z + b3*X*Z + rnorm(n, 0, sd = 10) 
DATA3 = data.frame(cbind(y, X, Z))

# fit linear model with interaction
fit5.lm &lt;- lm(y ~ X*Z, data = DATA3)

# constraint syntax
myConstraints5 &lt;- ' AVE := X + 16.86137*X.Z; 
                    AVE &gt; 0 '

iht(fit5.lm, constraints = myConstraints5)

# or
fit5.con &lt;- restriktor(fit5.lm, constraints = ' AVE := X + 16.86137*X.Z; 
                                                AVE &gt; 0 ')
iht(fit5.con)


# testing equality and/or inequality restrictions in SEM:

#########################
### real data example ###
#########################
# Multiple group path model for facial burns example.

# model syntax with starting values.
burns.model &lt;- 'Selfesteem ~ Age + c(m1, f1)*TBSA + HADS +
                           start(-.10, -.20)*TBSA  
             HADS ~ Age + c(m2, f2)*TBSA + RUM +
                    start(.10, .20)*TBSA '


# constraints syntax
burns.constraints &lt;- 'f2 &gt; 0  ; m1 &lt; 0
                      m2 &gt; 0  ; f1 &lt; 0
                      f2 &gt; m2 ; f1 &lt; m1'

# we only generate 2 bootstrap samples in this example; in practice
# you may wish to use a much higher number. 
# the double bootstrap was switched off; in practice you probably 
# want to set it to "standard".
example6 &lt;- iht(model = burns.model, data = FacialBurns,
                R = 2, constraints = burns.constraints,
                double.bootstrap = "no", group = "Sex")

example6

##########################
### artificial example ###
##########################

# Simple ANOVA model with 3 groups (N = 20 per group)
set.seed(1234)
Y &lt;- cbind(c(rnorm(20,0,1), rnorm(20,0.5,1), rnorm(20,1,1)))
grp &lt;- c(rep("1", 20), rep("2", 20), rep("3", 20))
Data &lt;- data.frame(Y, grp)

#create model matrix
fit.lm &lt;- lm(Y ~ grp, data = Data)
mfit &lt;- fit.lm$model
mm &lt;- model.matrix(mfit)

Y &lt;- model.response(mfit)
X &lt;- data.frame(mm[,2:3])
names(X) &lt;- c("d1", "d2")
Data.new &lt;- data.frame(Y, X)

# model
model &lt;- 'Y ~ 1 + a1*d1 + a2*d2'

# fit without constraints
fit &lt;- lavaan::sem(model, data = Data.new)

# constraints syntax: mu1 &lt; mu2 &lt; mu3
constraints &lt;- ' a1 &gt; 0
                 a1 &lt; a2 '

# we only generate 10 bootstrap samples in this example; in practice
# you may wish to use a much higher number, say &gt; 1000. The double 
# bootstrap is not necessary in case of an univariate ANOVA model.
example7 &lt;- iht(model = model, data = Data.new, 
                start = lavaan::parTable(fit),
                R = 10L, double.bootstrap = "no",
                constraints = constraints)
example7

</code></pre>

<hr>
<h2 id='iht-methods'>Methods for iht</h2><span id='topic+conTest-methods'></span><span id='topic+iht-methods'></span><span id='topic+print.conTest'></span>

<h3>Description</h3>

<p>Print function for objects of class <code>conTest</code>. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'conTest'
print(x, digits = max(3, getOption("digits") - 2), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="iht-methods_+3A_x">x</code></td>
<td>
<p>an object of class <code>conTest</code>.</p>
</td></tr> 
<tr><td><code id="iht-methods_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="iht-methods_+3A_...">...</code></td>
<td>
<p>no additional arguments for now.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, just the result of the print function
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  # unrestricted linear model for ages (in months) at which an 
  # infant starts to walk alone.
  
  # prepare data
  DATA &lt;- subset(ZelazoKolb1972, Group != "Control")
  
  # fit unrestricted linear model
  fit.lm &lt;- lm(Age ~ -1 + Group, data = DATA)
  
  # restricted linear model with restrictions that the walking 
  # exercises would not have a negative effect of increasing the 
  # mean age at which a child starts to walk. 
  fit.con &lt;- restriktor(fit.lm, constraints = "GroupActive &lt; GroupPassive &lt; GroupNo")
  
  iht(fit.con)
</code></pre>

<hr>
<h2 id='myGORICs'>An example of IC values</h2><span id='topic+myGORICs'></span>

<h3>Description</h3>

<p>An example of IC: A matrix with information criteria (AIC, ORIC, GORIC, or GORICA) values of size 4 x 3 (in general: S x 'NrHypos+1', where 'NrHypos+1' stands for the number of theory-based hypotheses plus a safeguard hypothesis (the complement or unconstrained)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(myGORICs)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 4 rows and 3 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(myGORICs)
  
</code></pre>

<hr>
<h2 id='myLLs'>An example of log-likelihood (LL) values</h2><span id='topic+myLLs'></span>

<h3>Description</h3>

<p>An example of LL: A matrix with log-likelihood values of size 4 x 3 (in general: S x 'NrHypos+1', where 'NrHypos+1' stands for the number of theory-based hypotheses plus a safeguard hypothesis (the complement or unconstrained)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(myLLs)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 4 rows and 3 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(myLLs)
  
</code></pre>

<hr>
<h2 id='myPTs'>An example of penalty (PT) values</h2><span id='topic+myPTs'></span>

<h3>Description</h3>

<p>An example of PT: A matrix with penalty values of size 4 x 3 (in general: S x 'NrHypos+1', where 'NrHypos+1' stands for the number of theory-based hypotheses plus a safeguard hypothesis (the complement or unconstrained)).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(myPTs)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>matrix</code> (inherits from <code>array</code>) with 4 rows and 3 columns.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  data(myPTs)
  
</code></pre>

<hr>
<h2 id='restriktor'>Estimating linear regression models with (in)equality restrictions</h2><span id='topic+restriktor'></span><span id='topic+conLM.lm'></span><span id='topic+conRLM.rlm'></span><span id='topic+conGLM.glm'></span><span id='topic+conMLM.mlm'></span>

<h3>Description</h3>

<p>Function <code>restriktor</code> estimates the parameters 
of an univariate and a multivariate linear model (<code>lm</code>), a 
robust estimation of the linear model (<code>rlm</code>) and a generalized 
linear model (<code>glm</code>) subject to linear equality and linear 
inequality restrictions. It is a convenience function. The real work 
horses are the <code>conLM</code>, <code>conMLM</code>, <code>conRLM</code> and 
the <code>conGLM</code> functions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>restriktor(object, constraints = NULL, ...)

## S3 method for class 'lm'
conLM(object, constraints = NULL, se = "standard", 
      B = 999, rhs = NULL, neq = 0L, mix_weights = "pmvnorm", 
      parallel = "no", ncpus = 1L, cl = NULL, seed = NULL, 
      control = list(), verbose = FALSE, debug = FALSE, ...)
      
## S3 method for class 'rlm'
conRLM(object, constraints = NULL, se = "standard", 
       B = 999, rhs = NULL, neq = 0L, mix_weights = "pmvnorm", 
       parallel = "no", ncpus = 1L, cl = NULL, seed = NULL, 
       control = list(), verbose = FALSE, debug = FALSE, ...)
       
## S3 method for class 'glm'
conGLM(object, constraints = NULL, se = "standard", 
       B = 999, rhs = NULL, neq = 0L, mix_weights = "pmvnorm", 
       parallel = "no", ncpus = 1L, cl = NULL, seed = NULL, 
       control = list(), verbose = FALSE, debug = FALSE, ...)

## S3 method for class 'mlm'
conMLM(object, constraints = NULL, se = "none", 
       B = 999, rhs = NULL, neq = 0L, mix_weights = "pmvnorm", 
       parallel = "no", ncpus = 1L, cl = NULL, seed = NULL, 
       control = list(), verbose = FALSE, debug = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="restriktor_+3A_object">object</code></td>
<td>
<p>a fitted linear model object of class &quot;lm&quot;, &quot;mlm&quot;,
&quot;rlm&quot; or &quot;glm&quot;. For class &quot;rlm&quot; only the loss function <code>bisquare</code> 
is supported for now, otherwise the function gives an error.</p>
</td></tr> 
<tr><td><code id="restriktor_+3A_constraints">constraints</code></td>
<td>
<p>there are two ways to constrain parameters. 
First, the constraint syntax consists of one or more text-based
descriptions, where the syntax can be specified as a literal 
string enclosed by single quotes. Only the names of <code>coef(model)</code>
can be used as names. See details for more information. Note that
objects of class &quot;mlm&quot; do not (yet) support this method. 
</p>
<p>Second, the constraint syntax consists of a matrix <code class="reqn">R</code> (or a vector in 
case of one constraint) and defines the left-hand side of the 
constraint <code class="reqn">R\theta \ge rhs</code>, where each row represents one 
constraint. The number of columns needs to correspond to the 
number of parameters estimated (<code class="reqn">\theta</code>) by model. The rows 
should be linear independent, otherwise the function gives an 
error. For more information about constructing the matrix <code class="reqn">R</code> and 
<code class="reqn">rhs</code> see details.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_se">se</code></td>
<td>
<p>if &quot;<code>standard</code>&quot; (default), conventional standard errors 
are computed based on inverting the observed augmented information 
matrix. If &quot;const&quot;, homoskedastic standard errors are computed. 
If &quot;<code>HC0</code>&quot; or just &quot;<code>HC</code>&quot;, heteroskedastic robust standard 
errors are computed (a.k.a Huber White). The options &quot;<code>HC1</code>&quot;, 
&quot;<code>HC2</code>&quot;, &quot;<code>HC3</code>&quot;, &quot;<code>HC4</code>&quot;, &quot;<code>HC4m</code>&quot;, and 
&quot;<code>HC5</code>&quot; are refinements of &quot;<code>HC0</code>&quot;. For more details about 
heteroskedastic robust standard errors see the <span class="pkg">sandwich</span> 
package. If &quot;<code>boot.standard</code>&quot;, bootstrapped standard 
errors are computed using standard bootstrapping. If &quot;<code>boot.model.based</code>&quot; 
or &quot;<code>boot.residual</code>&quot;, bootstrapped standard errors are computed 
using model-based bootstrapping. If &quot;<code>none</code>&quot;, no standard errors 
are computed. Note that for objects of class &quot;mlm&quot; no standard errors 
are available (yet).</p>
</td></tr>
<tr><td><code id="restriktor_+3A_b">B</code></td>
<td>
<p>integer; number of bootstrap draws for <code>se</code>. The 
default value is set to 999. Parallel support is available.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_rhs">rhs</code></td>
<td>
<p>vector on the right-hand side of the constraints; 
<code class="reqn">R\theta \ge rhs</code>. The length of this vector equals the 
number of rows of the constraints matrix <code class="reqn">R</code> and consists of 
zeros by default. Note: only used if constraints input is a 
matrix or vector.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_neq">neq</code></td>
<td>
<p>integer (default = 0) treating the number of 
constraints rows as equality constraints instead of inequality 
constraints. For example, if <code>neq = 2</code>, this means that the 
first two rows of the constraints matrix <code class="reqn">R</code> are treated as 
equality constraints. Note: only used if constraints input is a 
matrix or vector.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_mix_weights">mix_weights</code></td>
<td>
<p>if <code>"pmvnorm"</code> (default), the chi-bar-square 
weights are computed based on the multivariate normal distribution 
function with additional Monte Carlo steps. If <code>"boot"</code>, the 
chi-bar-square weights are computed using parametric bootstrapping. 
If <code>"none"</code>, no chi-bar-square weights are computed. The 
weights are necessary in the <code>restriktor.summary</code> function 
for computing the GORIC. Moreover, the weights are re-used in the 
<code><a href="#topic+iht">iht</a></code> function for computing the p-value for the 
test-statistic, unless the p-value is computed directly via bootstrapping.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_parallel">parallel</code></td>
<td>
<p>the type of parallel operation to be used (if any). 
If missing, the default is set &quot;no&quot;.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_ncpus">ncpus</code></td>
<td>
<p>integer: number of processes to be used in parallel 
operation: typically one would chose this to the number of 
available CPUs.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_cl">cl</code></td>
<td>
<p>an optional parallel or snow cluster for use if 
parallel = &quot;snow&quot;. If not supplied, a cluster on the local machine 
is created for the duration of the <code>restriktor</code> call.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_seed">seed</code></td>
<td>
<p>seed value.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_control">control</code></td>
<td>
<p>a list of control arguments: 
</p>

<ul>
<li> <p><code>absval</code> tolerance criterion for convergence 
(default = sqrt(.Machine$double.eps)). 
</p>
</li>
<li> <p><code>maxit</code> the maximum number of iterations for the 
optimizer (default = 10000). 
</p>
</li>
<li> <p><code>tol</code> numerical tolerance value. Estimates smaller 
than <code>tol</code> are set to 0.
</p>
</li></ul>

<p>Control options for calculating the chi-bar-square weights:
</p>

<ul>
<li> <p><code>chunk_size</code> integer; the chi-bar-square weights are computed for samples
of size <code>chunk_size = 5000L</code>. This process is repeated iteratively until the 
weights converges (see <code>convergenge_crit</code>) or the maximum is reached, i.e., 
<code>mix_weights_bootstrap_limit</code>.
</p>
</li>
<li> <p><code>mix_weights_bootstrap_limit</code> integer; maximum number of bootstrap draws.
The default value is set to 1e5.
</p>
</li>
<li> <p><code>convergence_crit</code> the convergence criterion for the iterative bootstrap
process. Default is 1e-03.
</p>
</li></ul>

</td></tr>
<tr><td><code id="restriktor_+3A_verbose">verbose</code></td>
<td>
<p>logical; if TRUE, information is shown at each bootstrap draw.</p>
</td></tr>
<tr><td><code id="restriktor_+3A_debug">debug</code></td>
<td>
<p>if TRUE, debugging information about the constraints
is printed out.</p>
</td></tr>
</table>
<p><em>Options for calculating the chi-bar-square weights</em>:
</p>
<table role = "presentation">
<tr><td><code id="restriktor_+3A_...">...</code></td>
<td>
<p>parameters passed to the truncated multivariate normal distribution.
By default, restriktor (i.e. <code>con_weights_boot</code> function) uses no 
truncation points for calculating the chi-bar-square weights, which renders 
to the multivariate normal distribution. See the manual page of the 
<code>rtmvnorm</code> function from the <span class="pkg">rtmvnorm</span> to see how to specify a 
truncated mvnorm distribution and the possible arguments.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The constraint syntax can be specified in two ways. First as a 
literal string enclosed by single quotes as shown below: 
</p>
<pre>myConstraints &lt;- '
    # 1. inequality constraints
      x1 &gt; 0
      x1 &lt; x2
    # or
      0 &lt; x1 &lt; x2
    
    ! 2. equality constraints  
      x3 == x4; x4 == x5 
    # or 
      x3 = x4; x4 = x5 
    # or
      x3 = x4 = x5'
  </pre>
<p>The variable names x1 to x5 refer to the corresponding regression
coefficient. Thus, constraints are impose on regression coefficients
and not on the data.
</p>
<p>Second, the above constraints syntax can also be written in 
matrix/vector notation as:
</p>
<p>(The first column refers to the intercept, the remaining five
columns refer to the regression coefficients x1 to x5.)
</p>
<pre>myConstraints &lt;-
    rbind(c(0, 0, 0,-1, 1, 0), #equality constraint x3 = x4
          c(0, 0, 0, 0,-1, 1), #equality constraint x4 = x5
          c(0, 1, 0, 0, 0, 0), #inequality constraint x1 &gt; rhs
          c(0,-1, 1, 0, 0, 0)) #inequality constraint x1 &lt; x2
  
# the length of rhs is equal to the number of myConstraints rows.      
myRhs &lt;- c(0,0,0,0) 
    
# the first two rows should be considered as equality constraints
myNeq &lt;- 2  
</pre>
<p>Blank lines and comments can be used in between the constraints, 
and constraints can be split over multiple lines. Both the 
hashtag (#) and the exclamation (!) characters can be used to 
start a comment. Multiple constraints can be placed on a single 
line if they are separated by a semicolon (;), a comma (,) or the &quot;&amp;&quot; sign. 
</p>
<p>In addition compound constraints can be stated via one or more longer equality 
or inequality sentences e.g., 'x1 &gt; x2 &gt; x3; x3 &lt; 4 &lt; x4' or 
'x1 == x2 == x3 &amp; x4 = 1'. Alternatively, the constrains can be specifies 
as '(x1, x2) &gt; (x3, x4)' which is equivalent to 'x1 &gt; x3; x1 &gt; x4; x2 &gt; x3; x2 &gt; x4'.
</p>
<p>There can be three types of text-based descriptions in the constraints 
syntax:
</p>

<ol>
<li><p> Equality constraints: The &quot;<code>==</code>&quot; or &quot;<code>=</code>&quot; operator can be 
used to define equality constraints (e.g., <code>x1 = 1</code> or 
<code>x1 = x2</code>).
</p>
</li>
<li><p> Inequality constraints: The &quot;<code>&lt;</code>&quot; or &quot;<code>&gt;</code>&quot; 
operator can be used to define inequality constraints 
(e.g., <code>x1 &gt; 1</code> or <code>x1 &lt; x2</code>).
</p>
</li>
<li><p> Newly defined parameters: The &quot;<code>:=</code>&quot; operator can 
be used to define new parameters, which take on values that 
are an arbitrary function of the original model parameters. 
The function must be specified in terms of the parameter names 
in <code>coef(model)</code> (e.g., <code>new := x1 + 2*x2</code>). By 
default, the standard errors for these defined parameters are 
computed by using the so-called Delta method.
</p>
</li></ol>

<p>Variable names of interaction effects in objects of class lm, 
rlm and glm contain a semi-colon (:) between the variables. To impose 
constraints on parameters of interaction effects, the semi-colon 
must be replaced by a dot (.) (e.g., <code>x3:x4</code> becomes 
<code>x3.x4</code>). In addition, the intercept variable names is shown 
as &quot;<code>(Intercept)</code>&quot;. To impose restrictions on the intercept 
both parentheses must be replaced by a dot &quot;<code>.Intercept.</code>&quot; 
(e.g.,<code>.Intercept. &gt; 10</code>). Note: in most practical situations 
we do not impose restrictions on the intercept because we do not 
have prior knowledge about the intercept. Moreover, the sign of 
the intercept can be changed arbitrarily by shifting the response 
variable <code class="reqn">y</code>.
</p>
<p>Each element can be modified using arithmetic operators. For example, 
if <code>x2</code> is expected to be twice as large as <code>x1</code>, 
then &quot;<code>2*x2 = x1</code>&quot;. 
</p>
<p>If <code>constraints = NULL</code>, the unrestricted model is fitted.
</p>
<p>### Note on not full row-rank ###
</p>
<p>If the restriction matrix is not of full row-rank, this means one of the following:
</p>

<ul>
<li><p> There is at least one redundant restriction. Then, either 
</p>

<ul>
<li><p>[a] Leave the redundant one out 
</p>
</li>
<li><p>[b] Use another (more time-consuming) way of obtaining the level probabilities 
for the penalty term (goric function does this by default): Bootstrapping, as discussed above.
</p>
</li></ul>

</li>
<li><p> There is at least one range restriction (e.g., -2 &lt; group1 &lt; 2). 
Such a restriction can be evaluated but there is a sensitivity (of a scaling 
factor in the covariance matrix, like with a prior in a Bayes factor) which 
currently cannot be checked for.
</p>
</li>
<li><p> There is at least one conflicting restriction (e.g., 2 &lt; group1 &lt; -2).
</p>
</li></ul>

<p>Such a restriction can evidently never hold and is thus impossible to evaluate. 
To prevent this type of error delete the one that is incorrect.
</p>


<h3>Value</h3>

<p>An object of class restriktor, for which a print and a summary method are available. 
More specifically, it is a list with the following items:
</p>
<table role = "presentation">
<tr><td><code>CON</code></td>
<td>
<p>a list with useful information about the restrictions.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the matched call.</p>
</td></tr>
<tr><td><code>timing</code></td>
<td>
<p>how much time several tasks take.</p>
</td></tr>
<tr><td><code>parTable</code></td>
<td>
<p>a parameter table with information about the 
observed variables in the model and the imposed restrictions.</p>
</td></tr>
<tr><td><code>b.unrestr</code></td>
<td>
<p>unrestricted regression coefficients.</p>
</td></tr>
<tr><td><code>b.restr</code></td>
<td>
<p>restricted regression coefficients.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>restricted residuals.</p>
</td></tr>
<tr><td><code>wresid</code></td>
<td>
<p>a working residual, weighted for &quot;inv.var&quot; weights 
only (rlm only)</p>
</td></tr>
<tr><td><code>fitted</code></td>
<td>
<p>restricted fitted mean values.</p>
</td></tr>
<tr><td><code>weights</code></td>
<td>
<p>(only for weighted fits) the specified weights.</p>
</td></tr>
<tr><td><code>wgt</code></td>
<td>
<p>the weights used in the IWLS process (rlm only).</p>
</td></tr>
<tr><td><code>scale</code></td>
<td>
<p>the robust scale estimate used (rlm only).</p>
</td></tr>
<tr><td><code>stddev</code></td>
<td>
<p>a scale estimate used for the standard errors.</p>
</td></tr>
<tr><td><code>R2.org</code></td>
<td>
<p>unrestricted R-squared.</p>
</td></tr>
<tr><td><code>R2.reduced</code></td>
<td>
<p>restricted R-squared.</p>
</td></tr>
<tr><td><code>df.residual</code></td>
<td>
<p>the residual degrees of freedom</p>
</td></tr>
<tr><td><code>s2.unrestr</code></td>
<td>
<p>mean squared error of unrestricted model.</p>
</td></tr>
<tr><td><code>s2.restr</code></td>
<td>
<p>mean squared error of restricted model.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>restricted log-likelihood.</p>
</td></tr>
<tr><td><code>Sigma</code></td>
<td>
<p>variance-covariance matrix of unrestricted model.</p>
</td></tr>
<tr><td><code>constraints</code></td>
<td>
<p>matrix with restrictions.</p>
</td></tr>
<tr><td><code>rhs</code></td>
<td>
<p>vector of right-hand side elements.</p>
</td></tr>
<tr><td><code>neq</code></td>
<td>
<p>number of equality restrictions.</p>
</td></tr>
<tr><td><code>wt.bar</code></td>
<td>
<p>chi-bar-square mixing weights or a.k.a. level probabilities.</p>
</td></tr>
<tr><td><code>iact</code></td>
<td>
<p>active restrictions.</p>
</td></tr>
<tr><td><code>converged</code></td>
<td>
<p>did the IWLS converge (rlm only)?</p>
</td></tr>
<tr><td><code>iter</code></td>
<td>
<p>number of iteration needed for convergence (rlm only).</p>
</td></tr>
<tr><td><code>bootout</code></td>
<td>
<p>object of class boot. Only available if bootstrapped
standard errors are requested, else bootout = NULL.</p>
</td></tr> 
<tr><td><code>control</code></td>
<td>
<p>list with control options.</p>
</td></tr>
<tr><td><code>model.org</code></td>
<td>
<p>original model.</p>
</td></tr>
<tr><td><code>se</code></td>
<td>
<p>as input. This information is needed in the summary 
function.</p>
</td></tr>
<tr><td><code>information</code></td>
<td>
<p>observed information matrix with the inverted 
information matrix and the augmented information matrix as attributes.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Leonard Vanbrabant and Yves Rosseel</p>


<h3>References</h3>

<p>Schoenberg, R. (1997). Constrained Maximum Likelihood. <em>Computational 
Economics</em>, <b>10</b>, 251&ndash;266.
</p>
<p>Shapiro, A. (1988). Towards a unified theory of inequality-constrained 
testing in multivariate analysis. <em>International Statistical Review</em> 
<b>56</b>, 49&ndash;62.
</p>
<p>Silvapulle, M.J. and Sen, P.K. (2005). <em>Constrained Statistical Inference</em>. 
Wiley, New York
</p>


<h3>See Also</h3>

 
<p><code><a href="#topic+iht">iht</a></code>,
<code><a href="#topic+goric">goric</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## lm
## unrestricted linear model for ages (in months) at which an 
## infant starts to walk alone.

# prepare data
DATA1 &lt;- subset(ZelazoKolb1972, Group != "Control")

# fit unrestricted linear model
fit1.lm &lt;- lm(Age ~ -1 + Group, data = DATA1)

# the variable names can be used to impose restrictions on
# the corresponding regression parameters.
coef(fit1.lm)

# restricted linear model with restrictions that the walking 
# exercises would not have a negative effect of increasing the 
# mean age at which a child starts to walk. 
fit1.con &lt;- restriktor(fit1.lm, constraints = ' GroupActive  &lt; GroupPassive &lt; GroupNo ')
summary(fit1.con)

# Or in matrix notation.
myConstraints1 &lt;- rbind(c(-1, 1, 0),
                        c( 0,-1, 1))
myRhs1 &lt;- rep(0L, nrow(myConstraints1)) 
myNeq1 &lt;- 0

fit1.con &lt;- restriktor(fit1.lm, constraints = myConstraints1,
                       rhs = myRhs1, neq = myNeq1)
summary(fit1.con)

#########################
## Artificial examples ##
#########################
library(MASS)

## mlm
# generate data
n &lt;- 30
mu &lt;- rep(0, 4)
Sigma &lt;- matrix(5,4,4)
  diag(Sigma) &lt;- c(10,10,10,10)
# 4 Y's.
Y &lt;- mvrnorm(n, mu, Sigma)

# fit unrestricted multivariate linear model
fit.mlm &lt;- lm(Y ~ 1)

# constraints
myConstraints2 &lt;- diag(0,4)
  diag(myConstraints2) &lt;- 1

# fit restricted multivariate linear model
fit2.con &lt;- restriktor(fit.mlm, constraints = myConstraints2)

summary(fit2.con)


## rlm
# generate data
n &lt;- 10
means &lt;- c(1,2,1,3)
nm &lt;- length(means)
group &lt;- as.factor(rep(1:nm, each = n))
y &lt;- rnorm(n * nm, rep(means, each = n))
DATA2 &lt;- data.frame(y, group)

# fit unrestricted robust linear model
fit3.rlm &lt;- rlm(y ~ -1 + group, data = DATA2, method = "MM")
coef(fit3.rlm)

## increasing means
myConstraints3 &lt;- ' group1 &lt; group2 &lt; group3 &lt; group4 '

# fit restricted robust linear model and compute 
# Huber-White (robust) standard errors.
fit3.con &lt;- restriktor(fit3.rlm, constraints = myConstraints3, 
                       se = "HC0")
summary(fit3.con)


## increasing means in matrix notation.
myConstraints3 &lt;- rbind(c(-1, 1, 0, 0),
                        c( 0,-1, 1, 0),
                        c( 0, 0,-1, 1))
myRhs3 &lt;- rep(0L, nrow(myConstraints3)) 
myNeq3 &lt;- 0

fit3.con &lt;- restriktor(fit3.rlm, constraints = myConstraints3,
                       rhs = myRhs3, neq = myNeq3, se = "HC0")
summary(fit3.con)

## equality restrictions only.
myConstraints4 &lt;- ' group1 = group2 = group3 = group4 '
                    
fit4.con &lt;- restriktor(fit3.rlm, constraints = myConstraints4)
summary(fit4.con)


## combination of equality and inequality restrictions.
myConstraints5 &lt;- ' group1  = group2
                    group3  &lt; group4 '

# fit restricted model and compute model-based bootstrapped 
# standard errors. We only generate 9 bootstrap samples in this 
# example; in practice you may wish to use a much higher number.
fit5.con &lt;- restriktor(fit3.rlm, constraints = myConstraints4, 
                       se = "boot.model.based", B = 9)
# an error is probably thrown, due to a too low number of bootstrap draws.
summary(fit5.con)

# restriktor can also be used to define effects using the := operator 
# and impose restrictions on them. For example, compute the average 
# effect (AVE) and impose the restriction AVE &gt; 0.
# generate data
n &lt;- 30
b0 &lt;- 10; b1 = 0.5; b2 = 1; b3 = 1.5
X &lt;- c(rep(c(0), n/2), rep(c(1), n/2))
set.seed(90) 
Z &lt;- rnorm(n, 16, 5)
y &lt;- b0 + b1*X + b2*Z + b3*X*Z + rnorm(n, 0, sd = 10) 
DATA3 = data.frame(cbind(y, X, Z))

# fit linear model with interaction
fit6.lm &lt;- lm(y ~ X*Z, data = DATA3)

fit6.con &lt;- restriktor(fit6.lm, constraints = ' AVE := X + 16.86137*X.Z; 
                                                AVE &gt; 0 ')
summary(fit6.con)
</code></pre>

<hr>
<h2 id='restriktor-methods'>Methods for restriktor</h2><span id='topic+restriktor-methods'></span><span id='topic+print.restriktor'></span><span id='topic+summary.restriktor'></span><span id='topic+print.summary.restriktor'></span><span id='topic+coef.restriktor'></span><span id='topic+model.matrix.restriktor'></span><span id='topic+logLik.restriktor'></span>

<h3>Description</h3>

<p>restricted estimation and confidence intervals for  
(robust) linear (in)equality restricted hypotheses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
## S3 method for class 'restriktor'
print(x, digits = max(3, getOption("digits") - 2), ...)

## S3 method for class 'restriktor'
summary(object, bootCIs = TRUE, 
        bty = "perc", level = 0.95, goric = "goric", ...)

## S3 method for class 'summary.restriktor'
print(x, digits = max(3, getOption("digits") - 2),
              signif.stars = getOption("show.signif.stars"), ...)     

## S3 method for class 'restriktor'
coef(object, ...)

## S3 method for class 'restriktor'
model.matrix(object, ...)

## S3 method for class 'restriktor'
logLik(object, ...)
  
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="restriktor-methods_+3A_object">object</code></td>
<td>
<p>an object of class <code>restriktor</code>.</p>
</td></tr>
<tr><td><code id="restriktor-methods_+3A_x">x</code></td>
<td>
<p>an object of class <code>restriktor</code>.</p>
</td></tr>
<tr><td><code id="restriktor-methods_+3A_bootcis">bootCIs</code></td>
<td>
<p>if TRUE (default), nonparametric bootstrap 
confidence intervals are generated. Only available if <code>object</code>
contains <code>bootout</code> object.</p>
</td></tr>
<tr><td><code id="restriktor-methods_+3A_bty">bty</code></td>
<td>
<p>a character string representing the type of interval
required. The value should be any of the values <code>"norm",
  "basic","perc","bca"</code>. The value <code>"stud"</code> is not supported.
For more details see <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>.</p>
</td></tr>
<tr><td><code id="restriktor-methods_+3A_level">level</code></td>
<td>
<p>the confidence level of the interval (default = 0.95).</p>
</td></tr>
<tr><td><code id="restriktor-methods_+3A_goric">goric</code></td>
<td>
<p>if <code>"goric"</code> (default), the generalized order-restricted 
information criterion value is computed. If <code>"gorica"</code> the 
log-likihood is computed using the multivariate normal distribution 
function. If <code>"goricc" or "goricca"</code>, a small sample version
of the <code>"goric" or "gorica"</code> is computed.</p>
</td></tr>
<tr><td><code id="restriktor-methods_+3A_digits">digits</code></td>
<td>
<p>the number of significant digits to use when printing.</p>
</td></tr>
<tr><td><code id="restriktor-methods_+3A_signif.stars">signif.stars</code></td>
<td>
<p>If TRUE, &quot;significance stars are printed 
for each coefficient.</p>
</td></tr>
<tr><td><code id="restriktor-methods_+3A_...">...</code></td>
<td>
<p>no additional arguments for now.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>print</code> returns the restricted coefficients.
The output from the <code>print.summary.conLM</code> function provides 
information that is comparable with the output from 
<code>print.summary.lm</code>. Additional information is provided 
about the unrestricted and restricted R-square and by default 
the output of the GORIC. If bootstrapped standard errors are 
requested (e.g., option <code>se = "boot.model.based"</code> in the 
<code>restriktor</code> function and <code>bootCI = TRUE</code> in the 
summary function) standard errors and confidence intervals 
are provided.
</p>


<h3>Value</h3>

<p>The function <code>summary</code> computes and returns a list of 
summary statistics of the fitted unrestricted and restricted 
(robust) linear model given in <code>object</code>, plus
</p>
<table role = "presentation">
<tr><td><code>se.type</code></td>
<td>
<p>type of standard error computed, equal to input 
<code>se</code> in the <code>restriktor</code> function.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the weighted residuals.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>a p x 4 matrix with columns for the 
estimated coefficient, its standard error, t-statistic and 
corresponding p-value. If <code>bootCIs = TRUE</code> and the 
<code>bootout</code> object is available in the object, bootstrapped
standard errors and confidence intervals are produced.</p>
</td></tr>
<tr><td><code>rdf</code></td>
<td>
<p>residual degrees of freedom.</p>
</td></tr>
<tr><td><code>R2.org</code></td>
<td>
<p>unrestricted R-squared.</p>
</td></tr>
<tr><td><code>R2.reduced</code></td>
<td>
<p>restricted R-squared.</p>
</td></tr>
<tr><td><code>goric</code></td>
<td>
<p>goric value and attributed its penalty term and
log-likelihood.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>  # unrestricted linear model for ages (in months) at which an 
  # infant starts to walk alone.
  
  # prepare data
  DATA &lt;- subset(ZelazoKolb1972, Group != "Control")
  
  # fit unrestricted linear model
  fit.lm &lt;- lm(Age ~ -1 + Group, data = DATA)
  
  # restricted linear model with restrictions that the walking 
  # exercises would not have a negative effect of increasing the 
  # mean age at which a child starts to walk. 
  fit.con &lt;- restriktor(fit.lm, constraints = ' GroupActive  &lt; GroupPassive &lt; GroupNo ')
  
  summary(fit.con)
</code></pre>

<hr>
<h2 id='ZelazoKolb1972'>
&quot;Walking&quot; in the newborn (4 treatment groups)
</h2><span id='topic+ZelazoKolb1972'></span>

<h3>Description</h3>

<p>The Zelazo, Zelazo and Kolb (1972) dataset consists of ages (in months) at which 
an infant starts to walk alone from four different treatment groups (Active-exercise, 
Passive-exercise, 8 week Control, No-exercise). 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ZelazoKolb1972)</code></pre>


<h3>Format</h3>

<p>A data frame of 23 observations of 4 treatment variables.
</p>

<dl>
<dt><code>Age</code></dt><dd><p>Age in months</p>
</dd>
<dt><code>Group</code></dt><dd><p>Active-exercise, Passive-exercise, 8-week Control group, No-exercise</p>
</dd>




</dl>



<h3>References</h3>

<p>Zelazo, P.R., Zelazo, N.A., and Kolb, S. (1972). &quot;Walking in the 
Newborn&quot;. Science, New Series, 176, 314-315
</p>


<h3>Examples</h3>

<pre><code class='language-R'>head(ZelazoKolb1972)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
