<!DOCTYPE html><html><head><title>Help for package mirt</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {mirt}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mirt-package'><p>Full information maximum likelihood estimation of IRT models.</p></a></li>
<li><a href='#anova-method'><p>Compare nested models with likelihood-based statistics</p></a></li>
<li><a href='#areainfo'><p>Function to calculate the area under a selection of information curves</p></a></li>
<li><a href='#averageMI'><p>Collapse values from multiple imputation draws</p></a></li>
<li><a href='#bfactor'><p>Full-Information Item Bi-factor and Two-Tier Analysis</p></a></li>
<li><a href='#Bock1997'><p>Description of Bock 1997 data</p></a></li>
<li><a href='#boot.LR'><p>Parametric bootstrap likelihood-ratio test</p></a></li>
<li><a href='#boot.mirt'><p>Calculate bootstrapped standard errors for estimated models</p></a></li>
<li><a href='#coef-method'><p>Extract raw coefs from model object</p></a></li>
<li><a href='#createGroup'><p>Create a user defined group-level object with correct generic functions</p></a></li>
<li><a href='#createItem'><p>Create a user defined item with correct generic functions</p></a></li>
<li><a href='#deAyala'><p>Description of deAyala data</p></a></li>
<li><a href='#DIF'><p>Differential item functioning statistics</p></a></li>
<li><a href='#DiscreteClass-class'><p>Class &quot;DiscreteClass&quot;</p></a></li>
<li><a href='#draw_parameters'><p>Draw plausible parameter instantiations from a given model</p></a></li>
<li><a href='#DRF'><p>Differential Response Functioning statistics</p></a></li>
<li><a href='#DTF'><p>Differential test functioning statistics</p></a></li>
<li><a href='#empirical_ES'><p>Empirical effect sizes based on latent trait estimates</p></a></li>
<li><a href='#empirical_plot'><p>Function to generate empirical unidimensional item and test plots</p></a></li>
<li><a href='#empirical_rxx'><p>Function to calculate the empirical (marginal) reliability</p></a></li>
<li><a href='#estfun.AllModelClass'><p>Extract Empirical Estimating Functions</p></a></li>
<li><a href='#expand.table'><p>Expand summary table of patterns and frequencies</p></a></li>
<li><a href='#expected.item'><p>Function to calculate expected value of item</p></a></li>
<li><a href='#expected.test'><p>Function to calculate expected test score</p></a></li>
<li><a href='#extract.group'><p>Extract a group from a multiple group mirt object</p></a></li>
<li><a href='#extract.item'><p>Extract an item object from mirt objects</p></a></li>
<li><a href='#extract.mirt'><p>Extract various elements from estimated model objects</p></a></li>
<li><a href='#fixedCalib'><p>Fixed-item calibration method</p></a></li>
<li><a href='#fixef'><p>Compute latent regression fixed effect expected values</p></a></li>
<li><a href='#fscores'><p>Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc)</p></a></li>
<li><a href='#gen.difficulty'><p>Generalized item difficulty summaries</p></a></li>
<li><a href='#imputeMissing'><p>Imputing plausible data for missing values</p></a></li>
<li><a href='#itemfit'><p>Item fit statistics</p></a></li>
<li><a href='#itemGAM'><p>Parametric smoothed regression lines for item response probability functions</p></a></li>
<li><a href='#iteminfo'><p>Function to calculate item information</p></a></li>
<li><a href='#itemplot'><p>Displays item surface and information plots</p></a></li>
<li><a href='#itemstats'><p>Generic item summary statistics</p></a></li>
<li><a href='#key2binary'><p>Score a test by converting response patterns to binary data</p></a></li>
<li><a href='#lagrange'><p>Lagrange test for freeing parameters</p></a></li>
<li><a href='#likert2int'><p>Convert ordered Likert-scale responses (character or factors) to integers</p></a></li>
<li><a href='#logLik-method'><p>Extract log-likelihood</p></a></li>
<li><a href='#LSAT6'><p>Description of LSAT6 data</p></a></li>
<li><a href='#LSAT7'><p>Description of LSAT7 data</p></a></li>
<li><a href='#M2'><p>Compute the M2 model fit statistic</p></a></li>
<li><a href='#marginal_rxx'><p>Function to calculate the marginal reliability</p></a></li>
<li><a href='#MDIFF'><p>Compute multidimensional difficulty index</p></a></li>
<li><a href='#mdirt'><p>Multidimensional discrete item response theory</p></a></li>
<li><a href='#MDISC'><p>Compute multidimensional discrimination index</p></a></li>
<li><a href='#mirt'><p>Full-Information Item Factor Analysis (Multidimensional Item Response</p>
Theory)</a></li>
<li><a href='#mirt.model'><p>Specify model information</p></a></li>
<li><a href='#mirtCluster'><p>Define a parallel cluster object to be used in internal functions</p></a></li>
<li><a href='#MixedClass-class'><p>Class &quot;MixedClass&quot;</p></a></li>
<li><a href='#mixedmirt'><p>Mixed effects modeling for MIRT models</p></a></li>
<li><a href='#MixtureClass-class'><p>Class &quot;MixtureClass&quot;</p></a></li>
<li><a href='#mod2values'><p>Convert an estimated mirt model to a data.frame</p></a></li>
<li><a href='#multipleGroup'><p>Multiple Group Estimation</p></a></li>
<li><a href='#MultipleGroupClass-class'><p>Class &quot;MultipleGroupClass&quot;</p></a></li>
<li><a href='#numerical_deriv'><p>Compute numerical derivatives</p></a></li>
<li><a href='#personfit'><p>Person fit statistics</p></a></li>
<li><a href='#PLCI.mirt'><p>Compute profiled-likelihood (or posterior) confidence intervals</p></a></li>
<li><a href='#plot+2CMultipleGroupClass+2Cmissing-method'><p>Plot various test-implied functions from models</p></a></li>
<li><a href='#poly2dich'><p>Change polytomous items to dichotomous item format</p></a></li>
<li><a href='#print-method'><p>Print the model objects</p></a></li>
<li><a href='#print.mirt_df'><p>Print generic for customized data.frame console output</p></a></li>
<li><a href='#print.mirt_list'><p>Print generic for customized list console output</p></a></li>
<li><a href='#print.mirt_matrix'><p>Print generic for customized matrix console output</p></a></li>
<li><a href='#probtrace'><p>Function to calculate probability trace lines</p></a></li>
<li><a href='#randef'><p>Compute posterior estimates of random effect</p></a></li>
<li><a href='#RCI'><p>Model-based Reliable Change Index</p></a></li>
<li><a href='#read.mirt'><p>Translate mirt parameters into suitable structure for plink package</p></a></li>
<li><a href='#remap.distance'><p>Remap item categories to have integer distances of 1</p></a></li>
<li><a href='#residuals-method'><p>Compute model residuals</p></a></li>
<li><a href='#RMSD_DIF'><p>RMSD effect size statistic to quantify category-level DIF</p></a></li>
<li><a href='#SAT12'><p>Description of SAT12 data</p></a></li>
<li><a href='#Science'><p>Description of Science data</p></a></li>
<li><a href='#show-method'><p>Show model object</p></a></li>
<li><a href='#SIBTEST'><p>(Generalized) Simultaneous Item Bias Test (SIBTEST)</p></a></li>
<li><a href='#simdata'><p>Simulate response patterns</p></a></li>
<li><a href='#SingleGroupClass-class'><p>Class &quot;SingleGroupClass&quot;</p></a></li>
<li><a href='#SLF'><p>Social Life Feelings Data</p></a></li>
<li><a href='#summary-method'><p>Summary of model object</p></a></li>
<li><a href='#testinfo'><p>Function to calculate test information</p></a></li>
<li><a href='#thetaComb'><p>Create all possible combinations of vector input</p></a></li>
<li><a href='#traditional2mirt'><p>Convert traditional IRT metric into slope-intercept form used in mirt</p></a></li>
<li><a href='#vcov-method'><p>Extract parameter variance covariance matrix</p></a></li>
<li><a href='#wald'><p>Wald statistics for mirt models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.41</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Multidimensional Item Response Theory</td>
</tr>
<tr>
<td>Description:</td>
<td>Analysis of discrete response data using
    unidimensional and multidimensional item analysis models under the Item
    Response Theory paradigm (Chalmers (2012) &lt;<a href="https://doi.org/10.18637%2Fjss.v048.i06">doi:10.18637/jss.v048.i06</a>&gt;). 
    Exploratory and confirmatory item factor analysis models
	are estimated with quadrature (EM) or stochastic (MHRM) methods. Confirmatory
    bi-factor and two-tier models are available for modeling item testlets using
	dimension reduction EM algorithms, while multiple group analyses and 
	mixed effects designs are included for detecting differential item, bundle, 
	and test functioning, and for modeling item and person covariates. 
	Finally, latent class models such as the DINA, DINO, multidimensional latent class, 
	mixture, and zero-inflated response models are supported.</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>stats, R (&ge; 3.6.0), stats4, lattice, methods</td>
</tr>
<tr>
<td>Imports:</td>
<td>GPArotation, gridExtra, Matrix (&ge; 1.5-0), Rcpp, mgcv, vegan,
Deriv, splines, pbapply (&ge; 1.3-0), dcurver</td>
</tr>
<tr>
<td>Suggests:</td>
<td>boot, latticeExtra, directlabels, shiny, knitr, markdown,
Rsolnp, nloptr, sirt, plink, mirtCAT</td>
</tr>
<tr>
<td>ByteCompile:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>yes</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Phil Chalmers &lt;rphilip.chalmers@gmail.com&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/philchalmers/mirt">https://github.com/philchalmers/mirt</a>,
<a href="https://github.com/philchalmers/mirt/wiki">https://github.com/philchalmers/mirt/wiki</a>,
<a href="https://groups.google.com/forum/#!forum/mirt-package">https://groups.google.com/forum/#!forum/mirt-package</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/philchalmers/mirt/issues?state=open">https://github.com/philchalmers/mirt/issues?state=open</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-17 14:31:29 UTC; phil</td>
</tr>
<tr>
<td>Author:</td>
<td>Phil Chalmers <a href="https://orcid.org/0000-0001-5332-2810"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Joshua Pritikin [ctb],
  Alexander Robitzsch [ctb],
  Mateusz Zoltak [ctb],
  KwonHyun Kim [ctb],
  Carl F. Falk [ctb],
  Adam Meade [ctb],
  Lennart Schneider [ctb],
  David King [ctb],
  Chen-Wei Liu [ctb],
  Ogreden Oguzhan [ctb]</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-17 15:50:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='mirt-package'>Full information maximum likelihood estimation of IRT models.</h2><span id='topic+mirt-package'></span>

<h3>Description</h3>

<p>Full information maximum likelihood estimation of multidimensional IRT models
</p>


<h3>Details</h3>

<p>Analysis of dichotomous and polytomous response data using
unidimensional and multidimensional latent trait models under the Item
Response Theory paradigm. Exploratory and confirmatory models can be
estimated with quadrature (EM) or stochastic (MHRM) methods. Confirmatory
bi-factor and two-tier analyses are available for modeling item testlets.
Multiple group analysis and mixed effects designs also are available for
detecting differential item and test functioning as well as modeling
item and person covariates. Finally, latent class models such as the DINA,
DINO, multidimensional latent class, and several other discrete variable
models are supported.
</p>
<p>Users interested in the most recent version of this package can visit
<a href="https://github.com/philchalmers/mirt">https://github.com/philchalmers/mirt</a> and follow the instructions
for installing the package from source. Questions regarding the package can
be sent to the mirt-package Google Group, located at
<a href="https://groups.google.com/forum/#!forum/mirt-package">https://groups.google.com/forum/#!forum/mirt-package</a>. User contributed files,
workshop files, and evaluated help files are also available on the package wiki
(<a href="https://github.com/philchalmers/mirt/wiki">https://github.com/philchalmers/mirt/wiki</a>).
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>

<hr>
<h2 id='anova-method'>Compare nested models with likelihood-based statistics</h2><span id='topic+anova-method'></span><span id='topic+anova+2CSingleGroupClass-method'></span><span id='topic+anova+2CMultipleGroupClass-method'></span><span id='topic+anova+2CMixedClass-method'></span><span id='topic+anova+2CDiscreteClass-method'></span><span id='topic+anova+2CMixtureClass-method'></span>

<h3>Description</h3>

<p>Compare nested models using likelihood ratio test (X2), Akaike Information Criterion (AIC),
Bayesian Information Criterion (BIC),
Sample-Size Adjusted BIC (SABIC), and Hannan-Quinn (HQ) Criterion.
When given a sequence of objects, <code>anova</code> tests the models against one another
in the order specified. Note that the <code>object</code> inputs should be ordered in terms
of most constrained model to least constrained.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SingleGroupClass'
anova(
  object,
  object2,
  ...,
  bounded = FALSE,
  mix = 0.5,
  frame = 1,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="anova-method_+3A_object">object</code></td>
<td>
<p>an object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>MixedClass</code>, reflecting the most constrained model fitted</p>
</td></tr>
<tr><td><code id="anova-method_+3A_object2">object2</code></td>
<td>
<p>a second model estimated from any of the mirt package estimation methods</p>
</td></tr>
<tr><td><code id="anova-method_+3A_...">...</code></td>
<td>
<p>additional less constrained model objects to be compared
sequentially to the previous model</p>
</td></tr>
<tr><td><code id="anova-method_+3A_bounded">bounded</code></td>
<td>
<p>logical; are the two models comparing a bounded parameter (e.g., comparing a single
2PL and 3PL model with 1 df)? If <code>TRUE</code> then a 50:50 mix of chi-squared distributions
is used to obtain the p-value</p>
</td></tr>
<tr><td><code id="anova-method_+3A_mix">mix</code></td>
<td>
<p>proportion of chi-squared mixtures. Default is 0.5</p>
</td></tr>
<tr><td><code id="anova-method_+3A_frame">frame</code></td>
<td>
<p>(internal parameter not for standard use)</p>
</td></tr>
<tr><td><code id="anova-method_+3A_verbose">verbose</code></td>
<td>
<p>(deprecated argument)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code>/<code>mirt_df</code> object
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x &lt;- mirt(Science, 1)
x2 &lt;- mirt(Science, 2)
anova(x, x2)

# compare three models sequentially (X2 not always meaningful)
x3 &lt;- mirt(Science, 1, 'gpcm')
x4 &lt;- mirt(Science, 1, 'nominal')
anova(x, x2, x3, x4)

# in isolation
anova(x)

# with priors on first model
model &lt;- "Theta = 1-4
          PRIOR = (1-4, a1, lnorm, 0, 10)"
xp &lt;- mirt(Science, model)
anova(xp, x2)
anova(xp)

# bounded parameter
dat &lt;- expand.table(LSAT7)
mod &lt;- mirt(dat, 1)
mod2 &lt;- mirt(dat, 1, itemtype = c(rep('2PL', 4), '3PL'))
anova(mod, mod2) #unbounded test
anova(mod, mod2, bounded = TRUE) #bounded

# priors
model &lt;- 'F = 1-5
          PRIOR = (5, g, norm, -1, 1)'
mod1b &lt;- mirt(dat, model, itemtype = c(rep('2PL', 4), '3PL'))
anova(mod1b)

model2 &lt;- 'F = 1-5
          PRIOR = (1-5, g, norm, -1, 1)'
mod2b &lt;- mirt(dat, model2, itemtype = '3PL')
anova(mod1b, mod2b)


## End(Not run)
</code></pre>

<hr>
<h2 id='areainfo'>Function to calculate the area under a selection of information curves</h2><span id='topic+areainfo'></span>

<h3>Description</h3>

<p>Compute the area of a test or item information function over a definite integral range.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>areainfo(
  x,
  theta_lim,
  which.items = 1:extract.mirt(x, "nitems"),
  group = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="areainfo_+3A_x">x</code></td>
<td>
<p>an object of class 'SingleGroupClass', or an object of class 'MultipleGroupClass' if a suitable
<code>group</code> input were supplied</p>
</td></tr>
<tr><td><code id="areainfo_+3A_theta_lim">theta_lim</code></td>
<td>
<p>range of integration to be computed</p>
</td></tr>
<tr><td><code id="areainfo_+3A_which.items">which.items</code></td>
<td>
<p>an integer vector indicating which items to include in the expected information function.
Default uses all possible items</p>
</td></tr>
<tr><td><code id="areainfo_+3A_group">group</code></td>
<td>
<p>group argument to pass to <code><a href="#topic+extract.group">extract.group</a></code> function. Required when the input object is
a multiple-group model</p>
</td></tr>
<tr><td><code id="areainfo_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="stats.html#topic+integrate">integrate</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code>data.frame</code> with the lower and upper integration range, the information area
within the range (Info), the information area over the range -10 to 10 (Total.Info), proportion
of total information given the integration range (Info.Proportion), and the number of items included (nitems)
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- expand.table(LSAT7)
mod &lt;- mirt(dat, 1)

areainfo(mod, c(-2,0), which.items = 1) #item 1
## Not run: 
areainfo(mod, c(-2,0), which.items = 1:3) #items 1 to 3
areainfo(mod, c(-2,0)) # all items (total test information)

# plot the area
area &lt;- areainfo(mod, c(-2,0))
Theta &lt;- matrix(seq(-3,3, length.out=1000))
info &lt;- testinfo(mod, Theta)
plot(info ~ Theta, type = 'l')

pick &lt;- Theta &gt;= -2 &amp; Theta &lt;=0
polygon(c(-2, Theta[pick], 0), c(0, info[pick], 0), col='lightblue')
text(x = 2, y = 0.5, labels = paste("Total Information:", round(area$TotalInfo, 3),
           "\n\nInformation in (-2, 0):", round(area$Info, 3),
           paste("(", round(100 * area$Proportion, 2), "%)", sep = "")), cex = 1.2)


## End(Not run)
</code></pre>

<hr>
<h2 id='averageMI'>Collapse values from multiple imputation draws</h2><span id='topic+averageMI'></span>

<h3>Description</h3>

<p>This function computes updated parameter and standard error estimates using multiple
imputation methodology. Given a set of parameter estimates and their associated standard
errors the function returns the weighted average of the overall between and within
variability due to the multiple imputations according to Rubin's (1987) methodology.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>averageMI(par, SEpar, as.data.frame = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="averageMI_+3A_par">par</code></td>
<td>
<p>a list containing parameter estimates which were computed the imputed datasets</p>
</td></tr>
<tr><td><code id="averageMI_+3A_separ">SEpar</code></td>
<td>
<p>a list containing standard errors associated with <code>par</code></p>
</td></tr>
<tr><td><code id="averageMI_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical; return a data.frame instead of a list? Default is TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a list or data.frame containing the updated averaged parameter estimates,
standard errors, and t-values with the associated degrees of freedom and two tailed p-values
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Rubin, D.B. (1987) Multiple Imputation for Nonresponse in Surveys. Wiley &amp; Sons, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# simulate data
set.seed(1234)
N &lt;- 1000

# covariates
X1 &lt;- rnorm(N); X2 &lt;- rnorm(N)
covdata &lt;- data.frame(X1, X2)
Theta &lt;- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))

# items and response data
a &lt;- matrix(1, 20); d &lt;- matrix(rnorm(20))
dat &lt;- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)

mod1 &lt;- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2)
coef(mod1, simplify=TRUE)

# draw plausible values for secondary analyses
pv &lt;- fscores(mod1, plausible.draws = 10)
pvmods &lt;- lapply(pv, function(x, covdata) lm(x ~ covdata$X1 + covdata$X2),
                 covdata=covdata)

# compute Rubin's multiple imputation average
so &lt;- lapply(pvmods, summary)
par &lt;- lapply(so, function(x) x$coefficients[, 'Estimate'])
SEpar &lt;- lapply(so, function(x) x$coefficients[, 'Std. Error'])
averageMI(par, SEpar)


## End(Not run)
</code></pre>

<hr>
<h2 id='bfactor'>Full-Information Item Bi-factor and Two-Tier Analysis</h2><span id='topic+bfactor'></span>

<h3>Description</h3>

<p><code>bfactor</code> fits a confirmatory maximum likelihood two-tier/bifactor/testlet model to
dichotomous and polytomous data under the item response theory paradigm.
The IRT models are fit using a dimensional reduction EM algorithm so that regardless
of the number of specific factors estimated the model only uses the number of
factors in the second-tier structure plus 1. For the bifactor model the maximum
number of dimensions is only 2 since the second-tier only consists of a
ubiquitous unidimensional factor. See <code><a href="#topic+mirt">mirt</a></code> for appropriate methods to be used
on the objects returned from the estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bfactor(
  data,
  model,
  model2 = paste0("G = 1-", ncol(data)),
  group = NULL,
  quadpts = NULL,
  invariance = "",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bfactor_+3A_data">data</code></td>
<td>
<p>a <code>matrix</code> or <code>data.frame</code> that consists of
numerically ordered data, with missing data coded as <code>NA</code></p>
</td></tr>
<tr><td><code id="bfactor_+3A_model">model</code></td>
<td>
<p>a numeric vector specifying which factor loads on which
item. For example, if for a 4 item test with two specific factors, the first
specific factor loads on the first two items and the second specific factor
on the last two, then the vector is <code>c(1,1,2,2)</code>. For items that should only load
on the second-tier factors (have no specific component) <code>NA</code> values may
be used as place-holders. These numbers will be translated into a format suitable for
<code>mirt.model()</code>, combined with the definition in <code>model2</code>, with the letter 'S'
added to the respective factor number</p>
</td></tr>
<tr><td><code id="bfactor_+3A_model2">model2</code></td>
<td>
<p>a two-tier model specification object defined by <code>mirt.model()</code> or
a string to be passed to <code><a href="#topic+mirt.model">mirt.model</a></code>. By default
the model will fit a unidimensional model in the second-tier, and therefore be equivalent to
the bifactor model</p>
</td></tr>
<tr><td><code id="bfactor_+3A_group">group</code></td>
<td>
<p>a factor variable indicating group membership used for multiple group analyses</p>
</td></tr>
<tr><td><code id="bfactor_+3A_quadpts">quadpts</code></td>
<td>
<p>number of quadrature nodes to use after accounting for the reduced number of dimensions.
Scheme is the same as the one used in <code><a href="#topic+mirt">mirt</a></code>, however it is in regards to the reduced
dimensions (e.g., a bifactor model has 2 dimensions to be integrated)</p>
</td></tr>
<tr><td><code id="bfactor_+3A_invariance">invariance</code></td>
<td>
<p>see <code><a href="#topic+multipleGroup">multipleGroup</a></code> for details, however, the specific factor variances
and means will be constrained according to the dimensional reduction algorithm</p>
</td></tr>
<tr><td><code id="bfactor_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the estimation engine. See <code><a href="#topic+mirt">mirt</a></code>
for more details and examples</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>bfactor</code> follows the item factor analysis strategy explicated by
Gibbons and Hedeker (1992), Gibbons et al. (2007), and Cai (2010).
Nested models may be compared via an approximate
chi-squared difference test or by a reduction in AIC or BIC (accessible via
<code><a href="stats.html#topic+anova">anova</a></code>). See <code><a href="#topic+mirt">mirt</a></code> for more details regarding the
IRT estimation approach used in this package.
</p>
<p>The two-tier model has a specific block diagonal covariance structure between the primary and
secondary latent traits. Namely, the secondary latent traits are assumed to be orthogonal to
all traits and have a fixed variance of 1, while the primary traits can be organized to vary
and covary with other primary traits in the model.
</p>
<p style="text-align: center;"><code class="reqn">\Sigma_{two-tier} = \left(\begin{array}{cc} G &amp; 0 \\ 0 &amp; diag(S) \end{array} \right)</code>
</p>

<p>The bifactor model is a special case of the two-tier model when <code class="reqn">G</code> above is a 1x1 matrix,
and therefore only 1 primary factor is being modeled. Evaluation of the numerical integrals
for the two-tier model requires only <code class="reqn">ncol(G) + 1</code> dimensions for integration since the
<code class="reqn">S</code> second order (or 'specific') factors require only 1 integration grid due to the
dimension reduction technique.
</p>
<p>Note: for multiple group two-tier analyses only the second-tier means and variances
should be freed since the specific factors are not treated independently due to the
dimension reduction technique.
</p>


<h3>Value</h3>

<p>function returns an object of class <code>SingleGroupClass</code>
(<a href="#topic+SingleGroupClass-class">SingleGroupClass-class</a>) or <code>MultipleGroupClass</code>(<a href="#topic+MultipleGroupClass-class">MultipleGroupClass-class</a>).
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Cai, L. (2010). A two-tier full-information item factor analysis model with applications.
<em>Psychometrika, 75</em>, 581-612.
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Bradlow, E.T., Wainer, H., &amp; Wang, X. (1999). A Bayesian random effects model for testlets.
<em>Psychometrika, 64</em>, 153-168.
</p>
<p>Gibbons, R. D., &amp; Hedeker, D. R. (1992). Full-information Item Bi-Factor
Analysis. <em>Psychometrika, 57</em>, 423-436.
</p>
<p>Gibbons, R. D., Darrell, R. B., Hedeker, D., Weiss, D. J., Segawa, E., Bhaumik, D. K.,
Kupfer, D. J., Frank, E., Grochocinski, V. J., &amp; Stover, A. (2007).
Full-Information item bifactor analysis of graded response data.
<em>Applied Psychological Measurement, 31</em>, 4-19.
</p>
<p>Wainer, H., Bradlow, E.T., &amp; Wang, X. (2007). Testlet response theory and its applications.
New York, NY: Cambridge University Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mirt">mirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

### load SAT12 and compute bifactor model with 3 specific factors
data(SAT12)
data &lt;- key2binary(SAT12,
  key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
specific &lt;- c(2,3,2,3,3,2,1,2,1,1,1,3,1,3,1,2,1,1,3,3,1,1,3,1,3,3,1,3,2,3,1,2)
mod1 &lt;- bfactor(data, specific)
summary(mod1)
itemplot(mod1, 18, drop.zeros = TRUE) #drop the zero slopes to allow plotting

### Try with fixed guessing parameters added
guess &lt;- rep(.1,32)
mod2 &lt;- bfactor(data, specific, guess = guess)
coef(mod2)
anova(mod1, mod2)

## don't estimate specific factor for item 32
specific[32] &lt;- NA
mod3 &lt;- bfactor(data, specific)
anova(mod3, mod1)

# same, but declared manually (not run)
#sv &lt;- mod2values(mod1)
#sv$value[220] &lt;- 0 #parameter 220 is the 32 items specific slope
#sv$est[220] &lt;- FALSE
#mod3 &lt;- bfactor(data, specific, pars = sv) #with excellent starting values


#########
# mixed itemtype example

# simulate data
a &lt;- matrix(c(
1,0.5,NA,
1,0.5,NA,
1,0.5,NA,
1,0.5,NA,
1,0.5,NA,
1,0.5,NA,
1,0.5,NA,
1,NA,0.5,
1,NA,0.5,
1,NA,0.5,
1,NA,0.5,
1,NA,0.5,
1,NA,0.5,
1,NA,0.5),ncol=3,byrow=TRUE)

d &lt;- matrix(c(
-1.0,NA,NA,
-1.5,NA,NA,
 1.5,NA,NA,
 0.0,NA,NA,
2.5,1.0,-1,
3.0,2.0,-0.5,
3.0,2.0,-0.5,
3.0,2.0,-0.5,
2.5,1.0,-1,
2.0,0.0,NA,
-1.0,NA,NA,
-1.5,NA,NA,
 1.5,NA,NA,
 0.0,NA,NA),ncol=3,byrow=TRUE)
items &lt;- rep('2PL', 14)
items[5:10] &lt;- 'graded'

sigma &lt;- diag(3)
dataset &lt;- simdata(a,d,2000,itemtype=items,sigma=sigma)
itemstats(dataset)

specific &lt;- c(rep(1,7),rep(2,7))
simmod &lt;- bfactor(dataset, specific)
coef(simmod)

#########
# General testlet response model (Wainer, 2007)

# simulate data
set.seed(1234)
a &lt;- matrix(0, 12, 4)
a[,1] &lt;- rlnorm(12, .2, .3)
ind &lt;- 1
for(i in 1:3){
   a[ind:(ind+3),i+1] &lt;- a[ind:(ind+3),1]
   ind &lt;- ind+4
}
print(a)
d &lt;- rnorm(12, 0, .5)
sigma &lt;- diag(c(1, .5, 1, .5))
dataset &lt;- simdata(a,d,2000,itemtype=rep('2PL', 12),sigma=sigma)
itemstats(dataset)

# estimate by applying constraints and freeing the latent variances
specific &lt;- c(rep(1,4),rep(2,4), rep(3,4))
model &lt;- "G = 1-12
          CONSTRAIN = (1, a1, a2), (2, a1, a2), (3, a1, a2), (4, a1, a2),
            (5, a1, a3), (6, a1, a3), (7, a1, a3), (8, a1, a3),
            (9, a1, a4), (10, a1, a4), (11, a1, a4), (12, a1, a4)
          COV = S1*S1, S2*S2, S3*S3"

simmod &lt;- bfactor(dataset, specific, model)
coef(simmod, simplify=TRUE)

# Constrained testlet model (Bradlow, 1999)
model2 &lt;- "G = 1-12
          CONSTRAIN = (1, a1, a2), (2, a1, a2), (3, a1, a2), (4, a1, a2),
            (5, a1, a3), (6, a1, a3), (7, a1, a3), (8, a1, a3),
            (9, a1, a4), (10, a1, a4), (11, a1, a4), (12, a1, a4),
            (GROUP, COV_22, COV_33, COV_44)
          COV = S1*S1, S2*S2, S3*S3"

simmod2 &lt;- bfactor(dataset, specific, model2)
coef(simmod2, simplify=TRUE)
anova(simmod2, simmod)


#########
# Two-tier model

# simulate data
set.seed(1234)
a &lt;- matrix(c(
  0,1,0.5,NA,NA,
  0,1,0.5,NA,NA,
  0,1,0.5,NA,NA,
  0,1,0.5,NA,NA,
  0,1,0.5,NA,NA,
  0,1,NA,0.5,NA,
  0,1,NA,0.5,NA,
  0,1,NA,0.5,NA,
  1,0,NA,0.5,NA,
  1,0,NA,0.5,NA,
  1,0,NA,0.5,NA,
  1,0,NA,NA,0.5,
  1,0,NA,NA,0.5,
  1,0,NA,NA,0.5,
  1,0,NA,NA,0.5,
  1,0,NA,NA,0.5),ncol=5,byrow=TRUE)

d &lt;- matrix(rnorm(16))
items &lt;- rep('2PL', 16)

sigma &lt;- diag(5)
sigma[1,2] &lt;- sigma[2,1] &lt;- .4
dataset &lt;- simdata(a,d,2000,itemtype=items,sigma=sigma)
itemstats(dataset)

specific &lt;- c(rep(1,5),rep(2,6),rep(3,5))
model &lt;- '
    G1 = 1-8
    G2 = 9-16
    COV = G1*G2'

# quadpts dropped for faster estimation, but not as precise
simmod &lt;- bfactor(dataset, specific, model, quadpts = 9, TOL = 1e-3)
coef(simmod, simplify=TRUE)
summary(simmod)
itemfit(simmod, QMC=TRUE)
M2(simmod, QMC=TRUE)
residuals(simmod, QMC=TRUE)


## End(Not run)

</code></pre>

<hr>
<h2 id='Bock1997'>Description of Bock 1997 data</h2><span id='topic+Bock1997'></span>

<h3>Description</h3>

<p>A 3-item tabulated data set extracted from Table 3 in Chapter Two.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Bock, R. D. (1997). The Nominal Categories Model. In van der Linden, W. J. &amp; Hambleton, R. K.
<em>Handbook of modern item response theory</em>. New York: Springer.
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
dat &lt;- expand.table(Bock1997)
head(dat)
itemstats(dat, use_ts=FALSE)

mod &lt;- mirt(dat, 1, 'nominal')

# reproduce table 3 in Bock (1997)
fs &lt;- round(fscores(mod, verbose = FALSE, full.scores = FALSE)[,c('F1','SE_F1')],2)
fttd &lt;- residuals(mod, type = 'exp')
table &lt;- data.frame(fttd[,-ncol(fttd)], fs)
table

mod &lt;- mirt(dat, 1, 'nominal')
coef(mod)

 
## End(Not run)
</code></pre>

<hr>
<h2 id='boot.LR'>Parametric bootstrap likelihood-ratio test</h2><span id='topic+boot.LR'></span>

<h3>Description</h3>

<p>Given two fitted models, compute a parametric bootstrap test to determine whether
the less restrictive models fits significantly better than the more restricted model.
Note that this hypothesis test also works when prior parameter distributions are included for
either model. Function can be run in parallel after using a suitable <code><a href="#topic+mirtCluster">mirtCluster</a></code>
definition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.LR(mod, mod2, R = 1000, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.LR_+3A_mod">mod</code></td>
<td>
<p>an estimated model object, more constrained than <code>mod2</code></p>
</td></tr>
<tr><td><code id="boot.LR_+3A_mod2">mod2</code></td>
<td>
<p>an estimated model object</p>
</td></tr>
<tr><td><code id="boot.LR_+3A_r">R</code></td>
<td>
<p>number of parametric bootstraps to use.</p>
</td></tr>
<tr><td><code id="boot.LR_+3A_verbose">verbose</code></td>
<td>
<p>logical; include additional information in the console?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a p-value evaluating whether the more restrictive model fits significantly worse
than the less restrictive model
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# standard
dat &lt;- expand.table(LSAT7)
mod1 &lt;- mirt(dat, 1)
mod2 &lt;- mirt(dat, 1, '3PL')

# standard LR test
anova(mod1, mod2)

# bootstrap LR test (run in parallel to save time)
if(interactive()) mirtCluster()
boot.LR(mod1, mod2, R=200)


## End(Not run)
</code></pre>

<hr>
<h2 id='boot.mirt'>Calculate bootstrapped standard errors for estimated models</h2><span id='topic+boot.mirt'></span>

<h3>Description</h3>

<p>Given an internal mirt object estimate the bootstrapped standard errors. It may
be beneficial to run the computations using multi-core architecture (e.g., the <code>parallel</code>
package). Parameters are organized from the freely estimated values in <code>mod2values(x)</code>
(equality constraints will also be returned in the bootstrapped estimates).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>boot.mirt(x, R = 100, boot.fun = NULL, technical = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="boot.mirt_+3A_x">x</code></td>
<td>
<p>an estimated model object</p>
</td></tr>
<tr><td><code id="boot.mirt_+3A_r">R</code></td>
<td>
<p>number of draws to use (passed to the <code>boot()</code> function)</p>
</td></tr>
<tr><td><code id="boot.mirt_+3A_boot.fun">boot.fun</code></td>
<td>
<p>a user-defined function used to extract the information from the bootstrap
fitted models. Must be of the form <code>boot.fun(x)</code>, where <code>x</code> is the
bootstrap fitted model under investigation, and the return must be a numeric vector. If
omitted a default function will be defined internally that returns the estimated
parameters from the <code>mod</code> object, resulting in bootstrapped parameter estimate
results</p>
</td></tr>
<tr><td><code id="boot.mirt_+3A_technical">technical</code></td>
<td>
<p>technical arguments passed to estimation engine. See <code><a href="#topic+mirt">mirt</a></code>
for details</p>
</td></tr>
<tr><td><code id="boot.mirt_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed on to <code>boot(...)</code> and mirt's
estimation engine</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# standard
mod &lt;- mirt(Science, 1)
booted &lt;- boot.mirt(mod, R=20)
plot(booted)
booted

#run in parallel using snow back-end using all available cores
mod &lt;- mirt(Science, 1)
booted &lt;- boot.mirt(mod, parallel = 'snow', ncpus = parallel::detectCores())
booted

####
# bootstrapped CIs for standardized factor loadings
boot.fun &lt;- function(mod){
  so &lt;- summary(mod, verbose=FALSE)
  as.vector(so$rotF)
}

# test to see if it works before running
boot.fun(mod)

# run
booted.loads &lt;- boot.mirt(mod, boot.fun=boot.fun)
booted.loads


## End(Not run)
</code></pre>

<hr>
<h2 id='coef-method'>Extract raw coefs from model object</h2><span id='topic+coef-method'></span><span id='topic+coef+2CSingleGroupClass-method'></span><span id='topic+coef+2CMultipleGroupClass-method'></span><span id='topic+coef+2CMixedClass-method'></span><span id='topic+coef+2CDiscreteClass-method'></span><span id='topic+coef+2CMixtureClass-method'></span>

<h3>Description</h3>

<p>Return a list (or data.frame) of raw item and group level coefficients. Note that while
the output to the console is rounded to three digits, the returned list of objects is not.
Hence, elements from <code>cfs &lt;- coef(mod); cfs[[1]]</code> will contain the non-rounded results (useful
for simulations).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SingleGroupClass'
coef(
  object,
  CI = 0.95,
  printSE = FALSE,
  rotate = "none",
  Target = NULL,
  IRTpars = FALSE,
  rawug = FALSE,
  as.data.frame = FALSE,
  simplify = FALSE,
  unique = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef-method_+3A_object">object</code></td>
<td>
<p>an object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>MixedClass</code></p>
</td></tr>
<tr><td><code id="coef-method_+3A_ci">CI</code></td>
<td>
<p>the amount of converged used to compute confidence intervals; default is
95 percent confidence intervals</p>
</td></tr>
<tr><td><code id="coef-method_+3A_printse">printSE</code></td>
<td>
<p>logical; print the standard errors instead of the confidence intervals? When
<code>IRTpars = TRUE</code> then the delta method will be used to compute the associated standard errors
from mirt's default slope-intercept form</p>
</td></tr>
<tr><td><code id="coef-method_+3A_rotate">rotate</code></td>
<td>
<p>see <code>summary</code> method for details. The default rotation is <code>'none'</code></p>
</td></tr>
<tr><td><code id="coef-method_+3A_target">Target</code></td>
<td>
<p>a dummy variable matrix indicting a target rotation pattern</p>
</td></tr>
<tr><td><code id="coef-method_+3A_irtpars">IRTpars</code></td>
<td>
<p>logical; convert slope intercept parameters into traditional IRT parameters?
Only applicable to unidimensional models or models with simple structure (i.e., only one non-zero slope).
If a suitable ACOV estimate was computed in the fitted
model, and <code>printSE = FALSE</code>, then suitable CIs will be included based on the delta
method (where applicable)</p>
</td></tr>
<tr><td><code id="coef-method_+3A_rawug">rawug</code></td>
<td>
<p>logical; return the untransformed internal g and u parameters?
If <code>FALSE</code>, g and u's are converted with the original format along with delta standard errors</p>
</td></tr>
<tr><td><code id="coef-method_+3A_as.data.frame">as.data.frame</code></td>
<td>
<p>logical; convert list output to a data.frame instead?</p>
</td></tr>
<tr><td><code id="coef-method_+3A_simplify">simplify</code></td>
<td>
<p>logical; if all items have the same parameter names (indicating they are
of the same class) then they are collapsed to a matrix, and a list of length 2 is returned
containing a matrix of item parameters and group-level estimates</p>
</td></tr>
<tr><td><code id="coef-method_+3A_unique">unique</code></td>
<td>
<p>return the vector of uniquely estimated parameters</p>
</td></tr>
<tr><td><code id="coef-method_+3A_verbose">verbose</code></td>
<td>
<p>logical; allow information to be printed to the console?</p>
</td></tr>
<tr><td><code id="coef-method_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+summary-method">summary-method</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
dat &lt;- expand.table(LSAT7)
x &lt;- mirt(dat, 1)
coef(x)
coef(x, IRTpars = TRUE)
coef(x, simplify = TRUE)

#with computed information matrix
x &lt;- mirt(dat, 1, SE = TRUE)
coef(x)
coef(x, printSE = TRUE)
coef(x, as.data.frame = TRUE)

#two factors
x2 &lt;- mirt(Science, 2)
coef(x2)
coef(x2, rotate = 'varimax')


## End(Not run)
</code></pre>

<hr>
<h2 id='createGroup'>Create a user defined group-level object with correct generic functions</h2><span id='topic+createGroup'></span>

<h3>Description</h3>

<p>Initializes the proper S4 class and methods necessary for mirt functions to use in estimation for defining
customized group-level functions. To use the defined objects pass to the
<code>mirt(..., customGroup = OBJECT)</code> command, and ensure that the class parameters are properly labelled.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createGroup(
  par,
  est,
  den,
  nfact,
  standardize = FALSE,
  gr = NULL,
  hss = NULL,
  gen = NULL,
  lbound = NULL,
  ubound = NULL,
  derivType = "Richardson"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createGroup_+3A_par">par</code></td>
<td>
<p>a named vector of the starting values for the parameters</p>
</td></tr>
<tr><td><code id="createGroup_+3A_est">est</code></td>
<td>
<p>a logical vector indicating which parameters should be freely estimated by default</p>
</td></tr>
<tr><td><code id="createGroup_+3A_den">den</code></td>
<td>
<p>the probability density function given the Theta/ability values.
First input contains a vector of all the defined parameters and the second input
must be a matrix called <code>Theta</code>.
Function also must return a <code>numeric</code> vector object corresponding to the associated densities for
each row in the <code>Theta</code> input</p>
</td></tr>
<tr><td><code id="createGroup_+3A_nfact">nfact</code></td>
<td>
<p>number of factors required for the model. E.g., for unidimensional models with only one
dimension of integration <code>nfact = 1</code></p>
</td></tr>
<tr><td><code id="createGroup_+3A_standardize">standardize</code></td>
<td>
<p>logical; use standardization of the quadrature table method proposed by
Woods and Thissen (2006)? If TRUE, the logical elements named <code>'MEAN_1'</code> and <code>'COV_11'</code>
can be included in the parameter vector, and when these values are set to FALSE in the <code>est</code>
input the E-table will be standardized to these fixed values (e.g.,
<code>par &lt;- c(a1=1, d=0, MEAN_1=0, COV_11=1)</code> with <code>est &lt;- c(TRUE, TRUE, FALSE, FALSE)</code> will
standardize the E-table to have a 0 mean and unit variance)</p>
</td></tr>
<tr><td><code id="createGroup_+3A_gr">gr</code></td>
<td>
<p>gradient function (vector of first derivatives) of the log-likelihood used in
estimation. The function must be of the form <code>gr(x, Theta)</code>, where <code>x</code> is the object
defined by <code>createGroup()</code> and <code>Theta</code> is a matrix of latent trait parameters</p>
</td></tr>
<tr><td><code id="createGroup_+3A_hss">hss</code></td>
<td>
<p>Hessian function (matrix of second derivatives) of the log-likelihood used in
estimation. If not specified a numeric approximation will be used.
The input is identical to the <code>gr</code> argument</p>
</td></tr>
<tr><td><code id="createGroup_+3A_gen">gen</code></td>
<td>
<p>a function used when <code>GenRandomPars = TRUE</code> is passed to the estimation function
to generate random starting values. Function must be of the form <code>function(object) ...</code>
and must return a vector with properties equivalent to the <code>par</code> object. If NULL,
parameters will remain at the defined starting values by default</p>
</td></tr>
<tr><td><code id="createGroup_+3A_lbound">lbound</code></td>
<td>
<p>optional vector indicating the lower bounds of the parameters. If not specified
then the bounds will be set to -Inf</p>
</td></tr>
<tr><td><code id="createGroup_+3A_ubound">ubound</code></td>
<td>
<p>optional vector indicating the lower bounds of the parameters. If not specified
then the bounds will be set to Inf</p>
</td></tr>
<tr><td><code id="createGroup_+3A_derivtype">derivType</code></td>
<td>
<p>if the <code>gr</code> or <code>hss</code> terms are not specified this type will be used to
obtain them numerically. Default is 'Richardson'</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# normal density example, N(mu, sigma^2)
den &lt;- function(obj, Theta) dnorm(Theta, obj@par[1], sqrt(obj@par[2]))
par &lt;- c(mu = 0, sigma2 = .5)
est &lt;- c(FALSE, TRUE)
lbound &lt;- c(-Inf, 0)
grp &lt;- createGroup(par, est, den, nfact = 1, lbound=lbound)

dat &lt;- expand.table(LSAT6)
mod &lt;- mirt(dat, 1, 'Rasch')
modcustom &lt;- mirt(dat, 1, 'Rasch', customGroup=grp)

coef(mod)
coef(modcustom)

</code></pre>

<hr>
<h2 id='createItem'>Create a user defined item with correct generic functions</h2><span id='topic+createItem'></span>

<h3>Description</h3>

<p>Initializes the proper S4 class and methods necessary for <code><a href="#topic+mirt">mirt</a></code>
functions to use in estimation. To use the defined objects pass to the
<code>mirt(..., customItems = list())</code> command, and
ensure that the classes are properly labeled and unique in the list.
Additionally, the input <code>mirt(..., customItemsData = list())</code> can
also be included to specify additional item-level information to better
recycle custom-item definitions (e.g., for supplying varying
Q-matrices), where the <code>list</code> input must have the same length as the
number of items. For further examples regarding how this function can be
used for fitting unfolding-type models see Liu and Chalmers (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createItem(
  name,
  par,
  est,
  P,
  gr = NULL,
  hss = NULL,
  gen = NULL,
  lbound = NULL,
  ubound = NULL,
  derivType = "Richardson",
  derivType.hss = "Richardson",
  bytecompile = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createItem_+3A_name">name</code></td>
<td>
<p>a character indicating the item class name to be defined</p>
</td></tr>
<tr><td><code id="createItem_+3A_par">par</code></td>
<td>
<p>a named vector of the starting values for the parameters</p>
</td></tr>
<tr><td><code id="createItem_+3A_est">est</code></td>
<td>
<p>a logical vector indicating which parameters should be freely estimated by default</p>
</td></tr>
<tr><td><code id="createItem_+3A_p">P</code></td>
<td>
<p>the probability trace function for all categories (first column is category 1, second
category two, etc). First input contains a vector of all the item parameters, the second input
must be a matrix called <code>Theta</code>, the third input must be the number of categories
called <code>ncat</code>, and (optionally) a fourth argument termed <code>itemdata</code>
may be included containing further  users specification information.
The last optional input is to be utilized within the estimation functions
such as <code><a href="#topic+mirt">mirt</a></code> via the list input <code>customItemsData</code>
to more naturally recycle custom-item definitions. Therefore, these inputs must be of the form
</p>
<p><code>function(par, Theta, ncat){...}</code>
</p>
<p>or
</p>
<p><code>function(par, Theta, ncat, itemdata){...}</code>
</p>
<p>to be valid; however, the names of the arguements is not relavent.
</p>
<p>Finally, this function must return a <code>matrix</code> object of category probabilities, where
the columns represent each respective category</p>
</td></tr>
<tr><td><code id="createItem_+3A_gr">gr</code></td>
<td>
<p>gradient function (vector of first derivatives) of the log-likelihood used in
estimation. The function must be of the form <code>gr(x, Theta)</code>, where <code>x</code> is the object
defined by <code>createItem()</code> and <code>Theta</code> is a matrix of latent trait parameters.
Tabulated (EM) or raw (MHRM) data are located in the <code>x@dat</code> slot, and are used to form
the complete data log-likelihood. If not specified a numeric approximation will be used</p>
</td></tr>
<tr><td><code id="createItem_+3A_hss">hss</code></td>
<td>
<p>Hessian function (matrix of second derivatives) of the log-likelihood used in
estimation. If not specified a numeric approximation will be used (required for the MH-RM
algorithm only). The input is identical to the <code>gr</code> argument</p>
</td></tr>
<tr><td><code id="createItem_+3A_gen">gen</code></td>
<td>
<p>a function used when <code>GenRandomPars = TRUE</code> is passed to the estimation function
to generate random starting values. Function must be of the form <code>function(object) ...</code>
and must return a vector with properties equivalent to the <code>par</code> object. If NULL,
parameters will remain at the defined starting values by default</p>
</td></tr>
<tr><td><code id="createItem_+3A_lbound">lbound</code></td>
<td>
<p>optional vector indicating the lower bounds of the parameters. If not specified
then the bounds will be set to -Inf</p>
</td></tr>
<tr><td><code id="createItem_+3A_ubound">ubound</code></td>
<td>
<p>optional vector indicating the lower bounds of the parameters. If not specified
then the bounds will be set to Inf</p>
</td></tr>
<tr><td><code id="createItem_+3A_derivtype">derivType</code></td>
<td>
<p>if the <code>gr</code> term is not specified this type will be used to
obtain the gradient numerically or symbolically. Default is the 'Richardson'
extrapolation method; see <code><a href="#topic+numerical_deriv">numerical_deriv</a></code> for details and other options. If
<code>'symbolic'</code> is supplied then the gradient will be computed using
a symbolical approach (potentially the most accurate method, though may fail depending
on how the <code>P</code> function was defined)</p>
</td></tr>
<tr><td><code id="createItem_+3A_derivtype.hss">derivType.hss</code></td>
<td>
<p>if the <code>hss</code> term is not specified this type will be used to
obtain the Hessian numerically. Default is the 'Richardson'
extrapolation method; see <code><a href="#topic+numerical_deriv">numerical_deriv</a></code> for details and other options. If
<code>'symbolic'</code> is supplied then the Hessian will be computed using
a symbolical approach (potentially the most accurate method, though may fail depending
on how the <code>P</code> function was defined)</p>
</td></tr>
<tr><td><code id="createItem_+3A_bytecompile">bytecompile</code></td>
<td>
<p>logical; where applicable, byte compile the functions provided? Default is
<code>TRUE</code> to provide</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>summary()</code> function will not return proper standardized loadings
since the function is not sure how to handle them (no slopes could be
defined at all!). Instead loadings of .001 are filled in as place-holders.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Liu, C.-W. and Chalmers, R. P. (2018). Fitting item response unfolding models to
Likert-scale data using mirt in R. <em>PLoS ONE, 13</em>, 5.
<a href="https://doi.org/10.1371/journal.pone.0196292">doi:10.1371/journal.pone.0196292</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

name &lt;- 'old2PL'
par &lt;- c(a = .5, b = -2)
est &lt;- c(TRUE, TRUE)
P.old2PL &lt;- function(par,Theta, ncat){
     a &lt;- par[1]
     b &lt;- par[2]
     P1 &lt;- 1 / (1 + exp(-1*a*(Theta - b)))
     cbind(1-P1, P1)
}

x &lt;- createItem(name, par=par, est=est, P=P.old2PL)

# So, let's estimate it!
dat &lt;- expand.table(LSAT7)
sv &lt;- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x), pars = 'values')
tail(sv) #looks good
mod &lt;- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x))
coef(mod)
mod2 &lt;- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x), method = 'MHRM')
coef(mod2)

# same definition as above, but using symbolic derivative computations
# (can be more accurate/stable)
xs &lt;- createItem(name, par=par, est=est, P=P.old2PL, derivType = 'symbolic')
mod &lt;- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=xs))
coef(mod, simplify=TRUE)

# several secondary functions supported
M2(mod, calcNull=FALSE)
itemfit(mod)
fscores(mod, full.scores=FALSE)
plot(mod)

# fit the same model, but specify gradient function explicitly (use of a browser() may be helpful)
gr &lt;- function(x, Theta){
     # browser()
     a &lt;- x@par[1]
     b &lt;- x@par[2]
     P &lt;- probtrace(x, Theta)
     PQ &lt;- apply(P, 1, prod)
     r_P &lt;- x@dat / P
     grad &lt;- numeric(2)
     grad[2] &lt;- sum(-a * PQ * (r_P[,2] - r_P[,1]))
     grad[1] &lt;- sum((Theta - b) * PQ * (r_P[,2] - r_P[,1]))

     ## check with internal numerical form to be safe
     # numerical_deriv(x@par[x@est], mirt:::EML, obj=x, Theta=Theta)
     grad
}

x &lt;- createItem(name, par=par, est=est, P=P.old2PL, gr=gr)
mod &lt;- mirt(dat, 1, c(rep('2PL',4), 'old2PL'), customItems=list(old2PL=x))
coef(mod, simplify=TRUE)

### non-linear
name &lt;- 'nonlin'
par &lt;- c(a1 = .5, a2 = .1, d = 0)
est &lt;- c(TRUE, TRUE, TRUE)
P.nonlin &lt;- function(par,Theta, ncat=2){
     a1 &lt;- par[1]
     a2 &lt;- par[2]
     d &lt;- par[3]
     P1 &lt;- 1 / (1 + exp(-1*(a1*Theta + a2*Theta^2 + d)))
     cbind(1-P1, P1)
}

x2 &lt;- createItem(name, par=par, est=est, P=P.nonlin)

mod &lt;- mirt(dat, 1, c(rep('2PL',4), 'nonlin'), customItems=list(nonlin=x2))
coef(mod)

### nominal response model (Bock 1972 version)
Tnom.dev &lt;- function(ncat) {
   T &lt;- matrix(1/ncat, ncat, ncat - 1)
   diag(T[-1, ]) &lt;-  diag(T[-1, ]) - 1
   return(T)
}

name &lt;- 'nom'
par &lt;- c(alp=c(3,0,-3),gam=rep(.4,3))
est &lt;- rep(TRUE, length(par))
P.nom &lt;- function(par, Theta, ncat){
   alp &lt;- par[1:(ncat-1)]
   gam &lt;- par[ncat:length(par)]
   a &lt;- Tnom.dev(ncat) %*% alp
   c &lt;- Tnom.dev(ncat) %*% gam
   z &lt;- matrix(0, nrow(Theta), ncat)
   for(i in 1:ncat)
       z[,i] &lt;- a[i] * Theta + c[i]
   P &lt;- exp(z) / rowSums(exp(z))
   P
}

nom1 &lt;- createItem(name, par=par, est=est, P=P.nom)
nommod &lt;- mirt(Science, 1, 'nom1', customItems=list(nom1=nom1))
coef(nommod)
Tnom.dev(4) %*% coef(nommod)[[1]][1:3] #a
Tnom.dev(4) %*% coef(nommod)[[1]][4:6] #d


## End(Not run)
</code></pre>

<hr>
<h2 id='deAyala'>Description of deAyala data</h2><span id='topic+deAyala'></span>

<h3>Description</h3>

<p>Mathematics data from de Ayala (2009; pg. 14); 5 item dataset in table format.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>de Ayala, R. J. (2009). <em>The theory and practice of item response theory</em>. Guilford Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
dat &lt;- expand.table(deAyala)
head(dat)
itemstats(dat)


## End(Not run)
</code></pre>

<hr>
<h2 id='DIF'>Differential item functioning statistics</h2><span id='topic+DIF'></span>

<h3>Description</h3>

<p>This function runs the Wald and likelihood-ratio approaches for testing differential
item functioning (DIF) with two or more groups. This is primarily a convenience wrapper to the
<code><a href="#topic+multipleGroup">multipleGroup</a></code> function for performing standard DIF procedures. Independent
models can be estimated in parallel by defining a parallel object with <code><a href="#topic+mirtCluster">mirtCluster</a></code>,
which will help to decrease the runtime. For best results, the baseline model should contain
a set of 'anchor' items and have freely estimated hyper-parameters in the focal groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DIF(
  MGmodel,
  which.par,
  scheme = "add",
  items2test = 1:extract.mirt(MGmodel, "nitems"),
  groups2test = "all",
  seq_stat = "SABIC",
  Wald = FALSE,
  p.adjust = "none",
  pairwise = FALSE,
  return_models = FALSE,
  return_seq_model = FALSE,
  max_run = Inf,
  plotdif = FALSE,
  type = "trace",
  simplify = TRUE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DIF_+3A_mgmodel">MGmodel</code></td>
<td>
<p>an object returned from <code><a href="#topic+multipleGroup">multipleGroup</a></code> to be used as the reference
model</p>
</td></tr>
<tr><td><code id="DIF_+3A_which.par">which.par</code></td>
<td>
<p>a character vector containing the parameter names which will be inspected for
DIF</p>
</td></tr>
<tr><td><code id="DIF_+3A_scheme">scheme</code></td>
<td>
<p>type of DIF analysis to perform, either by adding or dropping constraints across
groups. These can be:
</p>

<dl>
<dt>'add'</dt><dd><p>parameters in <code>which.par</code> will be constrained each item one at a time for
items that are specified in <code>items2test</code>. This is beneficial when examining DIF from a
model with parameters freely estimated across groups, and when inspecting differences via
the Wald test</p>
</dd>
<dt>'drop'</dt><dd><p>parameters in <code>which.par</code> will be freely estimated for items that are
specified in <code>items2test</code>. This is useful when supplying an overly restrictive model
and attempting to detect DIF with a slightly less restrictive model</p>
</dd>
<dt>'add_sequential'</dt><dd><p>sequentially loop over the items being tested, and at the end of the
loop treat DIF tests that satisfy the <code>seq_stat</code> criteria as invariant. The loop is
then re-run on the remaining invariant items to determine if they are now displaying DIF in
the less constrained model, and when no new invariant item is found the algorithm stops and
returns the items that displayed DIF. Note that the DIF statistics are relative to this final,
less constrained model which includes the DIF effects</p>
</dd>
<dt>'drop_sequential'</dt><dd><p>sequentially loop over the items being tested, and at the end of the
loop treat items that violate the <code>seq_stat</code> criteria as demonstrating DIF. The loop is
then re-run, leaving the items that previously demonstrated DIF as variable across groups,
and the remaining test items that previously showed invariance are re-tested. The algorithm
stops when no more items showing DIF are found and returns the items that displayed DIF.
Note that the DIF statistics are relative to this final,
less constrained model which includes the DIF effects</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="DIF_+3A_items2test">items2test</code></td>
<td>
<p>a numeric vector, or character vector containing the item names, indicating
which items will be tested for DIF. In models where anchor items are known, omit them from
this vector. For example, if items 1 and 2 are anchors in a 10 item test, then
<code>items2test = 3:10</code> would work for testing the remaining items (important to remember
when using sequential schemes)</p>
</td></tr>
<tr><td><code id="DIF_+3A_groups2test">groups2test</code></td>
<td>
<p>a character vector indicating which groups to use in the DIF testing
investigations. Default is <code>'all'</code>, which uses all group information to perform
joint hypothesis tests of DIF (for a two group setup these result in pair-wise tests).
For example, if the group names were 'g1', 'g2' and 'g3', and DIF was only to be investigated
between group 'g1' and 'g3' then pass <code>groups2test = c('g1', 'g3')</code></p>
</td></tr>
<tr><td><code id="DIF_+3A_seq_stat">seq_stat</code></td>
<td>
<p>select a statistic to test for in the sequential schemes. Potential values are
(in descending order of power) <code>'AIC'</code>, <code>'SABIC'</code>, <code>'HQ'</code>, and <code>'BIC'</code>.
If a numeric value is input that ranges between 0 and 1, the 'p' value will be tested
(e.g., <code>seq_stat = .05</code> will test for the difference of p &lt; .05 in the add scheme,
or p &gt; .05 in the drop scheme), along with the specified <code>p.adjust</code> input</p>
</td></tr>
<tr><td><code id="DIF_+3A_wald">Wald</code></td>
<td>
<p>logical; perform Wald tests for DIF instead of likelihood ratio test?</p>
</td></tr>
<tr><td><code id="DIF_+3A_p.adjust">p.adjust</code></td>
<td>
<p>string to be passed to the <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> function to adjust p-values.
Adjustments are located in the <code>adj_p</code> element in the returned list</p>
</td></tr>
<tr><td><code id="DIF_+3A_pairwise">pairwise</code></td>
<td>
<p>logical; perform pairwise tests between groups when the number of groups
is greater than 2? Useful as quickly specified post-hoc tests</p>
</td></tr>
<tr><td><code id="DIF_+3A_return_models">return_models</code></td>
<td>
<p>logical; return estimated model objects for further analysis?
Default is FALSE</p>
</td></tr>
<tr><td><code id="DIF_+3A_return_seq_model">return_seq_model</code></td>
<td>
<p>logical; on the last iteration of the sequential schemes, return
the fitted multiple-group model containing the freely estimated parameters indicative of
DIF? This is generally only useful when <code>scheme = 'add_sequential'</code>. Default is FALSE</p>
</td></tr>
<tr><td><code id="DIF_+3A_max_run">max_run</code></td>
<td>
<p>a number indicating the maximum number of cycles to perform in sequential
searches. The default is to perform search until no further DIF is found</p>
</td></tr>
<tr><td><code id="DIF_+3A_plotdif">plotdif</code></td>
<td>
<p>logical; create item plots for items that are displaying DIF according to the
<code>seq_stat</code> criteria? Only available for 'add' type schemes</p>
</td></tr>
<tr><td><code id="DIF_+3A_type">type</code></td>
<td>
<p>the <code>type</code> of plot argument passed to <code>plot()</code>. Default is 'trace', though
another good option is 'infotrace'. For ease of viewing, the <code>facet_item</code> argument to
mirt's <code>plot()</code> function is set to <code>TRUE</code></p>
</td></tr>
<tr><td><code id="DIF_+3A_simplify">simplify</code></td>
<td>
<p>logical; simplify the output by returning a data.frame object with
the differences between AIC, BIC, etc, as well as the chi-squared test (X2) and associated
df and p-values</p>
</td></tr>
<tr><td><code id="DIF_+3A_verbose">verbose</code></td>
<td>
<p>logical print extra information to the console?</p>
</td></tr>
<tr><td><code id="DIF_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+multipleGroup">multipleGroup</a></code> and <code>plot</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Generally, the precomputed baseline model should have been
configured with two estimation properties: 1) a set of 'anchor' items,
where the anchor items have various parameters that have been constrained to be equal
across the groups, and 2) contain freely estimated latent mean and variance terms in
all but one group (the so-called 'reference' group).
These two properties help to fix the metric of the groups so that
item parameter estimates do not contain latent distribution characteristics.
</p>


<h3>Value</h3>

<p>a <code>mirt_df</code> object with the information-based criteria for DIF, though this may be changed
to a list output when <code>return_models</code> or <code>simplify</code> are modified. As well, a silent
<code>'DIF_coefficeints'</code> attribute is included to view the item parameter differences
between the groups
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P., Counsell, A., and Flora, D. B. (2016). It might not
make a big DIF: Improved Differential Test Functioning statistics that account for
sampling variability. <em>Educational and Psychological Measurement, 76</em>, 114-140.
<a href="https://doi.org/10.1177/0013164415584576">doi:10.1177/0013164415584576</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multipleGroup">multipleGroup</a></code>, <code><a href="#topic+DRF">DRF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# simulate data where group 2 has a smaller slopes and more extreme intercepts
set.seed(12345)
a1 &lt;- a2 &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d1 &lt;- d2 &lt;- matrix(rnorm(15,0,.7),ncol=1)
a2[1:2, ] &lt;- a1[1:2, ]/3
d1[c(1,3), ] &lt;- d2[c(1,3), ]/4
head(data.frame(a.group1 = a1, a.group2 = a2, d.group1 = d1, d.group2 = d2))
itemtype &lt;- rep('2PL', nrow(a1))
N &lt;- 1000
dataset1 &lt;- simdata(a1, d1, N, itemtype)
dataset2 &lt;- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5))
dat &lt;- rbind(dataset1, dataset2)
group &lt;- c(rep('D1', N), rep('D2', N))

#### no anchors, all items tested for DIF by adding item constrains one item at a time.
# define a parallel cluster (optional) to help speed up internal functions
if(interactive()) mirtCluster()

# Information matrix with Oakes' identity (not controlling for latent group differences)
# NOTE: Without properly equating the groups the following example code is not testing for DIF,
     # but instead reflects a combination of DIF + latent-trait distribution effects
model &lt;- multipleGroup(dat, 1, group, SE = TRUE)

# Likelihood-ratio test for DIF (as well as model information)
dif &lt;- DIF(model, c('a1', 'd'))
dif

# function silently includes "DIF_coefficients" attribute to view
# the IRT parameters post-completion
extract.mirt(dif, "DIF_coefficients")

# same as above, but using Wald tests with Benjamini &amp; Hochberg adjustment
DIF(model, c('a1', 'd'), Wald = TRUE, p.adjust = 'fdr')

# equate the groups by assuming the last 5 items have no DIF
itemnames &lt;- colnames(dat)
model &lt;- multipleGroup(dat, 1, group, SE = TRUE,
   invariance = c(itemnames[11:ncol(dat)], 'free_means', 'free_var'))

# test whether adding slopes and intercepts constraints results in DIF. Plot items showing DIF
resulta1d &lt;- DIF(model, c('a1', 'd'), plotdif = TRUE, items2test=1:10)
resulta1d

# test whether adding only slope constraints results in DIF for all items
DIF(model, 'a1', items2test=1:10)

# Determine whether it's a1 or d parameter causing DIF (could be joint, however)
(a1s &lt;- DIF(model, 'a1', items2test = 1:3))
(ds &lt;- DIF(model, 'd', items2test = 1:3))

### drop down approach (freely estimating parameters across groups) when
### specifying a highly constrained model with estimated latent parameters
model_constrained &lt;- multipleGroup(dat, 1, group,
  invariance = c(colnames(dat), 'free_means', 'free_var'))
dropdown &lt;- DIF(model_constrained, c('a1', 'd'), scheme = 'drop')
dropdown

# View silent "DIF_coefficients" attribute
extract.mirt(dropdown, "DIF_coefficients")

### sequential schemes (add constraints)

### sequential searches using SABIC as the selection criteria
# starting from completely different models
stepup &lt;- DIF(model, c('a1', 'd'), scheme = 'add_sequential',
              items2test=1:10)
stepup

# step down procedure for highly constrained model
stepdown &lt;- DIF(model_constrained, c('a1', 'd'), scheme = 'drop_sequential')
stepdown

# view final MG model (only useful when scheme is 'add_sequential')
updated_mod &lt;- DIF(model, c('a1', 'd'), scheme = 'add_sequential',
               return_seq_model=TRUE)
plot(updated_mod, type='trace')


###################################
# Multi-group example

a1 &lt;- a2 &lt;- a3 &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d1 &lt;- d2 &lt;- d3 &lt;- matrix(rnorm(15,0,.7),ncol=1)
a2[1:2, ] &lt;- a1[1:2, ]/3
d3[c(1,3), ] &lt;- d2[c(1,3), ]/4
head(data.frame(a.group1 = a1, a.group2 = a2, a.group3 = a3,
                d.group1 = d1, d.group2 = d2, d.group3 = d3))
itemtype &lt;- rep('2PL', nrow(a1))
N &lt;- 1000
dataset1 &lt;- simdata(a1, d1, N, itemtype)
dataset2 &lt;- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5))
dataset3 &lt;- simdata(a3, d3, N, itemtype, mu = .2)
dat &lt;- rbind(dataset1, dataset2, dataset3)
group &lt;- gl(3, N, labels = c('g1', 'g2', 'g3'))

# equate the groups by assuming the last 5 items have no DIF
itemnames &lt;- colnames(dat)
model &lt;- multipleGroup(dat, group=group, SE=TRUE,
   invariance = c(itemnames[11:ncol(dat)], 'free_means', 'free_var'))
coef(model, simplify=TRUE)

# omnibus tests
dif &lt;- DIF(model, which.par = c('a1', 'd'), items2test=1:9)
dif

# pairwise post-hoc tests for items flagged via omnibus tests
dif.posthoc &lt;- DIF(model, which.par = c('a1', 'd'), items2test=1:2,
                   pairwise = TRUE)
dif.posthoc

# further probing for df = 1 tests, this time with Wald tests
DIF(model, which.par = c('a1'), items2test=1:2, pairwise = TRUE,
    Wald=TRUE)
DIF(model, which.par = c('d'), items2test=1:2, pairwise = TRUE,
    Wald=TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='DiscreteClass-class'>Class &quot;DiscreteClass&quot;</h2><span id='topic+DiscreteClass-class'></span>

<h3>Description</h3>

<p>Defines the object returned from <code><a href="#topic+mdirt">mdirt</a></code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>Call</code>:</dt><dd><p>function call </p>
</dd>
<dt><code>Data</code>:</dt><dd><p>list of data, sometimes in different forms </p>
</dd>
<dt><code>Options</code>:</dt><dd><p>list of estimation options</p>
</dd>
<dt><code>Fit</code>:</dt><dd><p>a list of fit information </p>
</dd>
<dt><code>Model</code>:</dt><dd><p>a list of model-based information </p>
</dd>
<dt><code>ParObjects</code>:</dt><dd><p>a list of the S4 objects used during estimation</p>
</dd>
<dt><code>OptimInfo</code>:</dt><dd><p>a list of arguments from the optimization process</p>
</dd>
<dt><code>Internals</code>:</dt><dd><p>a list of internal arguments for secondary computations (inspecting this
object is generally not required)</p>
</dd>
<dt><code>vcov</code>:</dt><dd><p>a matrix represented the asymptotic covariance matrix of the parameter estimates</p>
</dd>
<dt><code>time</code>:</dt><dd><p>a data.frame indicating the breakdown of computation times in seconds</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>print</dt><dd><p><code>signature(x = "DiscreteClass")</code> </p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "DiscreteClass")</code> </p>
</dd>
<dt>anova</dt><dd><p><code>signature(object = "DiscreteClass")</code> </p>
</dd>
<dt>coef</dt><dd><p><code>signature(x = "DiscreteClass")</code> </p>
</dd>
<dt>summary</dt><dd><p><code>signature(object = "DiscreteClass")</code> </p>
</dd>
<dt>residuals</dt><dd><p><code>signature(object = "DiscreteClass")</code> </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>

<hr>
<h2 id='draw_parameters'>Draw plausible parameter instantiations from a given model</h2><span id='topic+draw_parameters'></span>

<h3>Description</h3>

<p>Draws plausible parameters from a model using parametric sampling (if the information matrix
was computed) or via bootstrap sampling. Primarily for use with the <code><a href="#topic+DRF">DRF</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>draw_parameters(
  mod,
  draws,
  method = c("parametric", "boostrap"),
  redraws = 20,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="draw_parameters_+3A_mod">mod</code></td>
<td>
<p>estimated single or multiple-group model</p>
</td></tr>
<tr><td><code id="draw_parameters_+3A_draws">draws</code></td>
<td>
<p>number of draws to obtain</p>
</td></tr>
<tr><td><code id="draw_parameters_+3A_method">method</code></td>
<td>
<p>type of plausible values to obtain. Can be 'parametric', for the parametric sampling
scheme which uses the estimated information matrix, or 'boostrap' to obtain values from the <code><a href="boot.html#topic+boot">boot</a></code>
function. Default is 'parametric'</p>
</td></tr>
<tr><td><code id="draw_parameters_+3A_redraws">redraws</code></td>
<td>
<p>number of redraws to perform when the given parameteric sample does not satisfy the
upper and lower parameter bounds. If a valid set cannot be found within this number of draws then
an error will be thrown</p>
</td></tr>
<tr><td><code id="draw_parameters_+3A_verbose">verbose</code></td>
<td>
<p>logical; include additional information in the console?</p>
</td></tr>
<tr><td><code id="draw_parameters_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>returns a draws x p matrix of plausible parameters, where each row correspeonds to a single
set
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(1234)
n &lt;- 40
N &lt;- 500

# only first 5 items as anchors
model &lt;- 'F = 1-40
          CONSTRAINB = (1-5, a1), (1-5, d)'

a &lt;- matrix(1, n)
d &lt;- matrix(rnorm(n), n)
group &lt;- c(rep('Group_1', N), rep('Group_2', N))

## -------------
# groups completely equal
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a, d, N, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2)
mod &lt;- multipleGroup(dat, model, group=group, SE=TRUE,
                     invariance=c('free_means', 'free_var'))

param_set &lt;- draw_parameters(mod, 100)
head(param_set)

## End(Not run)

</code></pre>

<hr>
<h2 id='DRF'>Differential Response Functioning statistics</h2><span id='topic+DRF'></span>

<h3>Description</h3>

<p>Function performs various omnibus differential item (DIF), bundle (DBF), and test (DTF)
functioning procedures on an object
estimated with <code>multipleGroup()</code>. The compensatory and non-compensatory statistics provided
are described in Chalmers (2018), which generally can be interpreted as IRT generalizations
of the SIBTEST and CSIBTEST statistics. For hypothesis tests, these measures
require the ACOV matrix to be computed in the
fitted multiple-group model (otherwise, sets of plausible draws from the posterior are explicitly
required).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DRF(
  mod,
  draws = NULL,
  focal_items = 1L:extract.mirt(mod, "nitems"),
  param_set = NULL,
  den.type = "marginal",
  best_fitting = FALSE,
  CI = 0.95,
  npts = 1000,
  quadpts = NULL,
  theta_lim = c(-6, 6),
  Theta_nodes = NULL,
  plot = FALSE,
  DIF = FALSE,
  DIF.cats = FALSE,
  groups2test = "all",
  pairwise = FALSE,
  simplify = TRUE,
  p.adjust = "none",
  par.strip.text = list(cex = 0.7),
  par.settings = list(strip.background = list(col = "#9ECAE1"), strip.border = list(col =
    "black")),
  auto.key = list(space = "right", points = FALSE, lines = TRUE),
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DRF_+3A_mod">mod</code></td>
<td>
<p>a multipleGroup object which estimated only 2 groups</p>
</td></tr>
<tr><td><code id="DRF_+3A_draws">draws</code></td>
<td>
<p>a number indicating how many draws to take to form a suitable multiple imputation
or bootstrap estimate of the expected test scores (100 or more). If <code>boot = FALSE</code>,
requires an estimated parameter information matrix. Returns a list containing the
bootstrap/imputation distribution and null hypothesis test for the sDRF statistics</p>
</td></tr>
<tr><td><code id="DRF_+3A_focal_items">focal_items</code></td>
<td>
<p>a character/numeric vector indicating which items to include in the DRF tests. The
default uses all of the items (note that including anchors in the focal items has no effect
because they are exactly equal across groups). Selecting fewer items will result in tests of
'differential bundle functioning'</p>
</td></tr>
<tr><td><code id="DRF_+3A_param_set">param_set</code></td>
<td>
<p>an N x p matrix of parameter values drawn from the posterior (e.g., using the
parametric sampling approach, bootstrap, of MCMC). If supplied, then these will be used to compute
the DRF measures. Can be much more efficient to pre-compute these values if DIF, DBF, or DTF are
being evaluated within the same model (especially when using the bootstrap method).
See <code><a href="#topic+draw_parameters">draw_parameters</a></code></p>
</td></tr>
<tr><td><code id="DRF_+3A_den.type">den.type</code></td>
<td>
<p>character specifying how the density of the latent traits is computed.
Default is <code>'marginal'</code> to include the proportional information from both groups,
<code>'focal'</code> for just the focal group, and <code>'reference'</code> for the reference group</p>
</td></tr>
<tr><td><code id="DRF_+3A_best_fitting">best_fitting</code></td>
<td>
<p>logical; use the best fitting parametric distribution (Gaussian by default)
that was used at the time of model estimation? This will result in much fast computations, however
the results are more dependent upon the underlying modelling assumptions. Default is FALSE, which
uses the empirical histogram approach</p>
</td></tr>
<tr><td><code id="DRF_+3A_ci">CI</code></td>
<td>
<p>range of confidence interval when using draws input</p>
</td></tr>
<tr><td><code id="DRF_+3A_npts">npts</code></td>
<td>
<p>number of points to use for plotting. Default is 1000</p>
</td></tr>
<tr><td><code id="DRF_+3A_quadpts">quadpts</code></td>
<td>
<p>number of quadrature nodes to use when constructing DRF statistics. Default is extracted from
the input model object</p>
</td></tr>
<tr><td><code id="DRF_+3A_theta_lim">theta_lim</code></td>
<td>
<p>lower and upper limits of the latent trait (theta) to be evaluated, and is
used in conjunction with <code>quadpts</code> and <code>npts</code></p>
</td></tr>
<tr><td><code id="DRF_+3A_theta_nodes">Theta_nodes</code></td>
<td>
<p>an optional matrix of Theta values to be evaluated in the draws for the
sDRF statistics. However, these values are not averaged across, and instead give the bootstrap
confidence intervals at the respective Theta nodes. Useful when following up a large
sDRF or uDRF statistic, for example, to determine where the difference between the test curves are large
(while still accounting for sampling variability). Returns a matrix with observed
variability</p>
</td></tr>
<tr><td><code id="DRF_+3A_plot">plot</code></td>
<td>
<p>logical; plot the 'sDRF' functions for the evaluated sDBF or sDTF values across the
integration grid or, if <code>DIF = TRUE</code>, the selected items as a faceted plot of individual items?
If plausible parameter sets were obtained/supplied then imputed confidence intervals will be included</p>
</td></tr>
<tr><td><code id="DRF_+3A_dif">DIF</code></td>
<td>
<p>logical; return a list of item-level imputation properties using the DRF statistics?
These can generally be used as a DIF detection method and as a graphical display for
understanding DIF within each item</p>
</td></tr>
<tr><td><code id="DRF_+3A_dif.cats">DIF.cats</code></td>
<td>
<p>logical; same as <code>DIF = TRUE</code>, however computations will
be performed on each item category probability functions rather than the score functions.
Only useful for understanding DIF in polytomous items</p>
</td></tr>
<tr><td><code id="DRF_+3A_groups2test">groups2test</code></td>
<td>
<p>when more than 2 groups are being investigated which two groups
should be used in the effect size comparisons?</p>
</td></tr>
<tr><td><code id="DRF_+3A_pairwise">pairwise</code></td>
<td>
<p>logical; perform pairwise computations when the applying to multi-group settings</p>
</td></tr>
<tr><td><code id="DRF_+3A_simplify">simplify</code></td>
<td>
<p>logical; attempt to simplify the output rather than returning larger lists?</p>
</td></tr>
<tr><td><code id="DRF_+3A_p.adjust">p.adjust</code></td>
<td>
<p>string to be passed to the <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> function to adjust p-values.
Adjustments are located in the <code>adj_pvals</code> element in the returned list. Only applicable when
<code>DIF = TRUE</code></p>
</td></tr>
<tr><td><code id="DRF_+3A_par.strip.text">par.strip.text</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="DRF_+3A_par.settings">par.settings</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="DRF_+3A_auto.key">auto.key</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="DRF_+3A_verbose">verbose</code></td>
<td>
<p>logical; include additional information in the console?</p>
</td></tr>
<tr><td><code id="DRF_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>lattice</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The effect sizes estimates by the DRF function are
</p>
<p style="text-align: center;"><code class="reqn">sDRF = \int [S(C|\bm{\Psi}^{(R)},\theta) S(C|\bm{\Psi}^{(F)},\theta)] f(\theta)d\theta,</code>
</p>

<p style="text-align: center;"><code class="reqn">uDRF = \int |S(C|\bm{\Psi}^{(R)},\theta) S(C|\bm{\Psi}^{(F)},\theta)| f(\theta)d\theta,</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">dDRF = \sqrt{\int [S(C|\bm{\Psi}^{(R)},\theta) S(C|\bm{\Psi}^{(F)},\theta)]^2 f(\theta)d\theta}</code>
</p>

<p>where <code class="reqn">S(.)</code> are the scoring equations used to evaluate the model-implied
difference between the focal and reference group. The <code class="reqn">f(\theta)</code>
terms can either be estimated from the posterior via an empirical
histogram approach (default), or can use the best
fitting prior distribution that is obtain post-convergence (default is a Guassian
distribution). Note that, in comparison to Chalmers (2018), the focal group is
the leftmost scoring function while the reference group is the rightmost
scoring function. This is largely to keep consistent with similar effect
size statistics, such as SIBTEST, DFIT, Wainer's measures of impact, etc,
which in general can be seen as special-case estimators of this family.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P. (2018). Model-Based Measures for Detecting and Quantifying Response Bias.
<em>Psychometrika, 83</em>(3), 696-732. <a href="https://doi.org/10.1007/s11336-018-9626-9">doi:10.1007/s11336-018-9626-9</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multipleGroup">multipleGroup</a></code>, <code><a href="#topic+DIF">DIF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

set.seed(1234)
n &lt;- 30
N &lt;- 500

# only first 5 items as anchors
model &lt;- 'F = 1-30
          CONSTRAINB = (1-5, a1), (1-5, d)'

a &lt;- matrix(1, n)
d &lt;- matrix(rnorm(n), n)
group &lt;- c(rep('Group_1', N), rep('Group_2', N))

## -------------
# groups completely equal
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a, d, N, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2)
mod &lt;- multipleGroup(dat, model, group=group, SE=TRUE,
                     invariance=c('free_means', 'free_var'))
plot(mod)
plot(mod, which.items = 6:10) #DBF
plot(mod, type = 'itemscore')
plot(mod, type = 'itemscore', which.items = 10:15)

# empirical histogram approach
DRF(mod)
DRF(mod, focal_items = 6:10) #DBF
DRF(mod, DIF=TRUE)
DRF(mod, DIF=TRUE, focal_items = 10:15)

# Best-fitting Gaussian distributions
DRF(mod, best_fitting=TRUE)
DRF(mod, focal_items = 6:10, best_fitting=TRUE) #DBF
DRF(mod, DIF=TRUE, best_fitting=TRUE)
DRF(mod, DIF=TRUE, focal_items = 10:15, best_fitting=TRUE)

DRF(mod, plot = TRUE)
DRF(mod, focal_items = 6:10, plot = TRUE) #DBF
DRF(mod, DIF=TRUE, plot = TRUE)
DRF(mod, DIF=TRUE, focal_items = 10:15, plot = TRUE)

if(interactive()) mirtCluster()
DRF(mod, draws = 500)
DRF(mod, draws = 500, best_fitting=TRUE)
DRF(mod, draws = 500, plot=TRUE)

# pre-draw parameter set to save computations
#  (more useful when using non-parametric bootstrap)
param_set &lt;- draw_parameters(mod, draws = 500)
DRF(mod, focal_items = 6, param_set=param_set) #DIF test
DRF(mod, DIF=TRUE, param_set=param_set) #DIF test
DRF(mod, focal_items = 6:10, param_set=param_set) #DBF test
DRF(mod, param_set=param_set) #DTF test

DRF(mod, focal_items = 6:10, draws=500) #DBF test
DRF(mod, focal_items = 10:15, draws=500) #DBF test

DIFs &lt;- DRF(mod, draws = 500, DIF=TRUE)
print(DIFs)
DRF(mod, draws = 500, DIF=TRUE, plot=TRUE)

DIFs &lt;- DRF(mod, draws = 500, DIF=TRUE, focal_items = 6:10)
print(DIFs)
DRF(mod, draws = 500, DIF=TRUE, focal_items = 6:10, plot = TRUE)

DRF(mod, DIF=TRUE, focal_items = 6)
DRF(mod, draws=500, DIF=TRUE, focal_items = 6)

# evaluate specific values for sDRF
Theta_nodes &lt;- matrix(seq(-6,6,length.out = 100))

sDTF &lt;- DRF(mod, Theta_nodes=Theta_nodes)
head(sDTF)
sDTF &lt;- DRF(mod, Theta_nodes=Theta_nodes, draws=200)
head(sDTF)

# sDIF (isolate single item)
sDIF &lt;- DRF(mod, Theta_nodes=Theta_nodes, focal_items=6)
head(sDIF)
sDIF &lt;- DRF(mod, Theta_nodes=Theta_nodes, focal_items = 6, draws=200)
head(sDIF)

## -------------
## random slopes and intercepts for 15 items, and latent mean difference
##    (no systematic DTF should exist, but DIF will be present)
set.seed(1234)
dat1 &lt;- simdata(a, d, N, itemtype = 'dich', mu=.50, sigma=matrix(1.5))
dat2 &lt;- simdata(a + c(numeric(15), rnorm(n-15, 0, .25)),
                d + c(numeric(15), rnorm(n-15, 0, .5)), N, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2)
mod1 &lt;- multipleGroup(dat, 1, group=group)
plot(mod1)
DRF(mod1) #does not account for group differences! Need anchors

mod2 &lt;- multipleGroup(dat, model, group=group, SE=TRUE,
                      invariance=c('free_means', 'free_var'))
plot(mod2)

# significant DIF in multiple items....
# DIF(mod2, which.par=c('a1', 'd'), items2test=16:30)
DRF(mod2)
DRF(mod2, draws=500) #non-sig DTF due to item cancellation

## -------------
## systematic differing slopes and intercepts (clear DTF)
set.seed(1234)
dat1 &lt;- simdata(a, d, N, itemtype = 'dich', mu=.50, sigma=matrix(1.5))
dat2 &lt;- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)),
                d + c(numeric(15), rnorm(n-15, 1, .5)),
                N, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2)
mod3 &lt;- multipleGroup(dat, model, group=group, SE=TRUE,
                      invariance=c('free_means', 'free_var'))
plot(mod3) #visable DTF happening

# DIF(mod3, c('a1', 'd'), items2test=16:30)
DRF(mod3) #unsigned bias. Signed bias (group 2 scores higher on average)
DRF(mod3, draws=500)
DRF(mod3, draws=500, plot=TRUE) #multiple DRF areas along Theta

# plot the DIF
DRF(mod3, draws=500, DIF=TRUE, plot=TRUE)

# evaluate specific values for sDRF
Theta_nodes &lt;- matrix(seq(-6,6,length.out = 100))
sDTF &lt;- DRF(mod3, Theta_nodes=Theta_nodes, draws=200)
head(sDTF)

# DIF
sDIF &lt;- DRF(mod3, Theta_nodes=Theta_nodes, focal_items = 30, draws=200)
car::some(sDIF)

## ----------------------------------------------------------------
# polytomous example
# simulate data where group 2 has a different slopes/intercepts
set.seed(4321)
a1 &lt;- a2 &lt;- matrix(rlnorm(20,.2,.3))
a2[c(16:17, 19:20),] &lt;- a1[c(16:17, 19:20),] + c(-.5, -.25, .25, .5)

# for the graded model, ensure that there is enough space between the intercepts,
# otherwise closer categories will not be selected often
diffs &lt;- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum))
diffs &lt;- -(diffs - rowMeans(diffs))
d1 &lt;- d2 &lt;- diffs + rnorm(20)
rownames(d1) &lt;- rownames(d2) &lt;- paste0('Item.', 1:20)
d2[16:20,] &lt;- d1[16:20,] + matrix(c(-.5, -.5, -.5, -.5,
                                    1, 0, 0, -1,
                                    .5, .5, -.5, -.5,
                                    1, .5, 0, -1,
                                    .5, .5, .5, .5), byrow=TRUE, nrow=5)

tail(data.frame(a.group1 = a1, a.group2 = a2), 6)
list(d.group1 = d1[15:20,], d.group2 = d2[15:20,])

itemtype &lt;- rep('graded', nrow(a1))
N &lt;- 600
dataset1 &lt;- simdata(a1, d1, N, itemtype)
dataset2 &lt;- simdata(a2, d2, N, itemtype, mu = -.25, sigma = matrix(1.25))
dat &lt;- rbind(dataset1, dataset2)
group &lt;- c(rep('D1', N), rep('D2', N))

# item 1-10 as anchors
mod &lt;- multipleGroup(dat, group=group, SE=TRUE,
                     invariance=c(colnames(dat)[1:10], 'free_means', 'free_var'))
coef(mod, simplify=TRUE)
plot(mod)
plot(mod, type='itemscore')

# DIF tests vis Wald method
DIF(mod, items2test=11:20,
   which.par=c('a1', paste0('d', 1:4)),
   Wald=TRUE, p.adjust='holm')

DRF(mod)
DRF(mod, DIF=TRUE, focal_items=11:20)
DRF(mod, DIF.cats=TRUE, focal_items=11:20)

## ----------------------------------------------------------------
### multidimensional DTF

set.seed(1234)
n &lt;- 50
N &lt;- 1000

# only first 5 items as anchors within each dimension
model &lt;- 'F1 = 1-25
          F2 = 26-50
          COV = F1*F2
          CONSTRAINB = (1-5, a1), (1-5, 26-30, d), (26-30, a2)'

a &lt;- matrix(c(rep(1, 25), numeric(50), rep(1, 25)), n)
d &lt;- matrix(rnorm(n), n)
group &lt;- c(rep('Group_1', N), rep('Group_2', N))
Cov &lt;- matrix(c(1, .5, .5, 1.5), 2)
Mean &lt;- c(0, 0.5)

# groups completely equal
dat1 &lt;- simdata(a, d, N, itemtype = 'dich', sigma = cov2cor(Cov))
dat2 &lt;- simdata(a, d, N, itemtype = 'dich', sigma = Cov, mu = Mean)
dat &lt;- rbind(dat1, dat2)
mod &lt;- multipleGroup(dat, model, group=group, SE=TRUE,
                     invariance=c('free_means', 'free_var'))
coef(mod, simplify=TRUE)
plot(mod, degrees = c(45,45))
DRF(mod)

# some intercepts slightly higher in Group 2
d2 &lt;- d
d2[c(10:15, 31:35)] &lt;- d2[c(10:15, 31:35)] + 1
dat1 &lt;- simdata(a, d, N, itemtype = 'dich', sigma = cov2cor(Cov))
dat2 &lt;- simdata(a, d2, N, itemtype = 'dich', sigma = Cov, mu = Mean)
dat &lt;- rbind(dat1, dat2)
mod &lt;- multipleGroup(dat, model, group=group, SE=TRUE,
                     invariance=c('free_means', 'free_var'))
coef(mod, simplify=TRUE)
plot(mod, degrees = c(45,45))

DRF(mod)
DRF(mod, draws = 500)


## End(Not run)
</code></pre>

<hr>
<h2 id='DTF'>Differential test functioning statistics</h2><span id='topic+DTF'></span>

<h3>Description</h3>

<p>Function performs various omnibus differential test functioning procedures on an object
estimated with <code>multipleGroup()</code>. If the latent means/covariances are suspected to differ
then the input object should contain a set of 'anchor' items to ensure that only differential
test features are being detected rather than group differences. Returns signed (average area
above and below) and unsigned (total area) statistics, with descriptives such as the percent
average bias between group total scores for each statistic. If a grid of Theta values is passed,
these can be evaluated as well to determine specific DTF location effects.  For best results,
the baseline model should contain a set of 'anchor' items and have freely estimated
hyper-parameters in the focal groups. See <code><a href="#topic+DIF">DIF</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DTF(
  mod,
  draws = NULL,
  CI = 0.95,
  npts = 1000,
  theta_lim = c(-6, 6),
  Theta_nodes = NULL,
  plot = "none",
  auto.key = list(space = "right", points = FALSE, lines = TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DTF_+3A_mod">mod</code></td>
<td>
<p>a multipleGroup object which estimated only 2 groups</p>
</td></tr>
<tr><td><code id="DTF_+3A_draws">draws</code></td>
<td>
<p>a number indicating how many draws to take to form a suitable multiple imputation
estimate of the expected test scores (usually 100 or more). Returns a list containing the
imputation distribution and null hypothesis test for the sDTF statistic</p>
</td></tr>
<tr><td><code id="DTF_+3A_ci">CI</code></td>
<td>
<p>range of confidence interval when using draws input</p>
</td></tr>
<tr><td><code id="DTF_+3A_npts">npts</code></td>
<td>
<p>number of points to use in the integration. Default is 1000</p>
</td></tr>
<tr><td><code id="DTF_+3A_theta_lim">theta_lim</code></td>
<td>
<p>lower and upper limits of the latent trait (theta) to be evaluated, and is
used in conjunction with <code>npts</code></p>
</td></tr>
<tr><td><code id="DTF_+3A_theta_nodes">Theta_nodes</code></td>
<td>
<p>an optional matrix of Theta values to be evaluated in the draws for the
sDTF statistic. However, these values are not averaged across, and instead give the bootstrap
confidence intervals at the respective Theta nodes. Useful when following up a large
uDTF/sDTF statistic to determine where the difference between the test curves are large
(while still accounting for sampling variability). Returns a matrix with observed
variability</p>
</td></tr>
<tr><td><code id="DTF_+3A_plot">plot</code></td>
<td>
<p>a character vector indicating which plot to draw. Possible values are 'none',
'func' for the test score functions, and 'sDTF' for the evaluated sDTF values across the
integration grid. Each plot is drawn with imputed confidence envelopes</p>
</td></tr>
<tr><td><code id="DTF_+3A_auto.key">auto.key</code></td>
<td>
<p>logical; automatically generate key in lattice plot?</p>
</td></tr>
<tr><td><code id="DTF_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>lattice</code> and <code>boot</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P., Counsell, A., and Flora, D. B. (2016). It might not
make a big DIF: Improved Differential Test Functioning statistics that account for
sampling variability. <em>Educational and Psychological Measurement, 76</em>, 114-140.
<a href="https://doi.org/10.1177/0013164415584576">doi:10.1177/0013164415584576</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+multipleGroup">multipleGroup</a></code>, <code><a href="#topic+DIF">DIF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1234)
n &lt;- 30
N &lt;- 500

# only first 5 items as anchors
model &lt;- 'F = 1-30
          CONSTRAINB = (1-5, a1), (1-5, d)'

a &lt;- matrix(1, n)
d &lt;- matrix(rnorm(n), n)
group &lt;- c(rep('Group_1', N), rep('Group_2', N))

## -------------
# groups completely equal
dat1 &lt;- simdata(a, d, N, itemtype = '2PL')
dat2 &lt;- simdata(a, d, N, itemtype = '2PL')
dat &lt;- rbind(dat1, dat2)
mod &lt;- multipleGroup(dat, model, group=group, SE=TRUE,
                     invariance=c('free_means', 'free_var'))
plot(mod)

DTF(mod)
if(interactive()) mirtCluster()
DTF(mod, draws = 1000) #95% C.I. for sDTF containing 0. uDTF is very small
DTF(mod, draws = 1000, plot='sDTF') #sDTF 95% C.I.'s across Theta always include 0

## -------------
## random slopes and intercepts for 15 items, and latent mean difference
##    (no systematic DTF should exist, but DIF will be present)
set.seed(1234)
dat1 &lt;- simdata(a, d, N, itemtype = '2PL', mu=.50, sigma=matrix(1.5))
dat2 &lt;- simdata(a + c(numeric(15), runif(n-15, -.2, .2)),
                d + c(numeric(15), runif(n-15, -.5, .5)), N, itemtype = '2PL')
dat &lt;- rbind(dat1, dat2)
mod1 &lt;- multipleGroup(dat, 1, group=group)
plot(mod1) #does not account for group differences! Need anchors

mod2 &lt;- multipleGroup(dat, model, group=group, SE=TRUE,
                      invariance=c('free_means', 'free_var'))
plot(mod2)

# significant DIF in multiple items....
# DIF(mod2, which.par=c('a1', 'd'), items2test=16:30)
DTF(mod2)
DTF(mod2, draws=1000) #non-sig DTF due to item cancellation

## -------------
## systematic differing slopes and intercepts (clear DTF)
dat1 &lt;- simdata(a, d, N, itemtype = '2PL', mu=.50, sigma=matrix(1.5))
dat2 &lt;- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)), d + c(numeric(15), rnorm(n-15, 1, .5)),
                N, itemtype = '2PL')
dat &lt;- rbind(dat1, dat2)
mod3 &lt;- multipleGroup(dat, model, group=group, SE=TRUE,
                      invariance=c('free_means', 'free_var'))
plot(mod3) #visable DTF happening

# DIF(mod3, c('a1', 'd'), items2test=16:30)
DTF(mod3) #unsigned bias. Signed bias indicates group 2 scores generally higher on average
DTF(mod3, draws=1000)
DTF(mod3, draws=1000, plot='func')
DTF(mod3, draws=1000, plot='sDTF') #multiple DTF areas along Theta

# evaluate specific values for sDTF
Theta_nodes &lt;- matrix(seq(-6,6,length.out = 100))
sDTF &lt;- DTF(mod3, Theta_nodes=Theta_nodes)
head(sDTF)
sDTF &lt;- DTF(mod3, Theta_nodes=Theta_nodes, draws=100)
head(sDTF)


## End(Not run)
</code></pre>

<hr>
<h2 id='empirical_ES'>Empirical effect sizes based on latent trait estimates</h2><span id='topic+empirical_ES'></span>

<h3>Description</h3>

<p>Computes effect size measures of differential item functioning and differential
test/bundle functioning based on expected scores from Meade (2010).
Item parameters from both reference and focal group are used in conjunction with
focal group empirical theta estimates (and an assumed normally distributed theta)
to compute expected scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>empirical_ES(
  mod,
  Theta.focal = NULL,
  focal_items = 1L:extract.mirt(mod, "nitems"),
  DIF = TRUE,
  npts = 61,
  theta_lim = c(-6, 6),
  plot = FALSE,
  type = "b",
  par.strip.text = list(cex = 0.7),
  par.settings = list(strip.background = list(col = "#9ECAE1"), strip.border = list(col =
    "black")),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="empirical_ES_+3A_mod">mod</code></td>
<td>
<p>a multipleGroup object which estimated only 2 groups. The first group in this object
is assumed to be the reference group by default (i.e., <code>ref.group = 1</code>), which conforms to the
<code>invariance</code> arguments in <code><a href="#topic+multipleGroup">multipleGroup</a></code></p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_theta.focal">Theta.focal</code></td>
<td>
<p>an optional matrix of Theta values from the focal group to be evaluated. If not supplied
the default values to <code><a href="#topic+fscores">fscores</a></code> will be used in conjunction with the <code>...</code>
arguments passed</p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_focal_items">focal_items</code></td>
<td>
<p>a numeric vector indicating which items to include the tests. The
default uses all of the items. Selecting fewer items will result in tests of
'differential bundle functioning' when <code>DIF = FALSE</code></p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_dif">DIF</code></td>
<td>
<p>logical; return a data.frame of item-level imputation properties? If <code>FALSE</code>,
only DBF and DTF statistics will be reported</p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_npts">npts</code></td>
<td>
<p>number of points to use in the integration. Default is 61</p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_theta_lim">theta_lim</code></td>
<td>
<p>lower and upper limits of the latent trait (theta) to be evaluated, and is
used in conjunction with <code>npts</code></p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_plot">plot</code></td>
<td>
<p>logical; plot expected scores of items/test where expected scores are computed
using focal group thetas and both focal and reference group item parameters</p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_type">type</code></td>
<td>
<p>type of objects to draw in <code>lattice</code>; default plots both points and lines</p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_par.strip.text">par.strip.text</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_par.settings">par.settings</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="empirical_ES_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="#topic+fscores">fscores</a></code> and <code><a href="lattice.html#topic+xyplot">xyplot</a></code></p>
</td></tr>
</table>


<h3>DIF</h3>

<p>The default <code>DIF = TRUE</code> produces several effect sizes indices at the item level.
Signed indices allow DIF favoring the focal group at one point on the theta
distribution to cancel DIF favoring the reference group at another point on the theta
distribution. Unsigned indices take the absolute value before summing or averaging,
thus not allowing cancellation of DIF across theta.
</p>

<dl>
<dt>SIDS</dt><dd><p>Signed Item Difference in the Sample. The average difference in expected scores
across the focal sample using both focal and reference group item parameters.</p>
</dd>
<dt>UIDS</dt><dd><p>Unsigned Item Difference in the Sample. Same as SIDS except absolute value of
expected scores is taken prior to averaging across the sample.</p>
</dd>
<dt>D-Max</dt><dd><p>The maximum difference in expected scores in the sample.</p>
</dd>
<dt>ESSD</dt><dd><p>Expected Score Standardized Difference. Cohen's D for difference in expected scores.</p>
</dd>
<dt>SIDN</dt><dd><p>Signed Item Difference in a Normal distribution. Identical to SIDS but
averaged across a normal distribution rather than the sample.</p>
</dd>
<dt>UIDN</dt><dd><p>Unsigned Item Difference in a Normal distribution. Identical to UIDS but
averaged across a normal distribution rather than the sample.</p>
</dd>
</dl>



<h3>DBF/DTF</h3>

<p><code>DIF = FALSE</code> produces a series of test/bundle-level indices that are based on item-level
indices.
</p>

<dl>
<dt>STDS</dt><dd><p>Signed Test Differences in the Sample. The sum of the SIDS across items.</p>
</dd>
<dt>UTDS</dt><dd><p>Unsigned Test Differences in the Sample. The sum of the UIDS across items.</p>
</dd>
<dt>Stark's DTFR</dt><dd><p>Stark's version of STDS using a normal distribution rather than
sample estimated thetas.</p>
</dd>
<dt>UDTFR</dt><dd><p>Unsigned Expected Test Scores Differences in the Sample. The difference
in observed summed scale scores expected, on average, across a hypothetical focal
group with a normally distributed theta, had DF been uniform in nature for all items</p>
</dd>
<dt>UETSDS</dt><dd><p>Unsigned Expected Test Score Differences in the Sample.
The hypothetical difference expected scale scores that would have been present if
scale-level DF had been uniform across respondents (i.e., always favoring the
focal group).</p>
</dd>
<dt>UETSDN</dt><dd><p>Identical to UETSDS but computed using a normal distribution.</p>
</dd>
<dt>Test D-Max</dt><dd><p>Maximum expected test score differences in the sample.</p>
</dd>
<dt>ETSSD</dt><dd><p>Expected Test Score Standardized Difference. Cohen's D for expected
test scores.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Adam Meade, with contributions by Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Meade, A. W. (2010). A taxonomy of effect size measures for the differential functioning
of items and scales. <em>Journal of Applied Psychology, 95</em>, 728-743.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# no DIF
set.seed(12345)
a &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d &lt;- matrix(rnorm(15,0,.7),ncol=1)
itemtype &lt;- rep('2PL', nrow(a))
N &lt;- 1000
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5))
dat &lt;- rbind(dataset1, dataset2)

# ensure 'Ref' is the first group (and therefore reference group during estimation)
group &lt;- factor(c(rep('Ref', N), rep('Focal', N)), levels = c('Ref', 'Focal'))

mod &lt;- multipleGroup(dat, 1, group = group,
   invariance = c(colnames(dat)[1:5], 'free_means', 'free_var'))
coef(mod, simplify=TRUE)

empirical_ES(mod)
empirical_ES(mod, DIF=FALSE)
empirical_ES(mod, DIF=FALSE, focal_items = 10:15)

empirical_ES(mod, plot=TRUE)
empirical_ES(mod, plot=TRUE, DIF=FALSE)

###---------------------------------------------
# DIF
set.seed(12345)
a1 &lt;- a2 &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d1 &lt;- d2 &lt;- matrix(rnorm(15,0,.7),ncol=1)
a2[10:15,] &lt;- a2[10:15,] + rnorm(6, 0, .3)
d2[10:15,] &lt;- d2[10:15,] + rnorm(6, 0, .3)
itemtype &lt;- rep('dich', nrow(a1))
N &lt;- 1000
dataset1 &lt;- simdata(a1, d1, N, itemtype)
dataset2 &lt;- simdata(a2, d2, N, itemtype, mu = .1, sigma = matrix(1.5))
dat &lt;- rbind(dataset1, dataset2)
group &lt;- factor(c(rep('Ref', N), rep('Focal', N)), levels = c('Ref', 'Focal'))

mod &lt;- multipleGroup(dat, 1, group = group,
   invariance = c(colnames(dat)[1:5], 'free_means', 'free_var'))
coef(mod, simplify=TRUE)

empirical_ES(mod)
empirical_ES(mod, DIF = FALSE)
empirical_ES(mod, plot=TRUE)
empirical_ES(mod, plot=TRUE, DIF=FALSE)


## End(Not run)
</code></pre>

<hr>
<h2 id='empirical_plot'>Function to generate empirical unidimensional item and test plots</h2><span id='topic+empirical_plot'></span>

<h3>Description</h3>

<p>Given a dataset containing item responses this function will construct empirical graphics
using the observed responses to each item conditioned on the total score. When individual
item plots are requested then the total score will be formed without the item of interest
(i.e., the total score without that item).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>empirical_plot(
  data,
  which.items = NULL,
  type = "prop",
  smooth = FALSE,
  formula = resp ~ s(TS, k = 5),
  main = NULL,
  par.strip.text = list(cex = 0.7),
  par.settings = list(strip.background = list(col = "#9ECAE1"), strip.border = list(col =
    "black")),
  auto.key = list(space = "right", points = FALSE, lines = TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="empirical_plot_+3A_data">data</code></td>
<td>
<p>a <code>data.frame</code> or <code>matrix</code> of item responses (see <code><a href="#topic+mirt">mirt</a></code>
for typical input)</p>
</td></tr>
<tr><td><code id="empirical_plot_+3A_which.items">which.items</code></td>
<td>
<p>a numeric vector indicating which items to plot in a faceted image plot.
If NULL then empirical test plots will be constructed instead</p>
</td></tr>
<tr><td><code id="empirical_plot_+3A_type">type</code></td>
<td>
<p>character vector specifying type of plot to draw. When <code>which.item</code> is NULL
can be 'prop' (default) or 'hist', otherwise can be 'prop' (default) or 'boxplot'</p>
</td></tr>
<tr><td><code id="empirical_plot_+3A_smooth">smooth</code></td>
<td>
<p>logical; include a GAM smoother instead of the raw proportions? Default is FALSE</p>
</td></tr>
<tr><td><code id="empirical_plot_+3A_formula">formula</code></td>
<td>
<p>formula used for the GAM smoother</p>
</td></tr>
<tr><td><code id="empirical_plot_+3A_main">main</code></td>
<td>
<p>the main title for the plot. If NULL an internal default will be used</p>
</td></tr>
<tr><td><code id="empirical_plot_+3A_par.strip.text">par.strip.text</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="empirical_plot_+3A_par.settings">par.settings</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="empirical_plot_+3A_auto.key">auto.key</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="empirical_plot_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="lattice.html#topic+lattice">lattice</a></code> and <code>coef()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that these types of plots should only be used for unidimensional
tests with monotonically increasing item
response functions. If monotonicity is not true for all items, however, then these plots may
serve as a visual diagnostic tool so long as the majority of items are indeed monotonic.
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemstats">itemstats</a></code>, <code><a href="#topic+itemplot">itemplot</a></code>, <code><a href="#topic+itemGAM">itemGAM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

SAT12[SAT12 == 8] &lt;- NA
data &lt;- key2binary(SAT12,
   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))

# test plot
empirical_plot(data)
empirical_plot(data, type = 'hist')
empirical_plot(data, type = 'hist', breaks=20)

# items 1, 2 and 5
empirical_plot(data, c(1, 2, 5))
empirical_plot(data, c(1, 2, 5), smooth = TRUE)
empirical_plot(data, c(1, 2, 5), type = 'boxplot')

# replace weird looking items with unscored versions for diagnostics
empirical_plot(data, 32)
data[,32] &lt;- SAT12[,32]
empirical_plot(data, 32)
empirical_plot(data, 32, smooth = TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='empirical_rxx'>Function to calculate the empirical (marginal) reliability</h2><span id='topic+empirical_rxx'></span>

<h3>Description</h3>

<p>Given secondary latent trait estimates and their associated standard errors
returned from <code><a href="#topic+fscores">fscores</a></code>, compute the empirical reliability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>empirical_rxx(Theta_SE, T_as_X = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="empirical_rxx_+3A_theta_se">Theta_SE</code></td>
<td>
<p>a matrix of latent trait estimates returned from <code><a href="#topic+fscores">fscores</a></code> with the options
<code>full.scores = TRUE</code> and <code>full.scores.SE = TRUE</code></p>
</td></tr>
<tr><td><code id="empirical_rxx_+3A_t_as_x">T_as_X</code></td>
<td>
<p>logical; should the observed variance be equal to
<code>var(X) = var(T) + E(E^2)</code> or <code>var(X) = var(T)</code> when computing
empirical reliability estimates? Default (<code>FALSE</code>) uses the former</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fscores">fscores</a></code>, <code><a href="#topic+marginal_rxx">marginal_rxx</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

dat &lt;- expand.table(deAyala)
itemstats(dat)
mod &lt;- mirt(dat)

theta_se &lt;- fscores(mod, full.scores.SE = TRUE)
empirical_rxx(theta_se)

theta_se &lt;- fscores(mod, full.scores.SE = TRUE, method = 'ML')
empirical_rxx(theta_se)
empirical_rxx(theta_se, T_as_X = TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='estfun.AllModelClass'>Extract Empirical Estimating Functions</h2><span id='topic+estfun.AllModelClass'></span>

<h3>Description</h3>

<p>A function for extracting the empirical estimating functions of a fitted
<code><a href="#topic+mirt">mirt</a></code>, <code><a href="#topic+multipleGroup">multipleGroup</a></code> or <code><a href="#topic+bfactor">bfactor</a></code>
model. This is the derivative of the log-likelihood with respect to the
parameter vector, evaluated at the observed (case-wise) data. In other
words, this function returns the case-wise scores, evaluated at the fitted
model parameters. Currently, models fitted via the <code>EM</code> or <code>BL</code>
method are supported. For the computations, the internal <code>Theta</code> grid of
the model is being used which was already used during the estimation of
the model itself along with its matching normalized density.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>estfun.AllModelClass(
  x,
  weights = extract.mirt(x, "survey.weights"),
  centering = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="estfun.AllModelClass_+3A_x">x</code></td>
<td>
<p>a fitted model object of class <code>SingleGroupClass</code> or
<code>MultipleGroupClass</code></p>
</td></tr>
<tr><td><code id="estfun.AllModelClass_+3A_weights">weights</code></td>
<td>
<p>by default, the <code>survey.weights</code> which were (optionally)
specified when fitting the model are included to calculate the scores.
If specified by the user, this should be a numeric vector of length equal
to the total sample size. Note that if not all cases were weighted equally
when fitting the model, the weights must be corrected by taking their
square root if the scores are being used to compute the outer product of
gradients (OPG) estimate of the variance-covariance matrix (see examples
below).</p>
</td></tr>
<tr><td><code id="estfun.AllModelClass_+3A_centering">centering</code></td>
<td>
<p>a boolean variable that allows the centering of the case-wise
scores (i.e., setting their expected values to 0). If the case-wise scores were
obtained from maximum likelihood estimates, this setting does not affect the result.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An n x k matrix corresponding to n observations and k parameters
</p>


<h3>Author(s)</h3>

<p>Lennart Schneider <a href="mailto:lennart.sch@web.de">lennart.sch@web.de</a>; centering argument contributed by Rudolf Debelak (<a href="mailto:rudolf.debelak@psychologie.uzh.ch">rudolf.debelak@psychologie.uzh.ch</a>)
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mirt">mirt</a></code>, <code><a href="#topic+multipleGroup">multipleGroup</a></code>,
<code><a href="#topic+bfactor">bfactor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# fit a 2PL on the LSAT7 data and get the scores
mod1 &lt;- mirt(expand.table(LSAT7), 1, SE = TRUE, SE.type = "crossprod")
sc1 &lt;- estfun.AllModelClass(mod1)
# get the gradient
colSums(sc1)
# calculate the OPG estimate of the variance-covariance matrix "by hand"
vc1 &lt;- vcov(mod1)
all.equal(crossprod(sc1), chol2inv(chol(vc1)), check.attributes = FALSE)

# fit a multiple group 2PL and do the same as above
group &lt;- rep(c("G1", "G2"), 500)
mod2 &lt;- multipleGroup(expand.table(LSAT7), 1, group, SE = TRUE,
  SE.type = "crossprod")
sc2 &lt;- estfun.AllModelClass(mod2)
colSums(sc2)
vc2 &lt;- vcov(mod2)
all.equal(crossprod(sc2), chol2inv(chol(vc2)), check.attributes = FALSE)

# fit a bifactor model with 2 specific factors and do the same as above
mod3 &lt;- bfactor(expand.table(LSAT7), c(2, 2, 1, 1, 2), SE = TRUE,
  SE.type = "crossprod")
sc3 &lt;- estfun.AllModelClass(mod3)
colSums(sc3)
vc3 &lt;- vcov(mod3)
all.equal(crossprod(sc3), chol2inv(chol(vc3)), check.attributes = FALSE)

# fit a 2PL not weighting all cases equally
survey.weights &lt;- c(rep(2, sum(LSAT7$freq) / 2), rep(1, sum(LSAT7$freq) / 2))
survey.weights &lt;- survey.weights / sum(survey.weights) * sum(LSAT7$freq)
mod4 &lt;- mirt(expand.table(LSAT7), 1, SE = TRUE, SE.type = "crossprod",
  survey.weights = survey.weights)
sc4 &lt;- estfun.AllModelClass(mod4,
  weights = extract.mirt(mod4, "survey.weights"))
# get the gradient
colSums(sc4)
# to calculate the OPG estimate of the variance-covariance matrix "by hand",
# the weights must be adjusted by taking their square root
sc4_crp &lt;- estfun.AllModelClass(mod4,
  weights = sqrt(extract.mirt(mod4, "survey.weights")))
vc4 &lt;- vcov(mod4)
all.equal(crossprod(sc4_crp), chol2inv(chol(vc4)), check.attributes = FALSE)


## End(Not run)
</code></pre>

<hr>
<h2 id='expand.table'>Expand summary table of patterns and frequencies</h2><span id='topic+expand.table'></span>

<h3>Description</h3>

<p>The <code>expand.table</code> function expands a summary table of unique response
patterns to a full sized data-set. By default the response frequencies are
assumed to be on rightmost column of the input data, though this can be modified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand.table(tabdata, freq = colnames(tabdata)[ncol(tabdata)], sample = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expand.table_+3A_tabdata">tabdata</code></td>
<td>
<p>An object of class <code>data.frame</code> or <code>matrix</code>
with the unique response patterns and the number of frequencies
in the rightmost column (though see <code>freq</code> for details on how to omit this
column)</p>
</td></tr>
<tr><td><code id="expand.table_+3A_freq">freq</code></td>
<td>
<p>either a character vector specifying the column in <code>tabdata</code>
to be used as the frequency count indicator for each response pattern (defaults to
the right-most column) or a integer vector of length <code>nrow(tabdata)</code> specifying
the frequency counts. When using the latter approach the <code>tabdata</code> input should not
include any information regarding the counts, and instead should only include the unique
response patterns themselves</p>
</td></tr>
<tr><td><code id="expand.table_+3A_sample">sample</code></td>
<td>
<p>logical; randomly switch the rows in the expanded table? This does not change the
expanded data, only the row locations</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric matrix with all the response patterns.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(LSAT7)
head(LSAT7) # frequency in right-most column
LSAT7full &lt;- expand.table(LSAT7)
head(LSAT7full)
dim(LSAT7full)

# randomly switch rows in the expanded response table
LSAT7samp &lt;- expand.table(LSAT7, sample = TRUE)
head(LSAT7samp)
colMeans(LSAT7full)
colMeans(LSAT7samp) #equal

#--------

## Not run: 
# Generate data from separate response pattern matrix and freq vector
# The following uses Table 2.1 from de Ayala (2009)
f &lt;- c(691,2280,242,235,158,184,1685,1053,134,462,92,65,571,79,87,41,1682,702,
       370,63,626,412,166,52,28,15,2095,1219,500,187,40,3385)

pat &lt;- matrix(c(
   0, 0, 0, 0, 0,
   1, 0, 0, 0, 0,
   0, 1, 0, 0, 0,
   0, 0, 1, 0, 0,
   0, 0, 0, 1, 0,
   0, 0, 0, 0, 1,
   1, 1, 0, 0, 0,
   1, 0, 1, 0, 0,
   0, 1, 1, 0, 0,
   1, 0, 0, 1, 0,
   0, 1, 0, 1, 0,
   0, 0, 1, 1, 0,
   1, 0, 0, 0, 1,
   0, 1, 0, 0, 1,
   0, 0, 1, 0, 1,
   0, 0, 0, 1, 1,
   1, 1, 1, 0, 0,
   1, 1, 0, 1, 0,
   1, 0, 1, 1, 0,
   0, 1, 1, 1, 0,
   1, 1, 0, 0, 1,
   1, 0, 1, 0, 1,
   1, 0, 0, 1, 1,
   0, 1, 1, 0, 1,
   0, 1, 0, 1, 1,
   0, 0, 1, 1, 1,
   1, 1, 1, 1, 0,
   1, 1, 1, 0, 1,
   1, 1, 0, 1, 1,
   1, 0, 1, 1, 1,
   0, 1, 1, 1, 1,
   1, 1, 1, 1, 1), ncol=5, byrow=TRUE)

colnames(pat) &lt;- paste0('Item.', 1:5)
head(pat)

table2.1 &lt;- expand.table(pat, freq = f)
dim(table2.1)


## End(Not run)


</code></pre>

<hr>
<h2 id='expected.item'>Function to calculate expected value of item</h2><span id='topic+expected.item'></span>

<h3>Description</h3>

<p>Given an internal mirt object extracted from an estimated model
compute the expected value for an item given the ability parameter(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expected.item(x, Theta, min = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expected.item_+3A_x">x</code></td>
<td>
<p>an extracted internal mirt object containing item information (see <code><a href="#topic+extract.item">extract.item</a></code>)</p>
</td></tr>
<tr><td><code id="expected.item_+3A_theta">Theta</code></td>
<td>
<p>a vector (unidimensional) or matrix (multidimensional) of latent trait values</p>
</td></tr>
<tr><td><code id="expected.item_+3A_min">min</code></td>
<td>
<p>a constant value added to the expected values indicating the lowest theoretical
category. Default is 0</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract.item">extract.item</a></code>, <code><a href="#topic+expected.test">expected.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mod &lt;- mirt(Science, 1)
extr.2 &lt;- extract.item(mod, 2)
Theta &lt;- matrix(seq(-6,6, length.out=200))
expected &lt;- expected.item(extr.2, Theta, min(Science[,1])) #min() of first item
head(data.frame(expected, Theta=Theta))

</code></pre>

<hr>
<h2 id='expected.test'>Function to calculate expected test score</h2><span id='topic+expected.test'></span>

<h3>Description</h3>

<p>Given an estimated model compute the expected test score. Returns the expected values in the
same form as the data used to estimate the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expected.test(
  x,
  Theta,
  group = NULL,
  mins = TRUE,
  individual = FALSE,
  which.items = NULL,
  probs.only = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expected.test_+3A_x">x</code></td>
<td>
<p>an estimated mirt object</p>
</td></tr>
<tr><td><code id="expected.test_+3A_theta">Theta</code></td>
<td>
<p>a matrix of latent trait values</p>
</td></tr>
<tr><td><code id="expected.test_+3A_group">group</code></td>
<td>
<p>a number or character signifying which group the item should be extracted from
(applies to 'MultipleGroupClass' objects only)</p>
</td></tr>
<tr><td><code id="expected.test_+3A_mins">mins</code></td>
<td>
<p>logical; include the minimum value constants in the dataset. If FALSE, the
expected values for each item are determined from the scoring 0:(ncat-1)</p>
</td></tr>
<tr><td><code id="expected.test_+3A_individual">individual</code></td>
<td>
<p>logical; return tracelines for individual items?</p>
</td></tr>
<tr><td><code id="expected.test_+3A_which.items">which.items</code></td>
<td>
<p>an integer vector indicating which items to include in the expected test score. Default
uses all possible items</p>
</td></tr>
<tr><td><code id="expected.test_+3A_probs.only">probs.only</code></td>
<td>
<p>logical; return the probability for each category instead of
traceline score functions? Only useful when <code>individual=TRUE</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+expected.item">expected.item</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
dat &lt;- expand.table(deAyala)
model &lt;- 'F = 1-5
          CONSTRAIN = (1-5, a1)'
mod &lt;- mirt(dat, model)

Theta &lt;- matrix(seq(-6,6,.01))
tscore &lt;- expected.test(mod, Theta)
tail(cbind(Theta, tscore))

# use only first two items (i.e., a bundle)
bscore &lt;- expected.test(mod, Theta, which.items = 1:2)
tail(cbind(Theta, bscore))

# more low-level output (score and probabilty elements)
expected.test(mod, Theta, individual=TRUE)
expected.test(mod, Theta, individual=TRUE, probs.only=TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='extract.group'>Extract a group from a multiple group mirt object</h2><span id='topic+extract.group'></span>

<h3>Description</h3>

<p>Extract a single group from an object defined by <code><a href="#topic+multipleGroup">multipleGroup</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract.group(x, group)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract.group_+3A_x">x</code></td>
<td>
<p>mirt model of class 'MultipleGroupClass'</p>
</td></tr>
<tr><td><code id="extract.group_+3A_group">group</code></td>
<td>
<p>the name of the group to extract</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract.item">extract.item</a></code>, <code><a href="#topic+extract.mirt">extract.mirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(12345)
a &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d &lt;- matrix(rnorm(15,0,.7),ncol=1)
itemtype &lt;- rep('2PL', nrow(a))
N &lt;- 1000
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5))
dat &lt;- rbind(dataset1, dataset2)
group &lt;- c(rep('D1', N), rep('D2', N))
models &lt;- 'F1 = 1-15'

mod_configural &lt;- multipleGroup(dat, models, group = group)
group.1 &lt;- extract.group(mod_configural, 'D1') #extract first group
summary(group.1)
plot(group.1)

## End(Not run)
</code></pre>

<hr>
<h2 id='extract.item'>Extract an item object from mirt objects</h2><span id='topic+extract.item'></span>

<h3>Description</h3>

<p>Extract the internal mirt objects from any estimated model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract.item(x, item, group = NULL, drop.zeros = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract.item_+3A_x">x</code></td>
<td>
<p>mirt model of class 'SingleGroupClass' or 'MultipleGroupClass'</p>
</td></tr>
<tr><td><code id="extract.item_+3A_item">item</code></td>
<td>
<p>a number or character signifying which item to extract</p>
</td></tr>
<tr><td><code id="extract.item_+3A_group">group</code></td>
<td>
<p>a number signifying which group the item should be extracted from (applies to
'MultipleGroupClass' only)</p>
</td></tr>
<tr><td><code id="extract.item_+3A_drop.zeros">drop.zeros</code></td>
<td>
<p>logical; drop slope values that are numerically close to zero to reduce
dimensionality? Useful in objects returned from <code><a href="#topic+bfactor">bfactor</a></code> or other confirmatory
models that contain several zero slopes</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract.group">extract.group</a></code>, <code><a href="#topic+extract.mirt">extract.mirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
mod &lt;- mirt(Science, 1)
extr.1 &lt;- extract.item(mod, 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='extract.mirt'>Extract various elements from estimated model objects</h2><span id='topic+extract.mirt'></span>

<h3>Description</h3>

<p>A generic function to extract the internal objects from estimated models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract.mirt(x, what)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract.mirt_+3A_x">x</code></td>
<td>
<p>mirt model of class 'SingleGroupClass', 'MultipleGroupClass', 'MixedClass' or
'DiscreteGroupClass'</p>
</td></tr>
<tr><td><code id="extract.mirt_+3A_what">what</code></td>
<td>
<p>a string indicating what to extract</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Objects which can be extracted from mirt objects include:
</p>

<dl>
<dt>logLik</dt><dd><p>observed log-likelihood</p>
</dd>
<dt>logPrior</dt><dd><p>log term contributed by prior parameter distributions</p>
</dd>
<dt>G2</dt><dd><p>goodness of fit statistic</p>
</dd>
<dt>df</dt><dd><p>degrees of freedom</p>
</dd>
<dt>p</dt><dd><p>p-value for G2 statistic</p>
</dd>
<dt>RMSEA</dt><dd><p>root mean-square error of approximation based on G2</p>
</dd>
<dt>CFI</dt><dd><p>CFI fit statistic</p>
</dd>
<dt>TLI</dt><dd><p>TLI fit statistic</p>
</dd>
<dt>AIC</dt><dd><p>AIC</p>
</dd>
<dt>BIC</dt><dd><p>BIC</p>
</dd>
<dt>SABIC</dt><dd><p>sample size adjusted BIC</p>
</dd>
<dt>HQ</dt><dd><p>HQ</p>
</dd>
<dt>F</dt><dd><p>unrotated standardized loadings matrix</p>
</dd>
<dt>h2</dt><dd><p>factor communality estimates</p>
</dd>
<dt>LLhistory</dt><dd><p>EM log-likelihood history</p>
</dd>
<dt>tabdata</dt><dd><p>a tabular version of the raw response data input. Frequencies are stored
in <code>freq</code></p>
</dd>
<dt>freq</dt><dd><p>frequencies associated with <code>tabdata</code></p>
</dd>
<dt>K</dt><dd><p>an integer vector indicating the number of unique elements for each item</p>
</dd>
<dt>mins</dt><dd><p>an integer vector indicating the lowest category found in the input <code>data</code></p>
</dd>
<dt>model</dt><dd><p>input model syntax</p>
</dd>
<dt>method</dt><dd><p>estimation method used</p>
</dd>
<dt>itemtype</dt><dd><p>a vector of item types for each respective item (e.g., 'graded', '2PL', etc)</p>
</dd>
<dt>itemnames</dt><dd><p>a vector of item names from the input data</p>
</dd>
<dt>factorNames</dt><dd><p>a vector of factor names from the model definition</p>
</dd>
<dt>rowID</dt><dd><p>an integer vector indicating all valid row numbers used in the model estimation
(when all cases are used this will be <code>1:nrow(data)</code>)</p>
</dd>
<dt>data</dt><dd><p>raw input data of item responses</p>
</dd>
<dt>covdata</dt><dd><p>raw input data of data used as covariates</p>
</dd>
<dt>tabdatalong</dt><dd><p>similar to <code>tabdata</code>, however the responses have been transformed into
dummy coded variables</p>
</dd>
<dt>fulldatalong</dt><dd><p>analogous to <code>tabdatafull</code>, but for the raw input data instead of the
tabulated frequencies</p>
</dd>
<dt>EMhistory</dt><dd><p>if saved, extract the EM iteration history</p>
</dd>
<dt>exp_resp</dt><dd><p>expected probability of the unique response patterns</p>
</dd>
<dt>survey.weights</dt><dd><p>if supplied, the vector of survey weights used during estimation (NULL if missing)</p>
</dd>
<dt>converged</dt><dd><p>a logical value indicating whether the model terminated within
the convergence criteria</p>
</dd>
<dt>iterations</dt><dd><p>number of iterations it took to reach the convergence criteria</p>
</dd>
<dt>nest</dt><dd><p>number of freely estimated parameters</p>
</dd>
<dt>parvec</dt><dd><p>vector containing uniquely estimated parameters</p>
</dd>
<dt>vcov</dt><dd><p>parameter covariance matrix (associated with parvec)</p>
</dd>
<dt>condnum</dt><dd><p>the condition number of the Hessian (if computed). Otherwise NA</p>
</dd>
<dt>constrain</dt><dd><p>a list of item parameter constraints to indicate which item parameters were equal
during estimation</p>
</dd>
<dt>Prior</dt><dd><p>prior density distribution for the latent traits</p>
</dd>
<dt>thetaPosterior</dt><dd><p>posterior distribution for latent traits when using EM algorithm</p>
</dd>
<dt>key</dt><dd><p>if supplied, the data scoring key</p>
</dd>
<dt>nfact</dt><dd><p>number of latent traits/factors</p>
</dd>
<dt>nitems</dt><dd><p>number of items</p>
</dd>
<dt>ngroups</dt><dd><p>number of groups</p>
</dd>
<dt>groupNames</dt><dd><p>character vector of unique group names</p>
</dd>
<dt>group</dt><dd><p>a character vector indicating the group membership</p>
</dd>
<dt>invariance</dt><dd><p>a character vector indicating <code>invariance</code> input from <code><a href="#topic+multipleGroup">multipleGroup</a></code></p>
</dd>
<dt>secondordertest</dt><dd><p>a logical indicating whether the model passed the second-order test
based on the Hessian matrix. Indicates whether model is a potential local maximum solution</p>
</dd>
<dt>SEMconv</dt><dd><p>logical; check whether the supplemented EM information matrix converged. Will be <code>NA</code>
if not applicable</p>
</dd>
<dt>time</dt><dd><p>estimation time, broken into different sections</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract.group">extract.group</a></code>, <code><a href="#topic+extract.item">extract.item</a></code>, <code><a href="#topic+mod2values">mod2values</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
mod &lt;- mirt(Science, 1)

extract.mirt(mod, 'logLik')
extract.mirt(mod, 'F')

#multiple group model
grp &lt;- rep(c('G1', 'G2'), each = nrow(Science)/2)
mod2 &lt;- multipleGroup(Science, 1, grp)

grp1 &lt;- extract.group(mod2, 1) #extract single group model
extract.mirt(mod2, 'parvec')
extract.mirt(grp1, 'parvec')


## End(Not run)
</code></pre>

<hr>
<h2 id='fixedCalib'>Fixed-item calibration method</h2><span id='topic+fixedCalib'></span>

<h3>Description</h3>

<p>Implements the set of fixed-item calibration methods described by Kim (2006). The initial
calibrated model must be fitted via <code><a href="#topic+mirt">mirt</a></code>, is currently limited to
unidimensional models only, and should only be utilized when the new set of responses
are obtained from a population with similar distributional characteristics in the latent traits.
For more flexible calibration of items, including a fixed-item calibration variant involving
anchor items for equating, see <code><a href="#topic+multipleGroup">multipleGroup</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixedCalib(
  data,
  model = 1,
  old_mod,
  PAU = "MWU",
  NEMC = "MEM",
  technical = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixedCalib_+3A_data">data</code></td>
<td>
<p>new data to be used for calibration. Note that to be consistent
with the <code>mod</code> object, observed responses/NA placeholders must be included
to link the item names used in the original <code>mod</code> definition
(i.e., <code>extract.mirt(mod, what = 'itemnames')</code>)</p>
</td></tr>
<tr><td><code id="fixedCalib_+3A_model">model</code></td>
<td>
<p>type of model to fit for the complete dataset (not that for the fixed items
in <code>old_mod</code> the factor loadings/constraints specified by the potential <code><a href="#topic+mirt.model">mirt.model</a></code>
specification is not relevant)</p>
</td></tr>
<tr><td><code id="fixedCalib_+3A_old_mod">old_mod</code></td>
<td>
<p>a model of class SingleGroupClass fitted using <code><a href="#topic+mirt">mirt</a></code></p>
</td></tr>
<tr><td><code id="fixedCalib_+3A_pau">PAU</code></td>
<td>
<p>prior ability update (PAU) approach. Supports none (<code>"NWU"</code>),
one (<code>"OWU"</code>), and many (<code>"MWU"</code>)</p>
</td></tr>
<tr><td><code id="fixedCalib_+3A_nemc">NEMC</code></td>
<td>
<p>number of EM cycles (NEMC) to use for the to-be-estimated parameters.
Supports one (<code>"OEM"</code>) and many (<code>"MEM"</code>)</p>
</td></tr>
<tr><td><code id="fixedCalib_+3A_technical">technical</code></td>
<td>
<p>list of technical estimation arguments
(see <code><a href="#topic+mirt">mirt</a></code> for details)</p>
</td></tr>
<tr><td><code id="fixedCalib_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="#topic+mirt">mirt</a></code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Kim, S. (2006). A comparative study of IRT fixed parameter calibration methods.
<em>Journal of Educational Measurement, 4</em>(43), 355-381.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mirt">mirt</a></code>, <code><a href="#topic+multipleGroup">multipleGroup</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# single factor
set.seed(12345)
J &lt;- 50
a &lt;- matrix(abs(rnorm(J,1,.3)), ncol=1)
d &lt;- matrix(rnorm(J,0,.7),ncol=1)
itemtype &lt;- rep('2PL', nrow(a))

# calibration data theta ~ N(0,1)
N &lt;- 3000
dataset1 &lt;- simdata(a, d, N = N, itemtype=itemtype)

# new data (again, theta ~ N(0,1))
dataset2 &lt;- simdata(a, d, N = 1000, itemtype=itemtype)

# last 40% of experimental items not given to calibration group
#     (unobserved; hence removed)
dataset1 &lt;- dataset1[,-c(J:(J*.6))]
head(dataset1)

#--------------------------------------

# calibrated model from dataset1 only
mod &lt;- mirt(dataset1, model = 1)
coef(mod, simplify=TRUE)

# No Prior Weights Updating and One EM Cycle (NWU-OEM)
NWU_OEM &lt;- fixedCalib(dataset2, model=1, old_mod=mod, PAU='NWU', NEMC='OEM')
coef(NWU_OEM, simplify=TRUE)
data.frame(coef(NWU_OEM, simplify=TRUE)$items[,c('a1','d')],
           pop_a1=a, pop_d=d)
plot(NWU_OEM, type = 'empiricalhist')

# No Prior Weights Updating and Multiple EM Cycles (NWU-MEM)
NWU_MEM &lt;- fixedCalib(dataset2, model = 1, old_mod = mod, PAU = 'NWU')
coef(NWU_MEM, simplify=TRUE)
data.frame(coef(NWU_MEM, simplify=TRUE)$items[,c('a1','d')],
           pop_a1=a, pop_d=d)
plot(NWU_MEM, type = 'empiricalhist')

# One Prior Weights Updating and One EM Cycle (OWU-OEM)
OWU_OEM &lt;- fixedCalib(dataset2, model=1, old_mod=mod, PAU='OWU', NEMC="OEM")
coef(OWU_OEM, simplify=TRUE)
data.frame(coef(OWU_OEM, simplify=TRUE)$items[,c('a1','d')], pop_a1=a, pop_d=d)
plot(OWU_OEM, type = 'empiricalhist')

# One Prior Weights Updating and Multiple EM Cycles (OWU-MEM)
OWU_MEM &lt;- fixedCalib(dataset2, model = 1, old_mod = mod, PAU = 'OWU')
coef(OWU_MEM, simplify=TRUE)
data.frame(coef(OWU_MEM, simplify=TRUE)$items[,c('a1','d')],
           pop_a1=a, pop_d=d)
plot(OWU_MEM, type = 'empiricalhist')

# Multiple Prior Weights Updating and Multiple EM Cycles (MWU-MEM)
MWU_MEM &lt;- fixedCalib(dataset2, model = 1, old_mod = mod)
coef(MWU_MEM, simplify=TRUE)
data.frame(coef(MWU_MEM, simplify=TRUE)$items[,c('a1','d')],
           pop_a1=a, pop_d=d)
plot(MWU_MEM, type = 'empiricalhist')

# factor scores distribution check
fs &lt;- fscores(MWU_MEM)
hist(fs)
c(mean_calib=mean(fs[1:N, ]), sd_calib=sd(fs[1:N, ]))
c(mean_exper=mean(fs[-c(1:N), ]), sd_exper=sd(fs[-c(1:N), ]))


############################
## Item length constraint example for each participant in the experimental
## items group. In this example, all participants were forced to have a test
## length of J=30, though the item pool had J=50 total items.

# new experimental data (relatively extreme, theta ~ N(.5,1.5))
dataset2 &lt;- simdata(a, d, N = 1000, itemtype=itemtype,
    mu=.5, sigma=matrix(1.5))

# Add missing values to each participant in new dataset where individuals
# were randomly administered 10 experimental items, subject to the constraint
# that each participant received a test with J=30 items.
dataset2 &lt;- t(apply(dataset2, 1, function(x){
   NA_precalib &lt;- sample(1:30, 10)
   NA_experimental &lt;- sample(31:50, 10)
   x[c(NA_precalib, NA_experimental)] &lt;- NA
   x
}))
head(dataset2)

# check that all individuals had 30 items
all(rowSums(!is.na(dataset2)) == 30)

# Multiple Prior Weights Updating and Multiple EM Cycles (MWU-MEM)
MWU_MEM &lt;- fixedCalib(dataset2, model = 1, old_mod = mod)
coef(MWU_MEM, simplify=TRUE)
data.frame(coef(MWU_MEM, simplify=TRUE)$items[,c('a1','d')],
           pop_a1=a, pop_d=d)
plot(MWU_MEM, type = 'empiricalhist')

## factor scores check
fs &lt;- fscores(MWU_MEM)
hist(fs)
c(mean_calib=mean(fs[1:N, ]), sd_calib=sd(fs[1:N, ]))

## shrinkage, but generally different from calibrated sample
c(mean_exper=mean(fs[-c(1:N), ]), sd_exper=sd(fs[-c(1:N), ]))



## End(Not run)
</code></pre>

<hr>
<h2 id='fixef'>Compute latent regression fixed effect expected values</h2><span id='topic+fixef'></span>

<h3>Description</h3>

<p>Create expected values for fixed effects parameters in latent regression models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixef(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixef_+3A_x">x</code></td>
<td>
<p>an estimated model object from the <code><a href="#topic+mixedmirt">mixedmirt</a></code> or <code><a href="#topic+mirt">mirt</a></code>
function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models with the MH-RM Algorithm.
<em>Journal of Educational Measurement, 52</em>, 200-222. <a href="https://doi.org/10.1111/jedm.12072">doi:10.1111/jedm.12072</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mirt">mirt</a></code>, <code><a href="#topic+mixedmirt">mixedmirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

#simulate data
set.seed(1234)
N &lt;- 1000

# covariates
X1 &lt;- rnorm(N); X2 &lt;- rnorm(N)
covdata &lt;- data.frame(X1, X2)
Theta &lt;- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))

#items and response data
a &lt;- matrix(1, 20); d &lt;- matrix(rnorm(20))
dat &lt;- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)

#conditional model using X1 and X2 as predictors of Theta
mod1 &lt;- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2)

#latent regression fixed effects (i.e., expected values)
fe &lt;- fixef(mod1)
head(fe)

# with mixedmirt()
mod1b &lt;- mixedmirt(dat, covdata, 1, lr.fixed = ~ X1 + X2, fixed = ~ 0 + items)
fe2 &lt;- fixef(mod1b)
head(fe2)


## End(Not run)
</code></pre>

<hr>
<h2 id='fscores'>Compute factor score estimates (a.k.a, ability estimates, latent trait estimates, etc)</h2><span id='topic+fscores'></span>

<h3>Description</h3>

<p>Computes MAP, EAP, ML (Embretson &amp; Reise, 2000), EAP for sum-scores (Thissen et al., 1995),
or WLE (Warm, 1989) factor scores with a multivariate normal
prior distribution using equally spaced quadrature. EAP scores for models with more than
three factors are generally not recommended since the integration grid becomes very large,
resulting in slower estimation and less precision if the <code>quadpts</code> are too low.
Therefore, MAP scores should be used instead of EAP scores for higher dimensional models.
Multiple imputation variants are possible for each estimator if a parameter
information matrix was computed, which are useful if the sample size/number of items were small.
As well, if the model contained latent regression predictors this information will
be used in computing MAP and EAP estimates (for these models, <code>full.scores=TRUE</code>
will always be used). Finally, plausible value imputation is also available, and will also account
for latent regression predictor effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fscores(
  object,
  method = "EAP",
  full.scores = TRUE,
  rotate = "oblimin",
  Target = NULL,
  response.pattern = NULL,
  append_response.pattern = FALSE,
  na.rm = FALSE,
  plausible.draws = 0,
  plausible.type = "normal",
  quadpts = NULL,
  item_weights = rep(1, extract.mirt(object, "nitems")),
  returnER = FALSE,
  T_as_X = FALSE,
  return.acov = FALSE,
  mean = NULL,
  cov = NULL,
  covdata = NULL,
  verbose = TRUE,
  full.scores.SE = FALSE,
  theta_lim = c(-6, 6),
  MI = 0,
  use_dentype_estimate = FALSE,
  QMC = FALSE,
  custom_den = NULL,
  custom_theta = NULL,
  min_expected = 1,
  max_theta = 20,
  start = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fscores_+3A_object">object</code></td>
<td>
<p>a computed model object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>DiscreteClass</code></p>
</td></tr>
<tr><td><code id="fscores_+3A_method">method</code></td>
<td>
<p>type of factor score estimation method. Can be:
</p>

<ul>
<li> <p><code>"EAP"</code> for the expected a-posteriori (default). For models fit using
<code><a href="#topic+mdirt">mdirt</a></code> this will return the posterior classification probabilities
</p>
</li>
<li> <p><code>"MAP"</code> for the maximum a-posteriori (i.e, Bayes modal)
</p>
</li>
<li> <p><code>"ML"</code> for maximum likelihood
</p>
</li>
<li> <p><code>"WLE"</code> for weighted likelihood estimation
</p>
</li>
<li> <p><code>"EAPsum"</code> for the expected a-posteriori for each sum score
</p>
</li>
<li> <p><code>"plausible"</code> for a single plausible value imputation for each case.
This is equivalent to setting <code>plausible.draws = 1</code>
</p>
</li>
<li> <p><code>"classify"</code> for the posteriori classification probabilities (only
applicable when the input model was of class <code>MixtureClass</code>)
</p>
</li></ul>
</td></tr>
<tr><td><code id="fscores_+3A_full.scores">full.scores</code></td>
<td>
<p>if <code>FALSE</code> then a summary table with factor scores
for each unique pattern is displayed as a formatted <code>matrix</code> object.
Otherwise, a matrix of factor scores for each response pattern in the data
is returned (default)</p>
</td></tr>
<tr><td><code id="fscores_+3A_rotate">rotate</code></td>
<td>
<p>prior rotation to be used when estimating the factor scores. See
<code><a href="#topic+summary-method">summary-method</a></code> for details. If the object is not an exploratory model
then this argument is ignored</p>
</td></tr>
<tr><td><code id="fscores_+3A_target">Target</code></td>
<td>
<p>target rotation; see <code><a href="#topic+summary-method">summary-method</a></code> for details</p>
</td></tr>
<tr><td><code id="fscores_+3A_response.pattern">response.pattern</code></td>
<td>
<p>an optional argument used to calculate the factor scores and standard
errors for a given response vector or matrix/data.frame</p>
</td></tr>
<tr><td><code id="fscores_+3A_append_response.pattern">append_response.pattern</code></td>
<td>
<p>logical; should the inputs from <code>response.pattern</code> also be
appended to the factor score output?</p>
</td></tr>
<tr><td><code id="fscores_+3A_na.rm">na.rm</code></td>
<td>
<p>logical; remove rows with any missing values? This is generally not required due to
the nature of computing factors scores, however for the &quot;EAPsum&quot; method this may be necessary
to ensure that the sum-scores correspond to the same composite score</p>
</td></tr>
<tr><td><code id="fscores_+3A_plausible.draws">plausible.draws</code></td>
<td>
<p>number of plausible values to draw for future researchers
to perform secondary analyses of the latent trait scores. Typically used in conjunction
with latent regression predictors (see <code><a href="#topic+mirt">mirt</a></code> for details), but can
also be generated when no predictor variables were modelled. If <code>plausible.draws</code>
is greater than 0 a list of plausible values will be returned</p>
</td></tr>
<tr><td><code id="fscores_+3A_plausible.type">plausible.type</code></td>
<td>
<p>type of plausible values to obtain. Can be either <code>'normal'</code> (default)
to use a normal approximation based on the ACOV matrix, or <code>'MH'</code> to obtain Metropolis-Hastings
samples from the posterior (silently passes object to <code><a href="#topic+mirt">mirt</a></code>, therefore arguments like
<code>technical</code> can be supplied to increase the number of burn-in draws and discarded samples)</p>
</td></tr>
<tr><td><code id="fscores_+3A_quadpts">quadpts</code></td>
<td>
<p>number of quadrature to use per dimension. If not specified, a suitable
one will be created which decreases as the number of dimensions increases
(and therefore for estimates such as EAP, will be less accurate). This is determined from
the switch statement
<code>quadpts &lt;- switch(as.character(nfact), '1'=121, '2'=61, '3'=31, '4'=19, '5'=11, '6'=7, 5)</code></p>
</td></tr>
<tr><td><code id="fscores_+3A_item_weights">item_weights</code></td>
<td>
<p>a user-defined weight vector used in the likelihood expressions
to add more/less weight for a given observed response. Default is a vector of 1's,
indicating that all the items receive the same weight</p>
</td></tr>
<tr><td><code id="fscores_+3A_returner">returnER</code></td>
<td>
<p>logical; return empirical reliability (also known as marginal reliability)
estimates as a numeric values?</p>
</td></tr>
<tr><td><code id="fscores_+3A_t_as_x">T_as_X</code></td>
<td>
<p>logical; should the observed variance be equal to
<code>var(X) = var(T) + E(E^2)</code> or <code>var(X) = var(T)</code> when computing
empirical reliability estimates? Default (<code>FALSE</code>) uses the former</p>
</td></tr>
<tr><td><code id="fscores_+3A_return.acov">return.acov</code></td>
<td>
<p>logical; return a list containing covariance matrices instead of factors
scores? <code>impute = TRUE</code> not supported with this option</p>
</td></tr>
<tr><td><code id="fscores_+3A_mean">mean</code></td>
<td>
<p>a vector for custom latent variable means. If NULL, the default for 'group' values
from the computed mirt object will be used</p>
</td></tr>
<tr><td><code id="fscores_+3A_cov">cov</code></td>
<td>
<p>a custom matrix of the latent variable covariance matrix. If NULL, the default for
'group' values from the computed mirt object will be used</p>
</td></tr>
<tr><td><code id="fscores_+3A_covdata">covdata</code></td>
<td>
<p>when latent regression model has been fitted, and the <code>response.pattern</code>
input is used to score individuals, then this argument is used to include the latent regression
covariate terms for each row vector supplied to <code>response.pattern</code></p>
</td></tr>
<tr><td><code id="fscores_+3A_verbose">verbose</code></td>
<td>
<p>logical; print verbose output messages?</p>
</td></tr>
<tr><td><code id="fscores_+3A_full.scores.se">full.scores.SE</code></td>
<td>
<p>logical; when <code>full.scores == TRUE</code>, also return the
standard errors associated with each respondent? Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="fscores_+3A_theta_lim">theta_lim</code></td>
<td>
<p>lower and upper range to evaluate latent trait integral for each dimension. If
omitted, a range will be generated automatically based on the number of dimensions</p>
</td></tr>
<tr><td><code id="fscores_+3A_mi">MI</code></td>
<td>
<p>a number indicating how many multiple imputation draws to perform. Default is 0,
indicating that no MI draws will be performed</p>
</td></tr>
<tr><td><code id="fscores_+3A_use_dentype_estimate">use_dentype_estimate</code></td>
<td>
<p>logical; if the density of the latent trait was estimated in the model
(e.g., via Davidian curves or empirical histograms), should this information be used to compute
the latent trait estimates? Only applicable for EAP-based estimates (EAP, EAPsum, and plausible)</p>
</td></tr>
<tr><td><code id="fscores_+3A_qmc">QMC</code></td>
<td>
<p>logical; use quasi-Monte Carlo integration? If <code>quadpts</code> is omitted the
default number of nodes is 5000</p>
</td></tr>
<tr><td><code id="fscores_+3A_custom_den">custom_den</code></td>
<td>
<p>a function used to define the integration density (if required). The NULL default
assumes that the multivariate normal distribution with the 'GroupPars' hyper-parameters are
used. At the minimum must be of the form:
</p>
<p><code>function(Theta, ...)</code>
</p>
<p>where Theta is a matrix of latent trait values (will be a grid of values
if <code>method == 'EAPsum'</code> or <code>method == 'EAP'</code>, otherwise Theta will have only 1 row).
Additional arguments may included and are caught through the <code>fscores(...)</code> input. The
function <em>must</em> return a numeric vector of density weights (one for each row in Theta)</p>
</td></tr>
<tr><td><code id="fscores_+3A_custom_theta">custom_theta</code></td>
<td>
<p>a matrix of custom integration nodes to use instead of the default, where
each column corresponds to the respective dimension in the model</p>
</td></tr>
<tr><td><code id="fscores_+3A_min_expected">min_expected</code></td>
<td>
<p>when computing goodness of fit tests when <code>method = 'EAPsum'</code>, this value is used
to collapse across the conditioned total scores until the expected values are greater than this value. Note
that this only affect the goodness of fit tests and not the returned EAP for sum scores table</p>
</td></tr>
<tr><td><code id="fscores_+3A_max_theta">max_theta</code></td>
<td>
<p>the maximum/minimum value any given factor score estimate will achieve using
any modal estimator method (e.g., MAP, WLE, ML)</p>
</td></tr>
<tr><td><code id="fscores_+3A_start">start</code></td>
<td>
<p>a matrix of starting values to use for iterative estimation methods. Default
will start at a vector of 0's for each response pattern, or will start at the EAP
estimates (unidimensional models only). Must be in the form that matches
<code>full.scores = FALSE</code> (mostly used in the <code>mirtCAT</code> package)</p>
</td></tr>
<tr><td><code id="fscores_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>nlm</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function will return either a table with the computed scores and standard errors,
the original data matrix with scores appended to the rightmost column, or the scores only. By
default the latent means and covariances are determined from the estimated object,
though these can be overwritten. Iterative estimation methods can be estimated
in parallel to decrease estimation times if a <code><a href="#topic+mirtCluster">mirtCluster</a></code> object is available.
</p>
<p>If the input object is a discrete latent class object estimated from <code><a href="#topic+mdirt">mdirt</a></code>
then the returned results will be with respect to the posterior classification for each
individual. The method inputs for <code>'DiscreteClass'</code> objects may only be <code>'EAP'</code>,
for posterior classification of each response pattern, or <code>'EAPsum'</code> for posterior
classification based on the raw sum-score. For more information on these algorithms refer to
the <code>mirtCAT</code> package and the associated JSS paper (Chalmers, 2016).
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P. (2016). Generating Adaptive and Non-Adaptive Test Interfaces for
Multidimensional Item Response Theory Applications. <em>Journal of Statistical Software, 71</em>(5),
1-39. <a href="https://doi.org/10.18637/jss.v071.i05">doi:10.18637/jss.v071.i05</a>
</p>
<p>Embretson, S. E. &amp; Reise, S. P. (2000). Item Response Theory for Psychologists. Erlbaum.
</p>
<p>Thissen, D., Pommerich, M., Billeaud, K., &amp; Williams, V. S. L. (1995).
Item Response Theory for Scores on Tests Including Polytomous Items with Ordered Responses.
<em>Applied Psychological Measurement, 19</em>, 39-49.
</p>
<p>Warm, T. A. (1989). Weighted likelihood estimation of ability in item response theory.
<em>Psychometrika, 54</em>, 427-450.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+averageMI">averageMI</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mod &lt;- mirt(Science, 1)
tabscores &lt;- fscores(mod, full.scores = FALSE)
head(tabscores)

## Not run: 
fullscores &lt;- fscores(mod)
fullscores_with_SE &lt;- fscores(mod, full.scores.SE=TRUE)
head(fullscores)
head(fullscores_with_SE)

# change method argument to use MAP estimates
fullscores &lt;- fscores(mod, method='MAP')
head(fullscores)

# calculate MAP for a given response vector
fscores(mod, method='MAP', response.pattern = c(1,2,3,4))
# or matrix
fscores(mod, method='MAP', response.pattern = rbind(c(1,2,3,4), c(2,2,1,3)))

# return only the scores and their SEs
fscores(mod, method='MAP', response.pattern = c(1,2,3,4))

# use custom latent variable properties (diffuse prior for MAP is very close to ML)
fscores(mod, method='MAP', cov = matrix(1000), full.scores = FALSE)
fscores(mod, method='ML', full.scores = FALSE)

# EAPsum table of values based on total scores
(fs &lt;- fscores(mod, method = 'EAPsum', full.scores = FALSE))

# convert expected counts back into marginal probability distribution
within(fs,
   `P(y)` &lt;- expected / sum(observed))

# list of error VCOV matrices for EAPsum (works for other estimators as well)
acovs &lt;- fscores(mod, method = 'EAPsum', full.scores = FALSE, return.acov = TRUE)
acovs

# WLE estimation, run in parallel using available cores
if(interactive()) mirtCluster()
head(fscores(mod, method='WLE', full.scores = FALSE))

# multiple imputation using 30 draws for EAP scores. Requires information matrix
mod &lt;- mirt(Science, 1, SE=TRUE)
fs &lt;- fscores(mod, MI = 30)
head(fs)

# plausible values for future work
pv &lt;- fscores(mod, plausible.draws = 5)
lapply(pv, function(x) c(mean=mean(x), var=var(x), min=min(x), max=max(x)))

## define a custom_den function. EAP with a uniform prior between -3 and 3
fun &lt;- function(Theta, ...) as.numeric(dunif(Theta, min = -3, max = 3))
head(fscores(mod, custom_den = fun))

# custom MAP prior: standard truncated normal between 5 and -2
library(msm)
# need the :: scope for parallel to see the function (not require if no mirtCluster() defined)
fun &lt;- function(Theta, ...) msm::dtnorm(Theta, mean = 0, sd = 1, lower = -2, upper = 5)
head(fscores(mod, custom_den = fun, method = 'MAP', full.scores = FALSE))


####################
# scoring via response.pattern input (with latent regression structure)
# simulate data
set.seed(1234)
N &lt;- 1000

# covariates
X1 &lt;- rnorm(N); X2 &lt;- rnorm(N)
covdata &lt;- data.frame(X1, X2)
Theta &lt;- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))

# items and response data
a &lt;- matrix(1, 20); d &lt;- matrix(rnorm(20))
dat &lt;- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)

# conditional model using X1 and X2 as predictors of Theta
mod &lt;- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2)
coef(mod, simplify=TRUE)

# all EAP estimates that include latent regression information
fs &lt;- fscores(mod, full.scores.SE=TRUE)
head(fs)

# score only two response patterns
rp &lt;- dat[1:2, ]
cd &lt;- covdata[1:2, ]

fscores(mod, response.pattern=rp, covdata=cd)
fscores(mod, response.pattern=rp[2,], covdata=cd[2,]) # just one pattern


## End(Not run)
</code></pre>

<hr>
<h2 id='gen.difficulty'>Generalized item difficulty summaries</h2><span id='topic+gen.difficulty'></span>

<h3>Description</h3>

<p>Function provides the four generalized item difficulty representations
for polytomous response models described by Ali, Chang, and Anderson (2015).
These estimates are used to gauge how difficult a polytomous item may be.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gen.difficulty(mod, type = "IRF", interval = c(-30, 30), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gen.difficulty_+3A_mod">mod</code></td>
<td>
<p>a single factor model estimated by <code><a href="#topic+mirt">mirt</a></code></p>
</td></tr>
<tr><td><code id="gen.difficulty_+3A_type">type</code></td>
<td>
<p>type of generalized difficulty parameter to report.
Can be <code>'IRF'</code> to use the item response function (default),
<code>'mean'</code> to find the average of the difficulty estimates,
<code>'median'</code> the median of the difficulty estimates, and
<code>'trimmed'</code> to find the trimmed mean after removing the first
and last difficulty estimates</p>
</td></tr>
<tr><td><code id="gen.difficulty_+3A_interval">interval</code></td>
<td>
<p>interval range to search for <code>'IRF'</code> type</p>
</td></tr>
<tr><td><code id="gen.difficulty_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="stats.html#topic+uniroot">uniroot</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Ali, U. S., Chang, H.-H., &amp; Anderson, C. J. (2015). <em>Location indices for ordinal
polytomous items based on item response theory</em> (Research Report No. RR-15-20).
Princeton, NJ: Educational Testing Service. http://dx.doi.org/10.1002/ets2.12065
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

mod &lt;- mirt(Science, 1)
coef(mod, simplify=TRUE, IRTpars = TRUE)$items

gen.difficulty(mod)
gen.difficulty(mod, type = 'mean')

# also works for dichotomous items (though this is unnecessary)
dat &lt;- expand.table(LSAT7)
mod &lt;- mirt(dat, 1)
coef(mod, simplify=TRUE, IRTpars = TRUE)$items

gen.difficulty(mod)
gen.difficulty(mod, type = 'mean')


## End(Not run)
</code></pre>

<hr>
<h2 id='imputeMissing'>Imputing plausible data for missing values</h2><span id='topic+imputeMissing'></span>

<h3>Description</h3>

<p>Given an estimated model from any of mirt's model fitting functions and an estimate of the
latent trait, impute plausible missing data values. Returns the original data in a
<code>data.frame</code> without any NA values. If a list of <code>Theta</code> values is supplied then a
list of complete datasets is returned instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>imputeMissing(x, Theta, warn = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="imputeMissing_+3A_x">x</code></td>
<td>
<p>an estimated model x from the mirt package</p>
</td></tr>
<tr><td><code id="imputeMissing_+3A_theta">Theta</code></td>
<td>
<p>a matrix containing the estimates of the latent trait scores
(e.g., via <code><a href="#topic+fscores">fscores</a></code>)</p>
</td></tr>
<tr><td><code id="imputeMissing_+3A_warn">warn</code></td>
<td>
<p>logical; print warning messages?</p>
</td></tr>
<tr><td><code id="imputeMissing_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- expand.table(LSAT7)
(original &lt;- mirt(dat, 1))
NAperson &lt;- sample(1:nrow(dat), 20, replace = TRUE)
NAitem &lt;- sample(1:ncol(dat), 20, replace = TRUE)
for(i in 1:20)
    dat[NAperson[i], NAitem[i]] &lt;- NA
(mod &lt;- mirt(dat, 1))
scores &lt;- fscores(mod, method = 'MAP')

# re-estimate imputed dataset (good to do this multiple times and average over)
fulldata &lt;- imputeMissing(mod, scores)
(fullmod &lt;- mirt(fulldata, 1))

# with multipleGroup
set.seed(1)
group &lt;- sample(c('group1', 'group2'), 1000, TRUE)
mod2 &lt;- multipleGroup(dat, 1, group, TOL=1e-2)
fs &lt;- fscores(mod2)
fulldata2 &lt;- imputeMissing(mod2, fs)


## End(Not run)
</code></pre>

<hr>
<h2 id='itemfit'>Item fit statistics</h2><span id='topic+itemfit'></span>

<h3>Description</h3>

<p>Computes item-fit statistics for a variety of unidimensional and multidimensional models.
Poorly fitting items should be inspected with the empirical plots/tables
for unidimensional models, otherwise <code><a href="#topic+itemGAM">itemGAM</a></code> can be used to diagnose
where the functional form of the IRT model was misspecified, or models can be refit using
more flexible semi-parametric response models (e.g., <code>itemtype = 'spline'</code>).
If the latent trait density was approximated (e.g., Davidian curves, Empirical histograms, etc)
then passing <code>use_dentype_estimate = TRUE</code> will use the internally saved quadrature and
density components (where applicable). Currently, only S-X2 statistic supported for
mixture IRT models. Finally, where applicable the root mean-square error of approximation (RMSEA)
is reported to help gauge the magnitude of item misfit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itemfit(
  x,
  fit_stats = "S_X2",
  which.items = 1:extract.mirt(x, "nitems"),
  na.rm = FALSE,
  p.adjust = "none",
  group.bins = 10,
  group.size = NA,
  group.fun = mean,
  mincell = 1,
  mincell.X2 = 2,
  return.tables = FALSE,
  pv_draws = 30,
  boot = 1000,
  boot_dfapprox = 200,
  S_X2.plot = NULL,
  S_X2.plot_raw.score = TRUE,
  ETrange = c(-2, 2),
  ETpoints = 11,
  empirical.plot = NULL,
  empirical.CI = 0.95,
  empirical.poly.collapse = FALSE,
  method = "EAP",
  Theta = NULL,
  par.strip.text = list(cex = 0.7),
  par.settings = list(strip.background = list(col = "#9ECAE1"), strip.border = list(col =
    "black")),
  auto.key = list(space = "right", points = FALSE, lines = TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itemfit_+3A_x">x</code></td>
<td>
<p>a computed model object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>DiscreteClass</code></p>
</td></tr>
<tr><td><code id="itemfit_+3A_fit_stats">fit_stats</code></td>
<td>
<p>a character vector indicating which fit statistics should be computed.
Supported inputs are:
</p>

<ul>
<li> <p><code>'S_X2'</code> : Orlando and Thissen (2000, 2003) and
Kang and Chen's (2007) signed chi-squared test (default)
</p>
</li>
<li> <p><code>'Zh'</code> : Drasgow, Levine, &amp; Williams (1985) Zh
</p>
</li>
<li> <p><code>'X2'</code> : Bock's (1972) chi-squared method.
The default inputs compute Yen's (1981) Q1 variant of the X2 statistic
(i.e., uses a fixed <code>group.bins = 10</code>). However, Bock's group-size variable
median-based method can be computed by passing <code>group.fun = median</code> and
modifying the <code>group.size</code> input to the desired number of bins
</p>
</li>
<li> <p><code>'G2'</code> : McKinley &amp; Mills (1985) G2 statistic (similar method to Q1,
but with the likelihood-ratio test).
</p>
</li>
<li> <p><code>'PV_Q1'</code> : Chalmers and Ng's (2017) plausible-value variant
of the Q1 statistic.
</p>
</li>
<li> <p><code>'PV_Q1*'</code> : Chalmers and Ng's (2017) plausible-value variant
of the Q1 statistic that uses parametric bootstrapping to obtain a suitable empirical
distribution.
</p>
</li>
<li> <p><code>'X2*'</code> : Stone's (2000) fit statistics that require parametric
bootstrapping
</p>
</li>
<li> <p><code>'X2*_df'</code> : Stone's (2000) fit statistics that require parametric
bootstrapping to obtain scaled versions of the X2* and degrees of freedom
</p>
</li>
<li> <p><code>'infit'</code> : Compute the infit and outfit statistics
</p>
</li></ul>

<p>Note that 'S_X2' and 'Zh' cannot be computed when there are missing response data
(i.e., will require multiple-imputation/row-removal techniques).</p>
</td></tr>
<tr><td><code id="itemfit_+3A_which.items">which.items</code></td>
<td>
<p>an integer vector indicating which items to test for fit.
Default tests all possible items</p>
</td></tr>
<tr><td><code id="itemfit_+3A_na.rm">na.rm</code></td>
<td>
<p>logical; remove rows with any missing values? This is required for methods such
as S-X2 because they require the &quot;EAPsum&quot; method from <code><a href="#topic+fscores">fscores</a></code></p>
</td></tr>
<tr><td><code id="itemfit_+3A_p.adjust">p.adjust</code></td>
<td>
<p>method to use for adjusting all p-values for each respective item fit
statistic (see <code><a href="stats.html#topic+p.adjust">p.adjust</a></code> for available options). Default is <code>'none'</code></p>
</td></tr>
<tr><td><code id="itemfit_+3A_group.bins">group.bins</code></td>
<td>
<p>the number of bins to use for X2 and G2. For example,
setting <code>group.bins = 10</code> will will compute Yen's (1981) Q1 statistic when <code>'X2'</code> is
requested</p>
</td></tr>
<tr><td><code id="itemfit_+3A_group.size">group.size</code></td>
<td>
<p>approximate size of each group to be used in calculating the <code class="reqn">\chi^2</code>
statistic. The default <code>NA</code>
disables this command and instead uses the <code>group.bins</code> input to try and construct
equally sized bins</p>
</td></tr>
<tr><td><code id="itemfit_+3A_group.fun">group.fun</code></td>
<td>
<p>function used when <code>'X2'</code> or <code>'G2'</code> are computed. Determines the central
tendency measure within each partitioned group. E.g., setting <code>group.fun = median</code> will
obtain the median of each respective ability estimate in each subgroup (this is what was used
by Bock, 1972)</p>
</td></tr>
<tr><td><code id="itemfit_+3A_mincell">mincell</code></td>
<td>
<p>the minimum expected cell size to be used in the S-X2 computations. Tables will be
collapsed across items first if polytomous, and then across scores if necessary</p>
</td></tr>
<tr><td><code id="itemfit_+3A_mincell.x2">mincell.X2</code></td>
<td>
<p>the minimum expected cell size to be used in the X2 computations. Tables will be
collapsed if polytomous, however if this condition can not be met then the group block will
be omitted in the computations</p>
</td></tr>
<tr><td><code id="itemfit_+3A_return.tables">return.tables</code></td>
<td>
<p>logical; return tables when investigating <code>'X2'</code>, <code>'S_X2'</code>,
and <code>'X2*'</code>?</p>
</td></tr>
<tr><td><code id="itemfit_+3A_pv_draws">pv_draws</code></td>
<td>
<p>number of plausible-value draws to obtain for PV_Q1 and PV_Q1*</p>
</td></tr>
<tr><td><code id="itemfit_+3A_boot">boot</code></td>
<td>
<p>number of parametric bootstrap samples to create for PV_Q1* and X2*</p>
</td></tr>
<tr><td><code id="itemfit_+3A_boot_dfapprox">boot_dfapprox</code></td>
<td>
<p>number of parametric bootstrap samples to create for the X2*_df statistic
to approximate the scaling factor for X2* as well as the scaled degrees of freedom estimates</p>
</td></tr>
<tr><td><code id="itemfit_+3A_s_x2.plot">S_X2.plot</code></td>
<td>
<p>argument input is the same as <code>empirical.plot</code>, however the resulting image
is constructed according to the S-X2 statistic's conditional sum-score information</p>
</td></tr>
<tr><td><code id="itemfit_+3A_s_x2.plot_raw.score">S_X2.plot_raw.score</code></td>
<td>
<p>logical; use the raw-score information in the plot in stead of the latent
trait scale score? Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="itemfit_+3A_etrange">ETrange</code></td>
<td>
<p>rangone of integration nodes for Stone's X2* statistic</p>
</td></tr>
<tr><td><code id="itemfit_+3A_etpoints">ETpoints</code></td>
<td>
<p>number of integration nodes to use for Stone's X2* statistic</p>
</td></tr>
<tr><td><code id="itemfit_+3A_empirical.plot">empirical.plot</code></td>
<td>
<p>a single numeric value or character of the item name indicating which
item to plot (via <code>itemplot</code>) and overlay with the empirical <code class="reqn">\theta</code> groupings (see
<code>empirical.CI</code>). Useful for plotting the expected bins based on the <code>'X2'</code> or
<code>'G2'</code> method</p>
</td></tr>
<tr><td><code id="itemfit_+3A_empirical.ci">empirical.CI</code></td>
<td>
<p>a numeric value indicating the width of the empirical confidence interval
ranging between 0 and 1 (default of 0 plots not interval). For example, a 95
interval would be plotted when <code>empirical.CI = .95</code>. Only applicable to dichotomous items</p>
</td></tr>
<tr><td><code id="itemfit_+3A_empirical.poly.collapse">empirical.poly.collapse</code></td>
<td>
<p>logical; collapse polytomous item categories to for expected scoring
functions for empirical plots? Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="itemfit_+3A_method">method</code></td>
<td>
<p>type of factor score estimation method. See <code><a href="#topic+fscores">fscores</a></code> for more detail</p>
</td></tr>
<tr><td><code id="itemfit_+3A_theta">Theta</code></td>
<td>
<p>a matrix of factor scores for each person used for statistics that require
empirical estimates. If supplied, arguments typically passed to <code>fscores()</code> will be
ignored and these values will be used instead. Also required when estimating statistics
with missing data via imputation</p>
</td></tr>
<tr><td><code id="itemfit_+3A_par.strip.text">par.strip.text</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="itemfit_+3A_par.settings">par.settings</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="itemfit_+3A_auto.key">auto.key</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="itemfit_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>fscores()</code> and <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Bock, R. D. (1972). Estimating item parameters and latent ability when responses are scored
in two or more nominal categories. <em>Psychometrika, 37</em>, 29-51.
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P. &amp; Ng, V. (2017). Plausible-Value Imputation Statistics for Detecting
Item Misfit. <em>Applied Psychological Measurement, 41</em>, 372-387.
<a href="https://doi.org/10.1177/0146621617692079">doi:10.1177/0146621617692079</a>
</p>
<p>Drasgow, F., Levine, M. V., &amp; Williams, E. A. (1985). Appropriateness measurement with
polychotomous item response models and standardized indices.
<em>British Journal of Mathematical and Statistical Psychology, 38</em>, 67-86.
</p>
<p>Kang, T. &amp; Chen, Troy, T. (2007). An investigation of the performance of the generalized
S-X2 item-fit index for polytomous IRT models. ACT
</p>
<p>McKinley, R., &amp; Mills, C. (1985). A comparison of several goodness-of-fit statistics.
Applied Psychological Measurement, 9, 49-57.
</p>
<p>Orlando, M. &amp; Thissen, D. (2000). Likelihood-based item fit indices for dichotomous item
response theory models. <em>Applied Psychological Measurement, 24</em>, 50-64.
</p>
<p>Reise, S. P. (1990). A comparison of item- and person-fit methods of assessing model-data fit
in IRT. <em>Applied Psychological Measurement, 14</em>, 127-137.
</p>
<p>Stone, C. A. (2000). Monte Carlo Based Null Distribution for an Alternative Goodness-of-Fit
Test Statistics in IRT Models. <em>Journal of Educational Measurement, 37</em>, 58-75.
</p>
<p>Wright B. D. &amp; Masters, G. N. (1982). <em>Rating scale analysis</em>. MESA Press.
</p>
<p>Yen, W. M. (1981). Using simulation results to choose a latent trait model.
<em>Applied Psychological Measurement, 5</em>, 245-262.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+personfit">personfit</a></code>, <code><a href="#topic+itemGAM">itemGAM</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

P &lt;- function(Theta){exp(Theta^2 * 1.2 - 1) / (1 + exp(Theta^2 * 1.2 - 1))}

#make some data
set.seed(1234)
a &lt;- matrix(rlnorm(20, meanlog=0, sdlog = .1),ncol=1)
d &lt;- matrix(rnorm(20),ncol=1)
Theta &lt;- matrix(rnorm(2000))
items &lt;- rep('2PL', 20)
ps &lt;- P(Theta)
baditem &lt;- numeric(2000)
for(i in 1:2000)
   baditem[i] &lt;- sample(c(0,1), 1, prob = c(1-ps[i], ps[i]))
data &lt;- cbind(simdata(a,d, 2000, items, Theta=Theta), baditem=baditem)

x &lt;- mirt(data, 1)
raschfit &lt;- mirt(data, 1, itemtype='Rasch')
fit &lt;- itemfit(x)
fit

# p-value adjustment
itemfit(x, p.adjust='fdr')

# two different fit stats (with/without p-value adjustment)
itemfit(x, c('S_X2' ,'X2'), p.adjust='fdr')
itemfit(x, c('S_X2' ,'X2'))

# Conditional sum-score plot from S-X2 information
itemfit(x, S_X2.plot = 1) # good fit
itemfit(x, S_X2.plot = 2) # good fit
itemfit(x, S_X2.plot = 21) # bad fit

itemfit(x, 'X2') # just X2
itemfit(x, 'X2', method = 'ML') # X2 with maximum-likelihood estimates for traits
itemfit(x, group.bins=15, empirical.plot = 1, method = 'ML') #empirical item plot with 15 points
itemfit(x, group.bins=15, empirical.plot = 21, method = 'ML')

# PV and X2* statistics (parametric bootstrap stats not run to save time)
itemfit(x, 'PV_Q1')

if(interactive()) mirtCluster() # improve speed of bootstrap samples by running in parallel
# itemfit(x, 'PV_Q1*')
# itemfit(x, 'X2*') # Stone's 1993 statistic
# itemfit(x, 'X2*_df') # Stone's 2000 scaled statistic with df estimate

# empirical tables for X2 statistic
tabs &lt;- itemfit(x, 'X2', return.tables=TRUE, which.items = 1)
tabs

#infit/outfit statistics. method='ML' agrees better with eRm package
itemfit(raschfit, 'infit', method = 'ML') #infit and outfit stats

#same as above, but inputting ML estimates instead (saves time for re-use)
Theta &lt;- fscores(raschfit, method = 'ML')
itemfit(raschfit, 'infit', Theta=Theta)
itemfit(raschfit, empirical.plot=1, Theta=Theta)
itemfit(raschfit, 'X2', return.tables=TRUE, Theta=Theta, which.items=1)

# fit a new more flexible model for the mis-fitting item
itemtype &lt;- c(rep('2PL', 20), 'spline')
x2 &lt;- mirt(data, 1, itemtype=itemtype)
itemfit(x2)
itemplot(x2, 21)
anova(x, x2)

#------------------------------------------------------------

#similar example to Kang and Chen 2007
a &lt;- matrix(c(.8,.4,.7, .8, .4, .7, 1, 1, 1, 1))
d &lt;- matrix(rep(c(2.0,0.0,-1,-1.5),10), ncol=4, byrow=TRUE)
dat &lt;- simdata(a,d,2000, itemtype = rep('graded', 10))
head(dat)

mod &lt;- mirt(dat, 1)
itemfit(mod)
itemfit(mod, 'X2') # less useful given inflated Type I error rates
itemfit(mod, empirical.plot = 1)
itemfit(mod, empirical.plot = 1, empirical.poly.collapse=TRUE)

# collapsed tables (see mincell.X2) for X2 and G2
itemfit(mod, 'X2', return.tables = TRUE, which.items = 1)

mod2 &lt;- mirt(dat, 1, 'Rasch')
itemfit(mod2, 'infit', method = 'ML')

# massive list of tables for S-X2
tables &lt;- itemfit(mod, return.tables = TRUE)

#observed and expected total score patterns for item 1 (post collapsing)
tables$O[[1]]
tables$E[[1]]

# can also select specific items
# itemfit(mod, return.tables = TRUE, which.items=1)

# fit stats with missing data (run in parallel using all cores)
dat[sample(1:prod(dim(dat)), 100)] &lt;- NA
raschfit &lt;- mirt(dat, 1, itemtype='Rasch')

# use only valid data by removing rows with missing terms
itemfit(raschfit, c('S_X2', 'infit'), na.rm = TRUE)

# note that X2, G2, PV-Q1, and X2* do not require complete datasets
thetas &lt;- fscores(raschfit, method = 'ML') # save for faster computations
itemfit(raschfit, c('X2', 'G2'), Theta=thetas)
itemfit(raschfit, empirical.plot=1, Theta=thetas)
itemfit(raschfit, 'X2', return.tables=TRUE, which.items=1, Theta=thetas)


## End(Not run)

</code></pre>

<hr>
<h2 id='itemGAM'>Parametric smoothed regression lines for item response probability functions</h2><span id='topic+itemGAM'></span><span id='topic+plot.itemGAM'></span>

<h3>Description</h3>

<p>This function uses a generalized additive model (GAM) to estimate response curves for items that
do not seem to fit well in a given model. Using a stable axillary model, traceline functions for
poorly fitting dichotomous or polytomous items can be inspected using point estimates
(or plausible values) of the latent trait. Plots of the tracelines and their associated standard
errors are available to help interpret the misfit. This function may also be useful when adding
new items to an existing, well established set of items, especially when the parametric form of
the items under investigation are unknown.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itemGAM(
  item,
  Theta,
  formula = resp ~ s(Theta, k = 10),
  CI = 0.95,
  theta_lim = c(-3, 3),
  return.models = FALSE,
  ...
)

## S3 method for class 'itemGAM'
plot(
  x,
  y = NULL,
  par.strip.text = list(cex = 0.7),
  par.settings = list(strip.background = list(col = "#9ECAE1"), strip.border = list(col =
    "black")),
  auto.key = list(space = "right", points = FALSE, lines = TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itemGAM_+3A_item">item</code></td>
<td>
<p>a single poorly fitting item to be investigated. Can be a vector or matrix</p>
</td></tr>
<tr><td><code id="itemGAM_+3A_theta">Theta</code></td>
<td>
<p>a list or matrix of latent trait estimates typically returned from <code><a href="#topic+fscores">fscores</a></code></p>
</td></tr>
<tr><td><code id="itemGAM_+3A_formula">formula</code></td>
<td>
<p>an R formula to be passed to the <code>gam</code> function. Default fits a spline model
with 10 nodes. For multidimensional models, the traits are assigned the names 'Theta1', 'Theta2',
..., 'ThetaN'</p>
</td></tr>
<tr><td><code id="itemGAM_+3A_ci">CI</code></td>
<td>
<p>a number ranging from 0 to 1 indicating the confidence interval range. Default provides the
95 percent interval</p>
</td></tr>
<tr><td><code id="itemGAM_+3A_theta_lim">theta_lim</code></td>
<td>
<p>range of latent trait scores to be evaluated</p>
</td></tr>
<tr><td><code id="itemGAM_+3A_return.models">return.models</code></td>
<td>
<p>logical; return a list of GAM models for each category? Useful when the GAMs
should be inspected directly, but also when fitting multidimensional models (this is set to
TRUE automatically for multidimensional models)</p>
</td></tr>
<tr><td><code id="itemGAM_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>gam</code> or <code>lattice</code></p>
</td></tr>
<tr><td><code id="itemGAM_+3A_x">x</code></td>
<td>
<p>an object of class 'itemGAM'</p>
</td></tr>
<tr><td><code id="itemGAM_+3A_y">y</code></td>
<td>
<p>a <code>NULL</code> value ignored by the plotting function</p>
</td></tr>
<tr><td><code id="itemGAM_+3A_par.strip.text">par.strip.text</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="itemGAM_+3A_par.settings">par.settings</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="itemGAM_+3A_auto.key">auto.key</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemfit">itemfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
set.seed(10)
N &lt;- 1000
J &lt;- 30

a &lt;- matrix(1, J)
d &lt;- matrix(rnorm(J))
Theta &lt;- matrix(rnorm(N, 0, 1.5))
dat &lt;- simdata(a, d, N, itemtype = '2PL', Theta=Theta)

# make a bad item
ps &lt;- exp(Theta^2 + Theta) / (1 + exp(Theta^2 + Theta))
item1 &lt;- sapply(ps, function(x) sample(c(0,1), size = 1, prob = c(1-x, x)))

ps2 &lt;- exp(2 * Theta^2 + Theta + .5 * Theta^3) / (1 + exp(2 * Theta^2 + Theta + .5 * Theta^3))
item2 &lt;- sapply(ps2, function(x) sample(c(0,1), size = 1, prob = c(1-x, x)))

# how the actual item looks in the population
plot(Theta, ps, ylim = c(0,1))
plot(Theta, ps2, ylim = c(0,1))

baditems &lt;- cbind(item1, item2)
newdat &lt;- cbind(dat, baditems)

badmod &lt;- mirt(newdat, 1)
itemfit(badmod) #clearly a bad fit for the last two items
mod &lt;- mirt(dat, 1) #fit a model that does not contain the bad items
itemfit(mod)

#### Pure non-parametric way of investigating the items
library(KernSmoothIRT)
ks &lt;- ksIRT(newdat, rep(1, ncol(newdat)), 1)
plot(ks, item=c(1,31,32))
par(ask=FALSE)

# Using point estimates from the model
Theta &lt;- fscores(mod)
IG0 &lt;- itemGAM(dat[,1], Theta) #good item
IG1 &lt;- itemGAM(baditems[,1], Theta)
IG2 &lt;- itemGAM(baditems[,2], Theta)
plot(IG0)
plot(IG1)
plot(IG2)

# same as above, but with plausible values to obtain the standard errors
set.seed(4321)
ThetaPV &lt;- fscores(mod, plausible.draws=10)
IG0 &lt;- itemGAM(dat[,1], ThetaPV) #good item
IG1 &lt;- itemGAM(baditems[,1], ThetaPV)
IG2 &lt;- itemGAM(baditems[,2], ThetaPV)
plot(IG0)
plot(IG1)
plot(IG2)

## for polytomous test items
SAT12[SAT12 == 8] &lt;- NA
dat &lt;- key2binary(SAT12,
                  key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
dat &lt;- dat[,-32]
mod &lt;- mirt(dat, 1)

# Kernal smoothing is very sensitive to which category is selected as 'correct'
# 5th category as correct
ks &lt;- ksIRT(cbind(dat, SAT12[,32]), c(rep(1, 31), 5), 1)
plot(ks, items = c(1,2,32))

# 3rd category as correct
ks &lt;- ksIRT(cbind(dat, SAT12[,32]), c(rep(1, 31), 3), 1)
plot(ks, items = c(1,2,32))

# splines approach
Theta &lt;- fscores(mod)
IG &lt;- itemGAM(SAT12[,32], Theta)
plot(IG)

set.seed(1423)
ThetaPV &lt;- fscores(mod, plausible.draws=10)
IG2 &lt;- itemGAM(SAT12[,32], ThetaPV)
plot(IG2)

# assuming a simple increasing parametric form (like in a standard IRT model)
IG3 &lt;- itemGAM(SAT12[,32], Theta, formula = resp ~ Theta)
plot(IG3)
IG3 &lt;- itemGAM(SAT12[,32], ThetaPV, formula = resp ~ Theta)
plot(IG3)

### multidimensional example by returning the GAM objects
mod2 &lt;- mirt(dat, 2)
Theta &lt;- fscores(mod2)
IG4 &lt;- itemGAM(SAT12[,32], Theta, formula = resp ~ s(Theta1, k=10) + s(Theta2, k=10),
   return.models=TRUE)
names(IG4)
plot(IG4[[1L]], main = 'Category 1')
plot(IG4[[2L]], main = 'Category 2')
plot(IG4[[3L]], main = 'Category 3')


## End(Not run)
</code></pre>

<hr>
<h2 id='iteminfo'>Function to calculate item information</h2><span id='topic+iteminfo'></span>

<h3>Description</h3>

<p>Given an internal mirt item object extracted by using <code><a href="#topic+extract.item">extract.item</a></code>,
compute the item information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iteminfo(x, Theta, degrees = NULL, total.info = TRUE, multidim_matrix = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iteminfo_+3A_x">x</code></td>
<td>
<p>an extracted internal mirt object containing item information (see <code><a href="#topic+extract.item">extract.item</a></code>)</p>
</td></tr>
<tr><td><code id="iteminfo_+3A_theta">Theta</code></td>
<td>
<p>a vector (unidimensional) or matrix (multidimensional) of latent trait values</p>
</td></tr>
<tr><td><code id="iteminfo_+3A_degrees">degrees</code></td>
<td>
<p>a vector of angles in degrees that are between 0 and 90.
Only applicable when the input object is multidimensional</p>
</td></tr>
<tr><td><code id="iteminfo_+3A_total.info">total.info</code></td>
<td>
<p>logical; return the total information curve for the item? If <code>FALSE</code>,
information curves for each category are returned as a matrix</p>
</td></tr>
<tr><td><code id="iteminfo_+3A_multidim_matrix">multidim_matrix</code></td>
<td>
<p>logical; compute the information matrix for each row in <code>Theta</code>? If <code>Theta</code>
contains more than 1 row then a list of matrices will be returned, otherwise if <code>Theta</code> has exactly
one row then a matrix will be returned</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract.item">extract.item</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mod &lt;- mirt(Science, 1)
extr.2 &lt;- extract.item(mod, 2)
Theta &lt;- matrix(seq(-4,4, by = .1))
info.2 &lt;- iteminfo(extr.2, Theta)

#do something with the info?
plot(Theta, info.2, type = 'l', main = 'Item information')

## Not run: 

#category information curves
cat.info &lt;- iteminfo(extr.2, Theta, total.info = FALSE)
plot(Theta, cat.info[,1], type = 'l', ylim = c(0, max(cat.info)),
     ylab = 'info', main = 'Category information')
for(i in 2:ncol(cat.info))
   lines(Theta, cat.info[,i], col = i)

## Customized test information plot
T1 &lt;- T2 &lt;- 0
dat &lt;- expand.table(LSAT7)
mod1 &lt;- mirt(dat, 1)
mod2 &lt;- mirt(dat, 1, 'Rasch')
for(i in 1:5){
  T1 &lt;- T1 + iteminfo(extract.item(mod1, i), Theta)
  T2 &lt;- T2 + iteminfo(extract.item(mod2, i), Theta)
}
plot(Theta, T2/T1, type = 'l', ylab = 'Relative Test Information', las = 1)
lines(Theta, T1/T1, col = 'red')

# multidimensional
mod &lt;- mirt(dat, 2, TOL=1e-2)
ii &lt;- extract.item(mod, 1)
Theta &lt;- as.matrix(expand.grid(-4:4, -4:4))

iteminfo(ii, Theta, degrees=c(45,45)) # equal angle
iteminfo(ii, Theta, degrees=c(90,0)) # first dimension only

# information matrices
iteminfo(ii, Theta, multidim_matrix = TRUE)
iteminfo(ii, Theta[1, , drop=FALSE], multidim_matrix = TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='itemplot'>Displays item surface and information plots</h2><span id='topic+itemplot'></span>

<h3>Description</h3>

<p><code>itemplot</code> displays various item based IRT plots, with special options for plotting items
that contain several 0 slope parameters. Supports up to three dimensional models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itemplot(
  object,
  item,
  type = "trace",
  degrees = 45,
  CE = FALSE,
  CEalpha = 0.05,
  CEdraws = 1000,
  drop.zeros = FALSE,
  theta_lim = NULL,
  shiny = FALSE,
  rot = list(xaxis = -70, yaxis = 30, zaxis = 10),
  par.strip.text = list(cex = 0.7),
  npts = 200,
  par.settings = list(strip.background = list(col = "#9ECAE1"), strip.border = list(col =
    "black")),
  auto.key = list(space = "right", points = FALSE, lines = TRUE),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itemplot_+3A_object">object</code></td>
<td>
<p>a computed model object of class <code>SingleGroupClass</code>
or <code>MultipleGroupClass</code>. Input may also be a <code>list</code> for comparing similar item types
(e.g., 1PL vs 2PL)</p>
</td></tr>
<tr><td><code id="itemplot_+3A_item">item</code></td>
<td>
<p>a single numeric value, or the item name, indicating which item to plot</p>
</td></tr>
<tr><td><code id="itemplot_+3A_type">type</code></td>
<td>
<p>plot type to use, information (<code>'info'</code>), standard errors (<code>'SE'</code>),
item trace lines (<code>'trace'</code>), cumulative probability plots to indicate thresholds
(<code>'threshold'</code>), information and standard errors (<code>'infoSE'</code>) or
information and trace lines (<code>'infotrace'</code>),
category and total information (<code>'infocat'</code>),
relative efficiency lines (<code>'RE'</code>),
expected score <code>'score'</code>, or information and trace line contours (<code>'infocontour'</code> and
<code>'tracecontour'</code>; not supported for <code>MultipleGroupClass</code> objects)</p>
</td></tr>
<tr><td><code id="itemplot_+3A_degrees">degrees</code></td>
<td>
<p>the degrees argument to be used if there are two or three factors.
See <code><a href="#topic+iteminfo">iteminfo</a></code> for more detail. A new vector will be required for three dimensional
models to override the default</p>
</td></tr>
<tr><td><code id="itemplot_+3A_ce">CE</code></td>
<td>
<p>logical; plot confidence envelope?</p>
</td></tr>
<tr><td><code id="itemplot_+3A_cealpha">CEalpha</code></td>
<td>
<p>area remaining in the tail for confidence envelope. Default gives 95% confidence
region</p>
</td></tr>
<tr><td><code id="itemplot_+3A_cedraws">CEdraws</code></td>
<td>
<p>draws number of draws to use for confidence envelope</p>
</td></tr>
<tr><td><code id="itemplot_+3A_drop.zeros">drop.zeros</code></td>
<td>
<p>logical; drop slope values that are numerically close to zero to reduce
dimensionality? Useful in objects returned from <code><a href="#topic+bfactor">bfactor</a></code> or other confirmatory
models that contain several zero slopes</p>
</td></tr>
<tr><td><code id="itemplot_+3A_theta_lim">theta_lim</code></td>
<td>
<p>lower and upper limits of the latent trait (theta) to be evaluated, and is
used in conjunction with <code>npts</code>. Default uses <code>c(-6,6)</code></p>
</td></tr>
<tr><td><code id="itemplot_+3A_shiny">shiny</code></td>
<td>
<p>logical; run interactive display for item plots using the <code>shiny</code> interface.
This primarily is an instructive tool for demonstrating how item response curves
behave when adjusting their parameters</p>
</td></tr>
<tr><td><code id="itemplot_+3A_rot">rot</code></td>
<td>
<p>a list of rotation coordinates to be used for 3 dimensional plots</p>
</td></tr>
<tr><td><code id="itemplot_+3A_par.strip.text">par.strip.text</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="itemplot_+3A_npts">npts</code></td>
<td>
<p>number of quadrature points to be used for plotting features.
Larger values make plots look smoother</p>
</td></tr>
<tr><td><code id="itemplot_+3A_par.settings">par.settings</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="itemplot_+3A_auto.key">auto.key</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="itemplot_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="lattice.html#topic+lattice">lattice</a></code> and <code>coef()</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

data(LSAT7)
fulldata &lt;- expand.table(LSAT7)
mod1 &lt;- mirt(fulldata,1,SE=TRUE)
mod2 &lt;- mirt(fulldata,1, itemtype = 'Rasch')
mod3 &lt;- mirt(fulldata,2)

itemplot(mod1, 2)
itemplot(mod1, 2, CE = TRUE)
itemplot(mod1, 2, type = 'info')
itemplot(mod1, 2, type = 'info', CE = TRUE)

mods &lt;- list(twoPL = mod1, onePL = mod2)
itemplot(mods, 1, type = 'RE')

# multidimensional
itemplot(mod3, 4, type = 'info')
itemplot(mod3, 4, type = 'info',
  col.regions = colorRampPalette(c("white", "red"))(100))
itemplot(mod3, 4, type = 'infocontour')
itemplot(mod3, 4, type = 'tracecontour')

# polytomous items
pmod &lt;- mirt(Science, 1, SE=TRUE)
itemplot(pmod, 3)
itemplot(pmod, 3, type = 'threshold')
itemplot(pmod, 3, CE = TRUE)
itemplot(pmod, 3, type = 'score')
itemplot(pmod, 3, type = 'score', CE = TRUE)
itemplot(pmod, 3, type = 'infotrace')
itemplot(pmod, 3, type = 'infocat')


# use the directlabels package to put labels on tracelines
library(directlabels)
plt &lt;- itemplot(pmod, 3)
direct.label(plt, 'top.points')

# change colour theme of plots
bwtheme &lt;- standard.theme("pdf", color=FALSE)
plot(pmod, type='trace', par.settings=bwtheme)
itemplot(pmod, 1, type = 'trace', par.settings=bwtheme)

# additional modifications can be made via update().
# See ?update.trellis for further documentation
(plt &lt;- itemplot(pmod, 1))
update(plt, ylab = expression(Prob(theta))) # ylab changed

# infoSE plot
itemplot(pmod, 1, type = 'infoSE')

# uncomment to run interactive shiny applet
# itemplot(shiny = TRUE)
    
## End(Not run)

</code></pre>

<hr>
<h2 id='itemstats'>Generic item summary statistics</h2><span id='topic+itemstats'></span>

<h3>Description</h3>

<p>Function to compute generic item summary statistics that do not require
prior fitting of IRT models. Contains information about coefficient alpha
(and alpha if an item is deleted), mean/SD and frequency of total scores,
reduced item-total correlations, average/sd of the correlation between items,
response frequencies, and conditional mean/sd information given the
unweighted sum scores.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>itemstats(
  data,
  group = NULL,
  use_ts = TRUE,
  proportions = TRUE,
  ts.tables = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="itemstats_+3A_data">data</code></td>
<td>
<p>An object of class <code>data.frame</code> or <code>matrix</code>
with the response patterns</p>
</td></tr>
<tr><td><code id="itemstats_+3A_group">group</code></td>
<td>
<p>optional grouping variable to condition on when computing
summary information</p>
</td></tr>
<tr><td><code id="itemstats_+3A_use_ts">use_ts</code></td>
<td>
<p>logical; include information that is conditional on a
meaningful total score?</p>
</td></tr>
<tr><td><code id="itemstats_+3A_proportions">proportions</code></td>
<td>
<p>logical; include response proportion information for
each item?</p>
</td></tr>
<tr><td><code id="itemstats_+3A_ts.tables">ts.tables</code></td>
<td>
<p>logical; include mean/sd summary information
pertaining to the unweighted total score?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a list containing the summary statistics
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+empirical_plot">empirical_plot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# dichotomous data example
LSAT7full &lt;- expand.table(LSAT7)
head(LSAT7full)
itemstats(LSAT7full)

# behaviour with missing data
LSAT7full[1:5,1] &lt;- NA
itemstats(LSAT7full)

# data with no meaningful total score
head(SAT12)
itemstats(SAT12, use_ts=FALSE)

# extra total scores tables
dat &lt;- key2binary(SAT12,
                   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,
                           5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
itemstats(dat, ts.tables=TRUE)

# grouping information
group &lt;- gl(2, 300, labels=c('G1', 'G2'))
itemstats(dat, group=group)


#####
# polytomous data example
itemstats(Science)

# polytomous data with missing
newScience &lt;- Science
newScience[1:5,1] &lt;- NA
itemstats(newScience)

# unequal categories
newScience[,1] &lt;- ifelse(Science[,1] == 1, NA, Science[,1])
itemstats(newScience)

merged &lt;- data.frame(LSAT7full[1:392,], Science)
itemstats(merged)

</code></pre>

<hr>
<h2 id='key2binary'>Score a test by converting response patterns to binary data</h2><span id='topic+key2binary'></span>

<h3>Description</h3>

<p>The <code>key2binary</code> function will convert response pattern data to a
dichotomous format, given a response key.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>key2binary(fulldata, key, score_missing = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="key2binary_+3A_fulldata">fulldata</code></td>
<td>
<p>an object of class <code>data.frame</code>, <code>matrix</code>, or
<code>table</code> with the response patterns</p>
</td></tr>
<tr><td><code id="key2binary_+3A_key">key</code></td>
<td>
<p>a vector or matrix consisting of the 'correct' response to the items. Each
value/row corresponds to each column in <code>fulldata</code>. If the input is a matrix, multiple
scoring keys can be supplied for each item. NA values are used to indicate no scoring key (or
in the case of a matrix input, no additional scoring keys)</p>
</td></tr>
<tr><td><code id="key2binary_+3A_score_missing">score_missing</code></td>
<td>
<p>logical; should missing data elements be returned as incorrect (i.e., 0)?
If <code>FALSE</code>, all missing data terms will be kept as missing</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a numeric matrix with all the response patterns in
dichotomous format
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(SAT12)
head(SAT12)
key &lt;- c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)

dicho.SAT12 &lt;- key2binary(SAT12, key)
head(dicho.SAT12)

# multiple scoring keys
key2 &lt;- cbind(c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5),
              c(2,3,NA,1,rep(NA, 28)))
dicho.SAT12 &lt;- key2binary(SAT12, key2)

# keys from raw character responses
resp &lt;- as.data.frame(matrix(c(
  "B","B","D","D","E",
  "B","A","D","D","E",
  "B","A","D","C","E",
  "D","D","D","C","E",
  "B","C","A","D","A"), ncol=5, byrow=TRUE))

key &lt;- c("B", "D", "D", "C", "E")

d01 &lt;- key2binary(resp, key)
head(d01)

# score/don't score missing values
resp[1,1] &lt;- NA
d01NA &lt;- key2binary(resp, key) # without scoring
d01NA

d01 &lt;- key2binary(resp, key, score_missing = TRUE) # with scoring
d01


</code></pre>

<hr>
<h2 id='lagrange'>Lagrange test for freeing parameters</h2><span id='topic+lagrange'></span>

<h3>Description</h3>

<p>Lagrange (i.e., score) test to test whether parameters should be freed from a
more constrained baseline model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagrange(mod, parnum, SE.type = "Oakes", type = "Richardson", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lagrange_+3A_mod">mod</code></td>
<td>
<p>an estimated model</p>
</td></tr>
<tr><td><code id="lagrange_+3A_parnum">parnum</code></td>
<td>
<p>a vector, or list of vectors, containing one or more parameter
locations/sets of locations to be tested.
See objects returned from <code><a href="#topic+mod2values">mod2values</a></code> for the locations</p>
</td></tr>
<tr><td><code id="lagrange_+3A_se.type">SE.type</code></td>
<td>
<p>type of information matrix estimator to use. See <code><a href="#topic+mirt">mirt</a></code> for
further details</p>
</td></tr>
<tr><td><code id="lagrange_+3A_type">type</code></td>
<td>
<p>type of numerical algorithm passed to <code><a href="#topic+numerical_deriv">numerical_deriv</a></code> to
obtain the gradient terms</p>
</td></tr>
<tr><td><code id="lagrange_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code><a href="#topic+mirt">mirt</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+wald">wald</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
dat &lt;- expand.table(LSAT7)
mod &lt;- mirt(dat, 1, 'Rasch')
(values &lt;- mod2values(mod))

# test all fixed slopes individually
parnum &lt;- values$parnum[values$name == 'a1']
lagrange(mod, parnum)

# compare to LR test for first two slopes
mod2 &lt;- mirt(dat, 'F = 1-5
                   FREE = (1, a1)', 'Rasch')
coef(mod2, simplify=TRUE)$items
anova(mod, mod2)

mod2 &lt;- mirt(dat, 'F = 1-5
                   FREE = (2, a1)', 'Rasch')
coef(mod2, simplify=TRUE)$items
anova(mod, mod2)

mod2 &lt;- mirt(dat, 'F = 1-5
                   FREE = (3, a1)', 'Rasch')
coef(mod2, simplify=TRUE)$items
anova(mod, mod2)

# test slopes first two slopes and last three slopes jointly
lagrange(mod, list(parnum[1:2], parnum[3:5]))

# test all 5 slopes and first + last jointly
lagrange(mod, list(parnum[1:5], parnum[c(1, 5)]))


## End(Not run)
</code></pre>

<hr>
<h2 id='likert2int'>Convert ordered Likert-scale responses (character or factors) to integers</h2><span id='topic+likert2int'></span>

<h3>Description</h3>

<p>Given a matrix or data.frame object consisting of Likert responses return an
object of the same dimensions with integer values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>likert2int(x, levels = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="likert2int_+3A_x">x</code></td>
<td>
<p>a matrix of character values or data.frame of character/factor vectors</p>
</td></tr>
<tr><td><code id="likert2int_+3A_levels">levels</code></td>
<td>
<p>a named character vector indicating which integer values
should be assigned to which elements. If omitted, the order of the elements
will be determined after converting each column in <code>x</code> to a factor
variable</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+key2binary">key2binary</a></code>, <code><a href="#topic+poly2dich">poly2dich</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# simulate data

dat1 &lt;- matrix(sample(c('Disagree', 'Strongly Disagree', 'Agree',
                        'Neutral', 'Strongly Agree'), 1000*5, replace=TRUE),
               nrow=1000, ncol=5)
dat1[2,2] &lt;- dat1[3,3] &lt;- dat1[1,3] &lt;- NA # NAs added for flavour
dat2 &lt;- matrix(sample(c('D', 'SD', 'A', 'N', 'SA'), 1000*5, replace=TRUE),
               nrow=1000, ncol=5)
dat &lt;- cbind(dat1, dat2)

# separately
intdat1 &lt;- likert2int(dat1)
head(dat1)
head(intdat1)

# more useful with explicit levels
lvl1 &lt;- c('Strongly Disagree'=1, 'Disagree'=2, 'Neutral'=3, 'Agree'=4,
          'Strongly Agree'=5)
intdat1 &lt;- likert2int(dat1, levels = lvl1)
head(dat1)
head(intdat1)

# second data
lvl2 &lt;- c('SD'=1, 'D'=2, 'N'=3, 'A'=4, 'SA'=5)
intdat2 &lt;- likert2int(dat2, levels = lvl2)
head(dat2)
head(intdat2)

# full dataset (using both mapping schemes)
intdat &lt;- likert2int(dat, levels = c(lvl1, lvl2))
head(dat)
head(intdat)


#####
# data.frame as input with ordered factors

dat1 &lt;- data.frame(dat1)
dat2 &lt;- data.frame(dat2)
dat.old &lt;- cbind(dat1, dat2)
colnames(dat.old) &lt;- paste0('Item_', 1:10)
str(dat.old) # factors are leveled alphabetically by default

# create explicit ordering in factor variables
for(i in 1:ncol(dat1))
   levels(dat1[[i]]) &lt;- c('Strongly Disagree', 'Disagree', 'Neutral', 'Agree',
                          'Strongly Agree')

for(i in 1:ncol(dat2))
   levels(dat2[[i]]) &lt;- c('SD', 'D', 'N', 'A', 'SA')

dat &lt;- cbind(dat1, dat2)
colnames(dat) &lt;- colnames(dat.old)
str(dat) # note ordering

intdat &lt;- likert2int(dat)
head(dat)
head(intdat)


## End(Not run)
</code></pre>

<hr>
<h2 id='logLik-method'>Extract log-likelihood</h2><span id='topic+logLik-method'></span><span id='topic+logLik+2CSingleGroupClass-method'></span><span id='topic+logLik+2CMixtureClass-method'></span><span id='topic+logLik+2CMultipleGroupClass-method'></span><span id='topic+logLik+2CMixedClass-method'></span><span id='topic+logLik+2CDiscreteClass-method'></span>

<h3>Description</h3>

<p>Extract the observed-data log-likelihood.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SingleGroupClass'
logLik(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik-method_+3A_object">object</code></td>
<td>
<p>an object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>MixedClass</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x &lt;- mirt(Science, 1)
logLik(x)


## End(Not run)
</code></pre>

<hr>
<h2 id='LSAT6'>Description of LSAT6 data</h2><span id='topic+LSAT6'></span>

<h3>Description</h3>

<p>Data from Thissen (1982); contains 5 dichotomously scored
items obtained from the Law School Admissions Test, section 6.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Thissen, D. (1982). Marginal maximum likelihood estimation for the one-parameter logistic model.
<em>Psychometrika, 47</em>, 175-186.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
dat &lt;- expand.table(LSAT6)
head(dat)
itemstats(dat)

model &lt;- 'F = 1-5
         CONSTRAIN = (1-5, a1)'
(mod &lt;- mirt(dat, model))
M2(mod)
itemfit(mod)
coef(mod, simplify=TRUE)

# equivalentely, but with a different parameterization
mod2 &lt;- mirt(dat, 1, itemtype = 'Rasch')
anova(mod, mod2) #equal
M2(mod2)
itemfit(mod2)
coef(mod2, simplify=TRUE)
sqrt(coef(mod2)$GroupPars[2]) #latent SD equal to the slope in mod


## End(Not run)
</code></pre>

<hr>
<h2 id='LSAT7'>Description of LSAT7 data</h2><span id='topic+LSAT7'></span>

<h3>Description</h3>

<p>Data from Bock &amp; Lieberman (1970); contains 5 dichotomously scored
items obtained from the Law School Admissions Test, section 7.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Bock, R. D., &amp; Lieberman, M. (1970). Fitting a response model for <em>n</em>
dichotomously scored items. <em>Psychometrika, 35</em>(2), 179-197.
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
dat &lt;- expand.table(LSAT7)
head(dat)
itemstats(dat)

(mod &lt;- mirt(dat, 1))
coef(mod)

## End(Not run)
</code></pre>

<hr>
<h2 id='M2'>Compute the M2 model fit statistic</h2><span id='topic+M2'></span>

<h3>Description</h3>

<p>Computes the M2 (Maydeu-Olivares &amp; Joe, 2006) statistic when all data are dichotomous,
the collapsed M2* statistic (collapsing over univariate and bivariate response categories;
see Cai and Hansen, 2013), and the hybrid C2 statistic which only collapses only the bivariate
moments (Cai and Monro, 2014). The C2 variant is mainly useful when polytomous response models
do not have sufficient degrees of freedom to compute M2*. This function
also computes associated fit indices that are based on
fitting the null model. Supports single and multiple-group models.
If the latent trait density was approximated (e.g., Davidian curves, Empirical histograms, etc)
then passing <code>use_dentype_estimate = TRUE</code> will use the internally saved quadrature and
density components (where applicable).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>M2(
  obj,
  type = "M2*",
  calcNull = TRUE,
  na.rm = FALSE,
  quadpts = NULL,
  theta_lim = c(-6, 6),
  CI = 0.9,
  residmat = FALSE,
  QMC = FALSE,
  suppress = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="M2_+3A_obj">obj</code></td>
<td>
<p>an estimated model object from the mirt package</p>
</td></tr>
<tr><td><code id="M2_+3A_type">type</code></td>
<td>
<p>type of fit statistic to compute. Options are &quot;M2&quot;, &quot;M2*&quot; for the univariate and
bivariate collapsed version of the M2 statistic (&quot;M2&quot; currently limited to dichotomous
response data only), and &quot;C2&quot; for a hybrid between
M2 and M2* where only the bivariate moments are collapsed</p>
</td></tr>
<tr><td><code id="M2_+3A_calcnull">calcNull</code></td>
<td>
<p>logical; calculate statistics for the null model as well?
Allows for statistics such as the limited information TLI and CFI. Only valid when items all
have a suitable null model (e.g., those created via <code><a href="#topic+createItem">createItem</a></code> will not)</p>
</td></tr>
<tr><td><code id="M2_+3A_na.rm">na.rm</code></td>
<td>
<p>logical; remove rows with any missing values? The M2 family of statistics
requires a complete dataset in order to be well defined</p>
</td></tr>
<tr><td><code id="M2_+3A_quadpts">quadpts</code></td>
<td>
<p>number of quadrature points to use during estimation. If <code>NULL</code>,
a suitable value will be chosen based
on the rubric found in <code><a href="#topic+fscores">fscores</a></code></p>
</td></tr>
<tr><td><code id="M2_+3A_theta_lim">theta_lim</code></td>
<td>
<p>lower and upper range to evaluate latent trait integral for each dimension</p>
</td></tr>
<tr><td><code id="M2_+3A_ci">CI</code></td>
<td>
<p>numeric value from 0 to 1 indicating the range of the confidence interval for
RMSEA. Default returns the 90% interval</p>
</td></tr>
<tr><td><code id="M2_+3A_residmat">residmat</code></td>
<td>
<p>logical; return the residual matrix used to compute the SRMSR statistic?
Only the lower triangle of the residual correlation matrix will be returned
(the upper triangle is filled with NA's)</p>
</td></tr>
<tr><td><code id="M2_+3A_qmc">QMC</code></td>
<td>
<p>logical; use quasi-Monte Carlo integration? Useful for higher dimensional models.
If <code>quadpts</code> not specified, 5000 nodes are used by default</p>
</td></tr>
<tr><td><code id="M2_+3A_suppress">suppress</code></td>
<td>
<p>a numeric value indicating which parameter residual dependency combinations
to flag as being too high. Absolute values for the standardized residuals greater than
this value will be returned, while all values less than this value will be set to NA.
Must be used in conjunction with the argument <code>residmat = TRUE</code></p>
</td></tr>
<tr><td><code id="M2_+3A_...">...</code></td>
<td>
<p>additional arguments to pass</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a data.frame object with the M2-type statistic, along with the degrees of freedom,
p-value, RMSEA (with 90% confidence interval), SRMSR for each group (if all items were ordinal),
and optionally the TLI and CFI model fit statistics if <code>calcNull = TRUE</code>.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Cai, L. &amp; Hansen, M. (2013). Limited-information goodness-of-fit testing of
hierarchical item factor models. <em>British Journal of Mathematical and Statistical
Psychology, 66</em>, 245-276.
</p>
<p>Cai, L. &amp; Monro, S. (2014). <em>A new statistic for evaluating item response theory
models for ordinal data</em>. National Center for Research on Evaluation, Standards,
&amp; Student Testing. Technical Report.
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Maydeu-Olivares, A. &amp; Joe, H. (2006). Limited information goodness-of-fit testing in
multidimensional contingency tables. <em>Psychometrika, 71</em>, 713-732.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- as.matrix(expand.table(LSAT7))
(mod1 &lt;- mirt(dat, 1))
M2(mod1)
resids &lt;- M2(mod1, residmat=TRUE) #lower triangle of residual correlation matrix
resids
summary(resids[lower.tri(resids)])

# M2 with missing data present
dat[sample(1:prod(dim(dat)), 250)] &lt;- NA
mod2 &lt;- mirt(dat, 1)
# Compute stats by removing missing data row-wise
M2(mod2, na.rm = TRUE)

# C2 statistic (useful when polytomous IRT models have too few df)
pmod &lt;- mirt(Science, 1)
# This fails with too few df:
# M2(pmod)
# This, however, works:
M2(pmod, type = 'C2')


## End(Not run)
</code></pre>

<hr>
<h2 id='marginal_rxx'>Function to calculate the marginal reliability</h2><span id='topic+marginal_rxx'></span>

<h3>Description</h3>

<p>Given an estimated model and a prior density function, compute the marginal reliability
(Thissen and Wainer, 2001). This is only available for unidimensional tests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>marginal_rxx(mod, density = dnorm, var_theta = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="marginal_rxx_+3A_mod">mod</code></td>
<td>
<p>an object of class <code>'SingleGroupClass'</code></p>
</td></tr>
<tr><td><code id="marginal_rxx_+3A_density">density</code></td>
<td>
<p>a density function to use for integration. Default assumes the latent traits are from a
normal (Gaussian) distribution</p>
</td></tr>
<tr><td><code id="marginal_rxx_+3A_var_theta">var_theta</code></td>
<td>
<p>variance of the Theta distribution (typically 1 for many fitted
IRT models)</p>
</td></tr>
<tr><td><code id="marginal_rxx_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the density function</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Thissen, D. and Wainer, H. (2001). Test Scoring. Lawrence Erlbaum Associates.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+empirical_rxx">empirical_rxx</a></code>, <code><a href="#topic+extract.group">extract.group</a></code>, <code><a href="#topic+testinfo">testinfo</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

dat &lt;- expand.table(deAyala)
mod &lt;- mirt(dat, 1)

# marginal estimate
marginal_rxx(mod)

## Not run: 

# empirical estimate (assuming the same prior)
fscores(mod, returnER = TRUE)

# empirical rxx the alternative way, given theta scores and SEs
fs &lt;- fscores(mod, full.scores.SE=TRUE)
head(fs)
empirical_rxx(fs)


## End(Not run)
</code></pre>

<hr>
<h2 id='MDIFF'>Compute multidimensional difficulty index</h2><span id='topic+MDIFF'></span>

<h3>Description</h3>

<p>Returns a matrix containing the MDIFF values (Reckase, 2009). Only supported for items of class
'dich' and 'graded'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MDIFF(x, which.items = NULL, group = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MDIFF_+3A_x">x</code></td>
<td>
<p>an object of class 'SingleGroupClass', or an object of class 'MultipleGroupClass' if a suitable
<code>group</code> input were supplied</p>
</td></tr>
<tr><td><code id="MDIFF_+3A_which.items">which.items</code></td>
<td>
<p>a vector indicating which items to select. If NULL is used
(the default) then MDISC will be computed for all items</p>
</td></tr>
<tr><td><code id="MDIFF_+3A_group">group</code></td>
<td>
<p>group argument to pass to <code><a href="#topic+extract.group">extract.group</a></code> function. Required when the input object is
a multiple-group model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Reckase, M. D. (2009). Multidimensional Item Response Theory. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract.group">extract.group</a></code>, <code><a href="#topic+MDISC">MDISC</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

mod &lt;- mirt(Science, 2)
MDIFF(mod)

mod &lt;- mirt(expand.table(LSAT7), 2)
MDIFF(mod)


## End(Not run)
</code></pre>

<hr>
<h2 id='mdirt'>Multidimensional discrete item response theory</h2><span id='topic+mdirt'></span>

<h3>Description</h3>

<p><code>mdirt</code> fits a variety of item response models with discrete latent variables.
These include, but are not limited to, latent class analysis, multidimensional latent
class models, multidimensional discrete latent class models, DINA/DINO models,
grade of measurement models, C-RUM, and so on. If response models are not defined explicitly
then customized models can defined using the <code><a href="#topic+createItem">createItem</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdirt(
  data,
  model,
  customTheta = NULL,
  structure = NULL,
  item.Q = NULL,
  nruns = 1,
  method = "EM",
  covdata = NULL,
  formula = NULL,
  itemtype = "lca",
  optimizer = "nlminb",
  return_max = TRUE,
  group = NULL,
  GenRandomPars = FALSE,
  verbose = TRUE,
  pars = NULL,
  technical = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mdirt_+3A_data">data</code></td>
<td>
<p>a <code>matrix</code> or <code>data.frame</code> that consists of
numerically ordered data, with missing data coded as <code>NA</code></p>
</td></tr>
<tr><td><code id="mdirt_+3A_model">model</code></td>
<td>
<p>number of mutually exclusive classes to fit, or alternatively a more specific
<code><a href="#topic+mirt.model">mirt.model</a></code> definition (which reflects the so-called Q-matrix).
Note that when using a <code><a href="#topic+mirt.model">mirt.model</a></code>,
the order with which the syntax factors/attributes are defined are associated with the
columns in the <code>customTheta</code> input</p>
</td></tr>
<tr><td><code id="mdirt_+3A_customtheta">customTheta</code></td>
<td>
<p>input passed to <code>technical = list(customTheta = ...)</code>, but is included
directly in this function for convenience. This input is most interesting for discrete latent models
because it allows customized patterns of latent classes (i.e., defines the possible combinations
of the latent attribute profile). The default builds the pattern <code>customTheta = diag(model)</code>,
which is the typical pattern for the traditional latent class analysis whereby class
membership mutually distinct and exhaustive. See <code><a href="#topic+thetaComb">thetaComb</a></code> for a quick method
to generate a matrix with all possible combinations</p>
</td></tr>
<tr><td><code id="mdirt_+3A_structure">structure</code></td>
<td>
<p>an R formula allowing the profile probability patterns (i.e., the structural component of
the model) to be fitted according to a log-linear model. When <code>NULL</code>, all profile probabilities
(except one) will be estimated. Use of this input requires that the <code>customTheta</code> input is supplied,
and that the column names in this matrix match the names found within this formula</p>
</td></tr>
<tr><td><code id="mdirt_+3A_item.q">item.Q</code></td>
<td>
<p>a list of item-level Q-matrices indicating how the respective categories should be
modeled by the underlying attributes. Each matrix must represent a <code class="reqn">K_i \times A</code> matrix,
where <code class="reqn">K_i</code> represents the number of categories for the ith item, and <code class="reqn">A</code> is the number
of attributes included in the <code>Theta</code> matrix; otherwise, a value of<code>NULL</code> will default
to a matrix consisting of 1's for each <code class="reqn">K_i \times A</code> element except for the first row, which
contains only 0's for proper identification. Incidentally, the first row of each matrix <code>must</code>
contain only 0's so that the first category represents the reference category for identification</p>
</td></tr>
<tr><td><code id="mdirt_+3A_nruns">nruns</code></td>
<td>
<p>a numeric value indicating how many times the model should be fit to the data
when using random starting values. If greater than 1, <code>GenRandomPars</code> is set to true
by default</p>
</td></tr>
<tr><td><code id="mdirt_+3A_method">method</code></td>
<td>
<p>estimation method. Can be 'EM' or 'BL' (see <code><a href="#topic+mirt">mirt</a></code> for more details)</p>
</td></tr>
<tr><td><code id="mdirt_+3A_covdata">covdata</code></td>
<td>
<p>a data.frame of data used for latent regression models</p>
</td></tr>
<tr><td><code id="mdirt_+3A_formula">formula</code></td>
<td>
<p>an R formula (or list of formulas) indicating how the latent traits
can be regressed using external covariates in <code>covdata</code>. If a named list
of formulas is supplied (where the names correspond to the latent trait/attribute names in <code>model</code>)
then specific regression effects can be estimated for each factor. Supplying a single formula
will estimate the regression parameters for all latent variables by default</p>
</td></tr>
<tr><td><code id="mdirt_+3A_itemtype">itemtype</code></td>
<td>
<p>a vector indicating the itemtype associated with each item.
For discrete models this is limited to only 'lca' or items defined using a
<code><a href="#topic+createItem">createItem</a></code> definition</p>
</td></tr>
<tr><td><code id="mdirt_+3A_optimizer">optimizer</code></td>
<td>
<p>optimizer used for the M-step, set to <code>'nlminb'</code> by default.
See <code><a href="#topic+mirt">mirt</a></code> for more details</p>
</td></tr>
<tr><td><code id="mdirt_+3A_return_max">return_max</code></td>
<td>
<p>logical; when <code>nruns &gt; 1</code>, return the model that has the most optimal
maximum likelihood criteria? If FALSE, returns a list of all the estimated objects</p>
</td></tr>
<tr><td><code id="mdirt_+3A_group">group</code></td>
<td>
<p>a factor variable indicating group membership used for multiple group analyses</p>
</td></tr>
<tr><td><code id="mdirt_+3A_genrandompars">GenRandomPars</code></td>
<td>
<p>logical; use random starting values</p>
</td></tr>
<tr><td><code id="mdirt_+3A_verbose">verbose</code></td>
<td>
<p>logical; turn on messages to the R console</p>
</td></tr>
<tr><td><code id="mdirt_+3A_pars">pars</code></td>
<td>
<p>used for modifying starting values; see <code><a href="#topic+mirt">mirt</a></code> for details</p>
</td></tr>
<tr><td><code id="mdirt_+3A_technical">technical</code></td>
<td>
<p>list of lower-level inputs. See <code><a href="#topic+mirt">mirt</a></code> for details</p>
</td></tr>
<tr><td><code id="mdirt_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the estimation engine. See <code><a href="#topic+mirt">mirt</a></code>
for more details and examples</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Posterior classification accuracy for each response pattern may be obtained
via the <code><a href="#topic+fscores">fscores</a></code> function. The <code>summary()</code> function will display
the category probability values given the class membership, which can also
be displayed graphically with <code>plot()</code>, while <code>coef()</code>
displays the raw coefficient values (and their standard errors, if estimated). Finally,
<code>anova()</code> is used to compare nested models, while
<code><a href="#topic+M2">M2</a></code> and <code><a href="#topic+itemfit">itemfit</a></code> may be used for model fitting purposes.
</p>


<h3>'lca' model definition</h3>

<p>The latent class IRT model with two latent classes has the form
</p>
<p style="text-align: center;"><code class="reqn">P(x = k|\theta_1, \theta_2, a1, a2) = \frac{exp(a1 \theta_1 + a2 \theta_2)}{
  \sum_j^K exp(a1 \theta_1 + a2 \theta_2)}</code>
</p>

<p>where the <code class="reqn">\theta</code> values generally take on discrete points (such as 0 or 1).
For proper identification, the first category slope parameters
(<code class="reqn">a1</code> and <code class="reqn">a2</code>) are never freely estimated. Alternatively, supplying a different
grid of <code class="reqn">\theta</code> values will allow the estimation of similar models (multidimensional
discrete models, grade of membership, etc.). See the examples below.
</p>
<p>When the <code>item.Q</code> for is utilized, the above equation can be understood as
</p>
<p style="text-align: center;"><code class="reqn">P(x = k|\theta_1, \theta_2, a1, a2) = \frac{exp(a1 \theta_1 Q_{j1} + a2 \theta_2 Q_{j2})}{
  \sum_j^K exp(a1 \theta_1 Q_{j1} + a2 \theta_2 Q_{j2})}</code>
</p>

<p>where by construction <code>Q</code> is a <code class="reqn">K_i \times A</code> matrix indicating whether the category should
be modeled according to the latent class structure. For the standard latent class model, the Q-matrix
has as many rows as categories, as many columns as the number of classes/attributes modeled,
and consist of 0's in the first row and 1's elsewhere. This of course can be over-written by passing
an alternative <code>item.Q</code> definition for each respective item.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
</p>
<p>Proctor, C. H. (1970). A probabilistic formulation and statistical analysis for Guttman scaling.
<em>Psychometrika, 35</em>, 73-78.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+thetaComb">thetaComb</a></code>, <code><a href="#topic+fscores">fscores</a></code>, <code><a href="#topic+mirt.model">mirt.model</a></code>, <code><a href="#topic+M2">M2</a></code>,
<code><a href="#topic+itemfit">itemfit</a></code>, <code><a href="#topic+boot.mirt">boot.mirt</a></code>, <code><a href="#topic+mirtCluster">mirtCluster</a></code>,
<code><a href="#topic+wald">wald</a></code>, <code><a href="#topic+coef-method">coef-method</a></code>, <code><a href="#topic+summary-method">summary-method</a></code>,
<code><a href="#topic+anova-method">anova-method</a></code>, <code><a href="#topic+residuals-method">residuals-method</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# LSAT6 dataset
dat &lt;- expand.table(LSAT6)

# fit with 2-3 latent classes
(mod2 &lt;- mdirt(dat, 2))
## Not run: 
(mod3 &lt;- mdirt(dat, 3))
summary(mod2)
residuals(mod2)
residuals(mod2, type = 'exp')
anova(mod2, mod3)
M2(mod2)
itemfit(mod2)

# generate classification plots
plot(mod2)
plot(mod2, facet_items = FALSE)
plot(mod2, profile = TRUE)

# available for polytomous data
mod &lt;- mdirt(Science, 2)
summary(mod)
plot(mod)
plot(mod, profile=TRUE)

# classification based on response patterns
fscores(mod2, full.scores = FALSE)

# classify individuals either with the largest posterior probability.....
fs &lt;- fscores(mod2)
head(fs)
classes &lt;- 1:2
class_max &lt;- classes[apply(apply(fs, 1, max) == fs, 1, which)]
table(class_max)

# ... or by probability sampling (i.e., plausible value draws)
class_prob &lt;- apply(fs, 1, function(x) sample(1:2, 1, prob=x))
table(class_prob)

# plausible value imputations for stochastic classification in both classes
pvs &lt;- fscores(mod2, plausible.draws=10)
tabs &lt;- lapply(pvs, function(x) apply(x, 2, table))
tabs[[1]]


# fit with random starting points (run in parallel to save time)
if(interactive()) mirtCluster()
mod &lt;- mdirt(dat, 2, nruns=10)

#--------------------------
# Grade of measurement model

# define a custom Theta grid for including a 'fuzzy' class membership
(Theta &lt;- matrix(c(1, 0, .5, .5, 0, 1), nrow=3 , ncol=2, byrow=TRUE))
(mod_gom &lt;- mdirt(dat, 2, customTheta = Theta))
summary(mod_gom)

#-----------------
# Multidimensional discrete latent class model

dat &lt;- key2binary(SAT12,
     key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))

# define Theta grid for three latent classes
(Theta &lt;- thetaComb(0:1, 3))
(mod_discrete &lt;- mdirt(dat, 3, customTheta = Theta))
summary(mod_discrete)

# Located latent class model
model &lt;- mirt.model('C1 = 1-32
                     C2 = 1-32
                     C3 = 1-32
                     CONSTRAIN = (1-32, a1), (1-32, a2), (1-32, a3)')
(mod_located &lt;- mdirt(dat, model, customTheta = diag(3)))
summary(mod_located)

#-----------------
### DINA model example
# generate some suitable data for a two dimensional DINA application
#     (first columns are intercepts)
set.seed(1)
Theta &lt;- expand.table(matrix(c(1,0,0,0,
                               1,1,0,0,
                               1,0,1,0,
                               1,1,1,1), 4, 4, byrow=TRUE),
                      freq = c(200,200,100,500))
a &lt;- matrix(c(rnorm(15, -1.5, .5), rlnorm(5, .2, .3), numeric(15), rlnorm(5, .2, .3),
              numeric(15), rlnorm(5, .2, .3)), 15, 4)

guess &lt;- plogis(a[11:15,1]) # population guess
slip &lt;- 1 - plogis(rowSums(a[11:15,])) # population slip

dat &lt;- simdata(a, Theta=Theta, itemtype = 'lca')

# first column is the intercept, 2nd and 3rd are attributes
theta &lt;- cbind(1, thetaComb(0:1, 2))
theta &lt;- cbind(theta, theta[,2] * theta[,3]) #DINA interaction of main attributes
model &lt;- mirt.model('Intercept = 1-15
                     A1 = 1-5
                     A2 = 6-10
                     A1A2 = 11-15')

# last 5 items are DINA (first 10 are unidimensional C-RUMs)
DINA &lt;- mdirt(dat, model, customTheta = theta)
coef(DINA, simplify=TRUE)
summary(DINA)
M2(DINA) # fits well (as it should)

cfs &lt;- coef(DINA, simplify=TRUE)$items[11:15,]
cbind(guess, estguess = plogis(cfs[,1]))
cbind(slip, estslip = 1 - plogis(rowSums(cfs)))


### DINO model example
theta &lt;- cbind(1, thetaComb(0:1, 2))
# define theta matrix with negative interaction term
(theta &lt;- cbind(theta, -theta[,2] * theta[,3]))

model &lt;- mirt.model('Intercept = 1-15
                     A1 = 1-5, 11-15
                     A2 = 6-15
                     Yoshi = 11-15
                     CONSTRAIN = (11,a2,a3,a4), (12,a2,a3,a4), (13,a2,a3,a4),
                                 (14,a2,a3,a4), (15,a2,a3,a4)')

# last five items are DINOs (first 10 are unidimensional C-RUMs)
DINO &lt;- mdirt(dat, model, customTheta = theta)
coef(DINO, simplify=TRUE)
summary(DINO)
M2(DINO) #doesn't fit as well, because not the generating model

## C-RUM (analogous to MIRT model)
theta &lt;- cbind(1, thetaComb(0:1, 2))
model &lt;- mirt.model('Intercept = 1-15
                     A1 = 1-5, 11-15
                     A2 = 6-15')

CRUM &lt;- mdirt(dat, model, customTheta = theta)
coef(CRUM, simplify=TRUE)
summary(CRUM)

# good fit, but over-saturated (main effects for items 11-15 can be set to 0)
M2(CRUM)

#------------------
# multidimensional latent class model

dat &lt;- key2binary(SAT12,
     key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))

# 5 latent classes within 2 different sets of items
model &lt;- mirt.model('C1 = 1-16
                     C2 = 1-16
                     C3 = 1-16
                     C4 = 1-16
                     C5 = 1-16
                     C6 = 17-32
                     C7 = 17-32
                     C8 = 17-32
                     C9 = 17-32
                     C10 = 17-32
                     CONSTRAIN = (1-16, a1), (1-16, a2), (1-16, a3), (1-16, a4), (1-16, a5),
                       (17-32, a6), (17-32, a7), (17-32, a8), (17-32, a9), (17-32, a10)')

theta &lt;- diag(10) # defined explicitly. Otherwise, this profile is assumed
mod &lt;- mdirt(dat, model, customTheta = theta)
coef(mod, simplify=TRUE)
summary(mod)

#------------------
# multiple group with constrained group probabilities
 dat &lt;- key2binary(SAT12,
   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
group &lt;- rep(c('G1', 'G2'), each = nrow(SAT12)/2)
Theta &lt;- diag(2)

# the latent class parameters are technically located in the (nitems + 1) location
model &lt;- mirt.model('A1 = 1-32
                     A2 = 1-32
                     CONSTRAINB = (33, c1)')
mod &lt;- mdirt(dat, model, group = group, customTheta = Theta)
coef(mod, simplify=TRUE)
summary(mod)


#------------------
# Probabilistic Guttman Model (Proctor, 1970)

# example analysis can also be found in the sirt package (see ?prob.guttman)
data(data.read, package = 'sirt')
head(data.read)

Theta &lt;- matrix(c(1,0,0,0,
                  1,1,0,0,
                  1,1,1,0,
                  1,1,1,1), 4, byrow=TRUE)

model &lt;- mirt.model("INTERCEPT = 1-12
                     C1 = 1,7,9,11
                     C2 = 2,5,8,10,12
                     C3 = 3,4,6")

mod &lt;- mdirt(data.read, model, customTheta=Theta)
summary(mod)

M2(mod)
itemfit(mod)



## End(Not run)
</code></pre>

<hr>
<h2 id='MDISC'>Compute multidimensional discrimination index</h2><span id='topic+MDISC'></span>

<h3>Description</h3>

<p>Returns a vector containing the MDISC values for each item in the model input object (Reckase, 2009).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MDISC(x, group = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MDISC_+3A_x">x</code></td>
<td>
<p>an object of class 'SingleGroupClass', or an object of class 'MultipleGroupClass' if a suitable
<code>group</code> input were supplied</p>
</td></tr>
<tr><td><code id="MDISC_+3A_group">group</code></td>
<td>
<p>group argument to pass to <code><a href="#topic+extract.group">extract.group</a></code> function. Required when the input object is
a multiple-group model</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Reckase, M. D. (2009). Multidimensional Item Response Theory. Springer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract.group">extract.group</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

mod &lt;- mirt(Science, 2)
MDISC(mod)


## End(Not run)
</code></pre>

<hr>
<h2 id='mirt'>Full-Information Item Factor Analysis (Multidimensional Item Response
Theory)</h2><span id='topic+mirt'></span>

<h3>Description</h3>

<p><code>mirt</code> fits a maximum likelihood (or maximum a posteriori) factor analysis model
to any mixture of dichotomous and polytomous data under the item response theory paradigm
using either Cai's (2010) Metropolis-Hastings Robbins-Monro (MHRM) algorithm, with
an EM algorithm approach outlined by Bock and Aitkin (1981) using rectangular or
quasi-Monte Carlo integration grids, or with the stochastic EM (i.e., the first two stages
of the MH-RM algorithm). Models containing 'explanatory' person or item level predictors
can only be included by using the <code><a href="#topic+mixedmirt">mixedmirt</a></code> function, though latent
regression models can be fit using the <code>formula</code> input in this function.
Tests that form a two-tier or bi-factor structure should be estimated with the
<code><a href="#topic+bfactor">bfactor</a></code> function, which uses a dimension reduction EM algorithm for
modeling item parcels.  Multiple group analyses (useful for DIF and DTF testing) are
also available using the <code><a href="#topic+multipleGroup">multipleGroup</a></code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mirt(
  data,
  model = 1,
  itemtype = NULL,
  guess = 0,
  upper = 1,
  SE = FALSE,
  covdata = NULL,
  formula = NULL,
  SE.type = "Oakes",
  method = "EM",
  optimizer = NULL,
  dentype = "Gaussian",
  pars = NULL,
  constrain = NULL,
  calcNull = FALSE,
  draws = 5000,
  survey.weights = NULL,
  quadpts = NULL,
  TOL = NULL,
  gpcm_mats = list(),
  grsm.block = NULL,
  rsm.block = NULL,
  monopoly.k = 1L,
  key = NULL,
  large = FALSE,
  GenRandomPars = FALSE,
  accelerate = "Ramsay",
  verbose = TRUE,
  solnp_args = list(),
  nloptr_args = list(),
  spline_args = list(),
  control = list(),
  technical = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mirt_+3A_data">data</code></td>
<td>
<p>a <code>matrix</code> or <code>data.frame</code> that consists of
numerically ordered data, with missing data coded as <code>NA</code> (to convert from an ordered factor
<code>data.frame</code> see <code><a href="base.html#topic+data.matrix">data.matrix</a></code>)</p>
</td></tr>
<tr><td><code id="mirt_+3A_model">model</code></td>
<td>
<p>a string to be passed (or an object returned from) <code><a href="#topic+mirt.model">mirt.model</a></code>,
declaring how the IRT model is to be estimated (loadings, constraints, priors, etc).
For exploratory IRT models, a single numeric value indicating the number
of factors to extract is also supported. Default is 1, indicating that a unidimensional
model will be fit unless otherwise specified</p>
</td></tr>
<tr><td><code id="mirt_+3A_itemtype">itemtype</code></td>
<td>
<p>type of items to be modeled, declared as a vector for each item or a single value
which will be recycled for each item. The <code>NULL</code> default assumes that the items follow a graded or
2PL structure, however they may be changed to the following:
</p>

<ul>
<li> <p><code>'Rasch'</code> - Rasch/partial credit model by constraining slopes to 1 and freely estimating
the variance parameters (alternatively, can be specified by applying equality constraints to the
slope parameters in <code>'gpcm'</code>; Rasch, 1960)
</p>
</li>
<li> <p><code>'2PL'</code>, <code>'3PL'</code>, <code>'3PLu'</code>, and <code>'4PL'</code> - 2-4 parameter logistic model,
where <code>3PL</code> estimates the lower asymptote only while <code>3PLu</code> estimates the upper asymptote only
(Lord and Novick, 1968; Lord, 1980)
</p>
</li>
<li> <p><code>'5PL'</code> - 5 parameter logistic model to estimate asymmetric logistic
response curves. Currently restricted to unidimensional models
</p>
</li>
<li> <p><code>'CLL'</code> - complementary log-log link model.
Currently restricted to unidimensional models
</p>
</li>
<li> <p><code>'ULL'</code> - unipolar log-logistic model (Lucke, 2015). Note the use of this itemtype
will automatically use a log-normal distribution for the latent traits
</p>
</li>
<li> <p><code>'graded'</code> - graded response model (Samejima, 1969)
</p>
</li>
<li> <p><code>'grsm'</code> - graded ratings scale model in the
classical IRT parameterization (restricted to unidimensional models; Muraki, 1992)
</p>
</li>
<li> <p><code>'gpcm'</code> and <code>'gpcmIRT'</code> - generalized partial credit model in the slope-intercept
and classical parameterization. <code>'gpcmIRT'</code> is restricted to unidimensional models. Note that
optional scoring matrices for <code>'gpcm'</code> are available with the <code>gpcm_mats</code> input (Muraki, 1992)
</p>
</li>
<li> <p><code>'rsm'</code> - Rasch rating scale model using the <code>'gpcmIRT'</code> structure
(unidimensional only; Andrich, 1978)
</p>
</li>
<li> <p><code>'nominal'</code> - nominal response model (Bock, 1972)
</p>
</li>
<li> <p><code>'ideal'</code> - dichotomous ideal point model (Maydeu-Olivares, 2006)
</p>
</li>
<li> <p><code>'ggum'</code> - generalized graded unfolding model (Roberts, Donoghue, &amp; Laughlin, 2000)
and its multidimensional extension
</p>
</li>
<li> <p><code>'sequential'</code> - multidimensional sequential response model (Tutz, 1990) in slope-intercept form
</p>
</li>
<li> <p><code>'Tutz'</code> - same as the <code>'sequential'</code> itemtype, except the slopes are fixed to 1
and the latent variance terms are freely estimated (similar to the <code>'Rasch'</code> itemtype input)
</p>
</li>
<li> <p><code>'PC2PL'</code> and <code>'PC3PL'</code> - 2-3 parameter partially compensatory model.
Note that constraining the slopes to be equal across items will reduce the model to
Embretson's (a.k.a. Whitely's) multicomponent model (1980).
</p>
</li>
<li> <p><code>'2PLNRM'</code>, <code>'3PLNRM'</code>, <code>'3PLuNRM'</code>, and <code>'4PLNRM'</code> - 2-4 parameter nested
logistic model, where <code>3PLNRM</code> estimates the lower asymptote only while <code>3PLuNRM</code> estimates
the upper asymptote only (Suh and Bolt, 2010)
</p>
</li>
<li> <p><code>'spline'</code> - spline response model with the <code><a href="splines.html#topic+bs">bs</a></code> (default)
or the <code><a href="splines.html#topic+ns">ns</a></code> function (Winsberg, Thissen, and Wainer, 1984)
</p>
</li>
<li> <p><code>'monopoly'</code> - monotonic polynomial model for unidimensional tests
for dichotomous and polytomous response data (Falk and Cai, 2016)
</p>
</li></ul>

<p>Additionally, user defined item classes can also be defined using the <code><a href="#topic+createItem">createItem</a></code> function</p>
</td></tr>
<tr><td><code id="mirt_+3A_guess">guess</code></td>
<td>
<p>fixed pseudo-guessing parameters. Can be entered as a single
value to assign a global guessing parameter or may be entered as a numeric
vector corresponding to each item</p>
</td></tr>
<tr><td><code id="mirt_+3A_upper">upper</code></td>
<td>
<p>fixed upper bound parameters for 4-PL model. Can be entered as a single
value to assign a global guessing parameter or may be entered as a numeric
vector corresponding to each item</p>
</td></tr>
<tr><td><code id="mirt_+3A_se">SE</code></td>
<td>
<p>logical; estimate the standard errors by computing the parameter information matrix?
See <code>SE.type</code> for the type of estimates available</p>
</td></tr>
<tr><td><code id="mirt_+3A_covdata">covdata</code></td>
<td>
<p>a data.frame of data used for latent regression models</p>
</td></tr>
<tr><td><code id="mirt_+3A_formula">formula</code></td>
<td>
<p>an R formula (or list of formulas) indicating how the latent traits
can be regressed using external covariates in <code>covdata</code>. If a named list
of formulas is supplied (where the names correspond to the latent trait names in <code>model</code>)
then specific regression effects can be estimated for each factor. Supplying a single formula
will estimate the regression parameters for all latent traits by default</p>
</td></tr>
<tr><td><code id="mirt_+3A_se.type">SE.type</code></td>
<td>
<p>type of estimation method to use for calculating the parameter information matrix
for computing standard errors and <code><a href="#topic+wald">wald</a></code> tests. Can be:
</p>

<ul>
<li> <p><code>'Richardson'</code>, <code>'forward'</code>, or <code>'central'</code> for the numerical Richardson,
forward difference, and central difference evaluation of observed Hessian matrix
</p>
</li>
<li> <p><code>'crossprod'</code> and <code>'Louis'</code> for standard error computations based on the variance of the
Fisher scores as well as Louis' (1982) exact computation of the observed information matrix.
Note that Louis' estimates can take a long time to obtain for large sample sizes and long tests
</p>
</li>
<li> <p><code>'sandwich'</code> for the sandwich covariance estimate based on the
<code>'crossprod'</code> and <code>'Oakes'</code> estimates (see Chalmers, 2018, for details)
</p>
</li>
<li> <p><code>'sandwich.Louis'</code> for the sandwich covariance estimate based on the
<code>'crossprod'</code> and <code>'Louis'</code> estimates
</p>
</li>
<li> <p><code>'Oakes'</code> for Oakes' (1999) method using a central difference approximation
(see Chalmers, 2018, for details)
</p>
</li>
<li> <p><code>'SEM'</code> for the supplemented EM (disables the <code>accelerate</code> option automatically; EM only)
</p>
</li>
<li> <p><code>'Fisher'</code> for the expected information, <code>'complete'</code> for information based
on the complete-data Hessian used in EM algorithm
</p>
</li>
<li> <p><code>'MHRM'</code> and <code>'FMHRM'</code> for stochastic approximations of observed information matrix
based on the Robbins-Monro filter or a fixed number of MHRM draws without the RM filter.
These are the only options supported when <code>method = 'MHRM'</code>
</p>
</li>
<li> <p><code>'numerical'</code> to obtain the numerical estimate from a call to <code><a href="stats.html#topic+optim">optim</a></code>
when <code>method = 'BL'</code>
</p>
</li></ul>

<p>Note that both the <code>'SEM'</code> method becomes very sensitive if the ML solution has
has not been reached with sufficient precision, and may be further sensitive
if the history of the EM cycles is not stable/sufficient for convergence of the respective estimates.
Increasing the number of iterations (increasing <code>NCYCLES</code> and decreasing
<code>TOL</code>, see below) will help to improve the accuracy, and can be
run in parallel if a <code><a href="#topic+mirtCluster">mirtCluster</a></code> object has been defined (this will be
used for Oakes' method as well). Additionally,
inspecting the symmetry of the ACOV matrix for convergence issues by passing
<code>technical = list(symmetric = FALSE)</code> can be helpful to determine if a sufficient
solution has been reached</p>
</td></tr>
<tr><td><code id="mirt_+3A_method">method</code></td>
<td>
<p>a character object specifying the estimation algorithm to be used. The default is
<code>'EM'</code>, for the standard EM algorithm with fixed quadrature, <code>'QMCEM'</code> for
quasi-Monte Carlo EM estimation, or <code>'MCEM'</code> for Monte Carlo EM estimation.
The option <code>'MHRM'</code> may also be passed to use the MH-RM algorithm,
<code>'SEM'</code> for the Stochastic EM algorithm (first
two stages of the MH-RM stage using an optimizer other than a single Newton-Raphson iteration),
and <code>'BL'</code> for the Bock and Lieberman
approach (generally not recommended for longer tests).
</p>
<p>The <code>'EM'</code> is generally effective with 1-3 factors, but methods such as the <code>'QMCEM'</code>,
<code>'MCEM'</code>, <code>'SEM'</code>, or <code>'MHRM'</code> should be used when the dimensions are 3 or more. Note that
when the optimizer is stochastic the associated <code>SE.type</code> is automatically changed to
<code>SE.type = 'MHRM'</code> by default to avoid the use of quadrature</p>
</td></tr>
<tr><td><code id="mirt_+3A_optimizer">optimizer</code></td>
<td>
<p>a character indicating which numerical optimizer to use. By default, the EM
algorithm will use the <code>'BFGS'</code> when there are no upper and lower bounds box-constraints and
<code>'nlminb'</code> when there are.
</p>
<p>Other options include the Newton-Raphson (<code>'NR'</code>),
which can be more efficient than the <code>'BFGS'</code> but not as stable for more complex
IRT models (such as the nominal or nested logit models)
and the related <code>'NR1'</code> which is also the Newton-Raphson
but consists of only 1 update that has been coupled with RM Hessian (only
applicable when the MH-RM algorithm is used). The MH-RM algorithm uses the <code>'NR1'</code> by default,
though currently the <code>'BFGS'</code>, <code>'L-BFGS-B'</code>, and <code>'NR'</code>
are also supported with this method (with
fewer iterations by default) to emulate stochastic EM updates.
As well, the <code>'Nelder-Mead'</code> and <code>'SANN'</code>
estimators are available, but their routine use generally is not required or recommended.
</p>
<p>Additionally, estimation subroutines from the <code>Rsolnp</code> and <code>nloptr</code>
packages are available by passing the arguments <code>'solnp'</code> and <code>'nloptr'</code>,
respectively. This should be used in conjunction with the <code>solnp_args</code> and
<code>nloptr_args</code> specified below. If equality constraints were specified in the
model definition only the parameter with the lowest <code>parnum</code>
in the <code>pars = 'values'</code> data.frame is used in the estimation vector passed
to the objective function, and group hyper-parameters are omitted.
Equality an inequality functions should be of the form <code>function(p, optim_args)</code>,
where <code>optim_args</code> is a list of internally parameters that largely can be ignored
when defining constraints (though use of <code>browser()</code> here may be helpful)</p>
</td></tr>
<tr><td><code id="mirt_+3A_dentype">dentype</code></td>
<td>
<p>type of density form to use for the latent trait parameters. Current options include
</p>

<ul>
<li> <p><code>'Gaussian'</code> (default) assumes a multivariate Gaussian distribution with an associated
mean vector and variance-covariance matrix
</p>
</li>
<li> <p><code>'empiricalhist'</code> or <code>'EH'</code> estimates latent distribution using an empirical histogram described by
Bock and Aitkin (1981). Only applicable for unidimensional models estimated with the EM algorithm.
For this option, the number of cycles, TOL, and quadpts are adjusted accommodate for
less precision during estimation (namely: <code>TOL = 3e-5</code>, <code>NCYCLES = 2000</code>, <code>quadpts = 121</code>)
</p>
</li>
<li> <p><code>'empiricalhist_Woods'</code> or <code>'EHW'</code> estimates latent distribution using an empirical histogram described by
Bock and Aitkin (1981), with the same specifications as in <code>dentype = 'empiricalhist'</code>,
but with the extrapolation-interpolation method described by Woods (2007). NOTE: to improve stability
in the presence of extreme response styles (i.e., all highest or lowest in each item) the <code>technical</code> option
<code>zeroExtreme = TRUE</code> may be required to down-weight the contribution of these problematic patterns
</p>
</li>
<li> <p><code>'Davidian-#'</code> estimates semi-parametric Davidian curves described by Woods and Lin (2009),
where the <code>#</code> placeholder represents the number of Davidian parameters to estimate
(e.g., <code>'Davidian-6'</code> will estimate 6 smoothing parameters). By default, the number of
<code>quadpts</code> is increased to 121, and this method is only applicable for
unidimensional models estimated with the EM algorithm
</p>
</li></ul>

<p>Note that when <code>itemtype = 'ULL'</code> then a log-normal(0,1) density is used to support the unipolar scaling</p>
</td></tr>
<tr><td><code id="mirt_+3A_pars">pars</code></td>
<td>
<p>a data.frame with the structure of how the starting values, parameter numbers,
estimation logical values, etc, are defined. The user may observe how the model defines the
values by using <code>pars = 'values'</code>, and this object can in turn be modified and input back
into the estimation with <code>pars = mymodifiedpars</code></p>
</td></tr>
<tr><td><code id="mirt_+3A_constrain">constrain</code></td>
<td>
<p>a list of user declared equality constraints. To see how to define the
parameters correctly use <code>pars = 'values'</code> initially to see how the parameters are
labeled. To constrain parameters to be equal create a list with separate concatenated
vectors signifying which parameters to constrain. For example, to set parameters 1 and 5
equal, and also set parameters 2, 6, and 10 equal use
<code>constrain = list(c(1,5), c(2,6,10))</code>. Constraints can also be specified using the
<code><a href="#topic+mirt.model">mirt.model</a></code> syntax (recommended)</p>
</td></tr>
<tr><td><code id="mirt_+3A_calcnull">calcNull</code></td>
<td>
<p>logical; calculate the Null model for additional fit statistics (e.g., TLI)?
Only applicable if the data contains no NA's and the data is not overly sparse</p>
</td></tr>
<tr><td><code id="mirt_+3A_draws">draws</code></td>
<td>
<p>the number of Monte Carlo draws to estimate the log-likelihood for the MH-RM
algorithm. Default is 5000</p>
</td></tr>
<tr><td><code id="mirt_+3A_survey.weights">survey.weights</code></td>
<td>
<p>a optional numeric vector of survey weights to apply for each case in the
data (EM estimation only). If not specified, all cases are weighted equally (the standard IRT
approach). The sum of the <code>survey.weights</code> must equal the total sample size for proper
weighting to be applied</p>
</td></tr>
<tr><td><code id="mirt_+3A_quadpts">quadpts</code></td>
<td>
<p>number of quadrature points per dimension (must be larger than 2).
By default the number of quadrature uses the following scheme:
<code>switch(as.character(nfact), '1'=61, '2'=31, '3'=15, '4'=9, '5'=7, 3)</code>.
However, if the method input is set to <code>'QMCEM'</code> and this argument is left blank then
the default number of quasi-Monte Carlo integration nodes will be set to 5000 in total</p>
</td></tr>
<tr><td><code id="mirt_+3A_tol">TOL</code></td>
<td>
<p>convergence threshold for EM or MH-RM; defaults are .0001 and .001. If
<code>SE.type = 'SEM'</code> and this value is not specified, the default is set to <code>1e-5</code>.
To evaluate the model using only the starting values pass <code>TOL = NaN</code>, and
to evaluate the starting values without the log-likelihood pass <code>TOL = NA</code></p>
</td></tr>
<tr><td><code id="mirt_+3A_gpcm_mats">gpcm_mats</code></td>
<td>
<p>a list of matrices specifying how the scoring coefficients in the (generalized)
partial credit model should be constructed. If omitted, the standard gpcm format will be used
(i.e., <code>seq(0, k, by = 1)</code> for each trait). This input should be used if traits
should be scored different for each category (e.g., <code>matrix(c(0:3, 1,0,0,0), 4, 2)</code> for a
two-dimensional model where the first trait is scored like a gpcm, but the second trait is only
positively indicated when the first category is selected). Can be used when <code>itemtype</code>s
are <code>'gpcm'</code> or <code>'Rasch'</code>, but only when the respective element in
<code>gpcm_mats</code> is not <code>NULL</code></p>
</td></tr>
<tr><td><code id="mirt_+3A_grsm.block">grsm.block</code></td>
<td>
<p>an optional numeric vector indicating where the blocking should occur when
using the grsm, NA represents items that do not belong to the grsm block (other items that may
be estimated in the test data). For example, to specify two blocks of 3 with a 2PL item for
the last item: <code>grsm.block = c(rep(1,3), rep(2,3), NA)</code>. If NULL the all items are assumed
to be within the same group and therefore have the same number of item categories</p>
</td></tr>
<tr><td><code id="mirt_+3A_rsm.block">rsm.block</code></td>
<td>
<p>same as <code>grsm.block</code>, but for <code>'rsm'</code> blocks</p>
</td></tr>
<tr><td><code id="mirt_+3A_monopoly.k">monopoly.k</code></td>
<td>
<p>a vector of values (or a single value to repeated for each item) which indicate
the degree of the monotone polynomial fitted, where the monotone polynomial
corresponds to <code>monopoly.k * 2 + 1</code> (e.g., <code>monopoly.k = 2</code> fits a
5th degree polynomial). Default is <code>monopoly.k = 1</code>, which fits a 3rd degree polynomial</p>
</td></tr>
<tr><td><code id="mirt_+3A_key">key</code></td>
<td>
<p>a numeric vector of the response scoring key. Required when using nested logit item
types, and must be the same length as the number of items used. Items that are not nested logit
will ignore this vector, so use <code>NA</code> in item locations that are not applicable</p>
</td></tr>
<tr><td><code id="mirt_+3A_large">large</code></td>
<td>
<p>a <code>logical</code> indicating whether unique response patterns should be obtained prior
to performing the estimation so as to avoid repeating computations on identical patterns.
The default <code>TRUE</code> provides the correct degrees of freedom for the model since all unique patterns
are tallied (typically only affects goodness of fit statistics such as G2, but also will influence
nested model comparison methods such as <code>anova(mod1, mod2)</code>), while <code>FALSE</code> will use the
number of rows in <code>data</code> as a placeholder for the total degrees of freedom. As such, model
objects should only be compared if all flags were set to <code>TRUE</code> or all were set to <code>FALSE</code>
</p>
<p>Alternatively, if the collapse table of frequencies is desired for the purpose of saving computations
(i.e., only computing the collapsed frequencies for the data onte-time) then a character vector can
be passed with the arguement <code>large = 'return'</code> to return a list of all the desired
table information used by <code>mirt</code>. This list object can then be reused by passing it back
into the <code>large</code> argument to avoid re-tallying the data again
(again, useful when the dataset are very large and computing the tabulated data is
computationally burdensome). This strategy is shown below:
</p>

<dl>
<dt>Compute organized data</dt><dd><p>e.g., <code>internaldat &lt;- mirt(Science, 1, large = 'return')</code></p>
</dd>
<dt>Pass the organized data to all estimation functions</dt><dd><p>e.g.,
<code>mod &lt;- mirt(Science, 1, large = internaldat)</code></p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mirt_+3A_genrandompars">GenRandomPars</code></td>
<td>
<p>logical; generate random starting values prior to optimization instead of
using the fixed internal starting values?</p>
</td></tr>
<tr><td><code id="mirt_+3A_accelerate">accelerate</code></td>
<td>
<p>a character vector indicating the type of acceleration to use. Default
is <code>'Ramsay'</code>, but may also be <code>'squarem'</code> for the SQUAREM procedure (specifically,
the gSqS3 approach) described in Varadhan and Roldand (2008).
To disable the acceleration, pass <code>'none'</code></p>
</td></tr>
<tr><td><code id="mirt_+3A_verbose">verbose</code></td>
<td>
<p>logical; print observed- (EM) or complete-data (MHRM) log-likelihood
after each iteration cycle? Default is TRUE</p>
</td></tr>
<tr><td><code id="mirt_+3A_solnp_args">solnp_args</code></td>
<td>
<p>a list of arguments to be passed to the <code>solnp::solnp()</code> function for
equality constraints, inequality constraints, etc</p>
</td></tr>
<tr><td><code id="mirt_+3A_nloptr_args">nloptr_args</code></td>
<td>
<p>a list of arguments to be passed to the <code>nloptr::nloptr()</code>
function for equality constraints, inequality constraints, etc</p>
</td></tr>
<tr><td><code id="mirt_+3A_spline_args">spline_args</code></td>
<td>
<p>a named list of lists containing information to be passed to the <code><a href="splines.html#topic+bs">bs</a></code> (default)
and <code><a href="splines.html#topic+ns">ns</a></code> for each spline itemtype. Each element must refer to the name of the itemtype with the
spline, while the internal list names refer to the arguments which are passed. For example, if item 2 were called
'read2', and item 5 were called 'read5', both of which were of itemtype 'spline' but item 5 should use the
<code><a href="splines.html#topic+ns">ns</a></code> form, then a modified list for each input might be of the form:
</p>
<p><code>spline_args = list(read2 = list(degree = 4),
                           read5 = list(fun = 'ns', knots = c(-2, 2)))</code>
</p>
<p>This code input changes the <code>bs()</code> splines function to have a <code>degree = 4</code> input,
while the second element changes to the <code>ns()</code> function with knots set a <code>c(-2, 2)</code></p>
</td></tr>
<tr><td><code id="mirt_+3A_control">control</code></td>
<td>
<p>a list passed to the respective optimizers (i.e., <code>optim()</code>, <code>nlminb()</code>,
etc). Additional arguments have been included for the <code>'NR'</code> optimizer: <code>'tol'</code>
for the convergence tolerance in the M-step (default is <code>TOL/1000</code>), while the default
number of iterations for the Newton-Raphson optimizer is 50 (modified with the <code>'maxit'</code>
control input)</p>
</td></tr>
<tr><td><code id="mirt_+3A_technical">technical</code></td>
<td>
<p>a list containing lower level technical parameters for estimation. May be:
</p>

<dl>
<dt>NCYCLES</dt><dd><p>maximum number of EM or MH-RM cycles; defaults are 500 and 2000</p>
</dd>
<dt>MAXQUAD</dt><dd><p>maximum number of quadratures, which you can increase if you have more than
4GB or RAM on your PC; default 20000</p>
</dd>
<dt>theta_lim</dt><dd><p>range of integration grid for each dimension; default is <code>c(-6, 6)</code>. Note that
when <code>itemtype = 'ULL'</code> a log-normal distribution is used and the range is change to
<code>c(.01, and 6^2)</code>, where the second term is the square of the <code>theta_lim</code> input instead</p>
</dd>
<dt>set.seed</dt><dd><p>seed number used during estimation. Default is 12345</p>
</dd>
<dt>SEtol</dt><dd><p>standard error tolerance criteria for the S-EM and MHRM computation of the
information matrix. Default is 1e-3</p>
</dd>
<dt>symmetric</dt><dd><p>logical; force S-EM/Oakes information matrix estimates to be symmetric? Default is TRUE
so that computation of standard errors are more stable. Setting this to FALSE can help
to detect solutions that have not reached the ML estimate</p>
</dd>
<dt>SEM_window</dt><dd><p>ratio of values used to define the S-EM window based on the
observed likelihood differences across EM iterations. The default is
<code>c(0, 1 - SEtol)</code>, which provides nearly the very full S-EM window (i.e.,
nearly all EM cycles used). To use the a smaller SEM window change the window to
to something like <code>c(.9, .999)</code> to start at a point farther into the EM history</p>
</dd>
<dt>warn</dt><dd><p>logical; include warning messages during estimation? Default is TRUE</p>
</dd>
<dt>message</dt><dd><p>logical; include general messages during estimation? Default is TRUE</p>
</dd>
<dt>customK</dt><dd><p>a numeric vector used to explicitly declare the number of response
categories for each item. This should only be used when constructing mirt model for
reasons other than parameter estimation (such as to obtain factor scores), and requires
that the input data all have 0 as the lowest category. The format is the same as the
<code>extract.mirt(mod, 'K')</code> slot in all converged models</p>
</dd>
<dt>customPriorFun</dt><dd><p>a custom function used to determine the normalized density for
integration in the EM algorithm. Must be of the form <code>function(Theta, Etable){...}</code>,
and return a numeric vector with the same length as number of rows in <code>Theta</code>. The
<code>Etable</code> input contains the aggregated table generated from the current E-step
computations. For proper integration, the returned vector should sum to
1 (i.e., normalized). Note that if using the <code>Etable</code> it will be NULL
on the first call, therefore the prior will have to deal with this issue accordingly</p>
</dd>
<dt>zeroExtreme</dt><dd><p>logical; assign extreme response patterns a <code>survey.weight</code> of 0
(formally equivalent to removing these data vectors during estimation)?
When <code>dentype = 'EHW'</code>, where Woods' extrapolation is utilized,
this option may be required if the extrapolation causes expected densities to tend towards
positive or negative infinity. The default is <code>FALSE</code></p>
</dd>
<dt>customTheta</dt><dd><p>a custom <code>Theta</code> grid, in matrix form, used for integration.
If not defined, the grid is determined internally based on the number of <code>quadpts</code></p>
</dd>
<dt>nconstrain</dt><dd><p>same specification as the <code>constrain</code> list argument,
however imposes a negative equality constraint instead (e.g., <code class="reqn">a12 = -a21</code>, which
is specified as <code>nconstrain = list(c(12, 21))</code>). Note that each specification
in the list must be of length 2, where the second element is taken to be -1 times the
first element</p>
</dd>
<dt>delta</dt><dd><p>the deviation term used in numerical estimates when computing the ACOV matrix
with the 'forward' or 'central' numerical approaches, as well as Oakes' method with the
Richardson extrapolation. Default is 1e-5</p>
</dd>
<dt>parallel</dt><dd><p>logical; use the parallel cluster defined by <code><a href="#topic+mirtCluster">mirtCluster</a></code>?
Default is TRUE</p>
</dd>
<dt>storeEMhistory</dt><dd><p>logical; store the iteration history when using the EM algorithm?
Default is FALSE. When TRUE, use <code><a href="#topic+extract.mirt">extract.mirt</a></code> to extract</p>
</dd>
<dt>internal_constraints</dt><dd><p>logical; include the internal constraints when using certain
IRT models (e.g., 'grsm' itemtype). Disable this if you want to use special optimizers
such as the solnp. Default is <code>TRUE</code></p>
</dd>
<dt>gain</dt><dd><p>a vector of two values specifying the numerator and exponent
values for the RM gain function <code class="reqn">(val1 / cycle)^val2</code>.
Default is <code>c(0.10, 0.75)</code></p>
</dd>
<dt>BURNIN</dt><dd><p>number of burn in cycles (stage 1) in MH-RM; default is 150</p>
</dd>
<dt>SEMCYCLES</dt><dd><p>number of SEM cycles (stage 2) in MH-RM; default is 100</p>
</dd>
<dt>MHDRAWS</dt><dd><p>number of Metropolis-Hasting draws to use in the MH-RM at each iteration; default is 5</p>
</dd>
<dt>MHcand</dt><dd><p>a vector of values used to tune the MH sampler. Larger values will
cause the acceptance ratio to decrease. One value is required for each group in
unconditional item factor analysis (<code>mixedmirt()</code> requires additional values
for random effect). If null, these values are determined internally, attempting to
tune the acceptance of the draws to be between .1 and .4</p>
</dd>
<dt>MHRM_SE_draws</dt><dd><p>number of fixed draws to use when <code>SE=TRUE</code> and <code>SE.type = 'FMHRM'</code>
and the maximum number of draws when <code>SE.type = 'MHRM'</code>. Default is 2000</p>
</dd>
<dt>MCEM_draws</dt><dd><p>a function used to determine the number of quadrature points to draw for the
<code>'MCEM'</code> method. Must include one argument which indicates the iteration number of the
EM cycle. Default is <code>function(cycles) 500 + (cycles - 1)*2</code>, which starts the number of
draws at 500 and increases by 2 after each full EM iteration</p>
</dd>
<dt>info_if_converged</dt><dd><p>logical; compute the information matrix when using the MH-RM algorithm
only if the model converged within a suitable number of iterations? Default is <code>TRUE</code></p>
</dd>
<dt>logLik_if_converged</dt><dd><p>logical; compute the observed log-likelihood when using the MH-RM algorithm
only if the model converged within a suitable number of iterations? Default is <code>TRUE</code></p>
</dd>
<dt>keep_vcov_PD</dt><dd><p>logical; attempt to keep the variance-covariance matrix of the latent traits
positive definite during estimation in the EM algorithm? This generally improves the convergence
properties when the traits are highly correlated. Default is <code>TRUE</code></p>
</dd>
</dl>
</td></tr>
<tr><td><code id="mirt_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>function returns an object of class <code>SingleGroupClass</code>
(<a href="#topic+SingleGroupClass-class">SingleGroupClass-class</a>)
</p>


<h3>Confirmatory and Exploratory IRT</h3>

<p>Specification of the confirmatory item factor analysis model follows many of
the rules in the structural equation modeling framework for confirmatory factor analysis. The
variances of the latent factors are automatically fixed to 1 to help
facilitate model identification. All parameters may be fixed to constant
values or set equal to other parameters using the appropriate declarations.
Confirmatory models may also contain 'explanatory' person or item level predictors, though
including predictors is currently limited to the <code><a href="#topic+mixedmirt">mixedmirt</a></code> function.
</p>
<p>When specifying a single number greater than 1 as the <code>model</code> input to mirt
an exploratory IRT model will be estimated. Rotation and target matrix options are available
if they are passed to generic functions such as <code><a href="#topic+summary-method">summary-method</a></code> and
<code><a href="#topic+fscores">fscores</a></code>. Factor means and variances are fixed to ensure proper identification.
</p>
<p>If the model is an exploratory item factor analysis estimation will begin
by computing a matrix of quasi-polychoric correlations. A
factor analysis with <code>nfact</code> is then extracted and item parameters are
estimated by <code class="reqn">a_{ij} = f_{ij}/u_j</code>, where <code class="reqn">f_{ij}</code> is the factor
loading for the <em>j</em>th item on the <em>i</em>th factor, and <code class="reqn">u_j</code> is
the square root of the factor uniqueness, <code class="reqn">\sqrt{1 - h_j^2}</code>. The
initial intercept parameters are determined by calculating the inverse
normal of the item facility (i.e., item easiness), <code class="reqn">q_j</code>, to obtain
<code class="reqn">d_j = q_j / u_j</code>. A similar implementation is also used for obtaining
initial values for polytomous items.
</p>


<h3>A note on upper and lower bound parameters</h3>

<p>Internally the <code class="reqn">g</code> and <code class="reqn">u</code> parameters are transformed using a logit
transformation (<code class="reqn">log(x/(1-x))</code>), and can be reversed by using <code class="reqn">1 / (1 + exp(-x))</code>
following convergence. This also applies when computing confidence intervals for these
parameters, and is done so automatically if <code>coef(mod, rawug = FALSE)</code>.
</p>
<p>As such, when applying prior distributions to these parameters it is recommended to use a prior
that ranges from negative infinity to positive infinity, such as the normally distributed
prior via the <code>'norm'</code> input (see <code><a href="#topic+mirt.model">mirt.model</a></code>).
</p>


<h3>Convergence for quadrature methods</h3>

<p>Unrestricted full-information factor analysis is known to have problems with
convergence, and some items may need to be constrained or removed entirely
to allow for an acceptable solution. As a general rule dichotomous items with
means greater than .95, or items that are only .05 greater than the
guessing parameter, should be considered for removal from the analysis or
treated with prior parameter distributions. The same type of reasoning is
applicable when including upper bound parameters as well. For polytomous items, if categories
are rarely endorsed then this will cause similar issues. Also, increasing the
number of quadrature points per dimension, or using the
quasi-Monte Carlo integration method, may help to stabilize the estimation process
in higher dimensions. Finally, solutions that are not well defined also will have difficulty
converging, and can indicate that the model has been misspecified (e.g., extracting too many
dimensions).
</p>


<h3>Convergence for MH-RM method</h3>

<p>For the MH-RM algorithm, when the number of iterations grows very high (e.g., greater than 1500)
or when <code>Max Change = .2500</code> values are repeatedly printed
to the console too often (indicating that the parameters were being constrained since they are
naturally moving in steps greater than 0.25) then the model may either be ill defined or have a
very flat likelihood surface, and genuine maximum-likelihood parameter estimates may be difficult
to find. Standard errors are computed following the model convergence by passing
<code>SE = TRUE</code>, to perform an addition MH-RM stage but treating the maximum-likelihood
estimates as fixed points.
</p>


<h3>Additional helper functions</h3>

<p>Additional functions are available in the package which can be useful pre- and post-estimation.
These are:
</p>

<dl>
<dt><code><a href="#topic+mirt.model">mirt.model</a></code></dt><dd>
<p>Define the IRT model specification use special syntax. Useful for defining between and within
group parameter constraints, prior parameter distributions, and specifying the slope
coefficients for each factor</p>
</dd>
<dt><code><a href="#topic+coef-method">coef-method</a></code></dt><dd>
<p>Extract raw coefficients from the model, along with their standard errors and confidence
intervals</p>
</dd>
<dt><code><a href="#topic+summary-method">summary-method</a></code></dt><dd>
<p>Extract standardized loadings from model. Accepts a <code>rotate</code> argument for exploratory
item response model</p>
</dd>
<dt><code><a href="#topic+anova-method">anova-method</a></code></dt><dd>
<p>Compare nested models using likelihood ratio statistics as well as information criteria
such as the AIC and BIC</p>
</dd>
<dt><code><a href="#topic+residuals-method">residuals-method</a></code></dt><dd>
<p>Compute pairwise residuals between each item using methods such as the LD statistic
(Chen &amp; Thissen, 1997), as well as response pattern residuals</p>
</dd>
<dt><code><a href="#topic+plot-method">plot-method</a></code></dt><dd>
<p>Plot various types of test level plots including the test score and information functions
and more</p>
</dd>
<dt><code><a href="#topic+itemplot">itemplot</a></code></dt><dd>
<p>Plot various types of item level plots, including the score, standard error, and information
functions, and more</p>
</dd>
<dt><code><a href="#topic+createItem">createItem</a></code></dt><dd>
<p>Create a customized <code>itemtype</code> that does not currently exist in the package</p>
</dd>
<dt><code><a href="#topic+imputeMissing">imputeMissing</a></code></dt><dd>
<p>Impute missing data given some computed Theta matrix</p>
</dd>
<dt><code><a href="#topic+fscores">fscores</a></code></dt><dd>
<p>Find predicted scores for the latent traits using estimation methods such as EAP, MAP, ML,
WLE, and EAPsum</p>
</dd>
<dt><code><a href="#topic+wald">wald</a></code></dt><dd>
<p>Compute Wald statistics follow the convergence of a model with a suitable information matrix</p>
</dd>
<dt><code><a href="#topic+M2">M2</a></code></dt><dd>
<p>Limited information goodness of fit test statistic based to determine how well the model fits
the data</p>
</dd>
<dt><code><a href="#topic+itemfit">itemfit</a></code> and <code><a href="#topic+personfit">personfit</a></code></dt><dd>
<p>Goodness of fit statistics at the item and person levels, such as the S-X2, infit, outfit,
and more</p>
</dd>
<dt><code><a href="#topic+boot.mirt">boot.mirt</a></code></dt><dd>
<p>Compute estimated parameter confidence intervals via the bootstrap methods</p>
</dd>
<dt><code><a href="#topic+mirtCluster">mirtCluster</a></code></dt><dd>
<p>Define a cluster for the package functions to use for capitalizing on multi-core architecture
to utilize available CPUs when possible. Will help to decrease estimation times for tasks
that can be run in parallel</p>
</dd>
</dl>



<h3>IRT Models</h3>

<p>The parameter labels use the follow convention, here using two factors and <code class="reqn">K</code> as the total
number of categories (using <code class="reqn">k</code> for specific category instances).
</p>

<dl>
<dt>Rasch</dt><dd>
<p>Only one intercept estimated, and the latent variance of <code class="reqn">\theta</code> is freely estimated. If
the data have more than two categories then a partial credit model is used instead (see
'gpcm' below).
</p>
<p style="text-align: center;"><code class="reqn">P(x = 1|\theta, d) = \frac{1}{1 + exp(-(\theta + d))}</code>
</p>

</dd>
<dt>2-4PL</dt><dd>
<p>Depending on the model <code class="reqn">u</code> may be equal to 1 and <code class="reqn">g</code> may be equal to 0.
</p>
<p style="text-align: center;"><code class="reqn">P(x = 1|\theta, \psi) = g + \frac{(u - g)}{
      1 + exp(-(a_1 * \theta_1 + a_2 * \theta_2 + d))}</code>
</p>

</dd>
<dt>5PL</dt><dd>
<p>Currently restricted to unidimensional models
</p>
<p style="text-align: center;"><code class="reqn">P(x = 1|\theta, \psi) = g + \frac{(u - g)}{
      1 + exp(-(a_1 * \theta_1 + d))^S}</code>
</p>

<p>where <code class="reqn">S</code> allows for asymmetry in the response function and
is transformation constrained to be greater than 0 (i.e., <code>log(S)</code> is estimated rather than <code>S</code>)
</p>
</dd>
<dt>CLL</dt><dd>
<p>Complementary log-log model (see Shim, Bonifay, and Wiedermann, 2022)
</p>
<p style="text-align: center;"><code class="reqn">P(x = 1|\theta, b) = 1 - exp(-exp(\theta - b))</code>
</p>

<p>Currently restricted to unidimensional dichotomous data.
</p>
</dd>
<dt>graded</dt><dd>
<p>The graded model consists of sequential 2PL models,
</p>
<p style="text-align: center;"><code class="reqn">P(x = k | \theta, \psi) = P(x \ge k | \theta, \phi) - P(x \ge k + 1 | \theta, \phi)</code>
</p>

<p>Note that <code class="reqn">P(x \ge 1 | \theta, \phi) = 1</code> while <code class="reqn">P(x \ge K + 1 | \theta, \phi) = 0</code>
</p>
</dd>
<dt>ULL</dt><dd>
<p>The unipolar log-logistic model (ULL; Lucke, 2015) is defined the same as
the graded response model, however
</p>
<p style="text-align: center;"><code class="reqn">P(x \le k | \theta, \psi) = \frac{\lambda_k\theta^\eta}{1 + \lambda_k\theta^\eta}</code>
</p>
<p>.
Internally the <code class="reqn">\lambda</code> parameters are exponentiated to keep them positive, and should
therefore the reported estimates should be interpreted in log units
</p>
</dd>
<dt>grsm</dt><dd>
<p>A more constrained version of the graded model where graded spacing is equal across item
blocks and only adjusted by a single 'difficulty' parameter (c) while the latent variance
of <code class="reqn">\theta</code> is freely estimated (see Muraki, 1990 for this exact form).
This is restricted to unidimensional models only.
</p>
</dd>
<dt>gpcm/nominal</dt><dd><p>For the gpcm the <code class="reqn">d</code> values are treated as fixed and ordered values
from <code class="reqn">0:(K-1)</code> (in the nominal model <code class="reqn">d_0</code> is also set to 0). Additionally, for
identification in the nominal model <code class="reqn">ak_0 = 0</code>, <code class="reqn">ak_{(K-1)} = (K - 1)</code>.
</p>
<p style="text-align: center;"><code class="reqn">P(x = k | \theta, \psi) =
    \frac{exp(ak_{k-1} * (a_1 * \theta_1 + a_2 * \theta_2) + d_{k-1})}
    {\sum_{k=1}^K exp(ak_{k-1} * (a_1 * \theta_1 + a_2 * \theta_2) + d_{k-1})}</code>
</p>

<p>For the partial credit model (when <code>itemtype = 'Rasch'</code>; unidimensional only) the above
model is further constrained so that <code class="reqn">ak = (0,1,\ldots, K-1)</code>, <code class="reqn">a_1 = 1</code>, and the
latent variance of <code class="reqn">\theta_1</code> is freely estimated. Alternatively, the partial credit model
can be obtained by containing all the slope parameters in the gpcms to be equal.
More specific scoring function may be included by passing a suitable list or matrices
to the <code>gpcm_mats</code> input argument.
</p>
<p>In the nominal model this parametrization helps to identify the empirical ordering of the
categories by inspecting the <code class="reqn">ak</code> values. Larger values indicate that the item category
is more positively related to the latent trait(s) being measured. For instance, if an item
was truly ordinal (such as a Likert scale), and had 4 response categories, we would expect
to see <code class="reqn">ak_0 &lt; ak_1 &lt; ak_2 &lt; ak_3</code> following estimation. If on the other hand
<code class="reqn">ak_0 &gt; ak_1</code> then it would appear that the second category is less related to to the
trait than the first, and therefore the second category should be understood as the
'lowest score'.
</p>
<p>NOTE: The nominal model can become numerical unstable if poor choices for the high and low
values are chosen, resulting in <code>ak</code> values greater than <code>abs(10)</code> or more. It is
recommended to choose high and low anchors that cause the estimated parameters to fall
between 0 and <code class="reqn">K - 1</code> either by theoretical means or by re-estimating
the model with better values following convergence.
</p>
</dd>
<dt>gpcmIRT and rsm</dt><dd>
<p>The gpcmIRT model is the classical generalized partial credit model for unidimensional response
data. It will obtain the same fit as the <code>gpcm</code> presented above, however the parameterization
allows for the Rasch/generalized rating scale model as a special case.
</p>
<p>E.g., for a K = 4 category response model,
</p>
<p style="text-align: center;"><code class="reqn">P(x = 0 | \theta, \psi) = exp(0) / G</code>
</p>

<p style="text-align: center;"><code class="reqn">P(x = 1 | \theta, \psi) = exp(a(\theta - b1) + c) / G</code>
</p>

<p style="text-align: center;"><code class="reqn">P(x = 2 | \theta, \psi) = exp(a(2\theta - b1 - b2) + 2c) / G</code>
</p>

<p style="text-align: center;"><code class="reqn">P(x = 3 | \theta, \psi) = exp(a(3\theta - b1 - b2 - b3) + 3c) / G</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">G = exp(0) + exp(a(\theta - b1) + c) + exp(a(2\theta - b1 - b2) + 2c) +
       exp(a(3\theta - b1 - b2 - b3) + 3c)</code>
</p>

<p>Here <code class="reqn">a</code> is the slope parameter, the <code class="reqn">b</code> parameters are the threshold
values for each adjacent category, and <code class="reqn">c</code> is the so-called difficulty parameter when
a rating scale model is fitted (otherwise, <code class="reqn">c = 0</code> and it drops out of the computations).
</p>
<p>The gpcmIRT can be constrained to the partial credit IRT model by either constraining all the
slopes to be equal, or setting the slopes to 1 and freeing the latent variance parameter.
</p>
<p>Finally, the rsm is a more constrained version of the (generalized) partial
credit model where the spacing is equal
across item blocks and only adjusted by a single 'difficulty' parameter (c). Note that this
is analogous to the relationship between the graded model and the grsm (with an additional
constraint regarding the fixed discrimination parameters).
</p>
</dd>
<dt>sequential/Tutz</dt><dd>
<p>The multidimensional sequential response model has the form
</p>
<p style="text-align: center;"><code class="reqn">P(x = k | \theta, \psi) = \prod (1 - F(a_1 \theta_1 + a_2 \theta_2 + d_{sk}))
      F(a_1 \theta_1 + a_2 \theta_2 + d_{jk})</code>
</p>

<p>where <code class="reqn">F(\cdot)</code> is the cumulative logistic function.
The Tutz variant of this model (Tutz, 1990) (via <code>itemtype = 'Tutz'</code>)
assumes that the slope terms are all equal to 1 and the latent
variance terms are estimated (i.e., is a Rasch variant).
</p>
</dd>
<dt>ideal</dt><dd>
<p>The ideal point model has the form, with the upper bound constraint on <code class="reqn">d</code> set to 0:
</p>
<p style="text-align: center;"><code class="reqn">P(x = 1 | \theta, \psi) = exp(-0.5 * (a_1 * \theta_1 + a_2 * \theta_2 + d)^2)</code>
</p>

</dd>
<dt>partcomp</dt><dd><p>Partially compensatory models consist of the product of 2PL probability curves.
</p>
<p style="text-align: center;"><code class="reqn">P(x = 1 | \theta, \psi) = g + (1 - g) (\frac{1}{1 + exp(-(a_1 * \theta_1 + d_1))} *
    \frac{1}{1 + exp(-(a_2 * \theta_2 + d_2))})</code>
</p>

<p>Note that constraining the slopes to be equal across items will reduce the model to
Embretson's (a.k.a. Whitely's) multicomponent model (1980).
</p>
</dd>
<dt>2-4PLNRM</dt><dd><p>Nested logistic curves for modeling distractor items. Requires a scoring key.
The model is broken into two components for the probability of endorsement. For successful
endorsement the probability trace is the 1-4PL model, while for unsuccessful endorsement:
</p>
<p style="text-align: center;"><code class="reqn">P(x = 0 | \theta, \psi) =
    (1 - P_{1-4PL}(x = 1 | \theta, \psi)) * P_{nominal}(x = k | \theta, \psi)</code>
</p>

<p>which is the product of the complement of the dichotomous trace line with the nominal
response model. In the nominal model, the slope parameters defined above are constrained
to be 1's, while the last value of the <code class="reqn">ak</code> is freely estimated.
</p>
</dd>
<dt>ggum</dt><dd><p>The (multidimensional) generalized graded unfolding model is a
class of ideal point models useful for ordinal response data. The form is
</p>
<p style="text-align: center;"><code class="reqn">P(z=k|\theta,\psi)=\frac{exp\left[\left(z\sqrt{\sum_{d=1}^{D}
    a_{id}^{2}(\theta_{jd}-b_{id})^{2}}\right)+\sum_{k=0}^{z}\psi_{ik}\right]+
    exp\left[\left((M-z)\sqrt{\sum_{d=1}^{D}a_{id}^{2}(\theta_{jd}-b_{id})^{2}}\right)+
    \sum_{k=0}^{z}\psi_{ik}\right]}{\sum_{w=0}^{C}\left(exp\left[\left(w
    \sqrt{\sum_{d=1}^{D}a_{id}^{2}(\theta_{jd}-b_{id})^{2}}\right)+
    \sum_{k=0}^{z}\psi_{ik}\right]+exp\left[\left((M-w)
    \sqrt{\sum_{d=1}^{D}a_{id}^{2}(\theta_{jd}-b_{id})^{2}}\right)+
    \sum_{k=0}^{z}\psi_{ik}\right]\right)}</code>
</p>

<p>where <code class="reqn">\theta_{jd}</code> is the location of the <code class="reqn">j</code>th individual on the <code class="reqn">d</code>th dimension,
<code class="reqn">b_{id}</code> is the difficulty location of the <code class="reqn">i</code>th item on the <code class="reqn">d</code>th dimension,
<code class="reqn">a_{id}</code> is the discrimination of the <code class="reqn">j</code>th individual on the <code class="reqn">d</code>th dimension
(where the discrimination values are constrained to be positive),
<code class="reqn">\psi_{ik}</code> is the <code class="reqn">k</code>th subjective response category threshold for the <code class="reqn">i</code>th item,
assumed to be symmetric about the item and constant across dimensions, where
<code class="reqn">\psi_{ik} = \sum_{d=1}^D a_{id} t_{ik}</code>
<code class="reqn">z = 1,2,\ldots, C</code> (where <code class="reqn">C</code> is the number of categories minus 1),
and <code class="reqn">M = 2C + 1</code>.
</p>
</dd>
<dt>spline</dt><dd><p>Spline response models attempt to model the response curves uses non-linear and potentially
non-monotonic patterns. The form is
</p>
<p style="text-align: center;"><code class="reqn">P(x = 1|\theta, \eta) = \frac{1}{1 + exp(-(\eta_1 * X_1 + \eta_2 * X_2 + \cdots + \eta_n * X_n))}</code>
</p>

<p>where the <code class="reqn">X_n</code> are from the spline design matrix <code class="reqn">X</code> organized from the grid of <code class="reqn">\theta</code>
values. B-splines with a natural or polynomial basis are supported, and the <code>intercept</code> input is
set to <code>TRUE</code> by default.</p>
</dd>
<dt>monopoly</dt><dd><p>Monotone polynomial model for polytomous response data of the form
</p>
<p style="text-align: center;"><code class="reqn">P(x = k | \theta, \psi) =
    \frac{exp(\sum_1^k (m^*(\psi) + \xi_{c-1})}
    {\sum_1^C exp(\sum_1^K (m^*(\psi) + \xi_{c-1}))}</code>
</p>

<p>where <code class="reqn">m^*(\psi)</code> is the monotone polynomial function without the intercept.
</p>
</dd>
</dl>



<h3>HTML help files, exercises, and examples</h3>

<p>To access examples, vignettes, and exercise files that have been generated with knitr please
visit <a href="https://github.com/philchalmers/mirt/wiki">https://github.com/philchalmers/mirt/wiki</a>.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Andrich, D. (1978). A rating scale formulation for ordered response categories.
<em>Psychometrika, 43</em>, 561-573.
</p>
<p>Bock, R. D., &amp; Aitkin, M. (1981). Marginal maximum likelihood estimation of
item parameters: Application of an EM algorithm. <em>Psychometrika,
46</em>(4), 443-459.
</p>
<p>Bock, R. D., Gibbons, R., &amp; Muraki, E. (1988). Full-Information Item Factor
Analysis. <em>Applied Psychological Measurement, 12</em>(3), 261-280.
</p>
<p>Bock, R. D. &amp; Lieberman, M. (1970). Fitting a response model for n dichotomously
scored items. <em>Psychometrika, 35</em>, 179-197.
</p>
<p>Cai, L. (2010a). High-Dimensional exploratory item factor analysis by a
Metropolis-Hastings Robbins-Monro algorithm. <em>Psychometrika, 75</em>,
33-57.
</p>
<p>Cai, L. (2010b). Metropolis-Hastings Robbins-Monro algorithm for confirmatory
item factor analysis. <em>Journal of Educational and Behavioral
Statistics, 35</em>, 307-335.
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models with the MH-RM Algorithm.
<em>Journal of Educational Measurement, 52</em>, 200-222. <a href="https://doi.org/10.1111/jedm.12072">doi:10.1111/jedm.12072</a>
</p>
<p>Chalmers, R. P. (2018). Numerical Approximation of the Observed Information Matrix with Oakes' Identity.
<em>British Journal of Mathematical and Statistical Psychology</em> <em>DOI: 10.1111/bmsp.12127</em>
</p>
<p>Chalmers, R., P. &amp; Flora, D. (2014). Maximum-likelihood Estimation of Noncompensatory IRT
Models with the MH-RM Algorithm. <em>Applied Psychological Measurement, 38</em>, 339-358.
<a href="https://doi.org/10.1177/0146621614520958">doi:10.1177/0146621614520958</a>
</p>
<p>Chen, W. H. &amp; Thissen, D. (1997). Local dependence indices for item pairs using item
response theory. <em>Journal of Educational and Behavioral Statistics, 22</em>, 265-289.
</p>
<p>Falk, C. F. &amp; Cai, L. (2016). Maximum Marginal Likelihood Estimation of a
Monotonic Polynomial Generalized Partial Credit Model with Applications to
Multiple Group Analysis. <em>Psychometrika, 81</em>, 434-460.
</p>
<p>Lord, F. M. &amp; Novick, M. R. (1968). Statistical theory of mental test scores. Addison-Wesley.
</p>
<p>Lucke, J. F. (2015). Unipolar item response models. In S. P. Reise &amp; D. A. Revicki
(Eds.), Handbook of item response theory modeling: Applications to
typical performance assessment (pp. 272-284). New York, NY:  Routledge/Taylor &amp; Francis Group.
</p>
<p>Ramsay, J. O. (1975). Solving implicit equations in psychometric data analysis.
<em>Psychometrika, 40</em>, 337-360.
</p>
<p>Rasch, G. (1960). Probabilistic models for some intelligence and attainment tests.
<em>Danish Institute for Educational Research</em>.
</p>
<p>Roberts, J. S., Donoghue, J. R., &amp; Laughlin, J. E. (2000).
A General Item Response Theory Model for Unfolding Unidimensional Polytomous Responses.
<em>Applied Psychological Measurement, 24</em>, 3-32.
</p>
<p>Shim, H., Bonifay, W., &amp; Wiedermann, W. (2022). Parsimonious asymmetric item response
theory modeling with the complementary log-log link. <em>Behavior Research Methods, 55</em>,
200-219.
</p>
<p>Maydeu-Olivares, A., Hernandez, A. &amp; McDonald, R. P. (2006).
A Multidimensional Ideal Point Item Response Theory Model for Binary Data.
<em>Multivariate Behavioral Research, 41</em>, 445-471.
</p>
<p>Muraki, E. (1990). Fitting a polytomous item response model to Likert-type data.
<em>Applied Psychological Measurement, 14</em>, 59-71.
</p>
<p>Muraki, E. (1992). A generalized partial credit model: Application of an EM algorithm.
<em>Applied Psychological Measurement, 16</em>, 159-176.
</p>
<p>Muraki, E. &amp; Carlson, E. B. (1995). Full-information factor analysis for polytomous
item responses. <em>Applied Psychological Measurement, 19</em>, 73-90.
</p>
<p>Samejima, F. (1969). Estimation of latent ability using a response pattern of
graded scores. <em>Psychometrika Monographs</em>, 34.
</p>
<p>Suh, Y. &amp; Bolt, D. (2010). Nested logit models for multiple-choice item response data.
<em>Psychometrika, 75</em>, 454-473.
</p>
<p>Sympson, J. B. (1977). A model for testing with multidimensional items.
Proceedings of the 1977 Computerized Adaptive Testing Conference.
</p>
<p>Thissen, D. (1982). Marginal maximum likelihood estimation for the one-parameter logistic model.
<em>Psychometrika, 47</em>, 175-186.
</p>
<p>Tutz, G. (1990). Sequential item response models with ordered response.
<em>British Journal of Mathematical and Statistical Psychology, 43</em>, 39-55.
</p>
<p>Varadhan, R. &amp; Roland, C. (2008). Simple and Globally Convergent Methods for Accelerating
the Convergence of Any EM Algorithm. <em>Scandinavian Journal of Statistics, 35</em>, 335-353.
</p>
<p>Whitely, S. E. (1980). Multicomponent latent trait models for ability tests.
<em>Psychometrika, 45</em>(4), 470-494.
</p>
<p>Wood, R., Wilson, D. T., Gibbons, R. D., Schilling, S. G., Muraki, E., &amp;
Bock, R. D. (2003). <em>TESTFACT 4 for Windows: Test Scoring, Item Statistics,
and Full-information Item Factor Analysis</em> [Computer software]. Lincolnwood,
IL: Scientific Software International.
</p>
<p>Woods, C. M., and Lin, N. (2009). Item Response Theory With Estimation of the Latent Density Using Davidian Curves.
<em>Applied Psychological Measurement</em>,33(2), 102-117.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bfactor">bfactor</a></code>,  <code><a href="#topic+multipleGroup">multipleGroup</a></code>,  <code><a href="#topic+mixedmirt">mixedmirt</a></code>,
<code><a href="#topic+expand.table">expand.table</a></code>, <code><a href="#topic+key2binary">key2binary</a></code>, <code><a href="#topic+mod2values">mod2values</a></code>,
<code><a href="#topic+extract.item">extract.item</a></code>, <code><a href="#topic+iteminfo">iteminfo</a></code>, <code><a href="#topic+testinfo">testinfo</a></code>,
<code><a href="#topic+probtrace">probtrace</a></code>, <code><a href="#topic+simdata">simdata</a></code>, <code><a href="#topic+averageMI">averageMI</a></code>,
<code><a href="#topic+fixef">fixef</a></code>, <code><a href="#topic+extract.mirt">extract.mirt</a></code>, <code><a href="#topic+itemstats">itemstats</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# load LSAT section 7 data and compute 1 and 2 factor models
data &lt;- expand.table(LSAT7)
itemstats(data)

(mod1 &lt;- mirt(data, 1))
coef(mod1)
summary(mod1)
plot(mod1)
plot(mod1, type = 'trace')

## Not run: 
(mod2 &lt;- mirt(data, 1, SE = TRUE)) #standard errors via the Oakes method
(mod2 &lt;- mirt(data, 1, SE = TRUE, SE.type = 'SEM')) #standard errors with SEM method
coef(mod2)
(mod3 &lt;- mirt(data, 1, SE = TRUE, SE.type = 'Richardson')) #with numerical Richardson method
residuals(mod1)
plot(mod1) #test score function
plot(mod1, type = 'trace') #trace lines
plot(mod2, type = 'info') #test information
plot(mod2, MI=200) #expected total score with 95% confidence intervals

# estimated 3PL model for item 5 only
(mod1.3PL &lt;- mirt(data, 1, itemtype = c('2PL', '2PL', '2PL', '2PL', '3PL')))
coef(mod1.3PL)

# internally g and u pars are stored as logits, so usually a good idea to include normal prior
#  to help stabilize the parameters. For a value around .182 use a mean
#  of -1.5 (since 1 / (1 + exp(-(-1.5))) == .182)
model &lt;- 'F = 1-5
         PRIOR = (5, g, norm, -1.5, 3)'
mod1.3PL.norm &lt;- mirt(data, model, itemtype = c('2PL', '2PL', '2PL', '2PL', '3PL'))
coef(mod1.3PL.norm)
#limited information fit statistics
M2(mod1.3PL.norm)

# unidimensional ideal point model
idealpt &lt;- mirt(data, 1, itemtype = 'ideal')
plot(idealpt, type = 'trace', facet_items = TRUE)
plot(idealpt, type = 'trace', facet_items = FALSE)

# two factors (exploratory)
mod2 &lt;- mirt(data, 2)
coef(mod2)
summary(mod2, rotate = 'oblimin') #oblimin rotation
residuals(mod2)
plot(mod2)
plot(mod2, rotate = 'oblimin')

anova(mod1, mod2) #compare the two models
scoresfull &lt;- fscores(mod2) #factor scores for each response pattern
head(scoresfull)
scorestable &lt;- fscores(mod2, full.scores = FALSE) #save factor score table
head(scorestable)

# confirmatory (as an example, model is not identified since you need 3 items per factor)
# Two ways to define a confirmatory model: with mirt.model, or with a string

# these model definitions are equivalent
cmodel &lt;- mirt.model('
   F1 = 1,4,5
   F2 = 2,3')
cmodel2 &lt;- 'F1 = 1,4,5
            F2 = 2,3'

cmod &lt;- mirt(data, cmodel)
# cmod &lt;- mirt(data, cmodel2) # same as above
coef(cmod)
anova(cmod, mod2)
# check if identified by computing information matrix
(cmod &lt;- mirt(data, cmodel, SE = TRUE))

###########
# data from the 'ltm' package in numeric format
itemstats(Science)

pmod1 &lt;- mirt(Science, 1)
plot(pmod1)
plot(pmod1, type = 'trace')
plot(pmod1, type = 'itemscore')
summary(pmod1)

# Constrain all slopes to be equal with the constrain = list() input or mirt.model() syntax
# first obtain parameter index
values &lt;- mirt(Science,1, pars = 'values')
values #note that slopes are numbered 1,5,9,13, or index with values$parnum[values$name == 'a1']
(pmod1_equalslopes &lt;- mirt(Science, 1, constrain = list(c(1,5,9,13))))
coef(pmod1_equalslopes)

# using mirt.model syntax, constrain all item slopes to be equal
model &lt;- 'F = 1-4
          CONSTRAIN = (1-4, a1)'
(pmod1_equalslopes &lt;- mirt(Science, model))
coef(pmod1_equalslopes)

coef(pmod1_equalslopes)
anova(pmod1_equalslopes, pmod1) #significantly worse fit with almost all criteria

pmod2 &lt;- mirt(Science, 2)
summary(pmod2)
plot(pmod2, rotate = 'oblimin')
itemplot(pmod2, 1, rotate = 'oblimin')
anova(pmod1, pmod2)

# unidimensional fit with a generalized partial credit and nominal model
(gpcmod &lt;- mirt(Science, 1, 'gpcm'))
coef(gpcmod)

# for the nominal model the lowest and highest categories are assumed to be the
#  theoretically lowest and highest categories that related to the latent trait(s)
(nomod &lt;- mirt(Science, 1, 'nominal'))
coef(nomod) #ordering of ak values suggest that the items are indeed ordinal
anova(gpcmod, nomod)
itemplot(nomod, 3)

# generalized graded unfolding model
(ggum &lt;- mirt(Science, 1, 'ggum'))
coef(ggum, simplify=TRUE)
plot(ggum)
plot(ggum, type = 'trace')
plot(ggum, type = 'itemscore')

# monotonic polyomial models
(monopoly &lt;- mirt(Science, 1, 'monopoly'))
coef(monopoly, simplify=TRUE)
plot(monopoly)
plot(monopoly, type = 'trace')
plot(monopoly, type = 'itemscore')

# unipolar IRT model
unimod &lt;- mirt(Science, itemtype = 'ULL')
coef(unimod, simplify=TRUE)
plot(unimod)
plot(unimod, type = 'trace')
itemplot(unimod, 1)

# following use the correct log-normal density for latent trait
itemfit(unimod)
M2(unimod, type = 'C2')
fs &lt;- fscores(unimod)
hist(fs, 20)
fscores(unimod, method = 'EAPsum', full.scores = FALSE)

## example applying survey weights.
# weight the first half of the cases to be more representative of population
survey.weights &lt;- c(rep(2, nrow(Science)/2), rep(1, nrow(Science)/2))
survey.weights &lt;- survey.weights/sum(survey.weights) * nrow(Science)
unweighted &lt;- mirt(Science, 1)
weighted &lt;- mirt(Science, 1, survey.weights=survey.weights)

###########
# empirical dimensionality testing that includes 'guessing'

data(SAT12)
data &lt;- key2binary(SAT12,
  key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
itemstats(data)

mod1 &lt;- mirt(data, 1)
extract.mirt(mod1, 'time') #time elapsed for each estimation component

# optionally use Newton-Raphson for (generally) faster convergence in the M-step's
mod1 &lt;- mirt(data, 1, optimizer = 'NR')
extract.mirt(mod1, 'time')

mod2 &lt;- mirt(data, 2, optimizer = 'NR')
# difficulty converging with reduced quadpts, reduce TOL
mod3 &lt;- mirt(data, 3, TOL = .001, optimizer = 'NR')
anova(mod1,mod2)
anova(mod2, mod3) #negative AIC, 2 factors probably best

# same as above, but using the QMCEM method for generally better accuracy in mod3
mod3 &lt;- mirt(data, 3, method = 'QMCEM', TOL = .001, optimizer = 'NR')
anova(mod2, mod3)

# with fixed guessing parameters
mod1g &lt;- mirt(data, 1, guess = .1)
coef(mod1g)

###########
# graded rating scale example

# make some data
set.seed(1234)
a &lt;- matrix(rep(1, 10))
d &lt;- matrix(c(1,0.5,-.5,-1), 10, 4, byrow = TRUE)
c &lt;- seq(-1, 1, length.out=10)
data &lt;- simdata(a, d + c, 2000, itemtype = rep('graded',10))
itemstats(data)

mod1 &lt;- mirt(data, 1)
mod2 &lt;- mirt(data, 1, itemtype = 'grsm')
coef(mod2)
anova(mod2, mod1) #not sig, mod2 should be preferred
itemplot(mod2, 1)
itemplot(mod2, 5)
itemplot(mod2, 10)

###########
# 2PL nominal response model example (Suh and Bolt, 2010)
data(SAT12)
SAT12[SAT12 == 8] &lt;- NA #set 8 as a missing value
head(SAT12)

# correct answer key
key &lt;- c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5)
scoredSAT12 &lt;- key2binary(SAT12, key)
mod0 &lt;- mirt(scoredSAT12, 1)

# for first 5 items use 2PLNRM and nominal
scoredSAT12[,1:5] &lt;- as.matrix(SAT12[,1:5])
mod1 &lt;- mirt(scoredSAT12, 1, c(rep('nominal',5),rep('2PL', 27)))
mod2 &lt;- mirt(scoredSAT12, 1, c(rep('2PLNRM',5),rep('2PL', 27)), key=key)
coef(mod0)$Item.1
coef(mod1)$Item.1
coef(mod2)$Item.1
itemplot(mod0, 1)
itemplot(mod1, 1)
itemplot(mod2, 1)

# compare added information from distractors
Theta &lt;- matrix(seq(-4,4,.01))
par(mfrow = c(2,3))
for(i in 1:5){
    info &lt;- iteminfo(extract.item(mod0,i), Theta)
    info2 &lt;- iteminfo(extract.item(mod2,i), Theta)
    plot(Theta, info2, type = 'l', main = paste('Information for item', i), ylab = 'Information')
    lines(Theta, info, col = 'red')
}
par(mfrow = c(1,1))

# test information
plot(Theta, testinfo(mod2, Theta), type = 'l', main = 'Test information', ylab = 'Information')
lines(Theta, testinfo(mod0, Theta), col = 'red')

###########
# using the MH-RM algorithm
data(LSAT7)
fulldata &lt;- expand.table(LSAT7)
(mod1 &lt;- mirt(fulldata, 1, method = 'MHRM'))

# Confirmatory models

# simulate data
a &lt;- matrix(c(
1.5,NA,
0.5,NA,
1.0,NA,
1.0,0.5,
 NA,1.5,
 NA,0.5,
 NA,1.0,
 NA,1.0),ncol=2,byrow=TRUE)

d &lt;- matrix(c(
-1.0,NA,NA,
-1.5,NA,NA,
 1.5,NA,NA,
 0.0,NA,NA,
3.0,2.0,-0.5,
2.5,1.0,-1,
2.0,0.0,NA,
1.0,NA,NA),ncol=3,byrow=TRUE)

sigma &lt;- diag(2)
sigma[1,2] &lt;- sigma[2,1] &lt;- .4
items &lt;- c(rep('2PL',4), rep('graded',3), '2PL')
dataset &lt;- simdata(a,d,2000,items,sigma)

# analyses
# CIFA for 2 factor crossed structure

model.1 &lt;- '
  F1 = 1-4
  F2 = 4-8
  COV = F1*F2'

# compute model, and use parallel computation of the log-likelihood
if(interactive()) mirtCluster()
mod1 &lt;- mirt(dataset, model.1, method = 'MHRM')
coef(mod1)
summary(mod1)
residuals(mod1)

#####
# bifactor
model.3 &lt;- '
  G = 1-8
  F1 = 1-4
  F2 = 5-8'

mod3 &lt;- mirt(dataset,model.3, method = 'MHRM')
coef(mod3)
summary(mod3)
residuals(mod3)
anova(mod1,mod3)

#####
# polynomial/combinations
data(SAT12)
data &lt;- key2binary(SAT12,
                  key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))

model.quad &lt;- '
       F1 = 1-32
  (F1*F1) = 1-32'


model.combo &lt;- '
       F1 = 1-16
       F2 = 17-32
  (F1*F2) = 1-8'

(mod.quad &lt;- mirt(data, model.quad))
summary(mod.quad)
(mod.combo &lt;- mirt(data, model.combo))
anova(mod.combo, mod.quad)

# non-linear item and test plots
plot(mod.quad)
plot(mod.combo, type = 'SE')
itemplot(mod.quad, 1, type = 'score')
itemplot(mod.combo, 2, type = 'score')
itemplot(mod.combo, 2, type = 'infocontour')

## empirical histogram examples (normal, skew and bimodality)
# make some data
set.seed(1234)
a &lt;- matrix(rlnorm(50, .2, .2))
d &lt;- matrix(rnorm(50))
ThetaNormal &lt;- matrix(rnorm(2000))
ThetaBimodal &lt;- scale(matrix(c(rnorm(1000, -2), rnorm(1000,2)))) #bimodal
ThetaSkew &lt;- scale(matrix(rchisq(2000, 3))) #positive skew
datNormal &lt;- simdata(a, d, 2000, itemtype = '2PL', Theta=ThetaNormal)
datBimodal &lt;- simdata(a, d, 2000, itemtype = '2PL', Theta=ThetaBimodal)
datSkew &lt;- simdata(a, d, 2000, itemtype = '2PL', Theta=ThetaSkew)

normal &lt;- mirt(datNormal, 1, dentype = "empiricalhist")
plot(normal, type = 'empiricalhist')
histogram(ThetaNormal, breaks=30)

bimodal &lt;- mirt(datBimodal, 1, dentype = "empiricalhist")
plot(bimodal, type = 'empiricalhist')
histogram(ThetaBimodal, breaks=30)

skew &lt;- mirt(datSkew, 1, dentype = "empiricalhist")
plot(skew, type = 'empiricalhist')
histogram(ThetaSkew, breaks=30)

#####
# non-linear parameter constraints with Rsolnp package (nloptr supported as well):
# Find Rasch model subject to the constraint that the intercepts sum to 0

dat &lt;- expand.table(LSAT6)
itemstats(dat)

# free latent mean and variance terms
model &lt;- 'Theta = 1-5
          MEAN = Theta
          COV = Theta*Theta'

# view how vector of parameters is organized internally
sv &lt;- mirt(dat, model, itemtype = 'Rasch', pars = 'values')
sv[sv$est, ]

# constraint: create function for solnp to compute constraint, and declare value in eqB
eqfun &lt;- function(p, optim_args) sum(p[1:5]) #could use browser() here, if it helps
LB &lt;- c(rep(-15, 6), 1e-4) # more reasonable lower bound for variance term

mod &lt;- mirt(dat, model, sv=sv, itemtype = 'Rasch', optimizer = 'solnp',
   solnp_args=list(eqfun=eqfun, eqB=0, LB=LB))
print(mod)
coef(mod)
(ds &lt;- sapply(coef(mod)[1:5], function(x) x[,'d']))
sum(ds)

# same likelihood location as: mirt(dat, 1, itemtype = 'Rasch')


#######
# latent regression Rasch model

# simulate data
set.seed(1234)
N &lt;- 1000

# covariates
X1 &lt;- rnorm(N); X2 &lt;- rnorm(N)
covdata &lt;- data.frame(X1, X2)
Theta &lt;- matrix(0.5 * X1 + -1 * X2 + rnorm(N, sd = 0.5))

# items and response data
a &lt;- matrix(1, 20); d &lt;- matrix(rnorm(20))
dat &lt;- simdata(a, d, 1000, itemtype = '2PL', Theta=Theta)

# unconditional Rasch model
mod0 &lt;- mirt(dat, 1, 'Rasch')

# conditional model using X1 and X2 as predictors of Theta
mod1 &lt;- mirt(dat, 1, 'Rasch', covdata=covdata, formula = ~ X1 + X2)
coef(mod1, simplify=TRUE)
anova(mod0, mod1)

# bootstrapped confidence intervals
boot.mirt(mod1, R=5)

# draw plausible values for secondary analyses
pv &lt;- fscores(mod1, plausible.draws = 10)
pvmods &lt;- lapply(pv, function(x, covdata) lm(x ~ covdata$X1 + covdata$X2),
                 covdata=covdata)
# population characteristics recovered well, and can be averaged over
so &lt;- lapply(pvmods, summary)
so

# compute Rubin's multiple imputation average
par &lt;- lapply(so, function(x) x$coefficients[, 'Estimate'])
SEpar &lt;- lapply(so, function(x) x$coefficients[, 'Std. Error'])
averageMI(par, SEpar)

############
# Example using Gauss-Hermite quadrature with custom input functions

library(fastGHQuad)
data(SAT12)
data &lt;- key2binary(SAT12,
                   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
GH &lt;- gaussHermiteData(50)
Theta &lt;- matrix(GH$x)

# This prior works for uni- and multi-dimensional models
prior &lt;- function(Theta, Etable){
    P &lt;- grid &lt;- GH$w / sqrt(pi)
    if(ncol(Theta) &gt; 1)
        for(i in 2:ncol(Theta))
            P &lt;- expand.grid(P, grid)
     if(!is.vector(P)) P &lt;- apply(P, 1, prod)
     P
}

GHmod1 &lt;- mirt(data, 1, optimizer = 'NR',
              technical = list(customTheta = Theta, customPriorFun = prior))
coef(GHmod1, simplify=TRUE)

Theta2 &lt;- as.matrix(expand.grid(Theta, Theta))
GHmod2 &lt;- mirt(data, 2, optimizer = 'NR', TOL = .0002,
              technical = list(customTheta = Theta2, customPriorFun = prior))
summary(GHmod2, suppress=.2)

############
# Davidian curve example

dat &lt;- key2binary(SAT12,
                   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
dav &lt;- mirt(dat, 1, dentype = 'Davidian-4') # use four smoothing parameters
plot(dav, type = 'Davidian') # shape of latent trait distribution
coef(dav, simplify=TRUE)

fs &lt;- fscores(dav) # assume normal prior
fs2 &lt;- fscores(dav, use_dentype_estimate=TRUE) # use Davidian estimated prior shape
head(cbind(fs, fs2))

itemfit(dav) # assume normal prior
itemfit(dav, use_dentype_estimate=TRUE) # use Davidian estimated prior shape

###########
# 5PL and restricted 5PL example
dat &lt;- expand.table(LSAT7)

mod2PL &lt;- mirt(dat)
mod2PL

# Following does not converge without including strong priors
# mod5PL &lt;- mirt(dat, itemtype = '5PL')
# mod5PL

# restricted version of 5PL (asymmetric 2PL)
model &lt;- 'Theta = 1-5
          FIXED = (1-5, g), (1-5, u)'

mod2PL_asym &lt;- mirt(dat, model=model, itemtype = '5PL')
mod2PL_asym
coef(mod2PL_asym, simplify=TRUE)
coef(mod2PL_asym, simplify=TRUE, IRTpars=TRUE)

# no big difference statistically or visually
anova(mod2PL, mod2PL_asym)
plot(mod2PL, type = 'trace')
plot(mod2PL_asym, type = 'trace')


## End(Not run)
</code></pre>

<hr>
<h2 id='mirt.model'>Specify model information</h2><span id='topic+mirt.model'></span>

<h3>Description</h3>

<p>The <code>mirt.model</code> function scans/reads user input to specify the
confirmatory model. Item locations must be used in the specifications if no
<code>itemnames</code> argument is supplied. This is called implicitly by estimation functions
when a string is passed to the <code>model</code> argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mirt.model(
  input = NULL,
  itemnames = NULL,
  file = "",
  COV = NULL,
  quiet = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mirt.model_+3A_input">input</code></td>
<td>
<p>input for writing out the model syntax. Can either be a string declaration of
class character or the so-called Q-matrix or class <code>matrix</code> that specifies the model
either with integer or logical values. If the Q-matrix method
is chosen covariances terms can be specified with the <code>COV</code> input</p>
</td></tr>
<tr><td><code id="mirt.model_+3A_itemnames">itemnames</code></td>
<td>
<p>a character vector or factor indicating the item names. If a data.frame or
matrix object is supplied the names will be extracted using <code>colnames(itemnames)</code>.
Supplying this input allows the syntax to be specified with the raw item names rather than
item locations</p>
</td></tr>
<tr><td><code id="mirt.model_+3A_file">file</code></td>
<td>
<p>a input specifying an external file that declares the input.</p>
</td></tr>
<tr><td><code id="mirt.model_+3A_cov">COV</code></td>
<td>
<p>a symmetric, logical matrix used to declare which covariance terms are estimated</p>
</td></tr>
<tr><td><code id="mirt.model_+3A_quiet">quiet</code></td>
<td>
<p>logical argument passed to <code>scan()</code> to suppress console read message</p>
</td></tr>
<tr><td><code id="mirt.model_+3A_...">...</code></td>
<td>
<p>additional arguments for <code>scan()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Factors are first named and then specify which numerical items they affect
(i.e., where the slope is not equal to 0), separated either by commas or by
- to indicate a range of items. Products between factors may be specified
by enclosing the left hand term within brackets. To finish the declaration of
a model simply enter a blank line with only a carriage return (i.e., the
'enter' or 'return' key), or instead read in an input version of the model syntax.
The associated slopes throughout the package label these coefficients as
<code>a1, a2, ..., ak</code>, where the associated number is assigned according to the
respective order of the defined factors.
</p>
<p>For example, if the syntax were
</p>
<p><code>"G = 1-10
       F = 1-5
       A = 6-10"</code>
</p>
<p>then the <code>G</code> factor would be assigned the slopes <code>a1</code> for each item, <code>F</code> assigned
the slopes <code>a2</code>, and <code>A</code> assigned the slopes <code>a3</code>. The same principle applies to the
<code><a href="#topic+bfactor">bfactor</a></code> function whereby the slopes are automatically included for the specific factors
after the general factor structure has been assigned.
</p>
<p>There is an optional keyword for specifying the correlation between relationships between factors
called <code>COV</code>, and non-linear factor products can be included by enclosing the product
combination on the left hand side of the declaration (e.g., <code>(F1*F1)</code> would create a
quadratic factor for <code>F1</code>).
</p>
<p>The keywords <code>CONSTRAIN, CONSTRAINB, PRIOR, FIXED, FREE, START, UBOUND, LBOUND</code> can
be applied to specific sub-groups in multiple-group models by included square brackets before the
= sign, where groups are separated by commas. For example, to apply within-group equality
constraints to a group called &quot;male&quot;, then specifying:
</p>
<p><code>CONSTRAIN [male] = (1-5, a1)</code>
</p>
<p>is appropriate, while specifying the same constraints to the sub-groups
&quot;male&quot; and &quot;female&quot; would appear as
</p>
<p><code>CONSTRAIN [male, female] = (1-5, a1)</code>
</p>
<p>For all other groups in the multi-group model, these within-group equality constraints would not appear. Therefore, these
bracketed group specifications are useful when modifying priors, starting values, between/within group equality constraints,
and so on when the specifications for each sub-group may differ.
</p>
<p>Finally, the keyword <code>GROUP</code> can be used to specify the group-level
hyper-parameter terms, such as the means and variance of the default Gaussian
distribution. For example, to set the starting value of the variance
parameter (<code>COV_11</code>) to 1.5:
</p>
<p><code>START = (GROUP, COV_11, 1.5)</code>
</p>

<dl>
<dt>COV</dt><dd><p>Specify the relationship between the latent factors.
Estimating a correlation between factors is declared by joining the two
factors with an asterisk (e.g., F1*F2), or with an asterisk between three or more factors
to estimate all the possible correlations (e.g., F1*F2*F3)</p>
</dd>
<dt>MEAN</dt><dd><p>A comma separated list specifying which latent factor means to freely estimate.
E.g., <code>MEAN = F1, F2</code> will free the latent means for factors F1 and F2</p>
</dd>
<dt>CONSTRAIN</dt><dd><p>A bracketed, comma separated list specifying equality constrains between items.
The input format is
<code>CONSTRAIN = (items, ..., parameterName(s)),
  (items, ..., parameterName)</code>.
</p>
<p>For example, in a single group 10-item dichotomous tests, using the default 2PL model,
the first and last 5 item slopes (a1) can be constrained to be equal by using
<code>CONSTRAIN = (1-5, a1), (6-10, a1)</code>, or some combination
such as <code>CONSTRAIN = (1-3,4,5,a1), (6,7,8-10,a1)</code>.
</p>
<p>When constraining parameters to be equal across items with different parameter names, a
balanced bracketed vector must be supplied. E.g., setting the first slope for item 1 equal to
the second slope in item 3 would be <code>CONSTRAIN = (1, 3, a1, a2)</code>
</p>
</dd>
<dt>CONSTRAINB</dt><dd><p>A bracketed, comma separate list specifying equality constrains between groups.
The input format is <code>CONSTRAINB = (items, ..., parameterName),
  (items, ..., parameterName)</code>.
</p>
<p>For example, in a two group 10-item dichotomous tests, using the default 2PL model, the first
5 item slopes (a1) can be constrained to be equal across both groups by using
<code>CONSTRAINB = (1-5, a1)</code>, or some combination such as <code>CONSTRAINB = (1-3,4,5,a1)</code></p>
</dd>
<dt>PRIOR</dt><dd><p>A bracketed, comma separate list specifying prior parameter distributions.
The input format is
<code>PRIOR = (items, ..., parameterName, priorType, val1, val2),
  (items, ..., parameterName, priorType, val1, val2)</code>.
For example, in a single group 10-item dichotomous tests, using the default 2PL model,
defining a normal prior of N(0,2) for the first 5 item intercepts (d) can be defined by
<code>PRIOR = (1-5, d, norm, 0, 2)</code>
</p>
<p>Currently supported priors are of the form: <code>(items, norm, mean, sd)</code>
for the normal/Gaussian, <code>(items, lnorm, log_mean, log_sd)</code> for log-normal,
<code>(items, beta, alpha, beta)</code> for beta, and <code>(items, expbeta, alpha, beta)</code>
for the beta distribution after applying the
function <code><a href="stats.html#topic+plogis">plogis</a></code> to the input value (note, this is specifically for applying a beta
prior to the lower-bound parameters in 3/4PL models)</p>
</dd>
<dt>LBOUND</dt><dd><p>A bracketed, comma separate list specifying lower bounds for estimated
parameters (used in optimizers such as <code>L-BFGS-B</code> and <code>nlminb</code>).
The input format is <code>LBOUND = (items, ..., parameterName, value),
  (items, ..., parameterName, value)</code>.
</p>
<p>For example, in a single group 10-item dichotomous tests, using the 3PL model and
setting lower bounds for the 'g' parameters for the first 5 items to 0.2 is accomplished with
<code>LBOUND = (1-5, g, 0.2)</code></p>
</dd>
<dt>UBOUND</dt><dd><p>same as LBOUND, but specifying upper bounds in estimated parameters</p>
</dd>
<dt>START</dt><dd><p>A bracketed, comma separate list specifying the starting values for individual parameters.
The input is of the form <code>(items, ..., parameterName, value)</code>. For instance, setting the 10th and
12th to 15th item slope parameters (a1) to 1.0 is specified with <code>START = (10, 12-15, a1, 1.0)</code>
</p>
<p>For more hands on control of the starting values pass the argument <code>pars = 'values'</code> through
whatever estimation function is being used</p>
</dd>
<dt>FIXED</dt><dd><p>A bracketed, comma separate list specifying which parameters should be fixed at their
starting values (i.e., not freely estimated).
The input is of the form <code>(items, ..., parameterName)</code>. For instance, fixing the 10th and
12th to 15th item slope parameters (a1) is accomplished with <code>FIXED = (10, 12-15, a1)</code>
</p>
<p>For more hands on control of the estimated values pass the argument <code>pars = 'values'</code> through
whatever estimation function is being used</p>
</dd>
<dt>FREE</dt><dd><p>Equivalent to the <code>FIXED</code> input, except that parameters are freely estimated instead
of fixed at their starting value</p>
</dd>
<dt>NEXPLORE</dt><dd><p>Number of exploratory factors to extract. Usually this is not required
because passing a numeric value to the <code>model</code> argument in the estimation function
will generate an exploratory factor analysis model, however if different start values,
priors, lower and upper bounds, etc, are desired then this input can be used</p>
</dd>
</dl>



<h3>Value</h3>

<p>Returns a model specification object to be used in
<code><a href="#topic+mirt">mirt</a></code>, <code><a href="#topic+bfactor">bfactor</a></code>, <code><a href="#topic+multipleGroup">multipleGroup</a></code>, or
<code><a href="#topic+mixedmirt">mixedmirt</a></code>
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a> and Alexander Robitzsch
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# interactively through the console (not run)
#model &lt;- mirt.model()
#  F1 = 1,2,3,4-10
#  F2 = 10-20
#  (F1*F2) = 1,2,3,4-10
#  COV = F1*F2


# Or alternatively with a string input
s &lt;- 'F1 = 1,2,3,4-10
      F2 = 10-20
      (F1*F2) = 1,2,3,4-10
      COV = F1*F2'
model &lt;- mirt.model(s)

# strings can also be passed to the estimation functions directly,
#   which silently calls mirt.model(). E.g., using the string above:
# mod &lt;- mirt(data, s)


# Q-matrix specification
Q &lt;- matrix(c(1,1,1,0,0,0,0,0,0,1,1,1), ncol=2, dimnames = list(NULL, c('Factor1', 'Factor2')))
COV &lt;- matrix(c(FALSE, TRUE, TRUE, FALSE), 2)
model &lt;- mirt.model(Q, COV=COV)

## constrain various items slopes and all intercepts in single group model to be equal,
#   and use a log-normal prior for all the slopes
s &lt;- 'F = 1-10
      CONSTRAIN = (1-3, 5, 6, a1), (1-10, d)
      PRIOR = (1-10, a1, lnorm, .2, .2)'
model &lt;- mirt.model(s)


## constrain various items slopes and intercepts across groups for use in multipleGroup(),
#  and constrain first two slopes within 'group1' to be equal
s &lt;- 'F = 1-10
      CONSTRAIN = (1-2, a1)
      CONSTRAINB = (1-3, 5, 6, a1), (1-10, d)'
model &lt;- mirt.model(s)


## specify model using raw item names
data(data.read, package = 'sirt')
dat &lt;- data.read

# syntax with variable names
mirtsyn2 &lt;- "
       F1 = A1,B2,B3,C4
       F2 = A1-A4,C2,C4
       MEAN = F1
       COV = F1*F1, F1*F2
       CONSTRAIN=(A2-A4,a2),(A3,C2,d)
       PRIOR = (C3,A2-A4,a2,lnorm, .2, .2),(B3,d,norm,0,.0001)"
# create a mirt model
mirtmodel &lt;- mirt.model(mirtsyn2, itemnames=dat)
# or equivalently:
# mirtmodel &lt;- mirt.model(mirtsyn2, itemnames=colnames(dat))

# mod &lt;- mirt(dat , mirtmodel)

    
## End(Not run)
</code></pre>

<hr>
<h2 id='mirtCluster'>Define a parallel cluster object to be used in internal functions</h2><span id='topic+mirtCluster'></span>

<h3>Description</h3>

<p>This function defines a object that is placed in a relevant internal environment defined in mirt.
Internal functions such as <code>calcLogLik</code>, <code>fscores</code>, etc, will utilize this object
automatically to capitalize on parallel
processing architecture. The object defined is a call from <code>parallel::makeCluster()</code>.
Note that if you are defining other parallel objects (for simulation designs, for example)
it is not recommended to define a mirtCluster.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mirtCluster(spec, omp_threads, remove = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mirtCluster_+3A_spec">spec</code></td>
<td>
<p>input that is passed to <code>parallel::makeCluster()</code>. If no input is given the
maximum number of available local cores minus 1 will be used.
Setting this to NULL will skip a new definition (allows <code>omp_threads</code> to be used independently)</p>
</td></tr>
<tr><td><code id="mirtCluster_+3A_omp_threads">omp_threads</code></td>
<td>
<p>number of OpenMP threads to use (currently applies to E-step computations only).
Not used when argument input is missing</p>
</td></tr>
<tr><td><code id="mirtCluster_+3A_remove">remove</code></td>
<td>
<p>logical; remove previously defined <code>mirtCluster()</code>?</p>
</td></tr>
<tr><td><code id="mirtCluster_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to <code>parallel::makeCluster</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
if(interactive()){
  # use all available cores
  mirtCluster()
  mirtCluster(remove = TRUE)

  # make 4 cores available for parallel computing
  mirtCluster(4)
  mirtCluster(remove = TRUE)

  # create 3 core architecture in R, and 4 thread architecture with OpenMP
  mirtCluster(spec = 3, omp_threads = 4)

  # leave previous multicore objects, but change omp_threads
  mirtCluster(spec = NULL, omp_threads = 2)
}


## End(Not run)
</code></pre>

<hr>
<h2 id='MixedClass-class'>Class &quot;MixedClass&quot;</h2><span id='topic+MixedClass-class'></span>

<h3>Description</h3>

<p>Defines the object returned from <code><a href="#topic+mixedmirt">mixedmirt</a></code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>Call</code>:</dt><dd><p>function call </p>
</dd>
<dt><code>Data</code>:</dt><dd><p>list of data, sometimes in different forms </p>
</dd>
<dt><code>Options</code>:</dt><dd><p>list of estimation options</p>
</dd>
<dt><code>Fit</code>:</dt><dd><p>a list of fit information </p>
</dd>
<dt><code>Model</code>:</dt><dd><p>a list of model-based information </p>
</dd>
<dt><code>ParObjects</code>:</dt><dd><p>a list of the S4 objects used during estimation</p>
</dd>
<dt><code>OptimInfo</code>:</dt><dd><p>a list of arguments from the optimization process</p>
</dd>
<dt><code>Internals</code>:</dt><dd><p>a list of internal arguments for secondary computations (inspecting this
object is generally not required)</p>
</dd>
<dt><code>vcov</code>:</dt><dd><p>a matrix represented the asymptotic covariance matrix of the parameter estimates</p>
</dd>
<dt><code>time</code>:</dt><dd><p>a data.frame indicating the breakdown of computation times in seconds</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>coef</dt><dd><p><code>signature(object = "MixedClass")</code></p>
</dd>
<dt>print</dt><dd><p><code>signature(x = "MixedClass")</code> </p>
</dd>
<dt>residuals</dt><dd><p><code>signature(object = "MixedClass")</code></p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "MixedClass")</code> </p>
</dd>
<dt>summary</dt><dd><p><code>signature(object = "MixedClass")</code> </p>
</dd>
<dt>logLik</dt><dd><p><code>signature(object = "MixedClass")</code> </p>
</dd>
<dt>anova</dt><dd><p><code>signature(object = "MixedClass")</code> </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>

<hr>
<h2 id='mixedmirt'>Mixed effects modeling for MIRT models</h2><span id='topic+mixedmirt'></span>

<h3>Description</h3>

<p><code>mixedmirt</code> fits MIRT models using FIML estimation to dichotomous and polytomous
IRT models conditional on fixed and random effect of person and item level covariates.
This can also be understood as 'explanatory IRT' if only fixed effects are modeled, or
multilevel/mixed IRT if random and fixed effects are included. The method uses the MH-RM
algorithm exclusively. Additionally, computation of the log-likelihood can be sped up by
using parallel estimation via <code><a href="#topic+mirtCluster">mirtCluster</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mixedmirt(
  data,
  covdata = NULL,
  model = 1,
  fixed = ~1,
  random = NULL,
  itemtype = "Rasch",
  lr.fixed = ~1,
  lr.random = NULL,
  itemdesign = NULL,
  constrain = NULL,
  pars = NULL,
  return.design = FALSE,
  SE = TRUE,
  internal_constraints = TRUE,
  technical = list(SEtol = 1e-04),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mixedmirt_+3A_data">data</code></td>
<td>
<p>a <code>matrix</code> or <code>data.frame</code> that consists of
numerically ordered data, with missing data coded as <code>NA</code></p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_covdata">covdata</code></td>
<td>
<p>a <code>data.frame</code> that consists of the <code>nrow(data)</code> by <code>K</code>
'person level' fixed and random predictors. If missing data are present in this object
then the observations from <code>covdata</code> and <code>data</code> will be removed row-wise
via the <code>rowSums(is.na(covdata)) &gt; 0</code></p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_model">model</code></td>
<td>
<p>an object returned from, or a string to be passed to, <code>mirt.model()</code>
to declare how the IRT model is to be estimated. See <code><a href="#topic+mirt.model">mirt.model</a></code> and
<code><a href="#topic+mirt">mirt</a></code> for more detail</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_fixed">fixed</code></td>
<td>
<p>a right sided R formula for specifying the fixed effect (aka 'explanatory')
predictors from <code>covdata</code> and <code>itemdesign</code>. To estimate the intercepts for
each item the keyword <code>items</code> is reserved and automatically added to the <code>itemdesign</code>
input. If any polytomous items are being model the <code>items</code> are argument is not valid
since all intercept parameters are freely estimated and identified with the parameterizations
found in <code><a href="#topic+mirt">mirt</a></code>, and the first column in the fixed design matrix
(commonly the intercept or a reference group) is omitted</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_random">random</code></td>
<td>
<p>a right sided formula or list of formulas containing crossed random effects
of the form <code>v1 + ... v_n | G</code>, where <code>G</code> is the grouping variable and <code>v_n</code> are
random numeric predictors within each group. If no intercept value is specified then by default
the correlations between the <code>v</code>'s and <code>G</code> are estimated, but can be suppressed by
including the <code>~ -1 + ...</code> or 0 constant. <code>G</code> may contain interaction terms, such as
<code>group:items</code> to include cross or person-level interactions effects</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_itemtype">itemtype</code></td>
<td>
<p>same as itemtype in <code><a href="#topic+mirt">mirt</a></code>, except when the <code>fixed</code>
or <code>random</code> inputs are used does not support the following
item types: <code>c('PC2PL', 'PC3PL', '2PLNRM', '3PLNRM', '3PLuNRM', '4PLNRM')</code></p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_lr.fixed">lr.fixed</code></td>
<td>
<p>an R formula (or list of formulas) to specify regression
effects in the latent variables from the variables in <code>covdata</code>. This is used to construct models such as the so-called
'latent regression model' to explain person-level ability/trait differences. If a named list
of formulas is supplied (where the names correspond to the latent trait names in <code>model</code>)
then specific regression effects can be estimated for each factor. Supplying a single formula
will estimate the regression parameters for all latent traits by default.</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_lr.random">lr.random</code></td>
<td>
<p>a list of random effect terms for modeling variability in the
latent trait scores, where the syntax uses the same style as in the <code>random</code> argument.
Useful for building so-called 'multilevel IRT' models which are non-Rasch (multilevel Rasch
models do not technically require these because they can be built using the
<code>fixed</code> and <code>random</code> inputs alone)</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_itemdesign">itemdesign</code></td>
<td>
<p>a <code>data.frame</code> object used to create a design matrix for the items, where
each <code>nrow(itemdesign) == nitems</code> and the number of columns is equal to the number of
fixed effect predictors (i.e., item intercepts). By default an <code>items</code> variable is
reserved for modeling the item intercept parameters</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_constrain">constrain</code></td>
<td>
<p>a list indicating parameter equality constrains. See <code><a href="#topic+mirt">mirt</a></code> for
more detail</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_pars">pars</code></td>
<td>
<p>used for parameter starting values. See <code><a href="#topic+mirt">mirt</a></code> for more detail</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_return.design">return.design</code></td>
<td>
<p>logical; return the design matrices before they have (potentially)
been reassigned?</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_se">SE</code></td>
<td>
<p>logical; compute the standard errors by approximating the information matrix
using the MHRM algorithm? Default is TRUE</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_internal_constraints">internal_constraints</code></td>
<td>
<p>logical; use the internally defined constraints for constraining
effects across persons and items? Default is TRUE. Setting this to FALSE runs the risk of
under-identification</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_technical">technical</code></td>
<td>
<p>the technical list passed to the MH-RM estimation engine, with the
SEtol default increased to .0001. Additionally, the argument <code>RANDSTART</code> is available
to indicate at which iteration (during the burn-in stage) the additional random effect
variables should begin to be approximated (i.e.,
elements in <code>lr.random</code> and <code>random</code>). The default for <code>RANDSTART</code> is to start
at iteration 100, and when random effects are included the default number of burn-in iterations is increased
from 150 to 200. See <code><a href="#topic+mirt">mirt</a></code> for further details</p>
</td></tr>
<tr><td><code id="mixedmirt_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the MH-RM estimation engine. See
<code><a href="#topic+mirt">mirt</a></code> for more details and examples</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For dichotomous response models, <code>mixedmirt</code> follows the general form
</p>
<p style="text-align: center;"><code class="reqn">P(x = 1|\theta, \psi) = g + \frac{(u - g)}{1 + exp(-1 * [\theta a +
 X \beta + Z \delta])}</code>
</p>

<p>where X is a design matrix with associated <code class="reqn">\beta</code> fixed effect intercept coefficients,
and Z is a design matrix with associated <code class="reqn">\delta</code> random effects for the intercepts.
For simplicity and easier interpretation, the unique item intercept values typically found in
<code class="reqn">X \beta</code>
are extracted and reassigned within mirt's 'intercept' parameters (e.g., <code>'d'</code>).
To observe how the design matrices are structured prior to reassignment and estimation pass
the argument <code>return.design = TRUE</code>.
</p>
<p>Polytomous IRT models follow a similar format except the item intercepts are automatically
estimated internally, rendering the <code>items</code> argument in the fixed formula redundant and
therefore must be omitted from the specification. If there are a mixture of dichotomous and
polytomous items the intercepts for the dichotomous models are also estimated for consistency.
</p>
<p>The decomposition of the <code class="reqn">\theta</code> parameters is also possible to form
latent regression and multilevel IRT models by using the <code>lr.fixed</code> and <code>lr.random</code>
inputs. These effects decompose <code class="reqn">\theta</code> such that
</p>
<p style="text-align: center;"><code class="reqn">\theta = V \Gamma + W \zeta + \epsilon</code>
</p>

<p>where V and W are fixed and random effects design matrices for the associated coefficients.
</p>
<p>To simulate expected a posteriori predictions for the random effect terms
use the <code><a href="#topic+randef">randef</a></code> function.
</p>


<h3>Value</h3>

<p>function returns an object of class <code>MixedClass</code>
(<a href="#topic+MixedClass-class">MixedClass-class</a>).
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models with the MH-RM Algorithm.
<em>Journal of Educational Measurement, 52</em>, 200-222. <a href="https://doi.org/10.1111/jedm.12072">doi:10.1111/jedm.12072</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mirt">mirt</a></code>, <code><a href="#topic+randef">randef</a></code>, <code><a href="#topic+fixef">fixef</a></code>, <code><a href="#topic+boot.mirt">boot.mirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

# make some data
set.seed(1234)
N &lt;- 750
a &lt;- matrix(rlnorm(10,.3,1),10,1)
d &lt;- matrix(rnorm(10), 10)
Theta &lt;- matrix(sort(rnorm(N)))
pseudoIQ &lt;- Theta * 5 + 100  + rnorm(N, 0 , 5)
pseudoIQ &lt;- (pseudoIQ - mean(pseudoIQ))/10  #rescale variable for numerical stability
group &lt;- factor(rep(c('G1','G2','G3'), each = N/3))
data &lt;- simdata(a,d,N, itemtype = rep('2PL',10), Theta=Theta)
covdata &lt;- data.frame(group, pseudoIQ)

itemstats(data)

# use parallel computing
if(interactive()) mirtCluster()

# specify IRT model
model &lt;- 'Theta = 1-10'

# model with no person predictors
mod0 &lt;- mirt(data, model, itemtype = 'Rasch')

# group as a fixed effect predictor (aka, uniform dif)
mod1 &lt;- mixedmirt(data, covdata, model, fixed = ~ 0 + group + items)
anova(mod0, mod1)
summary(mod1)
coef(mod1)

# same model as above in lme4
wide &lt;- data.frame(id=1:nrow(data),data,covdata)
long &lt;- reshape2::melt(wide, id.vars = c('id', 'group', 'pseudoIQ'))
library(lme4)
lmod0 &lt;- glmer(value ~ 0 + variable + (1|id), long, family = binomial)
lmod1 &lt;- glmer(value ~ 0 + group + variable + (1|id), long, family = binomial)
anova(lmod0, lmod1)

# model using 2PL items instead of Rasch
mod1b &lt;- mixedmirt(data, covdata, model, fixed = ~ 0 + group + items, itemtype = '2PL')
anova(mod1, mod1b) #better with 2PL models using all criteria (as expected, given simdata pars)

# continuous predictor with group
mod2 &lt;- mixedmirt(data, covdata, model, fixed = ~ 0 + group + items + pseudoIQ)
summary(mod2)
anova(mod1b, mod2)

# view fixed design matrix with and without unique item level intercepts
withint &lt;- mixedmirt(data, covdata, model, fixed = ~ 0 + items + group, return.design = TRUE)
withoutint &lt;- mixedmirt(data, covdata, model, fixed = ~ 0 + group, return.design = TRUE)

# notice that in result above, the intercepts 'items1 to items 10' were reassigned to 'd'
head(withint$X)
tail(withint$X)
head(withoutint$X) # no intercepts design here to be reassigned into item intercepts
tail(withoutint$X)

###################################################
### random effects
# make the number of groups much larger
covdata$group &lt;- factor(rep(paste0('G',1:50), each = N/50))

# random groups
rmod1 &lt;- mixedmirt(data, covdata, 1, fixed = ~ 0 + items, random = ~ 1|group)
summary(rmod1)
coef(rmod1)

# random groups and random items
rmod2 &lt;- mixedmirt(data, covdata, 1, random = list(~ 1|group, ~ 1|items))
summary(rmod2)
eff &lt;- randef(rmod2) #estimate random effects

# random slopes with fixed intercepts (suppressed correlation)
rmod3 &lt;- mixedmirt(data, covdata, 1, fixed = ~ 0 + items, random = ~ -1 + pseudoIQ|group)
summary(rmod3)
eff &lt;- randef(rmod3)
str(eff)

###################################################
## LLTM, and 2PL version of LLTM
data(SAT12)
data &lt;- key2binary(SAT12,
                   key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
model &lt;- 'Theta = 1-32'

# Suppose that the first 16 items were suspected to be easier than the last 16 items,
#   and we wish to test this item structure hypothesis (more intercept designs are possible
#   by including more columns).
itemdesign &lt;- data.frame(itemorder = factor(c(rep('easier', 16), rep('harder', 16))))

# notice that the 'fixed = ~ ... + items' argument is omitted
LLTM &lt;- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, itemdesign = itemdesign,
   SE = TRUE) # SE argument ensures that the information matrix is computed accurately
summary(LLTM)
coef(LLTM)
wald(LLTM)
L &lt;- matrix(c(-1, 1, 0), 1)
wald(LLTM, L) #first half different from second

# compare to items with estimated slopes (2PL)
twoPL &lt;- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, itemtype = '2PL',
                   itemdesign = itemdesign)
# twoPL not mixing too well (AR should be between .2 and .5), decrease MHcand
twoPL &lt;- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, itemtype = '2PL',
                  itemdesign = itemdesign, technical = list(MHcand = 0.8))
anova(twoPL, LLTM) #much better fit
summary(twoPL)
coef(twoPL)

wald(twoPL)
L &lt;- matrix(0, 1, 34)
L[1, 1] &lt;- 1
L[1, 2] &lt;- -1
wald(twoPL, L) # n.s., which is the correct conclusion. Rasch approach gave wrong inference

## LLTM with item error term
LLTMwithError &lt;- mixedmirt(data, model = model, fixed = ~ 0 + itemorder, random = ~ 1|items,
    itemdesign = itemdesign)
summary(LLTMwithError)
# large item level variance after itemorder is regressed; not a great predictor of item difficulty
coef(LLTMwithError)

###################################################
### Polytomous example

# make an arbitrary group difference
covdat &lt;- data.frame(group = rep(c('m', 'f'), nrow(Science)/2))

# partial credit model
mod &lt;- mixedmirt(Science, covdat, model=1, fixed = ~ 0 + group)
coef(mod)

# gpcm to estimate slopes
mod2 &lt;- mixedmirt(Science, covdat, model=1, fixed = ~ 0 + group,
                 itemtype = 'gpcm')
summary(mod2)
anova(mod, mod2)

# graded model
mod3 &lt;- mixedmirt(Science, covdat, model=1, fixed = ~ 0 + group,
                 itemtype = 'graded')
coef(mod3)


###################################################
# latent regression with Rasch and 2PL models

set.seed(1)
n &lt;- 300
a &lt;- matrix(1, 10)
d &lt;- matrix(rnorm(10))
Theta &lt;- matrix(c(rnorm(n, 0), rnorm(n, 1), rnorm(n, 2)))
covdata &lt;- data.frame(group=rep(c('g1','g2','g3'), each=n))
dat &lt;- simdata(a, d, N=n*3, Theta=Theta, itemtype = '2PL')
itemstats(dat)

# had we known the latent abilities, we could have computed the regression coefs
summary(lm(Theta ~ covdata$group))

# but all we have is observed test data. Latent regression helps to recover these coefs
# Rasch model approach (and mirt equivalent)
rmod0 &lt;- mirt(dat, 1, 'Rasch') # unconditional

# these two models are equivalent
rmod1a &lt;- mirt(dat, 1, 'Rasch', covdata = covdata, formula = ~ group)
rmod1b &lt;- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items + group)
anova(rmod0, rmod1b)
coef(rmod1a, simplify=TRUE)
summary(rmod1b)

# 2PL, requires different input to allow Theta variance to remain fixed
mod0 &lt;- mirt(dat, 1) # unconditional
mod1a &lt;- mirt(dat, 1, covdata = covdata, formula = ~ group, itemtype = '2PL')
mod1b &lt;- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, lr.fixed = ~group, itemtype = '2PL')
anova(mod0, mod1b)
coef(mod1a)$lr.betas
summary(mod1b)

# specifying specific regression effects is accomplished by passing a list of formula
model &lt;- 'F1 = 1-5
         F2 = 6-10'
covdata$contvar &lt;- rnorm(nrow(covdata))
mod2 &lt;- mirt(dat, model, itemtype = 'Rasch', covdata=covdata,
        formula = list(F1 = ~ group + contvar, F2 = ~ group))
coef(mod2)[11:12]
mod2b &lt;- mixedmirt(dat, covdata, model, fixed = ~ 0 + items,
        lr.fixed = list(F1 = ~ group + contvar, F2 = ~ group))
summary(mod2b)

####################################################
## Simulated Multilevel Rasch Model

set.seed(1)
N &lt;- 2000
a &lt;- matrix(rep(1,10),10,1)
d &lt;- matrix(rnorm(10))
cluster = 100
random_intercept = rnorm(cluster,0,1)
Theta = numeric()
for (i in 1:cluster)
    Theta &lt;- c(Theta, rnorm(N/cluster,0,1) + random_intercept[i])

group = factor(rep(paste0('G',1:cluster), each = N/cluster))
covdata &lt;- data.frame(group)
dat &lt;- simdata(a,d,N, itemtype = rep('2PL',10), Theta=matrix(Theta))
itemstats(dat)

# null model
mod1 &lt;- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, random = ~ 1|group)
summary(mod1)

# include level 2 predictor for 'group' variance
covdata$group_pred &lt;- rep(random_intercept, each = N/cluster)
mod2 &lt;- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items + group_pred, random = ~ 1|group)

# including group means predicts nearly all variability in 'group'
summary(mod2)
anova(mod1, mod2)

# can also be fit for Rasch/non-Rasch models with the lr.random input
mod1b &lt;- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, lr.random = ~ 1|group)
summary(mod1b)

mod2b &lt;- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items + group_pred, lr.random = ~ 1|group)
summary(mod2b)
anova(mod1b, mod2b)

mod3 &lt;- mixedmirt(dat, covdata, 1, fixed = ~ 0 + items, lr.random = ~ 1|group, itemtype = '2PL')
summary(mod3)
anova(mod1b, mod3)

head(cbind(randef(mod3)$group, random_intercept))


## End(Not run)
</code></pre>

<hr>
<h2 id='MixtureClass-class'>Class &quot;MixtureClass&quot;</h2><span id='topic+MixtureClass-class'></span>

<h3>Description</h3>

<p>Defines the object returned from <code><a href="#topic+multipleGroup">multipleGroup</a></code> when estimated with
mixture distributions.
</p>


<h3>Slots</h3>


<dl>
<dt><code>Call</code>:</dt><dd><p>function call </p>
</dd>
<dt><code>Data</code>:</dt><dd><p>list of data, sometimes in different forms </p>
</dd>
<dt><code>Options</code>:</dt><dd><p>list of estimation options</p>
</dd>
<dt><code>Fit</code>:</dt><dd><p>a list of fit information </p>
</dd>
<dt><code>Model</code>:</dt><dd><p>a list of model-based information </p>
</dd>
<dt><code>ParObjects</code>:</dt><dd><p>a list of the S4 objects used during estimation</p>
</dd>
<dt><code>OptimInfo</code>:</dt><dd><p>a list of arguments from the optimization process</p>
</dd>
<dt><code>Internals</code>:</dt><dd><p>a list of internal arguments for secondary computations (inspecting this
object is generally not required)</p>
</dd>
<dt><code>vcov</code>:</dt><dd><p>a matrix represented the asymptotic covariance matrix of the parameter estimates</p>
</dd>
<dt><code>time</code>:</dt><dd><p>a data.frame indicating the breakdown of computation times in seconds</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>coef</dt><dd><p><code>signature(object = "MixtureClass")</code></p>
</dd>
<dt>print</dt><dd><p><code>signature(x = "MixtureClass")</code> </p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "MixtureClass")</code> </p>
</dd>
<dt>anova</dt><dd><p><code>signature(object = "MixtureClass")</code> </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>

<hr>
<h2 id='mod2values'>Convert an estimated mirt model to a data.frame</h2><span id='topic+mod2values'></span>

<h3>Description</h3>

<p>Given an estimated model from any of mirt's model fitting functions this function will convert
the model parameters into the design data frame of starting values and other parameter
characteristics (similar to using the <code>pars = 'values'</code> for obtaining starting values).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mod2values(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mod2values_+3A_x">x</code></td>
<td>
<p>an estimated model x from the mirt package</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract.mirt">extract.mirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
dat &lt;- expand.table(LSAT7)
mod &lt;- mirt(dat, 1)
values &lt;- mod2values(mod)
values

#use the converted values as starting values in a new model, and reduce TOL
mod2 &lt;- mirt(dat, 1, pars = values, TOL=1e-5)


## End(Not run)
</code></pre>

<hr>
<h2 id='multipleGroup'>Multiple Group Estimation</h2><span id='topic+multipleGroup'></span>

<h3>Description</h3>

<p><code>multipleGroup</code> performs a full-information
maximum-likelihood multiple group analysis for any combination of dichotomous and polytomous
data under the item response theory paradigm using either Cai's (2010)
Metropolis-Hastings Robbins-Monro (MHRM) algorithm or with an EM algorithm approach. This
function may be used for detecting differential item functioning (DIF), thought the
<code><a href="#topic+DIF">DIF</a></code> function may provide a more convenient approach. If the grouping
variable is not specified then the <code>dentype</code> input can be modified to fit
mixture models to estimate any latent group components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multipleGroup(
  data,
  model = 1,
  group,
  itemtype = NULL,
  invariance = "",
  method = "EM",
  dentype = "Gaussian",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multipleGroup_+3A_data">data</code></td>
<td>
<p>a <code>matrix</code> or <code>data.frame</code> that consists of
numerically ordered data, with missing data coded as <code>NA</code></p>
</td></tr>
<tr><td><code id="multipleGroup_+3A_model">model</code></td>
<td>
<p>string to be passed to, or a model object returned from, <code><a href="#topic+mirt.model">mirt.model</a></code>
declaring how the global model is to be estimated (useful to apply constraints here)</p>
</td></tr>
<tr><td><code id="multipleGroup_+3A_group">group</code></td>
<td>
<p>a <code>character</code> or <code>factor</code> vector indicating group membership. If a <code>character</code>
vector is supplied this will be automatically transformed into a <code><a href="base.html#topic+factor">factor</a></code> variable.
As well, the first level of the (factorized) grouping variable will be treated as the &quot;reference&quot; group</p>
</td></tr>
<tr><td><code id="multipleGroup_+3A_itemtype">itemtype</code></td>
<td>
<p>can be same type of input as is documented in <code><a href="#topic+mirt">mirt</a></code>, however may also be a
<code>ngroups</code> by <code>nitems</code> matrix specifying the type of IRT models for each group, respectively.
Rows of this input correspond to the levels of the <code>group</code> input. For mixture models the rows correspond
to the respective mixture grouping variables to be constructed, and the IRT models should be within these
mixtures</p>
</td></tr>
<tr><td><code id="multipleGroup_+3A_invariance">invariance</code></td>
<td>
<p>a character vector containing the following possible options:
</p>

<dl>
<dt><code>'free_mean'</code> or <code>'free_means'</code></dt><dd><p>freely estimate all latent means in all focal groups
(reference group constrained to a vector of 0's)</p>
</dd>
<dt><code>'free_var'</code>, <code>'free_vars'</code>, <code>'free_variance'</code>, or <code>'free_variances'</code></dt><dd>
<p>freely estimate all latent variances in focal groups
(reference group variances all constrained to 1)</p>
</dd>
<dt><code>'slopes'</code></dt><dd><p>to constrain all the slopes to be equal across all groups</p>
</dd>
<dt><code>'intercepts'</code></dt><dd><p>to constrain all the intercepts to be equal across all
groups, note for nominal models this also includes the category specific slope parameters</p>
</dd>
</dl>

<p>Additionally, specifying specific item name bundles (from <code>colnames(data)</code>) will
constrain all freely estimated parameters in each item to be equal across groups. This is
useful for selecting 'anchor' items for vertical and horizontal scaling, and for detecting
differential item functioning (DIF) across groups</p>
</td></tr>
<tr><td><code id="multipleGroup_+3A_method">method</code></td>
<td>
<p>a character object that is either <code>'EM'</code>, <code>'QMCEM'</code>, or <code>'MHRM'</code>
(default is <code>'EM'</code>). See <code><a href="#topic+mirt">mirt</a></code> for details</p>
</td></tr>
<tr><td><code id="multipleGroup_+3A_dentype">dentype</code></td>
<td>
<p>type of density form to use for the latent trait parameters. Current options include
all of the methods described in <code><a href="#topic+mirt">mirt</a></code>, as well as
</p>

<ul>
<li> <p><code>'mixture-#'</code> estimates mixtures of Gaussian distributions,
where the <code>#</code> placeholder represents the number of potential grouping variables
(e.g., <code>'mixture-3'</code> will estimate 3 underlying classes). Each class is
assigned the group name <code>MIXTURE_#</code>, where <code>#</code> is the class number.
Note that internally the mixture coefficients are stored as log values where
the first mixture group coefficient is fixed at 0
</p>
</li></ul>
</td></tr>
<tr><td><code id="multipleGroup_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to the estimation engine. See <code><a href="#topic+mirt">mirt</a></code>
for details and examples</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default the estimation in <code>multipleGroup</code> assumes that the models are maximally
independent, and therefore could initially be performed by sub-setting the data and running
identical models with <code>mirt</code> and aggregating the results (e.g., log-likelihood).
However, constrains may be automatically imposed across groups by invoking various
<code>invariance</code> keywords. Users may also supply a list of parameter equality constraints
to by <code>constrain</code> argument, of define equality constraints using the
<code><a href="#topic+mirt.model">mirt.model</a></code> syntax (recommended).
</p>


<h3>Value</h3>

<p>function returns an object of class <code>MultipleGroupClass</code>
(<a href="#topic+MultipleGroupClass-class">MultipleGroupClass-class</a>).
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mirt">mirt</a></code>, <code><a href="#topic+DIF">DIF</a></code>, <code><a href="#topic+extract.group">extract.group</a></code>, <code><a href="#topic+DRF">DRF</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# single factor
set.seed(12345)
a &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d &lt;- matrix(rnorm(15,0,.7),ncol=1)
itemtype &lt;- rep('2PL', nrow(a))
N &lt;- 1000
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5))
dat &lt;- rbind(dataset1, dataset2)
group &lt;- c(rep('D1', N), rep('D2', N))

# marginal information
itemstats(dat)

# conditional information
itemstats(dat, group=group)

mod_configural &lt;- multipleGroup(dat, 1, group = group) #completely separate analyses
# limited information fit statistics
M2(mod_configural)

mod_metric &lt;- multipleGroup(dat, 1, group = group, invariance=c('slopes')) #equal slopes
# equal intercepts, free variance and means
mod_scalar2 &lt;- multipleGroup(dat, 1, group = group,
                             invariance=c('slopes', 'intercepts', 'free_var','free_means'))
mod_scalar1 &lt;- multipleGroup(dat, 1, group = group,  #fixed means
                             invariance=c('slopes', 'intercepts', 'free_var'))
mod_fullconstrain &lt;- multipleGroup(dat, 1, group = group,
                             invariance=c('slopes', 'intercepts'))
extract.mirt(mod_fullconstrain, 'time') #time of estimation components

# optionally use Newton-Raphson for (generally) faster convergence in the M-step's
mod_fullconstrain &lt;- multipleGroup(dat, 1, group = group, optimizer = 'NR',
                             invariance=c('slopes', 'intercepts'))
extract.mirt(mod_fullconstrain, 'time') #time of estimation components

summary(mod_scalar2)
coef(mod_scalar2, simplify=TRUE)
residuals(mod_scalar2)
plot(mod_configural)
plot(mod_configural, type = 'info')
plot(mod_configural, type = 'trace')
plot(mod_configural, type = 'trace', which.items = 1:4)
itemplot(mod_configural, 2)
itemplot(mod_configural, 2, type = 'RE')

anova(mod_metric, mod_configural) #equal slopes only
anova(mod_scalar2, mod_metric) #equal intercepts, free variance and mean
anova(mod_scalar1, mod_scalar2) #fix mean
anova(mod_fullconstrain, mod_scalar1) #fix variance

# compared all at once (in order of most constrained to least)
anova(mod_fullconstrain, mod_scalar2, mod_configural)


# test whether first 6 slopes should be equal across groups
values &lt;- multipleGroup(dat, 1, group = group, pars = 'values')
values
constrain &lt;- list(c(1, 63), c(5,67), c(9,71), c(13,75), c(17,79), c(21,83))
equalslopes &lt;- multipleGroup(dat, 1, group = group, constrain = constrain)
anova(equalslopes, mod_configural)

# same as above, but using mirt.model syntax
newmodel &lt;- '
    F = 1-15
    CONSTRAINB = (1-6, a1)'
equalslopes &lt;- multipleGroup(dat, newmodel, group = group)
coef(equalslopes, simplify=TRUE)

############
# vertical scaling (i.e., equating when groups answer items others do not)
dat2 &lt;- dat
dat2[group == 'D1', 1:2] &lt;- dat2[group != 'D1', 14:15] &lt;- NA
head(dat2)
tail(dat2)

# items with missing responses need to be constrained across groups for identification
nms &lt;- colnames(dat2)
mod &lt;- multipleGroup(dat2, 1, group, invariance = nms[c(1:2, 14:15)])

# this will throw an error without proper constraints (SEs cannot be computed either)
# mod &lt;- multipleGroup(dat2, 1, group)

# model still does not have anchors, therefore need to add a few (here use items 3-5)
mod_anchor &lt;- multipleGroup(dat2, 1, group,
                            invariance = c(nms[c(1:5, 14:15)], 'free_means', 'free_var'))
coef(mod_anchor, simplify=TRUE)

# check if identified by computing information matrix
mod_anchor &lt;- multipleGroup(dat2, 1, group, pars = mod2values(mod_anchor), TOL=NaN, SE=TRUE,
                            invariance = c(nms[c(1:5, 14:15)], 'free_means', 'free_var'))
mod_anchor
coef(mod_anchor)
coef(mod_anchor, printSE=TRUE)


#############
# DIF test for each item (using all other items as anchors)
itemnames &lt;- colnames(dat)
refmodel &lt;- multipleGroup(dat, 1, group = group, SE=TRUE,
                          invariance=c('free_means', 'free_var', itemnames))

# loop over items (in practice, run in parallel to increase speed). May be better to use ?DIF
estmodels &lt;- vector('list', ncol(dat))
for(i in 1:ncol(dat))
    estmodels[[i]] &lt;- multipleGroup(dat, 1, group = group, verbose = FALSE,
                             invariance=c('free_means', 'free_var', itemnames[-i]))
anova(refmodel, estmodels[[1]])
(anovas &lt;- lapply(estmodels, function(x, refmodel) anova(refmodel, x),
   refmodel=refmodel))

# family-wise error control
p &lt;- do.call(rbind, lapply(anovas, function(x) x[2, 'p']))
p.adjust(p, method = 'BH')

# same as above, except only test if slopes vary (1 df)
# constrain all intercepts
estmodels &lt;- vector('list', ncol(dat))
for(i in 1:ncol(dat))
    estmodels[[i]] &lt;- multipleGroup(dat, 1, group = group, verbose = FALSE,
                             invariance=c('free_means', 'free_var', 'intercepts',
                             itemnames[-i]))

(anovas &lt;- lapply(estmodels, function(x, refmodel) anova(refmodel, x),
   refmodel=refmodel))

# quickly test with Wald test using DIF()
mod_configural2 &lt;- multipleGroup(dat, 1, group = group, SE=TRUE)
DIF(mod_configural2, which.par = c('a1', 'd'), Wald=TRUE, p.adjust = 'fdr')



#############
# Three group model where the latent variable parameters are constrained to
# be equal in the focal groups

set.seed(12345)
a &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d &lt;- matrix(rnorm(15,0,.7),ncol=1)
itemtype &lt;- rep('2PL', nrow(a))
N &lt;- 1000
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5))
dataset3 &lt;- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5))
dat &lt;- rbind(dataset1, dataset2, dataset3)
group &lt;- rep(c('D1', 'D2', 'D3'), each=N)

# marginal information
itemstats(dat)

# conditional information
itemstats(dat, group=group)

model &lt;- 'F1 = 1-15
          FREE[D2, D3] = (GROUP, MEAN_1), (GROUP, COV_11)
          CONSTRAINB[D2,D3] = (GROUP, MEAN_1), (GROUP, COV_11)'

mod &lt;- multipleGroup(dat, model, group = group, invariance = colnames(dat))
coef(mod, simplify=TRUE)



#############
# multiple factors

a &lt;- matrix(c(abs(rnorm(5,1,.3)), rep(0,15),abs(rnorm(5,1,.3)),
     rep(0,15),abs(rnorm(5,1,.3))), 15, 3)
d &lt;- matrix(rnorm(15,0,.7),ncol=1)
mu &lt;- c(-.4, -.7, .1)
sigma &lt;- matrix(c(1.21,.297,1.232,.297,.81,.252,1.232,.252,1.96),3,3)
itemtype &lt;- rep('2PL', nrow(a))
N &lt;- 1000
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a, d, N, itemtype, mu = mu, sigma = sigma)
dat &lt;- rbind(dataset1, dataset2)
group &lt;- c(rep('D1', N), rep('D2', N))

# group models
model &lt;- '
   F1 = 1-5
   F2 = 6-10
   F3 = 11-15'

# define mirt cluster to use parallel architecture
if(interactive()) mirtCluster()

# EM approach (not as accurate with 3 factors, but generally good for quick model comparisons)
mod_configural &lt;- multipleGroup(dat, model, group = group) #completely separate analyses
mod_metric &lt;- multipleGroup(dat, model, group = group, invariance=c('slopes')) #equal slopes
mod_fullconstrain &lt;- multipleGroup(dat, model, group = group, #equal means, slopes, intercepts
                             invariance=c('slopes', 'intercepts'))

anova(mod_metric, mod_configural)
anova(mod_fullconstrain, mod_metric)

# same as above, but with MHRM (generally  more accurate with 3+ factors, but slower)
mod_configural &lt;- multipleGroup(dat, model, group = group, method = 'MHRM')
mod_metric &lt;- multipleGroup(dat, model, group = group, invariance=c('slopes'), method = 'MHRM')
mod_fullconstrain &lt;- multipleGroup(dat, model, group = group, method = 'MHRM',
                             invariance=c('slopes', 'intercepts'))

anova(mod_metric, mod_configural)
anova(mod_fullconstrain, mod_metric)

############
# polytomous item example
set.seed(12345)
a &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d &lt;- matrix(rnorm(15,0,.7),ncol=1)
d &lt;- cbind(d, d-1, d-2)
itemtype &lt;- rep('graded', nrow(a))
N &lt;- 1000
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a, d, N, itemtype, mu = .1, sigma = matrix(1.5))
dat &lt;- rbind(dataset1, dataset2)
group &lt;- c(rep('D1', N), rep('D2', N))
model &lt;- 'F1 = 1-15'

mod_configural &lt;- multipleGroup(dat, model, group = group)
plot(mod_configural)
plot(mod_configural, type = 'SE')
itemplot(mod_configural, 1)
itemplot(mod_configural, 1, type = 'info')
plot(mod_configural, type = 'trace') # messy, score function typically better
plot(mod_configural, type = 'itemscore')

fs &lt;- fscores(mod_configural, full.scores = FALSE)
head(fs[["D1"]])
fscores(mod_configural, method = 'EAPsum', full.scores = FALSE)

# constrain slopes within each group to be equal (but not across groups)
model2 &lt;- 'F1 = 1-15
           CONSTRAIN = (1-15, a1)'
mod_configural2 &lt;- multipleGroup(dat, model2, group = group)
plot(mod_configural2, type = 'SE')
plot(mod_configural2, type = 'RE')
itemplot(mod_configural2, 10)

############
## empirical histogram example (normal and bimodal groups)
set.seed(1234)
a &lt;- matrix(rlnorm(50, .2, .2))
d &lt;- matrix(rnorm(50))
ThetaNormal &lt;- matrix(rnorm(2000))
ThetaBimodal &lt;- scale(matrix(c(rnorm(1000, -2), rnorm(1000,2)))) #bimodal
Theta &lt;- rbind(ThetaNormal, ThetaBimodal)
dat &lt;- simdata(a, d, 4000, itemtype = '2PL', Theta=Theta)
group &lt;- rep(c('G1', 'G2'), each=2000)

EH &lt;- multipleGroup(dat, 1, group=group, dentype="empiricalhist", invariance = colnames(dat))
coef(EH, simplify=TRUE)
plot(EH, type = 'empiricalhist', npts = 60)

# DIF test for item 1
EH1 &lt;- multipleGroup(dat, 1, group=group, dentype="empiricalhist", invariance = colnames(dat)[-1])
anova(EH, EH1)

#--------------------------------
# Mixture model (no prior group variable specified)

set.seed(12345)
nitems &lt;- 20
a1 &lt;- matrix(.75, ncol=1, nrow=nitems)
a2 &lt;- matrix(1.25, ncol=1, nrow=nitems)
d1 &lt;- matrix(rnorm(nitems,0,1),ncol=1)
d2 &lt;- matrix(rnorm(nitems,0,1),ncol=1)
itemtype &lt;- rep('2PL', nrow(a1))
N1 &lt;- 500
N2 &lt;- N1*2 # second class twice as large

dataset1 &lt;- simdata(a1, d1, N1, itemtype)
dataset2 &lt;- simdata(a2, d2, N2, itemtype)
dat &lt;- rbind(dataset1, dataset2)
# group &lt;- c(rep('D1', N1), rep('D2', N2))

# Mixture Rasch model (Rost, 1990)
models &lt;- 'F1 = 1-20
           CONSTRAIN = (1-20, a1)'
mod_mix &lt;- multipleGroup(dat, models, dentype = 'mixture-2', GenRandomPars = TRUE)
coef(mod_mix, simplify=TRUE)
summary(mod_mix)
plot(mod_mix)
plot(mod_mix, type = 'trace')
itemplot(mod_mix, 1, type = 'info')

head(fscores(mod_mix)) # theta estimates
head(fscores(mod_mix, method = 'classify')) # classification probability
itemfit(mod_mix)

# Mixture 2PL model
mod_mix2 &lt;- multipleGroup(dat, 1, dentype = 'mixture-2', GenRandomPars = TRUE)
anova(mod_mix, mod_mix2)
coef(mod_mix2, simplify=TRUE)
itemfit(mod_mix2)

# Compare to single group
mod &lt;- mirt(dat)
anova(mod, mod_mix2)

########################################
# Zero-inflated 2PL IRT model

n &lt;- 1000
nitems &lt;- 20

a &lt;- rep(2, nitems)
d &lt;- rep(c(-2,-1,0,1,2), each=nitems/5)
zi_p &lt;- 0.2 # Proportion of people in zero class

theta &lt;- rnorm(n, 0, 1)
zeros &lt;- matrix(0, n*zi_p, nitems)
nonzeros &lt;- simdata(a, d, n*(1-zi_p), itemtype = '2PL',
                   Theta = as.matrix(theta[1:(n*(1-zi_p))]))
data &lt;- rbind(nonzeros, zeros)

# define class with extreme theta but fixed item parameters
zi2PL &lt;- "F = 1-20
          START [MIXTURE_1] = (GROUP, MEAN_1, -100), (GROUP, COV_11, .00001),
                              (1-20, a1, 1.0), (1-20, d, 0)
          FIXED [MIXTURE_1] = (GROUP, MEAN_1), (GROUP, COV_11),
                              (1-20, a1), (1-20, d)"

# define custom Theta integration grid that contains extreme theta + normal grid
technical &lt;- list(customTheta = matrix(c(-100, seq(-6,6,length.out=61))))

# fit ZIM-IRT
zi2PL.fit &lt;- multipleGroup(data, zi2PL, dentype = 'mixture-2', technical=technical)
coef(zi2PL.fit, simplify=TRUE)


## End(Not run)
</code></pre>

<hr>
<h2 id='MultipleGroupClass-class'>Class &quot;MultipleGroupClass&quot;</h2><span id='topic+MultipleGroupClass-class'></span>

<h3>Description</h3>

<p>Defines the object returned from <code><a href="#topic+multipleGroup">multipleGroup</a></code>.
</p>


<h3>Slots</h3>


<dl>
<dt><code>Call</code>:</dt><dd><p>function call </p>
</dd>
<dt><code>Data</code>:</dt><dd><p>list of data, sometimes in different forms </p>
</dd>
<dt><code>Options</code>:</dt><dd><p>list of estimation options</p>
</dd>
<dt><code>Fit</code>:</dt><dd><p>a list of fit information </p>
</dd>
<dt><code>Model</code>:</dt><dd><p>a list of model-based information </p>
</dd>
<dt><code>ParObjects</code>:</dt><dd><p>a list of the S4 objects used during estimation</p>
</dd>
<dt><code>OptimInfo</code>:</dt><dd><p>a list of arguments from the optimization process</p>
</dd>
<dt><code>Internals</code>:</dt><dd><p>a list of internal arguments for secondary computations (inspecting this
object is generally not required)</p>
</dd>
<dt><code>vcov</code>:</dt><dd><p>a matrix represented the asymptotic covariance matrix of the parameter estimates</p>
</dd>
<dt><code>time</code>:</dt><dd><p>a data.frame indicating the breakdown of computation times in seconds</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>coef</dt><dd><p><code>signature(object = "MultipleGroupClass")</code></p>
</dd>
<dt>print</dt><dd><p><code>signature(x = "MultipleGroupClass")</code> </p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "MultipleGroupClass")</code> </p>
</dd>
<dt>anova</dt><dd><p><code>signature(object = "MultipleGroupClass")</code> </p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>

<hr>
<h2 id='numerical_deriv'>Compute numerical derivatives</h2><span id='topic+numerical_deriv'></span>

<h3>Description</h3>

<p>Compute numerical derivatives using forward/backward difference,
central difference, or Richardson extrapolation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>numerical_deriv(
  par,
  f,
  ...,
  delta = 1e-05,
  gradient = TRUE,
  type = "Richardson"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="numerical_deriv_+3A_par">par</code></td>
<td>
<p>a vector of parameters to find partial derivative at</p>
</td></tr>
<tr><td><code id="numerical_deriv_+3A_f">f</code></td>
<td>
<p>the objective function being evaluated</p>
</td></tr>
<tr><td><code id="numerical_deriv_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>f</code></p>
</td></tr>
<tr><td><code id="numerical_deriv_+3A_delta">delta</code></td>
<td>
<p>the term used to perturb the <code>f</code> function. Default is 1e-5</p>
</td></tr>
<tr><td><code id="numerical_deriv_+3A_gradient">gradient</code></td>
<td>
<p>logical; compute the gradient terms? If FALSE then the Hessian is computed instead</p>
</td></tr>
<tr><td><code id="numerical_deriv_+3A_type">type</code></td>
<td>
<p>type of difference to compute. Can be either <code>'forward'</code> for the forward difference,
<code>'central'</code> for the central difference, or <code>'Richardson'</code> for the Richardson extrapolation (default).
Backward difference is achieved by supplying a negative <code>delta</code> value with <code>'forward'</code>.
When <code>type = 'Richardson'</code>, the default value of <code>delta</code> is increased to <code>delta * 1000</code> for the
Hessian and <code>delta * 10</code> for the gradient to provide a reasonable perturbation starting
location (each <code>delta</code> is halved at each iteration).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
f &lt;- function(x) 3*x[1]^3 - 4*x[2]^2
par &lt;- c(3,8)

# grad = 9 * x^2 , -8 * y
(actual &lt;- c(9 * par[1]^2, -8 * par[2]))
numerical_deriv(par, f, type = 'forward')
numerical_deriv(par, f, type = 'central')
numerical_deriv(par, f, type = 'Richardson') # default

# Hessian = h11 -&gt; 18 * x, h22 -&gt; -8, h12 -&gt; h21 -&gt; 0
(actual &lt;- matrix(c(18 * par[1], 0, 0, -8), 2, 2))
numerical_deriv(par, f, type = 'forward', gradient = FALSE)
numerical_deriv(par, f, type = 'central', gradient = FALSE)
numerical_deriv(par, f, type = 'Richardson', gradient = FALSE) # default


## End(Not run)
</code></pre>

<hr>
<h2 id='personfit'>Person fit statistics</h2><span id='topic+personfit'></span>

<h3>Description</h3>

<p><code>personfit</code> calculates the Zh values from Drasgow, Levine and Williams (1985) for
unidimensional and multidimensional models, as well as the infit and outfit statistics.
The returned object is a <code>data.frame</code>
consisting either of the tabulated data or full data with the statistics appended to the
rightmost columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>personfit(
  x,
  method = "EAP",
  Theta = NULL,
  stats.only = TRUE,
  return.resids = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="personfit_+3A_x">x</code></td>
<td>
<p>a computed model object of class <code>SingleGroupClass</code> or <code>MultipleGroupClass</code></p>
</td></tr>
<tr><td><code id="personfit_+3A_method">method</code></td>
<td>
<p>type of factor score estimation method. See <code><a href="#topic+fscores">fscores</a></code> for more detail</p>
</td></tr>
<tr><td><code id="personfit_+3A_theta">Theta</code></td>
<td>
<p>a matrix of factor scores used for statistics that require empirical estimates. If
supplied, arguments typically passed to <code>fscores()</code> will be ignored and these values will
be used instead</p>
</td></tr>
<tr><td><code id="personfit_+3A_stats.only">stats.only</code></td>
<td>
<p>logical; return only the person fit statistics without their associated
response pattern?</p>
</td></tr>
<tr><td><code id="personfit_+3A_return.resids">return.resids</code></td>
<td>
<p>logical; return the N by J matrix of person and item residuals?</p>
</td></tr>
<tr><td><code id="personfit_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>fscores()</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Drasgow, F., Levine, M. V., &amp; Williams, E. A. (1985). Appropriateness measurement with
polychotomous item response models and standardized indices.
<em>British Journal of Mathematical and Statistical Psychology, 38</em>, 67-86.
</p>
<p>Reise, S. P. (1990). A comparison of item- and person-fit methods of assessing model-data fit
in IRT. <em>Applied Psychological Measurement, 14</em>, 127-137.
</p>
<p>Wright B. D. &amp; Masters, G. N. (1982). <em>Rating scale analysis</em>. MESA Press.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+itemfit">itemfit</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

#make some data
set.seed(1)
a &lt;- matrix(rlnorm(20),ncol=1)
d &lt;- matrix(rnorm(20),ncol=1)
items &lt;- rep('2PL', 20)
data &lt;- simdata(a,d, 2000, items)

# first observation responds 1 for most difficult, 0 for easiest
data[1,] &lt;- ifelse(d &gt; 0, 0, 1)

# second observations answers first half as 1 second half as 0
data[2,] &lt;- rep(1:0, each = 10)

x &lt;- mirt(data, 1)
fit &lt;- personfit(x)
head(fit)

# raw residuals
head(personfit(x, return.resids=TRUE))

# with missing data
data[3, c(1,3,5,7)] &lt;- NA
x.miss &lt;- mirt(data, 1)
fit.miss &lt;- personfit(x.miss)
head(fit.miss)
head(personfit(x.miss, return.resids=TRUE))

#using precomputed Theta
Theta &lt;- fscores(x, method = 'MAP', full.scores = TRUE)
head(personfit(x, Theta=Theta))

# multiple group Rasch model example
set.seed(12345)
a &lt;- matrix(rep(1, 16), ncol=1)
d &lt;- matrix(rnorm(16,0,.7),ncol=1)
itemtype &lt;- rep('dich', nrow(a))
N &lt;- 1000
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a, d, N, itemtype, sigma = matrix(1.5))
dat &lt;- rbind(dataset1, dataset2)

# first observation responds 1 for most difficult, 0 for easiest
dat[1,] &lt;- ifelse(d &gt; 0, 0, 1)

group &lt;- c(rep('D1', N), rep('D2', N))
models &lt;- 'F1 = 1-16'
mod_Rasch &lt;- multipleGroup(dat, models, itemtype = 'Rasch', group = group)
coef(mod_Rasch, simplify=TRUE)
pf &lt;- personfit(mod_Rasch, method='MAP')
head(pf)

  
## End(Not run)

</code></pre>

<hr>
<h2 id='PLCI.mirt'>Compute profiled-likelihood (or posterior) confidence intervals</h2><span id='topic+PLCI.mirt'></span>

<h3>Description</h3>

<p>Computes profiled-likelihood based confidence intervals. Supports the inclusion of
equality constraints. Object returns the confidence intervals
and whether the respective interval could be found.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PLCI.mirt(
  mod,
  parnum = NULL,
  alpha = 0.05,
  search_bound = TRUE,
  step = 0.5,
  lower = TRUE,
  upper = TRUE,
  inf2val = 30,
  NealeMiller = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PLCI.mirt_+3A_mod">mod</code></td>
<td>
<p>a converged mirt model</p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_parnum">parnum</code></td>
<td>
<p>a numeric vector indicating which parameters to estimate.
Use <code><a href="#topic+mod2values">mod2values</a></code> to determine parameter numbers. If <code>NULL</code>, all possible
parameters are used</p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_alpha">alpha</code></td>
<td>
<p>two-tailed alpha critical level</p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_search_bound">search_bound</code></td>
<td>
<p>logical; use a fixed grid of values around the ML estimate to
determine more suitable optimization bounds? Using this has much better behaviour
than setting fixed upper/lower bound values and searching from more extreme ends</p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_step">step</code></td>
<td>
<p>magnitude of steps used when <code>search_bound</code> is <code>TRUE</code>.
Smaller values create more points to search a suitable bound for (up to the
lower bound value visible with <code><a href="#topic+mod2values">mod2values</a></code>). When upper/lower bounds are detected
this value will be adjusted accordingly</p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_lower">lower</code></td>
<td>
<p>logical; search for the lower CI?</p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_upper">upper</code></td>
<td>
<p>logical; search for the upper CI?</p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_inf2val">inf2val</code></td>
<td>
<p>a numeric used to change parameter bounds which are infinity to a finite number.
Decreasing this too much may not allow a suitable bound to be located. Default is 30</p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_nealemiller">NealeMiller</code></td>
<td>
<p>logical; use the Neale and Miller 1997 approximation? Default is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_verbose">verbose</code></td>
<td>
<p>logical; include additional information in the console?</p>
</td></tr>
<tr><td><code id="PLCI.mirt_+3A_...">...</code></td>
<td>
<p>additional arguments to pass to the estimation functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P., Pek, J., &amp; Liu, Y. (2017). Profile-likelihood Confidence
Intervals in Item Response Theory Models. <em>Multivariate Behavioral Research, 52</em>, 533-550.
<a href="https://doi.org/10.1080/00273171.2017.1329082">doi:10.1080/00273171.2017.1329082</a>
</p>
<p>Neale, M. C. &amp; Miller, M. B. (1997). The use of likelihood-based confidence intervals in genetic
models. <em>Behavior Genetics, 27</em>, 113-120.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+boot.mirt">boot.mirt</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
if(interactive()) mirtCluster() #use all available cores to estimate CI's in parallel
dat &lt;- expand.table(LSAT7)
mod &lt;- mirt(dat, 1)

result &lt;- PLCI.mirt(mod)
result

# model with constraints
mod &lt;- mirt(dat, 'F = 1-5
                  CONSTRAIN = (1-5, a1)')

result &lt;- PLCI.mirt(mod)
result

mod2 &lt;- mirt(Science, 1)
result2 &lt;- PLCI.mirt(mod2)
result2

# only estimate CI's slopes
sv &lt;- mod2values(mod2)
parnum &lt;- sv$parnum[sv$name == 'a1']
result3 &lt;- PLCI.mirt(mod2, parnum)
result3


## End(Not run)
</code></pre>

<hr>
<h2 id='plot+2CMultipleGroupClass+2Cmissing-method'>Plot various test-implied functions from models</h2><span id='topic+plot+2CMultipleGroupClass+2Cmissing-method'></span><span id='topic+plot-method'></span><span id='topic+plot+2CSingleGroupClass-method'></span><span id='topic+plot+2CMultipleGroupClass-method'></span><span id='topic+plot+2CSingleGroupClass+2Cmissing-method'></span><span id='topic+plot+2CDiscreteClass+2Cmissing-method'></span><span id='topic+plot+2CMixtureClass+2Cmissing-method'></span>

<h3>Description</h3>

<p>Plot various test implied response functions from models estimated in the mirt package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'MultipleGroupClass,missing'
plot(
  x,
  y,
  type = "score",
  npts = 200,
  drop2 = TRUE,
  degrees = 45,
  which.items = 1:extract.mirt(x, "nitems"),
  rot = list(xaxis = -70, yaxis = 30, zaxis = 10),
  facet_items = TRUE,
  theta_lim = c(-6, 6),
  par.strip.text = list(cex = 0.7),
  par.settings = list(strip.background = list(col = "#9ECAE1"), strip.border = list(col =
    "black")),
  auto.key = list(space = "right", points = FALSE, lines = TRUE),
  ...
)

## S4 method for signature 'SingleGroupClass,missing'
plot(
  x,
  y,
  type = "score",
  npts = 200,
  drop2 = TRUE,
  degrees = 45,
  theta_lim = c(-6, 6),
  which.items = 1:extract.mirt(x, "nitems"),
  MI = 0,
  CI = 0.95,
  rot = list(xaxis = -70, yaxis = 30, zaxis = 10),
  facet_items = TRUE,
  main = NULL,
  drape = TRUE,
  colorkey = TRUE,
  ehist.cut = 1e-10,
  add.ylab2 = TRUE,
  par.strip.text = list(cex = 0.7),
  par.settings = list(strip.background = list(col = "#9ECAE1"), strip.border = list(col =
    "black")),
  auto.key = list(space = "right", points = FALSE, lines = TRUE),
  profile = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_x">x</code></td>
<td>
<p>an object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>DiscreteClass</code></p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_y">y</code></td>
<td>
<p>an arbitrary missing argument required for <code>R CMD check</code></p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_type">type</code></td>
<td>
<p>type of plot to view. Can be
</p>

<dl>
<dt><code>'info'</code></dt><dd><p>test information function</p>
</dd>
<dt><code>'rxx'</code></dt><dd><p>for the reliability function</p>
</dd>
<dt><code>'infocontour'</code></dt><dd><p>for the test information contours</p>
</dd>
<dt><code>'SE'</code></dt><dd><p>for the test standard error function</p>
</dd>
<dt><code>'infotrace'</code></dt><dd><p>item information traceline plots</p>
</dd>
<dt><code>'infoSE'</code></dt><dd><p>a combined test information and standard error plot</p>
</dd>
<dt><code>'trace'</code></dt><dd><p>item probability traceline plots</p>
</dd>
<dt><code>'itemscore'</code></dt><dd><p>item scoring traceline plots</p>
</dd>
<dt><code>'score'</code></dt><dd><p>expected total score surface</p>
</dd>
<dt><code>'scorecontour'</code></dt><dd><p>expected total score contour plot</p>
</dd>
<dt><code>'posteriorTheta'</code></dt><dd><p>posterior for the latent trait distribution</p>
</dd>
<dt><code>'EAPsum'</code></dt><dd><p>compares sum-scores to the expected values based
on the EAP for sum-scores method (see <code><a href="#topic+fscores">fscores</a></code>)</p>
</dd>
</dl>

<p>Note that if <code>dentype = 'empiricalhist'</code> was used in estimation then
the type <code>'empiricalhist'</code>
also will be available to generate the empirical histogram plot, and if
<code>dentype = 'Davidian-#'</code> was used then the type <code>'Davidian'</code>
will also be available to generate the curve estimates at the quadrature
nodes used during estimation</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_npts">npts</code></td>
<td>
<p>number of quadrature points to be used for plotting features.
Larger values make plots look smoother</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_drop2">drop2</code></td>
<td>
<p>logical; where appropriate, for dichotomous response items drop the lowest category
and provide information pertaining only to the second response option?</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_degrees">degrees</code></td>
<td>
<p>numeric value ranging from 0 to 90 used in <code>plot</code> to compute angle
for information-based plots with respect to the first dimension.
If a vector is used then a bubble plot is created with the summed information
across the angles specified (e.g., <code>degrees = seq(0, 90, by=10)</code>)</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_which.items">which.items</code></td>
<td>
<p>numeric vector indicating which items to be used when plotting. Default is
to use all available items</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_rot">rot</code></td>
<td>
<p>allows rotation of the 3D graphics</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_facet_items">facet_items</code></td>
<td>
<p>logical; apply grid of plots across items? If <code>FALSE</code>, items will be
placed in one plot for each group</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_theta_lim">theta_lim</code></td>
<td>
<p>lower and upper limits of the latent trait (theta) to be evaluated, and is
used in conjunction with <code>npts</code></p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_par.strip.text">par.strip.text</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_par.settings">par.settings</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_auto.key">auto.key</code></td>
<td>
<p>plotting argument passed to <code><a href="lattice.html#topic+lattice">lattice</a></code></p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to lattice</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_mi">MI</code></td>
<td>
<p>a single number indicating how many imputations to draw to form bootstrapped confidence
intervals for the selected test statistic. If greater than 0 a plot will be drawn with a shaded
region for the interval</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_ci">CI</code></td>
<td>
<p>a number from 0 to 1 indicating the confidence interval to select when MI input is
used. Default uses the 95% confidence (CI = .95)</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_main">main</code></td>
<td>
<p>argument passed to lattice. Default generated automatically</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_drape">drape</code></td>
<td>
<p>logical argument passed to lattice. Default generated automatically</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_colorkey">colorkey</code></td>
<td>
<p>logical argument passed to lattice. Default generated automatically</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_ehist.cut">ehist.cut</code></td>
<td>
<p>a probability value indicating a threshold for excluding cases in empirical
histogram plots. Values larger than the default will include more points in the tails of the
plot, potentially squishing the 'meat' of the plot to take up less area than visually desired</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_add.ylab2">add.ylab2</code></td>
<td>
<p>logical argument passed to lattice. Default generated automatically</p>
</td></tr>
<tr><td><code id="plot+2B2CMultipleGroupClass+2B2Cmissing-method_+3A_profile">profile</code></td>
<td>
<p>logical; provide a profile plot of response probabilities (objects returned from
<code><a href="#topic+mdirt">mdirt</a></code> only)</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x &lt;- mirt(Science, 1, SE=TRUE)
plot(x)
plot(x, type = 'info')
plot(x, type = 'infotrace')
plot(x, type = 'infotrace', facet_items = FALSE)
plot(x, type = 'infoSE')
plot(x, type = 'rxx')
plot(x, type = 'posteriorTheta')

# confidence interval plots when information matrix computed
plot(x)
plot(x, MI=100)
plot(x, type='info', MI=100)
plot(x, type='SE', MI=100)
plot(x, type='rxx', MI=100)

# use the directlabels package to put labels on tracelines
library(directlabels)
plt &lt;- plot(x, type = 'trace')
direct.label(plt, 'top.points')

# additional modifications can be made via update().
# See ?update.trellis for further documentation
plt
update(plt, ylab = expression(Prob(theta)),
            main = "Item Traceline Functions") # ylab/main changed

set.seed(1234)
group &lt;- sample(c('g1','g2'), nrow(Science), TRUE)
x2 &lt;- multipleGroup(Science, 1, group)
plot(x2)
plot(x2, type = 'trace')
plot(x2, type = 'trace', which.items = 1:2)
plot(x2, type = 'itemscore', which.items = 1:2)
plot(x2, type = 'trace', which.items = 1, facet_items = FALSE) #facet by group
plot(x2, type = 'info')

x3 &lt;- mirt(Science, 2)
plot(x3, type = 'info')
plot(x3, type = 'SE', theta_lim = c(-3,3))


## End(Not run)
</code></pre>

<hr>
<h2 id='poly2dich'>Change polytomous items to dichotomous item format</h2><span id='topic+poly2dich'></span>

<h3>Description</h3>

<p>Transforms a matrix of items into a new matrix where the select polytomous items have been
converted into comparable dichotomous items with the same information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>poly2dich(data, which.items = 1:ncol(data), sep = "_cat.")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="poly2dich_+3A_data">data</code></td>
<td>
<p>an object of class <code>data.frame</code> or <code>matrix</code></p>
</td></tr>
<tr><td><code id="poly2dich_+3A_which.items">which.items</code></td>
<td>
<p>a vector indicating which items should be transformed into the
dichotomous form. Default uses all input items</p>
</td></tr>
<tr><td><code id="poly2dich_+3A_sep">sep</code></td>
<td>
<p>character vector pattern to append to each item name in <code>data</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an integer matrix
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(Science)

head(Science)
newScience &lt;- poly2dich(Science)
head(newScience)

newScience2 &lt;- poly2dich(Science, which.items = 2)
head(newScience2)


## End(Not run)

</code></pre>

<hr>
<h2 id='print-method'>Print the model objects</h2><span id='topic+print-method'></span><span id='topic+print+2CSingleGroupClass-method'></span><span id='topic+print+2CMultipleGroupClass-method'></span><span id='topic+print+2CMixedClass-method'></span><span id='topic+print+2CDiscreteClass-method'></span><span id='topic+print+2CMixtureClass-method'></span>

<h3>Description</h3>

<p>Print model object summaries to the console.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SingleGroupClass'
print(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print-method_+3A_x">x</code></td>
<td>
<p>an object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>MixedClass</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x &lt;- mirt(Science, 1)
print(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='print.mirt_df'>Print generic for customized data.frame console output</h2><span id='topic+print.mirt_df'></span>

<h3>Description</h3>

<p>Provides a nicer output for most printed <code>data.frame</code> objects
defined by functions in <code>mirt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mirt_df'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mirt_df_+3A_x">x</code></td>
<td>
<p>object of class <code>'mirt_df'</code></p>
</td></tr>
<tr><td><code id="print.mirt_df_+3A_digits">digits</code></td>
<td>
<p>number of digits to round</p>
</td></tr>
<tr><td><code id="print.mirt_df_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>print(...)</code></p>
</td></tr>
</table>

<hr>
<h2 id='print.mirt_list'>Print generic for customized list console output</h2><span id='topic+print.mirt_list'></span>

<h3>Description</h3>

<p>Provides a nicer output for most printed <code>list</code> objects
defined by functions in <code>mirt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mirt_list'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mirt_list_+3A_x">x</code></td>
<td>
<p>object of class <code>'mirt_list'</code></p>
</td></tr>
<tr><td><code id="print.mirt_list_+3A_digits">digits</code></td>
<td>
<p>number of digits to round</p>
</td></tr>
<tr><td><code id="print.mirt_list_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>print(...)</code></p>
</td></tr>
</table>

<hr>
<h2 id='print.mirt_matrix'>Print generic for customized matrix console output</h2><span id='topic+print.mirt_matrix'></span>

<h3>Description</h3>

<p>Provides a nicer output for most printed <code>matrix</code>
objects defined by functions in <code>mirt</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mirt_matrix'
print(x, digits = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mirt_matrix_+3A_x">x</code></td>
<td>
<p>object of class <code>'mirt_matrix'</code></p>
</td></tr>
<tr><td><code id="print.mirt_matrix_+3A_digits">digits</code></td>
<td>
<p>number of digits to round</p>
</td></tr>
<tr><td><code id="print.mirt_matrix_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code>print(...)</code></p>
</td></tr>
</table>

<hr>
<h2 id='probtrace'>Function to calculate probability trace lines</h2><span id='topic+probtrace'></span>

<h3>Description</h3>

<p>Given an internal mirt object extracted from an estimated model, or the
single-group estimated model itself, compute the probability trace
lines for all categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>probtrace(x, Theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="probtrace_+3A_x">x</code></td>
<td>
<p>either an extracted internal mirt object containing item information
(see <code><a href="#topic+extract.item">extract.item</a></code>) or a model of class <code>SingleGroupClass</code>
typically returned by the function <code><a href="#topic+mirt">mirt</a></code> or <code><a href="#topic+bfactor">bfactor</a></code></p>
</td></tr>
<tr><td><code id="probtrace_+3A_theta">Theta</code></td>
<td>
<p>a vector (unidimensional) or matrix (unidimensional/multidimensional) of
latent trait values</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extract.item">extract.item</a></code>, <code><a href="#topic+extract.group">extract.group</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
mod &lt;- mirt(Science, 1)

# single item probabilty tracelines for Item 2
extr.2 &lt;- extract.item(mod, 2)
Theta &lt;- matrix(seq(-4,4, by = .1))
traceline &lt;- probtrace(extr.2, Theta)
head(data.frame(traceline, Theta=Theta))

# probability tracelines for all items in test
tracelines &lt;- probtrace(mod, Theta)
head(tracelines)

</code></pre>

<hr>
<h2 id='randef'>Compute posterior estimates of random effect</h2><span id='topic+randef'></span>

<h3>Description</h3>

<p>Stochastically compute random effects for <code>MixedClass</code> objects with Metropolis-Hastings
samplers and averaging over the draws to obtain expected a posteriori predictions.
Returns a list of the estimated effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randef(x, ndraws = 1000, thin = 10, return.draws = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="randef_+3A_x">x</code></td>
<td>
<p>an estimated model object from the <code><a href="#topic+mixedmirt">mixedmirt</a></code> function</p>
</td></tr>
<tr><td><code id="randef_+3A_ndraws">ndraws</code></td>
<td>
<p>total number of draws to perform. Default is 1000</p>
</td></tr>
<tr><td><code id="randef_+3A_thin">thin</code></td>
<td>
<p>amount of thinning to apply. Default is to use every 10th draw</p>
</td></tr>
<tr><td><code id="randef_+3A_return.draws">return.draws</code></td>
<td>
<p>logical; return a list containing the thinned draws of the posterior?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
</p>
<p>Chalmers, R. P. (2015). Extended Mixed-Effects Item Response Models with the MH-RM Algorithm.
<em>Journal of Educational Measurement, 52</em>, 200-222. <a href="https://doi.org/10.1111/jedm.12072">doi:10.1111/jedm.12072</a>
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# make an arbitrary groups
covdat &lt;- data.frame(group = rep(paste0('group', 1:49), each=nrow(Science)/49))

# partial credit model
mod &lt;- mixedmirt(Science, covdat, model=1, random = ~ 1|group)
summary(mod)

effects &lt;- randef(mod, ndraws = 2000, thin = 20)
head(effects$Theta)
head(effects$group)


## End(Not run)
</code></pre>

<hr>
<h2 id='RCI'>Model-based Reliable Change Index</h2><span id='topic+RCI'></span>

<h3>Description</h3>

<p>Computes an IRT version of the &quot;reliable change index&quot; (RCI) proposed by
Jacobson and Traux (1991) but modified to use IRT information about scores
and measurement error. Main benefit of the IRT approach is the inclusion
of response pattern information in the pre/post data score estimates, as well
as conditional standard error of measurement information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RCI(mod, predat, postdat, cutoffs = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RCI_+3A_mod">mod</code></td>
<td>
<p>single-group model fitted by <code><a href="#topic+mirt">mirt</a></code></p>
</td></tr>
<tr><td><code id="RCI_+3A_predat">predat</code></td>
<td>
<p>a vector (if one individual) or matrix/data.frame
of response data to be scored, where each individuals' responses are
included in exactly one row</p>
</td></tr>
<tr><td><code id="RCI_+3A_postdat">postdat</code></td>
<td>
<p>same as <code>predat</code>, but with respect to the post/follow-up
measurement</p>
</td></tr>
<tr><td><code id="RCI_+3A_cutoffs">cutoffs</code></td>
<td>
<p>optional vector of length 2 indicating the type of cut-offs to
report (e.g., <code>c(-1.96, 1.96)</code> reflects the 95 percent z-score type cut-off)</p>
</td></tr>
<tr><td><code id="RCI_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="#topic+fscores">fscores</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Jacobson, N. S., &amp; Truax, P. (1991). Clinical significance: A statistical approach
to defining meaningful change in psychotherapy research. Journal
of Consulting and Clinical Psychology, 59, 12-19.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

mod &lt;- mirt(Science, 1)

# single response pattern change using EAP information
RCI(mod, predat = c(1,2,3,2), postdat = c(1,2,2,1))

# WLE estimator
RCI(mod, predat = c(1,2,3,2), postdat = c(1,2,2,1), method = 'WLE')

# multiple respondents
RCI(mod, predat = Science[1:5,], postdat = Science[2:6,])

# include large-sample z-type cutoffs
RCI(mod, predat = Science[1:5,], postdat = Science[2:6,],
    cutoffs = c(-1.96, 1.96))

############################
# Example where individuals take completely different item set pre-post
#   but prior calibration has been performed to equate the items

dat &lt;- key2binary(SAT12,
  key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))

mod &lt;- mirt(dat, 1)

# with N=5 individuals under investigation
predat &lt;- postdat &lt;- dat[1:5,]
predat[, 17:32] &lt;- NA
postdat[, 1:16] &lt;- NA

head(predat)
head(postdat)

RCI(mod, predat, postdat)


## End(Not run)
</code></pre>

<hr>
<h2 id='read.mirt'>Translate mirt parameters into suitable structure for plink package</h2><span id='topic+read.mirt'></span>

<h3>Description</h3>

<p>This function exports item parameters from the <code>mirt</code> package to the
<code>plink</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read.mirt(x, as.irt.pars = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read.mirt_+3A_x">x</code></td>
<td>
<p>a single object (or list of objects) returned from <code>mirt, bfactor</code>, or a
single object returned by <code>multipleGroup</code></p>
</td></tr>
<tr><td><code id="read.mirt_+3A_as.irt.pars">as.irt.pars</code></td>
<td>
<p>if <code>TRUE</code>, the parameters will be output as an <code>irt.pars</code> object</p>
</td></tr>
<tr><td><code id="read.mirt_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>coef()</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

## unidimensional
library(plink)

data &lt;- expand.table(LSAT7)
(mod1 &lt;- mirt(data, 1))
plinkpars &lt;- read.mirt(mod1)
plot(plinkpars)
plot(mod1, type = 'trace')

# graded
mod2 &lt;- mirt(Science, 1)
plinkpars &lt;- read.mirt(mod2)
plot(plinkpars)
plot(mod2, type = 'trace')

# gpcm
mod3 &lt;- mirt(Science, 1, itemtype = 'gpcm')
plinkpars &lt;- read.mirt(mod3)
plot(plinkpars)
plot(mod3, type = 'trace')

# nominal
mod4 &lt;- mirt(Science, 1, itemtype = 'nominal')
plinkpars &lt;- read.mirt(mod4)
plot(plinkpars)
plot(mod4, type = 'trace')

## multidimensional

data &lt;- expand.table(LSAT7)
(mod1 &lt;- mirt(data, 2))
plinkpars &lt;- read.mirt(mod1)
plinkpars
plot(plinkpars)
plot(mod1, type = 'trace')

cmod &lt;- mirt.model('
   F1 = 1,4,5
   F2 = 2-4')
model &lt;- mirt(data, cmod)
plot(read.mirt(model))
itemplot(model, 1)

# graded
mod2 &lt;- mirt(Science, 2)
plinkpars &lt;- read.mirt(mod2)
plinkpars
plot(plinkpars)
plot(mod2, type = 'trace')

### multiple group equating example
set.seed(1234)
dat &lt;- expand.table(LSAT7)
group &lt;- sample(c('g1', 'g2'), nrow(dat), TRUE)
dat1 &lt;- dat[group == 'g1', ]
dat2 &lt;- dat[group == 'g2', ]
mod1 &lt;- mirt(dat1, 1)
mod2 &lt;- mirt(dat2, 1)

# convert and combine pars
plinkMG &lt;- read.mirt(list(g1=mod1, g2=mod2))

# equivalently:
# mod &lt;- multipleGroup(dat, 1, group)
# plinkMG &lt;- read.mirt(mod)

combine &lt;- matrix(1:5, 5, 2)
comb &lt;- combine.pars(plinkMG, combine, grp.names=unique(group))
out &lt;- plink(comb, rescale="SL")
equate(out)
equate(out, method = 'OSE')


## End(Not run)
</code></pre>

<hr>
<h2 id='remap.distance'>Remap item categories to have integer distances of 1</h2><span id='topic+remap.distance'></span>

<h3>Description</h3>

<p>The mirt package's estimation setup requires that all item responses have spaces
equal to 1 (e.g., a Likert scale scored from 1 through 5). In the event that categories
are missing the categories must be re-coded. This function is automatically called by
the package estimation functions (e.g., <code><a href="#topic+mirt">mirt</a></code>), however for convince this
function has been extracted for users to better understand the remapping consequences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remap.distance(data, message = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remap.distance_+3A_data">data</code></td>
<td>
<p>the response data to remap as a data.frame or matrix</p>
</td></tr>
<tr><td><code id="remap.distance_+3A_message">message</code></td>
<td>
<p>logical; print message information pertaining to which items were remapped?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# category 2 for item 1 missing
dat &lt;- Science
dat[,1] &lt;- ifelse(Science[,1] == 2, 1, Science[,1])
apply(dat, 2, table)

# mirt() automatically remaps categories
mod &lt;- mirt(dat, 1)
coef(mod, simplify=TRUE)

# this is the transformed data used by mirt()
remap_dat &lt;- remap.distance(dat)
apply(remap_dat, 2, table)


</code></pre>

<hr>
<h2 id='residuals-method'>Compute model residuals</h2><span id='topic+residuals-method'></span><span id='topic+residuals+2CSingleGroupClass-method'></span><span id='topic+residuals+2CMixtureClass-method'></span><span id='topic+residuals+2CMultipleGroupClass-method'></span><span id='topic+residuals+2CDiscreteClass-method'></span>

<h3>Description</h3>

<p>Return model implied residuals for linear dependencies between items or at the person level.
If the latent trait density was approximated (e.g., Davidian curves, Empirical histograms, etc)
then passing <code>use_dentype_estimate = TRUE</code> will use the internally saved quadrature and
density components (where applicable).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SingleGroupClass'
residuals(
  object,
  type = "LD",
  p.adjust = "none",
  df.p = FALSE,
  approx.z = FALSE,
  full.scores = FALSE,
  QMC = FALSE,
  printvalue = NULL,
  tables = FALSE,
  verbose = TRUE,
  Theta = NULL,
  suppress = NA,
  theta_lim = c(-6, 6),
  quadpts = NULL,
  fold = TRUE,
  upper = TRUE,
  technical = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals-method_+3A_object">object</code></td>
<td>
<p>an object of class <code>SingleGroupClass</code> or
<code>MultipleGroupClass</code>. Bifactor models are automatically detected and utilized for
better accuracy</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_type">type</code></td>
<td>
<p>type of residuals to be displayed.
Can be either <code>'LD'</code> or <code>'LDG2'</code> for a local dependence matrix based on the
X2 or G2 statistics (Chen &amp; Thissen, 1997), <code>'Q3'</code> for the statistic proposed by
Yen (1984), <code>'JSI'</code> for the jack-knife statistic proposed Edwards et al. (2018),
<code>'exp'</code> for the expected values for the frequencies of every response pattern,
and <code>'expfull'</code> for the expected values for every theoretically observable response pattern.
For the 'LD' and 'LDG2' types, the upper diagonal elements represent the standardized
residuals in the form of signed Cramers V coefficients</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_p.adjust">p.adjust</code></td>
<td>
<p>method to use for adjusting all p-values (see <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>
for available options). Default is <code>'none'</code></p>
</td></tr>
<tr><td><code id="residuals-method_+3A_df.p">df.p</code></td>
<td>
<p>logical; print the degrees of freedom and p-values?</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_approx.z">approx.z</code></td>
<td>
<p>logical; transform <code class="reqn">\chi^2(df)</code> information from LD tests into approximate
z-ratios instead using the transformation <code class="reqn">z=\sqrt{2 * \chi^2} - \sqrt{2 * df - 1}</code>?</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_full.scores">full.scores</code></td>
<td>
<p>logical; compute relevant statistics
for each subject in the original data?</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_qmc">QMC</code></td>
<td>
<p>logical; use quasi-Monte Carlo integration? If <code>quadpts</code> is omitted the
default number of nodes is 5000</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_printvalue">printvalue</code></td>
<td>
<p>a numeric value to be specified when using the <code>res='exp'</code>
option. Only prints patterns that have standardized residuals greater than
<code>abs(printvalue)</code>. The default (NULL) prints all response patterns</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_tables">tables</code></td>
<td>
<p>logical; for LD type, return the observed, expected, and standardized residual
tables for each item combination?</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_verbose">verbose</code></td>
<td>
<p>logical; allow information to be printed to the console?</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_theta">Theta</code></td>
<td>
<p>a matrix of factor scores used for statistics that require empirical estimates (i.e., Q3).
If supplied, arguments typically passed to <code>fscores()</code> will be ignored and these values will
be used instead</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_suppress">suppress</code></td>
<td>
<p>a numeric value indicating which parameter local dependency combinations
to flag as being too high. Absolute values for the standardized estimates greater than
this value will be returned, while all values less than this value will be set to NA</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_theta_lim">theta_lim</code></td>
<td>
<p>range for the integration grid</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_quadpts">quadpts</code></td>
<td>
<p>number of quadrature nodes to use. The default is extracted from model (if available)
or generated automatically if not available</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_fold">fold</code></td>
<td>
<p>logical; apply the sum 'folding' described by Edwards et al. (2018) for the JSI statistic?</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_upper">upper</code></td>
<td>
<p>logical; which portion of the matrix (upper versus lower triangle)
should the <code>suppress</code> argument be applied to?</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_technical">technical</code></td>
<td>
<p>list of technical arguments when models are re-estimated (see <code><a href="#topic+mirt">mirt</a></code>
for details)</p>
</td></tr>
<tr><td><code id="residuals-method_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>fscores()</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chen, W. H. &amp; Thissen, D. (1997). Local dependence indices for item pairs using item
response theory. <em>Journal of Educational and Behavioral Statistics, 22</em>, 265-289.
</p>
<p>Edwards, M. C., Houts, C. R. &amp; Cai, L. (2018). A Diagnostic Procedure to Detect Departures
From Local Independence in Item Response Theory Models.
<em>Psychological Methods, 23</em>, 138-149.
</p>
<p>Yen, W. (1984). Effects of local item dependence on the fit and equating performance of the three
parameter logistic model. <em>Applied Psychological Measurement, 8</em>, 125-145.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

x &lt;- mirt(Science, 1)
residuals(x)
residuals(x, tables = TRUE)
residuals(x, type = 'exp')
residuals(x, suppress = .15)
residuals(x, df.p = TRUE)
residuals(x, df.p = TRUE, p.adjust = 'fdr') # apply FWE control

# Pearson's X2 estimate for goodness-of-fit
full_table &lt;- residuals(x, type = 'expfull')
head(full_table)
X2 &lt;- with(full_table, sum((freq - exp)^2 / exp))
df &lt;- nrow(full_table) - extract.mirt(x, 'nest') - 1
p &lt;- pchisq(X2, df = df, lower.tail=FALSE)
data.frame(X2, df, p, row.names='Pearson-X2')

# above FOG test as a function
PearsonX2 &lt;- function(x){
   full_table &lt;- residuals(x, type = 'expfull')
   X2 &lt;- with(full_table, sum((freq - exp)^2 / exp))
   df &lt;- nrow(full_table) - extract.mirt(x, 'nest') - 1
   p &lt;- pchisq(X2, df = df, lower.tail=FALSE)
   data.frame(X2, df, p, row.names='Pearson-X2')
}
PearsonX2(x)


# extract results manually
out &lt;- residuals(x, df.p = TRUE, verbose=FALSE)
str(out)
out$df.p[1,2]

# with and without supplied factor scores
Theta &lt;- fscores(x)
residuals(x, type = 'Q3', Theta=Theta)
residuals(x, type = 'Q3', method = 'ML')

# Edwards et al. (2018) JSI statistic
N &lt;- 250
a &lt;- rnorm(10, 1.7, 0.3)
d &lt;- rnorm(10)
dat &lt;- simdata(a, d, N=250, itemtype = '2PL')

mod &lt;- mirt(dat, 1)
residuals(mod, type = 'JSI')
residuals(mod, type = 'JSI', fold=FALSE) # unfolded

# LD between items 1-2
aLD &lt;- numeric(10)
aLD[1:2] &lt;- rnorm(2, 2.55, 0.15)
a2 &lt;- cbind(a, aLD)
dat &lt;- simdata(a2, d, N=250, itemtype = '2PL')

mod &lt;- mirt(dat, 1)

# JSI executed in parallel over multiple cores
if(interactive()) mirtCluster()
residuals(mod, type = 'JSI')


## End(Not run)
</code></pre>

<hr>
<h2 id='RMSD_DIF'>RMSD effect size statistic to quantify category-level DIF</h2><span id='topic+RMSD_DIF'></span>

<h3>Description</h3>

<p>This function computes a set of RMSD &quot;badness-of-fit&quot; statistics when investing
DIF across a set of grouping variables. In a first step, a (potentially highly constrained)
multiple group model is fitted, while in a second step the item (and person) parameters
are estimated based on all examines across all groups. Category level DIF is assessed
based on how well the pseudo-table of counts match the (constrained) probability functions
implied by the original multiple group model (while also weighing across the implied density
function of the latent traits). If the RSMD fit is poor, indicating non-ignorable DIF,
then the multiple-group model should be adjusted to better account for the large response bias
due to using a pooled model. See Lee and von Davier (2020) and Buchholz and Hartig (2019) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSD_DIF(pooled_mod, flag = 0, probfun = TRUE, dentype = "norm")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="RMSD_DIF_+3A_pooled_mod">pooled_mod</code></td>
<td>
<p>a multiple-group model (used to compute the model-implied
probability in the goodness-of-fit test)</p>
</td></tr>
<tr><td><code id="RMSD_DIF_+3A_flag">flag</code></td>
<td>
<p>a numeric value used as a cut-off to help flag larger RMSD values
(e.g., <code>flag = .03</code> will highlight only categories with RMSD values greater than
.03)</p>
</td></tr>
<tr><td><code id="RMSD_DIF_+3A_probfun">probfun</code></td>
<td>
<p>logical; use probability functions to compute RMSD? If FALSE, the expected score
functions will be integrated instead, which may be useful for collapsing across the
categories in polytomous items</p>
</td></tr>
<tr><td><code id="RMSD_DIF_+3A_dentype">dentype</code></td>
<td>
<p>density to use for the latent trait.
Can be <code>'norm'</code> to use a normal Gaussian density where the mean/variance are extracted
from the model object(default), <code>'snorm'</code> for a standard normal distribution,
or <code>'empirical'</code> to use the density estimate obtained via the E-table</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Buchholz, J., and Hartig, J. (2019). Comparing Attitudes Across Groups: An IRT-Based Item-Fit Statistic
for the Analysis of Measurement Invariance. <em>Applied Psychological Measurement, 43</em>(3), 241-250.
<a href="https://doi.org/10.1177/0146621617748323">doi:10.1177/0146621617748323</a>
</p>
<p>Lee, S. S., and von Davier, M. (2020). Improving measurement properties of the PISA home
possessions scale through partial invariance modeling.
<em>Psychological test and assessment modeling</em>, 62(1):55-83.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DIF">DIF</a></code>, <code><a href="#topic+DRF">DRF</a></code>, <code><a href="#topic+multipleGroup">multipleGroup</a></code>, <code><a href="#topic+empirical_ES">empirical_ES</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

#----- generate some data
set.seed(12345)
a &lt;- a2 &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d &lt;- d2 &lt;- matrix(rnorm(15,0,.7),ncol=1)

# item 1 has DIF
d2[1] &lt;- d[1] - .5
a2[1] &lt;- a[1] + 1

itemtype &lt;- rep('2PL', nrow(a))
N &lt;- 1000
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a2, d2, N, itemtype)
dat &lt;- rbind(dataset1, dataset2)
group &lt;- c(rep('D1', N), rep('D2', N))

#-----

# fully pooled model
pooled_mod &lt;- multipleGroup(dat, 1, group=group,
   invariance = c(colnames(dat), 'free_mean', 'free_var'))
coef(pooled_mod, simplify=TRUE)

RMSD_DIF(pooled_mod)
RMSD_DIF(pooled_mod, dentype = 'empirical')
RMSD_DIF(pooled_mod, flag = .03)

# more freely estimated model (item 1 has 2 parameters estimated)
MGmod &lt;- multipleGroup(dat, 1, group=group,
                       invariance = c(colnames(dat)[-1], 'free_mean', 'free_var'))
coef(MGmod, simplify=TRUE)

# RMSD in item.1 now reduced (MG model accounts for DIF)
RMSD_DIF(MGmod)
RMSD_DIF(MGmod, flag = .03)


#################
# polytomous example
set.seed(12345)
a &lt;- a2 &lt;- matrix(rlnorm(20,.2,.3))

# for the graded model, ensure that there is enough space between the intercepts,
# otherwise closer categories will not be selected often (minimum distance of 0.3 here)
diffs &lt;- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum))
diffs &lt;- -(diffs - rowMeans(diffs))
d &lt;- d2 &lt;- diffs + rnorm(20)

# item 1 has slope + dif for first intercept parameter
d2[1] &lt;- d[1] - .5
a2[1] &lt;- a[1] + 1

itemtype &lt;- rep('graded', nrow(a))
N &lt;- 1000
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a2, d2, N, itemtype)
dat &lt;- rbind(dataset1, dataset2)
group &lt;- c(rep('D1', N), rep('D2', N))

#-----

# fully pooled model
pooled_mod &lt;- multipleGroup(dat, 1, group=group,
         invariance = c(colnames(dat), 'free_mean', 'free_var'))
coef(pooled_mod, simplify=TRUE)

# Item_1 fits poorly in several categories (RMSD &gt; .05)
RMSD_DIF(pooled_mod)
RMSD_DIF(pooled_mod, flag = .05)
RMSD_DIF(pooled_mod, flag = .1, probfun = FALSE) # use expected score function

# more freely estimated model (item 1 has more parameters estimated)
MGmod &lt;- multipleGroup(dat, 1, group=group,
                       invariance = c(colnames(dat)[-1], 'free_mean', 'free_var'))
coef(MGmod, simplify=TRUE)

# RMSDs in Item_1 now reduced (MG model better accounts for DIF)
RMSD_DIF(MGmod)
RMSD_DIF(MGmod, flag = .05)
RMSD_DIF(MGmod, probfun = FALSE, flag = .1) # use expected score function


## End(Not run)

</code></pre>

<hr>
<h2 id='SAT12'>Description of SAT12 data</h2><span id='topic+SAT12'></span>

<h3>Description</h3>

<p>Data obtained from the TESTFACT (Woods et al., 2003) manual, with 32 response pattern
scored items for a grade 12 science assessment test (SAT) measuring topics of chemistry,
biology, and physics. The scoring key for these data is
[1, 4, 5, 2, 3, 1, 2, 1, 3, 1, 2, 4, 2, 1, 5, 3, 4, 4, 1, 4, 3, 3, 4, 1, 3, 5, 1, 3, 1, 5, 4, 5],
respectively. However, careful analysis using the nominal response model suggests that the
scoring key for item 32 may be incorrect, and should be changed from 5 to 3.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Wood, R., Wilson, D. T., Gibbons, R. D., Schilling, S. G., Muraki, E., &amp; Bock, R. D. (2003).
TESTFACT 4 for Windows: Test Scoring, Item Statistics, and Full-information Item Factor Analysis
[Computer software]. Lincolnwood, IL: Scientific Software International.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

itemstats(SAT12, use_ts = FALSE)

# score the data (missing scored as 0)
head(SAT12)
dat &lt;- key2binary(SAT12,
    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
head(dat)
itemstats(dat)

# score the data, missing (value of 8) treated as NA
SAT12missing &lt;- SAT12
SAT12missing[SAT12missing == 8] &lt;- NA
dat &lt;- key2binary(SAT12missing,
    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,5))
head(dat)

# potentially better scoring for item 32 (based on nominal model finding)
dat &lt;- key2binary(SAT12,
    key = c(1,4,5,2,3,1,2,1,3,1,2,4,2,1,5,3,4,4,1,4,3,3,4,1,3,5,1,3,1,5,4,3))

## End(Not run)
</code></pre>

<hr>
<h2 id='Science'>Description of Science data</h2><span id='topic+Science'></span>

<h3>Description</h3>

<p>A 4-item data set borrowed from <code>ltm</code> package in R, first example
of the <code>grm()</code> function. See more complete documentation therein.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
itemstats(Science)

mod &lt;- mirt(Science, 1)
plot(mod, type = 'trace')

## End(Not run)
</code></pre>

<hr>
<h2 id='show-method'>Show model object</h2><span id='topic+show-method'></span><span id='topic+show+2CSingleGroupClass-method'></span><span id='topic+show+2CMultipleGroupClass-method'></span><span id='topic+show+2CMixedClass-method'></span><span id='topic+show+2CDiscreteClass-method'></span><span id='topic+show+2CMixtureClass-method'></span>

<h3>Description</h3>

<p>Print model object summaries to the console.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SingleGroupClass'
show(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show-method_+3A_object">object</code></td>
<td>
<p>an object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>MixedClass</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x &lt;- mirt(Science, 1)
show(x)

## End(Not run)
</code></pre>

<hr>
<h2 id='SIBTEST'>(Generalized) Simultaneous Item Bias Test (SIBTEST)</h2><span id='topic+SIBTEST'></span>

<h3>Description</h3>

<p>Classical test theory approach to detecting unidirectional and bidirectional (with one
crossing location) DIF. This family of statistics is intended for unidimensional tests,
and applies a regression-corrected matched-total score approach to quantify the response
bias between two or more groups. Can be used for DIF, DBF, and DTF testing with two or more
discrete groups.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIBTEST(
  dat,
  group,
  suspect_set,
  match_set,
  focal_name = unique(group)[2],
  guess_correction = 0,
  Jmin = 5,
  na.rm = FALSE,
  randomize = FALSE,
  C = cbind(1, -diag(length(unique(group)) - 1L)),
  pairwise = FALSE,
  DIF = FALSE,
  p.adjust.method = "none",
  permute = 1000,
  pk_focal = FALSE,
  correction = TRUE,
  remove_cross = FALSE,
  details = FALSE,
  plot = "none",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SIBTEST_+3A_dat">dat</code></td>
<td>
<p>integer-based dataset to be tested, containing dichotomous or polytomous responses</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_group">group</code></td>
<td>
<p>a (factor) vector indicating group membership
with the same length as the number of rows in <code>dat</code></p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_suspect_set">suspect_set</code></td>
<td>
<p>an integer vector indicating which items to inspect with SIBTEST. Including only
one value will perform a DIF test, while including more than one will perform a simultaneous
bundle test (DBF); including all non-matched items will perform DTF.
If missing, a simultaneous test using all the items not listed in match_set
will be used (i.e., DTF)</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_match_set">match_set</code></td>
<td>
<p>an integer vector indicating which items to use as the items which are matched
(i.e., contain no DIF). These are analogous to 'anchor' items in the likelihood method to locate
DIF. If missing, all items other than the items found in the <code>suspect_set</code> will be used</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_focal_name">focal_name</code></td>
<td>
<p>name of the focal group; e.g., <code>'focal'</code>. If not specified then one will be
selected automatically using <code>unique(group)[2]</code></p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_guess_correction">guess_correction</code></td>
<td>
<p>a vector of numbers from 0 to 1 indicating how much to correct the items
for guessing. It's length should be the same as ncol(dat)</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_jmin">Jmin</code></td>
<td>
<p>the minimum number of observations required when splitting the data into focal and
reference groups conditioned on the matched set</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_na.rm">na.rm</code></td>
<td>
<p>logical; remove rows in <code>dat</code> with any missing values? If <code>TRUE</code>,
rows with missing data will be removed, as well as the corresponding elements in the <code>group</code>
input</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_randomize">randomize</code></td>
<td>
<p>logical; perform the crossing test for non-compensatory bias
using Li and Stout's (1996) permutation approach? Default is <code>FALSE</code>, which uses the
ad-hoc mixed degrees of freedom method suggested by Chalmers (2018)</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_c">C</code></td>
<td>
<p>a contrast matrix to use for pooled testing with more than two groups. Default uses an
effects coding approach, where the last group (last column of the matrix) is treated as the reference
group, and each column is associated with the respective name via <code>unique(group)</code> (i.e., the first
column is the coefficient for <code>unique(group)[1]</code>, second column for <code>unique(group)[2]</code>, and
so on)</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_pairwise">pairwise</code></td>
<td>
<p>logical; perform pairwise comparisons in multi-group applications?</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_dif">DIF</code></td>
<td>
<p>logical; should the elements in <code>suspect_set</code> be treated one at a time
to test for DIF? Use of this logical will treat all other items as part of the <code>match_set</code>
unless this input is provided explicitly. Default is <code>FALSE</code> to allow DBF and DTF tests</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_p.adjust.method">p.adjust.method</code></td>
<td>
<p>a character input dictating which <code>method</code> to use in <code><a href="stats.html#topic+p.adjust">p.adjust</a></code>.
when studying more than two groups. Default does not present any p-value adjustments</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_permute">permute</code></td>
<td>
<p>number of permutations to perform when <code>randomize = TRUE</code>. Default is 1000</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_pk_focal">pk_focal</code></td>
<td>
<p>logical; using the group weights from the focal group instead of the total
sample? Default is FALSE as per Shealy and Stout's recommendation</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_correction">correction</code></td>
<td>
<p>logical; apply the composite correction for the difference between focal
composite scores using the true-score regression technique? Default is <code>TRUE</code>,
reflecting Shealy and Stout's linear extrapolation method</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_remove_cross">remove_cross</code></td>
<td>
<p>logical; remove the subtest information associated with the approximate
crossing location? If TRUE this reflects the CSIBTEST definition of Li and Stout (1996);
if FALSE, this reflects the version of CSIBTEST utilized by Chalmers (2018). Only applicable
in two-group settings (in multi-group this is fixed to FALSE)</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_details">details</code></td>
<td>
<p>logical; return a data.frame containing the details required to compute SIBTEST?</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_plot">plot</code></td>
<td>
<p>a character input indicating the type of plot to construct. Options are <code>'none'</code>
(default), <code>'observed'</code> for the scaled focal subtest scores against the matched subtest
scores, <code>'weights'</code> for the proportion weights used (i.e., the proportion of observations at
each matched score), <code>'difference'</code> for the difference between the scaled focal subtest scores
against the matched subtest scores, and <code>'wdifference'</code> for the conditional differences multiplied
by each respective weight. Note that the last plot reflects the components used in SIBTEST,
and therefore the sum of these plotted observations will equal the beta coefficient for SIBTEST</p>
</td></tr>
<tr><td><code id="SIBTEST_+3A_...">...</code></td>
<td>
<p>additional plotting arguments to be passed</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SIBTEST is similar to the Mantel-Haenszel approach for detecting DIF but uses a regression
correction based on the KR-20/coefficient alpha reliability index to correct the observed
differences when the latent trait distributions are not equal.
Function supports the standard SIBTEST for dichotomous and polytomous data (compensatory) and
supports crossing DIF testing (i.e., non-compensatory/non-uniform) using the asymptotic sampling
distribution version of the Crossing-SIBTEST (CSIBTEST) statistic described by
Chalmers (2018) and the permutation method described by Li and Stout (1996). This
function also supports the multi-group generalizations (GSIBTEST and GCSIBTEST)
proposed by Chalmers and Zheng (2023), where users may specify alternative
contrast matrices to evaluate specific comparisons between groups as well as
perform joint hypothesis tests.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R. P. (2018). Improving the Crossing-SIBTEST statistic for
detecting non-uniform DIF. <em>Psychometrika, 83</em>, 2, 376-386.
</p>
<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Chalmers, R. P. &amp; Zheng, G. (2023). Multi-group Generalizations of
SIBTEST and Crossing-SIBTEST. <em>Applied Measurement in Education, 36</em>(2), 171-191,
<a href="https://doi.org/10.1080/08957347.2023.2201703">doi:10.1080/08957347.2023.2201703</a>.
</p>
<p>Chang, H. H., Mazzeo, J. &amp; Roussos, L. (1996). DIF for Polytomously Scored Items: An Adaptation of the
SIBTEST Procedure. <em>Journal of Educational Measurement, 33</em>, 333-353.
</p>
<p>Li, H.-H. &amp; Stout, W. (1996). A new procedure for detection of crossing DIF.
<em>Psychometrika, 61</em>, 647-677.
</p>
<p>Shealy, R. &amp; Stout, W. (1993). A model-based standardization approach that separates true
bias/DIF from group ability differences and detect test bias/DTF as well as item bias/DIF.
<em>Psychometrika, 58</em>, 159-194.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

set.seed(1234)
n &lt;- 30
N &lt;- 500
a &lt;- matrix(1, n)
d &lt;- matrix(rnorm(n), n)
group &lt;- c(rep('reference', N), rep('focal', N*2))

## -------------
# groups completely equal
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a, d, N*2, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2)

# DIF (all other items as anchors)
SIBTEST(dat, group, suspect_set = 6)

# Some plots depicting the above tests
SIBTEST(dat, group, suspect_set = 6, plot = 'observed')
SIBTEST(dat, group, suspect_set = 6, plot = 'weights')
SIBTEST(dat, group, suspect_set = 6, plot = 'wdifference')

# Include CSIBTEST with randomization method
SIBTEST(dat, group, suspect_set = 6, randomize = TRUE)

# remove crossing-location (identical to Li and Stout 1996 definition of CSIBTEST)
SIBTEST(dat, group, suspect_set = 6, randomize = TRUE, remove_cross=TRUE)

# DIF (specific anchors)
SIBTEST(dat, group, match_set = 1:5, suspect_set = 6)
SIBTEST(dat, group, match_set = 1:5, suspect_set = 6, randomize=TRUE)

# DBF (all and specific anchors, respectively)
SIBTEST(dat, group, suspect_set = 11:30)
SIBTEST(dat, group, match_set = 1:5, suspect_set = 11:30)

# DTF
SIBTEST(dat, group, suspect_set = 11:30)
SIBTEST(dat, group, match_set = 1:10) #equivalent

# different hyper pars
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a, d, N*2, itemtype = 'dich', mu = .5, sigma = matrix(1.5))
dat &lt;- rbind(dat1, dat2)
SIBTEST(dat, group, 6:30)
SIBTEST(dat, group, 11:30)

# DIF testing with anchors 1 through 5
SIBTEST(dat, group, 6, match_set = 1:5)
SIBTEST(dat, group, 7, match_set = 1:5)
SIBTEST(dat, group, 8, match_set = 1:5)

# DIF testing with all other items as anchors
SIBTEST(dat, group, 6)
SIBTEST(dat, group, 7)
SIBTEST(dat, group, 8)

## -------------
## systematic differing slopes and intercepts (clear DTF)
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a + c(numeric(15), rnorm(n-15, 1, .25)), d + c(numeric(15), rnorm(n-15, 1, 1)),
  N*2, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2)
SIBTEST(dat, group, 6:30)
SIBTEST(dat, group, 11:30)

# Some plots depicting the above tests
SIBTEST(dat, group, suspect_set = 11:30, plot = 'observed')
SIBTEST(dat, group, suspect_set = 11:30, plot = 'weights')
SIBTEST(dat, group, suspect_set = 11:30, plot = 'wdifference')

# DIF testing using valid anchors
SIBTEST(dat, group, suspect_set = 6, match_set = 1:5)
SIBTEST(dat, group, suspect_set = 7, match_set = 1:5)
SIBTEST(dat, group, suspect_set = 30, match_set = 1:5)

# test DIF using specific match_set
SIBTEST(dat, group, suspect_set = 6:30, match_set = 1:5, DIF=TRUE)

# test DIF using all-other-as-anchors method (not typically recommended)
SIBTEST(dat, group, suspect_set = 1:30, DIF=TRUE)

# randomization method is fairly poor when smaller matched-set used
SIBTEST(dat, group, suspect_set = 30, match_set = 1:5, randomize=TRUE)
SIBTEST(dat, group, suspect_set = 30, randomize=TRUE)

## ----------------------------------
# three group SIBTEST test
set.seed(1234)
n &lt;- 30
N &lt;- 1000
a &lt;- matrix(1, n)
d &lt;- matrix(rnorm(n), n)
group &lt;- c(rep('group1', N), rep('group2', N), rep('group3', N))

# groups completely equal
dat1 &lt;- simdata(a, d, N, itemtype = 'dich')
dat2 &lt;- simdata(a, d, N, itemtype = 'dich')
dat3 &lt;- simdata(a, d, N, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2, dat3)

# omnibus test using effects-coding contrast matrix (default)
SIBTEST(dat, group, suspect_set = 6)
SIBTEST(dat, group, suspect_set = 6, randomize=TRUE)

# explicit contrasts
SIBTEST(dat, group, suspect_set = 6, randomize=TRUE,
        C = matrix(c(1,-1,0), 1))

# test all items for DIF
SIBTEST(dat, group, suspect_set = 1:ncol(dat), DIF=TRUE)
SIBTEST(dat, group, suspect_set = 16:ncol(dat), DIF=TRUE,
        match_set = 1:15) # specific anchors

# post-hoc between two groups only
pick &lt;- group %in% c('group1', 'group2')
SIBTEST(subset(dat, pick), group[pick], suspect_set = 1:ncol(dat), DIF=TRUE)

# post-hoc pairwise comparison for all groups
SIBTEST(dat, group, suspect_set = 1:ncol(dat), DIF=TRUE, pairwise = TRUE)

## systematic differing slopes and intercepts
dat2 &lt;- simdata(a + c(numeric(15), .5,.5,.5,.5,.5, numeric(10)),
        d + c(numeric(15), 0,.6,.7,.8,.9, numeric(10)),
        N, itemtype = 'dich')
dat &lt;- rbind(dat1, dat2, dat3)

SIBTEST(dat, group, suspect_set = 16)
SIBTEST(dat, group, suspect_set = 16, randomize=TRUE)

SIBTEST(dat, group, suspect_set = 19)
SIBTEST(dat, group, suspect_set = 19, randomize=TRUE)

SIBTEST(dat, group, suspect_set = c(16, 19), DIF=TRUE)
SIBTEST(dat, group, suspect_set = c(16, 19), DIF=TRUE, pairwise=TRUE)



## End(Not run)
</code></pre>

<hr>
<h2 id='simdata'>Simulate response patterns</h2><span id='topic+simdata'></span>

<h3>Description</h3>

<p>Simulates response patterns for compensatory and noncompensatory MIRT models
from multivariate normally distributed factor (<code class="reqn">\theta</code>) scores, or from
a user input matrix of <code class="reqn">\theta</code>'s.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simdata(
  a,
  d,
  N,
  itemtype,
  sigma = NULL,
  mu = NULL,
  guess = 0,
  upper = 1,
  nominal = NULL,
  t = NULL,
  Theta = NULL,
  gpcm_mats = list(),
  returnList = FALSE,
  model = NULL,
  equal.K = TRUE,
  which.items = NULL,
  mins = 0,
  lca_cats = NULL,
  prob.list = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simdata_+3A_a">a</code></td>
<td>
<p>a matrix/vector of slope parameters. If slopes are to be constrained to
zero then use <code>NA</code> or simply set them equal to 0</p>
</td></tr>
<tr><td><code id="simdata_+3A_d">d</code></td>
<td>
<p>a matrix/vector of intercepts. The matrix should have as many columns as
the item with the largest number of categories, and filled empty locations
with <code>NA</code>. When a vector is used the test is assumed to consist only of dichotomous items
(because only one intercept per item is provided). When <code>itemtype = 'lca'</code> intercepts will not
be used</p>
</td></tr>
<tr><td><code id="simdata_+3A_n">N</code></td>
<td>
<p>sample size</p>
</td></tr>
<tr><td><code id="simdata_+3A_itemtype">itemtype</code></td>
<td>
<p>a character vector of length <code>nrow(a)</code> (or 1, if all the item types are
the same) specifying the type of items to simulate. Inputs can either be the same as
the inputs found in the <code>itemtype</code> argument in <code><a href="#topic+mirt">mirt</a></code> or the
internal classes defined by the package. Typical <code>itemtype</code> inputs that
are passed to <code><a href="#topic+mirt">mirt</a></code> are used then these will be converted into
the respective internal classes automatically.
</p>
<p>If the internal class of the object is specified instead, the inputs can
be <code>'dich', 'graded', 'gpcm', 'sequential', 'nominal', 'nestlogit', 'partcomp', 'gumm'</code>,
or <code>'lca'</code>, for dichotomous, graded, generalized partial credit, sequential,
nominal, nested logit, partially compensatory,
generalized graded unfolding model, and latent class analysis model.
Note that for the gpcm, nominal, and nested logit models there should
be as many parameters as desired categories, however to parametrized them for meaningful
interpretation the first category intercept should
equal 0 for these models (second column for <code>'nestlogit'</code>, since first column is for the
correct item traceline). For nested logit models the 'correct' category is always the lowest
category (i.e., == 1). It may be helpful to use <code><a href="#topic+mod2values">mod2values</a></code> on data-sets that
have already been estimated to understand the itemtypes more intimately</p>
</td></tr>
<tr><td><code id="simdata_+3A_sigma">sigma</code></td>
<td>
<p>a covariance matrix of the underlying distribution. Default is
the identity matrix. Used when <code>Theta</code> is not supplied</p>
</td></tr>
<tr><td><code id="simdata_+3A_mu">mu</code></td>
<td>
<p>a mean vector of the underlying distribution. Default is a vector
of zeros. Used when <code>Theta</code> is not supplied</p>
</td></tr>
<tr><td><code id="simdata_+3A_guess">guess</code></td>
<td>
<p>a vector of guessing parameters for each item; only applicable
for dichotomous items. Must be either a scalar value that will affect all of
the dichotomous items, or a vector with as many values as to be simulated items</p>
</td></tr>
<tr><td><code id="simdata_+3A_upper">upper</code></td>
<td>
<p>same as <code>guess</code>, but for upper bound parameters</p>
</td></tr>
<tr><td><code id="simdata_+3A_nominal">nominal</code></td>
<td>
<p>a matrix of specific item category slopes for nominal models.
Should be the dimensions as the intercept specification with one less column, with <code>NA</code>
in locations where not applicable. Note that during estimation the first slope will be
constrained to 0 and the last will be constrained to the number of categories minus 1,
so it is best to set these as the values for the first and last categories as well</p>
</td></tr>
<tr><td><code id="simdata_+3A_t">t</code></td>
<td>
<p>matrix of t-values for the 'ggum' itemtype, where each row corresponds to a given item.
Also determines the number of categories, where <code>NA</code> can be used for non-applicable categories</p>
</td></tr>
<tr><td><code id="simdata_+3A_theta">Theta</code></td>
<td>
<p>a user specified matrix of the underlying ability parameters,
where <code>nrow(Theta) == N</code> and <code>ncol(Theta) == ncol(a)</code>. When this is supplied the
<code>N</code> input is not required</p>
</td></tr>
<tr><td><code id="simdata_+3A_gpcm_mats">gpcm_mats</code></td>
<td>
<p>a list of matrices specifying the scoring scheme for generalized partial
credit models (see <code><a href="#topic+mirt">mirt</a></code> for details)</p>
</td></tr>
<tr><td><code id="simdata_+3A_returnlist">returnList</code></td>
<td>
<p>logical; return a list containing the data, item objects defined
by <code>mirt</code> containing the population parameters and item structure, and the
latent trait matrix <code>Theta</code>? Default is FALSE</p>
</td></tr>
<tr><td><code id="simdata_+3A_model">model</code></td>
<td>
<p>a single group object, typically returned by functions such as <code><a href="#topic+mirt">mirt</a></code> or
<code><a href="#topic+bfactor">bfactor</a></code>. Supplying this will render all other parameter elements (excluding the
<code>Theta</code>, <code>N</code>, <code>mu</code>, and <code>sigma</code> inputs) redundant (unless explicitly provided).
This input can therefore be used to create parametric bootstrap data whereby plausible data implied by the
estimated model can be generated and evaluated</p>
</td></tr>
<tr><td><code id="simdata_+3A_equal.k">equal.K</code></td>
<td>
<p>logical; when a <code>model</code> input is supplied, should the generated data contain the same
number of categories as the original data indicated by <code>extract.mirt(model, 'K')</code>? Default is TRUE,
which will redrawn data until this condition is satisfied</p>
</td></tr>
<tr><td><code id="simdata_+3A_which.items">which.items</code></td>
<td>
<p>an integer vector used to indicate which items to simulate when a
<code>model</code> input is included. Default simulates all items</p>
</td></tr>
<tr><td><code id="simdata_+3A_mins">mins</code></td>
<td>
<p>an integer vector (or single value to be used for each item) indicating what
the lowest category should be. If <code>model</code> is supplied then this will be extracted from
<code>slot(mod, 'Data')$mins</code>, otherwise the default is 0</p>
</td></tr>
<tr><td><code id="simdata_+3A_lca_cats">lca_cats</code></td>
<td>
<p>a vector indicating how many categories each lca item should have. If not supplied
then it is assumed that 2 categories should be generated for each item</p>
</td></tr>
<tr><td><code id="simdata_+3A_prob.list">prob.list</code></td>
<td>
<p>an optional list containing matrix/data.frames of probabilities values for
each category to be simulated. This is useful when creating customized probability functions
to be sampled from</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a data matrix simulated from the parameters, or a list containing the data,
item objects, and Theta matrix.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>
<p>Reckase, M. D. (2009). <em>Multidimensional Item Response Theory</em>. New York: Springer.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
### Parameters from Reckase (2009), p. 153

set.seed(1234)

a &lt;- matrix(c(
 .7471, .0250, .1428,
 .4595, .0097, .0692,
 .8613, .0067, .4040,
1.0141, .0080, .0470,
 .5521, .0204, .1482,
1.3547, .0064, .5362,
1.3761, .0861, .4676,
 .8525, .0383, .2574,
1.0113, .0055, .2024,
 .9212, .0119, .3044,
 .0026, .0119, .8036,
 .0008, .1905,1.1945,
 .0575, .0853, .7077,
 .0182, .3307,2.1414,
 .0256, .0478, .8551,
 .0246, .1496, .9348,
 .0262, .2872,1.3561,
 .0038, .2229, .8993,
 .0039, .4720, .7318,
 .0068, .0949, .6416,
 .3073, .9704, .0031,
 .1819, .4980, .0020,
 .4115,1.1136, .2008,
 .1536,1.7251, .0345,
 .1530, .6688, .0020,
 .2890,1.2419, .0220,
 .1341,1.4882, .0050,
 .0524, .4754, .0012,
 .2139, .4612, .0063,
 .1761,1.1200, .0870),30,3,byrow=TRUE)*1.702

d &lt;- matrix(c(.1826,-.1924,-.4656,-.4336,-.4428,-.5845,-1.0403,
  .6431,.0122,.0912,.8082,-.1867,.4533,-1.8398,.4139,
  -.3004,-.1824,.5125,1.1342,.0230,.6172,-.1955,-.3668,
  -1.7590,-.2434,.4925,-.3410,.2896,.006,.0329),ncol=1)*1.702

mu &lt;- c(-.4, -.7, .1)
sigma &lt;- matrix(c(1.21,.297,1.232,.297,.81,.252,1.232,.252,1.96),3,3)

dataset1 &lt;- simdata(a, d, 2000, itemtype = '2PL')
dataset2 &lt;- simdata(a, d, 2000, itemtype = '2PL', mu = mu, sigma = sigma)

#mod &lt;- mirt(dataset1, 3, method = 'MHRM')
#coef(mod)

## Not run: 

### Unidimensional graded response model with 5 categories each

a &lt;- matrix(rlnorm(20,.2,.3))

# for the graded model, ensure that there is enough space between the intercepts,
# otherwise closer categories will not be selected often (minimum distance of 0.3 here)
diffs &lt;- t(apply(matrix(runif(20*4, .3, 1), 20), 1, cumsum))
diffs &lt;- -(diffs - rowMeans(diffs))
d &lt;- diffs + rnorm(20)

dat &lt;- simdata(a, d, 500, itemtype = 'graded')
# mod &lt;- mirt(dat, 1)

### An example of a mixed item, bifactor loadings pattern with correlated specific factors

a &lt;- matrix(c(
.8,.4,NA,
.4,.4,NA,
.7,.4,NA,
.8,NA,.4,
.4,NA,.4,
.7,NA,.4),ncol=3,byrow=TRUE)

d &lt;- matrix(c(
-1.0,NA,NA,
 1.5,NA,NA,
 0.0,NA,NA,
0.0,-1.0,1.5,  #the first 0 here is the recommended constraint for nominal
0.0,1.0,-1, #the first 0 here is the recommended constraint for gpcm
2.0,0.0,NA),ncol=3,byrow=TRUE)

nominal &lt;- matrix(NA, nrow(d), ncol(d))
# the first 0 and last (ncat - 1) = 2 values are the recommended constraints
nominal[4, ] &lt;- c(0,1.2,2)

sigma &lt;- diag(3)
sigma[2,3] &lt;- sigma[3,2] &lt;- .25
items &lt;- c('2PL','2PL','2PL','nominal','gpcm','graded')

dataset &lt;- simdata(a,d,2000,items,sigma=sigma,nominal=nominal)

#mod &lt;- bfactor(dataset, c(1,1,1,2,2,2), itemtype=c(rep('2PL', 3), 'nominal', 'gpcm','graded'))
#coef(mod)

#### Convert standardized factor loadings to slopes

F2a &lt;- function(F, D=1.702){
    h2 &lt;- rowSums(F^2)
    a &lt;- (F / sqrt(1 - h2)) * D
    a
}

(F &lt;- matrix(c(rep(.7, 5), rep(.5,5))))
(a &lt;- F2a(F))
d &lt;- rnorm(10)

dat &lt;- simdata(a, d, 5000, itemtype = '2PL')
mod &lt;- mirt(dat, 1)
coef(mod, simplify=TRUE)$items
summary(mod)

mod2 &lt;- mirt(dat, 'F1 = 1-10
                   CONSTRAIN = (1-5, a1), (6-10, a1)')
summary(mod2)
anova(mod2, mod)

#### Convert classical 3PL paramerization into slope-intercept form
nitems &lt;- 50
as &lt;- rlnorm(nitems, .2, .2)
bs &lt;- rnorm(nitems, 0, 1)
gs &lt;- rbeta(nitems, 5, 17)

# convert first item (only intercepts differ in resulting transformation)
traditional2mirt(c('a'=as[1], 'b'=bs[1], 'g'=gs[1], 'u'=1), cls='3PL')

# convert all difficulties to intercepts
ds &lt;- numeric(nitems)
for(i in 1:nitems)
   ds[i] &lt;- traditional2mirt(c('a'=as[i], 'b'=bs[i], 'g'=gs[i], 'u'=1),
                             cls='3PL')[2]

dat &lt;- simdata(as, ds, N=5000, guess=gs, itemtype = '3PL')

# estimate with beta prior for guessing parameters
# mod &lt;- mirt(dat, model="Theta = 1-50
#                         PRIOR = (1-50, g, expbeta, 5, 17)", itemtype = '3PL')
# coef(mod, simplify=TRUE, IRTpars=TRUE)$items
# data.frame(as, bs, gs, us=1)


#### Unidimensional nonlinear factor pattern

theta &lt;- rnorm(2000)
Theta &lt;- cbind(theta,theta^2)

a &lt;- matrix(c(
.8,.4,
.4,.4,
.7,.4,
.8,NA,
.4,NA,
.7,NA),ncol=2,byrow=TRUE)
d &lt;- matrix(rnorm(6))
itemtype &lt;- rep('2PL',6)

nonlindata &lt;- simdata(a=a, d=d, itemtype=itemtype, Theta=Theta)

#model &lt;- '
#F1 = 1-6
#(F1 * F1) = 1-3'
#mod &lt;- mirt(nonlindata, model)
#coef(mod)

#### 2PLNRM model for item 4 (with 4 categories), 2PL otherwise

a &lt;- matrix(rlnorm(4,0,.2))

# first column of item 4 is the intercept for the correct category of 2PL model,
#    otherwise nominal model configuration
d &lt;- matrix(c(
-1.0,NA,NA,NA,
 1.5,NA,NA,NA,
 0.0,NA,NA,NA,
 1, 0.0,-0.5,0.5),ncol=4,byrow=TRUE)

nominal &lt;- matrix(NA, nrow(d), ncol(d))
nominal[4, ] &lt;- c(NA,0,.5,.6)

items &lt;- c(rep('2PL',3),'nestlogit')

dataset &lt;- simdata(a,d,2000,items,nominal=nominal)

#mod &lt;- mirt(dataset, 1, itemtype = c('2PL', '2PL', '2PL', '2PLNRM'), key=c(NA,NA,NA,0))
#coef(mod)
#itemplot(mod,4)

# return list of simulation parameters
listobj &lt;- simdata(a,d,2000,items,nominal=nominal, returnList=TRUE)
str(listobj)

# generate dataset from converged model
mod &lt;- mirt(Science, 1, itemtype = c(rep('gpcm', 3), 'nominal'))
sim &lt;- simdata(model=mod, N=1000)
head(sim)

Theta &lt;- matrix(rnorm(100))
sim &lt;- simdata(model=mod, Theta=Theta)
head(sim)

# alternatively, define a suitable object with functions from the mirtCAT package
# help(generate.mirt_object)
library(mirtCAT)

nitems &lt;- 50
a1 &lt;- rlnorm(nitems, .2,.2)
d &lt;- rnorm(nitems)
g &lt;- rbeta(nitems, 20, 80)
pars &lt;- data.frame(a1=a1, d=d, g=g)
head(pars)

obj &lt;- generate.mirt_object(pars, '3PL')
dat &lt;- simdata(N=200, model=obj)

#### 10 item GGUMs test with 4 categories each
a &lt;- rlnorm(10, .2, .2)
b &lt;- rnorm(10) #passed to d= input, but used as the b parameters
diffs &lt;- t(apply(matrix(runif(10*3, .3, 1), 10), 1, cumsum))
t &lt;- -(diffs - rowMeans(diffs))

dat &lt;- simdata(a, b, 1000, 'ggum', t=t)
apply(dat, 2, table)
# mod &lt;- mirt(dat, 1, 'ggum')
# coef(mod)

######
# prob.list example

# custom probability function that returns a matrix
fun &lt;- function(a, b, theta){
    P &lt;- 1 / (1 + exp(-a * (theta-b)))
    cbind(1-P, P)
}

set.seed(1)
theta &lt;- matrix(rnorm(100))
prob.list &lt;- list()
nitems &lt;- 5
a &lt;- rlnorm(nitems, .2, .2); b &lt;- rnorm(nitems, 0, 1/2)
for(i in 1:nitems) prob.list[[i]] &lt;- fun(a[i], b[i], theta)
str(prob.list)

dat &lt;- simdata(prob.list=prob.list)
head(dat)

# prob.list input is useful when defining custom items as well
name &lt;- 'old2PL'
par &lt;- c(a = .5, b = -2)
est &lt;- c(TRUE, TRUE)
P.old2PL &lt;- function(par,Theta, ncat){
     a &lt;- par[1]
     b &lt;- par[2]
     P1 &lt;- 1 / (1 + exp(-1*a*(Theta - b)))
     cbind(1-P1, P1)
}

x &lt;- createItem(name, par=par, est=est, P=P.old2PL)

prob.list[[1]] &lt;- x@P(x@par, theta)



## End(Not run)
</code></pre>

<hr>
<h2 id='SingleGroupClass-class'>Class &quot;SingleGroupClass&quot;</h2><span id='topic+SingleGroupClass-class'></span>

<h3>Description</h3>

<p>Defines the object returned from <code><a href="#topic+mirt">mirt</a></code> when model is exploratory.
</p>


<h3>Slots</h3>


<dl>
<dt><code>Call</code>:</dt><dd><p>function call </p>
</dd>
<dt><code>Data</code>:</dt><dd><p>list of data, sometimes in different forms </p>
</dd>
<dt><code>Options</code>:</dt><dd><p>list of estimation options</p>
</dd>
<dt><code>Fit</code>:</dt><dd><p>a list of fit information </p>
</dd>
<dt><code>Model</code>:</dt><dd><p>a list of model-based information </p>
</dd>
<dt><code>ParObjects</code>:</dt><dd><p>a list of the S4 objects used during estimation</p>
</dd>
<dt><code>OptimInfo</code>:</dt><dd><p>a list of arguments from the optimization process</p>
</dd>
<dt><code>Internals</code>:</dt><dd><p>a list of internal arguments for secondary computations (inspecting this
object is generally not required)</p>
</dd>
<dt><code>vcov</code>:</dt><dd><p>a matrix represented the asymptotic covariance matrix of the parameter estimates</p>
</dd>
<dt><code>time</code>:</dt><dd><p>a data.frame indicating the breakdown of computation times in seconds</p>
</dd>
</dl>



<h3>Methods</h3>


<dl>
<dt>anova</dt><dd><p><code>signature(object = "SingleGroupClass")</code></p>
</dd>
<dt>coef</dt><dd><p><code>signature(object = "SingleGroupClass")</code></p>
</dd>
<dt>plot</dt><dd><p><code>signature(x = "SingleGroupClass", y = "missing")</code></p>
</dd>
<dt>print</dt><dd><p><code>signature(x = "SingleGroupClass")</code> </p>
</dd>
<dt>residuals</dt><dd><p><code>signature(object = "SingleGroupClass")</code></p>
</dd>
<dt>show</dt><dd><p><code>signature(object = "SingleGroupClass")</code> </p>
</dd>
<dt>summary</dt><dd><p><code>signature(object = "SingleGroupClass")</code></p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>

<hr>
<h2 id='SLF'>Social Life Feelings Data</h2><span id='topic+SLF'></span>

<h3>Description</h3>

<p>A 5-item data set analyzed by Bartholomew (1998). Data contains
dichotomous responses (endorsement vs non-endorsement) from 1490 German
respondents to five statements on perceptions of social life.
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Bartholomew, D., J. (1998). Scaling unobservable constructs in social science. Journal of the Royal
Statistical Society - Series C, 47, 1-13.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# tabular format
data(SLF)
SLF

# full dataset
full &lt;- expand.table(SLF)
itemstats(full)

mod &lt;- mirt(full)
plot(mod, type = 'trace')


## End(Not run)
</code></pre>

<hr>
<h2 id='summary-method'>Summary of model object</h2><span id='topic+summary-method'></span><span id='topic+summary+2CSingleGroupClass-method'></span><span id='topic+summary+2CMultipleGroupClass-method'></span><span id='topic+summary+2CMixedClass-method'></span><span id='topic+summary+2CDiscreteClass-method'></span><span id='topic+summary+2CMixtureClass-method'></span>

<h3>Description</h3>

<p>Transforms coefficients into a standardized factor loading's metric. For <code>MixedClass</code> objects,
the fixed and random coefficients are printed. Note that while the output to the console is rounded
to three digits, the returned list of objects is not. For simulations, use
<code>output &lt;- summary(mod, verbose = FALSE)</code> to suppress the console messages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SingleGroupClass'
summary(
  object,
  rotate = "oblimin",
  Target = NULL,
  suppress = 0,
  suppress.cor = 0,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary-method_+3A_object">object</code></td>
<td>
<p>an object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>MixedClass</code></p>
</td></tr>
<tr><td><code id="summary-method_+3A_rotate">rotate</code></td>
<td>
<p>a string indicating which rotation to use for exploratory models, primarily
from the <code>GPArotation</code> package (see documentation therein).
</p>
<p>Rotations currently supported are: <code>'promax'</code>, <code>'oblimin'</code>, <code>'varimax'</code>,
<code>'quartimin'</code>, <code>'targetT'</code>, <code>'targetQ'</code>, <code>'pstT'</code>, <code>'pstQ'</code>,
<code>'oblimax'</code>, <code>'entropy'</code>, <code>'quartimax'</code>, <code>'simplimax'</code>,
<code>'bentlerT'</code>, <code>'bentlerQ'</code>, <code>'tandemI'</code>, <code>'tandemII'</code>,
<code>'geominT'</code>, <code>'geominQ'</code>, <code>'cfT'</code>, <code>'cfQ'</code>, <code>'infomaxT'</code>,
<code>'infomaxQ'</code>, <code>'mccammon'</code>, <code>'bifactorT'</code>, <code>'bifactorQ'</code>.
</p>
<p>For models that are not exploratory this input will automatically be set to <code>'none'</code></p>
</td></tr>
<tr><td><code id="summary-method_+3A_target">Target</code></td>
<td>
<p>a dummy variable matrix indicting a target rotation pattern. This is required for
rotations such as <code>'targetT'</code>, <code>'targetQ'</code>, <code>'pstT'</code>, and <code>'pstQ'</code></p>
</td></tr>
<tr><td><code id="summary-method_+3A_suppress">suppress</code></td>
<td>
<p>a numeric value indicating which (possibly rotated) factor
loadings should be suppressed. Typical values are around .3 in most
statistical software. Default is 0 for no suppression</p>
</td></tr>
<tr><td><code id="summary-method_+3A_suppress.cor">suppress.cor</code></td>
<td>
<p>same as <code>suppress</code>, but for the correlation matrix
output</p>
</td></tr>
<tr><td><code id="summary-method_+3A_verbose">verbose</code></td>
<td>
<p>logical; allow information to be printed to the console?</p>
</td></tr>
<tr><td><code id="summary-method_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef-method">coef-method</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x &lt;- mirt(Science, 2)
summary(x)
summary(x, rotate = 'varimax')


## End(Not run)
</code></pre>

<hr>
<h2 id='testinfo'>Function to calculate test information</h2><span id='topic+testinfo'></span>

<h3>Description</h3>

<p>Given an estimated model compute the test information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>testinfo(
  x,
  Theta,
  degrees = NULL,
  group = NULL,
  individual = FALSE,
  which.items = 1:extract.mirt(x, "nitems")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="testinfo_+3A_x">x</code></td>
<td>
<p>an object of class 'SingleGroupClass', or an object of class 'MultipleGroupClass' if a suitable
<code>group</code> input were supplied</p>
</td></tr>
<tr><td><code id="testinfo_+3A_theta">Theta</code></td>
<td>
<p>a matrix of latent trait values</p>
</td></tr>
<tr><td><code id="testinfo_+3A_degrees">degrees</code></td>
<td>
<p>a vector of angles in degrees that are between 0 and 90.
Only applicable when the input object is multidimensional</p>
</td></tr>
<tr><td><code id="testinfo_+3A_group">group</code></td>
<td>
<p>group argument to pass to <code><a href="#topic+extract.group">extract.group</a></code> function. Required when the input object is
a multiple-group model</p>
</td></tr>
<tr><td><code id="testinfo_+3A_individual">individual</code></td>
<td>
<p>logical; return a data.frame of information traceline for each item?</p>
</td></tr>
<tr><td><code id="testinfo_+3A_which.items">which.items</code></td>
<td>
<p>an integer vector indicating which items to include in the expected information function.
Default uses all possible items</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
dat &lt;- expand.table(deAyala)
(mirt(dat, 1, '2PL', pars = 'values'))
mod &lt;- mirt(dat, 1, '2PL', constrain = list(c(1,5,9,13,17)))

Theta &lt;- matrix(seq(-4,4,.01))
tinfo &lt;- testinfo(mod, Theta)
plot(Theta, tinfo, type = 'l')

## Not run: 

# compare information loss between two tests
tinfo_smaller &lt;- testinfo(mod, Theta, which.items = 3:5)

# removed item informations
plot(Theta, iteminfo(extract.item(mod, 1), Theta), type = 'l')
plot(Theta, iteminfo(extract.item(mod, 2), Theta), type = 'l')

# most loss of info around -1 when removing items 1 and 2; expected given item info functions
plot(Theta, tinfo_smaller - tinfo, type = 'l')



## End(Not run)
</code></pre>

<hr>
<h2 id='thetaComb'>Create all possible combinations of vector input</h2><span id='topic+thetaComb'></span>

<h3>Description</h3>

<p>This function constructs all possible k-way combinations of an input vector.
It is primarily useful when used in conjunction with the <code><a href="#topic+mdirt">mdirt</a></code> function,
though users may have other uses for it as well. See <code><a href="base.html#topic+expand.grid">expand.grid</a></code> for more
flexible combination formats.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>thetaComb(theta, nfact, intercept = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="thetaComb_+3A_theta">theta</code></td>
<td>
<p>the vector from which all possible combinations should be obtained</p>
</td></tr>
<tr><td><code id="thetaComb_+3A_nfact">nfact</code></td>
<td>
<p>the number of observations (and therefore the number of columns to return in
the matrix of combinations)</p>
</td></tr>
<tr><td><code id="thetaComb_+3A_intercept">intercept</code></td>
<td>
<p>logical; should a vector of 1's be appended to the first column of the
result to include an intercept design component? Default is <code>FALSE</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix with all possible combinations
</p>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# all possible joint combinations for the vector -4 to 4
thetaComb(-4:4, 2)

# all possible binary combinations for four observations
thetaComb(c(0,1), 4)

# all possible binary combinations for four observations (with intercept)
thetaComb(c(0,1), 4, intercept=TRUE)

</code></pre>

<hr>
<h2 id='traditional2mirt'>Convert traditional IRT metric into slope-intercept form used in mirt</h2><span id='topic+traditional2mirt'></span>

<h3>Description</h3>

<p>This is a helper function for users who have previously available traditional/classical
IRT parameters and want to know the equivalent slope-intercept translation used in <code>mirt</code>.
Note that this function assumes that the supplied models are unidimensional by definition (i.e.,
will have only one slope/discrimination). If there is no supported slope-intercept transformation
available then the original vector of parameters will be returned by default.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>traditional2mirt(x, cls, ncat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="traditional2mirt_+3A_x">x</code></td>
<td>
<p>a vector of parameters to tranform</p>
</td></tr>
<tr><td><code id="traditional2mirt_+3A_cls">cls</code></td>
<td>
<p>the class or itemtype of the supplied model</p>
</td></tr>
<tr><td><code id="traditional2mirt_+3A_ncat">ncat</code></td>
<td>
<p>the number of categories implied by the IRT model</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Supported class transformations for the <code>cls</code> input are:
</p>

<dl>
<dt>Rasch, 2PL, 3PL, 3PLu, 4PL</dt><dd>
<p>Form must be: (discrimination, difficulty, lower-bound, upper-bound)
</p>
</dd>
<dt>graded</dt><dd>
<p>Form must be: (discrimination, difficulty 1, difficulty 2, ..., difficulty k-1)
</p>
</dd>
<dt>gpcm</dt><dd>
<p>Form must be: (discrimination, difficulty 1, difficulty 2, ..., difficulty k-1)
</p>
</dd>
<dt>nominal</dt><dd>
<p>Form must be: (discrimination 1, discrimination 2, ..., discrimination k,
difficulty 1, difficulty 2, ..., difficulty k)
</p>
</dd>
</dl>



<h3>Value</h3>

<p>a named vector of slope-intercept parameters (if supported)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# classical 3PL model
vec &lt;- c(a=1.5, b=-1, g=.1, u=1)
slopeint &lt;- traditional2mirt(vec, '3PL', ncat=2)
slopeint

# classical graded model (four category)
vec &lt;- c(a=1.5, b1=-1, b2=0, b3=1.5)
slopeint &lt;- traditional2mirt(vec, 'graded', ncat=4)
slopeint

# classical generalize partial credit model (four category)
vec &lt;- c(a=1.5, b1=-1, b2=0, b3=1.5)
slopeint &lt;- traditional2mirt(vec, 'gpcm', ncat=4)
slopeint

# classical nominal model (4 category)
vec &lt;- c(a1=.5, a2 = -1, a3=1, a4=-.5, d1=1, d2=-1, d3=-.5, d4=.5)
slopeint &lt;- traditional2mirt(vec, 'nominal', ncat=4)
slopeint


</code></pre>

<hr>
<h2 id='vcov-method'>Extract parameter variance covariance matrix</h2><span id='topic+vcov-method'></span><span id='topic+vcov+2CSingleGroupClass-method'></span><span id='topic+vcov+2CMixtureClass-method'></span><span id='topic+vcov+2CMultipleGroupClass-method'></span><span id='topic+vcov+2CMixedClass-method'></span><span id='topic+vcov+2CDiscreteClass-method'></span>

<h3>Description</h3>

<p>Extract parameter variance covariance matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'SingleGroupClass'
vcov(object)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov-method_+3A_object">object</code></td>
<td>
<p>an object of class <code>SingleGroupClass</code>,
<code>MultipleGroupClass</code>, or <code>MixedClass</code></p>
</td></tr>
</table>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
x &lt;- mirt(Science, 1, SE=TRUE)
vcov(x)


## End(Not run)
</code></pre>

<hr>
<h2 id='wald'>Wald statistics for mirt models</h2><span id='topic+wald'></span>

<h3>Description</h3>

<p>Compute a Wald test given an <code>L</code> vector or matrix of numeric contrasts. Requires that the
model information matrix be computed (by passing <code>SE = TRUE</code> when estimating the model). Use
<code>wald(model)</code> to observe how the information matrix columns are named, especially if
the estimated model contains constrained parameters (e.g., 1PL).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wald(object, L, C = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wald_+3A_object">object</code></td>
<td>
<p>estimated object from <code>mirt</code>, <code>bfactor</code>,
<code>multipleGroup</code>, <code>mixedmirt</code>, or <code>mdirt</code></p>
</td></tr>
<tr><td><code id="wald_+3A_l">L</code></td>
<td>
<p>a coefficient matrix with dimensions <code>nconstrasts x npars.estimated</code>,
or a character vector giving the hypothesis in symbolic form
(syntax format borrowed from the <code>car</code> package; see <code>Details</code> below).
Omitting this value will return the column names of the
information matrix used to identify the (potentially constrained) parameters</p>
</td></tr>
<tr><td><code id="wald_+3A_c">C</code></td>
<td>
<p>a constant vector of population parameters to be compared along side L, where
<code>length(C) == row(L)</code>. By default a vector of 0's is constructed. Note that when using
the syntax input for <code>L</code> this argument is ignored
</p>
<p>The following description is borrowed from <code>car</code> package documentation pertaining to the character vector
input to the argument <code>L</code>: &quot;The hypothesis matrix can be supplied as a numeric matrix (or vector), the rows of which
specify linear combinations of the model
coefficients, which are tested equal to the corresponding entries in the right-hand-side vector, which defaults to a vector of zeroes.
</p>
<p>Alternatively, the hypothesis can be specified symbolically as a character vector with one or more elements, each of which gives either
a linear combination of coefficients, or a linear equation in the coefficients (i.e., with both a left and right side separated by an
equals sign). Components of a linear expression or linear equation can consist of numeric constants, or numeric constants multiplying
coefficient names (in which case the number precedes the coefficient, and may be separated from it by spaces or an asterisk);
constants of 1 or -1 may be omitted. Spaces are always optional. Components are separated by plus or minus signs. Newlines or tabs
in hypotheses will be treated as spaces. See the examples below.&quot;</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Phil Chalmers <a href="mailto:rphilip.chalmers@gmail.com">rphilip.chalmers@gmail.com</a>
</p>


<h3>References</h3>

<p>Chalmers, R., P. (2012). mirt: A Multidimensional Item Response Theory
Package for the R Environment. <em>Journal of Statistical Software, 48</em>(6), 1-29.
<a href="https://doi.org/10.18637/jss.v048.i06">doi:10.18637/jss.v048.i06</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# View parnumber index
data(LSAT7)
data &lt;- expand.table(LSAT7)
mod &lt;- mirt(data, 1, SE = TRUE)
coef(mod)

# see how the information matrix relates to estimated parameters, and how it lines up
#   with the parameter index
(infonames &lt;- wald(mod))
index &lt;- mod2values(mod)
index[index$est, ]

# second item slope equal to 0?
L &lt;- matrix(0, 1, 10)
L[1,3] &lt;- 1
wald(mod, L)

# same as above using character syntax input
infonames
wald(mod, "a1.5 = 0")

# simultaneously test equal factor slopes for item 1 and 2, and 4 and 5
L &lt;- matrix(0, 2, 10)
L[1,1] &lt;- L[2, 7] &lt;- 1
L[1,3] &lt;- L[2, 9] &lt;- -1
L
wald(mod, L)

# Again, using more efficient syntax
infonames
wald(mod, c("a1.1 = a1.5", "a1.13 = a1.17"))

# log-Liklihood tests (requires estimating a new model)
cmodel &lt;- 'theta = 1-5
           CONSTRAIN = (1,2, a1), (4,5, a1)'
mod2 &lt;- mirt(data, cmodel)
# or, equivalently
#mod2 &lt;- mirt(data, 1, constrain = list(c(1,5), c(13,17)))
anova(mod2, mod)

#####
# test equality of means in multi-group model:
#    H0: (mu1 - mu2) = (mu3 - mu4)

set.seed(12345)
a &lt;- matrix(abs(rnorm(15,1,.3)), ncol=1)
d &lt;- matrix(rnorm(15,0,.7),ncol=1)
itemtype &lt;- rep('2PL', nrow(a))
N &lt;- 500
dataset1 &lt;- simdata(a, d, N, itemtype)
dataset2 &lt;- simdata(a, d, N, itemtype, mu = .5)
dataset3 &lt;- simdata(a, d, N, itemtype, mu = -1)
dataset4 &lt;- simdata(a, d, N, itemtype, mu = -.5)
dat &lt;- rbind(dataset1, dataset2, dataset3, dataset4)
group &lt;- factor(rep(paste0('D', 1:4), each=N))
levels(group)
models &lt;- 'F1 = 1-15'

# 3 means estimated
mod_free &lt;- multipleGroup(dat, models, group = group, SE=TRUE,
                          invariance=c('slopes', 'intercepts', 'free_var','free_means'))
wald(mod_free) # obtain parameter names
# View(mod2values(mod_free))

# reference group mean = 0 by default
wald(mod_free, c("0 - MEAN_1.123 = MEAN_1.185 - MEAN_1.247"))



## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
