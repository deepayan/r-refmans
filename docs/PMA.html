<!DOCTYPE html><html><head><title>Help for package PMA</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {PMA}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#CCA'><p>Perform sparse canonical correlation analysis using the penalized matrix</p>
decomposition.</a></li>
<li><a href='#CCA.permute'><p>Select tuning parameters for sparse canonical correlation analysis using the</p>
penalized matrix decomposition.</a></li>
<li><a href='#download_breast_data'><p>Download and return the breast data</p></a></li>
<li><a href='#MultiCCA'><p>Perform sparse multiple canonical correlation analysis.</p></a></li>
<li><a href='#MultiCCA.permute'><p>Select tuning parameters for sparse multiple canonical correlation analysis</p>
using the penalized matrix decomposition.</a></li>
<li><a href='#PlotCGH'><p>Plot CGH data</p></a></li>
<li><a href='#PMA-package'><p>Penalized Multivariate Analysis</p></a></li>
<li><a href='#PMD'><p>Get a penalized matrix decomposition for a data matrix.</p></a></li>
<li><a href='#PMD.cv'><p>Do tuning parameter selection for PMD via cross-validation</p></a></li>
<li><a href='#SPC'><p>Perform sparse principal component analysis</p></a></li>
<li><a href='#SPC.cv'><p>Perform cross-validation on sparse principal component analysis</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Penalized Multivariate Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2-3</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-06</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bnaras/PMA">https://github.com/bnaras/PMA</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bnaras/PMA/issues">https://github.com/bnaras/PMA/issues</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Performs Penalized Multivariate Analysis: a penalized
        matrix decomposition, sparse principal components analysis,
        and sparse canonical correlation analysis, described in
        Witten, Tibshirani and Hastie (2009)
        &lt;<a href="https://doi.org/10.1093%2Fbiostatistics%2Fkxp008">doi:10.1093/biostatistics/kxp008</a>&gt; and Witten and Tibshirani
        (2009) Extensions of sparse canonical correlation analysis,
        with applications to genomic data
        &lt;<a href="https://doi.org/10.2202%2F1544-6115.1470">doi:10.2202/1544-6115.1470</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-06 21:54:03 UTC; naras</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniela Witten [aut],
  Rob Tibshirani [aut],
  Sam Gross [aut],
  Balasubramanian Narasimhan [cre, aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Balasubramanian Narasimhan &lt;naras@stanford.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-06 23:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='CCA'>Perform sparse canonical correlation analysis using the penalized matrix
decomposition.</h2><span id='topic+CCA'></span><span id='topic+print.CCA'></span>

<h3>Description</h3>

<p>Given matrices X and Z, which represent two sets of features on the same set
of samples, find sparse u and v such that u'X'Zv is large.  For X and Z, the
samples are on the rows and the features are on the columns. X and Z must
have same number of rows, but may (and usually will) have different numbers
of columns. The columns of X and/or Z can be unordered or ordered. If
unordered, then a lasso penalty will be used to obtain the corresponding
canonical vector. If ordered, then a fused lasso penalty will be used; this
will result in smoothness.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CCA(
  x,
  z,
  typex = c("standard", "ordered"),
  typez = c("standard", "ordered"),
  penaltyx = NULL,
  penaltyz = NULL,
  K = 1,
  niter = 15,
  v = NULL,
  trace = TRUE,
  standardize = TRUE,
  xnames = colnames(x),
  znames = colnames(z),
  chromx = NULL,
  chromz = NULL,
  upos = FALSE,
  uneg = FALSE,
  vpos = FALSE,
  vneg = FALSE,
  outcome = NULL,
  y = NULL,
  cens = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CCA_+3A_x">x</code></td>
<td>
<p>Data matrix; samples are rows and columns are features. Cannot
contain missing values.</p>
</td></tr>
<tr><td><code id="CCA_+3A_z">z</code></td>
<td>
<p>Data matrix; samples are rows and columns are features.  Cannot
contain missing values.</p>
</td></tr>
<tr><td><code id="CCA_+3A_typex">typex</code></td>
<td>
<p>Are the columns of x unordered (type=&quot;standard&quot;) or ordered
(type=&quot;ordered&quot;)? If &quot;standard&quot;, then a lasso penalty is applied to u, to
enforce sparsity. If &quot;ordered&quot; (generally used for CGH data), then a fused
lasso penalty is applied, to enforce both sparsity and smoothness.</p>
</td></tr>
<tr><td><code id="CCA_+3A_typez">typez</code></td>
<td>
<p>Are the columns of z unordered (type=&quot;standard&quot;) or ordered
(type=&quot;ordered&quot;)? If &quot;standard&quot;, then a lasso penalty is applied to v, to
enforce sparsity. If &quot;ordered&quot; (generally used for CGH data), then a fused
lasso penalty is applied, to enforce both sparsity and smoothness.</p>
</td></tr>
<tr><td><code id="CCA_+3A_penaltyx">penaltyx</code></td>
<td>
<p>The penalty to be applied to the matrix x, i.e. the penalty
that results in the canonical vector u. If typex is &quot;standard&quot; then the L1
bound on u is penaltyx*sqrt(ncol(x)). In this case penaltyx must be between
0 and 1 (larger L1 bound corresponds to less penalization). If &quot;ordered&quot;
then it's the fused lasso penalty lambda, which must be non-negative (larger
lambda corresponds to more penalization).</p>
</td></tr>
<tr><td><code id="CCA_+3A_penaltyz">penaltyz</code></td>
<td>
<p>The penalty to be applied to the matrix z, i.e. the penalty
that results in the canonical vector v. If typez is &quot;standard&quot; then the L1
bound on v is penaltyz*sqrt(ncol(z)). In this case penaltyz must be between
0 and 1 (larger L1 bound corresponds to less penalization). If &quot;ordered&quot;
then it's the fused lasso penalty lambda, which must be non-negative (larger
lambda corresponds to more penalization).</p>
</td></tr>
<tr><td><code id="CCA_+3A_k">K</code></td>
<td>
<p>The number of u's and v's desired; that is, the number of canonical
vectors to be obtained.</p>
</td></tr>
<tr><td><code id="CCA_+3A_niter">niter</code></td>
<td>
<p>How many iterations should be performed? Default is 15.</p>
</td></tr>
<tr><td><code id="CCA_+3A_v">v</code></td>
<td>
<p>The first K columns of the v matrix of the SVD of X'Z. If NULL,
then the SVD of X'Z will be computed inside the CCA function. However, if
you plan to run this function multiple times, then save a copy of this
argument so that it does not need to be re-computed (since that process can
be time-consuming if X and Z both have high dimension).</p>
</td></tr>
<tr><td><code id="CCA_+3A_trace">trace</code></td>
<td>
<p>Print out progress?</p>
</td></tr>
<tr><td><code id="CCA_+3A_standardize">standardize</code></td>
<td>
<p>Should the columns of x and z be centered (to have mean
zero) and scaled (to have standard deviation 1)? Default is TRUE.</p>
</td></tr>
<tr><td><code id="CCA_+3A_xnames">xnames</code></td>
<td>
<p>An optional vector of column names for x, defaults to <code>colnames(x)</code></p>
</td></tr>
<tr><td><code id="CCA_+3A_znames">znames</code></td>
<td>
<p>An optional vector of column names for z, defaults to <code>colnames(z)</code></p>
</td></tr>
<tr><td><code id="CCA_+3A_chromx">chromx</code></td>
<td>
<p>Used only if typex is &quot;ordered&quot;; allows user to specify a
vector of length ncol(x) giving the chromosomal location of each CGH spot.
This is so that smoothness will be enforced within each chromosome, but not
between chromosomes.</p>
</td></tr>
<tr><td><code id="CCA_+3A_chromz">chromz</code></td>
<td>
<p>Used only if typez is &quot;ordered&quot;; allows user to specify a
vector of length ncol(z) giving the chromosomal location of each CGH spot.
This is so that smoothness will be enforced within each chromosome, but not
between chromosomes.</p>
</td></tr>
<tr><td><code id="CCA_+3A_upos">upos</code></td>
<td>
<p>If TRUE, then require elements of u to be positive. FALSE by
default. Can only be used if type is &quot;standard&quot;.</p>
</td></tr>
<tr><td><code id="CCA_+3A_uneg">uneg</code></td>
<td>
<p>If TRUE, then require elements of u to be negative. FALSE by
default.  Can only be used if type is &quot;standard&quot;.</p>
</td></tr>
<tr><td><code id="CCA_+3A_vpos">vpos</code></td>
<td>
<p>If TRUE, require elements of v to be positive. FALSE by default.
Can only be used if type is &quot;standard&quot;.</p>
</td></tr>
<tr><td><code id="CCA_+3A_vneg">vneg</code></td>
<td>
<p>If TRUE, require elements of v to be negative. FALSE by default.
Can only be used if type is &quot;standard&quot;.</p>
</td></tr>
<tr><td><code id="CCA_+3A_outcome">outcome</code></td>
<td>
<p>If you would like to incorporate a phenotype into CCA
analysis - that is, you wish to find features that are correlated across the
two data sets and also correlated with a phenotype - then use one of
&quot;survival&quot;, &quot;multiclass&quot;, or &quot;quantitative&quot; to indicate outcome type.
Default is NULL.</p>
</td></tr>
<tr><td><code id="CCA_+3A_y">y</code></td>
<td>
<p>If outcome is not NULL, then this is a vector of phenotypes - one
for each row of x and z. If outcome is &quot;survival&quot; then these are survival
times; must be non-negative. If outcome is &quot;multiclass&quot; then these are class
labels (1,2,3,...). Default NULL.</p>
</td></tr>
<tr><td><code id="CCA_+3A_cens">cens</code></td>
<td>
<p>If outcome is &quot;survival&quot; then these are censoring statuses for
each observation. 1 is complete, 0 is censored. Default NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is useful for performing an integrative analysis of two sets
of measurements taken on the same set of samples: for instance, gene
expression and CGH measurements on the same set of patients. It takes in two
data sets, called x and z, each of which have (the same set of) samples on
the rows. If z is a matrix of CGH data with <em>ordered</em> CGH spots on the
columns, then use typez=&quot;ordered&quot;. If z consists of unordered columns, then
use typez=&quot;standard&quot;. Similarly for typex.
</p>
<p>This function performs the penalized matrix decomposition on the data matrix
$X'Z$. Therefore, the results should be the same as running the PMD function
on t(x)\
using the CCA function is much faster because it avoids computation of
$X'Z$.
</p>
<p>The CCA criterion is as follows: find unit vectors $u$ and $v$ such that
$u'X'Zv$ is maximized subject to constraints on $u$ and $v$.  If
typex=&quot;standard&quot; and typez=&quot;standard&quot; then the constraints on $u$ and $v$
are lasso ($L_1$). If typex=&quot;ordered&quot; then the constraint on $u$ is a fused
lasso penalty (promoting sparsity and smoothness). Similarly if
typez=&quot;ordered&quot;.
</p>
<p>When type x is &quot;standard&quot;: the L1 bound of u is penaltyx*sqrt(ncol(x)).
</p>
<p>When typex is &quot;ordered&quot;: penaltyx controls the amount of sparsity and
smoothness in u, via the fused lasso penalty: $lambda sum_j |u_j| + lambda
sum_j |u_j - u_(j-1)|$. If NULL, then it will be chosen adaptively from the
data.
</p>


<h3>Value</h3>

<table>
<tr><td><code>u</code></td>
<td>
<p>u is output. If you asked for multiple factors then each
column of u is a factor. u has dimension nxK if you asked for K factors.</p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>v is output. If you asked for multiple factors then each column of
v is a factor. v has dimension pxK if you asked for K factors.</p>
</td></tr> <tr><td><code>d</code></td>
<td>
<p>A
vector of length K, which can alternatively be computed as the diagonal of
the matrix $u'X'Zv$.</p>
</td></tr> <tr><td><code>v.init</code></td>
<td>
<p>The first K factors of the v matrix of
the SVD of x'z. This is saved in case this function will be re-run later.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009)
<em>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</em>, <em>Biostatistics, Gol 10 (3), 515-534, Jul 2009</em><br />
</p>


<h3>See Also</h3>

<p><a href="#topic+PMD">PMD</a>,<a href="#topic+CCA.permute">CCA.permute</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# first, do CCA with type="standard"
# A simple simulated example
set.seed(3189)
u &lt;- matrix(c(rep(1,25),rep(0,75)),ncol=1)
v1 &lt;- matrix(c(rep(1,50),rep(0,450)),ncol=1)
v2 &lt;- matrix(c(rep(0,50),rep(1,50),rep(0,900)),ncol=1)
x &lt;- u%*%t(v1) + matrix(rnorm(100*500),ncol=500)
z &lt;- u%*%t(v2) + matrix(rnorm(100*1000),ncol=1000)
# Can run CCA with default settings, and can get e.g. 3 components
out &lt;- CCA(x,z,typex="standard",typez="standard",K=3)
print(out,verbose=TRUE) # To get less output, just print(out)
# Or can use CCA.permute to choose optimal parameter values
perm.out &lt;- CCA.permute(x,z,typex="standard",typez="standard",nperms=7)
print(perm.out)
plot(perm.out)
out &lt;- CCA(x,z,typex="standard",typez="standard",K=1,
	   penaltyx=perm.out$bestpenaltyx,penaltyz=perm.out$bestpenaltyz,
	   v=perm.out$v.init)
print(out)


##### The remaining examples are commented out, but uncomment to run: ######

# Not run, to save time:
## Not run: 
## Now try CCA with a constraint that elements of u must be negative and
## elements of v must be positive:
perm.out &lt;- CCA.permute(x,z,typex="standard",typez="standard",nperms=7,
penaltyxs=seq(.1,.7,len=10), penaltyzs=seq(.1,.7,len=10), uneg=TRUE, vpos=TRUE)
print(perm.out)
plot(perm.out)
out &lt;- CCA(x,z,typex="standard",typez="standard",K=1,
	   penaltyx=perm.out$bestpenaltyx,penaltyz=perm.out$bestpenaltyz,
           v=perm.out$v.init, uneg=TRUE, vpos=TRUE)
print(out)


## Suppose we also have a quantitative outcome, y, and we want to find
## features in x and z that are correlated with each other and with the
## outcome:
y &lt;- rnorm(nrow(x))
perm.out &lt;- CCA.permute(x,z,typex="standard",typez="standard",
			outcome="quantitative",y=y, nperms=6)
print(perm.out)
out&lt;-CCA(x,z,typex="standard",typez="standard",outcome="quantitative",
	 y=y,penaltyx=perm.out$bestpenaltyx,penaltyz=perm.out$bestpenaltyz)
print(out)

## now, do CCA with type="ordered"
## Example involving the breast cancer data: gene expression + CGH
set.seed(22)
breastdata &lt;- download_breast_data()
with(breastdata, {
dna &lt;- t(dna)
rna &lt;- t(rna)
perm.out &lt;- CCA.permute(x=rna,z=dna[,chrom==1],typex="standard",
		       	typez="ordered",nperms=5,penaltyxs=seq(.02,.7,len=10))
## We run CCA using all gene exp. data, but CGH data on chrom 1 only.
print(perm.out)
plot(perm.out)
out &lt;- CCA(x=rna,z=dna[,chrom==1], typex="standard", typez="ordered",
	   penaltyx=perm.out$bestpenaltyx,
           v=perm.out$v.init, penaltyz=perm.out$bestpenaltyz,
           xnames=substr(genedesc,1,20),
           znames=paste("Pos", sep="", nuc[chrom==1]))
# Save time by inputting  lambda and v
print(out) # could do print(out,verbose=TRUE)
print(genechr[out$u!=0]) # Cool! The genes associated w/ gain or loss
## on chrom 1 are located on chrom 1!!
par(mfrow=c(1,1))
PlotCGH(out$v, nuc=nuc[chrom==1], chrom=chrom[chrom==1],
main="Regions of gain/loss on Chrom 1 assoc'd with gene expression")
} )

## End(Not run)

</code></pre>

<hr>
<h2 id='CCA.permute'>Select tuning parameters for sparse canonical correlation analysis using the
penalized matrix decomposition.</h2><span id='topic+CCA.permute'></span>

<h3>Description</h3>

<p>This function can be used to automatically select tuning parameters for
sparse CCA using the penalized matrix decompostion. For each data set x and
z, two types are possible: (1) type &quot;standard&quot;, which does not assume any
ordering of the columns of the data set, and (2) type &quot;ordered&quot;, which
assumes that columns of the data set are ordered and thus that corresponding
canonical vector should be both sparse and smooth (e.g. CGH data).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CCA.permute(
  x,
  z,
  typex = c("standard", "ordered"),
  typez = c("standard", "ordered"),
  penaltyxs = NULL,
  penaltyzs = NULL,
  niter = 3,
  v = NULL,
  trace = TRUE,
  nperms = 25,
  standardize = TRUE,
  chromx = NULL,
  chromz = NULL,
  upos = FALSE,
  uneg = FALSE,
  vpos = FALSE,
  vneg = FALSE,
  outcome = NULL,
  y = NULL,
  cens = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="CCA.permute_+3A_x">x</code></td>
<td>
<p>Data matrix; samples are rows and columns are features.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_z">z</code></td>
<td>
<p>Data matrix; samples are rows and columns are features. Note that x
and z must have the same number of rows, but may (and generally will) have
different numbers of columns.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_typex">typex</code></td>
<td>
<p>Are the columns of x unordered (type=&quot;standard&quot;) or ordered
(type=&quot;ordered&quot;)? If &quot;standard&quot;, then a lasso penalty is applied to v, to
enforce sparsity. If &quot;ordered&quot; (generally used for CGH data), then a fused
lasso penalty is applied, to enforce both sparsity and smoothness.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_typez">typez</code></td>
<td>
<p>Are the columns of z unordered (type=&quot;standard&quot;) or ordered
(type=&quot;ordered&quot;)? If &quot;standard&quot;, then a lasso penalty is applied to v, to
enforce sparsity. If &quot;ordered&quot; (generally used for CGH data), then a fused
lasso penalty is applied, to enforce both sparsity and smoothness.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_penaltyxs">penaltyxs</code></td>
<td>
<p>The set of x penalties to be considered. If
typex=&quot;standard&quot;, then the L1 bound on u is penaltyxs*sqrt(ncol(x)). If
&quot;ordered&quot;, then it's the lambda for the fused lasso penalty. The user can
specify a single value or a vector of values. If penaltyxs is a vector and
penaltyzs is a vector, then the vectors must have the same length. If NULL,
then the software will automatically choose a single lambda value if type is
&quot;ordered&quot;, or a grid of (L1 bounds)/sqrt(ncol(x)) if type is &quot;standard&quot;.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_penaltyzs">penaltyzs</code></td>
<td>
<p>The set of z penalties to be considered. If
typez=&quot;standard&quot;, then the L1 bound on v is penaltyzs*sqrt(ncol(z)). If
&quot;ordered&quot;, then it's the lambda for the fused lasso penalty. The user can
specify a single value or a vector of values. If penaltyzs is a vector and
penaltyzs is a vector, then the vectors must have the same length. If NULL,
then the software will automatically choose a single lambda value if type is
&quot;ordered&quot;, or a grid of (L1 bounds)/sqrt(ncol(z)) if type is &quot;standard&quot;.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_niter">niter</code></td>
<td>
<p>How many iterations should be performed each time CCA is
called? Default is 3, since an approximate estimate of u and v is acceptable
in this case, and otherwise this function can be quite time-consuming.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_v">v</code></td>
<td>
<p>The first K columns of the v matrix of the SVD of X'Z. If NULL,
then the SVD of X'Z will be computed inside this function. However, if you
plan to run this function multiple times, then save a copy of this argument
so that it does not need to be re-computed (since that process can be
time-consuming if X and Z both have high dimension).</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_trace">trace</code></td>
<td>
<p>Print out progress?</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_nperms">nperms</code></td>
<td>
<p>How many times should the data be permuted? Default is 25. A
large value of nperms is very important here, since the formula for
computing the z-statistics requires a standard deviation estimate for the
correlations obtained via permutation, which will not be accurate if nperms
is very small.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_standardize">standardize</code></td>
<td>
<p>Should the columns of X and Z be centered (to have mean
zero) and scaled (to have standard deviation 1)? Default is TRUE.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_chromx">chromx</code></td>
<td>
<p>Used only if typex=&quot;ordered&quot;; a vector of length ncol(x) that
allows you to specify which chromosome each CGH spot is on. If NULL, then it
is assumed that all CGH spots are on same chromosome.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_chromz">chromz</code></td>
<td>
<p>Used only if typex=&quot;ordered&quot;; a vector of length ncol(z) that
allows you to specify which chromosome each CGH spot is on. If NULL, then it
is assumed that all CGH spots are on same chromosome.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_upos">upos</code></td>
<td>
<p>If TRUE, then require all elements of u to be positive in sign.
Default is FALSE. Can only be used if type is standard.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_uneg">uneg</code></td>
<td>
<p>If TRUE, then require all elements of u to be negative in sign.
Default is FALSE. Can only be used if type is standard.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_vpos">vpos</code></td>
<td>
<p>If TRUE, then require all elements of v to be positive in sign.
Default is FALSE.  Can only be used if type is standard.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_vneg">vneg</code></td>
<td>
<p>If TRUE, then require all elements of v to be negative in sign.
Default is FALSE. Can only be used if type is standard.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_outcome">outcome</code></td>
<td>
<p>If you would like to incorporate a phenotype into CCA
analysis - that is, you wish to find features that are correlated across the
two data sets and also correlated with a phenotype - then use one of
&quot;survival&quot;, &quot;multiclass&quot;, or &quot;quantitative&quot; to indicate outcome type.
Default is NULL.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_y">y</code></td>
<td>
<p>If outcome is not NULL, then this is a vector of phenotypes - one
for each row of x and z. If outcome is &quot;survival&quot; then these are survival
times; must be non-negative. If outcome is &quot;multiclass&quot; then these are class
labels. Default NULL.</p>
</td></tr>
<tr><td><code id="CCA.permute_+3A_cens">cens</code></td>
<td>
<p>If outcome is &quot;survival&quot; then these are censoring statuses for
each observation. 1 is complete, 0 is censored. Default NULL.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For X and Z, the samples are on the rows and the features are on the
columns.
</p>
<p>The tuning parameters are selected using a permutation scheme. For each
candidate tuning parameter value, the following is performed: (1) The
samples in X are randomly permuted nperms times, to obtain matrices
$X*_1,X*_2,...$. (2) Sparse CCA is run on each permuted data set $(X*_i,Z)$
to obtain factors $(u*_i, v*_i)$. (3) Sparse CCA is run on the original data
(X,Z) to obtain factors u and v. (4) Compute $c*_i=cor(X*_i u*_i,Z v*_i)$
and $c=cor(Xu,Zv)$. (5) Use Fisher's transformation to convert these
correlations into random variables that are approximately normally
distributed. Let Fisher(c) denote the Fisher transformation of c. (6)
Compute a z-statistic for Fisher(c), using
$(Fisher(c)-mean(Fisher(c*)))/sd(Fisher(c*))$. The larger the z-statistic,
the &quot;better&quot; the corresponding tuning parameter value.
</p>
<p>This function also gives the p-value for each pair of canonical variates
(u,v) resulting from a given tuning parameter value. This p-value is
computed as the fraction of $c*_i$'s that exceed c (using the notation of
the previous paragraph).
</p>
<p>Using this function, only the first left and right canonical variates are
considered in selection of the tuning parameter.
</p>
<p>Note that x and z must have same number of rows. This function
performs just a one-dimensional search in tuning parameter space,
even if penaltyxs and penaltyzs both are vectors: the pairs
<code style="white-space: pre;">&#8288;(penaltyxs[1],penaltyzs[1])&#8288;</code>,
<code style="white-space: pre;">&#8288;(penaltyxs[2],penaltyzs[2])&#8288;</code>,.... are considered.
</p>


<h3>Value</h3>

<table>
<tr><td><code>zstat</code></td>
<td>
<p>The vector of z-statistics, one per element of
sumabss.</p>
</td></tr> <tr><td><code>pvals</code></td>
<td>
<p>The vector of p-values, one per element of sumabss.</p>
</td></tr>
<tr><td><code>bestpenaltyx</code></td>
<td>
<p>The x penalty that resulted in the highest z-statistic.</p>
</td></tr>
<tr><td><code>bestpenaltyz</code></td>
<td>
<p>The z penalty that resulted in the highest z-statistic.</p>
</td></tr>
<tr><td><code>cors</code></td>
<td>
<p>The value of cor(Xu,Zv) obtained for each value of sumabss.</p>
</td></tr>
<tr><td><code>corperms</code></td>
<td>
<p>The nperms values of cor(X<em>u</em>,Zv*) obtained for each value
of sumabss, where X* indicates the X matrix with permuted rows, and u* and
v* are the output of CCA using data (X*,Z).</p>
</td></tr> <tr><td><code>ft.cors</code></td>
<td>
<p>The result of
applying Fisher transformation to cors.</p>
</td></tr> <tr><td><code>ft.corperms</code></td>
<td>
<p>The result of
applying Fisher transformation to corperms.</p>
</td></tr> <tr><td><code>nnonzerous</code></td>
<td>
<p>Number of
non-zero u's resulting from applying CCA to data (X,Z) for each value of
sumabss.</p>
</td></tr> <tr><td><code>nnonzerouv</code></td>
<td>
<p>Number of non-zero v's resulting from applying
CCA to data (X,Z) for each value of sumabss.</p>
</td></tr> <tr><td><code>v.init</code></td>
<td>
<p>The first factor
of the v matrix of the SVD of x'z. This is saved in case this function (or
the CCA function) will be re-run later.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009)
<em>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</em>, <em>Biostatistics, Gol 10 (3), 515-534, Jul 2009</em><br />
</p>


<h3>See Also</h3>

<p><a href="#topic+PMD">PMD</a>,<a href="#topic+CCA">CCA</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples in CCA function

</code></pre>

<hr>
<h2 id='download_breast_data'>Download and return the breast data</h2><span id='topic+download_breast_data'></span>

<h3>Description</h3>

<p>Breast cancer gene expression + DNA copy number data set from Chin
et. al. and used in Witten, et. al. See references below.
</p>
<p>This data set consists of gene expression and DNA copy number
measurements on a set of 89 samples. The data set can be used to
perform integrative analysis of gene expression and DNA copy number
data, as in . That is,
we can look for sets of genes that are associated with regions of
chromosomal gain/loss.
</p>
<p>Missing values were imputed using 5-nearest neighbors (see library
<code>pamr</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>download_breast_data(url = "https://tibshirani.su.domains/PMA/breastdata.rda")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="download_breast_data_+3A_url">url</code></td>
<td>
<p>source, default <code>"https://tibshirani.su.domains/PMA/breastdata.rda"</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing the following elements:
</p>

<ul>
<li> <p><code>dna</code>: a 2149x89 matrix of CGH spots x Samples
</p>
</li>
<li> <p><code>rna</code>: a 19672x89 matrix of Genes x Samples
</p>
</li>
<li> <p><code>chrom</code>: a 2149-vector of chromosomal location of each CGH spot
</p>
</li>
<li> <p><code>nuc</code>: a 2149-vector of nucleotide position for each CGH spot
</p>
</li>
<li> <p><code>gene</code>: a 19672-vector wiith an accession number for each gene
</p>
</li>
<li> <p><code>genenames</code>: a 19672-vector with a name for each gene
</p>
</li>
<li> <p><code>genechr</code>: a 19672-vector with a chromosomal location for each gene
</p>
</li>
<li> <p><code>genedesc</code>: a 19672-vector with a description for each gene
</p>
</li>
<li> <p><code>genepos</code>: a 19672-vector with a nucleotide position for each gene.
</p>
</li></ul>



<h3>References</h3>

<p>Chin K., et. al. (2006) <a href="https://doi.org/10.1016/j.ccr.2006.10.009">doi:10.1016/j.ccr.2006.10.009</a>.
</p>
<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009) <a href="https://doi.org/10.1093/biostatistics/kxp008">doi:10.1093/biostatistics/kxp008</a>.
</p>

<hr>
<h2 id='MultiCCA'>Perform sparse multiple canonical correlation analysis.</h2><span id='topic+MultiCCA'></span><span id='topic+print.MultiCCA'></span>

<h3>Description</h3>

<p>Given matrices $X1,...,XK$, which represent K sets of features on the same
set of samples, find sparse $w1,...,wK$ such that $sum_(i&lt;j) (wi' Xi' Xj
wj)$ is large. If the columns of Xk are ordered (and type=&quot;ordered&quot;) then wk
will also be smooth. For $X1,...,XK$, the samples are on the rows and the
features are on the columns. $X1,...,XK$ must have same number of rows, but
may (and usually will) have different numbers of columns.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultiCCA(
  xlist,
  penalty = NULL,
  ws = NULL,
  niter = 25,
  type = "standard",
  ncomponents = 1,
  trace = TRUE,
  standardize = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MultiCCA_+3A_xlist">xlist</code></td>
<td>
<p>A list of length K, where K is the number of data sets on which
to perform sparse multiple CCA. Data set k should be a matrix of dimension
$n x p_k$ where $p_k$ is the number of features in data set k.</p>
</td></tr>
<tr><td><code id="MultiCCA_+3A_penalty">penalty</code></td>
<td>
<p>The penalty terms to be used. Can be a single value (if the
same penalty term is to be applied to each data set) or a K-vector,
indicating a different penalty term for each data set. There are 2 possible
interpretations for the penalty terms: If type=&quot;standard&quot; then this is an L1
bound on wk, and it must be between 1 and $sqrt(p_k)$ ($p_k$ is the number
of features in matrix Xk). If type=&quot;ordered&quot; then this is the parameter for
the fused lasso penalty on wk.</p>
</td></tr>
<tr><td><code id="MultiCCA_+3A_ws">ws</code></td>
<td>
<p>A list of length K. The kth element contains the first ncomponents
columns of the v matrix of the SVD of Xk. If NULL, then the SVD of
$X1,...,XK$ will be computed inside the MultiCCA function. However, if you
plan to run this function multiple times, then save a copy of this argument
so that it does not need to be re-computed.</p>
</td></tr>
<tr><td><code id="MultiCCA_+3A_niter">niter</code></td>
<td>
<p>How many iterations should be performed? Default is 25.</p>
</td></tr>
<tr><td><code id="MultiCCA_+3A_type">type</code></td>
<td>
<p>Are the columns of $x1,...,xK$ unordered (type=&quot;standard&quot;) or
ordered (type=&quot;ordered&quot;)? If &quot;standard&quot;, then a lasso penalty is applied to
v, to enforce sparsity. If &quot;ordered&quot; (generally used for CGH data), then a
fused lasso penalty is applied, to enforce both sparsity and smoothness.
This argument can be a vector of length K (if different data sets are of
different types) or it can be a single value &quot;ordered&quot;/&quot;standard&quot; (if all
data sets are of the same type).</p>
</td></tr>
<tr><td><code id="MultiCCA_+3A_ncomponents">ncomponents</code></td>
<td>
<p>How many factors do you want? Default is 1.</p>
</td></tr>
<tr><td><code id="MultiCCA_+3A_trace">trace</code></td>
<td>
<p>Print out progress?</p>
</td></tr>
<tr><td><code id="MultiCCA_+3A_standardize">standardize</code></td>
<td>
<p>Should the columns of $X1,...,XK$ be centered (to have
mean zero) and scaled (to have standard deviation 1)? Default is TRUE.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ws</code></td>
<td>
<p>A list of length K, containg the sparse canonical variates
found (element k is a $p_k x ncomponents$ matrix).</p>
</td></tr> <tr><td><code>ws.init</code></td>
<td>
<p>A list of
length K containing the initial values of ws used, by default these are the
v vector of the svd of matrix Xk.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009)
<em>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</em>, <em>Biostatistics, Gol 10 (3), 515-534, Jul 2009</em><br />
</p>


<h3>See Also</h3>

<p><a href="#topic+MultiCCA.permute">MultiCCA.permute</a>,<a href="#topic+CCA">CCA</a>, <a href="#topic+CCA.permute">CCA.permute</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Generate 3 data sets so that first 25 features are correlated across
# the data sets...
set.seed(123)
u &lt;- matrix(rnorm(50),ncol=1)
v1 &lt;- matrix(c(rep(.5,25),rep(0,75)),ncol=1)
v2 &lt;- matrix(c(rep(1,25),rep(0,25)),ncol=1)
v3 &lt;- matrix(c(rep(.5,25),rep(0,175)),ncol=1)

x1 &lt;- u%*%t(v1) + matrix(rnorm(50*100),ncol=100)
x2 &lt;- u%*%t(v2) + matrix(rnorm(50*50),ncol=50)
x3 &lt;- u%*%t(v3) + matrix(rnorm(50*200),ncol=200)

xlist &lt;- list(x1, x2, x3)

# Run MultiCCA.permute w/o specifying values of tuning parameters to
# try.
# The function will choose the lambda for the ordered data set.
# Then permutations will be used to select optimal sum(abs(w)) for
# standard data sets.
# We assume that x1 is standard, x2 is ordered, x3 is standard:
perm.out &lt;- MultiCCA.permute(xlist, type=c("standard", "ordered",
"standard"))
print(perm.out)
plot(perm.out)
out &lt;- MultiCCA(xlist, type=c("standard", "ordered", "standard"),
penalty=perm.out$bestpenalties, ncomponents=2, ws=perm.out$ws.init)
print(out)
# Or if you want to specify tuning parameters by hand:
# this time, assume all data sets are standard:
perm.out &lt;- MultiCCA.permute(xlist, type="standard",
penalties=cbind(c(1.1,1.1,1.1),c(2,3,4),c(5,7,10)), ws=perm.out$ws.init)
print(perm.out)
plot(perm.out)

# Making use of the fact that the features are ordered:
out &lt;- MultiCCA(xlist, type="ordered", penalty=.6)
par(mfrow=c(3,1))
PlotCGH(out$ws[[1]], chrom=rep(1,ncol(x1)))
PlotCGH(out$ws[[2]], chrom=rep(2,ncol(x2)))
PlotCGH(out$ws[[3]], chrom=rep(3,ncol(x3)))

</code></pre>

<hr>
<h2 id='MultiCCA.permute'>Select tuning parameters for sparse multiple canonical correlation analysis
using the penalized matrix decomposition.</h2><span id='topic+MultiCCA.permute'></span><span id='topic+print.MultiCCA.permute'></span><span id='topic+plot.MultiCCA.permute'></span>

<h3>Description</h3>

<p>This function can be used to automatically select tuning parameters for
sparse multiple CCA. This is the analog of sparse CCA, when &gt;2 data sets are
available. Each data set may have features of type=&quot;standard&quot; or
type=&quot;ordered&quot; (e.g. CGH data). Assume that there are K data sets, called
$X1,...,XK$.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MultiCCA.permute(
  xlist,
  penalties = NULL,
  ws = NULL,
  type = "standard",
  nperms = 10,
  niter = 3,
  trace = TRUE,
  standardize = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MultiCCA.permute_+3A_xlist">xlist</code></td>
<td>
<p>A list of length K, where K is the number of data sets on which
to perform sparse multiple CCA. Data set k should be a matrix of dimension
$n x p_k$ where $p_k$ is the number of features in data set k.</p>
</td></tr>
<tr><td><code id="MultiCCA.permute_+3A_penalties">penalties</code></td>
<td>
<p>The penalty terms to be considered in the cross-validation.
If the same penalty term is desired for each data set, then this should be a
vector of length equal to the number of penalty terms to be considered. If
different penalty terms are desired for each data set, then this should be a
matrix with rows equal to the number of data sets, and columns equal to the
number of penalty terms to be considered. For a given data set Xk, if type
is &quot;standard&quot; then the penalty term should be a number between 1 and
$sqrt(p_k)$ (the number of features in data set k); it is a L1 bound on wk.
If type is &quot;ordered&quot;, on the other hand, the penalty term is of the form
lambda in the fused lasso penalty. Therefore, the interpretation of the
argument depends on whether type is &quot;ordered&quot; or &quot;standard&quot; for this data
set.</p>
</td></tr>
<tr><td><code id="MultiCCA.permute_+3A_ws">ws</code></td>
<td>
<p>A list of length K; the kth element contanis the first ncomponents
columns of the v matrix of the SVD of Xk. If NULL, then the SVD of Xk will
be computed inside this function. However, if you plan to run this function
multiple times, then save a copy of this argument so that it does not need
to be re-computed.</p>
</td></tr>
<tr><td><code id="MultiCCA.permute_+3A_type">type</code></td>
<td>
<p>A K-vector containing elements &quot;standard&quot; or &quot;ordered&quot; - or a
single value. If a single value, then it is assumed that all elements are
the same (either &quot;standard&quot; or &quot;ordered&quot;).  If columns of v are ordered
(e.g. CGH spots ordered along the chromosome) then &quot;ordered&quot;, otherwise use
&quot;standard&quot;. &quot;standard&quot; will result in a lasso ($L_1$) penalty on v, which
will result in smoothness. &quot;ordered&quot; will result in a fused lasso penalty on
v, yielding both sparsity and smoothness.</p>
</td></tr>
<tr><td><code id="MultiCCA.permute_+3A_nperms">nperms</code></td>
<td>
<p>How many times should the data be permuted? Default is 25. A
large value of nperms is very important here, since the formula for
computing the z-statistics requires a standard deviation estimate for the
correlations obtained via permutation, which will not be accurate if nperms
is very small.</p>
</td></tr>
<tr><td><code id="MultiCCA.permute_+3A_niter">niter</code></td>
<td>
<p>How many iterations should be performed each time CCA is
called? Default is 3, since an approximate estimate of u and v is acceptable
in this case, and otherwise this function can be quite time-consuming.</p>
</td></tr>
<tr><td><code id="MultiCCA.permute_+3A_trace">trace</code></td>
<td>
<p>Print out progress?</p>
</td></tr>
<tr><td><code id="MultiCCA.permute_+3A_standardize">standardize</code></td>
<td>
<p>Should the columns of X and Z be centered (to have mean
zero) and scaled (to have standard deviation 1)? Default is TRUE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The tuning parameters are selected using a permutation scheme. For each
candidate tuning parameter value, the following is performed: (1) Repeat the
following n times, for n large: (a) The samples in $(X1,...,XK)$ are
randomly permuted to obtain data sets $(X1*,...,XK*)$. (b) Sparse multiple
CCA is run on the permuted data sets $(X1*,...,XK*)$ to get canonical
variates $(w1*,...,wK*)$. (c) Record $t* = sum_(i&lt;j) Cor(Xi* wi*, Xj* wj*)$.
(2) Sparse CCA is run on the original data $(X1,...,XK)$ to obtain canonical
variates $(w1,...,wK)$. (3) Record $t = sum_(i&lt;j) Cor(Xi wi, Xj wj)$. (4)
The resulting p-value is given by $mean(t* &gt; t)$; that is, the fraction of
permuted totals that exceed the total on the real data. Then, choose the
tuning parameter value that gives the smallest value in Step 4.
</p>
<p>This function only selets tuning parameters for the FIRST sparse multiple
CCA factors.
</p>
<p>Note that $x1,...,xK$ must have same number of rows. This function performs
just a one-dimensional search in tuning parameter space.
</p>


<h3>Value</h3>

<table>
<tr><td><code>zstat</code></td>
<td>
<p>The vector of z-statistics, one per element of
penalties.</p>
</td></tr> <tr><td><code>pvals</code></td>
<td>
<p>The vector of p-values, one per element of
penalties.</p>
</td></tr> <tr><td><code>bestpenalties</code></td>
<td>
<p>The best set of penalties (the one with the
highest zstat).</p>
</td></tr> <tr><td><code>cors</code></td>
<td>
<p>The value of $sum_(j&lt;k) cor(Xk wk, Xj wj)$
obtained for each value of penalties.</p>
</td></tr> <tr><td><code>corperms</code></td>
<td>
<p>The nperms values of
$sum_(j&lt;k) cor(Xk* wk*, Xj* wj*)$ obtained for each value of penalties,
where Xk* indicates the Xk matrix with permuted rows, and wk* is the
canonical variate corresponding to the permuted data.</p>
</td></tr>
<tr><td><code>ws.init</code></td>
<td>
<p>Initial values used for ws in sparse multiple CCA algorithm.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009)
<em>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</em>, <em>Biostatistics, Gol 10 (3), 515-534, Jul 2009</em><br />
</p>


<h3>See Also</h3>

<p><a href="#topic+MultiCCA">MultiCCA</a>, <a href="#topic+CCA.permute">CCA.permute</a>, <a href="#topic+CCA">CCA</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# See examples in MultiCCA function

</code></pre>

<hr>
<h2 id='PlotCGH'>Plot CGH data</h2><span id='topic+PlotCGH'></span>

<h3>Description</h3>

<p>Given a vector of gains/losses at CGH spots, this makes a plot of gain/loss
on each chromosome.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PlotCGH(array, chrom = NULL, nuc = NULL, main = "", scaleEachChrom = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PlotCGH_+3A_array">array</code></td>
<td>
<p>A vector containing the chromosomal location of each CGH spot.</p>
</td></tr>
<tr><td><code id="PlotCGH_+3A_chrom">chrom</code></td>
<td>
<p>A numeric vector of the same length as &quot;array&quot;; its values
should indicate the chromosome that each CGH spot is on (for instance, for
human genomic data, values of chrom should range from 1 to 24). If NULL,
then it is assumed that all elements of 'array' are on the same chromosome.</p>
</td></tr>
<tr><td><code id="PlotCGH_+3A_nuc">nuc</code></td>
<td>
<p>A numeric vector of same length as &quot;array&quot;, indicating the
nucleotide position of each CGH spot. If NULL, then the function assumes
that each CGH spot corresponds to a consecutive position. E.g. if there are
200 CGH spots on chromosome 1, then they are located at positions
1,2,...,199,200.</p>
</td></tr>
<tr><td><code id="PlotCGH_+3A_main">main</code></td>
<td>
<p>Give your plot a title.</p>
</td></tr>
<tr><td><code id="PlotCGH_+3A_scaleeachchrom">scaleEachChrom</code></td>
<td>
<p>Default is TRUE. This means that each chromosomes CGH
spots are divided by 1.1 times the max of the CGH spots on that chromosome.
This way, the CGH spots on each chromosome of the plot are as big as
possible (i.e. easy to see). If FALSE, then all of the CGH spots are divided
by 1.1 times the max of ALL the CGH spots. This means that on some
chromosomes CGH spots might be hard to see, but has the advantage that now
relative magnitudes of CGH spots on different chromosomes can be seen from
figure.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function makes a plot of regions of genomic gain/loss.
</p>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009)
<em>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</em>, <em>Biostatistics, Gol 10 (3), 515-534, Jul 2009</em><br />
</p>


<h3>See Also</h3>

<p><a href="#topic+PMD">PMD</a>, <a href="#topic+PMD.cv">PMD.cv</a>, <a href="#topic+CCA">CCA</a>, <a href="#topic+CCA.permute">CCA.permute</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Use breast data
breastdata &lt;- download_breast_data()
with(breastdata, {
# dna contains CGH data and chrom contains chromosome of each CGH spot;
# nuc contains position of each CGH spot.
dna &lt;- t(dna)
ch1 &lt;- which(chrom == 1)
PlotCGH(dna[1,],chrom=chrom,nuc=nuc,main="Sample 1: All Chromosomes")
PlotCGH(dna[1,ch1], chrom=chrom[ch1], nuc=nuc[ch1],
main= "Sample 1: Chrom 1")
chlt3 = which(chrom &lt;= 3)
PlotCGH(dna[1,chlt3], chrom=chrom[chlt3], nuc=nuc[chlt3],
 main="Sample 1: Chroms 1, 2, and 3")
} )

## End(Not run)
</code></pre>

<hr>
<h2 id='PMA-package'>Penalized Multivariate Analysis</h2><span id='topic+PMA-package'></span><span id='topic+PMA'></span>

<h3>Description</h3>

<p>This package is called <strong>PMA</strong>, for __P__enalized __M__ultivariate
__A__nalysis.  It implements three methods: A penalized matrix
decomposition, sparse principal components analysis, and sparse
canonical correlations analysis. All are described in the reference below.
The main functions are: <code>PMD</code>, <code>CCA</code> and <code>SPC</code>.
</p>


<h3>Details</h3>

<p>The first, <code>PMD</code>, performs a penalized matrix decomposition.  <code>CCA</code>
performs sparse canonical correlation analysis. <code>SPC</code> performs sparse
principal components analysis.
</p>
<p>There also are cross-validation functions for tuning parameter selection for
each of the above methods: <code>SPC.cv</code>, <code>PMD.cv</code>, <code>CCA.permute</code>. And <code>PlotCGH</code> produces
nice plots for DNA copy number data.
</p>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009) <a href="https://doi.org/10.1093/biostatistics/kxp008">doi:10.1093/biostatistics/kxp008</a>.
</p>

<hr>
<h2 id='PMD'>Get a penalized matrix decomposition for a data matrix.</h2><span id='topic+PMD'></span>

<h3>Description</h3>

<p>Performs a penalized matrix decomposition for a data matrix. Finds factors u
and v that summarize the data matrix well. u and v will both be sparse, and
v can optionally also be smooth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PMD(
  x,
  type = c("standard", "ordered"),
  sumabs = 0.4,
  sumabsu = 5,
  sumabsv = NULL,
  lambda = NULL,
  niter = 20,
  K = 1,
  v = NULL,
  trace = TRUE,
  center = TRUE,
  chrom = NULL,
  rnames = NULL,
  cnames = NULL,
  upos = FALSE,
  uneg = FALSE,
  vpos = FALSE,
  vneg = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PMD_+3A_x">x</code></td>
<td>
<p>Data matrix of dimension $n x p$, which can contain NA for missing
values.</p>
</td></tr>
<tr><td><code id="PMD_+3A_type">type</code></td>
<td>
<p>&quot;standard&quot; or &quot;ordered&quot;: Do we want v to simply be sparse, or
should it also be smooth? If the columns of x are ordered (e.g. CGH spots
along a chromosome) then choose &quot;ordered&quot;. Default is &quot;standard&quot;. If
&quot;standard&quot;, then the PMD function will make use of sumabs OR
sumabsu&amp;sumabsv. If &quot;ordered&quot;, then the function will make use of sumabsu
and lambda.</p>
</td></tr>
<tr><td><code id="PMD_+3A_sumabs">sumabs</code></td>
<td>
<p>Used only if type is &quot;standard&quot;. A measure of sparsity for u
and v vectors, between 0 and 1. When sumabs is specified, and sumabsu and
sumabsv are NULL, then sumabsu is set to $sqrt(n)*sumabs$ and sumabsv is set
to $sqrt(p)*sumabs$. If sumabs is specified, then sumabsu and sumabsv should
be NULL. Or if sumabsu and sumabsv are specified, then sumabs should be
NULL.</p>
</td></tr>
<tr><td><code id="PMD_+3A_sumabsu">sumabsu</code></td>
<td>
<p>Used for types &quot;ordered&quot; AND &quot;standard&quot;. How sparse do you
want u to be? This is the sum of absolute values of elements of u. It must
be between 1 and the square root of the number of rows in data matrix. The
smaller it is, the sparser u will be.</p>
</td></tr>
<tr><td><code id="PMD_+3A_sumabsv">sumabsv</code></td>
<td>
<p>Used only if type is &quot;standard&quot;. How sparse do you want v to
be? This is the sum of absolute values of elements of v. It must be between
1 and square root of number of columns of data. The smaller it is, the
sparser v will be.</p>
</td></tr>
<tr><td><code id="PMD_+3A_lambda">lambda</code></td>
<td>
<p>Used only if type is &quot;ordered&quot;. This is the tuning parameter
for the fused lasso penalty on v, which takes the form $lambda ||v||<em>1 +
lambda |v_j - v</em>(j-1)|$. $lambda$ must be non-negative. If NULL, then it is
chosen adaptively from the data.</p>
</td></tr>
<tr><td><code id="PMD_+3A_niter">niter</code></td>
<td>
<p>How many iterations should be performed. It is best to run at
least 20 of so. Default is 20.</p>
</td></tr>
<tr><td><code id="PMD_+3A_k">K</code></td>
<td>
<p>The number of factors in the PMD to be returned; default is 1.</p>
</td></tr>
<tr><td><code id="PMD_+3A_v">v</code></td>
<td>
<p>The first right singular vector(s) of the data. (If missing data is
present, then the missing values are imputed before the singular vectors are
calculated.) v is used as the initial value for the iterative PMD algorithm.
If x is large, then this step can be time-consuming; therefore, if PMD is to
be run multiple times, then v should be computed once and saved.</p>
</td></tr>
<tr><td><code id="PMD_+3A_trace">trace</code></td>
<td>
<p>Print out progress as iterations are performed? Default is
TRUE.</p>
</td></tr>
<tr><td><code id="PMD_+3A_center">center</code></td>
<td>
<p>Subtract out mean of x? Default is TRUE.</p>
</td></tr>
<tr><td><code id="PMD_+3A_chrom">chrom</code></td>
<td>
<p>If type is &quot;ordered&quot;, then this gives the option to specify
that some columns of x (corresponding to CGH spots) are on different
chromosomes. Then v will be sparse, and smooth <em>within</em> each chromosome but
not <em>between</em> chromosomes. Length of chrom should equal number of columns of
x, and each entry in chrom should be a number corresponding to which
chromosome the CGH spot is on.</p>
</td></tr>
<tr><td><code id="PMD_+3A_rnames">rnames</code></td>
<td>
<p>An optional vector containing a name for each row of x.</p>
</td></tr>
<tr><td><code id="PMD_+3A_cnames">cnames</code></td>
<td>
<p>An optional vector containing a name for each column of x.</p>
</td></tr>
<tr><td><code id="PMD_+3A_upos">upos</code></td>
<td>
<p>Constrain the elements of u to be positive? TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="PMD_+3A_uneg">uneg</code></td>
<td>
<p>Constrain the elements of u to be negative? TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="PMD_+3A_vpos">vpos</code></td>
<td>
<p>Constrain the elements of v to be positive? TRUE or FALSE.
Cannot be used if type is &quot;ordered&quot;.</p>
</td></tr>
<tr><td><code id="PMD_+3A_vneg">vneg</code></td>
<td>
<p>Constrain the elements of v to be negative? TRUE or FALSE.
Cannot be used if type is &quot;ordered.&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The criterion for the PMD is as follows: we seek vectors $u$ and $v$ such
that $u'Xv$ is large, subject to $||u||_2=1, ||v||_2=1$ and additional
penalties on $u$ and $v$. These additional penalties are as follows: If type
is &quot;standard&quot;, then lasso ($L_1$) penalties (promoting sparsity) are placed
on u and v. If type is &quot;ordered&quot;, then lasso penalty is placed on u and a
fused lasso penalty (promoting sparsity and smoothness) is placed on v.
</p>
<p>If type is &quot;standard&quot;, then arguments sumabs OR sumabsu&amp;sumabsv are used. If
type is &quot;ordered&quot;, then sumabsu AND lambda are used. Sumabsu is the bound of
absolute value of elements of u. Sumabsv is bound of absolute value of
elements of v. If sumabs is given, then sumabsu is set to
sqrt(nrow(x))*sumabs and sumabsv is set to sqrt(ncol(x))*sumabs. $lambda$ is
the parameter for the fused lasso penalty on v when type is &quot;ordered&quot;:
$lambda(||v||<em>1 + sum_j |v_j - v</em>(j-1))$.
</p>


<h3>Value</h3>

<table>
<tr><td><code>u</code></td>
<td>
<p>u is output. If you asked for multiple factors then each
column of u is a factor. u has dimension nxK if you asked for K factors.</p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>v is output. If you asked for multiple factors then each column of
v is a factor. v has dimension pxK if you asked for K factors.</p>
</td></tr> <tr><td><code>d</code></td>
<td>
<p>d
is output. Computationally, $d=u'Xv$ where $u$ and $v$ are the sparse
factors output by the PMD function and $X$ is the data matrix input to the
PMD function. When K=1, the residuals of the rank-1 PMD are given by $X -
duv'$.</p>
</td></tr> <tr><td><code>v.init</code></td>
<td>
<p>The first right singular vector(s) of the data; these
are returned to save on computation time if PMD will be run again.</p>
</td></tr>
<tr><td><code>meanx</code></td>
<td>
<p>Mean of x that was subtracted out before PMD was performed.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009)
<em>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</em>, <em>Biostatistics, Gol 10 (3), 515-534, Jul 2009</em><br />
</p>


<h3>See Also</h3>

<p><a href="#topic+PMD.cv">PMD.cv</a>, <a href="#topic+SPC">SPC</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# Try PMD with L1 penalty on rows and columns: type="standard"
# A simple simulated example
set.seed(1)
# Our data is a rank-one matrix, plus noise. The underlying components
# contain 50 and 75 non-zero elements, respectively.
u &lt;- matrix(c(rnorm(50), rep(0,150)),
ncol=1)
v &lt;- matrix(c(rnorm(75),rep(0,225)), ncol=1)
x &lt;- u%*%t(v)+
matrix(rnorm(200*300),ncol=300)
# We can use cross-validation to try to find optimal value of sumabs
cv.out &lt;- PMD.cv(x, type="standard", sumabss=seq(0.1, 0.6, len=20))
print(cv.out)
plot(cv.out)
# The optimal value of sumabs is 0.4157, but we can get within one
# standard error of that CV error using sumabs=0.337, which corresponds to
# an average of 45.8 and 71.8 non-zero elements in each component - pretty
# close to the true model.
# We can fit the model corresponding to the lowest cross-validation error:
out &lt;- PMD(x, type="standard", sumabs=cv.out$bestsumabs, K=1, v=cv.out$v.init)
print(out)
par(mfrow=c(2,2))
par(mar=c(2,2,2,2))
plot(out$u[,1], main="Est. u")
plot(out$v[,1], main="Est. v")
plot(u, main="True u")
plot(v, main="True v")
# And if we want to control sumabsu and sumabsv separately, we can do
# that too. Let's get 2 components while we're at it:
out2 &lt;- PMD(x, type="standard",  K=2, sumabsu=6, sumabsv=8, v=out$v.init,
cnames=paste("v", sep=" ", 1:ncol(x)), rnames=paste("u", sep=" ", 1:nrow(x)))
print(out2)

# Now check out PMD with L1 penalty on rows and fused lasso penalty on
# columns: type="ordered". We'll use the Chin et al (2006) Cancer Cell
# data set; try "?breastdata" for more info.
## Not run: 
breastdata &lt;- download_breast_data()
with(breastdata, {
# dna contains CGH data and chrom contains chromosome of each CGH spot;
# nuc contains position of each CGH spot.
dna &lt;- t(dna) # Need samples on rows and CGH spots on columns
# First, look for shared regions of gain/loss on chromosome 1.
# Use cross-validation to choose tuning parameter value
par(mar=c(2,2,2,2))
ch1 = which(chrom == 1)
cv.out &lt;- PMD.cv(dna[, ch1],type="ordered",chrom=chrom[ch1],
nuc=nuc[ch1],
sumabsus=seq(1, sqrt(nrow(dna)), len=15))
print(cv.out)
plot(cv.out)
out &lt;- PMD(dna[,chrom==1],type="ordered",
sumabsu=cv.out$bestsumabsu,chrom=chrom[chrom==1],K=1,v=cv.out$v.init,
cnames=paste("Pos",sep="",
nuc[chrom==1]), rnames=paste("Sample", sep=" ", 1:nrow(dna)))
print(out, verbose=TRUE)
# Which samples actually have that region of gain/loss?
par(mfrow=c(3,1))
par(mar=c(2,2,2,2))
PlotCGH(dna[which.min(out$u[,1]),chrom==1],chrom=chrom[chrom==1],
main=paste(paste(paste("Sample ", sep="", which.min(out$u[,1])),
sep="; u=", round(min(out$u[,1]),3))),nuc=nuc[chrom==1])
PlotCGH(dna[88,chrom==1], chrom=chrom[chrom==1],
main=paste("Sample 88; u=", sep="", round(out$u[88,1],3)),
nuc=nuc[chrom==1])
PlotCGH(out$v[,1],chrom=chrom[chrom==1], main="V",nuc=nuc[chrom==1])
} )

## End(Not run)
</code></pre>

<hr>
<h2 id='PMD.cv'>Do tuning parameter selection for PMD via cross-validation</h2><span id='topic+PMD.cv'></span>

<h3>Description</h3>

<p>Performs cross-validation to select tuning parameters for rank-1 PMD, the
penalized matrix decomposition for a data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>PMD.cv(
  x,
  type = c("standard", "ordered"),
  sumabss = seq(0.1, 0.7, len = 10),
  sumabsus = NULL,
  lambda = NULL,
  nfolds = 5,
  niter = 5,
  v = NULL,
  chrom = NULL,
  nuc = NULL,
  trace = TRUE,
  center = TRUE,
  upos = FALSE,
  uneg = FALSE,
  vpos = FALSE,
  vneg = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="PMD.cv_+3A_x">x</code></td>
<td>
<p>Data matrix of dimension $n x p$, which can contain NA for missing
values.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_type">type</code></td>
<td>
<p>&quot;standard&quot; or &quot;ordered&quot;: Do we want v to simply be sparse, or
should it also be smooth? If the columns of x are ordered (e.g. CGH spots
along a chromosome) then choose &quot;ordered&quot;. Default is &quot;standard&quot;. If
&quot;standard&quot;, then the PMD function will make use of sumabs OR
sumabsu&amp;sumabsv. If &quot;ordered&quot;, then the function will make use of sumabsu
and lambda.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_sumabss">sumabss</code></td>
<td>
<p>Used only if type is &quot;standard&quot;. A vector of sumabs values to
be used. Sumabs is a measure of sparsity for u and v vectors, between 0 and
</p>

<ol>
<li><p> When sumabss is specified, and sumabsus and sumabsvs are NULL, then
sumabsus is set to $sqrt(n)*sumabss$ and sumabsvs is set at
$sqrt(p)*sumabss$. If sumabss is specified, then sumabsus and sumabsvs
should be NULL. Or if sumabsus and sumabsvs are specified, then sumabss
should be NULL.
</p>
</li></ol>
</td></tr>
<tr><td><code id="PMD.cv_+3A_sumabsus">sumabsus</code></td>
<td>
<p>Used only for type &quot;ordered&quot;. A vector of sumabsu values to
be used. Sumabsu measures sparseness of u - it is the sum of absolute values
of elements of u. Must be between 1 and sqrt(n).</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_lambda">lambda</code></td>
<td>
<p>Used only if type is &quot;ordered&quot;. This is the tuning parameter
for the fused lasso penalty on v, which takes the form $lambda ||v||<em>1 +
lambda |v_j - v</em>(j-1)|$. $lambda$ must be non-negative. If NULL, then it is
chosen adaptively from the data.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_nfolds">nfolds</code></td>
<td>
<p>How many cross-validation folds should be performed?  Default
is 5.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_niter">niter</code></td>
<td>
<p>How many iterations should be performed. For speed, only 5 are
performed by default.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_v">v</code></td>
<td>
<p>The first right singular vector(s) of the data. (If missing data is
present, then the missing values are imputed before the singular vectors are
calculated.) v is used as the initial value for the iterative PMD algorithm.
If x is large, then this step can be time-consuming; therefore, if PMD is to
be run multiple times, then v should be computed once and saved.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_chrom">chrom</code></td>
<td>
<p>If type is &quot;ordered&quot;, then this gives the option to specify
that some columns of x (corresponding to CGH spots) are on different
chromosomes. Then v will be sparse, and smooth <em>within</em> each chromosome but
not <em>between</em> chromosomes. Length of chrom should equal number of columns of
x, and each entry in chrom should be a number corresponding to which
chromosome the CGH spot is on.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_nuc">nuc</code></td>
<td>
<p>If type is &quot;ordered&quot;, can specify the nucleotide position of each
CGH spot (column of x), to be used in plotting. If NULL, then it is assumed
that CGH spots are equally spaced.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_trace">trace</code></td>
<td>
<p>Print out progress as iterations are performed? Default is
TRUE.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_center">center</code></td>
<td>
<p>Subtract out mean of x? Default is TRUE</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_upos">upos</code></td>
<td>
<p>Constrain the elements of u to be positive? TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_uneg">uneg</code></td>
<td>
<p>Constrain the elements of u to be negative? TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_vpos">vpos</code></td>
<td>
<p>Constrain the elements of v to be positive? TRUE or FALSE.
Cannot be used if type is &quot;ordered&quot;.</p>
</td></tr>
<tr><td><code id="PMD.cv_+3A_vneg">vneg</code></td>
<td>
<p>Constrain the elements of v to be negative? TRUE or FALSE.
Cannot be used if type is &quot;ordered.&quot;</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If type is &quot;standard&quot;, then lasso ($L_1$) penalties (promoting sparsity) are
placed on u and v. If type is &quot;ordered&quot;, then lasso penalty is placed on u
and a fused lasso penalty (promoting sparsity and smoothness) is placed on
v.
</p>
<p>Cross-validation of the rank-1 PMD is performed over sumabss (if type is
&quot;standard&quot;) or over sumabsus (if type is &quot;ordered&quot;). If type is &quot;ordered&quot;,
then lambda is chosen from the data without cross-validation.
</p>
<p>The cross-validation works as follows: Some percent of the elements of $x$
is removed at random from the data matrix. The PMD is performed for a range
of tuning parameter values on this partially-missing data matrix; then,
missing values are imputed using the decomposition obtained. The value of
the tuning parameter that results in the lowest sum of squared errors of the
missing values if &quot;best&quot;.
</p>
<p>To do cross-validation on the rank-2 PMD, first the rank-1 PMD should be
computed, and then this function should be performed on the residuals, given
by $x-udv'$.
</p>


<h3>Value</h3>

<table>
<tr><td><code>cv</code></td>
<td>
<p>Average sum of squared errors obtained over
cross-validation folds.</p>
</td></tr> <tr><td><code>cv.error</code></td>
<td>
<p>Standard error of average sum of
squared errors obtained over cross-validation folds.</p>
</td></tr> <tr><td><code>bestsumabs</code></td>
<td>
<p>If
type=&quot;standard&quot;, then value of sumabss resulting in smallest CV error is
returned.</p>
</td></tr> <tr><td><code>bestsumabsu</code></td>
<td>
<p>If type=&quot;ordered&quot;, then value of sumabsus
resulting in smallest CV error is returned.</p>
</td></tr> <tr><td><code>v.init</code></td>
<td>
<p>The first right
singular vector(s) of the data; these are returned to save on computation
time if PMD will be run again.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009)
<em>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</em>, <em>Biostatistics, Gol 10 (3), 515-534, Jul 2009</em><br />
</p>


<h3>See Also</h3>

<p><a href="#topic+PMD">PMD</a>, <a href="#topic+SPC">SPC</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See examples in PMD help file
</code></pre>

<hr>
<h2 id='SPC'>Perform sparse principal component analysis</h2><span id='topic+SPC'></span><span id='topic+print.SPC'></span>

<h3>Description</h3>

<p>Performs sparse principal components analysis by applying PMD to a data
matrix with lasso ($L_1$) penalty on the columns and no penalty on the rows.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SPC(
  x,
  sumabsv = 4,
  niter = 20,
  K = 1,
  orth = FALSE,
  trace = TRUE,
  v = NULL,
  center = TRUE,
  cnames = NULL,
  vpos = FALSE,
  vneg = FALSE,
  compute.pve = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SPC_+3A_x">x</code></td>
<td>
<p>Data matrix of dimension $n x p$, which can contain NA for missing
values. We are interested in finding sparse principal components of
dimension $p$.</p>
</td></tr>
<tr><td><code id="SPC_+3A_sumabsv">sumabsv</code></td>
<td>
<p>How sparse do you want v to be? This is the sum of absolute
values of elements of v. It must be between 1 and square root of number of
columns of data. The smaller it is, the sparser v will be.</p>
</td></tr>
<tr><td><code id="SPC_+3A_niter">niter</code></td>
<td>
<p>How many iterations should be performed. It is best to run at
least 20 of so. Default is 20.</p>
</td></tr>
<tr><td><code id="SPC_+3A_k">K</code></td>
<td>
<p>The number of factors in the PMD to be returned; default is 1.</p>
</td></tr>
<tr><td><code id="SPC_+3A_orth">orth</code></td>
<td>
<p>If TRUE, then use method of Section 3.2 of Witten, Tibshirani
and Hastie (2008) to obtain multiple sparse principal components. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="SPC_+3A_trace">trace</code></td>
<td>
<p>Print out progress as iterations are performed? Default is
TRUE.</p>
</td></tr>
<tr><td><code id="SPC_+3A_v">v</code></td>
<td>
<p>The first right singular vector(s) of the data. (If missing data is
present, then the missing values are imputed before the singular vectors are
calculated.) v is used as the initial value for the iterative PMD($L_1$,
$L_1$) algorithm. If x is large, then this step can be time-consuming;
therefore, if PMD is to be run multiple times, then v should be computed
once and saved.</p>
</td></tr>
<tr><td><code id="SPC_+3A_center">center</code></td>
<td>
<p>Subtract out mean of x? Default is TRUE</p>
</td></tr>
<tr><td><code id="SPC_+3A_cnames">cnames</code></td>
<td>
<p>An optional vector containing a name for each column.</p>
</td></tr>
<tr><td><code id="SPC_+3A_vpos">vpos</code></td>
<td>
<p>Constrain the elements of v to be positive? TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="SPC_+3A_vneg">vneg</code></td>
<td>
<p>Constrain the elements of v to be negative? TRUE or FALSE.</p>
</td></tr>
<tr><td><code id="SPC_+3A_compute.pve">compute.pve</code></td>
<td>
<p>Compute percent variance explained? Default TRUE. If not
needed, then choose FALSE to save time.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>PMD(x,sumabsu=sqrt(nrow(x)), sumabsv=3, K=1) and SPC(x,sumabsv=3, K=1) give
the same result, since the SPC method is simply PMD with an L1 penalty on
the columns and no penalty on the rows.
</p>
<p>In Witten, Tibshirani, and Hastie (2008), two methods are presented for
obtaining multiple factors for SPC. The methods are as follows:
</p>
<p>(1) If one has already obtained factors $k-1$ factors then oen can compute
residuals by subtracting out these factors. Then $u_k$ and $v_k$ can be
obtained by applying the SPC/PMD algorithm to the residuals.
</p>
<p>(2) One can require that $u_k$ be orthogonal to $u_i$'s with $i&lt;k$; the
method is slightly more complicated, and is explained in WT&amp;H(2008).
</p>
<p>Method 1 is performed by running SPC with option orth=FALSE (the default)
and Method 2 is performed using option orth=TRUE. Note that Methods 1 and 2
always give identical results for the first component, and often given quite
similar results for later components.
</p>


<h3>Value</h3>

<table>
<tr><td><code>u</code></td>
<td>
<p>u is output. If you asked for multiple factors then each
column of u is a factor. u has dimension nxK if you asked for K factors.</p>
</td></tr>
<tr><td><code>v</code></td>
<td>
<p>v is output. These are the sparse principal components. If you
asked for multiple factors then each column of v is a factor. v has
dimension pxK if you asked for K factors.</p>
</td></tr> <tr><td><code>d</code></td>
<td>
<p>d is output; it is the
diagonal of the matrix $D$ in the penalized matrix decomposition. In the
case of the rank-1 decomposition, it is given in the formulation
$||X-duv'||_F^2$ subject to $||u||_1 &lt;= sumabsu$, $||v||_1 &lt;= sumabsv$.
Computationally, $d=u'Xv$ where $u$ and $v$ are the sparse factors output by
the PMD function and $X$ is the data matrix input to the PMD function.</p>
</td></tr>
<tr><td><code>prop.var.explained</code></td>
<td>
<p>A vector containing the proportion of variance
explained by the first 1, 2, ..., K sparse principal components obtaineds.
Formula for proportion of variance explained is on page 20 of Shen &amp; Huang
(2008), Journal of Multivariate Analysis 99: 1015-1034.</p>
</td></tr> <tr><td><code>v.init</code></td>
<td>
<p>The
first right singular vector(s) of the data; these are returned to save on
computation time if PMD will be run again.</p>
</td></tr> <tr><td><code>meanx</code></td>
<td>
<p>Mean of x that was
subtracted out before SPC was performed.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009)
<em>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</em>, <em>Biostatistics, Gol 10 (3), 515-534, Jul 2009</em><br />
</p>


<h3>See Also</h3>

<p><a href="#topic+SPC.cv">SPC.cv</a>, <a href="#topic+PMD">PMD</a>, <a href="#topic+PMD.cv">PMD.cv</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# A simple simulated example
#NOT RUN
#set.seed(1)
#u &lt;- matrix(c(rnorm(50), rep(0,150)),ncol=1)
#v &lt;- matrix(c(rnorm(75),rep(0,225)), ncol=1)
#x &lt;- u%*%t(v)+matrix(rnorm(200*300),ncol=300)
## Perform Sparse PCA - that is, decompose a matrix w/o penalty on rows
## and w/ L1 penalty on columns
## First, we perform sparse PCA and get 4 components, but we do not
## require subsequent components to be orthogonal to previous components
#out &lt;- SPC(x,sumabsv=3, K=4)
#print(out,verbose=TRUE)
## We could have selected sumabsv by cross-validation, using function SPC.cv
## Now, we do sparse PCA using method in Section 3.2 of WT&amp;H(2008) for getting
## multiple components - that is, we require components to be orthogonal
#out.orth &lt;- SPC(x,sumabsv=3, K=4, orth=TRUE)
#print(out.orth,verbose=TRUE)
#par(mfrow=c(1,1))
#plot(out$u[,1], out.orth$u[,1], xlab="", ylab="")
## Note that the first components w/ and w/o orth option are identical,
## since the orth option only affects the way that subsequent components
## are found
#print(round(t(out$u)%*%out$u,4)) # not orthogonal
#print(round(t(out.orth$u)%*%out.orth$u,4)) # orthogonal
#
## Use SPC.cv to choose tuning parameters:
#cv.out &lt;- SPC.cv(x)
#print(cv.out)
#plot(cv.out)
#out &lt;- SPC(x, sumabsv=cv.out$bestsumabsv)
#print(out)
## or we could do
#out &lt;- SPC(x, sumabsv=cv.out$bestsumabsv1se)
#print(out)
#
#
</code></pre>

<hr>
<h2 id='SPC.cv'>Perform cross-validation on sparse principal component analysis</h2><span id='topic+SPC.cv'></span><span id='topic+plot.SPC.cv'></span><span id='topic+print.SPC.cv'></span>

<h3>Description</h3>

<p>Selects tuning parameter for the sparse principal component analysis method
of Witten, Tibshirani, and Hastie (2008), which involves applying PMD to a
data matrix with lasso ($L_1$) penalty on the columns and no penalty on the
rows. The tuning parameter controls the sum of absolute values - or $L_1$
norm - of the elements of the sparse principal component.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SPC.cv(
  x,
  sumabsvs = seq(1.2, 5, len = 10),
  nfolds = 5,
  niter = 5,
  v = NULL,
  trace = TRUE,
  orth = FALSE,
  center = TRUE,
  vpos = FALSE,
  vneg = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SPC.cv_+3A_x">x</code></td>
<td>
<p>Data matrix of dimension $n x p$, which can contain NA for missing
values. We are interested in finding sparse principal components of
dimension $p$.</p>
</td></tr>
<tr><td><code id="SPC.cv_+3A_sumabsvs">sumabsvs</code></td>
<td>
<p>Range of sumabsv values to be considered in
cross-validation. Sumabsv is the sum of absolute values of elements of v. It
must be between 1 and square root of number of columns of data. The smaller
it is, the sparser v will be.</p>
</td></tr>
<tr><td><code id="SPC.cv_+3A_nfolds">nfolds</code></td>
<td>
<p>Number of cross-validation folds performed.</p>
</td></tr>
<tr><td><code id="SPC.cv_+3A_niter">niter</code></td>
<td>
<p>How many iterations should be performed. By default, perform
only 5 for speed reasons.</p>
</td></tr>
<tr><td><code id="SPC.cv_+3A_v">v</code></td>
<td>
<p>The first right singular vector(s) of the data. (If missing data is
present, then the missing values are imputed before the singular vectors are
calculated.) v is used as the initial value for the iterative PMD($L_1$,
$L_1$) algorithm. If x is large, then this step can be time-consuming;
therefore, if PMD is to be run multiple times, then v should be computed
once and saved.</p>
</td></tr>
<tr><td><code id="SPC.cv_+3A_trace">trace</code></td>
<td>
<p>Print out progress as iterations are performed? Default is
TRUE.</p>
</td></tr>
<tr><td><code id="SPC.cv_+3A_orth">orth</code></td>
<td>
<p>If TRUE, then use method of Section 3.2 of Witten, Tibshirani
and Hastie (2008) to obtain multiple sparse principal components. Default is
FALSE.</p>
</td></tr>
<tr><td><code id="SPC.cv_+3A_center">center</code></td>
<td>
<p>Subtract out mean of x? Default is TRUE</p>
</td></tr>
<tr><td><code id="SPC.cv_+3A_vpos">vpos</code></td>
<td>
<p>Constrain elements of v to be positive? Default is FALSE.</p>
</td></tr>
<tr><td><code id="SPC.cv_+3A_vneg">vneg</code></td>
<td>
<p>Constrain elements of v to be negative? Default is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method only performs cross-validation for the first sparse principal
component. It does so by performing the following steps nfolds times: (1)
replace a fraction of the data with missing values, (2) perform SPC on this
new data matrix using a range of tuning parameter values, each time getting
a rank-1 approximationg $udv'$ where $v$ is sparse, (3) measure the mean
squared error of the rank-1 estimate of the missing values created in step
1.
</p>
<p>Then, the selected tuning parameter value is that which resulted in the
lowest average mean squared error in step 3.
</p>
<p>In order to perform cross-validation for the second sparse principal
component, apply this function to $X-udv'$ where $udv'$ are the output of
running SPC on the raw data $X$.
</p>


<h3>Value</h3>

<table>
<tr><td><code>cv</code></td>
<td>
<p>Average sum of squared errors that results for each tuning
parameter value.</p>
</td></tr> <tr><td><code>cv.error</code></td>
<td>
<p>Standard error of the average sum of
squared error that results for each tuning parameter value.</p>
</td></tr>
<tr><td><code>bestsumabsv</code></td>
<td>
<p>Value of sumabsv that resulted in lowest CV error.</p>
</td></tr>
<tr><td><code>nonzerovs</code></td>
<td>
<p>Average number of non-zero elements of v for each candidate
value of sumabsvs.</p>
</td></tr> <tr><td><code>v.init</code></td>
<td>
<p>Initial value of v that was passed in. Or,
if that was NULL, then first right singular vector of X.</p>
</td></tr>
<tr><td><code>bestsumabsv1se</code></td>
<td>
<p>The smallest value of sumabsv that is within 1
standard error of smallest CV error.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Witten D. M., Tibshirani R.,  and Hastie, T. (2009)
<em>A penalized matrix decomposition, with applications to sparse principal components and canonical correlation analysis</em>, <em>Biostatistics, Gol 10 (3), 515-534, Jul 2009</em><br />
</p>


<h3>See Also</h3>

<p><a href="#topic+SPC">SPC</a>, <a href="#topic+PMD">PMD</a>, <a href="#topic+PMD.cv">PMD.cv</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
#NOT RUN
## A simple simulated example
#set.seed(1)
#u &lt;- matrix(c(rnorm(50), rep(0,150)),ncol=1)
#v &lt;- matrix(c(rnorm(75),rep(0,225)), ncol=1)
#x &lt;- u%*%t(v)+matrix(rnorm(200*300),ncol=300)
## Perform Sparse PCA - that is, decompose a matrix w/o penalty on rows
## and w/ L1 penalty on columns
## First, we perform sparse PCA and get 4 components, but we do not
## require subsequent components to be orthogonal to previous components
#cv.out &lt;- SPC.cv(x, sumabsvs=seq(1.2, sqrt(ncol(x)), len=6))
#print(cv.out)
#plot(cv.out)
#out &lt;- SPC(x,sumabsv=cv.out$bestsumabs, K=4) # could use
## cv.out$bestsumabvsv1se instead
#print(out,verbose=TRUE)
## Now, we do sparse PCA using method in Section 3.2 of WT&amp;H(2008) for getting
## multiple components - that is, we require components to be orthogonal
#cv.out &lt;- SPC.cv(x, sumabsvs=seq(1.2, sqrt(ncol(x)), len=6), orth=TRUE)
#print(cv.out)
#plot(cv.out)
#out.orth &lt;- SPC(x,sumabsv=cv.out$bestsumabsv, K=4, orth=TRUE)
#print(out.orth,verbose=TRUE)
#par(mfrow=c(1,1))
#plot(out$u[,1], out.orth$u[,1], xlab="", ylab="")
#
#
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
