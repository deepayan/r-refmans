<!DOCTYPE html><html><head><title>Help for package sfaR</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sfaR}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coef'><p>Extract coefficients of stochastic frontier models</p></a></li>
<li><a href='#dairynorway'><p>Data on Norwegian dairy farms</p></a></li>
<li><a href='#dairyspain'><p>Data on Spanish dairy farms</p></a></li>
<li><a href='#efficiencies'><p>Compute conditional (in-)efficiency estimates of stochastic frontier models</p></a></li>
<li><a href='#electricity'><p>Data on U.S. electric power generation</p></a></li>
<li><a href='#extract'><p>Extract frontier information to be used with <b>texreg</b> package</p></a></li>
<li><a href='#fitted'><p>Extract fitted values of stochastic frontier models</p></a></li>
<li><a href='#ic'><p>Extract information criteria of stochastic frontier models</p></a></li>
<li><a href='#logLik'><p>Extract log-likelihood value of stochastic frontier models</p></a></li>
<li><a href='#marginal'><p>Marginal effects of the inefficiency drivers in stochastic frontier models</p></a></li>
<li><a href='#nobs'><p>Extract total number of observations used in frontier models</p></a></li>
<li><a href='#residuals'><p>Extract residuals of stochastic frontier models</p></a></li>
<li><a href='#ricephil'><p>Data on rice production in the Philippines</p></a></li>
<li><a href='#sfacross'><p>Stochastic frontier estimation using cross-sectional data</p></a></li>
<li><a href='#sfalcmcross'><p>Latent class stochastic frontier using cross-sectional data</p></a></li>
<li><a href='#sfaR-deprecated'><p>Deprecated functions of sfaR</p></a></li>
<li><a href='#sfaR-package'><p>sfaR: A package for estimating stochastic frontier models</p></a></li>
<li><a href='#sfaselectioncross'><p>Sample selection in stochastic frontier estimation using cross-section data</p></a></li>
<li><a href='#skewnessTest'><p>Skewness test for stochastic frontier models</p></a></li>
<li><a href='#summary'><p>Summary of results for stochastic frontier models</p></a></li>
<li><a href='#swissrailways'><p>Data on Swiss railway companies</p></a></li>
<li><a href='#utility'><p>Data on U.S. electricity generating plants</p></a></li>
<li><a href='#vcov'><p>Compute variance-covariance matrix of stochastic frontier models</p></a></li>
<li><a href='#worldprod'><p>Data on world production</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Stochastic Frontier Analysis Routines</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Maximum likelihood estimation for stochastic frontier
    analysis (SFA) of production (profit) and cost functions. The package
    includes the basic stochastic frontier for cross-sectional or pooled
    data with several distributions for the one-sided error term (i.e.,
    Rayleigh, gamma, Weibull, lognormal, uniform, generalized exponential
    and truncated skewed Laplace), the latent class stochastic frontier
    model (LCM) as described in Dakpo et al. (2021)
    &lt;<a href="https://doi.org/10.1111%2F1477-9552.12422">doi:10.1111/1477-9552.12422</a>&gt;, for cross-sectional and pooled data,
    and the sample selection model as described in Greene (2010)
    &lt;<a href="https://doi.org/10.1007%2Fs11123-009-0159-1">doi:10.1007/s11123-009-0159-1</a>&gt;, and applied in Dakpo et al. (2021)
    &lt;<a href="https://doi.org/10.1111%2Fagec.12683">doi:10.1111/agec.12683</a>&gt;.  Several possibilities in terms of
    optimization algorithms are proposed.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/hdakpo/sfaR">https://github.com/hdakpo/sfaR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/hdakpo/sfaR/issues">https://github.com/hdakpo/sfaR/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cubature, fastGHQuad, Formula, marqLevAlg, maxLik, methods,
mnorm, nleqslv, plm, qrng, randtoolbox, sandwich, stats,
texreg, trustOptim, ucminf</td>
</tr>
<tr>
<td>Suggests:</td>
<td>lmtest</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-04 10:01:46 UTC; Dakpo</td>
</tr>
<tr>
<td>Author:</td>
<td>K Hervé Dakpo [aut, cre],
  Yann Desjeux [aut],
  Arne Henningsen [aut],
  Laure Latruffe [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>K Hervé Dakpo &lt;k-herve.dakpo@inrae.fr&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-04 11:30:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='coef'>Extract coefficients of stochastic frontier models</h2><span id='topic+coef'></span><span id='topic+coef.sfacross'></span><span id='topic+coef.summary.sfacross'></span><span id='topic+coef.sfalcmcross'></span><span id='topic+coef.summary.sfalcmcross'></span><span id='topic+coef.sfaselectioncross'></span><span id='topic+coef.summary.sfaselectioncross'></span>

<h3>Description</h3>

<p>From an object of class <code>'summary.sfacross'</code>,
<code>'summary.sfalcmcross'</code>, or <code>'summary.sfaselectioncross'</code>,
<code><a href="#topic+coef">coef</a></code> extracts the coefficients,
their standard errors, z-values, and (asymptotic) P-values.
</p>
<p>From on object of class <code>'sfacross'</code>, <code>'sfalcmcross'</code>, or
<code>'sfaselectioncross'</code>, it extracts only the estimated coefficients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
coef(object, extraPar = FALSE, ...)

## S3 method for class 'summary.sfacross'
coef(object, ...)

## S3 method for class 'sfalcmcross'
coef(object, extraPar = FALSE, ...)

## S3 method for class 'summary.sfalcmcross'
coef(object, ...)

## S3 method for class 'sfaselectioncross'
coef(object, extraPar = FALSE, ...)

## S3 method for class 'summary.sfaselectioncross'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef_+3A_object">object</code></td>
<td>
<p>A stochastic frontier model returned by <code><a href="#topic+sfacross">sfacross</a></code>,
<code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>, or an object
of class <code>'summary.sfacross'</code>, <code>'summary.sfalcmcross'</code>, or<br />
<code>'summary.sfaselectioncross'</code>.</p>
</td></tr>
<tr><td><code id="coef_+3A_extrapar">extraPar</code></td>
<td>
<p>Logical (default = <code>FALSE</code>). If <code>TRUE</code>, additional
parameters are returned:
</p>
<p><code>sigmaSq</code> = <code>sigmauSq</code> + <code>sigmavSq</code>
</p>
<p><code>lambdaSq</code> = <code>sigmauSq</code>/<code>sigmavSq</code>
</p>
<p><code>sigmauSq</code> = <code class="reqn">\exp{(Wu)}</code> = <code class="reqn">\exp{(\bm{\delta}' \mathbf{Z}_u)}</code>
</p>
<p><code>sigmavSq</code> = <code class="reqn">\exp{(Wv)}</code> = <code class="reqn">\exp{(\bm{\phi}' \mathbf{Z}_v)}</code>
</p>
<p><code>sigma</code> = <code>sigmaSq</code>^0.5
</p>
<p><code>lambda</code> = <code>lambdaSq</code>^0.5
</p>
<p><code>sigmau</code> = <code>sigmauSq</code>^0.5
</p>
<p><code>sigmav</code> = <code>sigmavSq</code>^0.5
</p>
<p><code>gamma</code> = <code>sigmauSq</code>/(<code>sigmauSq</code> + <code>sigmavSq</code>)</p>
</td></tr>
<tr><td><code id="coef_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For objects of class <code>'summary.sfacross'</code>,
<code>'summary.sfalcmcross'</code>, or <code>'summary.sfaselectioncross'</code>,
<code><a href="#topic+coef">coef</a></code> returns a matrix with four columns. Namely, the
estimated coefficients, their standard errors, z-values,
and (asymptotic) P-values.
</p>
<p>For objects of class <code>'sfacross'</code>, <code>'sfalcmcross'</code>, or
<code>'sfaselectioncross'</code>, <code><a href="#topic+coef">coef</a></code> returns a numeric vector of
the estimated coefficients. If <code>extraPar = TRUE</code>, additional parameters,
detailed in the section &lsquo;Arguments&rsquo;, are also returned. In the case
of object of class <code>'sfalcmcross'</code>, each additional
parameter ends with <code>'#'</code> that represents the class number.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional or pooled data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Using data on fossil fuel fired steam electric power generation plants in the U.S.
# Translog SFA (cost function) truncated normal with scaling property
tl_u_ts &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu, uhet = ~ regu, data = utility, S = -1,
scaling = TRUE, method = 'mla')
coef(tl_u_ts, extraPar = TRUE)
coef(summary(tl_u_ts))

## End(Not run)

</code></pre>

<hr>
<h2 id='dairynorway'>Data on Norwegian dairy farms</h2><span id='topic+dairynorway'></span>

<h3>Description</h3>

<p>This dataset contains nine years (1998-2006) of information on Norwegian dairy
farms.
</p>


<h3>Format</h3>

<p>A data frame with 2,727 observations on the following 23 variables.
</p>
 <dl>
<dt>farmid</dt><dd><p>Farm identification.</p>
</dd> <dt>year</dt><dd><p>Year
identification.</p>
</dd> <dt>y1</dt><dd><p>Milk sold (1000 liters).</p>
</dd> <dt>y2</dt><dd><p>Meat (1000 NOK).</p>
</dd>
<dt>y3</dt><dd><p>Support payments (1000 NOK).</p>
</dd> <dt>y4</dt><dd><p>Other outputs (1000 NOK).</p>
</dd>
<dt>p1</dt><dd><p>Milk price (NOK/liter).</p>
</dd> <dt>p2</dt><dd><p>Meat price (cattle index).</p>
</dd>
<dt>p3</dt><dd><p>Support payments price (CP index).</p>
</dd> <dt>p4</dt><dd><p>Other outputs price index.</p>
</dd>
<dt>x1</dt><dd><p>Land (decare (daa) = 0.1 ha).</p>
</dd> <dt>x2</dt><dd><p>Labour (1000 hours).</p>
</dd>
<dt>x3</dt><dd><p>Purchase feed (1000 NOK).</p>
</dd> <dt>x4</dt><dd><p>Other variable costs (1000 NOK).</p>
</dd>
<dt>x5</dt><dd><p>Cattle capital (1000 NOK).</p>
</dd> <dt>x6</dt><dd><p>Other capital (1000 NOK).</p>
</dd>
<dt>w1</dt><dd><p>Land price (NOK/daa).</p>
</dd> <dt>w2</dt><dd><p>Labour price (NOK/hour).</p>
</dd>
<dt>w3</dt><dd><p>Feed price index.</p>
</dd> <dt>w4</dt><dd><p>Other variable cost index.</p>
</dd>
<dt>w5</dt><dd><p>Cattle capital rent.</p>
</dd> <dt>w6</dt><dd><p>Other capital rent and depreciation.</p>
</dd>
<dt>tc</dt><dd><p>Total cost.</p>
</dd></dl>



<h3>Source</h3>

<p><a href="https://sites.google.com/site/sfbook2014/home/for-stata-v12-v13-v14">https://sites.google.com/site/sfbook2014/home/for-stata-v12-v13-v14</a>
</p>


<h3>References</h3>

<p>Kumbhakar, S.C., H.J. Wang, and A. Horncastle. 2014. <em>A
Practitioner's Guide to Stochastic Frontier Analysis Using Stata</em>. Cambridge
University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
str(dairynorway)
summary(dairynorway)
</code></pre>

<hr>
<h2 id='dairyspain'>Data on Spanish dairy farms</h2><span id='topic+dairyspain'></span>

<h3>Description</h3>

<p>This dataset contains six years of observations on 247 dairy farms in
northern Spain, drawn from 1993-1998. The original data consist in the farm
and year identifications, plus measurements on one output (i.e. milk), and
four inputs (i.e. cows, land, labor and feed).
</p>


<h3>Format</h3>

<p>A data frame with 1,482 observations on the following 29 variables.
</p>
 <dl>
<dt>FARM</dt><dd><p>Farm identification.</p>
</dd> <dt>AGEF</dt><dd><p>Age of the farmer.</p>
</dd>
<dt>YEAR</dt><dd><p>Year identification.</p>
</dd> <dt>COWS</dt><dd><p>Number of milking cows.</p>
</dd>
<dt>LAND</dt><dd><p>Agricultural area.</p>
</dd> <dt>MILK</dt><dd><p>Milk production.</p>
</dd>
<dt>LABOR</dt><dd><p>Labor.</p>
</dd> <dt>FEED</dt><dd><p>Feed.</p>
</dd> <dt>YIT</dt><dd><p>Log of <code>MILK</code>.</p>
</dd>
<dt>X1</dt><dd><p>Log of <code>COWS</code>.</p>
</dd> <dt>X2</dt><dd><p>Log of <code>LAND</code>.</p>
</dd> <dt>X3</dt><dd><p>Log
of <code>LABOR</code>.</p>
</dd> <dt>X4</dt><dd><p>Log of <code>FEED</code>.</p>
</dd> <dt>X11</dt><dd><p>1/2 *
<code>X1</code>^2.</p>
</dd> <dt>X22</dt><dd><p>1/2 * <code>X2</code>^2.</p>
</dd> <dt>X33</dt><dd><p>1/2 * <code>X3</code>^2.</p>
</dd>
<dt>X44</dt><dd><p>1/2 * <code>X4</code>^2.</p>
</dd> <dt>X12</dt><dd><p><code>X1</code> * <code>X2</code>.</p>
</dd>
<dt>X13</dt><dd><p><code>X1</code> * <code>X3</code>.</p>
</dd> <dt>X14</dt><dd><p><code>X1</code> * <code>X4</code>.</p>
</dd>
<dt>X23</dt><dd><p><code>X2</code> * <code>X3</code>.</p>
</dd> <dt>X24</dt><dd><p><code>X2</code> * <code>X4</code>.</p>
</dd>
<dt>X34</dt><dd><p><code>X3</code> * <code>X4</code>.</p>
</dd> <dt>YEAR93</dt><dd><p>Dummy for <code>YEAR =
1993</code>.</p>
</dd> <dt>YEAR94</dt><dd><p>Dummy for <code>YEAR = 1994</code>.</p>
</dd> <dt>YEAR95</dt><dd><p>Dummy for
<code>YEAR = 1995</code>.</p>
</dd> <dt>YEAR96</dt><dd><p>Dummy for <code>YEAR = 1996</code>.</p>
</dd>
<dt>YEAR97</dt><dd><p>Dummy for <code>YEAR = 1997</code>.</p>
</dd> <dt>YEAR98</dt><dd><p>Dummy for
<code>YEAR = 1998</code>.</p>
</dd> </dl>



<h3>Details</h3>

<p>This dataset has been used in Alvarez <em>et al.</em> (2004).  The data have
been normalized so that the logs of the inputs sum to zero over the 1,482
observations.
</p>


<h3>Source</h3>

<p><a href="http://pages.stern.nyu.edu/~wgreene/Econometrics/oldPanelDataSets.htm">http://pages.stern.nyu.edu/~wgreene/Econometrics/oldPanelDataSets.htm</a>
</p>


<h3>References</h3>

<p>Alvarez, A., C. Arias, and W. Greene. 2004. Accounting for
unobservables in production models: management and inefficiency.
<em>Econometric Society</em>, <b>341</b>:1&ndash;20.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
str(dairyspain)
summary(dairyspain)
</code></pre>

<hr>
<h2 id='efficiencies'>Compute conditional (in-)efficiency estimates of stochastic frontier models</h2><span id='topic+efficiencies'></span><span id='topic+efficiencies.sfacross'></span><span id='topic+efficiencies.sfalcmcross'></span><span id='topic+efficiencies.sfaselectioncross'></span>

<h3>Description</h3>

<p><code><a href="#topic+efficiencies">efficiencies</a></code> returns (in-)efficiency estimates of models
estimated with <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
efficiencies(object, level = 0.95, newData = NULL, ...)

## S3 method for class 'sfalcmcross'
efficiencies(object, level = 0.95, newData = NULL, ...)

## S3 method for class 'sfaselectioncross'
efficiencies(object, level = 0.95, newData = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="efficiencies_+3A_object">object</code></td>
<td>
<p>A stochastic frontier model returned
by <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.</p>
</td></tr>
<tr><td><code id="efficiencies_+3A_level">level</code></td>
<td>
<p>A number between between 0 and 0.9999 used for the computation
of (in-)efficiency confidence intervals (defaut = <code>0.95</code>). Only used
when <code>udist</code> = <code>'hnormal'</code>, <code>'exponential'</code>, <code>'tnormal'</code>
or <code>'uniform'</code> in <code><a href="#topic+sfacross">sfacross</a></code>.</p>
</td></tr>
<tr><td><code id="efficiencies_+3A_newdata">newData</code></td>
<td>
<p>Optional data frame that is used to calculate the efficiency
estimates. If NULL (the default), the efficiency estimates are calculated
for the observations that were used in the estimation. In the case of object of
class <code>sfaselectioncross</code></p>
</td></tr>
<tr><td><code id="efficiencies_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In general, the conditional inefficiency is obtained following
Jondrow <em>et al.</em> (1982) and the conditional efficiency is computed
following Battese and Coelli (1988). In some cases the conditional mode is
also returned (Jondrow <em>et al.</em> 1982). The confidence interval is
computed following Horrace and Schmidt (1996), Hjalmarsson <em>et al.</em>
(1996), or Berra and Sharma (1999) (see &lsquo;Value&rsquo; section).
</p>
<p>In the case of the half normal distribution for the one-sided error term,
the formulae are as follows (for notations, see the &lsquo;Details&rsquo; section
of <code><a href="#topic+sfacross">sfacross</a></code> or <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>):
</p>
 <ul>
<li><p> The conditional inefficiency is: </p>
</li></ul>

<p style="text-align: center;"><code class="reqn">E\left\lbrack u_i|\epsilon_i\right
\rbrack=\mu_{i\ast} + \sigma_\ast\frac{\phi
\left(\frac{\mu_{i\ast}}{\sigma_\ast}\right)}{
\Phi\left(\frac{\mu_{i\ast}}{\sigma_\ast}\right)}</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\mu_{i\ast}=\frac{-S\epsilon_i\sigma_u^2}{ \sigma_u^2 + \sigma_v^2}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\sigma_\ast^2 = \frac{\sigma_u^2 \sigma_v^2}{\sigma_u^2 + \sigma_v^2}</code>
</p>

 <ul>
<li><p> The Battese and Coelli (1988) conditional efficiency is
obtained with: </p>
</li></ul>

<p style="text-align: center;"><code class="reqn">E\left\lbrack\exp{\left(-u_i\right)}
|\epsilon_i\right\rbrack = \exp{\left(-\mu_{i\ast}+
\frac{1}{2}\sigma_\ast^2\right)}\frac{\Phi\left(
\frac{\mu_{i\ast}}{\sigma_\ast}-\sigma_\ast\right)}{
\Phi\left(\frac{\mu_{i\ast}}{\sigma_\ast}\right)}</code>
</p>

 <ul>
<li><p> The reciprocal of the Battese and Coelli (1988) conditional
efficiency is obtained with: </p>
</li></ul>

<p style="text-align: center;"><code class="reqn">E\left\lbrack\exp{\left(u_i\right)}
|\epsilon_i\right\rbrack = \exp{\left(\mu_{i\ast}+
\frac{1}{2}\sigma_\ast^2\right)} \frac{\Phi\left(
\frac{\mu_{i\ast}}{\sigma_\ast}+\sigma_\ast\right)}{
\Phi\left(\frac{\mu_{i\ast}}{\sigma_\ast}\right)}</code>
</p>

 <ul>
<li><p> The conditional mode is computed using: </p>
</li></ul>

<p style="text-align: center;"><code class="reqn">M\left\lbrack u_i|\epsilon_i\right
\rbrack= \mu_{i\ast} \quad \hbox{For} \quad 
\mu_{i\ast} &gt; 0</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">M\left\lbrack u_i|\epsilon_i\right
\rbrack= 0 \quad \hbox{For} \quad \mu_{i\ast} \leq 0</code>
</p>

 <ul>
<li><p> The confidence intervals are obtained with: </p>
</li></ul>

<p style="text-align: center;"><code class="reqn">\mu_{i\ast} + I_L\sigma_\ast \leq 
E\left\lbrack u_i|\epsilon_i\right\rbrack \leq 
\mu_{i\ast} + I_U\sigma_\ast </code>
</p>

<p>with <code class="reqn">LB_i = \mu_{i*} + I_L\sigma_*</code> and
<code class="reqn">UB_i = \mu_{i*} + I_U\sigma_*</code>
</p>
<p>and
</p>
<p style="text-align: center;"><code class="reqn">I_L = \Phi^{-1}\left\lbrace 1 -
\left(1-\frac{\alpha}{2}\right)\left\lbrack 1-
\Phi\left(-\frac{\mu_{i\ast}}{\sigma_\ast}\right)
\right\rbrack\right\rbrace </code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">I_U = \Phi^{-1}\left\lbrace 1-
\frac{\alpha}{2}\left\lbrack 1-\Phi
\left(-\frac{\mu_{i\ast}}{\sigma_\ast}\right)
\right\rbrack\right\rbrace</code>
</p>

<p>Thus
</p>
<p style="text-align: center;"><code class="reqn">\exp{\left(-UB_i\right)} \leq E\left
\lbrack\exp{\left(-u_i\right)}|\epsilon_i\right\rbrack 
\leq\exp{\left(-LB_i\right)}</code>
</p>

<p>In the case of the sample selection, as underlined in Greene (2010), the
conditional inefficiency could be computed using Jondrow <em>et al.</em> (1982).
However, here the conditionanl (in)efficiency is obtained using the properties
of the closed skew-normal (CSN) distribution (Lai, 2015). The conditional
efficiency can be obtained using the moment generating functions of a CSN
distribution (see Gonzalez-Farias <em>et al.</em> (2004)). We have:
</p>
<p style="text-align: center;"><code class="reqn">E\left\lbrack\exp{\left(tu_i\right)}
|\epsilon_i\right\rbrack = M_{u|\epsilon}(t)=\frac{\Phi_2\left(\tilde{\mathbf{D}}
\tilde{\bm{\Sigma}}t; \tilde{\bm{\kappa}}, \tilde{\bm{\Delta}} + 
\tilde{\mathbf{D}}\tilde{\bm{\Sigma}}\tilde{\mathbf{D}}' \right)}{
\Phi_2\left(\mathbf{0}; \tilde{\bm{\kappa}}, \tilde{\bm{\Delta}} + 
\tilde{\mathbf{D}}\tilde{\bm{\Sigma}}\tilde{\mathbf{D}}'\right)}\exp{
\left(t\tilde{\bm{\pi}} + \frac{1}{2}t^2\tilde{\bm{\Sigma}}\right)}</code>
</p>

<p>where <code class="reqn">\tilde{\bm{\pi}} = \frac{-S\epsilon_i\sigma_u^2}{\sigma_v^2 + \sigma_u^2}</code>,
<code class="reqn">\tilde{\bm{\Sigma}} = \frac{\sigma_v^2\sigma_u^2}{\sigma_v^2 + \sigma_u^2}</code>,
<code class="reqn">\tilde{\mathbf{D}} = \begin{pmatrix} \frac{S\rho}{\sigma_v} \\ 1 \end{pmatrix}</code>,
<code class="reqn">\tilde{\bm{\kappa}} = \begin{pmatrix} - \mathbf{Z}'_{si}\bm{\gamma} - 
\frac{\rho\sigma_v\epsilon_i}{\sigma_v^2 + \sigma_u^2}\\ 
\frac{S\sigma_u^2\epsilon_i}{\sigma_v^2 + \sigma_u^2} \end{pmatrix}</code>,
<code class="reqn">\tilde{\bm{\Delta}} = \begin{pmatrix}1-\rho^2 &amp; 0 \\ 0 &amp; 0\end{pmatrix}</code>.
</p>
<p>The derivation of the efficiency and the reciprocal efficiency is obtained by replacing
<code class="reqn">t = -1</code> and <code class="reqn">t =1</code>, respectively. To obtain the inefficiency as
<code class="reqn">E\left[u_i|\epsilon_i\right]</code> is more complicated as it requires the
derivation of a multivariate normal cdf. We have:
</p>
<p style="text-align: center;"><code class="reqn">E\left[u_i|\epsilon_i\right] = \left. \frac{\partial M_{u|\epsilon}(t)}{\partial t}\right\rvert_{t = 0}</code>
</p>

<p>Then
</p>
<p style="text-align: center;"><code class="reqn">E\left[u_i|\epsilon_i\right] = \tilde{\bm{\pi}} + 
\left(\tilde{\mathbf{D}}\tilde{\bm{\Sigma}}\right)'\frac{\Phi_2^*
\left(\mathbf{0}; \tilde{\bm{\kappa}}, \ddot{\bm{\Delta}}\right)}{
\Phi_2\left(\mathbf{0}; \tilde{\bm{\kappa}}, \ddot{\bm{\Delta}}\right)}</code>
</p>

<p>where <code class="reqn">\Phi_2^* \left(\mathbf{s}; \tilde{\bm{\kappa}}, \ddot{\bm{\Delta}}\right)=
\frac{\partial \Phi_2\left(\mathbf{s}; \tilde{\bm{\kappa}}, \ddot{\bm{\Delta}} \right)}{\partial \mathbf{s}}</code>
</p>


<h3>Value</h3>

<p>A data frame that contains individual (in-)efficiency estimates.
These are ordered in the same way as the corresponding observations in the
dataset used for the estimation.
</p>
<p><b>- For object of class <code>'sfacross'</code> the following elements are returned:</b>
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>Conditional inefficiency. In the case argument <code>udist</code> of
<a href="#topic+sfacross">sfacross</a> is set to <code>'uniform'</code>, two conditional inefficiency
estimates are returned: <code>u1</code> for the classic conditional inefficiency
following Jondrow <em>et al.</em> (1982), and <code>u2</code> which is obtained when
<code class="reqn">\theta/\sigma_v \longrightarrow \infty</code> (see Nguyen, 2010).</p>
</td></tr>
<tr><td><code>uLB</code></td>
<td>
<p>Lower bound for conditional inefficiency. Only when the argument
<code>udist</code> of <a href="#topic+sfacross">sfacross</a> is set to <code>'hnormal'</code>,
<code>'exponential'</code>, <code>'tnormal'</code> or <code>'uniform'</code>.</p>
</td></tr>
<tr><td><code>uUB</code></td>
<td>
<p>Upper bound for conditional inefficiency. Only when the argument
<code>udist</code> of <a href="#topic+sfacross">sfacross</a> is set to <code>'hnormal'</code>,
<code>'exponential'</code>, <code>'tnormal'</code> or <code>'uniform'</code>.</p>
</td></tr>
<tr><td><code>teJLMS</code></td>
<td>
<p><code class="reqn">\exp{(-E[u|\epsilon])}</code>. When the argument <code>udist</code> of
<a href="#topic+sfacross">sfacross</a> is set to <code>'uniform'</code>, <code>teJLMS1</code> =
<code class="reqn">\exp{(-E[u_1|\epsilon])}</code> and <code>teJLMS2</code> =
<code class="reqn">\exp{(-E[u_2|\epsilon])}</code>. Only when <code>logDepVar = TRUE</code>.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>Conditional model. Only when the argument <code>udist</code> of
<a href="#topic+sfacross">sfacross</a> is set to <code>'hnormal'</code>, <code>'exponential'</code>,
<code>'tnormal'</code>, or <code>'rayleigh'</code>.</p>
</td></tr>
<tr><td><code>teMO</code></td>
<td>
<p><code class="reqn">\exp{(-m)}</code>. Only when, in the function <a href="#topic+sfacross">sfacross</a>,
<code>logDepVar = TRUE</code> and <code>udist = 'hnormal'</code>, <code>'exponential'</code>,
<code>'tnormal'</code>, <code>'uniform'</code>, or <code>'rayleigh'</code>.</p>
</td></tr>
<tr><td><code>teBC</code></td>
<td>
<p>Battese and Coelli (1988) conditional efficiency. Only when, in
the function <a href="#topic+sfacross">sfacross</a>,  <code>logDepVar = TRUE</code>.
In the case <code>udist = 'uniform'</code>, two
conditional efficiency estimates are returned:
<code>teBC1</code> which is the classic conditional efficiency following
Battese and Coelli (1988) and <code>teBC2</code> when
<code class="reqn">\theta/\sigma_v \longrightarrow \infty</code> (see Nguyen, 2010).</p>
</td></tr>
<tr><td><code>teBC_reciprocal</code></td>
<td>
<p>Reciprocal of Battese and Coelli (1988) conditional
efficiency. Similar to <code>teBC</code> except that it is computed as
<code class="reqn">E\left[\exp{(u)}|\epsilon\right]</code>.</p>
</td></tr>
<tr><td><code>teBCLB</code></td>
<td>
<p>Lower bound for Battese and Coelli (1988) conditional
efficiency. Only when, in the function <a href="#topic+sfacross">sfacross</a>, <code>logDepVar = TRUE</code> and
<code>udist = 'hnormal'</code>, <code>'exponential'</code>, <code>'tnormal'</code>,
or <code>'uniform'</code>.</p>
</td></tr>
<tr><td><code>teBCUB</code></td>
<td>
<p>Upper bound for Battese and Coelli (1988) conditional
efficiency. Only when, in the function <a href="#topic+sfacross">sfacross</a>, <code>logDepVar = TRUE</code> and
<code>udist = 'hnormal'</code>, <code>'exponential'</code>, <code>'tnormal'</code>,
or <code>'uniform'</code>.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>In the case <code>udist = 'uniform'</code>. <code class="reqn">u \in [0, \theta]</code>.</p>
</td></tr>
</table>
<p><b>- For object of class <code>'sfalcmcross'</code> the following elements are returned:</b>
</p>
<table>
<tr><td><code>Group_c</code></td>
<td>
<p>Most probable class for each observation.</p>
</td></tr>
<tr><td><code>PosteriorProb_c</code></td>
<td>
<p>Highest posterior probability.</p>
</td></tr>
<tr><td><code>u_c</code></td>
<td>
<p>Conditional inefficiency of the most probable class given the
posterior probability.</p>
</td></tr>
<tr><td><code>teJLMS_c</code></td>
<td>
<p><code class="reqn">\exp{(-E[u_c|\epsilon_c])}</code>. Only when, in the function
<a href="#topic+sfalcmcross">sfalcmcross</a> <code>logDepVar = TRUE</code>.</p>
</td></tr>
<tr><td><code>teBC_c</code></td>
<td>
<p><code class="reqn">E\left[\exp{(-u_c)}|\epsilon_c\right]</code>. Only when, in the
function <a href="#topic+sfalcmcross">sfalcmcross</a> <code>logDepVar = TRUE</code>.</p>
</td></tr>
<tr><td><code>teBC_reciprocal_c</code></td>
<td>
<p><code class="reqn">E\left[\exp{(u_c)}|\epsilon_c\right]</code>. Only
when, in the function <a href="#topic+sfalcmcross">sfalcmcross</a> <code>logDepVar = TRUE</code>.</p>
</td></tr>
<tr><td><code>PosteriorProb_c#</code></td>
<td>
<p>Posterior probability of class #.</p>
</td></tr>
<tr><td><code>PriorProb_c#</code></td>
<td>
<p>Prior probability of class #.</p>
</td></tr>
<tr><td><code>u_c#</code></td>
<td>
<p>Conditional inefficiency associated to class #, regardless of
<code>Group_c</code>.</p>
</td></tr>
<tr><td><code>teBC_c#</code></td>
<td>
<p>Conditional efficiency
(<code class="reqn">E\left[\exp{(-u_c)}|\epsilon_c\right]</code>) associated to class #,
regardless of <code>Group_c</code>. Only when, in the function
<a href="#topic+sfalcmcross">sfalcmcross</a> <code>logDepVar = TRUE</code>.</p>
</td></tr>
<tr><td><code>teBC_reciprocal_c#</code></td>
<td>
<p>Reciprocal conditional efficiency
(<code class="reqn">E\left[\exp{(u_c)}|\epsilon_c\right]</code>) associated to class #,
regardless of <code>Group_c</code>. Only when, in the function
<a href="#topic+sfalcmcross">sfalcmcross</a> <code>logDepVar = TRUE</code>.</p>
</td></tr>
<tr><td><code>ineff_c#</code></td>
<td>
<p>Conditional inefficiency (<code>u_c</code>) for observations in
class # only.</p>
</td></tr>
<tr><td><code>effBC_c#</code></td>
<td>
<p>Conditional efficiency (<code>teBC_c</code>) for observations in
class # only.</p>
</td></tr>
<tr><td><code>ReffBC_c#</code></td>
<td>
<p>Reciprocal conditional efficiency (<code>teBC_reciprocal_c</code>)
for observations in class # only.</p>
</td></tr>
<tr><td><code>theta_c#</code></td>
<td>
<p>In the case <code>udist = 'uniform'</code>. <code class="reqn">u \in [0, \theta_{c\#}]</code>.</p>
</td></tr>
</table>
<p><b>- For object of class <code>'sfaselectioncross'</code> the following elements are returned:</b>
</p>
<table>
<tr><td><code>u</code></td>
<td>
<p>Conditional inefficiency.</p>
</td></tr>
<tr><td><code>teJLMS</code></td>
<td>
<p><code class="reqn">\exp{(-E[u|\epsilon])}</code>. Only when <code>logDepVar = TRUE</code>.</p>
</td></tr>
<tr><td><code>teBC</code></td>
<td>
<p>Battese and Coelli (1988) conditional efficiency. Only when, in
the function <a href="#topic+sfaselectioncross">sfaselectioncross</a>,
<code>logDepVar = TRUE</code>.</p>
</td></tr>
<tr><td><code>teBC_reciprocal</code></td>
<td>
<p>Reciprocal of Battese and Coelli (1988) conditional
efficiency. Similar to <code>teBC</code> except that it is computed as
<code class="reqn">E\left[\exp{(u)}|\epsilon\right]</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Battese, G.E., and T.J. Coelli. 1988. Prediction of firm-level
technical efficiencies with a generalized frontier production function and
panel data. <em>Journal of Econometrics</em>, <b>38</b>:387&ndash;399.
</p>
<p>Bera, A.K., and S.C. Sharma. 1999. Estimating production uncertainty in
stochastic frontier production function models. <em>Journal of
Productivity Analysis</em>, <b>12</b>:187-210.
</p>
<p>Gonzalez-Farias, G., Dominguez-Molina, A., Gupta, A. K., 2004. Additive
properties of skew normal random vectors.
<em>Journal of Statistical Planning and Inference</em>. <b>126</b>: 521-534.
</p>
<p>Greene, W., 2010. A stochastic frontier model with correction
for sample selection. <em>Journal of Productivity Analysis</em>. <b>34</b>, 15&ndash;24.
</p>
<p>Hjalmarsson, L., S.C. Kumbhakar, and A. Heshmati. 1996. DEA, DFA and SFA: A
comparison. <em>Journal of Productivity Analysis</em>, <b>7</b>:303-327.
</p>
<p>Horrace, W.C., and P. Schmidt. 1996. Confidence statements for efficiency
estimates from stochastic frontier models. <em>Journal of Productivity
Analysis</em>, <b>7</b>:257-282.
</p>
<p>Jondrow, J., C.A.K. Lovell, I.S. Materov, and P. Schmidt. 1982. On the
estimation of technical inefficiency in the stochastic frontier production
function model. <em>Journal of Econometrics</em>, <b>19</b>:233&ndash;238.
</p>
<p>Lai, H. P., 2015. Maximum likelihood estimation of the stochastic frontier
model with endogenous switching or sample selection.
<em>Journal of Productivity Analysis</em>, <b>43</b>: 105-117.
</p>
<p>Nguyen, N.B. 2010. Estimation of technical efficiency in stochastic frontier
analysis. PhD Dissertation, Bowling Green State University, August.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional or pooled data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Using data on fossil fuel fired steam electric power generation plants in the U.S.
# Translog SFA (cost function) truncated normal with scaling property
tl_u_ts &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) + log(wl/wf) +
log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) + I(log(wl/wf) *
log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)), udist = 'tnormal',
muhet = ~ regu, uhet = ~ regu, data = utility, S = -1, scaling = TRUE, method = 'mla')
eff.tl_u_ts &lt;- efficiencies(tl_u_ts)
head(eff.tl_u_ts)
summary(eff.tl_u_ts)

## End(Not run)

</code></pre>

<hr>
<h2 id='electricity'>Data on U.S. electric power generation</h2><span id='topic+electricity'></span>

<h3>Description</h3>

<p>This dataset is on electric power generation in the United States.
</p>


<h3>Format</h3>

<p>A data frame with 123 observations on the following 9 variables.
</p>
 <dl>
<dt>firm</dt><dd><p>Firm identification.</p>
</dd> <dt>cost</dt><dd><p>Total cost in 1970,
MM USD.</p>
</dd> <dt>output</dt><dd><p>Output in million KwH.</p>
</dd> <dt>lprice</dt><dd><p>Labor price.</p>
</dd>
<dt>lshare</dt><dd><p>Labor's cost share.</p>
</dd> <dt>cprice</dt><dd><p>Capital price.</p>
</dd>
<dt>cshare</dt><dd><p>Capital's cost share.</p>
</dd> <dt>fprice</dt><dd><p>Fuel price.</p>
</dd>
<dt>fshare</dt><dd><p>Fuel's cost share.</p>
</dd> </dl>



<h3>Details</h3>

<p>The dataset is from Christensen and Greene (1976) and has also been used in
Greene (1990).
</p>


<h3>Source</h3>

<p><a href="http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm">http://pages.stern.nyu.edu/~wgreene/Text/tables/tablelist5.htm</a>
</p>


<h3>References</h3>

<p>Christensen, L.R., and W.H. Greene. 1976. Economies of scale in
US electric power generation. <em>The Journal of Political Economy</em>,
<b>84</b>:655&ndash;676.
</p>
<p>Greene, W.H. 1990. A Gamma-distributed stochastic frontier model.
<em>Journal of Econometrics</em>, <b>46</b>:141&ndash;163.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
str(electricity)
summary(electricity)
</code></pre>

<hr>
<h2 id='extract'>Extract frontier information to be used with <b>texreg</b> package</h2><span id='topic+extract'></span><span id='topic+extract.sfacross'></span><span id='topic+extract.sfalcmcross'></span><span id='topic+extract.sfaselectioncross'></span>

<h3>Description</h3>

<p>Extract coefficients and additional information for stochastic frontier models
returned by <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract.sfacross(model, ...)

extract.sfalcmcross(model, ...)

extract.sfaselectioncross(model, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_+3A_model">model</code></td>
<td>
<p>objects of class <code>'sfacross'</code>, <code>'sfalcmcross'</code>, or
<code>'sfaselectioncross'</code></p>
</td></tr>
<tr><td><code id="extract_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A texreg object representing the statistical model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
hlf &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) + 
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'hnormal', uhet = ~ regu, data = utility, S = -1, method = 'bfgs')
trnorm &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) + 
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu, data = utility, S = -1, method = 'bfgs')

tscal &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu, uhet = ~ regu, data = utility, 
S = -1, method = 'bfgs', scaling = TRUE)

expo &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'exponential', uhet = ~ regu, data = utility, S = -1, method = 'bfgs')

texreg::screenreg(list(hlf, trnorm, tscal, expo))

</code></pre>

<hr>
<h2 id='fitted'>Extract fitted values of stochastic frontier models</h2><span id='topic+fitted'></span><span id='topic+fitted.sfacross'></span><span id='topic+fitted.sfalcmcross'></span><span id='topic+fitted.sfaselectioncross'></span>

<h3>Description</h3>

<p><code><a href="#topic+fitted">fitted</a></code> returns the fitted frontier values from stochastic
frontier models estimated with <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>,
or <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
fitted(object, ...)

## S3 method for class 'sfalcmcross'
fitted(object, ...)

## S3 method for class 'sfaselectioncross'
fitted(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fitted_+3A_object">object</code></td>
<td>
<p>A stochastic frontier model returned
by <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.</p>
</td></tr>
<tr><td><code id="fitted_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>In the case of an object of class <code>'sfacross'</code>, or
<code>'sfaselectioncross'</code>, a vector of fitted values is returned.
</p>
<p>In the case of an object of class <code>'sfalcmcross'</code>, a data frame
containing the fitted values for each class is returned where each variable
ends with <code>'_c#'</code>, <code>'#'</code> being the class number.
</p>


<h3>Note</h3>

<p>The fitted values are ordered in the same way as the corresponding
observations in the dataset used for the estimation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional or pooled data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Using data on eighty-two countries production (GDP)
# LCM Cobb Douglas (production function) half normal distribution
cb_2c_h &lt;- sfalcmcross(formula = ly ~ lk + ll + yr, udist = 'hnormal', 
data = worldprod)
fit.cb_2c_h &lt;- fitted(cb_2c_h)
head(fit.cb_2c_h)

## End(Not run)

</code></pre>

<hr>
<h2 id='ic'>Extract information criteria of stochastic frontier models</h2><span id='topic+ic'></span><span id='topic+ic.sfacross'></span><span id='topic+ic.sfalcmcross'></span><span id='topic+ic.sfaselectioncross'></span>

<h3>Description</h3>

<p><code><a href="#topic+ic">ic</a></code> returns information criterion from stochastic
frontier models estimated with <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>,
or <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
ic(object, IC = "AIC", ...)

## S3 method for class 'sfalcmcross'
ic(object, IC = "AIC", ...)

## S3 method for class 'sfaselectioncross'
ic(object, IC = "AIC", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ic_+3A_object">object</code></td>
<td>
<p>A stochastic frontier model returned
by <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.</p>
</td></tr>
<tr><td><code id="ic_+3A_ic">IC</code></td>
<td>
<p>Character string. Information criterion measure. Three criteria
are available: </p>
 <ul>
<li> <p><code>'AIC'</code> for Akaike information criterion
(default) </p>
</li>
<li> <p><code>'BIC'</code> for Bayesian information criterion </p>
</li>
<li>
<p><code>'HQIC'</code> for Hannan-Quinn information criterion </p>
</li></ul>
<p>.</p>
</td></tr>
<tr><td><code id="ic_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The different information criteria are computed as follows: </p>
 <ul>
<li>
<p>AIC: <code class="reqn">-2 \log{LL} + 2 * K</code> </p>
</li>
<li><p> BIC: <code class="reqn">-2 \log{LL} + \log{N} * K</code>
</p>
</li>
<li><p> HQIC: <code class="reqn">-2 \log{LL} + 2 \log{\left[\log{N}\right]} * K</code> </p>
</li></ul>
<p> where
<code class="reqn">LL</code> is the maximum likelihood value, <code class="reqn">K</code> the number of parameters
estimated and <code class="reqn">N</code> the number of observations.
</p>


<h3>Value</h3>

<p><code><a href="#topic+ic">ic</a></code> returns the value of the information criterion
(AIC, BIC or HQIC) of the maximum likelihood coefficients.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional or pooled data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Using data on Swiss railway
# LCM (cost function) half normal distribution
cb_2c_u &lt;- sfalcmcross(formula = LNCT ~ LNQ2 + LNQ3 + LNNET + LNPK + LNPL,
udist = 'hnormal', uhet = ~ 1, data = swissrailways, S = -1, method='ucminf')
ic(cb_2c_u)
ic(cb_2c_u, IC = 'BIC')
ic(cb_2c_u, IC = 'HQIC')

## End(Not run)

</code></pre>

<hr>
<h2 id='logLik'>Extract log-likelihood value of stochastic frontier models</h2><span id='topic+logLik'></span><span id='topic+logLik.sfacross'></span><span id='topic+logLik.sfalcmcross'></span><span id='topic+logLik.sfaselectioncross'></span>

<h3>Description</h3>

<p><code><a href="#topic+logLik">logLik</a></code> extracts the log-likelihood value(s) from stochastic
frontier models estimated with <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>,
or <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
logLik(object, individual = FALSE, ...)

## S3 method for class 'sfalcmcross'
logLik(object, individual = FALSE, ...)

## S3 method for class 'sfaselectioncross'
logLik(object, individual = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logLik_+3A_object">object</code></td>
<td>
<p>A stochastic frontier model returned
by <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.</p>
</td></tr>
<tr><td><code id="logLik_+3A_individual">individual</code></td>
<td>
<p>Logical. If <code>FALSE</code> (default), the sum of all
observations' log-likelihood values is returned. If <code>TRUE</code>, a vector of
each observation's log-likelihood value is returned.</p>
</td></tr>
<tr><td><code id="logLik_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+logLik">logLik</a></code> returns either an object of class
<code>'logLik'</code>, which is the log-likelihood value with the total number of
observations (<code>nobs</code>) and the number of free parameters (<code>df</code>) as
attributes, when <code>individual = FALSE</code>, or a list of elements, containing
the log-likelihood of each observation (<code>logLik</code>), the total number of
observations (<code>Nobs</code>) and the number of free parameters (<code>df</code>),
when <code>individual = TRUE</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional or pooled data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Using data on fossil fuel fired steam electric power generation plants in the U.S.
# Translog SFA (cost function) truncated normal with scaling property
tl_u_ts &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu, uhet = ~ regu, data = utility, S = -1,
scaling = TRUE, method = 'mla')
logLik(tl_u_ts)

## Using data on eighty-two countries production (GDP)
# LCM Cobb Douglas (production function) half normal distribution
cb_2c_h &lt;- sfalcmcross(formula = ly ~ lk + ll + yr, udist = 'hnormal', 
data = worldprod, S = 1)
logLik(cb_2c_h, individual = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='marginal'>Marginal effects of the inefficiency drivers in stochastic frontier models</h2><span id='topic+marginal'></span><span id='topic+marginal.sfacross'></span><span id='topic+marginal.sfalcmcross'></span><span id='topic+marginal.sfaselectioncross'></span>

<h3>Description</h3>

<p>This function returns marginal effects of the inefficiency drivers from stochastic
frontier models estimated with <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>,
or <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
marginal(object, newData = NULL, ...)

## S3 method for class 'sfalcmcross'
marginal(object, newData = NULL, ...)

## S3 method for class 'sfaselectioncross'
marginal(object, newData = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="marginal_+3A_object">object</code></td>
<td>
<p>A stochastic frontier model returned
by <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.</p>
</td></tr>
<tr><td><code id="marginal_+3A_newdata">newData</code></td>
<td>
<p>Optional data frame that is used to calculate the marginal
effect of <code class="reqn">Z</code> variables on inefficiency. If NULL (the default), the
marginal estimates are calculated for the observations that were used in the
estimation.</p>
</td></tr>
<tr><td><code id="marginal_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+marginal">marginal</a></code> operates in the presence of exogenous
variables that explain inefficiency, namely the inefficiency drivers
(<code class="reqn">uhet = ~ Z_u</code> or <code class="reqn">muhet = ~ Z_{mu}</code>).
</p>
<p>Two components are computed for each variable: the marginal effects on the
expected inefficiency (<code class="reqn">\frac{\partial E[u]}{\partial Z_{mu}}</code>) and
the marginal effects on the variance of inefficiency (<code class="reqn">\frac{\partial
V[u]}{\partial Z_{mu}}</code>).
</p>
<p>The model also allows the Wang (2002) parametrization of <code class="reqn">\mu</code> and
<code class="reqn">\sigma_u^2</code> by the same vector of exogenous variables. This double
parameterization accounts for non-monotonic relationships between the
inefficiency and its drivers.
</p>


<h3>Value</h3>

<p><code><a href="#topic+marginal">marginal</a></code> returns a data frame containing the marginal
effects of the <code class="reqn">Z_u</code> variables on the expected inefficiency (each
variable has the prefix <code>'Eu_'</code>) and on the variance of the
inefficiency (each variable has the prefix <code>'Vu_'</code>).
</p>
<p>In the case of the latent class stochastic frontier (LCM), each variable
ends with <code>'_c#'</code> where <code>'#'</code> is the class number.
</p>


<h3>References</h3>

<p>Wang, H.J. 2002. Heteroscedasticity and non-monotonic efficiency
effects of a stochastic frontier model. <em>Journal of Productivity
Analysis</em>, <b>18</b>:241&ndash;253.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional or pooled data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Using data on fossil fuel fired steam electric power generation plants in the U.S.
# Translog SFA (cost function) truncated normal with scaling property
tl_u_ts &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu + wl, uhet = ~ regu + wl, data = utility, 
S = -1, scaling = TRUE, method = 'mla')
marg.tl_u_ts &lt;- marginal(tl_u_ts)
summary(marg.tl_u_ts)

## Using data on eighty-two countries production (GDP)
# LCM Cobb Douglas (production function) half normal distribution
cb_2c_h &lt;- sfalcmcross(formula = ly ~ lk + ll + yr, udist = 'hnormal',
    data = worldprod, uhet = ~ initStat + h, S = 1, method = 'mla')
  marg.cb_2c_h &lt;- marginal(cb_2c_h)
  summary(marg.cb_2c_h)
  
## End(Not run)

</code></pre>

<hr>
<h2 id='nobs'>Extract total number of observations used in frontier models</h2><span id='topic+nobs'></span><span id='topic+nobs.sfacross'></span><span id='topic+nobs.sfalcmcross'></span><span id='topic+nobs.sfaselectioncross'></span>

<h3>Description</h3>

<p>This function extracts the total number of 'observations' from a
fitted frontier model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
nobs(object, ...)

## S3 method for class 'sfalcmcross'
nobs(object, ...)

## S3 method for class 'sfaselectioncross'
nobs(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nobs_+3A_object">object</code></td>
<td>
<p>a <code>sfacross</code>, <code>sfalcmcross</code>, or <code>sfaselectioncross</code>
object for which the number of total observations is to be extracted.</p>
</td></tr>
<tr><td><code id="nobs_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>nobs</code> gives the number of observations actually
used by the estimation procedure. It is not necessarily the number
of observations of the model frame (number of rows in the model
frame), because sometimes the model frame is further reduced by the
estimation procedure especially in the presence of NA. In the case of
<code>sfaselectioncross</code>, <code>nobs</code> returns the number of observations used in the
frontier equation.
</p>


<h3>Value</h3>

<p>A single number, normally an integer.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional or pooled data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Using data on fossil fuel fired steam electric power generation plants in the U.S.
# Translog (cost function) half normal with heteroscedasticity
tl_u_h &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'hnormal', uhet = ~ regu, data = utility, S = -1, method = 'bfgs')
nobs(tl_u_h)

## End(Not run)

</code></pre>

<hr>
<h2 id='residuals'>Extract residuals of stochastic frontier models</h2><span id='topic+residuals'></span><span id='topic+residuals.sfacross'></span><span id='topic+residuals.sfalcmcross'></span><span id='topic+residuals.sfaselectioncross'></span>

<h3>Description</h3>

<p>This function returns the residuals' values from stochastic frontier models
estimated with <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
residuals(object, ...)

## S3 method for class 'sfalcmcross'
residuals(object, ...)

## S3 method for class 'sfaselectioncross'
residuals(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals_+3A_object">object</code></td>
<td>
<p>A stochastic frontier model returned
by <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.</p>
</td></tr>
<tr><td><code id="residuals_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>When the <code>object</code> is of class <code>'sfacross'</code>, or
<code>'sfaselectioncross'</code>, <code><a href="#topic+residuals">residuals</a></code> returns a vector of
residuals values.
</p>
<p>When the <code>object</code> is of <code>'sfalcmcross'</code>,
<code><a href="#topic+residuals">residuals</a></code> returns a data frame containing the residuals values
for each latent class, where each variable ends with <code>'_c#'</code>,
<code>'#'</code> being the class number.
</p>


<h3>Note</h3>

<p>The residuals values are ordered in the same way as the corresponding
observations in the dataset used for the estimation.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional or pooled data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Using data on fossil fuel fired steam electric power generation plants in the U.S.
# Translog SFA (cost function) truncated normal with scaling property
tl_u_ts &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu, uhet = ~ regu, data = utility, S = -1,
scaling = TRUE, method = 'mla')
resid.tl_u_ts &lt;- residuals(tl_u_ts)
head(resid.tl_u_ts)

## Using data on eighty-two countries production (GDP)
# LCM Cobb Douglas (production function) half normal distribution
cb_2c_h &lt;- sfalcmcross(formula = ly ~ lk + ll + yr, udist = 'hnormal', 
data = worldprod, S = 1)
resid.cb_2c_h &lt;- residuals(cb_2c_h)
head(resid.cb_2c_h)

## End(Not run)

</code></pre>

<hr>
<h2 id='ricephil'>Data on rice production in the Philippines</h2><span id='topic+ricephil'></span>

<h3>Description</h3>

<p>This dataset contains annual data collected from 43 smallholder rice
producers in the Tarlac region of the Philippines between 1990 and 1997.
</p>


<h3>Format</h3>

<p>A data frame with 344 observations on the following 17 variables.
</p>
 <dl>
<dt>YEARDUM</dt><dd><p>Time period (1= 1990, ..., 8 = 1997).</p>
</dd>
<dt>FARMERCODE</dt><dd><p>Farmer code (1, ..., 43).</p>
</dd> <dt>PROD</dt><dd><p>Output (tonnes of
freshly threshed rice).</p>
</dd> <dt>AREA</dt><dd><p>Area planted (hectares).</p>
</dd>
<dt>LABOR</dt><dd><p>Labor used (man-days of family and hired labor).</p>
</dd>
<dt>NPK</dt><dd><p>Fertiliser used (kg of active ingredients).</p>
</dd> <dt>OTHER</dt><dd><p>Other
inputs used (Laspeyres index = 100 for Farm 17 in 1991).</p>
</dd>
<dt>PRICE</dt><dd><p>Output price (pesos per kg).</p>
</dd> <dt>AREAP</dt><dd><p>Rental price of land
(pesos per hectare).</p>
</dd> <dt>LABORP</dt><dd><p>Labor price (pesos per hired man-day).</p>
</dd>
<dt>NPKP</dt><dd><p>Fertiliser price (pesos per kg of active ingredient).</p>
</dd>
<dt>OTHERP</dt><dd><p>Price of other inputs (implicit price index).</p>
</dd> <dt>AGE</dt><dd><p>Age
of the household head (years).</p>
</dd> <dt>EDYRS</dt><dd><p>Education of the household head
(years).</p>
</dd> <dt>HHSIZE</dt><dd><p>Household size.</p>
</dd> <dt>NADULT</dt><dd><p>Number of adults in
the household.</p>
</dd> <dt>BANRAT</dt><dd><p>Percentage of area classified as bantog
(upland) fields.</p>
</dd> </dl>



<h3>Details</h3>

<p>This dataset is published as supplement to Coelli <em>et al.</em> (2005).
While most variables of this dataset were supplied by the International Rice
Research Institute (IRRI), some were calculated by Coelli <em>et al.</em>
(2005, see p. 325&ndash;326). The survey is described in Pandey <em>et al.</em>
(1999).
</p>


<h3>Source</h3>

<p>Supplementary files for Coelli <em>et al.</em> (2005),
<a href="http://www.uq.edu.au/economics/cepa/crob2005/software/CROB2005.zip">http://www.uq.edu.au/economics/cepa/crob2005/software/CROB2005.zip</a>.
</p>


<h3>References</h3>

<p>Coelli, T. J., Rao, D. S. P., O'Donnell, C. J., and Battese, G.
E. 2005. <em>An Introduction to Efficiency and Productivity Analysis</em>,
Springer, New York.
</p>
<p>Pandey, S., Masciat, P., Velasco, L, and Villano, R. 1999. Risk analysis of
a rainfed rice production system system in Tarlac, Central Luzon,
Philippines. <em>Experimental Agriculture</em>, <b>35</b>:225&ndash;237.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
str(ricephil)
summary(ricephil)
</code></pre>

<hr>
<h2 id='sfacross'>Stochastic frontier estimation using cross-sectional data</h2><span id='topic+sfacross'></span><span id='topic+print.sfacross'></span><span id='topic+bread.sfacross'></span><span id='topic+estfun.sfacross'></span>

<h3>Description</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code> is a symbolic formula-based function for the
estimation of stochastic frontier models in the case of cross-sectional or
pooled cross-sectional data, using maximum (simulated) likelihood - M(S)L.
</p>
<p>The function accounts for heteroscedasticity in both one-sided and two-sided
error terms as in Reifschneider and Stevenson (1991), Caudill and Ford
(1993), Caudill <em>et al.</em> (1995) and Hadri (1999), but also
heterogeneity in the mean of the pre-truncated distribution as in Kumbhakar
<em>et al.</em> (1991), Huang and Liu (1994) and Battese and Coelli (1995).
</p>
<p>Ten distributions are possible for the one-sided error term and eleven
optimization algorithms are available.
</p>
<p>The truncated normal - normal distribution with scaling property as in Wang
and Schmidt (2002) is also implemented.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfacross(
  formula,
  muhet,
  uhet,
  vhet,
  logDepVar = TRUE,
  data,
  subset,
  weights,
  wscale = TRUE,
  S = 1L,
  udist = "hnormal",
  scaling = FALSE,
  start = NULL,
  method = "bfgs",
  hessianType = 1L,
  simType = "halton",
  Nsim = 100,
  prime = 2L,
  burn = 10,
  antithetics = FALSE,
  seed = 12345,
  itermax = 2000,
  printInfo = FALSE,
  tol = 1e-12,
  gradtol = 1e-06,
  stepmax = 0.1,
  qac = "marquardt"
)

## S3 method for class 'sfacross'
print(x, ...)

## S3 method for class 'sfacross'
bread(x, ...)

## S3 method for class 'sfacross'
estfun(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sfacross_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be estimated based on
the generic function <code>formula</code> (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfacross_+3A_muhet">muhet</code></td>
<td>
<p>A one-part formula to consider heterogeneity in the mean of the
pre-truncated distribution (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfacross_+3A_uhet">uhet</code></td>
<td>
<p>A one-part formula to consider heteroscedasticity in the
one-sided error variance (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfacross_+3A_vhet">vhet</code></td>
<td>
<p>A one-part formula to consider heteroscedasticity in the
two-sided error variance (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfacross_+3A_logdepvar">logDepVar</code></td>
<td>
<p>Logical. Informs whether the dependent variable is logged
(<code>TRUE</code>) or not (<code>FALSE</code>). Default = <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_data">data</code></td>
<td>
<p>The data frame containing the data.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_subset">subset</code></td>
<td>
<p>An optional vector specifying a subset of observations to be
used in the optimization process.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_weights">weights</code></td>
<td>
<p>An optional vector of weights to be used for weighted
log-likelihood. Should be <code>NULL</code> or numeric vector with positive values.
When <code>NULL</code>, a numeric vector of 1 is used.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_wscale">wscale</code></td>
<td>
<p>Logical. When <code>weights</code> is not <code>NULL</code>, a scaling
transformation is used such that the <code>weights</code> sum to the sample
size. Default <code>TRUE</code>. When <code>FALSE</code> no scaling is used.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_s">S</code></td>
<td>
<p>If <code>S = 1</code> (default), a production (profit) frontier is
estimated: <code class="reqn">\epsilon_i = v_i-u_i</code>. If <code>S = -1</code>, a cost frontier is
estimated: <code class="reqn">\epsilon_i = v_i+u_i</code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_udist">udist</code></td>
<td>
<p>Character string. Default = <code>'hnormal'</code>. Distribution
specification for the one-sided error term. 10 different distributions are
available: </p>
 <ul>
<li> <p><code>'hnormal'</code>, for the half normal
distribution (Aigner <em>et al.</em> 1977, Meeusen and Vandenbroeck 1977)
</p>
</li>
<li> <p><code>'exponential'</code>, for the exponential distribution </p>
</li>
<li>
<p><code>'tnormal'</code> for the truncated normal distribution (Stevenson 1980)
</p>
</li>
<li> <p><code>'rayleigh'</code>, for the Rayleigh distribution (Hajargasht 2015)
</p>
</li>
<li> <p><code>'uniform'</code>, for the uniform distribution (Li 1996, Nguyen 2010)
</p>
</li>
<li> <p><code>'gamma'</code>, for the Gamma distribution (Greene 2003) </p>
</li>
<li>
<p><code>'lognormal'</code>, for the log normal distribution (Migon and Medici 2001,
Wang and Ye 2020) </p>
</li>
<li> <p><code>'weibull'</code>, for the Weibull distribution
(Tsionas 2007) </p>
</li>
<li> <p><code>'genexponential'</code>, for the generalized
exponential distribution (Papadopoulos 2020) </p>
</li>
<li> <p><code>'tslaplace'</code>, for
the truncated skewed Laplace distribution (Wang 2012). </p>
</li></ul>
</td></tr>
<tr><td><code id="sfacross_+3A_scaling">scaling</code></td>
<td>
<p>Logical. Only when <code>udist = 'tnormal'</code> and <code>scaling
= TRUE</code>, the scaling property model (Wang and Schmidt 2002) is estimated.
Default = <code>FALSE</code>. (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfacross_+3A_start">start</code></td>
<td>
<p>Numeric vector. Optional starting values for the maximum
likelihood (ML) estimation.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_method">method</code></td>
<td>
<p>Optimization algorithm used for the estimation. Default =
<code>'bfgs'</code>. 11 algorithms are available: </p>
 <ul>
<li> <p><code>'bfgs'</code>,
for Broyden-Fletcher-Goldfarb-Shanno (see
<code><a href="maxLik.html#topic+maxBFGS">maxBFGS</a></code>) </p>
</li>
<li> <p><code>'bhhh'</code>, for
Berndt-Hall-Hall-Hausman (see <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code>) </p>
</li>
<li>
<p><code>'nr'</code>, for Newton-Raphson (see <code><a href="maxLik.html#topic+maxNR">maxNR</a></code>)
</p>
</li>
<li> <p><code>'nm'</code>, for Nelder-Mead (see <code><a href="maxLik.html#topic+maxNM">maxNM</a></code>)
</p>
</li>
<li> <p><code>'cg'</code>, for Conjugate Gradient
(see <code><a href="maxLik.html#topic+maxCG">maxCG</a></code>) </p>
</li>
<li> <p><code>'sann'</code>, for Simulated
Annealing (see <code><a href="maxLik.html#topic+maxSANN">maxSANN</a></code>) </p>
</li>
<li> <p><code>'ucminf'</code>,
for a quasi-Newton type optimisation with BFGS updating of the inverse Hessian and
soft line search with a trust region type monitoring of the input to the line
search algorithm (see <code><a href="ucminf.html#topic+ucminf">ucminf</a></code>)
</p>
</li>
<li> <p><code>'mla'</code>, for general-purpose optimization based on
Marquardt-Levenberg algorithm (see <code><a href="marqLevAlg.html#topic+mla">mla</a></code>)
</p>
</li>
<li> <p><code>'sr1'</code>, for Symmetric Rank 1 (see
<code><a href="trustOptim.html#topic+trust.optim">trust.optim</a></code>) </p>
</li>
<li> <p><code>'sparse'</code>,
for trust regions and sparse Hessian
(see <code><a href="trustOptim.html#topic+trust.optim">trust.optim</a></code>) </p>
</li>
<li>
<p><code>'nlminb'</code>, for optimization using PORT routines (see
<code><a href="stats.html#topic+nlminb">nlminb</a></code>)</p>
</li></ul>
</td></tr>
<tr><td><code id="sfacross_+3A_hessiantype">hessianType</code></td>
<td>
<p>Integer. If <code>1</code> (Default), analytic Hessian is
returned for all the distributions. If <code>2</code>,
bhhh Hessian is estimated (<code class="reqn">g'g</code>).</p>
</td></tr>
<tr><td><code id="sfacross_+3A_simtype">simType</code></td>
<td>
<p>Character string. If <code>simType = 'halton'</code> (Default),
Halton draws are used for maximum simulated likelihood (MSL). If
<code>simType = 'ghalton'</code>, Generalized-Halton draws are used for MSL. If
<code>simType = 'sobol'</code>, Sobol draws are used for MSL. If <code>simType =
'uniform'</code>, uniform draws are used for MSL. (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfacross_+3A_nsim">Nsim</code></td>
<td>
<p>Number of draws for MSL. Default 100.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_prime">prime</code></td>
<td>
<p>Prime number considered for Halton and Generalized-Halton
draws. Default = <code>2</code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_burn">burn</code></td>
<td>
<p>Number of the first observations discarded in the case of Halton
draws. Default = <code>10</code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_antithetics">antithetics</code></td>
<td>
<p>Logical. Default = <code>FALSE</code>. If <code>TRUE</code>,
antithetics counterpart of the uniform draws is computed. (see section
&lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfacross_+3A_seed">seed</code></td>
<td>
<p>Numeric. Seed for the random draws.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_itermax">itermax</code></td>
<td>
<p>Maximum number of iterations allowed for optimization.
Default = <code>2000</code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_printinfo">printInfo</code></td>
<td>
<p>Logical. Print information during optimization. Default =
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_tol">tol</code></td>
<td>
<p>Numeric. Convergence tolerance. Default = <code>1e-12</code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_gradtol">gradtol</code></td>
<td>
<p>Numeric. Convergence tolerance for gradient. Default =
<code>1e-06</code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_stepmax">stepmax</code></td>
<td>
<p>Numeric. Step max for <code>ucminf</code> algorithm. Default =
<code>0.1</code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_qac">qac</code></td>
<td>
<p>Character. Quadratic Approximation Correction for <code>'bhhh'</code>
and <code>'nr'</code> algorithms. If <code>'stephalving'</code>, the step length is
decreased but the direction is kept. If <code>'marquardt'</code> (default), the
step length is decreased while also moving closer to the pure gradient
direction. See <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code> and
<code><a href="maxLik.html#topic+maxNR">maxNR</a></code>.</p>
</td></tr>
<tr><td><code id="sfacross_+3A_x">x</code></td>
<td>
<p>an object of class sfacross (returned by the function
<code><a href="#topic+sfacross">sfacross</a></code>).</p>
</td></tr>
<tr><td><code id="sfacross_+3A_...">...</code></td>
<td>
<p>additional arguments of frontier are passed to sfacross;
additional arguments of the print, bread, estfun, nobs methods are currently
ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The stochastic frontier model for the cross-sectional data is defined as:
</p>
<p style="text-align: center;"><code class="reqn">y_i = \alpha + \mathbf{x_i^{\prime}}\bm{\beta} + v_i - Su_i</code>
</p>

<p>with
</p>
<p style="text-align: center;"><code class="reqn">\epsilon_i = v_i -Su_i</code>
</p>

<p>where <code class="reqn">i</code> is the observation, <code class="reqn">y</code> is the
output (cost, revenue, profit), <code class="reqn">\mathbf{x}</code> is the vector of main explanatory
variables (inputs and other control variables), <code class="reqn">u</code> is the one-sided
error term with variance <code class="reqn">\sigma_{u}^2</code>, and <code class="reqn">v</code> is the two-sided
error term with variance <code class="reqn">\sigma_{v}^2</code>.
</p>
<p><code>S = 1</code> in the case of production (profit) frontier function and
<code>S = -1</code> in the case of cost frontier function.
</p>
<p>The model is estimated using maximum likelihood (ML) for most distributions
except the Gamma, Weibull and log-normal distributions for which maximum
simulated likelihood (MSL) is used. For this latter, several draws can be
implemented namely Halton, Generalized Halton, Sobol and uniform. In the
case of uniform draws, antithetics can also be computed: first <code>Nsim/2</code>
draws are obtained, then the <code>Nsim/2</code> other draws are obtained as
counterpart of one (<code>1-draw</code>).
</p>
<p>To account for heteroscedasticity in the variance parameters of the error
terms, a single part (right) formula can also be specified. To impose the
positivity to these parameters, the variances are modelled as:
<code class="reqn">\sigma^2_u = \exp{(\bm{\delta}'\mathbf{Z}_u)}</code> or <code class="reqn">\sigma^2_v =
\exp{(\bm{\phi}'\mathbf{Z}_v)}</code>, where <code class="reqn">\mathbf{Z}_u</code> and <code class="reqn">\mathbf{Z}_v</code> are the heteroscedasticity
variables (inefficiency drivers in the case of <code class="reqn">\mathbf{Z}_u</code>) and <code class="reqn">\bm{\delta}</code>
and <code class="reqn">\bm{\phi}</code> the coefficients. In the case of heterogeneity in the
truncated mean <code class="reqn">\mu</code>, it is modelled as <code class="reqn">\mu=\bm{\omega}'\mathbf{Z}_{\mu}</code>. The
scaling property can be applied for the truncated normal distribution:
<code class="reqn">u \sim h(\mathbf{Z}_u, \delta)u</code> where <code class="reqn">u</code> follows a truncated normal
distribution <code class="reqn">N^+(\tau, \exp{(cu)})</code>.
</p>
<p>In the case of the truncated normal distribution, the convolution of
<code class="reqn">u_i</code> and <code class="reqn">v_i</code> is:
</p>
<p style="text-align: center;"><code class="reqn">f(\epsilon_i)=\frac{1}{\sqrt{\sigma_u^2 + 
\sigma_v^2}}\phi\left(\frac{S\epsilon_i + \mu}{\sqrt{
\sigma_u^2 + \sigma_v^2}}\right)\Phi\left(\frac{
\mu_{i*}}{\sigma_*}\right)\Big/\Phi\left(\frac{
\mu}{\sigma_u}\right)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\mu_{i*}=\frac{\mu\\\sigma_v^2 - 
S\epsilon_i\sigma_u^2}{\sigma_u^2 + \sigma_v^2}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\sigma_*^2 = \frac{\sigma_u^2 
\sigma_v^2}{\sigma_u^2 + \sigma_v^2}</code>
</p>

<p>In the case of the half normal distribution the convolution is obtained by
setting <code class="reqn">\mu=0</code>.
</p>
<p><code>sfacross</code> allows for the maximization of weighted log-likelihood.
When option <code>weights</code> is specified and <code>wscale = TRUE</code>, the weights
are scaled as:
</p>
<p style="text-align: center;"><code class="reqn">new_{weights} = sample_{size} \times 
\frac{old_{weights}}{\sum(old_{weights})}</code>
</p>

<p>For complex problems, non-gradient methods (e.g. <code>nm</code> or <code>sann</code>)
can be used to warm start the optimization and zoom in the neighborhood of
the solution. Then a gradient-based methods is recommended in the second
step. In the case of <code>sann</code>, we recommend to significantly increase the
iteration limit (e.g. <code>itermax = 20000</code>). The Conjugate Gradient
(<code>cg</code>) can also be used in the first stage.
</p>
<p>A set of extractor functions for fitted model objects is available for
objects of class <code>'sfacross'</code> including methods to the generic functions
<code><a href="#topic+print.sfacross">print</a></code>,
<code><a href="#topic+summary.sfacross">summary</a></code>, <code><a href="#topic+coef.sfacross">coef</a></code>,
<code><a href="#topic+fitted.sfacross">fitted</a></code>,
<code><a href="#topic+logLik.sfacross">logLik</a></code>,
<code><a href="#topic+residuals.sfacross">residuals</a></code>,
<code><a href="#topic+vcov.sfacross">vcov</a></code>,
<code><a href="#topic+efficiencies.sfacross">efficiencies</a></code>,
<code><a href="#topic+ic.sfacross">ic</a></code>,
<code><a href="#topic+marginal.sfacross">marginal</a></code>,
<code><a href="#topic+skewnessTest">skewnessTest</a></code>,
<code><a href="#topic+estfun.sfacross">estfun</a></code> and
<code><a href="#topic+bread.sfacross">bread</a></code> (from the <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> package),
<code><a href="lmtest.html#topic+coeftest">lmtest::coeftest()</a></code> (from the <a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> package).
</p>


<h3>Value</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code> returns a list of class <code>'sfacross'</code>
containing the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>The estimated model.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>The argument <code>'S'</code>. See the section &lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>typeSfa</code></td>
<td>
<p>Character string. 'Stochastic Production/Profit Frontier, e =
v - u' when <code>S = 1</code> and 'Stochastic Cost Frontier, e = v + u' when
<code>S = -1</code>.</p>
</td></tr>
<tr><td><code>Nobs</code></td>
<td>
<p>Number of observations used for optimization.</p>
</td></tr>
<tr><td><code>nXvar</code></td>
<td>
<p>Number of explanatory variables in the production or cost
frontier.</p>
</td></tr>
<tr><td><code>nmuZUvar</code></td>
<td>
<p>Number of variables explaining heterogeneity in the
truncated mean, only if <code>udist = 'tnormal'</code> or <code>'lognormal'</code>.</p>
</td></tr>
<tr><td><code>scaling</code></td>
<td>
<p>The argument <code>'scaling'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>logDepVar</code></td>
<td>
<p>The argument <code>'logDepVar'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>nuZUvar</code></td>
<td>
<p>Number of variables explaining heteroscedasticity in the
one-sided error term.</p>
</td></tr>
<tr><td><code>nvZVvar</code></td>
<td>
<p>Number of variables explaining heteroscedasticity in the
two-sided error term.</p>
</td></tr>
<tr><td><code>nParm</code></td>
<td>
<p>Total number of parameters estimated.</p>
</td></tr>
<tr><td><code>udist</code></td>
<td>
<p>The argument <code>'udist'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>startVal</code></td>
<td>
<p>Numeric vector. Starting value for M(S)L estimation.</p>
</td></tr>
<tr><td><code>dataTable</code></td>
<td>
<p>A data frame (tibble format) containing information on data
used for optimization along with residuals and fitted values of the OLS and
M(S)L estimations, and the individual observation log-likelihood. When
<code>weights</code> is specified an additional variable is also provided in
<code>dataTable</code>.</p>
</td></tr>
<tr><td><code>olsParam</code></td>
<td>
<p>Numeric vector. OLS estimates.</p>
</td></tr>
<tr><td><code>olsStder</code></td>
<td>
<p>Numeric vector. Standard errors of OLS estimates.</p>
</td></tr>
<tr><td><code>olsSigmasq</code></td>
<td>
<p>Numeric. Estimated variance of OLS random error.</p>
</td></tr>
<tr><td><code>olsLoglik</code></td>
<td>
<p>Numeric. Log-likelihood value of OLS estimation.</p>
</td></tr>
<tr><td><code>olsSkew</code></td>
<td>
<p>Numeric. Skewness of the residuals of the OLS estimation.</p>
</td></tr>
<tr><td><code>olsM3Okay</code></td>
<td>
<p>Logical. Indicating whether the residuals of the OLS
estimation have the expected skewness.</p>
</td></tr>
<tr><td><code>CoelliM3Test</code></td>
<td>
<p>Coelli's test for OLS residuals skewness. (See Coelli,
1995).</p>
</td></tr>
<tr><td><code>AgostinoTest</code></td>
<td>
<p>D'Agostino's test for OLS residuals skewness. (See
D'Agostino and Pearson, 1973).</p>
</td></tr>
<tr><td><code>isWeights</code></td>
<td>
<p>Logical. If <code>TRUE</code> weighted log-likelihood is
maximized.</p>
</td></tr>
<tr><td><code>optType</code></td>
<td>
<p>Optimization algorithm used.</p>
</td></tr>
<tr><td><code>nIter</code></td>
<td>
<p>Number of iterations of the ML estimation.</p>
</td></tr>
<tr><td><code>optStatus</code></td>
<td>
<p>Optimization algorithm termination message.</p>
</td></tr>
<tr><td><code>startLoglik</code></td>
<td>
<p>Log-likelihood at the starting values.</p>
</td></tr>
<tr><td><code>mlLoglik</code></td>
<td>
<p>Log-likelihood value of the M(S)L estimation.</p>
</td></tr>
<tr><td><code>mlParam</code></td>
<td>
<p>Parameters obtained from M(S)L estimation.</p>
</td></tr>
<tr><td><code>gradient</code></td>
<td>
<p>Each variable gradient of the M(S)L estimation.</p>
</td></tr>
<tr><td><code>gradL_OBS</code></td>
<td>
<p>Matrix. Each variable individual observation gradient of
the M(S)L estimation.</p>
</td></tr>
<tr><td><code>gradientNorm</code></td>
<td>
<p>Gradient norm of the M(S)L estimation.</p>
</td></tr>
<tr><td><code>invHessian</code></td>
<td>
<p>Covariance matrix of the parameters obtained from the
M(S)L estimation.</p>
</td></tr>
<tr><td><code>hessianType</code></td>
<td>
<p>The argument <code>'hessianType'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>mlDate</code></td>
<td>
<p>Date and time of the estimated model.</p>
</td></tr>
<tr><td><code>simDist</code></td>
<td>
<p>The argument <code>'simDist'</code>, only if <code>udist =
'gamma'</code>, <code>'lognormal'</code> or , <code>'weibull'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>The argument <code>'Nsim'</code>, only if <code>udist = 'gamma'</code>,
<code>'lognormal'</code> or , <code>'weibull'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>FiMat</code></td>
<td>
<p>Matrix of random draws used for MSL, only if <code>udist =
'gamma'</code>, <code>'lognormal'</code> or , <code>'weibull'</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For the Halton draws, the code is adapted from the <span class="pkg">mlogit</span>
package.
</p>


<h3>References</h3>

<p>Aigner, D., Lovell, C. A. K., and Schmidt, P. 1977. Formulation
and estimation of stochastic frontier production function models.
<em>Journal of Econometrics</em>, <b>6</b>(1), 21&ndash;37.
</p>
<p>Battese, G. E., and Coelli, T. J. 1995. A model for technical inefficiency
effects in a stochastic frontier production function for panel data.
<em>Empirical Economics</em>, <b>20</b>(2), 325&ndash;332.
</p>
<p>Caudill, S. B., and Ford, J. M. 1993. Biases in frontier estimation due to
heteroscedasticity. <em>Economics Letters</em>, <b>41</b>(1), 17&ndash;20.
</p>
<p>Caudill, S. B., Ford, J. M., and Gropper, D. M. 1995. Frontier estimation
and firm-specific inefficiency measures in the presence of
heteroscedasticity. <em>Journal of Business &amp; Economic Statistics</em>,
<b>13</b>(1), 105&ndash;111.
</p>
<p>Coelli, T. 1995. Estimators and hypothesis tests for a stochastic frontier
function - a Monte-Carlo analysis. <em>Journal of Productivity Analysis</em>,
<b>6</b>:247&ndash;268.
</p>
<p>D'Agostino, R., and E.S. Pearson. 1973. Tests for departure from normality.
Empirical results for the distributions of <code class="reqn">b_2</code> and <code class="reqn">\sqrt{b_1}</code>.
<em>Biometrika</em>, <b>60</b>:613&ndash;622.
</p>
<p>Greene, W. H. 2003. Simulated likelihood estimation of the normal-Gamma
stochastic frontier function. <em>Journal of Productivity Analysis</em>,
<b>19</b>(2-3), 179&ndash;190.
</p>
<p>Hadri, K. 1999. Estimation of a doubly heteroscedastic stochastic frontier
cost function. <em>Journal of Business &amp; Economic Statistics</em>,
<b>17</b>(3), 359&ndash;363.
</p>
<p>Hajargasht, G. 2015. Stochastic frontiers with a Rayleigh distribution.
<em>Journal of Productivity Analysis</em>, <b>44</b>(2), 199&ndash;208.
</p>
<p>Huang, C. J., and Liu, J.-T. 1994. Estimation of a non-neutral stochastic
frontier production function. <em>Journal of Productivity Analysis</em>,
<b>5</b>(2), 171&ndash;180.
</p>
<p>Kumbhakar, S. C., Ghosh, S., and McGuckin, J. T. 1991) A generalized
production frontier approach for estimating determinants of inefficiency in
U.S. dairy farms. <em>Journal of Business &amp; Economic Statistics</em>,
<b>9</b>(3), 279&ndash;286.
</p>
<p>Li, Q. 1996. Estimating a stochastic production frontier when the adjusted
error is symmetric. <em>Economics Letters</em>, <b>52</b>(3), 221&ndash;228.
</p>
<p>Meeusen, W., and Vandenbroeck, J. 1977. Efficiency estimation from
Cobb-Douglas production functions with composed error. <em>International
Economic Review</em>, <b>18</b>(2), 435&ndash;445.
</p>
<p>Migon, H. S., and Medici, E. V. 2001. Bayesian hierarchical models for
stochastic production frontier. Lacea, Montevideo, Uruguay.
</p>
<p>Nguyen, N. B. 2010. Estimation of technical efficiency in stochastic
frontier analysis. PhD dissertation, Bowling Green State University, August.
</p>
<p>Papadopoulos, A. 2021. Stochastic frontier models using the generalized
exponential distribution. <em>Journal of Productivity Analysis</em>,
<b>55</b>:15&ndash;29.
</p>
<p>Reifschneider, D., and Stevenson, R. 1991. Systematic departures from the
frontier: A framework for the analysis of firm inefficiency.
<em>International Economic Review</em>, <b>32</b>(3), 715&ndash;723.
</p>
<p>Stevenson, R. E. 1980. Likelihood Functions for Generalized Stochastic
Frontier Estimation. <em>Journal of Econometrics</em>, <b>13</b>(1), 57&ndash;66.
</p>
<p>Tsionas, E. G. 2007. Efficiency measurement with the Weibull stochastic
frontier. <em>Oxford Bulletin of Economics and Statistics</em>, <b>69</b>(5),
693&ndash;706.
</p>
<p>Wang, K., and Ye, X. 2020. Development of alternative stochastic frontier
models for estimating time-space prism vertices. <em>Transportation</em>.
</p>
<p>Wang, H.J., and Schmidt, P. 2002. One-step and two-step estimation of the
effects of exogenous variables on technical efficiency levels. <em>Journal
of Productivity Analysis</em>, <b>18</b>:129&ndash;144.
</p>
<p>Wang, J. 2012. A normal truncated skewed-Laplace model in stochastic
frontier analysis. Master thesis, Western Kentucky University, May.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.sfacross">print</a></code> for printing <code>sfacross</code>
object.
</p>
<p><code><a href="#topic+summary.sfacross">summary</a></code> for creating and printing
summary results.
</p>
<p><code><a href="#topic+coef.sfacross">coef</a></code> for extracting coefficients of the
estimation.
</p>
<p><code><a href="#topic+efficiencies.sfacross">efficiencies</a></code> for computing
(in-)efficiency estimates.
</p>
<p><code><a href="#topic+fitted.sfacross">fitted</a></code> for extracting the fitted frontier
values.
</p>
<p><code><a href="#topic+ic.sfacross">ic</a></code> for extracting information criteria.
</p>
<p><code><a href="#topic+logLik.sfacross">logLik</a></code> for extracting log-likelihood
value(s) of the estimation.
</p>
<p><code><a href="#topic+marginal.sfacross">marginal</a></code> for computing marginal effects of
inefficiency drivers.
</p>
<p><code><a href="#topic+residuals.sfacross">residuals</a></code> for extracting residuals of the
estimation.
</p>
<p><code><a href="#topic+skewnessTest">skewnessTest</a></code> for conducting residuals
skewness test.
</p>
<p><code><a href="#topic+vcov.sfacross">vcov</a></code> for computing the variance-covariance
matrix of the coefficients.
</p>
<p><code><a href="#topic+bread.sfacross">bread</a></code> for bread for sandwich estimator.
</p>
<p><code><a href="#topic+estfun.sfacross">estfun</a></code> for gradient extraction for each
observation.
</p>
<p><code><a href="#topic+skewnessTest">skewnessTest</a></code> for implementing skewness test.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Using data on fossil fuel fired steam electric power generation plants in the U.S.
# Translog (cost function) half normal with heteroscedasticity
tl_u_h &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'hnormal', uhet = ~ regu, data = utility, S = -1, method = 'bfgs')
summary(tl_u_h)

# Translog (cost function) truncated normal with heteroscedasticity
tl_u_t &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu, data = utility, S = -1, method = 'bhhh')
summary(tl_u_t)

# Translog (cost function) truncated normal with scaling property
tl_u_ts &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu, uhet = ~ regu, data = utility, S = -1,
scaling = TRUE, method = 'mla')
summary(tl_u_ts)

## Using data on Philippine rice producers
# Cobb Douglas (production function) generalized exponential, and Weibull 
# distributions

cb_p_ge &lt;- sfacross(formula = log(PROD) ~ log(AREA) + log(LABOR) + log(NPK) +
log(OTHER), udist = 'genexponential', data = ricephil, S = 1, method = 'bfgs')
summary(cb_p_ge)

## Using data on U.S. electric utility industry
# Cost frontier Gamma distribution
tl_u_g &lt;- sfacross(formula = log(cost/fprice) ~ log(output) + I(log(output)^2) +
I(log(lprice/fprice)) + I(log(cprice/fprice)), udist = 'gamma', uhet = ~ 1,
data = electricity, S = -1, method = 'bfgs', simType = 'halton', Nsim = 200,
hessianType = 2)
summary(tl_u_g)

</code></pre>

<hr>
<h2 id='sfalcmcross'>Latent class stochastic frontier using cross-sectional data</h2><span id='topic+sfalcmcross'></span><span id='topic+print.sfalcmcross'></span><span id='topic+bread.sfalcmcross'></span><span id='topic+estfun.sfalcmcross'></span>

<h3>Description</h3>

<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code> is a symbolic formula based function for the
estimation of the latent class stochastic frontier model (LCM) in the case
of cross-sectional or pooled cross-sectional data. The model is estimated
using maximum likelihood (ML). See Orea and Kumbhakar (2004), Parmeter and
Kumbhakar (2014, p282).
</p>
<p>Only the half-normal distribution is possible for the one-sided error term.
Eleven optimization algorithms are available.
</p>
<p>The function also accounts for heteroscedasticity in both one-sided and
two-sided error terms, as in Reifschneider and Stevenson (1991), Caudill and
Ford (1993), Caudill <em>et al.</em> (1995) and Hadri (1999).
</p>
<p>The model can estimate up to five classes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfalcmcross(
  formula,
  uhet,
  vhet,
  thet,
  logDepVar = TRUE,
  data,
  subset,
  weights,
  wscale = TRUE,
  S = 1L,
  udist = "hnormal",
  start = NULL,
  whichStart = 2L,
  initAlg = "nm",
  initIter = 100,
  lcmClasses = 2,
  method = "bfgs",
  hessianType = 1,
  itermax = 2000L,
  printInfo = FALSE,
  tol = 1e-12,
  gradtol = 1e-06,
  stepmax = 0.1,
  qac = "marquardt"
)

## S3 method for class 'sfalcmcross'
print(x, ...)

## S3 method for class 'sfalcmcross'
bread(x, ...)

## S3 method for class 'sfalcmcross'
estfun(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sfalcmcross_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be estimated based on
the generic function <code>formula</code> (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_uhet">uhet</code></td>
<td>
<p>A one-part formula to account for heteroscedasticity in the
one-sided error variance (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_vhet">vhet</code></td>
<td>
<p>A one-part formula to account for heteroscedasticity in the
two-sided error variance (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_thet">thet</code></td>
<td>
<p>A one-part formula to account for technological heterogeneity in
the construction of the classes.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_logdepvar">logDepVar</code></td>
<td>
<p>Logical. Informs whether the dependent variable is logged
(<code>TRUE</code>) or not (<code>FALSE</code>). Default = <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_data">data</code></td>
<td>
<p>The data frame containing the data.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_subset">subset</code></td>
<td>
<p>An optional vector specifying a subset of observations to be
used in the optimization process.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_weights">weights</code></td>
<td>
<p>An optional vector of weights to be used for weighted
log-likelihood. Should be <code>NULL</code> or numeric vector with positive values.
When <code>NULL</code>, a numeric vector of 1 is used.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_wscale">wscale</code></td>
<td>
<p>Logical. When <code>weights</code> is not <code>NULL</code>, a scaling
transformation is used such that the <code>weights</code> sums to the sample
size. Default <code>TRUE</code>. When <code>FALSE</code> no scaling is used.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_s">S</code></td>
<td>
<p>If <code>S = 1</code> (default), a production (profit) frontier is
estimated: <code class="reqn">\epsilon_i = v_i-u_i</code>. If <code>S = -1</code>, a cost frontier is
estimated: <code class="reqn">\epsilon_i = v_i+u_i</code>.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_udist">udist</code></td>
<td>
<p>Character string. Distribution specification for the one-sided
error term. Only the half normal distribution <code>'hnormal'</code> (Aigner
<em>et al.</em>, 1977, Meeusen and Vandenbroeck, 1977) is currently
implemented.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_start">start</code></td>
<td>
<p>Numeric vector. Optional starting values for the maximum
likelihood (ML) estimation.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_whichstart">whichStart</code></td>
<td>
<p>Integer. If <code>'whichStart = 1'</code>, the starting values
are obtained from the method of moments. When <code>'whichStart = 2'</code>
(Default), the model is initialized by solving the homoscedastic pooled
cross section SFA model.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_initalg">initAlg</code></td>
<td>
<p>Character string specifying the algorithm used for
initialization and obtain the starting values (when <code>'whichStart = 2'</code>).
Only <span class="pkg">maxLik</span> package algorithms are available:
</p>
 <ul>
<li> <p><code>'bfgs'</code>, for Broyden-Fletcher-Goldfarb-Shanno
(see <code><a href="maxLik.html#topic+maxBFGS">maxBFGS</a></code>)
</p>
</li>
<li> <p><code>'bhhh'</code>, for Berndt-Hall-Hall-Hausman
(see <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code>)
</p>
</li>
<li> <p><code>'nr'</code>, for Newton-Raphson (see <code><a href="maxLik.html#topic+maxNR">maxNR</a></code>)
</p>
</li>
<li> <p><code>'nm'</code>, for Nelder-Mead - Default -
(see <code><a href="maxLik.html#topic+maxNM">maxNM</a></code>)
</p>
</li>
<li> <p><code>'cg'</code>, for Conjugate Gradient
(see <code><a href="maxLik.html#topic+maxCG">maxCG</a></code>) </p>
</li>
<li> <p><code>'sann'</code>, for Simulated
Annealing (see <code><a href="maxLik.html#topic+maxSANN">maxSANN</a></code>)
</p>
</li></ul>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_inititer">initIter</code></td>
<td>
<p>Maximum number of iterations for initialization algorithm.
Default <code>100</code>.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_lcmclasses">lcmClasses</code></td>
<td>
<p>Number of classes to be estimated (default = <code>2</code>). A
maximum of five classes can be estimated.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_method">method</code></td>
<td>
<p>Optimization algorithm used for the estimation.  Default =
<code>'bfgs'</code>. 11 algorithms are available: </p>
 <ul>
<li> <p><code>'bfgs'</code>,
for Broyden-Fletcher-Goldfarb-Shanno (see
<code><a href="maxLik.html#topic+maxBFGS">maxBFGS</a></code>) </p>
</li>
<li> <p><code>'bhhh'</code>, for
Berndt-Hall-Hall-Hausman (see <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code>) </p>
</li>
<li>
<p><code>'nr'</code>, for Newton-Raphson (see <code><a href="maxLik.html#topic+maxNR">maxNR</a></code>)
</p>
</li>
<li> <p><code>'nm'</code>, for Nelder-Mead (see <code><a href="maxLik.html#topic+maxNM">maxNM</a></code>)
</p>
</li>
<li> <p><code>'cg'</code>, for Conjugate Gradient
(see <code><a href="maxLik.html#topic+maxCG">maxCG</a></code>) </p>
</li>
<li> <p><code>'sann'</code>, for Simulated
Annealing (see <code><a href="maxLik.html#topic+maxSANN">maxSANN</a></code>)
</p>
</li>
<li> <p><code>'ucminf'</code>, for a quasi-Newton type optimization with BFGS updating of
the inverse Hessian and soft line search with a trust region type monitoring
of the input to the line search algorithm
(see <code><a href="ucminf.html#topic+ucminf">ucminf</a></code>)
</p>
</li>
<li> <p><code>'mla'</code>, for general-purpose optimization based on
Marquardt-Levenberg algorithm (see <code><a href="marqLevAlg.html#topic+mla">mla</a></code>)
</p>
</li>
<li> <p><code>'sr1'</code>, for Symmetric Rank 1 (see
<code><a href="trustOptim.html#topic+trust.optim">trust.optim</a></code>) </p>
</li>
<li> <p><code>'sparse'</code>,
for trust regions and sparse Hessian
(see <code><a href="trustOptim.html#topic+trust.optim">trust.optim</a></code>) </p>
</li>
<li>
<p><code>'nlminb'</code>, for optimization using PORT routines (see
<code><a href="stats.html#topic+nlminb">nlminb</a></code>)</p>
</li></ul>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_hessiantype">hessianType</code></td>
<td>
<p>Integer. If <code>1</code> (default), analytic Hessian is
returned. If <code>2</code>, bhhh Hessian is estimated (<code class="reqn">g'g</code>).</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_itermax">itermax</code></td>
<td>
<p>Maximum number of iterations allowed for optimization.
Default = <code>2000</code>.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_printinfo">printInfo</code></td>
<td>
<p>Logical. Print information during optimization. Default =
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_tol">tol</code></td>
<td>
<p>Numeric. Convergence tolerance. Default = <code>1e-12</code>.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_gradtol">gradtol</code></td>
<td>
<p>Numeric. Convergence tolerance for gradient. Default =
<code>1e-06</code>.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_stepmax">stepmax</code></td>
<td>
<p>Numeric. Step max for <code>ucminf</code> algorithm. Default =
<code>0.1</code>.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_qac">qac</code></td>
<td>
<p>Character. Quadratic Approximation Correction for <code>'bhhh'</code>
and <code>'nr'</code> algorithms. If <code>'qac = stephalving'</code>, the step length
is decreased but the direction is kept. If <code>'qac = marquardt'</code>
(default), the step length is decreased while also moving closer to the pure
gradient direction. See <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code> and
<code><a href="maxLik.html#topic+maxNR">maxNR</a></code>.</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_x">x</code></td>
<td>
<p>an object of class sfalcmcross (returned by the function
<code><a href="#topic+sfalcmcross">sfalcmcross</a></code>).</p>
</td></tr>
<tr><td><code id="sfalcmcross_+3A_...">...</code></td>
<td>
<p>additional arguments of frontier are passed to sfalcmcross;
additional arguments of the print, bread, estfun, nobs methods are currently
ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>LCM is an estimation of a finite mixture of production functions:
</p>
<p style="text-align: center;"><code class="reqn">y_i = \alpha_j + \mathbf{x_i^{\prime}} 
\bm{\beta_j} + v_{i|j} - Su_{i|j}</code>
</p>

<p style="text-align: center;"><code class="reqn">\epsilon_{i|j} = v_{i|j} - Su_{i|j}</code>
</p>

<p>where <code class="reqn">i</code> is the observation, <code class="reqn">j</code> is the class, <code class="reqn">y</code> is the
output (cost, revenue, profit), <code class="reqn">x</code> is the vector of main explanatory
variables (inputs and other control variables), <code class="reqn">u</code> is the one-sided
error term with variance <code class="reqn">\sigma_{u}^2</code>, and <code class="reqn">v</code> is the two-sided
error term with variance <code class="reqn">\sigma_{v}^2</code>.
</p>
<p><code>S = 1</code> in the case of production (profit) frontier function and
<code>S = -1</code> in the case of cost frontier function.
</p>
<p>The contribution of observation <code class="reqn">i</code> to the likelihood conditional on
class <code class="reqn">j</code> is defined as:
</p>
<p style="text-align: center;"><code class="reqn">P(i|j) = \frac{2}{\sqrt{\sigma_{u|j}^2 + 
\sigma_{v|j}^2}}\phi\left(\frac{S\epsilon_{i|j}}{\sqrt{
\sigma_{u|j}^2 +\sigma_{v|j}^2}}\right)\Phi\left(\frac{
\mu_{i*|j}}{\sigma_{*|j}}\right)</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">\mu_{i*|j}=\frac{- S\epsilon_{i|j}
\sigma_{u|j}^2}{\sigma_{u|j}^2 + \sigma_{v|j}^2}</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">\sigma_*^2 = \frac{\sigma_{u|j}^2 
\sigma_{v|j}^2}{\sigma_{u|j}^2 + \sigma_{v|j}^2}</code>
</p>

<p>The prior probability of using a particular technology can depend on some
covariates (namely the variables separating the observations into classes)
using a logit specification:
</p>
<p style="text-align: center;"><code class="reqn">\pi(i,j) = \frac{\exp{(\bm{\theta}_j'\mathbf{Z}_{hi})}}{
\sum_{m=1}^{J}\exp{(\bm{\theta}_m'\mathbf{Z}_{hi})}}</code>
</p>

<p>with <code class="reqn">\mathbf{Z}_h</code> the covariates, <code class="reqn">\bm{\theta}</code> the coefficients estimated for
the covariates, and <code class="reqn">\exp(\bm{\theta}_J'\mathbf{Z}_h)=1</code>.
</p>
<p>The unconditional likelihood of observation <code class="reqn">i</code> is simply the average
over the <code class="reqn">J</code> classes:
</p>
<p style="text-align: center;"><code class="reqn">P(i) = \sum_{m=1}^{J}\pi(i,m)P(i|m)</code>
</p>

<p>The number of classes to retain can be based on information criterion (see
for instance <code><a href="#topic+ic.sfalcmcross">ic</a></code>).
</p>
<p>Class assignment is based on the largest posterior probability. This
probability is obtained using Bayes' rule, as follows for class <code class="reqn">j</code>:
</p>
<p style="text-align: center;"><code class="reqn">w\left(j|i\right)=\frac{P\left(i|j\right)
\pi\left(i,j\right)}{\sum_{m=1}^JP\left(i|m\right)
\pi\left(i, m\right)}</code>
</p>

<p>To accommodate heteroscedasticity in the variance parameters of the error
terms, a single part (right) formula can also be specified. To impose the
positivity on these parameters, the variances are modelled respectively as:
<code class="reqn">\sigma^2_{u|j} = \exp{(\bm{\delta}_j'\mathbf{Z}_u)}</code> and <code class="reqn">\sigma^2_{v|j} =
\exp{(\bm{\phi}_j'\mathbf{Z}_v)}</code>, where <code class="reqn">Z_u</code> and <code class="reqn">Z_v</code> are the
heteroscedasticity variables (inefficiency drivers in the case of <code class="reqn">\mathbf{Z}_u</code>)
and <code class="reqn">\bm{\delta}</code> and <code class="reqn">\bm{\phi}</code> the coefficients. <code>'sfalcmcross'</code> only
supports the half-normal distribution for the one-sided error term.
</p>
<p><code>sfalcmcross</code> allows for the maximization of weighted log-likelihood.
When option <code>weights</code> is specified and <code>wscale = TRUE</code>, the weights
are scaled as:
</p>
<p style="text-align: center;"><code class="reqn">new_{weights} = sample_{size} \times 
\frac{old_{weights}}{\sum(old_{weights})}</code>
</p>

<p>For complex problems, non-gradient methods (e.g. <code>nm</code> or
<code>sann</code>) can be used to warm start the optimization and zoom in the
neighborhood of the solution. Then a gradient-based methods is recommended
in the second step. In the case of <code>sann</code>, we recommend to significantly
increase the iteration limit (e.g. <code>itermax = 20000</code>). The Conjugate
Gradient (<code>cg</code>) can also be used in the first stage.
</p>
<p>A set of extractor functions for fitted model objects is available for
objects of class <code>'sfalcmcross'</code> including methods to the generic functions
<code><a href="#topic+print.sfalcmcross">print</a></code>,
<code><a href="#topic+summary.sfalcmcross">summary</a></code>,
<code><a href="#topic+coef.sfalcmcross">coef</a></code>,
<code><a href="#topic+fitted.sfalcmcross">fitted</a></code>,
<code><a href="#topic+logLik.sfalcmcross">logLik</a></code>,
<code><a href="#topic+residuals.sfalcmcross">residuals</a></code>,
<code><a href="#topic+vcov.sfalcmcross">vcov</a></code>,
<code><a href="#topic+efficiencies.sfalcmcross">efficiencies</a></code>,
<code><a href="#topic+ic.sfalcmcross">ic</a></code>,
<code><a href="#topic+marginal.sfalcmcross">marginal</a></code>,
<code><a href="#topic+estfun.sfalcmcross">estfun</a></code> and
<code><a href="#topic+bread.sfalcmcross">bread</a></code> (from the <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> package),
<code><a href="lmtest.html#topic+coeftest">lmtest::coeftest()</a></code> (from the <a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> package).
</p>


<h3>Value</h3>

<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code> returns a list of class <code>'sfalcmcross'</code>
containing the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>formula</code></td>
<td>
<p>Multi parts formula describing the estimated model.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>The argument <code>'S'</code>. See the section &lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>typeSfa</code></td>
<td>
<p>Character string. 'Latent Class Production/Profit Frontier, e
= v - u' when <code>S = 1</code> and 'Latent Class Cost Frontier, e = v + u' when
<code>S = -1</code>.</p>
</td></tr>
<tr><td><code>Nobs</code></td>
<td>
<p>Number of observations used for optimization.</p>
</td></tr>
<tr><td><code>nXvar</code></td>
<td>
<p>Number of main explanatory variables.</p>
</td></tr>
<tr><td><code>nZHvar</code></td>
<td>
<p>Number of variables in the logit specification of the finite
mixture model (i.e. number of covariates).</p>
</td></tr>
<tr><td><code>logDepVar</code></td>
<td>
<p>The argument <code>'logDepVar'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>nuZUvar</code></td>
<td>
<p>Number of variables explaining heteroscedasticity in the
one-sided error term.</p>
</td></tr>
<tr><td><code>nvZVvar</code></td>
<td>
<p>Number of variables explaining heteroscedasticity in the
two-sided error term.</p>
</td></tr>
<tr><td><code>nParm</code></td>
<td>
<p>Total number of parameters estimated.</p>
</td></tr>
<tr><td><code>udist</code></td>
<td>
<p>The argument <code>'udist'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>startVal</code></td>
<td>
<p>Numeric vector. Starting value for ML estimation.</p>
</td></tr>
<tr><td><code>dataTable</code></td>
<td>
<p>A data frame (tibble format) containing information on data
used for optimization along with residuals and fitted values of the OLS and
ML estimations, and the individual observation log-likelihood. When
<code>weights</code> is specified an additional variable is also provided in
<code>dataTable</code>.</p>
</td></tr>
<tr><td><code>initHalf</code></td>
<td>
<p>When <code>start = NULL</code> and <code>whichStart == 2L</code>.
Initial ML estimation with half normal distribution for the one-sided error
term. Model to construct the starting values for
the latent class estimation. Object of class <code>'maxLik'</code> and
<code>'maxim'</code> returned.</p>
</td></tr>
<tr><td><code>isWeights</code></td>
<td>
<p>Logical. If <code>TRUE</code> weighted log-likelihood is
maximized.</p>
</td></tr>
<tr><td><code>optType</code></td>
<td>
<p>The optimization algorithm used.</p>
</td></tr>
<tr><td><code>nIter</code></td>
<td>
<p>Number of iterations of the ML estimation.</p>
</td></tr>
<tr><td><code>optStatus</code></td>
<td>
<p>An optimization algorithm termination message.</p>
</td></tr>
<tr><td><code>startLoglik</code></td>
<td>
<p>Log-likelihood at the starting values.</p>
</td></tr>
<tr><td><code>nClasses</code></td>
<td>
<p>The number of classes estimated.</p>
</td></tr>
<tr><td><code>mlLoglik</code></td>
<td>
<p>Log-likelihood value of the ML estimation.</p>
</td></tr>
<tr><td><code>mlParam</code></td>
<td>
<p>Numeric vector. Parameters obtained from ML estimation.</p>
</td></tr>
<tr><td><code>mlParamMatrix</code></td>
<td>
<p>Double. Matrix of ML parameters by class.</p>
</td></tr>
<tr><td><code>gradient</code></td>
<td>
<p>Numeric vector. Each variable gradient of the ML
estimation.</p>
</td></tr>
<tr><td><code>gradL_OBS</code></td>
<td>
<p>Matrix. Each variable individual observation gradient of
the ML estimation.</p>
</td></tr>
<tr><td><code>gradientNorm</code></td>
<td>
<p>Numeric. Gradient norm of the ML estimation.</p>
</td></tr>
<tr><td><code>invHessian</code></td>
<td>
<p>The covariance matrix of the parameters obtained from the
ML estimation.</p>
</td></tr>
<tr><td><code>hessianType</code></td>
<td>
<p>The argument <code>'hessianType'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>mlDate</code></td>
<td>
<p>Date and time of the estimated model.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>In the case of panel data, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code> estimates a pooled
cross-section where the probability of belonging to a class a priori is not
permanent (not fixed over time).
</p>


<h3>References</h3>

<p>Aigner, D., Lovell, C. A. K., and P. Schmidt. 1977. Formulation
and estimation of stochastic frontier production function models.
<em>Journal of Econometrics</em>, <b>6</b>(1), 21&ndash;37.
</p>
<p>Caudill, S. B., and J. M. Ford. 1993. Biases in frontier estimation due to
heteroscedasticity. <em>Economics Letters</em>, <b>41</b>(1), 17&ndash;20.
</p>
<p>Caudill, S. B., Ford, J. M., and D. M. Gropper. 1995. Frontier estimation
and firm-specific inefficiency measures in the presence of
heteroscedasticity. <em>Journal of Business &amp; Economic Statistics</em>,
<b>13</b>(1), 105&ndash;111.
</p>
<p>Hadri, K. 1999. Estimation of a doubly heteroscedastic stochastic frontier
cost function. <em>Journal of Business &amp; Economic Statistics</em>,
<b>17</b>(3), 359&ndash;363.
</p>
<p>Meeusen, W., and J. Vandenbroeck. 1977. Efficiency estimation from
Cobb-Douglas production functions with composed error. <em>International
Economic Review</em>, <b>18</b>(2), 435&ndash;445.
</p>
<p>Orea, L., and S.C. Kumbhakar. 2004. Efficiency measurement using a latent
class stochastic frontier model. <em>Empirical Economics</em>, <b>29</b>,
169&ndash;183.
</p>
<p>Parmeter, C.F., and S.C. Kumbhakar. 2014. Efficiency analysis: A primer on
recent advances. <em>Foundations and Trends in Econometrics</em>, <b>7</b>,
191&ndash;385.
</p>
<p>Reifschneider, D., and R. Stevenson. 1991. Systematic departures from the
frontier: A framework for the analysis of firm inefficiency.
<em>International Economic Review</em>, <b>32</b>(3), 715&ndash;723.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.sfalcmcross">print</a></code> for printing <code>sfalcmcross</code>
object.
</p>
<p><code><a href="#topic+summary.sfalcmcross">summary</a></code> for creating and printing
summary results.
</p>
<p><code><a href="#topic+coef.sfalcmcross">coef</a></code> for extracting coefficients of the
estimation.
</p>
<p><code><a href="#topic+efficiencies.sfalcmcross">efficiencies</a></code> for computing
(in-)efficiency estimates.
</p>
<p><code><a href="#topic+fitted.sfalcmcross">fitted</a></code> for extracting the fitted frontier
values.
</p>
<p><code><a href="#topic+ic.sfalcmcross">ic</a></code> for extracting information criteria.
</p>
<p><code><a href="#topic+logLik.sfalcmcross">logLik</a></code> for extracting log-likelihood
value(s) of the estimation.
</p>
<p><code><a href="#topic+marginal.sfalcmcross">marginal</a></code> for computing marginal effects of
inefficiency drivers.
</p>
<p><code><a href="#topic+residuals.sfalcmcross">residuals</a></code> for extracting residuals of the
estimation.
</p>
<p><code><a href="#topic+vcov.sfalcmcross">vcov</a></code> for computing the variance-covariance
matrix of the coefficients.
</p>
<p><code><a href="#topic+bread.sfalcmcross">bread</a></code> for bread for sandwich estimator.
</p>
<p><code><a href="#topic+estfun.sfalcmcross">estfun</a></code> for gradient extraction for each
observation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Using data on eighty-two countries production (GDP)
# LCM Cobb Douglas (production function) half normal distribution
# Intercept and initStat used as separating variables
cb_2c_h1 &lt;- sfalcmcross(formula = ly ~ lk + ll + yr, thet = ~initStat, 
data = worldprod)
summary(cb_2c_h1)

# summary of the initial ML model
summary(cb_2c_h1$InitHalf)

# Only the intercept is used as the separating variable
# and only variable initStat is used as inefficiency driver
cb_2c_h3 &lt;- sfalcmcross(formula = ly ~ lk + ll + yr, uhet = ~initStat, 
data = worldprod)
summary(cb_2c_h3)

</code></pre>

<hr>
<h2 id='sfaR-deprecated'>Deprecated functions of sfaR</h2><span id='topic+sfaR-deprecated'></span><span id='topic+lcmcross'></span><span id='topic+print.lcmcross'></span><span id='topic+bread.lcmcross'></span><span id='topic+estfun.lcmcross'></span><span id='topic+coef.lcmcross'></span><span id='topic+coef.summary.lcmcross'></span><span id='topic+fitted.lcmcross'></span><span id='topic+ic.lcmcross'></span><span id='topic+logLik.lcmcross'></span><span id='topic+marginal.lcmcross'></span><span id='topic+nobs.lcmcross'></span><span id='topic+residuals.lcmcross'></span><span id='topic+summary.lcmcross'></span><span id='topic+print.summary.lcmcross'></span><span id='topic+efficiencies.lcmcross'></span><span id='topic+vcov.lcmcross'></span>

<h3>Description</h3>

<p>These functions are provided for compatibility with older versions of
&lsquo;sfaR&rsquo; only, and could be defunct at a future release.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcmcross(
  formula,
  uhet,
  vhet,
  thet,
  logDepVar = TRUE,
  data,
  subset,
  weights,
  wscale = TRUE,
  S = 1L,
  udist = "hnormal",
  start = NULL,
  whichStart = 2L,
  initAlg = "nm",
  initIter = 100,
  lcmClasses = 2,
  method = "bfgs",
  hessianType = 1,
  itermax = 2000L,
  printInfo = FALSE,
  tol = 1e-12,
  gradtol = 1e-06,
  stepmax = 0.1,
  qac = "marquardt"
)

## S3 method for class 'lcmcross'
print(x, ...)

## S3 method for class 'lcmcross'
bread(x, ...)

## S3 method for class 'lcmcross'
estfun(x, ...)

## S3 method for class 'lcmcross'
coef(object, extraPar = FALSE, ...)

## S3 method for class 'summary.lcmcross'
coef(object, ...)

## S3 method for class 'lcmcross'
fitted(object, ...)

## S3 method for class 'lcmcross'
ic(object, IC = "AIC", ...)

## S3 method for class 'lcmcross'
logLik(object, individual = FALSE, ...)

## S3 method for class 'lcmcross'
marginal(object, newData = NULL, ...)

## S3 method for class 'lcmcross'
nobs(object, ...)

## S3 method for class 'lcmcross'
residuals(object, ...)

## S3 method for class 'lcmcross'
summary(object, grad = FALSE, ci = FALSE, ...)

## S3 method for class 'summary.lcmcross'
print(x, digits = max(3, getOption("digits") - 2), ...)

## S3 method for class 'lcmcross'
efficiencies(object, level = 0.95, newData = NULL, ...)

## S3 method for class 'lcmcross'
vcov(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sfaR-deprecated_+3A_formula">formula</code></td>
<td>
<p>A symbolic description of the model to be estimated based on
the generic function <code>formula</code> (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_uhet">uhet</code></td>
<td>
<p>A one-part formula to account for heteroscedasticity in the
one-sided error variance (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_vhet">vhet</code></td>
<td>
<p>A one-part formula to account for heteroscedasticity in the
two-sided error variance (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_thet">thet</code></td>
<td>
<p>A one-part formula to account for technological heterogeneity in
the construction of the classes.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_logdepvar">logDepVar</code></td>
<td>
<p>Logical. Informs whether the dependent variable is logged
(<code>TRUE</code>) or not (<code>FALSE</code>). Default = <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_data">data</code></td>
<td>
<p>The data frame containing the data.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_subset">subset</code></td>
<td>
<p>An optional vector specifying a subset of observations to be
used in the optimization process.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_weights">weights</code></td>
<td>
<p>An optional vector of weights to be used for weighted
log-likelihood. Should be <code>NULL</code> or numeric vector with positive values.
When <code>NULL</code>, a numeric vector of 1 is used.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_wscale">wscale</code></td>
<td>
<p>Logical. When <code>weights</code> is not <code>NULL</code>, a scaling
transformation is used such that the <code>weights</code> sums to the sample
size. Default <code>TRUE</code>. When <code>FALSE</code> no scaling is used.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_s">S</code></td>
<td>
<p>If <code>S = 1</code> (default), a production (profit) frontier is
estimated: <code class="reqn">\epsilon_i = v_i-u_i</code>. If <code>S = -1</code>, a cost frontier is
estimated: <code class="reqn">\epsilon_i = v_i+u_i</code>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_udist">udist</code></td>
<td>
<p>Character string. Distribution specification for the one-sided
error term. Only the half normal distribution <code>'hnormal'</code> (Aigner
<em>et al.</em>, 1977, Meeusen and Vandenbroeck, 1977) is currently
implemented.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_start">start</code></td>
<td>
<p>Numeric vector. Optional starting values for the maximum
likelihood (ML) estimation.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_whichstart">whichStart</code></td>
<td>
<p>Integer. If <code>'whichStart = 1'</code>, the starting values
are obtained from the method of moments. When <code>'whichStart = 2'</code>
(Default), the model is initialized by solving the homoscedastic pooled
cross section SFA model. <code>'whichStart = 1'</code> can be fast.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_initalg">initAlg</code></td>
<td>
<p>Character string specifying the algorithm used for
initialization and obtain the starting values (when <code>'whichStart = 2'</code>).
Only <span class="pkg">maxLik</span> package algorithms are available:
</p>
 <ul>
<li> <p><code>'bfgs'</code>, for Broyden-Fletcher-Goldfarb-Shanno
(see <code><a href="maxLik.html#topic+maxBFGS">maxBFGS</a></code>)
</p>
</li>
<li> <p><code>'bhhh'</code>, for Berndt-Hall-Hall-Hausman
(see <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code>)
</p>
</li>
<li> <p><code>'nr'</code>, for Newton-Raphson (see <code><a href="maxLik.html#topic+maxNR">maxNR</a></code>)
</p>
</li>
<li> <p><code>'nm'</code>, for Nelder-Mead - Default -
(see <code><a href="maxLik.html#topic+maxNM">maxNM</a></code>)
</p>
</li>
<li> <p><code>'cg'</code>, for Conjugate Gradient
(see <code><a href="maxLik.html#topic+maxCG">maxCG</a></code>) </p>
</li>
<li> <p><code>'sann'</code>, for Simulated
Annealing (see <code><a href="maxLik.html#topic+maxSANN">maxSANN</a></code>)
</p>
</li></ul>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_inititer">initIter</code></td>
<td>
<p>Maximum number of iterations for initialization algorithm.
Default <code>100</code>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_lcmclasses">lcmClasses</code></td>
<td>
<p>Number of classes to be estimated (default = <code>2</code>). A
maximum of five classes can be estimated.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_method">method</code></td>
<td>
<p>Optimization algorithm used for the estimation.  Default =
<code>'bfgs'</code>. 11 algorithms are available: </p>
 <ul>
<li> <p><code>'bfgs'</code>,
for Broyden-Fletcher-Goldfarb-Shanno (see
<code><a href="maxLik.html#topic+maxBFGS">maxBFGS</a></code>) </p>
</li>
<li> <p><code>'bhhh'</code>, for
Berndt-Hall-Hall-Hausman (see <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code>) </p>
</li>
<li>
<p><code>'nr'</code>, for Newton-Raphson (see <code><a href="maxLik.html#topic+maxNR">maxNR</a></code>)
</p>
</li>
<li> <p><code>'nm'</code>, for Nelder-Mead (see <code><a href="maxLik.html#topic+maxNM">maxNM</a></code>)
</p>
</li>
<li> <p><code>'cg'</code>, for Conjugate Gradient
(see <code><a href="maxLik.html#topic+maxCG">maxCG</a></code>) </p>
</li>
<li> <p><code>'sann'</code>, for Simulated
Annealing (see <code><a href="maxLik.html#topic+maxSANN">maxSANN</a></code>)
</p>
</li>
<li> <p><code>'ucminf'</code>, for a quasi-Newton type optimization with BFGS updating of
the inverse Hessian and soft line search with a trust region type monitoring
of the input to the line search algorithm
(see <code><a href="ucminf.html#topic+ucminf">ucminf</a></code>)
</p>
</li>
<li> <p><code>'mla'</code>, for general-purpose optimization based on
Marquardt-Levenberg algorithm (see <code><a href="marqLevAlg.html#topic+mla">mla</a></code>)
</p>
</li>
<li> <p><code>'sr1'</code>, for Symmetric Rank 1 (see
<code><a href="trustOptim.html#topic+trust.optim">trust.optim</a></code>) </p>
</li>
<li> <p><code>'sparse'</code>,
for trust regions and sparse Hessian
(see <code><a href="trustOptim.html#topic+trust.optim">trust.optim</a></code>) </p>
</li>
<li>
<p><code>'nlminb'</code>, for optimization using PORT routines (see
<code><a href="stats.html#topic+nlminb">nlminb</a></code>)</p>
</li></ul>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_hessiantype">hessianType</code></td>
<td>
<p>Integer. If <code>1</code> (default), analytic Hessian is
returned. If <code>2</code>, bhhh Hessian is estimated (<code class="reqn">g'g</code>).</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_itermax">itermax</code></td>
<td>
<p>Maximum number of iterations allowed for optimization.
Default = <code>2000</code>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_printinfo">printInfo</code></td>
<td>
<p>Logical. Print information during optimization. Default =
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_tol">tol</code></td>
<td>
<p>Numeric. Convergence tolerance. Default = <code>1e-12</code>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_gradtol">gradtol</code></td>
<td>
<p>Numeric. Convergence tolerance for gradient. Default =
<code>1e-06</code>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_stepmax">stepmax</code></td>
<td>
<p>Numeric. Step max for <code>ucminf</code> algorithm. Default =
<code>0.1</code>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_qac">qac</code></td>
<td>
<p>Character. Quadratic Approximation Correction for <code>'bhhh'</code>
and <code>'nr'</code> algorithms. If <code>'qac = stephalving'</code>, the step length
is decreased but the direction is kept. If <code>'qac = marquardt'</code>
(default), the step length is decreased while also moving closer to the pure
gradient direction. See <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code> and
<code><a href="maxLik.html#topic+maxNR">maxNR</a></code>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_x">x</code></td>
<td>
<p>an object of class lcmcross (returned by the function
<code><a href="#topic+lcmcross">lcmcross</a></code>).</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_...">...</code></td>
<td>
<p>additional arguments of frontier are passed to lcmcross;
additional arguments of the print, bread, estfun, nobs methods are currently
ignored.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_object">object</code></td>
<td>
<p>an object of class lcmcross (returned by the function
<code><a href="#topic+lcmcross">lcmcross</a></code>).</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_extrapar">extraPar</code></td>
<td>
<p>Logical (default = <code>FALSE</code>). If <code>TRUE</code>, additional
parameters are returned (see <code><a href="#topic+coef">coef</a></code> or <code><a href="#topic+vcov">vcov</a></code>).</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_ic">IC</code></td>
<td>
<p>Character string. Information criterion measure. Three criteria
are available: </p>
 <ul>
<li> <p><code>'AIC'</code> for Akaike information criterion
(default) </p>
</li>
<li> <p><code>'BIC'</code> for Bayesian information criterion </p>
</li>
<li>
<p><code>'HQIC'</code> for Hannan-Quinn information criterion </p>
</li></ul>
<p>.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_individual">individual</code></td>
<td>
<p>Logical. If <code>FALSE</code> (default), the sum of all
observations' log-likelihood values is returned. If <code>TRUE</code>, a vector of
each observation's log-likelihood value is returned.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_newdata">newData</code></td>
<td>
<p>Optional data frame that is used to calculate the efficiency
estimates. If NULL (the default), the efficiency estimates are calculated
for the observations that were used in the estimation.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_grad">grad</code></td>
<td>
<p>Logical. Default = <code>FALSE</code>. If <code>TRUE</code>, the gradient
for the maximum likelihood (ML) estimates of the different parameters is
returned.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_ci">ci</code></td>
<td>
<p>Logical. Default = <code>FALSE</code>. If <code>TRUE</code>, the 95%
confidence interval for the different parameters (OLS or/and ML estimates) is
returned.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_digits">digits</code></td>
<td>
<p>Numeric. Number of digits displayed in values.</p>
</td></tr>
<tr><td><code id="sfaR-deprecated_+3A_level">level</code></td>
<td>
<p>A number between between 0 and 0.9999 used for the computation
of (in-)efficiency confidence intervals (defaut = <code>0.95</code>). Not used in the
case of <code>lcmcross</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The following functions are deprecated and could be removed from <span class="pkg">sfaR</span>
in a near future. Use the replacement indicated below:
</p>

<ul>
<li><p>lcmcross: <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>
</p>
</li>
<li><p>bread.lcmcross: <code><a href="#topic+bread.sfalcmcross">bread.sfalcmcross</a></code>
</p>
</li>
<li><p>coef.lcmcross: <code><a href="#topic+coef.sfalcmcross">coef.sfalcmcross</a></code>
</p>
</li>
<li><p>coef.summary.lcmcross: <code><a href="#topic+coef.summary.sfalcmcross">coef.summary.sfalcmcross</a></code>
</p>
</li>
<li><p>efficiencies.lcmcross: <code><a href="#topic+efficiencies.sfalcmcross">efficiencies.sfalcmcross</a></code>
</p>
</li>
<li><p>estfun.lcmcross: <code><a href="#topic+estfun.sfalcmcross">estfun.sfalcmcross</a></code>
</p>
</li>
<li><p>fitted.lcmcross: <code><a href="#topic+fitted.sfalcmcross">fitted.sfalcmcross</a></code>
</p>
</li>
<li><p>ic.lcmcross: <code><a href="#topic+ic.sfalcmcross">ic.sfalcmcross</a></code>
</p>
</li>
<li><p>logLik.lcmcross: <code><a href="#topic+logLik.sfalcmcross">logLik.sfalcmcross</a></code>
</p>
</li>
<li><p>marginal.lcmcross: <code><a href="#topic+marginal.sfalcmcross">marginal.sfalcmcross</a></code>
</p>
</li>
<li><p>nobs.lcmcross: <code><a href="#topic+nobs.sfalcmcross">nobs.sfalcmcross</a></code>
</p>
</li>
<li><p>print.lcmcross: <code><a href="#topic+print.sfalcmcross">print.sfalcmcross</a></code>
</p>
</li>
<li><p>print.summary.lcmcross: <code><a href="#topic+print.summary.sfalcmcross">print.summary.sfalcmcross</a></code>
</p>
</li>
<li><p>residuals.lcmcross: <code><a href="#topic+residuals.sfalcmcross">residuals.sfalcmcross</a></code>
</p>
</li>
<li><p>summary.lcmcross: <code><a href="#topic+summary.sfalcmcross">summary.sfalcmcross</a></code>
</p>
</li>
<li><p>vcov.lcmcross: <code><a href="#topic+vcov.sfalcmcross">vcov.sfalcmcross</a></code>
</p>
</li></ul>


<hr>
<h2 id='sfaR-package'>sfaR: A package for estimating stochastic frontier models</h2><span id='topic+sfaR-package'></span><span id='topic+sfaR'></span>

<h3>Description</h3>

<p>The <span class="pkg">sfaR</span> package provides a set of tools (maximum likelihood - ML and
maximum simulated likelihood - MSL) for various specifications of stochastic
frontier analysis (SFA).
</p>


<h3>Details</h3>

<p>Three categories of functions are available: <code><a href="#topic+sfacross">sfacross</a></code>,
<code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>,
which estimate different types of frontiers and offer eleven alternative
optimization algorithms (i.e., &quot;bfgs&quot;, &quot;bhhh&quot;, &quot;nr&quot;, &quot;nm&quot;, &quot;cg&quot;, &quot;sann&quot;,
&quot;ucminf&quot;, &quot;mla&quot;, &quot;sr1&quot;, &quot;sparse&quot;, &quot;nlminb&quot;).
</p>


<h3>sfacross</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code> estimates the basic stochastic
frontier analysis (SFA) for cross-sectional or pooled data and allows for
ten different distributions for the one-sided error term. These distributions
include the exponential, the gamma, the generalized exponential,
the half normal, the lognormal, the truncated normal, the truncated skewed
Laplace, the Rayleigh, the uniform, and the Weibull distributions.
In the case of the gamma, lognormal, and Weibull distributions, maximum
simulated likelihood (MSL) is used with the possibility of four specific
distributions to construct the draws: halton, generalized halton, sobol and
uniform. Heteroscedasticity in both error terms can be implemented, in
addition to heterogeneity in the truncated mean parameter in the case of the
truncated normal and lognormal distributions. In addition, in the case of the
truncated normal distribution, the scaling property can be estimated.
</p>


<h3>sfalcmcross</h3>

<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code> estimates latent class
stochastic frontier models (LCM) for cross-sectional or pooled data.
It accounts for technological heterogeneity by splitting the observations
into a maximum number of five classes. The classification operates based on
a logit functional form that can be specified using some covariates (namely,
the separating variables allowing the separation of observations in several
classes). Only the half normal distribution is available for the one-sided
error term. Heteroscedasticity in both error terms is possible. The choice of
the number of classes can be guided by several information criteria (i.e.,
AIC, BIC, or HQIC).
</p>


<h3>sfaselectioncross</h3>

<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> estimates the
frontier for cross-sectional or pooled data in the presence of sample
selection. The model solves the selection bias due to the correlation
between the two-sided error terms in both the selection and the frontier
equations. The likelihood can be estimated using five different
possibilities: gauss-kronrod quadrature, adaptive integration over hypercubes
(hcubature and pcubature), gauss-hermite quadrature, and
maximum simulated likelihood. Only the half normal
distribution is available for the one-sided error term. Heteroscedasticity
in both error terms is possible.
</p>


<h3>Bugreport</h3>

<p>Any bug or suggestion can be reported using the
<code>sfaR</code> tracker facilities at:
<a href="https://github.com/hdakpo/sfaR/issues">https://github.com/hdakpo/sfaR/issues</a>
</p>


<h3>Author(s)</h3>

<p>K Hervé Dakpo, Yann Desjeux, Arne Henningsen and Laure Latruffe
</p>

<hr>
<h2 id='sfaselectioncross'>Sample selection in stochastic frontier estimation using cross-section data</h2><span id='topic+sfaselectioncross'></span><span id='topic+print.sfaselectioncross'></span><span id='topic+bread.sfaselectioncross'></span><span id='topic+estfun.sfaselectioncross'></span>

<h3>Description</h3>

<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> is a symbolic formula based function for the
estimation of the stochastic frontier model in the presence of sample
selection. The model accommodates cross-sectional or pooled cross-sectional data.
The model can be estimated using different quadrature approaches or
maximum simulated likelihood (MSL). See Greene (2010).
</p>
<p>Only the half-normal distribution is possible for the one-sided error term.
Eleven optimization algorithms are available.
</p>
<p>The function also accounts for heteroscedasticity in both one-sided and
two-sided error terms, as in Reifschneider and Stevenson (1991), Caudill and
Ford (1993), Caudill <em>et al.</em> (1995) and Hadri (1999).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sfaselectioncross(
  selectionF,
  frontierF,
  uhet,
  vhet,
  modelType = "greene10",
  logDepVar = TRUE,
  data,
  subset,
  weights,
  wscale = TRUE,
  S = 1L,
  udist = "hnormal",
  start = NULL,
  method = "bfgs",
  hessianType = 2L,
  lType = "ghermite",
  Nsub = 100,
  uBound = Inf,
  simType = "halton",
  Nsim = 100,
  prime = 2L,
  burn = 10,
  antithetics = FALSE,
  seed = 12345,
  itermax = 2000,
  printInfo = FALSE,
  intol = 1e-06,
  tol = 1e-12,
  gradtol = 1e-06,
  stepmax = 0.1,
  qac = "marquardt"
)

## S3 method for class 'sfaselectioncross'
print(x, ...)

## S3 method for class 'sfaselectioncross'
bread(x, ...)

## S3 method for class 'sfaselectioncross'
estfun(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sfaselectioncross_+3A_selectionf">selectionF</code></td>
<td>
<p>A symbolic (formula) description of the selection equation.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_frontierf">frontierF</code></td>
<td>
<p>A symbolic (formula) description of the outcome (frontier) equation.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_uhet">uhet</code></td>
<td>
<p>A one-part formula to consider heteroscedasticity in the
one-sided error variance (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_vhet">vhet</code></td>
<td>
<p>A one-part formula to consider heteroscedasticity in the
two-sided error variance (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_modeltype">modelType</code></td>
<td>
<p>Character string. Model used to solve the selection bias. Only the
model discussed in Greene (2010) is currently available.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_logdepvar">logDepVar</code></td>
<td>
<p>Logical. Informs whether the dependent variable is logged
(<code>TRUE</code>) or not (<code>FALSE</code>). Default = <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_data">data</code></td>
<td>
<p>The data frame containing the data.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_subset">subset</code></td>
<td>
<p>An optional vector specifying a subset of observations to be
used in the optimization process.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_weights">weights</code></td>
<td>
<p>An optional vector of weights to be used for weighted log-likelihood.
Should be <code>NULL</code> or numeric vector with positive values. When <code>NULL</code>,
a numeric vector of 1 is used.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_wscale">wscale</code></td>
<td>
<p>Logical. When <code>weights</code> is not <code>NULL</code>, a scaling transformation
is used such that the <code>weights</code> sum to the sample size. Default <code>TRUE</code>.
When <code>FALSE</code> no scaling is used.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_s">S</code></td>
<td>
<p>If <code>S = 1</code> (default), a production (profit) frontier is
estimated: <code class="reqn">\epsilon_i = v_i-u_i</code>. If <code>S = -1</code>, a cost frontier is
estimated: <code class="reqn">\epsilon_i = v_i+u_i</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_udist">udist</code></td>
<td>
<p>Character string. Distribution specification for the one-sided
error term. Only the half normal distribution <code>'hnormal'</code> is currently
implemented.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_start">start</code></td>
<td>
<p>Numeric vector. Optional starting values for the maximum
likelihood (ML) estimation.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_method">method</code></td>
<td>
<p>Optimization algorithm used for the estimation.  Default =
<code>'bfgs'</code>. 11 algorithms are available: </p>
 <ul>
<li> <p><code>'bfgs'</code>,
for Broyden-Fletcher-Goldfarb-Shanno (see
<code><a href="maxLik.html#topic+maxBFGS">maxBFGS</a></code>) </p>
</li>
<li> <p><code>'bhhh'</code>, for
Berndt-Hall-Hall-Hausman (see <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code>) </p>
</li>
<li>
<p><code>'nr'</code>, for Newton-Raphson (see <code><a href="maxLik.html#topic+maxNR">maxNR</a></code>)
</p>
</li>
<li> <p><code>'nm'</code>, for Nelder-Mead (see <code><a href="maxLik.html#topic+maxNM">maxNM</a></code>)
</p>
</li>
<li> <p><code>'cg'</code>, for Conjugate Gradient (see <code><a href="maxLik.html#topic+maxCG">maxCG</a></code>)
</p>
</li>
<li> <p><code>'sann'</code>, for Simulated Annealing (see <code><a href="maxLik.html#topic+maxSANN">maxSANN</a></code>)
</p>
</li>
<li> <p><code>'ucminf'</code>, for a quasi-Newton type optimization with BFGS updating of the
inverse Hessian and soft line search with a trust region type monitoring of
the input to the line search algorithm (see <code><a href="ucminf.html#topic+ucminf">ucminf</a></code>)
</p>
</li>
<li> <p><code>'mla'</code>, for general-purpose optimization based on
Marquardt-Levenberg algorithm (see <code><a href="marqLevAlg.html#topic+mla">mla</a></code>)
</p>
</li>
<li> <p><code>'sr1'</code>, for Symmetric Rank 1 (see
<code><a href="trustOptim.html#topic+trust.optim">trust.optim</a></code>) </p>
</li>
<li> <p><code>'sparse'</code>, for trust
regions and sparse Hessian (see <code><a href="trustOptim.html#topic+trust.optim">trust.optim</a></code>) </p>
</li>
<li>
<p><code>'nlminb'</code>, for optimization using PORT routines (see
<code><a href="stats.html#topic+nlminb">nlminb</a></code>)</p>
</li></ul>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_hessiantype">hessianType</code></td>
<td>
<p>Integer. If <code>1</code>, analytic Hessian is
returned. If <code>2</code>, bhhh Hessian is estimated (<code class="reqn">g'g</code>). bhhh hessian is
estimated by default as the estimation is conducted in two steps.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_ltype">lType</code></td>
<td>
<p>Specifies the way the likelihood is estimated. Five possibilities are
available: <code>kronrod</code> for Gauss-Kronrod quadrature
(see <code><a href="stats.html#topic+integrate">integrate</a></code>), <code>hcubature</code> and
<code>pcubature</code> for adaptive integration over hypercubes
(see <code><a href="cubature.html#topic+hcubature">hcubature</a></code> and
<code><a href="cubature.html#topic+pcubature">pcubature</a></code>), <code>ghermite</code> for Gauss-Hermite
quadrature (see <code><a href="fastGHQuad.html#topic+gaussHermiteData">gaussHermiteData</a></code>), and
<code>msl</code> for maximum simulated likelihood. Default <code>ghermite</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_nsub">Nsub</code></td>
<td>
<p>Integer. Number of subdivisions/nodes used for quadrature approaches.
Default <code>Nsub = 100</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_ubound">uBound</code></td>
<td>
<p>Numeric. Upper bound for the inefficiency component when solving
integrals using quadrature approaches except Gauss-Hermite for which the upper
bound is automatically infinite (<code>Inf</code>). Default <code>uBound = Inf</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_simtype">simType</code></td>
<td>
<p>Character string. If <code>simType = 'halton'</code> (Default),
Halton draws are used for maximum simulated likelihood (MSL). If
<code>simType = 'ghalton'</code>, Generalized-Halton draws are used for MSL. If
<code>simType = 'sobol'</code>, Sobol draws are used for MSL. If <code>simType =
'uniform'</code>, uniform draws are used for MSL. (see section &lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_nsim">Nsim</code></td>
<td>
<p>Number of draws for MSL (default 100).</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_prime">prime</code></td>
<td>
<p>Prime number considered for Halton and Generalized-Halton
draws. Default = <code>2</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_burn">burn</code></td>
<td>
<p>Number of the first observations discarded in the case of Halton
draws. Default = <code>10</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_antithetics">antithetics</code></td>
<td>
<p>Logical. Default = <code>FALSE</code>. If <code>TRUE</code>,
antithetics counterpart of the uniform draws is computed. (see section
&lsquo;Details&rsquo;).</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_seed">seed</code></td>
<td>
<p>Numeric. Seed for the random draws.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_itermax">itermax</code></td>
<td>
<p>Maximum number of iterations allowed for optimization.
Default = <code>2000</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_printinfo">printInfo</code></td>
<td>
<p>Logical. Print information during optimization. Default =
<code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_intol">intol</code></td>
<td>
<p>Numeric. Integration tolerance for quadrature approaches
(<code>kronrod, hcubature, pcubature</code>).</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_tol">tol</code></td>
<td>
<p>Numeric. Convergence tolerance. Default = <code>1e-12</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_gradtol">gradtol</code></td>
<td>
<p>Numeric. Convergence tolerance for gradient. Default =
<code>1e-06</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_stepmax">stepmax</code></td>
<td>
<p>Numeric. Step max for <code>ucminf</code> algorithm. Default =
<code>0.1</code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_qac">qac</code></td>
<td>
<p>Character. Quadratic Approximation Correction for <code>'bhhh'</code>
and <code>'nr'</code> algorithms. If <code>'stephalving'</code>, the step length is
decreased but the direction is kept. If <code>'marquardt'</code> (default), the
step length is decreased while also moving closer to the pure gradient
direction. See <code><a href="maxLik.html#topic+maxBHHH">maxBHHH</a></code> and
<code><a href="maxLik.html#topic+maxNR">maxNR</a></code>.</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_x">x</code></td>
<td>
<p>an object of class sfaselectioncross (returned by the function <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>).</p>
</td></tr>
<tr><td><code id="sfaselectioncross_+3A_...">...</code></td>
<td>
<p>additional arguments of frontier are passed to sfaselectioncross;
additional arguments of the print, bread, estfun, nobs methods are currently ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The current model is an extension of Heckman (1976, 1979) sample selection model to
nonlinear models particularly stochastic frontier model. The model has first been discussed in
Greene (2010), and an application can be found in Dakpo et al. (2021). Practically, we have:
</p>
<p style="text-align: center;"><code class="reqn">
y_{1i} =  \left\{ \begin{array}{ll}
1 &amp; \mbox{if} \quad y_{1i}^* &gt; 0  \\
0 &amp; \mbox{if} \quad y_{1i}^* \leq 0 \\
\end{array}
\right.
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
y_{1i}^*=\mathbf{Z}_{si}^{\prime} \mathbf{\gamma} + w_i, \quad 
w_i \sim \mathcal{N}(0, 1)
</code>
</p>

<p>and
</p>
<p style="text-align: center;"><code class="reqn">
y_{2i} =  \left\{ \begin{array}{ll}
y_{2i}^* &amp; \mbox{if} \quad y_{1i}^* &gt; 0  \\
NA &amp; \mbox{if} \quad y_{1i}^* \leq 0 \\
\end{array}
\right.
</code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn">
y_{2i}^*=\mathbf{x_{i}^{\prime}} \mathbf{\beta} + v_i - Su_i, \quad 
v_i = \sigma_vV_i \quad \wedge \quad V_i \sim \mathcal{N}(0, 1), \quad 
u_i = \sigma_u|U_i| \quad \wedge \quad U_i \sim \mathcal{N}(0, 1)
</code>
</p>

<p><code class="reqn">y_{1i}</code> describes the selection equation while <code class="reqn">y_{2i}</code> represents
the frontier equation. The selection bias arises from the correlation
between the two symmetric random components <code class="reqn">v_i</code> and <code class="reqn">w_i</code>:
</p>
<p style="text-align: center;"><code class="reqn">
(v_i, w_i) \sim \mathcal{N}_2\left\lbrack(0,0), (1, \rho \sigma_v, \sigma_v^2) \right\rbrack
</code>
</p>

<p>Conditionaly on <code class="reqn">|U_i|</code>, the probability associated to each observation is:
</p>
<p style="text-align: center;"><code class="reqn">
Pr \left\lbrack y_{1i}^* \leq 0 \right\rbrack^{1-y_{1i}} \cdot \left\lbrace 
f(y_{2i}|y_{1i}^* &gt; 0) \times Pr\left\lbrack y_{1i}^* &gt; 0 
\right\rbrack \right\rbrace^{y_{1i}}
</code>
</p>

<p>Using the conditional probability formula:
</p>
<p style="text-align: center;"><code class="reqn">
P\left(A\cap B\right) = P(A) \cdot P(B|A) = P(B) \cdot P(A|B)
</code>
</p>

<p>Therefore:
</p>
<p style="text-align: center;"><code class="reqn">
f(y_{2i}|y_{1i}^* \geq 0) \cdot Pr\left\lbrack y_{1i}^* \geq 0\right\rbrack = 
f(y_{2i}) \cdot Pr(y_{1i}^* \geq 0|y_{2i})
</code>
</p>

<p>Using the properties of a bivariate normal distribution, we have:
</p>
<p style="text-align: center;"><code class="reqn">
y_{i1}^* | y_{i2} \sim N\left(\mathbf{Z_{si}^{\prime}} \bm{\gamma}+\frac{\rho}{
\sigma_v}v_i, 1-\rho^2\right)
</code>
</p>

<p>Hence conditionally on <code class="reqn">|U_i|</code>, we have:
</p>
<p style="text-align: center;"><code class="reqn">
f(y_{2i}|y_{1i}^* \geq 0) \cdot Pr\left\lbrack y_{1i}^* \geq 0\right\rbrack = 
\frac{1}{\sigma_v}\phi\left(\frac{v_i}{\sigma_v}\right)\Phi\left(\frac{
\mathbf{Z_{si}^{\prime}} \bm{\gamma}+\frac{\rho}{\sigma_v}v_i}{
\sqrt{1-\rho^2}}\right)
</code>
</p>

<p>The conditional likelihood is equal to:
</p>
<p style="text-align: center;"><code class="reqn">
L_i\big||U_i| = \Phi(-\mathbf{Z_{si}^{\prime}} \bm{\gamma})^{1-y_{1i}} \times 
\left\lbrace \frac{1}{\sigma_v}\phi\left(\frac{y_{2i}-\mathbf{x_{i}^{\prime}} 
\bm{\beta} + S\sigma_u|U_i|}{\sigma_v}\right)\Phi\left(\frac{
\mathbf{Z_{si}^{\prime}} \bm{\gamma}+\frac{\rho}{\sigma_v}\left(y_{2i}-
\mathbf{x_{i}^{\prime}} \bm{\beta} + S\sigma_u|U_i|\right)}{\sqrt{1-\rho^2}}
\right) \right\rbrace ^{y_{1i}}
</code>
</p>

<p>Since the non-selected observations bring no additional information,
the conditional likelihood to be considered is:
</p>
<p style="text-align: center;"><code class="reqn">
L_i\big||U_i| = \frac{1}{\sigma_v}\phi\left(\frac{y_{2i}-\mathbf{x_{i}^{\prime}} 
\bm{\beta} + S\sigma_u|U_i|}{\sigma_v}\right) \Phi\left(\frac{\mathbf{Z_{si}^{\prime}} 
\bm{\gamma}+\frac{\rho}{\sigma_v}\left(y_{2i}-\mathbf{x_{i}^{\prime}} \bm{\beta} + 
S\sigma_u|U_i|\right)}{\sqrt{1-\rho^2}}\right) 
</code>
</p>

<p>The unconditional likelihood is obtained by integrating <code class="reqn">|U_i|</code> out of the conditional likelihood. Thus
</p>
<p style="text-align: center;"><code class="reqn">
L_i\\ = \int_{|U_i|} \frac{1}{\sigma_v}\phi\left(\frac{y_{2i}-\mathbf{x_{i}^{\prime}} 
\bm{\beta} + S\sigma_u|U_i|}{\sigma_v}\right) \Phi\left(\frac{\mathbf{Z_{si}^{\prime}} 
\bm{\gamma}+ \frac{\rho}{\sigma_v}\left(y_{2i}-\mathbf{x_{i}^{\prime}} \bm{\beta} + 
S\sigma_u|U_i|\right)}{\sqrt{1-\rho^2}}\right)p\left(|U_i|\right)d|U_i|
</code>
</p>

<p>To simplifiy the estimation, the likelihood can be estimated using a two-step approach.
In the first step, the probit model can be run and estimate of <code class="reqn">\gamma</code> can be obtained.
Then, in the second step, the following model is estimated:
</p>
<p style="text-align: center;"><code class="reqn">
L_i\\ = \int_{|U_i|} \frac{1}{\sigma_v}\phi\left(\frac{y_{2i}-\mathbf{x_{i}^{\prime}} 
\bm{\beta} + S\sigma_u|U_i|}{\sigma_v}\right) \Phi\left(\frac{a_i + 
\frac{\rho}{\sigma_v}\left(y_{2i}-\mathbf{x_{i}^{\prime}} \bm{\beta} + 
S\sigma_u|U_i|\right)}{\sqrt{1-\rho^2}}\right)p\left(|U_i|\right)d|U_i| 
</code>
</p>

<p>where <code class="reqn">a_i = \mathbf{Z_{si}^{\prime}} \hat{\bm{\gamma}}</code>. This likelihood can be estimated using
five different approaches: Gauss-Kronrod quadrature, adaptive integration over hypercubes
(hcubature and pcubature), Gauss-Hermite quadrature, and
maximum simulated likelihood. We also use the BHHH estimator to obtain
the asymptotic standard errors for the parameter estimators.
</p>
<p><code>sfaselectioncross</code> allows for the maximization of weighted log-likelihood.
When option <code>weights</code> is specified and <code>wscale = TRUE</code>, the weights
are scaled as:
</p>
<p style="text-align: center;"><code class="reqn">
new_{weights} = sample_{size} \times \frac{old_{weights}}{\sum(old_{weights})}
</code>
</p>

<p>For complex problems, non-gradient methods (e.g. <code>nm</code> or <code>sann</code>) can be
used to warm start the optimization and zoom in the neighborhood of the
solution. Then a gradient-based methods is recommended in the second step. In the case
of <code>sann</code>, we recommend to significantly increase the iteration limit
(e.g. <code>itermax = 20000</code>). The Conjugate Gradient (<code>cg</code>) can also be used
in the first stage.
</p>
<p>A set of extractor functions for fitted model objects is available for objects of class
<code>'sfaselectioncross'</code> including methods to the generic functions <code><a href="#topic+print.sfaselectioncross">print</a></code>,
<code><a href="#topic+summary.sfaselectioncross">summary</a></code>, <code><a href="#topic+coef.sfaselectioncross">coef</a></code>,
<code><a href="#topic+fitted.sfaselectioncross">fitted</a></code>, <code><a href="#topic+logLik.sfaselectioncross">logLik</a></code>,
<code><a href="#topic+residuals.sfaselectioncross">residuals</a></code>, <code><a href="#topic+vcov.sfaselectioncross">vcov</a></code>,
<code><a href="#topic+efficiencies.sfaselectioncross">efficiencies</a></code>, <code><a href="#topic+ic.sfaselectioncross">ic</a></code>,
<code><a href="#topic+marginal.sfaselectioncross">marginal</a></code>,
<code><a href="#topic+estfun.sfaselectioncross">estfun</a></code> and
<code><a href="#topic+bread.sfaselectioncross">bread</a></code> (from the <a href="https://CRAN.R-project.org/package=sandwich"><span class="pkg">sandwich</span></a> package),
<code><a href="lmtest.html#topic+coeftest">lmtest::coeftest()</a></code> (from the <a href="https://CRAN.R-project.org/package=lmtest"><span class="pkg">lmtest</span></a> package).
</p>


<h3>Value</h3>

<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> returns a list of class <code>'sfaselectioncross'</code>
containing the following elements:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The matched call.</p>
</td></tr>
<tr><td><code>selectionF</code></td>
<td>
<p>The selection equation formula.</p>
</td></tr>
<tr><td><code>frontierF</code></td>
<td>
<p>The frontier equation formula.</p>
</td></tr>
<tr><td><code>S</code></td>
<td>
<p>The argument <code>'S'</code>. See the section &lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>typeSfa</code></td>
<td>
<p>Character string. 'Stochastic Production/Profit Frontier, e =
v - u' when <code>S = 1</code> and 'Stochastic Cost Frontier, e = v + u' when
<code>S = -1</code>.</p>
</td></tr>
<tr><td><code>Ninit</code></td>
<td>
<p>Number of initial observations in all samples.</p>
</td></tr>
<tr><td><code>Nobs</code></td>
<td>
<p>Number of observations used for optimization.</p>
</td></tr>
<tr><td><code>nXvar</code></td>
<td>
<p>Number of explanatory variables in the production or cost
frontier.</p>
</td></tr>
<tr><td><code>logDepVar</code></td>
<td>
<p>The argument <code>'logDepVar'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>nuZUvar</code></td>
<td>
<p>Number of variables explaining heteroscedasticity in the
one-sided error term.</p>
</td></tr>
<tr><td><code>nvZVvar</code></td>
<td>
<p>Number of variables explaining heteroscedasticity in the
two-sided error term.</p>
</td></tr>
<tr><td><code>nParm</code></td>
<td>
<p>Total number of parameters estimated.</p>
</td></tr>
<tr><td><code>udist</code></td>
<td>
<p>The argument <code>'udist'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>startVal</code></td>
<td>
<p>Numeric vector. Starting value for M(S)L estimation.</p>
</td></tr>
<tr><td><code>dataTable</code></td>
<td>
<p>A data frame (tibble format) containing information on data
used for optimization along with residuals and fitted values of the OLS and
M(S)L estimations, and the individual observation log-likelihood. When argument <code>weights</code>
is specified, an additional variable is provided in <code>dataTable</code>.</p>
</td></tr>
<tr><td><code>lpmObj</code></td>
<td>
<p>Linear probability model used for initializing the first step
probit model.</p>
</td></tr>
<tr><td><code>probitObj</code></td>
<td>
<p>Probit model. Object of class <code>'maxLik'</code> and <code>'maxim'</code>.</p>
</td></tr>
<tr><td><code>ols2stepParam</code></td>
<td>
<p>Numeric vector. OLS second step estimates for
selection correction. Inverse Mills Ratio is introduced as an additional
explanatory variable.</p>
</td></tr>
<tr><td><code>ols2stepStder</code></td>
<td>
<p>Numeric vector. Standard errors of OLS second step estimates.</p>
</td></tr>
<tr><td><code>ols2stepSigmasq</code></td>
<td>
<p>Numeric. Estimated variance of OLS second step random error.</p>
</td></tr>
<tr><td><code>ols2stepLoglik</code></td>
<td>
<p>Numeric. Log-likelihood value of OLS second step estimation.</p>
</td></tr>
<tr><td><code>ols2stepSkew</code></td>
<td>
<p>Numeric. Skewness of the residuals of the OLS second step estimation.</p>
</td></tr>
<tr><td><code>ols2stepM3Okay</code></td>
<td>
<p>Logical. Indicating whether the residuals of the OLS
second step estimation have the expected skewness.</p>
</td></tr>
<tr><td><code>CoelliM3Test</code></td>
<td>
<p>Coelli's test for OLS residuals skewness. (See Coelli,
1995).</p>
</td></tr>
<tr><td><code>AgostinoTest</code></td>
<td>
<p>D'Agostino's test for OLS residuals skewness. (See
D'Agostino and Pearson, 1973).</p>
</td></tr>
<tr><td><code>isWeights</code></td>
<td>
<p>Logical. If <code>TRUE</code> weighted log-likelihood is
maximized.</p>
</td></tr>
<tr><td><code>lType</code></td>
<td>
<p>Type of likelihood estimated. See the section &lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>optType</code></td>
<td>
<p>Optimization algorithm used.</p>
</td></tr>
<tr><td><code>nIter</code></td>
<td>
<p>Number of iterations of the ML estimation.</p>
</td></tr>
<tr><td><code>optStatus</code></td>
<td>
<p>Optimization algorithm termination message.</p>
</td></tr>
<tr><td><code>startLoglik</code></td>
<td>
<p>Log-likelihood at the starting values.</p>
</td></tr>
<tr><td><code>mlLoglik</code></td>
<td>
<p>Log-likelihood value of the M(S)L estimation.</p>
</td></tr>
<tr><td><code>mlParam</code></td>
<td>
<p>Parameters obtained from M(S)L estimation.</p>
</td></tr>
<tr><td><code>gradient</code></td>
<td>
<p>Each variable gradient of the M(S)L estimation.</p>
</td></tr>
<tr><td><code>gradL_OBS</code></td>
<td>
<p>Matrix. Each variable individual observation gradient of
the M(S)L estimation.</p>
</td></tr>
<tr><td><code>gradientNorm</code></td>
<td>
<p>Gradient norm of the M(S)L estimation.</p>
</td></tr>
<tr><td><code>invHessian</code></td>
<td>
<p>Covariance matrix of the parameters obtained from the
M(S)L estimation.</p>
</td></tr>
<tr><td><code>hessianType</code></td>
<td>
<p>The argument <code>'hessianType'</code>. See the section
&lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>mlDate</code></td>
<td>
<p>Date and time of the estimated model.</p>
</td></tr>
<tr><td><code>simDist</code></td>
<td>
<p>The argument <code>'simDist'</code>, only if <code>lType =
'msl'</code>. See the section &lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>Nsim</code></td>
<td>
<p>The argument <code>'Nsim'</code>, only if <code>lType = 'msl'</code>.
See the section &lsquo;Arguments&rsquo;.</p>
</td></tr>
<tr><td><code>FiMat</code></td>
<td>
<p>Matrix of random draws used for MSL, only if <code>lType =
'msl'</code>.</p>
</td></tr>
<tr><td><code>gHermiteData</code></td>
<td>
<p>List. Gauss-Hermite quadrature rule as provided by
<code><a href="fastGHQuad.html#topic+gaussHermiteData">gaussHermiteData</a></code>. Only if <code>lType = 
'ghermite'</code>.</p>
</td></tr>
<tr><td><code>Nsub</code></td>
<td>
<p>Number of subdivisions used for quadrature approaches.</p>
</td></tr>
<tr><td><code>uBound</code></td>
<td>
<p>Upper bound for the inefficiency component when solving
integrals using quadrature approaches except Gauss-Hermite for which the upper
bound is automatically infinite (<code>Inf</code>).</p>
</td></tr>
<tr><td><code>intol</code></td>
<td>
<p>Integration tolerance for quadrature approaches except Gauss-Hermite.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For the Halton draws, the code is adapted from the <span class="pkg">mlogit</span>
package.
</p>


<h3>References</h3>

<p>Caudill, S. B., and Ford, J. M. 1993. Biases in frontier estimation due to
heteroscedasticity. <em>Economics Letters</em>, <b>41</b>(1), 17&ndash;20.
</p>
<p>Caudill, S. B., Ford, J. M., and Gropper, D. M. 1995. Frontier estimation
and firm-specific inefficiency measures in the presence of
heteroscedasticity. <em>Journal of Business &amp; Economic Statistics</em>,
<b>13</b>(1), 105&ndash;111.
</p>
<p>Coelli, T. 1995. Estimators and hypothesis tests for a stochastic frontier
function - a Monte-Carlo analysis. <em>Journal of Productivity Analysis</em>,
<b>6</b>:247&ndash;268.
</p>
<p>D'Agostino, R., and E.S. Pearson. 1973. Tests for departure from normality.
Empirical results for the distributions of <code class="reqn">b_2</code> and <code class="reqn">\sqrt{b_1}</code>.
<em>Biometrika</em>, <b>60</b>:613&ndash;622.
</p>
<p>Dakpo, K. H., Latruffe, L., Desjeux, Y., Jeanneaux, P., 2022.
Modeling heterogeneous technologies in the presence of sample selection:
The case of dairy farms and the adoption of agri-environmental schemes in France.
<em>Agricultural Economics</em>, <b>53</b>(3), 422-438.
</p>
<p>Greene, W., 2010. A stochastic frontier model with correction
for sample selection. <em>Journal of Productivity Analysis</em>. <b>34</b>, 15&ndash;24.
</p>
<p>Hadri, K. 1999. Estimation of a doubly heteroscedastic stochastic frontier
cost function. <em>Journal of Business &amp; Economic Statistics</em>,
<b>17</b>(3), 359&ndash;363.
</p>
<p>Heckman, J., 1976. Discrete, qualitative and limited dependent variables.
<em>Ann Econ Soc Meas.</em> <b>4</b>, 475&ndash;492.
</p>
<p>Heckman, J., 1979. Sample Selection Bias as a Specification Error.
<em>Econometrica</em>. <b>47</b>, 153&ndash;161.
</p>
<p>Reifschneider, D., and Stevenson, R. 1991. Systematic departures from the
frontier: A framework for the analysis of firm inefficiency.
<em>International Economic Review</em>, <b>32</b>(3), 715&ndash;723.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.sfaselectioncross">print</a></code> for printing <code>sfaselectioncross</code> object.
</p>
<p><code><a href="#topic+summary.sfaselectioncross">summary</a></code> for creating and printing
summary results.
</p>
<p><code><a href="#topic+coef.sfaselectioncross">coef</a></code> for extracting coefficients of the
estimation.
</p>
<p><code><a href="#topic+efficiencies.sfaselectioncross">efficiencies</a></code> for computing
(in-)efficiency estimates.
</p>
<p><code><a href="#topic+fitted.sfaselectioncross">fitted</a></code> for extracting the fitted frontier
values.
</p>
<p><code><a href="#topic+ic.sfaselectioncross">ic</a></code> for extracting information criteria.
</p>
<p><code><a href="#topic+logLik.sfaselectioncross">logLik</a></code> for extracting log-likelihood
value(s) of the estimation.
</p>
<p><code><a href="#topic+marginal.sfaselectioncross">marginal</a></code> for computing marginal effects of
inefficiency drivers.
</p>
<p><code><a href="#topic+residuals.sfaselectioncross">residuals</a></code> for extracting residuals of the
estimation.
</p>
<p><code><a href="#topic+vcov.sfaselectioncross">vcov</a></code> for computing the variance-covariance
matrix of the coefficients.
</p>
<p><code><a href="#topic+bread.sfaselectioncross">bread</a></code> for bread for sandwich estimator.
</p>
<p><code><a href="#topic+estfun.sfaselectioncross">estfun</a></code> for gradient extraction for each
observation.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

## Simulated example

N &lt;- 2000  # sample size
set.seed(12345)
z1 &lt;- rnorm(N)
z2 &lt;- rnorm(N)
v1 &lt;- rnorm(N)
v2 &lt;- rnorm(N)
e1 &lt;- v1
e2 &lt;- 0.7071 * (v1 + v2)
ds &lt;- z1 + z2 + e1
d &lt;- ifelse(ds &gt; 0, 1, 0)
u &lt;- abs(rnorm(N))
x1 &lt;- rnorm(N)
x2 &lt;- rnorm(N)
y &lt;- x1 + x2 + e2 - u
data &lt;- cbind(y = y, x1 = x1, x2 = x2, z1 = z1, z2 = z2, d = d)

## Estimation using quadrature (Gauss-Kronrod)

selecRes1 &lt;- sfaselectioncross(selectionF = d ~ z1 + z2, frontierF = y ~ x1 + x2, 
modelType = 'greene10', method = 'bfgs',
logDepVar = TRUE, data = as.data.frame(data),
S = 1L, udist = 'hnormal', lType = 'kronrod', Nsub = 100, uBound = Inf,
simType = 'halton', Nsim = 300, prime = 2L, burn = 10, antithetics = FALSE,
seed = 12345, itermax = 2000, printInfo = FALSE)

summary(selecRes1)

## Estimation using maximum simulated likelihood

selecRes2 &lt;- sfaselectioncross(selectionF = d ~ z1 + z2, frontierF = y ~ x1 + x2, 
modelType = 'greene10', method = 'bfgs',
logDepVar = TRUE, data = as.data.frame(data),
S = 1L, udist = 'hnormal', lType = 'msl', Nsub = 100, uBound = Inf,
simType = 'halton', Nsim = 300, prime = 2L, burn = 10, antithetics = FALSE,
seed = 12345, itermax = 2000, printInfo = FALSE)

summary(selecRes2)


## End(Not run)

</code></pre>

<hr>
<h2 id='skewnessTest'>Skewness test for stochastic frontier models</h2><span id='topic+skewnessTest'></span>

<h3>Description</h3>

<p><code><a href="#topic+skewnessTest">skewnessTest</a></code> computes skewness test for stochastic frontier
models (i.e. objects of class <code>'sfacross'</code>).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>skewnessTest(object, test = "agostino")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="skewnessTest_+3A_object">object</code></td>
<td>
<p>An object of class <code>'sfacross'</code>, returned by
<code><a href="#topic+sfacross">sfacross</a></code>.</p>
</td></tr>
<tr><td><code id="skewnessTest_+3A_test">test</code></td>
<td>
<p>A character string specifying the test to implement. If
<code>'agostino'</code> (default), D'Agostino skewness test is implemented
(D'Agostino and Pearson, 1973).  If <code>'coelli'</code>, Coelli skewness test is
implemented (Coelli, 1995).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>skewnessTest</code> returns the results of either the D'Agostino's
or the Coelli's skewness test.
</p>


<h3>Note</h3>

<p><code><a href="#topic+skewnessTest">skewnessTest</a></code> is currently only available for object of
class <code>'sfacross'</code>.
</p>


<h3>References</h3>

<p>Coelli, T. 1995. Estimators and hypothesis tests for a
stochastic frontier function - a Monte-Carlo analysis. <em>Journal of
Productivity Analysis</em>, <b>6</b>:247&ndash;268.
</p>
<p>D'Agostino, R., and E.S. Pearson. 1973. Tests for departure from normality.
Empirical results for the distributions of <code class="reqn">b_2</code> and <code class="reqn">\sqrt{b_1}</code>.
<em>Biometrika</em>, <b>60</b>:613&ndash;622.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
## Using data on fossil fuel fired steam electric power generation plants in the U.S.
# Translog SFA (cost function) truncated normal with scaling property
tl_u_ts &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu, uhet = ~ regu, data = utility, S = -1,
scaling = TRUE, method = 'mla')
skewnessTest(tl_u_ts)
skewnessTest(tl_u_ts, test = 'coelli')

## End(Not run)

</code></pre>

<hr>
<h2 id='summary'>Summary of results for stochastic frontier models</h2><span id='topic+summary'></span><span id='topic+summary.sfacross'></span><span id='topic+print.summary.sfacross'></span><span id='topic+summary.sfalcmcross'></span><span id='topic+print.summary.sfalcmcross'></span><span id='topic+summary.sfaselectioncross'></span><span id='topic+print.summary.sfaselectioncross'></span>

<h3>Description</h3>

<p>Create and print summary results for stochastic frontier models returned by
<code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
summary(object, grad = FALSE, ci = FALSE, ...)

## S3 method for class 'summary.sfacross'
print(x, digits = max(3, getOption("digits") - 2), ...)

## S3 method for class 'sfalcmcross'
summary(object, grad = FALSE, ci = FALSE, ...)

## S3 method for class 'summary.sfalcmcross'
print(x, digits = max(3, getOption("digits") - 2), ...)

## S3 method for class 'sfaselectioncross'
summary(object, grad = FALSE, ci = FALSE, ...)

## S3 method for class 'summary.sfaselectioncross'
print(x, digits = max(3, getOption("digits") - 2), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_+3A_object">object</code></td>
<td>
<p>An object of either class <code>'sfacross'</code> returned by the
function <code><a href="#topic+sfacross">sfacross</a></code>, or <code>'sfalcmcross'</code> returned by the
function <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or class <code>'sfaselectioncross'</code> returned
by the function <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.</p>
</td></tr>
<tr><td><code id="summary_+3A_grad">grad</code></td>
<td>
<p>Logical. Default = <code>FALSE</code>. If <code>TRUE</code>, the gradient
for the maximum likelihood (ML) estimates of the different parameters is
returned.</p>
</td></tr>
<tr><td><code id="summary_+3A_ci">ci</code></td>
<td>
<p>Logical. Default = <code>FALSE</code>. If <code>TRUE</code>, the 95%
confidence interval for the different parameters (OLS or/and ML estimates) is
returned.</p>
</td></tr>
<tr><td><code id="summary_+3A_...">...</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
<tr><td><code id="summary_+3A_x">x</code></td>
<td>
<p>An object of either class <code>'summary.sfacross'</code>, <code>'summary.sfalcmcross'</code>, or<br />
<code>'summary.sfaselectioncross'</code>.</p>
</td></tr>
<tr><td><code id="summary_+3A_digits">digits</code></td>
<td>
<p>Numeric. Number of digits displayed in values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code><a href="#topic+summary">summary</a></code> method returns a list of class
<code>'summary.sfacross'</code>, <code>'summary.sfalcmcross'</code>, or<br />
<code>'summary.sfaselectioncross'</code>
that contains the same elements as an object returned by <code><a href="#topic+sfacross">sfacross</a></code>,
<code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> with the
following additional elements:
</p>
<table>
<tr><td><code>AIC</code></td>
<td>
<p>Akaike information criterion.</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>Bayesian information criterion.</p>
</td></tr>
<tr><td><code>HQIC</code></td>
<td>
<p>Hannan-Quinn information criterion.</p>
</td></tr>
<tr><td><code>sigmavSq</code></td>
<td>
<p>For <code>object</code> of class <code>'sfacross'</code> or
<code>'sfaselectioncross'</code>. Variance of
the two-sided error term (<code class="reqn">\sigma_v^2</code>).</p>
</td></tr>
<tr><td><code>sigmauSq</code></td>
<td>
<p>For <code>object</code> of class <code>'sfacross'</code> or
<code>'sfaselectioncross'</code>. Parametrization of the variance of the one-sided
error term (<code class="reqn">\sigma_u^2</code>).</p>
</td></tr>
<tr><td><code>Varu</code></td>
<td>
<p>For <code>object</code> of class <code>'sfacross'</code> or
<code>'sfaselectioncross'</code>. Variance of the one-sided error term.</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>For <code>object</code> of class <code>'sfacross'</code> with <code>'udist
= uniform'</code>.  <code class="reqn">\Theta</code> value in the case the uniform distribution is
defined as: <code class="reqn">u_i \in [0, \Theta]</code>.</p>
</td></tr>
<tr><td><code>Eu</code></td>
<td>
<p>For <code>object</code> of class <code>'sfacross'</code> or
<code>'sfaselectioncross'</code>. Expected unconditional inefficiency
(<code class="reqn">E[u]</code>).</p>
</td></tr>
<tr><td><code>Expu</code></td>
<td>
<p>For <code>object</code> of class <code>'sfacross'</code> or
<code>'sfaselectioncross'</code>. Expected unconditional efficiency
(<code class="reqn">E[\exp(u)]</code>).</p>
</td></tr>
<tr><td><code>olsRes</code></td>
<td>
<p>For <code>object</code> of class <code>'sfacross'</code>. Matrix of OLS
estimates, their standard errors, t-values, P-values, and when <code>ci =
TRUE</code> their confidence intervals.</p>
</td></tr>
<tr><td><code>ols2StepRes</code></td>
<td>
<p>For <code>object</code> of class <code>'sfaselectioncross'</code>.
Matrix of OLS 2 step estimates, their standard errors, t-values, P-values,
and when <code>ci = TRUE</code> their confidence intervals.</p>
</td></tr>
<tr><td><code>mlRes</code></td>
<td>
<p>Matrix of ML estimates, their standard errors, z-values,
asymptotic P-values, and when <code>grad = TRUE</code> their gradient, <code>ci =
TRUE</code> their confidence intervals.</p>
</td></tr>
<tr><td><code>chisq</code></td>
<td>
<p>For <code>object</code> of class <code>'sfacross'</code>. Chi-square
statistics of the difference between the stochastic frontier and the OLS.</p>
</td></tr>
<tr><td><code>df</code></td>
<td>
<p>Degree of freedom for the inefficiency model.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function for cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function for cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function for cross-sectional or pooled data.
</p>
<p><code><a href="#topic+print.sfacross">print</a></code> for printing <code>sfacross</code> object.
</p>
<p><code><a href="#topic+coef.sfacross">coef</a></code> for extracting coefficients of the
estimation.
</p>
<p><code><a href="#topic+efficiencies.sfacross">efficiencies</a></code> for computing
(in-)efficiency estimates.
</p>
<p><code><a href="#topic+fitted.sfacross">fitted</a></code> for extracting the fitted frontier
values.
</p>
<p><code><a href="#topic+ic.sfacross">ic</a></code> for extracting information criteria.
</p>
<p><code><a href="#topic+logLik.sfacross">logLik</a></code> for extracting log-likelihood
value(s) of the estimation.
</p>
<p><code><a href="#topic+marginal.sfacross">marginal</a></code> for computing marginal effects of
inefficiency drivers.
</p>
<p><code><a href="#topic+residuals.sfacross">residuals</a></code> for extracting residuals of the
estimation.
</p>
<p><code><a href="#topic+vcov.sfacross">vcov</a></code> for computing the variance-covariance
matrix of the coefficients.
</p>
<p><code><a href="#topic+bread.sfacross">bread</a></code> for bread for sandwich estimator.
</p>
<p><code><a href="#topic+estfun.sfacross">estfun</a></code> for gradient extraction for each
observation.
</p>
<p><code><a href="#topic+skewnessTest">skewnessTest</a></code> for implementing skewness test.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Using data on fossil fuel fired steam electric power generation plants in the U.S.
# Translog SFA (cost function) truncated normal with scaling property
tl_u_ts &lt;- sfacross(formula = log(tc/wf) ~ log(y) + I(1/2 * (log(y))^2) +
log(wl/wf) + log(wk/wf) + I(1/2 * (log(wl/wf))^2) + I(1/2 * (log(wk/wf))^2) +
I(log(wl/wf) * log(wk/wf)) + I(log(y) * log(wl/wf)) + I(log(y) * log(wk/wf)),
udist = 'tnormal', muhet = ~ regu, uhet = ~ regu, data = utility, S = -1,
scaling = TRUE, method = 'mla')
summary(tl_u_ts, grad = TRUE, ci = TRUE)

</code></pre>

<hr>
<h2 id='swissrailways'>Data on Swiss railway companies</h2><span id='topic+swissrailways'></span>

<h3>Description</h3>

<p>This dataset is an unbalanced panel of 50 Swiss railway companies over the
period 1985-1997.
</p>


<h3>Format</h3>

<p>A data frame with 605 observations on the following 42 variables.
</p>
 <dl>
<dt>ID</dt><dd><p>Firm identification.</p>
</dd> <dt>YEAR</dt><dd><p>Year identification.</p>
</dd>
<dt>NI</dt><dd><p>Number of years observed.</p>
</dd> <dt>STOPS</dt><dd><p>Number of stops in
network.</p>
</dd> <dt>NETWORK</dt><dd><p>Network length (in meters).</p>
</dd> <dt>NARROW_T</dt><dd><p>Dummy
variable for railroads with narrow track.</p>
</dd> <dt>RACK</dt><dd><p>Dummy variable for
‘rack rail’ in network.</p>
</dd> <dt>TUNNEL</dt><dd><p>Dummy variable for network with
tunnels over 300 meters on average.</p>
</dd> <dt>T</dt><dd><p>Time indicator, first year =
0.</p>
</dd> <dt>Q2</dt><dd><p>Passenger output – passenger km.</p>
</dd> <dt>Q3</dt><dd><p>Freight output
– ton km.</p>
</dd> <dt>CT</dt><dd><p>Total cost (1,000 Swiss franc).</p>
</dd> <dt>PL</dt><dd><p>Labor
price.</p>
</dd> <dt>PE</dt><dd><p>Electricity price.</p>
</dd> <dt>PK</dt><dd><p>Capital price.</p>
</dd>
<dt>VIRAGE</dt><dd><p>1 for railroads with curvy tracks.</p>
</dd> <dt>LNCT</dt><dd><p>Log of
<code>CT</code>/<code>PE</code>.</p>
</dd> <dt>LNQ2</dt><dd><p>Log of <code>Q2</code>.</p>
</dd> <dt>LNQ3</dt><dd><p>Log of
<code>Q3</code>.</p>
</dd> <dt>LNNET</dt><dd><p>Log of <code>NETWORK</code>/1000.</p>
</dd> <dt>LNPL</dt><dd><p>Log of
<code>PL</code>/<code>PE</code>.</p>
</dd> <dt>LNPE</dt><dd><p>Log of <code>PE</code>.</p>
</dd> <dt>LNPK</dt><dd><p>Log of
<code>PK</code>/<code>PE</code>.</p>
</dd> <dt>LNSTOP</dt><dd><p>Log of <code>STOPS</code>.</p>
</dd> <dt>MLNQ2</dt><dd><p>Mean
of <code>LNQ2</code>.</p>
</dd> <dt>MLNQ3</dt><dd><p>Mean of <code>LNQ3</code>.</p>
</dd> <dt>MLNNET</dt><dd><p>Mean of
<code>LNNET</code>.</p>
</dd> <dt>MLNPL</dt><dd><p>Mean of <code>LNPL</code>.</p>
</dd> <dt>MLNPK</dt><dd><p>Mean of
<code>LNPK</code>.</p>
</dd> <dt>MLNSTOP</dt><dd><p>Mean of <code>LNSTOP</code>.</p>
</dd> </dl>



<h3>Details</h3>

<p>The dataset is extracted from the annual reports of the Swiss Federal Office
of Statistics on public transport companies and has been used in Farsi
<em>et al.</em> (2005).
</p>


<h3>Source</h3>

<p><a href="http://pages.stern.nyu.edu/~wgreene/Text/Edition7/tablelist8new.htm">http://pages.stern.nyu.edu/~wgreene/Text/Edition7/tablelist8new.htm</a>
</p>
<p><a href="http://people.stern.nyu.edu/wgreene/Microeconometrics.htm">http://people.stern.nyu.edu/wgreene/Microeconometrics.htm</a>
</p>


<h3>References</h3>

<p>Farsi, M., M. Filippini, and W. Greene. 2005. Efficiency
measurement in network industries: Application to the Swiss railway
companies. <em>Journal of Regulatory Economics</em>, <b>28</b>:69&ndash;90.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
str(swissrailways)
</code></pre>

<hr>
<h2 id='utility'>Data on U.S. electricity generating plants</h2><span id='topic+utility'></span>

<h3>Description</h3>

<p>This dataset contains data on fossil fuel fired steam electric power
generation plants in the United States between 1986 and 1996.
</p>


<h3>Format</h3>

<p>A data frame with 791 observations on the following 11 variables.
</p>
 <dl>
<dt>firm</dt><dd><p>Plant identification.</p>
</dd> <dt>year</dt><dd><p>Year
identification.</p>
</dd> <dt>y</dt><dd><p>Net-steam electric power generation in
megawatt-hours.</p>
</dd> <dt>regu</dt><dd><p>Dummy variable which takes a value equal to 1
if the power plant is in a state which enacted legislation or issued a
regulatory order to implement retail access during the sample period, and 0
otherwise.</p>
</dd> <dt>k</dt><dd><p>Capital stock.</p>
</dd> <dt>labor</dt><dd><p>Labor and maintenance.</p>
</dd>
<dt>fuel</dt><dd><p>Fuel.</p>
</dd> <dt>wl</dt><dd><p>Labor price.</p>
</dd> <dt>wf</dt><dd><p>Fuel price.</p>
</dd>
<dt>wk</dt><dd><p>Capital price.</p>
</dd> <dt>tc</dt><dd><p>Total cost.</p>
</dd> </dl>



<h3>Details</h3>

<p>The dataset has been used in Kumbhakar <em>et al.</em> (2014).
</p>


<h3>Source</h3>

<p><a href="https://sites.google.com/site/sfbook2014/home/for-stata-v12-v13-v14">https://sites.google.com/site/sfbook2014/home/for-stata-v12-v13-v14</a>
</p>


<h3>References</h3>

<p>Kumbhakar, S.C., H.J. Wang, and A. Horncastle. 2014. <em>A
Practitioner's Guide to Stochastic Frontier Analysis Using Stata</em>. Cambridge
University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
str(utility)
summary(utility)
</code></pre>

<hr>
<h2 id='vcov'>Compute variance-covariance matrix of stochastic frontier models</h2><span id='topic+vcov'></span><span id='topic+vcov.sfacross'></span><span id='topic+vcov.sfalcmcross'></span><span id='topic+vcov.sfaselectioncross'></span>

<h3>Description</h3>

<p><code><a href="#topic+vcov">vcov</a></code> computes the variance-covariance matrix of the maximum
likelihood (ML) coefficients from stochastic frontier models estimated with
<code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>,
or <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sfacross'
vcov(object, extraPar = FALSE, ...)

## S3 method for class 'sfalcmcross'
vcov(object, ...)

## S3 method for class 'sfaselectioncross'
vcov(object, extraPar = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vcov_+3A_object">object</code></td>
<td>
<p>A stochastic frontier model returned
by <code><a href="#topic+sfacross">sfacross</a></code>, <code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, or
<code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.</p>
</td></tr>
<tr><td><code id="vcov_+3A_extrapar">extraPar</code></td>
<td>
<p>Logical. Only available for non heteroscedastic models
returned by <code><a href="#topic+sfacross">sfacross</a></code> and <code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code>.
Default = <code>FALSE</code>. If <code>TRUE</code>, variances and covariances of
additional parameters are returned:
</p>
<p><code>sigmaSq</code> = <code>sigmauSq</code> + <code>sigmavSq</code>
</p>
<p><code>lambdaSq</code> = <code>sigmauSq</code>/<code>sigmavSq</code>
</p>
<p><code>sigmauSq</code> = <code class="reqn">\exp{(Wu)}</code> = <code class="reqn">\exp{(\bm{\delta} \mathbf{Z}_u)}</code>
</p>
<p><code>sigmavSq</code> = <code class="reqn">\exp{(Wv)}</code> = <code class="reqn">\exp{(\bm{\phi} \mathbf{Z}_v)}</code>
</p>
<p><code>sigma</code> = <code>sigmaSq</code>^0.5
</p>
<p><code>lambda</code> = <code>lambdaSq</code>^0.5
</p>
<p><code>sigmau</code> = <code>sigmauSq</code>^0.5
</p>
<p><code>sigmav</code> = <code>sigmavSq</code>^0.5
</p>
<p><code>gamma</code> = <code>sigmauSq</code>/(<code>sigmauSq</code> + <code>sigmavSq</code>)</p>
</td></tr>
<tr><td><code id="vcov_+3A_...">...</code></td>
<td>
<p>Currently ignored</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variance-covariance matrix is obtained by the inversion of the
negative Hessian matrix. Depending on the distribution and the
<code>'hessianType'</code> option, the analytical/numeric Hessian or the bhhh
Hessian is evaluated.
</p>
<p>The argument <code>extraPar</code>, is currently available only for objects of class
<code>'sfacross'</code> and <code>'sfaselectioncross'</code>. When
<code>'extraPar = TRUE'</code>, the variance-covariance of the additional
parameters is obtained using the delta method.
</p>


<h3>Value</h3>

<p>The variance-covariance matrix of the maximum likelihood
coefficients is returned.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+sfacross">sfacross</a></code>, for the stochastic frontier analysis model
fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfalcmcross">sfalcmcross</a></code>, for the latent class stochastic frontier analysis
model fitting function using cross-sectional or pooled data.
</p>
<p><code><a href="#topic+sfaselectioncross">sfaselectioncross</a></code> for sample selection in stochastic frontier
model fitting function using cross-sectional data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Using data on Spanish dairy farms
# Cobb Douglas (production function) half normal distribution
cb_s_h &lt;- sfacross(formula = YIT ~ X1 + X2 + X3 + X4, udist = 'hnormal',
data = dairyspain, S = 1, method = 'bfgs')
vcov(cb_s_h)
vcov(cb_s_h, extraPar = TRUE)
 
# Other variance-covariance matrices can be obtained using the sandwich package
 
# Robust variance-covariance matrix
 
requireNamespace('sandwich', quietly = TRUE)
 
sandwich::vcovCL(cb_s_h)
 
# Coefficients and standard errors can be obtained using lmtest package
 
requireNamespace('lmtest', quietly = TRUE)
 
lmtest::coeftest(cb_s_h, vcov. = sandwich::vcovCL)
 
# Clustered standard errors
 
lmtest::coeftest(cb_s_h, vcov. = sandwich::vcovCL, cluster = ~ FARM)
 
# Doubly clustered standard errors
 
lmtest::coeftest(cb_s_h, vcov. = sandwich::vcovCL, cluster = ~ FARM + YEAR)
 
# BHHH standard errors
 
lmtest::coeftest(cb_s_h, vcov. = sandwich::vcovOPG)
 
# Adjusted BHHH standard errors
 
lmtest::coeftest(cb_s_h, vcov. = sandwich::vcovOPG, adjust = TRUE)

## Using data on eighty-two countries production (GDP)
# LCM Cobb Douglas (production function) half normal distribution
cb_2c_h &lt;- sfalcmcross(formula = ly ~ lk + ll + yr, udist = 'hnormal',
data = worldprod, uhet = ~ initStat, S = 1)
vcov(cb_2c_h)

</code></pre>

<hr>
<h2 id='worldprod'>Data on world production</h2><span id='topic+worldprod'></span>

<h3>Description</h3>

<p>This dataset provides information on production related variables for
eighty-two countries over the period 1960–1987.
</p>


<h3>Format</h3>

<p>A data frame with 2,296 observations on the following 12 variables.
</p>
 <dl>
<dt>country</dt><dd><p>Country name.</p>
</dd> <dt>code</dt><dd><p>Country
identification.</p>
</dd> <dt>yr</dt><dd><p>Year identification.</p>
</dd> <dt>y</dt><dd><p>GDP in 1987 U.S.
dollars.</p>
</dd> <dt>k</dt><dd><p>Physical capital stock in 1987 U.S. dollars.</p>
</dd>
<dt>l</dt><dd><p>Labor (number of individuals in the workforce between the age of
15 and 64).</p>
</dd> <dt>h</dt><dd><p>Human capital-adjusted labor.</p>
</dd> <dt>ly</dt><dd><p>Log of
<code>y</code>.</p>
</dd> <dt>lk</dt><dd><p>Log of <code>k</code>.</p>
</dd> <dt>ll</dt><dd><p>Log of <code>l</code>.</p>
</dd>
<dt>lh</dt><dd><p>Log of <code>h</code>.</p>
</dd> <dt>initStat</dt><dd><p>Log of the initial capital to
labor ratio of each country, <code>lk</code> - <code>ll</code>, measured at the
beginning of the sample period.</p>
</dd> </dl>



<h3>Details</h3>

<p>The dataset is from the World Bank STARS database and has been used in
Kumbhakar <em>et al.</em> (2014).
</p>


<h3>Source</h3>

<p><a href="https://sites.google.com/site/sfbook2014/home/for-stata-v12-v13-v14">https://sites.google.com/site/sfbook2014/home/for-stata-v12-v13-v14</a>
</p>


<h3>References</h3>

<p>Kumbhakar, S.C., H.J. Wang, and A. Horncastle. 2014. <em>A
Practitioner's Guide to Stochastic Frontier Analysis Using Stata</em>. Cambridge
University Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
str(worldprod)
summary(worldprod)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
