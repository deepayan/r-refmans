<!DOCTYPE html><html lang="en"><head><title>Help for package ipw</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ipw}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#basdat'><p>HIV: TB and Survival (Baseline Data)</p></a></li>
<li><a href='#haartdat'><p>HAART and Survival in HIV Patients</p></a></li>
<li><a href='#healthdat'><p>IQ, Income and Health</p></a></li>
<li><a href='#ipwplot'><p>Plot Inverse Probability Weights</p></a></li>
<li><a href='#ipwpoint'><p>Estimate Inverse Probability Weights (Point Treatment)</p></a></li>
<li><a href='#ipwtm'><p>Estimate Inverse Probability Weights (Time Varying)</p></a></li>
<li><a href='#timedat'><p>HIV: TB and Survival (Longitudinal Measurements)</p></a></li>
<li><a href='#tstartfun'><p>Compute Starting Time For Counting Process Notation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.2.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-01-02</td>
</tr>
<tr>
<td>Title:</td>
<td>Estimate Inverse Probability Weights</td>
</tr>
<tr>
<td>Author:</td>
<td>Willem M. van der Wal [aut, cre],
  Ronald B. Geskus [aut] (maintainer 2011-2022)</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Willem M. van der Wal &lt;willem@vanderwalresearch.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>MASS, nnet, survival, geepack, graphics, methods, stats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>nlme, survey, boot</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions to estimate the probability to receive the observed treatment, based on
    individual characteristics. The inverse of these probabilities can be used as weights when
	estimating causal effects from observational data via marginal structural models. Both point
	treatment situations and longitudinal studies can be analysed. The same functions can be used to
	correct for informative censoring.	</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-12-11 08:06:24 UTC; hornik</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-12-11 08:22:39 UTC</td>
</tr>
</table>
<hr>
<h2 id='basdat'>HIV: TB and Survival (Baseline Data)</h2><span id='topic+basdat'></span>

<h3>Description</h3>

<p>Simulated dataset. Baseline data of 386 HIV positive individuals, including time of first active tuberculosis, time of death, individual end time. Time varying CD4 measurements of these patients are included in dataset <code><a href="#topic+timedat">timedat</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(basdat)</code></pre>


<h3>Format</h3>

<p>A data frame with 386 observations on the following 4 variables.
</p>

<dl>
<dt><code>id</code></dt><dd><p>patient ID.</p>
</dd>
<dt><code>Ttb</code></dt><dd><p>time of first active tuberculosis, measured in days since HIV seroconversion.</p>
</dd>
<dt><code>Tdeath</code></dt><dd><p>time of death, measured in days since HIV seroconversion.</p>
</dd>
<dt><code>Tend</code></dt><dd><p>individual end time (either death or censoring), measured in days since HIV seroconversion.</p>
</dd>
</dl>



<h3>Details</h3>

<p>These simulated data are used together with data in <code><a href="#topic+timedat">timedat</a></code> in a detailed causal modelling example using inverse probability weighting (IPW). See <code><a href="#topic+ipwtm">ipwtm</a></code> for the example. Data were simulated using the algorithm described in Van der Wal e.a. (2009).
</p>


<h3>Author(s)</h3>

<p>Willem M. van der Wal <a href="mailto:willem@vanderwalresearch.com">willem@vanderwalresearch.com</a>, Ronald B. Geskus <a href="mailto:rgeskus@oucru.org">rgeskus@oucru.org</a></p>


<h3>References</h3>

<p>Van der Wal W.M. &amp; Geskus R.B. (2011). ipw: An R Package for Inverse  Probability Weighting. <em>Journal of Statistical Software</em>, <b>43</b>(13), 1-23. <a href="https://doi.org/10.18637/jss.v043.i13">doi:10.18637/jss.v043.i13</a>.
</p>
<p>Van der Wal W.M., Prins M., Lumbreras B. &amp; Geskus R.B. (2009). A simple G-computation algorithm to quantify the causal effect of a secondary illness on the progression of a chronic disease. <em>Statistics in Medicine</em>, <b>28</b>(18), 2325-2337.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+basdat">basdat</a></code>, <code><a href="#topic+haartdat">haartdat</a></code>, <code><a href="#topic+ipwplot">ipwplot</a></code>, <code><a href="#topic+ipwpoint">ipwpoint</a></code>, <code><a href="#topic+ipwtm">ipwtm</a></code>, <code><a href="#topic+timedat">timedat</a></code>, <code><a href="#topic+tstartfun">tstartfun</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#see ?ipwtm for example
</code></pre>

<hr>
<h2 id='haartdat'>HAART and Survival in HIV Patients</h2><span id='topic+haartdat'></span>

<h3>Description</h3>

<p>Survival data measured in 1200 HIV positive patients. Start of follow-up is HIV seroconversion. Each row corresponds to a 100 day interval of follow-up time, using the counting process notation. Patients can initiate HAART therapy. CD4 count is a confounder for the effect of HAART on mortality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(haartdat)</code></pre>


<h3>Format</h3>


<dl>
<dt><code>patient</code></dt><dd><p>patient ID</p>
</dd>
<dt><code>tstart</code></dt><dd><p>starting time for each interval of follow-up, measured in days since HIV seroconversion</p>
</dd>
<dt><code>fuptime</code></dt><dd><p>end time for each interval of follow-up, measured in days since HIV seroconversion</p>
</dd>
<dt><code>haartind</code></dt><dd><p>indicator for the initiation of HAART therapy at the end of the interval (0=HAART not initiated/1=HAART initiated).</p>
</dd>
<dt><code>event</code></dt><dd><p>indicator for death at the end of the interval (0=alive/1=died)</p>
</dd>
<dt><code>sex</code></dt><dd><p>sex (0=male/1=female)</p>
</dd>
<dt><code>age</code></dt><dd><p>age at the start of follow-up (years)</p>
</dd>
<dt><code>cd4.sqrt</code></dt><dd><p>square root of CD4 count, measured at fuptime, before <code>haartind</code></p>
</dd>
</dl>



<h3>Details</h3>

<p>These data were simulated.
</p>
<p>Patients can initiate HAART at <code>fuptime=0</code>. Therefore, to allow the fitting of a model predicting initiation of HAART, starting time for the first interval within each patient is negative (-100).
</p>


<h3>Author(s)</h3>

<p>Willem M. van der Wal <a href="mailto:willem@vanderwalresearch.com">willem@vanderwalresearch.com</a>, Ronald B. Geskus <a href="mailto:rgeskus@oucru.org">rgeskus@oucru.org</a></p>


<h3>References</h3>

<p>Van der Wal W.M. &amp; Geskus R.B. (2011). ipw: An R Package for Inverse  Probability Weighting. <em>Journal of Statistical Software</em>, <b>43</b>(13), 1-23. <a href="https://doi.org/10.18637/jss.v043.i13">doi:10.18637/jss.v043.i13</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+basdat">basdat</a></code>, <code><a href="#topic+haartdat">haartdat</a></code>, <code><a href="#topic+ipwplot">ipwplot</a></code>, <code><a href="#topic+ipwpoint">ipwpoint</a></code>, <code><a href="#topic+ipwtm">ipwtm</a></code>, <code><a href="#topic+timedat">timedat</a></code>, <code><a href="#topic+tstartfun">tstartfun</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#see ?ipwtm for example
</code></pre>

<hr>
<h2 id='healthdat'>IQ, Income and Health</h2><span id='topic+healthdat'></span>

<h3>Description</h3>

<p>A simulated dataset containing IQ, income and health score measurements in 1000 individuals.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(healthdat)</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 rows, with each row corresponding to a separate individual. The following variables are included:
</p>

<dl>
<dt><code>id</code></dt><dd><p>individual ID.</p>
</dd>
<dt><code>iq</code></dt><dd><p>IQ score.</p>
</dd>
<dt><code>income</code></dt><dd><p>gross monthly income (EUR).</p>
</dd>
<dt><code>health</code></dt><dd><p>health score (0-100).</p>
</dd>
</dl>


<h3>Details</h3>

<p>In these simulated data, IQ is a confounder for the effect of income on health. 
</p>


<h3>Author(s)</h3>

<p>Willem M. van der Wal <a href="mailto:willem@vanderwalresearch.com">willem@vanderwalresearch.com</a>, Ronald B. Geskus <a href="mailto:rgeskus@oucru.org">rgeskus@oucru.org</a></p>


<h3>References</h3>

<p>Van der Wal W.M. &amp; Geskus R.B. (2011). ipw: An R Package for Inverse  Probability Weighting. <em>Journal of Statistical Software</em>, <b>43</b>(13), 1-23. <a href="https://doi.org/10.18637/jss.v043.i13">doi:10.18637/jss.v043.i13</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+basdat">basdat</a></code>, <code><a href="#topic+haartdat">haartdat</a></code>, <code><a href="#topic+healthdat">healthdat</a></code>, <code><a href="#topic+ipwplot">ipwplot</a></code>, <code><a href="#topic+ipwpoint">ipwpoint</a></code>, <code><a href="#topic+ipwtm">ipwtm</a></code>, <code><a href="#topic+timedat">timedat</a></code>, <code><a href="#topic+tstartfun">tstartfun</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#see ?ipwpoint for example
</code></pre>

<hr>
<h2 id='ipwplot'>Plot Inverse Probability Weights
</h2><span id='topic+ipwplot'></span>

<h3>Description</h3>

<p>For time varying weights: display boxplots within strata of follow-up time.
For point treatment weights: display density plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipwplot(weights, timevar = NULL, binwidth = NULL, logscale = TRUE,
        xlab = NULL, ylab = NULL, main = "", ref = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ipwplot_+3A_weights">weights</code></td>
<td>
<p>numerical vector of inverse probability weights to plot.</p>
</td></tr>
<tr><td><code id="ipwplot_+3A_timevar">timevar</code></td>
<td>
<p>numerical vector representing follow-up time. When specified, boxplots within strata of follow-up time are displayed. When left unspecified, a density plot is displayed.</p>
</td></tr>
<tr><td><code id="ipwplot_+3A_binwidth">binwidth</code></td>
<td>
<p>numerical value indicating the width of the intervals of follow-up time; for each interval a boxplot is made. Ignored when <code>timevar</code> is not specified.</p>
</td></tr>
<tr><td><code id="ipwplot_+3A_logscale">logscale</code></td>
<td>
<p>logical value. If <code>TRUE</code>, weights are plotted on a logarithmic scale.</p>
</td></tr>
<tr><td><code id="ipwplot_+3A_xlab">xlab</code></td>
<td>
<p>label for the horizontal axis.</p>
</td></tr>
<tr><td><code id="ipwplot_+3A_ylab">ylab</code></td>
<td>
<p>label for the vertical axis.</p>
</td></tr>
<tr><td><code id="ipwplot_+3A_main">main</code></td>
<td>
<p>main title for the plot.</p>
</td></tr>
<tr><td><code id="ipwplot_+3A_ref">ref</code></td>
<td>
<p>logical value. If <code>TRUE</code>, a reference line is plotted at <code>y=1</code>.</p>
</td></tr>
<tr><td><code id="ipwplot_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="graphics.html#topic+boxplot">boxplot</a></code> (when <code>timevar</code> is specified) or <code><a href="base.html#topic+plot">plot</a></code> (when <code>timevar</code> is not specified).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A plot is displayed.
</p>


<h3>Author(s)</h3>

<p>Willem M. van der Wal <a href="mailto:willem@vanderwalresearch.com">willem@vanderwalresearch.com</a>, Ronald B. Geskus <a href="mailto:rgeskus@oucru.org">rgeskus@oucru.org</a></p>


<h3>References</h3>

<p>Van der Wal W.M. &amp; Geskus R.B. (2011). ipw: An R Package for Inverse  Probability Weighting. <em>Journal of Statistical Software</em>, <b>43</b>(13), 1-23. <a href="https://doi.org/10.18637/jss.v043.i13">doi:10.18637/jss.v043.i13</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+basdat">basdat</a></code>, <code><a href="#topic+haartdat">haartdat</a></code>, <code><a href="#topic+ipwplot">ipwplot</a></code>, <code><a href="#topic+ipwpoint">ipwpoint</a></code>, <code><a href="#topic+ipwtm">ipwtm</a></code>, <code><a href="#topic+timedat">timedat</a></code>, <code><a href="#topic+tstartfun">tstartfun</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#see ?ipwpoint and ?ipwtm for examples
</code></pre>

<hr>
<h2 id='ipwpoint'>Estimate Inverse Probability Weights (Point Treatment)</h2><span id='topic+ipwpoint'></span>

<h3>Description</h3>

<p>Estimate inverse probability weights to fit marginal structural models in a point treatment situation. The exposure for which we want to estimate the causal effect can be binomial, multinomial, ordinal or continuous. Both stabilized and unstabilized weights can be estimated.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipwpoint(exposure, family, link, numerator = NULL, denominator,
         data, trunc = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ipwpoint_+3A_exposure">exposure</code></td>
<td>
<p>a vector, representing the exposure variable of interest. Both numerical and categorical variables can be used. A binomial exposure variable should be coded using values <code>0</code>/<code>1</code>.</p>
</td></tr>
<tr><td><code id="ipwpoint_+3A_family">family</code></td>
<td>
<p>is used to specify a family of link functions, used to model the relationship between the variables in <code>numerator</code> or <code>denominator</code> and <code>exposure</code>, respectively. Alternatives are <code>"binomial"</code>,<code>"multinomial"</code>, <code>"ordinal"</code> and <code>"gaussian"</code>. A specific link function is then chosen using the argument <code>link</code>, as explained below. Regression models are fitted using <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="nnet.html#topic+multinom">multinom</a></code>, <code><a href="MASS.html#topic+polr">polr</a></code> or <code><a href="stats.html#topic+glm">glm</a></code>, respectively.</p>
</td></tr>
<tr><td><code id="ipwpoint_+3A_link">link</code></td>
<td>
<p>specifies the link function between the variables in <code>numerator</code> or <code>denominator</code> and <code>exposure</code>, respectively. For <code>family = "binomial"</code> (fitted using <code><a href="stats.html#topic+glm">glm</a></code>) alternatives are <code>"logit"</code>, <code>"probit"</code>, <code>"cauchit"</code>, <code>"log"</code> and <code>"cloglog"</code>. For <code>family = "multinomial"</code> this argument is ignored, and multinomial logistic regression models are always used (fitted using <code><a href="nnet.html#topic+multinom">multinom</a></code>). For <code>family = </code><code>"ordinal"</code> (fitted using <code><a href="MASS.html#topic+polr">polr</a></code>) alternatives are <code>"logit"</code>, <code>"probit"</code>, <code>"cauchit"</code>, and <code>"cloglog"</code>. For <code>family = "gaussian"</code> this argument is ignored, and a linear regression model with identity link is always used (fitted using <code><a href="stats.html#topic+glm">glm</a></code>).</p>
</td></tr>
<tr><td><code id="ipwpoint_+3A_numerator">numerator</code></td>
<td>
<p>is a formula, specifying the right-hand side of the model used to estimate the elements in the numerator of the inverse probability weights. When left unspecified, unstabilized weights with a numerator of 1 are estimated.</p>
</td></tr>
<tr><td><code id="ipwpoint_+3A_denominator">denominator</code></td>
<td>
<p>is a formula, specifying the right-hand side of the model used to estimate the elements in the denominator of the inverse probability weights. This typically includes the variables specified in the numerator model, as well as confounders for which to correct.</p>
</td></tr>
<tr><td><code id="ipwpoint_+3A_data">data</code></td>
<td>
<p>is a dataframe containing <code>exposure</code> and the variables used in <code>numerator</code> and <code>denominator</code>.</p>
</td></tr>
<tr><td><code id="ipwpoint_+3A_trunc">trunc</code></td>
<td>
<p>optional truncation percentile (0-0.5). E.g. when <code>trunc = 0.01</code>, the left tail is truncated to the 1st percentile, and the right tail is truncated to the 99th percentile.When specified, both un-truncated and truncated weights are returned.</p>
</td></tr>
<tr><td><code id="ipwpoint_+3A_...">...</code></td>
<td>
<p>are further arguments passed to the function that is used to estimate the numerator and denominator models (the function is chosen using <code>family</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For each unit under observation, this function computes an inverse probability weight, which is the ratio of two probabilities:
</p>

<ul>
<li><p> the numerator contains the probability of the observed exposure level given observed values of stabilization factors (usually a set of baseline covariates). These probabilities are estimated using the model regressing <code>exposure</code> on the terms in <code>numerator</code>, using the link function indicated by <code>family</code> and <code>link</code>.
</p>
</li>
<li><p> the denominator contains the probability of the observed exposure level given the observed values of a set of confounders, as well as the stabilization factors in the numerator. These probabilities are estimated using the model regressing <code>exposure</code> on the terms in <code>denominator</code>, using the link function indicated by <code>family</code> and <code>link</code>.</p>
</li></ul>

<p>When the models from which the elements in the numerator and denominator are predicted are correctly specified, and there is no unmeasured confounding, weighting the observations by the inverse probability weights adjusts for confounding of the effect of the exposure of interest. On the weighted dataset a marginal structural model can then be fitted, quantifying the causal effect of the exposure on the outcome of interest.
</p>
<p>With <code>numerator</code> specified, stabilized weights are computed, otherwise unstabilized weighs with a numerator of 1 are computed. With a continuous exposure, using <code>family = "gaussian"</code>, weights are computed using the ratio of predicted densities. Therefore, for <code>family = "gaussian"</code> only stabilized weights can be used, since unstabilized weights would have infinity variance.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table role = "presentation">
<tr><td><code>ipw.weights</code></td>
<td>
<p>is a vector containing inverse probability weights for each unit under observation. This vector is returned in the same order as the measurements contained in <code>data</code>, to facilitate merging.</p>
</td></tr>
<tr><td><code>weights.trunc</code></td>
<td>
<p>is a vector containing truncated inverse probability weights for each unit under observation. This vector is only returned when <code>trunc</code> is specified.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>is the original function call to <code>ipwpoint</code>.</p>
</td></tr>
<tr><td><code>num.mod</code></td>
<td>
<p>is the numerator model, only returned when <code>numerator</code> is specified.</p>
</td></tr>
<tr><td><code>den.mod</code></td>
<td>
<p>is the denominator model.</p>
</td></tr>
</table>


<h3>Missing values</h3>

<p>Currently, the <code>exposure</code> variable and the variables used in <code>numerator</code> and <code>denominator</code> should not contain missing values.</p>


<h3>Author(s)</h3>

<p>Willem M. van der Wal <a href="mailto:willem@vanderwalresearch.com">willem@vanderwalresearch.com</a>, Ronald B. Geskus <a href="mailto:rgeskus@oucru.org">rgeskus@oucru.org</a></p>


<h3>References</h3>

<p>Cole, S.R. &amp; Hernán, M.A. (2008). Constructing inverse probability weights for marginal structural models. <em>American Journal of Epidemiology</em>, <b>168</b>(6), 656-664.
</p>
<p>Robins, J.M., Hernán, M.A. &amp; Brumback, B.A. (2000). Marginal structural models and causal inference in epidemiology. <em>Epidemiology</em>, <b>11</b>, 550-560.
</p>
<p>Van der Wal W.M. &amp; Geskus R.B. (2011). ipw: An R Package for Inverse  Probability Weighting. <em>Journal of Statistical Software</em>, <b>43</b>(13), 1-23. <a href="https://doi.org/10.18637/jss.v043.i13">doi:10.18637/jss.v043.i13</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+basdat">basdat</a></code>, <code><a href="#topic+haartdat">haartdat</a></code>, <code><a href="#topic+ipwplot">ipwplot</a></code>, <code><a href="#topic+ipwpoint">ipwpoint</a></code>, <code><a href="#topic+ipwtm">ipwtm</a></code>, <code><a href="#topic+timedat">timedat</a></code>, <code><a href="#topic+tstartfun">tstartfun</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Simulate data with continuous confounder and outcome, binomial exposure.
#Marginal causal effect of exposure on outcome: 10.
n &lt;- 1000
simdat &lt;- data.frame(l = rnorm(n, 10, 5))
a.lin &lt;- simdat$l - 10
pa &lt;- exp(a.lin)/(1 + exp(a.lin))
simdat$a &lt;- rbinom(n, 1, prob = pa)
simdat$y &lt;- 10*simdat$a + 0.5*simdat$l + rnorm(n, -10, 5)
simdat[1:5,]

#Estimate ipw weights.
temp &lt;- ipwpoint(
   exposure = a,
   family = "binomial",
   link = "logit",
   numerator = ~ 1,
   denominator = ~ l,
   data = simdat)
summary(temp$ipw.weights)

#Plot inverse probability weights
graphics.off()
ipwplot(weights = temp$ipw.weights, logscale = FALSE,
   main = "Stabilized weights", xlim = c(0, 8))

#Examine numerator and denominator models.
summary(temp$num.mod)
summary(temp$den.mod)

#Paste inverse probability weights
simdat$sw &lt;- temp$ipw.weights

#Marginal structural model for the causal effect of a on y
#corrected for confounding by l using inverse probability weighting
#with robust standard error from the survey package.
require("survey")
msm &lt;- (svyglm(y ~ a, design = svydesign(~ 1, weights = ~ sw,
   data = simdat)))
coef(msm)
confint(msm)


## Not run: 
#Compute basic bootstrap confidence interval .
#require(boot)
#boot.fun &lt;- function(dat, index){
#   coef(glm(
#       formula = y ~ a,
#       data = dat[index,],
#       weights = ipwpoint(
#           exposure = a,
#           family = "gaussian",
#           numerator = ~ 1,
#           denominator = ~ l,
#           data = dat[index,])$ipw.weights))[2]
#   }
#bootres &lt;- boot(simdat, boot.fun, 499);bootres
#boot.ci(bootres, type = "basic")

## End(Not run)

</code></pre>

<hr>
<h2 id='ipwtm'>Estimate Inverse Probability Weights (Time Varying)</h2><span id='topic+ipwtm'></span>

<h3>Description</h3>

<p>Estimate inverse probability weights to fit marginal structural models, with a time-varying exposure and time-varying confounders. Within each unit under observation this function computes inverse probability weights at each time point during follow-up. The exposure can be binomial, multinomial, ordinal or continuous. Both stabilized and unstabilized weights can be estimated.</p>


<h3>Usage</h3>

<pre><code class='language-R'>ipwtm(exposure, family, link, numerator = NULL, denominator, id,
       tstart, timevar, type, data, corstr = "ar1", trunc = NULL,
       ...)</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ipwtm_+3A_exposure">exposure</code></td>
<td>
<p>vector, representing the exposure of interest. Both numerical and categorical variables can be used. A binomial exposure variable should be coded using values <code>0</code>/<code>1</code>.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_family">family</code></td>
<td>
<p>specifies a family of link functions, used to model the relationship between the variables in <code>numerator</code> or <code>denominator</code> and <code>exposure</code>, respectively. Alternatives are <code>"binomial"</code>, <code>"survival"</code>, <code>"multinomial"</code>, <code>"ordinal"</code> and <code>"gaussian"</code>. A specific link function is then chosen using the argument <code>link</code>, as explained below. Regression models are fitted using <code><a href="stats.html#topic+glm">glm</a></code>, <code><a href="survival.html#topic+coxph">coxph</a></code>, <code><a href="nnet.html#topic+multinom">multinom</a></code>, <code><a href="MASS.html#topic+polr">polr</a></code> or <code>geeglm</code>, respectively.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_link">link</code></td>
<td>
<p>specifies the specific link function between the variables in <code>numerator</code> or <code>denominator</code> and exposure, respectively. For <code>family="binomial"</code> (fitted using <code><a href="stats.html#topic+glm">glm</a></code>) alternatives are <code>"logit"</code>, <code>"probit"</code>, <code>"cauchit"</code>, <code>"log"</code> and <code>"cloglog"</code>. For <code>family="survival"</code> this argument is ignored, and Cox proportional hazards models are always used (fitted using <code><a href="survival.html#topic+coxph">coxph</a></code>). For <code>family="multinomial"</code> this argument is ignored, and multinomial logistic regression models are always used (fitted using <code><a href="nnet.html#topic+multinom">multinom</a></code>). For <code>family=</code> <code>"ordinal"</code> (fitted using <code><a href="MASS.html#topic+polr">polr</a></code>) alternatives are <code>"logit"</code>, <code>"probit"</code>, <code>"cauchit"</code>, and <code>"cloglog"</code>. For <code>family="gaussian"</code> this argument is ignored, and GEE models with an identity link are always used (fitted using <code>geeglm</code>.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_numerator">numerator</code></td>
<td>
<p>is a formula, specifying the right-hand side of the model used to estimate the elements in the numerator of the inverse probability weights. When left unspecified, unstabilized weights with a numerator of 1 are estimated.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_denominator">denominator</code></td>
<td>
<p>is a formula, specifying the right-hand side of the model used to estimate the elements in the denominator of the inverse probability weights.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_id">id</code></td>
<td>
<p>vector, uniquely identifying the units under observation (typically patients) within which the longitudinal measurements are taken.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_tstart">tstart</code></td>
<td>
<p>numerical vector, representing the starting time of follow-up intervals, using the counting process notation. This argument is only needed when <code>family=</code> <code>"survival"</code>, otherwise it is ignored. The Cox proportional hazards models are fitted using counting process data. Since a switch in exposure level can occur at the start of follow-up, <code>tstart</code> should be negative for the first interval (with <code>timevar=0</code>) within each patient.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_timevar">timevar</code></td>
<td>
<p>numerical vector, representing follow-up time, starting at <code>0</code>. This variable is used as the end time of follow-up intervals, using the counting process notation, when <code>family="survival"</code>.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_type">type</code></td>
<td>
<p>specifies the type of exposure. Alternatives are <code>"first"</code>, <code>"cens"</code> and <code>"all"</code>. With <code>type="first"</code>, weights are estimated up to the first switch from the lowest exposure value (typically <code>0</code> or the first factor level) to any other value. After this switch, weights will then be constant. Such a weight is e.g. used when estimating the effect of &ldquo;initiation of HAART&rdquo; on mortality (see example 1 below). <code>type="first"</code> is currently only implemented for <code>"binomial"</code>, <code>"survival"</code>, <code>"multinomial"</code> and <code>"ordinal"</code> families. With <code>type="cens"</code> inverse probability of censoring weights (IPCW) are estimated as defined in appendix 1 in Cole &amp; Hernán (2008). IPCW is illustrated in example 1 below. <code>type="cens"</code> is currently only implemented for <code>"binomial"</code> and <code>"survival"</code> families. With <code>type="all"</code>, all time points are used to estimate weights. <code>type="all"</code> is implemented only for the <code>"binomial"</code> and <code>"gaussian"</code> family.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_data">data</code></td>
<td>
<p>dataframe containing <code>exposure</code>, variables in <code>numerator</code> and <code>denominator</code>, <code>id</code>, <code>tstart</code> and <code>timevar</code>.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_corstr">corstr</code></td>
<td>
<p>correlation structure, only needed when using <code>family = "gaussian"</code>. Defaults to &quot;ar1&quot;. See <code>geeglm</code> for details.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_trunc">trunc</code></td>
<td>
<p>optional truncation percentile (0-0.5). E.g. when <code>trunc = 0.01</code>, the left tail is truncated to the 1st percentile, and the right tail is truncated to the 99th percentile. When specified, both un-truncated and truncated weights are returned.</p>
</td></tr>
<tr><td><code id="ipwtm_+3A_...">...</code></td>
<td>
<p>are further arguments passed to the function that is used to estimate the numerator and denominator models (the function is chosen using <code>family</code>).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Within each unit under observation i (usually patients), this function computes inverse probability weights at each time point j during follow-up. These weights are the cumulative product over all previous time points up to j of the ratio of two probabilities:
</p>

<ul>
<li><p> the numerator contains at each time point the probability of the observed exposure level given observed values of stabilization factors and the observed exposure history up to the time point before j. These probabilities are estimated using the model regressing <code>exposure</code> on the terms in <code>numerator</code>, using the link function indicated by <code>family</code> and <code>link</code>.
</p>
</li>
<li><p> the denominator contains at each time point the probability of the observed exposure level given the observed history of time varying confounders up to j, as well as the stabilization factors in the numerator and the observed exposure history up to the time point before j. These probabilities are estimated using the model regressing <code>exposure</code> on the terms in <code>denominator</code>, using the link function indicated by <code>family</code> and <code>link</code>.</p>
</li></ul>

<p>When the models from which the elements in the numerator and denominator are predicted are correctly specified, and there is no unmeasured confounding, weighting observations ij by the inverse probability weights adjusts for confounding of the effect of the exposure of interest. On the weighted dataset a marginal structural model can then be fitted, quantifying the causal effect of the exposure on the outcome of interest.
</p>
<p>With <code>numerator</code> specified, stabilized weights are computed, otherwise unstabilized weights with a numerator of 1 are computed. With a continuous exposure, using <code>family = "gaussian"</code>, weights are computed using the ratio of predicted densities at each time point. Therefore, for <code>family = "gaussian"</code> only stabilized weights can be used, since unstabilized weights would have infinity variance.
</p>


<h3>Value</h3>

<p>A list containing the following elements:
</p>
<table role = "presentation">
<tr><td><code>ipw.weights</code></td>
<td>
<p>vector containing inverse probability weights for each observation. Returned in the same order as the observations in <code>data</code>, to facilitate merging.</p>
</td></tr>
<tr><td><code>weights.trunc</code></td>
<td>
<p>vector containing truncated inverse probability weights, only returned when <code>trunc</code> is specified.</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>the original function call.</p>
</td></tr>
<tr><td><code>selvar</code></td>
<td>
<p>selection variable. With <code>type = "first"</code>, <code>selvar = 1</code> within each unit under observation, up to and including the first time point at which a switch from the lowest value of <code>exposure</code> to any other value is made, and <code>selvar = 0</code> after the first switch. For <code>type = "all"</code>, <code>selvar = 1</code> for all measurements. The numerator and denominator models are fitted only on observations with <code>selvar = 1</code>. Returned in the same order as observations in <code>data</code>, to facilitate merging.</p>
</td></tr>
<tr><td><code>num.mod</code></td>
<td>
<p>the numerator model, only returned when <code>numerator</code> is specified.</p>
</td></tr>
<tr><td><code>den.mod</code></td>
<td>
<p>the denominator model.</p>
</td></tr>
</table>


<h3>Missing values</h3>

<p>Currently, the <code>exposure</code> variable and the variables used in <code>numerator</code> and <code>denominator</code>, <code>id</code>, <code>tstart</code> and <code>timevar</code> should not contain missing values.</p>


<h3>Author(s)</h3>

<p>Willem M. van der Wal <a href="mailto:willem@vanderwalresearch.com">willem@vanderwalresearch.com</a>, Ronald B. Geskus <a href="mailto:rgeskus@oucru.org">rgeskus@oucru.org</a></p>


<h3>References</h3>

<p>Cole, S.R. &amp; Hernán, M.A. (2008). Constructing inverse probability weights for marginal structural models. <em>American Journal of Epidemiology</em>, <b>168</b>(6), 656-664. <a href="https://pubmed.ncbi.nlm.nih.gov:443/18682488/">https://pubmed.ncbi.nlm.nih.gov:443/18682488/</a>.
</p>
<p>Robins, J.M., Hernán, M.A. &amp; Brumback, B.A. (2000). Marginal structural models and causal inference in epidemiology. <em>Epidemiology</em>, <b>11</b>, 550-560. <a href="https://pubmed.ncbi.nlm.nih.gov/10955408/">https://pubmed.ncbi.nlm.nih.gov/10955408/</a>.
</p>
<p>Van der Wal W.M. &amp; Geskus R.B. (2011). ipw: An R Package for Inverse  Probability Weighting. <em>Journal of Statistical Software</em>, <b>43</b>(13), 1-23. <a href="https://doi.org/10.18637/jss.v043.i13">doi:10.18637/jss.v043.i13</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+basdat">basdat</a></code>, <code><a href="#topic+haartdat">haartdat</a></code>, <code><a href="#topic+ipwplot">ipwplot</a></code>, <code><a href="#topic+ipwpoint">ipwpoint</a></code>, <code><a href="#topic+ipwtm">ipwtm</a></code>, <code><a href="#topic+timedat">timedat</a></code>, <code><a href="#topic+tstartfun">tstartfun</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>########################################################################
#EXAMPLE 1

#Load longitudinal data from HIV positive individuals.
data(haartdat)

#CD4 is confounder for the effect of initiation of HAART therapy on mortality.
#Estimate inverse probability weights to correct for confounding.
#Exposure allocation model is Cox proportional hazards model.
temp &lt;- ipwtm(
   exposure = haartind,
   family = "survival",
   numerator = ~ sex + age,
   denominator = ~ sex + age + cd4.sqrt,
   id = patient,
   tstart = tstart,
   timevar = fuptime,
   type = "first",
   data = haartdat)

#plot inverse probability weights
graphics.off()
ipwplot(weights = temp$ipw.weights, timevar = haartdat$fuptime,
  binwidth = 100, ylim = c(-1.5, 1.5), main = "Stabilized inverse probability weights")

#CD4 count has an effect both on dropout and mortality, which causes informative censoring.
#Use inverse probability of censoring weighting to correct for effect of CD4 on dropout.
#Use Cox proportional hazards model for dropout.
temp2 &lt;- ipwtm(
   exposure = dropout,
   family = "survival",
   numerator = ~ sex + age,
   denominator = ~ sex + age + cd4.sqrt,
   id = patient,
   tstart = tstart,
   timevar = fuptime,
   type = "cens",
   data = haartdat)

#plot inverse probability of censoring weights
graphics.off()
ipwplot(weights = temp2$ipw.weights, timevar = haartdat$fuptime,
  binwidth = 100, ylim = c(-1.5, 1.5), main = "Stabilized inverse probability of censoring weights")

#MSM for the causal effect of initiation of HAART on mortality.
#Corrected both for confounding and informative censoring.
#With robust standard error obtained using cluster().
require(survival)
summary(coxph(Surv(tstart, fuptime, event) ~ haartind + cluster(patient),
   data = haartdat, weights = temp$ipw.weights*temp2$ipw.weights))

#uncorrected model
summary(coxph(Surv(tstart, fuptime, event) ~ haartind, data = haartdat))

########################################################################
#EXAMPLE 2

data(basdat)
data(timedat)

#Aim: to model the causal effect of active tuberculosis (TB) on mortality.
#Longitudinal CD4 is a confounder as well as intermediate for the effect of TB.

#process original measurements
   #check for ties (not allowed)
      table(duplicated(timedat[,c("id", "fuptime")]))
   #take square root of CD4 because of skewness
      timedat$cd4.sqrt &lt;- sqrt(timedat$cd4count)
   #add TB time to dataframe
      timedat &lt;- merge(timedat, basdat[,c("id", "Ttb")], by = "id", all.x = TRUE)
   #compute TB status
      timedat$tb.lag &lt;- ifelse(with(timedat, !is.na(Ttb) &amp; fuptime &gt; Ttb), 1, 0)
   #longitudinal CD4-model
      require(nlme)
      cd4.lme &lt;- lme(cd4.sqrt ~ fuptime + tb.lag, random = ~ fuptime | id,
      data = timedat)

#build new dataset:
#rows corresponding to TB-status switches, and individual end times
   times &lt;- sort(unique(c(basdat$Ttb, basdat$Tend)))
   startstop &lt;- data.frame(
      id = rep(basdat$id, each = length(times)),
      fuptime = rep(times, nrow(basdat)))
   #add baseline data to dataframe
      startstop &lt;- merge(startstop, basdat, by = "id", all.x = TRUE)
   #limit individual follow-up using Tend
      startstop &lt;- startstop[with(startstop, fuptime &lt;= Tend),]
   startstop$tstart &lt;- tstartfun(id, fuptime, startstop) #compute tstart (?tstartfun)
   #indicate TB status
      startstop$tb &lt;- ifelse(with(startstop, !is.na(Ttb) &amp; fuptime &gt;= Ttb), 1, 0)
   #indicate TB status at previous time point
      startstop$tb.lag &lt;- ifelse(with(startstop, !is.na(Ttb) &amp; fuptime &gt; Ttb), 1, 0)
   #indicate death
      startstop$event &lt;- ifelse(with(startstop, !is.na(Tdeath) &amp; fuptime &gt;= Tdeath),
      1, 0)
   #impute CD4, based on TB status at previous time point.
      startstop$cd4.sqrt &lt;- predict(cd4.lme, newdata = data.frame(id = startstop$id,
         fuptime = startstop$fuptime, tb.lag = startstop$tb.lag))

#compute inverse probability weights
   temp &lt;- ipwtm(
      exposure = tb,
      family = "survival",
      numerator = ~ 1,
      denominator = ~ cd4.sqrt,
      id = id,
      tstart = tstart,
      timevar = fuptime,
      type = "first",
      data = startstop)
   summary(temp$ipw.weights)
   ipwplot(weights = temp$ipw.weights, timevar = startstop$fuptime, binwidth = 100)

#models
   #IPW-fitted MSM, using cluster() to obtain robust standard error estimate
      require(survival)
      summary(coxph(Surv(tstart, fuptime, event) ~ tb + cluster(id),
      data = startstop, weights = temp$ipw.weights))
   #unadjusted
      summary(coxph(Surv(tstart, fuptime, event) ~ tb, data = startstop))
   #adjusted using conditioning: part of the effect of TB is adjusted away
      summary(coxph(Surv(tstart, fuptime, event) ~ tb + cd4.sqrt, data = startstop))

## Not run: 
#compute bootstrap CI for TB parameter (takes a few hours)
#taking into account the uncertainty introduced by modelling longitudinal CD4
#taking into account the uncertainty introduced by estimating the inverse probability weights
#robust with regard to weights unequal to 1
#  require(boot)
#  boot.fun &lt;- function(data, index, data.tm){
#     data.samp &lt;- data[index,]
#     data.samp$id.samp &lt;- 1:nrow(data.samp)
#     data.tm.samp &lt;- do.call("rbind", lapply(data.samp$id.samp, function(id.samp) {
#       cbind(data.tm[data.tm$id == data.samp$id[data.samp$id.samp == id.samp],],
#         id.samp = id.samp)
#       }
#     ))
#     cd4.lme &lt;- lme(cd4.sqrt ~ fuptime + tb.lag, random = ~ fuptime | id.samp, data = data.tm.samp)
#     times &lt;- sort(unique(c(data.samp$Ttb, data.samp$Tend)))
#     startstop.samp &lt;- data.frame(id.samp = rep(data.samp$id.samp, each = length(times)),
#                                  fuptime = rep(times, nrow(data.samp)))
#     startstop.samp &lt;- merge(startstop.samp, data.samp, by = "id.samp", all.x = TRUE)
#     startstop.samp &lt;- startstop.samp[with(startstop.samp, fuptime &lt;= Tend),]
#     startstop.samp$tstart &lt;- tstartfun(id.samp, fuptime, startstop.samp)
#     startstop.samp$tb &lt;- ifelse(with(startstop.samp, !is.na(Ttb) &amp; fuptime &gt;= Ttb), 1, 0)
#     startstop.samp$tb.lag &lt;- ifelse(with(startstop.samp, !is.na(Ttb) &amp; fuptime &gt; Ttb), 1, 0)
#     startstop.samp$event &lt;- ifelse(with(startstop.samp, !is.na(Tdeath) &amp; fuptime &gt;= Tdeath), 1, 0)
#     startstop.samp$cd4.sqrt &lt;- predict(cd4.lme, newdata = data.frame(id.samp =
#       startstop.samp$id.samp, fuptime = startstop.samp$fuptime, tb.lag = startstop.samp$tb.lag))
#
#     return(coef(coxph(Surv(tstart, fuptime, event) ~ tb, data = startstop.samp,
#        weights = ipwtm(
#             exposure = tb,
#             family = "survival",
#             numerator = ~ 1,
#             denominator = ~ cd4.sqrt,
#             id = id.samp,
#             tstart = tstart,
#             timevar = fuptime,
#             type = "first",
#             data = startstop.samp)$ipw.weights))[1])
#     }
#  bootres &lt;- boot(data = basdat, statistic = boot.fun, R = 999, data.tm = timedat)
#  bootres
#  boot.ci(bootres, type = "basic")
#
## End(Not run)
</code></pre>

<hr>
<h2 id='timedat'>HIV: TB and Survival (Longitudinal Measurements)</h2><span id='topic+timedat'></span>

<h3>Description</h3>

<p>Simulated dataset. Time varying CD4 measurements of 386 HIV positive individuals. Time of first active tuberculosis, time of death and individual end time of the patients are included in dataset <code><a href="#topic+basdat">basdat</a></code>.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(timedat)</code></pre>


<h3>Format</h3>

<p>A data frame with 6291 observations on the following 3 variables.
</p>

<dl>
<dt><code>id</code></dt><dd><p>patient ID.</p>
</dd>
<dt><code>fuptime</code></dt><dd><p>follow-up time (days since HIV seroconversion).</p>
</dd>
<dt><code>cd4count</code></dt><dd><p>CD4 count measured at fuptime.</p>
</dd>
</dl>



<h3>Details</h3>

<p>These simulated data are used together with data in <code><a href="#topic+basdat">basdat</a></code> in a detailed causal modelling example using inverse probability weighting (IPW). See <code><a href="#topic+ipwtm">ipwtm</a></code> for the example. Data were simulated using the algorithm described in Van der Wal e.a. (2009).
</p>


<h3>Author(s)</h3>

<p>Willem M. van der Wal <a href="mailto:willem@vanderwalresearch.com">willem@vanderwalresearch.com</a>, Ronald B. Geskus <a href="mailto:rgeskus@oucru.org">rgeskus@oucru.org</a></p>


<h3>References</h3>

<p>Cole, S.R. &amp; Hernán, M.A. (2008). Constructing inverse probability weights for marginal structural models. <em>American Journal of Epidemiology</em>, <b>168</b>(6), 656-664.
</p>
<p>Robins, J.M., Hernán, M.A. &amp; Brumback, B.A. (2000). Marginal structural models and causal inference in epidemiology. <em>Epidemiology</em>, <b>11</b>, 550-560.
</p>
<p>Van der Wal W.M. &amp; Geskus R.B. (2011). ipw: An R Package for Inverse  Probability Weighting. <em>Journal of Statistical Software</em>, <b>43</b>(13), 1-23. <a href="https://doi.org/10.18637/jss.v043.i13">doi:10.18637/jss.v043.i13</a>.
</p>
<p>Van der Wal W.M., Prins M., Lumbreras B. &amp; Geskus R.B. (2009). A simple G-computation algorithm to quantify the causal effect of a secondary illness on the progression of a chronic disease. <em>Statistics in Medicine</em>, <b>28</b>(18), 2325-2337.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+basdat">basdat</a></code>, <code><a href="#topic+haartdat">haartdat</a></code>, <code><a href="#topic+ipwplot">ipwplot</a></code>, <code><a href="#topic+ipwpoint">ipwpoint</a></code>, <code><a href="#topic+ipwtm">ipwtm</a></code>, <code><a href="#topic+timedat">timedat</a></code>, <code><a href="#topic+tstartfun">tstartfun</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#See ?ipwtm for example
</code></pre>

<hr>
<h2 id='tstartfun'>Compute Starting Time For Counting Process Notation</h2><span id='topic+tstartfun'></span>

<h3>Description</h3>

<p>Function to compute starting time for intervals of follow-up, when using the counting process notation. Within each unit under observation (usually individuals), computes starting time equal to:
</p>

<ul>
<li><p> time of previous record when there is a previous record.
</p>
</li>
<li><p> -1 for first record.
</p>
</li></ul>


<h3>Usage</h3>

<pre><code class='language-R'>tstartfun(id, timevar, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="tstartfun_+3A_id">id</code></td>
<td>
<p>numerical vector, uniquely identifying the units under observation, within which the longitudinal measurements are taken.</p>
</td></tr>
<tr><td><code id="tstartfun_+3A_timevar">timevar</code></td>
<td>
<p>numerical vector, representing follow-up time, starting at 0.</p>
</td></tr>
<tr><td><code id="tstartfun_+3A_data">data</code></td>
<td>
<p>dataframe containing <code>id</code> and <code>timevar</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Numerical vector containing starting time for each record. In the same order as the records in <code>data</code>, to facilitate merging.</p>


<h3>Missing values</h3>

<p>Currently, <code>id</code> and <code>timevar</code> should not contain missing values.</p>


<h3>Author(s)</h3>

<p>Willem M. van der Wal <a href="mailto:willem@vanderwalresearch.com">willem@vanderwalresearch.com</a>, Ronald B. Geskus <a href="mailto:rgeskus@oucru.org">rgeskus@oucru.org</a></p>


<h3>References</h3>

<p>Van der Wal W.M. &amp; Geskus R.B. (2011). ipw: An R Package for Inverse  Probability Weighting. <em>Journal of Statistical Software</em>, <b>43</b>(13), 1-23. <a href="https://doi.org/10.18637/jss.v043.i13">doi:10.18637/jss.v043.i13</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+basdat">basdat</a></code>, <code><a href="#topic+haartdat">haartdat</a></code>, <code><a href="#topic+ipwplot">ipwplot</a></code>, <code><a href="#topic+ipwpoint">ipwpoint</a></code>, <code><a href="#topic+ipwtm">ipwtm</a></code>, <code><a href="#topic+timedat">timedat</a></code>, <code><a href="#topic+tstartfun">tstartfun</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>#data
mydata1 &lt;- data.frame(
   patient = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2),
   time.days = c(14, 34, 41, 56, 72, 98, 0, 11, 28, 35))

#compute starting time for each interval
mydata1$tstart &lt;- tstartfun(patient, time.days, mydata1)

#result
mydata1

#see also ?ipwtm for example
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
