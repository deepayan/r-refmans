<!DOCTYPE html><html><head><title>Help for package misspi</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {misspi}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#evaliq'><p>Evaluate the Imputation Quality</p></a></li>
<li><a href='#missar'><p>Generate Data that is Missing At Random (MAR)</p></a></li>
<li><a href='#misspi'><p>Missing Value Imputation in Parallel</p></a></li>
<li><a href='#toxicity'><p>Toxicity Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Missing Value Imputation in Parallel</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A framework that boosts the imputation of 'missForest' by Stekhoven, D.J. and BÃ¼hlmann, P. (2012) &lt;<a href="https://doi.org/10.1093%2Fbioinformatics%2Fbtr597">doi:10.1093/bioinformatics/btr597</a>&gt; by harnessing parallel processing and through the fast Gradient Boosted Decision Trees (GBDT) implementation 'LightGBM' by Ke, Guolin et al.(2017) <a href="https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision">https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision</a>. 'misspi' has the following main advantages:
             1. Allows embrassingly parallel imputation on large scale data.
             2. Accepts a variety of machine learning models as methods with friendly user portal.
             3. Supports multiple initializations methods.
             4. Supports early stopping that prohibits unnecessary iterations.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>lightgbm, doParallel, doSNOW, foreach, ggplot2, glmnet, SIS,
plotly</td>
</tr>
<tr>
<td>Suggests:</td>
<td>e1071, neuralnet</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-16 20:07:35 UTC; jiangzhongli</td>
</tr>
<tr>
<td>Author:</td>
<td>Zhongli Jiang [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Zhongli Jiang &lt;jiang548@purdue.edu&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-17 09:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='evaliq'>Evaluate the Imputation Quality</h2><span id='topic+evaliq'></span>

<h3>Description</h3>

<p>Calculates Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Normalized Root Mean Squared Error (NRMSE). It also performs visualization for imputation quality evaluation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>evaliq(x.true, x.impute, plot = TRUE, interactive = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="evaliq_+3A_x.true">x.true</code></td>
<td>
<p>a vector with true values.</p>
</td></tr>
<tr><td><code id="evaliq_+3A_x.impute">x.impute</code></td>
<td>
<p>a vector with estimated values.</p>
</td></tr>
<tr><td><code id="evaliq_+3A_plot">plot</code></td>
<td>
<p>a Boolean that indicates whether to plot or not.</p>
</td></tr>
<tr><td><code id="evaliq_+3A_interactive">interactive</code></td>
<td>
<p>a Boolean that indicates whether to use interactive plot when the plot option is invoked (plot = &quot;TRUE&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>rmse root mean squared error.
</p>
<p>mae mean absolute error.
</p>
<p>nrmse normalized root mean squared error.
</p>


<h3>Author(s)</h3>

<p>Zhongli Jiang <a href="mailto:jiang548@purdue.edu">jiang548@purdue.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+misspi">misspi</a></code>, <code><a href="#topic+missar">missar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A very quick example
n &lt;- 100
x.true &lt;- rnorm(n)
x.est &lt;- x.true
na.idx &lt;- sample(1:n, 20)
x.est[na.idx] &lt;- x.est[na.idx] + rnorm(length(na.idx), sd = 0.1)

# Default plot
er.eval &lt;- evaliq(x.true[na.idx], x.est[na.idx])

# Interactive plot
er.eval &lt;- evaliq(x.true[na.idx], x.est[na.idx], interactive = TRUE)

# Turn off plot
# All of the three case will return the value of error
er.eval &lt;- evaliq(x.true[na.idx], x.est[na.idx], plot = FALSE)
er.eval



# Real data example
set.seed(0)
data(toxicity, package = "misspi")
toxicity.miss &lt;- missar(toxicity, 0.4, 0.2)
impute.res &lt;- misspi(toxicity.miss)
x.imputed &lt;- impute.res$x.imputed

na.idx &lt;- which(is.na(toxicity.miss))
evaliq(toxicity[na.idx], x.imputed[na.idx])
evaliq(toxicity[na.idx], x.imputed[na.idx], interactive = TRUE)

</code></pre>

<hr>
<h2 id='missar'>Generate Data that is Missing At Random (MAR)</h2><span id='topic+missar'></span>

<h3>Description</h3>

<p>Simulates missing value at random as NA for a given matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>missar(x, miss.rate = 0.2, miss.var = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="missar_+3A_x">x</code></td>
<td>
<p>a matrix to be used to fill in missing values as NA.</p>
</td></tr>
<tr><td><code id="missar_+3A_miss.rate">miss.rate</code></td>
<td>
<p>a value of missing rate within the range (0, 1) for variables that contain missing values.</p>
</td></tr>
<tr><td><code id="missar_+3A_miss.var">miss.var</code></td>
<td>
<p>proportion of variables (columns) that contain missing values.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>x a matrix with missing values in &quot;NA&quot;.
</p>


<h3>Author(s)</h3>

<p>Zhongli Jiang <a href="mailto:jiang548@purdue.edu">jiang548@purdue.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+misspi">misspi</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

set.seed(0)
data(toxicity, package = "misspi")
toxicity.miss &lt;- missar(toxicity, 0.4, 1)
toxicity.miss[1:5, 1:5]

</code></pre>

<hr>
<h2 id='misspi'>Missing Value Imputation in Parallel</h2><span id='topic+misspi'></span>

<h3>Description</h3>

<p>Enables embarrassingly parallel computing for imputation. Some of the advantages include
</p>

<ul>
<li><p> Provides fast implementation especially for high dimensional datasets.
</p>
</li>
<li><p> Accepts a variety of machine learning models as methods with friendly user portal.
</p>
</li>
<li><p> Supports multiple initializations.
</p>
</li>
<li><p> Supports early stopping that prohibits unnecessary iterations.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>misspi(
  x,
  ncore = NULL,
  init.method = "rf",
  method = "rf",
  earlystopping = TRUE,
  ntree = 100,
  init.ntree = 100,
  viselect = NULL,
  lgb.params = NULL,
  lgb.params0 = NULL,
  model.train = NULL,
  pmm = TRUE,
  nn = 3,
  intcol = NULL,
  maxiter = 10,
  rdiff.thre = 0.01,
  verbose = TRUE,
  progress = TRUE,
  nlassofold = 5,
  isis = FALSE,
  char = " * ",
  iteration = TRUE,
  ndecimal = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="misspi_+3A_x">x</code></td>
<td>
<p>a matrix of numerical values for imputation, missing value should all be &quot;NA&quot;.</p>
</td></tr>
<tr><td><code id="misspi_+3A_ncore">ncore</code></td>
<td>
<p>number of cores to use, will be set to the cores detected as default.</p>
</td></tr>
<tr><td><code id="misspi_+3A_init.method">init.method</code></td>
<td>
<p>initializing method to fill in the missing value before imputation. Support &quot;rf&quot; for random forest imputation as default, &quot;mean&quot; for mean imputation, &quot;median&quot; for median imputation.</p>
</td></tr>
<tr><td><code id="misspi_+3A_method">method</code></td>
<td>
<p>method name for the imputation, support &quot;rf&quot; for random forest, &quot;lgb&quot; for lightgbm, &quot;lasso&quot; for LASSO, or &quot;customize&quot; if you want to use your own method.</p>
</td></tr>
<tr><td><code id="misspi_+3A_earlystopping">earlystopping</code></td>
<td>
<p>a Boolean which indicates whether to stop the algorithm if the relative difference stop decreasing, with TRUE as default.</p>
</td></tr>
<tr><td><code id="misspi_+3A_ntree">ntree</code></td>
<td>
<p>number of trees to use for imputation when method is &quot;rf&quot; or &quot;gbm&quot;.</p>
</td></tr>
<tr><td><code id="misspi_+3A_init.ntree">init.ntree</code></td>
<td>
<p>number of trees to use for initialization when method is &quot;rf&quot;</p>
</td></tr>
<tr><td><code id="misspi_+3A_viselect">viselect</code></td>
<td>
<p>the number of variables with highest variable importance calculated from random forest initialization to work on if the value is not NULL. This would only work when init.method is &quot;rf&quot;, and method is &quot;rf&quot; or &quot;gbm&quot;.</p>
</td></tr>
<tr><td><code id="misspi_+3A_lgb.params">lgb.params</code></td>
<td>
<p>parameters to customize for lightgbm models, could be invoked when method is &quot;rf&quot; or &quot;gbm&quot;.</p>
</td></tr>
<tr><td><code id="misspi_+3A_lgb.params0">lgb.params0</code></td>
<td>
<p>parameters to customize for initialization using random forest, could be invoked when init.method is &quot;rf&quot;.</p>
</td></tr>
<tr><td><code id="misspi_+3A_model.train">model.train</code></td>
<td>
<p>machine learning model to be invoked for customizing the imputation. Only invoked when parameter method = &quot;customize&quot;. The input model should be able to take y~x for fitting process where y, and x are matrices, also make sure that it could be called using method &quot;predict&quot; for model prediction. You could pass the parameters for the model through the additional arguments ...</p>
</td></tr>
<tr><td><code id="misspi_+3A_pmm">pmm</code></td>
<td>
<p>a Boolean which indicated whether to use predictive mean matching.</p>
</td></tr>
<tr><td><code id="misspi_+3A_nn">nn</code></td>
<td>
<p>number of neighbors to use for prediction if predictive mean matching is invoked (pmm is &quot;TRUE&quot;).</p>
</td></tr>
<tr><td><code id="misspi_+3A_intcol">intcol</code></td>
<td>
<p>a vector of indices of columns that are know to be integer, and will be round to integer in every iteration.</p>
</td></tr>
<tr><td><code id="misspi_+3A_maxiter">maxiter</code></td>
<td>
<p>maximum number of iterations for imputation.</p>
</td></tr>
<tr><td><code id="misspi_+3A_rdiff.thre">rdiff.thre</code></td>
<td>
<p>relative difference threshold for determining the imputation convergence.</p>
</td></tr>
<tr><td><code id="misspi_+3A_verbose">verbose</code></td>
<td>
<p>a Boolean that indicates whether to print out the intermediate steps verbally.</p>
</td></tr>
<tr><td><code id="misspi_+3A_progress">progress</code></td>
<td>
<p>a Boolean that indicates whether to show the progress bar.</p>
</td></tr>
<tr><td><code id="misspi_+3A_nlassofold">nlassofold</code></td>
<td>
<p>number of folds for cross validation when the method is &quot;lasso&quot;.</p>
</td></tr>
<tr><td><code id="misspi_+3A_isis">isis</code></td>
<td>
<p>a Boolean that indicates whether to use isis if the method is &quot;lasso&quot;, recommended to use for ultra high dimension.</p>
</td></tr>
<tr><td><code id="misspi_+3A_char">char</code></td>
<td>
<p>a character to use which also accept unicode for progress bar. For example, u03c, u213c for pi, u2694 for swords, u2605 for star, u2654 for king, u26a1 for thunder, u2708 for plane.</p>
</td></tr>
<tr><td><code id="misspi_+3A_iteration">iteration</code></td>
<td>
<p>a Boolean that indicates whether use iterative algorithm.</p>
</td></tr>
<tr><td><code id="misspi_+3A_ndecimal">ndecimal</code></td>
<td>
<p>number of decimals to round for the result, with NULL meaning no intervention.</p>
</td></tr>
<tr><td><code id="misspi_+3A_...">...</code></td>
<td>
<p>other arguments to be passed to the method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list that contains the imputed values, time consumed and number of iterations.
</p>
<p>x.imputed the imputed matrix.
</p>
<p>time.elapsed time consumed for the algorithm.
</p>
<p>niter number of iterations used in the algorithm.
</p>


<h3>Author(s)</h3>

<p>Zhongli Jiang <a href="mailto:jiang548@purdue.edu">jiang548@purdue.edu</a>
</p>


<h3>References</h3>

<p>Azur, M. J., Stuart, E. A., Frangakis, C., &amp; Leaf, P. J. (2011). Multiple imputation by chained equations: what is it and how does it work?. International journal of methods in psychiatric research, 20(1), 40-49.
</p>
<p>Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., ... &amp; Liu, T. Y. (2017). Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems, 30.
</p>
<p>Stekhoven, D. J., &amp; BÃ¼hlmann, P. (2012). MissForestânon-parametric missing value imputation for mixed-type data. Bioinformatics, 28(1), 112-118.
</p>
<p>Fan, J., &amp; Lv, J. (2008). Sure independence screening for ultrahigh dimensional feature space. Journal of the Royal Statistical Society Series B: Statistical Methodology, 70(5), 849-911.
</p>
<p>Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society Series B: Statistical Methodology, 58(1), 267-288.
</p>
<p>Breiman, L. (2001). Random forests. Machine learning, 45, 5-32.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+missar">missar</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

# Quick example 1
# Load a small data
data(iris)
# Keep numerical columns
num.col &lt;- which(sapply(iris, is.numeric))
iris.numeric &lt;- as.matrix(iris[, num.col])
set.seed(0)
iris.miss &lt;- missar(iris.numeric, 0.3, 1)
iris.impute &lt;- misspi(iris.miss)
iris.impute

# Quick example 2
# Load a high dimensional data
data(toxicity, package = "misspi")
set.seed(0)
toxicity.miss &lt;- missar(toxicity, 0.4, 0.2)
toxicity.impute &lt;- misspi(toxicity.miss)
toxicity.impute

# Change cores
iris.impute.5core &lt;- misspi(iris.miss, ncore = 5)

# Change initialization and maximum iterations (no iteration in the example)
iris.impute.mean.5iter &lt;- misspi(iris.miss, init.method = "mean", maxiter = 0)

# Change fun shapes for progress bar
iris.impute.king &lt;- misspi(iris.miss, char = " \u2654")


# Use variable selection
toxicity.impute.vi &lt;- misspi(toxicity.miss, viselect = 128)


# Use different machine learning algorithms as method
# linear model
iris.impute.lm &lt;- misspi(iris.miss, model.train = lm)

# From external packages
# Support Vector Machine (SVM)

library(e1071)
iris.impute.svm.radial &lt;- misspi(iris.miss, model.train = svm)


# Neural Networks

library(neuralnet)
iris.impute.nn &lt;- misspi(iris.miss, model.train = neuralnet)


</code></pre>

<hr>
<h2 id='toxicity'>Toxicity Data</h2><span id='topic+toxicity'></span>

<h3>Description</h3>

<p>The data was created by Gul, S., Rahim, F., Isin, S. et al. (2021) <a href="https://doi.org/10.1038/s41598-021-97962-5">doi:10.1038/s41598-021-97962-5</a>, downloaded and cleaned from UCI Machine Learning Repository with <a href="https://doi.org/10.24432/C59313">doi:10.24432/C59313</a>. The toxicity data consists of 171 molecules with 1203 molecule descriptors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(toxicity)
</code></pre>


<h3>Format</h3>

<p>A matrix with 171 rows and 1203 columns
</p>


<h3>References</h3>

<p><a href="https://doi.org/10.1038/s41598-021-97962-5">doi:10.1038/s41598-021-97962-5</a> Gul, S., Rahim, F., Isin, S., Yilmaz, F., Ozturk, N., Turkay, M., &amp; Kavakli, I. H. (2021). Structure-based design and classifications of small molecules regulating the circadian rhythm period. Scientific reports, 11(1), 18510.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
