<!DOCTYPE html><html><head><title>Help for package climatol</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {climatol}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#climatol-internal'><p>Internal <code>climatol</code> functions</p></a></li>
<li><a href='#climatol2rclimdex'><p>Convert DAILY data from <code>climatol</code> to RClimDex input format</p></a></li>
<li><a href='#csv2climatol'><p>Convert data in a single CSV file to <code>climatol</code> input format</p></a></li>
<li><a href='#dahgrid'><p>Interpolation of normalized homogeneous data on a predefined grid</p></a></li>
<li><a href='#dahstat'><p>Extract series or statistics of the homogenized data</p></a></li>
<li><a href='#daily2climatol'><p>Convert daily data files to <code>climatol</code> input format</p></a></li>
<li><a href='#Datasets'><p>Data sets to run examples of the functions in the <code>climatol</code> package.</p></a></li>
<li><a href='#datrestore'><p>Rename homogen's output files</p></a></li>
<li><a href='#datsubset'><p>Subset data by subperiod, code list or no. of years with data</p></a></li>
<li><a href='#db2dat'><p>Get daily or monthly data from a database and build input files *.dat and *.est</p></a></li>
<li><a href='#dd2m'><p>Compute monthly data from daily (or subdaily) series</p></a></li>
<li><a href='#dens2Dplot'><p>Two dimensional density plot</p></a></li>
<li><a href='#diagwl'><p>Walter &amp; Lieth climatic diagram</p></a></li>
<li><a href='#exampleFiles'><p>Get the path to some example files</p></a></li>
<li><a href='#fix.sunshine'><p>Check homogenized daily sunshine hours and prune any excess</p></a></li>
<li><a href='#homogen'><p>Automatic homogenization of climatological series</p></a></li>
<li><a href='#IDFcurves'><p>Obtain Intensity-Duration-Frequency curves</p></a></li>
<li><a href='#meteogram'><p>Daily meteogram of eight meteorological variables</p></a></li>
<li><a href='#MHisopleths'><p>Isopleths on a months-hours diagram</p></a></li>
<li><a href='#outrename'><p>Rename homogen's output files</p></a></li>
<li><a href='#QCthresholds'><p>Obtain monthly thresholds for Quality Control alerts</p></a></li>
<li><a href='#rclimdex2climatol'><p>Convert RClimDex daily data files to <code>climatol</code> input format</p></a></li>
<li><a href='#runtnd'><p>Running trends on time windows of different lengths</p></a></li>
<li><a href='#sef2climatol'><p>Convert SEF data files to <code>climatol</code> input files.</p></a></li>
<li><a href='#windrose'><p>Wind-rose plot</p></a></li>
<li><a href='#xls2csv'><p>Join all data in *.xls or *.xlsx files into a single CSV file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>4.1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-03-23</td>
</tr>
<tr>
<td>Title:</td>
<td>Climate Tools (Series Homogenization and Derived Products)</td>
</tr>
<tr>
<td>Author:</td>
<td>Jose A. Guijarro &lt;jaguijarro21@gmail.com&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jose A. Guijarro &lt;jaguijarro21@gmail.com&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>grDevices, graphics, stats, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>evd, fields, gstat, maps, mapdata, ncdf4, raster, readxl,
RODBC, sp</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions for the quality control, homogenization and missing data filling of climatological series and to obtain climatological summaries and grids from the results. Also functions to display wind-roses, meteograms, Walter&amp;Lieth diagrams, and more.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://climatol.eu">https://climatol.eu</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-22 22:39:34 UTC; jag</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-22 23:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='climatol-internal'>Internal <code>climatol</code> functions</h2><span id='topic+cerrar'></span><span id='topic+climatol.version'></span><span id='topic+cuct'></span><span id='topic+read.dat'></span><span id='topic+snht'></span><span id='topic+wtest'></span><span id='topic+unsufix'></span>

<h3>Description</h3>

<p>Internal <code>climatol</code> functions
</p>


<h3>Details</h3>

<p>These functions are used internally and are not intended to be
called directly by the user.
</p>

<hr>
<h2 id='climatol2rclimdex'>Convert DAILY data from <code>climatol</code> to RClimDex input format</h2><span id='topic+climatol2rclimdex'></span>

<h3>Description</h3>

<p>This function reads homogenized daily series of precipitation (RR) and
extreme temperatures (TX, TN), adjusted from the last homogeneous sub-period,
and writes them in files (one per station) with RClimDex format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>climatol2rclimdex(varRR, varTX, varTN, yiRR, yfRR, yiTX=yiRR, yfTX=yfRR,
  yiTN=yiRR, yfTN=yfRR, header=TRUE, prefix='hoclm', dir=NA, na='-99.9')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="climatol2rclimdex_+3A_varrr">varRR</code>, <code id="climatol2rclimdex_+3A_vartx">varTX</code>, <code id="climatol2rclimdex_+3A_vartn">varTN</code></td>
<td>
<p>Name of the variables in the <code>climatol</code> destination files. If some variable is not available, name it as &rdquo;.</p>
</td></tr>  
<tr><td><code id="climatol2rclimdex_+3A_yirr">yiRR</code>, <code id="climatol2rclimdex_+3A_yfrr">yfRR</code></td>
<td>
<p>Initial and final years of the homogenized RR series.</p>
</td></tr>
<tr><td><code id="climatol2rclimdex_+3A_yitx">yiTX</code>, <code id="climatol2rclimdex_+3A_yftx">yfTX</code>, <code id="climatol2rclimdex_+3A_yitn">yiTN</code>, <code id="climatol2rclimdex_+3A_yftn">yfTN</code></td>
<td>
<p>Initial and final years of the TX and TN series. (The same as yiRR and yfRR by default.)</p>
</td></tr>
<tr><td><code id="climatol2rclimdex_+3A_header">header</code></td>
<td>
<p>include a header in the files? (<code>TRUE</code> by default)</p>
</td></tr>
<tr><td><code id="climatol2rclimdex_+3A_prefix">prefix</code></td>
<td>
<p>Prefix to prepend to station codes to name the output RClimDex files.</p>
</td></tr>
<tr><td><code id="climatol2rclimdex_+3A_dir">dir</code></td>
<td>
<p>Destination directory of the output RClimDex files. (If not set, they will be saved into the current R working directory).</p>
</td></tr>
<tr><td><code id="climatol2rclimdex_+3A_na">na</code></td>
<td>
<p>Missing data code to use in the ouput files. (<code>'-99.9'</code> by
default.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After homogenizing daily series with <code>climatol</code>, the user may be
interested in applying the RClimDex program to the homogenized series. This
function automatizes the conversion of file formats between both programs.
</p>
<p>Note that if there are some days with TX&lt;TN (can happen because of the
independent homogenization of extreme temperatures), a trivial fix will be
applied by just exchanging the problem values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory and generate input files:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)

## copy example daily RR, TX and TN homogenization results:
file.copy(exampleFiles('RR_1981-1995.rda'),'.')
file.copy(exampleFiles('TX_1981-1995.rda'),'.')
file.copy(exampleFiles('TN_1981-1995.rda'),'.')

## Now run the example:
climatol2rclimdex('RR','TX','TN',1981,1995)

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='csv2climatol'>Convert data in a single CSV file to <code>climatol</code> input format</h2><span id='topic+csv2climatol'></span>

<h3>Description</h3>

<p>This function helps to prepare the <code>climatol</code> input files when the users
have their data in a single CSV file, as the output of xls2csv().
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  csv2climatol(csvfile, datacol=6:8, stnfile=csvfile, stncol=1:5, varcli,
  anyi=NA, anyf=NA, mindat=NA, sep=',', dec='.', na.strings='NA',
  dateformat='%Y-%m-%d', cf=1, ndec=1, header=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="csv2climatol_+3A_csvfile">csvfile</code></td>
<td>
<p>name of the CSV file containing the data.</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_datacol">datacol</code></td>
<td>
<p>column(s) holding station codes, dates and data.</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_stnfile">stnfile</code></td>
<td>
<p>name of the CSV file containing station codes, names and
coordinates (if these data are not in the csvfile).</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_stncol">stncol</code></td>
<td>
<p>columns holding longitudes, latitudes, elevations and station
codes and names.</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_varcli">varcli</code></td>
<td>
<p>short name of the climatic variable under study.</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_anyi">anyi</code></td>
<td>
<p>first year to study.</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_anyf">anyf</code></td>
<td>
<p>last year to study.</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_mindat">mindat</code></td>
<td>
<p>minimum required number of data per station (by default,
60 monthly data or 365 daily data).</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_sep">sep</code></td>
<td>
<p>data separator (',' by default: Comma Separated Values).</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_dec">dec</code></td>
<td>
<p>decimal point ('.' by default).</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_na.strings">na.strings</code></td>
<td>
<p>strings coding missing data ('NA' by default).</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_dateformat">dateformat</code></td>
<td>
<p>format of dates (if not in separate columns.
Default: <code>'%Y-%m-%d')</code></p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_cf">cf</code></td>
<td>
<p>conversion factor to apply if data units need to be changed.</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_ndec">ndec</code></td>
<td>
<p>no. of decimals to round to.</p>
</td></tr>
<tr><td><code id="csv2climatol_+3A_header">header</code></td>
<td>
<p><code>TRUE</code> by default, set to <code>FALSE</code> if <code>csvfile</code> has no header.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>datacol</code> holds  4 (or 5) values, dates are expected to appear as
year, month (and days) in separate columns. Otherwise, dates will be provided
as character strings (see parameter <code>dateformat</code>).
Station codes, names and coordinates can go in a separate file
<code>stnfile</code>. At least coordinates and station codes must be present in
either <code>csvfile</code> or <code>stnfile</code>. Put a zero for any inexistent
columns. Example when <code>stnfile</code> contains only, in this order, latitudes,
longitudes and station names: <code>stncol=c(2,1,0,3,0)</code>.
Note that if a stnfile is provided, then sep, dec, na.strings and header
defined for csvfile will also be applied to stnfile.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+xls2csv">xls2csv</a></code>, <code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)

## Create origin and destination directories and copy example input files:
dir.create('dir1'); dir.create('dir2')
file.copy(exampleFiles('p064.xlsx'),'dir1')
file.copy(exampleFiles('p082.xlsx'),'dir1')
file.copy(exampleFiles('p084.xlsx'),'dir1')

## Create input files for csv2climatol with the function xls2csv:
xls2csv('dir1','dir2','RR')

## Add bogus coordinates and elevations to the station file:
est=read.table('xls_RR_stations.csv',sep=',')
est=data.frame(1:3,21:23,101:103,est)
write.table(est,'xls_RR_stations.csv',sep=',',row.names=FALSE,col.names=FALSE)

## Now run the example of csv2climatol:
csv2climatol('xls_RR_data.csv', datacol=1:5, stnfile='xls_RR_stations.csv',
  varcli='RR',header=FALSE)

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='dahgrid'>Interpolation of normalized homogeneous data on a predefined grid</h2><span id='topic+dahgrid'></span>

<h3>Description</h3>

<p>Homogenized data generated by <code><a href="#topic+homogen">homogen</a></code> are normalized and
interpolated on a grid provided by the user at every time step, and saved
into a NetCDF file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dahgrid(varcli, anyi, anyf, anyip=anyi, anyfp=anyf, grid, idp=2.0,
obsonly=TRUE, nmax=Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dahgrid_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the studied climatic variable, as in the data
file name.</p>
</td></tr>
<tr><td><code id="dahgrid_+3A_anyi">anyi</code></td>
<td>
<p>Initial year of the homogenized data.</p>
</td></tr>
<tr><td><code id="dahgrid_+3A_anyf">anyf</code></td>
<td>
<p>Final year of the homogenized data.</p>
</td></tr>
<tr><td><code id="dahgrid_+3A_anyip">anyip</code></td>
<td>
<p>First year of the desired reference period. (The reference period defaults to the whole period of the data).</p>
</td></tr>
<tr><td><code id="dahgrid_+3A_anyfp">anyfp</code></td>
<td>
<p>Last year of the desired reference period.</p>
</td></tr>
<tr><td><code id="dahgrid_+3A_grid">grid</code></td>
<td>
<p>Grid on which interpolations must be performed.</p>
</td></tr>
<tr><td><code id="dahgrid_+3A_idp">idp</code></td>
<td>
<p>Power of the inverse distance weights (2 by default).</p>
</td></tr>
<tr><td><code id="dahgrid_+3A_obsonly">obsonly</code></td>
<td>
<p>Do not interpolate estimated missing data. (<code>TRUE</code> by
default).</p>
</td></tr>
<tr><td><code id="dahgrid_+3A_nmax">nmax</code></td>
<td>
<p>Maximum number of nearest stations to use (all by default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Homogenized data are read from the binary file &lsquo;<span class="file">VRB_ANYI-ANYF.rda</span>&rsquo;
generated by <code><a href="#topic+homogen">homogen</a></code>. Only series reconstructed from their
longest homogeneous sub-period are retained, and they are normalized by their
means (and standard deviations, if <code>std=3</code>), computed for the selected
reference period (or for the whole period of the data, by default).
</p>
<p>Unless <code>obsonly</code> is set to <code>FALSE</code>, data that were missing in the
observed series are deleted to avoid interpolation of already interpolated
data.
</p>
<p>Finally, the normalized homogeneous data are interpolated on the predefined
grid for every time step using an inverse distance weight method, and the
resulting grids are stored in a NetCDF file named &lsquo;<span class="file">VRB_ANYIP-ANYFP.nc</span>&rsquo;,
including grids of the reference means (and standard deviations, if applied).
</p>
<p>The user must provide the grid as an object of class SpatialPixel, as in this
example defining a grid from 40N,3E to 43N,7E with a resolution of 0.1
degrees:
</p>
<p><code>grid &lt;- expand.grid(x=seq(3,7,.1),y=seq(40,43,.1))</code><br />
<code>library(sp)</code><br />
<code>coordinates(grid) &lt;- ~ x+y</code>
</p>
<p>The resolution of this grid need not be too high, but adjusted to the spatial
density of the available series. However, a higher resolution will produce
smoother maps when plotted.
</p>
<p>The user may be more interested in obtaining grids of absolute values, rather
than normalized. This can be achieved simply by undoing the normalization on
the grids with the help of the provided grids of reference means and standard
deviations. However, the resulting grids will only be the product of a
geometrical interpolation, and will not reflect the influence of orography
and other physiographic effects on the studied climatic variable. Therefore,
it is more advisable to derive better reference grids of means (and standard
deviations, if needed) by applying a geostatistical model to the reference
means (provided in the file &lsquo;<span class="file">VRB_ANYIP-ANYFP_means.csv</span>&rsquo; with their
corresponding coordinates).
</p>
<p>This better quality climatic maps will probably have a higher resolution than
that of the grids of the NetCDF file provided by this function. In that case,
these normalized grids must be interpolated to the grid of the
geostatistically derived climatic maps before undoing the normalization to
obtain the final maps of absolute values at all or selected time-steps of the
studied period.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory and write input files:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)

## Copy an example file of homogenization results:
file.copy(exampleFiles('Temp_1991-2000.rda'),'.')

## Now run the example:
## (very coarse grid (3x2 points) to run in less than the 10 seconds CRAN limit)
grd &lt;- expand.grid(x=seq(-2.8,-2.4,.2),y=seq(38.86,39.06,.2))
sp::coordinates(grd) &lt;- ~ x+y
dahgrid('Temp',1991,2000,grid=grd)

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='dahstat'>Extract series or statistics of the homogenized data</h2><span id='topic+dahstat'></span>

<h3>Description</h3>

<p>Lists series, means, medians, standard deviations, quantiles or trends, for a
specified period, from series homogenized by <code><a href="#topic+homogen">homogen</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dahstat(varcli, anyi, anyf, anyip=anyi, anyfp=anyf, stat="me", ndc=NA, vala=2,
valm=vala, cod=NULL, prob=.5, all=FALSE, long=FALSE, relref=FALSE, pernyr=10,
estcol=c(1,2,4), sep=',', dec='.')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dahstat_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the studied climatic variable,
as in the data file name.</p>
</td></tr>
<tr><td><code id="dahstat_+3A_anyi">anyi</code></td>
<td>
<p>Initial year of the homogenized period.</p>
</td></tr>
<tr><td><code id="dahstat_+3A_anyf">anyf</code></td>
<td>
<p>Final year of the homogenized period.</p>
</td></tr>
<tr><td><code id="dahstat_+3A_anyip">anyip</code></td>
<td>
<p>First year of the period to analyze. (Defaults to <code>anyi</code>).</p>
</td></tr>
<tr><td><code id="dahstat_+3A_anyfp">anyfp</code></td>
<td>
<p>Last year of the period to analyze. (Defaults to <code>anyf</code>).</p>
</td></tr>
<tr><td><code id="dahstat_+3A_stat">stat</code></td>
<td>
<p>Statistical parameter to compute for the selected period:
</p>

<dl>
<dt>&quot;me&quot;:</dt><dd><p>Means (default),</p>
</dd>
<dt>&quot;mdn&quot;</dt><dd><p>Medians,</p>
</dd>
<dt>&quot;max&quot;</dt><dd><p>Maxima,</p>
</dd>
<dt>&quot;min&quot;</dt><dd><p>Minima,</p>
</dd>
<dt>&quot;std&quot;</dt><dd><p>Standard deviations,</p>
</dd>
<dt>&quot;q&quot;</dt><dd><p>Quantiles (see the <code>prob</code> parameter),</p>
</dd>
<dt>&quot;tnd&quot;</dt><dd><p>OLS trends and their p-values,</p>
</dd>
<dt>&quot;series&quot;</dt><dd><p>Do not compute any statistic; only write homogenized
series and flags into two CSV files.</p>
</dd>
<dt>&quot;mseries&quot;</dt><dd><p>As before, but output series in individual *.csv files.
(Not applicable to daily series.)</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="dahstat_+3A_ndc">ndc</code></td>
<td>
<p>Number of decimal places to be saved in the output file (defaults to that used in the homogenization).</p>
</td></tr>
<tr><td><code id="dahstat_+3A_vala">vala</code></td>
<td>
<p>Annual values to compute from the sub-annual data:
</p>

<dl>
<dt>0:</dt><dd><p>None,</p>
</dd>
<dt>1:</dt><dd><p>Sum,</p>
</dd>
<dt>2:</dt><dd><p>Mean (default),</p>
</dd>
<dt>3:</dt><dd><p>Maximum,</p>
</dd>
<dt>4:</dt><dd><p>Minimum.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="dahstat_+3A_valm">valm</code></td>
<td>
<p>Monthly values to calculate from sub-monthly data (defaults to
<code>vala</code>):
</p>

<dl>
<dt>1:</dt><dd><p>Sum,</p>
</dd>
<dt>2:</dt><dd><p>Mean,</p>
</dd>
<dt>3:</dt><dd><p>Maximum,</p>
</dd>
<dt>4:</dt><dd><p>Minimum.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="dahstat_+3A_cod">cod</code></td>
<td>
<p>Vector of requested station codes (all by default).</p>
</td></tr>
<tr><td><code id="dahstat_+3A_prob">prob</code></td>
<td>
<p>Probability for the computation of quantiles (0.5 by default,
i.e., medians). You can set probabilities with more than 2 decimals, but
the name of the output file will be identified with the rounded percentile.</p>
</td></tr>
<tr><td><code id="dahstat_+3A_all">all</code></td>
<td>
<p>If <code>TRUE</code>, all reconstructed series will be used. The default
is <code>FALSE</code>, hence using only the series reconstructed from the last
homogeneous subperiod.</p>
</td></tr>
<tr><td><code id="dahstat_+3A_long">long</code></td>
<td>
<p>If <code>TRUE</code> (the default is <code>FALSE</code>), only series
reconstructed from the longest homogeneous subperiod will be used.</p>
</td></tr>
<tr><td><code id="dahstat_+3A_relref">relref</code></td>
<td>
<p>If <code>TRUE</code>, statistics from reliable reference series will
also be listed. (<code>FALSE</code> by default).</p>
</td></tr>
<tr><td><code id="dahstat_+3A_pernyr">pernyr</code></td>
<td>
<p>Number of years on which to express trend units (10 by default).</p>
</td></tr>
<tr><td><code id="dahstat_+3A_estcol">estcol</code></td>
<td>
<p>Columns of the homogenized stations file to be included in the
output file. (Defaults to c(1,2,4), the columns of station coordinates and codes).</p>
</td></tr>
<tr><td><code id="dahstat_+3A_sep">sep</code></td>
<td>
<p>Field separator (',' by default).</p>
</td></tr>
<tr><td><code id="dahstat_+3A_dec">dec</code></td>
<td>
<p>Decimal point ('.' by default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Homogenized data are read from the file &lsquo;<span class="file">VRB_ANYI-ANYF.rda</span>&rsquo;
saved by <code><a href="#topic+homogen">homogen</a></code>, while this function saves the
computed data for the specified period in &lsquo;<span class="file">VRB_ANYIP-ANYFP.STAT</span>&rsquo;,
where <code>STAT</code> is substituted by the <code>stat</code> requested
statistic. An exception is when <code>stat="q"</code>, since then the
extension of the output file will be <code>qPP</code>, where <code>PP</code>
stands for the specified <code>prob</code> probability (in percent).
</p>
<p>The output period <code>ANYIP-ANYFP</code> must of course be comprised
within the period of the input data, <code>ANYI-ANYF</code>.
</p>
<p><code>stat='tnd'</code> computes trends by Ordinary Least Squares linear regression
on time, listing them in a CSV file &lsquo;<span class="file">*_tnd.csv</span>&rsquo; and their p-values in
&lsquo;<span class="file">*_pval.csv</span>&rsquo;
</p>
<p>If <code>stat='series'</code> is chosen, two text files in CSV format will be
produced for every station, one with the data and another with their flags: 0
for original, 1 for infilled and 2 for corrected data.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code>, <code><a href="#topic+dahgrid">dahgrid</a></code>.</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)

## Copy an example file of homogenization results:
file.copy(exampleFiles('Temp_1991-2000.rda'),'.')

## Now run the examples:
dahstat('Temp', 1991, 2000)
dahstat('Temp', 1991, 2000, stat='q', prob=0.4)
dahstat('Temp', 1991, 2000, stat='tnd')
dahstat('Temp', 1991, 2000, stat='series')

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='daily2climatol'>Convert daily data files to <code>climatol</code> input format</h2><span id='topic+daily2climatol'></span>

<h3>Description</h3>

<p>This function can be useful to prepare the <code>climatol</code> input files when the users have their daily data in per station individual files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>daily2climatol(stfile, stcol=1:6, datcol=1:4, varcli, anyi=NA, anyf=NA,
  mindat=365, sep=',', dec='.', na.strings='NA', dateformat='%Y-%m-%d',
  header=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="daily2climatol_+3A_stfile">stfile</code></td>
<td>
<p>File with file names and station coordinates, codes and names.</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_stcol">stcol</code></td>
<td>
<p>Columns in <code>stfile</code> holding data file names, longitudes,
latitudes, elevations and station codes and names. (Defaults to 1:6. Use 0
for codes and/or names columns if they are missing, and numeric values will
be assigned.)</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_datcol">datcol</code></td>
<td>
<p>Columns in data files holding year, month, day, value.</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the studied climatic variable.</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_anyi">anyi</code></td>
<td>
<p>First year to study (defaults to the first year of available data).</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_anyf">anyf</code></td>
<td>
<p>Last year to study (defaults to the last year of available data).</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_mindat">mindat</code></td>
<td>
<p>Minimum required number of data per station. (Defaults to 365
daily data.)</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_sep">sep</code></td>
<td>
<p>Field separator in all files, whether data or stations. (',' by default.)</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_dec">dec</code></td>
<td>
<p>Decimal point. ('.' by default.)</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_na.strings">na.strings</code></td>
<td>
<p>Strings coding missing data (<code>'NA'</code> by default).</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_dateformat">dateformat</code></td>
<td>
<p>Format of dates if not in separate columns. (<code>'%Y-%m-%d'</code> by default.)</p>
</td></tr>
<tr><td><code id="daily2climatol_+3A_header">header</code></td>
<td>
<p>Logical value indicating whether input files have a header line
or not. (<code>TRUE</code> by default.)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many users have their daily series in separate files (one per station). This
function can be used to read these daily data files and write the input files
needed by the <code>homogen</code> function of this <code>climatol</code> package.
</p>
<p>When either station codes or names are missing in the stations file, its
corresponding column must be set to 0. In this case, codes and/or names will be
assigned with numeric values.
</p>
<p>Field separator, decimal point and the presence of a header line must be consistent in all files (data files and stations file).
</p>
<p>If your files follow the RClimDex convention, you can use the <code>rclimdex2climatol</code> function instead.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rclimdex2climatol">rclimdex2climatol</a></code>, <code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory and write example input files:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)
data(climatol_data)
df=cbind(File=c('p064.csv','p084.csv','p082.csv'),SIstations)
write.csv(df,'stations.csv',row.names=FALSE,quote=FALSE)
write.csv(p064.df,'p064.csv',row.names=FALSE,quote=FALSE)
write.csv(p084.df,'p084.csv',row.names=FALSE,quote=FALSE)
write.csv(p082.df,'p082.csv',row.names=FALSE,quote=FALSE)

## Now run the example:
daily2climatol(stfile='stations.csv',varcli='RR')

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='Datasets'>Data sets to run examples of the functions in the <code>climatol</code> package.</h2><span id='topic+Datasets'></span><span id='topic+climatol_data'></span><span id='topic+AWS_1day'></span><span id='topic+AWS_1year'></span><span id='topic+datcli'></span><span id='topic+p064.df'></span><span id='topic+p082.df'></span><span id='topic+p084.df'></span><span id='topic+prec10min'></span><span id='topic+RR3st'></span><span id='topic+SIstations'></span><span id='topic+Tav'></span><span id='topic+Temp.dat'></span><span id='topic+Temp.est'></span><span id='topic+TN3st'></span><span id='topic+TX3st'></span>

<h3>Description</h3>

<p>This object contains several small datasets needed to run the examples of most functions.</p>


<h3>Usage</h3>

<pre><code class='language-R'>  data(climatol_data)
</code></pre>


<h3>Details</h3>

<p>This data set holds the following collection of data objects:
</p>

<dl>
<dt>TX3st</dt><dd><p>Maximum daily temperature of 3 stations during 1981-1995.</p>
</dd>
<dt>TN3st</dt><dd><p>Minimum daily temperature of 3 stations during 1981-1995.</p>
</dd>
<dt>RR3st</dt><dd><p>Daily precipitation of 3 stations during 1981-1995.</p>
</dd>
<dt>SIstations</dt><dd><p>Stations coordinates, codes and names of the <code>*3st</code> data.</p>
</dd>
<dt>p064.df</dt><dd><p>Data frame with RR, TX and TN data for station p064.</p>
</dd>
<dt>p084.df</dt><dd><p>Data frame with RR, TX and TN data for station p084.</p>
</dd>
<dt>p082.df</dt><dd><p>Data frame with RR, TX and TN data for station p082.</p>
</dd>
<dt>AWS_1year</dt><dd><p>Hourly data from an Automatic Weather Station during one year.</p>
</dd>
<dt>AWS_1day</dt><dd><p>10 minutes data from an Automatic Weather Station during one day.</p>
</dd>
<dt>datcli</dt><dd><p>Monthly climatic parameters to plot a Walter&amp;Lieth diagram.</p>
</dd>
<dt>Temp.dat</dt><dd><p>Monthly temperature of five stations during 1961-2005.</p>
</dd>
<dt>Temp.est</dt><dd><p>Stations coordinates, codes and names of the <code>Temp.dat</code> data.</p>
</dd>
<dt>Tav</dt><dd><p>Annual average temperature at Oslo (Norway) during 1901-2020.</p>
</dd>
<dt>prec10min</dt><dd><p>Ten minutes precipitation data during 1991-2020.</p>
</dd>
</dl>

<p>Some examples need the use of files rather than these data objects. In that case they are provided in a special folder of the installation directory tree and are made accessible through the function <code><a href="#topic+exampleFiles">exampleFiles</a></code>.
</p>


<h3>Source</h3>

<p><code>RR3st, TX3st, TN3st, p064.df, p082.df and p084.df</code> data were obtained
from the historical run (1950-2005) of the Regional Atmospheric Climate Model
version 2 of the Royal Netherlands Meteorological Institute (KNMI) in the frame of the INDECIS project &lt;https://indecis.eu&gt;.
</p>
<p>Oslo annual average temperatures <code>Tav</code> were downloaded from the HCLIM
database.
</p>
<p>The other objects contain real data, but anonimized to avoid data policy
restrictions.
</p>


<h3>References</h3>

<p>Lundstad, Elin; Brugnara, Yuri; Broennimann, Stefan (2022): Global Early
Instrumental Monthly Meteorological Multivariable Database (HCLIM).
https://doi.org/10.1594/PANGAEA.940724
</p>


<h3>See Also</h3>

<p><code><a href="#topic+exampleFiles">exampleFiles</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(climatol_data)
datcli
head(p064.df)
head(AWS_1year)
</code></pre>

<hr>
<h2 id='datrestore'>Rename homogen's output files</h2><span id='topic+datrestore'></span>

<h3>Description</h3>

<p>This function restores some deleted outliers into the dah matrix of the <code>*.rda</code> output file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>datrestore(varcli, anyi, anyf, QCout=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="datrestore_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the studied climatic variable,
as in the data file name.</p>
</td></tr>
<tr><td><code id="datrestore_+3A_anyi">anyi</code></td>
<td>
<p>Initial year of the study period.</p>
</td></tr>
<tr><td><code id="datrestore_+3A_anyf">anyf</code></td>
<td>
<p>Final year of the study period.</p>
</td></tr>
<tr><td><code id="datrestore_+3A_qcout">QCout</code></td>
<td>
<p>Set this parameter to <code>TRUE</code> to read the selected outliers to be restored from the <code>*-QC*_out.csv</code> output by a previous run of <code>homogen(..., onlyQC=TRUE)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>When the user checks the list of outliers in the output file <code>*_out.csv</code>, true extreme values (or sequences of identical values) that have been deleted can be restored by changing their <code>deleted</code> field to negative.
This accepted values will be restored in the <code>dah</code> matrix of homogenized series contained in the <code>*.rda</code> file output by the <code>homogen</code> function, but only in the series reconstructed from the last homogeneous subperiod.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory, write input files and homogenize them:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)
data(climatol_data)
write.table(Temp.est,'Temp_1961-2005.est',row.names=FALSE,col.names=FALSE)
write(Temp.dat,'Temp_1961-2005.dat')
homogen('Temp',1961,2005) #obtain homogenization output files
out &lt;- read.csv('Temp_1961-2005_out.csv') #read list of outliers
## Change the sign of a couple of deleted values to be restored:
out[2,6] &lt;- -1; out[6,6] &lt;- -9
write.csv(out,'Temp_1961-2005_out.csv',row.names=FALSE)

## Now run the example:
datrestore('Temp',1961,2005) #restore the selected values

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='datsubset'>Subset data by subperiod, code list or no. of years with data</h2><span id='topic+datsubset'></span>

<h3>Description</h3>

<p>This function allows saving a subset of <code>climatol</code> input data into new input
files by selecting a subperiod, a minimum number of years with data and/or a group of stations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>datsubset(varcli, anyi, anyf, anyis=anyi, anyfs=anyf, minny=NA, codes=NULL,
na.strings=NA, ini=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="datsubset_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the studied climatic variable.</p>
</td></tr>
<tr><td><code id="datsubset_+3A_anyi">anyi</code></td>
<td>
<p>Initial year of the data present in the file.</p>
</td></tr>
<tr><td><code id="datsubset_+3A_anyf">anyf</code></td>
<td>
<p>Final year of the data present in the file.</p>
</td></tr>
<tr><td><code id="datsubset_+3A_anyis">anyis</code></td>
<td>
<p>First year of the output subperiod. (Defaults to <code>anyi</code>).</p>
</td></tr>
<tr><td><code id="datsubset_+3A_anyfs">anyfs</code></td>
<td>
<p>Last year of the output subperiod. (Defaults to <code>anyf</code>).</p>
</td></tr>
<tr><td><code id="datsubset_+3A_minny">minny</code></td>
<td>
<p>Minimum number of years with data to retain the series.</p>
</td></tr>
<tr><td><code id="datsubset_+3A_codes">codes</code></td>
<td>
<p>Vector of chosen station codes. (Defaults to <code>NULL</code>, meaning all).</p>
</td></tr>
<tr><td><code id="datsubset_+3A_na.strings">na.strings</code></td>
<td>
<p>Strings marking missing data (<code>NA</code> by default).</p>
</td></tr>
<tr><td><code id="datsubset_+3A_ini">ini</code></td>
<td>
<p>Initial date (if not January 1st).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Homogenization by <code>climatol</code> requires that no time step be totally void of data in all stations simultaneously. This function allows subsetting already existing <code>climatol</code> input files by selecting a subperiod and/or stations with a minimum number of years with data (may contain gaps).
</p>
<p>Another possibility is to choose a group of stations, useful when the initial cluster analysis reveals areas with different climate regimes that should be homogenized independently.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory and write input files:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)
data(climatol_data)
write.table(Temp.est,'Temp_1961-2005.est',row.names=FALSE,col.names=FALSE)
write(Temp.dat,'Temp_1961-2005.dat',ncolumns=12)

## Now run the examples:
datsubset('Temp',1961,2005,1971,2000,minny=20)
datsubset('Temp',1971,2000,codes=c('st02','st03'))

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='db2dat'>Get daily or monthly data from a database and build input files *.dat and *.est</h2><span id='topic+db2dat'></span>

<h3>Description</h3>

<p>This function facilitates the creation of the input files needed by this package by retrieving the data from a database through an RODBC connection.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>db2dat(varcli, anyi, anyf, minny=5, daily=TRUE, ch, dformat='%Y-%m-%d',
vtable, vcode, vdate, vval, stable, scode, sname, sx, sy, sz)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="db2dat_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the studied climatic variable,
as it will appear in all data file names.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_anyi">anyi</code></td>
<td>
<p>Initial year of the data to be included in the file.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_anyf">anyf</code></td>
<td>
<p>Final year of the data to be included in the file.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_minny">minny</code></td>
<td>
<p>Minimum number of years with data for a series to be included in
the file.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_daily">daily</code></td>
<td>
<p>Logical flag indicating whether the data are daily (the default) or monthly (set <code>daily=FALSE</code> in this case).</p>
</td></tr>
<tr><td><code id="db2dat_+3A_ch">ch</code></td>
<td>
<p>Already open ODBC connection to the climatic database.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_dformat">dformat</code></td>
<td>
<p>Date format in the database.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_vtable">vtable</code></td>
<td>
<p>Name of the table containing our climatic variable.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_vcode">vcode</code></td>
<td>
<p>Name of the variable containing station codes in the <code>vtable</code> table.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_vdate">vdate</code></td>
<td>
<p>Name of the variable containing dates in the <code>vtable</code> table.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_vval">vval</code></td>
<td>
<p>Name of the climatic variable in the <code>vtable</code> table.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_stable">stable</code></td>
<td>
<p>Name of the table containing station information (metadata).</p>
</td></tr>
<tr><td><code id="db2dat_+3A_scode">scode</code></td>
<td>
<p>Name of the variable containing station codes in the table <code>stable</code>.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_sname">sname</code></td>
<td>
<p>Name of the variable containing station names in the <code>stable</code> table.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_sx">sx</code></td>
<td>
<p>Name of the variable containing longitudes (degrees with decimals!) in the <code>stable</code> table.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_sy">sy</code></td>
<td>
<p>Name of the variable containing latitudes (degrees with decimals!) in the <code>stable</code> table.</p>
</td></tr>
<tr><td><code id="db2dat_+3A_sz">sz</code></td>
<td>
<p>Name of the variable containing elevations (meters) in the <code>stable</code> table.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates the two input files needed by the homogenization functions of this package, &lsquo;<span class="file">VRB_YEAR-YEAR.dat</span>&rsquo; (holding the data) and &lsquo;<span class="file">VRB_YEAR-YEAR.est</span>&rsquo; (holding station coordinates, codes and names).
</p>
<p>The table in the accessed database must contain either daily or monthly data (set <code>daily=FALSE</code> in this case). Otherwise the number of data per series will not be match the expected value and the function will fail.
</p>
<p>Moreover, every data item must be in a different record in the database, as in this example table of monthly data (different variables for the same time step are O.K.):
</p>
<p><code>Station   Date     T.max T.min Rel.Hum Precip  Wind.speed</code><br />
<code>S032    1991-01-01  12.1  -2.1    59    128.2     5.4</code><br />
<code>S032    1991-02-01  13.2  -2.5    62     78.4     6.2</code><br />
<code>...</code>
</p>
<p>But if the table in the database arranges all monthly values of one year (or all daily values of one month) in a single record, then this function cannot be applied. In this cases, try to use the database functionalities to output series into CSV files and apply other conversion functions as <code>csv2climatol</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code>, <code><a href="#topic+csv2climatol">csv2climatol</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## First we must access our climatic database through RODBC, wich requires to
## have this package installed. System programs that allow ODBC connections to
## databases must also be installed and properly configured.

## For this example we will assume that our database is named "climate" and we
## access it with user "USER" and password "PASS".  Then we open the connection
## with:
library(RODBC)
ch &lt;- odbcConnect("climate",uid="USER",pwd="PASS")

## Now we want to use this function to gather all monthly relative humidity
## averages for the period 1961-2015, requiring a minimum of 10 years of data
## (not necessarily consecutive). We must use the corresponding names of tables
## and headers existing the the database, and putting the parameters in the
## required order we avoid the need to name them:
db2dat('HRel',1961,2015,10,FALSE,ch,'%Y-%m-%d','monthly_relhum',
'Station','Date','Value','stations','Station','Name','Longitude',
'Latitude','Elevation')

odbcClose(ch) #close the connection if you do not need it anymore

## Our data would now be ready to be homogenized with the homogen function:
homogen('HRel',1961,2015,vmin=0,vmax=100)

## End(Not run)
</code></pre>

<hr>
<h2 id='dd2m'>Compute monthly data from daily (or subdaily) series</h2><span id='topic+dd2m'></span>

<h3>Description</h3>

<p>Daily or sub-daily series are aggregated into total, mean, maximum, or
minimum monthly values, and saved to files in <code>climatol</code> input format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dd2m(varcli, anyi, anyf, ndec=1, valm=2, namax=30, x=NULL, na.strings="NA",
tz='utc')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dd2m_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the studied climatic variable,
as in the data file name.</p>
</td></tr>
<tr><td><code id="dd2m_+3A_anyi">anyi</code></td>
<td>
<p>Initial year of the data present in the file.</p>
</td></tr>
<tr><td><code id="dd2m_+3A_anyf">anyf</code></td>
<td>
<p>Final year of the data present in the file.</p>
</td></tr>
<tr><td><code id="dd2m_+3A_ndec">ndec</code></td>
<td>
<p>Number of decimal places to be saved in the output file.</p>
</td></tr>
<tr><td><code id="dd2m_+3A_valm">valm</code></td>
<td>
<p>Monthly value to compute:
</p>

<dl>
<dt>1:</dt><dd><p>Sum,</p>
</dd>
<dt>2:</dt><dd><p>Mean,</p>
</dd>
<dt>3:</dt><dd><p>Maximum,</p>
</dd>
<dt>4:</dt><dd><p>Minimum,</p>
</dd>
<dt>5:</dt><dd><p>Standard deviation.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="dd2m_+3A_namax">namax</code></td>
<td>
<p>Maximum percentage of missing data in any month to compute its
monthly value. (30 by default)</p>
</td></tr>
<tr><td><code id="dd2m_+3A_x">x</code></td>
<td>
<p>Time vector. If not provided, it will be built as dates (or date-time for sub-daily data) beginning January 1st of the initial year. The user must provide if data are taken at irregular intervals or are not beginning the first of January.</p>
</td></tr>
<tr><td><code id="dd2m_+3A_na.strings">na.strings</code></td>
<td>
<p>Missing data code in the original daily data. (<code>NA</code> by default.)</p>
</td></tr>
<tr><td><code id="dd2m_+3A_tz">tz</code></td>
<td>
<p>Time zone (<code>'utc'</code> by default). Only relevant for subdaily data.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Data are read from files &lsquo;<span class="file">VRB_YEAR-YEAR.dat</span>&rsquo; and
&lsquo;<span class="file">VRB_YEAR-YEAR.est</span>&rsquo;, and output monthly data will be saved to
files with the same names but with the suffix <code>-m</code> appended to the name of the variable.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code>, <code><a href="#topic+dahstat">dahstat</a></code>, <code><a href="#topic+dahgrid">dahgrid</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory and write input files:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)
data(climatol_data)
write.table(SIstations,'RR_1981-1995.est',row.names=FALSE,col.names=FALSE)
write(as.matrix(RR3st[,2:4]),'RR_1981-1995.dat')

## Now run the example:
dd2m('RR',1981,1995,valm=1)

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='dens2Dplot'>Two dimensional density plot</h2><span id='topic+dens2Dplot'></span>

<h3>Description</h3>

<p>This function generates a scatter plot enhancing density with different colors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dens2Dplot(x, y, nbins=100, pal=NULL, xlab='', ylab='', xlim=c(NA,NA),
ylim=c(NA,NA), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dens2Dplot_+3A_x">x</code>, <code id="dens2Dplot_+3A_y">y</code></td>
<td>
<p>Variables for the scatter plot.</p>
</td></tr>
<tr><td><code id="dens2Dplot_+3A_nbins">nbins</code></td>
<td>
<p>Number of bins in X and Y coordinates of the scatter plot.</p>
</td></tr>
<tr><td><code id="dens2Dplot_+3A_pal">pal</code></td>
<td>
<p>Color palette</p>
</td></tr>
<tr><td><code id="dens2Dplot_+3A_xlab">xlab</code>, <code id="dens2Dplot_+3A_ylab">ylab</code></td>
<td>
<p>Labels for X and Y axis</p>
</td></tr>
<tr><td><code id="dens2Dplot_+3A_xlim">xlim</code>, <code id="dens2Dplot_+3A_ylim">ylim</code></td>
<td>
<p>Limits for X and Y axis</p>
</td></tr>
<tr><td><code id="dens2Dplot_+3A_...">...</code></td>
<td>
<p>Other graphic parameters</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function has been inspired by Elzizi's answer at http://stackoverflow.com/questions/18089752/r-generate-2d-histogram-from-raw-data
The user can add a grid, title and other details to the scatter plot.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n=1000000; x=rnorm(n,15,4); y=x+rnorm(n,5,6)
dens2Dplot(x,y,xlab='Variable X',ylab='Variable Y',las=1)

## Let's add a grid and a title:
grid(col=grey(.4))
title('Example of dens2Dplot')
</code></pre>

<hr>
<h2 id='diagwl'>Walter &amp; Lieth climatic diagram</h2><span id='topic+diagwl'></span>

<h3>Description</h3>

<p>Plot a Walter &amp; Lieth climatic diagram of a station.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagwl(dat, cols=1:6, format='%Y-%m-%d', yeari=NA, yearf=NA,
stname='', alt=NA, per='', mlab='', shem=NULL, p3line=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diagwl_+3A_dat">dat</code></td>
<td>
<p>Data frame with the required climatic data (see details).</p>
</td></tr>
<tr><td><code id="diagwl_+3A_cols">cols</code></td>
<td>
<p>Columns containing dates and daily data of precipitation and
extreme temperatures. Set to NULL if a monthly climate summary is provided.</p>
</td></tr>
<tr><td><code id="diagwl_+3A_format">format</code></td>
<td>
<p>Format of the dates if data are provided in 4 columns ['%Y-%m-%d'].</p>
</td></tr>
<tr><td><code id="diagwl_+3A_yeari">yeari</code>, <code id="diagwl_+3A_yearf">yearf</code></td>
<td>
<p>Initial and final years of the period to use. (Defaults
to the period contained in <code>dat</code>, but if it contains a climate summary,
then the parameter <code>per</code> should be supplied (see below).</p>
</td></tr>
<tr><td><code id="diagwl_+3A_stname">stname</code></td>
<td>
<p>Name of the climatological station.</p>
</td></tr>
<tr><td><code id="diagwl_+3A_alt">alt</code></td>
<td>
<p>Elevation (altitude) of the climatological station.</p>
</td></tr>
<tr><td><code id="diagwl_+3A_per">per</code></td>
<td>
<p>If data is a data frame with already calculated climate averages,
the original period of the data.</p>
</td></tr>
<tr><td><code id="diagwl_+3A_mlab">mlab</code></td>
<td>
<p>Vector of 12 monthly labels for the X axis (see the details).</p>
</td></tr>
<tr><td><code id="diagwl_+3A_shem">shem</code></td>
<td>
<p>Southern hemisphere? <code>NULL</code> by default, to be detected from
warm season. Set to TRUE or FALSE to force southern or northern hemisphere.</p>
</td></tr>
<tr><td><code id="diagwl_+3A_p3line">p3line</code></td>
<td>
<p>Draw a supplementary precipitation line referenced to three
times the temperature? (<code>FALSE</code> by default.)</p>
</td></tr>
<tr><td><code id="diagwl_+3A_...">...</code></td>
<td>
<p>Other optional graphic parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The data frame can contain daily data of precipitation and extreme
temperatures or 12 columns with pre-calculated monthly climate parameters.
</p>
<p>In the latter case, the monthly values from January to December must be in
the 12 first columns (any additional trailing columns will be disregarded)
and four rows, in the following order:
</p>

<dl>
<dt>Row 1:</dt><dd><p>Mean total precipitation</p>
</dd>
<dt>Row 2:</dt><dd><p>Mean maximum daily temperature</p>
</dd>
<dt>Row 3:</dt><dd><p>Mean minimum daily temperature</p>
</dd>
<dt>Row 4:</dt><dd><p>Absolute minimum daily temperature</p>
</dd>
</dl>

<p>This last row is used only to determine the probable frost months
(when absolute monthly minimums are equal or lower than 0 C).
</p>
<p>Alternatively, if series of daily data of precipitation and extreme
temperatures are provided, dates can be given in three separate columns
(year, month, day) or in a single column with the specified <code>format</code>
(<code>'%Y-%m-%d'</code> by default).
</p>
<p><code>cols</code> indicate in which columns are located the dates and climatic
data. By default they are expected in columns 1 to 3 for year, month and day,
and columns 4 to 6 for precipitation, maximum and minimum temperature
respectively.)
</p>
<p><code>mlab</code> is the vector for the 12 monthly labels, but it may be set to
just <code>'en'</code> or <code>'es'</code> to use the first letter of month names in
English or Spanish respectively.
</p>
<p>As described by Walter and Lieth, when monthly precipitation is greater than
100 mm, the scale is increased from 2 mm/C to 20 mm/C to avoid too high
diagrams in very wet locations. This change is indicated by a black
horizontal line, and the graph over it is filled in solid blue.
</p>
<p>When the precipitation graph lies under the temperature graph (P &lt; 2T) we
have an arid period (filled in dotted red vertical lines). Otherwise the
period is considered wet (filled in blue lines), unless <code>p3line=TRUE</code>,
that draws a precipitation black line with a scale P = 3T; in this case
the period in which 3T &gt; P &gt; 2T is considered semi-arid. (Parameter
<code>p3line</code> was suggested by Bogdan Rosca.)
</p>
<p>Daily maximum average temperature of the hottest month and daily minimum
average temperature of the coldest month are frequently used in vegetation
studies, and are labeled in black at the left margin of the diagram.
</p>


<h3>References</h3>

<p>Walter H &amp; Lieth H (1960): Klimadiagramm Weltatlas. G. Fischer,
Jena.</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(climatol_data)

## from pre-calculated monthly climatic data:
diagwl(datcli,cols=NULL,est="My Airport",alt=100,per="1961-90",mlab="en")

## from daily series of precipitation and extreme temperatures:
diagwl(p064.df, stname="Cold Place", alt=100, mlab="en")

## idem limiting the period to calculate monthly values:
diagwl(p064.df, yearf=1990, stname="Cold Place", alt=100, mlab="en")
</code></pre>

<hr>
<h2 id='exampleFiles'>Get the path to some example files</h2><span id='topic+exampleFiles'></span>

<h3>Description</h3>

<p>This function provides the path to files needed to run examples of some functions of the <code>climatol</code> package. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  exampleFiles(file=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exampleFiles_+3A_file">file</code></td>
<td>
<p>Name of the needed file. If NULL, all example files will be listed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is an adaptation of <code>readxl_example</code>, of the <code>readxl</code> package.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>exampleFiles()
exampleFiles('Temp_1991-2000.rda')
</code></pre>

<hr>
<h2 id='fix.sunshine'>Check homogenized daily sunshine hours and prune any excess</h2><span id='topic+fix.sunshine'></span>

<h3>Description</h3>

<p>This function loads homogenization results of daily sunshine series and
prunes any excess over maximum theoretical sunshine duration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> fix.sunshine(varcli, anyi, anyf) </code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fix.sunshine_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the homogenized climatic variable.</p>
</td></tr>
<tr><td><code id="fix.sunshine_+3A_anyi">anyi</code></td>
<td>
<p>First year of the homogenized series.</p>
</td></tr>
<tr><td><code id="fix.sunshine_+3A_anyf">anyf</code></td>
<td>
<p>Last year of the homogenized series.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Any modified value is listed to the console and written to <code>fix.sunshine.txt</code>
</p>
<p>The original <code>*.rda</code> file is saved as <code>*.rda.bak</code> and a new
<code>*.rda</code> file is written with the fixed sunshine values.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)

## copy example daily sunshine homogenization results:
file.copy(exampleFiles('SS_1991-2000.rda'),'.')

## Now run the example:
fix.sunshine('SS',1991,2000)

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in the directory:
print(wd)
</code></pre>

<hr>
<h2 id='homogen'>Automatic homogenization of climatological series</h2><span id='topic+homogen'></span>

<h3>Description</h3>

<p>Automatic homogenization of climatological series, including missing
data filling and detection and correction of outliers and shifts in the
mean of the series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>homogen(varcli, anyi, anyf, test='snht', nref=NULL, std=NA, swa=NA,
ndec=1, niqd=c(4,1), dz.max=.01, dz.min=-dz.max, cumc=NA, wd=NULL, inht=25,
sts=5, maxdif=NA, maxite=999, force=FALSE, wz=.001, mindat=NA, onlyQC=FALSE,
annual=c('mean','sum','total'), x=NULL, ini=NA, na.strings="NA", vmin=NA,
vmax=NA, hc.method='ward.D2', nclust=300, cutlev=NA, grdcol=grey(.4),
mapcol=grey(.4), expl=FALSE, metad=FALSE, sufbrk='m', tinc=NA, tz='utc',
rlemin=NA, rlemax=NA, cex=1.1, uni=NA, raway=TRUE, graphics=TRUE, verb=TRUE,
logf=TRUE, snht1=NA, snht2=NA, gp=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="homogen_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the studied climatic variable.</p>
</td></tr>
<tr><td><code id="homogen_+3A_anyi">anyi</code></td>
<td>
<p>Initial year of the data.</p>
</td></tr>
<tr><td><code id="homogen_+3A_anyf">anyf</code></td>
<td>
<p>Final year of the data.</p>
</td></tr>
<tr><td><code id="homogen_+3A_test">test</code></td>
<td>
<p>Inhomogeneity test to apply: 'snht' (the default) or 'cuct'
(Cucconi test, experimental).</p>
</td></tr>
<tr><td><code id="homogen_+3A_nref">nref</code></td>
<td>
<p>Maximum number of references for data estimation [defaults to 10
in the detection stages, and to 4 in the final series adjustments].</p>
</td></tr>
<tr><td><code id="homogen_+3A_std">std</code></td>
<td>
<p>Type of normalization:
</p>

<dl>
<dt>1:</dt><dd><p>deviations from the mean,</p>
</dd>
<dt>2:</dt><dd><p>rates to the mean (only for means greater than 1),</p>
</dd>
<dt>3:</dt><dd><p>standardization (subtract the mean and divide by the sample
standard deviation).</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="homogen_+3A_swa">swa</code></td>
<td>
<p>Size of the step forward to be applied to the overlapping window
application of the detection test [365 terms (one year) for daily data, and 60
otherwise].</p>
</td></tr>
<tr><td><code id="homogen_+3A_ndec">ndec</code></td>
<td>
<p>Number of decimal digits to round the homogenized data [1].</p>
</td></tr>
<tr><td><code id="homogen_+3A_niqd">niqd</code></td>
<td>
<p>Number of interquartilic distances to delete big outliers [4] and too long runs of identical values [1]. [Defaults to <code>c(4,1)</code>]</p>
</td></tr>
<tr><td><code id="homogen_+3A_dz.max">dz.max</code></td>
<td>
<p>Threshold of outlier tolerance, in standard deviations if greater than one, or as a percentage of data to reject otherwise [0.01].</p>
</td></tr>
<tr><td><code id="homogen_+3A_dz.min">dz.min</code></td>
<td>
<p>Lower threshold of outlier tolerance if different from <code>dz.max</code>.</p>
</td></tr>
<tr><td><code id="homogen_+3A_cumc">cumc</code></td>
<td>
<p>Code of accumulated missing data.</p>
</td></tr>
<tr><td><code id="homogen_+3A_wd">wd</code></td>
<td>
<p>Distance (in km) at which reference data will weight half of those
located at zero distance [<code>c(0,0,100)</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_inht">inht</code></td>
<td>
<p>Thresholds for the change in the mean detection tests [25].</p>
</td></tr>
<tr><td><code id="homogen_+3A_sts">sts</code></td>
<td>
<p>Series tail size (no. of terms) not tested for inhomogeneities [5].</p>
</td></tr>
<tr><td><code id="homogen_+3A_maxdif">maxdif</code></td>
<td>
<p>Maximum data difference from previous iteration [<code>ndec/2</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_maxite">maxite</code></td>
<td>
<p>Maximum number of iterations to compute means of the series
[999].</p>
</td></tr>
<tr><td><code id="homogen_+3A_force">force</code></td>
<td>
<p>Force direct homogenization of daily or sub-daily series [<code>FALSE</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_wz">wz</code></td>
<td>
<p>Scale parameter of the vertical coordinate <code>Z</code> [0.001].</p>
</td></tr>
<tr><td><code id="homogen_+3A_mindat">mindat</code></td>
<td>
<p>Minimum number of data for a split fragment to become a new
series [<code>swa/2</code> for daily series or 12 terms otherwise].</p>
</td></tr>
<tr><td><code id="homogen_+3A_onlyqc">onlyQC</code></td>
<td>
<p>Set to <code>TRUE</code> if only initial Quality Controls are requested [<code>FALSE</code>]</p>
</td></tr>
<tr><td><code id="homogen_+3A_annual">annual</code></td>
<td>
<p>Running annual value to graph in the PDF output. One of 'mean' (the default), 'sum' or 'total' (equivalent to 'sum').</p>
</td></tr>
<tr><td><code id="homogen_+3A_x">x</code></td>
<td>
<p>Time vector. Only needed if data are taken at irregular intervals.</p>
</td></tr>
<tr><td><code id="homogen_+3A_ini">ini</code></td>
<td>
<p>Initial date, with format <code>'YYYY-MM-DD'</code>, if series does not begin on January first (as recommended).</p>
</td></tr>
<tr><td><code id="homogen_+3A_na.strings">na.strings</code></td>
<td>
<p>Character strings to be treated as missing data [<code>'NA'</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_vmin">vmin</code></td>
<td>
<p>Minimum possible value (lower limit) of the studied variable.</p>
</td></tr>
<tr><td><code id="homogen_+3A_vmax">vmax</code></td>
<td>
<p>Maximum possible value (upper limit) of the studied variable.</p>
</td></tr>
<tr><td><code id="homogen_+3A_hc.method">hc.method</code></td>
<td>
<p>Hierarchical clustering method ['ward.D2'].</p>
</td></tr>
<tr><td><code id="homogen_+3A_nclust">nclust</code></td>
<td>
<p>Maximum number of series for the cluster analysis [300].</p>
</td></tr>
<tr><td><code id="homogen_+3A_cutlev">cutlev</code></td>
<td>
<p>Level to cut the dendrogram to define clusters [<code>NA</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_grdcol">grdcol</code></td>
<td>
<p>Color of the graphic background grids [<code>grey(0.04)</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_mapcol">mapcol</code></td>
<td>
<p>Color of coastlines and borders in the stations map [<code>grey(0.04)</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_expl">expl</code></td>
<td>
<p>Perform an exploratory analysis? [<code>FALSE</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_metad">metad</code></td>
<td>
<p>Use the breakpoints file as metadata? [<code>FALSE</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_sufbrk">sufbrk</code></td>
<td>
<p>Suffix to add to <code>varcli</code> to form the name of the provided
metadata file [<code>'m'</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_tinc">tinc</code></td>
<td>
<p>Time increment between data [<code>NA</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_tz">tz</code></td>
<td>
<p>Time zone [<code>'utc'</code>]. Only relevant for subdaily data.</p>
</td></tr>
<tr><td><code id="homogen_+3A_rlemin">rlemin</code></td>
<td>
<p>Data run lengths will exclude values <code>&lt;= rlemin</code> in quality control [<code>NA</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_rlemax">rlemax</code></td>
<td>
<p>Data run lengths will exclude values <code>&gt;= rlemax</code> in quality control [<code>NA</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_cex">cex</code></td>
<td>
<p>Character expansion factor for graphic labels and titles [1.1].</p>
</td></tr>
<tr><td><code id="homogen_+3A_uni">uni</code></td>
<td>
<p>Units to use in some axis labels [&rdquo;].</p>
</td></tr>
<tr><td><code id="homogen_+3A_raway">raway</code></td>
<td>
<p>Increase internal distances to reanalysis series to give more
weight to observed series [<code>TRUE</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_graphics">graphics</code></td>
<td>
<p>Output graphics to a PDF file [<code>TRUE</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_verb">verb</code></td>
<td>
<p>Verbosity [<code>TRUE</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_logf">logf</code></td>
<td>
<p>Save console messages to a log file? [<code>TRUE</code>].</p>
</td></tr>
<tr><td><code id="homogen_+3A_snht1">snht1</code>, <code id="homogen_+3A_snht2">snht2</code></td>
<td>
<p>Obsolete (use <code>inht</code> instead), but kept for backwards compatibility.</p>
</td></tr>
<tr><td><code id="homogen_+3A_gp">gp</code></td>
<td>
<p>Obsolete (use <code>graphics=FALSE</code> for <code>gp=0</code>, <code>onlyQC=TRUE</code> for <code>gp=1</code> or <code>annual="total"</code> for <code>gp=4</code>), but kept for backwards compatibility.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Input data must be provided in two text files, one with the data (with
extension <code>dat</code>) and another with the station coordinates (with extension
<code>est</code>). Both have as base name, &lsquo;<span class="file">VRB_YEAR-YEAR</span>&rsquo;, composed by
the short name of the climatological variable, and the initial and final years
of the data, as set in the first three parameters of the call, <code>varcli</code>,
<code>anyi</code> and <code>anyf</code>.
</p>
<p>Data are stored in a free blank separated format (any number of data items per
line is allowed), in chronological order, station by station (all data from
station 1 go first, then all data from station 2, and so on). As dates are not
stored in this file, all data must be present in the file, using a code for any
missing data in the records (<code>NA</code> by default, but any other code can be
used, provided that they are specified in the parameter <code>na.strings</code>).
</p>
<p>The stations file, with extension <code>est</code>, is also a blank separated text
file where each line identifies a single station, with structure <code>'X Y Z
CODE NAME'</code>. Coordinates <code>X</code> and <code>Y</code> are expected in geographical
degrees (longitude and latitude, in this order and in decimal form). Otherwise
they will be assumed to be in km, or in m if the mean of either <code>X</code> and
<code>Y</code> is greater than 10000; elevation <code>Z</code> must be supplied in m; and
the identification <code>CODE</code> and the full <code>NAME</code> of the station must be
quoted if they contains blanks). Fully reliable series may be marked by putting
an asterisk (*) at the beginning of their <code>CODE</code> to skip their outlier and
break-point analysis. This is not recommended with observed series, but can be
useful when using reanalysis series as references in data sparse regions.
</p>
<p>This function will stop with an error condition if any time step becomes void
of data in all stations at the same time. One or more series with data in the
void time steps must be added to successfully run <code>homogen</code> again. If no
other series are available in the area, reanalysis series of the closer
grid-points can be used, adding their coordinates to the <code>*.est</code> file and
prepending an asterisk (<code>*</code>) to the codes assigned to the series as
mentioned above.
</p>
<p><code>dz.max</code> (and <code>dz.min</code> if different from <code>dz.max</code>) can be a
vector of two values, one for suspect data and the other for probable errors.
Only the latter will be deleted, but all will be listed in the &lsquo;<span class="file">*_out.csv</span>&rsquo;
output file. By default, the more extreme 0.01% in each tail of the
distribution will be considered errors, and values exceeding 0.1% will be
suspect data. Inspection of the anomalies histogram near the end of the PDF
output file will help in tuning these parameters by setting number of standard
deviations to be used as rejection thresholds.
</p>
<p><code>inht</code> has a default value of 25, which is a suitable conservative value
for monthly values of temperature, but not so much for precipitation or for
daily series. Therefore it is advisable to adjust it empirically with the help
of the histograms available by the end of the graphic output. Anyway,
inhomogeneities in daily or subdaily series should be detected on their monthly
aggregates, which can be easily obtained by means of the function <code>dd2m</code>.
Two values can be given to this parameter (one for each of the two detection
stages), as in e.g.  <code>inht=c(30,25)</code>. When only one value is provided, it
will be used for both stages. If any or both values are zeros, the
corresponding homogenization stage will be skipped.
</p>
<p>The default value <code>wz=0.001</code> gives to the vertical coordinate (in m) the
same weight as the horizontal coordinates (internally managed in km). Other
values can be set to overweight elevation differences (wz&gt;0.001) or to
calculate only horizontal distances (wz=0).
</p>
<p><code>vmin</code> and <code>vmax</code> are unset by default, but if the variable is found
to have a skewed probability distribution with a minimum value of zero,
<code>vmin</code> will be set to zero. The same will happen if the user sets
<code>std=2</code>.
</p>
<p><code>sufbrk</code> is only relevant when <code>metad=TRUE</code>. Its default value
<code>'m'</code> is meant to read the file of break-points detected at the monthly
scale, but if the data were originally monthly, <code>sufbrk=''</code> should be set.
</p>
<p><code>tinc</code>, unset by default, can be defined for subdaily data, as in e.g.:
<code>tinc='3 hours'</code>, especially if first and/or last years are incomplete.
Units can be 'hours', 'mins' or 'secs'.
</p>
<p>The default <code>cex=1.1</code> increase by a 10% the size of labels in the graphic
output. Note that if station names are long, they will not fit in titles when
increasing this parameter too much.
</p>
<p>The graphic output file (in PDF format) begins with a first quality control of
the series, providing box-plots for every series showing (1) the range of their
values, (2) their increments between successive terms and (3) the length of
segments with constant data. Too big outliers are deleted at this stage because
they would compromise the quality of the homogenization and missing data
filling. During the rest of the process outlier detection and deletion is based
on spatial differences between neighboring normalized data. (Deleted data which were not errors but due to local phenomena can be restored to the homogenized series with the help of the <code>datrestore</code> function.)
</p>
<p>The following pages offer: (a) a summary of the data availability and frequency
distribution; (b) a correlogram of the first differences of the series, (c) a
dendrogram based on these correlations and a map with the station locations
(marked with numbers if less than 100, and with symbols otherwise; (d) graphics
of normalized spatial anomalies showing the detected breaks, the minimum
distance to a reference data and the number of references used; (e) a histogram
of maximum inht values found in overlapping window analysis; (d) and (e) are
repeated for the analysis on the whole series; (f) histograms of number of
splits per station and per year; (g) graphics of final anomalies of the series;
(h) graphics of the reconstructed series and applied corrections; (i) a
histogram of the normalized anomalies of all data (useful to set rejection
thresholds for the outliers); (j) final histograms of inht values; and (k) a
plot of quality/singularity of the stations (a bad score may be due to a bad
quality of the series, but also to a singular siting with a peculiar
micro-climate).
</p>
<p>Note that every time that a significant shift in the mean of the series is
detected, it will be split into two (potentially) homogeneous sub-periods, and
hence the final number of homogenized series will be increased, as complete
homogeneous series will be reconstructed from all of them. When several
homogeneous series have been yielded for the same location, the user can choose
to use that reconstructed from the last sub-period (the usual behavior of
other homogenization packages), which is perfect for climate monitoring of
newly incoming data. However, statistics derived from all of them can be useful
for climatic mapping, when no a priori knowledge can indicate which of the
sub-periods will be more representative at the spatial scale of the map).
</p>
<p>The processing time can range from seconds (a few monthly series) to many hours
(hundreds of daily series). If you must process a huge amount of data, you
should consider splitting your study region into smaller areas to be
homogenized independently.
</p>


<h3>Value</h3>

<p>This function does not return any value, its results being saved to files
with the same base name as the input files, and extensions:  
</p>

<dl>
<dt>*.txt:</dt><dd><p>A text file that logs all the processing output,</p>
</dd> 
<dt>*_out.csv:</dt><dd><p>List of corrected outliers,</p>
</dd> 
<dt>*_brk.csv:</dt><dd><p>List of corrected breaks,</p>
</dd> 
<dt>*.pdf:</dt><dd><p>PDF file with a collection of diagnostic graphics,</p>
</dd>
<dt>*.rda:</dt><dd><p>Homogenization results in R binary format, used by the
<code>dahstat</code> and other post-processing functions, but can be loaded
by the user for further data manipulation with the function <code>load</code>. This
file contains the following objects:
</p>

<dl>
<dt>dat</dt><dd><p>matrix of the original series,</p>
</dd>
<dt>dah</dt><dd><p>matrix of the homogenized series,</p>
</dd>
<dt>nd</dt><dd><p>number of data (time steps) in every series,</p>
</dd>
<dt>ndec</dt><dd><p>number of decimals in the data,</p>
</dd>
<dt>uni</dt><dd><p>data units,</p>
</dd>
<dt>est.c</dt><dd><p>data frame with columns:
</p>

<dl>
<dt>X</dt><dd><p>longitude,</p>
</dd>
<dt>Y</dt><dd><p>latitude,</p>
</dd>
<dt>Z</dt><dd><p>elevation,</p>
</dd>
<dt>Code</dt><dd><p>station code,</p>
</dd>
<dt>Name</dt><dd><p>station name,</p>
</dd>
<dt>pod</dt><dd><p>percentage of original data,</p>
</dd>
<dt>snht</dt><dd><p>(or <code>cuct</code> when <code>test='cuct'</code>): Remaining
inhomogeneity test values in the homogenized series. Can be greater
than the set <code>inht</code> threshold because of a lower number of reference
stations,</p>
</dd>
<dt>rmse</dt><dd><p>estimated root mean squared errors of the homogenized series</p>
</dd>
</dl>
</dd>
<dt>ct</dt><dd><p>Cluster Analysis series groups,</p>
</dd>
<dt>nei</dt><dd><p>number of input series,</p>
</dd>
<dt>ne</dt><dd><p>number of series after the homogenization,</p>
</dd>
<dt>nm</dt><dd><p>number of &quot;months&quot; (data items) in a year (0=daily data),</p>
</dd>
<dt>std</dt><dd><p>type of normalization applied to the data,</p>
</dd>
<dt>x</dt><dd><p>vector of the time dimension,</p>
</dd>
<dt>ini</dt><dd><p>initial date of the period under study.</p>
</dd>
</dl>

</dd> </dl>



<h3>References</h3>

<p>Guijarro JA (2014): Quality Control and Homogenization of Climatological
Series. In Eslamian S (Ed.), Handbook of Engineering Hydrology, Vol. 1:
Fundamentals and Applications. Francis and Taylor, CRC Group, USA, ISBN
9781466552357, 636 pp.
</p>
<p>Azorin-Molina C, Guijarro JA, McVicar TR, Trewin BC, Frost AJ, Chen D (2019):
An approach to homogenize daily peak wind gusts: An application to the
Australian series. Int. J. Climatol., 39:2260-2277. doi: 10.1002/joc.5949
</p>
<p>Dumitrescu A, Cheval S, Guijarro JA (2019): Homogenization of a combined hourly
air temperature dataset over Romania. Int. J. Climatol., 40:2599-2608, DOI:
10.1002/joc.6353
</p>
<p>Visit &lt;https://climatol.eu/&gt; for updates of code and documentation (user's
guide, links to videos, etc).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dahstat">dahstat</a></code>, <code><a href="#topic+dahgrid">dahgrid</a></code>, <code><a href="#topic+outrename">outrename</a></code>, <code><a href="#topic+datrestore">datrestore</a></code>, <code><a href="#topic+dd2m">dd2m</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory and write input files:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)
data(climatol_data)
write.table(Temp.est,'Temp_1961-2005.est',row.names=FALSE,col.names=FALSE)
write(Temp.dat,'Temp_1961-2005.dat')

## Now run the example:
homogen('Temp',1961,2005)

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='IDFcurves'>Obtain Intensity-Duration-Frequency curves</h2><span id='topic+IDFcurves'></span>

<h3>Description</h3>

<p>Intensity-Duration-Frequency curves are obtained from a sub-hourly time series of precipitation by adjusting Generalized Extreme Value distribution to annual maxima of different time intervals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>IDFcurves(prdat, stname, clmn=1:2, tz='utc', na.code=NA,
prunits='mm', mindpy=0.8, gumbel=TRUE, timeaggr=c(10,20,30,60,120,180,360,720),
retper=c(5,10,20,30,50,75,100),...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="IDFcurves_+3A_prdat">prdat</code></td>
<td>
<p>Data frame with Time (as POSIXct) and sub-hourly precipitation data.</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_stname">stname</code></td>
<td>
<p>Station name.</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_clmn">clmn</code></td>
<td>
<p>Columns where Time and precipitation data are located in <code>prdat</code>.</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_tz">tz</code></td>
<td>
<p>Time zone [<code>'utc'</code> by default].</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_na.code">na.code</code></td>
<td>
<p>Numeric missing data code.</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_prunits">prunits</code></td>
<td>
<p>Precipitation units [mm].</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_mindpy">mindpy</code></td>
<td>
<p>Minimum available data proportion to process data in any year.</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_gumbel">gumbel</code></td>
<td>
<p>Adjust a Gumbel distribution? [<code>TRUE</code>].</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_timeaggr">timeaggr</code></td>
<td>
<p>Time intervals (in minutes) on which to aggregate precipitation.</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_retper">retper</code></td>
<td>
<p>Return periods (in years) for extreme precipitation estimation.</p>
</td></tr>
<tr><td><code id="IDFcurves_+3A_...">...</code></td>
<td>
<p>Additional graphic parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The precipitation time series must be provided as a data frame with POSIXct
times in the first column and precipitation in the second. However, these
data can be in other columns of a wider data frame if the columns containing
these variables are defined in the parameter <code>clmn</code>.
</p>
<p>When setting <code>gumbel=FALSE</code> a Generalized Extreme Value distribution will be adjusted instead of the particular case of a Gumbel distribution.
</p>


<h3>Value</h3>

<p>A table of maximum precipitation accumulations (totals, not mm/h as in the graphic) is returned invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(climatol_data)
tab &lt;- IDFcurves(prec10min,'My airport',cex.axis=1.2,cex.lab=1.2) #IDF plot

## See the maximum precipitation accumulations in the different time intervals:
tab

## End(Not run)
</code></pre>

<hr>
<h2 id='meteogram'>Daily meteogram of eight meteorological variables</h2><span id='topic+meteogram'></span>

<h3>Description</h3>

<p>This function plots a meteogram from hourly or sub-hourly data of eight
meteorological variables available in a data frame spanning one day.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  meteogram(df, code='', name='', cols=1:9, tz='utc', hlab='Hours', 
  datefm='%Y-%m-%d', vlab=c('Wind direction (deg)','Wind speed (m/s)',NA,NA,
  'Temperature (C)','Rel. humidity (%)','Precip. (mm)','Pressure (hPa)'),
  vcol=c(hsv(.1,1,.9),hsv(.1,1,.9),2,2,2,hsv(.4,1,.7),4,'brown'),
  llim=c(0,0,NA,NA,0,0,0,NA), ulim=c(360,20,NA,NA,20,100,4,NA))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="meteogram_+3A_df">df</code></td>
<td>
<p>Data frame with (around) one day of data.</p>
</td></tr>
<tr><td><code id="meteogram_+3A_code">code</code></td>
<td>
<p>Code of the station.</p>
</td></tr>
<tr><td><code id="meteogram_+3A_name">name</code></td>
<td>
<p>Name of the station.</p>
</td></tr>
<tr><td><code id="meteogram_+3A_cols">cols</code></td>
<td>
<p>Column order of the expected variables (see details).</p>
</td></tr>
<tr><td><code id="meteogram_+3A_tz">tz</code></td>
<td>
<p>Time zone of the supplied time vector (<code>'utc'</code> by default).</p>
</td></tr>
<tr><td><code id="meteogram_+3A_hlab">hlab</code></td>
<td>
<p>Label for hours (<code>'Hours'</code> by default).</p>
</td></tr>
<tr><td><code id="meteogram_+3A_datefm">datefm</code></td>
<td>
<p>Date format for the title of the meteogram (the default is
<code>'%Y-%m-%d'</code>, the ISO 8601 date format).</p>
</td></tr>
<tr><td><code id="meteogram_+3A_vlab">vlab</code></td>
<td>
<p>Variable labels.</p>
</td></tr>
<tr><td><code id="meteogram_+3A_vcol">vcol</code></td>
<td>
<p>Colors for every variable.</p>
</td></tr>
<tr><td><code id="meteogram_+3A_llim">llim</code></td>
<td>
<p>Lower graphic limits (if fixed).</p>
</td></tr>
<tr><td><code id="meteogram_+3A_ulim">ulim</code></td>
<td>
<p>Upper graphic limits (if fixed).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function expects a data frame containing observation time
and eight meteorological variables in this column order:
</p>

<ol>
<li><p>Time of the observation (as POSIXct)
</p>
</li>
<li><p>10 minutes average wind direction in degrees
</p>
</li>
<li><p>10 minutes average wind speed in m/s
</p>
</li>
<li><p>3 sec. maximum gust direction in degrees
</p>
</li>
<li><p>3 sec. maximum gust speed in m/s
</p>
</li>
<li><p>Air temperature in degrees Celsius
</p>
</li>
<li><p>Relative humidity in %
</p>
</li>
<li><p>Precipitation in mm
</p>
</li>
<li><p>Barometric pressure in hPa
</p>
</li></ol>

<p>However, if the data frame has these variables in a different order, it can
be specified with the parameter <code>cols</code>.
</p>
<p>See <code><a href="base.html#topic+strftime">strftime</a></code> for ways to specify date formats.
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+strftime">strftime</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(climatol_data)
meteogram(AWS_1day, 'S123', 'My airport')
</code></pre>

<hr>
<h2 id='MHisopleths'>Isopleths on a months-hours diagram</h2><span id='topic+MHisopleths'></span>

<h3>Description</h3>

<p>This function takes hourly or subhourly data (spanning at least one
year) and plots isopleths of the chosen variable in a colored two-dimensional
(months, hours) diagram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>MHisopleths(dat, vrb, fun='mean', xlab='Months', ylab='Hours', cex=1.2,
  col4RP=c('cyan','yellow','red'), title='')
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MHisopleths_+3A_dat">dat</code></td>
<td>
<p> dataframe containing the data in columns with date/time
of class POSIX in the first column.</p>
</td></tr>
<tr><td><code id="MHisopleths_+3A_vrb">vrb</code></td>
<td>
<p>name of the column containing the chosen data.</p>
</td></tr>
<tr><td><code id="MHisopleths_+3A_fun">fun</code></td>
<td>
<p>function to aggregate subhourly data into hourly.</p>
</td></tr>
<tr><td><code id="MHisopleths_+3A_xlab">xlab</code>, <code id="MHisopleths_+3A_ylab">ylab</code></td>
<td>
<p>labels for the X and Y axis.</p>
</td></tr>
<tr><td><code id="MHisopleths_+3A_cex">cex</code></td>
<td>
<p>character expansion parameter for the size of labels.</p>
</td></tr>
<tr><td><code id="MHisopleths_+3A_col4rp">col4RP</code></td>
<td>
<p>vector of colors for the <code>colorRampPalette</code> function.</p>
</td></tr>
<tr><td><code id="MHisopleths_+3A_title">title</code></td>
<td>
<p>main title.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The user can choose any column of data present in <code>dat</code>. (Depending on
the variable the default colors may not be the most appropriate.)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(climatol_data)
MHisopleths(AWS_1year,'Temp',title='Mean temperature (C) -- My airport, 2002')
MHisopleths(AWS_1year,'WSpd',title='Wind speed (m/s) -- My airport, 2002')
</code></pre>

<hr>
<h2 id='outrename'>Rename homogen's output files</h2><span id='topic+outrename'></span>

<h3>Description</h3>

<p>This function inserts a suffix to the output file names of <code>homogen</code>,
to prevent them from being overwritten by any further run.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outrename(varcli, anyi, anyf, suffix, restore=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="outrename_+3A_varcli">varcli</code></td>
<td>
<p>Short name of the studied climatic variable,
as in the data file name.</p>
</td></tr>
<tr><td><code id="outrename_+3A_anyi">anyi</code></td>
<td>
<p>Initial year of the study period.</p>
</td></tr>
<tr><td><code id="outrename_+3A_anyf">anyf</code></td>
<td>
<p>Final year of the study period.</p>
</td></tr>
<tr><td><code id="outrename_+3A_suffix">suffix</code></td>
<td>
<p>Suffix to be inserted (or removed) in the output file names.</p>
</td></tr>
<tr><td><code id="outrename_+3A_restore">restore</code></td>
<td>
<p>Set this parameter to <code>TRUE</code> to remove the <code>suffix</code>
previously inserted by this function. (<code>FALSE</code> by default.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The suffix is appended to the <code>varcli</code> after a hyphen. The purpose of
this function is to allow a new application of <code>homogen</code> to the same
data with different parameters without overwriting the previous results.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory, write input files and homogenize them:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)
data(climatol_data)
write.table(Temp.est,'Temp_1961-2005.est',row.names=FALSE,col.names=FALSE)
write(Temp.dat,'Temp_1961-2005.dat',ncolumns=12)
datsubset('Temp',1961,2005,1991) #subset data to shorten example run time
homogen('Temp',1991,2005) #obtain homogenization output files

## Now run the example:
outrename('Temp',1991,2005,'bak') #rename them to avoid being overwritten

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='QCthresholds'>Obtain monthly thresholds for Quality Control alerts</h2><span id='topic+QCthresholds'></span>

<h3>Description</h3>

<p>This function calculate monthly quantiles of daily or subdaily series that can be used as thresholds for Quality Control alerts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  QCthresholds(dat, ndec=1, probs=c(0.,.001,.01,.99,.999,1.), minval=NA,
  maxval=NA, homog=TRUE, verb=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="QCthresholds_+3A_dat">dat</code></td>
<td>
<p>Either the name of a *.rda file of <code>climatol</code> homogenization results or a data.frame of daily (or subdaily) data in columns, dates or date/times (of class Date or POSIXct) in the first column and station codes in the header</p>
</td></tr>
<tr><td><code id="QCthresholds_+3A_ndec">ndec</code></td>
<td>
<p>number of decimals of output values [1] (defaults shown between brackets)</p>
</td></tr>
<tr><td><code id="QCthresholds_+3A_probs">probs</code></td>
<td>
<p>probabilities of the quantiles to be computed [0., .001, .01, .99, .999, 1.]</p>
</td></tr>
<tr><td><code id="QCthresholds_+3A_minval">minval</code></td>
<td>
<p>minimum value to compute runs of constant values [<code>NA</code>].</p>
</td></tr>
<tr><td><code id="QCthresholds_+3A_maxval">maxval</code></td>
<td>
<p>maximum value to compute runs of constant values [<code>NA</code>].</p>
</td></tr>
<tr><td><code id="QCthresholds_+3A_homog">homog</code></td>
<td>
<p>use homogenized data if a *.rda file is used as input [<code>TRUE</code>].</p>
</td></tr>
<tr><td><code id="QCthresholds_+3A_verb">verb</code></td>
<td>
<p>list all calculated values? [<code>TRUE</code>].</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>minval</code> and <code>maxval</code> allow to exclude frequent values that would
result in the report of long runs of identical data. Examples: set
<code>minval=0.1</code> in daily precipitation to avoid long runs of zeros or set
<code>maxval=97</code> in relative humidity to avoid long runs of near saturation
values in episodes of persistent fog.
</p>
<p>Calculated thresholds are shown in the text output and are also saved in a
binary R file named <code>QCthresholds.Rdat</code>, which contains the matrices
<code>thr1</code>, <code>thr2</code> and <code>thr3</code>. Load this file and write the
thresholds in the required format for importation into a Climate Data
Management System.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory and write input files:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)
data(climatol_data)

## Now run the examples:
QCthresholds(RR3st,minval=0.1) #daily precipitation of three stations
QCthresholds(TX3st) #daily maximum temperatures of three stations
load('QCthresholds.Rdat') #load last calculated thresholds
thr1[1,,] #thresholds with 0% probability to find lower values
thr1[,3,] #monthly thresholds of the third station
thr2 #thresholds of absolute increments between consecutive data
thr3 #thresholds for equal data run lengths

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='rclimdex2climatol'>Convert RClimDex daily data files to <code>climatol</code> input format</h2><span id='topic+rclimdex2climatol'></span>

<h3>Description</h3>

<p>This function can be useful to prepare the <code>climatol</code> input files when the user have their daily data in RClimDex format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rclimdex2climatol(stfile, stcol=1:5, kvar, chrcod=c(6,10), sep='', anyi=NA,
anyf=NA, mis=-99.9, mindat=365, header=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rclimdex2climatol_+3A_stfile">stfile</code></td>
<td>
<p>Name of the file with the list of data file names and station coordinates, codes and names.</p>
</td></tr>  
<tr><td><code id="rclimdex2climatol_+3A_stcol">stcol</code></td>
<td>
<p>Columns in <code>stfile</code> holding data file names, longitudes,
latitudes, elevations and station codes and names. (Defaults to 1:5.)</p>
</td></tr>
<tr><td><code id="rclimdex2climatol_+3A_kvar">kvar</code></td>
<td>
<p>RClimDex variable to extract: 1 (RR), 2 (TX), 3 (TN).</p>
</td></tr>
<tr><td><code id="rclimdex2climatol_+3A_chrcod">chrcod</code></td>
<td>
<p>Initial and final characters of data file names to be used as station codes. c(6,10) by default.</p>
</td></tr>
<tr><td><code id="rclimdex2climatol_+3A_sep">sep</code></td>
<td>
<p>Field separator in <code>stfile</code> and data files (space or tab by default).</p>
</td></tr>
<tr><td><code id="rclimdex2climatol_+3A_anyi">anyi</code></td>
<td>
<p>First year to study. (Defaults to the first year of available data.)</p>
</td></tr>
<tr><td><code id="rclimdex2climatol_+3A_anyf">anyf</code></td>
<td>
<p>Last year to study. (Defaults to the last year of available data.)</p>
</td></tr>
<tr><td><code id="rclimdex2climatol_+3A_mis">mis</code></td>
<td>
<p>Missing data code. (Defaults to -99.9.)</p>
</td></tr>
<tr><td><code id="rclimdex2climatol_+3A_mindat">mindat</code></td>
<td>
<p>Minimum required number of data per station. (Defaults to 365 daily data.)</p>
</td></tr>
<tr><td><code id="rclimdex2climatol_+3A_header">header</code></td>
<td>
<p>Do files have a header line? <code>TRUE</code> by default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Users of the RClimDex program can convert their daily data files to the
<code>climatol</code> format. All files listed in <code>stfile</code> will be read, and the
selected variable (precipitation, maximum or minimum temperature) will be
stored in a unique <code>*.dat</code> file, with its companion <code>*.est</code> station
file.  Therefore, if you want to convert all three variables, you must run this
function three times.
</p>
<p>Coordinates must be given in degrees with decimals, using the minus sign for sourthern latitudes and western longitudes.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homogen">homogen</a></code>, <code><a href="#topic+climatol2rclimdex">climatol2rclimdex</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)

## Prepare a few files in RClimDex format:
data(climatol_data)
gY=c(46,46,46); mY=c(06,15,14); sY=c(42,25,53)
gX=c(14,15,14); mX=c(03,09,50); sX=c(05,06,05)
df=data.frame(File=c('p064.txt','p084.txt','p082.txt'),
LatDeg=gY,LatMin=mY,LatSec=sY,LonDeg=gX,LonMin=mX,LonSec=sX,
elev=SIstations[,3],name=SIstations[,5])
write.table(df,'stations.txt',sep='\t',row.names=FALSE)
write.table(p064.df,'p064.txt',sep='\t',row.names=FALSE,quote=FALSE)
write.table(p084.df,'p084.txt',sep='\t',row.names=FALSE,quote=FALSE)
write.table(p082.df,'p082.txt',sep='\t',row.names=FALSE,quote=FALSE)

## Now run the example:
rclimdex2climatol('stations.txt',3,chrcod=c(1,4))

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='runtnd'>Running trends on time windows of different lengths</h2><span id='topic+runtnd'></span>

<h3>Description</h3>

<p>This function plots running trends on time windows of different lengths in a
colored grid with axis 'Last year' and 'Window length'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  runtnd(d, anyi, minyr=10, units='Units', pernyr=10, stname=NA, k=NULL,
  palneg=c('blue','white'), palpos=c('white','red'), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="runtnd_+3A_d">d</code></td>
<td>
<p>Series of annual values (without missing data).</p>
</td></tr>
<tr><td><code id="runtnd_+3A_anyi">anyi</code></td>
<td>
<p>Initial year of the series.</p>
</td></tr>
<tr><td><code id="runtnd_+3A_units">units</code></td>
<td>
<p>Units label for the legend.</p>
</td></tr>
<tr><td><code id="runtnd_+3A_minyr">minyr</code></td>
<td>
<p>Minimum no. of years to compute trends (10 by default).</p>
</td></tr>
<tr><td><code id="runtnd_+3A_pernyr">pernyr</code></td>
<td>
<p>Factor for trend units (per 10 years by default).</p>
</td></tr>
<tr><td><code id="runtnd_+3A_stname">stname</code></td>
<td>
<p>Station name (for the title).</p>
</td></tr>
<tr><td><code id="runtnd_+3A_k">k</code></td>
<td>
<p>Vector of breaks for the trend scale colors (automatically set by
default).</p>
</td></tr>
<tr><td><code id="runtnd_+3A_palneg">palneg</code></td>
<td>
<p>Color gradation for negative trends [<code>c('blue','white')</code>].</p>
</td></tr>
<tr><td><code id="runtnd_+3A_palpos">palpos</code></td>
<td>
<p>Color gradation for positive trends [<code>c('white','red')</code>].</p>
</td></tr>
<tr><td><code id="runtnd_+3A_...">...</code></td>
<td>
<p>Additional graphic parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input must be a complete (no missing data) series of annual values.
</p>
<p>If <code>minyr</code> is negative, running trends calculated on <code>-minyr</code> years
will be plotted, with increasing line widths when significance reaches 0.10
and 0.05 levels. Otherwise, a colored graphic of running trends calculated on
different window widths will be displayed, masking low significance values
with white dots.
</p>


<h3>Value</h3>

<p>A data frame or a list with <code>tnd</code> (trends) and <code>pvl</code> (p-values) is
returned invisibly when <code>minyr</code> is negative or positive, respectively.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(climatol_data)
runtnd(Tav, 1901, -30, units='C', stname='Oslo', cex.axis=1.2, cex.lab=1.2)
runtnd(Tav[31:120], 1931, 30, units='C', stname='Oslo')
</code></pre>

<hr>
<h2 id='sef2climatol'>Convert SEF data files to <code>climatol</code> input files.</h2><span id='topic+sef2climatol'></span>

<h3>Description</h3>

<p>This function reads all SEF files contained in a directory and writes their data in <code>*.dat</code> and <code>*.est</code> <code>climatol</code> input files.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  sef2climatol(dr,Vbl,varcli=Vbl,ndec=1,na.strings="NA",mindat=NA)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sef2climatol_+3A_dr">dr</code></td>
<td>
<p>directory containing the SEF files</p>
</td></tr>
<tr><td><code id="sef2climatol_+3A_vbl">Vbl</code></td>
<td>
<p>name of the variable in the SEF files</p>
</td></tr>
<tr><td><code id="sef2climatol_+3A_varcli">varcli</code></td>
<td>
<p>name of the variable in the <code>climatol</code> destination files</p>
</td></tr>
<tr><td><code id="sef2climatol_+3A_ndec">ndec</code></td>
<td>
<p>number of decimals to save</p>
</td></tr>
<tr><td><code id="sef2climatol_+3A_na.strings">na.strings</code></td>
<td>
<p>missing data codes (specified as quoted strings)</p>
</td></tr>
<tr><td><code id="sef2climatol_+3A_mindat">mindat</code></td>
<td>
<p>minimum required number of data per station</p>
</td></tr>
</table>


<h3>Details</h3>

<p>SEF (Station Exchange Format) is the Copernicus Climate Change Service
format for Data Rescue projects. Visit https://datarescue.climate.copernicus.eu/node/80
</p>
<p>Missing elevations will be assigned the value 99
</p>
<p>Some files may contain a single quotation mark in the metadata field,
causing not reading the end of line until a pairing quoting is found in
the following line, hence skipping half of the data. Parameter quote='\'
has been set in the reading command as a workaround.
</p>
<p>All data are dumped into a temporary file named <code>SEFdata.csv</code>, which is used by the function <code>csv2climatol</code> to write the input files for <code>climatol</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+csv2climatol">csv2climatol</a></code>, <code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory and write input files:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)

## Create a directory and copy all SEF files to be processed:
dir.create('dir1')
file.copy(exampleFiles('GHCN_v4_Bhamo.tsv'),'dir1')
file.copy(exampleFiles('GHCN_v4_Diamond_Island.tsv'),'dir1')

## Now run the function:
sef2climatol('dir1','ta')

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in directory:
print(wd)
</code></pre>

<hr>
<h2 id='windrose'>Wind-rose plot</h2><span id='topic+windrose'></span>

<h3>Description</h3>

<p>This function plots a wind-rose from a data frame with columns DateTime,
Wind direction and Wind speed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>windrose(dat, cols=1:3, code='', name='', uni='m/s', ndir=16, spdcut=NULL,
maxnsc=8, fnum=4, fint=5, flab=2, ang=-3*pi/16, margin=c(0,0,4,0),
pal=c('cyan','yellow','orange','red','brown'), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="windrose_+3A_dat">dat</code></td>
<td>
<p>Data frame with columns DateTime, Wind direction and Wind speed.</p>
</td></tr>
<tr><td><code id="windrose_+3A_cols">cols</code></td>
<td>
<p>Columns containing DateTime, Wind direction and Wind speed [1:3].</p>
</td></tr>
<tr><td><code id="windrose_+3A_code">code</code></td>
<td>
<p>Station code.</p>
</td></tr>
<tr><td><code id="windrose_+3A_name">name</code></td>
<td>
<p>Station name.</p>
</td></tr>
<tr><td><code id="windrose_+3A_uni">uni</code></td>
<td>
<p>Speed units for the legend header ['m/s'].</p>
</td></tr>
<tr><td><code id="windrose_+3A_ndir">ndir</code></td>
<td>
<p>Number of classes of wind direction [16].</p>
</td></tr>
<tr><td><code id="windrose_+3A_spdcut">spdcut</code></td>
<td>
<p>Speed values to set the wind speed classes. If not provided,
classes will be automatically calculated.</p>
</td></tr>
<tr><td><code id="windrose_+3A_maxnsc">maxnsc</code></td>
<td>
<p>Maximum number of wind speed classes [8].</p>
</td></tr>
<tr><td><code id="windrose_+3A_fnum">fnum</code></td>
<td>
<p>Number of reference circles to plot [4].</p>
</td></tr>
<tr><td><code id="windrose_+3A_fint">fint</code></td>
<td>
<p>Frequency interval (in %) between reference circles [5].</p>
</td></tr>
<tr><td><code id="windrose_+3A_flab">flab</code></td>
<td>
<p>Parameter indicating which circles must be labelled:
</p>

<dl>
<dt>1:</dt><dd><p>Label outer circle only,</p>
</dd>
<dt>2:</dt><dd><p>Label all circles (the default),</p>
</dd>
<dt>Other value:</dt><dd><p>Do not label any circle.</p>
</dd>
</dl>

</td></tr>
<tr><td><code id="windrose_+3A_ang">ang</code></td>
<td>
<p>Angle along which circles will be labeled, in radians [<code>-3*pi/16</code>].</p>
</td></tr>
<tr><td><code id="windrose_+3A_margin">margin</code></td>
<td>
<p>Margins vector for the plot (to be passed to <code>par</code>) [<code>c(0,0,4,0)</code>].</p>
</td></tr>
<tr><td><code id="windrose_+3A_pal">pal</code></td>
<td>
<p>Color gradation to fill the frequency polygons.</p>
</td></tr>
<tr><td><code id="windrose_+3A_...">...</code></td>
<td>
<p>Other graphic parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>After reading the data, a frequency table is calculated in 16 wind directions
and a variable number of wind speed classes, which can be set by the user.
Calm observations (wind speed equal to zero) are distributed proportionally
into the first wind speed class. The wind direction data must be provided in
degrees.
</p>
<p>This table, which covers all available pairs of wind direction and speed present in the data frame, is the basis of the wind-rose plot.
</p>


<h3>Value</h3>

<p>The table of wind frequencies by direction and speed classes is returned invisibly.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(climatol_data) #load example data
windtable &lt;- windrose(AWS_1year, 1:3, 'st123', 'My airport') #plot windrose
print(windtable) #display the table of calculated wind frequencies
</code></pre>

<hr>
<h2 id='xls2csv'>Join all data in *.xls or *.xlsx files into a single CSV file</h2><span id='topic+xls2csv'></span>

<h3>Description</h3>

<p>This function reads all *.xls or *.xlsx files contained in a directory and dumps their data into a single CSV file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  xls2csv(tmpdir, archdir, var, datcols=1:4, codesep='-', dec='.', sep=',') 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="xls2csv_+3A_tmpdir">tmpdir</code></td>
<td>
<p>temporal directory containing the files to read.</p>
</td></tr>
<tr><td><code id="xls2csv_+3A_archdir">archdir</code></td>
<td>
<p>directory where to archive files after processing.</p>
</td></tr>
<tr><td><code id="xls2csv_+3A_var">var</code></td>
<td>
<p>destination name of the variable.</p>
</td></tr>
<tr><td><code id="xls2csv_+3A_datcols">datcols</code></td>
<td>
<p>data columns to be written to the output file.</p>
</td></tr>
<tr><td><code id="xls2csv_+3A_codesep">codesep</code></td>
<td>
<p>character string separating the code from the rest of the file name (<code>'-'</code> by default).</p>
</td></tr>
<tr><td><code id="xls2csv_+3A_dec">dec</code></td>
<td>
<p>character to use as decimal point in the output file (<code>'.'</code> by default).</p>
</td></tr>
<tr><td><code id="xls2csv_+3A_sep">sep</code></td>
<td>
<p>character separating data in the output file (<code>','</code> by default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>File names must begin with their station code, which may optionally be followed by a hyphen ('-') or other code separator character (specified with the parameter <code>codesep</code>) and the name of the station or other characters.
</p>
<p>File contents must have one header line at the top. If they contain more,
supplementary header lines should have at least one empty cell in the columns
of date and data to be read.
</p>
<p>After their data have been dumped into the output <code>xls_*_data.csv</code> file, original files are moved to the <code>archdir</code> directory.
</p>
<p>Note that data are appended to the output CSV files every time you run this function putting new files in the <code>tmpdir</code> directory.
</p>
<p>Code and station names (if included in the file names) are appended to <code>xls_*_stations.csv</code>.
</p>
<p><code>climatol</code> input files can then be obtained from both output
<code>xls_*.csv</code> files with the <code>csv2climatol</code> function.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+csv2climatol">csv2climatol</a></code>, <code><a href="#topic+homogen">homogen</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>## Set a temporal working directory:
wd &lt;- tempdir()
wd0 &lt;- setwd(wd)

## Create origin and destination directories and copy example input files:
dir.create('dir1'); dir.create('dir2')
file.copy(exampleFiles('p064.xlsx'),'dir1')
file.copy(exampleFiles('p082.xlsx'),'dir1')
file.copy(exampleFiles('p084.xlsx'),'dir1')

## Now run the example:
xls2csv('dir1','dir2','TN',datcols=c(1:3,6))

## Return to user's working directory:
setwd(wd0)

## Input and output files can be found in the directory:
print(wd)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
