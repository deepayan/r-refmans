<!DOCTYPE html><html><head><title>Help for package lcda</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lcda}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#cclcda'><p>Common Components Latent Class Discriminant Analysis (CCLCDA)</p></a></li>
<li><a href='#cclcda2'><p>Common Components Latent Class Discriminant Analysis 2 (CCLCDA2)</p></a></li>
<li><a href='#lcda'><p>Latent Class Discriminant Analysis (LCDA)</p></a></li>
<li><a href='#predict.cclcda'><p>Predict method for Common Components Latent Class Discriminant Analysis (CCLCDA)</p></a></li>
<li><a href='#predict.cclcda2'><p>Predict method for Common Components Latent Class Discriminant Analysis 2 (CCLCDA2)</p></a></li>
<li><a href='#predict.lcda'><p>Predict method for Latent Class Discriminant Analysis (LCDA)</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Latent Class Discriminant Analysis</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-15</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.6.0), poLCA</td>
</tr>
<tr>
<td>Author:</td>
<td>Michael Buecker</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michael Buecker &lt;michael.buecker@fh-muenster.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Providing a method for Local Discrimination via Latent Class Models. The approach is described in <a href="https://www.r-project.org/conferences/useR-2009/abstracts/pdf/Bucker.pdf">https://www.r-project.org/conferences/useR-2009/abstracts/pdf/Bucker.pdf</a>.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL]</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-15 13:49:27 UTC; michael</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-15 14:10:02 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
</table>
<hr>
<h2 id='cclcda'>Common Components Latent Class Discriminant Analysis (CCLCDA)</h2><span id='topic+cclcda'></span><span id='topic+cclcda.default'></span><span id='topic+cclcda.formula'></span>

<h3>Description</h3>

<p>Local Discrimination via Latent Class Models with common components.</p>


<h3>Usage</h3>

<pre><code class='language-R'>cclcda(x, ...)


## Default S3 method:
cclcda(x, grouping=NULL, prior=NULL,
                         probs.start=NULL, nrep=1, m=3, 
                         maxiter = 1000, tol = 1e-10,
                         subset, na.rm = FALSE, ...)

## S3 method for class 'formula'
cclcda(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cclcda_+3A_x">x</code></td>
<td>
<p>Matrix or data frame containing the explanatory variables. Manifest variables must contain only integer values, and must be coded with consecutive values from 1 to the maximum number of outcomes for each variable. All missing values should be entered as NA.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_grouping">grouping</code></td>
<td>
<p>A factor specifying the class for each observation; if not specified, the first column of 'data' is taken. The class must be coded by integer values with consecutive values from 1 to the maximum number of classes.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_formula">formula</code></td>
<td>
<p>Formula of the form <code>'groups ~ x1 + x2 + ...'</code>.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in formula are to be taken.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_prior">prior</code></td>
<td>
<p>The prior probabilities of class membership. If unspecified, the class proportions for the training set are used. If present, the probabilities should be specified in the order of the factor levels.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_probs.start">probs.start</code></td>
<td>
<p>A list of matrices (per variable) of response probabilities <code class="reqn">\theta_{mkdr}</code> to be used as the starting values for the estimation algorithm. Each matrix in the list corresponds to one manifest variable, with one row for each latent class, and one column for each outcome. The default is <code>NULL</code>, producing random starting values. Note that if <code>nrep&gt;1</code>, then any user-specified <code>probs.start</code> values are only used in the first of the nrep attempts.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_nrep">nrep</code></td>
<td>
<p>Number of times to estimate the model, using different random values of <code>probs.start</code>. The default is one. Setting <code>nrep&gt;1</code> automates the search for the global &ndash; rather than just a local &ndash; maximum of the log-likelihood function. <code>cclcda</code> uses the parameter estimates corresponding to the model with the greatest log-likelihood.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_m">m</code></td>
<td>
<p>The number of subclasses. Can be either a vector containing the number of subclasses per class or a number of subclasses for all classes. Default is <code>m=3</code>.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations through which the estimation algorithm will cycle.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_tol">tol</code></td>
<td>
<p>A tolerance value for judging when convergence has been reached. When the one-iteration change in the estimated log-likelihood is less than <code>tol</code>, the estimation algorithm stops updating and considers the maximum log-likelihood to have been found.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the training sample.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, for how <code>cclcda</code> handles cases with missing values on the manifest variables. If <code>TRUE</code>, those cases are removed (listwise deleted) before estimating the model. If <code>FALSE</code>, cases with missing values are retained. Cases with missing covariates are always removed. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cclcda_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>cclcda.default</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>cclcda</code>-function performs a Common Components Latent Class Discriminant Analysis (CCLCDA). The model to estimate is
</p>
<p style="text-align: center;"><code class="reqn">f(x) = \sum_{m=1}^{M} w_{m} \prod_{d=1}^D\prod_{r=1}^{R_d} \theta_{mdr}^{x_{dr}},</code>
</p>

<p>where <code class="reqn">m</code> is the latent subclass index, <code class="reqn">d</code> is the variable index and <code class="reqn">r</code> is the observation index. The variable <code class="reqn">x_{dr}</code> is <code class="reqn">1</code> if the variable <code class="reqn">d</code> of this observation is <code class="reqn">r</code>.
This common Latent Class Modell will be estimated for all classes by the <code>poLCA</code>-function (see <code><a href="poLCA.html#topic+poLCA">poLCA</a></code>) and class conditional mixing proportions <code class="reqn">w_{mk}</code> are computed afterwards. These weights are computed by
</p>
<p style="text-align: center;"><code class="reqn">\frac{1}{N_k} \sum_{n=1}^{N_k}\hat{P}(m, k|X=x_n),</code>
</p>

<p>where <code class="reqn">k</code> is the class index and <code class="reqn">N_k</code> the number of observations in class <code class="reqn">k</code>.
</p>
<p>The LCA uses the assumption of local independence to estimate a mixture model of latent multi-way tables, the number of which (<code>m</code>) is specified by the user. Estimated parameters include the latent-class-conditional response probabilities for each manifest variable <code class="reqn">\theta_{mdr}</code> and the class conditional mixing proportions <code class="reqn">w_{mk}</code> denoting population share of observations corresponding to each latent multi-way table per class. 
</p>
<p>Posterior class probabilities can be estimated with the <code>predict</code> method.
</p>


<h3>Value</h3>

<p>A list of class <code>cclcda</code> containing the following components:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The (matched) function call.</p>
</td></tr>
<tr><td><code>lca.theta</code></td>
<td>
<p>The estimated class conditional response probabilities of the LCA given as a list of matrices like <code>probs.start</code>.</p>
</td></tr>
<tr><td><code>lca.w</code></td>
<td>
<p>The estimated mixing proportions of the LCA.</p>
</td></tr>
<tr><td><code>lca.wmk</code></td>
<td>
<p>The estimated class conditional mixing proportions of the LCA.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>Prior probabilites.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>Number of latent subclasses.</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>Number of different responses per variable.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Number of classes.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>Number of variables.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>Value of the AIC for each class conditional Latent Class Model.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>Value of the BIC for each class conditional Latent Class Model.</p>
</td></tr>
<tr><td><code>Gsq</code></td>
<td>
<p>The likelihood ratio/deviance statistic for each class conditional model.</p>
</td></tr>
<tr><td><code>Chisq</code></td>
<td>
<p>The Pearson Chi-square goodness of fit statistic for fitted vs. observed multiway tables for each class conditional model.</p>
</td></tr>
<tr><td><code>entropy</code></td>
<td>
<p>Value of the weighted entropy as described below.</p>
</td></tr>
<tr><td><code>gini</code></td>
<td>
<p>Value of the weighted Gini coefficient as described below.</p>
</td></tr>
<tr><td><code>chi.stat</code></td>
<td>
<p>Value of the Chi-square test statistik of the test  of latent class membership and class membership as described below.</p>
</td></tr>
<tr><td><code>chi.p</code></td>
<td>
<p>P Value of the Chi-square of the test  of latent class membership and class membership as described below.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If the number of latent classes per class is unknown a model selection must be accomplished to determine the value of <code>m</code>. For this goal there are some model selection criteria implemented. The AIC, BIC, likelihood ratio statistic and the Chi-square goodness of fit statistic are taken from the poLCA-function (see <code><a href="poLCA.html#topic+poLCA">poLCA</a></code>).
</p>
<p>Additionally <code>cclcda</code> provides quality criteria which should give insight into the model's classification potential. These criteria are similar to the splitting criteria of classification trees. The impurity measures are
</p>
<p>&ndash; Weighted entropy: The weighted entropy is given by
</p>
<p style="text-align: center;"><code class="reqn">H := - \sum_{m=1}^M  P(m) \sum_{k=1}^K \left(P(k|m) \cdot \log_{K}{P(k|m)}\right).</code>
</p>

<p>&ndash; Weighted Gini coefficient: The weighted Gini coefficient is given by
</p>
<p style="text-align: center;"><code class="reqn">G := \sum_{m=1}^M  P(m) \left[ 1- \sum_{k=1}^{K} \left( P(k|m) \right)^2 \right].</code>
</p>

<p>&ndash; Pearson's Chi-square test: A Pearson's Chi-square test is performed to test the independence of latent class membership and class membership.
</p>


<h3>Author(s)</h3>

<p> Michael B\&quot;ucker</p>


<h3>See Also</h3>

 <p><code><a href="#topic+predict.cclcda">predict.cclcda</a></code>, <code><a href="#topic+lcda">lcda</a></code>, <code><a href="#topic+predict.lcda">predict.lcda</a></code>, <code><a href="#topic+cclcda2">cclcda2</a></code>, <code><a href="#topic+predict.cclcda2">predict.cclcda2</a></code>, <code><a href="poLCA.html#topic+poLCA">poLCA</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># response probabilites
probs1 &lt;- list()

probs1[[1]] &lt;- matrix(c(0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1,
                        0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7), 
                      nrow=4, byrow=TRUE)
probs1[[2]] &lt;- matrix(c(0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1,
                        0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1),
                      nrow=4, byrow=TRUE)
probs1[[3]] &lt;- matrix(c(0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7,
                        0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1),
                      nrow=4, byrow=TRUE)
probs1[[4]] &lt;- matrix(c(0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1,
                        0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1),
                      nrow=4, byrow=TRUE)

prior &lt;- c(0.5,0.5)
wmk &lt;- matrix(c(0.45,0.45,0.05,0.05,0.05,0.05,0.45,0.45),
              ncol=4, nrow=2, byrow=TRUE)
wkm &lt;- apply(wmk*prior, 2, function(x) x/sum(x))

# generation of training data
data_temp &lt;- poLCA.simdata(N = 1000, probs = probs1,
                           nclass = 2, ndv = 4, nresp = 4,
                           P=rep(0.25,4))
data &lt;- data_temp$dat
lclass &lt;- data_temp$trueclass
grouping &lt;- numeric()
for (i in 1:length(lclass))
{
grouping[i] &lt;- sample(c(1,2),1, prob=wkm[,lclass[i]])
}

# generation of test data
data_temp &lt;- poLCA.simdata(N = 500, probs = probs1,
                           nclass = 2, ndv = 4, nresp = 4,
                           P=rep(0.25,4))
data.test &lt;- data_temp$dat
lclass &lt;- data_temp$trueclass
grouping.test &lt;- numeric()
for (i in 1:length(lclass))
{
grouping.test[i] &lt;- sample(c(1,2),1, prob=wkm[,lclass[i]])
}

# cclcda-procedure
object &lt;- cclcda(data, grouping, m=4)
object
</code></pre>

<hr>
<h2 id='cclcda2'>Common Components Latent Class Discriminant Analysis 2 (CCLCDA2)</h2><span id='topic+cclcda2'></span><span id='topic+cclcda2.default'></span><span id='topic+cclcda2.formula'></span>

<h3>Description</h3>

<p>Local Discrimination via Latent Class Models with common components</p>


<h3>Usage</h3>

<pre><code class='language-R'>cclcda2(x, ...)

## Default S3 method:
cclcda2(x, grouping=NULL, prior=NULL,
                          probs.start=NULL, wmk.start=NULL, 
                          nrep=1, m=3, maxiter = 1000, 
                          tol = 1e-10, subset, na.rm = FALSE, ...)

## S3 method for class 'formula'
cclcda2(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cclcda2_+3A_x">x</code></td>
<td>
<p>Matrix or data frame containing the explanatory variables. Manifest variables must contain only integer values, and must be coded with consecutive values from 1 to the maximum number of outcomes for each variable. All missing values should be entered as NA.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_grouping">grouping</code></td>
<td>
<p>A factor specifying the class for each observation; if not specified, the first column of 'data' is taken. The class must be coded by integer values with consecutive values from 1 to the maximum number of classes.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_formula">formula</code></td>
<td>
<p>Formula of the form <code>'groups ~ x1 + x2 + ...'</code>.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in formula are to be taken.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_prior">prior</code></td>
<td>
<p>The prior probabilities of class membership. If unspecified, the class proportions for the training set are used. If present, the probabilities should be specified in the order of the factor levels.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_probs.start">probs.start</code></td>
<td>
<p>A list of matrices (per variable) of response probabilities <code class="reqn">\theta_{mkdr}</code> to be used as the starting values for the estimation algorithm. Each matrix in the list corresponds to one manifest variable, with one row for each latent class, and one column for each outcome. The default is <code>NULL</code>, producing random starting values. Note that if <code>nrep&gt;1</code>, then any user-specified <code>probs.start</code> values are only used in the first of the nrep attempts.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_wmk.start">wmk.start</code></td>
<td>
<p>A matrix of starting values for the parameter <code class="reqn">w_{mk}</code> (see details). The default is <code>NULL</code>, producing random starting values. Note that if <code>nrep&gt;1</code>, then any user-specified <code>wmk.start</code> values are only used in the first of the nrep attempts.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_nrep">nrep</code></td>
<td>
<p>Number of times to estimate the model, using different random values of <code>probs.start</code>. The default is one. Setting <code>nrep&gt;1</code> automates the search for the global &ndash; rather than just a local &ndash; maximum of the log-likelihood function. <code>cclcda2</code> uses the parameter estimates corresponding to the model with the greatest log-likelihood.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_m">m</code></td>
<td>
<p>The number of subclasses. Can be either a vector containing the number of subclasses per class or a number of subclasses for all classes. Default is <code>m=3</code>.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations through which the estimation algorithm will cycle.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_tol">tol</code></td>
<td>
<p>A tolerance value for judging when convergence has been reached. When the one-iteration change in the estimated log-likelihood is less than <code>tol</code>, the estimation algorithm stops updating and considers the maximum log-likelihood to have been found.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the training sample.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, for how <code>cclcda2</code> handles cases with missing values on the manifest variables. If <code>TRUE</code>, those cases are removed (listwise deleted) before estimating the model. If <code>FALSE</code>, cases with missing values are retained. Cases with missing covariates are always removed. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="cclcda2_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>cclcda2.default</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>cclcda2</code>-function performs a Common Components Latent Class Discriminant Analysis 2 (CCLCDA2). The class conditional model to estimate is
</p>
<p style="text-align: center;"><code class="reqn">f_k(x) = \sum_{m=1}^{M_k} w_{mk} \prod_{d=1}^D\prod_{r=1}^{R_d} \theta_{mdr}^{x_{dr}},</code>
</p>

<p>where <code class="reqn">m</code> is the latent subclass index, <code class="reqn">d</code> is the variable index and <code class="reqn">r</code> is the observation index. The variable <code class="reqn">x_{dr}</code> is <code class="reqn">1</code> if the variable <code class="reqn">d</code> of this observation is <code class="reqn">r</code>.
This Latent Class Modell will be estimated. The class conditional mixing proportions <code class="reqn">w_{mk}</code> and the parameters <code class="reqn">\theta_{mdr}</code> are computed in every step of the EM-Algorithm.
</p>
<p>The LCA uses the assumption of local independence to estimate a mixture model of latent multi-way tables, the number of which (<code>m</code>) is specified by the user. Estimated parameters include the latent-class-conditional response probabilities for each manifest variable <code class="reqn">\theta_{mdr}</code> and the class conditional mixing proportions <code class="reqn">w_{mk}</code> denoting population share of observations corresponding to each latent multi-way table per class. 
</p>
<p>Posterior class probabilities can be estimated with the <code>predict</code> method.
</p>


<h3>Value</h3>

<p>A list of class <code>cclcda2</code> containing the following components:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The (matched) function call.</p>
</td></tr>
<tr><td><code>lca.theta</code></td>
<td>
<p>The estimated class conditional response probabilities of the LCA given as a list of matrices like <code>probs.start</code>.</p>
</td></tr>
<tr><td><code>lca.w</code></td>
<td>
<p>The estimated mixing proportions of the LCA.</p>
</td></tr>
<tr><td><code>lca.wmk</code></td>
<td>
<p>The estimated class conditional mixing proportions of the LCA.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>Prior probabilites.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>Number of latent subclasses.</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>Number of different responses per variable.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Number of classes.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>Number of variables.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>Value of the AIC for each class conditional Latent Class Model.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>Value of the BIC for each class conditional Latent Class Model.</p>
</td></tr>
<tr><td><code>Gsq</code></td>
<td>
<p>The likelihood ratio/deviance statistic for each class conditional model.</p>
</td></tr>
<tr><td><code>Chisq</code></td>
<td>
<p>The Pearson Chi-square goodness of fit statistic for fitted vs. observed multiway tables for each class conditional model.</p>
</td></tr>
<tr><td><code>entropy</code></td>
<td>
<p>Value of the weighted entropy as described below.</p>
</td></tr>
<tr><td><code>gini</code></td>
<td>
<p>Value of the weighted Gini coefficient as described below.</p>
</td></tr>
<tr><td><code>chi.stat</code></td>
<td>
<p>Value of the Chi-square test statistik of the test  of latent class membership and class membership as described below.</p>
</td></tr>
<tr><td><code>chi.p</code></td>
<td>
<p>P Value of the Chi-square of the test  of latent class membership and class membership as described below.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If the number of latent classes per class is unknown a model selection must be accomplished to determine the value of <code>m</code>. For this goal there are some model selection criteria implemented. The AIC, BIC, likelihood ratio statistic and the Chi-square goodness of fit statistic are taken from the poLCA-function (see <code><a href="poLCA.html#topic+poLCA">poLCA</a></code>).
</p>
<p>Additionally <code>cclcda2</code> provides quality criteria which should give insight into the model's classification potential. These criteria are similar to the splitting criteria of classification trees. The impurity measures are
</p>
<p>&ndash; Weighted entropy: The weighted entropy is given by
</p>
<p style="text-align: center;"><code class="reqn">H := - \sum_{m=1}^M  P(m) \sum_{k=1}^K \left(P(k|m) \cdot \log_{K}{P(k|m)}\right).</code>
</p>

<p>&ndash; Weighted Gini coefficient: The weighted Gini coefficient is given by
</p>
<p style="text-align: center;"><code class="reqn">G := \sum_{m=1}^M  P(m) \left[ 1- \sum_{k=1}^{K} \left( P(k|m) \right)^2 \right].</code>
</p>

<p>&ndash; Pearson's Chi-square test: A Pearson's Chi-square test is performed to test the independence of latent class membership and class membership.
</p>


<h3>Author(s)</h3>

<p> Michael B\&quot;ucker</p>


<h3>See Also</h3>

 <p><code><a href="#topic+predict.cclcda2">predict.cclcda2</a></code>, <code><a href="#topic+lcda">lcda</a></code>, <code><a href="#topic+predict.lcda">predict.lcda</a></code>, <code><a href="#topic+cclcda">cclcda</a></code>, <code><a href="#topic+predict.cclcda">predict.cclcda</a></code>, <code><a href="poLCA.html#topic+poLCA">poLCA</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># response probabilites
probs1 &lt;- list()

probs1[[1]] &lt;- matrix(c(0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1,
                        0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7), 
                      nrow=4, byrow=TRUE)
probs1[[2]] &lt;- matrix(c(0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1,
                        0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1),
                      nrow=4, byrow=TRUE)
probs1[[3]] &lt;- matrix(c(0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7,
                        0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1),
                      nrow=4, byrow=TRUE)
probs1[[4]] &lt;- matrix(c(0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1,
                        0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1),
                      nrow=4, byrow=TRUE)

prior &lt;- c(0.5,0.5)
wmk &lt;- matrix(c(0.45,0.45,0.05,0.05,0.05,0.05,0.45,0.45),
              ncol=4, nrow=2, byrow=TRUE)
wkm &lt;- apply(wmk*prior, 2, function(x) x/sum(x))

# generation of training data
data_temp &lt;- poLCA.simdata(N = 1000, probs = probs1,
                           nclass = 2, ndv = 4, nresp = 4,
                           P=rep(0.25,4))
data &lt;- data_temp$dat
lclass &lt;- data_temp$trueclass
grouping &lt;- numeric()
for (i in 1:length(lclass))
{
grouping[i] &lt;- sample(c(1,2),1, prob=wkm[,lclass[i]])
}

# generation of test data
data_temp &lt;- poLCA.simdata(N = 500, probs = probs1,
                           nclass = 2, ndv = 4, nresp = 4,
                           P=rep(0.25,4))
data.test &lt;- data_temp$dat
lclass &lt;- data_temp$trueclass
grouping.test &lt;- numeric()
for (i in 1:length(lclass))
{
grouping.test[i] &lt;- sample(c(1,2),1, prob=wkm[,lclass[i]])
}

# cclcda-procedure
object &lt;- cclcda2(data, grouping, m=4)
object
</code></pre>

<hr>
<h2 id='lcda'>Latent Class Discriminant Analysis (LCDA)</h2><span id='topic+lcda'></span><span id='topic+lcda.default'></span><span id='topic+lcda.formula'></span>

<h3>Description</h3>

<p>Local Discrimination via Latent Class Models</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcda(x, ...)


## Default S3 method:
lcda(x, grouping=NULL, prior=NULL,
                       probs.start=NULL, nrep=1, m=3, 
                       maxiter = 1000, tol = 1e-10,
                       subset, na.rm = FALSE, ...)

## S3 method for class 'formula'
lcda(formula, data, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lcda_+3A_x">x</code></td>
<td>
<p>Matrix or data frame containing the explanatory variables. Manifest variables must contain only integer values, and must be coded with consecutive values from 1 to the maximum number of outcomes for each variable. All missing values should be entered as NA.</p>
</td></tr>
<tr><td><code id="lcda_+3A_grouping">grouping</code></td>
<td>
<p>A factor specifying the class for each observation; if not specified, the first column of <code>data</code> is taken. The class must be coded by integer values with consecutive values from 1 to the maximum number of classes.</p>
</td></tr>
<tr><td><code id="lcda_+3A_formula">formula</code></td>
<td>
<p>Formula of the form <code>'groups ~ x1 + x2 + ...'</code>.</p>
</td></tr>
<tr><td><code id="lcda_+3A_data">data</code></td>
<td>
<p>Data frame from which variables specified in formula are to be taken.</p>
</td></tr>
<tr><td><code id="lcda_+3A_prior">prior</code></td>
<td>
<p>The prior probabilities of class membership. If unspecified, the class proportions for the training set are used. If present, the probabilities should be specified in the order of the factor levels.</p>
</td></tr>
<tr><td><code id="lcda_+3A_probs.start">probs.start</code></td>
<td>
<p>A list (per class) of lists of matrices (per variable) of response probabilities <code class="reqn">\theta_{mkdr}</code> to be used as the starting values for the estimation algorithm. Each matrix in the list corresponds to one manifest variable, with one row for each latent class, and one column for each outcome. The default is <code>NULL</code>, producing random starting values. Note that if <code>nrep&gt;1</code>, then any user-specified <code>probs.start</code> values are only used in the first of the nrep attempts.</p>
</td></tr>
<tr><td><code id="lcda_+3A_nrep">nrep</code></td>
<td>
<p>Number of times to estimate the model, using different random values of <code>probs.start</code>. The default is one. Setting <code>nrep&gt;1</code> automates the search for the global &ndash; rather than just a local &ndash; maximum of the log-likelihood function. <code>lcda</code> uses the parameter estimates corresponding to the model with the greatest log-likelihood.</p>
</td></tr>
<tr><td><code id="lcda_+3A_m">m</code></td>
<td>
<p>The number of subclasses per class. Can be either a vector containing the number of subclasses per class or a number of subclasses for all classes. Default is <code>m=3</code>.</p>
</td></tr>
<tr><td><code id="lcda_+3A_maxiter">maxiter</code></td>
<td>
<p>The maximum number of iterations through which the estimation algorithm will cycle.</p>
</td></tr>
<tr><td><code id="lcda_+3A_tol">tol</code></td>
<td>
<p>A tolerance value for judging when convergence has been reached. When the one-iteration change in the estimated log-likelihood is less than <code>tol</code>, the estimation algorithm stops updating and considers the maximum log-likelihood to have been found.</p>
</td></tr>
<tr><td><code id="lcda_+3A_subset">subset</code></td>
<td>
<p>An index vector specifying the cases to be used in the training sample.</p>
</td></tr>
<tr><td><code id="lcda_+3A_na.rm">na.rm</code></td>
<td>
<p>Logical, for how <code>lcda</code> handles cases with missing values on the manifest variables. If <code>TRUE</code>, those cases are removed (listwise deleted) before estimating the model. If <code>FALSE</code>, cases with missing values are retained. Cases with missing covariates are always removed. The default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="lcda_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to <code>lcda</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>lcda</code>-function performs a Latent Class Discriminant Analysis (LCDA).  A Latent Class Modell will be estimated for each class by the <code>poLCA</code>-function (see <code><a href="poLCA.html#topic+poLCA">poLCA</a></code>).
The class conditional model is given by
</p>
<p style="text-align: center;"><code class="reqn">f_k(x) = \sum_{m=1}^{M_k} w_{mk} \prod_{d=1}^D\prod_{r=1}^{R_d} \theta_{mkdr}^{x_{kdr}},</code>
</p>

<p>where <code class="reqn">k</code> is the class index, <code class="reqn">m</code> is the latent subclass index, <code class="reqn">d</code> is the variable index and <code class="reqn">r</code> is the observation index. The variable <code class="reqn">x_{kdr}</code> is <code class="reqn">1</code> if the variable <code class="reqn">d</code> of this observation is <code class="reqn">r</code> and in class <code class="reqn">k</code>. The parameter <code class="reqn">w_{mk}</code> is the class conditional mixture weight and <code class="reqn">\theta_{mkdr}</code> is the probability for outcome <code class="reqn">r</code> of variable <code class="reqn">d</code> in subclass <code class="reqn">m</code> of class <code class="reqn">k</code>.
</p>
<p>These Latent Class Models use the assumption of local independence to estimate a mixture model of latent multi-way tables. The mixture models are estimated by the EM-algorithm. The number of mixture components (<code>m</code>) is specified by the user. Estimated parameters include the latent-class conditional response probabilities for each manifest variable  <code class="reqn">\theta_{mkdr}</code> and the class conditional mixing proportions <code class="reqn">w_{mk}</code> denoting the population share of observations corresponding to each latent multi-way table.
</p>
<p>Posterior class probabilities and class memberships can be estimated with the <code>predict</code> method.</p>


<h3>Value</h3>

<p>A list of class <code>lcda</code> containing the following components:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The (matched) function call.</p>
</td></tr>
<tr><td><code>lca.theta</code></td>
<td>
<p>The estimated class conditional response probabilities of the LCA given as a list of matrices like <code>probs.start</code>.</p>
</td></tr>
<tr><td><code>lca.w</code></td>
<td>
<p>The estimated mixing proportions of the LCA.</p>
</td></tr>
<tr><td><code>prior</code></td>
<td>
<p>Prior probabilites.</p>
</td></tr>
<tr><td><code>m</code></td>
<td>
<p>Number of latent subclasses per class.</p>
</td></tr>
<tr><td><code>r</code></td>
<td>
<p>Number of possible responses per variable.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>Number of classes.</p>
</td></tr>
<tr><td><code>d</code></td>
<td>
<p>Number of variables.</p>
</td></tr>
<tr><td><code>aic</code></td>
<td>
<p>Value of the AIC for each class conditional Latent Class Model.</p>
</td></tr>
<tr><td><code>bic</code></td>
<td>
<p>Value of the BIC for each class conditional Latent Class Model.</p>
</td></tr>
<tr><td><code>Gsq</code></td>
<td>
<p>The likelihood ratio/deviance statistic for each class conditional model.</p>
</td></tr>
<tr><td><code>Chisq</code></td>
<td>
<p>The Pearson Chi-square goodness of fit statistic for fitted vs. observed multiway tables for each class conditional model.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If the number of latent classes per class is unknown a model selection must be accomplished to determine the value of <code>m</code>. For this goal there are some model selection criteria implemented. The AIC, BIC, likelihood ratio statistic and the Chi-square goodness of fit statistic are taken from the poLCA-function (see <code><a href="poLCA.html#topic+poLCA">poLCA</a></code>). For each class these criteria can be regarded separately and for each class the number of latent classes can be determined.</p>


<h3>Author(s)</h3>

<p> Michael B\&quot;ucker</p>


<h3>See Also</h3>

 <p><code><a href="#topic+predict.lcda">predict.lcda</a></code>, <code><a href="#topic+cclcda">cclcda</a></code>, <code><a href="#topic+predict.cclcda">predict.cclcda</a></code>, <code><a href="#topic+cclcda2">cclcda2</a></code>, <code><a href="#topic+predict.cclcda2">predict.cclcda2</a></code>, <code><a href="poLCA.html#topic+poLCA">poLCA</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># response probabilites for class 1
probs1 &lt;- list()
probs1[[1]] &lt;- matrix(c(0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1), 
                      nrow=2, byrow=TRUE)
probs1[[2]] &lt;- matrix(c(0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1),
                      nrow=2, byrow=TRUE)
probs1[[3]] &lt;- matrix(c(0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7),
                      nrow=2, byrow=TRUE)
probs1[[4]] &lt;- matrix(c(0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1),
                      nrow=2, byrow=TRUE)

# response probabilites for class 2
probs2 &lt;- list()
probs2[[1]] &lt;- matrix(c(0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7),
                      nrow=2, byrow=TRUE)
probs2[[2]] &lt;- matrix(c(0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1),
                      nrow=2, byrow=TRUE)
probs2[[3]] &lt;- matrix(c(0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1),
                      nrow=2, byrow=TRUE)
probs2[[4]] &lt;- matrix(c(0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1),
                      nrow=2, byrow=TRUE)

# generation of data
simdata1 &lt;- poLCA.simdata(N = 500, probs = probs1, nclass = 2,
              ndv = 4, nresp = 4, missval = FALSE)

simdata2 &lt;- poLCA.simdata(N = 500, probs = probs2, nclass = 2,
              ndv = 4, nresp = 4, missval = FALSE)

data1 &lt;- simdata1$dat
data2 &lt;- simdata2$dat

data &lt;- cbind(rbind(data1, data2), rep(c(1,2), each=500))
names(data)[5] &lt;- "grouping"
data &lt;- data[sample(1:1000),]
grouping &lt;- data[[5]]
data &lt;- data[,1:4]

# lcda-procedure
object &lt;- lcda(data, grouping=grouping, m=2)
object
</code></pre>

<hr>
<h2 id='predict.cclcda'>Predict method for Common Components Latent Class Discriminant Analysis (CCLCDA)</h2><span id='topic+predict.cclcda'></span>

<h3>Description</h3>

<p>Classifies new observations using parameters determined by
the <code>cclcda</code>-function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cclcda'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cclcda_+3A_object">object</code></td>
<td>
<p>Object of class <code>cclcda</code>.</p>
</td></tr>
<tr><td><code id="predict.cclcda_+3A_newdata">newdata</code></td>
<td>
<p>Data frame of cases to be classified.</p>
</td></tr>
<tr><td><code id="predict.cclcda_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Posterior probabilities for new observations using parameters determined by
the <code>cclcda</code>-function are computed. The classification of the new data is done by the Bayes decision function.
</p>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>class</code></td>
<td>
<p>Vector (of class <code>factor</code>) of classifications.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>Posterior probabilities for the classes. 
For details of computation see <code><a href="#topic+cclcda">cclcda</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Michael B\&quot;ucker</p>


<h3>See Also</h3>

 <p><code><a href="#topic+cclcda">cclcda</a></code>, <code><a href="#topic+lcda">lcda</a></code>, <code><a href="#topic+predict.lcda">predict.lcda</a></code>, <code><a href="#topic+cclcda2">cclcda2</a></code>, <code><a href="#topic+predict.cclcda2">predict.cclcda2</a></code>, <code><a href="poLCA.html#topic+poLCA">poLCA</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># response probabilites
probs1 &lt;- list()

probs1[[1]] &lt;- matrix(c(0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1,
                        0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7), 
                      nrow=4, byrow=TRUE)
probs1[[2]] &lt;- matrix(c(0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1,
                        0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1),
                      nrow=4, byrow=TRUE)
probs1[[3]] &lt;- matrix(c(0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7,
                        0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1),
                      nrow=4, byrow=TRUE)
probs1[[4]] &lt;- matrix(c(0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1,
                        0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1),
                      nrow=4, byrow=TRUE)

prior &lt;- c(0.5,0.5)
wmk &lt;- matrix(c(0.45,0.45,0.05,0.05,0.05,0.05,0.45,0.45),
              ncol=4, nrow=2, byrow=TRUE)
wkm &lt;- apply(wmk*prior, 2, function(x) x/sum(x))

# generation of training data
data_temp &lt;- poLCA.simdata(N = 1000, probs = probs1,
                           nclass = 2, ndv = 4, nresp = 4,
                           P=rep(0.25,4))
data &lt;- data_temp$dat
lclass &lt;- data_temp$trueclass
grouping &lt;- numeric()
for (i in 1:length(lclass))
{
grouping[i] &lt;- sample(c(1,2),1, prob=wkm[,lclass[i]])
}

# generation of test data
data_temp &lt;- poLCA.simdata(N = 500, probs = probs1,
                           nclass = 2, ndv = 4, nresp = 4,
                           P=rep(0.25,4))
data.test &lt;- data_temp$dat
lclass &lt;- data_temp$trueclass
grouping.test &lt;- numeric()
for (i in 1:length(lclass))
{
grouping.test[i] &lt;- sample(c(1,2),1, prob=wkm[,lclass[i]])
}

# cclcda-procedure
object &lt;- cclcda(data, grouping, m=4)
pred &lt;- predict(object, data.test)$class
1-(sum(pred==grouping.test)/500)
</code></pre>

<hr>
<h2 id='predict.cclcda2'>Predict method for Common Components Latent Class Discriminant Analysis 2 (CCLCDA2)</h2><span id='topic+predict.cclcda2'></span>

<h3>Description</h3>

<p>Classifies new observations using parameters determined by
the <code>cclcda2</code>-function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cclcda2'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.cclcda2_+3A_object">object</code></td>
<td>
<p>Object of class <code>cclcda2</code>.</p>
</td></tr>
<tr><td><code id="predict.cclcda2_+3A_newdata">newdata</code></td>
<td>
<p>Data frame of cases to be classified.</p>
</td></tr>
<tr><td><code id="predict.cclcda2_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Posterior probabilities for new observations using parameters determined by
the <code>cclcda2</code>-function are computed. The classification of the new data is done by the Bayes decision function.
</p>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>class</code></td>
<td>
<p>Vector (of class <code>factor</code>) of classifications.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>Posterior probabilities for the classes. 
For details of computation see <code><a href="#topic+cclcda2">cclcda2</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Michael B\&quot;ucker</p>


<h3>See Also</h3>

 <p><code><a href="#topic+cclcda2">cclcda2</a></code>, <code><a href="#topic+lcda">lcda</a></code>, <code><a href="#topic+predict.lcda">predict.lcda</a></code>, <code><a href="#topic+cclcda">cclcda</a></code>, <code><a href="#topic+predict.cclcda">predict.cclcda</a></code>, <code><a href="poLCA.html#topic+poLCA">poLCA</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># response probabilites
probs1 &lt;- list()

probs1[[1]] &lt;- matrix(c(0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1,
                        0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7), 
                      nrow=4, byrow=TRUE)
probs1[[2]] &lt;- matrix(c(0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1,
                        0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1),
                      nrow=4, byrow=TRUE)
probs1[[3]] &lt;- matrix(c(0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7,
                        0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1),
                      nrow=4, byrow=TRUE)
probs1[[4]] &lt;- matrix(c(0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1,
                        0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1),
                      nrow=4, byrow=TRUE)

prior &lt;- c(0.5,0.5)
wmk &lt;- matrix(c(0.45,0.45,0.05,0.05,0.05,0.05,0.45,0.45),
              ncol=4, nrow=2, byrow=TRUE)
wkm &lt;- apply(wmk*prior, 2, function(x) x/sum(x))

# generation of training data
data_temp &lt;- poLCA.simdata(N = 1000, probs = probs1,
                           nclass = 2, ndv = 4, nresp = 4,
                           P=rep(0.25,4))
data &lt;- data_temp$dat
lclass &lt;- data_temp$trueclass
grouping &lt;- numeric()
for (i in 1:length(lclass))
{
grouping[i] &lt;- sample(c(1,2),1, prob=wkm[,lclass[i]])
}

# generation of test data
data_temp &lt;- poLCA.simdata(N = 500, probs = probs1,
                           nclass = 2, ndv = 4, nresp = 4,
                           P=rep(0.25,4))
data.test &lt;- data_temp$dat
lclass &lt;- data_temp$trueclass
grouping.test &lt;- numeric()
for (i in 1:length(lclass))
{
grouping.test[i] &lt;- sample(c(1,2),1, prob=wkm[,lclass[i]])
}

# cclcda2-procedure
object &lt;- cclcda2(data, grouping, m=4)
pred &lt;- predict(object, data.test)$class
1-(sum(pred==grouping.test)/500)
</code></pre>

<hr>
<h2 id='predict.lcda'>Predict method for Latent Class Discriminant Analysis (LCDA)</h2><span id='topic+predict.lcda'></span>

<h3>Description</h3>

<p>Classifies new observations using the parameters determined by
the <code>lcda</code>-function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lcda'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.lcda_+3A_object">object</code></td>
<td>
<p>Object of class <code>lcda2</code>.</p>
</td></tr>
<tr><td><code id="predict.lcda_+3A_newdata">newdata</code></td>
<td>
<p>Data frame of cases to be classified.</p>
</td></tr>
<tr><td><code id="predict.lcda_+3A_...">...</code></td>
<td>
<p>Further arguments are ignored.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Posterior probabilities for new observations using parameters determined by
the <code>lcda</code>-function are computed. The classification of the new data is done by the Bayes decision function.
</p>


<h3>Value</h3>

<p>A list with components:
</p>
<table>
<tr><td><code>class</code></td>
<td>
<p>Vector (of class <code>factor</code>) of classifications.</p>
</td></tr>
<tr><td><code>posterior</code></td>
<td>
<p>Posterior probabilities for the classes. 
For details of computation see <code><a href="#topic+lcda">lcda</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p> Michael B\&quot;ucker</p>


<h3>See Also</h3>

 <p><code><a href="#topic+lcda">lcda</a></code>, <code><a href="#topic+cclcda">cclcda</a></code>, <code><a href="#topic+predict.cclcda">predict.cclcda</a></code>, <code><a href="#topic+cclcda2">cclcda2</a></code>, <code><a href="#topic+predict.cclcda2">predict.cclcda2</a></code>, <code><a href="poLCA.html#topic+poLCA">poLCA</a></code> </p>


<h3>Examples</h3>

<pre><code class='language-R'># response probabilites for class 1
probs1 &lt;- list()
probs1[[1]] &lt;- matrix(c(0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1), 
                      nrow=2, byrow=TRUE)
probs1[[2]] &lt;- matrix(c(0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1),
                      nrow=2, byrow=TRUE)
probs1[[3]] &lt;- matrix(c(0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7),
                      nrow=2, byrow=TRUE)
probs1[[4]] &lt;- matrix(c(0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1),
                      nrow=2, byrow=TRUE)

# response probabilites for class 2
probs2 &lt;- list()
probs2[[1]] &lt;- matrix(c(0.1,0.1,0.7,0.1,0.1,0.1,0.1,0.7),
                      nrow=2, byrow=TRUE)
probs2[[2]] &lt;- matrix(c(0.1,0.1,0.1,0.7,0.7,0.1,0.1,0.1),
                      nrow=2, byrow=TRUE)
probs2[[3]] &lt;- matrix(c(0.7,0.1,0.1,0.1,0.1,0.7,0.1,0.1),
                      nrow=2, byrow=TRUE)
probs2[[4]] &lt;- matrix(c(0.1,0.7,0.1,0.1,0.1,0.1,0.7,0.1),
                      nrow=2, byrow=TRUE)

# generation of data
simdata1 &lt;- poLCA.simdata(N = 500, probs = probs1, nclass = 2,
              ndv = 4, nresp = 4, missval = FALSE)

simdata2 &lt;- poLCA.simdata(N = 500, probs = probs2, nclass = 2,
              ndv = 4, nresp = 4, missval = FALSE)

data1 &lt;- simdata1$dat
data2 &lt;- simdata2$dat

data &lt;- cbind(rbind(data1, data2), rep(c(1,2), each=500))
names(data)[5] &lt;- "grouping"
data &lt;- data[sample(1:1000),]
grouping &lt;- data[[5]]
data &lt;- data[,1:4]

# lcda-procedure
object &lt;- lcda(data, grouping=grouping, m=2)
pred.class &lt;- predict(object, newdata=data)$class
sum(pred.class==grouping)/length(pred.class)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
