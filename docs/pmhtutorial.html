<!DOCTYPE html><html lang="en"><head><title>Help for package pmhtutorial</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pmhtutorial}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#example1_lgss'><p>State estimation in a linear Gaussian state space model</p></a></li>
<li><a href='#example2_lgss'><p>Parameter estimation in a linear Gaussian state space model</p></a></li>
<li><a href='#example3_sv'><p>Parameter estimation in a simple stochastic volatility model</p></a></li>
<li><a href='#example4_sv'><p>Parameter estimation in a simple stochastic volatility model</p></a></li>
<li><a href='#example5_sv'><p>Parameter estimation in a simple stochastic volatility model</p></a></li>
<li><a href='#generateData'><p>Generates data from a linear Gaussian state space model</p></a></li>
<li><a href='#kalmanFilter'><p>Kalman filter for state estimate in a linear Gaussian state space model</p></a></li>
<li><a href='#makePlotsParticleMetropolisHastingsSVModel'><p>Make plots for tutorial</p></a></li>
<li><a href='#particleFilter'><p>Fully-adapted particle filter for state estimate in a linear Gaussian state</p>
space model</a></li>
<li><a href='#particleFilterSVmodel'><p>Bootstrap particle filter for state estimate in a simple stochastic</p>
volatility model</a></li>
<li><a href='#particleMetropolisHastings'><p>Particle Metropolis-Hastings algorithm for a linear Gaussian state space</p>
model</a></li>
<li><a href='#particleMetropolisHastingsSVmodel'><p>Particle Metropolis-Hastings algorithm for a stochastic volatility model</p>
model</a></li>
<li><a href='#particleMetropolisHastingsSVmodelReparameterised'><p>Particle Metropolis-Hastings algorithm for a stochastic volatility model</p>
model</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Minimal Working Examples for Particle Metropolis-Hastings</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5</td>
</tr>
<tr>
<td>Author:</td>
<td>Johan Dahlin</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Johan Dahlin &lt;uni@johandahlin.com&gt;</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/compops/pmh-tutorial-rpkg">https://github.com/compops/pmh-tutorial-rpkg</a></td>
</tr>
<tr>
<td>Description:</td>
<td>Routines for state estimate in a linear
    Gaussian state space model and a simple stochastic volatility model using
    particle filtering. Parameter inference is also carried out in these models
    using the particle Metropolis-Hastings algorithm that includes the particle
    filter to provided an unbiased estimator of the likelihood. This package is
    a collection of minimal working examples of these algorithms and is only
    meant for educational use and as a start for learning to them on your own.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.3)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>mvtnorm, Quandl, grDevices, graphics, stats</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-03-22 16:10:20 UTC; work</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-03-22 18:10:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='example1_lgss'>State estimation in a linear Gaussian state space model</h2><span id='topic+example1_lgss'></span>

<h3>Description</h3>

<p>Minimal working example of state estimation in a linear Gaussian state
space model using Kalman filtering and a fully-adapted particle filter.
The code estimates the bias and mean squared error (compared with the
Kalman estimate) while varying the number of particles in the particle
filter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example1_lgss()
</code></pre>


<h3>Details</h3>

<p>The Kalman filter is a standard implementation without an input. The
particle filter is fully adapted (i.e. takes the current observation into
account when proposing new particles and computing the weights).
</p>


<h3>Value</h3>

<p>Returns a plot with the generated observations y and the difference in the
state estimates obtained by the Kalman filter (the optimal solution) and
the particle filter (with 20 particles). Furthermore, the function returns
plots of the estimated bias and mean squared error of the state estimate
obtained using the particle filter (while varying the number of particles)
and the Kalman estimates.
</p>
<p>The function returns a list with the elements:
</p>

<ul>
<li><p>y: The observations generated from the model.
</p>
</li>
<li><p>x: The states generated from the model.
</p>
</li>
<li><p>kfEstimate: The estimate of the state from the Kalman filter.
</p>
</li>
<li><p>pfEstimate: The estimate of the state from the particle filter with
20 particles.
</p>
</li></ul>



<h3>Note</h3>

<p>See Section 3.2 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example1_lgss()
</code></pre>

<hr>
<h2 id='example2_lgss'>Parameter estimation in a linear Gaussian state space model</h2><span id='topic+example2_lgss'></span>

<h3>Description</h3>

<p>Minimal working example of parameter estimation in a linear Gaussian state
space model using the particle Metropolis-Hastings algorithm with a
fully-adapted particle filter providing an unbiased estimator of the
likelihood. The code estimates the parameter posterior for one parameter
using simulated data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example2_lgss(noBurnInIterations = 1000, noIterations = 5000,
  noParticles = 100, initialPhi = 0.5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="example2_lgss_+3A_noburniniterations">noBurnInIterations</code></td>
<td>
<p>The number of burn-in iterations in the PMH algorithm.
This parameter must be smaller than <code>noIterations</code>.</p>
</td></tr>
<tr><td><code id="example2_lgss_+3A_noiterations">noIterations</code></td>
<td>
<p>The number of iterations in the PMH algorithm. 100 iterations
takes about ten seconds on a laptop to execute. 5000 iterations are used
in the reference below.</p>
</td></tr>
<tr><td><code id="example2_lgss_+3A_noparticles">noParticles</code></td>
<td>
<p>The number of particles to use when estimating the likelihood.</p>
</td></tr>
<tr><td><code id="example2_lgss_+3A_initialphi">initialPhi</code></td>
<td>
<p>The initial guess of the parameter phi.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Particle Metropolis-Hastings (PMH) algorithm makes use of a Gaussian
random walk as the proposal for the parameter. The PMH algorithm is run
using different step lengths in the proposal. This is done to illustrate
the difficulty when tuning the proposal and the impact of a too
small/large step length.
</p>


<h3>Value</h3>

<p>Returns the estimate of the posterior mean.
</p>


<h3>Note</h3>

<p>See Section 4.2 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

    example2_lgss(noBurnInIterations=200, noIterations=1000)

</code></pre>

<hr>
<h2 id='example3_sv'>Parameter estimation in a simple stochastic volatility model</h2><span id='topic+example3_sv'></span>

<h3>Description</h3>

<p>Minimal working example of parameter estimation in a stochastic volatility
model using the particle Metropolis-Hastings algorithm with a bootstrap
particle filter providing an unbiased estimator of the likelihood. The
code estimates the parameter posterior for three parameters using
real-world data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example3_sv(noBurnInIterations = 2500, noIterations = 7500,
  noParticles = 500, initialTheta = c(0, 0.9, 0.2),
  stepSize = diag(c(0.1, 0.01, 0.05)^2), syntheticData = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="example3_sv_+3A_noburniniterations">noBurnInIterations</code></td>
<td>
<p>The number of burn-in iterations in the PMH
algorithm. Must be smaller than <code>noIterations</code>.</p>
</td></tr>
<tr><td><code id="example3_sv_+3A_noiterations">noIterations</code></td>
<td>
<p>The number of iterations in the PMH algorithm. 100
iterations takes about a minute on a laptop to execute.</p>
</td></tr>
<tr><td><code id="example3_sv_+3A_noparticles">noParticles</code></td>
<td>
<p>The number of particles to use when estimating the likelihood.</p>
</td></tr>
<tr><td><code id="example3_sv_+3A_initialtheta">initialTheta</code></td>
<td>
<p>The initial guess of the parameters theta.</p>
</td></tr>
<tr><td><code id="example3_sv_+3A_stepsize">stepSize</code></td>
<td>
<p>The step sizes of the random walk proposal. Given as a covariance
matrix.</p>
</td></tr>
<tr><td><code id="example3_sv_+3A_syntheticdata">syntheticData</code></td>
<td>
<p>If TRUE, data is not downloaded from the Internet. This is only used when running tests of the package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Particle Metropolis-Hastings (PMH) algorithm makes use of a Gaussian
random walk as the proposal for the parameters. The data are scaled
log-returns from the OMXS30 index during the period from January 2, 2012
to January 2, 2014.
</p>
<p>This version of the code makes use of a somewhat well-tuned proposal as a
pilot run to estimate the posterior covariance and therefore increase the
mixing of the Markov chain.
</p>


<h3>Value</h3>

<p>The function returns the estimated marginal parameter posteriors for each
parameter, the trace of the Markov chain and the resulting autocorrelation
function. The data is also presented with an estimate of the
log-volatility.
</p>
<p>The function returns a list with the elements:
</p>

<ul>
<li><p>thhat: The estimate of the mean of the parameter posterior.
</p>
</li>
<li><p>xhat: The estimate of the mean of the log-volatility posterior.
</p>
</li>
<li><p>thhatSD: The estimate of the standard deviation of the parameter
posterior.
</p>
</li>
<li><p>xhatSD: The estimate of the standard deviation of the log-volatility
posterior.
</p>
</li>
<li><p>iact: The estimate of the integrated autocorrelation time for each
parameter.
</p>
</li>
<li><p>estCov: The estimate of the covariance of the parameter posterior.
</p>
</li>
<li><p>theta: The trace of the chain exploring the parameter posterior.
</p>
</li></ul>



<h3>Note</h3>

<p>See Section 5 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
    example3_sv(noBurnInIterations=200, noIterations=1000)

## End(Not run)
</code></pre>

<hr>
<h2 id='example4_sv'>Parameter estimation in a simple stochastic volatility model</h2><span id='topic+example4_sv'></span>

<h3>Description</h3>

<p>Minimal working example of parameter estimation in a stochastic volatility
model using the particle Metropolis-Hastings algorithm with a bootstrap
particle filter providing an unbiased estimator of the likelihood. The
code estimates the parameter posterior for three parameters using
real-world data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example4_sv(noBurnInIterations = 2500, noIterations = 7500,
  noParticles = 500, initialTheta = c(0, 0.9, 0.2),
  syntheticData = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="example4_sv_+3A_noburniniterations">noBurnInIterations</code></td>
<td>
<p>The number of burn-in iterations in the PMH
algorithm. Must be smaller than <code>noIterations</code>.</p>
</td></tr>
<tr><td><code id="example4_sv_+3A_noiterations">noIterations</code></td>
<td>
<p>The number of iterations in the PMH algorithm. 100
iterations takes about a minute on a laptop to execute.</p>
</td></tr>
<tr><td><code id="example4_sv_+3A_noparticles">noParticles</code></td>
<td>
<p>The number of particles to use when estimating the likelihood.</p>
</td></tr>
<tr><td><code id="example4_sv_+3A_initialtheta">initialTheta</code></td>
<td>
<p>The initial guess of the parameters theta.</p>
</td></tr>
<tr><td><code id="example4_sv_+3A_syntheticdata">syntheticData</code></td>
<td>
<p>If TRUE, data is not downloaded from the Internet. This is only used when running tests of the package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Particle Metropolis-Hastings (PMH) algorithm makes use of a Gaussian
random walk as the proposal for the parameters. The data are scaled
log-returns from the OMXS30 index during the period from January 2, 2012
to January 2, 2014.
</p>
<p>This version of the code makes use of a proposal that is tuned using a run of
<code><a href="#topic+example3_sv">example3_sv</a></code> and therefore have better mixing
properties.
</p>


<h3>Value</h3>

<p>The function returns the estimated marginal parameter posteriors for each
parameter, the trace of the Markov chain and the resulting autocorrelation
function. The data is also presented with an estimate of the
log-volatility.
</p>
<p>The function returns a list with the elements:
</p>

<ul>
<li><p>thhat: The estimate of the mean of the parameter posterior.
</p>
</li>
<li><p>xhat: The estimate of the mean of the log-volatility posterior.
</p>
</li>
<li><p>thhatSD: The estimate of the standard deviation of the parameter
posterior.
</p>
</li>
<li><p>xhatSD: The estimate of the standard deviation of the log-volatility
posterior.
</p>
</li>
<li><p>iact: The estimate of the integrated autocorrelation time for each
parameter.
</p>
</li>
<li><p>estCov: The estimate of the covariance of the parameter posterior.
</p>
</li></ul>



<h3>Note</h3>

<p>See Section 6.3.1 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
    example4_sv(noBurnInIterations=200, noIterations=1000)

## End(Not run)
</code></pre>

<hr>
<h2 id='example5_sv'>Parameter estimation in a simple stochastic volatility model</h2><span id='topic+example5_sv'></span>

<h3>Description</h3>

<p>Minimal working example of parameter estimation in a stochastic volatility
model using the particle Metropolis-Hastings algorithm with a bootstrap
particle filter providing an unbiased estimator of the likelihood. The
code estimates the parameter posterior for three parameters using
real-world data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>example5_sv(noBurnInIterations = 2500, noIterations = 7500,
  noParticles = 500, initialTheta = c(0, 0.9, 0.2),
  syntheticData = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="example5_sv_+3A_noburniniterations">noBurnInIterations</code></td>
<td>
<p>The number of burn-in iterations in the PMH
algorithm. Must be smaller than <code>noIterations</code>.</p>
</td></tr>
<tr><td><code id="example5_sv_+3A_noiterations">noIterations</code></td>
<td>
<p>The number of iterations in the PMH algorithm. 100
iterations takes about a minute on a laptop to execute.</p>
</td></tr>
<tr><td><code id="example5_sv_+3A_noparticles">noParticles</code></td>
<td>
<p>The number of particles to use when estimating the likelihood.</p>
</td></tr>
<tr><td><code id="example5_sv_+3A_initialtheta">initialTheta</code></td>
<td>
<p>The initial guess of the parameters theta.</p>
</td></tr>
<tr><td><code id="example5_sv_+3A_syntheticdata">syntheticData</code></td>
<td>
<p>If TRUE, data is not downloaded from the Internet. This is only used when running tests of the package.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Particle Metropolis-Hastings (PMH) algorithm makes use of a Gaussian
random walk as the proposal for the parameters. The data are scaled
log-returns from the OMXS30 index during the period from January 2, 2012
to January 2, 2014.
</p>
<p>This version of the code makes use of a proposal that is tuned using a
pilot run. Furthermore the model is reparameterised to enjoy better mixing
properties by making the parameters unrestricted to a certain part of the
real-line.
</p>


<h3>Value</h3>

<p>The function returns the estimated marginal parameter posteriors for each
parameter, the trace of the Markov chain and the resulting autocorrelation
function. The data is also presented with an estimate of the
log-volatility.
</p>
<p>The function returns a list with the elements:
</p>

<ul>
<li><p>thhat: The estimate of the mean of the parameter posterior.
</p>
</li>
<li><p>xhat: The estimate of the mean of the log-volatility posterior.
</p>
</li>
<li><p>thhatSD: The estimate of the standard deviation of the parameter
posterior.
</p>
</li>
<li><p>xhatSD: The estimate of the standard deviation of the log-volatility
posterior.
</p>
</li>
<li><p>iact: The estimate of the integrated autocorrelation time for each
parameter.
</p>
</li>
<li><p>estCov: The estimate of the covariance of the parameter posterior.
</p>
</li></ul>



<h3>Note</h3>

<p>See Section 6.3.2 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
    example5_sv(noBurnInIterations=200, noIterations=1000)

## End(Not run)
</code></pre>

<hr>
<h2 id='generateData'>Generates data from a linear Gaussian state space model</h2><span id='topic+generateData'></span>

<h3>Description</h3>

<p>Generates data from a specific linear Gaussian state space model of the form 
<code class="reqn"> x_{t} = \phi x_{t-1} + \sigma_v v_t </code> and <code class="reqn"> y_t = x_t + 
\sigma_e e_t </code>, where <code class="reqn">v_t</code> and <code class="reqn">e_t</code> denote independent standard 
Gaussian random variables, i.e. <code class="reqn">N(0,1)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generateData(theta, noObservations, initialState)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generateData_+3A_theta">theta</code></td>
<td>
<p>The parameters <code class="reqn">\theta=\{\phi,\sigma_v,\sigma_e\}</code> of the 
LGSS model. The parameter <code class="reqn">\phi</code> that scales the current state in 
the state dynamics is restricted to [-1,1] to obtain a stable model. 
The standard deviations of the state process noise <code class="reqn">\sigma_v</code> 
and the observation process noise <code class="reqn">\sigma_e</code> must be positive.</p>
</td></tr>
<tr><td><code id="generateData_+3A_noobservations">noObservations</code></td>
<td>
<p>The number of time points to simulate.</p>
</td></tr>
<tr><td><code id="generateData_+3A_initialstate">initialState</code></td>
<td>
<p>The initial state.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list with the elements: 
</p>

<ul>
<li><p>x: The latent state for <code class="reqn">t=0,...,T</code>.
</p>
</li>
<li><p>y: The observation for <code class="reqn">t=0,...,T</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>

<hr>
<h2 id='kalmanFilter'>Kalman filter for state estimate in a linear Gaussian state space model</h2><span id='topic+kalmanFilter'></span>

<h3>Description</h3>

<p>Estimates the filtered state and the log-likelihood for a linear Gaussian 
state space model of the form <code class="reqn"> x_{t} = \phi x_{t-1} + \sigma_v v_t </code> 
and <code class="reqn"> y_t = x_t + \sigma_e e_t </code>, where <code class="reqn">v_t</code> and <code class="reqn">e_t</code> denote 
independent standard Gaussian random variables, i.e.<code class="reqn">N(0,1)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kalmanFilter(y, theta, initialState, initialStateCovariance)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kalmanFilter_+3A_y">y</code></td>
<td>
<p>Observations from the model for <code class="reqn">t=1,...,T</code>.</p>
</td></tr>
<tr><td><code id="kalmanFilter_+3A_theta">theta</code></td>
<td>
<p>The parameters <code class="reqn">\theta=\{\phi,\sigma_v,\sigma_e\}</code> of the 
LGSS model. The parameter <code class="reqn">\phi</code> scales the current state in 
the state dynamics. The standard deviations of the state process noise
and the observation process noise are denoted <code class="reqn">\sigma_v</code> and 
<code class="reqn">\sigma_e</code>, respectively.</p>
</td></tr>
<tr><td><code id="kalmanFilter_+3A_initialstate">initialState</code></td>
<td>
<p>The initial state.</p>
</td></tr>
<tr><td><code id="kalmanFilter_+3A_initialstatecovariance">initialStateCovariance</code></td>
<td>
<p>The initial covariance of the state.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list with the elements:
</p>

<ul>
<li><p>xHatFiltered: The estimate of the filtered state at time <code class="reqn">t=1,...,T</code>.
</p>
</li>
<li><p>logLikelihood: The estimate of the log-likelihood.
</p>
</li></ul>



<h3>Note</h3>

<p>See Section 3 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generates 500 observations from a linear state space model with
# (phi, sigma_e, sigma_v) = (0.5, 1.0, 0.1) and zero initial state.
theta &lt;- c(0.5, 1.0, 0.1)
d &lt;- generateData(theta, noObservations=500, initialState=0.0) 

# Estimate the filtered state using Kalman filter
kfOutput &lt;- kalmanFilter(d$y, theta, 
                         initialState=0.0, initialStateCovariance=0.01)

# Plot the estimate and the true state
par(mfrow=c(3, 1))
plot(d$x, type="l", xlab="time", ylab="true state", bty="n", 
  col="#1B9E77")
plot(kfOutput$xHatFiltered, type="l", xlab="time", 
  ylab="Kalman filter estimate", bty="n", col="#D95F02")
plot(d$x-kfOutput$xHatFiltered, type="l", xlab="time", 
  ylab="difference", bty="n", col="#7570B3")
</code></pre>

<hr>
<h2 id='makePlotsParticleMetropolisHastingsSVModel'>Make plots for tutorial</h2><span id='topic+makePlotsParticleMetropolisHastingsSVModel'></span>

<h3>Description</h3>

<p>Creates diagnoistic plots from runs of the particle Metropolis-Hastings algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makePlotsParticleMetropolisHastingsSVModel(y, res, noBurnInIterations,
  noIterations, nPlot)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="makePlotsParticleMetropolisHastingsSVModel_+3A_y">y</code></td>
<td>
<p>Observations from the model for <code class="reqn">t=1,...,T</code>.</p>
</td></tr>
<tr><td><code id="makePlotsParticleMetropolisHastingsSVModel_+3A_res">res</code></td>
<td>
<p>The output from a run of particleMetropolisHastings,
particleMetropolisHastingsSVmodel or
particleMetropolisHastingsSVmodelReparameterised.</p>
</td></tr>
<tr><td><code id="makePlotsParticleMetropolisHastingsSVModel_+3A_noburniniterations">noBurnInIterations</code></td>
<td>
<p>The number of burn-in iterations in the 
PMH algorithm. Must be smaller than noIterations.</p>
</td></tr>
<tr><td><code id="makePlotsParticleMetropolisHastingsSVModel_+3A_noiterations">noIterations</code></td>
<td>
<p>The number of iterations in the PMH algorithm.</p>
</td></tr>
<tr><td><code id="makePlotsParticleMetropolisHastingsSVModel_+3A_nplot">nPlot</code></td>
<td>
<p>Number of steps in the Markov chain to plot.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns plots similar to the ones in the reference as
well as the estimate of the integrated autocorrelation time
for each parameter.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>

<hr>
<h2 id='particleFilter'>Fully-adapted particle filter for state estimate in a linear Gaussian state 
space model</h2><span id='topic+particleFilter'></span>

<h3>Description</h3>

<p>Estimates the filtered state and the log-likelihood for a linear Gaussian 
state space model of the form <code class="reqn"> x_{t} = \phi x_{t-1} + \sigma_v v_t </code> 
and <code class="reqn"> y_t = x_t + \sigma_e e_t </code>, where <code class="reqn">v_t</code> and <code class="reqn">e_t</code> denote 
independent standard Gaussian random variables, i.e.<code class="reqn">N(0,1)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>particleFilter(y, theta, noParticles, initialState)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="particleFilter_+3A_y">y</code></td>
<td>
<p>Observations from the model for <code class="reqn">t=1,...,T</code>.</p>
</td></tr>
<tr><td><code id="particleFilter_+3A_theta">theta</code></td>
<td>
<p>The parameters <code class="reqn">\theta=\{\phi,\sigma_v,\sigma_e\}</code> of the 
LGSS model. The parameter <code class="reqn">\phi</code> scales the current state in 
the state dynamics. The standard deviations of the state process noise
and the observation process noise are denoted <code class="reqn">\sigma_v</code> and 
<code class="reqn">\sigma_e</code>, respectively.</p>
</td></tr>
<tr><td><code id="particleFilter_+3A_noparticles">noParticles</code></td>
<td>
<p>The number of particles to use in the filter.</p>
</td></tr>
<tr><td><code id="particleFilter_+3A_initialstate">initialState</code></td>
<td>
<p>The initial state.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list with the elements:
</p>

<ul>
<li><p>xHatFiltered: The estimate of the filtered state at time <code class="reqn">t=1,...,T</code>.
</p>
</li>
<li><p>logLikelihood: The estimate of the log-likelihood.
</p>
</li>
<li><p>particles: The particle system at each time point.
</p>
</li>
<li><p>weights: The particle weights at each time point.
</p>
</li></ul>



<h3>Note</h3>

<p>See Section 3 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Generates 500 observations from a linear state space model with
# (phi, sigma_e, sigma_v) = (0.5, 1.0, 0.1) and zero initial state.
theta &lt;- c(0.5, 1.0, 0.1)
d &lt;- generateData(theta, noObservations=500, initialState=0.0) 

# Estimate the filtered state using a Particle filter
pfOutput &lt;- particleFilter(d$y, theta, noParticles = 50, 
  initialState=0.0)

# Plot the estimate and the true state
par(mfrow=c(3, 1))
plot(d$x[1:500], type="l", xlab="time", ylab="true state", bty="n", 
  col="#1B9E77")
plot(pfOutput$xHatFiltered, type="l", xlab="time", 
  ylab="paticle filter estimate", bty="n", col="#D95F02")
plot(d$x[1:500]-pfOutput$xHatFiltered, type="l", xlab="time", 
  ylab="difference", bty="n", col="#7570B3")
</code></pre>

<hr>
<h2 id='particleFilterSVmodel'>Bootstrap particle filter for state estimate in a simple stochastic 
volatility model</h2><span id='topic+particleFilterSVmodel'></span>

<h3>Description</h3>

<p>Estimates the filtered state and the log-likelihood for a stochastic 
volatility model of the form <code class="reqn">x_t = \mu + \phi ( x_{t-1} - \mu ) + 
\sigma_v v_t</code> and <code class="reqn">y_t = \exp(x_t/2) e_t</code>, where <code class="reqn">v_t</code> and <code class="reqn">e_t</code> 
denote independent standard Gaussian random variables, i.e. <code class="reqn">N(0,1)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>particleFilterSVmodel(y, theta, noParticles)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="particleFilterSVmodel_+3A_y">y</code></td>
<td>
<p>Observations from the model for <code class="reqn">t=1,...,T</code>.</p>
</td></tr>
<tr><td><code id="particleFilterSVmodel_+3A_theta">theta</code></td>
<td>
<p>The parameters <code class="reqn">\theta=\{\mu,\phi,\sigma_v\}</code>. 
The mean of the log-volatility process is denoted <code class="reqn">\mu</code>. 
The persistence of the log-volatility process is denoted <code class="reqn">\phi</code>. 
The standard deviation of the log-volatility process is 
denoted <code class="reqn">\sigma_v</code>.</p>
</td></tr>
<tr><td><code id="particleFilterSVmodel_+3A_noparticles">noParticles</code></td>
<td>
<p>The number of particles to use in the filter.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list with the elements:
</p>

<ul>
<li><p>xHatFiltered: The estimate of the filtered state at time <code class="reqn">t=1,...,T</code>.
</p>
</li>
<li><p>logLikelihood: The estimate of the log-likelihood.
</p>
</li></ul>



<h3>Note</h3>

<p>See Section 5 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
  # Get the data from Quandl
  library("Quandl")
  d &lt;- Quandl("NASDAQOMX/OMXS30", start_date="2012-01-02",
              end_date="2014-01-02", type="zoo")
  y &lt;- as.numeric(100 * diff(log(d$"Index Value")))

  # Estimate the filtered state using a particle filter
  theta &lt;- c(-0.10, 0.97, 0.15)
  pfOutput &lt;- particleFilterSVmodel(y, theta, noParticles=100)

  # Plot the estimate and the true state
  par(mfrow=c(2, 1))
  plot(y, type="l", xlab="time", ylab="log-returns", bty="n",
    col="#1B9E77")
  plot(pfOutput$xHatFiltered, type="l", xlab="time",
    ylab="estimate of log-volatility", bty="n", col="#D95F02")

## End(Not run)
</code></pre>

<hr>
<h2 id='particleMetropolisHastings'>Particle Metropolis-Hastings algorithm for a linear Gaussian state space 
model</h2><span id='topic+particleMetropolisHastings'></span>

<h3>Description</h3>

<p>Estimates the parameter posterior for <code class="reqn">phi</code> a linear Gaussian state 
space model of the form <code class="reqn"> x_{t} = \phi x_{t-1} + \sigma_v v_t </code> and 
<code class="reqn"> y_t = x_t + \sigma_e e_t </code>, where <code class="reqn">v_t</code> and <code class="reqn">e_t</code> denote 
independent standard Gaussian random variables, i.e.<code class="reqn">N(0,1)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>particleMetropolisHastings(y, initialPhi, sigmav, sigmae, noParticles,
  initialState, noIterations, stepSize)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="particleMetropolisHastings_+3A_y">y</code></td>
<td>
<p>Observations from the model for <code class="reqn">t=1,...,T</code>.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastings_+3A_initialphi">initialPhi</code></td>
<td>
<p>The mean of the log-volatility process <code class="reqn">\mu</code>.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastings_+3A_sigmav">sigmav</code></td>
<td>
<p>The standard deviation of the state process <code class="reqn">\sigma_v</code>.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastings_+3A_sigmae">sigmae</code></td>
<td>
<p>The standard deviation of the observation process 
<code class="reqn">\sigma_e</code>.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastings_+3A_noparticles">noParticles</code></td>
<td>
<p>The number of particles to use in the filter.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastings_+3A_initialstate">initialState</code></td>
<td>
<p>The inital state.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastings_+3A_noiterations">noIterations</code></td>
<td>
<p>The number of iterations in the PMH algorithm.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastings_+3A_stepsize">stepSize</code></td>
<td>
<p>The standard deviation of the Gaussian random walk proposal 
for <code class="reqn">\phi</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The trace of the Markov chain exploring the marginal posterior for 
<code class="reqn">\phi</code>.
</p>


<h3>Note</h3>

<p>See Section 4 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

  # Generates 100 observations from a linear state space model with
  # (phi, sigma_e, sigma_v) = (0.5, 1.0, 0.1) and zero initial state.
  theta &lt;- c(0.5, 1.0, 0.1)
  d &lt;- generateData(theta, noObservations=100, initialState=0.0) 

  # Estimate the marginal posterior for phi
  pmhOutput &lt;- particleMetropolisHastings(d$y,
    initialPhi=0.1, sigmav=1.0, sigmae=0.1, noParticles=50, 
    initialState=0.0, noIterations=1000, stepSize=0.10)

  # Plot the estimate
  nbins &lt;- floor(sqrt(1000))
  par(mfrow=c(1, 1))
  hist(pmhOutput, breaks=nbins, main="", xlab=expression(phi), 
    ylab="marginal posterior", freq=FALSE, col="#7570B3")

</code></pre>

<hr>
<h2 id='particleMetropolisHastingsSVmodel'>Particle Metropolis-Hastings algorithm for a stochastic volatility model
model</h2><span id='topic+particleMetropolisHastingsSVmodel'></span>

<h3>Description</h3>

<p>Estimates the parameter posterior for <code class="reqn">\theta=\{\mu,\phi,\sigma_v\}</code> in 
a stochastic volatility model of the form <code class="reqn">x_t = \mu + \phi ( x_{t-1} - 
\mu ) + \sigma_v v_t</code> and <code class="reqn">y_t = \exp(x_t/2) e_t</code>, where <code class="reqn">v_t</code> and 
<code class="reqn">e_t</code> denote independent standard Gaussian random variables, i.e. 
<code class="reqn">N(0,1)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>particleMetropolisHastingsSVmodel(y, initialTheta, noParticles,
  noIterations, stepSize)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="particleMetropolisHastingsSVmodel_+3A_y">y</code></td>
<td>
<p>Observations from the model for <code class="reqn">t=1,...,T</code>.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastingsSVmodel_+3A_initialtheta">initialTheta</code></td>
<td>
<p>An inital value for the parameters 
<code class="reqn">\theta=\{\mu,\phi,\sigma_v\}</code>. The mean of the log-volatility 
process is denoted <code class="reqn">\mu</code>. The persistence of the log-volatility 
process is denoted <code class="reqn">\phi</code>. The standard deviation of the 
log-volatility process is denoted <code class="reqn">\sigma_v</code>.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastingsSVmodel_+3A_noparticles">noParticles</code></td>
<td>
<p>The number of particles to use in the filter.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastingsSVmodel_+3A_noiterations">noIterations</code></td>
<td>
<p>The number of iterations in the PMH algorithm.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastingsSVmodel_+3A_stepsize">stepSize</code></td>
<td>
<p>The standard deviation of the Gaussian random walk proposal 
for <code class="reqn">\theta</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The trace of the Markov chain exploring the posterior of <code class="reqn">\theta</code>.
</p>


<h3>Note</h3>

<p>See Section 5 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
  # Get the data from Quandl
  library("Quandl")
  d &lt;- Quandl("NASDAQOMX/OMXS30", start_date="2012-01-02",
              end_date="2014-01-02", type="zoo")
  y &lt;- as.numeric(100 * diff(log(d$"Index Value")))

  # Estimate the marginal posterior for phi
  pmhOutput &lt;- particleMetropolisHastingsSVmodel(y,
    initialTheta = c(0, 0.9, 0.2),
    noParticles=500,
    noIterations=1000,
    stepSize=diag(c(0.05, 0.0002, 0.002)))

  # Plot the estimate
  nbins &lt;- floor(sqrt(1000))
  par(mfrow=c(3, 1))
  hist(pmhOutput$theta[,1], breaks=nbins, main="", xlab=expression(mu),
    ylab="marginal posterior", freq=FALSE, col="#7570B3")
  hist(pmhOutput$theta[,2], breaks=nbins, main="", xlab=expression(phi),
    ylab="marginal posterior", freq=FALSE, col="#E7298A")
  hist(pmhOutput$theta[,3], breaks=nbins, main="",
    xlab=expression(sigma[v]), ylab="marginal posterior",
    freq=FALSE, col="#66A61E")

## End(Not run)
</code></pre>

<hr>
<h2 id='particleMetropolisHastingsSVmodelReparameterised'>Particle Metropolis-Hastings algorithm for a stochastic volatility model
model</h2><span id='topic+particleMetropolisHastingsSVmodelReparameterised'></span>

<h3>Description</h3>

<p>Estimates the parameter posterior for <code class="reqn">\theta=\{\mu,\phi,\sigma_v\}</code> in 
a stochastic volatility model of the form <code class="reqn">x_t = \mu + \phi ( x_{t-1} - 
\mu ) + \sigma_v v_t</code> and <code class="reqn">y_t = \exp(x_t/2) e_t</code>, where <code class="reqn">v_t</code> and 
<code class="reqn">e_t</code> denote independent standard Gaussian random variables, i.e. 
<code class="reqn">N(0,1)</code>. In this version of the PMH, we reparameterise the model and 
run the Markov chain on the  parameters <code class="reqn">\vartheta=\{\mu,\psi,
\varsigma\}</code>, where <code class="reqn">\phi=\tanh(\psi)</code> and <code class="reqn">sigma_v=\exp(\varsigma)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>particleMetropolisHastingsSVmodelReparameterised(y, initialTheta,
  noParticles, noIterations, stepSize)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="particleMetropolisHastingsSVmodelReparameterised_+3A_y">y</code></td>
<td>
<p>Observations from the model for <code class="reqn">t=1,...,T</code>.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastingsSVmodelReparameterised_+3A_initialtheta">initialTheta</code></td>
<td>
<p>An inital value for the parameters 
<code class="reqn">\theta=\{\mu,\phi,\sigma_v\}</code>. The mean of the log-volatility 
process is denoted <code class="reqn">\mu</code>. The persistence of the log-volatility 
process is denoted <code class="reqn">\phi</code>. The standard deviation of the 
log-volatility process is denoted <code class="reqn">\sigma_v</code>.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastingsSVmodelReparameterised_+3A_noparticles">noParticles</code></td>
<td>
<p>The number of particles to use in the filter.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastingsSVmodelReparameterised_+3A_noiterations">noIterations</code></td>
<td>
<p>The number of iterations in the PMH algorithm.</p>
</td></tr>
<tr><td><code id="particleMetropolisHastingsSVmodelReparameterised_+3A_stepsize">stepSize</code></td>
<td>
<p>The standard deviation of the Gaussian random walk proposal 
for <code class="reqn">\theta</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The trace of the Markov chain exploring the posterior of <code class="reqn">\theta</code>.
</p>


<h3>Note</h3>

<p>See Section 5 in the reference for more details.
</p>


<h3>Author(s)</h3>

<p>Johan Dahlin <a href="mailto:uni@johandahlin.com">uni@johandahlin.com</a>
</p>


<h3>References</h3>

<p>Dahlin, J. &amp; Schon, T. B. &quot;Getting Started with Particle 
Metropolis-Hastings for Inference in Nonlinear Dynamical Models.&quot; 
Journal of Statistical Software, Code Snippets,
88(2): 1&ndash;41, 2019.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
  # Get the data from Quandl
  library("Quandl")
  d &lt;- Quandl("NASDAQOMX/OMXS30", start_date="2012-01-02",
              end_date="2014-01-02", type="zoo")
  y &lt;- as.numeric(100 * diff(log(d$"Index Value")))

  # Estimate the marginal posterior for phi
  pmhOutput &lt;- particleMetropolisHastingsSVmodelReparameterised(
    y, initialTheta = c(0, 0.9, 0.2), noParticles=500,
    noIterations=1000, stepSize=diag(c(0.05, 0.0002, 0.002)))

  # Plot the estimate
  nbins &lt;- floor(sqrt(1000))
  par(mfrow=c(3, 1))
  hist(pmhOutput$theta[,1], breaks=nbins, main="", xlab=expression(mu),
    ylab="marginal posterior", freq=FALSE, col="#7570B3")
  hist(pmhOutput$theta[,2], breaks=nbins, main="", xlab=expression(phi),
    ylab="marginal posterior", freq=FALSE, col="#E7298A")
  hist(pmhOutput$theta[,3], breaks=nbins, main="",
    xlab=expression(sigma[v]), ylab="marginal posterior",
    freq=FALSE, col="#66A61E")

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
