<!DOCTYPE html><html lang="en"><head><title>Help for package autoRasch</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {autoRasch}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#autoRasch'><p>autoRasch: A package for semi-automatic Rasch analysis</p></a></li>
<li><a href='#autoRaschOptions'><p>autoRasch Optimization Parameters Setting</p></a></li>
<li><a href='#check.unidim'><p>Unidimensionality Check</p></a></li>
<li><a href='#checkRel'><p>Compute Reliability and Standard Error</p></a></li>
<li><a href='#compute_score'><p>Compute the In-plus-out-of-questionnaire log likelihood (with DIF) (IPOQ-LL(-DIF))</p></a></li>
<li><a href='#correl02_multidim'><p>Multidimensional polytomous data set with 0.2 correlation</p></a></li>
<li><a href='#correl03_multidim'><p>Multidimensional polytomous data set with 0.3 correlation</p></a></li>
<li><a href='#correl04_multidim'><p>Multidimensional polytomous data set with 0.4 Correlation</p></a></li>
<li><a href='#correl05_multidim'><p>Multidimensional polytomous data set with 0.5 Correlation</p></a></li>
<li><a href='#correl06_multidim'><p>Multidimensional polytomous data set with 0.6 Correlation</p></a></li>
<li><a href='#createGroup'><p>Create Mapping Matrix of DIF Groups</p></a></li>
<li><a href='#dataset'><p>The Simulated Dataset</p></a></li>
<li><a href='#dicho_inh_dset'><p>Inhomogenous Dichotomous Data Set</p></a></li>
<li><a href='#dicho_md_dset'><p>Uncorrelated Multidimensional Dichotomous Data Set</p></a></li>
<li><a href='#fitStats'><p>Fit statistics</p></a></li>
<li><a href='#generate_data'><p>Generate the artificial dataset</p></a></li>
<li><a href='#generic_model'><p>Estimation of the generic form of the models</p></a></li>
<li><a href='#gpcm'><p>Estimation of The Generalized Partial Credit Model</p></a></li>
<li><a href='#gpcm_dif'><p>Estimation of The Generalized Partial Credit Model with DIF</p></a></li>
<li><a href='#pcm'><p>Estimation of The Partial Credit Model (PCM)</p></a></li>
<li><a href='#pcm_dif'><p>Estimation of The Partial Credit Model with DIF</p></a></li>
<li><a href='#plot_EVC'><p>Plot The Expected Value Curves</p></a></li>
<li><a href='#plot_ICC'><p>Plot The Item Characteristic Curves</p></a></li>
<li><a href='#plot_PImap'><p>Plot The Person-Item Map</p></a></li>
<li><a href='#poly_inh_dset'><p>The Inhomogenous Polytomous Dataset</p></a></li>
<li><a href='#poly_md_dset'><p>Uncorrelated Multidimensional Polytomous Data Set</p></a></li>
<li><a href='#polydif_inh_dset'><p>The Inhomogenous Polytomous Dataset containing DIF items</p></a></li>
<li><a href='#residCor'><p>Residual Correlation</p></a></li>
<li><a href='#short_poly_data'><p>A Shorter Inhomogenous Polytomous Dataset</p></a></li>
<li><a href='#shortDIF'><p>A Shorter Polytomous Dataset with DIF</p></a></li>
<li><a href='#stepwise_search'><p>Stepwise Selection Search</p></a></li>
<li><a href='#testlets_dataset'><p>Multi-testlets Polytomous Data Set</p></a></li>
<li><a href='#withinItem_multidim'><p>Within-item Multidimensional Polytomous Data Set</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>0.2.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-10-19</td>
</tr>
<tr>
<td>Title:</td>
<td>Semi-Automated Rasch Analysis</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs Rasch analysis (semi-)automatically, which has been shown to be comparable with the standard Rasch analysis (Feri Wijayanto et al. (2021) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12218">doi:10.1111/bmsp.12218</a>&gt;, Feri Wijayanto et al. (2022) &lt;<a href="https://doi.org/10.3758%2Fs13428-022-01947-9">doi:10.3758/s13428-022-01947-9</a>&gt;, Feri Wijayanto et al. (2022) &lt;<a href="https://doi.org/10.1177%2F01466216221125178">doi:10.1177/01466216221125178</a>&gt;).</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>doParallel, foreach, Rcpp, lavaan</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat (&ge; 3.0.0), knitr, rmarkdown, markdown</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>RcppArmadillo, Rcpp</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-19 15:26:07 UTC; F.Wijayanto</td>
</tr>
<tr>
<td>Author:</td>
<td>Feri Wijayanto [aut, cre],
  Ioan Gabriel Bucur [aut],
  Perry Groot [aut],
  Tom Heskes [aut],
  Karlien Mul [ctb],
  Baziel G.M. van Engelen [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Feri Wijayanto &lt;f.wijayanto@cs.ru.nl&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-19 16:15:08 UTC</td>
</tr>
</table>
<hr>
<h2 id='autoRasch'>autoRasch: A package for semi-automatic Rasch analysis</h2><span id='topic+autoRasch'></span>

<h3>Description</h3>

<p>This package helps user to do Rasch analysis
(semi-)automatically which is comparable to the standard Rasch analysis using
common statistics.
</p>

<hr>
<h2 id='autoRaschOptions'>autoRasch Optimization Parameters Setting</h2><span id='topic+autoRaschOptions'></span>

<h3>Description</h3>

<p>Returns and updates the default settings used by the functions in <strong>autoRasch</strong> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autoRaschOptions(x = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="autoRaschOptions_+3A_x">x</code></td>
<td>
<p>A name of single parameter setting that is wanted to be shown. <code>NULL</code> means returns all parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>cd_control</code> lists the parameters used to control the coordinate descent optimization procedure. The paramaters are:
</p>

<ul>
<li><p><code>init.step</code>   Initial value of the delta parameters updating step. The default is <code>1</code>.
</p>
</li>
<li><p><code>scale.down</code>   A constant value to scale down the updating step. The default is <code>0.5</code>.
</p>
</li>
<li><p><code>maxit.cd.higher</code>   Maximum iteration in the higher level coordinate descent. The default is <code>500</code>.
</p>
</li>
<li><p><code>maxit.cd.lower</code>   Maximum iteration for every coordinate optimization in the lower level coordinate descent. The default is <code>500</code>.
</p>
</li>
<li><p><code>abs.tol</code>   The convergence tolerance. The algorithm stops if it is unable to reduce the negative log likelihood value by the given tolerance. The default is <code>1e-12</code>.
</p>
</li>
<li><p><code>max.dif.par</code>   The convergence tolerance. The algorithm stops if it is unable to update all of the parameters' value by the given tolerance. The default is <code>1e-8</code>.
</p>
</li></ul>



<h3>Value</h3>

<table role = "presentation">
<tr><td><code>fixed_par</code></td>
<td>
<p>   A vector of names of the parameter types that are set to be fixed. It means that these parameters are not going to be estimated.</p>
</td></tr>
<tr><td><code>fixed_theta</code></td>
<td>
<p>   A vector of <code>theta</code> values when <code>theta</code> are listed in the <code>fixed_par</code>. If it is not set, it will be set to zero.</p>
</td></tr>
<tr><td><code>fixed_beta</code></td>
<td>
<p>   A vector of <code>beta</code> values when <code>beta</code> are listed in the <code>fixed_par</code>. If it is not set, it will be set to zero.</p>
</td></tr>
<tr><td><code>fixed_gamma</code></td>
<td>
<p>   A vector of <code>gamma</code> (natural logarithm of discrimination parameters, <code class="reqn">\alpha = exp(\gamma)</code>) values when <code>gamma</code> are listed in the <code>fixed_par</code>. If it is not set, it will be set to zero.</p>
</td></tr>
<tr><td><code>fixed_delta</code></td>
<td>
<p>   A vector of <code>delta</code> values when <code>delta</code> are listed in the <code>fixed_par</code>. If it is not set, it will be set to zero.</p>
</td></tr>
<tr><td><code>isPenalized_theta</code></td>
<td>
<p>   It is a logical parameter whether, in the estimation procedure, <code>theta</code> is penalized or not.</p>
</td></tr>
<tr><td><code>isPenalized_gamma</code></td>
<td>
<p>   It is a logical parameter whether, in the estimation procedure, <code>gamma</code> is penalized or not.</p>
</td></tr>
<tr><td><code>isPenalized_delta</code></td>
<td>
<p>   It is a logical parameter whether, in the estimation procedure, <code>delta</code> is penalized or not.</p>
</td></tr>
<tr><td><code>groups_map</code></td>
<td>
<p>   A matrix <code class="reqn">n x f</code> to map the subject into DIF groups, where <code class="reqn">n</code> is number of subjects and <code class="reqn">f</code> is number of focal groups.</p>
</td></tr>
<tr><td><code>optz_method</code></td>
<td>
<p>    Options of the optimization method used. The default is <code>optim</code> which implies on applying the PJMLE which is implemented using <code>optim()</code>.
When it is set to <code>mixed</code> means that it applies the coordinate descent.</p>
</td></tr>
<tr><td><code>optim_control</code></td>
<td>
<p>   A list of setting parameters of the <code>optim()</code>. For complete settings can be seen in <code><a href="stats.html#topic+optim">stats::optim()</a></code>.</p>
</td></tr>
<tr><td><code>lambda_theta</code></td>
<td>
<p>   The regularization parameter to the <code>theta</code>. The default value is <code>0.05</code></p>
</td></tr>
<tr><td><code>lambda_in</code></td>
<td>
<p>   The regularization parameter to the <code>gamma</code> in the included itemset. The default value is <code>50</code>.</p>
</td></tr>
<tr><td><code>lambda_out</code></td>
<td>
<p>   The regularization parameter to the <code>gamma</code> in the excluded itemset. The default value is <code>1</code>.</p>
</td></tr>
<tr><td><code>lambda_delta</code></td>
<td>
<p>   The regularization parameter to the <code>delta</code>. The default value is <code>10</code>.</p>
</td></tr>
<tr><td><code>randomized</code></td>
<td>
<p>    A logical parameter whether the initial values of the estimated parameters are randomized or not.</p>
</td></tr>
<tr><td><code>random.init.th</code></td>
<td>
<p>   A threshold value to limit the range of the initial values. The default value is <code>1e-2</code>, means that the initial values range between <code>[-0.01,0.01]</code></p>
</td></tr>
<tr><td><code>isHessian</code></td>
<td>
<p>   A logical parameter whether, in the estimation procedure, need to return the Hessian matrix or not. The default value is <code>TRUE</code>, which means the Hessian matrix will be computed.</p>
</td></tr>
<tr><td><code>cd_control</code></td>
<td>
<p>   A list of coordinate descent optimization setting.</p>
</td></tr>
<tr><td><code>mode</code></td>
<td>
<p>   An option setting to use &quot;DIF&quot; or &quot;DSF&quot; mode.</p>
</td></tr>
<tr><td><code>isTraced</code></td>
<td>
<p>   A logical value whether the progress need to be tracked or not.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>### To show the default values
autoRaschOptions()
autoRaschOptions(x = "isHessian")

### To change the default values
adj_setting &lt;- autoRaschOptions()
adj_setting$isHessian &lt;- TRUE
pcm_res &lt;- pcm(shortDIF, setting = adj_setting)

</code></pre>

<hr>
<h2 id='check.unidim'>Unidimensionality Check</h2><span id='topic+check.unidim'></span>

<h3>Description</h3>

<p>This function checks the unidimensionality status using the confirmatory factor analysis.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>check.unidim(x, is.polychor = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="check.unidim_+3A_x">x</code></td>
<td>
<p>The dataset of responses.</p>
</td></tr>
<tr><td><code id="check.unidim_+3A_is.polychor">is.polychor</code></td>
<td>
<p>A boolean parameter to set whether the dataset is categorical or not.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list of the CFA output and the some of the goodness-of-fit indices (i.e., cfi, tli, rmsea, and srmr)
</p>

<hr>
<h2 id='checkRel'>Compute Reliability and Standard Error</h2><span id='topic+checkRel'></span><span id='topic+summary.seprel'></span>

<h3>Description</h3>

<p>This function computes the reliability index, separation and the standard error of the models estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>checkRel(obj)

## S3 method for class 'seprel'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="checkRel_+3A_obj">obj</code></td>
<td>
<p>Object that resulted from any models estimation, e.g., <code>pcm</code>, <code>gpcm</code>, <code>pcmdif</code>, and <code>gpcmdif</code>.</p>
</td></tr>
<tr><td><code id="checkRel_+3A_object">object</code></td>
<td>
<p>The object of class <code>'seprel'</code>.</p>
</td></tr>
<tr><td><code id="checkRel_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Person reliability index
</p>


<h3>Value</h3>

<p>A list of two objects, the reliability and the standard error.
</p>
<p><em>reliability</em>
</p>

<ul>
<li><p>PRI   Person reliability index.
</p>
</li>
<li><p>PSR   Person separation reliability.
</p>
</li>
<li><p>IRI   Item reliability index.
</p>
</li>
<li><p>ISR   Item separation reliability.
</p>
</li></ul>

<p><em>stdError</em>
</p>

<ul>
<li><p>var_err_pers   A matrix of variance error of the estimation.
</p>
</li>
<li><p>std_err_pers   A matrix of standard error of the estimation.
</p>
</li>
<li><p>rmsse_pers   Root mean square of the standard error per person.
</p>
</li>
<li><p>var_err_item   A matrix of variance error of the estimation.
</p>
</li>
<li><p>std_err_item   A matrix of standard error of the estimation.
</p>
</li>
<li><p>rmsse_item   Root mean square of the standard error per person.
</p>
</li>
<li><p>hessian_theta   Hessian matrix of <code>theta</code> parameter.
</p>
</li>
<li><p>hessian_beta   Hessian matrix of <code>beta</code> parameter.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>pcmObject &lt;- pcm(shortDIF)
rel &lt;- checkRel(pcmObject)
summary(rel)

</code></pre>

<hr>
<h2 id='compute_score'>Compute the In-plus-out-of-questionnaire log likelihood (with DIF) (IPOQ-LL(-DIF))</h2><span id='topic+compute_score'></span><span id='topic+compute_scores'></span><span id='topic+summary.score'></span>

<h3>Description</h3>

<p><code>compute_score</code> computes the the IPOQ-LL/IPOQ-LL-DIF score of an instrument (included set) of the given initial survey.
While <code>compute_scores</code> computes the IPOQ-LL/IPOQ-LL-DIF score of many (more than one) instruments (included sets) of
the given initial survey simultanously.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_score(
  X,
  incl_set,
  type = c("ipoqll", "ipoqlldif"),
  groups_map = c(),
  init_par_iq = c(),
  init_par_oq = c(),
  setting_par_iq = c(),
  setting_par_oq = c(),
  method = c("fast", "novel")
)

compute_scores(
  X,
  incl_sets,
  type = c("ipoqll", "ipoqlldif"),
  step_direct = c("fixed", "forward", "backward"),
  groups_map = c(),
  init_par_iq = c(),
  init_par_oq = c(),
  setting_par_iq = c(),
  setting_par_oq = c(),
  cores = NULL,
  method = c("fast", "novel"),
  timeLimit = 3600
)

## S3 method for class 'score'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compute_score_+3A_x">X</code></td>
<td>
<p>A matrix or data.frame of the observed responses (ordinal or binary response).</p>
</td></tr>
<tr><td><code id="compute_score_+3A_incl_set">incl_set</code></td>
<td>
<p>A vector of the items (columns) number in the data.frame X that are included in the included set.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_type">type</code></td>
<td>
<p>The type of the score. <code>ipoqll</code> if we ignore the presence of the DIF and <code>ipoqlldif</code> if we want to consider the DIF effect.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_groups_map">groups_map</code></td>
<td>
<p>Matrix to map the respondents to the DIF groups.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_init_par_iq">init_par_iq</code></td>
<td>
<p>Initial values of the parameters in the included set before the estimation begin.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_init_par_oq">init_par_oq</code></td>
<td>
<p>Initial values of the parameters in the excluded set before the estimation begin.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_setting_par_iq">setting_par_iq</code></td>
<td>
<p>The coordinate descent optimisation setting of the included set. See <code><a href="#topic+autoRaschOptions">autoRasch::autoRaschOptions()</a></code> <code>cd_control</code> parameter.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_setting_par_oq">setting_par_oq</code></td>
<td>
<p>The coordinate descent optimisation setting of the excluded set. See <code><a href="#topic+autoRaschOptions">autoRasch::autoRaschOptions()</a></code> <code>cd_control</code> parameter.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_method">method</code></td>
<td>
<p>The implementation option of log likelihood function. <code>fast</code> using a <code>c++</code> implementation and <code>novel</code> using an <code>R</code> implementation.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_incl_sets">incl_sets</code></td>
<td>
<p>A matrix as a results of a <code>rbind</code> of <code>incl_set</code>.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_step_direct">step_direct</code></td>
<td>
<p>How will you compute the criterion score. <code>fixed</code> for the given itemset,
<code>forward</code> computes all the scores of the possible combination of items if an item is added to the given set,
<code>backward</code>  computes all the scores of the possible combination of items if an item is removed to the given set.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_cores">cores</code></td>
<td>
<p>Number of cores that is used in the paralellization.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_timelimit">timeLimit</code></td>
<td>
<p>To limit the execution time of scores' computation.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_object">object</code></td>
<td>
<p>The object from the class <code>score</code>. The result of the score computation.</p>
</td></tr>
<tr><td><code id="compute_score_+3A_...">...</code></td>
<td>
<p>further argument passed or from other method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>compute_score</code> will return a vector which contains in-questionnaire log likelihood (IQ-LL(-DIF)), out-of-questionnaire log likelihood(OQ-LL(-DIF)),
IPOQ-LL(-DIF), included set's items' number in the given initial survey, the estimated theta parameters, the estimated items' parameters in the included set,
and the estimated items' parameters in the excluded set, sequentially.
</p>
<p><code>compute_scores</code> will return a matrix as a result of the <code>rbind</code> operation of the <code>compute_score</code>'s result.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>ipoqll_score &lt;- compute_score(shortDIF,incl_set = c(1:3),type = "ipoqll")
summary(ipoqll_score)

## Not run: 
ipoqll_scores &lt;- compute_scores(shortDIF,incl_set = rbind(c(1:3),c(2:4)),
                                type = "ipoqll", cores = 2)
View(ipoqll_scores)

## End(Not run)

</code></pre>

<hr>
<h2 id='correl02_multidim'>Multidimensional polytomous data set with 0.2 correlation</h2><span id='topic+correl02_multidim'></span>

<h3>Description</h3>

<p>Multidimensional polytomous data set with 0.2 correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(correl02_multidim)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 12 columns.
</p>

<hr>
<h2 id='correl03_multidim'>Multidimensional polytomous data set with 0.3 correlation</h2><span id='topic+correl03_multidim'></span>

<h3>Description</h3>

<p>Multidimensional polytomous data set with 0.3 correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(correl03_multidim)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 12 columns.
</p>

<hr>
<h2 id='correl04_multidim'>Multidimensional polytomous data set with 0.4 Correlation</h2><span id='topic+correl04_multidim'></span>

<h3>Description</h3>

<p>Multidimensional polytomous data set with 0.4 Correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(correl04_multidim)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 12 columns.
</p>

<hr>
<h2 id='correl05_multidim'>Multidimensional polytomous data set with 0.5 Correlation</h2><span id='topic+correl05_multidim'></span>

<h3>Description</h3>

<p>Multidimensional polytomous data set with 0.5 Correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(correl05_multidim)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 12 columns.
</p>

<hr>
<h2 id='correl06_multidim'>Multidimensional polytomous data set with 0.6 Correlation</h2><span id='topic+correl06_multidim'></span>

<h3>Description</h3>

<p>Multidimensional polytomous data set with 0.6 Correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(correl06_multidim)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 12 columns.
</p>

<hr>
<h2 id='createGroup'>Create Mapping Matrix of DIF Groups</h2><span id='topic+createGroup'></span>

<h3>Description</h3>

<p>This function automatically create a mapping matrix based on the existing DIF inducing covariates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createGroup(backInfo, idxUsed = NULL, contMethod = c("mean", "median"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="createGroup_+3A_backinfo">backInfo</code></td>
<td>
<p>A matrix of person background information (e.g., gender, country, age, etc);</p>
</td></tr>
<tr><td><code id="createGroup_+3A_idxused">idxUsed</code></td>
<td>
<p>The column number of <code>backInfo</code> that is used for creating the mapping matrix.</p>
</td></tr>
<tr><td><code id="createGroup_+3A_contmethod">contMethod</code></td>
<td>
<p>The method of how to handle a continuous variable (e.g., mean, median). This parameter is passing a function used to split the variable into binary. The default is <code>mean</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A binary matrix that maps respondents to the groups that the respondents belongs to.
</p>

<hr>
<h2 id='dataset'>The Simulated Dataset</h2><span id='topic+dataset'></span>

<h3>Description</h3>

<p>The artificial datasets used for simulation on various cases. The datasets consist of:
</p>

<ul>
<li> <p><code>inhomogenous_rasch_dataset</code>
</p>
</li>
<li> <p><code>inhomogenous_dataset</code>
</p>
</li>
<li> <p><code>uncorrel_rasch_multidim</code>
</p>
</li>
<li> <p><code>uncorrel_multidim</code>
</p>
</li>
<li> <p><code>correl02_multidim</code>
</p>
</li>
<li> <p><code>correl03_multidim</code>
</p>
</li>
<li> <p><code>correl04_multidim</code>
</p>
</li>
<li> <p><code>correl05_multidim</code>
</p>
</li>
<li> <p><code>correl06_multidim</code>
</p>
</li>
<li> <p><code>withinItem_multidim</code>
</p>
</li>
<li> <p><code>testlets_dataset</code>
</p>
</li></ul>



<h3>Details</h3>

<p><code>inhomogenous_rasch_dataset</code> is an artificial dataset of dichotomous responses which simulates three subscales with different predictability level (discrimination parameters). This dataset is generated by
</p>
<p><code>inhomogenous_rasch_dataset &lt;- generate_data(responseType = "discriminate", ncat = 2, alpha = c(0.04,0.045,0.05,0.055,0.06,0.065,0.2,0.25,0.3,0.35,0.4,0.45,2.6,2.65,2.7,2.75,2.8,2.85,2.9))</code>
</p>
<p><code>inhomogenous_dataset</code> is an artificial dataset which simulates three subscales with different predictability level (discrimination parameters). This dataset is generated by
</p>
<p><code>inhomogenous_dataset &lt;- generate_data(responseType = "discriminate", alpha = c(0.04,0.045,0.05,0.055,0.06,0.065,0.2,0.25,0.3,0.35,0.4,0.45,2.6,2.65,2.7,2.75,2.8,2.85,2.9))</code>
</p>
<p><code>uncorrel_rasch_multidim</code> is an artificial dataset of dichotomous responses which simulates three uncorrelated subscales from different dimensions. This dataset is generated by
</p>
<p><code>uncorrel_rasch_multidim &lt;- generate_data(responseType = "multidim.nocorrel", ncat = 2)</code>
</p>
<p><code>uncorrel_multidim</code> is an artificial dataset which simulates three uncorrelated subscales from different dimensions. This dataset is generated by
</p>
<p><code>uncorrel_multidim &lt;- generate_data(responseType = "multidim.nocorrel")</code>
</p>
<p><code>correl02_multidim</code> is an artificial dataset which simulates two subscales from different dimensions that having correlation of 0.2. This dataset is generated by
</p>
<p><code>correl02_multidim &lt;- generate_data(responseType = "multidim.withcorrel", corLevel = 0.2)</code>
</p>
<p>Similarly, <code>correl03_multidim</code>, <code>correl04_multidim</code>, <code>correl05_multidim</code>, and <code>correl06_multidim</code> are artificial datasets which consist of two correlated subscales with correlation of 0.3, 0.4, 0.5, and 0.6, respectively.
</p>
<p><code>withinItem_multidim</code> is an artificial dataset which consist of three subscales (dimensions) with some of items relate to more than one subscale (dimension). This dataset is generated by
</p>
<p><code>withinItem_multidim &lt;- generate_data(responseType = "multidim.within", ndim = 3, dim.members = list(c(1:6,13),c(3,7:12),c(5,13:18)))</code>
</p>
<p><code>testlets_dataset</code> is an artificial dataset which consist of two subscales with some of items relate to more than one subscale (dimension). This dataset is generated by
</p>
<p><code>testlets_dataset &lt;- generate_data(responseType = "testlets", ndim = 2, sdlambda = c(0,4))</code>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcm">pcm</a></code>, <code><a href="#topic+pcm_dif">pcm_dif</a></code>, <code><a href="#topic+gpcm">gpcm</a></code>, <code><a href="#topic+gpcm_dif">gpcm_dif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  #res &lt;- pcm(poly_inh_dset)
  #res
  #summary(res)

  #pcmdif_res &lt;- pcm_dif(polydif_inh_dset, groups_map = c(rep(1,245),rep(0,245)))
  #fit_res &lt;- fitStats(pcmdif_res)
  #summary(fit_res)
  #plot(fit_res, plotx = "gamma", ploty = "outfit")

</code></pre>

<hr>
<h2 id='dicho_inh_dset'>Inhomogenous Dichotomous Data Set</h2><span id='topic+dicho_inh_dset'></span>

<h3>Description</h3>

<p>Data set with binary type responses containing three subsets
with different discrimination values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dicho_inh_dset)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 18 columns.
</p>

<hr>
<h2 id='dicho_md_dset'>Uncorrelated Multidimensional Dichotomous Data Set</h2><span id='topic+dicho_md_dset'></span>

<h3>Description</h3>

<p>Data set with binary type responses containing three subsets which
represent different uncorrelated dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dicho_md_dset)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 18 columns.
</p>

<hr>
<h2 id='fitStats'>Fit statistics</h2><span id='topic+fitStats'></span><span id='topic+summary.fit'></span><span id='topic+itemfit'></span><span id='topic+personfit'></span><span id='topic+plot_fitStats'></span>

<h3>Description</h3>

<p>The goodness-of-fit statistics of Rasch analysis for items and persons. It consists of Outfit (Unweighted) Mean Square,
Infit (Weighted) Mean Square, Outfit ZSTD (Standardized Unweighted Mean Square), and Outfit ZSTD (Standardized Weighted Mean Square)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fitStats(obj, isAlpha = TRUE)

## S3 method for class 'fit'
summary(object, ...)

itemfit(objFit)

personfit(objFit)

plot_fitStats(objFit, toPlot = c("alpha", "infit"), useName = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fitStats_+3A_obj">obj</code></td>
<td>
<p>The object of class <code>'pcm'</code> or <code>'pcmdif'</code>.</p>
</td></tr>
<tr><td><code id="fitStats_+3A_isalpha">isAlpha</code></td>
<td>
<p>Boolean value that indicates whether the discrimination parameters is needed to be estimated or not.
The discrimination parameters are estimated using the corresponding models (GPCM or GPCM-DIF).</p>
</td></tr>
<tr><td><code id="fitStats_+3A_object">object</code></td>
<td>
<p>The object of class <code>'fit'</code>.</p>
</td></tr>
<tr><td><code id="fitStats_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
<tr><td><code id="fitStats_+3A_objfit">objFit</code></td>
<td>
<p>The object of class <code>'fit'</code>.</p>
</td></tr>
<tr><td><code id="fitStats_+3A_toplot">toPlot</code></td>
<td>
<p>An array with length two <code>c(x,y)</code>, to choose what to plot. There are five options to plot, which are alpha, outfit, infit, outfitz, and infitz</p>
</td></tr>
<tr><td><code id="fitStats_+3A_usename">useName</code></td>
<td>
<p>A logical statement whether the name of the variable are going to be used in the plot instead of the variable order.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><strong><code>fitStats()</code> will return a <code><a href="base.html#topic+list">list</a></code> which contains:</strong>
</p>
<table role = "presentation">
<tr><td><code>alpha</code></td>
<td>
<p>   A vector of estimated discrimination parameters for each items.</p>
</td></tr>
</table>
<p><em>i.fit</em>   Item fit statistics.
</p>

<ul>
<li><p>i.outfitMSQ   A vector of Outfit mean square values for each items.
</p>
</li>
<li><p>i.infitMSQ   A vector of Infit mean square values for each items.
</p>
</li>
<li><p>i.outfitZ   A vector of OutfitZ values for each items.
</p>
</li>
<li><p>i.infitZ   A vector of InfitZ values for each items.
</p>
</li></ul>

<p><em>p.fit</em>   Person fit statistics.
</p>

<ul>
<li><p>p.outfitMSQ   A vector of Outfit mean square values for each persons.
</p>
</li>
<li><p>p.infitMSQ   A vector of Infit mean square values for each persons.
</p>
</li>
<li><p>p.outfitZ   A vector of OutfitZ values for each persons.
</p>
</li>
<li><p>p.infitZ   A vector of InfitZ values for each persons.
</p>
</li></ul>

<p><em>traceMat</em>   Some computed matrices in the process. Only if <code>isTraced = TRUE</code>
</p>

<ul>
<li><p>emat   The expected values matrix.
</p>
</li>
<li><p>vmat   The variance matrix.
</p>
</li>
<li><p>cmat   The curtosis matrix.
</p>
</li>
<li><p>std.res   The standardized residual.
</p>
</li></ul>


<hr>
<h2 id='generate_data'>Generate the artificial dataset</h2><span id='topic+generate_data'></span>

<h3>Description</h3>

<p>This function generates simulated datasets with different attributes
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_data(
  responseType = "multidim.nocorrel",
  theta = c(-3, 3),
  sdtheta = 6,
  ntheta = 301,
  beta = c(-2.5, 2.5),
  sdbeta = 4,
  nitem = 6,
  alpha = c(1),
  sdlambda = 1,
  ncat = 5,
  thGap = 0.8,
  ndim = 3,
  randtype = "uniform",
  corLevel = 0,
  dim.members = c(),
  seed = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generate_data_+3A_responsetype">responseType</code></td>
<td>
<p>The type of the dataset. The types include <code>multidim.nocorrel</code>, <code>multidim.withcorrel</code>, <code>discriminate</code>, <code>multidim.within</code>, and <code>testlets</code>.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_theta">theta</code></td>
<td>
<p>A vector of the ability parameters range value, <code>c(min.theta,max.theta)</code>. It applies when the <code>randtype = "uniform"</code>.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_sdtheta">sdtheta</code></td>
<td>
<p>Standard deviation which is used to generate theta values using <code><a href="stats.html#topic+Normal">stats::rnorm()</a></code> with <code>n = ntheta</code>, <code>mean = 0</code>, and <code>sd = sdtheta</code>.It applies when the <code>randtype = "normal"</code>.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_ntheta">ntheta</code></td>
<td>
<p>The number of the observations.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_beta">beta</code></td>
<td>
<p>A vector of the item difficulty parameters range value, <code>c(min.beta,max.beta)</code>. It applies when the <code>randtype = "uniform"</code>.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_sdbeta">sdbeta</code></td>
<td>
<p>Standard deviation which is used to generate item location values using <code><a href="stats.html#topic+Normal">stats::rnorm()</a></code> with <code>n = nitem</code>, <code>mean = 0</code>, and <code>sd = sdbeta</code>.It applies when the <code>randtype = "normal"</code>.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_nitem">nitem</code></td>
<td>
<p>The number of the items in each subgroup.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_alpha">alpha</code></td>
<td>
<p>A vector of the discrimination parameters apply to each items.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_sdlambda">sdlambda</code></td>
<td>
<p>A vector of the standard deviation to simulate the testlet (local dependency) effect. The effect is added using <code><a href="stats.html#topic+Normal">stats::rnorm()</a></code> with <code>n = ntheta</code>, <code>mean = 0</code>, and <code>sd = sdlambda</code></p>
</td></tr>
<tr><td><code id="generate_data_+3A_ncat">ncat</code></td>
<td>
<p>The number of the response categories</p>
</td></tr>
<tr><td><code id="generate_data_+3A_thgap">thGap</code></td>
<td>
<p>The difference between adjacent threshold.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_ndim">ndim</code></td>
<td>
<p>The number of subgroups (dimensions/testlets) created.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_randtype">randtype</code></td>
<td>
<p>The randomize type. This includes <code>uniform</code> and <code>normal</code>.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_corlevel">corLevel</code></td>
<td>
<p>The correlation between the two dimensions.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_dim.members">dim.members</code></td>
<td>
<p>The list of item members in each dimension.</p>
</td></tr>
<tr><td><code id="generate_data_+3A_seed">seed</code></td>
<td>
<p>Integer seed for reproducibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The generated dataset as a <code>data.frame</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># 1. Multidimensional Polytomous Dataset with 0.2 Correlation
# Generate multidimensional dataset which having correlation of 0.2 between the dimensions
correl02_multidim &lt;- generate_data(
  responseType = "multidim.withcorrel", corLevel = 0.2, seed = 2021
)

# 2.  Within-item Multidimensional Polytomous Dataset
# Generate multidimensional dataset with some items relate to more than one
# dimension.
withinItem_multidim &lt;- generate_data(
  responseType = "multidim.within", ndim = 3,
  dim.members = list(c(1:6,13),c(3,7:12),c(5,13:18)), seed = 2021
)

# 3. Multi-testlets Polytomous Dataset
# Generate dataset which consist of two bundle items with different level of
# local dependency effect.
testlets_dataset &lt;- generate_data(
  responseType = "testlets", ndim = 2, sdlambda = c(0,4), seed = 2021
)

# 4a. Inhomogenous Dichotomous Dataset
# Generate dataset with binary type responses containing three subsets
# with different discrimination values.

dicho_inh_dset &lt;- generate_data(
  responseType = "discriminate", ncat = 2, seed = 2021,
  alpha = c(0.04,0.045,0.05,0.055,0.06,0.065,0.2,0.25,0.3,0.35,0.4,0.45,
            2.6,2.65,2.7,2.75,2.8,2.85)
)

# 4b. Inhomogenous Polytomous Dataset
# Generate dataset with polytomous responses (five categories) containing
# three subsets with different discrimination values.

poly_inh_dset &lt;- generate_data(
  responseType = "discriminate", ncat = 5, seed = 2021,
  alpha = c(0.04,0.045,0.05,0.055,0.06,0.065,0.2,0.25,0.3,0.35,0.4,0.45,
            2.6,2.65,2.7,2.75,2.8,2.85)
)

# 4c. Shorter Inhomogenous Polytomous Dataset
short_poly_data &lt;- generate_data(
  alpha = c(0.02,0.5,2), nitem = 3, ndim = 3, ncat = 5,
  theta = c(-6,6), beta = c(-4,4), ntheta = 151, seed = 2021
)

# 4d. Short Dataset containing DIF items
# Generate dataset with polytomous responses (five categories) containing
# three subsets with different discrimination values and two DIF-items.
seed &lt;- c(54748,96765)
difset_short1 &lt;- generate_data(responseType = "discriminate", ncat = 3,
                                ntheta = 50, nitem = 3, ndim = 1,
                                seed = seed[1], alpha = c(2))
difset_short2 &lt;- generate_data(responseType = "discriminate", ncat = 3,
                                ntheta = 50, nitem = 2, ndim = 1,
                                seed = seed[2], alpha = c(0.8),
                                beta = c(-2.5,2.5))
shortDIF &lt;- cbind(rbind(difset_short1,difset_short1),
                   c(difset_short2[,1],difset_short2[,2]))

# 5a. Uncorrelated Multidimensional Dichotomous Dataset
# Generate dataset with binary type responses containing three subsets which
# represent different uncorrelated dimensions.
dicho_md_dset &lt;- generate_data(
  responseType = "multidim.nocorrel", ncat = 2, seed = 2021
)

# 5b. Uncorrelated Multidimensional Polytomous Dataset
# Generate dataset with polytomous responses (five categories) containing
# three subsets which represent different uncorrelated dimensions.
poly_md_dset &lt;- generate_data(
  responseType = "multidim.nocorrel", ncat = 5, seed = 2021
)

</code></pre>

<hr>
<h2 id='generic_model'>Estimation of the generic form of the models</h2><span id='topic+generic_model'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of the generic form of the models by using penalized JML estimation. It allows users to adjust the default settings of the estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generic_model(X, init_par = c(), setting = c())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="generic_model_+3A_x">X</code></td>
<td>
<p>Input dataset as matrix or data frame with ordinal responses (starting from 0); rows represent individuals, column represent items.</p>
</td></tr>
<tr><td><code id="generic_model_+3A_init_par">init_par</code></td>
<td>
<p>Initial values of the estimated parameters.</p>
</td></tr>
<tr><td><code id="generic_model_+3A_setting">setting</code></td>
<td>
<p>Parameter settings which are listed in <code><a href="#topic+autoRaschOptions">autoRaschOptions()</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the discrimination parameters estimation, instead of estimating the discrimination parameters,
we are estimating the natural logarithm of the parameters to avoid negative values, <code class="reqn">\alpha = exp(\gamma)</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>   The dataset that is used for estimation.</p>
</td></tr>
<tr><td><code>name</code></td>
<td>
<p>   The name of each items in the dataset.</p>
</td></tr>
<tr><td><code>mt_vek</code></td>
<td>
<p>   A vector of the highest response category as many as the number of items.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>   The log likelihood of the estimation.</p>
</td></tr>
<tr><td><code>objtype</code></td>
<td>
<p>   Type of the model that is used.</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>
<p>   A vector of the DIF parameters of each items on each groups.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>   A vector of the natural logarithm of discrimination parameters of each items.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>   A vector of the difficulty parameter of each items' categories (thresholds).</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>   A vector of the ability parameters of each individuals.</p>
</td></tr>
</table>

<hr>
<h2 id='gpcm'>Estimation of The Generalized Partial Credit Model</h2><span id='topic+gpcm'></span><span id='topic+summary.gpcm'></span><span id='topic+print.gpcm'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a generalized partial credit model for polytomous responses
by using penalized JML estimation. Inputting a dichotomous responses to this model,
will automatically transforms the GPCM to the 2-PL model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpcm(X, init_par = c(), setting = c(), method = c("fast", "novel"))

## S3 method for class 'gpcm'
summary(object, ...)

## S3 method for class 'gpcm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpcm_+3A_x">X</code></td>
<td>
<p>Input dataset as matrix or data frame with ordinal responses (starting from 0);
rows represent individuals, columns represent items.</p>
</td></tr>
<tr><td><code id="gpcm_+3A_init_par">init_par</code></td>
<td>
<p>a vector of initial values of the estimated parameters.</p>
</td></tr>
<tr><td><code id="gpcm_+3A_setting">setting</code></td>
<td>
<p>a list of the optimization control setting parameters. See <code><a href="#topic+autoRaschOptions">autoRaschOptions()</a>.</code></p>
</td></tr>
<tr><td><code id="gpcm_+3A_method">method</code></td>
<td>
<p>The implementation option of log likelihood function. <code>fast</code> using a <code>c++</code> implementation and <code>novel</code> using an <code>R</code> implementation.</p>
</td></tr>
<tr><td><code id="gpcm_+3A_object">object</code></td>
<td>
<p>The object of class <code>'gpcm'</code>.</p>
</td></tr>
<tr><td><code id="gpcm_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
<tr><td><code id="gpcm_+3A_x">x</code></td>
<td>
<p>The object of class <code>'gpcm'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the discrimination parameters estimation, instead of estimating the discrimination parameters (<code class="reqn">\alpha</code>),
we are estimating its natural logarithm to avoid negative values, <code class="reqn">\alpha = exp(\gamma)</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>   The dataset that is used for estimation.</p>
</td></tr>
<tr><td><code>mt_vek</code></td>
<td>
<p>   A vector of the highest response given to items.</p>
</td></tr>
<tr><td><code>itemName</code></td>
<td>
<p>   The vector of names of items (columns) in the dataset.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>   The log likelihood of the estimation.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>   The hessian matrix. Only when the <code>isHessian = TRUE</code>.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>   A vector of the natural logarithm of discrimination parameters of each items.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>   A vector of the difficulty parameter of each items' categories (thresholds).</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>   A vector of the ability parameters of each individuals.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Muraki, E. (1992). A generalized partial credit model: Application of an EM algorithm. Applied Psychological Measurement, 16(2). https://doi.org/10.1177/014662169201600206
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcm">pcm</a></code>, <code><a href="#topic+gpcm">gpcm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gpcm_res &lt;- gpcm(short_poly_data)
summary(gpcm_res, par = "alpha")

</code></pre>

<hr>
<h2 id='gpcm_dif'>Estimation of The Generalized Partial Credit Model with DIF</h2><span id='topic+gpcm_dif'></span><span id='topic+summary.gpcmdif'></span><span id='topic+print.gpcmdif'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a generalized partial credit model with DIF for polytomous responses
by using penalized JML estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gpcm_dif(
  X,
  init_par = c(),
  groups_map = c(),
  setting = c(),
  method = c("fast", "novel")
)

## S3 method for class 'gpcmdif'
summary(object, ...)

## S3 method for class 'gpcmdif'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="gpcm_dif_+3A_x">X</code></td>
<td>
<p>A matrix or data frame as an input with ordinal responses (starting from 0);
rows represent individuals, columns represent items.</p>
</td></tr>
<tr><td><code id="gpcm_dif_+3A_init_par">init_par</code></td>
<td>
<p>a vector of initial values of the estimated parameters.</p>
</td></tr>
<tr><td><code id="gpcm_dif_+3A_groups_map">groups_map</code></td>
<td>
<p>Binary matrix. Respondents membership to DIF groups; rows represent individuals, column represent group partitions.</p>
</td></tr>
<tr><td><code id="gpcm_dif_+3A_setting">setting</code></td>
<td>
<p>a list of the optimization control setting parameters.See <code><a href="#topic+autoRaschOptions">autoRaschOptions()</a></code></p>
</td></tr>
<tr><td><code id="gpcm_dif_+3A_method">method</code></td>
<td>
<p>The implementation option of log likelihood function. <code>fast</code> using a <code>c++</code> implementation and <code>novel</code> using an <code>R</code> implementation.</p>
</td></tr>
<tr><td><code id="gpcm_dif_+3A_object">object</code></td>
<td>
<p>The object of class <code>'gpcmdif'</code>.</p>
</td></tr>
<tr><td><code id="gpcm_dif_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
<tr><td><code id="gpcm_dif_+3A_x">x</code></td>
<td>
<p>The object of class <code>'gpcmdif'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the discrimination parameters estimation, instead of estimating the discrimination parameters,
we are estimating the natural logarithm of the parameters to avoid negative values, <code class="reqn">\alpha = exp(\gamma)</code>.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>   The dataset that is used for estimation.</p>
</td></tr>
<tr><td><code>mt_vek</code></td>
<td>
<p>   A vector of the highest responses given to items.</p>
</td></tr>
<tr><td><code>itemName</code></td>
<td>
<p>   The vector of names of items (columns) in the dataset.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>   The log likelihood of the estimation.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>   The hessian matrix. Only when the <code>isHessian = TRUE</code>.</p>
</td></tr>
<tr><td><code>delta</code></td>
<td>
<p>   A vector of the DIF parameters of each items on each groups.</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>   A vector of the natural logarithm of discrimination parameters of each items.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>   A vector of the difficulty parameter of each items' categories (thresholds).</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>   A vector of the ability parameters of each individuals.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+pcm">pcm</a></code>, <code><a href="#topic+pcm_dif">pcm_dif</a></code>, <code><a href="#topic+gpcm">gpcm</a></code>, <code><a href="#topic+gpcm_dif">gpcm_dif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
gpcmdif_res &lt;- gpcm_dif(shortDIF, groups_map = c(rep(1,50),rep(0,50)))
summary(gpcmdif_res, par="delta")

## End(Not run)

</code></pre>

<hr>
<h2 id='pcm'>Estimation of The Partial Credit Model (PCM)</h2><span id='topic+pcm'></span><span id='topic+fitStats.pcm'></span><span id='topic+summary.pcm'></span><span id='topic+print.pcm'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a partial credit model for dichotomous and polytomous responses
by using penalized joint maximum likelihood estimation (PJMLE). Inputting a dichotomous responses to this model,
will automatically transforms the PCM to the Rasch model.
</p>
<p><code>fitStats</code> compute the fit statistics (e.g., Outfit and Infit) of the PCM model estimation (items and persons).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcm(X, init_par = c(), setting = c(), method = c("fast", "novel"))

## S3 method for class 'pcm'
fitStats(obj, isAlpha = TRUE)

## S3 method for class 'pcm'
summary(object, ...)

## S3 method for class 'pcm'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcm_+3A_x">X</code></td>
<td>
<p>Input dataset as matrix or data frame with ordinal responses (starting from 0);
rows represent individuals, columns represent items.</p>
</td></tr>
<tr><td><code id="pcm_+3A_init_par">init_par</code></td>
<td>
<p>a vector of initial values of the estimated parameters.</p>
</td></tr>
<tr><td><code id="pcm_+3A_setting">setting</code></td>
<td>
<p>a list of the optimization control setting parameters. See <code><a href="#topic+autoRaschOptions">autoRaschOptions()</a>.</code></p>
</td></tr>
<tr><td><code id="pcm_+3A_method">method</code></td>
<td>
<p>The implementation option of log likelihood function. <code>fast</code> using a <code>c++</code> implementation and <code>novel</code> using an <code>R</code> implementation.</p>
</td></tr>
<tr><td><code id="pcm_+3A_obj">obj</code></td>
<td>
<p>The object of class <code>'pcm'</code>.</p>
</td></tr>
<tr><td><code id="pcm_+3A_isalpha">isAlpha</code></td>
<td>
<p>Boolean value that indicates whether the discrimination parameters is needed to be estimated or not.
The discrimination parameters are estimated using the corresponding models (GPCM or GPCM-DIF).</p>
</td></tr>
<tr><td><code id="pcm_+3A_object">object</code></td>
<td>
<p>The object of class <code>'pcm'</code>.</p>
</td></tr>
<tr><td><code id="pcm_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
<tr><td><code id="pcm_+3A_x">x</code></td>
<td>
<p>The object of class <code>'pcm'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><strong><code>pcm()</code> will return a <code><a href="base.html#topic+list">list</a></code> which contains:</strong>
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>   The dataset that is used for estimation.</p>
</td></tr>
<tr><td><code>mt_vek</code></td>
<td>
<p>   A vector of the highest response given to items.</p>
</td></tr>
<tr><td><code>itemName</code></td>
<td>
<p>   The vector of names of items (columns) in the dataset.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>   The log likelihood of the estimation.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>   The hessian matrix. Only when the <code>isHessian = TRUE</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>   A vector of the difficulty parameter of each categories of items (thresholds).</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>   A vector of the ability parameters of each individuals.</p>
</td></tr>
</table>
<p><strong><code>fitStats()</code> will return a <code><a href="base.html#topic+list">list</a></code> which contains:</strong>
</p>
<table role = "presentation">
<tr><td><code>alpha</code></td>
<td>
<p>   A vector of estimated discrimination parameters for each items.</p>
</td></tr>
</table>
<p><em>i.fit</em>   Item fit statistics.
</p>

<ul>
<li><p>i.outfitMSQ   A vector of Outfit mean square values for each items.
</p>
</li>
<li><p>i.infitMSQ   A vector of Infit mean square values for each items.
</p>
</li>
<li><p>i.outfitZ   A vector of OutfitZ values for each items.
</p>
</li>
<li><p>i.infitZ   A vector of InfitZ values for each items.
</p>
</li></ul>

<p><em>p.fit</em>   Person fit statistics.
</p>

<ul>
<li><p>p.outfitMSQ   A vector of Outfit mean square values for each persons.
</p>
</li>
<li><p>p.infitMSQ   A vector of Infit mean square values for each persons.
</p>
</li>
<li><p>p.outfitZ   A vector of OutfitZ values for each persons.
</p>
</li>
<li><p>p.infitZ   A vector of InfitZ values for each persons.
</p>
</li></ul>

<p><em>traceMat</em>   Some computed matrices in the process.
</p>

<ul>
<li><p>emat   The expected values matrix.
</p>
</li>
<li><p>vmat   The variance matrix.
</p>
</li>
<li><p>cmat   The curtosis matrix.
</p>
</li>
<li><p>std.res   The standardized residual.
</p>
</li></ul>



<h3>References</h3>

<p>Wright, B. D., &amp; Masters, G. N. (1982). Rating Scale Analysis. Chicago: MESA Press.
</p>
<p>Masters, G. N. (1982). A rasch model for partial credit scoring. Psychometrika, 47(2), 149174. https://doi.org/10.1007/BF02296272. <br /><br />
Wright, B. D., &amp; Masters, G. N. (1990). Computation of outfit and infit statistics. Rasch Measurement Transactions, 3(4), 8485. Retrieved from https://www.rasch.org/rmt/rmt34e.htm
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcm">pcm</a></code>, <code><a href="#topic+gpcm">gpcm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>pcm_res &lt;- pcm(shortDIF)
summary(pcm_res)

#To summarize only for beta parameters
summary(pcm_res, par="beta")
fit_res &lt;- fitStats(pcm_res)
itemfit(fit_res)
personfit(fit_res)
plot_fitStats(fit_res, toPlot = c("alpha","outfit"), useName = TRUE)

</code></pre>

<hr>
<h2 id='pcm_dif'>Estimation of The Partial Credit Model with DIF</h2><span id='topic+pcm_dif'></span><span id='topic+fitStats.pcmdif'></span><span id='topic+summary.pcmdif'></span><span id='topic+print.pcmdif'></span>

<h3>Description</h3>

<p>This function computes the parameter estimates of a partial credit model with DIF for dichotomous and polytomous responses
by implementing the coordinate descent.
</p>
<p><code>fitStats</code> compute the fit statistics (i.e., Outfit and Infit) of the PCM-DIF model estimation (items and persons).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcm_dif(
  X,
  init_par = c(),
  groups_map = c(),
  setting = c(),
  method = c("fast", "novel")
)

## S3 method for class 'pcmdif'
fitStats(obj, isAlpha = TRUE)

## S3 method for class 'pcmdif'
summary(object, ...)

## S3 method for class 'pcmdif'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pcm_dif_+3A_x">X</code></td>
<td>
<p>A matrix or data frame as an input with ordinal responses (starting from 0);
rows represent individuals, columns represent items.</p>
</td></tr>
<tr><td><code id="pcm_dif_+3A_init_par">init_par</code></td>
<td>
<p>a vector of initial values of the estimated parameters.</p>
</td></tr>
<tr><td><code id="pcm_dif_+3A_groups_map">groups_map</code></td>
<td>
<p>Binary matrix. Respondents membership to DIF groups; rows represent individuals, column represent group partitions.</p>
</td></tr>
<tr><td><code id="pcm_dif_+3A_setting">setting</code></td>
<td>
<p>a list of the optimization control setting parameters.See <code><a href="#topic+autoRaschOptions">autoRaschOptions()</a></code></p>
</td></tr>
<tr><td><code id="pcm_dif_+3A_method">method</code></td>
<td>
<p>The implementation option of log likelihood function. <code>fast</code> using a <code>c++</code> implementation and <code>novel</code> using an <code>R</code> implementation.</p>
</td></tr>
<tr><td><code id="pcm_dif_+3A_obj">obj</code></td>
<td>
<p>The object of class <code>'pcmdif'</code>.</p>
</td></tr>
<tr><td><code id="pcm_dif_+3A_isalpha">isAlpha</code></td>
<td>
<p>Boolean value that indicates whether the discrimination parameters is needed to be estimated or not.
The discrimination parameters are estimated using the corresponding models (GPCM or GPCM-DIF).</p>
</td></tr>
<tr><td><code id="pcm_dif_+3A_object">object</code></td>
<td>
<p>The object of class <code>'pcmdif'</code>.</p>
</td></tr>
<tr><td><code id="pcm_dif_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
<tr><td><code id="pcm_dif_+3A_x">x</code></td>
<td>
<p>The object of class <code>'pcmdif'</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><strong><code>pcm_dif()</code> will return a <code><a href="base.html#topic+list">list</a></code> which contains:</strong>
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p>   The dataset that is used for estimation.</p>
</td></tr>
<tr><td><code>mt_vek</code></td>
<td>
<p>   A vector of the highest response given to items.</p>
</td></tr>
<tr><td><code>itemName</code></td>
<td>
<p>   The vector of names of items (columns) in the dataset.</p>
</td></tr>
<tr><td><code>loglik</code></td>
<td>
<p>   The log likelihood of the estimation.</p>
</td></tr>
<tr><td><code>hessian</code></td>
<td>
<p>   The hessian matrix. Only when the <code>isHessian = TRUE</code>.</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>   A vector of the difficulty parameter of each categories of items (thresholds).</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>   A vector of the ability parameters of each individuals.</p>
</td></tr>
</table>
<p><strong><code>fitStats()</code> will return a <code><a href="base.html#topic+list">list</a></code> which contains:</strong>
</p>
<table role = "presentation">
<tr><td><code>alpha</code></td>
<td>
<p>   A vector of estimated discrimination parameters for each items.</p>
</td></tr>
</table>
<p><em>i.fit</em>   Item fit statistics.
</p>

<ul>
<li><p>i.outfitMSQ   A vector of Outfit mean square values for each items.
</p>
</li>
<li><p>i.infitMSQ   A vector of Infit mean square values for each items.
</p>
</li>
<li><p>i.outfitZ   A vector of OutfitZ values for each items.
</p>
</li>
<li><p>i.infitZ   A vector of InfitZ values for each items.
</p>
</li></ul>

<p><em>p.fit</em>   Person fit statistics.
</p>

<ul>
<li><p>p.outfitMSQ   A vector of Outfit mean square values for each persons.
</p>
</li>
<li><p>p.infitMSQ   A vector of Infit mean square values for each persons.
</p>
</li>
<li><p>p.outfitZ   A vector of OutfitZ values for each persons.
</p>
</li>
<li><p>p.infitZ   A vector of InfitZ values for each persons.
</p>
</li></ul>

<p><em>traceMat</em>   Some computed matrices in the process.
</p>

<ul>
<li><p>emat   The expected values matrix.
</p>
</li>
<li><p>vmat   The variance matrix.
</p>
</li>
<li><p>cmat   The curtosis matrix.
</p>
</li>
<li><p>std.res   The standardized residual.
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+pcm">pcm</a></code>, <code><a href="#topic+pcm_dif">pcm_dif</a></code>, <code><a href="#topic+gpcm">gpcm</a></code>, <code><a href="#topic+gpcm_dif">gpcm_dif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
pcmdif_res &lt;- pcm_dif(shortDIF, groups_map = c(rep(1,50),rep(0,50)))
fit_res &lt;- fitStats(pcmdif_res)
itemfit(fit_res)
personfit(fit_res)
plot_fitStats(fit_res, toPlot = c("alpha","outfit"), useName = FALSE)

## End(Not run)

</code></pre>

<hr>
<h2 id='plot_EVC'>Plot The Expected Value Curves</h2><span id='topic+plot_EVC'></span>

<h3>Description</h3>

<p>This function plots the curve(s) of the estimated ability parameters against its expected responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_EVC(
  obj = c(),
  itemno = 5,
  xlab = NULL,
  ylab = NULL,
  xlim = c(-10, 10),
  col = c("green4", "darkorange2", "red2"),
  lty = c(1, 1, 1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_EVC_+3A_obj">obj</code></td>
<td>
<p>The object of class <code>'pcm'</code>.</p>
</td></tr>
<tr><td><code id="plot_EVC_+3A_itemno">itemno</code></td>
<td>
<p>A number of the item that is wanted to be plot.</p>
</td></tr>
<tr><td><code id="plot_EVC_+3A_xlab">xlab</code></td>
<td>
<p>a title for the x axis.</p>
</td></tr>
<tr><td><code id="plot_EVC_+3A_ylab">ylab</code></td>
<td>
<p>a title for the y axis.</p>
</td></tr>
<tr><td><code id="plot_EVC_+3A_xlim">xlim</code></td>
<td>
<p>the x limits (x1, x2) of the plot. Note that x1 &gt; x2 is allowed and leads to a reversed axis.
The default value, <code>NULL</code>, indicates that the range of the finite values to be plotted should be used;
see <code><a href="graphics.html#topic+plot.default">plot.default()</a></code></p>
</td></tr>
<tr><td><code id="plot_EVC_+3A_col">col</code></td>
<td>
<p>a vector of plotting colors</p>
</td></tr>
<tr><td><code id="plot_EVC_+3A_lty">lty</code></td>
<td>
<p>a vector of line types.</p>
</td></tr>
<tr><td><code id="plot_EVC_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>There are no values to return. Instead, it plots expected values from the model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- pcm(short_poly_data)
plot_EVC(res, itemno = 4)

</code></pre>

<hr>
<h2 id='plot_ICC'>Plot The Item Characteristic Curves</h2><span id='topic+plot_ICC'></span>

<h3>Description</h3>

<p>This function plots the curve(s) of the estimated ability parameters against the probabilities of responses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_ICC(
  obj,
  itemno = 5,
  xlab = NULL,
  ylab = NULL,
  xlim = c(-10, 10),
  col = c("green4", "darkorange2", "red2"),
  lty = c(1, 1, 1),
  main = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_ICC_+3A_obj">obj</code></td>
<td>
<p>The object of class <code>'pcm'</code>.</p>
</td></tr>
<tr><td><code id="plot_ICC_+3A_itemno">itemno</code></td>
<td>
<p>A number of the item that is wanted to be plot.</p>
</td></tr>
<tr><td><code id="plot_ICC_+3A_xlab">xlab</code></td>
<td>
<p>a title for the x axis.</p>
</td></tr>
<tr><td><code id="plot_ICC_+3A_ylab">ylab</code></td>
<td>
<p>a title for the y axis.</p>
</td></tr>
<tr><td><code id="plot_ICC_+3A_xlim">xlim</code></td>
<td>
<p>the x limits (x1, x2) of the plot. Note that x1 &gt; x2 is allowed and leads to a reversed axis.
The default value, <code>NULL</code>, indicates that the range of the finite values to be plotted should be used;
see <code><a href="graphics.html#topic+plot.default">plot.default()</a></code></p>
</td></tr>
<tr><td><code id="plot_ICC_+3A_col">col</code></td>
<td>
<p>a vector of plotting colors</p>
</td></tr>
<tr><td><code id="plot_ICC_+3A_lty">lty</code></td>
<td>
<p>a vector of line types.</p>
</td></tr>
<tr><td><code id="plot_ICC_+3A_main">main</code></td>
<td>
<p>String. Plot title.</p>
</td></tr>
<tr><td><code id="plot_ICC_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>There are no values to return. Instead, it plots the curve of item characteristics from the model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>res &lt;- pcm(short_poly_data)
plot_ICC(res, itemno = 4)

</code></pre>

<hr>
<h2 id='plot_PImap'>Plot The Person-Item Map</h2><span id='topic+plot_PImap'></span>

<h3>Description</h3>

<p>This function maps the distribution of the persons' abilities and the items difficulties along the latent continuum.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_PImap(
  obj,
  main = NULL,
  xlab = NULL,
  cex = NULL,
  cex.lab = NULL,
  cex.axis = NULL,
  cex.main = NULL,
  lwd = NULL,
  v = NULL,
  th_dif = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_PImap_+3A_obj">obj</code></td>
<td>
<p>The object of class <code>'pcm'</code>.</p>
</td></tr>
<tr><td><code id="plot_PImap_+3A_main">main</code></td>
<td>
<p>main title of the plot; see <code><a href="graphics.html#topic+plot.default">plot.default()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_PImap_+3A_xlab">xlab</code></td>
<td>
<p>Label for the x-axis; see <code><a href="graphics.html#topic+plot.default">plot.default()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_PImap_+3A_cex">cex</code></td>
<td>
<p>A numerical value giving the amount by which plotting text and symbols should be magnified relative to the default;
see <code><a href="graphics.html#topic+par">par()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_PImap_+3A_cex.lab">cex.lab</code></td>
<td>
<p>The magnification to be used for x and y labels relative to the current setting of cex;
see <code><a href="graphics.html#topic+par">par()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_PImap_+3A_cex.axis">cex.axis</code></td>
<td>
<p>The magnification to be used for axis annotation relative to the current setting of cex;
see <code><a href="graphics.html#topic+par">par()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_PImap_+3A_cex.main">cex.main</code></td>
<td>
<p>The magnification to be used for main titles relative to the current setting of cex;
see <code><a href="graphics.html#topic+par">par()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_PImap_+3A_lwd">lwd</code></td>
<td>
<p>The line width, a positive number, defaulting to 1;
see <code><a href="graphics.html#topic+par">par()</a></code>.</p>
</td></tr>
<tr><td><code id="plot_PImap_+3A_v">v</code></td>
<td>
<p>Variable names used</p>
</td></tr>
<tr><td><code id="plot_PImap_+3A_th_dif">th_dif</code></td>
<td>
<p>The threshold at which a DIF effect is still considered a DIF.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>There are no values to return. Instead, it shows a graphical map of the estimated ability and the estimated difficulty on the same scale.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
groupsMap &lt;- matrix(c(rep(1,50),rep(0,50)),ncol = 1, dimnames = list(c(1:100),c("V1")))
pcmdif_res &lt;- pcm_dif(shortDIF, groups_map = groupsMap)
plot_PImap(pcmdif_res)

## End(Not run)

</code></pre>

<hr>
<h2 id='poly_inh_dset'>The Inhomogenous Polytomous Dataset</h2><span id='topic+poly_inh_dset'></span>

<h3>Description</h3>

<p>The artificial dataset of a polytomous responses (five categories) which
contains three subsets with different discrimination values.
To reproduce this dataset: <br />
<code>poly_inh_dset &lt;- generate_data(responseType = "discriminate", ncat = 5, alpha = c(0.04,0.045,0.05,0.055,0.06,0.065,0.2,0.25,0.3,0.35,0.4,0.45,2.6,2.65,2.7,2.75,2.8,2.85,2.9))</code>
<br /><br /> will lead to similar but not the same dataset, due to the randomization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(poly_inh_dset)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 18 columns.
</p>

<hr>
<h2 id='poly_md_dset'>Uncorrelated Multidimensional Polytomous Data Set</h2><span id='topic+poly_md_dset'></span>

<h3>Description</h3>

<p>Data set with polytomous responses (five categories) containing
three subsets which represent different uncorrelated dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(poly_md_dset)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 18 columns.
</p>

<hr>
<h2 id='polydif_inh_dset'>The Inhomogenous Polytomous Dataset containing DIF items</h2><span id='topic+polydif_inh_dset'></span>

<h3>Description</h3>

<p>The artificial data set of a polytomous responses (five categories) which
contains three subsets with different discrimination values and two DIF-items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(polydif_inh_dset)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 490 rows and 20 columns.
</p>

<hr>
<h2 id='residCor'>Residual Correlation</h2><span id='topic+residCor'></span><span id='topic+corResid'></span><span id='topic+summary.ld'></span>

<h3>Description</h3>

<p>Compute the correlation of the standardized residual to check the local dependency status
</p>


<h3>Usage</h3>

<pre><code class='language-R'>residCor(objFit)

corResid(objFit)

## S3 method for class 'ld'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="residCor_+3A_objfit">objFit</code></td>
<td>
<p>object of class &quot;fit&quot;, the output of <code>fitStats()</code>.</p>
</td></tr>
<tr><td><code id="residCor_+3A_object">object</code></td>
<td>
<p>The object of class <code>'ld'</code>.</p>
</td></tr>
<tr><td><code id="residCor_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>ld_correl</code></td>
<td>
<p>  Correlation matrix of the standradized residual.</p>
</td></tr>
<tr><td><code>ld_mean</code></td>
<td>
<p>  The mean of the correlation.</p>
</td></tr>
<tr><td><code>ld_lowertri</code></td>
<td>
<p>  The lower triangle of the correlation matrix.</p>
</td></tr>
</table>

<hr>
<h2 id='short_poly_data'>A Shorter Inhomogenous Polytomous Dataset</h2><span id='topic+short_poly_data'></span>

<h3>Description</h3>

<p>The artificial dataset of a polytomous responses (three categories) which
contains three subsets with different discrimination values.
To reproduce this dataset: <br />
<code>short_poly_data &lt;- generate_data(alpha = c(0.02,0.5,2), nitem = 3, ndim = 3,ncat = 5, theta = c(-6,6), beta = c(-4,4), ntheta = 151)</code>
<br /><br /> will lead to similar but not the same dataset, due to the randomization.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(short_poly_data)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 151 rows and 9 columns.
</p>

<hr>
<h2 id='shortDIF'>A Shorter Polytomous Dataset with DIF</h2><span id='topic+shortDIF'></span>

<h3>Description</h3>

<p>The artificial dataset of a polytomous responses (three categories) which
contains three non-DIF items and a DIF item.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(shortDIF)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 100 rows and 4 columns.
</p>

<hr>
<h2 id='stepwise_search'>Stepwise Selection Search</h2><span id='topic+stepwise_search'></span><span id='topic+backward_search'></span><span id='topic+summary.search'></span><span id='topic+print.search'></span><span id='topic+plot_search'></span>

<h3>Description</h3>

<p>To search itemset that give maximum value of the criterion
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepwise_search(
  X,
  criterion = c("ipoqll", "ipoqlldif"),
  incl_set = c(),
  groups_map = c(),
  cores = NULL,
  isContinued = FALSE,
  prevData = c(),
  fileOutput = FALSE,
  tempFile = "temp_stepSearch.RData",
  isConvert = FALSE,
  setting_par_iq = c(),
  setting_par_oq = c(),
  method = c("fast", "novel"),
  isTraced = FALSE
)

backward_search(
  X,
  criterion = c("ipoqll", "ipoqlldif"),
  incl_set = c(),
  groups_map = c(),
  cores = NULL,
  isContinued = FALSE,
  prevData = c(),
  isConvert = FALSE,
  setting_par_iq = c(),
  fileOutput = FALSE,
  setting_par_oq = c(),
  method = c("fast", "novel"),
  tempFile = "temp_backSearch.RData",
  isTraced = FALSE
)

## S3 method for class 'search'
summary(object, ...)

## S3 method for class 'search'
print(x, ...)

plot_search(obj, remOrdered = TRUE, locateMax = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stepwise_search_+3A_x">X</code></td>
<td>
<p>A matrix or data.frame of the observed responses (ordinal or binary response).</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_criterion">criterion</code></td>
<td>
<p>The criterion that should be used. The default is ipoqll.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_incl_set">incl_set</code></td>
<td>
<p>A vector of initial items in the included set to start the search. The default is to start with full items.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_groups_map">groups_map</code></td>
<td>
<p>A matrix or vector to map the subject to the DIFs groups.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_cores">cores</code></td>
<td>
<p>An integer value of number of cores should be used for computation. The default is 2.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_iscontinued">isContinued</code></td>
<td>
<p>A logical value whether this search is continuing another unfinished search.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_prevdata">prevData</code></td>
<td>
<p>The filename of the temporary .RData file of the unfinished search.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_fileoutput">fileOutput</code></td>
<td>
<p>The filename if it is wished to save the output results in file (.RData and .csv) and FALSE if not.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_tempfile">tempFile</code></td>
<td>
<p>The filename of the temporary file to track the search progress. The default is <code>"temp_stepSearch.RData"</code> which also automatically produces <code>"temp_stepSearch.csv"</code>.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_isconvert">isConvert</code></td>
<td>
<p>A logical value whether it is wanted to recompute the score of the search results using IPOQ-LL-DIF criterion.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_setting_par_iq">setting_par_iq</code></td>
<td>
<p>a list of the optimization control setting parameters for the included set. See <code>setting</code> parameter in <code><a href="#topic+autoRaschOptions">autoRaschOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_setting_par_oq">setting_par_oq</code></td>
<td>
<p>a list of the optimization control setting parameters for the included set. See <code>setting</code> parameter in <code><a href="#topic+autoRaschOptions">autoRaschOptions()</a></code>.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_method">method</code></td>
<td>
<p>The implementation option of log likelihood function. <code>fast</code> using a <code>c++</code> implementation and <code>novel</code> using an <code>R</code> implementation.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_istraced">isTraced</code></td>
<td>
<p>A logical value whether the progress need to be tracked or not.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_object">object</code></td>
<td>
<p>The object of class <code>'search'</code>.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_x">x</code></td>
<td>
<p>The object of class <code>'search'</code>.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_obj">obj</code></td>
<td>
<p>An object of class &quot;search&quot;.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_remordered">remOrdered</code></td>
<td>
<p>A logical statement whether show the order of the items removal or not.</p>
</td></tr>
<tr><td><code id="stepwise_search_+3A_locatemax">locateMax</code></td>
<td>
<p>A logical statement whether the location of the maximum score is needed to be marked or not.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To search the itemset that give the maximum score.
</p>


<h3>Value</h3>

<p>Matrix of the highest scores (IQ-LL, OQ-LL, and IPOQ-LL) for every number of items in the included set in the set along with the corresponding itemset.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
search_res &lt;- backward_search(shortDIF,criterion = "ipoqll", incl_set = c(1:4), cores = 2)
plot_search(search_res, type="l")

## End(Not run)

</code></pre>

<hr>
<h2 id='testlets_dataset'>Multi-testlets Polytomous Data Set</h2><span id='topic+testlets_dataset'></span>

<h3>Description</h3>

<p>Generate data set which consist of two bundle items with different level of
local dependency effect.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(testlets_dataset)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 12 columns.
</p>

<hr>
<h2 id='withinItem_multidim'>Within-item Multidimensional Polytomous Data Set</h2><span id='topic+withinItem_multidim'></span>

<h3>Description</h3>

<p>Generate multidimensional dataset with some items relate to more than one
dimension.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(withinItem_multidim)
</code></pre>


<h3>Format</h3>

<p>An object of class <code>data.frame</code> with 301 rows and 18 columns.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
