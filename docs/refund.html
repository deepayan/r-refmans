<!DOCTYPE html><html><head><title>Help for package refund</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {refund}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#af'><p>Construct an FGAM regression term</p></a></li>
<li><a href='#af_old'><p>Construct an FGAM regression term</p></a></li>
<li><a href='#amc'><p>Additive model with constraints</p></a></li>
<li><a href='#bayes_fosr'><p>Bayesian Function-on-scalar regression</p></a></li>
<li><a href='#ccb.fpc'><p>Corrected confidence bands using functional principal components</p></a></li>
<li><a href='#cd4'><p>Observed CD4 cell counts</p></a></li>
<li><a href='#cmdscale_lanczos'><p>Faster multi-dimensional scaling</p></a></li>
<li><a href='#coef.pffr'><p>Get estimated coefficients from a pffr fit</p></a></li>
<li><a href='#coefboot.pffr'><p>Simple bootstrap CIs for pffr</p></a></li>
<li><a href='#coefficients.pfr'><p>Extract coefficient functions from a fitted pfr-object</p></a></li>
<li><a href='#content'><p>The CONTENT child growth study</p></a></li>
<li><a href='#COVID19'><p>The US weekly all-cause mortality and COVID19-associated deaths in 2020</p></a></li>
<li><a href='#create.prep.func'><p>Construct a function for preprocessing functional predictors</p></a></li>
<li><a href='#DTI'><p>Diffusion Tensor Imaging: tract profiles and outcomes</p></a></li>
<li><a href='#DTI2'><p>Diffusion Tensor Imaging: more fractional anisotropy profiles and outcomes</p></a></li>
<li><a href='#expand.call'><p>Return call with all possible arguments</p></a></li>
<li><a href='#f_sum'><p>Sum computation 1</p></a></li>
<li><a href='#f_sum2'><p>Sum computation 2</p></a></li>
<li><a href='#f_sum4'><p>Sum computation 2</p></a></li>
<li><a href='#f_trace'><p>Trace computation</p></a></li>
<li><a href='#fbps'><p>Sandwich smoother for matrix data</p></a></li>
<li><a href='#ff'><p>Construct a function-on-function regression term</p></a></li>
<li><a href='#ffpc'><p>Construct a PC-based function-on-function regression term</p></a></li>
<li><a href='#ffpcplot'><p>Plot PC-based function-on-function regression terms</p></a></li>
<li><a href='#fgam'><p>Functional Generalized Additive Models</p></a></li>
<li><a href='#fosr'><p>Function-on-scalar regression</p></a></li>
<li><a href='#fosr.perm'><p>Permutation testing for function-on-scalar regression</p></a></li>
<li><a href='#fosr.vs'><p>Function-on Scalar Regression with variable selection</p></a></li>
<li><a href='#fosr2s'><p>Two-step function-on-scalar regression</p></a></li>
<li><a href='#fpc'><p>Construct a FPC regression term</p></a></li>
<li><a href='#fpca.face'><p>Functional principal component analysis with fast covariance estimation</p></a></li>
<li><a href='#fpca.lfda'><p>Longitudinal Functional Data Analysis using FPCA</p></a></li>
<li><a href='#fpca.sc'><p>Functional principal components analysis by smoothed covariance</p></a></li>
<li><a href='#fpca.ssvd'><p>Smoothed FPCA via iterative penalized rank one SVDs.</p></a></li>
<li><a href='#fpca2s'><p>Functional principal component analysis by a two-stage method</p></a></li>
<li><a href='#fpcr'><p>Functional principal component regression</p></a></li>
<li><a href='#gasoline'><p>Octane numbers and NIR spectra of gasoline</p></a></li>
<li><a href='#getTF'><p>Get recognized transformation function</p></a></li>
<li><a href='#gibbs_cs_fpca'><p>Cross-sectional FoSR using a Gibbs sampler and FPCA</p></a></li>
<li><a href='#gibbs_cs_wish'><p>Cross-sectional FoSR using a Gibbs sampler and Wishart prior</p></a></li>
<li><a href='#gibbs_mult_fpca'><p>Multilevel FoSR using a Gibbs sampler and FPCA</p></a></li>
<li><a href='#gibbs_mult_wish'><p>Multilevel FoSR using a Gibbs sampler and Wishart prior</p></a></li>
<li><a href='#gls_cs'><p>Cross-sectional FoSR using GLS</p></a></li>
<li><a href='#lf'><p>Construct an FLM regression term</p></a></li>
<li><a href='#lf_old'><p>Construct an FLM regression term</p></a></li>
<li><a href='#lf.vd'><p>Construct a VDFR regression term</p></a></li>
<li><a href='#lofocv'><p>Leave-one-function-out cross-validation</p></a></li>
<li><a href='#lpeer'><p>Longitudinal Functional Models with Structured Penalties</p></a></li>
<li><a href='#lpfr'><p>Longitudinal penalized functional regression</p></a></li>
<li><a href='#mfpca.face'><p>Multilevel functional principal components analysis with fast covariance estimation</p></a></li>
<li><a href='#mfpca.sc'><p>Multilevel functional principal components analysis by smoothed covariance</p></a></li>
<li><a href='#model.matrix.pffr'><p>Obtain model matrix for a pffr fit</p></a></li>
<li><a href='#ols_cs'><p>Cross-sectional FoSR using GLS</p></a></li>
<li><a href='#pco_predict_preprocess'><p>Make predictions using pco basis terms</p></a></li>
<li><a href='#pcre'><p>pffr-constructor for functional principal component-based functional random intercepts.</p></a></li>
<li><a href='#peer'><p>Construct a PEER regression term in a <code>pfr</code> formula</p></a></li>
<li><a href='#peer_old'><p>Functional Models with Structured Penalties</p></a></li>
<li><a href='#PEER.Sim'><p>Simulated longitudinal data with functional predictor and scalar response,</p>
and structural information associated with predictor function</a></li>
<li><a href='#pffr'><p>Penalized flexible functional regression</p></a></li>
<li><a href='#pffr.check'><p>Some diagnostics for a fitted pffr model</p></a></li>
<li><a href='#pffrGLS'><p>Penalized function-on-function regression with non-i.i.d. residuals</p></a></li>
<li><a href='#pffrSim'><p>Simulate example data for pffr</p></a></li>
<li><a href='#pfr'><p>Penalized Functional Regression</p></a></li>
<li><a href='#pfr_old'><p>Penalized Functional Regression (old version)</p></a></li>
<li><a href='#pfr_plot.gam'><p>Local version of <code>plot.gam</code></p></a></li>
<li><a href='#plot.fosr'><p>Default plotting of function-on-scalar regression objects</p></a></li>
<li><a href='#plot.fosr.vs'><p>Plot for Function-on Scalar Regression with variable selection</p></a></li>
<li><a href='#plot.fpcr'><p>Default plotting for functional principal component regression output</p></a></li>
<li><a href='#plot.lpeer'><p>Plotting of estimated regression functions obtained through <code>lpeer()</code></p></a></li>
<li><a href='#plot.peer'><p>Plotting of estimated regression functions obtained through <code>peer()</code></p></a></li>
<li><a href='#plot.pffr'><p>Plot a pffr fit</p></a></li>
<li><a href='#plot.pfr'><p>Plot a pfr object</p></a></li>
<li><a href='#predict.fbps'><p>Prediction for fast bivariate <em>P</em>-spline (fbps)</p></a></li>
<li><a href='#predict.fgam'><p>Prediction from a fitted FGAM model</p></a></li>
<li><a href='#predict.fosr'><p>Prediction from a fitted bayes_fosr model</p></a></li>
<li><a href='#predict.fosr.vs'><p>Prediction for Function-on Scalar Regression with variable selection</p></a></li>
<li><a href='#Predict.matrix.dt.smooth'><p>Predict.matrix method for dt basis</p></a></li>
<li><a href='#Predict.matrix.fpc.smooth'><p>mgcv-style constructor for prediction of FPC terms</p></a></li>
<li><a href='#Predict.matrix.pcre.random.effect'><p>mgcv-style constructor for prediction of PC-basis functional random effects</p></a></li>
<li><a href='#Predict.matrix.peer.smooth'><p>mgcv-style constructor for prediction of PEER terms</p></a></li>
<li><a href='#Predict.matrix.pi.smooth'><p>Predict.matrix method for pi basis</p></a></li>
<li><a href='#predict.pffr'><p>Prediction for penalized function-on-function regression</p></a></li>
<li><a href='#predict.pfr'><p>Prediction from a fitted pfr model</p></a></li>
<li><a href='#print.summary.pffr'><p>Print method for summary of a pffr fit</p></a></li>
<li><a href='#pwcv'><p>Pointwise cross-validation for function-on-scalar regression</p></a></li>
<li><a href='#qq.pffr'><p>QQ plots for pffr model residuals</p></a></li>
<li><a href='#quadWeights'><p>Compute quadrature weights</p></a></li>
<li><a href='#re'><p>Random effects constructor for fgam</p></a></li>
<li><a href='#residuals.pffr'><p>Obtain residuals and fitted values for a pffr models</p></a></li>
<li><a href='#rlrt.pfr'><p>Likelihood Ratio Test and Restricted Likelihood Ratio Test for inference of</p>
functional predictors</a></li>
<li><a href='#sff'><p>Construct a smooth function-on-function regression term</p></a></li>
<li><a href='#smooth.construct.dt.smooth.spec'><p>Domain Transformation basis constructor</p></a></li>
<li><a href='#smooth.construct.fpc.smooth.spec'><p>Basis constructor for FPC terms</p></a></li>
<li><a href='#smooth.construct.pco.smooth.spec'><p>Principal coordinate ridge regression</p></a></li>
<li><a href='#smooth.construct.pcre.smooth.spec'><p>mgcv-style constructor for PC-basis functional random effects</p></a></li>
<li><a href='#smooth.construct.peer.smooth.spec'><p>Basis constructor for PEER terms</p></a></li>
<li><a href='#smooth.construct.pi.smooth.spec'><p>Parametric Interaction basis constructor</p></a></li>
<li><a href='#smooth.construct.pss.smooth.spec'><p>P-spline constructor with modified 'shrinkage' penalty</p></a></li>
<li><a href='#sofa'><p>SOFA (Sequential Organ Failure Assessment) Data</p></a></li>
<li><a href='#summary.pffr'><p>Summary for a pffr fit</p></a></li>
<li><a href='#summary.pfr'><p>Summary for a pfr fit</p></a></li>
<li><a href='#vb_cs_fpca'><p>Cross-sectional FoSR using Variational Bayes and FPCA</p></a></li>
<li><a href='#vb_cs_wish'><p>Cross-sectional FoSR using Variational Bayes and Wishart prior</p></a></li>
<li><a href='#vb_mult_fpca'><p>Multilevel FoSR using Variational Bayes and FPCA</p></a></li>
<li><a href='#vb_mult_wish'><p>Multilevel FoSR using Variational Bayes and Wishart prior</p></a></li>
<li><a href='#vis.fgam'><p>Visualization of FGAM objects</p></a></li>
<li><a href='#vis.pfr'><p>Visualization of PFR objects</p></a></li>
<li><a href='#Xt_siginv_X'><p>Internal computation function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Regression with Functional Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1-35</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-02-14</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>fda, Matrix, lattice, boot, mgcv (&ge; 1.9), MASS, magic, nlme,
gamm4, lme4, RLRsim, splines, grpreg, ggplot2, stats, pbs,
methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>RColorBrewer, reshape2, testthat</td>
</tr>
<tr>
<td>Description:</td>
<td>Methods for regression for functional
    data, including function-on-scalar, scalar-on-function, and
    function-on-function regression. Some of the functions are applicable to
    image data.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/refunders/refund">https://github.com/refunders/refund</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/refunders/refund/issues">https://github.com/refunders/refund/issues</a></td>
</tr>
<tr>
<td>Collate:</td>
<td>'Omegas.R' 'af.R' 'af_old.R' 'amc.R' 'ccb.fpc.R'
'create.prep.func.R' 'coefficients.pfr.R' 'dt_basis.R'
'irreg2mat.R' 'fbps.R' 'fgam.R' 'fosr.R' 'fosr.perm.R'
'fosr.perm.fit.R' 'fosr.perm.test.R' 'fosr.vs.R' 'fosr2s.R'
'fpc.R' 'fpca2s.R' 'fpca.sc.R' 'fpca.face.R' 'fpca.ssvd.R'
'fpcr.R' 'fpcr.setup.R' 'lf.R' 'lf_old.R' 'lf.vd.R' 'lofocv.R'
'lpeer.R' 'lpfr.R' 'quadWeights.R' 'lw.test.R' 'osplinepen2d.R'
'parse.predict.pfr.R' 'peer.R' 'peer_old.R' 'pffr-ff.R'
'pffr-ffpc.R' 'pffr-methods.R' 'pffr-pcre.R' 'pffr-robust.R'
'pffr-sff.R' 'pffr-utilities.R' 'pffr.R' 'pfr.R' 'pfr_old.R'
'pi_basis.R' 'plot.fosr.R' 'plot.fosr.perm.R' 'plot.fosr.vs.R'
'plot.fpcr.R' 'plot.lpeer.R' 'plot.peer.R' 'plot.pfr.R'
'poridge.R' 'postprocess.pfr.R' 'predict.fgam.R'
'predict.fosr.R' 'predict.pfr.R' 'predict.pfr_old.R'
'preprocess.pfr.R' 'pspline.setting.R' 'pwcv.R' 'summary.pfr.R'
're.R' 'rlrt.pfr.R' 'vis.fgam.R' 'predict.fosr.vs.R'
'CD4-data.R' 'content-data.R' 'COVID19-data.R' 'DTI-data.R'
'DTI2-data.R' 'PEER.Sim-data.R' 'gasoline-data.R' 'vis.pfr.R'
'GLS_CS.R' 'Gibbs_CS_FPCA.R' 'Gibbs_CS_Wish.R'
'Gibbs_Mult_FPCA.R' 'Gibbs_Mult_Wish.R' 'OLS_CS.R'
'VB_CS_FPCA.R' 'VB_CS_Wish.R' 'VB_Mult_FPCA.R' 'VB_Mult_Wish.R'
'XtSiginvX.R' 'bayes_fosr.R' 'f_sum.R' 'f_sum2.R' 'f_sum4.R'
'f_trace.R' 'mfpca.sc.R' 'mfpca.face.R' 'face.Cov.mfpca.R'
'fpca.lfda.R' 'predict.fbps.R' 'select_knots.R'</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-02-14 15:37:15 UTC; JWROBE8</td>
</tr>
<tr>
<td>Author:</td>
<td>Jeff Goldsmith [aut],
  Fabian Scheipl [aut],
  Lei Huang [aut],
  Julia Wrobel [aut, cre],
  Chongzhi Di [aut],
  Jonathan Gellar [aut],
  Jaroslaw Harezlak [aut],
  Mathew W. McLean [aut],
  Bruce Swihart [aut],
  Luo Xiao [aut],
  Ciprian Crainiceanu [aut],
  Philip T. Reiss [aut],
  Yakuan Chen [ctb],
  Sonja Greven [ctb],
  Lan Huo [ctb],
  Madan Gopal Kundu [ctb],
  So Young Park [ctb],
  David L. Miller [ctb],
  Ana-Maria Staicu [ctb],
  Erjia Cui [aut],
  Ruonan Li [ctb],
  Zheyuan Li [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Julia Wrobel &lt;julia.wrobel@emory.edu&gt;</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-02-14 20:20:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='af'>Construct an FGAM regression term</h2><span id='topic+af'></span>

<h3>Description</h3>

<p>Defines a term <code class="reqn">\int_{T}F(X_i(t),t)dt</code> for inclusion in an <code>mgcv::gam</code>-formula (or
<code><a href="mgcv.html#topic+bam">bam</a></code> or <code><a href="mgcv.html#topic+gamm">gamm</a></code> or <code>gamm4:::gamm</code>) as constructed by
<code><a href="#topic+pfr">pfr</a></code>, where <code class="reqn">F(x,t)</code> is an unknown smooth bivariate function and <code class="reqn">X_i(t)</code>
is a functional predictor on the closed interval <code class="reqn">T</code>. See <code><a href="mgcv.html#topic+smooth.terms">smooth.terms</a></code>
for a list of bivariate basis and penalty options; the default is a tensor
product basis with marginal cubic regression splines for estimating <code class="reqn">F(x,t)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>af(
  X,
  argvals = NULL,
  xind = NULL,
  basistype = c("te", "t2", "s"),
  integration = c("simpson", "trapezoidal", "riemann"),
  L = NULL,
  presmooth = NULL,
  presmooth.opts = NULL,
  Xrange = range(X, na.rm = T),
  Qtransform = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="af_+3A_x">X</code></td>
<td>
<p>functional predictors, typically expressed as an <code>N</code> by <code>J</code> matrix,
where <code>N</code> is the number of columns and <code>J</code> is the number of
evaluation points. May include missing/sparse functions, which are
indicated by <code>NA</code> values. Alternatively, can be an object of class
<code>"fd"</code>; see <code><a href="fda.html#topic+fd">fd</a></code>.</p>
</td></tr>
<tr><td><code id="af_+3A_argvals">argvals</code></td>
<td>
<p>indices of evaluation of <code>X</code>, i.e. <code class="reqn">(t_{i1},.,t_{iJ})</code> for
subject <code class="reqn">i</code>. May be entered as either a length-<code>J</code> vector, or as
an <code>N</code> by <code>J</code> matrix. Indices may be unequally spaced. Entering
as a matrix allows for different observations times for each subject. If
<code>NULL</code>, defaults to an equally-spaced grid between 0 or 1 (or within
<code>X$basis$rangeval</code> if <code>X</code> is a <code>fd</code> object.)</p>
</td></tr>
<tr><td><code id="af_+3A_xind">xind</code></td>
<td>
<p>same as argvals. It will not be supported in the next version of refund.</p>
</td></tr>
<tr><td><code id="af_+3A_basistype">basistype</code></td>
<td>
<p>defaults to <code>"te"</code>, i.e. a tensor product spline to represent <code class="reqn">F(x,t)</code> Alternatively,
use <code>"s"</code> for bivariate basis functions (see <code><a href="mgcv.html#topic+s">s</a></code>) or <code>"t2"</code> for an alternative
parameterization of tensor product splines (see <code><a href="mgcv.html#topic+t2">t2</a></code>)</p>
</td></tr>
<tr><td><code id="af_+3A_integration">integration</code></td>
<td>
<p>method used for numerical integration. Defaults to <code>"simpson"</code>'s rule
for calculating entries in <code>L</code>. Alternatively and for non-equidistant grids,
<code>"trapezoidal"</code> or <code>"riemann"</code>.</p>
</td></tr>
<tr><td><code id="af_+3A_l">L</code></td>
<td>
<p>an optional <code>N</code> by <code>ncol(argvals)</code> matrix giving the weights for the numerical
integration over <code>t</code>. If present, overrides <code>integration</code>.</p>
</td></tr>
<tr><td><code id="af_+3A_presmooth">presmooth</code></td>
<td>
<p>string indicating the method to be used for preprocessing functional predictor prior
to fitting. Options are <code>fpca.sc</code>, <code>fpca.face</code>, <code>fpca.ssvd</code>, <code>fpca.bspline</code>, and
<code>fpca.interpolate</code>. Defaults to <code>NULL</code> indicateing no preprocessing. See
<code><a href="#topic+create.prep.func">create.prep.func</a></code>.</p>
</td></tr>
<tr><td><code id="af_+3A_presmooth.opts">presmooth.opts</code></td>
<td>
<p>list including options passed to preprocessing method
<code><a href="#topic+create.prep.func">create.prep.func</a></code>.</p>
</td></tr>
<tr><td><code id="af_+3A_xrange">Xrange</code></td>
<td>
<p>numeric; range to use when specifying the marginal basis for the <em>x</em>-axis.  It may
be desired to increase this slightly over the default of <code>range(X)</code> if concerned about predicting
for future observed curves that take values outside of <code>range(X)</code></p>
</td></tr>
<tr><td><code id="af_+3A_qtransform">Qtransform</code></td>
<td>
<p>logical; should the functional be transformed using the empirical cdf and
applying a quantile transformation on each column of <code>X</code> prior to fitting?</p>
</td></tr>
<tr><td><code id="af_+3A_...">...</code></td>
<td>
<p>optional arguments for basis and penalization to be passed to the
function indicated by <code>basistype</code>. These could include, for example,
<code>"bs"</code>, <code>"k"</code>, <code>"m"</code>, etc. See <code><a href="mgcv.html#topic+te">te</a></code> or
<code><a href="mgcv.html#topic+s">s</a></code> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following entries:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>a <code>"call"</code> to <code>te</code> (or <code>s</code>, <code>t2</code>) using the appropriately
constructed covariate and weight matrices.</p>
</td></tr>
<tr><td><code>argvals</code></td>
<td>
<p>the <code>argvals</code> argument supplied to <code>af</code></p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>the  matrix of weights used for the integration</p>
</td></tr>
<tr><td><code>xindname</code></td>
<td>
<p>the name used for the functional predictor variable in the <code>formula</code> used by <code>mgcv</code></p>
</td></tr>
<tr><td><code>tindname</code></td>
<td>
<p>the name used for <code>argvals</code> variable in the <code>formula</code> used by <code>mgcv</code></p>
</td></tr>
<tr><td><code>Lname</code></td>
<td>
<p>the name used for the <code>L</code> variable in the <code>formula</code> used by <code>mgcv</code></p>
</td></tr>
<tr><td><code>presmooth</code></td>
<td>
<p>the <code>presmooth</code> argument supplied to <code>af</code></p>
</td></tr>
<tr><td><code>Xrange</code></td>
<td>
<p>the <code>Xrange</code> argument supplied to <code>af</code></p>
</td></tr>
<tr><td><code>prep.func</code></td>
<td>
<p>a function that preprocesses data based on the preprocessing method specified in <code>presmooth</code>. See
<code><a href="#topic+create.prep.func">create.prep.func</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mathew W. McLean <a href="mailto:mathew.w.mclean@gmail.com">mathew.w.mclean@gmail.com</a>, Fabian Scheipl,
and Jonathan Gellar
</p>


<h3>References</h3>

<p>McLean, M. W., Hooker, G., Staicu, A.-M., Scheipl, F., and Ruppert, D. (2014). Functional
generalized additive models. <em>Journal of Computational and Graphical Statistics</em>, <b>23 (1)</b>,
pp. 249-269.  Available at <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pfr">pfr</a></code>, <code><a href="#topic+lf">lf</a></code>, mgcv's <code><a href="mgcv.html#topic+linear.functional.terms">linear.functional.terms</a></code>,
<code><a href="#topic+pfr">pfr</a></code> for examples
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DTI)
## only consider first visit and cases (no PASAT scores for controls)
DTI1 &lt;- DTI[DTI$visit==1 &amp; DTI$case==1,]
DTI2 &lt;- DTI1[complete.cases(DTI1),]

## fit FGAM using FA measurements along corpus callosum
## as functional predictor with PASAT as response
## using 8 cubic B-splines for marginal bases with third
## order marginal difference penalties
## specifying gamma &gt; 1 enforces more smoothing when using
## GCV to choose smoothing parameters
fit1 &lt;- pfr(pasat ~ af(cca, k=c(8,8), m=list(c(2,3), c(2,3)),
                       presmooth="bspline", bs="ps"),
            method="GCV.Cp", gamma=1.2, data=DTI2)
plot(fit1, scheme=2)
vis.pfr(fit1)

## af term for the cca measurements plus an lf term for the rcst measurements
## leave out 10 samples for prediction
test &lt;- sample(nrow(DTI2), 10)
fit2 &lt;- pfr(pasat ~ af(cca, k=c(7,7), m=list(c(2,2), c(2,2)), bs="ps",
                       presmooth="fpca.face") +
                    lf(rcst, k=7, m=c(2,2), bs="ps"),
            method="GCV.Cp", gamma=1.2, data=DTI2[-test,])
par(mfrow=c(1,2))
plot(fit2, scheme=2, rug=FALSE)
vis.pfr(fit2, select=1, xval=.6)
pred &lt;- predict(fit2, newdata = DTI2[test,], type='response', PredOutOfRange = TRUE)
sqrt(mean((DTI2$pasat[test] - pred)^2))

## Try to predict the binary response disease status (case or control)
##   using the quantile transformed measurements from the rcst tract
##   with a smooth component for a scalar covariate that is pure noise
DTI3 &lt;- DTI[DTI$visit==1,]
DTI3 &lt;- DTI3[complete.cases(DTI3$rcst),]
z1 &lt;- rnorm(nrow(DTI3))
fit3 &lt;- pfr(case ~ af(rcst, k=c(7,7), m = list(c(2, 1), c(2, 1)), bs="ps",
                      presmooth="fpca.face", Qtransform=TRUE) +
                    s(z1, k = 10), family="binomial", select=TRUE, data=DTI3)
par(mfrow=c(1,2))
plot(fit3, scheme=2, rug=FALSE)
abline(h=0, col="green")

# 4 versions: fit with/without Qtransform, plotted with/without Qtransform
fit4 &lt;- pfr(case ~ af(rcst, k=c(7,7), m = list(c(2, 1), c(2, 1)), bs="ps",
                      presmooth="fpca.face", Qtransform=FALSE) +
                    s(z1, k = 10), family="binomial", select=TRUE, data=DTI3)
par(mfrow=c(2,2))
zlms &lt;- c(-7.2,4.3)
plot(fit4, select=1, scheme=2, main="QT=FALSE", zlim=zlms, xlab="t", ylab="rcst")
plot(fit4, select=1, scheme=2, Qtransform=TRUE, main="QT=FALSE", rug=FALSE,
     zlim=zlms, xlab="t", ylab="p(rcst)")
plot(fit3, select=1, scheme=2, main="QT=TRUE", zlim=zlms, xlab="t", ylab="rcst")
plot(fit3, select=1, scheme=2, Qtransform=TRUE, main="QT=TRUE", rug=FALSE,
     zlim=zlms, xlab="t", ylab="p(rcst)")

vis.pfr(fit3, select=1, plot.type="contour")

## End(Not run)

</code></pre>

<hr>
<h2 id='af_old'>Construct an FGAM regression term</h2><span id='topic+af_old'></span>

<h3>Description</h3>

<p>Defines a term <code class="reqn">\int_{T}F(X_i(t),t)dt</code> for inclusion in an <code>mgcv::gam</code>-formula (or
<code><a href="mgcv.html#topic+bam">bam</a></code> or <code><a href="mgcv.html#topic+gamm">gamm</a></code> or <code>gamm4:::gamm</code>) as constructed by
<code><a href="#topic+fgam">fgam</a></code>, where <code class="reqn">F(x,t)</code>$ is an unknown smooth bivariate function and <code class="reqn">X_i(t)</code>
is a functional predictor on the closed interval <code class="reqn">T</code>. Defaults to a cubic tensor product
B-spline with marginal second-order difference penalties for estimating <code class="reqn">F(x,t)</code>.  The
functional predictor must be fully observed on a regular grid
</p>


<h3>Usage</h3>

<pre><code class='language-R'>af_old(
  X,
  argvals = seq(0, 1, l = ncol(X)),
  xind = NULL,
  basistype = c("te", "t2", "s"),
  integration = c("simpson", "trapezoidal", "riemann"),
  L = NULL,
  splinepars = list(bs = "ps", k = c(min(ceiling(nrow(X)/5), 20), min(ceiling(ncol(X)/5),
    20)), m = list(c(2, 2), c(2, 2))),
  presmooth = TRUE,
  Xrange = range(X),
  Qtransform = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="af_old_+3A_x">X</code></td>
<td>
<p>an <code>N</code> by <code>J=ncol(argvals)</code> matrix of function evaluations
<code class="reqn">X_i(t_{i1}),., X_i(t_{iJ}); i=1,.,N.</code></p>
</td></tr>
<tr><td><code id="af_old_+3A_argvals">argvals</code></td>
<td>
<p>matrix (or vector) of indices of evaluations of <code class="reqn">X_i(t)</code>; i.e. a matrix with
<em>i</em>th row <code class="reqn">(t_{i1},.,t_{iJ})</code></p>
</td></tr>
<tr><td><code id="af_old_+3A_xind">xind</code></td>
<td>
<p>Same as argvals. It will discard this argument in the next version of refund.</p>
</td></tr>
<tr><td><code id="af_old_+3A_basistype">basistype</code></td>
<td>
<p>defaults to <code>"te"</code>, i.e. a tensor product spline to represent <code class="reqn">F(x,t)</code> Alternatively,
use <code>"s"</code> for bivariate basis functions (see <code><a href="mgcv.html#topic+s">s</a></code>) or <code>"t2"</code> for an alternative
parameterization of tensor product splines (see <code><a href="mgcv.html#topic+t2">t2</a></code>)</p>
</td></tr>
<tr><td><code id="af_old_+3A_integration">integration</code></td>
<td>
<p>method used for numerical integration. Defaults to <code>"simpson"</code>'s rule for
calculating entries in <code>L</code>. Alternatively and for non-equidistant grids, <code>"trapezoidal"</code>
or <code>"riemann"</code>. <code>"riemann"</code> integration is always used if <code>L</code> is specified</p>
</td></tr>
<tr><td><code id="af_old_+3A_l">L</code></td>
<td>
<p>optional weight matrix for the linear functional</p>
</td></tr>
<tr><td><code id="af_old_+3A_splinepars">splinepars</code></td>
<td>
<p>optional arguments specifying options for representing and penalizing the
function <code class="reqn">F(x,t)</code>. Defaults to a cubic tensor product B-spline with marginal second-order
difference penalties, i.e. <code>list(bs="ps", m=list(c(2, 2), c(2, 2))</code>, see <code><a href="mgcv.html#topic+te">te</a></code> or
<code><a href="mgcv.html#topic+s">s</a></code> for details</p>
</td></tr>
<tr><td><code id="af_old_+3A_presmooth">presmooth</code></td>
<td>
<p>logical; if true, the functional predictor is pre-smoothed prior to fitting; see
<code><a href="fda.html#topic+smooth.basisPar">smooth.basisPar</a></code></p>
</td></tr>
<tr><td><code id="af_old_+3A_xrange">Xrange</code></td>
<td>
<p>numeric; range to use when specifying the marginal basis for the <em>x</em>-axis.  It may
be desired to increase this slightly over the default of <code>range(X)</code> if concerned about predicting
for future observed curves that take values outside of <code>range(X)</code></p>
</td></tr>
<tr><td><code id="af_old_+3A_qtransform">Qtransform</code></td>
<td>
<p>logical; should the functional be transformed using the empirical cdf and
applying a quantile transformation on each column of <code>X</code> prior to fitting?  This ensures
<code>Xrange=c(0,1)</code>.  If <code>Qtransform=TRUE</code> and <code>presmooth=TRUE</code>, presmoothing is done prior
to transforming the functional predictor</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with the following entries:
</p>

<ol>
<li> <p><code>call</code> - a <code>"call"</code> to <code>te</code> (or <code>s</code>, <code>t2</code>) using the appropriately
constructed covariate and weight matrices.
</p>
</li>
<li> <p><code>argvals</code> - the <code>argvals</code> argument supplied to <code>af</code>
</p>
</li>
<li> <p><code>L</code>-the  matrix of weights used for the integration
</p>
</li>
<li> <p><code>xindname</code> - the name used for the functional predictor variable in the <code>formula</code> used by <code>mgcv</code>.
</p>
</li>
<li> <p><code>tindname</code> - the name used for <code>argvals</code> variable in the <code>formula</code> used by <code>mgcv</code>
</p>
</li>
<li> <p><code>Lname</code> - the name used for the <code>L</code> variable in the <code>formula</code> used by <code>mgcv</code>
</p>
</li>
<li> <p><code>presmooth</code> - the <code>presmooth</code> argument supplied to <code>af</code>
</p>
</li>
<li> <p><code>Qtranform</code> - the <code>Qtransform</code> argument supplied to <code>af</code>
</p>
</li>
<li> <p><code>Xrange</code> - the <code>Xrange</code> argument supplied to <code>af</code>
</p>
</li>
<li> <p><code>ecdflist</code> - a list containing one empirical cdf function from applying <code><a href="stats.html#topic+ecdf">ecdf</a></code>
to each (possibly presmoothed) column of <code>X</code>.  Only present if <code>Qtransform=TRUE</code>
</p>
</li>
<li> <p><code>Xfd</code> - an <code>fd</code> object from presmoothing the functional predictors using
<code><a href="fda.html#topic+smooth.basisPar">smooth.basisPar</a></code>.  Only present if <code>presmooth=TRUE</code>.  See <code><a href="fda.html#topic+fd">fd</a></code>.
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Mathew W. McLean <a href="mailto:mathew.w.mclean@gmail.com">mathew.w.mclean@gmail.com</a> and Fabian Scheipl
</p>


<h3>References</h3>

<p>McLean, M. W., Hooker, G., Staicu, A.-M., Scheipl, F., and Ruppert, D. (2014). Functional
generalized additive models. <em>Journal of Computational and Graphical Statistics</em>, <b>23 (1)</b>,
pp. 249-269.  Available at <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fgam">fgam</a></code>, <code><a href="#topic+lf">lf</a></code>, mgcv's <code><a href="mgcv.html#topic+linear.functional.terms">linear.functional.terms</a></code>,
<code><a href="#topic+fgam">fgam</a></code> for examples
</p>

<hr>
<h2 id='amc'>Additive model with constraints</h2><span id='topic+amc'></span>

<h3>Description</h3>

<p>An internal function, called by <code>fosr()</code>, that fits additive models
with linear constraints via a call to <code><a href="mgcv.html#topic+gam">gam</a></code> or
<code><a href="mgcv.html#topic+bam">bam</a></code> in the <span class="pkg">mgcv</span> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>amc(y, Xmat, S, gam.method = "REML", C = NULL, lambda = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="amc_+3A_y">y</code></td>
<td>
<p>response vector.</p>
</td></tr>
<tr><td><code id="amc_+3A_xmat">Xmat</code></td>
<td>
<p>design matrix.</p>
</td></tr>
<tr><td><code id="amc_+3A_s">S</code></td>
<td>
<p>list of penalty matrices.</p>
</td></tr>
<tr><td><code id="amc_+3A_gam.method">gam.method</code></td>
<td>
<p>smoothing parameter selection method: &quot;REML&quot; for
restricted maximum likelihood, &quot;GCV.Cp&quot; for generalized cross-validation.</p>
</td></tr>
<tr><td><code id="amc_+3A_c">C</code></td>
<td>
<p>matrix of linear constraints.  Dimension should be number of
constraints times <code>ncol(Xmat)</code>.</p>
</td></tr>
<tr><td><code id="amc_+3A_lambda">lambda</code></td>
<td>
<p>smoothing parameter value.  If <code>NULL</code>, the smoothing
parameter(s) will be estimated.</p>
</td></tr>
<tr><td><code id="amc_+3A_...">...</code></td>
<td>
<p>other arguments, passed to <code><a href="mgcv.html#topic+gam">gam</a></code> or
<code><a href="mgcv.html#topic+bam">bam</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The additive model is fitted using <code><a href="mgcv.html#topic+gam">gam</a></code>, unless there
are more than 10000 responses; in that case <code><a href="mgcv.html#topic+bam">bam</a></code> is
used.
</p>


<h3>Value</h3>

<p>A list with the following elements: </p>
<table>
<tr><td><code>gam</code></td>
<td>
<p>the <code>gam</code>
object returned by <code>gam</code> or <code>bam</code>.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>coefficients with respect to design matrix <code>Xmat</code>,
derived from the <code>gam()</code> fit.</p>
</td></tr> <tr><td><code>Vp</code>, <code>GinvXt</code></td>
<td>
<p>outputs used by
<code>fosr</code>.</p>
</td></tr> <tr><td><code>method</code></td>
<td>
<p>the <code>gam.method</code> argument of the call to
<code>amc</code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fosr">fosr</a></code>
</p>

<hr>
<h2 id='bayes_fosr'>Bayesian Function-on-scalar regression</h2><span id='topic+bayes_fosr'></span>

<h3>Description</h3>

<p>Wrapper function that implements several approaches to Bayesian function-
on-scalar regression. Currently handles real-valued response curves; models
can include subject-level random effects in a multilevel framework. The 
residual curve error structure can be estimated using Bayesian FPCA or a 
Wishart prior. Model parameters can be estimated using a Gibbs sampler
or variational Bayes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bayes_fosr(formula, data = NULL, est.method = "VB", cov.method = "FPCA", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bayes_fosr_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model. 
Random intercepts are designated using <code><a href="#topic+re">re</a></code>().</p>
</td></tr>
<tr><td><code id="bayes_fosr_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the 
variables in the model. If not found in data, the variables are taken from 
environment(formula), typically the environment from which the function is 
called.</p>
</td></tr>
<tr><td><code id="bayes_fosr_+3A_est.method">est.method</code></td>
<td>
<p>method used to estimate model parameters. Options are &quot;VB&quot;,
&quot;Gibbs&quot;, and &quot;GLS&quot; with &quot;VB&quot; as default. Variational Bayes is a fast approximation to
the full posterior and often provides good point estimates, but may be 
unreliable for inference. &quot;GLS&quot; doesn't do anything Bayesian &ndash; just fits an
unpenalized GLS estimator for the specified model.</p>
</td></tr>
<tr><td><code id="bayes_fosr_+3A_cov.method">cov.method</code></td>
<td>
<p>method used to estimate the residual covariance structure.
Options are &quot;FPCA&quot; and &quot;Wishart&quot;, with default &quot;FPCA&quot;</p>
</td></tr>
<tr><td><code id="bayes_fosr_+3A_...">...</code></td>
<td>
<p>additional arguments that are passed to individual fitting functions.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

library(reshape2)
library(dplyr)
library(ggplot2)

##### Cross-sectional real-data examples #####

## organize data
data(DTI)
DTI = subset(DTI, select = c(cca, case, pasat))
DTI = DTI[complete.cases(DTI),]
DTI$gender = factor(sample(c("male","female"), dim(DTI)[1], replace = TRUE))
DTI$status = factor(sample(c("RRMS", "SPMS", "PPMS"), dim(DTI)[1], replace = TRUE))

## fit models
default = bayes_fosr(cca ~ pasat, data = DTI)
VB = bayes_fosr(cca ~ pasat, data = DTI, Kp = 4, Kt = 10)
Gibbs = bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "Gibbs", cov.method = "Wishart",
                   N.iter = 500, N.burn = 200)
OLS = bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "OLS")
GLS = bayes_fosr(cca ~ pasat, data = DTI, Kt = 10, est.method = "GLS")

## plot results
models = c("default", "VB", "Gibbs", "OLS", "GLS")
intercepts = sapply(models, function(u) get(u)$beta.hat[1,])
slopes = sapply(models, function(u) get(u)$beta.hat[2,])

plot.dat = melt(intercepts); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) + 
   geom_path() + theme_bw()

plot.dat = melt(slopes); colnames(plot.dat) = c("grid", "method", "value")
ggplot(plot.dat, aes(x = grid, y = value, group = method, color = method)) + 
   geom_path() + theme_bw()

## fit a model with an interaction
fosr.dti.interaction = bayes_fosr(cca ~ pasat*gender, data = DTI, Kp = 4, Kt = 10)


##### Longitudinal real-data examples #####

data(DTI2)
class(DTI2$cca) = class(DTI2$cca)[-1]
DTI2 = subset(DTI2, select = c(cca, id, pasat))
DTI2 = DTI2[complete.cases(DTI2),]

default = bayes_fosr(cca ~ pasat + re(id), data = DTI2)
VB = bayes_fosr(cca ~ pasat + re(id), data = DTI2, Kt = 10, cov.method = "Wishart")


## End(Not run)

</code></pre>

<hr>
<h2 id='ccb.fpc'>Corrected confidence bands using functional principal components</h2><span id='topic+ccb.fpc'></span>

<h3>Description</h3>

<p>Uses iterated expectation and variances to obtain corrected estimates and
inference for functional expansions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ccb.fpc(
  Y,
  argvals = NULL,
  nbasis = 10,
  pve = 0.99,
  n.boot = 100,
  simul = FALSE,
  sim.alpha = 0.95
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ccb.fpc_+3A_y">Y</code></td>
<td>
<p>matrix of observed functions for which estimates and covariance
matrices are desired.</p>
</td></tr>
<tr><td><code id="ccb.fpc_+3A_argvals">argvals</code></td>
<td>
<p>numeric; function argument.</p>
</td></tr>
<tr><td><code id="ccb.fpc_+3A_nbasis">nbasis</code></td>
<td>
<p>number of splines used in the estimation of the mean function
and the bivariate smoothing of the covariance matrix</p>
</td></tr>
<tr><td><code id="ccb.fpc_+3A_pve">pve</code></td>
<td>
<p>proportion of variance explained used to choose the number of
principal components to be included in the expansion.</p>
</td></tr>
<tr><td><code id="ccb.fpc_+3A_n.boot">n.boot</code></td>
<td>
<p>number of bootstrap iterations used to estimate the
distribution of FPC decomposition objects.</p>
</td></tr>
<tr><td><code id="ccb.fpc_+3A_simul">simul</code></td>
<td>
<p>TRUE or FALSE, indicating whether critical values for
simultaneous confidence intervals should be estimated</p>
</td></tr>
<tr><td><code id="ccb.fpc_+3A_sim.alpha">sim.alpha</code></td>
<td>
<p>alpha level of the simultaneous intervals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To obtain corrected curve estimates and variances, this function accounts
for uncertainty in FPC decomposition objects. Observed curves are
resampled, and a FPC decomposition for each sample is constructed. A
mixed-model framework is used to estimate curves and variances conditional
on each decomposition, and iterated expectation and variances combines both
model-based and decomposition-based uncertainty.
</p>


<h3>Value</h3>

<table>
<tr><td><code>Yhat</code></td>
<td>
<p>a matrix whose rows are the estimates of the curves in
<code>Y</code>.</p>
</td></tr> <tr><td><code>Yhat.boot</code></td>
<td>
<p>a list containing the estimated curves within
each bootstrap iteration.</p>
</td></tr> <tr><td><code>diag.var</code></td>
<td>
<p>diagonal elements of the
covariance matrices for each estimated curve.</p>
</td></tr> <tr><td><code>VarMats</code></td>
<td>
<p>a list
containing the estimated covariance matrices for each curve in <code>Y</code>.</p>
</td></tr>
<tr><td><code>crit.val</code></td>
<td>
<p>estimated critical values for constructing simultaneous
confidence intervals.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:jeff.goldsmith@columbia.edu">jeff.goldsmith@columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Greven, S., and Crainiceanu, C. (2013).
Corrected confidence bands for functional data using principal components.
<em>Biometrics</em>, 69(1), 41&ndash;51.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
data(cd4)

# obtain a subsample of the data with 25 subjects
set.seed(1236)
sample = sample(1:dim(cd4)[1], 25)
Y.sub = cd4[sample,]

# obtain a mixed-model based FPCA decomposition
Fit.MM = fpca.sc(Y.sub, var = TRUE, simul = TRUE)

# use iterated variance to obtain curve estimates and variances
Fit.IV = ccb.fpc(Y.sub, n.boot = 25, simul = TRUE)

# for one subject, examine curve estimates, pointwise and simultaneous itervals
EX = 2
EX.IV =  cbind(Fit.IV$Yhat[EX,],
      Fit.IV$Yhat[EX,] + 1.96 * sqrt(Fit.IV$diag.var[EX,]),
      Fit.IV$Yhat[EX,] - 1.96 * sqrt(Fit.IV$diag.var[EX,]),
      Fit.IV$Yhat[EX,] + Fit.IV$crit.val[EX] * sqrt(Fit.IV$diag.var[EX,]),
      Fit.IV$Yhat[EX,] - Fit.IV$crit.val[EX] * sqrt(Fit.IV$diag.var[EX,]))

EX.MM =  cbind(Fit.MM$Yhat[EX,],
      Fit.MM$Yhat[EX,] + 1.96 * sqrt(Fit.MM$diag.var[EX,]),
      Fit.MM$Yhat[EX,] - 1.96 * sqrt(Fit.MM$diag.var[EX,]),
      Fit.MM$Yhat[EX,] + Fit.MM$crit.val[EX] * sqrt(Fit.MM$diag.var[EX,]),
      Fit.MM$Yhat[EX,] - Fit.MM$crit.val[EX] * sqrt(Fit.MM$diag.var[EX,]))

# plot data for one subject, with curve and interval estimates
d = as.numeric(colnames(cd4))
plot(d[which(!is.na(Y.sub[EX,]))], Y.sub[EX,which(!is.na(Y.sub[EX,]))], type = 'o',
  pch = 19, cex=.75, ylim = range(0, 3400), xlim = range(d),
    xlab = "Months since seroconversion", lwd = 1.2, ylab = "Total CD4 Cell Count",
      main = "Est. &amp; CI - Sampled Data")

matpoints(d, EX.IV, col = 2, type = 'l', lwd = c(2, 1, 1, 1, 1), lty = c(1,1,1,2,2))
matpoints(d, EX.MM, col = 4, type = 'l', lwd = c(2, 1, 1, 1, 1), lty = c(1,1,1,2,2))

legend("topright", c("IV Est", "IV PW Int", "IV Simul Int",
    expression(paste("MM - ", hat(theta), " Est", sep = "")),
    expression(paste("MM - ", hat(theta), " PW Int", sep = "")),
    expression(paste("MM - ", hat(theta), " Simul Int", sep = ""))),
    lty=c(1,1,2,1,1,2), lwd = c(2.5,.75,.75,2.5,.75,.75),
    col = c("red","red","red","blue","blue","blue"))

## End(Not run)
</code></pre>

<hr>
<h2 id='cd4'>Observed CD4 cell counts</h2><span id='topic+cd4'></span>

<h3>Description</h3>

<p>CD4 cell counts for 366 subjects between months -18 and 42 since
seroconversion. Each subject's observations are contained in a single row.
</p>


<h3>Format</h3>

<p>A data frame made up of a 366 x 61 matrix of CD4 cell counts
</p>


<h3>References</h3>

<p>Goldsmith, J., Greven, S., and Crainiceanu, C. (2013).
Corrected confidence bands for functional data using principal components.
<em>Biometrics</em>, 69(1), 41&ndash;51.
</p>

<hr>
<h2 id='cmdscale_lanczos'>Faster multi-dimensional scaling</h2><span id='topic+cmdscale_lanczos'></span>

<h3>Description</h3>

<p>This is a modified version of <code><a href="stats.html#topic+cmdscale">cmdscale</a></code> that uses the Lanczos
procedure (<code><a href="mgcv.html#topic+slanczos">slanczos</a></code>) instead of <code>eigen</code>. Called by
<code><a href="#topic+smooth.construct.pco.smooth.spec">smooth.construct.pco.smooth.spec</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cmdscale_lanczos(d, k = 2, eig = FALSE, add = FALSE, x.ret = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cmdscale_lanczos_+3A_d">d</code></td>
<td>
<p>a distance structure as returned by <code><a href="stats.html#topic+dist">dist</a></code>, or a full
symmetric matrix of distances or dissimilarities.</p>
</td></tr>
<tr><td><code id="cmdscale_lanczos_+3A_k">k</code></td>
<td>
<p>the maximum dimension of the space which the data are to be
represented in; must be in <code>{1, 2, ..., n-1}</code>.</p>
</td></tr>
<tr><td><code id="cmdscale_lanczos_+3A_eig">eig</code></td>
<td>
<p>logical indicating whether eigenvalues should be returned.</p>
</td></tr>
<tr><td><code id="cmdscale_lanczos_+3A_add">add</code></td>
<td>
<p>logical indicating if the additive constant of Cailliez (1983)
should be computed, and added to the non-diagonal dissimilarities such that
the modified dissimilarities are Euclidean.</p>
</td></tr>
<tr><td><code id="cmdscale_lanczos_+3A_x.ret">x.ret</code></td>
<td>
<p>indicates whether the doubly centred symmetric distance matrix
should be returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>as <code><a href="stats.html#topic+cmdscale">cmdscale</a></code>
</p>


<h3>Author(s)</h3>

<p>David L Miller, based on code by R Core.
</p>


<h3>References</h3>

<p>Cailliez, F. (1983). The analytical solution of the additive constant problem.
<em>Psychometrika</em>, 48, 343-349.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+smooth.construct.pco.smooth.spec">smooth.construct.pco.smooth.spec</a></code>
</p>

<hr>
<h2 id='coef.pffr'>Get estimated coefficients from a pffr fit</h2><span id='topic+coef.pffr'></span>

<h3>Description</h3>

<p>Returns estimated coefficient functions/surfaces <code class="reqn">\beta(t), \beta(s,t)</code>
and estimated smooth effects <code class="reqn">f(z), f(x,z)</code> or <code class="reqn">f(x, z, t)</code> and their point-wise estimated standard errors.
Not implemented for smooths in more than 3 dimensions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pffr'
coef(
  object,
  raw = FALSE,
  se = TRUE,
  freq = FALSE,
  sandwich = FALSE,
  seWithMean = TRUE,
  n1 = 100,
  n2 = 40,
  n3 = 20,
  Ktt = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.pffr_+3A_object">object</code></td>
<td>
<p>a fitted <code>pffr</code>-object</p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_raw">raw</code></td>
<td>
<p>logical, defaults to FALSE. If TRUE, the function simply returns <code>object$coefficients</code></p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_se">se</code></td>
<td>
<p>logical, defaults to TRUE. Return estimated standard error of the estimates?</p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_freq">freq</code></td>
<td>
<p>logical, defaults to FALSE. If FALSE, use posterior variance <code>object$Vp</code> for variability estimates,
else use <code>object$Ve</code>. See <code><a href="mgcv.html#topic+gamObject">gamObject</a></code></p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_sandwich">sandwich</code></td>
<td>
<p>logical, defaults to FALSE. Use a Sandwich-estimator for approximate variances? See Details.
THIS IS AN EXPERIMENTAL FEATURE, USE A YOUR OWN RISK.</p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_sewithmean">seWithMean</code></td>
<td>
<p>logical, defaults to TRUE. Include uncertainty about the intercept/overall mean in  standard errors returned for smooth components?</p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_n1">n1</code></td>
<td>
<p>see below</p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_n2">n2</code></td>
<td>
<p>see below</p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_n3">n3</code></td>
<td>
<p><code>n1, n2, n3</code> give the number of gridpoints for 1-/2-/3-dimensional smooth terms
used in the marginal equidistant grids over the range of the covariates at which the estimated effects are evaluated.</p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_ktt">Ktt</code></td>
<td>
<p>(optional) an estimate of the covariance operator of the residual process <code class="reqn">\epsilon_i(t) \sim N(0, K(t,t'))</code>,
evaluated on <code>yind</code> of <code>object</code>. If not supplied, this is estimated from the crossproduct matrices of the
observed residual vectors. Only relevant for sandwich CIs.</p>
</td></tr>
<tr><td><code id="coef.pffr_+3A_...">...</code></td>
<td>
<p>other arguments, not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>seWithMean</code>-option corresponds to the <code>"iterms"</code>-option in <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>.
The <code>sandwich</code>-options works as follows: Assuming that the residual vectors <code class="reqn">\epsilon_i(t), i=1,\dots,n</code> are i.i.d.
realizations of a mean zero Gaussian process with covariance <code class="reqn">K(t,t')</code>, we can construct an estimator for
<code class="reqn">K(t,t')</code> from the <code class="reqn">n</code> replicates of the observed residual vectors. The covariance matrix of the stacked observations
vec<code class="reqn">(Y_i(t))</code> is then given by a block-diagonal matrix with <code class="reqn">n</code> copies of the estimated <code class="reqn">K(t,t')</code> on the diagonal.
This block-diagonal matrix is used to construct the &quot;meat&quot; of a sandwich covariance estimator, similar to Chen et al. (2012),
see reference below.
</p>


<h3>Value</h3>

<p>If <code>raw==FALSE</code>, a list containing </p>

<ul>
<li> <p><code>pterms</code> a matrix containing the parametric / non-functional coefficients (and, optionally, their se's)
</p>
</li>
<li> <p><code>smterms</code> a named list with one entry for each smooth term in the model. Each entry contains
</p>

<ul>
<li> <p><code>coef</code> a matrix giving the grid values over the covariates, the estimated effect (and, optionally, the se's).
The first covariate varies the fastest.
</p>
</li>
<li> <p><code>x, y, z</code> the unique gridpoints used to evaluate the smooth/coefficient function/coefficient surface
</p>
</li>
<li> <p><code>xlim, ylim, zlim</code> the extent of the x/y/z-axes
</p>
</li>
<li> <p><code>xlab, ylab, zlab</code> the names of the covariates for the x/y/z-axes
</p>
</li>
<li> <p><code>dim</code> the dimensionality of the effect
</p>
</li>
<li> <p><code>main</code> the label of the smooth term (a short label, same as the one used in <code>summary.pffr</code>)
</p>
</li></ul>
</li></ul>



<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>


<h3>References</h3>

<p>Chen, H., Wang, Y., Paik, M.C., and Choi, A. (2013).
A marginal approach to reduced-rank penalized spline smoothing with application to multilevel functional data.
<em>Journal of the American Statistical Association</em>, 101, 1216&ndash;1229.
</p>


<h3>See Also</h3>

<p><code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code>, <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> which this routine is
based on.
</p>

<hr>
<h2 id='coefboot.pffr'>Simple bootstrap CIs for pffr</h2><span id='topic+coefboot.pffr'></span>

<h3>Description</h3>

<p>This function resamples observations in the data set to obtain approximate CIs for different
terms and coefficient functions that correct for the effects of dependency and heteroskedasticity
of the residuals along the index of the functional response, i.e., it aims for correct inference
if the residuals along the index of the functional response are not i.i.d.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>coefboot.pffr(
  object,
  n1 = 100,
  n2 = 40,
  n3 = 20,
  B = 100,
  ncpus = getOption("boot.ncpus", 1),
  parallel = c("no", "multicore", "snow"),
  cl = NULL,
  conf = c(0.9, 0.95),
  type = "percent",
  method = c("resample", "residual", "residual.c"),
  showProgress = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coefboot.pffr_+3A_object">object</code></td>
<td>
<p>a fitted <code><a href="#topic+pffr">pffr</a></code>-model</p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_n1">n1</code></td>
<td>
<p>see <code><a href="#topic+coef.pffr">coef.pffr</a></code></p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_n2">n2</code></td>
<td>
<p>see <code><a href="#topic+coef.pffr">coef.pffr</a></code></p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_n3">n3</code></td>
<td>
<p>see <code><a href="#topic+coef.pffr">coef.pffr</a></code></p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_b">B</code></td>
<td>
<p>number of bootstrap replicates, defaults to (a measly) 100</p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_ncpus">ncpus</code></td>
<td>
<p>see <code><a href="boot.html#topic+boot">boot</a></code>. Defaults to <code>getOption("boot.ncpus", 1L)</code> (like <code>boot</code>).</p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_parallel">parallel</code></td>
<td>
<p>see <code><a href="boot.html#topic+boot">boot</a></code></p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_cl">cl</code></td>
<td>
<p>see <code><a href="boot.html#topic+boot">boot</a></code></p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_conf">conf</code></td>
<td>
<p>desired levels of bootstrap CIs, defaults to 0.90 and 0.95</p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_type">type</code></td>
<td>
<p>type of bootstrap interval, see <code><a href="boot.html#topic+boot.ci">boot.ci</a></code>. Defaults to &quot;percent&quot; for percentile-based CIs.</p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_method">method</code></td>
<td>
<p>either &quot;resample&quot; (default) to resample response trajectories, or &quot;residual&quot; to resample responses as fitted values
plus residual trajectories or &quot;residual.c&quot; to resample responses as fitted values
plus residual trajectories that are centered at zero for each gridpoint.</p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_showprogress">showProgress</code></td>
<td>
<p>TRUE/FALSE</p>
</td></tr>
<tr><td><code id="coefboot.pffr_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with similar structure as the return value of <code><a href="#topic+coef.pffr">coef.pffr</a></code>, containing the
original point estimates of the various terms along with their bootstrap CIs.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>

<hr>
<h2 id='coefficients.pfr'>Extract coefficient functions from a fitted pfr-object</h2><span id='topic+coefficients.pfr'></span><span id='topic+coef.pfr'></span>

<h3>Description</h3>

<p>This function is used to extract a coefficient from a fitted 'pfr' model, in
particular smooth functions resulting from including functional terms specified
with <code>lf</code>, <code>af</code>, etc. It can also be used to extract smooths
genereated using <code>mgcv</code>'s <code>s</code>, <code>te</code>, or <code>t2</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pfr'
coefficients(
  object,
  select = 1,
  coords = NULL,
  n = NULL,
  se = ifelse(length(object$smooth) &amp; select, TRUE, FALSE),
  seWithMean = FALSE,
  useVc = TRUE,
  Qtransform = FALSE,
  ...
)

## S3 method for class 'pfr'
coef(
  object,
  select = 1,
  coords = NULL,
  n = NULL,
  se = ifelse(length(object$smooth) &amp; select, TRUE, FALSE),
  seWithMean = FALSE,
  useVc = TRUE,
  Qtransform = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coefficients.pfr_+3A_object">object</code></td>
<td>
<p>return object from <code><a href="#topic+pfr">pfr</a></code></p>
</td></tr>
<tr><td><code id="coefficients.pfr_+3A_select">select</code></td>
<td>
<p>integer indicating the index of the desired smooth term
in <code>object$smooth</code>. Enter 0 to request the raw coefficients
(i.e., <code>object$coefficients</code>) and standard errors (if <code>se==TRUE</code>).</p>
</td></tr>
<tr><td><code id="coefficients.pfr_+3A_coords">coords</code></td>
<td>
<p>named list indicating the desired coordinates where the
coefficient function is to be evaluated. Names must match the argument names
in <code>object$smooth[[select]]$term</code>. If <code>NULL</code>, uses <code>n</code>
to generate equally-spaced coordinates.</p>
</td></tr>
<tr><td><code id="coefficients.pfr_+3A_n">n</code></td>
<td>
<p>integer vector indicating the number of equally spaced coordinates
for each argument. If length 1, the same number is used for each argument.
Otherwise, the length must match <code>object$smooth[[select]]$dim</code>.</p>
</td></tr>
<tr><td><code id="coefficients.pfr_+3A_se">se</code></td>
<td>
<p>if <code>TRUE</code>, returns pointwise standard error estimates. Defaults
to <code>FALSE</code> if raw coefficients are being returned; otherwise <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="coefficients.pfr_+3A_sewithmean">seWithMean</code></td>
<td>
<p>if <code>TRUE</code> the standard errors include uncertainty about
the overall mean; if <code>FALSE</code>, they relate purely to the centered
smooth itself. Marra and Wood (2012) suggests that <code>TRUE</code> results in
better coverage performance for GAMs.</p>
</td></tr>
<tr><td><code id="coefficients.pfr_+3A_usevc">useVc</code></td>
<td>
<p>if <code>TRUE</code>, standard errors are calculated using a covariance
matrix that has been corrected for smoothing parameter uncertainty. This
matrix will only be available under ML or REML smoothing.</p>
</td></tr>
<tr><td><code id="coefficients.pfr_+3A_qtransform">Qtransform</code></td>
<td>
<p>For additive functional terms, <code>TRUE</code> indicates the
coefficient should be extracted on the quantile-transformed scale, whereas
<code>FALSE</code> indicates the scale of the original data. Note this is
different from the <code>Qtransform</code> arguemnt of <code>af</code>, which specifies
the scale on which the term is fit.</p>
</td></tr>
<tr><td><code id="coefficients.pfr_+3A_...">...</code></td>
<td>
<p>these arguments are ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a data frame containing the evaluation points,
coefficient function values and optionally the SE's for the term indicated
by <code>select</code>.
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar and Fabian Scheipl
</p>


<h3>References</h3>

<p>Marra, G and S.N. Wood (2012) Coverage Properties of Confidence Intervals for
Generalized Additive Model Components. Scandinavian Journal of Statistics.
</p>

<hr>
<h2 id='content'>The CONTENT child growth study</h2><span id='topic+content'></span>

<h3>Description</h3>

<p>The CONTENT child growth study was funded by the Sixth Framework Programme 
of the European Union, Project CONTENT (INCO-DEV-3-032136) and was led by 
Dr. William Checkley. The study was conducted between May 2007 and February 
2011 in Las Pampas de San Juan Miraflores and Nuevo Paraiso, two peri-urban 
shanty towns with high population density located on the southern edge of 
Lima city in Peru.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(content)
</code></pre>


<h3>Format</h3>

<p>A list made up of </p>

<dl>
<dt>id</dt><dd><p>Numeric vector of subject ID numbers;</p>
</dd>
<dt>ma1fe0</dt><dd><p>Numeric vector of the sex of the child, 1 for male and 0 for female;</p>
</dd>
<dt>weightkg</dt><dd><p>Numeric vector of the weight of the child measured in kilograms(kg);</p>
</dd>
<dt>height</dt><dd><p>Numeric vector of the height of the child measured in centimeters;</p>
</dd>
<dt>agedays</dt><dd><p>Numeric vector of the age of the child measured in days;</p>
</dd>
<dt>cbmi</dt><dd><p>Numeric vector of the BMI of the child;</p>
</dd>
<dt>zlen</dt><dd><p>Numeric vector of the height-for-age z-scores;</p>
</dd>
<dt>zwei</dt><dd><p>Numeric vector of the weight-for-age z-scores;</p>
</dd>
<dt>zwfl</dt><dd><p>Numeric vector of the weight-for-height z-scores;</p>
</dd>
<dt>zbmi</dt><dd><p>Numeric vector of the BMI-for-age z-scores;</p>
</dd>
</dl>



<h3>References</h3>

<p>Crainiceanu, C., Goldsmith, J., Leroux, A., Cui, E. (2023). Functional
Data Analysis with R. <em>Chapman &amp; Hall/CRC Statistics</em>
</p>

<hr>
<h2 id='COVID19'>The US weekly all-cause mortality and COVID19-associated deaths in 2020</h2><span id='topic+COVID19'></span>

<h3>Description</h3>

<p>The COVID19 mortality data used in the &quot;Functional Data Analysis with R&quot; book
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(COVID19)
</code></pre>


<h3>Format</h3>

<p>A list made up of </p>

<dl>
<dt>US_weekly_mort</dt><dd><p>A numeric vector of length 207, which contains the 
total number of weekly all-cause deaths in the US from January 14, 2017 to December 26, 2020;</p>
</dd>
<dt>US_weekly_mort_dates</dt><dd><p>A vector of dates of length 207, which contains 
the weeks corresponding to the US_weekly_mort vector;</p>
</dd>
<dt>US_weekly_mort_CV19</dt><dd><p>A numeric vector of length 52, which contains the 
total number of weekly COVID 19 deaths in the US from January 4, 2020 to December 26, 2020;</p>
</dd>
<dt>US_weekly_mort_CV19_dates</dt><dd><p>A vector of dates of length 52, which contains 
the weeks corresponding to the US_weekly_mort_CV19 vector;</p>
</dd>
<dt>US_weekly_excess_mort_2020</dt><dd><p>A numeric vector of length 52, which contains 
the US weekly excess mortality (total mortality in one week in 2020 minus 
total mortality in the corresponding week of 2019) from January 4, 2020 to December 26, 2020;</p>
</dd>
<dt>US_weekly_excess_mort_2020_dates</dt><dd><p>A vector dates of length 52, which contains 
the weeks corresponding to the US_weekly_excess_mort_2020 vector.;</p>
</dd>
<dt>US_states_names</dt><dd><p>A vector of strings containing the names of 52 US states 
and territories in alphabetic order. These are the states for which all-cause 
and Covid-19 data are available in this data set;</p>
</dd>
<dt>US_states_population</dt><dd><p>A numeric vector containing the population of the 
52 states in the vector US_states_names estimated as of July 1, 2020. The 
order of the vector US_states_population is the same as that of US_states_names;</p>
</dd>
<dt>States_excess_mortality</dt><dd><p>A numeric 52 x 52 dimensional matrix that 
contains the weekly US excess mortality in 52 states and territories. Each 
row corresponds to one state in the same order as the vector US_states_names. 
Each column corresponds to a week in 2020 corresponding to the order in the 
vector US_weekly_excess_mort_2020_dates. The (i,j)th entry of the matrix is 
the difference in all-cause mortality during the week j of 2020 and 2019 for state i;</p>
</dd>
<dt>States_excess_mortality_per_million</dt><dd><p>A numeric 52 x 52 dimensional matrix 
that contains the weekly US excess mortality in 52 states and territories 
per one million individuals. This is obtained by dividing every row (corresponding 
to a state) of States_excess_mortality by the population of that state stored 
in US_states_population and multiplying by one million;</p>
</dd>
<dt>States_CV19_mortality</dt><dd><p>A numeric 52 x 52 dimensional matrix that contains 
the weekly US Covid-19 mortality in 52 states and territories. Each row 
corresponds to one state in the same order as the vector US_states_names. Each 
column corresponds to a week in 2020 corresponding to the order in the 
vector US_weekly_excess_mort_2020_dates;</p>
</dd>
<dt>States_CV19_mortality_per_million</dt><dd><p>A numeric 52 x 52 dimensional matrix 
that contains the weekly US Covid-19 mortality in 52 states and territories 
per one million individuals. This is obtained by dividing every row (corresponding 
to a state) of States_CV19_mortality by the population of that state stored 
in US_states_population and multiplying by one million.</p>
</dd>
</dl>



<h3>References</h3>

<p>Crainiceanu, C., Goldsmith, J., Leroux, A., Cui, E. (2023). Functional
Data Analysis with R. <em>Chapman &amp; Hall/CRC Statistics</em>
</p>

<hr>
<h2 id='create.prep.func'>Construct a function for preprocessing functional predictors</h2><span id='topic+create.prep.func'></span>

<h3>Description</h3>

<p>Prior to using functions <code>X</code> as predictors in a scalar-on-function regression, it is often
necessary to presmooth curves to remove measurement error or interpolate to a common grid. This
function creates a function to do this preprocessing depending on the method specified.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.prep.func(
  X,
  argvals = seq(0, 1, length = ncol(X)),
  method = c("fpca.sc", "fpca.face", "fpca.ssvd", "bspline", "interpolate"),
  options = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create.prep.func_+3A_x">X</code></td>
<td>
<p>an <code>N</code> by <code>J=ncol(argvals)</code> matrix of function evaluations
<code class="reqn">X_i(t_{i1}),., X_i(t_{iJ}); i=1,.,N.</code> For FPCA-based processing methods, these functions are
used to define the eigen decomposition used to preprocess current and future data (for example, in
<code><a href="#topic+predict.pfr">predict.pfr</a></code>)</p>
</td></tr>
<tr><td><code id="create.prep.func_+3A_argvals">argvals</code></td>
<td>
<p>matrix (or vector) of indices of evaluations of <code class="reqn">X_i(t)</code>; i.e. a matrix with
<em>i</em>th row <code class="reqn">(t_{i1},.,t_{iJ})</code></p>
</td></tr>
<tr><td><code id="create.prep.func_+3A_method">method</code></td>
<td>
<p>character string indicating the preprocessing method. Options
are <code>"fpca.sc"</code>, <code>"fpca.face"</code>, <code>"fpca.ssvd"</code>, <code>"bspline"</code>,
and <code>"interpolate"</code>. The first three use the corresponding existing function;
<code>"bspline"</code> uses an (unpenalized) cubic bspline smoother with <code>nbasis</code> basis 
functions; <code>"interpolate"</code> uses linear interpolation.</p>
</td></tr>
<tr><td><code id="create.prep.func_+3A_options">options</code></td>
<td>
<p>list of options passed to the preprocessing method; as an example, options for <code>fpca.sc</code>
include <code>pve</code>, <code>nbasis</code>, and <code>npc</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a function that returns the preprocessed functional predictors, with arguments
</p>
<table>
<tr><td><code>newX</code></td>
<td>
<p>The functional predictors to process</p>
</td></tr>
<tr><td><code>argvals.</code></td>
<td>
<p>Indices of evaluation of <code>newX</code></p>
</td></tr>
<tr><td><code>options.</code></td>
<td>
<p>Any options needed to preprocess the predictor functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pfr">pfr</a></code>, <code><a href="#topic+fpca.sc">fpca.sc</a></code>, <code><a href="#topic+fpca.face">fpca.face</a></code>, <code><a href="#topic+fpca.ssvd">fpca.ssvd</a></code>
</p>

<hr>
<h2 id='DTI'>Diffusion Tensor Imaging: tract profiles and outcomes</h2><span id='topic+DTI'></span>

<h3>Description</h3>

<p>Fractional anisotropy (FA) tract profiles for the corpus callosum (cca) and
the right corticospinal tract (rcst). Accompanying the tract profiles are
the subject ID numbers, visit number, total number of scans, multiple
sclerosis case status and Paced Auditory Serial Addition Test (pasat)
score.
</p>


<h3>Format</h3>

<p>A data frame made up of </p>

<dl>
<dt>cca</dt><dd><p>A 382 x 93
matrix of fractional anisotropy tract profiles from the corpus
callosum;</p>
</dd>
<dt>rcst</dt><dd><p>A 382 x 55 matrix
of fractional anisotropy tract profiles from the right corticospinal
tract;</p>
</dd>
<dt>ID</dt><dd><p>Numeric vector of subject ID numbers;</p>
</dd>
<dt>visit</dt><dd><p>Numeric vector of the subject-specific visit
numbers;</p>
</dd>
<dt>visit.time</dt><dd><p>Numeric vector of the subject-specific visit time, measured
in days since first visit;</p>
</dd>
<dt>Nscans</dt><dd><p>Numeric vector indicating the total number of visits
for each subject;</p>
</dd>
<dt>case</dt><dd><p>Numeric vector of multiple sclerosis case status: 0 - healthy control, 1 - MS case;</p>
</dd>
<dt>sex</dt><dd><p>factor variable indicated subject's sex;</p>
</dd>
<dt>pasat</dt><dd><p>Numeric vector containing the PASAT score at
each visit.</p>
</dd>
</dl>



<h3>Details</h3>

<p>If you use this data as an example in written work, please include the
following acknowledgment: &ldquo;The MRI/DTI data were collected at Johns
Hopkins University and the Kennedy-Krieger Institute&quot;
</p>
<p>DTI2 uses mean diffusivity of the the corpus callosum rather than FA, and
parallel diffusivity of the rcst rather than FA. Please see the
documentation for DTI2.
</p>


<h3>References</h3>

<p>Goldsmith, J., Bobb, J., Crainiceanu, C., Caffo, B., and Reich,
D. (2011). Penalized Functional Regression. <em>Journal of Computational
and Graphical Statistics</em>, 20, 830 - 851.
</p>
<p>Goldsmith, J., Crainiceanu, C., Caffo, B., and Reich, D. (2010).
Longitudinal Penalized Functional Regression for Cognitive Outcomes on
Neuronal Tract Measurements. <em>Journal of the Royal Statistical
Society: Series C</em>, 61, 453 - 469.
</p>

<hr>
<h2 id='DTI2'>Diffusion Tensor Imaging: more fractional anisotropy profiles and outcomes</h2><span id='topic+DTI2'></span>

<h3>Description</h3>

<p>A diffusion tensor imaging dataset used in Swihart et al. (2012). Mean
diffusivity profiles for the corpus callosum (cca) and parallel diffusivity
for the right corticospinal tract (rcst). Accompanying the profiles are the
subject ID numbers, visit number, and Paced Auditory Serial Addition Test
(pasat) score. We thank Dr. Daniel Reich for making this dataset available.
</p>


<h3>Format</h3>

<p>A data frame made up of </p>

<dl>
<dt>cca</dt><dd><p>a 340 x 93
matrix of fractional anisotropy profiles from the corpus callosum;</p>
</dd>
<dt>rcst</dt><dd><p>a 340 x 55 matrix of fractional anisotropy
profiles from the right corticospinal tract;</p>
</dd>
<dt>id</dt><dd><p>numeric vector of subject ID numbers;</p>
</dd>
<dt>visit</dt><dd><p>numeric vector of the
subject-specific visit numbers;</p>
</dd>
<dt>pasat</dt><dd><p>numeric vector
containing the PASAT score at each visit.</p>
</dd>
</dl>



<h3>Details</h3>

<p>If you use this data as an example in written work, please include the
following acknowledgment: &ldquo;The MRI/DTI data were collected at Johns
Hopkins University and the Kennedy-Krieger Institute&quot;
</p>
<p>Note: DTI2 uses mean diffusivity of the the corpus callosum rather than
fractional anisotropy (FA), and parallel diffusivity of the rcst rather
than FA. Please see the documentation for DTI for more about the DTI
dataset.
</p>


<h3>References</h3>

<p>Goldsmith, J., Bobb, J., Crainiceanu, C., Caffo, B., and Reich,
D. (2011). Penalized functional regression. <em>Journal of Computational
and Graphical Statistics</em>, 20(4), 830&ndash;851.
</p>
<p>Goldsmith, J., Crainiceanu, C., Caffo, B., and Reich, D. (2012).
Longitudinal penalized functional regression for cognitive outcomes on
neuronal tract measurements. <em>Journal of the Royal Statistical
Society: Series C</em>, 61(3), 453&ndash;469.
</p>
<p>Swihart, B. J., Goldsmith, J., and Crainiceanu, C. M. (2014). Restricted 
Likelihood  Ratio Tests for Functional Effects in the Functional Linear Model. 
<em>Technometrics</em>, 56, 483&ndash;493.
</p>

<hr>
<h2 id='expand.call'>Return call with all possible arguments</h2><span id='topic+expand.call'></span>

<h3>Description</h3>

<p>Return a call in which all of the arguments which were supplied or have presets are specified by their full names and their supplied or default values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expand.call(
  definition = NULL,
  call = sys.call(sys.parent(1)),
  expand.dots = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expand.call_+3A_definition">definition</code></td>
<td>
<p>a function. See <code><a href="base.html#topic+match.call">match.call</a></code>.</p>
</td></tr>
<tr><td><code id="expand.call_+3A_call">call</code></td>
<td>
<p>an unevaluated call to the function specified by definition. See <code><a href="base.html#topic+match.call">match.call</a></code>.</p>
</td></tr>
<tr><td><code id="expand.call_+3A_expand.dots">expand.dots</code></td>
<td>
<p>logical. Should arguments matching ... in the call be included or left as a ... argument? See <code><a href="base.html#topic+match.call">match.call</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of mode &quot;<code><a href="base.html#topic+call">call</a></code>&quot;.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>


<h3>See Also</h3>

<p><code><a href="base.html#topic+match.call">match.call</a></code>
</p>

<hr>
<h2 id='f_sum'>Sum computation 1</h2><span id='topic+f_sum'></span>

<h3>Description</h3>

<p>Internal function used compute a sum in FPCA-based covariance updates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f_sum(mu.q.c, sig.q.c, theta, obspts.mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f_sum_+3A_mu.q.c">mu.q.c</code></td>
<td>
<p>current value of mu.q.c</p>
</td></tr>
<tr><td><code id="f_sum_+3A_sig.q.c">sig.q.c</code></td>
<td>
<p>current value of sig.q.c</p>
</td></tr>
<tr><td><code id="f_sum_+3A_theta">theta</code></td>
<td>
<p>spline basis</p>
</td></tr>
<tr><td><code id="f_sum_+3A_obspts.mat">obspts.mat</code></td>
<td>
<p>matrix indicating the points on which data is observed</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>

<hr>
<h2 id='f_sum2'>Sum computation 2</h2><span id='topic+f_sum2'></span>

<h3>Description</h3>

<p>Internal function used compute a sum in FPCA-based covariance updates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f_sum2(y, fixef, mu.q.c, kt, theta)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f_sum2_+3A_y">y</code></td>
<td>
<p>outcome matrix</p>
</td></tr>
<tr><td><code id="f_sum2_+3A_fixef">fixef</code></td>
<td>
<p>current estimate of fixed effects</p>
</td></tr>
<tr><td><code id="f_sum2_+3A_mu.q.c">mu.q.c</code></td>
<td>
<p>current value of mu.q.c</p>
</td></tr>
<tr><td><code id="f_sum2_+3A_kt">kt</code></td>
<td>
<p>number of basis functions</p>
</td></tr>
<tr><td><code id="f_sum2_+3A_theta">theta</code></td>
<td>
<p>spline basis</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>

<hr>
<h2 id='f_sum4'>Sum computation 2</h2><span id='topic+f_sum4'></span>

<h3>Description</h3>

<p>Internal function used compute a sum in FPCA-based covariance updates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f_sum4(mu.q.c, sig.q.c, mu.q.bpsi, sig.q.bpsi, theta, obspts.mat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f_sum4_+3A_mu.q.c">mu.q.c</code></td>
<td>
<p>current value of mu.q.c</p>
</td></tr>
<tr><td><code id="f_sum4_+3A_sig.q.c">sig.q.c</code></td>
<td>
<p>current value of sig.q.c</p>
</td></tr>
<tr><td><code id="f_sum4_+3A_mu.q.bpsi">mu.q.bpsi</code></td>
<td>
<p>current value of mu.q.bpsi</p>
</td></tr>
<tr><td><code id="f_sum4_+3A_sig.q.bpsi">sig.q.bpsi</code></td>
<td>
<p>current value of sig.q.bpsi</p>
</td></tr>
<tr><td><code id="f_sum4_+3A_theta">theta</code></td>
<td>
<p>current value of theta</p>
</td></tr>
<tr><td><code id="f_sum4_+3A_obspts.mat">obspts.mat</code></td>
<td>
<p>matrix indicating where curves are observed</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>

<hr>
<h2 id='f_trace'>Trace computation</h2><span id='topic+f_trace'></span>

<h3>Description</h3>

<p>Internal function used compute a trace in FPCA-based covariance updates
</p>


<h3>Usage</h3>

<pre><code class='language-R'>f_trace(Theta_i, Sig_q_Bpsi, Kp, Kt)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="f_trace_+3A_theta_i">Theta_i</code></td>
<td>
<p>basis functions on observed grid points</p>
</td></tr>
<tr><td><code id="f_trace_+3A_sig_q_bpsi">Sig_q_Bpsi</code></td>
<td>
<p>variance of FPC basis coefficients</p>
</td></tr>
<tr><td><code id="f_trace_+3A_kp">Kp</code></td>
<td>
<p>number of FPCs</p>
</td></tr>
<tr><td><code id="f_trace_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>

<hr>
<h2 id='fbps'>Sandwich smoother for matrix data</h2><span id='topic+fbps'></span>

<h3>Description</h3>

<p>A fast bivariate <em>P</em>-spline method for smoothing matrix data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fbps(
  data,
  subj = NULL,
  covariates = NULL,
  knots = 35,
  knots.option = "equally-spaced",
  periodicity = c(FALSE, FALSE),
  p = 3,
  m = 2,
  lambda = NULL,
  selection = "GCV",
  search.grid = T,
  search.length = 100,
  method = "L-BFGS-B",
  lower = -20,
  upper = 20,
  control = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fbps_+3A_data">data</code></td>
<td>
<p>n1 by n2 data matrix without missing data</p>
</td></tr>
<tr><td><code id="fbps_+3A_subj">subj</code></td>
<td>
<p>vector of subject id (corresponding to the columns of data); defaults to NULL</p>
</td></tr>
<tr><td><code id="fbps_+3A_covariates">covariates</code></td>
<td>
<p>list of two vectors of covariates of lengths n1 and n2;
if NULL, then generates equidistant covariates</p>
</td></tr>
<tr><td><code id="fbps_+3A_knots">knots</code></td>
<td>
<p>list of two vectors of knots or number of equidistant knots
for all dimensions; defaults to 35</p>
</td></tr>
<tr><td><code id="fbps_+3A_knots.option">knots.option</code></td>
<td>
<p>knot selection method; defaults to &quot;equally-spaced&quot;</p>
</td></tr>
<tr><td><code id="fbps_+3A_periodicity">periodicity</code></td>
<td>
<p>vector of two logical, indicating periodicity in the direction of row and column; defaults to c(FALSE, FALSE)</p>
</td></tr>
<tr><td><code id="fbps_+3A_p">p</code></td>
<td>
<p>degrees of B-splines; defaults to 3</p>
</td></tr>
<tr><td><code id="fbps_+3A_m">m</code></td>
<td>
<p>order of differencing penalty; defaults to 2</p>
</td></tr>
<tr><td><code id="fbps_+3A_lambda">lambda</code></td>
<td>
<p>user-specified smoothing parameters; defaults to NULL</p>
</td></tr>
<tr><td><code id="fbps_+3A_selection">selection</code></td>
<td>
<p>selection of smoothing parameter; defaults to &quot;GCV&quot;</p>
</td></tr>
<tr><td><code id="fbps_+3A_search.grid">search.grid</code></td>
<td>
<p>logical; defaults to TRUE, if FALSE, uses
<code>optim</code></p>
</td></tr>
<tr><td><code id="fbps_+3A_search.length">search.length</code></td>
<td>
<p>number of equidistant (log scale) smoothing parameter;
defaults to 100</p>
</td></tr>
<tr><td><code id="fbps_+3A_method">method</code></td>
<td>
<p>see <code>optim</code>; defaults to <code>L-BFGS-B</code></p>
</td></tr>
<tr><td><code id="fbps_+3A_lower">lower</code>, <code id="fbps_+3A_upper">upper</code></td>
<td>
<p>bounds for log smoothing parameter, passed to
<code>optim</code>; defaults are -20 and 20.</p>
</td></tr>
<tr><td><code id="fbps_+3A_control">control</code></td>
<td>
<p>see <code>optim</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The smoothing parameter can be user-specified; otherwise, the function uses
grid searching method or <code>optim</code> for selecting the smoothing
parameter.
</p>


<h3>Value</h3>

<p>A list with components </p>
<table>
<tr><td><code>lambda</code></td>
<td>
<p>vector of length 2 of selected
smoothing parameters</p>
</td></tr> <tr><td><code>Yhat</code></td>
<td>
<p>fitted data</p>
</td></tr> <tr><td><code>trace</code></td>
<td>
<p>trace of the
overall smoothing matrix</p>
</td></tr> <tr><td><code>gcv</code></td>
<td>
<p>value of generalized cross validation</p>
</td></tr>
<tr><td><code>Theta</code></td>
<td>
<p>matrix of estimated coefficients</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luo Xiao <a href="mailto:lxiao@jhsph.edu">lxiao@jhsph.edu</a>
</p>


<h3>References</h3>

<p>Xiao, L., Li, Y., and Ruppert, D. (2013). Fast bivariate
<em>P</em>-splines: the sandwich smoother. <em>Journal of the Royal
Statistical Society: Series B</em>, 75(3), 577&ndash;599.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
##########################
#### True function   #####
##########################
n1 &lt;- 60
n2 &lt;- 80
x &lt;- (1:n1)/n1-1/2/n1
z &lt;- (1:n2)/n2-1/2/n2
MY &lt;- array(0,c(length(x),length(z)))

sigx &lt;- .3
sigz &lt;- .4
for(i in 1:length(x))
for(j in 1:length(z))
{
#MY[i,j] &lt;- .75/(pi*sigx*sigz) *exp(-(x[i]-.2)^2/sigx^2-(z[j]-.3)^2/sigz^2)
#MY[i,j] &lt;- MY[i,j] + .45/(pi*sigx*sigz) *exp(-(x[i]-.7)^2/sigx^2-(z[j]-.8)^2/sigz^2)
MY[i,j] = sin(2*pi*(x[i]-.5)^3)*cos(4*pi*z[j])
}
##########################
#### Observed data   #####
##########################
sigma &lt;- 1
Y &lt;- MY + sigma*rnorm(n1*n2,0,1)
##########################
####   Estimation    #####
##########################

est &lt;- fbps(Y,list(x=x,z=z))
mse &lt;- mean((est$Yhat-MY)^2)
cat("mse of fbps is",mse,"\n")
cat("The smoothing parameters are:",est$lambda,"\n")
########################################################################
########## Compare the estimated surface with the true surface #########
########################################################################

par(mfrow=c(1,2))
persp(x,z,MY,zlab="f(x,z)",zlim=c(-1,2.5), phi=30,theta=45,expand=0.8,r=4,
      col="blue",main="True surface")
persp(x,z,est$Yhat,zlab="f(x,z)",zlim=c(-1,2.5),phi=30,theta=45,
      expand=0.8,r=4,col="red",main="Estimated surface")
</code></pre>

<hr>
<h2 id='ff'>Construct a function-on-function regression term</h2><span id='topic+ff'></span>

<h3>Description</h3>

<p>Defines a term <code class="reqn">\int^{s_{hi, i}}_{s_{lo, i}} X_i(s)\beta(t,s)ds</code> for
inclusion in an <code>mgcv::gam</code>-formula (or <code>bam</code> or <code>gamm</code> or
<code>gamm4:::gamm4</code>) as constructed by <code><a href="#topic+pffr">pffr</a></code>. <br /> Defaults to a
cubic tensor product B-spline with marginal first order differences penalties
for <code class="reqn">\beta(t,s)</code> and numerical integration over the entire range
<code class="reqn">[s_{lo, i}, s_{hi, i}] = [\min(s_i), \max(s_i)]</code> by using Simpson
weights. Can't deal with any missing <code class="reqn">X(s)</code>, unequal lengths of
<code class="reqn">X_i(s)</code> not (yet?) possible. Unequal integration ranges for different
<code class="reqn">X_i(s)</code> should work. <code class="reqn">X_i(s)</code> is assumed to be numeric (duh...).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ff(
  X,
  yind = NULL,
  xind = seq(0, 1, l = ncol(X)),
  basistype = c("te", "t2", "ti", "s", "tes"),
  integration = c("simpson", "trapezoidal", "riemann"),
  L = NULL,
  limits = NULL,
  splinepars = if (basistype != "s") {
     list(bs = "ps", m = list(c(2, 1), c(2, 1)), k
    = c(5, 5))
 } else {
     list(bs = "tp", m = NA)
 },
  check.ident = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ff_+3A_x">X</code></td>
<td>
<p>an n by <code>ncol(xind)</code> matrix of function evaluations
<code class="reqn">X_i(s_{i1}),\dots, X_i(s_{iS})</code>; <code class="reqn">i=1,\dots,n</code>.</p>
</td></tr>
<tr><td><code id="ff_+3A_yind">yind</code></td>
<td>
<p><em>DEPRECATED</em> used to supply matrix (or vector) of indices of
evaluations of <code class="reqn">Y_i(t)</code>, no longer used.</p>
</td></tr>
<tr><td><code id="ff_+3A_xind">xind</code></td>
<td>
<p>vector of indices of evaluations of <code class="reqn">X_i(s)</code>,
i.e, <code class="reqn">(s_{1},\dots,s_{S})</code></p>
</td></tr>
<tr><td><code id="ff_+3A_basistype">basistype</code></td>
<td>
<p>defaults to &quot;<code><a href="mgcv.html#topic+te">te</a></code>&quot;, i.e. a tensor product
spline to represent <code class="reqn">\beta(t,s)</code>. Alternatively, use <code>"s"</code> for
bivariate basis functions (see <code>mgcv</code>'s <code><a href="mgcv.html#topic+s">s</a></code>) or
<code>"t2"</code> for an alternative parameterization of tensor product splines
(see <code>mgcv</code>'s <code><a href="mgcv.html#topic+t2">t2</a></code>).</p>
</td></tr>
<tr><td><code id="ff_+3A_integration">integration</code></td>
<td>
<p>method used for numerical integration. Defaults to
<code>"simpson"</code>'s rule for calculating entries in <code>L</code>. Alternatively
and for non-equidistant grids, <code>"trapezoidal"</code> or <code>"riemann"</code>.
<code>"riemann"</code> integration is always used if <code>limits</code> is specified</p>
</td></tr>
<tr><td><code id="ff_+3A_l">L</code></td>
<td>
<p>optional: an n by <code>ncol(xind)</code> matrix giving the weights for
the numerical integration over <code class="reqn">s</code>.</p>
</td></tr>
<tr><td><code id="ff_+3A_limits">limits</code></td>
<td>
<p>defaults to NULL for integration across the entire range of
<code class="reqn">X(s)</code>, otherwise specifies the integration limits <code class="reqn">s_{hi}(t),
s_{lo}(t)</code>: either one of <code>"s&lt;t"</code> or <code>"s&lt;=t"</code> for
<code class="reqn">(s_{hi}(t), s_{lo}(t)) = (t, 0]</code> or <code class="reqn">[t, 0]</code>, respectively, or a
function that takes <code>s</code> as the first and <code>t</code> as the second
argument and returns TRUE for combinations of values <code>(s,t)</code> if
<code>s</code> falls into the integration range for the given <code>t</code>. This is
an experimental feature and not well tested yet; use at your own risk.</p>
</td></tr>
<tr><td><code id="ff_+3A_splinepars">splinepars</code></td>
<td>
<p>optional arguments supplied to the <code>basistype</code>-term.
Defaults to a cubic tensor product B-spline with marginal first difference
penalties, i.e. <code>list(bs="ps", m=list(c(2, 1), c(2,1)))</code>. See
<code><a href="mgcv.html#topic+te">te</a></code> or <code><a href="mgcv.html#topic+s">s</a></code> in <span class="pkg">mgcv</span> for details</p>
</td></tr>
<tr><td><code id="ff_+3A_check.ident">check.ident</code></td>
<td>
<p>check identifiability of the model spec. See Details and
References. Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>check.ident==TRUE</code> and <code>basistype!="s"</code>  (the default), the
routine checks conditions for non-identifiability of the effect.  This occurs
if a) the marginal basis for the functional covariate is rank-deficient
(typically because the functional covariate has lower rank than the spline
basis along its index) and simultaneously b) the kernel of Cov<code class="reqn">(X(s))</code> is
not disjunct from the kernel of the marginal penalty over <code>s</code>. In
practice, a) occurs quite frequently, and b) occurs usually because
curve-wise mean centering has removed all constant components from the
functional covariate. <br /> If there is kernel overlap, <code class="reqn">\beta(t,s)</code> is
constrained to be orthogonal to functions in that overlap space (e.g., if the
overlap contains constant functions, constraints &quot;<code class="reqn">\int \beta(t,s) ds =
0</code> for all t&quot; are enforced). See reference for details.<br /> A warning is
always given if the effective rank of Cov<code class="reqn">(X(s))</code> (defined as the number
of eigenvalues accounting for at least 0.995 of the total variance in
<code class="reqn">X_i(s)</code>) is lower than 4. If <code class="reqn">X_i(s)</code> is of very low rank,
<code><a href="#topic+ffpc">ffpc</a></code>-term may be preferable.
</p>


<h3>Value</h3>

<p>A list containing </p>
<table>
<tr><td><code>call</code></td>
<td>
<p>a &quot;call&quot; to
<code><a href="mgcv.html#topic+te">te</a></code> (or <code><a href="mgcv.html#topic+s">s</a></code> or <code><a href="mgcv.html#topic+t2">t2</a></code>)
using the appropriately constructed covariate and weight matrices</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>a list containing the necessary covariate and weight matrices</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Fabian Scheipl, Sonja Greven
</p>


<h3>References</h3>

<p>For background on <code>check.ident</code>:<br /> Scheipl, F., Greven,
S. (2016). Identifiability in penalized function-on-function regression
models. Electronic Journal of Statistics, 10(1), 495&ndash;526.
<a href="https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-10/issue-1/Identifiability-in-penalized-function-on-function-regression-models/10.1214/16-EJS1123.full">https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-10/issue-1/Identifiability-in-penalized-function-on-function-regression-models/10.1214/16-EJS1123.full</a>
</p>


<h3>See Also</h3>

<p><code>mgcv</code>'s <code><a href="mgcv.html#topic+linear.functional.terms">linear.functional.terms</a></code>
</p>

<hr>
<h2 id='ffpc'>Construct a PC-based function-on-function regression term</h2><span id='topic+ffpc'></span>

<h3>Description</h3>

<p>Defines a term <code class="reqn">\int X_i(s)\beta(t,s)ds</code>
for inclusion in an <code>mgcv::gam</code>-formula (or <code>bam</code> or <code>gamm</code> or <code>gamm4:::gamm4</code>) as constructed
by <code><a href="#topic+pffr">pffr</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ffpc(
  X,
  yind = NULL,
  xind = seq(0, 1, length = ncol(X)),
  splinepars = list(bs = "ps", m = c(2, 1), k = 8),
  decomppars = list(pve = 0.99, useSymm = TRUE),
  npc.max = 15
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ffpc_+3A_x">X</code></td>
<td>
<p>an n by <code>ncol(xind)</code> matrix of function evaluations <code class="reqn">X_i(s_{i1}),\dots, X_i(s_{iS})</code>; <code class="reqn">i=1,\dots,n</code>.</p>
</td></tr>
<tr><td><code id="ffpc_+3A_yind">yind</code></td>
<td>
<p><em>DEPRECATED</em> used to supply matrix (or vector) of indices of evaluations of <code class="reqn">Y_i(t)</code>, no longer used.</p>
</td></tr>
<tr><td><code id="ffpc_+3A_xind">xind</code></td>
<td>
<p>matrix (or vector) of indices of evaluations of <code class="reqn">X_i(t)</code>, defaults to <code>seq(0, 1, length=ncol(X))</code>.</p>
</td></tr>
<tr><td><code id="ffpc_+3A_splinepars">splinepars</code></td>
<td>
<p>optional arguments supplied to the <code>basistype</code>-term. Defaults to a cubic
B-spline with first difference penalties and 8 basis functions for each <code class="reqn">\tilde \beta_k(t)</code>.</p>
</td></tr>
<tr><td><code id="ffpc_+3A_decomppars">decomppars</code></td>
<td>
<p>parameters for the FPCA performed with <code><a href="#topic+fpca.sc">fpca.sc</a></code>.</p>
</td></tr>
<tr><td><code id="ffpc_+3A_npc.max">npc.max</code></td>
<td>
<p>maximal number <code class="reqn">K</code> of FPCs to use, regardless of <code>decomppars</code>; defaults to 15</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In contrast to <code><a href="#topic+ff">ff</a></code>, <code>ffpc</code>
does an FPCA decomposition <code class="reqn">X(s) \approx \sum^K_{k=1} \xi_{ik} \Phi_k(s)</code> using <code><a href="#topic+fpca.sc">fpca.sc</a></code> and
represents <code class="reqn">\beta(t,s)</code> in the function space spanned by these <code class="reqn">\Phi_k(s)</code>.
That is, since
</p>
<p style="text-align: center;"><code class="reqn">\int X_i(s)\beta(t,s)ds = \sum^K_{k=1} \xi_{ik} \int \Phi_k(s) \beta(s,t) ds = \sum^K_{k=1} \xi_{ik} \tilde \beta_k(t),</code>
</p>

<p>the function-on-function term can be represented as a sum of <code class="reqn">K</code> univariate functions <code class="reqn">\tilde \beta_k(t)</code> in <code class="reqn">t</code> each multiplied by the FPC
scores <code class="reqn">\xi_{ik}</code>. The truncation parameter <code class="reqn">K</code> is chosen as described in <code><a href="#topic+fpca.sc">fpca.sc</a></code>.
Using this instead of <code>ff()</code> can be beneficial if the covariance operator of the <code class="reqn">X_i(s)</code>
has low effective rank (i.e., if <code class="reqn">K</code> is small). If the covariance operator of the <code class="reqn">X_i(s)</code>
is of (very) high rank, i.e., if <code class="reqn">K</code> is large, <code>ffpc()</code> will not be very efficient.
</p>
<p>To reduce model complexity, the <code class="reqn">\tilde \beta_k(t)</code> all have a single joint smoothing parameter
(in <code>mgcv</code>, they get the same <code>id</code>, see <code><a href="mgcv.html#topic+s">s</a></code>).<br />
</p>
<p>Please see <code><a href="#topic+pffr">pffr</a></code> for details on model specification and
implementation.
</p>


<h3>Value</h3>

<p>A list containing the necessary information to construct a term to be included in a <code>mgcv::gam</code>-formula.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(1122)
n &lt;- 55
S &lt;- 60
T &lt;- 50
s &lt;- seq(0,1, l=S)
t &lt;- seq(0,1, l=T)

#generate X from a polynomial FPC-basis:
rankX &lt;- 5
Phi &lt;- cbind(1/sqrt(S), poly(s, degree=rankX-1))
lambda &lt;- rankX:1
Xi &lt;- sapply(lambda, function(l)
            scale(rnorm(n, sd=sqrt(l)), scale=FALSE))
X &lt;- Xi %*% t(Phi)

beta.st &lt;- outer(s, t, function(s, t) cos(2 * pi * s * t))

y &lt;- (1/S*X) %*% beta.st + 0.1 * matrix(rnorm(n * T), nrow=n, ncol=T)

data &lt;- list(y=y, X=X)
# set number of FPCs to true rank of process for this example:
m.pc &lt;- pffr(y ~ c(1) + 0 + ffpc(X, yind=t, decomppars=list(npc=rankX)),
        data=data, yind=t)
summary(m.pc)
m.ff &lt;- pffr(y ~ c(1) + 0 + ff(X, yind=t), data=data, yind=t)
summary(m.ff)

# fits are very similar:
all.equal(fitted(m.pc), fitted(m.ff))

# plot implied coefficient surfaces:
layout(t(1:3))
persp(t, s, t(beta.st), theta=50, phi=40, main="Truth",
    ticktype="detailed")
plot(m.ff, select=1, zlim=range(beta.st), theta=50, phi=40,
    ticktype="detailed")
title(main="ff()")
ffpcplot(m.pc, type="surf", auto.layout=FALSE, theta = 50, phi = 40)
title(main="ffpc()")

# show default ffpcplot:
ffpcplot(m.pc)

## End(Not run)
</code></pre>

<hr>
<h2 id='ffpcplot'>Plot PC-based function-on-function regression terms</h2><span id='topic+ffpcplot'></span>

<h3>Description</h3>

<p>Convenience function for graphical summaries of <code>ffpc</code>-terms from a
<code>pffr</code> fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ffpcplot(
  object,
  type = c("fpc+surf", "surf", "fpc"),
  pages = 1,
  se.mult = 2,
  ticktype = "detailed",
  theta = 30,
  phi = 30,
  plot = TRUE,
  auto.layout = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ffpcplot_+3A_object">object</code></td>
<td>
<p>a fitted <code>pffr</code>-model</p>
</td></tr>
<tr><td><code id="ffpcplot_+3A_type">type</code></td>
<td>
<p>one of &quot;fpc+surf&quot;, &quot;surf&quot; or &quot;fpc&quot;: &quot;surf&quot; shows a perspective plot of the coefficient surface implied
by the estimated effect functions of the FPC scores, &quot;fpc&quot; shows three plots:
1) a scree-type plot of the estimated eigenvalues of the functional covariate, 2) the estimated eigenfunctions,
and 3) the estimated coefficient functions associated with the FPC scores. Defaults to showing both.</p>
</td></tr>
<tr><td><code id="ffpcplot_+3A_pages">pages</code></td>
<td>
<p>the number of pages over which to spread the output. Defaults to 1. (Irrelevant if <code>auto.layout=FALSE</code>.)</p>
</td></tr>
<tr><td><code id="ffpcplot_+3A_se.mult">se.mult</code></td>
<td>
<p>display estimated coefficient functions associated with the FPC scores with plus/minus this number time the estimated standard error.
Defaults to 2.</p>
</td></tr>
<tr><td><code id="ffpcplot_+3A_ticktype">ticktype</code></td>
<td>
<p>see <code><a href="graphics.html#topic+persp">persp</a></code>.</p>
</td></tr>
<tr><td><code id="ffpcplot_+3A_theta">theta</code></td>
<td>
<p>see <code><a href="graphics.html#topic+persp">persp</a></code>.</p>
</td></tr>
<tr><td><code id="ffpcplot_+3A_phi">phi</code></td>
<td>
<p>see <code><a href="graphics.html#topic+persp">persp</a></code>.</p>
</td></tr>
<tr><td><code id="ffpcplot_+3A_plot">plot</code></td>
<td>
<p>produce plots or only return plotting data? Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ffpcplot_+3A_auto.layout">auto.layout</code></td>
<td>
<p>should the the function set a suitable layout automatically? Defaults to TRUE</p>
</td></tr>
</table>


<h3>Value</h3>

<p>primarily produces plots, invisibly returns a list containing
the data used for the plots.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 #see ?ffpc

## End(Not run)
</code></pre>

<hr>
<h2 id='fgam'>Functional Generalized Additive Models</h2><span id='topic+fgam'></span>

<h3>Description</h3>

<p>Implements functional generalized additive models for functional and scalar covariates and scalar responses.
Additionally implements functional linear models.  This function is a wrapper for mgcv's <code><a href="mgcv.html#topic+gam">gam</a></code>
and its siblings to fit models of the general form
</p>
<p style="text-align: center;"><code class="reqn">g(E(Y_i)) = \beta_0 + \int_{T_1} F(X_{i1},t)dt+ \int_{T_2} \beta(t)X_{i2}dt + f(z_{i1}) + f(z_{i2}, z_{i3}) + \ldots</code>
</p>

<p>with a scalar (but not necessarily continuous) response Y, and link function g
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fgam(formula, fitter = NA, tensortype = c("te", "t2"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fgam_+3A_formula">formula</code></td>
<td>
<p>a formula with special terms as for gam, with additional special terms
<code><a href="#topic+af">af</a></code>(), <code><a href="#topic+lf">lf</a></code>(), <code><a href="#topic+re">re</a></code>().</p>
</td></tr>
<tr><td><code id="fgam_+3A_fitter">fitter</code></td>
<td>
<p>the name of the function used to estimate the model. Defaults to <code><a href="mgcv.html#topic+gam">gam</a></code>
if the matrix of functional responses has less than 2e5 data points and to
<code><a href="mgcv.html#topic+bam">bam</a></code> if not. &quot;gamm&quot; (see <code><a href="mgcv.html#topic+gamm">gamm</a></code>) and &quot;gamm4&quot;
(see <code><a href="gamm4.html#topic+gamm4">gamm4</a></code>) are valid options as well.</p>
</td></tr>
<tr><td><code id="fgam_+3A_tensortype">tensortype</code></td>
<td>
<p>defaults to <code><a href="mgcv.html#topic+te">te</a></code>, other valid option is <code><a href="mgcv.html#topic+t2">t2</a></code></p>
</td></tr>
<tr><td><code id="fgam_+3A_...">...</code></td>
<td>
<p>additional arguments that are valid for <code><a href="mgcv.html#topic+gam">gam</a></code> or <code><a href="mgcv.html#topic+bam">bam</a></code>; for example,
specify a <code>gamma</code> &gt; 1 to increase amount of smoothing when using GCV to choose smoothing
parameters or <code>method="REML"</code> to change to REML for estimation of smoothing parameters
(default is GCV).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a fitted fgam-object, which is a <code><a href="mgcv.html#topic+gam">gam</a></code>-object with some additional information
in a fgam-entry. If fitter is &quot;gamm&quot; or &quot;gamm4&quot;, only the $gam part of the
returned list is modified in this way.
</p>


<h3>Warning</h3>

<p>Binomial responses should be specified as a numeric vector rather than as a matrix or a factor.
</p>


<h3>Author(s)</h3>

<p>Mathew W. McLean <a href="mailto:mathew.w.mclean@gmail.com">mathew.w.mclean@gmail.com</a> and Fabian Scheipl
</p>


<h3>References</h3>

<p>McLean, M. W., Hooker, G., Staicu, A.-M., Scheipl, F., and Ruppert, D. (2014). Functional
generalized additive models. <em>Journal of Computational and Graphical Statistics</em>, <b>23 (1)</b>,
pp. 249-269.  Available at <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+af">af</a></code>, <code><a href="#topic+lf">lf</a></code>, <code><a href="#topic+predict.fgam">predict.fgam</a></code>, <code><a href="#topic+vis.fgam">vis.fgam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DTI)
## only consider first visit and cases (no PASAT scores for controls)
y &lt;- DTI$pasat[DTI$visit==1 &amp; DTI$case==1]
X &lt;- DTI$cca[DTI$visit==1 &amp; DTI$case==1, ]
X_2 &lt;- DTI$rcst[DTI$visit==1 &amp; DTI$case==1, ]

## remove samples containing missing data
ind &lt;- rowSums(is.na(X)) &gt; 0
ind2 &lt;- rowSums(is.na(X_2)) &gt; 0

y &lt;- y[!(ind | ind2)]
X &lt;- X[!(ind | ind2), ]
X_2 &lt;- X_2[!(ind | ind2), ]

N &lt;- length(y)

## fit fgam using FA measurements along corpus callosum
## as functional predictor with PASAT as response
## using 8 cubic B-splines for marginal bases with third
## order marginal difference penalties
## specifying gamma &gt; 1 enforces more smoothing when using
## GCV to choose smoothing parameters
#fit &lt;- fgam(y ~ af(X, k = c(8, 8), m = list(c(2, 3), c(2, 3))), gamma = 1.2)


## fgam term for the cca measurements plus an flm term for the rcst measurements
## leave out 10 samples for prediction
test &lt;- sample(N, 10)
#fit &lt;- fgam(y ~ af(X, k = c(7, 7), m = list(c(2, 2), c(2, 2))) +
 #      lf(X_2, k=7, m = c(2, 2)), subset=(1:N)[-test])
#plot(fit)
## predict the ten left outs samples
#pred &lt;- predict(fit, newdata = list(X=X[test, ], X_2 = X_2[test, ]), type='response',
 #               PredOutOfRange = TRUE)
#sqrt(mean((y[test] - pred)^2))
## Try to predict the binary response disease status (case or control)
##   using the quantile transformed measurements from the rcst tract
##   with a smooth component for a scalar covariate that is pure noise
y &lt;- DTI$case[DTI$visit==1]
X &lt;- DTI$cca[DTI$visit==1, ]
X_2 &lt;- DTI$rcst[DTI$visit==1, ]

ind &lt;- rowSums(is.na(X)) &gt; 0
ind2 &lt;- rowSums(is.na(X_2)) &gt; 0

y &lt;- y[!(ind | ind2)]
X &lt;- X[!(ind | ind2), ]
X_2 &lt;- X_2[!(ind | ind2), ]
z1 &lt;- rnorm(length(y))

## select=TRUE allows terms to be zeroed out of model completely
#fit &lt;- fgam(y ~ s(z1, k = 10) + af(X_2, k=c(7,7), m = list(c(2, 1), c(2, 1)),
 #           Qtransform=TRUE), family=binomial(), select=TRUE)
#plot(fit)

</code></pre>

<hr>
<h2 id='fosr'>Function-on-scalar regression</h2><span id='topic+fosr'></span>

<h3>Description</h3>

<p>Fit linear regression with functional responses and scalar predictors, with
efficient selection of optimal smoothing parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fosr(
  formula = NULL,
  Y = NULL,
  fdobj = NULL,
  data = NULL,
  X,
  con = NULL,
  argvals = NULL,
  method = c("OLS", "GLS", "mix"),
  gam.method = c("REML", "ML", "GCV.Cp", "GACV.Cp", "P-REML", "P-ML"),
  cov.method = c("naive", "mod.chol"),
  lambda = NULL,
  nbasis = 15,
  norder = 4,
  pen.order = 2,
  multi.sp = ifelse(method == "OLS", FALSE, TRUE),
  pve = 0.99,
  max.iter = 1,
  maxlam = NULL,
  cv1 = FALSE,
  scale = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fosr_+3A_formula">formula</code></td>
<td>
<p>Formula for fitting fosr. If used, data argument must not be null.</p>
</td></tr>
<tr><td><code id="fosr_+3A_y">Y</code>, <code id="fosr_+3A_fdobj">fdobj</code></td>
<td>
<p>the functional responses, given as either an <code class="reqn">n\times d</code>
matrix <code>Y</code> or a functional data object (class <code>"<a href="fda.html#topic+fd">fd</a>"</code>)
as in the <span class="pkg">fda</span> package.</p>
</td></tr>
<tr><td><code id="fosr_+3A_data">data</code></td>
<td>
<p>data frame containing the predictors and responses.</p>
</td></tr>
<tr><td><code id="fosr_+3A_x">X</code></td>
<td>
<p>the model matrix, whose columns represent scalar predictors.
Should ordinarily include a column of 1s.</p>
</td></tr>
<tr><td><code id="fosr_+3A_con">con</code></td>
<td>
<p>a row vector or matrix of linear contrasts of the coefficient
functions, to be constrained to equal zero.</p>
</td></tr>
<tr><td><code id="fosr_+3A_argvals">argvals</code></td>
<td>
<p>the <code class="reqn">d</code> argument values at which the coefficient
functions will be evaluated.</p>
</td></tr>
<tr><td><code id="fosr_+3A_method">method</code></td>
<td>
<p>estimation method: <code>"OLS"</code> for penalized ordinary least
squares, <code>"GLS"</code> for penalized generalized least squares, <code>"mix"</code>
for mixed effect models.</p>
</td></tr>
<tr><td><code id="fosr_+3A_gam.method">gam.method</code></td>
<td>
<p>smoothing parameter selection method, to be passed to
<code><a href="mgcv.html#topic+gam">gam</a></code>: <code>"REML"</code> for restricted maximum likelihood,
<code>"GCV.Cp"</code> for generalized cross-validation.</p>
</td></tr>
<tr><td><code id="fosr_+3A_cov.method">cov.method</code></td>
<td>
<p>covariance estimation method: the current options are
naive or modified Cholesky. See Details.</p>
</td></tr>
<tr><td><code id="fosr_+3A_lambda">lambda</code></td>
<td>
<p>smoothing parameter value.  If <code>NULL</code>, the smoothing
parameter(s) will be estimated.  See Details.</p>
</td></tr>
<tr><td><code id="fosr_+3A_nbasis">nbasis</code>, <code id="fosr_+3A_norder">norder</code></td>
<td>
<p>number of basis functions, and order of splines (the
default, 4, gives cubic splines), for the B-spline basis used to represent
the coefficient functions. When the functional responses are supplied using
<code>fdobj</code>, these arguments are ignored in favor of the values pertaining
to the supplied object.</p>
</td></tr>
<tr><td><code id="fosr_+3A_pen.order">pen.order</code></td>
<td>
<p>order of derivative penalty.</p>
</td></tr>
<tr><td><code id="fosr_+3A_multi.sp">multi.sp</code></td>
<td>
<p>a logical value indicating whether separate smoothing
parameters should be estimated for each coefficient function.  Currently
must be <code>FALSE</code> if <code>method = "OLS"</code>.</p>
</td></tr>
<tr><td><code id="fosr_+3A_pve">pve</code></td>
<td>
<p>if <code>method = 'mix'</code>, the percentage of variance explained
by the principal components; defaults to 0.99.</p>
</td></tr>
<tr><td><code id="fosr_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations if <code>method = "GLS"</code>.</p>
</td></tr>
<tr><td><code id="fosr_+3A_maxlam">maxlam</code></td>
<td>
<p>maximum smoothing parameter value to consider (when
<code>lamvec=NULL</code>; see <code><a href="#topic+lofocv">lofocv</a></code>).</p>
</td></tr>
<tr><td><code id="fosr_+3A_cv1">cv1</code></td>
<td>
<p>logical value indicating whether a cross-validation score should
be computed even if a single fixed <code>lambda</code> is specified (when
<code>method = "OLS"</code>).</p>
</td></tr>
<tr><td><code id="fosr_+3A_scale">scale</code></td>
<td>
<p>logical value or vector determining scaling of the matrix
<code>X</code> (see <code><a href="base.html#topic+scale">scale</a></code>, to which the value of this argument is
passed).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The GLS method requires estimating the residual covariance matrix, which
has dimension <code class="reqn">d\times d</code> when the responses are given by <code>Y</code>, or
<code class="reqn">nbasis\times nbasis</code> when they are given by <code>fdobj</code>. When
<code>cov.method = "naive"</code>, the ordinary sample covariance is used. But
this will be singular, or nonsingular but unstable, in high-dimensional
settings, which are typical. <code>cov.method = "mod.chol"</code> implements the
modified Cholesky method of Pourahmadi (1999) for estimation of covariance
matrices whose inverse is banded. The number of bands is chosen to maximize
the p-value for a sphericity test (Ledoit and Wolf, 2002) applied to the
&quot;prewhitened&quot; residuals. Note, however, that the banded inverse covariance
assumption is sometimes inappropriate, e.g., for periodic functional
responses.
</p>
<p>There are three types of values for argument <code>lambda</code>:</p>
<ol>
<li>
<p>if <code>NULL</code>, the smoothing parameter is estimated by
<code><a href="mgcv.html#topic+gam">gam</a></code> (package <span class="pkg">mgcv</span>) if <code>method = "GLS"</code>, or
by <code>optimize</code> if <code>method = "OLS"</code>; </p>
</li>
<li><p> if a scalar, this value
is used as the smoothing parameter (but only for the initial model, if
<code>method = "GLS"</code>); </p>
</li>
<li><p> if a vector, this is used as a grid of values
for optimizing the cross-validation score (provided <code>method = "OLS"</code>;
otherwise an error message is issued).</p>
</li></ol>

<p>Please note that currently, if <code>multi.sp = TRUE</code>, then <code>lambda</code>
must be <code>NULL</code> and <code>method</code> must be <code>"GLS"</code>.
</p>


<h3>Value</h3>

<p>An object of class <code>fosr</code>, which is a list with the following
elements: </p>
<table>
<tr><td><code>fd</code></td>
<td>
<p>object of class <code>"<a href="fda.html#topic+fd">fd</a>"</code> representing the
estimated coefficient functions. Its main components are a basis and a
matrix of coefficients with respect to that basis.</p>
</td></tr> <tr><td><code>pca.resid</code></td>
<td>
<p>if
<code>method = "mix"</code>, an object representing a functional PCA of the
residuals, performed by <code><a href="#topic+fpca.sc">fpca.sc</a></code> if the responses are in raw
form or by <code><a href="fda.html#topic+pca.fd">pca.fd</a></code> if in functional-data-object form.</p>
</td></tr>
<tr><td><code>U</code></td>
<td>
<p>if <code>method = "mix"</code>, an <code class="reqn">n\times m</code> matrix of random
effects, where <code class="reqn">m</code> is the number of functional PC's needed to explain
proportion <code>pve</code> of the residual variance. These random effects can be
interpreted as shrunken FPC scores.</p>
</td></tr> <tr><td><code>yhat</code>, <code>resid</code></td>
<td>
<p>objects of the same
form as the functional responses (see arguments <code>Y</code> and <code>fdobj</code>),
giving the fitted values and residuals.</p>
</td></tr> <tr><td><code>est.func</code></td>
<td>
<p>matrix of values
of the coefficient function estimates at the points given by
<code>argvals</code>.</p>
</td></tr> <tr><td><code>se.func</code></td>
<td>
<p>matrix of values of the standard error
estimates for the coefficient functions, at the points given by
<code>argvals</code>.</p>
</td></tr> <tr><td><code>argvals</code></td>
<td>
<p>points at which the coefficient functions
are evaluated.</p>
</td></tr> <tr><td><code>fit</code></td>
<td>
<p>fit object outputted by <code><a href="#topic+amc">amc</a></code>.</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p>effective degrees of freedom of the fit.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>smoothing parameter, or vector of smoothing parameters.</p>
</td></tr>
<tr><td><code>cv</code></td>
<td>
<p>cross-validated integrated squared error if <code>method="OLS"</code>,
otherwise <code>NULL</code>.</p>
</td></tr> <tr><td><code>roughness</code></td>
<td>
<p>value of the roughness penalty.</p>
</td></tr>
<tr><td><code>resp.type</code></td>
<td>
<p><code>"raw"</code> or <code>"fd"</code>, indicating whether the
responses were supplied in raw or functional-data-object form.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a>, Lan Huo, and Fabian
Scheipl
</p>


<h3>References</h3>

<p>Ledoit, O., and Wolf, M. (2002). Some hypothesis tests for the
covariance matrix when the dimension is large compared to the sample size.
<em>Annals of Statistics</em>, 30(4), 1081&ndash;1102.
</p>
<p>Pourahmadi, M. (1999). Joint mean-covariance models with applications to
longitudinal data: unconstrained parameterisation. <em>Biometrika</em>,
86(3), 677&ndash;690.
</p>
<p>Ramsay, J. O., and Silverman, B. W. (2005).  <em>Functional Data
Analysis</em>, 2nd ed., Chapter 13.  New York: Springer.
</p>
<p>Reiss, P. T., Huang, L., and Mennes, M. (2010).  Fast function-on-scalar
regression with penalized basis expansions.  <em>International Journal of
Biostatistics</em>, 6(1), article 28.  Available at
<a href="https://pubmed.ncbi.nlm.nih.gov/21969982/">https://pubmed.ncbi.nlm.nih.gov/21969982/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.fosr">plot.fosr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
require(fda)
# The first two lines, adapted from help(fRegress) in package fda,
# set up a functional data object representing daily average
# temperatures at 35 sites in Canada
daybasis25 &lt;- create.fourier.basis(rangeval=c(0, 365), nbasis=25,
                  axes=list('axesIntervals'))
Temp.fd &lt;- with(CanadianWeather, smooth.basisPar(day.5,
                dailyAv[,,'Temperature.C'], daybasis25)$fd)

modmat = cbind(1, model.matrix(~ factor(CanadianWeather$region) - 1))
constraints = matrix(c(0,1,1,1,1), 1)

# Penalized OLS with smoothing parameter chosen by grid search
olsmod = fosr(fdobj = Temp.fd, X = modmat, con = constraints, method="OLS", lambda=100*10:30)
plot(olsmod, 1)

# Test use formula to fit fosr
set.seed(2121)
data1 &lt;- pffrSim(scenario="ff", n=40)
formod = fosr(Y~xlin+xsmoo, data=data1)
plot(formod, 1)

# Penalized GLS
glsmod = fosr(fdobj = Temp.fd, X = modmat, con = constraints, method="GLS")
plot(glsmod, 1)

## End(Not run)
</code></pre>

<hr>
<h2 id='fosr.perm'>Permutation testing for function-on-scalar regression</h2><span id='topic+fosr.perm'></span><span id='topic+fosr.perm.fit'></span><span id='topic+fosr.perm.test'></span><span id='topic+plot.fosr.perm'></span>

<h3>Description</h3>

<p><code>fosr.perm()</code> is a wrapper function calling <code>fosr.perm.fit()</code>,
which fits models to permuted data, followed by <code>fosr.perm.test()</code>,
which performs the actual simultaneous hypothesis test.  Calling the latter
two functions separately may be useful for performing tests at different
significance levels.  By default, <code>fosr.perm()</code> produces a plot using
the plot function for class <code>fosr.perm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fosr.perm(
  Y = NULL,
  fdobj = NULL,
  X,
  con = NULL,
  X0 = NULL,
  con0 = NULL,
  argvals = NULL,
  lambda = NULL,
  lambda0 = NULL,
  multi.sp = FALSE,
  nperm,
  level = 0.05,
  plot = TRUE,
  xlabel = "",
  title = NULL,
  prelim = if (multi.sp) 0 else 15,
  ...
)

fosr.perm.fit(
  Y = NULL,
  fdobj = NULL,
  X,
  con = NULL,
  X0 = NULL,
  con0 = NULL,
  argvals = NULL,
  lambda = NULL,
  lambda0 = NULL,
  multi.sp = FALSE,
  nperm,
  prelim,
  ...
)

fosr.perm.test(x, level = 0.05)

## S3 method for class 'fosr.perm'
plot(x, level = 0.05, xlabel = "", title = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fosr.perm_+3A_y">Y</code>, <code id="fosr.perm_+3A_fdobj">fdobj</code></td>
<td>
<p>the functional responses, given as either an <code class="reqn">n\times d</code>
matrix <code>Y</code> or a functional data object (class <code>"<a href="fda.html#topic+fd">fd</a>"</code>)
as in the <span class="pkg">fda</span> package.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_x">X</code></td>
<td>
<p>the design matrix, whose columns represent scalar predictors.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_con">con</code></td>
<td>
<p>a row vector or matrix of linear contrasts of the coefficient
functions, to be restricted to equal zero.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_x0">X0</code></td>
<td>
<p>design matrix for the null-hypothesis model.  If <code>NULL</code>, the
null hypothesis is the intercept-only model.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_con0">con0</code></td>
<td>
<p>linear constraints for the null-hypothesis model.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_argvals">argvals</code></td>
<td>
<p>the <code class="reqn">d</code> argument values at which the coefficient
functions will be evaluated.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_lambda">lambda</code></td>
<td>
<p>smoothing parameter value.  If <code>NULL</code>, the smoothing
parameter(s) will be estimated.  See <code><a href="#topic+fosr">fosr</a></code> for details.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_lambda0">lambda0</code></td>
<td>
<p>smoothing parameter for null-hypothesis model.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_multi.sp">multi.sp</code></td>
<td>
<p>a logical value indicating whether separate smoothing
parameters should be estimated for each coefficient function.  Currently
must be <code>FALSE</code> if <code>method = "OLS"</code>.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_nperm">nperm</code></td>
<td>
<p>number of permutations.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_level">level</code></td>
<td>
<p>significance level for the simultaneous test.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_plot">plot</code></td>
<td>
<p>logical value indicating whether to plot the real- and
permuted-data pointwise F-type statistics.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_xlabel">xlabel</code></td>
<td>
<p>x-axis label for plots.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_title">title</code></td>
<td>
<p>title for plot.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_prelim">prelim</code></td>
<td>
<p>number of preliminary permutations.  The smoothing parameter
in the main permutations will be fixed to the median value from these
preliminary permutations.  If <code>prelim=0</code>, this is not done. Preliminary
permutations are not available when <code>multi.sp = TRUE</code> (hence the complicated default).</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_...">...</code></td>
<td>
<p>for <code>fosr.perm</code> and <code>fosr.perm.fit</code>, additional
arguments passed to <code><a href="#topic+fosr">fosr</a></code>.  These arguments may include
<code>max.iter</code>, <code>method</code>, <code>gam.method</code>, and <code>scale</code>.  For
<code>plot.fosr.perm</code>, graphical parameters (see <code><a href="graphics.html#topic+par">par</a></code>) for the
plot.</p>
</td></tr>
<tr><td><code id="fosr.perm_+3A_x">x</code></td>
<td>
<p>object of class <code>fosr.perm</code>, outputted by <code>fosr.perm</code>,
<code>fosr.perm.fit</code>, or <code>fosr.perm.test</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>fosr.perm</code> or <code>fosr.perm.test</code> produces an object of
class <code>fosr.perm</code>, which is a list with the elements below.
<code>fosr.perm.fit</code> also outputs an object of this class, but without the
last five elements. </p>
<table>
<tr><td><code>F</code></td>
<td>
<p>pointwise F-type statistics at each of the
points given by <code>argvals</code>.</p>
</td></tr> <tr><td><code>F.perm</code></td>
<td>
<p>a matrix, each of whose rows
gives the pointwise F-type statistics for a permuted data set.</p>
</td></tr>
<tr><td><code>argvals</code></td>
<td>
<p>points at which F-type statistics are computed.</p>
</td></tr>
<tr><td><code>lambda.real</code></td>
<td>
<p>smoothing parameter(s) for the real-data fit.</p>
</td></tr>
<tr><td><code>lambda.prelim</code></td>
<td>
<p>smoothing parameter(s) for preliminary permuted-data
fits.</p>
</td></tr> <tr><td><code>lambda.perm</code></td>
<td>
<p>smoothing parameter(s) for main permuted-data
fits.</p>
</td></tr> <tr><td><code>lambda0.real</code>, <code>lambda0.prelim</code>, <code>lambda0.perm</code></td>
<td>
<p>as above, but for
null hypothesis models.</p>
</td></tr> <tr><td><code>level</code></td>
<td>
<p>significance level of the test.</p>
</td></tr>
<tr><td><code>critval</code></td>
<td>
<p>critical value for the test.</p>
</td></tr> <tr><td><code>signif</code></td>
<td>
<p>vector of
logical values indicating whether significance is attained at each of the
points <code>argvals</code>.</p>
</td></tr> <tr><td><code>n2s</code></td>
<td>
<p>subset of 1, ...,
length(argvals) identifying the points at which the test statistic
changes from non-significant to significant.</p>
</td></tr> <tr><td><code>s2n</code></td>
<td>
<p>points at which
the test statistic changes from significant to non-significant.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a> and Lan Huo
</p>


<h3>References</h3>

<p>Reiss, P. T., Huang, L., and Mennes, M. (2010).  Fast
function-on-scalar regression with penalized basis expansions.
<em>International Journal of Biostatistics</em>, 6(1), article 28.  Available
at <a href="https://pubmed.ncbi.nlm.nih.gov/21969982/">https://pubmed.ncbi.nlm.nih.gov/21969982/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fosr">fosr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
# Test effect of region on mean temperature in the Canadian weather data
# The next two lines are taken from the fRegress.CV help file (package fda)
smallbasis  &lt;- create.fourier.basis(c(0, 365), 25)
tempfd &lt;- smooth.basis(day.5,
          CanadianWeather$dailyAv[,,"Temperature.C"], smallbasis)$fd

Xreg = cbind(1, model.matrix(~factor(CanadianWeather$region)-1))
conreg = matrix(c(0,1,1,1,1), 1)   # constrain region effects to sum to 0

# This is for illustration only; for a real test, must increase nperm
# (and probably prelim as well)
regionperm = fosr.perm(fdobj=tempfd, X=Xreg, con=conreg, method="OLS", nperm=10, prelim=3)

# Redo the plot, using axisIntervals() from the fda package
plot(regionperm, axes=FALSE, xlab="")
box()
axis(2)
axisIntervals(1)

## End(Not run)

</code></pre>

<hr>
<h2 id='fosr.vs'>Function-on Scalar Regression with variable selection</h2><span id='topic+fosr.vs'></span>

<h3>Description</h3>

<p>Implements an iterative algorithm for function-on-scalar regression with variable selection
by alternatively updating the coefficients and covariance structure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fosr.vs(
  formula,
  data,
  nbasis = 10,
  method = c("ls", "grLasso", "grMCP", "grSCAD"),
  epsilon = 1e-05,
  max.iter_num = 100
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fosr.vs_+3A_formula">formula</code></td>
<td>
<p>an object of class &quot;<code><a href="stats.html#topic+formula">formula</a></code>&quot;: an expression of the model to be fitted.</p>
</td></tr>
<tr><td><code id="fosr.vs_+3A_data">data</code></td>
<td>
<p>a data frame that contains the variables in the model.</p>
</td></tr>
<tr><td><code id="fosr.vs_+3A_nbasis">nbasis</code></td>
<td>
<p>number of B-spline basis functions used.</p>
</td></tr>
<tr><td><code id="fosr.vs_+3A_method">method</code></td>
<td>
<p>group variable selection method to be used (&quot;grLasso&quot;, &quot;grMCP&quot;, &quot;grSCAD&quot; refer to group Lasso, group MCP and group SCAD, respectively) or &quot;<code>ls</code>&quot; for least squares estimation.</p>
</td></tr>
<tr><td><code id="fosr.vs_+3A_epsilon">epsilon</code></td>
<td>
<p>the convergence criterion.</p>
</td></tr>
<tr><td><code id="fosr.vs_+3A_max.iter_num">max.iter_num</code></td>
<td>
<p>maximum number of iterations.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted fosr.vs-object, which is a list with the following elements:
</p>
<table>
<tr><td><code>formula</code></td>
<td>
<p>an object of class &quot;<code><a href="stats.html#topic+formula">formula</a></code>&quot;: an expression of the model to be fitted.</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>the estimated coefficient functions.</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>the fitted curves.</p>
</td></tr>
<tr><td><code>residuals</code></td>
<td>
<p>the residual curves.</p>
</td></tr>
<tr><td><code>vcov</code></td>
<td>
<p>the estimated variance-covariance matrix when convergence is achieved.</p>
</td></tr>
<tr><td><code>method</code></td>
<td>
<p>group variable selection method to be used or &quot;<code>ls</code>&quot; for least squares estimation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Yakuan Chen <a href="mailto:yc2641@cumc.columbia.edu">yc2641@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Chen, Y., Goldsmith, J., and Ogden, T. (2016).
Variable selection in function-on-scalar regression. <em>Stat</em> 5 88-101
</p>


<h3>See Also</h3>

<p><code><a href="grpreg.html#topic+grpreg">grpreg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(100)

I = 100
p = 20
D = 50
grid = seq(0, 1, length = D)

beta.true = matrix(0, p, D)
beta.true[1,] = sin(2*grid*pi)
beta.true[2,] = cos(2*grid*pi)
beta.true[3,] = 2

psi.true = matrix(NA, 2, D)
psi.true[1,] = sin(4*grid*pi)
psi.true[2,] = cos(4*grid*pi)
lambda = c(3,1)

set.seed(100)

X = matrix(rnorm(I*p), I, p)
C = cbind(rnorm(I, mean = 0, sd = lambda[1]), rnorm(I, mean = 0, sd = lambda[2]))

fixef = X%*%beta.true
pcaef = C %*% psi.true
error = matrix(rnorm(I*D), I, D)

Yi.true = fixef
Yi.pca = fixef + pcaef
Yi.obs = fixef + pcaef + error

data = as.data.frame(X)
data$Y = Yi.obs
fit.fosr.vs = fosr.vs(Y~., data = data, method="grMCP")
plot(fit.fosr.vs)

## End(Not run)


</code></pre>

<hr>
<h2 id='fosr2s'>Two-step function-on-scalar regression</h2><span id='topic+fosr2s'></span>

<h3>Description</h3>

<p>This function performs linear regression with functional responses and
scalar predictors by (1) fitting a separate linear model at each point
along the function, and then (2) smoothing the resulting coefficients to
obtain coefficient functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fosr2s(
  Y,
  X,
  argvals = seq(0, 1, , ncol(Y)),
  nbasis = 15,
  norder = 4,
  pen.order = norder - 2,
  basistype = "bspline"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fosr2s_+3A_y">Y</code></td>
<td>
<p>the functional responses, given as an <code class="reqn">n\times d</code> matrix.</p>
</td></tr>
<tr><td><code id="fosr2s_+3A_x">X</code></td>
<td>
<p><code class="reqn">n\times p</code> model matrix, whose columns represent scalar
predictors. Should ordinarily include a column of 1s.</p>
</td></tr>
<tr><td><code id="fosr2s_+3A_argvals">argvals</code></td>
<td>
<p>the <code class="reqn">d</code> argument values at which the functional
responses are evaluated, and at which the coefficient functions will be
evaluated.</p>
</td></tr>
<tr><td><code id="fosr2s_+3A_nbasis">nbasis</code></td>
<td>
<p>number of basis functions used to represent the coefficient
functions.</p>
</td></tr>
<tr><td><code id="fosr2s_+3A_norder">norder</code></td>
<td>
<p>norder of the spline basis, when <code>basistype="bspline"</code>
(the default, 4, gives cubic splines).</p>
</td></tr>
<tr><td><code id="fosr2s_+3A_pen.order">pen.order</code></td>
<td>
<p>order of derivative penalty.</p>
</td></tr>
<tr><td><code id="fosr2s_+3A_basistype">basistype</code></td>
<td>
<p>type of basis used. The basis is created by an appropriate
constructor function from the <span class="pkg">fda</span> package; see basisfd. Only <code>"bspline"</code> and <code>"fourier"</code> are
supported.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Unlike <code><a href="#topic+fosr">fosr</a></code> and <code><a href="#topic+pffr">pffr</a></code>, which obtain smooth
coefficient functions by minimizing a penalized criterion, this function
introduces smoothing only as a second step. The idea was proposed by Fan
and Zhang (2000), who employed local polynomials rather than roughness
penalization for the smoothing step.
</p>


<h3>Value</h3>

<p>An object of class <code>fosr</code>, which is a list with the following
elements: </p>
<table>
<tr><td><code>fd</code></td>
<td>
<p>object of class <code>"<a href="fda.html#topic+fd">fd</a>"</code> representing the
estimated coefficient functions. Its main components are a basis and a
matrix of coefficients with respect to that basis. </p>
</td></tr>
<tr><td><code>raw.coef</code></td>
<td>
<p><code class="reqn">d\times p</code> matrix of coefficient estimates from
regressing on <code>X</code> separately at each point along the function. </p>
</td></tr>
<tr><td><code>raw.se</code></td>
<td>
<p><code class="reqn">d\times p</code> matrix of standard errors of the raw
coefficient estimates. </p>
</td></tr> <tr><td><code>yhat</code></td>
<td>
<p><code class="reqn">n\times d</code> matrix of fitted
values. </p>
</td></tr> <tr><td><code>est.func</code></td>
<td>
<p><code class="reqn">d\times p</code> matrix of coefficient function
estimates, obtained by smoothing the columns of <code>raw.coef</code>. </p>
</td></tr>
<tr><td><code>se.func</code></td>
<td>
<p><code class="reqn">d\times p</code> matrix of coefficient function standard
errors. </p>
</td></tr> <tr><td><code>argvals</code></td>
<td>
<p>points at which the coefficient functions are
evaluated. </p>
</td></tr> <tr><td><code>lambda</code></td>
<td>
<p>smoothing parameters (chosen by REML) used to
smooth the <code class="reqn">p</code> coefficient functions with respect to the supplied
basis. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a> and Lan Huo
</p>


<h3>References</h3>

<p>Fan, J., and Zhang, J.-T. (2000). Two-step estimation of
functional linear models with applications to longitudinal data.
<em>Journal of the Royal Statistical Society, Series B</em>, 62(2), 303&ndash;322.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fosr">fosr</a></code>, <code><a href="#topic+pffr">pffr</a></code>
</p>

<hr>
<h2 id='fpc'>Construct a FPC regression term</h2><span id='topic+fpc'></span>

<h3>Description</h3>

<p>Constructs a functional principal component regression (Reiss and Ogden, 
2007, 2010) term for inclusion in an <code>mgcv::gam</code>-formula (or
<code><a href="mgcv.html#topic+bam">bam</a></code> or <code><a href="mgcv.html#topic+gamm">gamm</a></code> or <code>gamm4:::gamm</code>) as
constructed by <code><a href="#topic+pfr">pfr</a></code>. Currently only one-dimensional functions
are allowed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpc(
  X,
  argvals = NULL,
  method = c("svd", "fpca.sc", "fpca.face", "fpca.ssvd"),
  ncomp = NULL,
  pve = 0.99,
  penalize = (method == "svd"),
  bs = "ps",
  k = 40,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpc_+3A_x">X</code></td>
<td>
<p>functional predictors, typically expressed as an <code>N</code> by <code>J</code> matrix,
where <code>N</code> is the number of columns and <code>J</code> is the number of
evaluation points. May include missing/sparse functions, which are
indicated by <code>NA</code> values. Alternatively, can be an object of class
<code>"fd"</code>; see <code><a href="fda.html#topic+fd">fd</a></code>.</p>
</td></tr>
<tr><td><code id="fpc_+3A_argvals">argvals</code></td>
<td>
<p>indices of evaluation of <code>X</code>, i.e. <code class="reqn">(t_{i1},.,t_{iJ})</code> for
subject <code class="reqn">i</code>. May be entered as either a length-<code>J</code> vector, or as
an <code>N</code> by <code>J</code> matrix. Indices may be unequally spaced. Entering
as a matrix allows for different observations times for each subject. If
<code>NULL</code>, defaults to an equally-spaced grid between 0 or 1 (or within
<code>X$basis$rangeval</code> if <code>X</code> is a <code>fd</code> object.)</p>
</td></tr>
<tr><td><code id="fpc_+3A_method">method</code></td>
<td>
<p>the method used for finding principal components. The default
is an unconstrained SVD of the <code class="reqn">XB</code> matrix. Alternatives include
constrained (functional) principal components approaches</p>
</td></tr>
<tr><td><code id="fpc_+3A_ncomp">ncomp</code></td>
<td>
<p>number of principal components. if <code>NULL</code>, chosen by <code>pve</code></p>
</td></tr>
<tr><td><code id="fpc_+3A_pve">pve</code></td>
<td>
<p>proportion of variance explained; used to choose the number of
principal components</p>
</td></tr>
<tr><td><code id="fpc_+3A_penalize">penalize</code></td>
<td>
<p>if <code>TRUE</code>, a roughness penalty is applied to the
functional estimate. Defaults to <code>TRUE</code> if <code>method=="svd"</code>
(corresponding to the FPCR_R method of Reiss and Ogden (2007)), and
<code>FALSE</code> if <code>method!="svd"</code> (corresponding to FPCR_C).</p>
</td></tr>
<tr><td><code id="fpc_+3A_bs">bs</code></td>
<td>
<p>two letter character string indicating the <code>mgcv</code>-style basis
to use for pre-smoothing <code>X</code></p>
</td></tr>
<tr><td><code id="fpc_+3A_k">k</code></td>
<td>
<p>the dimension of the pre-smoothing basis</p>
</td></tr>
<tr><td><code id="fpc_+3A_...">...</code></td>
<td>
<p>additional options to be passed to <code><a href="#topic+lf">lf</a></code>. These include
<code>argvals</code>, <code>integration</code>, and any additional options for the
pre-smoothing basis (as constructed by <code>mgcv::s</code>), such as <code>m</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>fpc</code> is a wrapper for <code><a href="#topic+lf">lf</a></code>, which defines linear
functional predictors for any type of basis for inclusion in a <code>pfr</code>
formula. <code>fpc</code> simply calls <code>lf</code> with the appropriate options for
the <code>fpc</code> basis and penalty construction.
</p>
<p>This function implements both the FPCR-R and FPCR-C methods of Reiss and
Ogden (2007). Both methods consist of the following steps:
</p>

<ol>
<li><p> project <code class="reqn">X</code> onto a spline basis <code class="reqn">B</code>
</p>
</li>
<li><p> perform a principal components decomposition of <code class="reqn">XB</code>
</p>
</li>
<li><p> use those PC's as the basis in fitting a (generalized) functional
linear model
</p>
</li></ol>

<p>This implementation provides options for each of these steps. The basis
for in step 1 can be specified using the arguments <code>bs</code> and <code>k</code>,
as well as other options via <code>...</code>; see <code><a href="mgcv.html#topic+s">s</a></code> for
these options. The type of PC-decomposition is specified with <code>method</code>.
And the FLM can be fit either penalized or unpenalized via <code>penalize</code>.
</p>
<p>The default is FPCR-R, which uses a b-spline basis, an unconstrained 
principal components decomposition using <code><a href="base.html#topic+svd">svd</a></code>, and the FLM
fit with a second-order difference penalty. FPCR-C can be selected by
using a different option for <code>method</code>, indicating a constrained
(&quot;functional&quot;) PC decomposition, and by default an unpenalized fit of the
FLM.
</p>
<p>FPCR-R is also implemented in <code><a href="#topic+fpcr">fpcr</a></code>; here we implement the
method for inclusion in a <code>pfr</code> formula.
</p>


<h3>Value</h3>

<p>The result of a call to <code><a href="#topic+lf">lf</a></code>.
</p>


<h3>NOTE</h3>

<p>Unlike <code><a href="#topic+fpcr">fpcr</a></code>, <code>fpc</code> within a <code>pfr</code> formula does
not automatically decorrelate the functional predictors from additional
scalar covariates.
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar <a href="mailto:JGellar@mathematica-mpr.com">JGellar@mathematica-mpr.com</a>, Phil Reiss
<a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a>, Lan Huo <a href="mailto:lan.huo@nyumc.org">lan.huo@nyumc.org</a>, and
Lei Huang <a href="mailto:huangracer@gmail.com">huangracer@gmail.com</a>
</p>


<h3>References</h3>

<p>Reiss, P. T. (2006). Regression with signals and images as predictors. Ph.D.
dissertation, Department of Biostatistics, Columbia University. Available
at http://works.bepress.com/phil_reiss/11/.
</p>
<p>Reiss, P. T., and Ogden, R. T. (2007). Functional principal component
regression and functional partial least squares. <em>Journal of the
American Statistical Association</em>, 102, 984-996.
</p>
<p>Reiss, P. T., and Ogden, R. T. (2010). Functional generalized linear models
with images as predictors. <em>Biometrics</em>, 66, 61-69.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lf">lf</a></code>, <code><a href="#topic+smooth.construct.fpc.smooth.spec">smooth.construct.fpc.smooth.spec</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(gasoline)
par(mfrow=c(3,1))

# Fit PFCR_R
gasmod1 &lt;- pfr(octane ~ fpc(NIR, ncomp=30), data=gasoline)
plot(gasmod1, rug=FALSE)
est1 &lt;- coef(gasmod1)

# Fit FPCR_C with fpca.sc
gasmod2 &lt;- pfr(octane ~ fpc(NIR, method="fpca.sc", ncomp=6), data=gasoline)
plot(gasmod2, se=FALSE)
est2 &lt;- coef(gasmod2)

# Fit penalized model with fpca.face
gasmod3 &lt;- pfr(octane ~ fpc(NIR, method="fpca.face", penalize=TRUE), data=gasoline)
plot(gasmod3, rug=FALSE)
est3 &lt;- coef(gasmod3)

par(mfrow=c(1,1))
ylm &lt;- range(est1$value)*1.35
plot(value ~ X.argvals, type="l", data=est1, ylim=ylm)
lines(value ~ X.argvals, col=2, data=est2)
lines(value ~ X.argvals, col=3, data=est3)

</code></pre>

<hr>
<h2 id='fpca.face'>Functional principal component analysis with fast covariance estimation</h2><span id='topic+fpca.face'></span>

<h3>Description</h3>

<p>A fast implementation of the sandwich smoother (Xiao et al., 2013)
for covariance matrix smoothing. Pooled generalized cross validation
at the data level is used for selecting the smoothing parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpca.face(
  Y = NULL,
  ydata = NULL,
  Y.pred = NULL,
  argvals = NULL,
  pve = 0.99,
  npc = NULL,
  var = FALSE,
  simul = FALSE,
  sim.alpha = 0.95,
  center = TRUE,
  knots = 35,
  p = 3,
  m = 2,
  lambda = NULL,
  alpha = 1,
  search.grid = TRUE,
  search.length = 100,
  method = "L-BFGS-B",
  lower = -20,
  upper = 20,
  control = NULL,
  periodicity = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpca.face_+3A_y">Y</code>, <code id="fpca.face_+3A_ydata">ydata</code></td>
<td>
<p>the user must supply either <code>Y</code>, a matrix of functions
observed on a regular grid, or a data frame <code>ydata</code> representing
irregularly observed functions. See Details.</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_y.pred">Y.pred</code></td>
<td>
<p>if desired, a matrix of functions to be approximated using
the FPC decomposition.</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_argvals">argvals</code></td>
<td>
<p>numeric; function argument.</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_pve">pve</code></td>
<td>
<p>proportion of variance explained: used to choose the number of
principal components.</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_npc">npc</code></td>
<td>
<p>how many smooth SVs to try to extract, if <code>NA</code> (the
default) the hard thresholding rule of Gavish and Donoho (2014) is used (see
Details, References).</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_var">var</code></td>
<td>
<p>logical; should an estimate of standard error be returned?</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_simul">simul</code></td>
<td>
<p>logical; if <code>TRUE</code> curves will we simulated using
Monte Carlo to obtain an estimate of the <code>sim.alpha</code> quantile at each
<code>argval</code>; ignored if <code>var == FALSE</code></p>
</td></tr>
<tr><td><code id="fpca.face_+3A_sim.alpha">sim.alpha</code></td>
<td>
<p>numeric; if <code>simul==TRUE</code>, quantile to estimate at
each <code>argval</code>; ignored if <code>var == FALSE</code></p>
</td></tr>
<tr><td><code id="fpca.face_+3A_center">center</code></td>
<td>
<p>logical; center <code>Y</code> so that its column-means are 0? Defaults to
<code>TRUE</code></p>
</td></tr>
<tr><td><code id="fpca.face_+3A_knots">knots</code></td>
<td>
<p>number of knots to use or the vectors of knots; defaults to 35</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_p">p</code></td>
<td>
<p>integer; the degree of B-splines functions to use</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_m">m</code></td>
<td>
<p>integer; the order of difference penalty to use</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_lambda">lambda</code></td>
<td>
<p>smoothing parameter; if not specified smoothing parameter is
chosen using <code><a href="stats.html#topic+optim">optim</a></code> or a grid search</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_alpha">alpha</code></td>
<td>
<p>numeric; tuning parameter for GCV; see parameter <code>gamma</code>
in <code><a href="mgcv.html#topic+gam">gam</a></code></p>
</td></tr>
<tr><td><code id="fpca.face_+3A_search.grid">search.grid</code></td>
<td>
<p>logical; should a grid search be used to find <code>lambda</code>?
Otherwise, <code><a href="stats.html#topic+optim">optim</a></code> is used</p>
</td></tr>
<tr><td><code id="fpca.face_+3A_search.length">search.length</code></td>
<td>
<p>integer; length of grid to use for grid search for
<code>lambda</code>; ignored if <code>search.grid</code> is <code>FALSE</code></p>
</td></tr>
<tr><td><code id="fpca.face_+3A_method">method</code></td>
<td>
<p>method to use; see <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fpca.face_+3A_lower">lower</code></td>
<td>
<p>see <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fpca.face_+3A_upper">upper</code></td>
<td>
<p>see <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fpca.face_+3A_control">control</code></td>
<td>
<p>see <code><a href="stats.html#topic+optim">optim</a></code></p>
</td></tr>
<tr><td><code id="fpca.face_+3A_periodicity">periodicity</code></td>
<td>
<p>Option for a periodic spline basis. Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components
</p>

<ol>
<li> <p><code>Yhat</code> - If <code>Y.pred</code> is specified, the smooth version of
<code>Y.pred</code>.   Otherwise, if <code>Y.pred=NULL</code>, the smooth version of <code>Y</code>.
</p>
</li>
<li> <p><code>scores</code> - matrix of scores
</p>
</li>
<li> <p><code>mu</code> - mean function
</p>
</li>
<li> <p><code>npc</code> - number of principal components
</p>
</li>
<li> <p><code>efunctions</code> - matrix of eigenvectors
</p>
</li>
<li> <p><code>evalues</code> - vector of eigenvalues
</p>
</li>
<li> <p><code>pve</code> - The percent variance explained by the returned number of PCs
</p>
</li></ol>

<p>if <code>var == TRUE</code> additional components are returned
</p>

<ol>
<li> <p><code>sigma2</code> - estimate of the error variance
</p>
</li>
<li> <p><code>VarMats</code> - list of covariance function estimate for each
subject
</p>
</li>
<li> <p><code>diag.var</code> - matrix containing the diagonals of each matrix in
</p>
</li>
<li> <p><code>crit.val</code> - list of estimated quantiles; only returned if
<code>simul == TRUE</code>
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Luo Xiao
</p>


<h3>References</h3>

<p>Xiao, L., Li, Y., and Ruppert, D. (2013).
Fast bivariate <em>P</em>-splines: the sandwich smoother,
<em>Journal of the Royal Statistical Society: Series B</em>, 75(3), 577-599.
</p>
<p>Xiao, L., Ruppert, D., Zipunnikov, V., and Crainiceanu, C. (2016).
Fast covariance estimation for high-dimensional functional data.
<em>Statistics and Computing</em>, 26, 409-421.
DOI: 10.1007/s11222-014-9485-x.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fpca.sc">fpca.sc</a></code>  for another covariance-estimate based
smoothing of <code>Y</code>; <code><a href="#topic+fpca2s">fpca2s</a></code> and <code><a href="#topic+fpca.ssvd">fpca.ssvd</a></code>
for two SVD-based smoothings.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### settings
I &lt;- 50 # number of subjects
J &lt;- 3000 # dimension of the data
t &lt;- (1:J)/J # a regular grid on [0,1]
N &lt;- 4 #number of eigenfunctions
sigma &lt;- 2 ##standard deviation of random noises
lambdaTrue &lt;- c(1,0.5,0.5^2,0.5^3) # True eigenvalues

case = 1
### True Eigenfunctions

if(case==1) phi &lt;- sqrt(2)*cbind(sin(2*pi*t),cos(2*pi*t),
                                sin(4*pi*t),cos(4*pi*t))
if(case==2) phi &lt;- cbind(rep(1,J),sqrt(3)*(2*t-1),
                          sqrt(5)*(6*t^2-6*t+1),
                         sqrt(7)*(20*t^3-30*t^2+12*t-1))

###################################################
########     Generate Data            #############
###################################################
xi &lt;- matrix(rnorm(I*N),I,N);
xi &lt;- xi %*% diag(sqrt(lambdaTrue))
X &lt;- xi %*% t(phi); # of size I by J
Y &lt;- X + sigma*matrix(rnorm(I*J),I,J)

results &lt;- fpca.face(Y,center = TRUE, argvals=t,knots=100,pve=0.99)

# calculate percent variance explained by each PC
 evalues = results$evalues
 pve_vec = evalues * results$npc/sum(evalues)

###################################################
####               FACE                ########
###################################################
Phi &lt;- results$efunctions
eigenvalues &lt;- results$evalues

for(k in 1:N){
  if(Phi[,k] %*% phi[,k]&lt; 0)
    Phi[,k] &lt;- - Phi[,k]
}

### plot eigenfunctions
par(mfrow=c(N/2,2))
seq &lt;- (1:(J/10))*10
for(k in 1:N){
  plot(t[seq],Phi[seq,k]*sqrt(J),type="l",lwd = 3,
       ylim = c(-2,2),col = "red",
       ylab = paste("Eigenfunction ",k,sep=""),
       xlab="t",main="FACE")

  lines(t[seq],phi[seq,k],lwd = 2, col = "black")
}
</code></pre>

<hr>
<h2 id='fpca.lfda'>Longitudinal Functional Data Analysis using FPCA</h2><span id='topic+fpca.lfda'></span>

<h3>Description</h3>

<p>Implements longitudinal functional data analysis (Park and Staicu, 2015).
It decomposes longitudinally-observed functional observations in two steps.
It first applies FPCA on a properly defined marginal covariance function and obtain estimated scores (mFPCA step).
Then it further models the underlying process dynamics by applying another FPCA on a covariance of the estimated scores
obtained in the mFPCA step. The function also allows to use a random effects model to study the underlying process dynamics
instead of a KL expansion model in the second step. Scores in mFPCA step are estimated
using numerical integration. Scores in sFPCA step are estimated under a mixed model framework.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpca.lfda(
  Y,
  subject.index,
  visit.index,
  obsT = NULL,
  funcArg = NULL,
  numTEvalPoints = 41,
  newdata = NULL,
  fbps.knots = c(5, 10),
  fbps.p = 3,
  fbps.m = 2,
  mFPCA.pve = 0.95,
  mFPCA.knots = 35,
  mFPCA.p = 3,
  mFPCA.m = 2,
  mFPCA.npc = NULL,
  LongiModel.method = c("fpca.sc", "lme"),
  sFPCA.pve = 0.95,
  sFPCA.nbasis = 10,
  sFPCA.npc = NULL,
  gam.method = "REML",
  gam.kT = 10
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpca.lfda_+3A_y">Y</code></td>
<td>
<p>a matrix of which each row corresponds to one curve observed on a regular and dense grid 
(dimension of N by m; N = total number of observed functions; m = number of grid points)</p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_subject.index">subject.index</code></td>
<td>
<p>subject id; vector of length N with each element corresponding a row of Y</p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_visit.index">visit.index</code></td>
<td>
<p>index for visits (repeated measures); vector of length N with each element corresponding a row of Y</p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_obst">obsT</code></td>
<td>
<p>actual time of visits at which a function is observed; vector of length N with each element corresponding a row of Y</p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_funcarg">funcArg</code></td>
<td>
<p>numeric; function argument</p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_numtevalpoints">numTEvalPoints</code></td>
<td>
<p>total number of evaluation time points for visits; used for pre-binning in sFPCA step; defaults to 41</p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_newdata">newdata</code></td>
<td>
<p>an optional data frame providing predictors (i for subject id / Ltime for visit time) with which prediction is desired; defaults to NULL</p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_fbps.knots">fbps.knots</code></td>
<td>
<p>list of two vectors of knots or number of equidistanct knots for all dimensions
for a fast bivariate <em>P</em>-spline smoothing (fbps) method used to estimate a bivariate, smooth mean function; defaults to c(5,10); see <code>fbps</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_fbps.p">fbps.p</code></td>
<td>
<p>integer;degrees of B-spline functions to use for a fbps method; defaults to 3; see <code>fbps</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_fbps.m">fbps.m</code></td>
<td>
<p>integer;order of differencing penalty to use for a fbps method; defaults to 2; see <code>fbps</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_mfpca.pve">mFPCA.pve</code></td>
<td>
<p>proportion of variance explained for a mFPCA step; used to choose the number of principal components (PCs); defaults to 0.95; see <code>fpca.face</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_mfpca.knots">mFPCA.knots</code></td>
<td>
<p>number of knots to use or the vectors of knots in a mFPCA step; used for obtain a smooth estimate of a covariance function; defaults to 35; see <code>fpca.face</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_mfpca.p">mFPCA.p</code></td>
<td>
<p>integer; the degree of B-spline functions to use in a mFPCA step; defaults to 3; see <code>fpca.face</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_mfpca.m">mFPCA.m</code></td>
<td>
<p>integer;order of differencing penalty to use in a mFPCA step; defaults to 2; see <code>fpca.face</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_mfpca.npc">mFPCA.npc</code></td>
<td>
<p>pre-specified value for the number of principal components; if given, it overrides <code>pve</code>; defaults to NULL; see <code>fpca.face</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_longimodel.method">LongiModel.method</code></td>
<td>
<p>model and estimation method for estimating covariance of estimated scores from a mFPCA step; 
either KL expansion model or random effects model; defaults to fpca.sc</p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_sfpca.pve">sFPCA.pve</code></td>
<td>
<p>proportion of variance explained for sFPCA step; used to choose the number of principal components; defaults to 0.95; see <code>fpca.sc</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_sfpca.nbasis">sFPCA.nbasis</code></td>
<td>
<p>number of B-spline basis functions used in sFPCA step for estimation of the mean function and bivariate smoothing of the covariance surface; defaults to 10; see <code>fpca.sc</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_sfpca.npc">sFPCA.npc</code></td>
<td>
<p>pre-specified value for the number of principal components; if given, it overrides <code>pve</code>; defaults to NULL; see <code>fpca.sc</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_gam.method">gam.method</code></td>
<td>
<p>smoothing parameter estimation method when <code>gam</code> is used for predicting score functions at unobserved visit time, T; defaults to <code>REML</code>; see <code>gam</code></p>
</td></tr>
<tr><td><code id="fpca.lfda_+3A_gam.kt">gam.kT</code></td>
<td>
<p>dimension of basis functions to use; see <code>gam</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components </p>
<table>
<tr><td><code>obsData</code></td>
<td>
<p>observed data (input)</p>
</td></tr>
<tr><td><code>i</code></td>
<td>
<p>subject id</p>
</td></tr> <tr><td><code>funcArg</code></td>
<td>
<p>function argument</p>
</td></tr> <tr><td><code>visitTime</code></td>
<td>
<p>visit times</p>
</td></tr>
<tr><td><code>fitted.values</code></td>
<td>
<p>fitted values (in-sample); of the same dimension as Y</p>
</td></tr> <tr><td><code>fitted.values.all</code></td>
<td>
<p>a list of which each component consists of a subject's fitted values at all pairs of evaluation points (s and T)</p>
</td></tr> 
<tr><td><code>predicted.values</code></td>
<td>
<p>predicted values for variables provided in newdata</p>
</td></tr>
<tr><td><code>bivariateSmoothMeanFunc</code></td>
<td>
<p>estimated bivariate smooth mean function</p>
</td></tr>
<tr><td><code>mFPCA.efunctions</code></td>
<td>
<p>estimated eigenfunction in a mFPCA step</p>
</td></tr> <tr><td><code>mFPCA.evalues</code></td>
<td>
<p>estimated eigenvalues in a mFPCA step</p>
</td></tr>
<tr><td><code>mFPCA.npc</code></td>
<td>
<p>number of principal components selected with pre-specified pve in a mFPCA step</p>
</td></tr> <tr><td><code>mFPCA.scree.eval</code></td>
<td>
<p>estimated eigenvalues obtained with pre-specified pve = 0.9999; for scree plot</p>
</td></tr>
<tr><td><code>sFPCA.xiHat.bySubj</code></td>
<td>
<p>a list of which each component consists of a subject's predicted score functions evaluated at equidistanced grid in direction of visit time, T</p>
</td></tr> 
<tr><td><code>sFPCA.npc</code></td>
<td>
<p>a vector of numbers of principal components selected in a sFPCA step with pre-specified pve; length of mFPCA.npc</p>
</td></tr>
<tr><td><code>mFPCA.covar</code></td>
<td>
<p>estimated marginal covariance</p>
</td></tr> <tr><td><code>sFPCA.longDynCov.k</code></td>
<td>
<p>a list of estimated covariance of score function; length of mFPCA.npc</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A random effects model is recommended when a set of visit times for all subjects and visits is not dense in its range.
</p>


<h3>Author(s)</h3>

<p>So Young Park <a href="mailto:spark13@ncsu.edu">spark13@ncsu.edu</a>, Ana-Maria Staicu
</p>


<h3>References</h3>

<p>Park, S.Y. and Staicu, A.M. (2015). Longitudinal functional data analysis. Stat 4 212-226.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  ## Not run:  
  ########################################
  ###   Illustration with real data    ###
  ########################################   

  data(DTI)
  MS &lt;- subset(DTI, case ==1)  # subset data with multiple sclerosis (MS) case

  index.na &lt;- which(is.na(MS$cca))  
  Y &lt;- MS$cca; Y[index.na] &lt;- fpca.sc(Y)$Yhat[index.na]; sum(is.na(Y))
  id &lt;- MS$ID 
  visit.index &lt;- MS$visit 
  visit.time &lt;- MS$visit.time/max(MS$visit.time)

  lfpca.dti &lt;- fpca.lfda(Y = Y, subject.index = id,  
                         visit.index = visit.index, obsT = visit.time, 
                         LongiModel.method = 'lme',
                         mFPCA.pve = 0.95)
                         
  TT &lt;- seq(0,1,length.out=41); ss = seq(0,1,length.out=93)
  
  # estimated mean function
  persp(x = ss, y = TT, z = t(lfpca.dti$bivariateSmoothMeanFunc),
        xlab="s", ylab="visit times", zlab="estimated mean fn", col='light blue')
        
  # first three estimated marginal eigenfunctions
  matplot(ss, lfpca.dti$mFPCA.efunctions[,1:3], type='l', xlab='s', ylab='estimated eigen fn')
  
  # predicted scores function corresponding to first two marginal PCs
  matplot(TT, do.call(cbind, lapply(lfpca.dti$sFPCA.xiHat.bySubj, function(a) a[,1])),
          xlab="visit time (T)", ylab="xi_hat(T)", main = "k = 1", type='l')
  matplot(TT, do.call(cbind, lapply(lfpca.dti$sFPCA.xiHat.bySubj, function(a) a[,2])),
          xlab="visit time (T)", ylab="xi_hat(T)", main = "k = 2", type='l')

  # prediction of cca of first two subjects at T = 0, 0.5 and 1 (black, red, green)
  matplot(ss, t(lfpca.dti$fitted.values.all[[1]][c(1,21,41),]), 
         type='l', lty = 1, ylab="", xlab="s", main = "Subject = 1")    
  matplot(ss, t(lfpca.dti$fitted.values.all[[2]][c(1,21,41),]), 
         type='l', lty = 1, ylab="", xlab="s", main = "Subject = 2")    
     
  ########################################
  ### Illustration with simulated data ###
  ########################################   

  ###########################################################################################
  # data generation
  ###########################################################################################
  set.seed(1)
  n &lt;- 100 # number of subjects
  ss &lt;- seq(0,1,length.out=101) 
  TT &lt;- seq(0, 1, length.out=41)
  mi &lt;- runif(n, min=6, max=15)
  ij &lt;- sapply(mi, function(a) sort(sample(1:41, size=a, replace=FALSE)))
  
  # error variances
  sigma &lt;- 0.1 
  sigma_wn &lt;- 0.2

  lambdaTrue &lt;- c(1,0.5) # True eigenvalues
  eta1True &lt;- c(0.5, 0.5^2, 0.5^3) # True eigenvalues
  eta2True &lt;- c(0.5^2, 0.5^3) # True eigenvalues
  
  phi &lt;- sqrt(2)*cbind(sin(2*pi*ss),cos(2*pi*ss))
  psi1 &lt;- cbind(rep(1,length(TT)), sqrt(3)*(2*TT-1), sqrt(5)*(6*TT^2-6*TT+1))
  psi2 &lt;- sqrt(2)*cbind(sin(2*pi*TT),cos(2*pi*TT))
  
  zeta1 &lt;- sapply(eta1True, function(a) rnorm(n = n, mean = 0, sd = a))
  zeta2 &lt;- sapply(eta2True, function(a) rnorm(n = n, mean = 0, sd = a))
  
  xi1 &lt;- unlist(lapply(1:n, function(a) (zeta1 %*% t(psi1))[a,ij[[a]]] ))
  xi2 &lt;- unlist(lapply(1:n, function(a) (zeta2 %*% t(psi2))[a,ij[[a]]] ))
  xi &lt;- cbind(xi1, xi2)
  
  Tij &lt;- unlist(lapply(1:n, function(i) TT[ij[[i]]] ))
  i &lt;- unlist(lapply(1:n, function(i) rep(i, length(ij[[i]]))))
  j &lt;- unlist(lapply(1:n, function(i) 1:length(ij[[i]])))
  
  X &lt;- xi %*% t(phi)
  meanFn &lt;- function(s,t){ 0.5*t + 1.5*s + 1.3*s*t}
  mu &lt;- matrix(meanFn(s = rep(ss, each=length(Tij)), t=rep(Tij, length(ss)) ) , nrow=nrow(X))

  Y &lt;- mu +  X + 
     matrix(rnorm(nrow(X)*ncol(phi), 0, sigma), nrow=nrow(X)) %*% t(phi) + #correlated error
     matrix(rnorm(length(X), 0, sigma_wn), nrow=nrow(X)) # white noise

  matplot(ss, t(Y[which(i==2),]), type='l', ylab="", xlab="functional argument", 
         main="observations from subject i = 2")
  # END: data generation
  
  ###########################################################################################
  # Illustration I : when covariance of scores from a mFPCA step is estimated using fpca.sc
  ###########################################################################################
  est &lt;- fpca.lfda(Y = Y, 
                   subject.index = i, visit.index = j, obsT = Tij, 
                   funcArg = ss, numTEvalPoints = length(TT), 
                   newdata = data.frame(i = c(1:3), Ltime = c(Tij[1], 0.2, 0.5)), 
                   fbps.knots = 35, fbps.p = 3, fbps.m = 2,
                   LongiModel.method='fpca.sc',
                   mFPCA.pve = 0.95, mFPCA.knots = 35, mFPCA.p = 3, mFPCA.m = 2, 
                   sFPCA.pve = 0.95, sFPCA.nbasis = 10, sFPCA.npc = NULL,
                   gam.method = 'REML', gam.kT = 10)
  
  
  # mean function (true vs. estimated)
  par(mfrow=c(1,2))
  persp(x=TT, y = ss, z= t(sapply(TT, function(a) meanFn(s=ss, t = a))),
          xlab="visit times", ylab="s", zlab="true mean fn")
  persp(x = TT, y = ss, est$bivariateSmoothMeanFunc,
   xlab="visit times", ylab="s", zlab="estimated mean fn", col='light blue')
  
  ################   mFPCA step   ################
  par(mfrow=c(1,2))
  
  # marginal covariance fn (true vs. estimated)
  image(phi%*%diag(lambdaTrue)%*%t(phi))
  image(est$mFPCA.covar) 
  
  # eigenfunctions (true vs. estimated)
  matplot(ss, phi, type='l') 
  matlines(ss, cbind(est$mFPCA.efunctions[,1], est$mFPCA.efunctions[,2]), type='l', lwd=2)
  
  # scree plot
  plot(cumsum(est$mFPCA.scree.eval)/sum(est$mFPCA.scree.eval), type='l', 
       ylab = "Percentage of variance explained")
  points(cumsum(est$mFPCA.scree.eval)/sum(est$mFPCA.scree.eval), pch=16)
  
  ################   sFPCA step   ################
  par(mfrow=c(1,2))
  print(est$mFPCA.npc)  # k = 2
  
  # covariance of score functions for k = 1 (true vs. estimated)
  image(psi1%*%diag(eta1True)%*%t(psi1), main='TRUE')
  image(est$sFPCA.longDynCov.k[[1]], main='ESTIMATED')
  
  # covariance of score functions for k = 2 (true vs. estimated)
  image(psi2%*%diag(eta2True)%*%t(psi2))
  image(est$sFPCA.longDynCov.k[[2]])
  
  # estimated scores functions
  matplot(TT, do.call(cbind,lapply(est$sFPCA.xiHat.bySubj, function(a) a[,1])), 
          xlab="visit time", main="k=1", type='l', ylab="", col=rainbow(100, alpha = 1), 
          lwd=1, lty=1)
  matplot(TT, do.call(cbind,lapply(est$sFPCA.xiHat.bySubj, function(a) a[,2])), 
          xlab="visit time", main="k=2",type='l', ylab="", col=rainbow(100, alpha = 1), 
          lwd=1, lty=1)
  
  ################   In-sample and Out-of-sample Prediction   ################
  par(mfrow=c(1,2))
  # fitted
  matplot(ss, t(Y[which(i==1),]), type='l', ylab="", xlab="functional argument")
  matlines(ss, t(est$fitted.values[which(i==1),]), type='l', lwd=2)
  
 # sanity check : expect fitted and predicted (obtained using info from newdata) 
 #                values to be the same
 
  plot(ss, est$fitted.values[1,], type='p', xlab="", ylab="", pch = 1, cex=1)
  lines(ss, est$predicted.values[1,], type='l', lwd=2, col='blue')
  all.equal(est$predicted.values[1,], est$fitted.values[1,])
  
  ###########################################################################################
  # Illustration II : when covariance of scores from a mFPCA step is estimated using lmer
  ###########################################################################################
  est.lme &lt;- fpca.lfda(Y = Y, 
                       subject.index = i, visit.index = j, obsT = Tij,
                       funcArg = ss, numTEvalPoints = length(TT), 
                       newdata = data.frame(i = c(1:3), Ltime = c(Tij[1], 0.2, 0.5)), 
                       fbps.knots = 35, fbps.p = 3, fbps.m = 2,
                       LongiModel.method='lme',
                       mFPCA.pve = 0.95, mFPCA.knots = 35, mFPCA.p = 3, mFPCA.m = 2, 
                       gam.method = 'REML', gam.kT = 10)
  
  par(mfrow=c(2,2))
  
  # fpca.sc vs. lme (assumes linearity)
  matplot(TT, do.call(cbind,lapply(est$sFPCA.xiHat.bySubj, function(a) a[,1])), 
          xlab="visit time", main="k=1", type='l', ylab="", col=rainbow(100, alpha = 1), 
          lwd=1, lty=1)
  matplot(TT, do.call(cbind,lapply(est$sFPCA.xiHat.bySubj, function(a) a[,2])), 
          xlab="visit time", main="k=2",type='l', ylab="", col=rainbow(100, alpha = 1), 
          lwd=1, lty=1)
          
  matplot(TT, do.call(cbind,lapply(est.lme$sFPCA.xiHat.bySubj, function(a) a[,1])), 
          xlab="visit time", main="k=1", type='l', ylab="", col=rainbow(100, alpha = 1), 
          lwd=1, lty=1)
  matplot(TT, do.call(cbind,lapply(est.lme$sFPCA.xiHat.bySubj, function(a) a[,2])), 
          xlab="visit time", main="k=2", type='l', ylab="", col=rainbow(100, alpha = 1),
          lwd=1, lty=1)
  
## End(Not run)
</code></pre>

<hr>
<h2 id='fpca.sc'>Functional principal components analysis by smoothed covariance</h2><span id='topic+fpca.sc'></span>

<h3>Description</h3>

<p>Decomposes functional observations using functional principal components
analysis. A mixed model framework is used to estimate scores and obtain
variance estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpca.sc(
  Y = NULL,
  ydata = NULL,
  Y.pred = NULL,
  argvals = NULL,
  random.int = FALSE,
  nbasis = 10,
  pve = 0.99,
  npc = NULL,
  var = FALSE,
  simul = FALSE,
  sim.alpha = 0.95,
  useSymm = FALSE,
  makePD = FALSE,
  center = TRUE,
  cov.est.method = 2,
  integration = "trapezoidal"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpca.sc_+3A_y">Y</code>, <code id="fpca.sc_+3A_ydata">ydata</code></td>
<td>
<p>the user must supply either <code>Y</code>, a matrix of functions
observed on a regular grid, or a data frame <code>ydata</code> representing
irregularly observed functions. See Details.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_y.pred">Y.pred</code></td>
<td>
<p>if desired, a matrix of functions to be approximated using
the FPC decomposition.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_argvals">argvals</code></td>
<td>
<p>the argument values of the function evaluations in <code>Y</code>,
defaults to a equidistant grid from 0 to 1.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_random.int">random.int</code></td>
<td>
<p>If <code>TRUE</code>, the mean is estimated by
<code><a href="gamm4.html#topic+gamm4">gamm4</a></code> with random intercepts. If <code>FALSE</code> (the
default), the mean is estimated by <code><a href="mgcv.html#topic+gam">gam</a></code> treating all the
data as independent.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_nbasis">nbasis</code></td>
<td>
<p>number of B-spline basis functions used for estimation of the
mean function and bivariate smoothing of the covariance surface.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_pve">pve</code></td>
<td>
<p>proportion of variance explained: used to choose the number of
principal components.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_npc">npc</code></td>
<td>
<p>prespecified value for the number of principal components (if
given, this overrides <code>pve</code>).</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_var">var</code></td>
<td>
<p><code>TRUE</code> or <code>FALSE</code> indicating whether model-based
estimates for the variance of FPCA expansions should be computed.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_simul">simul</code></td>
<td>
<p>logical: should critical values be estimated for simultaneous
confidence intervals?</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_sim.alpha">sim.alpha</code></td>
<td>
<p>1 - coverage probability of the simultaneous intervals.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_usesymm">useSymm</code></td>
<td>
<p>logical, indicating whether to smooth only the upper
triangular part of the naive covariance (when <code>cov.est.method==2</code>).
This can save computation time for large data sets, and allows for
covariance surfaces that are very peaked on the diagonal.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_makepd">makePD</code></td>
<td>
<p>logical: should positive definiteness be enforced for the
covariance surface estimate?</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_center">center</code></td>
<td>
<p>logical: should an estimated mean function be subtracted from
<code>Y</code>? Set to <code>FALSE</code> if you have already demeaned the data using
your favorite mean function estimate.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_cov.est.method">cov.est.method</code></td>
<td>
<p>covariance estimation method. If set to <code>1</code>, a
one-step method that applies a bivariate smooth to the <code class="reqn">y(s_1)y(s_2)</code>
values. This can be very slow. If set to <code>2</code> (the default), a two-step
method that obtains a naive covariance estimate which is then smoothed.</p>
</td></tr>
<tr><td><code id="fpca.sc_+3A_integration">integration</code></td>
<td>
<p>quadrature method for numerical integration; only
<code>'trapezoidal'</code> is currently supported.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes a FPC decomposition for a set of observed curves,
which may be sparsely observed and/or measured with error. A mixed model
framework is used to estimate curve-specific scores and variances.
</p>
<p>FPCA via kernel smoothing of the covariance function, with the diagonal
treated separately, was proposed in Staniswalis and Lee (1998) and much
extended by Yao et al. (2005), who introduced the 'PACE' method.
<code>fpca.sc</code> uses penalized splines to smooth the covariance function, as
developed by Di et al. (2009) and Goldsmith et al. (2013).
</p>
<p>The functional data must be supplied as either </p>
 <ul>
<li><p> an <code class="reqn">n
\times d</code> matrix <code>Y</code>, each row of which is one functional observation,
with missing values allowed; or </p>
</li>
<li><p> a data frame <code>ydata</code>, with
columns <code>'.id'</code> (which curve the point belongs to, say <code class="reqn">i</code>),
<code>'.index'</code> (function argument such as time point <code class="reqn">t</code>), and
<code>'.value'</code> (observed function value <code class="reqn">Y_i(t)</code>).</p>
</li></ul>



<h3>Value</h3>

<p>An object of class <code>fpca</code> containing:
</p>
<table>
<tr><td><code>Yhat</code></td>
<td>
<p>FPC approximation (projection onto leading components)
of <code>Y.pred</code> if specified, or else of <code>Y</code>.</p>
</td></tr>
<tr><td><code>Y</code></td>
<td>
<p>the observed data</p>
</td></tr><tr><td><code>scores</code></td>
<td>
<p><code class="reqn">n
\times npc</code> matrix of estimated FPC scores.</p>
</td></tr> <tr><td><code>mu</code></td>
<td>
<p>estimated mean
function (or a vector of zeroes if <code>center==FALSE</code>).</p>
</td></tr> <tr><td><code>efunctions</code></td>
<td>
<p><code class="reqn">d \times npc</code> matrix of estimated eigenfunctions of the functional
covariance, i.e., the FPC basis functions.</p>
</td></tr> <tr><td><code>evalues</code></td>
<td>
<p>estimated
eigenvalues of the covariance operator, i.e., variances of FPC scores.</p>
</td></tr>
<tr><td><code>npc</code></td>
<td>
<p>number of FPCs: either the supplied <code>npc</code>, or the minimum
number of basis functions needed to explain proportion <code>pve</code> of the
variance in the observed curves.</p>
</td></tr> <tr><td><code>argvals</code></td>
<td>
<p>argument values of
eigenfunction evaluations</p>
</td></tr> <tr><td><code>pve</code></td>
<td>
<p>The percent variance explained by the returned number of PCs</p>
</td></tr><tr><td><code>sigma2</code></td>
<td>
<p>estimated measurement error
variance.</p>
</td></tr> <tr><td><code>diag.var</code></td>
<td>
<p>diagonal elements of the covariance matrices for
each estimated curve.</p>
</td></tr> <tr><td><code>VarMats</code></td>
<td>
<p>a list containing the estimated
covariance matrices for each curve in <code>Y</code>.</p>
</td></tr> <tr><td><code>crit.val</code></td>
<td>
<p>estimated
critical values for constructing simultaneous confidence intervals.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:jeff.goldsmith@columbia.edu">jeff.goldsmith@columbia.edu</a>, Sonja Greven
<a href="mailto:sonja.greven@stat.uni-muenchen.de">sonja.greven@stat.uni-muenchen.de</a>, Lan Huo
<a href="mailto:Lan.Huo@nyumc.org">Lan.Huo@nyumc.org</a>, Lei Huang <a href="mailto:huangracer@gmail.com">huangracer@gmail.com</a>, and
Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a>
</p>


<h3>References</h3>

<p>Di, C., Crainiceanu, C., Caffo, B., and Punjabi, N. (2009).
Multilevel functional principal component analysis. <em>Annals of Applied
Statistics</em>, 3, 458&ndash;488.
</p>
<p>Goldsmith, J., Greven, S., and Crainiceanu, C. (2013). Corrected confidence
bands for functional data using principal components. <em>Biometrics</em>,
69(1), 41&ndash;51.
</p>
<p>Staniswalis, J. G., and Lee, J. J. (1998). Nonparametric regression
analysis of longitudinal data. <em>Journal of the American Statistical
Association</em>, 93, 1403&ndash;1418.
</p>
<p>Yao, F., Mueller, H.-G., and Wang, J.-L. (2005). Functional data analysis
for sparse longitudinal data. <em>Journal of the American Statistical
Association</em>, 100, 577&ndash;590.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(ggplot2)
library(reshape2)
data(cd4)

Fit.MM = fpca.sc(cd4, var = TRUE, simul = TRUE)

Fit.mu = data.frame(mu = Fit.MM$mu,
                    d = as.numeric(colnames(cd4)))
Fit.basis = data.frame(phi = Fit.MM$efunctions,
                       d = as.numeric(colnames(cd4)))

## for one subject, examine curve estimate, pointwise and simultaneous itervals
EX = 1
EX.MM = data.frame(fitted = Fit.MM$Yhat[EX,],
           ptwise.UB = Fit.MM$Yhat[EX,] + 1.96 * sqrt(Fit.MM$diag.var[EX,]),
           ptwise.LB = Fit.MM$Yhat[EX,] - 1.96 * sqrt(Fit.MM$diag.var[EX,]),
           simul.UB = Fit.MM$Yhat[EX,] + Fit.MM$crit.val[EX] * sqrt(Fit.MM$diag.var[EX,]),
           simul.LB = Fit.MM$Yhat[EX,] - Fit.MM$crit.val[EX] * sqrt(Fit.MM$diag.var[EX,]),
           d = as.numeric(colnames(cd4)))

## plot data for one subject, with curve and interval estimates
EX.MM.m = melt(EX.MM, id = 'd')
ggplot(EX.MM.m, aes(x = d, y = value, group = variable, color = variable, linetype = variable)) +
  geom_path() +
  scale_linetype_manual(values = c(fitted = 1, ptwise.UB = 2,
                        ptwise.LB = 2, simul.UB = 3, simul.LB = 3)) +
  scale_color_manual(values = c(fitted = 1, ptwise.UB = 2,
                     ptwise.LB = 2, simul.UB = 3, simul.LB = 3)) +
  labs(x = 'Months since seroconversion', y = 'Total CD4 Cell Count')

## plot estimated mean function
ggplot(Fit.mu, aes(x = d, y = mu)) + geom_path() +
  labs(x = 'Months since seroconversion', y = 'Total CD4 Cell Count')

## plot the first two estimated basis functions
Fit.basis.m = melt(Fit.basis, id = 'd')
ggplot(subset(Fit.basis.m, variable %in% c('phi.1', 'phi.2')), aes(x = d,
y = value, group = variable, color = variable)) + geom_path()

## input a dataframe instead of a matrix
nid &lt;- 20
nobs &lt;- sample(10:20, nid, rep=TRUE)
ydata &lt;- data.frame(
    .id = rep(1:nid, nobs),
    .index = round(runif(sum(nobs), 0, 1), 3))
ydata$.value &lt;- unlist(tapply(ydata$.index,
                              ydata$.id,
                              function(x)
                                  runif(1, -.5, .5) +
                                  dbeta(x, runif(1, 6, 8), runif(1, 3, 5))
                              )
                       )

Fit.MM = fpca.sc(ydata=ydata, var = TRUE, simul = FALSE)


## End(Not run)
</code></pre>

<hr>
<h2 id='fpca.ssvd'>Smoothed FPCA via iterative penalized rank one SVDs.</h2><span id='topic+fpca.ssvd'></span>

<h3>Description</h3>

<p>Implements the algorithm of Huang, Shen, Buja (2008) for finding smooth right
singular vectors of a matrix <code>X</code> containing (contaminated) evaluations of
functional random variables on a regular, equidistant grid. If the number of
smooth SVs to extract is not specified, the function hazards a guess for the
appropriate number based on the asymptotically optimal truncation threshold
under the assumption of a low rank matrix contaminated with i.i.d. Gaussian
noise with unknown variance derived in Donoho, Gavish (2013). Please note that
Donoho, Gavish (2013) should be regarded as experimental for functional PCA,
and will typically not work well if you have more observations than grid
points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpca.ssvd(
  Y = NULL,
  ydata = NULL,
  argvals = NULL,
  npc = NA,
  center = TRUE,
  maxiter = 15,
  tol = 1e-04,
  diffpen = 3,
  gridsearch = TRUE,
  alphagrid = 1.5^(-20:40),
  lower.alpha = 1e-05,
  upper.alpha = 1e+07,
  verbose = FALSE,
  integration = "trapezoidal"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpca.ssvd_+3A_y">Y</code></td>
<td>
<p>data matrix (rows: observations; columns: grid of eval. points)</p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_ydata">ydata</code></td>
<td>
<p>a data frame <code>ydata</code> representing
irregularly observed functions. NOT IMPLEMENTED for this method.</p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_argvals">argvals</code></td>
<td>
<p>the argument values of the function evaluations in <code>Y</code>,
defaults to a equidistant grid from 0 to 1. See Details.</p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_npc">npc</code></td>
<td>
<p>how many smooth SVs to try to extract, if <code>NA</code> (the default)
the hard thresholding rule of Donoho, Gavish (2013) is used (see Details,
References).</p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_center">center</code></td>
<td>
<p>center <code>Y</code> so that its column-means are 0? Defaults to
<code>TRUE</code></p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_maxiter">maxiter</code></td>
<td>
<p>how many iterations of the power algorithm to perform at most
(defaults to 15)</p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_tol">tol</code></td>
<td>
<p>convergence tolerance for power algorithm (defaults to 1e-4)</p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_diffpen">diffpen</code></td>
<td>
<p>difference penalty order controlling the desired smoothness of
the right singular vectors, defaults to 3 (i.e., deviations from local
quadratic polynomials).</p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_gridsearch">gridsearch</code></td>
<td>
<p>use <code><a href="stats.html#topic+optimize">optimize</a></code> or a grid search to find
GCV-optimal smoothing parameters? defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_alphagrid">alphagrid</code></td>
<td>
<p>grid of smoothing parameter values for grid search</p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_lower.alpha">lower.alpha</code></td>
<td>
<p>lower limit for for smoothing parameter if
<code>!gridsearch</code></p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_upper.alpha">upper.alpha</code></td>
<td>
<p>upper limit for smoothing parameter if <code>!gridsearch</code></p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_verbose">verbose</code></td>
<td>
<p>generate graphical summary of progress and diagnostic messages?
defaults to <code>FALSE</code></p>
</td></tr>
<tr><td><code id="fpca.ssvd_+3A_integration">integration</code></td>
<td>
<p>ignored, see Details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>fpca.ssvd</code> computes smoothed orthonormal eigenvectors
of the supplied function evaluations (and associated scores), not (!)
evaluations of the smoothed orthonormal eigenfunctions. The smoothed
orthonormal eigenvectors are then rescaled by the length of the domain
defined by <code>argvals</code> to have a quadratic integral approximately equal
to one (instead of crossproduct equal to one), so they approximate the behavior
of smooth eigenfunctions. If <code>argvals</code> is not equidistant,
<code>fpca.ssvd</code> will simply return the smoothed eigenvectors without rescaling,
with a warning.
</p>


<h3>Value</h3>

<p>an <code>fpca</code> object like that returned from <code><a href="#topic+fpca.sc">fpca.sc</a></code>,
with entries <code>Yhat</code>, the smoothed trajectories, <code>Y</code>, the observed
data, <code>scores</code>, the estimated FPC loadings, <code>mu</code>, the column means
of <code>Y</code> (or a vector of zeroes if <code>!center</code>),  <code>efunctions</code>,
the estimated smooth FPCs (note that these are orthonormal vectors, not
evaluations of orthonormal functions if <code>argvals</code> is not equidistant),
<code>evalues</code>, their associated eigenvalues, and <code>npc</code>, the number of
smooth components that were extracted.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>


<h3>References</h3>

<p>Huang, J. Z., Shen, H., and Buja, A. (2008). Functional principal
components analysis via penalized rank one approximation. <em>Electronic
Journal of Statistics</em>, 2, 678-695
</p>
<p>Donoho, D.L., and Gavish, M. (2013). The Optimal Hard Threshold for Singular
Values is 4/sqrt(3). eprint arXiv:1305.5870. Available from
<a href="https://arxiv.org/abs/1305.5870">https://arxiv.org/abs/1305.5870</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fpca.sc">fpca.sc</a></code> and <code><a href="#topic+fpca.face">fpca.face</a></code> for FPCA based on
smoothing a covariance estimate; <code><a href="#topic+fpca2s">fpca2s</a></code> for a faster SVD-based
approach.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## as in Sec. 6.2 of Huang, Shen, Buja (2008):
 set.seed(2678695)
 n &lt;- 101
 m &lt;- 101
 s1 &lt;- 20
 s2 &lt;- 10
 s &lt;- 4
 t &lt;- seq(-1, 1, l=m)
 v1 &lt;- t + sin(pi*t)
 v2 &lt;- cos(3*pi*t)
 V &lt;- cbind(v1/sqrt(sum(v1^2)), v2/sqrt(sum(v2^2)))
 U &lt;- matrix(rnorm(n*2), n, 2)
 D &lt;- diag(c(s1^2, s2^2))
 eps &lt;- matrix(rnorm(m*n, sd=s), n, m)
 Y &lt;- U%*%D%*%t(V) + eps

smoothSV &lt;- fpca.ssvd(Y, verbose=TRUE)

 layout(t(matrix(1:4, nr=2)))
 clrs &lt;- sapply(rainbow(n), function(c)
           do.call(rgb, as.list(c(col2rgb(c)/255, .1))))
 matplot(V, type="l", lty=1, col=1:2, xlab="",
         main="FPCs: true", bty="n")
 matplot(smoothSV$efunctions, type="l", lty=1, col=1:5, xlab="",
         main="FPCs: estimate", bty="n")
 matplot(1:m, t(U%*%D%*%t(V)), type="l", lty=1, col=clrs, xlab="", ylab="",
         main="true smooth Y", bty="n")
 matplot(1:m, t(smoothSV$Yhat), xlab="", ylab="",
         type="l", lty=1,col=clrs, main="estimated smooth Y", bty="n")
</code></pre>

<hr>
<h2 id='fpca2s'>Functional principal component analysis by a two-stage method</h2><span id='topic+fpca2s'></span>

<h3>Description</h3>

<p>This function performs functional PCA by performing an ordinary singular
value decomposition on the functional data matrix, then smoothing the right
singular vectors by smoothing splines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpca2s(
  Y = NULL,
  ydata = NULL,
  argvals = NULL,
  npc = NA,
  center = TRUE,
  smooth = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpca2s_+3A_y">Y</code></td>
<td>
<p>data matrix (rows: observations; columns: grid of eval. points)</p>
</td></tr>
<tr><td><code id="fpca2s_+3A_ydata">ydata</code></td>
<td>
<p>a data frame <code>ydata</code> representing
irregularly observed functions. NOT IMPLEMENTED for this method.</p>
</td></tr>
<tr><td><code id="fpca2s_+3A_argvals">argvals</code></td>
<td>
<p>the argument values of the function evaluations in <code>Y</code>,
defaults to a equidistant grid from 0 to 1. See Details.</p>
</td></tr>
<tr><td><code id="fpca2s_+3A_npc">npc</code></td>
<td>
<p>how many smooth SVs to try to extract, if <code>NA</code> (the default)
the hard thresholding rule of Donoho, Gavish (2013) is used (see Details,
References).</p>
</td></tr>
<tr><td><code id="fpca2s_+3A_center">center</code></td>
<td>
<p>center <code>Y</code> so that its column-means are 0? Defaults to
<code>TRUE</code></p>
</td></tr>
<tr><td><code id="fpca2s_+3A_smooth">smooth</code></td>
<td>
<p>logical; defaults to TRUE, if NULL, no smoothing of
eigenvectors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that <code>fpca2s</code> computes smoothed orthonormal eigenvectors
of the supplied function evaluations (and associated scores), not (!)
evaluations of the smoothed orthonormal eigenfunctions. The smoothed
orthonormal eigenvectors are then rescaled by the length of the domain
defined by <code>argvals</code> to have a quadratic integral approximately equal
to one (instead of crossproduct equal to one), so they approximate the behavior
of smooth eigenfunctions. If <code>argvals</code> is not equidistant,
<code>fpca2s</code> will simply return the smoothed eigenvectors without rescaling,
with a warning.
</p>


<h3>Value</h3>

<p>an <code>fpca</code> object like that returned from <code><a href="#topic+fpca.sc">fpca.sc</a></code>,
with entries <code>Yhat</code>, the smoothed trajectories, <code>Y</code>, the observed
data, <code>scores</code>, the estimated FPC loadings, <code>mu</code>, the column means
of <code>Y</code> (or a vector of zeroes if <code>!center</code>),  <code>efunctions</code>,
the estimated smooth FPCs (note that these are orthonormal vectors, not
evaluations of orthonormal functions if <code>argvals</code> is not equidistant),
<code>evalues</code>, their associated eigenvalues, and <code>npc</code>, the number of
smooth components that were extracted.
</p>


<h3>Author(s)</h3>

<p>Luo Xiao <a href="mailto:lxiao@jhsph.edu">lxiao@jhsph.edu</a>, Fabian Scheipl
</p>


<h3>References</h3>

<p>Xiao, L., Ruppert, D., Zipunnikov, V., and Crainiceanu, C., (2013), Fast
covariance estimation for high-dimensional functional data. (submitted)
<a href="https://arxiv.org/abs/1306.5718">https://arxiv.org/abs/1306.5718</a>.
</p>
<p>Gavish, M., and Donoho, D. L.  (2014). The optimal hard threshold for
singular values is 4/sqrt(3).  <em>IEEE Transactions on Information Theory</em>, 60(8), 5040&ndash;5053.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fpca.sc">fpca.sc</a></code> and <code><a href="#topic+fpca.face">fpca.face</a></code> for FPCA based
on smoothing a covariance estimate; <code><a href="#topic+fpca.ssvd">fpca.ssvd</a></code> for another
SVD-based approach.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  #### settings
  I &lt;- 50 # number of subjects
  J &lt;- 3000 # dimension of the data
  t &lt;- (1:J)/J # a regular grid on [0,1]
  N &lt;- 4 #number of eigenfunctions
  sigma &lt;- 2 ##standard deviation of random noises
  lambdaTrue &lt;- c(1,0.5,0.5^2,0.5^3) # True eigenvalues

  case = 1
  ### True Eigenfunctions

  if(case==1) phi &lt;- sqrt(2)*cbind(sin(2*pi*t),cos(2*pi*t),
                                   sin(4*pi*t),cos(4*pi*t))
  if(case==2) phi &lt;- cbind(rep(1,J),sqrt(3)*(2*t-1),
                           sqrt(5)*(6*t^2-6*t+1),
                           sqrt(7)*(20*t^3-30*t^2+12*t-1))

  ###################################################
  ########     Generate Data            #############
  ###################################################
  xi &lt;- matrix(rnorm(I*N),I,N);
  xi &lt;- xi%*%diag(sqrt(lambdaTrue))
  X &lt;- xi%*%t(phi); # of size I by J
  Y &lt;- X + sigma*matrix(rnorm(I*J),I,J)

  results &lt;- fpca2s(Y,npc=4,argvals=t)
  ###################################################
  ####               SVDS               ########
  ###################################################
  Phi &lt;- results$efunctions
  eigenvalues &lt;- results$evalues

  for(k in 1:N){
    if(Phi[,k]%*%phi[,k]&lt; 0)
      Phi[,k] &lt;- - Phi[,k]
  }

 ### plot eigenfunctions
 par(mfrow=c(N/2,2))
 seq &lt;- (1:(J/10))*10
 for(k in 1:N){
      plot(t[seq],Phi[seq,k]*sqrt(J),type='l',lwd = 3,
           ylim = c(-2,2),col = 'red',
           ylab = paste('Eigenfunction ',k,sep=''),
           xlab='t',main='SVDS')

      lines(t[seq],phi[seq,k],lwd = 2, col = 'black')
      }
</code></pre>

<hr>
<h2 id='fpcr'>Functional principal component regression</h2><span id='topic+fpcr'></span>

<h3>Description</h3>

<p>Implements functional principal component regression (Reiss and Ogden,
2007, 2010) for generalized linear models with scalar responses and
functional predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fpcr(
  y,
  xfuncs = NULL,
  fdobj = NULL,
  ncomp = NULL,
  pve = 0.99,
  nbasis = NULL,
  basismat = NULL,
  penmat = NULL,
  argvals = NULL,
  covt = NULL,
  mean.signal.term = FALSE,
  spline.order = NULL,
  family = "gaussian",
  method = "REML",
  sp = NULL,
  pen.order = 2,
  cv1 = FALSE,
  nfold = 5,
  store.cv = FALSE,
  store.gam = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fpcr_+3A_y">y</code></td>
<td>
<p>scalar outcome vector.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_xfuncs">xfuncs</code></td>
<td>
<p>for 1D predictors, an <code class="reqn">n \times d</code> matrix of
signals/functional predictors, where <code class="reqn">n</code> is the length of <code>y</code> and
<code class="reqn">d</code> is the number of sites at which each signal is defined.  For 2D
predictors, an <code class="reqn">n \times d1 \times d2</code> array representing <code class="reqn">n</code>
images of dimension <code class="reqn">d1 \times d2</code>.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_fdobj">fdobj</code></td>
<td>
<p>functional data object (class &quot;<code><a href="fda.html#topic+fd">fd</a></code>&quot;) giving
the functional predictors. Allowed only for 1D functional predictors.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_ncomp">ncomp</code></td>
<td>
<p>number of principal components. If <code>NULL</code>, this is chosen
by <code>pve</code>.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_pve">pve</code></td>
<td>
<p>proportion of variance explained: used to choose the number of
principal components.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_nbasis">nbasis</code></td>
<td>
<p>number(s) of B-spline basis functions: either a scalar, or a
vector of values to be compared.  For 2D predictors, tensor product
B-splines are used, with the given basis dimension(s) in each direction;
alternatively, <code>nbasis</code> can be given in the form <code>list(v1,v2)</code>,
in which case cross-validation will be performed for each combination of
the first-dimension basis sizes in <code>v1</code> and the second-dimension basis
sizes in <code>v2</code>. Ignored if <code>fdobj</code> is supplied. If <code>fdobj</code> is
<em>not</em> supplied, this defaults to 40 (i.e., 40 B-spline basis
functions) for 1D predictors, and 15 (i.e., tensor product B-splines with
15 functions per dimension) for 2D predictors.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_basismat">basismat</code></td>
<td>
<p>a <code class="reqn">d \times K</code> matrix of values of <code class="reqn">K</code> basis
functions at the <code class="reqn">d</code> sites.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_penmat">penmat</code></td>
<td>
<p>a <code class="reqn">K \times K</code> matrix defining a penalty on the basis
coefficients.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_argvals">argvals</code></td>
<td>
<p>points at which the functional predictors and the
coefficient function are evaluated.  By default, if 1D functional
predictors are given by the <code class="reqn">n \times d</code> matrix <code>xfuncs</code>,
<code>argvals</code> is set to <code class="reqn">d</code> equally spaced points from 0 to 1; if they
are given by <code>fdobj</code>, <code>argvals</code> is set to 401 equally spaced
points spanning the domain of the given functions. For 2D (image)
predictors supplied as an <code class="reqn">n \times d1 \times d2</code> array, <code>argvals</code>
defaults to a list of (1) <code class="reqn">d1</code> equally spaced points from 0 to 1; (2)
<code class="reqn">d2</code> equally spaced points from 0 to 1.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_covt">covt</code></td>
<td>
<p>covariates: an <code class="reqn">n</code>-row matrix, or a vector of length
<code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_mean.signal.term">mean.signal.term</code></td>
<td>
<p>logical: should the mean of each subject's signal
be included as a covariate?</p>
</td></tr>
<tr><td><code id="fpcr_+3A_spline.order">spline.order</code></td>
<td>
<p>order of B-splines used, if <code>fdobj</code> is not
supplied; defaults to <code>4</code>, i.e., cubic B-splines.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_family">family</code></td>
<td>
<p>generalized linear model family. Current version supports
<code>"gaussian"</code> (the default) and <code>"binomial"</code>.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_method">method</code></td>
<td>
<p>smoothing parameter selection method, passed to function
<code><a href="mgcv.html#topic+gam">gam</a></code>; see the <code><a href="mgcv.html#topic+gam">gam</a></code> documentation for
details.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_sp">sp</code></td>
<td>
<p>a fixed smoothing parameter; if <code>NULL</code>, an optimal value is
chosen (see <code>method</code>).</p>
</td></tr>
<tr><td><code id="fpcr_+3A_pen.order">pen.order</code></td>
<td>
<p>order of derivative penalty applied when estimating the
coefficient function; defaults to <code>2</code>.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_cv1">cv1</code></td>
<td>
<p>logical: should cross-validation be performed to select the best
model if only one set of tuning parameters provided? By default,
<code>FALSE</code>. Note that, if there are multiple sets of tuning parameters
provided, cv is always performed.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_nfold">nfold</code></td>
<td>
<p>the number of validation sets (&quot;folds&quot;) into which the data
are divided; by default, 5.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_store.cv">store.cv</code></td>
<td>
<p>logical: should a CV result table be in the output? By
default, <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_store.gam">store.gam</code></td>
<td>
<p>logical: should the <code><a href="mgcv.html#topic+gam">gam</a></code> object be
included in the output? Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="fpcr_+3A_...">...</code></td>
<td>
<p>other arguments passed to function <code><a href="mgcv.html#topic+gam">gam</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>One-dimensional functional predictors can be given either in functional
data object form, using argument <code>fdobj</code> (see the <span class="pkg">fda</span> package of
Ramsay, Hooker and Graves, 2009, and Method 1 in the example below), or
explicitly, using <code>xfuncs</code> (see Method 2 in the example).  In the
latter case, arguments <code>basismat</code> and <code>penmat</code> can also be used
to specify the basis and/or penalty matrices (see Method 3).
</p>
<p>For two-dimensional predictors, functional data object form is not
supported.  Instead of radial B-splines as in Reiss and Ogden (2010), this
implementation employs tensor product cubic B-splines, sometimes known as
bivariate O-splines (Ormerod, 2008).
</p>
<p>For purposes of interpreting the fitted coefficients, please note that the
functional predictors are decorrelated from the scalar predictors before
fitting the model (when there are no scalar predictors other than the
intercept, this just means the columns of the functional predictor matrix
are de-meaned); see section 3.2 of Reiss (2006) for details.
</p>


<h3>Value</h3>

<p>A list with components </p>
<table>
<tr><td><code>gamObject</code></td>
<td>
<p>if <code>store.gam = TRUE</code>,
an object of class <code>gam</code> (see <code><a href="mgcv.html#topic+gamObject">gamObject</a></code> in the
<span class="pkg">mgcv</span> package documentation).</p>
</td></tr> <tr><td><code>fhat</code></td>
<td>
<p>coefficient function
estimate.</p>
</td></tr> <tr><td><code>se</code></td>
<td>
<p>pointwise Bayesian standard error.</p>
</td></tr>
<tr><td><code>undecor.coef</code></td>
<td>
<p>undecorrelated coefficient for covariates.</p>
</td></tr>
<tr><td><code>argvals</code></td>
<td>
<p>the supplied value of <code>argvals</code>.</p>
</td></tr> <tr><td><code>cv.table</code></td>
<td>
<p>a
table giving the CV criterion for each combination of <code>nbasis</code> and
<code>ncomp</code>, if <code>store.cv = TRUE</code>; otherwise, the CV criterion only
for the optimized combination of these parameters.  Set to <code>NULL</code> if
CV is not performed.</p>
</td></tr> <tr><td><code>nbasis</code>, <code>ncomp</code></td>
<td>
<p>when CV is performed, the values
of <code>nbasis</code> and <code>comp</code> that minimize the CV criterion.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a>, Lan Huo
<a href="mailto:lan.huo@nyumc.org">lan.huo@nyumc.org</a>, and Lei Huang <a href="mailto:huangracer@gmail.com">huangracer@gmail.com</a>
</p>


<h3>References</h3>

<p>Ormerod, J. T. (2008).  On semiparametric regression and data
mining.  Ph.D. dissertation, School of Mathematics and Statistics,
University of New South Wales.
</p>
<p>Ramsay, J. O., Hooker, G., and Graves, S. (2009). <em>Functional Data
Analysis with R and MATLAB</em>. New York: Springer.
</p>
<p>Reiss, P. T. (2006).  Regression with signals and images as predictors.
Ph.D. dissertation, Department of Biostatistics, Columbia University.
</p>
<p>Reiss, P. T., and Ogden, R. T. (2007).  Functional principal component
regression and functional partial least squares.  <em>Journal of the
American Statistical Association</em>, 102, 984&ndash;996.
</p>
<p>Reiss, P. T., and Ogden, R. T. (2010).  Functional generalized linear
models with images as predictors.  <em>Biometrics</em>, 66, 61&ndash;69.
</p>
<p>Wood, S. N. (2006). <em>Generalized Additive Models: An Introduction with
R</em>. Boca Raton, FL: Chapman &amp; Hall.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
require(fda)
### 1D functional predictor example ###

######### Octane data example #########
data(gasoline)

# Create the requisite functional data objects
bbasis = create.bspline.basis(c(900, 1700), 40)
wavelengths = 2*450:850
nir &lt;- t(gasoline$NIR)
gas.fd = smooth.basisPar(wavelengths, nir, bbasis)$fd

# Method 1: Call fpcr with fdobj argument
gasmod1 = fpcr(gasoline$octane, fdobj = gas.fd, ncomp = 30)
plot(gasmod1, xlab="Wavelength")
## Not run: 
# Method 2: Call fpcr with explicit signal matrix
gasmod2 = fpcr(gasoline$octane, xfuncs = gasoline$NIR, ncomp = 30)
# Method 3: Call fpcr with explicit signal, basis, and penalty matrices
gasmod3 = fpcr(gasoline$octane, xfuncs = gasoline$NIR,
               basismat = eval.basis(wavelengths, bbasis),
               penmat = getbasispenalty(bbasis), ncomp = 30)

# Check that all 3 calls yield essentially identical estimates
all.equal(gasmod1$fhat, gasmod2$fhat, gasmod3$fhat)
# But note that, in general, you'd have to specify argvals in Method 1
# to get the same coefficient function values as with Methods 2 &amp; 3.

## End(Not run)

### 2D functional predictor example ###

n = 200; d = 70

# Create true coefficient function
ftrue = matrix(0,d,d)
ftrue[40:46,34:38] = 1

# Generate random functional predictors, and scalar responses
ii = array(rnorm(n*d^2), dim=c(n,d,d))
iimat = ii; dim(iimat) = c(n,d^2)
yy = iimat %*% as.vector(ftrue) + rnorm(n, sd=.3)

mm = fpcr(yy, ii, ncomp=40)

image(ftrue)
contour(mm$fhat, add=TRUE)

## Not run: 
### Cross-validation ###
cv.gas = fpcr(gasoline$octane, xfuncs = gasoline$NIR,
                 nbasis=seq(20,40,5), ncomp = seq(10,20,5), store.cv = TRUE)
image(seq(20,40,5), seq(10,20,5), cv.gas$cv.table, xlab="Basis size",
      ylab="Number of PCs", xaxp=c(20,40,4), yaxp=c(10,20,2))


## End(Not run)
</code></pre>

<hr>
<h2 id='gasoline'>Octane numbers and NIR spectra of gasoline</h2><span id='topic+gasoline'></span>

<h3>Description</h3>

<p>Near-infrared reflectance spectra and octane numbers of 60 gasoline
samples.  Each NIR spectrum consists of log(1/reflectance) measurements at
401 wavelengths, in 2-nm intervals from 900 nm to 1700 nm.  We thank Prof.
John Kalivas for making this data set available.
</p>


<h3>Format</h3>

<p>A data frame comprising </p>

<dl>
<dt>octane</dt><dd><p>a numeric
vector of octane numbers for the 60 samples.</p>
</dd>
<dt>NIR</dt><dd><p>a 60 x 401
matrix of NIR spectra.</p>
</dd>
</dl>



<h3>Source</h3>

<p>Kalivas, John H. (1997).  Two data sets of near infrared spectra.
<em>Chemometrics and Intelligent Laboratory Systems</em>, 37, 255&ndash;259.
</p>


<h3>References</h3>

<p>For applications of functional principal component regression
to this data set:
</p>
<p>Reiss, P. T., and Ogden, R. T. (2007).  Functional principal component
regression and functional partial least squares.  <em>Journal of the
American Statistical Association</em>, 102, 984&ndash;996.
</p>
<p>Reiss, P. T., and Ogden, R. T. (2009).  Smoothing parameter selection for a
class of semiparametric linear models.  <em>Journal of the Royal
Statistical Society, Series B</em>, 71(2), 505&ndash;523.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fpcr">fpcr</a></code>
</p>

<hr>
<h2 id='getTF'>Get recognized transformation function</h2><span id='topic+getTF'></span>

<h3>Description</h3>

<p>Get recognized transformation function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>getTF(fname, nterm)
</code></pre>

<hr>
<h2 id='gibbs_cs_fpca'>Cross-sectional FoSR using a Gibbs sampler and FPCA</h2><span id='topic+gibbs_cs_fpca'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for cross-sectional data.
This function estimates model parameters using a Gibbs sampler and estimates
the residual covariance surface using FPCA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_cs_fpca(
  formula,
  Kt = 5,
  Kp = 2,
  data = NULL,
  verbose = TRUE,
  N.iter = 5000,
  N.burn = 1000,
  SEED = NULL,
  sig2.me = 0.01,
  alpha = 0.1,
  Aw = NULL,
  Bw = NULL,
  Apsi = NULL,
  Bpsi = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_cs_fpca_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_kp">Kp</code></td>
<td>
<p>number of FPCA basis functions to be estimated</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the 
variables in the model. If not found in data, the variables are taken from 
environment(formula), typically the environment from which the function is 
called.</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_n.iter">N.iter</code></td>
<td>
<p>number of iterations used in the Gibbs sampler</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_n.burn">N.burn</code></td>
<td>
<p>number of iterations discarded as burn-in</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_seed">SEED</code></td>
<td>
<p>seed value to start the sampler; ensures reproducibility</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_sig2.me">sig2.me</code></td>
<td>
<p>starting value for measurement error variance</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter balancing second-derivative penalty and
zeroth-derivative penalty (alpha = 0 is all second-derivative penalty)</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_aw">Aw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_bw">Bw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_apsi">Apsi</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for FPC effects</p>
</td></tr>
<tr><td><code id="gibbs_cs_fpca_+3A_bpsi">Bpsi</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for FPC effects</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='gibbs_cs_wish'>Cross-sectional FoSR using a Gibbs sampler and Wishart prior</h2><span id='topic+gibbs_cs_wish'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for cross-sectional data.
This function estimates model parameters using a Gibbs sampler and estimates
the residual covariance surface using a Wishart prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_cs_wish(
  formula,
  Kt = 5,
  data = NULL,
  verbose = TRUE,
  N.iter = 5000,
  N.burn = 1000,
  alpha = 0.1,
  min.iter = 10,
  max.iter = 50,
  Aw = NULL,
  Bw = NULL,
  v = NULL,
  SEED = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_cs_wish_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the
variables in the model. If not found in data, the variables are taken from
environment(formula), typically the environment from which the function is
called.</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_n.iter">N.iter</code></td>
<td>
<p>number of iterations used in the Gibbs sampler</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_n.burn">N.burn</code></td>
<td>
<p>number of iterations discarded as burn-in</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter balancing second-derivative penalty and
zeroth-derivative penalty (alpha = 0 is all second-derivative penalty)</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_min.iter">min.iter</code></td>
<td>
<p>minimum number of iterations</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_aw">Aw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_bw">Bw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_v">v</code></td>
<td>
<p>hyperparameter for inverse Wishart prior on residual covariance</p>
</td></tr>
<tr><td><code id="gibbs_cs_wish_+3A_seed">SEED</code></td>
<td>
<p>seed value to start the sampler; ensures reproducibility</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='gibbs_mult_fpca'>Multilevel FoSR using a Gibbs sampler and FPCA</h2><span id='topic+gibbs_mult_fpca'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for longitudinal data.
This function estimates model parameters using a Gibbs sampler and estimates
the residual covariance surface using FPCA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_mult_fpca(
  formula,
  Kt = 5,
  Kp = 2,
  data = NULL,
  verbose = TRUE,
  N.iter = 5000,
  N.burn = 1000,
  sig2.me = 0.01,
  alpha = 0.1,
  SEED = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_mult_fpca_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="gibbs_mult_fpca_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="gibbs_mult_fpca_+3A_kp">Kp</code></td>
<td>
<p>number of FPCA basis functions to be estimated</p>
</td></tr>
<tr><td><code id="gibbs_mult_fpca_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the 
variables in the model. If not found in data, the variables are taken from 
environment(formula), typically the environment from which the function is 
called.</p>
</td></tr>
<tr><td><code id="gibbs_mult_fpca_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
<tr><td><code id="gibbs_mult_fpca_+3A_n.iter">N.iter</code></td>
<td>
<p>number of iterations used in the Gibbs sampler</p>
</td></tr>
<tr><td><code id="gibbs_mult_fpca_+3A_n.burn">N.burn</code></td>
<td>
<p>number of iterations discarded as burn-in</p>
</td></tr>
<tr><td><code id="gibbs_mult_fpca_+3A_sig2.me">sig2.me</code></td>
<td>
<p>starting value for measurement error variance</p>
</td></tr>
<tr><td><code id="gibbs_mult_fpca_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter balancing second-derivative penalty and
zeroth-derivative penalty (alpha = 0 is all second-derivative penalty)</p>
</td></tr>
<tr><td><code id="gibbs_mult_fpca_+3A_seed">SEED</code></td>
<td>
<p>seed value to start the sampler; ensures reproducibility</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='gibbs_mult_wish'>Multilevel FoSR using a Gibbs sampler and Wishart prior</h2><span id='topic+gibbs_mult_wish'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for multilevel data.
This function estimates model parameters using a Gibbs sampler and estimates
the residual covariance surface using a Wishart prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gibbs_mult_wish(
  formula,
  Kt = 5,
  data = NULL,
  verbose = TRUE,
  N.iter = 5000,
  N.burn = 1000,
  alpha = 0.1,
  Az = NULL,
  Bz = NULL,
  Aw = NULL,
  Bw = NULL,
  v = NULL,
  SEED = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gibbs_mult_wish_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the
variables in the model. If not found in data, the variables are taken from
environment(formula), typically the environment from which the function is
called.</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_n.iter">N.iter</code></td>
<td>
<p>number of iterations used in the Gibbs sampler</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_n.burn">N.burn</code></td>
<td>
<p>number of iterations discarded as burn-in</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter balancing second-derivative penalty and
zeroth-derivative penalty (alpha = 0 is all second-derivative penalty)</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_az">Az</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for subject-level effects</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_bz">Bz</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for subject-level effects</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_aw">Aw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_bw">Bw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_v">v</code></td>
<td>
<p>hyperparameter for inverse Wishart prior on residual covariance</p>
</td></tr>
<tr><td><code id="gibbs_mult_wish_+3A_seed">SEED</code></td>
<td>
<p>seed value to start the sampler; ensures reproducibility</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='gls_cs'>Cross-sectional FoSR using GLS</h2><span id='topic+gls_cs'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for cross-sectional data.
This function estimates model parameters using GLS: first, an OLS estimate of 
spline coefficients is estimated; second, the residual covariance is estimated
using an FPC decomposition of the OLS residual curves; finally, a GLS estimate
of spline coefficients is estimated. Although this is in the 'BayesFoSR' package,
there is nothing Bayesian about this FoSR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gls_cs(
  formula,
  data = NULL,
  Kt = 5,
  basis = "bs",
  sigma = NULL,
  verbose = TRUE,
  CI.type = "pointwise"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gls_cs_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="gls_cs_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the 
variables in the model. If not found in data, the variables are taken from 
environment(formula), typically the environment from which the function is 
called.</p>
</td></tr>
<tr><td><code id="gls_cs_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="gls_cs_+3A_basis">basis</code></td>
<td>
<p>basis type; options are &quot;bs&quot; for b-splines and &quot;pbs&quot; for periodic
b-splines</p>
</td></tr>
<tr><td><code id="gls_cs_+3A_sigma">sigma</code></td>
<td>
<p>optional covariance matrix used in GLS; if <code>NULL</code>, OLS will be
used to estimated fixed effects, and the covariance matrix will be estimated from
the residuals.</p>
</td></tr>
<tr><td><code id="gls_cs_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
<tr><td><code id="gls_cs_+3A_ci.type">CI.type</code></td>
<td>
<p>Indicates CI type for coefficient functions; options are &quot;pointwise&quot; and
&quot;simultaneous&quot;</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='lf'>Construct an FLM regression term</h2><span id='topic+lf'></span>

<h3>Description</h3>

<p>Defines a term <code class="reqn">\int_{T}\beta(t)X_i(t)dt</code> for inclusion in an <code>mgcv::gam</code>-formula (or
<code><a href="mgcv.html#topic+bam">bam</a></code> or <code><a href="mgcv.html#topic+gamm">gamm</a></code> or <code>gamm4:::gamm</code>) as constructed by
<code><a href="#topic+pfr">pfr</a></code>, where <code class="reqn">\beta(t)</code> is an unknown coefficient
function and <code class="reqn">X_i(t)</code> is a functional predictor on the closed interval
<code class="reqn">T</code>. See
<code><a href="mgcv.html#topic+smooth.terms">smooth.terms</a></code> for a list of basis and penalty options; the
default is thin-plate regression splines, as this is the default option
for <code><a href="mgcv.html#topic+s">s</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lf(
  X,
  argvals = NULL,
  xind = NULL,
  integration = c("simpson", "trapezoidal", "riemann"),
  L = NULL,
  presmooth = NULL,
  presmooth.opts = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lf_+3A_x">X</code></td>
<td>
<p>functional predictors, typically expressed as an <code>N</code> by <code>J</code> matrix,
where <code>N</code> is the number of columns and <code>J</code> is the number of
evaluation points. May include missing/sparse functions, which are
indicated by <code>NA</code> values. Alternatively, can be an object of class
<code>"fd"</code>; see <code><a href="fda.html#topic+fd">fd</a></code>.</p>
</td></tr>
<tr><td><code id="lf_+3A_argvals">argvals</code></td>
<td>
<p>indices of evaluation of <code>X</code>, i.e. <code class="reqn">(t_{i1},.,t_{iJ})</code> for
subject <code class="reqn">i</code>. May be entered as either a length-<code>J</code> vector, or as
an <code>N</code> by <code>J</code> matrix. Indices may be unequally spaced. Entering
as a matrix allows for different observations times for each subject. If
<code>NULL</code>, defaults to an equally-spaced grid between 0 or 1 (or within
<code>X$basis$rangeval</code> if <code>X</code> is a <code>fd</code> object.)</p>
</td></tr>
<tr><td><code id="lf_+3A_xind">xind</code></td>
<td>
<p>same as argvals. It will not be supported in the next version of refund.</p>
</td></tr>
<tr><td><code id="lf_+3A_integration">integration</code></td>
<td>
<p>method used for numerical integration. Defaults to <code>"simpson"</code>'s rule
for calculating entries in <code>L</code>. Alternatively and for non-equidistant grids,
<code>"trapezoidal"</code> or <code>"riemann"</code>.</p>
</td></tr>
<tr><td><code id="lf_+3A_l">L</code></td>
<td>
<p>an optional <code>N</code> by <code>ncol(argvals)</code> matrix giving the weights for the numerical
integration over <code>t</code>. If present, overrides <code>integration</code>.</p>
</td></tr>
<tr><td><code id="lf_+3A_presmooth">presmooth</code></td>
<td>
<p>string indicating the method to be used for preprocessing functional predictor prior 
to fitting. Options are <code>fpca.sc</code>, <code>fpca.face</code>, <code>fpca.ssvd</code>, <code>fpca.bspline</code>, and 
<code>fpca.interpolate</code>. Defaults to <code>NULL</code> indicating no preprocessing. See
<code><a href="#topic+create.prep.func">create.prep.func</a></code>.</p>
</td></tr>
<tr><td><code id="lf_+3A_presmooth.opts">presmooth.opts</code></td>
<td>
<p>list including options passed to preprocessing method
<code><a href="#topic+create.prep.func">create.prep.func</a></code>.</p>
</td></tr>
<tr><td><code id="lf_+3A_...">...</code></td>
<td>
<p>optional arguments for basis and penalization to be passed to
<code>mgcv::s</code>. These could include, for example,
<code>"bs"</code>, <code>"k"</code>, <code>"m"</code>, etc. See <code><a href="mgcv.html#topic+s">s</a></code> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following entries
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>a <code>call</code> to <code>te</code> (or <code>s</code>, <code>t2</code>) using the appropriately
constructed covariate and weight matrices</p>
</td></tr>
<tr><td><code>argvals</code></td>
<td>
<p>the <code>argvals</code> argument supplied to <code>lf</code></p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>the  matrix of weights used for the integration</p>
</td></tr>
<tr><td><code>xindname</code></td>
<td>
<p>the name used for the functional predictor variable in the <code>formula</code>
used by <code>mgcv</code></p>
</td></tr>
<tr><td><code>tindname</code></td>
<td>
<p>the name used for <code>argvals</code> variable in the <code>formula</code> used by <code>mgcv</code></p>
</td></tr>
<tr><td><code>LXname</code></td>
<td>
<p>the name used for the <code>L</code> variable in the <code>formula</code> used by <code>mgcv</code></p>
</td></tr>
<tr><td><code>presmooth</code></td>
<td>
<p>the <code>presmooth</code> argument supplied to <code>lf</code></p>
</td></tr>
<tr><td><code>prep.func</code></td>
<td>
<p>a function that preprocesses data based on the preprocessing method specified in <code>presmooth</code>. See
<code><a href="#topic+create.prep.func">create.prep.func</a></code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Mathew W. McLean <a href="mailto:mathew.w.mclean@gmail.com">mathew.w.mclean@gmail.com</a>, Fabian Scheipl,
and Jonathan Gellar
</p>


<h3>References</h3>

<p>Goldsmith, J., Bobb, J., Crainiceanu, C., Caffo, B., and Reich, D. (2011).
Penalized functional regression. <em>Journal of Computational and Graphical
Statistics</em>, 20(4), 830-851.
</p>
<p>Goldsmith, J., Crainiceanu, C., Caffo, B., and Reich, D. (2012). Longitudinal
penalized functional regression for cognitive outcomes on neuronal tract
measurements. <em>Journal of the Royal Statistical Society: Series C</em>,
61(3), 453-469.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pfr">pfr</a></code>, <code><a href="#topic+af">af</a></code>, mgcv's <code><a href="mgcv.html#topic+smooth.terms">smooth.terms</a></code>
and <code><a href="mgcv.html#topic+linear.functional.terms">linear.functional.terms</a></code>; <code><a href="#topic+pfr">pfr</a></code> for additional examples
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DTI)
DTI1 &lt;- DTI[DTI$visit==1 &amp; complete.cases(DTI),]

# We can apply various preprocessing options to the DTI data
fit1 &lt;- pfr(pasat ~ lf(cca, k=30), data=DTI1)
fit2 &lt;- pfr(pasat ~ lf(cca, k=30, presmooth="fpca.sc",
                       presmooth.opts=list(nbasis=8, pve=.975)), data=DTI1)
fit3 &lt;- pfr(pasat ~ lf(cca, k=30, presmooth="fpca.face",
                       presmooth.opts=list(m=3, npc=9)), data=DTI1)
fit4 &lt;- pfr(pasat ~ lf(cca, k=30, presmooth="fpca.ssvd"), data=DTI1)
fit5 &lt;- pfr(pasat ~ lf(cca, k=30, presmooth="bspline",
                       presmooth.opts=list(nbasis=8)), data=DTI1)
fit6 &lt;- pfr(pasat ~ lf(cca, k=30, presmooth="interpolate"), data=DTI1)

# All models should result in similar fits
fits &lt;- as.data.frame(lapply(1:6, function(i)
  get(paste0("fit",i))$fitted.values))
names(fits) &lt;- c("none", "fpca.sc", "fpca.face", "fpca.ssvd", "bspline", "interpolate")
pairs(fits)

</code></pre>

<hr>
<h2 id='lf_old'>Construct an FLM regression term</h2><span id='topic+lf_old'></span>

<h3>Description</h3>

<p>Defines a term <code class="reqn">\int_{T}\beta(t)X_i(t)dt</code> for inclusion in an <code><a href="mgcv.html#topic+gam">gam</a></code>-formula
(or <code><a href="mgcv.html#topic+bam">bam</a></code> or <code><a href="mgcv.html#topic+gamm">gamm</a></code> or <code><a href="gamm4.html#topic+gamm4">gamm4</a></code>) as constructed by
<code><a href="#topic+fgam">fgam</a></code>, where <code class="reqn">\beta(t)</code> is an unknown coefficient function and <code class="reqn">X_i(t)</code>
is a functional predictor on the closed interval <code class="reqn">T</code>. Defaults to a cubic B-spline with
second-order difference penalties for estimating <code class="reqn">\beta(t)</code>.  The functional predictor must
be fully observed on a regular grid.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lf_old(
  X,
  argvals = seq(0, 1, l = ncol(X)),
  xind = NULL,
  integration = c("simpson", "trapezoidal", "riemann"),
  L = NULL,
  splinepars = list(bs = "ps", k = min(ceiling(n/4), 40), m = c(2, 2)),
  presmooth = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lf_old_+3A_x">X</code></td>
<td>
<p>an <code>N</code> by <code>J=ncol(argvals)</code> matrix of function evaluations
<code class="reqn">X_i(t_{i1}),., X_i(t_{iJ}); i=1,.,N.</code></p>
</td></tr>
<tr><td><code id="lf_old_+3A_argvals">argvals</code></td>
<td>
<p>matrix (or vector) of indices of evaluations of <code class="reqn">X_i(t)</code>; i.e. a matrix with
<em>i</em>th row <code class="reqn">(t_{i1},.,t_{iJ})</code></p>
</td></tr>
<tr><td><code id="lf_old_+3A_xind">xind</code></td>
<td>
<p>same as argvals. It will not be supported in the next version of refund.</p>
</td></tr>
<tr><td><code id="lf_old_+3A_integration">integration</code></td>
<td>
<p>method used for numerical integration. Defaults to <code>"simpson"</code>'s rule
for calculating entries in <code>L</code>. Alternatively and for non-equidistant grids,
&ldquo;<code>trapezoidal</code>&rdquo; or <code>"riemann"</code>. <code>"riemann"</code> integration is always used if
<code>L</code> is specified</p>
</td></tr>
<tr><td><code id="lf_old_+3A_l">L</code></td>
<td>
<p>an optional <code>N</code> by <code>ncol(argvals)</code> matrix giving the weights for the numerical
integration over <code>t</code></p>
</td></tr>
<tr><td><code id="lf_old_+3A_splinepars">splinepars</code></td>
<td>
<p>optional arguments specifying options for representing and penalizing the
functional coefficient <code class="reqn">\beta(t)</code>. Defaults to a cubic B-spline with second-order difference
penalties, i.e. <code>list(bs="ps", m=c(2, 1))</code> See <code><a href="mgcv.html#topic+te">te</a></code> or <code><a href="mgcv.html#topic+s">s</a></code> for details</p>
</td></tr>
<tr><td><code id="lf_old_+3A_presmooth">presmooth</code></td>
<td>
<p>logical; if true, the functional predictor is pre-smoothed prior to fitting.  See
<code><a href="fda.html#topic+smooth.basisPar">smooth.basisPar</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with the following entries
</p>

<ol>
<li> <p><code>call</code> - a <code>call</code> to <code>te</code> (or <code>s</code>, <code>t2</code>) using the appropriately
constructed covariate and weight matrices
</p>
</li>
<li> <p><code>argvals</code> - the <code>argvals</code> argument supplied to <code>lf</code>
</p>
</li>
<li> <p><code>L</code> - the  matrix of weights used for the integration
</p>
</li>
<li><p>xindname - the name used for the functional predictor variable in the <code>formula</code>
used by <code>mgcv</code>
</p>
</li>
<li> <p><code>tindname</code> - the name used for <code>argvals</code> variable in the <code>formula</code> used by <code>mgcv</code>
</p>
</li>
<li> <p><code>LXname</code> - the name used for the <code>L</code> variable in the <code>formula</code> used by <code>mgcv</code>
</p>
</li>
<li> <p><code>presmooth</code> - the <code>presmooth</code> argument supplied to <code>lf</code>
</p>
</li>
<li> <p><code>Xfd</code> - an <code>fd</code> object from presmoothing the functional predictors using
<code><a href="fda.html#topic+smooth.basisPar">smooth.basisPar</a></code>.  Only present if <code>presmooth=TRUE</code>.  See <code><a href="fda.html#topic+fd">fd</a></code>
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Mathew W. McLean <a href="mailto:mathew.w.mclean@gmail.com">mathew.w.mclean@gmail.com</a> and Fabian Scheipl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fgam">fgam</a></code>, <code><a href="#topic+af">af</a></code>, mgcv's <code><a href="mgcv.html#topic+linear.functional.terms">linear.functional.terms</a></code>,
<code><a href="#topic+fgam">fgam</a></code> for examples
</p>

<hr>
<h2 id='lf.vd'>Construct a VDFR regression term</h2><span id='topic+lf.vd'></span>

<h3>Description</h3>

<p>This function defines the a variable-domain functional regression term
for inclusion in an <code><a href="mgcv.html#topic+gam">gam</a></code>-formula (or <code><a href="mgcv.html#topic+bam">bam</a></code> or
<code><a href="mgcv.html#topic+gamm">gamm</a></code> or <code>gamm4::gamm</code> as constructed by
<code><a href="#topic+pfr">pfr</a></code>. These are functional predictors for which each function is
observed over a domain of different width.
The default is the term <code class="reqn">1/T_i\int_0^{T_i}X_i(t)\beta(t,T_i)dt</code>,
where <code class="reqn">X_i(t)</code> is a functional predictor of length <code class="reqn">T_i</code> and <code class="reqn">\beta(t,T_i)</code>
is an unknown bivariate coefficient function. Various domain transformations
are available, such as lagging or domain-standardizing the coordinates, or
parameterizing the interactions; these often result in improved model fit.
Basis choice is fully customizable using the options of
<code><a href="mgcv.html#topic+s">s</a></code> and <code><a href="mgcv.html#topic+te">te</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lf.vd(
  X,
  argvals = seq(0, 1, l = ncol(X)),
  vd = NULL,
  integration = c("simpson", "trapezoidal", "riemann"),
  L = NULL,
  basistype = c("s", "te", "t2"),
  transform = NULL,
  mp = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lf.vd_+3A_x">X</code></td>
<td>
<p>matrix containing variable-domain functions. Should be <code class="reqn">N x J</code>,
where <code class="reqn">N</code> is the number of subjects and <code class="reqn">J</code> is the maximum number of time
points per subject. Most rows will have <code>NA</code> values in the right-most
columns, corresponding to unobserved time points.</p>
</td></tr>
<tr><td><code id="lf.vd_+3A_argvals">argvals</code></td>
<td>
<p>indices of evaluation of <code>X</code>, i.e. <code class="reqn">(t_{i1},.,t_{iJ})</code> for
subject <code class="reqn">i</code>. May be entered as either a length-<code>J</code> vector, or as
an <code>N</code> by <code>J</code> matrix. Indices may be unequally spaced. Entering
as a matrix allows for different observations times for each subject.</p>
</td></tr>
<tr><td><code id="lf.vd_+3A_vd">vd</code></td>
<td>
<p>vector of values of containing the variable-domain width (<code class="reqn">T_i</code>
above). Defaults to the <code>argvals</code> value corresponding to the last
non-<code>NA</code> element of <code class="reqn">X_i(t)</code>.</p>
</td></tr>
<tr><td><code id="lf.vd_+3A_integration">integration</code></td>
<td>
<p>method used for numerical integration. Defaults to <code>"simpson"</code>'s rule
for calculating entries in <code>L</code>. Alternatively and for non-equidistant grids,
<code>"trapezoidal"</code> or <code>"riemann"</code>.</p>
</td></tr>
<tr><td><code id="lf.vd_+3A_l">L</code></td>
<td>
<p>an optional <code>N</code> by <code>ncol(argvals)</code> matrix giving the weights for the numerical
integration over <code>t</code>. If present, overrides <code>integration</code>.</p>
</td></tr>
<tr><td><code id="lf.vd_+3A_basistype">basistype</code></td>
<td>
<p>character string indicating type of bivariate basis used.
Options include <code>"s"</code> (the default), <code>"te"</code>, and <code>"t2"</code>,
which correspond to <code>mgcv::s</code>, <code>mgcv::te</code>, and <code>mgcv::t2</code>.</p>
</td></tr>
<tr><td><code id="lf.vd_+3A_transform">transform</code></td>
<td>
<p>character string indicating an optional basis transformation;
see Details for options.</p>
</td></tr>
<tr><td><code id="lf.vd_+3A_mp">mp</code></td>
<td>
<p>for <code>transform=="linear"</code> or <code>transform=="quadratic"</code>,
<code>TRUE</code> to use multiple penalties for the smooth (one for each marginal
basis). If <code>FALSE</code>, penalties are concatonated into a single
block-diagonal penalty matrix (with one smoothing parameter).</p>
</td></tr>
<tr><td><code id="lf.vd_+3A_...">...</code></td>
<td>
<p>optional arguments for basis and penalization to be passed to the
function indicated by <code>basistype</code>. These could include, for example,
<code>"bs"</code>, <code>"k"</code>, <code>"m"</code>, etc. See <code><a href="mgcv.html#topic+te">te</a></code> or
<code><a href="mgcv.html#topic+s">s</a></code> for details.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The variable-domain functional regression model uses the term
<code class="reqn">\frac1{T_i}\int_0^{T_i}X_i(t)\beta(t,T_i)dt</code> to incorporate a
functional predictor with subject-specific domain width. This term imposes
a smooth (nonparametric) interaction between <code class="reqn">t</code> and <code class="reqn">T_i</code>. The domain
of the coefficient function is the triangular (or trapezoidal) surface
defined by <code class="reqn">{t,T_i: 0\le t\le T_i}</code>. The default basis uses
bivariate thin-plate regression splines.
</p>
<p>Different basis transformations can result in different properties; see
Gellar, et al. (2014) for a more complete description. We make five basis
transformations easily accessible using the <code>transform</code> argument.
This argument is a character string that can take one of the following
values:
</p>

<ol>
<li> <p><code>"lagged"</code>: transforms <code>argvals</code> to <code>argvals - vd</code>
</p>
</li>
<li> <p><code>"standardized"</code>: transforms <code>argvals</code> to <code>argvals/vd</code>,
and then rescales <code>vd</code> linearly so it ranges from 0 to 1
</p>
</li>
<li> <p><code>"linear"</code>: first transforms the domain as in
<code>"standardized"</code>, then parameterizes the interaction with
<code>"vd"</code> to be linear
</p>
</li>
<li> <p><code>"quadratic"</code>: first transforms the domain as in
<code>"standardized"</code>, then parameterizes the interaction with
<code>"vd"</code> to be quadratic
</p>
</li>
<li> <p><code>"noInteraction"</code>: first transforms the domain as in
<code>"standardized"</code>, then reduces the bivariate basis to univariate
with no effect of <code>vd</code>. This would be equivalent to using
<code><a href="#topic+lf">lf</a></code> on the domain-standardized predictor functions.
</p>
</li></ol>

<p>The practical effect of using the <code>"lagged"</code> basis is to increase
smoothness along the right (diagonal) edge of the resultant estimate.
The practical effect of using a <code>"standardized"</code> basis is to allow
for greater smoothness at high values of <code class="reqn">T_i</code> compared to lower
values.
</p>
<p>These basis transformations rely on the basis constructors
available in the <code>mgcvTrans</code> package. For more specific control over
the transformations, you can use <code>bs="dt"</code> and/or <code>bs="pi"</code>;
see <code><a href="#topic+smooth.construct.dt.smooth.spec">smooth.construct.dt.smooth.spec</a></code> or
<code><a href="#topic+smooth.construct.pi.smooth.spec">smooth.construct.pi.smooth.spec</a></code> for an explanation of the
options (entered through the <code>xt</code> argument of <code>lf.vd</code>/<code>s</code>).
</p>
<p>Note that tensor product bases are only recommended when a standardized
transformation is used. Without this transformation, just under half of
the &quot;knots&quot; used to define the basis will fall outside the range of the
data and have no data available to estimate them. The penalty allows
the corresponding coefficients to be estimated, but results may be
unstable.
</p>


<h3>Value</h3>

<p>a list with the following entries
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>a <code>call</code> to <code>s</code> or <code>te</code>, using the appropriately constructed
weight matrices</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>data used by the <code>call</code>, which includes the matrices indicated
by <code>argname</code>, <code>Tindname</code>, and <code>LXname</code></p>
</td></tr>
<tr><td><code>L</code></td>
<td>
<p>the matrix of weights used for the integration</p>
</td></tr>
<tr><td><code>argname</code></td>
<td>
<p>the name used for the <code>argvals</code> variable in the <code>formula</code>
used by <code>mgcv::gam</code></p>
</td></tr>
<tr><td><code>Tindname</code></td>
<td>
<p>the name used for the <code>Tind</code> variable in the <code>formula</code>
used by <code>mgcv::gam</code></p>
</td></tr>
<tr><td><code>LXname</code></td>
<td>
<p>the name of the <code>by</code> variable used by <code>s</code> or <code>te</code>
in the <code>formula</code> for <code>mgcv::gam</code></p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jonathan E. Gellar &lt;JGellar@mathematica-mpr.com&gt;
</p>


<h3>References</h3>

<p>Gellar, Jonathan E., Elizabeth Colantuoni, Dale M. Needham, and
Ciprian M. Crainiceanu. Variable-Domain Functional Regression for Modeling
ICU Data. Journal of the American Statistical Association,
109(508):1425-1439, 2014.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pfr">pfr</a></code>, <code><a href="#topic+lf">lf</a></code>, mgcv's
<code><a href="mgcv.html#topic+linear.functional.terms">linear.functional.terms</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  data(sofa)
  fit.vd1 &lt;- pfr(death ~ lf.vd(SOFA) + age + los,
                 family="binomial", data=sofa)
  fit.vd2 &lt;- pfr(death ~ lf.vd(SOFA, transform="lagged") + age + los,
                 family="binomial", data=sofa)
  fit.vd3 &lt;- pfr(death ~ lf.vd(SOFA, transform="standardized") + age + los,
                 family="binomial", data=sofa)
  fit.vd4 &lt;- pfr(death ~ lf.vd(SOFA, transform="standardized",
                               basistype="te") + age + los,
                 family="binomial", data=sofa)
  fit.vd5 &lt;- pfr(death ~ lf.vd(SOFA, transform="linear", bs="ps") + age + los,
                 family="binomial", data=sofa)
  fit.vd6 &lt;- pfr(death ~ lf.vd(SOFA, transform="quadratic", bs="ps") + age + los,
                 family="binomial", data=sofa)
  fit.vd7 &lt;- pfr(death ~ lf.vd(SOFA, transform="noInteraction", bs="ps") + age + los,
                 family="binomial", data=sofa)
  
  ests &lt;- lapply(1:7, function(i) {
    c.i &lt;- coef(get(paste0("fit.vd", i)), n=173, n2=173) 
    c.i[(c.i$SOFA.arg &lt;= c.i$SOFA.vd),]
  })
  
  # Try plotting for each i
  i &lt;- 1
  lims &lt;- c(-2,8)
  if (requireNamespace("ggplot2", quietly = TRUE) &amp;
      requireNamespace("RColorBrewer", quietly = TRUE)) {
        est &lt;- ests[[i]]
        est$value[est$value&lt;lims[1]] &lt;- lims[1]
        est$value[est$value&gt;lims[2]] &lt;- lims[2]
        ggplot2::ggplot(est, ggplot2::aes(SOFA.arg, SOFA.vd)) +
          ggplot2::geom_tile(ggplot2::aes(colour=value, fill=value)) +
          ggplot2::scale_fill_gradientn(  name="", limits=lims,
                    colours=rev(RColorBrewer::brewer.pal(11,"Spectral"))) +
          ggplot2::scale_colour_gradientn(name="", limits=lims,
                    colours=rev(RColorBrewer::brewer.pal(11,"Spectral"))) +
          ggplot2::scale_y_continuous(expand = c(0,0)) +
          ggplot2::scale_x_continuous(expand = c(0,0)) +
          ggplot2::theme_bw()
  }

## End(Not run)
  
</code></pre>

<hr>
<h2 id='lofocv'>Leave-one-function-out cross-validation</h2><span id='topic+lofocv'></span>

<h3>Description</h3>

<p>This internal function, called by <code>fosr()</code> when <code>method="OLS"</code>,
performs efficient leave-one-function-out cross-validation using
Demmler-Reinsch orthogonalization to choose the smoothing parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lofocv(Y, X, S1, argvals, lamvec = NULL, constr = NULL, maxlam = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lofocv_+3A_y">Y</code></td>
<td>
<p>matrix of responses, e.g. with columns corresponding to basis
function coefficients.</p>
</td></tr>
<tr><td><code id="lofocv_+3A_x">X</code></td>
<td>
<p>model matrix.</p>
</td></tr>
<tr><td><code id="lofocv_+3A_s1">S1</code></td>
<td>
<p>penalty matrix.</p>
</td></tr>
<tr><td><code id="lofocv_+3A_argvals">argvals</code></td>
<td>
<p>values where the functions are evaluated</p>
</td></tr>
<tr><td><code id="lofocv_+3A_lamvec">lamvec</code></td>
<td>
<p>vector of candidate smoothing parameter values.  If
<code>NULL</code>, smoothing parameter is chosen by <code><a href="stats.html#topic+optimize">optimize</a></code>.</p>
</td></tr>
<tr><td><code id="lofocv_+3A_constr">constr</code></td>
<td>
<p>matrix of linear constraints.</p>
</td></tr>
<tr><td><code id="lofocv_+3A_maxlam">maxlam</code></td>
<td>
<p>maximum smoothing parameter value to consider (when
<code>lamvec=NULL</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>if <code>lamvec=NULL</code>, a list (returned by <code>optimize</code>) with
elements <code>minimum</code> and <code>objective</code> giving, respectively, the
chosen smoothing parameter and the associated cross-validation score.
Otherwise a 2-column table with the candidate smoothing parameters in the
first column and the corresponding cross-validation scores in the second.
</p>


<h3>Author(s)</h3>

<p>Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a> and Lei Huang
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fosr">fosr</a></code>, <code><a href="#topic+pwcv">pwcv</a></code>
</p>

<hr>
<h2 id='lpeer'>Longitudinal Functional Models with Structured Penalties</h2><span id='topic+lpeer'></span>

<h3>Description</h3>

<p>Implements longitudinal functional model with structured penalties (Kundu
et al., 2012) with scalar outcome, single functional predictor, one or more
scalar covariates and subject-specific random intercepts through mixed
model equivalence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpeer(
  Y,
  subj,
  t,
  funcs,
  argvals = NULL,
  covariates = NULL,
  comm.pen = TRUE,
  pentype = "Ridge",
  L.user = NULL,
  f_t = NULL,
  Q = NULL,
  phia = 10^3,
  se = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpeer_+3A_y">Y</code></td>
<td>
<p>vector of all outcomes over all visits or timepoints</p>
</td></tr>
<tr><td><code id="lpeer_+3A_subj">subj</code></td>
<td>
<p>vector containing the subject number for each observation</p>
</td></tr>
<tr><td><code id="lpeer_+3A_t">t</code></td>
<td>
<p>vector containing the time information when the observation are
taken</p>
</td></tr>
<tr><td><code id="lpeer_+3A_funcs">funcs</code></td>
<td>
<p>matrix containing observed functional predictors as rows. Rows
with <code>NA</code> and <code>Inf</code> values will be deleted.</p>
</td></tr>
<tr><td><code id="lpeer_+3A_argvals">argvals</code></td>
<td>
<p>matrix (or vector) of indices of evaluations of <code class="reqn">X_i(t)</code>; i.e. a matrix with
<em>i</em>th row <code class="reqn">(t_{i1},.,t_{iJ})</code></p>
</td></tr>
<tr><td><code id="lpeer_+3A_covariates">covariates</code></td>
<td>
<p>matrix of scalar covariates.</p>
</td></tr>
<tr><td><code id="lpeer_+3A_comm.pen">comm.pen</code></td>
<td>
<p>logical value indicating whether common penalty for all the
components of regression function. Default is <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="lpeer_+3A_pentype">pentype</code></td>
<td>
<p>type of penalty: either decomposition based penalty
(<code>'DECOMP'</code>) or ridge (<code>'RIDGE'</code>) or second-order difference
penalty (<code>'D2'</code>) or any user defined penalty (<code>'USER'</code>). For
decomposition based penalty user need to specify Q matrix in <code>Q</code>
argument (see details). For user defined penalty user need to specify L
matrix in <code>L</code> argument (see details). For Ridge and second-order
difference penalty, specification for arguments <code>L</code> and <code>Q</code> will
be ignored. Default is <code>'RIDGE'</code>.</p>
</td></tr>
<tr><td><code id="lpeer_+3A_l.user">L.user</code></td>
<td>
<p>penalty matrix. Need to be specified with
<code>pentype='USER'</code>. When <code>comm.pen=TRUE</code>, Number of columns need to
be equal with number of columns of matrix specified to <code>funcs</code>. When
<code>comm.pen=FALSE</code>, Number of columns need to be equal with the number
of columns of matrix specified to <code>funcs</code> times the number of
components of regression function. Each row represents a constraint on
functional predictor. This argument will be ignored when value of
<code>pentype</code> is other than <code>'USER'</code>.</p>
</td></tr>
<tr><td><code id="lpeer_+3A_f_t">f_t</code></td>
<td>
<p>vector or matrix with number of rows equal to number of total
observations and number of columns equal to d (see details). If matrix then
each column pertains to single function of time and the value in the column
represents the realization corresponding to time vector t. The column with
intercept or multiple of intercept will be dropped. A <code>NULL</code> value
refers to time-invariant regression function. Default value is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="lpeer_+3A_q">Q</code></td>
<td>
<p>Q matrix to derive decomposition based penalty. Need to be
specified with <code>pentype='DECOMP'</code>. When <code>comm.pen=TRUE</code>, number
of columns must equal number of columns of matrix specified to
<code>funcs</code>. When <code>comm.pen=FALSE</code>, Number of columns need to be
equal with the number of columns of matrix specified to <code>funcs</code> times
the number of components of regression function. Each row represents a
basis function where functional predictor is expected lie according to
prior belief. This argument will be ignored when value of <code>pentype</code> is
other than <code>'DECOMP'</code>.</p>
</td></tr>
<tr><td><code id="lpeer_+3A_phia">phia</code></td>
<td>
<p>scalar value of a in decomposition based penalty. Needs to be
specified with <code>pentype='DECOMP'</code>.</p>
</td></tr>
<tr><td><code id="lpeer_+3A_se">se</code></td>
<td>
<p>logical; calculate standard error when <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="lpeer_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="nlme.html#topic+lme">lme</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are any missing or infinite values in <code>Y</code>, <code>subj</code>,
<code>t</code>, <code>covariates</code>, <code>funcs</code> and <code>f_t</code>, the corresponding
row (or observation) will be dropped, and infinite values are not allowed
for these arguments. Neither <code>Q</code> nor <code>L</code> may contain missing or
infinite values.  <code>lpeer()</code> fits the following model:
</p>
<p><code class="reqn">y_{i(t)}=X_{i(t)}^T \beta+\int {W_{i(t)}(s)\gamma(t,s) ds}
+Z_{i(t)}u_i + \epsilon_{i(t)}</code>
</p>
<p>where <code class="reqn">\epsilon_{i(t)} ~ N(0,\sigma ^2)</code> and <code class="reqn">u_i ~ N(0,
\sigma_u^2)</code>.  For all the observations, predictor function
<code class="reqn">W_{i(t)}(s)</code> is evaluated at K sampling points. Here, regression
function <code class="reqn">\gamma (t,s)</code> is represented in terms of (d+1) component
functions <code class="reqn">\gamma_0(s)</code>,..., <code class="reqn">\gamma_d(s)</code> as follows
</p>
<p><code class="reqn">\gamma (t,s)= \gamma_0(s)+f_1(t) \gamma_1(s) + f_d(t) \gamma_d(s)</code>
</p>
<p>Values of <code class="reqn">y_{i(t)} , X_{i(t)}</code> and <code class="reqn">W_{i(t)}(s)</code> are passed
through argument <code>Y</code>, <code>covariates</code> and <code>funcs</code>,
respectively. Number of elements or rows in <code>Y</code>, <code>t</code>,
<code>subj</code>, <code>covariates</code> (if not <code>NULL</code>) and <code>funcs</code> need
to be equal.
</p>
<p>Values of <code class="reqn">f_1(t),...,f_d(t)</code> are passed through f_t argument. The
matrix passed through <code>f_t</code> argument should have d columns where each
column represents one and only one of <code class="reqn">f_1(t),..., f_d(t)</code>.
</p>
<p>The estimate of (d+1) component functions <code class="reqn">\gamma_0(s)</code>,...,
<code class="reqn">\gamma_d(s)</code> is obtained as penalized estimated. The following 3 types
of penalties can be used for a component function:
</p>
<p>i.  Ridge: <code class="reqn">I_K</code>
</p>
<p>ii.  Second-order difference: [<code class="reqn">d_{i,j}</code>] with <code class="reqn">d_{i,i} = d_{i,i+2}
= 1, d_{i,i+1} = -2</code>, otherwise <code class="reqn">d_{i,j} =0</code>
</p>
<p>iii. Decomposition based penalty: <code class="reqn">bP_Q+a(I-P_Q)</code> where <code class="reqn">P_Q= Q^T
(QQ^T)^{-1}Q</code>
</p>
<p>For Decomposition based penalty the user must specify <code>pentype=
'DECOMP'</code> and the associated Q matrix must be passed through the <code>Q</code>
argument. Alternatively, one can directly specify the penalty matrix by
setting <code>pentype= 'USER'</code> and using the <code>L</code> argument to supply
the associated L matrix.
</p>
<p>If Q (or L) matrix is similar for all the component functions then argument
<code>comm.pen</code> should have value <code>TRUE</code> and in that case specified
matrix to argument <code>Q</code> (or <code>L</code>) should have K columns. When Q (or
L) matrix is different for all the component functions then argument
<code>comm.pen</code> should have value <code>FALSE</code> and in that case specified
matrix to argument <code>Q</code> (or <code>L</code>) should have K(d+1) columns. Here
first K columns pertains to first component function, second K columns
pertains to second component functions, and so on.
</p>
<p>Default penalty is Ridge penalty for all the component functions and user
needs to specify <code>'RIDGE'</code>. For second-order difference penalty, user
needs to specify <code>'D2'</code>. When pentype is <code>'RIDGE'</code> or <code>'D2'</code>
the value of <code>comm.pen</code> is always <code>TRUE</code> and
<code>comm.pen=FALSE</code> will be ignored.
</p>


<h3>Value</h3>

<p>A list containing: </p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>result of the call to <code>lme</code></p>
</td></tr>
<tr><td><code>fitted.vals</code></td>
<td>
<p>predicted outcomes</p>
</td></tr> <tr><td><code>BetaHat</code></td>
<td>
<p>parameter estimates
for scalar covariates including intercept</p>
</td></tr> <tr><td><code>se.Beta</code></td>
<td>
<p>standard error of
parameter estimates for scalar covariates including intercept</p>
</td></tr>
<tr><td><code>Beta</code></td>
<td>
<p>parameter estimates with standard error for scalar covariates
including intercept</p>
</td></tr> <tr><td><code>GammaHat</code></td>
<td>
<p>estimates of components of regression
functions. Each column represents one component function. </p>
</td></tr>
<tr><td><code>Se.Gamma</code></td>
<td>
<p>standard error associated with <code>GammaHat</code></p>
</td></tr>
<tr><td><code>AIC</code></td>
<td>
<p>AIC value of fit (smaller is better) </p>
</td></tr> <tr><td><code>BIC</code></td>
<td>
<p>BIC value of
fit (smaller is better) </p>
</td></tr> <tr><td><code>logLik</code></td>
<td>
<p>(restricted) log-likelihood at
convergence</p>
</td></tr> <tr><td><code>lambda</code></td>
<td>
<p>list of estimated smoothing parameters
associated with each component function</p>
</td></tr> <tr><td><code>V</code></td>
<td>
<p>conditional variance of Y
treating only random intercept as random one. </p>
</td></tr> <tr><td><code>V1</code></td>
<td>
<p>unconditional
variance of Y </p>
</td></tr> <tr><td><code>N</code></td>
<td>
<p>number of subjects</p>
</td></tr> <tr><td><code>K</code></td>
<td>
<p>number of Sampling
points in functional predictor</p>
</td></tr> <tr><td><code>TotalObs</code></td>
<td>
<p>total number of
observations over all subjects</p>
</td></tr> <tr><td><code>Sigma.u</code></td>
<td>
<p>estimated sd of random
intercept. </p>
</td></tr> <tr><td><code>sigma</code></td>
<td>
<p>estimated within-group error standard deviation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Madan Gopal Kundu <a href="mailto:mgkundu@iupui.edu">mgkundu@iupui.edu</a>
</p>


<h3>References</h3>

<p>Kundu, M. G., Harezlak, J., and Randolph, T. W. (2012).
Longitudinal functional models with structured penalties (arXiv:1211.4763
[stat.AP]).
</p>
<p>Randolph, T. W., Harezlak, J, and Feng, Z. (2012). Structured penalties for
functional linear models - partially empirical eigenvectors for regression.
<em>Electronic Journal of Statistics</em>, 6, 323&ndash;353.
</p>


<h3>See Also</h3>

<p><code>peer</code>, <code>plot.lpeer</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
#------------------------------------------------------------------------
# Example 1: Estimation with Ridge penalty
#------------------------------------------------------------------------

##Load Data
data(DTI)

## Extract values for arguments for lpeer() from given data
cca = DTI$cca[which(DTI$case == 1),]
DTI = DTI[which(DTI$case == 1),]

##1.1 Fit the model with single component function
##    gamma(t,s)=gamm0(s)
t&lt;- DTI$visit
fit.cca.lpeer1 = lpeer(Y=DTI$pasat, t=t, subj=DTI$ID, funcs = cca)
plot(fit.cca.lpeer1)

##1.2 Fit the model with two component function
##    gamma(t,s)=gamm0(s) + t*gamma1(s)
fit.cca.lpeer2 = lpeer(Y=DTI$pasat, t=t, subj=DTI$ID, funcs = cca,
                      f_t=t, se=TRUE)
plot(fit.cca.lpeer2)

#------------------------------------------------------------------------
# Example 2: Estimation with structured penalty (need structural
#            information about regression function or predictor function)
#------------------------------------------------------------------------

##Load Data
data(PEER.Sim)

## Extract values for arguments for lpeer() from given data
K&lt;- 100
W&lt;- PEER.Sim[,c(3:(K+2))]
Y&lt;- PEER.Sim[,K+3]
t&lt;- PEER.Sim[,2]
id&lt;- PEER.Sim[,1]

##Load Q matrix containing structural information
data(Q)

##2.1 Fit the model with two component function
##    gamma(t,s)=gamm0(s) + t*gamma1(s)
Fit1&lt;- lpeer(Y=Y, subj=id, t=t, covariates=cbind(t), funcs=W,
	    pentype='DECOMP', f_t=cbind(1,t), Q=Q, se=TRUE)

Fit1$Beta
plot(Fit1)

##2.2 Fit the model with three component function
##    gamma(t,s)=gamm0(s) + t*gamma1(s) + t^2*gamma1(s)
Fit2&lt;- lpeer(Y=Y, subj=id, t=t, covariates=cbind(t), funcs=W,
		     pentype='DECOMP', f_t=cbind(1,t, t^2), Q=Q, se=TRUE)

Fit2$Beta
plot(Fit2)

##2.3 Fit the model with two component function with different penalties
##    gamma(t,s)=gamm0(s) + t*gamma1(s)
Q1&lt;- cbind(Q, Q)
Fit3&lt;- lpeer(Y=Y, subj=id, t=t, covariates=cbind(t), comm.pen=FALSE, funcs=W,
		     pentype='DECOMP', f_t=cbind(1,t), Q=Q1, se=TRUE)

##2.4 Fit the model with two component function with user defined penalties
##    gamma(t,s)=gamm0(s) + t*gamma1(s)
phia&lt;- 10^3
P_Q &lt;- t(Q)%*%solve(Q%*%t(Q))%*% Q
L&lt;- phia*(diag(K)- P_Q) + 1*P_Q
Fit4&lt;- lpeer(Y=Y, subj=id, t=t, covariates=cbind(t), funcs=W,
		     pentype='USER', f_t=cbind(1,t), L=L, se=TRUE)

L1&lt;- adiag(L, L)
Fit5&lt;- lpeer(Y=Y, subj=id, t=t, covariates=cbind(t), comm.pen=FALSE, funcs=W,
		     pentype='USER', f_t=cbind(1,t), L=L1, se=TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='lpfr'>Longitudinal penalized functional regression</h2><span id='topic+lpfr'></span>

<h3>Description</h3>

<p>Implements longitudinal penalized functional regression (Goldsmith et al.,
2012) for generalized linear functional models with scalar outcomes and
subject-specific random intercepts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lpfr(
  Y,
  subj,
  covariates = NULL,
  funcs,
  kz = 30,
  kb = 30,
  smooth.cov = FALSE,
  family = "gaussian",
  method = "REML",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lpfr_+3A_y">Y</code></td>
<td>
<p>vector of all outcomes over all visits</p>
</td></tr>
<tr><td><code id="lpfr_+3A_subj">subj</code></td>
<td>
<p>vector containing the subject number for each observation</p>
</td></tr>
<tr><td><code id="lpfr_+3A_covariates">covariates</code></td>
<td>
<p>matrix of scalar covariates</p>
</td></tr>
<tr><td><code id="lpfr_+3A_funcs">funcs</code></td>
<td>
<p>matrix or list of matrices containing observed functional
predictors as rows. NA values are allowed.</p>
</td></tr>
<tr><td><code id="lpfr_+3A_kz">kz</code></td>
<td>
<p>dimension of principal components basis for the observed
functional predictors</p>
</td></tr>
<tr><td><code id="lpfr_+3A_kb">kb</code></td>
<td>
<p>dimension of the truncated power series spline basis for the
coefficient function</p>
</td></tr>
<tr><td><code id="lpfr_+3A_smooth.cov">smooth.cov</code></td>
<td>
<p>logical; do you wish to smooth the covariance matrix of
observed functions? Increases computation time, but results in smooth
principal components</p>
</td></tr>
<tr><td><code id="lpfr_+3A_family">family</code></td>
<td>
<p>generalized linear model family</p>
</td></tr>
<tr><td><code id="lpfr_+3A_method">method</code></td>
<td>
<p>method for estimating the smoothing parameters; defaults to
REML</p>
</td></tr>
<tr><td><code id="lpfr_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="mgcv.html#topic+gam">gam</a></code> to fit
the regression model.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functional predictors are entered as a matrix or, in the case of multiple
functional predictors, as a list of matrices using the <code>funcs</code>
argument. Missing values are allowed in the functional predictors, but it
is assumed that they are observed over the same grid. Functional
coefficients and confidence bounds are returned as lists in the same order
as provided in the <code>funcs</code> argument, as are principal component and
spline bases.
</p>


<h3>Value</h3>

<table>
<tr><td><code>fit</code></td>
<td>
<p>result of the call to <code>gam</code></p>
</td></tr> <tr><td><code>fitted.vals</code></td>
<td>
<p>predicted outcomes</p>
</td></tr> <tr><td><code>betaHat</code></td>
<td>
<p>list of estimated coefficient
functions</p>
</td></tr> <tr><td><code>beta.covariates</code></td>
<td>
<p>parameter estimates for scalar
covariates</p>
</td></tr> <tr><td><code>ranef</code></td>
<td>
<p>vector of subject-specific random intercepts</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>design matrix used in the model fit</p>
</td></tr> <tr><td><code>phi</code></td>
<td>
<p>list of
truncated power series spline bases for the coefficient functions</p>
</td></tr>
<tr><td><code>psi</code></td>
<td>
<p>list of principal components basis for the functional
predictors</p>
</td></tr> <tr><td><code>varBetaHat</code></td>
<td>
<p>list containing covariance matrices for the
estimated coefficient functions</p>
</td></tr> <tr><td><code>Bounds</code></td>
<td>
<p>list of bounds of a 95%
confidence interval for the estimated coefficient functions</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith &lt;jeff.goldsmith@columbia.edu&gt;
</p>


<h3>References</h3>

<p>Goldsmith, J., Crainiceanu, C., Caffo, B., and Reich, D.
(2012). Longitudinal penalized functional regression for cognitive outcomes
on neuronal tract measurements. <em>Journal of the Royal Statistical
Society: Series C</em>, 61(3), 453&ndash;469.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
##################################################################
# use longitudinal data to regress continuous outcomes on
# functional predictors (continuous outcomes only recorded for
# case == 1)
##################################################################

data(DTI)

# subset data as needed for this example
cca = DTI$cca[which(DTI$case == 1),]
rcst = DTI$rcst[which(DTI$case == 1),]
DTI = DTI[which(DTI$case == 1),]


# note there is missingness in the functional predictors
apply(is.na(cca), 2, mean)
apply(is.na(rcst), 2, mean)


# fit two models with single functional predictors and plot the results
fit.cca = lpfr(Y=DTI$pasat, subj=DTI$ID, funcs = cca, smooth.cov=FALSE)
fit.rcst = lpfr(Y=DTI$pasat, subj=DTI$ID, funcs = rcst, smooth.cov=FALSE)

par(mfrow = c(1,2))
matplot(cbind(fit.cca$BetaHat[[1]], fit.cca$Bounds[[1]]),
  type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat",
  main = "CCA")
matplot(cbind(fit.rcst$BetaHat[[1]], fit.rcst$Bounds[[1]]),
  type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat",
  main = "RCST")


# fit a model with two functional predictors and plot the results
fit.cca.rcst = lpfr(Y=DTI$pasat, subj=DTI$ID, funcs = list(cca,rcst),
  smooth.cov=FALSE)

par(mfrow = c(1,2))
matplot(cbind(fit.cca.rcst$BetaHat[[1]], fit.cca.rcst$Bounds[[1]]),
  type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat",
  main = "CCA")
matplot(cbind(fit.cca.rcst$BetaHat[[2]], fit.cca.rcst$Bounds[[2]]),
  type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat",
  main = "RCST")

## End(Not run)
</code></pre>

<hr>
<h2 id='mfpca.face'>Multilevel functional principal components analysis with fast covariance estimation</h2><span id='topic+mfpca.face'></span>

<h3>Description</h3>

<p>Decompose dense or sparse multilevel functional observations using multilevel
functional principal component analysis with the fast covariance estimation
approach.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mfpca.face(
  Y,
  id,
  visit = NULL,
  twoway = TRUE,
  weight = "obs",
  argvals = NULL,
  pve = 0.99,
  npc = NULL,
  p = 3,
  m = 2,
  knots = 35,
  silent = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mfpca.face_+3A_y">Y</code></td>
<td>
<p>A multilevel functional dataset on a regular grid stored in a matrix.
Each row of the data is the functional observations at one visit for one subject.
Missingness is allowed and need to be labeled as NA. The data must be specified.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_id">id</code></td>
<td>
<p>A vector containing the id information to identify the subjects. The
data must be specified.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_visit">visit</code></td>
<td>
<p>A vector containing information used to identify the visits.
If not provided, assume the visit id are 1,2,... for each subject.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_twoway">twoway</code></td>
<td>
<p>Logical, indicating whether to carry out twoway ANOVA and
calculate visit-specific means. Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_weight">weight</code></td>
<td>
<p>The way of calculating covariance. <code>weight = "obs"</code> indicates
that the sample covariance is weighted by observations. <code>weight = "subj"</code>
indicates that the sample covariance is weighted equally by subjects. Defaults to <code>"obs"</code>.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_argvals">argvals</code></td>
<td>
<p>A vector containing observed locations on the functional domain.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_pve">pve</code></td>
<td>
<p>Proportion of variance explained. This value is used to choose the
number of principal components for both levels.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_npc">npc</code></td>
<td>
<p>Pre-specified value for the number of principal components.
If given, this overrides <code>pve</code>.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_p">p</code></td>
<td>
<p>The degree of B-splines functions to use. Defaults to 3.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_m">m</code></td>
<td>
<p>The order of difference penalty to use. Defaults to 2.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_knots">knots</code></td>
<td>
<p>Number of knots to use or the vectors of knots. Defaults to 35.</p>
</td></tr>
<tr><td><code id="mfpca.face_+3A_silent">silent</code></td>
<td>
<p>Logical, indicating whether to not display the name of each step.
Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The fast MFPCA approach (Cui et al., 2023) uses FACE (Xiao et al., 2016) to estimate
covariance functions and mixed model equations (MME) to predict
scores for each level. As a result, it has lower computational complexity than
MFPCA (Di et al., 2009) implemented in the <code>mfpca.sc</code> function, and
can be applied to decompose data sets with over 10000 subjects and over 10000
dimensions.
</p>


<h3>Value</h3>

<p>A list containing:
</p>
<table>
<tr><td><code>Yhat</code></td>
<td>
<p>FPC approximation (projection onto leading components)
of <code>Y</code>, estimated curves for all subjects and visits</p>
</td></tr>
<tr><td><code>Yhat.subject</code></td>
<td>
<p>Estimated subject specific curves for all subjects</p>
</td></tr>
<tr><td><code>Y.df</code></td>
<td>
<p>The observed data</p>
</td></tr>
<tr><td><code>mu</code></td>
<td>
<p>estimated mean function (or a vector of zeroes if <code>center==FALSE</code>).</p>
</td></tr>
<tr><td><code>eta</code></td>
<td>
<p>The estimated visit specific shifts from overall mean.</p>
</td></tr>
<tr><td><code>scores</code></td>
<td>
<p>A matrix of estimated FPC scores for level1 and level2.</p>
</td></tr>
<tr><td><code>efunctions</code></td>
<td>
<p>A matrix of estimated eigenfunctions of the functional
covariance, i.e., the FPC basis functions for levels 1 and 2.</p>
</td></tr>
<tr><td><code>evalues</code></td>
<td>
<p>Estimated eigenvalues of the covariance operator, i.e., variances
of FPC scores for levels 1 and 2.</p>
</td></tr>
<tr><td><code>pve</code></td>
<td>
<p>The percent variance explained by the returned number of PCs.</p>
</td></tr>
<tr><td><code>npc</code></td>
<td>
<p>Number of FPCs: either the supplied <code>npc</code>, or the minimum
number of basis functions needed to explain proportion <code>pve</code> of the
variance in the observed curves for levels 1 and 2.</p>
</td></tr>
<tr><td><code>sigma2</code></td>
<td>
<p>Estimated measurement error variance.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ruonan Li <a href="mailto:rli20@ncsu.edu">rli20@ncsu.edu</a>, Erjia Cui <a href="mailto:ecui@umn.edu">ecui@umn.edu</a>
</p>


<h3>References</h3>

<p>Cui, E., Li, R., Crainiceanu, C., and Xiao, L. (2023). Fast multilevel
functional principal component analysis. <em>Journal of Computational and
Graphical Statistics</em>, 32(3), 366-377.
</p>
<p>Di, C., Crainiceanu, C., Caffo, B., and Punjabi, N. (2009).
Multilevel functional principal component analysis. <em>Annals of Applied
Statistics</em>, 3, 458-488.
</p>
<p>Xiao, L., Ruppert, D., Zipunnikov, V., and Crainiceanu, C. (2016).
Fast covariance estimation for high-dimensional functional data.
<em>Statistics and Computing</em>, 26, 409-421.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(DTI)
mfpca.DTI &lt;- mfpca.face(Y = DTI$cca, id = DTI$ID, twoway = TRUE)
</code></pre>

<hr>
<h2 id='mfpca.sc'>Multilevel functional principal components analysis by smoothed covariance</h2><span id='topic+mfpca.sc'></span>

<h3>Description</h3>

<p>Decomposes functional observations using functional principal components
analysis. A mixed model framework is used to estimate scores and obtain
variance estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mfpca.sc(
  Y = NULL,
  id = NULL,
  visit = NULL,
  twoway = FALSE,
  argvals = NULL,
  nbasis = 10,
  pve = 0.99,
  npc = NULL,
  makePD = FALSE,
  center = TRUE,
  cov.est.method = 2,
  integration = "trapezoidal"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mfpca.sc_+3A_y">Y</code></td>
<td>
<p>The user must supply a matrix of functions on a regular grid</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_id">id</code></td>
<td>
<p>Must be supplied, a vector containing the id information used to identify clusters</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_visit">visit</code></td>
<td>
<p>A vector containing information used to identify visits. Defaults to <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_twoway">twoway</code></td>
<td>
<p>logical, indicating whether to carry out twoway ANOVA and calculate visit-specific means. Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_argvals">argvals</code></td>
<td>
<p>function argument.</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_nbasis">nbasis</code></td>
<td>
<p>number of B-spline basis functions used for estimation of the
mean function and bivariate smoothing of the covariance surface.</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_pve">pve</code></td>
<td>
<p>proportion of variance explained: used to choose the number of
principal components.</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_npc">npc</code></td>
<td>
<p>prespecified value for the number of principal components (if
given, this overrides <code>pve</code>).</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_makepd">makePD</code></td>
<td>
<p>logical: should positive definiteness be enforced for the
covariance surface estimate? Defaults to <code>FALSE</code> Only <code>FALSE</code> is currently supported.</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_center">center</code></td>
<td>
<p>logical: should an estimated mean function be subtracted from
<code>Y</code>? Set to <code>FALSE</code> if you have already demeaned the data using
your favorite mean function estimate.</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_cov.est.method">cov.est.method</code></td>
<td>
<p>covariance estimation method. If set to <code>1</code>, a
one-step method that applies a bivariate smooth to the <code class="reqn">y(s_1)y(s_2)</code>
values. This can be very slow. If set to <code>2</code> (the default), a two-step
method that obtains a naive covariance estimate which is then smoothed. <code>2</code> is currently supported.</p>
</td></tr>
<tr><td><code id="mfpca.sc_+3A_integration">integration</code></td>
<td>
<p>quadrature method for numerical integration; only
<code>"trapezoidal"</code> is currently supported.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes a multilevel FPC decomposition for a set of observed curves,
which may be sparsely observed and/or measured with error. A mixed model
framework is used to estimate level 1 and level 2  scores.
</p>
<p>MFPCA was proposed in Di et al. (2009), with variations for 
MFPCA with sparse data in Di et al. (2014). 
<code>mfpca.sc</code> uses penalized splines to smooth the covariance functions, as
Described in Di et al. (2009) and Goldsmith et al. (2013).
</p>


<h3>Value</h3>

<p>An object of class <code>mfpca</code> containing:
</p>
<table>
<tr><td><code>Yhat</code></td>
<td>
<p>FPC approximation (projection onto leading components)
of <code>Y</code>, estimated curves for all subjects and visits</p>
</td></tr>
<tr><td><code>Yhat.subject</code></td>
<td>
<p>estimated subject specific curves for all subjects</p>
</td></tr> 
<tr><td><code>Y</code></td>
<td>
<p>the observed data</p>
</td></tr><tr><td><code>scores</code></td>
<td>
<p><code class="reqn">n
\times npc</code> matrix of estimated FPC scores for level1 and level2.</p>
</td></tr> <tr><td><code>mu</code></td>
<td>
<p>estimated mean
function (or a vector of zeroes if <code>center==FALSE</code>).</p>
</td></tr> <tr><td><code>efunctions</code></td>
<td>
<p><code class="reqn">d \times npc</code> matrix of estimated eigenfunctions of the functional
covariance, i.e., the FPC basis functions for levels 1 and 2.</p>
</td></tr> <tr><td><code>evalues</code></td>
<td>
<p>estimated
eigenvalues of the covariance operator, i.e., variances of FPC scores for levels 1 and 2.</p>
</td></tr>
<tr><td><code>npc</code></td>
<td>
<p>number of FPCs: either the supplied <code>npc</code>, or the minimum
number of basis functions needed to explain proportion <code>pve</code> of the
variance in the observed curves for levels 1 and 2.</p>
</td></tr> <tr><td><code>sigma2</code></td>
<td>
<p>estimated measurement error
variance.</p>
</td></tr> <tr><td><code>eta</code></td>
<td>
<p>the estimated visit specific shifts from overall mean.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Julia Wrobel <a href="mailto:jw3134@cumc.columbia.edu">jw3134@cumc.columbia.edu</a>, Jeff Goldsmith <a href="mailto:jeff.goldsmith@columbia.edu">jeff.goldsmith@columbia.edu</a>, and Chongzhi Di
</p>


<h3>References</h3>

<p>Di, C., Crainiceanu, C., Caffo, B., and Punjabi, N. (2009).
Multilevel functional principal component analysis. <em>Annals of Applied
Statistics</em>, 3, 458&ndash;488.
</p>
<p>Di, C., Crainiceanu, C., Caffo, B., and Punjabi, N. (2014).
Multilevel sparse functional principal component analysis. <em>Stat</em>, 3, 126&ndash;143.
</p>
<p>Goldsmith, J., Greven, S., and Crainiceanu, C. (2013). Corrected confidence
bands for functional data using principal components. <em>Biometrics</em>,
69(1), 41&ndash;51.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
 data(DTI)
 DTI = subset(DTI, Nscans &lt; 6)  ## example where all subjects have 6 or fewer visits
 id  = DTI$ID
 Y = DTI$cca
 mfpca.DTI =  mfpca.sc(Y=Y, id = id, twoway = TRUE)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='model.matrix.pffr'>Obtain model matrix for a pffr fit</h2><span id='topic+model.matrix.pffr'></span>

<h3>Description</h3>

<p>Obtain model matrix for a pffr fit
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pffr'
model.matrix(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="model.matrix.pffr_+3A_object">object</code></td>
<td>
<p>a fitted <code>pffr</code>-object</p>
</td></tr>
<tr><td><code id="model.matrix.pffr_+3A_...">...</code></td>
<td>
<p>other arguments, passed to <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A model matrix
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>

<hr>
<h2 id='ols_cs'>Cross-sectional FoSR using GLS</h2><span id='topic+ols_cs'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for cross-sectional data.
This function estimates model parameters using GLS: first, an OLS estimate of 
spline coefficients is estimated; second, the residual covariance is estimated
using an FPC decomposition of the OLS residual curves; finally, a GLS estimate
of spline coefficients is estimated. Although this is in the 'BayesFoSR' package,
there is nothing Bayesian about this FoSR.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ols_cs(formula, data = NULL, Kt = 5, basis = "bs", verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ols_cs_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="ols_cs_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the 
variables in the model. If not found in data, the variables are taken from 
environment(formula), typically the environment from which the function is 
called.</p>
</td></tr>
<tr><td><code id="ols_cs_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="ols_cs_+3A_basis">basis</code></td>
<td>
<p>basis type; options are &quot;bs&quot; for b-splines and &quot;pbs&quot; for periodic
b-splines</p>
</td></tr>
<tr><td><code id="ols_cs_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='pco_predict_preprocess'>Make predictions using pco basis terms</h2><span id='topic+pco_predict_preprocess'></span>

<h3>Description</h3>

<p>This function performs the necessary preprocessing for making predictions
with <code><a href="mgcv.html#topic+gam">gam</a></code> models that include <code><a href="#topic+pco">pco</a></code> basis
terms. The function <code>pco_predict_preprocess</code> builds a <code>data.frame</code>
(or augments an existing one) to be used with the usual <code>predict</code>
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pco_predict_preprocess(model, newdata = NULL, dist_list)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pco_predict_preprocess_+3A_model">model</code></td>
<td>
<p>a fitted <code><a href="mgcv.html#topic+gam">gam</a></code> model with at least one term of
class &quot;<code>pco.smooth</code>&quot;.</p>
</td></tr>
<tr><td><code id="pco_predict_preprocess_+3A_newdata">newdata</code></td>
<td>
<p>data frame including the new values for any
non-<code><a href="#topic+pco">pco</a></code> terms in the original fit. If there were none, this
can be left as <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="pco_predict_preprocess_+3A_dist_list">dist_list</code></td>
<td>
<p>a list of <code>n</code> <code class="reqn">\times</code> <code>n*</code> matrices, one per
<code><a href="#topic+pco">pco</a></code> term in the model, giving the distances from the
<code>n*</code> prediction points to the <code>n</code> design points (original
observations). List entry names should correspond to the names of the terms
in the model (e.g., if the model includes a <code>s(x)</code> term,
<code>dist_list</code> must include an element named &quot;<code>x</code>&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Models with <code><a href="#topic+pco">pco</a></code> basis terms are fitted by inputting distances
among the observations and then regressing (with a ridge penalty) on leading
principal coordinates arising from these distances. To perform prediction, we
must input the distances from the new data points to the original points, and
then &quot;insert&quot; the former into the principal coordinate space by the
interpolation method of Gower (1968) (see also Miller, 2012).
</p>
<p>An example of how to use this function in practice is shown in
<code><a href="#topic+smooth.construct.pco.smooth.spec">smooth.construct.pco.smooth.spec</a></code>.
</p>


<h3>Value</h3>

<p>a <code><a href="base.html#topic+data.frame">data.frame</a></code> with the coordinates for the new data
inserted into principal coordinate space, in addition to the supplied
<code>newdata</code> if this was non-<code>NULL</code>. This can be used as the
<code>newdata</code> argument in a call to <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>.
</p>


<h3>Author(s)</h3>

<p>David L Miller
</p>


<h3>References</h3>

<p>Gower, J. C. (1968). Adding a point to vector diagrams in
multivariate analysis. Biometrika, 55(3), 582-585.
</p>
<p>Miller, D. L. (2012). On smooth models for complex domains and distances. PhD
dissertation, Department of Mathematical Sciences, University of Bath.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+smooth.construct.pco.smooth.spec">smooth.construct.pco.smooth.spec</a></code>
</p>

<hr>
<h2 id='pcre'>pffr-constructor for functional principal component-based functional random intercepts.</h2><span id='topic+pcre'></span>

<h3>Description</h3>

<p>pffr-constructor for functional principal component-based functional random intercepts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcre(id, efunctions, evalues, yind, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcre_+3A_id">id</code></td>
<td>
<p>grouping variable a factor</p>
</td></tr>
<tr><td><code id="pcre_+3A_efunctions">efunctions</code></td>
<td>
<p>matrix of eigenfunction evaluations on gridpoints <code>yind</code> (&lt;length of <code>yind</code>&gt; x &lt;no. of used eigenfunctions&gt;)</p>
</td></tr>
<tr><td><code id="pcre_+3A_evalues">evalues</code></td>
<td>
<p>eigenvalues associated with <code>efunctions</code></p>
</td></tr>
<tr><td><code id="pcre_+3A_yind">yind</code></td>
<td>
<p>vector of gridpoints on which <code>efunctions</code> are evaluated.</p>
</td></tr>
<tr><td><code id="pcre_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list used internally for constructing an appropriate call to <code>mgcv::gam</code>
</p>


<h3>Details</h3>

<p>Fits functional random intercepts <code class="reqn">B_i(t)</code> for a grouping variable <code>id</code>
using as a basis the functions <code class="reqn">\phi_m(t)</code> in <code>efunctions</code> with variances <code class="reqn">\lambda_m</code> in <code>evalues</code>:
<code class="reqn">B_i(t) \approx \sum_m^M \phi_m(t)\delta_{im}</code> with
independent <code class="reqn">\delta_{im} \sim N(0, \sigma^2\lambda_m)</code>, where <code class="reqn">\sigma^2</code>
is (usually) estimated and controls the overall contribution of the <code class="reqn">B_i(t)</code> while the relative importance
of the <code class="reqn">M</code> basisfunctions is controlled by the supplied variances <code>lambda_m</code>.
Can be used to model smooth residuals if <code>id</code> is simply an index of observations.
Differing from scalar random effects in <code>mgcv</code>, these effects are estimated under a &quot;sum-to-zero-for-each-t&quot;-constraint &ndash;
specifically <code class="reqn">\sum_i \hat b_i(t) = 0</code> (not <code class="reqn">\sum_i n_i \hat b_i(t) = 0</code>) where $n_i$ is the number of observed curves for
subject i, so the intercept curve for models with unbalanced group sizes no longer corresponds to the global mean function.
</p>
<p><code>efunctions</code> and <code>evalues</code> are typically eigenfunctions and eigenvalues of an estimated
covariance operator for the functional process to be modeled, i.e., they are
a functional principal components basis.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
residualfunction &lt;- function(t){
#generate quintic polynomial error functions
    drop(poly(t, 5)%*%rnorm(5, sd=sqrt(2:6)))
}
# generate data Y(t) = mu(t) + E(t) + white noise
set.seed(1122)
n &lt;- 50
T &lt;- 30
t &lt;- seq(0,1, l=T)
# E(t): smooth residual functions
E &lt;- t(replicate(n, residualfunction(t)))
int &lt;- matrix(scale(3*dnorm(t, m=.5, sd=.5) - dbeta(t, 5, 2)), byrow=T, n, T)
Y &lt;- int + E + matrix(.2*rnorm(n*T), n, T)
data &lt;- data.frame(Y=I(Y))
# fit model under independence assumption:
summary(m0 &lt;- pffr(Y ~ 1, yind=t, data=data))
# get first 5 eigenfunctions of residual covariance
# (i.e. first 5 functional PCs of empirical residual process)
Ehat &lt;- resid(m0)
fpcE &lt;- fpca.sc(Ehat, npc=5)
efunctions &lt;- fpcE$efunctions
evalues &lt;- fpcE$evalues
data$id &lt;- factor(1:nrow(data))
# refit model with fpc-based residuals
m1 &lt;- pffr(Y ~ 1 + pcre(id=id, efunctions=efunctions, evalues=evalues, yind=t), yind=t, data=data)
t1 &lt;- predict(m1, type="terms")
summary(m1)
#compare squared errors
mean((int-fitted(m0))^2)
mean((int-t1[[1]])^2)
mean((E-t1[[2]])^2)
# compare fitted &amp; true smooth residuals and fitted intercept functions:
layout(t(matrix(1:4,2,2)))
matplot(t(E), lty=1, type="l", ylim=range(E, t1[[2]]))
matplot(t(t1[[2]]), lty=1, type="l", ylim=range(E, t1[[2]]))
plot(m1, select=1, main="m1", ylim=range(Y))
lines(t, int[1,], col=rgb(1,0,0,.5))
plot(m0, select=1, main="m0", ylim=range(Y))
lines(t, int[1,], col=rgb(1,0,0,.5))

## End(Not run)
</code></pre>

<hr>
<h2 id='peer'>Construct a PEER regression term in a <code>pfr</code> formula</h2><span id='topic+peer'></span>

<h3>Description</h3>

<p>Defines a term <code class="reqn">\int_{T}\beta(t)X_i(t)dt</code> for inclusion in a
<code><a href="#topic+pfr">pfr</a></code> formula, where <code class="reqn">\beta(t)</code> is estimated with
structured penalties (Randolph et al., 2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>peer(
  X,
  argvals = NULL,
  pentype = "RIDGE",
  Q = NULL,
  phia = 10^3,
  L = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="peer_+3A_x">X</code></td>
<td>
<p>functional predictors, typically expressed as an <code>N</code> by <code>J</code> matrix,
where <code>N</code> is the number of columns and <code>J</code> is the number of
evaluation points. May include missing/sparse functions, which are
indicated by <code>NA</code> values. Alternatively, can be an object of class
<code>"fd"</code>; see <code><a href="fda.html#topic+fd">fd</a></code>.</p>
</td></tr>
<tr><td><code id="peer_+3A_argvals">argvals</code></td>
<td>
<p>indices of evaluation of <code>X</code>, i.e. <code class="reqn">(t_{i1},.,t_{iJ})</code> for
subject <code class="reqn">i</code>. May be entered as either a length-<code>J</code> vector, or as
an <code>N</code> by <code>J</code> matrix. Indices may be unequally spaced. Entering
as a matrix allows for different observations times for each subject. If
<code>NULL</code>, defaults to an equally-spaced grid between 0 or 1 (or within
<code>X$basis$rangeval</code> if <code>X</code> is a <code>fd</code> object.)</p>
</td></tr>
<tr><td><code id="peer_+3A_pentype">pentype</code></td>
<td>
<p>the type of penalty to apply, one of <code>"RIDGE"</code>, <code>"D"</code>,
<code>"DECOMP"</code>, or <code>"USER"</code>; see Details.</p>
</td></tr>
<tr><td><code id="peer_+3A_q">Q</code></td>
<td>
<p>matrix <code class="reqn">Q</code> used for <code>pentype="DECOMP"</code>; see Details.</p>
</td></tr>
<tr><td><code id="peer_+3A_phia">phia</code></td>
<td>
<p>scalar <code class="reqn">a</code> used for <code>pentype="DECOMP"</code>; see Details.</p>
</td></tr>
<tr><td><code id="peer_+3A_l">L</code></td>
<td>
<p>user-supplied penalty matrix for <code>pentype="USER"</code>; see
Details.</p>
</td></tr>
<tr><td><code id="peer_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code>lf</code> (and then
possibly <code>s</code>). Arguments processed by <code>lf</code> include, for example,
<code>integration</code> for specifying the method of numerical integration.
Arguments processed by <code>s</code>
include information related to basis and penalization, such as <code>m</code>
for specifying the order of the difference penalty; See Details.
<code>xt</code>-argument is not allowed for <code>peer</code>-terms and will cause
an error.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>peer</code> is a wrapper for <code><a href="#topic+lf">lf</a></code>, which defines linear
functional predictors for any type of basis. It simply calls <code>lf</code>
with the appropriate options for the <code>peer</code> basis and penalty construction.
The type of penalty is determined by the <code>pentype</code> argument. There
are four types of penalties available:
</p>

<ol>
<li> <p><code>pentype=="RIDGE"</code> for a ridge penalty, the default
</p>
</li>
<li> <p><code>pentype=="D"</code> for a difference penalty. The order of the
difference penalty may be specified by supplying an <code>m</code> argument
(default is 2).
</p>
</li>
<li> <p><code>pentype=="DECOMP"</code> for a decomposition-based penalty,
<code class="reqn">bP_Q + a(I-P_Q)</code>, where <code class="reqn">P_Q = Q^t(QQ^t)^{-1}Q</code>. The <code class="reqn">Q</code>
matrix must be specified by <code>Q</code>, and the scalar <code class="reqn">a</code> by
<code>phia</code>. The number of columns of <code>Q</code> must be equal to the
length of the data. Each row represents a basis function where the
functional predictor is expected to lie, according to prior belief.
</p>
</li>
<li> <p><code>pentype=="USER"</code> for a user-specified penalty matrix,
supplied by the <code>L</code> argument.
</p>
</li></ol>

<p>The original stand-alone implementation by Madan Gopal Kundu is available in
<code><a href="#topic+peer_old">peer_old</a></code>.
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar <a href="mailto:JGellar@mathematica-mpr.com">JGellar@mathematica-mpr.com</a> and
Madan Gopal Kundu <a href="mailto:mgkundu@iupui.edu">mgkundu@iupui.edu</a>
</p>


<h3>References</h3>

<p>Randolph, T. W., Harezlak, J, and Feng, Z. (2012). Structured penalties for
functional linear models - partially empirical eigenvectors for regression.
<em>Electronic Journal of Statistics</em>, 6, 323-353.
</p>
<p>Kundu, M. G., Harezlak, J., and Randolph, T. W. (2012). Longitudinal
functional models with structured penalties (arXiv:1211.4763 [stat.AP]).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pfr">pfr</a></code>, <code><a href="#topic+smooth.construct.peer.smooth.spec">smooth.construct.peer.smooth.spec</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
#------------------------------------------------------------------------
# Example 1: Estimation with D2 penalty
#------------------------------------------------------------------------

data(DTI)
DTI = DTI[which(DTI$case == 1),]
fit.D2 = pfr(pasat ~ peer(cca, pentype="D"), data=DTI)
plot(fit.D2)

#------------------------------------------------------------------------
# Example 2: Estimation with structured penalty (need structural
#            information about regression function or predictor function)
#------------------------------------------------------------------------

data(PEER.Sim)
data(Q)
PEER.Sim1&lt;- subset(PEER.Sim, t==0)

# Setting k to max possible value
fit.decomp &lt;- pfr(Y ~ peer(W, pentype="Decomp", Q=Q, k=99), data=PEER.Sim1)
plot(fit.decomp)

## End(Not run)


</code></pre>

<hr>
<h2 id='peer_old'>Functional Models with Structured Penalties</h2><span id='topic+peer_old'></span>

<h3>Description</h3>

<p>Implements functional model with structured penalties (Randolph et al.,
2012) with scalar outcome and single functional predictor through mixed
model equivalence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>peer_old(
  Y,
  funcs,
  argvals = NULL,
  pentype = "Ridge",
  L.user = NULL,
  Q = NULL,
  phia = 10^3,
  se = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="peer_old_+3A_y">Y</code></td>
<td>
<p>vector of all outcomes</p>
</td></tr>
<tr><td><code id="peer_old_+3A_funcs">funcs</code></td>
<td>
<p>matrix containing observed functional predictors as rows. Rows
with <code>NA</code> and <code>Inf</code> values will be deleted.</p>
</td></tr>
<tr><td><code id="peer_old_+3A_argvals">argvals</code></td>
<td>
<p>matrix (or vector) of indices of evaluations of <code class="reqn">X_i(t)</code>; i.e. a matrix with
<em>i</em>th row <code class="reqn">(t_{i1},.,t_{iJ})</code></p>
</td></tr>
<tr><td><code id="peer_old_+3A_pentype">pentype</code></td>
<td>
<p>type of penalty. It can be either decomposition based
penalty (<code>DECOMP</code>) or ridge (<code>RIDGE</code>) or second-order difference
penalty (<code>D2</code>) or any user defined penalty (<code>USER</code>). For
decomposition based penalty user need to specify Q matrix in Q argument
(see details). For user defined penalty user need to specify L matrix in L
argument (see details). For Ridge and second-order difference penalty,
specification for arguments L and Q will be ignored. Default is
<code>RIDGE</code>.</p>
</td></tr>
<tr><td><code id="peer_old_+3A_l.user">L.user</code></td>
<td>
<p>penalty matrix. Need to be specified with
<code>pentype='USER'</code>. Number of columns need to be equal with number of
columns of matrix specified to <code>funcs</code>. Each row represents a
constraint on functional predictor. This argument will be ignored when
value of <code>pentype</code> is other than <code>USER</code>.</p>
</td></tr>
<tr><td><code id="peer_old_+3A_q">Q</code></td>
<td>
<p>Q matrix to derive decomposition based penalty. Need to be
specified with <code>pentype='DECOMP'</code>. Number of columns need to be equal
with number of columns of matrix specified to <code>funcs</code>. Each row
represents a basis function where functional predictor is expected lie
according to prior belief. This argument will be ignored when value of
<code>pentype</code> is other than <code>DECOMP</code>.</p>
</td></tr>
<tr><td><code id="peer_old_+3A_phia">phia</code></td>
<td>
<p>Scalar value of a in decomposition based penalty. Need to be
specified with <code>pentype='DECOMP'</code>.</p>
</td></tr>
<tr><td><code id="peer_old_+3A_se">se</code></td>
<td>
<p>logical; calculate standard error when <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="peer_old_+3A_...">...</code></td>
<td>
<p>additional arguments passed to the <code><a href="nlme.html#topic+lme">lme</a></code> function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If there are any missing or infinite values in <code>Y</code>, and <code>funcs</code>,
the corresponding row (or observation) will be dropped. Neither <code>Q</code>
nor <code>L</code> may contain missing or infinite values.
</p>
<p><code>peer_old()</code> fits the following model:
</p>
<p><code class="reqn">y_i=\int {W_i(s)\gamma(s) ds} + \epsilon_i</code>
</p>
<p>where <code class="reqn">\epsilon_i ~ N(0,\sigma^2)</code>.  For all the observations,
predictor function <code class="reqn">W_i(s)</code> is evaluated at K sampling points. Here,
<code class="reqn">\gamma (s)</code> denotes the regression function.
</p>
<p>Values of <code class="reqn">y_i</code> and <code class="reqn">W_i(s)</code>are passed through argument Y and
funcs, respectively. Number of elements or rows in <code>Y</code> and
<code>funcs</code> need to be equal.
</p>
<p>The estimate of regression functions <code class="reqn">\gamma(s)</code> is obtained as
penalized estimated. Following 3 types of penalties can be used:
</p>
<p>i.  Ridge: <code class="reqn">I_K</code>
</p>
<p>ii.  Second-order difference: [<code class="reqn">d_{i,j}</code>] with <code class="reqn">d_{i,i} = d_{i,i+2}
= 1, d_{i,i+1} = -2</code>, otherwise <code class="reqn">d_{i,i} =0</code>
</p>
<p>iii. Decomposition based penalty: <code class="reqn">bP_Q+a(I-P_Q)</code> where <code class="reqn">P_Q=
Q^T(QQ^T)^{-1}Q</code>
</p>
<p>For Decomposition based penalty user need to specify
<code>pentype='DECOMP'</code> and associated Q matrix need to be passed through
<code>Q</code> argument.
</p>
<p>Alternatively, user can pass directly penalty matrix through argument L.
For this user need to specify <code>pentype='USER'</code> and associated L matrix
need to be passed through <code>L</code> argument.
</p>
<p>Default penalty is Ridge penalty and user needs to specify <code>RIDGE</code>.
For second-order difference penalty, user needs to specify <code>D2</code>.
</p>


<h3>Value</h3>

<p>a list containing: </p>
<table>
<tr><td><code>fit</code></td>
<td>
<p>result of the call to <code>lme</code></p>
</td></tr>
<tr><td><code>fitted.vals</code></td>
<td>
<p>predicted outcomes</p>
</td></tr> <tr><td><code>Gamma</code></td>
<td>
<p>estimates with
standard error for regression function</p>
</td></tr> <tr><td><code>GammaHat</code></td>
<td>
<p>estimates of
regression function</p>
</td></tr> <tr><td><code>se.Gamma</code></td>
<td>
<p>standard error associated with
<code>GammaHat</code></p>
</td></tr> <tr><td><code>AIC</code></td>
<td>
<p>AIC value of fit (smaller is better)</p>
</td></tr>
<tr><td><code>BIC</code></td>
<td>
<p>BIC value of fit (smaller is better)</p>
</td></tr>
<tr><td><code>logLik</code></td>
<td>
<p>(restricted) log-likelihood at convergence</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>estimates of smoothing parameter</p>
</td></tr> <tr><td><code>N</code></td>
<td>
<p>number of
subjects</p>
</td></tr> <tr><td><code>K</code></td>
<td>
<p>number of Sampling points in functional predictor</p>
</td></tr>
<tr><td><code>sigma</code></td>
<td>
<p>estimated within-group error standard deviation.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Madan Gopal Kundu <a href="mailto:mgkundu@iupui.edu">mgkundu@iupui.edu</a>
</p>


<h3>References</h3>

<p>Kundu, M. G., Harezlak, J., and Randolph, T. W. (2012).
Longitudinal functional models with structured penalties (arXiv:1211.4763
[stat.AP]).
</p>
<p>Randolph, T. W., Harezlak, J, and Feng, Z. (2012). Structured penalties for
functional linear models - partially empirical eigenvectors for regression.
<em>Electronic Journal of Statistics</em>, 6, 323&ndash;353.
</p>


<h3>See Also</h3>

<p><code>lpeer</code>, <code>plot.peer</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
#------------------------------------------------------------------------
# Example 1: Estimation with D2 penalty
#------------------------------------------------------------------------

## Load Data
data(DTI)

## Extract values for arguments for peer() from given data
cca = DTI$cca[which(DTI$case == 1),]
DTI = DTI[which(DTI$case == 1),]

##1.1 Fit the model
fit.cca.peer1 = peer(Y=DTI$pasat, funcs = cca, pentype='D2', se=TRUE)
plot(fit.cca.peer1)

#------------------------------------------------------------------------
# Example 2: Estimation with structured penalty (need structural
#            information about regression function or predictor function)
#------------------------------------------------------------------------

## Load Data
data(PEER.Sim)

## Extract values for arguments for peer() from given data
PEER.Sim1&lt;- subset(PEER.Sim, t==0)
W&lt;- PEER.Sim1$W
Y&lt;- PEER.Sim1$Y

##Load Q matrix containing structural information
data(Q)

##2.1 Fit the model
Fit1&lt;- peer(Y=Y, funcs=W, pentype='Decomp', Q=Q, se=TRUE)
plot(Fit1)

## End(Not run)

</code></pre>

<hr>
<h2 id='PEER.Sim'>Simulated longitudinal data with functional predictor and scalar response,
and structural information associated with predictor function</h2><span id='topic+PEER.Sim'></span><span id='topic+Q'></span>

<h3>Description</h3>

<p><code>PEER.Sim</code> contains simulated observations from 100 subjects, each
observed at 4 distinct timepoints. At each timepoint bumpy predictor
profile is generated randomly and the scalar response variable is generated
considering a time-varying regression function and subject intercept.
Accompanying the functional predictor and scalar response are the subject
ID numbers and time of measurements.
</p>


<h3>Format</h3>

<p>The data frame <code>PEER.Sim</code> is made up of subject ID
number(<code>id</code>), subject-specific time of measurement (<code>t</code>),
functional predictor profile (<code>W.1-W.100</code>) and scalar response
(<code>Y</code>)
</p>


<h3>Details</h3>

<p><code>Q</code> represents the 7 x 100 matrix where each row provides structural
information about the functional predictor profile for data
<code>PEER.Sim</code>. For specific details about the simulation and Q matrix,
please refer to Kundu et. al. (2012).
</p>


<h3>References</h3>

<p>Kundu, M. G., Harezlak, J., and Randolph, T. W. (2012).
Longitudinal functional models with structured penalties. (please contact
J. Harezlak at <a href="mailto:harezlak@iupui.edu">harezlak@iupui.edu</a>)
</p>

<hr>
<h2 id='pffr'>Penalized flexible functional regression</h2><span id='topic+pffr'></span>

<h3>Description</h3>

<p>Implements additive regression for functional and scalar covariates and
functional responses. This function is a wrapper for <code>mgcv</code>'s
<code><a href="mgcv.html#topic+gam">gam</a></code> and its siblings to fit models of the general form
<br /> <code class="reqn">E(Y_i(t)) = g(\mu(t) + \int X_i(s)\beta(s,t)ds + f(z_{1i}, t) +
f(z_{2i}) + z_{3i} \beta_3(t) + \dots )</code><br /> with a functional (but not
necessarily continuous) response <code class="reqn">Y(t)</code>, response function <code class="reqn">g</code>,
(optional) smooth intercept <code class="reqn">\mu(t)</code>, (multiple) functional covariates
<code class="reqn">X(t)</code> and scalar covariates <code class="reqn">z_1</code>, <code class="reqn">z_2</code>, etc.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pffr(
  formula,
  yind,
  data = NULL,
  ydata = NULL,
  algorithm = NA,
  method = "REML",
  tensortype = c("ti", "t2"),
  bs.yindex = list(bs = "ps", k = 5, m = c(2, 1)),
  bs.int = list(bs = "ps", k = 20, m = c(2, 1)),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pffr_+3A_formula">formula</code></td>
<td>
<p>a formula with special terms as for <code><a href="mgcv.html#topic+gam">gam</a></code>,
with additional special terms <code><a href="#topic+ff">ff</a>(), <a href="#topic+sff">sff</a>(),
<a href="#topic+ffpc">ffpc</a>(), <a href="#topic+pcre">pcre</a>()</code> and <code>c()</code>.</p>
</td></tr>
<tr><td><code id="pffr_+3A_yind">yind</code></td>
<td>
<p>a vector with length equal to the number of columns of the matrix
of functional responses giving the vector of evaluation points <code class="reqn">(t_1,
\dots ,t_{G})</code>. If not supplied, <code>yind</code> is set to
<code>1:ncol(&lt;response&gt;)</code>.</p>
</td></tr>
<tr><td><code id="pffr_+3A_data">data</code></td>
<td>
<p>an (optional) <code>data.frame</code> containing the data. Can also be
a named list for regular data. Functional covariates have to be supplied as
&lt;no. of observations&gt; by &lt;no. of evaluations&gt; matrices, i.e. each row is
one functional observation.</p>
</td></tr>
<tr><td><code id="pffr_+3A_ydata">ydata</code></td>
<td>
<p>an (optional) <code>data.frame</code> supplying functional responses
that are not observed on a regular grid. See Details.</p>
</td></tr>
<tr><td><code id="pffr_+3A_algorithm">algorithm</code></td>
<td>
<p>the name of the function used to estimate the model.
Defaults to <code><a href="mgcv.html#topic+gam">gam</a></code> if the matrix of functional responses
has less than <code>2e5</code> data points and to <code><a href="mgcv.html#topic+bam">bam</a></code> if not.
<code>'<a href="mgcv.html#topic+gamm">gamm</a>'</code>, <code>'<a href="gamm4.html#topic+gamm4">gamm4</a>'</code> and
<code>'<a href="mgcv.html#topic+jagam">jagam</a>'</code> are valid options as well. See Details for
<code>'<a href="gamm4.html#topic+gamm4">gamm4</a>'</code> and <code>'<a href="mgcv.html#topic+jagam">jagam</a>'</code>.</p>
</td></tr>
<tr><td><code id="pffr_+3A_method">method</code></td>
<td>
<p>Defaults to <code>"REML"</code>-estimation, including of unknown
scale. If <code>algorithm="bam"</code>, the default is switched to
<code>"fREML"</code>. See <code><a href="mgcv.html#topic+gam">gam</a></code> and <code><a href="mgcv.html#topic+bam">bam</a></code> for
details.</p>
</td></tr>
<tr><td><code id="pffr_+3A_tensortype">tensortype</code></td>
<td>
<p>which typ of tensor product splines to use. One of
&quot;<code><a href="mgcv.html#topic+ti">ti</a></code>&quot; or &quot;<code><a href="mgcv.html#topic+t2">t2</a></code>&quot;, defaults to
<code>ti</code>. <code>t2</code>-type terms do not enforce the more suitable special
constraints for functional regression, see Details.</p>
</td></tr>
<tr><td><code id="pffr_+3A_bs.yindex">bs.yindex</code></td>
<td>
<p>a named (!) list giving the parameters for spline bases on
the index of the functional response. Defaults to <code>list(bs="ps", k=5,
m=c(2, 1))</code>, i.e. 5 cubic B-splines bases with first order difference
penalty.</p>
</td></tr>
<tr><td><code id="pffr_+3A_bs.int">bs.int</code></td>
<td>
<p>a named (!) list giving the parameters for the spline basis for
the global functional intercept. Defaults to <code>list(bs="ps", k=20,
m=c(2, 1))</code>, i.e. 20 cubic B-splines bases with first order difference
penalty.</p>
</td></tr>
<tr><td><code id="pffr_+3A_...">...</code></td>
<td>
<p>additional arguments that are valid for <code><a href="mgcv.html#topic+gam">gam</a></code>,
<code><a href="mgcv.html#topic+bam">bam</a></code>, <code>'<a href="gamm4.html#topic+gamm4">gamm4</a>'</code> or
<code>'<a href="mgcv.html#topic+jagam">jagam</a>'</code>. <code>subset</code> is not implemented.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted <code>pffr</code>-object, which is a
<code><a href="mgcv.html#topic+gam">gam</a></code>-object with some additional information in an
<code>pffr</code>-entry. If <code>algorithm</code> is <code>"gamm"</code> or <code>"gamm4"</code>,
only the <code>$gam</code> part of the returned list is modified in this way.<br />
Available methods/functions to postprocess fitted models:
<code><a href="#topic+summary.pffr">summary.pffr</a></code>, <code><a href="#topic+plot.pffr">plot.pffr</a></code>,
<code><a href="#topic+coef.pffr">coef.pffr</a></code>, <code><a href="#topic+fitted.pffr">fitted.pffr</a></code>,
<code><a href="#topic+residuals.pffr">residuals.pffr</a></code>, <code><a href="#topic+predict.pffr">predict.pffr</a></code>,
<code><a href="#topic+model.matrix.pffr">model.matrix.pffr</a></code>,  <code><a href="#topic+qq.pffr">qq.pffr</a></code>,
<code><a href="#topic+pffr.check">pffr.check</a></code>.<br /> If <code>algorithm</code> is <code>"jagam"</code>, only
the location of the model file and the usual
<code><a href="mgcv.html#topic+jagam">jagam</a></code>-object are returned, you have to run the sampler
yourself.<br />
</p>


<h3>Details</h3>

<p>The routine can estimate </p>
 <ol>
<li><p> linear
functional effects of scalar (numeric or factor) covariates that vary
smoothly over <code class="reqn">t</code> (e.g. <code class="reqn">z_{1i} \beta_1(t)</code>, specified as
<code>~z1</code>), </p>
</li>
<li><p> nonlinear, and possibly multivariate functional effects
of (one or multiple) scalar covariates <code class="reqn">z</code> that vary smoothly over the
index <code class="reqn">t</code> of <code class="reqn">Y(t)</code> (e.g. <code class="reqn">f(z_{2i}, t)</code>, specified in the
<code>formula</code> simply as <code>~s(z2)</code>) </p>
</li>
<li><p> (nonlinear) effects of scalar
covariates that are constant over <code class="reqn">t</code> (e.g. <code class="reqn">f(z_{3i})</code>, specified
as <code>~c(s(z3))</code>, or <code class="reqn">\beta_3 z_{3i}</code>, specified as <code>~c(z3)</code>),
</p>
</li>
<li><p> function-on-function regression terms (e.g. <code class="reqn">\int
  X_i(s)\beta(s,t)ds</code>, specified as <code>~ff(X, yindex=t, xindex=s)</code>, see
<code><a href="#topic+ff">ff</a></code>). Terms given by <code><a href="#topic+sff">sff</a></code> and <code><a href="#topic+ffpc">ffpc</a></code>
provide nonlinear and FPC-based effects of functional covariates,
respectively. </p>
</li>
<li><p> concurrent effects of functional covariates <code>X</code>
measured on the same grid as the response  are specified as follows:
<code>~s(x)</code> for a smooth, index-varying effect <code class="reqn">f(X(t),t)</code>, <code>~x</code>
for a linear index-varying effect <code class="reqn">X(t)\beta(t)</code>, <code>~c(s(x))</code> for a
constant nonlinear effect <code class="reqn">f(X(t))</code>, <code>~c(x)</code> for a constant linear
effect <code class="reqn">X(t)\beta</code>. </p>
</li>
<li><p> Smooth functional random intercepts
<code class="reqn">b_{0g(i)}(t)</code> for a grouping variable <code>g</code> with levels <code class="reqn">g(i)</code>
can be specified via <code>~s(g, bs="re")</code>), functional random slopes
<code class="reqn">u_i b_{1g(i)}(t)</code> in a numeric variable <code>u</code> via <code>~s(g, u,
  bs="re")</code>). Scheipl, Staicu, Greven (2013) contains code examples for
modeling correlated functional random intercepts using
<code><a href="mgcv.html#topic+mrf">mrf</a></code>-terms. </p>
</li></ol>
<p> Use the <code>c()</code>-notation to denote
model terms that are constant over the index of the functional response.<br />
</p>
<p>Internally, univariate smooth terms without a <code>c()</code>-wrapper are
expanded into bivariate smooth terms in the original covariate and the
index of the functional response. Bivariate smooth terms (<code>s(), te()</code>
or <code>t2()</code>) without a <code>c()</code>-wrapper are expanded into trivariate
smooth terms in the original covariates and the index of the functional
response. Linear terms for scalar covariates or categorical covariates are
expanded into varying coefficient terms, varying smoothly over the index of
the functional response. For factor variables, a separate smooth function
with its own smoothing parameter is estimated for each level of the
factor.<br /> <br /> The marginal spline basis used for the index of the the
functional response is specified via the <em>global</em> argument
<code>bs.yindex</code>. If necessary, this can be overriden for any specific term
by supplying a <code>bs.yindex</code>-argument to that term in the formula, e.g.
<code>~s(x, bs.yindex=list(bs="tp", k=7))</code> would yield a tensor product
spline over <code>x</code> and the index of the response in which the marginal
basis for the index of the response are 7 cubic thin-plate spline functions
(overriding the global default for the basis and penalty on the index of
the response given by the <em>global</em> <code>bs.yindex</code>-argument).<br /> Use
<code>~-1 + c(1) + ...</code> to specify a model with only a constant and no
functional intercept. <br />
</p>
<p>The functional covariates have to be supplied as a <code class="reqn">n</code> by &lt;no. of
evaluations&gt; matrices, i.e. each row is one functional observation. For
data on a regular grid, the functional response is supplied in the same
format, i.e. as a matrix-valued entry in <code>data</code>,  which can contain
missing values.<br />
</p>
<p>If the functional responses are <em>sparse or irregular</em> (i.e., not
evaluated on the same evaluation points across all observations), the
<code>ydata</code>-argument can be used to specify the responses: <code>ydata</code>
must be a <code>data.frame</code> with 3 columns called <code>'.obs', '.index',
  '.value'</code> which specify which curve the point belongs to
(<code>'.obs'</code>=<code class="reqn">i</code>), at which <code class="reqn">t</code> it was observed
(<code>'.index'</code>=<code class="reqn">t</code>), and the observed value
(<code>'.value'</code>=<code class="reqn">Y_i(t)</code>). Note that the vector of unique sorted
entries in <code>ydata$.obs</code> must be equal to <code>rownames(data)</code> to
ensure the correct association of entries in <code>ydata</code> to the
corresponding rows of <code>data</code>. For both regular and irregular
functional responses, the model is then fitted with the data in long
format, i.e., for data on a grid the rows of the matrix of the functional
response evaluations <code class="reqn">Y_i(t)</code> are stacked into one long vector and the
covariates are expanded/repeated correspondingly. This means the models get
quite big fairly fast, since the effective number of rows in the design
matrix is number of observations times number of evaluations of <code class="reqn">Y(t)</code>
per observation.<br />
</p>
<p>Note that <code>pffr</code> does not use <code>mgcv</code>'s default identifiability
constraints (i.e., <code class="reqn">\sum_{i,t} \hat f(z_i, x_i, t) = 0</code> or
<code class="reqn">\sum_{i,t} \hat f(x_i, t) = 0</code>) for tensor product terms whose
marginals include the index <code class="reqn">t</code> of the functional response.  Instead,
<code class="reqn">\sum_i \hat f(z_i, x_i, t) = 0</code> for all <code class="reqn">t</code> is enforced, so that
effects varying over <code class="reqn">t</code> can be interpreted as local deviations from
the global functional intercept. This is achieved by using
<code><a href="mgcv.html#topic+ti">ti</a></code>-terms with a suitably modified <code>mc</code>-argument.
Note that this is not possible if <code>algorithm='gamm4'</code> since only
<code>t2</code>-type terms can then be used and these modified constraints are
not available for <code>t2</code>. We recommend using centered scalar covariates
for terms like <code class="reqn">z \beta(t)</code> (<code>~z</code>) and centered functional
covariates with <code class="reqn">\sum_i X_i(t) = 0</code> for all <code class="reqn">t</code> in <code>ff</code>-terms
so that the global functional intercept can be interpreted as the global
mean function.
</p>
<p>The <code>family</code>-argument can be used to specify all of the response
distributions and link functions described in
<code><a href="mgcv.html#topic+family.mgcv">family.mgcv</a></code>. Note that  <code>family = "gaulss"</code> is
treated in a special way: Users can supply the formula for the variance by
supplying a special argument <code>varformula</code>, but this is not modified in
the way that the <code>formula</code>-argument is but handed over to the fitter
directly, so this is for expert use only. If <code>varformula</code> is not
given, <code>pffr</code> will use the parameters from argument <code>bs.int</code> to
define a spline basis along the index of the response, i.e., a smooth
variance function over $t$ for responses $Y(t)$.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl, Sonja Greven
</p>


<h3>References</h3>

<p>Ivanescu, A., Staicu, A.-M., Scheipl, F. and Greven, S. (2015).
Penalized function-on-function regression. Computational Statistics,
30(2):539&ndash;568. <a href="https://biostats.bepress.com/jhubiostat/paper254/">https://biostats.bepress.com/jhubiostat/paper254/</a>
</p>
<p>Scheipl, F., Staicu, A.-M. and Greven, S. (2015). Functional Additive Mixed
Models. Journal of Computational &amp; Graphical Statistics, 24(2): 477&ndash;501.
<a href="https://arxiv.org/abs/1207.5947">https://arxiv.org/abs/1207.5947</a>
</p>
<p>F. Scheipl, J. Gertheiss, S. Greven (2016):  Generalized Functional Additive Mixed Models,
Electronic Journal of Statistics, 10(1), 1455&ndash;1492.
<a href="https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-10/issue-1/Generalized-functional-additive-mixed-models/10.1214/16-EJS1145.full">https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-10/issue-1/Generalized-functional-additive-mixed-models/10.1214/16-EJS1145.full</a>
</p>


<h3>See Also</h3>

<p><code><a href="mgcv.html#topic+smooth.terms">smooth.terms</a></code> for details of <code>mgcv</code> syntax
and available spline bases and penalties.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>###############################################################################
# univariate model:
# Y(t) = f(t)  + \int X1(s)\beta(s,t)ds + eps
set.seed(2121)
data1 &lt;- pffrSim(scenario="ff", n=40)
t &lt;- attr(data1, "yindex")
s &lt;- attr(data1, "xindex")
m1 &lt;- pffr(Y ~ ff(X1, xind=s), yind=t, data=data1)
summary(m1)
plot(m1, pages=1)

## Not run: 
###############################################################################
# multivariate model:
# E(Y(t)) = \beta_0(t)  + \int X1(s)\beta_1(s,t)ds + xlin \beta_3(t) +
#        f_1(xte1, xte2) + f_2(xsmoo, t) + \beta_4 xconst
data2 &lt;- pffrSim(scenario="all", n=200)
t &lt;- attr(data2, "yindex")
s &lt;- attr(data2, "xindex")
m2 &lt;- pffr(Y ~  ff(X1, xind=s) + #linear function-on-function
                xlin  +  #varying coefficient term
                c(te(xte1, xte2)) + #bivariate smooth term in xte1 &amp; xte2, const. over Y-index
                s(xsmoo) + #smooth effect of xsmoo varying over Y-index
                c(xconst), # linear effect of xconst constant over Y-index
        yind=t,
        data=data2)
summary(m2)
plot(m2)
str(coef(m2))
# convenience functions:
preddata &lt;- pffrSim(scenario="all", n=20)
str(predict(m2, newdata=preddata))
str(predict(m2, type="terms"))
cm2 &lt;- coef(m2)
cm2$pterms
str(cm2$smterms, 2)
str(cm2$smterms[["s(xsmoo)"]]$coef)

#############################################################################
# sparse data (80% missing on a regular grid):
set.seed(88182004)
data3 &lt;- pffrSim(scenario=c("int", "smoo"), n=100, propmissing=0.8)
t &lt;- attr(data3, "yindex")
m3.sparse &lt;- pffr(Y ~ s(xsmoo), data=data3$data, ydata=data3$ydata, yind=t)
summary(m3.sparse)
plot(m3.sparse,pages=1)

## End(Not run)
</code></pre>

<hr>
<h2 id='pffr.check'>Some diagnostics for a fitted pffr model</h2><span id='topic+pffr.check'></span>

<h3>Description</h3>

<p>This is simply a wrapper for <code><a href="mgcv.html#topic+gam.check">gam.check</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pffr.check(
  b,
  old.style = FALSE,
  type = c("deviance", "pearson", "response"),
  k.sample = 5000,
  k.rep = 200,
  rep = 0,
  level = 0.9,
  rl.col = 2,
  rep.col = "gray80",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pffr.check_+3A_b">b</code></td>
<td>
<p>a fitted <code><a href="#topic+pffr">pffr</a></code>-object</p>
</td></tr>
<tr><td><code id="pffr.check_+3A_old.style">old.style</code></td>
<td>
<p>If you want old fashioned plots, exactly as in Wood, 2006, set to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="pffr.check_+3A_type">type</code></td>
<td>
<p>type of residuals, see <code><a href="mgcv.html#topic+residuals.gam">residuals.gam</a></code>, used in
all plots.</p>
</td></tr>
<tr><td><code id="pffr.check_+3A_k.sample">k.sample</code></td>
<td>
<p>Above this k testing uses a random sub-sample of data.</p>
</td></tr>
<tr><td><code id="pffr.check_+3A_k.rep">k.rep</code></td>
<td>
<p>how many re-shuffles to do to get p-value for k testing.</p>
</td></tr>
<tr><td><code id="pffr.check_+3A_rep">rep</code></td>
<td>
<p>passed to <code><a href="mgcv.html#topic+qq.gam">qq.gam</a></code> when <code>old.style</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pffr.check_+3A_level">level</code></td>
<td>
<p>passed to <code><a href="mgcv.html#topic+qq.gam">qq.gam</a></code> when <code>old.style</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pffr.check_+3A_rl.col">rl.col</code></td>
<td>
<p>passed to <code><a href="mgcv.html#topic+qq.gam">qq.gam</a></code> when <code>old.style</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pffr.check_+3A_rep.col">rep.col</code></td>
<td>
<p>passed to <code><a href="mgcv.html#topic+qq.gam">qq.gam</a></code> when <code>old.style</code> is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pffr.check_+3A_...">...</code></td>
<td>
<p>extra graphics parameters to pass to plotting functions.</p>
</td></tr>
</table>

<hr>
<h2 id='pffrGLS'>Penalized function-on-function regression with non-i.i.d. residuals</h2><span id='topic+pffrGLS'></span>

<h3>Description</h3>

<p>Implements additive regression for functional and scalar covariates and functional responses.
This function is a wrapper for <code>mgcv</code>'s <code><a href="mgcv.html#topic+gam">gam</a></code> and its siblings to fit models of the general form <br />
<code class="reqn">Y_i(t) = \mu(t) + \int X_i(s)\beta(s,t)ds + f(z_{1i}, t) + f(z_{2i}) + z_{3i} \beta_3(t) + \dots  + E_i(t))</code><br />
with a functional (but not necessarily continuous) response <code class="reqn">Y(t)</code>,
(optional) smooth intercept <code class="reqn">\mu(t)</code>, (multiple) functional covariates <code class="reqn">X(t)</code> and scalar covariates
<code class="reqn">z_1</code>, <code class="reqn">z_2</code>, etc. The residual functions <code class="reqn">E_i(t) \sim GP(0, K(t,t'))</code> are assumed to be i.i.d.
realizations of a Gaussian process. An estimate of the covariance operator <code class="reqn">K(t,t')</code> evaluated on <code>yind</code>
has to be supplied in the <code>hatSigma</code>-argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pffrGLS(
  formula,
  yind,
  hatSigma,
  algorithm = NA,
  method = "REML",
  tensortype = c("te", "t2"),
  bs.yindex = list(bs = "ps", k = 5, m = c(2, 1)),
  bs.int = list(bs = "ps", k = 20, m = c(2, 1)),
  cond.cutoff = 500,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pffrGLS_+3A_formula">formula</code></td>
<td>
<p>a formula with special terms as for <code><a href="mgcv.html#topic+gam">gam</a></code>, with additional special terms <code><a href="#topic+ff">ff</a>()</code> and <code>c()</code>. See <code><a href="#topic+pffr">pffr</a></code>.</p>
</td></tr>
<tr><td><code id="pffrGLS_+3A_yind">yind</code></td>
<td>
<p>a vector with length equal to the number of columns of the matrix of functional responses giving the vector of evaluation points <code class="reqn">(t_1, \dots ,t_{G})</code>.
see <code><a href="#topic+pffr">pffr</a></code></p>
</td></tr>
<tr><td><code id="pffrGLS_+3A_hatsigma">hatSigma</code></td>
<td>
<p>(an estimate of) the within-observation covariance (along the responses' index), evaluated at <code>yind</code>. See Details.</p>
</td></tr>
<tr><td><code id="pffrGLS_+3A_algorithm">algorithm</code></td>
<td>
<p>the name of the function used to estimate the model. Defaults to <code><a href="mgcv.html#topic+gam">gam</a></code> if the matrix of functional responses has less than <code>2e5</code> data points
and to <code><a href="mgcv.html#topic+bam">bam</a></code> if not. &quot;gamm&quot; (see <code><a href="mgcv.html#topic+gamm">gamm</a></code>) and &quot;gamm4&quot; (see <code><a href="gamm4.html#topic+gamm4">gamm4</a></code>) are valid options as well.</p>
</td></tr>
<tr><td><code id="pffrGLS_+3A_method">method</code></td>
<td>
<p>See <code><a href="#topic+pffr">pffr</a></code></p>
</td></tr>
<tr><td><code id="pffrGLS_+3A_tensortype">tensortype</code></td>
<td>
<p>See <code><a href="#topic+pffr">pffr</a></code></p>
</td></tr>
<tr><td><code id="pffrGLS_+3A_bs.yindex">bs.yindex</code></td>
<td>
<p>See <code><a href="#topic+pffr">pffr</a></code></p>
</td></tr>
<tr><td><code id="pffrGLS_+3A_bs.int">bs.int</code></td>
<td>
<p>See <code><a href="#topic+pffr">pffr</a></code></p>
</td></tr>
<tr><td><code id="pffrGLS_+3A_cond.cutoff">cond.cutoff</code></td>
<td>
<p>if the condition number of <code>hatSigma</code> is greater than this,  <code>hatSigma</code> is
made &ldquo;more&rdquo; positive-definite via <code><a href="Matrix.html#topic+nearPD">nearPD</a></code> to ensure a condition number equal to cond.cutoff. Defaults to 500.</p>
</td></tr>
<tr><td><code id="pffrGLS_+3A_...">...</code></td>
<td>
<p>additional arguments that are valid for <code><a href="mgcv.html#topic+gam">gam</a></code> or <code><a href="mgcv.html#topic+bam">bam</a></code>. See <code><a href="#topic+pffr">pffr</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a fitted <code>pffr</code>-object, see <code><a href="#topic+pffr">pffr</a></code>.
</p>


<h3>Details</h3>

<p>Note that <code>hatSigma</code> has to be positive definite. If <code>hatSigma</code> is close to positive <em>semi-</em>definite or badly conditioned,
estimated standard errors become unstable (typically much too small). <code>pffrGLS</code> will try to diagnose this and issue a warning.
The danger is especially big if the number of functional observations is smaller than the number of gridpoints
(i.e, <code>length(yind)</code>), since the raw covariance estimate will not have full rank.<br />
Please see <code><a href="#topic+pffr">pffr</a></code> for details on model specification and
implementation. <br /> THIS IS AN EXPERIMENTAL VERSION AND NOT WELL TESTED YET &ndash; USE AT YOUR OWN RISK.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pffr">pffr</a></code>, <code><a href="#topic+fpca.sc">fpca.sc</a></code>
</p>

<hr>
<h2 id='pffrSim'>Simulate example data for pffr</h2><span id='topic+pffrSim'></span>

<h3>Description</h3>

<p>Simulates example data for <code><a href="#topic+pffr">pffr</a></code> from a variety of terms.
Scenario &quot;all&quot; generates data from a complex multivariate model </p>
<p style="text-align: center;"><code class="reqn">Y_i(t)
= \mu(t) + \int X_{1i}(s)\beta_1(s,t)ds + xlin \beta_3(t) + f(xte1, xte2) +
f(xsmoo, t) + \beta_4 xconst + f(xfactor, t) +  \epsilon_i(t)</code>
</p>
<p>. Scenarios &quot;int&quot;, &quot;ff&quot;, &quot;lin&quot;,
&quot;te&quot;, &quot;smoo&quot;, &quot;const&quot;, &quot;factor&quot;, generate data from simpler models containing only the
respective term(s)  in the model equation given above. Specifying a
vector-valued scenario will generate data from a combination of the
respective terms. Sparse/irregular response trajectories can be generated by
setting <code>propmissing</code> to something greater than 0 (and smaller than 1).
The return object then also includes a <code>ydata</code>-item with the sparsified
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pffrSim(
  scenario = "all",
  n = 100,
  nxgrid = 40,
  nygrid = 60,
  SNR = 10,
  propmissing = 0,
  limits = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pffrSim_+3A_scenario">scenario</code></td>
<td>
<p>see Description</p>
</td></tr>
<tr><td><code id="pffrSim_+3A_n">n</code></td>
<td>
<p>number of observations</p>
</td></tr>
<tr><td><code id="pffrSim_+3A_nxgrid">nxgrid</code></td>
<td>
<p>number of evaluation points of functional covariates</p>
</td></tr>
<tr><td><code id="pffrSim_+3A_nygrid">nygrid</code></td>
<td>
<p>number of evaluation points of the functional response</p>
</td></tr>
<tr><td><code id="pffrSim_+3A_snr">SNR</code></td>
<td>
<p>the signal-to-noise ratio for the generated data: empirical
variance of the additive predictor divided by variance of the errors.</p>
</td></tr>
<tr><td><code id="pffrSim_+3A_propmissing">propmissing</code></td>
<td>
<p>proportion of missing data in the response, default = 0.
See Details.</p>
</td></tr>
<tr><td><code id="pffrSim_+3A_limits">limits</code></td>
<td>
<p>a function that defines an integration range, see
<code><a href="#topic+ff">ff</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>See source code for details.<br />
</p>


<h3>Value</h3>

<p>a named list with the simulated data, and the true components of the
predictor etc as attributes.
</p>

<hr>
<h2 id='pfr'>Penalized Functional Regression</h2><span id='topic+pfr'></span>

<h3>Description</h3>

<p>Implements various approaches to penalized scalar-on-function regression.
These techniques include
Penalized Functional Regression (Goldsmith et al., 2011),
Longitudinal Penalized Functional Regression (Goldsmith, et al., 2012),
Functional Principal Component Regression (Reiss and Ogden, 2007),
Partially Empirical Eigenvectors for Regression (Randolph et al., 2012),
Functional Generalized Additive Models (McLean et al., 2013),
and
Variable-Domain Functional Regression (Gellar et al., 2014).
This function is a wrapper for mgcv's <code><a href="mgcv.html#topic+gam">gam</a></code> and its siblings
to fit models with a scalar (but not necessarily continuous) response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pfr(formula = NULL, fitter = NA, method = "REML", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pfr_+3A_formula">formula</code></td>
<td>
<p>a formula that could contain any of the following special terms:
<code><a href="#topic+lf">lf</a>()</code>, <code><a href="#topic+af">af</a>()</code>, <code><a href="#topic+lf.vd">lf.vd</a>()</code>,
<code><a href="#topic+peer">peer</a>()</code>,  <code><a href="#topic+fpc">fpc</a>()</code>,
or <code><a href="#topic+re">re</a>()</code>; also <code>mgcv</code>'s <code><a href="mgcv.html#topic+s">s</a>()</code>,
<code><a href="mgcv.html#topic+te">te</a>()</code>, or <code><a href="mgcv.html#topic+t2">t2</a>()</code>.</p>
</td></tr>
<tr><td><code id="pfr_+3A_fitter">fitter</code></td>
<td>
<p>the name of the function used to estimate the model. Defaults
to <code><a href="mgcv.html#topic+gam">gam</a></code> if the matrix of functional responses has less than 2e5
data points and to <code><a href="mgcv.html#topic+bam">bam</a></code> if not. &quot;gamm&quot; (see <code><a href="mgcv.html#topic+gamm">gamm</a></code>)
and &quot;gamm4&quot; (see <code><a href="gamm4.html#topic+gamm4">gamm4</a></code>) are valid options as well.</p>
</td></tr>
<tr><td><code id="pfr_+3A_method">method</code></td>
<td>
<p>The smoothing parameter estimation method. Default is
<code>"REML"</code>. For options, see <code><a href="mgcv.html#topic+gam">gam</a></code>.</p>
</td></tr>
<tr><td><code id="pfr_+3A_...">...</code></td>
<td>
<p>additional arguments that are valid for <code><a href="mgcv.html#topic+gam">gam</a></code> or
<code><a href="mgcv.html#topic+bam">bam</a></code>. These include <code>data</code> and <code>family</code> to specify
the input data and outcome family, as well as many options to control the
estimation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A fitted pfr-object, which is a <code><a href="mgcv.html#topic+gam">gam</a></code>-object with some
additional information in a <code>$pfr</code>-element. If fitter is <code>"gamm"</code>
or <code>"gamm4"</code>, only the <code>$gam</code> part of the returned list is
modified in this way.
</p>


<h3>Warning</h3>

<p>Binomial responses should be specified as a numeric vector rather than as a
matrix or a factor.
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar <a href="mailto:JGellar@mathematica-mpr.com">JGellar@mathematica-mpr.com</a>, Mathew W. McLean,
Jeff Goldsmith, and Fabian Scheipl
</p>


<h3>References</h3>

<p>Goldsmith, J., Bobb, J., Crainiceanu, C., Caffo, B., and Reich, D. (2011).
Penalized functional regression. <em>Journal of Computational and Graphical
Statistics</em>, 20(4), 830-851.
</p>
<p>Goldsmith, J., Crainiceanu, C., Caffo, B., and Reich, D. (2012). Longitudinal
penalized functional regression for cognitive outcomes on neuronal tract
measurements. <em>Journal of the Royal Statistical Society: Series C</em>,
61(3), 453-469.
</p>
<p>Reiss, P. T., and Ogden, R. T. (2007). Functional principal component
regression and functional partial least squares. <em>Journal of the
American Statistical Association</em>, 102, 984-996.
</p>
<p>Randolph, T. W., Harezlak, J, and Feng, Z. (2012). Structured penalties for
functional linear models - partially empirical eigenvectors for regression.
<em>Electronic Journal of Statistics</em>, 6, 323-353.
</p>
<p>McLean, M. W., Hooker, G., Staicu, A.-M., Scheipl, F., and
Ruppert, D. (2014). Functional generalized additive models. <em>Journal of
Computational and Graphical Statistics</em>, <b>23 (1)</b>, pp. 249-269.
Available at <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/</a>.
</p>
<p>Gellar, J. E., Colantuoni, E., Needham, D. M., and Crainiceanu, C. M. (2014).
Variable-Domain Functional Regression for Modeling ICU Data. Journal of the
American Statistical Association, 109(508): 1425-1439.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+af">af</a></code>, <code><a href="#topic+lf">lf</a></code>, <code><a href="#topic+lf.vd">lf.vd</a></code>,
<code><a href="#topic+fpc">fpc</a></code>, <code><a href="#topic+peer">peer</a></code>, <code><a href="#topic+re">re</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See lf(), lf.vd(), af(), fpc(), and peer() for additional examples

data(DTI)
DTI1 &lt;- DTI[DTI$visit==1 &amp; complete.cases(DTI),]
par(mfrow=c(1,2))

# Fit model with linear functional term for CCA
fit.lf &lt;- pfr(pasat ~ lf(cca, k=30, bs="ps"), data=DTI1)
plot(fit.lf, ylab=expression(paste(beta(t))), xlab="t")
## Not run: 
# Alternative way to plot
bhat.lf &lt;- coef(fit.lf, n=101)
bhat.lf$upper &lt;- bhat.lf$value + 1.96*bhat.lf$se
bhat.lf$lower &lt;- bhat.lf$value - 1.96*bhat.lf$se
matplot(bhat.lf$cca.argvals, bhat.lf[,c("value", "upper", "lower")],
        type="l", lty=c(1,2,2), col=1,
        ylab=expression(paste(beta(t))), xlab="t")

# Fit model with additive functional term for CCA, using tensor product basis
fit.af &lt;- pfr(pasat ~ af(cca, Qtransform=TRUE, k=c(7,7)), data=DTI1)
plot(fit.af, scheme=2, xlab="t", ylab="cca(t)", main="Tensor Product")
plot(fit.af, scheme=2, Qtransform=TRUE,
     xlab="t", ylab="cca(t)", main="Tensor Product")

# Change basistype to thin-plate regression splines
fit.af.s &lt;- pfr(pasat ~ af(cca, basistype="s", Qtransform=TRUE, k=50),
                data=DTI1)
plot(fit.af.s, scheme=2, xlab="t", ylab="cca(t)", main="TPRS", rug=FALSE)
plot(fit.af.s, scheme=2, Qtransform=TRUE,
     xlab="t", ylab="cca(t)", main="TPRS", rug=FALSE)

# Visualize bivariate function at various values of x
par(mfrow=c(2,2))
vis.pfr(fit.af, xval=.2)
vis.pfr(fit.af, xval=.4)
vis.pfr(fit.af, xval=.6)
vis.pfr(fit.af, xval=.8)

# Include random intercept for subject
DTI.re &lt;- DTI[complete.cases(DTI$cca),]
DTI.re$ID &lt;- factor(DTI.re$ID)
fit.re &lt;- pfr(pasat ~ lf(cca, k=30) + re(ID), data=DTI.re)
coef.re &lt;- coef(fit.re)
par(mfrow=c(1,2))
plot(fit.re)

# FPCR_R Model
fit.fpc &lt;- pfr(pasat ~ fpc(cca), data=DTI.re)
plot(fit.fpc)

# PEER Model with second order difference penalty
DTI.use &lt;- DTI[DTI$case==1,]
DTI.use &lt;- DTI.use[complete.cases(DTI.use$cca),]
fit.peer &lt;- pfr(pasat ~ peer(cca, argvals=seq(0,1,length=93),
                             integration="riemann", pentype="D"), data=DTI.use)
plot(fit.peer)

## End(Not run)
</code></pre>

<hr>
<h2 id='pfr_old'>Penalized Functional Regression (old version)</h2><span id='topic+pfr_old'></span>

<h3>Description</h3>

<p>This code implements the function pfr() available in refund 0.1-11. It is included
to maintain backwards compatibility. 
</p>
<p>Functional predictors are entered as a matrix or, in the case of
multiple functional predictors, as a list of matrices using the
<code>funcs</code> argument. Missing values are allowed in the functional
predictors, but it is assumed that they are observed over the same
grid. Functional coefficients and confidence bounds are returned as
lists in the same order as provided in the <code>funcs</code> argument, as
are principal component and spline bases.  Increasing values of
<code>nbasis</code> will increase computational time and the values of
<code>nbasis</code>, <code>kz</code>, and <code>kb</code> in relation to each other may
need to be adjusted in application-specific ways.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pfr_old(
  Y,
  subj = NULL,
  covariates = NULL,
  funcs,
  kz = 10,
  kb = 30,
  nbasis = 10,
  family = "gaussian",
  method = "REML",
  smooth.option = "fpca.sc",
  pve = 0.99,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pfr_old_+3A_y">Y</code></td>
<td>
<p>vector of all outcomes over all visits</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_subj">subj</code></td>
<td>
<p>vector containing the subject number for each observation</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_covariates">covariates</code></td>
<td>
<p>matrix of scalar covariates</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_funcs">funcs</code></td>
<td>
<p>matrix, or list of matrices, containing observed functional 
predictors as rows. NA values are allowed.</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_kz">kz</code></td>
<td>
<p>can be NULL; can be a scalar, in which case this will be the 
dimension of principal components basis for each and every observed 
functional predictors; can be a vector of length equal to the number 
of functional predictors, in which case each element will correspond 
to the dimension of principal components basis for the corresponding 
observed functional predictors</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_kb">kb</code></td>
<td>
<p>dimension of the B-spline basis for the coefficient function 
(note: this is a change from versions 0.1-7 and previous)</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_nbasis">nbasis</code></td>
<td>
<p>passed to refund::fpca.sc (note: using fpca.sc is a change 
from versions 0.1-7 and previous)</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_family">family</code></td>
<td>
<p>generalized linear model family</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_method">method</code></td>
<td>
<p>method for estimating the smoothing parameters; defaults 
to REML</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_smooth.option">smooth.option</code></td>
<td>
<p>method to do FPC decomposition on the predictors. 
Two options available &ndash; &quot;fpca.sc&quot; or &quot;fpca.face&quot;. If using &quot;fpca.sc&quot;, 
a number less than 35 for <code>nbasis</code> should be used while if using 
&quot;fpca.face&quot;,35 or more is recommended.</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_pve">pve</code></td>
<td>
<p>proportion of variance explained used to choose the number of 
principal components to be included in the expansion.</p>
</td></tr>
<tr><td><code id="pfr_old_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="mgcv.html#topic+gam">gam</a></code> to 
fit the regression model.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>fit</code></td>
<td>
<p>result of the call to <code>gam</code></p>
</td></tr>
<tr><td><code>fitted.vals</code></td>
<td>
<p>predicted outcomes</p>
</td></tr>
<tr><td><code>fitted.vals.level.0</code></td>
<td>
<p>predicted outcomes at population level</p>
</td></tr>
<tr><td><code>fitted.vals.level.1</code></td>
<td>
<p>predicted outcomes at subject-specific level (if applicable)</p>
</td></tr>
<tr><td><code>betaHat</code></td>
<td>
<p>list of estimated coefficient functions</p>
</td></tr>
<tr><td><code>beta.covariates</code></td>
<td>
<p>parameter estimates for scalar covariates</p>
</td></tr>
<tr><td><code>varBetaHat</code></td>
<td>
<p>list containing covariance matrices for the estimated coefficient functions</p>
</td></tr>
<tr><td><code>Bounds</code></td>
<td>
<p>list of bounds of a pointwise 95% confidence interval for the estimated coefficient functions</p>
</td></tr>
<tr><td><code>X</code></td>
<td>
<p>design matrix used in the model fit</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p>penalty matrix used in the model fit</p>
</td></tr>
<tr><td><code>phi</code></td>
<td>
<p>list of B-spline bases for the coefficient functions</p>
</td></tr>
<tr><td><code>psi</code></td>
<td>
<p>list of principal components basis for the functional predictors</p>
</td></tr>
<tr><td><code>C</code></td>
<td>
<p>stacked row-specific principal component scores</p>
</td></tr>
<tr><td><code>J</code></td>
<td>
<p>transpose of psi matrix multiplied by phi</p>
</td></tr>
<tr><td><code>CJ</code></td>
<td>
<p>C matrix multiplied J</p>
</td></tr>
<tr><td><code>Z1</code></td>
<td>
<p>design matrix of random intercepts</p>
</td></tr>
<tr><td><code>subj</code></td>
<td>
<p>subject identifiers as specified by user</p>
</td></tr>
<tr><td><code>fixed.mat</code></td>
<td>
<p>the fixed effects design matrix of the pfr as a mixed model</p>
</td></tr>
<tr><td><code>rand.mat</code></td>
<td>
<p>the fixed effects design matrix of the pfr as a mixed model</p>
</td></tr>
<tr><td><code>N_subj</code></td>
<td>
<p>the number of unique subjects, if subj is specified</p>
</td></tr>
<tr><td><code>p</code></td>
<td>
<p>number of scalar covariates</p>
</td></tr>
<tr><td><code>N.pred</code></td>
<td>
<p>number of functional covariates</p>
</td></tr>
<tr><td><code>kz</code></td>
<td>
<p>as specified</p>
</td></tr>
<tr><td><code>kz.adj</code></td>
<td>
<p>For smooth.option=&quot;fpca.sc&quot;, will be same as kz (or a vector of repeated values of the specified scalar kz).  For smooth.option=&quot;fpca.face&quot;, will be the corresponding number of principal components for each functional predictor as determined by fpca.face; will be less than or equal to kz on an elemental-wise level.</p>
</td></tr>
<tr><td><code>kb</code></td>
<td>
<p>as specified</p>
</td></tr>
<tr><td><code>nbasis</code></td>
<td>
<p>as specified</p>
</td></tr>
<tr><td><code>totD</code></td>
<td>
<p>number of penalty matrices created for mgcv::gam</p>
</td></tr>
<tr><td><code>funcs</code></td>
<td>
<p>as specified</p>
</td></tr>
<tr><td><code>covariates</code></td>
<td>
<p>as specified</p>
</td></tr>
<tr><td><code>smooth.option</code></td>
<td>
<p>as specified</p>
</td></tr>
</table>


<h3>Warning</h3>

<p>Binomial responses should be specified as a numeric vector rather than as a
matrix or a factor.
</p>


<h3>Author(s)</h3>

<p>Bruce Swihart <a href="mailto:bruce.swihart@gmail.com">bruce.swihart@gmail.com</a> and 
Jeff Goldsmith <a href="mailto:jeff.goldsmith@columbia.edu">jeff.goldsmith@columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Bobb, J., Crainiceanu, C., Caffo, B., and Reich, D. (2011).
Penalized functional regression. <em>Journal of Computational and Graphical
Statistics</em>, 20(4), 830-851.
</p>
<p>Goldsmith, J., Crainiceanu, C., Caffo, B., and Reich, D. (2012). Longitudinal
penalized functional regression for cognitive outcomes on neuronal tract
measurements. <em>Journal of the Royal Statistical Society: Series C</em>,
61(3), 453-469.
</p>
<p>Swihart, Bruce J., Goldsmith, Jeff; and Crainiceanu, Ciprian M. (July 2012). 
Testing for functional effects. Johns Hopkins University Dept. of Biostatistics 
Working Paper 247, available at <a href="https://biostats.bepress.com/jhubiostat/paper247/">https://biostats.bepress.com/jhubiostat/paper247/</a>
American Statistical Association, 109(508): 1425-1439.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rlrt.pfr">rlrt.pfr</a></code>, <code><a href="#topic+predict.pfr">predict.pfr</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
##################################################################
#########               DTI Data Example                 #########
##################################################################

##################################################################
# For more about this example, see Swihart et al. 2013
##################################################################

## load and reassign the data;
data(DTI2)
Y  &lt;- DTI2$pasat ## PASAT outcome
id &lt;- DTI2$id    ## subject id
W1 &lt;- DTI2$cca   ## Corpus Callosum
W2 &lt;- DTI2$rcst  ## Right corticospinal
V  &lt;- DTI2$visit ## visit

## prep scalar covariate
visit.1.rest &lt;- matrix(as.numeric(V &gt; 1), ncol=1)
covar.in &lt;- visit.1.rest 


## note there is missingness in the functional predictors
apply(is.na(W1), 2, mean)
apply(is.na(W2), 2, mean)

## fit two univariate models
pfr.obj.t1 &lt;- pfr(Y = Y, covariates=covar.in, funcs = list(W1),     subj = id, kz = 10, kb = 50)
pfr.obj.t2 &lt;- pfr(Y = Y, covariates=covar.in, funcs = list(W2),     subj = id, kz = 10, kb = 50)

### one model with two functional predictors using "smooth.face"
###  for smoothing predictors
pfr.obj.t3 &lt;- pfr(Y = Y, covariates=covar.in, funcs = list(W1, W2), 
                  subj = id, kz = 10, kb = 50, nbasis=35,smooth.option="fpca.face")

## plot the coefficient function and bounds
dev.new()
par(mfrow=c(2,2))
ran &lt;- c(-2,.5)
matplot(cbind(pfr.obj.t1$BetaHat[[1]], pfr.obj.t1$Bounds[[1]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "CCA", xlab="Location", ylim=ran)
abline(h=0, col="blue")
matplot(cbind(pfr.obj.t2$BetaHat[[1]], pfr.obj.t2$Bounds[[1]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "RCST", xlab="Location", ylim=ran)
abline(h=0, col="blue")
matplot(cbind(pfr.obj.t3$BetaHat[[1]], pfr.obj.t3$Bounds[[1]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "CCA  - mult.", xlab="Location", ylim=ran)
abline(h=0, col="blue")
matplot(cbind(pfr.obj.t3$BetaHat[[2]], pfr.obj.t3$Bounds[[2]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "RCST - mult.", xlab="Location", ylim=ran)
abline(h=0, col="blue")


##################################################################
# use baseline data to regress continuous outcomes on functional 
# predictors (continuous outcomes only recorded for case == 1)
##################################################################

data(DTI)

# subset data as needed for this example
cca = DTI$cca[which(DTI$visit ==1 &amp; DTI$case == 1),]
rcst = DTI$rcst[which(DTI$visit ==1 &amp; DTI$case == 1),]
DTI = DTI[which(DTI$visit ==1 &amp; DTI$case == 1),]
# note there is missingness in the functional predictors
apply(is.na(cca), 2, mean)
apply(is.na(rcst), 2, mean)

# fit two models with single functional predictors and plot the results
fit.cca = pfr(Y=DTI$pasat, funcs = cca, kz=10, kb=50, nbasis=20)
fit.rcst = pfr(Y=DTI$pasat, funcs = rcst, kz=10, kb=50, nbasis=20)

par(mfrow = c(1,2))
matplot(cbind(fit.cca$BetaHat[[1]], fit.cca$Bounds[[1]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "CCA")
matplot(cbind(fit.rcst$BetaHat[[1]], fit.rcst$Bounds[[1]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "RCST")

# fit a model with two functional predictors and plot the results
fit.cca.rcst = pfr(Y=DTI$pasat, funcs = list(cca, rcst), kz=10, kb=30, nbasis=20)

par(mfrow = c(1,2))
matplot(cbind(fit.cca.rcst$BetaHat[[1]], fit.cca.rcst$Bounds[[1]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "CCA")
matplot(cbind(fit.cca.rcst$BetaHat[[2]], fit.cca.rcst$Bounds[[2]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "RCST")

##################################################################
# use baseline data to regress binary case-status outcomes on 
# functional predictors
##################################################################

data(DTI)

# subset data as needed for this example
cca = DTI$cca[which(DTI$visit == 1),]
rcst = DTI$rcst[which(DTI$visit == 1),]
DTI = DTI[which(DTI$visit == 1),]

# fit two models with single functional predictors and plot the results
fit.cca = pfr(Y=DTI$case, funcs = cca, family = "binomial")
fit.rcst = pfr(Y=DTI$case, funcs = rcst, family = "binomial")

par(mfrow = c(1,2))
matplot(cbind(fit.cca$BetaHat[[1]], fit.cca$Bounds[[1]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "CCA")
matplot(cbind(fit.rcst$BetaHat[[1]], fit.rcst$Bounds[[1]]),
        type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat", 
        main = "RCST")

##################################################################
#########              Octane Data Example               #########
##################################################################

data(gasoline)
Y = gasoline$octane
funcs = gasoline$NIR
wavelengths = as.matrix(2*450:850)

# fit the model using pfr and the smoothing option "fpca.face"
fit = pfr(Y=Y, funcs=funcs, kz=15, kb=50,nbasis=35,smooth.option="fpca.face")

matplot(wavelengths, cbind(fit$BetaHat[[1]], fit$Bounds[[1]]), 
        type='l', lwd=c(2,1,1), lty=c(1,2,2), xlab = "Wavelengths", 
        ylab = "Coefficient Function", col=1)

## End(Not run)
</code></pre>

<hr>
<h2 id='pfr_plot.gam'>Local version of <code>plot.gam</code></h2><span id='topic+pfr_plot.gam'></span><span id='topic+plot.mgcv.smooth'></span><span id='topic+plot.random.effect'></span>

<h3>Description</h3>

<p>These internal functions were copied from Simon Wood's <code>mgcv</code> package,
with some minor changes to allow for plotting <code>pfr</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pfr_plot.gam(
  x,
  residuals = FALSE,
  rug = TRUE,
  se = TRUE,
  pages = 0,
  select = NULL,
  scale = -1,
  n = 100,
  n2 = 40,
  n3 = 3,
  theta = 30,
  phi = 30,
  jit = FALSE,
  xlab = NULL,
  ylab = NULL,
  main = NULL,
  ylim = NULL,
  xlim = NULL,
  too.far = 0.1,
  all.terms = FALSE,
  shade = FALSE,
  shade.col = "gray80",
  shift = 0,
  trans = I,
  seWithMean = FALSE,
  unconditional = FALSE,
  by.resids = FALSE,
  scheme = 0,
  ...
)

## S3 method for class 'mgcv.smooth'
plot(
  x,
  P = NULL,
  data = NULL,
  label = "",
  se1.mult = 1,
  se2.mult = 2,
  partial.resids = FALSE,
  rug = TRUE,
  se = TRUE,
  scale = -1,
  n = 100,
  n2 = 40,
  theta = 30,
  phi = 30,
  jit = FALSE,
  xlab = NULL,
  ylab = NULL,
  main = NULL,
  ylim = NULL,
  xlim = NULL,
  too.far = 0.1,
  shade = FALSE,
  shade.col = "gray80",
  shift = 0,
  trans = I,
  by.resids = FALSE,
  scheme = 0,
  ...
)

## S3 method for class 'random.effect'
plot(
  x,
  P = NULL,
  data = NULL,
  label = "",
  se1.mult = 1,
  se2.mult = 2,
  partial.resids = FALSE,
  rug = TRUE,
  se = TRUE,
  scale = -1,
  n = 100,
  n2 = 40,
  n3 = 3,
  theta = 30,
  phi = 30,
  jit = FALSE,
  xlab = NULL,
  ylab = NULL,
  main = NULL,
  ylim = NULL,
  xlim = NULL,
  too.far = 0.1,
  shade = FALSE,
  shade.col = "gray80",
  shift = 0,
  trans = I,
  by.resids = FALSE,
  scheme = 0,
  ...
)
</code></pre>


<h3>See Also</h3>

<p><code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code>
</p>

<hr>
<h2 id='plot.fosr'>Default plotting of function-on-scalar regression objects</h2><span id='topic+plot.fosr'></span>

<h3>Description</h3>

<p>Plots the coefficient function estimates produced by <code>fosr()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fosr'
plot(
  x,
  split = NULL,
  titles = NULL,
  xlabel = "",
  ylabel = "Coefficient function",
  set.mfrow = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fosr_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+fosr">fosr</a>"</code>.</p>
</td></tr>
<tr><td><code id="plot.fosr_+3A_split">split</code></td>
<td>
<p>value, or vector of values, at which to divide the set of
coefficient functions into groups, each plotted on a different scale.
E.g., if set to 1, the first function is plotted on one scale, and all
others on a different (common) scale.  If <code>NULL</code>, all functions are
plotted on the same scale.</p>
</td></tr>
<tr><td><code id="plot.fosr_+3A_titles">titles</code></td>
<td>
<p>character vector of titles for the plots produced, e.g.,
names of the corresponding scalar predictors.</p>
</td></tr>
<tr><td><code id="plot.fosr_+3A_xlabel">xlabel</code></td>
<td>
<p>label for the x-axes of the plots.</p>
</td></tr>
<tr><td><code id="plot.fosr_+3A_ylabel">ylabel</code></td>
<td>
<p>label for the y-axes of the plots.</p>
</td></tr>
<tr><td><code id="plot.fosr_+3A_set.mfrow">set.mfrow</code></td>
<td>
<p>logical value: if <code>TRUE</code>, the function will try to
set an appropriate value of the <code>mfrow</code> parameter for the plots.
Otherwise you may wish to set <code>mfrow</code> outside the function call.</p>
</td></tr>
<tr><td><code id="plot.fosr_+3A_...">...</code></td>
<td>
<p>graphical parameters (see <code><a href="graphics.html#topic+par">par</a></code>) for the plot.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fosr">fosr</a></code>, which includes examples.
</p>

<hr>
<h2 id='plot.fosr.vs'>Plot for Function-on Scalar Regression with variable selection</h2><span id='topic+plot.fosr.vs'></span>

<h3>Description</h3>

<p>Given a &quot;<code><a href="#topic+fosr.vs">fosr.vs</a></code>&quot; object, produces a figure of estimated coefficient functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fosr.vs'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fosr.vs_+3A_x">x</code></td>
<td>
<p>an object of class &quot;<code><a href="#topic+fosr.vs">fosr.vs</a></code>&quot;.</p>
</td></tr>
<tr><td><code id="plot.fosr.vs_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a figure of estimated coefficient functions.
</p>


<h3>Author(s)</h3>

<p>Yakuan Chen <a href="mailto:yc2641@cumc.columbia.edu">yc2641@cumc.columbia.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fosr.vs">fosr.vs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
I = 100
p = 20
D = 50
grid = seq(0, 1, length = D)

beta.true = matrix(0, p, D)
beta.true[1,] = sin(2*grid*pi)
beta.true[2,] = cos(2*grid*pi)
beta.true[3,] = 2

psi.true = matrix(NA, 2, D)
psi.true[1,] = sin(4*grid*pi)
psi.true[2,] = cos(4*grid*pi)
lambda = c(3,1)

set.seed(100)

X = matrix(rnorm(I*p), I, p)
C = cbind(rnorm(I, mean = 0, sd = lambda[1]), rnorm(I, mean = 0, sd = lambda[2]))

fixef = X%*%beta.true
pcaef = C %*% psi.true
error = matrix(rnorm(I*D), I, D)

Yi.true = fixef
Yi.pca = fixef + pcaef
Yi.obs = fixef + pcaef + error

data = as.data.frame(X)
data$Y = Yi.obs
fit.mcp = fosr.vs(Y~., data = data[1:80,], method="grMCP")
plot(fit.mcp)

## End(Not run)


</code></pre>

<hr>
<h2 id='plot.fpcr'>Default plotting for functional principal component regression output</h2><span id='topic+plot.fpcr'></span>

<h3>Description</h3>

<p>Inputs an object created by <code><a href="#topic+fpcr">fpcr</a></code>, and plots the estimated
coefficient function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fpcr'
plot(
  x,
  se = TRUE,
  col = 1,
  lty = c(1, 2, 2),
  xlab = "",
  ylab = "Coefficient function",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.fpcr_+3A_x">x</code></td>
<td>
<p>an object of class <code>"<a href="#topic+fpcr">fpcr</a>"</code>.</p>
</td></tr>
<tr><td><code id="plot.fpcr_+3A_se">se</code></td>
<td>
<p>if <code>TRUE</code> (the default), upper and lower lines are added at
2 standard errors (in the Bayesian sense; see Wood, 2006) above and below
the coefficient function estimate.  If a positive number is supplied, the
standard error is instead multiplied by this number.</p>
</td></tr>
<tr><td><code id="plot.fpcr_+3A_col">col</code></td>
<td>
<p>color for the line(s).  This should be either a number, or a
vector of length 3 for the coefficient function estimate, lower bound, and
upper bound, respectively.</p>
</td></tr>
<tr><td><code id="plot.fpcr_+3A_lty">lty</code></td>
<td>
<p>line type(s) for the coefficient function estimate, lower bound,
and upper bound.</p>
</td></tr>
<tr><td><code id="plot.fpcr_+3A_xlab">xlab</code>, <code id="plot.fpcr_+3A_ylab">ylab</code></td>
<td>
<p>x- and y-axis labels.</p>
</td></tr>
<tr><td><code id="plot.fpcr_+3A_...">...</code></td>
<td>
<p>other arguments passed to the underlying plotting function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>None; only a plot is produced.
</p>


<h3>Author(s)</h3>

<p>Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a>
</p>


<h3>References</h3>

<p>Wood, S. N. (2006). <em>Generalized Additive Models: An
Introduction with R</em>. Boca Raton, FL: Chapman &amp; Hall.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fpcr">fpcr</a></code>, which includes an example.
</p>

<hr>
<h2 id='plot.lpeer'>Plotting of estimated regression functions obtained through <code>lpeer()</code></h2><span id='topic+plot.lpeer'></span>

<h3>Description</h3>

<p>Plots the estimate of components of estimated regression function obtained
from an <code><a href="#topic+lpeer">lpeer</a></code> object along with pointwise confidence bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lpeer'
plot(x, conf = 0.95, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lpeer_+3A_x">x</code></td>
<td>
<p>object of class <code>"<a href="#topic+lpeer">lpeer</a>"</code>.</p>
</td></tr>
<tr><td><code id="plot.lpeer_+3A_conf">conf</code></td>
<td>
<p>pointwise confidence level.</p>
</td></tr>
<tr><td><code id="plot.lpeer_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="graphics.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pointwise confidence interval is displayed only if the user set <code>se=T</code>
in the call to <code><a href="#topic+lpeer">lpeer</a></code>, and does not reflect any multiplicity
correction.
</p>


<h3>Author(s)</h3>

<p>Madan Gopal Kundu <a href="mailto:mgkundu@iupui.edu">mgkundu@iupui.edu</a>
</p>


<h3>References</h3>

<p>Kundu, M. G., Harezlak, J., and Randolph, T. W. (2012).
Longitudinal functional models with structured penalties. (Please contact
J. Harezlak at <a href="mailto:harezlak@iupui.edu">harezlak@iupui.edu</a>.)
</p>
<p>Randolph, T. W., Harezlak, J, and Feng, Z. (2012). Structured penalties for
functional linear models - partially empirical eigenvectors for regression.
<em>Electronic Journal of Statistics</em>, 6, 323&ndash;353.
</p>


<h3>See Also</h3>

<p><code>peer</code>, <code>lpeer</code>, <code>plot.peer</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(DTI)
cca = DTI$cca[which(DTI$case == 1),]
DTI = DTI[which(DTI$case == 1),]
fit.cca.lpeer1 = lpeer(Y=DTI$pasat, t=DTI$visit, subj=DTI$ID, funcs = cca)
plot(fit.cca.lpeer1)

## End(Not run)
</code></pre>

<hr>
<h2 id='plot.peer'>Plotting of estimated regression functions obtained through <code>peer()</code></h2><span id='topic+plot.peer'></span>

<h3>Description</h3>

<p>Plots the estimate of components of estimated regression function obtained
from a <code><a href="#topic+peer">peer</a></code> object along with pointwise confidence bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'peer'
plot(
  x,
  conf = 0.95,
  ylab = "Estimated regression function",
  main = expression(gamma),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.peer_+3A_x">x</code></td>
<td>
<p>object of class <code>"<a href="#topic+peer">peer</a>"</code>.</p>
</td></tr>
<tr><td><code id="plot.peer_+3A_conf">conf</code></td>
<td>
<p>pointwise confidence level.</p>
</td></tr>
<tr><td><code id="plot.peer_+3A_ylab">ylab</code></td>
<td>
<p>y-axis label.</p>
</td></tr>
<tr><td><code id="plot.peer_+3A_main">main</code></td>
<td>
<p>title for the plot.</p>
</td></tr>
<tr><td><code id="plot.peer_+3A_...">...</code></td>
<td>
<p>additional arguments passed to <code><a href="graphics.html#topic+plot">plot</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pointwise confidence interval is displayed only if the user set <code>se=T</code>
in the call to <code><a href="#topic+peer">peer</a></code>, and does not reflect any multiplicity
correction.
</p>


<h3>Author(s)</h3>

<p>Madan Gopal Kundu <a href="mailto:mgkundu@iupui.edu">mgkundu@iupui.edu</a>
</p>


<h3>References</h3>

<p>Kundu, M. G., Harezlak, J., and Randolph, T. W. (2012).
Longitudinal functional models with structured penalties. (Please contact
J. Harezlak at <a href="mailto:harezlak@iupui.edu">harezlak@iupui.edu</a>.)
</p>
<p>Randolph, T. W., Harezlak, J, and Feng, Z. (2012). Structured penalties for
functional linear models - partially empirical eigenvectors for regression.
<em>Electronic Journal of Statistics</em>, 6, 323&ndash;353.
</p>


<h3>See Also</h3>

<p><code>peer</code>, <code>lpeer</code>, <code>plot.lpeer</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># See example in peer()
</code></pre>

<hr>
<h2 id='plot.pffr'>Plot a pffr fit</h2><span id='topic+plot.pffr'></span>

<h3>Description</h3>

<p>Plot a fitted pffr-object. Simply dispatches to <code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pffr'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pffr_+3A_x">x</code></td>
<td>
<p>a fitted <code>pffr</code>-object</p>
</td></tr>
<tr><td><code id="plot.pffr_+3A_...">...</code></td>
<td>
<p>arguments handed over to <code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function only generates plots.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>

<hr>
<h2 id='plot.pfr'>Plot a pfr object</h2><span id='topic+plot.pfr'></span>

<h3>Description</h3>

<p>This function plots the smooth coefficients of a pfr object. These include
functional coefficients as well as any smooths of scalar covariates. The
function dispatches to <code>pfr_plot.gam</code>, which is our local copy of
<code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code> with some minor changes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pfr'
plot(x, Qtransform = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.pfr_+3A_x">x</code></td>
<td>
<p>a fitted <code>pfr</code>-object</p>
</td></tr>
<tr><td><code id="plot.pfr_+3A_qtransform">Qtransform</code></td>
<td>
<p>For additive functional terms, <code>TRUE</code> indicates the
coefficient should be plotted on the quantile-transformed scale, whereas
<code>FALSE</code> indicates the scale of the original data. Note this is
different from the <code>Qtransform</code> arguemnt of <code>af</code>, which specifies
the scale on which the term is fit.</p>
</td></tr>
<tr><td><code id="plot.pfr_+3A_...">...</code></td>
<td>
<p>arguments handed over to <code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>This function's main purpose is its side effect of generating plots.
It also silently returns a list of the data used to produce the plots, which
can be used to generate customized plots.
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar
</p>


<h3>See Also</h3>

<p><code><a href="#topic+af">af</a></code>, <code><a href="#topic+pfr">pfr</a></code>
</p>

<hr>
<h2 id='predict.fbps'>Prediction for fast bivariate <em>P</em>-spline (fbps)</h2><span id='topic+predict.fbps'></span>

<h3>Description</h3>

<p>Produces predictions given a <code><a href="#topic+fbps">fbps</a></code> object and new data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fbps'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.fbps_+3A_object">object</code></td>
<td>
<p>an object returned by <code><a href="#topic+fbps">fbps</a></code></p>
</td></tr>
<tr><td><code id="predict.fbps_+3A_newdata">newdata</code></td>
<td>
<p>a data frame or list consisting of x and z values for which predicted values are desired. 
vectors of x and z need to be of the same length.</p>
</td></tr>
<tr><td><code id="predict.fbps_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with components </p>
<table>
<tr><td><code>x</code></td>
<td>
<p>a vector of x given in newdata</p>
</td></tr>
<tr><td><code>z</code></td>
<td>
<p>a vector of z given in newdata</p>
</td></tr> <tr><td><code>fitted.values</code></td>
<td>
<p>a vector of
fitted values corresponding to x and z given in newdata</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Luo Xiao <a href="mailto:lxiao@jhsph.edu">lxiao@jhsph.edu</a>
</p>


<h3>References</h3>

<p>Xiao, L., Li, Y., and Ruppert, D. (2013). Fast bivariate
<em>P</em>-splines: the sandwich smoother. <em>Journal of the Royal
Statistical Society: Series B</em>, 75(3), 577&ndash;599.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>##########################
#### True function   #####
##########################
n1 &lt;- 60
n2 &lt;- 80
x &lt;- (1: n1)/n1-1/2/n1
z &lt;- (1: n2)/n2-1/2/n2
MY &lt;- array(0,c(length(x),length(z)))
sigx &lt;- .3
sigz &lt;- .4
for(i in 1: length(x))
  for(j in 1: length(z))
 {
    #MY[i,j] &lt;- .75/(pi*sigx*sigz) *exp(-(x[i]-.2)^2/sigx^2-(z[j]-.3)^2/sigz^2)
    #MY[i,j] &lt;- MY[i,j] + .45/(pi*sigx*sigz) *exp(-(x[i]-.7)^2/sigx^2-(z[j]-.8)^2/sigz^2)
    MY[i,j] = sin(2*pi*(x[i]-.5)^3)*cos(4*pi*z[j])
  }

##########################
#### Observed data   #####
##########################
sigma &lt;- 1
Y &lt;- MY + sigma*rnorm(n1*n2,0,1)

##########################
####   Estimation    #####
##########################
est &lt;- fbps(Y,list(x=x,z=z))
mse &lt;- mean((est$Yhat-MY)^2)
cat("mse of fbps is",mse,"\n")
cat("The smoothing parameters are:",est$lambda,"\n")

########################################################################
########## Compare the estimated surface with the true surface #########
########################################################################

par(mfrow=c(1,2))
persp(x,z,MY,zlab="f(x,z)",zlim=c(-1,2.5), phi=30,theta=45,expand=0.8,r=4,
      col="blue",main="True surface")
persp(x,z,est$Yhat,zlab="f(x,z)",zlim=c(-1,2.5),phi=30,theta=45,
      expand=0.8,r=4,col="red",main="Estimated surface")

##########################
####   prediction    #####
##########################

# 1. make prediction with predict.fbps() for all pairs of x and z given in the original data
#    ( it's expected to have same results as Yhat obtianed using fbps() above )
newdata &lt;- list(x= rep(x, length(z)), z = rep(z, each=length(x)))
pred1 &lt;- predict(est, newdata=newdata)$fitted.values
pred1.mat &lt;- matrix(pred1, nrow=length(x))
par(mfrow=c(1,2))
image(pred1.mat); image(est$Yhat)
all.equal(as.numeric(pred1.mat), as.numeric(est$Yhat))

# 2. predict for pairs of first 10 x values and first 5 z values
newdata &lt;- list(x= rep(x[1:10], 5), z = rep(z[1:5], each=10))
pred2 &lt;- predict(est, newdata=newdata)$fitted.values
pred2.mat &lt;- matrix(pred2, nrow=10)
par(mfrow=c(1,2))
image(pred2.mat); image(est$Yhat[1:10,1:5])
all.equal(as.numeric(pred2.mat), as.numeric(est$Yhat[1:10,1:5]))
# 3. predict for one pair 
newdata &lt;- list(x=x[5], z=z[3])
pred3 &lt;- predict(est, newdata=newdata)$fitted.values
all.equal(as.numeric(pred3), as.numeric(est$Yhat[5,3]))
</code></pre>

<hr>
<h2 id='predict.fgam'>Prediction from a fitted FGAM model</h2><span id='topic+predict.fgam'></span>

<h3>Description</h3>

<p>Takes a fitted <code>fgam</code>-object produced by <code><a href="#topic+fgam">fgam</a></code> and produces predictions given a
new set of values for the model covariates or the original values used for the model fit.
Predictions can be accompanied by standard errors, based on the posterior distribution of the
model coefficients. This is a wrapper function for <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fgam'
predict(
  object,
  newdata,
  type = "response",
  se.fit = FALSE,
  terms = NULL,
  PredOutOfRange = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.fgam_+3A_object">object</code></td>
<td>
<p>a fitted <code>fgam</code> object as produced by <code><a href="#topic+fgam">fgam</a></code></p>
</td></tr>
<tr><td><code id="predict.fgam_+3A_newdata">newdata</code></td>
<td>
<p>a named list containing the values of the model covariates at which predictions
are required. If this is not provided then predictions corresponding to the original data are
returned. All variables provided to newdata should be in the format supplied to <code><a href="#topic+fgam">fgam</a></code>,
i.e., functional predictors must be supplied as matrices with each row corresponding to one
observed function. Index variables for the functional covariates are reused from the fitted model
object or alternatively can be supplied as attributes of the matrix of functional predictor values.
Any variables in the model not specified in newdata are set to their average values from the data
supplied during fitting the model</p>
</td></tr>
<tr><td><code id="predict.fgam_+3A_type">type</code></td>
<td>
<p>character; see <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> for details</p>
</td></tr>
<tr><td><code id="predict.fgam_+3A_se.fit">se.fit</code></td>
<td>
<p>logical; see <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> for details</p>
</td></tr>
<tr><td><code id="predict.fgam_+3A_terms">terms</code></td>
<td>
<p>character see <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> for details</p>
</td></tr>
<tr><td><code id="predict.fgam_+3A_predoutofrange">PredOutOfRange</code></td>
<td>
<p>logical; if this argument is true then any functional predictor values in
newdata corresponding to <code>fgam</code> terms that are greater[less] than the maximum[minimum] of the
domain of the marginal basis for the rows of the tensor product smooth are set to the maximum[minimum]
of the domain.  If this argument is false, attempting to predict a value of the functional predictor
outside the range of this basis produces an error</p>
</td></tr>
<tr><td><code id="predict.fgam_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>type == "lpmatrix"</code>, the design matrix for the supplied covariate values in long
format. If <code>se == TRUE</code>, a list with entries fit and se.fit containing fits and standard errors,
respectively. If <code>type == "terms" or "iterms"</code> each of these lists is a list of matrices of the
same dimension as the response for newdata containing the linear predictor and its se for each term
</p>


<h3>Author(s)</h3>

<p>Mathew W. McLean <a href="mailto:mathew.w.mclean@gmail.com">mathew.w.mclean@gmail.com</a> and Fabian Scheipl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fgam">fgam</a></code>, <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######### Octane data example #########
data(gasoline)
N &lt;- length(gasoline$octane)
wavelengths = 2*450:850
nir = matrix(NA, 60,401)
test &lt;- sample(60,20)
for (i in 1:60) nir[i,] = gasoline$NIR[i, ] # changes class from AsIs to matrix
y &lt;- gasoline$octane
#fit &lt;- fgam(y~af(nir,xind=wavelengths,splinepars=list(k=c(6,6),m=list(c(2,2),c(2,2)))),
  #            subset=(1:N)[-test])
#preds &lt;- predict(fit,newdata=list(nir=nir[test,]),type='response')
#plot(preds,y[test])
#abline(a=0,b=1)
</code></pre>

<hr>
<h2 id='predict.fosr'>Prediction from a fitted bayes_fosr model</h2><span id='topic+predict.fosr'></span>

<h3>Description</h3>

<p>Takes a fitted <code>fosr</code>-object produced by <code><a href="#topic+bayes_fosr">bayes_fosr</a></code> and produces predictions given a
new set of values for the model covariates or the original values used for the model fit.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fosr'
predict(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.fosr_+3A_object">object</code></td>
<td>
<p>a fitted <code>fosr</code> object as produced by <code><a href="#topic+bayes_fosr">bayes_fosr</a></code></p>
</td></tr>
<tr><td><code id="predict.fosr_+3A_newdata">newdata</code></td>
<td>
<p>a named list containing the values of the model covariates at which predictions
are required. If this is not provided then predictions corresponding to the original data are
returned. All variables provided to newdata should be in the format supplied to the model fitting 
function.</p>
</td></tr>
<tr><td><code id="predict.fosr_+3A_...">...</code></td>
<td>
<p>additional (unused) arguments</p>
</td></tr>
</table>


<h3>Value</h3>

<p>...
</p>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:jeff.goldsmith@columbia.edu">jeff.goldsmith@columbia.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bayes_fosr">bayes_fosr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(reshape2)
library(dplyr)
library(ggplot2)

##### Cross-sectional real-data example #####

## organize data
data(DTI)
DTI = subset(DTI, select = c(cca, case, pasat))
DTI = DTI[complete.cases(DTI),]
DTI$gender = factor(sample(c("male","female"), dim(DTI)[1], replace = TRUE))
DTI$status = factor(sample(c("RRMS", "SPMS", "PPMS"), dim(DTI)[1], replace = TRUE))

## fit models
VB = bayes_fosr(cca ~ pasat, data = DTI, Kp = 4, Kt = 10)

## obtain predictions
pred = predict(VB, sample_n(DTI, 10))

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.fosr.vs'>Prediction for Function-on Scalar Regression with variable selection</h2><span id='topic+predict.fosr.vs'></span>

<h3>Description</h3>

<p>Given a &quot;<code><a href="#topic+fosr.vs">fosr.vs</a></code>&quot; object and new data, produces fitted values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fosr.vs'
predict(object, newdata = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.fosr.vs_+3A_object">object</code></td>
<td>
<p>an object of class &quot;<code><a href="#topic+fosr.vs">fosr.vs</a></code>&quot;.</p>
</td></tr>
<tr><td><code id="predict.fosr.vs_+3A_newdata">newdata</code></td>
<td>
<p>a data frame that contains the values of the model covariates at which predictors are required.</p>
</td></tr>
<tr><td><code id="predict.fosr.vs_+3A_...">...</code></td>
<td>
<p>additional arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>fitted values.
</p>


<h3>Author(s)</h3>

<p>Yakuan Chen <a href="mailto:yc2641@cumc.columbia.edu">yc2641@cumc.columbia.edu</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fosr.vs">fosr.vs</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
I = 100
p = 20
D = 50
grid = seq(0, 1, length = D)

beta.true = matrix(0, p, D)
beta.true[1,] = sin(2*grid*pi)
beta.true[2,] = cos(2*grid*pi)
beta.true[3,] = 2

psi.true = matrix(NA, 2, D)
psi.true[1,] = sin(4*grid*pi)
psi.true[2,] = cos(4*grid*pi)
lambda = c(3,1)

set.seed(100)

X = matrix(rnorm(I*p), I, p)
C = cbind(rnorm(I, mean = 0, sd = lambda[1]), rnorm(I, mean = 0, sd = lambda[2]))

fixef = X%*%beta.true
pcaef = C %*% psi.true
error = matrix(rnorm(I*D), I, D)

Yi.true = fixef
Yi.pca = fixef + pcaef
Yi.obs = fixef + pcaef + error

data = as.data.frame(X)
data$Y = Yi.obs
fit.mcp = fosr.vs(Y~., data = data[1:80,], method="grMCP")
predicted.value = predict(fit.mcp, data[81:100,])


## End(Not run)

</code></pre>

<hr>
<h2 id='Predict.matrix.dt.smooth'>Predict.matrix method for dt basis</h2><span id='topic+Predict.matrix.dt.smooth'></span>

<h3>Description</h3>

<p>Predict.matrix method for dt basis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dt.smooth'
Predict.matrix(object, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict.matrix.dt.smooth_+3A_object">object</code></td>
<td>
<p>a <code>dt.smooth</code> object created by
<code><a href="#topic+smooth.construct.dt.smooth.spec">smooth.construct.dt.smooth.spec</a></code>, see
<code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
<tr><td><code id="Predict.matrix.dt.smooth_+3A_data">data</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>design matrix for domain-transformed terms
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar
</p>

<hr>
<h2 id='Predict.matrix.fpc.smooth'>mgcv-style constructor for prediction of FPC terms</h2><span id='topic+Predict.matrix.fpc.smooth'></span>

<h3>Description</h3>

<p>mgcv-style constructor for prediction of FPC terms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fpc.smooth'
Predict.matrix(object, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict.matrix.fpc.smooth_+3A_object">object</code></td>
<td>
<p>a <code>fpc.smooth</code> object created by
<code><a href="#topic+smooth.construct.fpc.smooth.spec">smooth.construct.fpc.smooth.spec</a></code>, see
<code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
<tr><td><code id="Predict.matrix.fpc.smooth_+3A_data">data</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>design matrix for FPC terms
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar
</p>

<hr>
<h2 id='Predict.matrix.pcre.random.effect'>mgcv-style constructor for prediction of PC-basis functional random effects</h2><span id='topic+Predict.matrix.pcre.random.effect'></span>

<h3>Description</h3>

<p>mgcv-style constructor for prediction of PC-basis functional random effects
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcre.random.effect'
Predict.matrix(object, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict.matrix.pcre.random.effect_+3A_object">object</code></td>
<td>
<p>a smooth specification object, see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
<tr><td><code id="Predict.matrix.pcre.random.effect_+3A_data">data</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>design matrix for PC-based functional random effects
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl;  adapted from 'Predict.matrix.random.effect' by S.N. Wood.
</p>

<hr>
<h2 id='Predict.matrix.peer.smooth'>mgcv-style constructor for prediction of PEER terms</h2><span id='topic+Predict.matrix.peer.smooth'></span>

<h3>Description</h3>

<p>mgcv-style constructor for prediction of PEER terms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'peer.smooth'
Predict.matrix(object, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict.matrix.peer.smooth_+3A_object">object</code></td>
<td>
<p>a <code>peer.smooth</code> object created by
<code><a href="#topic+smooth.construct.peer.smooth.spec">smooth.construct.peer.smooth.spec</a></code>, see
<code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
<tr><td><code id="Predict.matrix.peer.smooth_+3A_data">data</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>design matrix for PEER terms
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar
</p>

<hr>
<h2 id='Predict.matrix.pi.smooth'>Predict.matrix method for pi basis</h2><span id='topic+Predict.matrix.pi.smooth'></span>

<h3>Description</h3>

<p>Predict.matrix method for pi basis
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pi.smooth'
Predict.matrix(object, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Predict.matrix.pi.smooth_+3A_object">object</code></td>
<td>
<p>a <code>pi.smooth</code> object created by
<code><a href="#topic+smooth.construct.pi.smooth.spec">smooth.construct.pi.smooth.spec</a></code>, see
<code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
<tr><td><code id="Predict.matrix.pi.smooth_+3A_data">data</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>design matrix for PEER terms
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar
</p>

<hr>
<h2 id='predict.pffr'>Prediction for penalized function-on-function regression</h2><span id='topic+predict.pffr'></span>

<h3>Description</h3>

<p>Takes a fitted <code>pffr</code>-object produced by <code><a href="#topic+pffr">pffr</a>()</code> and produces
predictions given a new set of values for the model covariates or the original
values used for the model fit. Predictions can be accompanied by standard errors,
based on the posterior distribution of the model coefficients. This is a wrapper
function for <code><a href="mgcv.html#topic+predict.gam">predict.gam</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pffr'
predict(object, newdata, reformat = TRUE, type = "link", se.fit = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.pffr_+3A_object">object</code></td>
<td>
<p>a fitted <code>pffr</code>-object</p>
</td></tr>
<tr><td><code id="predict.pffr_+3A_newdata">newdata</code></td>
<td>
<p>A named list (or a <code>data.frame</code>) containing the values of the
model covariates at which predictions are required.
If no <code>newdata</code> is provided then predictions corresponding to the original data
are returned. If <code>newdata</code> is provided then it must contain all the variables needed
for prediction, in the format supplied to <code>pffr</code>, i.e., functional predictors must be
supplied as matrices with each row corresponding to one observed function.
See Details for more on index variables and prediction for models fit on
irregular or sparse data.</p>
</td></tr>
<tr><td><code id="predict.pffr_+3A_reformat">reformat</code></td>
<td>
<p>logical, defaults to TRUE. Should predictions be returned in matrix form (default) or
in the long vector shape returned by <code>predict.gam()</code>?</p>
</td></tr>
<tr><td><code id="predict.pffr_+3A_type">type</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+predict.gam">predict.gam</a>()</code> for details.
Note that <code>type == "lpmatrix"</code> will force <code>reformat</code> to FALSE.</p>
</td></tr>
<tr><td><code id="predict.pffr_+3A_se.fit">se.fit</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+predict.gam">predict.gam</a>()</code></p>
</td></tr>
<tr><td><code id="predict.pffr_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to <code><a href="mgcv.html#topic+predict.gam">predict.gam</a>()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Index variables (i.e., evaluation points) for the functional covariates are reused
from the fitted model object and cannot be supplied with <code>newdata</code>.
Prediction is always for the entire index range of the responses as defined
in the original fit. If the original fit was performed on sparse or irregular,
non-gridded response data supplied via <code>pffr</code>'s <code>ydata</code>-argument
and no <code>newdata</code> was supplied, this function will
simply return fitted values for the original evaluation points of the response (in list form).
If the original fit was performed on sparse or irregular data and <code>newdata</code> <em>was</em>
supplied, the function will return predictions on the grid of evaluation points given in
<code>object$pffr$yind</code>.
</p>


<h3>Value</h3>

<p>If <code>type == "lpmatrix"</code>, the design matrix for the supplied covariate values in long format.
If <code>se == TRUE</code>, a list with entries <code>fit</code> and <code>se.fit</code> containing fits and standard errors, respectively.
If <code>type == "terms"</code> or <code>"iterms"</code> each of these lists is a list of matrices of the same dimension as the response for <code>newdata</code>
containing the linear predictor and its se for each term.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>


<h3>See Also</h3>

<p><code><a href="mgcv.html#topic+predict.gam">predict.gam</a>()</code>
</p>

<hr>
<h2 id='predict.pfr'>Prediction from a fitted pfr model</h2><span id='topic+predict.pfr'></span>

<h3>Description</h3>

<p>Takes a fitted <code>pfr</code>-object produced by <code><a href="#topic+pfr">pfr</a></code> and produces predictions given a
new set of values for the model covariates or the original values used for the model fit.
Predictions can be accompanied by standard errors, based on the posterior distribution of the
model coefficients. This is a wrapper function for <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>()
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pfr'
predict(
  object,
  newdata,
  type = "response",
  se.fit = FALSE,
  terms = NULL,
  PredOutOfRange = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.pfr_+3A_object">object</code></td>
<td>
<p>a fitted <code>pfr</code> object as produced by <code><a href="#topic+pfr">pfr</a></code></p>
</td></tr>
<tr><td><code id="predict.pfr_+3A_newdata">newdata</code></td>
<td>
<p>a named list containing the values of the model covariates at which predictions
are required. If this is not provided then predictions corresponding to the original data are
returned. All variables provided to newdata should be in the format supplied to <code><a href="#topic+pfr">pfr</a></code>,
i.e., functional predictors must be supplied as matrices with each row corresponding to one
observed function. Index variables for the functional covariates are reused from the fitted model
object or alternatively can be supplied as attributes of the matrix of functional predictor values.
Any variables in the model not specified in newdata are set to their average values from the data
supplied during fitting the model</p>
</td></tr>
<tr><td><code id="predict.pfr_+3A_type">type</code></td>
<td>
<p>character; see <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> for details</p>
</td></tr>
<tr><td><code id="predict.pfr_+3A_se.fit">se.fit</code></td>
<td>
<p>logical; see <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> for details</p>
</td></tr>
<tr><td><code id="predict.pfr_+3A_terms">terms</code></td>
<td>
<p>character see <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code> for details</p>
</td></tr>
<tr><td><code id="predict.pfr_+3A_predoutofrange">PredOutOfRange</code></td>
<td>
<p>logical; if this argument is true then any functional predictor values in
newdata corresponding to <code>pfr</code> terms that are greater[less] than the maximum[minimum] of the
domain of the marginal basis for the rows of the tensor product smooth are set to the maximum[minimum]
of the domain.  If this argument is false, attempting to predict a value of the functional predictor
outside the range of this basis produces an error</p>
</td></tr>
<tr><td><code id="predict.pfr_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>type == "lpmatrix"</code>, the design matrix for the supplied covariate values in long
format. If <code>se == TRUE</code>, a list with entries fit and se.fit containing fits and standard errors,
respectively. If <code>type == "terms" or "iterms"</code> each of these lists is a list of matrices of the
same dimension as the response for newdata containing the linear predictor and its se for each term
</p>


<h3>Author(s)</h3>

<p>Mathew W. McLean <a href="mailto:mathew.w.mclean@gmail.com">mathew.w.mclean@gmail.com</a> and Fabian Scheipl
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pfr">pfr</a></code>, <code><a href="mgcv.html#topic+predict.gam">predict.gam</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>######### Octane data example #########
data(gasoline)
N &lt;- length(gasoline$octane)
wavelengths = 2*450:850
nir = matrix(NA, 60,401)
test &lt;- sample(60,20)
for (i in 1:60) nir[i,] = gasoline$NIR[i, ] # changes class from AsIs to matrix
y &lt;- gasoline$octane
#fit &lt;- pfr(y~af(nir,argvals=wavelengths,k=c(6,6), m=list(c(2,2),c(2,2))),
             # subset=(1:N)[-test])
#preds &lt;- predict(fit,newdata=list(nir=nir[test,]),type='response')
#plot(preds,y[test])
#abline(a=0,b=1)
</code></pre>

<hr>
<h2 id='print.summary.pffr'>Print method for summary of a pffr fit</h2><span id='topic+print.summary.pffr'></span>

<h3>Description</h3>

<p>Pretty printing for a <code>summary.pffr</code>-object.
See <code><a href="mgcv.html#topic+print.summary.gam">print.summary.gam</a>()</code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'summary.pffr'
print(
  x,
  digits = max(3, getOption("digits") - 3),
  signif.stars = getOption("show.signif.stars"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.summary.pffr_+3A_x">x</code></td>
<td>
<p>a fitted <code>pffr</code>-object</p>
</td></tr>
<tr><td><code id="print.summary.pffr_+3A_digits">digits</code></td>
<td>
<p>controls number of digits printed in output.</p>
</td></tr>
<tr><td><code id="print.summary.pffr_+3A_signif.stars">signif.stars</code></td>
<td>
<p>Should significance stars be printed alongside output?</p>
</td></tr>
<tr><td><code id="print.summary.pffr_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="#topic+summary.pffr">summary.pffr</a></code> object
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl, adapted from <code><a href="mgcv.html#topic+print.summary.gam">print.summary.gam</a>()</code> by Simon Wood, Henric Nilsson
</p>

<hr>
<h2 id='pwcv'>Pointwise cross-validation for function-on-scalar regression</h2><span id='topic+pwcv'></span>

<h3>Description</h3>

<p>Estimates prediction error for a function-on-scalar regression model by
leave-one-function-out cross-validation (CV), at each of a specified set of
points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pwcv(
  fdobj,
  Z,
  L = NULL,
  lambda,
  eval.pts = seq(min(fdobj$basis$range), max(fdobj$basis$range), length.out = 201),
  scale = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pwcv_+3A_fdobj">fdobj</code></td>
<td>
<p>a functional data object (class <code>fd</code>) giving the
functional responses.</p>
</td></tr>
<tr><td><code id="pwcv_+3A_z">Z</code></td>
<td>
<p>the model matrix, whose columns represent scalar predictors.</p>
</td></tr>
<tr><td><code id="pwcv_+3A_l">L</code></td>
<td>
<p>a row vector or matrix of linear contrasts of the coefficient
functions, to be restricted to equal zero.</p>
</td></tr>
<tr><td><code id="pwcv_+3A_lambda">lambda</code></td>
<td>
<p>smoothing parameter: either a nonnegative scalar or a vector,
of length <code>ncol(Z)</code>, of nonnegative values.</p>
</td></tr>
<tr><td><code id="pwcv_+3A_eval.pts">eval.pts</code></td>
<td>
<p>argument values at which the CV score is to be evaluated.</p>
</td></tr>
<tr><td><code id="pwcv_+3A_scale">scale</code></td>
<td>
<p>logical value or vector determining scaling of the matrix
<code>Z</code> (see <code><a href="base.html#topic+scale">scale</a></code>, to which the value of this argument is
passed).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Integrating the pointwise CV estimate over the function domain yields the
<em>cross-validated integrated squared error</em>, the standard overall model
fit score returned by <code><a href="#topic+lofocv">lofocv</a></code>.
</p>
<p>It may be desirable to derive the value of <code>lambda</code> from an
appropriate call to <code><a href="#topic+fosr">fosr</a></code>, as in the example below.
</p>


<h3>Value</h3>

<p>A vector of the same length as <code>eval.pts</code> giving the CV
scores.
</p>


<h3>Author(s)</h3>

<p>Philip Reiss <a href="mailto:phil.reiss@nyumc.org">phil.reiss@nyumc.org</a>
</p>


<h3>References</h3>

<p>Reiss, P. T., Huang, L., and Mennes, M. (2010).  Fast
function-on-scalar regression with penalized basis expansions.
<em>International Journal of Biostatistics</em>, 6(1), article 28.  Available
at <a href="https://pubmed.ncbi.nlm.nih.gov/21969982/">https://pubmed.ncbi.nlm.nih.gov/21969982/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fosr">fosr</a></code>, <code><a href="#topic+lofocv">lofocv</a></code>
</p>

<hr>
<h2 id='qq.pffr'>QQ plots for pffr model residuals</h2><span id='topic+qq.pffr'></span>

<h3>Description</h3>

<p>This is simply a wrapper for <code><a href="mgcv.html#topic+qq.gam">qq.gam</a>()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qq.pffr(
  object,
  rep = 0,
  level = 0.9,
  s.rep = 10,
  type = c("deviance", "pearson", "response"),
  pch = ".",
  rl.col = 2,
  rep.col = "gray80",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="qq.pffr_+3A_object">object</code></td>
<td>
<p>a fitted <code><a href="#topic+pffr">pffr</a></code>-object</p>
</td></tr>
<tr><td><code id="qq.pffr_+3A_rep">rep</code></td>
<td>
<p>How many replicate datasets to generate to simulate quantiles
of the residual distribution.  <code>0</code> results in an efficient
simulation free method for direct calculation, if this is possible for
the object family.</p>
</td></tr>
<tr><td><code id="qq.pffr_+3A_level">level</code></td>
<td>
<p>If simulation is used for the quantiles, then reference intervals can be provided for the QQ-plot, this specifies the level. 
0 or less for no intervals, 1 or more to simply plot the QQ plot for each replicate generated.</p>
</td></tr>
<tr><td><code id="qq.pffr_+3A_s.rep">s.rep</code></td>
<td>
<p>how many times to randomize uniform quantiles to data under direct computation.</p>
</td></tr>
<tr><td><code id="qq.pffr_+3A_type">type</code></td>
<td>
<p>what sort of residuals should be plotted?  See
<code><a href="mgcv.html#topic+residuals.gam">residuals.gam</a></code>.</p>
</td></tr>
<tr><td><code id="qq.pffr_+3A_pch">pch</code></td>
<td>
<p>plot character to use. 19 is good.</p>
</td></tr>
<tr><td><code id="qq.pffr_+3A_rl.col">rl.col</code></td>
<td>
<p>color for the reference line on the plot.</p>
</td></tr>
<tr><td><code id="qq.pffr_+3A_rep.col">rep.col</code></td>
<td>
<p>color for reference bands or replicate reference plots.</p>
</td></tr>
<tr><td><code id="qq.pffr_+3A_...">...</code></td>
<td>
<p>extra graphics parameters to pass to plotting functions.</p>
</td></tr>
</table>

<hr>
<h2 id='quadWeights'>Compute quadrature weights</h2><span id='topic+quadWeights'></span>

<h3>Description</h3>

<p>Utility function for numerical integration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>quadWeights(argvals, method = "trapezoidal")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="quadWeights_+3A_argvals">argvals</code></td>
<td>
<p>function arguments.</p>
</td></tr>
<tr><td><code id="quadWeights_+3A_method">method</code></td>
<td>
<p>quadrature method. Can be either <code>trapedoidal</code> or <code>midpoint</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector of quadrature weights for the points supplied in <code>argvals</code>.
</p>


<h3>Author(s)</h3>

<p>Clara Happ, with modifications by Philip Reiss
</p>

<hr>
<h2 id='re'>Random effects constructor for fgam</h2><span id='topic+re'></span>

<h3>Description</h3>

<p>Sets up a random effect for the levels of <code>x</code>. 
Use the <code>by</code>-argument to request random slopes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>re(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="re_+3A_x">x</code></td>
<td>
<p>a grouping variable: must be a <code>factor</code></p>
</td></tr>
<tr><td><code id="re_+3A_...">...</code></td>
<td>
<p>further arguments handed over to <code><a href="mgcv.html#topic+s">s</a></code>, 
see <code><a href="mgcv.html#topic+random.effects">random.effects</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="mgcv.html#topic+random.effects">random.effects</a></code> in <span class="pkg">mgcv</span>.
</p>


<h3>See Also</h3>

<p><code><a href="mgcv.html#topic+random.effects">random.effects</a></code>
</p>

<hr>
<h2 id='residuals.pffr'>Obtain residuals and fitted values for a pffr models</h2><span id='topic+residuals.pffr'></span><span id='topic+fitted.pffr'></span>

<h3>Description</h3>

<p>See <code><a href="#topic+predict.pffr">predict.pffr</a></code> for alternative options to extract estimated
values from a <code>pffr</code> object.
&quot;Fitted values&quot; here refers to the estimated additive predictor values,
these will not be on the scale of the response for models with link functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pffr'
residuals(object, reformat = TRUE, ...)

## S3 method for class 'pffr'
fitted(object, reformat = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residuals.pffr_+3A_object">object</code></td>
<td>
<p>a fitted <code>pffr</code>-object</p>
</td></tr>
<tr><td><code id="residuals.pffr_+3A_reformat">reformat</code></td>
<td>
<p>logical, defaults to TRUE. Should residuals be returned in
<code>n x yindex</code> matrix form (regular grid data) or, respectively, in the
shape of the originally supplied <code>ydata</code> argument (sparse/irregular
data), or, if <code>FALSE</code>, simply as a long vector as returned by
<code>resid.gam()</code>?</p>
</td></tr>
<tr><td><code id="residuals.pffr_+3A_...">...</code></td>
<td>
<p>other arguments, passed to <code><a href="mgcv.html#topic+residuals.gam">residuals.gam</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix or <code>ydata</code>-like <code>data.frame</code> or a vector of
residuals / fitted values (see <code>reformat</code>-argument)
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl
</p>

<hr>
<h2 id='rlrt.pfr'>Likelihood Ratio Test and Restricted Likelihood Ratio Test for inference of
functional predictors</h2><span id='topic+rlrt.pfr'></span>

<h3>Description</h3>

<p>NOTE: this function is designed to work with pfr_old() rather than pfr().
Given a pfr object of family=&quot;gaussian&quot;, tests whether the function is
identically equal to its mean (constancy), or whether the functional
predictor significantly improves the model (inclusion).  Based on
zero-variance-component work of Crainiceanu et al. (2004), Scheipl et al.
(2008), and Swihart et al. (2012).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rlrt.pfr(pfr.obj = pfr.obj, test = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rlrt.pfr_+3A_pfr.obj">pfr.obj</code></td>
<td>
<p>an object returned by pfr_old()</p>
</td></tr>
<tr><td><code id="rlrt.pfr_+3A_test">test</code></td>
<td>
<p>&quot;constancy&quot; will test functional form of the coefficient
function of the last function listed in funcs in pfr.obj against the null
of a constant line: the average of the functional predictor.  &quot;inclusion&quot;
will test functional form of the coefficient function of the last function
listed in funcs in pfr.obj against the null of 0: that is, whether the
functional predictor should be included in the model.</p>
</td></tr>
<tr><td><code id="rlrt.pfr_+3A_...">...</code></td>
<td>
<p>additional arguments</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A Penalized Functional Regression of family=&quot;gaussian&quot; can be represented
as a linear mixed model dependent on variance components. Testing whether
certain variance components and (potentially) fixed effect coefficients are
0 correspond to tests of constancy and inclusion of functional predictors.
</p>
<p>For rlrt.pfr, Restricted Likelihood Ratio Test is preferred for the
constancy test as under the special B-splines implementation of pfr for the
coefficient function basis the test involves only the variance component.
Therefore, the constancy test is best for pfr objects with method=&quot;REML&quot;;
if the method was something else, a warning is printed and the model refit
with &quot;REML&quot; and a test is then conducted.
</p>
<p>For rlrt.pfr, the Likelihood Ratio Test is preferred for the inclusion test
as under the special B-splines implementation of pfr for the coefficient
function basis the test involves both the variance component and a fixed
effect coefficient in the linear mixed model representation. Therefore, the
inclusion test is best for pfr objects with method=&quot;ML&quot;; if the method was
something else, a warning is printed and the model refit with &quot;ML&quot; and a
test is then conducted.
</p>


<h3>Value</h3>

<table>
<tr><td><code>p.val</code></td>
<td>
<p>the p-value for the full model (alternative) against
the null specified by the test</p>
</td></tr> <tr><td><code>test.stat</code></td>
<td>
<p>the test statistic, see
Scheipl et al. 2008 and Swihart et al 2012</p>
</td></tr>
<tr><td><code>ma</code></td>
<td>
<p>the alternative model as fit with mgcv::gam</p>
</td></tr> <tr><td><code>m0</code></td>
<td>
<p>the null
model as fit with mgcv::gam</p>
</td></tr> <tr><td><code>m</code></td>
<td>
<p>the model containing only the
parameters being tested as fit with mgcv::gam</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith &lt;jeff.goldsmith@columbia.edu&gt; and Bruce Swihart
&lt;bswihart@jhsph.edu&gt;
</p>


<h3>References</h3>

<p>Goldsmith, J., Bobb, J., Crainiceanu, C., Caffo, B., and Reich,
D. (2011). Penalized functional regression. <em>Journal of Computational
and Graphical Statistics</em>, 20(4), 830&ndash;851.
</p>
<p>Goldsmith, J., Crainiceanu, C., Caffo, B., and Reich, D. (2012).
Longitudinal penalized functional regression for cognitive outcomes on
neuronal tract measurements. <em>Journal of the Royal Statistical
Society: Series C</em>, 61(3), 453&ndash;469.
</p>
<p>Crainiceanu, C. and Ruppert, D. (2004) Likelihood ratio tests in linear
mixed models with one variance component. <em>Journal of the Royal
Statistical Society: Series B</em>, 66, 165&ndash;185.
</p>
<p>Scheipl, F. (2007) Testing for nonparametric terms and random effects in
structured additive regression. Diploma thesis.\
https://www.statistik.lmu.de/~scheipl/downloads/DIPLOM.zip.
</p>
<p>Scheipl, F., Greven, S. and Kuechenhoff, H (2008) Size and power of tests
for a zero random effect variance or polynomial regression in additive and
linear mixed models.  <em>Computational Statistics &amp; Data Analysis</em>,
52(7), 3283&ndash;3299.
</p>
<p>Swihart, Bruce J., Goldsmith, Jeff; and Crainiceanu, Ciprian M. (2012).
Testing for functional effects. Johns Hopkins University Dept. of
Biostatistics Working Paper 247. Available at
<a href="https://biostats.bepress.com/jhubiostat/paper247/">https://biostats.bepress.com/jhubiostat/paper247/</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pfr">pfr</a></code>, <code><a href="#topic+predict.pfr">predict.pfr</a></code>, package
<code>RLRsim</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 
##################################################################
#########               DTI Data Example                 #########
##################################################################

##################################################################
# For more about this example, see Swihart et al. 2012
# Testing for Functional Effects
##################################################################

## load and reassign the data;
data(DTI2)
O  &lt;- DTI2$pasat ## PASAT outcome
id &lt;- DTI2$id    ## subject id
W1 &lt;- DTI2$cca   ## Corpus Callosum
W2 &lt;- DTI2$rcst  ## Right corticospinal
V  &lt;- DTI2$visit ## visit

## prep scalar covariate
visit.1.rest &lt;- matrix(as.numeric(V &gt; 1), ncol=1)
covar.in &lt;- visit.1.rest


## note there is missingness in the functional predictors
apply(is.na(W1), 2, mean)
apply(is.na(W2), 2, mean)

## fit two univariate models, then one model with both functional predictors
pfr.obj.t1 &lt;- pfr_old(Y = O, covariates=covar.in, funcs = list(W1),     subj = id, kz = 10, kb = 50)
pfr.obj.t2 &lt;- pfr_old(Y = O, covariates=covar.in, funcs = list(W2),     subj = id, kz = 10, kb = 50)
pfr.obj.t3 &lt;- pfr_old(Y = O, covariates=covar.in, funcs = list(W1, W2), subj = id, kz = 10, kb = 50)

## plot the coefficient function and bounds
dev.new()
par(mfrow=c(2,2))
ran &lt;- c(-2,.5)
matplot(cbind(pfr.obj.t1$BetaHat[[1]], pfr.obj.t1$Bounds[[1]]),
  type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat",
  main = "CCA", xlab="Location", ylim=ran)
abline(h=0, col="blue")
matplot(cbind(pfr.obj.t2$BetaHat[[1]], pfr.obj.t2$Bounds[[1]]),
  type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat",
  main = "RCST", xlab="Location", ylim=ran)
abline(h=0, col="blue")
matplot(cbind(pfr.obj.t3$BetaHat[[1]], pfr.obj.t3$Bounds[[1]]),
  type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat",
  main = "CCA  - mult.", xlab="Location", ylim=ran)
abline(h=0, col="blue")
matplot(cbind(pfr.obj.t3$BetaHat[[2]], pfr.obj.t3$Bounds[[2]]),
  type = 'l', lty = c(1,2,2), col = c(1,2,2), ylab = "BetaHat",
  main = "RCST - mult.", xlab="Location", ylim=ran)
abline(h=0, col="blue")

## do some testing
t1 &lt;- rlrt.pfr(pfr.obj.t1, "constancy")
t2 &lt;- rlrt.pfr(pfr.obj.t2, "constancy")
t3 &lt;- rlrt.pfr(pfr.obj.t3, "inclusion")

t1$test.stat
t1$p.val

t2$test.stat
t2$p.val

t3$test.stat
t3$p.val


## do some testing with rlrt.pfr(); same as above but subj = NULL
pfr.obj.t1 &lt;- pfr(Y = O, covariates=covar.in, funcs = list(W1),     subj = NULL, kz = 10, kb = 50)
pfr.obj.t2 &lt;- pfr(Y = O, covariates=covar.in, funcs = list(W2),     subj = NULL, kz = 10, kb = 50)
pfr.obj.t3 &lt;- pfr(Y = O, covariates=covar.in, funcs = list(W1, W2), subj = NULL, kz = 10, kb = 50)

t1 &lt;- rlrt.pfr(pfr.obj.t1, "constancy")
t2 &lt;- rlrt.pfr(pfr.obj.t2, "constancy")
t3 &lt;- rlrt.pfr(pfr.obj.t3, "inclusion")

t1$test.stat
t1$p.val

t2$test.stat
t2$p.val

t3$test.stat
t3$p.val

## End(Not run)
</code></pre>

<hr>
<h2 id='sff'>Construct a smooth function-on-function regression term</h2><span id='topic+sff'></span>

<h3>Description</h3>

<p>Defines a term <code class="reqn">\int^{s_{hi, i}}_{s_{lo, i}} f(X_i(s), s, t) ds</code> for
inclusion in an <code>mgcv::gam</code>-formula (or <code>bam</code> or <code>gamm</code> or
<code>gamm4:::gamm</code>) as constructed by <code><a href="#topic+pffr">pffr</a></code>. Defaults to a
cubic tensor product B-spline with marginal second differences penalties for
<code class="reqn">f(X_i(s), s, t)</code> and integration over the entire range <code class="reqn">[s_{lo, i},
s_{hi, i}] = [\min(s_i), \max(s_i)]</code>. Can't deal with any missing <code class="reqn">X(s)</code>,
unequal lengths of <code class="reqn">X_i(s)</code> not (yet?) possible. Unequal ranges for
different <code class="reqn">X_i(s)</code> should work. <code class="reqn">X_i(s)</code> is assumed to be numeric.<br />
<code>sff()</code> IS AN EXPERIMENTAL FEATURE AND NOT WELL TESTED YET &ndash; USE AT
YOUR OWN RISK.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sff(
  X,
  yind,
  xind = seq(0, 1, l = ncol(X)),
  basistype = c("te", "t2", "s"),
  integration = c("simpson", "trapezoidal"),
  L = NULL,
  limits = NULL,
  splinepars = list(bs = "ps", m = c(2, 2, 2))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sff_+3A_x">X</code></td>
<td>
<p>an n by <code>ncol(xind)</code> matrix of function evaluations
<code class="reqn">X_i(s_{i1}),\dots, X_i(s_{iS})</code>; <code class="reqn">i=1,\dots,n</code>.</p>
</td></tr>
<tr><td><code id="sff_+3A_yind">yind</code></td>
<td>
<p><em>DEPRECATED</em> matrix (or vector) of indices of evaluations of
<code class="reqn">Y_i(t)</code>; i.e. matrix with rows <code class="reqn">(t_{i1},\dots,t_{iT})</code>; no longer
used.</p>
</td></tr>
<tr><td><code id="sff_+3A_xind">xind</code></td>
<td>
<p>vector of indices of evaluations of <code class="reqn">X_i(s)</code>,
i.e, <code class="reqn">(s_{1},\dots,s_{S})</code></p>
</td></tr>
<tr><td><code id="sff_+3A_basistype">basistype</code></td>
<td>
<p>defaults to &quot;<code><a href="mgcv.html#topic+te">te</a></code>&quot;, i.e. a tensor product
spline to represent <code class="reqn">f(X_i(s), t)</code>. Alternatively, use <code>"s"</code> for
bivariate basis functions (see <code><a href="mgcv.html#topic+s">s</a></code>) or <code>"t2"</code> for an
alternative parameterization of tensor product splines (see
<code><a href="mgcv.html#topic+t2">t2</a></code>).</p>
</td></tr>
<tr><td><code id="sff_+3A_integration">integration</code></td>
<td>
<p>method used for numerical integration. Defaults to
<code>"simpson"</code>'s rule. Alternatively and for non-equidistant grids,
<code>"trapezoidal"</code>.</p>
</td></tr>
<tr><td><code id="sff_+3A_l">L</code></td>
<td>
<p>optional: an n by <code>ncol(xind)</code> giving the weights for the
numerical integration over <code class="reqn">s</code>.</p>
</td></tr>
<tr><td><code id="sff_+3A_limits">limits</code></td>
<td>
<p>defaults to NULL for integration across the entire range of
<code class="reqn">X(s)</code>, otherwise specifies the integration limits <code class="reqn">s_{hi, i},
s_{lo, i}</code>: either one of <code>"s&lt;t"</code> or <code>"s&lt;=t"</code> for <code class="reqn">(s_{hi,
i}, s_{lo, i}) = (0, t)</code> or a function that takes <code>s</code> as the first and
<code>t</code> as the second argument and returns TRUE for combinations of values
<code>(s,t)</code> if <code>s</code> falls into the integration range for the given
<code>t</code>. This is an experimental feature and not well tested yet; use at
your own risk.</p>
</td></tr>
<tr><td><code id="sff_+3A_splinepars">splinepars</code></td>
<td>
<p>optional arguments supplied to the <code>basistype</code>-term.
Defaults to a cubic tensor product B-spline with marginal second
differences, i.e. <code>list(bs="ps", m=c(2,2,2))</code>. See
<code><a href="mgcv.html#topic+te">te</a></code> or <code><a href="mgcv.html#topic+s">s</a></code> for details</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing </p>
 <ul>
<li> <p><code>call</code> a &quot;call&quot; to
<code><a href="mgcv.html#topic+te">te</a></code> (or <code><a href="mgcv.html#topic+s">s</a></code>, <code><a href="mgcv.html#topic+t2">t2</a></code>)
using the appropriately constructed covariate and weight matrices (see
<code><a href="mgcv.html#topic+linear.functional.terms">linear.functional.terms</a></code>) </p>
</li>
<li> <p><code>data</code> a list
containing the necessary covariate and weight matrices </p>
</li></ul>



<h3>Author(s)</h3>

<p>Fabian Scheipl, based on Sonja Greven's trick for fitting functional
responses.
</p>

<hr>
<h2 id='smooth.construct.dt.smooth.spec'>Domain Transformation basis constructor</h2><span id='topic+smooth.construct.dt.smooth.spec'></span>

<h3>Description</h3>

<p>The <code>dt</code> basis allows for any of the standard <code>mgcv</code> (or
user-defined) bases to be aplied to a transformed version of the
original terms. Smooths may be of any number of terms. Transformations
are specified by supplying a function of any or all of the original terms.
&quot;<code>by</code>&quot; variables are not transformed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'dt.smooth.spec'
smooth.construct(object, data, knots)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.construct.dt.smooth.spec_+3A_object">object</code></td>
<td>
<p>a smooth specification object, generated by <code>s()</code>,
<code>te()</code>, <code>ti()</code>, or <code>t2()</code>, with <code>bs="dt"</code></p>
</td></tr>
<tr><td><code id="smooth.construct.dt.smooth.spec_+3A_data">data</code></td>
<td>
<p>a list containing just the data (including any by variable)
required by this term, with names corresponding to <code>object$term</code>
(and <code>object$by</code>). The <code>by</code> variable is the last element.</p>
</td></tr>
<tr><td><code id="smooth.construct.dt.smooth.spec_+3A_knots">knots</code></td>
<td>
<p>a list containing any knots supplied for basis setup - in same
order and with same names as <code>data</code>. Can be <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>object</code> should be creaated with an <code>xt</code> argument. For
non-tensor-product smooths, this will be a list with the following elements:
</p>

<ol>
<li> <p><code>tf</code> (required): a function or character string (or list of functions
and/or character strings) defining the coordinate transformations; see
further details below.
</p>
</li>
<li> <p><code>bs</code> (optional): character string indicating the <code>bs</code> for
the basis applied to the transformed coordinates; if empty, the appropriate
defaults are used.
</p>
</li>
<li> <p><code>basistype</code> (optional): character string indicating type of
bivariate basis used. Options include <code>"s"</code> (the default), <code>"te"</code>,
<code>"ti"</code>, and <code>"t2"</code>, which correspond to <code><a href="mgcv.html#topic+s">s</a></code>,
<code><a href="mgcv.html#topic+te">te</a></code>, <code><a href="mgcv.html#topic+ti">ti</a></code>, and <code><a href="mgcv.html#topic+t2">t2</a></code>.
</p>
</li>
<li> <p><code>...</code> (optional): for tensor product smooths, additional arguments
to the function specified by <code>basistype</code> that are not available in
<code>s()</code> can be included here, e.g. <code>d</code>, <code>np</code>, etc.
</p>
</li></ol>

<p>For tensor product smooths, we recommend using <code>s()</code> to set up the basis,
and specifying the tensor product using <code>xt$basistype</code> as described
above. If the basis is set up using <code>te()</code>, then the variables in
<code>object$term</code> will be split up, meaning all transformation functions
would have to be univariate.
</p>


<h3>Value</h3>

<p>An object of class &quot;dt.smooth&quot;. This will contain all the elements
associated with the <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code> object from the
inner smooth (defined by <code>xt$bs</code>), in addition to an <code>xt</code>
element used by the <code>Predict.matrix</code> method.
</p>


<h3>Transformation Functions</h3>

<p>Let <code>nterms = length(object$term)</code>. The <code>tf</code> element can take one
of the following forms:
</p>

<ol>
<li><p> a function of <code>nargs</code> arguments, where <code>nargs &lt;= nterms</code>.
If <code>nterms &gt; 1</code>, it is assumed that this function will be applied to
the first term of <code>object$term</code>. If all argument names of the
function are term names, then those arguments will correspond to those
terms; otherwise, they will correspond to the first <code>nargs</code> terms in
<code>object$term</code>.
</p>
</li>
<li><p> a character string corresponding to one of the built-in
transformations (listed below).
</p>
</li>
<li><p> A list of length <code>ntfuncs</code>, where <code>ntfuncs&lt;=nterms</code>,
containing either the functions or character strings described above. If
this list is named with term names, then the transformation functions
will be applied to those terms; otherwise, they will be applied to the
first <code>ntfuncs</code> terms in <code>object$term</code>.
</p>
</li></ol>

<p>The following character strings are recognized as built-in transformations:
</p>

<ul>
<li> <p><code>"log"</code>: log transformation (univariate)
</p>
</li>
<li> <p><code>"ecdf"</code>: empirical cumulative distribution function (univariate)
</p>
</li>
<li> <p><code>"linear01"</code>: linearly rescale from 0 to 1 (univariate)
</p>
</li>
<li> <p><code>"s-t"</code>: first term (&quot;s&quot;) minus the second term (&quot;t&quot;) (bivariate)
</p>
</li>
<li> <p><code>"s/t"</code>: first term (&quot;s&quot;) divided by the second term (&quot;t&quot;) (bivariate)
</p>
</li>
<li> <p><code>"QTransform"</code>: performs a time-specific ecdf transformation for
a bivariate smooth, where time is indicated by the first term, and
<code class="reqn">x</code> by the second term. Primarily for use with <code>refund::af</code>.
</p>
</li></ul>

<p>Some transformations rely on a fixed &quot;pivot point&quot; based on the data used to
fit the model, e.g. quantiles (such as the min or max) of this data.
When making predictions based on these transformations, the transformation
function will need to know what the pivot points are, based on the original
(not prediction) data. In order to accomplish this, we allow the user to
specify that they want their transformation function to refer to the original
data (as opposed to whatever the &quot;current&quot; data is). This is done by appending
a zero (&quot;0&quot;) to the argument name.
</p>
<p>For example, suppose you want to scale
the term linearly so that the data used to define the basis ranges from
0 to 1. The wrong way to define this transformation function:
<code>function(x) {(x - min(x))/(max(x) - min(x))}</code>.
This function will result in incorrect predictions if the range of data for
which preditions are being made is not the same as the range of data that was
used to define the basis. The proper way to define this function:
<code>function(x) {(x - min(x0))/(max(x0) - min(x0))}</code>.
By refering to <code>x0</code> instead of <code>x</code>, you are indicating that you
want to use the original data instead of the current data. This may seem
strange to refer to a variable that is not one of the arguments, but the
<code>"dt"</code> constructor explicitly places these variables in the environment
of the transformation function to make them available.
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar
</p>


<h3>See Also</h3>

<p><code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code>
</p>

<hr>
<h2 id='smooth.construct.fpc.smooth.spec'>Basis constructor for FPC terms</h2><span id='topic+smooth.construct.fpc.smooth.spec'></span>

<h3>Description</h3>

<p>Basis constructor for FPC terms
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fpc.smooth.spec'
smooth.construct(object, data, knots)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.construct.fpc.smooth.spec_+3A_object">object</code></td>
<td>
<p>a <code>fpc.smooth.spec</code> object, usually generated by a 
term <code>s(x, bs="fpc")</code>; see Details.</p>
</td></tr>
<tr><td><code id="smooth.construct.fpc.smooth.spec_+3A_data">data</code></td>
<td>
<p>a list containing the data (including any <code>by</code> variable)
required by this term, with names corresponding to <code>object$term</code>
(and <code>object$by</code>). Only the first element of this list is used.</p>
</td></tr>
<tr><td><code id="smooth.construct.fpc.smooth.spec_+3A_knots">knots</code></td>
<td>
<p>not used, but required by the generic <code>smooth.construct</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>object</code> must contain an <code>xt</code> element. This is a list that can
contain the following elements:
</p>

<dl>
<dt>X</dt><dd><p>(required) matrix of functional predictors</p>
</dd>
<dt>method</dt><dd><p>(required) the method of finding principal components;
options include <code>"svd"</code> (unconstrained), <code>"fpca.sc"</code>,
<code>"fpca.face"</code>, or <code>"fpca.ssvd"</code></p>
</dd>
<dt>npc</dt><dd><p>(optional) the number of PC's to retain</p>
</dd>
<dt>pve</dt><dd><p>(only needed if <code>npc</code> not supplied) the percent variance
explained used to determine <code>npc</code></p>
</dd>
<dt>penalize</dt><dd><p>(required) if <code>FALSE</code>, the smoothing parameter is
set to 0</p>
</dd>
<dt>bs</dt><dd><p>the basis class used to pre-smooth <code>X</code>; default is <code>"ps"</code></p>
</dd>
</dl>

<p>Any additional options for the pre-smoothing basis (e.g. <code>k</code>, <code>m</code>,
etc.) can be supplied in the corresponding elements of <code>object</code>.
See <code><a href="mgcv.html#topic+s">s</a></code> for a full list of options.
</p>


<h3>Value</h3>

<p>An object of class <code>"fpc.smooth"</code>. In addtional to the elements
listed in <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code>, the object will contain
</p>
<table>
<tr><td><code>sm</code></td>
<td>
<p>the smooth that is fit in order to generate the basis matrix
over <code>object$term</code></p>
</td></tr>
<tr><td><code>V.A</code></td>
<td>
<p>the matrix of principal components</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jonathan Gellar <a href="mailto:JGellar@mathematica-mpr.com">JGellar@mathematica-mpr.com</a>
</p>


<h3>References</h3>

<p>Reiss, P. T., and Ogden, R. T. (2007). Functional principal component
regression and functional partial least squares. <em>Journal of the
American Statistical Association</em>, 102, 984-996.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fpcr">fpcr</a></code>
</p>

<hr>
<h2 id='smooth.construct.pco.smooth.spec'>Principal coordinate ridge regression</h2><span id='topic+smooth.construct.pco.smooth.spec'></span><span id='topic+pco'></span><span id='topic+Predict.matrix.pco.smooth'></span><span id='topic+poridge'></span>

<h3>Description</h3>

<p>Smooth constructor function for principal coordinate ridge regression fitted
by <code><a href="mgcv.html#topic+gam">gam</a></code>. When the principal coordinates are defined by a
relevant distance among functional predictors, this is a form of nonparametric
scalar-on-function regression. Reiss et al. (2016) describe the approach and
apply it to dynamic time warping distances among functional predictors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pco.smooth.spec'
smooth.construct(object, data, knots)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.construct.pco.smooth.spec_+3A_object">object</code></td>
<td>
<p>a smooth specification object, usually generated by a term of
the form <code>s(dummy, bs="pco", k, xt)</code>; see Details.</p>
</td></tr>
<tr><td><code id="smooth.construct.pco.smooth.spec_+3A_data">data</code></td>
<td>
<p>a list containing just the data.</p>
</td></tr>
<tr><td><code id="smooth.construct.pco.smooth.spec_+3A_knots">knots</code></td>
<td>
<p>IGNORED!</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>pco.smooth</code>. The resulting object has an
<code>xt</code> element which contains details of the multidimensional scaling,
which may be interesting.
</p>


<h3>Details</h3>

<p>The constructor is not normally called directly, but is
rather used internally by <code><a href="mgcv.html#topic+gam">gam</a></code>.
</p>
<p>In a <code><a href="mgcv.html#topic+gam">gam</a></code> term of the above form <code>s(dummy, bs="pco",
 k, xt)</code>, </p>
 <ul>
<li> <p><code>dummy</code> is an arbitrary vector (or name of a
column in <code>data</code>) whose length is the number of observations. This is
not actually used, but is required as part of the input to
<code><a href="mgcv.html#topic+s">s</a></code>. Note that if multiple <code>pco</code> terms are used in
the model, there must be multiple unique term names (e.g., &quot;<code>dummy1</code>&quot;,
&quot;<code>dummy2</code>&quot;, etc). </p>
</li>
<li> <p><code>k</code> is the number of principal coordinates
(e.g., <code>k=9</code> will give a 9-dimensional projection of the data). </p>
</li>
<li>
<p><code>xt</code> is a list supplying the distance information, in one of two ways.
(i) A matrix <code>Dmat</code> of distances can be supplied directly via
<code>xt=list(D=Dmat,...)</code>. (ii) Alternatively, one can use
<code>xt=list(realdata=..., dist_fn=..., ...)</code> to specify a data
matrix <code>realdata</code> and distance function <code>dist_fn</code>, whereupon a
distance matrix <code>dist_fn(realdata)</code> is created. </p>
</li></ul>
<p> The list <code>xt</code>
also has the following optional elements: </p>
 <ul>
<li> <p><code>add</code>: Passed
to <code><a href="stats.html#topic+cmdscale">cmdscale</a></code> when performing multidimensional scaling; for
details, see the help for that function. (Default <code>FALSE</code>.)<br /> </p>
</li>
<li>
<p><code>fastcmd</code>: if <code>TRUE</code>, multidimensional scaling is performed by
<code><a href="#topic+cmdscale_lanczos">cmdscale_lanczos</a></code>, which uses Lanczos iteration to
eigendecompose the distance matrix; if <code>FALSE</code>, MDS is carried out by
<code><a href="stats.html#topic+cmdscale">cmdscale</a></code>. Default is <code>FALSE</code>, to use <code>cmdscale</code>. </p>
</li></ul>



<h3>Author(s)</h3>

<p>David L Miller, based on code from Lan Huo and Phil Reiss
</p>


<h3>References</h3>

<p>Reiss, P. T., Miller, D. L., Wu, P.-S., and Wen-Yu Hua, W.-Y.
Penalized nonparametric scalar-on-function regression via principal
coordinates. Under revision. Available at
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5714326/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5714326/</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# a simulated example
library(refund)
library(mgcv)
require(dtw)

## First generate the data
Xnl &lt;- matrix(0, 30, 101)
set.seed(813)
tt &lt;- sort(sample(1:90, 30))
for(i in 1:30){
  Xnl[i, tt[i]:(tt[i]+4)] &lt;- -1
  Xnl[i, (tt[i]+5):(tt[i]+9)] &lt;- 1
}
X.toy &lt;- Xnl + matrix(rnorm(30*101, ,0.05), 30)
y.toy &lt;- tt + rnorm(30, 0.05)
y.rainbow &lt;- rainbow(30, end=0.9)[(y.toy-min(y.toy))/
                                   diff(range(y.toy))*29+1]

## Display the toy data
par(mfrow=c(2, 2))
matplot((0:100)/100, t(Xnl[c(4, 25), ]), type="l", xlab="t", ylab="",
        ylim=range(X.toy), main="Noiseless functions")
matplot((0:100)/100, t(X.toy[c(4, 25), ]), type="l", xlab="t", ylab="",
        ylim=range(X.toy), main="Observed functions")
matplot((0:100)/100, t(X.toy), type="l", lty=1, col=y.rainbow, xlab="t",
        ylab="", main="Rainbow plot")

## Obtain DTW distances
D.dtw &lt;- dist(X.toy, method="dtw", window.type="sakoechiba", window.size=5)

## Compare PC vs. PCo ridge regression

# matrix to store results
GCVmat &lt;- matrix(NA, 15, 2)
# dummy response variable
dummy &lt;- rep(1,30)

# loop over possible projection dimensions
for (k. in 1:15){
  # fit PC (m1) and PCo (m2) ridge regression
  m1 &lt;- gam(y.toy ~ s(dummy, bs="pco", k=k.,
            xt=list(realdata=X.toy, dist_fn=dist)), method="REML")
  m2 &lt;- gam(y.toy ~ s(dummy, bs="pco", k=k., xt=list(D=D.dtw)), method="REML")
  # calculate and store GCV scores
  GCVmat[k., ] &lt;- length(y.toy) * c(sum(m1$residuals^2)/m1$df.residual^2,
                   sum(m2$residuals^2)/m2$df.residual^2)
}

## plot the GCV scores per dimension for each model
matplot(GCVmat, lty=1:2, col=1, pch=16:17, type="o", ylab="GCV",
        xlab="Number of principal components / coordinates",
        main="GCV score")
legend("right", c("PC ridge regression", "DTW-based PCoRR"), lty=1:2, pch=16:17)

## example of making a prediction

# fit a model to the toy data
m &lt;- gam(y.toy ~ s(dummy, bs="pco", k=2, xt=list(D=D.dtw)), method="REML")

# first build the distance matrix
# in this case we just subsample the original matrix
# see ?pco_predict_preprocess for more information on formatting this data
dist_list &lt;- list(dummy = as.matrix(D.dtw)[, c(1:5,10:15)])

# preprocess the prediction data
pred_data &lt;- pco_predict_preprocess(m, newdata=NULL, dist_list)

# make the prediction
p &lt;- predict(m, pred_data)

# check that these are the same as the corresponding fitted values
print(cbind(fitted(m)[ c(1:5,10:15)],p))


## End(Not run)
</code></pre>

<hr>
<h2 id='smooth.construct.pcre.smooth.spec'>mgcv-style constructor for PC-basis functional random effects</h2><span id='topic+smooth.construct.pcre.smooth.spec'></span>

<h3>Description</h3>

<p>Sets up design matrix for functional random effects based on the PC scores
of the covariance operator of the random effect process.
See <code><a href="mgcv.html#topic+smooth.construct.re.smooth.spec">smooth.construct.re.smooth.spec</a></code> for more details on <code>mgcv</code>-style smoother specification
and <code><a href="#topic+pcre">pcre</a></code> for the corresponding <code>pffr()</code>-formula wrapper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pcre.smooth.spec'
smooth.construct(object, data, knots)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.construct.pcre.smooth.spec_+3A_object">object</code></td>
<td>
<p>a smooth specification object, see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
<tr><td><code id="smooth.construct.pcre.smooth.spec_+3A_data">data</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
<tr><td><code id="smooth.construct.pcre.smooth.spec_+3A_knots">knots</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"random.effect"</code>. See <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code>
for the elements that this object will contain.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl;  adapted from 're' constructor by S.N. Wood.
</p>

<hr>
<h2 id='smooth.construct.peer.smooth.spec'>Basis constructor for PEER terms</h2><span id='topic+smooth.construct.peer.smooth.spec'></span>

<h3>Description</h3>

<p>Smooth basis constructor to define structured penalties (Randolph et al.,
2012) for smooth terms.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'peer.smooth.spec'
smooth.construct(object, data, knots)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.construct.peer.smooth.spec_+3A_object">object</code></td>
<td>
<p>a <code>peer.smooth.spec</code> object, usually generated by a 
term <code>s(x, bs="peer")</code>; see Details.</p>
</td></tr>
<tr><td><code id="smooth.construct.peer.smooth.spec_+3A_data">data</code></td>
<td>
<p>a list containing the data (including any <code>by</code> variable)
required by this term, with names corresponding to <code>object$term</code>
(and <code>object$by</code>). Only the first element of this list is used.</p>
</td></tr>
<tr><td><code id="smooth.construct.peer.smooth.spec_+3A_knots">knots</code></td>
<td>
<p>not used, but required by the generic <code>smooth.construct</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The smooth specification object, defined using <code>s()</code>, should
contain an <code>xt</code> element. <code>xt</code> will be a list that contains
additional information needed to specify the penalty. The type of penalty
is indicated by <code>xt$pentype</code>. There are four types of penalties
available:
</p>

<ol>
<li> <p><code>xt$pentype=="RIDGE"</code> for a ridge penalty, the default
</p>
</li>
<li> <p><code>xt$pentype=="D"</code> for a difference penalty. The order of the
difference penalty is specified by the <code>m</code> argument of
<code>s()</code>.
</p>
</li>
<li> <p><code>xt$pentype=="DECOMP"</code> for a decomposition-based penalty,
<code class="reqn">bP_Q + a(I-P_Q)</code>, where <code class="reqn">P_Q = Q^t(QQ^t)^{-1}Q</code>. The <code class="reqn">Q</code>
matrix must be specified by <code>xt$Q</code>, and the scalar <code class="reqn">a</code> by
<code>xt$phia</code>. The number of columns of <code>Q</code> must be equal to the
length of the data. Each row represents a basis function where the
functional predictor is expected to lie, according to prior belief.
</p>
</li>
<li> <p><code>xt$pentype=="USER"</code> for a user-specified penalty matrix
<code class="reqn">L</code>, supplied by <code>xt$L</code>.
</p>
</li></ol>



<h3>Value</h3>

<p>An object of class <code>"peer.smooth"</code>. See
<code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code> for the elements that this object will
contain.
</p>


<h3>Author(s)</h3>

<p>Madan Gopal Kundu <a href="mailto:mgkundu@iupui.edu">mgkundu@iupui.edu</a> and Jonathan Gellar
</p>


<h3>References</h3>

<p>Randolph, T. W., Harezlak, J, and Feng, Z. (2012). Structured penalties for
functional linear models - partially empirical eigenvectors for regression.
<em>Electronic Journal of Statistics</em>, 6, 323-353.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+peer">peer</a></code>
</p>

<hr>
<h2 id='smooth.construct.pi.smooth.spec'>Parametric Interaction basis constructor</h2><span id='topic+smooth.construct.pi.smooth.spec'></span>

<h3>Description</h3>

<p>The <code>pi</code> basis is appropriate for smooths of multiple variables. Its
purpose is to parameterize the way in which the basis changes with one of
those variables. For example, suppose the smooth is over three variables,
<code class="reqn">x</code>, <code class="reqn">y</code>, and <code class="reqn">t</code>, and we want to parameterize the effect of
<code class="reqn">t</code>. Then the <code>pi</code> basis will assume <code class="reqn">f(x,y,t) = \sum_k
g_k(t)*f_k(x,y)</code>, where the <code class="reqn">g_k(t)</code> functions are pre-specified and the
<code class="reqn">f_k(x,y)</code> functions are estimated using a bivariate basis. An example of
a parametric interaction is a linear interaction, which would take the form
<code class="reqn">f(x,y,t) = f_1(x,y) + t*f_2(x,y)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pi.smooth.spec'
smooth.construct(object, data, knots)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.construct.pi.smooth.spec_+3A_object">object</code></td>
<td>
<p>a smooth specification object, generated by, e.g.,
<code>s(x, y, t, bs="pi", xt=list(g=list(g1, g2, g3)))</code>. For
transformation functions <code>g1</code>, <code>g2</code>, and <code>g3</code>, see
Details below.</p>
</td></tr>
<tr><td><code id="smooth.construct.pi.smooth.spec_+3A_data">data</code></td>
<td>
<p>a list containing the variables of the smooth (<code>x</code>,
<code>y</code>, and <code>t</code> above), as well as any <code>by</code> variable.</p>
</td></tr>
<tr><td><code id="smooth.construct.pi.smooth.spec_+3A_knots">knots</code></td>
<td>
<p>a list containing any knots supplied for basis setup - in same
order and with same names as <code>data</code>. Can be <code>NULL</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All functions <code class="reqn">f_k()</code> are defined using the same basis set.
Accordingly, they are penalized using a single block-diagonal penalty matrix
and one smoothing parameter. Future versions of this function may be able
to relax this assumption.
</p>
<p><code>object</code> should be defined (using <code>s()</code>) with an <code>xt</code>
argument. This argument is a list that could contain any of the following
elements:
</p>

<ol>
<li> <p><code>g</code>: the functions <code class="reqn">g_k(t)</code>, specified as described below.
</p>
</li>
<li> <p><code>bs</code>: the basis code used for the functions <code class="reqn">f_k()</code>; defaults
to thin-plate regression splines, which is mgcv's default. The same
basis will be used for all <code class="reqn">k</code>.
</p>
</li>
<li> <p><code>idx</code>: an integer index indicating which variable from
<code>object$term</code> is to be parameterized, i.e., the <code class="reqn">t</code> variable;
defaults to <code>length(object$term)</code>
</p>
</li>
<li> <p><code>mp</code>: flag to indicate whether multiple penalties should
be estimated, one for each <code class="reqn">f_k()</code>. Defaults to <code>TRUE</code>. If
<code>FALSE</code>, the penalties for each <code class="reqn">k</code> are combined into a single
block-diagonal penalty matrix (with one smoothing parameter).
</p>
</li>
<li> <p><code>...</code>: further <code>xt</code> options to be passed onto the basis for
<code class="reqn">f_k()</code>.
</p>
</li></ol>

<p><code>xt$g</code> can be entered in one of the following forms:
</p>

<ol>
<li><p> a list of functions of length <code class="reqn">k</code>, where each function is of
one argument (assumed to be <code class="reqn">t</code>)
</p>
</li>
<li><p> one of the following recognized character strings: <code>"linear"</code>,
indicating a linear interaction, i.e. <code class="reqn">f(x,t) = f_1(x)+t*f_2(x)</code>;
<code>"quadratic"</code>, indicating a quadratic interaction, i.e.
<code class="reqn">f(x,t) = f_1(x)+t*f_2(x) + t^2*f_3(x)</code>; or
<code>"none"</code>, indicating no interaction with <code class="reqn">t</code>, i.e.
<code class="reqn">f(x,t)=f_1(x)</code>.
</p>
</li></ol>

<p>The only one of the above elements that is required is <code>xt</code>.
If default values for <code>bs</code>, <code>idx</code>, and <code>mp</code> are desired,
<code>xt</code> may also be entered as the <code>g</code> element itself; i.e.
<code>xt=g</code>, where <code>g</code> is either the list of functions or an acceptable
character string.
</p>
<p>Additional arguments for the lower-dimensional basis over <code>f_k</code> may
be entered using the corresponding arguments of <code>s()</code>, e.g.
<code>k</code>, <code>m</code>, <code>sp</code>, etc. For example,
<code>s(x, t, bs="pi", k=15, xt=list(g="linear", bs="ps"))</code>
will define a linear interaction with <code>t</code> of a univariate p-spline
basis of dimension 15 over <code>x</code>.
</p>


<h3>Value</h3>

<p>An object of class &quot;pi.smooth&quot;. See
<code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code> for the elements it will contain.
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl and Jonathan Gellar
</p>

<hr>
<h2 id='smooth.construct.pss.smooth.spec'>P-spline constructor with modified 'shrinkage' penalty</h2><span id='topic+smooth.construct.pss.smooth.spec'></span>

<h3>Description</h3>

<p>Construct a B-spline basis with a modified difference penalty
of full rank (i.e., that also penalizes low-order polynomials).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pss.smooth.spec'
smooth.construct(object, data, knots)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="smooth.construct.pss.smooth.spec_+3A_object">object</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code>. The shrinkage factor can be specified via <code>object$xt$shrink</code></p>
</td></tr>
<tr><td><code id="smooth.construct.pss.smooth.spec_+3A_data">data</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code>.</p>
</td></tr>
<tr><td><code id="smooth.construct.pss.smooth.spec_+3A_knots">knots</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+smooth.construct">smooth.construct</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This penalty-basis combination is useful to avoid non-identifiability issues for <code><a href="#topic+ff">ff</a></code> terms.
See 'ts' or 'cs' in <code><a href="mgcv.html#topic+smooth.terms">smooth.terms</a></code>
for similar &quot;shrinkage penalties&quot; for thin plate and cubic regression splines.
The basic idea is to replace the k-th zero eigenvalue of the original penalty by
<code class="reqn">s^k \nu_m</code>, where <code class="reqn">s</code> is the shrinkage factor (defaults to 0.1)
and <code class="reqn">\nu_m</code> is the smallest non-zero eigenvalue. See reference for the
original idea, implementation follows that in the 'ts' and 'cs' constructors
(see <code><a href="mgcv.html#topic+smooth.terms">smooth.terms</a></code>).
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl;  adapted from 'ts' and 'cs' constructors by S.N. Wood.
</p>


<h3>References</h3>

<p>Marra, G., &amp; Wood, S. N. (2011). Practical variable selection for generalized additive models.
<em>Computational Statistics &amp; Data Analysis</em>, 55(7), 2372-2387.
</p>

<hr>
<h2 id='sofa'>SOFA (Sequential Organ Failure Assessment) Data</h2><span id='topic+sofa'></span>

<h3>Description</h3>

<p>A dataset containing the SOFA scores (Vincent et al, 1996). for 520 patients,
hospitalized in the intensive care unit (ICU) with Acute Lung Injury. Daily
measurements are available for as long as each one remains in the ICU. This is an
example of variable-domain functional data, as described by Gellar et al. (2014).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sofa
</code></pre>


<h3>Format</h3>

<p>A data frame with 520 rows (subjects) and 7 variables:
</p>

<dl>
<dt>death</dt><dd><p>binary indicator that the subject died in the ICU</p>
</dd>
<dt>SOFA</dt><dd><p>520 x 173 matrix in variable-domain format (a ragged array). 
Each column represents an ICU day. Each row contains the SOFA scores for
a subject, one per day, for as long as the subject remained in the ICU.
The remaining cells of each row are padded with <code>NA</code>s. SOFA scores
range from 0 to 24, increasing with severity of organ failure. Missing
values during one's ICU stay have been imputed using LOCF.</p>
</dd>
<dt>SOFA_raw</dt><dd><p>Identical to the <code>SOFA</code> element, except that it contains
some missing values during one's hospitalization. These missing values
arise when a subject leaves the ICU temporarily, only to be re-admitted.
SOFA scores are not monitored outside the ICU.</p>
</dd>
<dt>los</dt><dd><p>ICU length of stay, i.e., the number of days the patient remained
in the ICU prior to death or final discharge.</p>
</dd>
<dt>age</dt><dd><p>Patient age</p>
</dd>
<dt>male</dt><dd><p>Binary indicator for male gender</p>
</dd>
<dt>Charlson</dt><dd><p>Charlson co-morbidity index, a measure of baseline health
status (before hospitalization and ALI).</p>
</dd>
</dl>



<h3>Details</h3>

<p>The data was collected as part of the Improving Care of ALI Patients (ICAP)
study (Needham et al., 2006). If you use this dataset as an example in
written work, please cite the study protocol.
</p>


<h3>References</h3>

<p>Vincent, JL, Moreno, R, Takala, J, Willatts, S, De Mendonca, A,
Bruining, H, Reinhart, CK, Suter, PM, Thijs, LG (1996). The SOFA ( Sepsis
related Organ Failure Assessment) score to describe organ
dysfunction/failure. Intensive Care Medicine, 22(7): 707-710.
</p>
<p>Needham, D. M., Dennison, C. R., Dowdy, D. W., Mendez-Tellez, P. A.,
Ciesla, N., Desai, S. V., Sevransky, J., Shanholtz, C., Scharfstein, D.,
Herridge, M. S., and Pronovost, P. J. (2006). Study protocol: The
Improving Care of Acute Lung Injury Patients (ICAP) study. Critical Care
(London, England), 10(1), R9.
</p>
<p>Gellar, Jonathan E., Elizabeth Colantuoni, Dale M. Needham, and
Ciprian M. Crainiceanu. Variable-Domain Functional Regression for Modeling
ICU Data. Journal of the American Statistical Association,
109(508):1425-1439, 2014.
</p>

<hr>
<h2 id='summary.pffr'>Summary for a pffr fit</h2><span id='topic+summary.pffr'></span>

<h3>Description</h3>

<p>Take a fitted <code>pffr</code>-object and produce summaries from it.
See <code><a href="mgcv.html#topic+summary.gam">summary.gam</a>()</code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pffr'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pffr_+3A_object">object</code></td>
<td>
<p>a fitted <code>pffr</code>-object</p>
</td></tr>
<tr><td><code id="summary.pffr_+3A_...">...</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+summary.gam">summary.gam</a>()</code> for options.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with summary information, see <code><a href="mgcv.html#topic+summary.gam">summary.gam</a>()</code>
</p>


<h3>Author(s)</h3>

<p>Fabian Scheipl, adapted from <code><a href="mgcv.html#topic+summary.gam">summary.gam</a>()</code> by Simon Wood, Henric Nilsson
</p>

<hr>
<h2 id='summary.pfr'>Summary for a pfr fit</h2><span id='topic+summary.pfr'></span>

<h3>Description</h3>

<p>Take a fitted <code>pfr</code>-object and produce summaries from it.
See <code><a href="mgcv.html#topic+summary.gam">summary.gam</a>()</code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'pfr'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.pfr_+3A_object">object</code></td>
<td>
<p>a fitted <code>pfr</code>-object</p>
</td></tr>
<tr><td><code id="summary.pfr_+3A_...">...</code></td>
<td>
<p>see <code><a href="mgcv.html#topic+summary.gam">summary.gam</a>()</code> for options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function currently simply strips the <code>"pfr"</code> class label and
calls <code><a href="mgcv.html#topic+summary.gam">summary.gam</a></code>.
</p>


<h3>Value</h3>

<p>A list with summary information, see <code><a href="mgcv.html#topic+summary.gam">summary.gam</a>()</code>
</p>


<h3>Author(s)</h3>

<p>Jonathan Gellar <a href="mailto:JGellar@mathematica-mpr.com">JGellar@mathematica-mpr.com</a>, Fabian Scheipl
</p>

<hr>
<h2 id='vb_cs_fpca'>Cross-sectional FoSR using Variational Bayes and FPCA</h2><span id='topic+vb_cs_fpca'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for cross-sectional data.
This function estimates model parameters using a VB and estimates
the residual covariance surface using FPCA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vb_cs_fpca(
  formula,
  data = NULL,
  verbose = TRUE,
  Kt = 5,
  Kp = 2,
  alpha = 0.1,
  Aw = NULL,
  Bw = NULL,
  Apsi = NULL,
  Bpsi = NULL,
  argvals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vb_cs_fpca_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the 
variables in the model. If not found in data, the variables are taken from 
environment(formula), typically the environment from which the function is 
called.</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_kp">Kp</code></td>
<td>
<p>number of FPCA basis functions to be estimated</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter balancing second-derivative penalty and
zeroth-derivative penalty (alpha = 0 is all second-derivative penalty)</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_aw">Aw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_bw">Bw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_apsi">Apsi</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for FPC effects</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_bpsi">Bpsi</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for FPC effects</p>
</td></tr>
<tr><td><code id="vb_cs_fpca_+3A_argvals">argvals</code></td>
<td>
<p>not currently implemented</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='vb_cs_wish'>Cross-sectional FoSR using Variational Bayes and Wishart prior</h2><span id='topic+vb_cs_wish'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for cross-sectional data.
This function estimates model parameters using VB and estimates
the residual covariance surface using a Wishart prior.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vb_cs_wish(
  formula,
  data = NULL,
  verbose = TRUE,
  Kt = 5,
  alpha = 0.1,
  min.iter = 10,
  max.iter = 50,
  Aw = NULL,
  Bw = NULL,
  v = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vb_cs_wish_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="vb_cs_wish_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the 
variables in the model. If not found in data, the variables are taken from 
environment(formula), typically the environment from which the function is 
called.</p>
</td></tr>
<tr><td><code id="vb_cs_wish_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
<tr><td><code id="vb_cs_wish_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="vb_cs_wish_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter balancing second-derivative penalty and
zeroth-derivative penalty (alpha = 0 is all second-derivative penalty)</p>
</td></tr>
<tr><td><code id="vb_cs_wish_+3A_min.iter">min.iter</code></td>
<td>
<p>minimum number of iterations of VB algorithm</p>
</td></tr>
<tr><td><code id="vb_cs_wish_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations of VB algorithm</p>
</td></tr>
<tr><td><code id="vb_cs_wish_+3A_aw">Aw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects; if <code>NULL</code>, defaults to <code>Kt/2</code>.</p>
</td></tr>
<tr><td><code id="vb_cs_wish_+3A_bw">Bw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects; if <code>NULL</code>, defaults to 
1/2 tr(mu.q.beta 
of the model</p>
</td></tr>
<tr><td><code id="vb_cs_wish_+3A_v">v</code></td>
<td>
<p>hyperparameter for inverse Wishart prior on residual covariance; if <code>NULL</code>,
Psi defaults to an FPCA decomposition of the residual covariance in which residuals are 
estimated based on an OLS fit of the model (note the &quot;nugget effect&quot; on this covariance
is assumed to be constant over the time domain).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='vb_mult_fpca'>Multilevel FoSR using Variational Bayes and FPCA</h2><span id='topic+vb_mult_fpca'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for multilevel data.
This function estimates model parameters using a VB and estimates
the residual covariance surface using FPCA.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vb_mult_fpca(
  formula,
  data = NULL,
  verbose = TRUE,
  Kt = 5,
  Kp = 2,
  alpha = 0.1,
  argvals = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vb_mult_fpca_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="vb_mult_fpca_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the 
variables in the model. If not found in data, the variables are taken from 
environment(formula), typically the environment from which the function is 
called.</p>
</td></tr>
<tr><td><code id="vb_mult_fpca_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
<tr><td><code id="vb_mult_fpca_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="vb_mult_fpca_+3A_kp">Kp</code></td>
<td>
<p>number of FPCA basis functions to be estimated</p>
</td></tr>
<tr><td><code id="vb_mult_fpca_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter balancing second-derivative penalty and
zeroth-derivative penalty (alpha = 0 is all second-derivative penalty)</p>
</td></tr>
<tr><td><code id="vb_mult_fpca_+3A_argvals">argvals</code></td>
<td>
<p>not currently implemented</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='vb_mult_wish'>Multilevel FoSR using Variational Bayes and Wishart prior</h2><span id='topic+vb_mult_wish'></span>

<h3>Description</h3>

<p>Fitting function for function-on-scalar regression for cross-sectional data.
This function estimates model parameters using VB and estimates
the residual covariance surface using a Wishart prior. If prior hyperparameters
are <code>NULL</code> they are estimated using the data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vb_mult_wish(
  formula,
  data = NULL,
  verbose = TRUE,
  Kt = 5,
  alpha = 0.1,
  min.iter = 10,
  max.iter = 50,
  Az = NULL,
  Bz = NULL,
  Aw = NULL,
  Bw = NULL,
  v = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vb_mult_wish_+3A_formula">formula</code></td>
<td>
<p>a formula indicating the structure of the proposed model.</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_data">data</code></td>
<td>
<p>an optional data frame, list or environment containing the 
variables in the model. If not found in data, the variables are taken from 
environment(formula), typically the environment from which the function is 
called.</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_verbose">verbose</code></td>
<td>
<p>logical defaulting to <code>TRUE</code> &ndash; should updates on progress be printed?</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_kt">Kt</code></td>
<td>
<p>number of spline basis functions used to estimate coefficient functions</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter balancing second-derivative penalty and
zeroth-derivative penalty (alpha = 0 is all second-derivative penalty)</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_min.iter">min.iter</code></td>
<td>
<p>minimum number of iterations of VB algorithm</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_max.iter">max.iter</code></td>
<td>
<p>maximum number of iterations of VB algorithm</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_az">Az</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for subject-level effects</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_bz">Bz</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for subject-level effects</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_aw">Aw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_bw">Bw</code></td>
<td>
<p>hyperparameter for inverse gamma controlling variance of spline terms
for population-level effects</p>
</td></tr>
<tr><td><code id="vb_mult_wish_+3A_v">v</code></td>
<td>
<p>hyperparameter for inverse Wishart prior on residual covariance</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>


<h3>References</h3>

<p>Goldsmith, J., Kitago, T. (2016).
Assessing Systematic Effects of Stroke on Motor Control using Hierarchical 
Function-on-Scalar Regression. <em>Journal of the Royal Statistical Society:
Series C</em>, 65 215-236.
</p>

<hr>
<h2 id='vis.fgam'>Visualization of FGAM objects</h2><span id='topic+vis.fgam'></span>

<h3>Description</h3>

<p>Produces perspective or contour plot views of an estimated surface corresponding to <code><a href="#topic+af">af</a></code>
terms fit using <code><a href="#topic+fgam">fgam</a></code> or plots &ldquo;slices&rdquo; of the estimated surface or estimated
second derivative surface with one of its arguments fixed and corresponding twice-standard error
&ldquo;Bayesian&rdquo; confidence bands constructed using the method in Marra and Wood (2012).  See the details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vis.fgam(
  object,
  af.term,
  xval = NULL,
  tval = NULL,
  deriv2 = FALSE,
  theta = 50,
  plot.type = "persp",
  ticktype = "detailed",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vis.fgam_+3A_object">object</code></td>
<td>
<p>an <code>fgam</code> object, produced by <code><a href="#topic+fgam">fgam</a></code></p>
</td></tr>
<tr><td><code id="vis.fgam_+3A_af.term">af.term</code></td>
<td>
<p>character; the name of the functional predictor to be plotted.  Only important
if multiple <code>af</code> terms are fit.  Defaults to the first <code>af</code> term in <code>object$call</code></p>
</td></tr>
<tr><td><code id="vis.fgam_+3A_xval">xval</code></td>
<td>
<p>a number in the range of functional predictor to be plotted.  The surface will be plotted
with the first argument of the estimated surface fixed at this value</p>
</td></tr>
<tr><td><code id="vis.fgam_+3A_tval">tval</code></td>
<td>
<p>a number in the domain of the functional predictor to be plotted.  The surface will be
plotted with the second argument of the estimated surface fixed at this value. Ignored if <code>xval</code>
is specified</p>
</td></tr>
<tr><td><code id="vis.fgam_+3A_deriv2">deriv2</code></td>
<td>
<p>logical; if <code>TRUE</code>, plot the estimated second derivative surface along with
Bayesian confidence bands.  Only implemented for the &quot;slices&quot; plot from either <code>xval</code> or
<code>tval</code> being specified</p>
</td></tr>
<tr><td><code id="vis.fgam_+3A_theta">theta</code></td>
<td>
<p>numeric; viewing angle; see <code><a href="graphics.html#topic+persp">persp</a></code></p>
</td></tr>
<tr><td><code id="vis.fgam_+3A_plot.type">plot.type</code></td>
<td>
<p>one of <code>"contour"</code> (to use <code><a href="lattice.html#topic+levelplot">levelplot</a></code>) or <code>"persp"</code>
(to use <code><a href="graphics.html#topic+persp">persp</a></code>).  Ignored if either <code>xval</code> or <code>tval</code> is specified</p>
</td></tr>
<tr><td><code id="vis.fgam_+3A_ticktype">ticktype</code></td>
<td>
<p>how to draw the tick marks if <code>plot.type="persp"</code>.  Defaults to <code>"detailed"</code></p>
</td></tr>
<tr><td><code id="vis.fgam_+3A_...">...</code></td>
<td>
<p>other options to be passed to <code><a href="graphics.html#topic+persp">persp</a></code>, <code><a href="lattice.html#topic+levelplot">levelplot</a></code>, or
<code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence bands used when plotting slices of the estimated surface or second derivative
surface are the ones proposed in Marra and Wood (2012).  These are a generalization of the &quot;Bayesian&quot;
intervals of Wahba (1983) with an adjustment for the uncertainty about the model intercept. The
estimated covariance matrix of the model parameters is obtained from assuming a particular Bayesian
model on the parameters.
</p>


<h3>Value</h3>

<p>Simply produces a plot
</p>


<h3>Author(s)</h3>

<p>Mathew W. McLean <a href="mailto:mathew.w.mclean@gmail.com">mathew.w.mclean@gmail.com</a>
</p>


<h3>References</h3>

<p>McLean, M. W., Hooker, G., Staicu, A.-M., Scheipl, F., and Ruppert, D. (2014). Functional
generalized additive models. <em>Journal of Computational and Graphical Statistics</em>, <b>23(1)</b>,
pp. 249-269.  Available at <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/</a>.
</p>
<p>Marra, G., and Wood, S. N. (2012) Coverage properties of confidence intervals for generalized
additive model components. <em>Scandinavian Journal of Statistics</em>, <b>39(1)</b>, pp. 53&ndash;74.
</p>
<p>Wabha, G. (1983) &quot;Confidence intervals&quot; for the cross-validated smoothing spline. <em>Journal of the
Royal Statistical Society, Series B</em>, <b>45(1)</b>, pp. 133&ndash;150.
</p>


<h3>See Also</h3>

<p><code><a href="mgcv.html#topic+vis.gam">vis.gam</a></code>, <code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code>, <code><a href="#topic+fgam">fgam</a></code>, <code><a href="graphics.html#topic+persp">persp</a></code>,
<code><a href="lattice.html#topic+levelplot">levelplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>################# DTI Example #####################
data(DTI)

## only consider first visit and cases (since no PASAT scores for controls)
y &lt;- DTI$pasat[DTI$visit==1 &amp; DTI$case==1]
X &lt;- DTI$cca[DTI$visit==1 &amp; DTI$case==1,]

## remove samples containing missing data
ind &lt;- rowSums(is.na(X))&gt;0

y &lt;- y[!ind]
X &lt;- X[!ind,]

## fit the fgam using FA measurements along corpus
## callosum as functional predictor with PASAT as response
## using 8 cubic B-splines for each marginal bases with
## third order marginal difference penalties
## specifying gamma&gt;1 enforces more smoothing when using GCV
## to choose smoothing parameters
#fit &lt;- fgam(y~af(X,splinepars=list(k=c(8,8),m=list(c(2,3),c(2,3)))),gamma=1.2)

## contour plot of the fitted surface
#vis.fgam(fit,plot.type='contour')

## similar to Figure 5 from McLean et al.
## Bands seem too conservative in some cases
#xval &lt;- runif(1, min(fit$fgam$ft[[1]]$Xrange), max(fit$fgam$ft[[1]]$Xrange))
#tval &lt;- runif(1, min(fit$fgam$ft[[1]]$xind), max(fit$fgam$ft[[1]]$xind))
#par(mfrow=c(4, 1))
#vis.fgam(fit, af.term='X', deriv2=FALSE, xval=xval)
#vis.fgam(fit, af.term='X', deriv2=FALSE, tval=tval)
#vis.fgam(fit, af.term='X', deriv2=TRUE, xval=xval)
#vis.fgam(fit, af.term='X', deriv2=TRUE, tval=tval)
</code></pre>

<hr>
<h2 id='vis.pfr'>Visualization of PFR objects</h2><span id='topic+vis.pfr'></span>

<h3>Description</h3>

<p>Produces perspective or contour plot views of an estimated surface corresponding
smooths over two or more dimensions. Alternatively plots &ldquo;slices&rdquo; of the
estimated surface or estimated second derivative surface with one of its arguments fixed.
Corresponding twice-standard error &ldquo;Bayesian&rdquo; confidence bands are
constructed using the method in Marra and Wood (2012). See the details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vis.pfr(
  object,
  select = 1,
  xval = NULL,
  tval = NULL,
  deriv2 = FALSE,
  theta = 50,
  plot.type = "persp",
  ticktype = "detailed",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="vis.pfr_+3A_object">object</code></td>
<td>
<p>an <code>pfr</code> object, produced by <code><a href="#topic+pfr">pfr</a></code></p>
</td></tr>
<tr><td><code id="vis.pfr_+3A_select">select</code></td>
<td>
<p>index for the smooth term to be plotted, according to its position
in the model formula (and in <code>object$smooth</code>). Not needed if only one
multivariate term is present.</p>
</td></tr>
<tr><td><code id="vis.pfr_+3A_xval">xval</code></td>
<td>
<p>a number in the range of functional predictor to be plotted.  The surface will be plotted
with the first argument of the estimated surface fixed at this value</p>
</td></tr>
<tr><td><code id="vis.pfr_+3A_tval">tval</code></td>
<td>
<p>a number in the domain of the functional predictor to be plotted.  The surface will be
plotted with the second argument of the estimated surface fixed at this value. Ignored if <code>xval</code>
is specified.</p>
</td></tr>
<tr><td><code id="vis.pfr_+3A_deriv2">deriv2</code></td>
<td>
<p>logical; if <code>TRUE</code>, plot the estimated second derivative surface along with
Bayesian confidence bands.  Only implemented for the &quot;slices&quot; plot from either <code>xval</code> or
<code>tval</code> being specified</p>
</td></tr>
<tr><td><code id="vis.pfr_+3A_theta">theta</code></td>
<td>
<p>numeric; viewing angle; see <code><a href="graphics.html#topic+persp">persp</a></code></p>
</td></tr>
<tr><td><code id="vis.pfr_+3A_plot.type">plot.type</code></td>
<td>
<p>one of <code>"contour"</code> (to use <code><a href="lattice.html#topic+levelplot">levelplot</a></code>) or <code>"persp"</code>
(to use <code><a href="graphics.html#topic+persp">persp</a></code>).  Ignored if either <code>xval</code> or <code>tval</code> is specified</p>
</td></tr>
<tr><td><code id="vis.pfr_+3A_ticktype">ticktype</code></td>
<td>
<p>how to draw the tick marks if <code>plot.type="persp"</code>.  Defaults to <code>"detailed"</code></p>
</td></tr>
<tr><td><code id="vis.pfr_+3A_...">...</code></td>
<td>
<p>other options to be passed to <code><a href="graphics.html#topic+persp">persp</a></code>, <code><a href="lattice.html#topic+levelplot">levelplot</a></code>, or
<code><a href="graphics.html#topic+plot">plot</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The confidence bands used when plotting slices of the estimated surface or second derivative
surface are the ones proposed in Marra and Wood (2012).  These are a generalization of the &quot;Bayesian&quot;
intervals of Wahba (1983) with an adjustment for the uncertainty about the model intercept. The
estimated covariance matrix of the model parameters is obtained from assuming a particular Bayesian
model on the parameters.
</p>


<h3>Value</h3>

<p>Simply produces a plot
</p>


<h3>Author(s)</h3>

<p>Mathew W. McLean <a href="mailto:mathew.w.mclean@gmail.com">mathew.w.mclean@gmail.com</a>
</p>


<h3>References</h3>

<p>McLean, M. W., Hooker, G., Staicu, A.-M., Scheipl, F., and Ruppert, D. (2014). Functional
generalized additive models. <em>Journal of Computational and Graphical Statistics</em>, <b>23(1)</b>,
pp. 249-269.  Available at <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3982924/</a>.
</p>
<p>Marra, G., and Wood, S. N. (2012) Coverage properties of confidence intervals for generalized
additive model components. <em>Scandinavian Journal of Statistics</em>, <b>39(1)</b>, pp. 53&ndash;74.
</p>
<p>Wabha, G. (1983) &quot;Confidence intervals&quot; for the cross-validated smoothing spline. <em>Journal of the
Royal Statistical Society, Series B</em>, <b>45(1)</b>, pp. 133&ndash;150.
</p>


<h3>See Also</h3>

<p><code><a href="mgcv.html#topic+vis.gam">vis.gam</a></code>, <code><a href="mgcv.html#topic+plot.gam">plot.gam</a></code>, <code><a href="#topic+pfr">pfr</a></code>, <code><a href="graphics.html#topic+persp">persp</a></code>,
<code><a href="lattice.html#topic+levelplot">levelplot</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>################# DTI Example #####################
data(DTI)

## only consider first visit and cases (since no PASAT scores for controls),
## and remove missing data
DTI &lt;- DTI[DTI$visit==1 &amp; DTI$case==1 &amp; complete.cases(DTI$cca),]

## Fit the PFR using FA measurements along corpus
## callosum as functional predictor with PASAT as response
## using 8 cubic B-splines for each marginal bases with
## third order marginal difference penalties.
## Specifying gamma&gt;1 enforces more smoothing when using GCV
## to choose smoothing parameters
fit &lt;- pfr(pasat ~ af(cca, basistype="te", k=c(8,8), m=list(c(2,3),c(2,3)), bs="ps"),
           method="GCV.Cp", gamma=1.2, data=DTI)

## contour plot of the fitted surface
vis.pfr(fit, plot.type='contour')

## similar to Figure 5 from McLean et al.
## Bands seem too conservative in some cases
xval &lt;- runif(1, min(fit$pfr$ft[[1]]$Xrange), max(fit$pfr$ft[[1]]$Xrange))
tval &lt;- runif(1, min(fit$pfr$ft[[1]]$xind), max(fit$pfr$ft[[1]]$xind))
par(mfrow=c(2, 2))
vis.pfr(fit, deriv2=FALSE, xval=xval)
vis.pfr(fit, deriv2=FALSE, tval=tval)
vis.pfr(fit, deriv2=TRUE, xval=xval)
vis.pfr(fit, deriv2=TRUE, tval=tval)
</code></pre>

<hr>
<h2 id='Xt_siginv_X'>Internal computation function</h2><span id='topic+Xt_siginv_X'></span>

<h3>Description</h3>

<p>Internal function used compute the products
in cross-sectional VB algorithm and Gibbs sampler
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Xt_siginv_X(tx, siginv, y = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Xt_siginv_X_+3A_tx">tx</code></td>
<td>
<p>transpose of the X design matrix</p>
</td></tr>
<tr><td><code id="Xt_siginv_X_+3A_siginv">siginv</code></td>
<td>
<p>inverse variance matrix</p>
</td></tr>
<tr><td><code id="Xt_siginv_X_+3A_y">y</code></td>
<td>
<p>outcome matrix. if <code>NULL</code>, function computes
first product; if not, function computes second product.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Jeff Goldsmith <a href="mailto:ajg2202@cumc.columbia.edu">ajg2202@cumc.columbia.edu</a>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
