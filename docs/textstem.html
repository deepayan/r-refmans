<!DOCTYPE html><html><head><title>Help for package textstem</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {textstem}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#textstem'><p>Tools for Stemming and Lemmatizing Text</p></a></li>
<li><a href='#lemmatize_strings'><p>Lemmatize a Vector of Strings</p></a></li>
<li><a href='#lemmatize_words'><p>Lemmatize a Vector of Words</p></a></li>
<li><a href='#make_lemma_dictionary'><p>Generate a Lemma Dictionary</p></a></li>
<li><a href='#presidential_debates_2012'><p>2012 U.S. Presidential Debates</p></a></li>
<li><a href='#sam_i_am'><p>Sam I Am Text</p></a></li>
<li><a href='#stem_strings'><p>Stem a Vector of Strings</p></a></li>
<li><a href='#stem_words'><p>Stem a Vector of Words</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Tools for Stemming and Lemmatizing Text</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.4</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Tyler Rinker &lt;tyler.rinker@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools that stem and lemmatize text.  Stemming is a process that removes
         endings such as affixes.  Lemmatization is the process of grouping inflected
         forms together as a single base form.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0), koRpus.lang.en</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, hunspell, koRpus, lexicon (&ge; 0.4.1), quanteda (&ge;
0.99.12), SnowballC, stats, stringi, textclean, textshape,
utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Date:</td>
<td>2018-04-09</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://github.com/trinker/textstem">http://github.com/trinker/textstem</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="http://github.com/trinker/textstem/issues">http://github.com/trinker/textstem/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2018-04-09 13:31:16 UTC; Tyler</td>
</tr>
<tr>
<td>Author:</td>
<td>Tyler Rinker [aut, cre]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2018-04-09 15:03:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='textstem'>Tools for Stemming and Lemmatizing Text</h2><span id='topic+textstem'></span><span id='topic+package-textstem'></span><span id='topic+textstem-package'></span>

<h3>Description</h3>

<p>Tools that stem and lemmatize text.  Stemming is a process that removes
endings such as suffixes.  Lemmatization is the process of grouping 
inflected forms together as a single base form.
</p>

<hr>
<h2 id='lemmatize_strings'>Lemmatize a Vector of Strings</h2><span id='topic+lemmatize_strings'></span>

<h3>Description</h3>

<p>Lemmatize a vector of strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lemmatize_strings(x, dictionary = lexicon::hash_lemmas, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lemmatize_strings_+3A_x">x</code></td>
<td>
<p>A vector of strings.</p>
</td></tr>
<tr><td><code id="lemmatize_strings_+3A_dictionary">dictionary</code></td>
<td>
<p>A dictionary of base terms and lemmas to use for
replacement.  The first column should be the full word form in lower case
while the second column is the corresponding replacement lemma. The default
makes the dictionary from the text using
<code><a href="#topic+make_lemma_dictionary">make_lemma_dictionary</a></code>.  For larger texts a
dictionary may take some time to compute.  It may be more useful to generate
the dictionary prior to running the function and explicitly pass the
dictionary in.</p>
</td></tr>
<tr><td><code id="lemmatize_strings_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="textshape.html#topic+split_token">split_token</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of lemmatized strings.
</p>


<h3>Note</h3>

<p>The lemmatizer splits the string apart into tokens for speed
optimization.  After the lemmatizing occurs the strings are pasted back
together.  The strings are not guaranteed to retain exact spacing of the
original.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lemmatize_words">lemmatize_words</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(
    'the dirtier dog has eaten the pies',
    'that shameful pooch is tricky and sneaky',
    "He opened and then reopened the food bag",
    'There are skies of blue and red roses too!',
    NA,
    "The doggies, well they aren't joyfully running.",
    "The daddies are coming over...",
    "This is 34.546 above"
)

## Default lexicon::hash_lemmas dictionary
lemmatize_strings(x)

## Hunspell dictionary
lemma_dictionary &lt;- make_lemma_dictionary(x, engine = 'hunspell')
lemmatize_strings(x, dictionary = lemma_dictionary)

## Bigger data set
library(dplyr)
presidential_debates_2012$dialogue %&gt;%
    lemmatize_strings() %&gt;%
    head()

## Not run: 
## Treetagger dictionary
lemma_dictionary2 &lt;- make_lemma_dictionary(x, engine = 'treetagger')
lemmatize_strings(x, lemma_dictionary2)

lemma_dictionary3 &lt;- presidential_debates_2012$dialogue %&gt;%
    make_lemma_dictionary(engine = 'treetagger')

presidential_debates_2012$dialogue %&gt;%
     lemmatize_strings(lemma_dictionary3) %&gt;%
     head()

## End(Not run)
</code></pre>

<hr>
<h2 id='lemmatize_words'>Lemmatize a Vector of Words</h2><span id='topic+lemmatize_words'></span>

<h3>Description</h3>

<p>Lemmatize a vector of words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lemmatize_words(x, dictionary = lexicon::hash_lemmas, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lemmatize_words_+3A_x">x</code></td>
<td>
<p>A vector of words.</p>
</td></tr>
<tr><td><code id="lemmatize_words_+3A_dictionary">dictionary</code></td>
<td>
<p>A dictionary of base terms and lemmas to use for
replacement.  The first column should be the full word form in lower case
while the second column is the corresponding replacement lemma. The default
uses <code><a href="lexicon.html#topic+hash_lemmas">hash_lemmas</a></code>.  This may come from
<code><a href="#topic+make_lemma_dictionary">make_lemma_dictionary</a></code> as well, giving a more
targeted, smaller dictionary.  <code><a href="#topic+make_lemma_dictionary">make_lemma_dictionary</a></code>
has choices in <code>engine</code>s to use for the lemmatization.</p>
</td></tr>
<tr><td><code id="lemmatize_words_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of lemmatized words.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lemmatize_strings">lemmatize_strings</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("the", NA, 'doggies', ',', 'well', 'they', "aren\'t", 'Joyfully', 'running', '.')
lemmatize_words(x)
</code></pre>

<hr>
<h2 id='make_lemma_dictionary'>Generate a Lemma Dictionary</h2><span id='topic+make_lemma_dictionary'></span>

<h3>Description</h3>

<p>Given a set of text strings, the function generates a dictionary of lemmas
corresponding to words that are not in base form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_lemma_dictionary(..., engine = "hunspell", path = NULL,
  lang = switch(engine, hunspell = {     "en_US" }, treetagger = {     "en" },
  lexicon = {     NULL }, stop("engine not found")))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_lemma_dictionary_+3A_engine">engine</code></td>
<td>
<p>One of: &quot;hunspell&quot;, &quot;treetragger&quot; or &quot;lexicon&quot;.  The lexicon and hunspell choices use
the <span class="pkg">lexicon</span> and <span class="pkg">hunspell</span> packages, which may be faster than
TreeTagger, have the tooling available without installing external tools but
are likely less accurate.  TreeTagger is likely more accurate but requires installing
the <a href="http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger">TreeTagger</a>
program (<a href="http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger">http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger</a>.</p>
</td></tr>
<tr><td><code id="make_lemma_dictionary_+3A_path">path</code></td>
<td>
<p>Path to the TreeTagger program if <code>engine = "treetagger"</code>.
If <code>NULL</code> <code>textstem</code> will attempt to locate the location of
TreeTagger.</p>
</td></tr>
<tr><td><code id="make_lemma_dictionary_+3A_lang">lang</code></td>
<td>
<p>A character string naming the language to be used in <span class="pkg">koRpus</span>
(treetagger) or <span class="pkg">hunspell</span>.  The default language is <code>'en'</code> for
<span class="pkg">koRpus</span> (treetagger) and  <code>'en_US'</code> for <span class="pkg">hunspell</span>.  See
<code>?koRpus::treetag</code> or <code>?hunspell::dictionary</code> for details.  Note
that for <code>koRpus::treetag</code> <code>lang</code> is passed to both <code>lang</code> and
<code>prest</code> in the <code>TT.options</code> argument.</p>
</td></tr>
<tr><td><code id="make_lemma_dictionary_+3A_...">...</code></td>
<td>
<p>A vector of texts to generate lemmas for.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a two column <code><a href="base.html#topic+data.frame">data.frame</a></code> with tokens and
corresponding lemmas.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c('the dirtier dog has eaten the pies',
    'that shameful pooch is tricky and sneaky',
    "He opened and then reopened the food bag",
    'There are skies of blue and red roses too!'
)
make_lemma_dictionary(x)
## Not run: 
make_lemma_dictionary(x, engine = 'treetagger')

## End(Not run)
</code></pre>

<hr>
<h2 id='presidential_debates_2012'>2012 U.S. Presidential Debates</h2><span id='topic+presidential_debates_2012'></span>

<h3>Description</h3>

<p>A dataset containing a cleaned version of all three presidential debates for
the 2012 election.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(presidential_debates_2012)
</code></pre>


<h3>Format</h3>

<p>A data frame with 2912 rows and 4 variables</p>


<h3>Details</h3>


<ul>
<li><p> person. The speaker
</p>
</li>
<li><p> tot. Turn of talk
</p>
</li>
<li><p> dialogue. The words spoken
</p>
</li>
<li><p> time. Variable indicating which of the three debates the dialogue is from
</p>
</li></ul>


<hr>
<h2 id='sam_i_am'>Sam I Am Text</h2><span id='topic+sam_i_am'></span>

<h3>Description</h3>

<p>A dataset containing a character vector of the text from Seuss's 'Sam I Am'.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(sam_i_am)
</code></pre>


<h3>Format</h3>

<p>A character vector with 169 elements</p>


<h3>References</h3>

<p>Seuss, Dr. (1960). Green Eggs and Ham.
</p>

<hr>
<h2 id='stem_strings'>Stem a Vector of Strings</h2><span id='topic+stem_strings'></span>

<h3>Description</h3>

<p>Stem a vector of strings.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stem_strings(x, language = "porter", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stem_strings_+3A_x">x</code></td>
<td>
<p>A vector of strings.</p>
</td></tr>
<tr><td><code id="stem_strings_+3A_language">language</code></td>
<td>
<p>The name of a recognized language (see
<code><a href="SnowballC.html#topic+wordStem">wordStem</a></code>).</p>
</td></tr>
<tr><td><code id="stem_strings_+3A_...">...</code></td>
<td>
<p>Other arguments passed to <code><a href="textshape.html#topic+split_token">split_token</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of stemmed strings.
</p>


<h3>Note</h3>

<p>The stemmer requires splitting the string apart into tokens.  After the
stemming occurs the strings are pasted back together.  The strings are not
guaranteed to retain exact spacing of the original.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stem_words">stem_words</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c(
    'the dirtier dog has eaten the pies',
    'that shameful pooch is tricky and sneaky',
    "He opened and then reopened the food bag",
    'There are skies of blue and red roses too!',
    NA,
    "The doggies, well they aren't joyfully running.",
    "The daddies are coming over...",
    "This is 34.546 above"
)
stem_strings(x)
</code></pre>

<hr>
<h2 id='stem_words'>Stem a Vector of Words</h2><span id='topic+stem_words'></span>

<h3>Description</h3>

<p>Stem a vector of words.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stem_words(x, language = "porter", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stem_words_+3A_x">x</code></td>
<td>
<p>A vector of words.</p>
</td></tr>
<tr><td><code id="stem_words_+3A_language">language</code></td>
<td>
<p>The name of a recognized language (see
<code><a href="SnowballC.html#topic+wordStem">wordStem</a></code>).</p>
</td></tr>
<tr><td><code id="stem_words_+3A_...">...</code></td>
<td>
<p>ignored.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of stemmed words.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stem_strings">stem_strings</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- c("the", 'doggies', ',', 'well', 'they', "aren\'t", 'Joyfully', 'running', '.')
stem_words(x)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
