<!DOCTYPE html><html><head><title>Help for package Davies</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<script type="text/javascript" src="mathjax-config.js"></script>
<script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Davies}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Davies'><p>The Davies distribution</p></a></li>
<li><a href='#davies.moment'><p>Moments of the Davies distribution</p></a></li>
<li><a href='#davies.start'><p>start value for Davies minimization routines</p></a></li>
<li><a href='#expected.gld'><p>expected value of the Generalized Lambda Distribution</p></a></li>
<li><a href='#fit.davies.p'><p>Fits and plots Davies distributions to datasets</p></a></li>
<li><a href='#Gld'><p>The Generalized Lambda Distribution</p></a></li>
<li><a href='#least.squares'><p>Finds the optimal Davies distribution for a dataset</p></a></li>
<li><a href='#likelihood'><p>likelihood for the Davies distribution</p></a></li>
<li><a href='#objective'><p>The objective function for fitting the Davies distribution</p></a></li>
<li><a href='#ozturk'><p>Parameters used in a paper by Ozturk</p></a></li>
<li><a href='#plotcf'><p>p-value investigation</p></a></li>
<li><a href='#rstupid'><p>A stupid PDF</p></a></li>
<li><a href='#twolines.vert'><p>Order statistic comparison</p></a></li>
<li><a href='#x00m700p4'><p>Peak concentration for 100 instantaneous releases</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>The Davies Quantile Function</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2-0</td>
</tr>
<tr>
<td>Imports:</td>
<td>mathjaxr</td>
</tr>
<tr>
<td>Author:</td>
<td>Robin K. S. Hankin</td>
</tr>
<tr>
<td>Description:</td>
<td>Various utilities for the Davies distribution.</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Robin K. S. Hankin &lt;hankin.robin@gmail.com&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-02-15 21:50:06 UTC</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-02-15 20:59:06 UTC; rhankin</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>mathjaxr</td>
</tr>
</table>
<hr>
<h2 id='Davies'>The Davies distribution</h2><span id='topic+Davies'></span><span id='topic+davies'></span><span id='topic+ddavies'></span><span id='topic+pdavies'></span><span id='topic+qdavies'></span><span id='topic+rdavies'></span><span id='topic+ddavies.p'></span>

<h3>Description</h3>

<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>
<p>Density, distribution function, quantile function and random
generation for the Davies distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'> ddavies(x, params,log=FALSE)
 pdavies(x, params,log.p=FALSE,lower.tail=TRUE)
 qdavies(p, params,lower.tail=TRUE)
 rdavies(n, params)
ddavies.p(x,params,log=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Davies_+3A_x">x</code></td>
<td>
<p>quantile</p>
</td></tr>
<tr><td><code id="Davies_+3A_p">p</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="Davies_+3A_n">n</code></td>
<td>
<p>number of observations.  If <code>length(n) &gt; 1</code>, the length
is taken to be the number required</p>
</td></tr>
<tr><td><code id="Davies_+3A_lower.tail">lower.tail</code></td>
<td>
<p>logical; if <code>TRUE</code> (default), probabilities are
\(P(X\leq x)\), otherwise \(P(X>x)\)</p>
</td></tr>
<tr><td><code id="Davies_+3A_log">log</code>, <code id="Davies_+3A_log.p">log.p</code></td>
<td>
<p>logical; if <code>TRUE</code>, probabilities are given as
\(\log(p)\)</p>
</td></tr>
<tr><td><code id="Davies_+3A_params">params</code></td>
<td>
<p>A three-member vector holding \(C\),
\(\lambda_1\) and \(\lambda_2\)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Davies distribution is defined in terms of its quantile function:
</p>
<p style="text-align: center;"><i>Cp^lambda_1/(1-p)^lambda2</i></p>

<p>It does not have a closed-form  probability density function or
cumulative density function, so numerical solution is used.
</p>
<p>Function <code>ddavies.p()</code> returns the density of the Davies function
but as a function of the quantile.
</p>


<h3>Value</h3>

<p>Function
<code>ddavies()</code> gives the density,
<code>pdavies()</code> gives the distribution function,
<code>qdavies()</code> gives the quantile function, and
<code>rdavies()</code> generates random deviates.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>R. K. S. Hankin and A. Lee 2006.  &ldquo;A new family of non-negative
distributions&rdquo;  <em>Australia and New Zealand Journal of
Statistics</em>, 48(1):67&ndash;78</p>


<h3>See Also</h3>

<p><code><a href="#topic+Gld">Gld</a></code>, <code><a href="#topic+fit.davies.p">fit.davies.p</a></code>,
<code><a href="#topic+least.squares">least.squares</a></code>, <code><a href="#topic+skewness">skewness</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>params &lt;- c(10,0.1,0.1)
x &lt;- seq(from=4,to=20,by=0.2)
p &lt;- seq(from=1e-3,to=1-1e-3,len=50)

rdavies(n=5,params)
least.squares(rdavies(100,params))
plot(pdavies(x,params))


plot(p,qdavies(p,params))
plot(x,ddavies(x,params),type="b")

</code></pre>

<hr>
<h2 id='davies.moment'>Moments of the Davies distribution</h2><span id='topic+davies.moment'></span><span id='topic+kurtosis'></span><span id='topic+skewness'></span><span id='topic+expected.value'></span><span id='topic+expected.value.approx'></span><span id='topic+mu'></span><span id='topic+variance'></span><span id='topic+M'></span>

<h3>Description</h3>

<p>Moments of order statistics of random variables drawn from a Davies
distribution 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>davies.moment(n=1 , i=1 , order=1 , params)
M(order,params)
mu(params)
expected.value(n,i,params)
expected.value.approx(n,i,params)
variance(params)
skewness(params)
kurtosis(params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="davies.moment_+3A_params">params</code></td>
<td>
<p>A three-member vector holding <code class="reqn">C</code>,
<code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code></p>
</td></tr>
<tr><td><code id="davies.moment_+3A_n">n</code></td>
<td>
<p>The number of observations</p>
</td></tr>
<tr><td><code id="davies.moment_+3A_i">i</code></td>
<td>
<p>Return information about the <code class="reqn">i</code>-th order statistic (ie
<code class="reqn">i=1</code> means the smallest, <code class="reqn">i=n</code> means the biggest)</p>
</td></tr>
<tr><td><code id="davies.moment_+3A_order">order</code></td>
<td>
<p>The order (eg order=2 gives the square)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>davies.moment(n,i,order=r)</code> gives the <code class="reqn">r</code>-th moment
of the <code class="reqn">i</code>-th order statistic of <code class="reqn">n</code> observations.  The
following aliases are just convenience wrappers with <code class="reqn">n=i=1</code> (ie
moments of one observation from a Davies distribution):
</p>

<ul>
<li> <p><code>M()</code> gives the <code class="reqn">r</code>-th moment for <code class="reqn">n=i=1</code>
</p>
</li>
<li> <p><code>mu()</code> gives the first moment of a Davies distribution
(ie the mean)
</p>
</li>
<li> <p><code>variance()</code> gives the second <em>central</em> moment of a Davies
distribution
</p>
</li>
<li> <p><code>skewness()</code> gives the normalized skewness of a Davies
distribution
</p>
</li>
<li> <p><code>kurtosis()</code> gives the normalized kurtosis of a Davies
distribution
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>See Also</h3>

<p><code><a href="#topic+expected.value">expected.value</a></code>, <code><a href="#topic+expected.gld">expected.gld</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>params &lt;- c(10,0.1,0.1)
davies.moment(n=100,i=99,2,params) # ie the second moment of the 99th smallest
                            # observation of 100 drawn from a Davies
                            # distribution with parameters p


mean(rdavies(1e6,params))-mu(params)

#now reproduce the S-K graph:

f &lt;- function(x,y){c(skewness(c(1,x,y)),kurtosis(c(1,x,y)))}
g &lt;- function(j,vector,pp,qq=1){points(t(sapply(vector,f,y=j)),type="l",col="black",lty=qq)}

vector &lt;- c((0:300)/100 , (0:300)/10000 , seq(from=3,to=10,len=100))
vector &lt;- sort(unique(vector))

plot(t(sapply((0:10)/10,f,y=0)),
       xlim=c(-3,3),ylim=c(0,10),
       type="n",xlab="skewness",ylab="kurtosis")
g(0.001,vector,"red",qq=1)
g(0.01,vector,"yellow",qq=2)
g(0.02,vector,"green",qq=3)
g(0.05,vector,"blue",qq=4)
g(0.1 ,vector,"purple",qq=5)
g(0.14,vector,"black",qq=6)

x &lt;- seq(from=-3,to=3,len=30)
points(x,x^2+1,type="l",lwd=2)

leg.txt &lt;- expression(lambda[2]==0.001,
        lambda[2]==0.01,lambda[2]==0.02,lambda[2]==0.05,
        lambda[2]==0.1,lambda[2]==0.14)
legend(-1.1,10,leg.txt,col="black",lty=1:6)
</code></pre>

<hr>
<h2 id='davies.start'>start value for Davies minimization routines</h2><span id='topic+davies.start'></span>

<h3>Description</h3>

<p>Gives a &ldquo;start&rdquo; value for the optimization routines.  Uses
heuristics that seem to work.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>davies.start(x, threeps=c(0.1,0.5,0.9), small = 0.01) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="davies.start_+3A_x">x</code></td>
<td>
<p>dataset to be used</p>
</td></tr>
<tr><td><code id="davies.start_+3A_threeps">threeps</code></td>
<td>
<p>a three-element vector representing the quantiles to be
balanced.  The default values balance the first and ninth deciles
and the median.  These seem to work for me pretty well; YMMV</p>
</td></tr>
<tr><td><code id="davies.start_+3A_small">small</code></td>
<td>
<p>a &ldquo;small&rdquo; value to be used for <code class="reqn">\lambda_1</code>
and <code class="reqn">\lambda_1</code> because using exactly zero is inappropriate</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns a &ldquo;start&rdquo; value of the pararameters for use in one of the
Davies fitting routines <code>maximum.likelihood()</code> or <code>least.squares()</code>.
</p>
<p>Uses three heuristic methods (one assuming <code class="reqn">\lambda_1=
  \lambda_2</code>, one with <code class="reqn">\lambda_1=0</code>,
and one with <code class="reqn">\lambda_2=0</code>).  Returns the best one of the
three, as measured by <code>objective()</code>.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>See Also</h3>

<p><code><a href="#topic+least.squares">least.squares</a></code> , <code><a href="#topic+maximum.likelihood">maximum.likelihood</a></code>,
<code><a href="#topic+objective">objective</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- rchisq(40,1)
davies.start(d)
least.squares(d)

params &lt;- c(10 , 0.1 , -0.1)
x &lt;- rdavies(100 , params)
davies.start(x)

f &lt;- function(threeps){objective(davies.start(x,threeps),x)}

(jj&lt;-optim(c(0.1,0.5,0.9),f))
davies.start(x,jj$par)
least.squares(x)

#not bad at all.

</code></pre>

<hr>
<h2 id='expected.gld'>expected value of the Generalized Lambda Distribution</h2><span id='topic+expected.gld'></span><span id='topic+expected.gld.approx'></span>

<h3>Description</h3>

<p>Returns the expected value of the Generalized
Lambda Distribution</p>


<h3>Usage</h3>

<pre><code class='language-R'>expected.gld(n=1, i=1, params)
expected.gld.approx(n=1, i=1, params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expected.gld_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="expected.gld_+3A_i">i</code></td>
<td>
<p>Order statistic: <code class="reqn">i=1</code> means the smallest of
<code class="reqn">n</code>, and <code class="reqn">n=i</code> means the largest</p>
</td></tr>
<tr><td><code id="expected.gld_+3A_params">params</code></td>
<td>
<p>The four parameters of a GLD distribution</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>expected.gld</code> and <code>expected.approx</code> return the exact and
approximate values of the expected value of a Generalized Lambda
Distribution RV.
</p>
<p>Exploits the fact that the <code>gld</code> quantile function is the sum of
a constant and two <code>davies</code> quantile functions</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>References</h3>

<p>A. Ozturk and R. F. Dale, &ldquo;Least squares
estimation of the parameters of the generalized lambda distribution&rdquo;,
Technometrics 1985, 27(1):84 [it does not appear to be possible, as of
R-2.9.1, to render the diacritic marks in the first author's names in
a nicely portable way]
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Gld">Gld</a></code> , <code><a href="#topic+expected.value">expected.value</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>params &lt;- c(4.114,0.1333,0.0193,0.1588)
mean(rgld(1000,params))
expected.gld(n=1,i=1,params)
expected.gld.approx(n=1,i=1,params)


f &lt;- function(n){apply(matrix(rgld(n+n,params),2,n),2,min)}
#ie f(n) gives the smaller of 2 rgld RVs, n times.

mean(f(1000))
expected.gld(n=2,i=1,params)
expected.gld.approx(n=2,i=1,params)

plot(1:100,expected.gld.approx(n=100,i=1:100,params)-expected.gld(n=100,i=1:100,params))
# not bad, eh? ....yyyeeeeesss, but the parameters given by Ozturk give
# an almost zero second derivative for d(qgld)/dp, so the good agreement
# isn't surprising really.  Observe that the error is minimized at about
# p=0.2, where the point of inflection is.
</code></pre>

<hr>
<h2 id='fit.davies.p'>Fits and plots Davies distributions to datasets</h2><span id='topic+fit.davies.p'></span><span id='topic+fit.davies.q'></span>

<h3>Description</h3>

<p>A convenience wrapper (and pretty-printer) for
<code>maximum.likelihood()</code> and <code>least.squares()</code>.  Given a
dataset, it draws an empirical quantile function
(<code>fit.davies.p()</code>) or PDF (<code>fit.davies.q()</code>) and
superimposes the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit.davies.p(x , print.fit=FALSE, use.q=TRUE , params=NULL, small=1e-5 , ...)
fit.davies.q(x , print.fit=FALSE, use.q=TRUE , params=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fit.davies.p_+3A_x">x</code></td>
<td>
<p>dataset to be fitted and plotted</p>
</td></tr>
<tr><td><code id="fit.davies.p_+3A_print.fit">print.fit</code></td>
<td>
<p>Boolean with <code>TRUE</code> meaning print details of the fit</p>
</td></tr>
<tr><td><code id="fit.davies.p_+3A_use.q">use.q</code></td>
<td>
<p>Boolean with <code>TRUE</code> meaning use <code>least.squares()</code>
(rather than <code>maximum.likelihood()</code>)</p>
</td></tr>
<tr><td><code id="fit.davies.p_+3A_params">params</code></td>
<td>
<p>three-element vector holding the three parameters of the
davies dataset.  If <code>NULL</code>, determine the parameters using the method
indicated by <code>use.q</code></p>
</td></tr>
<tr><td><code id="fit.davies.p_+3A_small">small</code></td>
<td>
<p>small positive number showing range of quantiles to plot</p>
</td></tr>
<tr><td><code id="fit.davies.p_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to <code>plot()</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>print.fit</code> is <code>TRUE</code>, return the optimal parameters</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>See Also</h3>

<p><code><a href="#topic+least.squares">least.squares</a></code> ,  <code><a href="#topic+maximum.likelihood">maximum.likelihood</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  fit.davies.q(rchisq(100,1))
  fit.davies.p(exp(rnorm(100))) 

  data(x00m700p4)
  fit.davies.q(x00m700p4)
</code></pre>

<hr>
<h2 id='Gld'>The Generalized Lambda Distribution</h2><span id='topic+Gld'></span><span id='topic+gld'></span><span id='topic+dgld'></span><span id='topic+dgld.p'></span><span id='topic+pgld'></span><span id='topic+qgld'></span><span id='topic+rgld'></span>

<h3>Description</h3>

<script id="MathJax-script" async src="../../mathjaxr/doc/mathjax/es5/tex-chtml-full.js"></script>
<p>Density, distribution function, quantile function and random
generation for the Generalized Lambda Distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dgld(x, params)
dgld.p(x, params)
pgld(q, params)
qgld(p, params)
rgld(n, params)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Gld_+3A_x">x</code>, <code id="Gld_+3A_q">q</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="Gld_+3A_p">p</code></td>
<td>
<p>vector of probabilities</p>
</td></tr>
<tr><td><code id="Gld_+3A_n">n</code></td>
<td>
<p>In function <code>rgld()</code>, the number of observations.  If <code>length(n)&gt; 1</code>, the
length is taken to be the number required</p>
</td></tr>
<tr><td><code id="Gld_+3A_params">params</code></td>
<td>
<p>vector of parameters: <code>params[1]==lambda1</code> et seq</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Generalized Lambda distribution has quantile function
</p>
\[f(x)=\lambda_1 +(p^{\lambda_3} - (1-p)^{\lambda_4})/\lambda_2\]


<h3>Value</h3>

<p>Function 
<code>dgld()</code> gives the density,
<code>dgld.p()</code> gives the density in terms of the quantile,
<code>pgld()</code> gives the distribution function,
<code>qgld()</code> gives the quantile function, and
<code>rgld()</code> generates random deviates.
</p>


<h3>References</h3>


<ul>
<li>
<p>M. J. Wichura 1988. &ldquo;Algorithm AS 241: The Percentage Points of
the Normal Distribution&rdquo;.  <em>Applied Statistics</em>, <b>37</b>, 477&ndash;484.
</p>
</li>
<li>
<p>A. Ozturk and R. F. Dale 1985.  &ldquo;Least squares estimation
of the parameters of the generalized lambda distribution&rdquo;.
<em>Technometrics</em> 27(1):84
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+Davies">Davies</a></code>, <code><a href="#topic+expected.gld">expected.gld</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>params &lt;- c(4.114,0.1333,0.0193,0.1588)  #taken straight from some paper

gld.rv &lt;- rgld(100,params)

hist(gld.rv)
fit.davies.q(gld.rv)  #remember the Davies distn has 3 DF and the GLD 4...
</code></pre>

<hr>
<h2 id='least.squares'>Finds the optimal Davies distribution for a dataset</h2><span id='topic+least.squares'></span><span id='topic+maximum.likelihood'></span>

<h3>Description</h3>

<p>Finds the best-fit Davies distribution using either the least-squares
criterion (<code>least.squares()</code>) or maximum likelihood
(<code>maximum.likelihood()</code>)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>least.squares(data, do.print = FALSE, start.v = NULL)
maximum.likelihood(data, do.print = FALSE, start.v = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="least.squares_+3A_data">data</code></td>
<td>
<p>dataset to be fitted</p>
</td></tr>
<tr><td><code id="least.squares_+3A_do.print">do.print</code></td>
<td>
<p>Boolean with <code>TRUE</code> meaning print a GFM</p>
</td></tr>
<tr><td><code id="least.squares_+3A_start.v">start.v</code></td>
<td>
<p>A suitable starting vector of parameters
<code>c(C,lambda1,lambda2)</code>, with default <code>NULL</code> meaning to
use <code>start()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Uses <code>optim()</code> to find the best-fit Davies distribution to a set
of data.
</p>
<p><strong>Function <code>least.squares()</code> does not match that of Hankin
and Lee 2006</strong>.
</p>


<h3>Value</h3>

<p>Returns the parameters <code class="reqn">C,\lambda_1,\lambda_2</code> of
the best-fit Davies distribution to the dataset <code>data</code>
</p>


<h3>Note</h3>

<p>BUGS:
</p>
<p>Function <code>least.squares()</code> does not use the same methodology of
Hankin and Lee 2006, and its use is discouraged pending implentation.
</p>
<p>Quite apart from that, it can be screwed with bad value for
<code>start.v</code>.  Function <code>maximum.likelihod()</code> can be very slow.
It might be possible to improve this by using some sort of hot-start
for <code>optim()</code>.  </p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>See Also</h3>

<p><code><a href="#topic+davies.start">davies.start</a></code>, <code><a href="stats.html#topic+optim">optim</a></code>,
<code><a href="#topic+objective">objective</a></code>, <code><a href="#topic+likelihood">likelihood</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>
  p &lt;- c(10 , 0.1 , 0.1)
  d &lt;- rdavies(10,p)

  maximum.likelihood(d)  # quite slow
  least.squares(d)       # much faster but not recommended
</code></pre>

<hr>
<h2 id='likelihood'>likelihood for the Davies distribution</h2><span id='topic+likelihood'></span><span id='topic+neg.log.likelihood'></span>

<h3>Description</h3>

<p>Likelihood of observing <code>data</code>, on the hypothesis of
their coming from a Davies distribution of parameters <code>params</code>.
</p>
<p>Function <code>neg.log.likelihood()</code> gives minus the loglikelihood
</p>


<h3>Usage</h3>

<pre><code class='language-R'>likelihood(params, data)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="likelihood_+3A_params">params</code></td>
<td>
<p>Parameters of the Davies distribution</p>
</td></tr>
<tr><td><code id="likelihood_+3A_data">data</code></td>
<td>
<p>dataset for which the likelihood is computed</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>See Also</h3>

<p><code><a href="#topic+Davies">Davies</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>p1 &lt;- c(10, 0.1, 0.1)
p2 &lt;- c(10, 0.4, 0.1)
d &lt;- rdavies(100,p1)
likelihood(p1,d)
likelihood(p2,d)                 #should be smaller.
neg.log.likelihood(p1,rstupid(100)) #should be large negative.
</code></pre>

<hr>
<h2 id='objective'>The objective function for fitting the Davies distribution</h2><span id='topic+objective'></span><span id='topic+objective.approx'></span>

<h3>Description</h3>

<p>The &ldquo;distance&rdquo;
of a dataset from a particular Davies distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>objective(params, dataset)
objective.approx(params, dataset)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="objective_+3A_params">params</code></td>
<td>
<p>A three-member vector holding <code class="reqn">C</code>,
<code class="reqn">\lambda_1</code> and <code class="reqn">\lambda_2</code></p>
</td></tr>
<tr><td><code id="objective_+3A_dataset">dataset</code></td>
<td>
<p>The dataset to be considered</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Used by the <code>fit.davies.p()</code> and <code>fit.davies.q()</code> functions
</p>


<h3>Value</h3>

<p><code>objective</code> returns the &ldquo;distance&rdquo; of a
dataset from a particular
Davies distribution as measured by the sums of the squares of the
differences between observed (<code>dataset</code>) and
expected (<code>expected.value()</code>) values.
</p>
<p><code>objective.approx()</code> uses <code>expected.approx()</code> rather than
<code>expected()</code> to calculate expectations, as per equation 6.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit.davies.p">fit.davies.p</a></code>, <code><a href="#topic+fit.davies.q">fit.davies.q</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>params &lt;- c(10, 0.1, 0.1)
x &lt;- rdavies(100,params)
objective(params,x)
objective.approx(params,x)

objective(least.squares(x),x)
objective(davies.start(x),x)
  </code></pre>

<hr>
<h2 id='ozturk'>Parameters used in a paper by Ozturk</h2><span id='topic+ozturk'></span>

<h3>Description</h3>

<p>A four-element vector giving the parameters used by Ozturk.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(x00m700p4)</code></pre>


<h3>References</h3>

<p>A. Ozturk and R. F. Dale 1985.  &ldquo;Least squares estimation
of the parameters of the generalized lambda distribution&rdquo;.
<em>Technometrics</em> 27(1):84; see discussion under <code>expected.gld.Rd</code>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+expected.gld">expected.gld</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ozturk)
hist(rgld(100,ozturk))
</code></pre>

<hr>
<h2 id='plotcf'>p-value investigation</h2><span id='topic+plotcf'></span>

<h3>Description</h3>

<p>Plots sorted p-values showing which ones would have been rejected
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plotcf(y, q=0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plotcf_+3A_y">y</code></td>
<td>
<p>dataset</p>
</td></tr>
<tr><td><code id="plotcf_+3A_q">q</code></td>
<td>
<p>p-value of critical region</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Sorts p-values and plots the order statistic.  Useful for investigating
a statistical test by using it when the null hypothesis is KNOWN to be
true, just to check if the probability of rejection really is alpha.
</p>
<p>Also can be used when H0 is wrong, showing what beta is.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>Examples</h3>

<pre><code class='language-R'>f.H0.T &lt;- function(n,free=5){t.test(rt(n,df=free))$p.value}
f.H0.F &lt;- function(n,free=5){t.test(rf(n,df1=free,df2=free))$p.value}

plotcf(sapply(rep(10,100),f.H0.T))  # should reject about 5: thus
                                     # probability of a type I error is
                                     # about 0.05 (as it should be; this
                                     # is an exact test)
plotcf(sapply(rep(10,100),f.H0.F))  # should reject about 80: thus
                                     # probability of a type II error is
                                     # about 0.2 for this H_A.


</code></pre>

<hr>
<h2 id='rstupid'>A stupid PDF</h2><span id='topic+rstupid'></span>

<h3>Description</h3>

<p>a contrived PDF that cannot be closely approximated by a Davies distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rstupid(n, a = 1, b = 2, c = 3, d = 4)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rstupid_+3A_n">n</code></td>
<td>
<p>Number of observations</p>
</td></tr>
<tr><td><code id="rstupid_+3A_a">a</code></td>
<td>
<p>start of first uniform bit</p>
</td></tr>
<tr><td><code id="rstupid_+3A_b">b</code></td>
<td>
<p>end of first uniform bit</p>
</td></tr>
<tr><td><code id="rstupid_+3A_c">c</code></td>
<td>
<p>start of second uniform bit</p>
</td></tr>
<tr><td><code id="rstupid_+3A_d">d</code></td>
<td>
<p>end of second uniform bit</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>stupid</code> distribution is composed of two separate uniform
distributions: one from <code class="reqn">a</code> to <code class="reqn">b</code>, and one from <code class="reqn">c</code> to
<code class="reqn">d</code>.  It is specifically designed to be NOT fittable to any Davies
distribution.
</p>
<p>You could probably come up with a more stupid distribution
if you tried.
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>See Also</h3>

<p><code><a href="#topic+Davies">Davies</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>stupid &lt;- rstupid(500)
fit.davies.q(stupid)
</code></pre>

<hr>
<h2 id='twolines.vert'>Order statistic comparison</h2><span id='topic+twolines.vert'></span>

<h3>Description</h3>

<p>Plots two lines and shades the bit in between them
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twolines.vert(p, y1, y2, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="twolines.vert_+3A_p">p</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="twolines.vert_+3A_y1">y1</code></td>
<td>
<p>First set of ordinates</p>
</td></tr>
<tr><td><code id="twolines.vert_+3A_y2">y2</code></td>
<td>
<p>Second set of ordinates</p>
</td></tr>
<tr><td><code id="twolines.vert_+3A_...">...</code></td>
<td>
<p>Extra arguments, passed to <code>segments()</code>, for
the vertical lines</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Plots <code>p</code> against <code>y1</code>, and <code>p</code> against <code>y2</code>, and
shades the bit in between using vertical lines.  This is useful for
comparing two order statistics
</p>


<h3>Author(s)</h3>

<p>Robin K. S. Hankin</p>


<h3>See Also</h3>

<p><code><a href="#topic+Davies">Davies</a></code>,<code><a href="stats.html#topic+qqplot">qqplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>twolines.vert(1:100,sort(rnorm(100)),sort(rnorm(100)))
params &lt;- c(10 , 0.1 , 0.1)
twolines.vert(1:100 , sort(rdavies(100,params)) , sort(rdavies(100,params)))
</code></pre>

<hr>
<h2 id='x00m700p4'>Peak concentration for 100 instantaneous releases</h2><span id='topic+x00m700p4'></span>

<h3>Description</h3>

<p>This data set gives the peak concentration for 100 independent
instantaneous releases of neutral-buoyancy gas in a windtunnel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(x00m700p4)</code></pre>


<h3>Format</h3>

<p>A vector containing 100 observations</p>


<h3>References</h3>

<p>D. J. Hall and others 1991.  <em>Repeat variability in
instantaneously released heavy gas clouds&mdash;some wind tunnel model
experiments</em>.  Technical Report LR 804 (PA), Warren Spring
Laboratory, Gunnels Wood Road, Stevenage, Hertfordshire SG1 2BX.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(x00m700p4)
fit.davies.q(x00m700p4)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
