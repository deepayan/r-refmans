<!DOCTYPE html><html lang="en"><head><title>Help for package autoBagging</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {autoBagging}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#autoBagging'><p>autoBagging</p></a></li>
<li><a href='#abmodel'><p>abmodel</p></a></li>
<li><a href='#abmodel-class'><p>abmodel-class</p></a></li>
<li><a href='#baggedtrees'><p>bagged trees models</p></a></li>
<li><a href='#bagging'><p>bagging method</p></a></li>
<li><a href='#bb'><p>Boosting-based pruning of models</p></a></li>
<li><a href='#classmajority.landmarker'><p>classmajority.landmarker</p></a></li>
<li><a href='#classmajority.landmarker.correlation'><p>classmajority.landmarker.correlation</p></a></li>
<li><a href='#classmajority.landmarker.entropy'><p>classmajority.landmarker.entropy</p></a></li>
<li><a href='#classmajority.landmarker.interinfo'><p>classmajority.landmarker.interinfo</p></a></li>
<li><a href='#classmajority.landmarker.mutual.information'><p>classmajority.landmarker.mutual.information</p></a></li>
<li><a href='#ContAttrs'><p>Retrieve names of continuous attributes (not including the target)</p></a></li>
<li><a href='#dstump.landmarker_d1'><p>dstump.landmarker_d1</p></a></li>
<li><a href='#dstump.landmarker_d1.correlation'><p>dstump.landmarker_d1.correlation</p></a></li>
<li><a href='#dstump.landmarker_d1.entropy'><p>dstump.landmarker_d1.entropy</p></a></li>
<li><a href='#dstump.landmarker_d1.interinfo'><p>dstump.landmarker_d1.interinfo</p></a></li>
<li><a href='#dstump.landmarker_d1.mutual.information'><p>dstump.landmarker_d1.mutual.information</p></a></li>
<li><a href='#dstump.landmarker_d2'><p>dstump.landmarker_d2</p></a></li>
<li><a href='#dstump.landmarker_d2.correlation'><p>dstump.landmarker_d2.correlation</p></a></li>
<li><a href='#dstump.landmarker_d2.entropy'><p>dstump.landmarker_d2.entropy</p></a></li>
<li><a href='#dstump.landmarker_d2.interinfo'><p>dstump.landmarker_d2.interinfo</p></a></li>
<li><a href='#dstump.landmarker_d2.mutual.information'><p>dstump.landmarker_d2.mutual.information</p></a></li>
<li><a href='#dstump.landmarker_d3'><p>dstump.landmarker_d3</p></a></li>
<li><a href='#dstump.landmarker_d3.correlation'><p>dstump.landmarker_d3.correlation</p></a></li>
<li><a href='#dstump.landmarker_d3.entropy'><p>dstump.landmarker_d3.entropy</p></a></li>
<li><a href='#dstump.landmarker_d3.interinfo'><p>dstump.landmarker_d3.interinfo</p></a></li>
<li><a href='#dstump.landmarker_d3.mutual.information'><p>dstump.landmarker_d3.mutual.information</p></a></li>
<li><a href='#get_target'><p>get target variable</p></a></li>
<li><a href='#GetMeasure'><p>Retrieve the value of a previously computed measure</p></a></li>
<li><a href='#KNORA.E'><p>K-Nearest-ORAcle-Eliminate</p></a></li>
<li><a href='#lda.landmarker.correlation'><p>lda.landmarker.correlation</p></a></li>
<li><a href='#majority_voting'><p>majority voting</p></a></li>
<li><a href='#mdsq'><p>Margin Distance Minimization</p></a></li>
<li><a href='#nb.landmarker'><p>nb.landmarker</p></a></li>
<li><a href='#nb.landmarker.correlation'><p>nb.landmarker.correlation</p></a></li>
<li><a href='#nb.landmarker.entropy'><p>nb.landmarker.entropy</p></a></li>
<li><a href='#nb.landmarker.interinfo'><p>nb.landmarker.interinfo</p></a></li>
<li><a href='#nb.landmarker.mutual.information'><p>nb.landmarker.mutual.information</p></a></li>
<li><a href='#OLA'><p>Overall Local Accuracy</p></a></li>
<li><a href='#predict+2Cabmodel-method'><p>Predicting on new data with a <strong>abmodel</strong> model</p></a></li>
<li><a href='#ReadDF'><p>FUNCTION TO TRANSFORM DATA FRAME INTO LIST WITH GSI REQUIREMENTS</p></a></li>
<li><a href='#SymbAttrs'><p>Retrieve names of symbolic attributes (not including the target)</p></a></li>
<li><a href='#sysdata'><p>sysdata</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Learning to Rank Bagging Workflows with Metalearning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Fabio Pinto [aut],
  Vitor Cerqueira [cre],
  Carlos Soares [ctb],
  Joao Mendes-Moreira [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Vitor Cerqueira &lt;cerqueira.vitormanuel@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A framework for automated machine learning. Concretely, the focus is on the optimisation of bagging workflows. A bagging workflows is composed by three phases: (i) generation: which and how many predictive models to learn; (ii) pruning: after learning a set of models, the worst ones are cut off from the ensemble; and (iii) integration: how the models are combined for predicting a new observation. autoBagging optimises these processes by combining metalearning and a learning to rank approach to learn from metadata. It automatically ranks 63 bagging workflows by exploiting past performance and dataset characterization. A complete description of the method can be found in: Pinto, F., Cerqueira, V., Soares, C., Mendes-Moreira, J. (2017): "autoBagging: Learning to Rank Bagging Workflows with Metalearning" arXiv preprint arXiv:1706.09367.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>Imports:</td>
<td>cluster, xgboost, methods, e1071, rpart, abind, caret, MASS,
entropy, lsr, CORElearn, infotheo, minerva, party</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.0.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-07-01 16:56:00 UTC; root</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-07-02 00:06:44 UTC</td>
</tr>
</table>
<hr>
<h2 id='autoBagging'>autoBagging</h2><span id='topic+autoBagging'></span><span id='topic+autoBagging-package'></span>

<h3>Description</h3>

<p>Learning to Rank Bagging Workflows with Metalearning
</p>
<p>Machine Learning (ML) has been successfully applied to a
wide range of domains and applications. One of the techniques
behind most of these successful applications is Ensemble Learning (EL),
the field of ML that gave birth to methods such as Random Forests
or Boosting. The complexity of applying these techniques together
with the market scarcity on ML experts, has created the need for
systems that enable a fast and easy drop-in replacement for ML libraries.
Automated machine learning (autoML) is the field of ML that attempts
to answers these needs. Typically, these systems rely on optimization
techniques such as bayesian optimization to lead the search for the
best model. Our approach differs from these systems by making use of
the most recent advances on metalearning and a learning to rank
approach to learn from metadata. We propose autoBagging, an autoML
system that automatically ranks 63 bagging workflows by exploiting
past performance and dataset characterization. Results on 140
classification datasets from the OpenML platform show that autoBagging
can yield better performance than the Average Rank method and achieve
results that are not statistically different from an ideal model that
systematically selects the best workflow for each dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>autoBagging(form, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="autoBagging_+3A_form">form</code></td>
<td>
<p>formula. Currently supporting only categorical target
variables (classification tasks)</p>
</td></tr>
<tr><td><code id="autoBagging_+3A_data">data</code></td>
<td>
<p>training dataset with a categorical target variable</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The underlying model leverages the performance of the workflows
in historical data. It ranks and recommends workflows for a given
classification task. A bagging workflow is comprised by the following steps:
</p>

<dl>
<dt>generation</dt><dd><p>the number of trees to grow</p>
</dd>
<dt>pruning</dt><dd><p>the pruning of low performing trees in the ensemble</p>
</dd>
<dt>pruning cut-point</dt><dd><p>a parameter of the previous step</p>
</dd>
<dt>dynamic selection</dt><dd><p>the dynamic selection method used
to aggregate predictions. If none is recommended, majority voting
is used.</p>
</dd>
</dl>



<h3>Value</h3>

<p>an <code>abmodel</code> class object
</p>


<h3>References</h3>

<p>Pinto, F., Cerqueira, V., Soares, C., Mendes-Moreira, J.:
&quot;autoBagging: Learning to Rank Bagging Workflows
with Metalearning&quot; arXiv preprint arXiv:1706.09367 (2017).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bagging">bagging</a></code> for the bagging pipeline with a specific
workflow; <code><a href="#topic+baggedtrees">baggedtrees</a></code> for the bagging implementation;
<code><a href="#topic+abmodel-class">abmodel-class</a></code> for the returning class object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# splitting an example dataset into train/test:
train &lt;- iris[1:(.7*nrow(iris)), ]
test &lt;- iris[-c(1:(.7*nrow(iris))), ]
# then apply autoBagging to the train, using the desired formula:
# autoBagging will compute metafeatures on the dataset
# and apply a pre-trained ranking model to recommend a workflow.
model &lt;- autoBagging(Species ~., train)
# predictions are produced with the standard predict method
preds &lt;- predict(model, test)

## End(Not run)
</code></pre>

<hr>
<h2 id='abmodel'>abmodel</h2><span id='topic+abmodel'></span>

<h3>Description</h3>

<p>abmodel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>abmodel(base_models, form, data, dynamic_selection)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="abmodel_+3A_base_models">base_models</code></td>
<td>
<p>a list of decision tree classifiers</p>
</td></tr>
<tr><td><code id="abmodel_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="abmodel_+3A_data">data</code></td>
<td>
<p>dataset used to train <code>base_models</code></p>
</td></tr>
<tr><td><code id="abmodel_+3A_dynamic_selection">dynamic_selection</code></td>
<td>
<p>the dynamic selection/combination method
to use to aggregate predictions. If <code>none</code>, majority vote is used.</p>
</td></tr>
</table>

<hr>
<h2 id='abmodel-class'>abmodel-class</h2><span id='topic+abmodel-class'></span>

<h3>Description</h3>

<p><strong>abmodel</strong> is an S4 class that contains the ensemble model.
Besides the base learning algorithms&ndash;<code>base_models</code> &ndash;
<strong>abmodel</strong> class contains information about the
dynamic selection method to apply in new data.
</p>


<h3>Slots</h3>


<dl>
<dt><code>base_models</code></dt><dd><p>a list of decision tree classifiers</p>
</dd>
<dt><code>form</code></dt><dd><p>formula</p>
</dd>
<dt><code>data</code></dt><dd><p>dataset used to train <code>base_models</code></p>
</dd>
<dt><code>dynamic_selection</code></dt><dd><p>the dynamic selection/combination method
to use to aggregate predictions. If <code>none</code>, majority vote is used.</p>
</dd>
</dl>


<h3>See Also</h3>

<p><code><a href="#topic+autoBagging">autoBagging</a></code> function for the
method of automatic predicting of the best workflows.
</p>

<hr>
<h2 id='baggedtrees'>bagged trees models</h2><span id='topic+baggedtrees'></span>

<h3>Description</h3>

<p>The standard resampling with replacement (bootstrap) is used
as sampling strategy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>baggedtrees(form, data, ntree = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="baggedtrees_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="baggedtrees_+3A_data">data</code></td>
<td>
<p>training data</p>
</td></tr>
<tr><td><code id="baggedtrees_+3A_ntree">ntree</code></td>
<td>
<p>no of trees</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>ensemble &lt;- baggedtrees(Species ~., iris, ntree = 50)

</code></pre>

<hr>
<h2 id='bagging'>bagging method</h2><span id='topic+bagging'></span>

<h3>Description</h3>

<p>bagging method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bagging(form, data, ntrees, pruning, dselection, pruning_cp)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bagging_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bagging_+3A_data">data</code></td>
<td>
<p>training data</p>
</td></tr>
<tr><td><code id="bagging_+3A_ntrees">ntrees</code></td>
<td>
<p>ntrees</p>
</td></tr>
<tr><td><code id="bagging_+3A_pruning">pruning</code></td>
<td>
<p>model pruning method. A character vector. Currently, the
following methods are supported:
</p>

<dl>
<dt>mdsq</dt><dd><p>Margin-distance minimisation</p>
</dd>
<dt>bb</dt><dd><p>boosting based pruning</p>
</dd>
<dt>none</dt><dd><p>no pruning</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="bagging_+3A_dselection">dselection</code></td>
<td>
<p>dynamic selection of the available models. Currently, the
following methods are supported:
</p>

<dl>
<dt>ola</dt><dd><p>Overall Local Accuracy</p>
</dd>
<dt>knora-e</dt><dd><p>K-nearest-oracles-eliminate</p>
</dd>
<dt>none</dt><dd><p>no dynamic selection. Majority voting is used.</p>
</dd>
</dl>
</td></tr>
<tr><td><code id="bagging_+3A_pruning_cp">pruning_cp</code></td>
<td>
<p>The pruning cutpoint for the <code>pruning</code> method
picked.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code><a href="#topic+baggedtrees">baggedtrees</a></code> for the implementation of the bagging model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># splitting an example dataset into train/test:
train &lt;- iris[1:(.7*nrow(iris)), ]
test &lt;- iris[-c(1:(.7*nrow(iris))), ]
form &lt;- Species ~.
# a user-defined bagging workflow
m &lt;- bagging(form, iris, ntrees = 5, pruning = "bb", pruning_cp = .5, dselection = "ola")
preds &lt;- predict(m, test)
# a standard bagging workflow with 5 trees (5 trees for examplification purposes):
m2 &lt;- bagging(form, iris, ntrees = 5, pruning = "none", dselection = "none")
preds2 &lt;- predict(m2, test)

</code></pre>

<hr>
<h2 id='bb'>Boosting-based pruning of models</h2><span id='topic+bb'></span>

<h3>Description</h3>

<p>Boosting-based pruning of models
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bb(form, preds, data, cutPoint)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bb_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="bb_+3A_preds">preds</code></td>
<td>
<p>predictions in training data</p>
</td></tr>
<tr><td><code id="bb_+3A_data">data</code></td>
<td>
<p>training data</p>
</td></tr>
<tr><td><code id="bb_+3A_cutpoint">cutPoint</code></td>
<td>
<p>ratio of the total number of models to cut off</p>
</td></tr>
</table>

<hr>
<h2 id='classmajority.landmarker'>classmajority.landmarker</h2><span id='topic+classmajority.landmarker'></span>

<h3>Description</h3>

<p>classmajority.landmarker
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classmajority.landmarker(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classmajority.landmarker_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="classmajority.landmarker_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='classmajority.landmarker.correlation'>classmajority.landmarker.correlation</h2><span id='topic+classmajority.landmarker.correlation'></span>

<h3>Description</h3>

<p>classmajority.landmarker.correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classmajority.landmarker.correlation(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classmajority.landmarker.correlation_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="classmajority.landmarker.correlation_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='classmajority.landmarker.entropy'>classmajority.landmarker.entropy</h2><span id='topic+classmajority.landmarker.entropy'></span>

<h3>Description</h3>

<p>classmajority.landmarker.entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classmajority.landmarker.entropy(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classmajority.landmarker.entropy_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="classmajority.landmarker.entropy_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='classmajority.landmarker.interinfo'>classmajority.landmarker.interinfo</h2><span id='topic+classmajority.landmarker.interinfo'></span>

<h3>Description</h3>

<p>classmajority.landmarker.interinfo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classmajority.landmarker.interinfo(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classmajority.landmarker.interinfo_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="classmajority.landmarker.interinfo_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='classmajority.landmarker.mutual.information'>classmajority.landmarker.mutual.information</h2><span id='topic+classmajority.landmarker.mutual.information'></span>

<h3>Description</h3>

<p>classmajority.landmarker.mutual.information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classmajority.landmarker.mutual.information(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classmajority.landmarker.mutual.information_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="classmajority.landmarker.mutual.information_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='ContAttrs'>Retrieve names of continuous attributes (not including the target)</h2><span id='topic+ContAttrs'></span>

<h3>Description</h3>

<p>Retrieve names of continuous attributes (not including the target)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ContAttrs(dataset)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ContAttrs_+3A_dataset">dataset</code></td>
<td>
<p>structure describing the data set, according
to <code>read_data.R</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of strings
</p>


<h3>See Also</h3>

<p>read_data.R
</p>

<hr>
<h2 id='dstump.landmarker_d1'>dstump.landmarker_d1</h2><span id='topic+dstump.landmarker_d1'></span>

<h3>Description</h3>

<p>dstump.landmarker_d1
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d1(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d1_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d1_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d1.correlation'>dstump.landmarker_d1.correlation</h2><span id='topic+dstump.landmarker_d1.correlation'></span>

<h3>Description</h3>

<p>dstump.landmarker_d1.correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d1.correlation(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d1.correlation_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d1.correlation_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d1.entropy'>dstump.landmarker_d1.entropy</h2><span id='topic+dstump.landmarker_d1.entropy'></span>

<h3>Description</h3>

<p>dstump.landmarker_d1.entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d1.entropy(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d1.entropy_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d1.entropy_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d1.interinfo'>dstump.landmarker_d1.interinfo</h2><span id='topic+dstump.landmarker_d1.interinfo'></span>

<h3>Description</h3>

<p>dstump.landmarker_d1.interinfo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d1.interinfo(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d1.interinfo_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d1.interinfo_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d1.mutual.information'>dstump.landmarker_d1.mutual.information</h2><span id='topic+dstump.landmarker_d1.mutual.information'></span>

<h3>Description</h3>

<p>dstump.landmarker_d1.mutual.information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d1.mutual.information(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d1.mutual.information_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d1.mutual.information_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d2'>dstump.landmarker_d2</h2><span id='topic+dstump.landmarker_d2'></span>

<h3>Description</h3>

<p>dstump.landmarker_d2
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d2(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d2_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d2_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d2.correlation'>dstump.landmarker_d2.correlation</h2><span id='topic+dstump.landmarker_d2.correlation'></span>

<h3>Description</h3>

<p>dstump.landmarker_d2.correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d2.correlation(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d2.correlation_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d2.correlation_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d2.entropy'>dstump.landmarker_d2.entropy</h2><span id='topic+dstump.landmarker_d2.entropy'></span>

<h3>Description</h3>

<p>dstump.landmarker_d2.entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d2.entropy(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d2.entropy_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d2.entropy_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d2.interinfo'>dstump.landmarker_d2.interinfo</h2><span id='topic+dstump.landmarker_d2.interinfo'></span>

<h3>Description</h3>

<p>dstump.landmarker_d2.interinfo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d2.interinfo(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d2.interinfo_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d2.interinfo_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d2.mutual.information'>dstump.landmarker_d2.mutual.information</h2><span id='topic+dstump.landmarker_d2.mutual.information'></span>

<h3>Description</h3>

<p>dstump.landmarker_d2.mutual.information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d2.mutual.information(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d2.mutual.information_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d2.mutual.information_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d3'>dstump.landmarker_d3</h2><span id='topic+dstump.landmarker_d3'></span>

<h3>Description</h3>

<p>dstump.landmarker_d3
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d3(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d3_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d3_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d3.correlation'>dstump.landmarker_d3.correlation</h2><span id='topic+dstump.landmarker_d3.correlation'></span>

<h3>Description</h3>

<p>dstump.landmarker_d3.correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d3.correlation(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d3.correlation_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d3.correlation_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d3.entropy'>dstump.landmarker_d3.entropy</h2><span id='topic+dstump.landmarker_d3.entropy'></span>

<h3>Description</h3>

<p>dstump.landmarker_d3.entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d3.entropy(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d3.entropy_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d3.entropy_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d3.interinfo'>dstump.landmarker_d3.interinfo</h2><span id='topic+dstump.landmarker_d3.interinfo'></span>

<h3>Description</h3>

<p>dstump.landmarker_d3.interinfo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d3.interinfo(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d3.interinfo_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d3.interinfo_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='dstump.landmarker_d3.mutual.information'>dstump.landmarker_d3.mutual.information</h2><span id='topic+dstump.landmarker_d3.mutual.information'></span>

<h3>Description</h3>

<p>dstump.landmarker_d3.mutual.information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dstump.landmarker_d3.mutual.information(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dstump.landmarker_d3.mutual.information_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="dstump.landmarker_d3.mutual.information_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='get_target'>get target variable</h2><span id='topic+get_target'></span>

<h3>Description</h3>

<p>get the target variable from a formula
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_target(form)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_target_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
</table>

<hr>
<h2 id='GetMeasure'>Retrieve the value of a previously computed measure</h2><span id='topic+GetMeasure'></span>

<h3>Description</h3>

<p>Retrieve the value of a previously computed measure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GetMeasure(inDCName, inDCSet, component.name = "value")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GetMeasure_+3A_indcname">inDCName</code></td>
<td>
<p>name of data characteristics</p>
</td></tr>
<tr><td><code id="GetMeasure_+3A_indcset">inDCSet</code></td>
<td>
<p>set of data characteristics already computed</p>
</td></tr>
<tr><td><code id="GetMeasure_+3A_component.name">component.name</code></td>
<td>
<p>name of component (e.g. time or value) to
retrieve; if NULL retrieve all</p>
</td></tr>
</table>


<h3>Value</h3>

<p>simple or structured value
</p>


<h3>Note</h3>

<p>if measure is not available, stop execution with error
</p>

<hr>
<h2 id='KNORA.E'>K-Nearest-ORAcle-Eliminate</h2><span id='topic+KNORA.E'></span>

<h3>Description</h3>

<p>A dynamic selection method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>KNORA.E(form, mod, v.data, t.data, k = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="KNORA.E_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="KNORA.E_+3A_mod">mod</code></td>
<td>
<p>a list comprising the individual models</p>
</td></tr>
<tr><td><code id="KNORA.E_+3A_v.data">v.data</code></td>
<td>
<p>validation data</p>
</td></tr>
<tr><td><code id="KNORA.E_+3A_t.data">t.data</code></td>
<td>
<p>test data, with the instances to predict</p>
</td></tr>
<tr><td><code id="KNORA.E_+3A_k">k</code></td>
<td>
<p>the number of nearest neighbors. Defaults to 5.</p>
</td></tr>
</table>

<hr>
<h2 id='lda.landmarker.correlation'>lda.landmarker.correlation</h2><span id='topic+lda.landmarker.correlation'></span>

<h3>Description</h3>

<p>lda.landmarker.correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'landmarker.correlation'
lda(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lda.landmarker.correlation_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="lda.landmarker.correlation_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='majority_voting'>majority voting</h2><span id='topic+majority_voting'></span>

<h3>Description</h3>

<p>majority voting
</p>


<h3>Usage</h3>

<pre><code class='language-R'>majority_voting(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="majority_voting_+3A_x">x</code></td>
<td>
<p>predictions produced by a set of models</p>
</td></tr>
</table>

<hr>
<h2 id='mdsq'>Margin Distance Minimization</h2><span id='topic+mdsq'></span>

<h3>Description</h3>

<p>Margin Distance Minimization
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdsq(form, preds, data, cutPoint)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mdsq_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="mdsq_+3A_preds">preds</code></td>
<td>
<p>predictions in training data</p>
</td></tr>
<tr><td><code id="mdsq_+3A_data">data</code></td>
<td>
<p>training data</p>
</td></tr>
<tr><td><code id="mdsq_+3A_cutpoint">cutPoint</code></td>
<td>
<p>ratio of the total number of models to cut off</p>
</td></tr>
</table>

<hr>
<h2 id='nb.landmarker'>nb.landmarker</h2><span id='topic+nb.landmarker'></span>

<h3>Description</h3>

<p>nb.landmarker
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nb.landmarker(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nb.landmarker_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="nb.landmarker_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='nb.landmarker.correlation'>nb.landmarker.correlation</h2><span id='topic+nb.landmarker.correlation'></span>

<h3>Description</h3>

<p>nb.landmarker.correlation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nb.landmarker.correlation(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nb.landmarker.correlation_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="nb.landmarker.correlation_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='nb.landmarker.entropy'>nb.landmarker.entropy</h2><span id='topic+nb.landmarker.entropy'></span>

<h3>Description</h3>

<p>nb.landmarker.entropy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nb.landmarker.entropy(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nb.landmarker.entropy_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="nb.landmarker.entropy_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='nb.landmarker.interinfo'>nb.landmarker.interinfo</h2><span id='topic+nb.landmarker.interinfo'></span>

<h3>Description</h3>

<p>nb.landmarker.interinfo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nb.landmarker.interinfo(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nb.landmarker.interinfo_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="nb.landmarker.interinfo_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='nb.landmarker.mutual.information'>nb.landmarker.mutual.information</h2><span id='topic+nb.landmarker.mutual.information'></span>

<h3>Description</h3>

<p>nb.landmarker.mutual.information
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nb.landmarker.mutual.information(dataset, data.char)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="nb.landmarker.mutual.information_+3A_dataset">dataset</code></td>
<td>
<p>train data for the landmarker</p>
</td></tr>
<tr><td><code id="nb.landmarker.mutual.information_+3A_data.char">data.char</code></td>
<td>
<p>dc</p>
</td></tr>
</table>

<hr>
<h2 id='OLA'>Overall Local Accuracy</h2><span id='topic+OLA'></span>

<h3>Description</h3>

<p>A dynamic selection method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>OLA(form, mod, v.data, t.data, k = 5)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="OLA_+3A_form">form</code></td>
<td>
<p>formula</p>
</td></tr>
<tr><td><code id="OLA_+3A_mod">mod</code></td>
<td>
<p>a list comprising the individual models</p>
</td></tr>
<tr><td><code id="OLA_+3A_v.data">v.data</code></td>
<td>
<p>validation data</p>
</td></tr>
<tr><td><code id="OLA_+3A_t.data">t.data</code></td>
<td>
<p>test data, with the instances to predict</p>
</td></tr>
<tr><td><code id="OLA_+3A_k">k</code></td>
<td>
<p>the number of nearest neighbors. Defaults to 5.</p>
</td></tr>
</table>

<hr>
<h2 id='predict+2Cabmodel-method'>Predicting on new data with a <strong>abmodel</strong> model</h2><span id='topic+predict+2Cabmodel-method'></span>

<h3>Description</h3>

<p>This is a <code>predict</code> method for predicting new data points using a
<code>abmodel</code> class object - refering to an ensemble
of bagged trees
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'abmodel'
predict(object, newdata)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict+2B2Cabmodel-method_+3A_object">object</code></td>
<td>
<p>A <strong>abmodel-class</strong> object.</p>
</td></tr>
<tr><td><code id="predict+2B2Cabmodel-method_+3A_newdata">newdata</code></td>
<td>
<p>New data to predict using an <code>abmodel</code> object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>predictions produced by an <code>abmodel</code> model.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+abmodel-class">abmodel-class</a></code> for details about the bagging model;
</p>

<hr>
<h2 id='ReadDF'>FUNCTION TO TRANSFORM DATA FRAME INTO LIST WITH GSI REQUIREMENTS</h2><span id='topic+ReadDF'></span>

<h3>Description</h3>

<p>FUNCTION TO TRANSFORM DATA FRAME INTO LIST WITH GSI REQUIREMENTS
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ReadDF(dat)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ReadDF_+3A_dat">dat</code></td>
<td>
<p>data frame</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list containing components that describe
the names (see ReadtAttrsInfo) and the data (see ReadData) files
</p>
<p>THIS FUNCTION HAS TO BE BASED IN READATTRSINFO AND READDATA
</p>

<hr>
<h2 id='SymbAttrs'>Retrieve names of symbolic attributes (not including the target)</h2><span id='topic+SymbAttrs'></span>

<h3>Description</h3>

<p>Retrieve names of symbolic attributes (not including the target)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SymbAttrs(dataset)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="SymbAttrs_+3A_dataset">dataset</code></td>
<td>
<p>structure describing the data set, according
to <code>read_data.R</code></p>
</td></tr>
</table>


<h3>Value</h3>

<p>list of strings
</p>


<h3>See Also</h3>

<p>read_data.R
</p>

<hr>
<h2 id='sysdata'>sysdata</h2><span id='topic+sysdata'></span>

<h3>Description</h3>

<p>Meta data needed to run the <strong>autoBagging</strong> method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sysdata
</code></pre>


<h3>Format</h3>

<p>a list comprising the following information
</p>

<dl>
<dt>avgRankMatrix</dt><dd><p>the average rank data regarding each bagging
workflow</p>
</dd>
<dt>workflows</dt><dd><p>metadata on the bagging workflows</p>
</dd>
<dt>MaxMinMetafeatures</dt><dd><p>range data on each metafeature</p>
</dd>
<dt>metafeatures</dt><dd><p>names and values of each metafeatures used
to describe the datasets</p>
</dd>
<dt>metamodel</dt><dd><p>the xgboost ranking metamodel</p>
</dd>
</dl>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
