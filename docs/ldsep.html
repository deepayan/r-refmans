<!DOCTYPE html><html><head><title>Help for package ldsep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ldsep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Dprime'><p>Get the standardized composite D'.</p></a></li>
<li><a href='#format_lddf'><p>Format an element of <code>mldest()</code> or</p>
<code>sldest()</code> into an
upper-triangular matrix.</a></li>
<li><a href='#get_prob_array'><p>Obtain the distribution of genotypes given haplotype frequencies under HWE</p></a></li>
<li><a href='#gl_to_gp'><p>Normalize genotype likelihoods to posterior probabilities.</p></a></li>
<li><a href='#glike'><p>Genotype log-likelihoods from <code>uit</code></p></a></li>
<li><a href='#gp'><p>Posterior probabilities from <code>uit</code></p></a></li>
<li><a href='#is.lddf'><p>Tests if an argument is a <code>lddf</code> object.</p></a></li>
<li><a href='#ldest'><p>Pairwise LD estimation in polyploids.</p></a></li>
<li><a href='#ldest_comp'><p>Estimates of composite pairwise LD based either on genotype estimates or</p>
genotype likelihoods.</a></li>
<li><a href='#ldest_hap'><p>Estimate haplotypic pair-wise LD using either genotypes or genotype</p>
likelihoods.</a></li>
<li><a href='#ldfast'><p>Fast bias-correction for LD Estimation</p></a></li>
<li><a href='#ldsep-package'><p>Linkage Disequilibrium Shrinkage Estimation for Polyploids</p></a></li>
<li><a href='#ldshrink'><p>Obtain shrinkage estimates of correlation from output of</p>
<code>mldest()</code> or <code>sldest()</code>.</a></li>
<li><a href='#mldest'><p>Estimate all pair-wise LD's in a collection of SNPs using genotypes or</p>
genotype likelihoods.</a></li>
<li><a href='#pbnorm_dist'><p>Returns distribution of proportional bivariate normal.</p></a></li>
<li><a href='#plot.lddf'><p>Plot the output of <code>mldest()</code> or</p>
<code>sldest()</code> using <code>corrplot()</code></a></li>
<li><a href='#pvcalc'><p>Calculate prior variances from a matrix of prior genotype probabilities.</p></a></li>
<li><a href='#slcor'><p>Sliding window correlation</p></a></li>
<li><a href='#sldest'><p>Sliding window LD estimation</p></a></li>
<li><a href='#uit'><p>Updog fits on the data from Uitdewilligen et. al. (2013)</p></a></li>
<li><a href='#zshrink'><p>Shrinks Fisher-z transformed correlation estimates and returns resulting</p>
correlation estimates.</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Linkage Disequilibrium Shrinkage Estimation for Polyploids</td>
</tr>
<tr>
<td>Version:</td>
<td>2.1.5</td>
</tr>
<tr>
<td>Description:</td>
<td>Estimate haplotypic or composite pairwise linkage disequilibrium
    (LD) in polyploids, using either genotypes or genotype likelihoods. 
    Support is provided to estimate the popular measures of LD: the LD 
    coefficient D, the standardized LD coefficient D', and the Pearson 
    correlation coefficient r. All estimates are returned with corresponding 
    standard errors. These estimates and standard errors can then be used
    for shrinkage estimation. The main functions are ldfast(), ldest(), mldest(),
    sldest(), plot.lddf(), format_lddf(), and ldshrink(). Details of the methods
    are available in Gerard (2021a) &lt;<a href="https://doi.org/10.1111%2F1755-0998.13349">doi:10.1111/1755-0998.13349</a>&gt;
    and Gerard (2021b) &lt;<a href="https://doi.org/10.1038%2Fs41437-021-00462-5">doi:10.1038/s41437-021-00462-5</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/dcgerard/ldsep/issues">https://github.com/dcgerard/ldsep/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.1</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp, foreach, doParallel, ashr, corrplot, lpSolve, abind,
modeest, matrixStats</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, covr, knitr, rmarkdown, updog (&ge; 2.0.2),
VariantAnnotation</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-10-18 14:34:18 UTC; dgerard</td>
</tr>
<tr>
<td>Author:</td>
<td>David Gerard <a href="https://orcid.org/0000-0001-9450-5023"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>David Gerard &lt;gerard.1787@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-10-18 22:52:43 UTC</td>
</tr>
</table>
<hr>
<h2 id='Dprime'>Get the standardized composite D'.</h2><span id='topic+Dprime'></span>

<h3>Description</h3>

<p>This function will either standardize by the maximum covariance
conditional on the marginal genotype distribution, or by the
maximum covariance conditional on the marginal allele frequencies.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Dprime(qmat, type = c("allele", "geno"), constrain = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Dprime_+3A_qmat">qmat</code></td>
<td>
<p>The observed joint genotype distribution.</p>
</td></tr>
<tr><td><code id="Dprime_+3A_type">type</code></td>
<td>
<p>Should we condition on the marginal genotype distribution
(<code>type = "geno"</code>), or should we condition on the allele frequency
(<code>type = "allele"</code>)?</p>
</td></tr>
<tr><td><code id="Dprime_+3A_constrain">constrain</code></td>
<td>
<p>A logical. This option is only applicable when
<code>type = "allele"</code>. Should return an value that is equal
to D' under HWE (<code>FALSE</code>) or a value that is constrained
to lie between -1 and 1 (<code>TRUE</code>)? Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Note that when <code>type = "allele"</code> and <code>constrain = FALSE</code>,
the resulting D' is constrained to fall between -K and K, where
K is the ploidy of the species. However, under HWE, this measure is
equal to haplotypic D'. Using <code>constrain = TRUE</code> will result
in a measure that is constrained to lie between -1 and 1, but
it will not equal haplotypic D' under HWE.
</p>
<p>Using <code>type = "geno"</code> is its own thing and will not equal
D' generally under HWE. When <code>type = "geno"</code>, then the
the <code>constrain</code> parameter has no effect.
</p>


<h3>Value</h3>

<p>A vector of length 2. The first element is the estimated
D'. The second element is the normalization used.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>K &lt;- 6
qmat &lt;- matrix(stats::runif((K+1)^2), nrow = K+1)
qmat &lt;- qmat / sum(qmat)
Dprime(qmat, type = "geno")
Dprime(qmat, type = "allele")

</code></pre>

<hr>
<h2 id='format_lddf'>Format an element of <code><a href="#topic+mldest">mldest</a>()</code> or
<code><a href="#topic+sldest">sldest</a>()</code> into an
upper-triangular matrix.</h2><span id='topic+format_lddf'></span>

<h3>Description</h3>

<p>Formats the LD estimates and standard errors output
from running <code><a href="#topic+mldest">mldest</a>()</code> or <code><a href="#topic+sldest">sldest</a>()</code>
into a more conventional upper-triangular matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_lddf(obj, element = "r2")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_lddf_+3A_obj">obj</code></td>
<td>
<p>An object of class <code>lddf</code>, usually output from
running either <code><a href="#topic+mldest">mldest</a>()</code> or
<code><a href="#topic+sldest">sldest</a>()</code>.</p>
</td></tr>
<tr><td><code id="format_lddf_+3A_element">element</code></td>
<td>
<p>Which element in <code>obj</code> should we format into an
upper-triangular matrix?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of the selected elements. Only the upper-triangle of the
matrix is filled. The lower-triangle and the diagonal are <code>NA</code>'s.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

## Simulate genotypes when true correlation is 0
nloci &lt;- 5
nind  &lt;- 100
K &lt;- 6
nc &lt;- 1
genomat &lt;- matrix(sample(0:K, nind * nloci, TRUE), nrow = nloci)

## Haplotypic LD estimates
lddf &lt;- mldest(geno = genomat,
               K = K,
               nc = nc,
               type = "hap")

## Obtain the D estimates in matrix form
Dmat &lt;- format_lddf(obj = lddf, element = "D")
Dmat

</code></pre>

<hr>
<h2 id='get_prob_array'>Obtain the distribution of genotypes given haplotype frequencies under HWE</h2><span id='topic+get_prob_array'></span>

<h3>Description</h3>

<p>This function will calculate the (log) probabilities for all genotype
combinations at two loci given just the haplotype frequencies. This
is under the assumptions of HWE.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_prob_array(K, prob, log_p = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_prob_array_+3A_k">K</code></td>
<td>
<p>The ploidy of the species.</p>
</td></tr>
<tr><td><code id="get_prob_array_+3A_prob">prob</code></td>
<td>
<p>Haplotype frequencies in the order of (ab, Ab, aB, AB).</p>
</td></tr>
<tr><td><code id="get_prob_array_+3A_log_p">log_p</code></td>
<td>
<p>A logical. Should we return the log-probabilities (<code>TRUE</code>)
or the probabilities (<code>FALSE</code>). Defaults to <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Element (i, j) is the (log) probability of genotype i-1 at locus 1
and genotype j-1 at locus 2.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>get_prob_array(K = 6, prob = c(0.1, 0.2, 0.3, 0.4), log_p = FALSE)

</code></pre>

<hr>
<h2 id='gl_to_gp'>Normalize genotype likelihoods to posterior probabilities.</h2><span id='topic+gl_to_gp'></span>

<h3>Description</h3>

<p>This will take genotype log-likelihoods and normalize them to
sum to one. This corresponds to using a naive discrete uniform prior
over the genotypes. It is not generally recommended that you use this
function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gl_to_gp(gl)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gl_to_gp_+3A_gl">gl</code></td>
<td>
<p>A three dimensional array of genotype <em>log</em>-likelihoods.
Element <code>gl[i, j, k]</code> is the genotype log-likelihood of dosage
<code>k</code> for individual <code>j</code> at SNP <code>i</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A three-dimensional array, of the same dimensions as <code>gl</code>,
containing the posterior probabilities of each dosage.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("glike")
class(glike)
dim(glike)
gl_to_gp(glike)

</code></pre>

<hr>
<h2 id='glike'>Genotype log-likelihoods from <code><a href="#topic+uit">uit</a></code></h2><span id='topic+glike'></span>

<h3>Description</h3>

<p>Contains an array of genotype log-likelihoods from
the <code><a href="#topic+uit">uit</a></code> dataset. Element <code>gp[i, j, k]</code> is the
log-likelihood of dosage <code>k-1</code> for individual <code>j</code>
at SNP <code>i</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>glike
</code></pre>


<h3>Format</h3>

<p>A three-dimensional <code>array</code> object.
</p>


<h3>Source</h3>

<p><a href="https://doi.org/10.1371/journal.pone.0062355">doi:10.1371/journal.pone.0062355</a>
</p>


<h3>References</h3>


<ul>
<li><p>Uitdewilligen, Jan GAML, Anne-Marie A. Wolters, B. Bjorn, Theo JA Borm, Richard GF Visser, and Herman J. Van Eck. &quot;A next-generation sequencing method for genotyping-by-sequencing of highly heterozygous autotetraploid potato.&quot; <em>PloS one</em> 8, no. 5 (2013): e62355. <a href="https://doi.org/10.1371/journal.pone.0062355">doi:10.1371/journal.pone.0062355</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+uit">uit</a></code> for the full <code>multidog()</code> fit.
</p>

<hr>
<h2 id='gp'>Posterior probabilities from <code><a href="#topic+uit">uit</a></code></h2><span id='topic+gp'></span>

<h3>Description</h3>

<p>Contains an array of posterior probabilities of the genotypes from
the <code><a href="#topic+uit">uit</a></code> dataset. Element <code>gp[i, j, k]</code> is the
posterior probability of dosage <code>k-1</code> for individual <code>j</code>
at SNP <code>i</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gp
</code></pre>


<h3>Format</h3>

<p>A three-dimensional <code>array</code> object.
</p>


<h3>Source</h3>

<p><a href="https://doi.org/10.1371/journal.pone.0062355">doi:10.1371/journal.pone.0062355</a>
</p>


<h3>References</h3>


<ul>
<li><p>Uitdewilligen, Jan GAML, Anne-Marie A. Wolters, B. Bjorn, Theo JA Borm, Richard GF Visser, and Herman J. Van Eck. &quot;A next-generation sequencing method for genotyping-by-sequencing of highly heterozygous autotetraploid potato.&quot; <em>PloS one</em> 8, no. 5 (2013): e62355. <a href="https://doi.org/10.1371/journal.pone.0062355">doi:10.1371/journal.pone.0062355</a>
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+uit">uit</a></code> for the full <code>multidog()</code> fit.
</p>

<hr>
<h2 id='is.lddf'>Tests if an argument is a <code>lddf</code> object.</h2><span id='topic+is.lddf'></span>

<h3>Description</h3>

<p>Tests if an argument is a <code>lddf</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.lddf(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.lddf_+3A_x">x</code></td>
<td>
<p>Anything.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A logical. <code>TRUE</code> if <code>x</code> is a <code>lddf</code> object,
and <code>FALSE</code> otherwise.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is.lddf("anything")
# FALSE

</code></pre>

<hr>
<h2 id='ldest'>Pairwise LD estimation in polyploids.</h2><span id='topic+ldest'></span>

<h3>Description</h3>

<p>Estimates either haplotypic or composite measures of LD using either
genotypes are genotype likelihoods via maximum likelihood.
The usual measures of LD are estimated (D, D', and r) along with
the Fisher-z transformation of r (called &quot;z&quot;). All estimates
are returned with standard errors. See Gerard (2021) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldest(
  ga,
  gb,
  K,
  se = TRUE,
  type = c("hap", "comp"),
  model = c("norm", "flex"),
  pen = ifelse(type == "hap", 2, 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldest_+3A_ga">ga</code></td>
<td>
<p>One of two possible inputs:
</p>

<ol>
<li><p>A vector of counts, containing the genotypes for each
individual at the first locus. When <code>type = "comp"</code>,
the vector of genotypes may be continuous (e.g. the
posterior mean genotype).
</p>
</li>
<li><p>A matrix of genotype log-likelihoods at the first locus.
The rows index the individuals and the columns index
the genotypes. That is <code>ga[i, j]</code> is the genotype
likelihood of individual <code>i</code> for genotype <code>j-1</code>.
</p>
</li></ol>
</td></tr>
<tr><td><code id="ldest_+3A_gb">gb</code></td>
<td>
<p>One of two possible inputs:
</p>

<ol>
<li><p>A vector of counts, containing the genotypes for each
individual at the second locus. When <code>type = "comp"</code>,
the vector of genotypes may be continuous (e.g. the
posterior mean genotype).
</p>
</li>
<li><p>A matrix of genotype log-likelihoods at the second locus.
The rows index the individuals and the columns index
the genotypes. That is <code>gb[i, j]</code> is the genotype
likelihood of individual <code>i</code> for genotype <code>j-1</code>.
</p>
</li></ol>
</td></tr>
<tr><td><code id="ldest_+3A_k">K</code></td>
<td>
<p>The ploidy of the species. Assumed to be the same for all
individuals.</p>
</td></tr>
<tr><td><code id="ldest_+3A_se">se</code></td>
<td>
<p>A logical. Should we calculate standard errors (<code>TRUE</code>) or
not (<code>FALSE</code>). Calculating standard errors can be really slow
when <code>type = "comp"</code>, <code>model = "flex"</code>, and when using
genotype likelihoods. Otherwise, standard error calculations
should be pretty fast.</p>
</td></tr>
<tr><td><code id="ldest_+3A_type">type</code></td>
<td>
<p>The type of LD to calculate. The available types are
haplotypic LD (<code>type = "hap"</code>) or composite LD
(<code>type = "comp"</code>). Haplotypic LD is only appropriate for
autopolyploids when the individuals are in Hardy-Weinberg
equilibrium (HWE). The composite
measures of LD are always applicable, and consistently estimate the
usual measures of LD when HWE is fulfilled in autopolyploids.
However, when HWE is not fulfilled, interpreting the
composite measures of LD could be a little tricky.</p>
</td></tr>
<tr><td><code id="ldest_+3A_model">model</code></td>
<td>
<p>When <code>type = "comp"</code> and using genotype likelihoods,
should we use the proportional
bivariate normal model to estimate the genotype distribution
(<code>model = "norm"</code>), or the general categorical distribution
(<code>model = "flex"</code>)? Defaults to <code>"norm"</code>.</p>
</td></tr>
<tr><td><code id="ldest_+3A_pen">pen</code></td>
<td>
<p>The penalty to be applied to the likelihood. You can think about
this as the prior sample size. Should be greater than 1. Does not
apply if <code>model = "norm"</code>, <code>type = "comp"</code>, and using
genotype likelihoods. Also does not apply when <code>type = "comp"</code>
and using genotypes.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with some or all of the following elements:
</p>

<dl>
<dt><code>D</code></dt><dd><p>The estimate of the LD coefficient.</p>
</dd>
<dt><code>D_se</code></dt><dd><p>The standard error of the estimate of
the LD coefficient.</p>
</dd>
<dt><code>r2</code></dt><dd><p>The estimate of the squared Pearson correlation.</p>
</dd>
<dt><code>r2_se</code></dt><dd><p>The standard error of the estimate of the
squared Pearson correlation.</p>
</dd>
<dt><code>r</code></dt><dd><p>The estimate of the Pearson correlation.</p>
</dd>
<dt><code>r_se</code></dt><dd><p>The standard error of the estimate of the
Pearson correlation.</p>
</dd>
<dt><code>Dprime</code></dt><dd><p>The estimate of the standardized LD
coefficient. When <code>type</code> = &quot;comp&quot;, this corresponds
to the standardization where we fix allele frequencies.</p>
</dd>
<dt><code>Dprime_se</code></dt><dd><p>The standard error of <code>Dprime</code>.</p>
</dd>
<dt><code>Dprimeg</code></dt><dd><p>The estimate of the standardized LD
coefficient. This corresponds to the standardization where
we fix genotype frequencies.</p>
</dd>
<dt><code>Dprimeg_se</code></dt><dd><p>The standard error of <code>Dprimeg</code>.</p>
</dd>
<dt><code>z</code></dt><dd><p>The Fisher-z transformation of <code>r</code>.</p>
</dd>
<dt><code>z_se</code></dt><dd><p>The standard error of the Fisher-z
transformation of <code>r</code>.</p>
</dd>
<dt><code>p_ab</code></dt><dd><p>The estimated haplotype frequency of ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_Ab</code></dt><dd><p>The estimated haplotype frequency of Ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_aB</code></dt><dd><p>The estimated haplotype frequency of aB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_AB</code></dt><dd><p>The estimated haplotype frequency of AB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>q_ij</code></dt><dd><p>The estimated frequency of genotype i at locus 1
and genotype j at locus 2. Only returned if estimating the
composite LD.</p>
</dd>
<dt><code>n</code></dt><dd><p>The number of individuals used to estimate pairwise LD.</p>
</dd>
</dl>



<h3>Haplotypic LD</h3>

<p>This section describes the methods used when <code>type = "hap"</code> is
selected.
</p>
<p>Haplotypic LD measures the association
between two loci on the same haplotype. When haplotypes are known, estimating
haplotypic LD is simple using just the haplotypic frequencies.
</p>
<p>When haplotypes are not known, we can still estimate haplotypic frequencies
using the genotypes or genotype likelihoods
<em>in autopolyploids as long as Hardy-Weinberg equilibrium (HWE) is satisfied</em>. We do
this via maximum likelihood using gradient ascent. Gradient ascent is
performed over the unconstrained parameterization of the 3-simplex from
Betancourt (2012). The estimated haplotype frequencies are then used to
estimate haplotypic LD.
</p>
<p>Standard errors are provided using standard maximum likelihood theory.
In brief, the Hessian matrix of the log-likelihood is calculated at
the MLE's of the haplotype frequencies. The negative inverse of this
Hessian matrix is approximately the covariance matrix of the MLE's of the
haplotype frequencies. Since all haplotypic LD measures are functions
of the haplotype frequencies, we use the delta-method to obtain
the standard errors for each LD estimate.
</p>
<p>A Dirichlet(2,2,2,2) prior is placed over the frequencies of
haplotypes 00, 01, 10, and 11. This corresponds to the &quot;add two&quot; rule
of Agresti (1998). You can change this prior via the <code>pen</code> argument.
</p>
<p>When you either do not have autopolyploids or when HWE is <em>not</em>
satisfied, then the estimates using <code>type = "hap"</code>
are nonsensical. However, the composite measures of LD are still
applicable (see below).
</p>


<h3>Composite LD</h3>

<p>This section describes the methods used when <code>type = "comp"</code> is
selected.
</p>
<p>When HWE is not satisfied, haplotype frequencies are not estimable. However,
measures of association between two loci are still estimable. These
associations may be caused by LD either on the same haplotype or between
different haplotypes. Cockerham and Weir (1977) thus called such measures
&quot;composite&quot; measures of LD.
</p>
<p>When the genotypes are known, these composite measures have simple
correspondences to well-known statistical measures of association.
D is the covariance of genotypes between loci divided by the ploidy.
r is the Pearson correlation of genotypes. D' is D divided by a
term that involves only mean genotypes.
</p>
<p>When genotypes are not known, we estimate the joint genotype frequencies
and use these to estimate the composite measures of LD using
genotype likelihoods. The distribution of genotypes is assumed to
either follow a proportional bivariate normal model (by default) or
a general categorical model.
</p>
<p>These estimates of composite measures of LD estimate the haplotypic
measures of LD when HWE is fulfilled, but are still applicable when HWE
is not fulfilled.
</p>
<p>When genotypes are known, standard errors are calculated using standard
moment-based approaches. When genotypes are not known, standard
errors are calculated using standard maximum likelihood theory,
same as for the haplotypic LD estimates (see above), or using
a bootstrap.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>References</h3>


<ul>
<li><p>Agresti, Alan, and Brent A. Coull. &quot;Approximate is better than
&quot;exact&quot; for interval estimation of binomial proportions.&quot;
<em>The American Statistician</em> 52, no. 2 (1998): 119-126.
<a href="https://doi.org/10.1080/00031305.1998.10480550">doi:10.1080/00031305.1998.10480550</a>
</p>
</li>
<li><p>Betancourt, Michael. &quot;Cruising the simplex: Hamiltonian Monte
Carlo and the Dirichlet distribution.&quot; In
<em>AIP Conference Proceedings 31st</em>, vol. 1443, no. 1,
pp. 157-164. American Institute of Physics, 2012.
<a href="https://doi.org/10.1063/1.3703631">doi:10.1063/1.3703631</a>
</p>
</li>
<li><p>Cockerham, C. Clark, and B. S. Weir. &quot;Digenic descent measures
for finite populations.&quot; <em>Genetics Research</em> 30, no. 2 (1977):
121-147. <a href="https://doi.org/10.1017/S0016672300017547">doi:10.1017/S0016672300017547</a>
</p>
</li>
<li><p>Gerard, David. &quot;Pairwise Linkage Disequilibrium Estimation
for Polyploids.&quot; <em>Molecular Ecology Resources</em> 21,
no. 4 (2021): 1230-1242. <a href="https://doi.org/10.1111/1755-0998.13349">doi:10.1111/1755-0998.13349</a>
</p>
</li></ul>



<h3>See Also</h3>


<dl>
<dt><code><a href="#topic+ldfast">ldfast</a>()</code></dt><dd><p>Fast, moment-based approach to LD estimation
that also accounts for genotype uncertainty.</p>
</dd>
<dt><code><a href="#topic+mldest">mldest</a>()</code></dt><dd><p>For calculating pairwise LD among all
pairs of a collection of SNPs.</p>
</dd>
<dt><code><a href="#topic+sldest">sldest</a>()</code></dt><dd><p>For calculating pairwise LD along a
sliding window of SNPs.</p>
</dd>
<dt><code><a href="#topic+ldest_hap">ldest_hap</a>()</code></dt><dd><p>For the function that directly estimates
haplotypic LD when HWE is fulfilled.</p>
</dd>
<dt><code><a href="#topic+ldest_comp">ldest_comp</a>()</code></dt><dd><p>For the function that directly
estimates composite LD.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 100 # sample size
K &lt;- 6 # ploidy

## generate some fake genotypes when LD = 0.
ga &lt;- stats::rbinom(n = n, size = K, prob = 0.5)
gb &lt;- stats::rbinom(n = n, size = K, prob = 0.5)
head(ga)
head(gb)

## generate some fake genotype likelihoods when LD = 0.
gamat &lt;- t(sapply(ga, stats::dnorm, x = 0:K, sd = 1, log = TRUE))
gbmat &lt;- t(sapply(gb, stats::dnorm, x = 0:K, sd = 1, log = TRUE))
head(gamat)
head(gbmat)

## Haplotypic LD with genotypes
ldout1 &lt;- ldest(ga = ga,
                gb = gb,
                K = K,
                type = "hap")
head(ldout1)

## Haplotypic LD with genotype likelihoods
ldout2 &lt;- ldest(ga = gamat,
                gb = gbmat,
                K = K,
                type = "hap")
head(ldout2)

## Composite LD with genotypes
ldout3 &lt;- ldest(ga = ga,
                gb = gb,
                K = K,
                type = "comp")
head(ldout3)

## Composite LD with genotype likelihoods and normal model
ldout4 &lt;- ldest(ga = gamat,
                gb = gbmat,
                K = K,
                type = "comp",
                model = "norm")
head(ldout4)

## Composite LD with genotype likelihoods and general categorical model
ldout5 &lt;- ldest(ga = gamat,
                gb = gbmat,
                K = K,
                type = "comp",
                model = "flex",
                se = FALSE)
head(ldout5)

ldout1[["D"]]
ldout2[["D"]]
ldout3[["D"]]
ldout4[["D"]]
ldout5[["D"]]

</code></pre>

<hr>
<h2 id='ldest_comp'>Estimates of composite pairwise LD based either on genotype estimates or
genotype likelihoods.</h2><span id='topic+ldest_comp'></span>

<h3>Description</h3>

<p>This function will estimate the composite LD between two loci, either
using genotype estimates or using genotype likelihoods. The resulting
measures of LD are generalizations of Burrow's &quot;composite&quot; LD measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldest_comp(
  ga,
  gb,
  K,
  pen = 1,
  useboot = TRUE,
  nboot = 50,
  se = TRUE,
  model = c("norm", "flex")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldest_comp_+3A_ga">ga</code></td>
<td>
<p>One of two possible inputs:
</p>

<ol>
<li><p>A vector of counts, containing the genotypes for each
individual at the first locus. When <code>type = "comp"</code>,
the vector of genotypes may be continuous (e.g. the
posterior mean genotype).
</p>
</li>
<li><p>A matrix of genotype log-likelihoods at the first locus.
The rows index the individuals and the columns index
the genotypes. That is <code>ga[i, j]</code> is the genotype
likelihood of individual <code>i</code> for genotype <code>j-1</code>.
</p>
</li></ol>
</td></tr>
<tr><td><code id="ldest_comp_+3A_gb">gb</code></td>
<td>
<p>One of two possible inputs:
</p>

<ol>
<li><p>A vector of counts, containing the genotypes for each
individual at the second locus. When <code>type = "comp"</code>,
the vector of genotypes may be continuous (e.g. the
posterior mean genotype).
</p>
</li>
<li><p>A matrix of genotype log-likelihoods at the second locus.
The rows index the individuals and the columns index
the genotypes. That is <code>gb[i, j]</code> is the genotype
likelihood of individual <code>i</code> for genotype <code>j-1</code>.
</p>
</li></ol>
</td></tr>
<tr><td><code id="ldest_comp_+3A_k">K</code></td>
<td>
<p>The ploidy of the species. Assumed to be the same for all
individuals.</p>
</td></tr>
<tr><td><code id="ldest_comp_+3A_pen">pen</code></td>
<td>
<p>The penalty to be applied to the likelihood. You can think about
this as the prior sample size. Should be greater than 1. Does not
apply if <code>model = "norm"</code>, <code>type = "comp"</code>, and using
genotype likelihoods. Also does not apply when <code>type = "comp"</code>
and using genotypes.</p>
</td></tr>
<tr><td><code id="ldest_comp_+3A_useboot">useboot</code></td>
<td>
<p>Should we use bootstrap standard errors <code>TRUE</code> or not
<code>FALSE</code>? Only applicable if using genotype likelihoods and
<code>model = "flex"</code></p>
</td></tr>
<tr><td><code id="ldest_comp_+3A_nboot">nboot</code></td>
<td>
<p>The number of bootstrap iterations to use is
<code>boot = TRUE</code>. Only applicable if using genotype likelihoods and
<code>model = "flex"</code>.</p>
</td></tr>
<tr><td><code id="ldest_comp_+3A_se">se</code></td>
<td>
<p>A logical. Should we calculate standard errors (<code>TRUE</code>) or
not (<code>FALSE</code>). Calculating standard errors can be really slow
when <code>type = "comp"</code>, <code>model = "flex"</code>, and when using
genotype likelihoods. Otherwise, standard error calculations
should be pretty fast.</p>
</td></tr>
<tr><td><code id="ldest_comp_+3A_model">model</code></td>
<td>
<p>Should we assume the class of joint genotype distributions
is from the proportional bivariate normal (<code>model = "norm"</code>)
or from the general categorical distribution (<code>model = "flex"</code>).
Only applicable if using genotype likelihoods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector with some or all of the following elements:
</p>

<dl>
<dt><code>D</code></dt><dd><p>The estimate of the LD coefficient.</p>
</dd>
<dt><code>D_se</code></dt><dd><p>The standard error of the estimate of
the LD coefficient.</p>
</dd>
<dt><code>r2</code></dt><dd><p>The estimate of the squared Pearson correlation.</p>
</dd>
<dt><code>r2_se</code></dt><dd><p>The standard error of the estimate of the
squared Pearson correlation.</p>
</dd>
<dt><code>r</code></dt><dd><p>The estimate of the Pearson correlation.</p>
</dd>
<dt><code>r_se</code></dt><dd><p>The standard error of the estimate of the
Pearson correlation.</p>
</dd>
<dt><code>Dprime</code></dt><dd><p>The estimate of the standardized LD
coefficient. When <code>type</code> = &quot;comp&quot;, this corresponds
to the standardization where we fix allele frequencies.</p>
</dd>
<dt><code>Dprime_se</code></dt><dd><p>The standard error of <code>Dprime</code>.</p>
</dd>
<dt><code>Dprimeg</code></dt><dd><p>The estimate of the standardized LD
coefficient. This corresponds to the standardization where
we fix genotype frequencies.</p>
</dd>
<dt><code>Dprimeg_se</code></dt><dd><p>The standard error of <code>Dprimeg</code>.</p>
</dd>
<dt><code>z</code></dt><dd><p>The Fisher-z transformation of <code>r</code>.</p>
</dd>
<dt><code>z_se</code></dt><dd><p>The standard error of the Fisher-z
transformation of <code>r</code>.</p>
</dd>
<dt><code>p_ab</code></dt><dd><p>The estimated haplotype frequency of ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_Ab</code></dt><dd><p>The estimated haplotype frequency of Ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_aB</code></dt><dd><p>The estimated haplotype frequency of aB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_AB</code></dt><dd><p>The estimated haplotype frequency of AB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>q_ij</code></dt><dd><p>The estimated frequency of genotype i at locus 1
and genotype j at locus 2. Only returned if estimating the
composite LD.</p>
</dd>
<dt><code>n</code></dt><dd><p>The number of individuals used to estimate pairwise LD.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 100 # sample size
K &lt;- 6 # ploidy

## generate some fake genotypes when LD = 0.
ga &lt;- stats::rbinom(n = n, size = K, prob = 0.5)
gb &lt;- stats::rbinom(n = n, size = K, prob = 0.5)
head(ga)
head(gb)

## generate some fake genotype likelihoods when LD = 0.
gamat &lt;- t(sapply(ga, stats::dnorm, x = 0:K, sd = 1, log = TRUE))
gbmat &lt;- t(sapply(gb, stats::dnorm, x = 0:K, sd = 1, log = TRUE))
head(gamat)
head(gbmat)

## Composite LD with genotypes
ldout1 &lt;- ldest_comp(ga = ga,
                     gb = gb,
                     K = K)
head(ldout1)

## Composite LD with genotype likelihoods
ldout2 &lt;- ldest_comp(ga = gamat,
                     gb = gbmat,
                     K = K,
                     se = FALSE,
                     model = "flex")
head(ldout2)

## Composite LD with genotype likelihoods and proportional bivariate normal
ldout3 &lt;- ldest_comp(ga = gamat,
                     gb = gbmat,
                     K = K,
                     model = "norm")
head(ldout3)

</code></pre>

<hr>
<h2 id='ldest_hap'>Estimate haplotypic pair-wise LD using either genotypes or genotype
likelihoods.</h2><span id='topic+ldest_hap'></span>

<h3>Description</h3>

<p>Given genotype (allele dosage) or genotype likelihood data
for each individual at a pair of loci, this function will
calculate the maximum likelihood estimates
and their corresponding asymptotic standard errors of some
measures of linkage disequilibrium (LD): D, D', the Pearson correlation,
the squared Pearson correlation, and the Fisher-z transformation of the
Pearson correlation. This function can be used for both
diploids and polyploids.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldest_hap(
  ga,
  gb,
  K,
  reltol = 10^-8,
  nboot = 100,
  useboot = FALSE,
  pen = 2,
  grid_init = FALSE,
  se = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldest_hap_+3A_ga">ga</code></td>
<td>
<p>One of two possible inputs:
</p>

<ol>
<li><p>A vector of counts, containing the genotypes for each
individual at the first locus. When <code>type = "comp"</code>,
the vector of genotypes may be continuous (e.g. the
posterior mean genotype).
</p>
</li>
<li><p>A matrix of genotype log-likelihoods at the first locus.
The rows index the individuals and the columns index
the genotypes. That is <code>ga[i, j]</code> is the genotype
likelihood of individual <code>i</code> for genotype <code>j-1</code>.
</p>
</li></ol>
</td></tr>
<tr><td><code id="ldest_hap_+3A_gb">gb</code></td>
<td>
<p>One of two possible inputs:
</p>

<ol>
<li><p>A vector of counts, containing the genotypes for each
individual at the second locus. When <code>type = "comp"</code>,
the vector of genotypes may be continuous (e.g. the
posterior mean genotype).
</p>
</li>
<li><p>A matrix of genotype log-likelihoods at the second locus.
The rows index the individuals and the columns index
the genotypes. That is <code>gb[i, j]</code> is the genotype
likelihood of individual <code>i</code> for genotype <code>j-1</code>.
</p>
</li></ol>
</td></tr>
<tr><td><code id="ldest_hap_+3A_k">K</code></td>
<td>
<p>The ploidy of the species. Assumed to be the same for all
individuals.</p>
</td></tr>
<tr><td><code id="ldest_hap_+3A_reltol">reltol</code></td>
<td>
<p>The relative tolerance for the stopping criterion.</p>
</td></tr>
<tr><td><code id="ldest_hap_+3A_nboot">nboot</code></td>
<td>
<p>Sometimes, the MLE standard errors don't exist. So we use
the bootstrap as a backup. <code>nboot</code> specifies the number
of bootstrap iterations.</p>
</td></tr>
<tr><td><code id="ldest_hap_+3A_useboot">useboot</code></td>
<td>
<p>A logical. Optionally, you may always use the bootstrap
to estimate the standard errors (<code>TRUE</code>). These will be more
accurate but also much slower, so this defaults to <code>FALSE</code>. Only
applicable if using genotype likelihoods.</p>
</td></tr>
<tr><td><code id="ldest_hap_+3A_pen">pen</code></td>
<td>
<p>The penalty to be applied to the likelihood. You can think about
this as the prior sample size. Should be greater than 1. Does not
apply if <code>model = "norm"</code>, <code>type = "comp"</code>, and using
genotype likelihoods. Also does not apply when <code>type = "comp"</code>
and using genotypes.</p>
</td></tr>
<tr><td><code id="ldest_hap_+3A_grid_init">grid_init</code></td>
<td>
<p>A logical. Should we initialize the gradient ascent
at a grid of initial values (<code>TRUE</code>) or just initialize
at one value corresponding to the simplex point
<code>rep(0.25, 4)</code> (<code>FALSE</code>)?</p>
</td></tr>
<tr><td><code id="ldest_hap_+3A_se">se</code></td>
<td>
<p>A logical. Should we calculate standard errors (<code>TRUE</code>) or
not (<code>FALSE</code>). Calculating standard errors can be really slow
when <code>type = "comp"</code>, <code>model = "flex"</code>, and when using
genotype likelihoods. Otherwise, standard error calculations
should be pretty fast.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let A and a be the reference and alternative alleles, respectively, at
locus 1. Let B and b be the reference and alternative alleles,
respectively, at locus 2. Let paa, pAb, paB, and pAB be the
frequencies of haplotypes ab, Ab, aB, and AB, respectively.
Let pA = pAb + pAB and let pB = paB + pAB
The <code>ldest</code> returns estimates of the following measures
of LD.
</p>

<ul>
<li><p>D: pAB - pA pB
</p>
</li>
<li><p>D': D / Dmax, where Dmax = min(pA pB, (1 - pA) (1 - pB)) if
D &lt; 0 and Dmax = min(pA (1 - pB), pA (1 - pB)) if D &gt; 0
</p>
</li>
<li><p>r-squared: The squared Pearson correlation,
r^2 = D^2 / (pA (1 - pA) pB (1 - pB))
</p>
</li>
<li><p>r: The Pearson correlation,
r = D / sqrt(pA (1 - pA) pB (1 - pB))
</p>
</li></ul>

<p>Estimates are obtained via maximum likelihood under the assumption
of Hardy-Weinberg equilibrium. The likelihood is calculated by
integrating over the possible haplotypes for each pair of genotypes.
</p>
<p>The resulting standard errors are based on the square roots of the inverse of the
negative Fisher-information. This is from standard maximum likelihood
theory. The Fisher-information is known to be biased low, so the actual
standard errors are probably a little bigger for small n (n &lt; 20).
In some cases the Fisher-information matrix is singular, and so we
in these cases we return a bootstrap estimate of the standard error.
</p>
<p>The standard error estimate of the squared Pearson correlation is not
valid when r^2 = 0.
</p>
<p>In cases where either SNP is estimated to be monoallelic
(<code>pA %in% c(0, 1)</code> or <code>pB %in% c(0, 1)</code>), this function
will return LD estimates of <code>NA</code>.
</p>


<h3>Value</h3>

<p>A vector with some or all of the following elements:
</p>

<dl>
<dt><code>D</code></dt><dd><p>The estimate of the LD coefficient.</p>
</dd>
<dt><code>D_se</code></dt><dd><p>The standard error of the estimate of
the LD coefficient.</p>
</dd>
<dt><code>r2</code></dt><dd><p>The estimate of the squared Pearson correlation.</p>
</dd>
<dt><code>r2_se</code></dt><dd><p>The standard error of the estimate of the
squared Pearson correlation.</p>
</dd>
<dt><code>r</code></dt><dd><p>The estimate of the Pearson correlation.</p>
</dd>
<dt><code>r_se</code></dt><dd><p>The standard error of the estimate of the
Pearson correlation.</p>
</dd>
<dt><code>Dprime</code></dt><dd><p>The estimate of the standardized LD
coefficient. When <code>type</code> = &quot;comp&quot;, this corresponds
to the standardization where we fix allele frequencies.</p>
</dd>
<dt><code>Dprime_se</code></dt><dd><p>The standard error of <code>Dprime</code>.</p>
</dd>
<dt><code>Dprimeg</code></dt><dd><p>The estimate of the standardized LD
coefficient. This corresponds to the standardization where
we fix genotype frequencies.</p>
</dd>
<dt><code>Dprimeg_se</code></dt><dd><p>The standard error of <code>Dprimeg</code>.</p>
</dd>
<dt><code>z</code></dt><dd><p>The Fisher-z transformation of <code>r</code>.</p>
</dd>
<dt><code>z_se</code></dt><dd><p>The standard error of the Fisher-z
transformation of <code>r</code>.</p>
</dd>
<dt><code>p_ab</code></dt><dd><p>The estimated haplotype frequency of ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_Ab</code></dt><dd><p>The estimated haplotype frequency of Ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_aB</code></dt><dd><p>The estimated haplotype frequency of aB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_AB</code></dt><dd><p>The estimated haplotype frequency of AB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>q_ij</code></dt><dd><p>The estimated frequency of genotype i at locus 1
and genotype j at locus 2. Only returned if estimating the
composite LD.</p>
</dd>
<dt><code>n</code></dt><dd><p>The number of individuals used to estimate pairwise LD.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 100 # sample size
K &lt;- 6 # ploidy

## generate some fake genotypes when LD = 0.
ga &lt;- stats::rbinom(n = n, size = K, prob = 0.5)
gb &lt;- stats::rbinom(n = n, size = K, prob = 0.5)
head(ga)
head(gb)

## generate some fake genotype likelihoods when LD = 0.
gamat &lt;- t(sapply(ga, stats::dnorm, x = 0:K, sd = 1, log = TRUE))
gbmat &lt;- t(sapply(gb, stats::dnorm, x = 0:K, sd = 1, log = TRUE))
head(gamat)
head(gbmat)

## Haplotypic LD with genotypes
ldout1 &lt;- ldest_hap(ga = ga,
                    gb = gb,
                    K = K)
head(ldout1)

## Haplotypic LD with genotype likelihoods
ldout2 &lt;- ldest_hap(ga = gamat,
                    gb = gbmat,
                    K = K)
head(ldout2)

</code></pre>

<hr>
<h2 id='ldfast'>Fast bias-correction for LD Estimation</h2><span id='topic+ldfast'></span>

<h3>Description</h3>

<p>Estimates the reliability ratios from posterior marginal moments and uses
these to correct the biases in linkage disequilibrium estimation
caused by genotype uncertainty. These methods are described in
Gerard (2021).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldfast(
  gp,
  type = c("r", "r2", "z", "D", "Dprime"),
  shrinkrr = TRUE,
  se = TRUE,
  thresh = TRUE,
  upper = 10,
  mode = c("zero", "estimate"),
  win = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldfast_+3A_gp">gp</code></td>
<td>
<p>A three-way array with dimensions SNPs by individuals by dosage.
That is, <code>gp[i, j, k]</code> is the posterior probability of
dosage <code>k-1</code> for individual <code>j</code> at SNP <code>i</code>.</p>
</td></tr>
<tr><td><code id="ldfast_+3A_type">type</code></td>
<td>
<p>What LD measure should we estimate?
</p>

<dl>
<dt><code>"r"</code></dt><dd><p>The Pearson correlation.</p>
</dd>
<dt><code>"r2"</code></dt><dd><p>The squared Pearson correlation.</p>
</dd>
<dt><code>"z"</code></dt><dd><p>The Fisher-z transformed Pearson correlation.</p>
</dd>
<dt><code>"D"</code></dt><dd><p>The LD coefficient.</p>
</dd>
<dt><code>"Dprime"</code></dt><dd><p>The standardized LD coefficient.</p>
</dd>
</dl>

<p>Note that these are all <em>composite</em> measures of LD (see
the description in <code><a href="#topic+ldest">ldest</a>()</code>).</p>
</td></tr>
<tr><td><code id="ldfast_+3A_shrinkrr">shrinkrr</code></td>
<td>
<p>A logical. Should we use adaptive shrinkage
(Stephens, 2016) to shrink the reliability ratios (<code>TRUE</code>)
or keep the raw reliability ratios (<code>FALSE</code>). Defaults
to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ldfast_+3A_se">se</code></td>
<td>
<p>Should we also return a matrix of standard errors (<code>TRUE</code>)
or not (<code>FALSE</code>)? It is faster to not return standard errors.
Defaults to <code>TRUE</code>.</p>
</td></tr>
<tr><td><code id="ldfast_+3A_thresh">thresh</code></td>
<td>
<p>A logical. Should we apply an upper bound on the reliability
ratios (<code>TRUE</code>) or not (<code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="ldfast_+3A_upper">upper</code></td>
<td>
<p>The upper bound on the reliability ratios if
<code>thresh = TRUE</code>. The default is a generous 10.</p>
</td></tr>
<tr><td><code id="ldfast_+3A_mode">mode</code></td>
<td>
<p>A character. Only applies if <code>shrinkrr = TRUE</code>. When using
hierarchical shrinkage on the log of the reliability ratios, should
we use zero as the mode (<code>mode = "zero"</code>) or estimate it using
the procedure of Robertson and Cryer (1974)
(<code>mode = "estimate"</code>)?</p>
</td></tr>
<tr><td><code id="ldfast_+3A_win">win</code></td>
<td>
<p>A positive integer. The window size. This will constrain the
correlations calculated to those +/- the window size. This will
only improve speed if the window size is <em>much</em> less than the
number of SNPs.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with some or all of the following elements:
</p>

<dl>
<dt><code>ldmat</code></dt><dd><p>The bias-corrected LD matrix.</p>
</dd>
<dt><code>rr</code></dt><dd><p>The estimated reliability ratio for each SNP. This
is the multiplicative factor applied to the naive LD estimate
for each SNP.</p>
</dd>
<dt><code>rr_raw</code></dt><dd><p>The raw reliability ratios (for the covariance,
not the correlation). Only returned if <code>shrinkrr = TRUE</code>.</p>
</dd>
<dt><code>rr_se</code></dt><dd><p>The standard errors for the <em>log</em>-raw
reliability ratios for each SNP. That is, we have
sd(log(rr_raw)) ~ rr_se. Only returned if <code>shrinkrr = TRUE</code>.</p>
</dd>
<dt><code>semat</code></dt><dd><p>A matrix of standard errors of the corresponding
estimators of LD.</p>
</dd>
</dl>



<h3>Details</h3>

<p>Returns consistent and bias-corrected estimates of linkage disequilibrium.
The usual measures of LD are implemented: D, D', r, r2, and z
(Fisher-z of r). These are all <em>composite</em> measures of LD, not
haplotypic measures of LD (see the description in <code><a href="#topic+ldest">ldest</a>()</code>).
They are always appropriate measures of association
between loci, but only correspond to haplotypic measures of LD when
Hardy-Weinberg equilibrium is fulfilled in autopolyploids.
</p>
<p>In order for these estimates to perform well, you need to use
posterior genotype probabilities that have been calculated using
adaptive priors, i.e. empirical/hierarchical Bayes approaches. There
are many approaches that do this, such as
<a href="https://cran.r-project.org/package=updog"><code>updog</code></a>,
<a href="https://cran.r-project.org/package=polyRAD"><code>polyRAD</code></a>,
<a href="https://cran.r-project.org/package=fitPoly"><code>fitPoly</code></a>, or
<a href="https://github.com/guilherme-pereira/vcf2sm"><code>SuperMASSA</code></a>.
Note that GATK uses a uniform prior, so would be inappropriate for
use in <code>ldfast()</code>.
</p>
<p>Calculating standard errors and performing hierarchical shrinkage of the
reliability ratios are both rather slow operations compared to just
raw method-of-moments based estimation for LD. If you don't need
standard errors, you can double your speed by setting
<code>se = FALSE</code>. It is not recommended that you disable the
hierarchical shrinkage.
</p>
<p>Due to sampling variability, the estimates sometime lie outside of the
theoretical boundaries of the parameters being estimated. In such cases,
we truncate the estimates at the boundary and return <code>NA</code> for the
standard errors.
</p>


<h3>Mathematical formulation</h3>

<p>Let
</p>

<ul>
<li><p><code class="reqn">r</code> be the sample correlation of posterior mean genotypes
between loci 1 and 2,
</p>
</li>
<li><p><code class="reqn">a1</code> be the sample variance of posterior means at locus 1,
</p>
</li>
<li><p><code class="reqn">a2</code> be the sample variance of posterior means at locus 2,
</p>
</li>
<li><p><code class="reqn">b1</code> be the sample mean of posterior variances at locus 1, and
</p>
</li>
<li><p><code class="reqn">b2</code> be the sample mean of posterior variances at locus 2.
</p>
</li></ul>

<p>Then the estimated Pearson correlation between the genotypes at
loci 1 and 2 is
</p>
<p style="text-align: center;"><code class="reqn">\sqrt{(a1 + b1)/a1}\sqrt{(a2 + b2)/a2}r.</code>
</p>

<p>All other LD calculations are based on this equation. In particular,
the estimated genotype variances at loci 1 and 2 are
<code class="reqn">a1 + b1</code> and <code class="reqn">a2 + b2</code>, respectively, which can be
used to calculate D and D'.
</p>
<p>The reliability ratio for SNP i is defined by <code class="reqn">(ai + bi)/ai</code>.
By default, we apply <code><a href="ashr.html#topic+ash">ash</a>()</code> (Stephens, 2016)
to the log of these reliability ratios before adjusting the
Pearson correlation. Standard errors are required before using
<code><a href="ashr.html#topic+ash">ash</a>()</code>, but these are easily obtained
using the central limit theorem and the delta-method.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>References</h3>


<ul>
<li><p>Gerard, David. Scalable Bias-corrected Linkage Disequilibrium Estimation Under Genotype Uncertainty. <em>Heredity</em>, 127(4), 357&ndash;362, 2021. <a href="https://doi.org/10.1038/s41437-021-00462-5">doi:10.1038/s41437-021-00462-5</a>.
</p>
</li>
<li><p>T. Robertson and J. D. Cryer. An iterative procedure for estimating the mode. <em>Journal of the American Statistical Association</em>, 69(348):10121016, 1974. <a href="https://doi.org/10.1080/01621459.1974.10480246">doi:10.1080/01621459.1974.10480246</a>.
</p>
</li>
<li><p>M. Stephens. False discovery rates: a new deal. <em>Biostatistics</em>, 18(2):275294, 10 2016. <a href="https://doi.org/10.1093/biostatistics/kxw041">doi:10.1093/biostatistics/kxw041</a>.
</p>
</li></ul>



<h3>See Also</h3>


<dl>
<dt><code><a href="ashr.html#topic+ash">ash</a>()</code></dt><dd><p>Function used to perform hierarchical
shrinkage on the log of the reliability ratios.</p>
</dd>
<dt><code><a href="#topic+ldest">ldest</a>()</code>, <code><a href="#topic+mldest">mldest</a>()</code>, <code><a href="#topic+sldest">sldest</a>()</code></dt><dd><p>Maximum likelihood estimation of linkage disequilibrium.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data("gp")

ldout &lt;- ldfast(gp, "r")
ldout$ldmat
ldout$rr
ldout$semat

ldout &lt;- ldfast(gp, "D")
ldout$ldmat
ldout$rr
ldout$semat

ldout &lt;- ldfast(gp, "Dprime")
ldout$ldmat
ldout$rr
ldout$semat

</code></pre>

<hr>
<h2 id='ldsep-package'>Linkage Disequilibrium Shrinkage Estimation for Polyploids</h2><span id='topic+ldsep-package'></span><span id='topic+ldsep'></span>

<h3>Description</h3>

<p>Estimate haplotypic or composite pairwise linkage disequilibrium
(LD) in polyploids, using either genotypes or genotype likelihoods. Support is
provided to estimate the popular measures of LD: the LD coefficient D,
the standardized LD coefficient D', and the Pearson correlation
coefficient r. All estimates are returned with corresponding
standard errors. These estimates and standard errors can then be used
for shrinkage estimation.
</p>


<h3>Functions</h3>

<p>The main functions are:
</p>

<dl>
<dt><code><a href="#topic+ldfast">ldfast</a>()</code></dt><dd><p>Fast, moment-based, bias-corrected LD
LD estimates from marginal posterior distributions.</p>
</dd>
<dt><code><a href="#topic+ldest">ldest</a>()</code></dt><dd><p>Estimates pairwise LD.</p>
</dd>
<dt><code><a href="#topic+mldest">mldest</a>()</code></dt><dd><p>Iteratively apply <code><a href="#topic+ldest">ldest</a>()</code>
across many pairs of SNPs.</p>
</dd>
<dt><code><a href="#topic+sldest">sldest</a>()</code></dt><dd><p>Iteratively apply <code><a href="#topic+ldest">ldest</a>()</code>
along a sliding window of fixed length.</p>
</dd>
<dt><code><a href="#topic+plot.lddf">plot.lddf</a>()</code></dt><dd><p>Plot method for the output of
<code><a href="#topic+mldest">mldest</a>()</code> and <code><a href="#topic+sldest">sldest</a>()</code>.</p>
</dd>
<dt><code><a href="#topic+format_lddf">format_lddf</a>()</code></dt><dd><p>Format the output of
<code><a href="#topic+mldest">mldest</a>()</code> and <code><a href="#topic+sldest">sldest</a>()</code> into a matrix.</p>
</dd>
<dt><code><a href="#topic+ldshrink">ldshrink</a>()</code></dt><dd><p>Shrink correlation estimates
using adaptive shrinkage (Stephens, 2017; Dey and Stephens, 2018).</p>
</dd>
</dl>



<h3>Citation</h3>

<p>If you find the methods in this package useful, please run the following
in R for citation information: <code>citation("ldsep")</code>
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>

<hr>
<h2 id='ldshrink'>Obtain shrinkage estimates of correlation from output of
<code><a href="#topic+mldest">mldest</a>()</code> or <code><a href="#topic+sldest">sldest</a>()</code>.</h2><span id='topic+ldshrink'></span>

<h3>Description</h3>

<p>This will take the output of either <code><a href="#topic+mldest">mldest</a>()</code> or
<code><a href="#topic+sldest">sldest</a>()</code>, shrink the Fisher-z transformed
correlation estimates using <code><a href="ashr.html#topic+ash">ash</a>()</code>
(Stephens, 2017; Dey and Stephens, 2018), then return
the corresponding correlation estimates. You can obtain estimates of
r^2 by just squaring these estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ldshrink(obj, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ldshrink_+3A_obj">obj</code></td>
<td>
<p>An object of class <code>lddf</code>, usually created using
either <code><a href="#topic+mldest">mldest</a>()</code> or <code><a href="#topic+sldest">sldest</a>()</code>.</p>
</td></tr>
<tr><td><code id="ldshrink_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="ashr.html#topic+ash">ash</a>()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A correlation matrix.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>References</h3>


<ul>
<li><p>Stephens, Matthew. &quot;False discovery rates: a new deal.&quot;
Biostatistics 18, no. 2 (2017): 275-294.
</p>
</li>
<li><p>Dey, Kushal K., and Matthew Stephens. &quot;CorShrink:
Empirical Bayes shrinkage estimation of correlations,
with applications.&quot; bioRxiv (2018): 368316.
</p>
</li></ul>


<hr>
<h2 id='mldest'>Estimate all pair-wise LD's in a collection of SNPs using genotypes or
genotype likelihoods.</h2><span id='topic+mldest'></span>

<h3>Description</h3>

<p>This function is a wrapper to run <code><a href="#topic+ldest">ldest</a>()</code> for many pairs of
SNPs. This takes a maximum likelihood approach to LD estimation. See
<code><a href="#topic+ldfast">ldfast</a>()</code> for a method-of-moments approach to LD estimation.
Support is provided for parallelization through the foreach and doParallel
packages. See Gerard (2021) for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mldest(
  geno,
  K,
  nc = 1,
  type = c("hap", "comp"),
  model = c("norm", "flex"),
  pen = ifelse(type == "hap", 2, 1),
  se = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mldest_+3A_geno">geno</code></td>
<td>
<p>One of two possible inputs:
</p>

<ul>
<li><p>A matrix of genotypes (allele dosages). The rows index the
SNPs and the columns index the individuals. That is,
<code>genomat[i, j]</code> is the allele dosage for individual
<code>j</code> in SNP <code>i</code>. When <code>type = "comp"</code>, the
dosages are allowed to be continuous (e.g. posterior
mean genotypes).
</p>
</li>
<li><p>A three-way array of genotype <em>log</em>-likelihoods.
The first dimension indexes the SNPs, the second dimension
indexes the individuals, and the third dimension indexes
the genotypes. That is, <code>genolike_array[i, j, k]</code>
is the genotype log-likelihood at SNP <code>i</code> for
individual <code>j</code> and dosage <code>k - 1</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="mldest_+3A_k">K</code></td>
<td>
<p>The ploidy of the species. Assumed to be the same for all
individuals.</p>
</td></tr>
<tr><td><code id="mldest_+3A_nc">nc</code></td>
<td>
<p>The number of computing cores to use. This should never be
more than the number of cores available in your computing environment.
You can determine the maximum number of available cores by running
<code>parallel::detectCores()</code> in R. This is probably fine for a
personal computer, but some environments are only
able to use fewer. Ask your admins if you are unsure.</p>
</td></tr>
<tr><td><code id="mldest_+3A_type">type</code></td>
<td>
<p>The type of LD to calculate. The available types are
haplotypic LD (<code>type = "hap"</code>) or composite LD
(<code>type = "comp"</code>). Haplotypic LD is only appropriate for
autopolyploids when the individuals are in Hardy-Weinberg
equilibrium (HWE). The composite
measures of LD are always applicable, and consistently estimate the
usual measures of LD when HWE is fulfilled in autopolyploids.
However, when HWE is not fulfilled, interpreting the
composite measures of LD could be a little tricky.</p>
</td></tr>
<tr><td><code id="mldest_+3A_model">model</code></td>
<td>
<p>When <code>type = "comp"</code> and using genotype likelihoods,
should we use the proportional
bivariate normal model to estimate the genotype distribution
(<code>model = "norm"</code>), or the general categorical distribution
(<code>model = "flex"</code>)? Defaults to <code>"norm"</code>.</p>
</td></tr>
<tr><td><code id="mldest_+3A_pen">pen</code></td>
<td>
<p>The penalty to be applied to the likelihood. You can think about
this as the prior sample size. Should be greater than 1. Does not
apply if <code>model = "norm"</code>, <code>type = "comp"</code>, and using
genotype likelihoods. Also does not apply when <code>type = "comp"</code>
and using genotypes.</p>
</td></tr>
<tr><td><code id="mldest_+3A_se">se</code></td>
<td>
<p>A logical. Should we calculate standard errors (<code>TRUE</code>) or
not (<code>FALSE</code>). Calculating standard errors can be really slow
when <code>type = "comp"</code>, <code>model = "flex"</code>, and when using
genotype likelihoods. Otherwise, standard error calculations
should be pretty fast.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+ldest">ldest</a>()</code> for details on the different types of LD
estimators supported.
</p>


<h3>Value</h3>

<p>A data frame of class <code>c("lddf", "data.frame")</code>
with some or all of the following elements:
</p>

<dl>
<dt><code>i</code></dt><dd><p>The index of the first SNP.</p>
</dd>
<dt><code>j</code></dt><dd><p>The index of the second SNP.</p>
</dd>
<dt><code>snpi</code></dt><dd><p>The row name corresponding to SNP <code>i</code>, if
row names are provided.</p>
</dd>
<dt><code>snpj</code></dt><dd><p>The row name corresponding to SNP <code>j</code>, if
row names are provided.</p>
</dd>
<dt><code>D</code></dt><dd><p>The estimate of the LD coefficient.</p>
</dd>
<dt><code>D_se</code></dt><dd><p>The standard error of the estimate of
the LD coefficient.</p>
</dd>
<dt><code>r2</code></dt><dd><p>The estimate of the squared Pearson correlation.</p>
</dd>
<dt><code>r2_se</code></dt><dd><p>The standard error of the estimate of the
squared Pearson correlation.</p>
</dd>
<dt><code>r</code></dt><dd><p>The estimate of the Pearson correlation.</p>
</dd>
<dt><code>r_se</code></dt><dd><p>The standard error of the estimate of the
Pearson correlation.</p>
</dd>
<dt><code>Dprime</code></dt><dd><p>The estimate of the standardized LD
coefficient. When <code>type</code> = &quot;comp&quot;, this corresponds
to the standardization where we fix allele frequencies.</p>
</dd>
<dt><code>Dprime_se</code></dt><dd><p>The standard error of <code>Dprime</code>.</p>
</dd>
<dt><code>Dprimeg</code></dt><dd><p>The estimate of the standardized LD
coefficient. This corresponds to the standardization where
we fix genotype frequencies.</p>
</dd>
<dt><code>Dprimeg_se</code></dt><dd><p>The standard error of <code>Dprimeg</code>.</p>
</dd>
<dt><code>z</code></dt><dd><p>The Fisher-z transformation of <code>r</code>.</p>
</dd>
<dt><code>z_se</code></dt><dd><p>The standard error of the Fisher-z
transformation of <code>r</code>.</p>
</dd>
<dt><code>p_ab</code></dt><dd><p>The estimated haplotype frequency of ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_Ab</code></dt><dd><p>The estimated haplotype frequency of Ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_aB</code></dt><dd><p>The estimated haplotype frequency of aB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_AB</code></dt><dd><p>The estimated haplotype frequency of AB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>q_ij</code></dt><dd><p>The estimated frequency of genotype i at locus 1
and genotype j at locus 2. Only returned if estimating the
composite LD.</p>
</dd>
<dt><code>n</code></dt><dd><p>The number of individuals used to estimate pairwise LD.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>References</h3>


<ul>
<li><p>Gerard, David. &quot;Pairwise Linkage Disequilibrium Estimation
for Polyploids.&quot; <em>Molecular Ecology Resources</em> 21,
no. 4 (2021): 1230-1242. <a href="https://doi.org/10.1111/1755-0998.13349">doi:10.1111/1755-0998.13349</a>
</p>
</li></ul>



<h3>See Also</h3>


<dl>
<dt><code><a href="#topic+ldfast">ldfast</a>()</code></dt><dd><p>Fast, moment-based approach to LD estimation
that also accounts for genotype uncertainty.</p>
</dd>
<dt><code><a href="#topic+ldest">ldest</a>()</code></dt><dd><p>For the base function that estimates
pairwise LD.</p>
</dd>
<dt><code><a href="#topic+sldest">sldest</a>()</code></dt><dd><p>For estimating pairwise LD along a
sliding window.</p>
</dd>
<dt><code><a href="#topic+format_lddf">format_lddf</a>()</code></dt><dd><p>For formatting the output of
<code>mldest()</code> as a matrix.</p>
</dd>
<dt><code><a href="#topic+plot.lddf">plot.lddf</a>()</code></dt><dd><p>For plotting the output of
<code>mldest()</code>.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

## Simulate genotypes when true correlation is 0
nloci &lt;- 5
nind  &lt;- 100
K &lt;- 6
nc &lt;- 1
genomat &lt;- matrix(sample(0:K, nind * nloci, TRUE), nrow = nloci)

## Composite LD estimates
lddf &lt;- mldest(geno = genomat,
               K = K,
               nc = nc,
               type = "comp")
lddf[1:6, 1:6]


</code></pre>

<hr>
<h2 id='pbnorm_dist'>Returns distribution of proportional bivariate normal.</h2><span id='topic+pbnorm_dist'></span>

<h3>Description</h3>

<p>Returns distribution of proportional bivariate normal.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pbnorm_dist(mu, sigma, K, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pbnorm_dist_+3A_mu">mu</code></td>
<td>
<p>A vector of length 2 containing the mean.</p>
</td></tr>
<tr><td><code id="pbnorm_dist_+3A_sigma">sigma</code></td>
<td>
<p>A 2-by-2 positive definite covariance matrix</p>
</td></tr>
<tr><td><code id="pbnorm_dist_+3A_k">K</code></td>
<td>
<p>The ploidy of the individual.</p>
</td></tr>
<tr><td><code id="pbnorm_dist_+3A_log">log</code></td>
<td>
<p>A logical. If <code>TRUE</code>, log probabilities are returned.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix. Element (i,j) is the (log) probability of genotype
i-1 at locus 1 and j-1 at locus 2.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>

<hr>
<h2 id='plot.lddf'>Plot the output of <code><a href="#topic+mldest">mldest</a>()</code> or
<code><a href="#topic+sldest">sldest</a>()</code> using <code><a href="corrplot.html#topic+corrplot">corrplot</a>()</code></h2><span id='topic+plot.lddf'></span>

<h3>Description</h3>

<p>Formats the LD estimates in the form of a matrix and creates a heatmap of
these estimates. This heatmap is created using the
<code><a href="corrplot.html#topic+corrplot">corrplot</a></code> R package. I've adjusted a lot of the defaults
to suit my visualization preferences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'lddf'
plot(
  x,
  element = "r2",
  type = c("upper", "full", "lower"),
  method = c("color", "circle", "square", "ellipse", "number", "shade", "pie"),
  diag = FALSE,
  is.corr = NULL,
  tl.pos = "n",
  title = NULL,
  na.label = "square",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.lddf_+3A_x">x</code></td>
<td>
<p>An object of class <code>lddf</code>, usually created using
either <code><a href="#topic+mldest">mldest</a>()</code> or <code><a href="#topic+sldest">sldest</a>()</code>.</p>
</td></tr>
<tr><td><code id="plot.lddf_+3A_element">element</code></td>
<td>
<p>Which element of <code>x</code> should we plot?</p>
</td></tr>
<tr><td><code id="plot.lddf_+3A_type">type</code></td>
<td>
<p>Character, <code>"full"</code>,
<code>"upper"</code> (default) or <code>"lower"</code>, display
full matrix, lower triangular or upper
triangular matrix.</p>
</td></tr>
<tr><td><code id="plot.lddf_+3A_method">method</code></td>
<td>
<p>See <code><a href="corrplot.html#topic+corrplot">corrplot</a>()</code> for available options.
Default value is <code>"color"</code>.</p>
</td></tr>
<tr><td><code id="plot.lddf_+3A_diag">diag</code></td>
<td>
<p>Logical, whether display the correlation coefficients
on the principal diagonal.</p>
</td></tr>
<tr><td><code id="plot.lddf_+3A_is.corr">is.corr</code></td>
<td>
<p>See <code><a href="corrplot.html#topic+corrplot">corrplot</a>()</code>. Default behavior
is <code>TRUE</code> if an element is constrained
between -1 and 1 and <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="plot.lddf_+3A_tl.pos">tl.pos</code></td>
<td>
<p>See <code><a href="corrplot.html#topic+corrplot">corrplot</a>()</code>. Default value
is <code>"n"</code>.</p>
</td></tr>
<tr><td><code id="plot.lddf_+3A_title">title</code></td>
<td>
<p>What should the title be? Defaults to the element name.</p>
</td></tr>
<tr><td><code id="plot.lddf_+3A_na.label">na.label</code></td>
<td>
<p>See <code><a href="corrplot.html#topic+corrplot">corrplot</a>()</code>. Default value
is <code>"square"</code>.</p>
</td></tr>
<tr><td><code id="plot.lddf_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to
<code><a href="corrplot.html#topic+corrplot">corrplot</a>()</code>. See the documentation of that
function for options.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For greater plotting flexibility, see <code><a href="corrplot.html#topic+corrplot">corrplot</a>()</code>
for the parameter options.
</p>


<h3>Value</h3>

<p>(Invisibly) returns a matrix of the selected elements.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

## Simulate genotypes when true correlation is 0
nloci &lt;- 5
nind  &lt;- 100
K &lt;- 6
nc &lt;- 1
genomat &lt;- matrix(sample(0:K, nind * nloci, TRUE), nrow = nloci)

## Haplotypic LD estimates
lddf &lt;- mldest(geno = genomat,
               K = K,
               nc = nc,
               type = "hap")

## Plot estimates of z
plot(lddf, element = "z")

</code></pre>

<hr>
<h2 id='pvcalc'>Calculate prior variances from a matrix of prior genotype probabilities.</h2><span id='topic+pvcalc'></span>

<h3>Description</h3>

<p>Given a matrix of prior probabilities for the genotypes at each SNP,
this function will calculate the prior variance of genotypes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pvcalc(priormat)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pvcalc_+3A_priormat">priormat</code></td>
<td>
<p>A matrix of prior genotype probabilities. Element
<code>priormat[i, j]</code> is the prior probability of dosage <code>j</code>
at SNP <code>i</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of prior variances.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("uit")
priormat &lt;- uit$snpdf[, paste0("Pr_", 0:4)]
pvcalc(priormat)

</code></pre>

<hr>
<h2 id='slcor'>Sliding window correlation</h2><span id='topic+slcor'></span>

<h3>Description</h3>

<p>Calculates the pairwise Pearson correlation between all columns
within a fixed window size (<code>win</code>)
using the <code>use = "pairwise.complete.obs"</code> option
from <code><a href="stats.html#topic+cor">cor</a>()</code>. That is, the correlation
between each pair of variables is computed using all complete pairs
of observations on those variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slcor(x, win = 1L)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="slcor_+3A_x">x</code></td>
<td>
<p>A numeric matrix. The variables index the columns.</p>
</td></tr>
<tr><td><code id="slcor_+3A_win">win</code></td>
<td>
<p>The size of the window. Defaults to 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A correlation matrix with only the observations within a window
containing calculated correlations.
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)
n &lt;- 10
p &lt;- 100
xmat &lt;- matrix(rnorm(n * p), ncol = n)
xmat[sample(n * p, size = 30)] &lt;- NA_real_
slcor(xmat, win = 2)

</code></pre>

<hr>
<h2 id='sldest'>Sliding window LD estimation</h2><span id='topic+sldest'></span>

<h3>Description</h3>

<p>This function is a wrapper for <code><a href="#topic+ldest">ldest</a>()</code> for estimating LD
along a sliding window of a fixed size. Support is provided for parallelization through the
foreach and doParallel packages.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sldest(
  geno,
  K,
  win = 50,
  nc = 1,
  type = c("hap", "comp"),
  model = c("norm", "flex"),
  pen = ifelse(type == "hap", 2, 1),
  se = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sldest_+3A_geno">geno</code></td>
<td>
<p>One of two possible inputs:
</p>

<ul>
<li><p>A matrix of genotypes (allele dosages). The rows index the
SNPs and the columns index the individuals. That is,
<code>genomat[i, j]</code> is the allele dosage for individual
<code>j</code> in SNP <code>i</code>. When <code>type = "comp"</code>, the
dosages are allowed to be continuous (e.g. posterior
mean genotypes).
</p>
</li>
<li><p>A three-way array of genotype <em>log</em>-likelihoods.
The first dimension indexes the SNPs, the second dimension
indexes the individuals, and the third dimension indexes
the genotypes. That is, <code>genolike_array[i, j, k]</code>
is the genotype log-likelihood at SNP <code>i</code> for
individual <code>j</code> and dosage <code>k - 1</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="sldest_+3A_k">K</code></td>
<td>
<p>The ploidy of the species. Assumed to be the same for all
individuals.</p>
</td></tr>
<tr><td><code id="sldest_+3A_win">win</code></td>
<td>
<p>The window size. Pairwise LD will be estimated plus or minus
these many positions. Larger sizes significantly increase the
computational load.</p>
</td></tr>
<tr><td><code id="sldest_+3A_nc">nc</code></td>
<td>
<p>The number of computing cores to use. This should never be
more than the number of cores available in your computing environment.
You can determine the maximum number of available cores by running
<code>parallel::detectCores()</code> in R. This is probably fine for a
personal computer, but some environments are only
able to use fewer. Ask your admins if you are unsure.</p>
</td></tr>
<tr><td><code id="sldest_+3A_type">type</code></td>
<td>
<p>The type of LD to calculate. The available types are
haplotypic LD (<code>type = "hap"</code>) or composite LD
(<code>type = "comp"</code>). Haplotypic LD is only appropriate for
autopolyploids when the individuals are in Hardy-Weinberg
equilibrium (HWE). The composite
measures of LD are always applicable, and consistently estimate the
usual measures of LD when HWE is fulfilled in autopolyploids.
However, when HWE is not fulfilled, interpreting the
composite measures of LD could be a little tricky.</p>
</td></tr>
<tr><td><code id="sldest_+3A_model">model</code></td>
<td>
<p>When <code>type = "comp"</code> and using genotype likelihoods,
should we use the proportional
bivariate normal model to estimate the genotype distribution
(<code>model = "norm"</code>), or the general categorical distribution
(<code>model = "flex"</code>)? Defaults to <code>"norm"</code>.</p>
</td></tr>
<tr><td><code id="sldest_+3A_pen">pen</code></td>
<td>
<p>The penalty to be applied to the likelihood. You can think about
this as the prior sample size. Should be greater than 1. Does not
apply if <code>model = "norm"</code>, <code>type = "comp"</code>, and using
genotype likelihoods. Also does not apply when <code>type = "comp"</code>
and using genotypes.</p>
</td></tr>
<tr><td><code id="sldest_+3A_se">se</code></td>
<td>
<p>A logical. Should we calculate standard errors (<code>TRUE</code>) or
not (<code>FALSE</code>). Calculating standard errors can be really slow
when <code>type = "comp"</code>, <code>model = "flex"</code>, and when using
genotype likelihoods. Otherwise, standard error calculations
should be pretty fast.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+ldest">ldest</a>()</code> for details on the different types of LD
estimators supported.
</p>


<h3>Value</h3>

<p>A data frame of class <code>c("lddf", "data.frame")</code>
with some or all of the following elements:
</p>

<dl>
<dt><code>i</code></dt><dd><p>The index of the first SNP.</p>
</dd>
<dt><code>j</code></dt><dd><p>The index of the second SNP.</p>
</dd>
<dt><code>snpi</code></dt><dd><p>The row name corresponding to SNP <code>i</code>, if
row names are provided.</p>
</dd>
<dt><code>snpj</code></dt><dd><p>The row name corresponding to SNP <code>j</code>, if
row names are provided.</p>
</dd>
<dt><code>D</code></dt><dd><p>The estimate of the LD coefficient.</p>
</dd>
<dt><code>D_se</code></dt><dd><p>The standard error of the estimate of
the LD coefficient.</p>
</dd>
<dt><code>r2</code></dt><dd><p>The estimate of the squared Pearson correlation.</p>
</dd>
<dt><code>r2_se</code></dt><dd><p>The standard error of the estimate of the
squared Pearson correlation.</p>
</dd>
<dt><code>r</code></dt><dd><p>The estimate of the Pearson correlation.</p>
</dd>
<dt><code>r_se</code></dt><dd><p>The standard error of the estimate of the
Pearson correlation.</p>
</dd>
<dt><code>Dprime</code></dt><dd><p>The estimate of the standardized LD
coefficient. When <code>type</code> = &quot;comp&quot;, this corresponds
to the standardization where we fix allele frequencies.</p>
</dd>
<dt><code>Dprime_se</code></dt><dd><p>The standard error of <code>Dprime</code>.</p>
</dd>
<dt><code>Dprimeg</code></dt><dd><p>The estimate of the standardized LD
coefficient. This corresponds to the standardization where
we fix genotype frequencies.</p>
</dd>
<dt><code>Dprimeg_se</code></dt><dd><p>The standard error of <code>Dprimeg</code>.</p>
</dd>
<dt><code>z</code></dt><dd><p>The Fisher-z transformation of <code>r</code>.</p>
</dd>
<dt><code>z_se</code></dt><dd><p>The standard error of the Fisher-z
transformation of <code>r</code>.</p>
</dd>
<dt><code>p_ab</code></dt><dd><p>The estimated haplotype frequency of ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_Ab</code></dt><dd><p>The estimated haplotype frequency of Ab.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_aB</code></dt><dd><p>The estimated haplotype frequency of aB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>p_AB</code></dt><dd><p>The estimated haplotype frequency of AB.
Only returned if estimating the haplotypic LD.</p>
</dd>
<dt><code>q_ij</code></dt><dd><p>The estimated frequency of genotype i at locus 1
and genotype j at locus 2. Only returned if estimating the
composite LD.</p>
</dd>
<dt><code>n</code></dt><dd><p>The number of individuals used to estimate pairwise LD.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>See Also</h3>


<dl>
<dt><code><a href="#topic+ldest">ldest</a>()</code></dt><dd><p>For the base function that estimates
pairwise LD.</p>
</dd>
<dt><code><a href="#topic+mldest">mldest</a>()</code></dt><dd><p>For estimating pairwise LD between
<em>all</em> provided SNPs.</p>
</dd>
<dt><code><a href="#topic+ldfast">ldfast</a>()</code></dt><dd><p>Fast, moment-based approach to LD estimation
that also accounts for genotype uncertainty.</p>
</dd>
<dt><code><a href="#topic+format_lddf">format_lddf</a>()</code></dt><dd><p>For formatting the output of
<code>sldest()</code> as a matrix.</p>
</dd>
<dt><code><a href="#topic+plot.lddf">plot.lddf</a>()</code></dt><dd><p>For plotting the output of
<code>sldest()</code>.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>set.seed(1)

## Simulate genotypes when true correlation is 0
nloci &lt;- 100
nind  &lt;- 100
win &lt;- 5
K &lt;- 6
nc &lt;- 1
genomat &lt;- matrix(sample(0:K, nind * nloci, TRUE), nrow = nloci)

## Composite LD estimates
lddf &lt;- sldest(geno = genomat,
               K = K,
               win = win,
               nc = nc,
               type = "comp")
plot(lddf, element = "z")

</code></pre>

<hr>
<h2 id='uit'>Updog fits on the data from Uitdewilligen et. al. (2013)</h2><span id='topic+uit'></span>

<h3>Description</h3>

<p>10 SNPs from the &quot;PGSC0003DMB000000062&quot; super scaffold were genotyped
using the <code><a href="updog.html#topic+multidog">multidog</a>()</code> function from the updog R package.
These data are the resulting output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>uit
</code></pre>


<h3>Format</h3>

<p>An object of class <code><a href="updog.html#topic+multidog">multidog</a>()</code>.
See the documentation from the updog R package.
</p>


<h3>Source</h3>

<p><a href="https://doi.org/10.1371/journal.pone.0062355">doi:10.1371/journal.pone.0062355</a>
</p>


<h3>References</h3>


<ul>
<li><p>Uitdewilligen, Jan GAML, Anne-Marie A. Wolters, B. Bjorn, Theo JA Borm, Richard GF Visser, and Herman J. Van Eck. &quot;A next-generation sequencing method for genotyping-by-sequencing of highly heterozygous autotetraploid potato.&quot; <em>PloS one</em> 8, no. 5 (2013): e62355. <a href="https://doi.org/10.1371/journal.pone.0062355">doi:10.1371/journal.pone.0062355</a>
</p>
</li></ul>


<hr>
<h2 id='zshrink'>Shrinks Fisher-z transformed correlation estimates and returns resulting
correlation estimates.</h2><span id='topic+zshrink'></span>

<h3>Description</h3>

<p>This function is a wrapper for adaptive shrinkage (Stephens, 2017) on the
Fisher-z transformed estimates of the Pearson correlation. This approach
was proposed in Dey and Stephens (2018) but is re-implemented here for now
since the CorShrink package is not available on CRAN.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>zshrink(zmat, smat, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="zshrink_+3A_zmat">zmat</code></td>
<td>
<p>The matrix of Fisher-z transformed correlation estimates.</p>
</td></tr>
<tr><td><code id="zshrink_+3A_smat">smat</code></td>
<td>
<p>The matrix of standard errors of the Fisher-z transformed
correlation estimates.</p>
</td></tr>
<tr><td><code id="zshrink_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass to <code><a href="ashr.html#topic+ash">ash</a>()</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix of correlation estimates. These are posterior means
of the correlation estimates after applying the CorShrink method
(Dey and Stephens, 2018).
</p>


<h3>Author(s)</h3>

<p>David Gerard
</p>


<h3>References</h3>


<ul>
<li><p>Stephens, Matthew. &quot;False discovery rates: a new deal.&quot;
Biostatistics 18, no. 2 (2017): 275-294.
</p>
</li>
<li><p>Dey, Kushal K., and Matthew Stephens. &quot;CorShrink:
Empirical Bayes shrinkage estimation of correlations,
with applications.&quot; bioRxiv (2018): 368316.
</p>
</li></ul>


</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
