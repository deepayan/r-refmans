<!DOCTYPE html><html lang="en"><head><title>Help for package fda.usc</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {fda.usc}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#fda.usc-package'><p>Functional Data Analysis and Utilities for Statistical Computing (fda.usc)</p></a></li>
<li><a href='#accuracy'><p>Performance measures for regression and classification models</p></a></li>
<li><a href='#aemet'><p>aemet data</p></a></li>
<li><a href='#classif.DD'><p>DD-Classifier Based on DD-plot</p></a></li>
<li><a href='#classif.depth'><p>Classifier from Functional Data</p></a></li>
<li><a href='#classif.gkam'><p>Classification Fitting Functional Generalized Kernel Additive Models</p></a></li>
<li><a href='#classif.glm'><p>Classification Fitting Functional Generalized Linear Models</p></a></li>
<li><a href='#classif.gsam'><p>Classification Fitting Functional Generalized Additive Models</p></a></li>
<li><a href='#classif.gsam.vs'><p>Variable Selection in Functional Data Classification</p></a></li>
<li><a href='#classif.kfold'><p>Functional Classification usign k-fold CV</p></a></li>
<li><a href='#classif.ML'><p>Functional classification using ML algotithms</p></a></li>
<li><a href='#classif.np'><p>Kernel Classifier from Functional Data</p></a></li>
<li><a href='#cond.F'><p>Conditional Distribution Function</p></a></li>
<li><a href='#cond.mode'><p>Conditional mode</p></a></li>
<li><a href='#cond.quantile'><p>Conditional quantile</p></a></li>
<li><a href='#create.fdata.basis'><p>Create Basis Set for Functional Data of fdata class</p></a></li>
<li><a href='#CV.S'><p>The cross-validation (CV) score</p></a></li>
<li><a href='#dcor.xy'><p>Distance Correlation Statistic and t-Test</p></a></li>
<li><a href='#depth.fdata'><p>Computation of depth measures for functional data</p></a></li>
<li><a href='#depth.mdata'><p>Provides the depth measure for multivariate data</p></a></li>
<li><a href='#depth.mfdata'><p>Provides the depth measure for a list of p&ndash;functional data objects</p></a></li>
<li><a href='#Descriptive'><p>Descriptive measures for functional data.</p></a></li>
<li><a href='#dev.S'><p>The deviance score</p></a></li>
<li><a href='#dfv.test'><p>Delsol, Ferraty and Vieu test for no functional-scalar interaction</p></a></li>
<li><a href='#dis.cos.cor'><p>Proximities between functional data</p></a></li>
<li><a href='#fanova.hetero'><p>ANOVA for heteroscedastic data</p></a></li>
<li><a href='#fanova.onefactor'><p>One&ndash;way anova model for functional data</p></a></li>
<li><a href='#fanova.RPm'><p>Functional ANOVA with Random Project.</p></a></li>
<li><a href='#fda.usc.internal'><p>fda.usc internal functions</p></a></li>
<li><a href='#fdata'><p>Converts raw data or other functional data classes into fdata class.</p></a></li>
<li><a href='#fdata.bootstrap'><p>Bootstrap samples of a functional statistic</p></a></li>
<li><a href='#fdata.cen'><p>Functional data centred (subtract the mean of each discretization point)</p></a></li>
<li><a href='#fdata.deriv'><p>Computes the derivative of functional data object.</p></a></li>
<li><a href='#fdata.methods'><p>fdata  S3 Group Generic Functions</p></a></li>
<li><a href='#fdata2basis'><p>Compute fucntional coefficients from functional data represented in a base of functions</p></a></li>
<li><a href='#fdata2fd'><p>Converts fdata class object into fd class object</p></a></li>
<li><a href='#fdata2pc'><p>Principal components for functional data</p></a></li>
<li><a href='#fdata2pls'><p>Partial least squares components for functional data.</p></a></li>
<li><a href='#FDR'><p>False Discorvery Rate (FDR)</p></a></li>
<li><a href='#fEqDistrib.test'><p>Tests for checking the equality of distributions between two functional populations.</p></a></li>
<li><a href='#fEqMoments.test'><p>Tests for checking the equality of means and/or covariance between two populations under gaussianity.</p></a></li>
<li><a href='#flm.Ftest'><p>F-test for the Functional Linear Model with scalar response</p></a></li>
<li><a href='#flm.test'><p>Goodness-of-fit test for the Functional Linear Model with scalar response</p></a></li>
<li><a href='#fregre.basis'><p>Functional Regression with scalar response using basis representation.</p></a></li>
<li><a href='#fregre.basis.cv'><p>Cross-validation Functional Regression with scalar response using basis</p>
representation.</a></li>
<li><a href='#fregre.basis.fr'><p>Functional Regression with functional response using basis representation.</p></a></li>
<li><a href='#fregre.bootstrap'><p>Bootstrap regression</p></a></li>
<li><a href='#fregre.gkam'><p>Fitting Functional Generalized Kernel Additive Models.</p></a></li>
<li><a href='#fregre.glm'><p>Fitting Functional Generalized Linear Models</p></a></li>
<li><a href='#fregre.glm.vs'><p>Variable Selection using Functional Linear Models</p></a></li>
<li><a href='#fregre.gls'><p>Fit Functional Linear Model Using Generalized Least Squares</p></a></li>
<li><a href='#fregre.gsam'><p>Fitting Functional Generalized Spectral Additive Models</p></a></li>
<li><a href='#fregre.gsam.vs'><p>Variable Selection using Functional Additive Models</p></a></li>
<li><a href='#fregre.igls'><p>Fit of  Functional Generalized Least Squares Model Iteratively</p></a></li>
<li><a href='#fregre.lm'><p>Fitting Functional Linear Models</p></a></li>
<li><a href='#fregre.np'><p>Functional regression with scalar response using non-parametric kernel</p>
estimation</a></li>
<li><a href='#fregre.np.cv'><p>Cross-validation functional regression with scalar response using kernel</p>
estimation.</a></li>
<li><a href='#fregre.pc'><p>Functional Regression with scalar response using Principal Components</p>
Analysis</a></li>
<li><a href='#fregre.pc.cv'><p>Functional penalized PC regression with scalar response using selection of</p>
number of PC components</a></li>
<li><a href='#fregre.plm'><p>Semi-functional partially linear model with scalar response.</p></a></li>
<li><a href='#fregre.pls'><p>Functional Penalized PLS regression with scalar response</p></a></li>
<li><a href='#fregre.pls.cv'><p>Functional penalized PLS regression with scalar response using selection of</p>
number of PLS components</a></li>
<li><a href='#GCCV.S'><p>The generalized correlated cross-validation (GCCV) score.</p></a></li>
<li><a href='#GCV.S'><p>The generalized correlated cross-validation (GCCV) score</p></a></li>
<li><a href='#h.default'><p>Calculation of the smoothing parameter (h) for a functional data</p></a></li>
<li><a href='#influence_quan'><p>Quantile for influence measures</p></a></li>
<li><a href='#influence.fregre.fd'><p>Functional influence measures</p></a></li>
<li><a href='#inprod.fdata'><p>Inner products of Functional Data Objects o class (fdata)</p></a></li>
<li><a href='#int.simpson'><p>Simpson integration</p></a></li>
<li><a href='#Kernel'><p>Symmetric Smoothing Kernels.</p></a></li>
<li><a href='#Kernel.asymmetric'><p>Asymmetric Smoothing Kernel</p></a></li>
<li><a href='#Kernel.integrate'><p>Integrate Smoothing Kernels.</p></a></li>
<li><a href='#kmeans.center.ini'><p>K-Means Clustering for functional data</p></a></li>
<li><a href='#ldata'><p>ldata class definition and utilities</p></a></li>
<li><a href='#LMDC.select'><p>Impact points selection of functional predictor and regression using local</p>
maxima distance correlation (LMDC)</a></li>
<li><a href='#MCO'><p>Mithochondiral calcium overload (MCO) data set</p></a></li>
<li><a href='#metric.dist'><p>Distance Matrix Computation</p></a></li>
<li><a href='#metric.DTW'><p>DTW: Dynamic time warping</p></a></li>
<li><a href='#metric.hausdorff'><p>Compute the Hausdorff distances between two curves.</p></a></li>
<li><a href='#metric.kl'><p>Kullback&ndash;Leibler distance</p></a></li>
<li><a href='#metric.ldata'><p>Distance Matrix Computation for ldata and mfdata class object</p></a></li>
<li><a href='#metric.lp'><p>Approximates Lp-metric distances for functional data.</p></a></li>
<li><a href='#mfdata'><p>mfdata class definition and utilities</p></a></li>
<li><a href='#na.omit.fdata'><p>A wrapper for the na.omit and na.fail function for fdata object</p></a></li>
<li><a href='#norm.fdata'><p>Approximates Lp-norm for functional data.</p></a></li>
<li><a href='#ops.fda.usc'><p>ops.fda.usc  Options Settings</p></a></li>
<li><a href='#optim.basis'><p>Select the number of basis using GCV method.</p></a></li>
<li><a href='#optim.np'><p>Smoothing of functional data using nonparametric kernel estimation</p></a></li>
<li><a href='#Outliers.fdata'><p>outliers for functional dataset</p></a></li>
<li><a href='#P.penalty'><p>Penalty matrix for higher order differences</p></a></li>
<li><a href='#PCvM.statistic'><p>PCvM statistic for the Functional Linear Model with scalar response</p></a></li>
<li><a href='#phoneme'><p>phoneme data</p></a></li>
<li><a href='#plot.fdata'><p>Plot functional data: fdata class object</p></a></li>
<li><a href='#poblenou'><p>poblenou data</p></a></li>
<li><a href='#predict.classif'><p>Predicts from a fitted classif object.</p></a></li>
<li><a href='#predict.classif.DD'><p>Predicts from a fitted classif.DD object.</p></a></li>
<li><a href='#predict.fregre.fd'><p>Predict method for functional linear model (fregre.fd class)</p></a></li>
<li><a href='#predict.fregre.fr'><p>Predict method for functional response model</p></a></li>
<li><a href='#predict.fregre.gkam'><p>Predict method for functional linear model</p></a></li>
<li><a href='#predict.fregre.gls'><p>Predictions from a functional gls object</p></a></li>
<li><a href='#r.ou'><p>Ornstein-Uhlenbeck process</p></a></li>
<li><a href='#rcombfdata'><p>Utils for generate functional data</p></a></li>
<li><a href='#rdir.pc'><p>Data-driven sampling of random directions guided by sample of functional</p>
data</a></li>
<li><a href='#rp.flm.statistic'><p>Statistics for testing the functional linear model using random projections</p></a></li>
<li><a href='#rp.flm.test'><p>Goodness-of fit test for the functional linear model using random</p>
projections</a></li>
<li><a href='#rproc2fdata'><p>Simulate several random processes.</p></a></li>
<li><a href='#rwild'><p>Wild bootstrap residuals</p></a></li>
<li><a href='#S.basis'><p>Smoothing matrix with roughness penalties by basis representation.</p></a></li>
<li><a href='#S.np'><p>Smoothing matrix by nonparametric methods</p></a></li>
<li><a href='#semimetric.basis'><p>Proximities between functional data</p></a></li>
<li><a href='#semimetric.NPFDA'><p>Proximities between functional data (semi-metrics)</p></a></li>
<li><a href='#subset.fdata'><p>Subsetting</p></a></li>
<li><a href='#summary.classif'><p>Summarizes information from kernel classification methods.</p></a></li>
<li><a href='#summary.fdata.comp'><p>Correlation for functional data by Principal Component Analysis</p></a></li>
<li><a href='#summary.fregre.fd'><p>Summarizes information from fregre.fd objects.</p></a></li>
<li><a href='#summary.fregre.gkam'><p>Summarizes information from fregre.gkam objects.</p></a></li>
<li><a href='#tecator'><p>tecator data</p></a></li>
<li><a href='#Var.y'><p>Sampling Variance estimates</p></a></li>
<li><a href='#weights4class'><p>Weighting tools</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Functional Data Analysis and Utilities for Statistical Computing</td>
</tr>
<tr>
<td>Version:</td>
<td>2.2.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2024-11-04</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0), fda, splines, MASS, mgcv, knitr</td>
</tr>
<tr>
<td>Imports:</td>
<td>methods, grDevices, graphics, utils, stats, nlme, doParallel,
parallel, iterators, foreach, kSamples</td>
</tr>
<tr>
<td>Suggests:</td>
<td>rmarkdown</td>
</tr>
<tr>
<td>Description:</td>
<td>Routines for exploratory and descriptive analysis of functional data such as depth measurements, atypical curves detection, regression models, supervised classification, unsupervised classification and functional analysis of variance.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/moviedo5/fda.usc">https://github.com/moviedo5/fda.usc</a>,
<a href="https://moviedo5.github.io/fda.usc/">https://moviedo5.github.io/fda.usc/</a>,
<a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/moviedo5/fda.usc/issues">https://github.com/moviedo5/fda.usc/issues</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Author:</td>
<td>Manuel Febrero Bande
    <a href="https://orcid.org/0000-0002-9536-2973"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Manuel Oviedo de la Fuente
    <a href="https://orcid.org/0000-0001-7360-3249"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre],
  Pedro Galeano [ctb],
  Alicia Nieto [ctb],
  Eduardo Garcia-Portugues [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Manuel Oviedo de la Fuente &lt;manuel.oviedo@udc.es&gt;</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-11-09 18:10:53 UTC; Manuel Oviedo</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-11-09 18:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='fda.usc-package'>Functional Data Analysis and Utilities for Statistical Computing (fda.usc)</h2><span id='topic+fda.usc-package'></span><span id='topic+fda.usc'></span>

<h3>Description</h3>

<p>This devel version carries out exploratory and descriptive analysis of functional
data exploring its most important features: such as depth measurements or
functional outliers detection, among others. <br /> It also helps to explain
and model the relationship between a dependent variable and independent
(regression models) and make predictions. Methods for supervised or
unsupervised classification of a set of functional data regarding a feature
of the data are also included. Finally, it can perform analysis of variance
model (ANOVA) for functional data.
</p>


<h3>Details</h3>

<p>Sections of fda.usc-package: <br /> 
</p>

<table>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> A.- Functional Data Representation </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> B.- Functional Outlier Detection </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> C.- Functional Regression Model </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> D.- Functional Supervised  Classification  </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> E.- Functional Non-Supervised Classification </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> F.- Functional ANOVA </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> G.- Auxiliary functions</td>
</tr>
<tr>
 <td style="text-align: left;">
 </td>
</tr>

</table>

<p>A.- Functional Data Representation <br /> The functions included in this
section allow to define, transform, manipulate and represent a functional
dataset in many ways including derivatives, non-parametric kernel methods or
basis representation.<br />
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fdata">fdata</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+plot.fdata">plot.fdata</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> <code><a href="#topic+fdata.deriv">fdata.deriv</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+CV.S">CV.S</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+GCV.S">GCV.S</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+optim.np">optim.np</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+optim.basis">optim.basis</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+S.NW">S.NW</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+S.LLR">S.LLR</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+S.basis">S.basis</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+Var.e">Var.e</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+Var.y">Var.y</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>B.- Functional Depth and Functional Outlier Detection <br />
</p>
<p>The functional data depth calculated by the different depth functions
implemented that could be use as a measure of centrality or outlyingness.<br />
<br /> B.1-Depth methods <code><a href="#topic+Depth">Depth</a></code>:<br /> </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+depth.FM">depth.FM</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+depth.mode">depth.mode</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+depth.RP">depth.RP</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+depth.RT">depth.RT</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+depth.RPD">depth.RPD</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+Descriptive">Descriptive</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>B.2-Functional Outliers detection methods:<br /> </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+outliers.depth.trim">outliers.depth.trim</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+outliers.depth.pond">outliers.depth.pond</a></code>
</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+outliers.thres.lrt">outliers.thres.lrt</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+outliers.lrt">outliers.lrt</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>
<p> C.- Functional Regression Models<br />
</p>
<p>C.1. Functional explanatory covariate and scalar response<br /> The functions
included in this section allow the estimation of different functional
regression models with a scalar response and a single functional explicative
covariate.<br /> </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fregre.pc">fregre.pc</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fregre.pls">fregre.pls</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+fregre.pls.cv">fregre.pls.cv</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fregre.basis">fregre.basis</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fregre.np">fregre.np</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>C.2. Test for the functional linear model (FLM) with scalar response.<br />
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+flm.Ftest">flm.Ftest</a></code>, F-test for the FLM with scalar
response </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+flm.test">flm.test</a></code>, Goodness-of-fit test for the FLM
with scalar response </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+PCvM.statistic">PCvM.statistic</a></code>, PCvM statistic
for the FLM with scalar response </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>C.3. Functional and non functional explanatory covariates.<br /> The functions
in this section extends those regression models in previous section in
several ways.
</p>

<table>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> <code><a href="#topic+fregre.plm">fregre.plm</a></code>: Semifunctional Partial Linear Regression (an extension of  <code><a href="stats.html#topic+lm">lm</a></code> model)</td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> <code><a href="#topic+fregre.lm">fregre.lm</a></code>: Functional Linear Regression (an extension of  <code><a href="stats.html#topic+lm">lm</a></code> model) </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> <code><a href="#topic+fregre.glm">fregre.glm</a></code>: Functional Generalized Linear Regression (an extension of  <code><a href="stats.html#topic+glm">glm</a></code> model) </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> <code><a href="#topic+fregre.gsam">fregre.gsam</a></code>: Functional Generalized Spectral Additive Regression  (an extension of  <a href="mgcv.html#topic+gam">gam</a> model)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> <code><a href="#topic+fregre.gkam">fregre.gkam</a></code>: Functional Generalized Kernel Additive Regression (an extension of  <code><a href="#topic+fregre.np">fregre.np</a></code> model) </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td>
</tr>

</table>

<p>C.4. Functional response model (<code><a href="#topic+fregre.basis.fr">fregre.basis.fr</a></code>) allows the
estimation of functional regression models with a functional response and a
single functional explicative covariate.<br />
</p>
<p>C.5. <code><a href="#topic+fregre.gls">fregre.gls</a></code> fits functional linear model using generalized
least squares.  <code><a href="#topic+fregre.igls">fregre.igls</a></code> fits iteratively a functional
linear model using generalized least squares.  <br />
</p>
<p>C.6. <code><a href="#topic+fregre.gsam.vs">fregre.gsam.vs</a></code>, Variable Selection using Functional Additive Models <br />
</p>
<p>D.- Functional Supervised Classification <br /> This section allows the
estimation of the groups in a training set of functional data <code>fdata</code>
class by different nonparametric methods of supervised classification. Once
these classifiers have been trained, they can be used to predict on new
functional data.<br /> <br /> Package allows the estimation of the groups in a
training set of functional data by different methods of supervised
classification. <br /> <br />
</p>
<p>D.1 Univariate predictor (x,y arguments, fdata class)
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+classif.knn">classif.knn</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+classif.kernel">classif.kernel</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">  </td>
</tr>

</table>

<p>D.2 Multiple predictors (formula,data arguments, ldata class)
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+classif.glm">classif.glm</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+classif.gsam">classif.gsam</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+classif.gkam">classif.gkam</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">  </td>
</tr>

</table>

<p>D.3 Depth classifiers (fdata or ldata class)
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+classif.DD">classif.DD</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+classif.depth">classif.depth</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">  </td>
</tr>

</table>

<p>D.4 Functional Classification usign k-fold CV 
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+classif.kfold">classif.kfold</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>E.- Functional Non-Supervised Classification <br /> This section allows the
estimation of the groups in a functional data set <code>fdata</code> class by
kmeans method. <br /> </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+kmeans.fd">kmeans.fd</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>F.- Functional ANOVA <br /> </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fanova.onefactor">fanova.onefactor</a></code>
</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fanova.RPm">fanova.RPm</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fanova.hetero">fanova.hetero</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>G.- Utilities and auxiliary functions:<br /> </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+fdata.bootstrap">fdata.bootstrap</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fdata2fd">fdata2fd</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+fdata2pc">fdata2pc</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+fdata2pls">fdata2pls</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+summary.fdata.comp">summary.fdata.comp</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+cond.F">cond.F</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+cond.quantile">cond.quantile</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+cond.mode">cond.mode</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+FDR">FDR</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+Kernel">Kernel</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+Kernel.asymmetric">Kernel.asymmetric</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+Kernel.integrate">Kernel.integrate</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> <code><a href="#topic+metric.lp">metric.lp</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+metric.kl">metric.kl</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> <code><a href="#topic+metric.DTW">metric.DTW</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+metric.hausdorff">metric.hausdorff</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> <code><a href="#topic+metric.dist">metric.dist</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+semimetric.NPFDA">semimetric.NPFDA</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> 
</td><td style="text-align: left;"> <code><a href="#topic+semimetric.basis">semimetric.basis</a></code> </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>


<table>
<tr>
 <td style="text-align: left;"> Package: </td><td style="text-align: left;"> fda.usc</td>
</tr>
<tr>
 <td style="text-align: left;"> Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;"> Version: </td><td style="text-align: left;">
2.0.3</td>
</tr>
<tr>
 <td style="text-align: left;"> Date: </td><td style="text-align: left;"> 2021-06-03</td>
</tr>
<tr>
 <td style="text-align: left;"> License: </td><td style="text-align: left;"> GPL-2 </td>
</tr>
<tr>
 <td style="text-align: left;"> LazyLoad: </td><td style="text-align: left;">
yes</td>
</tr>
<tr>
 <td style="text-align: left;"> <a href="https://github.com/moviedo5/fda.usc/">https://github.com/moviedo5/fda.usc/</a> </td>
</tr>

</table>



<h3>Author(s)</h3>

<p><em>Authors:</em> Manuel Febrero Bande <a href="mailto:manuel.febrero@usc.es">manuel.febrero@usc.es</a>
and Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>
<p><em>Contributors:</em> Pedro Galeano, Alicia Nieto-Reyes, Eduardo
Garcia-Portugues <a href="mailto:eduardo.garcia@usc.es">eduardo.garcia@usc.es</a> and STAPH group
<a href="https://www.math.univ-toulouse.fr/~ferraty/">https://www.math.univ-toulouse.fr/~ferraty/</a> 
</p>
<p><em>Maintainer:</em> Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).
<em>Statistical Computing in Functional Data Analysis: The R Package
fda.usc.</em> Journal of Statistical Software, 51(4), 1-28.
<a href="https://doi.org/10.18637/jss.v051.i04">doi:10.18637/jss.v051.i04</a>
</p>

<hr>
<h2 id='accuracy'>Performance measures for regression and classification models</h2><span id='topic+accuracy'></span><span id='topic+cat2meas'></span><span id='topic+tab2meas'></span><span id='topic+pred2meas.'></span><span id='topic+pred.MSE'></span><span id='topic+pred.RMSE'></span><span id='topic+pred.MAE'></span><span id='topic+pred2meas'></span>

<h3>Description</h3>

<p><code><a href="#topic+cat2meas">cat2meas</a></code> and <code><a href="#topic+tab2meas">tab2meas</a></code> calculate the measures for a multiclass classification model.<br />
<code><a href="#topic+pred2meas">pred2meas</a></code> calculates the measures for a regression model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cat2meas(yobs, ypred, measure = "accuracy", cost = rep(1, nlevels(yobs)))

tab2meas(tab, measure = "accuracy", cost = rep(1, nrow(tab)))

pred.MSE(yobs, ypred)

pred.RMSE(yobs, ypred)

pred.MAE(yobs, ypred)

pred2meas(yobs, ypred, measure = "RMSE")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="accuracy_+3A_yobs">yobs</code></td>
<td>
<p>A vector of the labels, true class or observed response. Can be <code>numeric</code>, <code>character</code>, or <code>factor</code>.</p>
</td></tr>
<tr><td><code id="accuracy_+3A_ypred">ypred</code></td>
<td>
<p>A vector of the predicted labels, predicted class or predicted response. Can be <code>numeric, character, or factor</code>.</p>
</td></tr>
<tr><td><code id="accuracy_+3A_measure">measure</code></td>
<td>
<p>Type of measure, see <code>details</code> section.</p>
</td></tr>
<tr><td><code id="accuracy_+3A_cost">cost</code></td>
<td>
<p>Cost value by class (only for input factors).</p>
</td></tr>
<tr><td><code id="accuracy_+3A_tab">tab</code></td>
<td>
<p>Confusion matrix (Contingency table: observed class by rows, predicted class by columns).</p>
</td></tr>
</table>


<h3>Details</h3>


<ul>
<li> <p><code><a href="#topic+cat2meas">cat2meas</a></code> compute <code class="reqn">tab=table(yobs,ypred)</code> and calls <code><a href="#topic+tab2meas">tab2meas</a></code> function.
</p>
</li>
<li> <p><code><a href="#topic+tab2meas">tab2meas</a></code> function computes the following measures (see <code>measure</code> argument) for a binary classification model:
</p>

<ul>
<li> <p><code>accuracy</code>: Proportion of correct predictions.
<code class="reqn">\frac{TP + TN}{TP + TN + FP + FN}</code>
</p>
</li>
<li> <p><code>sensitivity, TPrate, recall</code>: True Positive Rate or recall.
<code class="reqn">\frac{TP}{TP + FN}</code>
</p>
</li>
<li> <p><code>precision</code>: Positive Predictive Value.
<code class="reqn">\frac{TP}{TP + FP}</code>
</p>
</li>
<li> <p><code>specificity, TNrate</code>: True Negative Rate.
<code class="reqn">\frac{TN}{TN + FP}</code>
</p>
</li>
<li> <p><code>FPrate</code>: False Positive Rate.
<code class="reqn">\frac{FP}{TN + FP}</code>
</p>
</li>
<li> <p><code>FNrate</code>: False Negative Rate.
<code class="reqn">\frac{FN}{TP + FN}</code>
</p>
</li>
<li> <p><code>Fmeasure</code>: Harmonic mean of precision and recall.
<code class="reqn">\frac{2}{\frac{1}{\text{recall}} + \frac{1}{\text{precision}}}</code>
</p>
</li>
<li> <p><code>Gmean</code>: Geometric Mean of recall and specificity.
<code class="reqn">\sqrt{\left(\frac{TP}{TP + FN}\right) \cdot \left(\frac{TN}{TN + FP}\right)}</code>
</p>
</li>
<li> <p><code>kappa</code>: Cohen's Kappa index.
<code class="reqn">Kappa = \frac{P_o - P_e}{1 - P_e}</code> where <code class="reqn">P_o</code> is the proportion of observed agreement, 
<code class="reqn">\frac{TP + TN}{TP + TN + FP + FN}</code>, and <code class="reqn">P_e</code> is the proportion of agreement expected by chance, 
<code class="reqn">\frac{(TP + FP)(TP + FN) + (TN + FN)(TN + FP)}{(TP + TN + FP + FN)^2}</code>.
</p>
</li>
<li> <p><code>cost</code>: Weighted accuracy, calculated as 
<code class="reqn">\frac{\sum (\text{diag(tab)} / \text{rowSums(tab)} \cdot \text{cost})}{\sum(\text{cost})}</code>
</p>
</li>
<li> <p><code>IOU</code>: Mean Intersection over Union.
<code class="reqn">\frac{TP}{TP + FN + FP}</code>
</p>
</li>
<li> <p><code>IOU4class</code>: Intersection over Union by class level.
<code class="reqn">\frac{TP}{TP + FN + FP}</code>#' </p>
</li></ul>

</li>
<li> <p><code><a href="#topic+pred2meas">pred2meas</a></code> function computes the following  measures of error, usign the <code>measure</code> argument, for observed and predicted vectors:
</p>

<ul>
<li> <p><code>MSE</code>: Mean squared error, <code class="reqn">\frac{\sum{(ypred- yobs)^2}}{n} </code>.
</p>
</li>
<li> <p><code>RMSE</code>: Root mean squared error <code class="reqn">\sqrt{\frac{\sum{(ypred- yobs)^2}}{n} }</code>.
</p>
</li>
<li> <p><code>MAE</code>: Mean Absolute Error, <code class="reqn">\frac{\sum |yobs - ypred|}{n}</code>.
</p>
</li></ul>

</li></ul>



<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+weights4class">weights4class</a>()</code>
</p>

<hr>
<h2 id='aemet'>aemet data</h2><span id='topic+aemet'></span>

<h3>Description</h3>

<p>Series of daily summaries of 73 spanish weather stations selected for the
period 1980-2009.  The dataset contains geographic information of each
station and the average for the period 1980-2009 of daily temperature, daily
precipitation and daily wind speed.
</p>


<h3>Format</h3>

<p>Elements of aemet:<br /> <code>..$df:</code> Data frame with information of
each wheather station:
</p>

<ul>
<li> <p><code>ind:</code> Indicated weather station.
</p>
</li>
<li>  <p><code>name:</code> Station Name.  36 marked UTF-8 strings.
</p>
</li>
<li>  <p><code>province:</code>Province (region) of Spain. 36 marked UTF-8 strings
</p>
</li>
<li> <p><code>altitude:</code> Altitude of the station (in meters).
</p>
</li>
<li>   <p><code>year.ini:</code> Start year.
</p>
</li>
<li>  <p><code>year.end:</code> End year.
</p>
</li>
<li>  <p><code>longitude:</code> x geographic coordinate of the station (in decimal degrees).
</p>
</li>
<li>  <p><code>latitude:</code> y geographic coordinate of the station (in decimal degrees).
</p>
</li></ul>

<p>The functional variables: 
</p>

<ul>
<li>  <p><code>...$temp</code>: mean curve of the average daily temperature
for the period 1980-2009 (in degrees Celsius, marked with UTF-8 string).
In leap years temperatures for February 28 and 29 were averaged.
</p>
</li>
<li> <p><code>...$wind.speed</code>: mean curve of the average daily wind speed for the
period 1980-2009 (in m/s).
</p>
</li>
<li>  <p><code>...$logprec</code>: mean curve of the log precipitation for
the period 1980-2009 (in log mm). Negligible precipitation 
(less than 1 tenth of mm) is replaced by <code>0.05</code> and no precipitation
(0.0 mm) is replaced by <code>0.01</code>.  Then the logarithm is applied.
</p>
</li></ul>



<h3>Details</h3>

<p>Meteorological State Agency of Spain (AEMET), <a href="https://www.aemet.es/es/portada">https://www.aemet.es/es/portada</a>. Government of Spain.<br />
It marks 36 UTF-8 string of names of stations and 3 UTF-8 string names of provinces through the function <code><a href="base.html#topic+iconv">iconv</a></code>.<br />
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>Source</h3>

<p>The data were obtained from the FTP of AEMET in 2009.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(aemet)
names(aemet)
names(aemet$df)
lat &lt;- ifelse(aemet$df$latitude&lt;31,"red","blue")
plot(aemet,col=lat)

## End(Not run)
</code></pre>

<hr>
<h2 id='classif.DD'>DD-Classifier Based on DD-plot</h2><span id='topic+classif.DD'></span>

<h3>Description</h3>

<p>Fits Nonparametric Classification Procedure Based on DD&ndash;plot
(depth-versus-depth plot) for G dimensions (<code class="reqn">G=g\times h</code>, g
levels and p data depth).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classif.DD(
  group,
  fdataobj,
  depth = "FM",
  classif = "glm",
  w,
  par.classif = list(),
  par.depth = list(),
  control = list(verbose = FALSE, draw = TRUE, col = NULL, alpha = 0.25)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classif.DD_+3A_group">group</code></td>
<td>
<p>Factor of length <em>n</em> with <em>g</em> levels.</p>
</td></tr>
<tr><td><code id="classif.DD_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="base.html#topic+data.frame">data.frame</a></code>, <code><a href="#topic+fdata">fdata</a></code> or <code>list</code>
with the multivariate, functional or both covariates respectively.</p>
</td></tr>
<tr><td><code id="classif.DD_+3A_depth">depth</code></td>
<td>
<p>Character vector specifying the type of depth functions to use,
see <code>Details</code>.</p>
</td></tr>
<tr><td><code id="classif.DD_+3A_classif">classif</code></td>
<td>
<p>Character vector specifying the type of classifier method to
use, see <code>Details</code>.</p>
</td></tr>
<tr><td><code id="classif.DD_+3A_w">w</code></td>
<td>
<p>Optional case weights, weights for each value of <code>depth</code>
argument, see <code>Details</code>.</p>
</td></tr>
<tr><td><code id="classif.DD_+3A_par.classif">par.classif</code></td>
<td>
<p>List of parameters for <code>classif</code> procedure.</p>
</td></tr>
<tr><td><code id="classif.DD_+3A_par.depth">par.depth</code></td>
<td>
<p>List of parameters for <code>depth</code> function.</p>
</td></tr>
<tr><td><code id="classif.DD_+3A_control">control</code></td>
<td>
<p>List of parameters for controlling the process.
</p>
<p>If <code>verbose=TRUE</code>, report extra information on progress.
</p>
<p>If <code>draw=TRUE</code> print DD-plot of two samples based on data depth.
</p>
<p><code>col</code>, the colors for points in DD&ndash;plot.
</p>
<p><code>alpha</code>, the alpha transparency used in the background of DD&ndash;plot, a
number in [0,1].</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Make the group classification of a training dataset using DD-classifier
estimation in the following steps.<br />
</p>
 
<ol>
<li><p> The function computes the selected <code>depth</code> measure of
the points in <code>fdataobj</code> w.r.t. a subsample of each g level group and p
data dimension (<code class="reqn">G=g \times p</code>).  The user can be specify the
parameters for depth function in <code>par.depth</code>.
</p>
<p>(i) Type of depth function from functional data, see <code><a href="#topic+Depth">Depth</a></code>:
</p>
 
<ul>
<li> <p><code>"FM"</code>: Fraiman and Muniz depth.
</p>
</li>
<li> <p><code>"mode"</code>: h-modal depth.
</p>
</li>
<li> <p><code>"RT"</code>: Random Tukey depth.
</p>
</li>
<li> <p><code>"RP"</code>: Random projection depth.
</p>
</li>
<li> <p><code>"RPD"</code>: Double random projection depth.
</p>
</li></ul>

<p>(ii) Type of depth function from multivariate functional data, see <code><a href="#topic+depth.mfdata">depth.mfdata</a></code>:
</p>
 
<ul>
<li> <p><code>"FMp"</code>: Fraiman and Muniz depth with common support. 
Suppose that all p-fdata objects have the same support (same rangevals); 
see <code><a href="#topic+depth.FMp">depth.FMp</a></code>.
</p>
</li>
<li> <p><code>"modep"</code>: h-modal depth using a p-dimensional metric; 
see <code><a href="#topic+depth.modep">depth.modep</a></code>.
</p>
</li>
<li> <p><code>"RPp"</code>: Random projection depth using a p-variate depth 
with the projections; see <code><a href="#topic+depth.RPp">depth.RPp</a></code>.
</p>
</li></ul>

<p>If the procedure requires to compute a distance such as in <code>"knn"</code> or <code>"np"</code> classifier or
<code>"mode"</code> depth, the user must use a proper distance function:
<code><a href="#topic+metric.lp">metric.lp</a></code> for functional data and <code><a href="#topic+metric.dist">metric.dist</a></code>
for multivariate data.
</p>
<p>(iii) Type of depth function from multivariate data, see
<code><a href="#topic+Depth.Multivariate">Depth.Multivariate</a></code>: 
</p>
 
<ul>
<li> <p><code>"SD"</code>: Simplicial depth (for bivariate data).
</p>
</li>
<li> <p><code>"HS"</code>: Half-space depth.
</p>
</li>
<li> <p><code>"MhD"</code>: Mahalanobis depth.
</p>
</li>
<li> <p><code>"RD"</code>: Random projections depth.
</p>
</li>
<li> <p><code>"LD"</code>: Likelihood depth.
</p>
</li></ul>

</li>
<li><p> The function calculates the misclassification rate based on data depth
computed in step (1) using the following classifiers.
</p>
 
<ul>
<li> <p><code>"MaxD"</code>: Maximum depth.
</p>
</li>
<li> <p><code>"DD1"</code>: Search for the best separating polynomial of degree 1.
</p>
</li>
<li> <p><code>"DD2"</code>: Search for the best separating polynomial of degree 2.
</p>
</li>
<li> <p><code>"DD3"</code>: Search for the best separating polynomial of degree 3.
</p>
</li>
<li> <p><code>"glm"</code>: Logistic regression computed using Generalized Linear Models; 
see <code><a href="#topic+classif.glm">classif.glm</a></code>.
</p>
</li>
<li> <p><code>"gam"</code>: Logistic regression computed using Generalized Additive Models; 
see <code><a href="#topic+classif.gsam">classif.gsam</a></code>.
</p>
</li>
<li> <p><code>"lda"</code>: Linear Discriminant Analysis computed using <a href="MASS.html#topic+lda">lda</a>. 
</p>
</li>
<li> <p><code>"qda"</code>: Quadratic Discriminant Analysis computed using <a href="MASS.html#topic+qda">qda</a>.
</p>
</li>
<li> <p><code>"knn"</code>: k-Nearest Neighbour classification computed using 
<code><a href="#topic+classif.knn">classif.knn</a></code>.
</p>
</li>
<li> <p><code>"np"</code>: Non-parametric Kernel classifier computed using 
<code><a href="#topic+classif.np">classif.np</a></code>.
</p>
</li></ul>

<p>The user can be specify the parameters for classifier function in <code>par.classif</code> such as the smoothing parameter
<code>par.classif[["h"]]</code>, if <code>classif="np"</code> or the k-Nearest
Neighbour <code>par.classif[["knn"]]</code>, if <code>classif="knn"</code>.
</p>
<p>In the case of polynomial classifier (<code>"DD1"</code>, <code>"DD2"</code> and
<code>"DD3"</code>) uses the original procedure proposed by Li et al. (2012), by
defalut rotating the DD-plot (to exchange abscise and ordinate) using in
<code>par.classif</code> argument <code>rotate=TRUE</code>. Notice that the maximum
depth classifier can be considered as a particular case of DD1, fixing the
slope with a value of 1 (<code>par.classif=list(pol=1)</code>).
</p>
<p>The number of possible different polynomials depends on the sample size
<code>n</code> and increases polynomially with order <code class="reqn">k</code>. In the case of
<code class="reqn">g</code> groups, so the procedure applies some multiple-start optimization
scheme to save time:
</p>
 
<ul>
<li><p> Generate all combinations of the elements of \( n \) taken \( k \) at a time: 
<code class="reqn">g \times combn(N,k)</code> candidate solutions. When this number 
exceeds <code>nmax=10000</code>, a random sample of <code>10000</code> combinations is selected.
</p>
</li>
<li><p> Smooth the empirical loss with the logistic function: 
<code class="reqn">1/(1+e^{-tx})</code>. The classification rule is constructed by 
optimizing the best <code>noptim</code> combinations in this random sample (by default, 
<code>noptim=1</code> and <code>tt=50/range(depth values)</code>). Note that Li et al. found 
that the optimization results become stable for 
<code class="reqn">t \in [50, 200]</code> when the depth is standardized 
with an upper bound of 1.  
</p>
</li></ul>

<p>The original procedure (Li et al. (2012)) not need to
try many initial polynomials (<code>nmax=1000</code>) and that the procedure
optimize the best (<code>noptim=1</code>), but we recommended to repeat the last
step for different solutions, as for example <code>nmax=250</code> and
<code>noptim=25</code>. User can change the parameters <code>pol</code>, <code>rotate</code>,
<code>nmax</code>, <code>noptim</code> and <code>tt</code> in the argument <code>par.classif</code>.
</p>
<p>The <code>classif.DD</code> procedure extends to multi-class problems by
incorporating the method of <em>majority voting</em> in the case of polynomial
classifier and the method <em>One vs the Rest</em> in the logistic case
(<code>"glm"</code> and <code>"gam"</code>).
</p>
</li></ol>



<h3>Value</h3>


<ul>
<li> <p><code>group.est</code>: Estimated vector groups by classified method selected.
</p>
</li>
<li> <p><code>misclassification</code>:  Probability of misclassification.
</p>
</li>
<li> <p><code>prob.classification</code>:  Probability of correct classification by group level.
</p>
</li>
<li> <p><code>dep</code>:  Data frame with the depth of the curves for functional data (or points for multivariate data) in
<code>fdataobj</code> w.r.t. each <code>group</code> level.
</p>
</li>
<li> <p><code>depth</code>:  Character vector specifying the type of depth functions used.
</p>
</li>
<li> <p><code>par.depth</code>:  List of parameters for <code>depth</code> function.
</p>
</li>
<li> <p><code>classif</code>:  Type of classifier used.
</p>
</li>
<li> <p><code>par.classif</code>:  List of parameters for <code>classif</code> procedure.
</p>
</li>
<li> <p><code>w</code>:  Optional case weights.
</p>
</li>
<li> <p><code>fit</code>: Fitted object by <code>classif</code> method using the depth as covariate.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>This version was created by Manuel Oviedo de la Fuente and Manuel
Febrero Bande and includes the original version for polynomial classifier
created by Jun Li, Juan A. Cuesta-Albertos and Regina Y. Liu.
</p>


<h3>References</h3>

<p>Cuesta-Albertos, J.A., Febrero-Bande, M. and Oviedo de la Fuente, M.
<em>The DDG-classifier in the functional setting</em>, (2017). Test, 26(1),
119-142. DOI: <a href="https://doi.org/10.1007/s11749-016-0502-6">doi:10.1007/s11749-016-0502-6</a>.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+predict.classif.DD">predict.classif.DD</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# DD-classif for functional data
data(tecator)
ab &lt;- tecator$absorp.fdata
ab1 &lt;- fdata.deriv(ab, nderiv = 1)
ab2 &lt;- fdata.deriv(ab, nderiv = 2)
gfat &lt;- factor(as.numeric(tecator$y$Fat&gt;=15))

# DD-classif for p=1 functional  data set
out01 &lt;- classif.DD(gfat,ab,depth="mode",classif="np")
out02 &lt;- classif.DD(gfat,ab2,depth="mode",classif="np")
# DD-plot in gray scale
ctrl &lt;- list(draw=T,col=gray(c(0,.5)),alpha=.2)
out02bis &lt;- classif.DD(gfat,ab2,depth="mode",classif="np",control=ctrl)

# 2 depth functions (same curves) 
ldat &lt;- mfdata("ab" = ab, "ab2" = ab2)
out03 &lt;- classif.DD(gfat,list(ab2,ab2),depth=c("RP","mode"),classif="np")
# DD-classif for p=2 functional data set
# Weighted version 
out04 &lt;- classif.DD(gfat, ldat, depth="mode",
                    classif="np", w=c(0.5,0.5))
# Model version
out05 &lt;- classif.DD(gfat,ldat,depth="mode",classif="np")
# Integrated version (for multivariate functional data)
out06 &lt;- classif.DD(gfat,ldat,depth="modep",classif="np")

# DD-classif for multivariate data
data(iris)
group &lt;- iris[,5]
x &lt;- iris[,1:4]
out07 &lt;- classif.DD(group,x,depth="LD",classif="lda")
summary(out07)
out08 &lt;- classif.DD(group, list(x,x), depth=c("MhD","LD"),
                    classif="lda")
summary(out08)

# DD-classif for functional data: g levels 
data(phoneme)
mlearn &lt;- phoneme[["learn"]]
glearn &lt;- as.numeric(phoneme[["classlearn"]])-1
out09 &lt;- classif.DD(glearn,mlearn,depth="FM",classif="glm")
out10 &lt;- classif.DD(glearn,list(mlearn,mlearn),depth=c("FM","RP"),classif="glm")
summary(out09)
summary(out10)

## End(Not run)
</code></pre>

<hr>
<h2 id='classif.depth'>Classifier from Functional Data</h2><span id='topic+classif.depth'></span>

<h3>Description</h3>

<p>Classification of functional data using maximum depth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classif.depth(
  group,
  fdataobj,
  newfdataobj,
  depth = "RP",
  par.depth = list(),
  CV = "none"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classif.depth_+3A_group">group</code></td>
<td>
<p>Factor of length <em>n</em></p>
</td></tr>
<tr><td><code id="classif.depth_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code>fdata</code>, <code>matrix</code> or <code>data.frame</code> class
object of train data.</p>
</td></tr>
<tr><td><code id="classif.depth_+3A_newfdataobj">newfdataobj</code></td>
<td>
<p><code>fdata</code>, <code>matrix</code> or <code>data.frame</code> class
object of test data.</p>
</td></tr>
<tr><td><code id="classif.depth_+3A_depth">depth</code></td>
<td>
<p>Type of depth function from functional data:
</p>
 
<ul>
<li> <p><code>FM</code>: Fraiman and Muniz depth.
</p>
</li>
<li> <p><code>mode</code>: Modal depth.
</p>
</li>
<li> <p><code>RT</code>: Random Tukey depth.
</p>
</li>
<li> <p><code>RP</code>: Random project depth.
</p>
</li>
<li> <p><code>RPD</code>: Double random project depth.
</p>
</li></ul>
</td></tr>
<tr><td><code id="classif.depth_+3A_par.depth">par.depth</code></td>
<td>
<p>List of parameters for <code>depth</code>.</p>
</td></tr>
<tr><td><code id="classif.depth_+3A_cv">CV</code></td>
<td>
<p>=&ldquo;none&rdquo; <code>group.est=group.pred</code>, =TRUE <code>group.est</code> is
estimated by cross-validation, =FALSE <code>group.est</code> is estimated.</p>
</td></tr>
</table>


<h3>Value</h3>

 
<ul>
<li> <p><code>group.est</code>: Vector of classes of train sample data.
</p>
</li>
<li> <p><code>group.pred</code>: Vector of classes of test sample data.
</p>
</li>
<li> <p><code>prob.classification</code>: Probability of correct classification by group.
</p>
</li>
<li> <p><code>max.prob</code>: Highest probability of correct classification.
</p>
</li>
<li> <p><code>fdataobj</code>: <code><a href="#topic+fdata">fdata</a></code> class object.
</p>
</li>
<li> <p><code>group</code>: Factor of length <em>n</em>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Febrero-Bande, M. and Oviedo de la Fuente, M.
</p>


<h3>References</h3>

<p>Cuevas, A., Febrero-Bande, M. and Fraiman, R. (2007).
<em>Robust estimation and classification for functional data via
projection-based depth notions.</em> Computational Statistics 22, 3, 481-496.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
mlearn&lt;-phoneme[["learn"]]
mtest&lt;-phoneme[["test"]]
glearn&lt;-phoneme[["classlearn"]]
gtest&lt;-phoneme[["classtest"]]

a1&lt;-classif.depth(glearn,mlearn,depth="RP")
table(a1$group.est,glearn)
a2&lt;-classif.depth(glearn,mlearn,depth="RP",CV=TRUE)
a3&lt;-classif.depth(glearn,mlearn,depth="RP",CV=FALSE)
a4&lt;-classif.depth(glearn,mlearn,mtest,"RP")
a5&lt;-classif.depth(glearn,mlearn,mtest,"RP",CV=TRUE)     
table(a5$group.est,glearn)
a6&lt;-classif.depth(glearn,mlearn,mtest,"RP",CV=FALSE)
table(a6$group.est,glearn)

## End(Not run)

</code></pre>

<hr>
<h2 id='classif.gkam'>Classification Fitting Functional Generalized Kernel Additive Models</h2><span id='topic+classif.gkam'></span>

<h3>Description</h3>

<p>Computes functional classification using functional explanatory variables
using backfitting algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classif.gkam(
  formula,
  data,
  weights = "equal",
  family = binomial(),
  par.metric = NULL,
  par.np = NULL,
  offset = NULL,
  prob = 0.5,
  type = "1vsall",
  control = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classif.gkam_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
procedure only considers functional covariates (not implemented for
non-functional covariates). The details of model specification are given
under <code>Details</code>.</p>
</td></tr>
<tr><td><code id="classif.gkam_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td></tr>
<tr><td><code id="classif.gkam_+3A_weights">weights</code></td>
<td>
<p>Weights:
</p>

<ul>
<li><p> if <code>character</code> string <code>='equal'</code> same weights for each observation (by default) and
<code>='inverse'</code> for inverse-probability of weighting.   
</p>
</li>
<li><p> if <code>numeric</code> vector of length <code>n</code>, Weight values of each observation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="classif.gkam_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)</p>
</td></tr>
<tr><td><code id="classif.gkam_+3A_par.metric">par.metric</code></td>
<td>
<p>List of arguments by covariable to pass to the
<code>metric</code> function by covariable.</p>
</td></tr>
<tr><td><code id="classif.gkam_+3A_par.np">par.np</code></td>
<td>
<p>List of arguments to pass to the <code>fregre.np.cv</code> function</p>
</td></tr>
<tr><td><code id="classif.gkam_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component to be
included in the linear predictor during fitting.</p>
</td></tr>
<tr><td><code id="classif.gkam_+3A_prob">prob</code></td>
<td>
<p>probability value used for binary discriminant.</p>
</td></tr>
<tr><td><code id="classif.gkam_+3A_type">type</code></td>
<td>
<p>If type is<code>"1vsall"</code>  (by default) 
a maximum probability scheme is applied: requires G binary classifiers.
If type is <code>"majority"</code>  (only for multicalss classification G &gt; 2) 
a voting scheme is applied: requires  G (G - 1) / 2 binary classifiers.</p>
</td></tr>
<tr><td><code id="classif.gkam_+3A_control">control</code></td>
<td>
<p>a list of parameters for controlling the fitting process, by
default: maxit, epsilon, trace and inverse.</p>
</td></tr>
<tr><td><code id="classif.gkam_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first item in the <code>data</code> list is called <em>&quot;df&quot;</em> and is a data
frame with the response, as <code><a href="stats.html#topic+glm">glm</a></code>.<br /> Functional covariates of
class <code>fdata</code> are introduced in the following items in the <code>data</code>
list.
</p>


<h3>Value</h3>

<p>Return <code>gam</code> object plus:
</p>

<ul>
<li> <p><code>formula</code>: formula.
</p>
</li>
<li> <p><code>data</code>: List that containing the variables in the model.
</p>
</li>
<li> <p><code>group</code>: Factor of length <em>n</em>.
</p>
</li>
<li> <p><code>group.est</code>: Estimated vector groups.
</p>
</li>
<li> <p><code>prob.classification</code>: Probability of correct classification by group.
</p>
</li>
<li> <p><code>prob.group</code>: Matrix of predicted class probabilities. For each
functional point shows the probability of each possible group membership.
</p>
</li>
<li> <p><code>max.prob</code>: Highest probability of correct classification.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande M. and Gonzalez-Manteiga W. (2012).
<em>Generalized Additive Models for Functional Data</em>. TEST.
Springer-Velag.  <a href="https://doi.org/10.1007/s11749-012-0308-0">doi:10.1007/s11749-012-0308-0</a>
</p>
<p>McCullagh and Nelder (1989), <em>Generalized Linear Models</em> 2nd ed.
Chapman and Hall.
</p>
<p>Opsomer J.D. and Ruppert D.(1997). <em>Fitting a bivariate additive model
by local polynomial regression</em>.Annals of Statistics, <code>25</code>, 186-211.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.gkam">fregre.gkam</a></code>.<br /> Alternative method:
<code><a href="#topic+classif.glm">classif.glm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
## Time-consuming: selection of 2 levels 
data(phoneme)
mlearn&lt;-phoneme[["learn"]][1:150]
glearn&lt;-factor(phoneme[["classlearn"]][1:150])
dataf&lt;-data.frame(glearn)
dat=list("df"=dataf,"x"=mlearn)
a1&lt;-classif.gkam(glearn~x,data=dat)
summary(a1)
mtest&lt;-phoneme[["test"]][1:150]
gtest&lt;-factor(phoneme[["classtest"]][1:150])
newdat&lt;-list("x"=mtest)
p1&lt;-predict(a1,newdat)
table(gtest,p1)

## End(Not run)  
</code></pre>

<hr>
<h2 id='classif.glm'>Classification Fitting Functional Generalized Linear Models</h2><span id='topic+classif.glm'></span>

<h3>Description</h3>

<p>Computes functional classification using functional (and non functional)
explanatory variables by basis representation.
</p>
<p>The first item in the <code>data</code> list is called <em>&quot;df&quot;</em> and is a data
frame with the response and non functional explanatory variables, as
<code><a href="stats.html#topic+glm">glm</a></code>.<br />
</p>
<p>Functional covariates of class <code>fdata</code> or <code>fd</code> are introduced in
the following items in the <code>data</code> list.<br /> <code>basis.x</code> is a list of
basis for represent each functional covariate. The basis object can be
created by the function: <code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <a href="fda.html#topic+pca.fd">pca.fd</a>
<code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <code><a href="#topic+create.fdata.basis">create.fdata.basis</a></code> o
<a href="fda.html#topic+create.basis">create.basis</a>.<br /> <code>basis.b</code> is a list of basis for
represent each functional beta parameter. If <code>basis.x</code> is a list of
functional principal components basis (see <code><a href="#topic+create.pc.basis">create.pc.basis</a></code> or
<a href="fda.html#topic+pca.fd">pca.fd</a>) the argument <code>basis.b</code> is ignored.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classif.glm(
  formula,
  data,
  family = binomial(),
  weights = "equal",
  basis.x = NULL,
  basis.b = NULL,
  type = "1vsall",
  prob = 0.5,
  CV = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classif.glm_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
details of model specification are given under <code>Details</code>.</p>
</td></tr>
<tr><td><code id="classif.glm_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td></tr>
<tr><td><code id="classif.glm_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions).</p>
</td></tr>
<tr><td><code id="classif.glm_+3A_weights">weights</code></td>
<td>
<p>Weights:
</p>

<ul>
<li><p> if <code>character</code> string <code>='equal'</code> same weights for each observation (by default) and
<code>='inverse'</code> for inverse-probability of weighting.   
</p>
</li>
<li><p> if <code>numeric</code> vector of length <code>n</code>, Weight values of each observation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="classif.glm_+3A_basis.x">basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td></tr>
<tr><td><code id="classif.glm_+3A_basis.b">basis.b</code></td>
<td>
<p>List of basis for functional beta parameter estimation.</p>
</td></tr>
<tr><td><code id="classif.glm_+3A_type">type</code></td>
<td>
<p>If type is<code>"1vsall"</code>  (by default) 
a maximum probability scheme is applied: requires G binary classifiers.
If type is <code>"majority"</code>  (only for multicalss classification G &gt; 2) 
a voting scheme is applied: requires  G (G - 1) / 2 binary classifiers.</p>
</td></tr>
<tr><td><code id="classif.glm_+3A_prob">prob</code></td>
<td>
<p>probability value used for binari discriminant.</p>
</td></tr>
<tr><td><code id="classif.glm_+3A_cv">CV</code></td>
<td>
<p>=TRUE, Cross-validation (CV) is done.</p>
</td></tr>
<tr><td><code id="classif.glm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return <code>glm</code> object plus:
</p>

<ul>
<li><p><code>formula</code>: formula.
</p>
</li>
<li><p><code>data</code>: List that containing the variables in the model. 
</p>
</li>
<li><p><code>group</code>: Factor of length <em>n</em>. 
</p>
</li>
<li><p><code>group.est</code>: Estimated vector groups.
</p>
</li>
<li><p><code>prob.classification</code>: Probability of correct classification by group.
</p>
</li>
<li><p><code>prob.group</code>: Matrix of predicted class probabilities. For each
functional point shows the probability of each possible group membership.
</p>
</li>
<li><p><code>max.prob</code>: Highest probability of correct classification.
</p>
</li></ul>



<h3>Note</h3>

<p>If the formula only contains a non functional explanatory variables
(multivariate covariates), the function compute a standard <code><a href="stats.html#topic+glm">glm</a></code>
procedure.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em>
Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>McCullagh and Nelder (1989), <em>Generalized Linear Models</em> 2nd ed.
Chapman and Hall.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) <em>Modern Applied Statistics
with S</em>, New York: Springer.  
Regression for R. R News 1(2):20-25
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.glm">fregre.glm</a></code>.<br /> 
<code><a href="#topic+classif.gsam">classif.gsam</a></code> and <code><a href="#topic+classif.gkam">classif.gkam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
ldat &lt;- ldata("df" = data.frame(y = phoneme[["classlearn"]]),
             "x" = phoneme[["learn"]])
a1 &lt;- classif.glm(y ~ x, data = ldat)
summary(a1)
newldat &lt;- ldata("df" = data.frame(y = phoneme[["classtest"]]),
                "x" = phoneme[["test"]])
p1 &lt;- predict(a1,newldat)
table(newldat$df$y,p1)
sum(p1==newldat$df$y)/250

## End(Not run)
</code></pre>

<hr>
<h2 id='classif.gsam'>Classification Fitting Functional Generalized Additive Models</h2><span id='topic+classif.gsam'></span>

<h3>Description</h3>

<p>Computes functional classification using functional (and non functional)
explanatory variables by basis representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classif.gsam(
  formula,
  data,
  family = binomial(),
  weights = "equal",
  basis.x = NULL,
  CV = FALSE,
  prob = 0.5,
  type = "1vsall",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classif.gsam_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
details of model specification are given under <code>Details</code>.</p>
</td></tr>
<tr><td><code id="classif.gsam_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td></tr>
<tr><td><code id="classif.gsam_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)</p>
</td></tr>
<tr><td><code id="classif.gsam_+3A_weights">weights</code></td>
<td>
<p>Weights:
</p>

<ul>
<li><p> if <code>character</code> string <code>='equal'</code> same weights for each observation (by default) and
<code>='inverse'</code> for inverse-probability of weighting.   
</p>
</li>
<li><p> if <code>numeric</code> vector of length <code>n</code>, Weight values of each observation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="classif.gsam_+3A_basis.x">basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td></tr>
<tr><td><code id="classif.gsam_+3A_cv">CV</code></td>
<td>
<p>=TRUE, Cross-validation (CV) is done.</p>
</td></tr>
<tr><td><code id="classif.gsam_+3A_prob">prob</code></td>
<td>
<p>probability value used for binari discriminant.</p>
</td></tr>
<tr><td><code id="classif.gsam_+3A_type">type</code></td>
<td>
<p>If type is<code>"1vsall"</code>  (by default) 
a maximum probability scheme is applied: requires G binary classifiers.
If type is <code>"majority"</code>  (only for multicalss classification G &gt; 2) 
a voting scheme is applied: requires  G (G - 1) / 2 binary classifiers.</p>
</td></tr>
<tr><td><code id="classif.gsam_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first item in the <code>data</code> list is called <em>&quot;df&quot;</em> and is a data
frame with the response and non functional explanatory variables, as
<code><a href="stats.html#topic+glm">glm</a></code>.<br />
</p>
<p>Functional covariates of class <code>fdata</code> or <code>fd</code> are introduced in
the following items in the <code>data</code> list.<br /> <code>basis.x</code> is a list of
basis for represent each functional covariate. The basis object can be
created by the function: <code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <a href="fda.html#topic+pca.fd">pca.fd</a>
<code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <code><a href="#topic+create.fdata.basis">create.fdata.basis</a></code> o
<a href="fda.html#topic+create.basis">create.basis</a>.
</p>


<h3>Value</h3>

<p>Return <code>gam</code> object plus:
</p>

<ul>
<li> <p><code>formula</code>: formula.
</p>
</li>
<li> <p><code>data</code>: List that containing the variables in the model.
</p>
</li>
<li> <p><code>group</code>: Factor of length <em>n</em>. 
</p>
</li>
<li> <p><code>group.est</code>: Estimated vector groups
</p>
</li>
<li> <p><code>prob.classification</code>: Probability of correct classification by group.
</p>
</li>
<li> <p><code>prob.group</code>: Matrix of predicted class probabilities. For each
functional point shows the probability of each possible group membership.
</p>
</li>
<li> <p><code>max.prob</code>: Highest probability of correct classification.
</p>
</li>
<li> <p><code>type</code>: Type of classification scheme: 1 vs all  or majority voting.
</p>
</li></ul>



<h3>Note</h3>

<p>If the formula only contains a non functional explanatory variables
(multivariate covariates), the function compute a standard <code><a href="stats.html#topic+glm">glm</a></code>
procedure.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em>
Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>McCullagh and Nelder (1989), <em>Generalized Linear Models</em> 2nd ed.
Chapman and Hall.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) <em>Modern Applied Statistics
with S</em>, New York: Springer.  
Regression for R. R News 1(2):20-25
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.gsam">fregre.gsam</a></code>.<br /> Alternative method:
<code><a href="#topic+classif.np">classif.np</a></code>, <code><a href="#topic+classif.glm">classif.glm</a></code> and
<code><a href="#topic+classif.gkam">classif.gkam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
ldat &lt;- ldata("df" = data.frame(y = phoneme[["classlearn"]]),
              "x" = phoneme[["learn"]])
              classifKgroups &lt;- fda.usc:::classifKgroups
a1 &lt;- classif.gsam( y ~ s(x,k=3),data=ldat)
summary(a1)
newldat &lt;- ldata("df" = data.frame(y = phoneme[["classtest"]]),
              "x" = phoneme[["test"]])
p1 &lt;- predict(a1,newldat)
table(newldat$df$y,p1)
sum(p1==newldat$df$y)/250

## End(Not run)
</code></pre>

<hr>
<h2 id='classif.gsam.vs'>Variable Selection in Functional Data Classification</h2><span id='topic+classif.gsam.vs'></span>

<h3>Description</h3>

<p>Computes classification by selecting the functional (and non functional)
explanatory variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classif.gsam.vs(
  data = list(),
  y,
  x,
  family = binomial(),
  weights = "equal",
  basis.x = NULL,
  basis.b = NULL,
  type = "1vsall",
  prob = 0.5,
  alpha = 0.05,
  dcor.min = 0.01,
  smooth = TRUE,
  measure = "accuracy",
  xydist,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classif.gsam.vs_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model.  &quot;df&quot; element
is a  <code>data.frame</code> with the response and scalar covariates (numeric and factors
variables are allowed). Functional covariates of class <code>fdata</code> or
<code>fd</code> are introduced in the following items in the <code>data</code> list.</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_y">y</code></td>
<td>
<p><code>caracter</code> string with the name of the scalar response variable</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_x">x</code></td>
<td>
<p><code>caracter</code> string vector with the name of the scalar and functional
potential covariates.</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_weights">weights</code></td>
<td>
<p>Weights:
</p>

<ul>
<li><p> if <code>character</code> string <code>='equal'</code> same weights for each observation (by default) and
<code>='inverse'</code> for inverse-probability of weighting.   
</p>
</li>
<li><p> if <code>numeric</code> vector of length <code>n</code>, Weight values of each observation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_basis.x">basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_basis.b">basis.b</code></td>
<td>
<p>List of basis for functional beta parameter estimation.</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_type">type</code></td>
<td>
<p><code>character</code>, type of scheme classification. <code>'1vsall'</code>  (by default) 
strategy involves training a single classifier per class, with the samples of that class 
as positive samples and all other samples as negatives. Other posibility for K-way multiclass problem
is the <code>'majority'</code> voting scheme (also called one vs one). 
The procedure  trains the <code class="reqn">K (K - 1) / 2</code>  binary classifiers and predicts the final class label as the class
label that has been predicted most frequently.</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_prob">prob</code></td>
<td>
<p>probability value used for binary discriminant.</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_alpha">alpha</code></td>
<td>
<p>alpha value to test the null hypothesis for the test of
independence among covariate X and residual e. By default is <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_dcor.min">dcor.min</code></td>
<td>
<p>lower threshold for the variable X to be considered. X is
discarded if the distance correlation <code class="reqn">R(X,e)&lt; dcor.min</code> (e is the
residual).</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_smooth">smooth</code></td>
<td>
<p>if <code>TRUE</code>, a smooth estimate is made for all covariates included
in the model (less for factors). The model is adjusted with the estimated
variable linearly or smoothly. If the models are equivalent, the model is
adjusted with the linearly estimated variable.</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_measure">measure</code></td>
<td>
<p>measure related with correct classification (by default accuracy).</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_xydist">xydist</code></td>
<td>
<p>list with the matrices of distances of each variable (all
potential covariates and the response) with itself.</p>
</td></tr>
<tr><td><code id="classif.gsam.vs_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the final fitted model (same result of the classsification method) plus:<br />
</p>

<ul>
<li> <p><code>dcor</code>, <code>matrix</code> with the values of distance correlation for each
pontential covariate  (by column) and the residual of the model in each step (by row).
</p>
</li>
<li> <p><code>i.predictor</code>, <code>vector</code> with 1 if the variable is selected, 0 otherwise.
</p>
</li>
<li> <p><code>ipredictor</code>, <code>vector</code> with the name of selected variables (in order of selection)
</p>
</li></ul>



<h3>Note</h3>

<p>Adapted version from the original method in repression: <code><a href="#topic+fregre.gsam.vs">fregre.gsam.vs</a></code>.
</p>


<h3>Author(s)</h3>

<p>Febrero-Bande, M. and Oviedo de la Fuente, M.
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Gonz\'alez-Manteiga, W. and Oviedo de la
Fuente, M. Variable selection in functional additive regression models,
(2018).  Computational Statistics, 1-19. DOI:
<a href="https://doi.org/10.1007/s00180-018-0844-5">doi:10.1007/s00180-018-0844-5</a>
</p>


<h3>See Also</h3>

<p>See Also as:  <code><a href="#topic+classif.gsam">classif.gsam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x &lt;- tecator$absorp.fdata
x1 &lt;- fdata.deriv(x)
x2 &lt;- fdata.deriv(x,nderiv=2)
y &lt;- factor(ifelse(tecator$y$Fat&lt;12,0,1))
xcat0 &lt;- cut(rnorm(length(y)),4)
xcat1 &lt;- cut(tecator$y$Protein,4)
xcat2 &lt;- cut(tecator$y$Water,4)
ind &lt;- 1:129
dat    &lt;- data.frame("Fat"=y, x1$data, xcat1, xcat2)
ldat &lt;- ldata("df"=dat[ind,],"x"=x[ind,],"x1"=x1[ind,],"x2"=x2[ind,])
# 3 functionals (x,x1,x2), 3 factors (xcat0, xcat1, xcat2)
# and 100 scalars (impact poitns of x1) 

res.gam &lt;- classif.gsam(Fat~s(x),data=ldat)
summary(res.gam)

# Time consuming
res.gam.vs &lt;- classif.gsam.vs("Fat",data=ldat)
summary(res.gam.vs)
res.gam.vs$i.predictor
res.gam.vs$ipredictor

# Prediction 
newldat &lt;- ldata("df"=dat[-ind,],"x"=x[-ind,],
                "x1"=x1[-ind,],"x2"=x2[-ind,])
pred.gam &lt;- predict(res.gam,newldat)                
pred.gam.vs &lt;- predict(res.gam.vs,newldat)
cat2meas(newldat$df$Fat, pred.gam)
cat2meas(newldat$df$Fat, pred.gam.vs)

## End(Not run)
</code></pre>

<hr>
<h2 id='classif.kfold'>Functional Classification usign k-fold CV</h2><span id='topic+classif.kfold'></span>

<h3>Description</h3>

<p>Computes Functional Classification using k-fold cross-validation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classif.kfold(
  formula,
  data,
  classif = "classif.glm",
  par.classif,
  kfold = 10,
  param.kfold = NULL,
  measure = "accuracy",
  cost,
  models = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classif.kfold_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced to that class):
a symbolic description of the model to be fitted. The procedure only considers functional covariates (not implemented for non-functional covariates).</p>
</td></tr>
<tr><td><code id="classif.kfold_+3A_data">data</code></td>
<td>
<p><code>list</code>, it contains the variables in the model.</p>
</td></tr>
<tr><td><code id="classif.kfold_+3A_classif">classif</code></td>
<td>
<p>character,  name of classification method to be used in fitting the model, see <code>Details</code> section.</p>
</td></tr>
<tr><td><code id="classif.kfold_+3A_par.classif">par.classif</code></td>
<td>
<p><code>list</code> of arguments used in the classification method.</p>
</td></tr>
<tr><td><code id="classif.kfold_+3A_kfold">kfold</code></td>
<td>
<p><code>integer</code>, number of k-fold.</p>
</td></tr>
<tr><td><code id="classif.kfold_+3A_param.kfold">param.kfold</code></td>
<td>
<p><code>list</code>,  arguments related to number of k-folds for each covariate, see <code>Details</code> section.</p>
</td></tr>
<tr><td><code id="classif.kfold_+3A_measure">measure</code></td>
<td>
<p><code>character</code>, type of measure of accuracy used, see <code><a href="#topic+cat2meas">cat2meas</a></code> function.</p>
</td></tr>
<tr><td><code id="classif.kfold_+3A_cost">cost</code></td>
<td>
<p><code>numeric</code>, see <code><a href="#topic+cat2meas">cat2meas</a></code> function.</p>
</td></tr>
<tr><td><code id="classif.kfold_+3A_models">models</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, return a list of the fitted models used,  (k-fold -1) X (number of parameters)</p>
</td></tr>
<tr><td><code id="classif.kfold_+3A_verbose">verbose</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code>, print some internal results.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Parameters for k-fold cross validation:
</p>

<ol>
<li><p> Number of basis elements: 
</p>

<ul>
<li><p> Data-driven basis such as Functional Principal Componetns (PC). No implemented for PLS basis yet.
</p>
</li>
<li><p> Fixed basis (bspline, fourier, etc.).  
</p>
</li></ul>

<p>Option used in some classifiers such as <code><a href="#topic+classif.glm">classif.glm</a></code>, <code><a href="#topic+classif.gsam">classif.gsam</a></code>, <code><a href="#topic+classif.svm">classif.svm</a></code>, etc.
</p>
</li>
<li><p> Bandwidth parameter.  Option used in  non-parametric classificiation models such as  <code><a href="#topic+classif.np">classif.np</a></code> and <code><a href="#topic+classif.gkam">classif.gkam</a></code>.
</p>
</li></ol>



<h3>Value</h3>

<p>Best fitted model computed by the k-fold CV  using the method indicated 
in the <code>classif</code> argument and also returns:
</p>

<ol>
<li> <p><code>param.min</code>, value of parameter (or parameters) selected by k-fold CV. 
</p>
</li>
<li> <p><code>params.error</code>, k-fold CV error for each parameter combination. 
</p>
</li>
<li> <p><code>pred.kfold</code>, predicted response computed by k-fold CV.
</p>
</li>
<li> <p><code>model</code>, if <code>TRUE</code>, list of models for each parameter combination.
</p>
</li></ol>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)    
cutpoint &lt;- 18
tecator$y$class &lt;- factor(ifelse(tecator$y$Fat&lt;cutpoint,0,1))
table(tecator$y$class )
x &lt;- tecator[[1]]
x2 &lt;- fdata.deriv(tecator[[1]],2)
data  &lt;-   list("df"=tecator$y,x=x,x2=x2)
formula  &lt;-   formula(class~x+x2)

# ex: default excution of classifier (no k-fold CV)
classif="classif.glm"
out.default &lt;- classif.kfold(formula, data, classif = classif)
out.default
out.default$param.min
out.default$params.error
summary(out.default)

# ex: Number of PC basis elements selected by 10-fold CV
# Logistic classifier
kfold = 10
param.kfold   &lt;-   list("x"=list("pc"=c(1:8)),"x2"=list("pc"=c(1:8)))
out.kfold1   &lt;-   classif.kfold(formula, data, classif = classif,
                            kfold = kfold,param.kfold = param.kfold)
out.kfold1$param.min
min(out.kfold1$params.error)
summary(out.kfold1)

# ex: Number of PC basis elements selected by 10-fold CV
# Logistic classifier with inverse weighting
out.kfold2 &lt;- classif.kfold(formula, data, classif = classif,
                            par.classif=list("weights"="inverse"),
                            kfold = kfold,param.kfold = param.kfold)
out.kfold2$param.min
min(out.kfold2$params.error)
summary(out.kfold2)

# ex: Number of fourier  basis elements selected by 10-fold CV
# Logistic classifier 
ibase = seq(5,15,by=2)
param.kfold &lt;- list("x"=list("fourier"=ibase),
                    "x2"=list("fourier"=ibase))
out.kfold3 &lt;- classif.kfold(formula, data, classif = classif,
                            kfold = kfold,param.kfold = param.kfold)
out.kfold3$param.min
min(out.kfold3$params.error)
summary(out.kfold3)

# ex: Number of k-nearest neighbors selected by 10-fold CV
# non-parametric classifier  (only for a functional covariate)

output &lt;- classif.kfold( class ~ x, data, classif = "classif.knn",
                       param.kfold= list("x"=list("knn"=c(3,5,9,13))))
output$param.min
output$params.error

output &lt;- classif.kfold( class ~ x2, data, classif = "classif.knn",
                       param.kfold= list("x2"=list("knn"=c(3,5,9,13))))
output$param.min
output$params.error 

## End(Not run)
 
</code></pre>

<hr>
<h2 id='classif.ML'>Functional classification using ML algotithms</h2><span id='topic+classif.ML'></span><span id='topic+classif.nnet'></span><span id='topic+classif.rpart'></span><span id='topic+classif.randomForest'></span><span id='topic+classif.cv.glmnet'></span><span id='topic+classif.svm'></span><span id='topic+classif.ksvm'></span><span id='topic+classif.naiveBayes'></span><span id='topic+classif.lda'></span><span id='topic+classif.qda'></span><span id='topic+classif.multinom'></span><span id='topic+classif.gbm'></span>

<h3>Description</h3>

<p>Computes functional classification using functional (and non functional)
explanatory variables by rpart, nnet, svm or random forest model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classif.nnet(formula, data, basis.x = NULL, weights = "equal", size, ...)

classif.rpart(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.svm(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.ksvm(formula, data, basis.x = NULL, weights = "equal", ...)

classif.randomForest(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.lda(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.qda(
  formula,
  data,
  basis.x = NULL,
  weights = "equal",
  type = "1vsall",
  ...
)

classif.naiveBayes(formula, data, basis.x = NULL, laplace = 0, ...)

classif.cv.glmnet(formula, data, basis.x = NULL, weights = "equal", ...)

classif.gbm(formula, data, basis.x = NULL, weights = "equal", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classif.ML_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
details of model specification are given under <code>Details</code>.</p>
</td></tr>
<tr><td><code id="classif.ML_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td></tr>
<tr><td><code id="classif.ML_+3A_basis.x">basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td></tr>
<tr><td><code id="classif.ML_+3A_weights">weights</code></td>
<td>
<p>Weights:
</p>

<ul>
<li><p> if <code>character</code> string <code>='equal'</code> same weights for each observation (by default) and
<code>='inverse'</code> for inverse-probability of weighting.   
</p>
</li>
<li><p> if <code>numeric</code> vector of length <code>n</code>, Weight values of each observation.
</p>
</li></ul>
</td></tr>
<tr><td><code id="classif.ML_+3A_size">size</code></td>
<td>
<p>number of units in the hidden layer. Can be zero if there are skip-layer units.</p>
</td></tr>
<tr><td><code id="classif.ML_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="classif.ML_+3A_type">type</code></td>
<td>
<p>If type is<code>"1vsall"</code>  (by default) 
a maximum probability scheme is applied: requires G binary classifiers.
If type is <code>"majority"</code>  (only for multicalss classification G &gt; 2) 
a voting scheme is applied: requires  G (G - 1) / 2 binary classifiers.</p>
</td></tr>
<tr><td><code id="classif.ML_+3A_laplace">laplace</code></td>
<td>
<p>value used for Laplace smoothing (additive smoothing). Defaults to 0 (no Laplace smoothing).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The first item in the <code>data</code> list is called <em>&quot;df&quot;</em> and is a data
frame with the response and non functional explanatory variables, as
<code><a href="stats.html#topic+glm">glm</a></code>.<br />
</p>
<p>Functional covariates of class <code>fdata</code> or <code>fd</code> are introduced in
the following items in the <code>data</code> list.<br /> <code>basis.x</code> is a list of
basis for represent each functional covariate. The b object can be
created by the function: <code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <a href="fda.html#topic+pca.fd">pca.fd</a>
<code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <code><a href="#topic+create.fdata.basis">create.fdata.basis</a></code> o
<a href="fda.html#topic+create.basis">create.basis</a>.<br /> <code>basis.b</code> is a list of basis for
represent each functional beta parameter. If <code>basis.x</code> is a list of
functional principal components basis (see <code><a href="#topic+create.pc.basis">create.pc.basis</a></code> or
<a href="fda.html#topic+pca.fd">pca.fd</a>) the argument <code>basis.b</code> is ignored.
</p>


<h3>Value</h3>

<p>Return <code>classif</code> object plus:
</p>

<ul>
<li> <p><code>formula</code>: formula.
</p>
</li>
<li> <p><code>data</code>: List that containing the variables in the model.
</p>
</li>
<li> <p><code>group</code>: Factor of length <em>n</em>. 
</p>
</li>
<li> <p><code>group.est</code>: Estimated vector groups.
</p>
</li>
<li> <p><code>prob.classification</code>: Probability of correct classification by group.
</p>
</li>
<li> <p><code>prob.group</code>: Matrix of predicted class probabilities. For each
functional point shows the probability of each possible group membership.
</p>
</li>
<li> <p><code>max.prob</code>: Highest probability of correct classification.
</p>
</li>
<li><p><code>type</code>:  Type of classification scheme: 1 vs all  or majority voting.
</p>
</li>
<li> <p><code>fit</code>: list of binary classification fitted models.
</p>
</li></ul>



<h3>Note</h3>

<p>Wrapper versions for multivariate and functional classification:
</p>

<ul>
<li> <p><code>classif.lda</code>,<code>classif.qda</code>: uses <code>lda</code> and  <code>qda</code> functions and requires <code>MASS</code> package.
</p>
</li>
<li> <p><code>classif.nnet</code>: uses <code>nnet</code> function and requires <code>nnet</code> package.
</p>
</li>
<li> <p><code>classif.rpart</code>: uses <code>nnet</code> function and requires <code>rpart</code> package.
</p>
</li>
<li> <p><code>classif.svm</code>, <code>classif.naiveBayes</code>: uses <code>svm</code> and  <code>naiveBayes</code> functions and requires <code>e1071</code> package.
</p>
</li>
<li> <p><code>classif.ksvm</code>: uses <code>weighted.ksvm </code> function and requires <code>personalized</code> package.
</p>
</li>
<li> <p><code>classif.randomForest</code>: uses <code>randomForest</code> function and requires <code>randomForest</code> package.
</p>
</li>
<li> <p><code>classif.cv.glmnet</code>: uses <code>cv.glmnet</code> function and requires <code>glmnet</code> package.
</p>
</li>
<li> <p><code>classif.gbm</code>: uses <code>gbm</code> function and requires <code>gbm</code> package.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Febrero-Bande, M. and Oviedo de la Fuente, M.
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), 
<em>Functional Data Analysis</em>, 2nd ed., Springer, New York. 
</p>
<p>McCullagh and Nelder (1989), <em>Generalized Linear Models</em> 2nd ed. Chapman and Hall.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) <em>Modern Applied Statistics
with S</em>, New York: Springer.  
Regression for R. R News 1(2):20-25
</p>


<h3>See Also</h3>

<p>See Also as: <a href="rpart.html#topic+rpart">rpart</a>.<br /> Alternative method:
<code><a href="#topic+classif.np">classif.np</a></code>, <code><a href="#topic+classif.glm">classif.glm</a></code>,
<code><a href="#topic+classif.gsam">classif.gsam</a></code> and <code><a href="#topic+classif.gkam">classif.gkam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
mlearn&lt;-phoneme[["learn"]]
glearn&lt;-phoneme[["classlearn"]]
mtest&lt;-phoneme[["test"]]
gtest&lt;-phoneme[["classtest"]]
dataf&lt;-data.frame(glearn)
dat=ldata("df"=dataf,"x"=mlearn)
a1&lt;-classif.rpart(glearn~x,data=dat)
a2&lt;-classif.nnet(glearn~x,data=dat)
a3&lt;-classif.gbm(glearn~x,data=dat)
a4&lt;-classif.randomForest(glearn~x,data=dat)
a5&lt;-classif.cv.glmnet(glearn~x,data=dat)
newdat&lt;-list("x"=mtest)
p1&lt;-predict(a1,newdat,type="class")
p2&lt;-predict(a2,newdat,type="class")
p3&lt;-predict(a3,newdat,type="class")
p4&lt;-predict(a4,newdat,type="class")
p5&lt;-predict(a5,newdat,type="class")
mean(p1==gtest);mean(p2==gtest);mean(p3==gtest)
mean(p4==gtest);mean(p5==gtest)

## End(Not run)

</code></pre>

<hr>
<h2 id='classif.np'>Kernel Classifier from Functional Data</h2><span id='topic+classif.np'></span><span id='topic+classif.kernel'></span><span id='topic+classif.knn'></span>

<h3>Description</h3>

<p>Fits Nonparametric Supervised Classification for Functional Data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classif.np(
  group,
  fdataobj,
  h = NULL,
  Ker = AKer.norm,
  metric,
  weights = "equal",
  type.S = S.NW,
  par.S = list(),
  ...
)

classif.knn(
  group,
  fdataobj,
  knn = NULL,
  metric,
  weights = "equal",
  par.S = list(),
  ...
)

classif.kernel(
  group,
  fdataobj,
  h = NULL,
  Ker = AKer.norm,
  metric,
  weights = "equal",
  par.S = list(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="classif.np_+3A_group">group</code></td>
<td>
<p>Factor of length <em>n</em></p>
</td></tr>
<tr><td><code id="classif.np_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="classif.np_+3A_h">h</code></td>
<td>
<p>Vector of smoothing parameter or bandwidth.</p>
</td></tr>
<tr><td><code id="classif.np_+3A_ker">Ker</code></td>
<td>
<p>Type of kernel used.</p>
</td></tr>
<tr><td><code id="classif.np_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="classif.np_+3A_weights">weights</code></td>
<td>
<p>weights.</p>
</td></tr>
<tr><td><code id="classif.np_+3A_type.s">type.S</code></td>
<td>
<p>Type of smothing matrix <code>S</code>. By default <code>S</code> is
calculated by Nadaraya-Watson kernel estimator (<code>S.NW</code>).</p>
</td></tr>
<tr><td><code id="classif.np_+3A_par.s">par.S</code></td>
<td>
<p>List of parameters for <code>type.S</code>: <code>w</code>, the weights.</p>
</td></tr>
<tr><td><code id="classif.np_+3A_...">...</code></td>
<td>
<p>Arguments to be passed for <code><a href="#topic+metric.lp">metric.lp</a></code> o other
metric function and <code><a href="#topic+Kernel">Kernel</a></code> function.</p>
</td></tr>
<tr><td><code id="classif.np_+3A_knn">knn</code></td>
<td>
<p>Vector of number of nearest neighbors considered.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Make the group classification of a training dataset using kernel or KNN
estimation: <code><a href="#topic+Kernel">Kernel</a></code>.
</p>
<p>Different types of metric funtions can be used.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>fdataobj</code>: <code><a href="#topic+fdata">fdata</a></code> class object.
</p>
</li>
<li> <p><code>group</code>: Factor of length <code>n</code>.
</p>
</li>
<li> <p><code>group.est</code>: Estimated vector groups.
</p>
</li>
<li> <p><code>prob.group</code>: Matrix of predicted class probabilities. For each functional point shows the probability of each possible group membership.
</p>
</li>
<li> <p><code>max.prob</code>: Highest probability of correct classification.
</p>
</li>
<li> <p><code>h.opt</code>: Optimal smoothing parameter or bandwidht estimated.
</p>
</li>
<li> <p><code>D</code>: Matrix of distances of the optimal quantile distance <code>hh.opt</code>.
</p>
</li>
<li> <p><code>prob.classification</code>: Probability of correct classification by group.
</p>
</li>
<li> <p><code>misclassification</code>: Vector of probability of misclassification by number of neighbors <code>knn</code>.
</p>
</li>
<li> <p><code>h</code>: Vector of smoothing parameter or bandwidht.
</p>
</li>
<li> <p><code>C</code>: A call of function <code>classif.kernel</code>.
</p>
</li></ul>



<h3>Note</h3>

<p>If <code>fdataobj</code> is a data.frame the function considers the case of
multivariate covariates. <br /> <code><a href="#topic+metric.dist">metric.dist</a></code> function is used to
compute the distances between the rows of a data matrix (as
<code><a href="stats.html#topic+dist">dist</a></code> function.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>
<p>Ferraty, F. and Vieu, P. (2006). <em>NPFDA in practice</em>. Free access on
line at <a href="https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/">https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+predict.classif">predict.classif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
mlearn &lt;- phoneme[["learn"]]
glearn &lt;- phoneme[["classlearn"]]
h &lt;- 9:19
out &lt;- classif.np(glearn,mlearn,h=h)
summary(out)
head(round(out$prob.group,4))

## End(Not run)

</code></pre>

<hr>
<h2 id='cond.F'>Conditional Distribution Function</h2><span id='topic+cond.F'></span>

<h3>Description</h3>

<p>Calculate the conditional distribution function of a scalar response with
functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cond.F(
  fdata0,
  y0,
  fdataobj,
  y,
  h = 0.15,
  g = 0.15,
  metric = metric.lp,
  Ker = list(AKer = AKer.epa, IKer = IKer.epa),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cond.F_+3A_fdata0">fdata0</code></td>
<td>
<p>Conditional explanatory functional data of <code><a href="#topic+fdata">fdata</a></code>
class.</p>
</td></tr>
<tr><td><code id="cond.F_+3A_y0">y0</code></td>
<td>
<p>Vector of conditional response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="cond.F_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="cond.F_+3A_y">y</code></td>
<td>
<p>Vector of scalar response with length <code>nn</code>.</p>
</td></tr>
<tr><td><code id="cond.F_+3A_h">h</code></td>
<td>
<p>Smoothing parameter or bandwidth of response <code>y</code>.</p>
</td></tr>
<tr><td><code id="cond.F_+3A_g">g</code></td>
<td>
<p>Smoothing parameter or bandwidth of explanatory functional data
<code>fdataobj</code>.</p>
</td></tr>
<tr><td><code id="cond.F_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="cond.F_+3A_ker">Ker</code></td>
<td>
<p>List of 2 arguments. The fist argument is a character string that
determines the type of asymetric kernel (see
<code><a href="#topic+Kernel.asymmetric">Kernel.asymmetric</a></code>). Asymmetric Epanechnikov kernel is selected
by default. The second argumentis a string that determines the type of
integrated kernel(see <code><a href="#topic+Kernel.integrate">Kernel.integrate</a></code>). Integrate
Epanechnikov kernel is selected by default.<br />.</p>
</td></tr>
<tr><td><code id="cond.F_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>x.dist=NULL</code> the distance matrix between <code>fdata</code> objects is
calculated by function passed in <code>metric</code> argument.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>Fc</code>: Conditional distribution function.
</p>
</li>
<li> <p><code>y0</code>: Vector of conditional response.
</p>
</li>
<li> <p><code>g</code>: Smoothing parameter or bandwidth of explanatory functional data (<code>fdataobj</code>).
</p>
</li>
<li> <p><code>h</code>: Smoothing parameter or bandwidth of respone, <code>y</code>.
</p>
</li>
<li> <p><code>x.dist</code>: Distance matrix between curves of <code>fdataobj</code> object.
</p>
</li>
<li> <p><code>xy.dist</code>: Distance matrix between cuves of <code>fdataobj</code> and <code>fdata0</code> objects.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+cond.mode">cond.mode</a></code> and
<code><a href="#topic+cond.quantile">cond.quantile</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read data
n= 500
t= seq(0,1,len=101)
beta = t*sin(2*pi*t)^2
x = matrix(NA, ncol=101, nrow=n)
y=numeric(n)
x0&lt;-rproc2fdata(n,seq(0,1,len=101),sigma="wiener")
x1&lt;-rproc2fdata(n,seq(0,1,len=101),sigma=0.1)
x&lt;-x0*3+x1
fbeta = fdata(beta,t)
y&lt;-inprod.fdata(x,fbeta)+rnorm(n,sd=0.1) 
prx=x[1:100];pry=y[1:100]
ind=101;ind2=102:110
pr0=x[ind];pr10=x[ind2,]
ndist=61
gridy=seq(-1.598069,1.598069, len=ndist)

# Conditional Function
res1 = cond.F(pr10, gridy, prx, pry,p=1)
res2 = cond.F(pr10, gridy, prx, pry,h=0.3)
res3 = cond.F(pr10, gridy, prx, pry,g=0.25,h=0.3)

plot(res1$Fc[,1],type="l",ylim=c(0,1))
lines(res2$Fc[,1],type="l",col=2)
lines(res3$Fc[,1],type="l",col=3)

## End(Not run)

</code></pre>

<hr>
<h2 id='cond.mode'>Conditional mode</h2><span id='topic+cond.mode'></span>

<h3>Description</h3>

<p>Computes the mode for conditional distribution function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cond.mode(Fc, method = "monoH.FC", draw = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cond.mode_+3A_fc">Fc</code></td>
<td>
<p>Object estimated by <code>cond.F</code> function.</p>
</td></tr>
<tr><td><code id="cond.mode_+3A_method">method</code></td>
<td>
<p>Specifies the type of spline to be used. Possible values are
<em>&quot;diff&quot;</em>, <em>&quot;fmm&quot;</em>, <em>&quot;natural&quot;</em>, <em>&quot;periodic&quot;</em> and
<em>&quot;monoH.FC&quot;</em>.</p>
</td></tr>
<tr><td><code id="cond.mode_+3A_draw">draw</code></td>
<td>
<p>=TRUE, plots the conditional distribution and density function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The conditional mode is calculated as the maximum argument of the derivative
of the conditional distribution function (density function <code>f</code>).
</p>


<h3>Value</h3>

<p>Return the mode for conditional distribution function.
</p>
 
<ul>
<li> <p><code>mode.cond</code>: Conditional mode.
</p>
</li>
<li> <p><code>x</code>: A grid of length <code>n</code> where the conditional density function is evaluated.
</p>
</li>
<li> <p><code>f</code>: The conditional density function evaluated at <code>x</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+cond.F">cond.F</a></code>, <code><a href="#topic+cond.quantile">cond.quantile</a></code> and
<a href="stats.html#topic+splinefun">splinefun</a> .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
n= 500
t= seq(0,1,len=101)
beta = t*sin(2*pi*t)^2
x = matrix(NA, ncol=101, nrow=n)
y=numeric(n)
x0&lt;-rproc2fdata(n,seq(0,1,len=101),sigma="wiener")
x1&lt;-rproc2fdata(n,seq(0,1,len=101),sigma=0.1)
x&lt;-x0*3+x1
fbeta = fdata(beta,t)
y&lt;-inprod.fdata(x,fbeta)+rnorm(n,sd=0.1)
prx=x[1:100];pry=y[1:100]
ind=101;ind2=101:110
pr0=x[ind];pr10=x[ind2]
ndist=161
gridy=seq(-1.598069,1.598069, len=ndist)
# Conditional Function
I=5
# Time consuming
res = cond.F(pr10[I], gridy, prx, pry, h=1)
mcond=cond.mode(res)
mcond2=cond.mode(res,method="diff")

## End(Not run)

</code></pre>

<hr>
<h2 id='cond.quantile'>Conditional quantile</h2><span id='topic+cond.quantile'></span>

<h3>Description</h3>

<p>Computes the quantile for conditional distribution function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cond.quantile(
  qua = 0.5,
  fdata0,
  fdataobj,
  y,
  fn,
  a = min(y),
  b = max(y),
  tol = 10^floor(log10(max(y) - min(y)) - 3),
  iter.max = 100,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cond.quantile_+3A_qua">qua</code></td>
<td>
<p>Quantile value, by default the median (<code>qua</code>=0.5).</p>
</td></tr>
<tr><td><code id="cond.quantile_+3A_fdata0">fdata0</code></td>
<td>
<p>Conditional functional explanatory data of <code><a href="#topic+fdata">fdata</a></code>
class object.</p>
</td></tr>
<tr><td><code id="cond.quantile_+3A_fdataobj">fdataobj</code></td>
<td>
<p>Functional explanatory data of <code><a href="#topic+fdata">fdata</a></code> class
object.</p>
</td></tr>
<tr><td><code id="cond.quantile_+3A_y">y</code></td>
<td>
<p>Scalar Response.</p>
</td></tr>
<tr><td><code id="cond.quantile_+3A_fn">fn</code></td>
<td>
<p>Conditional distribution function.</p>
</td></tr>
<tr><td><code id="cond.quantile_+3A_a">a</code></td>
<td>
<p>Lower limit.</p>
</td></tr>
<tr><td><code id="cond.quantile_+3A_b">b</code></td>
<td>
<p>Upper limit.</p>
</td></tr>
<tr><td><code id="cond.quantile_+3A_tol">tol</code></td>
<td>
<p>Tolerance.</p>
</td></tr>
<tr><td><code id="cond.quantile_+3A_iter.max">iter.max</code></td>
<td>
<p>Maximum iterations allowed, by default <code>100</code>.</p>
</td></tr>
<tr><td><code id="cond.quantile_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the quantile for conditional distribution function.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+cond.F">cond.F</a></code> and <code><a href="#topic+cond.mode">cond.mode</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
n= 100
t= seq(0,1,len=101)
beta = t*sin(2*pi*t)^2
x = matrix(NA, ncol=101, nrow=n)
y=numeric(n)
x0&lt;-rproc2fdata(n,seq(0,1,len=101),sigma="wiener")
x1&lt;-rproc2fdata(n,seq(0,1,len=101),sigma=0.1)
x&lt;-x0*3+x1
fbeta = fdata(beta,t)
y&lt;-inprod.fdata(x,fbeta)+rnorm(n,sd=0.1)

prx=x[1:50];pry=y[1:50]
ind=50+1;ind2=51:60
pr0=x[ind];pr10=x[ind2]
ndist=161
gridy=seq(-1.598069,1.598069, len=ndist)
ind4=5
y0 = gridy[ind4]

# Conditional median
med=cond.quantile(qua=0.5,fdata0=pr0,fdataobj=prx,y=pry,fn=cond.F,h=1)

# Conditional CI 95% conditional
lo=cond.quantile(qua=0.025,fdata0=pr0,fdataobj=prx,y=pry,fn=cond.F,h=1)
up=cond.quantile(qua=0.975,fdata0=pr0,fdataobj=prx,y=pry,fn=cond.F,h=1)
print(c(lo,med,up))

## End(Not run)

</code></pre>

<hr>
<h2 id='create.fdata.basis'>Create Basis Set for Functional Data of fdata class</h2><span id='topic+create.fdata.basis'></span><span id='topic+create.pc.basis'></span><span id='topic+create.pls.basis'></span><span id='topic+create.raw.fdata'></span>

<h3>Description</h3>

<p>Compute basis for functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create.fdata.basis(
  fdataobj,
  l = 1:5,
  maxl = max(l),
  type.basis = "bspline",
  rangeval = fdataobj$rangeval,
  class.out = "fd"
)

create.pc.basis(
  fdataobj,
  l = 1:5,
  norm = TRUE,
  basis = NULL,
  lambda = 0,
  P = c(0, 0, 1),
  ...
)

create.pls.basis(
  fdataobj,
  y,
  l = 1:5,
  norm = TRUE,
  lambda = 0,
  P = c(0, 0, 1),
  ...
)

create.raw.fdata(fdataobj, l = 1:nrow(fdataobj))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create.fdata.basis_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_l">l</code></td>
<td>
<p>Vector of basis index.</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_maxl">maxl</code></td>
<td>
<p>maximum number of basis</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_type.basis">type.basis</code></td>
<td>
<p>Type of basis (see create.basis function).</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_rangeval">rangeval</code></td>
<td>
<p>A vector of length 2 giving the lower and upper limits of
the range of permissible values for the function argument.</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_class.out">class.out</code></td>
<td>
<p>==&quot;fd&quot; basisfd class, ==&quot;fdata&quot; fdata class.</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_norm">norm</code></td>
<td>
<p>If <code>TRUE</code> the norm of eigenvectors <code>basis</code> is 1.</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_basis">basis</code></td>
<td>
<p>&quot;fd&quot; basis object.</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_lambda">lambda</code></td>
<td>
<p>Amount of penalization. Default value is 0, i.e. no
penalization is used.</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_p">P</code></td>
<td>
<p>If P is a vector: coefficients to define the penalty matrix object.
By default P=c(0,0,1) penalize the second derivative (curvature) or
acceleration.  If P is a matrix: the penalty matrix object.</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="create.fdata.basis_+3A_y">y</code></td>
<td>
<p>Vector of response (scalar).</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>basis</code>: basis object.
</p>
</li>
<li> <p><code>x</code>: if <code>TRUE</code> the value of the rotated data (the centred data multiplied by the basis matrix) is returned.
</p>
</li>
<li> <p><code>mean</code>: functional mean of <code>fdataobj</code>.
</p>
</li>
<li> <p><code>df</code>: degree of freedom.
</p>
</li>
<li> <p><code>type</code>: type of basis.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O. and Silverman, Bernard W. (2006),
<em>Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>N. Kraemer, A.-L. Boulsteix, and G. Tutz (2008). Penalized Partial Least
Squares with Applications to B-Spline Transformations and Functional Data.
Chemometrics and Intelligent Laboratory Systems, 94, 60 - 69.
<a href="https://doi.org/10.1016/j.chemolab.2008.06.009">doi:10.1016/j.chemolab.2008.06.009</a>
</p>


<h3>See Also</h3>

<p>See Also as <a href="fda.html#topic+create.basis">create.basis</a> and <code><a href="#topic+fdata2pc">fdata2pc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
basis.pc&lt;-create.pc.basis(tecator$absorp.fdata,c(1,4,5))
plot(basis.pc$basis,col=1)
summary(basis.pc)
basis.pls&lt;-create.pls.basis(tecator$absorp.fdata,y=tecator$y[,1],c(1,4,5))
summary(basis.pls)
plot(basis.pls$basis,col=2)
summary(basis.pls)

basis.fd&lt;-create.fdata.basis(tecator$absorp.fdata,c(1,4,5),
type.basis="fourier")
plot(basis.pc$basis)
basis.fdata&lt;-create.fdata.basis(tecator$absorp.fdata,c(1,4,5),
type.basis="fourier",class.out="fdata")
plot(basis.fd,col=2,lty=1)
lines(basis.fdata,col=3,lty=1)

## End(Not run)
</code></pre>

<hr>
<h2 id='CV.S'>The cross-validation (CV) score</h2><span id='topic+CV.S'></span>

<h3>Description</h3>

<p>Compute the leave-one-out cross-validation score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>CV.S(y, S, W = NULL, trim = 0, draw = FALSE, metric = metric.lp, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="CV.S_+3A_y">y</code></td>
<td>
<p>Matrix of set cases with dimension (<code>n</code> x <code>m</code>), where
<code>n</code> is the number of curves and <code>m</code> are the points observed in
each curve.</p>
</td></tr>
<tr><td><code id="CV.S_+3A_s">S</code></td>
<td>
<p>Smoothing matrix, see <code><a href="#topic+S.NW">S.NW</a></code>, <code><a href="#topic+S.LLR">S.LLR</a></code> or
<code class="reqn">S.KNN</code>.</p>
</td></tr>
<tr><td><code id="CV.S_+3A_w">W</code></td>
<td>
<p>Matrix of weights.</p>
</td></tr>
<tr><td><code id="CV.S_+3A_trim">trim</code></td>
<td>
<p>The alpha of the trimming.</p>
</td></tr>
<tr><td><code id="CV.S_+3A_draw">draw</code></td>
<td>
<p>=TRUE, draw the curves, the sample median and trimmed mean.</p>
</td></tr>
<tr><td><code id="CV.S_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="CV.S_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A.-If <code>trim=0</code>:<br />
</p>
<p style="text-align: center;"><code class="reqn">CV(h)=\frac{1}{n}
\sum_{i=1}^{n}{\Bigg(\frac{y_i-r_{i}(x_i)}{(1-S_{ii})}\Bigg)^{2}w(x_{i})}</code>
</p>
 <p><code class="reqn">S_{ii}</code> is the ith diagonal element of the smoothing
matrix <code class="reqn">S</code>.
</p>
<p>B.-If <code>trim&gt;0</code>:<br /> </p>
<p style="text-align: center;"><code class="reqn">CV(h)=\frac{1}{l}
\sum_{i=1}^{l}{\Bigg(\frac{y_i-r_{i}(x_i)}{(1-S_{ii})}\Bigg)^{2}w(x_{i})}</code>
</p>
 <p><code class="reqn">S_{ii}</code>
is the ith diagonal element of the smoothing matrix <code class="reqn">S</code> and l the
index of <code>(1-trim)</code> curves with less error.
</p>


<h3>Value</h3>

<p> Returns CV score calculated for input parameters.  
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Wasserman, L. <em>All of Nonparametric Statistics</em>. Springer
Texts in Statistics, 2006.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+optim.np">optim.np</a></code> <br /> Alternative method:
<code><a href="#topic+GCV.S">GCV.S</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x&lt;-tecator$absorp.fdata
np&lt;-ncol(x)
tt&lt;-1:np
S1 &lt;- S.NW(tt,3,Ker.epa)
S2 &lt;- S.LLR(tt,3,Ker.epa)
S3 &lt;- S.NW(tt,5,Ker.epa)
S4 &lt;- S.LLR(tt,5,Ker.epa)
cv1 &lt;- CV.S(x, S1)
cv2 &lt;- CV.S(x, S2)
cv3 &lt;- CV.S(x, S3)
cv4 &lt;- CV.S(x, S4)
cv5 &lt;- CV.S(x, S4,trim=0.1,draw=TRUE)
cv1;cv2;cv3;cv4;cv5
S6 &lt;- S.KNN(tt,1,Ker.unif,cv=TRUE)
S7 &lt;- S.KNN(tt,5,Ker.unif,cv=TRUE)
cv6 &lt;- CV.S(x, S6)
cv7 &lt;- CV.S(x, S7)
cv6;cv7

## End(Not run)
 
</code></pre>

<hr>
<h2 id='dcor.xy'>Distance Correlation Statistic and t-Test</h2><span id='topic+dcor.xy'></span><span id='topic+dcor.test'></span><span id='topic+dcor.dist'></span><span id='topic+bcdcor.dist'></span>

<h3>Description</h3>

<p>Distance correlation t-test of multivariate and functional 
independence (wrapper functions of energy package).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcor.xy(x, y, test = TRUE, metric.x, metric.y, par.metric.x, par.metric.y, n)

dcor.dist(D1, D2)

bcdcor.dist(D1, D2, n)

dcor.test(D1, D2, n)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dcor.xy_+3A_x">x</code></td>
<td>
<p>data (fdata, matrix or data.frame class) of first sample.</p>
</td></tr>
<tr><td><code id="dcor.xy_+3A_y">y</code></td>
<td>
<p>data (fdata, matrix or data.frame class) of second sample.</p>
</td></tr>
<tr><td><code id="dcor.xy_+3A_test">test</code></td>
<td>
<p>if TRUE, compute bias corrected distance correlation statistic
and the corresponding t-test, else compute distance correlation statistic.</p>
</td></tr>
<tr><td><code id="dcor.xy_+3A_metric.x">metric.x</code>, <code id="dcor.xy_+3A_metric.y">metric.y</code></td>
<td>
<p>Name of metric or semi-metric function used for
compute the distances of <code>x</code> and <code>y</code> object respectively. By
default, <code><a href="#topic+metric.lp">metric.lp</a></code> for functional data and
<code><a href="#topic+metric.dist">metric.dist</a></code> for multivariate data.</p>
</td></tr>
<tr><td><code id="dcor.xy_+3A_par.metric.x">par.metric.x</code>, <code id="dcor.xy_+3A_par.metric.y">par.metric.y</code></td>
<td>
<p>List of parameters for the corresponding
metric function.</p>
</td></tr>
<tr><td><code id="dcor.xy_+3A_n">n</code></td>
<td>
<p>The sample size used in bias corrected version of distance
correlation, by default is the number of rows of <code>x</code>.</p>
</td></tr>
<tr><td><code id="dcor.xy_+3A_d1">D1</code></td>
<td>
<p>Distances of first sample (x data).</p>
</td></tr>
<tr><td><code id="dcor.xy_+3A_d2">D2</code></td>
<td>
<p>Distances of second sample (y data).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These wrapper functions extend the functions of the <code>energy</code> package
for multivariate data to functional data.  Distance correlation is a measure
of dependence between random vectors introduced by Szekely, Rizzo, and
Bakirov (2007).
<code>dcor.xy</code> performs a nonparametric t-test of multivariate or functional
independence in high dimension. The distribution of the test statistic is
approximately Student t with <code class="reqn">n(n-3)/2-1</code> degrees of freedom and for
<code class="reqn">n \geq 10</code> the statistic is approximately distributed as standard
normal.  Wrapper function of <code>energy:::dcor.ttest</code>.  The t statistic is
a transformation of a bias corrected version of distance correlation (see SR
2013 for details). Large values (upper tail) of the t statistic are
significant.<br /> 
<code>dcor.test</code> similar to <code>dcor.xy</code> but only for distance matrix.
<code>dcor.dist</code> compute distance correlation statistic.  Wrapper function
of <code>energy::dcor</code> but only for distance matrix
<code>bcdcor.dist</code> compute bias corrected distance correlation statistic.
Wrapper function of <code>energy:::bcdcor</code> but only for distance matrix.
</p>


<h3>Value</h3>

<p><code>dcor.test</code> returns a list with class <code>htest</code> containing
</p>

<ul>
<li> <p><code>method</code>: description of test.
</p>
</li>
<li> <p><code>statistic</code>: observed value of the test statistic.
</p>
</li>
<li> <p><code>parameter</code>: degrees of freedom.
</p>
</li>
<li> <p><code>estimate</code>: bias corrected distance correlation <code>bcdcor(x,y)</code>.
</p>
</li>
<li> <p><code>p.value</code>: p-value of the t-test.
</p>
</li>
<li> <p><code>data.name</code>: description of data.
</p>
</li></ul>

<p><code>dcor.xy</code> returns the previous list with class <code>htest</code> and 
</p>

<ul>
<li> <p><code>D1</code>: the distance matrix of <code>x</code>.
</p>
</li>
<li> <p><code>D2</code>: the distance matrix of <code>y</code>.
</p>
</li></ul>

<p><code>dcor.dist</code> returns the distance correlation statistic.
</p>
<p><code>bcdcor.dist</code> returns the bias corrected distance correlation
statistic.
</p>


<h3>Author(s)</h3>

<p>Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a> and Manuel
Febrero Bande
</p>


<h3>References</h3>

<p>Szekely, G.J. and Rizzo, M.L. (2013). The distance correlation
t-test of independence in high dimension. <em>Journal of Multivariate
Analysis</em>, Volume 117, pp. 193-213. 
</p>
<p>Szekely, G.J., Rizzo, M.L., and Bakirov, N.K. (2007), Measuring and Testing
Dependence by Correlation of Distances, <em>Annals of Statistics</em>, Vol. 35
No. 6, pp. 2769-2794.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+metric.lp">metric.lp</a></code> amd <code><a href="#topic+metric.dist">metric.dist</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
x&lt;-rproc2fdata(100,1:50)
y&lt;-rproc2fdata(100,1:50)
dcor.xy(x, y,test=TRUE)
dx &lt;- metric.lp(x)
dy &lt;- metric.lp(y)
dcor.test(dx, dy)
bcdcor.dist(dx, dy)
dcor.xy(x, y,test=FALSE)
dcor.dist(dx, dy)

## End(Not run)

</code></pre>

<hr>
<h2 id='depth.fdata'>Computation of depth measures for functional data</h2><span id='topic+depth.fdata'></span><span id='topic+depth.mode'></span><span id='topic+Depth'></span><span id='topic+depth.FM'></span><span id='topic+depth.RP'></span><span id='topic+depth.RPD'></span><span id='topic+depth.RT'></span><span id='topic+depth.FSD'></span><span id='topic+depth.KFSD'></span>

<h3>Description</h3>

<p>Several depth measures can be computed for functional data for descriptive
or classification purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>depth.mode(
  fdataobj,
  fdataori = fdataobj,
  trim = 0.25,
  metric = metric.lp,
  h = NULL,
  scale = FALSE,
  draw = FALSE,
  ...
)

depth.RP(
  fdataobj,
  fdataori = fdataobj,
  trim = 0.25,
  nproj = 50,
  proj = "vexponential",
  dfunc = "TD1",
  par.dfunc = list(),
  scale = FALSE,
  draw = FALSE,
  ...
)

depth.RPD(
  fdataobj,
  fdataori = fdataobj,
  nproj = 20,
  proj = 1,
  deriv = c(0, 1),
  trim = 0.25,
  dfunc2 = mdepth.LD,
  method = "fmm",
  draw = FALSE,
  ...
)

depth.RT(
  fdataobj,
  fdataori = fdataobj,
  trim = 0.25,
  nproj = 10,
  proj = 1,
  xeps = 1e-07,
  draw = FALSE,
  ...
)

depth.KFSD(
  fdataobj,
  fdataori = fdataobj,
  trim = 0.25,
  h = NULL,
  scale = FALSE,
  draw = FALSE
)

depth.FSD(
  fdataobj,
  fdataori = fdataobj,
  trim = 0.25,
  scale = FALSE,
  draw = FALSE
)

depth.FM(
  fdataobj,
  fdataori = fdataobj,
  trim = 0.25,
  scale = FALSE,
  dfunc = "FM1",
  par.dfunc = list(scale = TRUE),
  draw = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="depth.fdata_+3A_fdataobj">fdataobj</code></td>
<td>
<p>The set of new curves to evaluate the depth.
<code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_fdataori">fdataori</code></td>
<td>
<p>The set of reference curves respect to which the depth is
computed.  <code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_trim">trim</code></td>
<td>
<p>The alpha of the trimming.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>. Distance
matrix between <code>fdataobj</code> and <code>fdataori</code>.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_h">h</code></td>
<td>
<p>Bandwidth, <code>h&gt;0</code>. Default argument values are provided as the
15%&ndash;quantile of the distance between <code>x</code> and <code>xx</code>.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_scale">scale</code></td>
<td>
<p>=TRUE, the depth is scaled respect to depths in
<code>fdataori</code>.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_draw">draw</code></td>
<td>
<p>=TRUE, draw the curves, the sample median and trimmed mean.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. For
<code>depth.mode</code> parameters for <code>metric</code>. For random projection
depths, parameters to be included in <code>rproc2fdata</code> not included before.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_nproj">nproj</code></td>
<td>
<p>The number of projections. Ignored if a <code>fdata</code> class
object is provided in <code>proj</code></p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_proj">proj</code></td>
<td>
<p>if a <code>fdata</code> class, projections provided by the user.
Otherwise, it is the <code>sigma</code> parameter of <code><a href="#topic+rproc2fdata">rproc2fdata</a></code>
function.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_dfunc">dfunc</code></td>
<td>
<p>type of univariate depth function used inside depth function:
&quot;FM1&quot; refers to the original Fraiman and Muniz univariate depth (default),
&quot;TD1&quot; Tukey (Halfspace),&quot;Liu1&quot; for simplical depth, &quot;LD1&quot; for Likelihood
depth and &quot;MhD1&quot; for Mahalanobis 1D depth. Also, any user function
fulfilling the following pattern <code>FUN.USER(x,xx,...)</code> and returning a
<code>dep</code> component can be included.f</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_par.dfunc">par.dfunc</code></td>
<td>
<p>List of parameters for <em>dfunc</em>.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_deriv">deriv</code></td>
<td>
<p>Number of derivatives described in integer vector <code>deriv</code>.
<code>=0</code> means no derivative.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_dfunc2">dfunc2</code></td>
<td>
<p>Multivariate depth function (second step depth function) in
RPD depth, by default <code><a href="#topic+mdepth.LD">mdepth.LD</a></code>. Any user function with the
pattern <code>FUN.USER(x,xx,...)</code> can be employed.</p>
</td></tr>
<tr><td><code id="depth.fdata_+3A_method">method</code></td>
<td>
<p>Type of derivative method. See <code><a href="#topic+fdata.deriv">fdata.deriv</a></code> for
more details.
</p>
 
<ul>
<li> <p><code>numeric</code>: the procedure considers the argument value as the bandwidth.
</p>
</li>
<li> <p><code>NULL</code>: (by default) the bandwidth is provided as the 
15%&ndash;quantile of the distance among curves of  <code>fdataori</code>.
</p>
</li>
<li> <p><code>character</code>:  a  string (like <code>"0.15"</code>), the procedure
reads the numeric value and consider it as the quantile of the distance in
<code>fdataori</code> (as in the second case). 
</p>
</li></ul>
</td></tr>
<tr><td><code id="depth.fdata_+3A_xeps">xeps</code></td>
<td>
<p>Accuracy. The left limit of the empirical distribution function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type of depth functions: Fraiman and Muniz (FM)
depth, modal depth, random Tukey (RT), random projection (RP) depth and
double random projection depth (RPD).
</p>
 
<ul>
<li> <p><code><a href="#topic+depth.FM">depth.FM</a></code>: computes the integration of an univariate depth
along the axis x (see Fraiman and Muniz 2001). It is also known as
Integrated Depth.
</p>
</li>
<li> <p><code><a href="#topic+depth.mode">depth.mode</a></code>: implements the modal depth (see Cuevas et al
2007).
</p>
</li>
<li> <p><code><a href="#topic+depth.RT">depth.RT</a></code>: implements the Random Tukey depth (see
Cuesta&ndash;Albertos and Nieto&ndash;Reyes 2008).
</p>
</li>
<li> <p><code><a href="#topic+depth.RP">depth.RP</a></code>: computes the Random Projection depth (see
Cuevas et al. 2007).
</p>
</li>
<li> <p><code><a href="#topic+depth.RPD">depth.RPD</a></code>: implements a depth measure based on random
projections possibly using several derivatives (see Cuevas et al. 2007).
</p>
</li>
<li> <p><code><a href="#topic+depth.FSD">depth.FSD</a></code>: computes the Functional Spatial Depth (see
Sguera et al. 2014).
</p>
</li>
<li> <p><code><a href="#topic+depth.KFSD">depth.KFSD</a></code>: implements the Kernelized Functional Spatial
Depth (see Sguera et al. 2014).
</p>
</li></ul>
 
 
<ul>
<li> <p><code><a href="#topic+depth.mode">depth.mode</a></code>: calculates the depth of a datum
accounting the number of curves in its neighbourhood. By default, the
distance is calculated using <code><a href="#topic+metric.lp">metric.lp</a></code> function although any
other distance could be employed through argument <code>metric</code> (with the
general pattern <code>USER.DIST(fdataobj,fdataori)</code>).
</p>
</li>
<li> <p><code><a href="#topic+depth.RP">depth.RP</a></code>: summarizes the random projections
through averages whereas the <code><a href="#topic+depth.RT">depth.RT</a></code> function uses the
minimum of all projections.
</p>
</li>
<li> <p><code><a href="#topic+depth.RPD">depth.RPD</a></code>: involves the original
trajectories and the derivatives of each curve in two steps. It builds
random projections for the function and their derivatives (indicated in the
parameter <code>deriv</code>) and then applies a depth function (by default
<code><a href="#topic+depth.mode">depth.mode</a></code>) to this set of random projections (by default the
Tukey one).
</p>
</li>
<li> <p><code><a href="#topic+depth.FSD">depth.FSD</a></code> and <code><a href="#topic+depth.KFSD">depth.KFSD</a></code>: are the
implementations of the default versions of the functional spatial depths
proposed in Sguera et al 2014. At this moment, it is not possible to change
the kernel in the second one.
</p>
</li></ul>



<h3>Value</h3>

<p>Return a list with:
</p>

<ul>
<li> <p><code>median</code>: Deepest curve.
</p>
</li>
<li> <p><code>lmed</code>: Index deepest element <code>median</code>.
</p>
</li>
<li> <p><code>mtrim</code>: <code>fdata</code> class object with the average from the <code>(1-trim)%</code> deepest curves. 
</p>
</li>
<li> <p><code>ltrim</code>: Indexes of curves that conform the trimmed mean <code>mtrim</code>. 
</p>
</li>
<li> <p><code>dep</code>: Depth of each curve of fdataobj w.r.t. fdataori.
</p>
</li>
<li> <p><code>dep.ori</code>: Depth of each curve of fdataori w.r.t. fdataori.
</p>
</li>
<li> <p><code>proj</code>: The projection value of each point on the curves.  
</p>
</li>
<li> <p><code>dist</code>: Distance matrix between curves or functional data.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Cuevas, A., Febrero-Bande, M., Fraiman, R. (2007). Robust
estimation and classification for functional data via projection-based depth
notions. <em>Computational Statistics</em> 22, 3, 481-496.
</p>
<p>Fraiman R, Muniz G. (2001). Trimmed means for functional data. <em>Test</em>
10: 419-440.
</p>
<p>Cuesta&ndash;Albertos, JA, Nieto&ndash;Reyes, A. (2008) The Random Tukey Depth.
<em>Computational Statistics and Data Analysis</em> Vol. 52, Issue 11,
4979-4988.
</p>
<p>Febrero-Bande, M, Oviedo de la Fuente, M. (2012).  Statistical Computing in
Functional Data Analysis: The R Package fda.usc. <em>Journal of
Statistical Software</em>, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>
<p>Sguera C, Galeano P, Lillo R (2014). Spatial depth based classification for
functional data. <em>TEST</em> 23(4):725&ndash;750.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+Descriptive">Descriptive</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#Ex: CanadianWeather data
tt=1:365
fdataobj&lt;-fdata(t(CanadianWeather$dailyAv[,,1]),tt)
# Fraiman-Muniz Depth
out.FM=depth.FM(fdataobj,trim=0.1,draw=TRUE)
#Modal Depth
out.mode=depth.mode(fdataobj,trim=0.1,draw=TRUE)
out.RP=depth.RP(fdataobj,trim=0.1,draw=TRUE)
out.RT=depth.RT(fdataobj,trim=0.1,draw=TRUE)
out.FSD=depth.FSD(fdataobj,trim=0.1,draw=TRUE)
out.KFSD=depth.KFSD(fdataobj,trim=0.1,draw=TRUE)
## Double Random Projections
out.RPD=depth.RPD(fdataobj,deriv=c(0,1),dfunc2=mdepth.LD,
trim=0.1,draw=TRUE)
out&lt;-c(out.FM$mtrim,out.mode$mtrim,out.RP$mtrim,out.RPD$mtrim)
plot(fdataobj,col="grey")
lines(out)
cdep&lt;-cbind(out.FM$dep,out.mode$dep,out.RP$dep,out.RT$dep,out.FSD$dep,out.KFSD$dep)
colnames(cdep)&lt;-c("FM","mode","RP","RT","FSD","KFSD")
pairs(cdep)
round(cor(cdep),2)

## End(Not run)

</code></pre>

<hr>
<h2 id='depth.mdata'>Provides the depth measure for multivariate data</h2><span id='topic+depth.mdata'></span><span id='topic+mdepth.LD'></span><span id='topic+Depth.Multivariate'></span><span id='topic+mdepth.FM'></span><span id='topic+mdepth.HS'></span><span id='topic+mdepth.MhD'></span><span id='topic+mdepth.SD'></span><span id='topic+mdepth.TD'></span><span id='topic+mdepth.RP'></span><span id='topic+mdepth.FSD'></span><span id='topic+mdepth.KFSD'></span>

<h3>Description</h3>

<p>Compute measure of centrality of the multivariate data. Type of depth
function: simplicial depth (SD), Mahalanobis depth (MhD), Random Half&ndash;Space
depth (HS), random projection depth (RP) and Likelihood Depth (LD).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mdepth.LD(x, xx = x, metric = metric.dist, h = NULL, scale = FALSE, ...)

mdepth.HS(x, xx = x, proj = 50, scale = FALSE, xeps = 1e-15, random = FALSE)

mdepth.RP(x, xx = x, proj = 50, scale = FALSE)

mdepth.MhD(x, xx = x, scale = FALSE)

mdepth.KFSD(x, xx = x, trim = 0.25, h = NULL, scale = FALSE, draw = FALSE)

mdepth.FSD(x, xx = x, trim = 0.25, scale = FALSE, draw = FALSE)

mdepth.FM(x, xx = x, scale = FALSE, dfunc = "TD1")

mdepth.TD(x, xx = x, xeps = 1e-15, scale = FALSE)

mdepth.SD(x, xx = NULL, scale = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="depth.mdata_+3A_x">x</code></td>
<td>
<p>is a set of points, a d-column matrix.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_xx">xx</code></td>
<td>
<p>is a d-dimension multivariate reference sample (a d-column matrix)
where <code>x</code> points are evaluated.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.dist">metric.dist</a></code>.
Distance matrix between <code>x</code> and <code>xx</code> is computed.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_h">h</code></td>
<td>
<p>Bandwidth, <code>h&gt;0</code>. Default argument values are provided as the
15%&ndash;quantile of the distance between <code>x</code> and <code>xx</code>.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_scale">scale</code></td>
<td>
<p>=TRUE, scale the depth, see <a href="base.html#topic+scale">scale</a>.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_proj">proj</code></td>
<td>
<p>are the directions for random projections, by default 500 random
projections generated from a scaled <code>runif(500,-1,1)</code>.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_xeps">xeps</code></td>
<td>
<p>Accuracy. The left limit of the empirical distribution function.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_random">random</code></td>
<td>
<p>=TRUE for random projections. =FALSE for deterministic
projections.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_trim">trim</code></td>
<td>
<p>The alpha of the trimming.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_draw">draw</code></td>
<td>
<p>=TRUE, draw the curves, the sample median and trimmed mean.</p>
</td></tr>
<tr><td><code id="depth.mdata_+3A_dfunc">dfunc</code></td>
<td>
<p>type of univariate depth function used inside depth function:
&quot;FM1&quot; refers to the original Fraiman and Muniz univariate depth (default),
&quot;TD1&quot; Tukey (Halfspace),&quot;Liu1&quot; for simplical depth, &quot;LD1&quot; for Likelihood
depth and &quot;MhD1&quot; for Mahalanobis 1D depth. Also, any user function
fulfilling the following pattern <code>FUN.USER(x,xx,...)</code> and returning a
<code>dep</code> component can be included.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type of depth measures:
</p>
 
<ul>
<li><p> The <code><a href="#topic+mdepth.SD">mdepth.SD</a></code> calculates the simplicial depth (HD) of the points in <code>x</code> w.r.t.
<code>xx</code> (for bivariate data).  
</p>
</li>
<li><p> The <code><a href="#topic+mdepth.HS">mdepth.HS</a></code> function calculates the random half&ndash;space depth (HS)
of the points in <code>x</code> w.r.t. <code>xx</code> based on random projections <code>proj</code>.  
</p>
</li>
<li><p> The <code><a href="#topic+mdepth.MhD">mdepth.MhD</a></code> function calculates the Mahalanobis depth (MhD)
of the points in <code>x</code> w.r.t. <code>xx</code>.  
</p>
</li>
<li><p> The <code><a href="#topic+mdepth.RP">mdepth.RP</a></code> calculates the random' projection depth (RP) 
of the points in <code>x</code> w.r.t. <code>xx</code> based on random projections <code>proj</code>.
</p>
</li>
<li><p> The <code><a href="#topic+mdepth.LD">mdepth.LD</a></code> calculates the Likelihood depth (LD) of the points 
in <code>x</code> w.r.t. <code>xx</code>.  
</p>
</li>
<li><p> The <code><a href="#topic+mdepth.TD">mdepth.TD</a></code> function provides the Tukey depth measure for multivariate data.
</p>
</li></ul>



<h3>Value</h3>

 
<ul>
<li> <p><code>lmed</code>: Index of the deepest element (median) of <code>xx</code>.
</p>
</li>
<li> <p><code>ltrim</code>: Index of the set of points <code>x</code> with trimmed mean <code>mtrim</code>. 
</p>
</li>
<li> <p><code>dep</code>: Depth of each point in <code>x</code> with respect to <code>xx</code>.
</p>
</li>
<li> <p><code>proj</code>: The projection value of each point onto the set of points.
</p>
</li>
<li> <p><code>x</code>: A set of points to be evaluated.
</p>
</li>
<li> <p><code>xx</code>: A reference sample.
</p>
</li>
<li> <p><code>name</code>: Name of the depth method.
</p>
</li></ul>



<h3>Author(s)</h3>

<p><code><a href="#topic+mdepth.RP">mdepth.RP</a></code>, <code><a href="#topic+mdepth.MhD">mdepth.MhD</a></code> and
<code><a href="#topic+mdepth.HS">mdepth.HS</a></code> are versions created by Manuel Febrero Bande and
Manuel Oviedo de la Fuente of the original version created by Jun Li, Juan
A. Cuesta Albertos and Regina Y. Liu for polynomial classifier.
</p>


<h3>References</h3>

<p>Liu, R. Y., Parelius, J. M., and Singh, K. (1999). Multivariate
analysis by data depth: descriptive statistics, graphics and inference,(with
discussion and a rejoinder by Liu and Singh). <em>The Annals of
Statistics</em>, 27(3), 783-858.
</p>


<h3>See Also</h3>

<p>Functional depth functions: <code><a href="#topic+depth.FM">depth.FM</a></code>,
<code><a href="#topic+depth.mode">depth.mode</a></code>, <code><a href="#topic+depth.RP">depth.RP</a></code>, <code><a href="#topic+depth.RPD">depth.RPD</a></code>
and <code><a href="#topic+depth.RT">depth.RT</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
group&lt;-iris[,5]
x&lt;-iris[,1:2]
                                  
MhD&lt;-mdepth.MhD(x)
PD&lt;-mdepth.RP(x)
HD&lt;-mdepth.HS(x)
SD&lt;-mdepth.SD(x)

x.setosa&lt;-x[group=="setosa",]
x.versicolor&lt;-x[group=="versicolor",] 
x.virginica&lt;-x[group=="virginica",]
d1&lt;-mdepth.SD(x,x.setosa)$dep
d2&lt;-mdepth.SD(x,x.versicolor)$dep
d3&lt;-mdepth.SD(x,x.virginica)$dep

## End(Not run)
</code></pre>

<hr>
<h2 id='depth.mfdata'>Provides the depth measure for a list of p&ndash;functional data objects</h2><span id='topic+depth.mfdata'></span><span id='topic+depth.modep'></span><span id='topic+depth.FMp'></span><span id='topic+depth.RPp'></span>

<h3>Description</h3>

<p>This function computes the depth measure for a list of p&ndash;functional data
objects.  The procedure extends the Fraiman and Muniz (FM), modal, and
random project depth functions from 1 functional dataset to p functional
datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>depth.modep(
  mfdata,
  mfdataref = mfdata,
  h = NULL,
  metric,
  par.metric = list(),
  method = "euclidean",
  scale = FALSE,
  trim = 0.25,
  draw = FALSE,
  ask = FALSE
)

depth.RPp(
  mfdata,
  mfdataref = mfdata,
  nproj = 50,
  proj = "vexponential",
  trim = 0.25,
  dfunc = "mdepth.TD",
  par.dfunc = list(scale = TRUE),
  draw = FALSE,
  ask = FALSE
)

depth.FMp(
  mfdata,
  mfdataref = mfdata,
  trim = 0.25,
  dfunc = "mdepth.MhD",
  par.dfunc = list(scale = FALSE),
  draw = FALSE,
  ask = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="depth.mfdata_+3A_mfdata">mfdata</code></td>
<td>
<p>A list of new curves (list of fdata ojects) to evaluate the
depth.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_mfdataref">mfdataref</code></td>
<td>
<p>A set of reference curves (list of fdata ojects) w.r.t. the
depth of mfdata is computed.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_h">h</code></td>
<td>
<p>Bandwidth, <code>h&gt;0</code>. Default argument values are provided as the
15%&ndash;quantile of the distance between <code>fdataobj</code> and <code>fdataori</code>.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_metric">metric</code></td>
<td>
<p>Metric or semi&ndash;metric function used for compute the distance
between each element in <code>ldata</code> w.r.t. <code>ldataref</code>, by default
<code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_par.metric">par.metric</code></td>
<td>
<p>list of parameters for the metric function.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_method">method</code></td>
<td>
<p>Type of the distance measure (by default <code>euclidean</code>) to
compute the metric between the p-distance matrix computed from the p
functional data elements.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_scale">scale</code></td>
<td>
<p>=TRUE, scale the depth.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_trim">trim</code></td>
<td>
<p>The alpha of the trimming.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_draw">draw</code></td>
<td>
<p>=TRUE, draw the curves, the sample median and trimmed mean.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_ask">ask</code></td>
<td>
<p>logical. If <code>TRUE</code> (and the R session is interactive) the
user is asked for input, before a new figure is drawn.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_nproj">nproj</code></td>
<td>
<p>The number projection.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_proj">proj</code></td>
<td>
<p>if is a character: create the random projection using a
covariance matrix by process indicated in the argument (by default, proj=1,
sigma=diag(ncol(fdataobj))), else if is a matrix of random projection
provided by the user.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_dfunc">dfunc</code></td>
<td>
<p>Type of multivariate depth (of order p) function used in
Framiman and Muniz depth, <code>depth.FMp</code> or in Random Projection
depth,<code>depth.FMp</code>: : </p>
 <ul>
<li><p> The <code><a href="#topic+mdepth.SD">mdepth.SD</a></code>
function provides the simplicial depth measure for bivariate data.  </p>
</li>
<li>
<p>The <code><a href="#topic+mdepth.LD">mdepth.LD</a></code> function provides the Likelihood depth measure
based on Nadaraya&ndash;Watson estimator of empirical density function.  </p>
</li>
<li>
<p>The <code><a href="#topic+mdepth.HS">mdepth.HS</a></code> function implements a half-space depth measure
based on random projections.  </p>
</li>
<li><p> The <code><a href="#topic+mdepth.TD">mdepth.TD</a></code> function
implements a Tukey depth measure.  </p>
</li>
<li><p> The
<code><a href="#topic+mdepth.MhD">mdepth.MhD</a></code>function implements a Mahalanobis depth measure.
</p>
</li>
<li><p> The <code><a href="#topic+mdepth.RP">mdepth.RP</a></code> function provides the depth measure using
random projections for multivariate data.  </p>
</li></ul>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_par.dfunc">par.dfunc</code></td>
<td>
<p>list of parameters for the <code>dfunc</code> depth function, see
<code><a href="#topic+Depth.Multivariate">Depth.Multivariate</a></code>.</p>
</td></tr>
<tr><td><code id="depth.mfdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

 
<ul>
<li> <p><code><a href="#topic+depth.FMp">depth.FMp</a></code>, this procedure suposes that each
curve of the mfdataobj have the same support [0,T] (same argvals and
rangeval).  The FMp depth is defined as: <code class="reqn">FM_i^p
=\int_{0}^{T}Z_i^p(t)dt</code> where
<code class="reqn">Z_i^p(t)</code> is a <code class="reqn">p</code>&ndash;variate depth of the vector
<code class="reqn">(x_i^1(t),\ldots,x_i^p(t))</code> w.r.t. the sample
at <code class="reqn">t</code>. 
derivatives. In this case,note solo un dato funcional se reduce
depth.FM=depth.FM1 
</p>
</li>
<li><p> The <code><a href="#topic+depth.RPp">depth.RPp</a></code> function calculates the depth in two
steps. It builds random projections for the each curve of the <code>mfdata</code>
w.r.t. each curve of the <code>mfdataref</code> object. Then it applyes a
multivariate depth function specified in <code>dfunc</code> argument to the set of
random projections.  This procedure is a generalization of Random Projection
with derivatives (RPD) implemented in <code><a href="#topic+depth.RPD">depth.RPD</a></code> function.
Now, the procedure computes a p-variate depth with the projections using the
<code class="reqn">p</code> functional dataset.
</p>
</li>
<li><p> The modal depth <code><a href="#topic+depth.modep">depth.modep</a></code> function calculates the
depth in three steps.  First, the function calculates a suitable metrics or
semi&ndash;metrics <code class="reqn">m_1+\cdots+m_p</code> for each curve of the
<code>mfdata</code> w.r.t. each curve in the <code>mfdataref</code> object using the
<code>metric</code> and <code>par.metric</code> arguments, see <code><a href="#topic+metric.lp">metric.lp</a></code>
or <code><a href="#topic+semimetric.NPFDA">semimetric.NPFDA</a></code> for more details.  Second, the function
uses the <code class="reqn">p</code>&ndash;dimensional metrics to construct a new metric, specified
in <code>method</code> argument, by default if <code>method="euclidean"</code>, i.e.
<code class="reqn">m:=\sqrt{m_1^2+\cdots+m_p^2}</code>. Finally, the
empirical <em>h</em>&ndash;depth is computed as:
</p>
<p style="text-align: center;"><code class="reqn">\hat{f}_h(x_0)=N^{-1}\sum_{i=1}^{N}{K(m/h)}</code>
</p>
<p> where <code class="reqn">x</code> is dataset with p observed fucntional data, <code class="reqn">m</code> is
a suitable metric or semi&ndash;metric, <code class="reqn">K(t)</code> is an asymmetric kernel
function and <code>h</code> is the bandwidth parameter. 
</p>
</li></ul>



<h3>Value</h3>


<ul>
<li> <p><code>lmed</code>: Index deepest element <code>median</code>.
</p>
</li>
<li> <p><code>ltrim</code>: Index of curves with trimmed mean <code>mtrim</code>.
</p>
</li>
<li> <p><code>dep</code>: Depth of each curve of <code>fdataobj</code> w.r.t. <code>fdataori</code>.
</p>
</li>
<li> <p><code>dfunc</code>: Second depth function used as multivariate depth, see details section.
</p>
</li>
<li> <p><code>par.dfunc</code>: List of parameters for the <code>dfunc</code> depth function.
</p>
</li>
<li> <p><code>proj</code>: The projection value of each point on the curves.
</p>
</li>
<li> <p><code>dist</code>: Distance matrix between curves or functional data.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Cuevas, A., Febrero-Bande, M. and Fraiman, R. (2007).
<em>Robust estimation and classification for functional data via
projection-based depth notions.</em> Computational Statistics 22, 3, 481-496.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+Descriptive">Descriptive</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
xx&lt;-tecator$absorp
xx1&lt;-fdata.deriv(xx,1)
lx&lt;-list(xx=xx,xx=xx1)
# Fraiman-Muniz Depth
par.df&lt;-list(scale =TRUE)
out.FM1p=depth.FMp(lx,trim=0.1,draw=TRUE, par.dfunc = par.df)
out.FM2p=depth.FMp(lx,trim=0.1,dfunc="mdepth.LD",
par.dfunc = par.df, draw=TRUE)

# Random Project Depth
out.RP1p=depth.RPp(lx,trim=0.1,dfunc="mdepth.TD",
draw=TRUE,par.dfunc = par.df)
out.RP2p=depth.RPp(lx,trim=0.1,dfunc="mdepth.LD",
draw=TRUE,par.dfunc = par.df)

#Modal Depth
out.mode1p=depth.modep(lx,trim=0.1,draw=T,scale=T)
out.mode2p=depth.modep(lx,trim=0.1,method="manhattan",
draw=T,scale=T)

par(mfrow=c(2,3))
plot(out.FM1p$dep,out.FM2p$dep)
plot(out.RP1p$dep,out.RP2p$dep)
plot(out.mode1p$dep,out.mode2p$dep)
plot(out.FM1p$dep,out.RP1p$dep)
plot(out.RP1p$dep,out.mode1p$dep)
plot(out.FM1p$dep,out.mode1p$dep)

## End(Not run)

</code></pre>

<hr>
<h2 id='Descriptive'>Descriptive measures for functional data.</h2><span id='topic+Descriptive'></span><span id='topic+func.mean'></span><span id='topic+func.mean.formula'></span><span id='topic+func.trim.FM'></span><span id='topic+func.trim.mode'></span><span id='topic+func.trim.RP'></span><span id='topic+func.trim.RT'></span><span id='topic+func.trim.RPD'></span><span id='topic+func.med.FM'></span><span id='topic+func.med.mode'></span><span id='topic+func.med.RP'></span><span id='topic+func.med.RT'></span><span id='topic+func.med.RPD'></span><span id='topic+func.var'></span><span id='topic+func.trimvar.FM'></span><span id='topic+func.trimvar.mode'></span><span id='topic+func.trimvar.RP'></span><span id='topic+func.trimvar.RT'></span><span id='topic+func.trimvar.RPD'></span>

<h3>Description</h3>

<p>Central and dispersion measures for functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>func.mean(x)

func.var(fdataobj)

func.trim.FM(fdataobj, ...)

func.trim.mode(fdataobj, ...)

func.trim.RP(fdataobj, ...)

func.trim.RT(fdataobj, ...)

func.trim.RPD(fdataobj, ...)

func.med.FM(fdataobj, ...)

func.med.mode(fdataobj, ...)

func.med.RP(fdataobj, ...)

func.med.RT(fdataobj, ...)

func.med.RPD(fdataobj, ...)

func.trimvar.FM(fdataobj, ...)

func.trimvar.mode(fdataobj, ...)

func.trimvar.RP(fdataobj, ...)

func.trimvar.RPD(fdataobj, ...)

func.trim.RT(fdataobj, ...)

func.med.RT(fdataobj, ...)

func.trimvar.RT(fdataobj, ...)

func.mean.formula(formula, data = NULL, ..., drop = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Descriptive_+3A_x">x</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> or <code><a href="#topic+ldata">ldata</a></code>  class object.</p>
</td></tr>
<tr><td><code id="Descriptive_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="Descriptive_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.  If the
argument <code>p</code> is passed, it used <code><a href="#topic+metric.lp">metric.lp</a></code> function, by
default <code>p=2</code>.<br /> If the argument <code>trim</code> (alpha of the trimming)
is passed, it used <code><a href="#topic+metric.lp">metric.lp</a></code> function.<br /> If the argument
<code>deriv</code> (number of derivatives to use) is passed. This parameter is
used in <code><a href="#topic+depth.RPD">depth.RPD</a></code> function, by default it uses <code>deriv
=(0,1)</code>.</p>
</td></tr>
<tr><td><code id="Descriptive_+3A_formula">formula</code></td>
<td>
<p>a formula, such as y ~ group, where y is a fdata object to be
split into groups according to the grouping variable group (usually a
factor).</p>
</td></tr>
<tr><td><code id="Descriptive_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the formula. The item
called <em>&quot;df&quot;</em> is a data frame with the grouping variable. The item
called <em>&quot;y&quot;</em> is a fdata object.</p>
</td></tr>
<tr><td><code id="Descriptive_+3A_drop">drop</code></td>
<td>
<p>logical indicating if levels that do not occur should be dropped
(if f is a factor or a list).</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code><a href="#topic+func.mean.formula">func.mean.formula</a></code> The value returned from split is a
list of fdata containing the mean curves<br /> for the groups. The components
of the list are named by the levels of f (after converting to a factor, or
if already a factor and drop = TRUE, dropping unused levels).<br />
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.mean">func.mean</a></code> gives mean curve. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+func.var">func.var</a></code> gives variance curve. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+func.trim.FM">func.trim.FM</a></code> Returns the average from the <code>(1-trim)</code>%
deepest curves following FM criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.trim.mode">func.trim.mode</a></code>
Returns the average from the <code>(1-trim)</code>% deepest curves following mode
criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.trim.RP">func.trim.RP</a></code> Returns the average from the
<code>(1-trim)</code>% deepest curves following RP criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+func.trim.RT">func.trim.RT</a></code> Returns the average from the <code>(1-trim)</code>%
deepest curves following RT criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.trim.RPD">func.trim.RPD</a></code>
Returns the average from the <code>(1-trim)</code>% deepest curves following RPD
criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.med.FM">func.med.FM</a></code> Returns the deepest curve
following FM criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.med.mode">func.med.mode</a></code> Returns the
deepest curve following mode criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.med.RP">func.med.RP</a></code>
Returns the deepest curve following RP criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+func.med.RPD">func.med.RPD</a></code> Returns the deepest curve following RPD criteria.
</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.trimvar.FM">func.trimvar.FM</a></code> Returns the marginal variance from
the deepest curves followinng FM criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+func.trimvar.mode">func.trimvar.mode</a></code> Returns the marginal variance from the
deepest curves followinng mode criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
<code><a href="#topic+func.trimvar.RP">func.trimvar.RP</a></code> Returns the marginal variance from the deepest
curves followinng RP criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.trimvar.RT">func.trimvar.RT</a></code>
Returns the marginal variance from the deepest curves followinng RT
criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> <code><a href="#topic+func.trimvar.RPD">func.trimvar.RPD</a></code> Returns the marginal
variance from the deepest curves followinng RPD criteria. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).
<em>Statistical Computing in Functional Data Analysis: The R Package
fda.usc.</em> Journal of Statistical Software, 51(4), 1-28.
<a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#' # Example with Montreal Daily Temperature (fda-package)
fdataobj&lt;-fdata(MontrealTemp)

# Measures of central tendency by group
fac&lt;-factor(c(rep(1,len=17),rep(2,len=17)))
ldata=list("df"=data.frame(fac),"fdataobj"=fdataobj)
a1&lt;-func.mean.formula(fdataobj~fac,data=ldata)
plot(a1)

# Measures of central tendency
a1&lt;-func.mean(fdataobj)
a2&lt;-func.trim.FM(fdataobj)
a3&lt;-func.trim.mode(fdataobj)
a4&lt;-func.trim.RP(fdataobj)
# a5&lt;-func.trim.RPD(fdataobj,deriv=c(0,1)) # Time-consuming
a6&lt;-func.med.FM(fdataobj)
a7&lt;-func.med.mode(fdataobj)
a8&lt;-func.med.RP(fdataobj)
# a9&lt;-func.med.RPD(fdataobj,deriv=c(0,1)) # Time-consuming
# a10&lt;-func.med.RT(fdataobj)

par(mfrow=c(1,2))
plot(c(a1,a2,a3,a4),ylim=c(-26,29),main="Central tendency: trimmed mean")
plot(c(a1,a6,a7,a8),ylim=c(-26,29),main="Central tendency: median")

## Measures of dispersion
b1&lt;-func.var(fdataobj)
b2&lt;-func.trimvar.FM(fdataobj)
b3&lt;-func.trimvar.FM(fdataobj,trim=0.1)
b4&lt;-func.trimvar.mode(fdataobj)
b5&lt;-func.trimvar.mode(fdataobj,p=1)
b6&lt;-func.trimvar.RP(fdataobj)
b7&lt;-func.trimvar.RPD(fdataobj)
b8&lt;-func.trimvar.RPD(fdataobj)
b9&lt;-func.trimvar.RPD(fdataobj,deriv=c(0,1))
dev.new()
par(mfrow=c(1,2))
plot(c(b1,b2,b3,b4,b5),ylim=c(0,79),main="Measures of dispersion I")
plot(c(b1,b6,b7,b8,b9),ylim=c(0,79),main="Measures of dispersion II")

## End(Not run)

</code></pre>

<hr>
<h2 id='dev.S'>The deviance score</h2><span id='topic+dev.S'></span>

<h3>Description</h3>

<p>Returns the deviance of a fitted model object by GCV score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dev.S(
  y,
  S,
  obs,
  family = gaussian(),
  off,
  offdf,
  criteria = "GCV",
  W = diag(1, ncol = ncol(S), nrow = nrow(S)),
  trim = 0,
  draw = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dev.S_+3A_y">y</code></td>
<td>
<p>Matrix of set cases with dimension (<code>n</code> x <code>m</code>), where
<code>n</code> is the number of curves and <code>m</code> are the points observed in
each curve.</p>
</td></tr>
<tr><td><code id="dev.S_+3A_s">S</code></td>
<td>
<p>Smoothing matrix.</p>
</td></tr>
<tr><td><code id="dev.S_+3A_obs">obs</code></td>
<td>
<p>observed response.</p>
</td></tr>
<tr><td><code id="dev.S_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)</p>
</td></tr>
<tr><td><code id="dev.S_+3A_off">off</code></td>
<td>
<p>off</p>
</td></tr>
<tr><td><code id="dev.S_+3A_offdf">offdf</code></td>
<td>
<p>off, degrees of freedom</p>
</td></tr>
<tr><td><code id="dev.S_+3A_criteria">criteria</code></td>
<td>
<p>The penalizing function. By default <em>&quot;Rice&quot;</em> criteria.
Possible values are <em>&quot;GCV&quot;</em>, <em>&quot;AIC&quot;</em>, <em>&quot;FPE&quot;</em>,
<em>&quot;Shibata&quot;</em>, <em>&quot;Rice&quot;</em>.</p>
</td></tr>
<tr><td><code id="dev.S_+3A_w">W</code></td>
<td>
<p>Matrix of weights.</p>
</td></tr>
<tr><td><code id="dev.S_+3A_trim">trim</code></td>
<td>
<p>The alpha of the trimming.</p>
</td></tr>
<tr><td><code id="dev.S_+3A_draw">draw</code></td>
<td>
<p>=TRUE, draw the curves, the sample median and trimmed mean.</p>
</td></tr>
<tr><td><code id="dev.S_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Up to a constant, minus twice the maximized log-likelihood. Where sensible,
the constant is chosen so that a saturated model has deviance zero.
</p>
<p style="text-align: center;"><code class="reqn">GCV(h)=p(h) \Xi(n^{-1}h^{-1})</code>
</p>
 
<p>Where <br /> </p>
<p style="text-align: center;"><code class="reqn">p(h)=\frac{1}{n}
\sum_{i=1}^{n}{\Big(y_i-r_{i}(x_i)\Big)^{2}w(x_i)}</code>
</p>
 <p><br /> and penalty
function </p>
<p style="text-align: center;"><code class="reqn">\Xi()</code>
</p>
<p> can be selected from the following criteria: <br />
</p>
<p>Generalized Cross-validation (GCV):
</p>
<p style="text-align: center;"><code class="reqn">\Xi_{GCV}(n^{-1}h^{-1})=(1-n^{-1}S_{ii})^{-2}</code>
</p>
 <p><br /> Akaike's
Information Criterion (AIC): 
</p>
<p style="text-align: center;"><code class="reqn">\Xi_{AIC}(n^{-1}h^{-1})=exp(2n^{-1}S_{ii})</code>
</p>
 
<p>Finite Prediction Error (FPE) 
</p>
<p style="text-align: center;"><code class="reqn">\Xi_{FPE}(n^{-1}h^{-1})=\frac{(1+n^{-1}S_{ii})}{(1-n^{-1}S_{ii})}</code>
</p>

<p>Shibata's model selector (Shibata): 
</p>
<p style="text-align: center;"><code class="reqn">\Xi_{Shibata}(n^{-1}h^{-1})=(1+2n^{-1}S_{ii})</code>
</p>

<p>Rice's bandwidth selector (Rice):
</p>
<p style="text-align: center;"><code class="reqn">\Xi_{Rice}(n^{-1}h^{-1})=(1-2n^{-1}S_{ii})^{-1}</code>
</p>



<h3>Value</h3>

<p>Returns GCV score calculated for input parameters.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Wasserman, L. <em>All of Nonparametric Statistics</em>. Springer
Texts in Statistics, 2006.
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+GCV.S">GCV.S</a></code>. <br /> Alternative method:
<code><a href="#topic+CV.S">CV.S</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(phoneme)
mlearn&lt;-phoneme$learn
np&lt;-ncol(mlearn)
tt&lt;-mlearn[["argvals"]]
S1 &lt;- S.NW(tt,2.5)
gcv1 &lt;- dev.S(mlearn$data[1,],obs=(sample(150)), 
S1,off=rep(1,150),offdf=3)
gcv2 &lt;- dev.S(mlearn$data[1,],obs=sort(sample(150)), 
S1,off=rep(1,150),offdf=3)

</code></pre>

<hr>
<h2 id='dfv.test'>Delsol, Ferraty and Vieu test for no functional-scalar interaction</h2><span id='topic+dfv.test'></span><span id='topic+dfv.statistic'></span>

<h3>Description</h3>

<p>The function <code>dfv.test</code> tests the null hypothesis of no interaction between a functional covariate and a scalar response in a general framework. The null hypothesis is </p>
<p style="text-align: center;"><code class="reqn">H_0:\,m(X)=0,</code>
</p>
<p> where <code class="reqn">m(\cdot)</code> denotes the regression function of the functional variate <code class="reqn">X</code> over the centred scalar response <code class="reqn">Y</code> (<code class="reqn">E[Y]=0</code>). The null hypothesis is tested by the smoothed integrated square error of the response (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dfv.statistic(
  X.fdata,
  Y,
  h = quantile(x = metric.lp(X.fdata), probs = c(0.05, 0.1, 0.15, 0.25, 0.5)),
  K = function(x) 2 * dnorm(abs(x)),
  weights = rep(1, dim(X.fdata$data)[1]),
  d = metric.lp,
  dist = NULL
)

dfv.test(
  X.fdata,
  Y,
  B = 5000,
  h = quantile(x = metric.lp(X.fdata), probs = c(0.05, 0.1, 0.15, 0.25, 0.5)),
  K = function(x) 2 * dnorm(abs(x)),
  weights = rep(1, dim(X.fdata$data)[1]),
  d = metric.lp,
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dfv.test_+3A_x.fdata">X.fdata</code></td>
<td>
<p>Functional covariate. The object must be in the class <code><a href="#topic+fdata">fdata</a></code>.</p>
</td></tr>
<tr><td><code id="dfv.test_+3A_y">Y</code></td>
<td>
<p>Scalar response. Must be a vector with the same number of elements as functions are in <code>X.fdata</code>.</p>
</td></tr>
<tr><td><code id="dfv.test_+3A_h">h</code></td>
<td>
<p>Bandwidth parameter for the kernel smoothing. This is a crucial parameter that affects the power performance of the test. One possibility to choose it is considering the Cross-validatory bandwidth of the nonparametric functional regression, given by the function <code><a href="#topic+fregre.np">fregre.np</a></code> (see Examples). 
Other possibility is to consider a grid of bandwidths. This is the default option, considering the grid given by the quantiles 0.05, 0.10, 0.15, 0.25 and 0.50 of the functional <code class="reqn">L^2</code> distances of the data.</p>
</td></tr>
<tr><td><code id="dfv.test_+3A_k">K</code></td>
<td>
<p>Kernel function. If no specified it is taken to be the rescaled right part of the normal density.</p>
</td></tr>
<tr><td><code id="dfv.test_+3A_weights">weights</code></td>
<td>
<p>A vector of weights for the sample data. The default is the uniform weights <code>rep(1,dim(X.fdata$data)[1])</code>.</p>
</td></tr>
<tr><td><code id="dfv.test_+3A_d">d</code></td>
<td>
<p>Semimetric to use in the kernel smoothers. By default is the <code class="reqn">L^2</code> distance given by <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="dfv.test_+3A_dist">dist</code></td>
<td>
<p>Matrix of distances of the functional data, used to save time in the bootstrap calibration. If not given, the matrix is automatically computed using the semimetric <code>d</code>.</p>
</td></tr>
<tr><td><code id="dfv.test_+3A_b">B</code></td>
<td>
<p>Number of bootstrap replicates to calibrate the distribution of the test statistic. <code>B=5000</code> replicates are the recommended for carry out the test, although for exploratory analysis (<b>not inferential</b>), an acceptable less time-consuming option is <code>B=500</code>.</p>
</td></tr>
<tr><td><code id="dfv.test_+3A_verbose">verbose</code></td>
<td>
<p>Either to show or not information about computing progress.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Delsol, Ferraty and Vieu statistic is defined as 
</p>
<p style="text-align: center;"><code class="reqn">T_n=\int\bigg(\sum_{i=1}^n(Y_i-m(X_i))K\bigg(\frac{d(X,X_i)}{h}\bigg)\bigg)^2\omega(X)dP_X(X)</code>
</p>

<p>and in the case of no interaction with centred scalar response (when <code class="reqn">H_0:\,m(X)=0</code> 
holds), its sample version is computed from 
</p>
<p style="text-align: center;"><code class="reqn">T_n=\frac{1}{n}\sum_{j=1}^n\bigg(\sum_{i=1}^n Y_iK\bigg(\frac{d(X_j,X_i)}{h}\bigg)\bigg)^2\omega(X_j).</code>
</p>

<p>The sample version implemented here does not consider a splitting of the sample, as the authors 
comment in their paper. The statistic is computed by the function <code>dfv.statistic</code> and, before
applying the test, the response <code class="reqn">Y</code> is centred. The distribution of the test statistic
is approximated by a wild bootstrap on the residuals, using the <em>golden section bootstrap</em>.
</p>
<p>Please note that if a grid of bandwidths is passed, a harmless warning message will prompt at the
end of the test (it comes from returning several p-values in the <code>htest</code> class).
</p>


<h3>Value</h3>

<p>The value of <code>dfv.statistic</code> is a vector of length <code>length(h)</code> with the values
of the statistic for each bandwidth. The value of <code>dfv.test</code> is an object with class 
<code>"htest"</code> whose underlying structure is a list containing the following components:
</p>

<ul>
<li> <p><code>statistic</code>: The value of the Delsol, Ferraty and Vieu test statistic.
</p>
</li>
<li> <p><code>boot.statistics</code>: A vector of length <code>B</code> with the values of the bootstrap test statistics.
</p>
</li>
<li> <p><code>p.value</code>: The p-value of the test.
</p>
</li>
<li> <p><code>method</code>: The character string &quot;Delsol, Ferraty and Vieu test for no functional-scalar interaction&quot;.
</p>
</li>
<li> <p><code>B</code>: The number of bootstrap replicates used.
</p>
</li>
<li> <p><code>h</code>: Bandwidth parameters for the test.
</p>
</li>
<li> <p><code>K</code>: Kernel function used.
</p>
</li>
<li> <p><code>weights</code>: The weights considered.
</p>
</li>
<li> <p><code>d</code>: Matrix of distances of the functional data.
</p>
</li>
<li> <p><code>data.name</code>: The character string &quot;Y=0+e&quot;.
</p>
</li></ul>



<h3>Note</h3>

<p>No NA's are allowed neither in the functional covariate nor in the scalar response.
</p>


<h3>Author(s)</h3>

<p>Eduardo Garcia-Portugues. Please, report bugs and suggestions
to <a href="mailto:eduardo.garcia.portugues@uc3m.es">eduardo.garcia.portugues@uc3m.es</a>
</p>


<h3>References</h3>

<p>Delsol, L., Ferraty, F. and Vieu, P. (2011). Structural test in regression on functional variables. 
Journal of Multivariate Analysis, 102, 422-447. <a href="https://doi.org/10.1016/j.jmva.2010.10.003">doi:10.1016/j.jmva.2010.10.003</a>
</p>
<p>Delsol, L. (2013). No effect tests in regression on functional variable and some applications to spectrometric studies. Computational Statistics, 28(4), 1775-1811. <a href="https://doi.org/10.1007/s00180-012-0378-1">doi:10.1007/s00180-012-0378-1</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rwild">rwild</a></code>, <code><a href="#topic+flm.test">flm.test</a></code>, <code><a href="#topic+flm.Ftest">flm.Ftest</a></code>, <code><a href="#topic+fregre.np">fregre.np</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Simulated example ##
X=rproc2fdata(n=50,t=seq(0,1,l=101),sigma="OU")

beta0=fdata(mdata=rep(0,length=101)+rnorm(101,sd=0.05),
argvals=seq(0,1,l=101),rangeval=c(0,1))
beta1=fdata(mdata=cos(2*pi*seq(0,1,l=101))-(seq(0,1,l=101)-0.5)^2+
rnorm(101,sd=0.05),argvals=seq(0,1,l=101),rangeval=c(0,1))

# Null hypothesis holds
Y0=drop(inprod.fdata(X,beta0)+rnorm(50,sd=0.1))

# Null hypothesis does not hold
Y1=drop(inprod.fdata(X,beta1)+rnorm(50,sd=0.1))

# We use the CV bandwidth given by fregre.np
# Do not reject H0
dfv.test(X,Y0,h=fregre.np(X,Y0)$h.opt,B=100)
# dfv.test(X,Y0,B=5000)

# Reject H0
dfv.test(X,Y1,B=100)
# dfv.test(X,Y1,B=5000)

## End(Not run)

</code></pre>

<hr>
<h2 id='dis.cos.cor'>Proximities between functional data</h2><span id='topic+dis.cos.cor'></span>

<h3>Description</h3>

<p>Computes the cosine correlation distance between two functional dataset of
class <code>fdata</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dis.cos.cor(fdata1, fdata2 = NULL, as.dis = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dis.cos.cor_+3A_fdata1">fdata1</code></td>
<td>
<p>Functional data 1 or curve 1.</p>
</td></tr>
<tr><td><code id="dis.cos.cor_+3A_fdata2">fdata2</code></td>
<td>
<p>Functional data 2 or curve 2.</p>
</td></tr>
<tr><td><code id="dis.cos.cor_+3A_as.dis">as.dis</code></td>
<td>
<p>Returns the distance matrix como 1-cor(fdata1,fdata2).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a proximity/distance matrix (depending on <code>as.dis</code>)  between functional data.
</p>


<h3>References</h3>

<p>Kemmeren P, van Berkum NL, Vilo J, et al. (2002). <em>Protein
Interaction Verification and Functional Annotation by Integrated Analysis of
Genome-Scale Data </em>. Mol Cell. 2002 9(5):1133-43.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+metric.lp">metric.lp</a></code> and <code><a href="#topic+semimetric.NPFDA">semimetric.NPFDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
 r1&lt;-rnorm(1001,sd=.01)
 r2&lt;-rnorm(1001,sd=.01)
 x&lt;-seq(0,2*pi,length=1001)
 fx&lt;-fdata(sin(x)/sqrt(pi)+r1,x)
 dis.cos.cor(fx,fx)
 dis.cos.cor(c(fx,fx),as.dis=TRUE)
 fx0&lt;-fdata(rep(0,length(x))+r2,x)
 plot(c(fx,fx0))
 dis.cos.cor(c(fx,fx0),as.dis=TRUE)
 
## End(Not run)
 
</code></pre>

<hr>
<h2 id='fanova.hetero'>ANOVA for heteroscedastic data</h2><span id='topic+fanova.hetero'></span><span id='topic+anova.hetero'></span>

<h3>Description</h3>

<p>Univariate ANOVA for heteroscedastic data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fanova.hetero(object = NULL, formula, pr = FALSE, contrast = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fanova.hetero_+3A_object">object</code></td>
<td>
<p>A data frame with dimension (<code>n</code> x <code>p+1</code>).  In the
first column contains the <code>n</code> response values and on the following
<code>p</code> columns the explanatory variables specified in the formula.</p>
</td></tr>
<tr><td><code id="fanova.hetero_+3A_formula">formula</code></td>
<td>
<p>as <a href="stats.html#topic+formula">formula</a>.</p>
</td></tr>
<tr><td><code id="fanova.hetero_+3A_pr">pr</code></td>
<td>
<p>If TRUE, print intermediate results.</p>
</td></tr>
<tr><td><code id="fanova.hetero_+3A_contrast">contrast</code></td>
<td>
<p>List of special contrast to be used, by default no special
contrasts are used (<code>contrast</code>=<code>NULL</code>).</p>
</td></tr>
<tr><td><code id="fanova.hetero_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function fits a univariate analysis of variance model and allows
calculate special contrasts defined by the user.  The list of special
contrast to be used for some of the factors in the formula.  Each matrix of
the list has <code>r</code> rows and <code>r-1</code> columns.
</p>
<p>The user can also request special predetermined contrasts, for example using
<code><a href="stats.html#topic+contr.helmert">contr.helmert</a></code>, <code><a href="stats.html#topic+contr.sum">contr.sum</a></code> or
<code><a href="stats.html#topic+contr.treatment">contr.treatment</a></code> functions.
</p>


<h3>Value</h3>

<p>Return: 
</p>

<ul>
<li> <p><code>ans</code>: A list with components including: the Beta estimation <code>Est</code>,
the factor degrees of freedom <code>df1</code>, the residual degrees of freedom
<code>df2</code>, and the <code>p-value</code> for each factor. 
</p>
</li>
<li> <p><code>contrast</code>: List of special contrasts.
</p>
</li></ul>



<h3>Note</h3>

<p>anova.hetero deprecated
</p>
<p>It only works with categorical variables.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Brunner, E., Dette, H., Munk, A. <em>Box-Type Approximations
in Nonparametric Factorial Designs.</em> Journal of the American Statistical
Association, Vol. 92, No. 440 (Dec., 1997), pp. 1494-1502.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fanova.RPm">fanova.RPm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
ind=1 # beetwen 1:150
fdataobj=data.frame(phoneme$learn[["data"]][,ind])
n=dim(fdataobj)[1]
group&lt;-factor(phoneme$classlearn)

#ex 1: real factor and random factor
group.rand=as.factor(sample(rep(1:3,n),n))
f=data.frame(group,group.rand)
mm=data.frame(fdataobj,f)
colnames(mm)=c("value","group","group.rand")
out1=fanova.hetero(object=mm[,-2],value~group.rand,pr=FALSE)
out2=fanova.hetero(object=mm[,-3],value~group,pr=FALSE)
out1
out2

#ex 2: real factor, random factor and  special contrasts
cr5=contr.sum(5)  #each level vs last level
cr3=c(1,0,-1)			#first level vs last level
out.contrast=fanova.hetero(object=mm[,-3],value~group,pr=FALSE,
contrast=list(group=cr5))
out.contrast

## End(Not run)     
</code></pre>

<hr>
<h2 id='fanova.onefactor'>One&ndash;way anova model for functional data</h2><span id='topic+fanova.onefactor'></span><span id='topic+anova.onefactor'></span>

<h3>Description</h3>

<p>One&ndash;way anova model for k independent samples of functional data. 
The function contrasts the null hypothesis of equality of mean functions 
of functional data based on the an asymptotic version of the anova F&ndash;test. 
</p>
<p style="text-align: center;"><code class="reqn">H_0:\, m_1=\ldots=m_k</code>
</p>



<h3>Usage</h3>

<pre><code class='language-R'>fanova.onefactor(
  object,
  group,
  nboot = 100,
  plot = FALSE,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fanova.onefactor_+3A_object">object</code></td>
<td>
<p>functional response data.  fdata class object with <code>n</code> curves.</p>
</td></tr>
<tr><td><code id="fanova.onefactor_+3A_group">group</code></td>
<td>
<p>a factor specifying the class for each curve.</p>
</td></tr>
<tr><td><code id="fanova.onefactor_+3A_nboot">nboot</code></td>
<td>
<p>number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="fanova.onefactor_+3A_plot">plot</code></td>
<td>
<p>if <code>TRUE</code>, plot the mean of each factor level and the results of test.</p>
</td></tr>
<tr><td><code id="fanova.onefactor_+3A_verbose">verbose</code></td>
<td>
<p>if <code>TRUE</code>, print intermediate results.</p>
</td></tr>
<tr><td><code id="fanova.onefactor_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function returns the p&ndash;value of  test using one&ndash;way anova model over <code>nboot</code> runs.
</p>


<h3>Value</h3>

<p>Returns:
</p>

<ul>
<li> <p><code>p-value</code>: Probability of rejecting the null hypothesis H0 at a significance level.
</p>
</li>
<li> <p><code>stat</code>: Statistic value of the test.
</p>
</li>
<li> <p><code>wm</code>: Statistic values of bootstrap resamples.
</p>
</li></ul>



<h3>Note</h3>

<p>anova.onefactor deprecated.
</p>


<h3>Author(s)</h3>

<p>Juan A. Cuesta-Albertos, Manuel Febrero-Bande, Manuel Oviedo de la
Fuente<br /> <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Cuevas, A., Febrero, M., &amp; Fraiman, R. (2004). <em>An anova test for functional data.</em> Computational statistics &amp; data analysis, <b>47</b>(1), 111-122.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fanova.RPm">fanova.RPm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(MCO)
grupo&lt;-MCO$classintact
datos&lt;-MCO$intact
res=fanova.onefactor(datos,grupo,nboot=50,plot=TRUE)
grupo &lt;- MCO$classpermea
datos &lt;- MCO$permea
res=fanova.onefactor(datos,grupo,nboot=50,plot=TRUE)

## End(Not run)  
</code></pre>

<hr>
<h2 id='fanova.RPm'>Functional ANOVA with Random Project.</h2><span id='topic+fanova.RPm'></span><span id='topic+summary.fanova.RPm'></span><span id='topic+anova.RPm'></span>

<h3>Description</h3>

<p>The procedure is based on the analysis of randomly chosen one-dimensional
projections. The function tests ANOVA models for functional data with
continuous covariates and perform special contrasts for the factors in the
formula.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fanova.RPm(
  object,
  formula,
  data.fac,
  RP = min(30, ncol(object)),
  alpha = 0.95,
  zproj = NULL,
  par.zproj = list(norm = TRUE),
  hetero = TRUE,
  pr = FALSE,
  w = rep(1, ncol(object)),
  nboot = 0,
  contrast = NULL,
  ...
)

## S3 method for class 'fanova.RPm'
summary(object, ndec = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fanova.RPm_+3A_object">object</code></td>
<td>
<p>Functional response data.  Object with class fdata with
<code>n</code> curves discretizated in <code>m</code> points. For multivariate problems
<code>object</code> can be a <code>data.frame</code> or a <code>matrix</code></p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_formula">formula</code></td>
<td>
<p>as <a href="stats.html#topic+formula">formula</a> without response.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_data.fac">data.fac</code></td>
<td>
<p>Explanatory variables.  Data frame with dimension (<code>n</code>
x <code>p</code>), where <code>p</code> are the number of factors or covariates
considered.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_rp">RP</code></td>
<td>
<p>Vector of number of random projections.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_alpha">alpha</code></td>
<td>
<p>Confidence level, by default <code>alpha</code>=0.95.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_zproj">zproj</code></td>
<td>
<p>Function for generating the projections or an object that
contains that projections.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_par.zproj">par.zproj</code></td>
<td>
<p>List of parameters for <code>zproj</code> function.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_hetero">hetero</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code> (by default) means heteroskedastic ANOVA.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_pr">pr</code></td>
<td>
<p><code>logical</code>. If <code>TRUE</code> prints intermediate results.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_w">w</code></td>
<td>
<p>Vector of weights (only for multivariate problems).</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_nboot">nboot</code></td>
<td>
<p>Number of bootstrap samples, by default no bootstrap
computations, <code>nboot</code>=0.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_contrast">contrast</code></td>
<td>
<p>List of special contrast to be used ; by default no special
contrasts are used (<code>contrast</code>=<code>NULL</code>).</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="fanova.RPm_+3A_ndec">ndec</code></td>
<td>
<p>Number of decimals.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>zproj</code> allows to change the generator process of the projections. This
can be done through the inclusion of a function or a collection of
projections generated outside the function. By default, for a functional
problem, the function <code><a href="#topic+rproc2fdata">rproc2fdata</a></code> is used. For multivariate problems,
if no function is included, the projections are generated by a normalized
gaussian process of the same dimension as <code>object</code>. Any user function
can be included with the only limitation that the two first parameters are:
</p>

<ul>
<li> <p><code>n</code>: number of projections
</p>
</li>
<li> <p><code>t</code>: discretization points for functional problems
</p>
</li>
<li> <p><code>m</code>: number of columns for multivariate problems.
</p>
</li></ul>

<p>That functions must return a <code>fdata</code> or <code>matrix</code> object
respectively.  
</p>
<p>The function allows user-defined contrasts.  The list of contrast to be used
for some of the factors in the formula.  Each contrast matrix in the list
has <code>r</code> rows, where <code>r</code> is the number of factor levels. The user
can also request special predetermined contrasts, for example using the
<code><a href="stats.html#topic+contr.helmert">contr.helmert</a></code>, <code><a href="stats.html#topic+contr.sum">contr.sum</a></code> or
<code><a href="stats.html#topic+contr.treatment">contr.treatment</a></code> functions.
</p>
<p>The function returns (by default) the significance of the variables using
the Bonferroni test and the False Discovery Rate test. Bootstrap procedure
provides more precision
</p>


<h3>Value</h3>

<p>An object with the following components:<br /> 
</p>

<ul>
<li> <p><code>proj</code>: The projection value of each point on the curves. Matrix with dimensions
(<code>RP</code> x <code>m</code>), where <code>RP</code> is the number of projections and
<code>m</code> is the number of points observed in each projection curve. 
</p>
</li>
<li> <p><code>mins</code>: Minimum number for each random projection. 
</p>
</li>
<li> <p><code>result</code>: p-value for each random projection. 
</p>
</li>
<li> <p><code>test.Bonf</code>: Significance (TRUE or FALSE) for
vector of random projections <code>RP</code> in columns and factors (and special
contrasts) in rows. 
</p>
</li>
<li> <p><code>p.Bonf</code>: p-value for vector of random projections
<code>RP</code> in columns and factors (and special contrasts) in rows.
</p>
</li>
<li> <p><code>test.fdr</code>: False Discovery Rate (TRUE or FALSE) for vector of random
projections <code>RP</code> in columns and factors (and special contrasts) in rows.
</p>
</li>
<li> <p><code>p.fdr</code>: p-value of False Discovery Rate for vector of random
projections <code>RP</code> in columns and factors (and special contrasts) in rows.
</p>
</li>
<li> <p><code>test.Boot</code>: False Discovery Rate (TRUE or FALSE) for vector of random
projections <code>RP</code> in columns and factors (and special contrasts) in rows.
</p>
</li>
<li> <p><code>p.Boot</code>: p-value of Bootstrap sample for vector of random projections
<code>RP</code> in columns and factors (and special contrasts) in rows.
</p>
</li></ul>



<h3>Note</h3>

<p>anova.RPm deprecated.
</p>
<p>If <code>hetero=TRUE</code> then all factors must be categorical.
</p>


<h3>Author(s)</h3>

<p>Juan A. Cuesta-Albertos, Manuel Febrero-Bande, Manuel Oviedo de la
Fuente<br /> <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Cuesta-Albertos, J.A., Febrero-Bande, M. <em>A simple multiway
ANOVA for functional data.</em> TEST 2010, DOI <b>10.1007/s11749-010-0185-3</b>.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fanova.onefactor">fanova.onefactor</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# ex fanova.hetero
data(phoneme)
names(phoneme)
# A MV matrix obtained from functional data
data=as.data.frame(phoneme$learn$data[,c(1,seq(0,150,10)[-1])]) 
group=phoneme$classlearn
n=nrow(data)
group.rand=as.factor(sample(rep(1:3,len=n),n))
RP=c(2,5,15,30)

#ex 1: real factor and random factor
m03=data.frame(group,group.rand)
resul1=fanova.RPm(phoneme$learn,~group+group.rand,m03,RP=c(5,30))
summary(resul1)

#ex 2: real factor with special contrast
m0=data.frame(group)
cr5=contr.sum(5)   #each level vs last level
resul03c1=fanova.RPm(data,~group,m0,contrast=list(group=cr5))
summary(resul03c1)

#ex 3: random factor with special contrast. Same projs as ex 2.
m0=data.frame(group.rand)
zz=resul03c1$proj
cr3=contr.sum(3)   #each level vs last level
resul03c1=fanova.RPm(data,~group.rand,m0,contrast=list(group.rand=cr3),zproj=zz)
summary(resul03c1)

## End(Not run)
  
</code></pre>

<hr>
<h2 id='fda.usc.internal'>fda.usc internal functions</h2><span id='topic+fda.usc.internal'></span><span id='topic+trace.matrix'></span><span id='topic++5B.fdata'></span><span id='topic++5B.fdist'></span><span id='topic++2B.fdata'></span><span id='topic+-.fdata'></span><span id='topic++2A.fdata'></span><span id='topic++2F.fdata'></span><span id='topic+c.fdata'></span><span id='topic++3D+3D.fdata'></span><span id='topic++21+3D.fdata'></span><span id='topic+dim.fdata'></span><span id='topic+ncol.fdata'></span><span id='topic+nrow.fdata'></span><span id='topic+NROW.fdata'></span><span id='topic+NCOL.fdata'></span><span id='topic+length.fdata'></span><span id='topic++5E.fdata'></span><span id='topic+argvals'></span><span id='topic+rangeval'></span><span id='topic+missing.fdata'></span><span id='topic+omit.fdata'></span><span id='topic+omit2.fdata'></span><span id='topic+is.na.fdata'></span><span id='topic+anyNA.fdata'></span><span id='topic+count.na.fdata'></span><span id='topic+colnames.fdata'></span><span id='topic+rownames.fdata'></span><span id='topic+fdata.trace'></span><span id='topic+argvals.equi'></span><span id='topic+unlist_fdata'></span>

<h3>Description</h3>

<p>Internal undocumentation functions for fda.usc package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>trace.matrix(x, na.rm = TRUE)

argvals.equi(tt)

## S3 method for class 'fdata'
fdata1 + fdata2

## S3 method for class 'fdata'
fdata1 - fdata2

## S3 method for class 'fdata'
fdata1 * fdata2

## S3 method for class 'fdata'
fdata1 / fdata2

## S3 method for class 'fdata'
fdataobj[i = TRUE, j = TRUE, drop = FALSE]

## S3 method for class 'fdata'
fdata1 != fdata2

## S3 method for class 'fdata'
fdata1 == fdata2

## S3 method for class 'fdata'
fdataobj ^ pot

## S3 method for class 'fdata'
dim(x)

ncol.fdata(x)

nrow.fdata(x)

## S3 method for class 'fdata'
length(x)

NROW.fdata(x)

NCOL.fdata(x)

rownames.fdata(x)

colnames.fdata(x)

## S3 method for class 'fdata'
c(...)

argvals(fdataobj)

rangeval(fdataobj)

## S3 method for class 'fdist'
fdataobj[i = TRUE, j = TRUE, drop = FALSE]

## S3 method for class 'fdata'
is.na(x)

## S3 method for class 'fdata'
anyNA(x, recursive = FALSE)

count.na.fdata(x)

unlist_fdata(x, recursive = TRUE, use.names = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fda.usc.internal_+3A_x">x</code></td>
<td>
<p><code>matrix</code> or <code>fdata</code> class object.</p>
</td></tr>
<tr><td><code id="fda.usc.internal_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>. Should missing values (including <code>NaN</code>) be removed?</p>
</td></tr>
<tr><td><code id="fda.usc.internal_+3A_tt">tt</code></td>
<td>
<p>Argvals</p>
</td></tr>
<tr><td><code id="fda.usc.internal_+3A_fdataobj">fdataobj</code>, <code id="fda.usc.internal_+3A_fdata1">fdata1</code>, <code id="fda.usc.internal_+3A_fdata2">fdata2</code></td>
<td>
<p><code>fdata</code> class object.</p>
</td></tr>
<tr><td><code id="fda.usc.internal_+3A_i">i</code>, <code id="fda.usc.internal_+3A_j">j</code></td>
<td>
<p>Indices specifying elements to extract, replace. Indices are numeric or character vectors or empty</p>
</td></tr>
<tr><td><code id="fda.usc.internal_+3A_drop">drop</code></td>
<td>
<p>For <code>fdata</code> class object. If TRUE the result is coerced to the lowest possible dimension of  element <code>data</code>. This only works for extracting elements, not for the replacement.</p>
</td></tr>
<tr><td><code id="fda.usc.internal_+3A_pot">pot</code></td>
<td>
<p>Numeric value for exponentiation.</p>
</td></tr>
<tr><td><code id="fda.usc.internal_+3A_...">...</code></td>
<td>
<p><code>fdata</code> objects to be concatenated.</p>
</td></tr>
<tr><td><code id="fda.usc.internal_+3A_recursive">recursive</code></td>
<td>
<p>should <code>anyNA</code> be applied recursively to lists and pairlists? (in  anyNA.fdata function)
<code>logical</code> Should unlisting be applied to list components of x? (in unlist_fdata function).</p>
</td></tr>
<tr><td><code id="fda.usc.internal_+3A_use.names">use.names</code></td>
<td>
<p><code>logical</code> Should names be preserved?</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>argvals.equi</code> function returns <code>TRUE</code> if the argvals are equispaced 
and <code>FALSE</code> in othercase.
</p>


<h3>Note</h3>

<p>In &quot;Ops&quot; functions <code>"+.fdata"</code>, <code>"-.fdata"</code>, <code>"*.fdata"</code> and 
<code>"/.fdata"</code>: The lengths of the objects <code>fdata1</code> and <code>fdata2</code> may
be different because operates recycled into minimum size as necessary.
</p>


<h3>References</h3>

<p>Febrero-Bande,  M., Oviedo de la Fuente, M. (2012).  <em>Statistical Computing
in Functional Data Analysis: The R Package fda.usc.</em>  Journal of Statistical Software, 
51(4), 1-28. <a href="https://doi.org/10.18637/jss.v051.i04">doi:10.18637/jss.v051.i04</a>
</p>

<hr>
<h2 id='fdata'>Converts raw data or other functional data classes into fdata class.</h2><span id='topic+fdata'></span>

<h3>Description</h3>

<p>Create a functional data object of class <code>fdata</code> from (<code>matrix</code>,
<code>data.frame</code>, <code>numeric</code>, <code>integer</code>, <code>fd, fds, fts</code> or
<code>sfts</code>) class data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdata(mdata, argvals = NULL, rangeval = NULL, names = NULL, fdata2d = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdata_+3A_mdata">mdata</code></td>
<td>
<p>Matrix of set cases with dimension (<code>n</code> x <code>m</code>), where
<code>n</code> is the number of curves and <code>m</code> are the points observed in
each curve.</p>
</td></tr>
<tr><td><code id="fdata_+3A_argvals">argvals</code></td>
<td>
<p>Argvals, by default: <code>1:m</code>.</p>
</td></tr>
<tr><td><code id="fdata_+3A_rangeval">rangeval</code></td>
<td>
<p>(optional) Range of discretization points, by default:
range(<code>argvals</code>).</p>
</td></tr>
<tr><td><code id="fdata_+3A_names">names</code></td>
<td>
<p>(optional) list with tree components: <code>main</code> an overall
title, <code>xlab</code> title for <code>x</code> axis and <code>ylab</code> title for
<code>y</code> axis.</p>
</td></tr>
<tr><td><code id="fdata_+3A_fdata2d">fdata2d</code></td>
<td>
<p>TRUE class fdata2d, the functional data is observed in at
least a two grids (the <code>argvals</code> is a list of vectors). By default
<code>fdata2d=FALSE</code> the functional data is observed in a single grid (the
<code>argvals</code> is a vector).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return <code>fdata</code> class object with: 
</p>
 
<ul>
<li> <p><code>"data"</code>: matrix of set cases with dimension (<code>n</code> x <code>m</code>),
where <code>n</code> is the number of curves and <code>m</code> are the points observed
in each curve 
</p>
</li>
<li> <p><code>"rangeval"</code>: the discretizations points values, if not provided: <code>1:m</code> 
</p>
</li>
<li> <p><code>"rangeval"</code>: range of the discretizations points values, by default: range(<code>argvals</code>) 
</p>
</li>
<li> <p><code>"names"</code>: (optional) list with <code>main</code> an overall title, <code>xlab</code>
title for <code>x</code> axis and <code>ylab</code> title for <code>y</code> axis.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).
<em>Statistical Computing in Functional Data Analysis: The R Package
fda.usc.</em> Journal of Statistical Software, 51(4), 1-28.
<a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+plot.fdata">plot.fdata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
mlearn&lt;-phoneme$learn[1:4,1:150]
# Center curves
fdata.c=fdata.cen(mlearn)$Xcen
par(mfrow=c(2,1))
plot(mlearn,type="l")
plot(fdata.c,type="l")

# Convert  from class fda to fdata
bsp1 &lt;- create.bspline.basis(c(1,150),21)
fd1 &lt;- Data2fd(1:150,y=t(mlearn$data),basisobj=bsp1)
fdataobj=fdata(fd1)

# Convert  from class fds, fts or sfts to fdata
#require(fds)
#a=fds(x = 1:20, y = Simulationdata$y, xname = "x", 
# yname = "Simulated value")
#b=fts(x = 15:49, y = Australiasmoothfertility$y, xname = "Age",
#    yname = "Fertility rate")
#c=sfts(ts(as.numeric(ElNino_ERSST_region_1and2$y), frequency = 12), xname = "Month",
#yname = "Sea surface temperature")
#class(a);class(b);class(c)
#fdataobj=fdata(b)

## End(Not run)

</code></pre>

<hr>
<h2 id='fdata.bootstrap'>Bootstrap samples of a functional statistic</h2><span id='topic+fdata.bootstrap'></span><span id='topic+fdata.bootstrap2'></span>

<h3>Description</h3>

<p>provides bootstrap samples for functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdata.bootstrap(
  fdataobj,
  statistic = func.mean,
  alpha = 0.05,
  nb = 200,
  smo = 0,
  draw = FALSE,
  draw.control = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdata.bootstrap_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code>fdata</code> class object.</p>
</td></tr>
<tr><td><code id="fdata.bootstrap_+3A_statistic">statistic</code></td>
<td>
<p>Sample statistic. It must be a function that returns an
object of class <code>fdata</code>. By default, it uses sample mean
<code><a href="#topic+func.mean">func.mean</a></code>.  See <code><a href="#topic+Descriptive">Descriptive</a></code> for other
statistics.</p>
</td></tr>
<tr><td><code id="fdata.bootstrap_+3A_alpha">alpha</code></td>
<td>
<p>Significance value.</p>
</td></tr>
<tr><td><code id="fdata.bootstrap_+3A_nb">nb</code></td>
<td>
<p>Number of bootstrap resamples.</p>
</td></tr>
<tr><td><code id="fdata.bootstrap_+3A_smo">smo</code></td>
<td>
<p>The smoothing parameter for the bootstrap samples as a proportion
of the sample variance matrix.</p>
</td></tr>
<tr><td><code id="fdata.bootstrap_+3A_draw">draw</code></td>
<td>
<p>If <code>TRUE</code>, plot the bootstrap samples and the statistic.</p>
</td></tr>
<tr><td><code id="fdata.bootstrap_+3A_draw.control">draw.control</code></td>
<td>
<p>List that it specifies the <code>col</code>, <code>lty</code> and
<code>lwd</code> for objects: <code>fdataobj</code>, <code>statistic</code>, <code>IN</code> and
<code>OUT</code>.</p>
</td></tr>
<tr><td><code id="fdata.bootstrap_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code><a href="#topic+fdata.bootstrap">fdata.bootstrap</a></code> computes a confidence ball using bootstrap in
the following way: 
</p>
 
<ul>
<li><p> Let <code class="reqn">X_1(t),\ldots,X_n(t)</code> be the original data and
<code class="reqn">T=T(X_1(t),\ldots,X_n(t))</code> be the sample statistic.
</p>
</li>
<li><p> Calculate the <code>nb</code> bootstrap resamples
<code class="reqn">\left\{X_{1}^{*}(t),\cdots,X_n^*(t)\right\}</code>,
using the following scheme: <code class="reqn">X_i^*(t)=X_i(t)+Z(t)</code>, 
where <code class="reqn">Z(t)</code> is normally distributed with mean 0 and covariance matrix
<code class="reqn">\gamma\Sigma_x</code>, where <code class="reqn">\Sigma_x</code> is the
covariance matrix of <code class="reqn">\left\{X_1(t),\ldots,X_n(t)\right\}</code> 
and <code class="reqn">\gamma</code> is the smoothing parameter.  
</p>
</li>
<li><p> Let <code class="reqn">T^{*j}=T(X^{*j}_1(t),...,X^{*j}_n(t))</code>
be the estimate using the <code class="reqn">j</code> resample.  
</p>
</li>
<li><p> Compute <code class="reqn">d(T,T^{*j})</code>, <code class="reqn">j=1,\ldots,nb</code>. Define the bootstrap 
confidence ball of level <code class="reqn">1-\alpha</code> as <code class="reqn">CB(\alpha)=X\in E</code> 
such that <code class="reqn">d(T,X)\leq d_{\alpha}</code> being
<code class="reqn">d_{\alpha}</code> the quantile <code class="reqn">(1-\alpha)</code> of the
distances between the bootstrap resamples and the sample estimate. 
</p>
</li></ul>

<p>The <code>fdata.bootstrap</code> function allows us to define a statistic
calculated on the <code>nb</code> resamples, control the degree of smoothing by
<code>smo</code> argument and represent the confidence ball with level
<code class="reqn">1-\alpha</code> as those resamples that fulfill the condition of
belonging to <code class="reqn">CB(\alpha)</code>.  The <code>statistic</code> used by
default is the mean (<code><a href="#topic+func.mean">func.mean</a></code>) but also other depth-based
functions can be used (see <code>help(Descriptive)</code>).
</p>


<h3>Value</h3>


<ul>
<li> <p><code>statistic</code>: <code>fdata</code> class object with the statistic estimate from <code>nb</code> bootstrap samples.
</p>
</li>
<li> <p><code>dband</code>: Bootstrap estimate of <code>(1-alpha)%</code> distance.
</p>
</li>
<li> <p><code>rep.dist</code>: Distance from every replicate.
</p>
</li>
<li> <p><code>resamples</code>: <code>fdata</code> class object with the bootstrap resamples.
</p>
</li>
<li> <p><code>fdataobj</code>: <code>fdata</code> class object.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Cuevas A., Febrero-Bande, M. and Fraiman, R. (2007).
<em>Robust estimation and classification for functional data via
projection-based depth notions.</em> Computational Statistics 22, 3: 481-496.
</p>
<p>Cuevas A., Febrero-Bande, M., Fraiman R. 2006.  <em>On the use of
bootstrap for estimating functions with functional data.</em> Computational
Statistics and Data Analysis 51: 1063-1074.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+Descriptive">Descriptive</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
absorp&lt;-tecator$absorp.fdata
# Time consuming
#Bootstrap for Trimmed Mean with depth mode
out.boot=fdata.bootstrap(absorp,statistic=func.trim.FM,nb=200,draw=TRUE)
names(out.boot)
#Bootstrap for Median with with depth mode
control=list("col"=c("grey","blue","cyan"),"lty"=c(2,1,1),"lwd"=c(1,3,1))
out.boot=fdata.bootstrap(absorp,statistic=func.med.mode,
draw=TRUE,draw.control=control)

## End(Not run)
</code></pre>

<hr>
<h2 id='fdata.cen'>Functional data centred (subtract the mean of each discretization point)</h2><span id='topic+fdata.cen'></span>

<h3>Description</h3>

<p>The function fdata.cen centres the curves by subtracting the functional
mean.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdata.cen(fdataobj, meanX = func.mean(fdataobj))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdata.cen_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fdata.cen_+3A_meanx">meanX</code></td>
<td>
<p>The functional mean subtracted in the <code>fdatobj</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return:<br /> two <code>fdata</code> class objects with: </p>
<table role = "presentation">
<tr><td><code>Xcen</code></td>
<td>
<p> The
centered fdata.</p>
</td></tr> <tr><td><code>meanX</code></td>
<td>
<p> Functional mean substracted.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+fdata">fdata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
mlearn&lt;-phoneme[["learn"]][13:15,]
fdata.c=fdata.cen(mlearn)$Xcen
par(mfrow=c(1,2))
plot(mlearn,type="l")
plot(fdata.c,type="l")

## End(Not run)

</code></pre>

<hr>
<h2 id='fdata.deriv'>Computes the derivative of functional data object.</h2><span id='topic+fdata.deriv'></span>

<h3>Description</h3>

<p>Computes the derivative of functional data.
</p>
 
<ul>
<li><p> If method =<em>&quot;bspline&quot;</em>, <em>&quot;exponential&quot;</em>, <em>&quot;fourier&quot;</em>, 
<em>&quot;monomial&quot;</em> or <em>&quot;polynomial&quot;</em>.
<code>fdata.deriv</code> function creates a basis to represent the functional
data. 
The functional data are converted to class <code>fd</code> using the <a href="fda.html#topic+Data2fd">Data2fd</a>
function and the basis indicated in the <code>method</code>.
Finally, the function calculates the derivative of order <code>nderiv</code> of
curves using <a href="fda.html#topic+deriv.fd">deriv.fd</a> function.<br /> 
</p>
</li>
<li><p> If <code>method</code>=<em>&quot;fmm&quot;</em>, <em>&quot;periodic&quot;</em>, <em>&quot;natural&quot;</em> or
<em>&quot;monoH.FC&quot;</em> is used <code><a href="stats.html#topic+splinefun">splinefun</a></code> function.
</p>
</li>
<li><p> If <code>method</code>=<em>&quot;diff&quot;</em>, raw derivation is applied.  Not recommended to
use this method when the values are not equally spaced.<br /> 
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>fdata.deriv(
  fdataobj,
  nderiv = 1,
  method = "bspline",
  class.out = "fdata",
  nbasis = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdata.deriv_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fdata.deriv_+3A_nderiv">nderiv</code></td>
<td>
<p>Order of derivation, by defalult <code>nderiv</code>=1.</p>
</td></tr>
<tr><td><code id="fdata.deriv_+3A_method">method</code></td>
<td>
<p>Type of derivative method, for more information see
<b>details</b>.</p>
</td></tr>
<tr><td><code id="fdata.deriv_+3A_class.out">class.out</code></td>
<td>
<p>Class of functional data returned: <code>fdata</code> or
<code>fd</code> class.</p>
</td></tr>
<tr><td><code id="fdata.deriv_+3A_nbasis">nbasis</code></td>
<td>
<p>Number of Basis for <code>fdatataobj\$DATA</code>. It is only used
if method =<em>&quot;bspline&quot;</em>, <em>&quot;exponential&quot;</em>, <em>&quot;fourier&quot;</em>,
<em>&quot;monomial&quot;</em> or <em>&quot;polynomial&quot;</em></p>
</td></tr>
<tr><td><code id="fdata.deriv_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the derivative of functional data of <code>fd</code> class if
<code>class.out</code>=&quot;<em>fd</em>&quot; or  <code>fdata</code> class if <code>class.out</code>=&quot;<em>fdata</em>&quot;.
</p>


<h3>See Also</h3>

<p>See also <a href="fda.html#topic+deriv.fd">deriv.fd</a> , <code><a href="stats.html#topic+splinefun">splinefun</a></code> and
<code><a href="#topic+fdata">fdata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tecator)
absorp=tecator$absorp.fdata
tecator.fd1=fdata2fd(absorp)
tecator.fd2=fdata2fd(absorp,"fourier",9)
tecator.fd3=fdata2fd(absorp,"fourier",nbasis=9,nderiv=1)
#tecator.fd1;tecator.fd2;tecator.fd3
tecator.fdata1=fdata(tecator.fd1)
tecator.fdata2=fdata(tecator.fd2)
tecator.fdata3=fdata(tecator.fd3)
tecator.fdata4=fdata.deriv(absorp,nderiv=1,method="bspline",
class.out='fdata',nbasis=9)
tecator.fd4=fdata.deriv(tecator.fd3,nderiv=0,class.out='fd',nbasis=9)
plot(tecator.fdata4)
plot(fdata.deriv(absorp,nderiv=1,method="bspline",class.out='fd',nbasis=11))

</code></pre>

<hr>
<h2 id='fdata.methods'>fdata  S3 Group Generic Functions</h2><span id='topic+fdata.methods'></span><span id='topic+Math.fdata'></span><span id='topic+Ops.fdata'></span><span id='topic+Summary.fdata'></span><span id='topic+split.fdata'></span><span id='topic+order.fdata'></span><span id='topic+is.fdata'></span>

<h3>Description</h3>

<p>fdata Group generic methods defined for four specified groups
of functions, Math, Ops, Summary and Complex.
</p>
<p>order.fdata and split.fdata: A wrapper for the order and split  function for fdata object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fdata'
Math(x, ...)

## S3 method for class 'fdata'
Ops(e1, e2 = NULL)

## S3 method for class 'fdata'
Summary(..., na.rm = FALSE)

## S3 method for class 'fdata'
split(x, f, drop = FALSE, ...)

order.fdata(y, fdataobj, na.last = TRUE, decreasing = FALSE)

is.fdata(fdataobj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdata.methods_+3A_x">x</code></td>
<td>
<p>An <code>fdata</code> object containing values to be divided into groups or an <code>list</code> of <code>fdata</code> objects  containing values to be combine by rows in a to be flatten one <code>fdata</code> object.</p>
</td></tr>
<tr><td><code id="fdata.methods_+3A_...">...</code></td>
<td>
<p>Further arguments passed to methods.</p>
</td></tr>
<tr><td><code id="fdata.methods_+3A_e1">e1</code>, <code id="fdata.methods_+3A_e2">e2</code></td>
<td>
<p><code>fdata</code> class object</p>
</td></tr>
<tr><td><code id="fdata.methods_+3A_na.rm">na.rm</code></td>
<td>
<p><code>logical</code>: should missing values be removed?</p>
</td></tr>
<tr><td><code id="fdata.methods_+3A_f">f</code></td>
<td>
<p>a factor in the sense that as.factor(f) defines the grouping, or a list of such factors in which case their interaction is used for the grouping.</p>
</td></tr>
<tr><td><code id="fdata.methods_+3A_drop">drop</code></td>
<td>
<p><code>logical</code> indicating if levels that do not occur should be dropped (if f is a factor or a list).</p>
</td></tr>
<tr><td><code id="fdata.methods_+3A_y">y</code></td>
<td>
<p>A sequence of numeric, complex, character or logical vectors, all of the same length, or a classed R object.</p>
</td></tr>
<tr><td><code id="fdata.methods_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code>fdata</code> class object.</p>
</td></tr>
<tr><td><code id="fdata.methods_+3A_na.last">na.last</code></td>
<td>
<p>for controlling the treatment of NAs. If TRUE, missing values in the data are put last; if FALSE, they are put first; if NA, they are removed; if &quot;keep&quot; they are kept with rank NA.</p>
</td></tr>
<tr><td><code id="fdata.methods_+3A_decreasing">decreasing</code></td>
<td>
<p><code>logical</code> Should the sort order be increasing or decreasing?.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In <code>order.fdata</code> the funcional data is ordered w.r.t the sample order of the values of vector.
</p>
<p><code>split.fdata</code> divides the data in the fdata object <code>x</code> into the groups defined by <code>f</code>.
</p>


<h3>Value</h3>

 
<ul>
<li><p> split.fdata: The value returned from <code>split</code> is a list of fdata objects 
containing the values for the groups. The components of the list are named by
the levels of f (after converting to a factor, or if already a factor and 
drop = TRUE, dropping unused levels).\
</p>
</li>
<li><p> order.fdata:  returns the functional data <code>fdataobj</code>  w.r.t. a permutation 
which rearranges its first argument into ascending or descending order.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero Bande and Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See  <a href="base.html#topic+Summary">Summary</a> and <a href="base.html#topic+Complex">Complex</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
absor&lt;-tecator$absorp.fdata
absor2&lt;-fdata.deriv(absor,1)
absor&lt;-absor2[1:5,1:4]
absor2&lt;-absor2[1:5,1:4]
sum(absor)
round(absor,4)
log1&lt;-log(absor)

fdataobj&lt;-fdata(MontrealTemp)
fac&lt;-factor(c(rep(1,len=17),rep(2,len=17)))
a1&lt;-split(fdataobj,fac)
dim(a1[[1]]);dim(a1[[2]])

## End(Not run)

</code></pre>

<hr>
<h2 id='fdata2basis'>Compute fucntional coefficients from functional data represented in a base of functions</h2><span id='topic+fdata2basis'></span><span id='topic+summary.basis.fdata'></span>

<h3>Description</h3>

<p>Compute fucntional coefficients from functional data (<code><a href="#topic+fdata">fdata</a></code> class object) 
represented in a basis (fixed of data-driven basis).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdata2basis(fdataobj, basis, method = c("grid", "inprod"))

## S3 method for class 'basis.fdata'
summary(object, draw = TRUE, index = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdata2basis_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fdata2basis_+3A_basis">basis</code></td>
<td>
<p>a functional basis object defining the basis</p>
</td></tr>
<tr><td><code id="fdata2basis_+3A_method">method</code></td>
<td>
<p>character string, if it is &quot;grid&quot; the fdata object is evaluated in the grid (<code>argvals</code> of fdata),
if it is &quot;inprod&quot; the basis representation of functional data is computed by inner product 
(<code><a href="#topic+inprod.fdata">inprod.fdata</a>(fdataobj,basis)</code>).</p>
</td></tr>
<tr><td><code id="fdata2basis_+3A_object">object</code></td>
<td>
<p><code>basis.fdata</code> class object calculated by: <code><a href="#topic+fdata2basis">fdata2basis</a></code></p>
</td></tr>
<tr><td><code id="fdata2basis_+3A_draw">draw</code></td>
<td>
<p>logical, original curves  and their basis representation are plotted</p>
</td></tr>
<tr><td><code id="fdata2basis_+3A_index">index</code></td>
<td>
<p>vector, by default (if NULL) the first n curves are plotted, where n = min(4, length(fdataobj)). 
Otherwise, index vector indicates taht curvesare plotted.</p>
</td></tr>
<tr><td><code id="fdata2basis_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>fdata2basis</code> function returns: 
</p>

<ul>
<li> <p><code>coef</code>:  A matrix or two-dimensional array of coefficients.
</p>
</li>
<li> <p><code>basis</code>:  Basis of <code><a href="#topic+fdata">fdata</a></code> class evaluated on the same grid as <code>fdataobj</code>. 
</p>
</li></ul>

<p>And  summary function return: 
</p>

<ul>
<li> <p><code>R</code>: a matrix with a measure similar to R-sq for each curve aproximation (by row) and number of basis elements (by column).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente  <a href="mailto:manuel.oviedo@usc.es">manuel.oviedo@usc.es</a>
</p>


<h3>See Also</h3>

<p>Inverse function: <code><a href="#topic+gridfdata">gridfdata</a></code>.
Alternative method: <code><a href="#topic+fdata2pc">fdata2pc</a></code>, <code><a href="#topic+fdata2pls">fdata2pls</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
T &lt;- 71
S &lt;- 51
tj &lt;- round(seq(0,1,len=T),3)
si &lt;- round(seq(0,1,len=S),3)
beta1 &lt;- outer(si,tj,function(si,tj){exp(-5*abs((tj-si)/5))})
nbasis.s =7
nbasis.t=11
base.s &lt;- create.fourier.basis(c(0,1),nbasis=nbasis.s)
base.t &lt;- create.fourier.basis(c(0,1),nbasis=nbasis.t)
y1 &lt;- fdata(rbind(log(1+tj),1-5*(tj-0.5)^2),argvals=tj,rangeval=c(0,1))
aa &lt;- fdata2basis(y1,base.t,method="inprod")
summary(aa)
plot(gridfdata(aa$coefs,aa$basis))
lines(y1,lwd=2,col=c(3,4),lty=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='fdata2fd'>Converts fdata class object into fd class object</h2><span id='topic+fdata2fd'></span>

<h3>Description</h3>

<p>Converts <code>fdata</code> class object into <code>fd</code> class object using
<code>Data2fd</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdata2fd(
  fdataobj,
  type.basis = NULL,
  nbasis = NULL,
  nderiv = 0,
  lambda = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdata2fd_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fdata2fd_+3A_type.basis">type.basis</code></td>
<td>
<p>Type of basis. A function <code>create."type.basis".basis</code>
must exists. By default, <code>bspline</code> basis is used.</p>
</td></tr>
<tr><td><code id="fdata2fd_+3A_nbasis">nbasis</code></td>
<td>
<p>Number of basis which is used in <code>create.basis</code> function.</p>
</td></tr>
<tr><td><code id="fdata2fd_+3A_nderiv">nderiv</code></td>
<td>
<p>Order of derivation which is used in <code>deriv.fd</code> function
(optional).</p>
</td></tr>
<tr><td><code id="fdata2fd_+3A_lambda">lambda</code></td>
<td>
<p>Weight on the smoothing operator specified by <code>nderiv</code>.</p>
</td></tr>
<tr><td><code id="fdata2fd_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return an object of the <code>fd</code> class.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).
<em>Statistical Computing in Functional Data Analysis: The R Package
fda.usc.</em> Journal of Statistical Software, 51(4), 1-28.
<a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+fdata">fdata</a></code> and <a href="fda.html#topic+Data2fd">Data2fd</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
mlearn&lt;-phoneme$learn[1]
fdata2=fdata2fd(mlearn)
class(mlearn)
class(fdata2)
fdata3=fdata2fd(mlearn,type.basis="fourier",nbasis=7)
plot(mlearn)
lines(fdata2,col=2)
lines(fdata3,col=3)
fdata5=fdata2fd(mlearn,nderiv=1)

## End(Not run)
</code></pre>

<hr>
<h2 id='fdata2pc'>Principal components for functional data</h2><span id='topic+fdata2pc'></span>

<h3>Description</h3>

<p>Compute (penalized) principal components for functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdata2pc(fdataobj, ncomp = 2, norm = TRUE, lambda = 0, P = c(0, 0, 1), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdata2pc_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fdata2pc_+3A_ncomp">ncomp</code></td>
<td>
<p>Number of principal components.</p>
</td></tr>
<tr><td><code id="fdata2pc_+3A_norm">norm</code></td>
<td>
<p>=TRUE the norm of eigenvectors <code>(rotation)</code> is 1.</p>
</td></tr>
<tr><td><code id="fdata2pc_+3A_lambda">lambda</code></td>
<td>
<p>Amount of penalization. Default value is 0, i.e. no
penalization is used.</p>
</td></tr>
<tr><td><code id="fdata2pc_+3A_p">P</code></td>
<td>
<p>If P is a vector: coefficients to define the penalty matrix object.
By default P=c(0,0,1) penalize the second derivative (curvature) or
acceleration.  If P is a matrix: the penalty matrix object.</p>
</td></tr>
<tr><td><code id="fdata2pc_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Smoothing is achieved by penalizing the integral of the square of the
derivative of order m over rangeval: </p>
 <ul>
<li><p> m = 0 penalizes the
squared difference from 0 of the function </p>
</li>
<li><p> m = 1 penalize the square of
the slope or velocity </p>
</li>
<li><p> m = 2 penalize the squared acceleration </p>
</li>
<li><p> m
= 3 penalize the squared rate of change of acceleration </p>
</li></ul>



<h3>Value</h3>


<ul>
<li> <p><code>d</code>: The standard deviations of the functional principal components. 
</p>
</li>
<li> <p><code>rotation</code>: Also known as loadings. A <code>fdata</code> class object whose rows contain the eigenvectors. 
</p>
</li>
<li> <p><code>x</code>: Also known as scores. The value of the rotated functional data is returned.
</p>
</li>
<li> <p><code>fdataobj.cen</code>: The centered <code>fdataobj</code> object. 
</p>
</li>
<li> <p><code>mean</code>: The functional mean of the <code>fdataobj</code> object. 
</p>
</li>
<li> <p><code>l</code>: Vector of indices of principal components. 
</p>
</li>
<li> <p><code>C</code>: The matched call. 
</p>
</li>
<li> <p><code>lambda</code>: Amount of penalization. 
</p>
</li>
<li> <p><code>P</code>: Penalty matrix.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@usc.es">manuel.oviedo@usc.es</a>
</p>


<h3>References</h3>

<p>Venables, W. N. and B. D. Ripley (2002). <em>Modern Applied
Statistics with S</em>. Springer-Verlag.
</p>
<p>N. Kraemer, A.-L. Boulsteix, and G. Tutz (2008). Penalized Partial Least
Squares with Applications to B-Spline Transformations and Functional Data.
Chemometrics and Intelligent Laboratory Systems, 94, 60 - 69.
<a href="https://doi.org/10.1016/j.chemolab.2008.06.009">doi:10.1016/j.chemolab.2008.06.009</a>
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as <a href="base.html#topic+svd">svd</a> and <a href="stats.html#topic+varimax">varimax</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Not run: 
 n= 100;tt= seq(0,1,len=51)
 x0&lt;-rproc2fdata(n,tt,sigma="wiener")
 x1&lt;-rproc2fdata(n,tt,sigma=0.1)
 x&lt;-x0*3+x1
 pc=fdata2pc(x,lambda=1)
 summary(pc)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='fdata2pls'>Partial least squares components for functional data.</h2><span id='topic+fdata2pls'></span>

<h3>Description</h3>

<p>Compute penalized partial least squares (PLS) components for functional
data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fdata2pls(fdataobj, y, ncomp = 2, lambda = 0, P = c(0, 0, 1), norm = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fdata2pls_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fdata2pls_+3A_y">y</code></td>
<td>
<p>Scalar response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="fdata2pls_+3A_ncomp">ncomp</code></td>
<td>
<p>The number of components to include in the model.</p>
</td></tr>
<tr><td><code id="fdata2pls_+3A_lambda">lambda</code></td>
<td>
<p>Amount of penalization. Default value is 0, i.e. no
penalization is used.</p>
</td></tr>
<tr><td><code id="fdata2pls_+3A_p">P</code></td>
<td>
<p>If P is a vector: coefficients to define the penalty matrix object.
By default <code class="reqn">P=c(0,0,1)</code> penalizes the second derivative (curvature) or
acceleration.  If P is a matrix: the penalty matrix object.</p>
</td></tr>
<tr><td><code id="fdata2pls_+3A_norm">norm</code></td>
<td>
<p>If <code>TRUE</code> the <code>fdataobj</code> are centered and scaled.</p>
</td></tr>
<tr><td><code id="fdata2pls_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>norm=TRUE</code>, computes the PLS by
<code>NIPALS</code> algorithm and the Degrees of Freedom using the Krylov
representation of PLS, see Kraemer and Sugiyama (2011).<br /> 
If <code>norm=FALSE</code>, computes the PLS by Orthogonal Scores Algorithm and
the Degrees of Freedom are the number of components <code>ncomp</code>, see
Martens and Naes (1989).
</p>


<h3>Value</h3>

<p><code>fdata2pls</code> function return:
</p>
<p>The <code>fdata2pls</code> function returns: 
</p>

<ul>
<li> <p><code>df</code>: Degree of freedom.
</p>
</li>
<li> <p><code>rotation</code>: <code><a href="#topic+fdata">fdata</a></code> class object. 
</p>
</li>
<li> <p><code>x</code>: The value of the rotated data (the centered data multiplied by the rotation matrix) is returned.
</p>
</li>
<li> <p><code>fdataobj.cen</code>: The centered <code>fdataobj</code> object. 
</p>
</li>
<li> <p><code>mean</code>: Mean of <code>fdataobj</code>. 
</p>
</li>
<li> <p><code>l</code>: Vector of indices of principal components. 
</p>
</li>
<li> <p><code>C</code>: The matched call.
</p>
</li>
<li> <p><code>lambda</code>: Amount of penalization. 
</p>
</li>
<li> <p><code>P</code>: Penalty matrix.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente  <a href="mailto:manuel.oviedo@usc.es">manuel.oviedo@usc.es</a>
</p>


<h3>References</h3>

<p>Kraemer, N., Sugiyama M. (2011). <em>The Degrees of Freedom of
Partial Least Squares Regression</em>. Journal of the American Statistical
Association. Volume 106, 697-705.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>
<p>Martens, H., Naes, T. (1989) <em>Multivariate calibration.</em> Chichester:
Wiley.
</p>


<h3>See Also</h3>

<p>Used in:
<code><a href="#topic+fregre.pls">fregre.pls</a></code>, <code><a href="#topic+fregre.pls.cv">fregre.pls.cv</a></code>.
Alternative method: <code><a href="#topic+fdata2pc">fdata2pc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
n= 500;tt= seq(0,1,len=101)
x0&lt;-rproc2fdata(n,tt,sigma="wiener")
x1&lt;-rproc2fdata(n,tt,sigma=0.1)
x&lt;-x0*3+x1
beta = tt*sin(2*pi*tt)^2
fbeta = fdata(beta,tt)
y&lt;-inprod.fdata(x,fbeta)+rnorm(n,sd=0.1)
pls1=fdata2pls(x,y)
pls1$call
summary(pls1)
pls1$l
norm.fdata(pls1$rotation)

## End(Not run)
</code></pre>

<hr>
<h2 id='FDR'>False Discorvery Rate (FDR)</h2><span id='topic+FDR'></span><span id='topic+pvalue.FDR'></span>

<h3>Description</h3>

<p>Compute the False Discovery Rate for a vector of p-values and alpha value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>FDR(pvalues = NULL, alpha = 0.95, dep = 1)

pvalue.FDR(pvalues = NULL, dep = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="FDR_+3A_pvalues">pvalues</code></td>
<td>
<p>Vector of p-values</p>
</td></tr>
<tr><td><code id="FDR_+3A_alpha">alpha</code></td>
<td>
<p>Alpha value (level of significance).</p>
</td></tr>
<tr><td><code id="FDR_+3A_dep">dep</code></td>
<td>
<p>Parameter dependence test. By default <code>dep = 1</code>, direct
dependence between tests.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>FDR</code> method is used for multiple hypothesis testing to correct
problems of multiple contrasts.<br /> If <code>dep = 1</code>, the tests are
positively correlated, for example when many tests are the same contrast.
<br /> If <code>dep &lt; 1</code> the tests are negatively correlated.
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>out.FDR=TRUE</code>: If there are significative differences.
</p>
</li>
<li> <p><code>pv.FDR</code>: p-value for False Discovery Rate test.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Febrero-Bande, M.  and Oviedo de la Fuente, M.
</p>


<h3>References</h3>

<p>Benjamini, Y., Yekutieli, D. (2001). <em>The control of the
false discovery rate in multiple testing under dependency</em>. Annals of
Statistics. 29 (4): 1165-1188. DOI:10.1214/aos/1013699998.
</p>


<h3>See Also</h3>

<p>Function used in <code><a href="#topic+fanova.RPm">fanova.RPm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> p=seq(1:50)/1000
 FDR(p)
 pvalue.FDR(p)
 FDR(p,alpha=0.9999)
 FDR(p,alpha=0.9)
 FDR(p,alpha=0.9,dep=-1)
</code></pre>

<hr>
<h2 id='fEqDistrib.test'>Tests for checking the equality of distributions between two functional populations.</h2><span id='topic+fEqDistrib.test'></span><span id='topic+XYRP.test'></span><span id='topic+MMD.test'></span><span id='topic+MMDA.test'></span>

<h3>Description</h3>

<p>Three tests for the equality of distributions of two populations are provided. The null hypothesis is that the two populations are the same
</p>


<h3>Usage</h3>

<pre><code class='language-R'>XYRP.test(X.fdata, Y.fdata, nproj = 10, npc = 5, test = c("KS", "AD"))

MMD.test(
  X.fdata,
  Y.fdata,
  metric = "metric.lp",
  B = 1000,
  alpha = 0.95,
  kern = "RBF",
  ops.metric = list(lp = 2),
  draw = FALSE
)

MMDA.test(
  X.fdata,
  Y.fdata,
  metric = "metric.lp",
  B = 1000,
  alpha = 0.95,
  kern = "RBF",
  ops.metric = list(lp = 2),
  draw = FALSE
)

fEqDistrib.test(
  X.fdata,
  Y.fdata,
  metric = "metric.lp",
  method = c("Exch", "WildB"),
  B = 5000,
  ops.metric = list(lp = 2),
  iboot = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fEqDistrib.test_+3A_x.fdata">X.fdata</code></td>
<td>
<p><code>fdata</code> object containing the curves from the first population.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_y.fdata">Y.fdata</code></td>
<td>
<p><code>fdata</code> object containing the curves from the second population.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_nproj">nproj</code></td>
<td>
<p>Number of projections for <code>XYRP.test</code>.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_npc">npc</code></td>
<td>
<p>The number of principal components employed for generating the random projections.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_test">test</code></td>
<td>
<p>For <code>XYRP.test</code> &quot;KS&quot; and/or &quot;AD&quot; for computing Kolmogorov-Smirnov or Anderson-Darling p-values in the projections.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_metric">metric</code></td>
<td>
<p>Character with the metric function for computing distances among curves.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_b">B</code></td>
<td>
<p>Number of bootstrap or Monte Carlo replicas.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_alpha">alpha</code></td>
<td>
<p>Confidence level for computing the threshold. By default =0.95.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_kern">kern</code></td>
<td>
<p>For <code>MMDA.test</code> &quot;RBF&quot; or &quot;metric&quot; for indicating the use of Radial Basis Function or directly, the distances.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_ops.metric">ops.metric</code></td>
<td>
<p>List of parameters to be used with <code>metric</code>.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_draw">draw</code></td>
<td>
<p>By default, FALSE. Plots the density of the bootstrap replicas jointly with the statistic.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_method">method</code></td>
<td>
<p>In <code>fEqDistrib.test</code> a character indicating the bootstrap method for computing the distribution under H0.
&quot;Exch&quot; for Exchangeable bootstrap and &quot;WildB&quot; for Wild Bootstrap. By default, both are provided.</p>
</td></tr>
<tr><td><code id="fEqDistrib.test_+3A_iboot">iboot</code></td>
<td>
<p>In <code>fEqDistrib.test</code> returns the bootstrap replicas.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+XYRP.test">XYRP.test</a></code> computes the p-values using random projections. Requires <code>kSamples</code> library. 
<code><a href="#topic+MMD.test">MMD.test</a></code> computes Maximum Mean Discrepancy p-values using permutations (see Sejdinovic et al, (2013)) and <code><a href="#topic+MMDA.test">MMDA.test</a></code> 
does the same using an asymptotic approximation. 
<code><a href="#topic+fEqDistrib.test">fEqDistrib.test</a></code> checks the equality of distributions using an embedding in a RKHS and two bootstrap approximations for 
calibration.
</p>


<h3>Value</h3>

<p>A list with the following components by function:
</p>

<ul>
<li> <p><code>XYRP.test</code>, <code>FDR.pv</code>: p-value using FDR, <code>proj.pv</code>: Matrix of p-values obtained for projections.
</p>
</li>
<li> <p><code>MMD.test</code>, <code>MMDA.test</code>: <code>stat</code>: Statistic, <code>p.value</code>: p-value, <code>thresh</code>: Threshold at level <code>alpha</code>.
</p>
</li>
<li> <p><code>fEqDistrib.test</code>, <code>result</code>: <code>data.frame</code> with columns <code>Stat</code> and <code>p.value</code>, 
<code>Boot</code>: <code>data.frame</code> with bootstrap replicas if <code>iboot=TRUE</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.febrero@usc.es">manuel.febrero@usc.es</a>
</p>


<h3>References</h3>

<p>Sejdinovic, D., Sriperumbudur, B., Gretton, A., Fukumizu, K. <em>Equivalence of distance-based and RKHS-based statistics in Hypothesis Testing</em> The Annals of Statistics, 2013. 
DOI <b>10.1214/13-AOS1140</b>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fmean.test.fdata">fmean.test.fdata</a>, <a href="#topic+cov.test.fdata">cov.test.fdata</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tt=seq(0,1,len=51)
bet=0
mu1=fdata(10*tt*(1-tt)^(1+bet),tt)
mu2=fdata(10*tt^(1+bet)*(1-tt),tt) 
fsig=1
X=rproc2fdata(100,tt,mu1,sigma="vexponential",par.list=list(scale=0.2,theta=0.35))
Y=rproc2fdata(100,tt,mu2,sigma="vexponential",par.list=list(scale=0.2*fsig,theta=0.35))
fmean.test.fdata(X,Y,npc=-.98,draw=TRUE)
cov.test.fdata(X,Y,npc=5,draw=TRUE)
bet=0.1
mu1=fdata(10*tt*(1-tt)^(1+bet),tt)
mu2=fdata(10*tt^(1+bet)*(1-tt),tt) 
fsig=1.5
X=rproc2fdata(100,tt,mu1,sigma="vexponential",par.list=list(scale=0.2,theta=0.35))
Y=rproc2fdata(100,tt,mu2,sigma="vexponential",par.list=list(scale=0.2*fsig,theta=0.35))
fmean.test.fdata(X,Y,npc=-.98,draw=TRUE)
cov.test.fdata(X,Y,npc=5,draw=TRUE)
XYRP.test(X,Y,nproj=15)
MMD.test(X,Y,B=1000)
fEqDistrib.test(X,Y,B=1000)

## End(Not run)

</code></pre>

<hr>
<h2 id='fEqMoments.test'>Tests for checking the equality of means and/or covariance between two populations under gaussianity.</h2><span id='topic+fEqMoments.test'></span><span id='topic+fmean.test.fdata'></span><span id='topic+cov.test.fdata'></span>

<h3>Description</h3>

<p>Two tests for the equality of means and covariances of two populations are provided.
Both tests are constructed under gaussianity following Horvath &amp; Kokoszka, 2012, Chapter 5.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fmean.test.fdata(
  X.fdata,
  Y.fdata,
  method = c("X2", "Boot"),
  npc = 5,
  alpha = 0.95,
  B = 1000,
  draw = FALSE
)

cov.test.fdata(
  X.fdata,
  Y.fdata,
  method = c("X2", "Boot"),
  npc = 5,
  alpha = 0.95,
  B = 1000,
  draw = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fEqMoments.test_+3A_x.fdata">X.fdata</code></td>
<td>
<p><code>fdata</code> object containing the curves from the first population.</p>
</td></tr>
<tr><td><code id="fEqMoments.test_+3A_y.fdata">Y.fdata</code></td>
<td>
<p><code>fdata</code> object containing the curves from the second population.</p>
</td></tr>
<tr><td><code id="fEqMoments.test_+3A_method">method</code></td>
<td>
<p>c(&quot;X2&quot;,&quot;Boot&quot;). &quot;X2&quot; includes the asymptotic distribution. &quot;Boot&quot; computes the bootstrap approximation.</p>
</td></tr>
<tr><td><code id="fEqMoments.test_+3A_npc">npc</code></td>
<td>
<p>The number of principal components employed. If <code>npc</code> is negative and 0&lt;<code>abs(npc)</code>&lt;1, the number of components 
are determined for explaining, at least, <code>abs(p)</code>% of variability.</p>
</td></tr>
<tr><td><code id="fEqMoments.test_+3A_alpha">alpha</code></td>
<td>
<p>Confidence level. By default =0.95.</p>
</td></tr>
<tr><td><code id="fEqMoments.test_+3A_b">B</code></td>
<td>
<p>Number of bootstrap replicas when method=&quot;Boot&quot;.</p>
</td></tr>
<tr><td><code id="fEqMoments.test_+3A_draw">draw</code></td>
<td>
<p>By default, <code>FALSE</code>. Plots the density of the bootstrap replicas jointly with the statistic.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code><a href="#topic+fmean.test.fdata">fmean.test.fdata</a></code> computes the test for equality of means. 
<code><a href="#topic+cov.test.fdata">cov.test.fdata</a></code> computes the test for equality of covariance operators.
Both tests have asymptotic distributions under the null related with chi-square distribution. Also, a 
parametric bootstrap procedure is implemented in both cases.
</p>


<h3>Value</h3>

<p>Return a list with:
</p>

<ul>
<li> <p><code>stat</code>: Value of the statistic.
</p>
</li>
<li> <p><code>pvalue</code>: P-values for the test.
</p>
</li>
<li> <p><code>vcrit</code>: Critical cutoff for rejecting the null hypothesis.
</p>
</li>
<li> <p><code>p</code>: Degrees of freedom for X2 statistic.
</p>
</li>
<li> <p><code>B</code>: Number of bootstrap replicas.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.febrero@usc.es">manuel.febrero@usc.es</a>
</p>


<h3>References</h3>

<p>Inference for Functional Data with Applications. Horvath, L and Kokoszka, P. (2012). Springer.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+fanova.RPm">fanova.RPm</a>, <a href="#topic+fanova.onefactor">fanova.onefactor</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tt=seq(0,1,len=51)
bet=0
mu1=fdata(10*tt*(1-tt)^(1+bet),tt)
mu2=fdata(10*tt^(1+bet)*(1-tt),tt) 
fsig=1
X=rproc2fdata(100,tt,mu1,sigma="vexponential",par.list=list(scale=0.2,theta=0.35))
Y=rproc2fdata(100,tt,mu2,sigma="vexponential",par.list=list(scale=0.2*fsig,theta=0.35))
fmean.test.fdata(X,Y,npc=-.98,draw=TRUE)
cov.test.fdata(X,Y,npc=5,draw=TRUE)
bet=0.1
mu1=fdata(10*tt*(1-tt)^(1+bet),tt)
mu2=fdata(10*tt^(1+bet)*(1-tt),tt) 
fsig=1.5
X=rproc2fdata(100,tt,mu1,sigma="vexponential",par.list=list(scale=0.2,theta=0.35))
Y=rproc2fdata(100,tt,mu2,sigma="vexponential",par.list=list(scale=0.2*fsig,theta=0.35))
fmean.test.fdata(X,Y,npc=-.98,draw=TRUE)
cov.test.fdata(X,Y,npc=5,draw=TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='flm.Ftest'>F-test for the Functional Linear Model with scalar response</h2><span id='topic+flm.Ftest'></span><span id='topic+Ftest.statistic'></span>

<h3>Description</h3>

<p>The function <code>flm.Ftest</code> tests the null hypothesis of no interaction between a functional covariate and a scalar response inside the Functional Linear Model (FLM): <code class="reqn">Y=\big&lt;X,\beta\big&gt;+\epsilon</code>. The null hypothesis is <code class="reqn">H_0:\,\beta=0</code> and the alternative is <code class="reqn">H_1:\,\beta\neq 0</code>. 
The null hypothesis is tested by a functional extension of the classical F-test (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Ftest.statistic(X.fdata, Y)

flm.Ftest(X.fdata, Y, B = 5000, verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flm.Ftest_+3A_x.fdata">X.fdata</code></td>
<td>
<p>Functional covariate for the FLM. The object must be in the class <code><a href="#topic+fdata">fdata</a></code>.</p>
</td></tr>
<tr><td><code id="flm.Ftest_+3A_y">Y</code></td>
<td>
<p>Scalar response for the FLM. Must be a vector with the same number of elements as functions are in <code>X.fdata</code>.</p>
</td></tr>
<tr><td><code id="flm.Ftest_+3A_b">B</code></td>
<td>
<p>Number of bootstrap replicates to calibrate the distribution of the test statistic. <code>B=5000</code> replicates are the recommended for carry out the test, although for exploratory analysis (<b>not inferential</b>), an acceptable less time-consuming option is <code>B=500</code>.</p>
</td></tr>
<tr><td><code id="flm.Ftest_+3A_verbose">verbose</code></td>
<td>
<p>Either to show or not information about computing progress.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Functional Linear Model with scalar response (FLM), is defined as
<code class="reqn">Y=\big&lt;X,\beta\big&gt;+\epsilon</code>, for a functional process <code class="reqn">X</code> 
such that <code class="reqn">E[X(t)]=0</code>, <code class="reqn">E[X(t)\epsilon]=0</code> for all <code class="reqn">t</code>
and for a scalar variable <code class="reqn">Y</code> such that <code class="reqn">E[Y]=0</code>.
The <em>functional F-test</em> is defined as
</p>
<p style="text-align: center;"><code class="reqn">T_n=\bigg\|\frac{1}{n}\sum_{i=1}^n (X_i-\bar X)(Y_i-\bar Y)\bigg\|,</code>
</p>
<p> where <code class="reqn">\bar X</code> is the functional mean of <code class="reqn">X</code>, <code class="reqn">\bar Y</code> is the ordinary mean of <code class="reqn">Y</code> and <code class="reqn">\|\cdot\|</code> is the <code class="reqn">L^2</code> functional norm.
The statistic is computed with the function <code>Ftest.statistic</code>. The distribution of the 
test statistic is approximated by a wild bootstrap resampling on the residuals, using the 
<em>golden section bootstrap</em>.
</p>


<h3>Value</h3>

<p>The value for <code>Ftest.statistic</code> is simply the F-test statistic. The value for <code>flm.Ftest</code> is an object with class <code>"htest"</code> whose underlying structure is a list containing the following components:
</p>

<ul>
<li> <p><code>statistic</code>: The value of the F-test statistic.
</p>
</li>
<li> <p><code>boot.statistics</code>: A vector of length <code>B</code> with the values of the bootstrap F-test statistics.
</p>
</li>
<li> <p><code>p.value</code>: The p-value of the test.
</p>
</li>
<li> <p><code>method</code>: The character string &quot;Functional Linear Model F-test&quot;.
</p>
</li>
<li> <p><code>B</code>: The number of bootstrap replicates used.
</p>
</li>
<li> <p><code>data.name</code>: The character string &quot;Y=&lt;X,0&gt;+e&quot;.
</p>
</li></ul>



<h3>Note</h3>

<p>No NA's are allowed neither in the functional covariate nor in the scalar response.
</p>


<h3>Author(s)</h3>

<p>Eduardo Garcia-Portugues. Please, report bugs and suggestions to <a href="mailto:eduardo.garcia.portugues@uc3m.es">eduardo.garcia.portugues@uc3m.es</a>
</p>


<h3>References</h3>

<p>Garcia-Portugues, E., Gonzalez-Manteiga, W. and Febrero-Bande, M. (2014). A goodness&ndash;of&ndash;fit test for the functional linear model with scalar response. Journal of Computational and Graphical Statistics, 23(3), 761-778. <a href="https://doi.org/10.1080/10618600.2013.812519">doi:10.1080/10618600.2013.812519</a>
</p>
<p>Gonzalez-Manteiga, W., Gonzalez-Rodriguez, G., Martinez-Calvo, A. and Garcia-Portugues, E. Bootstrap independence test for functional linear models. arXiv:1210.1072. <a href="https://arxiv.org/abs/1210.1072">https://arxiv.org/abs/1210.1072</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rwild">rwild</a></code>, <code><a href="#topic+flm.test">flm.test</a></code>, <code><a href="#topic+dfv.test">dfv.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Simulated example ##
X=rproc2fdata(n=50,t=seq(0,1,l=101),sigma="OU")
beta0=fdata(mdata=rep(0,length=101)+rnorm(101,sd=0.05),
argvals=seq(0,1,l=101),rangeval=c(0,1))
beta1=fdata(mdata=cos(2*pi*seq(0,1,l=101))-(seq(0,1,l=101)-0.5)^2+
rnorm(101,sd=0.05),argvals=seq(0,1,l=101),rangeval=c(0,1))

# Null hypothesis holds
Y0=drop(inprod.fdata(X,beta0)+rnorm(50,sd=0.1))
# Null hypothesis does not hold
Y1=drop(inprod.fdata(X,beta1)+rnorm(50,sd=0.1))

# Do not reject H0
flm.Ftest(X,Y0,B=100)
flm.Ftest(X,Y0,B=5000)

# Reject H0
flm.Ftest(X,Y1,B=100)
flm.Ftest(X,Y1,B=5000)

## End(Not run)
</code></pre>

<hr>
<h2 id='flm.test'>Goodness-of-fit test for the Functional Linear Model with scalar response</h2><span id='topic+flm.test'></span>

<h3>Description</h3>

<p>The function <code>flm.test</code> tests the composite null hypothesis of
a Functional Linear Model with scalar response (FLM),
</p>
<p style="text-align: center;"><code class="reqn">H_0:\,Y=\big&lt;X,\beta\big&gt;+\epsilon,</code>
</p>
<p>  versus
a general alternative. If <code class="reqn">\beta=\beta_0</code> is provided, then the 
simple hypothesis <code class="reqn">H_0:\,Y=\big&lt;X,\beta_0\big&gt;+\epsilon</code> is tested.
The testing of the null hypothesis is done by a Projected Cramer-von Mises statistic (see Details).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flm.test(
  X.fdata,
  Y,
  beta0.fdata = NULL,
  B = 5000,
  est.method = "pls",
  p = NULL,
  type.basis = "bspline",
  verbose = TRUE,
  plot.it = TRUE,
  B.plot = 100,
  G = 200,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flm.test_+3A_x.fdata">X.fdata</code></td>
<td>
<p>Functional covariate for the FLM. The object must be in the class 
<code><a href="#topic+fdata">fdata</a></code>.</p>
</td></tr>
<tr><td><code id="flm.test_+3A_y">Y</code></td>
<td>
<p>Scalar response for the FLM. Must be a vector with the same number of elements
as functions are in <code>X.fdata</code>.</p>
</td></tr>
<tr><td><code id="flm.test_+3A_beta0.fdata">beta0.fdata</code></td>
<td>
<p>Functional parameter for the simple null hypothesis, in the <code><a href="#topic+fdata">fdata</a></code> class. 
Recall that the <code>argvals</code> and <code>rangeval</code> arguments of <code>beta0.fdata</code> must be the same
of <code>X.fdata</code>. A possibility to do this is to consider, for example for <code class="reqn">\beta_0=0</code> 
(the simple null hypothesis of no interaction),
<code>beta0.fdata=fdata(mdata=rep(0,length(X.fdata$argvals)),</code><code>argvals=X.fdata$argvals,rangeval=X.fdata$rangeval)</code>.
If <code>beta0.fdata=NULL</code> (default), the function will test for the composite null hypothesis.</p>
</td></tr>
<tr><td><code id="flm.test_+3A_b">B</code></td>
<td>
<p>Number of bootstrap replicates to calibrate the distribution of the test statistic.
<code>B=5000</code> replicates are the recommended for carry out the test, although for exploratory analysis
(<b>not inferential</b>), an acceptable less time-consuming option is <code>B=500</code>.</p>
</td></tr>
<tr><td><code id="flm.test_+3A_est.method">est.method</code></td>
<td>
<p>Estimation method for the unknown parameter <code class="reqn">\beta</code>, 
only used in the composite case. Mainly, there are two options: specify the number of basis 
elements for the estimated <code class="reqn">\beta</code> by <code>p</code> or optimally select <code>p</code> by a
data-driven criteria (see Details section for discussion). Then, it must be one of the following 
methods:
</p>

<ul>
<li> <p><code>"pc"</code>: If <code>p</code>, the number of basis elements, is given, then <code class="reqn">\beta</code> is estimated by <code><a href="#topic+fregre.pc">fregre.pc</a></code>. Otherwise, an optimum <code>p</code> is chosen using <code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code> and the <code>"SICc"</code> criteria.
</p>
</li>
<li> <p><code>"pls"</code>: If <code>p</code> is given, <code class="reqn">\beta</code> is estimated by <code><a href="#topic+fregre.pls">fregre.pls</a></code>. Otherwise, an optimum <code>p</code> is chosen using <code><a href="#topic+fregre.pls.cv">fregre.pls.cv</a></code> and the <code>"SICc"</code> criteria. 
This is the default argument as it has been checked empirically that provides a good balance between the performance of the test and the estimation of <code class="reqn">\beta</code>.
</p>
</li>
<li> <p><code>"basis"</code>: If <code>p</code> is given, <code class="reqn">\beta</code> is estimated by <code><a href="#topic+fregre.basis">fregre.basis</a></code>. Otherwise, an optimum <code>p</code> is chosen using <code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code> and the <code>"GCV.S"</code> criteria. In these functions, the same basis for the arguments <code>basis.x</code> and <code>basis.b</code> is considered.
The type of basis used will be the given by the argument <code>type.basis</code> and must be one of the class of <code>create.basis</code>. Further arguments passed to <a href="fda.html#topic+create.basis">create.basis</a> (not <code>rangeval</code> that is taken as the <code>rangeval</code> of <code>X.fdata</code>), can be passed throughout <code>...</code>.
</p>
</li></ul>
</td></tr>
<tr><td><code id="flm.test_+3A_p">p</code></td>
<td>
<p>Number of elements of the basis considered. If it is not given, an optimal <code>p</code> will be chosen using a specific criteria (see <code>est.method</code> and <code>type.basis</code> arguments).</p>
</td></tr>
<tr><td><code id="flm.test_+3A_type.basis">type.basis</code></td>
<td>
<p>Type of basis used to represent the functional process. Depending on the hypothesis, it will have a different interpretation:
</p>

<ul>
<li><p> Simple hypothesis. One of these options:
</p>

<ul>
<li> <p><code>"bspline"</code>: If <code>p</code> is given, the functional process is expressed in a basis of <code>p</code> B-splines. If not, an optimal <code>p</code> will be chosen by <code><a href="#topic+optim.basis">optim.basis</a></code>, using the <code>"GCV.S"</code> criteria.
</p>
</li>
<li> <p><code>"fourier"</code>: If <code>p</code> is given, the functional process is expressed in a basis of <code>p</code> Fourier functions. If not, an optimal <code>p</code> will be chosen by <code><a href="#topic+optim.basis">optim.basis</a></code>, using the <code>"GCV.S"</code> criteria.
</p>
</li>
<li> <p><code>"pc"</code>: <code>p</code> must be given. Expresses the functional process in a basis of <code>p</code> principal components.
</p>
</li>
<li> <p><code>"pls"</code>: <code>p</code> must be given. Expresses the functional process in a basis of <code>p</code> partial least squares.
</p>
</li></ul>

<p>Although other basis types supported by <a href="fda.html#topic+create.basis">create.basis</a> are possible, <code>"bspline"</code> and <code>"fourier"</code> are recommended. Other basis types may cause incompatibilities.
</p>
</li>
<li><p> Composite hypothesis. This argument is only used when <code>est.method="basis"</code> and, in this case, it specifies the type of basis used in the basis estimation method of the functional parameter. Again, basis
<code>"bspline"</code> and <code>"fourier"</code> are recommended, as other basis types may cause incompatibilities.
</p>
</li></ul>
</td></tr>
<tr><td><code id="flm.test_+3A_verbose">verbose</code></td>
<td>
<p>Either to show or not information about computing progress.</p>
</td></tr>
<tr><td><code id="flm.test_+3A_plot.it">plot.it</code></td>
<td>
<p>Either to show or not a graph of the observed trajectory, 
and the bootstrap trajectories under the null composite hypothesis, of the 
process <code class="reqn">R_n(\cdot)</code> (see Details). Note that if <code>plot.it=TRUE</code>, 
the function takes more time to run.</p>
</td></tr>
<tr><td><code id="flm.test_+3A_b.plot">B.plot</code></td>
<td>
<p>Number of bootstrap trajectories to show in the resulting plot of the test.
As the trajectories shown are the first <code>B.plot</code> of <code>B</code>, <code>B.plot</code> must be 
lower or equal to <code>B</code>.</p>
</td></tr>
<tr><td><code id="flm.test_+3A_g">G</code></td>
<td>
<p>Number of projections used to compute the trajectories of the process
<code class="reqn">R_n(\cdot)</code> by Monte Carlo.</p>
</td></tr>
<tr><td><code id="flm.test_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <a href="fda.html#topic+create.basis">create.basis</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Functional Linear Model with scalar response (FLM), is defined as 
<code class="reqn">Y=\big&lt;X,\beta\big&gt;+\epsilon</code>, for a functional process 
<code class="reqn">X</code> such that <code class="reqn">E[X(t)]=0</code>, <code class="reqn">E[X(t)\epsilon]=0</code>
for all <code class="reqn">t</code> and for a scalar variable <code class="reqn">Y</code> such that <code class="reqn">E[Y]=0</code>.
Then, the test assumes that <code>Y</code> and <code>X.fdata</code> are <b>centred</b> and will automatically 
center them. So, bear in mind that when you apply the test for <code>Y</code> and <code>X.fdata</code>, 
actually,  you are applying it to <code>Y-mean(Y)</code> and <code>fdata.cen(X.fdata)$Xcen</code>.
The test statistic corresponds to the Cramer-von Mises norm of the <em>Residual Marked 
empirical Process based on Projections</em> <code class="reqn">R_n(u,\gamma)</code> defined in 
Garcia-Portugues <em>et al.</em> (2014). 
The expression of this process in a <code class="reqn">p</code>-truncated basis of the space <code class="reqn">L^2[0,T]</code>
leads to the <code class="reqn">p</code>-multivariate process <code class="reqn">R_{n,p}\big(u,\gamma^{(p)}\big)</code>, 
whose Cramer-von Mises norm is computed.
The choice of an appropriate <code class="reqn">p</code> to represent the functional process <code class="reqn">X</code>, 
in case that is not provided, is done via the estimation of <code class="reqn">\beta</code> for the composite 
hypothesis. For the simple hypothesis, as no estimation of <code class="reqn">\beta</code> is done, the choice 
of <code class="reqn">p</code> depends only on the functional process <code class="reqn">X</code>. As the result of the test may 
change for different <code class="reqn">p</code>'s, we recommend to use an automatic criterion to select <code class="reqn">p</code> 
instead of provide a fixed one.
The distribution of the test statistic is approximated by a wild bootstrap resampling on the 
residuals, using the <em>golden section bootstrap</em>.
Finally, the graph shown if <code>plot.it=TRUE</code> represents the observed trajectory, and the 
bootstrap trajectories under the null, of the process RMPP <em>integrated on the projections</em>:
</p>
<p style="text-align: center;"><code class="reqn">R_n(u)\approx\frac{1}{G}\sum_{g=1}^G R_n(u,\gamma_g),</code>
</p>

<p>where <code class="reqn">\gamma_g</code> are simulated as Gaussians processes. This gives a graphical idea of
how <em>distant</em> is the observed trajectory from the null hypothesis.
</p>


<h3>Value</h3>

<p>An object with class <code>"htest"</code> whose underlying structure is a list containing 
the following components:
</p>

<ul>
<li> <p><code>statistic</code>: The value of the test statistic.
</p>
</li>
<li> <p><code>boot.statistics</code>: A vector of length <code>B</code> with the values of the bootstrap test statistics.
</p>
</li>
<li> <p><code>p.value</code>: The p-value of the test.
</p>
</li>
<li> <p><code>method</code>: The method used.
</p>
</li>
<li> <p><code>B</code>: The number of bootstrap replicates used.
</p>
</li>
<li> <p><code>type.basis</code>: The type of basis used.
</p>
</li>
<li> <p><code>beta.est</code>: The estimated functional parameter <code class="reqn">\beta</code> in the composite 
hypothesis. For the simple hypothesis, the given <code>beta0.fdata</code>.
</p>
</li>
<li> <p><code>p</code>: The number of basis elements passed or automatically chosen.
</p>
</li>
<li> <p><code>ord</code>: The optimal order for PC and PLS given by <code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code> and  <code><a href="#topic+fregre.pls.cv">fregre.pls.cv</a></code>. For other methods, it is set to <code>1:p</code>.
</p>
</li>
<li> <p><code>data.name</code>: The character string &quot;Y=&lt;X,b&gt;+e&quot;.
</p>
</li></ul>



<h3>Note</h3>

<p>No NA's are allowed neither in the functional covariate nor in the scalar response.
</p>


<h3>Author(s)</h3>

<p>Eduardo Garcia-Portugues. Please, report bugs and suggestions to
<a href="mailto:edgarcia@est-econ.uc3m.es">edgarcia@est-econ.uc3m.es</a>
</p>


<h3>References</h3>

<p>Escanciano, J. C. (2006). A consistent diagnostic test for regression models using projections. Econometric Theory, 22, 1030-1051. <a href="https://doi.org/10.1017/S0266466606060506">doi:10.1017/S0266466606060506</a>
</p>
<p>Garcia-Portugues, E., Gonzalez-Manteiga, W. and Febrero-Bande, M. (2014). A goodness&ndash;of&ndash;fit test for the functional linear model with scalar response. Journal of Computational and Graphical Statistics, 23(3), 761-778. <a href="https://doi.org/10.1080/10618600.2013.812519">doi:10.1080/10618600.2013.812519</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Adot">Adot</a></code>, <code><a href="#topic+PCvM.statistic">PCvM.statistic</a></code>, <code><a href="#topic+rwild">rwild</a></code>, 
<code><a href="#topic+flm.Ftest">flm.Ftest</a></code>, <code><a href="#topic+dfv.test">dfv.test</a></code>,
<code><a href="#topic+fregre.pc">fregre.pc</a></code>, <code><a href="#topic+fregre.pls">fregre.pls</a></code>, <code><a href="#topic+fregre.basis">fregre.basis</a></code>, 
<code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code>, <code><a href="#topic+fregre.pls.cv">fregre.pls.cv</a></code>,
<code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code>, <code><a href="#topic+optim.basis">optim.basis</a></code>, 
<a href="fda.html#topic+create.basis">create.basis</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Simulated example #
X=rproc2fdata(n=100,t=seq(0,1,l=101),sigma="OU")
beta0=fdata(mdata=cos(2*pi*seq(0,1,l=101))-(seq(0,1,l=101)-0.5)^2+
            rnorm(101,sd=0.05),argvals=seq(0,1,l=101),rangeval=c(0,1))
Y=inprod.fdata(X,beta0)+rnorm(100,sd=0.1)

dev.new(width=21,height=7)
par(mfrow=c(1,3))
plot(X,main="X")
plot(beta0,main="beta0")
plot(density(Y),main="Density of Y",xlab="Y",ylab="Density")
rug(Y)

## Not run: 
# Composite hypothesis: do not reject FLM
pcvm.sim=flm.test(X,Y,B=50,B.plot=50,G=100,plot.it=TRUE)
pcvm.sim
flm.test(X,Y,B=5000)
 
# Estimated beta
dev.new()
plot(pcvm.sim$beta.est)

# Simple hypothesis: do not reject beta=beta0
flm.test(X,Y,beta0.fdata=beta0,B=50,B.plot=50,G=100)
flm.test(X,Y,beta0.fdata=beta0,B=5000) 

# AEMET dataset #
data(aemet)
# Remove the 5\
dev.new()
res.FM=depth.FM(aemet$temp,draw=TRUE)
qu=quantile(res.FM$dep,prob=0.05)
l=which(res.FM$dep&lt;=qu)
lines(aemet$temp[l],col=3)
aemet$df$name[l]

# Data without outliers 
wind.speed=apply(aemet$wind.speed$data,1,mean)[-l]
temp=aemet$temp[-l]
# Exploratory analysis: accept the FLM
pcvm.aemet=flm.test(temp,wind.speed,est.method="pls",B=100,B.plot=50,G=100)
pcvm.aemet

# Estimated beta
dev.new()
plot(pcvm.aemet$beta.est,lwd=2,col=2)
# B=5000 for more precision on calibration of the test: also accept the FLM
flm.test(temp,wind.speed,est.method="pls",B=5000) 

# Simple hypothesis: rejection of beta0=0? Limiting p-value...
dat=rep(0,length(temp$argvals))
flm.test(temp,wind.speed, beta0.fdata=fdata(mdata=dat,argvals=temp$argvals,
                                            rangeval=temp$rangeval),B=100)
flm.test(temp,wind.speed, beta0.fdata=fdata(mdata=dat,argvals=temp$argvals,
                                            rangeval=temp$rangeval),B=5000) 
                                            
# Tecator dataset #
data(tecator)
names(tecator)
absorp=tecator$absorp.fdata
ind=1:129 # or ind=1:215
x=absorp[ind,]
y=tecator$y$Fat[ind]
tt=absorp[["argvals"]]

# Exploratory analysis for composite hypothesis with automatic choose of p
pcvm.tecat=flm.test(x,y,B=100,B.plot=50,G=100)
pcvm.tecat

# B=5000 for more precision on calibration of the test: also reject the FLM
flm.test(x,y,B=5000) 

# Distribution of the PCvM statistic
plot(density(pcvm.tecat$boot.statistics),lwd=2,xlim=c(0,10),
              main="PCvM distribution", xlab="PCvM*",ylab="Density")
rug(pcvm.tecat$boot.statistics)
abline(v=pcvm.tecat$statistic,col=2,lwd=2)
legend("top",legend=c("PCvM observed"),lwd=2,col=2)

# Simple hypothesis: fixed p
dat=rep(0,length(x$argvals))
flm.test(x,y,beta0.fdata=fdata(mdata=dat,argvals=x$argvals,
                               rangeval=x$rangeval),B=100,p=11)
                               
# Simple hypothesis, automatic choose of p
flm.test(x,y,beta0.fdata=fdata(mdata=dat,argvals=x$argvals,
                               rangeval=x$rangeval),B=100)
flm.test(x,y,beta0.fdata=fdata(mdata=dat,argvals=x$argvals,
                               rangeval=x$rangeval),B=5000)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.basis'>Functional Regression with scalar response using basis representation.</h2><span id='topic+fregre.basis'></span>

<h3>Description</h3>

<p>Computes functional regression between functional explanatory variable
<code class="reqn">X(t)</code> and scalar response <code class="reqn">Y</code> using basis representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.basis(
  fdataobj,
  y,
  basis.x = NULL,
  basis.b = NULL,
  lambda = 0,
  Lfdobj = vec2Lfd(c(0, 0), rtt),
  weights = rep(1, n),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.basis_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fregre.basis_+3A_y">y</code></td>
<td>
<p>Scalar response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis_+3A_basis.x">basis.x</code></td>
<td>
<p>Basis for functional explanatory data <code>fdataobj</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis_+3A_basis.b">basis.b</code></td>
<td>
<p>Basis for functional beta parameter.</p>
</td></tr>
<tr><td><code id="fregre.basis_+3A_lambda">lambda</code></td>
<td>
<p>A roughness penalty. By default, no penalty <code>lambda=0</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis_+3A_lfdobj">Lfdobj</code></td>
<td>
<p>See <a href="fda.html#topic+eval.penalty">eval.penalty</a>.</p>
</td></tr>
<tr><td><code id="fregre.basis_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.basis_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">Y=\big&lt;X,\beta\big&gt;+\epsilon=\int_{T}{X(t)\beta(t)dt+\epsilon}</code>
</p>
 
<p>where <code class="reqn"> \big&lt; \cdot , \cdot \big&gt;</code> denotes the inner product on
<code class="reqn">L_2</code> and <code class="reqn">\epsilon</code> are random errors with mean zero, finite
variance <code class="reqn">\sigma^2</code> and <code class="reqn">E[X(t)\epsilon]=0</code>.
</p>
<p>The function uses the basis representation proposed by Ramsay and Silverman (2005) to model the
relationship between the scalar response and the functional covariate by
basis representation of the observed functional data
<code class="reqn">X(t)\approx\sum_{k=1}^{k_{n1}} c_k \xi_k(t)</code> and the unknown
functional parameter <code class="reqn">\beta(t)\approx\sum_{k=1}^{k_{n2}} b_k
\phi_k(t)</code>. <br />
</p>
<p>The functional linear models estimated by the expression: </p>
<p style="text-align: center;"><code class="reqn">\hat{y}=
\big&lt; X,\hat{\beta} \big&gt; =
C^{T}\psi(t)\phi^{T}(t)\hat{b}=\tilde{X}\hat{b}</code>
</p>
<p> where
<code class="reqn">\tilde{X}(t)=C^{T}\psi(t)\phi^{T}(t)</code>, and
<code class="reqn">\hat{b}=(\tilde{X}^{T}\tilde{X})^{-1}\tilde{X}^{T}y</code>
and so,
<code class="reqn">\hat{y}=\tilde{X}\hat{b}=\tilde{X}(\tilde{X}^{T}\tilde{X})^{-1}\tilde{X}^{T}y=Hy</code>
where <code class="reqn">H</code> is the hat matrix with degrees of freedom: <code class="reqn">df=tr(H)</code>.<br />
</p>
<p>If <code class="reqn">\lambda&gt;0</code> then <code>fregre.basis</code> incorporates a
roughness penalty: <br />
<code class="reqn">\hat{y}=\tilde{X}\hat{b}=\tilde{X}(\tilde{X}^{T}\tilde{X}+\lambda
R_0)^{-1}\tilde{X}^{T}y= H_{\lambda}y</code> where <code class="reqn">R_0</code> is the penalty matrix.<br />
</p>
<p>This function allows covariates of class <code>fdata</code>, <code>matrix</code>,
<code>data.frame</code> or directly covariates of class <code>fd</code>.  The function
also gives default values to arguments <code>basis.x</code> and <code>basis.b</code> for
representation on the basis of functional data <code class="reqn">X(t)</code> and the functional
parameter <code class="reqn">\beta(t)</code>, respectively.
</p>
<p>If <code>basis=</code><code>NULL</code> creates the <code>bspline</code> basis by
<a href="fda.html#topic+create.bspline.basis">create.bspline.basis</a>. <br /> If the functional covariate
<code>fdataobj</code> is a matrix or data.frame, it creates an object of class
&quot;fdata&quot; with default attributes, see <code><a href="#topic+fdata">fdata</a></code>.<br /> If
<code>basis.x$type=``fourier''</code> and <code>basis.b$type=``fourier''</code>, the
basis are orthonormal and the function decreases the number of fourier basis
elements on the <code class="reqn">min(k_{n1},k_{n2})</code>, where
<code class="reqn">k_{n1}</code> and <code class="reqn">k_{n2}</code> are the number of basis element of
<code>basis.x</code> and <code>basis.b</code> respectively.
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>call</code>: The matched call. 
</p>
</li>
<li> <p><code>coefficients</code>: A named vector of coefficients.
</p>
</li>
<li> <p><code>residuals</code>: <code>y</code> minus <code>fitted values</code>. 
</p>
</li>
<li> <p><code>fitted.values</code>: Estimated scalar response. 
</p>
</li>
<li> <p><code>beta.est</code>: Estimated beta parameter of class <code>fd</code>. 
</p>
</li>
<li> <p><code>weights</code>: (only for weighted fits) the specified weights. 
</p>
</li>
<li> <p><code>df.residual</code>: The residual degrees of freedom. 
</p>
</li>
<li> <p><code>r2</code>: Coefficient of determination. 
</p>
</li>
<li> <p><code>sr2</code>: Residual variance. 
</p>
</li>
<li> <p><code>Vp</code>: Estimated covariance matrix for the parameters.
</p>
</li>
<li> <p><code>H</code>: Hat matrix. 
</p>
</li>
<li> <p><code>y</code>: Response.
</p>
</li>
<li> <p><code>fdataobj</code>: Functional explanatory data of class <code>fdata</code>. 
</p>
</li>
<li> <p><code>a.est</code>: Intercept parameter estimated. 
</p>
</li>
<li> <p><code>x.fd</code>: Centered functional explanatory data of class <code>fd</code>. 
</p>
</li>
<li> <p><code>basis.b</code>: Basis used for beta parameter estimation. 
</p>
</li>
<li> <p><code>lambda.opt</code>: A roughness penalty.
</p>
</li>
<li> <p><code>Lfdobj</code>: Order of a derivative or a linear differential operator. 
</p>
</li>
<li> <p><code>P</code>: Penalty matrix. 
</p>
</li>
<li> <p><code>lm</code>: Return <code>lm</code> object.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em>
Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code>,
<code><a href="#topic+summary.fregre.fd">summary.fregre.fd</a></code> and <code><a href="#topic+predict.fregre.fd">predict.fregre.fd</a></code>.<br />
Alternative method: <code><a href="#topic+fregre.pc">fregre.pc</a></code> and <code><a href="#topic+fregre.np">fregre.np</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# fregre.basis
data(tecator)
names(tecator)
absorp=tecator$absorp.fdata
ind=1:129
x=absorp[ind,]
y=tecator$y$Fat[ind]
tt=absorp[["argvals"]]
res1=fregre.basis(x,y)
summary(res1)
basis1=create.bspline.basis(rangeval=range(tt),nbasis=19)
basis2=create.bspline.basis(rangeval=range(tt),nbasis=9)
res5=fregre.basis(x,y,basis1,basis2)
summary(res5)
x.d2=fdata.deriv(x,nbasis=19,nderiv=1,method="bspline",class.out="fdata")
res7=fregre.basis(x.d2,y,basis1,basis2)
summary(res7)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.basis.cv'>Cross-validation Functional Regression with scalar response using basis
representation.</h2><span id='topic+fregre.basis.cv'></span>

<h3>Description</h3>

<p>Computes functional regression between functional explanatory variables and
scalar response using basis representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.basis.cv(
  fdataobj,
  y,
  basis.x = NULL,
  basis.b = NULL,
  type.basis = NULL,
  lambda = 0,
  Lfdobj = vec2Lfd(c(0, 0), rtt),
  type.CV = GCV.S,
  par.CV = list(trim = 0),
  weights = rep(1, n),
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.basis.cv_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_y">y</code></td>
<td>
<p>Scalar response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_basis.x">basis.x</code></td>
<td>
<p>Basis for functional explanatory data <code>fdataobj</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_basis.b">basis.b</code></td>
<td>
<p>Basis for functional beta parameter.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_type.basis">type.basis</code></td>
<td>
<p>A vector of character string which determines type of
basis. By default <em>&quot;bspline&quot;</em>. It is only used when <code>basis.x</code> or
<code>basis.b</code> are a vector of number of basis considered.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_lambda">lambda</code></td>
<td>
<p>A roughness penalty. By default, no penalty <code>lambda=0</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_lfdobj">Lfdobj</code></td>
<td>
<p>See <a href="fda.html#topic+eval.penalty">eval.penalty</a>.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_type.cv">type.CV</code></td>
<td>
<p>Type of cross-validation. By default generalized
cross-validation <code><a href="#topic+GCV.S">GCV.S</a></code> method.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_par.cv">par.CV</code></td>
<td>
<p>List of parameters for <code>type.CV</code>: <code>trim</code>, the alpha
of the trimming and <code>draw</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code> information about the procedure is printed.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis.cv_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function <code>fregre.basis.cv()</code>  uses validation criterion defined by argument
<code>type.CV</code> to estimate the number of basis elements and/or the penalized
parameter (<code>lambda</code>) that best predicts the response.
</p>
<p>If <code>basis = NULL</code> creates bspline basis.<br />
</p>
<p>If the functional covariate <code>fdataobj</code> is in a format <code>raw data</code>,
such as matrix or data.frame, creates an object of class <code>fdata</code> with
default attributes, see <code><a href="#topic+fdata">fdata</a></code>.<br />
</p>
<p>If <code>basis.x</code> is a vector of number of basis elements and
<code>basis.b=NULL</code>, the function force the same number of elements in the
basis of <code>x</code> and <code>beta</code>.<br />
</p>
<p>If <code>basis.x$type=``fourier''</code> and <code>basis.b$type=``fourier''</code>, the
function decreases the number of fourier basis elements on the
<code class="reqn">min(k_{n1},k_{n2})</code>, where <code class="reqn">k_{n1}</code> and
<code class="reqn">k_{n2}</code> are the number of basis element of <code>basis.x</code> and
<code>basis.b</code> respectively.
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>fregre.basis</code>: Fitted regression object by the best parameters (basis elements for data and beta and lambda penalty). 
</p>
</li>
<li> <p><code>basis.x.opt</code>: Basis used for functional explanatory data estimation <code>fdata</code>. 
</p>
</li>
<li> <p><code>basis.b.opt</code>: Basis used for functional <code>beta</code> parameter estimation. 
</p>
</li>
<li> <p><code>lambda.opt</code>: <code>lambda</code> value that minimizes CV or GCV method. 
</p>
</li>
<li> <p><code>gcv.opt</code>: Minimum value of CV or GCV method. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O. and Silverman, Bernard W. (2006),
<em>Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.basis">fregre.basis</a></code>,
<code><a href="#topic+summary.fregre.fd">summary.fregre.fd</a></code> and <code><a href="#topic+predict.fregre.fd">predict.fregre.fd</a></code> .<br />
Alternative method: <code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code> and
<code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x&lt;-tecator$absorp.fdata[1:129]
y=tecator$y$Fat[1:129]
b1&lt;-c(15,21,31)
b2&lt;-c(7,9)
res1=fregre.basis.cv(x,y,basis.x=b1)
res2=fregre.basis.cv(x,y,basis.x=b1,basis.b=b2)
res1$gcv
res2$gcv
l=2^(-4:10)
res3=fregre.basis.cv(x,y,basis.b=b1,type.basis="fourier",
lambda=l,type.CV=GCV.S,par.CV=list(trim=0.15))
res3$gcv

## End(Not run)

</code></pre>

<hr>
<h2 id='fregre.basis.fr'>Functional Regression with functional response using basis representation.</h2><span id='topic+fregre.basis.fr'></span>

<h3>Description</h3>

<p>Computes functional regression between functional explanatory variable
<code class="reqn">X(s)</code> and functional response <code class="reqn">Y(t)</code> using basis representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.basis.fr(
  x,
  y,
  basis.s = NULL,
  basis.t = NULL,
  lambda.s = 0,
  lambda.t = 0,
  Lfdobj.s = vec2Lfd(c(0, 0), range.s),
  Lfdobj.t = vec2Lfd(c(0, 0), range.t),
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.basis.fr_+3A_x">x</code></td>
<td>
<p>Functional explanatory variable.</p>
</td></tr>
<tr><td><code id="fregre.basis.fr_+3A_y">y</code></td>
<td>
<p>Functional response variable.</p>
</td></tr>
<tr><td><code id="fregre.basis.fr_+3A_basis.s">basis.s</code></td>
<td>
<p>Basis related with <code>s</code> and it is used in the estimation
of <code class="reqn">\beta(s,t)</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis.fr_+3A_basis.t">basis.t</code></td>
<td>
<p>Basis related with <code>t</code> and it is used in the estimation
of <code class="reqn">\beta(s,t)</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis.fr_+3A_lambda.s">lambda.s</code></td>
<td>
<p>A roughness penalty with respect to <code>s</code> to be applied
in the estimation of <code class="reqn">\beta(s,t)</code>. By default, no penalty
<code>lambda.s=0</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis.fr_+3A_lambda.t">lambda.t</code></td>
<td>
<p>A roughness penalty with respect to <code>t</code> to be applied
in the estimation of <code class="reqn">\beta(s,t)</code>.  By default, no penalty
<code>lambda.t=0</code>.</p>
</td></tr>
<tr><td><code id="fregre.basis.fr_+3A_lfdobj.s">Lfdobj.s</code></td>
<td>
<p>A linear differential operator object with respect to
<code>s</code> . See <a href="fda.html#topic+eval.penalty">eval.penalty</a>.</p>
</td></tr>
<tr><td><code id="fregre.basis.fr_+3A_lfdobj.t">Lfdobj.t</code></td>
<td>
<p>A linear differential operator object with respect to
<code>t</code>. See <a href="fda.html#topic+eval.penalty">eval.penalty</a>.</p>
</td></tr>
<tr><td><code id="fregre.basis.fr_+3A_weights">weights</code></td>
<td>
<p>Weights.</p>
</td></tr>
<tr><td><code id="fregre.basis.fr_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">Y(t)=\alpha(t)+\int_{T}{X(s)\beta(s,t)ds+\epsilon(t)}</code>
</p>

<p>where <code class="reqn">\alpha(t)</code> is the intercept function, <code class="reqn">\beta(s,t)</code> is the
bivariate resgression function and <code class="reqn">\epsilon(t)</code> are the error term with
mean zero.
</p>
<p>The function is a wrapped of <a href="fda.html#topic+linmod">linmod</a> function proposed by
Ramsay and Silverman (2005) to model the relationship between the functional
response <code class="reqn">Y(t)</code> and the functional covariate <code class="reqn">X(t)</code> by basis
representation of both.
</p>
<p>The unknown bivariate functional parameter <code class="reqn">\beta(s,t)</code> can
be expressed as a double expansion in terms of <code class="reqn">K</code> basis function
<code class="reqn">\nu_k</code> and <code class="reqn">L</code> basis functions <code class="reqn">\theta_l</code>,
</p>
<p style="text-align: center;"><code class="reqn">\beta(s,t)=\sum_{k=1}^{K}\sum_{l=1}^{L} b_{kl}
\nu_{k}(s)\theta_{l}(t)=\nu(s)^{\top}\bold{B}\theta(t)</code>
</p>
<p> Then, the model can be
re&ndash;written in a matrix version as,
</p>
<p style="text-align: center;"><code class="reqn">Y(t)=\alpha(t)+\int_{T}{X(s)\nu(s)^{\top}\bold{B}\theta(t)ds+\epsilon(t)}=\alpha(t)+\bold{XB}\theta(t)+\epsilon(t)</code>
</p>
<p> where
<code class="reqn">\bold{X}=\int X(s)\nu^{\top}(t)ds</code> <br />
</p>
<p>This function allows objects of class <code>fdata</code> or directly covariates of
class <code>fd</code>.  If <code>x</code> is a <code>fdata</code> class, <code>basis.s</code> is
also the basis used to represent <code>x</code> as <code>fd</code> class object. If
<code>y</code> is a <code>fdata</code> class, <code>basis.t</code> is also the basis used to
represent <code>y</code> as <code>fd</code> class object. The function also gives
default values to arguments <code>basis.s</code> and <code>basis.t</code> for construct
the bifd class object used in the estimation of <code class="reqn">\beta(s,t)</code>.  If
<code>basis.s=</code><code>NULL</code> or <code>basis.t=</code><code>NULL</code> the function
creates a <code>bspline</code> basis by <a href="fda.html#topic+create.bspline.basis">create.bspline.basis</a>.
</p>
<p><code>fregre.basis.fr</code> incorporates a roughness penalty using an appropiate
linear differential operator; <code>lambda.s</code>, <code>Lfdobj.s</code> for
penalization of <code class="reqn">\beta</code>'s variations with respect to <code class="reqn">s</code> and
<br /> <code>lambda.t</code>, <code>Lfdobj.t</code> for penalization of
<code class="reqn">\beta</code>'s variations with respect to <code class="reqn">t</code>.<br />
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>call</code>: The matched call. 
</p>
</li>
<li> <p><code>a.est</code>: Intercept parameter estimated. 
</p>
</li>
<li> <p><code>coefficients</code>: The matrix of the coefficients. 
</p>
</li>
<li> <p><code>beta.est</code>: A bivariate functional data object of class <code>bifd</code> with the estimated parameters of <code class="reqn">\beta(s,t)</code>. 
</p>
</li>
<li> <p><code>fitted.values</code>: Estimated response. 
</p>
</li>
<li> <p><code>residuals</code>: <code>y</code> minus <code>fitted values</code>. 
</p>
</li>
<li> <p><code>y</code>: Functional response. 
</p>
</li>
<li> <p><code>x</code>: Functional explanatory data. 
</p>
</li>
<li> <p><code>lambda.s</code>: A roughness penalty with respect to <code>s</code>. 
</p>
</li>
<li> <p><code>lambda.t</code>: A roughness penalty with respect to <code>t</code>. 
</p>
</li>
<li> <p><code>Lfdobj.s</code>: A linear differential operator with respect to <code>s</code>. 
</p>
</li>
<li> <p><code>Lfdobj.t</code>: A linear differential operator with respect to <code>t</code>. 
</p>
</li>
<li> <p><code>weights</code>: Weights. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em>
Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+predict.fregre.fr">predict.fregre.fr</a></code>.
Alternative method: <a href="fda.html#topic+linmod">linmod</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
rtt&lt;-c(0, 365)
basis.alpha  &lt;- create.constant.basis(rtt)
basisx  &lt;- create.bspline.basis(rtt,11)
basisy  &lt;- create.bspline.basis(rtt,11)
basiss  &lt;- create.bspline.basis(rtt,7)
basist  &lt;- create.bspline.basis(rtt,9)

# fd class
dayfd&lt;-Data2fd(day.5,CanadianWeather$dailyAv,basisx)
tempfd&lt;-dayfd[,1]
log10precfd&lt;-dayfd[,3]
res1 &lt;-  fregre.basis.fr(tempfd, log10precfd,
basis.s=basiss,basis.t=basist)

# fdata class
tt&lt;-1:365
tempfdata&lt;-fdata(t(CanadianWeather$dailyAv[,,1]),tt,rtt)
log10precfdata&lt;-fdata(t(CanadianWeather$dailyAv[,,3]),tt,rtt)
res2&lt;-fregre.basis.fr(tempfdata,log10precfdata,
basis.s=basiss,basis.t=basist)

# penalization
Lfdobjt &lt;- Lfdobjs &lt;- vec2Lfd(c(0,0), rtt)
Lfdobjt &lt;- vec2Lfd(c(0,0), rtt)
lambdat&lt;-lambdas &lt;- 100
res1.pen &lt;- fregre.basis.fr(tempfdata,log10precfdata,basis.s=basiss,
basis.t=basist,lambda.s=lambdas,lambda.t=lambdat,
Lfdobj.s=Lfdobjs,Lfdobj.t=Lfdobjt)

res2.pen &lt;- fregre.basis.fr(tempfd, log10precfd,
basis.s=basiss,basis.t=basist,lambda.s=lambdas,
lambda.t=lambdat,Lfdobj.s=Lfdobjs,Lfdobj.t=Lfdobjt)

plot(log10precfd,col=1)
lines(res1$fitted.values,col=2)
plot(res1$residuals)
plot(res1$beta.est,tt,tt)
plot(res1$beta.est,tt,tt,type="persp",theta=45,phi=30)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.bootstrap'>Bootstrap regression</h2><span id='topic+fregre.bootstrap'></span><span id='topic+fregre.bootstrap2'></span>

<h3>Description</h3>

<p>Estimate the beta parameter by wild or smoothed bootstrap procedure
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.bootstrap(
  model,
  nb = 500,
  wild = TRUE,
  type.wild = "golden",
  newX = NULL,
  smo = 0.1,
  smoX = 0.05,
  alpha = 0.95,
  kmax.fix = FALSE,
  draw = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.bootstrap_+3A_model">model</code></td>
<td>
<p><code>fregre.pc</code>, <code>fregre.pls</code> or <code>fregre.basis</code>
object.</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_nb">nb</code></td>
<td>
<p>Number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_wild">wild</code></td>
<td>
<p>Naive or smoothed bootstrap depending of the <code>smo</code> and
<code>smoX</code> parameters.</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_type.wild">type.wild</code></td>
<td>
<p>Type of distribution of V in wild bootstrap procedure, see
<code><a href="#topic+rwild">rwild</a></code>.</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_newx">newX</code></td>
<td>
<p>A <code>fdata</code> class containing the values of the model
covariates at which predictions are required (only for smoothed bootstrap).</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_smo">smo</code></td>
<td>
<p>If <code class="reqn">&gt;0</code>, smoothed bootstrap on the residuals (proportion of
response variance).</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_smox">smoX</code></td>
<td>
<p>If <code class="reqn">&gt;0</code>, smoothed bootstrap on the explanatory functional
variable <code>fdata</code> (proportion of variance-covariance matrix of
<code>fdata</code> object.</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_alpha">alpha</code></td>
<td>
<p>Significance level used for graphical option, <code>draw=TRUE</code>.</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_kmax.fix">kmax.fix</code></td>
<td>
<p>The number of maximum components to consider in each
bootstrap iteration.  =TRUE, the bootstrap procedure considers the same
number of components used in the previous fitted model.  =FALSE, the
bootstrap procedure estimates the best components in each iteration.</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_draw">draw</code></td>
<td>
<p>=TRUE, plot the bootstrap estimated beta, and (optional) the CI
for the predicted response values.</p>
</td></tr>
<tr><td><code id="fregre.bootstrap_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Estimate the beta parameter by wild or smoothed bootstrap procedure using
principal components representation <code><a href="#topic+fregre.pc">fregre.pc</a></code>, Partial least
squares components (PLS) representation <code><a href="#topic+fregre.pls">fregre.pls</a></code> or basis
representation <code><a href="#topic+fregre.basis">fregre.basis</a></code>.<br /> If a new curves are in
<code>newX</code> argument the bootstrap method estimates the response using the
bootstrap resamples.
</p>
<p>If the model exhibits heteroskedasticity, the use of wild bootstrap
procedure is recommended (by default).
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>model</code>: <code>fregre.pc</code>, <code>fregre.pls</code> or <code>fregre.basis</code> object. 
</p>
</li>
<li> <p><code>beta.boot</code>: Functional beta estimated by the <code>nb</code> bootstrap regressions. 
</p>
</li>
<li> <p><code>norm.boot</code>: Norm of differences between the <code>nboot</code> betas estimated by bootstrap and beta estimated by the regression model. 
</p>
</li>
<li> <p><code>coefs.boot</code>: Matrix with the bootstrap estimated basis coefficients. 
</p>
</li>
<li> <p><code>kn.boot</code>: Vector or list of length <code>nb</code> with index of the basis, PC or PLS factors selected in each bootstrap regression. 
</p>
</li>
<li> <p><code>y.pred</code>: Predicted response values using <code>newX</code> covariates. 
</p>
</li>
<li> <p><code>y.boot</code>: Matrix of bootstrap predicted response values using <code>newX</code> covariates. 
</p>
</li>
<li> <p><code>newX</code>: A <code>fdata</code> class containing the values of the model covariates at which predictions are required (only for smoothed bootstrap).
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Galeano, P. and Gonzalez-Manteiga, W. (2010).
<em>Measures of influence for the functional linear model with scalar
response</em>. Journal of Multivariate Analysis 101, 327-339.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.pc">fregre.pc</a></code>, <code><a href="#topic+fregre.pls">fregre.pls</a></code>,
<code><a href="#topic+fregre.basis">fregre.basis</a></code>, .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
data(tecator)
iest&lt;-1:165
x=tecator$absorp.fdata[iest]
y=tecator$y$Fat[iest]
nb&lt;-25  ## Time-consuming
res.pc=fregre.pc(x,y,1:6)
# Fix the compontents used in the each regression
res.boot1=fregre.bootstrap(res.pc,nb=nb,wild=FALSE,kmax.fix=TRUE)
# Select the "best" compontents used in the each regression
res.boot2=fregre.bootstrap(res.pc,nb=nb,wild=FALSE,kmax.fix=FALSE) 
res.boot3=fregre.bootstrap(res.pc,nb=nb,wild=FALSE,kmax.fix=10) 
## predicted responses and bootstrap confidence interval
newx=tecator$absorp.fdata[-iest]
res.boot4=fregre.bootstrap(res.pc,nb=nb,wild=FALSE,newX=newx,draw=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.gkam'>Fitting Functional Generalized Kernel Additive Models.</h2><span id='topic+fregre.gkam'></span>

<h3>Description</h3>

<p>Computes functional regression between functional explanatory variables
<code class="reqn">(X^{1}(t_1),...,X^{q}(t_q))</code> and scalar response
<code class="reqn">Y</code> using backfitting algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.gkam(
  formula,
  family = gaussian(),
  data,
  weights = rep(1, nobs),
  par.metric = NULL,
  par.np = NULL,
  offset = NULL,
  control = list(maxit = 100, epsilon = 0.001, trace = FALSE, inverse = "solve"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.gkam_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
procedure only considers functional covariates (not implemented for
non-functional covariates). The details of model specification are given
under <code>Details</code>.</p>
</td></tr>
<tr><td><code id="fregre.gkam_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions).</p>
</td></tr>
<tr><td><code id="fregre.gkam_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td></tr>
<tr><td><code id="fregre.gkam_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.gkam_+3A_par.metric">par.metric</code></td>
<td>
<p>List of arguments by covariate to pass to the
<code>metric</code> function by covariate.</p>
</td></tr>
<tr><td><code id="fregre.gkam_+3A_par.np">par.np</code></td>
<td>
<p>List of arguments to pass to the <code>fregre.np.cv</code> function</p>
</td></tr>
<tr><td><code id="fregre.gkam_+3A_offset">offset</code></td>
<td>
<p>this can be used to specify an a priori known component to be
included in the linear predictor during fitting.</p>
</td></tr>
<tr><td><code id="fregre.gkam_+3A_control">control</code></td>
<td>
<p>a list of parameters for controlling the fitting process, by
default: <code>maxit</code>, <code>epsilon</code>, <code>trace</code> and <code>inverse</code></p>
</td></tr>
<tr><td><code id="fregre.gkam_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="fregre.gkam_+3A_inverse">inverse</code></td>
<td>
<p>=&quot;svd&quot; (by default) or =&quot;solve&quot; method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The smooth functions <code class="reqn">f(.)</code> are estimated nonparametrically using a
iterative local scoring algorithm by applying Nadaraya-Watson weighted
kernel smoothers using <code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code> in each step, see
Febrero-Bande and Gonzalez-Manteiga (2011) for more details.<br /> 
Consider the fitted response <code class="reqn">\hat{Y}=g^{-1}(H_{Q}y)</code>,
where <code class="reqn">H_{Q}</code> is the weighted hat matrix.<br /> Opsomer and Ruppert
(1997) solves a system of equations for fit the unknowns
<code class="reqn">f(\cdot)</code> computing the additive smoother matrix <code class="reqn">H_k</code>
such that <code class="reqn">\hat{f}_k (X^k)=H_{k}Y</code> and
<code class="reqn">H_Q=H_1+,\cdots,+H_q</code>. The additive model is fitted
as follows: </p>
<p style="text-align: center;"><code class="reqn">\hat{Y}=g^{-1}\Big(\sum_i^q
\hat{f_i}(X_i)\Big)</code>
</p>



<h3>Value</h3>


<ul>
<li> <p><code>result</code>: List of non-parametric estimation by covariate.
</p>
</li>
<li> <p><code>fitted.values</code>: Estimated scalar response. 
</p>
</li>
<li> <p><code>residuals</code>: <code>y</code> minus <code>fitted values</code>. 
</p>
</li>
<li> <p><code>effects</code>: The residual degrees of freedom. 
</p>
</li>
<li> <p><code>alpha</code>: Hat matrix. 
</p>
</li>
<li> <p><code>family</code>: Coefficient of determination. 
</p>
</li>
<li> <p><code>linear.predictors</code>: Residual variance.
</p>
</li>
<li> <p><code>deviance</code>: Scalar response. 
</p>
</li>
<li> <p><code>aic</code>: Functional explanatory data.
</p>
</li>
<li> <p><code>null.deviance</code>: Non functional explanatory data. 
</p>
</li>
<li> <p><code>iter</code>: Distance matrix between curves. 
</p>
</li>
<li> <p><code>w</code>: Beta coefficient estimated.
</p>
</li>
<li> <p><code>eqrank</code>: List that containing the variables in the model.
</p>
</li>
<li> <p><code>prior.weights</code>: Asymmetric kernel used. 
</p>
</li>
<li> <p><code>y</code>: Scalar response.
</p>
</li>
<li> <p><code>H</code>: Hat matrix, see Opsomer and Ruppert (1997) for more details.
</p>
</li>
<li> <p><code>converged</code>: Conv.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Febrero-Bande, M. and Oviedo de la Fuente, M.
</p>


<h3>References</h3>

<p>Febrero-Bande M. and Gonzalez-Manteiga W. (2012).
<em>Generalized Additive Models for Functional Data</em>. TEST.
Springer-Velag.  <a href="https://doi.org/10.1007/s11749-012-0308-0">doi:10.1007/s11749-012-0308-0</a>
</p>
<p>Opsomer J.D. and Ruppert D.(1997). <em>Fitting a bivariate additive model
by local polynomial regression</em>.Annals of Statistics, <code>25</code>, 186-211.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.gsam">fregre.gsam</a></code>, <code><a href="#topic+fregre.glm">fregre.glm</a></code>
and <code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code><br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
ab=tecator$absorp.fdata[1:100]
ab2=fdata.deriv(ab,2)
yfat=tecator$y[1:100,"Fat"]

# Example 1: # Changing the argument par.np and family
yfat.cat=ifelse(yfat&lt;15,0,1)
xlist=list("df"=data.frame(yfat.cat),"ab"=ab,"ab2"=ab2)
f2&lt;-yfat.cat~ab+ab2

par.NP&lt;-list("ab"=list(Ker=AKer.norm,type.S="S.NW"),
"ab2"=list(Ker=AKer.norm,type.S="S.NW"))
res2=fregre.gkam(f2,family=binomial(),data=xlist,
par.np=par.NP)
res2

# Example 2: Changing the argument par.metric and family link
par.metric=list("ab"=list(metric=semimetric.deriv,nderiv=2,nbasis=15),
"ab2"=list("metric"=semimetric.basis))
res3=fregre.gkam(f2,family=binomial("probit"),data=xlist,
par.metric=par.metric,control=list(maxit=2,trace=FALSE))
summary(res3)

# Example 3: Gaussian family (by default)
# Only 1 iteration (by default maxit=100)
xlist=list("df"=data.frame(yfat),"ab"=ab,"ab2"=ab2)
f&lt;-yfat~ab+ab2
res=fregre.gkam(f,data=xlist,control=list(maxit=1,trace=FALSE))
res

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.glm'>Fitting Functional Generalized Linear Models</h2><span id='topic+fregre.glm'></span>

<h3>Description</h3>

<p>Computes functional generalized linear model between functional covariate
<code class="reqn">X^j(t)</code> (and non functional covariate <code class="reqn">Z^j</code>) and
scalar response <code class="reqn">Y</code> using basis representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.glm(
  formula,
  family = gaussian(),
  data,
  basis.x = NULL,
  basis.b = NULL,
  subset = NULL,
  weights = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.glm_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
details of model specification are given under <code>Details</code>.</p>
</td></tr>
<tr><td><code id="fregre.glm_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)</p>
</td></tr>
<tr><td><code id="fregre.glm_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td></tr>
<tr><td><code id="fregre.glm_+3A_basis.x">basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td></tr>
<tr><td><code id="fregre.glm_+3A_basis.b">basis.b</code></td>
<td>
<p>List of basis for <code class="reqn">\beta(t)</code> parameter estimation.</p>
</td></tr>
<tr><td><code id="fregre.glm_+3A_subset">subset</code></td>
<td>
<p>an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td></tr>
<tr><td><code id="fregre.glm_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.glm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is an extension of the linear regression models:
<code><a href="#topic+fregre.lm">fregre.lm</a></code> where the <code class="reqn">E[Y|X,Z]</code> is related to the linear
prediction <code class="reqn">\eta</code> via a link function <code class="reqn">g(.)</code>.
</p>
<p style="text-align: center;"><code class="reqn">E[Y|X,Z]=\eta=g^{-1}(\alpha+\sum_{j=1}^{p}\beta_{j}Z^{j}+\sum_{k=1}^{q}\frac{1}{\sqrt{T_k}}\int_{T_k}{X^{k}(t)\beta_{k}(t)dt})</code>
</p>

<p>where <code class="reqn">Z=\left[ Z^1,\cdots,Z^p \right]</code> are the
non functional covariates and <code class="reqn">X(t)=\left[ X^{1}(t_1),\cdots,X^{q}(t_q)
\right]</code> are the functional ones.
</p>
<p>The first item in the <code>data</code> list is called <em>&quot;df&quot;</em> and is a data
frame with the response and non functional explanatory variables, as
<code><a href="stats.html#topic+glm">glm</a></code>.<br />
</p>
<p>Functional covariates of class <code>fdata</code> or <code>fd</code> are introduced in
the following items in the <code>data</code> list.<br /> <code>basis.x</code> is a list of
basis for represent each functional covariate. The basis object can be
created by the function: <code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <a href="fda.html#topic+pca.fd">pca.fd</a>
<code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <code><a href="#topic+create.fdata.basis">create.fdata.basis</a></code> o
<a href="fda.html#topic+create.basis">create.basis</a>.<br /> <code>basis.b</code> is a list of basis for
represent each <code class="reqn">\beta(t)</code> parameter. If <code>basis.x</code> is a list of
functional principal components basis (see <code><a href="#topic+create.pc.basis">create.pc.basis</a></code> or
<a href="fda.html#topic+pca.fd">pca.fd</a>) the argument <code>basis.b</code> is ignored.
</p>
<p>represent beta lower than the number of basis used to represent the
functional data.
</p>


<h3>Value</h3>

<p>Return <code>glm</code> object plus:
</p>
 
<ul>
<li> <p><code>basis.x</code>: Basis used for <code>fdata</code> or <code>fd</code> covariates. 
</p>
</li>
<li> <p><code>basis.b</code>: Basis used for beta parameter estimation. 
</p>
</li>
<li> <p><code>beta.l</code>: List of estimated beta parameter of functional covariates. 
</p>
</li>
<li> <p><code>data</code>: List that contains the variables in the model. 
</p>
</li>
<li> <p><code>formula</code>: Formula. 
</p>
</li></ul>



<h3>Note</h3>

<p>If the formula only contains a non functional explanatory variables
(multivariate covariates), the function compute a standard <code><a href="stats.html#topic+glm">glm</a></code>
procedure.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em>
Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>McCullagh and Nelder (1989), <em>Generalized Linear Models</em> 2nd ed.
Chapman and Hall.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) <em>Modern Applied Statistics
with S</em>, New York: Springer.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+predict.fregre.glm">predict.fregre.glm</a></code> and
<code><a href="stats.html#topic+summary.glm">summary.glm</a></code>.<br /> Alternative method if
<code>family</code>=<em>gaussian</em>: <code><a href="#topic+fregre.lm">fregre.lm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
data(tecator)
x=tecator$absorp.fdata
y=tecator$y$Fat
tt=x[["argvals"]]
dataf=as.data.frame(tecator$y)
nbasis.x=11
nbasis.b=7
basis1=create.bspline.basis(rangeval=range(tt),nbasis=nbasis.x)
basis2=create.bspline.basis(rangeval=range(tt),nbasis=nbasis.b)
f=Fat~Protein+x
basis.x=list("x"=basis1)
basis.b=list("x"=basis2)
ldata=list("df"=dataf,"x"=x)
res=fregre.glm(f,family=gaussian(),data=ldata,basis.x=basis.x,
basis.b=basis.b)
summary(res)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.glm.vs'>Variable Selection using Functional Linear Models</h2><span id='topic+fregre.glm.vs'></span>

<h3>Description</h3>

<p>Computes functional GLM model between functional covariates
<code class="reqn">(X^1(t_1),\cdots,X^{q}(t_q))</code> and non functional covariates
<code class="reqn">(Z^1,...,Z^p)</code> with a scalar response <code class="reqn">Y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.glm.vs(
  data = list(),
  y,
  include = "all",
  exclude = "none",
  family = gaussian(),
  weights = NULL,
  basis.x = NULL,
  numbasis.opt = FALSE,
  dcor.min = 0.1,
  alpha = 0.05,
  par.model,
  xydist,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.glm.vs_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model. 
&quot;df&quot; element is a data.frame containing the response and scalar covariates 
(numeric and factors variables are allowed). Functional covariates of class
<code>fdata</code> or <code>fd</code> are included as named components in the <code>data</code> list.</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_y">y</code></td>
<td>
<p>Caracter string with the name of the scalar response variable.</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_include">include</code></td>
<td>
<p>vector with the name of variables to use. By default <code>"all"</code>, all variables are used.</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_exclude">exclude</code></td>
<td>
<p>vector with the name of variables to not use. By default  <code>"none"</code>, no variable is deleted.</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_basis.x">basis.x</code></td>
<td>
<p>Basis parameter options
</p>

<ul>
<li><p><code>list</code> (recomended)  List of basis for functional covariates,
see same argument in <code><a href="#topic+fregre.glm">fregre.glm</a></code>. By default, 
the function uses a basis of 3 PC to represent each functional covariate. 
</p>
</li>
<li><p><code>vector</code> (by default) Vector with two parameters:
</p>

<ol>
<li><p> Type of basis. By default <code>basis.x[1]="pc"</code>, principal
component basis is used  for each functional covariate included in the model.
Other options <code>"pls"</code> and <code>"bspline"</code>.  
</p>
</li>
<li><p> Maximum number of  basis elements <code>numbasis</code>  to be used.
By default, <code>basis.x[2]=3</code>. 
</p>
</li></ol>

</li></ul>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_numbasis.opt">numbasis.opt</code></td>
<td>
<p>Logical, if <code>FALSE</code> by default, for each functional 
covariate included in the model, the function uses all basis elements. 
Otherwise, the function selects the significant coefficients.</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_dcor.min">dcor.min</code></td>
<td>
<p>Threshold for a variable to be entered into the model. X is discarded 
if the distance correlation <code class="reqn">R(X,e)&lt; dcor.min</code> (e is the residual of previous steps).</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_alpha">alpha</code></td>
<td>
<p>Alpha value for testing the independence among covariate X and residual
e in previous steps. By default is <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_par.model">par.model</code></td>
<td>
<p>Model parameters.</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_xydist">xydist</code></td>
<td>
<p>List with the inner distance matrices of each variable (all potential 
covariates and the response).</p>
</td></tr>
<tr><td><code id="fregre.glm.vs_+3A_trace">trace</code></td>
<td>
<p>Interactive Tracing and Debugging of Call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is an extension of the functional generalized spectral additive 
regression models: <code><a href="#topic+fregre.glm">fregre.glm</a></code> where the <code class="reqn">E[Y|X,Z]</code> is related to the 
linear prediction <code class="reqn">\eta</code> via a link function <code class="reqn">g(\cdot)</code>. 
</p>
<p style="text-align: center;"><code class="reqn">E[Y|X,Z]=\eta=g^{-1}(\alpha+\sum_{j=1}^{p}\beta_{j}Z^{j}+\sum_{k=1}^{q}\frac{1}{\sqrt{T_k}}\int_{T_k}{X^{k}(t)\beta_{k}(t)dt})</code>
</p>

<p>where <code class="reqn">Z=\left[ Z^1,\cdots,Z^p \right]</code> are the
non functional covariates and <code class="reqn">X(t)=\left[ X^{1}(t_1),\cdots,X^{q}(t_q)
\right]</code> are the functional ones.
</p>


<h3>Value</h3>

<p>Return an object corresponding to the estimated additive mdoel using 
the selected variables (ame output as the<code><a href="#topic+fregre.glm">fregre.glm</a></code> function) and the following elements:
</p>

<ul>
<li><p><code>gof</code>, the goodness of fit for each step of VS algorithm.
</p>
</li>
<li><p><code>i.predictor</code>, <code>vector</code> with 1 if the variable is selected, 0 otherwise.
</p>
</li>
<li><p><code>ipredictor</code>, <code>vector</code> with the name of selected variables (in order of selection)
</p>
</li>
<li><p><code>dcor</code>, the value of distance correlation for each potential covariate and the residual of the model in each step.
</p>
</li></ul>



<h3>Note</h3>

<p>If the formula only contains a non functional explanatory variables (multivariate covariates),
the function compute a standard  <code><a href="stats.html#topic+glm">glm</a></code> procedure.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo-de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Gonz\'alez-Manteiga, W. and Oviedo de la
Fuente, M. Variable selection in functional additive regression models,
(2018).  Computational Statistics, 1-19. DOI: <a href="https://doi.org/10.1007/s00180-018-0844-5">doi:10.1007/s00180-018-0844-5</a>
</p>


<h3>See Also</h3>

<p>See Also as:  <code><a href="#topic+predict.fregre.glm">predict.fregre.glm</a></code> and <code><a href="stats.html#topic+summary.glm">summary.glm</a></code>.
Alternative methods: <code><a href="#topic+fregre.glm">fregre.glm</a></code>, <code><a href="#topic+fregre.glm">fregre.glm</a></code>
and <code><a href="#topic+fregre.gsam.vs">fregre.gsam.vs</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
data(tecator)
x=tecator$absorp.fdata
x1 &lt;- fdata.deriv(x)
x2 &lt;- fdata.deriv(x,nderiv=2)
y=tecator$y$Fat
xcat0 &lt;- cut(rnorm(length(y)),4)
xcat1 &lt;- cut(tecator$y$Protein,4)
xcat2 &lt;- cut(tecator$y$Water,4)
ind &lt;- 1:165
dat &lt;- data.frame("Fat"=y, x1$data, xcat1, xcat2)
ldat &lt;- ldata("df"=dat[ind,],"x"=x[ind,],"x1"=x1[ind,],"x2"=x2[ind,])
# 3 functionals (x,x1,x2), 3 factors (xcat0, xcat1, xcat2)
# and 100 scalars (impact poitns of x1) 

# Time consuming
res.glm0 &lt;- fregre.glm.vs(data=ldat,y="Fat",numbasis.opt=T) # All the covariates
summary(res.glm0)
res.glm0$ipredictors
res.glm0$i.predictor

res.glm1 &lt;- fregre.glm.vs(data=ldat,y="Fat") # All the covariates
summary(res.glm1)
res.glm1$ipredictors
covar &lt;- c("xcat0","xcat1","xcat2","x","x1","x2")
res.glm2 &lt;- fregre.glm.vs(data=ldat, y="Fat", include=covar)
summary(res.glm2)
res.glm2$ipredictors 
res.glm2$i.predictor

res.glm3 &lt;- fregre.glm.vs(data=ldat,y="Fat",
                           basis.x=c("type.basis"="pc","numbasis"=2))
summary(res.glm3)
res.glm3$ipredictors

res.glm4 &lt;- fregre.glm.vs(data=ldat,y="Fat",include=covar,
basis.x=c("type.basis"="pc","numbasis"=5),numbasis.opt=T)
summary(res.glm4)
res.glm4$ipredictors
lpc &lt;- list("x"=create.pc.basis(ldat$x,1:4)
           ,"x1"=create.pc.basis(ldat$x1,1:3)
           ,"x2"=create.pc.basis(ldat$x2,1:4))
res.glm5 &lt;- fregre.glm.vs(data=ldat,y="Fat",basis.x=lpc)
summary(res.glm5)
res.glm5 &lt;- fregre.glm.vs(data=ldat,y="Fat",basis.x=lpc,numbasis.opt=T)
summary(res.glm5)
bsp &lt;- create.fourier.basis(ldat$x$rangeval,7)
lbsp &lt;- list("x"=bsp,"x1"=bsp,"x2"=bsp)
res.glm6 &lt;- fregre.glm.vs(data=ldat,y="Fat",basis.x=lbsp)
summary(res.glm6)
# Prediction like fregre.glm() 
newldat &lt;- ldata("df"=dat[-ind,],"x"=x[-ind,],"x1"=x1[-ind,],
                "x2"=x2[-ind,])
pred.glm1 &lt;- predict(res.glm1,newldat)
pred.glm2 &lt;- predict(res.glm2,newldat)
pred.glm3 &lt;- predict(res.glm3,newldat)
pred.glm4 &lt;- predict(res.glm4,newldat)
pred.glm5 &lt;- predict(res.glm5,newldat)
pred.glm6 &lt;- predict(res.glm6,newldat)
plot(dat[-ind,"Fat"],pred.glm1)
points(dat[-ind,"Fat"],pred.glm2,col=2)
points(dat[-ind,"Fat"],pred.glm3,col=3)
points(dat[-ind,"Fat"],pred.glm4,col=4)
points(dat[-ind,"Fat"],pred.glm5,col=5)
points(dat[-ind,"Fat"],pred.glm6,col=6)
pred2meas(newldat$df$Fat,pred.glm1)
pred2meas(newldat$df$Fat,pred.glm2)
pred2meas(newldat$df$Fat,pred.glm3)
pred2meas(newldat$df$Fat,pred.glm4)
pred2meas(newldat$df$Fat,pred.glm5)
pred2meas(newldat$df$Fat,pred.glm6)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.gls'>Fit Functional Linear Model Using Generalized Least Squares</h2><span id='topic+fregre.gls'></span>

<h3>Description</h3>

<p>This function fits a functional linear model using generalized least
squares. The errors are allowed to be correlated and/or have unequal
variances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.gls(
  formula,
  data,
  correlation = NULL,
  basis.x = NULL,
  basis.b = NULL,
  rn,
  lambda,
  weights = NULL,
  subset,
  method = c("REML", "ML"),
  control = list(),
  verbose = FALSE,
  criteria = "GCCV1",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.gls_+3A_formula">formula</code></td>
<td>
<p>a two-sided linear formula object describing the model, with
the response on the left of a <code>~</code> operator and the terms, separated by
<code>+</code> operators, on the right.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_data">data</code></td>
<td>
<p>an optional data frame containing the variables named in
<code>model</code>, <code>correlation</code>, <code>weights</code>, and <code>subset</code>. By
default the variables are taken from the environment from which <code>gls</code>
is called.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_correlation">correlation</code></td>
<td>
<p>an optional <a href="nlme.html#topic+corStruct">corStruct</a> object describing the
within-group correlation structure. See the documentation of
<a href="nlme.html#topic+corClasses">corClasses</a> for a description of the available <code>corStruct</code>
classes. If a grouping variable is to be used, it must be specified in the
<code>form</code> argument to the <code>corStruct</code> constructor. Defaults to
<code>NULL</code>, corresponding to uncorrelated errors.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_basis.x">basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_basis.b">basis.b</code></td>
<td>
<p>List of basis for <code class="reqn">\beta(t)</code> parameter estimation.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_rn">rn</code></td>
<td>
<p>List of Ridge parameter.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_lambda">lambda</code></td>
<td>
<p>List of Roughness penalty parameter.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_weights">weights</code></td>
<td>
<p>an optional <a href="nlme.html#topic+varFunc">varFunc</a> object or one-sided formula
describing the within-group heteroscedasticity structure. If given as a
formula, it is used as the argument to <a href="nlme.html#topic+varFixed">varFixed</a>, corresponding
to fixed variance weights. See the documentation on <a href="nlme.html#topic+varClasses">varClasses</a>
for a description of the available <a href="nlme.html#topic+varFunc">varFunc</a> classes. Defaults
to <code>NULL</code>, corresponding to homoscedastic errors.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_subset">subset</code></td>
<td>
<p>an optional expression indicating which subset of the rows of
<code>data</code> should be used in the fit. This can be a logical vector, or a
numeric vector indicating which observation numbers are to be included, or a
character vector of the row names to be included.  All observations are
included by default.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_method">method</code></td>
<td>
<p>a character string.  If <code>"REML"</code> the model is fit by
maximizing the restricted log-likelihood.  If <code>"ML"</code> the log-likelihood
is maximized.  Defaults to <code>"REML"</code>.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_control">control</code></td>
<td>
<p>a list of control values for the estimation algorithm to
replace the default values returned by the function
<a href="nlme.html#topic+glsControl">glsControl</a>.  Defaults to an empty list.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_verbose">verbose</code></td>
<td>
<p>an optional logical value. If <code>TRUE</code> information on the
evolution of the iterative algorithm is printed. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_criteria">criteria</code></td>
<td>
<p>GCCV criteria, see <code><a href="#topic+GCCV.S">GCCV.S</a></code>.</p>
</td></tr>
<tr><td><code id="fregre.gls_+3A_...">...</code></td>
<td>
<p>some methods for this generic require additional arguments.
None are used in this method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>"gls"</code> representing the functional linear
model fit. Generic functions such as <code>print</code>, <code>plot</code>, and
<code>summary</code> have methods to show the results of the fit.<br /> 
See <a href="nlme.html#topic+glsObject">glsObject</a> for the components of the fit. The functions
<code><a href="stats.html#topic+resid">resid</a></code>, <code><a href="stats.html#topic+coef">coef</a></code>, and <code><a href="stats.html#topic+fitted">fitted</a></code> can be
used to extract some of its components.<br /> 
Besides, the class(z) is &quot;gls&quot;, &quot;lm&quot;, and &quot;fregre.lm&quot; with the following
objects: 
</p>

<ul>
<li> <p><code>sr2</code>: Residual variance. 
</p>
</li>
<li> <p><code>Vp</code>: Estimated covariance matrix for the parameters. 
</p>
</li>
<li> <p><code>lambda</code>: A roughness penalty.
</p>
</li>
<li> <p><code>basis.x</code>: Basis used for <code>fdata</code> or <code>fd</code> covariates.
</p>
</li>
<li> <p><code>basis.b</code>: Basis used for beta parameter estimation. 
</p>
</li>
<li> <p><code>beta.l</code>: List of estimated beta parameter of functional covariates. 
</p>
</li>
<li> <p><code>data</code>: List containing the variables in the model. 
</p>
</li>
<li> <p><code>formula</code>: Formula used in the adjusted model. 
</p>
</li>
<li> <p><code>formula.ini</code>: Formula in call.
</p>
</li>
<li> <p><code>W</code>: Inverse of covariance matrix. 
</p>
</li>
<li> <p><code>correlation</code>: See <code>glsObject</code> for the components of the fit.
</p>
</li></ul>



<h3>References</h3>

<p>Oviedo de la Fuente, M., Febrero-Bande, M., Pilar Munoz, and
Dominguez, A.  (2018). Predicting seasonal influenza transmission using 
functional regression models with temporal dependence. PloS one, 13(4), e0194250.
<a href="https://doi.org/10.1371/journal.pone.0194250">doi:10.1371/journal.pone.0194250</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
data(tecator)
x=tecator$absorp.fdata
x.d2&lt;-fdata.deriv(x,nderiv=)
tt&lt;-x[["argvals"]]
dataf=as.data.frame(tecator$y)

# plot the response
plot(ts(tecator$y$Fat))

nbasis.x=11;nbasis.b=7
basis1=create.bspline.basis(rangeval=range(tt),nbasis=nbasis.x)
basis2=create.bspline.basis(rangeval=range(tt),nbasis=nbasis.b)
basis.x=list("x.d2"=basis1)
basis.b=list("x.d2"=basis2)
ldata=list("df"=dataf,"x.d2"=x.d2)
res.gls=fregre.gls(Fat~x.d2,data=ldata, correlation=corAR1(),
                   basis.x=basis.x,basis.b=basis.b)
summary(res.gls)                   

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.gsam'>Fitting Functional Generalized Spectral Additive Models</h2><span id='topic+fregre.gsam'></span>

<h3>Description</h3>

<p>Computes a functional GAM model between a functional covariate
<code class="reqn">(X^1(t_1), \dots, X^{q}(t_q))</code> and a non-functional
covariate <code class="reqn">(Z^1, ..., Z^p)</code> with a scalar response <code class="reqn">Y</code>.
</p>
<p>This function extends functional generalized linear regression models (<code><a href="#topic+fregre.glm">fregre.glm</a></code>) 
where <code class="reqn">E[Y|X,Z]</code> is related to the linear predictor <code class="reqn">\eta</code> via a link function 
<code class="reqn">g(\cdot)</code> with integrated smoothness estimation by the smooth
functions <code class="reqn">f(\cdot)</code>.
</p>
<p style="text-align: center;"><code class="reqn">E[Y|X,Z]=\eta=g^{-1}\left(\alpha+\sum_{i=1}^{p}f_{i}(Z^{i})+\sum_{k=1}^{q}\sum_{j=1}^{k_q} f_{j}^{k}(\xi_j^k)\right)</code>
</p>

<p>where <code class="reqn">\xi_j^k</code> is the coefficient of the basis function expansion of
<code class="reqn">X^k</code>; in PCA analysis, <code class="reqn">\xi_j^k</code> is the score of the
<code class="reqn">j</code>-functional PC of <code class="reqn">X^k</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.gsam(
  formula,
  family = gaussian(),
  data = list(),
  weights = NULL,
  basis.x = NULL,
  basis.b = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.gsam_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
details of model specification are given under <code>Details</code>.</p>
</td></tr>
<tr><td><code id="fregre.gsam_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)</p>
</td></tr>
<tr><td><code id="fregre.gsam_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td></tr>
<tr><td><code id="fregre.gsam_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.gsam_+3A_basis.x">basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td></tr>
<tr><td><code id="fregre.gsam_+3A_basis.b">basis.b</code></td>
<td>
<p>List of basis for functional beta parameter estimation.</p>
</td></tr>
<tr><td><code id="fregre.gsam_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The smooth functions <code class="reqn">f(\cdot)</code> can be added to the right-hand
side of the formula to specify that the linear predictor depends on smooth
functions of predictors using smooth terms <code><a href="mgcv.html#topic+s">s</a></code> and
<code><a href="mgcv.html#topic+te">te</a></code> as in <code><a href="mgcv.html#topic+gam">gam</a></code> (or linear functionals of these as
<code class="reqn">Z \beta</code> and <code class="reqn">\langle X(t), \beta \rangle</code> in
<code><a href="#topic+fregre.glm">fregre.glm</a></code>).
</p>
<p>The first item in the <code>data</code> list is called <em>&quot;df&quot;</em> and is a data
frame with the response and non-functional explanatory variables, as in
<code><a href="mgcv.html#topic+gam">gam</a></code>.<br />
</p>
<p>Functional covariates of class <code>fdata</code> or <code>fd</code> are introduced in
the following items of the <code>data</code> list.<br /> <code>basis.x</code> is a list of
basis functions for representing each functional covariate. The basis object can be
created using functions such as <code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <code><a href="fda.html#topic+pca.fd">pca.fd</a></code>,
<code><a href="#topic+create.fdata.basis">create.fdata.basis</a></code>, or <code><a href="fda.html#topic+create.basis">create.basis</a></code>.<br /> 
<code>basis.b</code> is a list of basis functions for representing each functional beta parameter. 
If <code>basis.x</code> is a list of functional principal components basis functions 
(see <code><a href="#topic+create.pc.basis">create.pc.basis</a></code> or <code><a href="fda.html#topic+pca.fd">pca.fd</a></code>), the argument <code>basis.b</code> is ignored.
</p>


<h3>Value</h3>

<p>Return <code>gam</code> object plus:
</p>

<ul>
<li> <p><code>basis.x</code>: Basis used for <code>fdata</code> or <code>fd</code> covariates. 
</p>
</li>
<li> <p><code>basis.b</code>: Basis used for beta parameter estimation. 
</p>
</li>
<li> <p><code>data</code>: List containing the variables in the model. 
</p>
</li>
<li> <p><code>formula</code>: Formula used in the model. 
</p>
</li>
<li> <p><code>y.pred</code>: Predicted response by cross-validation.
</p>
</li></ul>



<h3>Note</h3>

<p>If the formula only contains a non functional explanatory variables
(multivariate covariates), the function compute a standard <code><a href="stats.html#topic+glm">glm</a></code>
procedure.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Muller HG and Stadtmuller U. (2005). <em>Generalized
functional linear models.</em> Ann. Statist.33 774-805.
</p>
<p>Wood (2001) <em>mgcv:GAMs and Generalized Ridge Regression for R</em>. R News
1(2):20-25.
</p>
<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em> Functional Data
Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>Venables, W. N. and Ripley, B. D. (2002) <em>Modern Applied Statistics
with S</em>, New York: Springer.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+predict.fregre.gsam">predict.fregre.gsam</a></code> and
<a href="mgcv.html#topic+summary.gam">summary.gam</a>.<br /> Alternative methods: <code><a href="#topic+fregre.glm">fregre.glm</a></code>
and <code><a href="#topic+fregre.gkam">fregre.gkam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x &lt;- tecator$absorp.fdata
x.d1 &lt;- fdata.deriv(x)
tt &lt;- x[["argvals"]]
dataf &lt;- as.data.frame(tecator$y)
nbasis.x &lt;- 11
nbasis.b &lt;- 5
basis1 &lt;- create.bspline.basis(rangeval=range(tt),nbasis=nbasis.x)
basis2 &lt;- create.bspline.basis(rangeval=range(tt),nbasis=nbasis.b)
f &lt;- Fat ~ s(Protein) + s(x)
basis.x &lt;- list("x"=basis1,"x.d1"=basis1)
basis.b &lt;- list("x"=basis2,"x.d1"=basis2)
ldat &lt;- ldata("df" = dataf, "x" = x , "x.d1" = x.d1)
res &lt;- fregre.gsam(Fat ~ Water + s(Protein) + x + s(x.d1), ldat,
                   family = gaussian(),  basis.x = basis.x,
                   basis.b = basis.b)
summary(res)
pred &lt;- predict(res,ldat)
plot(pred-res$fitted)
pred2 &lt;- predict.gam(res,res$XX)
plot(pred2-res$fitted)
plot(pred2-pred)
res2 &lt;- fregre.gsam(Fat ~ te(Protein, k = 3) + x, data =  ldat,
                     family=gaussian())
summary(res2)

##  dropind basis pc
basis.pc0 &lt;- create.pc.basis(x,c(2,4,7))
basis.pc1 &lt;- create.pc.basis(x.d1,c(1:3))
basis.x &lt;- list("x"=basis.pc0,"x.d1"=basis.pc1)
ldata &lt;- ldata("df"=dataf,"x"=x,"x.d1"=x.d1)  
res.pc &lt;- fregre.gsam(f,data=ldata,family=gaussian(),
          basis.x=basis.x,basis.b=basis.b)
summary(res.pc)
 
##  Binomial family
ldat$df$FatCat &lt;- factor(ifelse(tecator$y$Fat &gt; 20, 1, 0))
res.bin &lt;- fregre.gsam(FatCat ~ Protein + s(x),ldat,family=binomial())
summary(res.bin)
table(ldat$df$FatCat, ifelse(res.bin$fitted.values &lt; 0.5,0,1))

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.gsam.vs'>Variable Selection using Functional Additive Models</h2><span id='topic+fregre.gsam.vs'></span>

<h3>Description</h3>

<p>Computes functional GAM model between functional covariates
<code class="reqn">(X^1(t_1),\cdots,X^{q}(t_q))</code> and non functional covariates
<code class="reqn">(Z^1,...,Z^p)</code> with a scalar response <code class="reqn">Y</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.gsam.vs(
  data = list(),
  y,
  include = "all",
  exclude = "none",
  family = gaussian(),
  weights = NULL,
  basis.x = NULL,
  numbasis.opt = FALSE,
  kbs,
  dcor.min = 0.1,
  alpha = 0.05,
  par.model,
  xydist,
  trace = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.gsam.vs_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model. 
&quot;df&quot; element is a data.frame containing the response and scalar covariates 
(numeric and factors variables are allowed). Functional covariates of class
<code>fdata</code> or <code>fd</code> are included as named components in the <code>data</code> list.</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_y">y</code></td>
<td>
<p>Caracter string with the name of the scalar response variable.</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_include">include</code></td>
<td>
<p>vector with the name of variables to use. By default <code>"all"</code>, all variables are used.</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_exclude">exclude</code></td>
<td>
<p>vector with the name of variables to not use. By default  <code>"none"</code>, no variable is deleted.</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_family">family</code></td>
<td>
<p>a description of the error distribution and link function to
be used in the model. This can be a character string naming a family
function, a family function or the result of a call to a family function.
(See <code><a href="stats.html#topic+family">family</a></code> for details of family functions.)</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_basis.x">basis.x</code></td>
<td>
<p>Basis parameter options
</p>

<ul>
<li><p><code>list</code> (recomended)  List of basis for functional covariates,
see same argument in <code><a href="#topic+fregre.glm">fregre.glm</a></code>. By default, 
the function uses a basis of 3 PC to represent each functional covariate. 
</p>
</li>
<li><p><code>vector</code> (by default) Vector with two parameters:
</p>

<ol>
<li><p> Type of basis. By default <code>basis.x[1]="pc"</code>, principal
component basis is used  for each functional covariate included in the model.
Other options <code>"pls"</code> and <code>"bspline"</code>.  
</p>
</li>
<li><p> Maximum number of  basis elements <code>numbasis</code>  to be used.
By default, <code>basis.x[2]=3</code>. 
</p>
</li></ol>

</li></ul>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_numbasis.opt">numbasis.opt</code></td>
<td>
<p>Logical, if <code>FALSE</code> by default, for each functional 
covariate included in the model, the function uses all basis elements. 
Otherwise, the function selects the significant coefficients.</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_kbs">kbs</code></td>
<td>
<p>The dimension of the basis used to represent the smooth term. The default 
depends on the number of variables that the smooth is a function of.</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_dcor.min">dcor.min</code></td>
<td>
<p>Threshold for a variable to be entered into the model. X is discarded 
if the distance correlation <code class="reqn">R(X,e)&lt; dcor.min</code> (e is the residual of previous steps).</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_alpha">alpha</code></td>
<td>
<p>Alpha value for testing the independence among covariate X and residual
e in previous steps. By default is <code>0.05</code>.</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_par.model">par.model</code></td>
<td>
<p>Model parameters.</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_xydist">xydist</code></td>
<td>
<p>List with the inner distance matrices of each variable (all potential 
covariates and the response).</p>
</td></tr>
<tr><td><code id="fregre.gsam.vs_+3A_trace">trace</code></td>
<td>
<p>Interactive Tracing and Debugging of Call.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is an extension of the functional generalized spectral additive 
regression models: <code><a href="#topic+fregre.gsam">fregre.gsam</a></code> where the <code class="reqn">E[Y|X,Z]</code> is related to the 
linear prediction <code class="reqn">\eta</code> via a link function <code class="reqn">g(\cdot)</code> with integrated 
smoothness estimation by the smooth functions <code class="reqn">f(\cdot)</code>. 
</p>
<p style="text-align: center;"><code class="reqn">E[Y|X,Z] = \eta = g^{-1}(\alpha + \sum_{i=1}^{p} f_{i}(Z^{i}) + \sum_{k=1}^{q} \sum_{j=1}^{k_q} f_{j}^{k}(\xi_j^k))</code>
</p>

<p>where <code class="reqn">\xi_j^k</code> is the coefficient of the basis function expansion of 
<code class="reqn">X^k</code>, (in PCA analysis, <code class="reqn">\xi_j^k</code> is the score of the <code class="reqn">j</code>-functional
PC of <code class="reqn">X^k</code>).
</p>
<p>The smooth functions <code class="reqn">f(\cdot)</code> can be added to the right-hand side of the formula
to specify that the linear predictor depends on smooth functions of predictors using smooth 
terms <a href="mgcv.html#topic+s">s</a> and <a href="mgcv.html#topic+te">te</a> as in <a href="mgcv.html#topic+gam">gam</a> (or linear functionals of 
these as <code class="reqn">Z\beta</code> and <code class="reqn">\langle X(t), \beta(t) \rangle</code> in <code><a href="#topic+fregre.glm">fregre.glm</a></code>).
</p>


<h3>Value</h3>

<p>Return an object corresponding to the estimated additive mdoel using 
the selected variables (ame output as the<code><a href="#topic+fregre.gsam">fregre.gsam</a></code> function) and the following elements:
</p>

<ul>
<li> <p><code>gof</code>: the goodness of fit for each step of VS algorithm.
</p>
</li>
<li> <p><code>i.predictor</code>: <code>vector</code> with 1 if the variable is selected, 0 otherwise.
</p>
</li>
<li> <p><code>ipredictor</code>: <code>vector</code> with the name of selected variables (in order of selection)
</p>
</li>
<li> <p><code>dcor</code>: the value of distance correlation for each potential covariate and the residual of the model in each step.
</p>
</li></ul>



<h3>Note</h3>

<p>If the formula only contains a non functional explanatory variables (multivariate covariates),
the function compute a standard  <a href="mgcv.html#topic+gam">gam</a> procedure.
</p>


<h3>Author(s)</h3>

<p>Manuel Feb-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Gonz\'alez-Manteiga, W. and Oviedo de la
Fuente, M. Variable selection in functional additive regression models,
(2018).  Computational Statistics, 1-19. DOI: <a href="https://doi.org/10.1007/s00180-018-0844-5">doi:10.1007/s00180-018-0844-5</a>
</p>


<h3>See Also</h3>

<p>See Also as:  <code><a href="#topic+predict.fregre.gsam">predict.fregre.gsam</a></code> and <a href="mgcv.html#topic+summary.gam">summary.gam</a>.
Alternative methods: <code><a href="#topic+fregre.glm">fregre.glm</a></code>, <code><a href="#topic+fregre.gsam">fregre.gsam</a></code>
and <code><a href="#topic+fregre.gkam">fregre.gkam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
data(tecator)
x=tecator$absorp.fdata
x1 &lt;- fdata.deriv(x)
x2 &lt;- fdata.deriv(x,nderiv=2)
y=tecator$y$Fat
xcat0 &lt;- cut(rnorm(length(y)),4) 
xcat1 &lt;- cut(tecator$y$Protein,4)
xcat2 &lt;- cut(tecator$y$Water,4)
ind &lt;- 1:165
dat &lt;- data.frame("Fat"=y, x1$data, xcat1, xcat2)
ldat &lt;- ldata("df"=dat[ind,],"x"=x[ind,],"x1"=x1[ind,],"x2"=x2[ind,])
# 3 functionals (x,x1,x2), 3 factors (xcat0, xcat1, xcat2)
# and 100 scalars (impact poitns of x1) 

# Time consuming
res.gam0 &lt;- fregre.gsam.vs(data=ldat,y="Fat"
            ,exclude="x2",numbasis.opt=T) # All the covariates
summary(res.gam0)
res.gam0$ipredictors

res.gam1 &lt;- fregre.gsam.vs(data=ldat,y="Fat") # All the covariates
summary(res.gam1)
res.gam1$ipredictors

covar &lt;- c("xcat0","xcat1","xcat2","x","x1","x2")
res.gam2 &lt;- fregre.gsam.vs(data=ldat, y="Fat", include=covar)
summary(res.gam2)
res.gam2$ipredictors 
res.gam2$i.predictor

res.gam3 &lt;- fregre.gsam.vs(data=ldat,y="Fat",
            basis.x=c("type.basis"="pc","numbasis"=10))
summary(res.gam3)
res.gam3$ipredictors

res.gam4 &lt;- fregre.gsam.vs(data=ldat,y="Fat",include=c("x","x1","x2"),
basis.x=c("type.basis"="pc","numbasis"=5),numbasis.opt=T)
summary(res.gam4)
res.gam4$ipredictors
lpc &lt;- list("x"=create.pc.basis(ldat$x,1:4)
           ,"x1"=create.pc.basis(ldat$x1,1:3)
           ,"x2"=create.pc.basis(ldat$x2,1:12))
res.gam5 &lt;- fregre.gsam.vs(data=ldat,y="Fat",basis.x=lpc)
summary(res.gam5)
res.gam6 &lt;- fregre.gsam.vs(data=ldat,y="Fat",basis.x=lpc,numbasis.opt=T)
summary(res.gam6)
bsp &lt;- create.fourier.basis(ldat$x$rangeval,7)
lbsp &lt;- list("x"=bsp,"x1"=bsp,"x2"=bsp)
res.gam7 &lt;- fregre.gsam.vs(data=ldat,y="Fat",basis.x=lbsp,kbs=4)
summary(res.gam7)
# Prediction like fregre.gsam() 
newldat &lt;- ldata("df"=dat[-ind,],"x"=x[-ind,],"x1"=x1[-ind,],
                "x2"=x2[-ind,])
pred.gam1 &lt;- predict(res.gam1,newldat)
pred.gam2 &lt;- predict(res.gam2,newldat)
pred.gam3 &lt;- predict(res.gam3,newldat)
pred.gam4 &lt;- predict(res.gam4,newldat)
pred.gam5 &lt;- predict(res.gam5,newldat)
pred.gam6 &lt;- predict(res.gam6,newldat)
pred.gam7 &lt;- predict(res.gam7,newldat)
plot(dat[-ind,"Fat"],pred.gam1)
points(dat[-ind,"Fat"],pred.gam2,col=2)
points(dat[-ind,"Fat"],pred.gam3,col=3)
points(dat[-ind,"Fat"],pred.gam4,col=4)
points(dat[-ind,"Fat"],pred.gam5,col=5)
points(dat[-ind,"Fat"],pred.gam6,col=6)
points(dat[-ind,"Fat"],pred.gam7,col=7)
pred2meas(newldat$df$Fat,pred.gam1)
pred2meas(newldat$df$Fat,pred.gam2)
pred2meas(newldat$df$Fat,pred.gam3)
pred2meas(newldat$df$Fat,pred.gam4)
pred2meas(newldat$df$Fat,pred.gam5)
pred2meas(newldat$df$Fat,pred.gam6)
pred2meas(newldat$df$Fat,pred.gam7)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.igls'>Fit of  Functional Generalized Least Squares Model Iteratively</h2><span id='topic+fregre.igls'></span>

<h3>Description</h3>

<p>This function fits iteratively a functional linear model using generalized 
least squares. The errors are allowed to be correlated and/or have unequal variances.  
</p>

<ol>
<li><p> Begin with a preliminary estimation of <code class="reqn">\hat{\theta}=\theta_0</code> (for instance, 
<code class="reqn">\theta_0=0</code>). Compute <code class="reqn">\hat{W}</code>.
</p>
</li>
<li><p> Estimate <code class="reqn">b_\Sigma =(Z'\hat{W}Z)^{-1}Z'\hat{W}y</code>
</p>
</li>
<li><p> Based on the residuals, <code class="reqn">\hat{e}=\left(y-Zb_\Sigma \right)</code>, update
<code class="reqn">\hat{\theta}=\rho\left({\hat{e}}\right)</code> where <code class="reqn">\rho</code> depends on the 
dependence structure chosen.
</p>
</li>
<li><p> Repeats steps 2 and 3 until convergence (small changes in <code class="reqn">b_\Sigma</code> and/or <code class="reqn">\hat{\theta}</code>). 
</p>
</li></ol>



<h3>Usage</h3>

<pre><code class='language-R'>fregre.igls(
  formula,
  data,
  basis.x = NULL,
  basis.b = NULL,
  correlation,
  maxit = 100,
  rn,
  lambda,
  weights = rep(1, n),
  control,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.igls_+3A_formula">formula</code></td>
<td>
<p>A two-sided linear formula object describing the
model, with the response on the left of a <code>~</code> operator and the
terms, separated by <code>+</code> operators, on the right.</p>
</td></tr>
<tr><td><code id="fregre.igls_+3A_data">data</code></td>
<td>
<p>An optional data frame containing the variables named in
<code>model</code>, <code>correlation</code>, <code>weights</code>, and
<code>subset</code>. By default the variables are taken from the environment
from which <code>gls</code> is called.</p>
</td></tr>
<tr><td><code id="fregre.igls_+3A_basis.x">basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td></tr>
<tr><td><code id="fregre.igls_+3A_basis.b">basis.b</code></td>
<td>
<p>List of basis for <code class="reqn">\beta(t)</code> parameter estimation.</p>
</td></tr>
<tr><td><code id="fregre.igls_+3A_correlation">correlation</code></td>
<td>
<p>List  describing the  correlation structure. Defaults to 
<code>NULL</code>, corresponding to uncorrelated errors.
See the following internal functions  for a description and a code example in script file.
</p>

<ul>
<li> <p><code>corUnstruc(x)</code>, fit an unstrutured correlation.
</p>
</li>
<li> <p><code>cor.AR(x, order.max = 8, p=1, method = "lm")</code> fit an Autoregressive Models to Time Series using <code><a href="stats.html#topic+ar">ar</a></code> function.
</p>
</li>
<li> <p><code>cor.ARMA(x, p, d = 0, q = 0, method = "lm", order.max = 1)</code> Fit an ARIMA model to a univariate time series using <code><a href="stats.html#topic+arima">arima</a></code> function.
</p>
</li>
<li> <p><code>corExpo(xy,range, method = "euclidean",p=2)</code> Fit an exponential correlation structure.
</p>
</li></ul>
</td></tr>
<tr><td><code id="fregre.igls_+3A_maxit">maxit</code></td>
<td>
<p>Number of maximum of interactions.</p>
</td></tr>
<tr><td><code id="fregre.igls_+3A_rn">rn</code></td>
<td>
<p>List of Ridge parameter.</p>
</td></tr>
<tr><td><code id="fregre.igls_+3A_lambda">lambda</code></td>
<td>
<p>List of Roughness penalty parameter.</p>
</td></tr>
<tr><td><code id="fregre.igls_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.igls_+3A_control">control</code></td>
<td>
<p>Control parameters.</p>
</td></tr>
<tr><td><code id="fregre.igls_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>fregre.igls</code> representing the functional linear model
fit with temporal dependence errors.
Beside, the class(z) is  similar to &quot;fregre.lm&quot; plus the following objects:
</p>

<ul>
<li> <p><code>corStruct</code>: Fitted  AR or ARIMA model.  
</p>
</li></ul>



<h3>References</h3>

<p>Oviedo de la Fuente, M., Febrero-Bande, M., Pilar Munoz, and
Dominguez, A.  (2018). Predicting seasonal influenza transmission using 
functional regression models with temporal dependence. PloS one, 13(4), e0194250.
<a href="https://doi.org/10.1371/journal.pone.0194250">doi:10.1371/journal.pone.0194250</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
data(tecator)
x=tecator$absorp.fdata
x.d2&lt;-fdata.deriv(x,nderiv=)
tt&lt;-x[["argvals"]]
dataf=as.data.frame(tecator$y)
# plot the response
plot(ts(tecator$y$Fat))
ldata=list("df"=dataf,"x.d2"=x.d2)
res.gls=fregre.igls(Fat~x.d2,data=ldata,
correlation=list("cor.ARMA"=list()),
control=list("p"=1)) 
res.gls
res.gls$corStruct

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.lm'>Fitting Functional Linear Models</h2><span id='topic+fregre.lm'></span>

<h3>Description</h3>

<p>Computes functional regression between functional (and non functional)
explanatory variables and scalar response using basis representation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.lm(
  formula,
  data,
  basis.x = NULL,
  basis.b = NULL,
  lambda = NULL,
  P = NULL,
  weights = rep(1, n),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.lm_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
details of model specification are given under <code>Details</code>.</p>
</td></tr>
<tr><td><code id="fregre.lm_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model. 
Functional covariates are recommended to be of class fdata. 
Objects of class &quot;fd&quot; can be used at the user's own risk.</p>
</td></tr>
<tr><td><code id="fregre.lm_+3A_basis.x">basis.x</code></td>
<td>
<p>List of basis for functional explanatory data estimation.</p>
</td></tr>
<tr><td><code id="fregre.lm_+3A_basis.b">basis.b</code></td>
<td>
<p>List of basis for functional beta parameter estimation.</p>
</td></tr>
<tr><td><code id="fregre.lm_+3A_lambda">lambda</code></td>
<td>
<p>List, indexed by the names of the functional covariates, 
which contains the Roughness penalty parameter.</p>
</td></tr>
<tr><td><code id="fregre.lm_+3A_p">P</code></td>
<td>
<p>List, indexed by the names of the functional covariates, which contains the parameters for the creation of the penalty matrix.</p>
</td></tr>
<tr><td><code id="fregre.lm_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.lm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This section is presented as an extension of the linear regression models:
<code><a href="#topic+fregre.pc">fregre.pc</a></code>, <code><a href="#topic+fregre.pls">fregre.pls</a></code> and
<code><a href="#topic+fregre.basis">fregre.basis</a></code>. Now, the scalar response <code class="reqn">Y</code> is estimated by
more than one functional covariate <code class="reqn">X^j(t)</code> and also more than one non
functional covariate <code class="reqn">Z^j</code>. The regression model is given by:
</p>
<p style="text-align: center;"><code class="reqn">E[Y|X,Z]=\alpha+\sum_{j=1}^{p}\beta_{j}Z^{j}+\sum_{k=1}^{q}\frac{1}{\sqrt{T_k}}\int_{T_k}{X^{k}(t)\beta_{k}(t)dt}
</code>
</p>

<p>where <code class="reqn">Z=\left[ Z^1,\cdots,Z^p \right]</code> are the non
functional covariates, <code class="reqn">X(t)=\left[ X^{1}(t_1),\cdots,X^{q}(t_q)
\right]</code> are the functional ones and
<code class="reqn">\epsilon</code> are random errors with mean zero , finite variance
<code class="reqn">\sigma^2</code> and <code class="reqn">E[X(t)\epsilon]=0</code>.  
</p>
<p>The first item in the <code>data</code> list is called <em>&quot;df&quot;</em> and is a data
frame with the response and non functional explanatory variables, as
<code><a href="stats.html#topic+lm">lm</a></code>. Functional covariates of class <code>fdata</code> or <code>fd</code>
are introduced in the following items in the <code>data</code> list.<br />
</p>
<p><code>basis.x</code> is a list of basis for represent each functional covariate.
The basis object can be created by the function:
<code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <a href="fda.html#topic+pca.fd">pca.fd</a>
<code><a href="#topic+create.pc.basis">create.pc.basis</a></code>, <code><a href="#topic+create.fdata.basis">create.fdata.basis</a></code> or
<a href="fda.html#topic+create.basis">create.basis</a>.<br /> <code>basis.b</code> is a list of basis for
represent each functional <code class="reqn">\beta_k</code> parameter. If <code>basis.x</code> is a
list of functional principal components basis (see
<code><a href="#topic+create.pc.basis">create.pc.basis</a></code> or <a href="fda.html#topic+pca.fd">pca.fd</a>) the argument
<code>basis.b</code> <em>(is unnecessary and)</em> is ignored.<br />
</p>
<p>Penalty options are under development, not guaranteed to work properly.
The user can penalty the basis elements by: (i) <code>lambda</code> is a list of
rough penalty values of each functional covariate, see
<code><a href="#topic+P.penalty">P.penalty</a></code> for more details.
</p>


<h3>Value</h3>

<p>Return <code>lm</code> object plus:
</p>

<ul>
<li> <p><code>sr2</code>: Residual variance.
</p>
</li>
<li> <p><code>Vp</code>: Estimated covariance matrix for the parameters. 
</p>
</li>
<li> <p><code>lambda</code>: A roughness penalty. 
</p>
</li>
<li> <p><code>basis.x</code>: Basis used for <code>fdata</code> or <code>fd</code> covariates. 
</p>
</li>
<li> <p><code>basis.b</code>: Basis used for beta parameter estimation.
</p>
</li>
<li> <p><code>beta.l</code>: List of estimated beta parameter of functional covariates.
</p>
</li>
<li> <p><code>data</code>: List containing the variables in the model.
</p>
</li>
<li> <p><code>formula</code>: Formula used in the model.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@usc.es">manuel.oviedo@usc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em>
Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+predict.fregre.lm">predict.fregre.lm</a></code> and
<code><a href="stats.html#topic+summary.lm">summary.lm</a></code>.<br /> Alternative method: <code><a href="#topic+fregre.glm">fregre.glm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x &lt;- tecator$absorp.fdata
y &lt;- tecator$y$Fat
tt &lt;- x[["argvals"]]
dataf &lt;- as.data.frame(tecator$y)

nbasis.x &lt;- 11
nbasis.b &lt;- 5
basis1 &lt;- create.bspline.basis(rangeval=range(tt),nbasis=nbasis.x)
basis2 &lt;- create.bspline.basis(rangeval=range(tt),nbasis=nbasis.b)
basis.x &lt;- list("x"=basis1)
basis.b &lt;- list("x"=basis2)
f &lt;- Fat ~ Protein + x
ldat &lt;- ldata("df"=dataf,"x"=x)
res &lt;- fregre.lm(f,ldat,  basis.b=basis.b)
summary(res)
f2 &lt;- Fat ~ Protein + xd +xd2
xd &lt;- fdata.deriv(x,nderiv=1,class.out='fdata', nbasis=nbasis.x)
xd2 &lt;- fdata.deriv(x,nderiv=2,class.out='fdata', nbasis=nbasis.x)
ldat2 &lt;- list("df"=dataf,"xd"=xd,"x"=x,"xd2"=xd2)
basis.x2 &lt;- NULL#list("xd"=basis1)
basis.b2 &lt;- NULL#list("xd"=basis2)
basis.b2 &lt;- list("xd"=basis2,"xd2"=basis2,"x"=basis2)
res2 &lt;- fregre.lm(f2, ldat2,basis.b=basis.b2)
summary(res2)
par(mfrow=c(2,1))
plot(res$beta.l$x,main="functional beta estimation")
plot(res2$beta.l$xd,col=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.np'>Functional regression with scalar response using non-parametric kernel
estimation</h2><span id='topic+fregre.np'></span>

<h3>Description</h3>

<p>Computes functional regression between functional explanatory variables and
scalar response using kernel estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.np(
  fdataobj,
  y,
  h = NULL,
  Ker = AKer.norm,
  metric = metric.lp,
  type.S = S.NW,
  par.S = list(w = 1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.np_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fregre.np_+3A_y">y</code></td>
<td>
<p>Scalar response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="fregre.np_+3A_h">h</code></td>
<td>
<p>Bandwidth, <code>h&gt;0</code>. Default argument values are provided as the
5%&ndash;quantile of the distance between <code>fdataobj</code> curves, see
<code><a href="#topic+h.default">h.default</a></code>.</p>
</td></tr>
<tr><td><code id="fregre.np_+3A_ker">Ker</code></td>
<td>
<p>Type of asymmetric kernel used, by default asymmetric normal
kernel.</p>
</td></tr>
<tr><td><code id="fregre.np_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="fregre.np_+3A_type.s">type.S</code></td>
<td>
<p>Type of smothing matrix <code>S</code>. By default <code>S</code> is
calculated by Nadaraya-Watson kernel estimator (<code>S.NW</code>).</p>
</td></tr>
<tr><td><code id="fregre.np_+3A_par.s">par.S</code></td>
<td>
<p>List of parameters for <code>type.S</code>: <code>w</code>, the weights.</p>
</td></tr>
<tr><td><code id="fregre.np_+3A_...">...</code></td>
<td>
<p>Arguments to be passed for <code><a href="#topic+metric.lp">metric.lp</a></code> o other
metric function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The non-parametric functional regression model can be written as follows </p>
<p style="text-align: center;"><code class="reqn">y_i =r(X_i)+\epsilon_i</code>
</p>
<p> where the unknown smooth real function <code class="reqn">r</code> is
estimated using kernel estimation by means of
</p>
<p style="text-align: center;"><code class="reqn">\hat{r}(X)=\frac{\sum_{i=1}^{n}{K(h^{-1}d(X,X_{i}))y_{i}}}{\sum_{i=1}^{n}{K(h^{-1}d(X,X_{i}))}}</code>
</p>
<p> where <code class="reqn">K</code> is an
kernel function (see <code>Ker</code> argument), <code>h</code> is the smoothing
parameter and <code class="reqn">d</code> is a metric or a semi-metric (see <code>metric</code>
argument).
</p>
<p>The distance between curves is calculated using the <code><a href="#topic+metric.lp">metric.lp</a></code>
although any other semimetric could be used (see
<code><a href="#topic+semimetric.basis">semimetric.basis</a></code> or <code><a href="#topic+semimetric.NPFDA">semimetric.NPFDA</a></code> functions).
The kernel is applied to a metric or semi-metrics that provides non-negative
values, so it is common to use asymmetric kernels. Different asymmetric
kernels can be used, see <code><a href="#topic+Kernel.asymmetric">Kernel.asymmetric</a></code>.<br />
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>call</code>: The matched call. 
</p>
</li>
<li> <p><code>fitted.values</code>: Estimated scalar response. 
</p>
</li>
<li> <p><code>H</code>: Hat matrix. 
</p>
</li>
<li> <p><code>residuals</code>: <code>y</code> minus <code>fitted values</code>. 
</p>
</li>
<li> <p><code>df.residual</code>: The residual degrees of freedom. 
</p>
</li>
<li> <p><code>r2</code>: Coefficient of determination. 
</p>
</li>
<li> <p><code>sr2</code>: Residual variance. 
</p>
</li>
<li> <p><code>y</code>: Response. 
</p>
</li>
<li> <p><code>fdataobj</code>: Functional explanatory data. 
</p>
</li>
<li> <p><code>mdist</code>: Distance matrix between <code>x</code> and <code>newx</code>.
</p>
</li>
<li> <p><code>Ker</code>: Asymmetric kernel used. 
</p>
</li>
<li> <p><code>h.opt</code>: Smoothing parameter or bandwidth.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York. <br />
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code>,
<code><a href="#topic+summary.fregre.fd">summary.fregre.fd</a></code> and <code><a href="#topic+predict.fregre.fd">predict.fregre.fd</a></code> .<br />
Alternative method: <code><a href="#topic+fregre.basis">fregre.basis</a></code>,cand <code><a href="#topic+fregre.pc">fregre.pc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
absorp=tecator$absorp.fdata
ind=1:129
x=absorp[ind,]
y=tecator$y$Fat[ind]

res.np=fregre.np(x,y,Ker=AKer.epa)
summary(res.np)
res.np2=fregre.np(x,y,Ker=AKer.tri)
summary(res.np2)

# with other semimetrics.
res.pca1=fregre.np(x,y,Ker=AKer.tri,metri=semimetric.pca,q=1)
summary(res.pca1)
res.deriv=fregre.np(x,y,metri=semimetric.deriv)
summary(res.deriv)
x.d2=fdata.deriv(x,nderiv=1,method="fmm",class.out='fdata')
res.deriv2=fregre.np(x.d2,y)
summary(res.deriv2)
x.d3=fdata.deriv(x,nderiv=1,method="bspline",class.out='fdata')
res.deriv3=fregre.np(x.d3,y)
summary(res.deriv3)

## End(Not run)

</code></pre>

<hr>
<h2 id='fregre.np.cv'>Cross-validation functional regression with scalar response using kernel
estimation.</h2><span id='topic+fregre.np.cv'></span>

<h3>Description</h3>

<p>Computes functional regression between functional explanatory variables and
scalar response using asymmetric kernel estimation by cross-validation
method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.np.cv(
  fdataobj,
  y,
  h = NULL,
  Ker = AKer.norm,
  metric = metric.lp,
  type.CV = GCV.S,
  type.S = S.NW,
  par.CV = list(trim = 0),
  par.S = list(w = 1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.np.cv_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fregre.np.cv_+3A_y">y</code></td>
<td>
<p>Scalar response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="fregre.np.cv_+3A_h">h</code></td>
<td>
<p>Bandwidth, <code>h&gt;0</code>. Default argument values are provided as the
sequence of length 25 from 2.5%&ndash;quantile to 25%&ndash;quantile of the distance
between <code>fdataobj</code> curves, see <code><a href="#topic+h.default">h.default</a></code>.</p>
</td></tr>
<tr><td><code id="fregre.np.cv_+3A_ker">Ker</code></td>
<td>
<p>Type of asymmetric kernel used, by default asymmetric normal
kernel.</p>
</td></tr>
<tr><td><code id="fregre.np.cv_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="fregre.np.cv_+3A_type.cv">type.CV</code></td>
<td>
<p>Type of cross-validation. By default generalized
cross-validation <code><a href="#topic+GCV.S">GCV.S</a></code> method.</p>
</td></tr>
<tr><td><code id="fregre.np.cv_+3A_type.s">type.S</code></td>
<td>
<p>Type of smothing matrix <code>S</code>. By default <code>S</code> is
calculated by Nadaraya-Watson kernel estimator (<code>S.NW</code>).</p>
</td></tr>
<tr><td><code id="fregre.np.cv_+3A_par.cv">par.CV</code></td>
<td>
<p>List of parameters for <code>type.CV</code>: <code>trim</code>, the alpha
of the trimming<br /> and <code>draw=TRUE</code>.</p>
</td></tr>
<tr><td><code id="fregre.np.cv_+3A_par.s">par.S</code></td>
<td>
<p>List of parameters for <code>type.S</code>: <code>w</code>, the weights.</p>
</td></tr>
<tr><td><code id="fregre.np.cv_+3A_...">...</code></td>
<td>
<p>Arguments to be passed for <code><a href="#topic+metric.lp">metric.lp</a></code> o other
metric function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The non-parametric functional regression model can be written as follows
</p>
<p style="text-align: center;"><code class="reqn"> y_i =r(X_i) + \epsilon_i </code>
</p>
<p> where the unknown smooth real function
<code class="reqn">r</code> is estimated using kernel estimation by means of
</p>
<p style="text-align: center;"><code class="reqn">\hat{r}(X)=\frac{\sum_{i=1}^{n}{K(h^{-1}d(X,X_{i}))y_{i}}}{\sum_{i=1}^{n}{K(h^{-1}d(X,X_{i}))}}</code>
</p>

<p>where <code class="reqn">K</code> is an kernel function (see <code>Ker</code> argument), <code>h</code> is
the smoothing parameter and <code class="reqn">d</code> is a metric or a semi-metric (see
<code>metric</code> argument).
</p>
<p>The function estimates the value of smoothing parameter (also called
bandwidth) <code>h</code> through Generalized Cross-validation <code>GCV</code>
criteria, see <code><a href="#topic+GCV.S">GCV.S</a></code> or <code><a href="#topic+CV.S">CV.S</a></code>.
</p>
<p>The function estimates the value of smoothing parameter or the bandwidth
through the cross validation methods: <code><a href="#topic+GCV.S">GCV.S</a></code> or
<code><a href="#topic+CV.S">CV.S</a></code>. It computes the distance between curves using the
<code><a href="#topic+metric.lp">metric.lp</a></code>, although any other semimetric could be used (see
<code><a href="#topic+semimetric.basis">semimetric.basis</a></code> or <code><a href="#topic+semimetric.NPFDA">semimetric.NPFDA</a></code> functions).
Different asymmetric kernels can be used, see
<code><a href="#topic+Kernel.asymmetric">Kernel.asymmetric</a></code>.<br />
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>call</code>: The matched call.
</p>
</li>
<li> <p><code>residuals</code>: <code>y</code> minus <code>fitted values</code>.
</p>
</li>
<li> <p><code>fitted.values</code>: Estimated scalar response.
</p>
</li>
<li> <p><code>df.residual</code>: The residual degrees of freedom.
</p>
</li>
<li> <p><code>r2</code>: Coefficient of determination.
</p>
</li>
<li> <p><code>sr2</code>: Residual variance.
</p>
</li>
<li> <p><code>H</code>: Hat matrix.
</p>
</li>
<li> <p><code>y</code>: Response.
</p>
</li>
<li> <p><code>fdataobj</code>: Functional explanatory data.
</p>
</li>
<li> <p><code>mdist</code>: Distance matrix between <code>x</code> and <code>newx</code>.
</p>
</li>
<li> <p><code>Ker</code>: Asymmetric kernel used.
</p>
</li>
<li> <p><code>gcv</code>: CV or GCV values.
</p>
</li>
<li> <p><code>h.opt</code>: Smoothing parameter or bandwidth that minimizes CV or GCV method.
</p>
</li>
<li> <p><code>h</code>: Vector of smoothing parameter or bandwidth.
</p>
</li>
<li> <p><code>cv</code>: List with the fitted values and residuals estimated by CV, without the same curve.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.np">fregre.np</a></code>,
<code><a href="#topic+summary.fregre.fd">summary.fregre.fd</a></code> and <code><a href="#topic+predict.fregre.fd">predict.fregre.fd</a></code> .<br />
Alternative method: <code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code> and
<code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
absorp=tecator$absorp.fdata
ind=1:129
x=absorp[ind,]
y=tecator$y$Fat[ind]
Ker=AKer.tri
res.np=fregre.np.cv(x,y,Ker=Ker)
summary(res.np)
res.np2=fregre.np.cv(x,y,type.CV=GCV.S,criteria="Shibata")
summary(res.np2)

## Example with other semimetrics (not run)
res.pca1=fregre.np.cv(x,y,Ker=Ker,metric=semimetric.pca,q=1)
summary(res.pca1)
res.deriv=fregre.np.cv(x,y,Ker=Ker,metric=semimetric.deriv)
summary(res.deriv)

x.d2=fdata.deriv(x,nderiv=1,method="fmm",class.out='fdata')
res.deriv2=fregre.np.cv(x.d2,y,Ker=Ker)
summary(res.deriv2)
x.d3=fdata.deriv(x,nderiv=1,method="bspline",class.out='fdata')
res.deriv3=fregre.np.cv(x.d3,y,Ker=Ker)
summary(res.deriv3)

## End(Not run)

</code></pre>

<hr>
<h2 id='fregre.pc'>Functional Regression with scalar response using Principal Components
Analysis</h2><span id='topic+fregre.pc'></span>

<h3>Description</h3>

<p>Computes functional (ridge or penalized) regression between functional
explanatory variable <code class="reqn">X(t)</code> and scalar response <code class="reqn">Y</code> using Principal
Components Analysis.<br /> </p>
<p style="text-align: center;"><code class="reqn">Y=\big&lt;X,\beta\big&gt;+\epsilon=\int_{T}{X(t)\beta(t)dt+\epsilon}</code>
</p>
 
<p>where <code class="reqn"> \big&lt; \cdot , \cdot \big&gt;</code> denotes the inner product on
<code class="reqn">L_2</code> and <code class="reqn">\epsilon</code> are random errors with mean zero , finite
variance <code class="reqn">\sigma^2</code> and <code class="reqn">E[X(t)\epsilon]=0</code>.<br />
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.pc(
  fdataobj,
  y,
  l = NULL,
  lambda = 0,
  P = c(0, 0, 1),
  weights = rep(1, len = n),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.pc_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object or <code>fdata.comp</code> class
object created<br /> by <code><a href="#topic+create.pc.basis">create.pc.basis</a></code> function.</p>
</td></tr>
<tr><td><code id="fregre.pc_+3A_y">y</code></td>
<td>
<p>Scalar response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="fregre.pc_+3A_l">l</code></td>
<td>
<p>Index of components to include in the model.If is null <code>l</code> (by
default), <code>l=1:3</code>.</p>
</td></tr>
<tr><td><code id="fregre.pc_+3A_lambda">lambda</code></td>
<td>
<p>Amount of penalization. Default value is 0, i.e. no
penalization is used.</p>
</td></tr>
<tr><td><code id="fregre.pc_+3A_p">P</code></td>
<td>
<p>If <code>P</code> is a vector: <code>P</code> are coefficients to define the
penalty matrix object, see <code><a href="#topic+P.penalty">P.penalty</a></code>. If <code>P</code> is a matrix:
P is the penalty matrix object.</p>
</td></tr>
<tr><td><code id="fregre.pc_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.pc_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function computes the <code class="reqn">\left\{\nu_k\right\}_{k=1}^{\infty}</code> orthonormal
basis of functional principal components to represent the functional data as
<code class="reqn">X_i(t)=\sum_{k=1}^{\infty}\gamma_{ik}\nu_k</code> and the functional parameter as
<code class="reqn">\beta(t)=\sum_{k=1}^{\infty}\beta_k\nu_k</code>, where <code class="reqn">\gamma_{ik}=\Big&lt; X_i(t),\nu_k\Big&gt;</code> and
<code class="reqn">\beta_{k}=\Big&lt;\beta,\nu_k\Big&gt;</code>. <br /> 
The response can be fitted by: 
</p>
 
<ul>
<li> <p><code class="reqn">\lambda=0</code>, no penalization,
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}=\nu_k^{\top}(\nu_k^{\top}\nu_k)^{-1}\nu_k^{\top}y</code>
</p>
 
</li>
<li><p> Ridge regression, <code class="reqn">\lambda&gt;0</code> and <code class="reqn">P=1</code>,
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}=\nu_k^{\top}(\nu_k\top \nu_k+\lambda I)^{-1}\nu_k^{\top}y</code>
</p>

</li>
<li><p> Penalized regression, <code class="reqn">\lambda&gt;0</code> and <code class="reqn">P\neq0</code>. For example, <code class="reqn">P=c(0,0,1)</code> penalizes the second derivative (curvature) by <code>P=P.penalty(fdataobj["argvals"],P)</code>,
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}=\nu_k^{\top}(\nu_k\top \nu_k+\lambda \nu_k^{\top}
\textbf{P}\nu_k)^{-1}\nu_k^{\top}y</code>
</p>

</li></ul>



<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>call</code>: The matched call of <code><a href="#topic+fregre.pc">fregre.pc</a></code> function.
</p>
</li>
<li> <p><code>coefficients</code>: A named vector of coefficients.
</p>
</li>
<li> <p><code>residuals</code>: <code>y</code> minus <code>fitted values</code>.
</p>
</li>
<li> <p><code>fitted.values</code>: Estimated scalar response.
</p>
</li>
<li> <p><code>beta.est</code>: Beta coefficient estimated of class <code>fdata</code>.
</p>
</li>
<li> <p><code>df.residual</code>: The residual degrees of freedom. In ridge regression, <code>df(rn)</code> is the effective degrees of freedom.
</p>
</li>
<li> <p><code>r2</code>: Coefficient of determination.
</p>
</li>
<li> <p><code>sr2</code>: Residual variance.
</p>
</li>
<li> <p><code>Vp</code>: Estimated covariance matrix for the parameters.
</p>
</li>
<li> <p><code>H</code>: Hat matrix.
</p>
</li>
<li> <p><code>l</code>: Index of principal components selected.
</p>
</li>
<li> <p><code>lambda</code>: Amount of shrinkage.
</p>
</li>
<li> <p><code>P</code>: Penalty matrix.
</p>
</li>
<li> <p><code>fdata.comp</code>: Fitted object in <code><a href="#topic+fdata2pc">fdata2pc</a></code> function.
</p>
</li>
<li> <p><code>lm</code>: <code>lm</code> object.
</p>
</li>
<li> <p><code>fdataobj</code>: Functional explanatory data.
</p>
</li>
<li> <p><code>y</code>: Scalar response.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Cai TT, Hall P. 2006. <em>Prediction in functional linear
regression</em>. Annals of Statistics 34: 2159-2179.
</p>
<p>Cardot H, Ferraty F, Sarda P. 1999. <em>Functional linear model</em>.
Statistics and Probability Letters 45: 11-22.
</p>
<p>Hall P, Hosseini-Nasab M. 2006. <em>On properties of functional principal
components analysis</em>. Journal of the Royal Statistical Society B 68:
109-126.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>
<p>N. Kraemer, A.-L. Boulsteix, and G. Tutz (2008). <em>Penalized Partial
Least Squares with Applications to B-Spline Transformations and Functional
Data</em>. Chemometrics and Intelligent Laboratory Systems, 94, 60 - 69.
<a href="https://doi.org/10.1016/j.chemolab.2008.06.009">doi:10.1016/j.chemolab.2008.06.009</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code>,
<code><a href="#topic+summary.fregre.fd">summary.fregre.fd</a></code> and <code><a href="#topic+predict.fregre.fd">predict.fregre.fd</a></code>.
</p>
<p>Alternative method: <code><a href="#topic+fregre.basis">fregre.basis</a></code> and <code><a href="#topic+fregre.np">fregre.np</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
absorp &lt;- tecator$absorp.fdata
ind &lt;- 1:129
x &lt;- absorp[ind,]
y &lt;- tecator$y$Fat[ind]
res &lt;- fregre.pc(x,y)
summary(res)
res2 &lt;- fregre.pc(x,y,l=c(1,3,4))
summary(res2)
# Functional Ridge Regression
res3 &lt;- fregre.pc(x,y,l=c(1,3,4),lambda=1,P=1)
summary(res3)
# Functional Regression with 2nd derivative penalization
res4 &lt;- fregre.pc(x,y,l=c(1,3,4),lambda=1,P=c(0,0,1))
summary(res4)
betas &lt;- c(res$beta.est,res2$beta.est,
           res3$beta.est,res4$beta.est)
plot(betas)

## End(Not run) 

</code></pre>

<hr>
<h2 id='fregre.pc.cv'>Functional penalized PC regression with scalar response using selection of
number of PC components</h2><span id='topic+fregre.pc.cv'></span>

<h3>Description</h3>

<p>Functional Regression with scalar response using selection of number of
(penalized) principal components PC through cross-validation. The algorithm
selects the PC with best estimates the response. The selection is performed
by cross-validation (CV) or Model Selection Criteria (MSC). After is
computing functional regression using the best selection of principal
components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.pc.cv(
  fdataobj,
  y,
  kmax = 8,
  lambda = 0,
  P = c(0, 0, 1),
  criteria = "SIC",
  weights = rep(1, len = n),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.pc.cv_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fregre.pc.cv_+3A_y">y</code></td>
<td>
<p>Scalar response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="fregre.pc.cv_+3A_kmax">kmax</code></td>
<td>
<p>The number of components to include in the model.</p>
</td></tr>
<tr><td><code id="fregre.pc.cv_+3A_lambda">lambda</code></td>
<td>
<p>Vector with the amounts of penalization. Default value is 0,
i.e. no penalization is used.  If <code>lambda=TRUE</code> the algorithm computes
a sequence of lambda values.</p>
</td></tr>
<tr><td><code id="fregre.pc.cv_+3A_p">P</code></td>
<td>
<p>The vector of coefficients to define the penalty matrix object. For
example, if <code>P=c(1,0,0)</code>, ridge regresion is computed and if
<code>P=c(0,0,1)</code>, penalized regression is computed penalizing the second
derivative (curvature).</p>
</td></tr>
<tr><td><code id="fregre.pc.cv_+3A_criteria">criteria</code></td>
<td>
<p>Type of cross-validation (CV) or Model Selection Criteria
(MSC) applied. Possible values are <em>&quot;CV&quot;</em>, <em>&quot;AIC&quot;</em>, <em>&quot;AICc&quot;</em>,
<em>&quot;SIC&quot;</em>, <em>&quot;SICc&quot;</em>, <em>&quot;HQIC&quot;</em>.</p>
</td></tr>
<tr><td><code id="fregre.pc.cv_+3A_weights">weights</code></td>
<td>
<p>weights</p>
</td></tr>
<tr><td><code id="fregre.pc.cv_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code><a href="#topic+fregre.pc">fregre.pc</a></code> or
<code><a href="#topic+fregre.pls">fregre.pls</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm selects the best principal components <code>pc.opt</code> from the first <code>kmax</code> PC and (optionally) the best penalized parameter <code>lambda.opt</code> from a sequence of non-negative
numbers <code>lambda</code>. <br />  
If <code>kmax</code> is a integer (by default and recomended) the procedure is as follows (see example 1):
</p>

<ul>
<li><p> Calculate the best principal component (<em>pc.order[1]</em>) between <code>kmax</code> by
<code><a href="#topic+fregre.pc">fregre.pc</a></code>.
</p>
</li>
<li><p> Calculate the second-best principal component (<code>pc.order [2]</code>) between the <code>(kmax-1)</code> by
<code><a href="#topic+fregre.pc">fregre.pc</a></code> and calculate the criteria value of the two
principal components.  
</p>
</li>
<li><p> The process (point 1 and 2) is repeated until <code>kmax</code> principal component (<em>pc.order[kmax]</em>). 
</p>
</li>
<li><p> The proces (point 1, 2 and 3) is repeated for each <code>lambda</code> value.
</p>
</li>
<li><p> The method selects the principal components (<code>pc.opt</code>=<code>pc.order[1:k.min]</code>) and (optionally) the lambda
parameter with minimum MSC criteria.
</p>
</li></ul>

<p>If <code>kmax</code> is a sequence of integer the procedure is as follows (see example 2): 
</p>

<ul>
<li><p> The method selects the best principal components with minimum MSC criteria by
stepwise regression using <code><a href="#topic+fregre.pc">fregre.pc</a></code> in each step.  
</p>
</li>
<li><p> The process (point 1) is repeated for each <code>lambda</code> value.
</p>
</li>
<li><p> The method selects the principal components (<code>pc.opt</code>=<code>pc.order[1:k.min]</code>) and (optionally) the lambda
parameter with minimum MSC criteria. 
</p>
</li></ul>

<p>Finally, is computing functional PC regression between functional explanatory variable <code class="reqn">X(t)</code> and scalar
response <code class="reqn">Y</code> using the best selection of PC <code>pc.opt</code> and ridge
parameter <code>rn.opt</code>.  <br />  
The criteria selection is done by cross-validation (CV) or Model Selection
Criteria (MSC).  
</p>

<ul>
<li><p> Predictive Cross-Validation:
<code class="reqn">PCV(k_n)=\frac{1}{n}\sum_{i=1}^{n}{\Big(y_i -\hat{y}_{(-i,k_n)}
\Big)^2}</code>,<br />
<code>criteria</code>=&ldquo;CV&rdquo;
</p>
</li>
<li><p> Model Selection Criteria: <code class="reqn">MSC(k_n)=log \left[
\frac{1}{n}\sum_{i=1}^{n}{\Big(y_i-\hat{y}_i\Big)^2} \right]
+p_n\frac{k_n}{n} </code> 
</p>
</li></ul>

<p><code class="reqn">p_n=\frac{log(n)}{n}</code>, <code>criteria</code>=&ldquo;SIC&rdquo; (by default)<br />
<code class="reqn">p_n=\frac{log(n)}{n-k_n-2}</code>, <code>criteria</code>=&ldquo;SICc&rdquo;<br /> 
<code class="reqn">p_n=2</code>, <code>criteria</code>=&ldquo;AIC&rdquo;<br />
<code class="reqn">p_n=\frac{2n}{n-k_n-2}</code>, <code>criteria</code>=&ldquo;AICc&rdquo;<br />
<code class="reqn">p_n=\frac{2log(log(n))}{n}</code>, <code>criteria</code>=&ldquo;HQIC&rdquo;<br />
where <code>criteria</code> is an argument that controls the
type of validation used in the selection of the smoothing parameter
<code>kmax</code><code class="reqn">=k_n</code> and penalized parameter
<code>lambda</code><code class="reqn">=\lambda</code>.
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>fregre.pc</code>: Fitted regression object by the best (<code>pc.opt</code>) components.
</p>
</li>
<li> <p><code>pc.opt</code>: Index of PC components selected.
</p>
</li>
<li> <p><code>MSC.min</code>: Minimum Model Selection Criteria (MSC) value for the (<code>pc.opt</code>) components.
</p>
</li>
<li> <p><code>MSC</code>: Minimum Model Selection Criteria (MSC) value for <code>kmax</code> components.
</p>
</li></ul>



<h3>Note</h3>

<p><code>criteria=``CV''</code> is not recommended: time-consuming.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).
<em>Statistical Computing in Functional Data Analysis: The R Package
fda.usc.</em> Journal of Statistical Software, 51(4), 1-28.
<a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See also as:<code><a href="#topic+fregre.pc">fregre.pc</a></code> .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x&lt;-tecator$absorp.fdata[1:129]
y&lt;-tecator$y$Fat[1:129]
# no penalization
 res.pc1=fregre.pc.cv(x,y,8)
# 2nd derivative penalization
 res.pc2=fregre.pc.cv(x,y,8,lambda=TRUE,P=c(0,0,1))
# Ridge regression
res.pc3=fregre.pc.cv(x,y,1:8,lambda=TRUE,P=1) 

## End(Not run)

</code></pre>

<hr>
<h2 id='fregre.plm'>Semi-functional partially linear model with scalar response.</h2><span id='topic+fregre.plm'></span>

<h3>Description</h3>

<p>Computes functional regression between functional (and non functional)
explanatory variables and scalar response using asymmetric kernel
estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.plm(
  formula,
  data,
  h = NULL,
  Ker = AKer.norm,
  metric = metric.lp,
  type.CV = GCV.S,
  type.S = S.NW,
  par.CV = list(trim = 0, draw = FALSE),
  par.S = list(w = 1),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.plm_+3A_formula">formula</code></td>
<td>
<p>an object of class <code>formula</code> (or one that can be coerced
to that class): a symbolic description of the model to be fitted. The
details of model specification are given under <code>Details</code>.</p>
</td></tr>
<tr><td><code id="fregre.plm_+3A_data">data</code></td>
<td>
<p>List that containing the variables in the model.</p>
</td></tr>
<tr><td><code id="fregre.plm_+3A_h">h</code></td>
<td>
<p>Bandwidth, <code>h&gt;0</code>. Default argument values are provided as the
sequence of length 51 from 2.5%&ndash;quantile to 25%&ndash;quantile of the distance
between the functional data, see <code><a href="#topic+h.default">h.default</a></code>.</p>
</td></tr>
<tr><td><code id="fregre.plm_+3A_ker">Ker</code></td>
<td>
<p>Type of asymmetric kernel used, by default asymmetric normal
kernel.</p>
</td></tr>
<tr><td><code id="fregre.plm_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="fregre.plm_+3A_type.cv">type.CV</code></td>
<td>
<p>Type of cross-validation. By default generalized
cross-validation <code><a href="#topic+GCV.S">GCV.S</a></code> method.</p>
</td></tr>
<tr><td><code id="fregre.plm_+3A_type.s">type.S</code></td>
<td>
<p>Type of smothing matrix <code>S</code>. By default <code>S</code> is
calculated by Nadaraya-Watson kernel estimator (<code>S.NW</code>).</p>
</td></tr>
<tr><td><code id="fregre.plm_+3A_par.cv">par.CV</code></td>
<td>
<p>List of parameters for <code>type.CV</code>: <code>trim</code>, the alpha
of the trimming<br /> and <code>draw=TRUE</code>.</p>
</td></tr>
<tr><td><code id="fregre.plm_+3A_par.s">par.S</code></td>
<td>
<p>List of parameters for <code>type.S</code>: <code>w</code>, the weights.</p>
</td></tr>
<tr><td><code id="fregre.plm_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An extension of the non-parametric functional regression models is the
semi-functional partial linear model proposed in Aneiros-Perez and Vieu
(2005). This model uses a non-parametric kernel procedure as that described
in <code><a href="#topic+fregre.np">fregre.np</a></code>. The output <code class="reqn">y</code> is scalar. A functional
covariate <code class="reqn">X</code> and a multivariate non functional covariate <code class="reqn">Z</code> are
considered.
</p>
<p style="text-align: center;"><code class="reqn">y =r(X)+\sum_{j=1}^{p}{Z_j\beta_j}+\epsilon</code>
</p>

<p>The unknown smooth real function <code class="reqn">r</code> is estimated by means of
</p>
<p style="text-align: center;"><code class="reqn">\hat{r}_{h}(X)=\sum_{i=1}^{n}{w_{n,h}(X,X_{i})(Y_{i}-Z_{i}^{T}\hat{\beta}_{h})}</code>
</p>
<p> where <code class="reqn">W_h</code> is the weight
function:
</p>
<p><code class="reqn">w_{n,h}(X,X_{i})=\frac{K(d(X,X_i)/h)}{\sum_{j=1}^{n}K(d(X,X_j)/h)}</code> with smoothing
parameter <code class="reqn">h</code>, an asymmetric kernel <code class="reqn">K</code> and a metric or semi-metric
<code class="reqn">d</code>.  In <code>fregre.plm()</code> by default <code class="reqn">W_h</code> is a functional
version of the Nadaraya-Watson-type weights (<code>type.S=S.NW</code>) with
asymmetric normal kernel (<code>Ker=AKer.norm</code>) in <code class="reqn">L_2</code><br />
(<code>metric=metric.lp</code> with <code>p=2</code>). The unknown parameters
<code class="reqn">\beta_j</code> for the multivariate non functional covariates are estimated
by means of
<code class="reqn">\hat{\beta}_j=(\tilde{Z}_{h}^{T}\tilde{Z}_{h})^{-1}\tilde{Z}_{h}^{T}\tilde{Z}_{h}</code> where <code class="reqn">\tilde{Z}_{h}=(I-W_{h})Z</code> with the
smoothing parameter <code class="reqn">h</code>. The errors <code class="reqn">\epsilon</code> are independent, with
zero mean, finite variance <code class="reqn">\sigma^2</code> and
<code class="reqn">E[\epsilon|Z_1,\ldots,Z_p,X(t)]=0</code>.<br />
</p>
<p>The first item in the <code>data</code> list is called <em>&quot;df&quot;</em> and is a data
frame with the response and non functional explanatory variables, as
<code>link{lm}</code>. If non functional data into the formula then
<code><a href="stats.html#topic+lm">lm</a></code> regression is performed.<br /> Functional variable
(<code>fdata</code> or <code>fd</code> class) is introduced in the second item in the
<code>data</code> list.  If only functional variable into the formula then
<code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code> is performed.<br />
</p>
<p>The function estimates the value of smoothing parameter or the bandwidth
<code>h</code> through Generalized Cross-validation <code>GCV</code> criteria. It
computes the distance between curves using the <code><a href="#topic+metric.lp">metric.lp</a></code>,
although you can also use other metric function. <br /> Different asymmetric
kernels can be used, see <code><a href="#topic+Kernel.asymmetric">Kernel.asymmetric</a></code>.<br />
</p>


<h3>Value</h3>


<ul>
<li> <p><code>call</code>: The matched call. 
</p>
</li>
<li> <p><code>fitted.values</code>: Estimated scalar response. 
</p>
</li>
<li> <p><code>residuals</code>: <code>y</code> minus <code>fitted values</code>.
</p>
</li>
<li> <p><code>df.residual</code>: The residual degrees of freedom. 
</p>
</li>
<li> <p><code>H</code>: Hat matrix.
</p>
</li>
<li> <p><code>r2</code>: Coefficient of determination. 
</p>
</li>
<li> <p><code>sr2</code>: Residual variance.
</p>
</li>
<li> <p><code>y</code>: Scalar response. 
</p>
</li>
<li> <p><code>fdataobj</code>: Functional explanatory data.
</p>
</li>
<li> <p><code>XX</code>: Non functional explanatory data. 
</p>
</li>
<li> <p><code>mdist</code>: Distance matrix between curves. 
</p>
</li>
<li> <p><code>betah</code>: beta coefficient estimated. 
</p>
</li>
<li> <p><code>data</code>: List that containing the variables in the model. 
</p>
</li>
<li> <p><code>Ker</code>: Asymmetric kernel used. 
</p>
</li>
<li> <p><code>h.opt</code>: Value that minimizes CV or GCV method. 
</p>
</li>
<li> <p><code>h</code>: Smoothing parameter or bandwidth.
</p>
</li>
<li> <p><code>data</code>: List that containing the variables in the model.
</p>
</li>
<li> <p><code>gcv</code>: GCV values. 
</p>
</li>
<li> <p><code>formula</code>: formula.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Aneiros-Perez G. and Vieu P. (2005). <em>Semi-functional
partial linear regression</em>.  Statistics &amp; Probability Letters, 76:1102-1110.
</p>
<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional data
analysis.</em> Springer Series in Statistics, New York.
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+predict.fregre.plm">predict.fregre.plm</a></code> and
<code><a href="#topic+summary.fregre.fd">summary.fregre.fd</a></code><br /> Alternative methods:
<code><a href="#topic+fregre.lm">fregre.lm</a></code>, <code><a href="#topic+fregre.np">fregre.np</a></code> and
<code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x=tecator$absorp.fdata[1:129]
dataf=tecator$y[1:129,]

f=Fat~Water+x
ldata=list("df"=dataf,"x"=x)
res.plm=fregre.plm(f,ldata)
summary(res.plm)

# with 2nd derivative of functional data
x.fd=fdata.deriv(x,nderiv=2)
f2=Fat~Water+x.fd
ldata2=list("df"=dataf,"x.fd"=x.fd)
res.plm2=fregre.plm(f2,ldata2)
summary(res.plm2)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.pls'>Functional Penalized PLS regression with scalar response</h2><span id='topic+fregre.pls'></span>

<h3>Description</h3>

<p>Computes functional linear regression between functional explanatory variable <code class="reqn">X(t)</code> and scalar response <code class="reqn">Y</code> using penalized Partial
Least Squares (PLS) </p>
<p style="text-align: center;"><code class="reqn">Y=\big&lt;\tilde{X},\beta\big&gt;+\epsilon=\int_{T}{\tilde{X}(t)\beta(t)dt+\epsilon}</code>
</p>
<p> where <code class="reqn"> \big&lt; \cdot , \cdot \big&gt;</code> denotes the inner product on
<code class="reqn">L_2</code> and <code class="reqn">\epsilon</code> are random errors with mean zero , finite variance <code class="reqn">\sigma^2</code> and <code class="reqn">E[\tilde{X}(t)\epsilon]=0</code>.<br />
<code class="reqn">\left\{\nu_k\right\}_{k=1}^{\infty}</code> orthonormal basis of PLS to represent the functional data as <code class="reqn">X_i(t)=\sum_{k=1}^{\infty}\gamma_{ik}\nu_k</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.pls(fdataobj, y = NULL, l = NULL, lambda = 0, P = c(0, 0, 1), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.pls_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fregre.pls_+3A_y">y</code></td>
<td>
<p>Scalar response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="fregre.pls_+3A_l">l</code></td>
<td>
<p>Index of components to include in the model.</p>
</td></tr>
<tr><td><code id="fregre.pls_+3A_lambda">lambda</code></td>
<td>
<p>Amount of penalization. Default value is 0, i.e. no
penalization is used.</p>
</td></tr>
<tr><td><code id="fregre.pls_+3A_p">P</code></td>
<td>
<p>If <code>P</code> is a vector: <code>P</code> are coefficients to define the
penalty matrix object. By default <code>P=c(0,0,1)</code> penalize the second
derivative (curvature) or acceleration.  If <code>P</code> is a matrix: P is the
penalty matrix object.</p>
</td></tr>
<tr><td><code id="fregre.pls_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Functional (FPLS) algorithm maximizes the covariance between <code class="reqn">X(t)</code> and the scalar response <code class="reqn">Y</code> via the partial least squares (PLS) components.
The functional penalized PLS are calculated in <code><a href="#topic+fdata2pls">fdata2pls</a></code> by alternative formulation of the NIPALS algorithm proposed by Kraemer and
Sugiyama (2011).<br /> 
Let <code class="reqn">\left\{\tilde{\nu}_k\right\}_{k=1}^{\infty}</code> the functional PLS components and <code class="reqn">\tilde{X}_i(t)=\sum_{k=1}^{\infty}\tilde{\gamma}_{ik}\tilde{\nu}_k</code> and <code class="reqn">\beta(t)=\sum_{k=1}^{\infty}\tilde{\beta}_k\tilde{\nu}_k</code>. The functional linear model is estimated by: </p>
<p style="text-align: center;"><code class="reqn">\hat{y}=\big&lt; X,\hat{\beta} \big&gt; \approx \sum_{k=1}^{k_n}\tilde{\gamma}_{k}\tilde{\beta}_k </code>
</p>
<p><br /> 
The response can be fitted by: 
</p>
 <ul>
<li> <p><code class="reqn">\lambda=0</code>, no penalization,
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}=\nu_k^{\top}(\nu_k^{\top}\nu_k)^{-1}\nu_k^{\top}y</code>
</p>


<ul>
<li><p> Penalized regression, <code class="reqn">\lambda&gt;0</code> and <code class="reqn">P\neq0</code>. For example, <code class="reqn">P=c(0,0,1)</code> penalizes the
second derivative (curvature) by <code>P=P.penalty(fdataobj["argvals"],P)</code>,
</p>
<p style="text-align: center;"><code class="reqn">\hat{y}=\nu_k^{\top}(\nu_k\top \nu_k+\lambda \nu_k^{\top} \textbf{P}\nu_k)^{-1}\nu_k^{\top}y</code>
</p>
 </li></ul>

</li></ul>



<h3>Value</h3>

<p>Return: 
</p>

<ul>
<li> <p><code>call</code>: The matched call of <code><a href="#topic+fregre.pls">fregre.pls</a></code> function.
</p>
</li>
<li> <p><code>beta.est</code>: Beta coefficient estimated of class <code>fdata</code>.
</p>
</li>
<li> <p><code>coefficients</code>: A named vector of coefficients.
</p>
</li>
<li> <p><code>fitted.values</code>: Estimated scalar response.
</p>
</li>
<li> <p><code>residuals</code>: <code>y</code> minus <code>fitted values</code>.
</p>
</li>
<li> <p><code>H</code>: Hat matrix.
</p>
</li>
<li> <p><code>df.residual</code>: The residual degrees of freedom.
</p>
</li>
<li> <p><code>r2</code>: Coefficient of determination.
</p>
</li>
<li> <p><code>GCV</code>: GCV criterion.
</p>
</li>
<li> <p><code>sr2</code>: Residual variance.
</p>
</li>
<li> <p><code>l</code>: Index of components to include in the model.
</p>
</li>
<li> <p><code>lambda</code>: Amount of shrinkage.
</p>
</li>
<li> <p><code>fdata.comp</code>: Fitted object in <code><a href="#topic+fdata2pls">fdata2pls</a></code> function.
</p>
</li>
<li> <p><code>lm</code>: Fitted object in <code><a href="stats.html#topic+lm">lm</a></code> function.
</p>
</li>
<li> <p><code>fdataobj</code>: Functional explanatory data.
</p>
</li>
<li> <p><code>y</code>: Scalar response.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Preda C. and Saporta G. <em>PLS regression on a stochastic
process</em>. Comput. Statist. Data Anal. 48 (2005): 149-158.
</p>
<p>N. Kraemer, A.-L. Boulsteix, and G. Tutz (2008). <em>Penalized Partial
Least Squares with Applications to B-Spline Transformations and Functional
Data</em>. Chemometrics and Intelligent Laboratory Systems, 94, 60 - 69.
<a href="https://doi.org/10.1016/j.chemolab.2008.06.009">doi:10.1016/j.chemolab.2008.06.009</a>
</p>
<p>Martens, H., Naes, T. (1989) <em>Multivariate calibration.</em> Chichester:
Wiley.
</p>
<p>Kraemer, N., Sugiyama M. (2011). <em>The Degrees of Freedom of Partial
Least Squares Regression</em>. Journal of the American Statistical Association.
Volume 106, 697-705.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+P.penalty">P.penalty</a></code> and
<code><a href="#topic+fregre.pls.cv">fregre.pls.cv</a></code>.<br /> Alternative method: <code><a href="#topic+fregre.pc">fregre.pc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x &lt;- tecator$absorp.fdata
y &lt;- tecator$y$Fat
res &lt;- fregre.pls(x,y,c(1:4))
summary(res)
res1 &lt;- fregre.pls(x,y,l=1:4,lambda=100,P=c(1))
res4 &lt;- fregre.pls(x,y,l=1:4,lambda=1,P=c(0,0,1))
summary(res4)#' plot(res$beta.est)
lines(res1$beta.est,col=4)
lines(res4$beta.est,col=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='fregre.pls.cv'>Functional penalized PLS regression with scalar response using selection of
number of PLS components</h2><span id='topic+fregre.pls.cv'></span>

<h3>Description</h3>

<p>Functional Regression with scalar response using selection of number of
penalized principal componentes PPLS through cross-validation. The algorithm
selects the PPLS components with best estimates the response. The selection
is performed by cross-validation (CV) or Model Selection Criteria (MSC).
After is computing functional regression using the best selection of PPLS
components.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fregre.pls.cv(
  fdataobj,
  y,
  kmax = 8,
  lambda = 0,
  P = c(0, 0, 1),
  criteria = "SIC",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fregre.pls.cv_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="fregre.pls.cv_+3A_y">y</code></td>
<td>
<p>Scalar response with length <code>n</code>.</p>
</td></tr>
<tr><td><code id="fregre.pls.cv_+3A_kmax">kmax</code></td>
<td>
<p>The number of components to include in the model.</p>
</td></tr>
<tr><td><code id="fregre.pls.cv_+3A_lambda">lambda</code></td>
<td>
<p>Vector with the amounts of penalization. Default value is 0,
i.e. no penalization is used.  If <code>lambda=TRUE</code> the algorithm computes
a sequence of lambda values.</p>
</td></tr>
<tr><td><code id="fregre.pls.cv_+3A_p">P</code></td>
<td>
<p>The vector of coefficients to define the penalty matrix object. For
example, if <code>P=c(0,0,1)</code>, penalized regression is computed penalizing
the second derivative (curvature).</p>
</td></tr>
<tr><td><code id="fregre.pls.cv_+3A_criteria">criteria</code></td>
<td>
<p>Type of cross-validation (CV) or Model Selection Criteria
(MSC) applied. Possible values are <em>&quot;CV&quot;</em>, <em>&quot;AIC&quot;</em>, <em>&quot;AICc&quot;</em>,
<em>&quot;SIC&quot;</em>, <em>&quot;SICc&quot;</em>, <em>&quot;HQIC&quot;</em>.</p>
</td></tr>
<tr><td><code id="fregre.pls.cv_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code><a href="#topic+fregre.pls">fregre.pls</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The algorithm selects the best principal components
<code>pls.opt</code> from the first <code>kmax</code> PLS and (optionally) the best
penalized parameter <code>lambda.opt</code> from a sequence of non-negative
numbers <code>lambda</code>. 
</p>
 
<ul>
<li><p> The method selects the best principal components with
minimum MSC criteria by stepwise regression using <code><a href="#topic+fregre.pls">fregre.pls</a></code>
in each step.  
</p>
</li>
<li><p> The process (point 1) is repeated for each <code>lambda</code> value.  
</p>
</li>
<li><p> The method selects the principal components (<code>pls.opt</code>=<code>pls.order[1:k.min]</code>) and (optionally) the lambda parameter with minimum MSC criteria.
</p>
</li></ul>
 
<p>Finally, is computing functional PLS regression between functional explanatory variable <code class="reqn">X(t)</code> and scalar response <code class="reqn">Y</code> using the best selection of PLS <code>pls.opt</code> and ridge parameter <code>rn.opt</code>.  
The criteria selection is done by cross-validation (CV) or Model Selection Criteria (MSC).   
</p>
 
<ul>
<li><p> Predictive Cross-Validation: <code class="reqn">PCV(k_n)=\frac{1}{n}\sum_{i=1}^{n}{\Big(y_i -\hat{y}_{(-i,k_n)}\Big)^2}</code>, <code>criteria</code>=&ldquo;CV&rdquo; 
</p>
</li>
<li><p> Model Selection Criteria: 
<code class="reqn">MSC(k_n)=log \left[ \frac{1}{n}\sum_{i=1}^{n}{\Big(y_i-\hat{y}_i\Big)^2} \right] +p_n\frac{k_n}{n} </code> <br />
<code class="reqn">p_n=\frac{log(n)}{n}</code>, <code>criteria</code>=&ldquo;SIC&rdquo; (by default)<br />
<code class="reqn">p_n=\frac{log(n)}{n-k_n-2}</code>,
<code>criteria</code>=&ldquo;SICc&rdquo;<br /> <code class="reqn">p_n=2</code>, <code>criteria</code>=&ldquo;AIC&rdquo;<br />
<code class="reqn">p_n=\frac{2n}{n-k_n-2}</code>, <code>criteria</code>=&ldquo;AICc&rdquo;<br />
<code class="reqn">p_n=\frac{2log(log(n))}{n}</code>,
<code>criteria</code>=&ldquo;HQIC&rdquo;<br />
where <code>criteria</code> is an argument that controls the
type of validation used in the selection of the smoothing parameter
<code>kmax</code><code class="reqn">=k_n</code> and penalized parameter <code>lambda</code><code class="reqn">=\lambda</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>fregre.pls</code>: Fitted regression object by the best (<code>pls.opt</code>) components.
</p>
</li>
<li> <p><code>pls.opt</code>: Index of PLS components selected.
</p>
</li>
<li> <p><code>MSC.min</code>: Minimum Model Selection Criteria (MSC) value for the (<code>pls.opt</code>) components.
</p>
</li>
<li> <p><code>MSC</code>: Minimum Model Selection Criteria (MSC) value for <code>kmax</code> components.
</p>
</li></ul>



<h3>Note</h3>

<p><code>criteria=``CV''</code> is not recommended: time-consuming.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Preda C. and Saporta G. <em>PLS regression on a stochastic
process</em>. Comput. Statist. Data Anal. 48 (2005): 149-158.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See also as:<code><a href="#topic+fregre.pc">fregre.pc</a></code> .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x&lt;-tecator$absorp.fdata[1:129]
y&lt;-tecator$y$Fat[1:129]
# no penalization
pls1&lt;- fregre.pls.cv(x,y,8)
# 2nd derivative penalization
pls2&lt;-fregre.pls.cv(x,y,8,lambda=0:5,P=c(0,0,1))

## End(Not run)

</code></pre>

<hr>
<h2 id='GCCV.S'>The generalized correlated cross-validation (GCCV) score.</h2><span id='topic+GCCV.S'></span>

<h3>Description</h3>

<p>The generalized correlated cross-validation (GCV) score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GCCV.S(
  y,
  S,
  criteria = "GCCV1",
  W = NULL,
  trim = 0,
  draw = FALSE,
  metric = metric.lp,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GCCV.S_+3A_y">y</code></td>
<td>
<p>Response vectorith length <code>n</code> or Matrix of set cases with
dimension (<code>n</code> x <code>m</code>), where <code>n</code> is the number of curves and
<code>m</code> are the points observed in each curve.</p>
</td></tr>
<tr><td><code id="GCCV.S_+3A_s">S</code></td>
<td>
<p>Smoothing matrix, see <code><a href="#topic+S.NW">S.NW</a></code>, <code><a href="#topic+S.LLR">S.LLR</a></code> or
<code class="reqn">S.KNN</code>.</p>
</td></tr>
<tr><td><code id="GCCV.S_+3A_criteria">criteria</code></td>
<td>
<p>The penalizing function. By default <em>&quot;Rice&quot;</em> criteria.
&quot;GCCV1&quot;,&quot;GCCV2&quot;,&quot;GCCV3&quot;,&quot;GCV&quot;) Possible values are <em>&quot;GCCV1&quot;</em>,
<em>&quot;GCCV2&quot;</em>, <em>&quot;GCCV3&quot;</em>, <em>&quot;GCV&quot;</em>.</p>
</td></tr>
<tr><td><code id="GCCV.S_+3A_w">W</code></td>
<td>
<p>Matrix of weights.</p>
</td></tr>
<tr><td><code id="GCCV.S_+3A_trim">trim</code></td>
<td>
<p>The alpha of the trimming.</p>
</td></tr>
<tr><td><code id="GCCV.S_+3A_draw">draw</code></td>
<td>
<p>=TRUE, draw the curves, the sample median and trimmed mean.</p>
</td></tr>
<tr><td><code id="GCCV.S_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="GCCV.S_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p style="text-align: center;"><code class="reqn">GCCV = \frac{\sum_{i=1}^n {(y_{i} - \hat{y}_{i, b})}^2}{(1 - \frac{tr(C)}{n})^2}</code>
</p>

<p>where <code class="reqn">C = 2S\Sigma(\theta) - S\Sigma(\theta)S'</code> <br />
and <code class="reqn">\Sigma</code> is the <code class="reqn">n \times n</code> covariance matrix with <code class="reqn">cor(\epsilon_i, \epsilon_j) = \sigma</code>.<br />
</p>
<p>Here, <code class="reqn">S</code> is the smoothing matrix, and there are options for <code class="reqn">C</code>:
</p>

<ul>
<li><p> A.- If <code class="reqn">C = 2S\Sigma - S\Sigma S</code>
</p>
</li>
<li><p> B.- If <code class="reqn">C = S\Sigma</code>
</p>
</li>
<li><p> C.- If <code class="reqn">C = S\Sigma S'</code>
</p>
</li></ul>

<p>with <code class="reqn">\Sigma</code> as the <code class="reqn">n \times n</code> covariance matrix and <code class="reqn">cor(\epsilon_i, \epsilon_j) = \sigma</code>.
</p>


<h3>Value</h3>

<p>Returns GCCV score calculated for input parameters.
</p>


<h3>Note</h3>

<p>Provided that <code class="reqn">C = I</code> and the smoother matrix S is symmetric and
idempotent, as is the case for many linear fitting techniques, the trace
term reduces to <code class="reqn">n - tr[S]</code>, which is proportional to the familiar
denominator in GCV.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Carmack, P. S., Spence, J. S., and Schucany, W. R. (2012).
Generalised correlated cross-validation. Journal of Nonparametric
Statistics, 24(2):269&ndash;282.
</p>
<p>Oviedo de la Fuente, M., Febrero-Bande, M., Munoz, P., and Dominguez, A.
Predicting seasonal influenza transmission using Functional Regression
Models with Temporal Dependence.<a href="https://arxiv.org/abs/1610.08718">https://arxiv.org/abs/1610.08718</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+optim.np">optim.np</a></code>. <br /> Alternative method
(independent case): <code><a href="#topic+GCV.S">GCV.S</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x=tecator$absorp.fdata
x.d2&lt;-fdata.deriv(x,nderiv=)
tt&lt;-x[["argvals"]]
dataf=as.data.frame(tecator$y)
y=tecator$y$Fat
# plot the response
plot(ts(tecator$y$Fat))

nbasis.x=11;nbasis.b=7
basis1=create.bspline.basis(rangeval=range(tt),nbasis=nbasis.x)
basis2=create.bspline.basis(rangeval=range(tt),nbasis=nbasis.b)
basis.x=list("x.d2"=basis1)
basis.b=list("x.d2"=basis2)
ldata=list("df"=dataf,"x.d2"=x.d2)
# No correlation
res.gls=fregre.gls(Fat~x.d2,data=ldata, 
                   basis.x=basis.x,basis.b=basis.b)
# AR1 correlation                   
res.gls=fregre.gls(Fat~x.d2,data=ldata, correlation=corAR1(),
                   basis.x=basis.x,basis.b=basis.b)
GCCV.S(y,res.gls$H,"GCCV1",W=res.gls$W)
res.gls$gcv

## End(Not run)
</code></pre>

<hr>
<h2 id='GCV.S'>The generalized correlated cross-validation (GCCV) score</h2><span id='topic+GCV.S'></span>

<h3>Description</h3>

<p>Compute the  generalized correlated cross-validation (GCV) score.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>GCV.S(
  y,
  S,
  criteria = "GCV",
  W = NULL,
  trim = 0,
  draw = FALSE,
  metric = metric.lp,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="GCV.S_+3A_y">y</code></td>
<td>
<p>Matrix of set cases with dimension (<code>n</code> x <code>m</code>), where
<code>n</code> is the number of curves and <code>m</code> are the points observed in
each curve.</p>
</td></tr>
<tr><td><code id="GCV.S_+3A_s">S</code></td>
<td>
<p>Smoothing matrix, see <code><a href="#topic+S.NW">S.NW</a></code>, <code><a href="#topic+S.LLR">S.LLR</a></code> or</p>
</td></tr>
<tr><td><code id="GCV.S_+3A_criteria">criteria</code></td>
<td>
<p>The penalizing function. By default <em>&quot;Rice&quot;</em> criteria. 
Possible values are <em>&quot;GCCV1&quot;</em>, <em>&quot;GCCV2&quot;</em>, <em>&quot;GCCV3&quot;</em>, <em>&quot;GCV&quot;</em>.</p>
</td></tr>
<tr><td><code id="GCV.S_+3A_w">W</code></td>
<td>
<p>Matrix of weights.</p>
</td></tr>
<tr><td><code id="GCV.S_+3A_trim">trim</code></td>
<td>
<p>The alpha of the trimming.</p>
</td></tr>
<tr><td><code id="GCV.S_+3A_draw">draw</code></td>
<td>
<p>=TRUE, draw the curves, the sample median and trimmed mean.</p>
</td></tr>
<tr><td><code id="GCV.S_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="GCV.S_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A.-If <code>trim=0</code>:<br />
</p>
<p style="text-align: center;"><code class="reqn">GCCV=\frac{\sum_{i=1}^n {y_{i}-\hat{y}_{i,b}}^2}{1-\frac{tr(C)}{n}^2}</code>
</p>
 
<p>where <code class="reqn">S</code> is the smoothing matrix <code class="reqn">S</code> and:<br />
A.-If <code class="reqn">C=2S\Sigma - S\Sigma S</code> <br />
B.-If  <code class="reqn">C=S\Sigma</code> <br />
C.-If  <code class="reqn">C=S\Sigma S'</code> <br />
with <code class="reqn">\Sigma</code> is the n x n covariance matrix with
<code class="reqn">cor(\epsilon_i,\epsilon_j ) =\sigma</code>
Note: Provided that <code class="reqn">C = I</code> and the smoother matrix S is symmetric and idempotent, as is the case for many linear fitting techniques, the trace term reduces to  <code class="reqn">n - tr[S]</code>, which is proportional to the familiar denominator in GCV.
</p>


<h3>Value</h3>

<p> Returns GCV score calculated for input parameters.  
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Wasserman, L. <em>All of Nonparametric Statistics</em>. Springer Texts in Statistics, 2006. 
Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University Press, 1994.
Febrero-Bande,  M., Oviedo de la Fuente, M. (2012).  <em>Statistical Computing in Functional Data Analysis: The R Package fda.usc.</em>
Journal of Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+optim.np">optim.np</a></code> <br /> Alternative method:
<code><a href="#topic+CV.S">CV.S</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
mlearn&lt;-phoneme$learn
tt&lt;-1:ncol(mlearn)
S1 &lt;- S.NW(tt,2.5)
S2 &lt;- S.LLR(tt,2.5)
gcv1 &lt;- GCV.S(mlearn, S1)
gcv2 &lt;- GCV.S(mlearn, S2)
gcv3 &lt;- GCV.S(mlearn, S1,criteria="AIC")
gcv4 &lt;- GCV.S(mlearn, S2,criteria="AIC")
gcv1; gcv2; gcv3; gcv4

## End(Not run)
 
</code></pre>

<hr>
<h2 id='h.default'>Calculation of the smoothing parameter (h) for a functional data</h2><span id='topic+h.default'></span>

<h3>Description</h3>

<p>Calculation of the smoothing parameter (h) for a functional data using
nonparametric kernel estimation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>h.default(
  fdataobj,
  prob = c(0.025, 0.25),
  len = 51,
  metric = metric.lp,
  type.S = "S.NW",
  Ker = Ker.norm,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="h.default_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="h.default_+3A_prob">prob</code></td>
<td>
<p>Vector of probabilities for extracting the quantiles of the distance matrix. If <code>length(prob)=2</code> 
a sequence between <code>prob[1]</code> and <code>prob[2]</code> of length <code>len</code>.</p>
</td></tr>
<tr><td><code id="h.default_+3A_len">len</code></td>
<td>
<p>Vector length of smoothing parameter <code>h</code> to return only used when <code>length(prob)=2</code>.</p>
</td></tr>
<tr><td><code id="h.default_+3A_metric">metric</code></td>
<td>
<p>If is a function: name of the function to calculate the
distance matrix between the curves, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.  If
is a matrix: distance matrix between the curves.
kernel.</p>
</td></tr>
<tr><td><code id="h.default_+3A_type.s">type.S</code></td>
<td>
<p>Type of smothing matrix <code>S</code>.  Possible values are:
Nadaraya-Watson estimator <em>&quot;S.NW&quot;</em> and K nearest neighbors estimator
<em>&quot;S.KNN&quot;</em></p>
</td></tr>
<tr><td><code id="h.default_+3A_ker">Ker</code></td>
<td>
<p>Kernel function. By default, <em>Ker.norm</em>. Useful for scaling the bandwidth values
according to Kernel</p>
</td></tr>
<tr><td><code id="h.default_+3A_...">...</code></td>
<td>
<p>Arguments to be passed for metric argument.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the vector of smoothing parameter or bandwidth <code>h</code>.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+metric.lp">metric.lp</a></code>, <code><a href="#topic+Kernel">Kernel</a></code> and
<code><a href="#topic+S.NW">S.NW</a></code>. <br /> Function used in <code><a href="#topic+fregre.np">fregre.np</a></code> and
<code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(aemet)
h1&lt;-h.default(aemet$temp,prob=c(0.025, 0.25),len=2)
mdist&lt;-metric.lp(aemet$temp)
h2&lt;-h.default(aemet$temp,len=2,metric=mdist)
h3&lt;-h.default(aemet$temp,len=2,metric=semimetric.pca,q=2)
h4&lt;-h.default(aemet$temp,len=2,metric=semimetric.pca,q=4)
h5&lt;-h.default(aemet$temp,prob=c(.2),type.S="S.KNN")
h1;h2;h3;h4;h5

## End(Not run)
</code></pre>

<hr>
<h2 id='influence_quan'>Quantile for influence measures</h2><span id='topic+influence_quan'></span>

<h3>Description</h3>

<p>Estimate the quantile of measures of influence for each observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>influence_quan(model,out.influ,mue.boot=500,
smo=0.1,smoX=0.05,alpha=0.95,kmax.fix=FALSE,...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="influence_quan_+3A_model">model</code></td>
<td>
<p><code>fregre.pc</code>, <code>fregre.basis</code> or <code>fregre.basis.cv</code>
object.</p>
</td></tr>
<tr><td><code id="influence_quan_+3A_out.influ">out.influ</code></td>
<td>
<p><code>inflluence.fd</code> bject</p>
</td></tr>
<tr><td><code id="influence_quan_+3A_mue.boot">mue.boot</code></td>
<td>
<p>Number of bootstrap samples</p>
</td></tr>
<tr><td><code id="influence_quan_+3A_smo">smo</code></td>
<td>
<p>Smoothing parameter as a proportion of response variance.</p>
</td></tr>
<tr><td><code id="influence_quan_+3A_smox">smoX</code></td>
<td>
<p>Smoothing parameter for <code>fdata</code> object as a proportion of
variance-covariance matrix of the explanatory functional variable.</p>
</td></tr>
<tr><td><code id="influence_quan_+3A_alpha">alpha</code></td>
<td>
<p>Significance level.</p>
</td></tr>
<tr><td><code id="influence_quan_+3A_kmax.fix">kmax.fix</code></td>
<td>
<p>The maximum number of principal comoponents or number of
basis is fixed by <code>model</code> object.</p>
</td></tr>
<tr><td><code id="influence_quan_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Compute the quantile of measures of influence estimated in
<code><a href="#topic+influence.fregre.fd">influence.fregre.fd</a></code> for functional regression using principal
components representation (<code><a href="#topic+fregre.pc">fregre.pc</a></code>) or basis
representation<br /> (<code><a href="#topic+fregre.basis">fregre.basis</a></code> or
<code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code>).
</p>
<p>A smoothed bootstrap method is used to estimate the quantiles of the influence measures, which allows to point out
which observations have the larger influence on estimation and prediction.
</p>


<h3>Value</h3>

<p>Return:
</p>
 
<ul>
<li> <p><code>quan.cook.for</code>:  Distance Cook Prediction Quantile.
</p>
</li>
<li> <p><code>quan.cook.est</code>: Distance Cook Estimation Quantile.
</p>
</li>
<li> <p><code>quan.cook.Pena</code>: Pena Distance Quantile.
</p>
</li>
<li> <p><code>mues.est</code>: Sample Cook generated. 
</p>
</li>
<li> <p><code>mues.pena</code>: Sample Pena generated.
</p>
</li>
<li> <p><code>beta.boot</code>: Functional beta estimated by bootstrap method.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Galeano, P. and Gonzalez-Manteiga, W. (2010).
<em>Measures of influence for the functional linear model with scalar
response</em>. Journal of Multivariate Analysis 101, 327-339.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+influence.fregre.fd">influence.fregre.fd</a></code>,
<code><a href="#topic+fregre.basis">fregre.basis</a></code>, <code><a href="#topic+fregre.pc">fregre.pc</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x=tecator$absorp.fdata
y=tecator$y$Fat
res=fregre.pc(x,y,1:6)

#time consuming
res.infl=influence.fregre.fd(res)
resquan=influence_quan(res,res.infl,4,0.01,0.05,0.95)
plot(res.infl$betas,type="l",col=2)
lines(res$beta.est,type="l",col=3)
lines(resquan$betas.boot,type="l",col="gray")

res=fregre.basis(x,y)
res.infl=influence.fregre.fd(res)
resquan=influence_quan(res,res.infl,mue.boot=4,kmax.fix=T)
plot(resquan$betas.boot,type="l",col=4)
lines(res.infl$betas,type="l",col=2)
lines(resquan$betas.boot,type="l",col="gray")

## End(Not run)
</code></pre>

<hr>
<h2 id='influence.fregre.fd'>Functional influence measures</h2><span id='topic+influence.fregre.fd'></span>

<h3>Description</h3>

<p>Once estimated the functional regression model with scalar response,
influence.fregre.fd function is used to obtain the functional influence measures.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fregre.fd'
influence(model, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="influence.fregre.fd_+3A_model">model</code></td>
<td>
<p><code>fregre.pc</code>, <code>fregre.basis</code> or <code>fregre.basis.cv</code> object.</p>
</td></tr>
<tr><td><code id="influence.fregre.fd_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Identify influential observations in the functional linear model in which 
the predictor is functional and the response is scalar.
Three statistics are introduced for measuring the influence:   Distance Cook Prediction
<code>DCP</code>, Distance Cook Estimation <code>DCE</code> and Distance
<code class="reqn">\mbox{pe}\tilde{\mbox{n}}\mbox{a} </code> <code>DP</code> respectively.
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>DCP</code>: Cook's Distance for Prediction.
</p>
</li>
<li> <p><code>DCE</code>: Cook's Distance for Estimation.
</p>
</li>
<li> <p><code>DP</code>:<code class="reqn">\mbox{Pe}\tilde{\mbox{n}}\mbox{a's} </code> Distance.
</p>
</li></ul>



<h3>Note</h3>

<p>influence.fdata deprecated.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Galeano, P. and Gonzalez-Manteiga, W. (2010). <em>Measures of influence for the functional linear model with scalar response</em>. Journal of Multivariate Analysis 101, 327-339.
</p>
<p>Febrero-Bande,  M., Oviedo de la Fuente, M. (2012).  <em>Statistical Computing in Functional Data Analysis: The R Package fda.usc.</em>
Journal of Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as:  <code><a href="#topic+fregre.pc">fregre.pc</a></code>, <code><a href="#topic+fregre.basis">fregre.basis</a></code>, 
<code><a href="#topic+influence_quan">influence_quan</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
x=tecator$absorp.fdata[1:129]
y=tecator$y$Fat[1:129]

res1=fregre.pc(x,y,1:5)  
# time consuming
res.infl1=influence(res1)  
res2=fregre.basis(x,y)  
res.infl2=influence(res2)  

res&lt;-res1
res.infl&lt;-res.infl1
mat=cbind(y,res$fitted.values,res.infl$DCP,res.infl$DCE,res.infl$DP)
colnames(mat)=c("Resp.","Pred.","DCP","DCE","DP")
pairs(mat)

## End(Not run)
</code></pre>

<hr>
<h2 id='inprod.fdata'>Inner products of Functional Data Objects o class (fdata)</h2><span id='topic+inprod.fdata'></span>

<h3>Description</h3>

<p>Computes a inner products of functional data objects of class fdata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>inprod.fdata(fdata1, fdata2 = NULL, w = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="inprod.fdata_+3A_fdata1">fdata1</code></td>
<td>
<p>Functional data 1 or curve 1. <code>fdata1$data</code> with
dimension (<code>n1</code> x <code>m</code>), where <code>n1</code> is the number of curves
and <code>m</code> are the points observed in each curve.</p>
</td></tr>
<tr><td><code id="inprod.fdata_+3A_fdata2">fdata2</code></td>
<td>
<p>Functional data 2 or curve 2. <code>fdata2$data</code> with
dimension (<code>n2</code> x <code>m</code>), where <code>n2</code> is the number of curves
and <code>m</code> are the points observed in each curve.</p>
</td></tr>
<tr><td><code id="inprod.fdata_+3A_w">w</code></td>
<td>
<p>Vector of weights with length <code>m</code>, If <code>w</code> = 1
approximates the metric Lp by Simpson's rule. By default it uses <code>w</code> =
1</p>
</td></tr>
<tr><td><code id="inprod.fdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default it uses weights <code>w=1</code>.  </p>
<p style="text-align: center;"><code class="reqn"> \left\langle fdata1,fdata2
\right\rangle=\frac{1}{\int_{a}^{b}w(x)dx} \int_{a}^{b} fdata1(x) *
fdata2(x)w(x) dx </code>
</p>
<p> The observed points on each curve are equally spaced
(by default) or not.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See also <a href="fda.html#topic+inprod">inprod</a> and <code><a href="#topic+norm.fdata">norm.fdata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x&lt;-seq(0,2*pi,length=1001)
fx1&lt;-sin(x)/sqrt(pi)
fx2&lt;-cos(x)/sqrt(pi)
argv&lt;-seq(0,2*pi,len=1001)
fdat0&lt;-fdata(rep(0,len=1001),argv,range(argv))
fdat1&lt;-fdata(fx1,x,range(x))
inprod.fdata(fdat1,fdat1)
inprod.fdata(fdat1,fdat1)
metric.lp(fdat1)
metric.lp(fdat1,fdat0)
norm.fdata(fdat1)
# The same
integrate(function(x){(abs(sin(x)/sqrt(pi))^2)},0,2*pi)
integrate(function(x){(abs(cos(x)/sqrt(pi))^2)},0,2*pi)

## End(Not run)
</code></pre>

<hr>
<h2 id='int.simpson'>Simpson integration</h2><span id='topic+int.simpson'></span><span id='topic+int.simpson2'></span>

<h3>Description</h3>

<p>Computes the integral of <code>fdataobj$data</code> with respect to
<code>fdataobj$argvals</code> using simpson or trapezoid rule integration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>int.simpson(fdataobj, method = NULL)

int.simpson2(x, y, equi = TRUE, method = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="int.simpson_+3A_fdataobj">fdataobj</code></td>
<td>
<p>fdata objtect.</p>
</td></tr>
<tr><td><code id="int.simpson_+3A_method">method</code></td>
<td>
<p>Method for numerical integration, see details.</p>
</td></tr>
<tr><td><code id="int.simpson_+3A_x">x</code></td>
<td>
<p>Sorted vector of x-axis values: <code>argvals</code>.</p>
</td></tr>
<tr><td><code id="int.simpson_+3A_y">y</code></td>
<td>
<p>Vector of y-axis values.</p>
</td></tr>
<tr><td><code id="int.simpson_+3A_equi">equi</code></td>
<td>
<p>=TRUE, the observed points on each curve are equally spaced (by
default).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Posible values for <code>method</code> are: </p>
 <ul>
<li> <p><code>"TRAPZ"</code>:
Trapezoid rule integration. </p>
</li>
<li> <p><code>"CSR"</code>: Composite Simpson's rule
integration.  </p>
</li>
<li> <p><code>"ESR"</code>: Extended Simpson's rule integration. </p>
</li></ul>
<p> If
<code>method=NULL</code> (default), the value of <code>par.fda.usc$int.method</code> is
used.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See also <code><a href="stats.html#topic+integrate">integrate</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x&lt;-seq(0,2*pi,length=1001)
fx&lt;-fdata(sin(x)/sqrt(pi),x)
fx0&lt;-fdata(rep(0,length(x)),x)
int.simpson(fx0)
int.simpson(fx)

## End(Not run)
</code></pre>

<hr>
<h2 id='Kernel'>Symmetric Smoothing Kernels.</h2><span id='topic+Kernel'></span><span id='topic+Ker.norm'></span><span id='topic+Ker.cos'></span><span id='topic+Ker.epa'></span><span id='topic+Ker.tri'></span><span id='topic+Ker.quar'></span><span id='topic+Ker.unif'></span>

<h3>Description</h3>

<p>Represent symmetric smoothing kernels:: normal, cosine, triweight, quartic
and uniform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kernel(u, type.Ker = "Ker.norm")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Kernel_+3A_u">u</code></td>
<td>
<p>Data.</p>
</td></tr>
<tr><td><code id="Kernel_+3A_type.ker">type.Ker</code></td>
<td>
<p>Type of Kernel. By default normal kernel.</p>
</td></tr>
</table>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Ker.norm=dnorm(u)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
Ker.cos=ifelse(abs(u)&lt;=1,pi/4*(cos(pi*u/2)),0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
Ker.epa=ifelse(abs(u)&lt;=1,3/4*(1-u^2),0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
Ker.tri=ifelse(abs(u)&lt;=1,35/32*(1-u^2)^3,0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
Ker.quar=ifelse(abs(u)&lt;=1,15/16*(1-u^2)^2,0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
Ker.unif=ifelse(abs(u)&lt;=1,1/2,0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>Type of kernel: </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Normal Kernel: <code>Ker.norm</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
Cosine Kernel: <code>Ker.cos</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Epanechnikov Kernel: <code>Ker.epa</code></td>
</tr>
<tr>
 <td style="text-align: left;">
</td><td style="text-align: left;"> Triweight Kernel: <code>Ker.tri</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Quartic Kernel:
<code>Ker.quar</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Uniform Kernel: <code>Ker.unif</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Value</h3>

<p>Returns symmetric kernel.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York. <br />
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y=qnorm(seq(.1,.9,len=100))
a&lt;-Kernel(u=y)
b&lt;-Kernel(type.Ker="Ker.tri",u=y)
c=Ker.cos(y)
</code></pre>

<hr>
<h2 id='Kernel.asymmetric'>Asymmetric Smoothing Kernel</h2><span id='topic+Kernel.asymmetric'></span><span id='topic+AKer.norm'></span><span id='topic+AKer.cos'></span><span id='topic+AKer.epa'></span><span id='topic+AKer.tri'></span><span id='topic+AKer.quar'></span><span id='topic+AKer.unif'></span>

<h3>Description</h3>

<p>Represent Asymmetric Smoothing Kernels: normal, cosine, triweight, quartic
and uniform. </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> AKer.norm=ifelse(u&gt;=0,2*dnorm(u),0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
AKer.cos=ifelse(u&gt;=0,pi/2*(cos(pi*u/2)),0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> AKer.epa=ifelse(u&gt;=0 &amp;
u&lt;=1,3/2*(1-u^2),0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> AKer.tri=ifelse(u&gt;=0 &amp;
u&lt;=1,35/16*(1-u^2)^3,0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> AKer.quar=ifelse(u&gt;=0 &amp;
u&lt;=1,15/8*(1-u^2)^2,0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> AKer.unif=ifelse(u&gt;=0 &amp; u&lt;=1,1,0)</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Usage</h3>

<pre><code class='language-R'>Kernel.asymmetric(u, type.Ker = "AKer.norm")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Kernel.asymmetric_+3A_u">u</code></td>
<td>
<p>Data.</p>
</td></tr>
<tr><td><code id="Kernel.asymmetric_+3A_type.ker">type.Ker</code></td>
<td>
<p>Type of asymmetric metric kernel, by default asymmetric
normal kernel.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type of Asymmetric kernel: </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Asymmetric Normal Kernel:
<code>AKer.norm</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Asymmetric Cosine Kernel: <code>AKer.cos</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
Asymmetric Epanechnikov Kernel: <code>AKer.epa</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Asymmetric Triweight
Kernel: <code>AKer.tri</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Asymmetric Quartic Kernel:
<code>AKer.quar</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Asymmetric Uniform Kernel: <code>AKer.unif</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Value</h3>

<p>Returns asymmetric kernel.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y=qnorm(seq(.1,.9,len=100))
a&lt;-Kernel.asymmetric(u=y)
b&lt;-Kernel.asymmetric(type.Ker="AKer.tri",u=y)
c=AKer.cos(y)
</code></pre>

<hr>
<h2 id='Kernel.integrate'>Integrate Smoothing Kernels.</h2><span id='topic+Kernel.integrate'></span><span id='topic+IKer.norm'></span><span id='topic+IKer.cos'></span><span id='topic+IKer.epa'></span><span id='topic+IKer.tri'></span><span id='topic+IKer.quar'></span><span id='topic+IKer.unif'></span>

<h3>Description</h3>

<p>Represent integrate kernels: normal, cosine, triweight, quartic and uniform.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Kernel.integrate(u, Ker = Ker.norm, a = -1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Kernel.integrate_+3A_u">u</code></td>
<td>
<p>data</p>
</td></tr>
<tr><td><code id="Kernel.integrate_+3A_ker">Ker</code></td>
<td>
<p>Type of Kernel. By default normal kernel.</p>
</td></tr>
<tr><td><code id="Kernel.integrate_+3A_a">a</code></td>
<td>
<p>Lower limit of integration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Type of integrate kernel: </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Integrate Normal Kernel:
<code>IKer.norm</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Integrate Cosine Kernel: <code>IKer.cos</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
Integrate Epanechnikov Kernel: <code>IKer.epa</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Integrate Triweight
Kernel: <code>IKer.tri</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Integrate Quartic Kernel:
<code>IKer.quar</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> Integrate Uniform Kernel: <code>IKer.unif</code></td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>



<h3>Value</h3>

<p>Returns integrate kernel.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994.
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+Kernel">Kernel</a></code> and <a href="stats.html#topic+integrate">integrate</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y=qnorm(seq(.1,.9,len=100))
d=IKer.tri(y)
e=IKer.cos(y)
e2=Kernel.integrate(u=y,Ker=Ker.cos)
e-e2
f=IKer.epa(y)
f2=Kernel.integrate(u=y,Ker=Ker.epa)
f-f2
plot(d,type="l",ylab="Integrate Kernel")
lines(e,col=2,type="l")
lines(f,col=4,type="l") 

</code></pre>

<hr>
<h2 id='kmeans.center.ini'>K-Means Clustering for functional data</h2><span id='topic+kmeans.center.ini'></span><span id='topic+kmeans.fd'></span>

<h3>Description</h3>

<p>Perform k-means clustering on functional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kmeans.center.ini(
  fdataobj,
  ncl = 2,
  metric = metric.lp,
  draw = TRUE,
  method = "sample",
  max.iter = 100,
  max.comb = 1e+06,
  par.metric = NULL,
  ...
)

kmeans.fd(
  fdataobj,
  ncl = 2,
  metric = metric.lp,
  dfunc = func.trim.FM,
  max.iter = 100,
  par.metric = NULL,
  par.dfunc = list(trim = 0.05),
  method = "sample",
  cluster.size = 5,
  draw = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kmeans.center.ini_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_ncl">ncl</code></td>
<td>
<p>See details section.</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_draw">draw</code></td>
<td>
<p>=TRUE, draw the curves in the color of the centers.</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_method">method</code></td>
<td>
<p>Method for selecting initial centers. If
<code>method</code>=<em>&quot;Sample&quot;</em> (by default) takes <code>n</code> times a random
selection by the <code>ncl</code> centers. The <code>ncl</code> curves with greater
distance are the initial centers. If <code>method</code>=<em>&quot;Exact&quot;</em> calculated
all combinations (if &lt; 1e+6) of <code>ncl</code> centers. The <code>ncl</code> curves with greater
distance are the initial centers (this method may be too slow).</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_max.iter">max.iter</code></td>
<td>
<p>Maximum number of iterations for the detection of centers.</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_max.comb">max.comb</code></td>
<td>
<p>Maximum number of initial selection of
centers (only used when <code>method="exact"</code>).</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_par.metric">par.metric</code></td>
<td>
<p>List of arguments to pass to the <code>metric</code> function.</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_dfunc">dfunc</code></td>
<td>
<p>Type of depth measure, by default FM depth.</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_par.dfunc">par.dfunc</code></td>
<td>
<p>List of arguments to pass to the <code>dfunc</code> function .</p>
</td></tr>
<tr><td><code id="kmeans.center.ini_+3A_cluster.size">cluster.size</code></td>
<td>
<p>Minimum cluster size (by default is 5). If a cluster has fewer curves,
it is eliminated and the process is continued with a less cluster.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method searches the locations around which are grouped data (for a
predetermined number of groups).<br />
</p>
<p>If <code>ncl=NULL</code>, randomizes the initial centers, <code>ncl=2</code> using
<code>kmeans.center.ini</code> function.<br /> If <code>ncl</code> is an integer,
indicating the number of groups to classify,<br /> are selected <code>ncl</code>
initial centers using <code>kmeans.center.ini</code> function.<br /> If <code>ncl</code> is
a vector of integers, indicating the position of the initial centers with
<code>length(ncl)</code> equal to number of groups.<br /> If <code>ncl</code> is a
<code>fdata</code> class objecct, <code>ncl</code> are the initial centers curves with
<code>nrow(ncl)</code> number of groups.<br />
</p>


<h3>Value</h3>

<p>Return:
</p>

<ul>
<li> <p><code>cluster</code>: Indexes of groups assigned.
</p>
</li>
<li> <p><code>centers</code>: Curves centers.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Hartigan, J. A. and Wong, M. A. (1979). <em>A K-means
clustering algorithm</em>. Applied Statistics 28, 100 \-108.
</p>


<h3>See Also</h3>

<p>See Also generic <a href="stats.html#topic+kmeans">kmeans</a> function.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(fda.usc)
data(phoneme)
mlearn &lt;- phoneme$learn[c(1:50,101:150,201:250),]
# Unsupervised classification
out.fd1 &lt;- kmeans.fd(mlearn,ncl=3,draw=TRUE)
out.fd2 &lt;- kmeans.fd(mlearn,ncl=3,draw=TRUE,method="exact")
# Different Depth function
ind &lt;- c(17,77,126)
out.fd3 &lt;- kmeans.fd(mlearn,ncl=mlearn[ind,],draw=FALSE,
dfunc &lt;- func.trim.FM,par.dfunc=list(trim=0.1))
out.fd4 &lt;- kmeans.fd(mlearn, ncl=mlearn[ind,], draw=FALSE, 
dfunc = func.med.FM)
group &lt;- c(rep(1,50), rep(2,50),rep(3,50))
table(out.fd4$cluster, group)

## End(Not run)

</code></pre>

<hr>
<h2 id='ldata'>ldata class definition and utilities</h2><span id='topic+ldata'></span><span id='topic+c.ldata'></span><span id='topic+is.ldata'></span><span id='topic+names.ldata'></span><span id='topic++5B.ldata'></span><span id='topic+plot.ldata'></span><span id='topic+subset.ldata'></span><span id='topic+ldata.cen'></span><span id='topic+mean.ldata'></span><span id='topic+mean.fdata'></span><span id='topic+NCOL.ldata'></span><span id='topic+NROW.ldata'></span><span id='topic+ncol.ldata'></span><span id='topic+nrow.ldata'></span><span id='topic+Ops.ldata'></span><span id='topic+Math.ldata'></span><span id='topic+Summary.ldata'></span>

<h3>Description</h3>

<p>ldata is a list with two type of objects:
</p>

<ul>
<li> <p><code>df</code> is a data frame with the multivariate data with n rows.
</p>
</li>
<li> <p><code>...</code>  fdata objects of class <code>fdata</code> with n rows.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>ldata(df, ..., mfdata)

## S3 method for class 'ldata'
names(x)

is.ldata(x)

## S3 method for class 'ldata'
x[i, row = FALSE]

## S3 method for class 'ldata'
subset(x, subset, ...)

## S3 method for class 'ldata'
plot(x, ask = FALSE, color, var.name, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ldata_+3A_df">df</code></td>
<td>
<p>data frame</p>
</td></tr>
<tr><td><code id="ldata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to methods.</p>
</td></tr>
<tr><td><code id="ldata_+3A_mfdata">mfdata</code></td>
<td>
<p>list of fdata objects</p>
</td></tr>
<tr><td><code id="ldata_+3A_i">i</code></td>
<td>
<p>index</p>
</td></tr>
<tr><td><code id="ldata_+3A_row">row</code></td>
<td>
<p>logical If <code>FALSE</code>  (by default), <code>i</code> index selects 
the variables. If <code>TRUE</code>,  <code>i</code> index selects the observations.</p>
</td></tr>
<tr><td><code id="ldata_+3A_subset">subset</code></td>
<td>
<p>subset</p>
</td></tr>
<tr><td><code id="ldata_+3A_ask">ask</code></td>
<td>
<p>logilcal    If TRUE (and the R session is interactive) the user is asked for input, before a new figure is drawn.</p>
</td></tr>
<tr><td><code id="ldata_+3A_color">color</code></td>
<td>
<p>colors to interpolate; must be a valid argument to  <code>colorRampPalette</code>.</p>
</td></tr>
<tr><td><code id="ldata_+3A_var.name">var.name</code></td>
<td>
<p>name of continuous univariate variable used in <code>color</code> argument</p>
</td></tr>
<tr><td><code id="ldata_+3A_ldata">ldata</code>, <code id="ldata_+3A_x">x</code></td>
<td>
<p>object of class <code>ldata</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(tecator)
ab0 &lt;- tecator$absorp.fdata
ab1 &lt;- fdata.deriv(ab0)
ab2 &lt;- fdata.deriv(ab0,nderiv=2)
ldat&lt;-ldata(tecator$y,ab1=ab1,ab2=ab2)
is.ldata(ldat)
class(ldat)
plot(ldat[[1]])
plot(ldat[[2]]) 
# plot(ldat)
# plot(ldat,var.name="Fat")
</code></pre>

<hr>
<h2 id='LMDC.select'>Impact points selection of functional predictor and regression using local
maxima distance correlation (LMDC)</h2><span id='topic+LMDC.select'></span><span id='topic+LMDC.regre'></span>

<h3>Description</h3>

<p>LMDC.select function selects impact points of functional predictior using
local maxima distance correlation (LMDC) for a scalar response given.<br />
LMDC.regre function fits a multivariate regression method using the selected
impact points like covariates for a scalar response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LMDC.select(
  y,
  covar,
  data,
  tol = 0.06,
  pvalue = 0.05,
  plot = FALSE,
  local.dc = TRUE,
  smo = FALSE,
  verbose = FALSE
)

LMDC.regre(
  y,
  covar,
  data,
  newdata,
  pvalue = 0.05,
  method = "lm",
  par.method = NULL,
  plot = FALSE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LMDC.select_+3A_y">y</code></td>
<td>
<p>name of the response variable.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_covar">covar</code></td>
<td>
<p>vector with the names of the covaviables (or points of impact)
with length <code>p</code>.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_data">data</code></td>
<td>
<p>data frame with length n rows and at least p + 1 columns,
containing the scalar response and the potencial p covaviables (or points of
impact) in the model.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_tol">tol</code></td>
<td>
<p>Tolerance value for distance correlation and imapct point.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_pvalue">pvalue</code></td>
<td>
<p>pvalue of bias corrected distance correlation t-test.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_plot">plot</code></td>
<td>
<p>logical value, if TRUE plots the distance correlation curve for
each covariate in multivariate case and in each discretization points
(argvals) in the functional case.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_local.dc">local.dc</code></td>
<td>
<p>Compute local distance correlation.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_smo">smo</code></td>
<td>
<p>logical. If TRUE, the curve of distance correlation computed in
the impact points is smoothed using B-spline representation with a suitable
number of basis elements.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_verbose">verbose</code></td>
<td>
<p>print iterative and relevant steps of the procedure.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_newdata">newdata</code></td>
<td>
<p>An optional data frame in which to look for variables with
which to predict.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_method">method</code></td>
<td>
<p>Name of regression method used, see details. This argument is
used in do.call function like &quot;what&quot; argument.</p>
</td></tr>
<tr><td><code id="LMDC.select_+3A_par.method">par.method</code></td>
<td>
<p>List of parameters used to call the method. This argument
is used in do.call function like &quot;args&quot; argument.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>String of characters corresponding to the name of the regression method
called.
Model available options:
</p>
 
<ul>
<li> <p><code>"lm"</code>: Step-wise lm regression model (uses lm function, stats
package). Recommended for linear models, test linearity using.
<code><a href="#topic+flm.test">flm.test</a></code> function.  
</p>
</li>
<li> <p><code>"gam"</code>: Step-wise gam regression model (uses gam function, mgcv package).
Recommended for non-linear models.
</p>
</li></ul>

<p>Models that use the indicated function of the required package: 
</p>

<ul>
<li> <p><code>"svm"</code>: Support vector machine (svm function, e1071 package).
</p>
</li>
<li> <p><code>"knn"</code>: k-nearest neighbor regression (knnn.reg function, FNN package).
</p>
</li>
<li> <p><code>"lars"</code>: Least Angle Regression using Lasso (lars function, lars
package).
</p>
</li>
<li> <p><code>"glmnet"</code>: Lasso and Elastic-Net Regularized Generalized Linear Models
(glmnet and cv.glmnet function, glmnet package).
</p>
</li>
<li> <p><code>"rpart"</code>: Recursive partitioning for regression a (rpart function, rpart package).
</p>
</li>
<li> <p><code>"flam"</code>: Fit the Fused Lasso Additive Model for a Sequence of Tuning
Parameters (flam function, flam package). 
</p>
</li>
<li> <p><code>"novas"</code>: NOnparametric VAriable Selection (code available in
<a href="https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NOVAS/novas-routines.R">https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NOVAS/novas-routines.R</a>).
</p>
</li>
<li> <p><code>"cosso"</code>: Fit Regularized Nonparametric Regression Models Using COSSO
Penalty (cosso function, cosso package). 
</p>
</li>
<li> <p><code>"npreg"</code>: kernel regression estimate of a one (1) dimensional dependent
variable on p-variate explanatory data (npreg function, np package). 
</p>
</li>
<li> <p><code>"mars"</code>: Multivariate adaptive regression splines (mars function, mda
package). 
</p>
</li>
<li> <p><code>"nnet"</code>:  Fit Neural Networks (nnet function, nnet package). 
</p>
</li>
<li> <p><code>"lars"</code>: Fits Least Angle Regression, Lasso and Infinitesimal Forward
Stagewise regression models (lars function, lars package).  
</p>
</li></ul>



<h3>Value</h3>

<table role = "presentation">
<tr><td><code>LMDC.select</code></td>
<td>
<p> function returns a list of two elements:</p>
</td></tr>
<tr><td><code>cor</code></td>
<td>
<p> the value of distance correlation for each covariate.</p>
</td></tr> 
<tr><td><code>maxLocal</code></td>
<td>
<p> index or locations of local maxima distance correlations.</p>
</td></tr> 
<tr><td><code>LMDC.regre</code></td>
<td>
<p> function returns a list of folowing elements:</p>
</td></tr>
<tr><td><code>model</code></td>
<td>
<p> object corresponding to the estimated method using the selected variables.</p>
</td></tr>
<tr><td><code>xvar</code></td>
<td>
<p> names of selected variables (impact points).</p>
</td></tr>
<tr><td><code>edf</code></td>
<td>
<p> effective degrees of freedom.</p>
</td></tr>
<tr><td><code>nvar</code></td>
<td>
<p> number of selected variables (impact points).</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ordonez, C., Oviedo de la Fuente, M., Roca-Pardinas, J.,
Rodriguez-Perez, J. R. (2018). Determining optimum wavelengths for leaf
water content estimation from reflectance: A distance correlation approach.
<em>Chemometrics and Intelligent Laboratory Systems</em>. 173,41-50
<a href="https://doi.org/10.1016/j.chemolab.2017.12.001">doi:10.1016/j.chemolab.2017.12.001</a>.
</p>


<h3>See Also</h3>

<p>See Also as: <a href="stats.html#topic+lm">lm</a>, <a href="mgcv.html#topic+gam">gam</a>,
<code><a href="#topic+dcor.xy">dcor.xy</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
absorp=fdata.deriv(tecator$absorp.fdata,2)
ind=1:129
x=absorp[ind,]
y=tecator$y$Fat[ind]
newx=absorp[-ind,]
newy=tecator$y$Fat[-ind]

## Functional PC regression
res.pc=fregre.pc(x,y,1:6)
pred.pc=predict(res.pc,newx)

# Functional regression with basis representation
res.basis=fregre.basis.cv(x,y)
pred.basis=predict(res.basis[[1]],newx)

# Functional nonparametric regression
res.np=fregre.np.cv(x,y)
pred.np=predict(res.np,newx)

dat    &lt;- data.frame("y"=y,x$data)
newdat &lt;- data.frame("y"=newy,newx$data)

res.gam=fregre.gsam(y~s(x),data=list("df"=dat,"x"=x))
pred.gam=predict(res.gam,list("x"=newx))

dc.raw &lt;- LMDC.select("y",data=dat, tol = 0.05, pvalue= 0.05,
                      plot=F, smo=T,verbose=F)
covar &lt;- paste("X",dc.raw$maxLocal,sep="")                      
# Preselected design/impact points 
covar
ftest&lt;-flm.test(dat[,-1],dat[,"y"], B=500, verbose=F,
    plot.it=F,type.basis="pc",est.method="pc",p=4,G=50)
    
if (ftest$p.value&gt;0.05) { 
  # Linear relationship, step-wise lm is recommended
  out &lt;- LMDC.regre("y",covar,dat,newdat,pvalue=.05,
              method ="lm",plot=F,verbose=F)
} else {
 # Non-Linear relationship, step-wise gam is recommended
  out &lt;- LMDC.regre("y",covar,dat,newdat,pvalue=.05,
              method ="gam",plot=F,verbose=F) }  
             
# Final  design/impact points
out$xvar

# Predictions
mean((newy-pred.pc)^2)                
mean((newy-pred.basis)^2) 
mean((newy-pred.np)^2)              
mean((newy-pred.gam)^2) 
mean((newy-out$pred)^2)

## End(Not run)                          
</code></pre>

<hr>
<h2 id='MCO'>Mithochondiral calcium overload (MCO) data set</h2><span id='topic+MCO'></span>

<h3>Description</h3>

<p>The mithochondiral calcium overload (MCO) was measured in two groups
(control and treatment) every 10 seconds during an hour in isolated mouse
cardiac cells. In fact, due to technical reasons, the original experiment
[see Ruiz-Meana et al. (2000)] was performed twice, using both the &quot;intact&quot;,
original cells and &quot;permeabilized&quot; cells (a condition related to the
mitochondrial membrane).
</p>


<h3>Format</h3>

<p>Elements of MCO:<br /> <code>..$intact</code>: <code>fdata</code> class object with
&ldquo;intact cells&rdquo;curves,<br /> </p>
 <ul>
<li> <p><code>"data"</code>: Matrix of class
<code>fdata</code> with 89 intact cells curves (rows) measured every 10 seconds
during an hour in isolated mouse cardiac cell. </p>
</li>
<li> <p><code>"argvals"</code>, 360
discretization points from seond 0 to 3590. </p>
</li>
<li> <p><code>"rangeval"</code>:
range(<code>"argvals"</code>). </p>
</li>
<li> <p><code>"names"</code> list with: <code>main</code> an
overall title &quot;Control Intact Treatment&quot;, <code>xlab</code> title for <code>x</code>
axis &quot;seconds&quot; and <code>ylab</code> title for <code>y</code> axis &quot;Ca&quot;. </p>
</li></ul>

<p><code>..$classintact</code>: Factor levels of &ldquo;intact cells&rdquo; curves: &quot;1&quot; control
group and &quot;2&quot; treatment group.<br />
</p>
<p><code>..$permea</code>: <code>fdata</code> class object with &ldquo;permeabilized cells&rdquo;
curves (whose membrane has been removed), </p>
 <ul>
<li> <p><code>"data"</code>:
Matrix of class <code>fdata</code> with 90 permeabilizzed cells curves (rows)
measured every 10 seconds during an hour in isolated mouse cardiac cell.
</p>
</li>
<li> <p><code>"argvals"</code>, 360 discretization points from seond 0 to 3590.
</p>
</li>
<li> <p><code>"rangeval"</code>: range(<code>"argvals"</code>). </p>
</li>
<li> <p><code>"names"</code> list
with: <code>main</code> an overall title &quot;Control Intact Treatment&quot;, <code>xlab</code>
title for <code>x</code> axis &quot;seconds&quot; and <code>ylab</code> title for <code>y</code> axis
&quot;Ca&quot;. </p>
</li></ul>
 <p><code>..$classpermea</code>: Factor levels of &ldquo;permeabilized cells&rdquo;
curves: &quot;1&quot; control group and &quot;2&quot; treatment group.<br />
</p>


<h3>Note</h3>

<p>The structure of the curves during the initial period (first 180
seconds) of the experiment shows a erratic behavior (not very relevant in
the experiment context) during this period.
</p>


<h3>References</h3>

<p>Ruiz&ndash;Meana M, Garcia-Dorado D, Pina P, Inserte J, Agullo L, Soler&ndash;Soler J.
Cariporide preserves mitochondrial proton gradient and delays ATP depletion
in cardiomyocytes during ischemic conditions. <em>American Journal
Physiology Heart Circulatori Physiology</em>. 2003 Sep;285(3):H999&ndash;1006.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MCO)
names(MCO)
par(mfrow=c(1,2))
plot.fdata(MCO$intact, col=MCO$classintact)
plot.fdata(MCO$permea, col=MCO$classintact)

</code></pre>

<hr>
<h2 id='metric.dist'>Distance Matrix Computation</h2><span id='topic+metric.dist'></span>

<h3>Description</h3>

<p>This function computes the distances between the rows of a data matrix by
using the specified distance measure.
</p>
<p>This function returns a distance matrix by using <code><a href="stats.html#topic+dist">dist</a></code>
function. <br /> The matrix dimension is (<code>n1</code> x <code>n1</code>) if
<code>y=NULL</code>, (<code>n1</code> x <code>n2</code>) otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric.dist(x, y = NULL, method = "euclidean", p = 2, dscale = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metric.dist_+3A_x">x</code></td>
<td>
<p>Data frame 1. The dimension is (<code>n1</code> x <code>m</code>).</p>
</td></tr>
<tr><td><code id="metric.dist_+3A_y">y</code></td>
<td>
<p>Data frame 2. The dimension is (<code>n2</code> x <code>m</code>).</p>
</td></tr>
<tr><td><code id="metric.dist_+3A_method">method</code></td>
<td>
<p>The distance measure to be used. This must be one of
&quot;euclidean&quot;, &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;, &quot;binary&quot; or &quot;minkowski&quot;.</p>
</td></tr>
<tr><td><code id="metric.dist_+3A_p">p</code></td>
<td>
<p>The power of the Minkowski distance.</p>
</td></tr>
<tr><td><code id="metric.dist_+3A_dscale">dscale</code></td>
<td>
<p>If scale is a numeric, the distance matrix is divided by the
scale value. If scale is a function (as the mean for example) the distance
matrix is divided by the corresponding value from the output of the
function.</p>
</td></tr>
<tr><td><code id="metric.dist_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code><a href="stats.html#topic+dist">dist</a></code> function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See also <code><a href="stats.html#topic+dist">dist</a></code> for multivariate date case and
<code><a href="#topic+metric.lp">metric.lp</a> for functional data case</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
d&lt;-metric.dist(iris[,1:4])
matplot(d,type="l",col=as.numeric(iris[,5]))

## End(Not run)
</code></pre>

<hr>
<h2 id='metric.DTW'>DTW: Dynamic time warping</h2><span id='topic+metric.DTW'></span><span id='topic+metric.WDTW'></span><span id='topic+metric.TWED'></span>

<h3>Description</h3>

<p>Computes distances time warping for functional data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric.DTW(fdata1, fdata2 = NULL, p = 2, w = min(ncol(fdata1), ncol(fdata2)))

metric.WDTW(
  fdata1,
  fdata2 = NULL,
  p = 2,
  w = min(ncol(fdata1), ncol(fdata2)),
  wmax = 1,
  g = 0.05
)

metric.TWED(fdata1, fdata2 = NULL, p = 2, lambda = 1, nu = 0.05)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metric.DTW_+3A_fdata1">fdata1</code></td>
<td>
<p>Functional data 1 or curve 1. If <code>fdata</code> class, the dimension of <code>fdata1$data</code> object is (<code>n1</code> x <code>m</code>), where <code>n1</code> is the number of curves and <code>m</code> are the points observed in each curve.</p>
</td></tr>
<tr><td><code id="metric.DTW_+3A_fdata2">fdata2</code></td>
<td>
<p>Functional data 2 or curve 2. If <code>fdata</code> class, the dimension of <code>fdata2$data</code> object is (<code>n2</code> x <code>m</code>), where <code>n2</code> is the number of curves and <code>m</code> are the points observed in each curve.</p>
</td></tr>
<tr><td><code id="metric.DTW_+3A_p">p</code></td>
<td>
<p>Lp norm, by default it uses <code>p = 2</code></p>
</td></tr>
<tr><td><code id="metric.DTW_+3A_w">w</code></td>
<td>
<p>Vector of weights with length <code>m</code>, If <code>w = 1</code> approximates the metric Lp by Simpson's rule. By default it uses <code>w = 1</code></p>
</td></tr>
<tr><td><code id="metric.DTW_+3A_wmax">wmax</code></td>
<td>
<p><code>numeric</code> maximum value of weight, (1 by default)</p>
</td></tr>
<tr><td><code id="metric.DTW_+3A_g">g</code></td>
<td>
<p><code>numeric</code> <code>g=0</code> (constant), <code>0.05</code> (linear) by default, 0.25 <code>sigmoid</code>, 3 two weight values</p>
</td></tr>
<tr><td><code id="metric.DTW_+3A_lambda">lambda</code></td>
<td>
<p><code>numeric</code> lambda value (0 by default)</p>
</td></tr>
<tr><td><code id="metric.DTW_+3A_nu">nu</code></td>
<td>
<p><code>numeric</code> constant value, (0 by default)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Three optins:
</p>

<ul>
<li><p> DTW: Dynamic time warping
</p>
</li>
<li><p> WDTW: Weight Dynamic time warping
</p>
</li>
<li><p> TWED: twed   
</p>
</li></ul>



<h3>Value</h3>

<p>DTW matrix
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Jeong, Y. S., Jeong, M. K., &amp; Omitaomu, O. A. (2011). Weighted dynamic time warping for 
time series classification. <em>Pattern Recognition</em>, 44(9), 2231-2240
</p>


<h3>See Also</h3>

<p>See also  <code><a href="#topic+semimetric.basis">semimetric.basis</a></code> and <code><a href="#topic+semimetric.NPFDA">semimetric.NPFDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
metric.DTW(tecator$absorp.fdata[1:4,])
ab=tecator[[1]]
D1=fda.usc:::DTW(ab$data[1,],ab$data[2,],p=2)
aa1=fda.usc:::findPath(D1$D)
D2=fda.usc:::DTW(ab$data[1,],ab$data[2,],p=2,w=5)
aa2=fda.usc:::findPath(D2$D)
D3=fda.usc:::WDTW(ab$data[1,],ab$data[2,],p=2,g=0.05) 
aa3=fda.usc:::findPath(D3$D)
D4=fda.usc:::TWED(ab$data[1,],ab$data[2,],p=2,lambda=0,nu=0)
aa4=fda.usc:::findPath(D4$D)
par(mfrow=c(2,2))
plot(c(ab[1:2]))
segments(ab$argvals[aa1[,1]],ab[1]$data[aa1[,1]],ab$argvals[aa1[,2]],ab[2]$data[aa1[,2]])
plot(c(ab[1:2]))
segments(ab$argvals[aa2[,1]],ab[1]$data[aa2[,1]],ab$argvals[aa2[,2]],ab[2]$data[aa2[,2]],col=2)
plot(c(ab[1:2]))
segments(ab$argvals[aa3[,1]],ab[1]$data[aa3[,1]],ab$argvals[aa3[,2]],ab[2]$data[aa3[,2]],col=3)
plot(c(ab[1:2]))
segments(ab$argvals[aa4[,1]],ab[1]$data[aa4[,1]],ab$argvals[aa4[,2]],ab[2]$data[aa4[,2]],col=4)

## End(Not run)

</code></pre>

<hr>
<h2 id='metric.hausdorff'>Compute the Hausdorff distances between two curves.</h2><span id='topic+metric.hausdorff'></span>

<h3>Description</h3>

<p>Hausdorff distance is the greatest of all the distances from a point in one
curve to the closest point in the other curve (been closest the euclidean
distance).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric.hausdorff(fdata1, fdata2 = fdata1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metric.hausdorff_+3A_fdata1">fdata1</code></td>
<td>
<p>Curves 1 of <code>fdata</code> class. The dimension of <code>fdata1</code>
object is (<code>n1</code> x <code>m</code>), where <code>n1</code> is the number of points
observed in <code>t</code> coordinates with lenght <code>m</code>.</p>
</td></tr>
<tr><td><code id="metric.hausdorff_+3A_fdata2">fdata2</code></td>
<td>
<p>Curves 2 of <code>fdata</code> class. The dimension of <code>fdata2</code>
object is (<code>n2</code> x <code>m</code>), where <code>n2</code> is the number of points
observed in <code>t</code> coordinates with lenght <code>m</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Let <code class="reqn">G(X)=\left\{ (t,X(t))\in R^2 \right\}</code> and
<code class="reqn">G(Y)=\left\{(t,Y(t))\in R^2\right\}</code> be two
graphs of the considered curves <code class="reqn">X</code> and <code class="reqn">Y</code> respectively, the
Hausdorff distance <code class="reqn">d_H(X, Y)</code> is defined as,
</p>
<p style="text-align: center;"><code class="reqn"> d_H(X,Y)=max\left\{ sup_{x\in G(X)} inf_{y\in G(Y)} d_2(x,y),
sup_{y\in G(Y)} inf_{x\in G(X)}d_2(x,y)\right\},</code>
</p>

<p>where <code class="reqn">d_2(x,y)</code> is the euclidean distance, see <code><a href="#topic+metric.lp">metric.lp</a>.</code>
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:    
data(poblenou)
nox&lt;-poblenou$nox[1:6]
# Hausdorff vs maximum distance
out1&lt;-metric.hausdorff(nox)       
out2&lt;-metric.lp(nox,lp=0) 
out1
out2
par(mfrow=c(1,3))
plot(nox)
plot(hclust(as.dist(out1)))
plot(hclust(as.dist(out2)))

## End(Not run)   

</code></pre>

<hr>
<h2 id='metric.kl'>Kullback&ndash;Leibler distance</h2><span id='topic+metric.kl'></span>

<h3>Description</h3>

<p>Measures the proximity between two groups of densities (of class
<code>fdata</code>) by computing the Kullback&ndash;Leibler distance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric.kl(fdata1, fdata2 = NULL, symm = TRUE, base = exp(1), eps = 1e-10, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metric.kl_+3A_fdata1">fdata1</code></td>
<td>
<p>Functional data 1 (<code>fdata</code> class) with the densities. The
dimension of <code>fdata1</code> object is (<code>n1</code> x <code>m</code>), where <code>n1</code>
is the number of densities and <code>m</code> is the number of coordinates of the
points where the density is observed.</p>
</td></tr>
<tr><td><code id="metric.kl_+3A_fdata2">fdata2</code></td>
<td>
<p>Functional data 2 (<code>fdata</code> class) with the densities. The
dimension of <code>fdata2</code> object is (<code>n2</code> x <code>m</code>).</p>
</td></tr>
<tr><td><code id="metric.kl_+3A_symm">symm</code></td>
<td>
<p>If <code>TRUE</code> the symmetric K&ndash;L distance is computed, see
details section.</p>
</td></tr>
<tr><td><code id="metric.kl_+3A_base">base</code></td>
<td>
<p>The logarithm base used to compute the distance.</p>
</td></tr>
<tr><td><code id="metric.kl_+3A_eps">eps</code></td>
<td>
<p>Tolerance value.</p>
</td></tr>
<tr><td><code id="metric.kl_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Kullback&ndash;Leibler distance between <code class="reqn">f(t)</code> and <code class="reqn">g(t)</code> is
</p>
<p style="text-align: center;"><code class="reqn">metric.kl(f(t),g(t))= \int_{a}^{b} {f(t) log\left(\frac{f(t)}{g(t)}\right)dt}</code>
</p>
<p> where <code class="reqn">t</code> are the <code>m</code> coordinates of the points
where the density is observed (the <code>argvals</code> of the <code>fdata</code> object).
</p>
<p>The Kullback&ndash;Leibler distance is asymmetric, 
</p>
<p style="text-align: center;"><code class="reqn">metric.kl(f(t),g(t))\neq metric.kl(g(t),f(t))</code>
</p>

<p>A symmetry version of K&ndash;L distance (by default) can be obtained by
</p>
<p style="text-align: center;"><code class="reqn">0.5\left(metric.kl(f(t),g(t))+metric.kl(g(t),f(t))\right)</code>
</p>

<p>If <code class="reqn">\left(f_i(t)=0\ \&amp; \ g_j(t)=0\right) \Longrightarrow
metric.kl(f(t),g(t))=0</code>.
</p>
<p>If <code class="reqn">\left|f_i(t)-g_i(t) \right|\leq \epsilon \Longrightarrow
f_i(t)=f_i(t)+\epsilon</code>,
where <code class="reqn">\epsilon</code> is the tolerance value (by default <code>eps=1e-10</code>).
</p>
<p>The coordinates of the points where the density is observed (discretization
points <code class="reqn">t</code>) can be equally spaced (by default) or not.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Kullback, S., Leibler, R.A. (1951). <em>On information and
sufficiency.</em> Annals of Mathematical Statistics, 22: 79-86
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+metric.lp">metric.lp</a></code> and <code><a href="#topic+fdata">fdata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:    
n&lt;-201                                                                                       
tt01&lt;-seq(0,1,len=n)                                                                         
rtt01&lt;-c(0,1)  
x1&lt;-dbeta(tt01,20,5)                                                                           
x2&lt;-dbeta(tt01,21,5)                                                                           
y1&lt;-dbeta(tt01,5,20)                                                                           
y2&lt;-dbeta(tt01,5,21)                                                                           
xy&lt;-fdata(rbind(x1,x2,y1,y2),tt01,rtt01)
plot(xy)
round(metric.kl(xy,xy,eps=1e-5),6)  
round(metric.kl(xy,eps=1e-5),6)
round(metric.kl(xy,eps=1e-6),6)
round(metric.kl(xy,xy,symm=FALSE,eps=1e-5),6)  
round(metric.kl(xy,symm=FALSE,eps=1e-5),6)

plot(c(fdata(y1[1:101]),fdata(y2[1:101])))                       
metric.kl(fdata(x1))  
metric.kl(fdata(x1),fdata(x2),eps=1e-5,symm=F)       
metric.kl(fdata(x1),fdata(x2),eps=1e-6,symm=F)       
metric.kl(fdata(y1[1:101]),fdata(y2[1:101]),eps=1e-13,symm=F)  
metric.kl(fdata(y1[1:101]),fdata(y2[1:101]),eps=1e-14,symm=F)  

## End(Not run)   

</code></pre>

<hr>
<h2 id='metric.ldata'>Distance Matrix Computation for ldata and mfdata class object</h2><span id='topic+metric.ldata'></span><span id='topic+metric.mfdata'></span>

<h3>Description</h3>

<p>This function computes the distances between the list elements
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric.ldata(
  ldata1,
  ldata2 = NULL,
  include = "all",
  exclude = "none",
  metric,
  par.metric = NULL,
  w,
  method = "none"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metric.ldata_+3A_ldata1">ldata1</code></td>
<td>
<p>List with  of fdata objects and a data.frame object calle 'df'.</p>
</td></tr>
<tr><td><code id="metric.ldata_+3A_ldata2">ldata2</code></td>
<td>
<p>List with  of fdata objects and a data.frame object calle 'df'.</p>
</td></tr>
<tr><td><code id="metric.ldata_+3A_include">include</code></td>
<td>
<p>vector with the name of variables to use</p>
</td></tr>
<tr><td><code id="metric.ldata_+3A_exclude">exclude</code></td>
<td>
<p>vector with the name of variables to not use</p>
</td></tr>
<tr><td><code id="metric.ldata_+3A_metric">metric</code></td>
<td>
<p>Type of metric to combine, if 'none', the function no combine and return a list o distances for each variable included</p>
</td></tr>
<tr><td><code id="metric.ldata_+3A_par.metric">par.metric</code></td>
<td>
<p>List of metric parameters for each variable included</p>
</td></tr>
<tr><td><code id="metric.ldata_+3A_w">w</code></td>
<td>
<p>weights to combine the metric (if metric is not 'none')</p>
</td></tr>
<tr><td><code id="metric.ldata_+3A_method">method</code></td>
<td>
<p>The distance measure to be used. This must be one of
&quot;euclidean&quot;, &quot;maximum&quot;, &quot;manhattan&quot;, &quot;canberra&quot;, &quot;binary&quot; or &quot;minkowski&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function returns a distance matrix by using <code><a href="#topic+metric.lp">metric.lp</a></code>
function for <code>fdata</code> objects and  <code><a href="#topic+metric.dist">metric.dist</a></code>
function for <code>vector</code> and <code>matric</code> objects. <br />
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manul.oviedo@usc.es">manul.oviedo@usc.es</a>
</p>


<h3>See Also</h3>

<p>See also <code><a href="stats.html#topic+dist">dist</a></code> for multivariate date case and
<code><a href="#topic+metric.lp">metric.lp</a> for functional data case</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
names(tecator)[2] &lt;- "df"
# Example 1 (list of distances)
ldist &lt;- metric.ldata(tecator,method="none")
lapply(ldist,names)
# Example 2 (combined metric)
mdist &lt;- metric.ldata(tecator,method="euclidean")
dim(mdist) 

## End(Not run)
</code></pre>

<hr>
<h2 id='metric.lp'>Approximates Lp-metric distances for functional data.</h2><span id='topic+metric.lp'></span>

<h3>Description</h3>

<p>Measures the proximity between the functional data and curves approximating
Lp-metric. If <code>w = 1</code> approximates the Lp-metric by Simpson's rule. By
default it uses <code>lp = 2</code> and weights <code>w = 1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>metric.lp(fdata1, fdata2 = NULL, lp = 2, w = 1, dscale = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="metric.lp_+3A_fdata1">fdata1</code></td>
<td>
<p>Functional data 1 or curve 1. If <code>fdata</code> class, the
dimension of <code>fdata1$data</code> object is (<code>n1</code> x <code>m</code>), where
<code>n1</code> is the number of curves and <code>m</code> are the points observed in
each curve.</p>
</td></tr>
<tr><td><code id="metric.lp_+3A_fdata2">fdata2</code></td>
<td>
<p>Functional data 2 or curve 2. If <code>fdata</code> class, the
dimension of <code>fdata2$data</code> object is (<code>n2</code> x <code>m</code>), where
<code>n2</code> is the number of curves and <code>m</code> are the points observed in
each curve.</p>
</td></tr>
<tr><td><code id="metric.lp_+3A_lp">lp</code></td>
<td>
<p>Lp norm, by default it uses <code>lp = 2</code></p>
</td></tr>
<tr><td><code id="metric.lp_+3A_w">w</code></td>
<td>
<p>Vector of weights with length <code>m</code>, If <code>w = 1</code>
approximates the metric Lp by Simpson's rule. By default it uses <code>w =
1</code></p>
</td></tr>
<tr><td><code id="metric.lp_+3A_dscale">dscale</code></td>
<td>
<p>If scale is a numeric, the distance matrix is divided by the
scale value. If scale is a function (as the mean for example) the distance
matrix is divided by the corresponding value from the output of the
function.</p>
</td></tr>
<tr><td><code id="metric.lp_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default it uses the L2-norm with <code>lp = 2</code>.  </p>
<p style="text-align: center;"><code class="reqn">Let \ \ f(x)=
fdata1(x)-fdata2(x)</code>
</p>

<p style="text-align: center;"><code class="reqn">\left\|f\right\|_p=\left ( \frac{1}{\int_{a}^{b}w(x)dx} \int_{a}^{b}
\left|f(x)\right|^{p}w(x)dx \right)^{1/p}</code>
</p>
 <p><br /> 
The observed points on each curve are equally spaced (by default) or not.
</p>
<p>The L<code class="reqn">\infty</code>-norm is computed with <code>lp = 0</code>.
</p>
<p style="text-align: center;"><code class="reqn">d(fdata1(x),fdata2(x))_{\infty}=sup
\left|fdata1(x)-fdata2(x)\right|</code>
</p>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).
<em>Statistical Computing in Functional Data Analysis: The R Package
fda.usc.</em> Journal of Statistical Software, 51(4), 1-28.
<a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+semimetric.basis">semimetric.basis</a></code> and
<code><a href="#topic+semimetric.NPFDA">semimetric.NPFDA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
#	INFERENCE PHONDAT
data(phoneme)
mlearn&lt;-phoneme$learn[1:100]
mtest&lt;-phoneme$test[1:100]
glearn&lt;-phoneme$classlearn[1:100]
gtest&lt;-phoneme$classtest[1:100]
# Matrix of distances of curves of DATA1
mdist1&lt;-metric.lp(mlearn)

# Matrix of distances between curves of DATA1 and curves of DATA2
mdist2&lt;-metric.lp(mlearn,mtest,lp=2)
# mdist with L1 norm and weigth=v
v=dnorm(seq(-3,3,len=dim(mlearn)[2]))
mdist3&lt;-metric.lp(mlearn,mtest,lp=1,w=v)
plot(1:100,mdist2[1,],type="l",ylim=c(1,max(mdist3[1,])))
lines(mdist3[1,],type="l",col="2")

# mdist with mlearn with different discretization points.
# mlearn2=mlearn
# mlearn2[["argvals"]]=seq(0,1,len=150)
# mdist5&lt;-metric.lp(mlearn,mlearn2)
# mdist6&lt;-metric.lp(mlearn2,mlearn) 
# sum(mdist5-mdist6)
# sum(mdist1-mdist6)

x&lt;-seq(0,2*pi,length=1001)
fx&lt;-fdata(sin(x)/sqrt(pi),x)
fx0&lt;-fdata(rep(0,length(x)),x)
metric.lp(fx,fx0)
# The same
integrate(function(x){(abs(sin(x)/sqrt(pi))^2)},0,2*pi)

## End(Not run)

</code></pre>

<hr>
<h2 id='mfdata'>mfdata class definition and utilities</h2><span id='topic+mfdata'></span><span id='topic+c.mfdata'></span><span id='topic+is.mfdata'></span><span id='topic+names.mfdata'></span><span id='topic++5B.mfdata'></span><span id='topic+plot.mfdata'></span><span id='topic+subset.mfdata'></span><span id='topic+mfdata.cen'></span><span id='topic+mean.mfdata'></span><span id='topic+NCOL.mfdata'></span><span id='topic+NROW.mfdata'></span><span id='topic+ncol.mfdata'></span><span id='topic+nrow.mfdata'></span><span id='topic+Ops.mfdata'></span><span id='topic+Math.mfdata'></span><span id='topic+Summary.mfdata'></span>

<h3>Description</h3>

<p>mfdata is a list with fdata type of object:
</p>

<ul>
<li> <p><code>...</code>  fdata objects of class <code>fdata</code> with n rows.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>mfdata(...)

## S3 method for class 'mfdata'
names(x)

## S3 method for class 'mfdata'
subset(x, subset, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mfdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to methods.</p>
</td></tr>
<tr><td><code id="mfdata_+3A_x">x</code></td>
<td>
<p>object of class <code>mfdata</code></p>
</td></tr>
<tr><td><code id="mfdata_+3A_subset">subset</code></td>
<td>
<p>subset</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>data(tecator)
ab0 &lt;- tecator$absorp.fdata
ab1 &lt;- fdata.deriv(ab0)
ab2 &lt;- fdata.deriv(ab0,nderiv=2)
mdat &lt;- mfdata(ab0, ab1, ab2)
is.ldata(mdat)
class(mdat)
plot(mdat[[1]])
plot(mdat[[2]]) 
plot(mdat)
</code></pre>

<hr>
<h2 id='na.omit.fdata'>A wrapper for the na.omit and na.fail function for fdata object</h2><span id='topic+na.omit.fdata'></span><span id='topic+na.fail.fdata'></span>

<h3>Description</h3>

<p><code>na.fail</code> returns the object if it does not contain any 
missing values, and signals an error otherwise. <code>na.omit</code> returns the object
with incomplete cases removed.
If <code>na.omit.fdata</code> removes cases, the row numbers of the cases form the 
<code>"na.action"</code> attribute of the result, of class <code>"omit"</code>, see generic 
function <code><a href="stats.html#topic+na.omit">na.omit</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fdata'
na.omit(object, ...)

## S3 method for class 'fdata'
na.fail(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="na.omit.fdata_+3A_object">object</code></td>
<td>
<p>an <code>fdata</code> object.</p>
</td></tr>
<tr><td><code id="na.omit.fdata_+3A_...">...</code></td>
<td>
<p>further potential arguments passed to methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The value returned from <code>omit</code> is a <code>fdata</code> object with incomplete cases removed.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero Bande and Manuel Oviedo
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
fdataobj&lt;-fdata(MontrealTemp)
fdataobj$data[3,3]&lt;-NA
fdataobj$data[10,]&lt;-NA
fdastaobj2&lt;-na.omit(fdataobj)

## End(Not run) 

</code></pre>

<hr>
<h2 id='norm.fdata'>Approximates Lp-norm for functional data.</h2><span id='topic+norm.fdata'></span><span id='topic+norm.fd'></span>

<h3>Description</h3>

<p>Approximates Lp-norm for functional data (fdata) object using metric or
semimetric functions. Norm for functional data using by default Lp-metric.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>norm.fdata(fdataobj, metric = metric.lp, ...)

norm.fd(fdobj)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="norm.fdata_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="norm.fdata_+3A_metric">metric</code></td>
<td>
<p>Metric function, by default <code><a href="#topic+metric.lp">metric.lp</a></code>.</p>
</td></tr>
<tr><td><code id="norm.fdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="norm.fdata_+3A_fdobj">fdobj</code></td>
<td>
<p>Functional data or curves of <a href="fda.html#topic+fd">fd</a> class.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>By default it computes the L2-norm with <code>p = 2</code> and weights <code>w</code>
with length=<code>(m-1)</code>.  </p>
<p style="text-align: center;"><code class="reqn">Let \ \ f(x)= fdataobj(x)\ </code>
</p>

<p style="text-align: center;"><code class="reqn">\left\|f\right\|_p=\left ( \frac{1}{\int_{a}^{b}w(x)dx} \int_{a}^{b}
\left|f(x)\right|^{p}w(x)dx \right)^{1/p}</code>
</p>

<p>The observed points on each curve are equally spaced (by default) or not.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+metric.lp">metric.lp</a></code> and <code><a href="base.html#topic+norm">norm</a></code><br />
Alternative method: <a href="fda.html#topic+inprod">inprod</a> of fda-package
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
x&lt;-seq(0,2*pi,length=1001)
fx1&lt;-sin(x)/sqrt(pi)
fx2&lt;-cos(x)/sqrt(pi)
argv&lt;-seq(0,2*pi,len=1001)
fdat0&lt;-fdata(rep(0,len=1001),argv,range(argv))
fdat1&lt;-fdata(fx1,x,range(x))
metric.lp(fdat1)
metric.lp(fdat1,fdat0)
norm.fdata(fdat1)
# The same
integrate(function(x){(abs(sin(x)/sqrt(pi))^2)},0,2*pi)
integrate(function(x){(abs(cos(x)/sqrt(pi))^2)},0,2*pi)

bspl1&lt;- create.bspline.basis(c(0,2*pi),21)
fd.bspl1 &lt;- fd(basisobj=bspl1)
fd.bspl2&lt;-fdata2fd(fdat1,nbasis=21)
norm.fd(fd.bspl1)
norm.fd(fd.bspl2)

## End(Not run)

</code></pre>

<hr>
<h2 id='ops.fda.usc'>ops.fda.usc  Options Settings</h2><span id='topic+ops.fda.usc'></span>

<h3>Description</h3>

<p>Set or query graphical and prompt output parameters. Allow the user to set and examine a variety of global or local options which affect the way in which fda.usc functions computes and displays its results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ops.fda.usc(
  verbose = FALSE,
  trace = FALSE,
  warning = FALSE,
  ncores = NULL,
  int.method = "TRAPZ",
  reset = FALSE,
  eps = as.double(.Machine[[1]] * 10)
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ops.fda.usc_+3A_verbose">verbose</code></td>
<td>
<p><code>logical</code>. Should R report extra information on progress? Set to <code>TRUE</code> by the command-line option &ndash;verbose.</p>
</td></tr>
<tr><td><code id="ops.fda.usc_+3A_trace">trace</code></td>
<td>
<p><code>logical</code>. Show internal information of procedure.</p>
</td></tr>
<tr><td><code id="ops.fda.usc_+3A_warning">warning</code></td>
<td>
<p><code>logical</code>: If true, warnings are shown.</p>
</td></tr>
<tr><td><code id="ops.fda.usc_+3A_ncores">ncores</code></td>
<td>
<p>integer. Number of CPU cores on the current host.</p>
</td></tr>
<tr><td><code id="ops.fda.usc_+3A_int.method">int.method</code></td>
<td>
<p>see <code>method</code> argument in <code><a href="#topic+int.simpson">int.simpson</a></code> function.</p>
</td></tr>
<tr><td><code id="ops.fda.usc_+3A_reset">reset</code></td>
<td>
<p><code>logical</code>.  If <code>TRUE</code> creates a new Parallel Socket Cluster (ncores&gt;1) or a sequential parallel backend (ncores=1). It is useful when worker initialization failed or after a crush.</p>
</td></tr>
<tr><td><code id="ops.fda.usc_+3A_eps">eps</code></td>
<td>
<p>epsilon parameter.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Oviedo de la Fuente (<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# If worker initialization failed, please execute this code
 ncores &lt;- max(parallel::detectCores() -1,1)
 if (ncores==1) {
     foreach::registerDoSEQ()
 }  else{
 cl &lt;-  suppressWarnings(parallel::makePSOCKcluster(ncores ))
 doParallel::registerDoParallel(cl)
 }
 ops.fda.usc()

## End(Not run)

</code></pre>

<hr>
<h2 id='optim.basis'>Select the number of basis using GCV method.</h2><span id='topic+optim.basis'></span><span id='topic+min.basis'></span>

<h3>Description</h3>

<p>Functional data estimation via basis representation using cross-validation
(CV) or generalized cross-validation (GCV) method with a roughness penalty.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optim.basis(
  fdataobj,
  type.CV = GCV.S,
  W = NULL,
  lambda = 0,
  numbasis = floor(seq(ncol(fdataobj)/16, ncol(fdataobj)/2, len = 10)),
  type.basis = "bspline",
  par.CV = list(trim = 0, draw = FALSE),
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optim.basis_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="optim.basis_+3A_type.cv">type.CV</code></td>
<td>
<p>Type of cross-validation. By default generalized
cross-validation (GCV) method.</p>
</td></tr>
<tr><td><code id="optim.basis_+3A_w">W</code></td>
<td>
<p>Matrix of weights.</p>
</td></tr>
<tr><td><code id="optim.basis_+3A_lambda">lambda</code></td>
<td>
<p>A roughness penalty. By default, no penalty <code>lambda=0</code>.</p>
</td></tr>
<tr><td><code id="optim.basis_+3A_numbasis">numbasis</code></td>
<td>
<p>Number of basis to use.</p>
</td></tr>
<tr><td><code id="optim.basis_+3A_type.basis">type.basis</code></td>
<td>
<p>Character string which determines type of basis. By
default <em>&quot;bspline&quot;</em>.</p>
</td></tr>
<tr><td><code id="optim.basis_+3A_par.cv">par.CV</code></td>
<td>
<p>List of parameters for type.CV: trim, the alpha of the
trimming and <code>draw=TRUE</code>.</p>
</td></tr>
<tr><td><code id="optim.basis_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code> information about GCV values and input
parameters is printed. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="optim.basis_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. Arguments to
be passed by default to <a href="fda.html#topic+create.basis">create.basis</a>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Provides the least GCV for functional data for a list of number of basis
<code>num.basis</code> and lambda values <code>lambda</code>. You can define the type of
CV to use with the <code>type.CV</code>, the default is used <code>GCV.S</code>. 
</p>
<p>Smoothing matrix is performed by <code><a href="#topic+S.basis">S.basis</a></code>. <code>W</code> is the
matrix of weights of the discretization points.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>gcv</code>: Returns GCV values calculated for input parameters.
</p>
</li>
<li> <p><code>fdataobj</code>: Matrix of set cases with dimension (<code>n</code> x <code>m</code>), where <code>n</code> is the number of curves and <code>m</code> are the points observed in each curve. 
</p>
</li>
<li> <p><code>fdata.est</code>: Estimated <code>fdata</code> class object.
</p>
</li>
<li> <p><code>numbasis.opt</code>: <code>numbasis</code> value that minimizes CV or GCV method.
</p>
</li>
<li> <p><code>lambda.opt</code>: <code>lambda</code> value that minimizes CV or GCV method.
</p>
</li>
<li> <p><code>basis.opt</code>: <code>basis</code> for the minimum CV or GCV method.
</p>
</li>
<li> <p><code>S.opt</code>: Smoothing matrix for the minimum CV or GCV method.
</p>
</li>
<li> <p><code>gcv.opt</code>: Minimum of CV or GCV method. 
</p>
</li>
<li> <p><code>lambda</code>: A roughness penalty. By default, no penalty <code>lambda=0</code>.
</p>
</li>
<li> <p><code>numbasis</code>: Number of basis to use. 
</p>
</li>
<li> <p><code>verbose</code>: If <code>TRUE</code> information about GCV values and input parameters is printed. Default is <code>FALSE</code>.
</p>
</li></ul>

<p>#' @author Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>Note</h3>

<p>min.basis deprecated.
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em>
Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>Wasserman, L. <em>All of Nonparametric Statistics</em>. Springer Texts in
Statistics, 2006.
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+S.basis">S.basis</a></code>. <br /> Alternative method:
<code><a href="#topic+optim.np">optim.np</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
a1&lt;-seq(0,1,by=.01)
a2=rnorm(length(a1),sd=0.2)
f1&lt;-(sin(2*pi*a1))+rnorm(length(a1),sd=0.2)
nc&lt;-50
np&lt;-length(f1)
tt=1:101
S&lt;-S.NW(tt,2)
mdata&lt;-matrix(NA,ncol=np,nrow=50)
for (i in 1:50) mdata[i,]&lt;- (sin(2*pi*a1))+rnorm(length(a1),sd=0.2)
mdata&lt;-fdata(mdata)
nb&lt;-floor(seq(5,29,len=5))
l&lt;-2^(-5:15)
out&lt;-optim.basis(mdata,lambda=l,numbasis=nb,type.basis="fourier")
matplot(t(out$gcv),type="l",main="GCV with fourier basis")

# out1&lt;-optim.basis(mdata,type.CV = CV.S,lambda=l,numbasis=nb)
# out2&lt;-optim.basis(mdata,lambda=l,numbasis=nb)

# variance calculations
y&lt;-mdata
i&lt;-3
z=qnorm(0.025/np)
fdata.est&lt;-out$fdata.est
var.e&lt;-Var.e(mdata,out$S.opt)
var.y&lt;-Var.y(mdata,out$S.opt)
var.y2&lt;-Var.y(mdata,out$S.opt,var.e)

# estimated fdata and point confidence interval
upper.var.e&lt;-out$fdata.est[["data"]][i,]-z*sqrt(diag(var.e))
lower.var.e&lt;-out$fdata.est[["data"]][i,]+z*sqrt(diag(var.e))
dev.new()
plot(y[i,],lwd=1,ylim=c(min(lower.var.e),max(upper.var.e)))
lines(out$fdata.est[["data"]][i,],col=gray(.1),lwd=1)
lines(out$fdata.est[["data"]][i,]+z*sqrt(diag(var.y)),col=gray(0.7),lwd=2)
lines(out$fdata.est[["data"]][i,]-z*sqrt(diag(var.y)),col=gray(0.7),lwd=2)
lines(upper.var.e,col=gray(.3),lwd=2,lty=2)
lines(lower.var.e,col=gray(.3),lwd=2,lty=2)
legend("top",legend=c("Var.y","Var.error"), col = c(gray(0.7),
gray(0.3)),lty=c(1,2))

## End(Not run)

</code></pre>

<hr>
<h2 id='optim.np'>Smoothing of functional data using nonparametric kernel estimation</h2><span id='topic+optim.np'></span><span id='topic+min.np'></span>

<h3>Description</h3>

<p>Smoothing of functional data using nonparametric kernel
estimation with cross-validation (CV) or generalized cross-validation 
(GCV) methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>optim.np(
  fdataobj,
  h = NULL,
  W = NULL,
  Ker = Ker.norm,
  type.CV = GCV.S,
  type.S = S.NW,
  par.CV = list(trim = 0, draw = FALSE),
  par.S = list(),
  correl = TRUE,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="optim.np_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="optim.np_+3A_h">h</code></td>
<td>
<p>Smoothing parameter or bandwidth.</p>
</td></tr>
<tr><td><code id="optim.np_+3A_w">W</code></td>
<td>
<p>Matrix of weights.</p>
</td></tr>
<tr><td><code id="optim.np_+3A_ker">Ker</code></td>
<td>
<p>Type of kernel used, by default normal kernel.</p>
</td></tr>
<tr><td><code id="optim.np_+3A_type.cv">type.CV</code></td>
<td>
<p>Type of cross-validation. By default generalized
cross-validation (GCV) method. Possible values are <em>GCV.S</em> and
<em>CV.S</em></p>
</td></tr>
<tr><td><code id="optim.np_+3A_type.s">type.S</code></td>
<td>
<p>Type of smothing matrix <code>S</code>. By default <code>S</code> is
calculated by Nadaraya-Watson kernel estimator (<code>S.NW</code>). Possible
values are <code><a href="#topic+S.KNN">S.KNN</a></code>,  <code><a href="#topic+S.LLR">S.LLR</a></code>, 
<code><a href="#topic+S.LPR">S.LPR</a></code> and  <code><a href="#topic+S.LCR">S.LCR</a></code>.</p>
</td></tr>
<tr><td><code id="optim.np_+3A_par.cv">par.CV</code></td>
<td>
<p>List of parameters  for type.CV: <code>trim</code>, the alpha of the
trimming and <code>draw=TRUE</code></p>
</td></tr>
<tr><td><code id="optim.np_+3A_par.s">par.S</code></td>
<td>
<p>List of parameters for <code>type.S</code>:
<code>tt</code> for argvals,  <code>h</code> for bandwidth,  
<code>Ker</code> for kernel, etc.</p>
</td></tr>
<tr><td><code id="optim.np_+3A_correl">correl</code></td>
<td>
<p>logical. If <code>TRUE</code> the bandwidth parameter <code>h</code> is computed following the 
procedure described for De  Brabanter et al. (2018). (option avalaible since v1.6.0 version)</p>
</td></tr>
<tr><td><code id="optim.np_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code> information about GCV values and input
parameters is printed. Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="optim.np_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. Arguments to
be passed for kernel method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Calculate the minimum GCV for a vector of values of the smoothing parameter
<code>h</code>.
Nonparametric smoothing is performed by the kernel function.
The type of kernel to use with the parameter <code>Ker</code> and the type of
smothing matrix <code>S</code> to use with the parameter <code>type.S</code> can be
selected by the user, see function <code><a href="#topic+Kernel">Kernel</a></code>.
W is the matrix of weights of the discretization points.
</p>


<h3>Value</h3>

<p>Returns GCV or CV values calculated for input parameters.
</p>

<ul>
<li> <p><code>gcv</code>: GCV or CV for a vector of values of the smoothing parameter
<code>h</code>. 
</p>
</li>
<li> <p><code>fdataobj</code>: <code><a href="#topic+fdata">fdata</a></code> class object.
</p>
</li>
<li> <p><code>fdata.est</code>: Estimated <code>fdata</code> class object.
</p>
</li>
<li> <p><code>h.opt</code>: <code>h</code> value that minimizes CV or GCV method.
</p>
</li>
<li> <p><code>S.opt</code>: Smoothing matrix for the minimum CV or GCV method.
</p>
</li>
<li> <p><code>gcv.opt</code>: Minimum of CV or GCV method.
</p>
</li>
<li> <p><code>h</code>: Smoothing parameter or bandwidth.
</p>
</li></ul>



<h3>Note</h3>

<p>min.np deprecated.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>
<p>Wasserman, L. <em>All of Nonparametric Statistics</em>. Springer Texts in
Statistics, 2006.
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994. 
</p>
<p>De Brabanter, K., Cao, F., Gijbels, I., Opsomer, J. (2018). Local polynomial regression with correlated errors in random design and
unknown correlation structure.  <em>Biometrika</em>, 105(3), 681-69.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012). Statistical Computing in
Functional Data Analysis: The R Package fda.usc. <em>Journal of
Statistical Software</em>, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>Alternative method:  <code><a href="#topic+optim.basis">optim.basis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Exemple, phoneme DATA
data(phoneme)
mlearn&lt;-phoneme$learn[1:100]

out1&lt;-optim.np(mlearn,type.CV=CV.S,type.S=S.NW)
np&lt;-ncol(mlearn)
# variance calculations
y&lt;-mlearn
out&lt;-out1
i&lt;-1
z=qnorm(0.025/np)
fdata.est&lt;-out$fdata.est
tt&lt;-y[["argvals"]]
var.e&lt;-Var.e(y,out$S.opt)
var.y&lt;-Var.y(y,out$S.opt)
var.y2&lt;-Var.y(y,out$S.opt,var.e)

# plot estimated fdata and point confidence interval
upper.var.e&lt;-fdata.est[i,]-z*sqrt(diag(var.e))
lower.var.e&lt;-fdata.est[i,]+z*sqrt(diag(var.e))
dev.new()
plot(y[i,],lwd=1, 
ylim=c(min(lower.var.e$data),max(upper.var.e$data)),xlab="t")
lines(fdata.est[i,],col=gray(.1),lwd=1)
lines(fdata.est[i,]+z*sqrt(diag(var.y)),col=gray(0.7),lwd=2)
lines(fdata.est[i,]-z*sqrt(diag(var.y)),col=gray(0.7),lwd=2)
lines(upper.var.e,col=gray(.3),lwd=2,lty=2)
lines(lower.var.e,col=gray(.3),lwd=2,lty=2)
legend("bottom",legend=c("Var.y","Var.error"),
col = c(gray(0.7),gray(0.3)),lty=c(1,2))

## End(Not run)

</code></pre>

<hr>
<h2 id='Outliers.fdata'>outliers for functional dataset</h2><span id='topic+Outliers.fdata'></span><span id='topic+outliers.depth.pond'></span><span id='topic+outliers.depth.trim'></span><span id='topic+outliers.thres.lrt'></span><span id='topic+outliers.lrt'></span><span id='topic+quantile.outliers.trim'></span><span id='topic+quantile.outliers.pond'></span>

<h3>Description</h3>

<p>Procedure for detecting funcitonal outliers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>outliers.depth.pond(
  fdataobj,
  nb = 200,
  smo = 0.05,
  quan = 0.5,
  dfunc = depth.mode,
  ...
)

outliers.depth.trim(
  fdataobj,
  nb = 200,
  smo = 0.05,
  trim = 0.01,
  quan = 0.5,
  dfunc = depth.mode,
  ...
)

outliers.lrt(fdataobj, nb = 200, smo = 0.05, trim = 0.1, ...)

outliers.thres.lrt(fdataobj, nb = 200, smo = 0.05, trim = 0.1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Outliers.fdata_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="Outliers.fdata_+3A_nb">nb</code></td>
<td>
<p>The number of bootstrap samples.</p>
</td></tr>
<tr><td><code id="Outliers.fdata_+3A_smo">smo</code></td>
<td>
<p>The smoothing parameter for the bootstrap samples.</p>
</td></tr>
<tr><td><code id="Outliers.fdata_+3A_quan">quan</code></td>
<td>
<p>Quantile to determine the cutoff from the Bootstrap procedure (by default=0.5)</p>
</td></tr>
<tr><td><code id="Outliers.fdata_+3A_dfunc">dfunc</code></td>
<td>
<p>Type of depth measure, by default <code>depth.mode</code>.</p>
</td></tr>
<tr><td><code id="Outliers.fdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="Outliers.fdata_+3A_trim">trim</code></td>
<td>
<p>The alpha of the trimming.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Outlier detection in functional data by likelihood ratio test (<code>outliers.lrt</code>). The threshold for outlier detection is given by the 
<code>outliers.thres.lrt</code>.
Outlier detection in functional data by depth measures: 
</p>

<ul>
<li> <p><code>outliers.depth.pond</code>: function weights the data according to depth.    
</p>
</li>
<li> <p><code>outliers.depth.trim</code>: function uses trimmed data.
</p>
</li></ul>

<p><code>quantile_outliers_pond</code> and <code>quantile_outliers_trim</code> functions provides
the quantiles of the bootstrap samples for functional outlier detection by, 
respectively, weigthed and trimmed procedures. Bootstrap smoothing function 
(<code><a href="#topic+fdata.bootstrap">fdata.bootstrap</a></code> with <code>nb</code> resamples) is applied to these 
weighted or trimmed data. If <code>smo=0</code> smoothed bootstrap is not performed.
The function returns a vector of size <code>1</code>x<code>nb</code> with bootstrap replicas of the quantile.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>outliers</code></td>
<td>
<p> Indexes of functional outlier.</p>
</td></tr>
<tr><td><code>dep.out</code></td>
<td>
<p>  Depth value of functional outlier.</p>
</td></tr>
<tr><td><code>dep.out</code></td>
<td>
<p>  Iteration in which the  functional outlier is detected.</p>
</td></tr>
<tr><td><code>quantile</code></td>
<td>
<p>  Threshold for outlier detection.</p>
</td></tr>
<tr><td><code>dep</code></td>
<td>
<p>  Depth value of functional data.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Cuevas A, Febrero M, Fraiman R. 2006.  <em>On the use of bootstrap for estimating functions with functional data</em>. Computational Statistics and Data Analysis 51: 1063-1074.
</p>
<p>Febrero-Bande, M., Galeano, P., and Gonzalez-Manteiga, W. (2008).  
<em>Outlier detection in functional data by depth measures with application to identify abnormal NOx levels</em>. Environmetrics 19, 4, 331&ndash;345. 
</p>
<p>Febrero-Bande, M., Galeano, P. and Gonzalez-Manteiga, W.	 (2007). <em>A functional analysis of NOx levels: location and scale estimation and outlier detection</em>. Computational Statistics 22, 3, 411-427.
</p>
<p>Febrero-Bande,  M., Oviedo de la Fuente, M. (2012).  <em>Statistical Computing in Functional Data Analysis: The R Package fda.usc.</em>
Journal of Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also: <code><a href="#topic+fdata.bootstrap">fdata.bootstrap</a></code>, <code><a href="#topic+Depth">Depth</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(aemet)
nb=20 # Time consuming
out.trim&lt;-outliers.depth.trim(aemet$temp,dfunc=depth.FM,nb=nb)
plot(aemet$temp,col=1,lty=1)
lines(aemet$temp[out.trim[[1]]],col=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='P.penalty'>Penalty matrix for higher order differences</h2><span id='topic+P.penalty'></span>

<h3>Description</h3>

<p>This function computes the matrix that penalizes the higher order
differences.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>P.penalty(tt, P = c(0, 0, 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="P.penalty_+3A_tt">tt</code></td>
<td>
<p>vector of the <code>n</code> discretization points or argvals.</p>
</td></tr>
<tr><td><code id="P.penalty_+3A_p">P</code></td>
<td>
<p>vector of coefficients with the order of the differences. Default
value <code>P</code>=c(0,0,1) penalizes the second order difference.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For example, if <code>P</code>=c(0,1,2), the function return the penalty matrix
the second order difference of a vector <code class="reqn">tt</code>. That is </p>
<p style="text-align: center;"><code class="reqn">v^T P_j tt=
\sum_{i=3} ^{n} (\Delta tt_i) ^2</code>
</p>
<p> where </p>
<p style="text-align: center;"><code class="reqn">\Delta tt_i= tt_i -2 tt_{i-1}
+ tt_{i-2}</code>
</p>
<p> is the second order difference. More details can be found in
Kraemer, Boulesteix, and Tutz (2008).
</p>


<h3>Value</h3>

<p>penalty matrix of size <code>sum(n)</code> x <code>sum(n)</code>
</p>


<h3>Note</h3>

<p>The discretization points can be equidistant or not.
</p>


<h3>Author(s)</h3>

<p>This version is created by Manuel Oviedo de la Fuente modified the
original version created by Nicole Kramer in <code>ppls</code> package.
</p>


<h3>References</h3>

<p>N. Kraemer, A.-L. Boulsteix, and G. Tutz (2008). <em>Penalized
Partial Least Squares with Applications to B-Spline Transformations and
Functional Data</em>. Chemometrics and Intelligent Laboratory Systems, 94, 60 -
69. <a href="https://doi.org/10.1016/j.chemolab.2008.06.009">doi:10.1016/j.chemolab.2008.06.009</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fdata2pls">fdata2pls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
P.penalty((1:10)/10,P=c(0,0,1))
# a more detailed example can be found under script file 
</code></pre>

<hr>
<h2 id='PCvM.statistic'>PCvM statistic for the Functional Linear Model with scalar response</h2><span id='topic+PCvM.statistic'></span><span id='topic+Adot'></span>

<h3>Description</h3>

<p>Projected Cramer-von Mises statistic (PCvM) for the Functional Linear Model with scalar response (FLM): 
<code class="reqn">Y=\big&lt;X,\beta\big&gt;+\varepsilon</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Adot(X, inpr)

PCvM.statistic(X, residuals, p, Adot.vec)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="PCvM.statistic_+3A_x">X</code></td>
<td>
<p>Functional covariate for the FLM. 
The object must be either in the class <code><a href="#topic+fdata">fdata</a></code> or in the class <a href="fda.html#topic+fd">fd</a>.
It is used to compute the matrix of inner products.</p>
</td></tr>
<tr><td><code id="PCvM.statistic_+3A_inpr">inpr</code></td>
<td>
<p>Matrix of inner products of <code>X</code>. Computed if not given.</p>
</td></tr>
<tr><td><code id="PCvM.statistic_+3A_residuals">residuals</code></td>
<td>
<p>Residuals of the estimated FLM.</p>
</td></tr>
<tr><td><code id="PCvM.statistic_+3A_p">p</code></td>
<td>
<p>Number of elements of the functional basis where the functional covariate is represented.</p>
</td></tr>
<tr><td><code id="PCvM.statistic_+3A_adot.vec">Adot.vec</code></td>
<td>
<p>Output from the <code>Adot</code> function (see Details). Computed if not given.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In order to optimize the computation of the statistic, the critical parts
of these two functions are coded in FORTRAN. The hardest part corresponds to the 
function <code>Adot</code>, which involves the computation of a symmetric matrix of dimension 
<code class="reqn">n\times n</code> where each entry is a sum of <code class="reqn">n</code> elements.
As this matrix is symmetric, the order of the method can be reduced from <code class="reqn">O(n^3)</code>
to <code class="reqn">O\big(\frac{n^3-n^2}{2}\big)</code>. The memory requirement can also be reduced
to <code class="reqn">O\big(\frac{n^2-n+2}{2}\big)</code>. The value of <code>Adot</code> is a vector of 
length <code class="reqn">\frac{n^2-n+2}{2}</code> where the first element is the common diagonal 
element and the rest are the lower triangle entries of the matrix, sorted by rows (see Examples).
</p>


<h3>Value</h3>

<p>For <code>PCvM.statistic</code>, the value of the statistic. For <code>Adot</code>,
a suitable output to be used in the argument <code>Adot.vec</code>.
</p>


<h3>Note</h3>

<p>No NA's are allowed in the functional covariate.
</p>


<h3>Author(s)</h3>

<p>Eduardo Garcia-Portugues. Please, report bugs and suggestions
to <a href="mailto:eduardo.garcia.portugues@uc3m.es">eduardo.garcia.portugues@uc3m.es</a>
</p>


<h3>References</h3>

<p>Escanciano, J. C. (2006). A consistent diagnostic test for regression models using projections. 
Econometric  Theory, 22, 1030-1051. <a href="https://doi.org/10.1017/S0266466606060506">doi:10.1017/S0266466606060506</a>
</p>
<p>Garcia-Portugues, E., Gonzalez-Manteiga, W. and Febrero-Bande, M. (2014). A goodness&ndash;of&ndash;fit
test for the functional linear model with scalar response. Journal of Computational and 
Graphical Statistics, 23(3), 761-778. <a href="https://doi.org/10.1080/10618600.2013.812519">doi:10.1080/10618600.2013.812519</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flm.test">flm.test</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Functional process
X=rproc2fdata(n=10,t=seq(0,1,l=101))
# Adot
Adot.vec=Adot(X)

# Obtain the entire matrix Adot
Ad=diag(rep(Adot.vec[1],dim(X$data)[1]))
Ad[upper.tri(Ad,diag=FALSE)]=Adot.vec[-1]
Ad=t(Ad)
Ad=Ad+t(Ad)-diag(diag(Ad))
Ad
# Statistic
PCvM.statistic(X,residuals=rnorm(10),p=5)
</code></pre>

<hr>
<h2 id='phoneme'>phoneme data</h2><span id='topic+phoneme'></span>

<h3>Description</h3>

<p>Phoneme curves
</p>


<h3>Format</h3>

<p>Elements of phoneme:<br /> <code>..$learn</code>: learning sample of curves.
<code>fdata</code> class object with: i.- <code>"data"</code>: Matrix of class
<code>fdata</code> with 250 curves (rows) discretized in 150 points or argvals
(columns).<br />, ii.- <code>"argvals"</code>, iii.- <code>"rangeval"</code>:
range(<code>"argvals"</code>), iv.- <code>"names"</code> list with: <code>main</code> an
overall title &quot;Phoneme learn&quot;, <code>xlab</code> title for <code>x</code> axis
&quot;frequencies&quot; and <code>ylab</code> title for <code>y</code> axis &quot;log-periodograms&quot;.<br />
<br /> <code>..$test</code>: testing sample of curves. <code>fdata</code> class object
with: i.- <code>"data"</code>: Matrix of class <code>fdata</code> with 250 curves (rows)
discretized in 150 points or argvals (columns).<br />, ii.- <code>"argvals"</code>,
iii.- <code>"rangeval"</code>: range(<code>"argvals"</code>), iv.- <code>"names"</code> list
with: <code>main</code> an overall title &quot;Phoneme learn&quot;, <code>xlab</code> title for
<code>x</code> axis &quot;frequencies&quot; and <code>ylab</code> title for <code>y</code> axis
&quot;log-periodograms&quot;.<br /> <br /> <code>..$classlearn</code>:learning class numbers (as
factor). Factor levels: &quot;sh&quot; 1, &quot;iy&quot; 2, &quot;dcl&quot; 3, &quot;aa&quot; 4 and &quot;ao&quot; 5.<br /> <br />
<code>..$classtest</code>: testing class numbers (as factor). Factor levels: &quot;sh&quot;
1, &quot;iy&quot; 2, &quot;dcl&quot; 3, &quot;aa&quot; 4 and &quot;ao&quot; 5.<br />
</p>


<h3>Details</h3>

<p>The following instructions have been used file: <br />
<a href="https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/npfda-phondiscRS.txt">https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/npfda-phondiscRS.txt</a><br />
of <code>Phoneme dataset</code> file.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande and Manuel Oviedo de la Fuente
&lt;manuel.oviedo@udc.es&gt;
</p>


<h3>Source</h3>

<p><a href="https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/npfda-datasets.html">https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/npfda-datasets.html</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>NPFDA in practice</em>. Free
access on line at <a href="https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/">https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(phoneme)
names(phoneme)
names(phoneme$learn)
class(phoneme$learn)
dim(phoneme$learn)
table(phoneme$classlearn)

</code></pre>

<hr>
<h2 id='plot.fdata'>Plot functional data: fdata class object</h2><span id='topic+plot.fdata'></span><span id='topic+lines.fdata'></span><span id='topic+title.fdata'></span><span id='topic+plot.bifd'></span><span id='topic+plot.depth'></span><span id='topic+plot.mdepth'></span><span id='topic+plot.lfdata'></span>

<h3>Description</h3>

<p>Plot object of class <code>fdata</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fdata'
plot(x, type, main, xlab, ylab, lty = 1, mfrow = c(1, 1), time = 1, ...)

## S3 method for class 'fdata'
lines(x, ...)

title.fdata(x, main = NULL, xlab = NULL, ylab = NULL, rownames = NULL)

## S3 method for class 'mdepth'
plot(x, trim, levgray = 0.9, ...)

## S3 method for class 'depth'
plot(x, trim, levgray = 0.9, ...)

## S3 method for class 'bifd'
plot(x, argvals.s, argvals.t, ...)

## S3 method for class 'lfdata'
plot(x, ask = FALSE, col, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot.fdata_+3A_x">x</code></td>
<td>
<p><code>fdata</code> class object with:  </p>
 
<ul>
<li> <p><code>"data"</code>:  For <code>fdata</code> class object as curve (1d), <code>"data"</code> is a
<code>matrix</code> (by default), <code>data.frame</code> or <code>array</code> of set cases
with dimension (<code>n</code> x <code>m</code>), where <code>n</code> is the number of curves
and <code>m</code> are the points observed in each curve over the x&ndash;axe.<br /> For
<code>fdata2d</code> class object as surface (2d). <code>"data"</code> is a <code>array</code>
of set cases with dimension (<code>n</code> x <code>m1</code> x <code>m2</code>), where
<code>n</code> is the number of functional data and <code>m1</code> and <code>m2</code> are
the points observed over the x&ndash;y plane.  </p>
</li>
<li> <p><code>"argvals"</code>: vector or
list of vectors with the discretizations points values.  </p>
</li>
<li>
<p><code>"rangeval"</code>: vector or list of vectors with the range of the
discretizations points values, by default range(<code>argvals</code>).  </p>
</li>
<li>
<p><code>"names"</code>: (optional) list with <code>main</code> an overall title,
<code>xlab</code> title for <code>x</code> axis and <code>ylab</code> title for <code>y</code> axis.
</p>
</li></ul>
 
<p>or a two-argument functional data object, see <a href="fda.html#topic+bifd">bifd</a>.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_type">type</code></td>
<td>
<p>1-character string giving the type of plot desired.<br /> The
following values are possible for <code>fdata</code> class object: &quot;l&quot; for lines
(by default),&quot;p&quot; for points, , &quot;o&quot; for overplotted points and lines, &quot;b&quot;,
&quot;c&quot; for (empty if &quot;c&quot;) points joined by lines, &quot;s&quot; and &quot;S&quot; for stair steps
and &quot;h&quot; for histogram-like vertical lines. Finally, &quot;n&quot; does not produce any
points or lines.<br /> The following values are possible for <code>fdata2d</code>
class object: &quot;image.contour&quot; (by default) to display three-dimensional data
and add the contour lines, &quot;image&quot; to display three-dimensional data,
&quot;contour&quot; to display a contour plot, &quot;persp&quot; to display a perspective plots
of a surface over the x-y plane and &quot;filled.contour&quot; to display a contour
plot with the areas between the contours filled in solid color.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_main">main</code></td>
<td>
<p>an overall title for the plot: see <code><a href="graphics.html#topic+title">title</a></code>.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_xlab">xlab</code></td>
<td>
<p>xlab title for x axis, as in plot.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_ylab">ylab</code></td>
<td>
<p>ylab title for y axis, as in plot.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_lty">lty</code></td>
<td>
<p>a vector of line types, see <code><a href="graphics.html#topic+par">par</a></code>.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_mfrow">mfrow</code></td>
<td>
<p>A vector of the form c(nr, nc). Subsequent figures will be
drawn in an nr-by-nc array on the device by rows (mfrow).</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_time">time</code></td>
<td>
<p>The time interval to suspend plot execution for, in seconds, see
<a href="base.html#topic+Sys.sleep">Sys.sleep</a>.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <a href="graphics.html#topic+matplot">matplot</a> function
(for fdata class) or <a href="graphics.html#topic+image">image</a>, <a href="graphics.html#topic+contour">contour</a>,
<a href="graphics.html#topic+persp">persp</a> or <a href="graphics.html#topic+filled.contour">filled.contour</a> (for fdata2d
class).</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_rownames">rownames</code></td>
<td>
<p>Row names.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_trim">trim</code></td>
<td>
<p>The alpha of the trimming.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_levgray">levgray</code></td>
<td>
<p>A vector of desired gray levels between 0 and 1; zero
indicates &quot;black&quot; and one indicates &quot;white&quot;.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_argvals.s">argvals.s</code></td>
<td>
<p>a vector of argument values for the first argument s of the
functional data object to be evaluated.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_argvals.t">argvals.t</code></td>
<td>
<p>a vector of argument values for the second argument t of
the functional data object to be evaluated.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_ask">ask</code></td>
<td>
<p>Logical. If <code>TRUE</code>, prompts for user interaction with the current graphics device.</p>
</td></tr>
<tr><td><code id="plot.fdata_+3A_col">col</code></td>
<td>
<p>The colors for curves, lines and points.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Febrero Bande and Manuel Oviedo de la Fuente
&lt;manuel.oviedo@udc.es&gt;
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+fdata">fdata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Example for fdata class of 1 dimension (curve)
a1&lt;-seq(0,1,by=.01)
a2=rnorm(length(a1),sd=0.2)
f1&lt;-(sin(2*pi*a1))+rnorm(length(a1),sd=0.2)
nc&lt;-10
np&lt;-length(f1)
tt=seq(0,1,len=101)
mdata&lt;-matrix(NA,ncol=np,nrow=nc)
for (i in 1:nc) mdata[i,]&lt;- (sin(2*pi*a1))+rnorm(length(a1),sd=0.2)
fdataobj&lt;-fdata(mdata,tt)
res=plot.fdata(fdataobj,type="l",col=gray(1:nrow(mdata)/nrow(mdata)))
lines(func.mean(fdataobj),col=3,lwd=2) #original curve

# example for fdata2d class of 2 dimension (surface)
t1 &lt;- seq(0, 1, length= 51)
t2 &lt;- seq(0, 1, length= 31)
z&lt;-array(NA,dim=c(4,51,31))
for (i in 1:4) z[i,,] &lt;- outer(t1, t2, function(a, b) (i*a)*(b)^i)
z.fdata&lt;-fdata(z,list(t1,t2))
plot(z.fdata,time=2)
plot(z.fdata,mfrow=c(2,2),type="persp",theta=30)

## End(Not run)

</code></pre>

<hr>
<h2 id='poblenou'>poblenou data</h2><span id='topic+poblenou'></span>

<h3>Description</h3>

<p>NOx levels measured every hour by a control station in Poblenou in Barcelona
(Spain).
</p>


<h3>Format</h3>

<p>The format is:<br /> <code>..$nox</code>: <code>fdata</code> class object with: <br />
i.- <code>"data"</code>: Matrix with 115 curves (rows) discretized in 24 points or
argvals (columns).<br /> ii.- <code>"argvals": 0:23</code><br /> iii.-
<code>"rangeval"=(0,23)</code>: range(<code>"argvals"</code>), <br /> iv.- <code>"names"</code>
list with: <code>main</code> an overall title &quot;NOx data set&quot;, <code>xlab</code> title
for <code>x</code> axis &quot;Hours&quot; and <code>ylab</code> title for <code>y</code> axis &quot;NOx
(mglm^3)&quot;.<br /> <br /> <code>..$df</code>: Data Frame with (115x3) dimension.  <br />
&quot;date&quot; in the first column.<br /> Second column (&quot;day.week&quot;).  Factor levels:
&quot;Monday&quot; 1, &quot;Tuesday&quot; 2, &quot;Wednesday&quot; 3, &quot;Thursday&quot; 4, &quot;Friday&quot; 5, &quot;Saturday&quot;
6 and &quot;Sunday&quot; 7.<br /> Third column &quot;day.festive&quot;.  Factor levels: &quot;non
festive day&quot; 0 and &quot;festive day&quot; 1.<br />
</p>


<h3>Details</h3>

<p>The dataset starts on 23 February and ends on 26 June, in 2005. We split the
whole sample of hourly measures in a dataset of functional trajectories of
24 h observations (each curve represents the evolution of the levels in 1
day).<br /> Twelve curves that contained missing data were eliminated.
</p>


<h3>Author(s)</h3>

<p>Febrero-Bande, M and Oviedo de la Fuente, Manuel
</p>


<h3>Source</h3>

<p><a href="https://mediambient.gencat.cat/ca/05_ambits_dactuacio/">https://mediambient.gencat.cat/ca/05_ambits_dactuacio/</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Galeano, P., and Gonzalez-Manteiga, W.
(2008).  <em>Outlier detection in functional data by depth measures with
application to identify abnormal NOx levels</em>. Environmetrics 19, 4, 331-345.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(poblenou)
names(poblenou)
names(poblenou$nox) 
nox&lt;-poblenou$nox
class(nox)
ind.weekend&lt;-as.integer(poblenou$df[,"day.week"])&gt;5
plot(nox,col=ind.weekend+1)

</code></pre>

<hr>
<h2 id='predict.classif'>Predicts from a fitted classif object.</h2><span id='topic+predict.classif'></span>

<h3>Description</h3>

<p>Classifier of functional data by kernel method using functional data object
of class <code>classif</code>.  Returns the predicted classes using a previously trained model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'classif'
predict(object, new.fdataobj = NULL, type = "class", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.classif_+3A_object">object</code></td>
<td>
<p>Object <code>object</code> estimated by: k nearest neighbors method
<code>classif.knn</code>, kernel method <code>classif.kernel</code>.</p>
</td></tr>
<tr><td><code id="predict.classif_+3A_new.fdataobj">new.fdataobj</code></td>
<td>
<p>New functional explanatory data of <code>fdata</code> class.</p>
</td></tr>
<tr><td><code id="predict.classif_+3A_type">type</code></td>
<td>
<p>Type of prediction (&quot;class or probability of each group
membership&quot;).</p>
</td></tr>
<tr><td><code id="predict.classif_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If type=&quot;class&quot;, produces a vector of predictions.
If type=&quot;probs&quot;, a list with the following components is returned: 
</p>

<ul>
<li> <p><code>group.pred</code> the vector of predictions. 
</p>
</li>
<li> <p><code>prob.group</code> the matrix of predicted probability by factor level. 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametricc functional
data analysis.</em> Springer Series in Statistics, New York.
</p>
<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em> Functional Data
Analysis</em>, 2nd ed., Springer, New York.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+classif.np">classif.np</a></code> <code><a href="#topic+classif.glm">classif.glm</a></code>,
<code><a href="#topic+classif.gsam">classif.gsam</a></code> and <code><a href="#topic+classif.gkam">classif.gkam</a></code> .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
mlearn &lt;- phoneme[["learn"]][1:100]
glearn &lt;- phoneme[["classlearn"]][1:100]

#	ESTIMATION knn
out1 &lt;- classif.knn(glearn, mlearn, knn = 3)
summary(out1)

#	PREDICTION knn
mtest &lt;- phoneme[["test"]][1:100]
gtest &lt;- phoneme[["classtest"]][1:100]
pred1 &lt;- predict(out1, mtest)
table(pred1, gtest)
 
#	ESTIMATION kernel 
h &lt;- 2^(0:5)
# using metric distances computed in classif.knn
out2 &lt;- classif.kernel(glearn, mlearn, h = h, metric = out1$mdist)
summary(out2)
#	PREDICTION kernel
pred2 &lt;- predict(out2,mtest)
table(pred2,gtest)

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.classif.DD'>Predicts from a fitted classif.DD object.</h2><span id='topic+predict.classif.DD'></span>

<h3>Description</h3>

<p>Classifier of functional (and multivariate) data by DD&ndash;classifier.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'classif.DD'
predict(object, new.fdataobj = NULL, type = "class", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.classif.DD_+3A_object">object</code></td>
<td>
<p>Object <code>object</code> estimated by <code>classif.DD</code>.</p>
</td></tr>
<tr><td><code id="predict.classif.DD_+3A_new.fdataobj">new.fdataobj</code></td>
<td>
<p>By default, new p functional explanatory dataset or new
mulitvariate data of <code>data.frame</code> class</p>
</td></tr>
<tr><td><code id="predict.classif.DD_+3A_type">type</code></td>
<td>
<p>!=&rdquo;predictive&rdquo;, for each row of data shows the probability of
each group membership.</p>
</td></tr>
<tr><td><code id="predict.classif.DD_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Returns the groups or classes predicted using a previously trained model.
</p>


<h3>Value</h3>


<ul>
<li> <p><code>group.pred</code>:Vector of groups or classes predicted
</p>
</li>
<li> <p><code>prob.group</code>: For each functional data shows the probability of each group membership.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Febrero-Bande, M., and Oviedo de la Fuente, M.
</p>


<h3>References</h3>

<p>Li, J., P.C., Cuesta-Albertos, J.A. and Liu, R.
<em>DD&ndash;Classifier: Nonparametric Classification Procedure Based on
DD-plot</em>.  Journal of the American Statistical Association (2012), Vol. 107,
737&ndash;753.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+classif.DD">classif.DD</a></code> .
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# DD-classif for multivariate data 
data(iris)
iris&lt;-iris[1:100,]
ii&lt;-sample(1:100,80)
group.train&lt;-factor(iris[ii,5])
x.train&lt;-iris[ii,1:4]
out1=classif.DD(group.train,x.train,depth="MhD",classif="lda")
out2=classif.DD(group.train,x.train,depth="MhD",classif="glm")
summary(out1)
summary(out2)
x.test&lt;-iris[-ii,1:4]
pred1=predict(out1,x.test)
pred2=predict(out2,x.test)
group.test&lt;-iris[-ii,5]
table(pred1,group.test)
table(pred2,group.test)

# DD-classif for Functional data
data(phoneme)
mlearn&lt;-phoneme[["learn"]]
glearn&lt;-phoneme[["classlearn"]]

#	ESTIMATION 
out1=classif.DD(glearn,mlearn,depth="FM",classif="glm")
summary(out1)
#	PREDICTION 
mtest&lt;-phoneme[["test"]]
gtest&lt;-phoneme[["classtest"]]
pred1=predict(out1,mtest)
table(pred1,gtest)

## End(Not run)
</code></pre>

<hr>
<h2 id='predict.fregre.fd'>Predict method for functional linear model (fregre.fd class)</h2><span id='topic+predict.fregre.fd'></span>

<h3>Description</h3>

<p>Computes predictions for regression between functional explanatory variables
and scalar response using: basis representation, Principal Components
Analysis, Partial least squares or nonparametric kernel estimation.
</p>
<p>Predicts from a fitted <code>fregre.basis</code> object,see
<code><a href="#topic+fregre.basis">fregre.basis</a></code> or <code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code><br /> Predicts from
a fitted <code>fregre.pc</code> object,see <code><a href="#topic+fregre.pc">fregre.pc</a></code> or
<code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code><br /> Predicts from a fitted <code>fregre.pls</code>
object,see <code><a href="#topic+fregre.pls">fregre.pls</a></code> or <code><a href="#topic+fregre.pls.cv">fregre.pls.cv</a></code><br />
Predicts from a fitted <code>fregre.np</code> object, see <code><a href="#topic+fregre.np">fregre.np</a></code>
or <code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fregre.fd'
predict(
  object,
  new.fdataobj = NULL,
  se.fit = FALSE,
  scale = NULL,
  df = df,
  interval = "none",
  level = 0.95,
  weights = 1,
  pred.var = res.var/weights,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.fregre.fd_+3A_object">object</code></td>
<td>
<p><code>fregre.fd</code> object.</p>
</td></tr>
<tr><td><code id="predict.fregre.fd_+3A_new.fdataobj">new.fdataobj</code></td>
<td>
<p>New functional explanatory data of <code>fdata</code> class.</p>
</td></tr>
<tr><td><code id="predict.fregre.fd_+3A_se.fit">se.fit</code></td>
<td>
<p>=TRUE (not default) standard error estimates are returned for
each prediction.</p>
</td></tr>
<tr><td><code id="predict.fregre.fd_+3A_scale">scale</code></td>
<td>
<p>Scale parameter for std.err. calculation.</p>
</td></tr>
<tr><td><code id="predict.fregre.fd_+3A_df">df</code></td>
<td>
<p>Degrees of freedom for scale.</p>
</td></tr>
<tr><td><code id="predict.fregre.fd_+3A_interval">interval</code></td>
<td>
<p>Type of interval calculation.</p>
</td></tr>
<tr><td><code id="predict.fregre.fd_+3A_level">level</code></td>
<td>
<p>Tolerance/confidence level.</p>
</td></tr>
<tr><td><code id="predict.fregre.fd_+3A_weights">weights</code></td>
<td>
<p>variance weights for prediction. This can be a numeric vector
or a one-sided model formula. In the latter case, it is interpreted as an
expression evaluated in newdata</p>
</td></tr>
<tr><td><code id="predict.fregre.fd_+3A_pred.var">pred.var</code></td>
<td>
<p>the variance(s) for future observations to be assumed for
prediction intervals. See <code>link{predict.lm}</code> for more details.</p>
</td></tr>
<tr><td><code id="predict.fregre.fd_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>se.fit = FALSE</code>, a vector of predictions of scalar response
is returned or a matrix of predictions and bounds with column names fit,
lwr, and upr if interval is set.
If <code>se.fit =TRUE</code> a list with the following components is returned: 
</p>

<ul>
<li>  <p><code>fit</code>: A vector of predictions or a matrix of predictions and bounds as above.
</p>
</li>
<li>  <p><code>se.fit</code>: Associated standard error estimates of predictions.
</p>
</li>
<li>  <p><code>residual.scale</code>: Residual standard deviations.
</p>
</li>
<li>  <p><code>df</code>: Degrees of freedom for residual.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Cai TT, Hall P. 2006. <em>Prediction in functional linear
regression</em>. Annals of Statistics 34: 2159-2179.
</p>
<p>Cardot H, Ferraty F, Sarda P. 1999. <em>Functional linear model</em>.
Statistics and Probability Letters 45: 11-22.
</p>
<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional data
analysis.</em> Springer Series in Statistics, New York.
</p>
<p>Hall P, Hosseini-Nasab M. 2006. <em>On properties of functional principal
components analysis</em>. Journal of the Royal Statistical Society B 68:
109-126.
</p>
<p>Hardle, W. <em>Applied Nonparametric Regression</em>. Cambridge University
Press, 1994.
</p>
<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em> Functional Data
Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).  <em>Statistical
Computing in Functional Data Analysis: The R Package fda.usc.</em> Journal of
Statistical Software, 51(4), 1-28. <a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.basis">fregre.basis</a></code>,
<code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code>, <code><a href="#topic+fregre.np">fregre.np</a></code>,
<code><a href="#topic+fregre.np.cv">fregre.np.cv</a></code>, <br /> <code><a href="#topic+fregre.pc">fregre.pc</a></code>,
<code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code>, <code><a href="#topic+fregre.pls">fregre.pls</a></code>,
<code><a href="#topic+fregre.pls.cv">fregre.pls.cv</a></code> <br /> and <code><a href="#topic+summary.fregre.fd">summary.fregre.fd</a></code>.<br />
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
absorp=tecator$absorp.fdata
ind=1:129
x=absorp[ind,]
y=tecator$y$Fat[ind]
newx=absorp[-ind,]
newy=matrix(tecator$y$Fat[-ind],ncol=1)
## Functional PC regression
res.pc=fregre.pc(x,y,1:6)
pred.pc=predict(res.pc,newx)
# Functional PLS regression
res.pls=fregre.pls(x,y,1:6)
pred.pls=predict(res.pls,newx)
# Functional nonparametric regression
res.np=fregre.np(x,y,Ker=AKer.tri,metric=semimetric.deriv)
pred.np=predict(res.np,newx)
# Functional regression with basis representation
res.basis=fregre.basis.cv(x,y)
pred.basis=predict(res.basis[[1]],newx)
 
dev.new()
plot(pred.pc-newy)
points(pred.pls-newy,col=2,pch=2)
points(pred.np-newy,col=3,pch=3)
points(pred.basis-newy,col=4,pch=4)
sum((pred.pc-newy)^2,na.rm=TRUE)/sum((newy-mean(newy))^2,na.rm=TRUE)
sum((pred.pls-newy)^2,na.rm=TRUE)/sum((newy-mean(newy))^2,na.rm=TRUE)
sum((pred.np-newy)^2,na.rm=TRUE)/sum((newy-mean(newy))^2,na.rm=TRUE)
sum((pred.basis-newy)^2,na.rm=TRUE)/sum((newy-mean(newy))^2,na.rm=TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.fregre.fr'>Predict method for functional response model</h2><span id='topic+predict.fregre.fr'></span>

<h3>Description</h3>

<p>Computes predictions for regression between functional explanatory variables
and functional response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fregre.fr'
predict(object, new.fdataobj = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.fregre.fr_+3A_object">object</code></td>
<td>
<p><code>fregre.fr</code> object.</p>
</td></tr>
<tr><td><code id="predict.fregre.fr_+3A_new.fdataobj">new.fdataobj</code></td>
<td>
<p>New functional explanatory data of <code>fdata</code> class.</p>
</td></tr>
<tr><td><code id="predict.fregre.fr_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the predicted functional data.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.basis.fr">fregre.basis.fr</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
# CV prediction for CandianWeather data
rtt&lt;-c(0, 365)
basiss  &lt;- create.bspline.basis(rtt,7)
basist  &lt;- create.bspline.basis(rtt,9)
nam&lt;-dimnames(CanadianWeather$dailyAv)[[2]]

# fdata class (raw data)
tt&lt;-1:365
tempfdata&lt;-fdata(t(CanadianWeather$dailyAv[,,1]),tt,rtt)
log10precfdata&lt;-fdata(t(CanadianWeather$dailyAv[,,3]),tt,rtt)
rng&lt;-range(log10precfdata) 
for (ind in 1:35){
 res1&lt;-  fregre.basis.fr(tempfdata[-ind], log10precfdata[-ind],
 basis.s=basiss,basis.t=basist)
 pred1&lt;-predict(res1,tempfdata[ind])
 plot( log10precfdata[ind],col=1,ylim=rng,main=nam[ind])
 lines(pred1,lty=2,col=2)
 Sys.sleep(1)
}

# fd class  (smooth data)
basis.alpha  &lt;- create.constant.basis(rtt)
basisx  &lt;- create.bspline.basis(rtt,65)

dayfd&lt;-Data2fd(day.5,CanadianWeather$dailyAv,basisx)
tempfd&lt;-dayfd[,1]
log10precfd&lt;-dayfd[,3]
for (ind in 1:35){
 res2 &lt;-  fregre.basis.fr(tempfd[-ind], log10precfd[-ind],
 basis.s=basiss,basis.t=basist)
 pred2&lt;-predict(res2,tempfd[ind])
 plot(log10precfd[ind],col=1,ylim=range(log10precfd$coef),main=nam[ind]) 
 lines(pred2,lty=2,col=2)
 Sys.sleep(.5)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='predict.fregre.gkam'>Predict method for functional linear model</h2><span id='topic+predict.fregre.gkam'></span><span id='topic+predict.fregre.glm'></span><span id='topic+predict.fregre.gsam'></span><span id='topic+predict.fregre.lm'></span><span id='topic+predict.fregre.plm'></span>

<h3>Description</h3>

<p>Computes predictions for regression between functional (and non functional)
explanatory variables and scalar response. 
</p>
 
<ul>
<li> <p><code>predict.fregre.lm</code>, Predict method for functional linear model of
<code><a href="#topic+fregre.lm">fregre.lm</a></code> fits object using basis or principal component
representation.
</p>
</li>
<li> <p><code>predict.fregre.plm</code>, Predict method for
semi-functional linear regression model of <code><a href="#topic+fregre.plm">fregre.plm</a></code> fits
object using using asymmetric kernel estimation. 
</p>
</li>
<li> <p><code>predict.fregre.glm</code>, Predict method for functional generalized linear
model of <code><a href="#topic+fregre.glm">fregre.glm</a></code> fits object using basis or principal
component representation. 
</p>
</li>
<li> <p><code>predict.fregre.gsam</code>, Predict method for functional generalized 
spectral additive model of <code><a href="#topic+fregre.gsam">fregre.gsam</a></code> fits object using basis 
or principal component representation.
</p>
</li>
<li> <p><code>predict.fregre.gkam</code>, Predict method for functional generalized 
kernel additive model of <code><a href="#topic+fregre.gkam">fregre.gkam</a></code> fits object using 
backfitting algorithm. 
</p>
</li></ul>

<p>These functions use the model fitting function <code><a href="stats.html#topic+lm">lm</a></code>,
<code><a href="stats.html#topic+glm">glm</a></code> or <a href="mgcv.html#topic+gam">gam</a> properties.<br /> If using functional
data derived, is recommended to use a number of bases to represent beta
lower than the number of bases used to represent the functional data. <br />
The first item in the <code>data</code> list of <code>newx</code> argument is called
<em>&quot;df&quot;</em> and is a data frame with the response and non functional
explanatory variables, as <code><a href="stats.html#topic+lm">lm</a></code>, <code><a href="stats.html#topic+glm">glm</a></code> or
<a href="mgcv.html#topic+gam">gam</a>. Functional variables (<code>fdata</code> and <code>fd</code> class)
are introduced in the following items in the <code>data</code> list of <code>newx</code>
argument.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fregre.gkam'
predict(object, newx = NULL, type = "response", ...)

## S3 method for class 'fregre.glm'
predict(object, newx = NULL, type = "response", ...)

## S3 method for class 'fregre.gsam'
predict(object, newx = NULL, type = "response", ...)

## S3 method for class 'fregre.lm'
predict(
  object,
  newx = NULL,
  type = "response",
  se.fit = FALSE,
  scale = NULL,
  df = df,
  interval = "none",
  level = 0.95,
  weights = 1,
  pred.var = res.var/weights,
  ...
)

## S3 method for class 'fregre.plm'
predict(object, newx = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.fregre.gkam_+3A_object">object</code></td>
<td>
<p><code>fregre.lm</code>, <code>fregre.plm</code>, <code>fregre.glm</code>,
<code>fregre.gsam</code><br /> or <code>fregre.gkam</code> object.</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_newx">newx</code></td>
<td>
<p>An optional data list in which to look for variables with which
to predict. If omitted, the fitted values are used. List of new explanatory
data.</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_type">type</code></td>
<td>
<p>a character vector, Type of prediction: (<code>response</code>, <code>terms</code> for model terms or <code>effects</code>  for model terms where
the partial effects are summarized for each functional variable.</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_se.fit">se.fit</code></td>
<td>
<p>=TRUE (not default) standard error estimates are returned for
each prediction.</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_scale">scale</code></td>
<td>
<p>Scale parameter for std.err. calculation.</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_df">df</code></td>
<td>
<p>Degrees of freedom for scale.</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_interval">interval</code></td>
<td>
<p>Type of interval calculation.</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_level">level</code></td>
<td>
<p>Tolerance/confidence level.</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_weights">weights</code></td>
<td>
<p>variance weights for prediction. This can be a numeric vector
or a one-sided model formula. In the latter case, it is interpreted as an
expression evaluated in newdata</p>
</td></tr>
<tr><td><code id="predict.fregre.gkam_+3A_pred.var">pred.var</code></td>
<td>
<p>the variance(s) for future observations to be assumed for
prediction intervals. See <code>link{predict.lm}</code> for more details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the predicted values and optionally:
</p>

<ul>
<li> <p><code>predict.lm,predict.glm,predict.gam</code>: produces a vector of predictions
or a matrix of predictions and bounds with column names fit, lwr, and upr if
interval is set. If se.fit is TRUE, a list with the following components is
returned: fit vector or matrix as above.
</p>
</li>
<li> <p><code>se.fit</code>: standard error of predicted means.
</p>
</li>
<li> <p><code>residual.scale</code>: residual standard deviations.
</p>
</li>
<li> <p><code>df</code>: degrees of freedom for residual.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Febrero-Bande, M., Oviedo de la Fuente, M. (2012).
<em>Statistical Computing in Functional Data Analysis: The R Package
fda.usc.</em> Journal of Statistical Software, 51(4), 1-28.
<a href="https://www.jstatsoft.org/v51/i04/">https://www.jstatsoft.org/v51/i04/</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+fregre.lm">fregre.lm</a></code>, <code><a href="#topic+fregre.plm">fregre.plm</a></code>,
<code><a href="#topic+fregre.glm">fregre.glm</a></code>, <code><a href="#topic+fregre.gsam">fregre.gsam</a></code> and
<code><a href="#topic+fregre.gkam">fregre.gkam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
ind &lt;- 1:129
x &lt;- tecator$absorp.fdata
x.d2 &lt;- fdata.deriv(x,nderiv=2)
tt &lt;- x[["argvals"]]
dataf &lt;- as.data.frame(tecator$y)
ldat &lt;- ldata("df" = dataf[ind,], "x.d2" = x.d2[ind])
basis.x &lt;- list("x.d2" = create.pc.basis(ldat$x.d2))
res &lt;- fregre.gsam(Fat ~  s(x.d2,k=3),
                   data=ldat, family = gaussian(),
                   basis.x = basis.x)
newldat &lt;- ldata("df" = dataf[-ind,], "x.d2" = x.d2[-ind])
pred &lt;- predict(res, newldat)
plot(pred,tecator$y$Fat[-ind])
res.glm &lt;- fregre.glm(Fat  ~  x.d2, data = ldat,
                  family = gaussian(),basis.x = basis.x)
pred.glm &lt;- predict(res.glm, newldat)
newy &lt;- tecator$y$Fat[-ind]
points(pred.glm,tecator$y$Fat[-ind],col=2)

# Time-consuming 
res.gkam &lt;- fregre.gkam(Fat ~ x.d2, data = ldat)
pred.gkam &lt;- predict(res.gkam, newldat)
points(pred.gkam,tecator$y$Fat[-ind],col = 4)

((1/length(newy)) * sum((drop(newy)-pred)^2)) / var(newy)
((1/length(newy)) * sum((newy-pred.glm)^2)) / var(newy)    
((1/length(newy)) * sum((newy-pred.gkam)^2)) / var(newy)    

## End(Not run)                                                                                                              
</code></pre>

<hr>
<h2 id='predict.fregre.gls'>Predictions from a functional gls object</h2><span id='topic+predict.fregre.gls'></span><span id='topic+predict.fregre.igls'></span>

<h3>Description</h3>

<p>The predictions for the functional generalized least squares fitted linear
model represented by <code>object</code> are obtained at the covariate values
defined in <code>newx</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fregre.gls'
predict(
  object,
  newx = NULL,
  type = "response",
  se.fit = FALSE,
  scale = NULL,
  df,
  interval = "none",
  ...
)

## S3 method for class 'fregre.igls'
predict(
  object,
  newx = NULL,
  data,
  df = df,
  weights = 1,
  pred.var,
  n.ahead = 1L,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.fregre.gls_+3A_object">object</code></td>
<td>
<p><code>fregre.gls</code> object.</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_newx">newx</code></td>
<td>
<p>An optional data list in which to look for
variables with which to predict. If omitted, the fitted values are used.
List of new explanatory data.</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_type">type</code></td>
<td>
<p>Type of prediction (response or model term).</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_se.fit">se.fit</code></td>
<td>
<p>=TRUE (not default) standard error estimates are returned for
each prediction.</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_scale">scale</code></td>
<td>
<p>Scale parameter for std.err. calculation.</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_df">df</code></td>
<td>
<p>Degrees of freedom for scale.</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_interval">interval</code></td>
<td>
<p>Type of interval calculation.</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_data">data</code></td>
<td>
<p>Data frame with the time or spatinal index</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_weights">weights</code></td>
<td>
<p>variance weights for prediction. This can be a numeric vector
or a one-sided model formula. In the latter case, it is interpreted as an
expression evaluated in newdata</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_pred.var">pred.var</code></td>
<td>
<p>the variance(s) for future observations to be assumed for
prediction intervals. See <code>link{predict.lm}</code> for more details.</p>
</td></tr>
<tr><td><code id="predict.fregre.gls_+3A_n.ahead">n.ahead</code></td>
<td>
<p>number of steps ahead at which to predict.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a vector with the predicted values.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Oviedo de la Fuente, M., Febrero-Bande, M., Pilar Munoz, and
Dominguez, A. Predicting seasonal influenza transmission using Functional
Regression Models with Temporal Dependence. arXiv:1610.08718.
<a href="https://arxiv.org/abs/1610.08718">https://arxiv.org/abs/1610.08718</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fregre.gls">fregre.gls</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(tecator)
ind&lt;-1:190
x &lt;-fdata.deriv(tecator$absorp.fdata,nderiv=1)
dataf=as.data.frame(tecator$y)
dataf$itime &lt;- 1:nrow(x)
ldat=list("df"=dataf[ind,],"x"=x[ind])
newldat=list("df"=dataf[-ind,],"x"=x[-ind])
newy &lt;- tecator$y$Fat[-ind]
ff &lt;- Fat ~ x
res.lm &lt;- fregre.lm(ff,data=ldat)
summary(res.lm)
res.gls &lt;- fregre.gls(ff,data=ldat, correlation=corAR1())
summary(res.gls)
par.cor &lt;- list("cor.ARMA"=list("p"=1))
par.cor &lt;- list("cor.ARMA"=list("index"=c("itime"),"p"=1))
res.igls &lt;- fregre.igls(ff,data=ldat,correlation=par.cor) 
pred.lm &lt;- predict(res.lm,newldat)
pred.gls &lt;- predict(res.gls,newldat)
pred.igls &lt;- predict(res.igls,newldat)
mean((pred.lm-newldat$df$Fat)^2)
mean((pred.gls-newldat$df$Fat)^2)
mean((pred.igls-newldat$df$Fat)^2)

## End(Not run)

</code></pre>

<hr>
<h2 id='r.ou'>Ornstein-Uhlenbeck process</h2><span id='topic+r.ou'></span>

<h3>Description</h3>

<p>Sampling of paths of the Ornstein-Uhlenbeck process.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>r.ou(
  n,
  t = seq(0, 1, len = 201),
  mu = 0,
  alpha = 1,
  sigma = 1,
  x0 = rnorm(n, mean = mu, sd = sigma/sqrt(2 * alpha))
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="r.ou_+3A_n">n</code></td>
<td>
<p>number of curves.</p>
</td></tr>
<tr><td><code id="r.ou_+3A_t">t</code></td>
<td>
<p>discretization points.</p>
</td></tr>
<tr><td><code id="r.ou_+3A_mu">mu</code></td>
<td>
<p>mean of the process.</p>
</td></tr>
<tr><td><code id="r.ou_+3A_alpha">alpha</code></td>
<td>
<p>strength of the drift.</p>
</td></tr>
<tr><td><code id="r.ou_+3A_sigma">sigma</code></td>
<td>
<p>diffusion coefficient.</p>
</td></tr>
<tr><td><code id="r.ou_+3A_x0">x0</code></td>
<td>
<p>a number or a vector of length <code>n</code> giving the initial
value(s) of the Ornstein-Uhlenbeck process. By default, <code>n</code> points are
sampled from the stationary distribution.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Functional sample, an <code><a href="#topic+fdata">fdata</a></code> object of length
<code>n</code>.
</p>


<h3>Author(s)</h3>

<p>Eduardo Garcia-Portugues (<a href="mailto:edgarcia@est-econ.uc3m.es">edgarcia@est-econ.uc3m.es</a>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(r.ou(n = 100))
plot(r.ou(n = 100, alpha = 2, sigma = 4, x0 = 1:100))

</code></pre>

<hr>
<h2 id='rcombfdata'>Utils for generate functional data</h2><span id='topic+rcombfdata'></span><span id='topic+gridfdata'></span>

<h3>Description</h3>

<p><code>gridfdata</code> generates <code>n</code> curves as lineal combination of the
original curves <code>fdataobj</code> plus a functional trend <code>mu</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcombfdata(n = 10, fdataobj, mu, sdarg = rep(1, nrow(fdataobj)), norm = 1)

gridfdata(coef, fdataobj, mu)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rcombfdata_+3A_n">n</code></td>
<td>
<p>Number of curves to be generated</p>
</td></tr>
<tr><td><code id="rcombfdata_+3A_fdataobj">fdataobj</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="rcombfdata_+3A_mu">mu</code></td>
<td>
<p>Functional trend, by default <code>mu</code>=<code class="reqn">\mu(t)=0</code>. An object
of class <code><a href="#topic+fdata">fdata</a></code>.  
<code>t</code><code class="reqn">=</code><code>argvals(mu)</code>.</p>
</td></tr>
<tr><td><code id="rcombfdata_+3A_sdarg">sdarg</code></td>
<td>
<p>Standard deviation of the coefficients.</p>
</td></tr>
<tr><td><code id="rcombfdata_+3A_norm">norm</code></td>
<td>
<p>Norm of the coefficients. The norm is adjusted before the
transformation for <code>sdarg</code> is performed.</p>
</td></tr>
<tr><td><code id="rcombfdata_+3A_coef">coef</code></td>
<td>
<p>Coefficients of the combination. A matrix with number of columns
equal to number of curves in <code>fdataobj</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>rcombfdata</code> generates <code>n</code> random linear combinations of the
<code>fdataobj</code> curves plus a functional trend <code>mu</code>. The coefficients
of the combinations follows a normal distribution with zero mean and
standard deviation <code>sdarg</code>.
</p>


<h3>Value</h3>

<p>Return the functional trajectories as a <code>fdata</code> class object.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+rproc2fdata">rproc2fdata</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
tt=seq(0,1,len=51)
fou3=create.fourier.basis(c(0,1),nbasis=3)
fdataobj=fdata(t(eval.basis(tt,fou3)),argvals=tt)

coef=expand.grid(0,seq(-1,1,len=11),seq(-1,1,len=11))
grid=gridfdata(coef,fdataobj)
plot(grid,lty=1)

rcomb=rcombfdata(n=51,fdataobj,mu=fdata(30*tt*(1-tt),tt))
plot(rcomb,lty=1)

## End(Not run)

</code></pre>

<hr>
<h2 id='rdir.pc'>Data-driven sampling of random directions guided by sample of functional
data</h2><span id='topic+rdir.pc'></span>

<h3>Description</h3>

<p>Generation of random directions based on the principal components <code class="reqn">\hat
e_1,\ldots,\hat e_k</code> of a sample of functional data
<code class="reqn">X_1,\ldots,X_n</code>. The random directions are sampled as
</p>
<p style="text-align: center;"><code class="reqn">h=\sum_{j=1}^kh_j\hat e_j,</code>
</p>
<p> with
<code class="reqn">h_j\sim\mathcal{N}(0, \sigma_j^2)</code>,
<code class="reqn">j=1,\ldots,k</code>. Useful for sampling non-orthogonal random
directions <code class="reqn">h</code> such that they are non-orthogonal for the random
sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdir.pc(
  n,
  X.fdata,
  ncomp = 0.95,
  fdata2pc.obj = fdata2pc(X.fdata, ncomp = min(length(X.fdata$argvals), nrow(X.fdata))),
  sd = 0,
  zero.mean = TRUE,
  norm = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rdir.pc_+3A_n">n</code></td>
<td>
<p>number of curves to be generated.</p>
</td></tr>
<tr><td><code id="rdir.pc_+3A_x.fdata">X.fdata</code></td>
<td>
<p>an <code><a href="#topic+fdata">fdata</a></code> object used to compute the
functional principal components.</p>
</td></tr>
<tr><td><code id="rdir.pc_+3A_ncomp">ncomp</code></td>
<td>
<p>if an integer vector is provided, the index for the principal
components to be considered. If a threshold between <code>0</code> and <code>1</code> is
given, the number of components <code class="reqn">k</code> is determined automatically as
the minimum number that explains at least the <code>ncomp</code> proportion of the
total variance of <code>X.fdata</code>.</p>
</td></tr>
<tr><td><code id="rdir.pc_+3A_fdata2pc.obj">fdata2pc.obj</code></td>
<td>
<p>output of <code><a href="#topic+fdata2pc">fdata2pc</a></code> containing as
many components as the ones to be selected by <code>ncomp</code>. Otherwise, it is
computed internally.</p>
</td></tr>
<tr><td><code id="rdir.pc_+3A_sd">sd</code></td>
<td>
<p>if <code>0</code>, the standard deviations <code class="reqn">\sigma_j</code> are estimated
by the standard deviations of the scores for <code class="reqn">e_j</code>. If not, the
<code class="reqn">\sigma_j</code>'s are set to <code>sd</code>.</p>
</td></tr>
<tr><td><code id="rdir.pc_+3A_zero.mean">zero.mean</code></td>
<td>
<p>whether the projections should have zero mean. If not, the
mean is set to the mean of <code>X.fdata</code>.</p>
</td></tr>
<tr><td><code id="rdir.pc_+3A_norm">norm</code></td>
<td>
<p>whether the samples should be L2-normalized or not.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code><a href="#topic+fdata">fdata</a></code> object with the sampled directions.
</p>


<h3>Author(s)</h3>

<p>Eduardo Garcia-Portugues (<a href="mailto:edgarcia@est-econ.uc3m.es">edgarcia@est-econ.uc3m.es</a>) and
Manuel Febrero-Bande (<a href="mailto:manuel.febrero@usc.es">manuel.febrero@usc.es</a>).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Simulate some data
set.seed(345673)
X.fdata &lt;- r.ou(n = 200, mu = 0, alpha = 1, sigma = 2, t = seq(0, 1, l = 201), 
                x0 = rep(0, 200))
pc &lt;- fdata2pc(X.fdata, ncomp = 20)

# Samples
set.seed(34567)
rdir.pc(n = 5, X.fdata = X.fdata, zero.mean = FALSE)$data[, 1:5]
set.seed(34567)
rdir.pc(n = 5, X.fdata = X.fdata, fdata2pc.obj = pc)$data[, 1:5]

# Comparison for the variance type
set.seed(456732)
n.proj &lt;- 100
set.seed(456732)
samp1 &lt;- rdir.pc(n = n.proj, X.fdata = X.fdata, sd = 1, norm = FALSE, ncomp = 0.99)
set.seed(456732)
samp2 &lt;- rdir.pc(n = n.proj, X.fdata = X.fdata, sd = 0, norm = FALSE, ncomp = 0.99)
set.seed(456732)
samp3 &lt;- rdir.pc(n = n.proj, X.fdata = X.fdata, sd = 1, norm = TRUE, ncomp = 0.99)
set.seed(456732)
samp4 &lt;- rdir.pc(n = n.proj, X.fdata = X.fdata, sd = 0, norm = TRUE, ncomp = 0.99)
par(mfrow = c(1, 2))
plot(X.fdata, col = gray(0.85), lty = 1)
lines(samp1[1:10], col = 2, lty = 1)
lines(samp2[1:10], col = 4, lty = 1)
legend("topleft", legend = c("Data", "Different variances", "Equal variances"), 
       col = c(gray(0.85), 2, 4), lwd = 2)
plot(X.fdata, col = gray(0.85), lty = 1)
lines(samp3[1:10], col = 5, lty = 1)
lines(samp4[1:10], col = 6, lty = 1)
legend("topleft", legend = c("Data", "Different variances, normalized", 
       "Equal variances, normalized"), col = c(gray(0.85), 5:6), lwd = 2)

# Correlations (stronger with different variances and unnormalized; 
# stronger with lower ncomp)
ind &lt;- lower.tri(matrix(nrow = n.proj, ncol = n.proj))
median(abs(cor(sapply(1:n.proj, function(i) inprod.fdata(X.fdata, samp1[i]))))[ind])
median(abs(cor(sapply(1:n.proj, function(i) inprod.fdata(X.fdata, samp2[i]))))[ind])
median(abs(cor(sapply(1:n.proj, function(i) inprod.fdata(X.fdata, samp3[i]))))[ind])
median(abs(cor(sapply(1:n.proj, function(i) inprod.fdata(X.fdata, samp4[i]))))[ind])

# Comparison for the threshold
samp1 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.25, fdata2pc.obj = pc)
samp2 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.50, fdata2pc.obj = pc)
samp3 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.90, fdata2pc.obj = pc)
samp4 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.95, fdata2pc.obj = pc)
samp5 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.99, fdata2pc.obj = pc)
cols &lt;- rainbow(5, alpha = 0.25)
par(mfrow = c(3, 2))
plot(X.fdata, col = gray(0.75), lty = 1, main = "Data")
plot(samp1, col = cols[1], lty = 1, main = "Threshold = 0.25")
plot(samp2, col = cols[2], lty = 1, main = "Threshold = 0.50")
plot(samp3, col = cols[3], lty = 1, main = "Threshold = 0.90")
plot(samp4, col = cols[4], lty = 1, main = "Threshold = 0.95")
plot(samp5, col = cols[5], lty = 1, main = "Threshold = 0.99")

# Normalizing
samp1 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.50, fdata2pc.obj = pc,
                 norm = TRUE)
samp2 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.90, fdata2pc.obj = pc,
                 norm = TRUE)
samp3 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.95, fdata2pc.obj = pc,
                 norm = TRUE)
samp4 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.99, fdata2pc.obj = pc,
                 norm = TRUE)
samp5 &lt;- rdir.pc(n = 100, X.fdata = X.fdata, ncomp = 0.999, fdata2pc.obj = pc,
                 norm = TRUE)
cols &lt;- rainbow(5, alpha = 0.25)
par(mfrow = c(3, 2))
plot(X.fdata, col = gray(0.75), lty = 1, main = "Data")
plot(samp1, col = cols[1], lty = 1, main = "Threshold = 0.50")
plot(samp2, col = cols[2], lty = 1, main = "Threshold = 0.90")
plot(samp3, col = cols[3], lty = 1, main = "Threshold = 0.95")
plot(samp4, col = cols[4], lty = 1, main = "Threshold = 0.99")
plot(samp5, col = cols[5], lty = 1, main = "Threshold = 0.999")

## End(Not run)
</code></pre>

<hr>
<h2 id='rp.flm.statistic'>Statistics for testing the functional linear model using random projections</h2><span id='topic+rp.flm.statistic'></span>

<h3>Description</h3>

<p>Computes the Cramer-von Mises (CvM) and Kolmogorv-Smirnov (kS) statistics on
the projected process </p>
<p style="text-align: center;"><code class="reqn">T_{n,h}(u)=\frac{1}{n}\sum_{i=1}^n (Y_i-\langle
X_i,\hat \beta\rangle)1_{\{\langle X_i, h\rangle\leq u\}},</code>
</p>

<p>designed to test the goodness-of-fit of a functional linear model with
scalar response.
<code>NA</code>'s are not allowed neither in the functional covariate nor in the
scalar response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rp.flm.statistic(proj.X, residuals, proj.X.ord = NULL, F.code = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rp.flm.statistic_+3A_proj.x">proj.X</code></td>
<td>
<p>matrix of size <code>c(n, n.proj)</code> containing, for each
column, the projections of the functional data <code class="reqn">X_1,\ldots,X_n</code> into a
random direction <code class="reqn">h</code>. Not required if <code>proj.X.ord</code> is provided.</p>
</td></tr>
<tr><td><code id="rp.flm.statistic_+3A_residuals">residuals</code></td>
<td>
<p>the residuals of the fitted funtional linear model,
<code class="reqn">Y_i-\langle X_i,\hat \beta\rangle</code>.
Either a vector of length <code>n</code> (same residuals for all projections) or a
matrix of size <code>c(n.proj, n)</code> (each projection has an associated set
residuals).</p>
</td></tr>
<tr><td><code id="rp.flm.statistic_+3A_proj.x.ord">proj.X.ord</code></td>
<td>
<p>matrix containing the row permutations of <code>proj.X</code>
which rearranges them increasingly, for each column. So, for example
<code>proj.X[proj.X.ord[, 1], 1]</code> equals <code>sort(proj.X[, 1])</code>. If not
provided, it is computed internally.</p>
</td></tr>
<tr><td><code id="rp.flm.statistic_+3A_f.code">F.code</code></td>
<td>
<p>whether to use faster <code>FORTRAN</code> code or <code>R</code> code.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing: 
</p>
 
<ul>
<li> <p><code>list("statistic")</code>: a matrix of size <code>c(n.proj, 2)</code> with the the CvM (first column) and KS (second)
statistics, for the <code>n.proj</code> different projections.
</p>
</li>
<li> <p><code>list("proj.X.ord")</code>: the computed row permutations of <code>proj.X</code>,
useful for recycling in subsequent calls to <code>rp.flm.statistic</code> with the
same projections but different residuals.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Eduardo Garcia-Portugues (<a href="mailto:edgarcia@est-econ.uc3m.es">edgarcia@est-econ.uc3m.es</a>) and
Manuel Febrero-Bande (<a href="mailto:manuel.febrero@usc.es">manuel.febrero@usc.es</a>).
</p>


<h3>References</h3>

<p>Cuesta-Albertos, J.A., Garcia-Portugues, E., Febrero-Bande, M.
and Gonzalez-Manteiga, W. (2017). Goodness-of-fit tests for the functional
linear model based on randomly projected empirical processes.
arXiv:1701.08363. <a href="https://arxiv.org/abs/1701.08363">https://arxiv.org/abs/1701.08363</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Simulated example
set.seed(345678)
t &lt;- seq(0, 1, l = 101)
n &lt;- 100
X &lt;- r.ou(n = n, t = t)
beta0 &lt;- fdata(mdata = cos(2 * pi * t) - (t - 0.5)^2, argvals = t,
               rangeval = c(0,1))
Y &lt;- inprod.fdata(X, beta0) + rnorm(n, sd = 0.1)

# Linear model
mod &lt;- fregre.pc(fdataobj = X, y = Y, l = 1:3)

# Projections
proj.X1 &lt;- inprod.fdata(X, r.ou(n = 1, t = t))
proj.X2 &lt;- inprod.fdata(X, r.ou(n = 1, t = t))
proj.X12 &lt;- cbind(proj.X1, proj.X2)

# Statistics
t1 &lt;- rp.flm.statistic(proj.X = proj.X1, residuals = mod$residuals)
t2 &lt;- rp.flm.statistic(proj.X = proj.X2, residuals = mod$residuals)
t12 &lt;- rp.flm.statistic(proj.X = proj.X12, residuals = mod$residuals)
t1$statistic
t2$statistic
t12$statistic

# Recycling proj.X.ord
rp.flm.statistic(proj.X.ord = t1$proj.X.ord, residuals = mod$residuals)$statistic
t1$statistic

# Sort in the columns
cbind(proj.X12[t12$proj.X.ord[, 1], 1], proj.X12[t12$proj.X.ord[, 2], 2]) -
apply(proj.X12, 2, sort)

# FORTRAN and R code
rp.flm.statistic(proj.X = proj.X1, residuals = mod$residuals)$statistic -
rp.flm.statistic(proj.X = proj.X1, residuals = mod$residuals, 
                 F.code = FALSE)$statistic

# Matrix and vector residuals
rp.flm.statistic(proj.X = proj.X12, residuals = mod$residuals)$statistic
rp.flm.statistic(proj.X = proj.X12, 
                 residuals = rbind(mod$residuals, mod$residuals * 2))$statistic

## End(Not run)

</code></pre>

<hr>
<h2 id='rp.flm.test'>Goodness-of fit test for the functional linear model using random
projections</h2><span id='topic+rp.flm.test'></span>

<h3>Description</h3>

<p>Tests the composite null hypothesis of a Functional Linear Model with scalar
response (FLM), </p>
<p style="text-align: center;"><code class="reqn">H_0:\,Y=\langle
X,\beta\rangle+\epsilon\quad\mathrm{vs}\quad H_1:\,Y\neq\langle
X,\beta\rangle+\epsilon.</code>
</p>
<p> If <code class="reqn">\beta=\beta_0</code> is provided, then
the simple hypothesis <code class="reqn">H_0:\,Y=\langle X,\beta_0\rangle+\epsilon</code> is tested. The way of testing the null hypothesis
is via a norm (Cramer-von Mises or Kolmogorov-Smirnov) in the empirical
process indexed by the projections.
</p>
<p>No NA's are allowed neither in the functional covariate nor in the scalar
response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rp.flm.test(
  X.fdata,
  Y,
  beta0.fdata = NULL,
  B = 1000,
  n.proj = 10,
  est.method = "pc",
  p = NULL,
  p.criterion = "SICc",
  pmax = 20,
  type.basis = "bspline",
  projs = 0.95,
  verbose = TRUE,
  same.rwild = FALSE,
  seed = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rp.flm.test_+3A_x.fdata">X.fdata</code></td>
<td>
<p>functional observations in the class
<code><a href="#topic+fdata">fdata</a></code>.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_y">Y</code></td>
<td>
<p>scalar responses for the FLM. Must be a vector with the same number
of elements as functions are in <code>X.fdata</code>.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_beta0.fdata">beta0.fdata</code></td>
<td>
<p>functional parameter for the simple null hypothesis, in
the <code><a href="#topic+fdata">fdata</a></code> class. The <code>argvals</code> and
<code>rangeval</code> arguments of <code>beta0.fdata</code> must be the same of
<code>X.fdata</code>. If <code>beta0.fdata=NULL</code> (default), the function will test
for the composite null hypothesis.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_b">B</code></td>
<td>
<p>number of bootstrap replicates to calibrate the distribution of the
test statistic.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_n.proj">n.proj</code></td>
<td>
<p>vector with the number of projections to consider.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_est.method">est.method</code></td>
<td>
<p>Estimation method for <code class="reqn">\beta</code>, only used in the
composite case. There are three methods: 
</p>
 
<ul>
<li> <p><code>"pc"</code>: if <code>p</code> is given, then <code class="reqn">\beta</code> is estimated by
<code><a href="#topic+fregre.pc">fregre.pc</a></code>. Otherwise, <code>p</code> is chosen using <code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code> and the <code>p.criterion</code> criterion.
</p>
</li>
<li> <p><code>"pls"</code>: if <code>p</code> is given, <code class="reqn">\beta</code> is estimated by <code><a href="#topic+fregre.pls">fregre.pls</a></code>. 
Otherwise, <code>p</code> is chosen using <code><a href="#topic+fregre.pls.cv">fregre.pls.cv</a></code> and the <code>p.criterion</code> criterion.
</p>
</li>
<li> <p><code>"basis"</code>: if <code>p</code> is given, <code class="reqn">\beta</code> is estimated by <code><a href="#topic+fregre.basis">fregre.basis</a></code>. 
Otherwise, <code>p</code> is chosen using <code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code> and the <code>p.criterion</code> criterion. 
Both in <code><a href="#topic+fregre.basis">fregre.basis</a></code> and <code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code>, the same basis for
<code>basis.x</code> and <code>basis.b</code> is considered.
</p>
</li></ul>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_p">p</code></td>
<td>
<p>number of elements for the basis representation of
<code>beta0.fdata</code> and <code>X.fdata</code> with the <code>est.method</code> (only
composite hypothesis). If not supplied, it is estimated from the data.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_p.criterion">p.criterion</code></td>
<td>
<p>for <code>est.method</code> equal to <code>"pc"</code> or
<code>"pls"</code>, either <code>"SIC"</code>, <code>"SICc"</code> or one of the criterions
described in <code><a href="#topic+fregre.pc.cv">fregre.pc.cv</a></code>. For <code>"basis"</code> a value
for <code>type.CV</code> in <code><a href="#topic+fregre.basis.cv">fregre.basis.cv</a></code> such as
<code>GCV.S</code>.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_pmax">pmax</code></td>
<td>
<p>maximum size of the basis expansion to consider in when using
<code>p.criterion</code>.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_type.basis">type.basis</code></td>
<td>
<p>type of basis if <code>est.method = "basis"</code>.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_projs">projs</code></td>
<td>
<p>a <code><a href="#topic+fdata">fdata</a></code> object containing the random
directions employed to project <code>X.fdata</code>. If numeric, the convenient
value for <code>ncomp</code> in <code><a href="#topic+rdir.pc">rdir.pc</a></code>.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_verbose">verbose</code></td>
<td>
<p>whether to show or not information about the testing
progress.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_same.rwild">same.rwild</code></td>
<td>
<p>wether to employ the same wild bootstrap residuals for
different projections or not.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_seed">seed</code></td>
<td>
<p>seed to be employed with <code>set.seed</code> for initializing random projections.</p>
</td></tr>
<tr><td><code id="rp.flm.test_+3A_...">...</code></td>
<td>
<p>further arguments passed to <a href="fda.html#topic+create.basis">create.basis</a> (not
<code>rangeval</code> that is taken as the <code>rangeval</code> of <code>X.fdata</code>).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object with class <code>"htest"</code> whose underlying structure is a
list containing the following components: 
</p>

<ul>
<li> <p><code>p.values.fdr</code>: a matrix of size <code>c(n.proj, 2)</code>, containing
in each row the FDR p-values of the CvM and KS tests up to that projection.
</p>
</li>
<li> <p><code>proj.statistics</code>: a matrix of size <code>c(max(n.proj), 2)</code>
with the value of the test statistic on each projection.
</p>
</li>
<li> <p><code>boot.proj.statistics</code>: an array of size <code>c(max(n.proj), 2,
B)</code> with the values of the bootstrap test statistics for each projection.
</p>
</li>
<li> <p><code>proj.p.values</code>: a matrix of size <code>c(max(n.proj), 2)</code>.
</p>
</li>
<li> <p><code>method</code>: information about the test performed and the kind of
estimation performed.
</p>
</li>
<li> <p><code>B</code>: number of bootstrap replicates used.
</p>
</li>
<li> <p><code>n.proj</code>: number of projections specified.
</p>
</li>
<li> <p><code>projs</code>: random directions employed to project <code>X.fdata</code>.
</p>
</li>
<li> <p><code>type.basis</code>: type of basis for <code>est.method = "basis"</code>.
</p>
</li>
<li> <p><code>beta.est</code>: estimated functional parameter <code class="reqn">\hat \beta</code> in the composite hypothesis. For the simple hypothesis, <code>beta0.fdata</code>.
</p>
</li>
<li> <p><code>p</code>: number of basis elements considered for estimation of <code class="reqn">\beta</code>.
</p>
</li>
<li> <p><code>p.criterion</code>: criterion employed for selecting <code>p</code>.
</p>
</li>
<li> <p><code>data.name</code>: the character string &quot;Y = &lt;X, b&gt; + e&quot;.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Eduardo Garcia-Portugues (<a href="mailto:edgarcia@est-econ.uc3m.es">edgarcia@est-econ.uc3m.es</a>) and
Manuel Febrero-Bande (<a href="mailto:manuel.febrero@usc.es">manuel.febrero@usc.es</a>).
</p>


<h3>References</h3>

<p>Cuesta-Albertos, J.A., Garcia-Portugues, E., Febrero-Bande, M.
and Gonzalez-Manteiga, W. (2017). Goodness-of-fit tests for the functional
linear model based on randomly projected empirical processes.
arXiv:1701.08363. <a href="https://arxiv.org/abs/1701.08363">https://arxiv.org/abs/1701.08363</a>
</p>
<p>Garcia-Portugues, E., Gonzalez-Manteiga, W. and Febrero-Bande, M. (2014). A
goodness-of-fit test for the functional linear model with scalar response.
Journal of Computational and Graphical Statistics, 23(3), 761&ndash;778.
<a href="https://doi.org/10.1080/10618600.2013.812519">doi:10.1080/10618600.2013.812519</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Simulated example

set.seed(345678)
t &lt;- seq(0, 1, l = 101)
n &lt;- 100
X &lt;- r.ou(n = n, t = t, alpha = 2, sigma = 0.5)
beta0 &lt;- fdata(mdata = cos(2 * pi * t) - (t - 0.5)^2, argvals = t,
               rangeval = c(0,1))
Y &lt;- inprod.fdata(X, beta0) + rnorm(n, sd = 0.1)

# Test all cases
rp.flm.test(X.fdata = X, Y = Y, est.method = "pc")
rp.flm.test(X.fdata = X, Y = Y, est.method = "pls")
rp.flm.test(X.fdata = X, Y = Y, est.method = "basis", 
            p.criterion = fda.usc.devel::GCV.S)
rp.flm.test(X.fdata = X, Y = Y, est.method = "pc", p = 5)
rp.flm.test(X.fdata = X, Y = Y, est.method = "pls", p = 5)
rp.flm.test(X.fdata = X, Y = Y, est.method = "basis", p = 5)
rp.flm.test(X.fdata = X, Y = Y, beta0.fdata = beta0)

# Composite hypothesis: do not reject FLM
rp.test &lt;- rp.flm.test(X.fdata = X, Y = Y, est.method = "pc")
rp.test$p.values.fdr
pcvm.test &lt;- flm.test(X.fdata = X, Y = Y, est.method = "pc", B = 1e3,
                      plot.it = FALSE)
pcvm.test

# Estimation of beta
par(mfrow = c(1, 3))
plot(X, main = "X")
plot(beta0, main = "beta")
lines(rp.test$beta.est, col = 2)
lines(pcvm.test$beta.est, col = 3)
plot(density(Y), main = "Density of Y", xlab = "Y", ylab = "Density")
rug(Y)

# Simple hypothesis: do not reject beta = beta0
rp.flm.test(X.fdata = X, Y = Y, beta0.fdata = beta0)$p.values.fdr
flm.test(X.fdata = X, Y = Y, beta0.fdata = beta0, B = 1e3, plot.it = FALSE)

# Simple hypothesis: reject beta = beta0^2
rp.flm.test(X.fdata = X, Y = Y, beta0.fdata = beta0^2)$p.values.fdr
flm.test(X.fdata = X, Y = Y, beta0.fdata = beta0^2, B = 1e3, plot.it = FALSE)

# Tecator dataset

# Load data
data(tecator)
absorp &lt;- tecator$absorp.fdata
ind &lt;- 1:129 # or ind &lt;- 1:215
x &lt;- absorp[ind, ]
y &lt;- tecator$y$Fat[ind]

# Composite hypothesis
rp.tecat &lt;- rp.flm.test(X.fdata = x, Y = y, est.method = "pc")
pcvm.tecat &lt;- flm.test(X.fdata = x, Y = y, est.method = "pc", B = 1e3,
                       plot.it = FALSE)
rp.tecat$p.values.fdr[c(5, 10), ]
pcvm.tecat

# Simple hypothesis
zero &lt;- fdata(mdata = rep(0, length(x$argvals)), argvals = x$argvals,
              rangeval = x$rangeval)
rp.flm.test(X.fdata = x, Y = y, beta0.fdata = zero)
flm.test(X.fdata = x, Y = y, beta0.fdata = zero, B = 1e3)

# With derivatives
rp.tecat &lt;- rp.flm.test(X.fdata = fdata.deriv(x, 1), Y = y, est.method = "pc")
rp.tecat$p.values.fdr
rp.tecat &lt;- rp.flm.test(X.fdata = fdata.deriv(x, 2), Y = y, est.method = "pc")
rp.tecat$p.values.fdr

# AEMET dataset

# Load data
data(aemet)
wind.speed &lt;- apply(aemet$wind.speed$data, 1, mean)
temp &lt;- aemet$temp

# Remove the 5% of the curves with less depth (i.e. 4 curves)
par(mfrow = c(1, 1))
res.FM &lt;- depth.FM(temp, draw = TRUE)
qu &lt;- quantile(res.FM$dep, prob = 0.05)
l &lt;- which(res.FM$dep &lt;= qu)
lines(aemet$temp[l], col = 3)

# Data without outliers
wind.speed &lt;- wind.speed[-l]
temp &lt;- temp[-l]

# Composite hypothesis
rp.aemet &lt;- rp.flm.test(X.fdata = temp, Y = wind.speed, est.method = "pc")
pcvm.aemet &lt;- flm.test(X.fdata = temp, Y = wind.speed, B = 1e3,
                       est.method = "pc", plot.it = FALSE)
rp.aemet$p.values.fdr
apply(rp.aemet$p.values.fdr, 2, range)
pcvm.aemet

# Simple hypothesis
zero &lt;- fdata(mdata = rep(0, length(temp$argvals)), argvals = temp$argvals,
              rangeval = temp$rangeval)
flm.test(X.fdata = temp, Y = wind.speed, beta0.fdata = zero, B = 1e3,
         plot.it = FALSE)
rp.flm.test(X.fdata = temp, Y = wind.speed, beta0.fdata = zero)

## End(Not run)
</code></pre>

<hr>
<h2 id='rproc2fdata'>Simulate several random processes.</h2><span id='topic+rproc2fdata'></span>

<h3>Description</h3>

<p>Simulate Functional Data from different processes: Ornstein Uhlenbeck,
Brownian, Fractional Brownian, Gaussian or Exponential variogram.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rproc2fdata(
  n,
  t = NULL,
  mu = rep(0, length(t)),
  sigma = 1,
  par.list = list(scale = 1, theta = 0.2 * diff(rtt), H = 0.5),
  norm = FALSE,
  verbose = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rproc2fdata_+3A_n">n</code></td>
<td>
<p>Number of functional curves to be generated.</p>
</td></tr>
<tr><td><code id="rproc2fdata_+3A_t">t</code></td>
<td>
<p>Discretization points.</p>
</td></tr>
<tr><td><code id="rproc2fdata_+3A_mu">mu</code></td>
<td>
<p><code>vector</code> which specifies the trend values at the
discretization points, by default <code>mu</code>=<code class="reqn">\mu(t)=0</code>.  If <code>mu</code> is
a <code>fdata</code> class object, <code>t</code><code class="reqn">=</code><code>argvals(mu)</code>.</p>
</td></tr>
<tr><td><code id="rproc2fdata_+3A_sigma">sigma</code></td>
<td>
<p>A positive-definite symmetric matrix,
<code class="reqn">\Sigma_{s,t}</code>, specifying the covariance matrix among grid
points.  If <code>sigma</code> is a <code>scalar</code>, creates a random Gaussian
process with <code class="reqn">\Sigma_{s,t}=</code><code>sigmaI</code> (by default
<code>sigma=1</code>).<br /> If <code>sigma</code> is a <code>vector</code>, creates a random
Gaussian process with <code class="reqn">\Sigma_{s,t}=</code><code>diag(sigma)</code>.<br /> If
<code>sigma</code> is a character: create a random process using the covariance
matrix <code class="reqn">\Sigma_{s,t}</code> indicated in the argument, </p>
 <ul>
<li>
<p><code>"OU"</code> or <code>"OrnsteinUhlenbeck"</code>, creates a random Ornstein
Uhlenbeck process with
<code class="reqn">\Sigma_{s,t}=\frac{\sigma^2}{2\theta}e^{-\theta\left(s+t\right)}
\left(e^{2\theta\left(s+t\right)}-1\right)</code>, by default
<code class="reqn">\theta=1/(3range(t))</code>,
<code class="reqn">\sigma^2={1}</code>.  </p>
</li>
<li> <p><code>"brownian"</code> or <code>"wiener"</code>,
creates a random Wiener process with <code class="reqn">\Sigma_{s,t}=\sigma^2
min(s,t)</code>, by default
<code class="reqn">\sigma^2=1</code>. </p>
</li>
<li> <p><code>"fbrownian"</code>, creates a random
fractional brownian process with
<code class="reqn">\Sigma_{s,t}=\sigma^{2H}/2{|s|^{2H}+|t|^{2H}-|s-t|^{2H}}</code>,
by default <code class="reqn">\sigma^2=1</code> and <code class="reqn">H=0.5</code> (brownian
process).  </p>
</li>
<li> <p><code>"vexponential"</code>, creates a random gaussian process
with exponential variogram <code class="reqn">\Sigma_{s,t}=\sigma^2
e^{\left(-\frac{\left|s-t\right|}{\theta}\right)}</code>, by default <code class="reqn">\theta={0.2
range(t)}</code>, <code class="reqn">\sigma^2={1}</code>. </p>
</li></ul>
</td></tr>
<tr><td><code id="rproc2fdata_+3A_par.list">par.list</code></td>
<td>
<p>List of parameter to process, by default <code>"scale"</code>
<code class="reqn">\sigma^2=1</code>, <code>"theta"</code> <code class="reqn">\theta=0.2
range(t)</code> and <code>"H"</code>=0.5.</p>
</td></tr>
<tr><td><code id="rproc2fdata_+3A_norm">norm</code></td>
<td>
<p>If <code>TRUE</code> the norm of random projection is 1. Default is
<code>FALSE</code></p>
</td></tr>
<tr><td><code id="rproc2fdata_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, information about procedure is printed.
Default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="rproc2fdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Return the functional random processes as a <code>fdata</code> class
object.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
par(mfrow=c(3,2))
lent&lt;-30
tt&lt;-seq(0,1,len=lent)
mu&lt;-fdata(rep(0,lent),tt)
plot(rproc2fdata(200,t=tt,sigma="OU",par.list=list("scale"=1)))
plot(rproc2fdata(200,mu=mu,sigma="OU",par.list=list("scale"=1)))
plot(rproc2fdata(200,t=tt,sigma="vexponential"))
plot(rproc2fdata(200,t=tt,sigma=1:lent))
plot(rproc2fdata(200,t=tt,sigma="brownian"))
plot(rproc2fdata(200,t=tt,sigma="wiener"))
#plot(rproc2fdata(200,seq(0,1,len=30),sigma="oo")) # this is an error 

## End(Not run)

</code></pre>

<hr>
<h2 id='rwild'>Wild bootstrap residuals</h2><span id='topic+rwild'></span>

<h3>Description</h3>

<p>The wild bootstrap residuals are computed as <code class="reqn">residuals*V</code>, where <code class="reqn">V</code> is a sampling from a random variable (see details section).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rwild(residuals, type = "golden")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rwild_+3A_residuals">residuals</code></td>
<td>
<p>residuals</p>
</td></tr>
<tr><td><code id="rwild_+3A_type">type</code></td>
<td>
<p>Type of distribution of V.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For the construction of wild bootstrap residuals, sampling from a random variable <code class="reqn">V</code> such that <code class="reqn">E[V^2]=0</code> and <code class="reqn">E[V]=0</code> is needed. 
A simple and suitable <code class="reqn">V</code> is obtained with a discrete variable of the form:
</p>

<ul>
<li><p> &ldquo;golden&rdquo;, Sampling from golden section bootstrap values suggested by Mammen (1993).
</p>
<p style="text-align: center;"><code class="reqn">P\Bigg\{ V=\frac{1-\sqrt{5}}{2} \Bigg\} = \frac{5+\sqrt{5}}{10} \, and \, P\Bigg\{ V=\frac{1+\sqrt{5}}{2} \Bigg\} = \frac{5-\sqrt{5}}{10},</code>
</p>

<p>which leads to the <em>golden section bootstrap</em>.  
</p>
</li>
<li><p> &ldquo;Rademacher&rdquo;, Sampling from Rademacher distribution values
<code class="reqn">\big\{-1,\,1\big\}</code> with probabilities <code class="reqn">\big\{\frac{1}{2},\,\frac{1}{2}\big\}</code>, respectively.  
</p>
</li>
<li><p> &ldquo;normal&rdquo;, Sampling from a standard normal distribution.
</p>
</li></ul>



<h3>Value</h3>

<p>The wild bootstrap residuals computed using a sample of the random variable <code class="reqn">V</code>.
</p>


<h3>Author(s)</h3>

<p>Eduardo Garcia-Portugues, Manuel Febrero-Bande and  Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>.
</p>


<h3>References</h3>

<p>Mammen, E. (1993). <em>Bootstrap and wild bootstrap for high dimensional linear models</em>.
Annals of Statistics 21, 255 285.
Davidson, R. and E. Flachaire (2001). <em>The wild bootstrap, tamed at last</em>. working paper IER1000, Queens University.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+flm.test">flm.test</a></code>, <code><a href="#topic+flm.Ftest">flm.Ftest</a></code>, <code><a href="#topic+dfv.test">dfv.test</a></code>, <code><a href="#topic+fregre.bootstrap">fregre.bootstrap</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>n&lt;-100
# For golden wild bootstrap variable
e.boot0=rwild(rep(1,len=n),"golden")
# Construction of wild bootstrap residuals
e=rnorm(n)
e.boot1=rwild(e,"golden")
e.boot2=rwild(e,"Rademacher")
e.boot3=rwild(e,"normal")
summary(e.boot1)
summary(e.boot2)
summary(e.boot3)
             
</code></pre>

<hr>
<h2 id='S.basis'>Smoothing matrix with roughness penalties by basis representation.</h2><span id='topic+S.basis'></span>

<h3>Description</h3>

<p>Provides the smoothing matrix <code>S</code> with roughness penalties.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>S.basis(tt, basis, lambda = 0, Lfdobj = vec2Lfd(c(0, 0)), w = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="S.basis_+3A_tt">tt</code></td>
<td>
<p>Discretization points.</p>
</td></tr>
<tr><td><code id="S.basis_+3A_basis">basis</code></td>
<td>
<p>Basis to use. See <a href="fda.html#topic+create.basis">create.basis</a>.</p>
</td></tr>
<tr><td><code id="S.basis_+3A_lambda">lambda</code></td>
<td>
<p>A roughness penalty. By default, no penalty <code>lambda</code>=0.</p>
</td></tr>
<tr><td><code id="S.basis_+3A_lfdobj">Lfdobj</code></td>
<td>
<p>See <a href="fda.html#topic+eval.penalty">eval.penalty</a>.</p>
</td></tr>
<tr><td><code id="S.basis_+3A_w">w</code></td>
<td>
<p>Optional case weights.</p>
</td></tr>
<tr><td><code id="S.basis_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods. Arguments to
be passed by default to <a href="fda.html#topic+create.basis">create.basis</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Provides the smoothing matrix S for the discretization points <code>tt</code> and
b<code>basis</code> with roughness penalties. If <code>lambda=0</code> is not used
penalty, else a basis roughness penalty matrix is caluclated using
<a href="fda.html#topic+getbasispenalty">getbasispenalty</a>.
</p>


<h3>Value</h3>

<p>Return the smoothing matrix <code>S</code>.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O. and Silverman, Bernard W. (2006). <em> Functional Data
Analysis</em>, 2nd ed., Springer, New York.
</p>
<p>Wasserman, L. <em>All of Nonparametric Statistics</em>. Springer Texts in
Statistics, 2006.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+S.np">S.np</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
np=101
tt=seq(0,1,len=np)

nbasis=11
base1 &lt;- create.bspline.basis(c(0, np), nbasis)
base2 &lt;- create.fourier.basis(c(0, np), nbasis)

S1&lt;-S.basis(tt,basis=base1,lambda=3)
image(S1) 
S2&lt;-S.basis(tt,basis=base2,lambda=3)
image(S2)

## End(Not run)
</code></pre>

<hr>
<h2 id='S.np'>Smoothing matrix by nonparametric methods</h2><span id='topic+S.np'></span><span id='topic+S.LLR'></span><span id='topic+S.KNN'></span><span id='topic+S.LPR'></span><span id='topic+S.LCR'></span><span id='topic+S.NW'></span>

<h3>Description</h3>

<p>Provides the smoothing matrix <code>S</code> for the discretization points <code>tt</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>S.LLR(tt, h, Ker = Ker.norm, w = NULL, cv = FALSE)

S.LPR(tt, h, p = 1, Ker = Ker.norm, w = NULL, cv = FALSE)

S.LCR(tt, h, Ker = Ker.norm, w = NULL, cv = FALSE)

S.KNN(tt, h = NULL, Ker = Ker.unif, w = NULL, cv = FALSE)

S.NW(tt, h = NULL, Ker = Ker.norm, w = NULL, cv = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="S.np_+3A_tt">tt</code></td>
<td>
<p>Vector of discretization points or distance matrix <code>mdist</code></p>
</td></tr>
<tr><td><code id="S.np_+3A_h">h</code></td>
<td>
<p>Smoothing parameter or bandwidth. In S.KNN, number of k-nearest neighbors.</p>
</td></tr>
<tr><td><code id="S.np_+3A_ker">Ker</code></td>
<td>
<p>Type of kernel used, by default normal kernel.</p>
</td></tr>
<tr><td><code id="S.np_+3A_w">w</code></td>
<td>
<p>Optional case weights.</p>
</td></tr>
<tr><td><code id="S.np_+3A_cv">cv</code></td>
<td>
<p>If <code>TRUE</code>, cross-validation is done.</p>
</td></tr>
<tr><td><code id="S.np_+3A_p">p</code></td>
<td>
<p>Polynomial degree.
be passed by default to <a href="fda.html#topic+create.basis">create.basis</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>Options: 
</p>

<ul>
<li> <p><code>S.NW</code>: Nadaraya-Watson kernel estimator with bandwidth parameter <code>h</code>.
</p>
</li>
<li> <p><code>S.LLR</code>: Local Linear Smoothing with bandwidth parameter <code>h</code>.
</p>
</li>
<li> <p><code>S.KNN</code>: K nearest neighbors estimator with parameter <code>knn</code>.
</p>
</li>
<li> <p><code>S.LPR</code>: Polynomial Local Regression Estimator with parameter of polynomial <code>p</code> and of kernel <code>Ker</code>.
</p>
</li>
<li> <p><code>S.LCR</code>: Local Cubic Regression Estimator with kernel <code>Ker</code>.
</p>
</li></ul>



<h3>Value</h3>

<p>Return the smoothing matrix <code>S</code>.
</p>

<ul>
<li> <p><code>S.LLR</code>: Local Linear Smoothing.
</p>
</li>
<li> <p><code>S.NW</code>:  Nadaraya-Watson kernel estimator.
</p>
</li>
<li> <p><code>S.KNN</code>: k nearest neighbors estimator.
</p>
</li>
<li> <p><code>S.LPR</code>: Local Polynomial Regression Estimator.
</p>
</li>
<li> <p><code>S.LCR</code>: Cubic Polynomial Regression.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional data analysis.</em> Springer Series in Statistics, New York. 
</p>
<p>Wasserman, L. <em>All of Nonparametric Statistics</em>. Springer Texts in Statistics, 2006.
</p>
<p>Opsomer, J. D., and Ruppert, D. (1997). Fitting a bivariate additive model by local polynomial regression. <em>The Annals of Statistics</em>, 25(1), 186-211.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+S.basis">S.basis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  tt &lt;- 1:101
  S &lt;- S.LLR(tt,h=5)
  S2 &lt;- S.LLR(tt,h=10,Ker=Ker.tri)
  S3 &lt;- S.NW(tt,h=10,Ker=Ker.tri)
  S4 &lt;- S.KNN(tt,h=5,Ker=Ker.tri)
  par(mfrow=c(2,3))
  image(S)
  image(S2)
  image(S3)
  image(S4)
  S5 &lt;- S.LPR(tt,h=10,p=1, Ker=Ker.tri)
  S6 &lt;- S.LCR(tt,h=10,Ker=Ker.tri)
  image(S5)
  image(S6)

## End(Not run)
</code></pre>

<hr>
<h2 id='semimetric.basis'>Proximities between functional data</h2><span id='topic+semimetric.basis'></span>

<h3>Description</h3>

<p>Approximates semi-metric distances for functional data of class <code>fdata</code>
or <code>fd</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimetric.basis(
  fdata1,
  fdata2 = fdata1,
  nderiv = 0,
  type.basis1 = NULL,
  nbasis1 = NULL,
  type.basis2 = type.basis1,
  nbasis2 = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="semimetric.basis_+3A_fdata1">fdata1</code></td>
<td>
<p>Functional data 1 or curve 1.</p>
</td></tr>
<tr><td><code id="semimetric.basis_+3A_fdata2">fdata2</code></td>
<td>
<p>Functional data 2 or curve 2.</p>
</td></tr>
<tr><td><code id="semimetric.basis_+3A_nderiv">nderiv</code></td>
<td>
<p>Order of derivation, used in <code>deriv.fd</code></p>
</td></tr>
<tr><td><code id="semimetric.basis_+3A_type.basis1">type.basis1</code></td>
<td>
<p>Type of Basis for <code>fdata1</code>.</p>
</td></tr>
<tr><td><code id="semimetric.basis_+3A_nbasis1">nbasis1</code></td>
<td>
<p>Number of Basis for <code>fdata1</code>.</p>
</td></tr>
<tr><td><code id="semimetric.basis_+3A_type.basis2">type.basis2</code></td>
<td>
<p>Type of Basis for <code>fdata2</code>.</p>
</td></tr>
<tr><td><code id="semimetric.basis_+3A_nbasis2">nbasis2</code></td>
<td>
<p>Number of Basis for <code>fdata2.</code></p>
</td></tr>
<tr><td><code id="semimetric.basis_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Approximates semi-metric distances for functional data of two <code>fd</code>
class objects.  If functional data are not functional <code>fd</code> class, the
<code>semimetric.basis</code> function creates a basis to represent the functional
data, by default is used <a href="fda.html#topic+create.bspline.basis">create.bspline.basis</a> and the
<code>fdata</code> class object is converted to <code>fd</code> class using the
<a href="fda.html#topic+Data2fd">Data2fd</a>.<br /> The function calculates distances between the
derivative of order <code>nderiv</code> of curves using <a href="fda.html#topic+deriv.fd">deriv.fd</a>
function.
</p>


<h3>Value</h3>

<p>Returns a proximities matrix between functional data.
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+metric.lp">metric.lp</a></code>, <code><a href="#topic+semimetric.NPFDA">semimetric.NPFDA</a></code>
and <a href="fda.html#topic+deriv.fd">deriv.fd</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(phoneme)
DATA1&lt;-phoneme$learn[c(30:50,210:230)]
DATA2&lt;-phoneme$test[231:250]
a1=semimetric.basis(DATA1,DATA2)
a2=semimetric.basis(DATA1,DATA2,type.basis1="fourier",
nbasis1=11, type.basis2="fourier",nbasis2=11)
fd1 &lt;- fdata2fd(DATA1)
fd2 &lt;- fdata2fd(DATA2)
a3=semimetric.basis(fd1,fd2)
a4=semimetric.basis(fd1,fd2,nderiv=1)

## End(Not run)

</code></pre>

<hr>
<h2 id='semimetric.NPFDA'>Proximities between functional data (semi-metrics)</h2><span id='topic+semimetric.NPFDA'></span><span id='topic+semimetric.deriv'></span><span id='topic+semimetric.fourier'></span><span id='topic+semimetric.hshift'></span><span id='topic+semimetric.mplsr'></span><span id='topic+semimetric.pca'></span>

<h3>Description</h3>

<p>Computes semi-metric distances of functional data based on Ferraty F and
Vieu, P. (2006).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>semimetric.deriv(
  fdata1,
  fdata2 = fdata1,
  nderiv = 1,
  nknot = ifelse(floor(ncol(DATA1)/3) &gt; floor((ncol(DATA1) - nderiv - 4)/2),
    floor((ncol(DATA1) - nderiv - 4)/2), floor(ncol(DATA1)/3)),
  ...
)

semimetric.fourier(
  fdata1,
  fdata2 = fdata1,
  nderiv = 0,
  nbasis = ifelse(floor(ncol(DATA1)/3) &gt; floor((ncol(DATA1) - nderiv - 4)/2),
    floor((ncol(DATA1) - nderiv - 4)/2), floor(ncol(DATA1)/3)),
  period = NULL,
  ...
)

semimetric.hshift(fdata1, fdata2 = fdata1, t = 1:ncol(DATA1), ...)

semimetric.mplsr(fdata1, fdata2 = fdata1, q = 2, class1, ...)

semimetric.pca(fdata1, fdata2 = fdata1, q = 1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="semimetric.NPFDA_+3A_fdata1">fdata1</code></td>
<td>
<p>Functional data 1 or curve 1. <code>DATA1</code> with dimension
(<code>n1</code> x <code>m</code>), where <code>n1</code> is the number of curves and <code>m</code>
are the points observed in each curve.</p>
</td></tr>
<tr><td><code id="semimetric.NPFDA_+3A_fdata2">fdata2</code></td>
<td>
<p>Functional data 2 or curve 2. <code>DATA1</code> with dimension
(<code>n2</code> x <code>m</code>), where <code>n2</code> is the number of curves and <code>m</code>
are the points observed in each curve.</p>
</td></tr>
<tr><td><code id="semimetric.NPFDA_+3A_nderiv">nderiv</code></td>
<td>
<p>Order of derivation, used in <code>semimetric.deriv</code> and <br />
<code>semimetric.fourier</code></p>
</td></tr>
<tr><td><code id="semimetric.NPFDA_+3A_nknot">nknot</code></td>
<td>
<p>semimetric.deriv argument: number of interior knots (needed for
defining the B-spline basis).</p>
</td></tr>
<tr><td><code id="semimetric.NPFDA_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="semimetric.NPFDA_+3A_nbasis">nbasis</code></td>
<td>
<p><code>semimetric.fourier</code>: size of the basis.</p>
</td></tr>
<tr><td><code id="semimetric.NPFDA_+3A_period">period</code></td>
<td>
<p><code>semimetric.fourier</code>:allows to select the period for the
fourier expansion.</p>
</td></tr>
<tr><td><code id="semimetric.NPFDA_+3A_t">t</code></td>
<td>
<p><code>semimetric.hshift</code>: vector which defines <code>t</code> (one can
choose <code>1,2,...,nbt</code> where <code>nbt</code> is the number of points of the
discretization)</p>
</td></tr>
<tr><td><code id="semimetric.NPFDA_+3A_q">q</code></td>
<td>
<p>If <code>semimetric.pca</code>: the retained number of principal
components.<br /> If <code>semimetric.mplsr</code>: the retained number of factors.</p>
</td></tr>
<tr><td><code id="semimetric.NPFDA_+3A_class1">class1</code></td>
<td>
<p><code>semimetric.mplsr</code>: vector containing a categorical
response which corresponds to class number for units stored in <code>DATA1</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>semimetric.deriv</code>: approximates <code class="reqn">L_2</code> metric
between derivatives of the curves based on ther B-spline representation. The
derivatives set with the argument <code>nderiv</code>.<br />
<code>semimetric.fourier</code>: approximates <code class="reqn">L_2</code> metric between the curves
based on ther B-spline representation. The derivatives set with the argument
<code>nderiv</code>.<br /> <code>semimetric.hshift</code>: computes distance between curves
taking into account an horizontal shift effect.<br /> <code>semimetric.mplsr</code>:
computes distance between curves based on the partial least squares
method.<br /> <code>semimetric.pca</code>: computes distance between curves based on
the functional principal components analysis method.
</p>
<p>In the next semi-metric functions the functional data <code class="reqn">X</code> is
approximated by <code class="reqn">k_n</code> elements of the Fourier, B&ndash;spline, PC or PLS basis
using, <code class="reqn">\hat{X_i} =\sum_{k=1}^{k_n}\nu_{k,i}\xi_k</code>, where <code class="reqn">\nu_k</code>
are the coefficient of the expansion on the basis function
<code class="reqn">\left\{\xi_k\right\}_{k=1}^{\infty}</code>.<br /> The distances between the q-order derivatives of two curves <code class="reqn">X_{1}</code> and
<code class="reqn">X_2</code> is,
</p>
<p style="text-align: center;"><code class="reqn">d_{2}^{(q)}\left(X_1,X_2\right)_{k_n}=\sqrt{\frac{1}{T}\int_{T}\left(X_{1}^{(q)}(t)-X_{2}^{(q)}(t)\right)^2
dt}</code>
</p>
<p> where <code class="reqn">X_{i}^{(q)}\left(t\right)</code> denot the <code class="reqn">q</code> derivative of
<code class="reqn">X_i</code>.
</p>
<p><code>semimetric.deriv</code> and <code>semimetric.fourier</code> function use a
B-spline and Fourier approximation respectively for each curve and the
derivatives are directly computed by differentiating several times their
analytic form, by default <code>q=1</code> and <code>q=0</code> respectively.
<code>semimetric.pca</code> and <code>semimetric.mprls</code> function compute
proximities between curves based on the functional principal components
analysis (FPCA) and the functional partial least square analysis (FPLS),
respectively. The FPC and FPLS reduce the functional data in a reduced
dimensional space (q components). <code>semimetric.mprls</code> function requires
a scalar response.
</p>
<p style="text-align: center;"><code class="reqn">d_{2}^{(q)}\left(X_1,X_2\right)_{k_n}\approx\sqrt{\sum_{k=1}^{k_n}\left(\nu_{k,1}-\nu_{k,2}\right)^2\left\|\xi_k^{(q)}\right\|dt}</code>
</p>

<p><code>semimetric.hshift</code> computes proximities between curves taking into
account an horizontal shift effect.
</p>
<p style="text-align: center;"><code class="reqn">d_{hshift}\left(X_1,X_2\right)=\min_{h\in\left[-mh,mh\right]}d_2(X_1(t),X_2(t+h))</code>
</p>

<p>where <code class="reqn">mh</code> is the maximum horizontal shifted allowed.
</p>


<h3>Value</h3>

<p>Returns a proximities matrix between two functional datasets.
</p>


<h3>Source</h3>

<p><a href="https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/">https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/</a>
</p>


<h3>References</h3>

<p>Ferraty, F. and Vieu, P. (2006). <em>Nonparametric functional
data analysis.</em> Springer Series in Statistics, New York.
</p>
<p>Ferraty, F. and Vieu, P. (2006). <em>NPFDA in practice</em>.  Free access on
line at <a href="https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/">https://www.math.univ-toulouse.fr/~ferraty/SOFTWARES/NPFDA/</a>
</p>


<h3>See Also</h3>

<p>See also <code><a href="#topic+metric.lp">metric.lp</a></code> and <code><a href="#topic+semimetric.basis">semimetric.basis</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
#	INFERENCE PHONDAT
data(phoneme)
ind=1:100 # 2 groups
mlearn&lt;-phoneme$learn[ind,]
mtest&lt;-phoneme$test[ind,]
n=nrow(mlearn[["data"]])
np=ncol(mlearn[["data"]])
mdist1=semimetric.pca(mlearn,mtest)
mdist2=semimetric.pca(mlearn,mtest,q=2)
mdist3=semimetric.deriv(mlearn,mtest,nderiv=0)
mdist4=semimetric.fourier(mlearn,mtest,nderiv=2,nbasis=21)
#uses hshift function
#mdist5=semimetric.hshift(mlearn,mtest) #takes a lot
glearn&lt;-phoneme$classlearn[ind]
#uses mplsr function
mdist6=semimetric.mplsr(mlearn,mtest,5,glearn)
mdist0=metric.lp(mlearn,mtest)
b=as.dist(mdist6)
c2=hclust(b)
plot(c2)
memb &lt;- cutree(c2, k = 2)
table(memb,phoneme$classlearn[ind])
 
## End(Not run) 
  
</code></pre>

<hr>
<h2 id='subset.fdata'>Subsetting</h2><span id='topic+subset.fdata'></span>

<h3>Description</h3>

<p>Return subsets of <code>fdata</code> which meet conditions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fdata'
subset(x, subset, select, drop = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="subset.fdata_+3A_x">x</code></td>
<td>
<p>object to be subsetted (<code>fdata</code> class).</p>
</td></tr>
<tr><td><code id="subset.fdata_+3A_subset">subset</code></td>
<td>
<p>logical expression indicating elements or rows to keep.</p>
</td></tr>
<tr><td><code id="subset.fdata_+3A_select">select</code></td>
<td>
<p>logical expression indicating points or columns to keep.</p>
</td></tr>
<tr><td><code id="subset.fdata_+3A_drop">drop</code></td>
<td>
<p>passed on to <code>[</code> indexing operator.</p>
</td></tr>
<tr><td><code id="subset.fdata_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object similar to <code>x</code> contain just the selected elements.
</p>


<h3>See Also</h3>

<p>See <code><a href="base.html#topic+subset">subset</a></code> and <code><a href="#topic+fdata">fdata</a></code>.
</p>

<hr>
<h2 id='summary.classif'>Summarizes information from kernel classification methods.</h2><span id='topic+summary.classif'></span><span id='topic+print.classif'></span>

<h3>Description</h3>

<p>Summary function for <code><a href="#topic+classif.knn">classif.knn</a></code> or <code><a href="#topic+classif.kernel">classif.kernel</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'classif'
summary(object, ...)

## S3 method for class 'classif'
print(x, digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.classif_+3A_object">object</code></td>
<td>
<p>Estimated by kernel classification.</p>
</td></tr>
<tr><td><code id="summary.classif_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
<tr><td><code id="summary.classif_+3A_x">x</code></td>
<td>
<p>Estimated by kernel classification.</p>
</td></tr>
<tr><td><code id="summary.classif_+3A_digits">digits</code></td>
<td>
<p>how many significant digits are to be used for numeric and complex x.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>object</code> from <code><a href="#topic+classif.knn">classif.knn</a></code> or <code><a href="#topic+classif.kernel">classif.kernel</a></code>
</p>


<h3>Value</h3>

<p>Shows:
</p>
 
<ul>
<li><p> -Probability of correct classification by group <code>prob.classification</code>.
</p>
</li>
<li><p> -Confusion matrix between the theoretical groups and estimated groups.
</p>
</li>
<li><p> -Highest probability of correct classification <code>max.prob</code>. 
</p>
</li></ul>

<p>If the object is returned from the function <code><a href="#topic+classif.knn">classif.knn</a></code>
</p>
 
<ul>
<li><p> -Vector of probability of correct classification by number of neighbors <code>knn</code>.
</p>
</li>
<li><p>  -Optimal number of neighbors: <code>knn.opt</code>. 
</p>
</li></ul>

<p>If the object is returned from the function: <code><a href="#topic+classif.kernel">classif.kernel</a></code>
</p>
 
<ul>
<li><p> -Vector of probability of correct classification by banwidth <code>h</code>.
</p>
</li>
<li><p>  -Functional measure of closeness (optimal distance, <code>h.opt</code>). 
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>See Also as: <code><a href="#topic+classif.knn">classif.knn</a></code>,
<code><a href="#topic+classif.kernel">classif.kernel</a></code> <br /> and <code><a href="#topic+summary.classif">summary.classif</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run:  
data(phoneme)
mlearn&lt;-phoneme[["learn"]]
glearn&lt;-phoneme[["classlearn"]]
out=classif.knn(glearn,mlearn,knn=c(3,5,7))
summary(out)
out2=classif.kernel(glearn,mlearn,h=2^(0:5))
summary(out2)

## End(Not run)
</code></pre>

<hr>
<h2 id='summary.fdata.comp'>Correlation for functional data by Principal Component Analysis</h2><span id='topic+summary.fdata.comp'></span>

<h3>Description</h3>

<p>Summary of functional principal components
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fdata.comp'
summary(object, biplot = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.fdata.comp_+3A_object">object</code></td>
<td>
<p>fdata.comp class object calculated by: <code>fdata2pc</code>,
<code>fdata2pls</code>, <code>fregre.pc</code> or <code>fregre.pls</code>.</p>
</td></tr>
<tr><td><code id="summary.fdata.comp_+3A_biplot">biplot</code></td>
<td>
<p>=TRUE draw the biplot and PC (or PLS) components.</p>
</td></tr>
<tr><td><code id="summary.fdata.comp_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>corplot</code>=TRUE, are displaying the biplot between the PC (or PLS) components.<br />
If <code>ask</code>=TRUE, draw each graph in a window, waiting to confirm the change
of page with a click of the mouse or pressing ENTER.  If <code>ask</code>=FALSE draw graphs in one window.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande and Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Becker, R. A., Chambers, J. M. and Wilks, A. R. (1988).
<em>The New S Language</em>. Wadsworth &amp; Brooks/Cole.
</p>
<p>Venables, W. N. and B. D. Ripley (2002). <em>Modern Applied Statistics
with S</em>. Springer-Verlag.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+fdata2pc">fdata2pc</a></code>, <code><a href="#topic+fdata2pls">fdata2pls</a></code> and <a href="stats.html#topic+cor">cor</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(fda.usc)
n &lt;- 200
tt &lt;- seq(0,1,len=101)
x0 &lt;- rproc2fdata(n,tt,sigma="wiener")
x1 &lt;- rproc2fdata(n,tt,sigma=0.1)
x &lt;- x0*3+x1
beta &lt;- tt*sin(2*pi*tt)^2
fbeta &lt;- fdata(beta,tt)
pc1 &lt;- fdata2pc(x,3)
summary.fdata.comp(pc1)
y &lt;- inprod.fdata(x,fbeta) #+ rnorm(n,sd=0.1)
pls1 &lt;- fdata2pls(x,y,2)
summary(pls1)

## End(Not run)

</code></pre>

<hr>
<h2 id='summary.fregre.fd'>Summarizes information from fregre.fd objects.</h2><span id='topic+summary.fregre.fd'></span><span id='topic+summary.fregre.lm'></span><span id='topic+plot.summary.lm'></span><span id='topic+summary.fregre.igls'></span><span id='topic+print.fregre.igls'></span><span id='topic+print.fregre.plm'></span><span id='topic+print.fregre.fd'></span>

<h3>Description</h3>

<p>Summary function for <code><a href="#topic+fregre.pc">fregre.pc</a></code>, <code><a href="#topic+fregre.basis">fregre.basis</a></code>,
<code><a href="#topic+fregre.pls">fregre.pls</a></code>, <code><a href="#topic+fregre.np">fregre.np</a></code><br /> and
<code><a href="#topic+fregre.plm">fregre.plm</a></code> functions.
</p>
<p>Shows:<br /> </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Call.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -R squared.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Residual
variance.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Index of possible atypical curves or possible
outliers.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Index of possible influence curves.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>
<p> If the
<code>fregre.fd</code> object comes from the <code><a href="#topic+fregre.pc">fregre.pc</a></code> then shows:
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Variability of explicative variables explained by
Principal Components.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Variability for each principal components
-PC-.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>If draw=TRUE plot: <br /> </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -y vs y fitted values.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
-Residuals vs fitted values.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Standarized residuals vs fitted
values.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Levarage.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Residual boxplot.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
-Quantile-Quantile Plot (qqnorm).</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>
<p> If <code>ask</code>=FALSE draw graphs in
one window, by default. If <code>ask</code>=TRUE, draw each graph in a window,
waiting to confirm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fregre.fd'
summary(object, times.influ = 3, times.sigma = 3, draw = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.fregre.fd_+3A_object">object</code></td>
<td>
<p>Estimated by functional regression, <code>fregre.fd</code> object.</p>
</td></tr>
<tr><td><code id="summary.fregre.fd_+3A_times.influ">times.influ</code></td>
<td>
<p>Limit for detect possible infuence curves.</p>
</td></tr>
<tr><td><code id="summary.fregre.fd_+3A_times.sigma">times.sigma</code></td>
<td>
<p>Limit for detect possible oultiers or atypical curves.</p>
</td></tr>
<tr><td><code id="summary.fregre.fd_+3A_draw">draw</code></td>
<td>
<p>=TRUE draw estimation and residuals graphics.</p>
</td></tr>
<tr><td><code id="summary.fregre.fd_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>Influence</code>: Vector of influence measures.
</p>
</li>
<li> <p><code>i.influence</code>: Index of possible influence curves.
</p>
</li>
<li> <p><code>i.atypical</code>: Index of possible atypical curves or possible outliers.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Manuel Febrero-Bande and Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>Summary function for <code><a href="#topic+fregre.pc">fregre.pc</a></code>,
<code><a href="#topic+fregre.basis">fregre.basis</a></code>, <code><a href="#topic+fregre.pls">fregre.pls</a></code>, <br />
<code><a href="#topic+fregre.np">fregre.np</a></code> and <code><a href="#topic+fregre.plm">fregre.plm</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Ex 1. Simulated data
n= 200;tt= seq(0,1,len=101)
x0&lt;-rproc2fdata(n,tt,sigma="wiener")
x1&lt;-rproc2fdata(n,tt,sigma=0.1)
x&lt;-x0*3+x1
beta = tt*sin(2*pi*tt)^2
fbeta = fdata(beta,tt)
y&lt;-inprod.fdata(x,fbeta)+rnorm(n,sd=0.1)

# Functional regression
res=fregre.pc(x,y,l=c(1:5))
summary(res,3,ask=TRUE)

res2=fregre.pls(x,y,l=c(1:4))
summary(res2)

res3=fregre.pls(x,y)
summary(res3)

## End(Not run)

</code></pre>

<hr>
<h2 id='summary.fregre.gkam'>Summarizes information from fregre.gkam objects.</h2><span id='topic+summary.fregre.gkam'></span><span id='topic+print.fregre.gkam'></span>

<h3>Description</h3>

<p>Summary function for <code><a href="#topic+fregre.gkam">fregre.gkam</a></code> function.
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Family used.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Number or iteration of algorithm
and if it has converged. </td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Residual and null deviance.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
-Number of data.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>
 
<p>Produces a list of summary information for a fitted
fregre.np object for each functional covariate.  
</p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;">
-Call.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -R squared.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Residual variance.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Index of
possible atypical curves or possible outliers.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Index of possible
influence curves.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>
<p> If draw=TRUE plot: <br /> </p>

<table>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -y vs y
fitted values.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Residuals vs fitted values.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Residual
boxplot.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Quantile-Quantile Plot (qqnorm).</td>
</tr>
<tr>
 <td style="text-align: left;"> </td><td style="text-align: left;"> -Plot for a each
single model term.</td>
</tr>
<tr>
 <td style="text-align: left;"> </td>
</tr>

</table>

<p>If <code>ask</code>=FALSE draw graphs in one window, by
default. If <code>ask</code>=TRUE, draw each graph in a window, waiting to
confirm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'fregre.gkam'
summary(object, draw = TRUE, selec = NULL, times.influ = 3, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.fregre.gkam_+3A_object">object</code></td>
<td>
<p>Estimated by functional regression, <code>fregre.fd</code> object.</p>
</td></tr>
<tr><td><code id="summary.fregre.gkam_+3A_draw">draw</code></td>
<td>
<p>=TRUE draw estimation and residuals graphics.</p>
</td></tr>
<tr><td><code id="summary.fregre.gkam_+3A_selec">selec</code></td>
<td>
<p>Allows the plot for a single model term to be selected for
printing. e.g. if you just want the plot for the second smooth term set
selec=2.  .</p>
</td></tr>
<tr><td><code id="summary.fregre.gkam_+3A_times.influ">times.influ</code></td>
<td>
<p>Limit for detect possible infuence curves.</p>
</td></tr>
<tr><td><code id="summary.fregre.gkam_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande and Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>See Also</h3>

<p>Summary function for <code><a href="#topic+fregre.gkam">fregre.gkam</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Time consuming
data(tecator)
ind&lt;-1:129
ab=tecator$absorp.fdata[ind]
ab2=fdata.deriv(ab,2)
yfat=as.integer(cut(tecator$y[ind,"Fat"],c(0,15,100)))-1
xlist=list("df"=data.frame(yfat),"ab2"=ab2,"ab"=ab)
f&lt;-yfat~ab+ab2
res=fregre.gkam(f, data = xlist, family = binomial("logit"),
                control = list(maxit = 2))
summary(res)


## End(Not run)

</code></pre>

<hr>
<h2 id='tecator'>tecator data</h2><span id='topic+tecator'></span>

<h3>Description</h3>

<p>Water, Fat and Protein content of meat samples
</p>


<h3>Format</h3>

<p>The format is: <br /> <code>..$absorp.fdata</code>: absorbance data.
<code>fdata</code> class object with: <br /> </p>
 <ul>
<li> <p><code>"data"</code>: Matrix of
class <code>fdata</code> with 215 curves (rows) discretized in 100 points or
argvals (columns).<br /> </p>
</li>
<li> <p><code>"argvals"</code>: 100 discretization points from
850 to 1050nm <br /> </p>
</li>
<li> <p><code>"rangeval"</code>=(850,1050):
range(<code>"argvals"</code>) </p>
</li>
<li> <p><code>"names"</code> list with: <code>main</code> an
overall title &quot;Tecator data set&quot;, <code>xlab</code> title for <code>x</code> axis
&quot;Wavelength (nm)&quot; and <code>ylab</code> title for <code>y</code> axis &quot;Absorbances&quot;. </p>
</li></ul>

<p><code>..$y</code>: the percentages of Fat, Water and Protein.  The three contents
are determined by analytic chemistry.<br />
</p>


<h3>Details</h3>

<p><code>absorp.fdata</code> absorbance data for 215 samples. The first 129 were
originally used as a training set endpoints the percentages of Fat, Water
and Protein.<br /> for more details see tecator package
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande and Manuel Oviedo de la Fuente <a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(tecator)
names(tecator)
names(tecator$absorp.fdata)
names(tecator$y)
names(tecator$y)
class(tecator$absorp.fdata)
class(tecator$y)
dim(tecator$absorp.fdata)
dim(tecator$y)

</code></pre>

<hr>
<h2 id='Var.y'>Sampling Variance estimates</h2><span id='topic+Var.y'></span><span id='topic+Var.e'></span>

<h3>Description</h3>

<p>Sampling variance or error variance estimates for regression estimates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Var.y(y, S, Var.e = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Var.y_+3A_y">y</code></td>
<td>
<p><code><a href="#topic+fdata">fdata</a></code> class object.</p>
</td></tr>
<tr><td><code id="Var.y_+3A_s">S</code></td>
<td>
<p>Smoothing matrix calculated by <code><a href="#topic+S.basis">S.basis</a></code> or
<code><a href="#topic+S.NW">S.NW</a></code> functions.</p>
</td></tr>
<tr><td><code id="Var.y_+3A_var.e">Var.e</code></td>
<td>
<p>Error Variance Estimates. If <code>Var.e</code>=NULL, Var.e is
calculated.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Var.y: returns the sampling variance of the functional data. Var.e:
returns the sampling error variance of the functional data.
</p>


<h3>Author(s)</h3>

<p>Manuel Febrero-Bande, Manuel Oviedo de la Fuente
<a href="mailto:manuel.oviedo@udc.es">manuel.oviedo@udc.es</a>
</p>


<h3>References</h3>

<p>Ramsay, James O., and Silverman, Bernard W. (2006), <em>
Functional Data Analysis</em>, 2nd ed., Springer, New York.
</p>


<h3>See Also</h3>

<p>See Also as <code><a href="#topic+Var.e">Var.e</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>a1&lt;-seq(0,1,by=.01)
a2=rnorm(length(a1),sd=0.2)
f1&lt;-(sin(2*pi*a1))+rnorm(length(a1),sd=0.2)
nc&lt;-50
np&lt;-length(f1)
tt=1:101
mdata&lt;-matrix(NA,ncol=np,nrow=nc)
for (i in 1:nc) mdata[i,]&lt;- (sin(2*pi*a1))+rnorm(length(a1),sd=0.2)
mdata&lt;-fdata(mdata,tt)
S=S.NW(tt,h=0.15)
var.e&lt;-Var.e(mdata,S)
var.y&lt;-Var.y(mdata,S)
var.y2&lt;-Var.y(mdata,S,var.e) #the same
</code></pre>

<hr>
<h2 id='weights4class'>Weighting tools</h2><span id='topic+weights4class'></span>

<h3>Description</h3>

<p>computes inverse probability weighting.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>weights4class(x, type = c("equal", "inverse"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="weights4class_+3A_x">x</code></td>
<td>
<p>A vector of the labels, true class or observed response. Can be <code>numeric, character, or factor</code></p>
</td></tr>
<tr><td><code id="weights4class_+3A_type">type</code></td>
<td>
<p>Type of weights.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>Other performance: 
<code><a href="#topic+accuracy">accuracy</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
