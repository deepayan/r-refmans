<!DOCTYPE html><html lang="en-US"><head><title>Help for package ecocomDP</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ecocomDP}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#annotation_dictionary'><p>Annotations of published data</p></a></li>
<li><a href='#ants_L0_flat'><p>Joined and flat version of EDI data package knb-lter-hfr.118.33</p></a></li>
<li><a href='#ants_L1'><p>The ecocomDP (L1) version of EDI data package knb-lter-hfr.118.33</p></a></li>
<li><a href='#calc_geo_extent_bounding_box_m2'><p>Calculate geo_extent_bounding_box_m2 for the dataset_summary table</p></a></li>
<li><a href='#calc_length_of_survey_years'><p>Calculate length_of_survey_years for the dataset_summary table</p></a></li>
<li><a href='#calc_number_of_years_sampled'><p>Calculate number_of_years_sampled for the dataset_summary table</p></a></li>
<li><a href='#calc_std_dev_interval_betw_years'><p>Calculate std_dev_interval_betw_years for the dataset_summary table</p></a></li>
<li><a href='#convert_to_dwca'><p>Convert a dataset to the Darwin Core Archive format</p></a></li>
<li><a href='#create_dataset_summary'><p>Create the dataset_summary table</p></a></li>
<li><a href='#create_eml'><p>Create EML metadata</p></a></li>
<li><a href='#create_location'><p>Create the location table</p></a></li>
<li><a href='#create_location_ancillary'><p>Create the location_ancillary table</p></a></li>
<li><a href='#create_observation'><p>Create the observation table</p></a></li>
<li><a href='#create_observation_ancillary'><p>Create the observation_ancillary table</p></a></li>
<li><a href='#create_taxon'><p>Create the taxon table</p></a></li>
<li><a href='#create_taxon_ancillary'><p>Create the taxon_ancillary table</p></a></li>
<li><a href='#create_variable_mapping'><p>Create the variable_mapping table</p></a></li>
<li><a href='#flatten_data'><p>Flatten a dataset</p></a></li>
<li><a href='#plot_sample_space_time'><p>Plot dates and times samples were collected or observations were made</p></a></li>
<li><a href='#plot_sites'><p>Plot sites on US map</p></a></li>
<li><a href='#plot_taxa_abund'><p>Plot mean taxa abundances per 'observation_id'</p></a></li>
<li><a href='#plot_taxa_accum_sites'><p>Plot taxa accumulation by site accumulation</p></a></li>
<li><a href='#plot_taxa_accum_time'><p>Plot taxa accumulation through time</p></a></li>
<li><a href='#plot_taxa_diversity'><p>Plot diversity (taxa richness) through time</p></a></li>
<li><a href='#plot_taxa_occur_freq'><p>Plot taxon occurrence frequencies</p></a></li>
<li><a href='#plot_taxa_rank'><p>Plot taxa ranks</p></a></li>
<li><a href='#plot_taxa_sample_time'><p>Plot dates and times samples were taken (DEPRECATED)</p></a></li>
<li><a href='#plot_taxa_shared_sites'><p>Plot number of unique taxa shared across sites</p></a></li>
<li><a href='#read_data'><p>Read published data</p></a></li>
<li><a href='#save_data'><p>Save a dataset</p></a></li>
<li><a href='#search_data'><p>Search published data</p></a></li>
<li><a href='#validate_data'><p>Validate tables against the model</p></a></li>
<li><a href='#write_tables'><p>Write tables to file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tools to Create, Use, and Convert ecocomDP Data</td>
</tr>
<tr>
<td>Description:</td>
<td>Work with the Ecological Community Data Design Pattern. 'ecocomDP' 
    is a flexible data model for harmonizing ecological community surveys, in a 
    research question agnostic format, from source data published across 
    repositories, and with methods that keep the derived data up-to-date as the 
    underlying sources change. Described in O'Brien et al. (2021), 
    &lt;<a href="https://doi.org/10.1016%2Fj.ecoinf.2021.101374">doi:10.1016/j.ecoinf.2021.101374</a>&gt;.</td>
</tr>
<tr>
<td>Version:</td>
<td>1.3.2</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/EDIorg/ecocomDP">https://github.com/EDIorg/ecocomDP</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/EDIorg/ecocomDP/issues">https://github.com/EDIorg/ecocomDP/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>RColorBrewer, data.table, dplyr, EML (&ge; 2.0.5), emld (&ge;
0.5.1), geosphere, ggplot2, httr, lubridate, magrittr, methods,
neonUtilities (&ge; 2.1.1), rlang, rmarkdown, stats, stringr,
tidyr, tools, utils, uuid, xml2, neonOS</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, mime, reader, ritis, taxize, testthat, worrms,
ggrepel, usmap (&ge; 0.6.1), sf (&ge; 1.0.9), maps</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Language:</td>
<td>en-US</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-08-16 18:45:06 UTC; csmith</td>
</tr>
<tr>
<td>Author:</td>
<td>Colin Smith <a href="https://orcid.org/0000-0003-2261-9931"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut,
    cre, cph],
  Eric Sokol <a href="https://orcid.org/0000-0001-5923-0917"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Margaret O'Brien <a href="https://orcid.org/0000-0002-1693-8322"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Matt Bitters [ctb],
  Melissa Chen [ctb],
  Savannah Gonzales [ctb],
  Matt Helmus [ctb],
  Brendan Hobart [ctb],
  Ruvi Jaimes [ctb],
  Lara Janson [ctb],
  Marta Jarzyna [ctb],
  Michael Just [ctb],
  Daijiang Li [ctb],
  Wynne Moss [ctb],
  Kari Norman [ctb],
  Stephanie Parker [ctb],
  Rafael Rangel <a href="https://orcid.org/0009-0000-6265-3064"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Natalie Robinson [ctb],
  Thilina Surasinghe [ctb],
  Kyle Zollo-Venecek
    <a href="https://orcid.org/0000-0002-1615-590X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Colin Smith &lt;colin.smith@wisc.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-08-16 21:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='annotation_dictionary'>Annotations of published data</h2><span id='topic+annotation_dictionary'></span>

<h3>Description</h3>

<p>View the collection of dataset- and attribute-level annotations
from existing ecocomDP datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>annotation_dictionary()
</code></pre>


<h3>Details</h3>

<p>Use the search field to find the annotation terms and URIs.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
View(annotation_dictionary())

## End(Not run)
    
</code></pre>

<hr>
<h2 id='ants_L0_flat'>Joined and flat version of EDI data package knb-lter-hfr.118.33</h2><span id='topic+ants_L0_flat'></span>

<h3>Description</h3>

<p>A fully joined and flat version of EDI data package knb-lter-hfr.118.33 (Ant Assemblages in Hemlock Removal Experiment at Harvard Forest since 2003) with all relevant ecocomDP L1 identifiers and content added. Use this dataset as an input to the <code>L0_flat</code> argument of the &quot;create&quot; functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ants_L0_flat
</code></pre>


<h3>Format</h3>

<p>A data frame with 2931 rows and 45 variables:
</p>

<dl>
<dt>datetime</dt><dd><p>dates</p>
</dd>
<dt>block</dt><dd><p>block</p>
</dd>
<dt>plot</dt><dd><p>plot number</p>
</dd>
<dt>treatment</dt><dd><p>treatment type</p>
</dd>
<dt>moose.cage</dt><dd><p>location of grid with respect to moose exclosure</p>
</dd>
<dt>trap.type</dt><dd><p>trap type</p>
</dd>
<dt>trap.num</dt><dd><p>applies only to pitfall cups</p>
</dd>
<dt>subfamily</dt><dd><p>ant subfamily</p>
</dd>
<dt>hl</dt><dd><p>head length. We used trait definitions from Del Toro et al. (2015) and filled in missing species' data with information from Ellison et al.</p>
</dd>
<dt>rel</dt><dd><p>eye length relative to body size</p>
</dd>
<dt>rll</dt><dd><p>femur length relative to body size</p>
</dd>
<dt>colony.size</dt><dd><p>size of colony for each species</p>
</dd>
<dt>feeding.preference</dt><dd><p>feeding preference for each species</p>
</dd>
<dt>nest.substrate</dt><dd><p>nest substrate</p>
</dd>
<dt>primary.habitat</dt><dd><p>primary habitat</p>
</dd>
<dt>secondary.habitat</dt><dd><p>secondary habitat associations</p>
</dd>
<dt>seed.disperser</dt><dd><p>whether or not a seed dispersing species</p>
</dd>
<dt>slavemaker.sp</dt><dd><p>whether or not a slavemaking species</p>
</dd>
<dt>behavior</dt><dd><p>classifications based on behavioral interactions with other ants</p>
</dd>
<dt>biogeographic.affinity</dt><dd><p>biogeographic affinity based on available occurrence records</p>
</dd>
<dt>source</dt><dd><p>where trait information was found. Full citations for literature are as follows: Del Toro, I., R.R. Silva, and A.M. Ellison. 2015. Predicated impacts of climatic change on ant functional diversity and distributions in eastern North American forests. Diversity and Distributions 21:781-791; Ellison, A.M., N.J. Gotelli, G. Alpert, and E.J. Farnsworth. 2012. A field guide to the ants of New England. Yale University Press, New Haven, Connecticut, USA.</p>
</dd>
<dt>unit_hl</dt><dd><p>units for &quot;hl&quot; variable</p>
</dd>
<dt>unit_rel</dt><dd><p>units for &quot;rel&quot; variable</p>
</dd>
<dt>unit_rll</dt><dd><p>units for &quot;rll&quot; variable</p>
</dd>
<dt>variable_name</dt><dd><p>variables of the primary observation table</p>
</dd>
<dt>value</dt><dd><p>values of variable_name</p>
</dd>
<dt>unit</dt><dd><p>units of variable_name</p>
</dd>
<dt>observation_id</dt><dd><p>the observation id</p>
</dd>
<dt>location_id</dt><dd><p>the location id</p>
</dd>
<dt>event_id</dt><dd><p>the event id</p>
</dd>
<dt>latitude</dt><dd><p>approximate latitude of study area</p>
</dd>
<dt>longitude</dt><dd><p>approximate longitude of study area</p>
</dd>
<dt>elevation</dt><dd><p>approximate elevation of study area</p>
</dd>
<dt>taxon_name</dt><dd><p>name of organism</p>
</dd>
<dt>taxon_id</dt><dd><p>the taxon id</p>
</dd>
<dt>taxon_rank</dt><dd><p>the taxon rank</p>
</dd>
<dt>authority_system</dt><dd><p>the authority system taxon_name was resolved to</p>
</dd>
<dt>authority_taxon_id</dt><dd><p>the id of taxon_name in authority_system</p>
</dd>
<dt>package_id</dt><dd><p>the identifier of this ecocomDP dataset</p>
</dd>
<dt>original_package_id</dt><dd><p>the identifier of the source dataset</p>
</dd>
<dt>length_of_survey_years</dt><dd><p>number of years the survey has been ongoing</p>
</dd>
<dt>number_of_years_sampled</dt><dd><p>number of years during the survey that samples were taken</p>
</dd>
<dt>std_dev_interval_betw_years</dt><dd><p>the standard deviation between surveys in years</p>
</dd>
<dt>max_num_taxa</dt><dd><p>number of unique taxa in this dataset</p>
</dd>
<dt>geo_extent_bounding_box_m2</dt><dd><p>the study area in meters squared</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-hfr&amp;identifier=118&amp;revision=33">https://portal.edirepository.org/nis/mapbrowse?scope=knb-lter-hfr&amp;identifier=118&amp;revision=33</a>
</p>

<hr>
<h2 id='ants_L1'>The ecocomDP (L1) version of EDI data package knb-lter-hfr.118.33</h2><span id='topic+ants_L1'></span>

<h3>Description</h3>

<p>The the ecocomDP (L1) formatted version of EDI data package knb-lter-hfr.118.33 (Ant Assemblages in Hemlock Removal Experiment at Harvard Forest since 2003) read from the EDI API with <code>read_data(id = "edi.193.5")</code>. Use this dataset as an input to data &quot;use&quot; functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ants_L1
</code></pre>


<h3>Format</h3>

<p>A list of:
</p>

<dl>
<dt>id</dt><dd><p>The dataset identifier</p>
</dd>
<dt>metadata</dt><dd><p>See source url for metadata</p>
</dd>
<dt>tables</dt><dd><p>A list of data frames, each an ecocomDP table</p>
</dd>
<dt>validation_issues</dt><dd><p>Is NULL because there are no validation issues for this dataset</p>
</dd>
</dl>



<h3>Source</h3>

<p><a href="https://portal.edirepository.org/nis/mapbrowse?scope=edi&amp;identifier=193&amp;revision=5">https://portal.edirepository.org/nis/mapbrowse?scope=edi&amp;identifier=193&amp;revision=5</a>
</p>

<hr>
<h2 id='calc_geo_extent_bounding_box_m2'>Calculate geo_extent_bounding_box_m2 for the dataset_summary table</h2><span id='topic+calc_geo_extent_bounding_box_m2'></span>

<h3>Description</h3>

<p>Calculate geo_extent_bounding_box_m2 for the dataset_summary table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_geo_extent_bounding_box_m2(west, east, north, south)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_geo_extent_bounding_box_m2_+3A_west">west</code></td>
<td>
<p>(numeric) West longitude in decimal degrees and negative if west of the prime meridian.</p>
</td></tr>
<tr><td><code id="calc_geo_extent_bounding_box_m2_+3A_east">east</code></td>
<td>
<p>(numeric) East longitude in decimal degrees and negative if west of the prime meridian.</p>
</td></tr>
<tr><td><code id="calc_geo_extent_bounding_box_m2_+3A_north">north</code></td>
<td>
<p>(numeric) North latitude in decimal degrees and negative if south of the equator.</p>
</td></tr>
<tr><td><code id="calc_geo_extent_bounding_box_m2_+3A_south">south</code></td>
<td>
<p>(numeric) South latitude in decimal degrees and negative if south of the equator.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(numeric) Area of study site in meters squared.
</p>

<hr>
<h2 id='calc_length_of_survey_years'>Calculate length_of_survey_years for the dataset_summary table</h2><span id='topic+calc_length_of_survey_years'></span>

<h3>Description</h3>

<p>Calculate length_of_survey_years for the dataset_summary table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_length_of_survey_years(dates)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_length_of_survey_years_+3A_dates">dates</code></td>
<td>
<p>(Date) Dates from the L0 source dataset encompassing the entire study duration.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(numeric) Number of years the study has been ongoing.
</p>

<hr>
<h2 id='calc_number_of_years_sampled'>Calculate number_of_years_sampled for the dataset_summary table</h2><span id='topic+calc_number_of_years_sampled'></span>

<h3>Description</h3>

<p>Calculate number_of_years_sampled for the dataset_summary table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_number_of_years_sampled(dates)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_number_of_years_sampled_+3A_dates">dates</code></td>
<td>
<p>(Date) Dates from the L0 source dataset encompassing the entire study duration.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(numeric) Number of survey years in which a sample was taken.
</p>

<hr>
<h2 id='calc_std_dev_interval_betw_years'>Calculate std_dev_interval_betw_years for the dataset_summary table</h2><span id='topic+calc_std_dev_interval_betw_years'></span>

<h3>Description</h3>

<p>Calculate std_dev_interval_betw_years for the dataset_summary table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calc_std_dev_interval_betw_years(dates)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="calc_std_dev_interval_betw_years_+3A_dates">dates</code></td>
<td>
<p>(Date) Dates from the L0 source dataset encompassing the entire study duration.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(numeric) The standard deviation between sampling events (in years).
</p>

<hr>
<h2 id='convert_to_dwca'>Convert a dataset to the Darwin Core Archive format</h2><span id='topic+convert_to_dwca'></span>

<h3>Description</h3>

<p>Convert a dataset to the Darwin Core Archive format
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_to_dwca(
  path,
  core_name,
  source_id,
  derived_id,
  url = NULL,
  user_id,
  user_domain
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convert_to_dwca_+3A_path">path</code></td>
<td>
<p>(character) Path to which the DwC-A data objects and EML will be written.</p>
</td></tr>
<tr><td><code id="convert_to_dwca_+3A_core_name">core_name</code></td>
<td>
<p>(character) The central table of the DwC-A dataset being created. Can be: &quot;event&quot; (event core). Occurrence core is not yet supported.</p>
</td></tr>
<tr><td><code id="convert_to_dwca_+3A_source_id">source_id</code></td>
<td>
<p>(character) Identifier of an ecocomDP dataset published in a supported repository. Currently, the EDI Data Repository is supported.</p>
</td></tr>
<tr><td><code id="convert_to_dwca_+3A_derived_id">derived_id</code></td>
<td>
<p>(character) Identifier of the DwC-A dataset being created.</p>
</td></tr>
<tr><td><code id="convert_to_dwca_+3A_url">url</code></td>
<td>
<p>(character) URL to the publicly accessible directory containing DwC-A data objects. This argument supports direct download of the data entities by a data repository and is used for automated revisioning and publication.</p>
</td></tr>
<tr><td><code id="convert_to_dwca_+3A_user_id">user_id</code></td>
<td>
<p>(character) Identifier of user account associated with the data repository in which this ecocomDP dataset will be archived. Only <code>user_id</code> from the EDI is currently supported.</p>
</td></tr>
<tr><td><code id="convert_to_dwca_+3A_user_domain">user_domain</code></td>
<td>
<p>(character) Domain (data repository) the <code>user_id</code> belongs to. Currently, EDI is supported.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Reads in an ecocomDP dataset from a supported repository and converts it to a DwC-A package.
</p>


<h3>Value</h3>

<p>DwC-A tables, meta.xml, and corresponding EML metadata.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Create directory for DwC-A outputs
mypath &lt;- paste0(tempdir(), "/data")
dir.create(mypath)

# Convert an EDI published ecocomDP dataset to a DwC-A
convert_to_dwca(
  path = mypath, 
  core_name = "event", 
  source_id = "edi.193.5", 
  derived_id = "edi.834.2", 
  user_id = "ecocomdp",
  user_domain = "EDI")

dir(mypath)

# Clean up
unlink(mypath, recursive = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='create_dataset_summary'>Create the dataset_summary table</h2><span id='topic+create_dataset_summary'></span>

<h3>Description</h3>

<p>Create the dataset_summary table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_dataset_summary(
  L0_flat,
  package_id,
  original_package_id = NULL,
  length_of_survey_years,
  number_of_years_sampled,
  std_dev_interval_betw_years,
  max_num_taxa,
  geo_extent_bounding_box_m2 = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_dataset_summary_+3A_l0_flat">L0_flat</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The fully joined source L0 dataset, in &quot;flat&quot; format (see details).</p>
</td></tr>
<tr><td><code id="create_dataset_summary_+3A_package_id">package_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier of the derived L1 dataset.</p>
</td></tr>
<tr><td><code id="create_dataset_summary_+3A_original_package_id">original_package_id</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the identifier of the source L0 dataset.</p>
</td></tr>
<tr><td><code id="create_dataset_summary_+3A_length_of_survey_years">length_of_survey_years</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the number of years the study has been ongoing. Use <code>calc_length_of_survey_years()</code> to calculate this value.</p>
</td></tr>
<tr><td><code id="create_dataset_summary_+3A_number_of_years_sampled">number_of_years_sampled</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the number of years within the period of study that samples were taken. Use <code>calc_number_of_years_sampled()</code> to calculate this value.</p>
</td></tr>
<tr><td><code id="create_dataset_summary_+3A_std_dev_interval_betw_years">std_dev_interval_betw_years</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the standard deviation of the interval between sampling events. Use <code>calc_std_dev_interval_betw_years()</code> to calculate this value.</p>
</td></tr>
<tr><td><code id="create_dataset_summary_+3A_max_num_taxa">max_num_taxa</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the number of unique taxa in the source L0 dataset.</p>
</td></tr>
<tr><td><code id="create_dataset_summary_+3A_geo_extent_bounding_box_m2">geo_extent_bounding_box_m2</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the area (in meters) of the study location, if applicable (some L0 were collected at a single point). Use <code>calc_geo_extent_bounding_box_m2()</code> to calculate this value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects specified columns from <code>L0_flat</code> and returns distinct rows.
</p>
<p>&quot;flat&quot; format refers to the fully joined source L0 dataset in &quot;wide&quot; form with the exception of the core observation variables, which are in &quot;long&quot; form (i.e. using the variable_name, value, unit columns of the observation table). This &quot;flat&quot; format is the &quot;widest&quot; an L1 ecocomDP dataset can be consistently spread due to the frequent occurrence of L0 source datasets with &gt; 1 core observation variable.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) The dataset_summary table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>flat &lt;- ants_L0_flat

dataset_summary &lt;- create_dataset_summary(
  L0_flat = flat, 
  package_id = "package_id", 
  original_package_id = "original_package_id", 
  length_of_survey_years = "length_of_survey_years",
  number_of_years_sampled = "number_of_years_sampled", 
  std_dev_interval_betw_years = "std_dev_interval_betw_years", 
  max_num_taxa = "max_num_taxa", 
  geo_extent_bounding_box_m2 = "geo_extent_bounding_box_m2")

dataset_summary

</code></pre>

<hr>
<h2 id='create_eml'>Create EML metadata</h2><span id='topic+create_eml'></span>

<h3>Description</h3>

<p>Create EML metadata
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_eml(
  path,
  source_id,
  derived_id,
  script,
  script_description,
  is_about = NULL,
  contact,
  user_id,
  user_domain,
  basis_of_record = NULL,
  url = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_eml_+3A_path">path</code></td>
<td>
<p>(character) Path to the directory containing ecocomDP tables, conversion script, and where EML metadata will be written.</p>
</td></tr>
<tr><td><code id="create_eml_+3A_source_id">source_id</code></td>
<td>
<p>(character) Identifier of a data package published in a supported repository. Currently, the EDI Data Repository is supported.</p>
</td></tr>
<tr><td><code id="create_eml_+3A_derived_id">derived_id</code></td>
<td>
<p>(character) Identifier of the dataset being created.</p>
</td></tr>
<tr><td><code id="create_eml_+3A_script">script</code></td>
<td>
<p>(character) Name of file used to convert <code>source_id</code> to <code>derived_id</code>.</p>
</td></tr>
<tr><td><code id="create_eml_+3A_script_description">script_description</code></td>
<td>
<p>(character) Description of <code>script</code>.</p>
</td></tr>
<tr><td><code id="create_eml_+3A_is_about">is_about</code></td>
<td>
<p>(named character) An optional argument for specifying dataset level annotations describing what this dataset &quot;is about&quot;.</p>
</td></tr>
<tr><td><code id="create_eml_+3A_contact">contact</code></td>
<td>
<p>(data.frame) Contact information for the person that created this ecocomDP dataset, containing these columns:
</p>

<ul>
<li><p> givenName
</p>
</li>
<li><p> surName
</p>
</li>
<li><p> organizationName
</p>
</li>
<li><p> electronicMailAddress
</p>
</li></ul>
</td></tr>
<tr><td><code id="create_eml_+3A_user_id">user_id</code></td>
<td>
<p>(character) Identifier of user associated with <code>user_domain</code>.</p>
</td></tr>
<tr><td><code id="create_eml_+3A_user_domain">user_domain</code></td>
<td>
<p>(character) Domain (data repository) the <code>user_id</code> belongs to. Currently, EDI is supported.</p>
</td></tr>
<tr><td><code id="create_eml_+3A_basis_of_record">basis_of_record</code></td>
<td>
<p>(character) An optional argument to facilitate creation of a Darwin Core record from this dataset using <code>convert_to_dwca()</code>. Use this to define the Darwin Core property <a href="https://dwc.tdwg.org/terms/#dwc:basisOfRecord">basisOfRecord</a> as <a href="http://rs.tdwg.org/dwc/terms/HumanObservation">HumanObservation</a> or <a href="http://rs.tdwg.org/dwc/terms/MachineObservation">MachineObservation</a>.</p>
</td></tr>
<tr><td><code id="create_eml_+3A_url">url</code></td>
<td>
<p>(character) URL to the publicly accessible directory containing ecocomDP tables, conversion script, and EML metadata. This argument supports direct download of the data entities by a data repository and is used for automated revisioning and publication.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates an EML record for an ecocomDP by combining metadata from <code>source_id</code> with boiler-plate metadata describing the ecocomDP model. Changes to the <code>source_id</code> EML include:
</p>

<ul>
<li> <p><strong>&lt;access&gt;</strong> Adds <code>user_id</code> to the list of principals granted read and write access to the ecocomDP data package this EML describes.
</p>
</li>
<li> <p><strong>&lt;title&gt;</strong> Adds a note that this is a derived data package in the ecocomDP format.
</p>
</li>
<li> <p><strong>&lt;pubDate&gt;</strong> Adds the date this EML was created.
</p>
</li>
<li> <p><strong>&lt;abstract&gt;</strong> Adds a note that this is a derived data package in the ecocomDP format.
</p>
</li>
<li> <p><strong>&lt;keywordSet</strong> Adds the &quot;ecocomDP&quot; keyword to enable search and discovery of all ecocomDP data packages in the data repository it is published, and 7 terms from the LTER Controlled vocabulary: &quot;communities&quot;, &quot;community composition&quot;, &quot;community dynamics&quot;, &quot;community patterns&quot;, &quot;species composition&quot;, &quot;species diversity&quot;, and &quot;species richness&quot;. Darwin Core Terms listed under <code>basis_of_record</code> are listed and used by <code>convert_to_dwca()</code> to create a Darwin Core Archive of this ecocomDP data package.
</p>
</li>
<li> <p><strong>&lt;intellectualRights&gt;</strong> Keeps intact the original intellectual rights license <code>source_id</code> was released under, or uses <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode">CCO</a> if missing.
</p>
</li>
<li> <p><strong>&lt;taxonomicCoverage&gt;</strong> Appends to the taxonomic coverage element with data supplied in the ecocomDP taxon table.
</p>
</li>
<li> <p><strong>&lt;contact&gt;</strong> Adds the ecocomDP creator as a point of contact.
</p>
</li>
<li> <p><strong>&lt;methodStep&gt;</strong> Adds a note that this data package was created by the <code>script</code>, and adds provenance metadata noting that this is a derived dataset and describes where the <code>source_id</code> can be accessed.
</p>
</li>
<li> <p><strong>&lt;dataTables&gt;</strong> Replaces the <code>source_id</code> table metadata with descriptions of the the ecocomDP tables.
</p>
</li>
<li> <p><strong>&lt;otherEntity&gt;</strong> Adds <code>script</code> and <code>script_description</code>. otherEntities of <code>source_id</code> are removed.
</p>
</li>
<li> <p><strong>&lt;annotations&gt;</strong> Adds boilerplate annotations describing the ecocomDP at the dataset, entity, and entity attribute levels.
</p>
</li></ul>

<p>Taxa listed in the taxon table, and resolved to one of the supported authority systems (i.e. <a href="https://www.itis.gov/">ITIS</a>, <a href="https://www.marinespecies.org/">WORMS</a>, or <a href="https://gbif.org">GBIF</a>), will have their full taxonomic hierarchy expanded, including any common names for each level.
</p>


<h3>Value</h3>

<p>An EML metadata file.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Create directory with ecocomDP tables for create_eml()
mypath &lt;- paste0(tempdir(), "/data")
dir.create(mypath)
inpts &lt;- c(ants_L1$tables, path = mypath)
do.call(write_tables, inpts)
file.copy(system.file("extdata", "create_ecocomDP.R", package = "ecocomDP"), mypath)
dir(mypath)

# Describe, with annotations, what the source L0 dataset "is about"
dataset_annotations &lt;- c(
  `species abundance` = "http://purl.dataone.org/odo/ECSO_00001688",
  Population = "http://purl.dataone.org/odo/ECSO_00000311",
  `level of ecological disturbance` = "http://purl.dataone.org/odo/ECSO_00002588",
  `type of ecological disturbance` = "http://purl.dataone.org/odo/ECSO_00002589")

# Add self as contact information incase questions arise
additional_contact &lt;- data.frame(
  givenName = 'Colin',
  surName = 'Smith',
  organizationName = 'Environmental Data Initiative',
  electronicMailAddress = 'csmith@mail.com',
  stringsAsFactors = FALSE)

# Create EML
eml &lt;- create_eml(
  path = mypath,
  source_id = "knb-lter-hfr.118.33",
  derived_id = "edi.193.5",
  is_about = dataset_annotations,
  script = "create_ecocomDP.R",
  script_description = "A function for converting knb-lter-hrf.118 to ecocomDP",
  contact = additional_contact,
  user_id = 'ecocomdp',
  user_domain = 'EDI',
  basis_of_record = "HumanObservation")

dir(mypath)
View(eml)

# Clean up
unlink(mypath, recursive = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='create_location'>Create the location table</h2><span id='topic+create_location'></span>

<h3>Description</h3>

<p>Create the location table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_location(
  L0_flat,
  location_id,
  location_name,
  latitude = NULL,
  longitude = NULL,
  elevation = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_location_+3A_l0_flat">L0_flat</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The fully joined source L0 dataset, in &quot;flat&quot; format (see details).</p>
</td></tr>
<tr><td><code id="create_location_+3A_location_id">location_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier assigned to each unique location at the observation level.</p>
</td></tr>
<tr><td><code id="create_location_+3A_location_name">location_name</code></td>
<td>
<p>(character) One or more columns in <code>L0_flat</code> of sampling locations ordered from high to low in terms of nesting, where the lowest is the level of observation (e.g. <code>location_name = c("plot", "subplot")</code>).</p>
</td></tr>
<tr><td><code id="create_location_+3A_latitude">latitude</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the latitude in decimal degrees of <code>location_id</code>. Latitudes south of the equator are negative.</p>
</td></tr>
<tr><td><code id="create_location_+3A_longitude">longitude</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the longitude in decimal degrees of <code>location_id</code>. Longitudes west of the prime meridian are negative.</p>
</td></tr>
<tr><td><code id="create_location_+3A_elevation">elevation</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the elevation in meters relative to sea level of <code>location_id</code>. Above sea level is positive. Below sea level is negative.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects specified columns from <code>L0_flat</code>, creates data frames for each <code>location_name</code>, assigns <code>latitude</code>, <code>longitude</code>, and <code>elevation</code> to the lowest nesting level (i.e. the observation level) returning <code>NA</code> for higher levels (these will have to be filled manually afterwards), and determines the relationships between location_id and parent_location_id from <code>L0_flat</code> and <code>location_name</code>.
</p>
<p>To prevent the listing of duplicate location_name values, and to enable the return of <code>location_name</code> columns by <code>flatten_data()</code>, location_name values are suffixed with the column they came from according to: <code>paste0(&lt;column name&gt;, "__", &lt;column value&gt;)</code>. Example: A column named &quot;plot&quot; with values &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, in <code>L0_flat</code> would be listed in the resulting location table under the location_name column as &quot;1&quot;, &quot;2&quot;, &quot;3&quot; and therefore no way to discern these values correspond with &quot;plot&quot;. Applying the above listed solution returns &quot;plot__1&quot;, &quot;plot__2&quot;, &quot;plot__3&quot; in the location table and returns the column &quot;plot&quot; with values c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;) by <code>flatten_data()</code>.
</p>
<p>&quot;flat&quot; format refers to the fully joined source L0 dataset in &quot;wide&quot; form with the exception of the core observation variables, which are in &quot;long&quot; form (i.e. using the variable_name, value, unit columns of the observation table). This &quot;flat&quot; format is the &quot;widest&quot; an L1 ecocomDP dataset can be consistently spread due to the frequent occurrence of L0 source datasets with &gt; 1 core observation variable.
</p>
<p>Additionally, latitude, longitude, and elevation of sites nested above the observation level will have to be manually added after the location table is returned.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) The location table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>flat &lt;- ants_L0_flat

location &lt;- create_location(
  L0_flat = flat, 
  location_id = "location_id", 
  location_name = c("block", "plot"), 
  latitude = "latitude", 
  longitude = "longitude", 
  elevation = "elevation")

location

</code></pre>

<hr>
<h2 id='create_location_ancillary'>Create the location_ancillary table</h2><span id='topic+create_location_ancillary'></span>

<h3>Description</h3>

<p>Create the location_ancillary table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_location_ancillary(
  L0_flat,
  location_id,
  datetime = NULL,
  variable_name,
  unit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_location_ancillary_+3A_l0_flat">L0_flat</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The fully joined source L0 dataset, in &quot;flat&quot; format (see details).</p>
</td></tr>
<tr><td><code id="create_location_ancillary_+3A_location_id">location_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier assigned to each unique location at the observation level.</p>
</td></tr>
<tr><td><code id="create_location_ancillary_+3A_datetime">datetime</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the date, and if applicable time, of ancillary location data following the ISO-8601 standard format (e.g. YYYY-MM-DD hh:mm:ss).</p>
</td></tr>
<tr><td><code id="create_location_ancillary_+3A_variable_name">variable_name</code></td>
<td>
<p>(character) Columns in <code>L0_flat</code> containing the ancillary location data.</p>
</td></tr>
<tr><td><code id="create_location_ancillary_+3A_unit">unit</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the units of each <code>variable_name</code> following the column naming convention: unit_&lt;variable_name&gt; (e.g. &quot;unit_depth&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects specified columns from <code>L0_flat</code>, converts into long (attribute-value) form by gathering <code>variable_name</code>. Regular expression matching joins <code>unit</code> to any associated <code>variable_name</code> and is listed in the resulting table's &quot;unit&quot; column.
</p>
<p>&quot;flat&quot; format refers to the fully joined source L0 dataset in &quot;wide&quot; form with the exception of the core observation variables, which are in &quot;long&quot; form (i.e. using the variable_name, value, unit columns of the observation table). This &quot;flat&quot; format is the &quot;widest&quot; an L1 ecocomDP dataset can be consistently spread due to the frequent occurrence of L0 source datasets with &gt; 1 core observation variable.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) The location_ancillary table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>flat &lt;- ants_L0_flat

location_ancillary &lt;- create_location_ancillary(
  L0_flat = flat,
  location_id = "location_id",
  variable_name = "treatment")

location_ancillary

</code></pre>

<hr>
<h2 id='create_observation'>Create the observation table</h2><span id='topic+create_observation'></span>

<h3>Description</h3>

<p>Create the observation table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_observation(
  L0_flat,
  observation_id,
  event_id = NULL,
  package_id,
  location_id,
  datetime,
  taxon_id,
  variable_name,
  value,
  unit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_observation_+3A_l0_flat">L0_flat</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The fully joined source L0 dataset, in &quot;flat&quot; format (see details).</p>
</td></tr>
<tr><td><code id="create_observation_+3A_observation_id">observation_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier assigned to each unique observation.</p>
</td></tr>
<tr><td><code id="create_observation_+3A_event_id">event_id</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the identifier assigned to each unique sampling event.</p>
</td></tr>
<tr><td><code id="create_observation_+3A_package_id">package_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier of the derived L1 dataset.</p>
</td></tr>
<tr><td><code id="create_observation_+3A_location_id">location_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier assigned to each unique location at the observation level.</p>
</td></tr>
<tr><td><code id="create_observation_+3A_datetime">datetime</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the date, and if applicable time, of the observation following the ISO-8601 standard format (e.g. YYYY-MM-DD hh:mm:ss).</p>
</td></tr>
<tr><td><code id="create_observation_+3A_taxon_id">taxon_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier assigned to each unique organism at the observation level.</p>
</td></tr>
<tr><td><code id="create_observation_+3A_variable_name">variable_name</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the names of variables measured.</p>
</td></tr>
<tr><td><code id="create_observation_+3A_value">value</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the values of <code>variable_name</code>.</p>
</td></tr>
<tr><td><code id="create_observation_+3A_unit">unit</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the units of <code>variable_name</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects specified columns from <code>L0_flat</code> and returns distinct rows.
</p>
<p>&quot;flat&quot; format refers to the fully joined source L0 dataset in &quot;wide&quot; form with the exception of the core observation variables, which are in &quot;long&quot; form (i.e. using the variable_name, value, unit columns of the observation table). This &quot;flat&quot; format is the &quot;widest&quot; an L1 ecocomDP dataset can be consistently spread due to the frequent occurrence of L0 source datasets with &gt; 1 core observation variable.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) The observation table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>flat &lt;- ants_L0_flat

observation &lt;- create_observation(
  L0_flat = flat, 
  observation_id = "observation_id", 
  event_id = "event_id", 
  package_id = "package_id",
  location_id = "location_id", 
  datetime = "datetime", 
  taxon_id = "taxon_id", 
  variable_name = "variable_name",
  value = "value",
  unit = "unit")

observation

</code></pre>

<hr>
<h2 id='create_observation_ancillary'>Create the observation_ancillary table</h2><span id='topic+create_observation_ancillary'></span>

<h3>Description</h3>

<p>Create the observation_ancillary table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_observation_ancillary(
  L0_flat,
  observation_id,
  variable_name,
  unit = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_observation_ancillary_+3A_l0_flat">L0_flat</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The fully joined source L0 dataset, in &quot;flat&quot; format (see details).</p>
</td></tr>
<tr><td><code id="create_observation_ancillary_+3A_observation_id">observation_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier assigned to each unique observation.</p>
</td></tr>
<tr><td><code id="create_observation_ancillary_+3A_variable_name">variable_name</code></td>
<td>
<p>(character) Columns in <code>L0_flat</code> containing the ancillary observation data.</p>
</td></tr>
<tr><td><code id="create_observation_ancillary_+3A_unit">unit</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the units of each <code>variable_name</code> following the column naming convention: unit_&lt;variable_name&gt; (e.g. &quot;unit_temperature&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects specified columns from <code>L0_flat</code>, converts into long (attribute-value) form by gathering <code>variable_name</code>. Regular expression matching joins <code>unit</code> to any associated <code>variable_name</code> and is listed in the resulting table's &quot;unit&quot; column.
</p>
<p>&quot;flat&quot; format refers to the fully joined source L0 dataset in &quot;wide&quot; form with the exception of the core observation variables, which are in &quot;long&quot; form (i.e. using the variable_name, value, unit columns of the observation table). This &quot;flat&quot; format is the &quot;widest&quot; an L1 ecocomDP dataset can be consistently spread due to the frequent occurrence of L0 source datasets with &gt; 1 core observation variable.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) The observation_ancillary table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>flat &lt;- ants_L0_flat

observation_ancillary &lt;- create_observation_ancillary(
  L0_flat = flat,
  observation_id = "observation_id", 
  variable_name = c("trap.type", "trap.num", "moose.cage"))

observation_ancillary

</code></pre>

<hr>
<h2 id='create_taxon'>Create the taxon table</h2><span id='topic+create_taxon'></span>

<h3>Description</h3>

<p>Create the taxon table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_taxon(
  L0_flat,
  taxon_id,
  taxon_rank = NULL,
  taxon_name,
  authority_system = NULL,
  authority_taxon_id = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_taxon_+3A_l0_flat">L0_flat</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The fully joined source L0 dataset, in &quot;flat&quot; format (see details).</p>
</td></tr>
<tr><td><code id="create_taxon_+3A_taxon_id">taxon_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier assigned to each unique organism at the observation level.</p>
</td></tr>
<tr><td><code id="create_taxon_+3A_taxon_rank">taxon_rank</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the taxonomic rank of the organism in <code>taxon_name</code>.</p>
</td></tr>
<tr><td><code id="create_taxon_+3A_taxon_name">taxon_name</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the taxonomic name of the organism.</p>
</td></tr>
<tr><td><code id="create_taxon_+3A_authority_system">authority_system</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the name of the authority system <code>authority_taxon_id</code> is from (e.g. &quot;ITIS&quot;).</p>
</td></tr>
<tr><td><code id="create_taxon_+3A_authority_taxon_id">authority_taxon_id</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the identifier corresponding to <code>taxon_name</code> in the <code>authority_system</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects specified columns from <code>L0_flat</code> and returns distinct rows.
</p>
<p>Taxa listed in the taxon table, and resolved to one of the supported authority systems (i.e. <a href="https://www.itis.gov/">ITIS</a>, <a href="https://www.marinespecies.org/">WORMS</a>, or <a href="https://gbif.org">GBIF</a>), will have their full taxonomic hierarchy expanded, including any common names for each level.
</p>
<p>&quot;flat&quot; format refers to the fully joined source L0 dataset in &quot;wide&quot; form with the exception of the core observation variables, which are in &quot;long&quot; form (i.e. using the variable_name, value, unit columns of the observation table). This &quot;flat&quot; format is the &quot;widest&quot; an L1 ecocomDP dataset can be consistently spread due to the frequent occurrence of L0 source datasets with &gt; 1 core observation variable.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) The taxon table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>flat &lt;- ants_L0_flat

taxon &lt;- create_taxon(
  L0_flat = flat, 
  taxon_id = "taxon_id", 
  taxon_rank = "taxon_rank", 
  taxon_name = "taxon_name", 
  authority_system = "authority_system", 
  authority_taxon_id = "authority_taxon_id")

taxon

</code></pre>

<hr>
<h2 id='create_taxon_ancillary'>Create the taxon_ancillary table</h2><span id='topic+create_taxon_ancillary'></span>

<h3>Description</h3>

<p>Create the taxon_ancillary table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_taxon_ancillary(
  L0_flat,
  taxon_id,
  datetime = NULL,
  variable_name,
  unit = NULL,
  author = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_taxon_ancillary_+3A_l0_flat">L0_flat</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The fully joined source L0 dataset, in &quot;flat&quot; format (see details).</p>
</td></tr>
<tr><td><code id="create_taxon_ancillary_+3A_taxon_id">taxon_id</code></td>
<td>
<p>(character) Column in <code>L0_flat</code> containing the identifier assigned to each unique organism at the observation level.</p>
</td></tr>
<tr><td><code id="create_taxon_ancillary_+3A_datetime">datetime</code></td>
<td>
<p>(character) An optional in <code>L0_flat</code> containing the date, and if applicable time, of ancillary location data following the ISO-8601 standard format (e.g. YYYY-MM-DD hh:mm:ss).</p>
</td></tr>
<tr><td><code id="create_taxon_ancillary_+3A_variable_name">variable_name</code></td>
<td>
<p>(character) Columns in <code>L0_flat</code> containing the ancillary taxon data.</p>
</td></tr>
<tr><td><code id="create_taxon_ancillary_+3A_unit">unit</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the units of each <code>variable_name</code> following the column naming convention: unit_&lt;variable_name&gt; (e.g. &quot;unit_average_length&quot;).</p>
</td></tr>
<tr><td><code id="create_taxon_ancillary_+3A_author">author</code></td>
<td>
<p>(character) An optional column in <code>L0_flat</code> containing the person associated with identification of taxa in the taxon table.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects specified columns from <code>L0_flat</code>, converts into long (attribute-value) form by gathering <code>variable_name</code>. Regular expression matching joins <code>unit</code> to any associated <code>variable_name</code> and is listed in the resulting table's &quot;unit&quot; column.
</p>
<p>&quot;flat&quot; format refers to the fully joined source L0 dataset in &quot;wide&quot; form with the exception of the core observation variables, which are in &quot;long&quot; form (i.e. using the variable_name, value, unit columns of the observation table). This &quot;flat&quot; format is the &quot;widest&quot; an L1 ecocomDP dataset can be consistently spread due to the frequent occurrence of L0 source datasets with &gt; 1 core observation variable.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) The taxon_ancillary table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>flat &lt;- ants_L0_flat

taxon_ancillary &lt;- create_taxon_ancillary(
  L0_flat = flat,
  taxon_id = "taxon_id",
  variable_name = c(
    "subfamily", "hl", "rel", "rll", "colony.size", 
    "feeding.preference", "nest.substrate", "primary.habitat", 
    "secondary.habitat", "seed.disperser", "slavemaker.sp", 
    "behavior", "biogeographic.affinity", "source"),
  unit = c("unit_hl", "unit_rel", "unit_rll"))

taxon_ancillary

</code></pre>

<hr>
<h2 id='create_variable_mapping'>Create the variable_mapping table</h2><span id='topic+create_variable_mapping'></span>

<h3>Description</h3>

<p>Create the variable_mapping table
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_variable_mapping(
  observation,
  observation_ancillary = NULL,
  location_ancillary = NULL,
  taxon_ancillary = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_variable_mapping_+3A_observation">observation</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The observation table.</p>
</td></tr>
<tr><td><code id="create_variable_mapping_+3A_observation_ancillary">observation_ancillary</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The optional observation_ancillary table.</p>
</td></tr>
<tr><td><code id="create_variable_mapping_+3A_location_ancillary">location_ancillary</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The optional location_ancillary table.</p>
</td></tr>
<tr><td><code id="create_variable_mapping_+3A_taxon_ancillary">taxon_ancillary</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The optional taxon_ancillary table.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects specified data tables, extracts unique variable_name values from each, converts into long (attribute-value) form with the table name and variable_name values to the resulting table's &quot;table_name&quot; and &quot;variable_name&quot; columns, respectively. The resulting table's &quot;mapped_system&quot;, &quot;mapped_id&quot;, and &quot;mapped_label&quot; are filled with <code>NA</code> and are to be manually filled.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) The variable_mapping table.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>flat &lt;- ants_L0_flat

# Create inputs to variable_mapping()

observation &lt;- create_observation(
  L0_flat = flat, 
  observation_id = "observation_id", 
  event_id = "event_id", 
  package_id = "package_id",
  location_id = "location_id", 
  datetime = "datetime", 
  taxon_id = "taxon_id", 
  variable_name = "variable_name",
  value = "value",
  unit = "unit")

observation_ancillary &lt;- create_observation_ancillary(
  L0_flat = flat,
  observation_id = "observation_id", 
  variable_name = c("trap.type", "trap.num", "moose.cage"))

location_ancillary &lt;- create_location_ancillary(
  L0_flat = flat,
  location_id = "location_id",
  variable_name = "treatment")

taxon_ancillary &lt;- create_taxon_ancillary(
  L0_flat = flat,
  taxon_id = "taxon_id",
  variable_name = c(
    "subfamily", "hl", "rel", "rll", "colony.size", 
    "feeding.preference", "nest.substrate", "primary.habitat", 
    "secondary.habitat", "seed.disperser", "slavemaker.sp", 
    "behavior", "biogeographic.affinity", "source"),
  unit = c("unit_hl", "unit_rel", "unit_rll"))

# Create variable_mapping table

variable_mapping &lt;- create_variable_mapping(
  observation = observation,
  observation_ancillary = observation_ancillary,
  location_ancillary = location_ancillary, 
  taxon_ancillary = taxon_ancillary)

variable_mapping

</code></pre>

<hr>
<h2 id='flatten_data'>Flatten a dataset</h2><span id='topic+flatten_data'></span>

<h3>Description</h3>

<p>Flatten a dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flatten_data(data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flatten_data_+3A_data">data</code></td>
<td>
<p>(list) The dataset object returned by <code>read_data()</code>, or a named list of ecocoomDP tables.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The &quot;flat&quot; format refers to the fully joined source L0 dataset in &quot;wide&quot; form with the exception of the core observation variables, which are in &quot;long&quot; form (i.e. using the variable_name, value, unit columns of the observation table). This &quot;flat&quot; format is the &quot;widest&quot; an L1 ecocomDP dataset can be consistently spread due to the frequent occurrence of L0 source datasets with &gt; 1 core observation variable.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) A single flat table created by joining and spreading all <code>tables</code>, except the observation table. See details for more information on this &quot;flat&quot; format.
</p>


<h3>Note</h3>

<p>Warnings/Errors from <code>flatten_data()</code> can most often be fixed by addressing any validation issues reported by <code>read_data()</code> (e.g. non-unique composite keys).
</p>
<p>Ancillary identifiers are dropped from the returned object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Flatten a dataset object
flat &lt;- flatten_data(ants_L1)
flat

# Flatten a list of tables
tables &lt;- ants_L1$tables
flat &lt;- flatten_data(tables)
flat

</code></pre>

<hr>
<h2 id='plot_sample_space_time'>Plot dates and times samples were collected or observations were made</h2><span id='topic+plot_sample_space_time'></span>

<h3>Description</h3>

<p>Plot dates and times samples were collected or observations were made
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_sample_space_time(
  data,
  id = NA_character_,
  alpha = 1,
  color_var = "package_id",
  shape_var = "package_id",
  observation = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_sample_space_time_+3A_data">data</code></td>
<td>
<p>(list or tbl_df, tbl, data.frame) The dataset object returned by <code>read_data()</code>, a named list of tables containing the observation table, or a flat table containing columns of the observation table.</p>
</td></tr>
<tr><td><code id="plot_sample_space_time_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles. Is automatically assigned when <code>data</code> is a dataset object containing the <code>id</code> field, or is a table containing the package_id column.</p>
</td></tr>
<tr><td><code id="plot_sample_space_time_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Alpha-transparency scale of data points. Useful when many data points overlap. Allowed values are between 0 and 1, where 1 is 100% opaque. Default is 1.</p>
</td></tr>
<tr><td><code id="plot_sample_space_time_+3A_color_var">color_var</code></td>
<td>
<p>(character) Name of column to use to assign colors to the points on the plot</p>
</td></tr>
<tr><td><code id="plot_sample_space_time_+3A_shape_var">shape_var</code></td>
<td>
<p>(character) Name of column to use to assign shapes to the points on the plot</p>
</td></tr>
<tr><td><code id="plot_sample_space_time_+3A_observation">observation</code></td>
<td>
<p>(tbl_df, tbl, data.frame) DEPRECATED: Use <code>data</code> instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> parameter accepts a range of input types but ultimately requires the 9 columns of the observation table.
</p>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read a dataset of interest
dataset &lt;- read_data("edi.193.5")

# Plot the dataset
plot_sample_space_time(dataset)

# Flatten the dataset, manipulate, then plot
dataset %&gt;%
  flatten_data() %&gt;%
  dplyr::filter(lubridate::as_date(datetime) &gt; "2003-07-01") %&gt;%
  dplyr::filter(as.numeric(location_id) &gt; 4) %&gt;%
  plot_sample_space_time()

## End(Not run)

# Plot the example dataset
plot_sample_space_time(ants_L1)

</code></pre>

<hr>
<h2 id='plot_sites'>Plot sites on US map</h2><span id='topic+plot_sites'></span>

<h3>Description</h3>

<p>Plot sites on US map
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_sites(
  data,
  id = NA_character_,
  alpha = 1,
  labels = TRUE,
  color_var = "package_id",
  shape_var = "package_id"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_sites_+3A_data">data</code></td>
<td>
<p>(list or tbl_df, tbl, data.frame) The dataset object returned by <code>read_data()</code>, a named list of tables containing the observation and taxon tables, or a flat table containing columns of the observation and location tables.</p>
</td></tr>
<tr><td><code id="plot_sites_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles. Is automatically assigned when <code>data</code> is a dataset object containing the <code>id</code> field, or is a table containing the package_id column.</p>
</td></tr>
<tr><td><code id="plot_sites_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Alpha-transparency scale of data points. Useful when many data points overlap. Allowed values are between 0 and 1, where 1 is 100% opaque. Default is 1.</p>
</td></tr>
<tr><td><code id="plot_sites_+3A_labels">labels</code></td>
<td>
<p>(logical) Argument to show labels of each US state. Default is TRUE.</p>
</td></tr>
<tr><td><code id="plot_sites_+3A_color_var">color_var</code></td>
<td>
<p>(character) Name of column to use to assign colors to the points on the plot</p>
</td></tr>
<tr><td><code id="plot_sites_+3A_shape_var">shape_var</code></td>
<td>
<p>(character) Name of column to use to assign shapes to the points on the plot</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> parameter accepts a range of input types but ultimately requires the 14 columns of the combined observation and location tables.
</p>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(dplyr)
# Read a dataset of interest
dataset &lt;- read_data("edi.193.5")

# Plot the dataset
plot_sites(dataset)

# Flatten dataset then plot
dataset %&gt;%
 flatten_data() %&gt;%
 plot_sites()

# Download a NEON dataset
dataset2 &lt;- read_data(
 id = "neon.ecocomdp.20120.001.001",
 site= c('COMO','LECO'), 
 startdate = "2017-06",
 enddate = "2021-03",
 token = Sys.getenv("NEON_TOKEN"), # option to use a NEON token
 check.size = FALSE)

# Combine the two datasets and plot. This requires the datasets be first
# flattened and then stacked.
flattened_data1 &lt;- dataset %&gt;% flatten_data()
flattened_data2 &lt;- dataset2 %&gt;% flatten_data()
stacked_data &lt;- bind_rows(flattened_data1,flattened_data2)
plot_sites(stacked_data)

## End(Not run)

# Plot the example dataset
plot_sites(ants_L1)

</code></pre>

<hr>
<h2 id='plot_taxa_abund'>Plot mean taxa abundances per 'observation_id'</h2><span id='topic+plot_taxa_abund'></span>

<h3>Description</h3>

<p>Plot taxon abundances averaged across observation records for each taxon. Abundances are reported using the units provided in the dataset. In some cases, these counts are not standardized to sampling effort.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_taxa_abund(
  data,
  id = NA_character_,
  min_relative_abundance = 0,
  trans = "identity",
  facet_var = NA_character_,
  color_var = NA_character_,
  facet_scales = "free",
  alpha = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_taxa_abund_+3A_data">data</code></td>
<td>
<p>(list or tbl_df, tbl, data.frame) The dataset object returned by <code>read_data()</code>, a named list of tables containing the observation and taxon tables, or a flat table containing columns of the observation and taxon tables.</p>
</td></tr>
<tr><td><code id="plot_taxa_abund_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles. Is automatically assigned when <code>data</code> is a dataset object containing the <code>id</code> field, or is a table containing the package_id column.</p>
</td></tr>
<tr><td><code id="plot_taxa_abund_+3A_min_relative_abundance">min_relative_abundance</code></td>
<td>
<p>(numeric) Minimum relative abundance allowed for taxa included in the plot; a value between 0 and 1, inclusive.</p>
</td></tr>
<tr><td><code id="plot_taxa_abund_+3A_trans">trans</code></td>
<td>
<p>(character) Define the transform applied to the response variable; &quot;identity&quot; is default, &quot;log1p&quot; is x+1 transform. Built-in transformations include &quot;asn&quot;, &quot;atanh&quot;, &quot;boxcox&quot;, &quot;date&quot;, &quot;exp&quot;, &quot;hms&quot;, &quot;identity&quot;, &quot;log&quot;, &quot;log10&quot;, &quot;log1p&quot;, &quot;log2&quot;, &quot;logit&quot;, &quot;modulus&quot;, &quot;probability&quot;, &quot;probit&quot;, &quot;pseudo_log&quot;, &quot;reciprocal&quot;, &quot;reverse&quot;, &quot;sqrt&quot; and &quot;time&quot;.</p>
</td></tr>
<tr><td><code id="plot_taxa_abund_+3A_facet_var">facet_var</code></td>
<td>
<p>(character) Name of column to use for faceting. Must be a column of the observation or taxon table.</p>
</td></tr>
<tr><td><code id="plot_taxa_abund_+3A_color_var">color_var</code></td>
<td>
<p>(character) Name of column to use for plot colors.</p>
</td></tr>
<tr><td><code id="plot_taxa_abund_+3A_facet_scales">facet_scales</code></td>
<td>
<p>(character) Should scales be free (&quot;free&quot;, default value), fixed (&quot;fixed&quot;), or free in one dimension (&quot;free_x&quot;, &quot;free_y&quot;)?</p>
</td></tr>
<tr><td><code id="plot_taxa_abund_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Alpha-transparency scale of data points. Useful when many data points overlap. Allowed values are between 0 and 1, where 1 is 100% opaque. Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> parameter accepts a range of input types but ultimately requires the 13 columns of the combined observation and taxon tables.
</p>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read a dataset of interest
dataset &lt;- read_data("edi.193.5")

# plot ecocomDP formatted dataset
plot_taxa_abund(dataset)

# plot flattened ecocomDP dataset, log(x+1) transform abundances
plot_taxa_abund(
  data = flatten_data(dataset),
  trans = "log1p")

# facet by location color by taxon_rank, log 10 transform
plot_taxa_abund(
  data = dataset,
  facet_var = "location_id",
  color_var = "taxon_rank",
  trans = "log10")

# facet by location, minimum rel. abund = 0.05, log 10 transform
plot_taxa_abund(
  data = dataset,
  facet_var = "location_id",
  min_relative_abundance = 0.05,
  trans = "log1p")

# color by location, log 10 transform
plot_taxa_abund(
  data = dataset,
  color_var = "location_id",
  trans = "log10")

# tidy syntax, flatten then filter data by date
dataset %&gt;%
  flatten_data() %&gt;%
  dplyr::filter(
    lubridate::as_date(datetime) &gt; "2003-07-01") %&gt;%
  plot_taxa_abund(
    trans = "log1p",
    min_relative_abundance = 0.01)

## End(Not run)

# Plot the example dataset
plot_taxa_abund(ants_L1)

</code></pre>

<hr>
<h2 id='plot_taxa_accum_sites'>Plot taxa accumulation by site accumulation</h2><span id='topic+plot_taxa_accum_sites'></span>

<h3>Description</h3>

<p>Plot taxa accumulation by site accumulation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_taxa_accum_sites(data, id = NA_character_, alpha = 1, observation = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_taxa_accum_sites_+3A_data">data</code></td>
<td>
<p>(list or tbl_df, tbl, data.frame) The dataset object returned by <code>read_data()</code>, a named list of tables containing the observation table, or a flat table containing columns of the observation table.</p>
</td></tr>
<tr><td><code id="plot_taxa_accum_sites_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles. Is automatically assigned when <code>data</code> is a dataset object containing the <code>id</code> field, or is a table containing the package_id column.</p>
</td></tr>
<tr><td><code id="plot_taxa_accum_sites_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Alpha-transparency scale of data points. Useful when many data points overlap. Allowed values are between 0 and 1, where 1 is 100% opaque. Default is 1.</p>
</td></tr>
<tr><td><code id="plot_taxa_accum_sites_+3A_observation">observation</code></td>
<td>
<p>(tbl_df, tbl, data.frame) DEPRECATED: Use <code>data</code> instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> parameter accepts a range of input types but ultimately requires the 9 columns of the observation table.
</p>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read a dataset of interest
dataset &lt;- read_data("edi.193.5")

# Plot the dataset
plot_taxa_accum_sites(dataset)

# Flatten the dataset, manipulate, then plot
dataset %&gt;%
  flatten_data() %&gt;%
  dplyr::filter(lubridate::as_date(datetime) &gt; "2003-07-01") %&gt;%
  plot_taxa_accum_sites()

# Plot from the observation table directly
plot_taxa_accum_sites(dataset$tables$observation)

## End(Not run)

# Plot the example dataset
plot_taxa_accum_sites(ants_L1)

</code></pre>

<hr>
<h2 id='plot_taxa_accum_time'>Plot taxa accumulation through time</h2><span id='topic+plot_taxa_accum_time'></span>

<h3>Description</h3>

<p>Plot taxa accumulation through time
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_taxa_accum_time(data, id = NA_character_, alpha = 1, observation = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_taxa_accum_time_+3A_data">data</code></td>
<td>
<p>(list or tbl_df, tbl, data.frame) The dataset object returned by <code>read_data()</code>, a named list of tables containing the observation table, or a flat table containing columns of the observation table.</p>
</td></tr>
<tr><td><code id="plot_taxa_accum_time_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles. Is automatically assigned when <code>data</code> is a dataset object containing the <code>id</code> field, or is a table containing the package_id column.</p>
</td></tr>
<tr><td><code id="plot_taxa_accum_time_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Alpha-transparency scale of data points. Useful when many data points overlap. Allowed values are between 0 and 1, where 1 is 100% opaque. Default is 1.</p>
</td></tr>
<tr><td><code id="plot_taxa_accum_time_+3A_observation">observation</code></td>
<td>
<p>(tbl_df, tbl, data.frame) DEPRECATED: Use <code>data</code> instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> parameter accepts a range of input types but ultimately requires the 9 columns of the observation table.
</p>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read a dataset of interest
dataset &lt;- read_data("edi.193.5")

# Plot the dataset
plot_taxa_accum_time(dataset)

# Flatten the dataset, manipulate, then plot
dataset %&gt;%
  flatten_data() %&gt;%
  dplyr::filter(lubridate::as_date(datetime) &gt; "2003-07-01") %&gt;%
  plot_taxa_accum_time()

# Plot from the observation table directly
plot_taxa_accum_time(dataset$tables$observation)

## End(Not run)

# Plot the example dataset
plot_taxa_accum_time(ants_L1)

</code></pre>

<hr>
<h2 id='plot_taxa_diversity'>Plot diversity (taxa richness) through time</h2><span id='topic+plot_taxa_diversity'></span>

<h3>Description</h3>

<p>Plot diversity (taxa richness) through time
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_taxa_diversity(
  data,
  id = NA_character_,
  time_window_size = "day",
  observation = NULL,
  alpha = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_taxa_diversity_+3A_data">data</code></td>
<td>
<p>(list or tbl_df, tbl, data.frame) The dataset object returned by <code>read_data()</code>, a named list of tables containing the observation table, or a flat table containing columns of the observation table.</p>
</td></tr>
<tr><td><code id="plot_taxa_diversity_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles. Is automatically assigned when <code>data</code> is a dataset object containing the <code>id</code> field, or is a table containing the package_id column.</p>
</td></tr>
<tr><td><code id="plot_taxa_diversity_+3A_time_window_size">time_window_size</code></td>
<td>
<p>(character) Define the time window over which to aggregate observations for calculating richness. Can be: &quot;day&quot; or &quot;year&quot;</p>
</td></tr>
<tr><td><code id="plot_taxa_diversity_+3A_observation">observation</code></td>
<td>
<p>(tbl_df, tbl, data.frame) DEPRECATED: Use <code>data</code> instead.</p>
</td></tr>
<tr><td><code id="plot_taxa_diversity_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Alpha-transparency scale of data points. Useful when many data points overlap. Allowed values are between 0 and 1, where 1 is 100% opaque. Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> parameter accepts a range of input types but ultimately requires the 9 columns of the observation table.
</p>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read a dataset of interest
dataset &lt;- read_data("edi.193.5")

# Plot the dataset
plot_taxa_diversity(dataset)

# Plot the dataset with observations aggregated by year
plot_taxa_diversity(dataset, time_window_size = "year")

# Flatten the dataset, manipulate, then plot
dataset %&gt;%
  flatten_data() %&gt;%
  dplyr::filter(
    lubridate::as_date(datetime) &gt; "2007-01-01") %&gt;%
  plot_taxa_diversity()

# Plot from the observation table directly
plot_taxa_diversity(dataset$tables$observation)

## End(Not run)

# Plot the example dataset
plot_taxa_diversity(ants_L1)

</code></pre>

<hr>
<h2 id='plot_taxa_occur_freq'>Plot taxon occurrence frequencies</h2><span id='topic+plot_taxa_occur_freq'></span>

<h3>Description</h3>

<p>Plot taxon occurrence frequences as the number of 'event_id' by 'location_id' combinations in which a taxon is observed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_taxa_occur_freq(
  data,
  id = NA_character_,
  min_occurrence = 0,
  facet_var = NA_character_,
  color_var = NA_character_,
  facet_scales = "free",
  alpha = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_taxa_occur_freq_+3A_data">data</code></td>
<td>
<p>(list or tbl_df, tbl, data.frame) The dataset object returned by <code>read_data()</code>, a named list of tables containing the observation and taxon tables, or a flat table containing columns of the observation and taxon tables.</p>
</td></tr>
<tr><td><code id="plot_taxa_occur_freq_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles. Is automatically assigned when <code>data</code> is a dataset object containing the <code>id</code> field, or is a table containing the package_id column.</p>
</td></tr>
<tr><td><code id="plot_taxa_occur_freq_+3A_min_occurrence">min_occurrence</code></td>
<td>
<p>(numeric) Minimum number of occurrences allowed for taxa included in the plot.</p>
</td></tr>
<tr><td><code id="plot_taxa_occur_freq_+3A_facet_var">facet_var</code></td>
<td>
<p>(character) Name of column to use for faceting. Must be a column of the observation or taxon table.</p>
</td></tr>
<tr><td><code id="plot_taxa_occur_freq_+3A_color_var">color_var</code></td>
<td>
<p>(character) Name of column to use for plot colors.</p>
</td></tr>
<tr><td><code id="plot_taxa_occur_freq_+3A_facet_scales">facet_scales</code></td>
<td>
<p>(character) Should scales be free (&quot;free&quot;, default value), fixed (&quot;fixed&quot;), or free in one dimension (&quot;free_x&quot;, &quot;free_y&quot;)?</p>
</td></tr>
<tr><td><code id="plot_taxa_occur_freq_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Alpha-transparency scale of data points. Useful when many data points overlap. Allowed values are between 0 and 1, where 1 is 100% opaque. Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> parameter accepts a range of input types but ultimately requires the 13 columns of the combined observation and taxon tables.
</p>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read a dataset of interest
dataset &lt;- read_data("edi.193.5")

# Plot the dataset
plot_taxa_occur_freq(dataset)

# Facet by location and color by taxon_rank
plot_taxa_occur_freq(
  data = dataset,
  facet_var = "location_id",
  color_var = "taxon_rank")

# Color by location and only include taxa with &gt;= 5 occurrences
plot_taxa_occur_freq(
  data = dataset,
  color_var = "location_id",
  min_occurrence = 5)

# Flatten, filter using a time cutoff, then plot
dataset %&gt;%
  flatten_data() %&gt;%
  dplyr::filter(lubridate::as_date(datetime) &gt; "2003-07-01") %&gt;%
  plot_taxa_occur_freq()

## End(Not run)
# Plot the example dataset
plot_taxa_occur_freq(ants_L1)

</code></pre>

<hr>
<h2 id='plot_taxa_rank'>Plot taxa ranks</h2><span id='topic+plot_taxa_rank'></span>

<h3>Description</h3>

<p>Plot the number of observations that use each taxonomic rank in the dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_taxa_rank(
  data,
  id = NA_character_,
  facet_var = NA_character_,
  facet_scales = "free_x",
  alpha = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_taxa_rank_+3A_data">data</code></td>
<td>
<p>(list or tbl_df, tbl, data.frame) The dataset object returned by <code>read_data()</code>, a named list of tables containing the observation and taxon tables, or a flat table containing columns of the observation and taxon tables.</p>
</td></tr>
<tr><td><code id="plot_taxa_rank_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles. Is automatically assigned when <code>data</code> is a dataset object containing the <code>id</code> field, or is a table containing the package_id column.</p>
</td></tr>
<tr><td><code id="plot_taxa_rank_+3A_facet_var">facet_var</code></td>
<td>
<p>(character) Name of column to use for faceting. Must be a column of the observation or taxon table.</p>
</td></tr>
<tr><td><code id="plot_taxa_rank_+3A_facet_scales">facet_scales</code></td>
<td>
<p>(character) Should scales be free (&quot;free&quot;, default value), fixed (&quot;fixed&quot;), or free in one dimension (&quot;free_x&quot;, &quot;free_y&quot;)?</p>
</td></tr>
<tr><td><code id="plot_taxa_rank_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Alpha-transparency scale of data points. Useful when many data points overlap. Allowed values are between 0 and 1, where 1 is 100% opaque. Default is 1.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> parameter accepts a range of input types but ultimately requires the 13 columns of the combined observation and taxon tables.
</p>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read a dataset of interest
dataset &lt;- read_data(
  id = "neon.ecocomdp.20120.001.001",
  site= c('COMO','LECO'),
  startdate = "2017-06",
  enddate = "2019-09",
  check.size = FALSE)

# Plot the dataset
plot_taxa_rank(dataset)

# Plot with facet by location
plot_taxa_rank(dataset, facet_var = "location_id")

# Flatten the dataset, manipulate, then plot
dataset %&gt;%
  flatten_data() %&gt;%
  dplyr::filter(lubridate::as_date(datetime) &gt; "2003-07-01") %&gt;%
  dplyr::filter(grepl("COMO",location_id)) %&gt;%
  plot_taxa_rank()

## End(Not run)

# Plot the example dataset
plot_taxa_rank(ants_L1)

</code></pre>

<hr>
<h2 id='plot_taxa_sample_time'>Plot dates and times samples were taken (DEPRECATED)</h2><span id='topic+plot_taxa_sample_time'></span>

<h3>Description</h3>

<p>This function has been deprecated. Use <code>plot_sample_space_time()</code> instead.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_taxa_sample_time(observation, id = NA_character_, alpha = 1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_taxa_sample_time_+3A_observation">observation</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The observation table.</p>
</td></tr>
<tr><td><code id="plot_taxa_sample_time_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles.</p>
</td></tr>
<tr><td><code id="plot_taxa_sample_time_+3A_alpha">alpha</code></td>
<td>
<p>(numeric) Alpha-transparency scale of data points. Useful when many data points overlap. Allowed values are between 0 and 1, where 1 is 100% opaque. Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device
</p>

<hr>
<h2 id='plot_taxa_shared_sites'>Plot number of unique taxa shared across sites</h2><span id='topic+plot_taxa_shared_sites'></span>

<h3>Description</h3>

<p>Plot number of unique taxa shared across sites
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_taxa_shared_sites(data, id = NA_character_, observation = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_taxa_shared_sites_+3A_data">data</code></td>
<td>
<p>(list or tbl_df, tbl, data.frame) The dataset object returned by <code>read_data()</code>, a named list of tables containing the observation table, or a flat table containing columns of the observation table.</p>
</td></tr>
<tr><td><code id="plot_taxa_shared_sites_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to be used in plot subtitles. Is automatically assigned when <code>data</code> is a dataset object containing the <code>id</code> field, or is a table containing the package_id column.</p>
</td></tr>
<tr><td><code id="plot_taxa_shared_sites_+3A_observation">observation</code></td>
<td>
<p>(tbl_df, tbl, data.frame) DEPRECATED: Use <code>data</code> instead.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>data</code> parameter accepts a range of input types but ultimately requires the 9 columns of the observation table.
</p>


<h3>Value</h3>

<p>(gg, ggplot) A gg, ggplot object if assigned to a variable, otherwise a plot to your active graphics device
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read a dataset of interest
dataset &lt;- read_data("edi.193.5")

# Plot the dataset
plot_taxa_shared_sites(dataset)

# Flatten the dataset, manipulate, then plot
dataset %&gt;%
  flatten_data() %&gt;%
  dplyr::filter(lubridate::as_date(datetime) &gt; "2003-07-01") %&gt;%
  dplyr::filter(as.numeric(location_id) &gt; 4) %&gt;%
  plot_taxa_shared_sites()

# Plot from the observation table directly
plot_taxa_shared_sites(dataset$tables$observation)

## End(Not run)

# Plot the example dataset
plot_taxa_shared_sites(ants_L1)

</code></pre>

<hr>
<h2 id='read_data'>Read published data</h2><span id='topic+read_data'></span>

<h3>Description</h3>

<p>Read published data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_data(
  id = NULL,
  parse_datetime = TRUE,
  unique_keys = FALSE,
  site = "all",
  startdate = NA,
  enddate = NA,
  package = "basic",
  check.size = FALSE,
  nCores = 1,
  forceParallel = FALSE,
  token = NA,
  neon.data.save.dir = NULL,
  neon.data.read.path = NULL,
  ...,
  from = NULL,
  format = "new"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="read_data_+3A_id">id</code></td>
<td>
<p>(character) Identifier of dataset to read. Identifiers are listed in the &quot;id&quot; column of the <code>search_data()</code> output. Older versions of datasets can be read, but a warning is issued.</p>
</td></tr>
<tr><td><code id="read_data_+3A_parse_datetime">parse_datetime</code></td>
<td>
<p>(logical) Parse datetime values if TRUE, otherwise return as character strings.</p>
</td></tr>
<tr><td><code id="read_data_+3A_unique_keys">unique_keys</code></td>
<td>
<p>(logical) Whether to create globally unique primary keys (and associated foreign keys). Useful in maintaining referential integrity when working with multiple datasets. If TRUE, <code>id</code> is appended to each table's primary key and associated foreign key. Default is FALSE.</p>
</td></tr>
<tr><td><code id="read_data_+3A_site">site</code></td>
<td>
<p>(character) For NEON data, a character vector of site codes to filter data on. Sites are listed in the &quot;sites&quot; column of the <code>search_data()</code> output. Defaults to &quot;all&quot;, meaning all sites.</p>
</td></tr>
<tr><td><code id="read_data_+3A_startdate">startdate</code></td>
<td>
<p>(character) For NEON data, the start date to filter on in the form YYYY-MM. Defaults to NA, meaning all available dates.</p>
</td></tr>
<tr><td><code id="read_data_+3A_enddate">enddate</code></td>
<td>
<p>(character) For NEON data, the end date to filter on in the form YYYY-MM. Defaults to NA, meaning all available dates.</p>
</td></tr>
<tr><td><code id="read_data_+3A_package">package</code></td>
<td>
<p>(character) For NEON data, either 'basic' or 'expanded', indicating which data package to download. Defaults to basic.</p>
</td></tr>
<tr><td><code id="read_data_+3A_check.size">check.size</code></td>
<td>
<p>(logical) For NEON data, should the user approve the total file size before downloading? Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="read_data_+3A_ncores">nCores</code></td>
<td>
<p>(integer) For NEON data, the number of cores to parallelize the stacking procedure. Defaults to 1.</p>
</td></tr>
<tr><td><code id="read_data_+3A_forceparallel">forceParallel</code></td>
<td>
<p>(logical) For NEON data, if the data volume to be processed does not meet minimum requirements to run in parallel, this overrides. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="read_data_+3A_token">token</code></td>
<td>
<p>(character) For NEON data, a user specific API token (generated within neon.datascience user accounts).</p>
</td></tr>
<tr><td><code id="read_data_+3A_neon.data.save.dir">neon.data.save.dir</code></td>
<td>
<p>(character) For NEON data, an optional and experimental argument (i.e. may not be supported in future releases), indicating the directory where NEON source data should be saved upon download from the NEON API. Data are downloaded using <code>neonUtilities::loadByProduct()</code> and saved in this directory as an .rds file. The filename will follow the format &lt;NEON data product ID&gt;_&lt;timestamp&gt;.rds</p>
</td></tr>
<tr><td><code id="read_data_+3A_neon.data.read.path">neon.data.read.path</code></td>
<td>
<p>(character) For NEON data, an optional and experimental argument (i.e. may not be supported in future releases), defining a path to read in an .rds file of 'stacked NEON data' from <code>neonUtilities::loadByProduct()</code>. See details below for more information.</p>
</td></tr>
<tr><td><code id="read_data_+3A_...">...</code></td>
<td>
<p>For NEON data, other arguments to <code>neonUtilities::loadByProduct()</code></p>
</td></tr>
<tr><td><code id="read_data_+3A_from">from</code></td>
<td>
<p>(character) Full path of file to be read (if .rds), or path to directory containing saved datasets (if .csv).</p>
</td></tr>
<tr><td><code id="read_data_+3A_format">format</code></td>
<td>
<p>(character) Format of returned object, which can be: &quot;new&quot; (the new implementation) or &quot;old&quot; (the original implementation; deprecated). In the new format, the top most level of nesting containing the &quot;id&quot; field has been moved to the same level as the &quot;tables&quot;, &quot;metadata&quot;, and &quot;validation_issues&quot; fields.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Validation checks are applied to each dataset ensuring it complies with the ecocomDP model. A warning is issued when any validation checks fail. All datasets are returned, even if they fail validation.
</p>
<p>Column classes are coerced to those defined in the ecocomDP specification.
</p>
<p>Validation happens each time files are read, from source APIs or local environments.
</p>
<p>Details for <code>read_data()</code> function regarding NEON data: Using this function to read data with an <code>id</code> that begins with &quot;neon.ecocomdp&quot; will result in a query to download NEON data from the NEON Data Portal API using <code>neonUtilities::loadByProduct()</code>. If a query includes provisional data (or if you are not sure if the query includes provisional data), we recommend saving a copy of the data in the original format provided by NEON in addition to the derived ecocomDP data package. To do this, provide a directory path using the <code>neon.data.read.path</code> argument. For example, the query <code>my_ecocomdp_data &lt;- read_data(id = "neon.ecocomdp.10022.001.001", neon.data.save.dir = "my_neon_data")</code> will download the data for NEON Data Product ID DP1.10022.001 (ground beetles in pitfall traps) and convert it to the ecocomDP data model. In doing so, a copy of the original NEON download will be saved in the directory &quot;my_ neon_data with the filename 
&quot;DP1.10022.001_&lt;timestamp&gt;.RDS&quot; and the derived data package in the ecocomDP format will be stored in your R environment in an object named &quot;my_ecocomdp_data&quot;. Further, if you wish to reload a previously downloaded NEON dataset into the ecocomDP format, you can do so using <code>my_ecocomdp_data &lt;- read_data(id = "neon.ecocomdp.10022.001.001", neon.data.read.path = 
    "my_neon_data/DP1.10022.001_&lt;timestamp&gt;.RDS")</code>
</p>
<p>Provisional NEON data. Despite NEON's controlled data entry, at times, errors are found in published data; for example, an analytical lab may adjust its calibration curve and re-calculate past analyses, or field scientists may discover a past misidentification. In these cases, Level 0 data are edited and the data are re-processed to Level 1 and re-published. Published data files include a time stamp in the file name; a new time stamp indicates data have been re-published and may contain differences from previously published data. Data are subject to re-processing at any time during an initial provisional period; data releases are never re-processed. All records downloaded from the NEON API will have a &quot;release&quot; field. For any provisional record, the value of this field will be &quot;PROVISIONAL&quot;, otherwise, this field will have a value indicating the version of the release to which the record belongs. More details can be found at https://www.neonscience.org/data-samples/data-management/data-revisions-releases.
</p>


<h3>Value</h3>

<p>(list) A dataset with the structure:
</p>

<ul>
<li><p> id - Dataset identifier
</p>
</li>
<li><p> metadata - List of info about the dataset. NOTE: This object is underdevelopment and content may change in future releases.
</p>
</li>
<li><p> tables - List of dataset tables as data.frames.
</p>
</li>
<li><p> validation_issues - List of validation issues. If the dataset fails any validation checks, then descriptions of each issue are listed here.
</p>
</li></ul>



<h3>Note</h3>

<p>This function may not work between 01:00 - 03:00 UTC on Wednesdays due to regular maintenance of the EDI Data Repository.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Read from EDI
dataset &lt;- read_data("edi.193.5")
str(dataset, max.level = 2)

# Read from NEON (full dataset)
dataset &lt;- read_data("neon.ecocomdp.20120.001.001")

# Read from NEON with filters (partial dataset)
dataset &lt;- read_data(
 id = "neon.ecocomdp.20120.001.001", 
 site = c("COMO", "LECO", "SUGG"),
 startdate = "2017-06", 
 enddate = "2019-09",
 check.size = FALSE)

# Read with datetimes as character
dataset &lt;- read_data("edi.193.5", parse_datetime = FALSE)
is.character(dataset$tables$observation$datetime)

# Read from saved .rds
save_data(dataset, tempdir())
dataset &lt;- read_data(from = paste0(tempdir(), "/dataset.rds"))

# Read from saved .csv
save_data(dataset, tempdir(), type = ".csv")# Save as .csv
dataset &lt;- read_data(from = tempdir())

## End(Not run)

</code></pre>

<hr>
<h2 id='save_data'>Save a dataset</h2><span id='topic+save_data'></span>

<h3>Description</h3>

<p>Save a dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>save_data(dataset, path, type = ".rds", name = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="save_data_+3A_dataset">dataset</code></td>
<td>
<p>(list) One or more datasets of the structure returned by <code>read_data()</code>. Name of the <code>dataset</code> object will become the file name if <code>name</code> is not used.</p>
</td></tr>
<tr><td><code id="save_data_+3A_path">path</code></td>
<td>
<p>(character) Path to the directory in which <code>dataset</code> will be written.</p>
</td></tr>
<tr><td><code id="save_data_+3A_type">type</code></td>
<td>
<p>(character) Type of file to save the <code>dataset</code> as. Default is &quot;.rds&quot; but can also be &quot;.csv&quot;. Note: metadata and validation_issues are lost when using &quot;.csv&quot;.</p>
</td></tr>
<tr><td><code id="save_data_+3A_name">name</code></td>
<td>
<p>(character) An optional argument for setting the saved file name (for .rds) if you'd like it to be different than <code>dataset</code>'s object name.</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>.rds</code></td>
<td>
<p>If <code>type = ".rds"</code>, then an .rds representation of <code>dataset</code> is returned.</p>
</td></tr>
<tr><td><code>.csv</code></td>
<td>
<p>If <code>type = ".csv"</code>, then an set of .csv files are written to a sub-directory of <code>path</code> named after the data package/product ID.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>Subsequent calls won't overwrite files or directories
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create directory for the data
mypath &lt;- paste0(tempdir(), "/data")
dir.create(mypath)

# Save as .rds
save_data(ants_L1, mypath)
dir(mypath)

# Save as .rds with the name "mydata"
save_data(ants_L1, mypath, name = "mydata")
dir(mypath)

# Save as .csv
save_data(ants_L1, mypath, type = ".csv")
dir(mypath)

## Not run: 
# Save multiple datasets
ids &lt;- c("edi.193.5", "edi.303.2", "edi.290.2")
datasets &lt;- lapply(ids, read_data)
save_data(datasets, mypath)
dir(mypath)

## End(Not run)

# Clean up
unlink(mypath, recursive = TRUE)

</code></pre>

<hr>
<h2 id='search_data'>Search published data</h2><span id='topic+search_data'></span>

<h3>Description</h3>

<p>Search published data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>search_data(text, taxa, num_taxa, num_years, sd_years, area, boolean = "AND")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="search_data_+3A_text">text</code></td>
<td>
<p>(character) Text to search for in dataset titles, descriptions, and abstracts. Datasets matching any exact words or phrase will be returned. Can be a regular expression as used by <code>stringr::str_detect()</code>. Is not case sensitive. Works with <code>boolean</code>.</p>
</td></tr>
<tr><td><code id="search_data_+3A_taxa">taxa</code></td>
<td>
<p>(character) Taxonomic names to search on. To effectively search the taxonomic tree, it is advisable to start with specific taxonomic names and then gradually broaden the search to higher rank levels when needed. For instance, if searching for &quot;Astragalus gracilis&quot; (species) doesn't produce any results, try expanding the search to &quot;Astragalus&quot; (Genus), &quot;Fabaceae&quot; (Family), and so on. This approach accounts for variations in organism identification, ensuring a more comprehensive exploration of the taxonomic hierarchy.</p>
</td></tr>
<tr><td><code id="search_data_+3A_num_taxa">num_taxa</code></td>
<td>
<p>(numeric) Minimum and maximum number of taxa the dataset should contain. Any datasets within this range will be returned.</p>
</td></tr>
<tr><td><code id="search_data_+3A_num_years">num_years</code></td>
<td>
<p>(numeric) Minimum and maximum number of years sampled the dataset should contain. Any datasets within this range will be returned.</p>
</td></tr>
<tr><td><code id="search_data_+3A_sd_years">sd_years</code></td>
<td>
<p>(numeric) Minimum and maximum standard deviation between survey dates (in years). Any datasets within this range will be returned.</p>
</td></tr>
<tr><td><code id="search_data_+3A_area">area</code></td>
<td>
<p>(numeric) Bounding coordinates within which the data should originate. Accepted values are in decimal degrees and in the order: North, East, South, West. Any datasets with overlapping areas or contained points will be returned.</p>
</td></tr>
<tr><td><code id="search_data_+3A_boolean">boolean</code></td>
<td>
<p>(character) Boolean operator to use when searching <code>text</code> and <code>taxa</code>. Supported operators are: &quot;AND&quot;, &quot;OR&quot;. Default is &quot;AND&quot;. Note, other parameters used in a search are combined with an implicit &quot;AND&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Currently, to accommodate multiple L1 versions of NEON data products, search results for a NEON L0 will also list all the L1 versions available for the match. This method is based on the assumption that the summary data among L1 versions is the same, which may need to be addressed in the future. A list of L0 and corresponding L1 identifiers are listed in /inst/L1_versions.txt. Each L1 version is accompanied by qualifying text that's appended to the title, abstract, and descriptions for comprehension of the differences among L1 versions.
</p>


<h3>Value</h3>

<p>(tbl_df, tbl, data.frame) Search results with these feilds:
</p>

<ul>
<li><p> source - Source from which the dataset originates. Currently supported are &quot;EDI&quot; and &quot;NEON&quot;.
</p>
</li>
<li><p> id - Identifier of the dataset.
</p>
</li>
<li><p> title - Title of the dataset.
</p>
</li>
<li><p> description - Description of dataset. Only returned for NEON datasets.
</p>
</li>
<li><p> abstract - Abstract of dataset.
</p>
</li>
<li><p> years - Number of years sampled.
</p>
</li>
<li><p> sampling_interval - Standard deviation between sampling events in years.
</p>
</li>
<li><p> sites - Sites names or abbreviations. Only returned for NEON datasets.
</p>
</li>
<li><p> url - URL to dataset.
</p>
</li>
<li><p> source_id - Identifier of source L0 dataset.
</p>
</li>
<li><p> source_id_url - URL to source L0 dataset.
</p>
</li></ul>



<h3>Note</h3>

<p>This function may not work between 01:00 - 03:00 UTC on Wednesdays due to regular maintenance of the EDI Data Repository.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Empty search returns all available datasets
search_data()

# "text" searches titles, descriptions, and abstracts
search_data(text = "Lake")

# "taxa" searches taxonomic ranks for a match
search_data(taxa = "Plantae")

# "num_years" searches the number of years sampled
search_data(num_years = c(10, 20))

# Use any combination of search fields to find the data you're looking for
search_data(
  text = c("Lake", "River"),
  taxa = c("Plantae", "Animalia"),
  num_taxa = c(0, 10),
  num_years = c(10, 100),
  sd_years = c(.01, 100),
  area = c(47.1, -86.7, 42.5, -92),
  boolean = "OR")

## End(Not run)

</code></pre>

<hr>
<h2 id='validate_data'>Validate tables against the model</h2><span id='topic+validate_data'></span>

<h3>Description</h3>

<p>Validate tables against the model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validate_data(dataset = NULL, path = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="validate_data_+3A_dataset">dataset</code></td>
<td>
<p>(list) A dataset of the structure returned by <code>read_data()</code>.</p>
</td></tr>
<tr><td><code id="validate_data_+3A_path">path</code></td>
<td>
<p>(character) Path to a directory containing ecocomDP tables as files.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Validation checks:
</p>

<ul>
<li><p> File names - File names are the ecocomDP table names.
</p>
</li>
<li><p> Table presence - Required tables are present.
</p>
</li>
<li><p> Column names - Column names of all tables match the model.
</p>
</li>
<li><p> Column presence - Required columns are present.
</p>
</li>
<li><p> Column classes - Column classes match the model specification.
</p>
</li>
<li><p> Datetime format - Date and time formats follow the model specification.
</p>
</li>
<li><p> Primary keys - Primary keys of tables are unique.
</p>
</li>
<li><p> Composite keys - Composite keys (unique constraints) of each table are unique.
</p>
</li>
<li><p> Referential integrity - Foreign keys have a corresponding primary key.
</p>
</li>
<li><p> Coordinate format - Values are in decimal degree format.
</p>
</li>
<li><p> Coordinate range - Values are within -90 to 90 and -180 to 180.
</p>
</li>
<li><p> Elevation - Values are less than Mount Everest (8848 m) and greater than Mariana Trench (-10984 m).
</p>
</li>
<li><p> Variable mapping - variable_name is in table_name.
</p>
</li>
<li><p> Mapped_id - values in mapped_id are valid URIs
</p>
</li></ul>



<h3>Value</h3>

<p>(list) If any checks fail, then a list of validation issues are returned along with a warning. If no issues are found then NULL is returned.
</p>


<h3>Note</h3>

<p>This function is used by ecocomDP creators (to ensure what has been created is valid), maintainers (to improve the quality of archived ecocomDP datasets), and users (to ensure the data being used is free of error).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Write a set of ecocomDP tables to file for validation
mydir &lt;- paste0(tempdir(), "/dataset")
dir.create(mydir)
write_tables(
  path = mydir,
  observation = ants_L1$tables$observation, 
  observation_ancillary = ants_L1$tables$observation_ancillary,
  location = ants_L1$tables$location,
  location_ancillary = ants_L1$tables$location_ancillary,
  taxon = ants_L1$tables$taxon,
  taxon_ancillary = ants_L1$tables$taxon_ancillary,
  dataset_summary = ants_L1$tables$dataset_summary,
  variable_mapping = ants_L1$tables$variable_mapping)

# Validate
validate_data(path = mydir)

# Clean up
unlink(mydir, recursive = TRUE)

## End(Not run)

</code></pre>

<hr>
<h2 id='write_tables'>Write tables to file</h2><span id='topic+write_tables'></span>

<h3>Description</h3>

<p>Write tables to file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_tables(
  path,
  sep = ",",
  observation = NULL,
  location = NULL,
  taxon = NULL,
  dataset_summary = NULL,
  observation_ancillary = NULL,
  location_ancillary = NULL,
  taxon_ancillary = NULL,
  variable_mapping = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="write_tables_+3A_path">path</code></td>
<td>
<p>(character) A path to the directory in which the files will be written.</p>
</td></tr>
<tr><td><code id="write_tables_+3A_sep">sep</code></td>
<td>
<p>(character) Field delimiter to use when writing files. Default is comma.</p>
</td></tr>
<tr><td><code id="write_tables_+3A_observation">observation</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The observation table.</p>
</td></tr>
<tr><td><code id="write_tables_+3A_location">location</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The location table.</p>
</td></tr>
<tr><td><code id="write_tables_+3A_taxon">taxon</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The taxon table.</p>
</td></tr>
<tr><td><code id="write_tables_+3A_dataset_summary">dataset_summary</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The dataset_summary table.</p>
</td></tr>
<tr><td><code id="write_tables_+3A_observation_ancillary">observation_ancillary</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The observation_ancillary table.</p>
</td></tr>
<tr><td><code id="write_tables_+3A_location_ancillary">location_ancillary</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The location_ancillary table.</p>
</td></tr>
<tr><td><code id="write_tables_+3A_taxon_ancillary">taxon_ancillary</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The taxon_ancillary table.</p>
</td></tr>
<tr><td><code id="write_tables_+3A_variable_mapping">variable_mapping</code></td>
<td>
<p>(tbl_df, tbl, data.frame) The variable_mapping table.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>ecocomDP tables as <code>sep</code> delimited files
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create directory for the tables
mypath &lt;- paste0(tempdir(), "/data")
dir.create(mypath)

# Create a couple inputs to write_tables()

flat &lt;- ants_L0_flat

observation &lt;- create_observation(
  L0_flat = flat, 
  observation_id = "observation_id", 
  event_id = "event_id", 
  package_id = "package_id",
  location_id = "location_id", 
  datetime = "datetime", 
  taxon_id = "taxon_id", 
  variable_name = "variable_name",
  value = "value",
  unit = "unit")

observation_ancillary &lt;- create_observation_ancillary(
  L0_flat = flat,
  observation_id = "observation_id", 
  variable_name = c("trap.type", "trap.num", "moose.cage"))

# Write tables to file

write_tables(
  path = mypath, 
  observation = observation, 
  observation_ancillary = observation_ancillary)

dir(mypath)

# Clean up
unlink(mypath, recursive = TRUE)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
