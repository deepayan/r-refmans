<!DOCTYPE html><html lang="en"><head><title>Help for package KRMM</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {KRMM}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#KRMM-package'><p>Kernel Ridge Mixed Model</p></a></li>
<li><a href='#EM_REML_MM'><p>Expectation-Maximization (EM) algorithm for the restricted maximum likelihood (REML) associated to the mixed model</p></a></li>
<li><a href='#Kernel_Ridge_MM'>
<p>Kernel ridge regression in the mixed model framework</p></a></li>
<li><a href='#Predict_kernel_Ridge_MM'>
<p>Predict function for Kernel_Ridge_MM object</p></a></li>
<li><a href='#Tune_kernel_Ridge_MM'><p>Tune kernel ridge regression in the mixed model framework</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Kernel Ridge Mixed Model</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Laval Jacquin [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Laval Jacquin &lt;jacquin.julien@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Solves kernel ridge regression, within the the mixed model framework, for the linear, polynomial, Gaussian, Laplacian and ANOVA kernels. The model components (i.e. fixed and random effects) and variance parameters are estimated using the expectation-maximization (EM) algorithm. All the estimated components and parameters, e.g. BLUP of dual variables and BLUP of random predictor effects for the linear kernel (also known as RR-BLUP), are available. The kernel ridge mixed model (KRMM) is described in Jacquin L, Cao T-V and Ahmadi N (2016) A Unified and Comprehensible View of Parametric and Kernel Methods for Genomic Prediction with Application to Rice. Front. Genet. 7:145. &lt;<a href="https://doi.org/10.3389%2Ffgene.2016.00145">doi:10.3389/fgene.2016.00145</a>&gt;.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats,MASS,kernlab,cvTools,robustbase</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>5.0.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2017-06-03 16:29:07 UTC; laval_jacquin</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2017-06-03 17:46:04 UTC</td>
</tr>
</table>
<hr>
<h2 id='KRMM-package'>Kernel Ridge Mixed Model</h2><span id='topic+KRMM-package'></span>

<h3>Description</h3>

<p>Solves kernel ridge regression, within the the mixed model framework, for the linear, polynomial, Gaussian, Laplacian and ANOVA kernels.
The model components (i.e. fixed and random effects) and variance parameters are estimated using the expectation-maximization (EM) algorithm. 
All the estimated components and parameters, e.g. BLUP of dual variables and BLUP of random predictor effects for the linear kernel (also known as RR-BLUP), are available. 
The kernel ridge mixed model (KRMM) is described in Jacquin L, Cao T-V and Ahmadi N (2016) A Unified and Comprehensible View of Parametric and Kernel Methods for Genomic Prediction with Application to Rice. Front. Genet. 7:145.</p>


<h3>Details</h3>

<p>This package solves kernel ridge regression for various kernels within the following mixed model framework: Y =X*Beta + Z*U + E, where X and Z correspond to the design matrices of predictors with fixed and random effects respectively.
The functions provided with this package are Kernel_Ridge_MM, Tune_kernel_Ridge_MM, Predict_kernel_Ridge_MM and EM_REML_MM.
</p>


<h3>Author(s)</h3>

<p>Laval Jacquin
Maintainer: Laval Jacquin &lt;jacquin.julien@gmail.com&gt;
</p>


<h3>References</h3>

<p>Jacquin et al. (2016). A unified and comprehensible view of parametric and kernel methods for genomic prediction with application to rice (in peer review).
</p>
<p>Robinson, G. K. (1991). That blup is a good thing: the estimation of random effects. Statistical science, 534 15-32 
</p>
<p>Foulley, J.-L. (2002). Algorithme em: théorie et application au modèle mixte. Journal de la Société française de Statistique 143, 57-109
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

library(KRMM)

### SIMULATE DATA 
set.seed(123)
p=200
N=100

beta=rnorm(p, mean=0, sd=1.0)
X=matrix(runif(p*N, min=0, max=1), ncol=p, byrow=TRUE)  #X: covariates (i.e. predictors)

f=X%*%beta                    #f: data generating process (i.e. DGP)
E=rnorm(N, mean=0, sd=0.5)

Y=f+E                           #Y: observed response data

hist(f)
hist(beta)
Nb_train=floor((2/3)*N)

###======================================================================###
### CREATE TRAINING AND TARGET SETS FOR RESPONSE AND PREDICTOR VARIABLES ###
###======================================================================###

Index_train=sample(1:N, size=Nb_train, replace=FALSE)

### Covariates (i.e. predictors) for training and target sets

Predictors_train=X[Index_train, ]
Response_train=Y[Index_train]

Predictors_target=X[-Index_train, ]
True_value_target=f[-Index_train]    #True value (generated by DGP) we want to predict

###=================================================================================###
### PREDICTION WITH KERNEL RIDGE REGRESSION SOLVED WITHIN THE MIXED MODEL FRAMEWORK ### 
###=================================================================================###

#Linear kernel

Linear_KRR_model_train = Kernel_Ridge_MM(Y_train=Response_train, 
 Matrix_covariates_train=Predictors_train, method="RR-BLUP")

f_hat_target_Linear_KRR = Predict_kernel_Ridge_MM( Linear_KRR_model_train,
 Matrix_covariates_target=Predictors_target )

#Gaussian kernel

Gaussian_KRR_model_train = Kernel_Ridge_MM( Y_train=Response_train, 
 Matrix_covariates_train=Predictors_train, method="RKHS", rate_decay_kernel=5.0)

f_hat_target_Gaussian_KRR = Predict_kernel_Ridge_MM( Gaussian_KRR_model_train, 
 Matrix_covariates_target=Predictors_target )


#Graphics for RR-BLUP

dev.new(width=30, height=20)
par(mfrow=c(3,1))	
plot(f_hat_target_Linear_KRR, True_value_target)
plot(Linear_KRR_model_train$Gamma_hat, xlab="Feature (i.e. covariate) number", 
ylab="Feature effect (i.e. Gamma_hat)", main="BLUP of covariate effects based on training data")
hist(Linear_KRR_model_train$Gamma_hat, main="Distribution of BLUP of 
covariate effects based on training data" )


# Compare prediction based on linear (i.e. RR-BLUP) and Gaussian kernel

dev.new(width=30, height=20)
par(mfrow=c(1,2))
plot(f_hat_target_Linear_KRR, True_value_target)
plot(f_hat_target_Gaussian_KRR, True_value_target)

mean((f_hat_target_Linear_KRR - True_value_target)^2)
mean((f_hat_target_Gaussian_KRR - True_value_target)^2)


## End(Not run)

</code></pre>

<hr>
<h2 id='EM_REML_MM'>Expectation-Maximization (EM) algorithm for the restricted maximum likelihood (REML) associated to the mixed model
</h2><span id='topic+EM_REML_MM'></span>

<h3>Description</h3>

<p>EM_REML_MM estimates the components and variance parameters of the following mixed model; Y =X*Beta + Z*U + E, using the EM-REML algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>		EM_REML_MM( Mat_K_inv, Y, X, Z, init_sigma2K, 
		
		init_sigma2E, convergence_precision, 
		
		nb_iter, display )		
	</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="EM_REML_MM_+3A_mat_k_inv">Mat_K_inv</code></td>
<td>
<p>numeric matrix; the inverse of the kernel matrix</p>
</td></tr>
<tr><td><code id="EM_REML_MM_+3A_y">Y</code></td>
<td>
<p>numeric vector; response vector</p>
</td></tr>
<tr><td><code id="EM_REML_MM_+3A_x">X</code></td>
<td>
<p>numeric matrix; design matrix of predictors with fixed effects</p>
</td></tr>
<tr><td><code id="EM_REML_MM_+3A_z">Z</code></td>
<td>
<p>numeric matrix; design matrix of predictors with random effects</p>
</td></tr>
<tr><td><code id="EM_REML_MM_+3A_init_sigma2k">init_sigma2K</code>, <code id="EM_REML_MM_+3A_init_sigma2e">init_sigma2E</code></td>
<td>

<p>numeric scalars;
initial guess values, associated to the mixed model variance parameters,
for the EM-REML algorithm
</p>
</td></tr>
<tr><td><code id="EM_REML_MM_+3A_convergence_precision">convergence_precision</code>, <code id="EM_REML_MM_+3A_nb_iter">nb_iter</code></td>
<td>
		
<p>convergence precision (i.e. tolerance) associated to the mixed model 
variance parameters, for the EM-REML algorithm, and number of maximum 
iterations allowed if convergence is not reached
</p>
</td></tr>
<tr><td><code id="EM_REML_MM_+3A_display">display</code></td>
<td>

<p>boolean (TRUE or FALSE character string); 
should estimated components be displayed at each iteration 
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Beta_hat</code></td>
<td>
<p>Estimated fixed effect(s)</p>
</td></tr>
<tr><td><code>Sigma2K_hat</code>, <code>Sigma2E_hat</code></td>
<td>
<p>Estimated variance components</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Laval Jacquin &lt;jacquin.julien@gmail.com&gt;</p>


<h3>References</h3>

<p>Foulley, J.-L. (2002). Algorithme em: théorie et application au modèle mixte. Journal de la Société française de Statistique 143, 57-109
</p>

<hr>
<h2 id='Kernel_Ridge_MM'>
Kernel ridge regression in the mixed model framework
</h2><span id='topic+Kernel_Ridge_MM'></span>

<h3>Description</h3>

<p>Kernel_Ridge_MM solves kernel ridge regression for various kernels within the following mixed model framework: Y =X*Beta + Z*U + E, where
X and Z correspond to the design matrices of predictors with fixed and random effects respectively.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>	
	Kernel_Ridge_MM( Y_train, X_train=as.vector(rep(1,length(Y_train))), 

	Z_train=diag(1,length(Y_train)), Matrix_covariates_train, method="RKHS",

	kernel="Gaussian", rate_decay_kernel=0.1, degree_poly=2, scale_poly=1, 
	
	offset_poly=1, degree_anova=3, init_sigma2K=2, init_sigma2E=3, 

	convergence_precision=1e-8, nb_iter=1000, display="FALSE" )
	</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Kernel_Ridge_MM_+3A_y_train">Y_train</code></td>
<td>
<p>numeric vector; response vector for training data</p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_x_train">X_train</code></td>
<td>
<p>numeric matrix; design matrix of predictors with fixed effects for training data (default is a vector of ones)</p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_z_train">Z_train</code></td>
<td>
<p>numeric matrix; design matrix of predictors with random effects for training data (default is identity matrix)</p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_matrix_covariates_train">Matrix_covariates_train</code></td>
<td>
<p>numeric matrix of entries used to build the kernel matrix</p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_method">method</code></td>
<td>
<p>character string; RKHS, GBLUP or RR-BLUP</p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_kernel">kernel</code></td>
<td>
<p>character string; Gaussian, Laplacian or ANOVA (kernels for RKHS regression ONLY, the linear kernel is automatically built for GBLUP and RR-BLUP and hence no kernel is supplied for these methods) </p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_rate_decay_kernel">rate_decay_kernel</code></td>
<td>
<p>numeric scalar; hyperparameter of the Gaussian, Laplacian or ANOVA kernel (default is 0.1)</p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_degree_poly">degree_poly</code>, <code id="Kernel_Ridge_MM_+3A_scale_poly">scale_poly</code>, <code id="Kernel_Ridge_MM_+3A_offset_poly">offset_poly</code></td>
<td>
<p>numeric scalars; parameters for polynomial kernel (defaults are 2, 1 and 1 respectively)</p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_degree_anova">degree_anova</code></td>
<td>
<p>numeric scalar; parameter for ANOVA kernel (defaults is 3)</p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_init_sigma2k">init_sigma2K</code>, <code id="Kernel_Ridge_MM_+3A_init_sigma2e">init_sigma2E</code></td>
<td>
<p>numeric scalars;
initial guess values, associated to the mixed model variance parameters, for the EM-REML algorithm
(defaults are 2 and 3 respectively)
</p>
</td></tr>
<tr><td><code id="Kernel_Ridge_MM_+3A_convergence_precision">convergence_precision</code>, <code id="Kernel_Ridge_MM_+3A_nb_iter">nb_iter</code></td>
<td>
		
<p>numeric scalars; convergence precision (i.e. tolerance) associated to the mixed model variance parameters,
for the EM-REML algorithm, and number of maximum iterations allowed if 
convergence is not reached (defaults are 1e-8 and 1000 respectively)
</p>
</td></tr>	
<tr><td><code id="Kernel_Ridge_MM_+3A_display">display</code></td>
<td>

<p>boolean (TRUE or FALSE character string); 
should estimated components be displayed at each   
iteration 
</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The matrix Matrix_covariates_train is mandatory to build the kernel matrix for model estimation, and prediction (see Predict_kernel_Ridge_MM).
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>Beta_hat</code></td>
<td>
<p>Estimated fixed effect(s)</p>
</td></tr>
<tr><td><code>Sigma2K_hat</code>, <code>Sigma2E_hat</code></td>
<td>
<p>Estimated variance components</p>
</td></tr>
<tr><td><code>Vect_alpha</code></td>
<td>
<p>Estimated dual variables</p>
</td></tr>
<tr><td><code>Gamma_hat</code></td>
<td>
<p>RR-BLUP of covariates effects 
(i.e. available for RR-BLUP method only)</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Laval Jacquin &lt;jacquin.julien@gmail.com&gt;</p>


<h3>References</h3>

<p>Jacquin et al. (2016). A unified and comprehensible view of parametric and kernel methods for genomic prediction with application to rice (in peer review).
</p>
<p>Robinson, G. K. (1991). That blup is a good thing: the estimation of random effects. Statistical science, 534 15-32 
</p>
<p>Foulley, J.-L. (2002). Algorithme em: théorie et application au modèle mixte. Journal de la Société française de Statistique 143, 57-109
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

library(KRMM)

### SIMULATE DATA 
set.seed(123)
p=200
N=100

beta=rnorm(p, mean=0, sd=1.0)
X=matrix(runif(p*N, min=0, max=1), ncol=p, byrow=TRUE)  #X: covariates (i.e. predictors)

f=X%*%beta                    #f: data generating process (i.e. DGP)
E=rnorm(N, mean=0, sd=0.5)

Y=f+E                           #Y: observed response data

hist(f)
hist(beta)
Nb_train=floor((2/3)*N)

###======================================================================###
### CREATE TRAINING AND TARGET SETS FOR RESPONSE AND PREDICTOR VARIABLES ###
###======================================================================###

Index_train=sample(1:N, size=Nb_train, replace=FALSE)

### Covariates (i.e. predictors) for training and target sets

Predictors_train=X[Index_train, ]
Response_train=Y[Index_train]

Predictors_target=X[-Index_train, ]
True_value_target=f[-Index_train]    #True value (generated by DGP) we want to predict


###=================================================================================###
### PREDICTION WITH KERNEL RIDGE REGRESSION SOLVED WITHIN THE MIXED MODEL FRAMEWORK ### 
###=================================================================================###


#Linear kernel

Linear_KRR_model_train = Kernel_Ridge_MM(Y_train=Response_train, 
Matrix_covariates_train=Predictors_train, method="RR-BLUP")

f_hat_target_Linear_KRR = Predict_kernel_Ridge_MM( Linear_KRR_model_train, 
Matrix_covariates_target=Predictors_target )

#Gaussian kernel

Gaussian_KRR_model_train = Kernel_Ridge_MM( Y_train=Response_train, 
Matrix_covariates_train=Predictors_train, method="RKHS", rate_decay_kernel=5.0)
f_hat_target_Gaussian_KRR = Predict_kernel_Ridge_MM( Gaussian_KRR_model_train, 
Matrix_covariates_target=Predictors_target )


#Graphics for RR-BLUP

dev.new(width=30, height=20)
par(mfrow=c(3,1))	
plot(f_hat_target_Linear_KRR, True_value_target)
plot(Linear_KRR_model_train$Gamma_hat, xlab="Feature (i.e. covariate) number", 
 ylab="Feature effect (i.e. Gamma_hat)", main="BLUP of covariate effects based on training data")
hist(Linear_KRR_model_train$Gamma_hat, main="Distribution of BLUP of
covariate effects based on training data" )


# Compare prediction based on linear (i.e. RR-BLUP) and Gaussian kernel

par(mfrow=c(1,2))
plot(f_hat_target_Linear_KRR, True_value_target)
plot(f_hat_target_Gaussian_KRR, True_value_target)

mean((f_hat_target_Linear_KRR - True_value_target)^2)
mean((f_hat_target_Gaussian_KRR - True_value_target)^2)


## End(Not run)

</code></pre>

<hr>
<h2 id='Predict_kernel_Ridge_MM'>
Predict function for Kernel_Ridge_MM object
</h2><span id='topic+Predict_kernel_Ridge_MM'></span>

<h3>Description</h3>

<p>Predict the value(s) for a vector or a design matrix of covariates (i.e. features)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>		Predict_kernel_Ridge_MM( Model_kernel_Ridge_MM, Matrix_covariates_target,
		
		X_target=as.vector(rep(1,dim(Matrix_covariates_target)[1])),
		
		Z_target=diag(1,dim(Matrix_covariates_target)[1]) ) 
	</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Predict_kernel_Ridge_MM_+3A_model_kernel_ridge_mm">Model_kernel_Ridge_MM</code></td>
<td>
<p>a Kernel_Ridge_MM object</p>
</td></tr>
<tr><td><code id="Predict_kernel_Ridge_MM_+3A_matrix_covariates_target">Matrix_covariates_target</code></td>
<td>
<p>numeric matrix; design matrix of covariates for target data</p>
</td></tr>
<tr><td><code id="Predict_kernel_Ridge_MM_+3A_x_target">X_target</code></td>
<td>
<p>numeric matrix; design matrix of predictors with fixed effects for target data (default is a vector of ones)</p>
</td></tr>
<tr><td><code id="Predict_kernel_Ridge_MM_+3A_z_target">Z_target</code></td>
<td>
<p>numeric matrix; design matrix of predictors with random effects for target data (default is identity matrix)</p>
</td></tr>
</table>


<h3>Details</h3>

 
<p>The matrix Matrix_covariates_target is mandatory to build the kernel matrix (with Matrix_covariates_train from Model_kernel_Ridge_MM) for prediction.
</p>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>f_hat</code></td>
<td>
<p> Predicted value for target data, i.e. f_hat = X_target*Beta_hat + Z_target*U_target where U_target=K_target_train*alpha_train
and alpha_train is the BLUP of alpha for the model, i.e. alpha_train=Cov(alpha,Y_train)*Var(Y_train)^-1*(Y_train - E[Y_train]) </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Laval Jacquin &lt;jacquin.julien@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## Not run: 

library(KRMM)

### SIMULATE DATA 
set.seed(123)
p=200
N=100

beta=rnorm(p, mean=0, sd=1.0)
X=matrix(runif(p*N, min=0, max=1), ncol=p, byrow=TRUE)  #X: covariates (i.e. predictors)

f=X%*%beta                    #f: data generating process (i.e. DGP)
E=rnorm(N, mean=0, sd=0.5)

Y=f+E                           #Y: observed response data

hist(f)
hist(beta)
Nb_train=floor((2/3)*N)

###======================================================================###
### CREATE TRAINING AND TARGET SETS FOR RESPONSE AND PREDICTOR VARIABLES ###
###======================================================================###

Index_train=sample(1:N, size=Nb_train, replace=FALSE)

### Covariates (i.e. predictors) for training and target sets

Predictors_train=X[Index_train, ]
Response_train=Y[Index_train]

Predictors_target=X[-Index_train, ]
True_value_target=f[-Index_train]    #True value (generated by DGP) we want to predict


###=================================================================================###
### PREDICTION WITH KERNEL RIDGE REGRESSION SOLVED WITHIN THE MIXED MODEL FRAMEWORK ### 
###=================================================================================###

Gaussian_KRR_model_train = Kernel_Ridge_MM( Y_train=Response_train,
 Matrix_covariates_train=Predictors_train, method="RKHS", rate_decay_kernel=5.0)

### Predict new entries for target set and measure prediction error

f_hat_target_Gaussian_KRR = Predict_kernel_Ridge_MM( Gaussian_KRR_model_train, 
 Matrix_covariates_target=Predictors_target )

plot(f_hat_target_Gaussian_KRR, True_value_target)


## End(Not run)


</code></pre>

<hr>
<h2 id='Tune_kernel_Ridge_MM'>Tune kernel ridge regression in the mixed model framework</h2><span id='topic+Tune_kernel_Ridge_MM'></span>

<h3>Description</h3>

<p>Tune_kernel_Ridge_MM tunes the rate of decay parameter of kernels, by K-folds cross-validation, for kernel ridge regression
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  		Tune_kernel_Ridge_MM( Y_train, X_train=as.vector(rep(1,length(Y_train))),
		
		Z_train=diag(1,length(Y_train)), Matrix_covariates_train, 
		
		method="RKHS", kernel="Gaussian", rate_decay_kernel=0.1, 
		
		degree_poly=2, scale_poly=1, offset_poly=1,
		
		degree_anova=3, init_sigma2K=2, init_sigma2E=3,

		convergence_precision=1e-8, nb_iter=1000, display="FALSE",

		rate_decay_grid=seq(0.1,1.0,length.out=10),

		nb_folds=5, loss="mse")		
	</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_rate_decay_grid">rate_decay_grid</code></td>
<td>

<p>Grid over which the rate of decay is tuned by K-folds cross-validation
</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_nb_folds">nb_folds</code></td>
<td>

<p>Number of folds, i.e. K=nb_folds (default is 5)
</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_loss">loss</code></td>
<td>
<p> mse (mean square error) or cor (correlation) (default is mse)</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_y_train">Y_train</code></td>
<td>
<p>numeric vector; response vector for training data</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_x_train">X_train</code></td>
<td>
<p>numeric matrix; design matrix of predictors with fixed  effects for training data (default is a vector of ones)</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_z_train">Z_train</code></td>
<td>
<p>numeric matrix; design matrix of predictors with random effects for training data (default is identity matrix)</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_matrix_covariates_train">Matrix_covariates_train</code></td>
<td>
<p>numeric matrix of entries used to build the kernel matrix</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_method">method</code></td>
<td>
<p>character string; RKHS, GBLUP or RR-BLUP</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_kernel">kernel</code></td>
<td>
<p>character string; Gaussian, Laplacian or ANOVA (kernels for RKHS regression ONLY, the linear kernel is automatically built for GBLUP and RR-BLUP and hence no kernel is supplied for these methods) </p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_rate_decay_kernel">rate_decay_kernel</code></td>
<td>
<p>	numeric scalar;
hyperparameter of the Gaussian, Laplacian or ANOVA kernel (default is 0.1)
</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_degree_poly">degree_poly</code>, <code id="Tune_kernel_Ridge_MM_+3A_scale_poly">scale_poly</code>, <code id="Tune_kernel_Ridge_MM_+3A_offset_poly">offset_poly</code></td>
<td>
<p>numeric scalars; parameters for polynomial kernel (defaults are 2, 1 and 1 respectively)</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_degree_anova">degree_anova</code></td>
<td>

<p>numeric scalar; parameter for ANOVA kernel (defaults is 3)
</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_init_sigma2k">init_sigma2K</code>, <code id="Tune_kernel_Ridge_MM_+3A_init_sigma2e">init_sigma2E</code></td>
<td>

<p>numeric scalars;
initial guess values, associated to the mixed model variance parameters, for the EM-REML algorithm
(defaults are 2 and 3 respectively)
</p>
</td></tr>
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_convergence_precision">convergence_precision</code>, <code id="Tune_kernel_Ridge_MM_+3A_nb_iter">nb_iter</code></td>
<td>
		
<p>numeric scalars; convergence precision (i.e. tolerance) associated to the mixed model variance parameters,
for the EM-REML algorithm, and number of maximum iterations allowed if 
convergence is not reached (defaults are 1e-8 and 1000 respectively)
</p>
</td></tr>	
<tr><td><code id="Tune_kernel_Ridge_MM_+3A_display">display</code></td>
<td>

<p>boolean (TRUE or FALSE character string); 
should estimated components be displayed at each   
iteration 
</p>
</td></tr>
</table>


<h3>Value</h3>

<table role = "presentation">
<tr><td><code>tuned_model</code></td>
<td>
<p>the tuned model (a Kernel_Ridge_MM object)</p>
</td></tr>
<tr><td><code>expected_loss_grid</code></td>
<td>
<p>the average loss for each rate of decay tested over the grid</p>
</td></tr>
<tr><td><code>optimal_h</code></td>
<td>
<p>the rate of decay minimizing the average loss</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Laval Jacquin &lt;jacquin.julien@gmail.com&gt;</p>


<h3>Examples</h3>

<pre><code class='language-R'> 

## Not run: 

library(KRMM)

### SIMULATE DATA 
set.seed(123)
p=200
N=100

beta=rnorm(p, mean=0, sd=1.0)
X=matrix(runif(p*N, min=0, max=1), ncol=p, byrow=TRUE)  #X: covariates (i.e. predictors)

f=X%*%beta        #f: data generating process (i.e. DGP)
E=rnorm(N, mean=0, sd=0.5)

Y=f+E                                                  #Y: response data

hist(f)
hist(beta)
Nb_train=floor((2/3)*N)

###======================================================================###
###	CREATE TRAINING AND TARGET SETS FOR RESPONSE AND PREDICTOR VARIABLES ###
###======================================================================###

Index_train=sample(1:N, size=Nb_train, replace=FALSE)

### Covariates (i.e. predictors) for training and target sets

Predictors_train=X[Index_train, ]
Response_train=Y[Index_train]

Predictors_target=X[-Index_train, ]
True_value_target=f[-Index_train]    #True value (generated by DGP) we want to predict

###=======================###
### Tuned Gaussian Kernel ###
###=======================###

Tuned_Gaussian_KRR_train = Tune_kernel_Ridge_MM( Y_train=Response_train, Matrix_covariates_train
=Predictors_train, method='RKHS', rate_decay_grid=seq(1,10,length.out=10), nb_folds=5, loss='mse' )

Tuned_Gaussian_KRR_model_train = Tuned_Gaussian_KRR_train$tuned_model
Tuned_Gaussian_KRR_train$optimal_h
Tuned_Gaussian_KRR_train$rate_decay_grid
Tuned_Gaussian_KRR_train$expected_loss_grid

dev.new()
plot(Tuned_Gaussian_KRR_train$rate_decay_grid, Tuned_Gaussian_KRR_train$expected_loss_grid,
 type="l", main="Tuning the rate of decay (for Gaussian kernel) with K-folds cross-validation")

### Predict with tuned model
 
f_hat_target_tuned_Gaussian_KRR = Predict_kernel_Ridge_MM( Tuned_Gaussian_KRR_model_train, 
Matrix_covariates_target=Predictors_target )

mean((f_hat_target_tuned_Gaussian_KRR-True_value_target)^2)
cor(f_hat_target_tuned_Gaussian_KRR,True_value_target)



## End(Not run)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
