<!DOCTYPE html><html><head><title>Help for package hmer</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {hmer}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#analyze_diagnostic'><p>Diagnostic Analysis for Emulators</p></a></li>
<li><a href='#behaviour_plot'><p>Output Plotting</p></a></li>
<li><a href='#bimodal_emulator_from_data'><p>Bimodal Emulation</p></a></li>
<li><a href='#BirthDeath'><p>Birth-Death Model Results</p></a></li>
<li><a href='#classification_diag'><p>Classification Diagnostics</p></a></li>
<li><a href='#collect_emulators'><p>Collect and order emulators</p></a></li>
<li><a href='#comparison_diag'><p>Comparison Diagnostics</p></a></li>
<li><a href='#Correlator'><p>Correlation Structure</p></a></li>
<li><a href='#diagnostic_pass'><p>Automated Diagnostics and Modifications</p></a></li>
<li><a href='#diagnostic_wrap'><p>Diagnostic plots for wave outputs</p></a></li>
<li><a href='#directional_deriv'><p>Derivative inner product</p></a></li>
<li><a href='#directional_proposal'><p>Emulated Derivative Point Proposal</p></a></li>
<li><a href='#effect_strength'><p>Find Effect Strength of Active Variables</p></a></li>
<li><a href='#Emulator'><p>Bayes Linear Emulator</p></a></li>
<li><a href='#emulator_from_data'><p>Generate Emulators from Data</p></a></li>
<li><a href='#emulator_plot'><p>Plot Emulator Outputs</p></a></li>
<li><a href='#exp_sq'><p>Exponential squared correlation function</p></a></li>
<li><a href='#full_wave'><p>Automatic Wave Calculation</p></a></li>
<li><a href='#gamma_exp'><p>Gamma-exponential correlation function</p></a></li>
<li><a href='#generate_new_design'><p>Generate Proposal Points</p></a></li>
<li><a href='#generate_new_runs'><p>Generate Proposal Points</p></a></li>
<li><a href='#get_diagnostic'><p>Diagnostic Tests for Emulators</p></a></li>
<li><a href='#HierarchicalEmulator'><p>Hierarchical Bayes Linear Emulator</p></a></li>
<li><a href='#hit_by_wave'><p>Output Hit Summary</p></a></li>
<li><a href='#idemc'><p>IDEMC Point Generation</p></a></li>
<li><a href='#individual_errors'><p>Predictive Error Plots</p></a></li>
<li><a href='#matern'><p>Matern correlation function</p></a></li>
<li><a href='#nth_implausible'><p>nth Maximum Implausibility</p></a></li>
<li><a href='#orn_uhl'><p>Ornstein-Uhlenbeck correlation function</p></a></li>
<li><a href='#output_plot'><p>Emulator Expectation Against Target Outputs</p></a></li>
<li><a href='#plot_actives'><p>Active variable plotting</p></a></li>
<li><a href='#plot_lattice'><p>Plot Lattice of Emulator Implausibilities</p></a></li>
<li><a href='#plot_wrap'><p>Plot proposed points</p></a></li>
<li><a href='#problem_data'><p>Data for an interesting emulation problem</p></a></li>
<li><a href='#Proto_emulator'><p>Prototype Class for Emulator-like Objects</p></a></li>
<li><a href='#rat_quad'><p>Rational Quadratic correlation function</p></a></li>
<li><a href='#residual_diag'><p>Emulator Regression Residuals</p></a></li>
<li><a href='#simulator_plot'><p>Plot simulator outputs for multiple waves</p></a></li>
<li><a href='#SIR_stochastic'><p>Stochastic SIR Data</p></a></li>
<li><a href='#SIREmulators'><p>Sample Emulators</p></a></li>
<li><a href='#SIRImplausibility'><p>Sample Implausibility Data</p></a></li>
<li><a href='#SIRMultiWaveData'><p>Sample Multi-wave Results</p></a></li>
<li><a href='#SIRMultiWaveEmulators'><p>Sample Multi-wave Emulators</p></a></li>
<li><a href='#SIRSample'><p>Sample SIR data</p></a></li>
<li><a href='#space_removal'><p>Percentage of Space Removed</p></a></li>
<li><a href='#space_removed'><p>Space Removal Diagnostics</p></a></li>
<li><a href='#standard_errors'><p>Standardized Error Diagnostics</p></a></li>
<li><a href='#subset_emulators'><p>Subsetting for Bimodal/Variance Emulators</p></a></li>
<li><a href='#summary_diag'><p>Summary Statistics for Emulators</p></a></li>
<li><a href='#validation_diagnostics'><p>Emulator Diagnostics</p></a></li>
<li><a href='#validation_pairs'><p>Validation Set Diagnostics and Implausibility</p></a></li>
<li><a href='#variance_emulator_from_data'><p>Variance Emulator Creation (Deprecated)</p></a></li>
<li><a href='#wave_dependencies'><p>Multiple Wave Inputs vs Outputs</p></a></li>
<li><a href='#wave_points'><p>Multiple Wave Point Plotting</p></a></li>
<li><a href='#wave_values'><p>Multiple Wave Output Plotting</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>History Matching and Emulation Package</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.6</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Andrew Iskauskas &lt;andrew.iskauskas@durham.ac.uk&gt;</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/andy-iskauskas/hmer/issues">https://github.com/andy-iskauskas/hmer/issues</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/andy-iskauskas/hmer">https://github.com/andy-iskauskas/hmer</a>,
<a href="https://hmer-package.github.io/website/">https://hmer-package.github.io/website/</a></td>
</tr>
<tr>
<td>Description:</td>
<td>A set of objects and functions for Bayes Linear emulation and history matching.
  Core functionality includes automated training of emulators to data, diagnostic functions
  to ensure suitability, and a variety of proposal methods for generating 'waves' of points.
  For details on the mathematical background, there are many papers available on the topic
  (see references attached to function help files); for details of the functions in this package,
  consult the manual or help files.</td>
</tr>
<tr>
<td>Suggests:</td>
<td>spelling, knitr, rmarkdown, deSolve, testthat (&ge; 3.0.0),
covr, progressr</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.1.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>purrr, stringr, tidyr, dplyr, ggplot2, lhs, MASS, R6, viridis,
mvtnorm, GGally, rlang, isoband, cluster, pdist, ggbeeswarm</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Language:</td>
<td>en-GB</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-30 16:44:24 UTC; andy</td>
</tr>
<tr>
<td>Author:</td>
<td>Andrew Iskauskas <a href="https://orcid.org/0000-0003-2825-3651"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  TJ McKinley <a href="https://orcid.org/0000-0002-9485-3236"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-30 17:10:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='analyze_diagnostic'>Diagnostic Analysis for Emulators</h2><span id='topic+analyze_diagnostic'></span>

<h3>Description</h3>

<p>Produces summary and plots for diagnostics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>analyze_diagnostic(
  in_data,
  output_name,
  targets = NULL,
  plt = interactive(),
  cutoff = 3,
  target_viz = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="analyze_diagnostic_+3A_in_data">in_data</code></td>
<td>
<p>The data to perform the analysis on</p>
</td></tr>
<tr><td><code id="analyze_diagnostic_+3A_output_name">output_name</code></td>
<td>
<p>The name of the output emulated</p>
</td></tr>
<tr><td><code id="analyze_diagnostic_+3A_targets">targets</code></td>
<td>
<p>If required or desired, the targets for the system outputs</p>
</td></tr>
<tr><td><code id="analyze_diagnostic_+3A_plt">plt</code></td>
<td>
<p>Whether or not to plot the analysis</p>
</td></tr>
<tr><td><code id="analyze_diagnostic_+3A_cutoff">cutoff</code></td>
<td>
<p>The implausibility cutoff for diagnostic &lsquo;ce&rsquo;</p>
</td></tr>
<tr><td><code id="analyze_diagnostic_+3A_target_viz">target_viz</code></td>
<td>
<p>How to show the targets on the diagnostic plots</p>
</td></tr>
<tr><td><code id="analyze_diagnostic_+3A_...">...</code></td>
<td>
<p>Any other parameters to pass to subfunctions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given diagnostic information (almost certainly provided from <code><a href="#topic+get_diagnostic">get_diagnostic</a></code>),
we can plot the results and highlight the points that are worthy of concern or further
consideration. Each diagnostic available has a plot associated with it which can be produced
here:
</p>
<p>Standardized Error: A histogram of standardized errors. Outliers should be considered, as well
as whether very many points have either large or small errors.
</p>
<p>Comparison Diagnostics: Error bars around points, corresponding to emulator prediction plus or
minus emulator uncertainty. A green line indicates where the emulator and simulator prediction
would be in complete agreement: error bars that do not overlap with this line (coloured red) are
to be considered. Where targets are provided, the colouration is limited only to points where
the simulator prediction would be close to the targets.
</p>
<p>Classification Error: A point plot comparing emulator implausibility to simulator
implausibility, sectioned into regions horizontally and vertically by <code>cutoff</code>. Points
that lie in the lower right quadrant (i.e. emulator would reject; simulator would not) should
be considered.
</p>
<p>This function takes a data.frame that contains the input points, simulator values and, depending
on the diagnostic, a set of summary measures. It returns a data.frame of any points that failed
the diagnostic.
</p>
<p>We may also superimpose the target bounds on the comparison diagnostics, to get a sense of
where it is most important that the emulator and simulator agree. The <code>target_viz</code>
argument controls this, and has three options: 'interval' (a horizontal interval); 'solid'
(a solid grey box whose dimensions match the target region in both vertical and horizontal
extent); and 'hatched' (similar to solid, but a semi-transparent box with hatching inside).
Any such vizualisation has extent equal to the target plus/mius 4.5 times the target
uncertainty. By default, <code>target_viz = NULL</code>, indicating that no superposition is shown.
</p>


<h3>Value</h3>

<p>A data.frame of failed points
</p>


<h3>References</h3>

<p>Jackson (2018) &lt;http://etheses.dur.ac.uk/12826&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_diagnostic">get_diagnostic</a></code>
</p>
<p>Other diagnostic functions: 
<code><a href="#topic+classification_diag">classification_diag</a>()</code>,
<code><a href="#topic+comparison_diag">comparison_diag</a>()</code>,
<code><a href="#topic+get_diagnostic">get_diagnostic</a>()</code>,
<code><a href="#topic+individual_errors">individual_errors</a>()</code>,
<code><a href="#topic+residual_diag">residual_diag</a>()</code>,
<code><a href="#topic+standard_errors">standard_errors</a>()</code>,
<code><a href="#topic+summary_diag">summary_diag</a>()</code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a>()</code>
</p>

<hr>
<h2 id='behaviour_plot'>Output Plotting</h2><span id='topic+behaviour_plot'></span>

<h3>Description</h3>

<p>A simple diagnostic plot that compares the output values to input values, for
each possible combination. If emulators are provided, the emulator predictions
are plotted; otherwise the model outputs are plotted.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>behaviour_plot(
  ems,
  points,
  model = missing(ems),
  out_names = unique(names(collect_emulators(ems))),
  targets = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="behaviour_plot_+3A_ems">ems</code></td>
<td>
<p>A set of <code><a href="#topic+Emulator">Emulator</a></code> objects.</p>
</td></tr>
<tr><td><code id="behaviour_plot_+3A_points">points</code></td>
<td>
<p>A set of points at which to evaluate the emulator expectation</p>
</td></tr>
<tr><td><code id="behaviour_plot_+3A_model">model</code></td>
<td>
<p>If TRUE, use the model outputs; else use emulator expectation</p>
</td></tr>
<tr><td><code id="behaviour_plot_+3A_out_names">out_names</code></td>
<td>
<p>If no emulators are provided, use this argument to indicate outputs.</p>
</td></tr>
<tr><td><code id="behaviour_plot_+3A_targets">targets</code></td>
<td>
<p>If targets are provided, these are added into the plots.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If emulators are provided, then the <code>points</code> argument is optional: if given
then the emulator predictions will correspond to those at the points provided. If
no points are provided, 100*d (where d is the number of input parameters) are sampled
uniformly from the space and used to predict at.
</p>
<p>If no emulators are provided, then points must be provided, along with the names of
the outputs to plot; each named output must exist as a column in the points data.frame.
</p>


<h3>Value</h3>

<p>The dependency plots.
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> behaviour_plot(SIREmulators$ems, model = FALSE)
 behaviour_plot(points = SIRSample$training, out_names = names(SIREmulators$ems))
 #&gt; Throws a warning
 behaviour_plot(SIRMultiWaveEmulators, model = TRUE, targets = SIREmulators$targets)
</code></pre>

<hr>
<h2 id='bimodal_emulator_from_data'>Bimodal Emulation</h2><span id='topic+bimodal_emulator_from_data'></span>

<h3>Description</h3>

<p>Performs emulation of bimodal outputs and/or systems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bimodal_emulator_from_data(
  data,
  output_names,
  ranges,
  input_names = names(ranges),
  verbose = interactive(),
  na.rm = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bimodal_emulator_from_data_+3A_data">data</code></td>
<td>
<p>The data to train emulators on (as in variance_emulator_from_data)</p>
</td></tr>
<tr><td><code id="bimodal_emulator_from_data_+3A_output_names">output_names</code></td>
<td>
<p>The names of the outputs to emulate</p>
</td></tr>
<tr><td><code id="bimodal_emulator_from_data_+3A_ranges">ranges</code></td>
<td>
<p>The parameter ranges</p>
</td></tr>
<tr><td><code id="bimodal_emulator_from_data_+3A_input_names">input_names</code></td>
<td>
<p>The names of the parameters (by default inferred from <code>ranges</code>)</p>
</td></tr>
<tr><td><code id="bimodal_emulator_from_data_+3A_verbose">verbose</code></td>
<td>
<p>Should status updates be provided?</p>
</td></tr>
<tr><td><code id="bimodal_emulator_from_data_+3A_na.rm">na.rm</code></td>
<td>
<p>Should NA values be removed before training?</p>
</td></tr>
<tr><td><code id="bimodal_emulator_from_data_+3A_...">...</code></td>
<td>
<p>Any other parameters to pass to emulator training</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is deprecated in favour of using <code><a href="#topic+emulator_from_data">emulator_from_data</a></code>
with argument <code>emulator_type = "multistate"</code>. See the associated help file.
</p>
<p>In many stochastic systems, particularly disease models, the outputs exhibit bimodality - a
familiar example is where a disease either takes off or dies out. In these cases, it is not
sensible to emulate the outputs based on all realisations, and instead we should emulate each
mode separately.
</p>
<p>This function first tries to identify bimodality. If detected, it determines which of the
outputs in the data exhibits the bimodality: to these two separate emulators are trained, one
to each mode. The emulators are provided with any data that is relevant to their training; for
example, bimodality can exist in some regions of parameter space but not others. Points where
bimodality is present have their realisations allocated between the two modes while points
where no bimodality exists have their realisations provided to both modes. Targets that do not
exhibit bimodality are trained as a normal stochastic output: that is, using the default of
<code><a href="#topic+variance_emulator_from_data">variance_emulator_from_data</a></code>.
</p>
<p>The function also estimates the proportion of realisations in each mode for the set of outputs.
This value is also emulated as a deterministic emulator and included in the output.
</p>
<p>The output of the function is a list, containing three objects: <code>mode1</code>, <code>mode2</code>, and
<code>prop</code>. The first two objects have the form produced by <code>variance_emulator_from_data</code>
while <code>prop</code> has the form of an <code>emulator_from_data</code> output.
</p>


<h3>Value</h3>

<p>A list <code>(mode1, mode2, prop)</code> of emulator lists and objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
  # Use the stochastic SIR dataset
  SIR_ranges &lt;- list(aSI = c(0.1, 0.8), aIR = c(0, 0.5), aSR = c(0, 0.05))
  SIR_names &lt;- c("I10", "I25", "I50", "R10", "R25", "R50")
  b_ems &lt;- bimodal_emulator_from_data(SIR_stochastic$training, SIR_names, SIR_ranges)
 

</code></pre>

<hr>
<h2 id='BirthDeath'>Birth-Death Model Results</h2><span id='topic+BirthDeath'></span>

<h3>Description</h3>

<p>An RData object containing two data.frames. The first consists of ten parameter
sets run through a simple, two-parameter, stochastic birth-death model; five of the
points have 500 replicates and the other five have only 5 replicates. The second
consists of ten further points, each with ten replicates. The objects are denoted
<code>training</code> and <code>validation</code>, representing their expected usage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>BirthDeath
</code></pre>


<h3>Format</h3>

<p>A list of two data.frames <code>training</code> and <code>validation</code>: each
data.frame has the following columns:
</p>

<dl>
<dt>lambda</dt><dd><p>Birth rate</p>
</dd>
<dt>mu</dt><dd><p>Death rate</p>
</dd>
<dt>Y</dt><dd><p>The number of people at time t = 15</p>
</dd>
</dl>



<h3>Details</h3>

<p>The initial population for the simulations is 100 people; the model is run until
t = 15 to obtain the results to emulate.
</p>

<hr>
<h2 id='classification_diag'>Classification Diagnostics</h2><span id='topic+classification_diag'></span>

<h3>Description</h3>

<p>Shorthand function for diagnostic test &lsquo;ce&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classification_diag(
  emulator,
  targets,
  validation,
  cutoff = 3,
  plt = interactive()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classification_diag_+3A_emulator">emulator</code></td>
<td>
<p>The emulator in question</p>
</td></tr>
<tr><td><code id="classification_diag_+3A_targets">targets</code></td>
<td>
<p>The output targets</p>
</td></tr>
<tr><td><code id="classification_diag_+3A_validation">validation</code></td>
<td>
<p>The validation set</p>
</td></tr>
<tr><td><code id="classification_diag_+3A_cutoff">cutoff</code></td>
<td>
<p>The implausibility cutoff</p>
</td></tr>
<tr><td><code id="classification_diag_+3A_plt">plt</code></td>
<td>
<p>Whether to plot or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details of the function, see <code><a href="#topic+get_diagnostic">get_diagnostic</a></code> and for the plot
see <code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a></code>.
</p>


<h3>Value</h3>

<p>A data.frame of failed points
</p>


<h3>References</h3>

<p>Jackson (2018) &lt;http://etheses.dur.ac.uk/12826&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_diagnostic">get_diagnostic</a></code>, <code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a></code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a></code>
</p>
<p>Other diagnostic functions: 
<code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a>()</code>,
<code><a href="#topic+comparison_diag">comparison_diag</a>()</code>,
<code><a href="#topic+get_diagnostic">get_diagnostic</a>()</code>,
<code><a href="#topic+individual_errors">individual_errors</a>()</code>,
<code><a href="#topic+residual_diag">residual_diag</a>()</code>,
<code><a href="#topic+standard_errors">standard_errors</a>()</code>,
<code><a href="#topic+summary_diag">summary_diag</a>()</code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a>()</code>
</p>

<hr>
<h2 id='collect_emulators'>Collect and order emulators</h2><span id='topic+collect_emulators'></span>

<h3>Description</h3>

<p>Manipulates lists (or lists of lists) of emulators into a useable form.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>collect_emulators(
  emulators,
  targets = NULL,
  cutoff = 3,
  ordering = c("params", "imp", "volume"),
  sample_size = 200,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="collect_emulators_+3A_emulators">emulators</code></td>
<td>
<p>The recursive list of emulators</p>
</td></tr>
<tr><td><code id="collect_emulators_+3A_targets">targets</code></td>
<td>
<p>If not NULL, uses implausibility to order the emulators.</p>
</td></tr>
<tr><td><code id="collect_emulators_+3A_cutoff">cutoff</code></td>
<td>
<p>The implausibility cutoff to use (if required)</p>
</td></tr>
<tr><td><code id="collect_emulators_+3A_ordering">ordering</code></td>
<td>
<p>The order in which to apply the relevant metrics</p>
</td></tr>
<tr><td><code id="collect_emulators_+3A_sample_size">sample_size</code></td>
<td>
<p>The number of points to apply implausibility to (if required)</p>
</td></tr>
<tr><td><code id="collect_emulators_+3A_...">...</code></td>
<td>
<p>Any additional arguments to pass recursively to collect_emulators</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most often used as a pre-processing stage for <code>generate_new_design</code> or
<code>nth_implausible</code>, this takes a list of emulators in a variety of forms
coming from either multiple waves of history matching, hierarchical emulation
or bimodal emulation, and arrange them in a form suitable for sequential analysis.
Emulators are also ordered by a number of factors: number of parameters, size of
the minimum enclosing hyperrectangle, and implausibility (where applicable).
</p>
<p>If targets are provided, then the emulators can also be tested on the basis of
how restrictive they are: this is included in the ordering. The cutoff by which to
make a determination of implausibility for a point is governed by <code>cutoff</code>.
The number of points to sample to consider implausibility is chosen by the value
of <code>sample_size</code>: higher values are likely to be a more accurate reflection
but will take longer.
</p>
<p>The weighting of each of the three metrics can be chosen using the <code>ordering</code>
argument: metrics with higher weight are closer to the front of the character vector.
The metrics are denoted &quot;params&quot; for number of parameters, &quot;imp&quot; for restrictiveness,
and &quot;volume&quot; for volume of the hyperrectangle. For instance, a character vector
<code>c("volume", "imp")</code> would sort first by volume of the minimum enclosing hyperrectangle,
resolve ties by restrictiveness, and not consider the number of parameters.
</p>


<h3>Value</h3>

<p>A list of emulators with the ordered property described above.
</p>

<hr>
<h2 id='comparison_diag'>Comparison Diagnostics</h2><span id='topic+comparison_diag'></span>

<h3>Description</h3>

<p>Shorthand function for diagnostic test &lsquo;cd&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comparison_diag(emulator, targets, validation, sd = 3, plt = interactive())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="comparison_diag_+3A_emulator">emulator</code></td>
<td>
<p>The emulator in question</p>
</td></tr>
<tr><td><code id="comparison_diag_+3A_targets">targets</code></td>
<td>
<p>The output targets</p>
</td></tr>
<tr><td><code id="comparison_diag_+3A_validation">validation</code></td>
<td>
<p>The validation set</p>
</td></tr>
<tr><td><code id="comparison_diag_+3A_sd">sd</code></td>
<td>
<p>The range of uncertainty allowed</p>
</td></tr>
<tr><td><code id="comparison_diag_+3A_plt">plt</code></td>
<td>
<p>Whether to plot or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details of the function, see <code><a href="#topic+get_diagnostic">get_diagnostic</a></code> and for the plot
see <code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a></code>.
</p>


<h3>Value</h3>

<p>A data.frame of failed points
</p>


<h3>References</h3>

<p>Jackson (2018) &lt;http://etheses.dur.ac.uk/12826&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_diagnostic">get_diagnostic</a></code>, <code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a></code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a></code>
</p>
<p>Other diagnostic functions: 
<code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a>()</code>,
<code><a href="#topic+classification_diag">classification_diag</a>()</code>,
<code><a href="#topic+get_diagnostic">get_diagnostic</a>()</code>,
<code><a href="#topic+individual_errors">individual_errors</a>()</code>,
<code><a href="#topic+residual_diag">residual_diag</a>()</code>,
<code><a href="#topic+standard_errors">standard_errors</a>()</code>,
<code><a href="#topic+summary_diag">summary_diag</a>()</code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a>()</code>
</p>

<hr>
<h2 id='Correlator'>Correlation Structure</h2><span id='topic+Correlator'></span>

<h3>Description</h3>

<p>Creates a correlation structure, with the necessary specifications.
</p>
<p>The correlator has three main elements: the type of correlator, the associated
hyperparameters, and the nugget term. The nugget term is broadly separate from
the other two parameters, being type-independent.
</p>


<h3>Constructor</h3>

<p><code>Correlator$new(corr, hp, nug)</code>
</p>


<h3>Arguments</h3>

<p><code>corr</code> The type of correlation function. This is provided as a string which
corresponds exactly with a function - the function should take three arguments
<code>x, xp, hp</code>. This gives a correlation function u(x, xp) defined by
hyperparameters <code>hp</code>. For a simple example, see <code><a href="#topic+exp_sq">exp_sq</a></code>.
</p>
<p><code>hp</code> The associated hyperparameters needed to define the correlation
structure, as a named list. In the case of <code>exp_sq</code>, this is a list of
one element, <code>list(theta)</code>.
</p>
<p><code>nug</code> The size of the nugget term. In situations where not all variables
are active, the main part of u(x) operates only on the active parts, xA. The
presence of the nugget term accounts for the fact that points at the same
position in the active space need not be at the same position in the full space.
</p>
<p>By default, <code>Correlator$new()</code> initialises with <code>corr = exp_sq</code>,
<code>hp = list(theta = 0.1)</code>, and <code>nug = 0</code>.
</p>


<h3>Accessor Methods</h3>

<p><code>get_corr(x, xp = NULL, actives = TRUE)</code> Returns the correlation
between two points. If <code>xp</code> is <code>NULL</code>, then this is correlation
between a set of points and themselves (i.e. 1 on the diagonal). All variables
are assumed to be active unless otherwise stated in <code>actives</code>.
</p>
<p><code>get_hyper_p()</code> Returns the list of hyperparameters.
</p>
<p><code>print()</code> Produces a summary of the correlation structure specification.
</p>


<h3>Object Methods</h3>

<p><code>set_hyper_p(hp, nugget)</code> Modifies the hyperparameter and/or nugget
terms. Returns a new <code>Correlator</code> object.
</p>


<h3>Options for Correlations</h3>

<p>The default choice (and that supported by other functions in this package, particularly
emulator_from_data) for the correlation structure is exponential-squared, due to the
useful properties it possesses. However, one can manually instantiate a Correlator with
a different underlying structure. Built-in alternatives are as follows, as well as whether
a form exists for its derivative:
</p>

<dl>
<dt><code><a href="#topic+matern">matern</a></code></dt><dd><p>the Mat√©rn function (derivative exists)</p>
</dd>
<dt><code><a href="#topic+orn_uhl">orn_uhl</a></code></dt><dd><p>the Ornstein-Uhlenbeck function (no derivative)</p>
</dd>
<dt><code><a href="#topic+rat_quad">rat_quad</a></code></dt><dd><p>the rational quadratic function (derivative exists)</p>
</dd>
</dl>

<p>One more function, <code><a href="#topic+gamma_exp">gamma_exp</a></code>, is available but not directly supported
by <code>emulator_from_data</code>, for example, due to its very limited suitability to
emulating model outputs. However, this can be used as a test case for writing one's
own correlation functions and using them with <code>emulator_from_data</code>.
</p>
<p>A user-defined correlation function can be provided to the Correlator: the requirements
are that the function accept data.matrix objects as its first and second arguments,
and accept a named list of hyperparameters as its third argument, and return a matrix
of correlations between rows of the data.matrices. If a derivative also
exists, it should take the same name as the correlation function with &quot;_d&quot; appended to
it, and the directions to differentiate with respect to should come after the
hyperparameter argument. For example, the rational quadratic functions have the form
</p>
<p><code>rat_quad(x1, x2, hp = list(alpha, theta))</code>
</p>
<p><code>rat_quad_d(x1, x2, hp = list(alpha, theta), dx1, dx2)</code>
</p>
<p>If defining a custom correlation function, care should be taken with hyperparameter
estimation - see <code><a href="#topic+emulator_from_data">emulator_from_data</a></code> examples for details.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_corr &lt;- Correlator$new(nug = 0.1)
test_corr
point1 &lt;- data.frame(a = 0.1, b = 0.2, c = 0.3)
point2 &lt;- data.frame(a = 0.15, b = 0.18, c = 0.295)
test_corr$get_corr(point1) #&gt; 1
test_corr$get_corr(point1, point2) #&gt; 0.6717557
test_corr$get_corr(point1, point2, actives = c(TRUE, TRUE, FALSE)) #&gt; 0.6734372

new_corr &lt;- test_corr$set_hyper_p(list(theta = 0.5), nug = 0.01)
new_corr$get_corr(point1, point2) #&gt; 0.9784845
new_corr$get_corr(point1, point2, actives = c(TRUE, TRUE, FALSE)) #&gt; 0.9785824

mat_corr &lt;- Correlator$new('matern', list(nu = 1.5, theta = 0.5))
mat_corr$get_corr(data.frame(a = c(1, 0.9), b = c(4, 4.2)))
</code></pre>

<hr>
<h2 id='diagnostic_pass'>Automated Diagnostics and Modifications</h2><span id='topic+diagnostic_pass'></span>

<h3>Description</h3>

<p>Perform a set of diagnostics on emulators, changing them if needed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagnostic_pass(
  ems,
  targets,
  validation,
  check_output = FALSE,
  verbose = interactive(),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diagnostic_pass_+3A_ems">ems</code></td>
<td>
<p>The emulators to consider</p>
</td></tr>
<tr><td><code id="diagnostic_pass_+3A_targets">targets</code></td>
<td>
<p>The output targets to compare implausibility against</p>
</td></tr>
<tr><td><code id="diagnostic_pass_+3A_validation">validation</code></td>
<td>
<p>The set of validation points (either a single data.frame or one per emulator)</p>
</td></tr>
<tr><td><code id="diagnostic_pass_+3A_check_output">check_output</code></td>
<td>
<p>Whether to check for suitability of outputs re. targets</p>
</td></tr>
<tr><td><code id="diagnostic_pass_+3A_verbose">verbose</code></td>
<td>
<p>Whether messages should be printed while running</p>
</td></tr>
<tr><td><code id="diagnostic_pass_+3A_...">...</code></td>
<td>
<p>Other arguments to pass to helper functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>NOTE: Automated diagnostics are currently only supported for determinstic
emulators.
</p>
<p>There are a number of different characteristics that emulators might possess
that give rise to diagnostic flags. This function collects together some of those
whose resulting modifications can be automated. The tests, and consequences, are
as follows.
</p>

<dl>
<dt>Structured Input Space</dt><dd><p>Looks for errors with dependence on input parameters. If
found, the emulator's correlation length is reduced (to a minimum of 1/3);</p>
</dd>
<dt>Structured Output Space</dt><dd><p>Looks for errors with dependence on output value. If
found, the training and validation data is resampled and emulators are retrained,
to try to incorporate/remove high leverage points;</p>
</dd>
<dt>Misclassification</dt><dd><p>Checks agreement between emulator and simulator implausibility
classification. If they do not match, emulator uncertainty is inflated;</p>
</dd>
<dt>Comparison</dt><dd><p>Checks that the emulator predictions agree with the simulator
predictions at the validation points, allowing for expected margin of error.</p>
</dd>
</dl>

<p>If the automated modifications are not sufficient to remove problems, then
offending emulators are removed from the set under consideration. Emulators in
this category should be carefully considered and their outputs analyzed: they may
require manual determination of the regression surface or additional training
points in the neightbourhood of the problematic inputs.
</p>
<p>The validation set can also be checked for suitability independent of emulator
structure: if <code>check_output = TRUE</code> then the outputs of the validation set
will be compared against targets, as well as checking the implausibility of the
points with respect to the emulators. If any outputs are consistent under- or
over-estimates, or if all points are to be ruled out as implausible, the emulators
corresponding to these outputs are removed. This option should be used with care:
such a situation could be informative for considering the model structure and
whether one should expect a match to observational data.
</p>


<h3>Value</h3>

<p>A collection of modified emulators, potentially a subset of the original collection
</p>


<h3>Examples</h3>

<pre><code class='language-R'> new_ems &lt;- diagnostic_pass(SIREmulators$ems, SIREmulators$targets, SIRSample$validation)
</code></pre>

<hr>
<h2 id='diagnostic_wrap'>Diagnostic plots for wave outputs</h2><span id='topic+diagnostic_wrap'></span>

<h3>Description</h3>

<p>A wrapper function for the set of diagnostic plots for multiple waves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diagnostic_wrap(
  waves,
  targets,
  output_names = names(targets),
  input_names = names(waves[[1]])[!names(waves[[1]]) %in% names(targets)],
  directory = NULL,
  s.heights = rep(1000, 4),
  s.widths = s.heights,
  include.norm = TRUE,
  include.log = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="diagnostic_wrap_+3A_waves">waves</code></td>
<td>
<p>The wave points, as a list of data.frames.</p>
</td></tr>
<tr><td><code id="diagnostic_wrap_+3A_targets">targets</code></td>
<td>
<p>The output targets.</p>
</td></tr>
<tr><td><code id="diagnostic_wrap_+3A_output_names">output_names</code></td>
<td>
<p>The outputs to plot.</p>
</td></tr>
<tr><td><code id="diagnostic_wrap_+3A_input_names">input_names</code></td>
<td>
<p>The inputs to plot.</p>
</td></tr>
<tr><td><code id="diagnostic_wrap_+3A_directory">directory</code></td>
<td>
<p>The location of files to be saved (if required).</p>
</td></tr>
<tr><td><code id="diagnostic_wrap_+3A_s.heights">s.heights</code></td>
<td>
<p>The heights of the saved pngs (if directory is not NULL).</p>
</td></tr>
<tr><td><code id="diagnostic_wrap_+3A_s.widths">s.widths</code></td>
<td>
<p>The widths of the saved pngs (if directory is not NULL).</p>
</td></tr>
<tr><td><code id="diagnostic_wrap_+3A_include.norm">include.norm</code></td>
<td>
<p>Should normalized versions of simulator_plot and wave_dependencies be made?</p>
</td></tr>
<tr><td><code id="diagnostic_wrap_+3A_include.log">include.log</code></td>
<td>
<p>Should the log-scale version of simulator_plot be made?</p>
</td></tr>
<tr><td><code id="diagnostic_wrap_+3A_...">...</code></td>
<td>
<p>Optional parameters (eg <code>p_size</code>, <code>l_wid</code>, ...)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The functions <code><a href="#topic+simulator_plot">simulator_plot</a></code>, <code><a href="#topic+wave_points">wave_points</a></code>, <code><a href="#topic+wave_points">wave_points</a></code>,
and <code><a href="#topic+wave_dependencies">wave_dependencies</a></code> are called, one after the other, to allow diagnosis of waves
of emulation.
</p>
<p>The <code>directory</code> option should be used as follows. If the desired location is in fact
a folder, it should end in &quot;/&quot;; if instead the structure requires each plot to be saved with a
prefix, then it should be provided. For example, <code>directory = "Plots/"</code> in the first event
or <code>directory = "Plots/unique-identifier"</code> in the second event.
</p>


<h3>Value</h3>

<p>The set of plots (either into console or saved).
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 diagnostic_wrap(SIRMultiWaveData, SIREmulators$targets)
 diagnostic_wrap(SIRMultiWaveData, SIREmulators$targets,
  input_names = c('aSI', 'aIR'), output_names = c('nI', 'nR'),
  p_size = 0.8, l_wid = 0.8, wave_numbers = 1:3, zero_in = FALSE, surround = TRUE)
  
</code></pre>

<hr>
<h2 id='directional_deriv'>Derivative inner product</h2><span id='topic+directional_deriv'></span>

<h3>Description</h3>

<p>Find the (uncertainty modified) inner product between the derivative at a point <code>x</code>
and a proposed direction <code>v</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>directional_deriv(em, x, v, sd = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="directional_deriv_+3A_em">em</code></td>
<td>
<p>The emulator in question</p>
</td></tr>
<tr><td><code id="directional_deriv_+3A_x">x</code></td>
<td>
<p>The point in input space to evaluate at</p>
</td></tr>
<tr><td><code id="directional_deriv_+3A_v">v</code></td>
<td>
<p>The direction to assess</p>
</td></tr>
<tr><td><code id="directional_deriv_+3A_sd">sd</code></td>
<td>
<p>How many standard deviations to consider.</p>
</td></tr>
<tr><td><code id="directional_deriv_+3A_...">...</code></td>
<td>
<p>Additional arguments to pass through (eg local.var to the emulator functions)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a point <code>x</code> and a direction <code>v</code>, we find the overlap between E[f'(x)] and
<code>v</code>. The emulated derivative has uncertainty associated with it: the variance is taken
into account using <code class="reqn">v^{T} Var[f'(x)] v</code>.
</p>
<p>If <code>sd == NULL</code>, then only the (normed) overlap between the derivative and the direction
vector is returned. Otherwise a pair of values are returned: these are the normed overlap plus
or minus <code>sd</code> times the uncertainty.
</p>
<p>This function is concerned with ascertaining whether a direction is oriented in the direction
of the emulator gradient, subject to the uncertainty around the estimate of the derivative.
It allows for a consideration of &quot;emulated gradient descent&quot;.
</p>


<h3>Value</h3>

<p>Either a single numeric or a pair of numerics (see description)
</p>


<h3>Examples</h3>

<pre><code class='language-R'> directional_deriv(SIREmulators$ems[[1]], SIRSample$validation[1,], c(1,1,1))

</code></pre>

<hr>
<h2 id='directional_proposal'>Emulated Derivative Point Proposal</h2><span id='topic+directional_proposal'></span>

<h3>Description</h3>

<p>Proposes a new point by applying &lsquo;emulated gradient descent&rsquo; on an existing point.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>directional_proposal(
  ems,
  x,
  targets,
  accept = 2,
  hstart = 1e-04,
  hcutoff = 1e-09,
  iteration.measure = "exp",
  iteration.steps = 100,
  nv = 500
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="directional_proposal_+3A_ems">ems</code></td>
<td>
<p>The emulators to evaluate with respect to.</p>
</td></tr>
<tr><td><code id="directional_proposal_+3A_x">x</code></td>
<td>
<p>The original point.</p>
</td></tr>
<tr><td><code id="directional_proposal_+3A_targets">targets</code></td>
<td>
<p>The list of emulator targets.</p>
</td></tr>
<tr><td><code id="directional_proposal_+3A_accept">accept</code></td>
<td>
<p>The implausibility below which we allow an output to worsen.</p>
</td></tr>
<tr><td><code id="directional_proposal_+3A_hstart">hstart</code></td>
<td>
<p>The initial step size.</p>
</td></tr>
<tr><td><code id="directional_proposal_+3A_hcutoff">hcutoff</code></td>
<td>
<p>The minimum allowed step size.</p>
</td></tr>
<tr><td><code id="directional_proposal_+3A_iteration.measure">iteration.measure</code></td>
<td>
<p>Either &lsquo;exp&rsquo; for expectation or &lsquo;imp&rsquo; for implausibility.</p>
</td></tr>
<tr><td><code id="directional_proposal_+3A_iteration.steps">iteration.steps</code></td>
<td>
<p>The number of allowed iterations.</p>
</td></tr>
<tr><td><code id="directional_proposal_+3A_nv">nv</code></td>
<td>
<p>The number of directions on the n-sphere to try.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a point (preferably close to the implausibility boundary) <code>x</code>, we can calculate
the emulated gradient at this point for each emulator. If the estimate of the expectation
at this point for a given emulator is larger than the target value, then we would like to
move in the direction of greatest decrease for this emulator, and conversely for an estimate
of the expectation that's smaller than the target value. The combination of this information
for every emulator under consideration defines a preferred set of directions of travel from
this point.
</p>
<p>We may try to find a shared direction which improves (or at least does not worsen) all
emulator evaluations. If a point is already well inside the implausibility boundary for a given
output (where &lsquo;well inside&rsquo; is defined by the value of <code>accept</code>), we may allow this
output to worsen in order to improve the others.
</p>
<p>Provided a shared direction, v, can be identified, we iteratively move in this direction. Define
the new proposed point x' = x + h*v, where h is a step-size given by <code>hstart</code>. Compare
the summary statistic (either expectational difference or implausibility) to that provided by
the original point; if the new point gives improvement, then continue to move in this direction
until no further improvement is possible for this step-size. The step-size is reduced (up to
a minimum of <code>hcutoff</code>) and the process is repeated. Only finitely many iteration steps
are permitted; this can be tuned by supplying a value of <code>iteration.steps</code>.
</p>


<h3>Value</h3>

<p>Either a new proposal point, or the original point if an improvement could not be found.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Take a point from the SIR system at later waves with low (but &gt;3) implausibility
 start_point &lt;- SIRMultiWaveData[[2]][90,1:3]
 ems &lt;- SIRMultiWaveEmulators[[3]]
 targs &lt;- SIREmulators$targets
 # Using expected error as measure
 new_point1 &lt;- directional_proposal(ems, start_point, targs, iteration.steps = 50,
  nv = 100)
 # Using implausibility as measure
 new_point2 &lt;- directional_proposal(ems, start_point, targs, iteration.measure = 'imp',
  iteration.steps = 50, nv = 100)
 all_points &lt;- do.call('rbind.data.frame', list(start_point, new_point1, new_point2))
 nth_implausible(ems, all_points, targs)

</code></pre>

<hr>
<h2 id='effect_strength'>Find Effect Strength of Active Variables</h2><span id='topic+effect_strength'></span>

<h3>Description</h3>

<p>Collates the linear and quadratic contributions of the active variables to the global
emulators' behaviour
</p>


<h3>Usage</h3>

<pre><code class='language-R'>effect_strength(
  ems,
  plt = interactive(),
  line.plot = FALSE,
  grid.plot = FALSE,
  labels = TRUE,
  quadratic = TRUE,
  xvar = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="effect_strength_+3A_ems">ems</code></td>
<td>
<p>The Emulator object(s) to be analysed.</p>
</td></tr>
<tr><td><code id="effect_strength_+3A_plt">plt</code></td>
<td>
<p>Should the results be plotted?</p>
</td></tr>
<tr><td><code id="effect_strength_+3A_line.plot">line.plot</code></td>
<td>
<p>Should a line plot be produced?</p>
</td></tr>
<tr><td><code id="effect_strength_+3A_grid.plot">grid.plot</code></td>
<td>
<p>Should the effect strengths be plotted as a grid?</p>
</td></tr>
<tr><td><code id="effect_strength_+3A_labels">labels</code></td>
<td>
<p>Whether or not the legend should be included.</p>
</td></tr>
<tr><td><code id="effect_strength_+3A_quadratic">quadratic</code></td>
<td>
<p>Whether or not quadratic effect strength should be calculated.</p>
</td></tr>
<tr><td><code id="effect_strength_+3A_xvar">xvar</code></td>
<td>
<p>Should the inputs be used on the x-axis?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a set of emulators, it can be useful to see the relative contributions of various
parameters to the global part of the emulator (i.e. the regression surface). This
function extracts the relevant information from a list of emulator objects.
</p>
<p>The parameter <code>quadratic</code> controls whether quadratic effect strength is
calculated and plotted (an unnecessary plot if, say, linear emulators have been trained).
The remaining options control visual aspects of the plots: <code>line.plot</code> determines
whether a line or bar (default) plot should be produced, <code>grid.plot</code> determines
whether the results are plotted as a graph or a grid, and <code>labels</code> determines
if a legend should be provided with the plot (for large numbers of emulators, it is
advisable to set this to <code>FALSE</code>).
</p>


<h3>Value</h3>

<p>A list of data.frames: the first is the linear strength, and the second quadratic.
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> effect &lt;- effect_strength(SIREmulators$ems)
 effect_line &lt;- effect_strength(SIREmulators$ems, line.plot = TRUE)
 effect_grid &lt;- effect_strength(SIREmulators$ems, grid.plot = TRUE)
</code></pre>

<hr>
<h2 id='Emulator'>Bayes Linear Emulator</h2><span id='topic+Emulator'></span>

<h3>Description</h3>

<p>Creates a univariate emulator object.
</p>
<p>The structure of the emulator is <code>f(x) = g(x) * beta + u(x)</code>, for
regression functions <code>g(x)</code>, regression coefficients <code>beta</code>,
and correlation structure <code>u(x)</code>. An emulator can be created with
or without data; the preferred method is to create an emulator based on
prior specifications in the absence of data, then use that emulator
with data to generate a new one (see examples).
</p>


<h3>Constructor</h3>

<p><code>Emulator$new(basis_f, beta, u, ranges, ...)</code>
</p>


<h3>Arguments</h3>

<p>Required:
</p>
<p><code>basis_f</code> A list of basis functions to be used. The constant function
<code>function(x) 1</code> should be provided as the first element.
</p>
<p><code>beta</code> The specification for the regression parameters. This should
be provided in the form <code>list(mu, sigma)</code>, where <code>mu</code> are the
expectations of the coefficients (aligning with the ordering of <code>basis_f</code>)
and <code>sigma</code> the corresponding covariance matrix.
</p>
<p><code>u</code> The specifications for the correlation structure. This should
be specified in the form <code>list(sigma, corr)</code>, where <code>sigma</code> is
a single-valued object, and <code>corr</code> is a Correlator object.
</p>
<p><code>ranges</code> A named list of ranges for the input parameters, provided as
a named list of length-two numeric vectors.
</p>
<p>Optional:
</p>
<p><code>data</code> A <code>data.frame</code> consisting of the data with which to adjust
the emulator, consisting of input values for each parameter and the output.
</p>
<p><code>out_name</code> The name of the output variable.
</p>
<p><code>a_vars</code> A logical vector indicating which variables are active for
this emulator.
</p>
<p><code>discs</code> Model discrepancies: does not include observational error. Ideally
split into <code>list(internal = ..., external = ...)</code>.
</p>
<p>Internal:
</p>
<p><code>model</code> If a linear model, or otherwise, has been fitted to the data,
it lives here.
</p>
<p><code>original_em</code> If the emulator has been adjusted, the unadjusted
<code>Emulator</code> object is stored, for use of <code>set_sigma</code> or similar.
</p>
<p><code>multiplier</code> A multiplicative factor to be applied to u_sigma. Typically
equal to 1, unless changes have been made by, for example, <code>mult_sigma</code>.
</p>


<h3>Constructor Details</h3>

<p>The constructor must take, as a minimum: a list of vectorised basis
functions, whose length is equal to the number of regression
coefficients; a correlation structure, which can be non-stationary;
and the parameter ranges, used to scale all inputs to the range [-1,1].
</p>
<p>The construction of a correlation structure is detailed in the documentation
for Correlator.
</p>


<h3>Accessor Methods</h3>

<p><code>get_exp(x, include_c)</code> Returns the emulator expectation at a point,
or at a collection of points. If <code>include_c = FALSE</code>, the contribution
made by the correlation structure is not included.
</p>
<p><code>get_cov(x, xp = NULL, full = FALSE, include_c)</code> Returns the covariance between
collections of points <code>x</code> and <code>xp</code>. If <code>xp</code> is not supplied,
then this is equivalent to <code>get_cov(x, x, ...)</code>; if <code>full = TRUE</code>,
then the full covariance matrix is calculated - this is FALSE by default
due to most built-in uses requiring only the diagonal terms, and allows us
to take advantage of computational tricks for efficiency.
</p>
<p><code>implausibility(x, z, cutoff = NULL)</code> Returns the implausibility for a
collection of points <code>x</code>. The implausibility is the distance between the
emulator expectation and a desired output value, weighted by the emulator
variance and any external uncertainty. The target, z, should be specified
as a named pair <code>list(val, sigma)</code>, or a single numeric value.
If <code>cutoff = NULL</code>, the output is a numeric <code>I</code>; if <code>cutoff</code>
is a numeric value, then the output is boolean corresponding to
<code>I &lt;= cutoff</code>.
</p>
<p><code>get_exp_d(x, p)</code> Returns the expectation of the derivative of the emulated
function, E[f'(x)]. Similar in structure to <code>get_exp</code> but for the additional
parameter <code>p</code>, which indicates which of the input dimensions the derivative
is performed with respect to.
</p>
<p><code>get_cov_d(x, p1, xp = NULL, p2 = NULL, full = FALSE)</code> Returns the variance of
the derivative of the emulated function, Var[f'(x)]. The arguments are similar to
that of <code>get_cov</code>, but for the addition of parameters <code>p1</code> and <code>p2</code>,
which indicate the derivative directions. Formally, the output of this function is
equivalent to Cov[df/dp1, df/dp2].
</p>
<p><code>print(...)</code> Returns a summary of the emulator specifications.
</p>
<p><code>plot(...)</code> A wrapper for <code><a href="#topic+emulator_plot">emulator_plot</a></code> for a single Emulator object.
</p>


<h3>Object Methods</h3>

<p><code>adjust(data, out_name)</code> Performs Bayes Linear Adjustment, given <code>data</code>.
The data should contain all input parameters, even inactive ones, and the
single output that we wish to emulate. <code>adjust</code> creates a new <code>Emulator</code>
object with the adjusted expectation and variance resulting from Bayes
Linear adjustment, allowing for the requisite predictions to be made using
<code>get_exp</code> and <code>get_cov</code>.
</p>
<p><code>set_sigma(sigma)</code> Modifies the (usually constant) global variance of
the correlation structure, <code>Var[u(X)]</code>. If the emulator has been trained,
the original emulator is modified and Bayes Linear adjustment is again performed.
</p>
<p><code>mult_sigma(m)</code> Modifies the global variance of the correlation structure via
a multiplicative factor. As with <code>set_sigma</code>, this change will chain through
any prior emulators if the emulator in question is Bayes Linear adjusted.
</p>
<p><code>set_hyperparams(hp, nugget)</code> Modifies the underlying correlator for <code>u(x)</code>.
Behaves in a similar way to <code>set_sigma</code> as regards trained emulators. See
the Correlator documentation for details of <code>hp</code> and <code>nugget</code>.
</p>


<h3>References</h3>

<p>Goldstein &amp; Wooff (2007) &lt;ISBN: 9780470065662&gt;
</p>
<p>Craig, Goldstein, Seheult &amp; Smith (1998) &lt;doi:10.1111/1467-9884.00115&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>basis_functions &lt;- list(function(x) 1, function(x) x[[1]], function(x) x[[2]])
beta &lt;- list(mu = c(1,2,3),
             sigma = matrix(c(0.5, -0.1, 0.2, -0.1, 1, 0, 0.2, 0, 1.5), nrow = 3))
u &lt;- list(mu = function(x) 0, sigma = 3, corr = Correlator$new('exp_sq', list(theta = 0.1)))
ranges &lt;- list(a = c(-0.5, 0.5), b = c(-1, 2))
em &lt;- Emulator$new(basis_functions, beta, u, ranges)
em
# Individual evaluations of points
# Points should still be declared in a data.frame
em$get_exp(data.frame(a = 0.1, b = 0.1)) #&gt; 0.6
em$get_cov(data.frame(a = 0.1, b = 0.1)) #&gt; 9.5
# 4x4 grid of points
sample_points &lt;- expand.grid(a = seq(-0.5, 0.5, length.out = 4), b = seq(-1, 2, length.out = 4))
em$get_exp(sample_points) # Returns 16 expectations
em$get_cov(sample_points) # Returns 16 variances
sample_points_2 &lt;- expand.grid(a = seq(-0.5, 0.5, length.out = 3),
                               b = seq(-1, 2, length.out = 4))
em$get_cov(sample_points, xp = sample_points_2, full = TRUE) # Returns a 16x12 matrix of covariances


fake_data &lt;- data.frame(a = runif(10, -0.5, 0.5), b = runif(10, -1, 2))
fake_data$c &lt;- fake_data$a + 2*fake_data$b
newem &lt;- em$adjust(fake_data, 'c')
all(round(newem$get_exp(fake_data[,names(ranges)]),5) == round(fake_data$c,5)) #&gt;TRUE

matern_em &lt;- Emulator$new(basis_f = c(function(x) 1, function(x) x[[1]], function(x) x[[2]]),
 beta = list(mu = c(1, 0.5, 2), sigma = diag(0, nrow = 3)),
 u = list(corr = Correlator$new('matern', list(nu = 1.5, theta = 0.4))),
 ranges = list(x = c(-1, 1), y = c(0, 3)))
matern_em$get_exp(data.frame(x = 0.4, y = 2.3))

newem_data &lt;- Emulator$new(basis_functions, beta, u, ranges, data = fake_data)
all(round(newem$get_exp(fake_data[,names(ranges)]),5)
   == round(newem_data$get_exp(fake_data[,names(ranges)]), 5)) #&gt;TRUE
newem$get_exp_d(sample_points, 'a')
newem$get_cov_d(sample_points, 'b', p2 = 'a')
</code></pre>

<hr>
<h2 id='emulator_from_data'>Generate Emulators from Data</h2><span id='topic+emulator_from_data'></span>

<h3>Description</h3>

<p>Given data from simulator runs, generates a set of <code><a href="#topic+Emulator">Emulator</a></code> objects,
one for each output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emulator_from_data(
  input_data,
  output_names,
  ranges,
  input_names = names(ranges),
  emulator_type = NULL,
  specified_priors = NULL,
  order = 2,
  beta.var = FALSE,
  corr_name = "exp_sq",
  adjusted = TRUE,
  discrepancies = NULL,
  verbose = interactive(),
  na.rm = FALSE,
  check.ranges = FALSE,
  targets = NULL,
  has.hierarchy = FALSE,
  covariance_opts = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emulator_from_data_+3A_input_data">input_data</code></td>
<td>
<p>Required. A data.frame containing parameter and output values</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_output_names">output_names</code></td>
<td>
<p>Required. A character vector of output names</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_ranges">ranges</code></td>
<td>
<p>Required if input_names is not given. A named list of input parameter ranges</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_input_names">input_names</code></td>
<td>
<p>Required if ranges is not given. The names of the parameters</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_emulator_type">emulator_type</code></td>
<td>
<p>Selects between deterministic, variance, covariance, and multistate emulation</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_specified_priors">specified_priors</code></td>
<td>
<p>A collection of user-determined priors (see description)</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_order">order</code></td>
<td>
<p>To what polynomial order should regression surfaces be fitted?</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_beta.var">beta.var</code></td>
<td>
<p>Should uncertainty in the regression coefficients be included?</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_corr_name">corr_name</code></td>
<td>
<p>If not exp_sq, the name of the correlation structures to fit</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_adjusted">adjusted</code></td>
<td>
<p>Should the return emulators be Bayes linear adjusted?</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_discrepancies">discrepancies</code></td>
<td>
<p>Any known internal or external discrepancies of the model</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_verbose">verbose</code></td>
<td>
<p>Should status updates be provided?</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_na.rm">na.rm</code></td>
<td>
<p>If TRUE, removes output values that are NA</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_check.ranges">check.ranges</code></td>
<td>
<p>If TRUE, modifies ranges to a conservative minimum enclosing hyperrectangle</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_targets">targets</code></td>
<td>
<p>If provided, outputs are checked for consistent over/underestimation</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_has.hierarchy">has.hierarchy</code></td>
<td>
<p>Internal - distinguishes deterministic from hierarchical emulators</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_covariance_opts">covariance_opts</code></td>
<td>
<p>User-specified options for emulating covariance matrices</p>
</td></tr>
<tr><td><code id="emulator_from_data_+3A_...">...</code></td>
<td>
<p>Any additional parameters for custom correlators or additional verbosity options</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Many of the parameters that can be passed to this function are optional: the minimal operating
example requires <code>input_data</code>, <code>output_names</code>, and one of <code>ranges</code> or
<code>input_names</code>. If <code>ranges</code> is supplied, the input names are intuited from that list,
data.frame, or data.matrix; if only <code>input_names</code> is supplied, then ranges are
assumed to be [-1, 1] for each input.
</p>
<p>The ranges can be provided in a few different ways: either as a named list of length-2
numeric vectors (corresponding to upper and lower bounds for each parameter); as a
data.frame with 2 columns and each row corresponding to a parameter; or as a data.matrix
defined similarly as the data.frame. In the cases where the ranges are provided as a
data.frame or data.matrix, the <code>row.names</code> of the data object must be provided, and
a warning will be given if not.
</p>
<p>If the set <code>(input_data, output_names, ranges)</code> is provided and nothing else,
then emulators are fitted as follows. The basis functions and associated regression
coefficients are generated using linear regression up to quadratic order, allowing for
cross-terms. These regression parameters are assumed 'known'.
</p>
<p>The correlation function c(x, x') is assumed to be <code><a href="#topic+exp_sq">exp_sq</a></code> and a corresponding
<code><a href="#topic+Correlator">Correlator</a></code> object is created. The hyperparameters of the correlation
structure are determined using a constrained maximum likelihood argument. This determines
the variance, correlation length, and nugget term.
</p>
<p>The maximum allowed order of the regression coefficients is controlled by <code>order</code>;
the regression coefficients themselves can be deemed uncertain by setting
<code>beta.var = TRUE</code> (in which case their values can change in the hyperparameter
estimation); the hyperparameter search can be overridden by specifying ranges for
each using <code>hp_range</code>.
</p>
<p>In the presence of expert beliefs about the structure of the emulators, information
can be supplied directly using the <code>specified_priors</code> argument. This can contain
specific regression coefficient values <code>beta</code> and regression functions <code>func</code>,
correlation structures <code>u</code>, hyperparameter values <code>hyper_p</code> and nugget term
values <code>delta</code>.
</p>
<p>Some rudimentary data handling functionality exists, but is not a substitute for
sense-checking input data directly. The <code>na.rm</code> option will remove rows of
training data that contain NA values if true; the <code>check.ranges</code> option allows
a redefinition of the ranges of input parameters for emulator training if true. The
latter is a common practice in later waves of emulation in order to maximise the
predictive power of the emulators, but should only be used if it is believed that
the training set provided is truly representative of and spans the full space of
interest.
</p>
<p>Various different classes of emulator can be created using this function, depending
on the nature of the model. The <code>emulator_type</code> argument accepts a few different
options:
</p>

<dl>
<dt>&quot;variance&quot;</dt><dd><p>Create emulators for the mean and variance surfaces, for each stochastic output</p>
</dd>
<dt>&quot;covariance</dt><dd><p>Create emulators for the mean surface, and a covariance matrix for the variance surface</p>
</dd>
<dt>&quot;multistate&quot;</dt><dd><p>Create sets of emulators per output for multistate stochastic systems</p>
</dd>
<dt>&quot;default&quot;</dt><dd><p>Deterministic emulators with no covariance structure</p>
</dd>
</dl>

<p>The &quot;default&quot; behaviour will apply if the <code>emulator_type</code> argument is not supplied, or
does not match any of the above options. If the data provided looks to display stochasticity,
but default behaviour is used, a warning will be generated and only the first model result
for each individual parameter set will be used in training.
</p>
<p>For examples of this function's usage (including optional argument behaviour), see the examples.
</p>


<h3>Value</h3>

<p>An appropriately structured list of <code><a href="#topic+Emulator">Emulator</a></code> objects
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Deterministic: use the SIRSample training dataset as an example.
ranges &lt;- list(aSI = c(0.1, 0.8), aIR = c(0, 0.5), aSR = c(0, 0.05))
out_vars &lt;- c('nS', 'nI', 'nR')
ems_linear &lt;- emulator_from_data(SIRSample$training, out_vars, ranges, order = 1)
ems_linear # Printout of the key information.

# Stochastic: use the BirthDeath training dataset
v_ems &lt;- emulator_from_data(BirthDeath$training, c("Y"),
 list(lambda = c(0, 0.08), mu = c(0.04, 0.13)), emulator_type = 'variance')

# If different specifications are wanted for variance/expectation ems, then
# enter a list with entries 'variance', 'expectation'. Eg corr_names
v_ems_corr &lt;- emulator_from_data(BirthDeath$training, c("Y"),
 list(lambda = c(0, 0.08), mu = c(0.4, 0.13)), emulator_type = 'variance',
 corr_name = list(variance = "matern", expectation = "exp_sq")
)


  ems_quad &lt;- emulator_from_data(SIRSample$training, out_vars, ranges)
  ems_quad # Now includes quadratic terms
  ems_cub &lt;- emulator_from_data(SIRSample$training, out_vars, ranges, order = 3)
  ems_cub # Up to cubic order in the parameters

  ems_unadjusted &lt;- emulator_from_data(SIRSample$training, out_vars, ranges, adjusted = FALSE)
  ems_unadjusted # Looks the same as ems_quad, but the emulators are not Bayes Linear adjusted

  # Reproduce the linear case, but with slightly adjusted beta values
  basis_f &lt;- list(
   c(function(x) 1, function(x) x[[1]], function(x) x[[2]]),
   c(function(x) 1, function(x) x[[1]], function(x) x[[2]]),
   c(function(x) 1, function(x) x[[1]], function(x) x[[3]])
  )
  beta_val &lt;- list(
   list(mu = c(550, -400, 250)),
   list(mu = c(200, 200, -300)),
   list(mu = c(200, 200, -50))
  )
  ems_custom_beta &lt;- emulator_from_data(SIRSample$training, out_vars, ranges,
   specified_priors = list(func = basis_f, beta = beta_val)
  )
  # Custom correlation functions
  corr_structs &lt;- list(
   list(sigma = 83, corr = Correlator$new('exp_sq', list(theta = 0.5), nug = 0.1)),
   list(sigma = 95, corr = Correlator$new('exp_sq', list(theta = 0.4), nug = 0.25)),
   list(sigma = 164, corr = Correlator$new('matern', list(theta = 0.2, nu = 1.5), nug = 0.45))
  )
  ems_custom_u &lt;- emulator_from_data(SIRSample$training, out_vars, ranges,
  specified_priors = list(u = corr_structs))
  # Allowing the function to choose hyperparameters for 'non-standard' correlation functions
  ems_matern &lt;- emulator_from_data(SIRSample$training, out_vars, ranges, corr_name = 'matern')
  # Providing hyperparameters directly
  matern_hp &lt;- list(
   list(theta = 0.8, nu = 1.5),
   list(theta = 0.6, nu = 2.5),
   list(theta = 1.2, nu = 0.5)
  )
  ems_matern2 &lt;- emulator_from_data(SIRSample$training, out_vars, ranges, corr_name = 'matern',
   specified_priors = list(hyper_p = matern_hp))
  # "Custom" correaltion function with user-specified ranges: gamma exponential
  # Any named, defined, correlation function can be passed. See Correlator documentation
  ems_gamma &lt;- emulator_from_data(SIRSample$training, out_vars, ranges, corr_name = 'gamma_exp',
   specified_priors = list(hyper_p = list(gamma = c(0.01, 2), theta = c(1/3, 2))))

  # Multistate emulation: use the stochastic SIR dataset
  SIR_names &lt;- c("I10", "I25", "I50", "R10", "R25", "R50")
  b_ems &lt;- emulator_from_data(SIR_stochastic$training, SIR_names,
   ranges, emulator_type = 'multistate')

  # Covariance emulation, with specified non-zero matrix elements
  which_cov &lt;- matrix(rep(TRUE, 16), nrow = 4)
  which_cov[2,3] &lt;- which_cov[3,2] &lt;- which_cov[1,4] &lt;- which_cov[4,1] &lt;- FALSE
  c_ems &lt;- emulator_from_data(SIR_stochastic$training, SIR_names[-c(3,6)], ranges,
   emulator_type = 'covariance', covariance_opts = list(matrix = which_cov))


</code></pre>

<hr>
<h2 id='emulator_plot'>Plot Emulator Outputs</h2><span id='topic+emulator_plot'></span>

<h3>Description</h3>

<p>A function for plotting emulator expectations, variances, and implausibilities
</p>


<h3>Usage</h3>

<pre><code class='language-R'>emulator_plot(
  ems,
  plot_type = "exp",
  ppd = 30,
  targets = NULL,
  cb = FALSE,
  params = NULL,
  fixed_vals = NULL,
  nth = 1,
  imp_breaks = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="emulator_plot_+3A_ems">ems</code></td>
<td>
<p>An <code><a href="#topic+Emulator">Emulator</a></code> object, or a list thereof.</p>
</td></tr>
<tr><td><code id="emulator_plot_+3A_plot_type">plot_type</code></td>
<td>
<p>The statistic to plot (see description or examples).</p>
</td></tr>
<tr><td><code id="emulator_plot_+3A_ppd">ppd</code></td>
<td>
<p>The number of points per plotting dimension</p>
</td></tr>
<tr><td><code id="emulator_plot_+3A_targets">targets</code></td>
<td>
<p>If required, the targets from which to calculate implausibility</p>
</td></tr>
<tr><td><code id="emulator_plot_+3A_cb">cb</code></td>
<td>
<p>A boolean representing whether a colourblind-friendly plot is produced.</p>
</td></tr>
<tr><td><code id="emulator_plot_+3A_params">params</code></td>
<td>
<p>Which two input parameters should be plotted?</p>
</td></tr>
<tr><td><code id="emulator_plot_+3A_fixed_vals">fixed_vals</code></td>
<td>
<p>For fixed input parameters, the values they are held at.</p>
</td></tr>
<tr><td><code id="emulator_plot_+3A_nth">nth</code></td>
<td>
<p>If plotting nth maximum implausibility, which level maximum to plot.</p>
</td></tr>
<tr><td><code id="emulator_plot_+3A_imp_breaks">imp_breaks</code></td>
<td>
<p>If plotting nth maximum implausibility, defines the levels at
which to draw contours.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a single emulator, or a set of emulators, the emulator statistics can be plotted
across a two-dimensional slice of the parameter space. Which statistic is plotted is
determined by <code>plot_type</code>: options are &lsquo;exp&rsquo;, &lsquo;var&rsquo;, &lsquo;sd&rsquo;, &lsquo;imp&rsquo;, and &lsquo;nimp&rsquo;, which
correspond to expectation, variance, standard deviation, implausibility, and nth-max
implausibility.
</p>
<p>By default, the slice varies in the first two parameters of the emulators, and all other
parameters are taken to be fixed at their mid-range values. This behaviour can be changed
with the <code>params</code> and <code>fixed_vals</code> parameters (see examples).
</p>
<p>If the statistic is &lsquo;exp&rsquo;, &lsquo;var&rsquo; or &lsquo;sd&rsquo;, then the minimal set of parameters to pass to this
function are <code>ems</code> (which can be a list of emulators or a single one) and <code>plot_type</code>.
If the statistic is &lsquo;imp&rsquo; or &lsquo;nimp&rsquo;, then the <code>targets</code> must be supplied - it is not
necessary to specify the individual target for a single emulator plot. If the statistic is
&lsquo;nimp&rsquo;, then the level of maximum implausibility can be chosen with the parameter <code>nth</code>.
</p>
<p>Implausibility plots are typically coloured from green (low implausibility) to red (high
implausibility): a colourblind-friendly option is available and can be turned on by setting
<code>cb = TRUE</code>.
</p>
<p>The granularity of the plot is controlled by the <code>ppd</code> parameter, determining the number
of points per dimension in the grid. For higher detail, at the expense of longer computing
time, increase this value. The default is 30.
</p>


<h3>Value</h3>

<p>A ggplot object, or collection thereof.
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Reducing ppd to 10 for speed.
 emulator_plot(SIREmulators$ems, ppd = 10)
 emulator_plot(SIREmulators$ems$nS, ppd = 10)
 emulator_plot(SIREmulators$ems, plot_type = 'var', ppd = 10, params = c('aIR', 'aSR'))
 
    emulator_plot(SIREmulators$ems, plot_type = 'imp', ppd = 10,
     targets = SIREmulators$targets,
     fixed_vals = list(aSR = 0.02))
    emulator_plot(SIREmulators$ems, plot_type = 'nimp', cb = TRUE,
     targets = SIREmulators$targets, nth = 2, ppd = 10)
 

</code></pre>

<hr>
<h2 id='exp_sq'>Exponential squared correlation function</h2><span id='topic+exp_sq'></span>

<h3>Description</h3>

<p>For points <code>x</code>, <code>xp</code> and a correlation length <code>theta</code>, gives the exponent
of the squared distance between <code>x</code> and <code>xp</code>, weighted by <code>theta</code> squared.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>exp_sq(x, xp, hp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="exp_sq_+3A_x">x</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="exp_sq_+3A_xp">xp</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="exp_sq_+3A_hp">hp</code></td>
<td>
<p>The hyperparameter theta (correlation length)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The exponential-squared correlation between x and xp.
</p>


<h3>References</h3>

<p>Rasmussen &amp; Williams (2005) &lt;ISBN: 9780262182539&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>exp_sq(data.frame(a=1), data.frame(a=2), list(theta = 0.1))
#&gt; 3.720076e-44
exp_sq(data.frame(a=1,b=2,c=-1),data.frame(a=1.5,b=2.9,c=-0.7), list(theta = 0.2))
#&gt; 3.266131e-13
</code></pre>

<hr>
<h2 id='full_wave'>Automatic Wave Calculation</h2><span id='topic+full_wave'></span>

<h3>Description</h3>

<p>Performs a full wave of emulation and history matching, given data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>full_wave(
  data,
  ranges,
  targets,
  old_emulators = NULL,
  prop_train = 0.7,
  cutoff = 3,
  nth = 1,
  verbose = interactive(),
  n_points = nrow(data),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="full_wave_+3A_data">data</code></td>
<td>
<p>The data to train with.</p>
</td></tr>
<tr><td><code id="full_wave_+3A_ranges">ranges</code></td>
<td>
<p>The ranges of the input parameters</p>
</td></tr>
<tr><td><code id="full_wave_+3A_targets">targets</code></td>
<td>
<p>The output targets to match to.</p>
</td></tr>
<tr><td><code id="full_wave_+3A_old_emulators">old_emulators</code></td>
<td>
<p>Any emulators from previous waves.</p>
</td></tr>
<tr><td><code id="full_wave_+3A_prop_train">prop_train</code></td>
<td>
<p>What proportion of the data is used for training.</p>
</td></tr>
<tr><td><code id="full_wave_+3A_cutoff">cutoff</code></td>
<td>
<p>The implausibility cutoff for point generation and diagnostics.</p>
</td></tr>
<tr><td><code id="full_wave_+3A_nth">nth</code></td>
<td>
<p>The level of maximum implausibility to consider.</p>
</td></tr>
<tr><td><code id="full_wave_+3A_verbose">verbose</code></td>
<td>
<p>Should progress be printed to console?</p>
</td></tr>
<tr><td><code id="full_wave_+3A_n_points">n_points</code></td>
<td>
<p>The number of points to generate from <code><a href="#topic+generate_new_design">generate_new_design</a></code>.</p>
</td></tr>
<tr><td><code id="full_wave_+3A_...">...</code></td>
<td>
<p>Any arguments to be passed to <code><a href="#topic+emulator_from_data">emulator_from_data</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses all of the functionality from the package in a relatively conservative form.
The function performs the following steps:
</p>
<p>1) Split the data into a training set and a validation set, where <code>prop_train</code> indicates
what proportion of the data is used to train.
</p>
<p>2) Perform emulator training using <code><a href="#topic+emulator_from_data">emulator_from_data</a></code>. If a more involved
specification is desired, optional arguments can be passed to <code>emulator_from_data</code> using
the <code>...</code> argument.
</p>
<p>3) Perform diagnostics on the trained emulators, removing emulators that do not display
acceptable performance. Global emulator variance may also be modified to ensure that none of
the emulators demonstrate misclassification errors (from <code><a href="#topic+classification_diag">classification_diag</a></code>).
</p>
<p>4) Ordering the remaining emulators from most restrictive to least restrictive on the dataset
provided at this wave. Some point generation mechanisms terminate early if a point is ruled
out by a single emulator, so the ordering ensures this happens earlier rather than later.
</p>
<p>5) Generate the new points using the default method of <code><a href="#topic+generate_new_design">generate_new_design</a></code>, using
the normal procedure (for details, see the description for generate_new_design). By default, it
generates the same number of points as it was provided to train and validate on.
</p>
<p>If the parameter <code>old_emulators</code> is provided, this should be a list of emulators used
at all previous waves - for example if <code>full_wave</code> is used to do a second wave of
history matching, then <code>old_emulators</code> would contain the list of first-wave emulators.
</p>
<p>The function returns a list of two objects: <code>emulators</code> corresponding to this wave's
emulators, and <code>points</code> corresponding to the new proposed points. The points can then
be put into the simulator to generate runs for a subsequent wave.
</p>


<h3>Value</h3>

<p>A list of two objects: <code>points</code> and <code>emulators</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 ranges &lt;- list(aSI = c(0.1, 0.8), aIR = c(0, 0.5), aSR = c(0, 0.05))
 default &lt;- full_wave(do.call('rbind.data.frame', SIRSample), ranges,
  SIREmulators$targets)
 non_quad &lt;- full_wave(do.call('rbind.data.frame', SIRSample), ranges,
  SIREmulators$targets, quadratic = FALSE)
 second &lt;- full_wave(SIRMultiWaveData[[2]], ranges, SIREmulators$targets,
  old_emulators = SIRMultiWaveEmulators[[1]])
 
</code></pre>

<hr>
<h2 id='gamma_exp'>Gamma-exponential correlation function</h2><span id='topic+gamma_exp'></span>

<h3>Description</h3>

<p>For points <code>x</code>, <code>xp</code>, and a pair of hyperparameters <code>gamma</code> and <code>theta</code>,
gives the gamma-exponential correlation between the two points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gamma_exp(x, xp, hp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gamma_exp_+3A_x">x</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="gamma_exp_+3A_xp">xp</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="gamma_exp_+3A_hp">hp</code></td>
<td>
<p>The hyperparameters theta (correlation length) and gamma (exponent), as a named list</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The gamma-exponential correlation function, for d = |x-x'|, is given by
<code class="reqn">\exp(-(d/\theta)^\gamma)</code>. Gamma must be between 0 (exclusive) and 2 (inclusive).
</p>


<h3>Value</h3>

<p>The gamma-exponential correlation between x and xp.
</p>


<h3>References</h3>

<p>Rasmussen &amp; Williams (2005) &lt;ISBN: 9780262182539&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gamma_exp(data.frame(a=1), data.frame(a=2), list(gamma = 1.5, theta = 0.1))
#&gt; 1.846727e-14
gamma_exp(data.frame(a=1,b=2,c=-1),data.frame(a=1.5,b=2.9,c=-0.7), list(gamma = 1.3, theta = 0.2))
#&gt; 0.0001399953
</code></pre>

<hr>
<h2 id='generate_new_design'>Generate Proposal Points</h2><span id='topic+generate_new_design'></span>

<h3>Description</h3>

<p>Given a set of trained emulators, this finds the next set of points that will be
informative for a subsequent wave of emulation or, in the event that the
current wave is the last desired, a set of points that optimally span the
parameter region of interest. There are a number of different methods that can
be utilised, alone or in combination with one another, to generate the points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_new_design(
  ems,
  n_points,
  z,
  method = "default",
  cutoff = 3,
  plausible_set,
  verbose = interactive(),
  opts = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_new_design_+3A_ems">ems</code></td>
<td>
<p>A list of <code><a href="#topic+Emulator">Emulator</a></code> objects, trained
on previous design points.</p>
</td></tr>
<tr><td><code id="generate_new_design_+3A_n_points">n_points</code></td>
<td>
<p>The desired number of points to propose.</p>
</td></tr>
<tr><td><code id="generate_new_design_+3A_z">z</code></td>
<td>
<p>The targets to match to.</p>
</td></tr>
<tr><td><code id="generate_new_design_+3A_method">method</code></td>
<td>
<p>Which methods to use.</p>
</td></tr>
<tr><td><code id="generate_new_design_+3A_cutoff">cutoff</code></td>
<td>
<p>The value of the cutoff to use to assess suitability.</p>
</td></tr>
<tr><td><code id="generate_new_design_+3A_plausible_set">plausible_set</code></td>
<td>
<p>An optional set of known non-implausible points, to avoid LHD sampling.</p>
</td></tr>
<tr><td><code id="generate_new_design_+3A_verbose">verbose</code></td>
<td>
<p>Should progress statements be printed to the console?</p>
</td></tr>
<tr><td><code id="generate_new_design_+3A_opts">opts</code></td>
<td>
<p>A named list of opts as described.</p>
</td></tr>
<tr><td><code id="generate_new_design_+3A_...">...</code></td>
<td>
<p>Any parameters to pass via chaining to individual sampling functions (eg <code>distro</code>
for importance sampling or <code>ordering</code> for collecting emulators).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the <code>method</code> argument contains <code>'lhs'</code>, a Latin hypercube is generated and
non-implausible points from this design are retained. If more points are accepted
than the next design requires, then points are subselected using a maximin argument.
</p>
<p>If <code>method</code> contains <code>'line'</code>, then line sampling is performed. Given an
already established collection of non-implausible points, rays are drawn between
pairs of points (selected so as to maximise the distance between them) and more
points are sampled along the rays. Points thus sampled are retained if they lie
near a boundary of the non-implausible space, or on the boundary of the parameter
region of interest.
</p>
<p>If <code>method</code> contains <code>'importance'</code>, importance sampling is performed.
Given a collection of non-implausible points, a mixture distribution of either
multivariate normal or uniform ellipsoid proposals around the current non-implausible
set are constructed. The optimal standard deviation (in the normal case) or radius
(in the ellipsoid case) is determined using a burn-in phase, and points are
proposed until the desired number of points have been found.
</p>
<p>If <code>method</code> contains <code>'slice'</code>, then slice sampling is performed. Given
a single known non-implausible point, a minimum enclosing hyperrectangle (perhaps
after transforming the space) is determined and points are sampled for each dimension
of the parameter space uniformly, shrinking the minimum enclosing hyperrectangle as
appropriate. This method is akin to to a Gibbs sampler.
</p>
<p>If <code>method</code> contains <code>'optical'</code>, then optical depth sampling is used.
Given a set of non-implausible points, an approximation of the one-dimensional
marginal distributions for each parameter can be determined. From these derived
marginals, points are sampled and subject to rejection as in the LHD sampling.
</p>
<p>For any sampling strategy, the parameters <code>ems</code>, <code>n_points</code>, and <code>z</code>
must be provided. All methods rely on a means of assessing point suitability, which
we refer to as an implausibility measure. By default, this uses nth-maximum implausibility
as provided by <code><a href="#topic+nth_implausible">nth_implausible</a></code>; a user-defined method can be provided
instead by supplying the function call to <code>opts[["accept_measure"]]</code>. Any
such function must take at least five arguments: the emulators, the points, the
targets, and a cutoff, as well as a <code>...</code> argument to ensure compatibility with
the default behaviour of the point proposal method. Note that, in accordance with
the default functionality of <code><a href="#topic+nth_implausible">nth_implausible</a></code>, if emulating more than
10 outputs and an explicit <code>opts$nth</code> argument is not provided, then second-max
implausibility is used as the measure.
</p>
<p>The option <code>opts[["seek"]]</code> determines how many points should be chosen that
have a higher probability of matching targets, as opposed to not missing targets. Due
to the danger of such an approach if a representative space-filling design over the
space, this value should not be too high and should be used sparingly at early waves;
even at later waves, it is inadvisable to seek more than 10% of the output points
using this metric. The default is <code>seek = 0</code>, and can be provided as either
a percentage of points desired (in the range [0,1]) or the fixed number of points.
</p>
<p>The default behaviour is as follows. A set of initial points are generated from a
large LHD; line sampling is performed to find the boundaries of the space; then importance
sampling is used to fill out the space. The proposed set of points are thinned and
both line and importance sampling are applied again; this resampling behaviour is
controlled by <code>opts[["resample"]]</code>, where <code>resample = n</code> indicates that
the proposal will be thinned and resampled from <code>n</code> times (resulting in <code>n+1</code>
proposal stages).
</p>
<p>In regions where the non-implausible space at a given cutoff value is very hard to find,
the point proposal will start at a higher cutoff where it can find a space-filling design.
Given such a design at a higher cutoff, it can subselect to a lower cutoff by demanding
some percentage of the proposed points are retained and repeat. This approach terminates
if the 'ladder' of cutoffs reaches the desired cutoff, or if the process asymptotes at
a particular higher cutoff. The opts <code>ladder_tolerance</code> and <code>cutoff_tolerance</code>
determine the minimum improvement required in consecutive cutoffs for the process to not
be considered to be asymptoting and the level of closeness to the desired cutoff at whihc
we are prepared to stop, respectively. For instance, setting <code>ladder_tolerance</code> to
0.1 and <code>cutoff_tolerance</code> to 0.01, with a cutoff of 3, will terminate the process
if two consecutive cutoffs proposed are within 0.1 of each other, or when the points proposed
all have implausibility less than the 3.01.
</p>
<p>These methods may work slowly, or not at all, if the target space is extremely small in
comparison with the initial non-yet-ruled-out (NROY) space; it may also fail to give a
representative sample if the target space is formed of disconnected regions of different
volumes.
</p>


<h3>Value</h3>

<p>A data.frame containing the set of new points upon which to run the model.
</p>


<h3>Arguments within <code>opts</code></h3>


<dl>
<dt>accept_measure</dt><dd><p>A custom implausibility measure to be used.</p>
</dd>
<dt>cluster</dt><dd><p>Whether to try to apply emulator clustering.</p>
</dd>
<dt>cutoff_tolerance</dt><dd><p>Tolerance for an obtained cutoff to be similar enough to that desired.</p>
</dd>
<dt>ladder_tolerance</dt><dd><p>Tolerance with which to determine if the process is asymptoting.</p>
</dd>
<dt>nth</dt><dd><p>The level of nth implausibility to apply, if using the default implausibility.</p>
</dd>
<dt>resample</dt><dd><p>How many times to perform the resampling step once points are found.</p>
</dd>
<dt>seek</dt><dd><p>How many 'good' points should be sought: either as an integer or a ratio.</p>
</dd>
<dt>to_file</dt><dd><p>If output is to be written to file periodically, the file location.</p>
</dd>
<dt>points.factor (LHS, Cluster LHS)</dt><dd><p>How many more points than desired to sample.</p>
</dd>
<dt>pca_lhs (LHS)</dt><dd><p>Whether to apply PCA to the space before proposing.</p>
</dd>
<dt>n_lines (Line)</dt><dd><p>How many lines to draw.</p>
</dd>
<dt>ppl (Line)</dt><dd><p>The number of points to sample per line.</p>
</dd>
<dt>imp_distro (Importance)</dt><dd><p>The distribution to propose around points.</p>
</dd>
<dt>imp_scale (Importance)</dt><dd><p>The radius, or standard deviation, of proposed distributions.</p>
</dd>
<dt>pca_slice (Slice)</dt><dd><p>Whether to apply PCA to the space before slice sampling.</p>
</dd>
<dt>seek_distro (Seek)</dt><dd><p>The distribution to apply when looking for 'good' points.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'> 
  # A simple example that uses  number of the native and ... parameter opts.
  pts &lt;- generate_new_design(SIREmulators$ems, 100, SIREmulators$targets,
  distro = 'sphere', opts = list(resample = 0))
  # Non-default methods
  pts_slice &lt;- generate_new_design(SIREmulators$ems, 100, SIREmulators$targets,
  method = 'slice')
  ## Example using custom measure functionality
  custom_measure &lt;- function(ems, x, z, cutoff, ...) {
  imps_df &lt;- nth_implausible(ems, x, z, get_raw = TRUE)
  sorted_imps &lt;- t(apply(imps_df, 1, sort, decreasing = TRUE))
  imps1 &lt;- sorted_imps[,1] &lt;= cutoff
  imps2 &lt;- sorted_imps[,2] &lt;= cutoff - 0.5
  constraint &lt;- apply(x, 1, function(y) y[[1]] &lt;= 0.4)
  return(imps1 &amp; imps2 &amp; constraint)
  }
  pts_custom &lt;- generate_new_design(SIREmulators$ems, 100, SIREmulators$targets,
  opts = list(accept_measure = custom_measure))
 
</code></pre>

<hr>
<h2 id='generate_new_runs'>Generate Proposal Points</h2><span id='topic+generate_new_runs'></span>

<h3>Description</h3>

<p>This function is deprecated in favour of <code><a href="#topic+generate_new_design">generate_new_design</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>generate_new_runs(
  ems,
  n_points,
  z,
  method = "default",
  cutoff = 3,
  plausible_set,
  verbose = interactive(),
  opts = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="generate_new_runs_+3A_ems">ems</code></td>
<td>
<p>A list of <code><a href="#topic+Emulator">Emulator</a></code> objects, trained
on previous design points.</p>
</td></tr>
<tr><td><code id="generate_new_runs_+3A_n_points">n_points</code></td>
<td>
<p>The desired number of points to propose.</p>
</td></tr>
<tr><td><code id="generate_new_runs_+3A_z">z</code></td>
<td>
<p>The targets to match to.</p>
</td></tr>
<tr><td><code id="generate_new_runs_+3A_method">method</code></td>
<td>
<p>Which methods to use.</p>
</td></tr>
<tr><td><code id="generate_new_runs_+3A_cutoff">cutoff</code></td>
<td>
<p>The value of the cutoff to use to assess suitability.</p>
</td></tr>
<tr><td><code id="generate_new_runs_+3A_plausible_set">plausible_set</code></td>
<td>
<p>An optional set of known non-implausible points, to avoid LHD sampling.</p>
</td></tr>
<tr><td><code id="generate_new_runs_+3A_verbose">verbose</code></td>
<td>
<p>Should progress statements be printed to the console?</p>
</td></tr>
<tr><td><code id="generate_new_runs_+3A_opts">opts</code></td>
<td>
<p>A named list of opts as described.</p>
</td></tr>
<tr><td><code id="generate_new_runs_+3A_...">...</code></td>
<td>
<p>Any parameters to pass via chaining to individual sampling functions (eg <code>distro</code>
for importance sampling or <code>ordering</code> for collecting emulators).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a set of trained emulators, this finds the next set of points that will be
informative for a subsequent wave of emulation or, in the event that the
current wave is the last desired, a set of points that optimally span the
parameter region of interest. There are a number of different methods that can
be utilised, alone or in combination with one another, to generate the points.
</p>
<p>If the <code>method</code> argument contains <code>'lhs'</code>, a Latin hypercube is generated and
non-implausible points from this design are retained. If more points are accepted
than the next design requires, then points are subselected using a maximin argument.
</p>
<p>If <code>method</code> contains <code>'line'</code>, then line sampling is performed. Given an
already established collection of non-implausible points, rays are drawn between
pairs of points (selected so as to maximise the distance between them) and more
points are sampled along the rays. Points thus sampled are retained if they lie
near a boundary of the non-implausible space, or on the boundary of the parameter
region of interest.
</p>
<p>If <code>method</code> contains <code>'importance'</code>, importance sampling is performed.
Given a collection of non-implausible points, a mixture distribution of either
multivariate normal or uniform ellipsoid proposals around the current non-implausible
set are constructed. The optimal standard deviation (in the normal case) or radius
(in the ellipsoid case) is determined using a burn-in phase, and points are
proposed until the desired number of points have been found.
</p>
<p>If <code>method</code> contains <code>'slice'</code>, then slice sampling is performed. Given
a single known non-implausible point, a minimum enclosing hyperrectangle (perhaps
after transforming the space) is determined and points are sampled for each dimension
of the parameter space uniformly, shrinking the minimum enclosing hyperrectangle as
appropriate. This method is akin to to a Gibbs sampler.
</p>
<p>If <code>method</code> contains <code>'optical'</code>, then optical depth sampling is used.
Given a set of non-implausible points, an approximation of the one-dimensional
marginal distributions for each parameter can be determined. From these derived
marginals, points are sampled and subject to rejection as in the LHD sampling.
</p>
<p>For any sampling strategy, the parameters <code>ems</code>, <code>n_points</code>, and <code>z</code>
must be provided. All methods rely on a means of assessing point suitability, which
we refer to as an implausibility measure. By default, this uses nth-maximum implausibility
as provided by <code><a href="#topic+nth_implausible">nth_implausible</a></code>; a user-defined method can be provided
instead by supplying the function call to <code>opts[["accept_measure"]]</code>. Any
such function must take at least five arguments: the emulators, the points, the
targets, and a cutoff, as well as a <code>...</code> argument to ensure compatibility with
the default behaviour of the point proposal method.
</p>
<p>The option <code>opts[["seek"]]</code> determines how many points should be chosen that
have a higher probability of matching targets, as opposed to not missing targets. Due
to the danger of such an approach if a representative space-filling design over the
space, this value should not be too high and should be used sparingly at early waves;
even at later waves, it is inadvisable to seek more than 10% of the output points
using this metric. The default is <code>seek = 0</code>, and can be provided as either
a percentage of points desired (in the range [0,1]) or the fixed number of points.
</p>
<p>The default behaviour is as follows. A set of initial points are generated from a
large LHD; line sampling is performed to find the boundaries of the space; then importance
sampling is used to fill out the space. The proposed set of points are thinned and
both line and importance sampling are applied again; this resampling behaviour is
controlled by <code>opts[["resample"]]</code>, where <code>resample = n</code> indicates that
the proposal will be thinned and resampled from <code>n</code> times (resulting in <code>n+1</code>
proposal stages).
</p>
<p>In regions where the non-implausible space at a given cutoff value is very hard to find,
the point proposal will start at a higher cutoff where it can find a space-filling design.
Given such a design at a higher cutoff, it can subselect to a lower cutoff by demanding
some percentage of the proposed points are retained and repeat. This approach terminates
if the 'ladder' of cutoffs reaches the desired cutoff, or if the process asymptotes at
a particular higher cutoff. The opts <code>ladder_tolerance</code> and <code>cutoff_tolerance</code>
determine the minimum improvement required in consecutive cutoffs for the process to not
be considered to be asymptoting and the level of closeness to the desired cutoff at whihc
we are prepared to stop, respectively. For instance, setting <code>ladder_tolerance</code> to
0.1 and <code>cutoff_tolerance</code> to 0.01, with a cutoff of 3, will terminate the process
if two consecutive cutoffs proposed are within 0.1 of each other, or when the points proposed
all have implausibility less than the 3.01.
</p>
<p>These methods may work slowly, or not at all, if the target space is extremely small in
comparison with the initial non-yet-ruled-out (NROY) space; it may also fail to give a
representative sample if the target space is formed of disconnected regions of different
volumes.
</p>


<h3>Value</h3>

<p>A data.frame containing the set of new points upon which to run the model.
</p>


<h3>Arguments within <code>opts</code></h3>


<dl>
<dt>accept_measure</dt><dd><p>A custom implausibility measure to be used.</p>
</dd>
<dt>cluster</dt><dd><p>Whether to try to apply emulator clustering.</p>
</dd>
<dt>cutoff_tolerance</dt><dd><p>Tolerance for an obtained cutoff to be similar enough to that desired.</p>
</dd>
<dt>ladder_tolerance</dt><dd><p>Tolerance with which to determine if the process is asymptoting.</p>
</dd>
<dt>nth</dt><dd><p>The level of nth implausibility to apply, if using the default implausibility.</p>
</dd>
<dt>resample</dt><dd><p>How many times to perform the resampling step once points are found.</p>
</dd>
<dt>seek</dt><dd><p>How many 'good' points should be sought: either as an integer or a ratio.</p>
</dd>
<dt>to_file</dt><dd><p>If output is to be written to file periodically, the file location.</p>
</dd>
<dt>points.factor (LHS, Cluster LHS)</dt><dd><p>How many more points than desired to sample.</p>
</dd>
<dt>pca_lhs (LHS)</dt><dd><p>Whether to apply PCA to the space before proposing.</p>
</dd>
<dt>n_lines (Line)</dt><dd><p>How many lines to draw.</p>
</dd>
<dt>ppl (Line)</dt><dd><p>The number of points to sample per line.</p>
</dd>
<dt>imp_distro (Importance)</dt><dd><p>The distribution to propose around points.</p>
</dd>
<dt>imp_scale (Importance)</dt><dd><p>The radius, or standard deviation, of proposed distributions.</p>
</dd>
<dt>pca_slice (Slice)</dt><dd><p>Whether to apply PCA to the space before slice sampling.</p>
</dd>
<dt>seek_distro (Seek)</dt><dd><p>The distribution to apply when looking for 'good' points.</p>
</dd>
</dl>


<hr>
<h2 id='get_diagnostic'>Diagnostic Tests for Emulators</h2><span id='topic+get_diagnostic'></span>

<h3>Description</h3>

<p>Given an emulator, return a diagnostic measure.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_diagnostic(
  emulator,
  targets = NULL,
  validation = NULL,
  which_diag = "cd",
  stdev = 3,
  cleaned = NULL,
  warn = TRUE,
  kfold = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="get_diagnostic_+3A_emulator">emulator</code></td>
<td>
<p>An object of class Emulator</p>
</td></tr>
<tr><td><code id="get_diagnostic_+3A_targets">targets</code></td>
<td>
<p>If desired, the target values for the output(s) of the system</p>
</td></tr>
<tr><td><code id="get_diagnostic_+3A_validation">validation</code></td>
<td>
<p>If provided, the emulator is tested against the outputs of these points</p>
</td></tr>
<tr><td><code id="get_diagnostic_+3A_which_diag">which_diag</code></td>
<td>
<p>Which diagnostic measure to use (choosing from cd, ce, se above)</p>
</td></tr>
<tr><td><code id="get_diagnostic_+3A_stdev">stdev</code></td>
<td>
<p>For &lsquo;cd&rsquo;, a measure of the allowed distance from prediction and reality</p>
</td></tr>
<tr><td><code id="get_diagnostic_+3A_cleaned">cleaned</code></td>
<td>
<p>Internal for stochastic emulators</p>
</td></tr>
<tr><td><code id="get_diagnostic_+3A_warn">warn</code></td>
<td>
<p>Should a warning be shown if ce is chosen and no targets provided?</p>
</td></tr>
<tr><td><code id="get_diagnostic_+3A_kfold">kfold</code></td>
<td>
<p>Mainly internal: pre-computed k-fold diagnostic results for output</p>
</td></tr>
<tr><td><code id="get_diagnostic_+3A_...">...</code></td>
<td>
<p>Any other parameters to be passed through to subfunctions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An emulator's suitability can be checked in a number of ways. This function combines all
current diagnostics available in the package, returning a context-dependent data.frame
containing the results.
</p>
<p>Comparison Diagnostics (cd): Given a set of points, the emulator expectation and variance
are calculated. This gives a predictive range for the input point, according to the
emulator. We compare this against the actual value given by the simulator: points whose
emulator prediction is further away from the simulator prediction are to be investigated.
This 'distance' is given by <code>stdev</code>, and an emulator prediction correspondingly
should not be further away from the simulator value than stdev*uncertainty.
</p>
<p>Classification Error (ce): Given a set of targets, the emulator can determine implausibility
of a point with respect to the relevant target, accepting or rejecting it as appropriate.
We can define a similar &lsquo;implausibility&rsquo; function for the simulator: the combination of
the two rejection schemes gives four classifications of points. Any point where the
emulator would reject the point but the simulator would not should be investigated.
</p>
<p>Standardized Error (se): The known value at a point, combined with the emulator expectation
and uncertainty, can be combined to provide a standardized error for a point. This error
should not be too large, in general. but the diagnostic is more useful when looking at
a collection of such measures, where systematic bias or over/underconfidence can be seen.
</p>
<p>Which of the diagnostics is performed can be controlled by the <code>which_diag</code> argument.
If performing classification error diagnostics, a set of targets must be provided; for all
diagnostics, a validation (or holdout) set can be provided. If no such set is given, then
the emulator diagnostics are performed with respect to its training points, using k-fold
cross-validation.
</p>


<h3>Value</h3>

<p>A data.frame consisting of the input points, output values, and diagnostic measures.
</p>


<h3>See Also</h3>

<p>validation_diagnostics
</p>
<p>Other diagnostic functions: 
<code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a>()</code>,
<code><a href="#topic+classification_diag">classification_diag</a>()</code>,
<code><a href="#topic+comparison_diag">comparison_diag</a>()</code>,
<code><a href="#topic+individual_errors">individual_errors</a>()</code>,
<code><a href="#topic+residual_diag">residual_diag</a>()</code>,
<code><a href="#topic+standard_errors">standard_errors</a>()</code>,
<code><a href="#topic+summary_diag">summary_diag</a>()</code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Use the simple SIR model via SIREmulators
 get_diagnostic(SIREmulators$ems$nS, validation = SIRSample$validation)
 # Classification error fails without the set of targets
 get_diagnostic(SIREmulators$ems$nI, SIREmulators$targets, SIRSample$validation, 'ce')
 # No validation set: k-fold cross-validation will be used.
 get_diagnostic(SIREmulators$ems$nR, which_diag = 'se')

</code></pre>

<hr>
<h2 id='HierarchicalEmulator'>Hierarchical Bayes Linear Emulator</h2><span id='topic+HierarchicalEmulator'></span>

<h3>Description</h3>

<p>Creates a univariate emulator with hierarchical structure.
</p>
<p>This object does not differ extensively from the standard <code><a href="#topic+Emulator">Emulator</a></code> object, so
most of the functionality will not be listed here: the main difference is that
it allows for the variance structure of the emulator to be modified by a higher
order object. The typical usage is to create a variance emulator, whose predictions
inform the behaviour of a mean emulator with regard to a stochastic process.
</p>


<h3>Constructor</h3>

<p><code>HierarchicalEmulator$new(basis_f, beta, u, ranges, ...)</code>
</p>


<h3>Arguments</h3>

<p>For details of shared arguments, see <code><a href="#topic+Emulator">Emulator</a></code>.
</p>
<p><code>s_diag</code> The function that modifies the structure of the Bayes Linear adjustment.
</p>
<p><code>samples</code> A numeric vector that indicates how many replicates each of the training
points has.
</p>
<p><code>em_type</code> Whether the emulator is emulating a mean surface or a variance surface.
</p>


<h3>Constructor Details</h3>

<p>See <code><a href="#topic+Emulator">Emulator</a></code>: the constructor structure is the same save for the
new arguments discussed above.
</p>


<h3>Accessor Methods</h3>

<p><code>get_exp(x, samps = NULL)</code> Similar in form to the normal Emulator method; the
<code>samps</code> argument allows the estimation of summary statistics derived from
multiple realisations.
</p>
<p><code>get_cov(x, xp = NULL, full = FALSE, samps = NULL)</code> Differences here are in
line with those described in <code>get_exp</code>.
</p>


<h3>Object Methods</h3>

<p>Identical to those of <code><a href="#topic+Emulator">Emulator</a></code>: the one internal difference is that
<code>adjust</code> returns a HierarchicalEmulator rather than a standard one.
</p>


<h3>References</h3>

<p>Goldstein &amp; Vernon (2016), in preparation
</p>


<h3>Examples</h3>

<pre><code class='language-R'> h_em &lt;- emulator_from_data(BirthDeath$training, c('Y'),
  list(lambda = c(0, 0.08), mu = c(0.04, 0.13)), emulator_type = "variance")
 names(h_em) # c("expectation', 'variance')
</code></pre>

<hr>
<h2 id='hit_by_wave'>Output Hit Summary</h2><span id='topic+hit_by_wave'></span>

<h3>Description</h3>

<p>Provides a summary of numbers of points that hit n outputs
</p>


<h3>Usage</h3>

<pre><code class='language-R'>hit_by_wave(
  waves,
  targets,
  input_names,
  measure = "mean",
  plt = FALSE,
  as.per = TRUE,
  grid.plot = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="hit_by_wave_+3A_waves">waves</code></td>
<td>
<p>The collection of waves, as a list of data.frames</p>
</td></tr>
<tr><td><code id="hit_by_wave_+3A_targets">targets</code></td>
<td>
<p>The output targets</p>
</td></tr>
<tr><td><code id="hit_by_wave_+3A_input_names">input_names</code></td>
<td>
<p>The names of the input parameters</p>
</td></tr>
<tr><td><code id="hit_by_wave_+3A_measure">measure</code></td>
<td>
<p>If stochastic, the measure to use to compare (see description)</p>
</td></tr>
<tr><td><code id="hit_by_wave_+3A_plt">plt</code></td>
<td>
<p>If TRUE, results are plotted; else a data.frame is returned</p>
</td></tr>
<tr><td><code id="hit_by_wave_+3A_as.per">as.per</code></td>
<td>
<p>Should the data be percentages, or raw numbers?</p>
</td></tr>
<tr><td><code id="hit_by_wave_+3A_grid.plot">grid.plot</code></td>
<td>
<p>If <code>plt = TRUE</code>, determines the type of plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a collection of wave points and the targets used in history matching,
it might be informative to consider the proportion of points whose model
output matches a given number of targets. This function provides by-wave
information about how many parameter sets are matches to 0,1,2,...,n outputs.
</p>
<p>The results of the analysis can be presented as a <code>data.frame</code> object
where each row is a wave and each column a number of outputs; if <code>plt = TRUE</code>
the results are instead presented visually, as a grid coloured by proportion of
total points (if <code>grid.plot = TRUE</code>, the default) or as a series of discrete
density lines, one per wave. The <code>as.per</code> argument determines whether the
output values are raw or if they are calculated percentages of the total number
of parameter sets for a given wave.
</p>
<p>When the data arise from a stochastic model, and therefore parameter sets have
multiple realisations, there are multiple ways to analyze the data (determined
by <code>measure</code>). The options are &quot;mean&quot; to compare the means of realisations
to the outputs; &quot;real&quot; to compare all individual realisations; and &quot;stoch&quot; to
consider an output matched to if the mean lies within 3 standard deviations of
the output, where the standard deviation is calculated over the realisations.
</p>


<h3>Value</h3>

<p>Either a data.frame of results or a ggplot object plot
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> # Default Usage
 hit_by_wave(SIRMultiWaveData, SIREmulators$targets, c('aSI', 'aIR', 'aSR'))
 # Plotting - line plot or raw figures
 hit_by_wave(SIRMultiWaveData, SIREmulators$targets, c('aSI', 'aIR', 'aSR'),
  plt = TRUE, as.per = FALSE, grid.plot = FALSE)
</code></pre>

<hr>
<h2 id='idemc'>IDEMC Point Generation</h2><span id='topic+idemc'></span>

<h3>Description</h3>

<p>Performs Implausibility-driven Evolutionary Monte Carlo
</p>


<h3>Usage</h3>

<pre><code class='language-R'>idemc(
  ems,
  N,
  targets,
  cutoff = 3,
  s = max(500, ceiling(N/5)),
  sn = s,
  p = 0.4,
  thin = 1,
  pm = 0.9,
  w = 0.8,
  M = 10,
  detailed = FALSE,
  verbose = interactive(),
  get_burnt = FALSE,
  burnt = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="idemc_+3A_ems">ems</code></td>
<td>
<p>The emulators to evaluate implausibility on</p>
</td></tr>
<tr><td><code id="idemc_+3A_n">N</code></td>
<td>
<p>The desired number of final points to generate</p>
</td></tr>
<tr><td><code id="idemc_+3A_targets">targets</code></td>
<td>
<p>The target values for the emulated outputs</p>
</td></tr>
<tr><td><code id="idemc_+3A_cutoff">cutoff</code></td>
<td>
<p>The desired implausibility cutoff of the final proposal</p>
</td></tr>
<tr><td><code id="idemc_+3A_s">s</code></td>
<td>
<p>The number of points to generate at intermediate burn-in steps</p>
</td></tr>
<tr><td><code id="idemc_+3A_sn">sn</code></td>
<td>
<p>The number of points to generate at the final burn-in stage</p>
</td></tr>
<tr><td><code id="idemc_+3A_p">p</code></td>
<td>
<p>The proportion of space that should remain between ladder rungs</p>
</td></tr>
<tr><td><code id="idemc_+3A_thin">thin</code></td>
<td>
<p>The thinning factor: a factor T means N*T points are generated to obtain N</p>
</td></tr>
<tr><td><code id="idemc_+3A_pm">pm</code></td>
<td>
<p>The probability that an idemc step will use mutation moves</p>
</td></tr>
<tr><td><code id="idemc_+3A_w">w</code></td>
<td>
<p>The probability of local random walks in the mutation step</p>
</td></tr>
<tr><td><code id="idemc_+3A_m">M</code></td>
<td>
<p>The number of mutations to perform in an IDEMC step</p>
</td></tr>
<tr><td><code id="idemc_+3A_detailed">detailed</code></td>
<td>
<p>If TRUE, points proposed at every rung will be returned</p>
</td></tr>
<tr><td><code id="idemc_+3A_verbose">verbose</code></td>
<td>
<p>Should information about burn-in be displayed during the process?</p>
</td></tr>
<tr><td><code id="idemc_+3A_get_burnt">get_burnt</code></td>
<td>
<p>If TRUE, the procedure stops after burn-in, returning seeding for a full IDEMC proposal</p>
</td></tr>
<tr><td><code id="idemc_+3A_burnt">burnt</code></td>
<td>
<p>If provided, this is assumed to be the result of a burn-in (or a priori analysis)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This method for generating points is focused on finding non-implausible
regions that are either extremely small relative to the initial parameter
domain, or have interesting structure (particularly disconnected structure)
that would potentially be overlooked by more standard point generation methods.
The method is robust but computationally intensive, compared to normal methods,
and should not be used as a default - see <code><a href="#topic+generate_new_design">generate_new_design</a></code> for
less computationally expensive methods.
</p>
<p>The IDEMC method operates on an 'implausibility ladder', in the vein of common
annealing methods. Each rung of the ladder is characterised by the implausibility
threshold, and determinations are made about the structure of the points in each
rung using clustering. One step of the evolutionary algorithm can consist of the
following steps:
</p>
<p>Mutation. A point is modified using a random-walk proposal, which can be a global
move or a within-cluster move. Within-cluster moves are chosen with probability
<code>w</code>. The move is retained if the new point satisfies the implausibility
constraints of the rung.
</p>
<p>Crossover. Points are re-organised in descending order of how active each variable
is for the emulated outputs, and two different rungs are selected randomly. The
points are 'mixed' using one-point real crossover at a random crossover point,
producing two new points. The move is retained if both new points satisfy the
relevant implausibility constraints of their rung.
</p>
<p>Exchange. Two adjacent rungs are chosen and their points are swapped. The move
is retained if the higher-implausibility rung is appropriate for being in the
lower implausibility rung.
</p>
<p>At a given step, one of mutation or crossover is performed, with probability
of mutation being chosen determined by <code>pm</code>. If mutation is chosen, then
<code>M</code> mutation moves are performed; else <code>(n+1)/2</code> crossover moves are
performed on the <code>n</code> rungs. Exchange is always perfomed and <code>n+1</code> such
moves are performed.
</p>
<p>The choice of 'implausibility ladder' and clusters can be determined a priori,
or else this function performs a burn-in phase to determine them. Points are
generated using the idemc steps at the current rungs, and the next ladder rung
implausibility is chosen by requiring that a proportion <code>p</code> of points from
the previous rung are accepted in the new one. At each stage, <code>s</code> idemc
steps are performed. Once the final rung has implausibility no larger than the
desired <code>cutoff</code>, a final set of <code>sn</code> idemc steps are performed across
all rungs to determine final clusters.
</p>


<h3>Value</h3>

<p>Either a list of data.frames, one per rung, or a single data.frame of points.
</p>


<h3>References</h3>

<p>Vernon &amp; Williamson (2013) &lt;arXiv:1309.3520&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+generate_new_design">generate_new_design</a></code> for more standard point generation methods
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
  idemc_res &lt;- idemc(SIREmulators$ems, 200, SIREmulators$targets, s = 100, p = 0.3)
 

</code></pre>

<hr>
<h2 id='individual_errors'>Predictive Error Plots</h2><span id='topic+individual_errors'></span>

<h3>Description</h3>

<p>Plots the predictive error with respect to a variety of quantities.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>individual_errors(
  em,
  validation,
  errtype = "normal",
  xtype = "index",
  plottype = "normal"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="individual_errors_+3A_em">em</code></td>
<td>
<p>The emulator to perform diagnostics on</p>
</td></tr>
<tr><td><code id="individual_errors_+3A_validation">validation</code></td>
<td>
<p>The validation set of points with output(s)</p>
</td></tr>
<tr><td><code id="individual_errors_+3A_errtype">errtype</code></td>
<td>
<p>The type of individual error to be plotted.</p>
</td></tr>
<tr><td><code id="individual_errors_+3A_xtype">xtype</code></td>
<td>
<p>The value to plot against</p>
</td></tr>
<tr><td><code id="individual_errors_+3A_plottype">plottype</code></td>
<td>
<p>Whether to plot a standard or Q-Q plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The choice of errors to plot is controlled by <code>errtype</code>, and can be one
of four things: normal, corresponding to the regular standardised errors; eigen,
corresponding to the errors after reordering given by the eigendecomposition
of the emulator covariance matrix; chol, similarly deriving errors after Cholesky
decomposition; and cholpivot, deriving the errors after pivoted Cholesky decomposition.
</p>
<p>What the errors are plotted with respect to is controlled by <code>xtype</code>. The options
are index, which plots them in their order in the validation set; em, which plots errors
with respect to the emulator prediction at that point; and any named parameter of the
model, which plots with respect to the values of that parameter.
</p>
<p>Finally, the plot type is controlled by <code>plottype</code>: this can be one of normal,
which plots the errors; or qq, which produces a Q-Q plot of the errors.
</p>
<p>The default output is to plot the standardised errors (with no decomposition)
against the ordering in the validation set; i.e. <code>errtype = "normal"</code>,
<code>xtype = "index"</code>, <code>plottype = "normal"</code>.
</p>
<p>Some combinations are not permitted, as the output would not be meaningful. Errors
arising from an eigendecomposition cannot be plotted against either emulator prediction
or a particular parameter (due to the transformation induced by the eigendecomposition);
Q-Q plots are not plotted for a non-decomposed set of errors, as the correlation
between errors makes it much harder to interpret.
</p>


<h3>Value</h3>

<p>The relevant plot.
</p>


<h3>References</h3>

<p>Bastos &amp; O'Hagan (2009) &lt;doi:10.1198/TECH.2009.08019&gt;
</p>


<h3>See Also</h3>

<p>Other diagnostic functions: 
<code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a>()</code>,
<code><a href="#topic+classification_diag">classification_diag</a>()</code>,
<code><a href="#topic+comparison_diag">comparison_diag</a>()</code>,
<code><a href="#topic+get_diagnostic">get_diagnostic</a>()</code>,
<code><a href="#topic+residual_diag">residual_diag</a>()</code>,
<code><a href="#topic+standard_errors">standard_errors</a>()</code>,
<code><a href="#topic+summary_diag">summary_diag</a>()</code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>i1 &lt;- individual_errors(SIREmulators$ems$nS, SIRSample$validation)
i2 &lt;- individual_errors(SIREmulators$ems$nS, SIRSample$validation, "chol", "em")
i3 &lt;- individual_errors(SIREmulators$ems$nS, SIRSample$validation, "eigen", plottype = "qq")
i4 &lt;- individual_errors(SIREmulators$ems$nS, SIRSample$validation, "cholpivot", xtype = "aSI")

</code></pre>

<hr>
<h2 id='matern'>Matern correlation function</h2><span id='topic+matern'></span>

<h3>Description</h3>

<p>For points <code>x</code>, <code>xp</code>, and a pair of hyperparameters <code>nu</code> and <code>theta</code>, gives
the Matern correlation between the two points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>matern(x, xp, hp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="matern_+3A_x">x</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="matern_+3A_xp">xp</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="matern_+3A_hp">hp</code></td>
<td>
<p>The hyperparameters nu (smoothness) and theta (correlation length), as a named list</p>
</td></tr>
</table>


<h3>Details</h3>

<p>At present, only half-integer arguments for nu are supported.
</p>


<h3>Value</h3>

<p>The Matern correlation between x and xp.
</p>


<h3>References</h3>

<p>Rasmussen &amp; Williams (2005) &lt;ISBN: 9780262182539&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>matern(data.frame(a=1), data.frame(a=2), list(nu = 1.5, theta = 0.1))
#&gt; 5.504735e-07
matern(data.frame(a=1,b=2,c=-1),data.frame(a=1.5,b=2.9,c=-0.7), list(nu = 1.5, theta = 0.2))
#&gt; 0.0009527116
</code></pre>

<hr>
<h2 id='nth_implausible'>nth Maximum Implausibility</h2><span id='topic+nth_implausible'></span>

<h3>Description</h3>

<p>Computes the nth-maximum implausibility of points relative to a set of emulators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nth_implausible(
  ems,
  x,
  z,
  n = NULL,
  max_imp = Inf,
  cutoff = NULL,
  sequential = FALSE,
  get_raw = FALSE,
  ordered = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nth_implausible_+3A_ems">ems</code></td>
<td>
<p>A set of <code><a href="#topic+Emulator">Emulator</a></code> objects or nested sets thereof (see description)</p>
</td></tr>
<tr><td><code id="nth_implausible_+3A_x">x</code></td>
<td>
<p>An input point, or <code>data.frame</code> of points.</p>
</td></tr>
<tr><td><code id="nth_implausible_+3A_z">z</code></td>
<td>
<p>The target values, in the usual form or nested thereof.</p>
</td></tr>
<tr><td><code id="nth_implausible_+3A_n">n</code></td>
<td>
<p>The implausibility level to return.</p>
</td></tr>
<tr><td><code id="nth_implausible_+3A_max_imp">max_imp</code></td>
<td>
<p>A maximum implausibility to return (often used with plotting)</p>
</td></tr>
<tr><td><code id="nth_implausible_+3A_cutoff">cutoff</code></td>
<td>
<p>A numeric value, or vector of such, representing allowed implausibility</p>
</td></tr>
<tr><td><code id="nth_implausible_+3A_sequential">sequential</code></td>
<td>
<p>Should the emulators be evaluated sequentially?</p>
</td></tr>
<tr><td><code id="nth_implausible_+3A_get_raw">get_raw</code></td>
<td>
<p>Boolean - determines whether nth-implausibility should be applied.</p>
</td></tr>
<tr><td><code id="nth_implausible_+3A_ordered">ordered</code></td>
<td>
<p>If FALSE, emulators are ordered according to restrictiveness.</p>
</td></tr>
<tr><td><code id="nth_implausible_+3A_...">...</code></td>
<td>
<p>Any additional arguments to pass to chained functions (e.g. <code>ordering</code>
to pass to <code>collect_emulators</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a collection of emulators, we often combine the implausibility
measures for a given set of observations. The maximum implausibility of a point,
given a set of univariate emulators and an associated collection of target values,
is the largest implausibility of the collected set of implausibilities. The 2nd
maximum is the maximum of the set without the largest value, and so on. By default,
maximum implausibility will be considered when there are fewer than 10 targets to
match to; otherwise second-maximum implausibility is considered.
</p>
<p>If <code>sequential = TRUE</code> and a specific <code>cutoff</code> has been provided, then the
emulators' implausibility will be evaluated one emulator at a time. If a point
is judged non-implausible by more than <code>n</code> emulators, <code>FALSE</code> is
returned without evaluating any more. Due to R efficiencies, this is more efficient
than the 'evaluate all' method once more than around 10 emulators are considered.
</p>
<p>This function also deals with variance emulators and bimodal emulators, working in a nested
fashion. If targets are provided for both the expectation and variance as a list, then
given <code>ems = list(expectation = ..., variance = ...)</code> the implausibility is calculated
with respect to both sets of emulators, maximising as relevant. If targets are provided in
the 'normal' fashion, then only the mean emulators are used. The bimodal case is similar;
given a set of emulators <code>list(mode1 = list(expectation = ..., variance = ...), ...)</code>
then each mode has implausibility evaluated separately. The results from the two modes are
combined via piecewise minimisation.
</p>


<h3>Value</h3>

<p>Either the nth maximum implausibilities, or booleans (if cutoff is given).
</p>


<h3>Examples</h3>

<pre><code class='language-R'># A single point
nth_implausible(SIREmulators$ems, data.frame(aSI = 0.4, aIR = 0.25, aSR = 0.025),
 SIREmulators$targets)
# A data.frame of points
grid &lt;- expand.grid(
 aSI = seq(0.1, 0.8, length.out = 4),
 aIR = seq(0, 0.5, length.out = 4),
 aSR = seq(0, 0.05, length.out = 4)
)
# Vector of numerics
i1 &lt;- nth_implausible(SIREmulators$ems, grid, SIREmulators$targets)
# Vector of booleans (same as i1 &lt;= 3)
i2 &lt;- nth_implausible(SIREmulators$ems, grid, SIREmulators$targets, cutoff = 3)
# Throws a warning as n &gt; no. of targets
i3 &lt;- nth_implausible(SIREmulators$ems, grid, SIREmulators$targets, n = 4)
# Vector of booleans (note different output to i2)
i4 &lt;- nth_implausible(SIREmulators$ems, grid, SIREmulators$targets,
 cutoff = c(4, 2.5, 2))

# Variance Emulators
v_ems &lt;- emulator_from_data(BirthDeath$training, c('Y'),
 list(lambda = c(0, 0.08), mu = c(0.04, 0.13)), emulator_type = "variance")
v_targs = list(expectation = list(Y = c(90, 110)), variance = list(Y = c(55, 95)))
nth_implausible(v_ems, unique(BirthDeath$validation[,1:2]), v_targs)
## If there is a mismatch between emulators and targets, expectation is assumed
nth_implausible(v_ems$expectation, unique(BirthDeath$validation[,1:2]), v_targs)
nth_implausible(v_ems, unique(BirthDeath$validation[,1:2]), v_targs$expectation)

</code></pre>

<hr>
<h2 id='orn_uhl'>Ornstein-Uhlenbeck correlation function</h2><span id='topic+orn_uhl'></span>

<h3>Description</h3>

<p>For points <code>x</code>, <code>xp</code>, and a hyperparameter <code>theta</code>, gives
the Ornstein-Uhlenbeck correlation between the two points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>orn_uhl(x, xp, hp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="orn_uhl_+3A_x">x</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="orn_uhl_+3A_xp">xp</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="orn_uhl_+3A_hp">hp</code></td>
<td>
<p>The hyperparameter theta (correlation length) in a named list</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This correlation function can be seen as a specific case of the Matern correlation function
when nu = 1/2.
</p>


<h3>Value</h3>

<p>The Ornstein-Uhlenbeck correlation between x and xp.
</p>


<h3>References</h3>

<p>Rasmussen &amp; Williams (2005) &lt;ISBN: 9780262182539&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>orn_uhl(data.frame(a=1), data.frame(a=2), list(theta = 0.1))
#&gt; 4.539993e-05
orn_uhl(data.frame(a=1,b=2,c=-1),data.frame(a=1.5,b=2.9,c=-0.7), list(theta = 0.2))
#&gt; 0.00469197
orn_uhl(data.frame(a=1,b=1,c=1), data.frame(a=1.2,b=0.9,c=0.6), list(theta = 0.2)) ==
 matern(data.frame(a=1,b=1,c=1), data.frame(a=1.2,b=0.9,c=0.6), list(theta = 0.2, nu = 0.5)) #&gt; TRUE
</code></pre>

<hr>
<h2 id='output_plot'>Emulator Expectation Against Target Outputs</h2><span id='topic+output_plot'></span>

<h3>Description</h3>

<p>Plots emulator expectation across the parameter space, with comparison to the corresponding
target values (with appropriate uncertainty).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>output_plot(ems, targets, points = NULL, npoints = 1000)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="output_plot_+3A_ems">ems</code></td>
<td>
<p>The <code><a href="#topic+Emulator">Emulator</a></code> objects.</p>
</td></tr>
<tr><td><code id="output_plot_+3A_targets">targets</code></td>
<td>
<p>A named list of observations, given in the usual form.</p>
</td></tr>
<tr><td><code id="output_plot_+3A_points">points</code></td>
<td>
<p>A list of points at which the emulators should be evaluated.</p>
</td></tr>
<tr><td><code id="output_plot_+3A_npoints">npoints</code></td>
<td>
<p>If no points are provided, the number of input points to evaluate at.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If a <code>points</code> data.frame is not provided, then points are sampled uniformly from the
input region. Otherwise, the provided points are used: for example, if a representative
sample of the current NROY space is available.
</p>


<h3>Value</h3>

<p>A ggplot object
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> output_plot(SIREmulators$ems, SIREmulators$targets)
 output_plot(SIREmulators$ems, SIREmulators$targets, points = SIRSample$training)
</code></pre>

<hr>
<h2 id='plot_actives'>Active variable plotting</h2><span id='topic+plot_actives'></span>

<h3>Description</h3>

<p>For a set of emulators, demonstrate which variables are active.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_actives(ems, output_names = NULL, input_names = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_actives_+3A_ems">ems</code></td>
<td>
<p>The list of emulators to consider</p>
</td></tr>
<tr><td><code id="plot_actives_+3A_output_names">output_names</code></td>
<td>
<p>The names of the outputs to include in the plot, if not all</p>
</td></tr>
<tr><td><code id="plot_actives_+3A_input_names">input_names</code></td>
<td>
<p>The names of the inputs to include in the plot, if not all</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Each emulator has a list of &lsquo;active&rsquo; variables; those which contribute in an appreciable way
to its regression surface. It can be instructive to examine the differences in active variables
for a give collection of emulators. The plot here produces an nxp grid for n emulators in p
inputs; a square is blacked out if that variable does not contribute to that output.
</p>
<p>Both the outputs and inputs can be restricted to collections of interest, if desired, with the
optional <code>output_names</code> and <code>input_names</code> parameters.
</p>


<h3>Value</h3>

<p>A ggplot object corresponding to the plot
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> plot_actives(SIREmulators$ems)
 # Remove the nR output and aIR input from the plot
 plot_actives(SIREmulators$ems, c('nS', 'nI'), c('aSI', 'aSR'))
 # Note that we can equally restrict the emulator list...
 plot_actives(SIREmulators$ems[c('nS', 'nI')], input_names = c('aSI', 'aSR'))
</code></pre>

<hr>
<h2 id='plot_lattice'>Plot Lattice of Emulator Implausibilities</h2><span id='topic+plot_lattice'></span>

<h3>Description</h3>

<p>Plots a set of projections of the full-dimensional input space.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_lattice(
  ems,
  targets,
  ppd = 20,
  cb = FALSE,
  cutoff = 3,
  maxpoints = 50000,
  imp_breaks = NULL,
  contour = TRUE,
  ranges = NULL,
  raster_imp = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_lattice_+3A_ems">ems</code></td>
<td>
<p>The <code><a href="#topic+Emulator">Emulator</a></code> objects in question.</p>
</td></tr>
<tr><td><code id="plot_lattice_+3A_targets">targets</code></td>
<td>
<p>The corresponding target values.</p>
</td></tr>
<tr><td><code id="plot_lattice_+3A_ppd">ppd</code></td>
<td>
<p>The number of points to sample per dimension.</p>
</td></tr>
<tr><td><code id="plot_lattice_+3A_cb">cb</code></td>
<td>
<p>Whether or not a colourblind-friendly plot should be produced.</p>
</td></tr>
<tr><td><code id="plot_lattice_+3A_cutoff">cutoff</code></td>
<td>
<p>The cutoff value for non-implausible points.</p>
</td></tr>
<tr><td><code id="plot_lattice_+3A_maxpoints">maxpoints</code></td>
<td>
<p>The limit on the number of points to be evaluated.</p>
</td></tr>
<tr><td><code id="plot_lattice_+3A_imp_breaks">imp_breaks</code></td>
<td>
<p>If plotting nth maximum implausibility, defines the levels at
which to draw contours.</p>
</td></tr>
<tr><td><code id="plot_lattice_+3A_contour">contour</code></td>
<td>
<p>Logical determining whether to plot implausibility contours or not.</p>
</td></tr>
<tr><td><code id="plot_lattice_+3A_ranges">ranges</code></td>
<td>
<p>Parameter ranges. If not supplied, defaults to emulator ranges.</p>
</td></tr>
<tr><td><code id="plot_lattice_+3A_raster_imp">raster_imp</code></td>
<td>
<p>Should the implausibility plots be rasterised?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plots are:
</p>
<p>One dimensional optical depth plots (diagonal);
</p>
<p>Two dimensional optical depth plots (lower triangle);
</p>
<p>Two dimensional minimum implausibility plots (upper triangle).
</p>
<p>The optical depth is calculated as follows. A set of points is constructed across the
full d-dimensional parameter space, and implausibility is calculated at each point.
The points are collected into groups based on their placement in a projection to a
one- or two-dimensional slice of the parameter space. For each group, the proportion
of non-implausible points is calculated, and this value in [0,1] is plotted. The
minimum implausibility plots are similar, but with minimum implausibility calculated
rather than proportion of non-implausible points.
</p>
<p>The <code>maxpoints</code> argument is used as a cutoff for if a regular ppd grid would
result in a very large number of points. If this is the case, then <code>maxpoints</code> points
are sampled uniformly from the region instead of regularly spacing them.
</p>


<h3>Value</h3>

<p>A ggplot object
</p>


<h3>References</h3>

<p>Bower, Goldstein &amp; Vernon (2010) &lt;doi:10.1214/10-BA524&gt;
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 plot_lattice(SIREmulators$ems, SIREmulators$targets, ppd = 10)
 plot_lattice(SIREmulators$ems$nS, SIREmulators$targets)

</code></pre>

<hr>
<h2 id='plot_wrap'>Plot proposed points</h2><span id='topic+plot_wrap'></span>

<h3>Description</h3>

<p>A wrapper around R's base plot to show proposed points
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_wrap(points, ranges = NULL, p_size = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot_wrap_+3A_points">points</code></td>
<td>
<p>The points to plot</p>
</td></tr>
<tr><td><code id="plot_wrap_+3A_ranges">ranges</code></td>
<td>
<p>The parameter ranges</p>
</td></tr>
<tr><td><code id="plot_wrap_+3A_p_size">p_size</code></td>
<td>
<p>The size of the plotted points (passed to <code>cex</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a set of points proposed from emulators at a given wave, it's often useful to look at
how they are spread and where in parameter space they tend to lie relative to the original
ranges of the parameters. This function provides pairs plots of the parameters, with the
bounds of the plots calculated with respect to the parameter ranges provided.
</p>


<h3>Value</h3>

<p>The corresponding pairs plot
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> plot_wrap(SIRSample$training[,1:3], SIREmulators$ems[[1]]$ranges)

</code></pre>

<hr>
<h2 id='problem_data'>Data for an interesting emulation problem</h2><span id='topic+problem_data'></span>

<h3>Description</h3>

<p>An RData object consisting of four objects: a data.frame <code>data</code> of 208 points,
a set <code>targets</code> of 19 targets for outputs, a set <code>ranges</code> of 21 ranges for inputs,
and a data.frame <code>extra</code> of 26 additional points. This dataset is used to demonstrate
some of the subtleties of emulation in the vignettes, where data transformations can be
useful and careful attention should be paid to emulation at early waves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>problem_data
</code></pre>


<h3>Format</h3>

<p>A list of objects:
</p>

<dl>
<dt>data</dt><dd><p>The training data of 'space-filling' runs</p>
</dd>
<dt>targets</dt><dd><p>The output targets to match to</p>
</dd>
<dt>ranges</dt><dd><p>The input ranges over which the system is valid</p>
</dd>
<dt>extra</dt><dd><p>A set of 'extra' points, generated around a known point of best fit.</p>
</dd>
</dl>


<hr>
<h2 id='Proto_emulator'>Prototype Class for Emulator-like Objects</h2><span id='topic+Proto_emulator'></span>

<h3>Description</h3>

<p>Converts a prediction object into a form useable in hmer.
</p>
<p>The history matching process can be used for objects that are not
created by the <code>hmer</code> package: most notably Gaussian Process
(GP) emulators but even for simple linear models. This R6 class
converts such an object into a form that can be called directly and
reliably by the methods of the package, including for visualisation
and diagnostics.
</p>


<h3>Constructor</h3>

<p><code>Proto_emulator$new(ranges, output_name,
    predict_func, variance_func, ...)</code>
</p>


<h3>Arguments</h3>

<p>Required:
</p>
<p><code>ranges</code> A list of ranges for the inputs to the model.
</p>
<p><code>output_name</code> The name of the output modelled.
</p>
<p><code>predict_func</code> The function that provides the predictions at
a new point or points. The first argument of this function should be
<code>x</code>, where <code>x</code> is a <code>data.frame</code> of points. Additional
arguments can be specified as long as they match additional objects
passed via <code>...</code> (see below for details).
</p>
<p><code>variance_func</code> The function that encodes the prediction error
due to the model of choice. This, too, takes an argument <code>x</code> as
above as its first argument. Additional arguments can be specified as
long as they match additional objects passed via <code>...</code>
(see below for details).
</p>
<p>Optional:
</p>
<p><code>implausibility_func</code> A function that takes points <code>x</code> and a
target <code>z</code> (and potentially a cutoff value <code>cutoff</code> and additional
arguments) and returns a measure of closeness of the predicted value to the target (or
a boolean representing whether the prediction is within the specified
cutoff). Any custom implausibility should satisfy the definition: that is,
a point that is unlikely to match to the observation should have higher
implausibility than a point likely to match to the observation. If, for
example, a likelihood to be maximised is used as a surrogate for an
implausibility function, then one should transform it accordingly.
</p>
<p>If this argument is not provided, the standard implausibility is used:
namely, the absolute value of the difference between prediction and
observation, divided by the square root of the sum in quadrature of
the errors.
</p>
<p>Additional arguments can be specified as long as they match additional
objects passed via <code>...</code> (see below for details).
</p>
<p><code>print_func</code> If the prediction object has a suitable print function
that one wishes to transfer to the R6 class (e.g. <code>summary.lm</code>), it
is specified here.
</p>
<p><code>...</code> Additional objects to pass to <code>predict_func</code>, <code>variance_func</code>,
<code>implausibility_func</code> or <code>print_func</code>. The names of these objects
must match the additional argument names in the corresponding functions.
</p>


<h3>Constructor Details</h3>

<p>The constructor must take, as a minimum, the first four arguments (input
ranges, output name, and the prediction and variance functions). Default
behaviour exists if the implausibility function and print function are not
specified. The output of the constructor is an R6 object with the classes
&quot;Emulator&quot; and &quot;EmProto&quot;.
</p>


<h3>Accessor Methods</h3>

<p>Note that these have the same external structure as those in <code><a href="#topic+Emulator">Emulator</a></code>.
</p>
<p><code>get_exp(x)</code> Returns the prediction.
</p>
<p><code>get_cov(x)</code> Returns the prediction error.
</p>
<p><code>implausibility(x, z, cutoff = NULL)</code> Returns the 'implausibility'.
</p>
<p><code>print()</code> Prints relevant details of the object.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>    # Use linear regression with an "error" on the SIR dataset.
    ranges &lt;- list(aSI = c(0.1, 0.8), aIR = c(0, 0.5), aSR = c(0, 0.05))
    targets &lt;- SIREmulators$targets
    lms &lt;- purrr::map(names(targets),
     ~step(lm(data = SIRSample$training[,c(names(ranges), .)],
      formula = as.formula(paste0(., "~(",
       paste0(names(ranges), collapse = "+"),
       ")^2"
      ))
    ), trace = 0))
    # Set up the proto emulators
    proto_ems &lt;- purrr::map(seq_along(lms), function(l) {
      Proto_emulator$new(
         ranges,
         names(targets)[l],
         function(x) predict(lms[[l]], x),
         function(x) predict(lms[[l]], x, se.fit = TRUE)$se.fit^2 +
            predict(lms[[l]], x, se.fit = TRUE)$residual.scale^2,
         print_func = function() print(summary(lms[[l]]))
      )
    }) |&gt; setNames(names(targets))
    # Test with some hmer functions
    nth_implausible(proto_ems, SIRSample$validation, targets)
    emulator_plot(proto_ems)
    emulator_plot(proto_ems, 'imp', targets = targets)
    validation_diagnostics(proto_ems, targets, SIRSample$validation)
    new_points &lt;- generate_new_design(proto_ems, 100, targets)

</code></pre>

<hr>
<h2 id='rat_quad'>Rational Quadratic correlation function</h2><span id='topic+rat_quad'></span>

<h3>Description</h3>

<p>For points <code>x</code>, <code>xp</code>, and a pair of hyperparameters <code>alpha</code> and <code>theta</code>,
gives the rational quadratic correlation between the two points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rat_quad(x, xp, hp)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rat_quad_+3A_x">x</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="rat_quad_+3A_xp">xp</code></td>
<td>
<p>A data.frame of rows corresponding to position vectors</p>
</td></tr>
<tr><td><code id="rat_quad_+3A_hp">hp</code></td>
<td>
<p>The hyperparameters alpha (exponent and scale) and theta (correlation length)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This correlation function, for d = |x-x'|, has the form
<code class="reqn">(1+d^2/(2\alpha\theta^2))^{-\alpha}</code>, and can be seen as a superposition of exponential-squared
correlation functions.
</p>


<h3>Value</h3>

<p>The rational quadratic correlation between x and xp.
</p>


<h3>References</h3>

<p>Rasmussen &amp; Williams (2005) &lt;ISBN: 9780262182539&gt;
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rat_quad(data.frame(a=1), data.frame(a=2), list(alpha = 1.5, theta = 0.1))
#&gt; 0.004970797
rat_quad(data.frame(a=1,b=2,c=-1),data.frame(a=1.5,b=2.9,c=-0.7), list(alpha = 1.5, theta = 0.2))
#&gt; 0.02904466
</code></pre>

<hr>
<h2 id='residual_diag'>Emulator Regression Residuals</h2><span id='topic+residual_diag'></span>

<h3>Description</h3>

<p>Plots the emulator residuals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>residual_diag(emulator, histogram = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="residual_diag_+3A_emulator">emulator</code></td>
<td>
<p>The emulator to consider.</p>
</td></tr>
<tr><td><code id="residual_diag_+3A_histogram">histogram</code></td>
<td>
<p>Should a histogram or a scatter plot be shown? Default: FALSE</p>
</td></tr>
<tr><td><code id="residual_diag_+3A_...">...</code></td>
<td>
<p>Any additional arguments (used internally)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>An emulator is composed of two parts: a global regression surface, and a local
correlation structure. It can sometimes be informative to examine the residuals
of the regression surface on the training set, to determine the extent to which
the regression surface is being &lsquo;corrected for&rsquo; by the correlation structure.
</p>


<h3>Value</h3>

<p>A set of residuals, standardised by the regression surface residual standard error.
</p>


<h3>See Also</h3>

<p>Other diagnostic functions: 
<code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a>()</code>,
<code><a href="#topic+classification_diag">classification_diag</a>()</code>,
<code><a href="#topic+comparison_diag">comparison_diag</a>()</code>,
<code><a href="#topic+get_diagnostic">get_diagnostic</a>()</code>,
<code><a href="#topic+individual_errors">individual_errors</a>()</code>,
<code><a href="#topic+standard_errors">standard_errors</a>()</code>,
<code><a href="#topic+summary_diag">summary_diag</a>()</code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>residual_diag(SIREmulators$ems$nS)
residual_diag(SIREmulators$ems$nI, TRUE)

</code></pre>

<hr>
<h2 id='simulator_plot'>Plot simulator outputs for multiple waves</h2><span id='topic+simulator_plot'></span>

<h3>Description</h3>

<p>Plots the simulator results for points at successive waves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>simulator_plot(
  wave_points,
  z,
  zero_in = TRUE,
  palette = NULL,
  wave_numbers = seq(ifelse(zero_in, 0, 1), length(wave_points) - ifelse(zero_in, 1, 0)),
  normalize = FALSE,
  logscale = FALSE,
  byhit = FALSE,
  barcol = "#444444",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="simulator_plot_+3A_wave_points">wave_points</code></td>
<td>
<p>The set of wave points, as a list of data.frames</p>
</td></tr>
<tr><td><code id="simulator_plot_+3A_z">z</code></td>
<td>
<p>The set of target values for each output</p>
</td></tr>
<tr><td><code id="simulator_plot_+3A_zero_in">zero_in</code></td>
<td>
<p>Is wave zero included? Default: TRUE</p>
</td></tr>
<tr><td><code id="simulator_plot_+3A_palette">palette</code></td>
<td>
<p>If a larger palette is required, it should be supplied here.</p>
</td></tr>
<tr><td><code id="simulator_plot_+3A_wave_numbers">wave_numbers</code></td>
<td>
<p>Which waves to plot. If not supplied, all waves are plotted.</p>
</td></tr>
<tr><td><code id="simulator_plot_+3A_normalize">normalize</code></td>
<td>
<p>If true, plotting is done with rescaled target bounds.</p>
</td></tr>
<tr><td><code id="simulator_plot_+3A_logscale">logscale</code></td>
<td>
<p>If true, targets are log-scaled before plotting.</p>
</td></tr>
<tr><td><code id="simulator_plot_+3A_byhit">byhit</code></td>
<td>
<p>Should runs be grouped by number of targets hit, rather than wave?</p>
</td></tr>
<tr><td><code id="simulator_plot_+3A_barcol">barcol</code></td>
<td>
<p>The colour of the target error bars/bounds</p>
</td></tr>
<tr><td><code id="simulator_plot_+3A_...">...</code></td>
<td>
<p>Optional parameters (not to be used directly)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The values plotted are the outputs from the simulator; the points passed to it are the
points suggested by that wave of emulators. By default, wave 0 is included. A colour
scheme is chosen outright for all invocations of this function: it is a 10-colour
palette. If more waves are required, then an alternative palette should be selected.
</p>
<p>The output can be plotted in a number of ways: raw; with outputs transformed to log scale;
or with targets normalised so that target bounds are all [-1, 1]. These two options may
be helpful in visualising behaviour when outputs have vastly different scales, but one
still wishes to see them all in the same plot: these options can be toggled by setting
<code>logscale = TRUE</code> or <code>normalize = TRUE</code> respectively. The data can be grouped in
two ways, either colouring by wave of emulation (default) or by the number of targets hit;
the latter option is enabled by setting <code>byhit = TRUE</code>.
</p>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> simulator_plot(SIRMultiWaveData, SIREmulators$targets)
 simulator_plot(SIRMultiWaveData[2:4], SIREmulators$targets,
  zero_in = FALSE, wave_numbers = c(1,3))
 simulator_plot(SIRMultiWaveData, SIREmulators$targets, byhit = TRUE)

</code></pre>

<hr>
<h2 id='SIR_stochastic'>Stochastic SIR Data</h2><span id='topic+SIR_stochastic'></span>

<h3>Description</h3>

<p>An RData object consisting of two data.frames (in a similar fashion to <code>BirthDeath</code>).
The first consists of 30 points in the parameter space (aSI, aIR, aSR), each of which has
been inputted into the Gillespie algorithm for the stochastic version of the model used
in <code>GillespieSIR</code> (but with changed starting conditions) 100 times. The second has
similar form but for 20 unique points, each with 100 repetitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIR_stochastic
</code></pre>


<h3>Format</h3>

<p>A list of two data.frames <code>training</code> and <code>validation</code>: each has the
following columns:
</p>

<dl>
<dt>aSI</dt><dd><p>Infection rate</p>
</dd>
<dt>aIR</dt><dd><p>Recovery rate</p>
</dd>
<dt>aSR</dt><dd><p>Waning immunity rate</p>
</dd>
<dt>I10 (25, 50)</dt><dd><p>The number of infected people at t = 10 (25, 50)</p>
</dd>
<dt>R10 (25, 50)</dt><dd><p>The number of recovered people at t = 10 (25, 50)</p>
</dd>
</dl>



<h3>Details</h3>

<p>The outputs observed are the numbers of infected (I) and recovered (R) people at time points
t = 10, 25, 50. All outputs display some level of bimodality. The initial conditions to
generate the runs had S(0)=995, I(0)=5, R(0)=0.
</p>

<hr>
<h2 id='SIREmulators'>Sample Emulators</h2><span id='topic+SIREmulators'></span>

<h3>Description</h3>

<p>An RData object containing three trained emulators, and the associated
targets, for the SIR example. The emulators have been trained
on the <code><a href="#topic+SIRSample">SIRSample</a></code> training dataset using methods documented in
this package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIREmulators
</code></pre>


<h3>Format</h3>

<p>A list containing two objects:
</p>

<dl>
<dt>ems</dt><dd><p>The trained <code><a href="#topic+Emulator">Emulator</a></code> objects.</p>
</dd>
<dt>targets</dt><dd><p>The targets to match to, as a named list.</p>
</dd>
</dl>


<hr>
<h2 id='SIRImplausibility'>Sample Implausibility Data</h2><span id='topic+SIRImplausibility'></span>

<h3>Description</h3>

<p>A dataset containing 1000 points from the region bounded by
[0.1, 0.8], [0, 0.5], [0, 0.05] for aSI, aIR and aSR respectively.
Implausibility has been calculated (for emulators trained on the
<code><a href="#topic+SIRSample">SIRSample</a></code> training dataset) for each of the outputs
nS, nI, nR, and the maximum implausibility is included.
The target values used in calculating implausibility were:
</p>

<dl>
<dt>nS</dt><dd><p>between 324 and 358</p>
</dd>
<dt>nI</dt><dd><p>mean 143 (sigma 7.15)</p>
</dd>
<dt>nR</dt><dd><p>between 490 and 542</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>SIRImplausibility
</code></pre>


<h3>Format</h3>

<p>A data frame with 1000 rows and 7 variables:
</p>

<dl>
<dt>aSI</dt><dd><p>Infection: transition rate from S to I</p>
</dd>
<dt>aIR</dt><dd><p>Recovery: transition rate from I to R</p>
</dd>
<dt>aSR</dt><dd><p>Immunisation: transition rate from S to R</p>
</dd>
<dt>nS</dt><dd><p>Implausibility for nS</p>
</dd>
<dt>nI</dt><dd><p>Implausibility for nI</p>
</dd>
<dt>nR</dt><dd><p>Implausibility for nR</p>
</dd>
<dt>I</dt><dd><p>Maximum implausibility</p>
</dd>
</dl>


<hr>
<h2 id='SIRMultiWaveData'>Sample Multi-wave Results</h2><span id='topic+SIRMultiWaveData'></span>

<h3>Description</h3>

<p>An rda object containing four data.frames: an initial set of points
also provided in <code><a href="#topic+SIRSample">SIRSample</a></code>, and
the 90 points generated at each of three subsequent waves. The trained
emulators are provided in <code><a href="#topic+SIRMultiWaveEmulators">SIRMultiWaveEmulators</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIRMultiWaveData
</code></pre>


<h3>Format</h3>

<p>A list of data.frame objects:
</p>

<dl>
<dt>Wave 0</dt><dd><p>The initial points used in other examples</p>
</dd>
<dt>Wave 1</dt><dd><p>Points generated from the wave 1 emulators</p>
</dd>
<dt>Wave 2</dt><dd><p>Points generated from the wave 2 emulators</p>
</dd>
<dt>Wave 3</dt><dd><p>Points generated from the wave 3 emulators</p>
</dd>
</dl>


<hr>
<h2 id='SIRMultiWaveEmulators'>Sample Multi-wave Emulators</h2><span id='topic+SIRMultiWaveEmulators'></span>

<h3>Description</h3>

<p>An rda object containing three waves of emulators applied to
SIR model (described in <code><a href="#topic+SIRSample">SIRSample</a></code>). The corresponding points
(both training and validation) are stored in <code><a href="#topic+SIRMultiWaveData">SIRMultiWaveData</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIRMultiWaveEmulators
</code></pre>


<h3>Format</h3>

<p>A list containing <code><a href="#topic+Emulator">Emulator</a></code> objects:
</p>

<dl>
<dt>Wave 1</dt><dd><p>Emulators trained on Wave 0, generating wave 1 points</p>
</dd>
<dt>Wave 2</dt><dd><p>Emulators trained on the results of the above wave 1 points</p>
</dd>
<dt>Wave 3</dt><dd><p>Emulators trained on the results of the above wave 2 points</p>
</dd>
</dl>


<hr>
<h2 id='SIRSample'>Sample SIR data</h2><span id='topic+SIRSample'></span>

<h3>Description</h3>

<p>A small dataset containing points generated from a simple deterministic SIR model.
The model contains three input parameters, and generates three output
parameters. The initial populations are 950 susceptible (S), 50 infected (I),
and 0 recovered (R). The final values are taken at time t=10.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SIRSample
</code></pre>


<h3>Format</h3>

<p>A list of two data frames. The first has 30 rows and 6 variables, the second
60 rows and 6 variables. The structure is the same in both cases:
</p>

<dl>
<dt>aSI</dt><dd><p>Infection: transition rate from S to I</p>
</dd>
<dt>aIR</dt><dd><p>Recovery: transition rate from I to R</p>
</dd>
<dt>aSR</dt><dd><p>Immunisation: transition rate from S to R</p>
</dd>
<dt>nS</dt><dd><p>Final number of S</p>
</dd>
<dt>nI</dt><dd><p>Final number of I</p>
</dd>
<dt>nR</dt><dd><p>Final number of R</p>
</dd>
</dl>



<h3>Details</h3>

<p>The model operates using simple differential equations, where
</p>
<p>S' = aSR*R - aSI*S*R/(S+I+R)
</p>
<p>I' = aSI*S*R/(S+I+R) - aIR*I
</p>
<p>R' = aIR*I - aSR*R.
</p>

<hr>
<h2 id='space_removal'>Percentage of Space Removed</h2><span id='topic+space_removal'></span>

<h3>Description</h3>

<p>For a wave of emulators, estimates the proportion of space removed at this wave.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>space_removal(
  ems,
  targets,
  points = NULL,
  ppd = NULL,
  cutoff = 3,
  individual = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="space_removal_+3A_ems">ems</code></td>
<td>
<p>The emulators to compute over, as a list</p>
</td></tr>
<tr><td><code id="space_removal_+3A_targets">targets</code></td>
<td>
<p>The output target values</p>
</td></tr>
<tr><td><code id="space_removal_+3A_points">points</code></td>
<td>
<p>The points to test against</p>
</td></tr>
<tr><td><code id="space_removal_+3A_ppd">ppd</code></td>
<td>
<p>If no points are provided and uniform grid is wanted, the number of
points per parameter dimension.</p>
</td></tr>
<tr><td><code id="space_removal_+3A_cutoff">cutoff</code></td>
<td>
<p>The cutoff value for implausibility</p>
</td></tr>
<tr><td><code id="space_removal_+3A_individual">individual</code></td>
<td>
<p>If true, gives emulator-by-emulator results; otherwise works with maximum implausibility</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a collection of emulators corresponding to a wave, we can look at an estimate of
the proportion of points from previous waves that will be accepted at this wave, either
on an emulator-by-emulator basis (to see which outputs are most restrictive) or as an all-wave
determination.
</p>
<p>Naturally, such a statement will be an estimate of the restriction on the full space (which will
become more unreliable for higher dimensions), but it can give an order-of-magnitude statement,
or useful comparators between different emulators in a wave.
</p>
<p>If no points are provided, the training points for the emulators are used. For best results, a
good number of points should be given: typically one should consider using as many points as one
knows to be in the NROY space (including any validation points, if accessible).
</p>


<h3>Value</h3>

<p>A numeric corresponding to the proportions of points removed.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+space_removed">space_removed</a></code> for a visualisation of the space removal.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> space_removal(SIREmulators$ems, SIREmulators$targets,
  rbind(SIRSample$training, SIRSample$validation))
 space_removal(SIREmulators$ems, SIREmulators$targets,
  rbind(SIRSample$training, SIRSample$validation), individual = FALSE)
</code></pre>

<hr>
<h2 id='space_removed'>Space Removal Diagnostics</h2><span id='topic+space_removed'></span>

<h3>Description</h3>

<p>Finds the proportion of space removed as a function of implausibility cut-off and of one of
structural discrepancy, emulator variance, or correlation hyperparameter(s).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>space_removed(
  ems,
  targets,
  ppd = 10,
  u_mod = seq(0.8, 1.2, by = 0.1),
  intervals = seq(0, 10, length.out = 200),
  modified = "obs",
  maxpoints = 50000
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="space_removed_+3A_ems">ems</code></td>
<td>
<p>The <code><a href="#topic+Emulator">Emulator</a></code> objects.</p>
</td></tr>
<tr><td><code id="space_removed_+3A_targets">targets</code></td>
<td>
<p>The corresponding targets to match to.</p>
</td></tr>
<tr><td><code id="space_removed_+3A_ppd">ppd</code></td>
<td>
<p>The number of points per input dimension to sample at.</p>
</td></tr>
<tr><td><code id="space_removed_+3A_u_mod">u_mod</code></td>
<td>
<p>The proportional values by which to inflate/deflate the relevant statistic.</p>
</td></tr>
<tr><td><code id="space_removed_+3A_intervals">intervals</code></td>
<td>
<p>The interval values of the implausibility cutoff at which to evaluate.</p>
</td></tr>
<tr><td><code id="space_removed_+3A_modified">modified</code></td>
<td>
<p>The statistic to modify: obs, disc, var or hp (see above)</p>
</td></tr>
<tr><td><code id="space_removed_+3A_maxpoints">maxpoints</code></td>
<td>
<p>The maximum number of points to evaluate at</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The reduction in space is found by evaluating a p^d regular grid, where p is chosen by
<code>ppd</code> and d is the dimension of the input space. Larger values of p will give a more
accurate reflection of the space removed, at a corresponding computational cost. For the
purpose of quick-and-dirty diagnostics, <code>ppd = 5</code> is sufficient: the default is 10.
</p>
<p>The parameter <code>modified</code> can be one of three strings: <code>'obs'</code> corresponding
to observation uncertainty; <code>'disc'</code> corresponding to internal and external
discrepancy (as given in <code>Emulator$disc</code>); <code>'var'</code> corresponding to global
emulator variance (as given by <code>Emulator$u_sigma</code>), and <code>'hp'</code> corresponding to
the hyperparameters of the emulator correlation structure. In the first case, the
implausibilities are recalculated for each inflation value; in the other two cases the
emulators are retrained. For this reason, the <code>'var'</code> and <code>'hp'</code> options are
computationally more intensive. The default is <code>'obs'</code>.
</p>
<p>The inflationary/deflationary values are chosen by <code>u_mod</code>: the default is to take
80%, 90%, 100%, 110%, and 120% of the original value as the variation. The proportion of
points deemed non-implausible is checked at a set of implausibility cutoffs defined by
<code>intervals</code>, and a plot is returned showing the relevant data.
</p>


<h3>Value</h3>

<p>A ggplot object
</p>


<h3>See Also</h3>

<p><code><a href="#topic+space_removal">space_removal</a></code> for a numeric representation of space removed.
</p>
<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> space_removed(SIREmulators$ems, SIREmulators$targets, ppd = 5)
 space_removed(SIREmulators$ems$nS, SIREmulators$targets,
  ppd = 5, u_mod = seq(0.75, 1.25, by = 0.25), intervals = seq(2, 6, by = 0.1))
</code></pre>

<hr>
<h2 id='standard_errors'>Standardized Error Diagnostics</h2><span id='topic+standard_errors'></span>

<h3>Description</h3>

<p>Shorthand function for diagnostic test &lsquo;se&rsquo;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>standard_errors(
  emulator,
  targets = NULL,
  validation = NULL,
  plt = interactive()
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="standard_errors_+3A_emulator">emulator</code></td>
<td>
<p>The emulator in question</p>
</td></tr>
<tr><td><code id="standard_errors_+3A_targets">targets</code></td>
<td>
<p>The output targets</p>
</td></tr>
<tr><td><code id="standard_errors_+3A_validation">validation</code></td>
<td>
<p>The validation set</p>
</td></tr>
<tr><td><code id="standard_errors_+3A_plt">plt</code></td>
<td>
<p>Whether to plot or not</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details of the function, see <code><a href="#topic+get_diagnostic">get_diagnostic</a></code> and for the plot
see <code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a></code>.
</p>


<h3>Value</h3>

<p>A data.frame of failed points
</p>


<h3>References</h3>

<p>Jackson (2018) &lt;http://etheses.dur.ac.uk/12826&gt;
</p>


<h3>See Also</h3>

<p><code><a href="#topic+get_diagnostic">get_diagnostic</a></code>, <code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a></code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a></code>
</p>
<p>Other diagnostic functions: 
<code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a>()</code>,
<code><a href="#topic+classification_diag">classification_diag</a>()</code>,
<code><a href="#topic+comparison_diag">comparison_diag</a>()</code>,
<code><a href="#topic+get_diagnostic">get_diagnostic</a>()</code>,
<code><a href="#topic+individual_errors">individual_errors</a>()</code>,
<code><a href="#topic+residual_diag">residual_diag</a>()</code>,
<code><a href="#topic+summary_diag">summary_diag</a>()</code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a>()</code>
</p>

<hr>
<h2 id='subset_emulators'>Subsetting for Bimodal/Variance Emulators</h2><span id='topic+subset_emulators'></span>

<h3>Description</h3>

<p>Takes a collection of bimodal or stochastic emulators and subsets by output name.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subset_emulators(emulators, output_names)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subset_emulators_+3A_emulators">emulators</code></td>
<td>
<p>A set of emulators, often in nested form</p>
</td></tr>
<tr><td><code id="subset_emulators_+3A_output_names">output_names</code></td>
<td>
<p>The names of the desired outputs</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It can be useful to consider only a subset of outputs. In the normal case, this can be
easily achieved; however, when the emulators are in a nested structure such as that
provided by emulator_from_data with emulator_type = 'variance' or 'bimodal', it can
be more involved. This function allows the easy selecting of emulators by name, returning a
subset of them in the same form as the original object.
</p>
<p>This function is compatible with &lsquo;standard&rsquo; emulators; that is, those in a simple
list, equivalent to subsetting over the collection of output names of the emulators
that exist in <code>output_names</code>.
</p>


<h3>Value</h3>

<p>An object of the same form as 'emulators'.
</p>

<hr>
<h2 id='summary_diag'>Summary Statistics for Emulators</h2><span id='topic+summary_diag'></span>

<h3>Description</h3>

<p>Generates measures for emulator quality
</p>


<h3>Usage</h3>

<pre><code class='language-R'>summary_diag(emulator, validation, verbose = interactive())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary_diag_+3A_emulator">emulator</code></td>
<td>
<p>The emulator to test</p>
</td></tr>
<tr><td><code id="summary_diag_+3A_validation">validation</code></td>
<td>
<p>The validation set, consisting of points and output(s)</p>
</td></tr>
<tr><td><code id="summary_diag_+3A_verbose">verbose</code></td>
<td>
<p>Should statistics be printed out?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A couple of summary statistics can be generated for emulators, based on their
prediction errors on a validation set. This function produces the test statistic
for a comparison to a relevant chi-squared distribution, and the similar test
statistic for an F-distribution. In both cases, the expectation and standard
deviation of the underlying distribution are also provided.
</p>
<p>The output of this function is a logical vector stating whether the derived
value lies within 3-sigma of the expected value. In systems where errors are
expected to be correlated, higher weight should be given to the Mahalanobis
measure than the chi-squared measure. Any anomalous results can be investigated
in more depth using the <code><a href="#topic+individual_errors">individual_errors</a></code> function.
</p>


<h3>Value</h3>

<p>Whether the observed value lies within 3-sigma of the expected value.
</p>


<h3>References</h3>

<p>Bastos &amp; O'Hagan (2009) &lt;doi:10.1198/TECH.2009.08019&gt;
</p>


<h3>See Also</h3>

<p>Other diagnostic functions: 
<code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a>()</code>,
<code><a href="#topic+classification_diag">classification_diag</a>()</code>,
<code><a href="#topic+comparison_diag">comparison_diag</a>()</code>,
<code><a href="#topic+get_diagnostic">get_diagnostic</a>()</code>,
<code><a href="#topic+individual_errors">individual_errors</a>()</code>,
<code><a href="#topic+residual_diag">residual_diag</a>()</code>,
<code><a href="#topic+standard_errors">standard_errors</a>()</code>,
<code><a href="#topic+validation_diagnostics">validation_diagnostics</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> summary_diag(SIREmulators$ems$nR, SIRSample$validation)
</code></pre>

<hr>
<h2 id='validation_diagnostics'>Emulator Diagnostics</h2><span id='topic+validation_diagnostics'></span>

<h3>Description</h3>

<p>Performs the standard set of validation diagnostics on emulators.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validation_diagnostics(
  emulators,
  targets = NULL,
  validation = NULL,
  which_diag = c("cd", "ce", "se"),
  analyze = TRUE,
  diagnose = "expectation",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validation_diagnostics_+3A_emulators">emulators</code></td>
<td>
<p>A list of <code><a href="#topic+Emulator">Emulator</a></code> objects.</p>
</td></tr>
<tr><td><code id="validation_diagnostics_+3A_targets">targets</code></td>
<td>
<p>The list of observations for the outputs</p>
</td></tr>
<tr><td><code id="validation_diagnostics_+3A_validation">validation</code></td>
<td>
<p>The validation set, containing all inputs and outputs.</p>
</td></tr>
<tr><td><code id="validation_diagnostics_+3A_which_diag">which_diag</code></td>
<td>
<p>Which diagnostics should be performed (see description)</p>
</td></tr>
<tr><td><code id="validation_diagnostics_+3A_analyze">analyze</code></td>
<td>
<p>Should plotting and/or failing points be returned?</p>
</td></tr>
<tr><td><code id="validation_diagnostics_+3A_diagnose">diagnose</code></td>
<td>
<p>For bimodal systems, should the expectation or variance be considered?</p>
</td></tr>
<tr><td><code id="validation_diagnostics_+3A_...">...</code></td>
<td>
<p>Any additional parameters to pass to the diagnostics (eg sd, cutoff, ...)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>All the diagnostics here can be performed with or without a validation (or &lsquo;holdout&rsquo;)
set of data. The presence of a set of targets is optional for some checks but
mandatory for others: the appropriate warnings will be given in the event that some
checks cannot be applied.
</p>
<p>The current options for diagnostics (with the codes for <code>which_diag</code>) are:
</p>
<p>Standardised Errors (se)
</p>
<p>Comparison Diagnostics (cd)
</p>
<p>Classification Errors (ce)
</p>
<p>All of the above (all)
</p>
<p>For details of each of the tests, see the help file for
<code><a href="#topic+get_diagnostic">get_diagnostic</a></code>.
</p>


<h3>Value</h3>

<p>A data.frame containing points that failed one or more diagnostic tests.
</p>


<h3>See Also</h3>

<p>Other diagnostic functions: 
<code><a href="#topic+analyze_diagnostic">analyze_diagnostic</a>()</code>,
<code><a href="#topic+classification_diag">classification_diag</a>()</code>,
<code><a href="#topic+comparison_diag">comparison_diag</a>()</code>,
<code><a href="#topic+get_diagnostic">get_diagnostic</a>()</code>,
<code><a href="#topic+individual_errors">individual_errors</a>()</code>,
<code><a href="#topic+residual_diag">residual_diag</a>()</code>,
<code><a href="#topic+standard_errors">standard_errors</a>()</code>,
<code><a href="#topic+summary_diag">summary_diag</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>validation_diagnostics(SIREmulators$ems, SIREmulators$targets, SIRSample$validation)
# data.frame of failed points (empty) and a 3x3 set of plots
validation_diagnostics(SIREmulators$ems, SIREmulators$targets, SIRSample$validation,
 c('ce','cd'))
# empty data.frame and a 3x2 set of plots
validation_diagnostics(SIREmulators$ems, SIREmulators$targets, SIRSample$validation,
 cutoff = 2, sd = 2)
# k-fold (with k = 3)
validation_diagnostics(SIREmulators$ems, SIREmulators$targets, k = 3)
</code></pre>

<hr>
<h2 id='validation_pairs'>Validation Set Diagnostics and Implausibility</h2><span id='topic+validation_pairs'></span>

<h3>Description</h3>

<p>Creates pairs plots on the set of validation points of diagnostic suitability and
implausibility.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>validation_pairs(ems, points, targets, ranges, nth = 1, cb = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="validation_pairs_+3A_ems">ems</code></td>
<td>
<p>The <code><a href="#topic+Emulator">Emulator</a></code> object(s).</p>
</td></tr>
<tr><td><code id="validation_pairs_+3A_points">points</code></td>
<td>
<p>The set of validation points to plot.</p>
</td></tr>
<tr><td><code id="validation_pairs_+3A_targets">targets</code></td>
<td>
<p>The set of targets to match to.</p>
</td></tr>
<tr><td><code id="validation_pairs_+3A_ranges">ranges</code></td>
<td>
<p>If provided, this gives the plotting region (see above).</p>
</td></tr>
<tr><td><code id="validation_pairs_+3A_nth">nth</code></td>
<td>
<p>The level of maximum implausibility to plot.</p>
</td></tr>
<tr><td><code id="validation_pairs_+3A_cb">cb</code></td>
<td>
<p>Whether or not the colour scheme should be colourblind friendly.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plots are organised as follows:
</p>
<p>a) Emulated versus simulated output (lower diagonal). This is similar in spirit to
<code><a href="#topic+comparison_diag">comparison_diag</a></code>: the plotted points are their location in the input
space and the points are coloured by the emulator prediction's deviation from the
simulator value.
</p>
<p>b) Implausibility (upper diagonal). The points are again plotted based on their
location in input space, but their colouration is now based on the implausibility
of the point.
</p>
<p>If <code>ranges</code> is provided, then the plotting region is created relative to these
ranges. This can be useful if on later waves of a history match and the plotting is
to be done relative to the original input space, rather than the (reduced) parameter
space upon which the emulators have been trained.
</p>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> validation_pairs(SIREmulators$ems, SIRSample$validation, SIREmulators$targets)
 wider_ranges &lt;- purrr::map(SIREmulators$ems[[1]]$ranges, ~.*c(-2, 2))
 validation_pairs(SIREmulators$ems, SIRSample$validation,
  SIREmulators$targets, ranges = wider_ranges, cb = TRUE)
</code></pre>

<hr>
<h2 id='variance_emulator_from_data'>Variance Emulator Creation (Deprecated)</h2><span id='topic+variance_emulator_from_data'></span>

<h3>Description</h3>

<p>Trains hierarchical emulators to stochastic systems
</p>


<h3>Usage</h3>

<pre><code class='language-R'>variance_emulator_from_data(
  input_data,
  output_names,
  ranges,
  input_names = names(ranges),
  verbose = interactive(),
  na.rm = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="variance_emulator_from_data_+3A_input_data">input_data</code></td>
<td>
<p>All model runs at all points.</p>
</td></tr>
<tr><td><code id="variance_emulator_from_data_+3A_output_names">output_names</code></td>
<td>
<p>The observation names.</p>
</td></tr>
<tr><td><code id="variance_emulator_from_data_+3A_ranges">ranges</code></td>
<td>
<p>A named list of parameter ranges</p>
</td></tr>
<tr><td><code id="variance_emulator_from_data_+3A_input_names">input_names</code></td>
<td>
<p>The names of the parameters (if <code>ranges</code> is not provided).</p>
</td></tr>
<tr><td><code id="variance_emulator_from_data_+3A_verbose">verbose</code></td>
<td>
<p>Should status updates be printed to console?</p>
</td></tr>
<tr><td><code id="variance_emulator_from_data_+3A_na.rm">na.rm</code></td>
<td>
<p>Should NA values be removed before training?</p>
</td></tr>
<tr><td><code id="variance_emulator_from_data_+3A_...">...</code></td>
<td>
<p>Optional parameters that can be passed to <code>link{emulator_from_data}</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is deprecated in favour of using <code><a href="#topic+emulator_from_data">emulator_from_data</a></code>
with argument <code>emulator_type = "variance"</code>. See the associated help file.
</p>
<p>For stochastic systems, one may emulate the variance as well as the function itself.
This is particularly true if one expects the variance to be very different in different
areas of the parameter space (for example, in an epidemic model). This function performs
the requisite two-stage Bayes Linear update.
</p>
<p>All observations are required (including replicates at points) - this function collects
them into the required chunks and calculates the summary statistics as required.
</p>
<p>All other parameters passed to this function are equivalent to those in
emulators are the Bayes Linear adjusted forms.
</p>


<h3>Value</h3>

<p>A list of lists: one for the variance emulators and one for the function emulators.
</p>


<h3>References</h3>

<p>Goldstein &amp; Vernon (2016) in preparation
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
 # A simple example using the BirthDeath dataset
 v_ems &lt;- variance_emulator_from_data(BirthDeath$training, c("Y"),
  list(lambda = c(0, 0.08), mu = c(0.04, 0.13)), c_lengths = c(0.75))


</code></pre>

<hr>
<h2 id='wave_dependencies'>Multiple Wave Inputs vs Outputs</h2><span id='topic+wave_dependencies'></span>

<h3>Description</h3>

<p>Given multiple waves of points, produce input-output plots for each pair.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wave_dependencies(
  waves,
  targets,
  output_names = names(targets),
  input_names = names(waves[[1]])[!names(waves[[1]]) %in% names(targets)],
  p_size = 1.5,
  l_wid = 1.5,
  normalize = FALSE,
  zero_in = TRUE,
  wave_numbers = ifelse(zero_in, 0, 1):(length(waves) - ifelse(zero_in, 1, 0)),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wave_dependencies_+3A_waves">waves</code></td>
<td>
<p>The list of data.frame objects, one for each set of outputs at that wave.</p>
</td></tr>
<tr><td><code id="wave_dependencies_+3A_targets">targets</code></td>
<td>
<p>The target values of the outputs.</p>
</td></tr>
<tr><td><code id="wave_dependencies_+3A_output_names">output_names</code></td>
<td>
<p>The outputs to plot, if not all are wanted.</p>
</td></tr>
<tr><td><code id="wave_dependencies_+3A_input_names">input_names</code></td>
<td>
<p>The inputs to plot, if not all are wanted.</p>
</td></tr>
<tr><td><code id="wave_dependencies_+3A_p_size">p_size</code></td>
<td>
<p>Control for the point size on the plots: smaller is better for many plots.</p>
</td></tr>
<tr><td><code id="wave_dependencies_+3A_l_wid">l_wid</code></td>
<td>
<p>Control for line width of superimposed targets.</p>
</td></tr>
<tr><td><code id="wave_dependencies_+3A_normalize">normalize</code></td>
<td>
<p>If true, plotting is done with target bounds equal size.</p>
</td></tr>
<tr><td><code id="wave_dependencies_+3A_zero_in">zero_in</code></td>
<td>
<p>Is a wave 0 included in the waves list?</p>
</td></tr>
<tr><td><code id="wave_dependencies_+3A_wave_numbers">wave_numbers</code></td>
<td>
<p>Which waves to plot</p>
</td></tr>
<tr><td><code id="wave_dependencies_+3A_...">...</code></td>
<td>
<p>Optional parameters (not to be used directly)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>It can be useful to consider what the dependencies between the input values and output
values are, to investigate the suitability of the chosen input ranges (i.e. if widening
an input range could result in the targets being matchable). This function provides those
plots.
</p>
<p>For each output-input pair, a points plot is produced with the input value on the x-axis
and the output value on the y-axis. The target bounds are superimposed as horizontal lines.
The points themselves are coloured by which wave of history matching they came from.
</p>
<p>These can show dependencies between specific outputs and inputs and, if points are clustering
at the far left or right edge of a plot, can give an indication that the input ranges are
unsuitable for matching the target.
</p>


<h3>Value</h3>

<p>A grid of ggplot objects.
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> wave_dependencies(SIRMultiWaveData, SIREmulators$targets, l_wid = 0.8, p_size = 0.8)
 wave_dependencies(SIRMultiWaveData, SIREmulators$targets, c('nS', 'nI'), c('aIR', 'aSI'))
 
     # For many plots, it may be helpful to manually modify the font size
     wave_dependencies(SIRMultiWaveData, SIREmulators$targets) +
      ggplot2::theme(text = ggplot2::element_text(size = 5))
 
</code></pre>

<hr>
<h2 id='wave_points'>Multiple Wave Point Plotting</h2><span id='topic+wave_points'></span>

<h3>Description</h3>

<p>Given multiple waves of points, produces pairs plots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wave_points(
  waves,
  input_names,
  surround = FALSE,
  p_size = 1.5,
  zero_in = TRUE,
  wave_numbers = ifelse(zero_in, 0, 1):(length(waves) - ifelse(zero_in, 1, 0)),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wave_points_+3A_waves">waves</code></td>
<td>
<p>The list of data.frames, one for each set of points at that wave.</p>
</td></tr>
<tr><td><code id="wave_points_+3A_input_names">input_names</code></td>
<td>
<p>The input names to be plotted.</p>
</td></tr>
<tr><td><code id="wave_points_+3A_surround">surround</code></td>
<td>
<p>If true, points are surrounded by black boundaries.</p>
</td></tr>
<tr><td><code id="wave_points_+3A_p_size">p_size</code></td>
<td>
<p>The size of the points. Smaller values are better for high-dimensional spaces.</p>
</td></tr>
<tr><td><code id="wave_points_+3A_zero_in">zero_in</code></td>
<td>
<p>Is a wave 0 included in the waves list?</p>
</td></tr>
<tr><td><code id="wave_points_+3A_wave_numbers">wave_numbers</code></td>
<td>
<p>Which waves to plot</p>
</td></tr>
<tr><td><code id="wave_points_+3A_...">...</code></td>
<td>
<p>Optional parameters (not to be used directly)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Subsequent waves are overlaid on the same pairs plots, to determine the
evolution of the non-implausible region. One-dimensional density plots
are also created on the diagonal.
</p>


<h3>Value</h3>

<p>A ggplot object
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_values">wave_values</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> wave_points(SIRMultiWaveData, c('aSI', 'aIR', 'aSR'))
 
     wave_points(SIRMultiWaveData, c('aSI', 'aIR', 'aSR'), TRUE, 0.8)
     # For many plots, it may be helpful to manually modify the font size
     wave_points(SIRMultiWaveData, c('aSI', 'aIR', 'aSR')) +
      ggplot2::theme(text = ggplot2::element_text(size = 5))
 
</code></pre>

<hr>
<h2 id='wave_values'>Multiple Wave Output Plotting</h2><span id='topic+wave_values'></span>

<h3>Description</h3>

<p>Given multiple waves of points, produces pairs plots of the outputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wave_values(
  waves,
  targets,
  output_names = names(targets),
  ems = NULL,
  surround = FALSE,
  restrict = FALSE,
  p_size = 1.5,
  l_wid = 1.5,
  zero_in = TRUE,
  wave_numbers = ifelse(zero_in, 0, 1):(length(waves) - ifelse(zero_in, 0, 1)),
  which_wave = ifelse(zero_in, 0, 1),
  upper_scale = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wave_values_+3A_waves">waves</code></td>
<td>
<p>The list of data.frames, one for each set of outputs at that wave.</p>
</td></tr>
<tr><td><code id="wave_values_+3A_targets">targets</code></td>
<td>
<p>The output targets.</p>
</td></tr>
<tr><td><code id="wave_values_+3A_output_names">output_names</code></td>
<td>
<p>The outputs to plot.</p>
</td></tr>
<tr><td><code id="wave_values_+3A_ems">ems</code></td>
<td>
<p>If provided, plots the emulator expectations and 3-standard deviations.</p>
</td></tr>
<tr><td><code id="wave_values_+3A_surround">surround</code></td>
<td>
<p>As in <code><a href="#topic+wave_points">wave_points</a></code>.</p>
</td></tr>
<tr><td><code id="wave_values_+3A_restrict">restrict</code></td>
<td>
<p>Should the plotting automatically restrict to failing target windows?</p>
</td></tr>
<tr><td><code id="wave_values_+3A_p_size">p_size</code></td>
<td>
<p>As in <code><a href="#topic+wave_points">wave_points</a></code>.</p>
</td></tr>
<tr><td><code id="wave_values_+3A_l_wid">l_wid</code></td>
<td>
<p>The width of the lines that create the target boxes.</p>
</td></tr>
<tr><td><code id="wave_values_+3A_zero_in">zero_in</code></td>
<td>
<p>Is a wave 0 included in the waves list?</p>
</td></tr>
<tr><td><code id="wave_values_+3A_wave_numbers">wave_numbers</code></td>
<td>
<p>Which waves to plot.</p>
</td></tr>
<tr><td><code id="wave_values_+3A_which_wave">which_wave</code></td>
<td>
<p>Scaling for lower plots (see description)</p>
</td></tr>
<tr><td><code id="wave_values_+3A_upper_scale">upper_scale</code></td>
<td>
<p>Scaling for upper plots (ibid)</p>
</td></tr>
<tr><td><code id="wave_values_+3A_...">...</code></td>
<td>
<p>Optional parameters (not to be used directly)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function operates in a similar fashion to <code><a href="#topic+wave_points">wave_points</a></code> - the main
difference is that the output values are plotted. Consequently, the set of targets is required
to overlay the region of interest onto the plot.
</p>
<p>To ensure that the wave numbers provided in the legend match, one should provide waves
as a list of data.frames with the earliest wave at the start of the list.
</p>
<p>The parameters <code>which_wave</code> and <code>upper_scale</code> control the level of &lsquo;zoom&rsquo; on
each of the lower-triangular and upper-triangular plots, respectively. For the lower
plots, <code>which_wave</code> determines which of the provided waves is to be used to determine
the output ranges to plot with respect to: generally, higher <code>which_wave</code> values
result in a more zoomed-in plot. For the upper plots, <code>upper_scale</code> determines the
plot window via a multiple of the target bounds: higher values result in a more zoomed-out
plot. If not provided, these default to <code>which_wave=0</code> (or 1 if no wave 0 is given)
and <code>upper_scale = 1</code>. If the value provided to <code>which_wave</code> does not correspond
to a provided wave (or one explicitly not included in <code>wave_numbers</code>), it defaults to
the closest available wave to the value of <code>which_wave</code>.
</p>
<p>If <code>ems</code> is provided, it should follow the same structure as <code>waves</code>: at the very
least, it should contain all emulators trained over the course of the waves. The emulator
predictions for a target are made by the emulator for that target whose ranges are the
smallest such that contain the point.
</p>


<h3>Value</h3>

<p>A ggplot object.
</p>


<h3>See Also</h3>

<p>Other visualisation tools: 
<code><a href="#topic+behaviour_plot">behaviour_plot</a>()</code>,
<code><a href="#topic+diagnostic_wrap">diagnostic_wrap</a>()</code>,
<code><a href="#topic+effect_strength">effect_strength</a>()</code>,
<code><a href="#topic+emulator_plot">emulator_plot</a>()</code>,
<code><a href="#topic+hit_by_wave">hit_by_wave</a>()</code>,
<code><a href="#topic+output_plot">output_plot</a>()</code>,
<code><a href="#topic+plot_actives">plot_actives</a>()</code>,
<code><a href="#topic+plot_lattice">plot_lattice</a>()</code>,
<code><a href="#topic+plot_wrap">plot_wrap</a>()</code>,
<code><a href="#topic+simulator_plot">simulator_plot</a>()</code>,
<code><a href="#topic+space_removed">space_removed</a>()</code>,
<code><a href="#topic+validation_pairs">validation_pairs</a>()</code>,
<code><a href="#topic+wave_dependencies">wave_dependencies</a>()</code>,
<code><a href="#topic+wave_points">wave_points</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> wave_values(SIRMultiWaveData, SIREmulators$targets, surround = TRUE, p_size = 1)
 
   wave_values(SIRMultiWaveData, SIREmulators$targets, c('nS', 'nI'), l_wid = 0.8)
     wave_values(SIRMultiWaveData, SIREmulators$targets, l_wid = 0.8,
      wave_numbers = c(0, 1, 3), which_wave = 2, upper_scale =  1.5)
     # For many plots, it may be helpful to manually modify the font size
     wave_values(SIRMultiWaveData, SIREmulators$targets) +
      ggplot2::theme(text = ggplot2::element_text(size = 5))
 
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
