<!DOCTYPE html><html lang="en"><head><title>Help for package TSLSTMplus</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TSLSTMplus}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lagmatrix'><p>Create lead/lags of a variable</p></a></li>
<li><a href='#LSTMModel'><p>LSTMModel class</p></a></li>
<li><a href='#minmax_scale'><p>Min-Max Scaling of a Matrix</p></a></li>
<li><a href='#predict.LSTMModel'><p>Predict using a Trained LSTM Model</p></a></li>
<li><a href='#summary.LSTMModel'><p>Summary of a Trained LSTM Model</p></a></li>
<li><a href='#ts.lstm'><p>Long Short Term Memory (LSTM) Model for Time Series Forecasting</p></a></li>
<li><a href='#ts.prepare.data'><p>Prepare data for Long Short Term Memory (LSTM) Model for Time Series Forecasting</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Long-Short Term Memory for Time-Series Forecasting, Enhanced</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.6</td>
</tr>
<tr>
<td>Author:</td>
<td>Jaime Pizarroso Gonzalo [aut, ctb, cre],
  Antonio Mu√±oz San Roque [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Jaime Pizarroso Gonzalo &lt;jpizarroso@comillas.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Customizable configurations for the model are allowed, improving the capabilities and usability of this model compared to other packages. This package is based on 'keras' and 'tensorflow' modules and the algorithm of Paul and Garai (2021) &lt;<a href="https://doi.org/10.1007%2Fs00500-021-06087-4">doi:10.1007/s00500-021-06087-4</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>keras, tensorflow, stats, abind</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-02-03</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-03 12:15:39 UTC; jpizarroso</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-03 14:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='lagmatrix'>Create lead/lags of a variable</h2><span id='topic+lagmatrix'></span>

<h3>Description</h3>

<p>Create an array with lead/lags of an input variable.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lagmatrix(x, lag)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="lagmatrix_+3A_x">x</code></td>
<td>
<p>input variable.</p>
</td></tr>
<tr><td><code id="lagmatrix_+3A_lag">lag</code></td>
<td>
<p>vector of leads and lags. Positive numbers are lags, negative are leads. O is the original <code>x</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An array with the resulting leads and lags (columns).
</p>


<h3>Note</h3>

<p>This code was copied from the <code>ts.utils</code> package to avoid the archive
operations of the <code>smooth</code> package in 16-02-2025. This function might be deprecated
in future releases to use the one from <code>ts.utils</code> again.
</p>


<h3>Author(s)</h3>

<p>Nikolaos Kourentzes, <a href="mailto:nikolaos@kourentzes.com">nikolaos@kourentzes.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  x &lt;- rnorm(10)
  lagmatrix(x,c(0,1,-1))

</code></pre>

<hr>
<h2 id='LSTMModel'>LSTMModel class</h2><span id='topic+LSTMModel'></span>

<h3>Description</h3>

<p>LSTMModel class for further use in predict function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>LSTMModel(
  lstm_model,
  scale_output,
  scaler_output,
  scale_input,
  scaler_input,
  tsLag,
  xregLag,
  model_structure,
  batch_size,
  lags_as_sequences,
  stateful
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="LSTMModel_+3A_lstm_model">lstm_model</code></td>
<td>
<p>LSTM 'keras' model</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_scale_output">scale_output</code></td>
<td>
<p>indicate which type of scaler is used in the output</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_scaler_output">scaler_output</code></td>
<td>
<p>Scaler of output variable (and lags)</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_scale_input">scale_input</code></td>
<td>
<p>indicate which type of scaler is used in the input(s)</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_scaler_input">scaler_input</code></td>
<td>
<p>Scaler of input variable(s) (and lags)</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_tslag">tsLag</code></td>
<td>
<p>Lag of time series data</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_xreglag">xregLag</code></td>
<td>
<p>Lag of exogenous variables</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_model_structure">model_structure</code></td>
<td>
<p>Summary of the LSTM model previous to training</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_batch_size">batch_size</code></td>
<td>
<p>Batch size used during training of the model</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_lags_as_sequences">lags_as_sequences</code></td>
<td>
<p>Flag to indicate the model has been trained statefully</p>
</td></tr>
<tr><td><code id="LSTMModel_+3A_stateful">stateful</code></td>
<td>
<p>Flag to indicate if LSTM layers shall retain its state between batches.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>LSTMModel object
</p>


<h3>References</h3>

<p>Paul, R.K. and Garai, S. (2021). Performance comparison of wavelets-based machine learning technique for forecasting agricultural commodity prices, Soft Computing, 25(20), 12857-12873
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
if (keras::is_keras_available()){
  y&lt;-rnorm(100,mean=100,sd=50)
  x1&lt;-rnorm(100,mean=50,sd=50)
  x2&lt;-rnorm(100, mean=50, sd=25)
  x&lt;-cbind(x1,x2)
  TSLSTM&lt;-ts.lstm(ts=y,
                  xreg = x,
                  tsLag=2,
                  xregLag = 0,
                  LSTMUnits=5,
                  ScaleInput = 'scale',
                  ScaleOutput = 'scale',
                  Epochs=2)
}

</code></pre>

<hr>
<h2 id='minmax_scale'>Min-Max Scaling of a Matrix</h2><span id='topic+minmax_scale'></span>

<h3>Description</h3>

<p>This function applies min-max scaling to a matrix. Each column of the matrix is scaled independently.
The scaling process transforms the values in each column to a specified range, typically [0, 1]. The function
subtracts the minimum value of each column (if 'min' is 'TRUE' or a numeric vector) and then divides by the range
of each column (if 'range' is 'TRUE' or a numeric vector).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>minmax_scale(x, min = TRUE, range = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="minmax_scale_+3A_x">x</code></td>
<td>
<p>A numeric matrix whose columns are to be scaled.</p>
</td></tr>
<tr><td><code id="minmax_scale_+3A_min">min</code></td>
<td>
<p>Logical or numeric vector. If 'TRUE', the minimum value of each column is subtracted.
If a numeric vector is provided, it must have a length equal to the number of columns in 'x',
and these values are subtracted from each corresponding column.</p>
</td></tr>
<tr><td><code id="minmax_scale_+3A_range">range</code></td>
<td>
<p>Logical or numeric vector. If 'TRUE', each column is divided by its range.
If a numeric vector is provided, it must have a length equal to the number of columns in 'x',
and each column is divided by the corresponding value in this vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with the same dimensions as 'x', where each column has been scaled according to the min-max scaling process.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  data &lt;- matrix(rnorm(100), ncol = 10)
  scaled_data &lt;- minmax_scale(data)


</code></pre>

<hr>
<h2 id='predict.LSTMModel'>Predict using a Trained LSTM Model</h2><span id='topic+predict.LSTMModel'></span>

<h3>Description</h3>

<p>This function makes predictions using a trained LSTM model for time series forecasting. It performs iterative predictions where each step uses the prediction from the previous step. The function takes into account the lags in both the time series data and the exogenous variables.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LSTMModel'
predict(
  object,
  ts,
  xreg = NULL,
  xreg.new = NULL,
  horizon = NULL,
  BatchSize = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.LSTMModel_+3A_object">object</code></td>
<td>
<p>An LSTMModel object containing a trained LSTM model along with normalization parameters and lag values.</p>
</td></tr>
<tr><td><code id="predict.LSTMModel_+3A_ts">ts</code></td>
<td>
<p>A vector or time series object containing the historical time series data. It should have a number of observations at least equal to the lag of the time series data.</p>
</td></tr>
<tr><td><code id="predict.LSTMModel_+3A_xreg">xreg</code></td>
<td>
<p>(Optional) A matrix or data frame of exogenous variables to be used for prediction. It should have a number of rows at least equal to the lag of the exogenous variables.</p>
</td></tr>
<tr><td><code id="predict.LSTMModel_+3A_xreg.new">xreg.new</code></td>
<td>
<p>(Optional) A matrix or data frame of exogenous variables to be used for prediction. It should have a number of rows at least equal to the lag of the exogenous variables.</p>
</td></tr>
<tr><td><code id="predict.LSTMModel_+3A_horizon">horizon</code></td>
<td>
<p>The number of future time steps to predict.</p>
</td></tr>
<tr><td><code id="predict.LSTMModel_+3A_batchsize">BatchSize</code></td>
<td>
<p>(Optional) Batch size to use during prediction</p>
</td></tr>
<tr><td><code id="predict.LSTMModel_+3A_...">...</code></td>
<td>
<p>Optional arguments, no use is contemplated right now</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the forecasted values for the specified horizon.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  if (keras::is_keras_available()){
      y&lt;-rnorm(100,mean=100,sd=50)
      x1&lt;-rnorm(150,mean=50,sd=50)
      x2&lt;-rnorm(150, mean=50, sd=25)
      x&lt;-cbind(x1,x2)
      x.tr &lt;- x[1:100,]
      x.ts &lt;- x[101:150,]
      TSLSTM&lt;-ts.lstm(ts=y,
                      xreg = x.tr,
                      tsLag=2,
                      xregLag = 0,
                      LSTMUnits=5,
                      ScaleInput = 'scale',
                      ScaleOutput = 'scale',
                      Epochs=2)
      current_values &lt;- predict(TSLSTM, xreg = x.tr, ts = y)
      future_values &lt;- predict(TSLSTM, horizon=50, xreg = x, ts = y, xreg.new = x.ts)
   }

</code></pre>

<hr>
<h2 id='summary.LSTMModel'>Summary of a Trained LSTM Model</h2><span id='topic+summary.LSTMModel'></span>

<h3>Description</h3>

<p>This function generates the summary of the LSTM model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LSTMModel'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="summary.LSTMModel_+3A_object">object</code></td>
<td>
<p>An LSTMModel object containing a trained LSTM model along with normalization parameters and lag values.</p>
</td></tr>
<tr><td><code id="summary.LSTMModel_+3A_...">...</code></td>
<td>
<p>Optional arguments, no use is contemplated right now</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector containing the forecasted values for the specified horizon.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  if (keras::is_keras_available()){
      y&lt;-rnorm(100,mean=100,sd=50)
      x1&lt;-rnorm(100,mean=50,sd=50)
      x2&lt;-rnorm(100, mean=50, sd=25)
      x&lt;-cbind(x1,x2)
      TSLSTM&lt;-ts.lstm(ts=y,
                      xreg = x,
                      tsLag=2,
                      xregLag = 0,
                      LSTMUnits=5,
                      ScaleInput = 'scale',
                      ScaleOutput = 'scale',
                      Epochs=2)
      # Assuming TSLSTM is an LSTMModel object created using ts.lstm function
      summary(TSLSTM)
  }


</code></pre>

<hr>
<h2 id='ts.lstm'>Long Short Term Memory (LSTM) Model for Time Series Forecasting</h2><span id='topic+ts.lstm'></span>

<h3>Description</h3>

<p>The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Min-Max transformation has been used for data preparation. Here, we have used one LSTM layer as a simple LSTM model and a Dense layer is used as the output layer. Then, compile the model using the loss function, optimizer and metrics. This package is based on 'keras' and TensorFlow modules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ts.lstm(
  ts,
  xreg = NULL,
  tsLag = NULL,
  xregLag = 0,
  LSTMUnits,
  DenseUnits = NULL,
  DropoutRate = 0,
  Epochs = 10,
  CompLoss = "mse",
  CompMetrics = "mae",
  Optimizer = optimizer_rmsprop,
  ScaleOutput = c(NULL, "scale", "minmax"),
  ScaleInput = c(NULL, "scale", "minmax"),
  BatchSize = 1,
  LSTMActivationFn = "tanh",
  LSTMRecurrentActivationFn = "sigmoid",
  DenseActivationFn = "relu",
  ValidationSplit = 0.1,
  verbose = 2,
  RandomState = NULL,
  EarlyStopping = callback_early_stopping(monitor = "val_loss", min_delta = 0, patience =
    3, verbose = 0, mode = "auto"),
  LagsAsSequences = TRUE,
  Stateful = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ts.lstm_+3A_ts">ts</code></td>
<td>
<p>Time series data</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_xreg">xreg</code></td>
<td>
<p>Exogenous variables</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_tslag">tsLag</code></td>
<td>
<p>Lag of time series data. If NULL, no lags of the output are used.</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_xreglag">xregLag</code></td>
<td>
<p>Lag of exogenous variables</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_lstmunits">LSTMUnits</code></td>
<td>
<p>Number of unit in LSTM layers</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_denseunits">DenseUnits</code></td>
<td>
<p>Number of unit in Extra Dense layers. A Dense layer with a single neuron is always added at the end.</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_dropoutrate">DropoutRate</code></td>
<td>
<p>Dropout rate</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_epochs">Epochs</code></td>
<td>
<p>Number of epochs</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_comploss">CompLoss</code></td>
<td>
<p>Loss function</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_compmetrics">CompMetrics</code></td>
<td>
<p>Metrics</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_optimizer">Optimizer</code></td>
<td>
<p>'keras' optimizer</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_scaleoutput">ScaleOutput</code></td>
<td>
<p>Flag to indicate if ts shall be scaled before training</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_scaleinput">ScaleInput</code></td>
<td>
<p>Flag to indicate if xreg shall be scaled before training</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_batchsize">BatchSize</code></td>
<td>
<p>Batch size to use during training</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_lstmactivationfn">LSTMActivationFn</code></td>
<td>
<p>Activation function for LSTM layers</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_lstmrecurrentactivationfn">LSTMRecurrentActivationFn</code></td>
<td>
<p>Recurrent activation function for LSTM layers</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_denseactivationfn">DenseActivationFn</code></td>
<td>
<p>Activation function for Extra Dense layers</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_validationsplit">ValidationSplit</code></td>
<td>
<p>Validation split ration</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_verbose">verbose</code></td>
<td>
<p>Indicate how much information is given during training. Accepted values, 0, 1 or 2.</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_randomstate">RandomState</code></td>
<td>
<p>seed for replication</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_earlystopping">EarlyStopping</code></td>
<td>
<p>EarlyStopping according to 'keras'</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_lagsassequences">LagsAsSequences</code></td>
<td>
<p>Use lags as previous timesteps of features, otherwise use them as &quot;extra&quot; features.</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_stateful">Stateful</code></td>
<td>
<p>Flag to indicate if LSTM layers shall retain its state between batches.</p>
</td></tr>
<tr><td><code id="ts.lstm_+3A_...">...</code></td>
<td>
<p>Extra arguments passed to keras::layer_lstm</p>
</td></tr>
</table>


<h3>Value</h3>

<p>LSTMmodel object
</p>


<h3>References</h3>

<p>Paul, R.K. and Garai, S. (2021). Performance comparison of wavelets-based machine learning technique for forecasting agricultural commodity prices, Soft Computing, 25(20), 12857-12873
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
  if (keras::is_keras_available()){
      y&lt;-rnorm(100,mean=100,sd=50)
      x1&lt;-rnorm(100,mean=50,sd=50)
      x2&lt;-rnorm(100, mean=50, sd=25)
      x&lt;-cbind(x1,x2)
      TSLSTM&lt;-ts.lstm(ts=y,
                      xreg = x,
                      tsLag=2,
                      xregLag = 0,
                      LSTMUnits=5,
                      ScaleInput = 'scale',
                      ScaleOutput = 'scale',
                      Epochs=2)
  }

</code></pre>

<hr>
<h2 id='ts.prepare.data'>Prepare data for Long Short Term Memory (LSTM) Model for Time Series Forecasting</h2><span id='topic+ts.prepare.data'></span>

<h3>Description</h3>

<p>The LSTM (Long Short-Term Memory) model is a Recurrent Neural Network (RNN) based architecture that is widely used for time series forecasting. Min-Max transformation has been used for data preparation. Here, we have used one LSTM layer as a simple LSTM model and a Dense layer is used as the output layer. Then, compile the model using the loss function, optimizer and metrics. This package is based on 'keras' and TensorFlow modules.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ts.prepare.data(ts, xreg = NULL, tsLag, xregLag = 0)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ts.prepare.data_+3A_ts">ts</code></td>
<td>
<p>Time series data</p>
</td></tr>
<tr><td><code id="ts.prepare.data_+3A_xreg">xreg</code></td>
<td>
<p>Exogenous variables</p>
</td></tr>
<tr><td><code id="ts.prepare.data_+3A_tslag">tsLag</code></td>
<td>
<p>Lag of time series data</p>
</td></tr>
<tr><td><code id="ts.prepare.data_+3A_xreglag">xregLag</code></td>
<td>
<p>Lag of exogenous variables</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dataset with all lags created from exogenous and time series data.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  y &lt;- rnorm(100,mean=100,sd=50)
  x1 &lt;- rnorm(100,mean=50,sd=50)
  x2 &lt;- rnorm(100, mean=50, sd=25)
  x &lt;- cbind(x1,x2)
  ts.prepare.data(y, x, 2, 4)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
