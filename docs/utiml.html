<!DOCTYPE html><html><head><title>Help for package utiml</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {utiml}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#[.mlresult'><p>Filter a Multi-Label Result</p></a></li>
<li><a href='#+.mlconfmat'><p>Join two multi-label confusion matrix</p></a></li>
<li><a href='#as.bipartition'><p>Convert a mlresult to a bipartition matrix</p></a></li>
<li><a href='#as.matrix.mlconfmat'><p>Convert a multi-label Confusion Matrix to matrix</p></a></li>
<li><a href='#as.matrix.mlresult'><p>Convert a mlresult to matrix</p></a></li>
<li><a href='#as.mlresult'><p>Convert a matrix prediction in a multi label prediction</p></a></li>
<li><a href='#as.probability'><p>Convert a mlresult to a probability matrix</p></a></li>
<li><a href='#as.ranking'><p>Convert a mlresult to a ranking matrix</p></a></li>
<li><a href='#baseline'><p>Baseline reference for multilabel classification</p></a></li>
<li><a href='#br'><p>Binary Relevance for multi-label Classification</p></a></li>
<li><a href='#brplus'><p>BR+ or BRplus for multi-label Classification</p></a></li>
<li><a href='#cc'><p>Classifier Chains for multi-label Classification</p></a></li>
<li><a href='#clr'><p>Calibrated Label Ranking (CLR) for multi-label Classification</p></a></li>
<li><a href='#compute_multilabel_predictions'><p>Compute the multi-label ensemble predictions based on some vote schema</p></a></li>
<li><a href='#create_holdout_partition'><p>Create a holdout partition based on the specified algorithm</p></a></li>
<li><a href='#create_kfold_partition'><p>Create the k-folds partition based on the specified algorithm</p></a></li>
<li><a href='#create_random_subset'><p>Create a random subset of a dataset</p></a></li>
<li><a href='#create_subset'><p>Create a subset of a dataset</p></a></li>
<li><a href='#cv'><p>Multi-label cross-validation</p></a></li>
<li><a href='#dbr'><p>Dependent Binary Relevance (DBR) for multi-label Classification</p></a></li>
<li><a href='#ebr'><p>Ensemble of Binary Relevance for multi-label Classification</p></a></li>
<li><a href='#ecc'><p>Ensemble of Classifier Chains for multi-label Classification</p></a></li>
<li><a href='#eps'><p>Ensemble of Pruned Set for multi-label Classification</p></a></li>
<li><a href='#esl'><p>Ensemble of Single Label</p></a></li>
<li><a href='#fill_sparse_mldata'><p>Fill sparse dataset with 0 or &rdquo; values</p></a></li>
<li><a href='#fixed_threshold'><p>Apply a fixed threshold in the results</p></a></li>
<li><a href='#foodtruck'><p>Foodtruck multi-label dataset.</p></a></li>
<li><a href='#homer'><p>Hierarchy Of Multilabel classifiER (HOMER)</p></a></li>
<li><a href='#is.bipartition'><p>Test if a mlresult contains crisp values as default</p></a></li>
<li><a href='#is.probability'><p>Test if a mlresult contains score values as default</p></a></li>
<li><a href='#lcard_threshold'><p>Threshold based on cardinality</p></a></li>
<li><a href='#lift'><p>LIFT for multi-label Classification</p></a></li>
<li><a href='#lp'><p>Label Powerset for multi-label Classification</p></a></li>
<li><a href='#mbr'><p>Meta-BR or 2BR for multi-label Classification</p></a></li>
<li><a href='#mcut_threshold'><p>Maximum Cut Thresholding (MCut)</p></a></li>
<li><a href='#merge_mlconfmat'><p>Join a list of multi-label confusion matrix</p></a></li>
<li><a href='#mldata'><p>Fix the mldr dataset to use factors</p></a></li>
<li><a href='#mlknn'><p>Multi-label KNN (ML-KNN) for multi-label Classification</p></a></li>
<li><a href='#mlpredict'><p>Prediction transformation problems</p></a></li>
<li><a href='#mltrain'><p>Build transformation models</p></a></li>
<li><a href='#multilabel_confusion_matrix'><p>Compute the confusion matrix for a multi-label prediction</p></a></li>
<li><a href='#multilabel_evaluate'><p>Evaluate multi-label predictions</p></a></li>
<li><a href='#multilabel_measures'><p>Return the name of all measures</p></a></li>
<li><a href='#multilabel_prediction'><p>Create a mlresult object</p></a></li>
<li><a href='#normalize_mldata'><p>Normalize numerical attributes</p></a></li>
<li><a href='#ns'><p>Nested Stacking for multi-label Classification</p></a></li>
<li><a href='#partition_fold'><p>Create the multi-label dataset from folds</p></a></li>
<li><a href='#pcut_threshold'><p>Proportional Thresholding (PCut)</p></a></li>
<li><a href='#ppt'><p>Pruned Problem Transformation for multi-label Classification</p></a></li>
<li><a href='#predict.BASELINEmodel'><p>Predict Method for BASELINE</p></a></li>
<li><a href='#predict.BRmodel'><p>Predict Method for Binary Relevance</p></a></li>
<li><a href='#predict.BRPmodel'><p>Predict Method for BR+ (brplus)</p></a></li>
<li><a href='#predict.CCmodel'><p>Predict Method for Classifier Chains</p></a></li>
<li><a href='#predict.CLRmodel'><p>Predict Method for CLR</p></a></li>
<li><a href='#predict.DBRmodel'><p>Predict Method for DBR</p></a></li>
<li><a href='#predict.EBRmodel'><p>Predict Method for Ensemble of Binary Relevance</p></a></li>
<li><a href='#predict.ECCmodel'><p>Predict Method for Ensemble of Classifier Chains</p></a></li>
<li><a href='#predict.EPSmodel'><p>Predict Method for Ensemble of Pruned Set Transformation</p></a></li>
<li><a href='#predict.ESLmodel'><p>Predict Method for Ensemble of Single Label</p></a></li>
<li><a href='#predict.HOMERmodel'><p>Predict Method for HOMER</p></a></li>
<li><a href='#predict.LIFTmodel'><p>Predict Method for LIFT</p></a></li>
<li><a href='#predict.LPmodel'><p>Predict Method for Label Powerset</p></a></li>
<li><a href='#predict.MBRmodel'><p>Predict Method for Meta-BR/2BR</p></a></li>
<li><a href='#predict.MLKNNmodel'><p>Predict Method for ML-KNN</p></a></li>
<li><a href='#predict.NSmodel'><p>Predict Method for Nested Stacking</p></a></li>
<li><a href='#predict.PPTmodel'><p>Predict Method for Pruned Problem Transformation</p></a></li>
<li><a href='#predict.PruDentmodel'><p>Predict Method for PruDent</p></a></li>
<li><a href='#predict.PSmodel'><p>Predict Method for Pruned Set Transformation</p></a></li>
<li><a href='#predict.RAkELmodel'><p>Predict Method for RAkEL</p></a></li>
<li><a href='#predict.RDBRmodel'><p>Predict Method for RDBR</p></a></li>
<li><a href='#predict.RPCmodel'><p>Predict Method for RPC</p></a></li>
<li><a href='#print.BRmodel'><p>Print BR model</p></a></li>
<li><a href='#print.BRPmodel'><p>Print BRP model</p></a></li>
<li><a href='#print.CCmodel'><p>Print CC model</p></a></li>
<li><a href='#print.CLRmodel'><p>Print CLR model</p></a></li>
<li><a href='#print.DBRmodel'><p>Print DBR model</p></a></li>
<li><a href='#print.EBRmodel'><p>Print EBR model</p></a></li>
<li><a href='#print.ECCmodel'><p>Print ECC model</p></a></li>
<li><a href='#print.EPSmodel'><p>Print EPS model</p></a></li>
<li><a href='#print.ESLmodel'><p>Print ESL model</p></a></li>
<li><a href='#print.kFoldPartition'><p>Print a kFoldPartition object</p></a></li>
<li><a href='#print.LIFTmodel'><p>Print LIFT model</p></a></li>
<li><a href='#print.LPmodel'><p>Print LP model</p></a></li>
<li><a href='#print.majorityModel'><p>Print Majority model</p></a></li>
<li><a href='#print.MBRmodel'><p>Print MBR model</p></a></li>
<li><a href='#print.mlconfmat'><p>Print a Multi-label Confusion Matrix</p></a></li>
<li><a href='#print.MLKNNmodel'><p>Print MLKNN model</p></a></li>
<li><a href='#print.mlresult'><p>Print the mlresult</p></a></li>
<li><a href='#print.NSmodel'><p>Print NS model</p></a></li>
<li><a href='#print.PPTmodel'><p>Print PPT model</p></a></li>
<li><a href='#print.PruDentmodel'><p>Print PruDent model</p></a></li>
<li><a href='#print.PSmodel'><p>Print PS model</p></a></li>
<li><a href='#print.RAkELmodel'><p>Print RAkEL model</p></a></li>
<li><a href='#print.randomModel'><p>Print Random model</p></a></li>
<li><a href='#print.RDBRmodel'><p>Print RDBR model</p></a></li>
<li><a href='#print.RPCmodel'><p>Print RPC model</p></a></li>
<li><a href='#prudent'><p>PruDent classifier for multi-label Classification</p></a></li>
<li><a href='#ps'><p>Pruned Set for multi-label Classification</p></a></li>
<li><a href='#rakel'><p>Random k-labelsets for multilabel classification</p></a></li>
<li><a href='#rcut_threshold'><p>Rank Cut (RCut) threshold method</p></a></li>
<li><a href='#rdbr'><p>Recursive Dependent Binary Relevance (RDBR) for multi-label Classification</p></a></li>
<li><a href='#remove_attributes'><p>Remove attributes from the dataset</p></a></li>
<li><a href='#remove_labels'><p>Remove labels from the dataset</p></a></li>
<li><a href='#remove_skewness_labels'><p>Remove unusual or very common labels</p></a></li>
<li><a href='#remove_unique_attributes'><p>Remove unique attributes</p></a></li>
<li><a href='#remove_unlabeled_instances'><p>Remove examples without labels</p></a></li>
<li><a href='#replace_nominal_attributes'><p>Replace nominal attributes</p>
Replace the nominal attributes by binary attributes.</a></li>
<li><a href='#rpc'><p>Ranking by Pairwise Comparison (RPC) for multi-label Classification</p></a></li>
<li><a href='#scut_threshold'><p>SCut Score-based method</p></a></li>
<li><a href='#subset_correction'><p>Subset Correction of a predicted result</p></a></li>
<li><a href='#summary.mltransformation'><p>Summary method for mltransformation</p></a></li>
<li><a href='#toyml'><p>Toy multi-label dataset.</p></a></li>
<li><a href='#utiml'><p>utiml: Utilities for Multi-Label Learning</p></a></li>
<li><a href='#utiml_measure_names'><p>Return the name of measures</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Utilities for Multi-Label Learning</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-05-26</td>
</tr>
<tr>
<td>Description:</td>
<td>Multi-label learning strategies and others procedures to support multi-
  label classification in R. The package provides a set of multi-label procedures such as
  sampling methods, transformation strategies, threshold functions, pre-processing 
  techniques and evaluation metrics. A complete overview of the matter can be seen in
  Zhang, M. and Zhou, Z. (2014) &lt;<a href="https://doi.org/10.1109%2FTKDE.2013.39">doi:10.1109/TKDE.2013.39</a>&gt; and Gibaja, E. and 
  Ventura, S. (2015) A Tutorial on Multi-label Learning.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/rivolli/utiml">https://github.com/rivolli/utiml</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), mldr(&ge; 0.4.0), parallel, ROCR</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, utils, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>C50, e1071, infotheo, kknn, knitr, randomForest, rmarkdown,
markdown, rpart, testthat, xgboost(&ge; 0.6-4)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/rivolli/utiml">https://github.com/rivolli/utiml</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-05-28 23:35:29 UTC; rivolli</td>
</tr>
<tr>
<td>Author:</td>
<td>Adriano Rivolli [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Adriano Rivolli &lt;rivolli@utfpr.edu.br&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-05-31 07:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='+5B.mlresult'>Filter a Multi-Label Result</h2><span id='topic++5B.mlresult'></span>

<h3>Description</h3>

<p>If column filter is performed, then the result will be a matrix. Otherwise,
the result will be a mlresult.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlresult'
mlresult[rowFilter = T, colFilter, ...]
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B5B.mlresult_+3A_mlresult">mlresult</code></td>
<td>
<p>A mlresult object</p>
</td></tr>
<tr><td><code id="+2B5B.mlresult_+3A_rowfilter">rowFilter</code></td>
<td>
<p>A list of rows to filter</p>
</td></tr>
<tr><td><code id="+2B5B.mlresult_+3A_colfilter">colFilter</code></td>
<td>
<p>A list of columns to filter</p>
</td></tr>
<tr><td><code id="+2B5B.mlresult_+3A_...">...</code></td>
<td>
<p>Extra parameters to be used as the filter</p>
</td></tr>
</table>


<h3>Value</h3>

<p>mlresult or matrix. If column filter is performed, then the result
will be a matrix. Otherwise, the result will be a mlresult.
</p>

<hr>
<h2 id='+2B.mlconfmat'>Join two multi-label confusion matrix</h2><span id='topic++2B.mlconfmat'></span>

<h3>Description</h3>

<p>Join two multi-label confusion matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlconfmat'
mlcm1 + mlcm2
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="+2B2B.mlconfmat_+3A_mlcm1">mlcm1</code></td>
<td>
<p>A mlconfmat</p>
</td></tr>
<tr><td><code id="+2B2B.mlconfmat_+3A_mlcm2">mlcm2</code></td>
<td>
<p>Other mlconfmat</p>
</td></tr>
</table>


<h3>Value</h3>

<p>mlconfmat
</p>

<hr>
<h2 id='as.bipartition'>Convert a mlresult to a bipartition matrix</h2><span id='topic+as.bipartition'></span>

<h3>Description</h3>

<p>Convert a mlresult to a bipartition matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.bipartition(mlresult)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.bipartition_+3A_mlresult">mlresult</code></td>
<td>
<p>The mlresult object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix with bipartition values
</p>

<hr>
<h2 id='as.matrix.mlconfmat'>Convert a multi-label Confusion Matrix to matrix</h2><span id='topic+as.matrix.mlconfmat'></span>

<h3>Description</h3>

<p>Convert a multi-label Confusion Matrix to matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlconfmat'
as.matrix(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.matrix.mlconfmat_+3A_x">x</code></td>
<td>
<p>The mlconfmat</p>
</td></tr>
<tr><td><code id="as.matrix.mlconfmat_+3A_...">...</code></td>
<td>
<p>passed to as.matrix</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A confusion matrix with TP, TN, FP and FN columns
</p>

<hr>
<h2 id='as.matrix.mlresult'>Convert a mlresult to matrix</h2><span id='topic+as.matrix.mlresult'></span>

<h3>Description</h3>

<p>Convert a mlresult to matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlresult'
as.matrix(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.matrix.mlresult_+3A_x">x</code></td>
<td>
<p>The mlresult object</p>
</td></tr>
<tr><td><code id="as.matrix.mlresult_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix
</p>

<hr>
<h2 id='as.mlresult'>Convert a matrix prediction in a multi label prediction</h2><span id='topic+as.mlresult'></span><span id='topic+as.mlresult.default'></span><span id='topic+as.mlresult.mlresult'></span>

<h3>Description</h3>

<p>Convert a matrix prediction in a multi label prediction
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.mlresult(predictions, probability = TRUE, ...)

## Default S3 method:
as.mlresult(predictions, probability = TRUE, ..., threshold = 0.5)

## S3 method for class 'mlresult'
as.mlresult(predictions, probability = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.mlresult_+3A_predictions">predictions</code></td>
<td>
<p>a Matrix or data.frame contained the scores/probabilities
values. The columns are the labels and the rows are the examples.</p>
</td></tr>
<tr><td><code id="as.mlresult_+3A_probability">probability</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values are
the score between 0 and 1, otherwise the values are bipartition 0 or 1.
(Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="as.mlresult_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
<tr><td><code id="as.mlresult_+3A_threshold">threshold</code></td>
<td>
<p>A single value between 0 and 1 or a list with threshold
values contained one value per label (Default: 0.5). Only used when the
predictions are not a mlresult.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default mlresult transform method
</p>
</li>
<li> <p><code>mlresult</code>: change the mlresult type
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>predictions &lt;- matrix(runif(100), ncol = 10)
colnames(predictions) &lt;- paste('label', 1:10, sep='')

# Create a mlresult from a matrix
mlresult &lt;- as.mlresult(predictions)
mlresult &lt;- as.mlresult(predictions, probability = FALSE)
mlresult &lt;- as.mlresult(predictions, probability = FALSE, threshold = 0.6)

# Change the current type of a mlresult
mlresult &lt;- as.mlresult(mlresult, probability = TRUE)
</code></pre>

<hr>
<h2 id='as.probability'>Convert a mlresult to a probability matrix</h2><span id='topic+as.probability'></span>

<h3>Description</h3>

<p>Convert a mlresult to a probability matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.probability(mlresult)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.probability_+3A_mlresult">mlresult</code></td>
<td>
<p>The mlresult object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix with probabilities values
</p>

<hr>
<h2 id='as.ranking'>Convert a mlresult to a ranking matrix</h2><span id='topic+as.ranking'></span>

<h3>Description</h3>

<p>Convert a mlresult to a ranking matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.ranking(mlresult, ties.method = "min", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="as.ranking_+3A_mlresult">mlresult</code></td>
<td>
<p>The mlresult object</p>
</td></tr>
<tr><td><code id="as.ranking_+3A_ties.method">ties.method</code></td>
<td>
<p>A character string specifying how ties are treated
(Default: &quot;min&quot;). see <code><a href="base.html#topic+rank">rank</a></code> to more details.</p>
</td></tr>
<tr><td><code id="as.ranking_+3A_...">...</code></td>
<td>
<p>Others parameters passed to the <code><a href="base.html#topic+rank">rank</a></code> method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>matrix with ranking values
</p>

<hr>
<h2 id='baseline'>Baseline reference for multilabel classification</h2><span id='topic+baseline'></span>

<h3>Description</h3>

<p>Create a baseline model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>baseline(
  mdata,
  metric = c("general", "F1", "hamming-loss", "subset-accuracy", "ranking-loss"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="baseline_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="baseline_+3A_metric">metric</code></td>
<td>
<p>Define the strategy used to predict the labels.
</p>
<p>The possible values are: <code>'general'</code>, <code>'F1'</code>,
<code>'hamming-loss'</code> or <code>'subset-accuracy'</code>. See the description
for more details. (Default: <code>'general'</code>).</p>
</td></tr>
<tr><td><code id="baseline_+3A_...">...</code></td>
<td>
<p>not used</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Baseline is a naive multi-label classifier that maximize/minimize a specific
measure without induces a learning model. It uses the general information
about the labels in training dataset to estimate the labels in a test
dataset.
</p>
<p>The follow strategies are available:
</p>

<dl>
<dt><code>general</code></dt><dd><p>Predict the k most frequent labels, where k is the
integer most close of label cardinality.</p>
</dd>
<dt><code>F1</code></dt><dd><p>Predict the most frequent labels that obtain the best F1
measure in training data. In the original paper, the authors use the less
frequent labels.</p>
</dd>
<dt><code>hamming-loss</code></dt><dd><p>Predict the labels that are associated with more
than 50% of instances.</p>
</dd>
<dt><code>subset-accuracy</code></dt><dd><p>Predict the most common labelset.</p>
</dd>
<dt><code>ranking-loss</code></dt><dd><p>Predict a ranking based on the most frequent
labels.</p>
</dd>
</dl>



<h3>Value</h3>

<p>An object of class <code>BASELINEmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>predict</dt><dd><p>A list with the labels that will be predicted.</p>
</dd>
</dl>



<h3>References</h3>

<p>Metz, J., Abreu, L. F. de, Cherman, E. A., &amp; Monard, M. C. (2012). On the
Estimation of Predictive Evaluation Measure Baselines for Multi-label
Learning. In 13th Ibero-American Conference on AI (pp. 189-198).
Cartagena de Indias, Colombia.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- baseline(toyml)
pred &lt;- predict(model, toyml)

## Change the metric
model &lt;- baseline(toyml, "F1")
model &lt;- baseline(toyml, "subset-accuracy")
</code></pre>

<hr>
<h2 id='br'>Binary Relevance for multi-label Classification</h2><span id='topic+br'></span>

<h3>Description</h3>

<p>Create a Binary Relevance model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>br(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="br_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="br_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="br_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems</p>
</td></tr>
<tr><td><code id="br_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="br_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Binary Relevance is a simple and effective transformation method to predict
multi-label data. This is based on the one-versus-all approach to build a
specific model for each label.
</p>


<h3>Value</h3>

<p>An object of class <code>BRmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>models</dt><dd><p>A list of the generated models, named by the label names.</p>
</dd>
</dl>



<h3>References</h3>

<p>Boutell, M. R., Luo, J., Shen, X., &amp; Brown, C. M. (2004). Learning
multi-label scene classification. Pattern Recognition, 37(9), 1757-1771.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- br(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use SVM as base algorithm
model &lt;- br(toyml, "SVM")
pred &lt;- predict(model, toyml)

# Change the base algorithm and use 2 CORES
model &lt;- br(toyml[1:50], 'RF', cores = 2, seed = 123)

# Set a parameters for all subproblems
model &lt;- br(toyml, 'KNN', k=5)

</code></pre>

<hr>
<h2 id='brplus'>BR+ or BRplus for multi-label Classification</h2><span id='topic+brplus'></span>

<h3>Description</h3>

<p>Create a BR+ classifier to predict multi-label data. This is a simple approach
that enables the binary classifiers to discover existing label dependency by
themselves. The main idea of BR+ is to increment the feature space of the
binary classifiers to let them discover existing label dependency by
themselves.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>brplus(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="brplus_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="brplus_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="brplus_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="brplus_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="brplus_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation has different strategy to predict the final set of labels
for unlabeled examples, as proposed in original paper.
</p>


<h3>Value</h3>

<p>An object of class <code>BRPmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>freq</dt><dd><p>The label frequencies to use with the 'Stat' strategy</p>
</dd>
<dt>initial</dt><dd><p>The BR model to predict the values for the labels to
initial step</p>
</dd>
<dt>models</dt><dd><p>A list of final models named by the label names.</p>
</dd>
</dl>



<h3>References</h3>

<p>Cherman, E. A., Metz, J., &amp; Monard, M. C. (2012). Incorporating label
dependency into the binary relevance framework for multi-label
classification. Expert Systems with Applications, 39(2), 1647-1655.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Stacking methods: 
<code><a href="#topic+mbr">mbr</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use SVM as base algorithm
model &lt;- brplus(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use Random Forest as base algorithm and 2 cores
model &lt;- brplus(toyml, 'RF', cores = 2, seed = 123)

</code></pre>

<hr>
<h2 id='cc'>Classifier Chains for multi-label Classification</h2><span id='topic+cc'></span>

<h3>Description</h3>

<p>Create a Classifier Chains model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cc(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  chain = NA,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cc_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="cc_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="cc_+3A_chain">chain</code></td>
<td>
<p>A vector with the label names to define the chain order. If
empty the chain is the default label sequence of the dataset. (Default:
<code>NA</code>)</p>
</td></tr>
<tr><td><code id="cc_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="cc_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="cc_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Classifier Chains is a Binary Relevance transformation method based to
predict multi-label data. This is based on the one-versus-all approach to
build a specific model for each label. It is different from BR method due the
strategy of extended the attribute space with the 0/1 label relevances of all
previous classifiers, forming a classifier chain.
</p>


<h3>Value</h3>

<p>An object of class <code>CCmodel</code> containing the set of fitted
models, including: </p>

<dl>
<dt>chain</dt><dd><p>A vector with the chain order.</p>
</dd>
<dt>labels</dt><dd><p>A vector with the label names in expected order.</p>
</dd>
<dt>models</dt><dd><p>A list of models named by the label names.</p>
</dd>
</dl>



<h3>References</h3>

<p>Read, J., Pfahringer, B., Holmes, G., &amp; Frank, E. (2011). Classifier chains
for multi-label classification. Machine Learning, 85(3), 333-359.
</p>
<p>Read, J., Pfahringer, B., Holmes, G., &amp; Frank, E. (2009). Classifier Chains
for Multi-label Classification. Machine Learning and Knowledge Discovery
in Databases, Lecture Notes in Computer Science, 5782, 254-269.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- cc(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use a specific chain with C5.0 classifier
mychain &lt;- sample(rownames(toyml$labels))
model &lt;- cc(toyml, 'C5.0', mychain)

# Set a specific parameter
model &lt;- cc(toyml, 'KNN', k=5)

#Run with multiple-cores
model &lt;- cc(toyml, 'RF', cores = 2, seed = 123)

</code></pre>

<hr>
<h2 id='clr'>Calibrated Label Ranking (CLR) for multi-label Classification</h2><span id='topic+clr'></span>

<h3>Description</h3>

<p>Create a CLR model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clr(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clr_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="clr_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="clr_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems</p>
</td></tr>
<tr><td><code id="clr_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="clr_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>CLR is an extension of label ranking that incorporates the calibrated
scenario. The introduction of an artificial calibration label,
separates the relevant from the irrelevant labels.
</p>


<h3>Value</h3>

<p>An object of class <code>RPCmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>rpcmodel</dt><dd><p>A RPC model.</p>
</dd>
<dt>brmodel</dt><dd><p>A BR model used to calibrated the labels.</p>
</dd>
</dl>



<h3>References</h3>

<p>Brinker, K., Furnkranz, J., &amp; Hullermeier, E. (2006). A unified model for
multilabel classification and ranking. In Proceeding of the ECAI 2006:
17th European Conference on Artificial Intelligence. p. 489-493.
Furnkranz, J., Hullermeier, E., Loza Mencia, E., &amp; Brinker, K. (2008).
Multilabel classification via calibrated label ranking.
Machine Learning, 73(2), 133-153.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Pairwise methods: 
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- clr(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='compute_multilabel_predictions'>Compute the multi-label ensemble predictions based on some vote schema</h2><span id='topic+compute_multilabel_predictions'></span>

<h3>Description</h3>

<p>Compute the multi-label ensemble predictions based on some vote schema
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compute_multilabel_predictions(
  predictions,
  vote.schema = "maj",
  probability = getOption("utiml.use.probs", TRUE)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="compute_multilabel_predictions_+3A_predictions">predictions</code></td>
<td>
<p>A list of multi-label predictions (mlresult).</p>
</td></tr>
<tr><td><code id="compute_multilabel_predictions_+3A_vote.schema">vote.schema</code></td>
<td>
<p>Define the way that ensemble must compute the predictions.
The default valid options are:
</p>

<dl>
<dt>'avg'</dt><dd><p>Compute the mean of probabilities and the bipartitions</p>
</dd>
<dt>'maj'</dt><dd><p>Compute the majority of votes</p>
</dd>
<dt>'max'</dt><dd><p>Compute the higher probability for each instance/label</p>
</dd>
<dt>'min'</dt><dd><p>Compute the lower probability for each instance/label</p>
</dd>
</dl>
<p>. (Default: 'maj')</p>
</td></tr>
<tr><td><code id="compute_multilabel_predictions_+3A_probability">probability</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values are
the score between 0 and 1, otherwise the values are bipartition 0 or 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A mlresult with computed predictions.
</p>


<h3>Note</h3>

<p>You can create your own vote schema, just create a method that receive
two matrix (bipartitions and probabilities) and return a list with the
final bipartitions and probabilities.
</p>
<p>Remember that this method will compute the ensemble votes for each label.
Thus the bipartition and probability matrix passed as argument for this
method is related with the bipartitions and probabilities for a single
label.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
model &lt;- br(toyml, "KNN")
predictions &lt;- list(
 predict(model, toyml[1:10], k=1),
 predict(model, toyml[1:10], k=3),
 predict(model, toyml[1:10], k=5)
)

result &lt;- compute_multilabel_predictions(predictions, "maj")

## Random choice
random_choice &lt;- function (bipartition, probability) {
 cols &lt;- sample(seq(ncol(bipartition)), nrow(bipartition), replace = TRUE)
 list(
   bipartition = bipartition[cbind(seq(nrow(bipartition)), cols)],
   probability = probability[cbind(seq(nrow(probability)), cols)]
 )
}
result &lt;- compute_multilabel_predictions(predictions, "random_choice")

</code></pre>

<hr>
<h2 id='create_holdout_partition'>Create a holdout partition based on the specified algorithm</h2><span id='topic+create_holdout_partition'></span>

<h3>Description</h3>

<p>This method creates multi-label dataset for train, test, validation or other
proposes the partition method defined in <code>method</code>. The number of
partitions is defined in <code>partitions</code> parameter. Each instance is used
in only one partition of division.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_holdout_partition(
  mdata,
  partitions = c(train = 0.7, test = 0.3),
  method = c("random", "iterative", "stratified")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_holdout_partition_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset.</p>
</td></tr>
<tr><td><code id="create_holdout_partition_+3A_partitions">partitions</code></td>
<td>
<p>A list of percentages or a single value. The sum of all
values does not be greater than 1. If a single value is informed then the
complement of them is applied to generated the second partition. If two or
more values are informed and the sum of them is lower than 1 the partitions
will be generated with the informed proportion. If partitions have names,
they are used to name the return. (Default: <code>c(train=0.7, test=0.3)</code>).</p>
</td></tr>
<tr><td><code id="create_holdout_partition_+3A_method">method</code></td>
<td>
<p>The method to split the data. The default methods are:
</p>

<dl>
<dt>random</dt><dd><p>Split randomly the folds.</p>
</dd>
<dt>iterative</dt><dd><p>Split the folds considering the labels proportions
individually. Some specific label can not occurs in all
folds.</p>
</dd>
<dt>stratified</dt><dd><p>Split the folds considering the labelset proportions.</p>
</dd>
</dl>

<p>You can also create your own partition method. See the note and example
sections to more details. (Default: &quot;random&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with at least two datasets sampled as specified in partitions
parameter.
</p>


<h3>Note</h3>

<p>To create your own split method, you need to build a function that
receive a mldr object and a list with the proportions of examples in each
fold and return an other list with the index of the elements for each fold.
</p>


<h3>References</h3>

<p>Sechidis, K., Tsoumakas, G., &amp; Vlahavas, I. (2011). On the
stratification of multi-label data. In Proceedings of the Machine
Learning and Knowledge Discovery in Databases - European Conference,
ECML PKDD (pp. 145-158).
</p>


<h3>See Also</h3>

<p>Other sampling: 
<code><a href="#topic+create_kfold_partition">create_kfold_partition</a>()</code>,
<code><a href="#topic+create_random_subset">create_random_subset</a>()</code>,
<code><a href="#topic+create_subset">create_subset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dataset &lt;- create_holdout_partition(toyml)
names(dataset)
## [1] "train" "test"
#dataset$train
#dataset$test

dataset &lt;- create_holdout_partition(toyml, c(a=0.1, b=0.2, c=0.3, d=0.4))
#' names(dataset)
#' ## [1] "a" "b" "c" "d"

sequencial_split &lt;- function (mdata, r) {
 S &lt;- list()

 amount &lt;- trunc(r * mdata$measures$num.instances)
 indexes &lt;- c(0, cumsum(amount))
 indexes[length(r)+1] &lt;- mdata$measures$num.instances

 S &lt;- lapply(seq(length(r)), function (i) {
   seq(indexes[i]+1, indexes[i+1])
 })

 S
}
dataset &lt;- create_holdout_partition(toyml, method="sequencial_split")
</code></pre>

<hr>
<h2 id='create_kfold_partition'>Create the k-folds partition based on the specified algorithm</h2><span id='topic+create_kfold_partition'></span>

<h3>Description</h3>

<p>This method create the kFoldPartition object, from it is possible create
the dataset partitions to train, test and optionally to validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_kfold_partition(
  mdata,
  k = 10,
  method = c("random", "iterative", "stratified")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_kfold_partition_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset.</p>
</td></tr>
<tr><td><code id="create_kfold_partition_+3A_k">k</code></td>
<td>
<p>The number of desirable folds. (Default: 10)</p>
</td></tr>
<tr><td><code id="create_kfold_partition_+3A_method">method</code></td>
<td>
<p>The method to split the data. The default methods are:
</p>

<dl>
<dt>random</dt><dd><p>Split randomly the folds.</p>
</dd>
<dt>iterative</dt><dd><p>Split the folds considering the labels proportions
individually. Some specific label can not occurs in all
folds.</p>
</dd>
<dt>stratified</dt><dd><p>Split the folds considering the labelset
proportions.</p>
</dd>
</dl>

<p>You can also create your own partition method. See the note and example
sections to more details. (Default: &quot;random&quot;)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type kFoldPartition.
</p>


<h3>Note</h3>

<p>To create your own split method, you need to build a function that
receive a mldr object and a list with the proportions of examples in each
fold and return an other list with the index of the elements for each fold.
</p>


<h3>References</h3>

<p>Sechidis, K., Tsoumakas, G., &amp; Vlahavas, I. (2011). On the
stratification of multi-label data. In Proceedings of the Machine
Learning and Knowledge Discovery in Databases - European Conference,
ECML PKDD (pp. 145-158).
</p>


<h3>See Also</h3>

<p><a href="#topic+partition_fold">How to create the datasets from folds</a>
</p>
<p>Other sampling: 
<code><a href="#topic+create_holdout_partition">create_holdout_partition</a>()</code>,
<code><a href="#topic+create_random_subset">create_random_subset</a>()</code>,
<code><a href="#topic+create_subset">create_subset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>k10 &lt;- create_kfold_partition(toyml, 10)
k5 &lt;- create_kfold_partition(toyml, 5, "stratified")

sequencial_split &lt;- function (mdata, r) {
 S &lt;- list()

 amount &lt;- trunc(r * mdata$measures$num.instances)
 indexes &lt;- c(0, cumsum(amount))
 indexes[length(r)+1] &lt;- mdata$measures$num.instances

 S &lt;- lapply(seq(length(r)), function (i) {
   seq(indexes[i]+1, indexes[i+1])
 })

 S
}
k3 &lt;- create_kfold_partition(toyml, 3, "sequencial_split")
</code></pre>

<hr>
<h2 id='create_random_subset'>Create a random subset of a dataset</h2><span id='topic+create_random_subset'></span>

<h3>Description</h3>

<p>Create a random subset of a dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_random_subset(
  mdata,
  instances,
  attributes = mdata$measures$num.inputs,
  replacement = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_random_subset_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset</p>
</td></tr>
<tr><td><code id="create_random_subset_+3A_instances">instances</code></td>
<td>
<p>The number of expected instances</p>
</td></tr>
<tr><td><code id="create_random_subset_+3A_attributes">attributes</code></td>
<td>
<p>The number of expected attributes.
(Default: all attributes)</p>
</td></tr>
<tr><td><code id="create_random_subset_+3A_replacement">replacement</code></td>
<td>
<p>A boolean value to define sample with replacement or not.
(Default: FALSE)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A new mldr subset
</p>


<h3>See Also</h3>

<p>Other sampling: 
<code><a href="#topic+create_holdout_partition">create_holdout_partition</a>()</code>,
<code><a href="#topic+create_kfold_partition">create_kfold_partition</a>()</code>,
<code><a href="#topic+create_subset">create_subset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>small.toy &lt;- create_random_subset(toyml, 10, 3)
medium.toy &lt;- create_random_subset(toyml, 50, 5)
</code></pre>

<hr>
<h2 id='create_subset'>Create a subset of a dataset</h2><span id='topic+create_subset'></span>

<h3>Description</h3>

<p>Create a subset of a dataset
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_subset(mdata, rows, cols = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_subset_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset</p>
</td></tr>
<tr><td><code id="create_subset_+3A_rows">rows</code></td>
<td>
<p>A vector with the instances indexes (names or indexes).</p>
</td></tr>
<tr><td><code id="create_subset_+3A_cols">cols</code></td>
<td>
<p>A vector with the attributes indexes (names or indexes).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A new mldr subset
</p>


<h3>Note</h3>

<p>It is not necessary specify the labels attributes because they are
included by default.
</p>


<h3>See Also</h3>

<p>Other sampling: 
<code><a href="#topic+create_holdout_partition">create_holdout_partition</a>()</code>,
<code><a href="#topic+create_kfold_partition">create_kfold_partition</a>()</code>,
<code><a href="#topic+create_random_subset">create_random_subset</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Create a dataset with the 20 first examples and the 7 first attributes
small.toy &lt;- create_subset(toyml, seq(20), seq(7))

## Create a random dataset with 50 examples and 5 attributes
random.toy &lt;- create_subset(toyml, sample(100, 50), sample(10, 5))
</code></pre>

<hr>
<h2 id='cv'>Multi-label cross-validation</h2><span id='topic+cv'></span>

<h3>Description</h3>

<p>Perform the cross validation procedure for multi-label learning.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv(
  mdata,
  method,
  ...,
  cv.folds = 10,
  cv.sampling = c("random", "iterative", "stratified"),
  cv.results = FALSE,
  cv.predictions = FALSE,
  cv.measures = "all",
  cv.cores = getOption("utiml.cores", 1),
  cv.seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cv_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset.</p>
</td></tr>
<tr><td><code id="cv_+3A_method">method</code></td>
<td>
<p>The multi-label classification method. It also accepts the name
of the method as a string.</p>
</td></tr>
<tr><td><code id="cv_+3A_...">...</code></td>
<td>
<p>Additional parameters required by the method.</p>
</td></tr>
<tr><td><code id="cv_+3A_cv.folds">cv.folds</code></td>
<td>
<p>Number of folds. (Default: 10)</p>
</td></tr>
<tr><td><code id="cv_+3A_cv.sampling">cv.sampling</code></td>
<td>
<p>The method to split the data. The default methods are:
</p>

<dl>
<dt>random</dt><dd><p>Split randomly the folds.</p>
</dd>
<dt>iterative</dt><dd><p>Split the folds considering the labels proportions
individually. Some specific label can not occurs in all
folds.</p>
</dd>
<dt>stratified</dt><dd><p>Split the folds considering the labelset proportions.</p>
</dd>
</dl>

<p>(Default: &quot;random&quot;)</p>
</td></tr>
<tr><td><code id="cv_+3A_cv.results">cv.results</code></td>
<td>
<p>Logical value indicating if the folds results should be
reported (Default: FALSE).</p>
</td></tr>
<tr><td><code id="cv_+3A_cv.predictions">cv.predictions</code></td>
<td>
<p>Logical value indicating if the predictions should be
reported (Default: FALSE).</p>
</td></tr>
<tr><td><code id="cv_+3A_cv.measures">cv.measures</code></td>
<td>
<p>The measures names to be computed. Call
<code>multilabel_measures()</code> to see the expected measures. You can also
use <code>"bipartition"</code>, <code>"ranking"</code>, <code>"label-based"</code>,
<code>"example-based"</code>, <code>"macro-based"</code>, <code>"micro-based"</code> and
<code>"label-problem"</code> to include a set of measures. (Default: &quot;all&quot;).</p>
</td></tr>
<tr><td><code id="cv_+3A_cv.cores">cv.cores</code></td>
<td>
<p>The number of cores to parallelize the cross validation
procedure. (Default: <code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="cv_+3A_cv.seed">cv.seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If cv.results and cv.prediction are FALSE, the return is a vector
with the expected multi-label measures, otherwise, a list contained the
multi-label and the other expected results (the label measures and/or the
prediction object) for each fold.
</p>


<h3>See Also</h3>

<p>Other evaluation: 
<code><a href="#topic+multilabel_confusion_matrix">multilabel_confusion_matrix</a>()</code>,
<code><a href="#topic+multilabel_evaluate">multilabel_evaluate</a>()</code>,
<code><a href="#topic+multilabel_measures">multilabel_measures</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#Run 10 folds for BR method
res1 &lt;- cv(toyml, br, base.algorithm="RANDOM", cv.folds=10)

#Run 3 folds for RAkEL method and get the fold results and the prediction
res2 &lt;- cv(mdata=toyml, method="rakel", base.algorithm="RANDOM", k=2, m=10,
 cv.folds=3, cv.results=TRUE, cv.predictions=TRUE)
</code></pre>

<hr>
<h2 id='dbr'>Dependent Binary Relevance (DBR) for multi-label Classification</h2><span id='topic+dbr'></span>

<h3>Description</h3>

<p>Create a DBR classifier to predict multi-label data. This is a simple approach
that enables the binary classifiers to discover existing label dependency by
themselves. The idea of DBR is exactly the same used in BR+ (the training
method is the same, excepted by the argument <code>estimate.models</code> that
indicate if the estimated models must be created).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dbr(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  estimate.models = TRUE,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="dbr_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="dbr_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="dbr_+3A_estimate.models">estimate.models</code></td>
<td>
<p>Logical value indicating whether is necessary build
Binary Relevance classifier for estimate process. The default implementation
use BR as estimators, however when other classifier is desirable then use
the value <code>FALSE</code> to skip this process. (Default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="dbr_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="dbr_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="dbr_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>DBRmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>estimation</dt><dd><p>The BR model to estimate the values for the labels.
Only when the <code>estimate.models = TRUE</code>.</p>
</dd>
<dt>models</dt><dd><p>A list of final models named by the label names.</p>
</dd>
</dl>



<h3>References</h3>

<p>Montanes, E., Senge, R., Barranquero, J., Ramon Quevedo, J., Jose Del Coz,
J., &amp; Hullermeier, E. (2014). Dependent binary relevance models for
multi-label classification. Pattern Recognition, 47(3), 1494-1508.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rdbr">Recursive Dependent Binary Relevance</a></code>
</p>
<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- dbr(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use Random Forest as base algorithm and 2 cores
model &lt;- dbr(toyml, 'RF', cores = 2)

</code></pre>

<hr>
<h2 id='ebr'>Ensemble of Binary Relevance for multi-label Classification</h2><span id='topic+ebr'></span>

<h3>Description</h3>

<p>Create an Ensemble of Binary Relevance model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ebr(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  m = 10,
  subsample = 0.75,
  attr.space = 0.5,
  replacement = TRUE,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ebr_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="ebr_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="ebr_+3A_m">m</code></td>
<td>
<p>The number of Binary Relevance models used in the ensemble.
(Default: 10)</p>
</td></tr>
<tr><td><code id="ebr_+3A_subsample">subsample</code></td>
<td>
<p>A value between 0.1 and 1 to determine the percentage of
training instances that must be used for each classifier. (Default: 0.75)</p>
</td></tr>
<tr><td><code id="ebr_+3A_attr.space">attr.space</code></td>
<td>
<p>A value between 0.1 and 1 to determine the percentage of
attributes that must be used for each classifier. (Default: 0.50)</p>
</td></tr>
<tr><td><code id="ebr_+3A_replacement">replacement</code></td>
<td>
<p>Boolean value to define if use sampling with replacement
to create the data of the models of the ensemble. (Default: TRUE)</p>
</td></tr>
<tr><td><code id="ebr_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="ebr_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="ebr_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This model is composed by a set of Binary Relevance models. Binary Relevance
is a simple and effective transformation method to predict multi-label data.
</p>


<h3>Value</h3>

<p>An object of class <code>EBRmodel</code> containing the set of fitted
BR models, including:
</p>

<dl>
<dt>models</dt><dd><p>A list of BR models.</p>
</dd>
<dt>nrow</dt><dd><p>The number of instances used in each training dataset.</p>
</dd>
<dt>ncol</dt><dd><p>The number of attributes used in each training dataset.</p>
</dd>
<dt>rounds</dt><dd><p>The number of interactions.</p>
</dd>
</dl>



<h3>Note</h3>

<p>If you want to reproduce the same classification and obtain the same
result will be necessary set a flag utiml.mc.set.seed to FALSE.
</p>


<h3>References</h3>

<p>Read, J., Pfahringer, B., Holmes, G., &amp; Frank, E. (2011). Classifier
chains for multi-label classification. Machine Learning, 85(3), 333-359.
</p>
<p>Read, J., Pfahringer, B., Holmes, G., &amp; Frank, E. (2009).
Classifier Chains for Multi-label Classification. Machine Learning and
Knowledge Discovery in Databases, Lecture Notes in Computer Science,
5782, 254-269.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Ensemble methods: 
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- ebr(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use C5.0 with 90% of instances and only 5 rounds
model &lt;- ebr(toyml, 'C5.0', m = 5, subsample = 0.9)

# Use 75% of attributes
model &lt;- ebr(toyml, attr.space = 0.75)

# Running in 2 cores and define a specific seed
model1 &lt;- ebr(toyml, cores=2, seed = 312)

</code></pre>

<hr>
<h2 id='ecc'>Ensemble of Classifier Chains for multi-label Classification</h2><span id='topic+ecc'></span>

<h3>Description</h3>

<p>Create an Ensemble of Classifier Chains model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecc(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  m = 10,
  subsample = 0.75,
  attr.space = 0.5,
  replacement = TRUE,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecc_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="ecc_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="ecc_+3A_m">m</code></td>
<td>
<p>The number of Classifier Chains models used in the ensemble.
(Default: 10)</p>
</td></tr>
<tr><td><code id="ecc_+3A_subsample">subsample</code></td>
<td>
<p>A value between 0.1 and 1 to determine the percentage of
training instances that must be used for each classifier. (Default: 0.75)</p>
</td></tr>
<tr><td><code id="ecc_+3A_attr.space">attr.space</code></td>
<td>
<p>A value between 0.1 and 1 to determine the percentage of
attributes that must be used for each classifier. (Default: 0.50)</p>
</td></tr>
<tr><td><code id="ecc_+3A_replacement">replacement</code></td>
<td>
<p>Boolean value to define if use sampling with replacement
to create the data of the models of the ensemble. (Default: TRUE)</p>
</td></tr>
<tr><td><code id="ecc_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="ecc_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="ecc_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This model is composed by a set of Classifier Chains models. Classifier
Chains is a Binary Relevance transformation method based to predict
multi-label data. It is different from BR method due the strategy of extended
the attribute space with the 0/1 label relevances of all previous
classifiers, forming a classifier chain.
</p>


<h3>Value</h3>

<p>An object of class <code>ECCmodel</code> containing the set of fitted
CC models, including:
</p>

<dl>
<dt>rounds</dt><dd><p>The number of interactions</p>
</dd>
<dt>models</dt><dd><p>A list of BR models.</p>
</dd>
<dt>nrow</dt><dd><p>The number of instances used in each training dataset</p>
</dd>
<dt>ncol</dt><dd><p>The number of attributes used in each training dataset</p>
</dd>
</dl>



<h3>Note</h3>

<p>If you want to reproduce the same classification and obtain the same
result will be necessary set a flag utiml.mc.set.seed to FALSE.
</p>


<h3>References</h3>

<p>Read, J., Pfahringer, B., Holmes, G., &amp; Frank, E. (2011). Classifier
chains for multi-label classification. Machine Learning, 85(3), 333-359.
</p>
<p>Read, J., Pfahringer, B., Holmes, G., &amp; Frank, E. (2009).
Classifier Chains for Multi-label Classification. Machine Learning and
Knowledge Discovery in Databases, Lecture Notes in Computer Science,
5782, 254-269.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Ensemble methods: 
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Use all default values
model &lt;- ecc(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use C5.0 with 100% of instances and only 5 rounds
model &lt;- ecc(toyml, 'C5.0', m = 5, subsample = 1)

# Use 75% of attributes
model &lt;- ecc(toyml, attr.space = 0.75)

# Running in 2 cores and define a specific seed
model1 &lt;- ecc(toyml, cores=2, seed=123)

</code></pre>

<hr>
<h2 id='eps'>Ensemble of Pruned Set for multi-label Classification</h2><span id='topic+eps'></span>

<h3>Description</h3>

<p>Create an Ensemble of Pruned Set model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>eps(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  m = 10,
  subsample = 0.75,
  p = 3,
  strategy = c("A", "B"),
  b = 2,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="eps_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="eps_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="eps_+3A_m">m</code></td>
<td>
<p>The number of Pruned Set models used in the ensemble.</p>
</td></tr>
<tr><td><code id="eps_+3A_subsample">subsample</code></td>
<td>
<p>A value between 0.1 and 1 to determine the percentage of
training instances that must be used for each classifier. (Default: 0.63)</p>
</td></tr>
<tr><td><code id="eps_+3A_p">p</code></td>
<td>
<p>Number of instances to prune. All labelsets that occurs p times or
less in the training data is removed. (Default: 3)</p>
</td></tr>
<tr><td><code id="eps_+3A_strategy">strategy</code></td>
<td>
<p>The strategy  (A or B) for processing infrequent labelsets.
(Default: A).</p>
</td></tr>
<tr><td><code id="eps_+3A_b">b</code></td>
<td>
<p>The number used by the strategy for processing infrequent labelsets.</p>
</td></tr>
<tr><td><code id="eps_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="eps_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="eps_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pruned Set (PS) is a multi-class transformation that remove the less common
classes to predict multi-label data. The ensemble is created with different
subsets of the original multi-label data.
</p>


<h3>Value</h3>

<p>An object of class <code>EPSmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>rounds</dt><dd><p>The number of interactions</p>
</dd>
<dt>models</dt><dd><p>A list of PS models.</p>
</dd>
</dl>



<h3>References</h3>

<p>Read, J. (2008). A pruned problem transformation method for multi-label
classification. In Proceedings of the New Zealand Computer Science Research
Student Conference (pp. 143-150).
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Powerset: 
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>
</p>
<p>Other Ensemble methods: 
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- eps(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


##Change default configurations
model &lt;- eps(toyml, "RF", m=15, subsample=0.4, p=4, strategy="B", b=1)

</code></pre>

<hr>
<h2 id='esl'>Ensemble of Single Label</h2><span id='topic+esl'></span>

<h3>Description</h3>

<p>Create an Ensemble of Single Label model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>esl(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  m = 10,
  w = 1,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="esl_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="esl_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="esl_+3A_m">m</code></td>
<td>
<p>The number of members used in the ensemble. (Default: 10)</p>
</td></tr>
<tr><td><code id="esl_+3A_w">w</code></td>
<td>
<p>The weight given to the choice of the less frequent labels. When it
is 0, the labels will be random choose, when it is 1 the complement of the
label frequency is used as the probability to choose each label. Values
greater than 1 will privilege the less frequent labels. (Default: 1)</p>
</td></tr>
<tr><td><code id="esl_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems</p>
</td></tr>
<tr><td><code id="esl_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="esl_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ESL is an ensemble of multi-class model that uses the less frequent labels.
This is based on the label ignore approach different members of the ensemble.
</p>


<h3>Value</h3>

<p>An object of class <code>ESLmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the labels' frequencies.</p>
</dd>
<dt>models</dt><dd><p>A list of the multi-class models.</p>
</dd>
</dl>



<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- esl(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use SVM as base algorithm
model &lt;- esl(toyml, "SVM")
pred &lt;- predict(model, toyml)

# Change the base algorithm and use 2 CORES
model &lt;- esl(toyml[1:50], 'RF', cores = 2, seed = 123)

# Set a parameters for all subproblems
model &lt;- esl(toyml, 'KNN', k=5)

</code></pre>

<hr>
<h2 id='fill_sparse_mldata'>Fill sparse dataset with 0 or &rdquo; values</h2><span id='topic+fill_sparse_mldata'></span>

<h3>Description</h3>

<p>Transform a sparse dataset filling NA values to 0 or &rdquo; based on the column
type. Text columns with numeric values will be modified to numerical.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fill_sparse_mldata(mdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fill_sparse_mldata_+3A_mdata">mdata</code></td>
<td>
<p>The mldr dataset to be filled.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new mldr object.
</p>


<h3>See Also</h3>

<p>Other pre process: 
<code><a href="#topic+normalize_mldata">normalize_mldata</a>()</code>,
<code><a href="#topic+remove_attributes">remove_attributes</a>()</code>,
<code><a href="#topic+remove_labels">remove_labels</a>()</code>,
<code><a href="#topic+remove_skewness_labels">remove_skewness_labels</a>()</code>,
<code><a href="#topic+remove_unique_attributes">remove_unique_attributes</a>()</code>,
<code><a href="#topic+remove_unlabeled_instances">remove_unlabeled_instances</a>()</code>,
<code><a href="#topic+replace_nominal_attributes">replace_nominal_attributes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>sparse.toy &lt;- toyml
sparse.toy$dataset$ratt10[sample(100, 30)] &lt;- NA
complete.toy &lt;- fill_sparse_mldata(sparse.toy)
</code></pre>

<hr>
<h2 id='fixed_threshold'>Apply a fixed threshold in the results</h2><span id='topic+fixed_threshold'></span><span id='topic+fixed_threshold.default'></span><span id='topic+fixed_threshold.mlresult'></span>

<h3>Description</h3>

<p>Transform a prediction matrix with scores/probabilities in a mlresult
applying a fixed threshold. A global fixed threshold can be used of all
labels or different fixed thresholds, one for each label.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fixed_threshold(prediction, threshold = 0.5, probability = FALSE)

## Default S3 method:
fixed_threshold(prediction, threshold = 0.5, probability = FALSE)

## S3 method for class 'mlresult'
fixed_threshold(prediction, threshold = 0.5, probability = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fixed_threshold_+3A_prediction">prediction</code></td>
<td>
<p>A matrix with scores/probabilities where the columns
are the labels and the rows are the instances.</p>
</td></tr>
<tr><td><code id="fixed_threshold_+3A_threshold">threshold</code></td>
<td>
<p>A single value between 0 and 1 or a list with threshold
values contained one value per label.</p>
</td></tr>
<tr><td><code id="fixed_threshold_+3A_probability">probability</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values are
the score between 0 and 1, otherwise the values are bipartition 0 or 1.
(Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A mlresult object.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Fixed Threshold for matrix or data.frame
</p>
</li>
<li> <p><code>mlresult</code>: Fixed Threshold for mlresult
</p>
</li></ul>


<h3>References</h3>

<p>Al-Otaibi, R., Flach, P., &amp; Kull, M. (2014). Multi-label Classification: A
Comparative Study on Threshold Selection Methods. In First International
Workshop on Learning over Multiple Contexts (LMCE) at ECML-PKDD 2014.
</p>


<h3>See Also</h3>

<p>Other threshold: 
<code><a href="#topic+lcard_threshold">lcard_threshold</a>()</code>,
<code><a href="#topic+mcut_threshold">mcut_threshold</a>()</code>,
<code><a href="#topic+pcut_threshold">pcut_threshold</a>()</code>,
<code><a href="#topic+rcut_threshold">rcut_threshold</a>()</code>,
<code><a href="#topic+scut_threshold">scut_threshold</a>()</code>,
<code><a href="#topic+subset_correction">subset_correction</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a prediction matrix with scores
result &lt;- matrix(
 data = rnorm(9, 0.5, 0.2),
 ncol = 3,
 dimnames = list(NULL, c('lbl1',  'lb2', 'lb3'))
)

# Use 0.5 as threshold
fixed_threshold(result)

# Use an threshold for each label
fixed_threshold(result, c(0.4, 0.6, 0.7))
</code></pre>

<hr>
<h2 id='foodtruck'>Foodtruck multi-label dataset.</h2><span id='topic+foodtruck'></span>

<h3>Description</h3>

<p>The foodtruck multi-label dataset is a real multi-label dataset, which uses
habits and personal information to predict food truck cuisines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>foodtruck
</code></pre>


<h3>Format</h3>

<p>A mldr object with 407 instances, 21 features and 12 labels:
</p>


<h3>Details</h3>

<p>General Information
</p>

<ul>
<li><p> Cardinality: 2.28
</p>
</li>
<li><p> Density: 0.19
</p>
</li>
<li><p> Distinct multi-labels: 117
</p>
</li>
<li><p> Number of single labelsets: 74
</p>
</li>
<li><p> Max frequency: 114
</p>
</li></ul>



<h3>Source</h3>

<p>The dataset is described in:
Rivolli A., Parker L.C., de Carvalho A.C.P.L.F. (2017) Food Truck
Recommendation Using Multi-label Classification. In: Oliveira E., Gama J.,
Vale Z., Lopes Cardoso H. (eds) Progress in Artificial Intelligence. EPIA
2017. Lecture Notes in Computer Science, vol 10423. Springer, Cham
</p>

<hr>
<h2 id='homer'>Hierarchy Of Multilabel classifiER (HOMER)</h2><span id='topic+homer'></span>

<h3>Description</h3>

<p>Create a Hierarchy Of Multilabel classifiER (HOMER).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>homer(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  clusters = 3,
  method = c("balanced", "clustering", "random"),
  iteration = 100,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="homer_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="homer_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="homer_+3A_clusters">clusters</code></td>
<td>
<p>Number maximum of nodes in each level. (Default: 3)</p>
</td></tr>
<tr><td><code id="homer_+3A_method">method</code></td>
<td>
<p>The strategy used to organize the labels (create the
meta-labels). The options are: &quot;balanced&quot;, &quot;clustering&quot; and &quot;random&quot;.
(Default: &quot;balanced&quot;).</p>
</td></tr>
<tr><td><code id="homer_+3A_iteration">iteration</code></td>
<td>
<p>The number max of iterations, used by balanced or clustering
methods.</p>
</td></tr>
<tr><td><code id="homer_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="homer_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="homer_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>HOMER is an algorithm for effective and computationally efficient multilabel
classification in domains with many labels. It constructs a hierarchy of
multilabel classifiers, each one dealing with a much smaller set of labels.
</p>


<h3>Value</h3>

<p>An object of class <code>HOMERmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>clusters</dt><dd><p>The number of nodes in each level</p>
</dd>
<dt>models</dt><dd><p>The Hierarchy of BR models.</p>
</dd>
</dl>



<h3>References</h3>

<p>Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2008). Effective and efficient
multilabel classification in domains with large number of labels. In Proc.
ECML/PKDD 2008 Workshop on Mining Multidimensional Data (MMD'08)
(pp. 30-44). Antwerp, Belgium.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- homer(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


##Change default configurations
model &lt;- homer(toyml, "RF", clusters=5, method="clustering", iteration=10)

</code></pre>

<hr>
<h2 id='is.bipartition'>Test if a mlresult contains crisp values as default</h2><span id='topic+is.bipartition'></span>

<h3>Description</h3>

<p>Test if a mlresult contains crisp values as default
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.bipartition(mlresult)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.bipartition_+3A_mlresult">mlresult</code></td>
<td>
<p>The mlresult object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical value
</p>

<hr>
<h2 id='is.probability'>Test if a mlresult contains score values as default</h2><span id='topic+is.probability'></span>

<h3>Description</h3>

<p>Test if a mlresult contains score values as default
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is.probability(mlresult)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="is.probability_+3A_mlresult">mlresult</code></td>
<td>
<p>The mlresult object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>logical value
</p>

<hr>
<h2 id='lcard_threshold'>Threshold based on cardinality</h2><span id='topic+lcard_threshold'></span><span id='topic+lcard_threshold.default'></span><span id='topic+lcard_threshold.mlresult'></span>

<h3>Description</h3>

<p>Find and apply the best threshold based on cardinality of training set.
The threshold is choice based on how much the average observed label
cardinality is close to the average predicted label cardinality.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lcard_threshold(prediction, cardinality, probability = FALSE)

## Default S3 method:
lcard_threshold(prediction, cardinality, probability = FALSE)

## S3 method for class 'mlresult'
lcard_threshold(prediction, cardinality, probability = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lcard_threshold_+3A_prediction">prediction</code></td>
<td>
<p>A matrix or mlresult.</p>
</td></tr>
<tr><td><code id="lcard_threshold_+3A_cardinality">cardinality</code></td>
<td>
<p>A real value of training dataset label cardinality, used
to define the threshold value.</p>
</td></tr>
<tr><td><code id="lcard_threshold_+3A_probability">probability</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values are
the score between 0 and 1, otherwise the values are bipartition 0 or 1.
(Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A mlresult object.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Cardinality Threshold for matrix or data.frame
</p>
</li>
<li> <p><code>mlresult</code>: Cardinality Threshold for mlresult
</p>
</li></ul>


<h3>References</h3>

<p>Read, J., Pfahringer, B., Holmes, G., &amp; Frank, E. (2011). Classifier chains
for multi-label classification. Machine Learning, 85(3), 333-359.
</p>


<h3>See Also</h3>

<p>Other threshold: 
<code><a href="#topic+fixed_threshold">fixed_threshold</a>()</code>,
<code><a href="#topic+mcut_threshold">mcut_threshold</a>()</code>,
<code><a href="#topic+pcut_threshold">pcut_threshold</a>()</code>,
<code><a href="#topic+rcut_threshold">rcut_threshold</a>()</code>,
<code><a href="#topic+scut_threshold">scut_threshold</a>()</code>,
<code><a href="#topic+subset_correction">subset_correction</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prediction &lt;- matrix(runif(16), ncol = 4)
lcard_threshold(prediction, 2.1)
</code></pre>

<hr>
<h2 id='lift'>LIFT for multi-label Classification</h2><span id='topic+lift'></span>

<h3>Description</h3>

<p>Create a multi-label learning with Label specIfic FeaTures (LIFT) model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lift(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  ratio = 0.1,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lift_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="lift_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="lift_+3A_ratio">ratio</code></td>
<td>
<p>Control the number of clusters being retained. Must be between
0 and 1. (Default: <code>0.1</code>)</p>
</td></tr>
<tr><td><code id="lift_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="lift_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="lift_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>LIFT firstly constructs features specific to each label by conducting
clustering analysis on its positive and negative instances, and then performs
training and testing by querying the clustering results.
</p>


<h3>Value</h3>

<p>An object of class <code>LIFTmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>models</dt><dd><p>A list of the generated models, named by the label names.</p>
</dd>
</dl>



<h3>References</h3>

<p>Zhang, M.-L., &amp; Wu, L. (2015). Lift: Multi-Label Learning with
Label-Specific Features. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 37(1), 107-120.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lift(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Runing lift with a specific ratio
model &lt;- lift(toyml, "RF", 0.15)

</code></pre>

<hr>
<h2 id='lp'>Label Powerset for multi-label Classification</h2><span id='topic+lp'></span>

<h3>Description</h3>

<p>Create a Label Powerset model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lp(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lp_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="lp_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="lp_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems</p>
</td></tr>
<tr><td><code id="lp_+3A_cores">cores</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="lp_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Label Powerset is a simple transformation method to predict multi-label data.
This is based on the multi-class approach to build a model where the classes
are each labelset.
</p>


<h3>Value</h3>

<p>An object of class <code>LPmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>model</dt><dd><p>A multi-class model.</p>
</dd>
</dl>



<h3>References</h3>

<p>Boutell, M. R., Luo, J., Shen, X., &amp; Brown, C. M. (2004). Learning
multi-label scene classification. Pattern Recognition, 37(9), 1757-1771.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Powerset: 
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lp(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='mbr'>Meta-BR or 2BR for multi-label Classification</h2><span id='topic+mbr'></span>

<h3>Description</h3>

<p>Create a Meta-BR (MBR) classifier to predict multi-label data. To this, two
round of Binary Relevance is executed, such that, the first step generates
new attributes to enrich the second prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mbr(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  folds = 1,
  phi = 0,
  ...,
  predict.params = list(),
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mbr_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="mbr_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="mbr_+3A_folds">folds</code></td>
<td>
<p>The number of folds used in internal prediction. If this value
is 1 all dataset will be used in the first prediction. (Default: 1)</p>
</td></tr>
<tr><td><code id="mbr_+3A_phi">phi</code></td>
<td>
<p>A value between 0 and 1 to determine the correlation coefficient,
The value 0 include all labels in the second phase and the 1 only the
predicted label. (Default: 0)</p>
</td></tr>
<tr><td><code id="mbr_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="mbr_+3A_predict.params">predict.params</code></td>
<td>
<p>A list of default arguments passed to the predictor
algorithm. (Default: <code>list()</code>)</p>
</td></tr>
<tr><td><code id="mbr_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="mbr_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This implementation use complete training set for both training and
prediction steps of 2BR. However, the <code>phi</code> parameter may be used to
remove labels with low correlations on the second step.
</p>


<h3>Value</h3>

<p>An object of class <code>MBRmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>phi</dt><dd><p>The value of <code>phi</code> parameter.</p>
</dd>
<dt>correlation</dt><dd><p>The matrix of label correlations used in combination
with <code>phi</code> parameter to define the labels used in the second
step. </p>
</dd>
<dt>basemodel</dt><dd><p>The BRModel used in the first iteration.</p>
</dd>
<dt>models</dt><dd><p>A list of models named by the label names used in the
second iteration. </p>
</dd>
</dl>



<h3>References</h3>

<p>Tsoumakas, G., Dimou, A., Spyromitros, E., Mezaris, V., Kompatsiaris, I., &amp;
Vlahavas, I. (2009). Correlation-based pruning of stacked binary relevance
models for multi-label learning. In Proceedings of the Workshop on
Learning from Multi-Label Data (MLD'09) (pp. 22-30).
Godbole, S., &amp; Sarawagi, S. (2004). Discriminative Methods for Multi-labeled
Classification. In Data Mining and Knowledge Discovery (pp. 1-26).
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Stacking methods: 
<code><a href="#topic+brplus">brplus</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- mbr(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use 10 folds and different phi correlation with C5.0 classifier
model &lt;- mbr(toyml, 'C5.0', 10, 0.2)

# Run with 2 cores
 model &lt;- mbr(toyml, "SVM", cores = 2, seed = 123)

# Set a specific parameter
model &lt;- mbr(toyml, 'KNN', k=5)

</code></pre>

<hr>
<h2 id='mcut_threshold'>Maximum Cut Thresholding (MCut)</h2><span id='topic+mcut_threshold'></span><span id='topic+mcut_threshold.default'></span><span id='topic+mcut_threshold.mlresult'></span>

<h3>Description</h3>

<p>The Maximum Cut (MCut) automatically determines a threshold for each instance
that selects a subset of labels with higher scores than others. This leads to
the selection of the middle of the interval defined by these two scores as
the threshold.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mcut_threshold(prediction, probability = FALSE)

## Default S3 method:
mcut_threshold(prediction, probability = FALSE)

## S3 method for class 'mlresult'
mcut_threshold(prediction, probability = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mcut_threshold_+3A_prediction">prediction</code></td>
<td>
<p>A matrix or mlresult.</p>
</td></tr>
<tr><td><code id="mcut_threshold_+3A_probability">probability</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values are
the score between 0 and 1, otherwise the values are bipartition 0 or 1.
(Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A mlresult object.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Maximum Cut Thresholding (MCut) method for matrix
</p>
</li>
<li> <p><code>mlresult</code>: Maximum Cut Thresholding (MCut) for mlresult
</p>
</li></ul>


<h3>References</h3>

<p>Largeron, C., Moulin, C., &amp; Gery, M. (2012). MCut: A Thresholding Strategy
for Multi-label Classification. In 11th International Symposium, IDA 2012
(pp. 172-183).
</p>


<h3>See Also</h3>

<p>Other threshold: 
<code><a href="#topic+fixed_threshold">fixed_threshold</a>()</code>,
<code><a href="#topic+lcard_threshold">lcard_threshold</a>()</code>,
<code><a href="#topic+pcut_threshold">pcut_threshold</a>()</code>,
<code><a href="#topic+rcut_threshold">rcut_threshold</a>()</code>,
<code><a href="#topic+scut_threshold">scut_threshold</a>()</code>,
<code><a href="#topic+subset_correction">subset_correction</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prediction &lt;- matrix(runif(16), ncol = 4)
mcut_threshold(prediction)
</code></pre>

<hr>
<h2 id='merge_mlconfmat'>Join a list of multi-label confusion matrix</h2><span id='topic+merge_mlconfmat'></span>

<h3>Description</h3>

<p>Join a list of multi-label confusion matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>merge_mlconfmat(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_mlconfmat_+3A_object">object</code></td>
<td>
<p>A mlconfmat object or a list of mlconfmat objects</p>
</td></tr>
<tr><td><code id="merge_mlconfmat_+3A_...">...</code></td>
<td>
<p>mlconfmat objects</p>
</td></tr>
</table>


<h3>Value</h3>

<p>mlconfmat
</p>

<hr>
<h2 id='mldata'>Fix the mldr dataset to use factors</h2><span id='topic+mldata'></span>

<h3>Description</h3>

<p>Fix the mldr dataset to use factors
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mldata(mdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mldata_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A mldr object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toyml &lt;- mldata(toyml)
</code></pre>

<hr>
<h2 id='mlknn'>Multi-label KNN (ML-KNN) for multi-label Classification</h2><span id='topic+mlknn'></span>

<h3>Description</h3>

<p>Create a ML-KNN classifier to predict multi-label data. It is a multi-label
lazy learning, which is derived from the traditional K-nearest neighbor (KNN)
algorithm. For each unseen instance, its K nearest neighbors in the training
set are identified and based on statistical information gained from the label
sets of these neighboring instances, the maximum a posteriori (MAP) principle
is utilized to determine the label set for the unseen instance.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlknn(
  mdata,
  k = 10,
  s = 1,
  distance = "euclidean",
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlknn_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="mlknn_+3A_k">k</code></td>
<td>
<p>The number of neighbors. (Default: <code>10</code>)</p>
</td></tr>
<tr><td><code id="mlknn_+3A_s">s</code></td>
<td>
<p>Smoothing parameter controlling the strength of uniform prior. When
it is set to be 1, we have the Laplace smoothing. (Default: <code>1</code>).</p>
</td></tr>
<tr><td><code id="mlknn_+3A_distance">distance</code></td>
<td>
<p>The name of method used to compute the distance. See
<code><a href="stats.html#topic+dist">dist</a></code> to the list of options.
(Default: <code>"euclidian"</code>)</p>
</td></tr>
<tr><td><code id="mlknn_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="mlknn_+3A_cores">cores</code></td>
<td>
<p>Ignored because this method does not support multi-core.</p>
</td></tr>
<tr><td><code id="mlknn_+3A_seed">seed</code></td>
<td>
<p>Ignored because this method is deterministic.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>MLKNNmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>prior</dt><dd><p>The prior probability of each label to occur.</p>
</dd>
<dt>posterior</dt><dd><p>The posterior probability of each label to occur given
that k neighbors have it.</p>
</dd>
</dl>



<h3>References</h3>

<p>Zhang, M.L. L., &amp; Zhou, Z.H. H. (2007). ML-KNN: A lazy learning approach
to multi-label learning. Pattern Recognition, 40(7), 2038-2048.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- mlknn(toyml, k=3)
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='mlpredict'>Prediction transformation problems</h2><span id='topic+mlpredict'></span>

<h3>Description</h3>

<p>Base classifiers are used to build models to solve the the transformation
problems. To create a new base classifier, two steps are necessary:
</p>

<ol>
<li><p> Create a train method
</p>
</li>
<li><p> Create a prediction method
</p>
</li></ol>

<p>This section is about how to create the second step: a prediction method.
To create a new train method see <code><a href="#topic+mltrain">mltrain</a></code> documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlpredict(model, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlpredict_+3A_model">model</code></td>
<td>
<p>An object model returned by some mltrain method, its class
determine the name of this method.</p>
</td></tr>
<tr><td><code id="mlpredict_+3A_newdata">newdata</code></td>
<td>
<p>A data.frame with the new data to be predicted.</p>
</td></tr>
<tr><td><code id="mlpredict_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the predict method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix with the probabilities of each class value/example,
where the rows are the examples and the columns the class values.
</p>


<h3>How to create a new prediction base method</h3>

<p>Fist is necessary to know the class of model generate by the respective train
method, because this name determines the method name. It must start with
<code>'mlpredict.'</code>, followed by the model class name, e.g. a model with
class 'fooModel' must be called as <code>mlpredict.fooModel</code>.
</p>
<p>After defined the name, you need to implement your prediction base method.
The model built on mltrain is available on <code>model</code> parameter and the
<code>newdata</code> is the data to be predict.
</p>
<p>The return of this method must be a data.frame with two columns called
<code>"prediction"</code> and <code>"probability"</code>. The first column contains the
predicted class and the second the probability/score/confidence of this
prediction. The rows represents the examples.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Create a method that predict always the first class
# The model must be of the class 'fooModel'
mlpredict.fooModel &lt;- function (model, newdata, ...) {
   # Predict the first class with a random confidence
   data.frame(
     prediction = rep(model$classes[1], nrow(newdata)),
     probability = sapply(runif(nrow(newdata)), function (score) {
       max(score, 1 - score)
     }),
     row.names = rownames(newdata)
   )
}


# Create a SVM predict method using the e1071 package (the class of SVM model
# from e1071 package is 'svm')
library(e1071)
mlpredict.svm &lt;- function (dataset, newdata, ...) {
   result &lt;- predict(model, newdata, probability = TRUE, ...)
   attr(result, 'probabilities')
}

</code></pre>

<hr>
<h2 id='mltrain'>Build transformation models</h2><span id='topic+mltrain'></span>

<h3>Description</h3>

<p>Base classifiers are used to build models to solve the the transformation
problems. To create a new base classifier, two steps are necessary:
</p>

<ol>
<li><p> Create a train method
</p>
</li>
<li><p> Create a prediction method
</p>
</li></ol>

<p>This section is about how to create the first step: a train method.
To create a new predict model see <code><a href="#topic+mlpredict">mlpredict</a></code> documentation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mltrain(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mltrain_+3A_object">object</code></td>
<td>
<p>A <code>mltransformation</code> object. This is used as a list and
contains at least five values:
</p>

<dl>
<dt>object$data</dt><dd><p>A data.frame with the train data, where the columns are
the attributes and the rows are the examples.</p>
</dd>
<dt>object$labelname</dt><dd><p>The name of the class column.</p>
</dd>
<dt>object$labelindex</dt><dd><p>The column index of the class.</p>
</dd>
<dt>object$mldataset</dt><dd><p>The name of multi-label dataset.</p>
</dd>
<dt>object$mlmethod</dt><dd><p>The name of the multi-label method.</p>
</dd>
</dl>

<p>Others values may be specified by the multi-label method.</p>
</td></tr>
<tr><td><code id="mltrain_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base method.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A model object. The class of this model can be of any type, however,
this object will be passed to the respective mlpredict method.
</p>


<h3>How to create a new train base method</h3>

<p>First, is necessary to define a name of your classifier, because this name
determines the method name. The base method name must start with
<code>mltrain.base</code> followed by the designed name, e.g. a <code>'FOO'</code>
classify must be defined as <code>mltrain.baseFOO</code> (we suggest always use
upper case names).
</p>
<p>Next, your method must receive at least two parameters (<code>object, ...</code>).
Use <code>object$data[, object$labelindex]</code> or
<code>object$data[, object$labelname]</code> to access the labels values and use
<code>object$data[, -object$labelindex]</code> to access the predictive attributes.
If you need to know which are the multi-label dataset and method, use
<code>object$mldataset</code> and <code>object$mlmethod</code>, respectively.
</p>
<p>Finally, your method should return a model that will be used by the mlpredict
method. Remember, that your method may be used to build binary and
multi-class models.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Create a empty model of type FOO
mltrain.baseFOO &lt;- function (object, ...) {
   mymodel &lt;- list(
     classes = as.character(unique(object$data[, object$labelindex]))
   )
   class(mymodel) &lt;- 'fooModel'
   mymodel
}

# Using this base method with Binary Relevance
brmodel &lt;- br(toyml, 'FOO')



# Create a SVM method using the e1071 package
library(e1071)
mltrain.baseSVM &lt;- function (object, ...) {
   traindata &lt;- object$data[, -object$labelindex]
   labeldata &lt;- object$data[, object$labelindex]
   model &lt;- svm(traindata, labeldata, probability = TRUE, ...)
   model
}

</code></pre>

<hr>
<h2 id='multilabel_confusion_matrix'>Compute the confusion matrix for a multi-label prediction</h2><span id='topic+multilabel_confusion_matrix'></span>

<h3>Description</h3>

<p>The multi-label confusion matrix is an object that contains the prediction,
the expected values and also a lot of pre-processed information related with
these data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilabel_confusion_matrix(mdata, mlresult)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilabel_confusion_matrix_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset</p>
</td></tr>
<tr><td><code id="multilabel_confusion_matrix_+3A_mlresult">mlresult</code></td>
<td>
<p>A mlresult prediction</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A mlconfmat object that contains:
</p>

<dl>
<dt>Z</dt><dd><p>The bipartition matrix prediction.</p>
</dd>
<dt>Fx</dt><dd><p>The score/probability matrix prediction.</p>
</dd>
<dt>R</dt><dd><p>The ranking matrix prediction.</p>
</dd>
<dt>Y</dt><dd><p>The expected matrix bipartition.</p>
</dd>
<dt>TP</dt><dd><p>The True Positive matrix values.</p>
</dd>
<dt>FP</dt><dd><p>The False Positive matrix values.</p>
</dd>
<dt>TN</dt><dd><p>The True Negative matrix values.</p>
</dd>
<dt>FN</dt><dd><p>The False Negative matrix values.</p>
</dd>
<dt>Zi</dt><dd><p>The total of positive predictions for each instance.</p>
</dd>
<dt>Yi</dt><dd><p>The total of positive expected for each instance.</p>
</dd>
<dt>TPi</dt><dd><p>The total of True Positive predictions for each instance.</p>
</dd>
<dt>FPi</dt><dd><p>The total of False Positive predictions for each instance.</p>
</dd>
<dt>TNi</dt><dd><p>The total of True Negative predictions for each instance.</p>
</dd>
<dt>FNi</dt><dd><p>The total False Negative predictions for each instance.</p>
</dd>
<dt>Zl</dt><dd><p>The total of positive predictions for each label.</p>
</dd>
<dt>Yl</dt><dd><p>The total of positive expected for each label.</p>
</dd>
<dt>TPl</dt><dd><p>The total of True Positive predictions for each label.</p>
</dd>
<dt>FPl</dt><dd><p>The total of False Positive predictions for each label.</p>
</dd>
<dt>TNl</dt><dd><p>The total of True Negative predictions for each label.</p>
</dd>
<dt>FNl</dt><dd><p>The total False Negative predictions for each label.</p>
</dd>
</dl>



<h3>See Also</h3>

<p>Other evaluation: 
<code><a href="#topic+cv">cv</a>()</code>,
<code><a href="#topic+multilabel_evaluate">multilabel_evaluate</a>()</code>,
<code><a href="#topic+multilabel_measures">multilabel_measures</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
prediction &lt;- predict(br(toyml), toyml)

mlconfmat &lt;- multilabel_confusion_matrix(toyml, prediction)

# Label with the most number of True Positive values
which.max(mlconfmat$TPl)

# Number of wrong predictions for each label
errors &lt;- mlconfmat$FPl + mlconfmat$FNl

# Examples predict with all labels
which(mlconfmat$Zi == toyml$measures$num.labels)

# You can join one or more mlconfmat
part1 &lt;- create_subset(toyml, 1:50)
part2 &lt;- create_subset(toyml, 51:100)
confmatp1 &lt;- multilabel_confusion_matrix(part1, prediction[1:50, ])
confmatp2 &lt;- multilabel_confusion_matrix(part2, prediction[51:100, ])
mlconfmat &lt;- confmatp1 + confmatp2

</code></pre>

<hr>
<h2 id='multilabel_evaluate'>Evaluate multi-label predictions</h2><span id='topic+multilabel_evaluate'></span><span id='topic+multilabel_evaluate.mldr'></span><span id='topic+multilabel_evaluate.mlconfmat'></span>

<h3>Description</h3>

<p>This method is used to evaluate multi-label predictions. You can create a
confusion matrix object or use directly the test dataset and the predictions.
You can also specify which measures do you desire use.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilabel_evaluate(object, ...)

## S3 method for class 'mldr'
multilabel_evaluate(object, mlresult, measures = c("all"), labels = FALSE, ...)

## S3 method for class 'mlconfmat'
multilabel_evaluate(object, measures = c("all"), labels = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilabel_evaluate_+3A_object">object</code></td>
<td>
<p>A mldr dataset or a mlconfmat confusion matrix</p>
</td></tr>
<tr><td><code id="multilabel_evaluate_+3A_...">...</code></td>
<td>
<p>Extra parameters to specific measures.</p>
</td></tr>
<tr><td><code id="multilabel_evaluate_+3A_mlresult">mlresult</code></td>
<td>
<p>The prediction result (Optional, required only when the
mldr is used).</p>
</td></tr>
<tr><td><code id="multilabel_evaluate_+3A_measures">measures</code></td>
<td>
<p>The measures names to be computed. Call
<code>multilabel_measures()</code> to see the expected measures. You can also
use <code>"bipartition"</code>, <code>"ranking"</code>, <code>"label-based"</code>,
<code>"example-based"</code>, <code>"macro-based"</code>, <code>"micro-based"</code> and
<code>"label-problem"</code> to include a set of measures. (Default: &quot;all&quot;).</p>
</td></tr>
<tr><td><code id="multilabel_evaluate_+3A_labels">labels</code></td>
<td>
<p>Logical value defining if the label results should be also
returned. (Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If labels is FALSE return a vector with the expected multi-label
measures, otherwise, a list contained the multi-label and label measures.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>mldr</code>: Default S3 method
</p>
</li>
<li> <p><code>mlconfmat</code>: Default S3 method
</p>
</li></ul>


<h3>References</h3>

<p>Madjarov, G., Kocev, D., Gjorgjevikj, D., &amp; Dzeroski, S. (2012). An
extensive experimental comparison of methods for multi-label learning.
Pattern Recognition, 45(9), 3084-3104.
Zhang, M.-L., &amp; Zhou, Z.-H. (2014). A Review on Multi-Label Learning
Algorithms. IEEE Transactions on Knowledge and Data Engineering, 26(8),
1819-1837.
Gibaja, E., &amp; Ventura, S. (2015). A Tutorial on Multilabel Learning.
ACM Comput. Surv., 47(3), 52:1-2:38.
</p>


<h3>See Also</h3>

<p>Other evaluation: 
<code><a href="#topic+cv">cv</a>()</code>,
<code><a href="#topic+multilabel_confusion_matrix">multilabel_confusion_matrix</a>()</code>,
<code><a href="#topic+multilabel_measures">multilabel_measures</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
prediction &lt;- predict(br(toyml), toyml)

# Compute all measures
multilabel_evaluate(toyml, prediction)
multilabel_evaluate(toyml, prediction, labels=TRUE) # Return a list

# Compute bipartition measures
multilabel_evaluate(toyml, prediction, "bipartition")

# Compute multilples measures
multilabel_evaluate(toyml, prediction, c("accuracy", "F1", "macro-based"))

# Compute the confusion matrix before the measures
cm &lt;- multilabel_confusion_matrix(toyml, prediction)
multilabel_evaluate(cm)
multilabel_evaluate(cm, "example-based")
multilabel_evaluate(cm, c("hamming-loss", "subset-accuracy", "F1"))

</code></pre>

<hr>
<h2 id='multilabel_measures'>Return the name of all measures</h2><span id='topic+multilabel_measures'></span>

<h3>Description</h3>

<p>Return the name of all measures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilabel_measures()
</code></pre>


<h3>Value</h3>

<p>array of character contained the measures names.
</p>


<h3>See Also</h3>

<p>Other evaluation: 
<code><a href="#topic+cv">cv</a>()</code>,
<code><a href="#topic+multilabel_confusion_matrix">multilabel_confusion_matrix</a>()</code>,
<code><a href="#topic+multilabel_evaluate">multilabel_evaluate</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>multilabel_measures()
</code></pre>

<hr>
<h2 id='multilabel_prediction'>Create a mlresult object</h2><span id='topic+multilabel_prediction'></span>

<h3>Description</h3>

<p>Create a mlresult object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>multilabel_prediction(
  bipartitions,
  probabilities,
  probability = getOption("utiml.use.probs", TRUE),
  empty.prediction = getOption("utiml.empty.prediction", FALSE)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="multilabel_prediction_+3A_bipartitions">bipartitions</code></td>
<td>
<p>The matrix of predictions (bipartition values),
only 0 and 1</p>
</td></tr>
<tr><td><code id="multilabel_prediction_+3A_probabilities">probabilities</code></td>
<td>
<p>The matrix of probability/confidence of a prediction,
between 0..1</p>
</td></tr>
<tr><td><code id="multilabel_prediction_+3A_probability">probability</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values are
the score between 0 and 1, otherwise the values are bipartition 0 or 1.
(Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="multilabel_prediction_+3A_empty.prediction">empty.prediction</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values
may contains empty values, otherwise at least one label will be positive for
each instance.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult
</p>


<h3>Examples</h3>

<pre><code class='language-R'>probs &lt;- matrix(
 runif(90), ncol=3, dimnames = list(1:30, c("y1", "y2", "y3"))
)
preds &lt;- matrix(
 as.numeric(probs &gt; 0.5), ncol=3, dimnames = list(1:30, c("y1", "y2", "y3"))
)
multilabel_prediction(probs, preds)
</code></pre>

<hr>
<h2 id='normalize_mldata'>Normalize numerical attributes</h2><span id='topic+normalize_mldata'></span>

<h3>Description</h3>

<p>Normalize all numerical attributes to values between 0 and 1. The highest
value is changed to 1 and the lowest value to 0.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize_mldata(mdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize_mldata_+3A_mdata">mdata</code></td>
<td>
<p>The mldr dataset to be normalized.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new mldr object.
</p>


<h3>See Also</h3>

<p>Other pre process: 
<code><a href="#topic+fill_sparse_mldata">fill_sparse_mldata</a>()</code>,
<code><a href="#topic+remove_attributes">remove_attributes</a>()</code>,
<code><a href="#topic+remove_labels">remove_labels</a>()</code>,
<code><a href="#topic+remove_skewness_labels">remove_skewness_labels</a>()</code>,
<code><a href="#topic+remove_unique_attributes">remove_unique_attributes</a>()</code>,
<code><a href="#topic+remove_unlabeled_instances">remove_unlabeled_instances</a>()</code>,
<code><a href="#topic+replace_nominal_attributes">replace_nominal_attributes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>norm.toy &lt;- normalize_mldata(toyml)
</code></pre>

<hr>
<h2 id='ns'>Nested Stacking for multi-label Classification</h2><span id='topic+ns'></span>

<h3>Description</h3>

<p>Create a Nested Stacking model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ns(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  chain = NA,
  ...,
  predict.params = list(),
  cores = NULL,
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ns_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="ns_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="ns_+3A_chain">chain</code></td>
<td>
<p>A vector with the label names to define the chain order. If
empty the chain is the default label sequence of the dataset. (Default:
<code>NA</code>)</p>
</td></tr>
<tr><td><code id="ns_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="ns_+3A_predict.params">predict.params</code></td>
<td>
<p>A list of default arguments passed to the predict
algorithm. (default: <code>list()</code>)</p>
</td></tr>
<tr><td><code id="ns_+3A_cores">cores</code></td>
<td>
<p>Ignored because this method does not support multi-core.</p>
</td></tr>
<tr><td><code id="ns_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed.
(Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Nested Stacking is based on Classifier Chains transformation method to
predict multi-label data. It differs from CC to predict the labels values in
the training step and to regularize the output based on the labelsets
available on training data.
</p>


<h3>Value</h3>

<p>An object of class <code>NSmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>chain</dt><dd><p>A vector with the chain order</p>
</dd>
<dt>labels</dt><dd><p>A vector with the label names in expected order</p>
</dd>
<dt>labelset</dt><dd><p>The matrix containing only labels values</p>
</dd>
<dt>models</dt><dd><p>A list of models named by the label names.</p>
</dd>
</dl>



<h3>References</h3>

<p>Senge, R., Coz, J. J. del, &amp; Hullermeier, E. (2013). Rectifying classifier
chains for multi-label classification. In Workshop of Lernen, Wissen &amp;
Adaptivitat (LWA 2013) (pp. 162-169). Bamberg, Germany.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- ns(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use a specific chain with C5.0 classifier
mychain &lt;- sample(rownames(toyml$labels))
model &lt;- ns(toyml, 'C5.0', mychain)

# Set a specific parameter
model &lt;- ns(toyml, 'KNN', k=5)

</code></pre>

<hr>
<h2 id='partition_fold'>Create the multi-label dataset from folds</h2><span id='topic+partition_fold'></span>

<h3>Description</h3>

<p>This is a simple way to use k-fold cross validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>partition_fold(kfold, n, has.validation = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="partition_fold_+3A_kfold">kfold</code></td>
<td>
<p>A <code>kFoldPartition</code> object obtained from use of the method
<a href="#topic+create_kfold_partition">create_kfold_partition</a>.</p>
</td></tr>
<tr><td><code id="partition_fold_+3A_n">n</code></td>
<td>
<p>The number of the fold to separated train and test subsets.</p>
</td></tr>
<tr><td><code id="partition_fold_+3A_has.validation">has.validation</code></td>
<td>
<p>Logical value that indicate if a validation
dataset will be used. (Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list contained train and test mldr dataset:
</p>

<p><code>train</code>The mldr dataset with train examples, that includes all
examples except those that are in test and validation samples
<code>test</code>The mldr dataset with test examples, defined by the
number of the fold
<code>validation</code>Optionally, only if <code>has.validation = TRUE</code>.
The mldr dataset with validation examples

</p>


<h3>Examples</h3>

<pre><code class='language-R'>folds &lt;- create_kfold_partition(toyml, 10)

# Using the first partition
dataset &lt;- partition_fold(folds, 1)
names(dataset)
## [1] "train" "test"

# All iterations
for (i in 1:10) {
   dataset &lt;- partition_fold(folds, i)
   #dataset$train
   #dataset$test
}

# Using 3 folds validation
dataset &lt;- partition_fold(folds, 3, TRUE)
# dataset$train, dataset$test, #dataset$validation
</code></pre>

<hr>
<h2 id='pcut_threshold'>Proportional Thresholding (PCut)</h2><span id='topic+pcut_threshold'></span><span id='topic+pcut_threshold.default'></span><span id='topic+pcut_threshold.mlresult'></span>

<h3>Description</h3>

<p>Define the proportion of examples for each label will be positive.
The Proportion Cut (PCut) method can be a label-wise or global method that
calibrates the threshold(s) from the training data globally or per label.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcut_threshold(prediction, ratio, probability = FALSE)

## Default S3 method:
pcut_threshold(prediction, ratio, probability = FALSE)

## S3 method for class 'mlresult'
pcut_threshold(prediction, ratio, probability = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcut_threshold_+3A_prediction">prediction</code></td>
<td>
<p>A matrix or mlresult.</p>
</td></tr>
<tr><td><code id="pcut_threshold_+3A_ratio">ratio</code></td>
<td>
<p>A single value between 0 and 1 or a list with ratio values
contained one value per label.</p>
</td></tr>
<tr><td><code id="pcut_threshold_+3A_probability">probability</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values are
the score between 0 and 1, otherwise the values are bipartition 0 or 1.
(Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A mlresult object.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Proportional Thresholding (PCut) method for matrix
</p>
</li>
<li> <p><code>mlresult</code>: Proportional Thresholding (PCut) for mlresult
</p>
</li></ul>


<h3>References</h3>

<p>Al-Otaibi, R., Flach, P., &amp; Kull, M. (2014). Multi-label Classification: A
Comparative Study on Threshold Selection Methods. In First International
Workshop on Learning over Multiple Contexts (LMCE) at ECML-PKDD 2014.
</p>
<p>Largeron, C., Moulin, C., &amp; Gery, M. (2012). MCut: A Thresholding Strategy
for Multi-label Classification. In 11th International Symposium, IDA 2012
(pp. 172-183).
</p>


<h3>See Also</h3>

<p>Other threshold: 
<code><a href="#topic+fixed_threshold">fixed_threshold</a>()</code>,
<code><a href="#topic+lcard_threshold">lcard_threshold</a>()</code>,
<code><a href="#topic+mcut_threshold">mcut_threshold</a>()</code>,
<code><a href="#topic+rcut_threshold">rcut_threshold</a>()</code>,
<code><a href="#topic+scut_threshold">scut_threshold</a>()</code>,
<code><a href="#topic+subset_correction">subset_correction</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prediction &lt;- matrix(runif(16), ncol = 4)
pcut_threshold(prediction, .45)
</code></pre>

<hr>
<h2 id='ppt'>Pruned Problem Transformation for multi-label Classification</h2><span id='topic+ppt'></span>

<h3>Description</h3>

<p>Create a Pruned Problem Transformation model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ppt(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  p = 3,
  info.loss = FALSE,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ppt_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="ppt_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="ppt_+3A_p">p</code></td>
<td>
<p>Number of instances to prune. All labelsets that occurs p times or
less in the training data is removed. (Default: 3)</p>
</td></tr>
<tr><td><code id="ppt_+3A_info.loss">info.loss</code></td>
<td>
<p>Logical value where <code>TRUE</code> means discard infrequent
labelsets and <code>FALSE</code> means reintroduce infrequent labelsets via
subsets. (Default: FALSE)</p>
</td></tr>
<tr><td><code id="ppt_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems</p>
</td></tr>
<tr><td><code id="ppt_+3A_cores">cores</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="ppt_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pruned Problem Transformation (PPT) is a multi-class transformation that
remove the less common classes to predict multi-label data.
</p>


<h3>Value</h3>

<p>An object of class <code>PPTmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>model</dt><dd><p>A LP model contained only the most common labelsets.</p>
</dd>
</dl>



<h3>References</h3>

<p>Read, J., Pfahringer, B., &amp; Holmes, G. (2008). Multi-label classification
using ensembles of pruned sets. In Proceedings - IEEE International
Conference on Data Mining, ICDM (pp. 9951000).
Read, J. (2008). A pruned problem transformation method for multi-label
classification. In Proceedings of the New Zealand Computer Science
Research Student Conference (pp. 143-150).
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Powerset: 
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- ppt(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


##Change default configurations
model &lt;- ppt(toyml, "RF", p=4, info.loss=TRUE)

</code></pre>

<hr>
<h2 id='predict.BASELINEmodel'>Predict Method for BASELINE</h2><span id='topic+predict.BASELINEmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+baseline">baseline</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BASELINEmodel'
predict(object, newdata, probability = getOption("utiml.use.probs", TRUE), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.BASELINEmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>BASELINEmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.BASELINEmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.BASELINEmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.BASELINEmodel_+3A_...">...</code></td>
<td>
<p>not used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+baseline">Baseline</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- baseline(toyml)
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.BRmodel'>Predict Method for Binary Relevance</h2><span id='topic+predict.BRmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code><a href="#topic+br">br</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BRmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.BRmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>BRmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.BRmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.BRmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.BRmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.BRmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.BRmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+br">Binary Relevance (BR)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- br(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Predict SVM scores
model &lt;- br(toyml, "SVM")
pred &lt;- predict(model, toyml)

# Predict SVM bipartitions running in 2 cores
pred &lt;- predict(model, toyml, probability = FALSE, CORES = 2)

# Passing a specif parameter for SVM predict algorithm
pred &lt;- predict(model, toyml, na.action = na.fail)

</code></pre>

<hr>
<h2 id='predict.BRPmodel'>Predict Method for BR+ (brplus)</h2><span id='topic+predict.BRPmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>brplus</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BRPmodel'
predict(
  object,
  newdata,
  strategy = c("Dyn", "Stat", "Ord", "NU"),
  order = list(),
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.BRPmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>BRPmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.BRPmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.BRPmodel_+3A_strategy">strategy</code></td>
<td>
<p>The strategy prefix to determine how to estimate the values
of the augmented features of unlabeled examples.
</p>
<p>The possible values are: <code>'Dyn'</code>, <code>'Stat'</code>, <code>'Ord'</code> or
<code>'NU'</code>. See the description for more details. (Default: <code>'Dyn'</code>).</p>
</td></tr>
<tr><td><code id="predict.BRPmodel_+3A_order">order</code></td>
<td>
<p>The label sequence used to update the initial labels results
based on the final results. This argument is used only when the
<code>strategy = 'Ord'</code> (Default: <code>list()</code>)</p>
</td></tr>
<tr><td><code id="predict.BRPmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.BRPmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.BRPmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.BRPmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The strategies of estimate the values of the new features are separated in
two groups:
</p>

<dl>
<dt>No Update (<code>NU</code>)</dt><dd><p>This use the initial prediction of BR to all
labels. This name is because no modification is made to the initial
estimates of the augmented features during the prediction phase</p>
</dd>
<dt>With Update</dt><dd><p>This strategy update the initial prediction in that the
final predict occurs. There are three possibilities to define the order of
label sequences:
</p>

<dl>
<dt>Specific order (<code>Ord</code>)</dt><dd><p>The order is define by the user,
require a new argument  called <code>order</code>.</p>
</dd>
<dt>Static order (<code>Stat</code>)</dt><dd><p>Use the frequency of single labels in
the training set to define the sequence, where the least frequent
labels are predicted first</p>
</dd>
<dt>Dinamic order (<code>Dyn</code>)</dt><dd><p>Takes into account the confidence of
the initial prediction for each independent single label, to define a
sequence, where the labels predicted with less confidence are updated
first.</p>
</dd>
</dl>

</dd>
</dl>



<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>References</h3>

<p>Cherman, E. A., Metz, J., &amp; Monard, M. C. (2012). Incorporating label
dependency into the binary relevance framework for multi-label
classification. Expert Systems with Applications, 39(2), 1647-1655.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+brplus">BR+</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Predict SVM scores
model &lt;- brplus(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Predict SVM bipartitions and change the method to use No Update strategy
pred &lt;- predict(model, toyml, strategy = 'NU', probability = FALSE)

# Predict using a random sequence to update the labels
labels &lt;- sample(rownames(toyml$labels))
pred &lt;- predict(model, toyml, strategy = 'Ord', order = labels)

# Passing a specif parameter for SVM predict method
pred &lt;- predict(model, toyml, na.action = na.fail)

</code></pre>

<hr>
<h2 id='predict.CCmodel'>Predict Method for Classifier Chains</h2><span id='topic+predict.CCmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>cc</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CCmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = NULL,
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.CCmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>CCmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.CCmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.CCmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.CCmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.CCmodel_+3A_cores">cores</code></td>
<td>
<p>Ignored because this method does not support multi-core.</p>
</td></tr>
<tr><td><code id="predict.CCmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed.
(Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>Note</h3>

<p>The Classifier Chains prediction can not be parallelized
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cc">Classifier Chains (CC)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- cc(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Predict SVM bipartitions
pred &lt;- predict(model, toyml, prob = FALSE)

# Passing a specif parameter for SVM predict algorithm
pred &lt;- predict(model, toyml, na.action = na.fail)

</code></pre>

<hr>
<h2 id='predict.CLRmodel'>Predict Method for CLR</h2><span id='topic+predict.CLRmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+clr">clr</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CLRmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.CLRmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>CLRmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.CLRmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.CLRmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.CLRmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.CLRmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.CLRmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+br">Binary Relevance (BR)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- clr(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.DBRmodel'>Predict Method for DBR</h2><span id='topic+predict.DBRmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>dbr</code>.
In general this method is a restricted version of
<code><a href="#topic+predict.BRPmodel">predict.BRPmodel</a></code> using the 'NU' strategy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DBRmodel'
predict(
  object,
  newdata,
  estimative = NULL,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.DBRmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>DBRmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.DBRmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.DBRmodel_+3A_estimative">estimative</code></td>
<td>
<p>A matrix containing the bipartition result of other
multi-label classification algorithm or an mlresult object with the
predictions.</p>
</td></tr>
<tr><td><code id="predict.DBRmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.DBRmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.DBRmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.DBRmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As new feature is possible to use other multi-label classifier to predict the
estimate values of each label. To this use the prediction argument to inform
a result of other multi-label algorithm.
</p>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>References</h3>

<p>Montanes, E., Senge, R., Barranquero, J., Ramon Quevedo, J., Jose Del Coz,
J., &amp; Hullermeier, E. (2014). Dependent binary relevance models for
multi-label classification. Pattern Recognition, 47(3), 1494-1508.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbr">Dependent Binary Relevance (DBR)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Predict SVM scores
model &lt;- dbr(toyml)
pred &lt;- predict(model, toyml)

# Passing a specif parameter for SVM predict algorithm
pred &lt;- predict(model, toyml, na.action = na.fail)

# Using other classifier (EBR) to made the labels estimatives
estimative &lt;- predict(ebr(toyml), toyml)
model &lt;- dbr(toyml, estimate.models = FALSE)
pred &lt;- predict(model, toyml, estimative = estimative)

</code></pre>

<hr>
<h2 id='predict.EBRmodel'>Predict Method for Ensemble of Binary Relevance</h2><span id='topic+predict.EBRmodel'></span>

<h3>Description</h3>

<p>This method predicts values based upon a model trained by <code><a href="#topic+ebr">ebr</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EBRmodel'
predict(
  object,
  newdata,
  vote.schema = "maj",
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.EBRmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>EBRmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.EBRmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.EBRmodel_+3A_vote.schema">vote.schema</code></td>
<td>
<p>Define the way that ensemble must compute the predictions.
The default valid options are: c(&quot;avg&quot;, &quot;maj&quot;, &quot;max&quot;, &quot;min&quot;). If <code>NULL</code>
then all predictions are returned. (Default: <code>'maj'</code>)</p>
</td></tr>
<tr><td><code id="predict.EBRmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.EBRmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.EBRmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.EBRmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ebr">Ensemble of Binary Relevance (EBR)</a></code> <code>
   <a href="#topic+compute_multilabel_predictions">Compute Multi-label Predictions</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Predict SVM scores
model &lt;- ebr(toyml)
pred &lt;- predict(model, toyml)

# Predict SVM bipartitions running in 2 cores
pred &lt;- predict(model, toyml, prob = FALSE, cores = 2)

# Return the classes with the highest score
pred &lt;- predict(model, toyml, vote = 'max')

</code></pre>

<hr>
<h2 id='predict.ECCmodel'>Predict Method for Ensemble of Classifier Chains</h2><span id='topic+predict.ECCmodel'></span>

<h3>Description</h3>

<p>This method predicts values based upon a model trained by <code><a href="#topic+ecc">ecc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ECCmodel'
predict(
  object,
  newdata,
  vote.schema = "maj",
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ECCmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>ECCmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.ECCmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.ECCmodel_+3A_vote.schema">vote.schema</code></td>
<td>
<p>Define the way that ensemble must compute the predictions.
The default valid options are: c(&quot;avg&quot;, &quot;maj&quot;, &quot;max&quot;, &quot;min&quot;). If <code>NULL</code>
then all predictions are returned. (Default: <code>'maj'</code>)</p>
</td></tr>
<tr><td><code id="predict.ECCmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.ECCmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.ECCmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.ECCmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ecc">Ensemble of Classifier Chains (ECC)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Predict SVM scores
model &lt;- ecc(toyml)
pred &lt;- predict(model, toyml)

# Predict SVM bipartitions running in 2 cores
pred &lt;- predict(model, toyml, probability = FALSE, cores = 2)

# Return the classes with the highest score
pred &lt;- predict(model, toyml, vote.schema = 'max')

</code></pre>

<hr>
<h2 id='predict.EPSmodel'>Predict Method for Ensemble of Pruned Set Transformation</h2><span id='topic+predict.EPSmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+eps">eps</a></code>. Different from the others methods the probability value,
is actually, the sum of all probability predictions such as it is described
in the original paper.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EPSmodel'
predict(
  object,
  newdata,
  threshold = 0.5,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.EPSmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>EPSmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.EPSmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.EPSmodel_+3A_threshold">threshold</code></td>
<td>
<p>A threshold value for producing bipartitions. (Default: 0.5)</p>
</td></tr>
<tr><td><code id="predict.EPSmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.EPSmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.EPSmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the prediction. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.EPSmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+eps">Ensemble of Pruned Set (EPS)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- eps(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.ESLmodel'>Predict Method for Ensemble of Single Label</h2><span id='topic+predict.ESLmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+esl">esl</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ESLmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.ESLmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>ESLmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.ESLmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.ESLmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.ESLmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.ESLmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.ESLmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+esl">Ensemble of Single Label (ESL)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- esl(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.HOMERmodel'>Predict Method for HOMER</h2><span id='topic+predict.HOMERmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+homer">homer</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'HOMERmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.HOMERmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>HOMERmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.HOMERmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.HOMERmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.HOMERmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.HOMERmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the prediction. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.HOMERmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+homer">Hierarchy Of Multilabel classifiER (HOMER)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- homer(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.LIFTmodel'>Predict Method for LIFT</h2><span id='topic+predict.LIFTmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+lift">lift</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LIFTmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.LIFTmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>LIFTmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.LIFTmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.LIFTmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.LIFTmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.LIFTmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.LIFTmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lift">LIFT</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lift(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.LPmodel'>Predict Method for Label Powerset</h2><span id='topic+predict.LPmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code><a href="#topic+lp">lp</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LPmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.LPmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>LPmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.LPmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.LPmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.LPmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.LPmodel_+3A_cores">cores</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="predict.LPmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lp">Label Powerset (LP)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- lp(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.MBRmodel'>Predict Method for Meta-BR/2BR</h2><span id='topic+predict.MBRmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>mbr</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MBRmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.MBRmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>MBRmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.MBRmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.MBRmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.MBRmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.MBRmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.MBRmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mbr">Meta-BR (MBR or 2BR)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Predict SVM scores
model &lt;- mbr(toyml)
pred &lt;- predict(model, toyml)

# Predict SVM bipartitions
pred &lt;- predict(model, toyml, probability = FALSE)

# Passing a specif parameter for SVM predict algorithm
pred &lt;- predict(model, toyml, na.action = na.fail)

</code></pre>

<hr>
<h2 id='predict.MLKNNmodel'>Predict Method for ML-KNN</h2><span id='topic+predict.MLKNNmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>mlknn</code>.
'
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MLKNNmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.MLKNNmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>MLKNNmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.MLKNNmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.MLKNNmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.MLKNNmodel_+3A_...">...</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="predict.MLKNNmodel_+3A_cores">cores</code></td>
<td>
<p>Ignored because this method does not support multi-core.</p>
</td></tr>
<tr><td><code id="predict.MLKNNmodel_+3A_seed">seed</code></td>
<td>
<p>Ignored because this method is deterministic.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+mlknn">ML-KNN</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- mlknn(toyml)
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.NSmodel'>Predict Method for Nested Stacking</h2><span id='topic+predict.NSmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>ns</code>.
The scores of the prediction was adapted once this method uses a correction
of labelsets to predict only classes present on training data. To more
information about this implementation see <code><a href="#topic+subset_correction">subset_correction</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'NSmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = NULL,
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.NSmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>NSmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.NSmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.NSmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.NSmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.NSmodel_+3A_cores">cores</code></td>
<td>
<p>Ignored because this method does not support multi-core.</p>
</td></tr>
<tr><td><code id="predict.NSmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed.
(Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ns">Nested Stacking (NS)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- ns(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Predict SVM bipartitions
pred &lt;- predict(model, toyml, probability = FALSE)

# Passing a specif parameter for SVM predict algorithm
pred &lt;- predict(model, toyml, na.action = na.fail)

</code></pre>

<hr>
<h2 id='predict.PPTmodel'>Predict Method for Pruned Problem Transformation</h2><span id='topic+predict.PPTmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+ppt">ppt</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PPTmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.PPTmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>PPTmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.PPTmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.PPTmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.PPTmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.PPTmodel_+3A_cores">cores</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="predict.PPTmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ppt">Pruned Problem Transformation (PPT)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- ppt(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.PruDentmodel'>Predict Method for PruDent</h2><span id='topic+predict.PruDentmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>prudent</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PruDentmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.PruDentmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>PruDentmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.PruDentmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.PruDentmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.PruDentmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.PruDentmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.PruDentmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+prudent">PruDent</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Predict SVM scores
model &lt;- prudent(toyml)
pred &lt;- predict(model, toyml)

# Predict SVM bipartitions
pred &lt;- predict(model, toyml, probability = FALSE)

# Passing a specif parameter for SVM predict algorithm
pred &lt;- predict(model, toyml, na.action = na.fail)

</code></pre>

<hr>
<h2 id='predict.PSmodel'>Predict Method for Pruned Set Transformation</h2><span id='topic+predict.PSmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+ps">ps</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PSmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.PSmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>PSmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.PSmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.PSmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.PSmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.PSmodel_+3A_cores">cores</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="predict.PSmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ps">Pruned Set (PS)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- ps(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.RAkELmodel'>Predict Method for RAkEL</h2><span id='topic+predict.RAkELmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+rakel">rakel</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RAkELmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.RAkELmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>RAkELmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.RAkELmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.RAkELmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.RAkELmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.RAkELmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the prediction. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.RAkELmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rakel">Random k Labelsets (RAkEL)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- rakel(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='predict.RDBRmodel'>Predict Method for RDBR</h2><span id='topic+predict.RDBRmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by <code>rdbr</code>.
In general this method is a recursive version of
<code><a href="#topic+predict.DBRmodel">predict.DBRmodel</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RDBRmodel'
predict(
  object,
  newdata,
  estimative = NULL,
  max.iterations = 5,
  batch.mode = FALSE,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.RDBRmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>RDBRmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.RDBRmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.RDBRmodel_+3A_estimative">estimative</code></td>
<td>
<p>A matrix containing the bipartition result of other
multi-label classification algorithm or an mlresult object with the
predictions.</p>
</td></tr>
<tr><td><code id="predict.RDBRmodel_+3A_max.iterations">max.iterations</code></td>
<td>
<p>The maximum allowed iterations of the RDBR technique.
(Default: 5)</p>
</td></tr>
<tr><td><code id="predict.RDBRmodel_+3A_batch.mode">batch.mode</code></td>
<td>
<p>Logical value to determine if use the batch re-estimation.
If <code>FALSE</code> then use the stochastic re-estimation strategy.
(Default: <code>FALSE</code>)</p>
</td></tr>
<tr><td><code id="predict.RDBRmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.RDBRmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.RDBRmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.RDBRmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two versions of the update strategy of the estimated labels are implemented.
The batch re-estimates the labels only when a complete current label vector
is available. The stochastic uses re-estimated labels as soon as they become
available. This second does not support parallelize the prediction, however
stabilizes earlier than batch mode.
</p>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>References</h3>

<p>Rauber, T. W., Mello, L. H., Rocha, V. F., Luchi, D., &amp; Varejao, F. M.
(2014). Recursive Dependent Binary Relevance Model for Multi-label
Classification. In Advances in Artificial Intelligence - IBERAMIA, 206-217.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rdbr">Recursive Dependent Binary Relevance (RDBR)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Predict SVM scores
model &lt;- rdbr(toyml)
pred &lt;- predict(model, toyml)

# Passing a specif parameter for SVM predict algorithm
pred &lt;- predict(model, toyml, na.action = na.fail)

# Use the batch mode and increase the max number of iteration to 10
pred &lt;- predict(model, toyml, max.iterations = 10, batch.mode = TRUE)

# Using other classifier (EBR) to made the labels estimatives
estimative &lt;- predict(ebr(toyml), toyml, probability = FALSE)
model &lt;- rdbr(toyml, estimate.models = FALSE)
pred &lt;- predict(model, toyml, estimative = estimative)

</code></pre>

<hr>
<h2 id='predict.RPCmodel'>Predict Method for RPC</h2><span id='topic+predict.RPCmodel'></span>

<h3>Description</h3>

<p>This function predicts values based upon a model trained by
<code><a href="#topic+rpc">rpc</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RPCmodel'
predict(
  object,
  newdata,
  probability = getOption("utiml.use.probs", TRUE),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.RPCmodel_+3A_object">object</code></td>
<td>
<p>Object of class '<code>RPCmodel</code>'.</p>
</td></tr>
<tr><td><code id="predict.RPCmodel_+3A_newdata">newdata</code></td>
<td>
<p>An object containing the new input data. This must be a
matrix, data.frame or a mldr object.</p>
</td></tr>
<tr><td><code id="predict.RPCmodel_+3A_probability">probability</code></td>
<td>
<p>Logical indicating whether class probabilities should be
returned. (Default: <code>getOption("utiml.use.probs", TRUE)</code>)</p>
</td></tr>
<tr><td><code id="predict.RPCmodel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm prediction for all
subproblems.</p>
</td></tr>
<tr><td><code id="predict.RPCmodel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="predict.RPCmodel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of type mlresult, based on the parameter probability.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+br">Binary Relevance (BR)</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- rpc(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='print.BRmodel'>Print BR model</h2><span id='topic+print.BRmodel'></span>

<h3>Description</h3>

<p>Print BR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BRmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.BRmodel_+3A_x">x</code></td>
<td>
<p>The br model</p>
</td></tr>
<tr><td><code id="print.BRmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.BRPmodel'>Print BRP model</h2><span id='topic+print.BRPmodel'></span>

<h3>Description</h3>

<p>Print BRP model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'BRPmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.BRPmodel_+3A_x">x</code></td>
<td>
<p>The brp model</p>
</td></tr>
<tr><td><code id="print.BRPmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.CCmodel'>Print CC model</h2><span id='topic+print.CCmodel'></span>

<h3>Description</h3>

<p>Print CC model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CCmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.CCmodel_+3A_x">x</code></td>
<td>
<p>The cc model</p>
</td></tr>
<tr><td><code id="print.CCmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.CLRmodel'>Print CLR model</h2><span id='topic+print.CLRmodel'></span>

<h3>Description</h3>

<p>Print CLR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CLRmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.CLRmodel_+3A_x">x</code></td>
<td>
<p>The br model</p>
</td></tr>
<tr><td><code id="print.CLRmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.DBRmodel'>Print DBR model</h2><span id='topic+print.DBRmodel'></span>

<h3>Description</h3>

<p>Print DBR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DBRmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.DBRmodel_+3A_x">x</code></td>
<td>
<p>The dbr model</p>
</td></tr>
<tr><td><code id="print.DBRmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.EBRmodel'>Print EBR model</h2><span id='topic+print.EBRmodel'></span>

<h3>Description</h3>

<p>Print EBR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EBRmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.EBRmodel_+3A_x">x</code></td>
<td>
<p>The ebr model</p>
</td></tr>
<tr><td><code id="print.EBRmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.ECCmodel'>Print ECC model</h2><span id='topic+print.ECCmodel'></span>

<h3>Description</h3>

<p>Print ECC model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ECCmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ECCmodel_+3A_x">x</code></td>
<td>
<p>The ecc model</p>
</td></tr>
<tr><td><code id="print.ECCmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.EPSmodel'>Print EPS model</h2><span id='topic+print.EPSmodel'></span>

<h3>Description</h3>

<p>Print EPS model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'EPSmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.EPSmodel_+3A_x">x</code></td>
<td>
<p>The ps model</p>
</td></tr>
<tr><td><code id="print.EPSmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.ESLmodel'>Print ESL model</h2><span id='topic+print.ESLmodel'></span>

<h3>Description</h3>

<p>Print ESL model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ESLmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.ESLmodel_+3A_x">x</code></td>
<td>
<p>The esl model</p>
</td></tr>
<tr><td><code id="print.ESLmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.kFoldPartition'>Print a kFoldPartition object</h2><span id='topic+print.kFoldPartition'></span>

<h3>Description</h3>

<p>Print a kFoldPartition object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'kFoldPartition'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.kFoldPartition_+3A_x">x</code></td>
<td>
<p>The kFoldPartition object</p>
</td></tr>
<tr><td><code id="print.kFoldPartition_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print folds' detail
</p>

<hr>
<h2 id='print.LIFTmodel'>Print LIFT model</h2><span id='topic+print.LIFTmodel'></span>

<h3>Description</h3>

<p>Print LIFT model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LIFTmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.LIFTmodel_+3A_x">x</code></td>
<td>
<p>The lift model</p>
</td></tr>
<tr><td><code id="print.LIFTmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.LPmodel'>Print LP model</h2><span id='topic+print.LPmodel'></span>

<h3>Description</h3>

<p>Print LP model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'LPmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.LPmodel_+3A_x">x</code></td>
<td>
<p>The lp model</p>
</td></tr>
<tr><td><code id="print.LPmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.majorityModel'>Print Majority model</h2><span id='topic+print.majorityModel'></span>

<h3>Description</h3>

<p>Print Majority model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'majorityModel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.majorityModel_+3A_x">x</code></td>
<td>
<p>The base model</p>
</td></tr>
<tr><td><code id="print.majorityModel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.MBRmodel'>Print MBR model</h2><span id='topic+print.MBRmodel'></span>

<h3>Description</h3>

<p>Print MBR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MBRmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.MBRmodel_+3A_x">x</code></td>
<td>
<p>The mbr model</p>
</td></tr>
<tr><td><code id="print.MBRmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.mlconfmat'>Print a Multi-label Confusion Matrix</h2><span id='topic+print.mlconfmat'></span>

<h3>Description</h3>

<p>Print a Multi-label Confusion Matrix
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlconfmat'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mlconfmat_+3A_x">x</code></td>
<td>
<p>The mlconfmat</p>
</td></tr>
<tr><td><code id="print.mlconfmat_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print a confusion matrix
</p>

<hr>
<h2 id='print.MLKNNmodel'>Print MLKNN model</h2><span id='topic+print.MLKNNmodel'></span>

<h3>Description</h3>

<p>Print MLKNN model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'MLKNNmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.MLKNNmodel_+3A_x">x</code></td>
<td>
<p>The mlknn model</p>
</td></tr>
<tr><td><code id="print.MLKNNmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.mlresult'>Print the mlresult</h2><span id='topic+print.mlresult'></span>

<h3>Description</h3>

<p>Print the mlresult
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlresult'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mlresult_+3A_x">x</code></td>
<td>
<p>The mlresult to print</p>
</td></tr>
<tr><td><code id="print.mlresult_+3A_...">...</code></td>
<td>
<p>Extra parameters for print method</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print a prediction result
</p>

<hr>
<h2 id='print.NSmodel'>Print NS model</h2><span id='topic+print.NSmodel'></span>

<h3>Description</h3>

<p>Print NS model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'NSmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.NSmodel_+3A_x">x</code></td>
<td>
<p>The ns model</p>
</td></tr>
<tr><td><code id="print.NSmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.PPTmodel'>Print PPT model</h2><span id='topic+print.PPTmodel'></span>

<h3>Description</h3>

<p>Print PPT model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PPTmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.PPTmodel_+3A_x">x</code></td>
<td>
<p>The ppt model</p>
</td></tr>
<tr><td><code id="print.PPTmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.PruDentmodel'>Print PruDent model</h2><span id='topic+print.PruDentmodel'></span>

<h3>Description</h3>

<p>Print PruDent model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PruDentmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.PruDentmodel_+3A_x">x</code></td>
<td>
<p>The prudent model</p>
</td></tr>
<tr><td><code id="print.PruDentmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.PSmodel'>Print PS model</h2><span id='topic+print.PSmodel'></span>

<h3>Description</h3>

<p>Print PS model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'PSmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.PSmodel_+3A_x">x</code></td>
<td>
<p>The ps model</p>
</td></tr>
<tr><td><code id="print.PSmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.RAkELmodel'>Print RAkEL model</h2><span id='topic+print.RAkELmodel'></span>

<h3>Description</h3>

<p>Print RAkEL model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RAkELmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.RAkELmodel_+3A_x">x</code></td>
<td>
<p>The rakel model</p>
</td></tr>
<tr><td><code id="print.RAkELmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.randomModel'>Print Random model</h2><span id='topic+print.randomModel'></span>

<h3>Description</h3>

<p>Print Random model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'randomModel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.randomModel_+3A_x">x</code></td>
<td>
<p>The base model</p>
</td></tr>
<tr><td><code id="print.randomModel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.RDBRmodel'>Print RDBR model</h2><span id='topic+print.RDBRmodel'></span>

<h3>Description</h3>

<p>Print RDBR model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RDBRmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.RDBRmodel_+3A_x">x</code></td>
<td>
<p>The rdbr model</p>
</td></tr>
<tr><td><code id="print.RDBRmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='print.RPCmodel'>Print RPC model</h2><span id='topic+print.RPCmodel'></span>

<h3>Description</h3>

<p>Print RPC model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'RPCmodel'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.RPCmodel_+3A_x">x</code></td>
<td>
<p>The br model</p>
</td></tr>
<tr><td><code id="print.RPCmodel_+3A_...">...</code></td>
<td>
<p>ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='prudent'>PruDent classifier for multi-label Classification</h2><span id='topic+prudent'></span>

<h3>Description</h3>

<p>Create a PruDent classifier to predict multi-label data. To this, two
round of Binary Relevance is executed, such that, the first iteration
generates new attributes to enrich the second prediction.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>prudent(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  phi = 0,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="prudent_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="prudent_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="prudent_+3A_phi">phi</code></td>
<td>
<p>A value between 0 and 1 to determine the information gain. The
value 0 include all labels in the second phase and the 1 none.</p>
</td></tr>
<tr><td><code id="prudent_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="prudent_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="prudent_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the second phase only labels whose information gain is greater than a
specific phi value is added.
</p>


<h3>Value</h3>

<p>An object of class <code>PruDentmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>phi</dt><dd><p>The value of <code>phi</code> parameter.</p>
</dd>
<dt>IG</dt><dd><p>The matrix of Information Gain used in combination
with <code>phi</code> parameter to define the labels used in the second step.
</p>
</dd>
<dt>basemodel</dt><dd><p>The BRModel used in the first iteration.</p>
</dd>
<dt>metamodels</dt><dd><p>A list of models named by the label names used in the
second iteration.
</p>
</dd>
</dl>



<h3>References</h3>

<p>Alali, A., &amp; Kubat, M. (2015). PruDent: A Pruned and Confident Stacking
Approach for Multi-Label Classification. IEEE Transactions on Knowledge
and Data Engineering, 27(9), 2480-2493.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- prudent(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use different phi correlation with C5.0 classifier
model &lt;- prudent(toyml, 'C5.0', 0.3)

# Set a specific parameter
model &lt;- prudent(toyml, 'KNN', k=5)

</code></pre>

<hr>
<h2 id='ps'>Pruned Set for multi-label Classification</h2><span id='topic+ps'></span>

<h3>Description</h3>

<p>Create a Pruned Set model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ps(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  p = 3,
  strategy = c("A", "B"),
  b = 2,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ps_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="ps_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="ps_+3A_p">p</code></td>
<td>
<p>Number of instances to prune. All labelsets that occurs p times or
less in the training data is removed. (Default: 3)</p>
</td></tr>
<tr><td><code id="ps_+3A_strategy">strategy</code></td>
<td>
<p>The strategy  (A or B) for processing infrequent labelsets.
(Default: A).</p>
</td></tr>
<tr><td><code id="ps_+3A_b">b</code></td>
<td>
<p>The number used by the strategy for processing infrequent labelsets.</p>
</td></tr>
<tr><td><code id="ps_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="ps_+3A_cores">cores</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="ps_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Pruned Set (PS) is a multi-class transformation that remove the less common
classes to predict multi-label data.
</p>


<h3>Value</h3>

<p>An object of class <code>PSmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>model</dt><dd><p>A LP model contained only the most common labelsets.</p>
</dd>
</dl>



<h3>References</h3>

<p>Read, J., Pfahringer, B., &amp; Holmes, G. (2008). Multi-label classification
using ensembles of pruned sets. In Proceedings - IEEE International
Conference on Data Mining, ICDM (pp. 9951000).
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Powerset: 
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- ps(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


##Change default configurations
model &lt;- ps(toyml, "RF", p=4, strategy="B", b=1)

</code></pre>

<hr>
<h2 id='rakel'>Random k-labelsets for multilabel classification</h2><span id='topic+rakel'></span>

<h3>Description</h3>

<p>Create a RAkEL model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rakel(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  k = 3,
  m = 2 * mdata$measures$num.labels,
  overlapping = TRUE,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rakel_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="rakel_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="rakel_+3A_k">k</code></td>
<td>
<p>The number of labels used in each labelset. (Default: <code>3</code>)</p>
</td></tr>
<tr><td><code id="rakel_+3A_m">m</code></td>
<td>
<p>The number of LP models. Used when overlapping is TRUE, otherwise it
is ignored. (Default: <code>2 * length(labels)</code>)</p>
</td></tr>
<tr><td><code id="rakel_+3A_overlapping">overlapping</code></td>
<td>
<p>Logical value, that defines if the method must overlapping
the labelsets. If FALSE the method uses disjoint labelsets.
(Default: <code>TRUE</code>)</p>
</td></tr>
<tr><td><code id="rakel_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="rakel_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="rakel_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is running in parallel. (Default:
<code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RAndom k labELsets is an ensemble of LP models where each classifier is
trained with a small set of labels, called labelset. Two different strategies
for constructing the labelsets are the disjoint and overlapping labelsets.
</p>


<h3>Value</h3>

<p>An object of class <code>RAkELmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>labelsets</dt><dd><p>A list with the labelsets used to build the LP models.</p>
</dd>
<dt>model</dt><dd><p>A list of the generated models, named by the label names.</p>
</dd>
</dl>



<h3>References</h3>

<p>Tsoumakas, G., Katakis, I., &amp; Vlahavas, I. (2011). Random k-labelsets for
multilabel classification. IEEE Transactions on Knowledge and Data
Engineering, 23(7), 1079-1089.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>
<p>Other Powerset: 
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- rakel(toyml, "RANDOM")
pred &lt;- predict(model, toyml)

## SVM using k = 4 and m = 100
model &lt;- rakel(toyml, "SVM", k=4, m=100)

## Random Forest using disjoint labelsets
model &lt;- rakel(toyml, "RF", overlapping=FALSE)

</code></pre>

<hr>
<h2 id='rcut_threshold'>Rank Cut (RCut) threshold method</h2><span id='topic+rcut_threshold'></span><span id='topic+rcut_threshold.default'></span><span id='topic+rcut_threshold.mlresult'></span>

<h3>Description</h3>

<p>The Rank Cut (RCut) method is an instance-wise strategy, which outputs the k
labels with the highest scores for each instance at the deployment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rcut_threshold(prediction, k, probability = FALSE)

## Default S3 method:
rcut_threshold(prediction, k, probability = FALSE)

## S3 method for class 'mlresult'
rcut_threshold(prediction, k, probability = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rcut_threshold_+3A_prediction">prediction</code></td>
<td>
<p>A matrix or mlresult.</p>
</td></tr>
<tr><td><code id="rcut_threshold_+3A_k">k</code></td>
<td>
<p>The number of elements that will be positive.</p>
</td></tr>
<tr><td><code id="rcut_threshold_+3A_probability">probability</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values are
the score between 0 and 1, otherwise the values are bipartition 0 or 1.
(Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A mlresult object.
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Rank Cut (RCut) threshold method for matrix
</p>
</li>
<li> <p><code>mlresult</code>: Rank Cut (RCut) threshold method for mlresult
</p>
</li></ul>


<h3>References</h3>

<p>Al-Otaibi, R., Flach, P., &amp; Kull, M. (2014). Multi-label Classification: A
Comparative Study on Threshold Selection Methods. In First International
Workshop on Learning over Multiple Contexts (LMCE) at ECML-PKDD 2014.
</p>


<h3>See Also</h3>

<p>Other threshold: 
<code><a href="#topic+fixed_threshold">fixed_threshold</a>()</code>,
<code><a href="#topic+lcard_threshold">lcard_threshold</a>()</code>,
<code><a href="#topic+mcut_threshold">mcut_threshold</a>()</code>,
<code><a href="#topic+pcut_threshold">pcut_threshold</a>()</code>,
<code><a href="#topic+scut_threshold">scut_threshold</a>()</code>,
<code><a href="#topic+subset_correction">subset_correction</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prediction &lt;- matrix(runif(16), ncol = 4)
rcut_threshold(prediction, 2)
</code></pre>

<hr>
<h2 id='rdbr'>Recursive Dependent Binary Relevance (RDBR) for multi-label Classification</h2><span id='topic+rdbr'></span>

<h3>Description</h3>

<p>Create a RDBR classifier to predict multi-label data. This is a recursive
approach that enables the binary classifiers to discover existing label
dependency by themselves. The idea of RDBR is running DBR recursively until
the results stabilization of the result.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rdbr(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  estimate.models = TRUE,
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rdbr_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="rdbr_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="rdbr_+3A_estimate.models">estimate.models</code></td>
<td>
<p>Logical value indicating whether is necessary build
Binary Relevance classifier for estimate process. The default implementation
use BR as estimators, however when other classifier is desirable then use
the value <code>FALSE</code> to skip this process. (Default: <code>TRUE</code>).</p>
</td></tr>
<tr><td><code id="rdbr_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems.</p>
</td></tr>
<tr><td><code id="rdbr_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="rdbr_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The train method is exactly the same of DBR the recursion is in the predict
method.
</p>


<h3>Value</h3>

<p>An object of class <code>RDBRmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>estimation</dt><dd><p>The BR model to estimate the values for the labels.
Only when the <code>estimate.models = TRUE</code>.</p>
</dd>
<dt>models</dt><dd><p>A list of final models named by the label names.</p>
</dd>
</dl>



<h3>References</h3>

<p>Rauber, T. W., Mello, L. H., Rocha, V. F., Luchi, D., &amp; Varejao, F. M.
(2014). Recursive Dependent Binary Relevance Model for Multi-label
Classification. In Advances in Artificial Intelligence - IBERAMIA, 206-217.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dbr">Dependent Binary Relevance (DBR)</a></code>
</p>
<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rpc">rpc</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- rdbr(toyml, "RANDOM")
pred &lt;- predict(model, toyml)


# Use Random Forest as base algorithm and 2 cores
model &lt;- rdbr(toyml, 'RF', cores = 2, seed = 123)

</code></pre>

<hr>
<h2 id='remove_attributes'>Remove attributes from the dataset</h2><span id='topic+remove_attributes'></span>

<h3>Description</h3>

<p>Remove specified attributes generating a new multi-label dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_attributes(mdata, attributes)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_attributes_+3A_mdata">mdata</code></td>
<td>
<p>The mldr dataset to remove labels.</p>
</td></tr>
<tr><td><code id="remove_attributes_+3A_attributes">attributes</code></td>
<td>
<p>Attributes indexes or attributes names to be removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new mldr object.
</p>


<h3>Note</h3>

<p>If invalid attributes names or indexes were informed, they will be
ignored.
</p>


<h3>See Also</h3>

<p>Other pre process: 
<code><a href="#topic+fill_sparse_mldata">fill_sparse_mldata</a>()</code>,
<code><a href="#topic+normalize_mldata">normalize_mldata</a>()</code>,
<code><a href="#topic+remove_labels">remove_labels</a>()</code>,
<code><a href="#topic+remove_skewness_labels">remove_skewness_labels</a>()</code>,
<code><a href="#topic+remove_unique_attributes">remove_unique_attributes</a>()</code>,
<code><a href="#topic+remove_unlabeled_instances">remove_unlabeled_instances</a>()</code>,
<code><a href="#topic+replace_nominal_attributes">replace_nominal_attributes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toyml1 &lt;- remove_attributes(toyml, c("iatt8","iatt9", "ratt10"))
toyml2 &lt;- remove_attributes(toyml, 10)
</code></pre>

<hr>
<h2 id='remove_labels'>Remove labels from the dataset</h2><span id='topic+remove_labels'></span>

<h3>Description</h3>

<p>Remove specified labels generating a new multi-label dataset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_labels(mdata, labels)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_labels_+3A_mdata">mdata</code></td>
<td>
<p>The mldr dataset to remove labels.</p>
</td></tr>
<tr><td><code id="remove_labels_+3A_labels">labels</code></td>
<td>
<p>Label indexes or label names to be removed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new mldr object.
</p>


<h3>Note</h3>

<p>If invalid labels names or indexes were informed, they will be ignored.
</p>


<h3>See Also</h3>

<p>Other pre process: 
<code><a href="#topic+fill_sparse_mldata">fill_sparse_mldata</a>()</code>,
<code><a href="#topic+normalize_mldata">normalize_mldata</a>()</code>,
<code><a href="#topic+remove_attributes">remove_attributes</a>()</code>,
<code><a href="#topic+remove_skewness_labels">remove_skewness_labels</a>()</code>,
<code><a href="#topic+remove_unique_attributes">remove_unique_attributes</a>()</code>,
<code><a href="#topic+remove_unlabeled_instances">remove_unlabeled_instances</a>()</code>,
<code><a href="#topic+replace_nominal_attributes">replace_nominal_attributes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>toyml1 &lt;- remove_labels(toyml, c("y1","y5"))
toyml2 &lt;- remove_labels(toyml, c(11, 15))
</code></pre>

<hr>
<h2 id='remove_skewness_labels'>Remove unusual or very common labels</h2><span id='topic+remove_skewness_labels'></span>

<h3>Description</h3>

<p>Remove the labels that have smaller number of positive or negative examples
based on a specific threshold value.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_skewness_labels(mdata, t = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_skewness_labels_+3A_mdata">mdata</code></td>
<td>
<p>The mldr dataset to remove the skewness labels.</p>
</td></tr>
<tr><td><code id="remove_skewness_labels_+3A_t">t</code></td>
<td>
<p>Threshold value. Number of minimum examples positive and negative.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new mldr object.
</p>


<h3>See Also</h3>

<p>Other pre process: 
<code><a href="#topic+fill_sparse_mldata">fill_sparse_mldata</a>()</code>,
<code><a href="#topic+normalize_mldata">normalize_mldata</a>()</code>,
<code><a href="#topic+remove_attributes">remove_attributes</a>()</code>,
<code><a href="#topic+remove_labels">remove_labels</a>()</code>,
<code><a href="#topic+remove_unique_attributes">remove_unique_attributes</a>()</code>,
<code><a href="#topic+remove_unlabeled_instances">remove_unlabeled_instances</a>()</code>,
<code><a href="#topic+replace_nominal_attributes">replace_nominal_attributes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>remove_skewness_labels(toyml, 20)
</code></pre>

<hr>
<h2 id='remove_unique_attributes'>Remove unique attributes</h2><span id='topic+remove_unique_attributes'></span>

<h3>Description</h3>

<p>Remove the attributes that have a single value for all instances. Empty and
NA values are considered different values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_unique_attributes(mdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_unique_attributes_+3A_mdata">mdata</code></td>
<td>
<p>The mldr dataset to remove.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new mldr object.
</p>


<h3>See Also</h3>

<p>Other pre process: 
<code><a href="#topic+fill_sparse_mldata">fill_sparse_mldata</a>()</code>,
<code><a href="#topic+normalize_mldata">normalize_mldata</a>()</code>,
<code><a href="#topic+remove_attributes">remove_attributes</a>()</code>,
<code><a href="#topic+remove_labels">remove_labels</a>()</code>,
<code><a href="#topic+remove_skewness_labels">remove_skewness_labels</a>()</code>,
<code><a href="#topic+remove_unlabeled_instances">remove_unlabeled_instances</a>()</code>,
<code><a href="#topic+replace_nominal_attributes">replace_nominal_attributes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>alt.toy &lt;- toyml
alt.toy$dataset$ratt10 &lt;- mean(alt.toy$dataset$ratt10)
new.toy &lt;- remove_unique_attributes(alt.toy)
</code></pre>

<hr>
<h2 id='remove_unlabeled_instances'>Remove examples without labels</h2><span id='topic+remove_unlabeled_instances'></span>

<h3>Description</h3>

<p>Remove the examples that do not have labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>remove_unlabeled_instances(mdata)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="remove_unlabeled_instances_+3A_mdata">mdata</code></td>
<td>
<p>The mldr dataset to remove the instances.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new mldr object.
</p>


<h3>See Also</h3>

<p>Other pre process: 
<code><a href="#topic+fill_sparse_mldata">fill_sparse_mldata</a>()</code>,
<code><a href="#topic+normalize_mldata">normalize_mldata</a>()</code>,
<code><a href="#topic+remove_attributes">remove_attributes</a>()</code>,
<code><a href="#topic+remove_labels">remove_labels</a>()</code>,
<code><a href="#topic+remove_skewness_labels">remove_skewness_labels</a>()</code>,
<code><a href="#topic+remove_unique_attributes">remove_unique_attributes</a>()</code>,
<code><a href="#topic+replace_nominal_attributes">replace_nominal_attributes</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>new.toy &lt;- remove_labels(toyml, c(12,14))
remove_unlabeled_instances(new.toy)
</code></pre>

<hr>
<h2 id='replace_nominal_attributes'>Replace nominal attributes
Replace the nominal attributes by binary attributes.</h2><span id='topic+replace_nominal_attributes'></span>

<h3>Description</h3>

<p>Replace nominal attributes
Replace the nominal attributes by binary attributes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>replace_nominal_attributes(mdata, ordinal.attributes = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="replace_nominal_attributes_+3A_mdata">mdata</code></td>
<td>
<p>The mldr dataset to remove.</p>
</td></tr>
<tr><td><code id="replace_nominal_attributes_+3A_ordinal.attributes">ordinal.attributes</code></td>
<td>
<p>Not yet, but it will be used to specify which
attributes need to be replaced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a new mldr object.
</p>


<h3>See Also</h3>

<p>Other pre process: 
<code><a href="#topic+fill_sparse_mldata">fill_sparse_mldata</a>()</code>,
<code><a href="#topic+normalize_mldata">normalize_mldata</a>()</code>,
<code><a href="#topic+remove_attributes">remove_attributes</a>()</code>,
<code><a href="#topic+remove_labels">remove_labels</a>()</code>,
<code><a href="#topic+remove_skewness_labels">remove_skewness_labels</a>()</code>,
<code><a href="#topic+remove_unique_attributes">remove_unique_attributes</a>()</code>,
<code><a href="#topic+remove_unlabeled_instances">remove_unlabeled_instances</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>new.toy &lt;- toyml
new.column &lt;- as.factor(sample(c("a","b","c"), 100, replace = TRUE))
new.toy$dataset$ratt10 &lt;- new.column
head(replace_nominal_attributes(new.toy))
</code></pre>

<hr>
<h2 id='rpc'>Ranking by Pairwise Comparison (RPC) for multi-label Classification</h2><span id='topic+rpc'></span>

<h3>Description</h3>

<p>Create a RPC model for multilabel classification.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rpc(
  mdata,
  base.algorithm = getOption("utiml.base.algorithm", "SVM"),
  ...,
  cores = getOption("utiml.cores", 1),
  seed = getOption("utiml.seed", NA)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rpc_+3A_mdata">mdata</code></td>
<td>
<p>A mldr dataset used to train the binary models.</p>
</td></tr>
<tr><td><code id="rpc_+3A_base.algorithm">base.algorithm</code></td>
<td>
<p>A string with the name of the base algorithm. (Default:
<code>options("utiml.base.algorithm", "SVM")</code>)</p>
</td></tr>
<tr><td><code id="rpc_+3A_...">...</code></td>
<td>
<p>Others arguments passed to the base algorithm for all subproblems</p>
</td></tr>
<tr><td><code id="rpc_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the training. Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
<tr><td><code id="rpc_+3A_seed">seed</code></td>
<td>
<p>An optional integer used to set the seed. This is useful when
the method is run in parallel. (Default: <code>options("utiml.seed", NA)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RPC is a simple transformation method that uses pairwise classification to
predict multi-label data. This is based on the one-versus-one approach to
build a specific model for each label combination.
</p>


<h3>Value</h3>

<p>An object of class <code>RPCmodel</code> containing the set of fitted
models, including:
</p>

<dl>
<dt>labels</dt><dd><p>A vector with the label names.</p>
</dd>
<dt>models</dt><dd><p>A list of the generated models, named by the label names.</p>
</dd>
</dl>



<h3>References</h3>

<p>Hullermeier, E., Furnkranz, J., Cheng, W., &amp; Brinker, K. (2008).
Label ranking by learning pairwise preferences. Artificial Intelligence,
172(16-17), 1897-1916.
</p>


<h3>See Also</h3>

<p>Other Transformation methods: 
<code><a href="#topic+brplus">brplus</a>()</code>,
<code><a href="#topic+br">br</a>()</code>,
<code><a href="#topic+cc">cc</a>()</code>,
<code><a href="#topic+clr">clr</a>()</code>,
<code><a href="#topic+dbr">dbr</a>()</code>,
<code><a href="#topic+ebr">ebr</a>()</code>,
<code><a href="#topic+ecc">ecc</a>()</code>,
<code><a href="#topic+eps">eps</a>()</code>,
<code><a href="#topic+esl">esl</a>()</code>,
<code><a href="#topic+homer">homer</a>()</code>,
<code><a href="#topic+lift">lift</a>()</code>,
<code><a href="#topic+lp">lp</a>()</code>,
<code><a href="#topic+mbr">mbr</a>()</code>,
<code><a href="#topic+ns">ns</a>()</code>,
<code><a href="#topic+ppt">ppt</a>()</code>,
<code><a href="#topic+prudent">prudent</a>()</code>,
<code><a href="#topic+ps">ps</a>()</code>,
<code><a href="#topic+rakel">rakel</a>()</code>,
<code><a href="#topic+rdbr">rdbr</a>()</code>
</p>
<p>Other Pairwise methods: 
<code><a href="#topic+clr">clr</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>model &lt;- rpc(toyml, "RANDOM")
pred &lt;- predict(model, toyml)
</code></pre>

<hr>
<h2 id='scut_threshold'>SCut Score-based method</h2><span id='topic+scut_threshold'></span><span id='topic+scut_threshold.default'></span><span id='topic+scut_threshold.mlresult'></span>

<h3>Description</h3>

<p>This is a label-wise method that adjusts the threshold for each label to
achieve a specific loss function using a validation set or cross validation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>scut_threshold(
  prediction,
  expected,
  loss.function = NA,
  cores = getOption("utiml.cores", 1)
)

## Default S3 method:
scut_threshold(
  prediction,
  expected,
  loss.function = NA,
  cores = getOption("utiml.cores", 1)
)

## S3 method for class 'mlresult'
scut_threshold(
  prediction,
  expected,
  loss.function = NA,
  cores = getOption("utiml.cores", 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scut_threshold_+3A_prediction">prediction</code></td>
<td>
<p>A matrix or mlresult.</p>
</td></tr>
<tr><td><code id="scut_threshold_+3A_expected">expected</code></td>
<td>
<p>The expected labels for the prediction. May be a matrix with
the label values or a mldr object.</p>
</td></tr>
<tr><td><code id="scut_threshold_+3A_loss.function">loss.function</code></td>
<td>
<p>A loss function to be optimized. If you want to use your
own error function see the notes and example. (Default: Mean Squared Error)</p>
</td></tr>
<tr><td><code id="scut_threshold_+3A_cores">cores</code></td>
<td>
<p>The number of cores to parallelize the computation Values higher
than 1 require the <span class="pkg">parallel</span> package. (Default:
<code>options("utiml.cores", 1)</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Different from the others threshold methods instead of return the bipartition
results, it returns the threshold values for each label.
</p>


<h3>Value</h3>

<p>A numeric vector with the threshold values for each label
</p>


<h3>Methods (by class)</h3>


<ul>
<li> <p><code>default</code>: Default scut_threshold
</p>
</li>
<li> <p><code>mlresult</code>: Mlresult scut_threshold
</p>
</li></ul>


<h3>Note</h3>

<p>The loss function is a R method that receive two vectors, the expected
values of the label and the predicted values, respectively. Positive values
are represented by the 1 and the negative by the 0.
</p>


<h3>References</h3>

<p>Fan, R.-E., &amp; Lin, C.-J. (2007). A study on threshold selection for
multi-label classification. Department of Computer Science, National
Taiwan University.
</p>
<p>Al-Otaibi, R., Flach, P., &amp; Kull, M. (2014). Multi-label Classification: A
Comparative Study on Threshold Selection Methods. In First International
Workshop on Learning over Multiple Contexts (LMCE) at ECML-PKDD 2014.
</p>


<h3>See Also</h3>

<p>Other threshold: 
<code><a href="#topic+fixed_threshold">fixed_threshold</a>()</code>,
<code><a href="#topic+lcard_threshold">lcard_threshold</a>()</code>,
<code><a href="#topic+mcut_threshold">mcut_threshold</a>()</code>,
<code><a href="#topic+pcut_threshold">pcut_threshold</a>()</code>,
<code><a href="#topic+rcut_threshold">rcut_threshold</a>()</code>,
<code><a href="#topic+subset_correction">subset_correction</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>names &lt;- list(1:10, c("a", "b", "c"))
prediction &lt;- matrix(runif(30), ncol = 3, dimnames = names)
classes &lt;- matrix(sample(0:1, 30, rep = TRUE), ncol = 3, dimnames = names)
thresholds &lt;- scut_threshold(prediction, classes)
fixed_threshold(prediction, thresholds)


# Penalizes only FP predictions
mylossfunc &lt;- function (real, predicted) {
   mean(predicted - real * predicted)
}
prediction &lt;- predict(br(toyml, "RANDOM"), toyml)
scut_threshold(prediction, toyml, loss.function = mylossfunc, cores = 2)

</code></pre>

<hr>
<h2 id='subset_correction'>Subset Correction of a predicted result</h2><span id='topic+subset_correction'></span>

<h3>Description</h3>

<p>This method restrict a multi-label learner to predict only label combinations
whose existence is present in the (training) data. To this all labelsets
that are predicted but are not found on training data is replaced by the most
similar labelset.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>subset_correction(mlresult, train_y, probability = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="subset_correction_+3A_mlresult">mlresult</code></td>
<td>
<p>An object of mlresult that contain the scores and bipartition
values.</p>
</td></tr>
<tr><td><code id="subset_correction_+3A_train_y">train_y</code></td>
<td>
<p>A matrix/data.frame with all labels values of the training
dataset or a mldr train dataset.</p>
</td></tr>
<tr><td><code id="subset_correction_+3A_probability">probability</code></td>
<td>
<p>A logical value. If <code>TRUE</code> the predicted values are
the score between 0 and 1, otherwise the values are bipartition 0 or 1.
(Default: <code>FALSE</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the most similar is not unique, those label combinations with higher
frequency in the training data are preferred. The Hamming loss distance is
used to determine the difference between the labelsets.
</p>


<h3>Value</h3>

<p>A new mlresult where all results are present in the training
labelsets.
</p>


<h3>Note</h3>

<p>The original paper describes a method to create only bipartitions
result, but we adapted the method to change the scores. Based on the
base.threshold value the scores higher than the threshold value, but must be
lower are changed to respect this restriction. If <code>NULL</code> this
correction will be ignored.
</p>


<h3>References</h3>

<p>Senge, R., Coz, J. J. del, &amp; Hullermeier, E. (2013). Rectifying classifier
chains for multi-label classification. In Workshop of Lernen, Wissen &amp;
Adaptivitat (LWA 2013) (pp. 162-169). Bamberg, Germany.
</p>


<h3>See Also</h3>

<p>Other threshold: 
<code><a href="#topic+fixed_threshold">fixed_threshold</a>()</code>,
<code><a href="#topic+lcard_threshold">lcard_threshold</a>()</code>,
<code><a href="#topic+mcut_threshold">mcut_threshold</a>()</code>,
<code><a href="#topic+pcut_threshold">pcut_threshold</a>()</code>,
<code><a href="#topic+rcut_threshold">rcut_threshold</a>()</code>,
<code><a href="#topic+scut_threshold">scut_threshold</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>prediction &lt;- predict(br(toyml, "RANDOM"), toyml)
subset_correction(prediction, toyml)
</code></pre>

<hr>
<h2 id='summary.mltransformation'>Summary method for mltransformation</h2><span id='topic+summary.mltransformation'></span>

<h3>Description</h3>

<p>Summary method for mltransformation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mltransformation'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.mltransformation_+3A_object">object</code></td>
<td>
<p>A transformed dataset</p>
</td></tr>
<tr><td><code id="summary.mltransformation_+3A_...">...</code></td>
<td>
<p>additional arguments affecting the summary produced.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>No return value, called for print model's detail
</p>

<hr>
<h2 id='toyml'>Toy multi-label dataset.</h2><span id='topic+toyml'></span>

<h3>Description</h3>

<p>A toy multi-label dataset is a synthetic dataset generated by the tool
<a href="http://sites.labic.icmc.usp.br/mldatagen/">http://sites.labic.icmc.usp.br/mldatagen/</a> using the Hyperspheres
strategy. Its purpose is to be used for small tests and examples.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>toyml
</code></pre>


<h3>Format</h3>

<p>A mldr object with 100 instances, 10 features and 5 labels:
</p>

<dl>
<dt>att1</dt><dd><p>Relevant numeric attribute between (-1 and 1)</p>
</dd>
<dt>att2</dt><dd><p>Relevant numeric attribute between (-1 and 1)</p>
</dd>
<dt>att3</dt><dd><p>Relevant numeric attribute between (-1 and 1)</p>
</dd>
<dt>att4</dt><dd><p>Relevant numeric attribute between (-1 and 1)</p>
</dd>
<dt>att5</dt><dd><p>Relevant numeric attribute between (-1 and 1)</p>
</dd>
<dt>att6</dt><dd><p>Relevant numeric attribute between (-1 and 1)</p>
</dd>
<dt>att7</dt><dd><p>Relevant numeric attribute between (-1 and 1)</p>
</dd>
<dt>iatt8</dt><dd><p>Irrelevant numeric attribute between (-1 and 1)</p>
</dd>
<dt>iatt9</dt><dd><p>Irrelevant numeric attribute between (-1 and 1)</p>
</dd>
<dt>ratt10</dt><dd><p>Redundant numeric attribute between (-1 and 1)</p>
</dd>
<dt>y1</dt><dd><p>Label 'y1' - Frequency: 0.17</p>
</dd>
<dt>y2</dt><dd><p>Label 'y2' - Frequency: 0.78</p>
</dd>
<dt>y3</dt><dd><p>Label 'y3' - Frequency: 0.19</p>
</dd>
<dt>y4</dt><dd><p>Label 'y4' - Frequency: 0.69</p>
</dd>
<dt>y5</dt><dd><p>Label 'y5' - Frequency: 0.17</p>
</dd>
</dl>



<h3>Details</h3>

<p>General Information
</p>

<ul>
<li><p> Cardinality: 2
</p>
</li>
<li><p> Density: 0.4
</p>
</li>
<li><p> Distinct multi-labels: 18
</p>
</li>
<li><p> Number of single labelsets: 5
</p>
</li>
<li><p> Max frequency: 23
</p>
</li></ul>



<h3>Source</h3>

<p>Generated by <a href="http://sites.labic.icmc.usp.br/mldatagen/">http://sites.labic.icmc.usp.br/mldatagen/</a>
Configuration:
</p>

<ul>
<li><p> Strategy: Hyperspheres
</p>
</li>
<li><p> Relevant Features: 7
</p>
</li>
<li><p> Irrelevant Features: 2
</p>
</li>
<li><p> Redundant Features: 1
</p>
</li>
<li><p> Number of Labels (q): 5
</p>
</li>
<li><p> Number of Instances: 100
</p>
</li>
<li><p> Noise (from 0 to 1): 0.05
</p>
</li>
<li><p> Maximum Radius/Half-Edge of the Hyperspheres/Hypercubes: 0.8
</p>
</li>
<li><p> Minimum Radius/Half-Edge of the Hyperspheres/Hypercubes: ((q/10)+1)/q
</p>
</li></ul>


<hr>
<h2 id='utiml'>utiml: Utilities for Multi-Label Learning</h2><span id='topic+utiml'></span>

<h3>Description</h3>

<p>The utiml package is a framework for the application of classification
algorithms to multi-label data. Like the well known MULAN used with Weka, it
provides a set of multi-label procedures such as sampling methods,
transformation strategies, threshold functions, pre-processing techniques and
evaluation metrics. The package was designed to allow users to easily
perform complete multi-label classification experiments in the R environment.
</p>


<h3>Details</h3>

<p>Currently, the main methods supported are:
</p>

<ol>
<li>
<p><strong>Classification methods</strong>:
<code><a href="#topic+baseline">ML Baselines</a></code>,
<code><a href="#topic+br">Binary Relevance (BR)</a></code>,
<code><a href="#topic+brplus">BR+</a></code>,
<code><a href="#topic+cc">Classifier Chains</a></code>,
<code><a href="#topic+clr">Calibrated Label Ranking (CLR)</a></code>,
<code><a href="#topic+dbr">Dependent Binary Relevance (DBR)</a></code>,
<code><a href="#topic+ebr">Ensemble of Binary Relevance (EBR)</a></code>,
<code><a href="#topic+ecc">Ensemble of Classifier Chains (ECC)</a></code>,
<code><a href="#topic+eps">Ensemble of Pruned Set (EPS)</a></code>,
<code><a href="#topic+homer">Hierarchy Of Multilabel classifiER (HOMER)</a></code>,
<code><a href="#topic+lift">Label specIfic FeaTures (LIFT)</a></code>,
<code><a href="#topic+lp">Label Powerset (LP)</a></code>,
<code><a href="#topic+mbr">Meta-Binary Relevance (MBR or 2BR)</a></code>,
<code><a href="#topic+mlknn">Multi-label KNN (ML-KNN)</a></code>,
<code><a href="#topic+ns">Nested Stacking (NS)</a></code>,
<code><a href="#topic+ppt">Pruned Problem Transformation (PPT)</a></code>,
<code><a href="#topic+prudent">Pruned and Confident Stacking Approach (Prudent)</a></code>,
<code><a href="#topic+ps">Pruned Set (PS)</a></code>,
<code><a href="#topic+rakel">Random k-labelsets (RAkEL)</a></code>,
<code><a href="#topic+rdbr">Recursive Dependent Binary Relevance (RDBR)</a></code>,
<code><a href="#topic+rpc">Ranking by Pairwise Comparison (RPC)</a></code>

</p>
</li>
<li>
<p><strong>Evaluation methods</strong>:
<code><a href="#topic+cv">Performing a cross-validation procedure</a></code>,
<code><a href="#topic+multilabel_confusion_matrix">Confusion Matrix</a></code>,
<code><a href="#topic+multilabel_evaluate">Evaluate</a></code>,
<code><a href="#topic+multilabel_measures">Supported measures</a></code>

</p>
</li>
<li>
<p><strong>Pre-process utilities</strong>:
<code><a href="#topic+fill_sparse_mldata">Fill sparse data</a></code>,
<code><a href="#topic+normalize_mldata">Normalize data</a></code>,
<code><a href="#topic+remove_attributes">Remove attributes</a></code>,
<code><a href="#topic+remove_labels">Remove labels</a></code>,
<code><a href="#topic+remove_skewness_labels">Remove skewness labels</a></code>,
<code><a href="#topic+remove_unique_attributes">Remove unique attributes</a></code>,
<code><a href="#topic+remove_unlabeled_instances">Remove unlabeled instances</a></code>,
<code><a href="#topic+replace_nominal_attributes">Replace nominal attributes</a></code>

</p>
</li>
<li>
<p><strong>Sampling methods</strong>:
<code><a href="#topic+create_holdout_partition">Create holdout partitions</a></code>,
<code><a href="#topic+create_kfold_partition">Create k-fold partitions</a></code>,
<code><a href="#topic+create_random_subset">Create random subset</a></code>,
<code><a href="#topic+create_subset">Create subset</a></code>,
<code><a href="#topic+partition_fold">Partition fold</a></code>

</p>
</li>
<li>
<p><strong>Threshold methods</strong>:
<code><a href="#topic+fixed_threshold">Fixed threshold</a></code>,
<code><a href="#topic+lcard_threshold">Cardinality threshold</a></code>,
<code><a href="#topic+mcut_threshold">MCUT</a></code>,
<code><a href="#topic+pcut_threshold">PCUT</a></code>,
<code><a href="#topic+rcut_threshold">RCUT</a></code>,
<code><a href="#topic+scut_threshold">SCUT</a></code>,
<code><a href="#topic+subset_correction">Subset correction</a></code>

</p>
</li></ol>

<p>However, there are other utilities methods not previously cited as
<code><a href="#topic+as.bipartition">as.bipartition</a></code>, <code><a href="#topic+as.mlresult">as.mlresult</a></code>,
<code><a href="#topic+as.ranking">as.ranking</a></code>, <code><a href="#topic+multilabel_prediction">multilabel_prediction</a></code>, etc. More
details and examples are available on
<a href="https://github.com/rivolli/utiml">utiml repository</a>.
</p>


<h3>Notes</h3>

<p>We use the <code><a href="mldr.html#topic+mldr">mldr</a></code> package, to manipulate multi-label data.
See its documentation to more information about handle multi-label dataset.
</p>


<h3>Cite as</h3>

<pre>
  @article{RJ-2018-041,
     author = {Adriano Rivolli and Andre C. P. L. F. de Carvalho},
     title = {{The utiml Package: Multi-label Classification in R}},
     year = {2018},
     journal = {{The R Journal}},
     doi = {10.32614/RJ-2018-041},
     url = {https://doi.org/10.32614/RJ-2018-041},
     pages = {24--37},
     volume = {10},
     number = {2}
 }</pre>


<h3>Author(s)</h3>


<ul>
<li><p> Adriano Rivolli &lt;rivolli@utfpr.edu.br&gt;
</p>
</li></ul>

<p>This package is a result of my PhD at Institute of Mathematics and Computer
Sciences (ICMC) at the University of Sao Paulo, Brazil.
</p>
<p>PhD advisor: Andre C. P. L. F. de Carvalho
</p>

<hr>
<h2 id='utiml_measure_names'>Return the name of measures</h2><span id='topic+utiml_measure_names'></span>

<h3>Description</h3>

<p>Return the name of measures
</p>


<h3>Usage</h3>

<pre><code class='language-R'>utiml_measure_names(measures = c("all"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="utiml_measure_names_+3A_measures">measures</code></td>
<td>
<p>The group of measures (Default: &quot;all&quot;).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>array of character contained the measures names.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>utiml_measure_names()
utiml_measure_names("bipartition")
utiml_measure_names(c("micro-based", "macro-based"))

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
