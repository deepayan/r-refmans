<!DOCTYPE html><html><head><title>Help for package raters</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {raters}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#concordance'><p>Inter-rater agreement among a set of raters for nominal data</p>
</a></li>
<li><a href='#diagnostic'><p>Frequency of assignment of patients to diagnostic categories</p></a></li>
<li><a href='#raters-package'>
<p>A Modification of Fleiss' Kappa in case of Nominal and Ordinal Variables</p></a></li>
<li><a href='#uterine'><p>Variability in classification of carcinoma in situ of the</p>
uterine cervix
</a></li>
<li><a href='#winetable'>
<p>Sensory wine evaluation</p></a></li>
<li><a href='#wlin.conc'><p>Inter-rater agreement among a set of raters for ordinal data using linear weights</p>
</a></li>
<li><a href='#wquad.conc'><p>Inter-rater agreement among a set of raters for ordinal data using quadratic weights</p>
</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A Modification of Fleiss' Kappa in Case of Nominal and Ordinal
Variables</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.3</td>
</tr>
<tr>
<td>Author:</td>
<td>Daniele Giardiello [cre],
  Piero Quatto [aut],
  Enrico Ripamonti [aut],
  Stefano Vigliani [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Daniele Giardiello &lt;daniele.giardiello1@gmail.com&gt;</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Description:</td>
<td>The kappa statistic implemented by Fleiss is a very popular index for assessing the reliability of agreement among multiple observers. It is used both in the psychological and in the psychiatric field. Other fields of application are typically medicine, biology and engineering. Unfortunately,the kappa statistic may behave inconsistently in case of strong agreement between raters, since this index assumes lower values than it would have been expected. We propose a modification kappa implemented by Fleiss in case of nominal and ordinal variables. Monte Carlo simulations are used both to testing statistical hypotheses and to calculating percentile bootstrap confidence intervals based on proposed statistic in case of nominal and ordinal data.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-08-19 15:54:11 UTC; danie</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-08-19 16:10:05 UTC</td>
</tr>
</table>
<hr>
<h2 id='concordance'>Inter-rater agreement among a set of raters for nominal data

</h2><span id='topic+concordance'></span>

<h3>Description</h3>

<p>Computes a statistic as an index of inter-rater agreement among a set of raters in case of nominal data.  This procedure is based on a statistic not affected by paradoxes of Kappa.  
It is also possible to get the confidence interval at level alpha using the percentile Bootstrap and to evaluate if the agreement is nil using the test argument.
The p value can be approximated using the Normal, Chi squared distribution or using Monte Carlo algorithm.
Normal approximation and Monte Carlo procedure can be calculated
even though the number of observers is not the same for each evaluated subject.
Fleiss Kappa is also shown and its confidence interval, standard error and pvalue using Normal approximation are
available when the number of observes is the same for each classified subject and the test argument is specified.
The functions <code>wlin.conc</code> and <code>wquad.conc</code> can be used in case of ordinal data using linear or quadratic weight matrix, respectively.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>concordance(db, test = "Default", B = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="concordance_+3A_db">db</code></td>
<td>
<p>n*c matrix or data frame, n subjects c categories. The numbers inside the matrix or data frame indicate how many raters chose a specific category for a given subject.  A sum of row indicates the total number of raters who evaluated a given subject. </p>
</td></tr>
<tr><td><code id="concordance_+3A_test">test</code></td>
<td>
<p>Statistical test to evaluate if the raters make random assignment regardless of the characteristic of each subject. Under null hypothesis, it corresponds to a high percentage of assignment errors. Thus, the expected agreement is weak.
Normal approximation is advisable when the number of subject is pretty large while a Chi square approximation when the number of raters is large.
Monte Carlo test is useful for small samples even though the higher number of simulations, the more time the procedure takes.
If test is not mentioned, no test will be computed. 
</p>
</td></tr>
<tr><td><code id="concordance_+3A_b">B</code></td>
<td>
<p> Number of iterations for the percentile Bootstrap and for Monte Carlo test.</p>
</td></tr>   
<tr><td><code id="concordance_+3A_alpha">alpha</code></td>
<td>
<p> Level of significance for Bootstrap confidence interval</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>$Fleiss</code></td>
<td>
<p>A list with Kappa of Fleiss index. When the number of raters is the same for every evaluated subject, the standard deviation, the Z Wald test and the p value are also shown.</p>
</td></tr>
<tr><td><code>$Statistic</code></td>
<td>
<p>A list with the index of inter-rater agreement not affected by Kappa paradoxes and the percentile Bootstrap confidence interval. If the test argument is specified the p value is also shown. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Piero Quatto <a href="mailto:piero.quatto@unimib.it">piero.quatto@unimib.it</a>,
Daniele Giardiello <a href="mailto:daniele.giardiello1@gmail.com">daniele.giardiello1@gmail.com</a>
Stefano Vigliani <a href="mailto:stefano.vigliani@izsler.it">stefano.vigliani@izsler.it</a>
</p>


<h3>References</h3>

<p>Fleiss, J.L. (1971). Measuring nominal scale agreement among many raters. Psychological Bulletin <b>76, 378-382</b>
</p>
<p>Falotico, R. Quatto, P. (2010). On avoiding paradoxes in assessing inter-rater agreement. Italian Journal of Applied Statistics <b>22, 151-160</b>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(diagnostic)
concordance(diagnostic,test="Chisq")
concordance(diagnostic,test="Normal")
concordance(diagnostic,test="MC",B=100)
</code></pre>

<hr>
<h2 id='diagnostic'>Frequency of assignment of patients to diagnostic categories</h2><span id='topic+diagnostic'></span>

<h3>Description</h3>

<p>Six psychiatrists classified 30 patients into 5 diagnostic categories.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(diagnostic)</code></pre>


<h3>Format</h3>

<p>A matrix with 30 rows and 5 columns.
</p>

<dl>
<dt><code>Depression</code></dt><dd><p>number of psychiatrists who judged a given patient affected by &ldquo;Depression&rdquo;</p>
</dd>
<dt><code>Personality disorders</code></dt><dd><p>number of psychiatrists who judged a given patient affected by  &ldquo;Personality disorders&rdquo;</p>
</dd>
<dt><code>Schizophrenia</code></dt><dd><p>number of psychiatrists who judged a given patient affected by  &ldquo;Schizophrenia&rdquo;</p>
</dd>
<dt><code>Neurosis</code></dt><dd><p>number of psychiatrists who judged a given patient affected by &ldquo;Neurosis&rdquo;
</p>
</dd>
<dt><code>Other</code></dt><dd><p>number of psychiatrists who judged a given patient affected by &ldquo;Other&rdquo; diseases
</p>
</dd>
</dl>



<h3>References</h3>

<p>Fleiss, J.L. (1971). Measuring nominal scale agreement among many raters. Psychological Bulletin <b>76, 378-382</b>
</p>

<hr>
<h2 id='raters-package'>
A Modification of Fleiss' Kappa in case of Nominal and Ordinal Variables
</h2><span id='topic+raters-package'></span><span id='topic+raters'></span>

<h3>Description</h3>

<p>Computes a statistic as an index of inter-rater agreement among a set of raters in case of nominal or ordinal data.This procedure is based on a statistic not affected by Kappa paradoxes.
In case of ordinal data, the weighted versions of the statistic has been developed using a matrix of linear or quadratic weights. 
The percentile Boostrap confidence interval is computed and the test argument allows to perform if the agreement is nil.
The p value can be approximated using the Normal, Chi-squared distribution or using Monte Carlo algorithm in case of nominal data. Otherwise, the  approximation and the Monte Carlo algorithm is computed.
Fleiss' Kappa index is also shown in case of nominal data.
In a nutshell, the function <code>concordance</code> can be used
in case of nominal scale while the functions <code>wlin.conc</code> and <code>wquad.conc</code> can be used in case of ordinal 
data using linear or quadratic weights, respectively.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> raters</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 2.0.3</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL(&gt;=2)</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Daniele Giardiello, Piero Quatto, Enrico Ripamonti and Stefano Vigliani
</p>
<p>Maintainer: Daniele Giardiello &lt;daniele.giardiello1@gmail.com&gt;
</p>


<h3>References</h3>

<p>Fleiss, J.L. (1971). Measuring nominal scale agreement among many raters. Psychological Bulletin <b>76, 378-382</b>.
</p>
<p>Falotico, R. Quatto, P. (2010). On avoiding paradoxes in assessing inter-rater agreement. Italian Journal of Applied Statistics <b>22, 151-160.</b> 
</p>
<p>Falotico, R., Quatto, P. (2014). Fleiss' kappa statistic without paradoxes. Quality &amp; Quantity, <b>1-8</b>.
</p>
<p>Marasini, D. Quatto, P. Ripamonti, E. (2014).  Assessing the inter-rater agreement for ordinal data through weighted indexes. Statistical methods in medical research.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Nominal data
data(diagnostic)
concordance(diagnostic,test="Normal")

# Ordinal data with linear weights
data(winetable)
set.seed(12345)
wlin.conc(winetable,test="MC")

# Ordinal data with quadratic weights
data(winetable)
set.seed(12345)
wquad.conc(winetable,test="MC")
</code></pre>

<hr>
<h2 id='uterine'>Variability in classification of carcinoma in situ of the
uterine cervix

</h2><span id='topic+uterine'></span>

<h3>Description</h3>

<p> Seven oncologists classified 118 patients into five stages of carcinoma classification
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(uterine)</code></pre>


<h3>Format</h3>

<p>A data frame with 118 observations on the following 5 variables.
</p>

<dl>
<dt><code>Negative</code></dt><dd><p>number of doctors who judged a given patient as &quot;Negative&quot;</p>
</dd>
<dt><code>Atypical Squamous Hyperplasia</code></dt><dd><p>number of doctors who judged a given patient affected by &quot;Atypical Squamous Hyperplasia&quot;</p>
</dd>
<dt><code>Carcinoma in Situ</code></dt><dd><p>number of doctors who judged a given patient affected by &quot;Carcinoma in Situ&quot;</p>
</dd>
<dt><code>Squamous Carcinoma with Early Stromal Invasion</code></dt><dd><p>number of doctors who judged a given patient affected by &quot;Squamous Carcinoma with Early Stromal&quot;</p>
</dd>
<dt><code>Invasive Carcinoma</code></dt><dd><p>number of doctors who judged a given patient affected by &quot;Invasive Carcinoma&quot;</p>
</dd>
</dl>



<h3>References</h3>


<p>Holmquist, N.D. et al. (1967).
Variability in classification of carcinoma in situ of the
uterine cervix. Archives of Pathology <b>84,334-345</b>
</p>

<hr>
<h2 id='winetable'>
Sensory wine evaluation
</h2><span id='topic+winetable'></span>

<h3>Description</h3>

<p> The data wine in ordinal package represent a factorial experiment on factors determining the bitterness of wine
with 1 as &ldquo;Least bitter&rdquo;and 5 as &ldquo;Most bitter&rdquo;.
In this case, we supposed that eight different bottles of wine were evaluated by nine judges according to the bitterness scale described above.
It is possible to get this data using the dataframe wine included in ordinal package using <code>table(wine$bottle,wine$rating)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(winetable)</code></pre>


<h3>Format</h3>

<p>A data frame with 8 observations on 5 variables.
</p>


<h3>References</h3>


<p>Randall J.H.(1989) The Analysis of Sensory Data by Generalized Linear Model. Biometrical Journal
<b>vol 31,issue 7, pp 781-793</b>
</p>

<hr>
<h2 id='wlin.conc'>Inter-rater agreement among a set of raters for ordinal data using linear weights

</h2><span id='topic+wlin.conc'></span>

<h3>Description</h3>

<p>Computes a statistic as an index of inter-rater agreement among a set of raters in case of ordinal data using linear weights. 
The matrix of linear weights is defined inside the function.
This procedure is based on a statistic not affected by Kappa paradoxes.
It is also possible to get the confidence interval at level alpha using the percentile Bootstrap and to evaluate if the agreement is nil using the Monte Carlo algorithm.
Fleiss' Kappa cannot be used in case of ordinal data.
It is advisable to use <code>set.seed</code> to get the same replications for Bootstrap confidence limits and Montecarlo test.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>wlin.conc(db, test = "Default", B = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wlin.conc_+3A_db">db</code></td>
<td>
<p>n*c matrix or data frame, n subjects c categories. The numbers inside the matrix or data frame indicate how many raters chose a specific category for a given subject.  A sum of row indicates the total number of raters who evaluated a given subject. In case of ordinal data, the c categories can be sorted according to a specific scale.</p>
</td></tr>
<tr><td><code id="wlin.conc_+3A_test">test</code></td>
<td>
<p>Statistical test to evaluate if the raters make random assignment regardless of the characteristic of each subject. Under null hypothesis, it corresponds to a high percentage of assignment errors. Thus, the expected agreement is weak. If this argument is not specified the p value are not being computed.
</p>
</td></tr>
<tr><td><code id="wlin.conc_+3A_b">B</code></td>
<td>
<p> Number of iterations for the percentile Bootstrap and for Monte Carlo test.</p>
</td></tr>   
<tr><td><code id="wlin.conc_+3A_alpha">alpha</code></td>
<td>
<p> Level of significance for Bootstrap confidence interval and for Monte Carlo algorithm if it is specified</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>$Statistic</code></td>
<td>
<p>A list with the index of inter-rater agreement not affected by Kappa paradoxes for ordinal data and the percentile Bootstrap confidence interval. If the test argument is specified the p value is also shown. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Piero Quatto <a href="mailto:piero.quatto@unimib.it">piero.quatto@unimib.it</a>,
Daniele Giardiello <a href="mailto:daniele.giardiello1@gmail.com">daniele.giardiello1@gmail.com</a>
Stefano Vigliani <a href="mailto:stefano.vigliani@izsler.it">stefano.vigliani@izsler.it</a>
</p>


<h3>References</h3>

<p>Fleiss, J.L. (1971). Measuring nominal scale agreement among many raters. Psychological Bulletin <b>76, 378-382</b>
</p>
<p>Falotico, R. Quatto, P. (2010). On avoiding paradoxes in assessing inter-rater agreement. Italian Journal of Applied Statistics <b>22, 151-160</b>
</p>
<p>Marasini, D. Quatto, P. Ripamonti, E. (2014).  Assessing the inter-rater agreement for ordinal data through weighted indexes. Statistical methods in medical research.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(uterine)
set.seed(12345)
wlin.conc(uterine,test="MC",B=25)
</code></pre>

<hr>
<h2 id='wquad.conc'>Inter-rater agreement among a set of raters for ordinal data using quadratic weights

</h2><span id='topic+wquad.conc'></span>

<h3>Description</h3>

<p>Computes a statistic as an index of inter-rater agreement among a set of raters in case of ordinal data using quadratic weights. 
The matrix of quadratic weights is defined inside the function.
This procedure is based on a statistic not affected by Kappa paradoxes.
It is also possible to get the confidence interval at level alpha using the percentile Bootstrap and to evaluate if the agreement is nil using the Monte Carlo algorithm.
Fleiss' Kappa cannot be used in case of ordinal data.
It is advisable to use <code>set.seed</code> to get the same replications for Bootstrap confidence limits and Montecarlo test.
</p>



<h3>Usage</h3>

<pre><code class='language-R'>wquad.conc(db, test = "Default", B = 1000, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wquad.conc_+3A_db">db</code></td>
<td>
<p>n*c matrix or data frame, n subjects c categories. The numbers inside the matrix or data frame indicate how many raters chose a specific category for a given subject.  A sum of row indicates the total number of raters who evaluated a given subject. In case of ordinal data, the c categories can be sorted according to a specific scale.</p>
</td></tr>
<tr><td><code id="wquad.conc_+3A_test">test</code></td>
<td>
<p>Statistical test to evaluate if the raters make random assignment regardless of the characteristic of each subject. Under null hypothesis, it corresponds to a high percentage of assignment errors. Thus, the expected agreement is weak. If this argument is not specified the p value are not being computed.
</p>
</td></tr>
<tr><td><code id="wquad.conc_+3A_b">B</code></td>
<td>
<p> Number of iterations for the percentile Bootstrap and for Monte Carlo test.</p>
</td></tr>   
<tr><td><code id="wquad.conc_+3A_alpha">alpha</code></td>
<td>
<p> Level of significance for Bootstrap confidence interval and for Monte Carlo algorithm if it is specified</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:
</p>
<table>
<tr><td><code>$Statistic</code></td>
<td>
<p>A list with the index of inter-rater agreement not affected by Kappa paradoxes for ordinal data and the percentile Bootstrap confidence interval. If the test argument is specified the p value is also shown. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Piero Quatto <a href="mailto:piero.quatto@unimib.it">piero.quatto@unimib.it</a>,
Daniele Giardiello <a href="mailto:daniele.giardiello1@gmail.com">daniele.giardiello1@gmail.com</a>
Stefano Vigliani <a href="mailto:stefano.vigliani@izsler.it">stefano.vigliani@izsler.it</a>
</p>


<h3>References</h3>

<p>Fleiss, J.L. (1971). Measuring nominal scale agreement among many raters. Psychological Bulletin <b>76, 378-382</b>
</p>
<p>Falotico, R. Quatto, P. (2010). On avoiding paradoxes in assessing inter-rater agreement. Italian Journal of Applied Statistics <b>22, 151-160</b>
</p>
<p>Marasini, D. Quatto, P. Ripamonti, E. (2014).  Assessing the inter-rater agreement for ordinal data through weighted indexes. Statistical methods in medical research.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(uterine)
set.seed(12345)
wquad.conc(uterine,test="MC",B=25)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
