<!DOCTYPE html><html lang="en"><head><title>Help for package SEI</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SEI}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#aggregate_xts'><p>Aggregate values in xts objects</p></a></li>
<li><a href='#data_supply'><p>Time series of wind and solar energy production</p></a></li>
<li><a href='#data_wind_de'><p>Time series of average wind speed in Germany</p></a></li>
<li><a href='#fit_dist'><p>Fit a distribution to data</p></a></li>
<li><a href='#get_drought'><p>Get drought characteristics</p></a></li>
<li><a href='#get_pit'><p>Calculate probability integral transform values</p></a></li>
<li><a href='#plot_sei'><p>Plot standardised indices</p></a></li>
<li><a href='#std_index'><p>Calculate standardised indices</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Calculating Standardised Indices</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Convert a time series of observations to a time series of standardised indices that can be used to monitor variables on a common and probabilistically interpretable scale. The indices can be aggregated and rescaled to different time scales, visualised using plot capabilities, and calculated using a range of distributions. This includes flexible non-parametric and non-stationary methods.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/noeliaof/SEI">https://github.com/noeliaof/SEI</a>, <a href="https://noeliaof.github.io/SEI/">https://noeliaof.github.io/SEI/</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, xts, zoo, fitdistrplus, flexsurv, gamlss,
gamlss.dist, lmom</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, lubridate, dplyr, gridExtra, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-07-25 14:15:39 UTC; sa20i493</td>
</tr>
<tr>
<td>Author:</td>
<td>Sam Allen [aut, cre],
  Noelia Otero [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Sam Allen &lt;sam.allen@stat.math.ethz.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-08-27 11:20:46 UTC</td>
</tr>
</table>
<hr>
<h2 id='aggregate_xts'>Aggregate values in xts objects</h2><span id='topic+aggregate_xts'></span>

<h3>Description</h3>

<p>Inputs an xts time series and outputs an xts time series whose
values have been aggregated over a moving window of a user-specified length.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>aggregate_xts(
  x,
  agg_period = 1,
  agg_scale = c("days", "mins", "hours", "weeks", "months", "years"),
  agg_fun = "sum",
  timescale = c("days", "mins", "hours", "weeks", "months", "years"),
  na_thres = 10
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="aggregate_xts_+3A_x">x</code></td>
<td>
<p>xts object to be aggregated.</p>
</td></tr>
<tr><td><code id="aggregate_xts_+3A_agg_period">agg_period</code></td>
<td>
<p>length of the aggregation period.</p>
</td></tr>
<tr><td><code id="aggregate_xts_+3A_agg_scale">agg_scale</code></td>
<td>
<p>timescale of <code>agg_period</code>;
one of <code>'mins'</code>, <code>'hours'</code>, <code>'days'</code>, <code>'weeks'</code>, <code>'months'</code>, <code>'years'</code>.</p>
</td></tr>
<tr><td><code id="aggregate_xts_+3A_agg_fun">agg_fun</code></td>
<td>
<p>string specifying the function used to aggregate the data over the
aggregation period, default is <code>'sum'</code>.</p>
</td></tr>
<tr><td><code id="aggregate_xts_+3A_timescale">timescale</code></td>
<td>
<p>timescale of the data; one of <code>'mins'</code>, <code>'hours'</code>, <code>'days'</code>, <code>'weeks'</code>, <code>'months'</code>, <code>'years'</code>.</p>
</td></tr>
<tr><td><code id="aggregate_xts_+3A_na_thres">na_thres</code></td>
<td>
<p>threshold for the percentage of NA values allowed in the
aggregation period; default is 10%.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This has been adapted from code available at
<a href="https://github.com/WillemMaetens/standaRdized">https://github.com/WillemMaetens/standaRdized</a>.
</p>
<p>Given a vector <code class="reqn">x_{1}, x_{2}, \dots</code>, the function <code>aggregate_xts</code> calculates
aggregated values <code class="reqn">\tilde{x}_{1}, \tilde{x}_{2}, \dots</code> as
</p>
<p style="text-align: center;"><code class="reqn">\tilde{x}_{t} = f(x_{t}, x_{t-1}, \dots, x_{t - k + 1}),</code>
</p>

<p>for each time point <code class="reqn">t = k, k + 1, \dots</code>, where <code class="reqn">k</code> (<code>agg_period</code>) is the number
of time units (<code>agg_scale</code>) over which to aggregate the time series (<code>x</code>),
and <code class="reqn">f</code> (<code>agg_fun</code>) is the function used to perform the aggregation.
The first <code class="reqn">k - 1</code> values of the aggregated time series are returned as <code>NA</code>.
</p>
<p>By default, <code>agg_fun = "sum"</code>, meaning the aggregation results in accumulations over the
aggregation period:
</p>
<p style="text-align: center;"><code class="reqn">\tilde{x}_{t} = \sum_{k=1}^{K} x_{t - k + 1}.</code>
</p>

<p>Alternative functions can also be used. For example, specifying
<code>agg_fun = "mean"</code> returns the mean over the aggregation period,
</p>
<p style="text-align: center;"><code class="reqn">\tilde{x}_{t} = \frac{1}{K} \sum_{k=1}^{K} x_{t - k + 1},</code>
</p>

<p>while <code>agg_fun = "max"</code> returns the maximum over the aggregation period,
</p>
<p style="text-align: center;"><code class="reqn">\tilde{x}_{t} = \text{max}(\{x_{t}, x_{t-1}, \dots, x_{t - k + 1}\}).</code>
</p>

<p><code>agg_period</code> is a single numeric value specifying over how many time units the
data <code>x</code> is to be aggregated. By default, <code>agg_period</code> is assumed to correspond
to a number of days, but this can also be specified manually using the argument
<code>agg_scale</code>. <code>timescale</code> is the timescale of the input data <code>x</code>.
By default, this is also assumed to be &quot;days&quot;.
</p>
<p>Since the time series <code>x</code> aggregates data over the aggregation period, problems
may arise when <code>x</code> contains missing values. For example, if interest is
on daily accumulations, but 50% of the values in the aggregation period are missing,
the accumulation over this aggregation period will not be accurate.
This can be controlled using the argument <code>na_thres</code>.
<code>na_thres</code> specifies the percentage of <code>NA</code> values in the aggregation period
before a <code>NA</code> value is returned. i.e. the proportion of values that are allowed
to be missing. The default is <code>na_thres = 10</code>.
</p>


<h3>Value</h3>

<p>An xts time series with aggregated values.
</p>


<h3>Author(s)</h3>

<p>Sam Allen, Noelia Otero
</p>


<h3>Examples</h3>

<pre><code class='language-R'>

data(data_supply, package = "SEI")

# consider hourly German energy production data in 2019
supply_de &lt;- subset(data_supply, country == "Germany", select = c("date", "PWS"))
supply_de &lt;- xts::xts(supply_de$PWS, order.by = supply_de$date)

# daily accumulations
supply_de_daily &lt;- aggregate_xts(supply_de, timescale = "hours")

# weekly means
supply_de_weekly &lt;- aggregate_xts(supply_de, agg_scale = "weeks",
                                  agg_fun = "mean", timescale = "hours")

plot(supply_de, main = "Hourly energy production")
plot(supply_de_daily, main = "Daily accumulated energy production")
plot(supply_de_weekly, main = "Weekly averaged energy production")



</code></pre>

<hr>
<h2 id='data_supply'>Time series of wind and solar energy production</h2><span id='topic+data_supply'></span>

<h3>Description</h3>

<p>This dataset contains hourly time series of wind and solar energy production
in 27 European countries in 2019.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_supply")
</code></pre>


<h3>Format</h3>

<p>An object of type <code>data.frame</code> containing 3 variables:
</p>

<dl>
<dt>date</dt><dd><p>A <code>POSIXct</code> series of times at which energy production
is available.</p>
</dd>
<dt>country</dt><dd><p>The country to which the energy production measurement corresponds.</p>
</dd>
<dt>PWS</dt><dd><p>The hourly wind and solar energy production for the corresponding time and country.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The dataframe <code>data_supply</code> contains 236520 (24 x 365 x 27) rows, containing the wind
and solar energy production for each hour in 2019 for each of the 27 countries.
</p>
<p>This corresponds to a subset of the data used in Bloomfield and Brayshaw (2021),
which can be accessed at https://researchdata.reading.ac.uk/321/.
Users are referred to this paper for further details.
</p>


<h3>References</h3>

<p>Bloomfield, Hannah and Brayshaw, David (2021):
ERA5 derived time series of European aggregated surface weather variables, wind power, and solar power capacity factors: hourly data from 1950-2020.
<a href="https://doi.org/10.17864/1947.000321">doi:10.17864/1947.000321</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("data_supply")
</code></pre>

<hr>
<h2 id='data_wind_de'>Time series of average wind speed in Germany</h2><span id='topic+data_wind_de'></span>

<h3>Description</h3>

<p>This dataset contains a daily time series of average wind speeds across Germany between 1979 and 2019.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data("data_wind_de")
</code></pre>


<h3>Format</h3>

<p>An object of type <code>data.frame</code> containing 2 variables:
</p>

<dl>
<dt>date</dt><dd><p>A <code>POSIXct</code> series of times at which average wind speeds are available.</p>
</dd>
<dt>wsmean</dt><dd><p>The average wind speed in Germany for the corresponding time.</p>
</dd>
</dl>



<h3>Details</h3>

<p>The dataframe <code>data_wind_de</code> contains 14975 (365 x 41 + 10) rows, containing the
daily average wind speed in Germany for 41 years between 1979 and 2019. Ten leap
years occur within this period.
</p>
<p>This corresponds to a subset of the data that is publicly available at
https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels?tab=overview.
Users are referred to the reference below for further details.
</p>


<h3>References</h3>

<p>Hersbach, H et al. (2023):
ERA5 hourly data on single levels from 1940 to present. Copernicus Climate Change Service (C3S) Climate Data Store (CDS)
<a href="https://doi.org/10.24381/cds.adbb2d47">doi:10.24381/cds.adbb2d47</a>
Accessed 01-09-2022.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("wind_de")
</code></pre>

<hr>
<h2 id='fit_dist'>Fit a distribution to data</h2><span id='topic+fit_dist'></span>

<h3>Description</h3>

<p>Function to fit a specified distribution to a vector of data.
Returns the estimated distribution and relevant goodness-of-fit statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_dist(data, dist, method = "mle", preds = NULL, n_thres = 10, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_dist_+3A_data">data</code></td>
<td>
<p>A numeric vector.</p>
</td></tr>
<tr><td><code id="fit_dist_+3A_dist">dist</code></td>
<td>
<p>character string specifying the distribution to be fit to the data;
one of <code>'empirical'</code>, <code>'kde'</code>, <code>'norm'</code>, <code>'lnorm'</code>, <code>'logis'</code>, <code>'llogis'</code>,
<code>'exp'</code>, <code>'gamma'</code>, and <code>'weibull'</code>.</p>
</td></tr>
<tr><td><code id="fit_dist_+3A_method">method</code></td>
<td>
<p>A character string coding for the fitting method: 
<code>"mle"</code> for 'maximum likelihood estimation', <code>"mme"</code> for 'moment matching estimation', 
<code>"qme"</code> for 'quantile matching estimation', <code>"mge"</code> for 'maximum goodness-of-fit estimation'
and <code>"mse"</code> for 'maximum spacing estimation'.</p>
</td></tr>
<tr><td><code id="fit_dist_+3A_preds">preds</code></td>
<td>
<p>data frame of predictor variables on which the estimated distribution
should depend.</p>
</td></tr>
<tr><td><code id="fit_dist_+3A_n_thres">n_thres</code></td>
<td>
<p>minimum number of data points required to estimate the distribution;
default is 10.</p>
</td></tr>
<tr><td><code id="fit_dist_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="fitdistrplus.html#topic+fitdist">fitdist</a></code> or
<code><a href="gamlss.html#topic+gamlss">gamlss</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This has been adapted from code available at
<a href="https://github.com/WillemMaetens/standaRdized">https://github.com/WillemMaetens/standaRdized</a>.
</p>
<p><code>data</code> is a numeric vector of data from which the distribution is to be estimated.
</p>
<p><code>dist</code> is the specified distribution to be fit to <code>data</code>. This must be one of
<code>'empirical'</code>, <code>'kde'</code>, <code>'norm'</code>, <code>'lnorm'</code>, <code>'logis'</code>, <code>'llogis'</code>,
<code>'exp'</code>, <code>'gamma'</code>, and <code>'weibull'</code>. These correspond to the following
distributions: <code>'empirical'</code> returns the empirical distribution function of <code>data</code>,
<code>'kde'</code> applies (normal) kernel density estimation to <code>data</code>, while <code>'norm'</code>,
<code>'lnorm'</code>, <code>'logis'</code>, <code>'llogis'</code>, <code>'exp'</code>, <code>'gamma'</code>, and
<code>'weibull'</code> correspond to the normal, log-normal, logistic, log-logistic, exponential,
gamma, and Weibull distributions, respectively.
</p>
<p>By default, <code>dist = 'empirical'</code>, in which case the distribution is estimated
empirically from <code>data</code>. This is only recommended if there are at least 100 values
in <code>data</code>, and a warning message is returned otherwise. Parametric distributions
are more appropriate when there is relatively little data,
or good reason to expect that the data follows a particular distribution.
Kernel density estimation <code>dist = 'kde'</code> provides a flexible compromise between
using empirical methods and parametric distributions.
</p>
<p><code>n_thres</code> is the minimum number of observations required to fit the distribution.
The default is <code>n_thres = 10</code>. If the number of values in <code>data</code> is
smaller than <code>na_thres</code>, an error is returned. This guards against over-fitting,
which can result in distributions that do not generalise well out-of-sample.
</p>
<p><code>method</code> specifies the method used to estimate the distribution parameters.
This argument is redundant if <code>dist = 'empirical'</code> or <code>dist = 'kde'</code>.
Otherwise, <code>fit_dist</code> essentially provides a wrapper for
<code><a href="fitdistrplus.html#topic+fitdist">fitdist</a></code>, and further details can be found in the corresponding
documentation. Additional arguments to <code><a href="fitdistrplus.html#topic+fitdist">fitdist</a></code>
can also be specified via <code>...</code>.
Where relevant, the default is to estimate parameters using maximum likelihood estimation,
<code>method = "mle"</code>, though several alternative methods are also available; see
<code><a href="fitdistrplus.html#topic+fitdist">fitdist</a></code>. Parameter estimation is also possible using L-moment
matching (<code>method = 'lmme'</code>), for all distribution choices except the log-logistic
distribution. In this case, <code>fit_dist</code> is essentially a wrapper for the
<code><a href="lmom.html#topic+lmom">lmom</a></code> package.
</p>
<p>The distribution can also be non-stationary, by depending on some predictor variables or covariates.
These predictors can be included via the argument <code>preds</code>, which should be a data frame
with a separate column for each predictor, and with a number of rows equal to the length of
<code>data</code>. In this case, a Generalized Additive Model for
Location, Scale, and Shape (GAMLSS) is fit to <code>data</code> using the predictors in <code>preds</code>.
It is assumed that the mean of the distribution depends linearly on all of the predictors.
Variable arguments in <code>...</code> can also be used to specify relationships between the
scale and shape parameters of the distribution and the predictors; see examples below.
In this case, <code>fit_dist</code> is essentially a wrapper for <code><a href="gamlss.html#topic+gamlss">gamlss</a></code>,
and users are referred to the corresponding documentation for further implementation details.
</p>


<h3>Value</h3>

<p>A list containing the estimated distribution function (<code>F_x</code>), its parameters
(<code>params</code>), and properties of the fit such as the AIC and
Kolmogorov-Smirnov goodness-of-fit statistic (<code>fit</code>). If the estimated distribution
function depends on covariates, then the <code>gamlss</code> model fit is returned as the
parameters.
</p>


<h3>Author(s)</h3>

<p>Sam Allen, Noelia Otero
</p>


<h3>References</h3>

<p>Rigby, R. A., &amp; Stasinopoulos, D. M. (2005):
&lsquo;Generalized additive models for location, scale and shape&rsquo;,
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em> 54, 507-554.
<a href="https://doi.org/10.1111/j.1467-9876.2005.00510.x">doi:10.1111/j.1467-9876.2005.00510.x</a>
</p>
<p>Delignette-Muller, M. L., &amp; Dutang, C. (2015):
&lsquo;fitdistrplus: An R package for fitting distributions&rsquo;,
<em>Journal of Statistical Software</em> 64, 1-34.
<a href="https://doi.org/10.18637/jss.v064.i04">doi:10.18637/jss.v064.i04</a>
</p>
<p>Allen, S. &amp; N. Otero (2023):
&lsquo;Standardised indices to monitor energy droughts&rsquo;,
<em>Renewable Energy</em> 217, 119206.
<a href="https://doi.org/10.1016/j.renene.2023.119206">doi:10.1016/j.renene.2023.119206</a>
</p>


<h3>See Also</h3>

<p><code><a href="fitdistrplus.html#topic+fitdist">fitdist</a></code> <code><a href="gamlss.html#topic+gamlss">gamlss</a></code> <code><a href="lmom.html#topic+lmom">lmom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 1000
shape &lt;- 3
rate &lt;- 2

x &lt;- seq(0, 10, 0.01)

### gamma distribution

# maximum likelihood
data &lt;- rgamma(N, shape, rate)
out &lt;- fit_dist(data, dist = "gamma")
hist(data, breaks = 30, probability = TRUE)
lines(x, dgamma(x, out$params[1], out$params[2]), col = "blue")

# method of moments
out &lt;- fit_dist(data, dist = "gamma", method = "mme")
hist(data, breaks = 30, probability = TRUE)
lines(x, dgamma(x, out$params[1], out$params[2]), col = "blue")

# method of l-moments
out &lt;- fit_dist(data, dist = "gamma", method = "lmme")
hist(data, breaks = 30, probability = TRUE)
lines(x, dgamma(x, out$params[1], out$params[2]), col = "blue")


## weibull distribution

# maximum likelihood
data &lt;- rweibull(N, shape, 1/rate)
out &lt;- fit_dist(data, dist = "weibull")
hist(data, breaks = 30, probability = TRUE)
lines(x, dweibull(x, out$params[1], out$params[2]), col = "blue")

# method of l-moments
out &lt;- fit_dist(data, dist = "weibull", method = "lmme")
hist(data, breaks = 30, probability = TRUE)
lines(x, dweibull(x, out$params[1], out$params[2]), col = "blue")


## exponential distribution

# method of moments
out &lt;- fit_dist(data, dist = "exp", method = "mme")
hist(data, breaks = 30, probability = TRUE)
lines(x, dexp(x, out$params), col = "blue")


## logistic distribution

x &lt;- seq(-10, 20, 0.01)

# maximum likelihood
data &lt;- rlogis(N, shape, rate)
out &lt;- fit_dist(data, dist = "logis")
hist(data, breaks = 30, probability = TRUE)
lines(x, dlogis(x, out$params[1], out$params[2]), col = "blue")



##### non-stationary estimation using gamlss

## normal distribution
x &lt;- seq(-10, 20, length.out = N)
data &lt;- rnorm(N, x + shape, exp(x/10))
plot(data)
preds &lt;- data.frame(t = x)

out_st &lt;- fit_dist(data, dist = "norm")
out_nst &lt;- fit_dist(data, dist = "norm", preds = preds)
out_nst2 &lt;- fit_dist(data, dist = "norm", preds = preds, sigma.formula = ~ .)

# pit values without trend
pit_st &lt;- out_st$F_x(data, out_st$params)
hist(pit_st, breaks = 30, probability = TRUE, main = "No trend")
abline(1, 0, col = "red", lty = "dotted")
# pit values with trend in mean
pit_nst &lt;- out_nst$F_x(data, out_nst$params, preds)
hist(pit_nst, breaks = 30, probability = TRUE, main = "Trend in mean")
abline(1, 0, col = "red", lty = "dotted")
# pit values with trend in mean and sd
pit_nst2 &lt;- out_nst2$F_x(data, out_nst2$params, preds)
hist(pit_nst2, breaks = 30, probability = TRUE, main = "Trend in mean and standard deviation")
abline(1, 0, col = "red", lty = "dotted")


## log normal distribution
x &lt;- seq(0.01, 10, length.out = N)
data &lt;- rlnorm(N, (x + shape)/3, 1/rate)
plot(data)
preds &lt;- data.frame(t = x)

out &lt;- fit_dist(data, dist = "lnorm", preds = preds)
pit &lt;- out$F_x(data, out$params, preds)
hist(pit, breaks = 30, probability = TRUE, main = "PIT values for non-stationary fit")
abline(1, 0, col = "red", lty = "dotted")


</code></pre>

<hr>
<h2 id='get_drought'>Get drought characteristics</h2><span id='topic+get_drought'></span>

<h3>Description</h3>

<p>Extract characteristics of droughts from a time series of values. Drought characteristics
include the occurrence, intensity, magnitude, and duration of the drought.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_drought(
  x,
  thresholds = c(1.28, 1.64, 1.96),
  exceed = TRUE,
  cluster = 0,
  lag = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_drought_+3A_x">x</code></td>
<td>
<p>vector or xts object from which droughts are defined.</p>
</td></tr>
<tr><td><code id="get_drought_+3A_thresholds">thresholds</code></td>
<td>
<p>numeric vector containing thresholds to use when defining droughts.</p>
</td></tr>
<tr><td><code id="get_drought_+3A_exceed">exceed</code></td>
<td>
<p>logical; <code>TRUE</code> if a drought is defined when <code>x</code> is above the thresholds, <code>FALSE</code> otherwise.</p>
</td></tr>
<tr><td><code id="get_drought_+3A_cluster">cluster</code></td>
<td>
<p>integer specifying the number of time steps over which droughts should be clustered.</p>
</td></tr>
<tr><td><code id="get_drought_+3A_lag">lag</code></td>
<td>
<p>numeric specifying the value at which the drought should end.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A drought is assumed to be defined as an instance when the vector <code>x</code> exceeds
(if <code>exceed = TRUE</code>) or falls below (if <code>exceed = FALSE</code>) the specified
thresholds in <code>thresholds</code>.
</p>
<p><code>thresholds</code> can be a single value, or a vector of values. In the latter case,
each threshold is assumed to be a different level or intensity of the drought.
If <code>exceed = TRUE</code> then a higher threshold corresponds to a higher intensity,
and if <code>exceed = FALSE</code> then a lower threshold corresponds to a higher intensity.
For example, if <code>thresholds = c(1, 1.5, 2)</code>, then a level 1 drought occurs
whenever <code>x</code> exceeds 1 but is lower than 1.5, a level 2 drought occurs
whenever <code>x</code> exceeds 1.5 but is lower than 2, and a level 3 drought occurs
whenever <code>x</code> exceeds 2.
</p>
<p>By default, <code>thresholds = c(1.28, 1.64, 1.96)</code>, which corresponds to the
90th, 95th, and 97.5th percentiles of the standard normal distribution. These
thresholds are often used alongside standardised indices to define hydrometeorological
droughts; see references.
</p>
<p><code>cluster</code> represents the number
of time steps between different drought events that should be attributed to the same drought.
For example, suppose <code class="reqn">x_{i} \geq t, x_{i + 1} &lt; t, x_{i + 2} \geq t</code>,
where <code class="reqn">x_{i}</code> represents the <code class="reqn">i</code>-th value in <code>x</code>, and <code class="reqn">t</code> is the
lowest threshold in <code>thresholds</code>. In this case, one drought event will finish
at time point <code class="reqn">i</code> and a new drought event will begin at time point <code class="reqn">i + 2</code>;
no drought will occur at time point <code class="reqn">i + 1</code> because the value <code class="reqn">x_{i + 1}</code> is
below the threshold defining a drought. Since both <code class="reqn">x_{i}</code> and <code class="reqn">x_{i + 2}</code>
are classed as drought events, it may be desirable to ignore the fluctuation, and
assume that the drought persists through <code class="reqn">x_{i + 1}</code> despite its value. This can
be achieved by setting <code>cluster = 1</code>. If there were two time points separating
different drought events, these can be clustered together by setting <code>cluster = 2</code>,
and so on. The default is that no clustering should be implemented, i.e. <code>cluster = 0</code>.
</p>
<p>Alternatively, we may wish to assume that the drought persists until <code>x</code> falls below
a value that is not necessarily equal to the threshold defining a drought. For example,
hydrometeorological droughts based on standardised indices, such as the Standardised
Precipitation Index (SPI), are often defined to persist until the standardised index changes
sign, i.e. falls below zero. This can be achieved by setting <code>lag = 0</code>. More generally,
<code>lag</code> can be any numerical value. If <code>exceed = TRUE</code>, a warning is issued if
<code>lag</code> is above the lowest threshold, and if <code>exceed = FALSE</code>, a warning is
issued if <code>lag</code> is below the highest threshold. If <code>lag</code> is <code>NULL</code>
(the default), then no lagging is performed.
</p>
<p><code>get_drought()</code> currently does not use the time series information in
the xts input, thereby assuming that the time series is complete, without missing
time periods. If <code>x</code> is a vector, rather than an xts object, then this
is also implicitly assumed.
</p>
<p>The output is a dataframe containing the vector <code>x</code>, a logical vector
specifying whether each value of <code>x</code> corresponds to a drought event,
and the magnitude of the drought, defined as the sum of the values of <code>x</code> during
the drought; see references. The magnitude of the drought is only shown
on the last day of the drought. This makes it easier to compute statistics about
the drought magnitude, such as the average drought magnitude.
If <code>thresholds</code> is a vector, the intensity or level of the drought is also returned.
</p>


<h3>Value</h3>

<p>A data frame containing the original values <code>x</code> and the corresponding drought characteristics.
</p>


<h3>Author(s)</h3>

<p>Sam Allen, Noelia Otero
</p>


<h3>References</h3>

<p>McKee, T. B., Doesken, N. J., &amp; Kleist, J. (1993):
&lsquo;The relationship of drought frequency and duration to time scales&rsquo;,
<em>In Proceedings of the 8th Conference on Applied Climatology</em> 17, 179-183.
</p>
<p>Vicente-Serrano, S. M., Beguería, S., &amp; López-Moreno, J. I. (2010):
&lsquo;A multiscalar drought index sensitive to global warming: the standardized precipitation evapotranspiration index&rsquo;,
<em>Journal of Climate</em> 23, 1696-1718.
<a href="https://doi.org/10.1175/2009JCLI2909.1">doi:10.1175/2009JCLI2909.1</a>
</p>
<p>Allen, S. &amp; N. Otero (2023):
&lsquo;Standardised indices to monitor energy droughts&rsquo;,
<em>Renewable Energy</em> 217, 119206.
<a href="https://doi.org/10.1016/j.renene.2023.119206">doi:10.1016/j.renene.2023.119206</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
data(data_supply)

# consider daily German energy supply data in 2019
supply_de &lt;- subset(data_supply, country == "Germany", select = c("date", "PWS"))
supply_de &lt;- xts::xts(supply_de$PWS, order.by = supply_de$date)
supply_de_std &lt;- std_index(supply_de, rescale = "days", timescale = "hours")

# a drought may correspond to when energy supply is low
drought_df &lt;- get_drought(supply_de_std, thresholds = c(-1.28, -1.64, -1.96), exceed = FALSE)
head(drought_df)
mean(drought_df$occ) # droughts occur on roughly 10% of time steps

# cluster droughts two time steps apart
drought_df &lt;- get_drought(supply_de_std, thresholds = c(-1.28, -1.64, -1.96),
                          cluster = 2, exceed = FALSE)
mean(drought_df$occ) # droughts occur on roughly 11% of time steps

# let droughts persist until the standardised index changes sign
drought_df &lt;- get_drought(supply_de_std, thresholds = c(-1.28, -1.64, -1.96),
                          lag = 0, exceed = FALSE)
mean(drought_df$occ) # droughts occur on roughly 17% of time steps


</code></pre>

<hr>
<h2 id='get_pit'>Calculate probability integral transform values</h2><span id='topic+get_pit'></span>

<h3>Description</h3>

<p>Function to estimate the cumulative distribution function (CDF)
from a set of observations, and return the corresponding probability integral
transform (PIT) values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_pit(
  x_ref,
  x_new = x_ref,
  dist = "empirical",
  preds_ref = NULL,
  preds_new = preds_ref,
  method = "mle",
  return_fit = FALSE,
  lower = -Inf,
  upper = Inf,
  cens = "none",
  n_thres = 10,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_pit_+3A_x_ref">x_ref</code></td>
<td>
<p>numeric vector from which to estimate the CDF.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_x_new">x_new</code></td>
<td>
<p>numeric vector from which to calculate the PIT values.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_dist">dist</code></td>
<td>
<p>character string specifying the distribution to be fit to the data;
one of <code>'empirical'</code>, <code>'kde'</code>, <code>'norm'</code>, <code>'lnorm'</code>, <code>'logis'</code>, <code>'llogis'</code>,
<code>'exp'</code>, <code>'gamma'</code>, and <code>'weibull'</code>.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_preds_ref">preds_ref</code></td>
<td>
<p>data frame of predictor variables on which the estimated distribution
should depend, corresponding to the reference observations <code>x_ref</code>.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_preds_new">preds_new</code></td>
<td>
<p>data frame of predictor variables on which the estimated distribution
should depend, corresponding to the new observations <code>x_new</code>.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_method">method</code></td>
<td>
<p>A character string coding for the fitting method: 
<code>"mle"</code> for 'maximum likelihood estimation', <code>"mme"</code> for 'moment matching estimation', 
<code>"qme"</code> for 'quantile matching estimation', <code>"mge"</code> for 'maximum goodness-of-fit estimation'
and <code>"mse"</code> for 'maximum spacing estimation'.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_return_fit">return_fit</code></td>
<td>
<p>logical specifying whether to return parameters and goodness-of-fit
statistics for the distribution fit.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_lower">lower</code>, <code id="get_pit_+3A_upper">upper</code></td>
<td>
<p>numeric values specifying the lower and upper bounds at which the
values in <code>x_ref</code> and <code>x_new</code> are censored.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_cens">cens</code></td>
<td>
<p>method used to deal with censoring of the PIT values; either a string
(<code>'none'</code>, <code>'normal'</code> or <code>'prob'</code>), corresponding to common choices, or a custom numeric value.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_n_thres">n_thres</code></td>
<td>
<p>minimum number of data points required to estimate the distribution;
default is 10.</p>
</td></tr>
<tr><td><code id="get_pit_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="fitdistrplus.html#topic+fitdist">fitdist</a></code> or
<code><a href="gamlss.html#topic+gamlss">gamlss</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Continuous data</strong>
</p>
<p>If <code class="reqn">X</code> is a continuous random variable with cumulative distribution function (CDF)
<code class="reqn">F</code>, then the probability integral transform (PIT) <code class="reqn">F(X)</code> is uniformly distributed
between 0 and 1. Given a vector <code class="reqn">x_{1}, \dots, x_{n}</code> of realisations of <code class="reqn">X</code>,
<code>get_pit</code> produces an estimate <code class="reqn">\hat{F}</code> of the CDF <code class="reqn">F</code>, and returns a
vector of PIT values corresponding to another set of realisations <code class="reqn">z_{1}, \dots, z_{N}</code>,
</p>
<p style="text-align: center;"><code class="reqn">\hat{F}(z_{1}), \dots, \hat{F}(z_{n}).</code>
</p>

<p><code>x_ref</code> contains the values <code class="reqn">x_{1}, \dots, x_{n}</code> from which the CDF estimate
<code class="reqn">\hat{F}</code> is obtained. <code>x_new</code> contains the values <code class="reqn">z_{1}, \dots, z_{n}</code>
from which the PIT values <code class="reqn">\hat{F}(z_{1}), \dots, \hat{F}(z_{n})</code> are calculated.
By default, <code>x_ref</code> and <code>x_new</code> are the same, so that the PIT values are
calculated in-sample.
</p>
<p>To estimate the distribution, <code>get_pit</code> calls <code><a href="#topic+fit_dist">fit_dist</a></code>. The arguments
<code>dist</code>, <code>method</code> and <code>n_thres</code> are
documented in detail in the corresponding help page.
</p>
<p>To check that the chosen distribution adequately fits the data, the argument
<code>return_fit = TRUE</code> can be used to return the estimated parameters of the
distribution, as well as properties of the fit such as the AIC and a p-value
for the Kolmogorov-Smirnov goodness-of-fit test.
</p>
<p><strong>Non-stationary distributions</strong>
</p>
<p>The estimated distribution can also be non-stationary, by depending on some predictor variables or covariates.
These predictors can be included via the arguments <code>preds_ref</code> and <code>preds_new</code>,
which should be data frames with a separate column for each predictor, and with
numbers of rows equal to the lengths of <code>x_ref</code> and <code>x_new</code>, respectively.
In this case, a Generalized Additive Model for Location, Scale, and Shape (GAMLSS) is
fit to <code>x_ref</code> using the predictors in <code>preds_ref</code>.
The PIT values corresponding to <code>x_new</code> are then calculated by applying the
estimated distribution with predictors <code>preds_new</code>.
If a non-stationary distribution is to be estimated, both <code>preds_ref</code> and
<code>preds_new</code> must be provided. By default, <code>preds_new</code> is assumed to be
the same as <code>preds_ref</code>, to align with <code>x_new</code> being the same as <code>x_ref</code>.
</p>
<p><strong>Censored data</strong>
</p>
<p>If the random variable <code class="reqn">X</code> is not continuous, the PIT will not be uniformly distributed.
A relevant case is when <code class="reqn">X</code> is censored. For example, precipitation is censored below
at zero. This results in several PIT values being equal to <code class="reqn">F(0)</code>. The <code>lower</code>
and <code>upper</code> arguments to <code>get_pit</code> allow the user to specify the lower and upper
bounds at which the data is censored; the default is <code>lower = -Inf</code> and <code>upper = Inf</code>,
i.e. there is no censoring.
</p>
<p>If the PIT values are used to construct standardised indices, this censoring can lead to
unintuitive index values.
To deal with censored data, it has been proposed to map the PIT values of the censored
values to a different constant <code class="reqn">c</code>; see references. For example, for precipitation, the PIT
values would become
</p>
<p style="text-align: center;"><code class="reqn">F(X) \quad \text{if} \quad X &gt; 0,</code>
</p>

<p style="text-align: center;"><code class="reqn">c \quad \text{if} \quad X = 0.</code>
</p>

<p>The constant <code class="reqn">c</code> can be chosen so that the PIT values satisfy some desired property.
For example, if <code class="reqn">F(X)</code> is uniformly distributed between 0 and 1, then it has mean equal
to <code class="reqn">1/2</code>. Hence, <code class="reqn">c</code> could be chosen such that the mean of the PIT values of the
censored distribution are equal to <code class="reqn">1/2</code>.
Alternatively, if <code class="reqn">F(X)</code> is uniformly distributed between 0 and 1, then
the transformed PIT value <code class="reqn">\Phi^{-1}(F(X))</code> (where <code class="reqn">\Phi^{-1}</code> is the quantile function
of the standard normal distribution) follows a standard normal distribution, and therefore
has mean equal to 0. The constant <code class="reqn">c</code> could therefore be chosen such that the mean of the
transformed PIT values of the censored distribution are equal to 0.
</p>
<p>The argument <code>cens</code> in <code>get_pit</code> can be used to treat censored data. <code>cens</code>
can be one of four options: a single numeric value containing the value <code class="reqn">c</code> at which to
assign the PIT values of the censored realisations; the string <code>'none'</code> if no censoring
is to be performed; the string <code>'prob'</code> if <code class="reqn">c</code>
is to be chosen automatically so that the mean of the PIT values is equal to <code class="reqn">1/2</code>;
or the string <code>'normal'</code> if <code class="reqn">c</code> is to be chosen automatically so that the mean of
the transformed PIT values is equal to 0. If the data is censored both above and below,
then <code>cens</code> must be a numeric vector of length two, specifying the values to assign
the realisations that are censored both below and above.
</p>
<p>When the data is censored, <code>dist</code> corresponds to the distribution used to estimate the
uncensored realisations, e.g. positive precipitations. The probability of being at the boundary
points is estimated using the relative frequency of censored observations in <code>x_ref</code>.
</p>


<h3>Value</h3>

<p>A vector of PIT values if <code>return_fit = FALSE</code>, or, if <code>return_fit = TRUE</code>,
a list containing the estimated distribution function (<code>F_x</code>), its parameters
(<code>params</code>), and properties of the fit such as the AIC and
Kolmogorov-Smirnov goodness-of-fit statistic (<code>fit</code>). If the estimated distribution
function depends on covariates, then the <code>gamlss</code> model fit is returned as the
parameters.
</p>


<h3>Author(s)</h3>

<p>Sam Allen, Noelia Otero
</p>


<h3>References</h3>

<p>Rigby, R. A., &amp; Stasinopoulos, D. M. (2005):
&lsquo;Generalized additive models for location, scale and shape&rsquo;,
<em>Journal of the Royal Statistical Society Series C: Applied Statistics</em> 54, 507-554.
<a href="https://doi.org/10.1111/j.1467-9876.2005.00510.x">doi:10.1111/j.1467-9876.2005.00510.x</a>
</p>
<p>Stagge, J. H., Tallaksen, L. M., Gudmundsson, L., Van Loon, A. F., &amp; Stahl, K. (2015):
&lsquo;Candidate distributions for climatological drought indices (SPI and SPEI)&rsquo;,
<em>International Journal of Climatology</em> 35, 4027-4040.
<a href="https://doi.org/10.1002/joc.4267">doi:10.1002/joc.4267</a>
</p>
<p>Allen, S. &amp; N. Otero (2023):
&lsquo;Calculating standardised indices using SEI&rsquo;,
<em>EarthArXiv pre-print</em>.
<a href="https://doi.org/10.31223/X5GM4G">doi:10.31223/X5GM4G</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+fit_dist">fit_dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>N &lt;- 1000
shape &lt;- 3
rate &lt;- 2

x_ref &lt;- rgamma(N, shape, rate)
x_new &lt;- rgamma(N, shape, rate)

# empirical distribution
pit &lt;- get_pit(x_ref, x_new)
hist(pit)

# gamma distribution
pit &lt;- get_pit(x_ref, x_new, dist = "gamma", return_fit = TRUE)
hist(pit$pit)

hist(x_ref, breaks = 30, probability = TRUE)
lines(seq(0, 10, 0.01), dgamma(seq(0, 10, 0.01), pit$params[1], pit$params[2]), col = "blue")


# weibull distribution
pit &lt;- get_pit(x_ref, x_new, dist = "weibull", return_fit = TRUE)
hist(pit$pit)

hist(x_ref, breaks = 30, probability = TRUE)
lines(seq(0, 10, 0.01), dweibull(seq(0, 10, 0.01), pit$params[1], pit$params[2]), col = "blue")


# exponential distribution
pit &lt;- get_pit(x_ref, x_new, dist = "exp", return_fit = TRUE)
hist(pit$pit)

hist(x_ref, breaks = 30, probability = TRUE)
lines(seq(0, 10, 0.01), dexp(seq(0, 10, 0.01), pit$params[1]), col = "blue")


# gamma distribution with censoring
x_ref &lt;- c(x_ref, numeric(N))
pit &lt;- get_pit(x_ref, dist = "gamma", lower = 0, cens = "prob")
hist(pit)
mean(pit) # = 1/2
mean(qnorm(pit)) # != 0

pit &lt;- get_pit(x_ref, dist = "gamma", lower = 0, cens = "normal")
hist(qnorm(pit))
mean(pit) # != 1/2
mean(qnorm(pit)) # = 0


## normal distribution with trend in mean
x &lt;- seq(-10, 20, length.out = N)
x_ref &lt;- rnorm(N, x + shape, 2)
plot(x_ref)
preds &lt;- data.frame(t = x)

pit &lt;- get_pit(x_ref, preds_ref = preds, dist = "norm")
hist(pit)

## normal distribution with trend in mean and standard deviation
x_ref &lt;- rnorm(N, x + shape, exp(x/10))
plot(x_ref)
preds &lt;- data.frame(t = x)

pit &lt;- get_pit(x_ref, preds_ref = preds, dist = "norm", sigma.formula = ~ .)
hist(pit)
# sigma.formula is an optional argument in the gamlss::gamlss function


</code></pre>

<hr>
<h2 id='plot_sei'>Plot standardised indices</h2><span id='topic+plot_sei'></span>

<h3>Description</h3>

<p>Plot a time series or histogram of standardised indices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_sei(
  x,
  type = c("ts", "hist", "bar"),
  title = NULL,
  lab = "Std. Index",
  xlims = NULL,
  ylims = NULL,
  n_bins = 30
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_sei_+3A_x">x</code></td>
<td>
<p>vector or xts object containing the indices to be plotted.</p>
</td></tr>
<tr><td><code id="plot_sei_+3A_type">type</code></td>
<td>
<p>type of plot (either time series &quot;ts&quot;, histogram &quot;hist&quot;, or barplot &quot;bar&quot;).</p>
</td></tr>
<tr><td><code id="plot_sei_+3A_title">title</code></td>
<td>
<p>optional title of the plot.</p>
</td></tr>
<tr><td><code id="plot_sei_+3A_lab">lab</code></td>
<td>
<p>axis label.</p>
</td></tr>
<tr><td><code id="plot_sei_+3A_xlims">xlims</code>, <code id="plot_sei_+3A_ylims">ylims</code></td>
<td>
<p>lower and upper limits of the axes.</p>
</td></tr>
<tr><td><code id="plot_sei_+3A_n_bins">n_bins</code></td>
<td>
<p>the number of bins to show in the histogram.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The <code>plot_sei()</code> function can be used to plot either a time series (if <code>type = "ts"</code>)
or a histogram (if <code>type = "hist"</code> or <code>type = "bar"</code>) of the values in <code>x</code>.
</p>
<p>A time series can only be displayed if <code>x</code> is an <span class="pkg">xts</span> time series.
</p>
<p>The argument <code>lab</code> is a string containing the label of the x-axis if
<code>type = "hist"</code> or <code>type = "bar"</code> and the y-axis if <code>type = "ts"</code>.
</p>
<p>The options <code>type = "hist"</code> and <code>type = "bar"</code> both display histograms
of the data <code>x</code>. With <code>type = "hist"</code>, <code>plot_sei()</code> is essentially a
wrapper of <code>geom_histogram()</code>, while <code>type = "bar"</code> is a wrapper of
<code>geom_bar()</code>. The latter can provide more flexibility when plotting bounded data,
whereas the former is easier to use when superimposing densities on top.
</p>


<h3>Value</h3>

<p>A ggplot object displaying the standardised index values.
</p>


<h3>Author(s)</h3>

<p>Sam Allen, Noelia Otero
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data_supply)
# consider hourly German energy supply data in 2019
supply_de &lt;- subset(data_supply, country == "Germany", select = c("date", "PWS"))
supply_de &lt;- xts::xts(supply_de$PWS, order.by = supply_de$date)
supply_de_std &lt;- std_index(supply_de, timescale = "hours")

plot_sei(supply_de, title = "German renewable energy production in 2019")
plot_sei(supply_de_std, title = "German SREPI in 2019")

plot_sei(supply_de, type = "hist", title = "German renewable energy production in 2019")
plot_sei(supply_de_std, type = "hist", title = "German SREPI in 2019")

# type = "hist" and type = "bar both output a histogram of the index values
# type = "hist" can be useful to superimpose densities on top of the histogram
z &lt;- seq(-3.5, 3.5, length.out = length(supply_de_std))
plot_sei(supply_de_std, type = "hist", title = "German SREPI in 2019") +
 ggplot2::geom_line(ggplot2::aes(x = z, y = dnorm(z)), col = "blue")

# type = "bar" can be useful when the index values are bounded
supply_de_std &lt;- std_index(supply_de, timescale = "hours", index_type = "prob11")
plot_sei(supply_de_std, type = "hist", xlims = c(-1, 1), title = 'type = "hist"')
plot_sei(supply_de_std, type = "bar", xlims = c(-1, 1), title = 'type = "bar"')


</code></pre>

<hr>
<h2 id='std_index'>Calculate standardised indices</h2><span id='topic+std_index'></span>

<h3>Description</h3>

<p>Inputs a time series of a chosen variable (e.g. precipitation,
energy demand, residual load etc.) and returns a time series of standardised indices.
Indices can be calculated on any timescale.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>std_index(
  x_new,
  x_ref = x_new,
  dist = "empirical",
  preds_new = NULL,
  preds_ref = preds_new,
  method = "mle",
  return_fit = FALSE,
  index_type = "normal",
  gr_new = NULL,
  gr_ref = gr_new,
  timescale = NULL,
  moving_window = NULL,
  window_scale = NULL,
  agg_period = NULL,
  agg_scale = NULL,
  agg_fun = "sum",
  rescale = NULL,
  rescale_fun = "sum",
  ignore_na = FALSE,
  n_thres = 10,
  na_thres = 10,
  lower = -Inf,
  upper = Inf,
  cens = index_type,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="std_index_+3A_x_new">x_new</code></td>
<td>
<p>vector or time series to be converted to standardised indices.</p>
</td></tr>
<tr><td><code id="std_index_+3A_x_ref">x_ref</code></td>
<td>
<p>vector or time series containing reference data to use when calculating the standardised indices.</p>
</td></tr>
<tr><td><code id="std_index_+3A_dist">dist</code></td>
<td>
<p>character string specifying the distribution to be fit to the data;
one of <code>'empirical'</code>, <code>'kde'</code>, <code>'norm'</code>, <code>'lnorm'</code>, <code>'logis'</code>, <code>'llogis'</code>,
<code>'exp'</code>, <code>'gamma'</code>, and <code>'weibull'</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_preds_new">preds_new</code></td>
<td>
<p>data frame of predictor variables on which the estimated distribution
should depend, corresponding to the new observations <code>x_new</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_preds_ref">preds_ref</code></td>
<td>
<p>data frame of predictor variables on which the estimated distribution
should depend, corresponding to the reference observations <code>x_ref</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_method">method</code></td>
<td>
<p>A character string coding for the fitting method: 
<code>"mle"</code> for 'maximum likelihood estimation', <code>"mme"</code> for 'moment matching estimation', 
<code>"qme"</code> for 'quantile matching estimation', <code>"mge"</code> for 'maximum goodness-of-fit estimation'
and <code>"mse"</code> for 'maximum spacing estimation'.</p>
</td></tr>
<tr><td><code id="std_index_+3A_return_fit">return_fit</code></td>
<td>
<p>logical specifying whether to return parameters and goodness-of-fit
statistics for the distribution fit.</p>
</td></tr>
<tr><td><code id="std_index_+3A_index_type">index_type</code></td>
<td>
<p>the type of standardised index: <code>"normal"</code> (default), <code>"prob01"</code>,
or <code>"prob11"</code> (see details).</p>
</td></tr>
<tr><td><code id="std_index_+3A_gr_new">gr_new</code></td>
<td>
<p>vector of factors for which separate distributions should be applied to <code>x_new</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_gr_ref">gr_ref</code></td>
<td>
<p>vector of factors for which separate distributions should be fit to <code>x_ref</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_timescale">timescale</code></td>
<td>
<p>timescale of the data; one of <code>'mins'</code>, <code>'hours'</code>, <code>'days'</code>, <code>'weeks'</code>, <code>'months'</code>, <code>'years'</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_moving_window">moving_window</code></td>
<td>
<p>length of moving window on which to calculate the indices.</p>
</td></tr>
<tr><td><code id="std_index_+3A_window_scale">window_scale</code></td>
<td>
<p>timescale of <code>moving_window</code>; default is the timescale of the data.</p>
</td></tr>
<tr><td><code id="std_index_+3A_agg_period">agg_period</code></td>
<td>
<p>length of the aggregation period.</p>
</td></tr>
<tr><td><code id="std_index_+3A_agg_scale">agg_scale</code></td>
<td>
<p>timescale of <code>agg_period</code>;
one of <code>'mins'</code>, <code>'hours'</code>, <code>'days'</code>, <code>'weeks'</code>, <code>'months'</code>, <code>'years'</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_agg_fun">agg_fun</code></td>
<td>
<p>string specifying the function used to aggregate the data over the
aggregation period, default is <code>'sum'</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_rescale">rescale</code></td>
<td>
<p>the timescale that the time series should be rescaled to;
one of <code>"days"</code>, <code>"weeks"</code>, <code>"months"</code>, <code>"quarters"</code>, and <code>"years"</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_rescale_fun">rescale_fun</code></td>
<td>
<p>string specifying the function used to rescale the data; default is <code>"sum"</code>.</p>
</td></tr>
<tr><td><code id="std_index_+3A_ignore_na">ignore_na</code></td>
<td>
<p>logical specifying whether to ignore NAs when rescaling the time series.</p>
</td></tr>
<tr><td><code id="std_index_+3A_n_thres">n_thres</code></td>
<td>
<p>minimum number of data points required to estimate the distribution;
default is 10.</p>
</td></tr>
<tr><td><code id="std_index_+3A_na_thres">na_thres</code></td>
<td>
<p>threshold for the percentage of NA values allowed in the
aggregation period; default is 10%.</p>
</td></tr>
<tr><td><code id="std_index_+3A_lower">lower</code>, <code id="std_index_+3A_upper">upper</code></td>
<td>
<p>numeric values specifying the lower and upper bounds at which the
values in <code>x_ref</code> and <code>x_new</code> are censored.</p>
</td></tr>
<tr><td><code id="std_index_+3A_cens">cens</code></td>
<td>
<p>method used to deal with censoring of the PIT values; either a string
(<code>'none'</code>, <code>'normal'</code> or <code>'prob'</code>), corresponding to common choices, or a custom numeric value.</p>
</td></tr>
<tr><td><code id="std_index_+3A_...">...</code></td>
<td>
<p>additional arguments to be passed to <code><a href="fitdistrplus.html#topic+fitdist">fitdist</a></code> or
<code><a href="gamlss.html#topic+gamlss">gamlss</a></code></p>
</td></tr>
</table>


<h3>Details</h3>

<p><strong>Standardised indices</strong>
</p>
<p>Standardised indices are calculated by estimating the cumulative distribution function (CDF)
of the variable of interest, and using this to transform the measurements to
a standardised scale. <code>std_index</code> is a wrapper for <code><a href="#topic+get_pit">get_pit</a></code> and
<code><a href="#topic+fit_dist">fit_dist</a></code> that additionally allows for aggregation, rescaling, and grouping
of the time series. Further details can be found in the help pages of <code><a href="#topic+get_pit">get_pit</a></code>
and <code><a href="#topic+fit_dist">fit_dist</a></code>.
</p>
<p><code>std_index</code> estimates the CDF using a time series of reference data <code>x_ref</code>,
and applies the resulting transformation to the time series <code>x_new</code>. The result is
a time series of standardised <code>x_new</code> values. These standardised indices quantify
how extreme the <code>x_new</code> values are in reference to <code>x_ref</code>.
<code>x_new</code> and <code>x_ref</code> should therefore contain values of the same variable.
If <code>x_ref</code> is not specified, then it is set equal to <code>x_new</code>, so that the
standardised indices are calculated in-sample.
</p>
<p>The function returns a vector or time series (depending on the format of <code>x_new</code>)
containing the standardised indices corresponding to <code>x_new</code>. Three different
types of indices are available, which are explained in detail in the vignette.
The index type can be chosen using <code>index_type</code>, which must be one of
<code>"normal"</code> (default), <code>"prob01"</code>, and <code>"prob11"</code>.
</p>
<p><strong>Time series manipulations</strong>
</p>
<p><code>x_new</code> and <code>x_ref</code> can either be provided as vectors or <code><a href="xts.html#topic+xts">xts</a></code> time series.
In the latter case, the time series can be aggregated across timescales or rescaled.
This is useful, for example, if <code>x_new</code> contains hourly data, but interest is
on daily accumulations or averages of the hourly data.
</p>
<p>The argument <code>rescale</code> converts the data to a different timescale. The original
timescale of the data can be manually specified using the argument <code>timescale</code>.
<code>timescale</code> is required if the time series is to be aggregated or rescaled.
Otherwise, <code>std_index</code> will try to automatically determine the timescale of the data.
Manually specifying the timescale of the data is generally more robust. The rescaling
is performed using the function <code>rescale_fun</code>. By default,
<code>rescale_fun = "sum"</code>, so that values are added across the timescale of interest.
This can be changed to any user-specified function.
</p>
<p>The argument <code>agg_period</code> aggregates the data across the timescale of interest.
The aggregation is performed using <code><a href="#topic+aggregate_xts">aggregate_xts</a></code>.
This differs from <code>rescale</code> in that the resolution of the data remains the same.
<code>agg_period</code> is a number specifying how long the data should be aggregated across.
By default, it is assumed that <code>agg_period</code> is on the same timescale as <code>x_new</code>
and <code>x_ref</code>. For example, if the data is hourly and <code>agg_period = 24</code>, then
this assumes the data is to be aggregated over the past 24 hours. The scale of the
aggregation period can also be specified manually using <code>agg_scale</code>. For example,
specifying <code>agg_period = 1</code> and <code>agg_scale = "days"</code>
would also aggregate the data over the past day. <code>agg_fun</code> specifies how the
data is to be aggregated, the default is <code>agg_fun = "sum"</code>.
</p>
<p><strong>Distribution estimation</strong>
</p>
<p><code>dist</code> is the distribution used to estimate the CDF from <code>x_ref</code>.
Currently, functionality is available to fit one of the following distributions to the data:
Normal (<code>"norm"</code>), Log-normal (<code>"lnorm"</code>), Logistic (<code>"logis"</code>),
Log-logistic (<code>"llogis"</code>), Exponential (<code>"exp"</code>), Gamma (<code>"gamma"</code>),
and Weibull (<code>"weibull"</code>).
Alternatively, the CDF can be estimated empirically (<code>dist = "empirical"</code>)
based on the values in <code>x_ref</code>, or using kernel density estimation (<code>dist = "kde"</code>).
</p>
<p>If <code>dist</code> is a parametric family of distributions, then parameters of the
distribution are estimated from <code>x_ref</code>. <code>method</code> specifies how the parameters
are estimated; see <code><a href="#topic+fit_dist">fit_dist</a></code> for details.
The resulting parameters and corresponding goodness-of-fit statistics can be
returned by specifying <code>return_fit = TRUE</code>.
</p>
<p>By default, the distribution is estimated over all values in <code>x_ref</code>. Alternatively,
if <code>x_new</code> is an <code><a href="xts.html#topic+xts">xts</a></code> object, parameters can be estimated sequentially using a
moving window of values. <code>moving_window</code> determines the length of the moving window.
This is a single value, assumed to be on the same timescale as <code>x_new</code>.
The timsscale of the moving window can also be specified manually using <code>window_scale</code>.
<code>window_scale</code> must also be one of <code>"days"</code>, <code>"weeks"</code>, <code>"months"</code>,
<code>"quarters"</code>, and <code>"years"</code>.
</p>
<p>The estimated distribution can also be non-stationary, by depending on some predictors
or covariates. These predictors can be stored in data frames and input to <code>std_index</code>
via the arguments <code>preds_new</code> and <code>preds_ref</code>; see <code><a href="#topic+fit_dist">fit_dist</a></code> for
details. Predictors cannot be used if the data is to be rescaled, since this would also
require rescaling the predictors; in this case, an error is returned.
</p>
<p><strong>Grouping</strong>
</p>
<p>By default, one distribution is fit to all values in <code>x_ref</code>. Separate distributions
can be fit to different subsets of the data by specifying <code>gr_ref</code> and <code>gr_new</code>.
These should be factor vectors, where each factor corresponds to a different grouping or
subset of the data.
No factor should appear in <code>gr_new</code> that does not appear in <code>gr_ref</code>, since
there would be no data from which to estimate the distribution for this group. An error
is returned in this case.
Since the distribution of the values in <code>x_ref</code> could change for different groupings,
the argument <code>dist</code> can be a vector of strings of the same length as the number of
factor levels in <code>gr_new</code>. In this case, the first element of <code>dist</code>
should correspond to the first element of <code>levels(gr_new)</code> and so on.
If <code>dist</code> is a single string, then the same distribution is used for each grouping.
</p>


<h3>Value</h3>

<p>Time series of standardised indices. If <code>return_fit = TRUE</code>, then a list is returned
that contains the time series of standardised indices, as well as information about the
fit of the distribution to the data. If <code>gr_new</code> is specified, then <code>std_index</code>
returns a list of time series of standardised indices, with an element corresponding to
each factor in <code>gr_new</code>.
</p>


<h3>Author(s)</h3>

<p>Sam Allen, Noelia Otero
</p>


<h3>References</h3>

<p>McKee, T. B., Doesken, N. J., &amp; Kleist, J. (1993):
&lsquo;The relationship of drought frequency and duration to time scales&rsquo;,
<em>In Proceedings of the 8th Conference on Applied Climatology</em> 17, 179-183.
</p>
<p>Vicente-Serrano, S. M., Beguería, S., &amp; López-Moreno, J. I. (2010):
&lsquo;A multiscalar drought index sensitive to global warming: the standardized precipitation evapotranspiration index&rsquo;,
<em>Journal of Climate</em> 23, 1696-1718.
<a href="https://doi.org/10.1175/2009JCLI2909.1">doi:10.1175/2009JCLI2909.1</a>
</p>
<p>Allen, S. &amp; N. Otero (2023):
&lsquo;Standardised indices to monitor energy droughts&rsquo;,
<em>Renewable Energy</em> 217, 119206.
<a href="https://doi.org/10.1016/j.renene.2023.119206">doi:10.1016/j.renene.2023.119206</a>
</p>


<h3>See Also</h3>

<p><code><a href="xts.html#topic+xts">xts</a></code> <code><a href="#topic+aggregate_xts">aggregate_xts</a></code> <code><a href="#topic+get_pit">get_pit</a></code> <code><a href="#topic+fit_dist">fit_dist</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(data_supply)
# consider hourly German energy supply data in 2019
supply_de &lt;- subset(data_supply, country == "Germany", select = c("date", "PWS"))
supply_de &lt;- xts::xts(supply_de$PWS, order.by = supply_de$date)
#options(xts_check_TZ = FALSE)

# convert to hourly standardised indices
supply_de_std &lt;- std_index(supply_de, timescale = "hours")
hist(supply_de, main = "Raw values")
hist(supply_de_std, main = "Standardised values")

# convert to daily or weekly standardised indices
supply_de_std &lt;- std_index(supply_de, timescale = "hours", rescale = "days")

# convert to weekly standardised indices calculated on each day
supply_de_std &lt;- std_index(supply_de, timescale = "hours", rescale = "days",
                           agg_period = 1, agg_scale = "weeks")

# calculate standardised indices corresponding to December, based on the previous year
dec &lt;- zoo::index(supply_de) &gt; "2019-12-01 UTC"
supply_de_std_dec &lt;- std_index(x_new = supply_de[dec], x_ref = supply_de[!dec],
                               timescale = "hours")

# calculate standardised indices using a 100 day moving window
supply_de_std_dec &lt;- std_index(supply_de[dec], supply_de, timescale = "hours",
                               rescale = "days", moving_window = 100)

# suppose we are interested in the daily maximum rather than the daily total
supply_de_std &lt;- std_index(supply_de, timescale = "hours", rescale = "days",
                           rescale_fun = "max")
supply_de_std &lt;- std_index(supply_de, timescale = "hours", rescale = "days",
                           rescale_fun = "mean") # or average

# the default uses the empirical distribution, but this requires more data than
# parametric distributions, meaning it is not ideal when data is short, e.g. in weekly case
supply_de_std &lt;- std_index(supply_de, timescale = "hours", rescale = "weeks") # warning
# instead, we can use a parametric distribution, e.g. a gamma distribution
supply_de_std &lt;- std_index(supply_de, timescale = "hours", rescale = "weeks", dist = "gamma")
# we can check the fit by checking whether the indices resemble a standard normal distribution
hist(supply_de)
hist(supply_de_std)
# we can also look at the properties of the fit
supply_de_std &lt;- std_index(supply_de, timescale = "hours", rescale = "weeks",
                           dist = "gamma", return_fit = TRUE)

# we could also use kernel density estimation, which is a flexible compromise between the two
supply_de_std &lt;- std_index(supply_de, timescale = "hours", rescale = "weeks", dist = "kde")


# calculate separate indices for each quarter of 2019
season &lt;- ceiling(lubridate::month(zoo::index(supply_de)) / 3)
season &lt;- factor(c("Q1", "Q2", "Q3", "Q4")[season])
supply_de_std &lt;- std_index(supply_de, timescale = "hours", rescale = "days",
                           gr_new = season, dist = "kde", return_fit = TRUE)


# non-stationary distribution estimation using gamlss

N &lt;- 1000
x &lt;- seq(-10, 20, length.out = N)
data &lt;- rnorm(N, x, exp(x/10)) # non-stationary mean and standard deviation
plot.ts(data)
preds &lt;- data.frame(t = x)

# standardised indices without trend
si_st &lt;- std_index(data, dist = "norm")
plot_sei(si_st)
# standardised indices with trend in mean
si_nst &lt;- std_index(data, dist = "norm", preds_new = preds)
plot_sei(si_nst)
# standardised indices with trend in mean and sd
si_nst2 &lt;- std_index(data, dist = "norm", preds_new = preds, sigma.formula = ~ .)
plot_sei(si_nst2)


</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
