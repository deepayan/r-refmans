<!DOCTYPE html><html lang="en"><head><title>Help for package variantspark</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {variantspark}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#importance_tbl'><p>Extract the importance data frame</p></a></li>
<li><a href='#sample_names'><p>Display sample names</p></a></li>
<li><a href='#vs_connect'><p>Creating a variantspark connection</p></a></li>
<li><a href='#vs_importance_analysis'><p>Importance Analysis</p></a></li>
<li><a href='#vs_read_csv'><p>Reading a CSV file</p></a></li>
<li><a href='#vs_read_labels'><p>Reading labels</p></a></li>
<li><a href='#vs_read_vcf'><p>Reading a VCF file</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>A 'Sparklyr' Extension for 'VariantSpark'</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.1</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Samuel Macêdo &lt;samuelmacedo@recife.ifpe.edu.br&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>This is a 'sparklyr' extension integrating 'VariantSpark' and R. 'VariantSpark' is 
  a framework based on 'scala' and 'spark' to analyze genome datasets, 
  see <a href="https://bioinformatics.csiro.au/">https://bioinformatics.csiro.au/</a>. It was tested on datasets with 3000 samples 
  each one containing 80 million features in either unsupervised clustering approaches 
  and supervised applications, like classification and regression. The genome datasets
  are usually writing in VCF, a specific text file format used 
  in bioinformatics for storing gene sequence variations. So, 'VariantSpark' is a great 
  tool for genome research, because it is able to read VCF files, run analyses and return 
  the output in a 'spark' data frame.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.apache.org/licenses/LICENSE-2.0">Apache License 2.0</a> | file LICENSE</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>sparklyr (&ge; 1.0.1)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-06-11 23:30:12 UTC; dmmad</td>
</tr>
<tr>
<td>Author:</td>
<td>Samuel Macêdo [aut, cre],
  Javier Luraschi [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-06-13 16:20:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='importance_tbl'>Extract the importance data frame</h2><span id='topic+importance_tbl'></span>

<h3>Description</h3>

<p>This function extracts the importance data frame from the Importance Analysis
jobj.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>importance_tbl(importance, name = "importance_tbl")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="importance_tbl_+3A_importance">importance</code></td>
<td>
<p>A jobj from the class <code>ImportanceAnalysis</code>, usually the
output of <code>vs_importance_analysis()</code>.</p>
</td></tr>
<tr><td><code id="importance_tbl_+3A_name">name</code></td>
<td>
<p>The name to assign to the copied table in Spark.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sparklyr)
sc &lt;- spark_connect(master = "local")
vsc &lt;- vs_connect(sc)

hipster_vcf &lt;- vs_read_vcf(vsc, 
                           system.file("extdata/hipster.vcf.bz2",
                                       package = "variantspark"))
labels &lt;- vs_read_labels(vsc, 
                         system.file("extdata/hipster_labels.txt",
                                      package = "variantspark"))

importance &lt;- vs_importance_analysis(vsc, hipster_vcf, labels, 10)
importance_tbl(importance)

## End(Not run)

</code></pre>

<hr>
<h2 id='sample_names'>Display sample names</h2><span id='topic+sample_names'></span>

<h3>Description</h3>

<p>This function display the first N variant names.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sample_names(vcf_source, n_samples = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sample_names_+3A_vcf_source">vcf_source</code></td>
<td>
<p>An object with <code>VCFFeatureSource</code> class, usually the
output of the <code>vs_read_vcf()</code>.</p>
</td></tr>
<tr><td><code id="sample_names_+3A_n_samples">n_samples</code></td>
<td>
<p>The number os samples to display.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>spark_jobj, shell_jobj
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sparklyr)

sc &lt;- spark_connect(master = "local")
vsc &lt;- vs_connect(sc)

hipster_vcf &lt;- vs_read_vcf(vsc, 
                           system.file("extdata/hipster.vcf.bz2",
                                       package =  "variantspark"))

sample_names(hipster_vcf, 3)

## End(Not run)

</code></pre>

<hr>
<h2 id='vs_connect'>Creating a variantspark connection</h2><span id='topic+vs_connect'></span>

<h3>Description</h3>

<p>You need to create a variantspark connection to use this extension. To do this,
you pass as argument a spark connection that you can create
using <code>sparklyr::spark_connect()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vs_connect(sc)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vs_connect_+3A_sc">sc</code></td>
<td>
<p>A spark connection.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A variantspark connection
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(sparklyr)
sc &lt;- spark_connect(master = "spark://HOST:PORT")
connection_is_open(sc)
vsc &lt;- vs_connect(sc)
spark_disconnect(sc)

</code></pre>

<hr>
<h2 id='vs_importance_analysis'>Importance Analysis</h2><span id='topic+vs_importance_analysis'></span>

<h3>Description</h3>

<p>This function performs an Importance Analysis using random forest algorithm.
For more details, please look at
<a href="https://variantspark.readthedocs.io/en/latest/overview.html#importance-analysis">here</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vs_importance_analysis(vsc, vcf_source, labels, n_trees)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vs_importance_analysis_+3A_vsc">vsc</code></td>
<td>
<p>A variantspark connection.</p>
</td></tr>
<tr><td><code id="vs_importance_analysis_+3A_vcf_source">vcf_source</code></td>
<td>
<p>An object with <code>VCFFeatureSource</code> class, usually the
output of the <code>vs_read_vcf()</code>.</p>
</td></tr>
<tr><td><code id="vs_importance_analysis_+3A_labels">labels</code></td>
<td>
<p>An object with <code>CsvLabelSource</code>  class, usually the output
of the <code>vs_read_labels()</code>.</p>
</td></tr>
<tr><td><code id="vs_importance_analysis_+3A_n_trees">n_trees</code></td>
<td>
<p>The number of trees using in the random forest.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>spark_jobj, shell_jobj
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(sparklyr)
sc &lt;- spark_connect(master = "local")
vsc &lt;- vs_connect(sc)

hipster_vcf &lt;- vs_read_vcf(vsc, 
                           system.file("extdata/hipster.vcf.bz2",
                                       package =  "variantspark"))

labels &lt;- vs_read_labels(vsc, 
                         system.file("extdata/hipster_labels.txt",
                                      package =  "variantspark"))

vs_importance_analysis(vsc, hipster_vcf, labels, 10)

## End(Not run)

</code></pre>

<hr>
<h2 id='vs_read_csv'>Reading a CSV file</h2><span id='topic+vs_read_csv'></span>

<h3>Description</h3>

<p>The <code>vs_read_csv()</code> reads a CSV file format and returns a <code>jobj</code>
object from <code>CsvFeatureSource</code> scala class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vs_read_csv(vsc, path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vs_read_csv_+3A_vsc">vsc</code></td>
<td>
<p>A variantspark connection.</p>
</td></tr>
<tr><td><code id="vs_read_csv_+3A_path">path</code></td>
<td>
<p>The file's path.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>spark_jobj, shell_jobj
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Not run: 
library(sparklyr)

sc &lt;- spark_connect(master = "local")
vsc &lt;- vs_context(sc)

hipster_labels &lt;- vs_read_csv(vsc, 
                              system.file("extdata/hipster_labels.txt",
                                          package = "variantspark"))

hipster_labels 

## End(Not run)

</code></pre>

<hr>
<h2 id='vs_read_labels'>Reading labels</h2><span id='topic+vs_read_labels'></span>

<h3>Description</h3>

<p>This function reads only the label column of a CSV file and returns a <code>jobj</code>
object from <code>CsvLabelSource</code> scala class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vs_read_labels(vsc, path, label = "label")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vs_read_labels_+3A_vsc">vsc</code></td>
<td>
<p>A variantspark connection.</p>
</td></tr>
<tr><td><code id="vs_read_labels_+3A_path">path</code></td>
<td>
<p>The file's path.</p>
</td></tr>
<tr><td><code id="vs_read_labels_+3A_label">label</code></td>
<td>
<p>A string with the label column name.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>spark_jobj, shell_jobj
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Not run: 
library(sparklyr)

sc &lt;- spark_connect(master = "local")
vsc &lt;- vs_context(sc)

labels &lt;- vs_read_labels(vsc, 
                         system.file("extdata/hipster_labels.txt",
                                      package = "variantspark"))

labels 

## End(Not run)
</code></pre>

<hr>
<h2 id='vs_read_vcf'>Reading a VCF file</h2><span id='topic+vs_read_vcf'></span>

<h3>Description</h3>

<p>The Variant Call Format (VCF) specifies the format of a text file used in
bioinformatics for storing gene sequence variations. The format has been developed
with the advent of large-scale genotyping and DNA sequencing projects, such as
the 1000 Genomes Project. The <code>vs_read_vcf()</code> reads this format and returns
a <code>jobj</code> object from <code>VCFFeatureSource</code> scala class.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>vs_read_vcf(vsc, path)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="vs_read_vcf_+3A_vsc">vsc</code></td>
<td>
<p>A variantspark connection.</p>
</td></tr>
<tr><td><code id="vs_read_vcf_+3A_path">path</code></td>
<td>
<p>The file's path.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>spark_jobj, shell_jobj
</p>


<h3>Examples</h3>

<pre><code class='language-R'> 
## Not run: 
library(sparklyr)

sc &lt;- spark_connect(master = "local")
vsc &lt;- vs_context(sc)

hipster_vcf &lt;- vs_read_vcf(vsc, 
                           system.file("extdata/hipster.vcf.bz2",
                                       package = "variantspark"))

hipster_vcf 

## End(Not run)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
