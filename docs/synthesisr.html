<!DOCTYPE html><html><head><title>Help for package synthesisr</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {synthesisr}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#add_line_breaks'><p>Add line breaks to one or more strings</p></a></li>
<li><a href='#bibliography-class'><p>bibliography-class</p></a></li>
<li><a href='#clean_'><p>Clean a data.frame or vector</p></a></li>
<li><a href='#code_lookup'><p>Bibliographic code lookup for search results assembly</p></a></li>
<li><a href='#deduplicate'><p>Remove duplicates from a bibliographic data set</p></a></li>
<li><a href='#detect_'><p>Detect file formatting information</p></a></li>
<li><a href='#extract_unique_references'><p>Remove duplicates from a bibliographic data set</p></a></li>
<li><a href='#find_duplicates'><p>Detect duplicate values</p></a></li>
<li><a href='#format_citation'><p>Format a citation</p></a></li>
<li><a href='#fuzz_'><p>Calculate similarity between two strings</p></a></li>
<li><a href='#merge_columns'><p>Bind two or more data frames with different columns</p></a></li>
<li><a href='#override_duplicates'><p>Manually override duplicates</p></a></li>
<li><a href='#parse_'><p>Parse bibliographic text in a variety of formats</p></a></li>
<li><a href='#read_refs'><p>Import bibliographic search results</p></a></li>
<li><a href='#review_duplicates'><p>Manually review potential duplicates</p></a></li>
<li><a href='#string_'><p>Calculate similarity between two strings</p></a></li>
<li><a href='#synthesisr'><p>synthesisr: Import, assemble, and deduplicate bibiliographic datasets</p></a></li>
<li><a href='#write_bib'><p>Export data to a bibliographic format</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Import, Assemble, and Deduplicate Bibliographic Datasets</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A critical first step in systematic literature reviews
  and mining of academic texts is to identify relevant texts from a range
  of sources, particularly databases such as 'Web of Science' or 'Scopus'.
  These databases often export in different formats or with different metadata
  tags. 'synthesisr' expands on the tools outlined by Westgate (2019)
  &lt;<a href="https://doi.org/10.1002%2Fjrsm.1374">doi:10.1002/jrsm.1374</a>&gt; to import bibliographic data from a range of formats
  (such as 'bibtex', 'ris', or 'ciw') in a standard way, and allows merging
  and deduplication of the resulting dataset.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>stringdist</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-05-18</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-05-28 23:11:25 UTC; martin_westgate</td>
</tr>
<tr>
<td>Author:</td>
<td>Martin Westgate <a href="https://orcid.org/0000-0003-0854-2034"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Eliza Grames <a href="https://orcid.org/0000-0003-1743-6815"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Martin Westgate &lt;martinjwestgate@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-06-03 16:30:03 UTC</td>
</tr>
</table>
<hr>
<h2 id='add_line_breaks'>Add line breaks to one or more strings</h2><span id='topic+add_line_breaks'></span>

<h3>Description</h3>

<p>This function takes a vector of strings and adds line breaks every n characters. Primarily built to be called internally by format_citation, this function has been made available as it can be useful in other contexts.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>add_line_breaks(x, n = 50, max_n = 80, html = FALSE, max_time = 60)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="add_line_breaks_+3A_x">x</code></td>
<td>
<p>Either a string or a vector; if the vector is not of class character if will be coerced to one using as.character.</p>
</td></tr>
<tr><td><code id="add_line_breaks_+3A_n">n</code></td>
<td>
<p>Numeric: The desired number of characters that should separate consecutive line breaks.</p>
</td></tr>
<tr><td><code id="add_line_breaks_+3A_max_n">max_n</code></td>
<td>
<p>Numeric: The maximum number of characters that may separate consecutive line breaks.</p>
</td></tr>
<tr><td><code id="add_line_breaks_+3A_html">html</code></td>
<td>
<p>logical: Should the line breaks be specified in html?</p>
</td></tr>
<tr><td><code id="add_line_breaks_+3A_max_time">max_time</code></td>
<td>
<p>Numeric: What is the maximum amount of time (in seconds) allowed to adjust groups until character thresholds are reached?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Line breaks are only added between words, so the value of n is actually a threshold value rather than being matched exactly. max_n is matched exactly if a limit is set and max_time is not reached finding new break points between words.
</p>


<h3>Value</h3>

<p>Returns the input vector unaltered except for the addition of line breaks.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>add_line_breaks(c("On the Origin of Species"), n = 10)
</code></pre>

<hr>
<h2 id='bibliography-class'>bibliography-class</h2><span id='topic+bibliography-class'></span><span id='topic+summary.bibliography+2C'></span><span id='topic+print.bibliography+2C'></span><span id='topic+c.bibliography+2C'></span><span id='topic+as.data.frame.bibliography'></span><span id='topic+summary.bibliography'></span><span id='topic+print.bibliography'></span><span id='topic++5B.bibliography'></span><span id='topic+c.bibliography'></span><span id='topic+as.bibliography'></span>

<h3>Description</h3>

<p>This is a small number of standard methods for interacting with class 'bibliography'. More may be added later.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'bibliography'
summary(object, ...)

## S3 method for class 'bibliography'
print(x, n, ...)

## S3 method for class 'bibliography'
x[n]

## S3 method for class 'bibliography'
c(...)

## S3 method for class 'bibliography'
as.data.frame(x, ...)

as.bibliography(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bibliography-class_+3A_object">object</code></td>
<td>
<p>An object of class 'bibliography'</p>
</td></tr>
<tr><td><code id="bibliography-class_+3A_...">...</code></td>
<td>
<p>Any further information</p>
</td></tr>
<tr><td><code id="bibliography-class_+3A_x">x</code></td>
<td>
<p>An object of class 'bibliography'</p>
</td></tr>
<tr><td><code id="bibliography-class_+3A_n">n</code></td>
<td>
<p>Number of items to select/print</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Methods for class bibliography
</p>

<hr>
<h2 id='clean_'>Clean a data.frame or vector</h2><span id='topic+clean_'></span><span id='topic+clean_df'></span><span id='topic+clean_authors'></span><span id='topic+clean_colnames'></span>

<h3>Description</h3>

<p>Cleans column and author names
</p>


<h3>Usage</h3>

<pre><code class='language-R'>clean_df(data)

clean_authors(x)

clean_colnames(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="clean__+3A_data">data</code></td>
<td>
<p>A data.frame with bibliographic information.</p>
</td></tr>
<tr><td><code id="clean__+3A_x">x</code></td>
<td>
<p>A vector of strings</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns the input, but cleaner.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;-  data.frame(
  X..title. = c(
    "EviAtlas: a tool for visualising evidence synthesis databases",
    "revtools: An R package to support article screening for evidence synthesis",
    "An automated approach to identifying search terms for systematic reviews",
    "Reproducible, flexible and high-throughput data extraction from primary literature"),
  YEAR = c("2019", "2019", "2019", "2019"),
  authors = c(
    "Haddaway et al",
    "Westgate",
    "EM Grames AND AN Stillman  &amp; MW Tingley and CS Elphick",
    "Pick et al")
)

clean_df(df)

# or use sub-functions
colnames(df) &lt;- clean_colnames(df)
# colnames(df) &lt;- clean_colnames(colnames(df)) # also works
df$author &lt;- clean_authors(df$author)

</code></pre>

<hr>
<h2 id='code_lookup'>Bibliographic code lookup for search results assembly</h2><span id='topic+code_lookup'></span>

<h3>Description</h3>

<p>A data frame that can be used to look up common
codes for different bibliographic fields across
databases and merge them to a common format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>code_lookup
</code></pre>


<h3>Format</h3>

<p>A data frame with 226 obs of 12 variables
</p>

<dl>
<dt>code</dt><dd><p>code used in search results</p>
</dd>
<dt>order</dt><dd><p>the order in which to rank fields in assembled results</p>
</dd>
<dt>category_description</dt><dd><p>type of bibliographic data</p>
</dd>
<dt>entry_description</dt><dd><p>description of field</p>
</dd>
<dt>field</dt><dd><p>bibliographic field that codes correspond to</p>
</dd>
<dt>ris_generic</dt><dd><p>logical: If the code is used in generic ris files</p>
</dd>
<dt>ris_wos</dt><dd><p>logical: If the code is used in Web of Science ris files</p>
</dd>
<dt>ris_pubmed</dt><dd><p>logical: If the code is used in PubMed ris files</p>
</dd>
<dt>ris_scopus</dt><dd><p>logical: If the code is used in Scopus ris files</p>
</dd>
<dt>ris_asp</dt><dd><p>logical: If the code is used in Academic Search Premier ris files</p>
</dd>
<dt>ris_ovid</dt><dd><p>logical: If the code is used in Ovid ris files</p>
</dd>
<dt>ris_synthesisr</dt><dd><p>logical: If the code used in synthesisr imports &amp; exports</p>
</dd></dl>


<hr>
<h2 id='deduplicate'>Remove duplicates from a bibliographic data set</h2><span id='topic+deduplicate'></span>

<h3>Description</h3>

<p>Removes duplicates using sensible defaults
</p>


<h3>Usage</h3>

<pre><code class='language-R'>deduplicate(data, match_by, method, type = "merge", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="deduplicate_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing bibliographic information.</p>
</td></tr>
<tr><td><code id="deduplicate_+3A_match_by">match_by</code></td>
<td>
<p>Name of the column in <code>data</code> where duplicates should be sought.</p>
</td></tr>
<tr><td><code id="deduplicate_+3A_method">method</code></td>
<td>
<p>The duplicate detection function to use; see see <code>link{string_}</code> or <code>link{fuzz_}</code> for examples. Passed to <code>find_duplicates</code>.</p>
</td></tr>
<tr><td><code id="deduplicate_+3A_type">type</code></td>
<td>
<p>How should entries be selected? Default is <code>"merge"</code> which selected the entries with the largest number of characters in each column. Alternatively <code>"select"</code> returns the row with the highest total number of characters.</p>
</td></tr>
<tr><td><code id="deduplicate_+3A_...">...</code></td>
<td>
<p>Arguments passed to <code>find_duplicates</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a wrapper function to <code><a href="#topic+find_duplicates">find_duplicates</a></code> and <code>extract_unique_references</code>, which tries to choose some sensible defaults. Use with care.
</p>


<h3>Value</h3>

<p>A <code>data.frame</code> containing data identified as unique.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+find_duplicates">find_duplicates</a></code> and <code><a href="#topic+extract_unique_references">extract_unique_references</a></code> for underlying functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my_df &lt;-  data.frame(
  title = c(
    "EviAtlas: a tool for visualising evidence synthesis databases",
    "revtools: An R package to support article screening for evidence synthesis",
    "An automated approach to identifying search terms for systematic reviews",
    "Reproducible, flexible and high-throughput data extraction from primary literature",
    "eviatlas:tool for visualizing evidence synthesis databases.",
    "REVTOOLS a package to support article-screening for evidence synthsis"
  ),
  year = c("2019", "2019", "2019", "2019", NA, NA),
  authors = c("Haddaway et al", "Westgate",
              "Grames et al", "Pick et al", NA, NA),
  stringsAsFactors = FALSE
)

# run deduplication
dups &lt;- find_duplicates(
  my_df$title,
  method = "string_osa",
  rm_punctuation = TRUE,
  to_lower = TRUE
)

extract_unique_references(my_df, matches = dups)

# or, in one line:
deduplicate(my_df, "title",
  method = "string_osa",
  rm_punctuation = TRUE,
  to_lower = TRUE)
</code></pre>

<hr>
<h2 id='detect_'>Detect file formatting information</h2><span id='topic+detect_'></span><span id='topic+detect_parser'></span><span id='topic+detect_delimiter'></span><span id='topic+detect_lookup'></span><span id='topic+detect_year'></span>

<h3>Description</h3>

<p>Bibliographic data can be stored in a number of different file types, meaning that detecting consistent attributes of those files is necessary if they are to be parsed accurately. These functions attempt to identify some of those key file attributes. Specifically, <code>detect_parser</code> determines which <code><a href="#topic+parse_">parse_</a></code> function to use; <code>detect_delimiter</code> and <code>detect_lookup</code> identify different attributes of RIS files; and <code>detect_year</code> attempts to fill gaps in publication years from other information stored in a <code>data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>detect_parser(x)

detect_delimiter(x)

detect_lookup(tags)

detect_year(df)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="detect__+3A_x">x</code></td>
<td>
<p>A character vector containing bibliographic data</p>
</td></tr>
<tr><td><code id="detect__+3A_tags">tags</code></td>
<td>
<p>A character vector containing RIS tags.</p>
</td></tr>
<tr><td><code id="detect__+3A_df">df</code></td>
<td>
<p>a data.frame containing bibliographic data</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>detect_parser</code> and <code>detect_delimiter</code> return a length-1 character; <code>detect_year</code> returns a character vector listing estimated publication years; and <code>detect_lookup</code> returns a <code>data.frame</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>revtools &lt;- c(
  "",
  "PMID- 31355546",
  "VI  - 10",
  "IP  - 4",
  "DP  - 2019 Dec",
  "TI  - revtools: An R package to support article
         screening for evidence synthesis.",
  "PG  - 606-614",
  "LID - 10.1002/jrsm.1374 [doi]",
  "AU  - Westgate MJ",
  "LA  - eng",
  "PT  - Journal Article",
  "JT  - Research Synthesis Methods",
  ""
)

# detect basic attributes of ris files
detect_parser(revtools)
detect_delimiter(revtools)

# determine which tag format to use
tags &lt;- trimws(unlist(lapply(
  strsplit(revtools, "- "),
  function(a){a[1]}
)))
pubmed_tag_list &lt;- detect_lookup(tags[!is.na(tags)])

# find year data in other columns
df &lt;- as.data.frame(parse_pubmed(revtools))
df$year &lt;- detect_year(df)
</code></pre>

<hr>
<h2 id='extract_unique_references'>Remove duplicates from a bibliographic data set</h2><span id='topic+extract_unique_references'></span>

<h3>Description</h3>

<p>Given a list of duplicate entries and a data set, this function extracts only unique references.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extract_unique_references(data, matches, type = "merge")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extract_unique_references_+3A_data">data</code></td>
<td>
<p>A <code>data.frame</code> containing bibliographic information.</p>
</td></tr>
<tr><td><code id="extract_unique_references_+3A_matches">matches</code></td>
<td>
<p>A vector showing which entries in <code>data</code> are duplicates.</p>
</td></tr>
<tr><td><code id="extract_unique_references_+3A_type">type</code></td>
<td>
<p>How should entries be selected to retain? Default is <code>"merge"</code> which selects the entries with the largest number of characters in each column. Alternatively <code>"select"</code> which returns the row with the highest total number of characters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a <code>data.frame</code> of unique references.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+find_duplicates">find_duplicates</a></code>, <code><a href="#topic+deduplicate">deduplicate</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my_df &lt;-  data.frame(
  title = c(
    "EviAtlas: a tool for visualising evidence synthesis databases",
    "revtools: An R package to support article screening for evidence synthesis",
    "An automated approach to identifying search terms for systematic reviews",
    "Reproducible, flexible and high-throughput data extraction from primary literature",
    "eviatlas:tool for visualizing evidence synthesis databases.",
    "REVTOOLS a package to support article-screening for evidence synthsis"
  ),
  year = c("2019", "2019", "2019", "2019", NA, NA),
  authors = c("Haddaway et al", "Westgate",
              "Grames et al", "Pick et al", NA, NA),
  stringsAsFactors = FALSE
)

# run deduplication
dups &lt;- find_duplicates(
  my_df$title,
  method = "string_osa",
  rm_punctuation = TRUE,
  to_lower = TRUE
)

extract_unique_references(my_df, matches = dups)

# or, in one line:
deduplicate(my_df, "title",
  method = "string_osa",
  rm_punctuation = TRUE,
  to_lower = TRUE)
</code></pre>

<hr>
<h2 id='find_duplicates'>Detect duplicate values</h2><span id='topic+find_duplicates'></span>

<h3>Description</h3>

<p>Identifies duplicate bibliographic entries using different duplicate detection methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>find_duplicates(
  data,
  method = "exact",
  group_by,
  threshold,
  to_lower = FALSE,
  rm_punctuation = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="find_duplicates_+3A_data">data</code></td>
<td>
<p>A character vector containing duplicate bibliographic entries.</p>
</td></tr>
<tr><td><code id="find_duplicates_+3A_method">method</code></td>
<td>
<p>A string indicating how matching should be calculated. Either <code>"exact"</code> for exact matching (the default), or the name of a function for calculating string distance.</p>
</td></tr>
<tr><td><code id="find_duplicates_+3A_group_by">group_by</code></td>
<td>
<p>An optional vector, data.frame or list containing data to use as 'grouping' variables; that is, categories within which duplicates should be sought. Defaults to NULL, in which case all entries are compared against all others. Ignored if <code>method = "exact"</code>.</p>
</td></tr>
<tr><td><code id="find_duplicates_+3A_threshold">threshold</code></td>
<td>
<p>Numeric: the cutoff threshold for deciding if two strings are duplcates. Sensible values depend on the <code>method</code> chosen. Defaults to 5 is <code>method = "string_osa"</code> and must be specified in all other instances except <code>method = "exact"</code> (where no threshold is required).</p>
</td></tr>
<tr><td><code id="find_duplicates_+3A_to_lower">to_lower</code></td>
<td>
<p>Logical: Should all entries be converted to lower case before calculating string distance? Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="find_duplicates_+3A_rm_punctuation">rm_punctuation</code></td>
<td>
<p>Logical: Should punctuation should be removed before calculating string distance? Defaults to FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a vector of duplicate matches, with <code>attributes</code> listing methods used.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+string_">string_</a></code> or <code><a href="#topic+fuzz_">fuzz_</a></code> for suitable functions to pass to <code>methods</code>; <code><a href="#topic+extract_unique_references">extract_unique_references</a></code> and <code><a href="#topic+deduplicate">deduplicate</a></code> for higher-level functions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>my_df &lt;-  data.frame(
  title = c(
    "EviAtlas: a tool for visualising evidence synthesis databases",
    "revtools: An R package to support article screening for evidence synthesis",
    "An automated approach to identifying search terms for systematic reviews",
    "Reproducible, flexible and high-throughput data extraction from primary literature",
    "eviatlas:tool for visualizing evidence synthesis databases.",
    "REVTOOLS a package to support article-screening for evidence synthsis"
  ),
  year = c("2019", "2019", "2019", "2019", NA, NA),
  authors = c("Haddaway et al", "Westgate",
              "Grames et al", "Pick et al", NA, NA),
  stringsAsFactors = FALSE
)

# run deduplication
dups &lt;- find_duplicates(
  my_df$title,
  method = "string_osa",
  rm_punctuation = TRUE,
  to_lower = TRUE
)

extract_unique_references(my_df, matches = dups)

# or, in one line:
deduplicate(my_df, "title",
  method = "string_osa",
  rm_punctuation = TRUE,
  to_lower = TRUE)
</code></pre>

<hr>
<h2 id='format_citation'>Format a citation</h2><span id='topic+format_citation'></span>

<h3>Description</h3>

<p>This function takes an object of class data.frame, list, or bibliography and returns a formatted citation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>format_citation(
  data,
  details = TRUE,
  abstract = FALSE,
  add_html = FALSE,
  line_breaks = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="format_citation_+3A_data">data</code></td>
<td>
<p>An object of class data.frame, list, or or bibliography.</p>
</td></tr>
<tr><td><code id="format_citation_+3A_details">details</code></td>
<td>
<p>Logical: Should identifying information such as author names &amp; journal titles be displayed? Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="format_citation_+3A_abstract">abstract</code></td>
<td>
<p>Logical: Should the abstract be shown (if available)? Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="format_citation_+3A_add_html">add_html</code></td>
<td>
<p>Logical: Should the journal title be italicized using html codes? Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="format_citation_+3A_line_breaks">line_breaks</code></td>
<td>
<p>Either logical, stating whether line breaks should be added, or numeric stating how many characters should separate consecutive line breaks. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="format_citation_+3A_...">...</code></td>
<td>
<p>any other arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a string of length equal to length(data) that contains formatted citations.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>roses &lt;- c("@article{haddaway2018,
  title={ROSES RepOrting standards for Systematic Evidence Syntheses:
  pro forma, flow-diagram and descriptive summary of the plan and
  conduct of environmental systematic reviews and systematic maps},
  author={Haddaway, Neal R and Macura, Biljana and Whaley, Paul and Pullin, Andrew S},
  journal={Environmental Evidence},
  volume={7},
  number={1},
  pages={7},
  year={2018},
  publisher={Springer}
}")

tmp &lt;- tempfile()
writeLines(roses, tmp)

citation &lt;- read_ref(tmp)
format_citation(citation)
</code></pre>

<hr>
<h2 id='fuzz_'>Calculate similarity between two strings</h2><span id='topic+fuzz_'></span><span id='topic+fuzzdist'></span><span id='topic+fuzz_m_ratio'></span><span id='topic+fuzz_partial_ratio'></span><span id='topic+fuzz_token_sort_ratio'></span><span id='topic+fuzz_token_set_ratio'></span>

<h3>Description</h3>

<p>These functions duplicate the approach of the 'fuzzywuzzy' Python library for calculating string similarity.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fuzzdist(
  a,
  b,
  method = c("fuzz_m_ratio", "fuzz_partial_ratio", "fuzz_token_sort_ratio",
    "fuzz_token_set_ratio")
)

fuzz_m_ratio(a, b)

fuzz_partial_ratio(a, b)

fuzz_token_sort_ratio(a, b)

fuzz_token_set_ratio(a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fuzz__+3A_a">a</code></td>
<td>
<p>A character vector of items to match to b.</p>
</td></tr>
<tr><td><code id="fuzz__+3A_b">b</code></td>
<td>
<p>A character vector of items to match to a.</p>
</td></tr>
<tr><td><code id="fuzz__+3A_method">method</code></td>
<td>
<p>The method to use for fuzzy matching.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a score of same length as b, giving the proportional dissimilarity between a and b.
</p>


<h3>Note</h3>

<p><code>fuzz_m_ratio</code> is a measure of the number of letters that match between two strings. It is calculated as one minus two times the number of matched characters, divided by the number of characters in both strings.
</p>
<p><code>fuzz_partial_ratio</code> calculates the extent to which one string is a subset of the other. If one string is a perfect subset, then this will be zero.
</p>
<p><code>fuzz_token_sort_ratio</code> sorts the words in both strings into alphabetical order, and checks their similarity using fuzz_m_ratio.
</p>
<p><code>fuzz_token_set_ratio</code> is similar to fuzz_token_sort_ratio, but compares both sorted strings to each other, and to a third group made of words common to both strings. It then returns the maximum value of fuzz_m_ratio from these comparisons.
</p>
<p><code>fuzzdist</code> is a wrapper function, for compatability with <code>stringdist</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>fuzzdist("On the Origin of Species",
         "Of the Original Specs",
         method = "fuzz_m_ratio")
</code></pre>

<hr>
<h2 id='merge_columns'>Bind two or more data frames with different columns</h2><span id='topic+merge_columns'></span>

<h3>Description</h3>

<p>Takes two or more data.frames with different column names or different column orders and binds them to a single data.frame.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>merge_columns(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="merge_columns_+3A_x">x</code></td>
<td>
<p>Either a data.frame or a list of data.frames.</p>
</td></tr>
<tr><td><code id="merge_columns_+3A_y">y</code></td>
<td>
<p>A data.frame, optional if x is a list.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a single data.frame with all the input data frames merged.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df_1 &lt;-  data.frame(
  title = c(
    "EviAtlas: a tool for visualising evidence synthesis databases",
    "revtools: An R package to support article screening for evidence synthesis"
  ),
  year = c("2019", "2019")
)

df_2 &lt;-  data.frame(
  title = c(
    "An automated approach to identifying search terms for systematic reviews",
    "Reproducible, flexible and high-throughput data extraction from primary literature"
  ),
  authors = c("Grames et al", "Pick et al")
)

merge_columns(df_1, df_2)
</code></pre>

<hr>
<h2 id='override_duplicates'>Manually override duplicates</h2><span id='topic+override_duplicates'></span>

<h3>Description</h3>

<p>Re-assign group numbers to text that was classified as duplicated but is unique.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>override_duplicates(matches, overrides)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="override_duplicates_+3A_matches">matches</code></td>
<td>
<p>Numeric: a vector of group numbers for texts that indicates duplicates and unique values returned by the <code><a href="#topic+find_duplicates">find_duplicates</a></code> function.</p>
</td></tr>
<tr><td><code id="override_duplicates_+3A_overrides">overrides</code></td>
<td>
<p>Numeric: a vector of group numbers that are not true duplicates.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The input <code>matches</code> vector with unique group numbers for members of groups that the user overrides.
</p>

<hr>
<h2 id='parse_'>Parse bibliographic text in a variety of formats</h2><span id='topic+parse_'></span><span id='topic+parse_pubmed'></span><span id='topic+parse_ris'></span><span id='topic+parse_bibtex'></span><span id='topic+parse_csv'></span><span id='topic+parse_tsv'></span>

<h3>Description</h3>

<p>Text in standard formats - such as imported via <code><a href="base.html#topic+readLines">readLines</a></code> - can be parsed using a variety of standard formats. Use <code><a href="#topic+detect_parser">detect_parser</a></code> to determine which is the most appropriate parser for your situation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>parse_pubmed(x)

parse_ris(x, tag_naming = "best_guess")

parse_bibtex(x)

parse_csv(x)

parse_tsv(x)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="parse__+3A_x">x</code></td>
<td>
<p>A character vector containing bibliographic information in ris format.</p>
</td></tr>
<tr><td><code id="parse__+3A_tag_naming">tag_naming</code></td>
<td>
<p>What format are ris tags in? Defaults to &quot;best_guess&quot; See <code><a href="#topic+read_refs">read_refs</a></code> for a list of accepted arguments.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns an object of class <code>bibliography</code> (ris, bib, or pubmed formats) or <code>data.frame</code> (csv or tsv).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>eviatlas &lt;- c(
  "TY  - JOUR",
  "AU  - Haddaway, Neal R.",
  "AU  - Feierman, Andrew",
  "AU  - Grainger, Matthew J.",
  "AU  - Gray, Charles T.",
  "AU  - Tanriver-Ayder, Ezgi",
  "AU  - Dhaubanjar, Sanita",
  "AU  - Westgate, Martin J.",
  "PY  - 2019",
  "DA  - 2019/06/04",
  "TI  - EviAtlas: a tool for visualising evidence synthesis databases",
  "JO  - Environmental Evidence",
  "SP  - 22",
  "VL  - 8",
  "IS  - 1",
  "SN  - 2047-2382",
  "UR  - https://doi.org/10.1186/s13750-019-0167-1",
  "DO  - 10.1186/s13750-019-0167-1",
  "ID  - Haddaway2019",
  "ER  - "
)

detect_parser(eviatlas) # = "parse_ris"
df &lt;- as.data.frame(parse_ris(eviatlas))
ris_out &lt;- write_refs(df, format = "ris", file = FALSE)
</code></pre>

<hr>
<h2 id='read_refs'>Import bibliographic search results</h2><span id='topic+read_refs'></span><span id='topic+read_ref'></span>

<h3>Description</h3>

<p>Imports common bibliographic reference formats (i.e. .bib, .ris, or .txt).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>read_refs(
  filename,
  tag_naming = "best_guess",
  return_df = TRUE,
  verbose = FALSE
)

read_ref(
  filename,
  tag_naming = "best_guess",
  return_df = TRUE,
  verbose = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="read_refs_+3A_filename">filename</code></td>
<td>
<p>A path to a filename or vector of filenames containing search results to import.</p>
</td></tr>
<tr><td><code id="read_refs_+3A_tag_naming">tag_naming</code></td>
<td>
<p>Either a length-1 character stating how should ris tags be replaced (see details for a list of options), or an object inheriting from class <code>data.frame</code> containing user-defined replacement tags.</p>
</td></tr>
<tr><td><code id="read_refs_+3A_return_df">return_df</code></td>
<td>
<p>If TRUE (default), returns a data.frame; if FALSE, returns a list.</p>
</td></tr>
<tr><td><code id="read_refs_+3A_verbose">verbose</code></td>
<td>
<p>If TRUE, prints status updates (defaults to FALSE).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default for argument <code>tag_naming</code> is <code>"best_guess"</code>, which estimates what database has been used for ris tag replacement, then fills any gaps with generic tags. Any tags missing from the database (i.e. <code>code_lookup</code>) are passed unchanged. Other options are to use tags from Web of Science (<code>"wos"</code>), Scopus (<code>"scopus"</code>), Ovid (<code>"ovid"</code>) or Academic Search Premier (<code>"asp"</code>). If a <code>data.frame</code> is given, then it must contain two columns: <code>"code"</code> listing the original tags in the source document, and <code>"field"</code> listing the replacement column/tag names. The <code>data.frame</code> may optionally include a third column named <code>"order"</code>, which specifies the order of columns in the resulting <code>data.frame</code>; otherwise this will be taken as the row order. Finally, passing <code>"none"</code> to <code>replace_tags</code> suppresses tag replacement.
</p>


<h3>Value</h3>

<p>Returns a data.frame or list of assembled search results.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>read_ref</code>: Import a single file
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>litsearchr &lt;- c(
  "@article{grames2019,
  title={An automated approach to identifying search terms for
  systematic reviews using keyword co-occurrence networks},
  author={Grames, Eliza M and Stillman, Andrew N and Tingley, Morgan W and Elphick, Chris S},
  journal={Methods in Ecology and Evolution},
  volume={10},
  number={10},
  pages={1645--1654},
  year={2019},
  publisher={Wiley Online Library}
}"
)

tmp &lt;- tempfile()

writeLines(litsearchr, tmp)

df &lt;- read_refs(tmp, return_df = TRUE, verbose = TRUE)
</code></pre>

<hr>
<h2 id='review_duplicates'>Manually review potential duplicates</h2><span id='topic+review_duplicates'></span>

<h3>Description</h3>

<p>Allows users to manually review articles classified as duplicates.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>review_duplicates(text, matches)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="review_duplicates_+3A_text">text</code></td>
<td>
<p>A character vector of the text that was used to identify potential duplicates.</p>
</td></tr>
<tr><td><code id="review_duplicates_+3A_matches">matches</code></td>
<td>
<p>Numeric: a vector of group numbers for texts that indicates duplicates and unique values returned by the <code><a href="#topic+find_duplicates">find_duplicates</a></code> function.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> of potential duplicates grouped together.
</p>

<hr>
<h2 id='string_'>Calculate similarity between two strings</h2><span id='topic+string_'></span><span id='topic+string_osa'></span><span id='topic+string_lv'></span><span id='topic+string_dl'></span><span id='topic+string_hamming'></span><span id='topic+string_lcs'></span><span id='topic+string_qgram'></span><span id='topic+string_cosine'></span><span id='topic+string_jaccard'></span><span id='topic+string_jw'></span><span id='topic+string_soundex'></span>

<h3>Description</h3>

<p>These functions each access a specific <code>"methods"</code> argument provided by <code>stringdist</code>, and are provided for convenient calling by <code><a href="#topic+find_duplicates">find_duplicates</a></code>. They do not include any new functionality beyond that given by <code>stringdist</code>, which you should use for your own analyses.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>string_osa(a, b)

string_lv(a, b)

string_dl(a, b)

string_hamming(a, b)

string_lcs(a, b)

string_qgram(a, b)

string_cosine(a, b)

string_jaccard(a, b)

string_jw(a, b)

string_soundex(a, b)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="string__+3A_a">a</code></td>
<td>
<p>A character vector of items to match to b.</p>
</td></tr>
<tr><td><code id="string__+3A_b">b</code></td>
<td>
<p>A character vector of items to match to a.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a score of same length as b, giving the dissimilarity between a and b.
</p>

<hr>
<h2 id='synthesisr'>synthesisr: Import, assemble, and deduplicate bibiliographic datasets</h2><span id='topic+synthesisr'></span>

<h3>Description</h3>

<p>Systematic review searches include multiple databases
that export results in a variety of formats with overlap in
coverage between databases. To streamline the process of importing,
assembling, and deduplicating results, synthesisr recognizes
bibliographic files exported from databases commonly used for
systematic reviews and merges results into a standardized format.
</p>


<h3>Import &amp; Export</h3>

<p>The key task performed by <code>synthesisr</code> is flexible import and presentation of bibliographic data. This is typically achieved by <code><a href="#topic+read_refs">read_refs</a></code>, which can import multiple files at once and link them together into a single <code>data.frame</code>. Conversely, export is via <code><a href="#topic+write_refs">write_refs</a></code>. Users that require more detailed control can use the following functions:
</p>

<ul>
<li> <p><code><a href="#topic+detect_">detect_</a></code> Detect file attributes
</p>
</li>
<li> <p><code><a href="#topic+parse_">parse_</a></code> Parse a vector containing bibliographic data
</p>
</li>
<li> <p><code><a href="#topic+clean_">clean_</a></code> Cleaning functions for author and column names
</p>
</li>
<li> <p><code><a href="#topic+code_lookup">code_lookup</a></code> A dataset of potential ris tags
</p>
</li></ul>



<h3>Data formatting</h3>


<ul>
<li> <p><code><a href="#topic+bibliography-class">bibliography-class</a></code> Methods for class 'bibliography'
</p>
</li>
<li> <p><code><a href="#topic+merge_columns">merge_columns</a></code> rbind two data.frames with different numbers of columns
</p>
</li>
<li> <p><code><a href="#topic+format_citation">format_citation</a></code> Return a clean citation from a bibliography or data.frame
</p>
</li>
<li> <p><code><a href="#topic+add_line_breaks">add_line_breaks</a></code> Set a maximum character width for strings
</p>
</li></ul>



<h3>Deduplication</h3>

<p>When importing from multiple databases, it is likely that there will be duplicates in the resulting dataset. The easiest way to deal with this problem in <code>synthesisr</code> is using the <code><a href="#topic+deduplicate">deduplicate</a></code> command; but this can be risky, particularly if there are no DOIs in the dataset. To get finer control of the deduplication process, consider using the sub-functions:
</p>

<ul>
<li> <p><code><a href="#topic+find_duplicates">find_duplicates</a></code> Locate potentially duplicated references
</p>
</li>
<li> <p><code><a href="#topic+extract_unique_references">extract_unique_references</a></code> Return a data.frame with only 'unique' references
</p>
</li>
<li> <p><code><a href="#topic+review_duplicates">review_duplicates</a></code> Manually review potential duplicates
</p>
</li>
<li> <p><code><a href="#topic+override_duplicates">override_duplicates</a></code> Manually override identified duplicates
</p>
</li>
<li> <p><code><a href="#topic+fuzz_">fuzz_</a></code> Fuzzy string matching c/o 'fuzzywuzzy'
</p>
</li>
<li> <p><code><a href="#topic+string_">string_</a></code> Fuzzy string matching c/o <code>stringdist</code>
</p>
</li></ul>


<hr>
<h2 id='write_bib'>Export data to a bibliographic format</h2><span id='topic+write_bib'></span><span id='topic+write_ris'></span><span id='topic+write_refs'></span>

<h3>Description</h3>

<p>This function exports data.frames containing bibliographic information to either a .ris or .bib file.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>write_bib(x)

write_ris(x, tag_naming = "synthesisr")

write_refs(x, format = "ris", tag_naming = "synthesisr", file = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="write_bib_+3A_x">x</code></td>
<td>
<p>Either a data.frame containing bibliographic information or an object of class bibliography.</p>
</td></tr>
<tr><td><code id="write_bib_+3A_tag_naming">tag_naming</code></td>
<td>
<p>what naming convention should be used to write RIS files? See details for options.</p>
</td></tr>
<tr><td><code id="write_bib_+3A_format">format</code></td>
<td>
<p>What format should the data be exported as? Options are ris or bib.</p>
</td></tr>
<tr><td><code id="write_bib_+3A_file">file</code></td>
<td>
<p>Either logical indicating whether a file should be written (defaulting to FALSE), or a character giving the name of the file to be written.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Returns a character vector containing bibliographic information in the specified format if <code>file</code> is FALSE, or saves output to a file if TRUE.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>write_bib</code>: Format a bib file for export
</p>
</li>
<li> <p><code>write_ris</code>: Format a ris file for export
</p>
</li></ul>


<h3>Examples</h3>

<pre><code class='language-R'>eviatlas &lt;- c(
  "TY  - JOUR",
  "AU  - Haddaway, Neal R.",
  "AU  - Feierman, Andrew",
  "AU  - Grainger, Matthew J.",
  "AU  - Gray, Charles T.",
  "AU  - Tanriver-Ayder, Ezgi",
  "AU  - Dhaubanjar, Sanita",
  "AU  - Westgate, Martin J.",
  "PY  - 2019",
  "DA  - 2019/06/04",
  "TI  - EviAtlas: a tool for visualising evidence synthesis databases",
  "JO  - Environmental Evidence",
  "SP  - 22",
  "VL  - 8",
  "IS  - 1",
  "SN  - 2047-2382",
  "UR  - https://doi.org/10.1186/s13750-019-0167-1",
  "DO  - 10.1186/s13750-019-0167-1",
  "ID  - Haddaway2019",
  "ER  - "
)

detect_parser(eviatlas) # = "parse_ris"
df &lt;- as.data.frame(parse_ris(eviatlas))
ris_out &lt;- write_refs(df, format = "ris", file = FALSE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
