<!DOCTYPE html><html><head><title>Help for package lspartition</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {lspartition}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#lspartition-package'><p>Nonparametric Estimation and Inference using Partitioning-Based Least Squares Regression</p></a></li>
<li><a href='#lspkselect'><p>Tuning Parameter Selection Procedures for Partitioning-Based Regression Estimation and Inference</p></a></li>
<li><a href='#lsplincom'><p>Linear Combination of Estimators for <span class="pkg">lspartition</span> Package</p></a></li>
<li><a href='#lsprobust'><p>Partitioning-Based Least Squares Regression with Robust Inference.</p></a></li>
<li><a href='#lsprobust.plot'><p>Graphic Presentation of Results for <span class="pkg">lspartition</span> Package</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Nonparametric Estimation and Inference Procedures using
Partitioning-Based Least Squares Regression</td>
</tr>
<tr>
<td>Version:</td>
<td>0.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-08-08</td>
</tr>
<tr>
<td>Author:</td>
<td>Matias D. Cattaneo, Max H. Farrell, Yingjie Feng</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Yingjie Feng &lt;yingjief@princeton.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Tools for statistical analysis using partitioning-based least squares regression as described in Cattaneo, Farrell and Feng (2019a, &lt;<a href="https://doi.org/10.48550/arXiv.1804.04916">doi:10.48550/arXiv.1804.04916</a>&gt;) and Cattaneo, Farrell and Feng (2019b, &lt;<a href="https://doi.org/10.48550/arXiv.1906.00202">doi:10.48550/arXiv.1906.00202</a>&gt;): lsprobust() for nonparametric point estimation of regression functions and their derivatives and for robust bias-corrected (pointwise and uniform) inference; lspkselect() for data-driven selection of the IMSE-optimal number of knots; lsprobust.plot() for regression plots with robust confidence intervals and confidence bands; lsplincom() for estimation and inference for linear combinations of regression functions from different groups.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>ggplot2, pracma, mgcv, combinat, matrixStats, MASS, dplyr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-08-08 20:21:51 UTC; Administrator</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-08-08 22:40:06 UTC</td>
</tr>
</table>
<hr>
<h2 id='lspartition-package'>Nonparametric Estimation and Inference using Partitioning-Based Least Squares Regression</h2><span id='topic+lspartition-package'></span>

<h3>Description</h3>

<p>This package provides tools for statistical analysis using B-splines, wavelets, and
piecewise polynomials as described in
<a href="https://arxiv.org/abs/1804.04916">Cattaneo, Farrell and Feng (2019a)</a>:
<code><a href="#topic+lsprobust">lsprobust</a></code> for least squares point estimation with robust bias-corrected pointwise and
uniform inference procedures; <code><a href="#topic+lspkselect">lspkselect</a></code> for data-driven procedures
for selecting the IMSE-optimal number of partitioning knots; <code><a href="#topic+lsprobust.plot">lsprobust.plot</a></code>
for regression plots with robust confidence intervals and confidence bands;
<code><a href="#topic+lsplincom">lsplincom</a></code> for estimation and inference for linear combination of regression
functions of different groups.
</p>
<p>The companion software article, <a href="https://arxiv.org/abs/1906.00202">Cattaneo, Farrell and Feng (2019b)</a>,
provides further implementation details and empirical illustrations.
</p>


<h3>Author(s)</h3>

<p>Matias D. Cattaneo, Princeton University, Princeton, NJ. <a href="mailto:cattaneo@princeton.edu">cattaneo@princeton.edu</a>.
</p>
<p>Max H. Farrell, University of Chicago, Chicago, IL. <a href="mailto:max.farrell@chicagobooth.edu">max.farrell@chicagobooth.edu</a>.
</p>
<p>Yingjie Feng (maintainer), Princeton University, Princeton, NJ. <a href="mailto:yingjief@princeton.edu">yingjief@princeton.edu</a>.
</p>


<h3>References</h3>

<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019a): <a href="https://arxiv.org/abs/1804.04916">Large Sample Properties of Partitioning-Based Series Estimators</a>. Annals of Statistics, forthcoming. arXiv:1804.04916.
</p>
<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019b): <a href="https://arxiv.org/abs/1906.00202">lspartition: Partitioning-Based Least Squares Regression</a>. R Journal, forthcoming. arXiv:1906.00202.
</p>

<hr>
<h2 id='lspkselect'>Tuning Parameter Selection Procedures for Partitioning-Based Regression Estimation and Inference</h2><span id='topic+lspkselect'></span><span id='topic+print.lspkselect'></span><span id='topic+summary.lspkselect'></span>

<h3>Description</h3>

<p><code>lspkselect</code> implements data-driven procedures to select the Integrated Mean Squared Error (IMSE) optimal number of partitioning knots for partitioning-based least squares regression estimators. Three series methods are supported: B-splines, compactly supported wavelets, and piecewise polynomials.
See <a href="https://sites.google.com/site/nppackages/lspartition/Cattaneo-Farrell_2013_JoE.pdf?attredirects=0">Cattaneo and Farrell (2013)</a> and <a href="https://arxiv.org/abs/1804.04916">Cattaneo, Farrell and Feng (2019a)</a> for complete details.
</p>
<p>Companion commands: <code><a href="#topic+lsprobust">lsprobust</a></code> for partitioning-based least squares regression estimation and inference; <code><a href="#topic+lsprobust.plot">lsprobust.plot</a></code> for plotting results; <code><a href="#topic+lsplincom">lsplincom</a></code> for multiple sample estimation and inference.
</p>
<p>A detailed introduction to this command is given in <a href="https://arxiv.org/abs/1906.00202">Cattaneo, Farrell and Feng (2019b)</a>.
</p>
<p>For more details, and related Stata and R packages useful for empirical analysis,
visit <a href="https://sites.google.com/site/nppackages/">https://sites.google.com/site/nppackages/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lspkselect(y, x, m = NULL, m.bc = NULL, smooth = NULL,
  bsmooth = NULL, deriv = NULL, method = "bs", ktype = "uni",
  kselect = "imse-dpi", proj = TRUE, bc = "bc3", vce = "hc2",
  subset = NULL, rotnorm = TRUE)

## S3 method for class 'lspkselect'
print(x, ...)

## S3 method for class 'lspkselect'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lspkselect_+3A_y">y</code></td>
<td>
<p>Outcome variable.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_x">x</code></td>
<td>
<p>Independent variable. A matrix or data frame.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_m">m</code></td>
<td>
<p>Order of basis used in the main regression. Default is <code>m=2</code>.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_m.bc">m.bc</code></td>
<td>
<p>Order of basis used to estimate leading bias. Default is <code>m.bc=m+1</code>.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_smooth">smooth</code></td>
<td>
<p>Smoothness of B-splines for point estimation. When <code>smooth=s</code>, B-splines have <code>s</code>-order
continuous derivatives. Default is <code>smooth=m-2</code>.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_bsmooth">bsmooth</code></td>
<td>
<p>Smoothness of B-splines for bias correction. Default is <code>bsmooth=m.bc-2</code>.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_deriv">deriv</code></td>
<td>
<p>Derivative order of the regression function to be estimated. A vector object of the same
length as <code>ncol(x)</code>. Default is <code>deriv=c(0,...,0)</code>.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_method">method</code></td>
<td>
<p>Type of basis used for expansion. Options are <code>"bs"</code> for B-splines,
<code>"wav"</code> for compactly supported wavelets (Cohen, Daubechies and Vial, 1993),
and <code>"pp"</code> for piecewise polynomials. Default is <code>method="bs"</code>.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_ktype">ktype</code></td>
<td>
<p>Knot placement. Options are <code>"uni"</code> for evenly spaced knots over the
support of <code>x</code> and <code>"qua"</code> for quantile-spaced knots. Default is <code>ktype="uni"</code>.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_kselect">kselect</code></td>
<td>
<p>Method for selecting the number of inner knots used by <code>lspkselect</code>. Options
are <code>"imse-rot"</code> for a rule-of-thumb (ROT) implementation of IMSE-optimal number of knots,
<code>"imse-dpi"</code> for second generation direct plug-in (DPI) implementation of IMSE-optimal number
of knots, and <code>"all"</code> for both. Default is <code>kselect="imse-dpi"</code>.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_proj">proj</code></td>
<td>
<p>If <code>TRUE</code>, projection of leading approximation error onto the lower-order approximating space
is included for bias correction (splines and piecewise polynomial only). Default is <code>proj=TRUE</code>.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_bc">bc</code></td>
<td>
<p>Bias correction method. Options are <code>"bc1"</code> for higher-order-basis bias correction,
<code>"bc2"</code> for least squares bias correction, and <code>"bc3"</code> for plug-in bias correction.
Defaults are <code>"bc3"</code> for splines and piecewise polynomials and <code>"bc2"</code>
for wavelets.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_vce">vce</code></td>
<td>
<p>Procedure to compute the heteroskedasticity-consistent (HCk) variance-covariance matrix estimator with plug-in residuals. Options are
</p>

<ul>
<li> <p><code>"hc0"</code> for unweighted residuals (HC0).
</p>
</li>
<li> <p><code>"hc1"</code> for HC1 weights.
</p>
</li>
<li> <p><code>"hc2"</code> for HC2 weights. Default.
</p>
</li>
<li> <p><code>"hc3"</code> for HC3 weights.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lspkselect_+3A_subset">subset</code></td>
<td>
<p>Optional rule specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_rotnorm">rotnorm</code></td>
<td>
<p>If <code>TRUE</code>, ROT selection is adjusted using normal densities.</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_...">...</code></td>
<td>
<p>further arguments</p>
</td></tr>
<tr><td><code id="lspkselect_+3A_object">object</code></td>
<td>
<p>class <code>lspkselect</code> objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>ks</code></td>
<td>
<p>A matrix may contain <code>k.rot</code> (IMSE-optimal number of knots for
the main regression through ROT implementation), <code>k.bias.rot</code>
(IMSE-optimal number of knots for bias correction through ROT
implementation), <code>k.dpi</code> (IMSE-optimal number of knots for the
main regression through DPI implementation), <code>k.bias.dpi</code> (IMSE-optimal
number of knots for bias correction through DPI implementation)</p>
</td></tr>
<tr><td><code>opt</code></td>
<td>
<p>A list containing options passed to the function.</p>
</td></tr>
</table>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>print</code>: <code>print</code> method for class &quot;<code>lspkselect</code>&quot;.
</p>
</li>
<li> <p><code>summary</code>: <code>summary</code> method for class &quot;<code>lspkselect</code>&quot;.
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Matias D. Cattaneo, Princeton University, Princeton, NJ. <a href="mailto:cattaneo@princeton.edu">cattaneo@princeton.edu</a>.
</p>
<p>Max H. Farrell, University of Chicago, Chicago, IL. <a href="mailto:max.farrell@chicagobooth.edu">max.farrell@chicagobooth.edu</a>.
</p>
<p>Yingjie Feng (maintainer), Princeton University, Princeton, NJ. <a href="mailto:yingjief@princeton.edu">yingjief@princeton.edu</a>.
</p>


<h3>References</h3>

<p>Cattaneo, M. D., and M. H. Farrell (2013): <a href="https://sites.google.com/site/nppackages/lspartition/Cattaneo-Farrell_2013_JoE.pdf?attredirects=0">Optimal convergence rates, Bahadur representation, and asymptotic normality of partitioning estimators</a>. Journal of Econometrics 174(2): 127-143.
</p>
<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019a): <a href="https://arxiv.org/abs/1804.04916">Large Sample Properties of Partitioning-Based Series Estimators</a>. Annals of Statistics, forthcoming. arXiv:1804.04916.
</p>
<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019b): <a href="https://arxiv.org/abs/1906.00202">lspartition: Partitioning-Based Least Squares Regression</a>. R Journal, forthcoming. arXiv:1906.00202.
</p>
<p>Cohen, A., I. Daubechies, and P.Vial (1993): Wavelets on the Interval and Fast Wavelet Transforms. Applied and Computational Harmonic Analysis 1(1): 54-81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsprobust">lsprobust</a></code>, <code><a href="#topic+lsprobust.plot">lsprobust.plot</a></code>, <code><a href="#topic+lsplincom">lsplincom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x   &lt;- data.frame(runif(500), runif(500))
y   &lt;- sin(4*x[,1])+cos(x[,2])+rnorm(500)
est &lt;- lspkselect(y, x)
summary(est)

</code></pre>

<hr>
<h2 id='lsplincom'>Linear Combination of Estimators for <span class="pkg">lspartition</span> Package</h2><span id='topic+lsplincom'></span><span id='topic+print.lsplincom'></span><span id='topic+summary.lsplincom'></span>

<h3>Description</h3>

<p><code>lsplincom</code> implements user-specified linear combinations across different data sub-groups for regression functions estimation, and computes corresponding (pointwise and uniform) robust bias-corrected inference measures. Estimation and inference is implemented using the <span class="pkg">lspartition</span> package.
See <a href="https://sites.google.com/site/nppackages/lspartition/Cattaneo-Farrell_2013_JoE.pdf?attredirects=0">Cattaneo and Farrell (2013)</a> and <a href="https://arxiv.org/abs/1804.04916">Cattaneo, Farrell and Feng (2019a)</a> for complete details.
</p>
<p>A detailed introduction to this command is given in <a href="https://arxiv.org/abs/1906.00202">Cattaneo, Farrell and Feng (2019b)</a>.
</p>
<p>For more details, and related Stata and R packages useful for empirical analysis,
visit <a href="https://sites.google.com/site/nppackages/">https://sites.google.com/site/nppackages/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsplincom(y, x, G, R, eval = NULL, neval = NULL, level = 95,
  band = FALSE, cb.method = NULL, cb.grid = NULL, cb.ngrid = 50,
  B = 1000, subset = NULL, knot = NULL, ...)

## S3 method for class 'lsplincom'
print(x, ...)

## S3 method for class 'lsplincom'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsplincom_+3A_y">y</code></td>
<td>
<p>Outcome variable.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_x">x</code></td>
<td>
<p>Independent variable. A matrix or data frame.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_g">G</code></td>
<td>
<p>Group indicator. It may take on multiple discrete values.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_r">R</code></td>
<td>
<p>A numeric vector giving the linear combination of interest. Each element is the coefficient
of the conditional mean estimator of one group, and they are ordered ascendingly along the value
of <code>G</code>.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_eval">eval</code></td>
<td>
<p>Evaluation points. A matrix or data frame.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_neval">neval</code></td>
<td>
<p>Number of quantile-spaced evaluating points.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_level">level</code></td>
<td>
<p>Confidence level used for confidence intervals; default is <code>level=95</code>.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_band">band</code></td>
<td>
<p>If <code>TRUE</code>, the critical value for constructing confidence band is calculated. Default
is <code>band=FALSE</code>.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_cb.method">cb.method</code></td>
<td>
<p>Method used to calculate the critical value for confidence bands.
Options are <code>"pl"</code> for a simulation-based plug-in procedure, and
<code>"wb"</code> for a wild bootstrap procedure. If <code>band=TRUE</code> with
<code>cb.method</code> unspecified, default is <code>cb.method="pl"</code>.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_cb.grid">cb.grid</code></td>
<td>
<p>A matrix containing all grid points used to construct confidence bands. Each row
correponds to the coordinates of one grid point.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_cb.ngrid">cb.ngrid</code></td>
<td>
<p>A numeric vector of the same length as <code>ncol(x)</code>. Each element corresponds to
the number of grid points for each dimension used to implement uniform inference.
Default is <code>uni.ngrid=50</code>.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_b">B</code></td>
<td>
<p>Number of simulated samples used to obtain the critical value for confidence bands.
Default is <code>B=1000</code>.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_subset">subset</code></td>
<td>
<p>Optional rule specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_knot">knot</code></td>
<td>
<p>A list of numeric vectors giving the knot positions (including boundary knots) for each dimension
which are used in the main regression. The length of the list is equal to <code>ncol(x)</code>.
If not specified, it uses the number of knots either specified by users
or computed by the companion command <code>lspkselect</code> to generate the
corresponding knots according to the rule specified by <code>ktype</code>. See help for <code><a href="#topic+lsprobust">lsprobust</a></code>.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_...">...</code></td>
<td>
<p>Arguments to be passed to the function. See <code>lsprobust</code>.</p>
</td></tr>
<tr><td><code id="lsplincom_+3A_object">object</code></td>
<td>
<p>class <code>lsplincom</code> objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Estimate</code></td>
<td>
<p> A matrix containing eval (grid points), N (effective sample sizes),
tau.cl (point estimates with a basis of order <code>m</code>), tau.bc (bias corrected point
estimates with a basis of order <code>m.bc</code>), se.cl (standard error corresponding
to tau.cl), and se.rb (robust standard error).</p>
</td></tr>
<tr><td><code>sup.cval</code></td>
<td>
<p> Critical value for constructing confidence bands.</p>
</td></tr>
<tr><td><code>opt</code></td>
<td>
<p> A list containing options passed to the function.</p>
</td></tr>
</table>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>print</code>: <code>print</code> method for class &quot;<code>lsplincom</code>&quot;.
</p>
</li>
<li> <p><code>summary</code>: <code>summary</code> method for class &quot;<code>lsplincom</code>&quot;
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Matias D. Cattaneo, Princeton University, Princeton, NJ. <a href="mailto:cattaneo@princeton.edu">cattaneo@princeton.edu</a>.
</p>
<p>Max H. Farrell, University of Chicago, Chicago, IL. <a href="mailto:max.farrell@chicagobooth.edu">max.farrell@chicagobooth.edu</a>.
</p>
<p>Yingjie Feng (maintainer), Princeton University, Princeton, NJ. <a href="mailto:yingjief@princeton.edu">yingjief@princeton.edu</a>.
</p>


<h3>References</h3>

<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019a): <a href="https://arxiv.org/abs/1804.04916">Large Sample Properties of Partitioning-Based Series Estimators</a>. Annals of Statistics, forthcoming. arXiv:1804.04916.
</p>
<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019b): <a href="https://arxiv.org/abs/1906.00202">lspartition: Partitioning-Based Least Squares Regression</a>. R Journal, forthcoming. arXiv:1906.00202.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsprobust">lsprobust</a></code>, <code><a href="#topic+lspkselect">lspkselect</a></code>, <code><a href="#topic+lsprobust.plot">lsprobust.plot</a></code>,
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x   &lt;- runif(500)
y   &lt;- sin(4*x)+rnorm(500)
z   &lt;- c(rep(0, 250), rep(1, 250))
est &lt;- lsplincom(y, x, z, c(-1, 1))
summary(est)

</code></pre>

<hr>
<h2 id='lsprobust'>Partitioning-Based Least Squares Regression with Robust Inference.</h2><span id='topic+lsprobust'></span><span id='topic+print.lsprobust'></span><span id='topic+summary.lsprobust'></span>

<h3>Description</h3>

<p><code>lsprobust</code> implements partitioning-based least squares point estimators for the regression function and its derivatives. It also provides robust bias-corrected (pointwise and uniform) inference, including simulation-based confidence bands. Three series methods are supported: B-splines, compact supported wavelets, and piecewise polynomials.
See <a href="https://sites.google.com/site/nppackages/lspartition/Cattaneo-Farrell_2013_JoE.pdf?attredirects=0">Cattaneo and Farrell (2013)</a> and <a href="https://arxiv.org/abs/1804.04916">Cattaneo, Farrell and Feng (2019a)</a> for complete details.
</p>
<p>Companion commands: <code><a href="#topic+lspkselect">lspkselect</a></code> for data-driven IMSE-optimal selection of the number of knots on rectangular partitions; <code><a href="#topic+lsprobust.plot">lsprobust.plot</a></code> for plotting results; <code><a href="#topic+lsplincom">lsplincom</a></code> for multiple sample estimation and inference.
</p>
<p>A detailed introduction to this command is given in <a href="https://arxiv.org/abs/1906.00202">Cattaneo, Farrell and Feng (2019b)</a>.
</p>
<p>For more details, and related Stata and R packages useful for empirical analysis,
visit <a href="https://sites.google.com/site/nppackages/">https://sites.google.com/site/nppackages/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsprobust(y, x, eval = NULL, neval = NULL, method = "bs", m = NULL,
  m.bc = NULL, deriv = NULL, smooth = NULL, bsmooth = NULL,
  ktype = "uni", knot = NULL, nknot = NULL, same = TRUE,
  bknot = NULL, bnknot = NULL, J = NULL, bc = "bc3", proj = TRUE,
  kselect = "imse-dpi", vce = "hc2", level = 95, uni.method = NULL,
  uni.grid = NULL, uni.ngrid = 50, uni.out = FALSE, band = FALSE,
  B = 1000, subset = NULL, rotnorm = TRUE)

## S3 method for class 'lsprobust'
print(x, ...)

## S3 method for class 'lsprobust'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsprobust_+3A_y">y</code></td>
<td>
<p>Outcome variable.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_x">x</code></td>
<td>
<p>Independent variable. A matrix or data frame.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_eval">eval</code></td>
<td>
<p>Evaluation points. A matrix or data frame.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_neval">neval</code></td>
<td>
<p>Number of quantile-spaced evaluating points.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_method">method</code></td>
<td>
<p>Type of basis used for expansion. Options are <code>"bs"</code> for B-splines,
<code>"wav"</code> for compactly supported wavelets (Cohen, Daubechies and Vial, 1993),
and <code>"pp"</code> for piecewise polynomials. Default is <code>method="bs"</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_m">m</code></td>
<td>
<p>Order of basis used in the main regression. Default is <code>m=2</code>. For B-splines,
if <code>smooth</code> is specified but <code>m</code> is unspecified, default is <code>m=smooth+2</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_m.bc">m.bc</code></td>
<td>
<p>Order of basis used to estimate leading bias. Default is <code>m.bc=m+1</code>. For B-splines,
if <code>bsmooth</code> is specified but <code>m.bc</code> is unspecified, default is <code>m.bc=bsmooth+2</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_deriv">deriv</code></td>
<td>
<p>Derivative order of the regression function to be estimated. A vector object of the same
length as <code>ncol(x)</code>. Default is <code>deriv=c(0,...,0)</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_smooth">smooth</code></td>
<td>
<p>Smoothness of B-splines for point estimation. When <code>smooth=s</code>, B-splines have <code>s</code>-order
continuous derivatives. Default is <code>smooth=m-2</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_bsmooth">bsmooth</code></td>
<td>
<p>Smoothness of B-splines for bias correction. Default is <code>bsmooth=m.bc-2</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_ktype">ktype</code></td>
<td>
<p>Knot placement. Options are <code>"uni"</code> for evenly-spaced knots over the
support of <code>x</code> and <code>"qua"</code> for quantile-spaced knots. Default is <code>ktype="uni"</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_knot">knot</code></td>
<td>
<p>A list of numeric vectors giving the knot positions (including boundary knots) for each dimension
which are used in the main regression. The length of the list is equal to <code>ncol(x)</code>.
If not specified, it uses the number of knots either specified by users
or computed by the companion command <code>lspkselect</code> to generate the
corresponding knots according to the rule specified by <code>ktype</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_nknot">nknot</code></td>
<td>
<p>A numeric vector of the same length as <code>ncol(x)</code>. Each element corresponds to
the number of <em>inner</em> partitioning knots for each dimension used in the main regression.
If not specified, <code>nknot</code> is computed by the companion command <code>lspkselect</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_same">same</code></td>
<td>
<p>If <code>TRUE</code>, the same knots are used for bias correction as that for the
main regression. Default is <code>same=TRUE</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_bknot">bknot</code></td>
<td>
<p>A list of numeric vectors giving knot positions used for bias correction. If not
specified and <code>same=FALSE</code>, it uses the number of knots either specified by
users or computed by the companion command <code>lspkselect</code> to generate
knots according to the rule specified by <code>ktype</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_bnknot">bnknot</code></td>
<td>
<p>A numeric vector of the same length as <code>ncol(x)</code>. Each element corresponds
to the number of <em>inner</em> partitioning knots for each dimension used for bias
correction. If not specified, <code>bnknot</code> is computed by the companion command <code>lspkselect</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_j">J</code></td>
<td>
<p>A numeric vector containing resolution levels of father wavelets for each dimension.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_bc">bc</code></td>
<td>
<p>Bias correction method. Options are <code>"bc1"</code> for higher-order-basis bias correction,
<code>"bc2"</code> for least squares bias correction, and <code>"bc3"</code> for plug-in bias correction.
Default are <code>"bc3"</code> for splines and piecewise polynomials and <code>"bc2"</code>
for wavelets.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_proj">proj</code></td>
<td>
<p>If <code>TRUE</code>, projection of leading approximation error onto the lower-order approximation space
is included for bias correction (splines and piecewise polynomials only). Default is
<code>proj=TRUE</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_kselect">kselect</code></td>
<td>
<p>Method for selecting the number of <em>inner</em> knots used by <code>lspkselect</code>. Options
are <code>"imse-rot"</code> for ROT implementation of IMSE-optimal number of knots and
<code>"imse-dpi"</code> for second generation of DPI implementation of IMSE-optimal number
of knots. Default is <code>kselect="imse-dpi"</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_vce">vce</code></td>
<td>
<p>Procedure to compute the heteroskedasticity-consistent (HCk) variance-covariance matrix estimator with plug-in residuals. Options are
</p>

<ul>
<li> <p><code>"hc0"</code> for unweighted residuals (HC0).
</p>
</li>
<li> <p><code>"hc1"</code> for HC1 weights.
</p>
</li>
<li> <p><code>"hc2"</code> for HC2 weights. Default.
</p>
</li>
<li> <p><code>"hc3"</code> for HC3 weights.
</p>
</li></ul>
</td></tr>
<tr><td><code id="lsprobust_+3A_level">level</code></td>
<td>
<p>Confidence level used for confidence intervals; default is <code>level=95</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_uni.method">uni.method</code></td>
<td>
<p>Method used to implement uniform inference. Options are <code>"pl"</code> for
a simulation-based plug-in procedure, <code>"wb"</code> for a wild bootstrap
procedure. If unspecified, neither procedure is
implemented. Default is <code>uni.method=NULL</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_uni.grid">uni.grid</code></td>
<td>
<p>A matrix containing all grid points used to implement uniform inference. Each row
correponds to the coordinates of one grid point.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_uni.ngrid">uni.ngrid</code></td>
<td>
<p>A numeric vector of the same length as <code>ncol(x)</code>. Each element corresponds to
the number of grid points for each dimension used to implement uniform inference.
Default is <code>uni.ngrid=50</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_uni.out">uni.out</code></td>
<td>
<p>If <code>TRUE</code>, the quantities used to implement uniform inference is outputted. Default is
<code>uni.out=FALSE</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_band">band</code></td>
<td>
<p>If <code>TRUE</code>, the critical value for constructing confidence band is calculated. Default
is <code>band=FALSE</code>. If <code>band=TRUE</code> with <code>uni.method</code> unspecified,
default is <code>uni.method="pl"</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_b">B</code></td>
<td>
<p>Number of simulated samples used to obtain the critical value for confidence bands.
Default is <code>B=1000</code>.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_subset">subset</code></td>
<td>
<p>Optional rule specifying a subset of observations to be used.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_rotnorm">rotnorm</code></td>
<td>
<p>If <code>TRUE</code>, ROT selection is adjusted using normal densities.</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_...">...</code></td>
<td>
<p>further arguments</p>
</td></tr>
<tr><td><code id="lsprobust_+3A_object">object</code></td>
<td>
<p>class <code>lsprobust</code> objects.</p>
</td></tr>
</table>


<h3>Value</h3>

<table>
<tr><td><code>Estimate</code></td>
<td>
<p> A matrix containing eval (grid points), N (effective sample sizes),
tau.cl (point estimates with a basis of order <code>m</code>), tau.bc (bias corrected point
estimates with a basis of order <code>m.bc</code>), se.cl (standard error corresponding
to tau.cl), and se.rb (robust standard error).</p>
</td></tr>
<tr><td><code>k.num</code></td>
<td>
<p> A matrix containing the number of inner partitioning knots used in the main
regression and bias correction for each covariate.</p>
</td></tr>
<tr><td><code>knot</code></td>
<td>
<p> A list of knots for point estimation.</p>
</td></tr>
<tr><td><code>bknot</code></td>
<td>
<p> A list of knots for bias correction.</p>
</td></tr>
<tr><td><code>sup.cval</code></td>
<td>
<p> Critical value for constructing confidence band.</p>
</td></tr>
<tr><td><code>uni.output</code></td>
<td>
<p> A list containing quantities used to implement uniform inference.</p>
</td></tr>
<tr><td><code>opt</code></td>
<td>
<p> A list containing options passed to the function.</p>
</td></tr>
</table>


<h3>Methods (by generic)</h3>


<ul>
<li> <p><code>print</code>: <code>print</code> method for class &quot;<code>lsprobust</code>&quot;
</p>
</li>
<li> <p><code>summary</code>: <code>summary</code> method for class &quot;<code>lsprobust</code>&quot;
</p>
</li></ul>


<h3>Author(s)</h3>

<p>Matias D. Cattaneo, Princeton University, Princeton, NJ. <a href="mailto:cattaneo@princeton.edu">cattaneo@princeton.edu</a>.
</p>
<p>Max H. Farrell, University of Chicago, Chicago, IL. <a href="mailto:max.farrell@chicagobooth.edu">max.farrell@chicagobooth.edu</a>.
</p>
<p>Yingjie Feng (maintainer), Princeton University, Princeton, NJ. <a href="mailto:yingjief@princeton.edu">yingjief@princeton.edu</a>.
</p>


<h3>References</h3>

<p>Cattaneo, M. D., and M. H. Farrell (2013): <a href="https://sites.google.com/site/nppackages/lspartition/Cattaneo-Farrell_2013_JoE.pdf?attredirects=0">Optimal convergence rates, Bahadur representation, and asymptotic normality of partitioning estimators</a>. Journal of Econometrics 174(2): 127-143.
</p>
<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019a): <a href="https://arxiv.org/abs/1804.04916">Large Sample Properties of Partitioning-Based Series Estimators</a>. Annals of Statistics, forthcoming. arXiv:1804.04916.
</p>
<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019b): <a href="https://arxiv.org/abs/1906.00202">lspartition: Partitioning-Based Least Squares Regression</a>. R Journal, forthcoming. arXiv:1906.00202.
</p>
<p>Cohen, A., I. Daubechies, and P.Vial (1993): Wavelets on the Interval and Fast Wavelet Transforms. Applied and Computational Harmonic Analysis 1(1): 54-81.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lspkselect">lspkselect</a></code>, <code><a href="#topic+lsprobust.plot">lsprobust.plot</a></code>, <code><a href="#topic+lsplincom">lsplincom</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x   &lt;- data.frame(runif(500), runif(500))
y   &lt;- sin(4*x[,1])+cos(x[,2])+rnorm(500)
est &lt;- lsprobust(y, x)
summary(est)

</code></pre>

<hr>
<h2 id='lsprobust.plot'>Graphic Presentation of Results for <span class="pkg">lspartition</span> Package</h2><span id='topic+lsprobust.plot'></span>

<h3>Description</h3>

<p><code>lsprobust.plot</code> plots estimated regression functions and confidence regions using the <span class="pkg">lspartition</span> package.
See <a href="https://sites.google.com/site/nppackages/lspartition/Cattaneo-Farrell_2013_JoE.pdf?attredirects=0">Cattaneo and Farrell (2013)</a> and <a href="https://arxiv.org/abs/1804.04916">Cattaneo, Farrell and Feng (2019a)</a> for complete details.
</p>
<p>Companion command: <code><a href="#topic+lsprobust">lsprobust</a></code> for partitioning-based least squares regression
estimation and inference; <code><a href="#topic+lsprobust.plot">lsprobust.plot</a></code> for plotting results; <code><a href="#topic+lsplincom">lsplincom</a></code> for multiple sample estimation and inference.
</p>
<p>A detailed introduction to this command is given in <a href="https://arxiv.org/abs/1906.00202">Cattaneo, Farrell and Feng (2019b)</a>.
</p>
<p>For more details, and related Stata and R packages useful for empirical analysis,
visit <a href="https://sites.google.com/site/nppackages/">https://sites.google.com/site/nppackages/</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lsprobust.plot(..., alpha = NULL, type = NULL, CS = "ci",
  CStype = NULL, title = "", xlabel = "", ylabel = "",
  lty = NULL, lwd = NULL, lcol = NULL, pty = NULL, pwd = NULL,
  pcol = NULL, CSshade = NULL, CScol = NULL, legendTitle = NULL,
  legendGroups = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="lsprobust.plot_+3A_...">...</code></td>
<td>
<p>Objects returned by <code><a href="#topic+lsprobust">lsprobust</a></code>.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_alpha">alpha</code></td>
<td>
<p>Numeric scalar between 0 and 1, the significance level for plotting
confidence regions. If more than one is provided, they will be applied
to data series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_type">type</code></td>
<td>
<p>String, one of <code>"line"</code> (default), <code>"points"</code>, <code>"binscatter"</code>,
<code>"none"</code> or <code>"both"</code>, how the point estimates are plotted. If more
than one is provided, they will be applied to data series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_cs">CS</code></td>
<td>
<p>String, type of confidence sets. Options are <code>"ci"</code> for pointwise confidence
intervals, <code>"cb"</code> for uniform confidence bands, and <code>"all"</code> for both.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_cstype">CStype</code></td>
<td>
<p>String, one of <code>"region"</code> (shaded region, default), <code>"line"</code>
(dashed lines), <code>"ebar"</code> (error bars), <code>"all"</code> (all of the previous)
or <code>"none"</code> (no confidence region), how the confidence region should
be plotted. If more than one is provided, they will be applied to data series accordingly.
If <code>CS = "all"</code>, pointwise confidence intervals are forced to be represented by error bars,
and uniform bands are represented by both lines and regions.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_title">title</code></td>
<td>
<p>String, title of the plot.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_xlabel">xlabel</code></td>
<td>
<p>Strings, labels for x-axis.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_ylabel">ylabel</code></td>
<td>
<p>Strings, labels for y-axis.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_lty">lty</code></td>
<td>
<p>Line type for point estimates, only effective if <code>type</code> is <code>"line"</code> or
<code>"both"</code>. <code>1</code> for solid line, <code>2</code> for dashed line, <code>3</code>
for dotted line. For other options, see the instructions for <code><a href="ggplot2.html#topic+ggplot2">ggplot2</a></code>
or <code><a href="graphics.html#topic+par">par</a></code>. If more than one is provided, they will be applied to data
series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_lwd">lwd</code></td>
<td>
<p>Line width for point estimates, only effective if <code>type</code> is <code>"line"</code>
or <code>"both"</code>. Should be strictly positive. For other options, see the
instructions for <code><a href="ggplot2.html#topic+ggplot2">ggplot2</a></code> or <code><a href="graphics.html#topic+par">par</a></code>. If more than one
is provided, they will be applied to data series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_lcol">lcol</code></td>
<td>
<p>Line color for point estimates, only effective if <code>type</code> is <code>"line"</code> or
<code>"both"</code>. <code>1</code> for black, <code>2</code> for red, <code>3</code> for green,
<code>4</code> for blue. For other options, see the instructions for <code><a href="ggplot2.html#topic+ggplot2">ggplot2</a></code>
or <code><a href="graphics.html#topic+par">par</a></code>. If more than one is provided, they will be applied to
data series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_pty">pty</code></td>
<td>
<p>Scatter plot type for point estimates, only effective if <code>type</code> is
<code>"points"</code> or <code>"both"</code>. For options, see the instructions for
<code><a href="ggplot2.html#topic+ggplot2">ggplot2</a></code> or <code><a href="graphics.html#topic+par">par</a></code>. If more than one is provided,
they will be applied to data series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_pwd">pwd</code></td>
<td>
<p>Scatter plot size for point estimates, only effective if <code>type</code> is
<code>"points"</code> or <code>"both"</code>. Should be strictly positive. If more than
one is provided, they will be applied to data series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_pcol">pcol</code></td>
<td>
<p>Scatter plot color for point estimates, only effective if <code>type</code> is
<code>"points"</code> or <code>"both"</code>. <code>1</code> for black, <code>2</code> for red,
<code>3</code> for green, <code>4</code> for blue. For other options, see the instructions
for <code><a href="ggplot2.html#topic+ggplot2">ggplot2</a></code> or <code><a href="graphics.html#topic+par">par</a></code>. If more than one is provided,
they will be applied to data series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_csshade">CSshade</code></td>
<td>
<p>Numeric, opaqueness of the confidence region, should be between 0
(transparent) and 1. Default is 0.2. If more than one is provided,
they will be applied to data series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_cscol">CScol</code></td>
<td>
<p>Color for confidence region. <code>1</code> for black, <code>2</code> for red, <code>3</code>
for green, <code>4</code> for blue. For other options, see the instructions for
<code><a href="ggplot2.html#topic+ggplot2">ggplot2</a></code> or <code><a href="graphics.html#topic+par">par</a></code>. If more than one is provided,
they will be applied to data series accordingly.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_legendtitle">legendTitle</code></td>
<td>
<p>String, title of legend.</p>
</td></tr>
<tr><td><code id="lsprobust.plot_+3A_legendgroups">legendGroups</code></td>
<td>
<p>String vector, group names used in legend.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Companion command: <code><a href="#topic+lsprobust">lsprobust</a></code> for partition-based least-squares regression
estimation.
</p>


<h3>Value</h3>

<p>A standard <code><a href="ggplot2.html#topic+ggplot2">ggplot2</a></code> object is returned, hence can be used for further
customization.
</p>


<h3>Author(s)</h3>

<p>Matias D. Cattaneo, Princeton University, Princeton, NJ. <a href="mailto:cattaneo@princeton.edu">cattaneo@princeton.edu</a>.
</p>
<p>Max H. Farrell, University of Chicago, Chicago, IL. <a href="mailto:max.farrell@chicagobooth.edu">max.farrell@chicagobooth.edu</a>.
</p>
<p>Yingjie Feng (maintainer), Princeton University, Princeton, NJ. <a href="mailto:yingjief@princeton.edu">yingjief@princeton.edu</a>.
</p>


<h3>References</h3>

<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019a): <a href="https://arxiv.org/abs/1804.04916">Large Sample Properties of Partitioning-Based Series Estimators</a>. Annals of Statistics, forthcoming. arXiv:1804.04916.
</p>
<p>Cattaneo, M. D., M. H. Farrell, and Y. Feng (2019b): <a href="https://arxiv.org/abs/1906.00202">lspartition: Partitioning-Based Least Squares Regression</a>. R Journal, forthcoming. arXiv:1906.00202.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+lsprobust">lsprobust</a></code>, <code><a href="#topic+lspkselect">lspkselect</a></code>, <code><a href="#topic+lsplincom">lsplincom</a></code>, <code><a href="ggplot2.html#topic+ggplot2">ggplot2</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x   &lt;- runif(500)
y   &lt;- sin(4*x)+rnorm(500)
est &lt;- lsprobust(y, x)
lsprobust.plot(est)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
