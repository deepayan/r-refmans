<!DOCTYPE html><html lang="en"><head><title>Help for package MethodCompare</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {MethodCompare}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#MethodCompare-package'><p>Evaluating Bias and Precision in Method Comparison Studies</p></a></li>
<li><a href='#agreement0'><p>Plot the agreement before recalibration</p></a></li>
<li><a href='#agreement1'><p>Plot the agreement after recalibration</p></a></li>
<li><a href='#bias_plot'><p>Plot the bias and measurements</p></a></li>
<li><a href='#compare_plot'><p>Plot used to visualize the recalibration of the new method after estimating</p>
the bias</a></li>
<li><a href='#data1'><p>Simulated dataset 1</p></a></li>
<li><a href='#data2'><p>Simulated dataset 2</p></a></li>
<li><a href='#data3'><p>Simulated dataset 3</p></a></li>
<li><a href='#measure_compare'><p>Estimation of the amount of bias of the new measurement method relative to</p>
the reference method</a></li>
<li><a href='#mse'><p>Plot the mean squared errors</p></a></li>
<li><a href='#pct_agreement0'><p>Plot the percentage agreement before recalibration</p></a></li>
<li><a href='#pct_agreement1'><p>Plot the percentage agreement after recalibration</p></a></li>
<li><a href='#precision_plot'><p>Plot the precision of the methods</p></a></li>
<li><a href='#sqrt_mse'><p>Plot the square root of the mean squared errors</p></a></li>
<li><a href='#total_bias_plot'><p>Plot total bias</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Evaluating Bias and Precision in Method Comparison Studies</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Evaluate bias and precision in method comparison 
    studies. One provides measurements for each method and it takes care of 
    the estimates. Multiple plots to evaluate bias, precision and compare
    methods.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL (&ge; 3)</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Imports:</td>
<td>estimatr, graphics, lme4, Matrix, mfp, rockchalk, stats</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/UBERLULU/MethodCompare">https://github.com/UBERLULU/MethodCompare</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/UBERLULU/MethodCompare/issues">https://github.com/UBERLULU/MethodCompare/issues</a></td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-09 13:50:10 UTC; Thomas</td>
</tr>
<tr>
<td>Author:</td>
<td>Thomas Blomet [aut, cre],
  Mingkai Peng [aut],
  Patrick Taffé [aut],
  Tyler Williamson [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thomas Blomet &lt;thomas.blomet@alumni.epfl.ch&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-09 14:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='MethodCompare-package'>Evaluating Bias and Precision in Method Comparison Studies</h2><span id='topic+MethodCompare'></span><span id='topic+MethodCompare-package'></span>

<h3>Description</h3>

<p>The package &quot;MethodCompare&quot; allows one to assess bias, precision and agreement
of a new measurement method with respect to a reference method (also called
&quot;reference standard&quot;). It requires repeated measurements by at least one of
the two measurement methods.
</p>
<p>In this implementation, it is assumed by default that the reference method
has repeated measurements and the new method may have as few as only one
measurement per individual (The methodology can be adapted if you have more
repeated measurements by the new method than by the reference method, see
ref. below).
</p>
<p>It implements the methodology developped in:
</p>
<p>Taffé P. Effective plots to assess bias and precision in method comparison
studies. Stat Methods Med Res 2018;27:1650-1660.
</p>
<p>Taffé P. Assessing bias, precision, and agreement in method comparison
studies. Stat Methods Med Res 2020;29:778-796.
</p>
<p>For other relevant references:
</p>
<p>Blomet T, Taffé P, MethodCompare: An extended suite of R commands to assess
bias, precision, and agreement in method comparison studies.
To be published...
</p>
<p>Taffé P, Peng M, Stagg V, Williamson T. Biasplot: A package to effective
plots to assess bias and precision in method comparison studies.
Stata J 2017;17:208-221.
</p>
<p>Taffé P, Peng M, Stagg V, Williamson T. MethodCompare: An R package to
assess bias and precision in method comparison studies.
Stat Methods Med Res 2019;28:2557-2565.
</p>
<p>Taffé P, Halfon P, Halfon M. A new statistical methodology to assess bias
and precision overcomes the defects of the Bland &amp; Altman method. J Clin Epidemiol 2020;124:1-7.
</p>
<p>Taffé P. When can the Bland-Altman limits of agreement method be used and
when it should not be used. J Clin Epidemiol 2021; 137:176-181.
</p>
<p>Taffé P, Peng M, Stagg V, Williamson T. Extended biasplot command to assess
bias, precision, and agreement in method comparison studies.
Stata J 2023;23:97-118.
</p>


<h3>Details</h3>

<p>The functions implemented in this package are the following:
</p>

<ul>
<li> <p><a href="#topic+agreement0">agreement0</a>: Plot the agreement before recalibration
</p>
</li>
<li> <p><a href="#topic+agreement1">agreement1</a>: Plot the agreement after recalibration
</p>
</li>
<li> <p><a href="#topic+bias_plot">bias_plot</a>: Plot the bias and measurements
</p>
</li>
<li> <p><a href="#topic+compare_plot">compare_plot</a>: Plot used to visualize the recalibration of the new
method after estimating the bias
</p>
</li>
<li> <p><a href="#topic+measure_compare">measure_compare</a>: Estimation of the amount of bias of the new
measurement method relative to the reference method
</p>
</li>
<li> <p><a href="#topic+mse">mse</a>: Plot the mean squared errors
</p>
</li>
<li> <p><a href="#topic+pct_agreement0">pct_agreement0</a>: Plot the percentage agreement before recalibration
</p>
</li>
<li> <p><a href="#topic+pct_agreement1">pct_agreement1</a>: Plot the percentage agreement after recalibration
</p>
</li>
<li> <p><a href="#topic+precision_plot">precision_plot</a>: Plot the precision of the methods
</p>
</li>
<li> <p><a href="#topic+sqrt_mse">sqrt_mse</a>: Plot the square root of the mean squared errors
</p>
</li>
<li> <p><a href="#topic+total_bias_plot">total_bias_plot</a>: Plot total bias
</p>
</li></ul>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Thomas Blomet <a href="mailto:thomas.blomet@alumni.epfl.ch">thomas.blomet@alumni.epfl.ch</a>
</p>
<p>Authors:
</p>

<ul>
<li><p> Mingkai Peng
</p>
</li>
<li><p> Patrick Taffé <a href="mailto:patrick.taffe@unisante.ch">patrick.taffe@unisante.ch</a>
</p>
</li>
<li><p> Tyler Williamson
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://github.com/UBERLULU/MethodCompare">https://github.com/UBERLULU/MethodCompare</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/UBERLULU/MethodCompare/issues">https://github.com/UBERLULU/MethodCompare/issues</a>
</p>
</li></ul>


<hr>
<h2 id='agreement0'>Plot the agreement before recalibration</h2><span id='topic+agreement0'></span>

<h3>Description</h3>

<p>This function draws the &quot;agreement plot&quot; before recalibration, which is used
to visually appraise the degree of agreement between the new and reference
methods, before recalibration of the new method.
It is obtained by graphing a scatter plot of <code>y1-y2</code> (difference of the methods)
versus the BLUP of the latent trait, <code>x</code>, along with the bias and 95% limits
of agreement with their 95% simultaneous confidence bands.
The function adds a second scale on the right axis, showing the percentage
of agreement index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>agreement0(object, rarea = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="agreement0_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
<tr><td><code id="agreement0_+3A_rarea">rarea</code></td>
<td>
<p>if <code>TRUE</code>, draw the plot with shading areas between
the confidence bands.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the agreement without recalibration
agreement0(measure_model)
</code></pre>

<hr>
<h2 id='agreement1'>Plot the agreement after recalibration</h2><span id='topic+agreement1'></span>

<h3>Description</h3>

<p>This function draws the &quot;agreement plot&quot; after recalibration, which is used
to visually appraise the degree of agreement between the new and reference
methods, before recalibration of the new method.
It is obtained by graphing a scatter plot of <code>y1-y2</code> (difference of the methods)
versus the BLUP of the latent trait, <code>x</code>, along with the bias and 95% limits
of agreement with their 95% simultaneous confidence bands.
The function adds a second scale on the right axis, showing the percentage
of agreement index.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>agreement1(object, rarea = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="agreement1_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
<tr><td><code id="agreement1_+3A_rarea">rarea</code></td>
<td>
<p>if <code>TRUE</code>, draw the plot with shading areas between
the confidence bands.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the agreement after recalibration
agreement0(measure_model)
</code></pre>

<hr>
<h2 id='bias_plot'>Plot the bias and measurements</h2><span id='topic+bias_plot'></span>

<h3>Description</h3>

<p>This function draws the &quot;bias plot&quot;, which is used to visually assess the
bias of the new method relative to the reference method. It is obtained by
graphing a scatter plot of <code>y1</code> (new method) and <code>y2</code> (reference method) versus
the BLUP of the latent trait, <code>x</code>, along with the two regression lines.
The function adds a second scale on the right axis, showing the relationship
between the estimated amount of bias and BLUP of the latent trait, <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bias_plot(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bias_plot_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the bias
bias_plot(measure_model)
</code></pre>

<hr>
<h2 id='compare_plot'>Plot used to visualize the recalibration of the new method after estimating
the bias</h2><span id='topic+compare_plot'></span>

<h3>Description</h3>

<p>This function allows the visualization of the bias-corrected values (i.e.
recalibrated values, variable y1_corr) of the new measurement method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>compare_plot(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="compare_plot_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the bias
compare_plot(measure_model)
</code></pre>

<hr>
<h2 id='data1'>Simulated dataset 1</h2><span id='topic+data1'></span>

<h3>Description</h3>

<p>In the simulated dataset 1, each subject has 1 to 3 measurement values
from the new method and 10 to 20 measurement values from the reference method.
Compared to the reference method, the new method has differential bias of 4
and proportional bias of 0.8. Variance of the new method is smaller than that
for the reference method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data1
</code></pre>


<h3>Format</h3>



<h4><code>data1</code></h4>

<p>An object of class <code>data.frame</code> with 1468 rows and 3 columns
</p>



<h3>Details</h3>

<p>A data frame with 3 variables:
</p>

<dl>
<dt><code>id</code></dt><dd><p>identification number for subjects</p>
</dd>
<dt><code>y1</code></dt><dd><p>values from the new measuremment method</p>
</dd>
<dt><code>y2</code></dt><dd><p>values from the reference method</p>
</dd>
</dl>

<p>Dataset 1 was created based on the following equations:
</p>
<p style="text-align: center;"><code class="reqn">y_{1i}=4+0.8x_i+\varepsilon_{1i},\quad \varepsilon_{1i} \mid x_i \sim 
N(0,(0.2x_i)^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">y_{2i}=x_i+\varepsilon_{2i},\quad \varepsilon_{2i} \mid x_i \sim 
N(0,(1.75+0.08x_i)^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">x_i\sim Uniform[25-45]</code>
</p>

<p>for <code class="reqn">i=1,\ldots,100</code> and the number of repeated measurements for each
subject <code class="reqn">i</code> from the reference standard was <code class="reqn">n_{2i} \sim Uniform[10,20]</code>
and <code class="reqn">n_{1i} \sim Uniform[1,3]</code> for the new measurement method.
</p>

<hr>
<h2 id='data2'>Simulated dataset 2</h2><span id='topic+data2'></span>

<h3>Description</h3>

<p>In the simulated dataset 2, each subject has 10 to 20 measurement values
from the new method and 10 to 20 measurement values from the reference method.
Compared to the reference method, the new method has differential bias of 4
and proportional bias of 0.8. Variance of the new method is smaller than that
for the reference method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data2
</code></pre>


<h3>Format</h3>



<h4><code>data2</code></h4>

<p>An object of class <code>data.frame</code> with 1680 rows and 3 columns
</p>



<h3>Details</h3>

<p>A data frame with 3 variables:
</p>

<dl>
<dt><code>id</code></dt><dd><p>identification number for subjects</p>
</dd>
<dt><code>y1</code></dt><dd><p>values from the new measuremment method</p>
</dd>
<dt><code>y2</code></dt><dd><p>values from the reference method</p>
</dd>
</dl>

<p>Dataset 1 was created based on the following equations:
</p>
<p style="text-align: center;"><code class="reqn">y_{1i}=4+0.8x_i+\varepsilon_{1i},\quad \varepsilon_{1i} \mid x_i \sim 
N(0,(0.2x_i)^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">y_{2i}=x_i+\varepsilon_{2i},\quad \varepsilon_{2i} \mid x_i \sim 
N(0,(1.75+0.08x_i)^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">x_i\sim Uniform[20-100]</code>
</p>

<p>for <code class="reqn">i=1,\ldots,100</code> and the number of repeated measurements for each
subject <code class="reqn">i</code> from the reference standard was <code class="reqn">n_{2i} \sim Uniform[10,20]</code>
and <code class="reqn">n_{1i} \sim Uniform[10,20]</code> for the new measurement method.
</p>

<hr>
<h2 id='data3'>Simulated dataset 3</h2><span id='topic+data3'></span>

<h3>Description</h3>

<p>In the simulated dataset 3, each subject has 10 to 20 measurement values
from the new method and 10 to 20 measurement values from the reference method.
Compared to the reference method, the new method has differential bias of 1
and proportional bias of 0.9. Variance of the new method is smaller than that
for the reference method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data3
</code></pre>


<h3>Format</h3>



<h4><code>data3</code></h4>

<p>An object of class <code>data.frame</code> with 1682 rows and 3 columns
</p>



<h3>Details</h3>

<p>A data frame with 3 variables:
</p>

<dl>
<dt><code>id</code></dt><dd><p>identification number for subjects</p>
</dd>
<dt><code>y1</code></dt><dd><p>values from the new measuremment method</p>
</dd>
<dt><code>y2</code></dt><dd><p>values from the reference method</p>
</dd>
</dl>

<p>Dataset 1 was created based on the following equations:
</p>
<p style="text-align: center;"><code class="reqn">y_{1i}=1+0.9x_i+\varepsilon_{1i},\quad \varepsilon_{1i} \mid x_i \sim 
N(0,(1+0.04x_i)^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">y_{2i}=x_i+\varepsilon_{2i},\quad \varepsilon_{2i} \mid x_i \sim 
N(0,(1.75+0.08x_i)^2)</code>
</p>

<p style="text-align: center;"><code class="reqn">x_i\sim Uniform[20-100]</code>
</p>

<p>for <code class="reqn">i=1,\ldots,100</code> and the number of repeated measurements for each
subject <code class="reqn">i</code> from the reference standard was <code class="reqn">n_{2i} \sim Uniform[10,20]</code>
and <code class="reqn">n_{1i} \sim Uniform[10,20]</code> for the new measurement method.
</p>

<hr>
<h2 id='measure_compare'>Estimation of the amount of bias of the new measurement method relative to
the reference method</h2><span id='topic+measure_compare'></span>

<h3>Description</h3>

<p><code>measure_compare()</code> implements the methodology reported in the paper:
Taffé P. Effective plots to assess bias and precision in method comparison
studies. Stat Methods Med Res 2018;27:1650-1660. Other relevant references:
Taffé P, Peng M, Stagg V, Williamson T. Biasplot: A package to effective
plots to assess bias and precision in method comparison studies.
Stata J 2017;17:208-221. Taffé P, Peng M, Stagg V, Williamson T.
MethodCompare: An R package to assess bias and precision in method
comparison studies. Stat Methods Med Res 2019;28:2557-2565.
Taffé P, Halfon P, Halfon M. A new statistical methodology to assess bias
and precision overcomes the defects of the Bland &amp; Altman method.
J Clin Epidemiol 2020;124:1-7. Taffé P. Assessing bias, precision, and
agreement in method comparison studies. Stat Methods Med Res 2020;29:778-796.
Taffé P. When can the Bland-Altman limits of agreement method be used and
when it should not be used. J Clin Epidemiol 2021; 137:176-181.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>measure_compare(
  data,
  new = "y1",
  ref = "y2",
  id = "id",
  nb_simul = 1000,
  if_value = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="measure_compare_+3A_data">data</code></td>
<td>
<p>a required data frame containing the identification number of the
subject (<code>id</code>), the measurement values from the new method (<code>y1</code>) and
those from the reference method (<code>y2</code>).</p>
</td></tr>
<tr><td><code id="measure_compare_+3A_new">new</code></td>
<td>
<p>an optional string. The column name containing the measurements of the new
measurement method.</p>
</td></tr>
<tr><td><code id="measure_compare_+3A_ref">ref</code></td>
<td>
<p>an optional string. The column name containing the measurements of the
reference method (at least two measurements per subject).</p>
</td></tr>
<tr><td><code id="measure_compare_+3A_id">id</code></td>
<td>
<p>an optional string. The column name containing the subject
identification numbers.</p>
</td></tr>
<tr><td><code id="measure_compare_+3A_nb_simul">nb_simul</code></td>
<td>
<p>an optional number. The number of simulations used for simultaneous
confidence bands.</p>
</td></tr>
<tr><td><code id="measure_compare_+3A_if_value">if_value</code></td>
<td>
<p>an optional number. Restrict the study to observed
measurement greater than the provided value, i.e., <code>y1 &gt;= if_value &amp;&amp; y2 &gt;= if_value</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list with the following items:
</p>

<ul>
<li> <p><code>models</code>: a list of models fitted in estimation procedure
</p>
</li>
<li> <p><code>data</code>: the original data frame with renamed columns and
additional computed data
</p>
</li>
<li> <p><code>sim_params</code>: estimated model coefficients used afterward
</p>
</li>
<li> <p><code>nb_simul</code>: the number of simulations used for confidence bands
simulations
</p>
</li>
<li> <p><code>bias</code>: differential and proportional biases for new method and the
associated 95 percent confidence intervals
</p>
</li>
<li> <p><code>methods</code>: a list of methods names provided by the user
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
</code></pre>

<hr>
<h2 id='mse'>Plot the mean squared errors</h2><span id='topic+mse'></span>

<h3>Description</h3>

<p>This function draws the &quot;MSE plot&quot;, which is used to compare the precision of
the two measurement methods without recalibrating the new method.
It is obtained by graphing the mean squared errors of <code>y1</code> (new method) and <code>y2</code> (reference
method) versus the BLUP of the latent trait, <code>x</code>, along with their 95%
simultaneous confidence bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mse(object, rarea = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="mse_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
<tr><td><code id="mse_+3A_rarea">rarea</code></td>
<td>
<p>if <code>TRUE</code>, draw the plot with shading areas between
the confidence bands.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the mean squared errors
mse(measure_model)
</code></pre>

<hr>
<h2 id='pct_agreement0'>Plot the percentage agreement before recalibration</h2><span id='topic+pct_agreement0'></span>

<h3>Description</h3>

<p>This function draws the &quot;percentage agreement plot&quot; before recalibration,
which shows the amount of percentage agreement.
It is obtained by graphing the percentage agreement index before recalibration
versus the BLUP of the latent trait, <code>x</code>, along with its 95% simultaneous
confidence bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pct_agreement0(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pct_agreement0_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the percentage agreement without recalibration
pct_agreement0(measure_model)
</code></pre>

<hr>
<h2 id='pct_agreement1'>Plot the percentage agreement after recalibration</h2><span id='topic+pct_agreement1'></span>

<h3>Description</h3>

<p>This function draws the &quot;percentage agreement plot&quot; after recalibration,
which shows the amount of percentage agreement.
It is obtained by graphing the percentage agreement index after recalibration
versus the BLUP of the latent trait, <code>x</code>, along with its 95% simultaneous
confidence bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pct_agreement1(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pct_agreement1_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the percentage agreement after recalibration
pct_agreement0(measure_model)
</code></pre>

<hr>
<h2 id='precision_plot'>Plot the precision of the methods</h2><span id='topic+precision_plot'></span>

<h3>Description</h3>

<p>This function draws the &quot;precision plot&quot;, which allows the visual comparison
of the precision (i.e. standard deviation) of the new measurement method with
the reference standard by creating a scatter plot of the estimated standard
deviations, along with their 95% simultaneous confidence bands, against the
best linear prediction (BLUP) of the true latent trait, <code>x</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>precision_plot(object, object2 = NULL, log = FALSE, rarea = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="precision_plot_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
<tr><td><code id="precision_plot_+3A_object2">object2</code></td>
<td>
<p>(optional) returned by <a href="#topic+measure_compare">measure_compare</a> function.
If provided, will plot a second precision estimate.</p>
</td></tr>
<tr><td><code id="precision_plot_+3A_log">log</code></td>
<td>
<p>if <code>TRUE</code>, guarantee the simultaneous confidence bands around the
standard deviation of measurement errors to be strictly positive.</p>
</td></tr>
<tr><td><code id="precision_plot_+3A_rarea">rarea</code></td>
<td>
<p>if <code>TRUE</code>, draw the plot with shading areas between
the confidence bands.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the precision of the two methods
precision_plot(measure_model)
</code></pre>

<hr>
<h2 id='sqrt_mse'>Plot the square root of the mean squared errors</h2><span id='topic+sqrt_mse'></span>

<h3>Description</h3>

<p>This function draws the &quot;sqrt(MSE) plot&quot;, which is used to compare the precision of
the two measurement methods without recalibrating the new method.
It is obtained by graphing the square root mean squared errors of <code>y1</code> (new method) and <code>y2</code> (reference
method) versus the BLUP of the latent trait, <code>x</code>, along with their 95%
simultaneous confidence bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sqrt_mse(object, rarea = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sqrt_mse_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
<tr><td><code id="sqrt_mse_+3A_rarea">rarea</code></td>
<td>
<p>if <code>TRUE</code>, draw the plot with shading areas between
the confidence bands.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the square root mean squared errors
sqrt_mse(measure_model)
</code></pre>

<hr>
<h2 id='total_bias_plot'>Plot total bias</h2><span id='topic+total_bias_plot'></span>

<h3>Description</h3>

<p>This function draws the &quot;total bias plot&quot;, which is used to visually assess
the amount of bias.
It is obtained by graphing the <code>bias</code> versus the BLUP of the latent trait,
<code>x</code>, along with the 95% simultaneous confidence bands.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>total_bias_plot(object, object2 = NULL, rarea = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="total_bias_plot_+3A_object">object</code></td>
<td>
<p>list returned by <a href="#topic+measure_compare">measure_compare</a> function.</p>
</td></tr>
<tr><td><code id="total_bias_plot_+3A_object2">object2</code></td>
<td>
<p>(optional) returned by <a href="#topic+measure_compare">measure_compare</a> function.
If provided, will plot a second total bias estimate.</p>
</td></tr>
<tr><td><code id="total_bias_plot_+3A_rarea">rarea</code></td>
<td>
<p>if <code>TRUE</code>, draw the plot with shading areas between
the confidence bands.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
### Load the data
data(data1)
### Analysis
measure_model &lt;- measure_compare(data1, nb_simul=100)
### Plot the total bias
total_bias_plot(measure_model)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
