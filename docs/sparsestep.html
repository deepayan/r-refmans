<!DOCTYPE html><html><head><title>Help for package sparsestep</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {sparsestep}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coef.sparsestep'><p>Get the coefficients of a fitted SparseStep model</p></a></li>
<li><a href='#path.sparsestep'><p>Approximate path algorithm for the SparseStep model</p></a></li>
<li><a href='#plot.sparsestep'><p>Plot the SparseStep path</p></a></li>
<li><a href='#predict.sparsestep'><p>Make predictions from a SparseStep model</p></a></li>
<li><a href='#print.sparsestep'><p>Print the fitted SparseStep model</p></a></li>
<li><a href='#sparsestep'><p>Fit the SparseStep model</p></a></li>
<li><a href='#sparsestep-package'><p>SparseStep: Approximating the Counting Norm for Sparse Regularization</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2021-01-10</td>
</tr>
<tr>
<td>Title:</td>
<td>SparseStep Regression</td>
</tr>
<tr>
<td>Description:</td>
<td>Implements the SparseStep model for solving regression
    problems with a sparsity constraint on the parameters. The SparseStep
    regression model was proposed in Van den Burg, Groenen, and Alfons (2017)
    &lt;<a href="https://arxiv.org/abs/1701.06967">arXiv:1701.06967</a>&gt;. In the model, a regularization term is added to the
    regression problem which approximates the counting norm of the parameters.
    By iteratively improving the approximation a sparse solution to the
    regression problem can be obtained.  In this package both the standard
    SparseStep algorithm is implemented as well as a path algorithm which uses
    golden section search to determine solutions with different values for the
    regularization parameter.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.0.0), Matrix (&ge; 1.0-6)</td>
</tr>
<tr>
<td>Classification/MSC:</td>
<td>62J05, 62J07</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/GjjvdBurg/SparseStep">https://github.com/GjjvdBurg/SparseStep</a>,
<a href="https://arxiv.org/abs/1701.06967">https://arxiv.org/abs/1701.06967</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/GjjvdBurg/SparseStep">https://github.com/GjjvdBurg/SparseStep</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-01-10 14:35:07 UTC; gertjan</td>
</tr>
<tr>
<td>Author:</td>
<td>Gertjan van den Burg [aut, cre],
  Patrick Groenen [ctb],
  Andreas Alfons [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gertjan van den Burg &lt;gertjanvandenburg@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-01-10 14:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='coef.sparsestep'>Get the coefficients of a fitted SparseStep model</h2><span id='topic+coef.sparsestep'></span><span id='topic+coef'></span>

<h3>Description</h3>

<p>Returns the coefficients of the SparseStep model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sparsestep'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="coef.sparsestep_+3A_object">object</code></td>
<td>
<p>a <code>sparsestep</code> object</p>
</td></tr>
<tr><td><code id="coef.sparsestep_+3A_...">...</code></td>
<td>
<p>further argument are ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients of the SparseStep model (i.e. the betas) as a 
dgCMatrix. If the model was fitted with an intercept this will be the first
row in the resulting matrix.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen, Andreas Alfons<br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J., Groenen, P.J.F. and Alfons, A. (2017).
<em>SparseStep: Approximating the Counting Norm for Sparse Regularization</em>,
arXiv preprint arXiv:1701.06967 [stat.ME]. 
URL <a href="https://arxiv.org/abs/1701.06967">https://arxiv.org/abs/1701.06967</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*20), 100, 20)
y &lt;- rnorm(100)
fit &lt;- sparsestep(x, y)
coef(fit)

</code></pre>

<hr>
<h2 id='path.sparsestep'>Approximate path algorithm for the SparseStep model</h2><span id='topic+path.sparsestep'></span>

<h3>Description</h3>

<p>Fits the entire regularization path for SparseStep using a 
Golden Section search. Note that this algorithm is approximate, there is no 
guarantee that the solutions _between_ induced values of lambdas do not 
differ from those calculated. For instance, if solutions are calculated at 
<code class="reqn">\lambda_{i}</code> and <code class="reqn">\lambda_{i+1}</code>, this 
algorithm ensures that <code class="reqn">\lambda_{i+1}</code> has one more zero 
than the solution at <code class="reqn">\lambda_{i}</code> (provided the recursion 
depth is large enough). There is however no guarantee that there are no 
different solutions between <code class="reqn">\lambda_{i}</code> and 
<code class="reqn">\lambda_{i+1}</code>.  This is an ongoing research topic.
</p>
<p>Note that this path algorithm is not faster than running the 
<code>sparsestep</code> function with the same <code class="reqn">\lambda</code> sequence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>path.sparsestep(
  x,
  y,
  max.depth = 10,
  gamma0 = 1000,
  gammastop = 1e-04,
  IMsteps = 2,
  gammastep = 2,
  normalize = TRUE,
  intercept = TRUE,
  force.zero = TRUE,
  threshold = 1e-07,
  XX = NULL,
  Xy = NULL,
  use.XX = TRUE,
  use.Xy = TRUE,
  quiet = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="path.sparsestep_+3A_x">x</code></td>
<td>
<p>matrix of predictors</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_y">y</code></td>
<td>
<p>response</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_max.depth">max.depth</code></td>
<td>
<p>maximum recursion depth</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_gamma0">gamma0</code></td>
<td>
<p>starting value of the gamma parameter</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_gammastop">gammastop</code></td>
<td>
<p>stopping value of the gamma parameter</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_imsteps">IMsteps</code></td>
<td>
<p>number of steps of the majorization algorithm to perform for 
each value of gamma</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_gammastep">gammastep</code></td>
<td>
<p>factor to decrease gamma with at each step</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, each variable is standardized to have unit L2 
norm, otherwise it is left alone.</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_intercept">intercept</code></td>
<td>
<p>if TRUE, an intercept is included in the model (and not 
penalized), otherwise no intercept is included</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_force.zero">force.zero</code></td>
<td>
<p>if TRUE, absolute coefficients smaller than the provided 
threshold value are set to absolute zero as a post-processing step, 
otherwise no thresholding is performed</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_threshold">threshold</code></td>
<td>
<p>threshold value to use for setting coefficients to 
absolute zero</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_xx">XX</code></td>
<td>
<p>The X'X matrix; useful for repeated runs where X'X stays the same</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_xy">Xy</code></td>
<td>
<p>The X'y matrix; useful for repeated runs where X'y stays the same</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_use.xx">use.XX</code></td>
<td>
<p>whether or not to compute X'X and return it</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_use.xy">use.Xy</code></td>
<td>
<p>whether or not to compute X'y and return it</p>
</td></tr>
<tr><td><code id="path.sparsestep_+3A_quiet">quiet</code></td>
<td>
<p>don't print search info while running</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;sparsestep&quot; S3 object is returned, for which print, predict, 
coef, and plot methods exist. It has the following items:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The call that was used to construct the model.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The value(s) of lambda used to construct the model.</p>
</td></tr>
<tr><td><code>gamma0</code></td>
<td>
<p>The gamma0 value of the model.</p>
</td></tr>
<tr><td><code>gammastop</code></td>
<td>
<p>The gammastop value of the model</p>
</td></tr>
<tr><td><code>IMsteps</code></td>
<td>
<p>The IMsteps value of the model</p>
</td></tr>
<tr><td><code>gammastep</code></td>
<td>
<p>The gammastep value of the model</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Boolean indicating if an intercept was fitted in the 
model</p>
</td></tr>
<tr><td><code>force.zero</code></td>
<td>
<p>Boolean indicating if a force zero-setting was 
performed.</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>The threshold used for a forced zero-setting</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The resulting coefficients stored in a sparse matrix format 
(dgCMatrix). This matrix has dimensions nvar x nlambda</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>The intercept vector for each value of gamma of length nlambda</p>
</td></tr>
<tr><td><code>normx</code></td>
<td>
<p>Vector used to normalize the columns of x</p>
</td></tr>
<tr><td><code>meanx</code></td>
<td>
<p>Vector of column means of x</p>
</td></tr>
<tr><td><code>XX</code></td>
<td>
<p>The matrix X'X if use.XX was set to TRUE</p>
</td></tr>
<tr><td><code>Xy</code></td>
<td>
<p>The matrix X'y if use.Xy was set to TRUE</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen, Andreas Alfons<br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J., Groenen, P.J.F. and Alfons, A. (2017).
<em>SparseStep: Approximating the Counting Norm for Sparse Regularization</em>,
arXiv preprint arXiv:1701.06967 [stat.ME]. 
URL <a href="https://arxiv.org/abs/1701.06967">https://arxiv.org/abs/1701.06967</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef">coef</a></code>, <code><a href="base.html#topic+print">print</a></code>, <code><a href="#topic+predict">predict</a></code>, 
<code><a href="#topic+plot">plot</a></code>, and <code><a href="#topic+sparsestep">sparsestep</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*20), 100, 20)
y &lt;- rnorm(100)
pth &lt;- path.sparsestep(x, y)

</code></pre>

<hr>
<h2 id='plot.sparsestep'>Plot the SparseStep path</h2><span id='topic+plot.sparsestep'></span><span id='topic+plot'></span>

<h3>Description</h3>

<p>Plot the coefficients of the SparseStep path
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sparsestep'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.sparsestep_+3A_x">x</code></td>
<td>
<p>a <code>sparsestep</code> object</p>
</td></tr>
<tr><td><code id="plot.sparsestep_+3A_...">...</code></td>
<td>
<p>further argument to matplot</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen, Andreas Alfons<br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J., Groenen, P.J.F. and Alfons, A. (2017).
<em>SparseStep: Approximating the Counting Norm for Sparse Regularization</em>,
arXiv preprint arXiv:1701.06967 [stat.ME]. 
URL <a href="https://arxiv.org/abs/1701.06967">https://arxiv.org/abs/1701.06967</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*20), 100, 20)
y &lt;- rnorm(100)
fit &lt;- sparsestep(x, y)
plot(fit)
pth &lt;- path.sparsestep(x, y)
plot(pth)
</code></pre>

<hr>
<h2 id='predict.sparsestep'>Make predictions from a SparseStep model</h2><span id='topic+predict.sparsestep'></span><span id='topic+predict'></span>

<h3>Description</h3>

<p>Predicts the outcome variable for the SparseStep model for 
each value of lambda supplied to the model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sparsestep'
predict(object, newx, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.sparsestep_+3A_object">object</code></td>
<td>
<p>Fitted <code>sparsestep</code> object</p>
</td></tr>
<tr><td><code id="predict.sparsestep_+3A_newx">newx</code></td>
<td>
<p>Matrix of new values for <code>x</code> at which predictions are to 
be made.</p>
</td></tr>
<tr><td><code id="predict.sparsestep_+3A_...">...</code></td>
<td>
<p>further argument are ignored</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a matrix of numerical predictions of size nobs x nlambda
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen, Andreas Alfons<br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J., Groenen, P.J.F. and Alfons, A. (2017).
<em>SparseStep: Approximating the Counting Norm for Sparse Regularization</em>,
arXiv preprint arXiv:1701.06967 [stat.ME]. 
URL <a href="https://arxiv.org/abs/1701.06967">https://arxiv.org/abs/1701.06967</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*20), 100, 20)
y &lt;- rnorm(100)
fit &lt;- sparsestep(x, y)
yhat &lt;- predict(fit, x)

</code></pre>

<hr>
<h2 id='print.sparsestep'>Print the fitted SparseStep model</h2><span id='topic+print.sparsestep'></span>

<h3>Description</h3>

<p>Prints a short text of a fitted SparseStep model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'sparsestep'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.sparsestep_+3A_x">x</code></td>
<td>
<p>a <code>sparsestep</code> object to print</p>
</td></tr>
<tr><td><code id="print.sparsestep_+3A_...">...</code></td>
<td>
<p>further argument are ignored</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen, Andreas Alfons<br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J., Groenen, P.J.F. and Alfons, A. (2017).
<em>SparseStep: Approximating the Counting Norm for Sparse Regularization</em>,
arXiv preprint arXiv:1701.06967 [stat.ME]. 
URL <a href="https://arxiv.org/abs/1701.06967">https://arxiv.org/abs/1701.06967</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*20), 100, 20)
y &lt;- rnorm(100)
fit &lt;- sparsestep(x, y)
print(fit)

</code></pre>

<hr>
<h2 id='sparsestep'>Fit the SparseStep model</h2><span id='topic+sparsestep'></span>

<h3>Description</h3>

<p>Fits the SparseStep model for a chosen values of the 
regularization parameter.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sparsestep(
  x,
  y,
  lambda = c(0.1, 0.5, 1, 5, 10),
  gamma0 = 1000,
  gammastop = 1e-04,
  IMsteps = 2,
  gammastep = 2,
  normalize = TRUE,
  intercept = TRUE,
  force.zero = TRUE,
  threshold = 1e-07,
  XX = NULL,
  Xy = NULL,
  use.XX = TRUE,
  use.Xy = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="sparsestep_+3A_x">x</code></td>
<td>
<p>matrix of predictors</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_y">y</code></td>
<td>
<p>response</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_lambda">lambda</code></td>
<td>
<p>regularization parameter</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_gamma0">gamma0</code></td>
<td>
<p>starting value of the gamma parameter</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_gammastop">gammastop</code></td>
<td>
<p>stopping value of the gamma parameter</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_imsteps">IMsteps</code></td>
<td>
<p>number of steps of the majorization algorithm to perform for 
each value of gamma</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_gammastep">gammastep</code></td>
<td>
<p>factor to decrease gamma with at each step</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_normalize">normalize</code></td>
<td>
<p>if TRUE, each variable is standardized to have unit L2 
norm, otherwise it is left alone.</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_intercept">intercept</code></td>
<td>
<p>if TRUE, an intercept is included in the model (and not 
penalized), otherwise no intercept is included</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_force.zero">force.zero</code></td>
<td>
<p>if TRUE, absolute coefficients smaller than the provided 
threshold value are set to absolute zero as a post-processing step, 
otherwise no thresholding is performed</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_threshold">threshold</code></td>
<td>
<p>threshold value to use for setting coefficients to 
absolute zero</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_xx">XX</code></td>
<td>
<p>The X'X matrix; useful for repeated runs where X'X stays the same</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_xy">Xy</code></td>
<td>
<p>The X'y matrix; useful for repeated runs where X'y stays the same</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_use.xx">use.XX</code></td>
<td>
<p>whether or not to compute X'X and return it (boolean)</p>
</td></tr>
<tr><td><code id="sparsestep_+3A_use.xy">use.Xy</code></td>
<td>
<p>whether or not to compute X'y and return it (boolean)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A &quot;sparsestep&quot; S3 object is returned, for which print, predict, 
coef, and plot methods exist. It has the following items:
</p>
<table>
<tr><td><code>call</code></td>
<td>
<p>The call that was used to construct the model.</p>
</td></tr>
<tr><td><code>lambda</code></td>
<td>
<p>The value(s) of lambda used to construct the model.</p>
</td></tr>
<tr><td><code>gamma0</code></td>
<td>
<p>The gamma0 value of the model.</p>
</td></tr>
<tr><td><code>gammastop</code></td>
<td>
<p>The gammastop value of the model</p>
</td></tr>
<tr><td><code>IMsteps</code></td>
<td>
<p>The IMsteps value of the model</p>
</td></tr>
<tr><td><code>gammastep</code></td>
<td>
<p>The gammastep value of the model</p>
</td></tr>
<tr><td><code>intercept</code></td>
<td>
<p>Boolean indicating if an intercept was fitted in the 
model</p>
</td></tr>
<tr><td><code>force.zero</code></td>
<td>
<p>Boolean indicating if a force zero-setting was 
performed.</p>
</td></tr>
<tr><td><code>threshold</code></td>
<td>
<p>The threshold used for a forced zero-setting</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>The resulting coefficients stored in a sparse matrix format 
(dgCMatrix). This matrix has dimensions nvar x nlambda</p>
</td></tr>
<tr><td><code>a0</code></td>
<td>
<p>The intercept vector for each value of gamma of length nlambda</p>
</td></tr>
<tr><td><code>normx</code></td>
<td>
<p>Vector used to normalize the columns of x</p>
</td></tr>
<tr><td><code>meanx</code></td>
<td>
<p>Vector of column means of x</p>
</td></tr>
<tr><td><code>XX</code></td>
<td>
<p>The matrix X'X if use.XX was set to TRUE</p>
</td></tr>
<tr><td><code>Xy</code></td>
<td>
<p>The matrix X'y if use.Xy was set to TRUE</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen, Andreas Alfons<br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J., Groenen, P.J.F. and Alfons, A. (2017).
<em>SparseStep: Approximating the Counting Norm for Sparse Regularization</em>,
arXiv preprint arXiv:1701.06967 [stat.ME]. 
URL <a href="https://arxiv.org/abs/1701.06967">https://arxiv.org/abs/1701.06967</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef">coef</a></code>, <code><a href="base.html#topic+print">print</a></code>, <code><a href="#topic+predict">predict</a></code>, 
<code><a href="#topic+plot">plot</a></code>, and <code><a href="#topic+path.sparsestep">path.sparsestep</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*20), 100, 20)
y &lt;- rnorm(100)
fit &lt;- sparsestep(x, y)

</code></pre>

<hr>
<h2 id='sparsestep-package'>SparseStep: Approximating the Counting Norm for Sparse Regularization</h2><span id='topic+sparsestep-package'></span>

<h3>Description</h3>

<p>In the SparseStep regression model the ordinary least-squares problem is 
augmented with an approximation of the exact <code class="reqn">\ell_0</code> pseudonorm.  
This approximation is made increasingly more accurate in the SparseStep 
algorithm, resulting in a sparse solution to the regression problem. See 
the references for more information.
</p>


<h3>SparseStep functions</h3>

<p>The main SparseStep functions are:
</p>

<dl>
<dt><code><a href="#topic+sparsestep">sparsestep</a></code></dt><dd><p>Fit a SparseStep model for a given range of 
<code class="reqn">\lambda</code> values</p>
</dd>
<dt><code><a href="#topic+path.sparsestep">path.sparsestep</a></code></dt><dd><p>Fit the SparseStep model along a path 
of <code class="reqn">\lambda</code> values which are generated such that a model is created at 
each possible level of sparsity, or until a given recursion depth is 
reached.</p>
</dd>
</dl>

<p>Other available functions are:
</p>

<dl>
<dt><code><a href="#topic+plot">plot</a></code></dt><dd><p>Plot the coefficient path of the SparseStep 
model.</p>
</dd>
<dt><code><a href="#topic+predict">predict</a></code></dt><dd><p>Predict the outcome of the linear model using 
SparseStep</p>
</dd>
<dt><code><a href="#topic+coef">coef</a></code></dt><dd><p>Get the coefficients from the SparseStep model</p>
</dd>
<dt><code><a href="base.html#topic+print">print</a></code></dt><dd><p>Print a short description of the SparseStep 
model</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen, Andreas Alfons<br />
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J., Groenen, P.J.F. and Alfons, A. (2017).
<em>SparseStep: Approximating the Counting Norm for Sparse Regularization</em>,
arXiv preprint arXiv:1701.06967 [stat.ME]. 
URL <a href="https://arxiv.org/abs/1701.06967">https://arxiv.org/abs/1701.06967</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(100*20), 100, 20)
y &lt;- rnorm(100)
fit &lt;- sparsestep(x, y)
plot(fit)
fits &lt;- path.sparsestep(x, y)
plot(fits)
x2 &lt;- matrix(rnorm(50*20), 50, 20)
y2 &lt;- predict(fits, x2)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
