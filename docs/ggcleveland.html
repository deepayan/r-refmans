<!DOCTYPE html><html><head><title>Help for package ggcleveland</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {ggcleveland}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bin'><p>Dataset bin</p></a></li>
<li><a href='#dating'><p>Dataset dating</p></a></li>
<li><a href='#environmental'><p>Dataset environmental</p></a></li>
<li><a href='#equal_count'><p>The equal count algorithm</p></a></li>
<li><a href='#etanol'><p>Dataset etanol</p></a></li>
<li><a href='#fly'><p>Dataset fly</p></a></li>
<li><a href='#food'><p>Dataset food</p></a></li>
<li><a href='#fusion'><p>Dataset fusion</p></a></li>
<li><a href='#futbol'><p>Dataset futbol</p></a></li>
<li><a href='#galaxy'><p>Dataset galaxy</p></a></li>
<li><a href='#ganglion'><p>Dataset ganglion</p></a></li>
<li><a href='#gg_coplot'><p>Conditional plots</p></a></li>
<li><a href='#gg_pt'><p>Plots for power transformations</p></a></li>
<li><a href='#gg_quantiles'><p>Quantile-Quantile plots</p></a></li>
<li><a href='#gg_rf'><p>Residual-Fit plot</p></a></li>
<li><a href='#gg_sl'><p>Spread-Location plot</p></a></li>
<li><a href='#gg_tmd'><p>Tukey's Mean-Difference plot for one-way data</p></a></li>
<li><a href='#gg_tmd_paired'><p>The gg_tmd_paired function</p></a></li>
<li><a href='#make_coplot_df'><p>Creation of tibbles por coplots</p></a></li>
<li><a href='#ozone'><p>Dataset ozone</p></a></li>
<li><a href='#playfair'><p>Dataset playfair</p></a></li>
<li><a href='#polarization'><p>Dataset polarization</p></a></li>
<li><a href='#rubber'><p>Dataset rubber</p></a></li>
<li><a href='#transf_pot'><p>The trasf_pot function</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Implementation of Plots from Cleveland's Visualizing Data Book</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Description:</td>
<td>William S. Cleveland's book 'Visualizing Data' is a classic piece 
	of literature on Exploratory Data Analysis. Although it was written 
	several decades ago, its content is still relevant as it proposes several 
	tools which are useful to discover patterns and relationships among the data 
	under study, and also to assess the goodness of fit o a model.  This package 
	provides functions to produce the 'ggplot2' versions of the visualization tools 
	described in this book and is thought to be used in the context of courses on 
	Exploratory Data Analysis.</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, tidyr, ggplot2, rlang, magrittr, graphics, readr, egg,
vctrs, lattice, tibble, stringr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/mpru/ggcleveland">https://github.com/mpru/ggcleveland</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/mpru/ggcleveland/issues">https://github.com/mpru/ggcleveland/issues</a></td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-08-12 14:09:22 UTC; marcos</td>
</tr>
<tr>
<td>Author:</td>
<td>Marcos Prunello <a href="https://orcid.org/0000-0002-9611-527X"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Gonzalo Mari [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marcos Prunello &lt;marcosprunello@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-08-16 07:00:09 UTC</td>
</tr>
</table>
<hr>
<h2 id='bin'>Dataset bin</h2><span id='topic+bin'></span>

<h3>Description</h3>

<p>From Cleveland (1993): Bin packing is a computer problem that has challenged mathematicians working on the foundations of theoretical computer science. Suppose a large number of files of different sizes are to be written on floppies. No file can be split between two floppies, but we want to waste as little space as possible. Unfortunately, any algorithm that guarantees the minimum possible empty space takes an enormous amount of computation time unless the number of files is quite small. Fortunately, there are heuristic algorithms that run fast and do an extremely good job of packing, even though they do not guarantee the minimum of empty space. One is first fit decreasing. The files are packed from largest to smallest. For each file, the first floppy is tried; if it has sufficient empty space, the file is written, and if not, the second floppy is tried. If the second file has sufficient space, the file is written and if not, the third floppy is tried. The algorithm proceeds in this way until a floppy with space, possibly a completely empty one, is found. To supplement the theory of bin packing with empirical results, mathematicians and computer scientists have run simulations, computer experiments in which bins are packed with randomly generated weights. For one data set from one experiment, the weights were randomly selected from the interval 0 to 0.8 and packed in bins of size one. The number of weights, n, for each simulation run took one of 11 values: 125,250,500, and so forth by factors of 2 up to 128000. There were 25 runs for each of the 11 different numbers of weights, which makes 25 x 11 = 275 runs in all. For each run of the experiment, the performance of the algorithm was measured by the total amount of empty space in the bins that were used. We will study log empty space to enhance our understanding of multiplicative effects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bin
</code></pre>


<h3>Format</h3>

<p>A data frame with 275 rows and 2 variables:
</p>

<dl>
<dt>empty.space</dt><dd><p>total amount of empty space in the bins that were used</p>
</dd>
<dt>number.weights</dt><dd><p>number of weights</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='dating'>Dataset dating</h2><span id='topic+dating'></span>

<h3>Description</h3>

<p>From Cleveland (1993): Ages of many ancient objects are determined by carbon dating. A second dating method, first reported in 1990, provides calibration back to at least 30 kyr BP by measuring the decay of uranium to thorium. The group that invented the method took core samples in coral off the coast of Barbados and dated the material back to nearly 30 kyr BP using both the carbon and thorium methods. The thorium results were used to study the accuracy of the carbon method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dating
</code></pre>


<h3>Format</h3>

<p>A data frame with 19 rows and 2 variables:
</p>

<dl>
<dt>carbon</dt><dd><p>carbon age</p>
</dd>
<dt>thorium</dt><dd><p>thorium age</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='environmental'>Dataset environmental</h2><span id='topic+environmental'></span>

<h3>Description</h3>

<p>From Cleveland (1993): These measurements were made on 111 days from May to September of 1973 at sites in the New York City metropolitan region; there is one measurement of each variable on each day. Solar radiation is the amount from 0800 to 1200 in the frequency band 4000-7700A, and was measured in Central Park, New York City. Wind speed is the average of values at 0700 and 1000, and was measured at LaGuardia Airport, which is about 7 km from Central Park. Temperature is the daily maximum, and was also measured at LaGuardia. Ozone is the cube root of the average of hourly values from 1300 to 1500, and was measured at Roosevelt Island, which is about 2 km from Central Park and 5 km from LaGuardia.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>environmental
</code></pre>


<h3>Format</h3>

<p>A data frame with 111 rows and 2 variables:
</p>

<dl>
<dt>dia</dt><dd><p>day</p>
</dd>
<dt>ozono</dt><dd><p>ozone</p>
</dd>
<dt>radiacion</dt><dd><p>radiation</p>
</dd>
<dt>temperatura</dt><dd><p>temperature</p>
</dd>
<dt>viento</dt><dd><p>wind</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='equal_count'>The equal count algorithm</h2><span id='topic+equal_count'></span>

<h3>Description</h3>

<p>This function applies the equal count algorithm to divide a set of observations into intervals which can have certain level of ovelapping. It calls 'lattice::equal.count' but extends the output.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>equal_count(df, vble, n_int = 6, frac = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="equal_count_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="equal_count_+3A_vble">vble</code></td>
<td>
<p>numeric variable to be analized</p>
</td></tr>
<tr><td><code id="equal_count_+3A_n_int">n_int</code></td>
<td>
<p>number of intervals</p>
</td></tr>
<tr><td><code id="equal_count_+3A_frac">frac</code></td>
<td>
<p>overlapping fraction</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a list with two elements:
</p>

<dl>
<dt>intervals</dt><dd><p>a tibble where each rows referes to one of the generated interval, with its lower and upper limits, number of values in it and number of values overlapping with the next interval</p>
</dd>
<dt>df_long</dt><dd><p>a tibble in long format where each observation appears as many times as the number of intervals in which it belongs, with an identifier of the observation ('id', its position in the original data.frame) and an identifier of the interval.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>equal_count(iris, Sepal.Length, 15, 0.3)
</code></pre>

<hr>
<h2 id='etanol'>Dataset etanol</h2><span id='topic+etanol'></span>

<h3>Description</h3>

<p>From Cleveland (1993): An experiment studied exhaust from an experimental one-cylinder engine fueled by ethanol. The response, which will be denoted by NOx, is the concentration of nitric oxide, NO, plus the concentration of nitrogen dioxide, NO2, normalized by the amount of work of the engine. The units are microg/xg of NOx per joule. One factor is the equivalence ratio, E, at which the engine was run. E is a measure of the richness of the air and fuel mixture; as E increases there is more fuel in the mixture. Another factor is C, the compression ratio to which the engine is set. C is the volume inside the cylinder when the piston is retracted, divided by the volume when the piston is at its maximum point of penetration into the cylinder. There were 88 runs of the experiment.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>etanol
</code></pre>


<h3>Format</h3>

<p>A data frame with 88 rows and 2 variables:
</p>

<dl>
<dt>NOx</dt><dd><p>concentration of nitric oxide plus the concentration of nitrogen dioxide normalized by the amount of work of the engine.</p>
</dd>
<dt>C</dt><dd><p>compression ratio to which the engine is set</p>
</dd>
<dt>E</dt><dd><p>equivalence ratio at which the engine was run</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='fly'>Dataset fly</h2><span id='topic+fly'></span>

<h3>Description</h3>

<p>From Cleveland (1993): In 1924, a journal article reported 823 observations from a genetics experiment on flies' eyes. Stocks of the ubiquitous species Drosophila melanogaster Meig were hatched in nine incubators whose temperatures varied from 15°C to 31°C in equal steps of 2°C. The number of facets of the eyes of each hatched fly were reported in units that essentially make the measurement scale logarithmic. The goal of the experiment was to see how facet number depends on temperature.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fly
</code></pre>


<h3>Format</h3>

<p>A data frame with 823 rows and 2 variables:
</p>

<dl>
<dt>facet</dt><dd><p>number of facets of the eyes</p>
</dd>
<dt>temperature</dt><dd><p>incubator temperature</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='food'>Dataset food</h2><span id='topic+food'></span>

<h3>Description</h3>

<p>From Cleveland (1993): The food web for the animal species in an ecosystem is a description of who eats whom. A chain is a path through the web. It begins with a species that is eaten by no other, moves to a species that the first species eats, moves next to a species that the second species eats, and so forth until the chain ends at a species that preys on no other. If there are 7 species in the chain then there are 6 links between species, and the length of the chain is 6. The mean chain length of a web is the mean of the lengths of all chains in the web. A two-dimensional ecosystem lies in a flat environment such as a lake bottom or a grassland; movement of species in a third dimension is limited. In a three-dimensional ecosystem, there is considerable movement in three dimensions. One example is a forest canopy; another is a water column in an ocean or lake. A mixed ecosystem is made up of a two-dimensional environment and a three-dimensional environment with enough links between the two to regard it as a single ecosystem. An interesting study reports the mean chain lengths for 113 webs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>food
</code></pre>


<h3>Format</h3>

<p>A data frame with 113 rows and 2 variables:
</p>

<dl>
<dt>mean.length</dt><dd><p>mean web chain length</p>
</dd>
<dt>dimension</dt><dd><p>ecosystem dimenson</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='fusion'>Dataset fusion</h2><span id='topic+fusion'></span>

<h3>Description</h3>

<p>From Cleveland (1993): An experiment was run to study the effect of prior knowledge of an object's form on fusion time when looking at a stereogram. The experimenters measured the time of first fusion for a particular random dot stereogram. There were two groups of subjects. The NV subjects received either no information or verbal information. The VV subjects received a combination of verbal and visual information, either suggestive drawings of the object or a model of it. Thus the VV subjects actually saw something that depicted the object, but the NV subjects did not. The goal in analyzing the fusion times is to determine if there is a shift in the distribution of the VV times toward lower values compared with the NV times.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fusion
</code></pre>


<h3>Format</h3>

<p>A data frame with 78 rows and 2 variables:
</p>

<dl>
<dt>time</dt><dd><p>fusion times, seconds</p>
</dd>
<dt>nv.vv</dt><dd><p>experimental group</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='futbol'>Dataset futbol</h2><span id='topic+futbol'></span>

<h3>Description</h3>

<p>Data about leg length and kick distance from 300 football players.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>futbol
</code></pre>


<h3>Format</h3>

<p>A data frame with 300 rows and 2 variables:
</p>

<dl>
<dt>longp</dt><dd><p>category of leg length</p>
</dd>
<dt>dist</dt><dd><p>kick distance</p>
</dd>
</dl>



<h3>Source</h3>

<p>Unknown
</p>

<hr>
<h2 id='galaxy'>Dataset galaxy</h2><span id='topic+galaxy'></span>

<h3>Description</h3>

<p>From Cleveland (1993): NGC 7531 is a spiral galaxy in the Southern Hemisphere. If the only motion of NGC 7531 relative to the earth were the rapid recession due to the big bang, then over the entire region, the velocity relative to the earth would be constant and equal to about 1600 km/sec. But the actual motion is complex. The galaxy appears to be spinning, and there are other motions that are not well understood. The velocity at different points of the galaxy varies by more than 350 km/sec. These data present the locations where 323 measurements were made of the galaxy velocity. The two scales, whose units are arc seconds, are east-west and south-north positions, which form a coordinate system for the celestial sphere based on the earth's standard coordinate system. The goal in analyzing the galaxy data is to determine how the velocity measurements vary over the measurement region; thus velocity is a response and the two coordinate variables are factors.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>galaxy
</code></pre>


<h3>Format</h3>

<p>A data frame with 323 rows and 6 variables:
</p>

<dl>
<dt>ubicacion</dt><dd><p>location number</p>
</dd>
<dt>este.oeste</dt><dd><p>east-west position</p>
</dd>
<dt>norte.sur</dt><dd><p>south-north position</p>
</dd>
<dt>angulo</dt><dd><p>angle</p>
</dd>
<dt>posicion.radial</dt><dd><p>radial position</p>
</dd>
<dt>velocidad</dt><dd><p>velocity</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='ganglion'>Dataset ganglion</h2><span id='topic+ganglion'></span>

<h3>Description</h3>

<p>From Cleveland (1993): For species with highly developed visual systems, such as cats and man, the distribution of ganglion cells across the surface of the retina is not uniform. For example, cats at birth have a much greater density of cells in the central portion of the retina than on the periphery. But in the early stages of fetal development, the distribution of ganglion cells is uniform. The nonuniformity develops in later stages. The data presents the measurement for 14 cat fetuses ranging in age from 35 to 62 days of gestation of the ratio of the central ganglion cell density to the peripheral density and their retinal area, which is nearly monotonically increasing with age.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ganglion
</code></pre>


<h3>Format</h3>

<p>A data frame with 14 rows and 2 variables:
</p>

<dl>
<dt>area</dt><dd><p>retinal area</p>
</dd>
<dt>cp.ratio</dt><dd><p>ratio of the central ganglion cell density to the peripheral density</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='gg_coplot'>Conditional plots</h2><span id='topic+gg_coplot'></span>

<h3>Description</h3>

<p>Implements conditional plots or coplots.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_coplot(
  df,
  x,
  y,
  faceting,
  number_bins = 6,
  overlap = 0.5,
  equal_length = TRUE,
  loess = TRUE,
  loess_span = 3/4,
  loess_degree = 1,
  loess_family = "gaussian",
  ylabel = quo_text(y),
  xlabel = quo_text(x),
  facet_label = quo_text(faceting),
  facet_labeller = NULL,
  show_intervals = TRUE,
  intervals_height = 0.25,
  remove_strip = FALSE,
  facets_nrow = NULL,
  hline_at = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_coplot_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_x">x</code></td>
<td>
<p>numeric variable for x-axis</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_y">y</code></td>
<td>
<p>numeric variable for y-axis</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_faceting">faceting</code></td>
<td>
<p>faceting numeric variable</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_number_bins">number_bins</code></td>
<td>
<p>integer; the number of conditioning intervals</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_overlap">overlap</code></td>
<td>
<p>numeric &lt; 1; the fraction of overlap of the conditioning
variables</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_equal_length">equal_length</code></td>
<td>
<p>if 'overlap = 0' non overlaping intervals are produced
all with same length if 'equal_length' is 'TRUE' (default) or with the same
number of values otherwise.</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_loess">loess</code></td>
<td>
<p>logical; should a loess smoothing curve be added to the coplots?
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_loess_span">loess_span</code></td>
<td>
<p>span parameter for loess</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_loess_degree">loess_degree</code></td>
<td>
<p>degree parameter for loess</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_loess_family">loess_family</code></td>
<td>
<p>famiyly argument for the loess() function</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_ylabel">ylabel</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_xlabel">xlabel</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_facet_label">facet_label</code></td>
<td>
<p>label for faceting variable</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_facet_labeller">facet_labeller</code></td>
<td>
<p>defaults to NULL so facet labels are automatically
produced, but can take a fuction to be used in 'facet_wrap(~faceting,
labeller = labeller(faceting = facet_labeler))'</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_show_intervals">show_intervals</code></td>
<td>
<p>logical; should the overlapping intervals be shown on
their own panel on the top of the figure? Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_intervals_height">intervals_height</code></td>
<td>
<p>numeric between 0 and 1, relative size of the
intervals pane</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_remove_strip">remove_strip</code></td>
<td>
<p>logical; should de facets have no strips with labels?
Default to FALSE.</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_facets_nrow">facets_nrow</code></td>
<td>
<p>integer; number of rows for the facets</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_hline_at">hline_at</code></td>
<td>
<p>numeric; if provide a horizontal line will be added at that
heigth</p>
</td></tr>
<tr><td><code id="gg_coplot_+3A_...">...</code></td>
<td>
<p>addtional parameters passed to geom_point()</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the number of bins is equal to the number of unique values in the
faceting variable, then no overlaping intervals are produced and each value
in the faceting variable is used as a slice ('frac' is ingored).
</p>
<p>If 'overlap = 0' then 'ggplot2::cut_interval' is used to generate
the intervals if 'equal_length = TRUE' (default), otherwise
'ggplot2::cut_number' is used. If 'overlap' is not zero,
'graphics::co.interval' is called.
</p>


<h3>Value</h3>

<p>a coplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ruber)

# Slicing con intervalos solapados
gg_coplot(rubber, x = tensile.strength, y = abrasion.loss, faceting = hardness,
  number_bins = 6, overlap = 3/4,
  ylabel = "Pérdida de abrasión (g/hp-hour))",
  xlabel = "Resistencia a la tracción (kg/cm2)",
  facet_label = "Dureza (grados Shore)", loess_family = "symmetric", size = 2)

# Slicing con los valores únicos de la variable de faceting
gg_coplot(galaxy, x = posicion.radial, y = velocidad,
  faceting = angulo, number_bins = 7, loess_span = .5, loess_degree = 2,
  facet_labeller = function(x) paste0("Ángulo = ", x, "º"),
  facet_label = "Ángulo (grado)", facets_nrow = 2, intervals_height = 0.2,
  xlabel = "Posición radial (arcsec)", ylabel = "Velocidad (km/s)")

data(galaxy)
gg_coplot(galaxy, x = este.oeste, y = norte.sur, faceting = velocidad,
  number_bins = 25, overlap = 0,  size = 0.5,
  ylabel = "Coordenada sur-norte jittered (arcsec)",
  xlabel = "Coordenada este-oeste jittered (arcsec)",
  facet_label = "Velocidad (km/s)", facets_nrow = 5,
  remove_strip = TRUE, intervals_height = 0.15, loess = FALSE)
</code></pre>

<hr>
<h2 id='gg_pt'>Plots for power transformations</h2><span id='topic+gg_pt'></span>

<h3>Description</h3>

<p>Returns normal QQ plots for a set of power transformations. If there are
groups in the data, transformations can be applied separately to each of
them.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_pt(
  df,
  vble,
  group = NULL,
  taus = c(-1, -0.5, -0.25, 0, 0.25, 0.5, 1),
  xlabel = "Normal quantiles",
  ylabel = paste("Transformed", quo_text(vble)),
  nrow = 2,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_pt_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="gg_pt_+3A_vble">vble</code></td>
<td>
<p>numeric variable in df to be transformed</p>
</td></tr>
<tr><td><code id="gg_pt_+3A_group">group</code></td>
<td>
<p>optional character or factor grouping variable in df. Defaults
to NULL.</p>
</td></tr>
<tr><td><code id="gg_pt_+3A_taus">taus</code></td>
<td>
<p>vector of numeric values for the power transformations (0 is
considered to be the log transform)</p>
</td></tr>
<tr><td><code id="gg_pt_+3A_xlabel">xlabel</code></td>
<td>
<p>x-axis label</p>
</td></tr>
<tr><td><code id="gg_pt_+3A_ylabel">ylabel</code></td>
<td>
<p>y-axis label</p>
</td></tr>
<tr><td><code id="gg_pt_+3A_nrow">nrow</code></td>
<td>
<p>number of rows for facet_wrap, only applied when group is NULL.</p>
</td></tr>
<tr><td><code id="gg_pt_+3A_...">...</code></td>
<td>
<p>parameters to be passed to stat_qq(), such as size, color, shape.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)

# Without groups
fusion %&gt;%
  filter(nv.vv == "VV") %&gt;%
  gg_pt(time)

fusion %&gt;%
  filter(nv.vv == "VV") %&gt;%
  gg_pt(time, taus = c(-0.25, -0.5, -1, 0),
        xlabel = "Cuantiles normales", ylabel = "Valores transformados",
        nrow = 3, color = "red")

# With groups
gg_pt(fusion, time, nv.vv, taus = c(-0.5, -0.25, 0, 0.25, 0.5))

</code></pre>

<hr>
<h2 id='gg_quantiles'>Quantile-Quantile plots</h2><span id='topic+gg_quantiles'></span>

<h3>Description</h3>

<p>Returns a quantile-quantile plot to compare any given number of groups
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_quantiles(
  df,
  vble,
  group,
  combined = FALSE,
  xlabel = NULL,
  ylabel = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_quantiles_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="gg_quantiles_+3A_vble">vble</code></td>
<td>
<p>numeric variable to be analized</p>
</td></tr>
<tr><td><code id="gg_quantiles_+3A_group">group</code></td>
<td>
<p>character or factor grouping variable</p>
</td></tr>
<tr><td><code id="gg_quantiles_+3A_combined">combined</code></td>
<td>
<p>logical, defaults to FALSE, producing a matrix of pairwise QQ
plots. If TRUE, it produces a QQ plot of quantiles of each group versus
quantiles calculated by the combination of all groups. This is useful to
study residuals from a fit.</p>
</td></tr>
<tr><td><code id="gg_quantiles_+3A_xlabel">xlabel</code></td>
<td>
<p>label for x-axis</p>
</td></tr>
<tr><td><code id="gg_quantiles_+3A_ylabel">ylabel</code></td>
<td>
<p>label for y-axis</p>
</td></tr>
<tr><td><code id="gg_quantiles_+3A_...">...</code></td>
<td>
<p>parameters to be passed to geom_point(), such as size, color, shape.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)
data(futbol)

# Multiple groups
gg_quantiles(futbol, dist, longp)
gg_quantiles(futbol, dist, longp, size = 0.4, color = "red", shape = 3) +
  theme(panel.spacing = unit(2, "lines")) +
  theme_bw()

# Only 2 groups
futbol2 &lt;- dplyr::filter(futbol, longp %in% c("&lt; 0.81 m", "0.81 a 0.90 m"))
gg_quantiles(futbol2, dist, longp)

# Each groups vs quantiles from all groups combined
gg_quantiles(futbol, dist, longp, combined = TRUE)
</code></pre>

<hr>
<h2 id='gg_rf'>Residual-Fit plot</h2><span id='topic+gg_rf'></span>

<h3>Description</h3>

<p>Returns a Residual-Fit plot, optionally including centered observed values
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_rf(
  df,
  vble,
  fitted,
  res,
  cen_obs = FALSE,
  cen_obs_label = "Centered observed values",
  cen_fit_label = "Centered fitted values",
  res_label = "Residuals",
  xlabel = expression(f[i]),
  ylabel = quo_text(vble),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_rf_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_vble">vble</code></td>
<td>
<p>numeric variable in df with the observed values</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_fitted">fitted</code></td>
<td>
<p>numeric variable in df with the fitted values</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_res">res</code></td>
<td>
<p>numeric variable in df with the residuals</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_cen_obs">cen_obs</code></td>
<td>
<p>should centered observed values be included in a panel of
their own? Defaults to FALSE. If TRUE, values are centered using the mean
of all data</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_cen_obs_label">cen_obs_label</code></td>
<td>
<p>label for the panel of centered observed values</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_cen_fit_label">cen_fit_label</code></td>
<td>
<p>label for the panel of fitted values</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_res_label">res_label</code></td>
<td>
<p>label for the panel of residuals</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_xlabel">xlabel</code></td>
<td>
<p>x-axis label</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_ylabel">ylabel</code></td>
<td>
<p>y-axis label</p>
</td></tr>
<tr><td><code id="gg_rf_+3A_...">...</code></td>
<td>
<p>parameters to be passed to stat_qq(), such as size, color, shape.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The option to include the centered observed values as part of this
plot was inspired by work done by Eng. German Beltzer in lattice.
</p>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
data(futbol)

datos &lt;-
  futbol %&gt;%
  group_by(longp) %&gt;%
  mutate(ajuste = mean(dist), res = dist - ajuste)

gg_rf(datos, dist, ajuste, res)

gg_rf(datos, dist, ajuste, res, cen_obs = TRUE)

gg_rf(datos, dist, ajuste, res, cen_obs = TRUE,
      cen_obs_label = "Obs centradas", cen_fit_label = "Ajustados menos media",
      res_label = "Residuos", xlabel = "valor f", ylabel = "Distancia (m)",
      color = "red", size = 0.7)

</code></pre>

<hr>
<h2 id='gg_sl'>Spread-Location plot</h2><span id='topic+gg_sl'></span>

<h3>Description</h3>

<p>Returns a spread-location plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_sl(
  df,
  vble,
  group,
  jitterwidth = 0.1,
  jitteralpha = 0.5,
  linecol = "red",
  ylabel = expression(sqrt(abs(" Residuals "))),
  xlabel = "Medians"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_sl_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="gg_sl_+3A_vble">vble</code></td>
<td>
<p>numeric variable to be analized</p>
</td></tr>
<tr><td><code id="gg_sl_+3A_group">group</code></td>
<td>
<p>grouping character or factor variable</p>
</td></tr>
<tr><td><code id="gg_sl_+3A_jitterwidth">jitterwidth</code></td>
<td>
<p>width argument for geom_jitter</p>
</td></tr>
<tr><td><code id="gg_sl_+3A_jitteralpha">jitteralpha</code></td>
<td>
<p>alpha argument for geom_jitter</p>
</td></tr>
<tr><td><code id="gg_sl_+3A_linecol">linecol</code></td>
<td>
<p>col argument for geom_line</p>
</td></tr>
<tr><td><code id="gg_sl_+3A_ylabel">ylabel</code></td>
<td>
<p>y-axis label</p>
</td></tr>
<tr><td><code id="gg_sl_+3A_xlabel">xlabel</code></td>
<td>
<p>x-axis label</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot object with the spread-location plot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(ggplot2)

gg_sl(fusion, time, nv.vv)

gg_sl(fusion, time, nv.vv, jitterwidth = 0.4, linecol = "blue",
      jitteralpha = 1) +
  scale_color_discrete("Grupo") +
  xlim(2, 8)

</code></pre>

<hr>
<h2 id='gg_tmd'>Tukey's Mean-Difference plot for one-way data</h2><span id='topic+gg_tmd'></span>

<h3>Description</h3>

<p>Returns Tukey's Mean-Difference plot for one-way data
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_tmd(df, vble, group, xlabel = "Mean", ylabel = "Difference", ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_tmd_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="gg_tmd_+3A_vble">vble</code></td>
<td>
<p>numeric variable to be analized</p>
</td></tr>
<tr><td><code id="gg_tmd_+3A_group">group</code></td>
<td>
<p>character or factor grouping variable</p>
</td></tr>
<tr><td><code id="gg_tmd_+3A_xlabel">xlabel</code></td>
<td>
<p>label for x-axis, defaults to &quot;Mean&quot;</p>
</td></tr>
<tr><td><code id="gg_tmd_+3A_ylabel">ylabel</code></td>
<td>
<p>label for y-axis, defaults to &quot;Difference&quot;</p>
</td></tr>
<tr><td><code id="gg_tmd_+3A_...">...</code></td>
<td>
<p>parameters to be passed to geom_point(), such as size, color, shape.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(dplyr)
data(futbol)

# Multiple groups
gg_tmd(futbol, dist, longp)
gg_tmd(futbol, dist, longp, size = 0.4, color = "red", shape = 3)

# Only 2 groups
futbol %&gt;%
  filter(longp %in% c("&lt; 0.81 m", "0.81 a 0.90 m")) %&gt;%
  gg_tmd(dist, longp)
</code></pre>

<hr>
<h2 id='gg_tmd_paired'>The gg_tmd_paired function</h2><span id='topic+gg_tmd_paired'></span>

<h3>Description</h3>

<p>Returns Tukey's Mean-Difference plot for paired data (both variables must be measured in the same scale).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>gg_tmd_paired(
  df,
  vble1,
  vble2,
  xlabel = "Mean",
  ylabel = "Difference",
  loess = TRUE,
  loess_span = 1,
  loess_degree = 1,
  loess_family = "gaussian",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="gg_tmd_paired_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="gg_tmd_paired_+3A_vble1">vble1</code>, <code id="gg_tmd_paired_+3A_vble2">vble2</code></td>
<td>
<p>numeric variables to be analized</p>
</td></tr>
<tr><td><code id="gg_tmd_paired_+3A_xlabel">xlabel</code></td>
<td>
<p>label for x-axis, defaults to &quot;Mean&quot;</p>
</td></tr>
<tr><td><code id="gg_tmd_paired_+3A_ylabel">ylabel</code></td>
<td>
<p>label for y-axis, defaults to &quot;Difference&quot;</p>
</td></tr>
<tr><td><code id="gg_tmd_paired_+3A_loess">loess</code></td>
<td>
<p>logical; should a loess smoothing curve be added to the coplots?
Defaults to TRUE.</p>
</td></tr>
<tr><td><code id="gg_tmd_paired_+3A_loess_span">loess_span</code></td>
<td>
<p>span parameter for loess</p>
</td></tr>
<tr><td><code id="gg_tmd_paired_+3A_loess_degree">loess_degree</code></td>
<td>
<p>degree parameter for loess</p>
</td></tr>
<tr><td><code id="gg_tmd_paired_+3A_loess_family">loess_family</code></td>
<td>
<p>famiyly argument for the loess() function</p>
</td></tr>
<tr><td><code id="gg_tmd_paired_+3A_...">...</code></td>
<td>
<p>parameters to be passed to geom_point(), such as size, color, shape.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Differences are computed as 'vble1 - vble2'.
</p>


<h3>Value</h3>

<p>a ggplot
</p>


<h3>Examples</h3>

<pre><code class='language-R'>gg_tmd_paired(ozone, stamford, yonkers)
</code></pre>

<hr>
<h2 id='make_coplot_df'>Creation of tibbles por coplots</h2><span id='topic+make_coplot_df'></span>

<h3>Description</h3>

<p>It creates dataframes to be used in coplot
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_coplot_df(df, vble, number_bins = 6, overlap = 0.5, equal_length = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_coplot_df_+3A_df">df</code></td>
<td>
<p>dataframe</p>
</td></tr>
<tr><td><code id="make_coplot_df_+3A_vble">vble</code></td>
<td>
<p>faceting numeric variable</p>
</td></tr>
<tr><td><code id="make_coplot_df_+3A_number_bins">number_bins</code></td>
<td>
<p>integer; the number of conditioning intervals</p>
</td></tr>
<tr><td><code id="make_coplot_df_+3A_overlap">overlap</code></td>
<td>
<p>numeric &lt; 1; the fraction of overlap of the conditioning variables</p>
</td></tr>
<tr><td><code id="make_coplot_df_+3A_equal_length">equal_length</code></td>
<td>
<p>if 'overlap = 0' non overlaping intervals are produced
all with same length if 'equal_length' is 'TRUE' (default) or with the same
number of values otherwise.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Adapted from <a href="https://jfukuyama.github.io/teaching/stat670/notes/lecture-11.html">here</a>.
</p>
<p>If 'overlap = 0' then 'ggplot2::cut_interval' is used to generate
the intervals if 'equal_length = TRUE' (default), otherwise
'ggplot2::cut_number' is used. If 'overlap' is not zero,
'graphics::co.interval' is called.
</p>


<h3>Value</h3>

<p>a dataset to be used in the creation of coplots
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data_coplot &lt;- make_coplot_df(rubber, hardness, 6, 3/4)
</code></pre>

<hr>
<h2 id='ozone'>Dataset ozone</h2><span id='topic+ozone'></span>

<h3>Description</h3>

<p>From Cleveland (1993): The data are daily maximum ozone concentrations at ground level on 132 days from May 1,1974 to September 30,1974 at two sites in the U.S.A. — Yonkers, New York and Stamford, Connecticut — which are approximately 30 km from one another. The sample for each measurement is the air mass on a particular day, and the bivariate data arise from two measurements at the two sites.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ozone
</code></pre>


<h3>Format</h3>

<p>A data frame with 132 rows and 2 variables:
</p>

<dl>
<dt>dia</dt><dd><p>day</p>
</dd>
<dt>yonkers</dt><dd><p>air mass at Yonkers</p>
</dd>
<dt>stamford</dt><dd><p>air mass at Stamford</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='playfair'>Dataset playfair</h2><span id='topic+playfair'></span>

<h3>Description</h3>

<p>From Cleveland (1993): In 1801, William Playfair published his Statistical Breviary, which contains many displays of economic and demographic data. One display, beautifully reproduced by Tufte, graphs the populations of 22 cities by the areas of circles. The graph also contains a table of the populations, so we can compare the data and the areas of the circles.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>playfair
</code></pre>


<h3>Format</h3>

<p>A data frame with 22 rows and 2 variables:
</p>

<dl>
<dt>city</dt><dd><p>city</p>
</dd>
<dt>population</dt><dd><p>population</p>
</dd>
<dt>diameter</dt><dd><p>diameter of the circle in the figure</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='polarization'>Dataset polarization</h2><span id='topic+polarization'></span>

<h3>Description</h3>

<p>From Cleveland (1993): This data comes from an experiment on the scattering of sunhght in the atmosphere. One variable is the Babinet point, the scattering angle at which the polarization of sunhght vanishes. The other one is the atmospheric concentration of soHd particles in the air. The goal is to determine the dependence of the Babinet point on concentration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>polarization
</code></pre>


<h3>Format</h3>

<p>A data frame with 355 rows and 2 variables:
</p>

<dl>
<dt>concentration</dt><dd><p>particulate concentration</p>
</dd>
<dt>babinet</dt><dd><p>Babinet point</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='rubber'>Dataset rubber</h2><span id='topic+rubber'></span>

<h3>Description</h3>

<p>From Cleveland (1993): data from an industrial experiment in which thirty rubber specimens were rubbed by an abrasive material. Measurements of three variables - abrasion loss, hardness, and tensile strength - were made for each specimen. Abrasion loss is the amount of material abraded from a specimen per unit of energy expended in the rubbing; tensile strength is the force per unit of cross-sectional area required to break a specimen; and hardness is the rebound height of a steel indenter dropped onto a specimen. The goal is to determine the dependence of abrasion loss on tensile strength and hardness
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rubber
</code></pre>


<h3>Format</h3>

<p>A data frame with 78 rows and 2 variables:
</p>

<dl>
<dt>hardness</dt><dd><p>hardness</p>
</dd>
<dt>tensile.strength</dt><dd><p>tensile strength</p>
</dd>
<dt>abrasion.loss</dt><dd><p>abrasion loss</p>
</dd>
<dt>ts.low</dt><dd><p>tensile.strength - 180 if tensile.strength &lt; 180 or 0 otherwise</p>
</dd>
<dt>ts.high</dt><dd><p>tensile.strength - 180 if tensile.strength &gt; 180 or 0 otherwise</p>
</dd>
</dl>



<h3>Source</h3>

<p>Cleveland W. S. (1993). “Visualizing Data”. Hobart Press.
</p>

<hr>
<h2 id='transf_pot'>The trasf_pot function</h2><span id='topic+transf_pot'></span>

<h3>Description</h3>

<p>Helper function for gg_pt
</p>


<h3>Usage</h3>

<pre><code class='language-R'>transf_pot(x, tau = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="transf_pot_+3A_x">x</code></td>
<td>
<p>numeric vector to be transformed</p>
</td></tr>
<tr><td><code id="transf_pot_+3A_tau">tau</code></td>
<td>
<p>powers</p>
</td></tr>
</table>


<h3>Value</h3>

<p>vector of transformed values
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
