<!DOCTYPE html><html lang="en"><head><title>Help for package oaii</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {oaii}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#api_get_key'><p>Get the OpenAI API key from environment variable</p></a></li>
<li><a href='#api_set_key'><p>Store the OpenAI API key as environment variable</p></a></li>
<li><a href='#api_upload_file'><p>Create &quot;uploaded file&quot; object</p></a></li>
<li><a href='#assistants_create_assistant_request'><p>API assistants: create assistant</p></a></li>
<li><a href='#assistants_create_file_request'><p>API assistants: create assistant file</p></a></li>
<li><a href='#assistants_delete_assistant_file_request'><p>API assistants: delete assistant file</p></a></li>
<li><a href='#assistants_delete_assistant_request'><p>API assistants: delete assistant</p></a></li>
<li><a href='#assistants_list_asistants_request'><p>API assistants: list assistants</p></a></li>
<li><a href='#assistants_modify_assistant_request'><p>API assistants: modify assistant</p></a></li>
<li><a href='#assistants_retrieve_assistant_file_request'><p>API assistants: retrieve assistant file</p></a></li>
<li><a href='#assistants_retrieve_assistant_request'><p>API assistants: retrieve assistant</p></a></li>
<li><a href='#audio_speech_request'><p>API audio: text to speech request</p></a></li>
<li><a href='#audio_transcription_request'><p>API audio: speech to text (transcryption)</p></a></li>
<li><a href='#audio_translation_request'><p>API audio: translate audio file into English text</p></a></li>
<li><a href='#browseable_audio'><p>Create browseable HTML audio</p></a></li>
<li><a href='#chat_fetch_messages'><p>Fetch messages from response content</p></a></li>
<li><a href='#chat_request'><p>API chat: send create (chat) request</p></a></li>
<li><a href='#completions_fetch_text'><p>Fetch completions text from response content</p></a></li>
<li><a href='#completions_request'><p>API completions: create request</p></a></li>
<li><a href='#csv_to_dialog_df'><p>Read csv file as dialog data.frame</p></a></li>
<li><a href='#df_col_dt_format'><p>Replace unix timestamp column(s) to formated dt string</p></a></li>
<li><a href='#df_col_obj_implode'><p>Change to string nested lists in a given data.frame</p></a></li>
<li><a href='#df_exclude_col'><p>Remove columns from data.frame</p></a></li>
<li><a href='#df_null_replace'><p>Replace all NULL values in given data.frame</p></a></li>
<li><a href='#df_order_by_col'><p>Sort data.frame by column name</p></a></li>
<li><a href='#df_roxygen_tpl'><p>df roxygen template</p></a></li>
<li><a href='#dialog_df'><p>Create dialog data.frame</p></a></li>
<li><a href='#dialog_df_to_csv'><p>Save dialog data.frame as csv file</p></a></li>
<li><a href='#embeddings_create_request'><p>API embeddings: create embeddings</p></a></li>
<li><a href='#embeddings_object_request'><p>API embeddings: get embedding object</p></a></li>
<li><a href='#feedback'><p>Feedback - ask chat and receive reply</p></a></li>
<li><a href='#files_delete_request'><p>API files: delete file request</p></a></li>
<li><a href='#files_fetch_list'><p>Extract files list as data.frame from response object</p></a></li>
<li><a href='#files_list_request'><p>API files: get list request</p></a></li>
<li><a href='#files_retrieve_content_request'><p>API files: retrieve content request</p></a></li>
<li><a href='#files_retrieve_request'><p>API files: retrieve file request</p></a></li>
<li><a href='#files_roxygen_tpl'><p>API files: roxygen template</p></a></li>
<li><a href='#files_upload_request'><p>API files: upload request</p></a></li>
<li><a href='#fine_tuning_cancel_job_request'><p>API fine-tuning: cancel fine-tuning job request</p></a></li>
<li><a href='#fine_tuning_create_job_request'><p>API fine-tuning: create job (model) request</p></a></li>
<li><a href='#fine_tuning_events_list_request'><p>API fine-tuning: list events request</p></a></li>
<li><a href='#fine_tuning_fetch_events_list'><p>API fine-tuning: job list from response object</p></a></li>
<li><a href='#fine_tuning_fetch_jobs_list'><p>API fine-tuning: extract fine-tuning jobs list from response object</p></a></li>
<li><a href='#fine_tuning_fetch_retrived_job'><p>API fine-tuning: fetch retrived job object from response object</p></a></li>
<li><a href='#fine_tuning_jobs_list_request'><p>API fine-tuning: list jobs request</p></a></li>
<li><a href='#fine_tuning_retrive_job_request'><p>API fine-tuning: retrieve fine-tuning job request</p></a></li>
<li><a href='#images_edit_request'><p>API images: edit request</p></a></li>
<li><a href='#images_fech_set'><p>Fetch image set from response content</p></a></li>
<li><a href='#images_generator_request'><p>API images: create (generator) request</p></a></li>
<li><a href='#images_merge_sets'><p>Merge image set/sets</p></a></li>
<li><a href='#images_variation_request'><p>API images: create image variation request</p></a></li>
<li><a href='#is_browseable'><p>Test if RStudio Viewer (build in browser) is available</p></a></li>
<li><a href='#is_error'><p>Test if object belongs to &quot;error&quot; class</p></a></li>
<li><a href='#is_image_set'><p>Test if x is a image set</p></a></li>
<li><a href='#merge_dialog_df'><p>Merge multiple dialog data.frame</p></a></li>
<li><a href='#messages_create_message_request'><p>API messages: create message</p></a></li>
<li><a href='#messages_list_message_files_request'><p>API messages: list message files</p></a></li>
<li><a href='#messages_list_messages_request'><p>API messages: list messages</p></a></li>
<li><a href='#messages_modify_message_request'><p>API messages: modify message</p></a></li>
<li><a href='#messages_retrieve_message_file_request'><p>API messages: retrieve message file</p></a></li>
<li><a href='#messages_retrieve_message_request'><p>API messages: retrieve message</p></a></li>
<li><a href='#models_delete_request'><p>API models: delete model request</p></a></li>
<li><a href='#models_fetch_list'><p>Extract models from response object</p></a></li>
<li><a href='#models_list_request'><p>API models: list request</p></a></li>
<li><a href='#models_retrieve_request'><p>API models: retrieve model request</p></a></li>
<li><a href='#moderation_create_request'><p>API moderations: create moderation</p></a></li>
<li><a href='#print.oaii_content_audio'><p>Class oaii_content_audio print S3 method</p></a></li>
<li><a href='#print.oaii_content_audio_aac'><p>Class oaii_content_audio_aac print S3 method</p></a></li>
<li><a href='#print.oaii_content_audio_flac'><p>Class oaii_content_audio_flac print S3 method</p></a></li>
<li><a href='#print.oaii_content_audio_mp3'><p>Class oaii_content_audio_mp3 print S3 method</p></a></li>
<li><a href='#print.oaii_content_audio_opus'><p>Class oaii_content_audio_opus print S3 method</p></a></li>
<li><a href='#print.oaii_content_images'><p>Class oaii_content_images print S3 method</p></a></li>
<li><a href='#print.oaii_files_df'><p>print S3 method for oaii_files_df class</p></a></li>
<li><a href='#print.oaii_fine_tuning_events_df'><p>print S3 method for oaii_fine_tuning_events_df class</p></a></li>
<li><a href='#print.oaii_fine_tuning_job'><p>print S3 method for oaii_fine_tuning_job class</p></a></li>
<li><a href='#print.oaii_fine_tuning_jobs_df'><p>print S3 method for oaii_fine_tuning_jobs_df class</p></a></li>
<li><a href='#print.oaii_models_df'><p>print S3 method for oaii_models_df class</p></a></li>
<li><a href='#print.oaii_res_se'><p>Class oaii_res_se print S3 method</p></a></li>
<li><a href='#request'><p>API request</p></a></li>
<li><a href='#runs_cancel_run_request'><p>API runs: cancel a run</p></a></li>
<li><a href='#runs_create_run_request'><p>API runs: create run</p></a></li>
<li><a href='#runs_create_thread_and_run_request'><p>API runs: create thread and run</p></a></li>
<li><a href='#runs_list_run_steps_request'><p>API runs: list run steps</p></a></li>
<li><a href='#runs_list_runs_request'><p>API runs: list runs</p></a></li>
<li><a href='#runs_modify_run_request'><p>API runs: modify run</p></a></li>
<li><a href='#runs_retrieve_run_request'><p>API runs: retrieve run</p></a></li>
<li><a href='#runs_retrieve_run_step_request'><p>API runs: retrieve run step</p></a></li>
<li><a href='#runs_submit_tool_outputs_request'><p>API runs: submit tool outputs to run</p></a></li>
<li><a href='#set_logger'><p>Set log functions used by 'oaii' package</p></a></li>
<li><a href='#threads_create_thread_request'><p>API threads: create thread</p></a></li>
<li><a href='#threads_delete_thread_request'><p>API threads: delete thread</p></a></li>
<li><a href='#threads_modify_thread_request'><p>API threads: modify thread</p></a></li>
<li><a href='#threads_retrieve_thread_request'><p>API threads: retrieve thread</p></a></li>
<li><a href='#timestap_dt_str'><p>Convert unix timestamp to formated date/time string</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>'OpenAI' API R Interface</td>
</tr>
<tr>
<td>Version:</td>
<td>0.5.0</td>
</tr>
<tr>
<td>Description:</td>
<td>A comprehensive set of helpers that streamline data transmission
  and processing, making it effortless to interact with the 'OpenAI' API.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/cezarykuran/oaii">https://github.com/cezarykuran/oaii</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Imports:</td>
<td>base64enc, checkmate, httr, magrittr, utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>htmltools, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.0</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-13 01:35:54 UTC; rstudio</td>
</tr>
<tr>
<td>Author:</td>
<td>Cezary Kuran [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Cezary Kuran &lt;cezary.kuran@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-13 05:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='api_get_key'>Get the OpenAI API key from environment variable</h2><span id='topic+api_get_key'></span>

<h3>Description</h3>

<p>Get the OpenAI API key from environment variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>api_get_key()
</code></pre>


<h3>Value</h3>

<p>API key string
</p>


<h3>See Also</h3>

<p><a href="#topic+api_set_key">api_set_key</a>
</p>

<hr>
<h2 id='api_set_key'>Store the OpenAI API key as environment variable</h2><span id='topic+api_set_key'></span>

<h3>Description</h3>

<p>Store the OpenAI API key as environment variable
</p>


<h3>Usage</h3>

<pre><code class='language-R'>api_set_key(api_key)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="api_set_key_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p>API key string ('api_key')
</p>


<h3>See Also</h3>

<p><a href="#topic+api_get_key">api_get_key</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
api_set_key("my-secret-api-key-string")

## End(Not run)

</code></pre>

<hr>
<h2 id='api_upload_file'>Create &quot;uploaded file&quot; object</h2><span id='topic+api_upload_file'></span>

<h3>Description</h3>

<p>See <a href="httr.html#topic+upload_file">upload_file</a>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>api_upload_file(f, type = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="api_upload_file_+3A_f">f</code></td>
<td>
<p>string/raw, content of file or path to the file</p>
</td></tr>
<tr><td><code id="api_upload_file_+3A_type">type</code></td>
<td>
<p>mime type of path. If not supplied, will be guess by
<code><a href="mime.html#topic+guess_type">mime::guess_type()</a></code> when needed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>NULL if 'f' was NULL otherwise &quot;uploaded_file&quot; object
</p>

<hr>
<h2 id='assistants_create_assistant_request'>API assistants: create assistant</h2><span id='topic+assistants_create_assistant_request'></span>

<h3>Description</h3>

<p>Create an assistant with a model and instructions. To get more details, visit
https://platform.openai.com/docs/api-reference/assistants/createAssistant
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assistants_create_assistant_request(
  model,
  name = NULL,
  description = NULL,
  instructions = NULL,
  tools = NULL,
  file_ids = NULL,
  metadata = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assistants_create_assistant_request_+3A_model">model</code></td>
<td>
<p>string, ID of the model to use. You can use the List models API to see all of your available models,
or see our model overview for descriptions of them.</p>
</td></tr>
<tr><td><code id="assistants_create_assistant_request_+3A_name">name</code></td>
<td>
<p>NULL/string, the name of the assistant. The maximum length is 256 characters.</p>
</td></tr>
<tr><td><code id="assistants_create_assistant_request_+3A_description">description</code></td>
<td>
<p>NULL/string, the description of the assistant. The maximum length is 512 characters.</p>
</td></tr>
<tr><td><code id="assistants_create_assistant_request_+3A_instructions">instructions</code></td>
<td>
<p>NULL/string, the system instructions that the assistant uses. The maximum length is 32768
characters.</p>
</td></tr>
<tr><td><code id="assistants_create_assistant_request_+3A_tools">tools</code></td>
<td>
<p>NULL/list, a list of tool enabled on the assistant. There can be a maximum of 128 tools per
assistant. Tools can be of types code_interpreter, retrieval, or function.</p>
</td></tr>
<tr><td><code id="assistants_create_assistant_request_+3A_file_ids">file_ids</code></td>
<td>
<p>NULL/character vector, a list of file IDs attached to this assistant. There can be a maximum of 20
files attached to the assistant. Files are ordered by their creation date in ascending order.</p>
</td></tr>
<tr><td><code id="assistants_create_assistant_request_+3A_metadata">metadata</code></td>
<td>
<p>NULL/list, set of 16 key-value pairs that can be attached to an object. This can be useful for
storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long
and values can be a maxium of 512 characters long.</p>
</td></tr>
<tr><td><code id="assistants_create_assistant_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='assistants_create_file_request'>API assistants: create assistant file</h2><span id='topic+assistants_create_file_request'></span>

<h3>Description</h3>

<p>Create an assistant file by attaching a file (https://platform.openai.com/docs/api-reference/files) to an assistant
(https://platform.openai.com/docs/api-reference/assistants). To get more details, visit
https://platform.openai.com/docs/api-reference/assistants/createAssistantFile
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assistants_create_file_request(assistant_id, file_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assistants_create_file_request_+3A_assistant_id">assistant_id</code></td>
<td>
<p>string, the ID of the assistant for which to create a File.</p>
</td></tr>
<tr><td><code id="assistants_create_file_request_+3A_file_id">file_id</code></td>
<td>
<p>string, a file ID (with purpose=&quot;assistants&quot;) that the assistant should use. Useful for tools like
retrieval and code_interpreter that can access files.</p>
</td></tr>
<tr><td><code id="assistants_create_file_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='assistants_delete_assistant_file_request'>API assistants: delete assistant file</h2><span id='topic+assistants_delete_assistant_file_request'></span>

<h3>Description</h3>

<p>Delete an AssistantFile. To get more details, visit
https://platform.openai.com/docs/api-reference/assistants/deleteAssistantFile
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assistants_delete_assistant_file_request(
  assistant_id,
  file_id,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assistants_delete_assistant_file_request_+3A_assistant_id">assistant_id</code></td>
<td>
<p>string, the ID of the assistant who the file belongs to.</p>
</td></tr>
<tr><td><code id="assistants_delete_assistant_file_request_+3A_file_id">file_id</code></td>
<td>
<p>string, the ID of the file to delete</p>
</td></tr>
<tr><td><code id="assistants_delete_assistant_file_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='assistants_delete_assistant_request'>API assistants: delete assistant</h2><span id='topic+assistants_delete_assistant_request'></span>

<h3>Description</h3>

<p>Delete an assistant. To get more details, visit
https://platform.openai.com/docs/api-reference/assistants/deleteAssistant
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assistants_delete_assistant_request(assistant_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assistants_delete_assistant_request_+3A_assistant_id">assistant_id</code></td>
<td>
<p>string, the ID of the assistant to delete</p>
</td></tr>
<tr><td><code id="assistants_delete_assistant_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='assistants_list_asistants_request'>API assistants: list assistants</h2><span id='topic+assistants_list_asistants_request'></span>

<h3>Description</h3>

<p>Returns a list of assistants. To get more details, visit
https://platform.openai.com/docs/api-reference/assistants/listAssistants
https://platform.openai.com/docs/assistants
</p>
<p>Returns a list of assistant files. To get more details, visit
https://platform.openai.com/docs/api-reference/assistants/listAssistantFiles
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assistants_list_asistants_request(
  assistant_id,
  limit = NULL,
  order = NULL,
  after = NULL,
  before = NULL,
  api_key = api_get_key()
)

assistants_list_asistants_request(
  assistant_id,
  limit = NULL,
  order = NULL,
  after = NULL,
  before = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assistants_list_asistants_request_+3A_assistant_id">assistant_id</code></td>
<td>
<p>string, the ID of the assistant the file belongs to.</p>
</td></tr>
<tr><td><code id="assistants_list_asistants_request_+3A_limit">limit</code></td>
<td>
<p>NULL/integer, a limit on the number of objects to be returned. Limit can range between 1 and 100,
and the default is 20.</p>
</td></tr>
<tr><td><code id="assistants_list_asistants_request_+3A_order">order</code></td>
<td>
<p>NULL/string, sort order by the created_at timestamp of the objects. asc for ascending order and desc for
descending order. Defaults to desc</p>
</td></tr>
<tr><td><code id="assistants_list_asistants_request_+3A_after">after</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. after is an object ID that defines your place in the list.
For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include after=obj_foo in order to fetch the next page of the list.</p>
</td></tr>
<tr><td><code id="assistants_list_asistants_request_+3A_before">before</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. before is an object ID that defines your place in the
list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include before=obj_foo in order to fetch the previous page of the list.</p>
</td></tr>
<tr><td><code id="assistants_list_asistants_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='assistants_modify_assistant_request'>API assistants: modify assistant</h2><span id='topic+assistants_modify_assistant_request'></span>

<h3>Description</h3>

<p>Modifies an assistant. To get more details, visit
https://platform.openai.com/docs/api-reference/assistants/modifyAssistant
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assistants_modify_assistant_request(
  assistant_id,
  model = NULL,
  name = NULL,
  description = NULL,
  instructions = NULL,
  tools = NULL,
  file_ids = NULL,
  metadata = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assistants_modify_assistant_request_+3A_assistant_id">assistant_id</code></td>
<td>
<p>string, the ID of the assistant to modify</p>
</td></tr>
<tr><td><code id="assistants_modify_assistant_request_+3A_model">model</code></td>
<td>
<p>string, ID of the model to use. You can use the List models API to see all of your available models, or
see our model overview (https://platform.openai.com/docs/models/overview) for descriptions of them.</p>
</td></tr>
<tr><td><code id="assistants_modify_assistant_request_+3A_name">name</code></td>
<td>
<p>NULL/string, the name of the assistant. The maximum length is 256 characters.</p>
</td></tr>
<tr><td><code id="assistants_modify_assistant_request_+3A_description">description</code></td>
<td>
<p>NULL/string, the description of the assistant. The maximum length is 512 characters.</p>
</td></tr>
<tr><td><code id="assistants_modify_assistant_request_+3A_instructions">instructions</code></td>
<td>
<p>NULL/string, the system instructions that the assistant uses. The maximum length is 32768
characters.</p>
</td></tr>
<tr><td><code id="assistants_modify_assistant_request_+3A_tools">tools</code></td>
<td>
<p>NULL/list, a list of tool enabled on the assistant. There can be a maximum of 128 tools per
assistant. Tools can be of types code_interpreter, retrieval, or function.</p>
</td></tr>
<tr><td><code id="assistants_modify_assistant_request_+3A_file_ids">file_ids</code></td>
<td>
<p>NULL/character vector, a list of file IDs attached to this assistant. There can be a maximum of 20
files attached to the assistant. Files are ordered by their creation date in ascending order.</p>
</td></tr>
<tr><td><code id="assistants_modify_assistant_request_+3A_metadata">metadata</code></td>
<td>
<p>NULL/list, set of 16 key-value pairs that can be attached to an object. This can be useful for
storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long
and values can be a maxium of 512 characters long.</p>
</td></tr>
<tr><td><code id="assistants_modify_assistant_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='assistants_retrieve_assistant_file_request'>API assistants: retrieve assistant file</h2><span id='topic+assistants_retrieve_assistant_file_request'></span>

<h3>Description</h3>

<p>Retrieves an AssistantFile. To get more details, visit
https://platform.openai.com/docs/api-reference/assistants/getAssistantFile
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assistants_retrieve_assistant_file_request(
  assistant_id,
  file_id,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assistants_retrieve_assistant_file_request_+3A_assistant_id">assistant_id</code></td>
<td>
<p>string, the ID of the assistant who the file belongs to.</p>
</td></tr>
<tr><td><code id="assistants_retrieve_assistant_file_request_+3A_file_id">file_id</code></td>
<td>
<p>string, the ID of the file we're getting.</p>
</td></tr>
<tr><td><code id="assistants_retrieve_assistant_file_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='assistants_retrieve_assistant_request'>API assistants: retrieve assistant</h2><span id='topic+assistants_retrieve_assistant_request'></span>

<h3>Description</h3>

<p>Retrieves an assistant. To get more details, visit
https://platform.openai.com/docs/api-reference/assistants/getAssistant
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>assistants_retrieve_assistant_request(assistant_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="assistants_retrieve_assistant_request_+3A_assistant_id">assistant_id</code></td>
<td>
<p>string, the ID of the assistant to retrieve.</p>
</td></tr>
<tr><td><code id="assistants_retrieve_assistant_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='audio_speech_request'>API audio: text to speech request</h2><span id='topic+audio_speech_request'></span>

<h3>Description</h3>

<p>Generates audio from the input text. To get more details, visit
https://platform.openai.com/docs/api-reference/audio/createSpeech
https://platform.openai.com/docs/guides/speech-to-text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audio_speech_request(
  model,
  input,
  voice,
  response_format = NULL,
  speed = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="audio_speech_request_+3A_model">model</code></td>
<td>
<p>string, one of the available TTS models: 'tts-1' or 'tts-1-hd'</p>
</td></tr>
<tr><td><code id="audio_speech_request_+3A_input">input</code></td>
<td>
<p>string, the text to generate audio for. The maximum length is 4096 characters.</p>
</td></tr>
<tr><td><code id="audio_speech_request_+3A_voice">voice</code></td>
<td>
<p>string, the voice to use when generating the audio. Supported voices are alloy, echo, fable, onyx, nova,
and shimmer. Previews of the voices are available in the Text to speech guide -
https://platform.openai.com/docs/guides/text-to-speech/voice-options</p>
</td></tr>
<tr><td><code id="audio_speech_request_+3A_response_format">response_format</code></td>
<td>
<p>string, the format to audio in. Supported formats are mp3 (default), opus, aac, and flac</p>
</td></tr>
<tr><td><code id="audio_speech_request_+3A_speed">speed</code></td>
<td>
<p>double, the speed of the generated audio. Select a value from 0.25 to 4.0, 1.0 is the default.</p>
</td></tr>
<tr><td><code id="audio_speech_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- audio_speech_request(
  "tts-1",
  "When the power of love overcomes the love of power, the world will know peace.",
  "nova"
)
if (!is_error(res_content)) {
  writeBin(res_content, "peace.mp3")
}

## End(Not run)

</code></pre>

<hr>
<h2 id='audio_transcription_request'>API audio: speech to text (transcryption)</h2><span id='topic+audio_transcription_request'></span>

<h3>Description</h3>

<p>Transcribes audio into the input language. To get more details, visit
https://platform.openai.com/docs/api-reference/audio/createTranscription
https://platform.openai.com/docs/guides/speech-to-text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audio_transcription_request(
  file,
  model,
  language = NULL,
  prompt = NULL,
  response_format = NULL,
  temperature = NULL,
  file_type = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="audio_transcription_request_+3A_file">file</code></td>
<td>
<p>string/raw, content of the audio file or path to the audio file to transcribe, in one of these formats:
flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.</p>
</td></tr>
<tr><td><code id="audio_transcription_request_+3A_model">model</code></td>
<td>
<p>string, ID of the model to use. Only 'whisper-1' is currently available.</p>
</td></tr>
<tr><td><code id="audio_transcription_request_+3A_language">language</code></td>
<td>
<p>NULL/string, the language of the input audio. Supplying the input language in ISO-639-1 format will
improve accuracy and latency. See https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes</p>
</td></tr>
<tr><td><code id="audio_transcription_request_+3A_prompt">prompt</code></td>
<td>
<p>NULL/string, an optional text to guide the model's style or continue a previous audio segment. The
prompt (https://platform.openai.com/docs/guides/speech-to-text/prompting) should match the audio language.</p>
</td></tr>
<tr><td><code id="audio_transcription_request_+3A_response_format">response_format</code></td>
<td>
<p>NULL/string, The format of the transcript output, in one of these options: json (default),
text, srt, verbose_json, or vtt.</p>
</td></tr>
<tr><td><code id="audio_transcription_request_+3A_temperature">temperature</code></td>
<td>
<p>NULL/double, the sampling temperature, between 0 and 1. Higher values like 0.8 will make the
output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model
will use log probability to automatically increase the temperature until certain thresholds are hit. 0 is default.</p>
</td></tr>
<tr><td><code id="audio_transcription_request_+3A_file_type">file_type</code></td>
<td>
<p>NULL/string mime type of file (e.g. &quot;audio/mpeg&quot;). If NULL (default), will be guess by
mime::guess_type() when needed.</p>
</td></tr>
<tr><td><code id="audio_transcription_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- audio_speech_request(
  "path/to/audio/file.mp3",
  "whisper-1",
  "en",
  response_format = "text"
)
if (!is_error(res_content)) {
  message(res_content)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='audio_translation_request'>API audio: translate audio file into English text</h2><span id='topic+audio_translation_request'></span>

<h3>Description</h3>

<p>Translates audio into English. To get more details, visit
https://platform.openai.com/docs/api-reference/audio/createTranslation
https://platform.openai.com/docs/guides/speech-to-text
</p>


<h3>Usage</h3>

<pre><code class='language-R'>audio_translation_request(
  file,
  model,
  prompt = NULL,
  response_format = NULL,
  temperature = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="audio_translation_request_+3A_file">file</code></td>
<td>
<p>string/raw, content of the input audio file or path to the input audio file to translate, in one of these
formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm</p>
</td></tr>
<tr><td><code id="audio_translation_request_+3A_model">model</code></td>
<td>
<p>string, ID of the model to use. Only 'whisper-1' is currently available.</p>
</td></tr>
<tr><td><code id="audio_translation_request_+3A_prompt">prompt</code></td>
<td>
<p>string, An optional text to guide the model's style or continue a previous audio segment. The prompt
should be in English.</p>
</td></tr>
<tr><td><code id="audio_translation_request_+3A_response_format">response_format</code></td>
<td>
<p>string, the format of the transcript output, in one of these options: json (default), text,
srt, verbose_json, or vtt.</p>
</td></tr>
<tr><td><code id="audio_translation_request_+3A_temperature">temperature</code></td>
<td>
<p>double, the sampling temperature, between 0 and 1. Higher values like 0.8 will make the output
more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use
log probability to automatically increase the temperature until certain thresholds are hit. 0 is default.</p>
</td></tr>
<tr><td><code id="audio_translation_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- audio_translation_request(
  "path/to/audio/file.mp3",
  "whisper-1",
  response_format = "text"
)
if (!is_error(res_content)) {
  message(res_content)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='browseable_audio'>Create browseable HTML audio</h2><span id='topic+browseable_audio'></span>

<h3>Description</h3>

<p>Create browseable HTML audio
</p>


<h3>Usage</h3>

<pre><code class='language-R'>browseable_audio(data, format = "mp3")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="browseable_audio_+3A_data">data</code></td>
<td>
<p>audio data</p>
</td></tr>
<tr><td><code id="browseable_audio_+3A_format">format</code></td>
<td>
<p>audio format</p>
</td></tr>
</table>


<h3>Value</h3>

<p>HTML audio
</p>

<hr>
<h2 id='chat_fetch_messages'>Fetch messages from response content</h2><span id='topic+chat_fetch_messages'></span>

<h3>Description</h3>

<p>Fetch messages (dialog data.frame with chat messages) from response content
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chat_fetch_messages(res_content)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chat_fetch_messages_+3A_res_content">res_content</code></td>
<td>
<p>response object returned by <a href="#topic+chat_request">chat_request</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Messages from response as dialog data.frame (see <a href="#topic+dialog_df">dialog_df</a>)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  question &lt;- dialog_df("hi")
  res_content &lt;- chat_request(
    messages = question,
    model = "gpt-3.5-turbo"
  )
  if (!is_error(res_content)) {
    answer &lt;- chat_fetch_messages(res_content)
    conversation &lt;- merge_dialog_df(question, answer)
    print(conversation)
  }

## End(Not run)

</code></pre>

<hr>
<h2 id='chat_request'>API chat: send create (chat) request</h2><span id='topic+chat_request'></span>

<h3>Description</h3>

<p>Creates a model response for the given chat conversation. To get more details, visit
https://platform.openai.com/docs/api-reference/chat/create
https://platform.openai.com/docs/guides/text-generation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>chat_request(
  messages,
  model,
  frequency_penalty = NULL,
  logit_bias = NULL,
  logprobs = NULL,
  top_logprobs = NULL,
  max_tokens = NULL,
  n = NULL,
  presence_penalty = NULL,
  response_format = NULL,
  seed = NULL,
  stop = NULL,
  stream = NULL,
  temperature = NULL,
  top_p = NULL,
  tools = NULL,
  tool_choice = NULL,
  user = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="chat_request_+3A_messages">messages</code></td>
<td>
<p>data.frame, data.frame with messages comprising the conversation so far</p>
</td></tr>
<tr><td><code id="chat_request_+3A_model">model</code></td>
<td>
<p>string, ID of the model to use. See the model endpoint compatibility table
https://platform.openai.com/docs/models/model-endpoint-compatibility
for details on which models work with the Chat API.</p>
</td></tr>
<tr><td><code id="chat_request_+3A_frequency_penalty">frequency_penalty</code></td>
<td>
<p>NULL/double, number between -2.0 and 2.0. Positive values penalize new tokens based on their
existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim. More at
https://platform.openai.com/docs/guides/text-generation/parameter-details</p>
</td></tr>
<tr><td><code id="chat_request_+3A_logit_bias">logit_bias</code></td>
<td>
<p>NULL/list, modify the likelihood of specified tokens appearing in the completion. Accepts a list
that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to
100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will
vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or
100 should result in a ban or exclusive selection of the relevant token. See https://platform.openai.com/tokenizer</p>
</td></tr>
<tr><td><code id="chat_request_+3A_logprobs">logprobs</code></td>
<td>
<p>NULL/flag, whether to return log probabilities of the output tokens or not. If true, returns the log
probabilities of each output token returned in the content of message. This option is currently not available on the
gpt-4-vision-preview model. Defaults to false.</p>
</td></tr>
<tr><td><code id="chat_request_+3A_top_logprobs">top_logprobs</code></td>
<td>
<p>NULL/int, an integer between 0 and 5 specifying the number of most likely tokens to return at
each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.</p>
</td></tr>
<tr><td><code id="chat_request_+3A_max_tokens">max_tokens</code></td>
<td>
<p>NULL/int, the maximum number of tokens to generate in the chat completion</p>
</td></tr>
<tr><td><code id="chat_request_+3A_n">n</code></td>
<td>
<p>NULL/int, how many chat completion choices to generate for each input message.</p>
</td></tr>
<tr><td><code id="chat_request_+3A_presence_penalty">presence_penalty</code></td>
<td>
<p>NULL/double, number between -2.0 and 2.0. Positive values penalize new tokens based on
whether they appear in the text so far, increasing the model's likelihood to talk about new topics. See
https://platform.openai.com/docs/guides/text-generation/parameter-details</p>
</td></tr>
<tr><td><code id="chat_request_+3A_response_format">response_format</code></td>
<td>
<p>NULL/list, an object specifying the format that the model must output. Compatible with
gpt-4-1106-preview and gpt-3.5-turbo-1106. Setting to list(type = &quot;json_object&quot;) enables JSON mode, which guarantees
the message the model generates is valid JSON. Important: when using JSON mode, you must also instruct the model to
produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of
whitespace until the generation reaches the token limit, resulting in a long-running and seemingly &quot;stuck&quot; request.
Also note that the message content may be partially cut off if finish_reason=&quot;length&quot;, which indicates the generation
exceeded max_tokens or the conversation exceeded the max context length. Text is default response format.</p>
</td></tr>
<tr><td><code id="chat_request_+3A_seed">seed</code></td>
<td>
<p>NULL/int, this feature is in Beta. If specified, our system will make a best effort to sample
deterministically, such that repeated requests with the same seed and parameters should return the same result.
Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes
in the backend.</p>
</td></tr>
<tr><td><code id="chat_request_+3A_stop">stop</code></td>
<td>
<p>NULL/character vector, up to 4 sequences where the API will stop generating further tokens.</p>
</td></tr>
<tr><td><code id="chat_request_+3A_stream">stream</code></td>
<td>
<p>NULL/flag, if set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as
data-only server-sent events as they become available, with the stream terminated by a data: [DONE] message.
Defaults to false</p>
</td></tr>
<tr><td><code id="chat_request_+3A_temperature">temperature</code></td>
<td>
<p>NULL/double, what sampling temperature to use, between 0 and 2. Higher values like 0.8 will make
the output more random, while lower values like 0.2 will make it more focused and deterministic.</p>
</td></tr>
<tr><td><code id="chat_request_+3A_top_p">top_p</code></td>
<td>
<p>NULL/double, an alternative to sampling with temperature, called nucleus sampling, where the model
considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10
probability mass are considered. We generally recommend altering this or temperature but not both. Defaults to 1</p>
</td></tr>
<tr><td><code id="chat_request_+3A_tools">tools</code></td>
<td>
<p>NULL/list, a &quot;list&quot; of tools the model may call. Currently, only functions are supported as a tool.
Use this to provide a list of functions the model may generate JSON inputs for. Example value:
</p>
<pre>
list(
  # string (required), the type of the tool. Currently, only
  # 'function' is supported
  type = "function",
  
  # list (required)
  function = list(
    # string (optional)
    description = "some description",

    # string (required), the name of the function to be called.
    # Must be a-z, A-Z, 0-9, or contain underscores and dashes,
    # with a maximum length of 64
    name = "functionname",
    
    # list (optional), the parameters the functions accepts,
    # described as a JSON Schema object. Omitting parameters
    # defines a function with an empty parameter list.
    parameters = list()
  )
)
</pre></td></tr>
<tr><td><code id="chat_request_+3A_tool_choice">tool_choice</code></td>
<td>
<p>NULL/string/list, controls which (if any) function is called by the model. 'none' means the model
will not call a function and instead generates a message. 'auto' means the model can pick between generating a
message or calling a function. Specifying a particular function via list
'list(type = &quot;function&quot;, function&quot;: list(name: &quot;my_function&quot;))' forces the model to call that function. 'none' is the
default when no functions are present, 'auto' is the default if functions are present.</p>
</td></tr>
<tr><td><code id="chat_request_+3A_user">user</code></td>
<td>
<p>NULL/string, a unique identifier representing your end-user, which can help OpenAI to monitor and detect
abuse. See https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids</p>
</td></tr>
<tr><td><code id="chat_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  question &lt;- dialog_df("hi")
  res_content &lt;- chat_request(
    messages = question,
    model = "gpt-3.5-turbo"
  )
  if (!is_error(res_content)) {
    answer &lt;- chat_fetch_messages(res_content)
    conversation &lt;- merge_dialog_df(question, answer)
    print(conversation)
  }

## End(Not run)

</code></pre>

<hr>
<h2 id='completions_fetch_text'>Fetch completions text from response content</h2><span id='topic+completions_fetch_text'></span>

<h3>Description</h3>

<p>Fetch completions text from response content (<a href="#topic+completions_request">completions_request</a>)
as dialog data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>completions_fetch_text(res_content, role = "ai", ltrim = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="completions_fetch_text_+3A_res_content">res_content</code></td>
<td>
<p>response object returned by <a href="#topic+completions_request">completions_request</a></p>
</td></tr>
<tr><td><code id="completions_fetch_text_+3A_role">role</code></td>
<td>
<p>string, dialog role (phrase owner)</p>
</td></tr>
<tr><td><code id="completions_fetch_text_+3A_ltrim">ltrim</code></td>
<td>
<p>flag, trim left white space character(s) from text</p>
</td></tr>
</table>


<h3>Value</h3>

<p>dialog data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  prompt &lt;- "x=1, y=2, z=x*y, z=?"
  res_content &lt;- completions_request(
    model = "text-davinci-003",
    prompt = prompt
  )
  if (!is_error(res_content)) {
    answer &lt;- completions_fetch_text(res_content)
    print(answer)
  }

## End(Not run)

</code></pre>

<hr>
<h2 id='completions_request'>API completions: create request</h2><span id='topic+completions_request'></span>

<h3>Description</h3>

<p>To get more details, visit https://platform.openai.com/docs/api-reference/completions/create
</p>


<h3>Usage</h3>

<pre><code class='language-R'>completions_request(
  model,
  prompt,
  suffix = NULL,
  max_tokens = NULL,
  temperature = NULL,
  top_p = NULL,
  n = NULL,
  stream = NULL,
  logprobs = NULL,
  echo = NULL,
  stop = NULL,
  presence_penalty = NULL,
  frequency_penalty = NULL,
  best_of = NULL,
  user = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="completions_request_+3A_model">model</code></td>
<td>
<p>string, ID of the model to use. You can use the list models
(https://platform.openai.com/docs/api-reference/models/list)
API to see all of your available models, or see our model overview
(https://platform.openai.com/docs/models/overview)
for descriptions of them.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_prompt">prompt</code></td>
<td>
<p>API endpoint parameter</p>
</td></tr>
<tr><td><code id="completions_request_+3A_suffix">suffix</code></td>
<td>
<p>string/NULL, the suffix that comes after a completion
of inserted text.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_max_tokens">max_tokens</code></td>
<td>
<p>integer, the maximum number of tokens
(https://platform.openai.com/tokenizer) to generate
in the completion. The token count of your prompt plus max_tokens cannot
exceed the model's context length.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_temperature">temperature</code></td>
<td>
<p>double, what sampling temperature to use, between 0 and 2.
Higher values like 0.8 will make the output more random,
while lower values like 0.2 will make it more focused and deterministic.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_top_p">top_p</code></td>
<td>
<p>double, an alternative to sampling with temperature,
called nucleus sampling, where the model considers the results of the tokens
with top_p probability mass. So 0.1 means only the tokens comprising
the top 10% probability mass are considered.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_n">n</code></td>
<td>
<p>integer, How many completions to generate for each prompt.
Note: Because this parameter generates many completions,
it can quickly consume your token quota. Use carefully
and ensure that you have reasonable settings for 'max_tokens' and 'stop'.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_stream">stream</code></td>
<td>
<p>flag, Whether to stream back partial progress. If set,
tokens will be sent as data-only server-sent events as they become available,
with the stream terminated by a data: '[DONE]' message.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_logprobs">logprobs</code></td>
<td>
<p>integer, Include the log probabilities on the logprobs most
likely tokens, as well the chosen tokens. For example, if logprobs is 5,
the API will return a list of the 5 most likely tokens. The API will always
return the logprob of the sampled token, so there may be up to logprobs+1
elements in the response.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_echo">echo</code></td>
<td>
<p>logical, echo back the prompt in addition to the completion</p>
</td></tr>
<tr><td><code id="completions_request_+3A_stop">stop</code></td>
<td>
<p>string or array, up to 4 sequences where the API will stop
generating further tokens. The returned text will not contain the stop sequence.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_presence_penalty">presence_penalty</code></td>
<td>
<p>double, Number between -2.0 and 2.0.
Positive values penalize new tokens based on whether they appear in the text
so far, increasing the model's likelihood to talk about new topics.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_frequency_penalty">frequency_penalty</code></td>
<td>
<p>double, Number between -2.0 and 2.0.
Positive values penalize new tokens based on their existing frequency
in the text so far, decreasing the model's likelihood to repeat the same line
verbatim.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_best_of">best_of</code></td>
<td>
<p>integer, Generates best_of completions server-side and returns
the &quot;best&quot; (the one with the highest log probability per token). Results
cannot be streamed.
When used with n, best_of controls the number of candidate completions
and n specifies how many to return  best_of must be greater than n.</p>
</td></tr>
<tr><td><code id="completions_request_+3A_user">user</code></td>
<td>
<p>string, A unique identifier representing your end-user,
which can help OpenAI to monitor and detect abuse</p>
</td></tr>
<tr><td><code id="completions_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
  prompt &lt;- "x=1, y=2, z=x*y, z=?"
  res_content &lt;- completions_request(
    model = "text-davinci-003",
    prompt = prompt
  )
  if (!is_error(res_content)) {
    answer &lt;- completions_fetch_text(res_content)
    print(answer)
  }

## End(Not run)

</code></pre>

<hr>
<h2 id='csv_to_dialog_df'>Read csv file as dialog data.frame</h2><span id='topic+csv_to_dialog_df'></span>

<h3>Description</h3>

<p>Read csv file as dialog data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>csv_to_dialog_df(datapath)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="csv_to_dialog_df_+3A_datapath">datapath</code></td>
<td>
<p>string, csv file path</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Content of the input csv file as dialog data.frame,
SimpleError when an error occurs
</p>

<hr>
<h2 id='df_col_dt_format'>Replace unix timestamp column(s) to formated dt string</h2><span id='topic+df_col_dt_format'></span>

<h3>Description</h3>

<p>Replace unix timestamp column(s) to formated dt string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_col_dt_format(
  df,
  col,
  format = "%Y-%m-%d %H:%M:%S",
  tz = "",
  on_missing_col = "warn"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df_col_dt_format_+3A_df">df</code></td>
<td>
<p>data.frame, input data.frame</p>
</td></tr>
<tr><td><code id="df_col_dt_format_+3A_col">col</code></td>
<td>
<p>character vector, column names of the df that will be modified</p>
</td></tr>
<tr><td><code id="df_col_dt_format_+3A_format">format</code></td>
<td>
<p>A character string.  The default for the <code>format</code>
methods is
<code>"%Y-%m-%d %H:%M:%S"</code> if any element has a time
component which is not midnight, and <code>"%Y-%m-%d"</code>
otherwise.  If <code><a href="base.html#topic+options">options</a>("digits.secs")</code> is set, up to
the specified number of digits will be printed for seconds.</p>
</td></tr>
<tr><td><code id="df_col_dt_format_+3A_tz">tz</code></td>
<td>
<p>A character string specifying the time zone to be used for
the conversion.  System-specific (see <code><a href="base.html#topic+as.POSIXlt">as.POSIXlt</a></code>), but
<code>""</code> is the current time zone, and <code>"GMT"</code> is UTC.
Invalid values are most commonly treated as UTC, on some platforms with
a warning.</p>
</td></tr>
<tr><td><code id="df_col_dt_format_+3A_on_missing_col">on_missing_col</code></td>
<td>
<p>string, behavior for missing column(s):
&quot;warn&quot; - log warning, &quot;skip&quot; - skip missing column(s), &quot;stop&quot; - throw error</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Modified input data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  x = c("a", "b"),
  dt = c(1687868601, 1688417643)
)
df_col_dt_format(df, "dt")
df_col_dt_format(df, "dt", "%H:%M")

</code></pre>

<hr>
<h2 id='df_col_obj_implode'>Change to string nested lists in a given data.frame</h2><span id='topic+df_col_obj_implode'></span>

<h3>Description</h3>

<p>Change to string nested lists in a given data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_col_obj_implode(
  df,
  col,
  obj_prop = NULL,
  nested = TRUE,
  cell_header = "",
  objs_glue = "----\n",
  cell_footer = "",
  obj_header = "",
  props_glue = "\n",
  obj_footer = "",
  prop_fmt = "%s: %s",
  null_prop_str = "[null]",
  on_missing_col = "warn"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df_col_obj_implode_+3A_df">df</code></td>
<td>
<p>data.frame, input data.frame</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_col">col</code></td>
<td>
<p>character vector, df column names containing objects</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_obj_prop">obj_prop</code></td>
<td>
<p>NULL/character vector, object properties (NULL means all)</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_nested">nested</code></td>
<td>
<p>flag, whether the rows of the columns contain multiple objects</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_cell_header">cell_header</code></td>
<td>
<p>string/NULL, cell header</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_objs_glue">objs_glue</code></td>
<td>
<p>string, how to combine objects</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_cell_footer">cell_footer</code></td>
<td>
<p>string/NULL, cell footer</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_obj_header">obj_header</code></td>
<td>
<p>string/NULL, object header</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_props_glue">props_glue</code></td>
<td>
<p>string, how to combine properties</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_obj_footer">obj_footer</code></td>
<td>
<p>string/NULL, object footer</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_prop_fmt">prop_fmt</code></td>
<td>
<p>string, sprintf fmt parameter with two '%s' fields (property</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_null_prop_str">null_prop_str</code></td>
<td>
<p>string, value for NULL object property
name, value)</p>
</td></tr>
<tr><td><code id="df_col_obj_implode_+3A_on_missing_col">on_missing_col</code></td>
<td>
<p>string, behavior for missing column(s):
&quot;warn&quot; - log warning, &quot;skip&quot; - skip missing column(s), &quot;stop&quot; - throw error</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Modified input data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- as.data.frame(do.call(cbind, list(
  a = list(list(x = 1, y = 2), list(x = 3, y = 4)),
  b = list("z", "z")
)))
df_col_obj_implode(df, "a", c("x", "y"), nested = FALSE, props_glue = ", ")

</code></pre>

<hr>
<h2 id='df_exclude_col'>Remove columns from data.frame</h2><span id='topic+df_exclude_col'></span>

<h3>Description</h3>

<p>Remove columns from data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_exclude_col(df, col, on_missing_col = "warn")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df_exclude_col_+3A_df">df</code></td>
<td>
<p>data.frame, input data.frame</p>
</td></tr>
<tr><td><code id="df_exclude_col_+3A_col">col</code></td>
<td>
<p>character vector, column name(s) to be deleted</p>
</td></tr>
<tr><td><code id="df_exclude_col_+3A_on_missing_col">on_missing_col</code></td>
<td>
<p>string, behavior for missing column(s):
&quot;warn&quot; - log warning, &quot;skip&quot; - skip missing column(s), &quot;stop&quot; - throw error</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Modified input data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(a = 1:3, b = 1:3, c = 1:3)
df_exclude_col(df, "b")
df_exclude_col(df, c("a", "c"))

</code></pre>

<hr>
<h2 id='df_null_replace'>Replace all NULL values in given data.frame</h2><span id='topic+df_null_replace'></span>

<h3>Description</h3>

<p>Replace all NULL values in given data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_null_replace(df, replacement = "")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df_null_replace_+3A_df">df</code></td>
<td>
<p>data.frame, input data.frame</p>
</td></tr>
<tr><td><code id="df_null_replace_+3A_replacement">replacement</code></td>
<td>
<p>string, replacement for NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Modified input data.frame
</p>

<hr>
<h2 id='df_order_by_col'>Sort data.frame by column name</h2><span id='topic+df_order_by_col'></span>

<h3>Description</h3>

<p>Sort data.frame by column name
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_order_by_col(df, col, decreasing = FALSE, on_missing_col = "warn")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df_order_by_col_+3A_df">df</code></td>
<td>
<p>data.frame, input data.frame</p>
</td></tr>
<tr><td><code id="df_order_by_col_+3A_col">col</code></td>
<td>
<p>string, column name as sort source</p>
</td></tr>
<tr><td><code id="df_order_by_col_+3A_decreasing">decreasing</code></td>
<td>
<p>flag, should the sort order be increasing or decreasing?</p>
</td></tr>
<tr><td><code id="df_order_by_col_+3A_on_missing_col">on_missing_col</code></td>
<td>
<p>string, behavior for missing column(s):
&quot;warn&quot; - log warning, &quot;skip&quot; - skip missing column(s), &quot;stop&quot; - throw error</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Modified input data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df &lt;- data.frame(
  a = c("a", "b", "c"),
  b = c(1, 3, 2),
  c = c(3, 2, 1)
)
df_order_by_col(df, "b", decreasing = TRUE)
df_order_by_col(df, "c")

</code></pre>

<hr>
<h2 id='df_roxygen_tpl'>df roxygen template</h2><span id='topic+df_roxygen_tpl'></span>

<h3>Description</h3>

<p>df roxygen template
</p>


<h3>Usage</h3>

<pre><code class='language-R'>df_roxygen_tpl(df, on_missing_col)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="df_roxygen_tpl_+3A_df">df</code></td>
<td>
<p>data.frame, input data.frame</p>
</td></tr>
<tr><td><code id="df_roxygen_tpl_+3A_on_missing_col">on_missing_col</code></td>
<td>
<p>string, behavior for missing column(s):
&quot;warn&quot; - log warning, &quot;skip&quot; - skip missing column(s), &quot;stop&quot; - throw error</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Modified input data.frame
</p>

<hr>
<h2 id='dialog_df'>Create dialog data.frame</h2><span id='topic+dialog_df'></span>

<h3>Description</h3>

<p>Create dialog data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dialog_df(content, role = "user", finish_reason = "stop")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dialog_df_+3A_content">content</code></td>
<td>
<p>string, message content</p>
</td></tr>
<tr><td><code id="dialog_df_+3A_role">role</code></td>
<td>
<p>string, message role (&quot;owner&quot;)</p>
</td></tr>
<tr><td><code id="dialog_df_+3A_finish_reason">finish_reason</code></td>
<td>
<p>see https://platform.openai.com/docs/guides/gpt/chat-completions-response-format</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A one-row data.frame with columns: 'content', 'role' and 'finish_reason'
</p>


<h3>Examples</h3>

<pre><code class='language-R'>dialog_df("some text message")
dialog_df("some another text message", role = "assistant")

</code></pre>

<hr>
<h2 id='dialog_df_to_csv'>Save dialog data.frame as csv file</h2><span id='topic+dialog_df_to_csv'></span>

<h3>Description</h3>

<p>Save dialog data.frame as csv file
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dialog_df_to_csv(dialog_df, file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dialog_df_to_csv_+3A_dialog_df">dialog_df</code></td>
<td>
<p>data.frame, dialog data.frame to save in csv file</p>
</td></tr>
<tr><td><code id="dialog_df_to_csv_+3A_file">file</code></td>
<td>
<p>string, csv file path</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="utils.html#topic+write.table">write.table</a> return value or SimpleError
</p>

<hr>
<h2 id='embeddings_create_request'>API embeddings: create embeddings</h2><span id='topic+embeddings_create_request'></span>

<h3>Description</h3>

<p>Creates an embedding vector representing the input text. To get more details, visit
https://platform.openai.com/docs/api-reference/embeddings/create
https://platform.openai.com/docs/guides/embeddings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embeddings_create_request(
  input,
  model,
  encoding_format = NULL,
  user = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embeddings_create_request_+3A_input">input</code></td>
<td>
<p>character vector, input text to embed, encoded as a string or array of tokens. To embed multiple inputs
in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input
tokens for the model (8192 tokens for text-embedding-ada-002), cannot be an empty string, and any array must be 2048
dimensions or less.</p>
</td></tr>
<tr><td><code id="embeddings_create_request_+3A_model">model</code></td>
<td>
<p>string, ID of the model to use. You can use the list models API
(https://platform.openai.com/docs/api-reference/models/list) to see all of your available models, or see our model
overview (https://platform.openai.com/docs/models/overview) for descriptions of them.</p>
</td></tr>
<tr><td><code id="embeddings_create_request_+3A_encoding_format">encoding_format</code></td>
<td>
<p>string, he format to return the embeddings in. Can be either float (default) or base64.</p>
</td></tr>
<tr><td><code id="embeddings_create_request_+3A_user">user</code></td>
<td>
<p>string, a unique identifier representing your end-user, which can help OpenAI to monitor and detect
abuse. To learn more visit https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids</p>
</td></tr>
<tr><td><code id="embeddings_create_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='embeddings_object_request'>API embeddings: get embedding object</h2><span id='topic+embeddings_object_request'></span>

<h3>Description</h3>

<p>Represents an embedding vector returned by embedding endpoint. To get more details, visit
https://platform.openai.com/docs/api-reference/embeddings/object
https://platform.openai.com/docs/guides/embeddings
</p>


<h3>Usage</h3>

<pre><code class='language-R'>embeddings_object_request(index, embedding, object, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="embeddings_object_request_+3A_index">index</code></td>
<td>
<p>integer, The index of the embedding in the list of embeddings</p>
</td></tr>
<tr><td><code id="embeddings_object_request_+3A_embedding">embedding</code></td>
<td>
<p>double vector, the embedding vector, which is a &quot;list of floats&quot;. The length of vector depends on
the model as listed in the embedding guide.</p>
</td></tr>
<tr><td><code id="embeddings_object_request_+3A_object">object</code></td>
<td>
<p>string, the object type, which is always &quot;embedding&quot;</p>
</td></tr>
<tr><td><code id="embeddings_object_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='feedback'>Feedback - ask chat and receive reply</h2><span id='topic+feedback'></span>

<h3>Description</h3>

<p>Simple <a href="#topic+chat_request">chat_request</a> wrapper - send text to chat and get response.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>feedback(question, model = "gpt-3.5-turbo", max_tokens = NULL, print = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="feedback_+3A_question">question</code></td>
<td>
<p>string, question text</p>
</td></tr>
<tr><td><code id="feedback_+3A_model">model</code></td>
<td>
<p>string, ID of the model to use. See the model endpoint compatibility table
https://platform.openai.com/docs/models/model-endpoint-compatibility
for details on which models work with the Chat API.</p>
</td></tr>
<tr><td><code id="feedback_+3A_max_tokens">max_tokens</code></td>
<td>
<p>NULL/int, the maximum number of tokens to generate in the chat completion</p>
</td></tr>
<tr><td><code id="feedback_+3A_print">print</code></td>
<td>
<p>flag, If TRUE, print the answer on the console</p>
</td></tr>
</table>


<h3>Value</h3>

<p>string, chat answer
</p>

<hr>
<h2 id='files_delete_request'>API files: delete file request</h2><span id='topic+files_delete_request'></span>

<h3>Description</h3>

<p>Delete a file. To get more details, visit https://platform.openai.com/docs/api-reference/files/delete
</p>


<h3>Usage</h3>

<pre><code class='language-R'>files_delete_request(file_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="files_delete_request_+3A_file_id">file_id</code></td>
<td>
<p>string, id of the uploaded file</p>
</td></tr>
<tr><td><code id="files_delete_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='files_fetch_list'>Extract files list as data.frame from response object</h2><span id='topic+files_fetch_list'></span>

<h3>Description</h3>

<p>Extract files list as data.frame from response object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>files_fetch_list(res_content)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="files_fetch_list_+3A_res_content">res_content</code></td>
<td>
<p>response object returned by <a href="#topic+files_list_request">files_list_request</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>Files list as data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- files_list_request()
if (!is_error(res_content)) {
  files_list_df &lt;- files_fetch_list(res_content)
  print(files_list_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='files_list_request'>API files: get list request</h2><span id='topic+files_list_request'></span>

<h3>Description</h3>

<p>Returns a list of files that belong to the user's organization. To get more details, visit:
https://platform.openai.com/docs/api-reference/files/list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>files_list_request(purpose = NULL, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="files_list_request_+3A_purpose">purpose</code></td>
<td>
<p>NULL/string, only return files with the given purpose</p>
</td></tr>
<tr><td><code id="files_list_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- files_list_request()
if (!is_error(res_content)) {
  files_list_df &lt;- files_fetch_list(res_content)
  print(files_list_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='files_retrieve_content_request'>API files: retrieve content request</h2><span id='topic+files_retrieve_content_request'></span>

<h3>Description</h3>

<p>To get more details, visit https://platform.openai.com/docs/api-reference/files/retrieve-content
</p>


<h3>Usage</h3>

<pre><code class='language-R'>files_retrieve_content_request(file_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="files_retrieve_content_request_+3A_file_id">file_id</code></td>
<td>
<p>string, id of the uploaded file</p>
</td></tr>
<tr><td><code id="files_retrieve_content_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- files_retrieve_content_request("some-file-id")
if (!is_error(res_content)) {
  writeBin(res_content, "some-file.jsonl")
}

## End(Not run)

</code></pre>

<hr>
<h2 id='files_retrieve_request'>API files: retrieve file request</h2><span id='topic+files_retrieve_request'></span>

<h3>Description</h3>

<p>Returns information about a specific file. To get more details, visit: 
https://platform.openai.com/docs/api-reference/files/retrieve
</p>


<h3>Usage</h3>

<pre><code class='language-R'>files_retrieve_request(file_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="files_retrieve_request_+3A_file_id">file_id</code></td>
<td>
<p>string, id of the uploaded file</p>
</td></tr>
<tr><td><code id="files_retrieve_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='files_roxygen_tpl'>API files: roxygen template</h2><span id='topic+files_roxygen_tpl'></span>

<h3>Description</h3>

<p>API files: roxygen template
</p>


<h3>Usage</h3>

<pre><code class='language-R'>files_roxygen_tpl(api_key, file_id)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="files_roxygen_tpl_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
<tr><td><code id="files_roxygen_tpl_+3A_file_id">file_id</code></td>
<td>
<p>string, id of the uploaded file</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='files_upload_request'>API files: upload request</h2><span id='topic+files_upload_request'></span>

<h3>Description</h3>

<p>Upload a file that can be used across various endpoints. The size of all the files uploaded by one organization can
be up to 100 GB. The size of individual files can be a maximum of 512 MB or 2 million tokens for Assistants. See the
Assistants Tools guide (https://platform.openai.com/docs/assistants/tools) to learn more about the types of files
supported. The Fine-tuning API only supports .jsonl files. To get more details, visit:
https://platform.openai.com/docs/api-reference/files/upload
</p>


<h3>Usage</h3>

<pre><code class='language-R'>files_upload_request(file, purpose, file_type = NULL, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="files_upload_request_+3A_file">file</code></td>
<td>
<p>string/raw, path or content of the JSON Lines file to be uploaded</p>
</td></tr>
<tr><td><code id="files_upload_request_+3A_purpose">purpose</code></td>
<td>
<p>string, the intended purpose of the uploaded documents. Use &quot;fine-tune&quot; for Fine-tuning.</p>
</td></tr>
<tr><td><code id="files_upload_request_+3A_file_type">file_type</code></td>
<td>
<p>NULL/string, mime type of 'file'. See <a href="#topic+api_upload_file">api_upload_file</a></p>
</td></tr>
<tr><td><code id="files_upload_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='fine_tuning_cancel_job_request'>API fine-tuning: cancel fine-tuning job request</h2><span id='topic+fine_tuning_cancel_job_request'></span>

<h3>Description</h3>

<p>Immediately cancel a fine-tune job. To get more details, visit
https://platform.openai.com/docs/guides/fine-tuning
https://platform.openai.com/docs/api-reference/fine-tuning/cancel
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fine_tuning_cancel_job_request(fine_tuning_job_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fine_tuning_cancel_job_request_+3A_fine_tuning_job_id">fine_tuning_job_id</code></td>
<td>
<p>string, the ID of the fine-tuning job to cancel</p>
</td></tr>
<tr><td><code id="fine_tuning_cancel_job_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- fine_tuning_cancel_job_request("job-id")
if (!is_error(res_content)) {
  message("job canceled")
}

## End(Not run)

</code></pre>

<hr>
<h2 id='fine_tuning_create_job_request'>API fine-tuning: create job (model) request</h2><span id='topic+fine_tuning_create_job_request'></span>

<h3>Description</h3>

<p>Creates a fine-tuning job which begins the process of creating a new model from a given dataset. To get more details,
visit https://platform.openai.com/docs/guides/fine-tuning
https://platform.openai.com/docs/api-reference/fine-tuning/create
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fine_tuning_create_job_request(
  model,
  training_file,
  hyperparameters = NULL,
  suffix = NULL,
  validation_file = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fine_tuning_create_job_request_+3A_model">model</code></td>
<td>
<p>string, the name of the base model to fine-tune. You can select one of the supported models:
gpt-3.5-turbo-1106 (recommended), gpt-3.5-turbo-0613, babbage-002, davinci-002, gpt-4-0613 (experimental)</p>
</td></tr>
<tr><td><code id="fine_tuning_create_job_request_+3A_training_file">training_file</code></td>
<td>
<p>string, the ID of an uploaded file that contains training data. See <a href="#topic+files_upload_request">files_upload_request</a>.</p>
</td></tr>
<tr><td><code id="fine_tuning_create_job_request_+3A_hyperparameters">hyperparameters</code></td>
<td>
<p>list/NULL, the hyperparameters used for the fine-tuning job.
'hyperparameters$batch_size' string/integer/NULL defaults to &quot;auto&quot;, number of examples in each batch. A larger batch
size means that model parameters are updated less frequently, but with lower variance.
'hyperparameters$learning_rate_multiplier' string/number/NULL defaults to &quot;auto&quot;, scaling factor for the learning
rate. A smaller learning rate may be useful to avoid overfitting.
'hyperparameters$n_epochs' string/integer/NULL, defaults to &quot;auto&quot;, the number of epochs to train the model for. An
epoch refers to one full cycle through the training dataset.</p>
</td></tr>
<tr><td><code id="fine_tuning_create_job_request_+3A_suffix">suffix</code></td>
<td>
<p>string/NULL, A string of up to 18 characters that will be added to your fine-tuned model name. For
example, a suffix of &quot;custom-model-name&quot; would produce a model name like 
ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel</p>
</td></tr>
<tr><td><code id="fine_tuning_create_job_request_+3A_validation_file">validation_file</code></td>
<td>
<p>string/NULL, the ID of an uploaded file that contains validation data. If you provide this
file, the data is used to generate validation metrics periodically during fine-tuning. These metrics can be viewed in
the fine-tuning results file. The same data should not be present in both train and validation files. Your dataset
must be formatted as a JSONL file. You must upload your file with the purpose fine-tune.</p>
</td></tr>
<tr><td><code id="fine_tuning_create_job_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='fine_tuning_events_list_request'>API fine-tuning: list events request</h2><span id='topic+fine_tuning_events_list_request'></span>

<h3>Description</h3>

<p>Get status updates for a fine-tuning job. To get more details, visit
https://platform.openai.com/docs/guides/fine-tuning
https://platform.openai.com/docs/api-reference/fine-tuning/list-events
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fine_tuning_events_list_request(
  fine_tuning_job_id,
  after = NULL,
  limit = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fine_tuning_events_list_request_+3A_fine_tuning_job_id">fine_tuning_job_id</code></td>
<td>
<p>string, the ID of the fine-tuning job to get events for</p>
</td></tr>
<tr><td><code id="fine_tuning_events_list_request_+3A_after">after</code></td>
<td>
<p>string/NULL, identifier for the last event from the previous pagination request.</p>
</td></tr>
<tr><td><code id="fine_tuning_events_list_request_+3A_limit">limit</code></td>
<td>
<p>integer/NULL, number of events to retrieve (defaults to 20)</p>
</td></tr>
<tr><td><code id="fine_tuning_events_list_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- fine_tuning_events_list_request("job-id")
if (!is_error(res_content)) {
  fine_tuning_events_df &lt;- fine_tuning_fetch_events_list(res_content)
  print(fine_tuning_events_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='fine_tuning_fetch_events_list'>API fine-tuning: job list from response object</h2><span id='topic+fine_tuning_fetch_events_list'></span>

<h3>Description</h3>

<p>Extract fine-tuning job list as data.frame from response object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fine_tuning_fetch_events_list(res_content)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fine_tuning_fetch_events_list_+3A_res_content">res_content</code></td>
<td>
<p>response object returned by <a href="#topic+fine_tuning_events_list_request">fine_tuning_events_list_request</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>fine-tuning events list as data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- fine_tuning_events_list_request("job-id")
if (!is_error(res_content)) {
  fine_tuning_events_df &lt;- fine_tuning_fetch_events_list(res_content)
  print(fine_tuning_events_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='fine_tuning_fetch_jobs_list'>API fine-tuning: extract fine-tuning jobs list from response object</h2><span id='topic+fine_tuning_fetch_jobs_list'></span>

<h3>Description</h3>

<p>Extract fine-tuning jobs list as data.frame from response object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fine_tuning_fetch_jobs_list(res_content)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fine_tuning_fetch_jobs_list_+3A_res_content">res_content</code></td>
<td>
<p>response object returned by <a href="#topic+fine_tuning_jobs_list_request">fine_tuning_jobs_list_request</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>fine-tuning list models as data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- fine_tuning_jobs_list_request()
if (!is_error(res_content)) {
  fine_tuning_jobs_df &lt;- fine_tuning_fetch_jobs_list(res_content)
  print(fine_tuning_jobs_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='fine_tuning_fetch_retrived_job'>API fine-tuning: fetch retrived job object from response object</h2><span id='topic+fine_tuning_fetch_retrived_job'></span>

<h3>Description</h3>

<p>Extract fine-tuning job object from response object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fine_tuning_fetch_retrived_job(res_content)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fine_tuning_fetch_retrived_job_+3A_res_content">res_content</code></td>
<td>
<p>response object returned by <a href="#topic+fine_tuning_retrive_job_request">fine_tuning_retrive_job_request</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>fine-tuning job object
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- fine_tuning_retrive_job_request("job-id")
if (!is_error(res_content)) {
  fine_tuning_events_df &lt;- fine_tuning_fetch_events_list(res_content)
  print(fine_tuning_events_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='fine_tuning_jobs_list_request'>API fine-tuning: list jobs request</h2><span id='topic+fine_tuning_jobs_list_request'></span>

<h3>Description</h3>

<p>List your organization's fine-tuning jobs. To get more details, visit
https://platform.openai.com/docs/guides/fine-tuning
https://platform.openai.com/docs/api-reference/fine-tuning/list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fine_tuning_jobs_list_request(
  after = NULL,
  limit = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fine_tuning_jobs_list_request_+3A_after">after</code></td>
<td>
<p>NULL/string, identifier for the last job from the previous pagination request</p>
</td></tr>
<tr><td><code id="fine_tuning_jobs_list_request_+3A_limit">limit</code></td>
<td>
<p>NULL/integer, number of fine-tuning jobs to retrieve (default 20)</p>
</td></tr>
<tr><td><code id="fine_tuning_jobs_list_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- fine_tuning_jobs_list_request()
if (!is_error(res_content)) {
  fine_tuning_jobs_df &lt;- fine_tuning_fetch_jobs_list(res_content)
  print(fine_tuning_jobs_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='fine_tuning_retrive_job_request'>API fine-tuning: retrieve fine-tuning job request</h2><span id='topic+fine_tuning_retrive_job_request'></span>

<h3>Description</h3>

<p>Get info about a fine-tuning job. To get more details, visit
https://platform.openai.com/docs/guides/fine-tuning
https://platform.openai.com/docs/api-reference/fine-tuning/retrieve
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fine_tuning_retrive_job_request(fine_tuning_job_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fine_tuning_retrive_job_request_+3A_fine_tuning_job_id">fine_tuning_job_id</code></td>
<td>
<p>string, the ID of the fine-tuning job to get events for</p>
</td></tr>
<tr><td><code id="fine_tuning_retrive_job_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- fine_tuning_retrive_job_request("job-id")
if (!is_error(res_content)) {
  fine_tuning_events_df &lt;- fine_tuning_fetch_events_list(res_content)
  print(fine_tuning_events_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='images_edit_request'>API images: edit request</h2><span id='topic+images_edit_request'></span>

<h3>Description</h3>

<p>Creates an edited or extended image given an original image and a prompt. To get more details, visit
https://platform.openai.com/docs/api-reference/images/edits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>images_edit_request(
  image,
  prompt,
  mask = NULL,
  model = NULL,
  n = NULL,
  size = NULL,
  response_format = NULL,
  user = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="images_edit_request_+3A_image">image</code></td>
<td>
<p>string/raw, the image to edit. Must be a valid PNG file, less than 4MB, and square. If mask is not
provided, image must have transparency, which will be used as the mask.</p>
</td></tr>
<tr><td><code id="images_edit_request_+3A_prompt">prompt</code></td>
<td>
<p>string, a text description of the desired image(s). The maximum length is 1000 characters.</p>
</td></tr>
<tr><td><code id="images_edit_request_+3A_mask">mask</code></td>
<td>
<p>NULL/string/raw, an additional image whose fully transparent areas (e.g. where alpha is zero) indicate
where image should be edited. Must be a valid PNG file, less than 4MB, and have the same dimensions as 'image'.</p>
</td></tr>
<tr><td><code id="images_edit_request_+3A_model">model</code></td>
<td>
<p>NULL/string, the model to use for image generation. Only dall-e-2 is supported at this time.</p>
</td></tr>
<tr><td><code id="images_edit_request_+3A_n">n</code></td>
<td>
<p>NULL/int, the number of images to generate. Must be between 1 (default) and 10.</p>
</td></tr>
<tr><td><code id="images_edit_request_+3A_size">size</code></td>
<td>
<p>NULL/string, the size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 (default).</p>
</td></tr>
<tr><td><code id="images_edit_request_+3A_response_format">response_format</code></td>
<td>
<p>NULL/string, the format in which the generated images are returned. Must be one of &quot;url&quot; or
&quot;b64_json&quot;.</p>
</td></tr>
<tr><td><code id="images_edit_request_+3A_user">user</code></td>
<td>
<p>string a unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.</p>
</td></tr>
<tr><td><code id="images_edit_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='images_fech_set'>Fetch image set from response content</h2><span id='topic+images_fech_set'></span>

<h3>Description</h3>

<p>To get more details, visit https://platform.openai.com/docs/api-reference/images/create
https://platform.openai.com/docs/api-reference/images/edits
</p>


<h3>Usage</h3>

<pre><code class='language-R'>images_fech_set(res_content, prompt = NULL, size = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="images_fech_set_+3A_res_content">res_content</code></td>
<td>
<p>response object returned by <a href="#topic+images_generator_request">images_generator_request</a> or <a href="#topic+images_edit_request">images_edit_request</a></p>
</td></tr>
<tr><td><code id="images_fech_set_+3A_prompt">prompt</code></td>
<td>
<p>NULL/string additional info put into the image set object</p>
</td></tr>
<tr><td><code id="images_fech_set_+3A_size">size</code></td>
<td>
<p>NULL/string additional info put into the image set object</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Image set as a list consisting of three elements: 'data', 'prompt' and 'size'
</p>

<hr>
<h2 id='images_generator_request'>API images: create (generator) request</h2><span id='topic+images_generator_request'></span>

<h3>Description</h3>

<p>To get more details, visit https://platform.openai.com/docs/api-reference/images/create
</p>


<h3>Usage</h3>

<pre><code class='language-R'>images_generator_request(
  prompt,
  model = NULL,
  n = NULL,
  quality = NULL,
  response_format = NULL,
  size = NULL,
  style = NULL,
  user = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="images_generator_request_+3A_prompt">prompt</code></td>
<td>
<p>string, a text description of the desired image(s). The maximum length is 1000 characters for dall-e-2
and 4000 characters for dall-e-3.</p>
</td></tr>
<tr><td><code id="images_generator_request_+3A_model">model</code></td>
<td>
<p>NULL/string, the model to use for image generation. Defaults to 'dall-e-2'</p>
</td></tr>
<tr><td><code id="images_generator_request_+3A_n">n</code></td>
<td>
<p>NULL/int, the number of images to generate. Must be between 1 and 10. For dall-e-3, only n=1 is supported.</p>
</td></tr>
<tr><td><code id="images_generator_request_+3A_quality">quality</code></td>
<td>
<p>NULL/string, the quality of the image that will be generated. 'hd' creates images with finer details
and greater consistency across the image. This param is only supported for dall-e-3. Defaults to 'standard'.</p>
</td></tr>
<tr><td><code id="images_generator_request_+3A_response_format">response_format</code></td>
<td>
<p>NULL/string, the format in which the generated images are returned. Must be one of &quot;url&quot; or
&quot;b64_json&quot;.</p>
</td></tr>
<tr><td><code id="images_generator_request_+3A_size">size</code></td>
<td>
<p>NULL/string, the size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 for
dall-e-2. Must be one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3 models. 1024x1024 is default.</p>
</td></tr>
<tr><td><code id="images_generator_request_+3A_style">style</code></td>
<td>
<p>NULL/string, the style of the generated images. Must be one of 'vivid' (default) or 'natural'. Vivid
causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more
natural, less hyper-real looking images. This param is only supported for dall-e-3.</p>
</td></tr>
<tr><td><code id="images_generator_request_+3A_user">user</code></td>
<td>
<p>string a unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.</p>
</td></tr>
<tr><td><code id="images_generator_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='images_merge_sets'>Merge image set/sets</h2><span id='topic+images_merge_sets'></span>

<h3>Description</h3>

<p>Merge given image set/sets into single images sets object (list with image sets). Have a look at 
<a href="#topic+images_fech_set">images_fech_set</a>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>images_merge_sets(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="images_merge_sets_+3A_...">...</code></td>
<td>
<p>images set(s), NULL also allowed</p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of image set(s)
</p>

<hr>
<h2 id='images_variation_request'>API images: create image variation request</h2><span id='topic+images_variation_request'></span>

<h3>Description</h3>

<p>Creates a variation of a given image. To get more details, visit
https://platform.openai.com/docs/api-reference/images/createVariation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>images_variation_request(
  image,
  model = NULL,
  n = NULL,
  response_format = NULL,
  size = NULL,
  user = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="images_variation_request_+3A_image">image</code></td>
<td>
<p>string/raw, the image to edit. Must be a valid PNG file, less than 4MB, and square</p>
</td></tr>
<tr><td><code id="images_variation_request_+3A_model">model</code></td>
<td>
<p>NULL/string, the model to use for image generation. Only dall-e-2 is supported at this time.</p>
</td></tr>
<tr><td><code id="images_variation_request_+3A_n">n</code></td>
<td>
<p>NULL/int, the number of images to generate. Must be between 1 (default) and 10.</p>
</td></tr>
<tr><td><code id="images_variation_request_+3A_response_format">response_format</code></td>
<td>
<p>NULL/string, the format in which the generated images are returned. Must be one of &quot;url&quot; or
&quot;b64_json&quot;.</p>
</td></tr>
<tr><td><code id="images_variation_request_+3A_size">size</code></td>
<td>
<p>NULL/string, the size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 (default).</p>
</td></tr>
<tr><td><code id="images_variation_request_+3A_user">user</code></td>
<td>
<p>string a unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.</p>
</td></tr>
<tr><td><code id="images_variation_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='is_browseable'>Test if RStudio Viewer (build in browser) is available</h2><span id='topic+is_browseable'></span>

<h3>Description</h3>

<p>Test if RStudio Viewer (build in browser) is available
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_browseable()
</code></pre>


<h3>Value</h3>

<p>TRUE/FALSE
</p>

<hr>
<h2 id='is_error'>Test if object belongs to &quot;error&quot; class</h2><span id='topic+is_error'></span>

<h3>Description</h3>

<p>Test if object belongs to &quot;error&quot; class
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_error(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is_error_+3A_x">x</code></td>
<td>
<p>R variable</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE/FALSE
</p>


<h3>Examples</h3>

<pre><code class='language-R'>is_error(FALSE)
is_error(simpleError("test"))

</code></pre>

<hr>
<h2 id='is_image_set'>Test if x is a image set</h2><span id='topic+is_image_set'></span>

<h3>Description</h3>

<p>Test if x is a image set - a list consisting of three elements: data, prompt and size
</p>


<h3>Usage</h3>

<pre><code class='language-R'>is_image_set(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="is_image_set_+3A_x">x</code></td>
<td>
<p>R variable to test</p>
</td></tr>
</table>


<h3>Value</h3>

<p>TRUE/FALSE
</p>

<hr>
<h2 id='merge_dialog_df'>Merge multiple dialog data.frame</h2><span id='topic+merge_dialog_df'></span>

<h3>Description</h3>

<p>Merge multiple dialog data.frame
</p>


<h3>Usage</h3>

<pre><code class='language-R'>merge_dialog_df(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="merge_dialog_df_+3A_...">...</code></td>
<td>
<p>dialog data.frame or NULL</p>
</td></tr>
</table>


<h3>Value</h3>

<p>data.frame containing all input dialogs
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d1 &lt;- dialog_df("message 1")
d2 &lt;- dialog_df("message 2")
print(
  merge_dialog_df(
    d1,
    merge_dialog_df(d1, d2),
    NULL,
    d2
  )
)

</code></pre>

<hr>
<h2 id='messages_create_message_request'>API messages: create message</h2><span id='topic+messages_create_message_request'></span>

<h3>Description</h3>

<p>Create a message. To get more details, visit
https://platform.openai.com/docs/api-reference/messages/createMessage
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>messages_create_message_request(
  thread_id,
  role,
  content,
  file_ids = NULL,
  metadata = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="messages_create_message_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread to create a message for.</p>
</td></tr>
<tr><td><code id="messages_create_message_request_+3A_role">role</code></td>
<td>
<p>string, the role of the entity that is creating the message. Currently only user is supported.</p>
</td></tr>
<tr><td><code id="messages_create_message_request_+3A_content">content</code></td>
<td>
<p>string, the content of the message.</p>
</td></tr>
<tr><td><code id="messages_create_message_request_+3A_file_ids">file_ids</code></td>
<td>
<p>NULL/character vector, a list of File IDs that the message should use. There can be a maximum of 10
files attached to a message. Useful for tools like retrieval and code_interpreter that can access and use files.</p>
</td></tr>
<tr><td><code id="messages_create_message_request_+3A_metadata">metadata</code></td>
<td>
<p>NULL/list, set of 16 key-value pairs that can be attached to an object. This can be useful for
storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long
and values can be a maxium of 512 characters long.</p>
</td></tr>
<tr><td><code id="messages_create_message_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='messages_list_message_files_request'>API messages: list message files</h2><span id='topic+messages_list_message_files_request'></span>

<h3>Description</h3>

<p>Returns a list of message files. To get more details, visit
https://platform.openai.com/docs/api-reference/messages/listMessageFiles
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>messages_list_message_files_request(
  thread_id,
  message_id,
  limit = NULL,
  order = NULL,
  after = NULL,
  before = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="messages_list_message_files_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread the messages belong to</p>
</td></tr>
<tr><td><code id="messages_list_message_files_request_+3A_message_id">message_id</code></td>
<td>
<p>string, the ID of the message that the files belongs to</p>
</td></tr>
<tr><td><code id="messages_list_message_files_request_+3A_limit">limit</code></td>
<td>
<p>NULL/integer, a limit on the number of objects to be returned. Limit can range between 1 and 100,
and the default is 20.</p>
</td></tr>
<tr><td><code id="messages_list_message_files_request_+3A_order">order</code></td>
<td>
<p>NULL/string, sort order by the created_at timestamp of the objects. asc for ascending order and desc for
descending order. Defaults to desc</p>
</td></tr>
<tr><td><code id="messages_list_message_files_request_+3A_after">after</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. after is an object ID that defines your place in the list.
For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include after=obj_foo in order to fetch the next page of the list.</p>
</td></tr>
<tr><td><code id="messages_list_message_files_request_+3A_before">before</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. before is an object ID that defines your place in the
list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include before=obj_foo in order to fetch the previous page of the list.</p>
</td></tr>
<tr><td><code id="messages_list_message_files_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='messages_list_messages_request'>API messages: list messages</h2><span id='topic+messages_list_messages_request'></span>

<h3>Description</h3>

<p>Returns a list of messages for a given thread. To get more details, visit
https://platform.openai.com/docs/api-reference/messages/listMessages
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>messages_list_messages_request(
  thread_id,
  limit = NULL,
  order = NULL,
  after = NULL,
  before = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="messages_list_messages_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread the messages belong to</p>
</td></tr>
<tr><td><code id="messages_list_messages_request_+3A_limit">limit</code></td>
<td>
<p>NULL/integer, a limit on the number of objects to be returned. Limit can range between 1 and 100,
and the default is 20.</p>
</td></tr>
<tr><td><code id="messages_list_messages_request_+3A_order">order</code></td>
<td>
<p>NULL/string, sort order by the created_at timestamp of the objects. asc for ascending order and desc for
descending order. Defaults to desc</p>
</td></tr>
<tr><td><code id="messages_list_messages_request_+3A_after">after</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. after is an object ID that defines your place in the list.
For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include after=obj_foo in order to fetch the next page of the list.</p>
</td></tr>
<tr><td><code id="messages_list_messages_request_+3A_before">before</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. before is an object ID that defines your place in the
list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include before=obj_foo in order to fetch the previous page of the list.</p>
</td></tr>
<tr><td><code id="messages_list_messages_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='messages_modify_message_request'>API messages: modify message</h2><span id='topic+messages_modify_message_request'></span>

<h3>Description</h3>

<p>Modifies a message. To get more details, visit
https://platform.openai.com/docs/api-reference/messages/modifyMessage
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>messages_modify_message_request(
  thread_id,
  message_id,
  metadata = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="messages_modify_message_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread to which this message belongs</p>
</td></tr>
<tr><td><code id="messages_modify_message_request_+3A_message_id">message_id</code></td>
<td>
<p>string, the ID of the message to modify</p>
</td></tr>
<tr><td><code id="messages_modify_message_request_+3A_metadata">metadata</code></td>
<td>
<p>NULL/list, set of 16 key-value pairs that can be attached to an object. This can be useful for
storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long
and values can be a maximum of 512 characters long.</p>
</td></tr>
<tr><td><code id="messages_modify_message_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='messages_retrieve_message_file_request'>API messages: retrieve message file</h2><span id='topic+messages_retrieve_message_file_request'></span>

<h3>Description</h3>

<p>Retrieve a message file. To get more details, visit
https://platform.openai.com/docs/api-reference/messages/getMessageFile
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>messages_retrieve_message_file_request(
  thread_id,
  message_id,
  file_id,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="messages_retrieve_message_file_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread the messages belong to</p>
</td></tr>
<tr><td><code id="messages_retrieve_message_file_request_+3A_message_id">message_id</code></td>
<td>
<p>string, the ID of the message that the files belongs to</p>
</td></tr>
<tr><td><code id="messages_retrieve_message_file_request_+3A_file_id">file_id</code></td>
<td>
<p>string, the ID of the file being retrieved</p>
</td></tr>
<tr><td><code id="messages_retrieve_message_file_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='messages_retrieve_message_request'>API messages: retrieve message</h2><span id='topic+messages_retrieve_message_request'></span>

<h3>Description</h3>

<p>Retrieve a message. To get more details, visit
https://platform.openai.com/docs/api-reference/messages/getMessage
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>messages_retrieve_message_request(
  thread_id,
  message_id,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="messages_retrieve_message_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread the messages belong to</p>
</td></tr>
<tr><td><code id="messages_retrieve_message_request_+3A_message_id">message_id</code></td>
<td>
<p>string, the ID of the message that the files belongs to</p>
</td></tr>
<tr><td><code id="messages_retrieve_message_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='models_delete_request'>API models: delete model request</h2><span id='topic+models_delete_request'></span>

<h3>Description</h3>

<p>Delete a fine-tuned model. You must have the Owner role in your organization to delete a model. To get more details,
visit https://platform.openai.com/docs/models
https://platform.openai.com/docs/api-reference/fine-tunes/delete-model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>models_delete_request(model, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="models_delete_request_+3A_model">model</code></td>
<td>
<p>string, the model to delete</p>
</td></tr>
<tr><td><code id="models_delete_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='models_fetch_list'>Extract models from response object</h2><span id='topic+models_fetch_list'></span>

<h3>Description</h3>

<p>Extract models list as data.frame from response object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>models_fetch_list(res_content)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="models_fetch_list_+3A_res_content">res_content</code></td>
<td>
<p>response object returned by <a href="#topic+models_list_request">models_list_request</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>List of available models as data.frame
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- models_list_request()
if (!is_error(res_content)) {
  models_list_df &lt;- models_fetch_list(res_content)
  print(models_list_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='models_list_request'>API models: list request</h2><span id='topic+models_list_request'></span>

<h3>Description</h3>

<p>Lists the currently available models, and provides basic information about each one such as the owner and
availability. To get more details, visit: https://platform.openai.com/docs/models
https://platform.openai.com/docs/api-reference/models/list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>models_list_request(api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="models_list_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
res_content &lt;- models_list_request()
if (!is_error(res_content)) {
  models_list_df &lt;- models_fetch_list(res_content)
  print(models_list_df)
}

## End(Not run)

</code></pre>

<hr>
<h2 id='models_retrieve_request'>API models: retrieve model request</h2><span id='topic+models_retrieve_request'></span>

<h3>Description</h3>

<p>Retrieves a model instance, providing basic information about the model such as the owner and permissioning.
To get more details, visit: https://platform.openai.com/docs/models
https://platform.openai.com/docs/api-reference/models/list
</p>


<h3>Usage</h3>

<pre><code class='language-R'>models_retrieve_request(model, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="models_retrieve_request_+3A_model">model</code></td>
<td>
<p>string, the ID of the model to use for this request</p>
</td></tr>
<tr><td><code id="models_retrieve_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='moderation_create_request'>API moderations: create moderation</h2><span id='topic+moderation_create_request'></span>

<h3>Description</h3>

<p>Given a input text, outputs if the model classifies it as violating OpenAI's content policy. To get more details,
visit https://platform.openai.com/docs/api-reference/moderations/create
https://platform.openai.com/docs/guides/moderation
</p>


<h3>Usage</h3>

<pre><code class='language-R'>moderation_create_request(input, model = NULL, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="moderation_create_request_+3A_input">input</code></td>
<td>
<p>string, the input text to classify</p>
</td></tr>
<tr><td><code id="moderation_create_request_+3A_model">model</code></td>
<td>
<p>string, two content moderations models are available: 'text-moderation-stable' and 
'text-moderation-latest'. The default is 'text-moderation-latest' which will be automatically upgraded over time.
This ensures you are always using our most accurate model. If you use 'text-moderation-stable', we will provide
advanced notice before updating the model. Accuracy of 'text-moderation-stable' may be slightly lower than for
'text-moderation-latest'.</p>
</td></tr>
<tr><td><code id="moderation_create_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='print.oaii_content_audio'>Class oaii_content_audio print S3 method</h2><span id='topic+print.oaii_content_audio'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_content_audio'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_content_audio_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_content_audio_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_content_audio_aac'>Class oaii_content_audio_aac print S3 method</h2><span id='topic+print.oaii_content_audio_aac'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_content_audio_aac'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_content_audio_aac_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_content_audio_aac_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_content_audio_flac'>Class oaii_content_audio_flac print S3 method</h2><span id='topic+print.oaii_content_audio_flac'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_content_audio_flac'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_content_audio_flac_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_content_audio_flac_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_content_audio_mp3'>Class oaii_content_audio_mp3 print S3 method</h2><span id='topic+print.oaii_content_audio_mp3'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_content_audio_mp3'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_content_audio_mp3_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_content_audio_mp3_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_content_audio_opus'>Class oaii_content_audio_opus print S3 method</h2><span id='topic+print.oaii_content_audio_opus'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_content_audio_opus'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_content_audio_opus_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_content_audio_opus_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_content_images'>Class oaii_content_images print S3 method</h2><span id='topic+print.oaii_content_images'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_content_images'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_content_images_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_content_images_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_files_df'>print S3 method for oaii_files_df class</h2><span id='topic+print.oaii_files_df'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_files_df'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_files_df_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_files_df_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_fine_tuning_events_df'>print S3 method for oaii_fine_tuning_events_df class</h2><span id='topic+print.oaii_fine_tuning_events_df'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_fine_tuning_events_df'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_fine_tuning_events_df_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_fine_tuning_events_df_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_fine_tuning_job'>print S3 method for oaii_fine_tuning_job class</h2><span id='topic+print.oaii_fine_tuning_job'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_fine_tuning_job'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_fine_tuning_job_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_fine_tuning_job_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_fine_tuning_jobs_df'>print S3 method for oaii_fine_tuning_jobs_df class</h2><span id='topic+print.oaii_fine_tuning_jobs_df'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_fine_tuning_jobs_df'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_fine_tuning_jobs_df_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_fine_tuning_jobs_df_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_models_df'>print S3 method for oaii_models_df class</h2><span id='topic+print.oaii_models_df'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_models_df'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_models_df_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_models_df_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='print.oaii_res_se'>Class oaii_res_se print S3 method</h2><span id='topic+print.oaii_res_se'></span>

<h3>Description</h3>

<p><code>print</code> prints its argument and returns it <em>invisibly</em> (via
<code><a href="base.html#topic+invisible">invisible</a>(x)</code>).  It is a generic function which means that
new printing methods can be easily added for new <code><a href="base.html#topic+class">class</a></code>es.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'oaii_res_se'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="print.oaii_res_se_+3A_x">x</code></td>
<td>
<p>an object used to select a method.</p>
</td></tr>
<tr><td><code id="print.oaii_res_se_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>

<hr>
<h2 id='request'>API request</h2><span id='topic+request'></span>

<h3>Description</h3>

<p>To get more details, visit https://platform.openai.com/docs/api-reference/making-requests
</p>


<h3>Usage</h3>

<pre><code class='language-R'>request(
  endpoint,
  api_key = api_get_key(),
  body = NULL,
  query = NULL,
  encode = "json",
  method = "POST",
  content_class = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="request_+3A_endpoint">endpoint</code></td>
<td>
<p>string, API endpoint url</p>
</td></tr>
<tr><td><code id="request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
<tr><td><code id="request_+3A_body">body</code></td>
<td>
<p>One of the following:
</p>

<ul>
<li> <p><code>FALSE</code>: No body. This is typically not used with <code>POST</code>,
<code>PUT</code>, or <code>PATCH</code>, but can be useful if you need to send a
bodyless request (like <code>GET</code>) with <code>VERB()</code>.
</p>
</li>
<li> <p><code>NULL</code>: An empty body
</p>
</li>
<li> <p><code>""</code>: A length 0 body
</p>
</li>
<li> <p><code>upload_file("path/")</code>: The contents of a file.  The mime
type will be guessed from the extension, or can be supplied explicitly
as the second argument to <code>upload_file()</code>
</p>
</li>
<li><p> A character or raw vector: sent as is in body. Use
<code><a href="httr.html#topic+content_type">content_type()</a></code> to tell the server what sort of data
you are sending.
</p>
</li>
<li><p> A named list: See details for encode.
</p>
</li></ul>
</td></tr>
<tr><td><code id="request_+3A_query">query</code></td>
<td>
<p>NULL/list, query string elements as list(name1 = value1, name2 = value2)</p>
</td></tr>
<tr><td><code id="request_+3A_encode">encode</code></td>
<td>
<p>If the body is a named list, how should it be encoded? Can be
one of form (application/x-www-form-urlencoded), multipart,
(multipart/form-data), or json (application/json).
</p>
<p>For &quot;multipart&quot;, list elements can be strings or objects created by
<code><a href="httr.html#topic+upload_file">upload_file()</a></code>. For &quot;form&quot;, elements are coerced to strings
and escaped, use <code>I()</code> to prevent double-escaping. For &quot;json&quot;,
parameters are automatically &quot;unboxed&quot; (i.e. length 1 vectors are
converted to scalars). To preserve a length 1 vector as a vector,
wrap in <code>I()</code>. For &quot;raw&quot;, either a character or raw vector. You'll
need to make sure to set the <code><a href="httr.html#topic+content_type">content_type()</a></code> yourself.</p>
</td></tr>
<tr><td><code id="request_+3A_method">method</code></td>
<td>
<p>string, request method</p>
</td></tr>
<tr><td><code id="request_+3A_content_class">content_class</code></td>
<td>
<p>NULL/character vector, NULL or additional class
name(s) (S3) appended to the response content</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='runs_cancel_run_request'>API runs: cancel a run</h2><span id='topic+runs_cancel_run_request'></span>

<h3>Description</h3>

<p>Cancels a run that is &quot;in_progress&quot;. To get more details, visit 
https://platform.openai.com/docs/api-reference/runs/cancelRun
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runs_cancel_run_request(thread_id, run_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runs_cancel_run_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread (https://platform.openai.com/docs/api-reference/threads) to which this
run belongs</p>
</td></tr>
<tr><td><code id="runs_cancel_run_request_+3A_run_id">run_id</code></td>
<td>
<p>string, the ID of the run to cancel</p>
</td></tr>
<tr><td><code id="runs_cancel_run_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='runs_create_run_request'>API runs: create run</h2><span id='topic+runs_create_run_request'></span>

<h3>Description</h3>

<p>Create a run. To get more details, visit
https://platform.openai.com/docs/api-reference/runs/createRun
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runs_create_run_request(
  thread_id,
  assistant_id,
  model = NULL,
  instructions = NULL,
  additional_instructions = NULL,
  tools = NULL,
  metadata = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runs_create_run_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread to run</p>
</td></tr>
<tr><td><code id="runs_create_run_request_+3A_assistant_id">assistant_id</code></td>
<td>
<p>string, the ID of the assistant to use to execute this run</p>
</td></tr>
<tr><td><code id="runs_create_run_request_+3A_model">model</code></td>
<td>
<p>NULL/string, the ID of the model (https://platform.openai.com/docs/api-reference/models) to be used to
execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the
model associated with the assistant will be used.</p>
</td></tr>
<tr><td><code id="runs_create_run_request_+3A_instructions">instructions</code></td>
<td>
<p>NULL/string, overrides the instructions
(https://platform.openai.com/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for
modifying the behavior on a per-run basis.</p>
</td></tr>
<tr><td><code id="runs_create_run_request_+3A_additional_instructions">additional_instructions</code></td>
<td>
<p>NULL/string, appends additional instructions at the end of the instructions for the
run. This is useful for modifying the behavior on a per-run basis without overriding other instructions.</p>
</td></tr>
<tr><td><code id="runs_create_run_request_+3A_tools">tools</code></td>
<td>
<p>NULL/named list, override the tools the assistant can use for this run. This is useful for modifying the
behavior on a per-run basis. Example:
</p>
<pre>
# code interpreter tool
list(
  type = "code_interpreter"
)
# or retrieval tool
list(
  type = "retrieval"
)
# or function tool
list(
  type = "retrieval",
  function = list(
    # string (optional), a description of what the function
    # does, used by the model to choose when and how to call
    # the function.
    description = 
    # string (required), the name of the function to be called.
    # Must be a-z, A-Z, 0-9, or contain underscores and dashes,
    # with a maximum length of 64.
    name =
    # list (optional), the parameters the functions accepts.
    # See the guide
    # (https://platform.openai.com/docs/guides/text-generation/function-calling)
    # for examples. Omitting parameters defines a function
    # with an empty parameter list.
    parameters = list (
    )
 )
)</pre></td></tr>
<tr><td><code id="runs_create_run_request_+3A_metadata">metadata</code></td>
<td>
<p>NULL/list, set of 16 key-value pairs that can be attached to an object. This can be useful for
storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long
and values can be a maximum of 512 characters long.</p>
</td></tr>
<tr><td><code id="runs_create_run_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
runs_create_run_request(
  thread_id = "thread_abc123",
  assistant_id = "asst_abc123"
)

## End(Not run)

</code></pre>

<hr>
<h2 id='runs_create_thread_and_run_request'>API runs: create thread and run</h2><span id='topic+runs_create_thread_and_run_request'></span>

<h3>Description</h3>

<p>Create a thread and run it in one request. To get more details, visit
https://platform.openai.com/docs/api-reference/runs/createThreadAndRun
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runs_create_thread_and_run_request(
  assistant_id,
  thread,
  model = NULL,
  instructions = NULL,
  tools = NULL,
  metadata = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runs_create_thread_and_run_request_+3A_assistant_id">assistant_id</code></td>
<td>
<p>string, the ID of the assistant to use to execute this run</p>
</td></tr>
<tr><td><code id="runs_create_thread_and_run_request_+3A_thread">thread</code></td>
<td>
<p>NULL/list,
</p>
<pre>
list(
  # messages "array" (list of list(s))
  messages = list(
    list(
    # string (required), the role of the entity that is creating
    # the message. Currently only user is supported.
    role = 
    # string (required), the content of the message.
    content = 
    # character vector (optional), a list of File IDs that
    # the message should use. There can be a maximum of 10
    # files attached to a message. Useful for tools like retrieval
    # and code_interpreter that can access and use files.
    file_ids = 
    # named list (optional), set of 16 key-value pairs that
    # can be attached to an object. This can be useful for
    # storing additional information about the object in a
    # structured format. Keys can be a maximum of 64 characters
    # long and values can be a maximum of 512 characters long.
    metadata = list (
      meta1 = "value1"
    )
  )
 ),
 # named list (optional), set of 16 key-value pairs that
 # can be attached to an object. This can be useful for
 # storing additional information about the object in a structured
 # format. Keys can be a maximum of 64 characters long
 # and values can be a maximum of 512 characters long.
 metadata = list(
   metaX = "value y"
 )
)</pre></td></tr>
<tr><td><code id="runs_create_thread_and_run_request_+3A_model">model</code></td>
<td>
<p>NULL/string, the ID of the model (https://platform.openai.com/docs/api-reference/models) to be used to
execute this run. If a value is provided here, it will override the model associated with the assistant. If not, the
model associated with the assistant will be used.</p>
</td></tr>
<tr><td><code id="runs_create_thread_and_run_request_+3A_instructions">instructions</code></td>
<td>
<p>NULL/string, overrides the instructions
(https://platform.openai.com/docs/api-reference/assistants/createAssistant) of the assistant. This is useful for
modifying the behavior on a per-run basis.</p>
</td></tr>
<tr><td><code id="runs_create_thread_and_run_request_+3A_tools">tools</code></td>
<td>
<p>NULL/named list, override the tools the assistant can use for this run. This is useful for modifying the
behavior on a per-run basis. Example:
</p>
<pre>
# code interpreter tool
list(
  type = "code_interpreter"
)
# or retrieval tool
list(
  type = "retrieval"
)
# or function tool
list(
  type = "retrieval",
  function = list(
    # string (optional), a description of what the function does, used by the model to choose when and how to call
    # the function.
    description = 
    # string (required), the name of the function to be called. Must be a-z, A-Z, 0-9, or contain underscores and
    # dashes, with a maximum length of 64.
    name =
    # list (optional), the parameters the functions accepts. See the guide
    # (https://platform.openai.com/docs/guides/text-generation/function-calling) for examples. Omitting parameters
    # defines a function with an empty parameter list.
    parameters = list (
    )
 )
)</pre></td></tr>
<tr><td><code id="runs_create_thread_and_run_request_+3A_metadata">metadata</code></td>
<td>
<p>NULL/list, set of 16 key-value pairs that can be attached to an object. This can be useful for
storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long
and values can be a maximum of 512 characters long.</p>
</td></tr>
<tr><td><code id="runs_create_thread_and_run_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='runs_list_run_steps_request'>API runs: list run steps</h2><span id='topic+runs_list_run_steps_request'></span>

<h3>Description</h3>

<p>Returns a list of runs belonging to a thread. To get more details, visit
https://platform.openai.com/docs/api-reference/runs/listRuns
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runs_list_run_steps_request(
  thread_id,
  run_id,
  limit = NULL,
  order = NULL,
  after = NULL,
  before = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runs_list_run_steps_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread the run belongs to</p>
</td></tr>
<tr><td><code id="runs_list_run_steps_request_+3A_run_id">run_id</code></td>
<td>
<p>string, the ID of the run the run steps belong to</p>
</td></tr>
<tr><td><code id="runs_list_run_steps_request_+3A_limit">limit</code></td>
<td>
<p>NULL/integer, a limit on the number of objects to be returned. Limit can range between 1 and 100,
and the default is 20.</p>
</td></tr>
<tr><td><code id="runs_list_run_steps_request_+3A_order">order</code></td>
<td>
<p>NULL/string, sort order by the created_at timestamp of the objects. asc for ascending order and desc for
descending order. Defaults to desc</p>
</td></tr>
<tr><td><code id="runs_list_run_steps_request_+3A_after">after</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. after is an object ID that defines your place in the list.
For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include after=obj_foo in order to fetch the next page of the list.</p>
</td></tr>
<tr><td><code id="runs_list_run_steps_request_+3A_before">before</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. before is an object ID that defines your place in the
list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include before=obj_foo in order to fetch the previous page of the list.</p>
</td></tr>
<tr><td><code id="runs_list_run_steps_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='runs_list_runs_request'>API runs: list runs</h2><span id='topic+runs_list_runs_request'></span>

<h3>Description</h3>

<p>Returns a list of runs belonging to a thread. To get more details, visit
https://platform.openai.com/docs/api-reference/runs/listRuns
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runs_list_runs_request(
  thread_id,
  limit = NULL,
  order = NULL,
  after = NULL,
  before = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runs_list_runs_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread the run belongs to</p>
</td></tr>
<tr><td><code id="runs_list_runs_request_+3A_limit">limit</code></td>
<td>
<p>NULL/integer, a limit on the number of objects to be returned. Limit can range between 1 and 100,
and the default is 20.</p>
</td></tr>
<tr><td><code id="runs_list_runs_request_+3A_order">order</code></td>
<td>
<p>NULL/string, sort order by the created_at timestamp of the objects. asc for ascending order and desc for
descending order. Defaults to desc</p>
</td></tr>
<tr><td><code id="runs_list_runs_request_+3A_after">after</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. after is an object ID that defines your place in the list.
For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include after=obj_foo in order to fetch the next page of the list.</p>
</td></tr>
<tr><td><code id="runs_list_runs_request_+3A_before">before</code></td>
<td>
<p>NULL/string, a cursor for use in pagination. before is an object ID that defines your place in the
list. For instance, if you make a list request and receive 100 objects, ending with obj_foo, your subsequent call can
include before=obj_foo in order to fetch the previous page of the list.</p>
</td></tr>
<tr><td><code id="runs_list_runs_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='runs_modify_run_request'>API runs: modify run</h2><span id='topic+runs_modify_run_request'></span>

<h3>Description</h3>

<p>Modifies a run. To get more details, visit
https://platform.openai.com/docs/api-reference/runs/modifyRun
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runs_modify_run_request(
  thread_id,
  run_id,
  metadata = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runs_modify_run_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread (https://platform.openai.com/docs/api-reference/threads) that was run</p>
</td></tr>
<tr><td><code id="runs_modify_run_request_+3A_run_id">run_id</code></td>
<td>
<p>string, the ID of the run to modify</p>
</td></tr>
<tr><td><code id="runs_modify_run_request_+3A_metadata">metadata</code></td>
<td>
<p>NULL/list, set of 16 key-value pairs that can be attached to an object. This can be useful for
storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long
and values can be a maximum of 512 characters long.</p>
</td></tr>
<tr><td><code id="runs_modify_run_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='runs_retrieve_run_request'>API runs: retrieve run</h2><span id='topic+runs_retrieve_run_request'></span>

<h3>Description</h3>

<p>Retrieves a thread. To get more details, visit
https://platform.openai.com/docs/api-reference/threads/getThread
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runs_retrieve_run_request(thread_id, run_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runs_retrieve_run_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, The ID of the thread (https://platform.openai.com/docs/api-reference/threads) that was run</p>
</td></tr>
<tr><td><code id="runs_retrieve_run_request_+3A_run_id">run_id</code></td>
<td>
<p>string, the ID of the run to retrieve</p>
</td></tr>
<tr><td><code id="runs_retrieve_run_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='runs_retrieve_run_step_request'>API runs: retrieve run step</h2><span id='topic+runs_retrieve_run_step_request'></span>

<h3>Description</h3>

<p>Retrieves a run step. To get more details, visit
https://platform.openai.com/docs/api-reference/runs/getRunStep
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runs_retrieve_run_step_request(
  thread_id,
  run_id,
  step_id,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runs_retrieve_run_step_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread (https://platform.openai.com/docs/api-reference/threads) to which the
run and run step belongs</p>
</td></tr>
<tr><td><code id="runs_retrieve_run_step_request_+3A_run_id">run_id</code></td>
<td>
<p>string, the ID of the run to which the run step belongs</p>
</td></tr>
<tr><td><code id="runs_retrieve_run_step_request_+3A_step_id">step_id</code></td>
<td>
<p>string, the ID of the run step to retrieve</p>
</td></tr>
<tr><td><code id="runs_retrieve_run_step_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='runs_submit_tool_outputs_request'>API runs: submit tool outputs to run</h2><span id='topic+runs_submit_tool_outputs_request'></span>

<h3>Description</h3>

<p>When a run has the status: &quot;requires_action&quot; and required_action.type is submit_tool_outputs, this endpoint can be
used to submit the outputs from the tool calls once they're all completed. All outputs must be submitted in a single
request. To get more details, visit https://platform.openai.com/docs/api-reference/runs/submitToolOutputs
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>runs_submit_tool_outputs_request(
  thread_id,
  run_id,
  tool_outputs,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="runs_submit_tool_outputs_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread (https://platform.openai.com/docs/api-reference/threads) to which this
run belongs</p>
</td></tr>
<tr><td><code id="runs_submit_tool_outputs_request_+3A_run_id">run_id</code></td>
<td>
<p>string, the ID of the run that requires the tool output submission</p>
</td></tr>
<tr><td><code id="runs_submit_tool_outputs_request_+3A_tool_outputs">tool_outputs</code></td>
<td>
<p>list, a list of tools for which the outputs are being submitted.
</p>
<pre>
list(
  # string (optional), the ID of the tool call in the required_action
  # object within the run object the output is being submitted for.
  tool_call_id = 
  # string (optional), the output of the tool call to be
  # submitted to continue the run
  output = 
)</pre></td></tr>
<tr><td><code id="runs_submit_tool_outputs_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='set_logger'>Set log functions used by 'oaii' package</h2><span id='topic+set_logger'></span>

<h3>Description</h3>

<p>Set log functions used by 'oaii' package
</p>


<h3>Usage</h3>

<pre><code class='language-R'>set_logger(...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="set_logger_+3A_...">...</code></td>
<td>
<p>parameters in form log_level = function</p>
</td></tr>
</table>


<h3>Value</h3>

<p>invisible(NULL)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
logger &lt;- log4r::logger("DEBUG")
log_error &lt;- function(...) log4r::error(logger, ...)
log_warning &lt;- function(...) log4r::warn(logger, ...)
log_info &lt;- function(...) log4r::info(logger, ...)
log_debug &lt;- function(...) log4r::debug(logger, ...)

oaii::set_logger(
  error = log_error,
  warning = log_warning,
  info = log_info,
  debug = log_debug
)

## End(Not run)

</code></pre>

<hr>
<h2 id='threads_create_thread_request'>API threads: create thread</h2><span id='topic+threads_create_thread_request'></span>

<h3>Description</h3>

<p>Create threads that assistants can interact with. To get more details, visit
https://platform.openai.com/docs/api-reference/threads/createThread
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>threads_create_thread_request(
  messages = NULL,
  metadata = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="threads_create_thread_request_+3A_messages">messages</code></td>
<td>
<p>NULL/list, a list of messages to start the thread with. The message &quot;object&quot; description:
</p>
<pre>
list(
  list(
    # string (required), the role of the entity that is
    # creating the message. Currently only 'user' is supported.
    role = "user",
    # string (required), the content of the message.
    content = 
    # character vector (optional), a list of File IDs that
    # the message should use. There can be a maximum of 10
    # files attached to a message. Useful for tools like
    # retrieval and code_interpreter that can access and
    # use files.
    file_ids = 
    # named list (optional), set of 16 key-value pairs that
    # can be attached to an object. This can be useful for
    # storing additional information about the object in a
    # structured format. Keys can be a maximum of 64 characters
    # long and values can be a maximum of 512 characters long.
    metadata = list(
      meta1 = "value 2"
    )
  )
)</pre></td></tr>
<tr><td><code id="threads_create_thread_request_+3A_metadata">metadata</code></td>
<td>
<p>NULL/list, set of 16 key-value pairs that can be attached to an object. This can be useful for
storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long
and values can be a maximum of 512 characters long.</p>
</td></tr>
<tr><td><code id="threads_create_thread_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='threads_delete_thread_request'>API threads: delete thread</h2><span id='topic+threads_delete_thread_request'></span>

<h3>Description</h3>

<p>Delete a thread. To get more details, visit
https://platform.openai.com/docs/api-reference/threads/deleteThread
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>threads_delete_thread_request(thread_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="threads_delete_thread_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread to delete</p>
</td></tr>
<tr><td><code id="threads_delete_thread_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='threads_modify_thread_request'>API threads: modify thread</h2><span id='topic+threads_modify_thread_request'></span>

<h3>Description</h3>

<p>Modifies a thread. To get more details, visit
https://platform.openai.com/docs/api-reference/threads/modifyThread
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>threads_modify_thread_request(
  thread_id,
  metadata = NULL,
  api_key = api_get_key()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="threads_modify_thread_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread to modify. Only the 'metadata' can be modified.</p>
</td></tr>
<tr><td><code id="threads_modify_thread_request_+3A_metadata">metadata</code></td>
<td>
<p>NULL/list, set of 16 key-value pairs that can be attached to an object. This can be useful for
storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long
and values can be a maximum of 512 characters long.</p>
</td></tr>
<tr><td><code id="threads_modify_thread_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='threads_retrieve_thread_request'>API threads: retrieve thread</h2><span id='topic+threads_retrieve_thread_request'></span>

<h3>Description</h3>

<p>Retrieves a thread. To get more details, visit
https://platform.openai.com/docs/api-reference/threads/getThread
https://platform.openai.com/docs/assistants
</p>


<h3>Usage</h3>

<pre><code class='language-R'>threads_retrieve_thread_request(thread_id, api_key = api_get_key())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="threads_retrieve_thread_request_+3A_thread_id">thread_id</code></td>
<td>
<p>string, the ID of the thread to retrieve.</p>
</td></tr>
<tr><td><code id="threads_retrieve_thread_request_+3A_api_key">api_key</code></td>
<td>
<p>string, OpenAI API key
(see https://platform.openai.com/account/api-keys)</p>
</td></tr>
</table>


<h3>Value</h3>

<p><a href="httr.html#topic+content">content</a> of the httr <a href="httr.html#topic+response">response</a> object
or SimpleError (<a href="base.html#topic+conditions">conditions</a>) enhanced with
two additional fields: 'status_code' (response$status_code)
and 'message_long' (built on response content)
</p>

<hr>
<h2 id='timestap_dt_str'>Convert unix timestamp to formated date/time string</h2><span id='topic+timestap_dt_str'></span>

<h3>Description</h3>

<p>Convert unix timestamp to formated date/time string
</p>


<h3>Usage</h3>

<pre><code class='language-R'>timestap_dt_str(
  timestamp,
  format = "%Y-%m-%d %H:%M:%S",
  tz = "",
  usetz = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="timestap_dt_str_+3A_timestamp">timestamp</code></td>
<td>
<p>int, unix timestamp value</p>
</td></tr>
<tr><td><code id="timestap_dt_str_+3A_format">format</code></td>
<td>
<p>A character string.  The default for the <code>format</code>
methods is
<code>"%Y-%m-%d %H:%M:%S"</code> if any element has a time
component which is not midnight, and <code>"%Y-%m-%d"</code>
otherwise.  If <code><a href="base.html#topic+options">options</a>("digits.secs")</code> is set, up to
the specified number of digits will be printed for seconds.</p>
</td></tr>
<tr><td><code id="timestap_dt_str_+3A_tz">tz</code></td>
<td>
<p>A character string specifying the time zone to be used for
the conversion.  System-specific (see <code><a href="base.html#topic+as.POSIXlt">as.POSIXlt</a></code>), but
<code>""</code> is the current time zone, and <code>"GMT"</code> is UTC.
Invalid values are most commonly treated as UTC, on some platforms with
a warning.</p>
</td></tr>
<tr><td><code id="timestap_dt_str_+3A_usetz">usetz</code></td>
<td>
<p>logical.  Should the time zone abbreviation be appended
to the output?  This is used in printing times, and more reliable
than using <code>"%Z"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The <code>format</code> methods and <code>strftime</code> return character vectors
representing the time.  <code>NA</code> times are returned as
<code>NA_character_</code>.
</p>
<p><code>strptime</code> turns character representations into an object of
class <code>"<a href="base.html#topic+POSIXlt">POSIXlt</a>"</code>.  The time zone is used to set the
<code>isdst</code> component and to set the <code>"tzone"</code> attribute if
<code>tz != ""</code>.  If the specified time is invalid (for example
&lsquo;<span class="samp">&#8288;"2010-02-30 08:00"&#8288;</span>&rsquo;) all the components of the result are
<code>NA</code>.  (NB: this does means exactly what it says &ndash; if it is an
invalid time, not just a time that does not exist in some time zone.)
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
