<!DOCTYPE html><html><head><title>Help for package evclust</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {evclust}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bananas'><p>Generation of &quot;bananas&quot; datasets</p></a></li>
<li><a href='#bootclus'><p>Generating a credal partition by bootstraping Gaussian Mixture Models</p></a></li>
<li><a href='#bpec'><p>Belief Peak Evidential Clustering (BPEC)</p></a></li>
<li><a href='#butterfly'><p>Butterfly dataset</p></a></li>
<li><a href='#cecm'><p>Constrained Evidential c-means algorithm</p></a></li>
<li><a href='#create_fuzzy_credpart'><p>Creation of a &quot;credpart&quot; object from a from a fuzzy or possibilistic partition matrix</p></a></li>
<li><a href='#create_hard_credpart'><p>Creation of a &quot;credpart&quot; object from a vector of class labels</p></a></li>
<li><a href='#create_MLCL'><p>Random generation of Must-Link and Cannot-Link constraints</p></a></li>
<li><a href='#createD'><p>Computation of a  Euclidean distance matrix</p></a></li>
<li><a href='#createPairs'><p>Finding overlapping pairs of clusters</p></a></li>
<li><a href='#credal_RI'><p>Credal Rand indices</p></a></li>
<li><a href='#delta_Bel'><p>Delta-Bel graph for Belief Peak Evidential Clustering (BPEC)</p></a></li>
<li><a href='#ecm'><p>Evidential c-means algorithm</p></a></li>
<li><a href='#EkNNclus'><p>EkNNclus algorithm</p></a></li>
<li><a href='#evclust'><p>evclust: A package for evidential clustering</p></a></li>
<li><a href='#expandlink'><p>Expansion of must-link and cannot-link constraints</p></a></li>
<li><a href='#extractMass'><p>Creates an object of class &quot;credpart&quot;</p></a></li>
<li><a href='#fourclass'><p>Synthetic four-class dataset</p></a></li>
<li><a href='#harris'><p>Harris gradient-based optimization algorithm</p></a></li>
<li><a href='#kcevclus'><p>k-CEVCLUS algorithm</p></a></li>
<li><a href='#kevclus'><p>k-EVCLUS algorithm</p></a></li>
<li><a href='#knn_dist'><p>K nearest neighbors in a dissimilarity matrix</p></a></li>
<li><a href='#kpcca'><p>Kernel Pairwise Constrained Component Analysis (KPCCA)</p></a></li>
<li><a href='#makeF'><p>Creation of a matrix of focal sets</p></a></li>
<li><a href='#nnevclus'><p>NN-EVCLUS algorithm</p></a></li>
<li><a href='#nnevclus_mb'><p>NN-EVCLUS algorithm (minibatch version)</p></a></li>
<li><a href='#nonspecificity'><p>Nonspecificity of the relational representation of a credal partition</p></a></li>
<li><a href='#normalize.credpart'><p>Normalization of a credal partition</p></a></li>
<li><a href='#pairwise_mass'><p>Computes the relational representation</p></a></li>
<li><a href='#pcca'><p>Pairwise Constrained Component Analysis (PCCA)</p></a></li>
<li><a href='#plot.credpart'><p>Plotting a credal partition</p></a></li>
<li><a href='#predict.credpart'><p>Computation of a credal partition for new data</p></a></li>
<li><a href='#protein'><p>Protein dataset</p></a></li>
<li><a href='#recm'><p>Relational Evidential c-means algorithm</p></a></li>
<li><a href='#s2'><p>S2 dataset</p></a></li>
<li><a href='#summary.credpart'><p>Summary of a credal partition</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Evidential Clustering</td>
</tr>
<tr>
<td>Version:</td>
<td>2.0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-11-9</td>
</tr>
<tr>
<td>Author:</td>
<td>Thierry Denoeux</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Thierry Denoeux &lt;tdenoeux@utc.fr&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Various clustering algorithms that produce a credal partition,
    i.e., a set of Dempster-Shafer mass functions representing the membership of objects
    to clusters. The mass functions quantify the cluster-membership uncertainty of the     
    objects. The algorithms are: Evidential c-Means, Relational Evidential c-Means, 
    Constrained Evidential c-Means, Evidential Clustering, Constrained Evidential 
    Clustering, Evidential K-nearest-neighbor-based Clustering, Bootstrap Model-Based
    Evidential Clustering, Belief Peak Evidential Clustering, Neural-Network-based
    Evidential Clustering. </td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6.0),</td>
</tr>
<tr>
<td>Imports:</td>
<td>FNN, R.utils, limSolve, Matrix, mclust, quadprog, plyr</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>utils</td>
</tr>
<tr>
<td>Suggests:</td>
<td>utils, kernlab, MASS</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-11-09 12:55:56 UTC; Thierry</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-11-09 14:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bananas'>Generation of &quot;bananas&quot; datasets</h2><span id='topic+bananas'></span>

<h3>Description</h3>

<p><code>bananas</code> generates a dataset with two classes separated by a nonlinear boundary.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bananas(n, r = 5, s = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bananas_+3A_n">n</code></td>
<td>
<p>Number of observations.</p>
</td></tr>
<tr><td><code id="bananas_+3A_r">r</code></td>
<td>
<p>Radius of the two half circles (default: 5).</p>
</td></tr>
<tr><td><code id="bananas_+3A_s">s</code></td>
<td>
<p>Standard deviation of noise (default 1).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates a dataset with two complex-shaped classes, useful to test some nonlinear
or constrained clustering algorithms.
</p>


<h3>Value</h3>

<p>A list with two attributes:
</p>

<dl>
<dt>x</dt><dd><p>The (n,2) matrix of attributes.</p>
</dd>
<dt>y</dt><dd><p>The vector of class labels.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Feng Li.
</p>


<h3>References</h3>

<p>F. Li, S. Li and T. Denoeux. k-CEVCLUS: Constrained evidential clustering of 
large dissimilarity data. Knowledge-Based Systems (142):29-44, 2018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kcevclus">kcevclus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data&lt;-bananas(1000)
plot(data$x,pch=data$y,col=data$y)

</code></pre>

<hr>
<h2 id='bootclus'>Generating a credal partition by bootstraping Gaussian Mixture Models</h2><span id='topic+bootclus'></span>

<h3>Description</h3>

<p><code>bootclus</code> generates a credal partition by bootstrapping Gaussian Mixture Models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootclus(
  x,
  conf = 0.9,
  B = 500,
  param = list(G = NULL),
  type = "pairs",
  Omega = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bootclus_+3A_x">x</code></td>
<td>
<p>attribute matrix or data frame of size (n,p).</p>
</td></tr>
<tr><td><code id="bootclus_+3A_conf">conf</code></td>
<td>
<p>confidence level (default: 0.90).</p>
</td></tr>
<tr><td><code id="bootclus_+3A_b">B</code></td>
<td>
<p>number of bootstrap samples (default=500)</p>
</td></tr>
<tr><td><code id="bootclus_+3A_param">param</code></td>
<td>
<p>list of arguments passed to function <code>Mclust</code> in addition to 'data'.</p>
</td></tr>
<tr><td><code id="bootclus_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: <code class="reqn">\emptyset</code>, singletons and <code class="reqn">\Omega</code>;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all or selected pairs). Argument passed to <code>makeF</code>.</p>
</td></tr>
<tr><td><code id="bootclus_+3A_omega">Omega</code></td>
<td>
<p>Logical. If TRUE, <code class="reqn">\Omega</code> is a focal set. Default is FALSE. 
Argument passed to <code>makeF</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the <code>mclust</code> package to generate and bootstrap the mixture models.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>

<dl>
<dt>clus</dt><dd><p>An object of class '<code>Mclust</code>' returned by <code>Mclust</code>.</p>
</dd>
<dt>Clus</dt><dd><p>An object of class '<code>credpart</code>' providing the output credal partition.</p>
</dd>
<dt>CI</dt><dd><p>An array of dimension (2,n,n) containing the confidence intervals on pairwise probabilities.</p>
</dd>
<dt>BelPl</dt><dd><p>An array of dimension (2,n,n) containing the pairwise Bel-Pl intervals.</p>
</dd>
<dt>Time</dt><dd><p>A matrix of size (3,5) containing the computing time as returned by function <code>proctime</code>
for (1) the parameter estimation and bootstrap, (2) the computation fo the quantiles on pairwise 
probabilities, and (3) the computation of the credal partition.</p>
</dd>
</dl>



<h3>References</h3>

<p>T. Denoeux. Calibrated model-based evidential clustering using bootstrapping. 
Information Sciences, Vol. 528, pages 17-45, 2020.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ecm">ecm</a></code>, <code><a href="#topic+recm">recm</a></code>,
<code><a href="#topic+cecm">cecm</a></code>, <code><a href="#topic+kevclus">kevclus</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example with the Faithful geyser data
## Not run: 
data("faithful")
X&lt;-faithful
param=list(G=3)
res.faithful&lt;-bootclus(X,conf=0.90,B=100,param=param)
## Plot the results
plot(res.faithful$Clus,X)

## End(Not run)
</code></pre>

<hr>
<h2 id='bpec'>Belief Peak Evidential Clustering (BPEC)</h2><span id='topic+bpec'></span>

<h3>Description</h3>

<p><code>bpec</code> computes a credal partition from a matrix of attribute data using the
Belief Peak Evidential Clustering (BPEC) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bpec(
  x,
  g,
  type = "full",
  pairs = NULL,
  Omega = TRUE,
  alpha = 1,
  beta = 2,
  delta = 10,
  epsi = 0.001,
  disp = TRUE,
  distance = 1,
  m0 = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="bpec_+3A_x">x</code></td>
<td>
<p>input matrix of size n x d, where n is the number of objects and d the number of
attributes.</p>
</td></tr>
<tr><td><code id="bpec_+3A_g">g</code></td>
<td>
<p>Matrix of size c x d of prototypes (the belief peaks).</p>
</td></tr>
<tr><td><code id="bpec_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: empty set, singletons and Omega;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all
or selected pairs).</p>
</td></tr>
<tr><td><code id="bpec_+3A_pairs">pairs</code></td>
<td>
<p>Set of pairs to be included in the focal sets; if NULL, all pairs are
included. Used only if type=&quot;pairs&quot;.</p>
</td></tr>
<tr><td><code id="bpec_+3A_omega">Omega</code></td>
<td>
<p>Logical. If TRUE (default), the whole frame is included (for types 'simple' and
'pairs').</p>
</td></tr>
<tr><td><code id="bpec_+3A_alpha">alpha</code></td>
<td>
<p>Exponent of the cardinality in the cost function.</p>
</td></tr>
<tr><td><code id="bpec_+3A_beta">beta</code></td>
<td>
<p>Exponent of masses in the cost function.</p>
</td></tr>
<tr><td><code id="bpec_+3A_delta">delta</code></td>
<td>
<p>Distance to the empty set.</p>
</td></tr>
<tr><td><code id="bpec_+3A_epsi">epsi</code></td>
<td>
<p>Minimum amount of improvement.</p>
</td></tr>
<tr><td><code id="bpec_+3A_disp">disp</code></td>
<td>
<p>If TRUE (default), intermediate results are displayed.</p>
</td></tr>
<tr><td><code id="bpec_+3A_distance">distance</code></td>
<td>
<p>Type of distance use: 0=Euclidean, 1=Mahalanobis.</p>
</td></tr>
<tr><td><code id="bpec_+3A_m0">m0</code></td>
<td>
<p>Initial credal partition. Should be a matrix with n rows and a number of
columns equal to the number f of focal sets specified by 'type' and 'pairs'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>BPEC is identical to ECM, except that the prototypes are computed from delta-Bel graph using function
<code>delta_Bel</code>. The ECM algorithm is then run keeping the prototypes fixed. The distance to the 
prototypes can be the Euclidean disatnce or it can be an adaptive Mahalanobis distance as in the CECM
algorithm.
</p>


<h3>Value</h3>

<p>The credal partition (an object of class <code>"credpart"</code>).
</p>


<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>Z.-G. Su and T. Denoeux. BPEC: Belief-Peaks Evidential Clustering. IEEE Transactions 
on Fuzzy Systems, 27(1):111-123, 2019.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ecm">ecm</a></code>, <code><a href="#topic+cecm">cecm</a></code>, <code><a href="#topic+delta_Bel">delta_Bel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Clustering of the Four-class dataset
## Not run: 
data(fourclass)
x&lt;-fourclass[,1:2]
y&lt;-fourclass[,3]
DB&lt;-delta_Bel(x,100,0.9)
plot(x,pch=".")
points(DB$g0,pch=3,col="red",cex=2)
clus&lt;-bpec(x,DB$g0,type='pairs',delta=3,distance=1)
plot(clus,x,mfrow=c(2,2))

## End(Not run)
</code></pre>

<hr>
<h2 id='butterfly'>Butterfly dataset</h2><span id='topic+butterfly'></span>

<h3>Description</h3>

<p>A toy dataset used to illustrate fuzzy and evidential clustering algorithms. Also called
the 'Diamond' dataset. Adapted from Windham (1985), with one outlier added.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(butterfly)
</code></pre>


<h3>Format</h3>

<p>A matrix with 12 rows and 2 column.
</p>


<h3>References</h3>

<p>M.P. Windham. Numerical classification of proximity data with assignment measures.
Journal of classification, 2:157-172, 1985.
</p>
<p>M.-H. Masson and T. Denoeux. ECM: An evidential version of the fuzzy c-means algorithm.
Pattern Recognition, Vol. 41, Issue 4, pages 1384-1397, 2008.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(butterfly)
plot(butterfly[,1],butterfly[,2],xlab=expression(x[1]),ylab=expression(x[2]))
</code></pre>

<hr>
<h2 id='cecm'>Constrained Evidential c-means algorithm</h2><span id='topic+cecm'></span>

<h3>Description</h3>

<p><code>cecm</code> computes a credal partition from a matrix of attribute data and
pairwise constraints using the Constrained Evidential c-means (CECM) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cecm(
  x,
  c,
  type = "full",
  pairs = NULL,
  ntrials = 1,
  ML,
  CL,
  g0 = NULL,
  alpha = 1,
  delta = 10,
  xi = 0.5,
  distance = 0,
  epsi = 0.001,
  disp = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cecm_+3A_x">x</code></td>
<td>
<p>input matrix of size n x d, where n is the number of objects and d the number of
attributes.</p>
</td></tr>
<tr><td><code id="cecm_+3A_c">c</code></td>
<td>
<p>Number of  clusters.</p>
</td></tr>
<tr><td><code id="cecm_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: empty set, singletons and Omega;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all or selected pairs).</p>
</td></tr>
<tr><td><code id="cecm_+3A_pairs">pairs</code></td>
<td>
<p>Set of pairs to be included in the focal sets; if NULL, all pairs are
included. Used only if type=&quot;pairs&quot;.</p>
</td></tr>
<tr><td><code id="cecm_+3A_ntrials">ntrials</code></td>
<td>
<p>Number of runs of the optimization algorithm (set to 1 if <code>g0</code> is  supplied).</p>
</td></tr>
<tr><td><code id="cecm_+3A_ml">ML</code></td>
<td>
<p>Matrix nbML x 2 of must-link constraints. Each row of ML contains the indices
of objects that belong to the same class.</p>
</td></tr>
<tr><td><code id="cecm_+3A_cl">CL</code></td>
<td>
<p>Matrix nbCL x 2 of cannot-link constraints. Each row of CL contains the indices
of objects that belong to different classes.</p>
</td></tr>
<tr><td><code id="cecm_+3A_g0">g0</code></td>
<td>
<p>Initial prototypes, matrix of size c x d. If not supplied, the prototypes are
initialized randomly.</p>
</td></tr>
<tr><td><code id="cecm_+3A_alpha">alpha</code></td>
<td>
<p>Exponent of the cardinality in the cost function.</p>
</td></tr>
<tr><td><code id="cecm_+3A_delta">delta</code></td>
<td>
<p>Distance to the empty set.</p>
</td></tr>
<tr><td><code id="cecm_+3A_xi">xi</code></td>
<td>
<p>Tradeoff between the objective function Jecm and the constraints:
Jcecm=(1-xi)Jecm + xi Jconst.</p>
</td></tr>
<tr><td><code id="cecm_+3A_distance">distance</code></td>
<td>
<p>Type of distance use: 0=Euclidean, 1=Mahalanobis.</p>
</td></tr>
<tr><td><code id="cecm_+3A_epsi">epsi</code></td>
<td>
<p>Minimum amount of improvement.</p>
</td></tr>
<tr><td><code id="cecm_+3A_disp">disp</code></td>
<td>
<p>If TRUE (default), intermediate results are displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>CECM is a version of ECM allowing the user to specify pairwise constraints to guide
the clustering process. Pairwise constraints are of two kinds: must-link contraints are
pairs of objects that are known to belong to the same class, and cannot-link constraints
are pairs of objects that are known to belong to different classes. CECM can also learn
a metric for each cluster, like the Gustafson-Kessel algorithm in fuzzy clustering.
At each iteration, the algorithm solves a quadratic programming problem using an
interior ellipsoidal trust region and barrier function algorithm with dual solution
updating technique in the standard QP form (Ye, 1992).
</p>
<p>If  initial prototypes <code>g0</code> are provided, the number of trials is automatically set to 1.
</p>
<p>Remark: Due to the use of the Matrix package, messages may be generated by R's (S4) method
dispatch mechanism. They are not error messages, and they can be ignored.
</p>


<h3>Value</h3>

<p>The credal partition (an object of class <code>"credpart"</code>).
</p>


<h3>Author(s)</h3>

<p>Thierry Denoeux (from a MATLAB code written by Violaine Antoine).
</p>


<h3>References</h3>

<p>V. Antoine, B. Quost, M.-H. Masson and T. Denoeux. CECM: Constrained
Evidential C-Means algorithm. Computational Statistics and Data Analysis, Vol. 56,
Issue 4, pages 894&ndash;914, 2012. 
</p>
<p>Y. Ye. On affine-scaling algorithm for nonconvex quadratic programming.
Math. Programming 56 (1992) 285&ndash;300.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+create_MLCL">create_MLCL</a></code>, <code><a href="#topic+makeF">makeF</a></code>, <code><a href="#topic+extractMass">extractMass</a></code>,
<code><a href="#topic+ecm">ecm</a></code>, <code><a href="#topic+recm">recm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generation of a two-class dataset
## Not run: 
n&lt;-30
x&lt;-cbind(0.2*rnorm(n),rnorm(n))
y&lt;-c(rep(1,n/2),rep(2,n/2))
x[(n/2+1):n,1]&lt;-x[(n/2+1):n,1]+1
plot(x[,1],x[,2],asp=1,pch=y,col=y)
## Generation of 10 constraints
const&lt;-create_MLCL(y,nbConst=10)
## Call of cecm
clus&lt;-cecm(x=x,c=2,ML=const$M,CL=const$CL,delta=10)
plot(x[,1],x[,2],asp=1,pch=clus$y.pl,col=y)

## End(Not run)
</code></pre>

<hr>
<h2 id='create_fuzzy_credpart'>Creation of a &quot;credpart&quot; object from a from a fuzzy or possibilistic partition matrix</h2><span id='topic+create_fuzzy_credpart'></span>

<h3>Description</h3>

<p><code>create_fuzzy_credpart</code> creates a &quot;credpart&quot; object from a fuzzy or possibilistic partition matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_fuzzy_credpart(U)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_fuzzy_credpart_+3A_u">U</code></td>
<td>
<p>A fuzzy or possibilistic partition matrix of size n*c, wheer c is the nmber of clusters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;credpart&quot;.
</p>


<h3>References</h3>

<p>T. Denoeux, S. Li and S. Sriboonchitta. Evaluating and Comparing Soft Partitions: an 
Approach Based on Dempster-Shafer Theory. IEEE Transactions on Fuzzy Systems, 
26(3):1231-1244, 2018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extractMass">extractMass</a></code>,<code><a href="#topic+create_hard_credpart">create_hard_credpart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(fclust)
U&lt;-FKM(fourclass[,1:2],4)$U
clus&lt;-create_fuzzy_credpart(U)
summary(clus)

## End(Not run)
</code></pre>

<hr>
<h2 id='create_hard_credpart'>Creation of a &quot;credpart&quot; object from a vector of class labels</h2><span id='topic+create_hard_credpart'></span>

<h3>Description</h3>

<p><code>create_hard_credpart</code> creates a &quot;credpart&quot; object from a vector of class labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_hard_credpart(y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_hard_credpart_+3A_y">y</code></td>
<td>
<p>A vector of class labels.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class &quot;credpart&quot;.
</p>


<h3>References</h3>

<p>T. Denoeux, S. Li and S. Sriboonchitta. Evaluating and Comparing Soft Partitions: an 
Approach Based on Dempster-Shafer Theory. IEEE Transactions on Fuzzy Systems, 
26(3):1231-1244, 2018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extractMass">extractMass</a></code>, <code><a href="#topic+create_fuzzy_credpart">create_fuzzy_credpart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(fourclass)
y&lt;-kmeans(fourclass[,1:2],4)$cluster
clus&lt;-create_hard_credpart(y)
summary(clus)

## End(Not run)
</code></pre>

<hr>
<h2 id='create_MLCL'>Random generation of Must-Link and Cannot-Link constraints</h2><span id='topic+create_MLCL'></span>

<h3>Description</h3>

<p><code>create_MLCL</code> randomly generates Must-Link (ML) and Cannot-Link (CL) constraints from a vector y
of class labels.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_MLCL(y, nbConst)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="create_MLCL_+3A_y">y</code></td>
<td>
<p>Vector of class labels.</p>
</td></tr>
<tr><td><code id="create_MLCL_+3A_nbconst">nbConst</code></td>
<td>
<p>Number of constraints.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two components:
</p>

<dl>
<dt>ML</dt><dd><p>Matrix of ML constraints. Each row corresponds to a constraint.</p>
</dd>
<dt>CL</dt><dd><p>Matrix of ML constraints. Each row corresponds to a constraint.</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+cecm">cecm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y&lt;-sample(3,100,replace=TRUE)
const&lt;-create_MLCL(y,nbConst=10)
const$ML
const$CL

</code></pre>

<hr>
<h2 id='createD'>Computation of a  Euclidean distance matrix</h2><span id='topic+createD'></span>

<h3>Description</h3>

<p><code>createD</code> constructs an n x k matrix of Euclidean distances from an n x p matrix
of attribute data. For each object, the distances to k randomly selected objects are
computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createD(x, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createD_+3A_x">x</code></td>
<td>
<p>n x p data matrix.</p>
</td></tr>
<tr><td><code id="createD_+3A_k">k</code></td>
<td>
<p>Number of distances. If missing, an n x n distance matrix is computed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with two elements:
</p>

<dl>
<dt>D</dt><dd><p>n x k distance matrix.</p>
</dd>
<dt>J</dt><dd><p>n x k matrix of indices. D[i,j] is the Euclidean distance between x[i,] and
x[J[i,j],].</p>
</dd>
</dl>



<h3>See Also</h3>

<p><code><a href="#topic+kevclus">kevclus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(fourclass)
x&lt;-as.matrix(fourclass[,1:2])
dist&lt;-createD(x,k=10)
dim(dist$D)
dim(dist$J)

</code></pre>

<hr>
<h2 id='createPairs'>Finding overlapping pairs of clusters</h2><span id='topic+createPairs'></span>

<h3>Description</h3>

<p><code>createPairs</code> finds pairs of clusters that are mutual k nearest neighbors
in a credal partition. The similarity between two clusters k and l is defined as
<code class="reqn">\sum_{i=1}^n pl_{ik} pl_{il}</code>, where <code class="reqn">pl_{ik}</code> is the plausibility of object i belonging to
cluster k.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>createPairs(clus, k = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="createPairs_+3A_clus">clus</code></td>
<td>
<p>An object of class <code>credpart</code>. It should contain at
least two fields: clus$mass (the credal partition) and clus$pl.n (the normalized
plausibilities). The focal sets of the credal partition must be the empty set,
the singletons, and (optionally) the whole set of clusters.</p>
</td></tr>
<tr><td><code id="createPairs_+3A_k">k</code></td>
<td>
<p>The number of neighbors.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function allows one to use evidential clustering when the number of clusters
is large. A clustering algorithm is first run with a limited number
of focal sets (the empty set, the singletons and, optionally, the whole frame). Then,
the similarity between clusters is analysed to determine the pairs of neighboring
(overlapping) clusters. The clustering algorithm is then run again, adding these
pairs to the focal sets (see the example). The focal sets of the passed credal partition must be
the empty set (first row), the singletons (next c rows) and, optionally, the whole frame
(last row).
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>

<dl>
<dt>pairs</dt><dd><p>A matrix with two columns and p rows, containing the p pairs of
clusters. This matrix can be passed to <code><a href="#topic+ecm">ecm</a></code>, <code><a href="#topic+recm">recm</a></code>,
<code><a href="#topic+cecm">cecm</a></code> or <code><a href="#topic+kevclus">kevclus</a></code>.</p>
</dd>
<dt>m0</dt><dd><p>A  matrix of size (n,c+2+p), encoding the credal partition. The masses
assigned to the pairs are null.</p>
</dd>
<dt>S</dt><dd><p>The c x c matrix of similarities between clusters.</p>
</dd>
</dl>



<h3>References</h3>

<p>T. Denoeux, S. Sriboonchitta and O. Kanjanatarakul. Evidential clustering of large
dissimilarity data. Knowledge-Based Systems, vol. 106, pages 179-195, 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extractMass">extractMass</a></code>, <code><a href="#topic+ecm">ecm</a></code>, <code><a href="#topic+recm">recm</a></code>,
<code><a href="#topic+cecm">cecm</a></code>, <code><a href="#topic+kevclus">kevclus</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example with Four-class data
data("fourclass")
x&lt;-fourclass[,1:2]
y&lt;-fourclass[,3]
c=4
## Running k-EVCLUS with singletons
clus&lt;-kevclus(x=x,k=100,c=c,type='simple')
## Plot the results
plot(clus,X=x,mfrow=c(2,2),ytrue=y)
## Creating the pairs of clusters
P&lt;-createPairs(clus,k=2)
## Running k-EVCLUS again, with pairs of clusters
clus1&lt;-kevclus(x=x,k=100,c=c,type='pairs',pairs=P$pairs,m0=P$m0)
## Plot the results
plot(clus1,X=x,mfrow=c(2,2),ytrue=y)
</code></pre>

<hr>
<h2 id='credal_RI'>Credal Rand indices</h2><span id='topic+credal_RI'></span>

<h3>Description</h3>

<p><code>credal_RI</code> computes generalizations of the Rand index to compare credal partitions, as defined 
in Denoeux et al (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>credal_RI(P1, P2, type = "c")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="credal_RI_+3A_p1">P1</code></td>
<td>
<p>Relational representation of the first credal partition such as generated
by function <code>pairwise_mass</code></p>
</td></tr>
<tr><td><code id="credal_RI_+3A_p2">P2</code></td>
<td>
<p>Relational representation of the second credal partition such as generated
by function <code>pairwise_mass</code></p>
</td></tr>
<tr><td><code id="credal_RI_+3A_type">type</code></td>
<td>
<p>&quot;c&quot; for degree of conflict (default), &quot;j&quot; for Jousselme's distance and &quot;b&quot; for 
belief distance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In Denoeux et al. (2018), two generalizations of the Rand index for comparing credal partitions
are defined: one is based on distances between mass function, the other one is based on distances.
In the latter case, two distances are proposed: Jousselme's distance and the L1 distance between 
belief functions. These three indices can be computed by function <code>credal_RI</code>.
</p>


<h3>Value</h3>

<p>The credal Rand index
</p>


<h3>References</h3>

<p>T. Denoeux, S. Li and S. Sriboonchitta. Evaluating and Comparing Soft Partitions: an 
Approach Based on Dempster-Shafer Theory. IEEE Transactions on Fuzzy Systems, 
26(3):1231-1244, 2018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nonspecificity">nonspecificity</a></code>, <code><a href="#topic+pairwise_mass">pairwise_mass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Butterfly data
data(butterfly)
clus1&lt;-kevclus(butterfly,c=2) 
P1&lt;-pairwise_mass(clus1)
clus2&lt;-ecm(butterfly,c=2)
P2&lt;-pairwise_mass(clus2)
RI1&lt;-credal_RI(P1,P2,"c")
RI2&lt;-credal_RI(P1,P2,"j")
RI3&lt;-credal_RI(P1,P2,"b")
print(c(RI1,RI2,RI3))

</code></pre>

<hr>
<h2 id='delta_Bel'>Delta-Bel graph for Belief Peak Evidential Clustering (BPEC)</h2><span id='topic+delta_Bel'></span>

<h3>Description</h3>

<p><code>delta_Bel</code> computes the delta-Bel graph used to determine the proptotypes in the
Belief Peak Evidential Clustering (BPEC) algorithm. The user must manually specify the rectangles 
containing the protytypes (which are typically in the upper-right corner of the graph is the clusters
are well-seperated). These prototypes are then used by function <code>bpec</code> to compute a credal 
partition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>delta_Bel(x, K, q = 0.9)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="delta_Bel_+3A_x">x</code></td>
<td>
<p>input matrix of size n x d, where n is the number of objects and d the number of
attributes.</p>
</td></tr>
<tr><td><code id="delta_Bel_+3A_k">K</code></td>
<td>
<p>Number of neighbors to determine belief values</p>
</td></tr>
<tr><td><code id="delta_Bel_+3A_q">q</code></td>
<td>
<p>Parameter of the algorithm, between 0 and 1 (default: 0.9).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with three elements:
</p>

<dl>
<dt>BelC</dt><dd><p>The belief values.</p>
</dd>
<dt>delta</dt><dd><p>The delta values.</p>
</dd>
<dt>g0</dt><dd><p>A c*d matrix containing the prototypes.</p>
</dd>
<dt>ii</dt><dd><p>List of indices of the belief peaks.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Thierry Denoeux .
</p>


<h3>References</h3>

<p>Z.-G. Su and T. Denoeux. BPEC: Belief-Peaks Evidential Clustering. IEEE Transactions 
on Fuzzy Systems, 27(1):111-123, 2019.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+bpec">bpec</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(fourclass)
x&lt;-fourclass[,1:2]
y&lt;-fourclass[,3]
DB&lt;-delta_Bel(x,100,0.9)
plot(x,pch=".")
points(DB$g0,pch=3,col="red",cex=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='ecm'>Evidential c-means algorithm</h2><span id='topic+ecm'></span>

<h3>Description</h3>

<p><code>ecm</code> computes a credal partition from a matrix of attribute data using the
Evidential c-means (ECM) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ecm(
  x,
  c,
  g0 = NULL,
  type = "full",
  pairs = NULL,
  Omega = TRUE,
  ntrials = 1,
  alpha = 1,
  beta = 2,
  delta = 10,
  epsi = 0.001,
  init = "kmeans",
  disp = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ecm_+3A_x">x</code></td>
<td>
<p>input matrix of size n x d, where n is the number of objects and d the number of
attributes.</p>
</td></tr>
<tr><td><code id="ecm_+3A_c">c</code></td>
<td>
<p>Number of  clusters.</p>
</td></tr>
<tr><td><code id="ecm_+3A_g0">g0</code></td>
<td>
<p>Initial prototypes, matrix of size c x d. If not supplied, the prototypes are
initialized randomly.</p>
</td></tr>
<tr><td><code id="ecm_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: empty set, singletons and Omega;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all
or selected pairs).</p>
</td></tr>
<tr><td><code id="ecm_+3A_pairs">pairs</code></td>
<td>
<p>Set of pairs to be included in the focal sets; if NULL, all pairs are
included. Used only if type=&quot;pairs&quot;.</p>
</td></tr>
<tr><td><code id="ecm_+3A_omega">Omega</code></td>
<td>
<p>Logical. If TRUE (default), the whole frame is included (for types 'simple' and
'pairs').</p>
</td></tr>
<tr><td><code id="ecm_+3A_ntrials">ntrials</code></td>
<td>
<p>Number of runs of the optimization algorithm (set to 1 if m0 is  supplied).</p>
</td></tr>
<tr><td><code id="ecm_+3A_alpha">alpha</code></td>
<td>
<p>Exponent of the cardinality in the cost function.</p>
</td></tr>
<tr><td><code id="ecm_+3A_beta">beta</code></td>
<td>
<p>Exponent of masses in the cost function.</p>
</td></tr>
<tr><td><code id="ecm_+3A_delta">delta</code></td>
<td>
<p>Distance to the empty set.</p>
</td></tr>
<tr><td><code id="ecm_+3A_epsi">epsi</code></td>
<td>
<p>Minimum amount of improvement.</p>
</td></tr>
<tr><td><code id="ecm_+3A_init">init</code></td>
<td>
<p>Initialization: &quot;kmeans&quot; (default) or &quot;rand&quot; (random).</p>
</td></tr>
<tr><td><code id="ecm_+3A_disp">disp</code></td>
<td>
<p>If TRUE (default), intermediate results are displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>ECM is an evidential version algorithm of the Hard c-Means (HCM) and Fuzzy c-Means (FCM)
algorithms. As in HCM and FCM, each cluster is represented by a prototype. However, in ECM,
some sets of clusters are also represented by a prototype, which is defined as the center of mass
of the prototypes in each individual cluster. The algorithm iteratively optimizes a cost
function, with respect to the prototypes and to the credal partition. By default, each mass
function in the credal partition has <code class="reqn">2^c</code> focal sets, where c is the supplied number of
clusters. We can also limit the number of focal sets to
subsets of clusters with cardinalities 0, 1 and c (recommended if c&gt;=10), or to all or some
selected pairs of clusters.
If  initial prototypes g0 are provided, the number of trials is automatically set to 1.
</p>


<h3>Value</h3>

<p>The credal partition (an object of class <code>"credpart"</code>).
</p>


<h3>Author(s)</h3>

<p>Thierry Denoeux (from a MATLAB code written by Marie-Helene Masson).
</p>


<h3>References</h3>

<p>M.-H. Masson and T. Denoeux. ECM: An evidential version of the fuzzy
c-means algorithm. Pattern Recognition, Vol. 41, Issue 4, pages 1384&ndash;1397, 2008.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makeF">makeF</a></code>, <code><a href="#topic+extractMass">extractMass</a></code>, <code><a href="#topic+recm">recm</a></code>, <code><a href="#topic+cecm">cecm</a></code>,
<code><a href="#topic+plot.credpart">plot.credpart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Clustering of the Four-class dataset
## Not run: 
data(fourclass)
x&lt;-fourclass[,1:2]
y&lt;-fourclass[,3]
clus&lt;-ecm(x,c=4,type='full',alpha=1,beta=2,delta=sqrt(20),epsi=1e-3,disp=TRUE)
plot(clus,X=x,mfrow=c(2,2),ytrue=y,Outliers=TRUE,Approx=2)

## End(Not run)
</code></pre>

<hr>
<h2 id='EkNNclus'>EkNNclus algorithm</h2><span id='topic+EkNNclus'></span>

<h3>Description</h3>

<p><code>EkNNclus</code> computes hard and credal partitions from dissimilarity or attribute
data using the EkNNclus algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>EkNNclus(
  x = NULL,
  D,
  K,
  y0,
  ntrials = 1,
  q = 0.5,
  b = 1,
  disp = TRUE,
  tr = FALSE,
  eps = 1e-06
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="EkNNclus_+3A_x">x</code></td>
<td>
<p>n x p data matrix (n instances, p attributes).</p>
</td></tr>
<tr><td><code id="EkNNclus_+3A_d">D</code></td>
<td>
<p>n x n dissimilarity matrix (used only if x is not supplied).</p>
</td></tr>
<tr><td><code id="EkNNclus_+3A_k">K</code></td>
<td>
<p>Number of neighbors.</p>
</td></tr>
<tr><td><code id="EkNNclus_+3A_y0">y0</code></td>
<td>
<p>Initial partition (vector of length n, with values in (1,2,...)).</p>
</td></tr>
<tr><td><code id="EkNNclus_+3A_ntrials">ntrials</code></td>
<td>
<p>Number of runs of the algorithm (the best solution is kept).</p>
</td></tr>
<tr><td><code id="EkNNclus_+3A_q">q</code></td>
<td>
<p>Parameter in (0,1). Gamma is set to the inverse of the q-quantile of distances
from the K nearest neighbors (same notation as in the paper).</p>
</td></tr>
<tr><td><code id="EkNNclus_+3A_b">b</code></td>
<td>
<p>Exponent of distances, <code class="reqn">\alpha_{ij} = \phi(d_{ij}^b)</code>.</p>
</td></tr>
<tr><td><code id="EkNNclus_+3A_disp">disp</code></td>
<td>
<p>If TRUE, intermediate results are displayed.</p>
</td></tr>
<tr><td><code id="EkNNclus_+3A_tr">tr</code></td>
<td>
<p>If TRUE, a trace of the cost function is returned.</p>
</td></tr>
<tr><td><code id="EkNNclus_+3A_eps">eps</code></td>
<td>
<p>Minimal distance between two vectors (distances smaller than <code>eps</code>
are replaced by <code>eps</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The number of clusters is not specified. It is influenced by parameters K and q.
(It is advised to start with the default values.) For n not too large (say, until one
thousand), y0 can be defined as the vector (1,2,...,n). For larger values of n, it is
advised to start with a random partition of c clusters, c&lt;n.
</p>


<h3>Value</h3>

<p>The credal partition (an object of class <code>"credpart"</code>). In addition to the
usual attributes, the output credal partition has the following attributes:
</p>

<dl>
<dt>trace</dt><dd><p>Trace of the algorithm (sequence of values of the cost function).</p>
</dd>
<dt>W</dt><dd><p>The weight matrix.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>T. Denoeux, O. Kanjanatarakul and S. Sriboonchitta.
EK-NNclus: a clustering procedure based on the evidential K-nearest neighbor rule.
Knowledge-Based Systems, Vol. 88, pages 57&ndash;69, 2015.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Clustering of the fourclass dataset
## Not run: 
data(fourclass)
n&lt;-nrow(fourclass)
N=2
clus&lt;- EkNNclus(fourclass[,1:2],K=60,y0=(1:n),ntrials=N,q=0.9,b=2,disp=TRUE,tr=TRUE)
## Plot of the partition
plot(clus,X=fourclass[,1:2],ytrue=fourclass$y,Outliers=FALSE,plot_approx=FALSE)
## Plot of the cost function vs number of iteration
L&lt;-vector(length=N)
for(i in 1:N) L[i]&lt;-dim(clus$trace[clus$trace[,1]==i,])[1]
imax&lt;-which.max(L)
plot(0:(L[imax]-1),-clus$trace[clus$trace[,1]==imax,3],type="l",lty=imax,
xlab="time steps",ylab="energy")
for(i in (1:N)) if(i != imax) lines(0:(L[i]-1),-clus$trace[clus$trace[,1]==i,3],
type="l",lty=i)

## End(Not run)
</code></pre>

<hr>
<h2 id='evclust'>evclust: A package for evidential clustering</h2><span id='topic+evclust'></span><span id='topic+evclust-package'></span>

<h3>Description</h3>

<p>Various clustering algorithms that generate a credal partition, i.e., a set of mass
functions. Mass functions quantify the cluster-membership uncertainty of the objects.
The package consists in the following main functions, implementing different evidential
clustering algorithms:
</p>

<dl>
<dt>ecm</dt><dd><p>Evidential c-means algorithm (Masson and Denoeux, 2008)</p>
</dd>
<dt>recm</dt><dd><p>Relational Evidential c-means algorithm (Masson and Denoeux, 2009)</p>
</dd>
<dt>kevclus</dt><dd><p>$k$-EVCLUS algorithm (Denoeux and Masson, 2004; Denoeux et al., 2016) </p>
</dd>
<dt>EkNNclus</dt><dd><p>E$k$-NNclus algorithm (Denoeux et al., 2015)</p>
</dd>
<dt>cecm</dt><dd><p>Constrained Evidential c-means algorithm (Antoine et al, 2012)</p>
</dd>
<dt>kcevclus</dt><dd><p>Constrained evidential clustering (Antoine et al., 2014; Li et al., 2018)</p>
</dd>
<dt>bpec</dt><dd><p>Belief peak evidential clustering (Su and Denoeux, 2019)</p>
</dd>
<dt>nnevclus</dt><dd><p>Neural-network based evidential clustering (Denoeux, 2020a)</p>
</dd>
<dt>nnevclus_mb</dt><dd><p>Neural-network based evidential clustering, minibatch version 
(Denoeux, 2020a)</p>
</dd>
<dt>bootclus</dt><dd><p>Model-based evidential clustering using bootstrapping 
(Denoeux, 2020b)</p>
</dd>
</dl>



<h3>References</h3>

<p>V. Antoine, B. Quost, M.-H. Masson and T. Denoeux. CECM: Constrained
Evidential C-Means algorithm. Computational Statistics and Data Analysis, Vol. 56,
Issue 4, pages 894&ndash;914, 2012.
</p>
<p>T. Denoeux and M.-H. Masson. EVCLUS: Evidential Clustering of Proximity Data.
IEEE Transactions on Systems, Man and Cybernetics B, Vol. 34, Issue 1, 95&ndash;109, 2004.
</p>
<p>T. Denoeux, O. Kanjanatarakul and S. Sriboonchitta.
EK-NNclus: a clustering procedure based on the evidential K-nearest neighbor rule.
Knowledge-Based Systems, Vol. 88, pages 57&ndash;69, 2015.
</p>
<p>T. Denoeux, S. Sriboonchitta and O. Kanjanatarakul. Evidential clustering of large
dissimilarity data. Knowledge-Based Systems, vol. 106, pages 179-195, 2016.
</p>
<p>M.-H. Masson and T. Denoeux. ECM: An evidential version of the fuzzy c-means algorithm.
Pattern Recognition, Vol. 41, Issue 4, pages 1384&ndash;1397, 2008.
</p>
<p>M.-H. Masson and T. Denoeux. RECM: Relational Evidential c-means algorithm.
Pattern Recognition Letters, Vol. 30, pages 1015&ndash;1026, 2009.
</p>
<p>V. Antoine, B. Quost, M.-H. Masson and T. Denoeux. CEVCLUS: Evidential clustering 
with instance-level constraints for relational data. Soft Computing 18(7):1321-1335, 2014.
</p>
<p>F. Li, S. Li and T. Denoeux. k-CEVCLUS: Constrained evidential clustering of 
large dissimilarity data. Knowledge-Based Systems 142:29-44, 2018.
</p>
<p>Z.-G. Su and T. Denoeux. BPEC: Belief-Peaks Evidential Clustering. IEEE Transactions 
on Fuzzy Systems, 27(1):111-123, 2019.
</p>
<p>T. Denoeux. NN-EVCLUS: Neural Network-based Evidential Clustering. 
arXiv:2009.12795, 2020a.
</p>
<p>T. Denoeux. Calibrated model-based evidential clustering using bootstrapping. 
Information Sciences, Vol. 528, pages 17-45, 2020b.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ecm">ecm</a></code>, <code><a href="#topic+recm">recm</a></code>,
<code><a href="#topic+cecm">cecm</a></code>, <code><a href="#topic+kevclus">kevclus</a></code>, <code><a href="#topic+EkNNclus">EkNNclus</a></code>, 
<code><a href="#topic+kcevclus">kcevclus</a></code>, <code><a href="#topic+bpec">bpec</a></code>, <code><a href="#topic+nnevclus">nnevclus</a></code>, 
<code><a href="#topic+nnevclus_mb">nnevclus_mb</a></code>, <code><a href="#topic+bootclus">bootclus</a></code>.
</p>

<hr>
<h2 id='expandlink'>Expansion of must-link and cannot-link constraints</h2><span id='topic+expandlink'></span>

<h3>Description</h3>

<p><code>expandlink</code> returns an expanded set of must-link and cannot-link constraints using the
k nearest neighbors of each observation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>expandlink(link, ind, distan)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="expandlink_+3A_link">link</code></td>
<td>
<p>A list with two attributes: a matrix ML containing nbML x 2 must-link constraints
and a matrix CL containing nbCL x 2 cannot-link constraints.</p>
</td></tr>
<tr><td><code id="expandlink_+3A_ind">ind</code></td>
<td>
<p>An n*k matrix containing the k nearest neighbor indices.</p>
</td></tr>
<tr><td><code id="expandlink_+3A_distan">distan</code></td>
<td>
<p>An n*k matrix containing the k nearest neighbor distances.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Using the algorithm described in Li et al (2018), <code>expandlink</code> generates new must-link and
cannot-link constraints from existing ones, using the k nearest neighbors of each observations. The
extended constraint list can be used by constrained clusetring algorithms such as <cite>cecm</cite> and
<code>kcevclus</code>.
</p>


<h3>Value</h3>

<p>A list with two attributes:
</p>

<dl>
<dt>ML</dt><dd><p>The new matrix of must-link constraints.</p>
</dd>
<dt>CL</dt><dd><p>The new matrix of cannot-link constraints.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Feng Li and Thierry Denoeux.
</p>


<h3>References</h3>

<p>F. Li, S. Li and T. Denoeux. k-CEVCLUS: Constrained evidential clustering of 
large dissimilarity data. Knowledge-Based Systems (142):29-44, 2018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kcevclus">kcevclus</a></code>,<code><a href="#topic+cecm">cecm</a></code>,<code><a href="#topic+create_MLCL">create_MLCL</a></code>,
<code><a href="#topic+bananas">bananas</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data&lt;-bananas(200)
link&lt;-create_MLCL(data$y,10)
nml&lt;-nrow(link$ML)
plot(data$x,col=data$y)
for(k in 1:nml) lines(data$x[link$ML[k,],1],data$x[link$ML[k,],2],lwd=2,col="red")
ncl&lt;-nrow(link$CL)
for(k in 1:ncl) lines(data$x[link$CL[k,],1],data$x[link$CL[k,],2],lwd=2,col="blue")
library(FNN)
nn&lt;-get.knn(data$x,5)
link1&lt;-expandlink(link,ind=nn$nn.index,distan=nn$nn.dist)
nml&lt;-nrow(link1$ML)
for(k in 1:nml) lines(data$x[link1$ML[k,],1],data$x[link1$ML[k,],2],lwd=1,lty=2,col="red")
ncl&lt;-nrow(link1$CL)
for(k in 1:ncl) lines(data$x[link1$CL[k,],1],data$x[link1$CL[k,],2],lwd=1,lty=2,col="blue")

## End(Not run)

</code></pre>

<hr>
<h2 id='extractMass'>Creates an object of class &quot;credpart&quot;</h2><span id='topic+extractMass'></span>

<h3>Description</h3>

<p><code>extractMass</code> computes different ouputs (hard, fuzzy, rough partions, etc.)
from a credal partition and creates an object of class &quot;credpart&quot;.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>extractMass(
  mass,
  F,
  g = NULL,
  S = NULL,
  method,
  crit = NULL,
  Kmat = NULL,
  trace = NULL,
  D = NULL,
  W = NULL,
  J = NULL,
  param = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="extractMass_+3A_mass">mass</code></td>
<td>
<p>A credal partition (a matrix of n rows and f columns, where n is the
number of objects and f is the number of focal sets).</p>
</td></tr>
<tr><td><code id="extractMass_+3A_f">F</code></td>
<td>
<p>Matrix (f,c) of focal sets. If the empty set is a focal set, it must correspond to
the first row of F.</p>
</td></tr>
<tr><td><code id="extractMass_+3A_g">g</code></td>
<td>
<p>A c x d matrix of prototypes.</p>
</td></tr>
<tr><td><code id="extractMass_+3A_s">S</code></td>
<td>
<p>A list of length f containing the matrices <code class="reqn">S_j</code> defining the metrics for each cluster and
each group of cluster.</p>
</td></tr>
<tr><td><code id="extractMass_+3A_method">method</code></td>
<td>
<p>The method used to construct the credal partition (a character string).</p>
</td></tr>
<tr><td><code id="extractMass_+3A_crit">crit</code></td>
<td>
<p>The value of the optimized criterion (depends on the method used).</p>
</td></tr>
<tr><td><code id="extractMass_+3A_kmat">Kmat</code></td>
<td>
<p>The matrix of degrees of conflict. Same size as D (for method <code><a href="#topic+kevclus">kevclus</a></code>).</p>
</td></tr>
<tr><td><code id="extractMass_+3A_trace">trace</code></td>
<td>
<p>The trace of criterion values  (for methods <code><a href="#topic+kevclus">kevclus</a></code> and
<code><a href="#topic+EkNNclus">EkNNclus</a></code>).</p>
</td></tr>
<tr><td><code id="extractMass_+3A_d">D</code></td>
<td>
<p>The normalized dissimilarity matrix (for method <code><a href="#topic+kevclus">kevclus</a></code>).</p>
</td></tr>
<tr><td><code id="extractMass_+3A_w">W</code></td>
<td>
<p>The weight matrix (for method <code><a href="#topic+EkNNclus">EkNNclus</a></code>).</p>
</td></tr>
<tr><td><code id="extractMass_+3A_j">J</code></td>
<td>
<p>The matrix of indices (for method <code><a href="#topic+kevclus">kevclus</a></code>).</p>
</td></tr>
<tr><td><code id="extractMass_+3A_param">param</code></td>
<td>
<p>A method-dependent list of parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function collects varied information on a credal partition and stores it in
an object of class &quot;credpart&quot;. The lower and upper
approximations of clusters define rough partitions. They can be computed in two ways:
either from the set of clusters with maximum mass, or from the set of non dominated clusters.
A cluster <code class="reqn">\omega_k</code> is non dominated if <code class="reqn">pl(\omega_k)\ge bel(\omega_l)</code> for
all l different from k. Once a set of cluster <code class="reqn">Y_i</code> has been computed for each object,
object i belongs to the lower approximation of cluster k if <code class="reqn">Y_i={\omega_k}</code>. It
belongs to the upper approximation of cluster k if <code class="reqn">\omega_k \in Y_i</code>. See
Masson and Denoeux (2008) for more details, and Denoeux and Kanjanatarakul (2016) for
the interval dominance rule. The function creates an object of class <code>"credpart"</code>.
There are three methods for this class: <code><a href="#topic+plot.credpart">plot.credpart</a></code>,
<code><a href="#topic+summary.credpart">summary.credpart</a></code> and <code><a href="#topic+predict.credpart">predict.credpart</a></code>.
</p>


<h3>Value</h3>

<p>An object of class &quot;credpart&quot;  with the following components:
</p>

<dl>
<dt>method</dt><dd><p>The method used to construct the credal partition (a character string).</p>
</dd>
<dt>F</dt><dd><p>Matrix of focal sets. The first row always corresponds to the empty set.</p>
</dd>
<dt>conf</dt><dd><p>Masses assigned to the empty set, vector of length n.</p>
</dd>
<dt>mass</dt><dd><p>Mass functions, matrix of size (n,f).</p>
</dd>
<dt>mass.n</dt><dd><p>Normalized mass functions, matrix of size (n,f-1).</p>
</dd>
<dt>g</dt><dd><p>The prototypes (if defined).</p>
</dd>
<dt>S</dt><dd><p>The matrices <code class="reqn">S_j</code> defining the metrics for each cluster and each group of cluster
(if defined).</p>
</dd>
<dt>pl</dt><dd><p>Unnormalized plausibilities of the singletons, matrix of size (n,c).</p>
</dd>
<dt>pl.n</dt><dd><p>Normalized plausibilities of the singletons, matrix of size (n,c).</p>
</dd>
<dt>p</dt><dd><p>Probabilities derived from pl by the plausibility transformation, matrix of size (n,c).</p>
</dd>
<dt>bel</dt><dd><p>Unnormalized beliefs of the singletons, matrix of size (n,c).</p>
</dd>
<dt>bel.n</dt><dd><p>Normalized beliefs of the singletons, matrix of size (n,c).</p>
</dd>
<dt>y.pl</dt><dd><p>Maximum plausibility clusters, vector of length n.</p>
</dd>
<dt>y.bel</dt><dd><p>Maximum belief clusters, vector of length n.</p>
</dd>
<dt>betp</dt><dd><p>Unnormalized pignistic probabilities of the singletons, matrix of size (n,c).</p>
</dd>
<dt>betp.n</dt><dd><p>Normalized pignistic probabilities of the singletons, matrix of size (n,c).</p>
</dd>
<dt>Y</dt><dd><p>Sets of clusters with maximum mass, matrix of size (n,c).</p>
</dd>
<dt>outlier</dt><dd><p>n-vector of 0's and 1's, indicating which objects are outliers. An outlier
is an object such that the largest mass is assigned to the empty set.</p>
</dd>
<dt>lower.approx</dt><dd><p>Lower approximations of clusters, a list of length c.
Each element lower.approx[[i]] is a vector of object indices.</p>
</dd>
<dt>upper.approx</dt><dd><p>Upper approximations of clusters, a list of length c.
Each element upper.approx[[i]] is a vector of object indices.</p>
</dd>
<dt>Ynd</dt><dd><p>Sets of clusters selected by the interval dominance rule, matrix of size (n,c).</p>
</dd>
<dt>lower.approx.nd</dt><dd><p>Lower approximations of clusters using the interval dominance rule,
a list of length c. Each element lower.approx.nd[[i]] is a vector of objects.</p>
</dd>
<dt>upper.approx.nd</dt><dd><p>Upper approximations of clusters using the interval dominance rule,
a list of length c. Each element upper.approx.nd[[i]] is a vector of objects.</p>
</dd>
<dt>N</dt><dd><p>Average nonspecificity.</p>
</dd>
<dt>crit</dt><dd><p>The value of the optimized criterion (depends on the method used).</p>
</dd>
<dt>Kmat</dt><dd><p>The matrix of degrees of conflict. Same size as D (for method <code><a href="#topic+kevclus">kevclus</a></code>).</p>
</dd>
<dt>D</dt><dd><p>The normalized dissimilarity matrix (for method <code><a href="#topic+kevclus">kevclus</a></code>).</p>
</dd>
<dt>trace</dt><dd><p>The trace of criterion values  (for methods <code><a href="#topic+kevclus">kevclus</a></code> and
<code><a href="#topic+EkNNclus">EkNNclus</a></code>).</p>
</dd>
<dt>W</dt><dd><p>The weight matrix (for method <code><a href="#topic+EkNNclus">EkNNclus</a></code>).</p>
</dd>
<dt>J</dt><dd><p>The matrix of indices (for method <code><a href="#topic+kevclus">kevclus</a></code>).</p>
</dd>
<dt>param</dt><dd><p>A method-dependent list of parameters.</p>
</dd>
</dl>



<h3>References</h3>

<p>T. Denoeux and O. Kanjanatarakul. Beyond Fuzzy, Possibilistic and Rough: An
Investigation of Belief Functions in Clustering. 8th International conference on soft
methods in probability and statistics, Rome, 12-14 September, 2016.
</p>
<p>M.-H. Masson and T. Denoeux. ECM: An evidential version of the fuzzy c-means algorithm.
Pattern Recognition, Vol. 41, Issue 4, pages 1384-1397, 2008.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.credpart">plot.credpart</a></code>, <code><a href="#topic+summary.credpart">summary.credpart</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Four-class data
data(fourclass)
x&lt;-fourclass[,1:2]
y&lt;-fourclass[,3]
D&lt;-as.matrix(dist(x))^2
clus&lt;-recm(D,c=4,delta=10,ntrials=1)
summary(clus)
plot(clus,X=x,mfrow=c(1,1),ytrue=y,Outliers=TRUE)

## End(Not run)
</code></pre>

<hr>
<h2 id='fourclass'>Synthetic four-class dataset</h2><span id='topic+fourclass'></span>

<h3>Description</h3>

<p>A synthetic dataset with two attributes and four classes of 100 points each,  generated from a
multivariate t distribution with five degrees of freedom and centered, respectively,
on [0;0], [0;4], [4;0] and [4;4].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(fourclass)
</code></pre>


<h3>Format</h3>

<p>A data frame with three variables: x1, x2 and y (the true class).
</p>


<h3>References</h3>

<p>M.-H. Masson and T. Denoeux. ECM: An evidential version of the fuzzy c-means algorithm.
Pattern Recognition, Vol. 41, Issue 4, pages 1384-1397, 2008.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(fourclass)
plot(fourclass$x1,fourclass$x2,xlab=expression(x[1]),ylab=expression(x[2]),
col=fourclass$y,pch=fourclass$y)
</code></pre>

<hr>
<h2 id='harris'>Harris gradient-based optimization algorithm</h2><span id='topic+harris'></span>

<h3>Description</h3>

<p>The optimization algorithm implemented in <code>harris</code> is described on Silva &amp; Almeida (1990) and
summarized in Denoeux &amp; Masson (2004). The four parameters are:
</p>

<dl>
<dt>options[1]</dt><dd><p>Display parameter : 1 (default) displays some results.</p>
</dd>
<dt>options[2]</dt><dd><p>Maximum number of iterations (default: 100).</p>
</dd>
<dt>options[3]</dt><dd><p>Relative error for stopping criterion (default: 1e-4).</p>
</dd>
<dt>options[4]</dt><dd><p>Number of iterations between two displays.</p>
</dd>
</dl>



<h3>Usage</h3>

<pre><code class='language-R'>harris(fun, x, options = c(1, 100, 1e-04, 10), tr = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="harris_+3A_fun">fun</code></td>
<td>
<p>Function to be optimized. The function 'fun' should return a scalar function value 'fun' 
and a vector 'grad' containing the partial derivatives of fun at x.</p>
</td></tr>
<tr><td><code id="harris_+3A_x">x</code></td>
<td>
<p>Initial value (a vector).</p>
</td></tr>
<tr><td><code id="harris_+3A_options">options</code></td>
<td>
<p>Vector of parameters (see details).</p>
</td></tr>
<tr><td><code id="harris_+3A_tr">tr</code></td>
<td>
<p>If TRUE, returns a trace of objective function vs CPU time</p>
</td></tr>
<tr><td><code id="harris_+3A_...">...</code></td>
<td>
<p>Additional parameters passed to fun</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with three attributes:
</p>

<dl>
<dt>par</dt><dd><p>The minimizer of fun found.</p>
</dd>
<dt>value</dt><dd><p>The value of fun at par.</p>
</dd>
<dt>trace</dt><dd><p>The trace, a list with two attributes: 'time' and 'fct' (if tr==TRUE).</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>F. M. Silva and L. B. Almeida. Speeding up backpropagation. In Advanced Neural 
Computers, R. Eckmiller, ed., Elsevier-North-Holland, New-York, 151-158, 1990.
</p>
<p>T. Denoeux and M.-H. Masson. EVCLUS: Evidential Clustering of Proximity Data.
IEEE Transactions on Systems, Man and Cybernetics B, Vol. 34, Issue 1, 95&ndash;109, 2004.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcca">pcca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>opt&lt;-harris(function(x) return(list(fun=sum(x^2),grad=2*x)),rnorm(2),tr=TRUE)
print(c(opt$par,opt$value))
plot(opt$trace$fct,type="l")

</code></pre>

<hr>
<h2 id='kcevclus'>k-CEVCLUS algorithm</h2><span id='topic+kcevclus'></span>

<h3>Description</h3>

<p><code>kcevclus</code> computes a credal partition from a dissimilarity matrix and pairwise (must-link
and cannot-link) constraints using the k-CEVCLUS algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kcevclus(
  x,
  k = n - 1,
  D,
  J,
  c,
  ML,
  CL,
  xi = 0.5,
  type = "simple",
  pairs = NULL,
  m0 = NULL,
  ntrials = 1,
  disp = TRUE,
  maxit = 1000,
  epsi = 1e-05,
  d0 = quantile(D, 0.9),
  tr = FALSE,
  change.order = FALSE,
  norm = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kcevclus_+3A_x">x</code></td>
<td>
<p>nxp matrix of p attributes observed for n objects (optional).</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_k">k</code></td>
<td>
<p>Number of distances to compute for each object (default: n-1).</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_d">D</code></td>
<td>
<p>nxn or nxk dissimilarity matrix (used only of x is not supplied).</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_j">J</code></td>
<td>
<p>nxk matrix of indices. D[i,j] is the distance between objects i and
J[i,j]. (Used only if D is supplied and ncol(D)&lt;n; then k is set to ncol(D).)</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_c">c</code></td>
<td>
<p>Number of clusters</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_ml">ML</code></td>
<td>
<p>Matrix nbML x 2 of must-link constraints. Each row of ML contains the indices
of objects that belong to the same class.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_cl">CL</code></td>
<td>
<p>Matrix nbCL x 2 of cannot-link constraints. Each row of CL contains the indices
of objects that belong to different classes.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_xi">xi</code></td>
<td>
<p>Penalization coefficient.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: empty set, singletons and Omega;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all or selected pairs).</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_pairs">pairs</code></td>
<td>
<p>Set of pairs to be included in the focal sets; if NULL, all pairs are
included. Used only if type=&quot;pairs&quot;.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_m0">m0</code></td>
<td>
<p>Initial credal partition. Should be a matrix with n rows and a number of
columns equal to the number f of focal sets specified by 'type' and 'pairs'.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_ntrials">ntrials</code></td>
<td>
<p>Number of runs of the optimization algorithm (set to 1 if m0 is supplied
and change.order=FALSE).</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_disp">disp</code></td>
<td>
<p>If TRUE (default), intermediate results are displayed.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_epsi">epsi</code></td>
<td>
<p>Minimum amount of improvement.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_d0">d0</code></td>
<td>
<p>Parameter used for matrix normalization. The normalized distance corresponding
to d0 is 0.95.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_tr">tr</code></td>
<td>
<p>If TRUE, a trace of the stress function is returned.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_change.order">change.order</code></td>
<td>
<p>If TRUE, the order of objects is changed at each iteration of the
Iterative Row-wise Quadratic Programming (IRQP) algorithm.</p>
</td></tr>
<tr><td><code id="kcevclus_+3A_norm">norm</code></td>
<td>
<p>Normalization of distances. 1: division by mean(D^2) (default); 2: division par n*p.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>k-CEVCLUS is a version of EVCLUS allowing the user to specify pairwise constraints to guide
the clustering process. Pairwise constraints are of two kinds: must-link contraints are
pairs of objects that are known to belong to the same class, and cannot-link constraints
are pairs of objects that are known to belong to different classes. As <code>kevclus</code>, 
<code>kcevclus</code> uses the Iterative Row-wise Quadratic Programming (IRQP) algorithm 
(see ter Braak et al., 2009). It also makes it possible to use only a random sample of the 
dissimilarities, reducing the time and space complexity from quadratic to roughly linear 
(Denoeux et al., 2016).
</p>


<h3>Value</h3>

<p>The credal partition (an object of class <code>"credpart"</code>). In addition to the
usual attributes, the output credal partition has the following attributes:
</p>

<dl>
<dt>Kmat</dt><dd><p>The matrix of degrees of conflict. Same size as D.</p>
</dd>
<dt>D</dt><dd><p>The normalized dissimilarity matrix.</p>
</dd>
<dt>trace</dt><dd><p>Trace of the algorithm (Stress function vs iterations).</p>
</dd>
<dt>J</dt><dd><p>The matrix of indices.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Feng Li and Thierry Denoeux.
</p>


<h3>References</h3>

<p>F. Li, S. Li and T. Denoeux. k-CEVCLUS: Constrained evidential clustering of 
large dissimilarity data. Knowledge-Based Systems 142:29-44, 2018.
</p>
<p>T. Denoeux, S. Sriboonchitta and O. Kanjanatarakul. Evidential clustering of large
dissimilarity data. Knowledge-Based Systems 106:179-195, 2016.
</p>
<p>V. Antoine, B. Quost, M.-H. Masson and T. Denoeux. CEVCLUS: Evidential clustering 
with instance-level constraints for relational data. Soft Computing 18(7):1321-1335, 2014.
</p>
<p>C. J. ter Braak, Y. Kourmpetis, H. A. Kiers, and M. C. Bink. Approximating a
similarity matrix by a latent class model: A reappraisal of additive fuzzy clustering.
Computational Statistics &amp; Data Analysis 53(8):3183&ndash;3193, 2009.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kevclus">kevclus</a></code>,<code><a href="#topic+createD">createD</a></code>, <code><a href="#topic+makeF">makeF</a></code>, 
<code><a href="#topic+extractMass">extractMass</a></code>, <code><a href="#topic+create_MLCL">create_MLCL</a></code>,<code><a href="#topic+bananas">bananas</a></code>,
<code><a href="#topic+nnevclus">nnevclus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data&lt;-bananas(2000)
D&lt;-as.matrix(dist(data$x))
link&lt;-create_MLCL(data$y,2000)
clus0&lt;-kevclus(D=D,k=200,c=2)
clus1&lt;-kcevclus(D=D,k=200,c=2,ML=link2$ML,CL=link2$CL,Xi=0.1,m0=clus0$mass)
clus2&lt;-kcevclus(D=D,k=200,c=2,ML=link2$ML,CL=link2$CL,Xi=0.5,m0=clus1$mass)
plot(clus2,X=data$x,ytrue=data$y,Outliers=FALSE,Approx=1)

## End(Not run)

</code></pre>

<hr>
<h2 id='kevclus'>k-EVCLUS algorithm</h2><span id='topic+kevclus'></span>

<h3>Description</h3>

<p><code>kevclus</code> computes a credal partition from a dissimilarity matrix using the k-EVCLUS
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kevclus(
  x,
  k = n - 1,
  D,
  J,
  c,
  type = "simple",
  pairs = NULL,
  m0 = NULL,
  ntrials = 1,
  disp = TRUE,
  maxit = 1000,
  epsi = 1e-05,
  d0 = quantile(D, 0.9),
  tr = FALSE,
  change.order = FALSE,
  norm = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kevclus_+3A_x">x</code></td>
<td>
<p>nxp matrix of p attributes observed for n objects (optional).</p>
</td></tr>
<tr><td><code id="kevclus_+3A_k">k</code></td>
<td>
<p>Number of distances to compute for each object (default: n-1).</p>
</td></tr>
<tr><td><code id="kevclus_+3A_d">D</code></td>
<td>
<p>nxn or nxk dissimilarity matrix (used only of x is not supplied).</p>
</td></tr>
<tr><td><code id="kevclus_+3A_j">J</code></td>
<td>
<p>nxk matrix of indices. D[i,j] is the distance between objects i and
J[i,j]. (Used only if D is supplied and ncol(D)&lt;n; then k is set to ncol(D).)</p>
</td></tr>
<tr><td><code id="kevclus_+3A_c">c</code></td>
<td>
<p>Number of clusters</p>
</td></tr>
<tr><td><code id="kevclus_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: empty set, singletons and Omega;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all or selected pairs).</p>
</td></tr>
<tr><td><code id="kevclus_+3A_pairs">pairs</code></td>
<td>
<p>Set of pairs to be included in the focal sets; if NULL, all pairs are
included. Used only if type=&quot;pairs&quot;.</p>
</td></tr>
<tr><td><code id="kevclus_+3A_m0">m0</code></td>
<td>
<p>Initial credal partition. Should be a matrix with n rows and a number of
columns equal to the number f of focal sets specified by 'type' and 'pairs'.</p>
</td></tr>
<tr><td><code id="kevclus_+3A_ntrials">ntrials</code></td>
<td>
<p>Number of runs of the optimization algorithm (set to 1 if m0 is supplied
and change.order=FALSE).</p>
</td></tr>
<tr><td><code id="kevclus_+3A_disp">disp</code></td>
<td>
<p>If TRUE (default), intermediate results are displayed.</p>
</td></tr>
<tr><td><code id="kevclus_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="kevclus_+3A_epsi">epsi</code></td>
<td>
<p>Minimum amount of improvement.</p>
</td></tr>
<tr><td><code id="kevclus_+3A_d0">d0</code></td>
<td>
<p>Parameter used for matrix normalization. The normalized distance corresponding
to d0 is 0.95.</p>
</td></tr>
<tr><td><code id="kevclus_+3A_tr">tr</code></td>
<td>
<p>If TRUE, a trace of the stress function is returned.</p>
</td></tr>
<tr><td><code id="kevclus_+3A_change.order">change.order</code></td>
<td>
<p>If TRUE, the order of objects is changed at each iteration of the
Iterative Row-wise Quadratic Programming (IRQP) algorithm.</p>
</td></tr>
<tr><td><code id="kevclus_+3A_norm">norm</code></td>
<td>
<p>Normalization of distances. 1: division by mean(D^2) (default); 2: division par n*p.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This version of the EVCLUS algorithm uses the Iterative Row-wise Quadratic Programming
(IRQP) algorithm (see ter Braak et al., 2009). It also makes it possible to use only
a random sample of the dissimilarities, reducing the time and space complexity from
quadratic to roughly linear (Denoeux et al., 2016). The user must supply:
1) a matrix x or size (n,p) containing the values of p attributes for n objects, or
2) a matrix D of size (n,n) of dissimilarities between n objects, or
3) a matrix D of size (n,k) of dissimilarities between the n objects and k randomly selected
objects, AND a matrix J of size (n,k) of indices, such that D[i,j] is the distance between
objects i and J[i,j].
In cases 1 and 2, the user may supply the number $k$ of distances to be picked randomly for
each object. In case 3, k is set to the number of columns of D.
</p>


<h3>Value</h3>

<p>The credal partition (an object of class <code>"credpart"</code>). In addition to the
usual attributes, the output credal partition has the following attributes:
</p>

<dl>
<dt>Kmat</dt><dd><p>The matrix of degrees of conflict. Same size as D.</p>
</dd>
<dt>D</dt><dd><p>The normalized dissimilarity matrix.</p>
</dd>
<dt>trace</dt><dd><p>Trace of the algorithm (Stress function vs iterations).</p>
</dd>
<dt>J</dt><dd><p>The matrix of indices.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>T. Denoeux and M.-H. Masson. EVCLUS: Evidential Clustering of Proximity Data.
IEEE Transactions on Systems, Man and Cybernetics B, Vol. 34, Issue 1, 95&ndash;109, 2004.
</p>
<p>T. Denoeux, S. Sriboonchitta and O. Kanjanatarakul. Evidential clustering of large
dissimilarity data. Knowledge-Based Systems, vol. 106, pages 179-195, 2016.
</p>
<p>C. J. ter Braak, Y. Kourmpetis, H. A. Kiers, and M. C. Bink. Approximating a
similarity matrix by a latent class model: A reappraisal of additive fuzzy clustering.
Computational Statistics &amp; Data Analysis, 53(8):3183&ndash;3193, 2009.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+createD">createD</a></code>, <code><a href="#topic+makeF">makeF</a></code>, <code><a href="#topic+extractMass">extractMass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example with a non metric dissimilarity matrix: the Protein dataset
## Not run: 
data(protein)
clus &lt;- kevclus(D=protein$D,c=4,type='simple',d0=max(protein$D))
z&lt;- cmdscale(protein$D,k=2)  # Computation of 2 attributes by Multidimensional Scaling
plot(clus,X=z,mfrow=c(2,2),ytrue=protein$y,Outliers=FALSE,Approx=1)
## Example with k=30
clus &lt;- kevclus(D=protein$D,k=30,c=4,type='simple',d0=max(protein$D))
z&lt;- cmdscale(protein$D,k=2)  # Computation of 2 attributes by Multidimensional Scaling
plot(clus,X=z,mfrow=c(2,2),ytrue=protein$y,Outliers=FALSE,Approx=1)

## End(Not run)

</code></pre>

<hr>
<h2 id='knn_dist'>K nearest neighbors in a dissimilarity matrix</h2><span id='topic+knn_dist'></span>

<h3>Description</h3>

<p><code>knn_dist</code> searches for nearest neighbors in a dissimilarity matrix matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>knn_dist(D, K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="knn_dist_+3A_d">D</code></td>
<td>
<p>Dissimilarity matrix of size (n,n), where n is the number of objects.</p>
</td></tr>
<tr><td><code id="knn_dist_+3A_k">K</code></td>
<td>
<p>Number of neighbors</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is called by <code><a href="#topic+EkNNclus">EkNNclus</a></code> if argument x is not supplied.
It is not optimized and cannot be used for very large D. If an attribute matrix
x is supplied and D is the matrix of Euclidean distances, it is preferable to use
function <code><a href="FNN.html#topic+get.knn">get.knn</a></code> from package <code>FNN</code>.
</p>


<h3>Value</h3>

<p>A list with two components:
</p>

<dl>
<dt>nn.dist</dt><dd><p>An (n,K) matrix for the nearest neighbor dissimilarities.</p>
</dd>
<dt>nn.index</dt><dd><p>An (n,K) matrix for the nearest neighbor indices.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>See Also</h3>

<p><code><a href="FNN.html#topic+get.knn">get.knn</a></code>, <code><a href="#topic+EkNNclus">EkNNclus</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(butterfly)
n &lt;- nrow(butterfly)
D&lt;-as.matrix(dist(butterfly))
knn&lt;-knn_dist(D,K=2)
knn$nn.dist
knn$nn.index
</code></pre>

<hr>
<h2 id='kpcca'>Kernel Pairwise Constrained Component Analysis (KPCCA)</h2><span id='topic+kpcca'></span>

<h3>Description</h3>

<p>Using must-link and cannot-link constaints, KPCCA (Mignon &amp; Jury, 2012) learns a projection into a 
low-dimensional space where the distances between pairs of data points respect the desired constraints, 
exhibiting good generalization properties in presence of high dimensional data. This is a kernelized
version of <code>pcca</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kpcca(K, d1, ML, CL, beta = 1, epsi = 1e-04, etamax = 0.1, disp = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="kpcca_+3A_k">K</code></td>
<td>
<p>Gram matrix of size n*n</p>
</td></tr>
<tr><td><code id="kpcca_+3A_d1">d1</code></td>
<td>
<p>Number of extracted features.</p>
</td></tr>
<tr><td><code id="kpcca_+3A_ml">ML</code></td>
<td>
<p>Matrix nbML x 2 of must-link constraints. Each row of ML contains the indices
of objects that belong to the same class.</p>
</td></tr>
<tr><td><code id="kpcca_+3A_cl">CL</code></td>
<td>
<p>Matrix nbCL x 2 of cannot-link constraints. Each row of CL contains the indices
of objects that belong to different classes.</p>
</td></tr>
<tr><td><code id="kpcca_+3A_beta">beta</code></td>
<td>
<p>Sharpness parameter in the loss function (default: 1).</p>
</td></tr>
<tr><td><code id="kpcca_+3A_epsi">epsi</code></td>
<td>
<p>Minimal rate of change of the cost function (default: 1e-4).</p>
</td></tr>
<tr><td><code id="kpcca_+3A_etamax">etamax</code></td>
<td>
<p>Maximum step in the line search algorithm (default: 0.1).</p>
</td></tr>
<tr><td><code id="kpcca_+3A_disp">disp</code></td>
<td>
<p>If TRUE (default), intermediate results are displayed.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with three attributes:
</p>

<dl>
<dt>z</dt><dd><p>The n*d1 matrix of extracted features.</p>
</dd>
<dt>A</dt><dd><p>The projection matrix of size d1*n.</p>
</dd>
<dt>D</dt><dd><p>The Euclidean distance matrix in the projected space.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>A. Mignon and F. Jurie. PCCA: a new approach for distance learning from sparse 
pairwise constraints. In 2012 IEEE Conference on Computer Vision and Pattern Recognition, 
pages 2666-2672, 2012.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pcca">pcca</a></code>, <code><a href="#topic+create_MLCL">create_MLCL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(kernlab)
data&lt;-bananas(400)
plot(data$x,pch=data$y,col=data$y)
const&lt;-create_MLCL(data$y,1000)
rbf &lt;- rbfdot(sigma = 0.2)
K&lt;-kernelMatrix(rbf,data$x)
res.kpcca&lt;-kpcca(K,d1=1,ML=const$ML,CL=const$CL,beta=1)
plot(res.kpcca$z,col=data$y)

## End(Not run)

</code></pre>

<hr>
<h2 id='makeF'>Creation of a matrix of focal sets</h2><span id='topic+makeF'></span>

<h3>Description</h3>

<p><code>makeF</code> creates a matrix of focal sets
</p>


<h3>Usage</h3>

<pre><code class='language-R'>makeF(c, type = c("simple", "full", "pairs"), pairs = NULL, Omega = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="makeF_+3A_c">c</code></td>
<td>
<p>Number of  clusters.</p>
</td></tr>
<tr><td><code id="makeF_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: <code class="reqn">\emptyset</code>, singletons and <code class="reqn">\Omega</code>;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all or selected pairs).</p>
</td></tr>
<tr><td><code id="makeF_+3A_pairs">pairs</code></td>
<td>
<p>Set of pairs to be included in the focal sets; if NULL, all pairs
are included. Used only if type=&quot;pairs&quot;.</p>
</td></tr>
<tr><td><code id="makeF_+3A_omega">Omega</code></td>
<td>
<p>Logical. If TRUE (default), <code class="reqn">\Omega</code> is a focal set (for types 'simple' and
'pairs').</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A matrix (f,c) of focal sets.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>c&lt;-4
## Generation of all 16 focal sets
F&lt;-makeF(c,type='full')
## Generation of focal sets of cardinality 0, 1 and c
F&lt;-makeF(c,type='simple')
## Generation of focal sets of cardinality 0, 1, and 2
F&lt;-makeF(c,type='pairs',Omega=FALSE)
## Generation of focal sets of cardinality 0, 1, and c, plus the pairs (1,2) and (1,3)
F&lt;-makeF(c,type='pairs',pairs=matrix(c(1,2,1,3),nrow=2,byrow=TRUE))

</code></pre>

<hr>
<h2 id='nnevclus'>NN-EVCLUS algorithm</h2><span id='topic+nnevclus'></span>

<h3>Description</h3>

<p><code>nnevclus</code> computes a credal partition from a dissimilarity matrix using the NN-EVCLUS
algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nnevclus(
  x,
  k = n - 1,
  D = NULL,
  J = NULL,
  c,
  type = "simple",
  n_H,
  ntrials = 1,
  d0 = quantile(D, 0.9),
  fhat = NULL,
  lambda = 0,
  y = NULL,
  Is = NULL,
  nu = 0,
  ML = NULL,
  CL = NULL,
  xi = 0,
  tr = FALSE,
  options = c(1, 1000, 1e-04, 10),
  param0 = list(U0 = NULL, V0 = NULL, W0 = NULL, beta0 = NULL)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nnevclus_+3A_x">x</code></td>
<td>
<p>nxp matrix of p attributes observed for n objects.</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_k">k</code></td>
<td>
<p>Number of distances to compute for each object (default: n-1).</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_d">D</code></td>
<td>
<p>nxn or nxk dissimilarity matrix (optional). If absent, the Euclidean distance 
is computed.</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_j">J</code></td>
<td>
<p>nxk matrix of indices. D[i,j] is the distance between objects i and
J[i,j]. (Used only if D is supplied and ncol(D)&lt;n.)</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_c">c</code></td>
<td>
<p>Number of clusters</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: empty set, singletons and Omega;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all or selected pairs).</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_n_h">n_H</code></td>
<td>
<p>Number of hidden units (if one hidden layer), or a two-dimensional vector
of numbers of hidden units (if two hidden layers).</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_ntrials">ntrials</code></td>
<td>
<p>Number of runs of the optimization algorithm (set to 1 if param0 is 
supplied).</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_d0">d0</code></td>
<td>
<p>Parameter used for matrix normalization. The normalized distance corresponding
to d0 is 0.95.</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_fhat">fhat</code></td>
<td>
<p>Vector of outputs from a one-class SVM for novelty detection (optional)</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_lambda">lambda</code></td>
<td>
<p>Regularization coefficient (default: 0)</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_y">y</code></td>
<td>
<p>Optional vector of class labels for a subset of the training set 
(for semi-supervised learning).</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_is">Is</code></td>
<td>
<p>Vector of indices corresponding to y (for semi-supervised learning).</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_nu">nu</code></td>
<td>
<p>Coefficient of the supervised error term (default: 0).</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_ml">ML</code></td>
<td>
<p>Optional nbML*2 matrix of must-link constraints (for constrained clustering). 
Each row of ML contains the indices of objects that belong to the same class.</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_cl">CL</code></td>
<td>
<p>Optional nbCL*2 matrix of cannot-link constraints (for constrained clustering). 
Each row of CL contains the indices of objects that belong to different classes.</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_xi">xi</code></td>
<td>
<p>Coefficient of the constrained clustering loss (default: 0).</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_tr">tr</code></td>
<td>
<p>If TRUE, a trace of the stress function is returned.</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_options">options</code></td>
<td>
<p>Parameters of the optimization algorithm (see <code><a href="#topic+harris">harris</a></code>).</p>
</td></tr>
<tr><td><code id="nnevclus_+3A_param0">param0</code></td>
<td>
<p>Optional list of initial network parameters (see details).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a neural network version of <code>kevclus</code>. The neural net has one or two layers
of ReLU units and a softmax output layer (see Denoeux, 2020). The weight matrices are 
denoted by U, V and W for a two-hidden-layer network, or V and W for a one-hidden-layer 
network. The inputs are a feature vector x, an optional distance matrix D, and an 
optional vector of one-class SVM outputs fhat, which is used for novelty detection. 
Part of the output belief mass is transfered to the empty set based on beta[1]+beta[2]*fhat,
where beta is an additional parameter vector. The network can be trained in fully
unsupervised mode, in semi-supervised mode (with class labels for a subset of the
learning instances), or with pairwise constraints. The output is a credal partition 
(a &quot;credpart&quot; object), with a specific field containing the network parameters (U, V, W,
beta).
</p>


<h3>Value</h3>

<p>The output credal partition (an object of class <code>"credpart"</code>). In 
addition to the usual attributes, the output credal partition has the following 
attributes:
</p>

<dl>
<dt>Kmat</dt><dd><p>The matrix of degrees of conflict. Same size as D.</p>
</dd>
<dt>D</dt><dd><p>The normalized dissimilarity matrix.</p>
</dd>
<dt>trace</dt><dd><p>Trace of the algorithm (Stress function vs iterations).</p>
</dd>
<dt>J</dt><dd><p>The matrix of indices.</p>
</dd>
<dt>param</dt><dd><p>The network parameters as a list with components U, V, W and beta.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>T. Denoeux. NN-EVCLUS: Neural Network-based Evidential Clustering. 
Information Sciences, Vol. 572, Pages 297-330, 2021.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nnevclus_mb">nnevclus_mb</a></code>, <code><a href="#topic+predict.credpart">predict.credpart</a></code>, 
<code><a href="#topic+kevclus">kevclus</a></code>, <code><a href="#topic+kcevclus">kcevclus</a></code>, <code><a href="#topic+harris">harris</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Example with one hidden layer and no novelty detection
data(fourclass)
x&lt;-scale(fourclass[,1:2])
y&lt;-fourclass[,3]
clus&lt;-nnevclus(x,c=4,n_H=c(5,5),type='pairs') # One hidden layer
plot(clus,x,mfrow=c(2,2))

## Example with two hidden layers and novelty detection
library(kernlab)
data(fourclass)
x&lt;-scale(fourclass[,1:2])
y&lt;-fourclass[,3]
x&lt;-data.frame(x)
svmfit&lt;-ksvm(~.,data=x,type="one-svc",kernel="rbfdot",nu=0.2,kpar=list(sigma=0.2))
fhat&lt;-predict(svmfit,newdata=x,type="decision")
clus&lt;-nnevclus(x,k=200,c=4,n_H=c(5,5),type='pairs',fhat=fhat)
plot(clus,x,mfrow=c(2,2))

## Example with semi-supervised learning
data&lt;-bananas(400)
x&lt;-scale(data$x)
y&lt;-data$y
Is&lt;-sample(400, 50)  # Indices of labeled instances
plot(x,col=y,pch=y)
points(x[Is,],pch=16)
svmfit&lt;-ksvm(~.,data=x,type="one-svc",kernel="rbfdot",nu=0.2,kpar=list(sigma=0.2))
fhat&lt;-predict(svmfit,newdata=x,type="decision")
clus&lt;-nnevclus(x,k=100,c=2,n_H=10,type='full',fhat=fhat,Is=Is,y=y[Is],nu=0.5)
plot(clus,x)

## Example with pairwise constraints
data&lt;-bananas(400)
x&lt;-scale(data$x)
y&lt;-data$y
const&lt;-create_MLCL(y,500)
clus&lt;-nnevclus(x,k=100,c=2,n_H=10,type='full',fhat=fhat,ML=const$ML,CL=const$CL,
rho=0.5)
plot(clus,x)

## Example with pairwise constraints and PCCA
data(iris)
x&lt;-scale(as.matrix(iris[,1:4]))
y&lt;-as.integer(iris[,5])
const&lt;-create_MLCL(y,100)
res.pcca&lt;-pcca(x,3,const$ML,const$CL,beta=1)
plot(res.pcca$z,pch=y,col=y)
clus&lt;-nnevclus(x=x,D=res.pcca$D,c=3,n_H=10,type='full',ML=const$ML,CL=const$CL,rho=0.5)
plot(clus,x[,3:4])

## End(Not run)

</code></pre>

<hr>
<h2 id='nnevclus_mb'>NN-EVCLUS algorithm (minibatch version)</h2><span id='topic+nnevclus_mb'></span>

<h3>Description</h3>

<p><code>nnevclus_mb</code> computes a credal partition from a dissimilarity matrix using the 
NN-EVCLUS algorithm. Training is done using mini-batch gradient descent with the RMSprop
optimization algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nnevclus_mb(
  x,
  foncD = function(x) as.matrix(dist(x)),
  c,
  type = "simple",
  n_H,
  nbatch = 10,
  alpha0 = 0.9,
  fhat = NULL,
  lambda = 0,
  y = NULL,
  Is = NULL,
  nu = 0,
  disp = TRUE,
  options = list(Niter = 1000, epsi = 0.001, rho = 0.9, delta = 1e-08, Dtmax = 100, print
    = 5),
  param0 = list(V0 = NULL, W0 = NULL, beta0 = NULL)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nnevclus_mb_+3A_x">x</code></td>
<td>
<p>nxp matrix of p attributes observed for n objects.</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_foncd">foncD</code></td>
<td>
<p>A function to compute distances.</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_c">c</code></td>
<td>
<p>Number of clusters</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: empty set, singletons and Omega;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all or selected pairs).</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_n_h">n_H</code></td>
<td>
<p>Size or the hidden layer.</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_nbatch">nbatch</code></td>
<td>
<p>Number of mini-batches.</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_alpha0">alpha0</code></td>
<td>
<p>Order of the quantile to normalize distances. Parameter d0 is set to 
the alpha0-quantile of distances. Default: 0.9.</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_fhat">fhat</code></td>
<td>
<p>Vector of outputs from a one-class SVM for novelty detection (optional)</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_lambda">lambda</code></td>
<td>
<p>Regularization coefficient (default: 0)</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_y">y</code></td>
<td>
<p>Optional vector of class labels for a subset of the training set 
(for semi-supervised learning).</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_is">Is</code></td>
<td>
<p>Vector of indices corresponding to y (for semi-supervised learning).</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_nu">nu</code></td>
<td>
<p>Coefficient of the supervised error term (default: 0).</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_disp">disp</code></td>
<td>
<p>If TRUE, intermediate results are displayed.</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_options">options</code></td>
<td>
<p>Parameters of the optimization algorithm (Niter: maximum number of
iterations; epsi, rho, delta: parameters of RMSprop; Dtmax: the algorithm stops when
the loss has not decreased in the last Dtmax iterations; print: number of iterations 
between two displays).</p>
</td></tr>
<tr><td><code id="nnevclus_mb_+3A_param0">param0</code></td>
<td>
<p>Optional list of initial network parameters (see details).
</p>
<p>#'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a neural network version of <code>kevclus</code>. The neural net has one layer
of ReLU units and a softmax output layer (see Denoeux, 2020). The network is trained
in mini-batch mode using the RMSprop algorithm. The inputs are a feature vector x, 
an optional distance matrix D, and an optional vector of one-class SVM outputs fhat, 
which is used for novelty detection. Part of the output belief mass is transfered to 
the empty set based on beta[1]+beta[2]*fhat, where beta is an additional parameter 
vector. The network can be trained in fully unsupervised mode or in semi-supervised mode
(with class labels for a subset of the learning instances). The output is a credal 
partition (a &quot;credpart&quot; object), with a specific field containing the network parameters (U, V, W,
beta).
</p>


<h3>Value</h3>

<p>The output credal partition (an object of class <code>"credpart"</code>). In 
addition to the usual attributes, the output credal partition has the following 
attributes:
</p>

<dl>
<dt>Kmat</dt><dd><p>The matrix of degrees of conflict. Same size as D.</p>
</dd>
<dt>trace</dt><dd><p>Trace of the algorithm (values of the loss function).</p>
</dd>
<dt>param</dt><dd><p>The network parameters as a list with components V, W and beta.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>T. Denoeux. NN-EVCLUS: Neural Network-based Evidential Clustering. 
Information Sciences, Vol. 572, Pages 297-330, 2021.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+nnevclus">nnevclus</a></code>, <code><a href="#topic+predict.credpart">predict.credpart</a></code>, 
<code><a href="#topic+kevclus">kevclus</a></code>, <code><a href="#topic+kcevclus">kcevclus</a></code>, <code><a href="#topic+harris">harris</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Unsupervised learning
data(fourclass)
x&lt;-scale(fourclass[,1:2])
y&lt;-fourclass[,3]
svmfit&lt;-ksvm(~.,data=x,type="one-svc",kernel="rbfdot",nu=0.2,kpar=list(sigma=0.2))
fhat&lt;-predict(svmfit,newdata=x,type="decision")
clus&lt;-nnevclus_mb(x,foncD=function(x) as.matrix(dist(x)),c=4,type='pairs',
n_H=10,nbatch=10,alpha0=0.9,fhat=fhat)
plot(clus,x)
## semi-supervised learning
Is&lt;-sample(400,100)
clus&lt;-nnevclus_mb(x,foncD=function(x) as.matrix(dist(x)),c=4,type='pairs',
n_H=10,nbatch=10,alpha0=0.9,fhat=fhat,lambda=0, y=y[Is],Is=Is,nu=0.5)
plot(clus,x)

## End(Not run)

</code></pre>

<hr>
<h2 id='nonspecificity'>Nonspecificity of the relational representation of a credal partition</h2><span id='topic+nonspecificity'></span>

<h3>Description</h3>

<p><code>nonspecificity</code> the average nonspecificity of a credal partition, as defined 
in Denoeux et al (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>nonspecificity(P)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="nonspecificity_+3A_p">P</code></td>
<td>
<p>The relation representation of a credal partition as generated by 
<code><a href="#topic+pairwise_mass">pairwise_mass</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The mean nonspecificity (i.e, the average nonspecificity of pairwise mass functions in P).
</p>


<h3>References</h3>

<p>T. Denoeux, S. Li and S. Sriboonchitta. Evaluating and Comparing Soft Partitions: an 
Approach Based on Dempster-Shafer Theory. IEEE Transactions on Fuzzy Systems, 
26(3):1231-1244, 2018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+credal_RI">credal_RI</a></code>, <code><a href="#topic+pairwise_mass">pairwise_mass</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Butterfly data
data(butterfly)
clus&lt;-kevclus(butterfly,c=2)
P&lt;-pairwise_mass(clus)
print(nonspecificity(P))

</code></pre>

<hr>
<h2 id='normalize.credpart'>Normalization of a credal partition</h2><span id='topic+normalize.credpart'></span>

<h3>Description</h3>

<p><code>normalize.credpart</code> normalizes a credal partition (a <code>"credpart"</code> object).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>normalize.credpart(clus, method = "d")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="normalize.credpart_+3A_clus">clus</code></td>
<td>
<p>An object of class <code>"credpart"</code>, encoding a credal partition.</p>
</td></tr>
<tr><td><code id="normalize.credpart_+3A_method">method</code></td>
<td>
<p>Normalization method (&quot;d&quot; for Dempster or &quot;y&quot; for Yager).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The function implements two normalization methods: Dempster's normalization (the mass of each focal set
is divided by one minus the mass on the empty set), and yager's normalization (the mass of the empty set
is transfered to the whole frame).
</p>


<h3>Value</h3>

<p>The normalized credal partition (a <code>"credpart"</code> object).
</p>


<h3>References</h3>

<p>T. Denoeux and O. Kanjanatarakul. Beyond Fuzzy, Possibilistic and Rough: An
Investigation of Belief Functions in Clustering. 8th International conference on soft
methods in probability and statistics, Rome, 12-14 September, 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extractMass">extractMass</a></code>, <code><a href="#topic+plot.credpart">plot.credpart</a></code>, <code><a href="#topic+summary.credpart">summary.credpart</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(butterfly)
clus&lt;-kevclus(butterfly,c=2)
print(clus$mass)
clus1&lt;-normalize.credpart(clus,"d") # Dempster normalization
print(clus1$mass)
clus2&lt;-normalize.credpart(clus,"y") # Yager normalization
print(clus2$mass)

</code></pre>

<hr>
<h2 id='pairwise_mass'>Computes the relational representation</h2><span id='topic+pairwise_mass'></span>

<h3>Description</h3>

<p><code>pairwise_mass</code> computes the relational representation of a credal partition, as defined 
in Denoeux et al (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pairwise_mass(clus)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pairwise_mass_+3A_clus">clus</code></td>
<td>
<p>A credal partition (a matrix of n rows and f columns, where n is the
number of objects and f is the number of focal sets).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a credal partition, we can compute, for each pair of objects, a &quot;pairwise mass function&quot;
on a frame <code class="reqn">\Theta=\{s,\neg s\}</code>, where <code class="reqn">s</code> means that the two objects belong to the same
cluster, and <code class="reqn">\neg s</code> is the negation of <code class="reqn">s</code>. Function <code>pairwise_mass</code> compute these
pairwise mass functions for all object pairs. The result is return as a list with &quot;dist&quot; objects 
containing the masses of each of the two elements of <code class="reqn">\Theta</code>, and the masses on the empty set.
</p>


<h3>Value</h3>

<p>A list with three &quot;dist&quot; objects:
</p>

<dl>
<dt>M0</dt><dd><p>The masses assigned to the assumption that each pair of object (i,j) do not belong 
to the same class.</p>
</dd>
<dt>M1</dt><dd><p>The masses assigned to the assumption that each pair of object (i,j) belongs to 
the same class.</p>
</dd>
<dt>Me</dt><dd><p>The masses assigned to the empty set, for each pair of object (i,j).</p>
</dd>
</dl>



<h3>References</h3>

<p>T. Denoeux, S. Li and S. Sriboonchitta. Evaluating and Comparing Soft Partitions: an 
Approach Based on Dempster-Shafer Theory. IEEE Transactions on Fuzzy Systems, 
26(3):1231-1244, 2018.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+credal_RI">credal_RI</a></code>, <code><a href="#topic+nonspecificity">nonspecificity</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Butterfly data
data(butterfly)
clus&lt;-kevclus(butterfly,c=2)
P&lt;-pairwise_mass(clus)

</code></pre>

<hr>
<h2 id='pcca'>Pairwise Constrained Component Analysis (PCCA)</h2><span id='topic+pcca'></span>

<h3>Description</h3>

<p>Using must-link and cannot-link constaints, PCCA (Mignon &amp; Jury, 2012) learns a projection into a 
low-dimensional space where the distances between pairs of data points respect the desired constraints, 
exhibiting good generalization properties in presence of high dimensional data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pcca(x, d1, ML, CL, options = c(1, 1000, 1e-05, 10), beta = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="pcca_+3A_x">x</code></td>
<td>
<p>Data matrix of size n*d</p>
</td></tr>
<tr><td><code id="pcca_+3A_d1">d1</code></td>
<td>
<p>Number of extracted features.</p>
</td></tr>
<tr><td><code id="pcca_+3A_ml">ML</code></td>
<td>
<p>Matrix nbML x 2 of must-link constraints. Each row of ML contains the indices
of objects that belong to the same class.</p>
</td></tr>
<tr><td><code id="pcca_+3A_cl">CL</code></td>
<td>
<p>Matrix nbCL x 2 of cannot-link constraints. Each row of CL contains the indices
of objects that belong to different classes.</p>
</td></tr>
<tr><td><code id="pcca_+3A_options">options</code></td>
<td>
<p>Parameters of the optimization algorithm (see <code><a href="#topic+harris">harris</a></code>).</p>
</td></tr>
<tr><td><code id="pcca_+3A_beta">beta</code></td>
<td>
<p>Sharpness parameter in the loss function (default: 1).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with three attributes:
</p>

<dl>
<dt>z</dt><dd><p>The n*d1 matrix of extracted features.</p>
</dd>
<dt>L</dt><dd><p>The projection matrix of size d1*d.</p>
</dd>
<dt>D</dt><dd><p>The Euclidean distance matrix in the projected space</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Thierry Denoeux.
</p>


<h3>References</h3>

<p>A. Mignon and F. Jurie. PCCA: a new approach for distance learning from sparse 
pairwise constraints. In 2012 IEEE Conference on Computer Vision and Pattern Recognition, 
pages 2666-2672, 2012.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kpcca">kpcca</a></code>,<code><a href="#topic+harris">harris</a></code>,<code><a href="#topic+create_MLCL">create_MLCL</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(iris)
x&lt;-as.matrix(iris[,1:4])
y&lt;-as.integer(iris[,5])
const&lt;-create_MLCL(y,50)
res.pcca&lt;-pcca(x,1,const$ML,const$CL)
plot(res.pcca$z,col=y,pch=y)

## End(Not run)

</code></pre>

<hr>
<h2 id='plot.credpart'>Plotting a credal partition</h2><span id='topic+plot.credpart'></span>

<h3>Description</h3>

<p>Generates plots of a credal partition.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'credpart'
plot(
  x,
  X = NULL,
  ...,
  mfrow = c(1, 1),
  ytrue = NULL,
  Outliers = TRUE,
  Approx = 1,
  cex = 1,
  cexvar = "pl",
  cex_outliers = 1.3,
  cex_protos = 1,
  lwd = 2,
  ask = FALSE,
  plot_Shepard = FALSE,
  plot_approx = TRUE,
  plot_protos = TRUE,
  xlab = expression(x[1]),
  ylab = expression(x[2])
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.credpart_+3A_x">x</code></td>
<td>
<p>An object of class <code>"credpart"</code>, encoding a credal partition.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_x">X</code></td>
<td>
<p>A data matrix. If it has more than two columns (attributes), only the first two
columns are used.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_...">...</code></td>
<td>
<p>Other arguments to be passed to the plot function.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_mfrow">mfrow</code></td>
<td>
<p>A 2-vector defining the number of rows and columns of the plot. If mfrow=c(1,1),
only one figure is drawn. Otherwise, mfrow[1] x mfrow[2] should not be less than x, the
number of clusters.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_ytrue">ytrue</code></td>
<td>
<p>The vector of true class labels. If supplied, a different color is used for each true
cluster. Otherwise, the maximum-plausibility clusters are used instead.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_outliers">Outliers</code></td>
<td>
<p>If TRUE, the outliers are plotted, and they are not included in the lower
and upper approximations of the clusters.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_approx">Approx</code></td>
<td>
<p>If Approx==1 (default), the lower and upper cluster approximations are
computed using the interval dominance rule. Otherwise, the maximum mass rule is used.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_cex">cex</code></td>
<td>
<p>Maximum size of data points.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_cexvar">cexvar</code></td>
<td>
<p>Parameter determining if the size of the data points is proportional to the 
plausibilities ('pl', the default), the plausibilities of the normalized credal partition
('pl.n'), the degrees of belief ('bel'), the degrees of belief of the normalized credal partition
('bel.n'), or if it is constant ('cst', default).</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_cex_outliers">cex_outliers</code></td>
<td>
<p>Size of data points for outliers.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_cex_protos">cex_protos</code></td>
<td>
<p>Size of data points for prototypes (if applicable).</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_lwd">lwd</code></td>
<td>
<p>Line width for drawing the lower and upper approximations.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_ask">ask</code></td>
<td>
<p>Logical; if TRUE, the user is asked before each plot.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_plot_shepard">plot_Shepard</code></td>
<td>
<p>Logical; if TRUE and if the credal partition was generated by kevclus
the Shepard diagram is plotted.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_plot_approx">plot_approx</code></td>
<td>
<p>Logical; if TRUE (default) the convex hulls of the lower and upper approximations
are plotted.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_plot_protos">plot_protos</code></td>
<td>
<p>Logical; if TRUE (default) the prototypes are plotted (for methods generating
prototypes, like ECM).</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_xlab">xlab</code></td>
<td>
<p>Label of horizontal axis.</p>
</td></tr>
<tr><td><code id="plot.credpart_+3A_ylab">ylab</code></td>
<td>
<p>Label of vertical axis.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function plots different views of a credal partition in a two-dimensional attribute space. 
If mfrow=c(1,1) (the default), the function plot the dataset with a different symbol for each cluster.
</p>


<h3>Value</h3>

<p>The maximum plausibility hard partition, as well as the lower and upper approximations
of each cluster are drawn in the two-dimensional space specified by matrix <code>X</code>. If
prototypes are defined (for methods <code>"ecm"</code> and <code>"cecm"</code>), they are also
represented on the plot.  For methods <code>"kevclus"</code>, <code>"kcevclus"</code> or <code>"nnevclus"</code>  
a second plot with Shepard's diagram (degrees of conflict vs. transformed dissimilarities) is drawn. 
If input <code>X</code> is not supplied and the Shepard diagram exists, then only the Shepard diagram is drawn.
</p>


<h3>References</h3>

<p>T. Denoeux and O. Kanjanatarakul. Beyond Fuzzy, Possibilistic and Rough: An
Investigation of Belief Functions in Clustering. 8th International conference on soft
methods in probability and statistics, Rome, 12-14 September, 2016.
</p>
<p>M.-H. Masson and T. Denoeux. ECM: An evidential version of the fuzzy c-means algorithm.
Pattern Recognition, Vol. 41, Issue 4, pages 1384&ndash;1397, 2008.
</p>
<p>T. Denoeux, S. Sriboonchitta and O. Kanjanatarakul. Evidential clustering of large
dissimilarity data. Knowledge-Based Systems, vol. 106, pages 179-195, 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extractMass">extractMass</a></code>, <code><a href="#topic+summary.credpart">summary.credpart</a></code>, <code><a href="#topic+ecm">ecm</a></code>,
<code><a href="#topic+recm">recm</a></code>, <code><a href="#topic+cecm">cecm</a></code>, <code><a href="#topic+kevclus">kevclus</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example with Four-class data
data("fourclass")
x&lt;-fourclass[,1:2]
y&lt;-fourclass[,3]
c=4
## Running k-EVCLUS with singletons
clus&lt;-kevclus(x=x,k=100,c=c,type='simple')
## Plot the results
plot(clus,X=x,mfrow=c(2,2),ytrue=y)
</code></pre>

<hr>
<h2 id='predict.credpart'>Computation of a credal partition for new data</h2><span id='topic+predict.credpart'></span>

<h3>Description</h3>

<p><code>predict.credpart</code> is the <code>predict</code> method for <code>"credpart"</code> 
objects generated by <code>nnevclus</code> or <code>ecm</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'credpart'
predict(object, newdata, fhat = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.credpart_+3A_object">object</code></td>
<td>
<p>An object of class <code>"credpart"</code>, encoding a credal partition.</p>
</td></tr>
<tr><td><code id="predict.credpart_+3A_newdata">newdata</code></td>
<td>
<p>A matrix of size ntest*p containing the new data.</p>
</td></tr>
<tr><td><code id="predict.credpart_+3A_fhat">fhat</code></td>
<td>
<p>An optional vector of one-class SVM outputs (for method nn-evclus only)</p>
</td></tr>
<tr><td><code id="predict.credpart_+3A_...">...</code></td>
<td>
<p>Additional arguments (not used).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function computes a credal partial of newdata based on learnt information stored 
in a <code>"credpart"</code> objects created by <code><a href="#topic+ecm">ecm</a></code> or <code><a href="#topic+nnevclus">nnevclus</a></code>.
</p>


<h3>Value</h3>

<p>A credal partition of the new data.
</p>


<h3>References</h3>

<p>T. Denoeux and O. Kanjanatarakul. Beyond Fuzzy, Possibilistic and Rough: An
Investigation of Belief Functions in Clustering. 8th International conference on soft
methods in probability and statistics, Rome, 12-14 September, 2016.
</p>
<p>M.-H. Masson and T. Denoeux. ECM: An evidential version of the fuzzy c-means algorithm.
Pattern Recognition, Vol. 41, Issue 4, pages 1384&ndash;1397, 2008.
</p>
<p>T. Denoeux, S. Sriboonchitta and O. Kanjanatarakul. Evidential clustering of large
dissimilarity data. Knowledge-Based Systems, vol. 106, pages 179-195, 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ecm">ecm</a></code>, <code><a href="#topic+cecm">cecm</a></code>, <code><a href="#topic+nnevclus">nnevclus</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(fourclass)
train&lt;-sample(400,200)
x&lt;-fourclass[train,1:2]
x.test&lt;-x[-train,1:2]
clus&lt;-ecm(x,c=4,type='pairs',delta=sqrt(10),epsi=1e-3,disp=TRUE)
clus.test&lt;-predict(clus,x.test)
plot(clus.test,x.test,mfrow=c(2,2))

## End(Not run)
</code></pre>

<hr>
<h2 id='protein'>Protein dataset</h2><span id='topic+protein'></span>

<h3>Description</h3>

<p>This real data set consists of a dissimilarity matrix derived from the structural
comparison of 213 protein sequences. Each of these proteins is known to belong to one of four
classes of globins: hemoglobin-alpha (HA), hemoglobin-beta (HB), myoglobin (M) and
heterogeneous globins (G).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(protein)
</code></pre>


<h3>Format</h3>

<p>A list with three elements:
</p>

<dl>
<dt>D</dt><dd><p>The 213x213 dissimilarity matrix.</p>
</dd>
<dt>class</dt><dd><p>A 213-vector containing the class encoded a a factor with four levels:
&quot;G&quot;, &quot;HA&quot;, &quot;HB&quot;, &quot;M&quot;.</p>
</dd>
<dt>y</dt><dd><p>A 213-vector containing the class encoded by an integer between 1 and 4.</p>
</dd>
</dl>



<h3>References</h3>

<p>T. Hofmann,and J. Buhmann. Pairwise data clustering by deterministic annealing. IEEE
Transactions on Pattern Analysis and Machine Intelligence, 19(1):1&ndash;14, 1997.
</p>
<p>T. Graepel, R. Herbrich, P. Bollmann-Sdorra, and K. Obermayer. Classification on pairwise
proximity data. in Advances in Neural Information Processing Systems 11, M. Kearns,
S. Solla, and D. Kohn, eds., MIT Press, Cambridge, MA, 438&ndash;444, 1999.
</p>
<p>T. Denoeux and M.-H. Masson. EVCLUS: Evidential Clustering of Proximity Data.
IEEE Transactions on Systems, Man and Cybernetics B, Vol. 34, Issue 1, 95&ndash;109, 2004.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(protein)
z&lt;- cmdscale(protein$D,k=2)  # Multidimensional scaling
plot(z[,1],z[,2],xlab=expression(z[1]),ylab=expression(z[2]),pch=protein$y,col=protein$y)
</code></pre>

<hr>
<h2 id='recm'>Relational Evidential c-means algorithm</h2><span id='topic+recm'></span>

<h3>Description</h3>

<p><code>recm</code> computes a credal partition from a dissimilarity matrix using the
Relational Evidential c-means (RECM) algorithm.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>recm(
  D,
  c,
  type = "full",
  pairs = NULL,
  Omega = TRUE,
  m0 = NULL,
  ntrials = 1,
  alpha = 1,
  beta = 1.5,
  delta = quantile(D[upper.tri(D) | lower.tri(D)], 0.95),
  epsi = 1e-04,
  maxit = 5000,
  disp = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="recm_+3A_d">D</code></td>
<td>
<p>Dissimilarity matrix of size (n,n), where n is the number of objects.
Dissimilarities must be squared Euclidean distances to ensure convergence.</p>
</td></tr>
<tr><td><code id="recm_+3A_c">c</code></td>
<td>
<p>Number of  clusters.</p>
</td></tr>
<tr><td><code id="recm_+3A_type">type</code></td>
<td>
<p>Type of focal sets (&quot;simple&quot;: empty set, singletons and Omega;
&quot;full&quot;: all <code class="reqn">2^c</code> subsets of <code class="reqn">\Omega</code>; &quot;pairs&quot;: <code class="reqn">\emptyset</code>, singletons,
<code class="reqn">\Omega</code>, and all or selected pairs).</p>
</td></tr>
<tr><td><code id="recm_+3A_pairs">pairs</code></td>
<td>
<p>Set of pairs to be included in the focal sets; if NULL, all pairs are
included. Used only if type=&quot;pairs&quot;.</p>
</td></tr>
<tr><td><code id="recm_+3A_omega">Omega</code></td>
<td>
<p>Logical. If TRUE (default), the whole frame is included (for types 'simple' and
'pairs').</p>
</td></tr>
<tr><td><code id="recm_+3A_m0">m0</code></td>
<td>
<p>Initial credal partition. Should be a matrix with n rows and a number of
columns equal to the number f of focal sets specified by 'type' and 'pairs'.</p>
</td></tr>
<tr><td><code id="recm_+3A_ntrials">ntrials</code></td>
<td>
<p>Number of runs of the optimization algorithm (set to 1 if m0 is  supplied).</p>
</td></tr>
<tr><td><code id="recm_+3A_alpha">alpha</code></td>
<td>
<p>Exponent of the cardinality in the cost function.</p>
</td></tr>
<tr><td><code id="recm_+3A_beta">beta</code></td>
<td>
<p>Exponent of masses in the cost function.</p>
</td></tr>
<tr><td><code id="recm_+3A_delta">delta</code></td>
<td>
<p>Distance to the empty set.</p>
</td></tr>
<tr><td><code id="recm_+3A_epsi">epsi</code></td>
<td>
<p>Minimum amount of improvement.</p>
</td></tr>
<tr><td><code id="recm_+3A_maxit">maxit</code></td>
<td>
<p>Maximum number of iterations.</p>
</td></tr>
<tr><td><code id="recm_+3A_disp">disp</code></td>
<td>
<p>If TRUE (default), intermediate results are displayed.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>RECM is a relational version of the Evidential c-Means (ECM) algorithm. Convergence is
guaranteed only if elements of matrix D are squared Euclidean distances. However, the
algorithm is quite robust and generally provides sensible results even if the dissimilarities
are not metric. By default, each mass function in the credal partition has <code class="reqn">2^c</code> focal sets,
where c is the supplied number of clusters. We can also limit the number of focal sets to
subsets of clusters with cardinalities 0, 1 and c (recommended if c&gt;=10), or to all or some
selected pairs of clusters.
If an initial credal partition m0 is provided, the number of trials is automatically set to 1.
</p>


<h3>Value</h3>

<p>The credal partition (an object of class <code>"credpart"</code>).
</p>


<h3>Author(s)</h3>

<p>Thierry Denoeux (from a MATLAB code written by Marie-Helene Masson).
</p>


<h3>References</h3>

<p>M.-H. Masson and T. Denoeux. RECM: Relational Evidential c-means algorithm.
Pattern Recognition Letters, Vol. 30, pages 1015&ndash;1026, 2009.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+makeF">makeF</a></code>, <code><a href="#topic+extractMass">extractMass</a></code>, <code><a href="#topic+ecm">ecm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Clustering of the Butterfly dataset
## Not run: 
n &lt;- nrow(butterfly)
D&lt;-as.matrix(dist(butterfly))^2
clus&lt;-recm(D,c=2,delta=sqrt(50))
m&lt;-clus$mass
plot(1:n,m[,1],type="l",ylim=c(0,1),xlab="objects",ylab="masses")
lines(1:n,m[,2],lty=2)
lines(1:n,m[,3],lty=3)
lines(1:n,m[,4],lty=4)

 ## Clustering the protein data
 data(protein)
 clus &lt;- recm(D=protein$D,c=4,type='full',alpha=0.2,beta=1.1,delta=sqrt(20))

 z&lt;- cmdscale(protein$D,k=2)
 plot(clus,X=z,mfrow=c(2,2),ytrue=protein$y,Outliers=FALSE,Approx=1)
 
## End(Not run)
</code></pre>

<hr>
<h2 id='s2'>S2 dataset</h2><span id='topic+s2'></span>

<h3>Description</h3>

<p>This dataset contains 5000 two-dimensional vectors grouped in 15 Gaussian clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(s2)
</code></pre>


<h3>Format</h3>

<p>A matrix with 5000 rows and two columns.
</p>


<h3>References</h3>

<p>P. Franti and O. Virmajoki. Iterative shrinking method for clustering problems.
Pattern Recognition, 39(5):761&ndash;775, 2006.
</p>
<p>T. Denoeux, O. Kanjanatarakul and S. Sriboonchitta.
EK-NNclus: a clustering procedure based on the evidential K-nearest neighbor rule.
Knowledge-Based Systems, Vol. 88, pages 57&ndash;69, 2015.
</p>
<p>T. Denoeux, S. Sriboonchitta and O. Kanjanatarakul. Evidential clustering of large
dissimilarity data. Knowledge-Based Systems (accepted for publication),
DOI: 10.1016/j.knosys.2016.05.043, 2016.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(s2)
plot(s2[,1],s2[,2],xlab=expression(x[1]),ylab=expression(x[2]))
</code></pre>

<hr>
<h2 id='summary.credpart'>Summary of a credal partition</h2><span id='topic+summary.credpart'></span>

<h3>Description</h3>

<p><code>summary.credpart</code> is the <code>summary</code> method for <code>"credpart"</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'credpart'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.credpart_+3A_object">object</code></td>
<td>
<p>An object of class <code>"credpart"</code>, encoding a credal partition.</p>
</td></tr>
<tr><td><code id="summary.credpart_+3A_...">...</code></td>
<td>
<p>Additional arguments (not used).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function extracts basic information from <code>"credpart"</code> objects, such as created by
<code><a href="#topic+ecm">ecm</a></code>, <code><a href="#topic+recm">recm</a></code>, <code><a href="#topic+cecm">cecm</a></code>, <code><a href="#topic+EkNNclus">EkNNclus</a></code>or
<code><a href="#topic+kevclus">kevclus</a></code>.
</p>


<h3>Value</h3>

<p>Prints basic information on the credal partition.
</p>


<h3>References</h3>

<p>T. Denoeux and O. Kanjanatarakul. Beyond Fuzzy, Possibilistic and Rough: An
Investigation of Belief Functions in Clustering. 8th International conference on soft
methods in probability and statistics, Rome, 12-14 September, 2016.
</p>
<p>M.-H. Masson and T. Denoeux. ECM: An evidential version of the fuzzy c-means algorithm.
Pattern Recognition, Vol. 41, Issue 4, pages 1384&ndash;1397, 2008.
</p>
<p>T. Denoeux, S. Sriboonchitta and O. Kanjanatarakul. Evidential clustering of large
dissimilarity data. Knowledge-Based Systems, vol. 106, pages 179-195, 2016.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+extractMass">extractMass</a></code>, <code><a href="#topic+plot.credpart">plot.credpart</a></code>, <code><a href="#topic+ecm">ecm</a></code>,
<code><a href="#topic+recm">recm</a></code>, <code><a href="#topic+cecm">cecm</a></code>, <code><a href="#topic+EkNNclus">EkNNclus</a></code>, <code><a href="#topic+kevclus">kevclus</a></code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Example with Four-class data
data("fourclass")
x&lt;-fourclass[,1:2]
y&lt;-fourclass[,3]
c=4
## Running k-EVCLUS with singletons
clus&lt;-kevclus(x=x,k=100,c=c,type='simple')
summary(clus)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
