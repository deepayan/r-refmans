<!DOCTYPE html><html><head><title>Help for package iForecast</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {iForecast}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#data-sets'><p>Economic and Financial Data Sets</p></a></li>
<li><a href='#iForecast'><p>Extract predictions and class probabilities from train objects</p></a></li>
<li><a href='#rollingWindows'><p>Rolling timeframe for time series anaysis</p></a></li>
<li><a href='#ttsAutoML'><p>Train time series by automatic machine learning of <code>h2o</code> provided by H2O.ai</p></a></li>
<li><a href='#ttsCaret'><p>Train time series by <code>caret</code> and produce two types of time series forecasts: static and recursive</p></a></li>
<li><a href='#ttsLSTM'><p>Train time series by LSTM of <code>tensorflow</code> provided by <code>kera</code></p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Machine Learning Time Series Forecasting</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.7</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-07-01</td>
</tr>
<tr>
<td>Author:</td>
<td>Ho Tsung-wu</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Ho Tsung-wu &lt;tsungwu@ntnu.edu.tw&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Compute static, onestep and multistep time series forecasts for machine learning models.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5),caret</td>
</tr>
<tr>
<td>Imports:</td>
<td>magrittr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>data.table, forecast, h2o, keras, kernlab, lubridate,
tensorflow, tibble, timeSeries, timeDate, timetk, zoo</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-07-01 01:38:00 UTC; badal</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-07-01 08:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='data-sets'>Economic and Financial Data Sets</h2><span id='topic+ES_15m'></span><span id='topic+ES_Daily'></span><span id='topic+macrodata'></span><span id='topic+bc'></span>

<h3>Description</h3>

<p>ES_15m is 15-min realized absolute variance of e-mini S&amp;P 500. macrodata contains monthly US unemployment(unrate), ES_Daily is daily realized absolute variance of e-mini S&amp;P 500. macrodata contains monthly US unemployment(unrate) and  and year-to-year changes in three regional business cycle indices (OECD, NAFTA, and G7).
bc contains monthly business cycle data, bc is binary indicator(0=recession, 1=boom) of Taiwan's business cycle phases, IPI_TWN is industrial production index of Taiwan, LD_OECD, LD_G7, and LD_NAFTA are leading indicators of OECD, G7 and NAFTA regions; all four are monthly rate of changes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ES_15m)
data(macrodata)
data(ES_Daily)
data(bc)
</code></pre>


<h3>Value</h3>

<p>an object of class <code>"zoo"</code>.
</p>

<hr>
<h2 id='iForecast'>Extract predictions and class probabilities from train objects</h2><span id='topic+iForecast'></span>

<h3>Description</h3>

<p>It generates both the static and recursive time series plots of machine learning prediction object generated by ttsCaret, ttsAutoML and ttsLSTM.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>iForecast(Model,newdata,type)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="iForecast_+3A_model">Model</code></td>
<td>

<p>Object of trained model.
</p>
</td></tr>
<tr><td><code id="iForecast_+3A_newdata">newdata</code></td>
<td>
<p>The dataset for pediction, the column names must be the same as the trained data.
</p>
</td></tr>
<tr><td><code id="iForecast_+3A_type">type</code></td>
<td>
<p> If type=&quot;static&quot;, it computes the (static) forecasting values of insample model fit. If type=&quot;dynamic&quot;, it iteratively computes the multistep forecasting values given the insample estimated model. For dynamic forecasts, AR term is required.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function generates forecasts of ttsCaret,ttsAutoML, and ttsLSTM.
</p>


<h3>Value</h3>

<table>
<tr><td><code>prediction</code></td>
<td>
<p>The forecasted time series target variable. For binary case, it returns both porbabilities and class.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ho Tsung-wu &lt;tsungwu@ntnu.edu.tw&gt;, College of Management, National Taiwan Normal University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Cross-validation takes time, example below is commented.
## Machine Learning by library(caret)
#Case 1. Low frequency, regression type
data("macrodata")
dep &lt;- macrodata[569:669,"unrate",drop=FALSE]
ind &lt;- macrodata[569:669,-1,drop=FALSE]
train.end &lt;- "2018-12-01"# Choosing the end dating of train

models &lt;- c("svm","rf","rpart")[1]
type &lt;- c("none","trend","season","both")[1]
#Caret &lt;- ttsCaret(y=dep, x=ind, arOrder=c(1), xregOrder=c(1),
# method=models, tuneLength =1, train.end, type=type,resampling="cv",preProcess = #"center")
# testData1 &lt;- window(Caret$data,start="2019-01-01",end=end(Caret$data))
#P1 &lt;- iForecast(Model=Caret,newdata=testData1,type="static")
#P2 &lt;- iForecast(Model=Caret,newdata=testData1,type="dynamic")

#tail(cbind(testData1[,1],P1))
#tail(cbind(testData1[,1],P2))

#Case 2. Low frequency, binary type
data(bc) #binary dependent variable, business cycle phases
dep=bc[,1,drop=FALSE]
ind=bc[,-1]

train.end=as.character(rownames(dep))[as.integer(nrow(dep)*0.8)]
test.start=as.character(rownames(dep))[as.integer(nrow(dep)*0.8)+1]

#Caret = ttsCaret(y=dep, x=ind, arOrder=c(1), xregOrder=c(1), method=models,
#                   tuneLength =10, train.end, type=type)

#testData1=window(Caret$data,start=test.start,end=end(Caret$data))

#head(Caret$dataused)
#P1=iForecast(Model=Caret,newdata=testData1,type="static")
#P2=iForecast(Model=Caret,newdata=testData1,type="dynamic")

#tail(cbind(testData1[,1],P1),10)
#tail(cbind(testData1[,1],P2),10)

</code></pre>

<hr>
<h2 id='rollingWindows'>Rolling timeframe for time series anaysis</h2><span id='topic+rollingWindows'></span>

<h3>Description</h3>

<p>It extracts time stamp from a timeSeries object and separates the time into in-sample training and out-of-sample validation ranges.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rollingWindows(x,estimation="18m",by = "6m")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="rollingWindows_+3A_x">x</code></td>
<td>
<p>The time series matrix (vector) with <code>timeSeries</code> or <code>zoo</code> format of &quot;
</p>
</td></tr>
<tr><td><code id="rollingWindows_+3A_estimation">estimation</code></td>
<td>
<p>The range of insample estimation period, the default is 18 months(18m), where the k-fold cross-section is performed. Week and day are also supported  (see example).
</p>
</td></tr>
<tr><td><code id="rollingWindows_+3A_by">by</code></td>
<td>
<p>The range of out-of-sample validation/testing period, the default is 6 months(6m).Week and day are also supported (see example).
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is similar to the backtesting framework in portfolio analysis. Rolling windows fixes the origin and  the training sample grows over time, moving windows can be achieved by placing window() on dependent variable at each iteration.
</p>


<h3>Value</h3>

<table>
<tr><td><code>window</code></td>
<td>
<p>The time labels of from and to</p>
</td></tr></table>
<p>.</p>


<h3>Author(s)</h3>

<p>Ho Tsung-wu &lt;tsungwu@ntnu.edu.tw&gt;, College of Management, National Taiwan Normal University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(macrodata)
y=macrodata[,1,drop=FALSE]
timeframe=rollingWindows(y,estimation="300m",by="6m")
#estimation="300m", because macrodata is monthly
FROM=timeframe$from
TO=timeframe$to

data(ES_Daily)
y=ES_Daily[,1,drop=FALSE]
timeframe=rollingWindows(y,estimation  ="60w",by="1w")
#60 weeks as estimation windowand move by 1 week.

FROM=timeframe$from
TO=timeframe$to

y=ES_Daily[,1,drop=FALSE]
timeframe=rollingWindows(y,estimation  ="250d",by="1d")
#250-day as estimation window and move by 1 days.

</code></pre>

<hr>
<h2 id='ttsAutoML'>Train time series by automatic machine learning of <code>h2o</code> provided by H2O.ai</h2><span id='topic+ttsAutoML'></span>

<h3>Description</h3>

<p>It generates  both the static and recursive time series plots of H2O.ai object generated by package <code>h2o</code> provided by H2O.ai.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ttsAutoML(y,x=NULL,train.end,arOrder=2,xregOrder=0,maxSecs=30)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ttsAutoML_+3A_y">y</code></td>
<td>

<p>The time series object of the target variable, or the dependent variable, with <code>timeSeries</code> or <code>zoo</code> format, must have dimension. y can be either binary or continuous. Time format must be &quot;
</p>
</td></tr>
<tr><td><code id="ttsAutoML_+3A_x">x</code></td>
<td>
<p> The time series matrix of input variables, or the independent variables,  with <code>timeSeries</code> or <code>zoo</code> format. Time format must be &quot;
</p>
</td></tr>
<tr><td><code id="ttsAutoML_+3A_train.end">train.end</code></td>
<td>
<p>The end date of training data, must be specificed. The default dates of train.start and test.end are the start and the end of input data; and the test.start is the 1-period next of train.end.
</p>
</td></tr>
<tr><td><code id="ttsAutoML_+3A_arorder">arOrder</code></td>
<td>
<p>The autoregressive order of the target variable, which may be sequentially specifed like arOrder=1:5; or discontinuous lags like arOrder=c(1,3,5); zero is not allowed.
</p>
</td></tr>
<tr><td><code id="ttsAutoML_+3A_xregorder">xregOrder</code></td>
<td>
<p>The distributed lag structure of the input variables, which may be sequentially specifed like xregOrder=1:5; or discontinuous lags like xregOrder=c(0,3,5); zero is allowed since contemporaneous correlation is allowed.
</p>
</td></tr>
<tr><td><code id="ttsAutoML_+3A_maxsecs">maxSecs</code></td>
<td>
<p>The maximal run time specified, in seconds. Default=20.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls the h2o.automl function from package <code>h2o</code> to execute automatic machine learning estimation. When execution finished, it computes two types of time series forecasts: static and recursive. The procedure of h2o.automl automatically generates a lot of time features.
</p>


<h3>Value</h3>

<table>
<tr><td><code>output</code></td>
<td>
<p>Output object generated by train function of <code>caret</code>.</p>
</td></tr>
<tr><td><code>arOrder</code></td>
<td>
<p>The autoregressive order of the target variable used.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>The dataset of imputed.</p>
</td></tr>
<tr><td><code>dataused</code></td>
<td>
<p>The data used by arOrder, xregOrder</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ho Tsung-wu &lt;tsungwu@ntnu.edu.tw&gt;, College of Management, National Taiwan Normal University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Cross-validation takes time, example below is commented.
data("macrodata")
dep&lt;-macrodata[,"unrate",drop=FALSE]
ind&lt;-macrodata[,-1,drop=FALSE]

# Choosing the dates of training and testing data
train.end&lt;-"2008-12-01"

#autoML of H2O.ai

#autoML &lt;- ttsAutoML(y=dep, x=ind, train.end,arOrder=c(2,4),
# xregOrder=c(0,1,3), maxSecs =30)
#testData2 &lt;- window(autoML$dataused,start="2009-01-01",end=end(autoML$data))
#P1&lt;-iForecast(Model=autoML,newdata=testData2,type="static")
#P2&lt;-iForecast(Model=autoML,newdata=testData2,type="dynamic")

#tail(cbind(testData2[,1],P1))
#tail(cbind(testData2[,1],P2))


</code></pre>

<hr>
<h2 id='ttsCaret'>Train time series by <code>caret</code> and produce two types of time series forecasts: static and recursive</h2><span id='topic+ttsCaret'></span>

<h3>Description</h3>

<p>It generates both the static and recursive time series plots of machine learning prediction object generated by package <code>caret</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>
ttsCaret(
  y,
  x=NULL,
  method,
  train.end,
  arOrder=2,
  xregOrder=0,
  type,
  tuneLength =10,
  preProcess = NULL,
  resampling="boot",
  Number=NULL,
  Repeat=NULL)

</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ttsCaret_+3A_y">y</code></td>
<td>

<p>The time series object of the target variable, or the dependent variable,  with <code>timeSeries</code> or <code>zoo</code> format, must have dimension. y can be either binary or continuous.Time format must be &quot;
</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_x">x</code></td>
<td>
<p> The time series matrix of input variables, or the independent variables,  with <code>timeSeries</code> or <code>zoo</code> format.Time format must be &quot;
</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_method">method</code></td>
<td>
<p>The train_model_list of <code>caret</code>. While using this, make sure that the method allows regression. Methods in c(&quot;svm&quot;,&quot;rf&quot;,&quot;rpart&quot;,&quot;gamboost&quot;,&quot;BstLm&quot;,&quot;bstSm&quot;,&quot;blackboost&quot;) are feasible.
</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_train.end">train.end</code></td>
<td>
<p>The end date of training data, must be specificed.The default dates of train.start and test.end are the start and the end of input data; and the test.start is the 1-period next of train.end.
</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_arorder">arOrder</code></td>
<td>
<p>The autoregressive order of the target variable, which may be sequentially specifed like arOrder=1:5; or discontinuous lags like arOrder=c(1,3,5); zero is not allowed.
</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_xregorder">xregOrder</code></td>
<td>
<p>The distributed lag structure of the input variables, which may be sequentially specifed like xregOrder=0:5; or discontinuous lags like xregOrder=c(0,3,5); zero is allowed since contemporaneous correlation is allowed.
</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_type">type</code></td>
<td>
<p>The additional input variables. We have four selection:<br /> &quot;none&quot;=no other variables,<br /> &quot;trend&quot;=inclusion of time dummy, <br /> &quot;season&quot;=inclusion of seasonal dummies, <br /> &quot;both&quot;=inclusion of both trend and season. No default.
</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_tunelength">tuneLength</code></td>
<td>
<p>The same as the length specified in  train function of package <code>caret</code>.
</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_preprocess">preProcess</code></td>
<td>
<p>Whether to pre-process the data, current possibilities are &quot;BoxCox&quot;, &quot;YeoJohnson&quot;, &quot;expoTrans&quot;, &quot;center&quot;, &quot;scale&quot;, &quot;range&quot;, &quot;knnImpute&quot;, &quot;bagImpute&quot;, &quot;medianImpute&quot;, &quot;pca&quot;, &quot;ica&quot; and &quot;spatialSign&quot;.The default is no pre-processing. </p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_resampling">resampling</code></td>
<td>
<p>The method for resampling, as trainControl function list in package <code>caret</code>. The default is &quot;boot&quot; for  bootstrapping with 25 replications. Current choices are c(&quot;cv&quot;,&quot;boot&quot;,&quot;repeatedcv&quot;,&quot;LOOCV&quot;) where &quot;cv&quot; is K-fold CV with a default K=10 or specified by the &quot;Number&quot; below, &quot;LOOCV&quot; denotes the leave-one-out CV</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_number">Number</code></td>
<td>
<p>The number of K for K-Fold CV, default (NULL) is 10; for &quot;boot&quot; option, the default number of replications is 25</p>
</td></tr>
<tr><td><code id="ttsCaret_+3A_repeat">Repeat</code></td>
<td>
<p>The number for the repeatition for &quot;repeatedcv&quot;. </p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function calls the train function of package <code>caret</code> to execute estimation. When execution finished, we compute two types of time series forecasts: static and recursive.
</p>


<h3>Value</h3>

<table>
<tr><td><code>output</code></td>
<td>
<p>Output object generated by train function of <code>caret</code>.</p>
</td></tr>
<tr><td><code>arOrder</code></td>
<td>
<p>The autoregressive order of the target variable used.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>The dataset of imputed.</p>
</td></tr>
<tr><td><code>dataused</code></td>
<td>
<p>The data used by arOrder, xregOrder, and type.</p>
</td></tr>
<tr><td><code>training.Pred</code></td>
<td>
<p>All tuned prediction values of training data, using besTunes to extract the best prediction.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ho Tsung-wu &lt;tsungwu@ntnu.edu.tw&gt;, College of Management, National Taiwan Normal University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Cross-validation takes time, example below is commented.
## Machine Learning by library(caret)
library(zoo)
#Case 1. Low frequency
data("macrodata")
dep &lt;- macrodata[569:669,"unrate",drop=FALSE]
ind &lt;- macrodata[569:669,-1,drop=FALSE]
train.end &lt;- "2018-12-01"# Choosing the end dating of train

models &lt;- c("glm","knn","nnet","rpart","rf","svm","enet","gbm","lasso","bridge")[2]
type &lt;- c("none","trend","season","both")[1]
Caret &lt;- ttsCaret(y=dep, x=NULL, arOrder=c(1), xregOrder=c(1),
 method=models, tuneLength =1, train.end, type=type,
 resampling=c("boot","cv","repeatedcv")[2],preProcess = "center")
 testData1 &lt;- window(Caret$data,start="2019-01-01",end=end(Caret$data))
P1 &lt;- iForecast(Model=Caret,newdata=testData1,type="static")
P2 &lt;- iForecast(Model=Caret,newdata=testData1,type="dynamic")

tail(cbind(testData1[,1],P1,P2))

#Case 2. High frequency
#head(ES_15m)
#head(ES_Daily)
#dep &lt;- ES_15m #SP500 15-minute realized absolute variance
#ind &lt;- NULL
#train.end &lt;- as.character(rownames(dep))[as.integer(nrow(dep)*0.9)]

#models&lt;-c("svm","rf","rpart","gamboost","BstLm","bstSm","blackboost")[1]
#type&lt;-c("none","trend","season","both")[1]
# Caret &lt;- ttsCaret(y=dep, x=ind, arOrder=c(3,5), xregOrder=c(0,2,4),
# method=models, tuneLength =10, train.end, type=type,
# resampling=c("boot","cv","repeatedcv")[2],preProcess = "center")
#testData1&lt;-window(Caret$data,start="2009-01-01",end=end(Caret$data))
#P1&lt;-iForecast(Model=Caret,newdata=testData1,type="static")
#P2&lt;-iForecast(Model=Caret,newdata=testData1,type="dynamic")

</code></pre>

<hr>
<h2 id='ttsLSTM'>Train time series by LSTM of <code>tensorflow</code> provided by <code>kera</code></h2><span id='topic+ttsLSTM'></span>

<h3>Description</h3>

<p>It generates  both the static and recursive time series plots of deep learning LSTM object generated by package <code>tensorflow</code> provided by <code>kera</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ttsLSTM(y,
  x=NULL,
  train.end,
  arOrder=1,
  xregOrder=0,
  type,
  memoryLoops=10,
  shape=NULL,
  dim3=5,
  batch.range=2:7,
  batch.size=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ttsLSTM_+3A_y">y</code></td>
<td>

<p>The time series object of the target variable, or the dependent variable,  with <code>timeSeries</code> or <code>zoo</code> format, must have dimension. y can be both continuous and discrete.Time format must be &quot;
</p>
</td></tr>
<tr><td><code id="ttsLSTM_+3A_x">x</code></td>
<td>
<p> The time series matrix of input variables, or the independent variables,  with <code>timeSeries</code> or <code>zoo</code> format. Time format must be &quot;
</p>
</td></tr>
<tr><td><code id="ttsLSTM_+3A_train.end">train.end</code></td>
<td>
<p>The end date of training data, must be specificed.The default dates of train.start and test.end are the start and the end of input data; and the test.start is the 1-period next of train.end.
</p>
</td></tr>
<tr><td><code id="ttsLSTM_+3A_arorder">arOrder</code></td>
<td>
<p>The autoregressive order of the target variable, which may be sequentially specifed like arOrder=1:5; or discontinuous lags like arOrder=c(1,3,5); zero is not allowed.Default is 1.
</p>
</td></tr>
<tr><td><code id="ttsLSTM_+3A_xregorder">xregOrder</code></td>
<td>
<p>The distributed lag structure of the input variables, which may be sequentially specifed like xregOrder=1:5; or discontinuous lags like xregOrder=c(0,3,5); zero is allowed since contemporaneous correlation is allowed.
</p>
</td></tr>
<tr><td><code id="ttsLSTM_+3A_type">type</code></td>
<td>
<p>The additional input variables. We have four selection:<br /> &quot;none&quot;=no other variables,<br /> &quot;trend&quot;=inclusion of time dummy, <br /> &quot;season&quot;=inclusion of seasonal dummies, <br /> &quot;both&quot;=inclusion of both trend and season. No default.
</p>
</td></tr>
<tr><td><code id="ttsLSTM_+3A_memoryloops">memoryLoops</code></td>
<td>
<p>Length of LSTM learning network loop, to achieve better learning results, this not is suggested to be the same as the length of data row. Default is 10.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="ttsLSTM_+3A_shape">shape</code></td>
<td>
<p>The second dmension of LSTM array. If NULL, then it will use the number of columns of complete dataset.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="ttsLSTM_+3A_dim3">dim3</code></td>
<td>
<p>The third dmension of LSTM array. Default is 5.</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="ttsLSTM_+3A_batch.range">batch.range</code></td>
<td>
<p>The range of search batch.size. The code selects the first that satisfies exact division with the rows of data used</p>
</td></tr></table>
<p>.
</p>
<table>
<tr><td><code id="ttsLSTM_+3A_batch.size">batch.size</code></td>
<td>
<p>The number of batch size for LSTM layer. Default is NULL determined by searching among the batch.range.</p>
</td></tr></table>
<p>.
</p>


<h3>Details</h3>

<p>This function calls the function fit of package <code>tensorflow</code> to execute Long-Short Term Memory (LSTM) estimation. When execution finished, it computes two types of time series forecasts: static and recursive.
</p>


<h3>Value</h3>

<table>
<tr><td><code>output</code></td>
<td>
<p>Output object generated by train function of <code>caret</code>.</p>
</td></tr>
<tr><td><code>batch.size</code></td>
<td>
<p>The batch.size used for LSTM network.</p>
</td></tr>
<tr><td><code>k</code></td>
<td>
<p>The third dimension of arrayin LSTM network.</p>
</td></tr>
<tr><td><code>SHAPE</code></td>
<td>
<p>The shape size  of array in LSTM network.</p>
</td></tr>
<tr><td><code>arOrder</code></td>
<td>
<p>he autoregressive order of the target variable used.</p>
</td></tr>
<tr><td><code>data</code></td>
<td>
<p>The dataset of used.</p>
</td></tr>
<tr><td><code>dataused</code></td>
<td>
<p>The data used by arOrder, xregOrder, and type</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Ho Tsung-wu &lt;tsungwu@ntnu.edu.tw&gt;, College of Management, National Taiwan Normal University.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Cross-validation takes time, example below is commented.
data("macrodata")
dep&lt;-macrodata[,"unrate",drop=FALSE]
ind&lt;-macrodata[,-1,drop=FALSE]

# Choosing the dates of training and testing data
train.end&lt;-"2008-12-01"


#RNN with LSTM network
#LSTM&lt;-ttsLSTM(y=dep, x=ind, train.end,arOrder=c(2,4), xregOrder=c(1,4),
# memoryLoops=5, type=c("none","trend","season","both")[4],
# batch.range=2:7,batch.size=NULL)

#testData3&lt;-window(LSTM$dataused,start="2009-01-01",end=end(LSTM$data))
#P1&lt;-iForecast(Model=LSTM,newdata=testData3,type="static")
#P2&lt;-iForecast(Model=LSTM,newdata=testData3,type="dynamic")

#tail(cbind(testData3[,1],P1,P2))



</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
