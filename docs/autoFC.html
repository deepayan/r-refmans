<!DOCTYPE html><html lang="en"><head><title>Help for package autoFC</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {autoFC}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#build_scale_with_blueprint'><p>Construct Forced-Choice Blocks Aligned with the Specifications in a Blueprint</p></a></li>
<li><a href='#build_TIRT_var_names'><p>Build Variable Names for the Pairwise/Rank Responses in the TIRT Model</p></a></li>
<li><a href='#cal_block_energy'><p>Calculation of Item Block &quot;Energy&quot;</p></a></li>
<li><a href='#cal_block_energy_with_iia'><p>Calculation of Item Block &quot;Energy&quot; with IIAs Included</p></a></li>
<li><a href='#construct_blueprint'><p>Build a Blueprint Data Frame for the Focal FC Scale</p></a></li>
<li><a href='#convert_to_TIRT_response'><p>Convert the Latent Utility Values into Thurstonian IRT Pairwise/Rank Responses</p>
with Pre-Specified Block Design</a></li>
<li><a href='#empirical_reliability'><p>Calculate the Empirical Reliability of the Latent Trait Scores,</p>
Following the Formula in Brown &amp; Maydeu-Olivares (2018).</a></li>
<li><a href='#facfun'><p>Function for Checking If All Items in a Vector Are Unique</p></a></li>
<li><a href='#fit_TIRT_model'><p>Fit the Thurstonian IRT Model with Long Format Response Data</p></a></li>
<li><a href='#get_CFA_estimates'><p>Conduct Confirmatory Factor Analysis (CFA) and Obtain Parameter Estimates</p></a></li>
<li><a href='#get_iia'><p>Helper Function for Outputting IIA Characteristics of Each Block</p></a></li>
<li><a href='#get_simulation_matrices'><p>Generate Simulated Person and Item Parameter Matrices for the Thurstonian IRT Model</p>
Based on Confirmatory Factor Analysis Results</a></li>
<li><a href='#get_TIRT_long_data'><p>Convert the TIRT Pairwise/Rank Response Data into Long Format Compatible with the thurstonianIRT Package</p></a></li>
<li><a href='#HEXACO_example_data'><p>Example HEXACO Response Data</p></a></li>
<li><a href='#make_random_block'><p>Construction of Random Item Blocks</p></a></li>
<li><a href='#plot_scores'><p>Scatter Plot for True vs Estimated Scores, True Score vs Absolute Error, etc.</p></a></li>
<li><a href='#predict_scores'><p>Predict trait scores based on estimated model</p></a></li>
<li><a href='#RMSE_range'><p>Calculate the Overall RMSE of the Trait Scores, or the RMSE in a Certain Trait Score Range</p></a></li>
<li><a href='#sa_pairing_generalized'><p>Automatic Item Pairing Method in Forced-Choice Test Construction</p></a></li>
<li><a href='#triplet_block_info'><p>Block Information for the Example Triplet Response Data</p></a></li>
<li><a href='#triplet_example_data'><p>Example Triplet Response Data</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Automatic Construction of Forced-Choice Tests</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0.1002</td>
</tr>
<tr>
<td>Author:</td>
<td>Mengtong Li <a href="https://orcid.org/0000-0002-1766-4976"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [cre,
    aut],
  Tianjun Sun <a href="https://orcid.org/0000-0002-3655-0042"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Bo Zhang <a href="https://orcid.org/0000-0002-6730-7336"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Mengtong Li &lt;ml70@illinois.edu&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Forced-choice (FC) response has gained increasing popularity
    and interest for its resistance to faking when well-designed (Cao &amp;
    Drasgow, 2019 &lt;<a href="https://doi.org/10.1037%2Fapl0000414">doi:10.1037/apl0000414</a>&gt;). To established well-designed
    FC scales, typically each item within a block should measure different
    trait and have similar level of social desirability (Zhang et al.,
    2020 &lt;<a href="https://doi.org/10.1177%2F1094428119836486">doi:10.1177/1094428119836486</a>&gt;). Recent study also suggests the
    importance of high inter-item agreement of social desirability between
    items within a block (Pavlov et al., 2021 &lt;<a href="https://doi.org/10.31234%2Fosf.io%2Fhmnrc">doi:10.31234/osf.io/hmnrc</a>&gt;). 
    In addition to this, FC developers may
    also need to maximize factor loading differences (Brown &amp;
    Maydeu-Olivares, 2011 &lt;<a href="https://doi.org/10.1177%2F0013164410375112">doi:10.1177/0013164410375112</a>&gt;) or minimize item
    location differences (Cao &amp; Drasgow, 2019 &lt;<a href="https://doi.org/10.1037%2Fapl0000414">doi:10.1037/apl0000414</a>&gt;)
    depending on scoring models. Decision of which items should be
    assigned to the same block, termed item pairing, is thus critical to
    the quality of an FC test. This pairing process is essentially an
    optimization process which is currently carried out manually. However,
    given that we often need to simultaneously meet multiple objectives,
    manual pairing becomes impractical or even not feasible once the
    number of latent traits and/or number of items per trait are
    relatively large. To address these problems, autoFC is developed as a
    practical tool for facilitating the automatic construction of FC tests
    (Li et al., 2022 &lt;<a href="https://doi.org/10.1177%2F01466216211051726">doi:10.1177/01466216211051726</a>&gt;), essentially
    exempting users from the burden of manual item pairing and reducing
    the computational costs and biases induced by simple ranking methods.
    Given characteristics of each item (and item responses), FC measures can
    be constructed either automatically based on user-defined pairing criteria
    and weights, or based on exact specifications of each block (i.e., blueprint;
    see Li et al., 2024 &lt;<a href="https://doi.org/10.1177%2F10944281241229784">doi:10.1177/10944281241229784</a>&gt;). Users can also 
    generate simulated responses based on the Thurstonian Item Response Theory 
    model (Brown &amp; Maydeu-Olivares, 2011 &lt;<a href="https://doi.org/10.1177%2F0013164410375112">doi:10.1177/0013164410375112</a>&gt;) and 
    predict trait scores of simulated/actual respondents based on 
    an estimated model.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/tspsyched/autoFC">https://github.com/tspsyched/autoFC</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/tspsyched/autoFC/issues">https://github.com/tspsyched/autoFC/issues</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>dplyr, irrCAC, lavaan, MASS, SimDesign, thurstonianIRT,
MplusAutomation, glue, tidyr</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-03-13 16:00:01 UTC</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-03-12 17:23:50 UTC; Mengtong Li</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.10)</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
</table>
<hr>
<h2 id='build_scale_with_blueprint'>Construct Forced-Choice Blocks Aligned with the Specifications in a Blueprint</h2><span id='topic+build_scale_with_blueprint'></span>

<h3>Description</h3>

<p>This function takes in the information of all available items as well as
a blueprint data frame specifying the design of blocks, and returns a data frame of item
blocks consistent with the blueprint (if possible).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_scale_with_blueprint(
  item_df,
  blueprint,
  bp_block_name,
  bp_item_nums_name,
  bp_trait_name,
  bp_sign_name,
  bp_matching_criterion_name,
  df_item_nums_name,
  df_trait_name,
  df_sign_name,
  df_matching_criterion_name,
  df_matching_function,
  df_matching_adjust_factor,
  max_attempts_in_comb = 100,
  max_attempts_in_adjust
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="build_scale_with_blueprint_+3A_item_df">item_df</code></td>
<td>
<p>Data frame containing information related to all the available items</p>
</td></tr>
<tr><td><code id="build_scale_with_blueprint_+3A_blueprint">blueprint</code></td>
<td>
<p>Pre-specified blueprint for your blocks. Preferably constructed from <code>construct_blueprint()</code></p>
</td></tr>
<tr><td><code id="build_scale_with_blueprint_+3A_bp_block_name">bp_block_name</code>, <code id="build_scale_with_blueprint_+3A_bp_item_nums_name">bp_item_nums_name</code>, <code id="build_scale_with_blueprint_+3A_bp_trait_name">bp_trait_name</code>, <code id="build_scale_with_blueprint_+3A_bp_sign_name">bp_sign_name</code></td>
<td>
<p>Column names in the blueprint that specifies block number, item number in the block, desired trait of the item, and desired keying of the item, respectively</p>
</td></tr>
<tr><td><code id="build_scale_with_blueprint_+3A_bp_matching_criterion_name">bp_matching_criterion_name</code></td>
<td>
<p>Column name in the blueprint that indicates the additional matching criterion (cutoff value) you wish to test</p>
</td></tr>
<tr><td><code id="build_scale_with_blueprint_+3A_df_item_nums_name">df_item_nums_name</code>, <code id="build_scale_with_blueprint_+3A_df_trait_name">df_trait_name</code>, <code id="build_scale_with_blueprint_+3A_df_sign_name">df_sign_name</code></td>
<td>
<p>Column names in <code>item_df</code> that specifies item_number, trait of the item, and keying of the item, respectively</p>
</td></tr>
<tr><td><code id="build_scale_with_blueprint_+3A_df_matching_criterion_name">df_matching_criterion_name</code></td>
<td>
<p>Optional. Column name in <code>item_df</code> that is used to evaluate the matching criterion specified in <code>bp_matching_criterion_name</code></p>
</td></tr>
<tr><td><code id="build_scale_with_blueprint_+3A_df_matching_function">df_matching_function</code></td>
<td>
<p>Optional. A character string containing function name for evaluating the matching criterion</p>
</td></tr>
<tr><td><code id="build_scale_with_blueprint_+3A_df_matching_adjust_factor">df_matching_adjust_factor</code></td>
<td>
<p>Optional. A numeric value. If after <code>max_attempts_in_comb</code> attempts the additional
criteria in <code>df_matching_criterion_name</code> cannot be met (&gt; the cutoff value specified in <code>blueprint[, bp_matching_criterion_name]</code>), 
multiply that cutoff value by this adjusting factor.</p>
</td></tr>
<tr><td><code id="build_scale_with_blueprint_+3A_max_attempts_in_comb">max_attempts_in_comb</code></td>
<td>
<p>Optional. An integer value. How many attempts will be made for finding a block that satisfies the blueprint, before we adjust the cutoff value?</p>
</td></tr>
<tr><td><code id="build_scale_with_blueprint_+3A_max_attempts_in_adjust">max_attempts_in_adjust</code></td>
<td>
<p>Optional. An integer value. How many attempts will be made for adjusting cutoff value? 
Will throw a warning and return the currently partially constructed scale (and specify which block might have problems) if number of attempts exceeds this value.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Although automatically finding the block combinations that can satisfy
multiple certain criteria for matching can be helpful (as the primary functionality of the previous
version of <code>autoFC</code> is about), users may also wish to have exact specifications for some blocks in many cases. 
For example, typically in FC construction, we may want to explicitly specify the trait and keying combinations
for each block. This function allows you to explicitly do that. Users are free to extend this function if further
exact specifications are needed.
</p>
<p>For now, this function also allows users to specify one additional matching criterion for
the blocks. Users can designate the function for calculating this criterion (<code>df_matching_function</code>) and specify
a multiplicative adjusting factor (<code>df_matching_adjust_factor</code>), 
if the criterion fails to be met after a specified number of attempts (<code>max_attempts_in_comb</code>).
One good example of matching criterion is matching in social desirability rating, where you want ratings of the items in the same block
to be less than a certain cutoff.
</p>
<p>If after a certain number of times (<code>max_attempts_in_adjust</code>) the given block is still unable to be constructed 
(i.e., criterion matching still fails even if we relax the cutoff multiple times), a warning message will be shown
and a partially built scale will be returned. Warnings along with a partially built scale may also be returned 
when it is impossible for the remaining items in <code>item_df</code> to satisfy the specification in the blueprint
(e.g. we have no items for trait1 left, but the blueprint requires a block with an item measuring trait1).
</p>


<h3>Value</h3>

<p>A data frame containing the selected items for each specified block.
If matching criteria is specified, the data frame will also contain the number of
times we adjusted the cutoffs for each block, and the final matching criteria cutoff
resulting from adjustments.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>See Also</h3>

<p><code>construct_blueprint()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>#### For the case you do not need additional matching criterion
item_info &lt;- triplet_block_info
test_bp &lt;- construct_blueprint(N_blocks = 2, block_size = 3, 
                               traits = c("honestyhumility", "emotionality", "extraversion",
                                          "agreeableness", "conscientiousness", "openness"),
                               signs = c(-1, 1, 1,
                                         -1, -1, -1))
### Some arguments can be omitted if you don't have extra matching criteria.
picked_scale &lt;- build_scale_with_blueprint(item_df = item_info,
                                           blueprint = test_bp,
                                           ### These parameters are column names in test_bp
                                           bp_block_name = "block",
                                           bp_item_nums_name = "item_num",
                                           bp_trait_name = "traits",
                                           bp_sign_name = "signs",
                                           ### These parameters are column names in item_info
                                           df_item_nums_name = "ID",
                                           df_trait_name = "Factor",
                                           df_sign_name = "Keying")

#### Or you may want to match social desirability ratings, for example
test_bp2 &lt;- test_bp
test_bp2$SD_matching &lt;- rep(0.5, 6)

#### Suppose that the items also have their own ratings
item_info2 &lt;- item_info
item_info2$SD_rating &lt;- rnorm(15, 3.5, 1)
range_m &lt;- function(x) {
  return(max(x) - min(x))
}

picked_scale2 &lt;- build_scale_with_blueprint(item_df = item_info2,
                                            blueprint = test_bp2,
                                            ### These parameters are column names in test_bp2
                                            bp_block_name = "block",
                                            bp_item_nums_name = "item_num",
                                            bp_trait_name = "traits",
                                            bp_sign_name = "signs",
                                            ### These parameters are column names in item_info2
                                            df_item_nums_name = "ID",
                                            df_trait_name = "Factor",
                                            df_sign_name = "Keying",
                                            ### These parameters will be used 
                                            ### when you have extra matching criteria
                                            df_matching_criterion_name = "SD_rating",
                                            bp_matching_criterion_name = "SD_matching",
                                            ## Which function is used to calculate matching?
                                            df_matching_function = "range_m",
                                            df_matching_adjust_factor = 1.25,
                                            max_attempts_in_comb = 100,
                                            max_attempts_in_adjust = 20)

</code></pre>

<hr>
<h2 id='build_TIRT_var_names'>Build Variable Names for the Pairwise/Rank Responses in the TIRT Model</h2><span id='topic+build_TIRT_var_names'></span>

<h3>Description</h3>

<p>This function builds the variable names that corresponds to
the pairwise comparisons or ranks among items within each block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>build_TIRT_var_names(
  item_name = "i",
  block_size,
  N_blocks,
  format = "pairwise"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="build_TIRT_var_names_+3A_item_name">item_name</code></td>
<td>
<p>The prefix you want to have for your response variables.</p>
</td></tr>
<tr><td><code id="build_TIRT_var_names_+3A_block_size">block_size</code>, <code id="build_TIRT_var_names_+3A_n_blocks">N_blocks</code></td>
<td>
<p>The block size and total number of the forced-choice scale.</p>
</td></tr>
<tr><td><code id="build_TIRT_var_names_+3A_format">format</code></td>
<td>
<p>What format should the converted responses be in? Can be <code>"pairwise"</code> or <code>"ranks"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Choose the correct <code>item_name</code> so that they are consistent with the item names
in the data frame storing information of the items.
</p>


<h3>Value</h3>

<p>A vector of variable names
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>See Also</h3>

<p><code>get_TIRT_long_data()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>build_TIRT_var_names("i", block_size = 3, N_blocks = 20, format = "pairwise")
build_TIRT_var_names("i", block_size = 5, N_blocks = 12, format = "ranks")


</code></pre>

<hr>
<h2 id='cal_block_energy'>Calculation of Item Block &quot;Energy&quot;</h2><span id='topic+cal_block_energy'></span>

<h3>Description</h3>

<p>Calculates the total &quot;energy&quot; of one or multiple paired
item blocks, which is a linear combination of different functions
applied to different item characteristics of interest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cal_block_energy(block, item_chars, weights, FUN)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cal_block_energy_+3A_block">block</code></td>
<td>
<p>An <em>n</em> by <em>k</em> integer matrix,
where <em>n</em> is the number of item blocks
and <em>k</em> is the number of items per block.</p>
</td></tr>
<tr><td><code id="cal_block_energy_+3A_item_chars">item_chars</code></td>
<td>
<p>An <em>m</em> by <em>r</em> data frame,
where <em>m</em> is the total number of items to sample from,
whether it is included in the block or not,
whereas <em>r</em> is the number of item characteristics.</p>
</td></tr>
<tr><td><code id="cal_block_energy_+3A_weights">weights</code></td>
<td>
<p>A vector of length <em>r</em> with weights for each
item characteristics in <code>item_chars</code>.
Should provide a weight of 0 for specific characteristics
not of interest, such as item ID.</p>
</td></tr>
<tr><td><code id="cal_block_energy_+3A_fun">FUN</code></td>
<td>
<p>A vector of customized function names for optimizing each
item characteristic within each block, with length <em>r</em>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This energy calculation function serves as the core for determining the
acceptance or rejection of a newly built block over the previous one.
</p>
<p>Higher energy is considered more preferable in this case.
</p>
<p>Items in the same block can be paired based on characteristics such as:
</p>
<p>Mean score, Item Factor, Factor loading, Item IRT Parameters,
Reverse Coding, etc.
</p>
<p>Pairings of different characteristics can be optimized in different way,
by determining the customized function vector <code>FUN</code>
and the corresponding <code>weights</code>.
</p>


<h3>Value</h3>

<p>A numeric value indicating the total energy
for the given item block(s).
</p>


<h3>Note</h3>

<p>Use <code>cal_block_energy_with_iia</code> if inter-item agreement
(IIA) metrics are needed.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate 60 items loading on different Big Five dimensions,
## with different mean and item difficulty

item_dims &lt;- sample(c("Openness","Conscientiousness","Neuroticism",
                     "Extraversion","Agreeableness"), 60, replace = TRUE)
item_mean &lt;- rnorm(60, 5, 2)
item_difficulty &lt;- runif(60, -1, 1)

## Construct data frame for item characteristics and produce
## 20 random triplet blocks with these 60 items

item_df &lt;- data.frame(Dimensions = item_dims, Mean = item_mean,
                     Difficulty = item_difficulty)
solution &lt;- make_random_block(60, 60, 3)

## See ?facfun for its use.
cal_block_energy(solution, item_chars = item_df,
              weights = c(1,1,1), FUN = c("facfun", "var", "var"))

</code></pre>

<hr>
<h2 id='cal_block_energy_with_iia'>Calculation of Item Block &quot;Energy&quot; with IIAs Included</h2><span id='topic+cal_block_energy_with_iia'></span>

<h3>Description</h3>

<p>Calculates the total &quot;energy&quot; of one or multiple paired
item blocks, which is a linear combination of different functions
applied to different item characteristics of interest.
</p>
<p>This function extends <code>cal_block_energy</code> function
with consideration of inter item agreement (IIA) metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cal_block_energy_with_iia(block, item_chars, weights,
                                 FUN, rater_chars,
                                 iia_weights = c(BPlin = 1, BPquad = 1,
                                 AClin = 1, ACquad = 1), verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cal_block_energy_with_iia_+3A_block">block</code>, <code id="cal_block_energy_with_iia_+3A_item_chars">item_chars</code>, <code id="cal_block_energy_with_iia_+3A_weights">weights</code>, <code id="cal_block_energy_with_iia_+3A_fun">FUN</code></td>
<td>
<p>See <code>?cal_block_energy</code> for details.</p>
</td></tr>
<tr><td><code id="cal_block_energy_with_iia_+3A_rater_chars">rater_chars</code></td>
<td>
<p>A <em>p</em> by <em>m</em> numeric matrix with scores of each of the <em>p</em>
participants for the <em>m</em> items.</p>
</td></tr>
<tr><td><code id="cal_block_energy_with_iia_+3A_iia_weights">iia_weights</code></td>
<td>
<p>A vector of length 4 indicating weights given to each IIA metric:
</p>
<p>Linearly weighted AC (Gwet, 2008; 2014);
</p>
<p>Quadratic weighted AC;
</p>
<p>Linearly weighted Brennan-Prediger (BP) Index(Brennan &amp; Prediger, 1981; Gwet, 2014);
</p>
<p>Quadratic weighted BP.</p>
</td></tr>
<tr><td><code id="cal_block_energy_with_iia_+3A_verbose">verbose</code></td>
<td>
<p>Logical. Should IIAs be printed when this function is called?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This energy calculation function serves as the core for determining
the acceptance or rejection of a newly built block over the previous one.
Higher energy is considered more preferable in this case.
</p>
<p>Items in the same block can be paired based on characteristics such as:
Mean score, Item Factor, Factor loading, Item IRT Parameters,
Reverse Coding, etc.
</p>
<p>In addition, IIAs can be adopted to further estimate
rater agreements between different items,
if such information is available for the researchers.
</p>
<p>Pairings of different characteristics can be optimized in different way,
by determining the customized function vector <code>FUN</code>
and the corresponding <code>weights</code>.
Currently only linear weighted combination
for IIAs can be used in optimization.
</p>


<h3>Value</h3>

<p>A numeric value indicating the total energy
for the given item block(s).
</p>


<h3>Note</h3>

<p>Use <code>cal_block_energy_with_iia</code> if inter-item agreement
(IIA) metrics are needed.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>References</h3>

<p>Brennan, R. L., &amp; Prediger, D. J. (1981). Coefficient kappa: Some uses, misuses,
and alternatives. <em>Educational and Psychological Measurement, 41</em>(3),
687-699. https://doi.org/10.1177/001316448104100307
</p>
<p>Gwet, K. L. (2008). Computing inter rater reliability and its
variance in the presence of high agreement.
<em>British Journal of Mathematical and Statistical Psychology, 61</em>(1),
29-48. https://doi.org/10.1348/000711006X126600
</p>
<p>Gwet, K. L. (2014). <em>Handbook of inter-rater reliability (4th ed.):
The definitive guide to measuring the extent of agreement among raters</em>.
Gaithersburg, MD: Advanced Analytics Press.
</p>


<h3>See Also</h3>

<p><code>cal_block_energy</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate 60 items loading on different Big Five dimensions,
## with different mean and item difficulty

item_dims &lt;- sample(c("Openness","Conscientiousness","Neuroticism",
                     "Extraversion","Agreeableness"), 60, replace = TRUE)
item_mean &lt;- rnorm(60, 5, 2)
item_difficulty &lt;- runif(60, -1, 1)

## Construct data frame for item characteristics and produce
## 20 random triplet blocks with these 60 items

item_df &lt;- data.frame(Dimensions = item_dims, Mean = item_mean,
                     Difficulty = item_difficulty)
solution &lt;- make_random_block(60, 60, 3)


## Simple simulation of responses from 600 participants on the 60 items.
## In practice, should use real world data or simluation based on IRT parameters.

item_responses &lt;- matrix(sample(seq(1:5), 600*60, replace = TRUE), ncol = 60, byrow = TRUE)


cal_block_energy_with_iia(solution, item_chars = item_df, weights = c(1,1,1),
                          FUN = c("facfun", "var", "var"),
                          rater_chars = item_responses, iia_weights = c(1,1,1,1))

</code></pre>

<hr>
<h2 id='construct_blueprint'>Build a Blueprint Data Frame for the Focal FC Scale</h2><span id='topic+construct_blueprint'></span>

<h3>Description</h3>

<p>This function takes in specifications of block size, number of blocks,
as well as trait and keying of each item in these blocks, and returns a data frame
incorporating these information and ready to be further used for constructing FC
blocks by other functions like <code>build_scale_with_blueprint()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>construct_blueprint(N_blocks, block_size, traits, signs)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="construct_blueprint_+3A_n_blocks">N_blocks</code></td>
<td>
<p>Number of total FC blocks</p>
</td></tr>
<tr><td><code id="construct_blueprint_+3A_block_size">block_size</code></td>
<td>
<p>Desired block size for the FC scale</p>
</td></tr>
<tr><td><code id="construct_blueprint_+3A_traits">traits</code>, <code id="construct_blueprint_+3A_signs">signs</code></td>
<td>
<p>Optional vectors. If given, specifies which traits and signs
each item in the FC scale should have. <code>traits</code> is a string vector,
while <code>signs</code> is a numeric vector (1 for positive items and -1 for negative items)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A &quot;blueprint&quot; of the forced-choice scale is essentially a data frame
where each row represents one item in the forced-choice scale, and columns specify
which block the item belongs to, the trait that the item measures, and the keying of
that item.
</p>
<p>Note that these are only the basic item information typically needed when matching items
into FC blocks; Users can further add other columns to the blueprint if they want to match
based on more criteria.
</p>


<h3>Value</h3>

<p>A data frame, containing the block membership, trait and keying information of
all the items.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example_blueprint &lt;- construct_blueprint(N_blocks = 5, block_size = 3, 
                                         traits = sample(c("Openness", 
                                                           "Conscientiousness", 
                                                           "Extraversion", 
                                                           "Agreeableness", 
                                                           "Neuroticism"), 15, replace = TRUE),
                                         signs = sample(c(-1, 1), 15, replace = TRUE))

</code></pre>

<hr>
<h2 id='convert_to_TIRT_response'>Convert the Latent Utility Values into Thurstonian IRT Pairwise/Rank Responses
with Pre-Specified Block Design</h2><span id='topic+convert_to_TIRT_response'></span>

<h3>Description</h3>

<p>This function simulates the responses to forced-choice blocks (both MOLE and RANK format), with
the raw responses converted into pairwise or rank data to be understood by the Thurstonian IRT model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>convert_to_TIRT_response(
  Utility,
  block_design,
  format = "pairwise",
  partial = FALSE,
  block_size,
  N_blocks,
  N_response
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="convert_to_TIRT_response_+3A_utility">Utility</code></td>
<td>
<p>The utility matrix of all items. Note that if this matrix is produced 
from <code>get_simulation_matrices()</code>, the item order will be consistent with the order
they appear in the CFA model. Users may need to re-order the columns back into 1, 2, 3...order
before using this matrix as the input.</p>
</td></tr>
<tr><td><code id="convert_to_TIRT_response_+3A_block_design">block_design</code></td>
<td>
<p>A numeric matrix specifying which items will be in the same forced-choice block (row).</p>
</td></tr>
<tr><td><code id="convert_to_TIRT_response_+3A_format">format</code></td>
<td>
<p>What format should the converted responses be in? Can be <code>"pairwise"</code> or <code>"ranks"</code>.</p>
</td></tr>
<tr><td><code id="convert_to_TIRT_response_+3A_partial">partial</code></td>
<td>
<p>Only used when <code>format == "ranks"</code>. Should partial ranking responses be produced?</p>
</td></tr>
<tr><td><code id="convert_to_TIRT_response_+3A_block_size">block_size</code>, <code id="convert_to_TIRT_response_+3A_n_blocks">N_blocks</code></td>
<td>
<p>The block size and total number of the forced-choice scale. 
Preferably left blank and obtained through <code>block_design</code>.</p>
</td></tr>
<tr><td><code id="convert_to_TIRT_response_+3A_n_response">N_response</code></td>
<td>
<p>Number of simulated responses you wish to generate. Default to <code>nrow(Utility)</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>According to the Thurstonian IRT model, when a respondent needs to make a choice
between two items, they elicit a latent utility value for the two items and choose the item
that has a higher utility value. Choosing/Ranking among &gt;2 items follows a similar procedure
where the respondent generate latent utility for each item and produces a ranking or preference.
</p>
<p>For forced-choice blocks, the above choice procedure is conducted among the <code>block_size</code> items in the same block,
and the respondent can either indicate the most/least preferred item (MOLE format) or rank all the items
in terms of preference (RANK format). 
</p>
<p>Regardless of the format, the raw responses to the forced-choice blocks need to be converted into
either all pairwise comparisons (<code>format = "pairwise"</code>), or a full ranking (<code>format = "ranks"</code>), 
among the the <code>block_size</code> items in the same block. 
</p>
<p>We note that the when <code>block_size</code> is larger than 3 and when the MOLE format is used, some
pairwise comparisons among the items in the block will be missing by design. As for now, the current technique 
is not yet able to handle missing pairwise responses when <code>format = "pairwise"</code>.
Thus, if users wish to simulate responses to MOLE format blocks with <code>block_size</code> larger than 3, 
we recommend using <code>format = "ranks"</code> and also set <code>partial = TRUE</code>.
</p>


<h3>Value</h3>

<p>A data frame containing pairwise (if <code>format == "pairwise"</code>) or
rank (if <code>format == "ranks"</code>) responses to each block for the <code>N_response</code> participants.
</p>


<h3>Note</h3>

<p>Importantly, the <code>Utility</code> matrix produced by <code>get_simulation_matrices()</code> may not be directly
used in this function because that utility matrix will have the item columns placed
in the order they appear in the CFA model, not in the original Item 1, Item 2...order.
Users need to re-order the columns of the <code>Utility</code> matrix produced by <code>get_simulation_matrices()</code> accordingly 
before feeding the utility matrix to this function.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(lavaan)
rating_data &lt;- HEXACO_example_data
cfa_model &lt;- paste0("H =~ ", paste0("SS", seq(6,60,6), collapse = " + "), "\n",
                    "E =~ ", paste0("SS", seq(5,60,6), collapse = " + "), "\n",
                    "X =~ ", paste0("SS", seq(4,60,6), collapse = " + "), "\n",
                    "A =~ ", paste0("SS", seq(3,60,6), collapse = " + "), "\n",
                    "C =~ ", paste0("SS", seq(2,60,6), collapse = " + "), "\n",
                    "O =~ ", paste0("SS", seq(1,60,6), collapse = " + "), "\n")
cfa_estimates &lt;- get_CFA_estimates(response_data = rating_data,
                                   fit_model = cfa_model, 
                                   item_names = paste0("SS",c(1:60)))
cfa_matrices &lt;- get_simulation_matrices(loadings = cfa_estimates$loadings,
                                        intercepts = cfa_estimates$intercepts,
                                        residuals = cfa_estimates$residuals,
                                        covariances = cfa_estimates$covariances,
                                        N = 100, N_items = 60, N_dims = 6,
                                        dim_names = c("H", "E", "X", "A", "C", "O"),
                                        empirical = TRUE)

### Re-order the Utility columns!
cfa_matrices$Utility &lt;- cfa_matrices$Utility[,c(t(matrix(1:60, ncol = 6)[,6:1]))]
### N_response need to be consistent with those specified in get_simulated_matrices()
FC_resp &lt;- convert_to_TIRT_response(Utility = cfa_matrices$Utility,
                                    block_design = make_random_block(60, 60, 3),
                                    N_response = 100, format = "pairwise",
                                    block_size = 3, N_blocks = 20)
FC_rank_resp &lt;- convert_to_TIRT_response(Utility = cfa_matrices$Utility,
                                         block_design = make_random_block(60, 60, 5),
                                         N_response = 100, format = "ranks",
                                         block_size = 5, N_blocks = 12) 
FC_rank_partial_resp &lt;- convert_to_TIRT_response(Utility = cfa_matrices$Utility,
                                                 block_design = make_random_block(60, 60, 5),
                                                 N_response = 100, format = "ranks", partial = TRUE,
                                                 block_size = 5, N_blocks = 12)                                          
FC_resp
FC_rank_resp
FC_rank_partial_resp

</code></pre>

<hr>
<h2 id='empirical_reliability'>Calculate the Empirical Reliability of the Latent Trait Scores,
Following the Formula in Brown &amp; Maydeu-Olivares (2018).</h2><span id='topic+empirical_reliability'></span>

<h3>Description</h3>

<p>Calculates the empirical reliability using the formula in Brown &amp; Maydeu-Olivares (2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>empirical_reliability(dataset, score_names, se_names)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="empirical_reliability_+3A_dataset">dataset</code></td>
<td>
<p>Data frame with trait estimates and standard errors</p>
</td></tr>
<tr><td><code id="empirical_reliability_+3A_score_names">score_names</code></td>
<td>
<p>Vector of characters. Which columns specify trait scores?</p>
</td></tr>
<tr><td><code id="empirical_reliability_+3A_se_names">se_names</code></td>
<td>
<p>Vector of characters. Which columns specify trait standard errors?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For trait scores estimated using item response theory models, a suitable reliability estimate
is empirical reliability, which provides a summary estimate on how reliable the trait scores are &quot;as a whole&quot;.
</p>


<h3>Value</h3>

<p>A numeric vector containing empirical reliability estimates, ordered the same as in <code>score_names</code>.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>References</h3>

<p>Brown, A., &amp; Maydeu-Olivares, A. (2018). Ordinal factor analysis of graded-preference questionnaire data. 
<em>Structural Equation Modeling: A Multidisciplinary Journal, 25</em>(4), 516-529. https://doi.org/10.1080/10705511.2017.1392247
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: empirical_reliability(dataset, c("Trait1", "Trait2", "Trait3"), c("se1", "se2", "se3"))

</code></pre>

<hr>
<h2 id='facfun'>Function for Checking If All Items in a Vector Are Unique</h2><span id='topic+facfun'></span>

<h3>Description</h3>

<p>Returns <em>1</em> if each element in the vector is unique,
and <em>0</em> otherwise.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>facfun(vec)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="facfun_+3A_vec">vec</code></td>
<td>
<p>Input vector.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><em>1</em> if each element in the vector is unique,
and <em>0</em> otherwise.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  facfun(c("Openness", "Neuroticism", "Agreeableness"))
  facfun(c("Openness", "Openness", "Agreeableness"))
</code></pre>

<hr>
<h2 id='fit_TIRT_model'>Fit the Thurstonian IRT Model with Long Format Response Data</h2><span id='topic+fit_TIRT_model'></span>

<h3>Description</h3>

<p>Fits the Thurstonian IRT response model using either lavaan, Mplus, or stan methods. 
A long format response data set needs to be provided.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_TIRT_model(
  data_TIRT,
  method = "lavaan",
  lavaan_estimator = "WLSMV",
  stan_cores = 4,
  chains = 4,
  iter = 2000,
  verbose = TRUE,
  remove_mplus_file = FALSE,
  export_estimates = TRUE,
  file_name
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_TIRT_model_+3A_data_tirt">data_TIRT</code></td>
<td>
<p>Long format TIRT response data as generated from <code>get_TIRT_long_data()</code> or <code>thurstonianIRT::make_TIRT_data()</code>.</p>
</td></tr>
<tr><td><code id="fit_TIRT_model_+3A_method">method</code></td>
<td>
<p>Estimation method for the TIRT model. Can be <code>"lavaan"</code>, <code>"mplus"</code> or <code>"stan"</code>.</p>
</td></tr>
<tr><td><code id="fit_TIRT_model_+3A_lavaan_estimator">lavaan_estimator</code></td>
<td>
<p>Which estimator to use when lavaan is chosen as the method of estimating the TIRT model. Defaults to &quot;WLSMV&quot;.</p>
</td></tr>
<tr><td><code id="fit_TIRT_model_+3A_stan_cores">stan_cores</code>, <code id="fit_TIRT_model_+3A_chains">chains</code>, <code id="fit_TIRT_model_+3A_verbose">verbose</code>, <code id="fit_TIRT_model_+3A_iter">iter</code></td>
<td>
<p>Parameters used in <code>thurstonianIRT::fit_TIRT_stan</code></p>
</td></tr>
<tr><td><code id="fit_TIRT_model_+3A_remove_mplus_file">remove_mplus_file</code></td>
<td>
<p>Whether the input/output files will be removed after model estimation, when Mplus is chosen as the method of estimating the TIRT model.</p>
</td></tr>
<tr><td><code id="fit_TIRT_model_+3A_export_estimates">export_estimates</code></td>
<td>
<p>Logical. Should trait estimates be written to external files?</p>
</td></tr>
<tr><td><code id="fit_TIRT_model_+3A_file_name">file_name</code></td>
<td>
<p>If <code>export_estimates == TRUE</code>, specify the file name for the output file.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function incorporates the fit TIRT models functions in the <code>thurstonianIRT</code> package (Bürkner, 2019) and
by (a) providing a wrapper interface for users to choose from estimating from lavaan, MPLUS, or stan, (b) placing
the fit object, resulting trait estimates, and the original long format response data into one list as the return object.
Users need to provide a long format TIRT response data set as generated from <code>get_TIRT_long_data()</code> or from <code>thurstonianIRT::make_TIRT_data()</code>,
and they can choose from three estimation methods: lavaan, MPLUS or stan. For lavaan and stan, additional arguments can be specified.
</p>
<p>We note that currently the lavaan method does not provide standard error estimates. The stan method is the most stable
but can take a very long time for estimation. The mplus method can be a good choice but may occassionally produce errors
due to model convergence issues. In these rare cases, users may also consider using the Excel macro
developed by Brown &amp; Maydeu-Olivares (2012) to generate Mplus syntax and directly run the syntax in Mplus.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<p><code>final_estimates</code>   Final trait score and standard error estimates
</p>
<p><code>fit_object</code>   TIRT model fit object
</p>
<p><code>responses_TIRT</code>   The long format TIRT response
</p>
<p><code>long_estimates</code>   Final trait score and standard error estimates, in long format
</p>



<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>References</h3>

<p>Bürkner, P. C. (2019). thurstonianIRT: Thurstonian IRT models in R. <em>Journal of Open Source Software, 4</em>(42), 1662. https://doi.org/10.21105/joss.01662
</p>
<p>Brown, A., &amp; Maydeu-Olivares, A. (2012). Fitting a Thurstonian IRT model to forced-choice data using Mplus. <em>Behavior Research Methods, 44</em>, 1135-1147. https://doi.org/10.3758/s13428-012-0217-x
</p>


<h3>See Also</h3>

<p><code>thurstonianIRT::fit_TIRT_lavaan</code>,
</p>
<p><code>thurstonianIRT::fit_TIRT_mplus</code>, 
</p>
<p><code>thurstonianIRT::fit_TIRT_stan</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>set.seed(2024)
test_data &lt;- triplet_example_data[1:20,]
block_info &lt;- triplet_block_info
test_data_long &lt;- get_TIRT_long_data(block_info = triplet_block_info, response_data = test_data,
                                     response_varname = build_TIRT_var_names(N_blocks = 5, 
                                     block_size = 3, item_name = "i"),
                                     block_name = "Block", item_name = "ID", 
                                     trait_name = "Factor", sign_name = "Keying")
## Not run: 
    test_fit &lt;- fit_TIRT_model(test_data_long, method = "lavaan")
    test_fit$fit_object
    test_fit$final_estimates

## End(Not run)

</code></pre>

<hr>
<h2 id='get_CFA_estimates'>Conduct Confirmatory Factor Analysis (CFA) and Obtain Parameter Estimates</h2><span id='topic+get_CFA_estimates'></span>

<h3>Description</h3>

<p>Reads in responses to Likert-type scales and a specified factor model,
performs CFA, and produces parameter estimates required for producing 
subsequent simulation data (i.e., use as inputs for <code>get_simulation_matrices()</code>).
</p>
<p>This function returns factor loadings, intercepts, residual variances, 
and covariances among latent variables
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_CFA_estimates(response_data, fit_model, item_names)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_CFA_estimates_+3A_response_data">response_data</code></td>
<td>
<p>Likert-type response data. Requires the header including 
variable names.</p>
</td></tr>
<tr><td><code id="get_CFA_estimates_+3A_fit_model">fit_model</code></td>
<td>
<p>A pre-specified CFA model written in lavaan syntax.</p>
</td></tr>
<tr><td><code id="get_CFA_estimates_+3A_item_names">item_names</code></td>
<td>
<p>Names of the items you wish to obtain loadings, intercepts, 
and residuals. These variable names should appear in <code>response_data</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is essentially a wrapper for <code>lavaan::parameterEstimates()</code>
to obtain specific set of parameter estimates.
</p>
<p>Notice that we assume your CFA model does not have hierarchical factor structure,
nor does it have cross loadings or correlated residuals.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<p><code>loadings</code> Item loadings for <code>item_names</code>
</p>
<p><code>intercepts</code> Item intercepts for <code>item_names</code>
</p>
<p><code>residuals</code> Item residual variances for <code>item_names</code>
</p>
<p><code>covariances</code> Covariances between latent variables defined in <code>fit_model</code>
</p>
<p><code>model_fit</code> Model fit for <code>fit_model</code> on <code>response_data</code>

</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>References</h3>

<p>Ashton, M. C., &amp; Lee, K. (2009). The HEXACO–60: A short measure of the major dimensions of personality. 
<em>Journal of personality assessment, 91</em>(4), 340-345. https://doi.org/10.1080/00223890902935878
</p>


<h3>See Also</h3>

<p><code>get_simulation_matrices()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## We have a small response sample data (N = 100) on 
## the HEXACO-60 (Ashton &amp; Lee, 2009) scale in the package
## Names of the items are SS1-SS60 (Single-statement)
rating_data &lt;- HEXACO_example_data
cfa_model &lt;- paste0("H =~ ", paste0("SS", seq(6,60,6), collapse = " + "), "\n",
                   "E =~ ", paste0("SS", seq(5,60,6), collapse = " + "), "\n",
                   "X =~ ", paste0("SS", seq(4,60,6), collapse = " + "), "\n",
                   "A =~ ", paste0("SS", seq(3,60,6), collapse = " + "), "\n",
                   "C =~ ", paste0("SS", seq(2,60,6), collapse = " + "), "\n",
                   "O =~ ", paste0("SS", seq(1,60,6), collapse = " + "), "\n")
cfa_estimates &lt;- get_CFA_estimates(response_data = rating_data,
                                   fit_model = cfa_model, 
                                   item_names = paste0("SS",c(1:60)))


</code></pre>

<hr>
<h2 id='get_iia'>Helper Function for Outputting IIA Characteristics of Each Block</h2><span id='topic+get_iia'></span>

<h3>Description</h3>

<p>This function prints IIA metrics for select items,
given the individual responses for the items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_iia(block, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_iia_+3A_block">block</code></td>
<td>
<p>An <em>n</em> by <em>k</em> integer matrix,
where <em>n</em> is the number of item blocks
and <em>k</em> is the number of items per block.</p>
</td></tr>
<tr><td><code id="get_iia_+3A_data">data</code></td>
<td>
<p>A <em>p</em> by <em>m</em> numeric matrix with scores of
each of the <em>p</em> participants for the <em>m</em> items.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An <em>n</em> by <em>k</em> matrix indicating the four IIA metrics for each item block.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  item_responses &lt;- matrix(sample(seq(1:5), 600*60, replace = TRUE), ncol = 60, byrow = TRUE)
  get_iia(matrix(seq(1:60), ncol = 3, byrow = TRUE), item_responses)

</code></pre>

<hr>
<h2 id='get_simulation_matrices'>Generate Simulated Person and Item Parameter Matrices for the Thurstonian IRT Model
Based on Confirmatory Factor Analysis Results</h2><span id='topic+get_simulation_matrices'></span>

<h3>Description</h3>

<p>This function takes in factor analysis results from <code>lavaan::cfa()</code> or <code>get_CFA_estimates()</code>, and
generates simulated person and item parameter matrices for the Thurstonian IRT model. 
The latent &quot;utility&quot; value of each item for each simulated person is also produced.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_simulation_matrices(
  loadings,
  intercepts,
  residuals,
  covariances,
  N,
  N_items,
  N_dims,
  dim_names,
  empirical
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_simulation_matrices_+3A_loadings">loadings</code>, <code id="get_simulation_matrices_+3A_intercepts">intercepts</code>, <code id="get_simulation_matrices_+3A_residuals">residuals</code>, <code id="get_simulation_matrices_+3A_covariances">covariances</code></td>
<td>
<p>Data frame of factor loadings, intercepts, residuals and latent variable covariances,
preferably obtained from <code>get_CFA_estimates()</code>, or extracted from <code>lavaan::parameterEstimates()</code>.</p>
</td></tr>
<tr><td><code id="get_simulation_matrices_+3A_n">N</code></td>
<td>
<p>Number of simulated responses you wish to generate.</p>
</td></tr>
<tr><td><code id="get_simulation_matrices_+3A_n_items">N_items</code></td>
<td>
<p>Optional. Total number of response items. Default to the number of rows
in <code>loadings</code>.</p>
</td></tr>
<tr><td><code id="get_simulation_matrices_+3A_n_dims">N_dims</code></td>
<td>
<p>Optional. Total number of response items. Default to the length of <code>dim_names</code>.</p>
</td></tr>
<tr><td><code id="get_simulation_matrices_+3A_dim_names">dim_names</code></td>
<td>
<p>Name of the latent variables (dimensions); Order should be consistent with 
how they appear in your CFA model as you have specified in <code>get_CFA_estimates()</code>.</p>
</td></tr>
<tr><td><code id="get_simulation_matrices_+3A_empirical">empirical</code></td>
<td>
<p>As in <code>MASS::mvrnorm()</code>;  Should mu and sigma specify the empirical, 
rather than population mean and covariance?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Based on the Thurstonian IRT model (Brown &amp; Maydeu-Olivares, 2011), this function
generates the latent utility value of <code>N_item</code> Likert items for each of the 
<code>N</code> participants.
</p>
<p>Readers can refer to Brown &amp; Maydeu-Olivares (2011) and the online tutorial in
Li et al., (in press) for detailed description of simulation procedures.
</p>


<h3>Value</h3>

<p>A list containing:
</p>

<p><code>Lambda</code> Item loading matrix specifying which items load onto which dimension,
</p>
<p><code>Mu</code> Item intercept matrix,
</p>
<p><code>Epsilon</code> Item residual matrix,
</p>
<p><code>Theta</code> Simulated latent scores for each of the <code>N_dims</code> dimensions for all <code>N</code> simulated respondents,
</p>
<p><code>Utility</code> latent utility value of <code>N_item</code> Likert items for each of the <code>N</code> participants.

</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>References</h3>

<p>Brown, A., &amp; Maydeu-Olivares, A. (2011). Item response modeling of forced-choice questionnaires. <em>Educational and Psychological Measurement, 71</em>(3), 460-502. https://doi.org/10.1177/0013164410375112
Li, M., Zhang, B., Li, L., Sun, T., &amp; Brown, A., (2024). Mixed-Keying or Desirability-Matching in the Construction of Forced-Choice Measures? An Empirical Investigation and Practical Recommendations. <em>Organizational Research Methods</em>. https://doi.org/10.1177/10944281241229784
</p>


<h3>See Also</h3>

<p><code>get_CFA_estimates()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>rating_data &lt;- HEXACO_example_data
cfa_model &lt;- paste0("H =~ ", paste0("SS", seq(6,60,6), collapse = " + "), "\n",
                    "E =~ ", paste0("SS", seq(5,60,6), collapse = " + "), "\n",
                    "X =~ ", paste0("SS", seq(4,60,6), collapse = " + "), "\n",
                    "A =~ ", paste0("SS", seq(3,60,6), collapse = " + "), "\n",
                    "C =~ ", paste0("SS", seq(2,60,6), collapse = " + "), "\n",
                    "O =~ ", paste0("SS", seq(1,60,6), collapse = " + "), "\n")
cfa_estimates &lt;- get_CFA_estimates(response_data = rating_data,
                                   fit_model = cfa_model, 
                                   item_names = paste0("SS",c(1:60)))
cfa_matrices &lt;- get_simulation_matrices(loadings = cfa_estimates$loadings,
                                        intercepts = cfa_estimates$intercepts,
                                        residuals = cfa_estimates$residuals,
                                        covariances = cfa_estimates$covariances,
                                        N = 100, N_items = 60, N_dims = 6,
                                        dim_names = c("H", "E", "X", "A", "C", "O"),
                                        empirical = TRUE)

</code></pre>

<hr>
<h2 id='get_TIRT_long_data'>Convert the TIRT Pairwise/Rank Response Data into Long Format Compatible with the thurstonianIRT Package</h2><span id='topic+get_TIRT_long_data'></span>

<h3>Description</h3>

<p>To estimate the TIRT model using the thurstonianIRT Package, the pairwise/rank data needs to 
be converted into long format. Current function serves as that purpose.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_TIRT_long_data(
  block_info,
  response_data,
  response_varname,
  format = "pairwise",
  partial = FALSE,
  direction = "larger",
  family = "bernoulli",
  range = c(0, 1),
  block_name = "Block",
  item_name = "ID",
  trait_name = "Factor",
  sign_name = "Reversed"
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_TIRT_long_data_+3A_block_info">block_info</code></td>
<td>
<p>Information data frame related to keying, dimension, and ID of each item in each block.
The order of the rows in <code>block_info</code> need to be consistent with the order of the FC items.</p>
</td></tr>
<tr><td><code id="get_TIRT_long_data_+3A_response_data">response_data</code></td>
<td>
<p>TIRT pairwise/rank response data.</p>
</td></tr>
<tr><td><code id="get_TIRT_long_data_+3A_response_varname">response_varname</code></td>
<td>
<p>Column names of TIRT pairwise/ranked responses. Can be generated from <code>build_TIRT_var_names()</code>.</p>
</td></tr>
<tr><td><code id="get_TIRT_long_data_+3A_format">format</code>, <code id="get_TIRT_long_data_+3A_direction">direction</code>, <code id="get_TIRT_long_data_+3A_family">family</code>, <code id="get_TIRT_long_data_+3A_range">range</code>, <code id="get_TIRT_long_data_+3A_partial">partial</code></td>
<td>
<p>These parameters works the same as <code>thurstonianIRT::make_TIRT_data()</code>.</p>
</td></tr>
<tr><td><code id="get_TIRT_long_data_+3A_block_name">block_name</code>, <code id="get_TIRT_long_data_+3A_item_name">item_name</code>, <code id="get_TIRT_long_data_+3A_trait_name">trait_name</code>, <code id="get_TIRT_long_data_+3A_sign_name">sign_name</code></td>
<td>
<p>These parameters indicate the column names in <code>block_info</code> that specify
the following information of each item:
</p>
<p><code>block_name</code>: Which block does this item belong to?
<code>item_name</code>: What is the name of this item? 
<code>trait_name</code>: Which trait does this item belong to?
<code>sign_name</code>: What is the keying of this item?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function is essentially a wrapper of <code>thurstonianIRT::make_TIRT_data()</code>
to allow more functionalities to be incorporated in a single function.
</p>


<h3>Value</h3>

<p>A long format data frame that is compatible with subsequent analyses using the thurstonianIRT package
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>See Also</h3>

<p><code>thurstonianIRT::set_blocks_from_df()</code>, <code>thurstonianIRT::make_TIRT_data()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## See example in convert_to_TIRT_response() for FC_resp
## This example is just for demonstrative purposes showing how the long format data would look like.
## Not run: get_TIRT_long_data(block_info = triplet_block_info,
                            response_data = FC_resp[,c(1:15)], 
                            response_varname = build_TIRT_var_names("i", 3, 5, format = "pairwise"),
                            trait_name = "Factor", sign_name = "Keying")
## End(Not run)

</code></pre>

<hr>
<h2 id='HEXACO_example_data'>Example HEXACO Response Data</h2><span id='topic+HEXACO_example_data'></span>

<h3>Description</h3>

<p>Responses to the HEXACO-60 (Ashton &amp; Lee, 2009) scale from 100 actual respondents
</p>


<h3>Usage</h3>

<pre><code class='language-R'>HEXACO_example_data
</code></pre>


<h3>Format</h3>

<p>A data frame with 100 rows and 60 columns.
</p>

<dl>
<dt>SS1, SS2, SS3, SS4, SS5, SS6, SS7, SS8, SS9, SS10,
SS11, SS12, SS13, SS14, SS15, SS16, SS17, SS18, SS19, SS20,
SS21, SS22, SS23, SS24, SS25, SS26, SS27, SS28, SS29, SS30,
SS31, SS32, SS33, SS34, SS35, SS36, SS37, SS38, SS39, SS40,
SS41, SS42, SS43, SS44, SS45, SS46, SS47, SS48, SS49, SS50,
SS51, SS52, SS53, SS54, SS55, SS56, SS57, SS58, SS59, SS60</dt><dd><p>Represents the 60 HEXACO items.</p>
</dd>
</dl>



<h3>Source</h3>

<p>https://osf.io/yvpz3/?view_only=08601755f471440b80973194571b60bd
</p>


<h3>References</h3>

<p>Ashton, M. C., &amp; Lee, K. (2009). The HEXACO–60: A short measure of the major dimensions of personality. 
<em>Journal of Personality Assessment, 91</em>(4), 340-345. https://doi.org/10.1080/00223890902935878
</p>

<hr>
<h2 id='make_random_block'>Construction of Random Item Blocks</h2><span id='topic+make_random_block'></span>

<h3>Description</h3>

<p>Returns a matrix of randomly paired blocks
where each row represents a block.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_random_block(total_items, target_items = total_items, item_per_block)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="make_random_block_+3A_total_items">total_items</code></td>
<td>
<p>Integer value. Determines the total number of items we sample from.</p>
</td></tr>
<tr><td><code id="make_random_block_+3A_target_items">target_items</code></td>
<td>
<p>Integer value. Determines the number of items to use from
<code>total_items</code> to build item blocks.
Default to be equal to <code>total_items</code>. Should be no more than <code>total_items</code>.</p>
</td></tr>
<tr><td><code id="make_random_block_+3A_item_per_block">item_per_block</code></td>
<td>
<p>Integer value. Determines the number of items in each item block.
Should be no less than 2.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given the total number of items to pair from, number of items to build
paired blocks and number of items in each block,
<code>make_random_block</code> produces a matrix randomly paired blocks
where each row represents a block.
</p>
<p>It can also accommodate cases when <code>target_items</code>
is not a multiple of <code>item_per_block</code>.
</p>
<p>Can be used as initial solution for other functions in this package.
</p>


<h3>Value</h3>

<p>A matrix of integers indicating the item numbers, where the number of rows
equals <code>target_items</code> divided by <code>item_per_block</code>, rounded up,
and number of columns equals <code>item_per_block</code>.
</p>


<h3>Note</h3>

<p>If <code>target_items</code> is not a multiple of <code>item_per_block</code>,
the item set produced by <code>target_items</code> will be looped
until number of sampled items becomes a multiple of <code>item_per_block</code>.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Try out cases where you make target_items the default.
make_random_block(60, item_per_block = 3)

# You can also set your own values of target_items.
make_random_block(60, 45, item_per_block = 3)

# Also see what happens if target_items is not a multiple of item_per_block.
make_random_block(60, 50, item_per_block = 3)

</code></pre>

<hr>
<h2 id='plot_scores'>Scatter Plot for True vs Estimated Scores, True Score vs Absolute Error, etc.</h2><span id='topic+plot_scores'></span>

<h3>Description</h3>

<p>This function is a simple plot for diagnostic purposes examining
the performance of the FC scale based on simulated data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>plot_scores(x_scores, y_scores, type = "simple", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot_scores_+3A_x_scores">x_scores</code></td>
<td>
<p>Scores to be plotted on the x axis</p>
</td></tr>
<tr><td><code id="plot_scores_+3A_y_scores">y_scores</code></td>
<td>
<p>Scores to be plotted on the y axis</p>
</td></tr>
<tr><td><code id="plot_scores_+3A_type">type</code></td>
<td>
<p>Which type of plots is plotted? Can be <code>"simple"</code> for simple x-y plot, or <code>"abs.diff"</code>
for plotting absolute difference of (y-x) vs x.</p>
</td></tr>
<tr><td><code id="plot_scores_+3A_...">...</code></td>
<td>
<p>Other parameters used in <code>plot()</code></p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is only a very crude plot function extending <code>plot()</code> for demonstrative purposes.
Users are free to develop their own versions of plotting.
</p>


<h3>Value</h3>

<p>A scatter plot
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot_scores(rnorm(100), rnorm(100))

</code></pre>

<hr>
<h2 id='predict_scores'>Predict trait scores based on estimated model</h2><span id='topic+predict_scores'></span>

<h3>Description</h3>

<p>An easy wrapper for the <code>thurstonianIRT::predict()</code> function
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_scores(estimated_model, newdata, output_file = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_scores_+3A_estimated_model">estimated_model</code></td>
<td>
<p>Estimated model</p>
</td></tr>
<tr><td><code id="predict_scores_+3A_newdata">newdata</code></td>
<td>
<p>Response data from new response samples, in TIRT data format. 
Preferably be generated from <code>thurstonianIRT::make_TIRT_data()</code> or <code>get_TIRT_long_data()</code>.</p>
</td></tr>
<tr><td><code id="predict_scores_+3A_output_file">output_file</code></td>
<td>
<p>Character string. If specified, output the trait scores into a specified csv file.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data frame containing estimated trait scores of the new response sample
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>test_data &lt;- triplet_example_data[1:20,]
block_info &lt;- triplet_block_info
test_data_long &lt;- get_TIRT_long_data(block_info = triplet_block_info, response_data = test_data,
                                     response_varname = build_TIRT_var_names(N_blocks = 5, 
                                     block_size = 3, item_name = "i"),
                                     block_name = "Block", item_name = "ID", 
                                     trait_name = "Factor", sign_name = "Keying")
## Not run: 
    test_fit &lt;- fit_TIRT_model(test_data_long, method = "mplus")
    predict_scores(test_fit$fit_object, newdata = test_data[21:40,])

## End(Not run)

</code></pre>

<hr>
<h2 id='RMSE_range'>Calculate the Overall RMSE of the Trait Scores, or the RMSE in a Certain Trait Score Range</h2><span id='topic+RMSE_range'></span>

<h3>Description</h3>

<p>This function is also for diagnostic purposes, examining which interval on the
latent trait continuum does the FC scale demonstrate the best measurement accuracy.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>RMSE_range(true_scores, estimated_scores, range_breaks = NA)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="RMSE_range_+3A_true_scores">true_scores</code></td>
<td>
<p>Actual trait scores</p>
</td></tr>
<tr><td><code id="RMSE_range_+3A_estimated_scores">estimated_scores</code></td>
<td>
<p>Estimated trait scores from a specified model</p>
</td></tr>
<tr><td><code id="RMSE_range_+3A_range_breaks">range_breaks</code></td>
<td>
<p>A numeric vector. Specifies which trait scores ranges will the RMSE be calculated</p>
</td></tr>
</table>


<h3>Details</h3>

<p>TO BE DONE
</p>


<h3>Value</h3>

<p>If <code>range_breaks</code> is not specified, an overall RMSE numeric value will be returned;
else, a named list showing the RMSE in each score range will be returned.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>Examples</h3>

<pre><code class='language-R'>RMSE_range(rnorm(100), rnorm(100))
RMSE_range(rnorm(100), rnorm(100), range_breaks = c(-3, -2, -1, 0, 1, 2, 3))

</code></pre>

<hr>
<h2 id='sa_pairing_generalized'>Automatic Item Pairing Method in Forced-Choice Test Construction</h2><span id='topic+sa_pairing_generalized'></span>

<h3>Description</h3>

<p>Automatic construction of forced-choice tests based on
Simulated Annealing algorithm. Allows items to be:
</p>
<p>1. Matched in either pairs, triplets, quadruplets or blocks of any size;
</p>
<p>2. Matched based on any number of item-level characteristics
(e.g. Social desirability, factor) based on any customized criteria;
</p>
<p>3. Matched based on person-level inter-item agreement (IIA) metrics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sa_pairing_generalized(block, total_items, Temperature,
                              eta_Temperature = 0.01, r = 0.999,
                              end_criteria = 10^(-6),
                              item_chars, weights, FUN,
                              n_exchange = 2, prob_newitem = 0.25,
                              use_IIA = FALSE, rater_chars,
                              iia_weights = c(BPlin = 1, BPquad = 1,
                              AClin = 1, ACquad = 1))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sa_pairing_generalized_+3A_block">block</code></td>
<td>
<p>An <em>n</em> by <em>k</em> integer matrix,
where <em>n</em> is the number of item blocks
and <em>k</em> is the number of items per block.
</p>
<p>Serves as the initial starting blocks for the automatic pairing method.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_total_items">total_items</code></td>
<td>
<p>Integer value. How many items do we sample from
in order to build this <code>block</code>? Should be more than number of unique values
in <code>block</code>.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_temperature">Temperature</code></td>
<td>
<p>Initial temperature value. Can be left blank and be computed based on
the absolute value of initial energy of <code>block</code> (Recommended), and scaled
by <code>eta_Temperature</code>.
</p>
<p>In general, higher temperature represents a higher probability of
accepting an inferior solution.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_eta_temperature">eta_Temperature</code></td>
<td>
<p>A positive numeric value. The ratio of initial temperature to
initial energy of <code>block</code>, if <code>Temperature</code> is not designated.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_r">r</code></td>
<td>
<p>A positive numeric value less than 1.
Determines the reduction rate of <code>Temperature</code> after each iteration.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_end_criteria">end_criteria</code></td>
<td>
<p>A positive numeric value less than 1.
Iteration stops when temperature drops to below <code>end_criteria * Temperature</code>.
Default to be <code class="reqn">10^-6</code>.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_item_chars">item_chars</code></td>
<td>
<p>An <em>m</em> by <em>r</em> data frame,
where <em>m</em> is the total number of items to sample from,
whether it is included in the block or not,
whereas <em>r</em> is the number of item characteristics.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_weights">weights</code></td>
<td>
<p>A vector of length <em>r</em> with weights for each
item characteristics in <code>item_chars</code>.
Should provide a weight of 0 for specific characteristics
not of interest, such as item ID.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_fun">FUN</code></td>
<td>
<p>A vector of customized function names for optimizing each
item characteristic within each block, with length <em>r</em>.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_n_exchange">n_exchange</code></td>
<td>
<p>Integer value. Determines how many blocks are exchanged
in order to produce a new solution for each iteration.
Should be a value larger than 1 and less than <code>nrow(block)</code>.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_prob_newitem">prob_newitem</code></td>
<td>
<p>A value between <em>0</em> and <em>1</em>.
Probability of choosing the strategy of picking a new item,
when not all candidate items are used to build the FC scale.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_use_iia">use_IIA</code></td>
<td>
<p>Logical. Are IIA metrics used when performing automatic pairing?</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_rater_chars">rater_chars</code></td>
<td>
<p>A <em>p</em> by <em>m</em> numeric matrix with scores of each of the
<em>p</em> participants for the <em>m</em> items. Ignored when <code>use_IIA == FALSE</code>.</p>
</td></tr>
<tr><td><code id="sa_pairing_generalized_+3A_iia_weights">iia_weights</code></td>
<td>
<p>A vector of length 4 indicating weights given to each IIA metric:
</p>
<p>Linearly weighted AC (Gwet, 2008; 2014);
</p>
<p>Quadratic weighted AC;
</p>
<p>Linearly weighted Brennan-Prediger (BP) Index(Brennan &amp; Prediger, 1981; Gwet, 2014);
</p>
<p>Quadratic weighted BP.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing:
</p>

<p><code>block_initial</code> Initial starting block
</p>
<p><code>energy_initial</code> Initial energy for <code>block_initial</code>
</p>
<p><code>block_final</code> Final paired block after optimization by SA
</p>
<p><code>energy_final</code> Final energy for <code>block_final</code>

</p>


<h3>Note</h3>

<p>The essence of SA is the probablistic acceptance of solutions inferior to
the current state, which avoids getting stuck in local maxima/minima.
It is also recommended to try out different values of
<code>weights, iia_weights, eta_Temperature</code> to find out the best
combination of initial temperature and energy value
in order to provide optimally paired blocks.
</p>
<p>Use <code>cal_block_energy_with_iia</code> if inter-item agreement
(IIA) metrics are needed.
</p>


<h3>Author(s)</h3>

<p>Mengtong Li
</p>


<h3>References</h3>

<p>Brennan, R. L., &amp; Prediger, D. J. (1981). Coefficient kappa: Some uses, misuses,
and alternatives. <em>Educational and Psychological Measurement, 41</em>(3),
687-699. https://doi.org/10.1177/001316448104100307
</p>
<p>Gwet, K. L. (2008). Computing inter rater reliability and its
variance in the presence of high agreement.
<em>British Journal of Mathematical and Statistical Psychology, 61</em>(1),
29-48. https://doi.org/10.1348/000711006X126600
</p>
<p>Gwet, K. L. (2014). <em>Handbook of inter-rater reliability (4th ed.):
The definitive guide to measuring the extent of agreement among raters</em>.
Gaithersburg, MD: Advanced Analytics Press.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Simulate 60 items loading on different Big Five dimensions,
## with different mean and item difficulty

item_dims &lt;- sample(c("Openness","Conscientiousness","Neuroticism",
                     "Extraversion","Agreeableness"), 60, replace = TRUE)
item_mean &lt;- rnorm(60, 5, 2)
item_difficulty &lt;- runif(60, -1, 1)


item_df &lt;- data.frame(Dimensions = item_dims,
                     Mean = item_mean, Difficulty = item_difficulty)
solution &lt;- make_random_block(60, 60, 3)


item_responses &lt;- matrix(sample(seq(1:5), 600*60, replace = TRUE), nrow = 60, byrow = TRUE)

## Automatic pairing, without use of IIAs
## See ?facfun for information about what it does

sa_pairing_generalized(solution, 60, eta_Temperature = 0.01,
                                   r = 0.999, end_criteria = 0.001,
                                   weights = c(1,1,1),
                                   item_chars = item_df,
                                   FUN = c("facfun", "var", "var"))


## Automatic pairing, with IIAs

sa_pairing_generalized(solution, 60, eta_Temperature = 0.01,
                                   r = 0.999, end_criteria = 0.001,
                                   weights = c(1,1,1),
                                   item_chars = item_df,
                                   FUN = c("facfun", "var", "var"),
                                   use_IIA = TRUE,
                                   rater_chars = item_responses,
                                   iia_weights = c(BPlin = 1, BPquad = 1,
                                   AClin = 1, ACquad = 1))



</code></pre>

<hr>
<h2 id='triplet_block_info'>Block Information for the Example Triplet Response Data</h2><span id='topic+triplet_block_info'></span>

<h3>Description</h3>

<p>Block design information of the 5-block triplet for <code>triplet_example_data</code>, 
containing ID, factor, keying, and block membership for the 15 items.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triplet_block_info
</code></pre>


<h3>Format</h3>

<p>A data frame with 15 rows and 4 columns.
</p>

<dl>
<dt>Keying</dt><dd><p>Indicates whether the item is positively keyed (1) or negatively keyed (-1).</p>
</dd>
<dt>Factor</dt><dd><p>Indicates the factor of the item. It can be either one of the six HEXACO traits.</p>
</dd>
<dt>Block</dt><dd><p>Indicates which block this item belongs to.</p>
</dd>
<dt>ID</dt><dd><p>Indicates the ID of the item.</p>
</dd>
</dl>



<h3>Source</h3>

<p>https://osf.io/yvpz3/?view_only=08601755f471440b80973194571b60bd
</p>

<hr>
<h2 id='triplet_example_data'>Example Triplet Response Data</h2><span id='topic+triplet_example_data'></span>

<h3>Description</h3>

<p>Responses to a 5-block triplet forced-choice measure, 
converted into pairwise comparisons. This dataset originates from Li et al.'s 
(in press) study on forced-choice measurement.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>triplet_example_data
</code></pre>


<h3>Format</h3>

<p>A data frame with 541 rows and 15 columns.
</p>

<dl>
<dt>i1i2, i1i3, i2i3,
i4i5, i4i6, i5i6,
i7i8, i7i9, i8i9,
i10i11, i10i12, i11i12,
i13i14, i13i15, i14i15</dt><dd><p>All possible pairwise comparisons among items in the same block. With a triplet format, each block contains three items, producing three possible pairwise comparisons among these items.
Therefore, i1, i2, and i3 belong to block 1, and so on.
</p>
<p>i1i2 represents the pairwise comparison indicating whether i1 is preferable over i2.
If i1 is preferable over i2, then i1i2 = 1, else i1i2 = 0.</p>
</dd>
</dl>



<h3>Source</h3>

<p>https://osf.io/yvpz3/?view_only=08601755f471440b80973194571b60bd
</p>


<h3>References</h3>

<p>Li, M., Zhang, B., Li, L., Sun, T., &amp; Brown, A., (in press). Mixed-Keying or Desirability-Matching in the Construction of Forced-Choice Measures? An Empirical Investigation and Practical Recommendations. <em>Organizational Research Methods</em>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
