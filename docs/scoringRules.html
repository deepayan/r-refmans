<!DOCTYPE html><html><head><title>Help for package scoringRules</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {scoringRules}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#ar_ms'><p>Bayesian analysis of a Markov Switching autoregressive model</p></a></li>
<li><a href='#crps.numeric'><p>Continuous Ranked Probability Score for Parametric Forecast Distributions</p></a></li>
<li><a href='#GDP data'>
<p>Data and forecasts for US GDP growth</p></a></li>
<li><a href='#logs.numeric'><p>Logarithmic Score for Parametric Forecast Distributions</p></a></li>
<li><a href='#plot.casestudy'><p>Plot the output of run_casestudy</p></a></li>
<li><a href='#plot.mcstudy'><p>Plot the output of run_mcstudy</p></a></li>
<li><a href='#print.casestudy'><p>Simple print method for object of class casestudy</p></a></li>
<li><a href='#print.mcstudy'><p>Simple print function for object of class mcstudy</p></a></li>
<li><a href='#run_casestudy'><p>Run the case study in KLTG (2021), or a smaller version thereof</p></a></li>
<li><a href='#run_mcstudy'><p>Run the Monte Carlo study by KLTG (2021), or a smaller version thereof</p></a></li>
<li><a href='#scores'><p>Generic Scoring Rule Calculation</p></a></li>
<li><a href='#scores_2pexp'><p>Calculating scores for the two-piece-exponential distribution</p></a></li>
<li><a href='#scores_2pnorm'><p>Calculating scores for the two-piece-normal distribution</p></a></li>
<li><a href='#scores_beta'><p>Calculating scores for the beta distribution</p></a></li>
<li><a href='#scores_binom'><p>Calculating scores for the binomial distribution</p></a></li>
<li><a href='#scores_exp'><p>Calculating scores for the exponential distribution</p></a></li>
<li><a href='#scores_gamma'><p>Calculating scores for the gamma distribution</p></a></li>
<li><a href='#scores_gev'><p>Calculating scores for the generalized extreme value distribution</p></a></li>
<li><a href='#scores_gpd'><p>Calculating scores for the generalized Pareto distribution</p></a></li>
<li><a href='#scores_hyper'><p>Calculating scores for the hypergeometric distribution</p></a></li>
<li><a href='#scores_lapl'><p>Calculating scores for the Laplace distribution</p></a></li>
<li><a href='#scores_llapl'><p>Calculating scores for the log-Laplace distribution</p></a></li>
<li><a href='#scores_llogis'><p>Calculating scores for the log-logistic distribution</p></a></li>
<li><a href='#scores_lnorm'><p>Calculating scores for the log-normal distribution</p></a></li>
<li><a href='#scores_logis'><p>Calculating scores for the logistic distribution</p></a></li>
<li><a href='#scores_mixnorm'><p>Calculating scores for a mixture of normal distributions.</p></a></li>
<li><a href='#scores_moments'><p>Scoring Rules for a Vector of Moments</p></a></li>
<li><a href='#scores_nbinom'><p>Calculating scores for the negative binomial distribution</p></a></li>
<li><a href='#scores_norm'><p>Calculating scores for the normal distribution</p></a></li>
<li><a href='#scores_pois'><p>Calculating scores for the Poisson distribution</p></a></li>
<li><a href='#scores_sample_multiv'><p>Multivariate Scoring Rules for Simulated Forecast Distributions</p></a></li>
<li><a href='#scores_sample_multiv_weighted'><p>Weighted Multivariate Scoring Rules for Simulated Forecast Distributions (experimental)</p></a></li>
<li><a href='#scores_sample_univ'><p>Scoring Rules for Simulated Forecast Distributions</p></a></li>
<li><a href='#scores_sample_univ_weighted'><p>Weighted Scoring Rules for Simulated Forecast Distributions (experimental)</p></a></li>
<li><a href='#scores_t'><p>Calculating scores for Student's <code class="reqn">t</code>-distribution</p></a></li>
<li><a href='#scores_unif'><p>Calculating scores for the uniform distribution</p></a></li>
<li><a href='#summary.casestudy'><p>Summary method for class casestudy</p></a></li>
<li><a href='#summary.mcstudy'><p>Simple summary method for class mcstudy</p></a></li>
<li><a href='#Supplementary distributions: Positive real line'>
<p>Supplementary distributions (not in base R) supported on the positive real line.</p></a></li>
<li><a href='#Supplementary distributions: Real line'><p>Supplementary distributions (not in base R) supported on the real line.</p></a></li>
<li><a href='#Supplementary distributions: Variable support'>
<p>Supplementary distributions (not in base R) with variable support.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Scoring Rules for Parametric and Simulated Distribution
Forecasts</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-05-10</td>
</tr>
<tr>
<td>Description:</td>
<td>Dictionary-like reference for computing scoring rules in a wide
    range of situations. Covers both parametric forecast distributions (such as
    mixtures of Gaussians) and distributions generated via simulation.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/FK83/scoringRules">https://github.com/FK83/scoringRules</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.12.0), methods, MASS, knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.00)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>gsl (&ge; 1.8-3), hypergeo(&ge; 1.0), rmarkdown, testthat, crch,
ggplot2</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.3</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-05-10 20:14:58 UTC; fabian</td>
</tr>
<tr>
<td>Author:</td>
<td>Alexander I. Jordan
    <a href="https://orcid.org/0000-0001-7423-1352"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut],
  Fabian Krueger <a href="https://orcid.org/0000-0002-5112-9037"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Sebastian Lerch <a href="https://orcid.org/0000-0002-3467-4375"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Sam Allen [aut],
  Maximiliane Graeter [ctb]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Fabian Krueger &lt;Fabian.Krueger83@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-05-10 20:50:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='ar_ms'>Bayesian analysis of a Markov Switching autoregressive model</h2><span id='topic+ar_ms'></span>

<h3>Description</h3>

<p>Bayesian analysis of a Markov Switching autoregressive model
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ar_ms(
  y,
  nlag = 1,
  beta_switch = FALSE,
  variance_switch = TRUE,
  identification_constraint = "variance",
  n_burn = 5000,
  n_rep = 20000,
  forecast_periods = 5,
  printout = FALSE,
  Hm1_delta = 25,
  mu_delta = 0,
  s_ = 0.3,
  nu_ = 3,
  R = matrix(c(8, 2, 2, 8), nrow = 2)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ar_ms_+3A_y">y</code></td>
<td>
<p>numeric vector (time series to be analyzed).</p>
</td></tr>
<tr><td><code id="ar_ms_+3A_nlag">nlag</code></td>
<td>
<p>integer, number of autoregressive lags (defaults to one).</p>
</td></tr>
<tr><td><code id="ar_ms_+3A_beta_switch">beta_switch</code>, <code id="ar_ms_+3A_variance_switch">variance_switch</code></td>
<td>
<p>logicals, indicating whether there should be Markovian state 
dependence in regression parameters and residual variance, respectively. Defaults to 
<code>beta_switch = FALSE</code>, <code>variance_switch = TRUE</code>.</p>
</td></tr>
<tr><td><code id="ar_ms_+3A_identification_constraint">identification_constraint</code></td>
<td>
<p>character, indicating how to identify latent states. Possible values:
<code>"variance"</code>, <code>"mean"</code> and <code>"persistence"</code>. Defaults to <code>"variance"</code>.</p>
</td></tr>
<tr><td><code id="ar_ms_+3A_n_burn">n_burn</code>, <code id="ar_ms_+3A_n_rep">n_rep</code></td>
<td>
<p>integers, number of MCMC iterations for burn-in and main analysis.</p>
</td></tr>
<tr><td><code id="ar_ms_+3A_forecast_periods">forecast_periods</code></td>
<td>
<p>number of future periods for which forecasts are computed.</p>
</td></tr>
<tr><td><code id="ar_ms_+3A_printout">printout</code></td>
<td>
<p>logical, whether to print progress report during MCMC (defaults to <code>FALSE</code>).</p>
</td></tr>
<tr><td><code id="ar_ms_+3A_hm1_delta">Hm1_delta</code>, <code id="ar_ms_+3A_mu_delta">mu_delta</code>, <code id="ar_ms_+3A_s_">s_</code>, <code id="ar_ms_+3A_nu_">nu_</code>, <code id="ar_ms_+3A_r">R</code></td>
<td>
<p>prior parameters as described in KLTG (2021, Appendix E and Table 4).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The default parameters are as set by KLTG (2021, Section 5). The output matrices <code>fcMeans</code> and <code>fcSds</code> can be used to construct 
the mixture-of-parameters estimator analyzed by KLTG. While many of the model features can be changed as described above, the number of Markov regimes is always fixed at two. 
</p>
<p><a href="#topic+ar_ms">ar_ms</a> is an R/C++ implementation of Matlab code kindly shared by Gianni Amisano via his website (<a href="https://sites.google.com/site/gianniamisanowebsite/">https://sites.google.com/site/gianniamisanowebsite/</a>). See Amisano and Giacomini (2007) who analyze a similar model.
</p>


<h3>Value</h3>

<p>List containing parameter estimates and forecasts, with the following elements:
</p>

<ul>
<li> <p><code>pars</code>, matrix of posterior draws for parameters (rows are MCMC iterations, columns are parameters)
</p>
</li>
<li> <p><code>fcMeans</code> and <code>fcSds</code>, matrices of forecast means and standard deviations (rows are MCMC iterations, columns are forecast horizons)
</p>
</li>
<li> <p><code>probs</code>, matrix of filtered probabilities for first latent state (rows are MCMC iterations, columns are time periods, excluding the first <code>nlag</code> values for initialization). 
</p>
</li>
<li> <p><code>count</code>, integer, counter for the number of states that were relabeled based on <code>identification_constraint</code>.
</p>
</li></ul>



<h3>Author(s)</h3>

<p>Fabian Krueger, based on Matlab code by Gianni Amisano (see details section)
</p>


<h3>References</h3>

<p>Amisano, G. and R. Giacomini (2007), &lsquo;Comparing density forecasts via weighted likelihood ratio tests&rsquo;, Journal of Business and Economic Statistics 25, 177-190. <a href="https://doi.org/10.1198/073500106000000332">doi:10.1198/073500106000000332</a>
</p>
<p>Krueger, F., Lerch, S., Thorarinsdottir, T.L. and T. Gneiting (2021): &lsquo;Predictive inference based on Markov chain Monte Carlo output&rsquo;, <em>International Statistical Review</em> 89, 274-301. <a href="https://doi.org/10.1111/insr.12405">doi:10.1111/insr.12405</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+run_casestudy">run_casestudy</a> uses <a href="#topic+ar_ms">ar_ms</a> to replicate the results of KLTG (2021, Section 5).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
# Use GDP data from 2014Q4 edition
data(gdp)
dat &lt;- subset(gdp, vint == "2014Q4")
y &lt;- dat$val[order(dat$dt)]

# Fit model, using the default settings 
set.seed(816)
fit &lt;- ar_ms(y)

# Histograms of parameter draws
par(mfrow = c(2, 2))
hist(fit$pars[,1], main = "Intercept (state-invariant)", xlab = "")
hist(fit$pars[,2], main = "AR(1) term (state-invariant)", xlab = "")
hist(1/fit$pars[,3], main = "Residual variance in 1st state", xlab = "")
hist(1/fit$pars[,4], main = "Residual variance in 2nd state", xlab = "")

# By construction, the residual variance is smaller in the 1st than in the 2nd state:
print(mean(1/fit$pars[,3] &lt; 1/fit$pars[,4]))

## End(Not run)
</code></pre>

<hr>
<h2 id='crps.numeric'>Continuous Ranked Probability Score for Parametric Forecast Distributions</h2><span id='topic+crps.numeric'></span>

<h3>Description</h3>

<p>Calculate the Continuous Ranked Probability Score (CRPS) given observations
and parameters of a family of distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
crps(y, family, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="crps.numeric_+3A_y">y</code></td>
<td>
<p>vector of realized values.</p>
</td></tr>
<tr><td><code id="crps.numeric_+3A_family">family</code></td>
<td>
<p>string which specifies the parametric family; current options:
<code>"2pexp", "2pnorm", "beta", "binom", "clogis", "cnorm", "ct", "exp", "expM",
"exponential", "gamma", "gev", "gpd", "gtclogis", "gtcnorm", "gtct", "hyper", "lapl",
"laplace", "llapl", "llogis", "lnorm", "log-laplace", "log-logistic",
"log-normal", "logis", "logistic", "mixnorm", "mixture-normal", "nbinom",
"negative-binomial", "norm", "normal", "pois", "poisson", "t", "tlogis",
"tnorm", "tt", "two-piece-exponential", "two-piece-normal", "unif", "uniform"</code>.</p>
</td></tr>
<tr><td><code id="crps.numeric_+3A_...">...</code></td>
<td>
<p>vectors of parameter values; expected input depends on the chosen
<code>family</code>. See details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Mathematical details are available in Appendix A of the vignette
<em>Evaluating probabilistic forecasts with scoringRules</em> that
accompanies the package.
</p>
<p>The parameters supplied to each of the functions are numeric vectors:
</p>

<ol>
<li><p> Distributions defined on the real line:
</p>

<ul>
<li>
<p><code>"laplace"</code> or <code>"lapl"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter);
see <code><a href="#topic+crps_lapl">crps_lapl</a></code>
</p>
</li>
<li>
<p><code>"logistic"</code> or <code>"logis"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter);
see <code><a href="#topic+crps_logis">crps_logis</a></code>
</p>
</li>
<li>
<p><code>"normal"</code> or <code>"norm"</code>:
<code>mean</code>, <code>sd</code> (mean and standard deviation);
see <code><a href="#topic+crps_norm">crps_norm</a></code>
</p>
</li>
<li>
<p><code>"normal-mixture"</code> or <code>"mixture-normal"</code> or <code>"mixnorm"</code>:
<code>m</code> (mean parameters),
<code>s</code> (standard deviations),
<code>w</code> (weights);
see <code><a href="#topic+crps_mixnorm">crps_mixnorm</a></code>;
note: matrix-input for parameters
</p>
</li>
<li>
<p><code>"t"</code>:
<code>df</code> (degrees of freedom),
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter);
see <code><a href="#topic+crps_t">crps_t</a></code>
</p>
</li>
<li>
<p><code>"two-piece-exponential"</code> or <code>"2pexp"</code>:
<code>location</code> (real-valued location parameter),
<code>scale1</code>, <code>scale2</code> (positive scale parameters);
see <code><a href="#topic+crps_2pexp">crps_2pexp</a></code>
</p>
</li>
<li>
<p><code>"two-piece-normal"</code> or <code>"2pnorm"</code>:
<code>location</code> (real-valued location parameter),
<code>scale1</code>, <code>scale2</code> (positive scale parameters);
see <code><a href="#topic+crps_2pnorm">crps_2pnorm</a></code>
</p>
</li></ul>

</li>
<li><p> Distributions for non-negative random variables:
</p>

<ul>
<li>
<p><code>"exponential"</code> or <code>"exp"</code>:
<code>rate</code> (positive rate parameter);
see <code><a href="#topic+crps_exp">crps_exp</a></code>
</p>
</li>
<li>
<p><code>"gamma"</code>:
<code>shape</code> (positive shape parameter),
<code>rate</code> (positive rate parameter),
<code>scale</code> (alternative to <code>rate</code>);
see <code><a href="#topic+crps_gamma">crps_gamma</a></code>
</p>
</li>
<li>
<p><code>"log-laplace"</code> or <code>"llapl"</code>:
<code>locationlog</code> (real-valued location parameter),
<code>scalelog</code> (positive scale parameter);
see <code><a href="#topic+crps_llapl">crps_llapl</a></code>
</p>
</li>
<li>
<p><code>"log-logistic"</code> or <code>"llogis"</code>:
<code>locationlog</code> (real-valued location parameter),
<code>scalelog</code> (positive scale parameter);
see <code><a href="#topic+crps_llogis">crps_llogis</a></code>
</p>
</li>
<li>
<p><code>"log-normal"</code> or <code>"lnorm"</code>:
<code>locationlog</code> (real-valued location parameter),
<code>scalelog</code> (positive scale parameter);
see <code><a href="#topic+crps_lnorm">crps_lnorm</a></code>
</p>
</li></ul>

</li>
<li><p> Distributions with flexible support and/or point masses:
</p>

<ul>
<li>
<p><code>"beta"</code>:
<code>shape1</code>, <code>shape2</code> (positive shape parameters),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+crps_beta">crps_beta</a></code>
</p>
</li>
<li>
<p><code>"uniform"</code> or <code>"unif"</code>:
<code>min</code>, <code>max</code> (lower and upper limits),
<code>lmass</code>, <code>umass</code> (point mass in lower or upper limit);
see <code><a href="#topic+crps_unif">crps_unif</a></code>
</p>
</li>
<li>
<p><code>"expM"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter),
<code>mass</code> (point mass in <code>location</code>);
see <code><a href="#topic+crps_expM">crps_expM</a></code>
</p>
</li>
<li>
<p><code>"gev"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter),
<code>shape</code> (real-valued shape parameter);
see <code><a href="#topic+crps_gev">crps_gev</a></code>
</p>
</li>
<li>
<p><code>"gpd"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter),
<code>shape</code> (real-valued shape parameter),
<code>mass</code> (point mass in <code>location</code>);
see <code><a href="#topic+crps_gpd">crps_gpd</a></code>
</p>
</li>
<li>
<p><code>"tlogis"</code>:
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+crps_tlogis">crps_tlogis</a></code>
</p>
</li>
<li>
<p><code>"clogis"</code>:
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+crps_clogis">crps_clogis</a></code>
</p>
</li>
<li>
<p><code>"gtclogis"</code>:
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
<code>lmass</code>, <code>umass</code> (point mass in lower or upper limit);
see <code><a href="#topic+crps_gtclogis">crps_gtclogis</a></code>
</p>
</li>
<li>
<p><code>"tnorm"</code>:
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+crps_tnorm">crps_tnorm</a></code>
</p>
</li>
<li>
<p><code>"cnorm"</code>:
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+crps_cnorm">crps_cnorm</a></code>
</p>
</li>
<li>
<p><code>"gtcnorm"</code>:
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
<code>lmass</code>, <code>umass</code> (point mass in lower or upper limit);
see <code><a href="#topic+crps_gtcnorm">crps_gtcnorm</a></code>
</p>
</li>
<li>
<p><code>"tt"</code>:
<code>df</code> (degrees of freedom),
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+crps_tt">crps_tt</a></code>
</p>
</li>
<li>
<p><code>"ct"</code>:
<code>df</code> (degrees of freedom),
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+crps_ct">crps_ct</a></code>
</p>
</li>
<li>
<p><code>"gtct"</code>:
<code>df</code> (degrees of freedom),
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
<code>lmass</code>, <code>umass</code> (point mass in lower or upper limit);
see <code><a href="#topic+crps_gtct">crps_gtct</a></code>
</p>
</li></ul>

</li>
<li><p> Distributions of discrete variables:
</p>

<ul>
<li> 
<p><code>"binom"</code>:
<code>size</code> (number of trials (zero or more)),
<code>prob</code> (probability of success on each trial);
see <code><a href="#topic+crps_binom">crps_binom</a></code>
</p>
</li>
<li> 
<p><code>"hyper"</code>:
<code>m</code> (the number of white balls in the urn),
<code>n</code> (the number of black balls in the urn),
<code>k</code> (the number of balls drawn from the urn);
see <code><a href="#topic+crps_hyper">crps_hyper</a></code>
</p>
</li>
<li>
<p><code>"negative-binomial"</code> or <code>"nbinom"</code>:
<code>size</code> (positive dispersion parameter),
<code>prob</code> (success probability),
<code>mu</code> (mean, alternative to <code>prob</code>);
see <code><a href="#topic+crps_nbinom">crps_nbinom</a></code>
</p>
</li>
<li>
<p><code>"poisson"</code> or <code>"pois"</code>:
<code>lambda</code> (positive mean);
see <code><a href="#topic+crps_pois">crps_pois</a></code>
</p>
</li></ul>

</li></ol>

<p>All numerical arguments should be of the same length.
An exception are scalars of length 1, which will be recycled.
</p>


<h3>Value</h3>

<p>Vector of score values.
<em>A lower score indicates a better forecast.</em>
</p>


<h3>Author(s)</h3>

<p>Alexander Jordan, Fabian Krueger, Sebastian Lerch
</p>


<h3>References</h3>

<p><em>Closed form expressions of the CRPS for specific distributions:</em>
</p>
<p>Baran, S. and S. Lerch (2015):
'Log-normal distribution based Ensemble Model Output Statistics models for
probabilistic wind-speed forecasting',
Quarterly Journal of the Royal Meteorological Society 141, 2289-2299.
<a href="https://doi.org/10.1002/qj.2521">doi:10.1002/qj.2521</a>
<em>(Log-normal)</em>
</p>
<p>Friederichs, P. and T.L. Thorarinsdottir (2012):
'Forecast verification for extreme value distributions with an application
to probabilistic peak wind prediction',
Environmetrics 23, 579-594.
<a href="https://doi.org/10.1002/env.2176">doi:10.1002/env.2176</a>
<em>(Generalized Extreme Value, Generalized Pareto)</em>
</p>
<p>Gneiting, T., Larson, K., Westvelt III, A.H. and T. Goldman (2005):
'Calibrated probabilistic forecasting using ensemble model output statistics
and minimum CRPS estimation',
Monthly Weather Review 133, 1098-1118.
<a href="https://doi.org/10.1175/mwr2904.1">doi:10.1175/mwr2904.1</a>
<em>(Normal)</em>
</p>
<p>Gneiting, T., Larson, K., Westrick, K., Genton, M.G. and E. Aldrich (2006):
'Calibrated probabilistic forecasting at the stateline wind energy center:
The regime-switching space-time method',
Journal of the American Statistical Association 101, 968-979.
<a href="https://doi.org/10.1198/016214506000000456">doi:10.1198/016214506000000456</a>
<em>(Censored normal)</em>
</p>
<p>Gneiting, T. and T.L. Thorarinsdottir (2010):
&lsquo;Predicting inflation: Professional experts versus no-change forecasts&rsquo;,
arXiv preprint arXiv:1010.2318.
<em>(Two-piece normal)</em>
</p>
<p>Grimit, E.P.,  Gneiting, T., Berrocal, V.J. and N.A. Johnson (2006):
'The continuous ranked probability score for circular variables and its
application to mesoscale forecast ensemble verification',
Quarterly Journal of the Royal Meteorological Society 132, 2925-2942.
<a href="https://doi.org/10.1256/qj.05.235">doi:10.1256/qj.05.235</a>
<em>(Mixture of normals)</em>
</p>
<p>Scheuerer, M. and D. Moeller (2015):
'Probabilistic wind speed forecasting on a grid based on ensemble model
output statistics', Annals of Applied Statistics 9, 1328-1349.
<a href="https://doi.org/10.1214/15-aoas843">doi:10.1214/15-aoas843</a>
<em>(Gamma)</em>
</p>
<p>Thorarinsdottir, T.L. and T. Gneiting (2010):
'Probabilistic forecasts of wind speed: ensemble model output statistics by
using heteroscedastic censored regression',
Journal of the Royal Statistical Society (Series A) 173, 371-388.
<a href="https://doi.org/10.1111/j.1467-985x.2009.00616.x">doi:10.1111/j.1467-985x.2009.00616.x</a>
<em>(Truncated normal)</em>
</p>
<p>Wei, W. and L. Held (2014):
&lsquo;Calibration tests for count data&rsquo;,
TEST 23, 787-205.
<a href="https://doi.org/10.1007/s11749-014-0380-8">doi:10.1007/s11749-014-0380-8</a>
<em>(Poisson, Negative Binomial)</em>
</p>
<p><em>Independent listing of closed-form solutions for the CRPS:</em>
</p>
<p>Taillardat, M., Mestre, O., Zamo, M. and P. Naveau (2016):
'Calibrated ensemble forecasts using quantile regression forests and
ensemble model output statistics',
Monthly Weather Review 144, 2375-2393. 
<a href="https://doi.org/10.1175/mwr-d-15-0260.1">doi:10.1175/mwr-d-15-0260.1</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+logs.numeric">logs.numeric</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>crps(y = 1, family = "normal", mean = 0, sd = 2)
crps(y = rnorm(20), family = "normal", mean = 1:20, sd = sqrt(1:20))

## Arguments can have different lengths:
crps(y = rnorm(20), family = "normal", mean = 0, sd = 2)
crps(y = 1, family = "normal", mean = 1:20, sd = sqrt(1:20))

## Mixture of normal distributions requires matrix input for parameters:
mval &lt;- matrix(rnorm(20*50), nrow = 20)
sdval &lt;- matrix(runif(20*50, min = 0, max = 2), nrow = 20)
weights &lt;- matrix(rep(1/50, 20*50), nrow = 20)
crps(y = rnorm(20), family = "mixnorm", m = mval, s = sdval, w = weights)


</code></pre>

<hr>
<h2 id='GDP+20data'>
Data and forecasts for US GDP growth
</h2><span id='topic+gdp'></span><span id='topic+gdp_mcmc'></span>

<h3>Description</h3>

<p>Historical data and forecast distributions for the growth rate of US gross domestic product (GDP). The forecasts are generated from a Bayesian Markov Switching model as described in Section 5 of KLTG (2021). 
</p>


<h3>Format</h3>

<p><code>gdp</code> is a data frame which contains the real-time data set used in Section 5 of KLTG (2021), with the following columns:
</p>

<ul>
<li> <p><code>dt</code> - date in question (e.g., <code>"2013Q2"</code> for the second quarter of 2013)
</p>
</li>
<li> <p><code>vint</code> - data vintage (i.e., the date at which the realization was recorded); same format as <code>dt</code>
</p>
</li>
<li> <p><code>val</code> - value of the GDP growth rate
</p>
</li></ul>

<p><code>gdp_mcmc</code> is a list, whereby each element is a data frame. <code>gdp_mcmc$forecasts</code> contains the simulated forecast distributions. There are 20 columns (corresponding to quarters 2008:Q1 to 2012:Q4) and 5.000 rows (corresponding to simulation draws). <code>gdp_mcmc$actuals</code> contains the actual observations. There are 20 columns (again corresponding to quarterly dates) and a single row. 
</p>


<h3>Details</h3>

<p>The realizations in <code>gdp_mcmc$actuals</code> are also contained in <code>gdp</code>, based on the second available vintage for each date. For example, <code>gdp_mcmc$actuals$X2008Q1</code> is the entry in <code>gdp</code> for which <code>dt == "2008Q1"</code> and <code>vint == "2008Q3"</code>.
</p>


<h3>Source</h3>

<p>The GDP growth rate is computed from real-time data provided by the Federal Reserve Bank of Philadelphia, <a href="https://www.philadelphiafed.org/surveys-and-data/real-time-data-research/real-time-data-set-for-macroeconomists">https://www.philadelphiafed.org/surveys-and-data/real-time-data-research/real-time-data-set-for-macroeconomists</a> (series code &ldquo;ROUTPUT&rdquo;, second-vintage data). The same data also enters the model which is used to generate the forecast distribution. <em>Disclaimer: The provider of the raw data takes no responsibility for the accuracy of the data posted here. Furthermore, the raw data may be revised over time, and the website linked above should be consulted for the official, most recent version.</em>
</p>
<p>The model from which the forecast draws are generated is described in Section 5 of KLTG (2021). Forecasts are one quarter ahead (that is, they are based on data until the previous quarter).
</p>


<h3>References</h3>

<p>Krueger, F., Lerch, S., Thorarinsdottir, T.L. and T. Gneiting (2021): &lsquo;Predictive inference based on Markov chain Monte Carlo output&rsquo;, <em>International Statistical Review</em> 89, 274-301. <a href="https://doi.org/10.1111/insr.12405">doi:10.1111/insr.12405</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# Load data
data(gdp_mcmc)

# Histogram of forecast draws for 2012Q4
fc_draws &lt;- gdp_mcmc$forecasts[, "X2012Q4"]
hist(fc_draws, main = "Forecast draws for 2012:Q4", xlab = "Value")

# Add vertical line at realizing value
rlz &lt;- gdp_mcmc$actuals[, "X2012Q4"]
abline(v = rlz, lwd = 3)

# Compute CRPS for this forecast case
crps_sample(y = rlz, dat = fc_draws)


## End(Not run)
</code></pre>

<hr>
<h2 id='logs.numeric'>Logarithmic Score for Parametric Forecast Distributions</h2><span id='topic+logs.numeric'></span>

<h3>Description</h3>

<p>Calculate the logarithmic score (LogS) given observations
and parameters of a family of distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'numeric'
logs(y, family, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="logs.numeric_+3A_y">y</code></td>
<td>
<p>Vector of realized values.</p>
</td></tr>
<tr><td><code id="logs.numeric_+3A_family">family</code></td>
<td>
<p>String which specifies the parametric family; current options:
<code>"2pexp", "2pnorm", "beta", "binom", "exp", "exp2",
"exponential", "gamma", "gev", "gpd", "hyper", "lapl",
"laplace", "llapl", "llogis", "lnorm", "log-laplace", "log-logistic",
"log-normal", "logis", "logistic", "mixnorm", "mixture-normal", "nbinom",
"negative-binomial", "norm", "normal", "pois", "poisson", "t", "tlogis",
"tnorm", "tt", "two-piece-exponential", "two-piece-normal", "unif", "uniform"</code>.</p>
</td></tr>
<tr><td><code id="logs.numeric_+3A_...">...</code></td>
<td>
<p>Vectors of parameter values; expected input depends on the chosen
<code>family</code>. See details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The parameters supplied to each of the functions are numeric vectors:
</p>

<ol>
<li><p> Distributions defined on the real line:
</p>

<ul>
<li>
<p><code>"laplace"</code> or <code>"lapl"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter);
see <code><a href="#topic+logs_lapl">logs_lapl</a></code>
</p>
</li>
<li>
<p><code>"logistic"</code> or <code>"logis"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter);
see <code><a href="#topic+logs_logis">logs_logis</a></code>
</p>
</li>
<li>
<p><code>"normal"</code> or <code>"norm"</code>:
<code>mean</code>, <code>sd</code> (mean and standard deviation);
see <code><a href="#topic+logs_norm">logs_norm</a></code>
</p>
</li>
<li>
<p><code>"normal-mixture"</code> or <code>"mixture-normal"</code> or <code>"mixnorm"</code>:
<code>m</code> (mean parameters),
<code>s</code> (standard deviations),
<code>w</code> (weights);
see <code><a href="#topic+logs_mixnorm">logs_mixnorm</a></code>;
note: matrix-input for parameters
</p>
</li>
<li>
<p><code>"t"</code>:
<code>df</code> (degrees of freedom),
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter);
see <code><a href="#topic+logs_t">logs_t</a></code>
</p>
</li>
<li>
<p><code>"two-piece-exponential"</code> or <code>"2pexp"</code>:
<code>location</code> (real-valued location parameter),
<code>scale1</code>, <code>scale2</code> (positive scale parameters);
see <code><a href="#topic+logs_2pexp">logs_2pexp</a></code>
</p>
</li>
<li>
<p><code>"two-piece-normal"</code> or <code>"2pnorm"</code>:
<code>location</code> (real-valued location parameter),
<code>scale1</code>, <code>scale2</code> (positive scale parameters);
see <code><a href="#topic+logs_2pnorm">logs_2pnorm</a></code>
</p>
</li></ul>

</li>
<li><p> Distributions for non-negative random variables:
</p>

<ul>
<li>
<p><code>"exponential"</code> or <code>"exp"</code>:
<code>rate</code> (positive rate parameter);
see <code><a href="#topic+logs_exp">logs_exp</a></code>
</p>
</li>
<li>
<p><code>"gamma"</code>:
<code>shape</code> (positive shape parameter),
<code>rate</code> (positive rate parameter),
<code>scale</code> (alternative to <code>rate</code>);
see <code><a href="#topic+logs_gamma">logs_gamma</a></code>
</p>
</li>
<li>
<p><code>"log-laplace"</code> or <code>"llapl"</code>:
<code>locationlog</code> (real-valued location parameter),
<code>scalelog</code> (positive scale parameter);
see <code><a href="#topic+logs_llapl">logs_llapl</a></code>
</p>
</li>
<li>
<p><code>"log-logistic"</code> or <code>"llogis"</code>:
<code>locationlog</code> (real-valued location parameter),
<code>scalelog</code> (positive scale parameter);
see <code><a href="#topic+logs_llogis">logs_llogis</a></code>
</p>
</li>
<li>
<p><code>"log-normal"</code> or <code>"lnorm"</code>:
<code>locationlog</code> (real-valued location parameter),
<code>scalelog</code> (positive scale parameter);
see <code><a href="#topic+logs_lnorm">logs_lnorm</a></code>
</p>
</li></ul>

</li>
<li><p> Distributions with flexible support and/or point masses:
</p>

<ul>
<li>
<p><code>"beta"</code>:
<code>shape1</code>, <code>shape2</code> (positive shape parameters),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+logs_beta">logs_beta</a></code>
</p>
</li>
<li>
<p><code>"uniform"</code> or <code>"unif"</code>:
<code>min</code>, <code>max</code> (lower and upper limits);
see <code><a href="#topic+logs_unif">logs_unif</a></code>
</p>
</li>
<li>
<p><code>"exp2"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter);
see <code><a href="#topic+logs_exp2">logs_exp2</a></code>
</p>
</li>
<li>
<p><code>"gev"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter),
<code>shape</code> (real-valued shape parameter);
see <code><a href="#topic+logs_gev">logs_gev</a></code>
</p>
</li>
<li>
<p><code>"gpd"</code>:
<code>location</code> (real-valued location parameter),
<code>scale</code> (positive scale parameter),
<code>shape</code> (real-valued shape parameter);
see <code><a href="#topic+logs_gpd">logs_gpd</a></code>
</p>
</li>
<li>
<p><code>"tlogis"</code>:
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+logs_tlogis">logs_tlogis</a></code>
</p>
</li>
<li>
<p><code>"tnorm"</code>:
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+logs_tnorm">logs_tnorm</a></code>
</p>
</li>
<li>
<p><code>"tt"</code>:
<code>df</code> (degrees of freedom),
<code>location</code> (location parameter),
<code>scale</code> (scale parameter),
<code>lower</code>, <code>upper</code> (lower and upper limits);
see <code><a href="#topic+logs_tt">logs_tt</a></code>
</p>
</li></ul>

</li>
<li><p> Distributions of discrete variables:
</p>

<ul>
<li> 
<p><code>"binom"</code>:
<code>size</code> (number of trials (zero or more)),
<code>prob</code> (probability of success on each trial);
see <code><a href="#topic+crps_binom">crps_binom</a></code>
</p>
</li>
<li> 
<p><code>"hyper"</code>:
<code>m</code> (the number of white balls in the urn),
<code>n</code> (the number of black balls in the urn),
<code>k</code> (the number of balls drawn from the urn);
see <code><a href="#topic+crps_hyper">crps_hyper</a></code>
</p>
</li>
<li>
<p><code>"negative-binomial"</code> or <code>"nbinom"</code>:
<code>size</code> (positive dispersion parameter),
<code>prob</code> (success probability),
<code>mu</code> (mean, alternative to <code>prob</code>);
see <code><a href="#topic+logs_nbinom">logs_nbinom</a></code>
</p>
</li>
<li>
<p><code>"poisson"</code> or <code>"pois"</code>:
<code>lambda</code> (positive mean);
see <code><a href="#topic+logs_pois">logs_pois</a></code>
</p>
</li></ul>

</li></ol>

<p>All numerical arguments should be of the same length.
An exception are scalars of length 1, which will be recycled.
</p>


<h3>Value</h3>

<p>Vector of score values.
<em>A lower score indicates a better forecast.</em>
</p>


<h3>Author(s)</h3>

<p>Alexander Jordan, Fabian Krueger, Sebastian Lerch
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crps.numeric">crps.numeric</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>logs(y = 1, family = "normal", mean = 0, sd = 2) 
logs(y = rnorm(20), family = "normal", mean = 1:20, sd = sqrt(1:20))

## Arguments can have different lengths:
logs(y = rnorm(20), family = "normal", mean = 0, sd = 2)
logs(y = 1, family = "normal", mean = 1:20, sd = sqrt(1:20))

## Mixture of normal distributions requires matrix input for parameters:
mval &lt;- matrix(rnorm(20*50), nrow = 20)
sdval &lt;- matrix(runif(20*50, min = 0, max = 2), nrow = 20)
weights &lt;- matrix(rep(1/50, 20*50), nrow = 20)
logs(y = rnorm(20), family = "mixnorm", m = mval, s = sdval, w = weights)

</code></pre>

<hr>
<h2 id='plot.casestudy'>Plot the output of run_casestudy</h2><span id='topic+plot.casestudy'></span>

<h3>Description</h3>

<p>Plot the output of run_casestudy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'casestudy'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.casestudy_+3A_x">x</code></td>
<td>
<p>object of class <code>casestudy</code>, generated by <a href="#topic+run_casestudy">run_casestudy</a></p>
</td></tr>
<tr><td><code id="plot.casestudy_+3A_...">...</code></td>
<td>
<p>additional parameters, see details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot is in the same format as Figure 3 in KLTG (2021). Its content (nr of MCMC chains, 
maximal sample size, etc) depends on the parameters used to generate <a href="#topic+run_casestudy">run_casestudy</a>. In terms of 
additional inputs (<code>...</code>), the following are currently implemented:
</p>
<ul>
<li> <p><code>scoring_rule</code>, the scoring rule for which results are to be plotted, 
either <code>"crps"</code> or <code>"logs"</code>. Defaults to <code>"crps"</code>. </p>
</li>
<li> <p><code>add_main_title</code>, logical,
whether to add main title to plot. Defaults to <code>TRUE</code>.</p>
</li></ul>



<h3>Value</h3>

<p>none, used for the effect of drawing a plot.
</p>


<h3>Author(s)</h3>

<p>Fabian Krueger
</p>


<h3>References</h3>

<p>Krueger, F., Lerch, S., Thorarinsdottir, T.L. and T. Gneiting (2021): &lsquo;Predictive inference based on Markov chain Monte Carlo output&rsquo;, <em>International Statistical Review</em> 89, 274-301. <a href="https://doi.org/10.1111/insr.12405">doi:10.1111/insr.12405</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+run_casestudy">run_casestudy</a> produces the forecast results summarized by <a href="#topic+plot.casestudy">plot.casestudy</a>
</p>

<hr>
<h2 id='plot.mcstudy'>Plot the output of run_mcstudy</h2><span id='topic+plot.mcstudy'></span>

<h3>Description</h3>

<p>Plot the output of run_mcstudy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mcstudy'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mcstudy_+3A_x">x</code></td>
<td>
<p>object of class <code>mcstudy</code>, generated by <a href="#topic+run_mcstudy">run_mcstudy</a></p>
</td></tr>
<tr><td><code id="plot.mcstudy_+3A_...">...</code></td>
<td>
<p>additional parameters, see details below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The plot is in the same format as Figure 1 or 2 in KLTG (2021), depending on the 
parameters set when running <a href="#topic+run_mcstudy">run_mcstudy</a>. These parameters also determine the plot content 
(nr of MCMC chains, maximal sample size, etc). In terms of 
additional inputs (<code>...</code>), the following are currently implemented:
</p>
<ul>
<li> <p><code>scoring_rule</code>, the scoring rule for which results are to be plotted, 
either <code>"crps"</code> or <code>"logs"</code>. Defaults to <code>"crps"</code>. </p>
</li>
<li> <p><code>add_main_title</code>, logical,
whether to add main title to plot. Defaults to <code>TRUE</code>.</p>
</li></ul>



<h3>Value</h3>

<p>none, used for the effect of drawing a plot.
</p>


<h3>Author(s)</h3>

<p>Fabian Krueger
</p>


<h3>References</h3>

<p>Krueger, F., Lerch, S., Thorarinsdottir, T.L. and T. Gneiting (2021): &lsquo;Predictive inference based on Markov chain Monte Carlo output&rsquo;, <em>International Statistical Review</em> 89, 274-301. <a href="https://doi.org/10.1111/insr.12405">doi:10.1111/insr.12405</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+run_mcstudy">run_mcstudy</a> produces the simulation results summarized by <a href="#topic+plot.mcstudy">plot.mcstudy</a>
</p>

<hr>
<h2 id='print.casestudy'>Simple print method for object of class casestudy</h2><span id='topic+print.casestudy'></span>

<h3>Description</h3>

<p>Simple print method for object of class casestudy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'casestudy'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.casestudy_+3A_x">x</code></td>
<td>
<p>Object of class casestudy, generated via <a href="#topic+run_casestudy">run_casestudy</a></p>
</td></tr>
<tr><td><code id="print.casestudy_+3A_...">...</code></td>
<td>
<p>Additional specifications (presently not in use)</p>
</td></tr>
</table>

<hr>
<h2 id='print.mcstudy'>Simple print function for object of class mcstudy</h2><span id='topic+print.mcstudy'></span>

<h3>Description</h3>

<p>Simple print function for object of class mcstudy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mcstudy'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mcstudy_+3A_x">x</code></td>
<td>
<p>Object of class mcstudy, generated via <a href="#topic+run_mcstudy">run_mcstudy</a></p>
</td></tr>
<tr><td><code id="print.mcstudy_+3A_...">...</code></td>
<td>
<p>Additional specifications (presently not in use)</p>
</td></tr>
</table>

<hr>
<h2 id='run_casestudy'>Run the case study in KLTG (2021), or a smaller version thereof</h2><span id='topic+run_casestudy'></span>

<h3>Description</h3>

<p>Run the case study in KLTG (2021), or a smaller version thereof
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_casestudy(
  data_df,
  burnin_size = 5000,
  max_mcmc_sample_size = 5000,
  nr_of_chains = 3,
  first_vint = "1996Q2",
  last_vint = "2014Q3",
  forecast_horizon = 1,
  random_seed = 816
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="run_casestudy_+3A_data_df">data_df</code></td>
<td>
<p>data frame in the same format as the <a href="#topic+gdp">gdp</a> data set in this package.</p>
</td></tr>
<tr><td><code id="run_casestudy_+3A_burnin_size">burnin_size</code></td>
<td>
<p>length of the burn-in period used for each forecast.</p>
</td></tr>
<tr><td><code id="run_casestudy_+3A_max_mcmc_sample_size">max_mcmc_sample_size</code></td>
<td>
<p>maximal number of MCMC draws to consider (integer, must equal either 1000, 5000, 10000, 20000 or 40000). Defaults to 5000.</p>
</td></tr>
<tr><td><code id="run_casestudy_+3A_nr_of_chains">nr_of_chains</code></td>
<td>
<p>number of parallel MCMC for each forecast date (integer, defaults to 3).</p>
</td></tr>
<tr><td><code id="run_casestudy_+3A_first_vint">first_vint</code>, <code id="run_casestudy_+3A_last_vint">last_vint</code></td>
<td>
<p>first and last data vintage (= time point at which forecasts are made). Default to &quot;19962Q2&quot; and &quot;2014Q3&quot;, respectively.</p>
</td></tr>
<tr><td><code id="run_casestudy_+3A_forecast_horizon">forecast_horizon</code></td>
<td>
<p>forecast horizon to be analyzed (integer, defaults to 1).</p>
</td></tr>
<tr><td><code id="run_casestudy_+3A_random_seed">random_seed</code></td>
<td>
<p>seed for random numbers used during the MCMC sampling process. Defaults to 816.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The full results in Section 5 of KLTG (2021) are based on the following setup: <code>burnin_size = 10000</code>,
<code>max_mcmc_sample_size = 50000</code>, <code>nr_of_chains = 16</code>, <code>data_df = gdp</code>, <code>first_vint = "1996Q2"</code>, 
<code>last_vint = "2014Q3"</code>, and <code>forecast_horizon = 1</code>. Since running this full configuration is very 
time consuming, the default setup offers the possibility to run a small-scale study which reproduces the 
qualitative outcomes of the analysis. Running the small-scale study implied by the defaults of <code>run_study</code> as well as the GDP data (<code>data_df = gdp</code>) takes about 40 minutes on an Intel i7 processor.
</p>


<h3>Value</h3>

<p>Object of class &quot;casestudy&quot;, containing the results of the analysis. This object can be passed to <code>plot</code> for plotting, see the documentation for <a href="#topic+plot.casestudy">plot.casestudy</a>.
</p>


<h3>Author(s)</h3>

<p>Fabian Krueger
</p>


<h3>References</h3>

<p>Krueger, F., Lerch, S., Thorarinsdottir, T.L. and T. Gneiting (2021): &lsquo;Predictive inference based on Markov chain Monte Carlo output&rsquo;, <em>International Statistical Review</em> 89, 274-301. <a href="https://doi.org/10.1111/insr.12405">doi:10.1111/insr.12405</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+plot.casestudy">plot.casestudy</a> produces a summary plot of the results generated by <a href="#topic+run_casestudy">run_casestudy</a>
<a href="#topic+run_casestudy">run_casestudy</a> uses <a href="#topic+ar_ms">ar_ms</a> to fit a Bayesian Markov Switching model, recursively for several time periods.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(gdp)
cs &lt;- run_casestudy(data_df = gdp, last_vint = "1999Q4")
plot(cs)

## End(Not run)
</code></pre>

<hr>
<h2 id='run_mcstudy'>Run the Monte Carlo study by KLTG (2021), or a smaller version thereof</h2><span id='topic+run_mcstudy'></span>

<h3>Description</h3>

<p>Run the Monte Carlo study by KLTG (2021), or a smaller version thereof
</p>


<h3>Usage</h3>

<pre><code class='language-R'>run_mcstudy(
  s = 2,
  a = 0.5,
  n = 12,
  nr_iterations = 50,
  zoom = FALSE,
  random_seed = 816
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="run_mcstudy_+3A_s">s</code>, <code id="run_mcstudy_+3A_a">a</code>, <code id="run_mcstudy_+3A_n">n</code></td>
<td>
<p>parameters characterizing the process from which data are simulated (see Section 4 and Table 4 of KLTG, 2021). Defaults to the values reported in the main text of the paper.</p>
</td></tr>
<tr><td><code id="run_mcstudy_+3A_nr_iterations">nr_iterations</code></td>
<td>
<p>number of Monte Carlo iterations (defaults to 50).</p>
</td></tr>
<tr><td><code id="run_mcstudy_+3A_zoom">zoom</code></td>
<td>
<p>set to <code>TRUE</code> to produce results for a fine grid of small (MCMC) sample sizes, as in Figure 2 of KLTG (2021).</p>
</td></tr>
<tr><td><code id="run_mcstudy_+3A_random_seed">random_seed</code></td>
<td>
<p>seed used for running the simulation experiment. Defaults to 816.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The full results in Section 4 of KLTG (2021) are based on <code>s = 2</code>, <code>a = 0.5</code>,
<code>n = 12</code> and <code>nr_iterations = 1000</code>. Producing these results takes about 140 minutes on an 
Intel i7 processor.
</p>


<h3>Value</h3>

<p>Object of class &quot;mcstudy&quot;, containing the results of the analysis. This object can be passed to <code>plot</code> for plotting, see the documentation for <a href="#topic+plot.mcstudy">plot.mcstudy</a>.
</p>


<h3>Author(s)</h3>

<p>Fabian Krueger
</p>


<h3>References</h3>

<p>Krueger, F., Lerch, S., Thorarinsdottir, T.L. and T. Gneiting (2021): &lsquo;Predictive inference based on Markov chain Monte Carlo output&rsquo;, <em>International Statistical Review</em> 89, 274-301. <a href="https://doi.org/10.1111/insr.12405">doi:10.1111/insr.12405</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+plot.mcstudy">plot.mcstudy</a> produces a summary plot of the results generated by <a href="#topic+run_mcstudy">run_mcstudy</a>
</p>

<hr>
<h2 id='scores'>Generic Scoring Rule Calculation</h2><span id='topic+scores'></span><span id='topic+crps'></span><span id='topic+logs'></span>

<h3>Description</h3>

<p>Generic functions for calculating the Continuous Ranked Probability Score
and the Logarithmic Score of R objects.
</p>
<p><code>scoringRules</code> provides default methods
(<code><a href="#topic+crps.numeric">crps.numeric</a></code>, <code><a href="#topic+logs.numeric">logs.numeric</a></code>) to calculate scores of forecasts
that are members of families of parametric distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps(y, ...)

logs(y, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_+3A_y">y</code></td>
<td>
<p>an object for which the score is to be calculated</p>
</td></tr>
<tr><td><code id="scores_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean logarithmic score corresponds to the negative of the
log-likelihood <code><a href="stats.html#topic+logLik">logLik</a></code>.
</p>


<h3>Value</h3>

<p>Returns a vector of scores. One for each forecast-observation pair.
</p>


<h3>References</h3>

<p><em>General background and further references on scoring rules:</em>
</p>
<p>Gneiting, T. and A.E. Raftery (2007):
&lsquo;Strictly proper scoring rules, prediction and estimation&rsquo;,
Journal of the American Statistical Association 102, 359-378. <a href="https://doi.org/10.1198/016214506000001437">doi:10.1198/016214506000001437</a>
</p>
<p>Gneiting, T. and M. Katzfuss (2014):
&lsquo;Probabilistic forecasting&rsquo;,
Annual Review of Statistics and Its Application 1, 125-151. <a href="https://doi.org/10.1146/annurev-statistics-062713-085831">doi:10.1146/annurev-statistics-062713-085831</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+crps.numeric">crps.numeric</a></code>, <code><a href="#topic+logs.numeric">logs.numeric</a></code>
</p>

<hr>
<h2 id='scores_2pexp'>Calculating scores for the two-piece-exponential distribution</h2><span id='topic+scores_2pexp'></span><span id='topic+crps_2pexp'></span><span id='topic+logs_2pexp'></span>

<h3>Description</h3>

<p>Calculating scores for the two-piece-exponential distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_2pexp(y, scale1, scale2, location = 0)

logs_2pexp(y, scale1, scale2, location = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_2pexp_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_2pexp_+3A_scale1">scale1</code>, <code id="scores_2pexp_+3A_scale2">scale2</code></td>
<td>
<p>vectors of positive scale parameters.</p>
</td></tr>
<tr><td><code id="scores_2pexp_+3A_location">location</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_2pnorm'>Calculating scores for the two-piece-normal distribution</h2><span id='topic+scores_2pnorm'></span><span id='topic+crps_2pnorm'></span><span id='topic+logs_2pnorm'></span>

<h3>Description</h3>

<p>Calculating scores for the two-piece-normal distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_2pnorm(y, scale1, scale2, location = 0)

logs_2pnorm(y, scale1, scale2, location = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_2pnorm_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_2pnorm_+3A_scale1">scale1</code>, <code id="scores_2pnorm_+3A_scale2">scale2</code></td>
<td>
<p>vectors of positive scale parameters.</p>
</td></tr>
<tr><td><code id="scores_2pnorm_+3A_location">location</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_beta'>Calculating scores for the beta distribution</h2><span id='topic+scores_beta'></span><span id='topic+crps_beta'></span><span id='topic+logs_beta'></span><span id='topic+dss_beta'></span>

<h3>Description</h3>

<p>Calculating scores for the beta distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_beta(y, shape1, shape2, lower = 0, upper = 1)

logs_beta(y, shape1, shape2, lower = 0, upper = 1)

dss_beta(y, shape1, shape2, lower = 0, upper = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_beta_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_beta_+3A_shape1">shape1</code>, <code id="scores_beta_+3A_shape2">shape2</code></td>
<td>
<p>vectors of positive shape parameters.</p>
</td></tr>
<tr><td><code id="scores_beta_+3A_lower">lower</code>, <code id="scores_beta_+3A_upper">upper</code></td>
<td>
<p>vectors of lower and upper limits of the distribution. Must be finite.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_binom'>Calculating scores for the binomial distribution</h2><span id='topic+scores_binom'></span><span id='topic+crps_binom'></span><span id='topic+logs_binom'></span>

<h3>Description</h3>

<p>Calculating scores for the binomial distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_binom(y, size, prob)

logs_binom(y, size, prob)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_binom_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_binom_+3A_size">size</code></td>
<td>
<p>number of trials (zero or more).</p>
</td></tr>
<tr><td><code id="scores_binom_+3A_prob">prob</code></td>
<td>
<p>probability of success on each trial.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_exp'>Calculating scores for the exponential distribution</h2><span id='topic+scores_exp'></span><span id='topic+crps_exp'></span><span id='topic+crps_expM'></span><span id='topic+logs_exp'></span><span id='topic+logs_exp2'></span><span id='topic+dss_exp'></span>

<h3>Description</h3>

<p>Calculating scores (CRPS, LogS, DSS) for the exponential distribution,
and the exponential distribution with location-scale transformation and
point mass in <code>location</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_exp(y, rate = 1)

crps_expM(y, location = 0, scale = 1, mass = 0)

logs_exp(y, rate = 1)

logs_exp2(y, location = 0, scale = 1)

dss_exp(y, rate = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_exp_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_exp_+3A_rate">rate</code></td>
<td>
<p>vector of rates.</p>
</td></tr>
<tr><td><code id="scores_exp_+3A_location">location</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
<tr><td><code id="scores_exp_+3A_scale">scale</code></td>
<td>
<p>vector of positive scale parameters.</p>
</td></tr>
<tr><td><code id="scores_exp_+3A_mass">mass</code></td>
<td>
<p>vector of point masses in <code>location</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_gamma'>Calculating scores for the gamma distribution</h2><span id='topic+scores_gamma'></span><span id='topic+crps_gamma'></span><span id='topic+logs_gamma'></span><span id='topic+dss_gamma'></span>

<h3>Description</h3>

<p>Calculating scores for the gamma distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_gamma(y, shape, rate = 1, scale = 1/rate)

logs_gamma(y, shape, rate = 1, scale = 1/rate)

dss_gamma(y, shape, rate = 1, scale = 1/rate)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_gamma_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_gamma_+3A_shape">shape</code></td>
<td>
<p>vector of positive shape parameters.</p>
</td></tr>
<tr><td><code id="scores_gamma_+3A_rate">rate</code></td>
<td>
<p>an alternative way to specify the scale.</p>
</td></tr>
<tr><td><code id="scores_gamma_+3A_scale">scale</code></td>
<td>
<p>vector of positive scale parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_gev'>Calculating scores for the generalized extreme value distribution</h2><span id='topic+scores_gev'></span><span id='topic+crps_gev'></span><span id='topic+logs_gev'></span><span id='topic+dss_gev'></span>

<h3>Description</h3>

<p>Calculating scores for the generalized extreme value distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_gev(y, shape, location = 0, scale = 1)

logs_gev(y, shape, location = 0, scale = 1)

dss_gev(y, shape, location = 0, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_gev_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_gev_+3A_shape">shape</code></td>
<td>
<p>vector of positive shape parameters.</p>
</td></tr>
<tr><td><code id="scores_gev_+3A_location">location</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
<tr><td><code id="scores_gev_+3A_scale">scale</code></td>
<td>
<p>vector of positive scale parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_gpd'>Calculating scores for the generalized Pareto distribution</h2><span id='topic+scores_gpd'></span><span id='topic+crps_gpd'></span><span id='topic+logs_gpd'></span><span id='topic+dss_gpd'></span>

<h3>Description</h3>

<p>Calculating scores for the generalized Pareto distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_gpd(y, shape, location = 0, scale = 1, mass = 0)

logs_gpd(y, shape, location = 0, scale = 1)

dss_gpd(y, shape, location = 0, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_gpd_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_gpd_+3A_shape">shape</code></td>
<td>
<p>vector of positive shape parameters.</p>
</td></tr>
<tr><td><code id="scores_gpd_+3A_location">location</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
<tr><td><code id="scores_gpd_+3A_scale">scale</code></td>
<td>
<p>vector of positive scale parameters.</p>
</td></tr>
<tr><td><code id="scores_gpd_+3A_mass">mass</code></td>
<td>
<p>vector of point masses in <code>location</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_hyper'>Calculating scores for the hypergeometric distribution</h2><span id='topic+scores_hyper'></span><span id='topic+crps_hyper'></span><span id='topic+logs_hyper'></span>

<h3>Description</h3>

<p>Calculating scores for the hypergeometric distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_hyper(y, m, n, k)

logs_hyper(y, m, n, k)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_hyper_+3A_y">y</code></td>
<td>
<p>vector of observations / numbers of white balls drawn without replacement from an urn which contains both black and white balls.</p>
</td></tr>
<tr><td><code id="scores_hyper_+3A_m">m</code></td>
<td>
<p>the number of white balls in the urn.</p>
</td></tr>
<tr><td><code id="scores_hyper_+3A_n">n</code></td>
<td>
<p>the number of black balls in the urn.</p>
</td></tr>
<tr><td><code id="scores_hyper_+3A_k">k</code></td>
<td>
<p>the number of balls drawn from the urn, hence must be in
<code class="reqn">0,1,\dots, m+n</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_lapl'>Calculating scores for the Laplace distribution</h2><span id='topic+scores_lapl'></span><span id='topic+crps_lapl'></span><span id='topic+logs_lapl'></span><span id='topic+dss_lapl'></span>

<h3>Description</h3>

<p>Calculating scores for the Laplace distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_lapl(y, location = 0, scale = 1)

logs_lapl(y, location = 0, scale = 1)

dss_lapl(y, location = 0, scale = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_lapl_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_lapl_+3A_location">location</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
<tr><td><code id="scores_lapl_+3A_scale">scale</code></td>
<td>
<p>vector of positive scale parameters.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_llapl'>Calculating scores for the log-Laplace distribution</h2><span id='topic+scores_llapl'></span><span id='topic+crps_llapl'></span><span id='topic+logs_llapl'></span><span id='topic+dss_llapl'></span>

<h3>Description</h3>

<p>Calculating scores for the log-Laplace distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_llapl(y, locationlog, scalelog)

logs_llapl(y, locationlog, scalelog)

dss_llapl(y, locationlog, scalelog)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_llapl_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_llapl_+3A_locationlog">locationlog</code></td>
<td>
<p>vector of location parameters on the log scale.</p>
</td></tr>
<tr><td><code id="scores_llapl_+3A_scalelog">scalelog</code></td>
<td>
<p>vector of positive scale parameters on the log scale.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_llogis'>Calculating scores for the log-logistic distribution</h2><span id='topic+scores_llogis'></span><span id='topic+crps_llogis'></span><span id='topic+logs_llogis'></span><span id='topic+dss_llogis'></span>

<h3>Description</h3>

<p>Calculating scores for the log-logistic distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_llogis(y, locationlog, scalelog)

logs_llogis(y, locationlog, scalelog)

dss_llogis(y, locationlog, scalelog)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_llogis_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_llogis_+3A_locationlog">locationlog</code></td>
<td>
<p>vector of location parameters on the log scale.</p>
</td></tr>
<tr><td><code id="scores_llogis_+3A_scalelog">scalelog</code></td>
<td>
<p>vector of positive scale parameters on the log scale.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_lnorm'>Calculating scores for the log-normal distribution</h2><span id='topic+scores_lnorm'></span><span id='topic+crps_lnorm'></span><span id='topic+logs_lnorm'></span><span id='topic+dss_lnorm'></span>

<h3>Description</h3>

<p>Calculating scores for the log-normal distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_lnorm(y, meanlog = 0, sdlog = 1, locationlog = meanlog, scalelog = sdlog)

logs_lnorm(y, meanlog = 0, sdlog = 1, locationlog = meanlog, scalelog = sdlog)

dss_lnorm(y, meanlog = 0, sdlog = 1, locationlog = meanlog, scalelog = sdlog)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_lnorm_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_lnorm_+3A_meanlog">meanlog</code></td>
<td>
<p>an alternative way to specify <code>locationlog</code>.</p>
</td></tr>
<tr><td><code id="scores_lnorm_+3A_sdlog">sdlog</code></td>
<td>
<p>an alternative way to specify <code>scalelog</code>.</p>
</td></tr>
<tr><td><code id="scores_lnorm_+3A_locationlog">locationlog</code></td>
<td>
<p>vector of location parameters on the log scale.</p>
</td></tr>
<tr><td><code id="scores_lnorm_+3A_scalelog">scalelog</code></td>
<td>
<p>vector of positive scale parameters on the log scale.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_logis'>Calculating scores for the logistic distribution</h2><span id='topic+scores_logis'></span><span id='topic+crps_logis'></span><span id='topic+crps_clogis'></span><span id='topic+crps_tlogis'></span><span id='topic+crps_gtclogis'></span><span id='topic+logs_logis'></span><span id='topic+logs_tlogis'></span><span id='topic+dss_logis'></span><span id='topic+gradcrps_logis'></span><span id='topic+gradcrps_clogis'></span><span id='topic+gradcrps_tlogis'></span><span id='topic+hesscrps_logis'></span><span id='topic+hesscrps_clogis'></span><span id='topic+hesscrps_tlogis'></span>

<h3>Description</h3>

<p>These functions calculate scores (CRPS, logarithmic score) and its gradient and Hessian with respect
to the parameters of a location-scale transformed logistic
distribution. Furthermore, the censoring transformation and
the truncation transformation may be introduced on top of the
location-scale transformed logistic distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## score functions
crps_logis(y, location = 0, scale = 1)
crps_clogis(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
crps_tlogis(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
crps_gtclogis(y, location = 0, scale = 1, lower = -Inf, upper = Inf, lmass = 0, umass = 0)
logs_logis(y, location = 0, scale = 1)
logs_tlogis(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
dss_logis(y, location = 0, scale = 1)

## gradient (location, scale) functions
gradcrps_logis(y, location = 0, scale = 1)
gradcrps_clogis(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
gradcrps_tlogis(y, location = 0, scale = 1, lower = -Inf, upper = Inf)

## Hessian (location, scale) functions
hesscrps_logis(y, location = 0, scale = 1)
hesscrps_clogis(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
hesscrps_tlogis(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_logis_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_logis_+3A_location">location</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
<tr><td><code id="scores_logis_+3A_scale">scale</code></td>
<td>
<p>vector of scale paramters.</p>
</td></tr>
<tr><td><code id="scores_logis_+3A_lower">lower</code>, <code id="scores_logis_+3A_upper">upper</code></td>
<td>
<p>lower and upper truncation/censoring bounds.</p>
</td></tr>
<tr><td><code id="scores_logis_+3A_lmass">lmass</code>, <code id="scores_logis_+3A_umass">umass</code></td>
<td>
<p>vectors of point masses in <code>lower</code> and <code>upper</code>
respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For the score functions: a vector of score values.
</p>
<p>For the gradient and Hessian functions: a matrix with column names
corresponding to the respective partial derivatives.
</p>

<hr>
<h2 id='scores_mixnorm'>Calculating scores for a mixture of normal distributions.</h2><span id='topic+scores_mixnorm'></span><span id='topic+crps_mixnorm'></span><span id='topic+crps_mixnorm_int'></span><span id='topic+logs_mixnorm'></span><span id='topic+dss_mixnorm'></span>

<h3>Description</h3>

<p>Calculating scores for a mixture of normal distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_mixnorm(y, m, s, w = NULL)

crps_mixnorm_int(y, m, s, w = NULL, rel_tol = 1e-06)

logs_mixnorm(y, m, s, w = NULL)

dss_mixnorm(y, m, s, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_mixnorm_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_mixnorm_+3A_m">m</code></td>
<td>
<p>matrix of mean parameters; rows represent observations, columns represent mixture components.</p>
</td></tr>
<tr><td><code id="scores_mixnorm_+3A_s">s</code></td>
<td>
<p>matrix of scale parameters; same structure as <code>m</code>.</p>
</td></tr>
<tr><td><code id="scores_mixnorm_+3A_w">w</code></td>
<td>
<p>optional; matrix of non-negative weights; same structure as <code>m</code>.</p>
</td></tr>
<tr><td><code id="scores_mixnorm_+3A_rel_tol">rel_tol</code></td>
<td>
<p>relative accuracy for numerical integration.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>logs_mixnorm</code> and <code>crps_mixnorm</code> calculate scores via analytical formulas. <code>crps_mixnorm_int</code> uses numerical integration for the CRPS; this can be faster if there are many mixture components (i.e., if <code>m</code>, <code>s</code> and <code>w</code> have many columns). See examples below.
</p>


<h3>Value</h3>

<p>A vector of score values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Example 1: 100 observations, 15 mixture components
mval &lt;- matrix(rnorm(100*15), nrow = 100)
sdval &lt;- matrix(rgamma(100*15, shape = 2), nrow = 100)
weights &lt;- matrix(rep(1/15, 100*15), nrow = 100)
y &lt;- rnorm(100)
crps1 &lt;- crps_mixnorm(y = y, m = mval, s = sdval, w = weights)
crps2 &lt;- crps_mixnorm_int(y = y, m = mval, s = sdval, w = weights)

## Not run: 
# Example 2: 2 observations, 10000 mixture components
mval &lt;- matrix(rnorm(2*10000), nrow = 2)
sdval &lt;- matrix(rgamma(2*10000, shape = 2), nrow = 2)
weights &lt;- matrix(rep(1/10000, 2*10000), nrow = 2)
y &lt;- rnorm(2)
# With many mixture components, numerical integration is much faster
system.time(crps1 &lt;- crps_mixnorm(y = y, m = mval, s = sdval, w = weights))
system.time(crps2 &lt;- crps_mixnorm_int(y = y, m = mval, s = sdval, w = weights))

## End(Not run)
</code></pre>

<hr>
<h2 id='scores_moments'>Scoring Rules for a Vector of Moments</h2><span id='topic+scores_moments'></span><span id='topic+dss_moments'></span><span id='topic+ess_moments'></span>

<h3>Description</h3>

<p>Calculate scores (DSS, ESS) given observations and moments of the predictive distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dss_moments(y, mean = 0, var = 1)

ess_moments(y, mean = 0, var = 1, skew = 0)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_moments_+3A_y">y</code></td>
<td>
<p>vector of realized values.</p>
</td></tr>
<tr><td><code id="scores_moments_+3A_mean">mean</code></td>
<td>
<p>vector of mean values.</p>
</td></tr>
<tr><td><code id="scores_moments_+3A_var">var</code></td>
<td>
<p>vector of variance values.</p>
</td></tr>
<tr><td><code id="scores_moments_+3A_skew">skew</code></td>
<td>
<p>vector of skewness values.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The skewness of a random variable <code class="reqn">X</code> is the third standardized moment 
</p>
<p style="text-align: center;"><code class="reqn">E[(\frac{X-\textnormal{mean}}{\sqrt{\textnormal{var}}})^3].</code>
</p>



<h3>Value</h3>

<p>Value of the score. <em>A lower score indicates a better forecast.</em>
</p>


<h3>Author(s)</h3>

<p>Alexander Jordan, Sebastian Lerch
</p>


<h3>References</h3>

<p><em>Dawid-Sebastiani score:</em>
</p>
<p>Dawid, A.P. and P. Sebastiani (1999):
'Coherent dispersion criteria for optimal experimental design'
The Annals of Statistics, 27, 65-81. <a href="https://doi.org/10.1214/aos/1018031101">doi:10.1214/aos/1018031101</a>
</p>
<p><em>Error-spread score:</em>
</p>
<p>Christensen, H.M., I.M. Moroz, and T.N. Palmer (2015):
'Evaluation of ensemble forecast uncertainty using a new proper score:
Application to medium-range and seasonal forecasts',
Quarterly Journal of the Royal Meteorological Society, 141, 538-549. <a href="https://doi.org/10.1002/qj.2375">doi:10.1002/qj.2375</a>
</p>

<hr>
<h2 id='scores_nbinom'>Calculating scores for the negative binomial distribution</h2><span id='topic+scores_nbinom'></span><span id='topic+crps_nbinom'></span><span id='topic+logs_nbinom'></span><span id='topic+dss_nbinom'></span>

<h3>Description</h3>

<p>Calculating scores for the negative binomial distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_nbinom(y, size, prob, mu)

logs_nbinom(y, size, prob, mu)

dss_nbinom(y, size, prob, mu)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_nbinom_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_nbinom_+3A_size">size</code></td>
<td>
<p>target for number of successful trials, or dispersion
parameter (the shape parameter of the gamma mixing distribution).
Must be strictly positive, need not be integer.</p>
</td></tr>
<tr><td><code id="scores_nbinom_+3A_prob">prob</code></td>
<td>
<p>probability of success in each trial. <code>0 &lt; prob &lt;= 1</code>.</p>
</td></tr>
<tr><td><code id="scores_nbinom_+3A_mu">mu</code></td>
<td>
<p>alternative parametrization via mean: see &lsquo;Details&rsquo;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The mean of the negative binomial distribution is given by <code>mu</code> = <code>size</code>*(1-<code>prob</code>)/<code>prob</code>.
</p>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_norm'>Calculating scores for the normal distribution</h2><span id='topic+scores_norm'></span><span id='topic+crps_norm'></span><span id='topic+crps_cnorm'></span><span id='topic+crps_tnorm'></span><span id='topic+crps_gtcnorm'></span><span id='topic+logs_norm'></span><span id='topic+logs_tnorm'></span><span id='topic+dss_norm'></span><span id='topic+gradcrps_norm'></span><span id='topic+gradcrps_cnorm'></span><span id='topic+gradcrps_tnorm'></span><span id='topic+hesscrps_norm'></span><span id='topic+hesscrps_cnorm'></span><span id='topic+hesscrps_tnorm'></span>

<h3>Description</h3>

<p>These functions calculate scores (CRPS, LogS, DSS) and
their gradient and Hessian with respect
to the parameters of a location-scale transformed normal
distribution. Furthermore, the censoring transformation and
the truncation transformation may be introduced on top of the
location-scale transformed normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## score functions
crps_norm(y, mean = 0, sd = 1, location = mean, scale = sd)
crps_cnorm(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
crps_tnorm(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
crps_gtcnorm(y, location = 0, scale = 1, lower = -Inf, upper = Inf, lmass = 0, umass = 0)
logs_norm(y, mean = 0, sd = 1, location = mean, scale = sd)
logs_tnorm(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
dss_norm(y, mean = 0, sd = 1, location = mean, scale = sd)

## gradient (location, scale) functions
gradcrps_norm(y, location = 0, scale = 1)
gradcrps_cnorm(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
gradcrps_tnorm(y, location = 0, scale = 1, lower = -Inf, upper = Inf)

## Hessian (location, scale) functions
hesscrps_norm(y, location = 0, scale = 1)
hesscrps_cnorm(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
hesscrps_tnorm(y, location = 0, scale = 1, lower = -Inf, upper = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_norm_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_norm_+3A_mean">mean</code></td>
<td>
<p>an alternative way to specify <code>location</code>.</p>
</td></tr>
<tr><td><code id="scores_norm_+3A_sd">sd</code></td>
<td>
<p>an alternative way to specify <code>scale</code>.</p>
</td></tr>
<tr><td><code id="scores_norm_+3A_location">location</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
<tr><td><code id="scores_norm_+3A_scale">scale</code></td>
<td>
<p>vector of scale parameters.</p>
</td></tr>
<tr><td><code id="scores_norm_+3A_lower">lower</code>, <code id="scores_norm_+3A_upper">upper</code></td>
<td>
<p>lower and upper truncation/censoring bounds.</p>
</td></tr>
<tr><td><code id="scores_norm_+3A_lmass">lmass</code>, <code id="scores_norm_+3A_umass">umass</code></td>
<td>
<p>vectors of point masses in <code>lower</code> and <code>upper</code>
respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For the score functions: a vector of score values.
</p>
<p>For the gradient and Hessian functions: a matrix with column names
corresponding to the respective partial derivatives.
</p>

<hr>
<h2 id='scores_pois'>Calculating scores for the Poisson distribution</h2><span id='topic+scores_pois'></span><span id='topic+crps_pois'></span><span id='topic+logs_pois'></span><span id='topic+dss_pois'></span>

<h3>Description</h3>

<p>Calculating scores for the Poisson distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_pois(y, lambda)

logs_pois(y, lambda)

dss_pois(y, lambda)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_pois_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_pois_+3A_lambda">lambda</code></td>
<td>
<p>vector of (non-negative) means.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='scores_sample_multiv'>Multivariate Scoring Rules for Simulated Forecast Distributions</h2><span id='topic+scores_sample_multiv'></span><span id='topic+es_sample'></span><span id='topic+mmds_sample'></span><span id='topic+vs_sample'></span>

<h3>Description</h3>

<p>Compute multivariate scores of the form <code class="reqn">S(y, dat)</code>, where <code class="reqn">S</code> is a
proper scoring rule, <code class="reqn">y</code> is a d-dimensional realization vector and 
<code class="reqn">dat</code> is a simulated sample of multivariate forecasts. Three scores
are available: The energy score, a score based on a Gaussian kernel 
(<a href="#topic+mmds_sample">mmds_sample</a>, see details below) and the variogram score of order <code class="reqn">p</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>es_sample(y, dat, w = NULL)

mmds_sample(y, dat, w = NULL)

vs_sample(y, dat, w = NULL, w_vs = NULL, p = 0.5)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_sample_multiv_+3A_y">y</code></td>
<td>
<p>realized values (numeric vector of length d).</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_+3A_dat">dat</code></td>
<td>
<p>numeric matrix of data
(columns are simulation draws from multivariate forecast distribution).</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_+3A_w">w</code></td>
<td>
<p>numeric vector of weights for forecast draws (length equal to number of columns of <code>dat</code>)</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_+3A_w_vs">w_vs</code></td>
<td>
<p>numeric matrix of weights for <code>dat</code> used in the variogram
score. This matrix must be square and symmetric, with all elements being non-negative.
If no weights are specified, constant weights (with all elements of <code>w_vs</code> 
equal to one) are used.</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_+3A_p">p</code></td>
<td>
<p>order of variogram score. Standard choices include <code class="reqn">p = 1</code> and
<code class="reqn">p = 0.5</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the input matrix <code>dat</code> each column is expected to represent a sample
from the multivariate forecast distribution, the number of rows of <code>dat</code>
thus has to match the length of the observation vector <code>y</code>, and the
number of columns of <code>dat</code> is the number of simulated samples.
</p>
<p>In <a href="#topic+es_sample">es_sample</a> and <a href="#topic+mmds_sample">mmds_sample</a> it is possible to specify a vector <code>w</code> of weights 
attached to each forecast draw (i.e. each column of matrix <code>dat</code>). These
weights are analogous to the input <code>w</code> in <a href="#topic+crps_sample">crps_sample</a>. 
</p>
<p>In <a href="#topic+vs_sample">vs_sample</a> it is possible to specify a matrix <code>w_vs</code> of
non-negative weights that allow to emphasize or downweight pairs of
component combinations based on subjective expert decisions. <code>w_vs</code> is a
square, symmetric matrix with dimensions equal to the length of the input vector
<code>y</code>, and the entry in the <code class="reqn">i</code>-th row and <code class="reqn">j</code>-th column of
<code>w_vs</code> corresponds to the weight assigned to the combination of the
corresponding <code class="reqn">i</code>-th and <code class="reqn">j</code>-th component. A small example is provided below. 
For details and further examples, see Scheuerer and Hamill (2015).
</p>
<p>The &lsquo;MMD score&rsquo; in <a href="#topic+mmds_sample">mmds_sample</a> is a kernel scoring rule as described in 
Gneiting and Raftery (2007, Section 5). As for all other scores, 
we use a negative orientation, such that a smaller score corresponds to a better
forecast. We use a Gaussian kernel with standard deviation 1. This kernel is
the same as the one obtained by setting <code>rbfdot(sigma = .5)</code> in the 
R package kernlab (Karatzoglou et al., 2004). The naming prefix &lsquo;MMD&rsquo; is 
motivated by the machine learning literature on two sample testing 
(e.g. Gretton et al., 2012), where this type of kernel function is popular.
</p>


<h3>Value</h3>

<p>Value of the score. <em>A lower score indicates a better forecast.</em>
</p>


<h3>Author(s)</h3>

<p>Maximiliane Graeter, Sebastian Lerch, Fabian Krueger
</p>


<h3>References</h3>

<p><em>Energy score</em>
</p>
<p>Gneiting, T., Stanberry, L.I., Grimit, E.P., Held, L. and
N.A. Johnson (2008):
'Assessing probabilistic forecasts of multivariate quantities, with an
application to ensemble predictions of surface winds',
TEST, 17, 211-235. <a href="https://doi.org/10.1007/s11749-008-0114-x">doi:10.1007/s11749-008-0114-x</a>
</p>
<p><em>MMD score</em>
</p>
<p>Gneiting, T. and A.E. Raftery (2007):
&lsquo;Strictly proper scoring rules, prediction and estimation&rsquo;,
Journal of the American Statistical Association 102, 359-378. <a href="https://doi.org/10.1198/016214506000001437">doi:10.1198/016214506000001437</a>
</p>
<p>Gretton, A., Borgwardt, K. M., Rasch, M. J., Schölkopf, B. and
A. Smola (2012): &lsquo;A kernel two-sample test&rsquo;, Journal of' Machine 
Learning Research, 13, 723-773.
</p>
<p>Karatzoglou, A., Smola, A., Hornik, K. and Zeileis A. (2004). 
kernlab - An S4 Package for Kernel Methods in R. Journal of Statistical 
Software 11, 1-20. <a href="https://doi.org/10.18637/jss.v011.i09">doi:10.18637/jss.v011.i09</a> 
</p>
<p><em>Variogram-based proper scoring rules</em>
</p>
<p>Scheuerer, M. and T.M. Hamill (2015):
'Variogram-based proper scoring rules for probabilistic forecasts of
multivariate quantities',
Monthly Weather Review, 143, 1321-1334. <a href="https://doi.org/10.1175/mwr-d-14-00269.1">doi:10.1175/mwr-d-14-00269.1</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scores_sample_multiv_weighted">scores_sample_multiv_weighted</a></code> for weighted versions of the scoring rules documented here.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>d &lt;- 10  # number of dimensions
m &lt;- 50  # number of samples from multivariate forecast distribution

# parameters for multivariate normal example
mu0 &lt;- rep(0, d)
mu &lt;- rep(1, d)
S0 &lt;- S &lt;- diag(d)
S0[S0==0] &lt;- 0.2
S[S==0] &lt;- 0.1

# generate samples from multivariate normal distributions
obs &lt;- drop(mu0 + rnorm(d) %*% chol(S0))
fc_sample &lt;- replicate(m, drop(mu + rnorm(d) %*% chol(S)))

# compute Energy Score
es_sample(y = obs, dat = fc_sample)

# in the univariate case, Energy Score and CRPS are the same
# illustration: Evaluate forecast sample for the first variable
es_sample(y = obs[1], dat = fc_sample[1, , drop = FALSE])
crps_sample(y = obs[1], dat = fc_sample[1, ])

# illustration of observation weights for Energy Score
# example: equal weights for first half of draws; zero weights for other draws
w &lt;- rep(c(1, 0), each = .5*m)/(.5*m)
es_sample(y = obs, dat = fc_sample, w = w)

# weighting matrix for variogram score
# note that, unlike for w, weights in w_vs refer to dimensions 
# (rows of dat) rather than draws (cols of dat)
w_vs &lt;- outer(1:d, 1:d, function(x, y) .5^abs(x-y))

vs_sample(y = obs, dat = fc_sample) 
vs_sample(y = obs, dat = fc_sample, w_vs = w_vs) 
vs_sample(y = obs, dat = fc_sample, w_vs = w_vs, p = 1)


</code></pre>

<hr>
<h2 id='scores_sample_multiv_weighted'>Weighted Multivariate Scoring Rules for Simulated Forecast Distributions (experimental)</h2><span id='topic+scores_sample_multiv_weighted'></span><span id='topic+twes_sample'></span><span id='topic+owes_sample'></span><span id='topic+twmmds_sample'></span><span id='topic+owmmds_sample'></span><span id='topic+twvs_sample'></span><span id='topic+owvs_sample'></span>

<h3>Description</h3>

<p>Compute weighted versions of multivariate scores <code class="reqn">S(y, dat)</code>, where <code class="reqn">S</code> is a
proper scoring rule, <code class="reqn">y</code> is a d-dimensional realization vector and 
<code class="reqn">dat</code> is a simulated sample of multivariate forecasts. The weighted scores allow 
particular outcomes of interest to be emphasised during forecast evaluation.
Threshold-weighted and outcome-weighted versions of three multivariate scores are 
available: the energy score, a score based on a Gaussian kernel (<a href="#topic+mmds_sample">mmds_sample</a>, 
see details below) and the variogram score of order <code class="reqn">p</code>. Note that the functions 
documented here are a new experimental feature of the package, 
and feedback is highly welcome.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twes_sample(
  y,
  dat,
  a = -Inf,
  b = Inf,
  chain_func = function(x) pmin(pmax(x, a), b),
  w = NULL
)

owes_sample(
  y,
  dat,
  a = -Inf,
  b = Inf,
  weight_func = function(x) as.numeric(all(x &gt; a &amp; x &lt; b)),
  w = NULL
)

twmmds_sample(
  y,
  dat,
  a = -Inf,
  b = Inf,
  chain_func = function(x) pmin(pmax(x, a), b),
  w = NULL
)

owmmds_sample(
  y,
  dat,
  a = -Inf,
  b = Inf,
  weight_func = function(x) as.numeric(all(x &gt; a &amp; x &lt; b)),
  w = NULL
)

twvs_sample(
  y,
  dat,
  a = -Inf,
  b = Inf,
  chain_func = function(x) pmin(pmax(x, a), b),
  w = NULL,
  w_vs = NULL,
  p = 0.5
)

owvs_sample(
  y,
  dat,
  a = -Inf,
  b = Inf,
  weight_func = function(x) as.numeric(all(x &gt; a &amp; x &lt; b)),
  w = NULL,
  w_vs = NULL,
  p = 0.5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_sample_multiv_weighted_+3A_y">y</code></td>
<td>
<p>realized values (numeric vector of length d).</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_weighted_+3A_dat">dat</code></td>
<td>
<p>numeric matrix of data
(columns are simulation draws from multivariate forecast distribution).</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_weighted_+3A_a">a</code></td>
<td>
<p>numeric vector of of length d containing lower bounds for the indicator 
weight function <code>w(z) = 1{a[1] &lt; z[1] &lt; b[1], ..., a[d] &lt; z[d] &lt; b[d]}</code>.</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_weighted_+3A_b">b</code></td>
<td>
<p>numeric vector of of length d containing upper bounds for the indicator 
weight function <code>w(z) = 1{a[1] &lt; z[1] &lt; b[1], ..., a[d] &lt; z[d] &lt; b[d]}</code>.</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_weighted_+3A_chain_func">chain_func</code></td>
<td>
<p>function used to target particular outcomes in the threshold-weighted scores; 
the default corresponds to the weight function above.</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_weighted_+3A_w">w</code></td>
<td>
<p>numeric vector of weights for forecast draws (length equal to number of columns of <code>dat</code>)</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_weighted_+3A_weight_func">weight_func</code></td>
<td>
<p>function used to target particular outcomes in the outcome-weighted scores; 
the default corresponds to the weight function above.</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_weighted_+3A_w_vs">w_vs</code></td>
<td>
<p>numeric matrix of weights for <code>dat</code> used in the variogram
score. This matrix must be square and symmetric, with all elements being non-negative.
If no weights are specified, constant weights (with all elements of <code>w_vs</code> 
equal to one) are used.</p>
</td></tr>
<tr><td><code id="scores_sample_multiv_weighted_+3A_p">p</code></td>
<td>
<p>order of variogram score. Standard choices include <code class="reqn">p = 1</code> and
<code class="reqn">p = 0.5</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In the input matrix <code>dat</code> each column is expected to represent a sample
from the multivariate forecast distribution, the number of rows of <code>dat</code>
thus has to match the length of the observation vector <code>y</code>, and the
number of columns of <code>dat</code> is the number of simulated samples.
</p>
<p>The threshold-weighted scores (<code><a href="#topic+twes_sample">twes_sample</a></code>, <code><a href="#topic+twmmds_sample">twmmds_sample</a></code>, 
<code><a href="#topic+twvs_sample">twvs_sample</a></code>) transform <code>y</code> and <code>dat</code> using the chaining
function <code>chain_func</code> and then call the relevant unweighted score function
(<code><a href="#topic+es_sample">es_sample</a></code>, <code><a href="#topic+mmds_sample">mmds_sample</a></code>, <code><a href="#topic+vs_sample">vs_sample</a></code>). 
The outcome-weighted scores (<code><a href="#topic+owes_sample">owes_sample</a></code>, <code><a href="#topic+owmmds_sample">owmmds_sample</a></code>, 
<code><a href="#topic+owvs_sample">owvs_sample</a></code>) weight <code>y</code> and <code>dat</code> using the weight
function <code>weight_func</code> and then call the relevant unweighted score function
(<code><a href="#topic+es_sample">es_sample</a></code>, <code><a href="#topic+mmds_sample">mmds_sample</a></code>, <code><a href="#topic+vs_sample">vs_sample</a></code>). 
See the documentation for e.g. <code><a href="#topic+es_sample">es_sample</a></code> for further details.
</p>
<p>The default weight function used in the weighted scores is 
<code>w(z) = 1{a[1] &lt; z[1] &lt; b[1], ..., a[d] &lt; z[d] &lt; b[d]}</code>, which is equal to one 
if <code>z</code> is in the 'box' defined by the vectors <code>a</code> and <code>b</code>, and 
is equal to zero otherwise. This weight function emphasises outcomes between 
the vectors <code>a</code> and <code>b</code>, and is commonly used in practical applications 
when interest is on values above a threshold along multiple dimensions.
</p>
<p>Alternative weight functions can also be employed using the <code>chain_func</code> 
and <code>weight_func</code> arguments. Computation of the threshold-weighted scores
for samples from a predictive distribution requires a chaining function rather 
than a weight function. This is why a chaining function is an input for 
<code><a href="#topic+twes_sample">twes_sample</a></code>, <code><a href="#topic+twmmds_sample">twmmds_sample</a></code>, and <code><a href="#topic+twvs_sample">twvs_sample</a></code>,
whereas a weight function is an input for <code><a href="#topic+owes_sample">owes_sample</a></code>, 
<code><a href="#topic+owmmds_sample">owmmds_sample</a></code>, and <code><a href="#topic+owvs_sample">owvs_sample</a></code>. 
</p>
<p>The <code>chain_func</code> and <code>weight_func</code> arguments are functions that will 
be applied to the elements in <code>y</code> and <code>dat</code>. 
<code>weight_func</code> must input a numeric vector of length d, and output a single 
numeric value. An error will be returned if <code>weight_func</code> returns negative values.
<code>chain_func</code> must input a numeric vector of length d, and return a numeric
vector of length d.
</p>
<p>If no custom argument is given for <code>a</code>, <code>b</code>, <code>chain_func</code> or 
<code>weight_func</code>, then all weighted scores are equivalent to the standard 
unweighted scores <code><a href="#topic+es_sample">es_sample</a></code>, <code><a href="#topic+mmds_sample">mmds_sample</a></code>, and
<code><a href="#topic+vs_sample">vs_sample</a></code>.
</p>
<p>The <code>w</code> argument is also present in the unweighted scores.
<code>w</code> is used to weight the draws from the predictive distribution, and does 
not weight particular outcomes within the weighted scoring rules. This should not be
confused with the <code>weight_func</code> argument.
</p>


<h3>Value</h3>

<p>Value of the score. <em>A lower score indicates a better forecast.</em>
</p>


<h3>Author(s)</h3>

<p>Sam Allen
</p>


<h3>References</h3>

<p><em>Threshold-weighted scores</em>
</p>
<p>Allen, S., Ginsbourger, D. and J. Ziegel (2022):
&lsquo;Evaluating forecasts for high-impact events using transformed kernel scores&rsquo;,
arXiv preprint arXiv:2202.12732. 
<a href="https://doi.org/10.48550/arXiv.2202.12732">doi:10.48550/arXiv.2202.12732</a>
</p>
<p><em>Outcome-weighted scores:</em>
</p>
<p>Holzmann, H. and B. Klar (2017):
&lsquo;Focusing on regions of interest in forecast evaluation&rsquo;,
<em>Annals of Applied Statistics</em> 11, 2404-2431. 
<a href="https://doi.org/10.1214/17-AOAS1088">doi:10.1214/17-AOAS1088</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+scores_sample_multiv">scores_sample_multiv</a> for standard (un-weighted) scores based on simulated multivariate forecast distributions. <a href="#topic+scores_sample_univ_weighted">scores_sample_univ_weighted</a> for weighted scores based on simulated univariate forecast distributions
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
d &lt;- 3  # number of dimensions
m &lt;- 10  # number of samples from multivariate forecast distribution

# parameters for multivariate normal example
mu0 &lt;- rep(0, d)
mu &lt;- rep(1, d)
S0 &lt;- S &lt;- diag(d)
S0[S0==0] &lt;- 0.2
S[S==0] &lt;- 0.1

# generate samples from multivariate normal distributions
obs &lt;- drop(mu0 + rnorm(d) %*% chol(S0))
sample_fc &lt;- replicate(m, drop(mu + rnorm(d) %*% chol(S)))

# if no additional parameters are provided, the weighted scores are the same as
# the unweighted scores:
es_sample(y = obs, dat = sample_fc) # energy score
twes_sample(y = obs, dat = sample_fc) # threshold-weighted energy score
owes_sample(y = obs, dat = sample_fc) # outcome-weighted energy score

mmds_sample(y = obs, dat = sample_fc) # Gaussian kernel score
twmmds_sample(y = obs, dat = sample_fc) # threshold-weighted Gaussian kernel score
owmmds_sample(y = obs, dat = sample_fc) # outcome-weighted Gaussian kernel score

vs_sample(y = obs, dat = sample_fc) # variogram score
twvs_sample(y = obs, dat = sample_fc) # threshold-weighted variogram score
owvs_sample(y = obs, dat = sample_fc) # outcome-weighted variogram score


# the outcome-weighted scores are undefined if none of dat are between a and b
# this can lead to NaNs in some of the scores calculated below, particularly
# if the thresholds are extreme, or if the dimension is large


# emphasise outcomes greater than 0 in all dimensions
twes_sample(y = obs, dat = sample_fc, a = 0)
owes_sample(y = obs, dat = sample_fc, a = 0)
twmmds_sample(y = obs, dat = sample_fc, a = 0)
owmmds_sample(y = obs, dat = sample_fc, a = 0)
twvs_sample(y = obs, dat = sample_fc, a = 0)
owvs_sample(y = obs, dat = sample_fc, a = 0)

# this can also be done more explicitly by setting a = rep(0, d)
twes_sample(y = obs, dat = sample_fc, a = rep(0, d))
owes_sample(y = obs, dat = sample_fc, a = rep(0, d))

# a should also be specified fully if the threshold changes in each dimension
a &lt;- rnorm(d)
twes_sample(y = obs, dat = sample_fc, a = a)
owes_sample(y = obs, dat = sample_fc, a = a)
twmmds_sample(y = obs, dat = sample_fc, a = a)
owmmds_sample(y = obs, dat = sample_fc, a = a)
twvs_sample(y = obs, dat = sample_fc, a = a)
owvs_sample(y = obs, dat = sample_fc, a = a)

# emphasise outcomes smaller than 0 in all dimensions
twes_sample(y = obs, dat = sample_fc, b = 0)
owes_sample(y = obs, dat = sample_fc, b = 0)
twmmds_sample(y = obs, dat = sample_fc, b = 0)
owmmds_sample(y = obs, dat = sample_fc, b = 0)
twvs_sample(y = obs, dat = sample_fc, b = 0)
owvs_sample(y = obs, dat = sample_fc, b = 0)

# emphasise outcomes between (-1, -1, -1) and (1, 1, 1)
twes_sample(y = obs, dat = sample_fc, a = -1, b = 1)
owes_sample(y = obs, dat = sample_fc, a = -1, b = 1)
twmmds_sample(y = obs, dat = sample_fc, a = -1, b = 1)
owmmds_sample(y = obs, dat = sample_fc, a = -1, b = 1)
twvs_sample(y = obs, dat = sample_fc, a = -1, b = 1)
owvs_sample(y = obs, dat = sample_fc, a = -1, b = 1)

# emphasise outcomes between (-2, 0, -1) and (0, 2, 1)
a &lt;- c(-2, 0, -1)
b &lt;- c(0, 2, 1)
twes_sample(y = obs, dat = sample_fc, a = a, b = b)
owes_sample(y = obs, dat = sample_fc, a = a, b = b)
twmmds_sample(y = obs, dat = sample_fc, a = a, b = b)
owmmds_sample(y = obs, dat = sample_fc, a = a, b = b)
twvs_sample(y = obs, dat = sample_fc, a = a, b = b)
owvs_sample(y = obs, dat = sample_fc, a = a, b = b)


# values of a cannot be larger than the corresponding values of b
twes_sample(y = obs, dat = sample_fc, a = c(0, 0, 0), b = c(0, 0, 1))
twes_sample(y = obs, dat = sample_fc, a = c(0, 0, 0), b = c(0, 0, 0)) # error
twes_sample(y = obs, dat = sample_fc, a = c(0, 0, 0), b = c(1, 1, -1)) # error

# a and b must be of the same length (and of the same length as y)
owmmds_sample(y = obs, dat = sample_fc, a = c(0, 0), b = 1) # error
owmmds_sample(y = obs, dat = sample_fc, a = c(0, 0), b = c(1, 1)) # error


# alternative custom weight and chaining functions can also be used

# Example 1: the default weight function with an alternative chaining function
# the default weight function is 
# w(z) = 1{a[1] &lt; z[1] &lt; b[1], ..., a[d] &lt; z[d] &lt; b[d]}
# the default chaining function is 
# v(z) = (min(max(z[1], a[1]), b[1]), ..., min(max(z[d], a[d]), b[d]))
a &lt;- -2
b &lt;- 2
weight_func &lt;- function(x) as.numeric(all(x &gt; a &amp; x &lt; b))
chain_func &lt;- function(x) pmin(pmax(x, a), b)
owes_sample(y = obs, dat = sample_fc, a = a, b = b)
owes_sample(y = obs, dat = sample_fc, weight_func = weight_func)
twes_sample(y = obs, dat = sample_fc, a = a, b = b)
twes_sample(y = obs, dat = sample_fc, chain_func = chain_func)

# consider an alternative chaining function: v(z) = z if w(z) = 1, else v(z) = 0
chain_func &lt;- function(x) x*weight_func(x)
twes_sample(y = obs, dat = sample_fc, chain_func = chain_func)


# Example 2: a mulivariate Gaussian weight function with mean vector mu and 
# diagonal covariance matrix sigma
mu &lt;- rep(0, d)
sigma &lt;- diag(d)
weight_func &lt;- function(x) prod(pnorm(x, mu, diag(sigma)))
# the corresponding chaining function is
chain_func &lt;- function(x){
 (x - mu)*pnorm(x, mu, diag(sigma)) + (diag(sigma)^2)*dnorm(x, mu, diag(sigma))
}

owvs_sample(y = obs, dat = sample_fc, a = mu)
owvs_sample(y = obs, dat = sample_fc, weight_func = weight_func)
twvs_sample(y = obs, dat = sample_fc, a = mu)
twvs_sample(y = obs, dat = sample_fc, chain_func = chain_func)

## End(Not run)

</code></pre>

<hr>
<h2 id='scores_sample_univ'>Scoring Rules for Simulated Forecast Distributions</h2><span id='topic+scores_sample_univ'></span><span id='topic+crps_sample'></span><span id='topic+logs_sample'></span><span id='topic+dss_sample'></span>

<h3>Description</h3>

<p>Calculate scores (CRPS, LogS, DSS) given observations and draws from the predictive distributions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_sample(
  y,
  dat,
  method = "edf",
  w = NULL,
  bw = NULL,
  num_int = FALSE,
  show_messages = TRUE
)

logs_sample(y, dat, bw = NULL, show_messages = FALSE)

dss_sample(y, dat, w = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_sample_univ_+3A_y">y</code></td>
<td>
<p>vector of realized values.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_+3A_dat">dat</code></td>
<td>
<p>vector or matrix (depending on <code>y</code>; see details)
of simulation draws from forecast distribution.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_+3A_method">method</code></td>
<td>
<p>string; approximation method. Options:
&quot;edf&quot; (empirical distribution function) and
&quot;kde&quot; (kernel density estimation).</p>
</td></tr>
<tr><td><code id="scores_sample_univ_+3A_w">w</code></td>
<td>
<p>optional; vector or matrix (matching <code>dat</code>) of weights for method <code>"edf"</code>.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_+3A_bw">bw</code></td>
<td>
<p>optional; vector (matching <code>y</code>) of bandwidths for kernel density
estimation; see details.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_+3A_num_int">num_int</code></td>
<td>
<p>logical; if TRUE numerical integration is used for method <code>"kde"</code>.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_+3A_show_messages">show_messages</code></td>
<td>
<p>logical; display of messages (does not affect
warnings and errors).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a vector <code>y</code> of length n, <code>dat</code> should be given as a matrix
with n rows. If <code>y</code> has length 1, then <code>dat</code> may be a vector.
</p>
<p><code><a href="#topic+crps_sample">crps_sample</a></code> employs an empirical version of the quantile
decomposition of the CRPS (Laio and Tamea, 2007) when using
<code>method = "edf"</code>. For <code>method = "kde"</code>, it uses kernel density
estimation using a Gaussian kernel. The logarithmic score always uses kernel density estimation.
</p>
<p>The bandwidth (<code>bw</code>) for kernel density estimation can be
specified manually, in which case it must be a positive number. If
<code>bw == NULL</code>, the bandwidth is selected using the core function
<code><a href="stats.html#topic+bw.nrd">bw.nrd</a></code>. Numerical integration may speed up computation for
<code><a href="#topic+crps_sample">crps_sample</a></code> in case of large samples <code>dat</code>.
</p>


<h3>Value</h3>

<p>Value of the score. <em>A lower score indicates a better forecast.</em>
</p>


<h3>Author(s)</h3>

<p>Alexander Jordan, Fabian Krueger, Sebastian Lerch
</p>


<h3>References</h3>

<p><em>Evaluating simulation based forecast distributions:</em>
</p>
<p>Krueger, F., Lerch, S., Thorarinsdottir, T.L. and T. Gneiting (2021): &lsquo;Predictive inference based on Markov chain Monte Carlo output&rsquo;, <em>International Statistical Review</em> 89, 274-301. <a href="https://doi.org/10.1111/insr.12405">doi:10.1111/insr.12405</a>
</p>
<p><em>Empirical quantile decomposition of the CRPS:</em>
</p>
<p>Laio, F. and S. Tamea (2007):
'Verification tools for probabilistic forecasts of continuous
hydrological variables',
Hydrology and Earth System Sciences, 11, 1267-1277. <a href="https://doi.org/10.5194/hess-11-1267-2007">doi:10.5194/hess-11-1267-2007</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+scores_sample_univ_weighted">scores_sample_univ_weighted</a></code> for weighted versions of the scoring rules documented here.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# y has length greater than 1
y &lt;- 1:2
sample &lt;- matrix(rnorm(20), nrow = 2)
crps_sample(y = y, dat = sample)
logs_sample(y = y, dat = sample)

y &lt;- 1:2
sample &lt;- rnorm(10)
crps_sample(y = y, dat = sample) # error

# y has length 1
y &lt;- 1
sample &lt;- rnorm(10)
crps_sample(y = y, dat = sample)

sample &lt;- matrix(rnorm(10), nrow = 1)
crps_sample(y = y, dat = sample)

sample &lt;- matrix(rnorm(20), nrow = 2)
crps_sample(y = y, dat = sample) # error

## End(Not run)

</code></pre>

<hr>
<h2 id='scores_sample_univ_weighted'>Weighted Scoring Rules for Simulated Forecast Distributions (experimental)</h2><span id='topic+scores_sample_univ_weighted'></span><span id='topic+twcrps_sample'></span><span id='topic+owcrps_sample'></span><span id='topic+clogs_sample'></span>

<h3>Description</h3>

<p>Calculate weighted scores given observations and draws from univariate predictive distributions.
The weighted scoring rules that are available are the threshold-weighted CRPS, outcome-weighted CRPS, 
and conditional and censored likelihood scores. Note that the functions 
documented here are a new experimental feature of the package, and feedback is highly welcome.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>twcrps_sample(
  y,
  dat,
  a = -Inf,
  b = Inf,
  chain_func = function(x) pmin(pmax(x, a), b),
  w = NULL,
  show_messages = TRUE
)

owcrps_sample(
  y,
  dat,
  a = -Inf,
  b = Inf,
  weight_func = function(x) as.numeric(x &gt; a &amp; x &lt; b),
  w = NULL,
  show_messages = TRUE
)

clogs_sample(
  y,
  dat,
  a = -Inf,
  b = Inf,
  bw = NULL,
  show_messages = FALSE,
  cens = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_sample_univ_weighted_+3A_y">y</code></td>
<td>
<p>vector of realized values.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_weighted_+3A_dat">dat</code></td>
<td>
<p>vector or matrix (depending on <code>y</code>; see details)
of simulation draws from forecast distribution.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_weighted_+3A_a">a</code></td>
<td>
<p>numeric lower bound for the indicator weight function <code>w(z) = 1{a &lt; z &lt; b}</code>.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_weighted_+3A_b">b</code></td>
<td>
<p>numeric upper bound for the indicator weight function <code>w(z) = 1{a &lt; z &lt; b}</code>.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_weighted_+3A_chain_func">chain_func</code></td>
<td>
<p>function used to target particular outcomes in the threshold-weighted CRPS; 
the default corresponds to the weight function <code>w(z) = 1{a &lt; z &lt; b}</code>.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_weighted_+3A_w">w</code></td>
<td>
<p>optional; vector or matrix (matching <code>dat</code>) of ensemble weights. 
Note that these weights are not used in the weighted scoring rules; see details.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_weighted_+3A_show_messages">show_messages</code></td>
<td>
<p>logical; display of messages (does not affect
warnings and errors).</p>
</td></tr>
<tr><td><code id="scores_sample_univ_weighted_+3A_weight_func">weight_func</code></td>
<td>
<p>function used to target particular outcomes in the outcome-weighted CRPS; 
the default corresponds to the weight function <code>w(z) = 1{a &lt; z &lt; b}</code>.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_weighted_+3A_bw">bw</code></td>
<td>
<p>optional; vector (matching <code>y</code>) of bandwidths for kernel density
estimation for <code><a href="#topic+clogs_sample">clogs_sample</a></code>; see details.</p>
</td></tr>
<tr><td><code id="scores_sample_univ_weighted_+3A_cens">cens</code></td>
<td>
<p>logical; if TRUE, <code><a href="#topic+clogs_sample">clogs_sample</a></code> returns the censored
likelihood score; if FALSE, <code><a href="#topic+clogs_sample">clogs_sample</a></code> returns the conditional
likelihood score.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For a vector <code>y</code> of length n, <code>dat</code> should be given as a matrix
with n rows. If <code>y</code> has length 1, then <code>dat</code> may be a vector.
</p>
<p><code><a href="#topic+twcrps_sample">twcrps_sample</a></code> transforms <code>y</code> and <code>dat</code> using the chaining
function <code>chain_func</code> and then calls <code><a href="#topic+crps_sample">crps_sample</a></code>. 
<code><a href="#topic+owcrps_sample">owcrps_sample</a></code> weights <code>y</code> and <code>dat</code> using the weight function
<code>weight_func</code> and then calls <code><a href="#topic+crps_sample">crps_sample</a></code>. 
See the documentation for <code><a href="#topic+crps_sample">crps_sample</a></code> for further details.
</p>
<p>The default weight function used in the weighted scores is <code>w(z) = 1{a &lt; z &lt; b}</code>, 
which is equal to one if <code>z</code> is between <code>a</code> and <code>b</code>, and zero otherwise.
This weight function emphasises outcomes between <code>a</code> and <code>b</code>, and is 
commonly used in practical applications when interest is on values above a threshold
(set <code>b = Inf</code> and <code>a</code> equal to the threshold) or below a threshold 
(set <code>a = -Inf</code> and <code>b</code> equal to the threshold). 
</p>
<p>Alternative weight functions can also be employed using the <code>chain_func</code> 
and <code>weight_func</code> arguments to <code><a href="#topic+twcrps_sample">twcrps_sample</a></code> and <code><a href="#topic+owcrps_sample">owcrps_sample</a></code>,
respectively. Computation of the threshold-weighted CRPS for samples from a predictive distribution 
requires a chaining function rather than a weight function. This is why a chaining 
function is an input for <code><a href="#topic+twcrps_sample">twcrps_sample</a></code> whereas a weight function is an 
input for <code><a href="#topic+owcrps_sample">owcrps_sample</a></code>. Since <code><a href="#topic+clogs_sample">clogs_sample</a></code> requires 
kernel density estimation to approximate the forecast density, it cannot readily
be calculated for arbitrary weight functions, and is thus only available for 
the canonical weight function <code>w(z) = 1{a &lt; z &lt; b}</code>.
</p>
<p>The <code>chain_func</code> and <code>weight_func</code> arguments are functions that will 
be applied to the vector <code>y</code> and the columns of <code>dat</code>. It is assumed
that these functions are vectorised. Both functions must take a vector as an input
and output a vector of the same length, containing the weight (for <code>weight_func</code>) 
or transformed value (for <code>chain_func</code>) corresponding to each element in the 
input vector. An error will be returned if <code>weight_func</code> returns
negative values, and a warning message will appear if <code>chain_func</code> is 
not increasing. 
</p>
<p>If no custom argument is given for <code>a</code>, <code>b</code>, <code>chain_func</code> or 
<code>weight_func</code>, then both <code><a href="#topic+twcrps_sample">twcrps_sample</a></code> and <code><a href="#topic+owcrps_sample">owcrps_sample</a></code> 
are equivalent to the standard unweighted <code><a href="#topic+crps_sample">crps_sample</a></code>, and 
<code><a href="#topic+clogs_sample">clogs_sample</a></code> is equivalent to <code><a href="#topic+logs_sample">logs_sample</a></code>. 
</p>
<p>The <code>w</code> argument is also present in the unweighted scores (e.g. <code><a href="#topic+crps_sample">crps_sample</a></code>).
<code>w</code> is used to weight the draws from the predictive distribution, and does 
not weight particular outcomes within the weighted scoring rules. This should not be
confused with the <code>weight_func</code> argument, which is used within the weighted scores.
</p>


<h3>Value</h3>

<p>Value of the score. <em>A lower score indicates a better forecast.</em>
</p>


<h3>Author(s)</h3>

<p>Sam Allen
</p>


<h3>References</h3>

<p><em>Threshold-weighted CRPS:</em>
</p>
<p>Gneiting, T. and R. Ranjan (2011): 
&lsquo;Comparing density forecasts using threshold-and quantile-weighted scoring rules&rsquo;, 
<em>Journal of Business &amp; Economic Statistics</em> 29, 411-422. 
<a href="https://doi.org/10.1198/jbes.2010.08110">doi:10.1198/jbes.2010.08110</a>
</p>
<p>Allen, S., Ginsbourger, D. and J. Ziegel (2022): 
&lsquo;Evaluating forecasts for high-impact events using transformed kernel scores&rsquo;, 
<em>arXiv preprint</em> arXiv:2202.12732.
<a href="https://doi.org/10.48550/arXiv.2202.12732">doi:10.48550/arXiv.2202.12732</a>
</p>
<p><em>Outcome-weighted CRPS:</em>
</p>
<p>Holzmann, H. and B. Klar (2017):
&lsquo;Focusing on regions of interest in forecast evaluation&rsquo;,
<em>Annals of Applied Statistics</em> 11, 2404-2431. 
<a href="https://doi.org/10.1214/17-AOAS1088">doi:10.1214/17-AOAS1088</a>
</p>
<p><em>Conditional and censored likelihood scores:</em>
</p>
<p>Diks, C., Panchenko, V. and D. Van Dijk (2011):
&lsquo;Likelihood-based scoring rules for comparing density forecasts in tails&rsquo;,
<em>Journal of Econometrics</em> 163, 215-230.
<a href="https://doi.org/10.1016/j.jeconom.2011.04.001">doi:10.1016/j.jeconom.2011.04.001</a>
</p>


<h3>See Also</h3>

<p><a href="#topic+scores_sample_univ">scores_sample_univ</a> for standard (un-weighted) scores based on simulated forecast distributions. <a href="#topic+scores_sample_multiv_weighted">scores_sample_multiv_weighted</a> for weighted scores based on simulated multivariate forecast distributions.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

y &lt;- rnorm(10)
sample_fc &lt;- matrix(rnorm(100), nrow = 10)

crps_sample(y = y, dat = sample_fc)
twcrps_sample(y = y, dat = sample_fc)
owcrps_sample(y = y, dat = sample_fc)

logs_sample(y = y, dat = sample_fc)
clogs_sample(y = y, dat = sample_fc)
clogs_sample(y = y, dat = sample_fc, cens = FALSE)

# emphasise outcomes above 0
twcrps_sample(y = y, dat = sample_fc, a = 0)
owcrps_sample(y = y, dat = sample_fc, a = 0)
clogs_sample(y = y, dat = sample_fc, a = 0)
clogs_sample(y = y, dat = sample_fc, a = 0, cens = FALSE)

# emphasise outcomes below 0
twcrps_sample(y = y, dat = sample_fc, b = 0)
owcrps_sample(y = y, dat = sample_fc, b = 0)
clogs_sample(y = y, dat = sample_fc, b = 0) 

# emphasise outcomes between -1 and 1
twcrps_sample(y = y, dat = sample_fc, a = -1, b = 1)
owcrps_sample(y = y, dat = sample_fc, a = -1, b = 1)
clogs_sample(y = y, dat = sample_fc, a = -1, b = 1)


# a must be smaller than b 
twcrps_sample(y = y, dat = sample_fc, a = 1, b = -1) # error
owcrps_sample(y = y, dat = sample_fc, a = 0, b = 0) # error
clogs_sample(y = y, dat = sample_fc, a = 10, b = 9) # error

# a and b must be single numeric values (not vectors)
twcrps_sample(y = y, dat = sample_fc, a = rnorm(10)) # error


# the owCRPS is not well-defined if none of dat are between a and b
y &lt;- rnorm(10)
sample_fc &lt;- matrix(runif(100, -5, 1), nrow = 10)
owcrps_sample(y = y, dat = sample_fc, a = 1)
# the twCRPS is zero if none of y and dat are between a and b
twcrps_sample(y = y, dat = sample_fc, a = 1) 


# alternative custom weight and chaining functions can also be used

# Example 1: a Gaussian weight function with location mu and scale sigma
mu &lt;- 0
sigma &lt;- 0.5
weight_func &lt;- function(x) pnorm(x, mu, sigma)
# a corresponding chaining function is
chain_func &lt;- function(x) (x - mu)*pnorm(x, mu, sigma) + (sigma^2)*dnorm(x, mu, sigma)

x &lt;- seq(-2, 2, 0.01)
plot(x, weight_func(x), type = "l") # positive outcomes are given higher weight
plot(x, chain_func(x), type = "l") 

owcrps_sample(y = y, dat = sample_fc, a = mu)
owcrps_sample(y = y, dat = sample_fc, weight_func = weight_func)
twcrps_sample(y = y, dat = sample_fc, a = mu)
twcrps_sample(y = y, dat = sample_fc, chain_func = chain_func)


# Example 2: a sigmoid (or logistic) weight function with location mu and scale sigma
weight_func &lt;- function(x) plogis(x, mu, sigma)
chain_func &lt;- function(x) sigma*log(exp((x - mu)/sigma) + 1)

x &lt;- seq(-2, 2, 0.01)
plot(x, weight_func(x), type = "l") # positive outcomes are given higher weight
plot(x, chain_func(x), type = "l") 

owcrps_sample(y = y, dat = sample_fc, a = mu)
owcrps_sample(y = y, dat = sample_fc, weight_func = weight_func)
twcrps_sample(y = y, dat = sample_fc, a = mu)
twcrps_sample(y = y, dat = sample_fc, chain_func = chain_func)


# Example 3: the weight function w(z) = 1{z &lt; a or z &gt; b}
a &lt;- -1
b &lt;- 1
weight_func &lt;- function(x) as.numeric(x &lt; a | x &gt; b)
chain_func &lt;- function(x) (x &lt; a)*(x - a) + (x &gt; b)*(x - b) + a

x &lt;- seq(-2, 2, 0.01)
plot(x, weight_func(x), type = "l")
plot(x, chain_func(x), type = "l")

owcrps_sample(y = y, dat = sample_fc, weight_func = weight_func)
twcrps_sample(y = y, dat = sample_fc, chain_func = chain_func)
twcrps_sample(y = y, dat = sample_fc, b = -1) + twcrps_sample(y = y, dat = sample_fc, a = 1)
crps_sample(y = y, dat = sample_fc) - twcrps_sample(y = y, dat = sample_fc, a = -1, b = 1)

## End(Not run)

</code></pre>

<hr>
<h2 id='scores_t'>Calculating scores for Student's <code class="reqn">t</code>-distribution</h2><span id='topic+scores_t'></span><span id='topic+crps_t'></span><span id='topic+crps_ct'></span><span id='topic+crps_tt'></span><span id='topic+crps_gtct'></span><span id='topic+logs_t'></span><span id='topic+logs_tt'></span><span id='topic+dss_t'></span><span id='topic+gradcrps_t'></span><span id='topic+gradcrps_ct'></span><span id='topic+gradcrps_tt'></span><span id='topic+hesscrps_t'></span><span id='topic+hesscrps_ct'></span><span id='topic+hesscrps_tt'></span>

<h3>Description</h3>

<p>These functions calculate scores (CRPS, logarithmic score) and their gradient and Hessian with respect
to the parameters of a location-scale transformed Student's
<code class="reqn">t</code>-distribution. Furthermore, the censoring transformation and
the truncation transformation may be introduced on top of the
location-scale transformed normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## score functions
crps_t(y, df, location = 0, scale = 1)
crps_ct(y, df, location = 0, scale = 1, lower = -Inf, upper = Inf)
crps_tt(y, df, location = 0, scale = 1, lower = -Inf, upper = Inf)
crps_gtct(y, df, location = 0, scale = 1, lower = -Inf, upper = Inf, lmass = 0, umass = 0)
logs_t(y, df, location = 0, scale = 1)
logs_tt(y, df, location = 0, scale = 1, lower = -Inf, upper = Inf)
dss_t(y, df, location = 0, scale = 1)

## gradient (location, scale) functions
gradcrps_t(y, df, location = 0, scale = 1)
gradcrps_ct(y, df, location = 0, scale = 1, lower = -Inf, upper = Inf)
gradcrps_tt(y, df, location = 0, scale = 1, lower = -Inf, upper = Inf)

## Hessian (location, scale) functions
hesscrps_t(y, df, location = 0, scale = 1)
hesscrps_ct(y, df, location = 0, scale = 1, lower = -Inf, upper = Inf)
hesscrps_tt(y, df, location = 0, scale = 1, lower = -Inf, upper = Inf)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_t_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_t_+3A_df">df</code></td>
<td>
<p>vector of degrees of freedom.</p>
</td></tr>
<tr><td><code id="scores_t_+3A_location">location</code></td>
<td>
<p>vector of location parameters.</p>
</td></tr>
<tr><td><code id="scores_t_+3A_scale">scale</code></td>
<td>
<p>vector of scale paramters.</p>
</td></tr>
<tr><td><code id="scores_t_+3A_lower">lower</code>, <code id="scores_t_+3A_upper">upper</code></td>
<td>
<p>lower and upper truncation/censoring bounds.</p>
</td></tr>
<tr><td><code id="scores_t_+3A_lmass">lmass</code>, <code id="scores_t_+3A_umass">umass</code></td>
<td>
<p>vectors of point masses in <code>lower</code> and <code>upper</code>
respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>For the CRPS functions: a vector of score values.
</p>
<p>For the gradient and Hessian functions: a matrix with column names
corresponding to the respective partial derivatives.
</p>

<hr>
<h2 id='scores_unif'>Calculating scores for the uniform distribution</h2><span id='topic+scores_unif'></span><span id='topic+crps_unif'></span><span id='topic+logs_unif'></span><span id='topic+dss_unif'></span>

<h3>Description</h3>

<p>Calculating scores for the uniform distribution
</p>


<h3>Usage</h3>

<pre><code class='language-R'>crps_unif(y, min = 0, max = 1, lmass = 0, umass = 0)

logs_unif(y, min = 0, max = 1)

dss_unif(y, min = 0, max = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="scores_unif_+3A_y">y</code></td>
<td>
<p>vector of observations.</p>
</td></tr>
<tr><td><code id="scores_unif_+3A_min">min</code>, <code id="scores_unif_+3A_max">max</code></td>
<td>
<p>lower and upper limits of the distribution. Must be finite.</p>
</td></tr>
<tr><td><code id="scores_unif_+3A_lmass">lmass</code>, <code id="scores_unif_+3A_umass">umass</code></td>
<td>
<p>vectors of point masses in <code>min</code> and <code>max</code>
respectively.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of score values.
</p>

<hr>
<h2 id='summary.casestudy'>Summary method for class casestudy</h2><span id='topic+summary.casestudy'></span>

<h3>Description</h3>

<p>Summary method for class casestudy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'casestudy'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.casestudy_+3A_object">object</code></td>
<td>
<p>Object of class casestudy, generated via <a href="#topic+run_casestudy">run_casestudy</a></p>
</td></tr>
<tr><td><code id="summary.casestudy_+3A_...">...</code></td>
<td>
<p>Additional specifications (presently not in use)</p>
</td></tr>
</table>

<hr>
<h2 id='summary.mcstudy'>Simple summary method for class mcstudy</h2><span id='topic+summary.mcstudy'></span>

<h3>Description</h3>

<p>Simple summary method for class mcstudy
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mcstudy'
summary(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="summary.mcstudy_+3A_object">object</code></td>
<td>
<p>Object of class mcstudy, generated via <a href="#topic+run_mcstudy">run_mcstudy</a></p>
</td></tr>
<tr><td><code id="summary.mcstudy_+3A_...">...</code></td>
<td>
<p>Additional specifications (presently not in use)</p>
</td></tr>
</table>

<hr>
<h2 id='Supplementary+20distributions+3A+20Positive+20real+20line'>
Supplementary distributions (not in base R) supported on the positive real line.
</h2><span id='topic+fllapl'></span><span id='topic+fllogis'></span>

<h3>Description</h3>

<p>We include the probability density functions of some distributions which are part of scoringRules, but are not part of base R. The parametrizations used here are identical to the ones used when calling <code>crps</code> and <code>logs</code>.
</p>
<p>Here we document distributions on the positive real line: <code>fllapl</code> - log-Laplace distribution; <code>fllogis</code> - log-logistic distribution.</p>


<h3>Usage</h3>

<pre><code class='language-R'>fllapl(x, locationlog, scalelog)
fllogis(x, locationlog, scalelog)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Positive+2B20real+2B20line_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Positive+2B20real+2B20line_+3A_locationlog">locationlog</code></td>
<td>
<p>vector of location parameters on the log scale</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Positive+2B20real+2B20line_+3A_scalelog">scalelog</code></td>
<td>
<p>vector of scale parameters on the log scale</p>
</td></tr>
</table>


<h3>Details</h3>

<p>To be added.
</p>


<h3>Value</h3>

<p>Probability density function of the relevant distribution, evaluated at <code>x</code>.</p>


<h3>Author(s)</h3>

<p>Alexander Jordan</p>


<h3>See Also</h3>

<p>The documentation for <a href="#topic+crps.numeric">crps.numeric</a> contains the full list of distributions supported by scoringRules (includes the ones documented here, as well as many others).</p>

<hr>
<h2 id='Supplementary+20distributions+3A+20Real+20line'>Supplementary distributions (not in base R) supported on the real line.</h2><span id='topic+flapl'></span><span id='topic+f2pexp'></span><span id='topic+fmixnorm'></span><span id='topic+f2pnorm'></span>

<h3>Description</h3>

<p>We include the probability density functions of some distributions which are part of scoringRules, but are not part of base R. The parametrizations used here are identical to the ones used when calling <code>crps</code> and <code>logs</code>.
</p>
<p>Here we document distributions with support on the real line: <code>flapl</code> - Laplace distribution; <code>f2pexp</code> - two-piece exponential distribution; <code>fmixnorm</code> - mixture of normal distributions; <code>f2pnorm</code> - two-piece normal distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>flapl(x, location, scale)

f2pexp(x, location, scale1, scale2)
f2pnorm(x, location, scale1, scale2)

fmixnorm(x, m, s, w)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Real+2B20line_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Real+2B20line_+3A_location">location</code></td>
<td>
<p>vector of location parameters</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Real+2B20line_+3A_scale">scale</code>, <code id="Supplementary+2B20distributions+2B3A+2B20Real+2B20line_+3A_scale1">scale1</code>, <code id="Supplementary+2B20distributions+2B3A+2B20Real+2B20line_+3A_scale2">scale2</code></td>
<td>
<p>vector of scale parameters</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Real+2B20line_+3A_m">m</code></td>
<td>
<p>matrix of means (rows correspond to observations, columns correspond to mixture components)</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Real+2B20line_+3A_s">s</code></td>
<td>
<p>matrix of standard deviations (same structure as <code>m</code>)</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Real+2B20line_+3A_w">w</code></td>
<td>
<p>matrix of weights (same structure as <code>m</code>)</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The Laplace distribution (<code>flapl</code>) is described on <a href="https://en.wikipedia.org/wiki/Laplace_distribution">https://en.wikipedia.org/wiki/Laplace_distribution</a>. It is a special case of the two-piece exponential distribution (<code>f2pexp</code>), which allows for different scale parameters to the left and right of <code>location</code>.
</p>
<p>The density function of a mixture of normal distributions (<code>fmixnorm</code>) is given by the weighted sum over the mixture components, </p>
<p style="text-align: center;"><code class="reqn">f(x) = \sum w_i/s_i \phi((x - m_i)/s_i),</code>
</p>
<p> where <code class="reqn">\phi</code> is the pdf of the standard normal distribution.
</p>
<p>For details on the two-piece normal distribution (<code>f2pnorm</code>), see Box A of Wallis (2004, &quot;An Assessment of Bank of England and National Institute Inflation Forecast Uncertainties&quot;, National Institute Economic Review).
</p>


<h3>Value</h3>

<p>Probability density function of the relevant distribution, evaluated at <code>x</code>.</p>


<h3>Author(s)</h3>

<p>Alexander Jordan</p>


<h3>See Also</h3>

<p>The documentation for <a href="#topic+crps.numeric">crps.numeric</a> contains the full list of distributions supported by scoringRules (includes the ones documented here, as well as many others).
</p>
<p><a href="#topic+fnorm">fnorm</a>, <a href="#topic+flogis">flogis</a>, <a href="#topic+ft">ft</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Plot PDF of Laplace distribution
ff &lt;- function(x) flapl(x, location = 0, scale = 2)
curve(ff, from = -8, to = 8, bty = "n", xlab = "Value", 
      ylab = "PDF", 
      main = "Laplace distribution with location 0 and scale 2")
</code></pre>

<hr>
<h2 id='Supplementary+20distributions+3A+20Variable+20support'>
Supplementary distributions (not in base R) with variable support.
</h2><span id='topic+fexp'></span><span id='topic+fgev'></span><span id='topic+fgpd'></span><span id='topic+fnorm'></span><span id='topic+ft'></span><span id='topic+flogis'></span>

<h3>Description</h3>

<p>We include the probability density functions of some distributions which are part of scoringRules, but are not part of base R. The parametrizations used here are identical to the ones used when calling <code>crps</code> and <code>logs</code>.
</p>
<p>Here we document distributions with variable support: <code>fexp</code> - location-scale exponential distribution with a point mass on the lower boundary; <code>fgdp</code> - generalized Pareto distribution with a point mass on the lower boundary; <code>fgev</code> - generalized extreme value distribution; <code>fnorm</code>, <code>flogis</code>, <code>ft</code> - (normal/logistic/Student's t)-distribution with flexible domain and point masses on the boundaries.</p>


<h3>Usage</h3>

<pre><code class='language-R'>fexp(x, location, scale, mass = 0, log = FALSE)
fgpd(x, location, scale, shape, mass = 0, log = FALSE)

fgev(x, location, scale, shape)

fnorm(x, location, scale, lower = -Inf, upper = Inf, lmass = 0, umass = 0, log = FALSE)
ft(x, df, location, scale, lower = -Inf, upper = Inf, lmass = 0, umass = 0, log = FALSE)
flogis(x, location, scale, lower = -Inf, upper = Inf, lmass = 0, umass = 0, log = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_x">x</code></td>
<td>
<p>vector of quantiles</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_df">df</code></td>
<td>
<p>vector of degrees of freedom parameters</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_location">location</code></td>
<td>
<p>vector of location parameters</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_scale">scale</code></td>
<td>
<p>vector of scale parameters (positive)</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_shape">shape</code></td>
<td>
<p>vector of shape parameters</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_mass">mass</code></td>
<td>
<p>vector of point masses in <code>location</code></p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_lower">lower</code></td>
<td>
<p>vector of lower bounds</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_upper">upper</code></td>
<td>
<p>vector of upper bounds</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_lmass">lmass</code></td>
<td>
<p>vector of point masses in <code>lower</code>, or strings &quot;trunc&quot; / &quot;cens&quot;</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_umass">umass</code></td>
<td>
<p>vector of point masses in <code>upper</code>, or strings &quot;trunc&quot; / &quot;cens&quot;</p>
</td></tr>
<tr><td><code id="Supplementary+2B20distributions+2B3A+2B20Variable+2B20support_+3A_log">log</code></td>
<td>
<p>logical; if <code>TRUE</code>, the log of the density is returned</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For details on generalized extreme value and generalized Pareto distributions, see Friederichs, F. and T.L. Thorarinsdottir (2012, &quot;Forecast verification for extreme value distributions with an application to probabilistic peak wind prediction&quot;, Environmetrics 23, 579-594). Note that the support of both distributions depends on the input parameters; see <a href="https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution">https://en.wikipedia.org/wiki/Generalized_extreme_value_distribution</a> and <a href="https://en.wikipedia.org/wiki/Generalized_Pareto_distribution">https://en.wikipedia.org/wiki/Generalized_Pareto_distribution</a>.
</p>
<p>Sometimes truncated or censored versions of the normal distribution are used to model variables with a restricted domain (e.g. precipitation). We allow the flexible specification of lower and upper boundaries and point masses in those boundaries. The truncated normal distribution assumes no point masses (i.e. redistributes the cut-off) and can be specified using the string &quot;trunc&quot; instead of a numerical probability. In contrast, the censored distribution introduces a point mass at the bound in the amount of the cut-off. Here, the string &quot;cens&quot; may be used for <code>lmass</code> or <code>umass</code>. The most common use in practice lies in the context of non-negative quantities. For example, a truncated standard normal distribution (left truncation at zero) has pdf <code class="reqn">f(x) = \phi(x)/(1 - \Phi(0)),</code> for <code class="reqn">x \ge 0</code> and 0 otherwise. A censored standard normal distribution (left censoring at zero) has point mass <code class="reqn">\Phi(0)</code> at zero, and density <code class="reqn">\phi(x)</code> for <code class="reqn">x &gt; 0</code>. 
</p>
<p>The location-scale family based on Student's t-distribution (<code>ft</code>) has mean <code class="reqn">location</code> for <code class="reqn">df &gt; 1</code> and variance <code class="reqn">df/(df-2) * scale^2</code> for <code class="reqn">df &gt; 2</code>. Note that the <a href="#topic+crps">crps</a> exists only for <code class="reqn">df &gt; 1</code>. For details, see <a href="https://en.wikipedia.org/wiki/Student's_t-distribution#Non-standardized_Student.27s_t-distribution">https://en.wikipedia.org/wiki/Student's_t-distribution#Non-standardized_Student.27s_t-distribution</a>.
</p>


<h3>Value</h3>

<p>Density function of the relevant distribution, evaluated at <code>x</code>. NOTE: For distributions involving a point mass (e.g., when <code>lmass = "cens"</code> in <code>fnorm</code>), the density functions do not integrate to one.</p>


<h3>Author(s)</h3>

<p>Alexander Jordan</p>


<h3>See Also</h3>

<p>The documentation for <a href="#topic+crps.numeric">crps.numeric</a> contains the full list of distributions supported by scoringRules (includes the ones documented here, as well as many others).</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
