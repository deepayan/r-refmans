<!DOCTYPE html><html><head><title>Help for package blockForest</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {blockForest}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#blockfor'><p>Random Forest variants for block-structured covariate data</p></a></li>
<li><a href='#blockForest'><p>blockForest</p></a></li>
<li><a href='#predict.blockForest'><p>Prediction using Random Forest variants for block-structured covariate data</p></a></li>
<li><a href='#predictions.blockForest'><p>blockForest predictions</p></a></li>
<li><a href='#predictions.blockForest.prediction'><p>blockForest predictions</p></a></li>
<li><a href='#timepoints.blockForest'><p>blockForest timepoints</p></a></li>
<li><a href='#timepoints.blockForest.prediction'><p>blockForest timepoints</p></a></li>
<li><a href='#treeInfo'><p>Tree information in human readable format</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Block Forests: Random Forests for Blocks of Clinical and Omics
Covariate Data</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.6</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-03-03</td>
</tr>
<tr>
<td>Author:</td>
<td>Roman Hornung, Marvin N. Wright</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Marvin N. Wright &lt;cran@wrig.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>A random forest variant 'block forest' ('BlockForest') tailored to the 
  prediction of binary, survival and continuous outcomes using block-structured 
  covariate data, for example, clinical covariates plus measurements of a certain 
  omics data type or multi-omics data, that is, data for which measurements of 
  different types of omics data and/or clinical data for each patient exist. Examples 
  of different omics data types include gene expression measurements, mutation data
  and copy number variation measurements.
  Block forest are presented in Hornung &amp; Wright (2019). The package includes four
  other random forest variants for multi-omics data: 'RandomBlock', 'BlockVarSel', 
  'VarProb', and 'SplitWeights'. These were also considered in Hornung &amp; Wright (2019), 
  but performed worse than block forest in their comparison study based on 20 real 
  multi-omics data sets. Therefore, we recommend to use block forest ('BlockForest') 
  in applications. The other random forest variants can, however, be consulted for 
  academic purposes, for example, in the context of further methodological 
  developments. 
  Reference: Hornung, R. &amp; Wright, M. N. (2019) Block Forests: random forests for blocks of clinical and omics covariate data. BMC Bioinformatics 20:358. &lt;<a href="https://doi.org/10.1186%2Fs12859-019-2942-y">doi:10.1186/s12859-019-2942-y</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 0.11.2), Matrix, methods, survival</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppEigen</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.1)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.2.2</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/bips-hb/blockForest">https://github.com/bips-hb/blockForest</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/bips-hb/blockForest/issues">https://github.com/bips-hb/blockForest/issues</a></td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-03-31 05:58:13 UTC; wright</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-03-31 18:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='blockfor'>Random Forest variants for block-structured covariate data</h2><span id='topic+blockfor'></span>

<h3>Description</h3>

<p>Implements five Random Forest variants for prediction
of binary, survival and metric outcomes using block-structured covariate
data, for example, clinical covariates plus measurements of a certain omics data type
or multi-omics data, that is, data for which measurements of different types of omics data
and/or clinical data for each patient exist. For example, for the task of predicting
survival for each patient there might be available
clinical covariates, gene expression measurements, mutation data,
and copy number variation measurements. <br />
The group of covariates corresponding to one specific data type is denoted as a 'block'. <br />
NOTE: We strongly recommend using the variant &quot;BlockForest&quot; (or &quot;block forest&quot;)
in applications. The other four variants performed worse than &quot;BlockForest&quot;
in the analysis by Hornung &amp; Wright (2019). Using 20 real multi-omics data sets Hornung &amp; Wright (2019) compared all
five variants with each other and with alternatives, in particular with Random Survival Forest as existing
reference method. The ranking of the performances of the five variants was as follows
in the comparison study by Hornung &amp; Wright (2019): 1) &quot;BlockForest&quot;, 2) &quot;RandomBlock&quot;,
3) &quot;BlockVarSel&quot;, 4) &quot;VarProb&quot;, 5) &quot;SplitWeights&quot;. <br />
Each of the five variants uses a different split selection algorithm.
For details, see Hornung &amp; Wright (2019). <br />
Note that this R package is a fork of the R package ranger. <br />
NOTE ALSO: Including the clinical block mandatorily in the split point selection can considerably improve the prediction performance.
Whether or not this is the case, depends on the level of predictive information contained in the clinical block.
We recommend trying out including the clinical block mandatorily to see, whether this improves prediction
performance in the particular application. Note that in the case of including the clinical block mandatorily
and having more than only one omics block, &quot;RandomBlock&quot; performed (slightly) better than &quot;BlockForest&quot; in the comparison study by Hornung &amp; Wright (2019). 
Including the clinical block mandatorily can be performed by setting the function argument 'always.select.block'
of 'blockfor()' to the index of the clinical block (e.g., if the clinical block would be the second block in order, we would 
set always.select.block=2).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockfor(
  X,
  y,
  blocks,
  block.method = "BlockForest",
  num.trees = 2000,
  mtry = NULL,
  nsets = 300,
  num.trees.pre = 1500,
  splitrule = "extratrees",
  always.select.block = 0,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blockfor_+3A_x">X</code></td>
<td>
<p>Covariate matrix. observations in rows, variables in columns.</p>
</td></tr>
<tr><td><code id="blockfor_+3A_y">y</code></td>
<td>
<p>Target variable. If the outcome is binary, this is a factor with
two levels. If the outcome is metric, this is a numeric vector. If the outcome
is a survival outcome, this is a matrix with two columns, where the first column
contains the vector of survival/censoring times (one for each observation) and the second column contains
the status variable, that has the value '1' if the corresponding time is
a survival time and '0' if that time is a censoring time.</p>
</td></tr>
<tr><td><code id="blockfor_+3A_blocks">blocks</code></td>
<td>
<p>A list of length equal to the number M of blocks considered. Each
entry contains the vector of column indices in 'X' of the covariates in one of the M blocks.</p>
</td></tr>
<tr><td><code id="blockfor_+3A_block.method">block.method</code></td>
<td>
<p>Forest variant to use. One of the following: &quot;BlockForest&quot; (default), &quot;RandomBlock&quot;, &quot;BlockVarSel&quot;, &quot;VarProb&quot;, &quot;SplitWeights&quot;.
The latter listing is ordered according to the performances of these variants in the comparison study by Hornung &amp; Wright (2019),
with the best variant being listed first.</p>
</td></tr>
<tr><td><code id="blockfor_+3A_num.trees">num.trees</code></td>
<td>
<p>Number of trees in the forest.</p>
</td></tr>
<tr><td><code id="blockfor_+3A_mtry">mtry</code></td>
<td>
<p>This is either a number specifying the number of variables sampled for each
split from all variables (for variants &quot;VarProb&quot; and &quot;SplitWeights&quot;)
or a vector of length equal to the number of blocks, where the m-th entry of the
vector gives the number of variables to sample from block m (for variants &quot;BlockForest&quot;, &quot;RandomBlock&quot;, and &quot;BlockVarSel&quot;).
The default values are sqrt(p_1) + sqrt(p_2) + ... sqrt(p_M) and (sqrt(p_1), sqrt(p_2), ..., sqrt(p_M)), respectively,
where p_m denotes the number of variables in the m-th block (m = 1, ..., M) and sqrt() denoted the square root function.</p>
</td></tr>
<tr><td><code id="blockfor_+3A_nsets">nsets</code></td>
<td>
<p>Number of sets of tuning parameter values generated randomly in the optimization of the tuning parameters.
Each variant has a tuning parameter for each block, that is, there are M tuning parameters for each variant.
These tuning parameters are optimized in the following way: 1. Generate random sets of tuning parameter values
and measure there adequateness: For j = 1,..., nsets: a) Generate a random set of tuning parameter values;
b) Construct a forest (with num.trees.pre trees) using the set of tuning parameter values generated in a);
c) Record the out-of-bag (OOB) estimated prediction error of the forest constructed in b); 2. Use the set of tuning 
parameter values generated in 1. that is associated with the smallest OOB estimated prediction error.</p>
</td></tr>
<tr><td><code id="blockfor_+3A_num.trees.pre">num.trees.pre</code></td>
<td>
<p>Number of trees in each forest constructed during the optimization of the tuning
parameter values, see 'nsets' for details.</p>
</td></tr>
<tr><td><code id="blockfor_+3A_splitrule">splitrule</code></td>
<td>
<p>Splitting rule. Default &quot;extratrees&quot; (for computational efficiency). For other options see <code><a href="#topic+blockForest">blockForest</a></code>.</p>
</td></tr>
<tr><td><code id="blockfor_+3A_always.select.block">always.select.block</code></td>
<td>
<p>Number of block to make always available for splitting (e.g. clinical covariates).</p>
</td></tr>
<tr><td><code id="blockfor_+3A_...">...</code></td>
<td>
<p>Parameters passed to <code>blockForest</code>, such as <code>num.threads</code>, etc. See <code><a href="#topic+blockForest">blockForest</a></code> for details.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>blockfor</code> returns a list containing the following components: 
</p>
<table>
<tr><td><code>forest</code></td>
<td>
<p> object of class <code>"blockForest"</code>. Constructed forest.  </p>
</td></tr>
<tr><td><code>paramvalues</code></td>
<td>
<p> vector of length M. Optimized tuning parameter value for each block. </p>
</td></tr>
<tr><td><code>biased_oob_error_donotuse</code></td>
<td>
<p> numeric. OOB estimated prediction error. NOTE: This estimate should not be used, because it is (highly) optimistic (i.e, too small), because the data set was used twice - for optimizing the tuning parameter values and for estimating the prediction error. Instead, cross-validation should be used to estimate the prediction error. </p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Roman Hornung, Marvin N. Wright
</p>


<h3>References</h3>


<ul>
<li><p> Hornung, R. &amp; Wright, M. N. (2019) Block Forests: random forests for blocks of clinical and omics covariate data. BMC Bioinformatics 20:358. <a href="https://doi.org/10.1186/s12859-019-2942-y">doi:10.1186/s12859-019-2942-y</a>.
</p>
</li>
<li><p> Breiman, L. (2001). Random forests. Mach Learn, 45(1), 5-32. <a href="https://doi.org/10.1023/A%3A1010933404324">doi:10.1023/A:1010933404324</a>. 
</p>
</li>
<li><p> Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17. <a href="https://doi.org/10.18637/jss.v077.i01">doi:10.18637/jss.v077.i01</a>.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'># NOTE: There is no association between covariates and response for the
# simulated data below.
# Moreover, the input parameters of blockfor() are highly unrealistic
# (e.g., nsets = 10 is specified much too small).
# The purpose of the shown examples is merely to illustrate the
# application of blockfor().


# Generate data:
################

set.seed(1234)

# Covariate matrix:
X &lt;- cbind(matrix(nrow=40, ncol=5, data=rnorm(40*5)), 
           matrix(nrow=40, ncol=30, data=rnorm(40*30, mean=1, sd=2)),
           matrix(nrow=40, ncol=100, data=rnorm(40*100, mean=2, sd=3)))

# Block variable (list):
blocks &lt;- rep(1:3, times=c(5, 30, 100))
blocks &lt;- lapply(1:3, function(x) which(blocks==x))

# Binary outcome:
ybin &lt;- factor(sample(c(0,1), size=40, replace=TRUE), levels=c(0,1))

# Survival outcome:
ysurv &lt;- cbind(rnorm(40), sample(c(0,1), size=40, replace=TRUE))

# Application to binary outcome:
################################

blockforobj &lt;- blockfor(X, ybin, num.trees = 100, replace = TRUE, blocks=blocks,
                        nsets = 10, num.trees.pre = 50, splitrule="extratrees", 
                        block.method = "BlockForest")
# Tuning parameter estimates (see Hornung &amp; Wright (2019)):
blockforobj$paramvalues

# Application to survival outcome:
##################################

blockforobj &lt;- blockfor(X, ysurv, num.trees = 100, replace = TRUE, blocks=blocks,
                        nsets = 10, num.trees.pre = 50, splitrule="extratrees", 
                        block.method = "BlockForest")
blockforobj$paramvalues

</code></pre>

<hr>
<h2 id='blockForest'>blockForest</h2><span id='topic+blockForest'></span>

<h3>Description</h3>

<p>Block forests without parameter tuning. 
Use <code><a href="#topic+blockfor">blockfor</a></code> for standard interface.
This function is called by <code><a href="#topic+blockfor">blockfor</a></code>
and will rarely be considered directly by the user (since parameter tuning
is required in applications).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blockForest(
  formula = NULL,
  data = NULL,
  num.trees = 500,
  mtry = NULL,
  importance = "none",
  write.forest = TRUE,
  probability = FALSE,
  min.node.size = NULL,
  replace = TRUE,
  sample.fraction = ifelse(replace, 1, 0.632),
  case.weights = NULL,
  splitrule = NULL,
  num.random.splits = 1,
  alpha = 0.5,
  minprop = 0.1,
  split.select.weights = NULL,
  always.split.variables = NULL,
  blocks = NULL,
  block.method = "BlockForest",
  block.weights = NULL,
  respect.unordered.factors = NULL,
  scale.permutation.importance = FALSE,
  keep.inbag = FALSE,
  holdout = FALSE,
  quantreg = FALSE,
  num.threads = NULL,
  save.memory = FALSE,
  verbose = TRUE,
  seed = NULL,
  dependent.variable.name = NULL,
  status.variable.name = NULL,
  classification = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="blockForest_+3A_formula">formula</code></td>
<td>
<p>Object of class <code>formula</code> or <code>character</code> describing the model to fit. Interaction terms supported only for numerical variables.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_data">data</code></td>
<td>
<p>Training data of class <code>data.frame</code>, <code>matrix</code>, <code>dgCMatrix</code> (Matrix) or <code>gwaa.data</code> (GenABEL).</p>
</td></tr>
<tr><td><code id="blockForest_+3A_num.trees">num.trees</code></td>
<td>
<p>Number of trees.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_mtry">mtry</code></td>
<td>
<p>This is either a number specifying the number of variables sampled for each
split from all variables (for variants &quot;VarProb&quot; and &quot;SplitWeights&quot;)
or a vector of length equal to the number of blocks, where the m-th entry of the
vector gives the number of variables to sample from block m (for variants &quot;BlockForest&quot;, &quot;RandomBlock&quot;, and &quot;BlockVarSel&quot;).
The default values are sqrt(p_1) + sqrt(p_2) + ... sqrt(p_M) and (sqrt(p_1), sqrt(p_2), ..., sqrt(p_M)), respectively,
where p_m denotes the number of variables in the m-th block (m = 1, ..., M) and sqrt() denoted the square root function.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_importance">importance</code></td>
<td>
<p>Variable importance mode, one of 'none', 'impurity', 'impurity_corrected', 'permutation'. The 'impurity' measure is the Gini index for classification, the variance of the responses for regression and the sum of test statistics (see <code>splitrule</code>) for survival.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_write.forest">write.forest</code></td>
<td>
<p>Save <code>blockForest.forest</code> object, required for prediction. Set to <code>FALSE</code> to reduce memory usage if no prediction intended.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_probability">probability</code></td>
<td>
<p>Grow a probability forest as in Malley et al. (2012).</p>
</td></tr>
<tr><td><code id="blockForest_+3A_min.node.size">min.node.size</code></td>
<td>
<p>Minimal node size. Default 1 for classification, 5 for regression, 3 for survival, and 10 for probability.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_replace">replace</code></td>
<td>
<p>Sample with replacement.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_sample.fraction">sample.fraction</code></td>
<td>
<p>Fraction of observations to sample. Default is 1 for sampling with replacement and 0.632 for sampling without replacement. For classification, this can be a vector of class-specific values.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_case.weights">case.weights</code></td>
<td>
<p>Weights for sampling of training observations. Observations with larger weights will be selected with higher probability in the bootstrap (or subsampled) samples for the trees.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_splitrule">splitrule</code></td>
<td>
<p>Splitting rule, default &quot;extratrees&quot;. Other options are &quot;gini&quot; for classification and probability estimation, &quot;variance&quot;, or &quot;maxstat&quot; for regression and &quot;logrank&quot;, &quot;C&quot; or &quot;maxstat&quot; for survival.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_num.random.splits">num.random.splits</code></td>
<td>
<p>For &quot;extratrees&quot; splitrule.: Number of random splits to consider for each candidate splitting variable.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_alpha">alpha</code></td>
<td>
<p>For &quot;maxstat&quot; splitrule: Significance threshold to allow splitting.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_minprop">minprop</code></td>
<td>
<p>For &quot;maxstat&quot; splitrule: Lower quantile of covariate distribution to be considered for splitting.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_split.select.weights">split.select.weights</code></td>
<td>
<p>Numeric vector with weights between 0 and 1, representing the probability to select variables for splitting. Alternatively, a list of size num.trees, containing split select weight vectors for each tree can be used. Use this for the &quot;VarProb&quot; variant.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_always.split.variables">always.split.variables</code></td>
<td>
<p>Character vector with variable names to be always selected in addition to the <code>mtry</code> variables tried for splitting.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_blocks">blocks</code></td>
<td>
<p>Block memberships of the variables. See <code><a href="#topic+blockfor">blockfor</a></code> for details.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_block.method">block.method</code></td>
<td>
<p>Variant to use. Options are: &quot;BlockForest&quot; (default), &quot;RandomBlock&quot;, &quot;BlockVarSel&quot;, &quot;SplitWeights&quot;.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_block.weights">block.weights</code></td>
<td>
<p>Tuning parameter values for the blocks in the variants. A vector of length equal to the number of blocks or a list with vectors containing tree-wise values. For block.method='RandomBlock' these are the block sample probabilities.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_respect.unordered.factors">respect.unordered.factors</code></td>
<td>
<p>Handling of unordered factor covariates. One of 'ignore', 'order' and 'partition'. For the &quot;extratrees&quot; splitrule the default is &quot;partition&quot; for all other splitrules 'ignore'. Alternatively TRUE (='order') or FALSE (='ignore') can be used. See below for details.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_scale.permutation.importance">scale.permutation.importance</code></td>
<td>
<p>Scale permutation importance by standard error as in (Breiman 2001). Only applicable if permutation variable importance mode selected.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_keep.inbag">keep.inbag</code></td>
<td>
<p>Save how often observations are in-bag in each tree.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_holdout">holdout</code></td>
<td>
<p>Hold-out mode. Hold-out all samples with case weight 0 and use these for variable importance and prediction error.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_quantreg">quantreg</code></td>
<td>
<p>Prepare quantile prediction as in quantile regression forests (Meinshausen 2006). Regression only. Set <code>keep.inbag = TRUE</code> to prepare out-of-bag quantile prediction.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_num.threads">num.threads</code></td>
<td>
<p>Number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_save.memory">save.memory</code></td>
<td>
<p>Use memory saving (but slower) splitting mode. No effect for survival and GWAS data. Warning: This option slows down the tree growing, use only if you encounter memory problems.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_verbose">verbose</code></td>
<td>
<p>Show computation status and estimated runtime.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_seed">seed</code></td>
<td>
<p>Random seed. Default is <code>NULL</code>, which generates the seed from <code>R</code>. Set to <code>0</code> to ignore the <code>R</code> seed.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_dependent.variable.name">dependent.variable.name</code></td>
<td>
<p>Name of dependent variable, needed if no formula given. For survival forests this is the time variable.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_status.variable.name">status.variable.name</code></td>
<td>
<p>Name of status variable, only applicable to survival data and needed if no formula given. Use 1 for event and 0 for censoring.</p>
</td></tr>
<tr><td><code id="blockForest_+3A_classification">classification</code></td>
<td>
<p>Only needed if data is a matrix. Set to <code>TRUE</code> to grow a classification forest.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See <code><a href="#topic+blockfor">blockfor</a></code> and the <code>ranger</code> package.
</p>


<h3>Value</h3>

<p>Object of class <code>blockForest</code> with elements
</p>
<table>
<tr><td><code>forest</code></td>
<td>
<p>Saved forest (If write.forest set to TRUE). Note that the variable IDs in the <code>split.varIDs</code> object do not necessarily represent the column number in R.</p>
</td></tr>
<tr><td><code>predictions</code></td>
<td>
<p>Predicted classes/values, based on out of bag samples (classification and regression only).</p>
</td></tr>
<tr><td><code>variable.importance</code></td>
<td>
<p>Variable importance for each independent variable.</p>
</td></tr>
<tr><td><code>prediction.error</code></td>
<td>
<p>Overall out of bag prediction error. For classification this is the fraction of missclassified samples, for probability estimation and regression the mean squared error and for survival one minus Harrell's C-index.</p>
</td></tr>
<tr><td><code>r.squared</code></td>
<td>
<p>R squared. Also called explained variance or coefficient of determination (regression only). Computed on out of bag data.</p>
</td></tr>
<tr><td><code>confusion.matrix</code></td>
<td>
<p>Contingency table for classes and predictions based on out of bag samples (classification only).</p>
</td></tr>
<tr><td><code>unique.death.times</code></td>
<td>
<p>Unique death times (survival only).</p>
</td></tr>
<tr><td><code>chf</code></td>
<td>
<p>Estimated cumulative hazard function for each sample (survival only).</p>
</td></tr>
<tr><td><code>survival</code></td>
<td>
<p>Estimated survival function for each sample (survival only).</p>
</td></tr>
<tr><td><code>call</code></td>
<td>
<p>Function call.</p>
</td></tr>
<tr><td><code>num.trees</code></td>
<td>
<p>Number of trees.</p>
</td></tr>
<tr><td><code>num.independent.variables</code></td>
<td>
<p>Number of independent variables.</p>
</td></tr>
<tr><td><code>mtry</code></td>
<td>
<p>Value of mtry used.</p>
</td></tr>
<tr><td><code>min.node.size</code></td>
<td>
<p>Value of minimal node size used.</p>
</td></tr>
<tr><td><code>treetype</code></td>
<td>
<p>Type of forest/tree. classification, regression or survival.</p>
</td></tr>
<tr><td><code>importance.mode</code></td>
<td>
<p>Importance mode used.</p>
</td></tr>
<tr><td><code>num.samples</code></td>
<td>
<p>Number of samples.</p>
</td></tr>
<tr><td><code>inbag.counts</code></td>
<td>
<p>Number of times the observations are in-bag in the trees.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>


<ul>
<li><p> Hornung, R. &amp; Wright, M. N. (2019) Block Forests: random forests for blocks of clinical and omics covariate data. BMC Bioinformatics 20:358. <a href="https://doi.org/10.1186/s12859-019-2942-y">doi:10.1186/s12859-019-2942-y</a>.
</p>
</li>
<li><p> Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17. <a href="https://doi.org/10.18637/jss.v077.i01">doi:10.18637/jss.v077.i01</a>.
</p>
</li>
<li><p> Schmid, M., Wright, M. N. &amp; Ziegler, A. (2016). On the use of Harrell's C for clinical risk prediction via random survival forests. Expert Syst Appl 63:450-459. <a href="https://doi.org/10.1016/j.eswa.2016.07.018">doi:10.1016/j.eswa.2016.07.018</a>. 
</p>
</li>
<li><p> Wright, M. N., Dankowski, T. &amp; Ziegler, A. (2017). Unbiased split variable selection for random survival forests using maximally selected rank statistics. Stat Med. <a href="https://doi.org/10.1002/sim.7212">doi:10.1002/sim.7212</a>.
</p>
</li>
<li><p> Breiman, L. (2001). Random forests. Mach Learn, 45(1), 5-32. <a href="https://doi.org/10.1023/A%3A1010933404324">doi:10.1023/A:1010933404324</a>. 
</p>
</li>
<li><p> Ishwaran, H., Kogalur, U. B., Blackstone, E. H., &amp; Lauer, M. S. (2008). Random survival forests. Ann Appl Stat 2:841-860. <a href="https://doi.org/10.1097/JTO.0b013e318233d835">doi:10.1097/JTO.0b013e318233d835</a>. 
</p>
</li>
<li><p> Malley, J. D., Kruppa, J., Dasgupta, A., Malley, K. G., &amp; Ziegler, A. (2012). Probability machines: consistent probability estimation using nonparametric learning machines. Methods Inf Med 51:74-81. <a href="https://doi.org/10.3414/ME00-01-0052">doi:10.3414/ME00-01-0052</a>.
</p>
</li>
<li><p> Hastie, T., Tibshirani, R., Friedman, J. (2009). The Elements of Statistical Learning. Springer, New York. 2nd edition.
</p>
</li>
<li><p> Geurts, P., Ernst, D., Wehenkel, L. (2006). Extremely randomized trees. Mach Learn 63:3-42. <a href="https://doi.org/10.1007/s10994-006-6226-1">doi:10.1007/s10994-006-6226-1</a>.
</p>
</li>
<li><p> Meinshausen (2006). Quantile Regression Forests. J Mach Learn Res 7:983-999. <a href="https://www.jmlr.org/papers/v7/meinshausen06a.html">https://www.jmlr.org/papers/v7/meinshausen06a.html</a>.  
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+predict.blockForest">predict.blockForest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(blockForest)

# Standard Block Forest
blockForest(Species ~ ., iris, 
            blocks = list(1:2, 3:4), 
            mtry = c(1, 2), 
            block.weights = c(0.1, 0.9), 
            block.method = "BlockForest")

# Without blocks, grow standard random forest
blockForest(Species ~ ., iris)

</code></pre>

<hr>
<h2 id='predict.blockForest'>Prediction using Random Forest variants for block-structured covariate data</h2><span id='topic+predict.blockForest'></span>

<h3>Description</h3>

<p>This function is to be applied to the entry 'forest' of the output of
<code><a href="#topic+blockfor">blockfor</a></code>. See the example section for illustration.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blockForest'
predict(
  object,
  data = NULL,
  predict.all = FALSE,
  num.trees = object$num.trees,
  type = "response",
  se.method = "infjack",
  quantiles = c(0.1, 0.5, 0.9),
  seed = NULL,
  num.threads = NULL,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predict.blockForest_+3A_object">object</code></td>
<td>
<p><code>blockForest</code> object.</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_data">data</code></td>
<td>
<p>New test data of class <code>data.frame</code> or <code>gwaa.data</code> (GenABEL).</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_predict.all">predict.all</code></td>
<td>
<p>Return individual predictions for each tree instead of aggregated predictions for all trees. Return a matrix (sample x tree) for classification and regression, a 3d array for probability estimation (sample x class x tree) and survival (sample x time x tree).</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_num.trees">num.trees</code></td>
<td>
<p>Number of trees used for prediction. The first <code>num.trees</code> in the forest are used.</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_type">type</code></td>
<td>
<p>Type of prediction. One of 'response', 'se', 'terminalNodes', 'quantiles' with default 'response'. See below for details.</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_se.method">se.method</code></td>
<td>
<p>Method to compute standard errors. One of 'jack', 'infjack' with default 'infjack'. Only applicable if type = 'se'. See below for details.</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_quantiles">quantiles</code></td>
<td>
<p>Vector of quantiles for quantile prediction. Set <code>type = 'quantiles'</code> to use.</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_seed">seed</code></td>
<td>
<p>Random seed. Default is <code>NULL</code>, which generates the seed from <code>R</code>. Set to <code>0</code> to ignore the <code>R</code> seed. The seed is used in case of ties in classification mode.</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_num.threads">num.threads</code></td>
<td>
<p>Number of threads. Default is number of CPUs available.</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_verbose">verbose</code></td>
<td>
<p>Verbose output on or off.</p>
</td></tr>
<tr><td><code id="predict.blockForest_+3A_...">...</code></td>
<td>
<p>further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For <code>type = 'response'</code> (the default), the predicted classes (classification), predicted numeric values (regression), predicted probabilities (probability estimation) or survival probabilities (survival) are returned. 
For <code>type = 'se'</code>, the standard error of the predictions are returned (regression only). The jackknife-after-bootstrap or infinitesimal jackknife for bagging is used to estimate the standard errors based on out-of-bag predictions. See Wager et al. (2014) for details.
For <code>type = 'terminalNodes'</code>, the IDs of the terminal node in each tree for each observation in the given dataset are returned.
For <code>type = 'quantiles'</code>, the selected quantiles for each observation are estimated. See Meinshausen (2006) for details.
</p>
<p>If <code>type = 'se'</code> is selected, the method to estimate the variances can be chosen with <code>se.method</code>. Set <code>se.method = 'jack'</code> for jackknife-after-bootstrap and <code>se.method = 'infjack'</code> for the infinitesimal jackknife for bagging.
</p>
<p>For classification and <code>predict.all = TRUE</code>, a factor levels are returned as numerics.
To retrieve the corresponding factor levels, use <code>rf$forest$levels</code>, if <code>rf</code> is the ranger object.
</p>


<h3>Value</h3>

<p>Object of class <code>blockForest.prediction</code> with elements
</p>

<table>
<tr>
 <td style="text-align: left;">
      <code>predictions</code>    </td><td style="text-align: left;"> Predicted classes/values (only for classification and regression)  </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>unique.death.times</code> </td><td style="text-align: left;"> Unique death times (only for survival). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>chf</code> </td><td style="text-align: left;"> Estimated cumulative hazard function for each sample (only for survival). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>survival</code> </td><td style="text-align: left;"> Estimated survival function for each sample (only for survival). </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>num.trees</code>   </td><td style="text-align: left;"> Number of trees. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>num.independent.variables</code> </td><td style="text-align: left;"> Number of independent variables. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>treetype</code>    </td><td style="text-align: left;"> Type of forest/tree. Classification, regression or survival. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>num.samples</code>     </td><td style="text-align: left;"> Number of samples.
  </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>References</h3>


<ul>
<li><p> Wright, M. N. &amp; Ziegler, A. (2017). ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R. J Stat Softw 77:1-17. <a href="https://doi.org/10.18637/jss.v077.i01">doi:10.18637/jss.v077.i01</a>.
</p>
</li>
<li><p> Wager, S., Hastie T., &amp; Efron, B. (2014). Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife. J Mach Learn Res 15:1625-1651. <a href="https://jmlr.org/papers/v15/wager14a.html">https://jmlr.org/papers/v15/wager14a.html</a>.
</p>
</li>
<li><p> Meinshausen (2006). Quantile Regression Forests. J Mach Learn Res 7:983-999. <a href="https://www.jmlr.org/papers/v7/meinshausen06a.html">https://www.jmlr.org/papers/v7/meinshausen06a.html</a>.  
</p>
</li></ul>



<h3>See Also</h3>

<p><code><a href="#topic+blockForest">blockForest</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># NOTE: There is no association between covariates and response for the
# simulated data below.
# Moreover, the input parameters of blockfor() are highly unrealistic
# (e.g., nsets = 10 is specified much too small).
# The purpose of the shown examples is merely to illustrate the
# application of predict.blockForest().


# Generate data:
################

set.seed(1234)

# Covariate matrix:
X &lt;- cbind(matrix(nrow=40, ncol=5, data=rnorm(40*5)), 
           matrix(nrow=40, ncol=30, data=rnorm(40*30, mean=1, sd=2)),
           matrix(nrow=40, ncol=100, data=rnorm(40*100, mean=2, sd=3)))
colnames(X) &lt;- paste("X", 1:ncol(X), sep="")

# Block variable (list):
block &lt;- rep(1:3, times=c(5, 30, 100))
block &lt;- lapply(1:3, function(x) which(block==x))

# Binary outcome:
ybin &lt;- factor(sample(c(0,1), size=40, replace=TRUE), levels=c(0,1))

# Survival outcome:
ysurv &lt;- cbind(rnorm(40), sample(c(0,1), size=40, replace=TRUE))



# Divide in training and test data:

Xtrain &lt;- X[1:30,]
Xtest &lt;- X[31:40,]

ybintrain &lt;- ybin[1:30]
ybintest &lt;- ybin[31:40]

ysurvtrain &lt;- ysurv[1:30,]
ysurvtest &lt;- ysurv[31:40,]




# Binary outcome: Apply algorithm to training data and obtain predictions
# for the test data:
#########################################################################

# Apply a variant to the training data:

blockforobj &lt;- blockfor(Xtrain, ybintrain, num.trees = 100, replace = TRUE, block=block,
                        nsets = 10, num.trees.pre = 50, splitrule="extratrees", 
                        block.method = "SplitWeights")
blockforobj$paramvalues


# Obtain prediction for the test data:

(predres &lt;- predict(blockforobj$forest, data = Xtest, block.method = "SplitWeights"))
predres$predictions



# Survival outcome: Apply algorithm to training data and obtain predictions
# for the test data:
###########################################################################

# Apply a variant to the training data:

blockforobj &lt;- blockfor(Xtrain, ysurvtrain, num.trees = 100, replace = TRUE, block=block,
                        nsets = 10, num.trees.pre = 50, splitrule="extratrees", 
                        block.method = "SplitWeights")
blockforobj$paramvalues


# Obtain prediction for the test data:

(predres &lt;- predict(blockforobj$forest, data = Xtest, block.method = "SplitWeights"))
rowSums(predres$chf)

</code></pre>

<hr>
<h2 id='predictions.blockForest'>blockForest predictions</h2><span id='topic+predictions.blockForest'></span>

<h3>Description</h3>

<p>Extract training data predictions of blockForest object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blockForest'
predictions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictions.blockForest_+3A_x">x</code></td>
<td>
<p>blockForest object.</p>
</td></tr>
<tr><td><code id="predictions.blockForest_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions: Classes for Classification forests, Numerical values for Regressions forests and the estimated survival functions for all individuals for Survival forests.
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockForest">blockForest</a></code>
</p>

<hr>
<h2 id='predictions.blockForest.prediction'>blockForest predictions</h2><span id='topic+predictions.blockForest.prediction'></span><span id='topic+predictions'></span>

<h3>Description</h3>

<p>Extract predictions of blockForest prediction object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blockForest.prediction'
predictions(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="predictions.blockForest.prediction_+3A_x">x</code></td>
<td>
<p>blockForest prediction object.</p>
</td></tr>
<tr><td><code id="predictions.blockForest.prediction_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Predictions: Classes for Classification forests, Numerical values for Regressions forests and the estimated survival functions for all individuals for Survival forests.
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockForest">blockForest</a></code>
</p>

<hr>
<h2 id='timepoints.blockForest'>blockForest timepoints</h2><span id='topic+timepoints.blockForest'></span><span id='topic+timepoints'></span>

<h3>Description</h3>

<p>Extract unique death times of blockForest Survival forest
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blockForest'
timepoints(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timepoints.blockForest_+3A_x">x</code></td>
<td>
<p>blockForest Survival forest object.</p>
</td></tr>
<tr><td><code id="timepoints.blockForest_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Unique death times
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockForest">blockForest</a></code>
</p>

<hr>
<h2 id='timepoints.blockForest.prediction'>blockForest timepoints</h2><span id='topic+timepoints.blockForest.prediction'></span>

<h3>Description</h3>

<p>Extract unique death times of blockForest Survival prediction object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'blockForest.prediction'
timepoints(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="timepoints.blockForest.prediction_+3A_x">x</code></td>
<td>
<p>blockForest Survival prediction object.</p>
</td></tr>
<tr><td><code id="timepoints.blockForest.prediction_+3A_...">...</code></td>
<td>
<p>Further arguments passed to or from other methods.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Unique death times
</p>


<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>See Also</h3>

<p><code><a href="#topic+blockForest">blockForest</a></code>
</p>

<hr>
<h2 id='treeInfo'>Tree information in human readable format</h2><span id='topic+treeInfo'></span>

<h3>Description</h3>

<p>Extract tree information of a <code>blockForest</code> object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>treeInfo(object, tree = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="treeInfo_+3A_object">object</code></td>
<td>
<p><code>blockForest</code> object.</p>
</td></tr>
<tr><td><code id="treeInfo_+3A_tree">tree</code></td>
<td>
<p>Number of the tree of interest.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Node and variable ID's are 0-indexed, i.e., node 0 is the root node. 
If the formula interface is used in the <code>blockForest</code> call, the variable ID's are usually different to the original data used to grow the tree. 
Refer to the variable name instead to be sure.
</p>
<p>Splitting at unordered factors (nominal variables) depends on the option <code>respect.unordered.factors</code> in the <code>blockForest</code> call. 
For the &quot;ignore&quot; and &quot;order&quot; approaches, all values smaller or equal the <code>splitval</code> value go to the left and all values larger go to the right, as usual. 
However, with &quot;order&quot; the values correspond to the order in <code>object$forest$covariate.levels</code> instead of the original order (usually alphabetical).
In the &quot;partition&quot; mode, the <code>splitval</code> values for unordered factor are comma separated lists of values, representing the factor levels (in the original order) going to the left.
</p>


<h3>Value</h3>

<p>A data.frame with the columns
</p>

<table>
<tr>
 <td style="text-align: left;">
      <code>nodeID</code> </td><td style="text-align: left;"> The nodeID, 0-indexed. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>leftChild</code> </td><td style="text-align: left;"> ID of the left child node, 0-indexed. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>rightChild</code> </td><td style="text-align: left;"> ID of the right child node, 0-indexed. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>splitvarID</code> </td><td style="text-align: left;"> ID of the splitting variable, 0-indexed. Caution, the variable order changes if the formula interface is used. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>splitvarName</code> </td><td style="text-align: left;"> Name of the splitting variable. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>splitval</code> </td><td style="text-align: left;"> The splitting value. For numeric or ordinal variables, all values smaller or equal go to the left, larger values to the right. For unordered factor variables see above. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>terminal</code> </td><td style="text-align: left;"> Logical, TRUE for terminal nodes. </td>
</tr>
<tr>
 <td style="text-align: left;">
      <code>prediction</code> </td><td style="text-align: left;"> One column with the predicted class (factor) for classification and the predicted numerical value for regression. One probability per class for probability estimation in several columns. Nothing for survival, refer to <code>object$forest$chf</code> for the CHF node predictions. </td>
</tr>
<tr>
 <td style="text-align: left;">
  </td>
</tr>

</table>



<h3>Author(s)</h3>

<p>Marvin N. Wright
</p>


<h3>Examples</h3>

<pre><code class='language-R'>require(blockForest)
rf &lt;- blockForest(Species ~ ., data = iris)
treeInfo(rf, 1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
