<!DOCTYPE html><html><head><title>Help for package DIFboost</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DIFboost}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#DIFboost'>
<p>Detection of Differential Item Functioning (DIF) in Rasch Models by Boosting Techniques</p></a></li>
<li><a href='#DIFboost-package'>
<p>DIFboost</p></a></li>
<li><a href='#print.DIFboost'>
<p>Print function for DIFboost</p></a></li>
<li><a href='#simul.data'>
<p>Simulated data set</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Detection of Differential Item Functioning (DIF) in Rasch Models
by Boosting Techniques</td>
</tr>
<tr>
<td>Version:</td>
<td>0.3</td>
</tr>
<tr>
<td>Date:</td>
<td>2020-06-11</td>
</tr>
<tr>
<td>Imports:</td>
<td>mboost, penalized, stabs</td>
</tr>
<tr>
<td>Author:</td>
<td>Gunther Schauberger</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Gunther Schauberger &lt;gunther.schauberger@tum.de&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs detection of Differential Item Functioning using the method DIFboost as proposed by Schauberger and Tutz (2016) &lt;<a href="https://doi.org/10.1111%2Fbmsp.12060">doi:10.1111/bmsp.12060</a>&gt;. </td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-06-11 12:28:50 UTC; ge29weh</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-06-11 19:00:18 UTC</td>
</tr>
</table>
<hr>
<h2 id='DIFboost'>
Detection of Differential Item Functioning (DIF) in Rasch Models by Boosting Techniques
</h2><span id='topic+DIFboost'></span>

<h3>Description</h3>

<p>A function to perform DIFboost, a method to detect DIF (Differential Item Functioning) in Rasch Models. It can handle settings with many covariates and also metric covariates simultaneously. The method is described in Tutz and Schauberger (2015). Model/variable selection is performed using stability selection. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>DIFboost(Y, X, mstop = 400, trace = TRUE, cutoff = 0.9, 
         B = 500, mc.cores = 1, q = 0.6 * I)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="DIFboost_+3A_y">Y</code></td>
<td>

<p>Data frame (one row per person, one column per item) containing response. May only contain 0 or 1.
</p>
</td></tr>
<tr><td><code id="DIFboost_+3A_x">X</code></td>
<td>

<p>Data frame (one row per person, one column per covariate) containing covariates. Has to be standardized. 
</p>
</td></tr>
<tr><td><code id="DIFboost_+3A_mstop">mstop</code></td>
<td>

<p>Number of boosting iterations maximally performed in one iteration of the stability selection.
</p>
</td></tr>
<tr><td><code id="DIFboost_+3A_trace">trace</code></td>
<td>

<p>Should the trace of the single boosting steps be printed?
</p>
</td></tr>
<tr><td><code id="DIFboost_+3A_cutoff">cutoff</code></td>
<td>

<p>Cutoff value for stability selection. 
</p>
</td></tr>
<tr><td><code id="DIFboost_+3A_b">B</code></td>
<td>

<p>Number of subsamples used for stability selection.
</p>
</td></tr>
<tr><td><code id="DIFboost_+3A_mc.cores">mc.cores</code></td>
<td>

<p>Number of cores for parallelized stability selection. For windows machines, parallelization is not possible. 
</p>
</td></tr>
<tr><td><code id="DIFboost_+3A_q">q</code></td>
<td>

<p>Maximum number of base learner to be included in the boosting algorithm for one subsample in stability selection. By default set to 60 percent of the total number of items. 
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The method assumes the DIFmodel from Tutz and Schauberger (2015) where boosting is used for DIF detection. Computation is based on the functions <code><a href="mboost.html#topic+gamboost">gamboost</a></code> and <code><a href="mboost.html#topic+stabsel">stabsel</a></code>.  
</p>


<h3>Value</h3>

<table>
<tr><td><code>model</code></td>
<td>
<p>Model from inital gamboost fit</p>
</td></tr>
<tr><td><code>dif.mat</code></td>
<td>
<p>Estimates of the item-specific parameter estimates, with zeros for non-DIF items</p>
</td></tr>
<tr><td><code>coefficients</code></td>
<td>
<p>coefficient vector with all estimates from refitted model</p>
</td></tr>
<tr><td><code>theta</code></td>
<td>
<p>Estimated person abilities</p>
</td></tr>
<tr><td><code>beta</code></td>
<td>
<p>Estimated item difficulties</p>
</td></tr>
<tr><td><code>gamma</code></td>
<td>
<p>Estimated item-specific parameters</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p>Number of (valid) persons</p>
</td></tr>
<tr><td><code>I</code></td>
<td>
<p>Number of items</p>
</td></tr>
<tr><td><code>names.y</code></td>
<td>
<p>Names of the items</p>
</td></tr>
<tr><td><code>names.x</code></td>
<td>
<p>Names of the covariates</p>
</td></tr>
<tr><td><code>design.matrix</code></td>
<td>
<p>Design matrix for refitted model</p>
</td></tr>
<tr><td><code>PFER</code></td>
<td>
<p>upper bound for the per-family error rate. For details see <code><a href="mboost.html#topic+stabsel">stabsel</a></code>.</p>
</td></tr>
<tr><td><code>lin.pred</code></td>
<td>
<p>linear predictor from refitted model</p>
</td></tr>
<tr><td><code>DIF.items</code></td>
<td>
<p>Which items have been detected to be DIF items?</p>
</td></tr>
<tr><td><code>ref.item</code></td>
<td>
<p>Reference item</p>
</td></tr>
<tr><td><code>phat</code></td>
<td>
<p>selection probabilities for single base learners in stability selection. For details see <code><a href="mboost.html#topic+stabsel">stabsel</a></code></p>
</td></tr>
<tr><td><code>cutoff</code></td>
<td>
<p>cutoff value used for stability selection</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gunther Schauberger<br />
<a href="mailto:gunther.schauberger@tum">gunther.schauberger@tum</a><br />
<a href="https://www.sg.tum.de/epidemiologie/team/schauberger/">https://www.sg.tum.de/epidemiologie/team/schauberger/</a>
</p>


<h3>References</h3>

<p>Schauberger, Gunther and Tutz, Gerhard (2016): <em>Detection of Differential Item Functioning in Rasch Models by Boosting Techniques</em>, British Journal of Mathematical and Statistical Psychology, 69(1), 80 - 103
</p>


<h3>See Also</h3>

<p><code><a href="#topic+print.DIFboost">print.DIFboost</a></code>, <code><a href="mboost.html#topic+gamboost">gamboost</a></code>, <code><a href="mboost.html#topic+stabsel">stabsel</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(simul.data)

Y &lt;- simul.data[,1:10]
X &lt;- simul.data[,11:13]

m1 &lt;- DIFboost(Y = Y, X = X) 
print(m1)

## End(Not run)
</code></pre>

<hr>
<h2 id='DIFboost-package'>
DIFboost
</h2><span id='topic+DIFboost-package'></span>

<h3>Description</h3>

<p>A package to perform DIFboost, a method to detect DIF (Differential Item Functioning) in Rasch Models. It can handle settings with many covariates and also metric covariates simultaneously. The method is described in Tutz and Schauberger (2015). Model/variable selection is performed using stability selection. 
</p>


<h3>Details</h3>

<p>The method assumes the DIFmodel from Tutz and Schauberger (2015) where boosting is used for DIF detection. Computation is based on the functions <code><a href="mboost.html#topic+gamboost">gamboost</a></code> and <code><a href="mboost.html#topic+stabsel">stabsel</a></code>.  
</p>


<h3>Author(s)</h3>

<p>Gunther Schauberger<br />
<a href="mailto:gunther.schauberger@tum">gunther.schauberger@tum</a><br />
<a href="https://www.sg.tum.de/epidemiologie/team/schauberger/">https://www.sg.tum.de/epidemiologie/team/schauberger/</a>
</p>


<h3>References</h3>

<p>Schauberger, Gunther and Tutz, Gerhard (2016): <em>Detection of Differential Item Functioning in Rasch Models by Boosting Techniques</em>, British Journal of Mathematical and Statistical Psychology, 69(1), 80 - 103
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DIFboost">DIFboost</a></code>, <code><a href="#topic+print.DIFboost">print.DIFboost</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(simul.data)

Y &lt;- simul.data[,1:10]
X &lt;- simul.data[,11:13]

m1 &lt;- DIFboost(Y = Y, X = X) 
print(m1)

## End(Not run)
</code></pre>

<hr>
<h2 id='print.DIFboost'>
Print function for DIFboost
</h2><span id='topic+print.DIFboost'></span>

<h3>Description</h3>

<p>Prints the most important output of a DIFboost object. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'DIFboost'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.DIFboost_+3A_x">x</code></td>
<td>
<p>DIFboost object, created by <code><a href="#topic+DIFboost">DIFboost</a></code>
</p>
</td></tr>
<tr><td><code id="print.DIFboost_+3A_...">...</code></td>
<td>

<p>Further arguments to be passed to the <code><a href="base.html#topic+print">print</a></code> function.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Gunther Schauberger<br />
<a href="mailto:gunther.schauberger@tum">gunther.schauberger@tum</a><br />
<a href="https://www.sg.tum.de/epidemiologie/team/schauberger/">https://www.sg.tum.de/epidemiologie/team/schauberger/</a>
</p>


<h3>References</h3>

<p>Schauberger, Gunther and Tutz, Gerhard (2016): <em>Detection of Differential Item Functioning in Rasch Models by Boosting Techniques</em>, British Journal of Mathematical and Statistical Psychology, 69(1), 80 - 103
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DIFboost">DIFboost</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(simul.data)

Y &lt;- simul.data[,1:10]
X &lt;- simul.data[,11:13]

m1 &lt;- DIFboost(Y = Y, X = X) 
print(m1)

## End(Not run)
</code></pre>

<hr>
<h2 id='simul.data'>
Simulated data set
</h2><span id='topic+simul.data'></span>

<h3>Description</h3>

<p>Simulated data set with 100 persons, 10 items and 3 (standardized) covariates. Items 1, 2 and 3 are DIF items.</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(simul.data)</code></pre>


<h3>Format</h3>


<dl>
<dt><code>Item1</code></dt><dd><p>Item 1, DIF item</p>
</dd>
<dt><code>Item2</code></dt><dd><p>Item 2, DIF item</p>
</dd>
<dt><code>Item3</code></dt><dd><p>Item 3, DIF item</p>
</dd>
<dt><code>Item4</code></dt><dd><p>Item 4, non-DIF item</p>
</dd>
<dt><code>Item5</code></dt><dd><p>Item 5, non-DIF item</p>
</dd>
<dt><code>Item6</code></dt><dd><p>Item 6, non-DIF item</p>
</dd>
<dt><code>Item7</code></dt><dd><p>Item 7, non-DIF item</p>
</dd>
<dt><code>Item8</code></dt><dd><p>Item 8, non-DIF item</p>
</dd>
<dt><code>Item9</code></dt><dd><p>Item 9, non-DIF item</p>
</dd>
<dt><code>Item10</code></dt><dd><p>Item 10, non-DIF item</p>
</dd>                                
<dt><code>CovBin1</code></dt><dd><p>Binary covariate (standardized)</p>
</dd>
<dt><code>CovBin2</code></dt><dd><p>Binary covariate (standardized)</p>
</dd>
<dt><code>CovMet</code></dt><dd><p>Metric covariate (standardized)</p>
</dd>        
</dl>



<h3>Author(s)</h3>

<p>Gunther Schauberger<br />
<a href="mailto:gunther.schauberger@tum">gunther.schauberger@tum</a><br />
<a href="https://www.sg.tum.de/epidemiologie/team/schauberger/">https://www.sg.tum.de/epidemiologie/team/schauberger/</a>
</p>


<h3>References</h3>

<p>Schauberger, Gunther and Tutz, Gerhard (2016): <em>Detection of Differential Item Functioning in Rasch Models by Boosting Techniques</em>, British Journal of Mathematical and Statistical Psychology, 69(1), 80 - 103
</p>


<h3>See Also</h3>

<p><code><a href="#topic+DIFboost">DIFboost</a></code>, <code><a href="#topic+print.DIFboost">print.DIFboost</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
data(simul.data)

Y &lt;- simul.data[,1:10]
X &lt;- simul.data[,11:13]

m1 &lt;- DIFboost(Y = Y, X = X) 
print(m1)

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
