<!DOCTYPE html><html lang="en"><head><title>Help for package pdSpecEst</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {pdSpecEst}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#pdSpecEst'><p>pdSpecEst: An Analysis Toolbox for Hermitian Positive Definite Matrices</p></a></li>
<li><a href='#Expm'><p>Riemannian HPD exponential map</p></a></li>
<li><a href='#H.coeff'><p>Orthonormal basis expansion of a Hermitian matrix</p></a></li>
<li><a href='#InvWavTransf1D'><p>Inverse AI wavelet transform for curve of HPD matrices</p></a></li>
<li><a href='#InvWavTransf2D'><p>Inverse AI wavelet transform for surface of HPD matrices</p></a></li>
<li><a href='#Logm'><p>Riemannian HPD logarithmic map</p></a></li>
<li><a href='#Mid'><p>Geodesic midpoint between HPD matrices</p></a></li>
<li><a href='#pdCART'><p>Tree-structured trace thresholding of wavelet coefficients</p></a></li>
<li><a href='#pdDepth'><p>Data depth for HPD matrices</p></a></li>
<li><a href='#pdDist'><p>Compute distance between two HPD matrices</p></a></li>
<li><a href='#pdkMeans'><p>K-means clustering for HPD matrices</p></a></li>
<li><a href='#pdMean'><p>Weighted Karcher mean of HPD matrices</p></a></li>
<li><a href='#pdMedian'><p>Weighted intrinsic median of HPD matrices</p></a></li>
<li><a href='#pdNeville'><p>Polynomial interpolation of curves (1D) or surfaces (2D) of HPD matrices</p></a></li>
<li><a href='#pdParTrans'><p>Riemannian HPD parallel transport</p></a></li>
<li><a href='#pdPgram'><p>Multitaper HPD periodogram matrix</p></a></li>
<li><a href='#pdPgram2D'><p>Multitaper HPD time-varying periodogram matrix</p></a></li>
<li><a href='#pdPolynomial'><p>Generate intrinsic HPD polynomial curves</p></a></li>
<li><a href='#pdRankTests'><p>Rank-based hypothesis tests for HPD matrices</p></a></li>
<li><a href='#pdSpecClust1D'><p>Intrinsic wavelet HPD spectral matrix clustering</p></a></li>
<li><a href='#pdSpecClust2D'><p>Intrinsic wavelet HPD time-varying spectral clustering</p></a></li>
<li><a href='#pdSpecEst1D'><p>Intrinsic wavelet HPD spectral estimation</p></a></li>
<li><a href='#pdSpecEst2D'><p>Intrinsic wavelet HPD time-varying spectral estimation</p></a></li>
<li><a href='#pdSplineReg'><p>Cubic smoothing spline regression for HPD matrices</p></a></li>
<li><a href='#rARMA'><p>Simulate vARMA(2,2) time series</p></a></li>
<li><a href='#rExamples1D'><p>Several example curves of HPD matrices</p></a></li>
<li><a href='#rExamples2D'><p>Several example surfaces of HPD matrices</p></a></li>
<li><a href='#WavTransf1D'><p>Forward AI wavelet transform for curve of HPD matrices</p></a></li>
<li><a href='#WavTransf2D'><p>Forward AI wavelet transform for surface of HPD matrices</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>An Analysis Toolbox for Hermitian Positive Definite Matrices</td>
</tr>
<tr>
<td>Version:</td>
<td>1.2.4</td>
</tr>
<tr>
<td>Description:</td>
<td>An implementation of data analysis tools for samples of symmetric or 
  Hermitian positive definite matrices, such as collections of covariance matrices 
  or spectral density matrices. The tools in this package can be used to perform: (i) 
  intrinsic wavelet transforms for curves (1D) or surfaces (2D) of Hermitian positive 
  definite matrices with applications to dimension reduction, denoising and clustering in the 
  space of Hermitian positive definite matrices; and (ii) exploratory data analysis and inference 
  for samples of positive definite matrices by means of intrinsic data depth functions and 
  rank-based hypothesis tests in the space of Hermitian positive definite matrices.</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/JorisChau/pdSpecEst">https://github.com/JorisChau/pdSpecEst</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.4.0)</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Imports:</td>
<td>multitaper, Rcpp, ddalpha, Rdpack</td>
</tr>
<tr>
<td>RdMacros:</td>
<td>Rdpack</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo (&ge; 0.7.500.0.0)</td>
</tr>
<tr>
<td>SystemRequirements:</td>
<td>GNU make, C++11</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, grid, ggplot2, reshape2, viridis,
ggthemes</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2020-01-07 11:26:33 UTC; jchau</td>
</tr>
<tr>
<td>Author:</td>
<td>Joris Chau [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Joris Chau &lt;joris.chau@openanalytics.eu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2020-01-08 09:10:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='pdSpecEst'>pdSpecEst: An Analysis Toolbox for Hermitian Positive Definite Matrices</h2><span id='topic+pdSpecEst'></span><span id='topic+pdSpecEst-package'></span>

<h3>Description</h3>

<p>The <code>pdSpecEst</code> (<strong>p</strong>ositive <strong>d</strong>efinite <strong>Spec</strong>tral <strong>Est</strong>imation)
package provides data analysis tools for samples of symmetric or Hermitian positive definite matrices,
such as collections of positive definite covariance matrices or spectral density matrices.
</p>


<h3>Details</h3>

<p>The tools in this package can be used to perform:
</p>

<ul>
<li> <p><em>Intrinsic wavelet transforms</em> for curves (1D) and surfaces (2D) of Hermitian positive
definite matrices, with applications to for instance: dimension reduction, denoising and clustering for curves or
surfaces of Hermitian positive definite matrices, such as (time-varying) Fourier spectral density matrices.
These implementations are based in part on the paper (Chau and von
Sachs 2019) and Chapters 3
and 5 of (Chau 2018).
</p>
</li>
<li><p> Exploratory data analysis and inference for samples of Hermitian positive definite matrices by
means of <em>intrinsic data depth</em> and <em>depth rank-based hypothesis tests</em>. These implementations are based
on the paper (Chau et al. 2019) and Chapter 4 of (Chau 2018).
</p>
</li></ul>

<p>For more details and examples on how to use the package see the accompanying vignettes in the vignettes folder.
An R-Shiny app to demonstrate and test the implemented functionality in the package is available
<a href="https://jchau.shinyapps.io/pdSpecEst/">here</a>.
</p>
<p>Author and maintainer: <strong>Joris Chau</strong> (<a href="mailto:j.chau@uclouvain.be">j.chau@uclouvain.be</a>).
</p>
<p>Install the current development version via <code>devtools::install_github("JorisChau/pdSpecEst")</code>.
</p>


<h3>References</h3>

<p>Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, Ombao H, von
Sachs R (2019).
&ldquo;Intrinsic data depth for Hermitian positive definite matrices.&rdquo;
<em>Journal of Computational and Graphical Statistics</em>, <b>28</b>(2), 427&ndash;439.
doi: <a href="https://doi.org/10.1080/10618600.2018.1537926">10.1080/10618600.2018.1537926</a>.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.
</p>

<hr>
<h2 id='Expm'>Riemannian HPD exponential map</h2><span id='topic+Expm'></span>

<h3>Description</h3>

<p><code>Expm(P, H)</code> computes the projection of a Hermitian matrix <code>H</code> from the tangent space at a Hermitian
PD matrix <code>P</code> to the manifold of Hermitian PD matrices equipped with the affine-invariant Riemannian metric
via the exponential map as in e.g., (Pennec et al. 2006). This is the unique inverse of the Riemannian
logarithmic map <code><a href="#topic+Logm">Logm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Expm(P, H)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Expm_+3A_p">P</code></td>
<td>
<p>a Hermitian positive definite matrix.</p>
</td></tr>
<tr><td><code id="Expm_+3A_h">H</code></td>
<td>
<p>a Hermitian matrix (of equal dimension as <code>P</code>).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Logm">Logm</a>, <a href="#topic+pdParTrans">pdParTrans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Generate random Hermitian matrix
 H &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
 diag(H) &lt;- rnorm(3)
 H[lower.tri(H)] &lt;- t(Conj(H))[lower.tri(H)]
 ## Generate random HPD matrix
 p &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
 P &lt;- t(Conj(p)) %*% p
 ## Compute exponential map
 Expm(P, H)

</code></pre>

<hr>
<h2 id='H.coeff'>Orthonormal basis expansion of a Hermitian matrix</h2><span id='topic+H.coeff'></span>

<h3>Description</h3>

<p><code>H.coeff</code> expands a <code class="reqn">(d,d)</code>-dimensional Hermitian matrix <code>H</code>  with respect to
an orthonormal (in terms of the Frobenius inner product) basis of the space of Hermitian matrices.
That is, <code>H.coeff</code> transforms <code>H</code> into a numeric vector of <code class="reqn">d^2</code> real-valued basis coefficients,
which is possible as the space of Hermitian matrices is a real vector space. Let <code class="reqn">E_{nm}</code> be a
<code class="reqn">(d,d)</code>-dimensional zero matrix with a 1 at location <code class="reqn">(1, 1) \leq (n,m) \leq (d,d)</code>.
The orthonormal basis contains the following matrix elements; let  <code class="reqn">1 \le n \le d</code> and
<code class="reqn">1 \le m \le d</code>,
</p>

<dl>
<dt>If <code>n == m</code></dt><dd><p> the real matrix element <code class="reqn">E_{nn}</code></p>
</dd>
<dt>If <code>n &lt; m</code></dt><dd><p> the complex matrix element <code class="reqn">2i/\sqrt 2 E_{nm}</code></p>
</dd>
<dt>If <code>n &gt; m</code></dt><dd><p> the real matrix element <code class="reqn">2/\sqrt 2 E_{nm}</code></p>
</dd>
</dl>

<p>The orthonormal basis coefficients are ordered by scanning through the matrix <code>H</code> in a row-by-row
fashion.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>H.coeff(H, inverse = FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="H.coeff_+3A_h">H</code></td>
<td>
<p>if <code>inverse = FALSE</code>, a <code class="reqn">(d,d)</code>-dimensional Hermitian matrix; if <code>inverse = TRUE</code>, a numeric
vector of length <code class="reqn">d^2</code> with <code class="reqn">d</code> an integer.</p>
</td></tr>
<tr><td><code id="H.coeff_+3A_inverse">inverse</code></td>
<td>
<p>a logical value that determines whether the forward basis transform (<code>inverse = FALSE</code>) or the inverse
basis transform (<code>inverse = TRUE</code>) should be applied.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>inverse = FALSE</code> takes as input a <code class="reqn">(d,d)</code>-dimensional Hermitian matrix and outputs a numeric
vector of length <code class="reqn">d^2</code> containing the real-valued basis coefficients. If <code>inverse = TRUE</code> takes as input a
<code class="reqn">d^2</code>-dimensional numeric vector of basis coefficients and outputs the corresponding <code class="reqn">(d,d)</code>-dimensional
Hermitian matrix.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## random Hermitian matrix
H &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
diag(H) &lt;- rnorm(3)
H[lower.tri(H)] &lt;- t(Conj(H))[lower.tri(H)]

## orthonormal basis expansion
h &lt;- H.coeff(H)
H1 &lt;- H.coeff(h, inverse = TRUE) ## reconstructed Hermitian matrix
all.equal(H, H1)

</code></pre>

<hr>
<h2 id='InvWavTransf1D'>Inverse AI wavelet transform for curve of HPD matrices</h2><span id='topic+InvWavTransf1D'></span>

<h3>Description</h3>

<p><code>InvWavTransf1D</code> computes an inverse intrinsic average-interpolation (AI) wavelet
transform mapping an array of coarsest-scale HPD midpoints combined with a pyramid of Hermitian
wavelet coefficients to a curve in the manifold of HPD matrices equipped with a metric specified by the user,
as described in (Chau and von
Sachs 2019) and Chapter 3 of (Chau 2018). This is
the inverse operation of the function <code><a href="#topic+WavTransf1D">WavTransf1D</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>InvWavTransf1D(D, M0, order = 5, jmax, periodic = FALSE,
  metric = "Riemannian", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="InvWavTransf1D_+3A_d">D</code></td>
<td>
<p>a list of arrays containing the pyramid of wavelet coefficients, where each array contains the
(<code class="reqn">d,d</code>)-dimensional wavelet coefficients from the coarsest wavelet scale <code>j = 0</code> up to the finest
wavelet scale <code>j = jmax</code>. This is the same format as the <code>$D</code> component given as output by
<code><a href="#topic+WavTransf1D">WavTransf1D</a></code>.</p>
</td></tr>
<tr><td><code id="InvWavTransf1D_+3A_m0">M0</code></td>
<td>
<p>a numeric array containing the midpoint(s) at the coarsest scale <code>j = 0</code> in the midpoint pyramid.
This is the same format as the <code>$M0</code> component given as output by <code><a href="#topic+WavTransf1D">WavTransf1D</a></code>.</p>
</td></tr>
<tr><td><code id="InvWavTransf1D_+3A_order">order</code></td>
<td>
<p>an odd integer larger or equal to 1 corresponding to the order of the intrinsic AI refinement scheme,
defaults to <code>order = 5</code>. Note that if <code>order &gt; 9</code>, the computational cost
significantly increases as the wavelet transform no longer uses a fast wavelet refinement scheme based
on pre-determined weights.</p>
</td></tr>
<tr><td><code id="InvWavTransf1D_+3A_jmax">jmax</code></td>
<td>
<p>the maximum scale (resolution) up to which the HPD midpoints (i.e. scaling coefficients) are reconstructed.
If <code>jmax</code> is not specified it is set equal to the resolution in the finest wavelet scale <code>jmax = length(D)</code>.</p>
</td></tr>
<tr><td><code id="InvWavTransf1D_+3A_periodic">periodic</code></td>
<td>
<p>a logical value determining whether the curve of HPD matrices can be reflected at the boundary for
improved wavelet refinement schemes near the boundaries of the domain. This is useful for spectral matrix estimation,
where the spectral matrix is a symmetric and periodic curve in the frequency domain. Defaults to <code>periodic = FALSE</code>.</p>
</td></tr>
<tr><td><code id="InvWavTransf1D_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code>,
<code>"Euclidean"</code> or <code>"Riemannian-Rahman"</code>. See also the Details section below.</p>
</td></tr>
<tr><td><code id="InvWavTransf1D_+3A_...">...</code></td>
<td>
<p>additional arguments for internal use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input list of arrays <code>D</code> and array <code>M0</code> correspond to a pyramid of wavelet coefficients and
the coarsest-scale HPD midpoints respectively, both are structured in the same way as in the output of
<code>WavTransf1D</code>. As in the forward AI wavelet transform, if the refinement order is an odd integer smaller or
equal to 9, the function computes the inverse wavelet transform using a fast wavelet refinement scheme based on
weighted intrinsic averages with pre-determined weights as explained in (Chau and von
Sachs 2019) and Chapter 3 of
(Chau 2018). If the refinement order is an odd integer larger than 9, the wavelet refinement
scheme uses intrinsic polynomial prediction based on Neville's algorithm in the Riemannian manifold (via <code><a href="#topic+pdNeville">pdNeville</a></code>).<br />
The function computes the inverse intrinsic AI wavelet transform in the space of HPD matrices equipped with
one of the following metrics: (i) the affine-invariant Riemannian metric (default) as detailed in e.g., (Bhatia 2009)[Chapter 6]
or (Pennec et al. 2006); (ii) the log-Euclidean metric, the Euclidean inner product between matrix logarithms;
(iii) the Cholesky metric, the Euclidean inner product between Cholesky decompositions; (iv) the Euclidean metric; or
(v) the root-Euclidean metric. The default choice of metric (affine-invariant Riemannian) satisfies several useful properties
not shared by the other metrics, see (Chau and von
Sachs 2019) or (Chau 2018) for more details. Note that this comes
at the cost of increased computation time in comparison to one of the other metrics.
</p>


<h3>Value</h3>

<p>Returns a (<code class="reqn">d, d, m</code>)-dimensional array corresponding to a length <code class="reqn">m</code> curve of
(<code class="reqn">d,d</code>)-dimensional HPD matrices.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WavTransf1D">WavTransf1D</a></code>, <code><a href="#topic+pdSpecEst1D">pdSpecEst1D</a></code>, <code><a href="#topic+pdNeville">pdNeville</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- rExamples1D(2^8, example = "bumps")
P.wt &lt;- WavTransf1D(P$f) ## forward transform
P.f &lt;- InvWavTransf1D(P.wt$D, P.wt$M0) ## backward transform
all.equal(P.f, P$f)

</code></pre>

<hr>
<h2 id='InvWavTransf2D'>Inverse AI wavelet transform for surface of HPD matrices</h2><span id='topic+InvWavTransf2D'></span>

<h3>Description</h3>

<p><code>InvWavTransf2D</code> computes the inverse intrinsic average-interpolation (AI) wavelet
transform mapping an array of coarsest-scale HPD midpoints combined with a 2D pyramid of Hermitian
wavelet coefficients to a surface in the manifold of HPD matrices equipped with a metric specified by the
user, as described in Chapter 5 of (Chau 2018). This is the inverse operation of the
function <code><a href="#topic+WavTransf2D">WavTransf2D</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>InvWavTransf2D(D, M0, order = c(3, 3), jmax, metric = "Riemannian",
  ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="InvWavTransf2D_+3A_d">D</code></td>
<td>
<p>a list of arrays containing the 2D pyramid of wavelet coefficients, where each array contains the
(<code class="reqn">d,d</code>)-dimensional wavelet coefficients from the coarsest wavelet scale <code>j = 0</code> up to the finest
wavelet scale <code>j = jmax</code>. This is the same format as the <code>$D</code> component given as output by
<code><a href="#topic+WavTransf2D">WavTransf2D</a></code>.</p>
</td></tr>
<tr><td><code id="InvWavTransf2D_+3A_m0">M0</code></td>
<td>
<p>a numeric array containing the midpoint(s) at the coarsest scale <code>j = 0</code> in the 2D midpoint pyramid.
This is the same format as the <code>$M0</code> component given as output by <code><a href="#topic+WavTransf2D">WavTransf2D</a></code>.</p>
</td></tr>
<tr><td><code id="InvWavTransf2D_+3A_order">order</code></td>
<td>
<p>a 2-dimensional numeric vector <code class="reqn">(1,1) \le</code> <code>order</code> <code class="reqn">\le (9,9)</code> corresponding to the marginal
orders of the intrinsic 2D AI refinement scheme, defaults to <code>order = c(3, 3)</code>.</p>
</td></tr>
<tr><td><code id="InvWavTransf2D_+3A_jmax">jmax</code></td>
<td>
<p>the maximum scale (resolution) up to which the 2D surface of HPD midpoints (i.e. scaling coefficients) are
reconstructed. If <code>jmax</code> is not specified it is set equal to the resolution in the finest wavelet scale
<code>jmax = length(D)</code>.</p>
</td></tr>
<tr><td><code id="InvWavTransf2D_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code> or
<code>"Euclidean"</code>. See also the Details section below.</p>
</td></tr>
<tr><td><code id="InvWavTransf2D_+3A_...">...</code></td>
<td>
<p>additional arguments for internal use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input list of arrays <code>D</code> and array <code>M0</code> correspond to a 2D pyramid of wavelet coefficients and
the coarsest-scale HPD midpoints respectively, both are structured in the same way as in the output of
<code>WavTransf2D</code>. As in the forward AI wavelet transform, the marginal refinement orders should be smaller
or equal to 9, and the function computes the wavelet transform using a fast wavelet refinement scheme based on weighted
intrinsic averages with pre-determined weights as explained in Chapter 5 of (Chau 2018). By default
<code>WavTransf2D</code> computes the inverse intrinsic 2D AI wavelet transform equipping the space of HPD matrices with (i)
the affine-invariant Riemannian metric as detailed in e.g., (Bhatia 2009)[Chapter 6] or (Pennec et al. 2006).
Instead, the space of HPD matrices can also be equipped with one of the following metrics; (ii) the Log-Euclidean metric, the
Euclidean inner product between matrix logarithms; (iii) the Cholesky metric, the Euclidean inner product between Cholesky
decompositions; (iv) the Euclidean metric and (v) the root-Euclidean metric. The default choice of metric (affine-invariant Riemannian)
satisfies several useful properties not shared by the other metrics, see (Chau 2018) for more details. Note that this
comes at the cost of increased computation time in comparison to one of the other metrics.
</p>


<h3>Value</h3>

<p>Returns a (<code class="reqn">d, d, n_1, n_2</code>)-dimensional array corresponding to a rectangular surface of size <code class="reqn">n_1</code> by
<code class="reqn">n_2</code> of (<code class="reqn">d,d</code>)-dimensional HPD matrices.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WavTransf2D">WavTransf2D</a></code>, <code><a href="#topic+pdSpecEst2D">pdSpecEst2D</a></code>, <code><a href="#topic+pdNeville">pdNeville</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- rExamples2D(c(2^4, 2^4), 2, example = "tvar")
P.wt &lt;- WavTransf2D(P$f) ## forward transform
P.f &lt;- InvWavTransf2D(P.wt$D, P.wt$M0) ## backward transform
all.equal(P.f, P$f)

</code></pre>

<hr>
<h2 id='Logm'>Riemannian HPD logarithmic map</h2><span id='topic+Logm'></span>

<h3>Description</h3>

<p><code>Logm(P, Q)</code> computes the projection of a Hermitian PD matrix <code>Q</code> in the manifold of HPD matrices
equipped with the affine-invariant Riemannian metric to the tangent space attached at the Hermitian PD matrix
<code>P</code> via the logarithmic map as in e.g., (Pennec et al. 2006). This is the unique inverse of
the exponential map <code><a href="#topic+Expm">Expm</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Logm(P, Q)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Logm_+3A_p">P</code></td>
<td>
<p>a Hermitian positive definite matrix.</p>
</td></tr>
<tr><td><code id="Logm_+3A_q">Q</code></td>
<td>
<p>a Hermitian positive definite matrix (of equal dimension as <code>P</code>).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Pennec, X. (2006). Intrinsic statistics on Riemannian manifolds: Basic tools for geometric
measurements. <em>Journal of Mathematical Imaging and Vision</em> 25(1), 127-154.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Expm">Expm</a>, <a href="#topic+pdParTrans">pdParTrans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Generate two random HPD matrices
 q &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
 Q &lt;- t(Conj(q)) %*% q
 p &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
 P &lt;- t(Conj(p)) %*% p
 ## Compute logarithmic map
 Logm(P, Q)

</code></pre>

<hr>
<h2 id='Mid'>Geodesic midpoint between HPD matrices</h2><span id='topic+Mid'></span>

<h3>Description</h3>

<p><code>Mid</code> calculates the geodesic midpoint between two HPD matrices under the
affine-invariant Riemannian metric as in (Bhatia 2009)[Chapter 6].
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Mid(A, B)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Mid_+3A_a">A</code>, <code id="Mid_+3A_b">B</code></td>
<td>
<p>Hermitian positive definite matrices (of equal dimension).</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdMean">pdMean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'> ## Generate two random HPD matrices
 a &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
 A &lt;- t(Conj(a)) %*% a
 b &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
 B &lt;- t(Conj(b)) %*% b
 ## Compute midpoint
 Mid(A, B)
 ## Midpoint coincides with two-point intrinsic Karcher mean
 all.equal(pdMean(array(c(A, B), dim = c(3, 3, 2))), Mid(A, B))

</code></pre>

<hr>
<h2 id='pdCART'>Tree-structured trace thresholding of wavelet coefficients</h2><span id='topic+pdCART'></span>

<h3>Description</h3>

<p><code>pdCART</code> performs hard tree-structured thresholding of the Hermitian matrix-valued wavelet coefficients obtained with
<code><a href="#topic+WavTransf1D">WavTransf1D</a></code> or <code><a href="#topic+WavTransf2D">WavTransf2D</a></code> based on the trace of the whitened wavelet coefficients, as explained in
(Chau and von
Sachs 2019) or (Chau 2018). This function is primarily written for internal use in other functions and
is typically not used as a stand-alone function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdCART(D, D.white, order, alpha = 1, tree = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdCART_+3A_d">D</code></td>
<td>
<p>a list of wavelet coefficients as obtained from the <code>$D</code> component of <code><a href="#topic+WavTransf1D">WavTransf1D</a></code> or <code><a href="#topic+WavTransf2D">WavTransf2D</a></code> .</p>
</td></tr>
<tr><td><code id="pdCART_+3A_d.white">D.white</code></td>
<td>
<p>a list of whitened wavelet coefficients as obtained from the <code>$D.white</code> component of <code><a href="#topic+WavTransf1D">WavTransf1D</a></code> or <code><a href="#topic+WavTransf2D">WavTransf2D</a></code>.</p>
</td></tr>
<tr><td><code id="pdCART_+3A_order">order</code></td>
<td>
<p>the order(s) of the intrinsic 1D or 2D AI refinement scheme as in <code><a href="#topic+WavTransf1D">WavTransf1D</a></code> and <code><a href="#topic+WavTransf2D">WavTransf2D</a></code>.</p>
</td></tr>
<tr><td><code id="pdCART_+3A_alpha">alpha</code></td>
<td>
<p>tuning parameter specifying the penalty/sparsity parameter as <code>alpha</code> times the universal threshold.</p>
</td></tr>
<tr><td><code id="pdCART_+3A_tree">tree</code></td>
<td>
<p>logical value, if <code>tree = TRUE</code> performs tree-structured thresholding, otherwise performs
non-tree-structured hard thresholding of the coefficients.</p>
</td></tr>
<tr><td><code id="pdCART_+3A_...">...</code></td>
<td>
<p>additional arguments for internal use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Depending on the structure of the input list of arrays <code>D</code> the function performs 1D or 2D tree-structured thresholding of wavelet coefficients.
The optimal tree of wavelet coefficients is found by minimization of the <em>complexity penalized residual sum of squares</em> (CPRESS) criterion
in (Donoho 1997), via a fast tree-pruning algorithm. By default, the penalty parameter in the optimization procedure is set equal to
<code>alpha</code> times the universal threshold <code class="reqn">\sigma_w\sqrt(2\log(n))</code>, where <code class="reqn">\sigma_w^2</code> is the noise variance of the traces of the whitened
wavelet coefficients determined from the finest wavelet scale and <code class="reqn">n</code> is the total number of coefficients. By default, <code>alpha = 1</code>,
if <code>alpha = 0</code>, the penalty parameter is zero and the coefficients remain untouched.
</p>


<h3>Value</h3>

<p>Returns a list with two components:
</p>
<table role = "presentation">
<tr><td><code>w</code></td>
<td>
<p> a list of logical values specifying which coefficients to keep, with each list component
corresponding to an individual wavelet scale starting from the coarsest wavelet scale <code>j = 0</code>.</p>
</td></tr>
<tr><td><code>D_w</code></td>
<td>
<p> the list of thresholded wavelet coefficients, with each list component corresponding
to an individual wavelet scale.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>For thresholding of 1D wavelet coefficients, the noise
variance of the traces of the whitened wavelet coefficients is constant across scales as seen in (Chau and von
Sachs 2019). For thresholding of 2D
wavelet coefficients, there is a discrepancy between the constant noise variance of the traces of the whitened wavelet coefficients at the first
<code>abs(J1 - J2)</code> scales and the remaining scales, as discussed in Chapter 5 of (Chau 2018), where <code class="reqn">J_1 = \log_2(n_1)</code> and
<code class="reqn">J_2 = \log_2(n_2)</code> with <code class="reqn">n_1</code> and <code class="reqn">n_2</code> the dyadic number of observations in each marginal direction of the 2D rectangular tensor grid.
The reason is that the variances of the traces of the whitened coefficients are not homogeneous between: (i) scales at which the 1D wavelet refinement
scheme is applied and (ii) scales at which the 2D wavelet refinement scheme is applied. To correct for this discrepancy, the variances of the coefficients
at the 2D wavelet scales are normalized by the noise variance determined from the finest wavelet scale. The variances of the coefficients at the 1D wavelet
scales are normalized using the analytic noise variance of the traces of the whitened coefficients for a grid of complex random Wishart matrices, which
corresponds to the asymptotic distributional behavior of the HPD periodogram matrices obtained with e.g., <code><a href="#topic+pdPgram2D">pdPgram2D</a></code>. Note that if the
time-frequency grid is square, i.e., <code class="reqn">n_1 = n_2</code>, the variances of the traces of the whitened coefficients are again homogeneous across all wavelet scales.
</p>


<h3>References</h3>

<p>Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.<br /><br /> Donoho D (1997).
&ldquo;CART and best-ortho-basis: a connection.&rdquo;
<em>The Annals of Statistics</em>, <b>25</b>(5), 1870&ndash;1911.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+WavTransf1D">WavTransf1D</a></code>, <code><a href="#topic+InvWavTransf1D">InvWavTransf1D</a></code>, <code><a href="#topic+WavTransf2D">WavTransf2D</a></code>, <code><a href="#topic+InvWavTransf2D">InvWavTransf2D</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## 1D tree-structured trace thresholding
P &lt;- rExamples1D(2^8, example = "bumps")$P
Coeffs &lt;- WavTransf1D(P)
pdCART(Coeffs$D, Coeffs$D.white, order = 5)$w ## logical tree of non-zero coefficients

## Not run: 
## 2D tree-structured trace thresholding
P &lt;- rExamples2D(c(2^6, 2^6), 2, example = "tvar")$P
Coeffs &lt;- WavTransf2D(P)
pdCART(Coeffs$D, Coeffs$D.white, order = c(3, 3))$w

## End(Not run)

</code></pre>

<hr>
<h2 id='pdDepth'>Data depth for HPD matrices</h2><span id='topic+pdDepth'></span>

<h3>Description</h3>

<p><code>pdDepth</code> calculates the data depth of a HPD matrix with respect
to a given data cloud (i.e., a sample or collection) of HPD matrices, or the integrated
data depth of a sequence (curve) of HPD matrices with respect to a given data cloud of
sequences (curves) of HPD matrices as detailed in (Chau et al. 2019).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdDepth(y = NULL, X, method = "gdd", metric = "Riemannian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdDepth_+3A_y">y</code></td>
<td>
<p>either a <code class="reqn">(d,d)</code>-dimensional HPD matrix, or a <code class="reqn">(d, d, n)</code>-dimensional array corresponding to a sequence
or curve of HPD matrices. Defaults to <code>NULL</code>, in which case the data depth of each individual object in <code>X</code>
with respect to the data cloud <code>X</code> itself is calculated.</p>
</td></tr>
<tr><td><code id="pdDepth_+3A_x">X</code></td>
<td>
<p>depending on the input <code>y</code>, <code>X</code> is either a <code class="reqn">(d,d,S)</code>-dimensional array corresponding to a data cloud of
<code class="reqn">S</code> individual HPD matrices, or a <code class="reqn">(d,d,n,S)</code>-dimensional array corresponding to a data cloud of <code class="reqn">S</code>
sequences or curves of <code class="reqn">n</code> individual Hermitian PD matrices.</p>
</td></tr>
<tr><td><code id="pdDepth_+3A_method">method</code></td>
<td>
<p>the data depth measure, one of <code>'gdd'</code>, <code>'zonoid'</code> or <code>'spatial'</code> corresponding to
the geodesic distance depth, intrinsic zonoid depth, and intrinsic spatial depth respectively.</p>
</td></tr>
<tr><td><code id="pdDepth_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code> or
<code>"Euclidean"</code>. See also the Details section below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Available pointwise or integrated intrinsic data depth functions for samples of HPD matrices are: (i)
geodesic distance depth, (ii) intrinsic zonoid depth and (iii) intrinsic spatial depth.
The various data depth measures and their theoretical properties are described in
(Chau et al. 2019). If <code>y</code> is a <code class="reqn">(d,d)</code>-dimensional HPD matrix, <code>X</code> should be a <code class="reqn">(d,d,S)</code>-dimensional array
corresponding to a length <code>S</code> sequence of <code class="reqn">(d,d)</code>-dimensional HPD matrices and the pointwise
data depth values are computed. If <code>y</code> is a sequence of <code class="reqn">(d,d)</code>-dimensional HPD matrices of length <code>n</code>
(i.e., <code class="reqn">(d,d,n)</code>-dimensional array), <code>X</code> should be a <code class="reqn">(d,d,n,S)</code>-dimensional array of replicated sequences of HPD matrices
and the integrated data depth values according to (Chau et al. 2019) are computed. If <code>is.null(y)</code>, the data depth
of each individual object (i.e., a HPD matrix or a sequence of HPD matrices) in <code>X</code> is computed with
respect to the data cloud <code>X</code>. <br />
The function computes the intrinsic data depth values based on the metric space of HPD matrices equipped with
one of the following metrics: (i) Riemannian metric (default) as detailed in e.g., (Bhatia 2009)[Chapter 6] or
(Pennec et al. 2006), (ii) log-Euclidean metric, the Euclidean inner product between matrix logarithms,
(iii) Cholesky metric, the Euclidean inner product between Cholesky decompositions, (iv) Euclidean metric and
(v) root-Euclidean metric. The default choice (Riemannian) has several properties not shared by the
other metrics, see (Chau et al. 2019) for more details.
</p>


<h3>Value</h3>

<p>If <code>!is.null(y)</code>, <code>pdDepth</code> returns the numeric depth value of <code>y</code> with
respect to <code>X</code>. If <code>is.null(y)</code>, <code>pdDepth</code> returns a numeric vector of length <code>S</code> corresponding to
the vector of depth values for each individual object in <code>X</code> with respect to <code>X</code> itself.
</p>


<h3>Note</h3>

<p>The function does not check for positive definiteness of the input matrices, and may fail
if matrices are close to being singular.
</p>
<p>The data depth computations under the Riemannian metric are more involved than under the other
metrics, and may therefore result in (significantly) higher computation times.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J, Ombao H, von
Sachs R (2019).
&ldquo;Intrinsic data depth for Hermitian positive definite matrices.&rdquo;
<em>Journal of Computational and Graphical Statistics</em>, <b>28</b>(2), 427&ndash;439.
doi: <a href="https://doi.org/10.1080/10618600.2018.1537926">10.1080/10618600.2018.1537926</a>.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdDist">pdDist</a></code>, <code><a href="#topic+pdRankTests">pdRankTests</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Pointwise depth
X1 &lt;- replicate(50, Expm(diag(2), H.coeff(rnorm(4), inverse = TRUE)))
pdDepth(y = diag(2), X = X1) ## depth of one point
pdDepth(X = X1) ## depth of each point in the data cloud

## Integrated depth
X2 &lt;- replicate(50, replicate(5, Expm(diag(2), H.coeff(rnorm(4), inverse = TRUE))))
pdDepth(y = replicate(5, diag(2)), X2, method = "zonoid", metric = "logEuclidean")
pdDepth(X = X2, method = "zonoid", metric = "logEuclidean")

</code></pre>

<hr>
<h2 id='pdDist'>Compute distance between two HPD matrices</h2><span id='topic+pdDist'></span>

<h3>Description</h3>

<p><code>pdDist</code> calculates a distance between two Hermitian PD matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdDist(A, B, metric = "Riemannian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdDist_+3A_a">A</code>, <code id="pdDist_+3A_b">B</code></td>
<td>
<p>Hermitian positive definite matrices (of equal dimension).</p>
</td></tr>
<tr><td><code id="pdDist_+3A_metric">metric</code></td>
<td>
<p>the distance measure, one of <code>'Riemannian'</code>,
<code>'logEuclidean'</code>, <code>'Cholesky'</code>, <code>'Euclidean'</code>, <code>'rootEuclidean'</code> or <code>'Procrustes'</code>.
Defaults to <code>'Riemannian'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Available distance measures between two HPD matrices are: (i) the affine-invariant Riemannian distance (default) as in
e.g., (Bhatia 2009)[Chapter 6] or (Pennec et al. 2006); (ii) the Log-Euclidean distance,
the Euclidean distance between matrix logarithms; (iii) the Cholesky distance, the Euclidean distance between Cholesky decompositions;
(iv) the Euclidean distance; (v) the root-Euclidean distance; and (vi) the Procrustes distance as in (Dryden et al. 2009).
In particular, <code>pdDist</code> generalizes the function <code>shapes::distcov</code>, to compute the distance between two symmetric positive
definite matrices, in order to compute the distance between two Hermitian positive definite matrices.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Dryden I, Koloydenko A, Zhou D (2009).
&ldquo;Non-Euclidean statistics for covariance matrices, with applications to diffusion tensor imaging.&rdquo;
<em>The Annals of Applied Statistics</em>, <b>3</b>(3), 1102&ndash;1123.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> a &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
 A &lt;- t(Conj(a)) %*% a
 b &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
 B &lt;- t(Conj(b)) %*% b
 pdDist(A, B) ## Riemannian distance

</code></pre>

<hr>
<h2 id='pdkMeans'>K-means clustering for HPD matrices</h2><span id='topic+pdkMeans'></span>

<h3>Description</h3>

<p><code>pdkMeans</code> performs (fuzzy) k-means clustering for collections of HPD matrices, such as covariance or
spectral density matrices, based on a number of different metrics in the space of HPD matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdkMeans(X, K, metric = "Riemannian", m = 1, eps = 1e-05,
  max_iter = 100, centroids)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdkMeans_+3A_x">X</code></td>
<td>
<p>a (<code class="reqn">d,d,S</code>)-dimensional array of (<code class="reqn">d,d</code>)-dimensional HPD matrices for <code class="reqn">S</code>
different subjects. Also accepts a (<code class="reqn">d,d,n,S</code>)-dimensional array, which is understood to be an array of
<code class="reqn">n</code>-dimensional sequences of (<code class="reqn">d,d</code>)-dimensional HPD matrices for <code class="reqn">S</code> different subjects.</p>
</td></tr>
<tr><td><code id="pdkMeans_+3A_k">K</code></td>
<td>
<p>the number of clusters, a positive integer larger than 1.</p>
</td></tr>
<tr><td><code id="pdkMeans_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code> or
<code>"Euclidean"</code>. Additional details are given below.</p>
</td></tr>
<tr><td><code id="pdkMeans_+3A_m">m</code></td>
<td>
<p>a fuzziness parameter larger or equal to <code class="reqn">1</code>. If <code class="reqn">m = 1</code> the cluster assignments are no longer fuzzy,
i.e., the procedure performs hard clustering. Defaults to <code>m = 1</code>.</p>
</td></tr>
<tr><td><code id="pdkMeans_+3A_eps">eps</code></td>
<td>
<p>an optional tolerance parameter determining the stopping criterion. The k-means algorithm
terminates if the intrinsic distance between cluster centers is smaller than <code>eps</code>, defaults to <code>eps = 1e-05</code>.</p>
</td></tr>
<tr><td><code id="pdkMeans_+3A_max_iter">max_iter</code></td>
<td>
<p>an optional parameter tuning the maximum number of iterations in the
k-means algorithm, defaults to <code>max_iter = 100</code>.</p>
</td></tr>
<tr><td><code id="pdkMeans_+3A_centroids">centroids</code></td>
<td>
<p>an optional (<code class="reqn">d,d,K</code>)- or (<code class="reqn">d,d,n,K</code>)-dimensional array depending on the input array <code>X</code>
specifying the initial cluster centroids. If not specified, <code>K</code> initial cluster centroids are randomly sampled without
replacement from the input array <code>X</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input array <code>X</code> corresponds to a collection of <code class="reqn">(d,d)</code>-dimensional HPD matrices
for <code class="reqn">S</code> different subjects. If the fuzziness parameter satisfies <code>m &gt; 1</code>, the <code class="reqn">S</code> subjects are assigned to
<code class="reqn">K</code> different clusters in a probabilistic fashion according to a fuzzy k-means algorithm as detailed in classical texts,
such as (Bezdek 1981). If <code>m = 1</code>, the <code class="reqn">S</code> subjects are assigned to the <code class="reqn">K</code> clusters in a non-probabilistic
fashion according to a standard (hard) k-means algorithm. If not specified by the user, the <code class="reqn">K</code> cluster
centers are initialized by random sampling without replacement from the input array of HPD matrices <code>X</code>.
The distance measure in the (fuzzy) k-means algorithm is induced by the metric on the space of HPD matrices specified by the user.
By default, the space of HPD matrices is equipped with (i) the affine-invariant Riemannian metric (<code>metric = 'Riemannian'</code>)
as detailed in e.g., (Bhatia 2009)[Chapter 6] or (Pennec et al. 2006). Instead, this can also be one of:
(ii) the log-Euclidean metric (<code>metric = 'logEuclidean'</code>), the Euclidean inner product between matrix logarithms;
(iii) the Cholesky metric (<code>metric = 'Cholesky'</code>), the Euclidean inner product between Cholesky decompositions; (iv) the
Euclidean metric (<code>metric = 'Euclidean'</code>); or (v) the root-Euclidean metric (<code>metric = 'rootEuclidean'</code>). The default
choice of metric (affine-invariant Riemannian) satisfies several useful properties not shared by the other metrics, see e.g.,
<cite>C18</cite>pdSpecEst for more details. Note that this comes at the cost of increased computation time in comparison to one
of the other metrics.
</p>


<h3>Value</h3>

<p>Returns a list with two components:
</p>

<dl>
<dt>cl.assignments </dt><dd><p> an (<code class="reqn">S,K</code>)-dimensional matrix, where the value at position (<code class="reqn">s,k</code>) in the
matrix corresponds to the (probabilistic or binary) cluster membership assignment of subject <code class="reqn">s</code> with respect
to cluster <code class="reqn">k</code>.</p>
</dd>
<dt>cl.centroids </dt><dd><p> either a (<code class="reqn">d,d,K</code>)- or (<code class="reqn">d,d,n,K</code>)-dimensional array depending on the input array <code>X</code>
corresponding respectively to the <code>K</code> <code class="reqn">(d,d)</code>- or (<code class="reqn">d,d,n</code>)-dimensional final cluster centroids.
</p>
</dd>
</dl>



<h3>References</h3>

<p>Bezdek J (1981).
<em>Pattern Recognition with Fuzzy Objective Function Algorithms</em>.
Plenum Press, New York.<br /><br /> Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdDist">pdDist</a></code>, <code><a href="#topic+pdSpecClust1D">pdSpecClust1D</a></code>, <code><a href="#topic+pdSpecClust2D">pdSpecClust2D</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate 20 random HPD matrices in 2 groups
m &lt;- function(rescale){
 x &lt;- matrix(complex(real = rescale * rnorm(9), imaginary = rescale * rnorm(9)), nrow = 3)
 t(Conj(x)) %*% x
}
X &lt;- array(c(replicate(10, m(0.25)), replicate(10, m(1))), dim = c(3, 3, 20))

## Compute fuzzy k-means cluster assignments
cl &lt;- pdkMeans(X, K = 2, m = 2)$cl.assignments

</code></pre>

<hr>
<h2 id='pdMean'>Weighted Karcher mean of HPD matrices</h2><span id='topic+pdMean'></span>

<h3>Description</h3>

<p><code>pdMean</code> calculates an (approximate) weighted Karcher or Frechet mean of a sample of
<code class="reqn">(d,d)</code>-dimensional HPD matrices intrinsic to a user-specified metric. In the case of the
affine-invariant Riemannian metric as detailed in e.g., (Bhatia 2009)[Chapter 6] or
(Pennec et al. 2006), the weighted Karcher mean is either approximated via
the fast recursive algorithm in (Ho et al. 2013) or computed via the slower, but more accurate,
gradient descent algorithm in (Pennec 2006). By default, the unweighted Karcher mean is computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdMean(M, w, metric = "Riemannian", grad_desc = FALSE, maxit = 1000,
  reltol)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdMean_+3A_m">M</code></td>
<td>
<p>a <code class="reqn">(d,d,S)</code>-dimensional array corresponding to a sample of <code class="reqn">(d,d)</code>-dimensional HPD matrices of
size <code class="reqn">S</code>.</p>
</td></tr>
<tr><td><code id="pdMean_+3A_w">w</code></td>
<td>
<p>an <code class="reqn">S</code>-dimensional nonnegative weight vector, such that <code>sum(w) = 1</code>.</p>
</td></tr>
<tr><td><code id="pdMean_+3A_metric">metric</code></td>
<td>
<p>the distance measure, one of <code>'Riemannian'</code>, <code>'logEuclidean'</code>,
<code>'Cholesky'</code>, <code>'Euclidean'</code> or <code>'rootEuclidean'</code>. Defaults to <code>'Riemannian'</code>.</p>
</td></tr>
<tr><td><code id="pdMean_+3A_grad_desc">grad_desc</code></td>
<td>
<p>if <code>metric = "Riemannian"</code>, a logical value indicating if the
gradient descent algorithm in (Pennec 2006) should be used, defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pdMean_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations in gradient descent algorithm, only used if
<code>grad_desc = TRUE</code> and <code>metric = "Riemannian"</code>. Defaults to <code>1000</code></p>
</td></tr>
<tr><td><code id="pdMean_+3A_reltol">reltol</code></td>
<td>
<p>optional tolerance parameter in gradient descent algorithm, only used if
<code>grad_desc = TRUE</code> and <code>metric = "Riemannian"</code>. Defaults to <code>1E-10</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function does not check for positive definiteness of the input matrices, and (depending on the
specified metric) may fail if matrices are close to being singular.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Ho J, Cheng G, Salehian H, Vemuri B (2013).
&ldquo;Recursive Karcher expectation estimators and recursive law of large numbers.&rdquo;
<em>Artificial Intelligence and Statistics</em>, 325&ndash;332.<br /><br /> Pennec X (2006).
&ldquo;Intrinsic statistics on Riemannian manifolds: Basic tools for geometric measurements.&rdquo;
<em>Journal of Mathematical Imaging and Vision</em>, <b>25</b>(1), 127&ndash;154.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Mid">Mid</a></code>, <code><a href="#topic+pdMedian">pdMedian</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate random sample of HPD matrices
m &lt;- function(){
 X &lt;- matrix(complex(real=rnorm(9), imaginary=rnorm(9)), nrow=3)
 t(Conj(X)) %*% X
}
M &lt;- replicate(100, m())
z &lt;- rnorm(100)
## Generate random weight vector
w &lt;- abs(z)/sum(abs(z))
## Compute weighted (Riemannian) Karcher mean
pdMean(M, w)

</code></pre>

<hr>
<h2 id='pdMedian'>Weighted intrinsic median of HPD matrices</h2><span id='topic+pdMedian'></span>

<h3>Description</h3>

<p><code>pdMedian</code> calculates a weighted intrinsic median of a sample of <code class="reqn">(d,d)</code>-dimensional
HPD matrices based on a Weiszfeld algorithm intrinsic to the chosen metric.In the case of the
affine-invariant Riemannian metric as detailed in e.g., (Bhatia 2009)[Chapter 6] or
(Pennec et al. 2006), the intrinsic Weiszfeld algorithm in (Fletcher et al. 2009) is used.
By default, the unweighted intrinsic median is computed.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdMedian(M, w, metric = "Riemannian", maxit = 1000, reltol)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdMedian_+3A_m">M</code></td>
<td>
<p>a <code class="reqn">(d,d,S)</code>-dimensional array corresponding to a sample of <code class="reqn">(d,d)</code>-dimensional HPD matrices of
size <code class="reqn">S</code>.</p>
</td></tr>
<tr><td><code id="pdMedian_+3A_w">w</code></td>
<td>
<p>an <code class="reqn">S</code>-dimensional nonnegative weight vector, such that <code>sum(w) = 1</code>.</p>
</td></tr>
<tr><td><code id="pdMedian_+3A_metric">metric</code></td>
<td>
<p>the distance measure, one of <code>'Riemannian'</code>, <code>'logEuclidean'</code>,
<code>'Cholesky'</code>, <code>'Euclidean'</code> or <code>'rootEuclidean'</code>. Defaults to <code>'Riemannian'</code>.</p>
</td></tr>
<tr><td><code id="pdMedian_+3A_maxit">maxit</code></td>
<td>
<p>maximum number of iterations in gradient descent algorithm. Defaults to <code>1000</code></p>
</td></tr>
<tr><td><code id="pdMedian_+3A_reltol">reltol</code></td>
<td>
<p>optional tolerance parameter in gradient descent algorithm. Defaults to <code>1E-10</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function does not check for positive definiteness of the input matrices, and (depending on the
specified metric) may fail if matrices are close to being singular.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Fletcher P, Venkatasubramanian S, Joshi S (2009).
&ldquo;The geometric median on Riemannian manifolds with application to robust atlas estimation.&rdquo;
<em>NeuroImage</em>, <b>45</b>(1), S143&ndash;S152.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdMean">pdMean</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Generate random sample of HPD matrices
m &lt;- function(){
 X &lt;- matrix(complex(real=rnorm(9), imaginary=rnorm(9)), nrow=3)
 t(Conj(X)) %*% X
}
M &lt;- replicate(100, m())
## Generate random weight vector
z &lt;- rnorm(100)
w &lt;- abs(z)/sum(abs(z))
## Compute weighted intrinsic (Riemannian) median
pdMedian(M, w)

</code></pre>

<hr>
<h2 id='pdNeville'>Polynomial interpolation of curves (1D) or surfaces (2D) of HPD matrices</h2><span id='topic+pdNeville'></span>

<h3>Description</h3>

<p><code>pdNeville</code> performs intrinsic polynomial interpolation of curves or surfaces of HPD matrices
in the metric space of HPD matrices equipped with the affine-invariant Riemannian metric (see (Bhatia 2009)[Chapter 6]
or (Pennec et al. 2006)) via Neville's algorithm based on iterative geodesic interpolation detailed
in (Chau and von
Sachs 2019) and in Chapter 3 and 5 of (Chau 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdNeville(P, X, x, metric = "Riemannian")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdNeville_+3A_p">P</code></td>
<td>
<p>for polynomial curve interpolation, a <code class="reqn">(d, d, N)</code>-dimensional array corresponding to a length <code class="reqn">N</code> sequence
of <code class="reqn">(d, d)</code>-dimensional HPD matrices (control points) through which the interpolating polynomial
curve passes. For polynomial surface interpolation, a <code class="reqn">(d, d, N_1, N_2)</code>-dimensional array corresponding
to a tensor product grid of <code class="reqn">(d, d)</code>-dimensional HPD matrices (control points) through which the interpolating
polynomial surface passes.</p>
</td></tr>
<tr><td><code id="pdNeville_+3A_x">X</code></td>
<td>
<p>for polynomial curve interpolation, a numeric vector of length <code class="reqn">N</code> specifying the time points at which
the interpolating polynomial passes through the control points <code>P</code>. For polynomial surface interpolation, a list
with as elements two numeric vectors <code>x</code> and <code>y</code> of length <code class="reqn">N_1</code> and <code class="reqn">N_2</code> respectively. The numeric
vectors specify the time points on the tensor product grid <code>expand.grid(X$x, X$y)</code> at which the interpolating
polynomial passes trough the control points <code>P</code>.</p>
</td></tr>
<tr><td><code id="pdNeville_+3A_x">x</code></td>
<td>
<p>for polynomial curve interpolation, a numeric vector specifying the time points (locations) at which the
interpolating polynomial is evaluated. For polynomial surface interpolation, a list with as elements two numeric vectors
<code>x</code> and <code>y</code> specifying the time points (locations) on the tensor product grid <code>expand.grid(x$x, x$y)</code> at which the
interpolating polynomial surface is evaluated.</p>
</td></tr>
<tr><td><code id="pdNeville_+3A_metric">metric</code></td>
<td>
<p>the metric on the space of HPD matrices, by default <code>metric = "Riemannian"</code>, but instead of the Riemannian metric
this can also be set to <code>metric = "Euclidean"</code> to perform (standard) Euclidean polynomial interpolation of curves or
surfaces in the space of HPD matrices.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For polynomial curve interpolation, given <code class="reqn">N</code> control points (i.e., HPD matrices), the degree of the
interpolated polynomial is <code class="reqn">N - 1</code>. For polynomial surface interpolation, given <code class="reqn">N_1 \times N_2</code> control points
(i.e., HPD matrices) on a tensor product grid, the interpolated polynomial surface is of bi-degree <code class="reqn">(N_1 - 1, N_2 - 1)</code>.
Depending on the input array <code>P</code>, the function decides whether polynomial curve or polynomial surface interpolation
is performed.
</p>


<h3>Value</h3>

<p>For polynomial curve interpolation, a <code>(d, d, length(x))</code>-dimensional array corresponding to the interpolating polynomial
curve of <code class="reqn">(d,d)</code>-dimensional matrices of degree <code class="reqn">N-1</code> evaluated at times <code>x</code> and passing through the control points <code>P</code>
at times <code>X</code>. For polynomial surface interpolation, a <code>(d, d, length(x$x), length(x$y))</code>-dimensional array corresponding to the
interpolating polynomial surface of <code class="reqn">(d,d)</code>-dimensional matrices of bi-degree <code class="reqn">N_1 - 1, N_2 - 1</code> evaluated at times <code>expand.grid(x$x, x$y)</code>
and passing through the control points <code>P</code> at times <code>expand.grid(X$x, X$y)</code>.
</p>


<h3>Note</h3>

<p>If <code>metric = "Euclidean"</code>, the interpolating curve or surface may not be positive definite everywhere as the space of HPD
matrices equipped with the Euclidean metric has its boundary at a finite distance.
</p>
<p>The function does not check for positive definiteness of the input matrices, and may fail if <code>metric = "Riemannian"</code> and
the input matrices are close to being singular.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdPolynomial">pdPolynomial</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>### Polynomial curve interpolation
P &lt;- rExamples1D(50, example = 'gaussian')$f[, , 10*(1:5)]
P.poly &lt;- pdNeville(P, (1:5)/5, (1:50)/50)
## Examine matrix-component (1,1)
plot((1:50)/50, Re(P.poly[1, 1, ]), type = "l") ## interpolated polynomial
lines((1:5)/5, Re(P[1, 1, ]), col = 2) ## control points

### Polynomial surface interpolation
P.surf &lt;- array(P[, , 1:4], dim = c(2,2,2,2)) ## control points
P.poly &lt;- pdNeville(P.surf, list(x = c(0, 1), y = c(0, 1)), list(x = (0:10)/10, y = (0:10)/10))

</code></pre>

<hr>
<h2 id='pdParTrans'>Riemannian HPD parallel transport</h2><span id='topic+pdParTrans'></span>

<h3>Description</h3>

<p><code>pdParTrans</code> computes the parallel transport on the manifold of HPD matrices
equipped with the affine-invariant Riemannian metric as described in e.g., Chapter 2 of (Chau 2018). That is,
the function computes the parallel transport of a Hermitian matrix <code>W</code> in the tangent space
at the HPD matrix <code>P</code> along a geodesic curve in the direction of the Hermitian matrix <code>V</code>
in the tangent space at <code>P</code> for a unit time step.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdParTrans(P, V, W)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdParTrans_+3A_p">P</code></td>
<td>
<p>a <code class="reqn">(d,d)</code>-dimensional HPD matrix.</p>
</td></tr>
<tr><td><code id="pdParTrans_+3A_v">V</code></td>
<td>
<p>a <code class="reqn">(d,d)</code>-dimensional Hermitian matrix corresponding to a vector in the tangent space of <code>P</code>.</p>
</td></tr>
<tr><td><code id="pdParTrans_+3A_w">W</code></td>
<td>
<p>a <code class="reqn">(d,d)</code>-dimensional Hermitian matrix corresponding to a vector in the tangent space of <code>P</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>a <code class="reqn">(d,d)</code>-dimensional Hermitian matrix corresponding to the parallel transportation of <code>W</code> in
the direction of <code>V</code> along a geodesic curve for a unit time step.
</p>


<h3>References</h3>

<p>Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+Expm">Expm</a>, <a href="#topic+Logm">Logm</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Transport the vector W to the tangent space at the identity
W &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
diag(W) &lt;- rnorm(3)
W[lower.tri(W)] &lt;- t(Conj(W))[lower.tri(W)]
p &lt;- matrix(complex(real = rnorm(9), imaginary = rnorm(9)), nrow = 3)
P &lt;- t(Conj(p)) %*% p

pdParTrans(P, Logm(P, diag(3)), W) ## whitening transport

</code></pre>

<hr>
<h2 id='pdPgram'>Multitaper HPD periodogram matrix</h2><span id='topic+pdPgram'></span>

<h3>Description</h3>

<p>Given a multivariate time series, <code>pdPgram</code> computes a multitapered HPD periodogram matrix based on
averaging raw Hermitian PSD periodogram matrices of tapered multivariate time series segments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdPgram(X, B, method = c("multitaper", "bartlett"), bias.corr = F,
  nw = 3)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdPgram_+3A_x">X</code></td>
<td>
<p>an (<code class="reqn">n,d</code>)-dimensional matrix corresponding to a multivariate time series,
with the <code>d</code> columns corresponding to the components of the time series.</p>
</td></tr>
<tr><td><code id="pdPgram_+3A_b">B</code></td>
<td>
<p>depending on the argument <code>method</code>, either the number of orthogonal DPSS tapers, or the number of
non-overlapping segments to compute Bartlett's averaged periodogram. By default,
<code>B = d</code>, such that the averaged periodogram is guaranteed to be positive definite.</p>
</td></tr>
<tr><td><code id="pdPgram_+3A_method">method</code></td>
<td>
<p>the tapering method, either <code>"multitaper"</code> or <code>"bartlett"</code> explained in the Details
section below. Defaults to <code>"multitaper"</code>.</p>
</td></tr>
<tr><td><code id="pdPgram_+3A_bias.corr">bias.corr</code></td>
<td>
<p>should an asymptotic bias-correction under the affine-invariant Riemannian metric be applied to
the HPD periodogram matrix? Defaults to <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="pdPgram_+3A_nw">nw</code></td>
<td>
<p>a positive numeric value corresponding to the time-bandwidth parameter of the DPSS tapering functions,
see also <code><a href="multitaper.html#topic+dpss">dpss</a></code>, defaults to <code>nw = 3</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method = "multitaper"</code>, <code>pdPgram</code> calculates a <code class="reqn">(d,d)</code>-dimensional multitaper
periodogram matrix based on <code class="reqn">B</code> DPSS (Discrete Prolate Spheroidal Sequence or Slepian) orthogonal tapering functions
as in <code><a href="multitaper.html#topic+dpss">dpss</a></code> applied to the <code class="reqn">d</code>-dimensional time series <code>X</code>. If <code>method = "bartlett"</code>,
<code>pdPgram</code> computes a Bartlett spectral estimator by averaging the periodogram matrices of <code>B</code> non-overlapping
segments of the <code class="reqn">d</code>-dimensional time series <code>X</code>. Note that Bartlett's spectral estimator is a
specific (trivial) case of a multitaper spectral estimator with uniform orthogonal tapering windows.<br />
In the case of subsequent periodogram matrix denoising in the space of HPD matrices equipped with the
affine-invariant Riemannian metric, one should set <code>bias.corr = T</code>, thereby correcting for the asymptotic
bias of the periodogram matrix in the manifold of HPD matrices equipped with the affine-invariant metric as explained in
(Chau and von
Sachs 2019) and Chapter 3 of (Chau 2018). The pre-smoothed HPD periodogram matrix
(i.e., an initial noisy HPD spectral estimator) can be given as input to the function <code><a href="#topic+pdSpecEst1D">pdSpecEst1D</a></code> to perform
intrinsic wavelet-based spectral matrix estimation. In this case, set <code>bias.corr = F</code> (the default) as the appropriate
bias-corrections are applied internally by the function <code><a href="#topic+pdSpecEst1D">pdSpecEst1D</a></code>.
</p>


<h3>Value</h3>

<p>A list containing two components:
</p>
<table role = "presentation">
<tr><td><code>freq</code></td>
<td>
<p> vector of <code class="reqn">n/2</code> frequencies in the range <code class="reqn">[0,0.5)</code> at which the periodogram is evaluated.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p> a <code class="reqn">(d, d, n/2)</code>-dimensional array containing the
(<code class="reqn">d,d</code>)-dimensional multitaper periodogram matrices at frequencies corresponding
to <code>freq</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdPgram2D">pdPgram2D</a></code>, <code><a href="multitaper.html#topic+dpss">dpss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## ARMA(1,1) process: Example 11.4.1 in (Brockwell and Davis, 1991)
Phi &lt;- array(c(0.7, 0, 0, 0.6, rep(0, 4)), dim = c(2, 2, 2))
Theta &lt;- array(c(0.5, -0.7, 0.6, 0.8, rep(0, 4)), dim = c(2, 2, 2))
Sigma &lt;- matrix(c(1, 0.71, 0.71, 2), nrow = 2)
ts.sim &lt;- rARMA(200, 2, Phi, Theta, Sigma)
ts.plot(ts.sim$X) # plot generated time series traces
pgram &lt;- pdPgram(ts.sim$X)

</code></pre>

<hr>
<h2 id='pdPgram2D'>Multitaper HPD time-varying periodogram matrix</h2><span id='topic+pdPgram2D'></span>

<h3>Description</h3>

<p>Given a multivariate time series, <code>pdPgram2D</code> computes a multitapered HPD time-varying periodogram matrix based on
averaging raw Hermitian PSD time-varying periodogram matrices of tapered multivariate time series segments.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdPgram2D(X, B, tf.grid, method = c("dpss", "hermite"), nw = 3,
  bias.corr = F)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdPgram2D_+3A_x">X</code></td>
<td>
<p>an (<code class="reqn">n,d</code>)-dimensional matrix corresponding to a multivariate time series,
with the <code>d</code> columns corresponding to the components of the time series.</p>
</td></tr>
<tr><td><code id="pdPgram2D_+3A_b">B</code></td>
<td>
<p>depending on the argument <code>method</code>, either the number of orthogonal DPSS or Hermite tapering functions.
By default, <code>B = d</code>, such that the multitaper periodogram is guaranteed to be positive definite.</p>
</td></tr>
<tr><td><code id="pdPgram2D_+3A_tf.grid">tf.grid</code></td>
<td>
<p>a list with two components <code>tf.grid$time</code> and <code>tf.grid$frequency</code> specifying the
rectangular grid of time-frequency points at which the multitaper periodogram is evaluated. <code>tf.grid$time</code>
should be a numeric vector of rescaled time points in the range <code>(0,1)</code>. <code>tf.grid$frequency</code> should be a numeric
vector of frequency points in the range <code>(0,0.5)</code>, with 0.5 corresponding to the Nyquist frequency.</p>
</td></tr>
<tr><td><code id="pdPgram2D_+3A_method">method</code></td>
<td>
<p>the tapering method, either <code>"dpss"</code> or <code>"hermite"</code> explained in the Details
section below. Defaults to <code>method = "dpss"</code>.</p>
</td></tr>
<tr><td><code id="pdPgram2D_+3A_nw">nw</code></td>
<td>
<p>a positive numeric value corresponding to the time-bandwidth parameter of the tapering functions,
see also <code><a href="multitaper.html#topic+dpss">dpss</a></code>, defaults to <code>nw = 3</code>. Both the DPSS and Hermite tapers are
rescaled with the same time-bandwidth parameter.</p>
</td></tr>
<tr><td><code id="pdPgram2D_+3A_bias.corr">bias.corr</code></td>
<td>
<p>should an asymptotic bias-correction under the affine-invariant Riemannian metric be applied to
the HPD periodogram matrix? Defaults to <code>FALSE</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method = "dpss"</code>, <code>pdPgram2D</code> calculates a <code class="reqn">(d,d)</code>-dimensional multitaper time-varying
periodogram matrix based on sliding <code class="reqn">B</code> DPSS (Discrete Prolate Spheroidal Sequence or Slepian) orthogonal tapering functions
as in <code><a href="multitaper.html#topic+dpss">dpss</a></code> applied to the <code class="reqn">d</code>-dimensional time series <code>X</code>. If <code class="reqn">B \ge d</code>, the
multitaper time-varying periodogram matrix is guaranteed to be positive definite at each time-frequency point in the
grid <code>expand.grid(tf.grid$time, tf.grid$frequency)</code>. In short, the function <code>pdPgram2D</code> computes a multitaper
periodogram matrix (as in <code><a href="#topic+pdPgram">pdPgram</a></code>) in each of a number of non-overlapping time series
segments of <code>X</code>, with the time series segments centered around the (rescaled) time points in <code>tf.grid$time</code>.
If <code>method = "hermite"</code>, the function calculates a multitaper time-varying periodogram matrix replacing the DPSS
tapers by orthogonal Hermite tapering functions as in e.g., (Bayram and Baraniuk 1996). <br />
In the case of subsequent periodogram matrix denoising in the space of HPD matrices equipped with the
affine-invariant Riemannian metric, one should set <code>bias.corr = T</code>, thereby correcting for the asymptotic
bias of the periodogram matrix in the manifold of HPD matrices equipped with the affine-invariant metric as explained in
(Chau and von
Sachs 2019) and Chapter 3 and 5 of (Chau 2018). The pre-smoothed HPD periodogram matrix
(i.e., an initial noisy HPD spectral estimator) can be given as input to the function <code><a href="#topic+pdSpecEst2D">pdSpecEst2D</a></code> to perform
intrinsic wavelet-based time-varying spectral matrix estimation. In this case, set <code>bias.corr = F</code> (the default) as the
appropriate bias-corrections are applied internally by the function <code><a href="#topic+pdSpecEst2D">pdSpecEst2D</a></code>.
</p>


<h3>Value</h3>

<p>A list containing two components:
</p>
<table role = "presentation">
<tr><td><code>tf.grid</code></td>
<td>
<p> a list with two components corresponding to the rectangular grid of time-frequency points
at which the multitaper periodogram is evaluated.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p> a <code class="reqn">(d,d,m_1,m_2)</code>-dimensional array with <code>m_1 = length(tf.grid$time)</code> and
<code>m_2 = length(tf.grid$frequency)</code> corresponding to the (<code class="reqn">d,d</code>)-dimensional tapered periodogram matrices
evaluated at the time-frequency points in <code>tf.grid</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bayram M, Baraniuk R (1996).
&ldquo;Multiple window time-frequency analysis.&rdquo;
In <em>Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis</em>, 173&ndash;176.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdPgram">pdPgram</a></code>, <code><a href="multitaper.html#topic+dpss">dpss</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Coefficient matrices
Phi1 &lt;- array(c(0.4, 0, 0, 0.8, rep(0, 4)), dim = c(2, 2, 2))
Phi2 &lt;- array(c(0.8, 0, 0, 0.4, rep(0, 4)), dim = c(2, 2, 2))
Theta &lt;- array(c(0.5, -0.7, 0.6, 0.8, rep(0, 4)), dim = c(2, 2, 2))
Sigma &lt;- matrix(c(1, 0.71, 0.71, 2), nrow = 2)

## Generate piecewise stationary time series
ts.Phi &lt;- function(Phi) rARMA(2^9, 2, Phi, Theta, Sigma)$X
ts &lt;- rbind(ts.Phi(Phi1), ts.Phi(Phi2))

pgram &lt;- pdPgram2D(ts)

</code></pre>

<hr>
<h2 id='pdPolynomial'>Generate intrinsic HPD polynomial curves</h2><span id='topic+pdPolynomial'></span>

<h3>Description</h3>

<p><code>pdPolynomial</code> generates intrinsic polynomial curves in the manifold of HPD matrices
equipped with the affine-invariant Riemannian metric (see (Bhatia 2009)[Chapter 6]
or (Pennec et al. 2006)) according to the numerical integration procedure in (Hinkle et al. 2014).
Given an initial starting point <code>p0</code> (i.e., a HPD matrix) in the Riemannian manifold and covariant
derivatives up to order <code class="reqn">k - 1</code> at <code>p0</code>, <code>pdPolynomial</code> approximates the uniquely existing
intrinsic polynomial curve of degree <code class="reqn">k</code> passing through <code>p0</code> with the given covariant derivatives up
to order <code class="reqn">k - 1</code> and vanishing higher order covariant derivatives.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdPolynomial(p0, v0, delta.t = 0.01, steps = 100)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdPolynomial_+3A_p0">p0</code></td>
<td>
<p>a <code class="reqn">(d, d)</code>-dimensional HPD matrix specifying the starting point of the polynomial curve.</p>
</td></tr>
<tr><td><code id="pdPolynomial_+3A_v0">v0</code></td>
<td>
<p>a <code class="reqn">(d, d, k)</code>-dimensional array corresponding to a sequence of <code class="reqn">(d,d)</code>-dimensional Hermitian matrix-valued
covariant derivatives from order zero up to order <code class="reqn">k - 1</code> at the starting point <code>p0</code>.</p>
</td></tr>
<tr><td><code id="pdPolynomial_+3A_delta.t">delta.t</code></td>
<td>
<p>a numeric value determining the incrementing step size in the numerical integration procedure.
A smaller step size results in a higher resolution and therefore a more accurate approximation of the polynomial curve,
defaults to <code>delta.t = 0.01</code>.</p>
</td></tr>
<tr><td><code id="pdPolynomial_+3A_steps">steps</code></td>
<td>
<p>number of incrementing steps in the numerical integration procedure, defaults to <code>steps = 100</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>(d, d, length(steps))</code>-dimensional array corresponding to a generated (approximate)
intrinsic polynomial curve in the space of <code class="reqn">(d,d)</code>-dimensional HPD matrices of degree <code class="reqn">k</code>
passing through <code>p0</code> with the given covariant derivatives <code>v0</code> up to order <code class="reqn">k - 1</code>
and vanishing higher order covariant derivatives.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Hinkle J, Fletcher P, Joshi S (2014).
&ldquo;Intrinsic polynomials for regression on Riemannian manifolds.&rdquo;
<em>Journal of Mathematical Imaging and Vision</em>, <b>50</b>(1-2), 32&ndash;52.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdNeville">pdNeville</a></code>, <code><a href="#topic+pdParTrans">pdParTrans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## First-order polynomial
p0 &lt;- diag(3) ## HPD starting point
v0 &lt;- array(H.coeff(rnorm(9), inverse = TRUE), dim = c(3, 3, 1)) ## zero-th order cov. derivative
P.poly &lt;- pdPolynomial(p0, v0)

## First-order polynomials coincide with geodesic curves
P.geo &lt;- sapply(seq(0, 1, length = 100), function(t) Expm(p0, t * Logm(p0, P.poly[, , 100])),
               simplify = "array")
all.equal(P.poly, P.geo)

</code></pre>

<hr>
<h2 id='pdRankTests'>Rank-based hypothesis tests for HPD matrices</h2><span id='topic+pdRankTests'></span>

<h3>Description</h3>

<p><code>pdRankTests</code> performs a number of generalized rank-based hypothesis tests in the metric space of HPD matrices equipped
with the affine-invariant Riemannian metric or Log-Euclidean metric for samples of HPD matrices or samples of sequences
(curves) of HPD matrices as described in Chapter 4 of (Chau 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdRankTests(data, sample_sizes, test = c("rank.sum", "krusk.wall",
  "signed.rank", "bartels"), depth = c("gdd", "zonoid", "spatial"),
  metric = c("Riemannian", "logEuclidean"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdRankTests_+3A_data">data</code></td>
<td>
<p>either a <code class="reqn">(d,d,S)</code>-dimensional array corresponding to an array of pooled individual samples of <code class="reqn">(d,d)</code>-dimensional
HPD matrices, or a <code class="reqn">(d,d,n,S)</code>-dimensional array corresponding to an array of pooled individual samples of length <code class="reqn">n</code> sequences
of <code class="reqn">(d,d)</code>-dimensional HPD matrices.</p>
</td></tr>
<tr><td><code id="pdRankTests_+3A_sample_sizes">sample_sizes</code></td>
<td>
<p>a numeric vector specifying the individual sample sizes in the pooled sample <code>data</code>, such that <code>sum(sample_sizes)</code> is
equal to <code>S</code>. Not required for tests <code>"signed-rank"</code> and <code>"bartels"</code>, as the sample sizes are automatically determined from the input array
<code>data</code>.</p>
</td></tr>
<tr><td><code id="pdRankTests_+3A_test">test</code></td>
<td>
<p>rank-based hypothesis testing procedure, one of <code>"rank.sum"</code>, <code>"krusk.wall"</code>, <code>"signed.rank"</code>, <code>"bartels"</code> explained
in the Details section below.</p>
</td></tr>
<tr><td><code id="pdRankTests_+3A_depth">depth</code></td>
<td>
<p>data depth measure used in the rank-based tests, one of <code>"gdd"</code>, <code>"zonoid"</code>, or <code>"spatial"</code> corresponding to the
geodesic distance depth, intrinsic zonoid depth and intrinsic spatial depth respectively. Defaults to <code>"gdd"</code>. Not required for test
<code>"signed.rank"</code>. See the documentation of the function <code><a href="#topic+pdDepth">pdDepth</a></code> for additional details about the different depth measures.</p>
</td></tr>
<tr><td><code id="pdRankTests_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with, either <code>"Riemannian"</code> or <code>"logEuclidean"</code>. Defaults to
<code>"Riemannian"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For samples of <code class="reqn">(d,d)</code>-dimensional HPD matrices with pooled sample size <code class="reqn">S</code>, the argument
<code>data</code> is a <code class="reqn">(d,d,S)</code>-dimensional array of <code class="reqn">(d,d)</code>-dimensional HPD matrices, where the individual samples are
combined along the third array dimension. For samples of sequences of <code class="reqn">(d,d)</code>-dimensional HPD matrices with pooled sample
size <code class="reqn">S</code>, the argument <code>data</code> is a <code class="reqn">(d,d,n,S)</code>-dimensional array of length <code class="reqn">n</code> sequences
of <code class="reqn">(d,d)</code>-dimensional HPD matrices, where the individual samples are combined along the fourth array dimension. The argument
<code>sample_sizes</code> specifies the sizes of the individual samples so that <code>sum(sample_sizes)</code> is equal to <code>S</code>. <br />
The available generalized rank-based testing procedures (specified by the argument <code>test</code>) are:
</p>

<dl>
<dt><code>"rank.sum"</code></dt><dd><p>Intrinsic Wilcoxon rank-sum test to test for homogeneity of distributions of two independent
samples of HPD matrices or samples of sequences of HPD matrices. The usual univariate ranks are replaced by data depth
induced ranks obtained with <code><a href="#topic+pdDepth">pdDepth</a></code>.</p>
</dd>
<dt><code>"krusk.wall"</code></dt><dd><p>Intrinsic Kruskal-Wallis test to test for homogeneity of distributions of more than two independent
samples of HPD matrices or samples of sequences of HPD matrices. The usual univariate ranks are replaced by data depth
induced ranks obtained with <code><a href="#topic+pdDepth">pdDepth</a></code>.</p>
</dd>
<dt><code>"signed.rank"</code></dt><dd><p>Intrinsic signed-rank test to test for homogeneity of distributions of independent paired or matched samples
of HPD matrices. The intrinsic signed-rank test is <em>not</em> based on data depth induced ranks, but on a specific difference score in the Riemannian
manifold of HPD matrices equipped with either the affine-invariant Riemannian or Log-Euclidean metric.</p>
</dd>
<dt><code>"bartels"</code></dt><dd><p>Intrinsic Bartels-von Neumann test to test for randomness (i.e., exchangeability) within a single independent sample of
HPD matrices or a sample of sequences of HPD matrices. The usual univariate ranks are replaced by data depth induced
ranks obtained with <code><a href="#topic+pdDepth">pdDepth</a></code>.</p>
</dd>
</dl>

<p>The function computes the generalized rank-based test statistics in the <em>complete</em> metric space of HPD matrices equipped with one of the following metrics:
(i) the Riemannian metric (default) as detailed in e.g., (Bhatia 2009)[Chapter 6] or (Pennec et al. 2006); or (ii) the Log-Euclidean metric,
the Euclidean inner product between matrix logarithms. The default Riemannian metric is invariant under congruence transformation by any invertible matrix,
whereas the Log-Euclidean metric is only invariant under congruence transformation by unitary matrices, see (Chau 2018)[Chapter 4] for more details.
</p>


<h3>Value</h3>

<p>The function returns a list with five components:
</p>
<table role = "presentation">
<tr><td><code>test</code></td>
<td>
<p>name of the rank-based test</p>
</td></tr>
<tr><td><code>p.value</code></td>
<td>
<p>p-value of the test</p>
</td></tr>
<tr><td><code>statistic</code></td>
<td>
<p>computed test statistic</p>
</td></tr>
<tr><td><code>null.distr</code></td>
<td>
<p>distribution of the test statistic under the null hypothesis</p>
</td></tr>
<tr><td><code>depth.values</code></td>
<td>
<p>computed data depth values (if available)</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The intrinsic signed-rank test also provides a valid test for equivalence of spectral matrices of two multivariate stationary time
series based on the HPD periodogram matrices obtained via <code><a href="#topic+pdPgram">pdPgram</a></code>, see (Chau 2018)[Chapter 4] for the details.
</p>
<p>The function does not check for positive definiteness of the input matrices, and may fail
if matrices are close to being singular.
</p>
<p>The data depth computations under the Riemannian metric are more involved than under the Log-Euclidean
metric, and may therefore result in (significantly) higher computation times.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdDepth">pdDepth</a></code>, <code><a href="#topic+pdPgram">pdPgram</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## null hypothesis is true
data &lt;- replicate(100, Expm(diag(2), H.coeff(rnorm(4), inverse = TRUE)))
pdRankTests(data, sample_sizes = c(50, 50), test = "rank.sum") ## homogeneity 2 samples
pdRankTests(data, sample_sizes = rep(25, 4), test = "krusk.wall") ## homogeneity 4 samples
pdRankTests(data, test = "bartels") ## randomness

## null hypothesis is false
data1 &lt;- array(c(data, replicate(50, Expm(diag(2), H.coeff(0.5 * rnorm(4), inverse = TRUE)))),
                 dim = c(2,2,150))
pdRankTests(data1, sample_sizes = c(100, 50), test = "rank.sum")
pdRankTests(data1, sample_sizes = rep(50, 3), test = "krusk.wall")
pdRankTests(data1, test = "bartels")

## Not run: 
## signed-rank test for equivalence of spectra of multivariate time series
## ARMA(1,1) process: Example 11.4.1 in (Brockwell and Davis, 1991)
Phi &lt;- array(c(0.7, 0, 0, 0.6, rep(0, 4)), dim = c(2, 2, 2))
Theta &lt;- array(c(0.5, -0.7, 0.6, 0.8, rep(0, 4)), dim = c(2, 2, 2))
Sigma &lt;- matrix(c(1, 0.71, 0.71, 2), nrow = 2)
pgram &lt;- function(Sigma) pdPgram(rARMA(2^8, 2, Phi, Theta, Sigma)$X)$P

## null is true
pdRankTests(array(c(pgram(Sigma), pgram(Sigma)), dim = c(2,2,2^8)), test = "signed.rank")
## null is false
pdRankTests(array(c(pgram(Sigma), pgram(0.5 * Sigma)), dim = c(2,2,2^8)), test = "signed.rank")

## End(Not run)
</code></pre>

<hr>
<h2 id='pdSpecClust1D'>Intrinsic wavelet HPD spectral matrix clustering</h2><span id='topic+pdSpecClust1D'></span>

<h3>Description</h3>

<p><code>pdSpecClust1D</code> performs clustering of HPD spectral matrices corrupted by noise (e.g. HPD periodograms)
by combining wavelet thresholding and fuzzy clustering in the intrinsic wavelet coefficient domain according to
the following steps:
</p>

<ol>
<li><p> Transform a collection of noisy HPD spectral matrices to the intrinsic wavelet domain and denoise the
HPD matrix curves by (tree-structured) thresholding of wavelet coefficients with <code><a href="#topic+pdSpecEst1D">pdSpecEst1D</a></code>.
</p>
</li>
<li><p> Apply an intrinsic fuzzy c-means algorithm to the coarsest midpoints at scale <code>j = 0</code> across subjects.
</p>
</li>
<li><p> Taking into account the fuzzy cluster assignments in the previous step, apply a weighted fuzzy c-means
algorithm to the nonzero thresholded wavelet coefficients across subjects from scale <code>j = 1</code> up to <code>j = jmax</code>.
</p>
</li></ol>

<p>More details can be found in Chapter 3 of (Chau 2018) and the accompanying vignettes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdSpecClust1D(P, K, jmax, metric = "Riemannian", m = 2, d.jmax = 0.1,
  eps = c(1e-04, 1e-04), tau = 0.5, max_iter = 50,
  return.centers = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdSpecClust1D_+3A_p">P</code></td>
<td>
<p>a (<code class="reqn">d,d,n,S</code>)-dimensional array of HPD matrices, corresponding to a collection of sequences of
<code class="reqn">(d,d)</code>-dimensional HPD matrices of length <code class="reqn">n</code>, with <code class="reqn">n = 2^J</code> for some <code class="reqn">J &gt; 0</code>, for <code class="reqn">S</code> different
subjects.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_k">K</code></td>
<td>
<p>the number of clusters, a positive integer larger than 1.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_jmax">jmax</code></td>
<td>
<p>an upper bound on the maximum wavelet scale to be considered in the clustering procedure. If
<code>jmax</code> is not specified, it is set equal to the maximum (i.e., finest) wavelet scale minus 2.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code> or
<code>"Euclidean"</code>. Additional details are given below.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_m">m</code></td>
<td>
<p>the fuzziness parameter for both fuzzy c-means algorithms. <code>m</code> should be larger or equal to <code class="reqn">1</code>.
If <code class="reqn">m = 1</code> the cluster assignments are no longer fuzzy, i.e., the procedure
performs hard clustering.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_d.jmax">d.jmax</code></td>
<td>
<p>a proportion that is used to determine the maximum wavelet scale to be considered in the clustering
procedure. A larger value <code>d.jmax</code> leads to less wavelet coefficients being taken into account, and therefore
lower computational effort in the procedure. If <code>d.jmax</code> is not specified, by default <code>d.jmax = 0.1</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_eps">eps</code></td>
<td>
<p>an optional vector with two components determining the stopping criterion. The first step in the cluster procedure
terminates if the (integrated) intrinsic distance between cluster centers is smaller than <code>eps[1]</code>.
The second step in the cluster procedure terminates if the (integrated) Euclidean distance between cluster centers is smaller
than <code>eps[2]</code>. By default <code>eps = c(1e-04, 1e-04)</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_tau">tau</code></td>
<td>
<p>an optional argument tuning the weight given to the cluster assignments obtained in the first step of
the clustering algorithm. If <code>tau</code> is not specified, by default <code>tau = 0.5</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_max_iter">max_iter</code></td>
<td>
<p>an optional argument tuning the maximum number of iterations in both the first and second step of the
clustering algorithm, defaults to <code>max_iter = 50</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_return.centers">return.centers</code></td>
<td>
<p>should the cluster centers transformed back the space of HPD matrices also be returned?
Defaults to <code>return.centers = FALSE</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust1D_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to <code><a href="#topic+pdSpecEst1D">pdSpecEst1D</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input array <code>P</code> corresponds to a collection of initial noisy HPD spectral estimates of the <code class="reqn">(d,d)</code>-dimensional
spectral matrix at <code>n</code> different frequencies, with <code class="reqn">n = 2^J</code> for some <code class="reqn">J &gt; 0</code>, for <code class="reqn">S</code> different subjects.
These can be e.g., multitaper HPD periodograms given as output by the function <code><a href="#topic+pdPgram">pdPgram</a></code>.<br />
First, for each subject <code class="reqn">s = 1,\ldots,S</code>, thresholded wavelet coefficients in the intrinsic wavelet domain are
calculated by <code><a href="#topic+pdSpecEst1D">pdSpecEst1D</a></code>, see the function documentation for additional details on the wavelet thresholding
procedure.<br />
The maximum wavelet scale taken into account in the clustering procedure is determined by the arguments
<code>jmax</code> and <code>d.jmax</code>. The maximum scale is set to the minimum of <code>jmax</code> and the wavelet
scale <code class="reqn">j</code> for which the proportion of nonzero thresholded wavelet coefficients (averaged
across subjects) is smaller than <code>d.jmax</code>.<br />
The <code class="reqn">S</code> subjects are assigned to <code class="reqn">K</code> different clusters in a probabilistic fashion according to a
two-step procedure:
</p>

<ol>
<li><p> In the first step, an intrinsic fuzzy c-means algorithm, with fuzziness parameter <code class="reqn">m</code> is applied to the
<code class="reqn">S</code> coarsest midpoints at scale <code>j = 0</code> in the subject-specific midpoint pyramids. Note that the distance
function in the intrinsic c-means algorithm relies on the chosen metric on the space of HPD matrices.
</p>
</li>
<li><p> In the second step, a weighted fuzzy c-means algorithm based on the Euclidean
distance function, also with fuzziness parameter <code class="reqn">m</code>, is applied to the nonzero thresholded wavelet
coefficients of the <code class="reqn">S</code> different subjects. The tuning parameter <code>tau</code> controls the weight given
to the cluster assignments obtained in the first step of the clustering algorithm.
</p>
</li></ol>

<p>The function computes the forward and inverse intrinsic AI wavelet transform in the space of HPD matrices equipped with
one of the following metrics: (i) the affine-invariant Riemannian metric (default) as detailed in e.g., (Bhatia 2009)[Chapter 6]
or (Pennec et al. 2006); (ii) the log-Euclidean metric, the Euclidean inner product between matrix logarithms;
(iii) the Cholesky metric, the Euclidean inner product between Cholesky decompositions; (iv) the Euclidean metric; or
(v) the root-Euclidean metric. The default choice of metric (affine-invariant Riemannian) satisfies several useful properties
not shared by the other metrics, see (Chau and von
Sachs 2019) or (Chau 2018) for more details. Note that this comes
at the cost of increased computation time in comparison to one of the other metrics. <br />
If <code>return.centers = TRUE</code>, the function also returns the <code>K</code> HPD spectral matrix curves corresponding to
the cluster centers based on the given metric by applying the intrinsic inverse AI wavelet transform (
<code><a href="#topic+InvWavTransf1D">InvWavTransf1D</a></code>) to the cluster centers in the wavelet domain.
</p>


<h3>Value</h3>

<p>Depending on the input the function returns a list with five or six components:
</p>

<dl>
<dt>cl.prob </dt><dd><p> an (<code class="reqn">S,K</code>)-dimensional matrix, where the value at position (<code class="reqn">s,k</code>) in the
matrix corresponds to the probabilistic cluster membership assignment of subject <code class="reqn">s</code> with respect
to cluster <code class="reqn">k</code>.</p>
</dd>
<dt>cl.centers.D </dt><dd><p> a list of <code>K</code> wavelet coefficient pyramids, where each pyramid of wavelet
coefficients is associated to a cluster center.</p>
</dd>
<dt>cl.centers.M0 </dt><dd><p> a list of <code>K</code> arrays of coarse-scale midpoints at scale <code>j = 0</code>, where each
array is associated to a cluster center.</p>
</dd>
<dt>cl.centers.f </dt><dd><p> only available if <code>return.centers = TRUE</code>, returning a list of <code>K</code> <code class="reqn">(d,d,n)</code>-dimensional arrays,
where each array corresponds to a length <code class="reqn">n</code> curve of <code class="reqn">(d,d)</code>-dimensional HPD matrices associated to a cluster center.</p>
</dd>
<dt>cl.jmax </dt><dd><p> the maximum wavelet scale taken into account in the clustering procedure determined by
the input arguments <code>jmax</code> and <code>d.jmax</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdSpecEst1D">pdSpecEst1D</a></code>, <code><a href="#topic+pdSpecClust2D">pdSpecClust2D</a></code>, <code><a href="#topic+pdkMeans">pdkMeans</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## ARMA(1,1) process: Example 11.4.1 in (Brockwell and Davis, 1991)
Phi1 &lt;- array(c(0.5, 0, 0, 0.6, rep(0, 4)), dim = c(2, 2, 2))
Phi2 &lt;- array(c(0.7, 0, 0, 0.4, rep(0, 4)), dim = c(2, 2, 2))
Theta &lt;- array(c(0.5, -0.7, 0.6, 0.8, rep(0, 4)), dim = c(2, 2, 2))
Sigma &lt;- matrix(c(1, 0.71, 0.71, 2), nrow = 2)

## Generate periodogram data for 10 subjects in 2 groups
pgram &lt;- function(Phi) pdPgram(rARMA(2^9, 2, Phi, Theta, Sigma)$X)$P
P &lt;- array(c(replicate(5, pgram(Phi1)), replicate(5, pgram(Phi2))), dim=c(2,2,2^8,10))

cl &lt;- pdSpecClust1D(P, K = 2, metric = "logEuclidean")

</code></pre>

<hr>
<h2 id='pdSpecClust2D'>Intrinsic wavelet HPD time-varying spectral clustering</h2><span id='topic+pdSpecClust2D'></span>

<h3>Description</h3>

<p><code>pdSpecClust2D</code> performs clustering of HPD time-varying spectral matrices corrupted by noise (e.g. HPD time-varying
periodograms) by combining wavelet thresholding and fuzzy clustering in the intrinsic wavelet coefficient domain according to
the following steps:
</p>

<ol>
<li><p> Transform a collection of noisy HPD time-varying spectral matrices to the intrinsic wavelet domain and denoise the
HPD matrix surfaces by (tree-structured) thresholding of wavelet coefficients with <code><a href="#topic+pdSpecEst2D">pdSpecEst2D</a></code>.
</p>
</li>
<li><p> Apply an intrinsic fuzzy c-means algorithm to the coarsest midpoints at scale <code>j = 0</code> across subjects.
</p>
</li>
<li><p> Taking into account the fuzzy cluster assignments in the previous step, apply a weighted fuzzy c-means
algorithm to the nonzero thresholded wavelet coefficients across subjects from scale <code>j = 1</code> up to <code>j = jmax</code>.
</p>
</li></ol>

<p>More details can be found in Chapter 3 of (Chau 2018) and the accompanying vignettes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdSpecClust2D(P, K, jmax, metric = "Riemannian", m = 2, d.jmax = 0.1,
  eps = c(1e-04, 1e-04), tau = 0.5, max_iter = 50,
  return.centers = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdSpecClust2D_+3A_p">P</code></td>
<td>
<p>a (<code>d,d,n[1],n[2],S</code>)-dimensional array of HPD matrices, corresponding to a collection of surfaces of
<code class="reqn">(d,d)</code>-dimensional HPD matrices of size <code class="reqn">n_1 \times n_2</code>, with <code class="reqn">n_1 = 2^{J_1}</code> and <code class="reqn">n_2 = 2^{J_2}</code>
for some <code class="reqn">J_1,J_2 &gt; 0</code>, for <code class="reqn">S</code> different subjects.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_k">K</code></td>
<td>
<p>the number of clusters, a positive integer larger than 1.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_jmax">jmax</code></td>
<td>
<p>an upper bound on the maximum wavelet scale to be considered in the clustering procedure. If
<code>jmax</code> is not specified, it is set equal to the maximum (i.e., finest) wavelet scale minus 2.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code> or
<code>"Euclidean"</code>. Additional details are given below.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_m">m</code></td>
<td>
<p>the fuzziness parameter for both fuzzy c-means algorithms. <code>m</code> should be larger or equal to <code class="reqn">1</code>.
If <code class="reqn">m = 1</code> the cluster assignments are no longer fuzzy, i.e., the procedure
performs hard clustering.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_d.jmax">d.jmax</code></td>
<td>
<p>a proportion that is used to determine the maximum wavelet scale to be considered in the clustering
procedure. A larger value <code>d.jmax</code> leads to less wavelet coefficients being taken into account, and therefore
lower computational effort in the procedure. If <code>d.jmax</code> is not specified, by default <code>d.jmax = 0.1</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_eps">eps</code></td>
<td>
<p>an optional vector with two components determining the stopping criterion. The first step in the cluster procedure
terminates if the (integrated) intrinsic distance between cluster centers is smaller than <code>eps[1]</code>.
The second step in the cluster procedure terminates if the (integrated) Euclidean distance between cluster centers is smaller
than <code>eps[2]</code>. By default <code>eps = c(1e-04, 1e-04)</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_tau">tau</code></td>
<td>
<p>an optional argument tuning the weight given to the cluster assignments obtained in the first step of
the clustering algorithm. If <code>tau</code> is not specified, by default <code>tau = 0.5</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_max_iter">max_iter</code></td>
<td>
<p>an optional argument tuning the maximum number of iterations in both the first and second step of the
clustering algorithm, defaults to <code>max_iter = 50</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_return.centers">return.centers</code></td>
<td>
<p>should the cluster centers transformed back the space of HPD matrices also be returned?
Defaults to <code>return.centers = FALSE</code>.</p>
</td></tr>
<tr><td><code id="pdSpecClust2D_+3A_...">...</code></td>
<td>
<p>additional arguments passed on to <code><a href="#topic+pdSpecEst2D">pdSpecEst2D</a></code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input array <code>P</code> corresponds to a collection of initial noisy HPD time-varying spectral estimates of the
<code class="reqn">(d,d)</code>-dimensional time-varying spectral matrix at <code class="reqn">n_1 \times n_2</code> time-frequency points, with <code class="reqn">n_1, n_2</code>
dyadic numbers, for <code class="reqn">S</code> different subjects. These can be e.g., multitaper HPD time-varying periodograms given as output
by the function <code><a href="#topic+pdPgram2D">pdPgram2D</a></code>.<br />
First, for each subject <code class="reqn">s = 1,\ldots,S</code>, thresholded wavelet coefficients in the intrinsic wavelet domain are
calculated by <code><a href="#topic+pdSpecEst2D">pdSpecEst2D</a></code>, see the function documentation for additional details on the wavelet thresholding
procedure.<br />
The maximum wavelet scale taken into account in the clustering procedure is determined by the arguments
<code>jmax</code> and <code>d.jmax</code>. The maximum scale is set to the minimum of <code>jmax</code> and the wavelet
scale <code class="reqn">j</code> for which the proportion of nonzero thresholded wavelet coefficients (averaged
across subjects) is smaller than <code>d.jmax</code>.<br />
The <code class="reqn">S</code> subjects are assigned to <code class="reqn">K</code> different clusters in a probabilistic fashion according to a
two-step procedure:
</p>

<ol>
<li><p> In the first step, an intrinsic fuzzy c-means algorithm, with fuzziness parameter <code class="reqn">m</code> is applied to the
<code class="reqn">S</code> coarsest midpoints at scale <code>j = 0</code> in the subject-specific 2D midpoint pyramids. Note that the distance
function in the intrinsic c-means algorithm relies on the chosen metric on the space of HPD matrices.
</p>
</li>
<li><p> In the second step, a weighted fuzzy c-means algorithm based on the Euclidean
distance function, also with fuzziness parameter <code class="reqn">m</code>, is applied to the nonzero thresholded wavelet
coefficients of the <code class="reqn">S</code> different subjects. The tuning parameter <code>tau</code> controls the weight given
to the cluster assignments obtained in the first step of the clustering algorithm.
</p>
</li></ol>

<p>The function computes the forward and inverse intrinsic 2D AI wavelet transform in the space of HPD matrices equipped with
one of the following metrics: (i) the affine-invariant Riemannian metric (default) as detailed in e.g., (Bhatia 2009)[Chapter 6]
or (Pennec et al. 2006); (ii) the log-Euclidean metric, the Euclidean inner product between matrix logarithms;
(iii) the Cholesky metric, the Euclidean inner product between Cholesky decompositions; (iv) the Euclidean metric; or
(v) the root-Euclidean metric. The default choice of metric (affine-invariant Riemannian) satisfies several useful properties
not shared by the other metrics, see (Chau 2018) for more details. Note that this comes
at the cost of increased computation time in comparison to one of the other metrics. <br />
If <code>return.centers = TRUE</code>, the function also returns the <code>K</code> HPD time-varying spectral matrices corresponding to
the cluster centers based on the given metric by applying the intrinsic inverse 2D AI wavelet transform (
<code><a href="#topic+InvWavTransf2D">InvWavTransf2D</a></code>) to the cluster centers in the wavelet domain.
</p>


<h3>Value</h3>

<p>Depending on the input the function returns a list with five or six components:
</p>

<dl>
<dt>cl.prob </dt><dd><p> an (<code class="reqn">S,K</code>)-dimensional matrix, where the value at position (<code class="reqn">s,k</code>) in the
matrix corresponds to the probabilistic cluster membership assignment of subject <code class="reqn">s</code> with respect
to cluster <code class="reqn">k</code>.</p>
</dd>
<dt>cl.centers.D </dt><dd><p> a list of <code>K</code> wavelet coefficient pyramids, where each 2D pyramid of wavelet
coefficients is associated to a cluster center.</p>
</dd>
<dt>cl.centers.M0 </dt><dd><p> a list of <code>K</code> arrays of coarse-scale midpoints at scale <code>j = 0</code>, where each
array is associated to a cluster center.</p>
</dd>
<dt>cl.centers.f </dt><dd><p> only available if <code>return.centers = TRUE</code>, returning a list of <code>K</code> <code>(d,d,n[1],n[2])</code>-dimensional
arrays, where each array corresponds to an<code class="reqn">n_1 \times n_2</code>-sized surface of <code class="reqn">(d,d)</code>-dimensional HPD matrices associated
to a cluster center.</p>
</dd>
<dt>cl.jmax </dt><dd><p> the maximum wavelet scale taken into account in the clustering procedure determined by
the input arguments <code>jmax</code> and <code>d.jmax</code>.</p>
</dd>
</dl>



<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdSpecEst2D">pdSpecEst2D</a></code>, <code><a href="#topic+WavTransf2D">WavTransf2D</a></code>, <code><a href="#topic+pdDist">pdDist</a></code>, <code><a href="#topic+pdPgram2D">pdPgram2D</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## Generate noisy HPD surfaces for 6 subjects in 2 groups
n &lt;- c(2^5, 2^5)
P &lt;- array(c(rExamples2D(n, example = "tvar", replicates = 3)$P,
             rExamples2D(n, example = "tvar", replicates = 3)$P), dim = c(2, 2, n, 6))
cl &lt;- pdSpecClust2D(P, K = 2, metric = "logEuclidean")

## End(Not run)

</code></pre>

<hr>
<h2 id='pdSpecEst1D'>Intrinsic wavelet HPD spectral estimation</h2><span id='topic+pdSpecEst1D'></span>

<h3>Description</h3>

<p><code>pdSpecEst1D</code> calculates a <code class="reqn">(d,d)</code>-dimensional HPD wavelet-denoised spectral matrix estimator
by applying the following steps to an initial noisy HPD spectral estimate (obtained with e.g., <code><a href="#topic+pdPgram">pdPgram</a></code>):
</p>

<ol>
<li><p> a forward intrinsic AI wavelet transform, with <code><a href="#topic+WavTransf1D">WavTransf1D</a></code>,
</p>
</li>
<li><p> (tree-structured) thresholding of the wavelet coefficients, with <code><a href="#topic+pdCART">pdCART</a></code>,
</p>
</li>
<li><p> an inverse intrinsic AI wavelet transform, with <code><a href="#topic+InvWavTransf1D">InvWavTransf1D</a></code>.
</p>
</li></ol>

<p>The complete estimation procedure is described in more detail in (Chau and von
Sachs 2019) or Chapter 3 of
(Chau 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdSpecEst1D(P, order = 5, metric = "Riemannian", alpha = 1,
  return_val = "f", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdSpecEst1D_+3A_p">P</code></td>
<td>
<p>a (<code class="reqn">d,d,m</code>)-dimensional array of HPD matrices, corresponding to a sequence of <code class="reqn">(d,d)</code>-dimensional HPD matrices
of length <code class="reqn">m</code>, with <code class="reqn">m = 2^J</code> for some <code class="reqn">J &gt; 0</code>.</p>
</td></tr>
<tr><td><code id="pdSpecEst1D_+3A_order">order</code></td>
<td>
<p>an odd integer larger or equal to 1 corresponding to the order of the intrinsic AI refinement scheme,
defaults to <code>order = 5</code>. Note that if <code>order &gt; 9</code>, the computational cost
significantly increases as the wavelet transform no longer uses a fast wavelet refinement scheme based
on pre-determined weights.</p>
</td></tr>
<tr><td><code id="pdSpecEst1D_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code>,
<code>"Euclidean"</code> or <code>"Riemannian-Rahman"</code>. See also the Details section below.</p>
</td></tr>
<tr><td><code id="pdSpecEst1D_+3A_alpha">alpha</code></td>
<td>
<p>an optional tuning parameter in the wavelet thresholding procedure. The penalty (or sparsity)
parameter in the tree-structured wavelet thresholding procedure in <code><a href="#topic+pdCART">pdCART</a></code> is set to <code>alpha</code>
times the estimated universal threshold, defaults to <code>alpha = 1</code>.</p>
</td></tr>
<tr><td><code id="pdSpecEst1D_+3A_return_val">return_val</code></td>
<td>
<p>an optional argument that specifies whether the denoised spectral estimator
is returned or not. See the Details section below.</p>
</td></tr>
<tr><td><code id="pdSpecEst1D_+3A_...">...</code></td>
<td>
<p>additional arguments for internal use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input array <code>P</code> corresponds to an initial noisy HPD spectral estimate of the (<code class="reqn">d,d</code>)-dimensional
spectral matrix at <code>m</code> different frequencies, with <code class="reqn">m = 2^J</code> for some <code class="reqn">J &gt; 0</code>. This can be e.g.,
a multitaper HPD periodogram given as output by the function <code><a href="#topic+pdPgram">pdPgram</a></code>.<br />
<code>P</code> is transformed to the wavelet domain by the function <code><a href="#topic+WavTransf1D">WavTransf1D</a></code>, which applies an intrinsic
1D AI wavelet transform based on a metric specified by the user. The noise is removed by tree-structured
thresholding of the wavelet coefficients based on the trace of the whitened coefficients with <code><a href="#topic+pdCART">pdCART</a></code> by
minimization of a <em>complexity penalized residual sum of squares</em> (CPRESS) criterion via the fast tree-pruning algorithm
in (Donoho 1997). The penalty or sparsity parameter in the optimization procedure is set equal to <code>alpha</code>
times the universal threshold, where the noise variance of the traces of the whitened wavelet
coefficients are determined from the finest wavelet scale. See (Chau and von
Sachs 2019) and Chapter 3 of (Chau 2018)
for further details. <br />
The function computes the forward and inverse intrinsic AI wavelet transform in the space of HPD matrices equipped with
one of the following metrics: (i) the affine-invariant Riemannian metric (default) as detailed in e.g., (Bhatia 2009)[Chapter 6]
or (Pennec et al. 2006); (ii) the log-Euclidean metric, the Euclidean inner product between matrix logarithms;
(iii) the Cholesky metric, the Euclidean inner product between Cholesky decompositions; (iv) the Euclidean metric; or
(v) the root-Euclidean metric. The default choice of metric (affine-invariant Riemannian) satisfies several useful properties
not shared by the other metrics, see (Chau and von
Sachs 2019) or (Chau 2018) for more details. Note that this comes
at the cost of increased computation time in comparison to one of the other metrics. <br />
If <code>return_val = 'f'</code> the thresholded wavelet coefficients are transformed back to the frequency domain by
the inverse intrinsic 1D AI wavelet transform via <code><a href="#topic+InvWavTransf1D">InvWavTransf1D</a></code>, returning the wavelet-denoised
HPD spectral estimate.
</p>


<h3>Value</h3>

<p>The function returns a list with the following five components:
</p>
<table role = "presentation">
<tr><td><code>f</code></td>
<td>
<p> a (<code class="reqn">d,d,m</code>)-dimensional array of HPD matrices, corresponding to the HPD wavelet-denoised estimate
of the same resolution as the input array <code>P</code>. If <code>return_val != 'f'</code>, the inverse wavelet transform
of the thresholded wavelet coefficients is not computed and <code>f</code> is set equal to <code>NULL</code>.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p> the pyramid of threshold wavelet coefficients. This is a list of arrays, where each array contains the
(<code class="reqn">d,d</code>)-dimensional thresholded wavelet coefficients from the coarsest wavelet scale <code>j = 0</code> up to the finest
wavelet scale <code>j = jmax</code>.</p>
</td></tr>
<tr><td><code>M0</code></td>
<td>
<p> a numeric array containing the midpoint(s) at the coarsest scale <code>j = 0</code> in the midpoint pyramid.</p>
</td></tr>
<tr><td><code>tree.weights</code></td>
<td>
<p>a list of logical values specifying which coefficients to keep, with each list component
corresponding to an individual wavelet scale starting from the coarsest wavelet scale <code>j = 0</code>.</p>
</td></tr>
<tr><td><code>D.raw</code></td>
<td>
<p> the pyramid of non-thresholded wavelet coefficients in the same format as the component <code>$D</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function does not check for positive definiteness of the input matrices, and (depending on the
specified metric) may fail if matrices are close to being singular.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.<br /><br /> Donoho D (1997).
&ldquo;CART and best-ortho-basis: a connection.&rdquo;
<em>The Annals of Statistics</em>, <b>25</b>(5), 1870&ndash;1911.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdPgram">pdPgram</a></code>, <code><a href="#topic+WavTransf1D">WavTransf1D</a></code>, <code><a href="#topic+InvWavTransf1D">InvWavTransf1D</a></code>, <code><a href="#topic+pdCART">pdCART</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- rExamples1D(2^8, example = "bumps")$P
f &lt;- pdSpecEst1D(P)

</code></pre>

<hr>
<h2 id='pdSpecEst2D'>Intrinsic wavelet HPD time-varying spectral estimation</h2><span id='topic+pdSpecEst2D'></span>

<h3>Description</h3>

<p><code>pdSpecEst2D</code> calculates a <code class="reqn">(d,d)</code>-dimensional HPD wavelet-denoised time-varying spectral matrix estimator
by applying the following steps to an initial noisy HPD time-varying spectral estimate (obtained with e.g., <code><a href="#topic+pdPgram2D">pdPgram2D</a></code>):
</p>

<ol>
<li><p> a forward intrinsic AI wavelet transform, with <code><a href="#topic+WavTransf2D">WavTransf2D</a></code>,
</p>
</li>
<li><p> (tree-structured) thresholding of the wavelet coefficients, with <code><a href="#topic+pdCART">pdCART</a></code>,
</p>
</li>
<li><p> an inverse intrinsic AI wavelet transform, with <code><a href="#topic+InvWavTransf2D">InvWavTransf2D</a></code>.
</p>
</li></ol>

<p>The complete estimation procedure is described in more detail in Chapter 5 of (Chau 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdSpecEst2D(P, order = c(3, 3), metric = "Riemannian", alpha = 1,
  return_val = "f", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdSpecEst2D_+3A_p">P</code></td>
<td>
<p>a (<code class="reqn">d,d,n1,n2</code>)-dimensional array of HPD matrices corresponding to a rectangular surface of <code class="reqn">(d,d)</code>-dimensional HPD matrices
of size <code class="reqn">n_1 \times n_2</code>, with <code class="reqn">n_1 = 2^{J_1}</code> and <code class="reqn">n_2 = 2^{J_2}</code> for some <code class="reqn">J_1, J_2 &gt; 0</code>.</p>
</td></tr>
<tr><td><code id="pdSpecEst2D_+3A_order">order</code></td>
<td>
<p>a 2-dimensional numeric vector <code class="reqn">(1,1) \le</code> <code>order</code> <code class="reqn">\le (9,9)</code> corresponding to the marginal
orders of the intrinsic 2D AI refinement scheme, defaults to <code>order = c(3, 3)</code>.</p>
</td></tr>
<tr><td><code id="pdSpecEst2D_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code> or
<code>"Euclidean"</code>. See also the Details section below.</p>
</td></tr>
<tr><td><code id="pdSpecEst2D_+3A_alpha">alpha</code></td>
<td>
<p>an optional tuning parameter in the wavelet thresholding procedure. The penalty (or sparsity)
parameter in the tree-structured wavelet thresholding procedure in <code><a href="#topic+pdCART">pdCART</a></code> is set to <code>alpha</code>
times the estimated universal threshold, defaults to <code>alpha = 1</code>.</p>
</td></tr>
<tr><td><code id="pdSpecEst2D_+3A_return_val">return_val</code></td>
<td>
<p>an optional argument that specifies whether the denoised spectral estimator
is returned or not. See the Details section below.</p>
</td></tr>
<tr><td><code id="pdSpecEst2D_+3A_...">...</code></td>
<td>
<p>additional arguments for internal use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input array <code>P</code> corresponds to an initial noisy HPD time-varying spectral estimate of the (<code class="reqn">d, d</code>)-dimensional
spectral matrix at a time-frequency grid of size <code class="reqn">m_1 \times m_2</code>, with <code class="reqn">m_1, m_2</code> dyadic numbers. This can be e.g.,
a multitaper HPD time-varying periodogram given as output by the function <code><a href="#topic+pdPgram2D">pdPgram2D</a></code>.<br />
<code>P</code> is transformed to the wavelet domain by the function <code><a href="#topic+WavTransf2D">WavTransf2D</a></code>, which applies an intrinsic
2D AI wavelet transform based on a metric specified by the user. The noise is removed by tree-structured
thresholding of the wavelet coefficients based on the trace of the whitened coefficients with <code><a href="#topic+pdCART">pdCART</a></code> by
minimization of a <em>complexity penalized residual sum of squares</em> (CPRESS) criterion via the fast tree-pruning algorithm
in (Donoho 1997). The penalty (i.e., sparsity) parameter in the optimization procedure is set equal to <code>alpha</code>
times the universal threshold, where the noise variance of the traces of the whitened wavelet
coefficients are determined from the finest wavelet scale. See Chapter 5 of (Chau 2018)
for further details. <br />
The function computes the forward and inverse intrinsic 2D AI wavelet transform in the space of HPD matrices equipped with
one of the following metrics: (i) the affine-invariant Riemannian metric (default) as detailed in e.g., (Bhatia 2009)[Chapter 6]
or (Pennec et al. 2006); (ii) the log-Euclidean metric, the Euclidean inner product between matrix logarithms;
(iii) the Cholesky metric, the Euclidean inner product between Cholesky decompositions; (iv) the Euclidean metric; or
(v) the root-Euclidean metric. The default choice of metric (affine-invariant Riemannian) satisfies several useful properties
not shared by the other metrics, see (Chau and von
Sachs 2019) or (Chau 2018) for more details. Note that this comes
at the cost of increased computation time in comparison to one of the other metrics. <br />
If <code>return_val = 'f'</code> the thresholded wavelet coefficients are transformed back to the time-frequency domain by
the inverse intrinsic 2D AI wavelet transform via <code><a href="#topic+InvWavTransf2D">InvWavTransf2D</a></code>, returning the wavelet-denoised
HPD time-varying spectral estimate.
</p>


<h3>Value</h3>

<p>The function returns a list with the following five components:
</p>
<table role = "presentation">
<tr><td><code>f</code></td>
<td>
<p> a (<code class="reqn">d,d,m1,m2</code>)-dimensional array of HPD matrices, corresponding to the HPD wavelet-denoised estimate
on the same resolution grid of size <code class="reqn">m_1 \times m_2</code> as specified by the input array <code>P</code>. If <code>return_val != 'f'</code>, the
inverse wavelet transform of the thresholded wavelet coefficients is not computed and <code>f</code> is set equal to <code>NULL</code>.</p>
</td></tr>
<tr><td><code>D</code></td>
<td>
<p> the 2D pyramid of threshold wavelet coefficients. This is a list of arrays, where each array contains the rectangular grid
(<code class="reqn">d,d</code>)-dimensional thresholded wavelet coefficients from the coarsest wavelet scale <code>j = 0</code> up to the finest
wavelet scale <code>j = jmax</code>.</p>
</td></tr>
<tr><td><code>M0</code></td>
<td>
<p> a numeric array containing the midpoint(s) at the coarsest scale <code>j = 0</code> in the 2D midpoint pyramid.</p>
</td></tr>
<tr><td><code>tree.weights</code></td>
<td>
<p> a list of logical values specifying which coefficients to keep, with each list component
corresponding to an individual wavelet scale starting from the coarsest wavelet scale <code>j = 0</code>.</p>
</td></tr>
<tr><td><code>D.raw</code></td>
<td>
<p> the 2D pyramid of non-thresholded wavelet coefficients in the same format as the component <code>$D</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.<br /><br /> Donoho D (1997).
&ldquo;CART and best-ortho-basis: a connection.&rdquo;
<em>The Annals of Statistics</em>, <b>25</b>(5), 1870&ndash;1911.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+pdPgram2D">pdPgram2D</a></code>, <code><a href="#topic+WavTransf2D">WavTransf2D</a></code>, <code><a href="#topic+InvWavTransf2D">InvWavTransf2D</a></code>, <code><a href="#topic+pdCART">pdCART</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
P &lt;- rExamples2D(c(2^6, 2^6), 2, example = "tvar")$P
f &lt;- pdSpecEst2D(P)

## End(Not run)

</code></pre>

<hr>
<h2 id='pdSplineReg'>Cubic smoothing spline regression for HPD matrices</h2><span id='topic+pdSplineReg'></span>

<h3>Description</h3>

<p><code>pdSplineReg()</code> performs cubic smoothing spline regression in the space of HPD matrices equipped with the
affine-invariant Riemannian metric through minimization of a penalized regression objective function using a
geometric conjugate gradient descent method as outlined in (Boumal and Absil 2011a) and (Boumal and Absil 2011b).
This is a specific implementation of the more general algorithm in (Boumal and Absil 2011a) and (Boumal and Absil 2011b),
setting the part in the objective function based on the first-order finite geometric differences to zero, such that the solutions
of the regression problem are approximating cubic splines.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>pdSplineReg(P, f0, lam = 1, Nd, ini_step = 1, max_iter = 100,
  eps = 0.001, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pdSplineReg_+3A_p">P</code></td>
<td>
<p>a <code class="reqn">(d,d,n)</code>-dimensional array corresponding to a length <code class="reqn">n</code> sequence of (<code class="reqn">d, d</code>)-dimensional
noisy HPD matrices.</p>
</td></tr>
<tr><td><code id="pdSplineReg_+3A_f0">f0</code></td>
<td>
<p>a <code class="reqn">(d,d,n)</code>-dimensional array corresponding to an initial estimate of the smooth
target curve of (<code class="reqn">d, d</code>)-dimensional HPD matrices.</p>
</td></tr>
<tr><td><code id="pdSplineReg_+3A_lam">lam</code></td>
<td>
<p>a smoothness penalty, defaults to <code>lam = 1</code>. If <code>lam = 0</code>, the penalized curve estimate
coincides with geodesic interpolation of the data points with respect to the Riemannian metric.
If <code>lam</code> increases to <code class="reqn">\infty</code>, the penalized regression estimator is approximately a fitted geodesic curve.</p>
</td></tr>
<tr><td><code id="pdSplineReg_+3A_nd">Nd</code></td>
<td>
<p>a numeric value (<code>Nd &lt;= n</code>) determining a lower resolution of the cubic spline regression estimator to speed up
computation time, defaults to <code class="reqn">n</code>.</p>
</td></tr>
<tr><td><code id="pdSplineReg_+3A_ini_step">ini_step</code></td>
<td>
<p>initial candidate step size in a backtracking line search based on the Armijo-Goldstein
condition, defaults to <code>ini_step = 1</code>.</p>
</td></tr>
<tr><td><code id="pdSplineReg_+3A_max_iter">max_iter</code></td>
<td>
<p>maximum number of gradient descent iterations, defaults to <code>max_iter = 100</code>.</p>
</td></tr>
<tr><td><code id="pdSplineReg_+3A_eps">eps</code></td>
<td>
<p>optional tolerance parameter in gradient descent algorithm. The gradient descent procedure exits if the
absolute difference between consecutive evaluations of the objective function is smaller than <code>eps</code>,
defaults to <code>eps = 1E-3</code>.</p>
</td></tr>
<tr><td><code id="pdSplineReg_+3A_...">...</code></td>
<td>
<p>additional arguments for internal use.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list with three components:
</p>
<table role = "presentation">
<tr><td><code>f</code></td>
<td>
<p>a <code class="reqn">(d, d, N_d)</code>-dimensional array corresponding to a length <code>Nd</code> estimated cubic smoothing spline
curve of (<code class="reqn">d, d</code>)-dimensional HPD matrices.</p>
</td></tr>
<tr><td><code>cost</code></td>
<td>
<p>a numeric vector containing the costs of the objective function at each gradient descent iteration.</p>
</td></tr>
<tr><td><code>total_iter</code></td>
<td>
<p>total number of gradient descent iterations.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>This function does not check for positive definiteness of the matrices given as input, and may fail
if matrices are close to being singular.
</p>


<h3>References</h3>

<p>Boumal N, Absil P (2011a).
&ldquo;Discrete regression methods on the cone of positive-definite matrices.&rdquo;
In <em>IEEE ICASSP, 2011</em>, 4232&ndash;4235.<br /><br /> Boumal N, Absil P (2011b).
&ldquo;A discrete regression method on manifolds and its application to data on SO(n).&rdquo;
<em>IFAC Proceedings Volumes</em>, <b>44</b>(1), 2284&ndash;2289.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
set.seed(2)
P &lt;- rExamples1D(50, example = 'gaussian', noise.level = 0.1)
P.spline &lt;- pdSplineReg(P$P, P$P, lam = 0.5, Nd = 25)

## Examine matrix-component (1,1)
plot((1:50)/50, Re(P$P[1, 1, ]), type = "l", lty = 2) ## noisy observations
lines((1:25)/25, Re(P.spline$f[1, 1, ])) ## estimate
lines((1:50)/50, Re(P$f[1, 1, ]), col = 2, lty = 2) ## smooth target

## End(Not run)
</code></pre>

<hr>
<h2 id='rARMA'>Simulate vARMA(2,2) time series</h2><span id='topic+rARMA'></span>

<h3>Description</h3>

<p><code>rARMA</code> generates <code>d</code>-dimensional time series observations from a vARMA(2,2)
(vector-autoregressive-moving-average) process based on Gaussian white noise for testing and simulation
purposes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rARMA(n, d, Phi, Theta, Sigma, burn = 100, freq = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rARMA_+3A_n">n</code></td>
<td>
<p>number of time series observations to be generated.</p>
</td></tr>
<tr><td><code id="rARMA_+3A_d">d</code></td>
<td>
<p>dimension of the multivariate time series.</p>
</td></tr>
<tr><td><code id="rARMA_+3A_phi">Phi</code></td>
<td>
<p>a (<code class="reqn">d, d, 2</code>)-dimensional array, with <code>Phi[, , 1]</code> and <code>Phi[, , 2]</code>
the autoregressive (AR) coefficient matrices.</p>
</td></tr>
<tr><td><code id="rARMA_+3A_theta">Theta</code></td>
<td>
<p>a (<code class="reqn">d, d, 2</code>)-dimensional array, with <code>Theta[, , 1]</code> and <code>Theta[, , 2]</code>
the moving-average (MA) coefficient matrices.</p>
</td></tr>
<tr><td><code id="rARMA_+3A_sigma">Sigma</code></td>
<td>
<p>the covariance matrix of the Gaussian white noise component.</p>
</td></tr>
<tr><td><code id="rARMA_+3A_burn">burn</code></td>
<td>
<p>a burn-in period when generating the time series observations, by default <code>burn = 100</code>.</p>
</td></tr>
<tr><td><code id="rARMA_+3A_freq">freq</code></td>
<td>
<p>an optional vector of frequencies, if <code>!is.null(freq)</code> the function also returns the
underlying Fourier spectral matrix of the stationary generating process evaluated at the frequencies in <code>freq</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The function returns a list with two components:
</p>
<table role = "presentation">
<tr><td><code>X</code></td>
<td>
<p> generated time series observations, the <code>d</code> columns correspond to the components of
the multivariate time series.</p>
</td></tr>
<tr><td><code>f</code></td>
<td>
<p> if <code>!is.null(freq)</code>, <code>f</code> is a <code>(d, d, length(freq))</code>-dimensional array corresponding
to the underlying Fourier spectral matrix curve of <code class="reqn">(d,d)</code>-dimensional HPD matrices evaluated at the frequencies
in <code>freq</code>. If <code>is.null(freq)</code>, <code>f</code> is set to <code>NULL</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Brockwell P, Davis R (2006).
<em>Time Series: Theory and Methods</em>.
Springer, New York.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## ARMA(1,1) process: Example 11.4.1 in (Brockwell and Davis, 1991)
freq &lt;- seq(from = pi / 100, to = pi, length = 100)
Phi &lt;- array(c(0.7, 0, 0, 0.6, rep(0, 4)), dim = c(2, 2, 2))
Theta &lt;- array(c(0.5, -0.7, 0.6, 0.8, rep(0, 4)), dim = c(2, 2, 2))
Sigma &lt;- matrix(c(1, 0.71, 0.71, 2), nrow = 2)
ts.sim &lt;- rARMA(200, 2, Phi, Theta, Sigma, freq = freq)
ts.plot(ts.sim$X) # plot generated time series traces.

</code></pre>

<hr>
<h2 id='rExamples1D'>Several example curves of HPD matrices</h2><span id='topic+rExamples1D'></span>

<h3>Description</h3>

<p><code>rExamples1D()</code> generates several example (locally) smooth target <em>curves</em> of HPD matrices corrupted by
noise in a manifold of HPD matrices for testing and simulation purposes. For more details, see also Chapter 2 and 3 in
(Chau 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rExamples1D(n, d = 3, example = c("bumps", "two-cats", "heaviSine",
  "gaussian", "mix-gaussian", "arma", "peaks", "blocks"), user.f = NULL,
  return.ts = FALSE, replicates = 1, noise = "riem-gaussian",
  noise.level = 1, df.wishart = NULL, nblocks = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rExamples1D_+3A_n">n</code></td>
<td>
<p>number of sampled matrices to be generated.</p>
</td></tr>
<tr><td><code id="rExamples1D_+3A_d">d</code></td>
<td>
<p>row- (resp. column-)dimension of the generated matrices. Defaults to <code>d = 3</code>.</p>
</td></tr>
<tr><td><code id="rExamples1D_+3A_example">example</code></td>
<td>
<p>the example target HPD matrix curve, one of <code>'bumps'</code>, <code>'two-cats'</code>, <code>'heaviSine'</code>,
<code>'gaussian'</code>, <code>'mix-gaussian'</code>, <code>'arma'</code>, <code>'peaks'</code> or <code>'blocks'</code>.</p>
</td></tr>
<tr><td><code id="rExamples1D_+3A_user.f">user.f</code></td>
<td>
<p>user-specified target HPD matrix curve, should be a (<code class="reqn">d,d,n</code>)-dimensional array, corresponding to a length <code class="reqn">n</code> curve of
<code class="reqn">(d,d)</code>-dimensional HPD matrices.</p>
</td></tr>
<tr><td><code id="rExamples1D_+3A_return.ts">return.ts</code></td>
<td>
<p>a logical value, if <code>return.ts = TRUE</code> the function also returns time series observations generated via the Cramer representation
based on the transfer function of the example HPD spectral matrix and complex normal random variates. Defaults to <code>return.ts = FALSE</code>.</p>
</td></tr>
<tr><td><code id="rExamples1D_+3A_replicates">replicates</code></td>
<td>
<p>a positive integer specifying the number of replications of noisy HPD matrix curves to be generated based on the
target curve of HPD matrices. Defaults to <code>replicates = 1</code></p>
</td></tr>
<tr><td><code id="rExamples1D_+3A_noise">noise</code></td>
<td>
<p>noise distribution for the generated noisy curves of HPD matrices, one of <code>'riem-gaussian'</code>,
<code>'log-gaussian'</code>, <code>'wishart'</code>, <code>'log-wishart'</code> or <code>'periodogram'</code>, defaults to <code>'riem-gaussian'</code>.
Additional details are given below.</p>
</td></tr>
<tr><td><code id="rExamples1D_+3A_noise.level">noise.level</code></td>
<td>
<p>parameter to tune the signal-to-noise ratio for the generated noisy HPD matrix observations, only used if <code>noise != 'periodogram'</code>.
If <code>noise.level = 0</code>, the noise distributions are degenerate and the noisy HPD matrix observations coincide with the target HPD matrices.
Defaults to <code>noise.level = 1</code>.</p>
</td></tr>
<tr><td><code id="rExamples1D_+3A_df.wishart">df.wishart</code></td>
<td>
<p>optional parameter to specify the degrees of freedom in the case of a Wishart noise distribution (<code>noise = 'wishart'</code> or
<code>noise = 'log-wishart'</code>); or the number of DPSS tapers in the case of generated periodogram matrices if <code>noise = 'periodogram'</code>.
By default <code>df.wishart</code> is equal to the dimension <code>d</code> to guarantee positive definiteness of the generated noisy matrices.</p>
</td></tr>
<tr><td><code id="rExamples1D_+3A_nblocks">nblocks</code></td>
<td>
<p>optional parameter to specify the number of constant segments in the <code>'blocks'</code> HPD matrix curve. Only used if <code>example = 'blocks'</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The examples include: (i) a <code class="reqn">(3,3)</code>-dimensional <code>'bumps'</code> HPD matrix curve containing peaks and bumps of various smoothness degrees;
(ii) a <code class="reqn">(3,3)</code>-dimensional <code>'two-cats'</code> HPD matrix curve visualizing the contour of two side-by-side cats, with inhomogeneous
smoothness across the domain; (iii) a <code class="reqn">(3,3)</code>-dimensional <code>'heaviSine'</code> HPD matrix curve consisting of smooth sinosoids with a break;
(iv) a <code class="reqn">(2,2)</code>-dimensional <code>'gaussian'</code> HPD matrix curve consisting of smooth Gaussian functions; (v) a <code class="reqn">(d,d)</code>-dimensional
<code>'mix-gaussian'</code> HPD matrix curve consisting of a weighted linear combination of smooth Gaussian functions; (vi) a <code class="reqn">(2,2)</code>-dimensional
<code>'arma'</code> HPD matrix curve generated from the smooth spectral matrix of a 2-dimensional stationary ARMA(1,1)-process; (vii) a <code class="reqn">(d, d)</code>-
dimensional <code>'peaks'</code> HPD matrix curve containing several sharp peaks across the domain; and (viii) a <code class="reqn">(d, d)</code>-<code>'blocks'</code> HPD matrix
curve generated from locally constant segments of HPD matrices.<br />
In addition to the smooth target curve of HPD matrices, the function also returns a noisy version of the target curve of HPD matrices, corrupted
by a user-specified noise distribution. By default, the noisy HPD matrix observations follow an intrinsic signal plus i.i.d. noise model with
respect to the affine-invariant Riemannian metric, with a matrix log-Gaussian noise distribution (<code>noise = 'riem-gaussian'</code>), such that the
Riemannian Karcher means of the observations coincide with the target curve of HPD matrices. Additional details can be found in Chapters 2, 3,
and 5 of (Chau 2018). Other available signal-noise models include: (ii) a Log-Euclidean signal plus i.i.d. noise model, with
a matrix log-Gaussian noise distribution (<code>noise = 'log-gaussian'</code>); (iii) a Riemannian signal plus i.i.d. noise model, with a complex
Wishart noise distribution (<code>noise = 'wishart'</code>); (iv) a Log-Euclidean signal plus i.i.d. noise model, with a complex Wishart noise
distribution (<code>noise = 'log-wishart'</code>); and (v) noisy periodogram observations obtained with <code>pdPgram</code> from a stationary time series
generated via the Cramer representation based on the transfer function of the target HPD spectral matrix curve and complex normal random variates
(<code>noise = 'periodogram'</code>). If <code>return.ts = TRUE</code>, the function also returns the generated time series observations, which are not generated
by default if <code>noise != 'periodogram'</code>.
</p>


<h3>Value</h3>

<p>Depending on the input arguments returns a list with two or three components:
</p>
<table role = "presentation">
<tr><td><code>f</code></td>
<td>
<p> a (<code class="reqn">d,d,n</code>)-dimensional array, corresponding to the length <code class="reqn">n</code> example target curve of
<code class="reqn">(d,d)</code>-dimensional HPD matrices.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p> a (<code class="reqn">d,d,n</code>)-dimensional array, corresponding to a length <code class="reqn">n</code> curve of noisy <code class="reqn">(d,d)</code>-dimensional
HPD matrices centered around the smooth target HPD matrix curve <code>f</code>. If <code>replicates &gt; 1</code>, <code>P</code> is a <code>(d,d,n,length(replicates))</code>-dimensional
array, corresponding to a collection of replicated length <code class="reqn">n</code> curves of noisy <code class="reqn">(d,d)</code>-dimensional HPD matrices centered around
the smooth target HPD matrix curve <code>f</code>.</p>
</td></tr>
<tr><td><code>ts</code></td>
<td>
<p> generated <code class="reqn">d</code>-dimensional time series observations, only available if <code>return.ts = TRUE</code>.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>If <code>noise = 'wishart'</code>, the generated noisy HPD matrix observations are independent complex Wishart matrices, which can be
interpreted informally as pseudo-periodogram matrix observations, as the periodogram matrices based on strictly stationary time series
observations obtained with <code>noise = 'periodogram'</code> are asymptotically independent and asymptotically complex Wishart distributed,
see e.g., (Brillinger 1981).
</p>


<h3>References</h3>

<p>Brillinger D (1981).
<em>Time Series: Data Analysis and Theory</em>.
Holden-Day, San Francisco.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rExamples2D">rExamples2D</a></code>, <code><a href="#topic+pdPgram">pdPgram</a></code>, <code><a href="#topic+rARMA">rARMA</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example &lt;- rExamples1D(100, example = "bumps", return.ts = TRUE)
plot.ts(Re(example$ts), main = "3-d time series") # plot generated time series

</code></pre>

<hr>
<h2 id='rExamples2D'>Several example surfaces of HPD matrices</h2><span id='topic+rExamples2D'></span>

<h3>Description</h3>

<p><code>rExamples2D()</code> generates several example (locally) smooth target <em>surfaces</em> of HPD matrices corrupted by
noise in a manifold of HPD matrices for testing and simulation purposes. For more details, see also Chapter 2 and 5 in
(Chau 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>rExamples2D(n, d = 2, example = c("smiley", "tvar", "facets", "peak"),
  replicates = 1, noise = "riem-gaussian", noise.level = 1,
  df.wishart = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="rExamples2D_+3A_n">n</code></td>
<td>
<p>integer vector <code>c(n1, n2)</code> specifying the number of sampled matrices to be generated on a rectangular surface.</p>
</td></tr>
<tr><td><code id="rExamples2D_+3A_d">d</code></td>
<td>
<p>row- (resp. column-)dimension of the generated matrices. Defaults to <code>d = 2</code>.</p>
</td></tr>
<tr><td><code id="rExamples2D_+3A_example">example</code></td>
<td>
<p>the example target HPD matrix surface, one of <code>'smiley'</code>, <code>'tvar'</code>, <code>'facets'</code> or <code>'peak'</code>.</p>
</td></tr>
<tr><td><code id="rExamples2D_+3A_replicates">replicates</code></td>
<td>
<p>a positive integer specifying the number of replications of noisy HPD matrix surfaces to be generated based on the
target surface of HPD matrices. Defaults to <code>replicates = 1</code></p>
</td></tr>
<tr><td><code id="rExamples2D_+3A_noise">noise</code></td>
<td>
<p>noise distribution for the generated noisy surfaces of HPD matrices, one of <code>'riem-gaussian'</code>,
<code>'log-gaussian'</code>, <code>'wishart'</code>, <code>'log-wishart'</code> or <code>'periodogram'</code>, defaults to <code>'riem-gaussian'</code>.
Additional details are given below.</p>
</td></tr>
<tr><td><code id="rExamples2D_+3A_noise.level">noise.level</code></td>
<td>
<p>parameter to tune the signal-to-noise ratio for the generated noisy HPD matrix observations.
If <code>noise.level = 0</code>, the noise distributions are degenerate and the noisy HPD matrix observations coincide with the target HPD matrices.
Defaults to <code>noise.level = 1</code>.</p>
</td></tr>
<tr><td><code id="rExamples2D_+3A_df.wishart">df.wishart</code></td>
<td>
<p>optional parameter to specify the degrees of freedom in the case of a Wishart noise distribution (<code>noise = 'wishart'</code> or
<code>noise = 'log-wishart'</code>). By default <code>df.wishart</code> is equal to the dimension <code>d</code> to guarantee positive definiteness of the
generated noisy matrices.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The examples include: (i) a <code class="reqn">(d,d)</code>-dimensional <code>'smiley'</code> HPD matrix surface consisting of constant surfaces of random HPD matrices in
the shape of a smiley face; (ii) a <code class="reqn">(d,d)</code>-dimensional <code>'tvar'</code> HPD matrix surface generated from a time-varying vector-auto-
regressive process of order 1 with random time-varying coefficient matrix (<code class="reqn">\Phi</code>); (iii) a <code class="reqn">(d,d)</code>-dimensional <code>'facets'</code> HPD matrix
surface consisting of several facets generated from random geodesic surfaces; and (iv) a <code class="reqn">(d,d)</code>-dimensional <code>'peak'</code> HPD matrix surface
containing a pronounced peak in the center of its 2-d (e.g., time-frequency) domain.<br />
In addition to the (locally) smooth target surface of HPD matrices, the function also returns a noisy version of the target surface of HPD matrices, corrupted
by a user-specified noise distribution. By default, the noisy HPD matrix observations follow an intrinsic signal plus i.i.d. noise model with
respect to the affine-invariant Riemannian metric, with a matrix log-Gaussian noise distribution (<code>noise = 'riem-gaussian'</code>), such that the
Riemannian Karcher means of the observations coincide with the target surface of HPD matrices. Additional details can be found in Chapters 2, 3,
and 5 of (Chau 2018). Other available signal-noise models include: (ii) a Log-Euclidean signal plus i.i.d. noise model, with
a matrix log-Gaussian noise distribution (<code>noise = 'log-gaussian'</code>); (iii) a Riemannian signal plus i.i.d. noise model, with a complex
Wishart noise distribution (<code>noise = 'wishart'</code>); (iv) a Log-Euclidean signal plus i.i.d. noise model, with a complex Wishart noise
distribution (<code>noise = 'log-wishart'</code>).
</p>


<h3>Value</h3>

<p>Returns a list with two components:
</p>
<table role = "presentation">
<tr><td><code>f</code></td>
<td>
<p> a (<code>d,d,n[1],n[2]</code>)-dimensional array, corresponding to the <code class="reqn">(n_1 \times n_2)</code>-sized example target surface of
<code class="reqn">(d,d)</code>-dimensional HPD matrices.</p>
</td></tr>
<tr><td><code>P</code></td>
<td>
<p> a (<code>d,d,n[1],n[2]</code>)-dimensional array, corresponding to the <code class="reqn">(n_1 \times n_2)</code>-sized surface of noisy <code class="reqn">(d,d)</code>-dimensional
HPD matrices centered around the smooth target HPD matrix surface <code>f</code>. If <code>replicates &gt; 1</code>, <code>P</code> is a
<code>(d,d,n[1],n[2],length(replicates))</code>-dimensional array, corresponding to a collection of replicated <code class="reqn">(n_1 \times n_2)</code>-sized surfaces
of noisy <code class="reqn">(d,d)</code>-dimensional HPD matrices centered around the smooth target HPD matrix surface <code>f</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+rExamples1D">rExamples1D</a></code>, <code><a href="#topic+pdPgram2D">pdPgram2D</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example &lt;- rExamples2D(n = c(32, 32), example = "smiley")

</code></pre>

<hr>
<h2 id='WavTransf1D'>Forward AI wavelet transform for curve of HPD matrices</h2><span id='topic+WavTransf1D'></span>

<h3>Description</h3>

<p><code>WavTransf1D</code> computes a forward intrinsic average-interpolating (AI) wavelet transform for a
curve in the manifold of HPD matrices equipped with a metric specified by the user, such as the
affine-invariant Riemannian metric, as described in (Chau and von
Sachs 2019) and Chapter 3 of
(Chau 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WavTransf1D(P, order = 5, jmax, periodic = FALSE,
  metric = "Riemannian", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="WavTransf1D_+3A_p">P</code></td>
<td>
<p>a (<code class="reqn">d,d,m</code>)-dimensional array of HPD matrices, corresponding to a sequence of <code class="reqn">(d,d)</code>-dimensional HPD matrices
of length <code class="reqn">m</code>, with <code class="reqn">m = 2^J</code> for some <code class="reqn">J &gt; 0</code>.</p>
</td></tr>
<tr><td><code id="WavTransf1D_+3A_order">order</code></td>
<td>
<p>an odd integer larger or equal to 1 corresponding to the order of the intrinsic AI refinement scheme,
defaults to <code>order = 5</code>. Note that if <code>order &gt; 9</code>, the computational cost
significantly increases as the wavelet transform no longer uses a fast wavelet refinement scheme based
on pre-determined weights.</p>
</td></tr>
<tr><td><code id="WavTransf1D_+3A_jmax">jmax</code></td>
<td>
<p>the maximum scale up to which the wavelet coefficients are computed. If <code>jmax</code> is not
specified, it is set equal to the maximum possible scale <code>jmax = J-1</code>, where <code>J = log2(m)</code>.</p>
</td></tr>
<tr><td><code id="WavTransf1D_+3A_periodic">periodic</code></td>
<td>
<p>a logical value determining whether the curve of HPD matrices can be reflected at the boundary for
improved wavelet refinement schemes near the boundaries of the domain. This is useful for spectral matrix estimation,
in which case the spectral matrix is a symmetric and periodic curve in the frequency domain. Defaults to <code>periodic = FALSE</code>.</p>
</td></tr>
<tr><td><code id="WavTransf1D_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can also be one of: <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code>,
<code>"Euclidean"</code> or <code>"Riemannian-Rahman"</code>. See also the Details section below.</p>
</td></tr>
<tr><td><code id="WavTransf1D_+3A_...">...</code></td>
<td>
<p>additional arguments for internal use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The input array <code>P</code> corresponds to a discretized curve of <code class="reqn">(d,d)</code>-dimensional HPD matrices of
dyadic length. <code>WavTransf1D</code> then computes the intrinsic AI wavelet transform of <code>P</code> based on
the given refinement order and the chosen metric. If the refinement order is an odd integer smaller or
equal to 9, the function computes the wavelet transform using a fast wavelet refinement scheme based on weighted
intrinsic averages with pre-determined weights as explained in (Chau and von
Sachs 2019) and Chapter 3 of
(Chau 2018). If the refinement order is an odd integer larger than 9, the wavelet refinement
scheme uses intrinsic polynomial prediction based on Neville's algorithm in the Riemannian manifold (via <code><a href="#topic+pdNeville">pdNeville</a></code>).<br />
The function computes the intrinsic AI wavelet transform in the space of HPD matrices equipped with
one of the following metrics: (i) the affine-invariant Riemannian metric (default) as detailed in e.g., (Bhatia 2009)[Chapter 6]
or (Pennec et al. 2006); (ii) the log-Euclidean metric, the Euclidean inner product between matrix logarithms;
(iii) the Cholesky metric, the Euclidean inner product between Cholesky decompositions; (iv) the Euclidean metric; or
(v) the root-Euclidean metric. The default choice of metric (affine-invariant Riemannian) satisfies several useful properties
not shared by the other metrics, see (Chau and von
Sachs 2019) or (Chau 2018) for more details. Note that this comes
at the cost of increased computation time in comparison to one of the other metrics.
</p>


<h3>Value</h3>

<p>The function returns a list with three components:
</p>
<table role = "presentation">
<tr><td><code>D</code></td>
<td>
<p> the pyramid of wavelet coefficients. This is a list of arrays, where each array contains the
(<code class="reqn">d,d</code>)-dimensional Hermitian wavelet coefficients from the coarsest wavelet scale <code>j = 0</code> up to
the finest wavelet scale <code>j = jmax</code></p>
</td></tr></table>
<p>.
</p>
<table role = "presentation">
<tr><td><code>D.white</code></td>
<td>
<p> the pyramid of whitened wavelet coefficients. The structure of <code>D.white</code> is the same as
<code>D</code>, but with the wavelet coefficients replaced by their whitened counterparts as explained in
(Chau and von
Sachs 2019).</p>
</td></tr>
<tr><td><code>M0</code></td>
<td>
<p> a numeric array containing the midpoint(s) at the coarsest scale <code>j = 0</code> in the midpoint pyramid.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function does not check for positive definiteness of the input matrices, and (depending on the
specified metric) may fail if matrices are close to being singular.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Chau J, von
Sachs R (2019).
&ldquo;Intrinsic wavelet regression for curves of Hermitian positive definite matrices.&rdquo;
<em>Journal of the American Statistical Association</em>.
doi: <a href="https://doi.org/10.1080/01621459.2019.1700129">10.1080/01621459.2019.1700129</a>.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+InvWavTransf1D">InvWavTransf1D</a></code>, <code><a href="#topic+pdSpecEst1D">pdSpecEst1D</a></code>, <code><a href="#topic+pdNeville">pdNeville</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- rExamples1D(2^8, example = "bumps")
P.wt &lt;- WavTransf1D(P$f, periodic = FALSE)

</code></pre>

<hr>
<h2 id='WavTransf2D'>Forward AI wavelet transform for surface of HPD matrices</h2><span id='topic+WavTransf2D'></span>

<h3>Description</h3>

<p><code>WavTransf2D</code> computes a forward intrinsic average-interpolation (AI) wavelet transform for a
rectangular surface in the manifold of HPD matrices equipped with a metric specified by the user, such as the
affine-invariant Riemannian metric, as described in Chapter 5 of (Chau 2018).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>WavTransf2D(P, order = c(3, 3), jmax, metric = "Riemannian", ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="WavTransf2D_+3A_p">P</code></td>
<td>
<p>a (<code class="reqn">d,d,n1,n2</code>)-dimensional array of HPD matrices corresponding to a rectangular surface of <code class="reqn">(d,d)</code>-dimensional HPD matrices
of size <code class="reqn">n_1 \times n_2</code>, with <code class="reqn">n_1 = 2^{J_1}</code> and <code class="reqn">n_2 = 2^{J_2}</code> for some <code class="reqn">J_1, J_2 &gt; 0</code>.</p>
</td></tr>
<tr><td><code id="WavTransf2D_+3A_order">order</code></td>
<td>
<p>a 2-dimensional numeric vector <code class="reqn">(1,1) \le</code> <code>order</code> <code class="reqn">\le (9,9)</code> corresponding to the marginal
orders of the intrinsic 2D AI refinement scheme, defaults to <code>order = c(3, 3)</code>.</p>
</td></tr>
<tr><td><code id="WavTransf2D_+3A_jmax">jmax</code></td>
<td>
<p>the maximum scale up to which the wavelet coefficients are computed. If <code>jmax</code> is not
specified, it is set equal to the maximum possible scale <code>jmax = max(J1, J2) - 1</code>.</p>
</td></tr>
<tr><td><code id="WavTransf2D_+3A_metric">metric</code></td>
<td>
<p>the metric that the space of HPD matrices is equipped with. The default choice is <code>"Riemannian"</code>,
but this can be one of: <code>"Riemannian"</code>, <code>"logEuclidean"</code>, <code>"Cholesky"</code>, <code>"rootEuclidean"</code> or
<code>"Euclidean"</code>. See also the Details section below.</p>
</td></tr>
<tr><td><code id="WavTransf2D_+3A_...">...</code></td>
<td>
<p>additional arguments for internal use.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The 4-dimensional array <code>P</code> corresponds to a discretized rectangular surface of <code class="reqn">(d,d)</code>-dimensional
HPD matrices. The rectangular surface is of size <code class="reqn">n_1</code> by <code class="reqn">n_2</code>, where both <code class="reqn">n_1</code> and
<code class="reqn">n_2</code> are supposed to be dyadic numbers. <code>WavTransf2D</code> then computes the intrinsic AI wavelet transform
of <code>P</code> based on the given refinement orders and the chosen metric. The marginal refinement orders should be
smaller or equal to 9, and the function computes the wavelet transform using a fast wavelet refinement scheme based on weighted
intrinsic averages with pre-determined weights as explained in Chapter 5 of (Chau 2018). By default <code>WavTransf2D</code>
computes the intrinsic 2D AI wavelet transform equipping the space of HPD matrices with (i) the affine-invariant Riemannian metric as
detailed in e.g., (Bhatia 2009)[Chapter 6] or (Pennec et al. 2006). Instead, the space of HPD matrices
can also be equipped with one of the following metrics; (ii) the Log-Euclidean metric, the Euclidean inner product between matrix
logarithms; (iii) the Cholesky metric, the Euclidean inner product between Cholesky decompositions; (iv) the Euclidean metric and
(v) the root-Euclidean metric. The default choice of metric (affine-invariant Riemannian) satisfies several useful properties
not shared by the other metrics, see (Chau 2018) for more details. Note that this comes at the cost of increased computation
time in comparison to one of the other metrics.
</p>


<h3>Value</h3>

<p>The function returns a list with three components:
</p>
<table role = "presentation">
<tr><td><code>D</code></td>
<td>
<p> the 2D pyramid of wavelet coefficients. This is a list of arrays, where each 4-dimensional array contains the
(<code class="reqn">d,d</code>)-dimensional wavelet coefficients in a 2D grid of locations from the coarsest wavelet scale <code>j = 0</code>
up to the finest wavelet scale <code>j = jmax</code>.</p>
</td></tr>
<tr><td><code>D.white</code></td>
<td>
<p> the 2D pyramid of whitened wavelet coefficients. The structure of <code>D.white</code> is the same as
<code>D</code>, but with the wavelet coefficients replaced by their whitened counterparts as explained in Chapter 5 of
(Chau 2018).</p>
</td></tr>
<tr><td><code>M0</code></td>
<td>
<p> a numeric array containing the midpoint(s) at the coarsest scale <code>j = 0</code> in the 2D midpoint pyramid.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The function does not check for positive definiteness of the input matrices, and (depending on the
specified metric) may fail if matrices are close to being singular.
</p>


<h3>References</h3>

<p>Bhatia R (2009).
<em>Positive Definite Matrices</em>.
Princeton University Press, New Jersey.<br /><br /> Chau J (2018).
<em>Advances in Spectral Analysis for Multivariate, Nonstationary and Replicated Time Series</em>.
phdthesis, Universite catholique de Louvain.<br /><br /> Pennec X, Fillard P, Ayache N (2006).
&ldquo;A Riemannian framework for tensor computing.&rdquo;
<em>International Journal of Computer Vision</em>, <b>66</b>(1), 41&ndash;66.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+InvWavTransf2D">InvWavTransf2D</a></code>, <code><a href="#topic+pdSpecEst2D">pdSpecEst2D</a></code>, <code><a href="#topic+pdNeville">pdNeville</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>P &lt;- rExamples2D(c(2^4, 2^4), 2, example = "tvar")
P.wt &lt;- WavTransf2D(P$f)

</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
