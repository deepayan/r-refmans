<!DOCTYPE html><html lang="en"><head><title>Help for package TensorComplete</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {TensorComplete}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#Altopt'><p>Alternating optimization of the weighted classification loss</p></a></li>
<li><a href='#bic'><p>Bayesian Information Criterion (BIC) value.</p></a></li>
<li><a href='#fit_continuous_cp'><p>Signal tensor estimation from a noisy and incomplete data tensor based on CP low rank tensor method.</p></a></li>
<li><a href='#fit_continuous_tucker'><p>Signal tensor estimation from a noisy and incomplete data tensor based on the Tucker model.</p></a></li>
<li><a href='#fit_nonparaT'><p>Main function for nonparametric tensor estimation and completion based on low sign rank model.</p></a></li>
<li><a href='#fit_ordinal'><p>Main function for parametric tensor estimation and completion based on ordinal observations.</p></a></li>
<li><a href='#likelihood'><p>Log-likelihood function (cost function).</p></a></li>
<li><a href='#predict_ordinal'><p>Predict ordinal-valued tensor entries from the cumulative logistic model.</p></a></li>
<li><a href='#realization'><p>An ordinal-valued tensor randomly simulated from the cumulative model.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Tensor Noise Reduction and Completion Methods</td>
</tr>
<tr>
<td>Version:</td>
<td>0.2.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Chanwoo Lee &lt;chanwoo.lee@wisc.edu&gt;, Miaoyan Wang &lt;miaoyan.wang@wisc.edu&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Chanwoo Lee &lt;chanwoo.lee@wisc.edu&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>pracma, methods, utils, tensorregress, MASS</td>
</tr>
<tr>
<td>Description:</td>
<td>Efficient algorithms for tensor noise reduction and completion. This package includes a suite of parametric and nonparametric tools for estimating tensor signals from noisy, possibly incomplete observations. The methods allow a broad range of data types, including continuous, binary, and ordinal-valued tensor entries. The algorithms employ the alternating optimization. The detailed algorithm description can be found in the following three references.</td>
</tr>
<tr>
<td>URL:</td>
<td>Chanwoo Lee and Miaoyan Wang. Tensor denoising and completion
based on ordinal observations. ICML, 2020.
<a href="http://proceedings.mlr.press/v119/lee20i.html">http://proceedings.mlr.press/v119/lee20i.html</a> Chanwoo Lee and
Miaoyan Wang. Beyond the Signs: Nonparametric tensor completion
via sign series. NeurIPS, 2021.
<a href="https://papers.nips.cc/paper/2021/hash/b60c5ab647a27045b462934977ccad9a-Abstract.html">https://papers.nips.cc/paper/2021/hash/b60c5ab647a27045b462934977ccad9a-Abstract.html</a>
Chanwoo Lee, Lexin Li, Hao Helen Zhang, and Miaoyan Wang.
Nonparametric trace regression in high dimensions via sign
series representation. 2021. <a href="https://arxiv.org/abs/2105.01783">https://arxiv.org/abs/2105.01783</a></td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-04-13 03:26:51 UTC; chanwoolee</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-04-14 08:50:11 UTC</td>
</tr>
</table>
<hr>
<h2 id='Altopt'>Alternating optimization of the weighted classification loss</h2><span id='topic+Altopt'></span>

<h3>Description</h3>

<p>Optimize the weighted classification loss given a weight tensor, an observed data tensor, and a large margin loss. This function is used as a subroutine in the main function <code>fit_nonparaT</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>Altopt(Ybar,W,r,type = c("logistic","hinge"),start = "linear")
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="Altopt_+3A_ybar">Ybar</code></td>
<td>
<p>A given (possibly noisy and incomplete) data tensor.</p>
</td></tr>
<tr><td><code id="Altopt_+3A_w">W</code></td>
<td>
<p>A weight tensor used in the weighted classification loss.</p>
</td></tr>
<tr><td><code id="Altopt_+3A_r">r</code></td>
<td>
<p>A rank to be fitted (CP rank).</p>
</td></tr>
<tr><td><code id="Altopt_+3A_type">type</code></td>
<td>
<p>A large margin loss to be used. Logistic or hinge loss is available.</p>
</td></tr>
<tr><td><code id="Altopt_+3A_start">start</code></td>
<td>
<p>Choice of initialization method. Use random initialization if <code>start</code> = &quot;random&quot;; Use the initialization based on low rank approximation if <code>start</code> = &quot;linear&quot;. Linear initialization is default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned object is a list of components.
</p>
<p><code>binary_obj</code> - Trajectory of binary loss values over iterations.
</p>
<p><code>obj</code> - Trajectory of weighted classification loss values over iterations.
</p>
<p><code>iter</code> - The number of iterations.
</p>
<p><code>error</code> - Trajectory of errors over iterations.
</p>
<p><code>fitted</code> - A tensor that optimizes the weighted classification loss.
</p>


<h3>References</h3>

<p>C. Lee and M. Wang. Beyond the Signs: Nonparametric Tensor Completion via Sign Series. <em>Neural Information Processing Systems 34 (NeurIPS)</em>, 2021.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(tensorregress)
indices = c(2,2,2)
noise = rand_tensor(indices)@data
Theta = array(runif(prod(indices),min=-3,max = 3),indices)

# The signal plus noise model
Y = Theta + noise

# Optimize the weighted classification for given a sign tensor sign(Y) and a weight tensor abs(Y)
result = Altopt(sign(Y),abs(Y),r = 3,type = "hinge",start = "linear")
signTheta = sign(result$fitted)

</code></pre>

<hr>
<h2 id='bic'>Bayesian Information Criterion (BIC) value.</h2><span id='topic+bic'></span>

<h3>Description</h3>

<p>Compute Bayesian Information Criterion (BIC) given a parameter tensor, an observed tensor, the dimension, and the rank based on cumulative logistic model. This BIC function is designed for selecting rank in the <code>fit_ordinal</code> function.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bic(ttnsr,theta,omega,d,r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bic_+3A_ttnsr">ttnsr</code></td>
<td>
<p>An observed tensor.</p>
</td></tr>
<tr><td><code id="bic_+3A_theta">theta</code></td>
<td>
<p>A continuous-valued tensor (latent parameters).</p>
</td></tr>
<tr><td><code id="bic_+3A_omega">omega</code></td>
<td>
<p>The cut-off points.</p>
</td></tr>
<tr><td><code id="bic_+3A_d">d</code></td>
<td>
<p>Dimension of the tensor.</p>
</td></tr>
<tr><td><code id="bic_+3A_r">r</code></td>
<td>
<p>Rank of the tensor.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>BIC value at given inputs based on cumulative logistic model.
</p>

<hr>
<h2 id='fit_continuous_cp'>Signal tensor estimation from a noisy and incomplete data tensor based on CP low rank tensor method.</h2><span id='topic+fit_continuous_cp'></span>

<h3>Description</h3>

<p>Estimate a signal tensor from a noisy and incomplete data tensor using CP low rank tensor method.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_continuous_cp(data,r)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_continuous_cp_+3A_data">data</code></td>
<td>
<p>A given (possibly noisy and incomplete) data tensor.</p>
</td></tr>
<tr><td><code id="fit_continuous_cp_+3A_r">r</code></td>
<td>
<p>A rank to be fitted (CP rank).</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned object is a list of components.
</p>
<p><code>est</code> - An estimated signal tensor based on CP low rank tensor method.
</p>
<p><code>U</code> - A list of factor matrices.
</p>
<p><code>lambda</code> - A vector of tensor singular values.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(tensorregress)
indices = c(2,3,4)
noise = rand_tensor(indices)@data
Theta = array(runif(prod(indices),min=-3,max = 3),indices)

# The signal plus noise model
Y = Theta + noise

# Estimate Theta from CP low rank tensor method
hatTheta = fit_continuous_cp(Y,3)
print(hatTheta$est)

</code></pre>

<hr>
<h2 id='fit_continuous_tucker'>Signal tensor estimation from a noisy and incomplete data tensor based on the Tucker model.</h2><span id='topic+fit_continuous_tucker'></span>

<h3>Description</h3>

<p>Estimate a signal tensor from a noisy and incomplete data tensor using the Tucker model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_continuous_tucker(ttnsr,r,alpha = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_continuous_tucker_+3A_ttnsr">ttnsr</code></td>
<td>
<p>A given (possibly noisy and incomplete) data tensor.</p>
</td></tr>
<tr><td><code id="fit_continuous_tucker_+3A_r">r</code></td>
<td>
<p>A rank to be fitted (Tucker rank).</p>
</td></tr>
<tr><td><code id="fit_continuous_tucker_+3A_alpha">alpha</code></td>
<td>
<p>A signal level
</p>
<p><code>alpha = TRUE</code> If the signal level is unknown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<p><code>C</code> - An estimated core tensor.
</p>
<p><code>A</code> - Estimated factor matrices.
</p>
<p><code>iteration</code> - The number of iterations.
</p>
<p><code>cost</code> - Log-likelihood value at each iteration.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Latent parameters
library(tensorregress)
alpha = 10
A_1 = matrix(runif(10*2,min=-1,max=1),nrow = 10)
A_2 = matrix(runif(10*2,min=-1,max=1),nrow = 10)
A_3 = matrix(runif(10*2,min=-1,max=1),nrow = 10)
C = as.tensor(array(runif(2^3,min=-1,max=1),dim = c(2,2,2)))
theta = ttm(ttm(ttm(C,A_1,1),A_2,2),A_3,3)@data
theta = alpha*theta/max(abs(theta))
adj = mean(theta)
theta = theta-adj
omega = c(-0.2,0.2)+adj

# Observed tensor
ttnsr &lt;- realization(theta,omega)@data

# Estimation of parameters
continuous_est = fit_continuous_tucker(ttnsr,c(2,2,2),alpha = 10)

</code></pre>

<hr>
<h2 id='fit_nonparaT'>Main function for nonparametric tensor estimation and completion based on low sign rank model.</h2><span id='topic+fit_nonparaT'></span>

<h3>Description</h3>

<p>Estimate a signal tensor from a noisy and incomplete data tensor using nonparametric tensor method via sign series.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_nonparaT(Y,truer,H,Lmin,Lmax,option = 2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_nonparaT_+3A_y">Y</code></td>
<td>
<p>A given (possibly noisy and incomplete) data tensor. The function allows both continuous- and binary-valued tensors. Missing value should be encoded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="fit_nonparaT_+3A_truer">truer</code></td>
<td>
<p>Sign rank of the signal tensor.</p>
</td></tr>
<tr><td><code id="fit_nonparaT_+3A_h">H</code></td>
<td>
<p>Resolution parameter.</p>
</td></tr>
<tr><td><code id="fit_nonparaT_+3A_lmin">Lmin</code></td>
<td>
<p>Minimum value of the signal tensor (or minimum value of the tensor Y).</p>
</td></tr>
<tr><td><code id="fit_nonparaT_+3A_lmax">Lmax</code></td>
<td>
<p>Maximum value of the signal tensor (or maximum value of the tensor Y).</p>
</td></tr>
<tr><td><code id="fit_nonparaT_+3A_option">option</code></td>
<td>
<p>A large margin loss to be used. Use logistic loss if <code>option</code> = 1, hinge loss if <code>option</code> = 2. Hinge loss is default.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The returned object is a list of components.
</p>
<p><code>fitted</code> - A series of optimizers that minimize the weighted classification loss at each level.
</p>
<p><code>est</code> - An estimated signal tensor based on nonparametic tensor method via sign series.
</p>


<h3>References</h3>

<p>C. Lee and M. Wang. Beyond the Signs: Nonparametric Tensor Completion via Sign Series. <em>Neural Information Processing Systems 34 (NeurIPS)</em>, 2021.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(tensorregress)
indices = c(2,2,2)
noise = rand_tensor(indices)@data
Theta = array(runif(prod(indices),min=-1,max = 1),indices)

# The signal plus noise model
Y = Theta + noise

# Estimate Theta from nonparametic completion method via sign series
hatTheta = fit_nonparaT(Y,truer = 1,H = 1,Lmin = -1,Lmax = 1, option =2)
print(hatTheta$est)

</code></pre>

<hr>
<h2 id='fit_ordinal'>Main function for parametric tensor estimation and completion based on ordinal observations.</h2><span id='topic+fit_ordinal'></span>

<h3>Description</h3>

<p>Estimate a signal tensor from a noisy and incomplete ordinal-valued tensor using the cumulative logistic model.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fit_ordinal(ttnsr,r,omega=TRUE,alpha = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="fit_ordinal_+3A_ttnsr">ttnsr</code></td>
<td>
<p>A given (possibly noisy and incomplete) data tensor. The function allows binary- and ordinal-valued tensors. Missing value should be encoded as <code>NA</code>.</p>
</td></tr>
<tr><td><code id="fit_ordinal_+3A_r">r</code></td>
<td>
<p>A rank to be fitted (Tucker rank).</p>
</td></tr>
<tr><td><code id="fit_ordinal_+3A_omega">omega</code></td>
<td>
<p>The cut-off points if known,
</p>
<p><code>omega = TRUE</code> if unknown.</p>
</td></tr>
<tr><td><code id="fit_ordinal_+3A_alpha">alpha</code></td>
<td>
<p>A signal level
</p>
<p><code>alpha = TRUE</code> if the signal level is unknown.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following:
</p>
<p><code>C</code> - An estimated core tensor.
</p>
<p><code>A</code> - Estimated factor matrices.
</p>
<p><code>theta</code> - An estimated latent parameter tensor.
</p>
<p><code>iteration</code> - The number of iterations.
</p>
<p><code>cost</code> - Log-likelihood value at each iteration.
</p>
<p><code>omega</code> - Estimated cut-off points.
</p>


<h3>References</h3>

<p>C. Lee and M. Wang. Tensor denoising and completion based on ordinal observations. <em>International Conference on Machine Learning (ICML)</em>, 2020.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Latent parameters
library(tensorregress)
alpha = 10
A_1 = matrix(runif(10*2,min=-1,max=1),nrow = 10)
A_2 = matrix(runif(10*2,min=-1,max=1),nrow = 10)
A_3 = matrix(runif(10*2,min=-1,max=1),nrow = 10)
C = as.tensor(array(runif(2^3,min=-1,max=1),dim = c(2,2,2)))
theta = ttm(ttm(ttm(C,A_1,1),A_2,2),A_3,3)@data
theta = alpha*theta/max(abs(theta))
adj = mean(theta)
theta = theta-adj
omega = c(-0.2,0.2)+adj

# Observed tensor
ttnsr &lt;- realization(theta,omega)@data

# Estimation of parameters
ordinal_est = fit_ordinal(ttnsr,c(2,2,2),omega = TRUE,alpha = 10)

</code></pre>

<hr>
<h2 id='likelihood'>Log-likelihood function (cost function).</h2><span id='topic+likelihood'></span>

<h3>Description</h3>

<p>Return log-likelihood function (cost function) value evaluated at a given parameter tensor, an observed tensor, and cut-off points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>likelihood(ttnsr,theta,omega,type = c("ordinal","Gaussian"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="likelihood_+3A_ttnsr">ttnsr</code></td>
<td>
<p>An observed tensor data.</p>
</td></tr>
<tr><td><code id="likelihood_+3A_theta">theta</code></td>
<td>
<p>A continuous-valued tensor (latent parameters).</p>
</td></tr>
<tr><td><code id="likelihood_+3A_omega">omega</code></td>
<td>
<p>The cut-off points.</p>
</td></tr>
<tr><td><code id="likelihood_+3A_type">type</code></td>
<td>
<p>Types of log-likelihood function.
</p>
<p><code>"ordinal"</code> specifies log-likelihood function based on the cumulative logistic model.
</p>
<p><code>"Gaussian"</code> specifies log-likelihood function based on the Gaussian model.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Log-likelihood value at given inputs.
</p>

<hr>
<h2 id='predict_ordinal'>Predict ordinal-valued tensor entries from the cumulative logistic model.</h2><span id='topic+predict_ordinal'></span>

<h3>Description</h3>

<p>Predict ordinal-valued tensor entries given latent parameters and a type of estimations.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_ordinal(theta,omega,type = c("mode","mean","median"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_ordinal_+3A_theta">theta</code></td>
<td>
<p>A continuous-valued tensor (latent parameters).</p>
</td></tr>
<tr><td><code id="predict_ordinal_+3A_omega">omega</code></td>
<td>
<p>The cut-off points.</p>
</td></tr>
<tr><td><code id="predict_ordinal_+3A_type">type</code></td>
<td>
<p>Type of estimations:
</p>
<p><code>"mode"</code> specifies argmax based label estimation.
</p>
<p><code>"mean"</code> specifies mean based label estimation.
</p>
<p><code>"median"</code> specifies median based label estimation.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A predicted ordinal-valued tensor given latent parameters and a type of estimations.
</p>


<h3>References</h3>

<p>C. Lee and M. Wang. Tensor denoising and completion based on ordinal observations. <em>International Conference on Machine Learning (ICML)</em>, 2020.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>indices &lt;- c(10,20,30)
arr &lt;- array(runif(prod(indices),-2,2),dim = indices)
b &lt;- c(-1.5,0,1.5)
r_predict &lt;- predict_ordinal(arr,b,type = "mode");r_predict
</code></pre>

<hr>
<h2 id='realization'>An ordinal-valued tensor randomly simulated from the cumulative model.</h2><span id='topic+realization'></span>

<h3>Description</h3>

<p>Simulate an ordinal-valued tensor from the cumulative logistic model with the parameter tensor and the cut-off points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>realization(theta,omega)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="realization_+3A_theta">theta</code></td>
<td>
<p>A continuous-valued tensor (latent parameters).</p>
</td></tr>
<tr><td><code id="realization_+3A_omega">omega</code></td>
<td>
<p>The cut-off points.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An ordinal-valued tensor randomly simulated from the cumulative logistic model.
</p>


<h3>References</h3>

<p>C. Lee and M. Wang. Tensor denoising and completion based on ordinal observations. <em>International Conference on Machine Learning (ICML)</em>, 2020.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>indices &lt;- c(10,20,30)
arr &lt;- array(runif(prod(indices)),dim = indices)
b &lt;- qnorm((1:3)/4)
r_sample &lt;- realization(arr,b);r_sample
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
