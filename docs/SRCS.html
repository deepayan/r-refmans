<!DOCTYPE html><html><head><title>Help for package SRCS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {SRCS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#SRCS'><p>R package implementing the Statistical Ranking Color Scheme for visualizing the results of multiple parameterized pairwise comparisons.</p></a></li>
<li><a href='#ML1'>
<p>Performance of 6 different supervised classification algorithms on eight noisy datasets (see references)</p></a></li>
<li><a href='#MPB'>
<p>Performance of 8 different dynamic optimization algorithms on the Moving Peaks Benchmark (see references)</p></a></li>
<li><a href='#MPBall'>
<p>Performance of 3 different dynamic optimization algorithms on the Moving Peaks Benchmark captured at five time moments of the execution (see references)</p></a></li>
<li><a href='#plot.SRCS'><p>Heatmap plot of the ranking achieved by a target variable levels after all statistical pairwise comparisons in multi-parameter problem instances.</p></a></li>
<li><a href='#SRCScomparison'><p>Compares the performance of two algorithms for a single problem configuration specified by the user.</p></a></li>
<li><a href='#SRCSranks'><p>Computes the ranks of all the algorithms from their (repeated) results measurements after</p>
grouping them by several factors combined simultaneosly.</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Title:</td>
<td>Statistical Ranking Color Scheme for Multiple Pairwise
Comparisons</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of the SRCS method for a color-based visualization of the
    results of multiple pairwise tests on a large number of problem configurations, proposed in: 
    I.G. del Amo, D.A. Pelta. SRCS: a technique for comparing multiple algorithms under several
    factors in dynamic optimization problems. In: E. Alba, A. Nakib, P. Siarry
    (Eds.), Metaheuristics for Dynamic Optimization. Series: Studies in
    Computational Intelligence 433, Springer, Berlin/Heidelberg, 2012.</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2015-06-30</td>
</tr>
<tr>
<td>Author:</td>
<td>Pablo J. Villacorta &lt;pjvi@decsai.ugr.es&gt;</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Pablo J. Villacorta &lt;pjvi@decsai.ugr.es&gt;</td>
</tr>
<tr>
<td>Imports:</td>
<td>parallel, graphics, stats, grDevices, methods</td>
</tr>
<tr>
<td>Suggests:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/LGPL-3">LGPL (&ge; 3)</a></td>
</tr>
<tr>
<td>URL:</td>
<td><a href="http://decsai.ugr.es/~pjvi/r-packages.html">http://decsai.ugr.es/~pjvi/r-packages.html</a></td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>R.rsp</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2015-07-01 23:49:46 UTC; Pablo</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2015-07-02 06:47:17</td>
</tr>
</table>
<hr>
<h2 id='SRCS'>R package implementing the Statistical Ranking Color Scheme for visualizing the results of multiple parameterized pairwise comparisons.</h2><span id='topic+SRCS'></span><span id='topic+SRCS-package'></span>

<h3>Description</h3>

<p>An R implementation of SRCS: Statistical Ranking Color Scheme for visualizing the results of multiple pairwise comparisons in many
problem configurations at the same time, each defined by at most 3 additional parameters. For each problem configuration,
this technique ranks every level of the target value according to the performance in relation to how other levels
perform on the same problem configuration. Ranks are assigned according to statistical performance comparisons. Then,
a color is associated to each rank so it can be easily visualized and interpreted.
</p>


<h3>References</h3>

<p>I.G. del Amo, D.A.Pelta. SRCS: a technique for comparing multiple algorithms under several
factors in dynamic optimization problems, in: E. Alba, A. Nakib, P. Siarry (Eds.), Metaheuristics for Dynamic Optimization.
Series: Studies in Computational Intelligence 433, Springer, Berlin/Heidelberg, 2012.
</p>

<hr>
<h2 id='ML1'>
Performance of 6 different supervised classification algorithms on eight noisy datasets (see references)
</h2><span id='topic+ML1'></span>

<h3>Description</h3>

<p>Dataset with the test accuracy of 6 supervised classification algorithms on eight noisy datasets.
The way noise is introduced in originally clear datasets can be adjusted according to some parameters such as the noise type 
(attribute noise versus class noise) and the noise ratio.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(ML1)</code></pre>


<h3>Format</h3>

<p>A data frame with 52800 observations on the following 6 variables.
</p>

<dl>
<dt><code>Algorithm</code></dt><dd><p>A factor with 6 levels: <code>1-NN, 3-NN, 5-NN, C4.5, RIPPER, SVM</code>
that correspond to 6 different supervised classification algorithms.</p>
</dd>
<dt><code>Dataset</code></dt><dd><p>A factor with 8 levels: <code>autos, balanced, cleveland, ecoli, ionosphere, pima,</code> <code>vehicle</code> corresponding to the
names of eight datasets in which noise has been introduced artificially.</p>
</dd>
<dt><code>Noise type</code></dt><dd><p>A factor with 4 levels: <code>ATT_GAUS, ATT_RAND, CLA_PAIR, CLA_RAND</code> that correspond to
the type of noise introduced: ATT_* to denote noise added to (a percentage of) the attributes of the instance (either in a gaussian or 
uniformly random way), and CLA_* to denote noise which modifies the class of (a percentage of) the instances of the dataset
(either by any other class at random, as in CLA_RAND, or by replacing the label of only a percentage of the examples of the majority class by 
the label of the second-majority class as in CLA_PAIR).</p>
</dd>
<dt><code>Noise ratio</code></dt><dd><p>A real number with the ratio of attributes affected by noise (for <code>ATT_GAUS</code> and <code>ATT_RAND</code>), or 
the ratio of examples within the global dataset affected by a class error (for <code>CLA_PAIR</code> and <code>CLA_RAND</code>).</p>
</dd>
<dt><code>Fold</code></dt><dd><p>An integer number (between 1 and 25) associated with the repetition of the experiment. Recall that test results were obtained by
repeating five independent times a complete 5-fold Cross Validation process.</p>
</dd>
<dt><code>Performance</code></dt><dd><p>Real number between 0 and 1 with the accuracy (in percentage) of the classifier over the test examples.</p>
</dd>
</dl>



<h3>Source</h3>

<p>J.A. Saez, M.Galar, J.Luengo, F.Herrera, Tackling the Problem of Classification 
with Noisy Data using Multiple Classifier Systems: Analysis of the Performance and Robustness. 
Information Sciences, 247 (2013) 1-20.
</p>


<h3>References</h3>

<p>Christopher M. Bishop. Pattern Recognition and Machine Learning. Springer (2006).
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(ML1)
str(ML1)
head(ML1)
</code></pre>

<hr>
<h2 id='MPB'>
Performance of 8 different dynamic optimization algorithms on the Moving Peaks Benchmark (see references)
</h2><span id='topic+MPB'></span>

<h3>Description</h3>

<p>Dataset with the performance of several dynamic optimization algorithms in the Moving Peaks Benchmark problem (see the source section).
The MPB function can be configured according to some parameters such as the dimension, the change frequency and the severity of changes.
The performance measure employed is the average offline error.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MPB)</code></pre>


<h3>Format</h3>

<p>A data frame with 220000 observations on the following 5 variables.
</p>

<dl>
<dt><code>Algorithm</code></dt><dd><p>A factor with levels <code>reactive-cs</code> <code>independent-cs</code> <code>mqso-both</code> <code>mqso-rand</code> <code>mqso-change</code> <code>mqso</code> <code>agents</code> <code>soriga</code>
that correspond to 8 different algorithms for dynamic optimization applied to the Moving Peaks Benchmark function.</p>
</dd>
<dt><code>Dim</code></dt><dd><p>A numeric vector with the dimension (number of input variables) of the MPB function.</p>
</dd>
<dt><code>CF</code></dt><dd><p>A numeric vector with the change frequency along the time, i.e. the number of evaluations of the fitness function after which a change of the location of the function maxima happens.</p>
</dd>
<dt><code>Severity</code></dt><dd><p>A numeric vector with the severity of a change when it occurs.</p>
</dd>
<dt><code>OffError</code></dt><dd><p>A numeric vector with the performance measure, in this case the offline error computed as the average of the offline errors just before every change.</p>
</dd>
</dl>



<h3>Source</h3>

<p>I.G. del Amo, D.A. Pelta. SRCS: a technique for comparing multiple algorithms under several factors in dynamic optimization problems, in: 
E. Alba, A. Nakib, P. Siarry (Eds.), Metaheuristics for Dynamic Optimization. Series: Studies in Computational Intelligence 433, Springer, Berlin/Heidelberg, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MPB)
str(MPB)
head(MPB)
</code></pre>

<hr>
<h2 id='MPBall'>
Performance of 3 different dynamic optimization algorithms on the Moving Peaks Benchmark captured at five time moments of the execution (see references)
</h2><span id='topic+MPBall'></span>

<h3>Description</h3>

<p>Dataset with the performance of several dynamic optimization algorithms in the Moving Peaks Benchmark problem (see the source section) at five time moments, just before a change.
The MPB function can be configured according to some parameters such as the dimension, the change frequency and the severity of changes.
The performance measure employed is the average offline error, averaged from the beginning up to each time moment.
This dataset serves for illustrating how to compose a video sequence using function <code><a href="#topic+animatedplot">animatedplot</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(MPBall)</code></pre>


<h3>Format</h3>

<p>A data frame with 82500 observations on the following variables.
</p>

<dl>
<dt><code>Algorithm</code></dt><dd><p>A factor with levels <code>reactive-cs</code> <code>independent-cs</code> <code>mqso-both</code> <code>mqso-rand</code> <code>mqso-change</code> <code>mqso</code> <code>agents</code> <code>soriga</code>
that correspond to 8 different algorithms for dynamic optimization applied to the Moving Peaks Benchmark function.</p>
</dd>
<dt><code>Dim</code></dt><dd><p>A numeric vector with the dimension (number of input variables) of the MPB function.</p>
</dd>
<dt><code>CF</code></dt><dd><p>A numeric vector with the change frequency along the time, i.e. the number of evaluations of the fitness function after which a change of the location of the function maxima happens.</p>
</dd>
<dt><code>Severity</code></dt><dd><p>A numeric vector with the severity of a change when it occurs.</p>
</dd>
<dt>OffError_1,OffError_25,OffError_49,OffError_73,OffError_97</dt><dd>
<p>A numeric vector with the performance measure, in this case the offline error computed as the average (over the previous changes) of the offline errors just before every change. Each
algorithm was allowed to run for 100 slices, but we have selected only 5 moments of that process, i.e. before the first change, the 25th change, the 49th, 73th and 97th change, in
order to keep the resulting dataset reasonably small.</p>
</dd>
</dl>



<h3>Source</h3>

<p>I.G. del Amo, D.A. Pelta. SRCS: a technique for comparing multiple algorithms under several factors in dynamic optimization problems, in: 
E. Alba, A. Nakib, P. Siarry (Eds.), Metaheuristics for Dynamic Optimization. Series: Studies in Computational Intelligence 433, Springer, Berlin/Heidelberg, 2012.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(MPBall)
str(MPBall)
head(MPBall)
</code></pre>

<hr>
<h2 id='plot.SRCS'>Heatmap plot of the ranking achieved by a target variable levels after all statistical pairwise comparisons in multi-parameter problem instances.</h2><span id='topic+animatedplot'></span><span id='topic+plot.SRCS'></span><span id='topic+singleplot'></span>

<h3>Description</h3>

<p><code>plot.SRCS</code>: Function to display a grid of heatmaps representing the statistical ranking of one level of the target factor (usually, the algorithm)
vs the rest of levels of the target factor, over several problem configurations characterized by (at most) 3 parameters in addition to the target factor.
</p>
<p><code>animatedplot</code>: Function to generate an animated video consisting of a temporal sequence of grid plots like those generated by <code><a href="#topic+plot.SRCS">plot.SRCS</a></code>.
The function requires software ImageMagick has been installed.
</p>
<p><code>singleplot</code>: Function to display either a single heatmap representing the statistical ranking of one level of the target factor (usually, the algorithm)
vs the rest of levels of the target factor, over one single problem configurations defined by a combination of values for the problem configuration parameters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'SRCS'
plot(x, yOuter, xOuter, yInner, xInner, zInner = "rank",
  out.Y.par = list(), out.X.par = list(), inner.X.par = list(),
  inner.Y.par = list(), colorbar.par = list(),
  color.function = heat.colors, heatmaps.per.row = NULL,
  heatmaps.titles = NULL, show.colorbar = TRUE, annotation.lab = NULL,
  heat.cell.par = list(), heat.axes.par = list(),
  colorbar.cell.par = list(), colorbar.axes.par = list(),
  annotation.text.par = list(), ...)

animatedplot(x, filename, path.to.converter, yOuter, xOuter, yInner, xInner,
  zInner, width = 800, height = 800, res = 100, pointsize = 16,
  delay = 30, type = c("png", "jpeg", "bmp", "tiff"), quality = 75,
  compression = c("none", "rle", "lzw", "jpeg", "zip"), annotations = NULL,
  ...)

singleplot(x, yInner, xInner, zInner = "rank", color.function = heat.colors,
  labels.par = list(), colorbar.par = list(), heat.axes.par = list(),
  colorbar.axes.par = list(), haxis = TRUE, vaxis = TRUE, title = "",
  show.colorbar = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.SRCS_+3A_x">x</code></td>
<td>
<p>An SRCS object containing columns for the names of the problem parameters (including the algorithm) and the rank obtained
by that algorithm when compared with the rest over the same problem configuration. Typically this is the object returned by a call to <code><a href="#topic+SRCSranks">SRCSranks</a></code>.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_youter">yOuter</code>, <code id="plot.SRCS_+3A_xouter">xOuter</code></td>
<td>
<p>Names of the variables in <code>x</code> that will be placed vertically (in the left-most part) and horizontally (on the top), respectively.
Each level of <code>yOuter</code> (resp. <code>xOuter</code>) corresponds to a complete row (complete column) of heatmaps in the grid.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_yinner">yInner</code>, <code id="plot.SRCS_+3A_xinner">xInner</code></td>
<td>
<p>Names of the variables in <code>x</code> that will be placed on the Y axis and on the X axis of every heatmap, respectively.
Each level of <code>yInner</code> (resp. <code>xInner</code>) corresponds to a row (column) inside a heatmap.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_zinner">zInner</code></td>
<td>
<p>Name of the variable in <code>x</code> that will be represented with a color code inside every heatmap. Usually corresponds to the ranking column of <code>x</code>,
which will most often contain integer values (negatives are allowed). When the SRCS object being plotted has been returned by a call to <code>SRCSranks</code>,
this column is called &quot;rank&quot;.
For <code><a href="#topic+animatedplot">animatedplot</a></code>, it should be a vector of strings containing the names of the ranks
columns that will be depicted, each at a time, sorted by time instant (from the earliest to the most recent).</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_out.y.par">out.Y.par</code>, <code id="plot.SRCS_+3A_out.x.par">out.X.par</code></td>
<td>
<p>A tagged list with parameters to configure how the labels of the outer Y and X variables and their levels are displayed.
Valid parameters and their default values are as follows:
</p>

<ul>
<li><p><code>lab = TRUE</code> Label with the name of the variable. Will be displayed vertically
for the outer Y variable and horizontally for the outer X variable. Valid values: FALSE for no label;
NULL or TRUE for the name of the outer variable; and any string for a specific label. Defaults to TRUE.
</p>
</li>
<li><p><code>lab.width = lcm(1)</code> Width of the left-most column (for the outer Y variable) or top row (for the outer X variable) containing the name of the variable.
</p>
</li>
<li><p><code>lab.textpar = list(cex = 1.6)</code> Rest of parameters that will be passed to <code><a href="graphics.html#topic+text">text</a></code> to display this label.
Parameter <code>cex</code> (text magnification factor) will be set 1.6 by default when not provided. 
</p>
</li>
<li><p><code>levels.lab = TRUE</code> Whether a label should be displayed (or not) for every level of the variable. 
</p>
</li>
<li><p><code>levels.lab.width = lcm(1)</code>    Width of the row or column containing the levels of the variable.
</p>
</li>
<li><p><code>levels.lab.textpar = list(cex = 1.4)</code> Tagged list with more parameters that will be passed directly to <code><a href="graphics.html#topic+text">text</a></code> to display this label.
Parameter <code>cex</code> (text magnification factor) will be set 1.4 by default when not provided.
NOTE: if present, the value of parameter <code>str</code> will always be overwritten by 0 (horizontal text) for the outer X, and 90 (vertical text) for the outer Y variable.
</p>
</li>
<li><p><code>lab.bg = NULL</code> Background color of the rectangle where the label is placed. Default is transparent.
No additional checks will be done concerning the validity of this parameter.
</p>
</li>
<li><p><code>levels.bg = NULL</code> Background color of the rectangle where the levels of the label are placed. Default is transparent.
No additional checks will be done concerning the validity of this parameter.
</p>
</li>
<li><p><code>lab.border = NULL</code> Border color of the rectangle where the label is placed. Defaults to NULL (no line).
No additional checks will be done concerning the validity of this parameter.
</p>
</li>
<li><p><code>levels.border    = NULL</code> Line color of the rectangle border where the levels of this label are placed. Defaults to NULL (no line).
No additional checks will be done concerning the validity of this parameter.
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_inner.x.par">inner.X.par</code>, <code id="plot.SRCS_+3A_inner.y.par">inner.Y.par</code></td>
<td>
<p>A tagged list with parameters to configure how the labels of the innter Y and X variables and their levels are displayed.
Valid parameters and their default values are the following:
</p>

<ul>
<li><p><code>lab = TRUE</code>    Inner label to be shown. Valid values are FALSE for no label, NULL or TRUE for the name of variable passed as argument to <code><a href="#topic+plot.SRCS">plot.SRCS</a></code>,
or any string for a specific label. Defaults to TRUE.
</p>
</li>
<li><p><code>lab.width = lcm(1)</code> Width of the optional space for the label of the inner Y variable.
The label will be repeated along the rows of the left-most column of heatmaps.
</p>
</li>
<li><p><code>lab.textpar = list(cex = 1)</code>    Rest of parameters passed to <code><a href="graphics.html#topic+text">text</a></code> to display this label. 
</p>
</li>
<li><p><code>levels.loc = c("bottom", "left", "all", "none")</code> Location of the inner level labels: only in heatmaps of the left-most column or the bottom row,
or in every heatmap of the plot, or none. Defaults to &quot;bottom&quot; for the inner X variable and &quot;left&quot; for the inner Y variable.
When levels.loc is set to &quot;none&quot;, the value of params[[&quot;levels.at&quot;]] is ignored.
</p>
</li>
<li><p><code>levels.at = NULL</code> Levels of the inner variable where the label will be shown. Defaults to all the levels. They can be provided in any order,
since the order in which they will be displayed only depends on the order defined by the levels argument when that factor column of the data was created.
</p>
</li>
<li><p><code>levels.las = 1</code> Orientation of the level labels of this variable, defined as in <code><a href="graphics.html#topic+axis">axis</a></code>. 1 for horizontal, 2  for vertical.
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_colorbar.par">colorbar.par</code></td>
<td>
<p>Tagged list to configure the aspect of the colorbar legend displayed on the right part of the figure:
</p>

<ul>
<li><p><code>levels.at = NULL</code> String vector: Levels at which the Y axis ticks of the colorbar will be shown. By default, three levels will be labeled:
0, the <code>min(x[[zInner]])</code> and <code>max(x[[zInner]])</code>.
</p>
</li>
<li><p><code>hlines = TRUE</code> Logical: whether black horizontal lines should be displayed in the colorbar to separate the colors. Defaults to TRUE. 
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_color.function">color.function</code></td>
<td>
<p>A custom function that receives one argument (number of colors to be generated, (maxrank - minrank + 1) in our case) and returns a vector of that length
with the hexadecimal codes of the colors to be used in the heatmaps, see <code>heat.colors</code> or <code>terrain.colors</code> for instance. Defaults to the <code>heat.colors</code> function.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_heatmaps.per.row">heatmaps.per.row</code></td>
<td>
<p>Maximum number of heatmaps displayed in a row of the grid. Useful when variable <code>xOuter</code> has too many levels so they can be
splitted in two or more sub-rows of heatmaps, with all the sub-rows corresponding to a single level of the <code>yOuter</code> variable.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_heatmaps.titles">heatmaps.titles</code></td>
<td>
<p>A vector of the same length as the total number of heatmaps, i.e. unique(x[[yOuter]]) * unique(x[[xOuter]]), containing the
titles to be displayed on top of each heatmap. The elements of the vector will be associated to the heatmaps of the grid from left to right and from top to bottom.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_show.colorbar">show.colorbar</code></td>
<td>
<p>Logical: whether a colorbar legend will be shown on the right of the figure (one for each row of heatmaps) or not. Defaults to TRUE</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_annotation.lab">annotation.lab</code></td>
<td>
<p>String with the annotation title that will be displayer on the top left corner. Defaults to NULL, indicating no annotation will be shown.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_heat.cell.par">heat.cell.par</code></td>
<td>
<p>Tagged list that will be passed to <code><a href="graphics.html#topic+par">par</a></code> just before displaying each heatmap. This way expert users can configure exactly
the appearance of the heatmaps. No additional checks will be done concerning the validity of this list.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_heat.axes.par">heat.axes.par</code></td>
<td>
<p>Tagged list that will be passed to <code><a href="graphics.html#topic+axis">axis</a></code> when creating the heatmap axes. No additional validity checks are done.
The values of the arguments <code>side, at, labels</code> will always be replaced by suitable ones according to <code>inner.X.par[["levels.at"]]</code> or <code>inner.Y.par[["levels.at"]]</code>.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_colorbar.cell.par">colorbar.cell.par</code></td>
<td>
<p>Tagged list that will be passed to <code><a href="graphics.html#topic+par">par</a></code> just before showing each colorbar. No additional validity checks are done.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_colorbar.axes.par">colorbar.axes.par</code></td>
<td>
<p>Tagged list that will be passed to <code><a href="graphics.html#topic+axis">axis</a></code> to draw the axes of the colorbar. No additional validity checks are done.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_annotation.text.par">annotation.text.par</code></td>
<td>
<p>Tagged list that will be passed to <code><a href="graphics.html#topic+text">text</a></code> to show an additional title on the top left corner. No additional validity checks are done.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_...">...</code></td>
<td>
<p>(In <code>animatedplot</code>): Rest of optional parameters that will be passed to <code><a href="#topic+plot.SRCS">plot.SRCS</a></code> to plot every frame.
(In <code>singleplot</code>): A number of named arguments of the form <code>variable = value</code>, where <code>variable</code> is a column in <code>x</code>, for subsetting
<code>x</code> in a way that there exists exactly one occurrence of all the levels of <code>zInner</code> for each combination of yInner,xInner.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_filename">filename</code></td>
<td>
<p>Name of the output video file, including the extension. It is strongly recommended that the name ends in &quot;.gif&quot; to preserve most of image quality.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_path.to.converter">path.to.converter</code></td>
<td>
<p>String with the full path to the converter program delivered with ImageMagick, e.g. &quot;C:/Program Files/ImageMagick-&lt;version&gt;/convert.exe&quot;</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_width">width</code>, <code id="plot.SRCS_+3A_height">height</code></td>
<td>
<p>Width and height, in pixels, of the result video. Both default to 800</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_res">res</code></td>
<td>
<p>Nominal resolution (in ppi) of the output video. Used to set text size and line widths. Defaults to 100. See <code><a href="grDevices.html#topic+png">png</a>, <a href="grDevices.html#topic+jpeg">jpeg</a>, <a href="grDevices.html#topic+bmp">bmp</a>, <a href="grDevices.html#topic+tiff">tiff</a></code>.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_pointsize">pointsize</code></td>
<td>
<p>Point size argument to be passed to the functions that print to image. Defaults to 16.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_delay">delay</code></td>
<td>
<p>Time delay (in 1/100th of a second) spent in each of the images that compose the video. Defaults to 30, i.e. 0.3 seconds.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_type">type</code></td>
<td>
<p>The type of image file generated for each frame. The image files will be then joined together into a video. Should be one of <code>"png", "jpeg", "bmp", "tiff"</code>.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_quality">quality</code></td>
<td>
<p>The quality of the images, in a scale from 1 to 100. The less the quality, the more the compression and the smaller the file size.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_compression">compression</code></td>
<td>
<p>(For TIFF format only) Used to indicate the kind of compression. Must be one of <code>"none", "rle", "lzw", "jpeg"</code>. Ignored if <code>type</code> is not <code>"tiff"</code>.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_annotations">annotations</code></td>
<td>
<p>Vector of strings with the annotation label of every image of the video. Should have the same length as <code>zInner</code>. Defaults to NULL (no annotations).</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_labels.par">labels.par</code></td>
<td>
<p>Tagged list to configure how the labels will be displayed:
</p>

<ul>
<li><p><code>xlab    = TRUE</code> Label with the name of the variable for the X axis. Will be displayed horizontally. Valid values:
FALSE for no label; NULL or TRUE for the name of the outer variable; and any string for a specific label. Defaults to TRUE.
</p>
</li>
<li><p><code>ylab    = TRUE</code> Analogous for  the Y axis.
</p>
</li>
<li><p><code>xlevels.at = NULL</code> Levels of the X axis variable where the label will be shown. Defaults to all the levels.
The levels can be provided in any order, since the order in which they will be depicted only depends on the original order defined
when the corresponding factor column of the data was created.
</p>
</li>
<li><p><code>ylevels.at = NULL</code> Analogous for Y axis variable.
</p>
</li></ul>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_haxis">haxis</code>, <code id="plot.SRCS_+3A_vaxis">vaxis</code></td>
<td>
<p>Whether the X and the Y axes should be displayed or not. Defaults to TRUE for both.</p>
</td></tr>
<tr><td><code id="plot.SRCS_+3A_title">title</code></td>
<td>
<p>Title of the plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>plot.SRCS</code> plots a grid with the results over all problem configurations, and should be applied to the object returned by <code><a href="#topic+SRCSranks">SRCSranks</a></code> with
only one <code>performance</code> column.
</p>
<p><code>singleplot</code> is used for plotting only one heatmap for a subset of problem configurations
in which the outer X and Y parameters take a fixed value, and should be applied to the object returned by <code><a href="#topic+SRCScomparison">SRCScomparison</a></code>.
</p>
<p><code>animatedplot</code> creates a video from a sequence of plots, intended to show the temporal evolution of the ranking over time.
It should be applied only to the object returned by <code><a href="#topic+SRCSranks">SRCSranks</a></code> when the <code>performance</code> argument passed to it was a vector of strings,
each of them being the performance column of the data at a given time instant.
</p>


<h3>Note</h3>

<p>The function uses the base graphics system.
</p>


<h3>See Also</h3>

<p><code><a href="graphics.html#topic+text">text</a>, <a href="graphics.html#topic+par">par</a>, <a href="graphics.html#topic+axis">axis</a>, <a href="#topic+SRCSranks">SRCSranks</a>, <a href="#topic+animatedplot">animatedplot</a>, <a href="#topic+singleplot">singleplot</a></code>,
<a href="RColorBrewer.html#topic+brewer.pal">brewer.pal</a>, <a href="colorspace.html#topic+RGB">RGB</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Example from a Machine Learning problem with noisy data
	ranks = SRCSranks(ML1, params = c("Dataset", "Noise type", "Noise ratio"),
	  target = "Algorithm", performance="Performance", maximize = TRUE, ncores = 2,
	  paired = TRUE, pairing.col = "Fold");
	singleplot(ranks, yInner = "Noise type",
   xInner = "Noise ratio", Algorithm = "C4.5", Dataset = "glass")
	plot(x = ranks, yOuter = "Dataset", xOuter = "Algorithm", yInner = "Noise type",
	  xInner = "Noise ratio", out.X.par = list(levels.lab.textpar =
	  list(col = "white"), levels.bg = "black", levels.border = "white"),
	  out.Y.par = list(levels.bg = "gray"), colorbar.axes.par = list(cex.axis = 0.8),
	  show.colorbar = TRUE)
	SRCScomparison(ranks, "Algorithm", Dataset = "automobile", `Noise type` = "ATT_GAUS",
	  `Noise ratio`= 10, pvalues = FALSE)
# ---------------------------------------------------
## Not run: 
mat = matrix(NA, nrow = nrow(MPBall), ncol = ncol(MPBall))
# First, take the average of the previous performance columns up to each change point
for(j in 6:ncol(MPBall)){
  mat[,j] = rowSums(MPBall[,5:j])/(j-5+1)
}
MPBall[,6:ncol(MPBall)] = mat[,6:ncol(MPBall)]

ranksall = SRCSranks(MPBall, params = c("Dim", "CF", "Severity"), target="Algorithm",
   test = "tukeyHSD", performance=paste("OffError", seq(from=1, to = 100, by = 24),
   sep = "_"), maximize = FALSE, ncores = 2)

# Adjust argument path.to.converter to point to ImageMagick convert utility
animatedplot(x = ranksall, filename = "MPBconv_reduced.gif",
	             path.to.converter = "C:/Program Files/ImageMagick-6.8.8-Q8/convert.exe",
	             yOuter = "Algorithm", xOuter = "Dim", yInner = "CF", xInner = "Severity",
	             zInner = paste0("rank",1:5), delay = 30,
	             annotations = paste0("At change ",seq.int(from = 1, to = 100, by = 24)),
	             inner.Y.par = list(levels.at = c("40", "200", "400", "600", "800", "1000"),
              lab = "Change\nfrequency", levels.loc = "left"),
	             heat.cell.par = list(pty = "s"),
	             inner.X.par = list(levels.at = c("2", "8", "14")),
	             out.Y.par = list(levels.lab.textpar = list(cex = 1, col = "white"),
              levels.bg = "black", levels.border = "white"),
	             out.X.par = list(lab = "Dimension", levels.bg = "gray"),
	             colorbar.par = list(levels.at = c("-2", "0", "2")),
	             colorbar.axes.par = list(cex.axis = 0.8),
	             show.colorbar = TRUE, height = 500
            )
# The full dataset (20 MB) can be downloaded from
# http://decsai.ugr.es/~pjvi/SRCSfiles/MPBall.RData
# (the average must still be computed before plotting, just as in the example above)
# Check the script in http://decsai.ugr.es/~pjvi/SRCSfiles/DOPvideoScript.R

## End(Not run)
</code></pre>

<hr>
<h2 id='SRCScomparison'>Compares the performance of two algorithms for a single problem configuration specified by the user.</h2><span id='topic+SRCScomparison'></span>

<h3>Description</h3>

<p>Compares the performance of two algorithms for a single problem configuration specified by the user.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRCScomparison(rankdata, target, alpha = 0.05, pvalues = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRCScomparison_+3A_rankdata">rankdata</code></td>
<td>
<p>The ranks data frame obtained by a previous call to <code><a href="#topic+SRCSranks">SRCSranks</a></code>.</p>
</td></tr>
<tr><td><code id="SRCScomparison_+3A_target">target</code></td>
<td>
<p>Name of the target column in <code>rframe</code> that separates the levels to be compared, probably &quot;Algorithm&quot; or similar.</p>
</td></tr>
<tr><td><code id="SRCScomparison_+3A_alpha">alpha</code></td>
<td>
<p>Significance threshold to consider two set of measurements coming from two algorithms as statistically significant</p>
</td></tr>
<tr><td><code id="SRCScomparison_+3A_pvalues">pvalues</code></td>
<td>
<p>Boolean. TRUE indicates that the pairwise comparison table should contain p-values.
FALSE means only &quot;&gt;&quot;,&quot;&lt;&quot; or &quot;=&quot; (the latter for non-significant difference) will be displayed in the table. Defaults to FALSE.</p>
</td></tr>
<tr><td><code id="SRCScomparison_+3A_...">...</code></td>
<td>
<p>The rest of the columns in <code>rframe</code> and the values to fully specify a single problem configuration for which algorithms will be compared.
Must be indicated as named arguments, like in &quot;severity&quot; = 4.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A square matrix of the same dimension as algorithms found in the data. An entry i,j contains either the p-value of the Wilcoxon test between
algorithms i and j (if <code>pvalues</code> was set to TRUE), or the qualitative result (&quot;&gt;&quot;, &quot;&lt;&quot; or &quot;=&quot;) of the statistical comparison (if <code>pvalues</code> was set to FALSE).
</p>


<h3>See Also</h3>

<p><code><a href="#topic+SRCSranks">SRCSranks</a>, <a href="#topic+plot.SRCS">plot.SRCS</a></code> for a full working example of SRCScomparison.
</p>

<hr>
<h2 id='SRCSranks'>Computes the ranks of all the algorithms from their (repeated) results measurements after
grouping them by several factors combined simultaneosly.</h2><span id='topic+SRCSranks'></span>

<h3>Description</h3>

<p>Computes the ranks of all the algorithms from their (repeated) results measurements after
grouping them by several factors combined simultaneosly.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>SRCSranks(data, params, target, performance, pairing.col = NULL,
  test = c("wilcoxon", "t", "tukeyHSD", "custom"), fun = NULL,
  correction = p.adjust.methods, alpha = 0.05, maximize = TRUE,
  ncores = 1, paired = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="SRCSranks_+3A_data">data</code></td>
<td>
<p>A dataframe object containing (at least) two columns for the target factor and the performance measure
Additional columns are aimed at grouping the problem configuration by (at most) 3 different factors.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_params">params</code></td>
<td>
<p>A vector with the column names in <code>data</code> that define a problem configuration. If not already factor objects, those columns will be converted to
factors inside the function (note this does not alter the ordering of the levels in case it was explicitly set before the call).
Although an arbitrary number of columns can be passed, if the user intends to plot the ranks computed by this function, at most three columns should be passed.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_target">target</code></td>
<td>
<p>Name of the target column of <code>data</code>. For each combination of the values of <code>params</code>, the ranks are obtained by
comparing the repeated measurements of <code>performance</code> associated to each level of the <code>target</code> column.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_performance">performance</code></td>
<td>
<p>Name of the column of <code>data</code> containing the repeated performance measurements. If given a vector of strings,
then a separate ranking will be computed for each of the elements, and no p-values, mean or stdev columns will be returned, just the rankings together with the factors
to indicate which problem configuration corresponds to the rank.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_pairing.col">pairing.col</code></td>
<td>
<p>Name of the column which links together the paired samples, in case we have set <code>paired = TRUE</code>. Otherwise, this argument will be ignored.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_test">test</code></td>
<td>
<p>The statistical test to be performed to compare the performance of every level of the target variable at each problem configuration.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_fun">fun</code></td>
<td>
<p>Function performing a custom statistical test, if <code>test = "custom"</code>; otherwise, this argument is ignored. The function must receive exactly
two vectors (the first is a vector of real numbers and the second is a factor with the level to which each real number corresponds)
and must return a <code>pairwise.htest</code> object with a <code>p.value</code> field. This must be an (N-1)x(N-1) lower-triangular matrix, with exactly the same structure
as those returned in the <code>p.value</code> field by a call to <code><a href="stats.html#topic+pairwise.wilcox.test">pairwise.wilcox.test</a></code> or <code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code>.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_correction">correction</code></td>
<td>
<p>The p-value adjust method. Must be one of &quot;holm&quot;, &quot;hochberg&quot;, &quot;hommel&quot;, &quot;bonferroni&quot;, &quot;BH&quot;, &quot;BY&quot;, &quot;fdr&quot;, &quot;none&quot; (defaults to &quot;holm&quot;).
This parameter will be ignored if <code>test = "tukeyHSD"</code> as Tukey HSD incorporates its own correction procedure.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_alpha">alpha</code></td>
<td>
<p>Significance threshold for pairwise comparisons. Defaults to 0.05.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_maximize">maximize</code></td>
<td>
<p>Boolean indicating whether the higher the performance measure, the better (default), or vice-versa.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_ncores">ncores</code></td>
<td>
<p>Number of physical CPUs available for computations. If <code>ncores</code> &gt; 1, parallelization is achieved through the <code><a href="parallel.html#topic+parallel">parallel</a></code> package and
is applied to the computation of ranks for more than one problem configuration at the same time. Defaults to 1 (sequential).</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_paired">paired</code></td>
<td>
<p>Boolean indicating whether samples in the same problem configuration, which only differ in the target value, and in the same relative position (row) within their
respective target values are paired or not. Defaults to FALSE. This should be set to TRUE, for instance, in Machine Learning problems in which, for a fixed problem configuration,
the target variable (usually the algorithms being compared) is associated to a number of samples (results) coming from the Cross Validation process. If a K-fold CV is being done,
then we would have, for a given problem configuration, K rows for each of the algorithms being compared, all of them identical in all the columns except for the performance column.
In that case, the performance of the i-th row (1 &lt;= i &lt;= K) of all of those batches (groups of K rows) for that fixed problem configuration would be related,
hence every pairwise comparison should take into account paired samples.</p>
</td></tr>
<tr><td><code id="SRCSranks_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to the function <code>fun</code> that is called for every pairwise comparison.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>If <code>length(performance)</code> equals 1, an object of classes <code>c("SRCS", "data.frame")</code> with the following columns:
- A set of columns with the same names as the <code>params</code> and <code>target</code> arguments.
- Two columns called &quot;mean&quot; and &quot;sd&quot; containing the mean of the repeated peformance measurements for each problem configuration and the standard deviation.
- One column named &quot;rank&quot; with the actual rank of each level of the <code>target</code> variable within that problem configuration. The lower the rank, the better the algorithm.
- |target| additional columns containing the p-values resulting of the comparison between the algorithm and the rest for the same problem configuration,
where |target| is the number of levels of the target variable.
</p>
<p>If <code>length(performance)</code> &gt; 1 (let <code>P = length(performance)</code> for the explanation that follows), an object of classes <code>c("SRCS","data.frame")</code>
with the following columns:
- A set of columns with the same names as the <code>params</code> and <code>target</code> arguments.
- One column per element of the <code>performance</code> vector, named &quot;rank1&quot;, ..., &quot;rankP&quot;, containing, for each performance measure,
the rank of each level of the <code>target</code> variable within that problem configuration for that performance measure.
The higher the rank, the better the algorithm.
</p>


<h3>Note</h3>

<p>Although it has no effect on the results of <code>SRCSranks</code>, the user should preferably have set the order
of the factor levels explicitly by calling function <code>levels</code> before calling this function, specially if he intends to subsequently apply <code><a href="base.html#topic+plot">plot</a></code> to the results,
because the level order does affect the way graphics are arranged in the plot.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+plot.SRCS">plot.SRCS</a></code> for a full working example of <code>SRCSranks</code> and plotting facilities. Also
<code><a href="stats.html#topic+pairwise.wilcox.test">pairwise.wilcox.test</a></code>, <code><a href="stats.html#topic+t.test">t.test</a></code>, <code><a href="stats.html#topic+pairwise.t.test">pairwise.t.test</a></code>, <code><a href="stats.html#topic+TukeyHSD">TukeyHSD</a></code>, <code><a href="stats.html#topic+p.adjust.methods">p.adjust.methods</a></code>
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
