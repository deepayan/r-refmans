<!DOCTYPE html><html><head><title>Help for package varclust</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {varclust}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#calculate.pcas'><p>Calculates principal components for every cluster</p></a></li>
<li><a href='#choose.cluster.BIC'><p>Choses a subspace for a variable</p></a></li>
<li><a href='#cluster.pca.BIC'><p>mBIC for subspace clustering</p></a></li>
<li><a href='#data.simulation'><p>Simulates subspace clustering data</p></a></li>
<li><a href='#data.simulation.factors'><p>Simulates subspace clustering data with shared factors</p></a></li>
<li><a href='#integration'><p>Computes integration and acontamination of the clustering</p></a></li>
<li><a href='#misclassification'><p>Computes misclassification rate</p></a></li>
<li><a href='#mlcc.bic'><p>Multiple Latent Components Clustering - Subspace clustering with automatic</p>
estimation of number of clusters and their dimension</a></li>
<li><a href='#mlcc.kmeans'><p>Multiple Latent Components Clustering - kmeans algorithm</p></a></li>
<li><a href='#mlcc.reps'><p>Multiple Latent Components Clustering - Subspace clustering assuming that the</p>
number of clusters is known</a></li>
<li><a href='#plot.mlcc.fit'><p>Plot mlcc.fit class object</p></a></li>
<li><a href='#print.mlcc.fit'><p>Print mlcc.fit class object</p></a></li>
<li><a href='#print.mlcc.reps.fit'><p>Print mlcc.reps.fit class object</p></a></li>
<li><a href='#show.clusters'><p>Print clusters obtained from MLCC</p></a></li>
<li><a href='#varclust'><p>Variable Clustering with Multiple Latent Components Clustering algorithm</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variables Clustering</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.4</td>
</tr>
<tr>
<td>Date:</td>
<td>2019-06-08</td>
</tr>
<tr>
<td>Author:</td>
<td>Piotr Sobczyk, Stanislaw Wilczynski, Julie Josse, Malgorzata Bogdan</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Piotr Sobczyk &lt;pj.sobczyk@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Performs clustering of quantitative variables,
    assuming that clusters lie in low-dimensional subspaces. Segmentation of
    variables, number of clusters and their dimensions are selected based on
    BIC. Candidate models are identified based on many runs of K-means
    algorithm with different random initializations of cluster centers.</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.2.1)</td>
</tr>
<tr>
<td>Imports:</td>
<td>RcppEigen, foreach, parallel, doParallel, doRNG, pesel</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, mclust, rmarkdown, testthat</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>6.1.1</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2019-06-26 05:36:40 UTC; piotr</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2019-06-26 10:10:37 UTC</td>
</tr>
</table>
<hr>
<h2 id='calculate.pcas'>Calculates principal components for every cluster</h2><span id='topic+calculate.pcas'></span>

<h3>Description</h3>

<p>For given segmentation this function estimates dimensionality of each cluster (or chooses fixed dimensionality)
and for each cluster calculates the number of principal components equal to the this dimensionality
</p>


<h3>Usage</h3>

<pre><code class='language-R'>calculate.pcas(X, segmentation, number.clusters, max.subspace.dim,
  estimate.dimensions)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="calculate.pcas_+3A_x">X</code></td>
<td>
<p>A data matrix.</p>
</td></tr>
<tr><td><code id="calculate.pcas_+3A_segmentation">segmentation</code></td>
<td>
<p>A vector, segmentation of variables into clusters.</p>
</td></tr>
<tr><td><code id="calculate.pcas_+3A_number.clusters">number.clusters</code></td>
<td>
<p>An integer, number of subspaces (clusters).</p>
</td></tr>
<tr><td><code id="calculate.pcas_+3A_max.subspace.dim">max.subspace.dim</code></td>
<td>
<p>An integer, upper bound for allowed dimension of subspace.</p>
</td></tr>
<tr><td><code id="calculate.pcas_+3A_estimate.dimensions">estimate.dimensions</code></td>
<td>
<p>A boolean, if TRUE subspaces dimensions are estimated using PESEL.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A subset of principal components for every cluster.
</p>

<hr>
<h2 id='choose.cluster.BIC'>Choses a subspace for a variable</h2><span id='topic+choose.cluster.BIC'></span>

<h3>Description</h3>

<p>Selects a subspace closest to a given variable. To select the subspace, the method 
considers (for every subspace) a subset of its principal components and tries 
to fit a linear model with the variable as the response. Then the method chooses 
the subspace for which the value of BIC was the highest.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>choose.cluster.BIC(variable, pcas, number.clusters,
  show.warnings = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="choose.cluster.BIC_+3A_variable">variable</code></td>
<td>
<p>A variable to be assigned.</p>
</td></tr>
<tr><td><code id="choose.cluster.BIC_+3A_pcas">pcas</code></td>
<td>
<p>Orthogonal basis for each of the subspaces.</p>
</td></tr>
<tr><td><code id="choose.cluster.BIC_+3A_number.clusters">number.clusters</code></td>
<td>
<p>Number of subspaces (clusters).</p>
</td></tr>
<tr><td><code id="choose.cluster.BIC_+3A_show.warnings">show.warnings</code></td>
<td>
<p>A boolean - if set to TRUE all warnings are displayed, default value is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>index Number of most similar subspace to variable.
</p>

<hr>
<h2 id='cluster.pca.BIC'>mBIC for subspace clustering</h2><span id='topic+cluster.pca.BIC'></span>

<h3>Description</h3>

<p>Computes the value of modified Bayesian Information Criterion (mBIC) for 
given data set partition and clusters' dimensionalities. In each cluster we 
assume that variables are spanned by few factors. Considering maximum 
likelihood we get that those factors are in fact principal components. 
Additionally, it uses by default an informative prior distribution on models.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cluster.pca.BIC(X, segmentation, dims, numb.clusters, max.dim,
  flat.prior = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="cluster.pca.BIC_+3A_x">X</code></td>
<td>
<p>A matrix with only quantitative variables.</p>
</td></tr>
<tr><td><code id="cluster.pca.BIC_+3A_segmentation">segmentation</code></td>
<td>
<p>A vector, segmentation for which likelihood is computed. 
Clusters numbers should be from range [1, numb.clusters].</p>
</td></tr>
<tr><td><code id="cluster.pca.BIC_+3A_dims">dims</code></td>
<td>
<p>A vector of integers, dimensions of subspaces. Number of 
principal components (fixed or chosen by PESEL criterion) that span each 
subspace.</p>
</td></tr>
<tr><td><code id="cluster.pca.BIC_+3A_numb.clusters">numb.clusters</code></td>
<td>
<p>An integer, number of clusters.</p>
</td></tr>
<tr><td><code id="cluster.pca.BIC_+3A_max.dim">max.dim</code></td>
<td>
<p>An integer, upper bound for allowed dimension of a subspace.</p>
</td></tr>
<tr><td><code id="cluster.pca.BIC_+3A_flat.prior">flat.prior</code></td>
<td>
<p>A boolean, if TRUE (default is FALSE) then flat prior on 
models is used.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Value of mBIC
</p>

<hr>
<h2 id='data.simulation'>Simulates subspace clustering data</h2><span id='topic+data.simulation'></span>

<h3>Description</h3>

<p>Generates data for simulation with a low-rank subspace structure: variables 
are clustered and each cluster has a low-rank representation. Factors than 
span subspaces are not shared between clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.simulation(n = 100, SNR = 1, K = 10, numb.vars = 30,
  max.dim = 2, min.dim = 1, equal.dims = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.simulation_+3A_n">n</code></td>
<td>
<p>An integer, number of individuals.</p>
</td></tr>
<tr><td><code id="data.simulation_+3A_snr">SNR</code></td>
<td>
<p>A numeric, signal to noise ratio measured as variance of the 
variable, element of a subspace, to the variance of noise.</p>
</td></tr>
<tr><td><code id="data.simulation_+3A_k">K</code></td>
<td>
<p>An integer, number of subspaces.</p>
</td></tr>
<tr><td><code id="data.simulation_+3A_numb.vars">numb.vars</code></td>
<td>
<p>An integer, number of variables in each subspace.</p>
</td></tr>
<tr><td><code id="data.simulation_+3A_max.dim">max.dim</code></td>
<td>
<p>An integer, if equal.dims is TRUE then max.dim is dimension of
each subspace. If equal.dims is FALSE then subspaces dimensions are drawn 
from uniform distribution on [min.dim,max.dim].</p>
</td></tr>
<tr><td><code id="data.simulation_+3A_min.dim">min.dim</code></td>
<td>
<p>An integer, minimal dimension of subspace .</p>
</td></tr>
<tr><td><code id="data.simulation_+3A_equal.dims">equal.dims</code></td>
<td>
<p>A boolean, if TRUE (value set by default) all clusters are 
of the same dimension.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list consisting of: </p>
<table>
<tr><td><code>X</code></td>
<td>
<p>matrix, generated data</p>
</td></tr> 
<tr><td><code>signals</code></td>
<td>
<p>matrix, data without noise</p>
</td></tr> <tr><td><code>dims</code></td>
<td>
<p>vector, dimensions 
of subspaces</p>
</td></tr> <tr><td><code>factors</code></td>
<td>
<p>matrix, columns of which span subspaces</p>
</td></tr> 
<tr><td><code>s</code></td>
<td>
<p>vector, true partiton of variables</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- data.simulation()
sim.data2 &lt;- data.simulation(n = 30, SNR = 2, K = 5, numb.vars = 20, 
                             max.dim = 3, equal.dims = FALSE)
</code></pre>

<hr>
<h2 id='data.simulation.factors'>Simulates subspace clustering data with shared factors</h2><span id='topic+data.simulation.factors'></span>

<h3>Description</h3>

<p>Generating data for simulation with a low-rank subspace structure: variables
are clustered and each cluster has a low-rank representation. Factors that
span subspaces are shared between clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data.simulation.factors(n = 100, SNR = 1, K = 10, numb.vars = 30,
  numb.factors = 10, min.dim = 1, max.dim = 2, equal.dims = TRUE,
  separation.parameter = 0.1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="data.simulation.factors_+3A_n">n</code></td>
<td>
<p>An integer, number of individuals.</p>
</td></tr>
<tr><td><code id="data.simulation.factors_+3A_snr">SNR</code></td>
<td>
<p>A numeric, signal to noise ratio measured as variance of the 
variable, element of a subspace, to the variance of noise.</p>
</td></tr>
<tr><td><code id="data.simulation.factors_+3A_k">K</code></td>
<td>
<p>An integer, number of subspaces.</p>
</td></tr>
<tr><td><code id="data.simulation.factors_+3A_numb.vars">numb.vars</code></td>
<td>
<p>An integer, number of variables in each subspace.</p>
</td></tr>
<tr><td><code id="data.simulation.factors_+3A_numb.factors">numb.factors</code></td>
<td>
<p>An integer, number of factors from which subspaces basis
will be drawn.</p>
</td></tr>
<tr><td><code id="data.simulation.factors_+3A_min.dim">min.dim</code></td>
<td>
<p>An integer, minimal dimension of subspace .</p>
</td></tr>
<tr><td><code id="data.simulation.factors_+3A_max.dim">max.dim</code></td>
<td>
<p>An integer, if equal.dims is TRUE then max.dim is dimension of
each subspace. If equal.dims is FALSE then subspaces dimensions are drawn 
from uniform distribution on [min.dim,max.dim].</p>
</td></tr>
<tr><td><code id="data.simulation.factors_+3A_equal.dims">equal.dims</code></td>
<td>
<p>A boolean, if TRUE (value set by default) all clusters are 
of the same dimension.</p>
</td></tr>
<tr><td><code id="data.simulation.factors_+3A_separation.parameter">separation.parameter</code></td>
<td>
<p>a numeric, coefficients of variables in each 
subspace basis are drawn from range [separation.parameter,1]</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list consisting of: </p>
<table>
<tr><td><code>X</code></td>
<td>
<p>matrix, generated data</p>
</td></tr> 
<tr><td><code>signals</code></td>
<td>
<p>matrix, data without noise</p>
</td></tr> <tr><td><code>factors</code></td>
<td>
<p>matrix, columns
of which span subspaces</p>
</td></tr> <tr><td><code>indices</code></td>
<td>
<p>list of vectors, indices of factors
that span subspaces</p>
</td></tr> <tr><td><code>dims</code></td>
<td>
<p>vector, dimensions of subspaces</p>
</td></tr> 
<tr><td><code>s</code></td>
<td>
<p>vector, true partiton of variables</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>sim.data &lt;- data.simulation.factors()
sim.data2 &lt;- data.simulation.factors(n = 30, SNR = 2, K = 5, numb.vars = 20,
             numb.factors = 10, max.dim = 3, equal.dims = FALSE, separation.parameter = 0.2)
</code></pre>

<hr>
<h2 id='integration'>Computes integration and acontamination of the clustering</h2><span id='topic+integration'></span>

<h3>Description</h3>

<p>Integartion and acontamination are measures of the quality of a clustering 
with a reference to a true partition. Let <code class="reqn">X = (x_1, \ldots x_p)</code> be the 
data set, <code class="reqn">A</code> be a partition into clusters <code class="reqn">A_1, \ldots A_n</code> (true 
partition) and <code class="reqn">B</code> be a partition into clusters <code class="reqn">B_1, \ldots, B_m</code>. 
Then for cluster <code class="reqn">A_j</code> integration is eqaul to: </p>
<p style="text-align: center;"><code class="reqn">Int(A_j) = 
\frac{max_{k = 1, \ldots, m} \# \{  i \in \{ 1, \ldots p \}: x_i \in A_j 
\wedge x_i \in B_k \}  }{\# A_j}</code>
</p>
<p> The <code class="reqn">B_k</code> for which the value is 
maximized is called the integrating cluster of <code class="reqn">A_j</code>. Then the 
integration for the whole clustering equals is <code class="reqn">Int(A,B) = \frac{1}{n} 
\sum_{j=1}^n Int(A_j)</code> .The acontamination is defined by: </p>
<p style="text-align: center;"><code class="reqn">Acont(A_j) = 
\frac{ \# \{  i \in \{ 1, \ldots p \}: x_i \in A_j \wedge x_i \in B_k \} }{\#
B_k}</code>
</p>
<p> where <code class="reqn">B_k</code> is the integrating cluster for <code class="reqn">A_j</code>. Then the 
acontamination for the whole dataset is <code class="reqn">Acont(A,B) = \frac{1}{n} 
\sum_{j=1}^n Acont(A_j)</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>integration(group, true_group)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="integration_+3A_group">group</code></td>
<td>
<p>A vector, first partition.</p>
</td></tr>
<tr><td><code id="integration_+3A_true_group">true_group</code></td>
<td>
<p>A vector, second (reference) partition.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An array containing values of integration and acontamination.
</p>


<h3>References</h3>

<p>M. Sołtys. Metody analizy skupień. Master’s thesis, Wrocław 
University of Technology, 2010
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sim.data &lt;- data.simulation(n = 20, SNR = 1, K = 2, numb.vars = 50, max.dim = 2)
true_segmentation &lt;- rep(1:2, each=50)
mlcc.fit &lt;- mlcc.reps(sim.data$X, numb.clusters = 2, max.dim = 2, numb.cores=1)
integration(mlcc.fit$segmentation, true_segmentation)

</code></pre>

<hr>
<h2 id='misclassification'>Computes misclassification rate</h2><span id='topic+misclassification'></span>

<h3>Description</h3>

<p>Missclasification is a commonly used performance measure in subspace
clustering. It allows to compare two partitions with the same number of
clusters.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>misclassification(group, true_group, M, K)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="misclassification_+3A_group">group</code></td>
<td>
<p>A vector, first partition.</p>
</td></tr>
<tr><td><code id="misclassification_+3A_true_group">true_group</code></td>
<td>
<p>A vector, second (reference) partition.</p>
</td></tr>
<tr><td><code id="misclassification_+3A_m">M</code></td>
<td>
<p>An integer, maximal number of elements in one class.</p>
</td></tr>
<tr><td><code id="misclassification_+3A_k">K</code></td>
<td>
<p>An integer, number of classes.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>As getting exact value of misclassification requires checking all
permutations and is therefore intrackable even for modest number of clusters,
a heuristic approach is proposed. It is assumed that there are K classes of
maximum M elements. Additional requirement is that classes labels are from
range [1, K].
</p>


<h3>Value</h3>

<p>Misclassification rate.
</p>


<h3>References</h3>

<p>R. Vidal. Subspace clustering. Signal Processing Magazine, IEEE,
28(2):52-68,2011
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sim.data &lt;- data.simulation(n = 100, SNR = 1, K = 5, numb.vars = 30, max.dim = 2)
mlcc.fit &lt;- mlcc.reps(sim.data$X, numb.clusters = 5, numb.runs = 20, max.dim = 2, numb.cores=1)
misclassification(mlcc.fit$segmentation,sim.data$s, 30, 5)


#one can use this function not only for clusters
partition1 &lt;- sample(10, 300, replace = TRUE)
partition2 &lt;- sample(10, 300, replace = TRUE)
misclassification(partition1, partition1, max(table(partition1)), 10)
misclassification(partition1, partition2, max(table(partition2)), 10)
</code></pre>

<hr>
<h2 id='mlcc.bic'>Multiple Latent Components Clustering - Subspace clustering with automatic 
estimation of number of clusters and their dimension</h2><span id='topic+mlcc.bic'></span>

<h3>Description</h3>

<p>This function is an implementation of Multiple Latent Components Clustering 
(MLCC) algorithm which clusteres quantitative variables into a number, chosen
using mBIC, of groups. For each considered number of clusters in 
<em>numb.clusters</em> <code><a href="#topic+mlcc.reps">mlcc.reps</a></code> function is called. It invokes 
K-means based algorithm (<code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code>) finding local minimum of 
mBIC, which is run a given number of times (<em>numb.runs</em>) with different 
initializations. The best partition is choosen with mBIC (see 
<code><a href="#topic+mlcc.reps">mlcc.reps</a></code> function).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlcc.bic(X, numb.clusters = 1:10, numb.runs = 30, stop.criterion = 1,
  max.iter = 30, max.dim = 4, scale = TRUE, numb.cores = NULL,
  greedy = TRUE, estimate.dimensions = TRUE, verbose = FALSE,
  flat.prior = FALSE, show.warnings = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlcc.bic_+3A_x">X</code></td>
<td>
<p>A data frame or a matrix with only continuous variables.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_numb.clusters">numb.clusters</code></td>
<td>
<p>A vector, numbers of clusters to be checked.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_numb.runs">numb.runs</code></td>
<td>
<p>An integer, number of runs (initializations) of 
<code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code>.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_stop.criterion">stop.criterion</code></td>
<td>
<p>An integer, if an iteration of 
<code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code> algorithm makes less changes in partitions than 
<code>stop.criterion</code>, <code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code> stops.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_max.iter">max.iter</code></td>
<td>
<p>An integer, maximum number of iterations of the loop in 
<code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code> algorithm.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_max.dim">max.dim</code></td>
<td>
<p>An integer, if estimate.dimensions is FALSE then max.dim is 
dimension of each subspace. If estimate.dimensions is TRUE then subspaces 
dimensions are estimated from the range [1, max.dim].</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_scale">scale</code></td>
<td>
<p>A boolean, if TRUE (value set by default) then variables in 
dataset are scaled to zero mean and unit variance.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_numb.cores">numb.cores</code></td>
<td>
<p>An integer, number of cores to be used, by default all 
cores are used.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_greedy">greedy</code></td>
<td>
<p>A boolean, if TRUE (value set by default) the clusters are 
estimated in a greedy way - first local minimum of mBIC is chosen.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_estimate.dimensions">estimate.dimensions</code></td>
<td>
<p>A boolean, if TRUE (value set by default) 
subspaces dimensions are estimated.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_verbose">verbose</code></td>
<td>
<p>A boolean, if TRUE plot with mBIC values for different numbers
of clusters is produced and values of mBIC, computed for every number of 
clusters and subspaces dimensions, are printed (value set by default is 
FALSE).</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_flat.prior">flat.prior</code></td>
<td>
<p>A boolean, if TRUE then, instead of an informative prior 
that takes into account number of models for a given number of clusters, 
flat prior is used.</p>
</td></tr>
<tr><td><code id="mlcc.bic_+3A_show.warnings">show.warnings</code></td>
<td>
<p>A boolean, if set to TRUE all warnings are displayed, 
default value is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class mlcc.fit consisting of </p>
<table>
<tr><td><code>segmentation</code></td>
<td>
<p>a 
vector containing the partition of the variables</p>
</td></tr> <tr><td><code>BIC</code></td>
<td>
<p>numeric, value
of mBIC</p>
</td></tr> <tr><td><code>subspacesDimensions</code></td>
<td>
<p>a list containing dimensions of the 
subspaces</p>
</td></tr> <tr><td><code>nClusters</code></td>
<td>
<p>an integer, estimated number of clusters</p>
</td></tr> 
<tr><td><code>factors</code></td>
<td>
<p>a list of matrices, basis for each subspace</p>
</td></tr> 
<tr><td><code>all.fit</code></td>
<td>
<p>a list of segmentation, mBIC, subspaces dimension for all 
numbers of clusters considered for an estimated subspace dimensions</p>
</td></tr> 
<tr><td><code>all.fit.dims</code></td>
<td>
<p>a list of lists of segmentation, mBIC, subspaces 
dimension for all numbers of clusters and subspaces dimensions considered</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
sim.data &lt;- data.simulation(n = 50, SNR = 1, K = 3, numb.vars = 50, max.dim = 3)
mlcc.res &lt;- mlcc.bic(sim.data$X, numb.clusters = 1:5, numb.runs = 20, numb.cores = 1, verbose=TRUE)
show.clusters(sim.data$X, mlcc.res$segmentation)

</code></pre>

<hr>
<h2 id='mlcc.kmeans'>Multiple Latent Components Clustering - kmeans algorithm</h2><span id='topic+mlcc.kmeans'></span>

<h3>Description</h3>

<p>Performs k-means based subspace clustering. Center of each cluster is some 
number of principal components. This number can be fixed or estimated by 
PESEL. Similarity measure between variable and a cluster is calculated using 
BIC.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlcc.kmeans(X, number.clusters = 2, stop.criterion = 1,
  max.iter = 30, max.subspace.dim = 4, initial.segmentation = NULL,
  estimate.dimensions = TRUE, show.warnings = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlcc.kmeans_+3A_x">X</code></td>
<td>
<p>A matrix with only continuous variables.</p>
</td></tr>
<tr><td><code id="mlcc.kmeans_+3A_number.clusters">number.clusters</code></td>
<td>
<p>An integer, number of clusters to be used.</p>
</td></tr>
<tr><td><code id="mlcc.kmeans_+3A_stop.criterion">stop.criterion</code></td>
<td>
<p>An integer indicating how many changes in partitions 
triggers stopping the algorithm.</p>
</td></tr>
<tr><td><code id="mlcc.kmeans_+3A_max.iter">max.iter</code></td>
<td>
<p>An integer, maximum number of iterations of k-means loop.</p>
</td></tr>
<tr><td><code id="mlcc.kmeans_+3A_max.subspace.dim">max.subspace.dim</code></td>
<td>
<p>An integer, maximum dimension of subspaces.</p>
</td></tr>
<tr><td><code id="mlcc.kmeans_+3A_initial.segmentation">initial.segmentation</code></td>
<td>
<p>A vector, initial segmentation of variables to 
clusters.</p>
</td></tr>
<tr><td><code id="mlcc.kmeans_+3A_estimate.dimensions">estimate.dimensions</code></td>
<td>
<p>A boolean, if TRUE (value set by default) 
subspaces dimensions are estimated.</p>
</td></tr>
<tr><td><code id="mlcc.kmeans_+3A_show.warnings">show.warnings</code></td>
<td>
<p>A boolean, if set to TRUE all warnings are displayed, 
default value is FALSE.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list consisting of: </p>
<table>
<tr><td><code>segmentation</code></td>
<td>
<p>a vector containing the 
partition of the variables</p>
</td></tr> <tr><td><code>pcas</code></td>
<td>
<p>a list of matrices, basis vectors 
for each cluster (subspace)</p>
</td></tr>
</table>


<h3>References</h3>

<p><em>Bayesian dimensionality reduction with PCA using penalized semi-integrated likelihood</em>,
Piotr Sobczyk, Malgorzata Bogdan, Julie Josse
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sim.data &lt;- data.simulation(n = 50, SNR = 1, K = 5, numb.vars = 50, max.dim = 3)
mlcc.res &lt;- mlcc.kmeans(sim.data$X, number.clusters = 5, max.iter = 20, max.subspace.dim = 3)
show.clusters(sim.data$X, mlcc.res$segmentation)

</code></pre>

<hr>
<h2 id='mlcc.reps'>Multiple Latent Components Clustering - Subspace clustering assuming that the
number of clusters is known</h2><span id='topic+mlcc.reps'></span>

<h3>Description</h3>

<p>For a fixed number of cluster function returns the best partition and basis 
for each subspace.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mlcc.reps(X, numb.clusters = 2, numb.runs = 30, stop.criterion = 1,
  max.iter = 30, initial.segmentations = NULL, max.dim = 4,
  scale = TRUE, numb.cores = NULL, estimate.dimensions = TRUE,
  flat.prior = FALSE, show.warnings = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mlcc.reps_+3A_x">X</code></td>
<td>
<p>A data frame or a matrix with only continuous variables.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_numb.clusters">numb.clusters</code></td>
<td>
<p>An integer, number of cluster.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_numb.runs">numb.runs</code></td>
<td>
<p>An integer, number of runs of <code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a> 
algorithm</code> with random initialization.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_stop.criterion">stop.criterion</code></td>
<td>
<p>An integer, if an iteration of 
<code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code> algorithm makes less changes in partitions than 
<code>stop.criterion</code>, <code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code> stops.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_max.iter">max.iter</code></td>
<td>
<p>max.iter An integer, maximum number of iterations of the loop
in <code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code> algorithm.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_initial.segmentations">initial.segmentations</code></td>
<td>
<p>A list of vectors, segmentations that user wants
to be used as an initial segmentation in <code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code> 
algorithm.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_max.dim">max.dim</code></td>
<td>
<p>An integer, maximal dimension of subspaces.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_scale">scale</code></td>
<td>
<p>A boolean, if TRUE (value set by default) then variables in 
dataset are scaled to zero mean and unit variance.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_numb.cores">numb.cores</code></td>
<td>
<p>An integer, number of cores to be used, by default all 
cores are used.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_estimate.dimensions">estimate.dimensions</code></td>
<td>
<p>A boolean, if TRUE (value set by default) 
subspaces dimensions are estimated.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_flat.prior">flat.prior</code></td>
<td>
<p>A boolean, if TRUE then, instead of a prior that takes into
account number of models for a given number of clusters, flat prior is 
used.</p>
</td></tr>
<tr><td><code id="mlcc.reps_+3A_show.warnings">show.warnings</code></td>
<td>
<p>A boolean, if set to TRUE all warnings are displayed, 
default value is FALSE.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>In more detail, an algorithm <code><a href="#topic+mlcc.kmeans">mlcc.kmeans</a></code> is run a 
<em>numb.runs</em> of times with random or custom initializations. The best 
partition is selected according to the BIC.
</p>


<h3>Value</h3>

<p>A list consisting of </p>
<table>
<tr><td><code>segmentation</code></td>
<td>
<p>a vector containing the 
partition of the variables</p>
</td></tr> <tr><td><code>BIC</code></td>
<td>
<p>a numeric, value of the mBIC</p>
</td></tr> 
<tr><td><code>basis</code></td>
<td>
<p>a list of matrices, the factors for each of the subspaces</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
sim.data &lt;- data.simulation(n = 50, SNR = 1, K = 5, numb.vars = 50, max.dim = 3)
mlcc.res &lt;- mlcc.reps(sim.data$X, numb.clusters = 5, numb.runs = 20, max.dim = 4, numb.cores = 1)
show.clusters(sim.data$X, mlcc.res$segmentation)

</code></pre>

<hr>
<h2 id='plot.mlcc.fit'>Plot mlcc.fit class object</h2><span id='topic+plot.mlcc.fit'></span>

<h3>Description</h3>

<p>Plot mlcc.fit class object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcc.fit'
plot(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="plot.mlcc.fit_+3A_x">x</code></td>
<td>
<p>mlcc.fit class object</p>
</td></tr>
<tr><td><code id="plot.mlcc.fit_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to or from other methods. They are ignored in this function.</p>
</td></tr>
</table>

<hr>
<h2 id='print.mlcc.fit'>Print mlcc.fit class object</h2><span id='topic+print.mlcc.fit'></span>

<h3>Description</h3>

<p>Print mlcc.fit class object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcc.fit'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mlcc.fit_+3A_x">x</code></td>
<td>
<p>mlcc.fit class object</p>
</td></tr>
<tr><td><code id="print.mlcc.fit_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to or from other methods. They are ignored in this function.</p>
</td></tr>
</table>

<hr>
<h2 id='print.mlcc.reps.fit'>Print mlcc.reps.fit class object</h2><span id='topic+print.mlcc.reps.fit'></span>

<h3>Description</h3>

<p>Print mlcc.reps.fit class object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'mlcc.reps.fit'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="print.mlcc.reps.fit_+3A_x">x</code></td>
<td>
<p>mlcc.reps.fit class object</p>
</td></tr>
<tr><td><code id="print.mlcc.reps.fit_+3A_...">...</code></td>
<td>
<p>Further arguments to be passed to or from other methods. They are
ignored in this function.</p>
</td></tr>
</table>

<hr>
<h2 id='show.clusters'>Print clusters obtained from MLCC</h2><span id='topic+show.clusters'></span>

<h3>Description</h3>

<p>Print clusters obtained from MLCC
</p>


<h3>Usage</h3>

<pre><code class='language-R'>show.clusters(data, segmentation)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="show.clusters_+3A_data">data</code></td>
<td>
<p>The original data set.</p>
</td></tr>
<tr><td><code id="show.clusters_+3A_segmentation">segmentation</code></td>
<td>
<p>A vector, segmentation of variables into clusters.</p>
</td></tr>
</table>

<hr>
<h2 id='varclust'>Variable Clustering with Multiple Latent Components Clustering algorithm</h2><span id='topic+varclust'></span><span id='topic+varclust-package'></span>

<h3>Description</h3>

<p>Package varclust performs clustering of variables, according to a 
probabilistic model, which assumes that each cluster lies in a low 
dimensional subspace. Segmentation of variables, number of clusters and their
dimensions are selected based on the appropriate implementation of the 
Bayesian Information Criterion.
</p>


<h3>Details</h3>

<p>The best candidate models are identified by the specific implementation of 
K-means algorithm, in which cluster centers are represented by some number of
orthogonal factors(principal components of the variables within a cluster) 
and similarity between a given variable and a cluster center depends on 
residuals from a linear model fit. Based on the Bayesian Information 
Criterion (BIC), sums of squares of residuals are appropriately scaled, which
allows to avoid an over-excessive attraction by clusters with larger 
dimensions. To reduce the chance that the local minimum of modified BIC 
(mBIC) is obtained instead of the global one, for every fixed number of 
clusters in a given range K-means algorithm is run large number of times, 
with different random initializations of cluster centers.
</p>
<p>The main function of package <span class="pkg">varclust</span> is <code><a href="#topic+mlcc.bic">mlcc.bic</a></code> which 
allows clustering variables in a data with unknown number of clusters. 
Variable partition is computed with k-means based algorithm. Number of 
clusters and their dimensions are estimated using mBIC and PESEL 
respectively. If the number of clusters is known one might use function 
<code><a href="#topic+mlcc.reps">mlcc.reps</a></code>, which takes number of clusters as a parameter. For 
<code><a href="#topic+mlcc.reps">mlcc.reps</a></code> one might specify as well some initial segmentation 
for k-means algorithm. This can be useful if user has some a priori knowledge
about clustering.
</p>
<p>We provide also two functions to simulate datasets with described structure. 
The function <code><a href="#topic+data.simulation">data.simulation</a></code> generates the data so that the 
subspaces are indepentend and <code><a href="#topic+data.simulation.factors">data.simulation.factors</a></code> generates
the data where some factores are shared between the subspaces.
</p>
<p>We also provide function measures of quality of clustering. 
<code><a href="#topic+misclassification">misclassification</a></code> computes misclassification rate between two 
partitions. This performance measure is extensively used in image 
segmentation. The other measure is implemented as <code><a href="#topic+integration">integration</a></code> 
function.
</p>
<p>Version: 0.9.4
</p>


<h3>Author(s)</h3>

<p>Piotr Sobczyk, Stanislaw Wilczynski, Julie Josse, Malgorzata Bogdan
</p>
<p>Maintainer: Piotr Sobczyk <a href="mailto:pj.sobczyk@gmail.com">pj.sobczyk@gmail.com</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
sim.data &lt;- data.simulation(n = 50, SNR = 1, K = 3, numb.vars = 50, max.dim = 3)
mlcc.bic(sim.data$X, numb.clusters = 1:5, numb.runs = 20, numb.cores = 1, verbose = TRUE)
mlcc.reps(sim.data$X, numb.clusters = 3, numb.runs = 20, numb.cores = 1)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
