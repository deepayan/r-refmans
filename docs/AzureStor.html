<!DOCTYPE html><html lang="en"><head><title>Help for package AzureStor</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {AzureStor}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#acquire_lease'><p>Operations on blob leases</p></a></li>
<li><a href='#adls_filesystem'><p>Operations on an Azure Data Lake Storage Gen2 endpoint</p></a></li>
<li><a href='#az_storage'><p>Storage account resource class</p></a></li>
<li><a href='#blob_container'><p>Operations on a blob endpoint</p></a></li>
<li><a href='#call_azcopy'><p>Call the azcopy file transfer utility</p></a></li>
<li><a href='#copy_url_to_storage'><p>Upload and download generics</p></a></li>
<li><a href='#create_blob_snapshot'><p>Create, list and delete blob snapshots</p></a></li>
<li><a href='#create_storage_account'><p>Create Azure storage account</p></a></li>
<li><a href='#delete_storage_account'><p>Delete an Azure storage account</p></a></li>
<li><a href='#do_container_op'><p>Carry out operations on a storage account container or endpoint</p></a></li>
<li><a href='#file_share'><p>Operations on a file endpoint</p></a></li>
<li><a href='#get_account_sas'><p>Generate shared access signatures</p></a></li>
<li><a href='#get_storage_account'><p>Get existing Azure storage account(s)</p></a></li>
<li><a href='#get_storage_metadata'><p>Get/set user-defined metadata for a storage object</p></a></li>
<li><a href='#get_storage_properties'><p>Get storage properties for an object</p></a></li>
<li><a href='#list_adls_files'><p>Operations on an Azure Data Lake Storage Gen2 filesystem</p></a></li>
<li><a href='#list_azure_files'><p>Operations on a file share</p></a></li>
<li><a href='#list_blob_versions'><p>List and delete blob versions</p></a></li>
<li><a href='#list_blobs'><p>Operations on a blob container or blob</p></a></li>
<li><a href='#sign_request'><p>Signs a request to the storage REST endpoint with a shared key</p></a></li>
<li><a href='#storage_container'><p>Storage client generics</p></a></li>
<li><a href='#storage_endpoint'><p>Create a storage endpoint object</p></a></li>
<li><a href='#storage_save_rds'><p>Save and load R objects to/from a storage account</p></a></li>
<li><a href='#storage_write_delim'><p>Read and write a data frame to/from a storage account</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>Storage Management in 'Azure'</td>
</tr>
<tr>
<td>Version:</td>
<td>3.7.0</td>
</tr>
<tr>
<td>Description:</td>
<td>Manage storage in Microsoft's 'Azure' cloud: <a href="https://azure.microsoft.com/en-us/product-categories/storage/">https://azure.microsoft.com/en-us/product-categories/storage/</a>. On the admin side, 'AzureStor' includes features to create, modify and delete storage accounts. On the client side, it includes an interface to blob storage, file storage, and 'Azure Data Lake Storage Gen2': upload and download files and blobs; list containers and files/blobs; create containers; and so on. Authenticated access to storage is supported, via either a shared access key or a shared access signature (SAS). Part of the 'AzureR' family of packages.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://github.com/Azure/AzureStor">https://github.com/Azure/AzureStor</a> <a href="https://github.com/Azure/AzureR">https://github.com/Azure/AzureR</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/Azure/AzureStor/issues">https://github.com/Azure/AzureStor/issues</a></td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.3),</td>
</tr>
<tr>
<td>Imports:</td>
<td>utils, R6, httr (&ge; 1.4.0), mime, openssl, xml2, vctrs,
AzureRMR (&ge; 2.3.0)</td>
</tr>
<tr>
<td>Suggests:</td>
<td>AzureAuth, readr, knitr, rmarkdown, jsonlite, testthat,
processx, uuid</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-05-24 23:57:27 UTC; hongo</td>
</tr>
<tr>
<td>Author:</td>
<td>Hong Ooi [aut, cre],
  Microsoft [cph]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hong Ooi &lt;hongooi73@gmail.com&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-05-25 07:00:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='acquire_lease'>Operations on blob leases</h2><span id='topic+acquire_lease'></span><span id='topic+break_lease'></span><span id='topic+release_lease'></span><span id='topic+renew_lease'></span><span id='topic+change_lease'></span>

<h3>Description</h3>

<p>Manage leases for blobs and blob containers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>acquire_lease(container, blob = "", duration = 60, lease = NULL)

break_lease(container, blob = "", period = NULL)

release_lease(container, blob = "", lease)

renew_lease(container, blob = "", lease)

change_lease(container, blob = "", lease, new_lease)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="acquire_lease_+3A_container">container</code></td>
<td>
<p>A blob container object.</p>
</td></tr>
<tr><td><code id="acquire_lease_+3A_blob">blob</code></td>
<td>
<p>The name of an individual blob. If not supplied, the lease applies to the entire container.</p>
</td></tr>
<tr><td><code id="acquire_lease_+3A_duration">duration</code></td>
<td>
<p>For <code>acquire_lease</code>, The duration of the requested lease. For an indefinite duration, set this to -1.</p>
</td></tr>
<tr><td><code id="acquire_lease_+3A_lease">lease</code></td>
<td>
<p>For <code>acquire_lease</code> an optional proposed name of the lease; for <code>release_lease</code>, <code>renew_lease</code> and <code>change_lease</code>, the name of the existing lease.</p>
</td></tr>
<tr><td><code id="acquire_lease_+3A_period">period</code></td>
<td>
<p>For <code>break_lease</code>, the period for which to break the lease.</p>
</td></tr>
<tr><td><code id="acquire_lease_+3A_new_lease">new_lease</code></td>
<td>
<p>For <code>change_lease</code>, the proposed name of the lease.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Leasing is a way to prevent a blob or container from being accidentally deleted. The duration of a lease can range from 15 to 60 seconds, or be indefinite.
</p>


<h3>Value</h3>

<p>For <code>acquire_lease</code> and <code>change_lease</code>, a string containing the lease ID.
</p>


<h3>See Also</h3>

<p><a href="#topic+blob_container">blob_container</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storageservices/lease-blob">Leasing a blob</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storageservices/lease-container">Leasing a container</a>
</p>

<hr>
<h2 id='adls_filesystem'>Operations on an Azure Data Lake Storage Gen2 endpoint</h2><span id='topic+adls_filesystem'></span><span id='topic+adls_filesystem.character'></span><span id='topic+adls_filesystem.adls_endpoint'></span><span id='topic+print.adls_filesystem'></span><span id='topic+list_adls_filesystems'></span><span id='topic+list_adls_filesystems.character'></span><span id='topic+list_adls_filesystems.adls_endpoint'></span><span id='topic+create_adls_filesystem'></span><span id='topic+create_adls_filesystem.character'></span><span id='topic+create_adls_filesystem.adls_filesystem'></span><span id='topic+create_adls_filesystem.adls_endpoint'></span><span id='topic+delete_adls_filesystem'></span><span id='topic+delete_adls_filesystem.character'></span><span id='topic+delete_adls_filesystem.adls_filesystem'></span><span id='topic+delete_adls_filesystem.adls_endpoint'></span>

<h3>Description</h3>

<p>Get, list, create, or delete ADLSgen2 filesystems.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>adls_filesystem(endpoint, ...)

## S3 method for class 'character'
adls_filesystem(endpoint, key = NULL, token = NULL,
  sas = NULL, api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'adls_endpoint'
adls_filesystem(endpoint, name, ...)

## S3 method for class 'adls_filesystem'
print(x, ...)

list_adls_filesystems(endpoint, ...)

## S3 method for class 'character'
list_adls_filesystems(endpoint, key = NULL,
  token = NULL, sas = NULL,
  api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'adls_endpoint'
list_adls_filesystems(endpoint, ...)

create_adls_filesystem(endpoint, ...)

## S3 method for class 'character'
create_adls_filesystem(endpoint, key = NULL,
  token = NULL, sas = NULL,
  api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'adls_filesystem'
create_adls_filesystem(endpoint, ...)

## S3 method for class 'adls_endpoint'
create_adls_filesystem(endpoint, name, ...)

delete_adls_filesystem(endpoint, ...)

## S3 method for class 'character'
delete_adls_filesystem(endpoint, key = NULL,
  token = NULL, sas = NULL,
  api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'adls_filesystem'
delete_adls_filesystem(endpoint, ...)

## S3 method for class 'adls_endpoint'
delete_adls_filesystem(endpoint, name, confirm = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="adls_filesystem_+3A_endpoint">endpoint</code></td>
<td>
<p>Either an ADLSgen2 endpoint object as created by <a href="#topic+storage_endpoint">storage_endpoint</a> or <a href="#topic+adls_endpoint">adls_endpoint</a>, or a character string giving the URL of the endpoint.</p>
</td></tr>
<tr><td><code id="adls_filesystem_+3A_...">...</code></td>
<td>
<p>Further arguments passed to lower-level functions.</p>
</td></tr>
<tr><td><code id="adls_filesystem_+3A_key">key</code>, <code id="adls_filesystem_+3A_token">token</code>, <code id="adls_filesystem_+3A_sas">sas</code></td>
<td>
<p>If an endpoint object is not supplied, authentication credentials: either an access key, an Azure Active Directory (AAD) token, or a SAS, in that order of priority. Currently the <code>sas</code> argument is unused.</p>
</td></tr>
<tr><td><code id="adls_filesystem_+3A_api_version">api_version</code></td>
<td>
<p>If an endpoint object is not supplied, the storage API version to use when interacting with the host. Currently defaults to <code>"2019-07-07"</code>.</p>
</td></tr>
<tr><td><code id="adls_filesystem_+3A_name">name</code></td>
<td>
<p>The name of the filesystem to get, create, or delete.</p>
</td></tr>
<tr><td><code id="adls_filesystem_+3A_x">x</code></td>
<td>
<p>For the print method, a filesystem object.</p>
</td></tr>
<tr><td><code id="adls_filesystem_+3A_confirm">confirm</code></td>
<td>
<p>For deleting a filesystem, whether to ask for confirmation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You can call these functions in a couple of ways: by passing the full URL of the filesystem, or by passing the endpoint object and the name of the filesystem as a string.
</p>
<p>If authenticating via AAD, you can supply the token either as a string, or as an object of class AzureToken, created via <a href="AzureRMR.html#topic+reexports">AzureRMR::get_azure_token</a>. The latter is the recommended way of doing it, as it allows for automatic refreshing of expired tokens.
</p>


<h3>Value</h3>

<p>For <code>adls_filesystem</code> and <code>create_adls_filesystem</code>, an S3 object representing an existing or created filesystem respectively.
</p>
<p>For <code>list_adls_filesystems</code>, a list of such objects.
</p>


<h3>See Also</h3>

<p><a href="#topic+storage_endpoint">storage_endpoint</a>, <a href="#topic+az_storage">az_storage</a>, <a href="#topic+storage_container">storage_container</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- adls_endpoint("https://mystorage.dfs.core.windows.net/", key="access_key")

# list ADLSgen2 filesystems
list_adls_filesystems(endp)

# get, create, and delete a filesystem
adls_filesystem(endp, "myfs")
create_adls_filesystem(endp, "newfs")
delete_adls_filesystem(endp, "newfs")

# alternative way to do the same
adls_filesystem("https://mystorage.dfs.core.windows.net/myfs", key="access_key")
create_adls_filesystem("https://mystorage.dfs.core.windows.net/newfs", key="access_key")
delete_adls_filesystem("https://mystorage.dfs.core.windows.net/newfs", key="access_key")


## End(Not run)
</code></pre>

<hr>
<h2 id='az_storage'>Storage account resource class</h2><span id='topic+az_storage'></span>

<h3>Description</h3>

<p>Class representing a storage account, exposing methods for working with it.
</p>


<h3>Methods</h3>

<p>The following methods are available, in addition to those provided by the <a href="AzureRMR.html#topic+az_resource">AzureRMR::az_resource</a> class:
</p>

<ul>
<li> <p><code>new(...)</code>: Initialize a new storage object. See 'Initialization'.
</p>
</li>
<li> <p><code>list_keys()</code>: Return the access keys for this account.
</p>
</li>
<li> <p><code>get_account_sas(...)</code>: Return an account shared access signature (SAS). See 'Creating a shared access signature' below.
</p>
</li>
<li> <p><code>get_user_delegation_key(...)</code>: Returns a key that can be used to construct a user delegation SAS.
</p>
</li>
<li> <p><code>get_user_delegation_sas(...)</code>: Return a user delegation SAS.
</p>
</li>
<li> <p><code>revoke_user_delegation_keys()</code>: Revokes all user delegation keys for the account. This also renders all SAS's obtained via such keys invalid.
</p>
</li>
<li> <p><code>get_blob_endpoint(key, sas)</code>: Return the account's blob storage endpoint, along with an access key and/or a SAS. See 'Endpoints' for more details
</p>
</li>
<li> <p><code>get_file_endpoint(key, sas)</code>: Return the account's file storage endpoint.
</p>
</li>
<li> <p><code>regen_key(key)</code>: Regenerates (creates a new value for) an access key. The argument <code>key</code> can be 1 or 2.
</p>
</li></ul>



<h3>Initialization</h3>

<p>Initializing a new object of this class can either retrieve an existing storage account, or create a account on the host. Generally, the best way to initialize an object is via the <code>get_storage_account</code>, <code>create_storage_account</code> or <code>list_storage_accounts</code> methods of the <a href="AzureRMR.html#topic+az_resource_group">az_resource_group</a> class, which handle the details automatically.
</p>


<h3>Creating a shared access signature</h3>

<p>Note that you don't need to worry about this section if you have been <em>given</em> a SAS, and only want to use it to access storage.
</p>
<p>AzureStor supports generating three kinds of SAS: account, service and user delegation. An account SAS can be used with any type of storage. A service SAS can be used with blob and file storage, whle a user delegation SAS can be used with blob and ADLS2 storage.
</p>
<p>To create an account SAS, call the <code>get_account_sas()</code> method. This has the following signature:</p>
<pre>get_account_sas(key=self$list_keys()[1], start=NULL, expiry=NULL, services="bqtf", permissions="rl",
                resource_types="sco", ip=NULL, protocol=NULL)
</pre>
<p>To create a service SAS, call the <code>get_service_sas()</code> method, which has the following signature:</p>
<pre>get_service_sas(key=self$list_keys()[1], resource, service, start=NULL, expiry=NULL, permissions="r",
                resource_type=NULL, ip=NULL, protocol=NULL, policy=NULL, snapshot_time=NULL)
</pre>
<p>To create a user delegation SAS, you must first create a user delegation <em>key</em>. This takes the place of the account's access key in generating the SAS. The <code>get_user_delegation_key()</code> method has the following signature:</p>
<pre>get_user_delegation_key(token=self$token, key_start=NULL, key_expiry=NULL)
</pre>
<p>Once you have a user delegation key, you can use it to obtain a user delegation sas. The <code>get_user_delegation_sas()</code> method has the following signature:</p>
<pre>get_user_delegation_sas(key, resource, start=NULL, expiry=NULL, permissions="rl",
                        resource_type="c", ip=NULL, protocol=NULL, snapshot_time=NULL)
</pre>
<p>(Note that the <code>key</code> argument for this method is the user delegation key, <em>not</em> the account key.)
</p>
<p>To invalidate all user delegation keys, as well as the SAS's generated with them, call the <code>revoke_user_delegation_keys()</code> method. This has the following signature:</p>
<pre>revoke_user_delegation_keys()
</pre>
<p>See the <a href="#topic+sas">Shared access signatures</a> page for more information about this topic.
</p>


<h3>Endpoints</h3>

<p>The client-side interaction with a storage account is via an <em>endpoint</em>. A storage account can have several endpoints, one for each type of storage supported: blob, file, queue and table.
</p>
<p>The client-side interface in AzureStor is implemented using S3 classes. This is for consistency with other data access packages in R, which mostly use S3. It also emphasises the distinction between Resource Manager (which is for interacting with the storage account itself) and the client (which is for accessing files and data stored in the account).
</p>
<p>To create a storage endpoint independently of Resource Manager (for example if you are a user without admin or owner access to the account), use the <a href="#topic+blob_endpoint">blob_endpoint</a> or <a href="#topic+file_endpoint">file_endpoint</a> functions.
</p>
<p>If a storage endpoint is created without an access key and SAS, only public (anonymous) access is possible.
</p>


<h3>See Also</h3>

<p><a href="#topic+blob_endpoint">blob_endpoint</a>, <a href="#topic+file_endpoint">file_endpoint</a>,
<a href="#topic+create_storage_account">create_storage_account</a>, <a href="#topic+get_storage_account">get_storage_account</a>, <a href="#topic+delete_storage_account">delete_storage_account</a>, <a href="base.html#topic+Date">Date</a>, <a href="base.html#topic+POSIXt">POSIXt</a>
</p>
<p><a href="https://docs.microsoft.com/en-us/rest/api/storagerp/">Azure Storage Provider API reference</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storageservices/">Azure Storage Services API reference</a>
</p>
<p><a href="https://docs.microsoft.com/en-us/rest/api/storageservices/create-account-sas">Create an account SAS</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storageservices/create-user-delegation-sas">Create a user delegation SAS</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storageservices/create-service-sas">Create a service SAS</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# recommended way of retrieving a resource: via a resource group object
stor &lt;- resgroup$get_storage_account("mystorage")

# list account access keys
stor$list_keys()

# regenerate a key
stor$regen_key(1)

# storage endpoints
stor$get_blob_endpoint()
stor$get_file_endpoint()


## End(Not run)
</code></pre>

<hr>
<h2 id='blob_container'>Operations on a blob endpoint</h2><span id='topic+blob_container'></span><span id='topic+blob_container.character'></span><span id='topic+blob_container.blob_endpoint'></span><span id='topic+print.blob_container'></span><span id='topic+list_blob_containers'></span><span id='topic+list_blob_containers.character'></span><span id='topic+list_blob_containers.blob_endpoint'></span><span id='topic+create_blob_container'></span><span id='topic+create_blob_container.character'></span><span id='topic+create_blob_container.blob_container'></span><span id='topic+create_blob_container.blob_endpoint'></span><span id='topic+delete_blob_container'></span><span id='topic+delete_blob_container.character'></span><span id='topic+delete_blob_container.blob_container'></span><span id='topic+delete_blob_container.blob_endpoint'></span>

<h3>Description</h3>

<p>Get, list, create, or delete blob containers.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>blob_container(endpoint, ...)

## S3 method for class 'character'
blob_container(endpoint, key = NULL, token = NULL,
  sas = NULL, api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'blob_endpoint'
blob_container(endpoint, name, ...)

## S3 method for class 'blob_container'
print(x, ...)

list_blob_containers(endpoint, ...)

## S3 method for class 'character'
list_blob_containers(endpoint, key = NULL,
  token = NULL, sas = NULL,
  api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'blob_endpoint'
list_blob_containers(endpoint, ...)

create_blob_container(endpoint, ...)

## S3 method for class 'character'
create_blob_container(endpoint, key = NULL,
  token = NULL, sas = NULL,
  api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'blob_container'
create_blob_container(endpoint, ...)

## S3 method for class 'blob_endpoint'
create_blob_container(endpoint, name,
  public_access = c("none", "blob", "container"), ...)

delete_blob_container(endpoint, ...)

## S3 method for class 'character'
delete_blob_container(endpoint, key = NULL,
  token = NULL, sas = NULL,
  api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'blob_container'
delete_blob_container(endpoint, ...)

## S3 method for class 'blob_endpoint'
delete_blob_container(endpoint, name, confirm = TRUE, lease = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="blob_container_+3A_endpoint">endpoint</code></td>
<td>
<p>Either a blob endpoint object as created by <a href="#topic+storage_endpoint">storage_endpoint</a>, or a character string giving the URL of the endpoint.</p>
</td></tr>
<tr><td><code id="blob_container_+3A_...">...</code></td>
<td>
<p>Further arguments passed to lower-level functions.</p>
</td></tr>
<tr><td><code id="blob_container_+3A_key">key</code>, <code id="blob_container_+3A_token">token</code>, <code id="blob_container_+3A_sas">sas</code></td>
<td>
<p>If an endpoint object is not supplied, authentication credentials: either an access key, an Azure Active Directory (AAD) token, or a SAS, in that order of priority. If no authentication credentials are provided, only public (anonymous) access to the share is possible.</p>
</td></tr>
<tr><td><code id="blob_container_+3A_api_version">api_version</code></td>
<td>
<p>If an endpoint object is not supplied, the storage API version to use when interacting with the host. Currently defaults to <code>"2019-07-07"</code>.</p>
</td></tr>
<tr><td><code id="blob_container_+3A_name">name</code></td>
<td>
<p>The name of the blob container to get, create, or delete.</p>
</td></tr>
<tr><td><code id="blob_container_+3A_x">x</code></td>
<td>
<p>For the print method, a blob container object.</p>
</td></tr>
<tr><td><code id="blob_container_+3A_public_access">public_access</code></td>
<td>
<p>For creating a container, the level of public access to allow.</p>
</td></tr>
<tr><td><code id="blob_container_+3A_confirm">confirm</code></td>
<td>
<p>For deleting a container, whether to ask for confirmation.</p>
</td></tr>
<tr><td><code id="blob_container_+3A_lease">lease</code></td>
<td>
<p>For deleting a leased container, the lease ID.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You can call these functions in a couple of ways: by passing the full URL of the share, or by passing the endpoint object and the name of the container as a string.
</p>
<p>If authenticating via AAD, you can supply the token either as a string, or as an object of class AzureToken, created via <a href="AzureRMR.html#topic+reexports">AzureRMR::get_azure_token</a>. The latter is the recommended way of doing it, as it allows for automatic refreshing of expired tokens.
</p>


<h3>Value</h3>

<p>For <code>blob_container</code> and <code>create_blob_container</code>, an S3 object representing an existing or created container respectively.
</p>
<p>For <code>list_blob_containers</code>, a list of such objects.
</p>


<h3>See Also</h3>

<p><a href="#topic+storage_endpoint">storage_endpoint</a>, <a href="#topic+az_storage">az_storage</a>, <a href="#topic+storage_container">storage_container</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- blob_endpoint("https://mystorage.blob.core.windows.net/", key="access_key")

# list containers
list_blob_containers(endp)

# get, create, and delete a container
blob_container(endp, "mycontainer")
create_blob_container(endp, "newcontainer")
delete_blob_container(endp, "newcontainer")

# alternative way to do the same
blob_container("https://mystorage.blob.core.windows.net/mycontainer", key="access_key")
create_blob_container("https://mystorage.blob.core.windows.net/newcontainer", key="access_key")
delete_blob_container("https://mystorage.blob.core.windows.net/newcontainer", key="access_key")

# authenticating via AAD
token &lt;- AzureRMR::get_azure_token(resource="https://storage.azure.com/",
    tenant="myaadtenant",
    app="myappid",
    password="mypassword")
blob_container("https://mystorage.blob.core.windows.net/mycontainer", token=token)


## End(Not run)
</code></pre>

<hr>
<h2 id='call_azcopy'>Call the azcopy file transfer utility</h2><span id='topic+call_azcopy'></span><span id='topic+azcopy'></span>

<h3>Description</h3>

<p>Call the azcopy file transfer utility
</p>


<h3>Usage</h3>

<pre><code class='language-R'>call_azcopy(..., env = NULL,
  silent = getOption("azure_storage_azcopy_silent", FALSE))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="call_azcopy_+3A_...">...</code></td>
<td>
<p>Arguments to pass to AzCopy on the commandline. If no arguments are supplied, a help screen is printed.</p>
</td></tr>
<tr><td><code id="call_azcopy_+3A_env">env</code></td>
<td>
<p>A named character vector of environment variables to set for AzCopy.</p>
</td></tr>
<tr><td><code id="call_azcopy_+3A_silent">silent</code></td>
<td>
<p>Whether to print the output from AzCopy to the screen; also sets whether an error return code from AzCopy will be propagated to an R error. Defaults to the value of the <code>azure_storage_azcopy_silent</code> option, or FALSE if this is unset.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>AzureStor has the ability to use the Microsoft AzCopy commandline utility to transfer files. To enable this, ensure the processx package is installed and set the argument <code>use_azcopy=TRUE</code> in any call to an upload or download function; AzureStor will then call AzCopy to perform the file transfer rather than relying on its own code. You can also call AzCopy directly with the <code>call_azcopy</code> function.
</p>
<p>AzureStor requires version 10 or later of AzCopy. The first time you try to run it, AzureStor will check that the version of AzCopy is correct, and throw an error if it is version 8 or earlier.
</p>
<p>The AzCopy utility must be in your path for AzureStor to find it. Note that unlike earlier versions, Azcopy 10 is a single, self-contained binary file that can be placed in any directory.
</p>


<h3>Value</h3>

<p>A list, invisibly, with the following components:
</p>

<ul>
<li> <p><code>status</code>: The exit status of the AzCopy command. If this is NA, then the process was killed and had no exit status.
</p>
</li>
<li> <p><code>stdout</code>: The standard output of the command.
</p>
</li>
<li> <p><code>stderr</code>: The standard error of the command.
</p>
</li>
<li> <p><code>timeout</code>: Whether AzCopy was killed because of a timeout.
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="processx.html#topic+run">processx::run</a>, <a href="#topic+download_blob">download_blob</a>, <a href="#topic+download_azure_file">download_azure_file</a>, <a href="#topic+download_adls_file">download_adls_file</a>
</p>
<p><a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10">AzCopy page on Microsoft Docs</a>
</p>
<p><a href="https://github.com/Azure/azure-storage-azcopy">AzCopy GitHub repo</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- storage_endpoint("https://mystorage.blob.core.windows.net", sas="mysas")
cont &lt;- storage_container(endp, "mycontainer")

# print various help screens
call_azcopy("help")
call_azcopy("help", "copy")

# calling azcopy to download a blob
storage_download(cont, "myblob.csv", use_azcopy=TRUE)

# calling azcopy directly (must specify the SAS explicitly in the source URL)
call_azcopy("copy",
            "https://mystorage.blob.core.windows.net/mycontainer/myblob.csv?mysas",
            "myblob.csv")


## End(Not run)
</code></pre>

<hr>
<h2 id='copy_url_to_storage'>Upload and download generics</h2><span id='topic+copy_url_to_storage'></span><span id='topic+multicopy_url_to_storage'></span><span id='topic+copy_url_to_storage.blob_container'></span><span id='topic+multicopy_url_to_storage.blob_container'></span><span id='topic+storage_upload'></span><span id='topic+storage_upload.blob_container'></span><span id='topic+storage_upload.file_share'></span><span id='topic+storage_upload.adls_filesystem'></span><span id='topic+storage_multiupload'></span><span id='topic+storage_multiupload.blob_container'></span><span id='topic+storage_multiupload.file_share'></span><span id='topic+storage_multiupload.adls_filesystem'></span><span id='topic+storage_download'></span><span id='topic+storage_download.blob_container'></span><span id='topic+storage_download.file_share'></span><span id='topic+storage_download.adls_filesystem'></span><span id='topic+storage_multidownload'></span><span id='topic+storage_multidownload.blob_container'></span><span id='topic+storage_multidownload.file_share'></span><span id='topic+storage_multidownload.adls_filesystem'></span><span id='topic+download_from_url'></span><span id='topic+upload_to_url'></span>

<h3>Description</h3>

<p>Upload and download generics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>copy_url_to_storage(container, src, dest, ...)

multicopy_url_to_storage(container, src, dest, ...)

## S3 method for class 'blob_container'
copy_url_to_storage(container, src, dest, ...)

## S3 method for class 'blob_container'
multicopy_url_to_storage(container, src, dest, ...)

storage_upload(container, ...)

## S3 method for class 'blob_container'
storage_upload(container, ...)

## S3 method for class 'file_share'
storage_upload(container, ...)

## S3 method for class 'adls_filesystem'
storage_upload(container, ...)

storage_multiupload(container, ...)

## S3 method for class 'blob_container'
storage_multiupload(container, ...)

## S3 method for class 'file_share'
storage_multiupload(container, ...)

## S3 method for class 'adls_filesystem'
storage_multiupload(container, ...)

storage_download(container, ...)

## S3 method for class 'blob_container'
storage_download(container, ...)

## S3 method for class 'file_share'
storage_download(container, ...)

## S3 method for class 'adls_filesystem'
storage_download(container, ...)

storage_multidownload(container, ...)

## S3 method for class 'blob_container'
storage_multidownload(container, ...)

## S3 method for class 'file_share'
storage_multidownload(container, ...)

## S3 method for class 'adls_filesystem'
storage_multidownload(container, ...)

download_from_url(src, dest, key = NULL, token = NULL, sas = NULL, ...,
  overwrite = FALSE)

upload_to_url(src, dest, key = NULL, token = NULL, sas = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="copy_url_to_storage_+3A_container">container</code></td>
<td>
<p>A storage container object.</p>
</td></tr>
<tr><td><code id="copy_url_to_storage_+3A_src">src</code>, <code id="copy_url_to_storage_+3A_dest">dest</code></td>
<td>
<p>For <code>upload_to_url</code> and <code>download_from_url</code>, the source and destination files to transfer.</p>
</td></tr>
<tr><td><code id="copy_url_to_storage_+3A_...">...</code></td>
<td>
<p>Further arguments to pass to lower-level functions.</p>
</td></tr>
<tr><td><code id="copy_url_to_storage_+3A_key">key</code>, <code id="copy_url_to_storage_+3A_token">token</code>, <code id="copy_url_to_storage_+3A_sas">sas</code></td>
<td>
<p>Authentication arguments: an access key, Azure Active Directory (AAD) token or a shared access signature (SAS). If multiple arguments are supplied, a key takes priority over a token, which takes priority over a SAS. For <code>upload_to_url</code> and <code>download_to_url</code>, you can also provide a SAS as part of the URL itself.</p>
</td></tr>
<tr><td><code id="copy_url_to_storage_+3A_overwrite">overwrite</code></td>
<td>
<p>For downloading, whether to overwrite any destination files that exist.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>copy_url_to_storage</code> transfers the contents of the file at the specified HTTP[S] URL directly to storage, without requiring a temporary local copy to be made. <code>multicopy_url_to_storage</code> does the same, for multiple URLs at once. Currently methods for these are only implemented for blob storage.
</p>
<p>These functions allow you to transfer files to and from a storage account.
</p>
<p><code>storage_upload</code>, <code>storage_download</code>, <code>storage_multiupload</code> and <code>storage_multidownload</code> take as first argument a storage container, either for blob storage, file storage, or ADLSgen2. They dispatch to the corresponding file transfer functions for the given storage type.
</p>
<p><code>upload_to_url</code> and <code>download_to_url</code> allow you to transfer a file to or from Azure storage, given the URL of the source or destination. The storage details (endpoint, container name, and so on) are obtained from the URL.
</p>
<p>By default, the upload and download functions will display a progress bar while they are downloading. To turn this off, use <code>options(azure_storage_progress_bar=FALSE)</code>. To turn the progress bar back on, use <code>options(azure_storage_progress_bar=TRUE)</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+storage_container">storage_container</a>, <a href="#topic+blob_container">blob_container</a>, <a href="#topic+file_share">file_share</a>, <a href="#topic+adls_filesystem">adls_filesystem</a>
</p>
<p><a href="#topic+download_blob">download_blob</a>, <a href="#topic+download_azure_file">download_azure_file</a>, <a href="#topic+download_adls_file">download_adls_file</a>, <a href="#topic+call_azcopy">call_azcopy</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# download from blob storage
bl &lt;- storage_endpoint("https://mystorage.blob.core.windows.net/", key="access_key")
cont &lt;- storage_container(bl, "mycontainer")
storage_download(cont, "bigfile.zip", "~/bigfile.zip")

# same download but directly from the URL
download_from_url("https://mystorage.blob.core.windows.net/mycontainer/bigfile.zip",
                  "~/bigfile.zip",
                  key="access_key")

# upload to ADLSgen2
ad &lt;- storage_endpoint("https://myadls.dfs.core.windows.net/", token=mytoken)
cont &lt;- storage_container(ad, "myfilesystem")
create_storage_dir(cont, "newdir")
storage_upload(cont, "files.zip", "newdir/files.zip")

# same upload but directly to the URL
upload_to_url("files.zip",
              "https://myadls.dfs.core.windows.net/myfilesystem/newdir/files.zip",
              token=mytoken)


## End(Not run)
</code></pre>

<hr>
<h2 id='create_blob_snapshot'>Create, list and delete blob snapshots</h2><span id='topic+create_blob_snapshot'></span><span id='topic+list_blob_snapshots'></span><span id='topic+delete_blob_snapshot'></span>

<h3>Description</h3>

<p>Create, list and delete blob snapshots
</p>


<h3>Usage</h3>

<pre><code class='language-R'>create_blob_snapshot(container, blob, ...)

list_blob_snapshots(container, blob)

delete_blob_snapshot(container, blob, snapshot, confirm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="create_blob_snapshot_+3A_container">container</code></td>
<td>
<p>A blob container.</p>
</td></tr>
<tr><td><code id="create_blob_snapshot_+3A_blob">blob</code></td>
<td>
<p>The path/name of a blob.</p>
</td></tr>
<tr><td><code id="create_blob_snapshot_+3A_...">...</code></td>
<td>
<p>For <code>create_blob_snapshot</code>, an optional list of name-value pairs that will be treated as the metadata for the snapshot. If no metadata is supplied, the metadata for the base blob is copied to the snapshot.</p>
</td></tr>
<tr><td><code id="create_blob_snapshot_+3A_snapshot">snapshot</code></td>
<td>
<p>For <code>delete_blob_snapshot</code>, the specific snapshot to delete. This should be a datetime string, in the format <code>yyyy-mm-ddTHH:MM:SS.SSSSSSSZ</code>. To delete <em>all</em> snapshots for the blob, set this to <code>"all"</code>.</p>
</td></tr>
<tr><td><code id="create_blob_snapshot_+3A_confirm">confirm</code></td>
<td>
<p>Whether to ask for confirmation on deleting a blob's snapshots.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Blobs can have <em>snapshots</em> associated with them, which are the contents and optional metadata for the blob at a given point in time. A snapshot is identified by the date and time on which it was created.
</p>
<p><code>create_blob_snapshot</code> creates a new snapshot, <code>list_blob_snapshots</code> lists all the snapshots, and <code>delete_blob_snapshot</code> deletes a given snapshot or all snapshots for a blob.
</p>
<p>Note that snapshots are only supported if the storage account does NOT have hierarchical namespaces enabled.
</p>


<h3>Value</h3>

<p>For <code>create_blob_snapshot</code>, the datetime string that identifies the snapshot.
</p>
<p>For <code>list_blob_snapshots</code> a vector of such strings, or NULL if the blob has no snapshots.
</p>


<h3>See Also</h3>

<p>Other AzureStor functions that support blob snapshots by passing a <code>snapshot</code> argument: <a href="#topic+download_blob">download_blob</a>, <a href="#topic+get_storage_properties">get_storage_properties</a>, <a href="#topic+get_storage_metadata">get_storage_metadata</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

cont &lt;- blob_container("https://mystorage.blob.core.windows.net/mycontainer", key="access_key")

snap_id &lt;- create_blob_snapshot(cont, "myfile", tag1="value1", tag2="value2")

list_blob_snapshots(cont, "myfile")

get_storage_properties(cont, "myfile", snapshot=snap_id)

# returns list(tag1="value1", tag2="value2")
get_storage_metadata(cont, "myfile", snapshot=snap_id)

download_blob(cont, "myfile", snapshot=snap_id)

# delete all snapshots
delete_blob_snapshots(cont, "myfile", snapshot="all")


## End(Not run)
</code></pre>

<hr>
<h2 id='create_storage_account'>Create Azure storage account</h2><span id='topic+create_storage_account'></span>

<h3>Description</h3>

<p>Method for the <a href="AzureRMR.html#topic+az_resource_group">AzureRMR::az_resource_group</a> class.
</p>


<h3>Usage</h3>

<pre>create_storage_account(name, location, kind = "StorageV2", replication = "Standard_LRS",
                       access_tier = "hot"), https_only = TRUE,
                       hierarchical_namespace_enabled = TRUE, properties = list(), ...)
</pre>


<h3>Arguments</h3>


<ul>
<li> <p><code>name</code>: The name of the storage account.
</p>
</li>
<li> <p><code>location</code>: The location/region in which to create the account. Defaults to the resource group location.
</p>
</li>
<li> <p><code>kind</code>: The type of account, either <code>"StorageV2"</code> (the default), <code>"FileStorage"</code> or <code>"BlobStorage"</code>.
</p>
</li>
<li> <p><code>replication</code>: The replication strategy for the account. The default is locally-redundant storage (LRS).
</p>
</li>
<li> <p><code>access_tier</code>: The access tier, either <code>"hot"</code> or <code>"cool"</code>, for blobs.
</p>
</li>
<li> <p><code>https_only</code>: Whether a HTTPS connection is required to access the storage.
</p>
</li>
<li> <p><code>hierarchical_namespace_enabled</code>: Whether to enable hierarchical namespaces, which are a feature of Azure Data Lake Storage Gen 2 and provide more a efficient way to manage storage. See 'Details' below.
</p>
</li>
<li> <p><code>properties</code>: A list of other properties for the storage account.
</p>
</li>
<li><p> ... Other named arguments to pass to the <a href="#topic+az_storage">az_storage</a> initialization function.
</p>
</li></ul>



<h3>Details</h3>

<p>This method deploys a new storage account resource, with parameters given by the arguments. A storage account can host multiple types of storage:
</p>

<ul>
<li><p> blob storage
</p>
</li>
<li><p> file storage
</p>
</li>
<li><p> table storage
</p>
</li>
<li><p> queue storage
</p>
</li>
<li><p> Azure Data Lake Storage Gen2
</p>
</li></ul>

<p>Accounts created with <code>kind = "BlobStorage"</code> can only host blob storage, while those with <code>kind = "FileStorage"</code> can only host file storage. Accounts with <code>kind = "StorageV2"</code> can host all types of storage. AzureStor provides an R interface to ADLSgen2, blob and file storage, while the AzureQstor and AzureTableStor packages provide interfaces to queue and table storage respectively.
</p>


<h3>Value</h3>

<p>An object of class <code>az_storage</code> representing the created storage account.
</p>


<h3>See Also</h3>

<p><a href="#topic+get_storage_account">get_storage_account</a>, <a href="#topic+delete_storage_account">delete_storage_account</a>, <a href="#topic+az_storage">az_storage</a>
</p>
<p><a href="https://docs.microsoft.com/en-us/azure/storage/">Azure Storage documentation</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storagerp/">Azure Storage Provider API reference</a>,
<a href="https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-namespace">Azure Data Lake Storage hierarchical namespaces</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

rg &lt;- AzureRMR::az_rm$
    new(tenant="myaadtenant.onmicrosoft.com", app="app_id", password="password")$
    get_subscription("subscription_id")$
    get_resource_group("rgname")

# create a new storage account
rg$create_storage_account("mystorage", kind="StorageV2")

# create a blob storage account in a different region
rg$create_storage_account("myblobstorage",
    location="australiasoutheast",
    kind="BlobStorage")


## End(Not run)
</code></pre>

<hr>
<h2 id='delete_storage_account'>Delete an Azure storage account</h2><span id='topic+delete_storage_account'></span>

<h3>Description</h3>

<p>Method for the <a href="AzureRMR.html#topic+az_resource_group">AzureRMR::az_resource_group</a> class.
</p>


<h3>Usage</h3>

<pre>delete_storage_account(name, confirm=TRUE, wait=FALSE)
</pre>


<h3>Arguments</h3>


<ul>
<li> <p><code>name</code>: The name of the storage account.
</p>
</li>
<li> <p><code>confirm</code>: Whether to ask for confirmation before deleting.
</p>
</li>
<li> <p><code>wait</code>: Whether to wait until the deletion is complete.
</p>
</li></ul>



<h3>Value</h3>

<p>NULL on successful deletion.
</p>


<h3>See Also</h3>

<p><a href="#topic+create_storage_account">create_storage_account</a>, <a href="#topic+get_storage_account">get_storage_account</a>, <a href="#topic+az_storage">az_storage</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storagerp/">Azure Storage Provider API reference</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

rg &lt;- AzureRMR::az_rm$
    new(tenant="myaadtenant.onmicrosoft.com", app="app_id", password="password")$
    get_subscription("subscription_id")$
    get_resource_group("rgname")

# delete a storage account
rg$delete_storage_account("mystorage")


## End(Not run)
</code></pre>

<hr>
<h2 id='do_container_op'>Carry out operations on a storage account container or endpoint</h2><span id='topic+do_container_op'></span><span id='topic+call_storage_endpoint'></span>

<h3>Description</h3>

<p>Carry out operations on a storage account container or endpoint
</p>


<h3>Usage</h3>

<pre><code class='language-R'>do_container_op(container, operation = "", options = list(),
  headers = list(), http_verb = "GET", ...)

call_storage_endpoint(endpoint, path, options = list(), headers = list(),
  body = NULL, ..., http_verb = c("GET", "DELETE", "PUT", "POST", "HEAD",
  "PATCH"), http_status_handler = c("stop", "warn", "message", "pass"),
  timeout = getOption("azure_storage_timeout"), progress = NULL,
  return_headers = (http_verb == "HEAD"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="do_container_op_+3A_container">container</code>, <code id="do_container_op_+3A_endpoint">endpoint</code></td>
<td>
<p>For <code>do_container_op</code>, a storage container object (inheriting from <code>storage_container</code>). For <code>call_storage_endpoint</code>, a  storage endpoint object (inheriting from <code>storage_endpoint</code>).</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_operation">operation</code></td>
<td>
<p>The container operation to perform, which will form part of the URL path.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_options">options</code></td>
<td>
<p>A named list giving the query parameters for the operation.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_headers">headers</code></td>
<td>
<p>A named list giving any additional HTTP headers to send to the host. Note that AzureStor will handle authentication details, so you don't have to specify these here.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_http_verb">http_verb</code></td>
<td>
<p>The HTTP verb as a string, one of <code>GET</code>, <code>DELETE</code>, <code>PUT</code>, <code>POST</code>, <code>HEAD</code> or <code>PATCH</code>.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_...">...</code></td>
<td>
<p>Any additional arguments to pass to <code>httr::VERB</code>.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_path">path</code></td>
<td>
<p>The path component of the endpoint call.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_body">body</code></td>
<td>
<p>The request body for a <code>PUT/POST/PATCH</code> call.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_http_status_handler">http_status_handler</code></td>
<td>
<p>The R handler for the HTTP status code of the response. <code>"stop"</code>, <code>"warn"</code> or <code>"message"</code> will call the corresponding handlers in httr, while <code>"pass"</code> ignores the status code. The latter is primarily useful for debugging purposes.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_timeout">timeout</code></td>
<td>
<p>Optionally, the number of seconds to wait for a result. If the timeout interval elapses before the storage service has finished processing the operation, it returns an error. The default timeout is taken from the system option <code>azure_storage_timeout</code>; if this is <code>NULL</code> it means to use the service default.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_progress">progress</code></td>
<td>
<p>Used by the file transfer functions, to display a progress bar.</p>
</td></tr>
<tr><td><code id="do_container_op_+3A_return_headers">return_headers</code></td>
<td>
<p>Whether to return the (parsed) response headers, rather than the body. Ignored if <code>http_status_handler="pass"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions form the low-level interface between R and the storage API. <code>do_container_op</code> constructs a path from the operation and the container name, and passes it and the other arguments to <code>call_storage_endpoint</code>.
</p>


<h3>Value</h3>

<p>Based on the <code>http_status_handler</code> and <code>return_headers</code> arguments. If <code>http_status_handler</code> is <code>"pass"</code>, the entire response is returned without modification.
</p>
<p>If <code>http_status_handler</code> is one of <code>"stop"</code>, <code>"warn"</code> or <code>"message"</code>, the status code of the response is checked, and if an error is not thrown, the parsed headers or body of the response is returned. An exception is if the response was written to disk, as part of a file download; in this case, the return value is NULL.
</p>


<h3>See Also</h3>

<p><a href="#topic+blob_endpoint">blob_endpoint</a>, <a href="#topic+file_endpoint">file_endpoint</a>, <a href="#topic+adls_endpoint">adls_endpoint</a>
</p>
<p><a href="#topic+blob_container">blob_container</a>, <a href="#topic+file_share">file_share</a>, <a href="#topic+adls_filesystem">adls_filesystem</a>
</p>
<p><a href="httr.html#topic+GET">httr::GET</a>, <a href="httr.html#topic+PUT">httr::PUT</a>, <a href="httr.html#topic+POST">httr::POST</a>, <a href="httr.html#topic+PATCH">httr::PATCH</a>, <a href="httr.html#topic+HEAD">httr::HEAD</a>, <a href="httr.html#topic+DELETE">httr::DELETE</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# get the metadata for a blob
bl_endp &lt;- blob_endpoint("storage_acct_url", key="key")
cont &lt;- storage_container(bl_endp, "containername")
do_container_op(cont, "filename.txt", options=list(comp="metadata"), http_verb="HEAD")


## End(Not run)
</code></pre>

<hr>
<h2 id='file_share'>Operations on a file endpoint</h2><span id='topic+file_share'></span><span id='topic+file_share.character'></span><span id='topic+file_share.file_endpoint'></span><span id='topic+print.file_share'></span><span id='topic+list_file_shares'></span><span id='topic+list_file_shares.character'></span><span id='topic+list_file_shares.file_endpoint'></span><span id='topic+create_file_share'></span><span id='topic+create_file_share.character'></span><span id='topic+create_file_share.file_share'></span><span id='topic+create_file_share.file_endpoint'></span><span id='topic+delete_file_share'></span><span id='topic+delete_file_share.character'></span><span id='topic+delete_file_share.file_share'></span><span id='topic+delete_file_share.file_endpoint'></span>

<h3>Description</h3>

<p>Get, list, create, or delete file shares.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>file_share(endpoint, ...)

## S3 method for class 'character'
file_share(endpoint, key = NULL, token = NULL,
  sas = NULL, api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'file_endpoint'
file_share(endpoint, name, ...)

## S3 method for class 'file_share'
print(x, ...)

list_file_shares(endpoint, ...)

## S3 method for class 'character'
list_file_shares(endpoint, key = NULL, token = NULL,
  sas = NULL, api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'file_endpoint'
list_file_shares(endpoint, ...)

create_file_share(endpoint, ...)

## S3 method for class 'character'
create_file_share(endpoint, key = NULL, token = NULL,
  sas = NULL, api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'file_share'
create_file_share(endpoint, ...)

## S3 method for class 'file_endpoint'
create_file_share(endpoint, name, ...)

delete_file_share(endpoint, ...)

## S3 method for class 'character'
delete_file_share(endpoint, key = NULL, token = NULL,
  sas = NULL, api_version = getOption("azure_storage_api_version"), ...)

## S3 method for class 'file_share'
delete_file_share(endpoint, ...)

## S3 method for class 'file_endpoint'
delete_file_share(endpoint, name, confirm = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="file_share_+3A_endpoint">endpoint</code></td>
<td>
<p>Either a file endpoint object as created by <a href="#topic+storage_endpoint">storage_endpoint</a>, or a character string giving the URL of the endpoint.</p>
</td></tr>
<tr><td><code id="file_share_+3A_...">...</code></td>
<td>
<p>Further arguments passed to lower-level functions.</p>
</td></tr>
<tr><td><code id="file_share_+3A_key">key</code>, <code id="file_share_+3A_token">token</code>, <code id="file_share_+3A_sas">sas</code></td>
<td>
<p>If an endpoint object is not supplied, authentication credentials: either an access key, an Azure Active Directory (AAD) token, or a SAS, in that order of priority.</p>
</td></tr>
<tr><td><code id="file_share_+3A_api_version">api_version</code></td>
<td>
<p>If an endpoint object is not supplied, the storage API version to use when interacting with the host. Currently defaults to <code>"2019-07-07"</code>.</p>
</td></tr>
<tr><td><code id="file_share_+3A_name">name</code></td>
<td>
<p>The name of the file share to get, create, or delete.</p>
</td></tr>
<tr><td><code id="file_share_+3A_x">x</code></td>
<td>
<p>For the print method, a file share object.</p>
</td></tr>
<tr><td><code id="file_share_+3A_confirm">confirm</code></td>
<td>
<p>For deleting a share, whether to ask for confirmation.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>You can call these functions in a couple of ways: by passing the full URL of the share, or by passing the endpoint object and the name of the share as a string.
</p>


<h3>Value</h3>

<p>For <code>file_share</code> and <code>create_file_share</code>, an S3 object representing an existing or created share respectively.
</p>
<p>For <code>list_file_shares</code>, a list of such objects.
</p>


<h3>See Also</h3>

<p><a href="#topic+storage_endpoint">storage_endpoint</a>, <a href="#topic+az_storage">az_storage</a>, <a href="#topic+storage_container">storage_container</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

endp &lt;- file_endpoint("https://mystorage.file.core.windows.net/", key="access_key")

# list file shares
list_file_shares(endp)

# get, create, and delete a file share
file_share(endp, "myshare")
create_file_share(endp, "newshare")
delete_file_share(endp, "newshare")

# alternative way to do the same
file_share("https://mystorage.file.file.windows.net/myshare", key="access_key")
create_file_share("https://mystorage.file.core.windows.net/newshare", key="access_key")
delete_file_share("https://mystorage.file.core.windows.net/newshare", key="access_key")


## End(Not run)
</code></pre>

<hr>
<h2 id='get_account_sas'>Generate shared access signatures</h2><span id='topic+get_account_sas'></span><span id='topic+sas'></span><span id='topic+shared-access-signature'></span><span id='topic+shared_access_signature'></span><span id='topic+get_account_sas.az_storage'></span><span id='topic+get_account_sas.storage_endpoint'></span><span id='topic+get_account_sas.default'></span><span id='topic+get_user_delegation_key'></span><span id='topic+get_user_delegation_key.az_resource'></span><span id='topic+get_user_delegation_key.blob_endpoint'></span><span id='topic+revoke_user_delegation_keys'></span><span id='topic+revoke_user_delegation_keys.az_storage'></span><span id='topic+get_user_delegation_sas'></span><span id='topic+get_user_delegation_sas.az_storage'></span><span id='topic+get_user_delegation_sas.blob_endpoint'></span><span id='topic+get_user_delegation_sas.default'></span><span id='topic+get_service_sas'></span><span id='topic+get_service_sas.az_storage'></span><span id='topic+get_service_sas.storage_endpoint'></span><span id='topic+get_service_sas.default'></span>

<h3>Description</h3>

<p>The simplest way for a user to access files and data in a storage account is to give them the account's access key. This gives them full control of the account, and so may be a security risk. An alternative is to provide the user with a <em>shared access signature</em> (SAS), which limits access to specific resources and only for a set length of time. There are three kinds of SAS: account, service and user delegation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_account_sas(account, ...)

## S3 method for class 'az_storage'
get_account_sas(account, key = account$list_keys()[1], ...)

## S3 method for class 'storage_endpoint'
get_account_sas(account, key = account$key, ...)

## Default S3 method:
get_account_sas(account, key, start = NULL,
  expiry = NULL, services = "bqtf", permissions = "rl",
  resource_types = "sco", ip = NULL, protocol = NULL,
  auth_api_version = getOption("azure_storage_api_version"), ...)

get_user_delegation_key(account, ...)

## S3 method for class 'az_resource'
get_user_delegation_key(account, token = account$token, ...)

## S3 method for class 'blob_endpoint'
get_user_delegation_key(account,
  token = account$token, key_start = NULL, key_expiry = NULL, ...)

revoke_user_delegation_keys(account)

## S3 method for class 'az_storage'
revoke_user_delegation_keys(account)

get_user_delegation_sas(account, ...)

## S3 method for class 'az_storage'
get_user_delegation_sas(account, key, ...)

## S3 method for class 'blob_endpoint'
get_user_delegation_sas(account, key, ...)

## Default S3 method:
get_user_delegation_sas(account, key, resource,
  start = NULL, expiry = NULL, permissions = "rl", resource_type = "c",
  ip = NULL, protocol = NULL, snapshot_time = NULL,
  directory_depth = NULL,
  auth_api_version = getOption("azure_storage_api_version"), ...)

get_service_sas(account, ...)

## S3 method for class 'az_storage'
get_service_sas(account, resource, service = c("blob",
  "file"), key = account$list_keys()[1], ...)

## S3 method for class 'storage_endpoint'
get_service_sas(account, resource, key = account$key, ...)

## Default S3 method:
get_service_sas(account, resource, key, service,
  start = NULL, expiry = NULL, permissions = "rl",
  resource_type = NULL, ip = NULL, protocol = NULL, policy = NULL,
  snapshot_time = NULL, directory_depth = NULL,
  auth_api_version = getOption("azure_storage_api_version"), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_account_sas_+3A_account">account</code></td>
<td>
<p>An object representing a storage account. Depending on the generic, this can be one of the following: an Azure resource object (of class <code>az_storage</code>); a client storage endpoint (of class <code>storage_endpoint</code>); a <em>blob</em> storage endpoint (of class <code>blob_endpoint</code>); or a string with the name of the account.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_...">...</code></td>
<td>
<p>Arguments passed to lower-level functions.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_key">key</code></td>
<td>
<p>For <code>get_account_sas</code>, the <em>account</em> key, which controls full access to the storage account. For <code>get_user_delegation_sas</code>, a <em>user delegation</em> key, as obtained from <code>get_user_delegation_key</code>.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_start">start</code>, <code id="get_account_sas_+3A_expiry">expiry</code></td>
<td>
<p>The start and end dates for the account or user delegation SAS. These should be <code>Date</code> or <code>POSIXct</code> values, or strings coercible to such. If not supplied, the default is to generate start and expiry values for a period of 8 hours, starting from 15 minutes before the current time.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_services">services</code></td>
<td>
<p>For <code>get_account_sas</code>, the storage service(s) for which the SAS is valid. Defaults to <code>bqtf</code>, meaning blob (including ADLS2), queue, table and file storage.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_permissions">permissions</code></td>
<td>
<p>The permissions that the SAS grants. The default value of <code>rl</code> (read and list) essentially means read-only access.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_resource_types">resource_types</code></td>
<td>
<p>For an account SAS, the resource types for which the SAS is valid. For <code>get_account_sas</code> the default is <code>sco</code> meaning service, container and object. For <code>get_user_delegation_sas</code> the default is <code>c</code> meaning container-level access (including blobs within the container). Other possible values include &quot;b&quot; (a single blob) or &quot;d&quot; (a directory).</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_ip">ip</code></td>
<td>
<p>The IP address(es) or IP address range(s) for which the SAS is valid. The default is not to restrict access by IP.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_protocol">protocol</code></td>
<td>
<p>The protocol required to use the SAS. Possible values are <code>https</code> meaning HTTPS-only, or <code style="white-space: pre;">&#8288;https,http&#8288;</code> meaning HTTP is also allowed. Note that the storage account itself may require HTTPS, regardless of what the SAS allows.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_auth_api_version">auth_api_version</code></td>
<td>
<p>The storage API version to use for authenticating.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_token">token</code></td>
<td>
<p>For <code>get_user_delegation_key</code>, an AAD token from which to obtain user details. The token must have <code style="white-space: pre;">&#8288;https://storage.azure.com&#8288;</code> as its audience.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_key_start">key_start</code>, <code id="get_account_sas_+3A_key_expiry">key_expiry</code></td>
<td>
<p>For <code>get_user_delegation_key</code>, the start and end dates for the user delegation key.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_resource">resource</code></td>
<td>
<p>For <code>get_user_delegation_sas</code> and <code>get_service_sas</code>, the resource for which the SAS is valid. Both types of SAS allow this to be either a blob container, a directory or an individual blob; the resource should be specified in the form <code style="white-space: pre;">&#8288;containername[/dirname[/blobname]]&#8288;</code>. A service SAS can also be used with file shares and files, in which case the resource should be of the form <code style="white-space: pre;">&#8288;sharename[/path-to-filename]&#8288;</code>.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_resource_type">resource_type</code></td>
<td>
<p>For a service or user delegation SAS, the type of resource for which the SAS is valid. For blob storage, the default value is &quot;b&quot; meaning a single blob. For file storage, the default value is &quot;f&quot; meaning a single file. Other possible values include &quot;bs&quot; (a blob snapshot), &quot;c&quot; (a blob container), &quot;d&quot; (a directory in a blob container), or &quot;s&quot; (a file share). Note however that a user delegation SAS only supports blob storage.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_snapshot_time">snapshot_time</code></td>
<td>
<p>For a user delegation or service SAS, the blob snapshot for which the SAS is valid. Only required if <code>resource_type[s]="bs"</code>.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_directory_depth">directory_depth</code></td>
<td>
<p>For a service SAS, the depth of the directory, starting at 0 for the root. This is required if <code>resource_type="d"</code> and the account has a hierarchical namespace enabled.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_service">service</code></td>
<td>
<p>For a service SAS, the storage service for which the SAS is valid: either &quot;blob&quot; or &quot;file&quot;. Currently AzureStor does not support creating a service SAS for queue or table storage.</p>
</td></tr>
<tr><td><code id="get_account_sas_+3A_policy">policy</code></td>
<td>
<p>For a service SAS, optionally the name of a stored access policy to correlate the SAS with. Revoking the policy will also invalidate the SAS.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Listed here are S3 generics and methods to obtain a SAS for accessing storage; in addition, the <code><a href="#topic+az_storage">az_storage</a></code> resource class has R6 methods for <code>get_account_sas</code>, <code>get_service_sas</code>, <code>get_user_delegation_key</code> and <code>revoke_user_delegation_keys</code> which simply call the corresponding S3 method.
</p>
<p>Note that you don't need to worry about these methods if you have been <em>given</em> a SAS, and only want to use it to access a storage account.
</p>
<p>An <strong>account SAS</strong> is secured with the storage account key. An account SAS delegates access to resources in one or more of the storage services. All of the operations available via a user delegation SAS are also available via an account SAS. You can also delegate access to read, write, and delete operations on blob containers, tables, queues, and file shares. To obtain an account SAS, call <code>get_account_sas</code>.
</p>
<p>A <strong>service SAS</strong> is like an account SAS, but allows finer-grained control of access. You can create a service SAS that allows access only to specific blobs in a container, or files in a file share. To obtain a service SAS, call <code>get_service_sas</code>.
</p>
<p>A <strong>user delegation SAS</strong> is a SAS secured with Azure AD credentials. It's recommended that you use Azure AD credentials when possible as a security best practice, rather than using the account key, which can be more easily compromised. When your application design requires shared access signatures, use Azure AD credentials to create a user delegation SAS for superior security.
</p>
<p>Every SAS is signed with a key. To create a user delegation SAS, you must first request a <strong>user delegation key</strong>, which is then used to sign the SAS. The user delegation key is analogous to the account key used to sign a service SAS or an account SAS, except that it relies on your Azure AD credentials. To request the user delegation key, call <code>get_user_delegation_key</code>. With the user delegation key, you can then create the SAS with <code>get_user_delegation_sas</code>.
</p>
<p>To invalidate all user delegation keys, as well as the SAS's generated with them, call <code>revoke_user_delegation_keys</code>.
</p>
<p>See the examples and Microsoft Docs pages below for how to specify arguments like the services, permissions, and resource types. Also, while not explicitly mentioned in the documentation, ADLSgen2 storage can use any SAS that is valid for blob storage.
</p>


<h3>See Also</h3>

<p><a href="#topic+blob_endpoint">blob_endpoint</a>, <a href="#topic+file_endpoint">file_endpoint</a>,
<a href="base.html#topic+Date">Date</a>, <a href="base.html#topic+POSIXt">POSIXt</a>
</p>
<p><a href="https://docs.microsoft.com/en-us/rest/api/storagerp/">Azure Storage Provider API reference</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storageservices/">Azure Storage Services API reference</a>
</p>
<p><a href="https://docs.microsoft.com/en-us/rest/api/storageservices/create-account-sas">Create an account SAS</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storageservices/create-user-delegation-sas">Create a user delegation SAS</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storageservices/create-service-sas">Create a service SAS</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># account SAS valid for 7 days
get_account_sas("mystorage", "access_key", start=Sys.Date(), expiry=Sys.Date() + 7)

# SAS with read/write/create/delete permissions
get_account_sas("mystorage", "access_key", permissions="rwcd")

# SAS limited to blob (+ADLS2) and file storage
get_account_sas("mystorage", "access_key", services="bf")

# SAS for file storage, allows access to files only (not shares)
get_account_sas("mystorage", "access_key", services="f", resource_types="o")

# getting the key from an endpoint object
endp &lt;- storage_endpoint("https://mystorage.blob.core.windows.net", key="access_key")
get_account_sas(endp, permissions="rwcd")

# service SAS for a container
get_service_sas(endp, "containername")

# service SAS for a directory
get_service_sas(endp, "containername/dirname")

# read/write service SAS for a blob
get_service_sas(endp, "containername/blobname", permissions="rw")

## Not run: 

# user delegation key valid for 24 hours
token &lt;- AzureRMR::get_azure_token("https://storage.azure.com", "mytenant", "app_id")
endp &lt;- storage_endpoint("https://mystorage.blob.core.windows.net", token=token)
userkey &lt;- get_user_delegation_key(endp, start=Sys.Date(), expiry=Sys.Date() + 1)

# user delegation SAS for a container
get_user_delegation_sas(endp, userkey, resource="mycontainer")

# user delegation SAS for a specific file, read/write/create/delete access
# (order of permissions is important!)
get_user_delegation_sas(endp, userkey, resource="mycontainer/myfile",
                        resource_types="b", permissions="rcwd")


## End(Not run)
</code></pre>

<hr>
<h2 id='get_storage_account'>Get existing Azure storage account(s)</h2><span id='topic+get_storage_account'></span><span id='topic+list_storage_accounts'></span>

<h3>Description</h3>

<p>Methods for the <a href="AzureRMR.html#topic+az_resource_group">AzureRMR::az_resource_group</a> and <a href="AzureRMR.html#topic+az_subscription">AzureRMR::az_subscription</a> classes.
</p>


<h3>Usage</h3>

<pre>get_storage_account(name)
list_storage_accounts()
</pre>


<h3>Arguments</h3>


<ul>
<li> <p><code>name</code>: For <code>get_storage_account()</code>, the name of the storage account.
</p>
</li></ul>



<h3>Details</h3>

<p>The <code>AzureRMR::az_resource_group</code> class has both <code>get_storage_account()</code> and <code>list_storage_accounts()</code> methods, while the <code>AzureRMR::az_subscription</code> class only has the latter.
</p>


<h3>Value</h3>

<p>For <code>get_storage_account()</code>, an object of class <code>az_storage</code> representing the storage account.
</p>
<p>For <code>list_storage_accounts()</code>, a list of such objects.
</p>


<h3>See Also</h3>

<p><a href="#topic+create_storage_account">create_storage_account</a>, <a href="#topic+delete_storage_account">delete_storage_account</a>, <a href="#topic+az_storage">az_storage</a>,
<a href="https://docs.microsoft.com/en-us/rest/api/storagerp/">Azure Storage Provider API reference</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

rg &lt;- AzureRMR::az_rm$
    new(tenant="myaadtenant.onmicrosoft.com", app="app_id", password="password")$
    get_subscription("subscription_id")$
    get_resource_group("rgname")

# get a storage account
rg$get_storage_account("mystorage")


## End(Not run)
</code></pre>

<hr>
<h2 id='get_storage_metadata'>Get/set user-defined metadata for a storage object</h2><span id='topic+get_storage_metadata'></span><span id='topic+get_storage_metadata.blob_container'></span><span id='topic+get_storage_metadata.file_share'></span><span id='topic+get_storage_metadata.adls_filesystem'></span><span id='topic+set_storage_metadata'></span><span id='topic+set_storage_metadata.blob_container'></span><span id='topic+set_storage_metadata.file_share'></span><span id='topic+set_storage_metadata.adls_filesystem'></span>

<h3>Description</h3>

<p>Get/set user-defined metadata for a storage object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_storage_metadata(object, ...)

## S3 method for class 'blob_container'
get_storage_metadata(object, blob, snapshot = NULL, version = NULL, ...)

## S3 method for class 'file_share'
get_storage_metadata(object, file, isdir, ...)

## S3 method for class 'adls_filesystem'
get_storage_metadata(object, file, ...)

set_storage_metadata(object, ...)

## S3 method for class 'blob_container'
set_storage_metadata(object, blob, ..., keep_existing = TRUE)

## S3 method for class 'file_share'
set_storage_metadata(object, file, isdir, ..., keep_existing = TRUE)

## S3 method for class 'adls_filesystem'
set_storage_metadata(object, file, ..., keep_existing = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_storage_metadata_+3A_object">object</code></td>
<td>
<p>A blob container, file share or ADLS filesystem object.</p>
</td></tr>
<tr><td><code id="get_storage_metadata_+3A_...">...</code></td>
<td>
<p>For the metadata setters, name-value pairs to set as metadata for a blob or file.</p>
</td></tr>
<tr><td><code id="get_storage_metadata_+3A_blob">blob</code>, <code id="get_storage_metadata_+3A_file">file</code></td>
<td>
<p>Optionally the name of an individual blob, file or directory within a container.</p>
</td></tr>
<tr><td><code id="get_storage_metadata_+3A_snapshot">snapshot</code>, <code id="get_storage_metadata_+3A_version">version</code></td>
<td>
<p>For the blob method of <code>get_storage_metadata</code>, optional snapshot and version identifiers. These should be datetime strings, in the format &quot;yyyy-mm-ddTHH:MM:SS.SSSSSSSZ&quot;. Ignored if <code>blob</code> is omitted.</p>
</td></tr>
<tr><td><code id="get_storage_metadata_+3A_isdir">isdir</code></td>
<td>
<p>For the file share method, whether the <code>file</code> argument is a file or directory. If omitted, <code>get_storage_metadata</code> will auto-detect the type; however this can be slow, so supply this argument if possible.</p>
</td></tr>
<tr><td><code id="get_storage_metadata_+3A_keep_existing">keep_existing</code></td>
<td>
<p>For the metadata setters, whether to retain existing metadata information.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These methods let you get and set user-defined properties (metadata) for storage objects.
</p>


<h3>Value</h3>

<p><code>get_storage_metadata</code> returns a named list of metadata properties. If the <code>blob</code> or <code>file</code> argument is present, the properties will be for the blob/file specified. If this argument is omitted, the properties will be for the container itself.
</p>
<p><code>set_storage_metadata</code> returns the same list after setting the object's metadata, invisibly.
</p>


<h3>See Also</h3>

<p><a href="#topic+blob_container">blob_container</a>, <a href="#topic+file_share">file_share</a>, <a href="#topic+adls_filesystem">adls_filesystem</a>
</p>
<p><a href="#topic+get_storage_properties">get_storage_properties</a> for standard properties
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

fs &lt;- storage_container("https://mystorage.dfs.core.windows.net/myshare", key="access_key")
create_storage_dir("newdir")
storage_upload(share, "iris.csv", "newdir/iris.csv")

set_storage_metadata(fs, "newdir/iris.csv", name1="value1")
# will be list(name1="value1")
get_storage_metadata(fs, "newdir/iris.csv")

set_storage_metadata(fs, "newdir/iris.csv", name2="value2")
# will be list(name1="value1", name2="value2")
get_storage_metadata(fs, "newdir/iris.csv")

set_storage_metadata(fs, "newdir/iris.csv", name3="value3", keep_existing=FALSE)
# will be list(name3="value3")
get_storage_metadata(fs, "newdir/iris.csv")

# deleting all metadata
set_storage_metadata(fs, "newdir/iris.csv", keep_existing=FALSE)


## End(Not run)
</code></pre>

<hr>
<h2 id='get_storage_properties'>Get storage properties for an object</h2><span id='topic+get_storage_properties'></span><span id='topic+get_storage_properties.blob_container'></span><span id='topic+get_storage_properties.file_share'></span><span id='topic+get_storage_properties.adls_filesystem'></span><span id='topic+get_adls_file_acl'></span><span id='topic+get_adls_file_status'></span>

<h3>Description</h3>

<p>Get storage properties for an object
</p>


<h3>Usage</h3>

<pre><code class='language-R'>get_storage_properties(object, ...)

## S3 method for class 'blob_container'
get_storage_properties(object, blob, snapshot = NULL, version = NULL, ...)

## S3 method for class 'file_share'
get_storage_properties(object, file, isdir, ...)

## S3 method for class 'adls_filesystem'
get_storage_properties(object, file, ...)

get_adls_file_acl(filesystem, file)

get_adls_file_status(filesystem, file)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="get_storage_properties_+3A_object">object</code></td>
<td>
<p>A blob container, file share, or ADLS filesystem object.</p>
</td></tr>
<tr><td><code id="get_storage_properties_+3A_...">...</code></td>
<td>
<p>For compatibility with the generic.</p>
</td></tr>
<tr><td><code id="get_storage_properties_+3A_blob">blob</code>, <code id="get_storage_properties_+3A_file">file</code></td>
<td>
<p>Optionally the name of an individual blob, file or directory within a container.</p>
</td></tr>
<tr><td><code id="get_storage_properties_+3A_snapshot">snapshot</code>, <code id="get_storage_properties_+3A_version">version</code></td>
<td>
<p>For the blob method of <code>get_storage_properties</code>, optional snapshot and version identifiers. These should be datetime strings, in the format &quot;yyyy-mm-ddTHH:MM:SS.SSSSSSSZ&quot;. Ignored if <code>blob</code> is omitted.</p>
</td></tr>
<tr><td><code id="get_storage_properties_+3A_isdir">isdir</code></td>
<td>
<p>For the file share method, whether the <code>file</code> argument is a file or directory. If omitted, <code>get_storage_properties</code> will auto-detect the type; however this can be slow, so supply this argument if possible.</p>
</td></tr>
<tr><td><code id="get_storage_properties_+3A_filesystem">filesystem</code></td>
<td>
<p>An ADLS filesystem.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>get_storage_properties</code> returns a list describing the object properties. If the <code>blob</code> or <code>file</code> argument is present for the container methods, the properties will be for the blob/file specified. If this argument is omitted, the properties will be for the container itself.
</p>
<p><code>get_adls_file_acl</code> returns a string giving the ADLSgen2 ACL for the file.
</p>
<p><code>get_adls_file_status</code> returns a list of ADLSgen2 system properties for the file.
</p>


<h3>See Also</h3>

<p><a href="#topic+blob_container">blob_container</a>, <a href="#topic+file_share">file_share</a>, <a href="#topic+adls_filesystem">adls_filesystem</a>
</p>
<p><a href="#topic+get_storage_metadata">get_storage_metadata</a> for getting and setting <em>user-defined</em> properties (metadata)
</p>
<p><a href="#topic+list_blob_snapshots">list_blob_snapshots</a> to obtain the snapshots for a blob
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

fs &lt;- storage_container("https://mystorage.dfs.core.windows.net/myshare", key="access_key")
create_storage_dir("newdir")
storage_upload(share, "iris.csv", "newdir/iris.csv")

get_storage_properties(fs)
get_storage_properties(fs, "newdir")
get_storage_properties(fs, "newdir/iris.csv")

# these are ADLS only
get_adls_file_acl(fs, "newdir/iris.csv")
get_adls_file_status(fs, "newdir/iris.csv")


## End(Not run)
</code></pre>

<hr>
<h2 id='list_adls_files'>Operations on an Azure Data Lake Storage Gen2 filesystem</h2><span id='topic+list_adls_files'></span><span id='topic+multiupload_adls_file'></span><span id='topic+upload_adls_file'></span><span id='topic+multidownload_adls_file'></span><span id='topic+download_adls_file'></span><span id='topic+delete_adls_file'></span><span id='topic+create_adls_dir'></span><span id='topic+delete_adls_dir'></span><span id='topic+adls_file_exists'></span><span id='topic+adls_dir_exists'></span>

<h3>Description</h3>

<p>Upload, download, or delete a file; list files in a directory; create or delete directories; check file existence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_adls_files(filesystem, dir = "/", info = c("all", "name"),
  recursive = FALSE)

multiupload_adls_file(filesystem, src, dest, recursive = FALSE,
  blocksize = 2^22, lease = NULL, put_md5 = FALSE, use_azcopy = FALSE,
  max_concurrent_transfers = 10)

upload_adls_file(filesystem, src, dest = basename(src), blocksize = 2^24,
  lease = NULL, put_md5 = FALSE, use_azcopy = FALSE)

multidownload_adls_file(filesystem, src, dest, recursive = FALSE,
  blocksize = 2^24, overwrite = FALSE, check_md5 = FALSE,
  use_azcopy = FALSE, max_concurrent_transfers = 10)

download_adls_file(filesystem, src, dest = basename(src), blocksize = 2^24,
  overwrite = FALSE, check_md5 = FALSE, use_azcopy = FALSE)

delete_adls_file(filesystem, file, confirm = TRUE)

create_adls_dir(filesystem, dir)

delete_adls_dir(filesystem, dir, recursive = FALSE, confirm = TRUE)

adls_file_exists(filesystem, file)

adls_dir_exists(filesystem, dir)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="list_adls_files_+3A_filesystem">filesystem</code></td>
<td>
<p>An ADLSgen2 filesystem object.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_dir">dir</code>, <code id="list_adls_files_+3A_file">file</code></td>
<td>
<p>A string naming a directory or file respectively.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_info">info</code></td>
<td>
<p>Whether to return names only, or all information in a directory listing.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_recursive">recursive</code></td>
<td>
<p>For the multiupload/download functions, whether to recursively transfer files in subdirectories. For <code>list_adls_files</code>, and <code>delete_adls_dir</code>, whether the operation should recurse through subdirectories. For <code>delete_adls_dir</code>, this must be TRUE to delete a non-empty directory.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_src">src</code>, <code id="list_adls_files_+3A_dest">dest</code></td>
<td>
<p>The source and destination paths/files for uploading and downloading. See 'Details' below.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_blocksize">blocksize</code></td>
<td>
<p>The number of bytes to upload/download per HTTP(S) request.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_lease">lease</code></td>
<td>
<p>The lease for a file, if present.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_put_md5">put_md5</code></td>
<td>
<p>For uploading, whether to compute the MD5 hash of the file(s). This will be stored as part of the file's properties.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_use_azcopy">use_azcopy</code></td>
<td>
<p>Whether to use the AzCopy utility from Microsoft to do the transfer, rather than doing it in R.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_max_concurrent_transfers">max_concurrent_transfers</code></td>
<td>
<p>For <code>multiupload_adls_file</code> and <code>multidownload_adls_file</code>, the maximum number of concurrent file transfers. Each concurrent file transfer requires a separate R process, so limit this if you are low on memory.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_overwrite">overwrite</code></td>
<td>
<p>When downloading, whether to overwrite an existing destination file.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_check_md5">check_md5</code></td>
<td>
<p>For downloading, whether to verify the MD5 hash of the downloaded file(s). This requires that the file's <code>Content-MD5</code> property is set. If this is TRUE and the <code>Content-MD5</code> property is missing, a warning is generated.</p>
</td></tr>
<tr><td><code id="list_adls_files_+3A_confirm">confirm</code></td>
<td>
<p>Whether to ask for confirmation on deleting a file or directory.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>upload_adls_file</code> and <code>download_adls_file</code> are the workhorse file transfer functions for ADLSgen2 storage. They each take as inputs a <em>single</em> filename as the source for uploading/downloading, and a single filename as the destination. Alternatively, for uploading, <code>src</code> can be a <a href="base.html#topic+textConnection">textConnection</a> or <a href="base.html#topic+rawConnection">rawConnection</a> object; and for downloading, <code>dest</code> can be NULL or a <code>rawConnection</code> object. If <code>dest</code> is NULL, the downloaded data is returned as a raw vector, and if a raw connection, it will be placed into the connection. See the examples below.
</p>
<p><code>multiupload_adls_file</code> and <code>multidownload_adls_file</code> are functions for uploading and downloading <em>multiple</em> files at once. They parallelise file transfers by using the background process pool provided by AzureRMR, which can lead to significant efficiency gains when transferring many small files. There are two ways to specify the source and destination for these functions:
</p>

<ul>
<li><p> Both <code>src</code> and <code>dest</code> can be vectors naming the individual source and destination pathnames.
</p>
</li>
<li><p> The <code>src</code> argument can be a wildcard pattern expanding to one or more files, with <code>dest</code> naming a destination directory. In this case, if <code>recursive</code> is true, the file transfer will replicate the source directory structure at the destination.
</p>
</li></ul>

<p><code>upload_adls_file</code> and <code>download_adls_file</code> can display a progress bar to track the file transfer. You can control whether to display this with <code>options(azure_storage_progress_bar=TRUE|FALSE)</code>; the default is TRUE.
</p>
<p><code>adls_file_exists</code> and <code>adls_dir_exists</code> test for the existence of a file and directory, respectively.
</p>


<h4>AzCopy</h4>

<p><code>upload_azure_file</code> and <code>download_azure_file</code> have the ability to use the AzCopy commandline utility to transfer files, instead of native R code. This can be useful if you want to take advantage of AzCopy's logging and recovery features; it may also be faster in the case of transferring a very large number of small files. To enable this, set the <code>use_azcopy</code> argument to TRUE.
</p>
<p>Note that AzCopy only supports SAS and AAD (OAuth) token as authentication methods. AzCopy also expects a single filename or wildcard spec as its source/destination argument, not a vector of filenames or a connection.
</p>



<h3>Value</h3>

<p>For <code>list_adls_files</code>, if <code>info="name"</code>, a vector of file/directory names. If <code>info="all"</code>, a data frame giving the file size and whether each object is a file or directory.
</p>
<p>For <code>download_adls_file</code>, if <code>dest=NULL</code>, the contents of the downloaded file as a raw vector.
</p>
<p>For <code>adls_file_exists</code>, either TRUE or FALSE.
</p>


<h3>See Also</h3>

<p><a href="#topic+adls_filesystem">adls_filesystem</a>, <a href="#topic+az_storage">az_storage</a>, <a href="#topic+storage_download">storage_download</a>, <a href="#topic+call_azcopy">call_azcopy</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

fs &lt;- adls_filesystem("https://mystorage.dfs.core.windows.net/myfilesystem", key="access_key")

list_adls_files(fs, "/")
list_adls_files(fs, "/", recursive=TRUE)

create_adls_dir(fs, "/newdir")

upload_adls_file(fs, "~/bigfile.zip", dest="/newdir/bigfile.zip")
download_adls_file(fs, "/newdir/bigfile.zip", dest="~/bigfile_downloaded.zip")

delete_adls_file(fs, "/newdir/bigfile.zip")
delete_adls_dir(fs, "/newdir")

# uploading/downloading multiple files at once
multiupload_adls_file(fs, "/data/logfiles/*.zip")
multidownload_adls_file(fs, "/monthly/jan*.*", "/data/january")

# you can also pass a vector of file/pathnames as the source and destination
src &lt;- c("file1.csv", "file2.csv", "file3.csv")
dest &lt;- paste0("uploaded_", src)
multiupload_adls_file(share, src, dest)

# uploading serialized R objects via connections
json &lt;- jsonlite::toJSON(iris, pretty=TRUE, auto_unbox=TRUE)
con &lt;- textConnection(json)
upload_adls_file(fs, con, "iris.json")

rds &lt;- serialize(iris, NULL)
con &lt;- rawConnection(rds)
upload_adls_file(fs, con, "iris.rds")

# downloading files into memory: as a raw vector, and via a connection
rawvec &lt;- download_adls_file(fs, "iris.json", NULL)
rawToChar(rawvec)

con &lt;- rawConnection(raw(0), "r+")
download_adls_file(fs, "iris.rds", con)
unserialize(con)


## End(Not run)
</code></pre>

<hr>
<h2 id='list_azure_files'>Operations on a file share</h2><span id='topic+list_azure_files'></span><span id='topic+upload_azure_file'></span><span id='topic+multiupload_azure_file'></span><span id='topic+download_azure_file'></span><span id='topic+multidownload_azure_file'></span><span id='topic+delete_azure_file'></span><span id='topic+create_azure_dir'></span><span id='topic+delete_azure_dir'></span><span id='topic+azure_file_exists'></span><span id='topic+azure_dir_exists'></span>

<h3>Description</h3>

<p>Upload, download, or delete a file; list files in a directory; create or delete directories; check file existence.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_azure_files(share, dir = "/", info = c("all", "name"),
  prefix = NULL, recursive = FALSE)

upload_azure_file(share, src, dest = basename(src), create_dir = FALSE,
  blocksize = 2^22, put_md5 = FALSE, use_azcopy = FALSE)

multiupload_azure_file(share, src, dest, recursive = FALSE,
  create_dir = recursive, blocksize = 2^22, put_md5 = FALSE,
  use_azcopy = FALSE, max_concurrent_transfers = 10)

download_azure_file(share, src, dest = basename(src), blocksize = 2^22,
  overwrite = FALSE, check_md5 = FALSE, use_azcopy = FALSE)

multidownload_azure_file(share, src, dest, recursive = FALSE,
  blocksize = 2^22, overwrite = FALSE, check_md5 = FALSE,
  use_azcopy = FALSE, max_concurrent_transfers = 10)

delete_azure_file(share, file, confirm = TRUE)

create_azure_dir(share, dir, recursive = FALSE)

delete_azure_dir(share, dir, recursive = FALSE, confirm = TRUE)

azure_file_exists(share, file)

azure_dir_exists(share, dir)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="list_azure_files_+3A_share">share</code></td>
<td>
<p>A file share object.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_dir">dir</code>, <code id="list_azure_files_+3A_file">file</code></td>
<td>
<p>A string naming a directory or file respectively.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_info">info</code></td>
<td>
<p>Whether to return names only, or all information in a directory listing.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_prefix">prefix</code></td>
<td>
<p>For <code>list_azure_files</code>, filters the result to return only files and directories whose name begins with this prefix.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_recursive">recursive</code></td>
<td>
<p>For the multiupload/download functions, whether to recursively transfer files in subdirectories. For <code>list_azure_dir</code>, whether to include the contents of any subdirectories in the listing. For <code>create_azure_dir</code>, whether to recursively create each component of a nested directory path. For <code>delete_azure_dir</code>, whether to delete a subdirectory's contents first. Note that in all cases this can be slow, so try to use a non-recursive solution if possible.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_src">src</code>, <code id="list_azure_files_+3A_dest">dest</code></td>
<td>
<p>The source and destination files for uploading and downloading. See 'Details' below.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_create_dir">create_dir</code></td>
<td>
<p>For the uploading functions, whether to create the destination directory if it doesn't exist. Again for the file storage API this can be slow, hence is optional.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_blocksize">blocksize</code></td>
<td>
<p>The number of bytes to upload/download per HTTP(S) request.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_put_md5">put_md5</code></td>
<td>
<p>For uploading, whether to compute the MD5 hash of the file(s). This will be stored as part of the file's properties.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_use_azcopy">use_azcopy</code></td>
<td>
<p>Whether to use the AzCopy utility from Microsoft to do the transfer, rather than doing it in R.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_max_concurrent_transfers">max_concurrent_transfers</code></td>
<td>
<p>For <code>multiupload_azure_file</code> and <code>multidownload_azure_file</code>, the maximum number of concurrent file transfers. Each concurrent file transfer requires a separate R process, so limit this if you are low on memory.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_overwrite">overwrite</code></td>
<td>
<p>When downloading, whether to overwrite an existing destination file.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_check_md5">check_md5</code></td>
<td>
<p>For downloading, whether to verify the MD5 hash of the downloaded file(s). This requires that the file's <code>Content-MD5</code> property is set. If this is TRUE and the <code>Content-MD5</code> property is missing, a warning is generated.</p>
</td></tr>
<tr><td><code id="list_azure_files_+3A_confirm">confirm</code></td>
<td>
<p>Whether to ask for confirmation on deleting a file or directory.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>upload_azure_file</code> and <code>download_azure_file</code> are the workhorse file transfer functions for file storage. They each take as inputs a <em>single</em> filename as the source for uploading/downloading, and a single filename as the destination. Alternatively, for uploading, <code>src</code> can be a <a href="base.html#topic+textConnection">textConnection</a> or <a href="base.html#topic+rawConnection">rawConnection</a> object; and for downloading, <code>dest</code> can be NULL or a <code>rawConnection</code> object. If <code>dest</code> is NULL, the downloaded data is returned as a raw vector, and if a raw connection, it will be placed into the connection. See the examples below.
</p>
<p><code>multiupload_azure_file</code> and <code>multidownload_azure_file</code> are functions for uploading and downloading <em>multiple</em> files at once. They parallelise file transfers by using the background process pool provided by AzureRMR, which can lead to significant efficiency gains when transferring many small files. There are two ways to specify the source and destination for these functions:
</p>

<ul>
<li><p> Both <code>src</code> and <code>dest</code> can be vectors naming the individual source and destination pathnames.
</p>
</li>
<li><p> The <code>src</code> argument can be a wildcard pattern expanding to one or more files, with <code>dest</code> naming a destination directory. In this case, if <code>recursive</code> is true, the file transfer will replicate the source directory structure at the destination.
</p>
</li></ul>

<p><code>upload_azure_file</code> and <code>download_azure_file</code> can display a progress bar to track the file transfer. You can control whether to display this with <code>options(azure_storage_progress_bar=TRUE|FALSE)</code>; the default is TRUE.
</p>
<p><code>azure_file_exists</code> and <code>azure_dir_exists</code> test for the existence of a file and directory, respectively.
</p>


<h4>AzCopy</h4>

<p><code>upload_azure_file</code> and <code>download_azure_file</code> have the ability to use the AzCopy commandline utility to transfer files, instead of native R code. This can be useful if you want to take advantage of AzCopy's logging and recovery features; it may also be faster in the case of transferring a very large number of small files. To enable this, set the <code>use_azcopy</code> argument to TRUE.
</p>
<p>Note that AzCopy only supports SAS and AAD (OAuth) token as authentication methods. AzCopy also expects a single filename or wildcard spec as its source/destination argument, not a vector of filenames or a connection.
</p>



<h3>Value</h3>

<p>For <code>list_azure_files</code>, if <code>info="name"</code>, a vector of file/directory names. If <code>info="all"</code>, a data frame giving the file size and whether each object is a file or directory.
</p>
<p>For <code>download_azure_file</code>, if <code>dest=NULL</code>, the contents of the downloaded file as a raw vector.
</p>
<p>For <code>azure_file_exists</code>, either TRUE or FALSE.
</p>


<h3>See Also</h3>

<p><a href="#topic+file_share">file_share</a>, <a href="#topic+az_storage">az_storage</a>, <a href="#topic+storage_download">storage_download</a>, <a href="#topic+call_azcopy">call_azcopy</a>
</p>
<p><a href="https://github.com/Azure/azure-storage-azcopy">AzCopy version 10 on GitHub</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

share &lt;- file_share("https://mystorage.file.core.windows.net/myshare", key="access_key")

list_azure_files(share, "/")
list_azure_files(share, "/", recursive=TRUE)

create_azure_dir(share, "/newdir")

upload_azure_file(share, "~/bigfile.zip", dest="/newdir/bigfile.zip")
download_azure_file(share, "/newdir/bigfile.zip", dest="~/bigfile_downloaded.zip")

delete_azure_file(share, "/newdir/bigfile.zip")
delete_azure_dir(share, "/newdir")

# uploading/downloading multiple files at once
multiupload_azure_file(share, "/data/logfiles/*.zip")
multidownload_azure_file(share, "/monthly/jan*.*", "/data/january")

# you can also pass a vector of file/pathnames as the source and destination
src &lt;- c("file1.csv", "file2.csv", "file3.csv")
dest &lt;- paste0("uploaded_", src)
multiupload_azure_file(share, src, dest)

# uploading serialized R objects via connections
json &lt;- jsonlite::toJSON(iris, pretty=TRUE, auto_unbox=TRUE)
con &lt;- textConnection(json)
upload_azure_file(share, con, "iris.json")

rds &lt;- serialize(iris, NULL)
con &lt;- rawConnection(rds)
upload_azure_file(share, con, "iris.rds")

# downloading files into memory: as a raw vector, and via a connection
rawvec &lt;- download_azure_file(share, "iris.json", NULL)
rawToChar(rawvec)

con &lt;- rawConnection(raw(0), "r+")
download_azure_file(share, "iris.rds", con)
unserialize(con)


## End(Not run)
</code></pre>

<hr>
<h2 id='list_blob_versions'>List and delete blob versions</h2><span id='topic+list_blob_versions'></span><span id='topic+delete_blob_version'></span>

<h3>Description</h3>

<p>List and delete blob versions
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_blob_versions(container, blob)

delete_blob_version(container, blob, version, confirm = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="list_blob_versions_+3A_container">container</code></td>
<td>
<p>A blob container.</p>
</td></tr>
<tr><td><code id="list_blob_versions_+3A_blob">blob</code></td>
<td>
<p>The path/name of a blob.</p>
</td></tr>
<tr><td><code id="list_blob_versions_+3A_version">version</code></td>
<td>
<p>For <code>delete_blob_version</code>, the specific version to delete. This should be a datetime string, in the format <code>yyyy-mm-ddTHH:MM:SS.SSSSSSSZ</code>.</p>
</td></tr>
<tr><td><code id="list_blob_versions_+3A_confirm">confirm</code></td>
<td>
<p>Whether to ask for confirmation on deleting a blob version.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A version captures the state of a blob at a given point in time. Each version is identified with a version ID. When blob versioning is enabled for a storage account, Azure Storage automatically creates a new version with a unique ID when a blob is first created and each time that the blob is subsequently modified.
</p>
<p>A version ID can identify the current version or a previous version. A blob can have only one current version at a time.
</p>
<p>When you create a new blob, a single version exists, and that version is the current version. When you modify an existing blob, the current version becomes a previous version. A new version is created to capture the updated state, and that new version is the current version. When you delete a blob, the current version of the blob becomes a previous version, and there is no longer a current version. Any previous versions of the blob persist.
</p>
<p>Versions are different to <a href="#topic+list_blob_snapshots">snapshots</a>:
</p>

<ul>
<li><p> A new snapshot has to be explicitly created via <code>create_blob_snapshot</code>. A new blob version is automatically created whenever the base blob is modified (and hence there is no <code>create_blob_version</code> function).
</p>
</li>
<li><p> Deleting the base blob will also delete all snapshots for that blob, while blob versions will be retained (but will typically be inaccessible).
</p>
</li>
<li><p> Snapshots are only available for storage accounts with hierarchical namespaces disabled, while versioning can be used with any storage account.
</p>
</li></ul>



<h3>Value</h3>

<p>For <code>list_blob_versions</code>, a vector of datetime strings which are the IDs of each version.
</p>

<hr>
<h2 id='list_blobs'>Operations on a blob container or blob</h2><span id='topic+list_blobs'></span><span id='topic+upload_blob'></span><span id='topic+multiupload_blob'></span><span id='topic+download_blob'></span><span id='topic+multidownload_blob'></span><span id='topic+delete_blob'></span><span id='topic+create_blob_dir'></span><span id='topic+delete_blob_dir'></span><span id='topic+blob_exists'></span><span id='topic+blob_dir_exists'></span><span id='topic+copy_url_to_blob'></span><span id='topic+multicopy_url_to_blob'></span>

<h3>Description</h3>

<p>Upload, download, or delete a blob; list blobs in a container; create or delete directories; check blob availability.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>list_blobs(container, dir = "/", info = c("partial", "name", "all"),
  prefix = NULL, recursive = TRUE)

upload_blob(container, src, dest = basename(src), type = c("BlockBlob",
  "AppendBlob"), blocksize = if (type == "BlockBlob") 2^24 else 2^22,
  lease = NULL, put_md5 = FALSE, append = FALSE, use_azcopy = FALSE)

multiupload_blob(container, src, dest, recursive = FALSE,
  type = c("BlockBlob", "AppendBlob"), blocksize = if (type == "BlockBlob")
  2^24 else 2^22, lease = NULL, put_md5 = FALSE, append = FALSE,
  use_azcopy = FALSE, max_concurrent_transfers = 10)

download_blob(container, src, dest = basename(src), blocksize = 2^24,
  overwrite = FALSE, lease = NULL, check_md5 = FALSE,
  use_azcopy = FALSE, snapshot = NULL, version = NULL)

multidownload_blob(container, src, dest, recursive = FALSE,
  blocksize = 2^24, overwrite = FALSE, lease = NULL, check_md5 = FALSE,
  use_azcopy = FALSE, max_concurrent_transfers = 10)

delete_blob(container, blob, confirm = TRUE)

create_blob_dir(container, dir)

delete_blob_dir(container, dir, recursive = FALSE, confirm = TRUE)

blob_exists(container, blob)

blob_dir_exists(container, dir)

copy_url_to_blob(container, src, dest, lease = NULL, async = FALSE,
  auth_header = NULL)

multicopy_url_to_blob(container, src, dest, lease = NULL, async = FALSE,
  max_concurrent_transfers = 10, auth_header = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="list_blobs_+3A_container">container</code></td>
<td>
<p>A blob container object.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_dir">dir</code></td>
<td>
<p>For <code>list_blobs</code>, a string naming the directory. Note that blob storage does not support real directories; this argument simply filters the result to return only blobs whose names start with the given value.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_info">info</code></td>
<td>
<p>For <code>list_blobs</code>, level of detail about each blob to return: a vector of names only; the name, size, blob type, and whether this blob represents a directory; or all information.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_prefix">prefix</code></td>
<td>
<p>For <code>list_blobs</code>, an alternative way to specify the directory.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_recursive">recursive</code></td>
<td>
<p>For the multiupload/download functions, whether to recursively transfer files in subdirectories. For <code>list_blobs</code>, whether to include the contents of any subdirectories in the listing. For <code>delete_blob_dir</code>, whether to recursively delete subdirectory contents as well.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_src">src</code>, <code id="list_blobs_+3A_dest">dest</code></td>
<td>
<p>The source and destination files for uploading and downloading. See 'Details' below.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_type">type</code></td>
<td>
<p>When uploading, the type of blob to create. Currently only block and append blobs are supported.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_blocksize">blocksize</code></td>
<td>
<p>The number of bytes to upload/download per HTTP(S) request.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_lease">lease</code></td>
<td>
<p>The lease for a blob, if present.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_put_md5">put_md5</code></td>
<td>
<p>For uploading, whether to compute the MD5 hash of the blob(s). This will be stored as part of the blob's properties. Only used for block blobs.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_append">append</code></td>
<td>
<p>When uploading, whether to append the uploaded data to the destination blob. Only has an effect if <code>type="AppendBlob"</code>. If this is FALSE (the default) and the destination append blob exists, it is overwritten. If this is TRUE and the destination does not exist or is not an append blob, an error is thrown.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_use_azcopy">use_azcopy</code></td>
<td>
<p>Whether to use the AzCopy utility from Microsoft to do the transfer, rather than doing it in R.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_max_concurrent_transfers">max_concurrent_transfers</code></td>
<td>
<p>For <code>multiupload_blob</code> and <code>multidownload_blob</code>, the maximum number of concurrent file transfers. Each concurrent file transfer requires a separate R process, so limit this if you are low on memory.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_overwrite">overwrite</code></td>
<td>
<p>When downloading, whether to overwrite an existing destination file.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_check_md5">check_md5</code></td>
<td>
<p>For downloading, whether to verify the MD5 hash of the downloaded blob(s). This requires that the blob's <code>Content-MD5</code> property is set. If this is TRUE and the <code>Content-MD5</code> property is missing, a warning is generated.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_snapshot">snapshot</code>, <code id="list_blobs_+3A_version">version</code></td>
<td>
<p>For <code>download_blob</code>, optional snapshot and version identifiers. These should be datetime strings, in the format &quot;yyyy-mm-ddTHH:MM:SS.SSSSSSSZ&quot;. If omitted, download the base blob.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_blob">blob</code></td>
<td>
<p>A string naming a blob.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_confirm">confirm</code></td>
<td>
<p>Whether to ask for confirmation on deleting a blob.</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_async">async</code></td>
<td>
<p>For <code>copy_url_to_blob</code> and <code>multicopy_url_to_blob</code>, whether the copy operation should be asynchronous (proceed in the background).</p>
</td></tr>
<tr><td><code id="list_blobs_+3A_auth_header">auth_header</code></td>
<td>
<p>For <code>copy_url_to_blob</code> and <code>multicopy_url_to_blob</code>, an optional <code>Authorization</code> HTTP header to send to the source. This allows copying files that are not publicly available or otherwise have access restrictions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>upload_blob</code> and <code>download_blob</code> are the workhorse file transfer functions for blobs. They each take as inputs a <em>single</em> filename as the source for uploading/downloading, and a single filename as the destination. Alternatively, for uploading, <code>src</code> can be a <a href="base.html#topic+textConnection">textConnection</a> or <a href="base.html#topic+rawConnection">rawConnection</a> object; and for downloading, <code>dest</code> can be NULL or a <code>rawConnection</code> object. If <code>dest</code> is NULL, the downloaded data is returned as a raw vector, and if a raw connection, it will be placed into the connection. See the examples below.
</p>
<p><code>multiupload_blob</code> and <code>multidownload_blob</code> are functions for uploading and downloading <em>multiple</em> files at once. They parallelise file transfers by using the background process pool provided by AzureRMR, which can lead to significant efficiency gains when transferring many small files. There are two ways to specify the source and destination for these functions:
</p>

<ul>
<li><p> Both <code>src</code> and <code>dest</code> can be vectors naming the individual source and destination pathnames.
</p>
</li>
<li><p> The <code>src</code> argument can be a wildcard pattern expanding to one or more files, with <code>dest</code> naming a destination directory. In this case, if <code>recursive</code> is true, the file transfer will replicate the source directory structure at the destination.
</p>
</li></ul>

<p><code>upload_blob</code> and <code>download_blob</code> can display a progress bar to track the file transfer. You can control whether to display this with <code>options(azure_storage_progress_bar=TRUE|FALSE)</code>; the default is TRUE.
</p>
<p><code>multiupload_blob</code> can upload files either as all block blobs or all append blobs, but not a mix of both.
</p>
<p><code>blob_exists</code> and <code>blob_dir_exists</code> test for the existence of a blob and directory, respectively.
</p>
<p><code>delete_blob</code> deletes a blob, and <code>delete_blob_dir</code> deletes all blobs in a directory (possibly recursively). This will also delete any snapshots for the blob(s) involved.
</p>


<h4>AzCopy</h4>

<p><code>upload_blob</code> and <code>download_blob</code> have the ability to use the AzCopy commandline utility to transfer files, instead of native R code. This can be useful if you want to take advantage of AzCopy's logging and recovery features; it may also be faster in the case of transferring a very large number of small files. To enable this, set the <code>use_azcopy</code> argument to TRUE.
</p>
<p>The following points should be noted about AzCopy:
</p>

<ul>
<li><p> It only supports SAS and AAD (OAuth) token as authentication methods. AzCopy also expects a single filename or wildcard spec as its source/destination argument, not a vector of filenames or a connection.
</p>
</li>
<li><p> Currently, it does <em>not</em> support appending data to existing blobs.
</p>
</li></ul>




<h4>Directories</h4>

<p>Blob storage does not have true directories, instead using filenames containing a separator character (typically '/') to mimic a directory structure. This has some consequences:
</p>

<ul>
<li><p> The <code>isdir</code> column in the data frame output of <code>list_blobs</code> is a best guess as to whether an object represents a file or directory, and may not always be correct. Currently, <code>list_blobs</code> assumes that any object with a file size of zero is a directory.
</p>
</li>
<li><p> Zero-length files can cause problems for the blob storage service as a whole (not just AzureStor). Try to avoid uploading such files.
</p>
</li>
<li> <p><code>create_blob_dir</code> and <code>delete_blob_dir</code> are guaranteed to function as expected only for accounts with hierarchical namespaces enabled. When this feature is disabled, directories do not exist as objects in their own right: to create a directory, simply upload a blob to that directory. To delete a directory, delete all the blobs within it; as far as the blob storage service is concerned, the directory then no longer exists.
</p>
</li>
<li><p> Similarly, the output of <code>list_blobs(recursive=TRUE)</code> can vary based on whether the storage account has hierarchical namespaces enabled.
</p>
</li>
<li> <p><code>blob_exists</code> will return FALSE for a directory when the storage account does not have hierarchical namespaces enabled.
</p>
</li></ul>


<p><code>copy_url_to_blob</code> transfers the contents of the file at the specified HTTP[S] URL directly to blob storage, without requiring a temporary local copy to be made. <code>multicopy_url_to_blob</code> does the same, for multiple URLs at once. These functions have a current file size limit of 256MB.
</p>


<h3>Value</h3>

<p>For <code>list_blobs</code>, details on the blobs in the container. For <code>download_blob</code>, if <code>dest=NULL</code>, the contents of the downloaded blob as a raw vector. For <code>blob_exists</code> a flag whether the blob exists.
</p>


<h3>See Also</h3>

<p><a href="#topic+blob_container">blob_container</a>, <a href="#topic+az_storage">az_storage</a>, <a href="#topic+storage_download">storage_download</a>, <a href="#topic+call_azcopy">call_azcopy</a>, <a href="#topic+list_blob_snapshots">list_blob_snapshots</a>, <a href="#topic+list_blob_versions">list_blob_versions</a>
</p>
<p><a href="https://github.com/Azure/azure-storage-azcopy">AzCopy version 10 on GitHub</a>
<a href="https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs">Guide to the different blob types</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

cont &lt;- blob_container("https://mystorage.blob.core.windows.net/mycontainer", key="access_key")

list_blobs(cont)

upload_blob(cont, "~/bigfile.zip", dest="bigfile.zip")
download_blob(cont, "bigfile.zip", dest="~/bigfile_downloaded.zip")

delete_blob(cont, "bigfile.zip")

# uploading/downloading multiple files at once
multiupload_blob(cont, "/data/logfiles/*.zip", "/uploaded_data")
multiupload_blob(cont, "myproj/*")  # no dest directory uploads to root
multidownload_blob(cont, "jan*.*", "/data/january")

# append blob: concatenating multiple files into one
upload_blob(cont, "logfile1", "logfile", type="AppendBlob", append=FALSE)
upload_blob(cont, "logfile2", "logfile", type="AppendBlob", append=TRUE)
upload_blob(cont, "logfile3", "logfile", type="AppendBlob", append=TRUE)

# you can also pass a vector of file/pathnames as the source and destination
src &lt;- c("file1.csv", "file2.csv", "file3.csv")
dest &lt;- paste0("uploaded_", src)
multiupload_blob(cont, src, dest)

# uploading serialized R objects via connections
json &lt;- jsonlite::toJSON(iris, pretty=TRUE, auto_unbox=TRUE)
con &lt;- textConnection(json)
upload_blob(cont, con, "iris.json")

rds &lt;- serialize(iris, NULL)
con &lt;- rawConnection(rds)
upload_blob(cont, con, "iris.rds")

# downloading files into memory: as a raw vector, and via a connection
rawvec &lt;- download_blob(cont, "iris.json", NULL)
rawToChar(rawvec)

con &lt;- rawConnection(raw(0), "r+")
download_blob(cont, "iris.rds", con)
unserialize(con)

# copy from a public URL: Iris data from UCI machine learning repository
copy_url_to_blob(cont,
    "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data",
    "iris.csv")


## End(Not run)
</code></pre>

<hr>
<h2 id='sign_request'>Signs a request to the storage REST endpoint with a shared key</h2><span id='topic+sign_request'></span>

<h3>Description</h3>

<p>Signs a request to the storage REST endpoint with a shared key
</p>


<h3>Usage</h3>

<pre><code class='language-R'>sign_request(endpoint, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="sign_request_+3A_endpoint">endpoint</code></td>
<td>
<p>An endpoint object.</p>
</td></tr>
<tr><td><code id="sign_request_+3A_...">...</code></td>
<td>
<p>Further arguments to pass to individual methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a generic method to allow for variations in how the different storage services handle key authorisation. The default method works with blob, file and ADLSgen2 storage.
</p>


<h3>Value</h3>

<p>A named list of request headers. One of these should be the <code>Authorization</code> header containing the request signature.
</p>

<hr>
<h2 id='storage_container'>Storage client generics</h2><span id='topic+storage_container'></span><span id='topic+storage_generics'></span><span id='topic+storage_container.blob_endpoint'></span><span id='topic+storage_container.file_endpoint'></span><span id='topic+storage_container.adls_endpoint'></span><span id='topic+storage_container.character'></span><span id='topic+create_storage_container'></span><span id='topic+create_storage_container.blob_endpoint'></span><span id='topic+create_storage_container.file_endpoint'></span><span id='topic+create_storage_container.adls_endpoint'></span><span id='topic+create_storage_container.storage_container'></span><span id='topic+create_storage_container.character'></span><span id='topic+delete_storage_container'></span><span id='topic+delete_storage_container.blob_endpoint'></span><span id='topic+delete_storage_container.file_endpoint'></span><span id='topic+delete_storage_container.adls_endpoint'></span><span id='topic+delete_storage_container.storage_container'></span><span id='topic+delete_storage_container.character'></span><span id='topic+list_storage_containers'></span><span id='topic+list_storage_containers.blob_endpoint'></span><span id='topic+list_storage_containers.file_endpoint'></span><span id='topic+list_storage_containers.adls_endpoint'></span><span id='topic+list_storage_containers.character'></span><span id='topic+list_storage_files'></span><span id='topic+list_storage_files.blob_container'></span><span id='topic+list_storage_files.file_share'></span><span id='topic+list_storage_files.adls_filesystem'></span><span id='topic+create_storage_dir'></span><span id='topic+create_storage_dir.blob_container'></span><span id='topic+create_storage_dir.file_share'></span><span id='topic+create_storage_dir.adls_filesystem'></span><span id='topic+delete_storage_dir'></span><span id='topic+delete_storage_dir.blob_container'></span><span id='topic+delete_storage_dir.file_share'></span><span id='topic+delete_storage_dir.adls_filesystem'></span><span id='topic+delete_storage_file'></span><span id='topic+delete_storage_file.blob_container'></span><span id='topic+delete_storage_file.file_share'></span><span id='topic+delete_storage_file.adls_filesystem'></span><span id='topic+storage_file_exists'></span><span id='topic+storage_file_exists.blob_container'></span><span id='topic+storage_file_exists.file_share'></span><span id='topic+storage_file_exists.adls_filesystem'></span><span id='topic+storage_dir_exists'></span><span id='topic+storage_dir_exists.blob_container'></span><span id='topic+storage_dir_exists.file_share'></span><span id='topic+storage_dir_exists.adls_filesystem'></span><span id='topic+create_storage_snapshot'></span><span id='topic+create_storage_snapshot.blob_container'></span><span id='topic+list_storage_snapshots'></span><span id='topic+list_storage_snapshots.blob_container'></span><span id='topic+delete_storage_snapshot'></span><span id='topic+delete_storage_snapshot.blob_container'></span><span id='topic+list_storage_versions'></span><span id='topic+list_storage_versions.blob_container'></span><span id='topic+delete_storage_version'></span><span id='topic+delete_storage_version.blob_container'></span>

<h3>Description</h3>

<p>Storage client generics
</p>


<h3>Usage</h3>

<pre><code class='language-R'>storage_container(endpoint, ...)

## S3 method for class 'blob_endpoint'
storage_container(endpoint, name, ...)

## S3 method for class 'file_endpoint'
storage_container(endpoint, name, ...)

## S3 method for class 'adls_endpoint'
storage_container(endpoint, name, ...)

## S3 method for class 'character'
storage_container(endpoint, key = NULL, token = NULL, sas = NULL, ...)

create_storage_container(endpoint, ...)

## S3 method for class 'blob_endpoint'
create_storage_container(endpoint, name, ...)

## S3 method for class 'file_endpoint'
create_storage_container(endpoint, name, ...)

## S3 method for class 'adls_endpoint'
create_storage_container(endpoint, name, ...)

## S3 method for class 'storage_container'
create_storage_container(endpoint, ...)

## S3 method for class 'character'
create_storage_container(endpoint, key = NULL, token = NULL, sas = NULL, ...)

delete_storage_container(endpoint, ...)

## S3 method for class 'blob_endpoint'
delete_storage_container(endpoint, name, ...)

## S3 method for class 'file_endpoint'
delete_storage_container(endpoint, name, ...)

## S3 method for class 'adls_endpoint'
delete_storage_container(endpoint, name, ...)

## S3 method for class 'storage_container'
delete_storage_container(endpoint, ...)

## S3 method for class 'character'
delete_storage_container(endpoint, key = NULL,
  token = NULL, sas = NULL, confirm = TRUE, ...)

list_storage_containers(endpoint, ...)

## S3 method for class 'blob_endpoint'
list_storage_containers(endpoint, ...)

## S3 method for class 'file_endpoint'
list_storage_containers(endpoint, ...)

## S3 method for class 'adls_endpoint'
list_storage_containers(endpoint, ...)

## S3 method for class 'character'
list_storage_containers(endpoint, key = NULL, token = NULL, sas = NULL, ...)

list_storage_files(container, ...)

## S3 method for class 'blob_container'
list_storage_files(container, ...)

## S3 method for class 'file_share'
list_storage_files(container, ...)

## S3 method for class 'adls_filesystem'
list_storage_files(container, ...)

create_storage_dir(container, ...)

## S3 method for class 'blob_container'
create_storage_dir(container, dir, ...)

## S3 method for class 'file_share'
create_storage_dir(container, dir, ...)

## S3 method for class 'adls_filesystem'
create_storage_dir(container, dir, ...)

delete_storage_dir(container, ...)

## S3 method for class 'blob_container'
delete_storage_dir(container, dir, ...)

## S3 method for class 'file_share'
delete_storage_dir(container, dir, ...)

## S3 method for class 'adls_filesystem'
delete_storage_dir(container, dir, confirm = TRUE, ...)

delete_storage_file(container, ...)

## S3 method for class 'blob_container'
delete_storage_file(container, file, ...)

## S3 method for class 'file_share'
delete_storage_file(container, file, ...)

## S3 method for class 'adls_filesystem'
delete_storage_file(container, file, confirm = TRUE, ...)

storage_file_exists(container, file, ...)

## S3 method for class 'blob_container'
storage_file_exists(container, file, ...)

## S3 method for class 'file_share'
storage_file_exists(container, file, ...)

## S3 method for class 'adls_filesystem'
storage_file_exists(container, file, ...)

storage_dir_exists(container, dir, ...)

## S3 method for class 'blob_container'
storage_dir_exists(container, dir, ...)

## S3 method for class 'file_share'
storage_dir_exists(container, dir, ...)

## S3 method for class 'adls_filesystem'
storage_dir_exists(container, dir, ...)

create_storage_snapshot(container, file, ...)

## S3 method for class 'blob_container'
create_storage_snapshot(container, file, ...)

list_storage_snapshots(container, ...)

## S3 method for class 'blob_container'
list_storage_snapshots(container, ...)

delete_storage_snapshot(container, file, ...)

## S3 method for class 'blob_container'
delete_storage_snapshot(container, file, ...)

list_storage_versions(container, ...)

## S3 method for class 'blob_container'
list_storage_versions(container, ...)

delete_storage_version(container, file, ...)

## S3 method for class 'blob_container'
delete_storage_version(container, file, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="storage_container_+3A_endpoint">endpoint</code></td>
<td>
<p>A storage endpoint object, or for the character methods, a string giving the full URL to the container.</p>
</td></tr>
<tr><td><code id="storage_container_+3A_...">...</code></td>
<td>
<p>Further arguments to pass to lower-level functions.</p>
</td></tr>
<tr><td><code id="storage_container_+3A_name">name</code></td>
<td>
<p>For the storage container management methods, a container name.</p>
</td></tr>
<tr><td><code id="storage_container_+3A_key">key</code>, <code id="storage_container_+3A_token">token</code>, <code id="storage_container_+3A_sas">sas</code></td>
<td>
<p>For the character methods, authentication credentials for the container: either an access key, an Azure Active Directory (AAD) token, or a SAS. If multiple arguments are supplied, a key takes priority over a token, which takes priority over a SAS.</p>
</td></tr>
<tr><td><code id="storage_container_+3A_confirm">confirm</code></td>
<td>
<p>For the deletion methods, whether to ask for confirmation first.</p>
</td></tr>
<tr><td><code id="storage_container_+3A_container">container</code></td>
<td>
<p>A storage container object.</p>
</td></tr>
<tr><td><code id="storage_container_+3A_file">file</code>, <code id="storage_container_+3A_dir">dir</code></td>
<td>
<p>For the storage object management methods, a file or directory name.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These methods provide a framework for all storage management tasks supported by AzureStor. They dispatch to the appropriate functions for each type of storage.
</p>
<p>Storage container management methods:
</p>

<ul>
<li> <p><code>storage_container</code> dispatches to <code>blob_container</code>, <code>file_share</code> or <code>adls_filesystem</code>
</p>
</li>
<li> <p><code>create_storage_container</code> dispatches to <code>create_blob_container</code>, <code>create_file_share</code> or <code>create_adls_filesystem</code>
</p>
</li>
<li> <p><code>delete_storage_container</code> dispatches to <code>delete_blob_container</code>, <code>delete_file_share</code> or <code>delete_adls_filesystem</code>
</p>
</li>
<li> <p><code>list_storage_containers</code> dispatches to <code>list_blob_containers</code>, <code>list_file_shares</code> or <code>list_adls_filesystems</code>
</p>
</li></ul>

<p>Storage object management methods:
</p>

<ul>
<li> <p><code>list_storage_files</code> dispatches to <code>list_blobs</code>, <code>list_azure_files</code> or <code>list_adls_files</code>
</p>
</li>
<li> <p><code>create_storage_dir</code> dispatches to <code>create_blob_dir</code>, <code>create_azure_dir</code> or <code>create_adls_dir</code>
</p>
</li>
<li> <p><code>delete_storage_dir</code> dispatches to <code>delete_blob_dir</code>, <code>delete_azure_dir</code> or <code>delete_adls_dir</code>
</p>
</li>
<li> <p><code>delete_storage_file</code> dispatches to <code>delete_blob</code>, <code>delete_azure_file</code> or <code>delete_adls_file</code>
</p>
</li>
<li> <p><code>storage_file_exists</code> dispatches to <code>blob_exists</code>, <code>azure_file_exists</code> or <code>adls_file_exists</code>
</p>
</li>
<li> <p><code>storage_dir_exists</code> dispatches to <code>blob_dir_exists</code>, <code>azure_dir_exists</code> or <code>adls_dir_exists</code>
</p>
</li>
<li> <p><code>create_storage_snapshot</code> dispatches to <code>create_blob_snapshot</code>
</p>
</li>
<li> <p><code>list_storage_snapshots</code> dispatches to <code>list_blob_snapshots</code>
</p>
</li>
<li> <p><code>delete_storage_snapshot</code> dispatches to <code>delete_blob_snapshot</code>
</p>
</li>
<li> <p><code>list_storage_versions</code> dispatches to <code>list_blob_versions</code>
</p>
</li>
<li> <p><code>delete_storage_version</code> dispatches to <code>delete_blob_version</code>
</p>
</li></ul>



<h3>See Also</h3>

<p><a href="#topic+storage_endpoint">storage_endpoint</a>, <a href="#topic+blob_container">blob_container</a>, <a href="#topic+file_share">file_share</a>, <a href="#topic+adls_filesystem">adls_filesystem</a>
</p>
<p><a href="#topic+list_blobs">list_blobs</a>, <a href="#topic+list_azure_files">list_azure_files</a>, <a href="#topic+list_adls_files">list_adls_files</a>
</p>
<p>Similar generics exist for file transfer methods; see the page for <a href="#topic+storage_download">storage_download</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# storage endpoints for the one account
bl &lt;- storage_endpoint("https://mystorage.blob.core.windows.net/", key="access_key")
fl &lt;- storage_endpoint("https://mystorage.file.core.windows.net/", key="access_key")

list_storage_containers(bl)
list_storage_containers(fl)

# creating containers
cont &lt;- create_storage_container(bl, "newblobcontainer")
fs &lt;- create_storage_container(fl, "newfileshare")

# creating directories (if possible)
create_storage_dir(cont, "newdir")  # will error out
create_storage_dir(fs, "newdir")

# transfer a file
storage_upload(bl, "~/file.txt", "storage_file.txt")
storage_upload(cont, "~/file.txt", "newdir/storage_file.txt")


## End(Not run)
</code></pre>

<hr>
<h2 id='storage_endpoint'>Create a storage endpoint object</h2><span id='topic+storage_endpoint'></span><span id='topic+endpoint'></span><span id='topic+blob_endpoint'></span><span id='topic+file_endpoint'></span><span id='topic+queue_endpoint'></span><span id='topic+table_endpoint'></span><span id='topic+adls_endpoint'></span><span id='topic+print.storage_endpoint'></span><span id='topic+print.adls_endpoint'></span>

<h3>Description</h3>

<p>Create a storage endpoint object, for interacting with blob, file, table, queue or ADLSgen2 storage.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>storage_endpoint(endpoint, key = NULL, token = NULL, sas = NULL,
  api_version, service)

blob_endpoint(endpoint, key = NULL, token = NULL, sas = NULL,
  api_version = getOption("azure_storage_api_version"))

file_endpoint(endpoint, key = NULL, token = NULL, sas = NULL,
  api_version = getOption("azure_storage_api_version"))

adls_endpoint(endpoint, key = NULL, token = NULL, sas = NULL,
  api_version = getOption("azure_storage_api_version"))

## S3 method for class 'storage_endpoint'
print(x, ...)

## S3 method for class 'adls_endpoint'
print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="storage_endpoint_+3A_endpoint">endpoint</code></td>
<td>
<p>The URL (hostname) for the endpoint. This must be of the form <code style="white-space: pre;">&#8288;http[s]://{account-name}.{type}.{core-host-name}&#8288;</code>, where <code>type</code> is one of <code>"dfs"</code> (corresponding to ADLSgen2), <code>"blob"</code>, <code>"file"</code>, <code>"queue"</code> or <code>"table"</code>. On the public Azure cloud, endpoints will be of the form <code style="white-space: pre;">&#8288;https://{account-name}.{type}.core.windows.net&#8288;</code>.</p>
</td></tr>
<tr><td><code id="storage_endpoint_+3A_key">key</code></td>
<td>
<p>The access key for the storage account.</p>
</td></tr>
<tr><td><code id="storage_endpoint_+3A_token">token</code></td>
<td>
<p>An Azure Active Directory (AAD) authentication token. This can be either a string, or an object of class AzureToken created by <a href="AzureRMR.html#topic+reexports">AzureRMR::get_azure_token</a>. The latter is the recommended way of doing it, as it allows for automatic refreshing of expired tokens.</p>
</td></tr>
<tr><td><code id="storage_endpoint_+3A_sas">sas</code></td>
<td>
<p>A shared access signature (SAS) for the account.</p>
</td></tr>
<tr><td><code id="storage_endpoint_+3A_api_version">api_version</code></td>
<td>
<p>The storage API version to use when interacting with the host. Defaults to <code>"2019-07-07"</code>.</p>
</td></tr>
<tr><td><code id="storage_endpoint_+3A_service">service</code></td>
<td>
<p>For <code>storage_endpoint</code>, the service endpoint type: either &quot;blob&quot;, &quot;file&quot;, &quot;adls&quot;, &quot;queue&quot; or &quot;table&quot;. If this is missing, it is inferred from the endpoint hostname.</p>
</td></tr>
<tr><td><code id="storage_endpoint_+3A_x">x</code></td>
<td>
<p>For the print method, a storage endpoint object.</p>
</td></tr>
<tr><td><code id="storage_endpoint_+3A_...">...</code></td>
<td>
<p>For the print method, further arguments passed to lower-level functions.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is the starting point for the client-side storage interface in AzureRMR. <code>storage_endpoint</code> is a generic function to create an endpoint for any type of Azure storage while <code>adls_endpoint</code>, <code>blob_endpoint</code> and <code>file_endpoint</code> create endpoints for those types.
</p>
<p>If multiple authentication objects are supplied, they are used in this order of priority: first an access key, then an AAD token, then a SAS. If no authentication objects are supplied, only public (anonymous) access to the endpoint is possible.
</p>


<h3>Value</h3>

<p><code>storage_endpoint</code> returns an object of S3 class <code>"adls_endpoint"</code>, <code>"blob_endpoint"</code>, <code>"file_endpoint"</code>, <code>"queue_endpoint"</code> or <code>"table_endpoint"</code> depending on the type of endpoint. All of these also inherit from class <code>"storage_endpoint"</code>. <code>adls_endpoint</code>, <code>blob_endpoint</code> and <code>file_endpoint</code> return an object of the respective class.
</p>
<p>Note that while endpoint classes exist for all storage types, currently AzureStor only includes methods for interacting with ADLSgen2, blob and file storage.
</p>


<h3>Storage emulators</h3>

<p>AzureStor supports connecting to the <a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-use-emulator">Azure SDK</a> and <a href="https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azurite">Azurite</a> emulators for blob and queue storage. To connect, pass the full URL of the endpoint, including the account name, to the <code>blob_endpoint</code> and <code>queue_endpoint</code> methods (the latter from the AzureQstor package). The warning about an unrecognised endpoint can be ignored. See the linked pages, and the examples below, for details on how to authenticate with the emulator.
</p>
<p>Note that the Azure SDK emulator is no longer being actively developed; it's recommended to use Azurite for development work.
</p>


<h3>See Also</h3>

<p><a href="#topic+create_storage_account">create_storage_account</a>, <a href="#topic+adls_filesystem">adls_filesystem</a>, <a href="#topic+create_adls_filesystem">create_adls_filesystem</a>, <a href="#topic+file_share">file_share</a>, <a href="#topic+create_file_share">create_file_share</a>, <a href="#topic+blob_container">blob_container</a>, <a href="#topic+create_blob_container">create_blob_container</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

# obtaining an endpoint from the storage account resource object
stor &lt;- AzureRMR::get_azure_login()$
    get_subscription("sub_id")$
    get_resource_group("rgname")$
    get_storage_account("mystorage")
stor$get_blob_endpoint()

# creating an endpoint standalone
blob_endpoint("https://mystorage.blob.core.windows.net/", key="access_key")

# using an OAuth token for authentication -- note resource is 'storage.azure.com'
token &lt;- AzureAuth::get_azure_token("https://storage.azure.com",
                                    "myaadtenant", "app_id", "password")
adls_endpoint("https://myadlsstorage.dfs.core.windows.net/", token=token)


## Azurite storage emulator:

# connecting to Azurite with the default account and key (these also work for the Azure SDK)
azurite_account &lt;- "devstoreaccount1"
azurite_key &lt;-
   "Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw=="
blob_endpoint(paste0("http://127.0.0.1:10000/", azurite_account), key=azurite_key)

# to use a custom account name and key, set the AZURITE_ACCOUNTS env var before starting Azurite
Sys.setenv(AZURITE_ACCOUNTS="account1:key1")
blob_endpoint("http://127.0.0.1:10000/account1", key="key1")


## End(Not run)
</code></pre>

<hr>
<h2 id='storage_save_rds'>Save and load R objects to/from a storage account</h2><span id='topic+storage_save_rds'></span><span id='topic+storage_load_rds'></span><span id='topic+storage_save_rdata'></span><span id='topic+storage_load_rdata'></span>

<h3>Description</h3>

<p>Save and load R objects to/from a storage account
</p>


<h3>Usage</h3>

<pre><code class='language-R'>storage_save_rds(object, container, file, ...)

storage_load_rds(container, file, ...)

storage_save_rdata(..., container, file, envir = parent.frame())

storage_load_rdata(container, file, envir = parent.frame(), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="storage_save_rds_+3A_object">object</code></td>
<td>
<p>An R object to save to storage.</p>
</td></tr>
<tr><td><code id="storage_save_rds_+3A_container">container</code></td>
<td>
<p>An Azure storage container object.</p>
</td></tr>
<tr><td><code id="storage_save_rds_+3A_file">file</code></td>
<td>
<p>The name of a file in storage.</p>
</td></tr>
<tr><td><code id="storage_save_rds_+3A_...">...</code></td>
<td>
<p>Further arguments passed to <code>saveRDS</code>, <code>memDecompress</code>, <code>save</code> and <code>load</code> as appropriate.</p>
</td></tr>
<tr><td><code id="storage_save_rds_+3A_envir">envir</code></td>
<td>
<p>For <code>storage_save_rdata</code> and <code>storage_load_rdata</code>, the environment from which to get objects to save, or in which to restore objects, respectively.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These are equivalents to <code>saveRDS</code>, <code>readRDS</code>, <code>save</code> and <code>load</code> for saving and loading R objects to a storage account. They allow datasets and objects to be easily transferred to and from an R session, without having to manually create and delete temporary files.
</p>


<h3>See Also</h3>

<p><a href="#topic+storage_download">storage_download</a>, <a href="#topic+download_blob">download_blob</a>, <a href="#topic+download_azure_file">download_azure_file</a>, <a href="#topic+download_adls_file">download_adls_file</a>, <a href="base.html#topic+save">save</a>, <a href="base.html#topic+load">load</a>, <a href="base.html#topic+saveRDS">saveRDS</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

bl &lt;- storage_endpoint("https://mystorage.blob.core.windows.net/", key="access_key")
cont &lt;- storage_container(bl, "mycontainer")

storage_save_rds(iris, cont, "iris.rds")
irisnew &lt;- storage_load_rds(iris, "iris.rds")
identical(iris, irisnew)  # TRUE

storage_save_rdata(iris, mtcars, container=cont, file="dataframes.rdata")
storage_load_rdata(cont, "dataframes.rdata")


## End(Not run)
</code></pre>

<hr>
<h2 id='storage_write_delim'>Read and write a data frame to/from a storage account</h2><span id='topic+storage_write_delim'></span><span id='topic+storage_write_csv'></span><span id='topic+storage_write_csv2'></span><span id='topic+storage_read_delim'></span><span id='topic+storage_read_csv'></span><span id='topic+storage_read_csv2'></span>

<h3>Description</h3>

<p>Read and write a data frame to/from a storage account
</p>


<h3>Usage</h3>

<pre><code class='language-R'>storage_write_delim(object, container, file, delim = "\t", ...)

storage_write_csv(object, container, file, ...)

storage_write_csv2(object, container, file, ...)

storage_read_delim(container, file, delim = "\t", ...)

storage_read_csv(container, file, ...)

storage_read_csv2(container, file, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="storage_write_delim_+3A_object">object</code></td>
<td>
<p>A data frame to write to storage.</p>
</td></tr>
<tr><td><code id="storage_write_delim_+3A_container">container</code></td>
<td>
<p>An Azure storage container object.</p>
</td></tr>
<tr><td><code id="storage_write_delim_+3A_file">file</code></td>
<td>
<p>The name of a file in storage.</p>
</td></tr>
<tr><td><code id="storage_write_delim_+3A_delim">delim</code></td>
<td>
<p>For <code>storage_write_delim</code> and <code>storage_read_delim</code>, the field delimiter. Defaults to <code style="white-space: pre;">&#8288;\t&#8288;</code> (tab).</p>
</td></tr>
<tr><td><code id="storage_write_delim_+3A_...">...</code></td>
<td>
<p>Optional arguments passed to the file reading/writing functions. See 'Details'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>These functions let you read and write data frames to storage. <code>storage_read_delim</code> and <code>write_delim</code> are for reading and writing arbitrary delimited files. <code>storage_read_csv</code> and <code>write_csv</code> are for comma-delimited (CSV) files. <code>storage_read_csv2</code> and <code>write_csv2</code> are for files with the semicolon <code style="white-space: pre;">&#8288;;&#8288;</code> as delimiter and comma <code style="white-space: pre;">&#8288;,&#8288;</code> as the decimal point, as used in some European countries.
</p>
<p>If the readr package is installed, they call down to <code>read_delim</code>, <code>write_delim</code>, <code>read_csv2</code> and <code>write_csv2</code>. Otherwise, they use <code>read_delim</code> and <code>write.table</code>.
</p>


<h3>See Also</h3>

<p><a href="#topic+storage_download">storage_download</a>, <a href="#topic+download_blob">download_blob</a>, <a href="#topic+download_azure_file">download_azure_file</a>, <a href="#topic+download_adls_file">download_adls_file</a>,
<a href="utils.html#topic+write.table">write.table</a>, <a href="utils.html#topic+read.csv">read.csv</a>, <a href="readr.html#topic+write_delim">readr::write_delim</a>, <a href="readr.html#topic+read_delim">readr::read_delim</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

bl &lt;- storage_endpoint("https://mystorage.blob.core.windows.net/", key="access_key")
cont &lt;- storage_container(bl, "mycontainer")

storage_write_csv(iris, cont, "iris.csv")
# if readr is not installed
irisnew &lt;- storage_read_csv(cont, "iris.csv", stringsAsFactors=TRUE)
# if readr is installed
irisnew &lt;- storage_read_csv(cont, "iris.csv", col_types="nnnnf")

all(mapply(identical, iris, irisnew))  # TRUE


## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
