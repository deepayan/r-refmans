<!DOCTYPE html><html lang="en"><head><title>Help for package CPGLIB</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {CPGLIB}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#coef.CPGLIB'><p>Coefficients for CPGLIB Object</p></a></li>
<li><a href='#coef.cv.CPGLIB'><p>Coefficients for cv.CPGLIB Object</p></a></li>
<li><a href='#coef.cv.ProxGrad'><p>Coefficients for cv.ProxGrad Object</p></a></li>
<li><a href='#coef.ProxGrad'><p>Coefficients for ProxGrad Object</p></a></li>
<li><a href='#cpg'><p>Competing Proximal Gradients Library for Ensembles of Generalized Linear Models</p></a></li>
<li><a href='#cv.cpg'><p>Competing Proximal Gradients Library for Ensembles of Generalized Linear Models - Cross-Validation</p></a></li>
<li><a href='#cv.ProxGrad'><p>Generalized Linear Models via Proximal Gradients - Cross-validation</p></a></li>
<li><a href='#predict.CPGLIB'><p>Predictions for CPGLIB Object</p></a></li>
<li><a href='#predict.cv.CPGLIB'><p>Predictions for cv.ProxGrad Object</p></a></li>
<li><a href='#predict.cv.ProxGrad'><p>Predictions for cv.ProxGrad Object</p></a></li>
<li><a href='#predict.ProxGrad'><p>Predictions for ProxGrad Object</p></a></li>
<li><a href='#ProxGrad'><p>Generalized Linear Models via Proximal Gradients</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Competing Proximal Gradients Library</td>
</tr>
<tr>
<td>Version:</td>
<td>1.1.1</td>
</tr>
<tr>
<td>Date:</td>
<td>2022-11-21</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Anthony Christidis &lt;anthony.christidis@stat.ubc.ca&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>Functions to generate ensembles of generalized linear models using 
             competing proximal gradients. The optimal sparsity and diversity
             tuning parameters are selected via an alternating grid search.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>Biarch:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>Rcpp (&ge; 1.0.3)</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>Rcpp, RcppArmadillo</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, vctrs, mvnfast</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2022-11-21 22:18:09 UTC; antho</td>
</tr>
<tr>
<td>Author:</td>
<td>Anthony Christidis [aut, cre],
  Stefan Van Aelst [aut],
  Ruben Zamar [aut]</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2022-11-22 09:10:34 UTC</td>
</tr>
</table>
<hr>
<h2 id='coef.CPGLIB'>Coefficients for CPGLIB Object</h2><span id='topic+coef.CPGLIB'></span>

<h3>Description</h3>

<p><code>coef.CPGLIB</code> returns the coefficients for a CPGLIB object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CPGLIB'
coef(object, groups = NULL, ensemble_average = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.CPGLIB_+3A_object">object</code></td>
<td>
<p>An object of class CPGLIB.</p>
</td></tr>
<tr><td><code id="coef.CPGLIB_+3A_groups">groups</code></td>
<td>
<p>The groups in the ensemble for the coefficients. Default is all of the groups in the ensemble.</p>
</td></tr>
<tr><td><code id="coef.CPGLIB_+3A_ensemble_average">ensemble_average</code></td>
<td>
<p>Option to return the average of the coefficients over all the groups in the ensemble. Default is FALSE.</p>
</td></tr>
<tr><td><code id="coef.CPGLIB_+3A_...">...</code></td>
<td>
<p>Additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients for the CPGLIB object.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cpg">cpg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 300
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 150
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# CPGLIB - Multiple Groups
cpg.out &lt;- cpg(x.train, y.train,
               glm_type="Logistic",
               G=5, include_intercept=TRUE,
               alpha_s=3/4, alpha_d=1,
               lambda_sparsity=0.01, lambda_diversity=1,
               tolerance=1e-5, max_iter=1e5)
               
# Coefficients for each group                
cpg.coef &lt;- coef(cpg.out, ensemble_average = FALSE)


</code></pre>

<hr>
<h2 id='coef.cv.CPGLIB'>Coefficients for cv.CPGLIB Object</h2><span id='topic+coef.cv.CPGLIB'></span>

<h3>Description</h3>

<p><code>coef.cv.CPGLIB</code> returns the coefficients for a cv.CPGLIB object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.CPGLIB'
coef(object, groups = NULL, ensemble_average = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.cv.CPGLIB_+3A_object">object</code></td>
<td>
<p>An object of class cv.CPGLIB.</p>
</td></tr>
<tr><td><code id="coef.cv.CPGLIB_+3A_groups">groups</code></td>
<td>
<p>The groups in the ensemble for the coefficients. Default is all of the groups in the ensemble.</p>
</td></tr>
<tr><td><code id="coef.cv.CPGLIB_+3A_ensemble_average">ensemble_average</code></td>
<td>
<p>Option to return the average of the coefficients over all the groups in the ensemble. Default is FALSE.</p>
</td></tr>
<tr><td><code id="coef.cv.CPGLIB_+3A_...">...</code></td>
<td>
<p>Additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients for the cv.CPGLIB object. Default is FALSE.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.cpg">cv.cpg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 300
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 150
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)
mean(y.test)

# CV CPGLIB - Multiple Groups
cpg.out &lt;- cv.cpg(x.train, y.train,
                  glm_type = "Logistic",
                  G = 5, include_intercept = TRUE,
                  alpha_s = 3/4, alpha_d = 1,
                  n_lambda_sparsity = 100, n_lambda_diversity = 100,
                  tolerance = 1e-5, max_iter = 1e5)
cpg.coef &lt;- coef(cpg.out)

# Coefficients for each group                
cpg.coef &lt;- coef(cpg.out, ensemble_average = FALSE)




</code></pre>

<hr>
<h2 id='coef.cv.ProxGrad'>Coefficients for cv.ProxGrad Object</h2><span id='topic+coef.cv.ProxGrad'></span>

<h3>Description</h3>

<p><code>coef.cv.ProxGrad</code> returns the coefficients for a cv.ProxGrad object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.ProxGrad'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.cv.ProxGrad_+3A_object">object</code></td>
<td>
<p>An object of class cv.ProxGrad.</p>
</td></tr>
<tr><td><code id="coef.cv.ProxGrad_+3A_...">...</code></td>
<td>
<p>Additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients for the cv.ProxGrad object.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.ProxGrad">cv.ProxGrad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 1000
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 100
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# CV ProxGrad - Single Group
proxgrad.out &lt;- cv.ProxGrad(x.train, y.train,
                            glm_type = "Logistic",
                            include_intercept = TRUE,
                            alpha_s = 3/4,
                            n_lambda_sparsity = 100, 
                            tolerance = 1e-5, max_iter = 1e5)

# Coefficients
coef(proxgrad.out)



</code></pre>

<hr>
<h2 id='coef.ProxGrad'>Coefficients for ProxGrad Object</h2><span id='topic+coef.ProxGrad'></span>

<h3>Description</h3>

<p><code>coef.ProxGrad</code> returns the coefficients for a ProxGrad object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ProxGrad'
coef(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="coef.ProxGrad_+3A_object">object</code></td>
<td>
<p>An object of class ProxGrad.</p>
</td></tr>
<tr><td><code id="coef.ProxGrad_+3A_...">...</code></td>
<td>
<p>Additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The coefficients for the ProxGrad object.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ProxGrad">ProxGrad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 1000
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 100
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# ProxGrad - Single Group
proxgrad.out &lt;- ProxGrad(x.train, y.train,
                         glm_type = "Logistic",
                         include_intercept = TRUE,
                         alpha_s = 3/4,
                         lambda_sparsity = 0.01, 
                         tolerance = 1e-5, max_iter = 1e5)

# Coefficients
coef(proxgrad.out)



</code></pre>

<hr>
<h2 id='cpg'>Competing Proximal Gradients Library for Ensembles of Generalized Linear Models</h2><span id='topic+cpg'></span>

<h3>Description</h3>

<p><code>cpg</code> computes the coefficients for ensembles of generalized linear models via competing proximal gradients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cpg(
  x,
  y,
  glm_type = c("Linear", "Logistic")[1],
  G = 5,
  include_intercept = TRUE,
  alpha_s = 3/4,
  alpha_d = 1,
  lambda_sparsity,
  lambda_diversity,
  tolerance = 1e-08,
  max_iter = 1e+05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cpg_+3A_x">x</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code id="cpg_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr>
<tr><td><code id="cpg_+3A_glm_type">glm_type</code></td>
<td>
<p>Description of the error distribution and link function to be used for the model. Must be one of &quot;Linear&quot; or
&quot;Logistic&quot;. Default is &quot;Linear&quot;.</p>
</td></tr>
<tr><td><code id="cpg_+3A_g">G</code></td>
<td>
<p>Number of groups in the ensemble.</p>
</td></tr>
<tr><td><code id="cpg_+3A_include_intercept">include_intercept</code></td>
<td>
<p>Argument to determine whether there is an intercept. Default is TRUE.</p>
</td></tr>
<tr><td><code id="cpg_+3A_alpha_s">alpha_s</code></td>
<td>
<p>Sparsity mixing parmeter. Default is 3/4.</p>
</td></tr>
<tr><td><code id="cpg_+3A_alpha_d">alpha_d</code></td>
<td>
<p>Diversity mixing parameter. Default is 1.</p>
</td></tr>
<tr><td><code id="cpg_+3A_lambda_sparsity">lambda_sparsity</code></td>
<td>
<p>Sparsity tuning parameter value.</p>
</td></tr>
<tr><td><code id="cpg_+3A_lambda_diversity">lambda_diversity</code></td>
<td>
<p>Diversity tuning parameter value.</p>
</td></tr>
<tr><td><code id="cpg_+3A_tolerance">tolerance</code></td>
<td>
<p>Convergence criteria for the coefficients. Default is 1e-8.</p>
</td></tr>
<tr><td><code id="cpg_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations in the algorithm. Default is 1e5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>cpg</code>
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.CPGLIB">coef.CPGLIB</a></code>, <code><a href="#topic+predict.CPGLIB">predict.CPGLIB</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 300
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 150
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma  =  Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma  =  Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# CPGLIB - Multiple Groups
cpg.out &lt;- cpg(x.train, y.train,
               glm_type = "Logistic",
               G = 5, include_intercept = TRUE,
               alpha_s = 3/4, alpha_d = 1,
               lambda_sparsity = 0.01, lambda_diversity = 1,
               tolerance = 1e-5, max_iter = 1e5)

# Predictions
cpg.prob &lt;- predict(cpg.out, newx = x.test, type = "prob", 
                    groups = 1:cpg.out$G, ensemble_type = "Model-Avg")
cpg.class &lt;- predict(cpg.out, newx = x.test, type = "prob", 
                     groups = 1:cpg.out$G, ensemble_type = "Model-Avg")
plot(prob.test, cpg.prob, pch = 20)
abline(h = 0.5,v = 0.5)
mean((prob.test-cpg.prob)^2)
mean(abs(y.test-cpg.class))



</code></pre>

<hr>
<h2 id='cv.cpg'>Competing Proximal Gradients Library for Ensembles of Generalized Linear Models - Cross-Validation</h2><span id='topic+cv.cpg'></span>

<h3>Description</h3>

<p><code>cv.cpg</code> computes and cross-validates the coefficients for ensembles of generalized linear models via competing proximal gradients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.cpg(
  x,
  y,
  glm_type = c("Linear", "Logistic")[1],
  G = 5,
  full_diversity = FALSE,
  include_intercept = TRUE,
  alpha_s = 3/4,
  alpha_d = 1,
  n_lambda_sparsity = 100,
  n_lambda_diversity = 100,
  tolerance = 1e-08,
  max_iter = 1e+05,
  n_folds = 10,
  n_threads = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.cpg_+3A_x">x</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_glm_type">glm_type</code></td>
<td>
<p>Description of the error distribution and link function to be used for the model. Must be one of &quot;Linear&quot; or
&quot;Logistic&quot;. Default is &quot;Linear&quot;.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_g">G</code></td>
<td>
<p>Number of groups in the ensemble.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_full_diversity">full_diversity</code></td>
<td>
<p>Argument to determine if the overlap between the models should be zero. Default is FALSE.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_include_intercept">include_intercept</code></td>
<td>
<p>Argument to determine whether there is an intercept. Default is TRUE.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_alpha_s">alpha_s</code></td>
<td>
<p>Sparsity mixing parmeter. Default is 3/4.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_alpha_d">alpha_d</code></td>
<td>
<p>Diversity mixing parameter. Default is 1.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_n_lambda_sparsity">n_lambda_sparsity</code></td>
<td>
<p>Number of candidates for sparsity tuning parameter. Default is 100.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_n_lambda_diversity">n_lambda_diversity</code></td>
<td>
<p>Number of candidates for diveristy tuning parameter. Default is 100.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_tolerance">tolerance</code></td>
<td>
<p>Convergence criteria for the coefficients. Default is 1e-8.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations in the algorithm. Default is 1e5.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_n_folds">n_folds</code></td>
<td>
<p>Number of cross-validation folds. Default is 10.</p>
</td></tr>
<tr><td><code id="cv.cpg_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads. Default is a single thread.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class <code>cv.cpg</code>
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.cv.CPGLIB">coef.cv.CPGLIB</a></code>, <code><a href="#topic+predict.cv.CPGLIB">predict.cv.CPGLIB</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 300
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 150
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# CV CPGLIB - Multiple Groups
cpg.out &lt;- cv.cpg(x.train, y.train,
                  glm_type = "Logistic",
                  G = 5, include_intercept = TRUE,
                  alpha_s = 3/4, alpha_d = 1,
                  n_lambda_sparsity = 100, n_lambda_diversity = 100,
                  tolerance = 1e-5, max_iter = 1e5)

# Predictions
cpg.prob &lt;- predict(cpg.out, newx = x.test, type = "prob", 
                    groups = 1:cpg.out$G, ensemble_type = "Model-Avg")
cpg.class &lt;- predict(cpg.out, newx = x.test, type = "class", 
                     groups = 1:cpg.out$G, ensemble_type = "Model-Avg")
plot(prob.test, cpg.prob, pch = 20)
abline(h = 0.5,v = 0.5)
mean((prob.test-cpg.prob)^2)
mean(abs(y.test-cpg.class))



</code></pre>

<hr>
<h2 id='cv.ProxGrad'>Generalized Linear Models via Proximal Gradients - Cross-validation</h2><span id='topic+cv.ProxGrad'></span>

<h3>Description</h3>

<p><code>cv.ProxGrad</code> computes and cross-validates the coefficients for generalized linear models using proximal gradients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cv.ProxGrad(
  x,
  y,
  glm_type = c("Linear", "Logistic")[1],
  include_intercept = TRUE,
  alpha_s = 3/4,
  n_lambda_sparsity = 100,
  tolerance = 1e-08,
  max_iter = 1e+05,
  n_folds = 10,
  n_threads = 1
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cv.ProxGrad_+3A_x">x</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code id="cv.ProxGrad_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr>
<tr><td><code id="cv.ProxGrad_+3A_glm_type">glm_type</code></td>
<td>
<p>Description of the error distribution and link function to be used for the model. Must be one of &quot;Linear&quot; or
&quot;Logistic&quot;. Default is &quot;Linear&quot;.</p>
</td></tr>
<tr><td><code id="cv.ProxGrad_+3A_include_intercept">include_intercept</code></td>
<td>
<p>Argument to determine whether there is an intercept. Default is TRUE.</p>
</td></tr>
<tr><td><code id="cv.ProxGrad_+3A_alpha_s">alpha_s</code></td>
<td>
<p>Elastic net mixing parmeter. Default is 3/4.</p>
</td></tr>
<tr><td><code id="cv.ProxGrad_+3A_n_lambda_sparsity">n_lambda_sparsity</code></td>
<td>
<p>Sparsity tuning parameter value. Default is 100.</p>
</td></tr>
<tr><td><code id="cv.ProxGrad_+3A_tolerance">tolerance</code></td>
<td>
<p>Convergence criteria for the coefficients. Default is 1e-8.</p>
</td></tr>
<tr><td><code id="cv.ProxGrad_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations in the algorithm. Default is 1e5.</p>
</td></tr>
<tr><td><code id="cv.ProxGrad_+3A_n_folds">n_folds</code></td>
<td>
<p>Number of cross-validation folds. Default is 10.</p>
</td></tr>
<tr><td><code id="cv.ProxGrad_+3A_n_threads">n_threads</code></td>
<td>
<p>Number of threads. Default is a single thread.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class cv.ProxGrad
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.cv.ProxGrad">coef.cv.ProxGrad</a></code>, <code><a href="#topic+predict.cv.ProxGrad">predict.cv.ProxGrad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 1000
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 100
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# ProxGrad - Single Groups
proxgrad.out &lt;- cv.ProxGrad(x.train, y.train,
                            glm_type = "Logistic",
                            include_intercept = TRUE,
                            alpha_s = 3/4, 
                            n_lambda_sparsity = 100, 
                            tolerance = 1e-5, max_iter = 1e5)

# Predictions
proxgrad.prob &lt;- predict(proxgrad.out, newx = x.test, type = "prob")
proxgrad.class &lt;- predict(proxgrad.out, newx = x.test, type = "class")
plot(prob.test, proxgrad.prob, pch = 20)
abline(h = 0.5,v = 0.5)
mean((prob.test-proxgrad.prob)^2)
mean(abs(y.test-proxgrad.class))



</code></pre>

<hr>
<h2 id='predict.CPGLIB'>Predictions for CPGLIB Object</h2><span id='topic+predict.CPGLIB'></span>

<h3>Description</h3>

<p><code>predict.CPGLIB</code> returns the predictions for a CPGLIB object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'CPGLIB'
predict(
  object,
  newx,
  groups = NULL,
  ensemble_type = c("Model-Avg", "Coef-Avg", "Weighted-Prob", "Majority-Vote")[1],
  class_type = c("prob", "class")[1],
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.CPGLIB_+3A_object">object</code></td>
<td>
<p>An object of class CPGLIB.</p>
</td></tr>
<tr><td><code id="predict.CPGLIB_+3A_newx">newx</code></td>
<td>
<p>New data for predictions.</p>
</td></tr>
<tr><td><code id="predict.CPGLIB_+3A_groups">groups</code></td>
<td>
<p>The groups in the ensemble for the predictions. Default is all of the groups in the ensemble.</p>
</td></tr>
<tr><td><code id="predict.CPGLIB_+3A_ensemble_type">ensemble_type</code></td>
<td>
<p>The type of ensembling function for the models. Options are &quot;Model-Avg&quot;, &quot;Coef-Avg&quot; or &quot;Weighted-Prob&quot; for 
classifications predictions. Default is &quot;Model-Avg&quot;.</p>
</td></tr>
<tr><td><code id="predict.CPGLIB_+3A_class_type">class_type</code></td>
<td>
<p>The type of predictions for classification. Options are &quot;prob&quot; and &quot;class&quot;. Default is &quot;prob&quot;.</p>
</td></tr>
<tr><td><code id="predict.CPGLIB_+3A_...">...</code></td>
<td>
<p>Additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predictions for the CPGLIB object.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cpg">cpg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 300
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 150
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# CPGLIB - Multiple Groups
cpg.out &lt;- cpg(x.train, y.train,
               glm_type = "Logistic",
               G = 5, include_intercept = TRUE,
               alpha_s = 3/4, alpha_d = 1,
               lambda_sparsity = 0.01, lambda_diversity = 1,
               tolerance = 1e-5, max_iter = 1e5)

# Predictions
cpg.prob &lt;- predict(cpg.out, newx = x.test, type = "prob", 
                    groups = 1:cpg.out$G, ensemble_type = "Model-Avg")
cpg.class &lt;- predict(cpg.out, newx = x.test, type = "prob", 
                     groups = 1:cpg.out$G, ensemble_type = "Model-Avg")
plot(prob.test, cpg.prob, pch=20)
abline(h=0.5,v=0.5)
mean((prob.test-cpg.prob)^2)
mean(abs(y.test-cpg.class))



</code></pre>

<hr>
<h2 id='predict.cv.CPGLIB'>Predictions for cv.ProxGrad Object</h2><span id='topic+predict.cv.CPGLIB'></span>

<h3>Description</h3>

<p><code>predict.cv.CPGLIB</code> returns the predictions for a ProxGrad object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.CPGLIB'
predict(
  object,
  newx,
  groups = NULL,
  ensemble_type = c("Model-Avg", "Coef-Avg", "Weighted-Prob", "Majority-Vote")[1],
  class_type = c("prob", "class")[1],
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.cv.CPGLIB_+3A_object">object</code></td>
<td>
<p>An object of class cv.CPGLIB.</p>
</td></tr>
<tr><td><code id="predict.cv.CPGLIB_+3A_newx">newx</code></td>
<td>
<p>New data for predictions.</p>
</td></tr>
<tr><td><code id="predict.cv.CPGLIB_+3A_groups">groups</code></td>
<td>
<p>The groups in the ensemble for the predictions. Default is all of the groups in the ensemble.</p>
</td></tr>
<tr><td><code id="predict.cv.CPGLIB_+3A_ensemble_type">ensemble_type</code></td>
<td>
<p>The type of ensembling function for the models. Options are &quot;Model-Avg&quot;, &quot;Coef-Avg&quot; or &quot;Weighted-Prob&quot; for 
classifications predictions. Default is &quot;Model-Avg&quot;.</p>
</td></tr>
<tr><td><code id="predict.cv.CPGLIB_+3A_class_type">class_type</code></td>
<td>
<p>The type of predictions for classification. Options are &quot;prob&quot; and &quot;class&quot;. Default is &quot;prob&quot;.</p>
</td></tr>
<tr><td><code id="predict.cv.CPGLIB_+3A_...">...</code></td>
<td>
<p>Additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predictions for the cv.CPGLIB object.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.cpg">cv.cpg</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 300
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 150
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)
mean(y.test)

# CV CPGLIB - Multiple Groups
cpg.out &lt;- cv.cpg(x.train, y.train,
                  glm_type = "Logistic",
                  G = 5, include_intercept = TRUE,
                  alpha_s = 3/4, alpha_d = 1,
                  n_lambda_sparsity = 100, n_lambda_diversity = 100,
                  tolerance = 1e-5, max_iter = 1e5)

# Predictions
cpg.prob &lt;- predict(cpg.out, newx = x.test, type = "prob", 
                    groups = 1:cpg.out$G, ensemble_type = "Model-Avg")
cpg.class &lt;- predict(cpg.out, newx = x.test, type = "class", 
                     groups = 1:cpg.out$G, ensemble_type = "Model-Avg")
plot(prob.test, cpg.prob, pch = 20)
abline(h = 0.5,v = 0.5)
mean((prob.test-cpg.prob)^2)
mean(abs(y.test-cpg.class))




</code></pre>

<hr>
<h2 id='predict.cv.ProxGrad'>Predictions for cv.ProxGrad Object</h2><span id='topic+predict.cv.ProxGrad'></span>

<h3>Description</h3>

<p><code>predict.cv.ProxGrad</code> returns the predictions for a ProxGrad object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'cv.ProxGrad'
predict(object, newx, type = c("prob", "class")[1], ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.cv.ProxGrad_+3A_object">object</code></td>
<td>
<p>An object of class cv.ProxGrad.</p>
</td></tr>
<tr><td><code id="predict.cv.ProxGrad_+3A_newx">newx</code></td>
<td>
<p>New data for predictions.</p>
</td></tr>
<tr><td><code id="predict.cv.ProxGrad_+3A_type">type</code></td>
<td>
<p>The type of predictions for binary response. Options are &quot;prob&quot; (default) and &quot;class&quot;.</p>
</td></tr>
<tr><td><code id="predict.cv.ProxGrad_+3A_...">...</code></td>
<td>
<p>Additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predictions for the cv.ProxGrad object.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cv.ProxGrad">cv.ProxGrad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 1000
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 100
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# CV ProxGrad - Single Group
proxgrad.out &lt;- cv.ProxGrad(x.train, y.train,
                            glm_type = "Logistic",
                            include_intercept = TRUE,
                            alpha_s = 3/4,
                            n_lambda_sparsity = 100, 
                            tolerance = 1e-5, max_iter = 1e5)

# Predictions
proxgrad.prob &lt;- predict(proxgrad.out, newx = x.test, type = "prob")
proxgrad.class &lt;- predict(proxgrad.out, newx = x.test, type = "class")
plot(prob.test, proxgrad.prob, pch = 20)
abline(h = 0.5,v = 0.5)
mean((prob.test-proxgrad.prob)^2)
mean(abs(y.test-proxgrad.class))



</code></pre>

<hr>
<h2 id='predict.ProxGrad'>Predictions for ProxGrad Object</h2><span id='topic+predict.ProxGrad'></span>

<h3>Description</h3>

<p><code>predict.ProxGrad</code> returns the predictions for a ProxGrad object.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S3 method for class 'ProxGrad'
predict(object, newx, type = c("prob", "class")[1], ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict.ProxGrad_+3A_object">object</code></td>
<td>
<p>An object of class ProxGrad</p>
</td></tr>
<tr><td><code id="predict.ProxGrad_+3A_newx">newx</code></td>
<td>
<p>New data for predictions.</p>
</td></tr>
<tr><td><code id="predict.ProxGrad_+3A_type">type</code></td>
<td>
<p>The type of predictions for binary response. Options are &quot;prob&quot; (default) and &quot;class&quot;.</p>
</td></tr>
<tr><td><code id="predict.ProxGrad_+3A_...">...</code></td>
<td>
<p>Additional arguments for compatibility.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>The predictions for the ProxGrad object.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+ProxGrad">ProxGrad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 1000
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 100
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# ProxGrad - Single Group
proxgrad.out &lt;- ProxGrad(x.train, y.train,
                         glm_type = "Logistic",
                         include_intercept = TRUE,
                         alpha_s = 3/4,
                         lambda_sparsity = 0.01, 
                         tolerance = 1e-5, max_iter = 1e5)

# Predictions
proxgrad.prob &lt;- predict(proxgrad.out, newx = x.test, type = "prob")
proxgrad.class &lt;- predict(proxgrad.out, newx = x.test, type = "class")
plot(prob.test, proxgrad.prob, pch = 20)
abline(h = 0.5,v = 0.5)
mean((prob.test-proxgrad.prob)^2)
mean(abs(y.test-proxgrad.class))



</code></pre>

<hr>
<h2 id='ProxGrad'>Generalized Linear Models via Proximal Gradients</h2><span id='topic+ProxGrad'></span>

<h3>Description</h3>

<p><code>ProxGrad</code> computes the coefficients for generalized linear models using proximal gradients.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ProxGrad(
  x,
  y,
  glm_type = c("Linear", "Logistic")[1],
  include_intercept = TRUE,
  alpha_s = 3/4,
  lambda_sparsity,
  tolerance = 1e-08,
  max_iter = 1e+05
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="ProxGrad_+3A_x">x</code></td>
<td>
<p>Design matrix.</p>
</td></tr>
<tr><td><code id="ProxGrad_+3A_y">y</code></td>
<td>
<p>Response vector.</p>
</td></tr>
<tr><td><code id="ProxGrad_+3A_glm_type">glm_type</code></td>
<td>
<p>Description of the error distribution and link function to be used for the model. Must be one of &quot;Linear&quot; or
&quot;Logistic&quot; . Default is &quot;Linear&quot;.</p>
</td></tr>
<tr><td><code id="ProxGrad_+3A_include_intercept">include_intercept</code></td>
<td>
<p>Argument to determine whether there is an intercept. Default is TRUE.</p>
</td></tr>
<tr><td><code id="ProxGrad_+3A_alpha_s">alpha_s</code></td>
<td>
<p>Elastic net mixing parmeter. Default is 3/4.</p>
</td></tr>
<tr><td><code id="ProxGrad_+3A_lambda_sparsity">lambda_sparsity</code></td>
<td>
<p>Sparsity tuning parameter value.</p>
</td></tr>
<tr><td><code id="ProxGrad_+3A_tolerance">tolerance</code></td>
<td>
<p>Convergence criteria for the coefficients. Default is 1e-8.</p>
</td></tr>
<tr><td><code id="ProxGrad_+3A_max_iter">max_iter</code></td>
<td>
<p>Maximum number of iterations in the algorithm. Default is 1e5.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>An object of class ProxGrad.
</p>


<h3>Author(s)</h3>

<p>Anthony-Alexander Christidis, <a href="mailto:anthony.christidis@stat.ubc.ca">anthony.christidis@stat.ubc.ca</a>
</p>


<h3>See Also</h3>

<p><code><a href="#topic+coef.ProxGrad">coef.ProxGrad</a></code>, <code><a href="#topic+predict.ProxGrad">predict.ProxGrad</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Data simulation
set.seed(1)
n &lt;- 50
N &lt;- 2000
p &lt;- 1000
beta.active &lt;- c(abs(runif(p, 0, 1/2))*(-1)^rbinom(p, 1, 0.3))
# Parameters
p.active &lt;- 100
beta &lt;- c(beta.active[1:p.active], rep(0, p-p.active))
Sigma &lt;- matrix(0, p, p)
Sigma[1:p.active, 1:p.active] &lt;- 0.5
diag(Sigma) &lt;- 1

# Train data
x.train &lt;- mvnfast::rmvn(n, mu = rep(0, p), sigma = Sigma) 
prob.train &lt;- exp(x.train %*% beta)/
              (1+exp(x.train %*% beta))
y.train &lt;- rbinom(n, 1, prob.train)
# Test data
x.test &lt;- mvnfast::rmvn(N, mu = rep(0, p), sigma = Sigma)
prob.test &lt;- exp(x.test %*% beta)/
             (1+exp(x.test %*% beta))
y.test &lt;- rbinom(N, 1, prob.test)

# ProxGrad - Single Group
proxgrad.out &lt;- ProxGrad(x.train, y.train,
                         glm_type = "Logistic",
                         include_intercept = TRUE,
                         alpha_s = 3/4,
                         lambda_sparsity = 0.01, 
                         tolerance = 1e-5, max_iter = 1e5)

# Predictions
proxgrad.prob &lt;- predict(proxgrad.out, newx = x.test, type = "prob")
proxgrad.class &lt;- predict(proxgrad.out, newx = x.test, type = "class")
plot(prob.test, proxgrad.prob, pch = 20)
abline(h = 0.5,v = 0.5)
mean((prob.test-proxgrad.prob)^2)
mean(abs(y.test-proxgrad.class))



</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
