<!DOCTYPE html><html lang="en"><head><title>Help for package bigrquery</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {bigrquery}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#bigrquery-package'><p>bigrquery: An Interface to Google's 'BigQuery' 'API'</p></a></li>
<li><a href='#api-dataset'><p>BigQuery datasets</p></a></li>
<li><a href='#api-job'><p>BigQuery job: retrieve metadata</p></a></li>
<li><a href='#api-perform'><p>BigQuery jobs: perform a job</p></a></li>
<li><a href='#api-project'><p>BigQuery project methods</p></a></li>
<li><a href='#api-table'><p>BigQuery tables</p></a></li>
<li><a href='#bigquery'><p>BigQuery DBI driver</p></a></li>
<li><a href='#bq_auth'><p>Authorize bigrquery</p></a></li>
<li><a href='#bq_auth_configure'><p>Edit and view auth configuration</p></a></li>
<li><a href='#bq_deauth'><p>Clear current token</p></a></li>
<li><a href='#bq_field'><p>BigQuery field (and fields) class</p></a></li>
<li><a href='#bq_has_token'><p>Is there a token on hand?</p></a></li>
<li><a href='#bq_oauth_app'><p>Get currently configured OAuth app (deprecated)</p></a></li>
<li><a href='#bq_param'><p>Explicitly define query parameters</p></a></li>
<li><a href='#bq_projects'><p>List available projects</p></a></li>
<li><a href='#bq_query'><p>Submit query to BigQuery</p></a></li>
<li><a href='#bq_refs'><p>S3 classes for BigQuery datasets, tables and jobs</p></a></li>
<li><a href='#bq_table_download'><p>Download table data</p></a></li>
<li><a href='#bq_test_project'><p>Project to use for testing bigrquery</p></a></li>
<li><a href='#bq_token'><p>Produce configured token</p></a></li>
<li><a href='#bq_user'><p>Get info on current user</p></a></li>
<li><a href='#DBI'><p>DBI methods</p></a></li>
<li><a href='#src_bigquery'><p>A BigQuery data source for dplyr.</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Title:</td>
<td>An Interface to Google's 'BigQuery' 'API'</td>
</tr>
<tr>
<td>Version:</td>
<td>1.5.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Easily talk to Google's 'BigQuery' database from R.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://bigrquery.r-dbi.org">https://bigrquery.r-dbi.org</a>, <a href="https://github.com/r-dbi/bigrquery">https://github.com/r-dbi/bigrquery</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/r-dbi/bigrquery/issues">https://github.com/r-dbi/bigrquery/issues</a></td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.6)</td>
</tr>
<tr>
<td>Imports:</td>
<td>bit64, brio, cli, clock, curl, DBI, gargle (&ge; 1.5.0), httr,
jsonlite, lifecycle, methods, prettyunits, rlang (&ge; 1.1.0),
tibble</td>
</tr>
<tr>
<td>Suggests:</td>
<td>blob, covr, dbplyr (&ge; 2.4.0), dplyr (&ge; 1.1.0), hms, readr,
sodium, testthat (&ge; 3.1.5), wk (&ge; 0.3.2), withr</td>
</tr>
<tr>
<td>LinkingTo:</td>
<td>cli, cpp11, rapidjsonr</td>
</tr>
<tr>
<td>Config/Needs/website:</td>
<td>tidyverse/tidytemplate</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>Config/testthat/parallel:</td>
<td>TRUE</td>
</tr>
<tr>
<td>Config/testthat/start-first:</td>
<td>bq-table, dplyr</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Collate:</td>
<td>'bigrquery-package.R' 'bq-auth.R' 'bq-dataset.R'
'bq-download.R' 'bq-field.R' 'bq-job.R' 'bq-param.R'
'bq-parse.R' 'bq-perform.R' 'bq-project.R' 'bq-projects.R'
'bq-query.R' 'bq-refs.R' 'bq-request.R' 'bq-table.R'
'bq-test.R' 'camelCase.R' 'connections-page.R' 'cpp11.R'
'dbi-driver.R' 'dbi-connection.R' 'dbi-result.R' 'dplyr.R'
'gs-object.R' 'import-standalone-obj-type.R'
'import-standalone-s3-register.R'
'import-standalone-types-check.R' 'utils.R' 'zzz.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-03-14 16:42:02 UTC; hadleywickham</td>
</tr>
<tr>
<td>Author:</td>
<td>Hadley Wickham <a href="https://orcid.org/0000-0003-4757-117X"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut, cre],
  Jennifer Bryan <a href="https://orcid.org/0000-0002-6983-2759"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut],
  Posit Software, PBC [cph, fnd]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hadley Wickham &lt;hadley@posit.co&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-03-14 17:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='bigrquery-package'>bigrquery: An Interface to Google's 'BigQuery' 'API'</h2><span id='topic+bigrquery'></span><span id='topic+bigrquery-package'></span>

<h3>Description</h3>

<p>Easily talk to Google's 'BigQuery' database from R.
</p>


<h3>Package options</h3>


<dl>
<dt><code>bigrquery.quiet</code></dt><dd><p>Verbose output during processing? The default
value, <code>NA</code>, turns on verbose output for queries that run longer than
two seconds.  Use <code>FALSE</code> for immediate verbose output, <code>TRUE</code>
for quiet operation.</p>
</dd>
<dt><code>bigrquery.page.size</code></dt><dd><p>Default page size for fetching data,
defaults to 1e4.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Hadley Wickham <a href="mailto:hadley@posit.co">hadley@posit.co</a> (<a href="https://orcid.org/0000-0003-4757-117X">ORCID</a>)
</p>
<p>Authors:
</p>

<ul>
<li><p> Jennifer Bryan <a href="mailto:jenny@posit.co">jenny@posit.co</a> (<a href="https://orcid.org/0000-0002-6983-2759">ORCID</a>)
</p>
</li></ul>

<p>Other contributors:
</p>

<ul>
<li><p> Posit Software, PBC [copyright holder, funder]
</p>
</li></ul>



<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://bigrquery.r-dbi.org">https://bigrquery.r-dbi.org</a>
</p>
</li>
<li> <p><a href="https://github.com/r-dbi/bigrquery">https://github.com/r-dbi/bigrquery</a>
</p>
</li>
<li><p> Report bugs at <a href="https://github.com/r-dbi/bigrquery/issues">https://github.com/r-dbi/bigrquery/issues</a>
</p>
</li></ul>


<hr>
<h2 id='api-dataset'>BigQuery datasets</h2><span id='topic+api-dataset'></span><span id='topic+bq_dataset_create'></span><span id='topic+bq_dataset_meta'></span><span id='topic+bq_dataset_exists'></span><span id='topic+bq_dataset_update'></span><span id='topic+bq_dataset_delete'></span><span id='topic+bq_dataset_tables'></span>

<h3>Description</h3>

<p>Basic create-read-update-delete verbs for datasets.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_dataset_create(x, location = "US", ...)

bq_dataset_meta(x, fields = NULL)

bq_dataset_exists(x)

bq_dataset_update(x, ...)

bq_dataset_delete(x, delete_contents = FALSE)

bq_dataset_tables(x, page_size = 50, max_pages = Inf, warn = TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="api-dataset_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bq_dataset">bq_dataset</a></p>
</td></tr>
<tr><td><code id="api-dataset_+3A_location">location</code></td>
<td>
<p>Dataset location</p>
</td></tr>
<tr><td><code id="api-dataset_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the underlying API call.
snake_case names are automatically converted to camelCase.</p>
</td></tr>
<tr><td><code id="api-dataset_+3A_fields">fields</code></td>
<td>
<p>An optional field specification for
<a href="https://cloud.google.com/bigquery/docs/api-performance#partial-response">partial response</a></p>
</td></tr>
<tr><td><code id="api-dataset_+3A_delete_contents">delete_contents</code></td>
<td>
<p>If <code>TRUE</code>, will recursively delete all tables in
the dataset. Set to <code>FALSE</code> by default for safety.</p>
</td></tr>
<tr><td><code id="api-dataset_+3A_page_size">page_size</code></td>
<td>
<p>Number of items per page.</p>
</td></tr>
<tr><td><code id="api-dataset_+3A_max_pages">max_pages</code></td>
<td>
<p>Maximum number of pages to retrieve. Use <code>Inf</code> to retrieve
all pages (this may take a long time!)</p>
</td></tr>
<tr><td><code id="api-dataset_+3A_warn">warn</code></td>
<td>
<p>If <code>TRUE</code>, warn when there are unretrieved pages.</p>
</td></tr>
</table>


<h3>Google BigQuery API documentation</h3>


<ul>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/get">get</a>
</p>
</li>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/insert">insert</a>
</p>
</li>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/delete">delete</a>
</p>
</li>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/list">list</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
ds &lt;- bq_dataset(bq_test_project(), "dataset_api")
bq_dataset_exists(ds)

bq_dataset_create(ds)
bq_dataset_exists(ds)
str(bq_dataset_meta(ds))

bq_dataset_delete(ds)
bq_dataset_exists(ds)

# Use bq_test_dataset() to create a temporary dataset that will
# be automatically deleted
ds &lt;- bq_test_dataset()
bq_table_create(bq_table(ds, "x1"))
bq_table_create(bq_table(ds, "x2"))
bq_table_create(bq_table(ds, "x3"))
bq_dataset_tables(ds)

</code></pre>

<hr>
<h2 id='api-job'>BigQuery job: retrieve metadata</h2><span id='topic+api-job'></span><span id='topic+bq_job_meta'></span><span id='topic+bq_job_status'></span><span id='topic+bq_job_show_statistics'></span><span id='topic+bq_job_wait'></span>

<h3>Description</h3>

<p>To perform a job, see <a href="#topic+api-perform">api-perform</a>. These functions all retrieve metadata
(in various forms) about an existing job.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_job_meta(x, fields = NULL)

bq_job_status(x)

bq_job_show_statistics(x)

bq_job_wait(
  x,
  quiet = getOption("bigrquery.quiet"),
  pause = 0.5,
  call = caller_env()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="api-job_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bq_job">bq_job</a></p>
</td></tr>
<tr><td><code id="api-job_+3A_fields">fields</code></td>
<td>
<p>An optional field specification for
<a href="https://cloud.google.com/bigquery/docs/api-performance#partial-response">partial response</a></p>
</td></tr>
<tr><td><code id="api-job_+3A_quiet">quiet</code></td>
<td>
<p>If <code>FALSE</code>, displays progress bar; if <code>TRUE</code> is silent;
if <code>NA</code> picks based on whether or not you're in an interactive context.</p>
</td></tr>
<tr><td><code id="api-job_+3A_pause">pause</code></td>
<td>
<p>amount of time to wait between status requests</p>
</td></tr>
<tr><td><code id="api-job_+3A_call">call</code></td>
<td>
<p>The execution environment of a currently
running function, e.g. <code>caller_env()</code>. The function will be
mentioned in error messages as the source of the error. See the
<code>call</code> argument of <code><a href="rlang.html#topic+abort">abort()</a></code> for more information.</p>
</td></tr>
</table>


<h3>Google BigQuery API documentation</h3>


<ul>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/get">get</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
jobs &lt;- bq_project_jobs(bq_test_project())
jobs[[1]]

# Show statistics about job
bq_job_show_statistics(jobs[[1]])

# Wait for job to complete
bq_job_wait(jobs[[1]])

</code></pre>

<hr>
<h2 id='api-perform'>BigQuery jobs: perform a job</h2><span id='topic+api-perform'></span><span id='topic+bq_perform_extract'></span><span id='topic+bq_perform_upload'></span><span id='topic+bq_perform_load'></span><span id='topic+bq_perform_query'></span><span id='topic+bq_perform_query_dry_run'></span><span id='topic+bq_perform_copy'></span>

<h3>Description</h3>

<p>These functions are low-level functions designed to be used by experts.
Each of these low-level functions is paired with a high-level function that
you should use instead:
</p>

<ul>
<li> <p><code>bq_perform_copy()</code>:    <code><a href="#topic+bq_table_copy">bq_table_copy()</a></code>.
</p>
</li>
<li> <p><code>bq_perform_query()</code>:   <code><a href="#topic+bq_dataset_query">bq_dataset_query()</a></code>, <code><a href="#topic+bq_project_query">bq_project_query()</a></code>.
</p>
</li>
<li> <p><code>bq_perform_upload()</code>:  <code><a href="#topic+bq_table_upload">bq_table_upload()</a></code>.
</p>
</li>
<li> <p><code>bq_perform_load()</code>:    <code><a href="#topic+bq_table_load">bq_table_load()</a></code>.
</p>
</li>
<li> <p><code>bq_perform_extract()</code>: <code><a href="#topic+bq_table_save">bq_table_save()</a></code>.
</p>
</li></ul>



<h3>Usage</h3>

<pre><code class='language-R'>bq_perform_extract(
  x,
  destination_uris,
  destination_format = "NEWLINE_DELIMITED_JSON",
  compression = "NONE",
  ...,
  print_header = TRUE,
  billing = x$project
)

bq_perform_upload(
  x,
  values,
  fields = NULL,
  create_disposition = "CREATE_IF_NEEDED",
  write_disposition = "WRITE_EMPTY",
  ...,
  billing = x$project
)

bq_perform_load(
  x,
  source_uris,
  billing = x$project,
  source_format = "NEWLINE_DELIMITED_JSON",
  fields = NULL,
  nskip = 0,
  create_disposition = "CREATE_IF_NEEDED",
  write_disposition = "WRITE_EMPTY",
  ...
)

bq_perform_query(
  query,
  billing,
  ...,
  parameters = NULL,
  destination_table = NULL,
  default_dataset = NULL,
  create_disposition = "CREATE_IF_NEEDED",
  write_disposition = "WRITE_EMPTY",
  use_legacy_sql = FALSE,
  priority = "INTERACTIVE"
)

bq_perform_query_dry_run(
  query,
  billing,
  ...,
  default_dataset = NULL,
  parameters = NULL,
  use_legacy_sql = FALSE
)

bq_perform_copy(
  src,
  dest,
  create_disposition = "CREATE_IF_NEEDED",
  write_disposition = "WRITE_EMPTY",
  ...,
  billing = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="api-perform_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bq_table">bq_table</a></p>
</td></tr>
<tr><td><code id="api-perform_+3A_destination_uris">destination_uris</code></td>
<td>
<p>A character vector of fully-qualified Google Cloud
Storage URIs where the extracted table should be written. Can export
up to 1 Gb of data per file. Use a wild card URI (e.g.
<code style="white-space: pre;">&#8288;gs://[YOUR_BUCKET]/file-name-*.json&#8288;</code>) to automatically create any
number of files.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_destination_format">destination_format</code></td>
<td>
<p>The exported file format. Possible values
include &quot;CSV&quot;, &quot;NEWLINE_DELIMITED_JSON&quot; and &quot;AVRO&quot;. Tables with nested or
repeated fields cannot be exported as CSV.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_compression">compression</code></td>
<td>
<p>The compression type to use for exported files. Possible
values include &quot;GZIP&quot;, &quot;DEFLATE&quot;, &quot;SNAPPY&quot;, and &quot;NONE&quot;. &quot;DEFLATE&quot; and
&quot;SNAPPY&quot; are only supported for Avro.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the underlying API call.
snake_case names are automatically converted to camelCase.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_print_header">print_header</code></td>
<td>
<p>Whether to print out a header row in the results.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_billing">billing</code></td>
<td>
<p>Identifier of project to bill.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_values">values</code></td>
<td>
<p>Data frame of values to insert.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_fields">fields</code></td>
<td>
<p>A <a href="#topic+bq_fields">bq_fields</a> specification, or something coercible to it
(like a data frame). Leave as <code>NULL</code> to allow BigQuery to auto-detect
the fields.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_create_disposition">create_disposition</code></td>
<td>
<p>Specifies whether the job is allowed to create
new tables.
</p>
<p>The following values are supported:
</p>

<ul>
<li><p> &quot;CREATE_IF_NEEDED&quot;: If the table does not exist, BigQuery creates the
table.
</p>
</li>
<li><p> &quot;CREATE_NEVER&quot;: The table must already exist. If it does not, a
'notFound' error is returned in the job result.
</p>
</li></ul>
</td></tr>
<tr><td><code id="api-perform_+3A_write_disposition">write_disposition</code></td>
<td>
<p>Specifies the action that occurs if the
destination table already exists. The following values are supported:
</p>

<ul>
<li><p> &quot;WRITE_TRUNCATE&quot;: If the table already exists, BigQuery overwrites the
table data.
</p>
</li>
<li><p> &quot;WRITE_APPEND&quot;: If the table already exists, BigQuery appends the data
to the table.
</p>
</li>
<li><p> &quot;WRITE_EMPTY&quot;: If the table already exists and contains data, a
'duplicate' error is returned in the job result.
</p>
</li></ul>
</td></tr>
<tr><td><code id="api-perform_+3A_source_uris">source_uris</code></td>
<td>
<p>The fully-qualified URIs that point to your data in
Google Cloud.
</p>
<p>For Google Cloud Storage URIs: Each URI can contain one
''*'&ldquo; wildcard character and it must come after the 'bucket' name.
Size limits related to load jobs apply to external data sources.
</p>
<p>For Google Cloud Bigtable URIs: Exactly one URI can be specified and
it has be a fully specified and valid HTTPS URL for a Google Cloud
Bigtable table. For Google Cloud Datastore backups: Exactly one URI
can be specified. Also, the '*' wildcard character is not allowed.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_source_format">source_format</code></td>
<td>
<p>The format of the data files:
</p>

<ul>
<li><p> For CSV files, specify &quot;CSV&quot;.
</p>
</li>
<li><p> For datastore backups, specify &quot;DATASTORE_BACKUP&quot;.
</p>
</li>
<li><p> For newline-delimited JSON, specify &quot;NEWLINE_DELIMITED_JSON&quot;.
</p>
</li>
<li><p> For Avro, specify &quot;AVRO&quot;.
</p>
</li>
<li><p> For parquet, specify &quot;PARQUET&quot;.
</p>
</li>
<li><p> For orc, specify &quot;ORC&quot;.
</p>
</li></ul>
</td></tr>
<tr><td><code id="api-perform_+3A_nskip">nskip</code></td>
<td>
<p>For <code>source_format = "CSV"</code>, the number of header rows to skip.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_query">query</code></td>
<td>
<p>SQL query string.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_parameters">parameters</code></td>
<td>
<p>Named list of parameters match to query parameters.
Parameter <code>x</code> will be matched to placeholder <code style="white-space: pre;">&#8288;@x&#8288;</code>.
</p>
<p>Generally, you can supply R vectors and they will be automatically
converted to the correct type. If you need greater control, you can call
<code><a href="#topic+bq_param_scalar">bq_param_scalar()</a></code> or <code><a href="#topic+bq_param_array">bq_param_array()</a></code> explicitly.
</p>
<p>See <a href="https://cloud.google.com/bigquery/docs/parameterized-queries">https://cloud.google.com/bigquery/docs/parameterized-queries</a>
for more details.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_destination_table">destination_table</code></td>
<td>
<p>A <a href="#topic+bq_table">bq_table</a> where results should be stored.
If not supplied, results will be saved to a temporary table that lives
in a special dataset. You must supply this parameter for large
queries (&gt; 128 MB compressed).</p>
</td></tr>
<tr><td><code id="api-perform_+3A_default_dataset">default_dataset</code></td>
<td>
<p>A <a href="#topic+bq_dataset">bq_dataset</a> used to automatically qualify table names.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_use_legacy_sql">use_legacy_sql</code></td>
<td>
<p>If <code>TRUE</code> will use BigQuery's legacy SQL format.</p>
</td></tr>
<tr><td><code id="api-perform_+3A_priority">priority</code></td>
<td>
<p>Specifies a priority for the query. Possible values include
&quot;INTERACTIVE&quot; and &quot;BATCH&quot;. Batch queries do not start immediately,
but are not rate-limited in the same way as interactive queries.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="#topic+bq_job">bq_job</a>.
</p>


<h3>Google BigQuery API documentation</h3>


<ul>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs">jobs</a>
</p>
</li></ul>

<p>Additional information at:
</p>

<ul>
<li> <p><a href="https://cloud.google.com/bigquery/docs/exporting-data">exporting data</a>
</p>
</li>
<li> <p><a href="https://cloud.google.com/bigquery/docs/loading-data">loading data</a>
</p>
</li>
<li> <p><a href="https://cloud.google.com/bigquery/docs/writing-results">writing queries</a>
</p>
</li>
<li> <p><a href="https://cloud.google.com/bigquery/docs/managing-tables#copy-table">copying a table</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
ds &lt;- bq_test_dataset()
bq_mtcars &lt;- bq_table(ds, "mtcars")
job &lt;- bq_perform_upload(bq_mtcars, mtcars)
bq_table_exists(bq_mtcars)

bq_job_wait(job)
bq_table_exists(bq_mtcars)
head(bq_table_download(bq_mtcars))

</code></pre>

<hr>
<h2 id='api-project'>BigQuery project methods</h2><span id='topic+api-project'></span><span id='topic+bq_project_datasets'></span><span id='topic+bq_project_jobs'></span>

<h3>Description</h3>

<p>Projects have two primary components: datasets and jobs. Unlike other
BigQuery objects, is no accompanying <code>bq_project</code> S3 class because a project
is a simple string.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_project_datasets(x, page_size = 100, max_pages = 1, warn = TRUE)

bq_project_jobs(x, page_size = 100, max_pages = 1, warn = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="api-project_+3A_x">x</code></td>
<td>
<p>A string giving a project name.</p>
</td></tr>
<tr><td><code id="api-project_+3A_page_size">page_size</code></td>
<td>
<p>Number of items per page.</p>
</td></tr>
<tr><td><code id="api-project_+3A_max_pages">max_pages</code></td>
<td>
<p>Maximum number of pages to retrieve. Use <code>Inf</code> to retrieve
all pages (this may take a long time!)</p>
</td></tr>
<tr><td><code id="api-project_+3A_warn">warn</code></td>
<td>
<p>If <code>TRUE</code>, warn when there are unretrieved pages.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>bq_project_datasets()</code>: a list of <a href="#topic+bq_dataset">bq_dataset</a>s
</p>
</li>
<li> <p><code>bq_project_jobs()</code>: a list of <a href="#topic+bq_job">bq_job</a>s.
</p>
</li></ul>



<h3>Google BigQuery API documentation</h3>


<ul>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/datasets/list">datasets</a>
</p>
</li>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/list">jobs</a>
</p>
</li></ul>

<p>One day we might also expose the general <a href="https://cloud.google.com/resource-manager/reference/rest/v1/projects">project metadata</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
bq_project_datasets("bigquery-public-data")
bq_project_datasets("githubarchive")

bq_project_jobs(bq_test_project(), page_size = 10)

</code></pre>

<hr>
<h2 id='api-table'>BigQuery tables</h2><span id='topic+api-table'></span><span id='topic+bq_table_create'></span><span id='topic+bq_table_meta'></span><span id='topic+bq_table_fields'></span><span id='topic+bq_table_size'></span><span id='topic+bq_table_nrow'></span><span id='topic+bq_table_exists'></span><span id='topic+bq_table_delete'></span><span id='topic+bq_table_copy'></span><span id='topic+bq_table_upload'></span><span id='topic+bq_table_save'></span><span id='topic+bq_table_load'></span><span id='topic+bq_table_patch'></span>

<h3>Description</h3>

<p>Basic create-read-update-delete verbs for tables, as well as functions
uploading data (<code>bq_table_upload()</code>), saving to/loading from Google
Cloud Storage (<code>bq_table_load()</code>, <code>bq_table_save()</code>), and getting
various values from the metadata.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_table_create(x, fields = NULL, ...)

bq_table_meta(x, fields = NULL)

bq_table_fields(x)

bq_table_size(x)

bq_table_nrow(x)

bq_table_exists(x)

bq_table_delete(x)

bq_table_copy(x, dest, ..., quiet = NA)

bq_table_upload(x, values, ..., quiet = NA)

bq_table_save(x, destination_uris, ..., quiet = NA)

bq_table_load(x, source_uris, ..., quiet = NA)

bq_table_patch(x, fields)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="api-table_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bq_table">bq_table</a>, or an object coercible to a <code>bq_table</code>.</p>
</td></tr>
<tr><td><code id="api-table_+3A_fields">fields</code></td>
<td>
<p>A <a href="#topic+bq_fields">bq_fields</a> specification, or something coercible to it
(like a data frame).</p>
</td></tr>
<tr><td><code id="api-table_+3A_...">...</code></td>
<td>
<p>Additional arguments passed on to the underlying API call.
snake_case names are automatically converted to camelCase.</p>
</td></tr>
<tr><td><code id="api-table_+3A_dest">dest</code></td>
<td>
<p>Source and destination <a href="#topic+bq_table">bq_table</a>s.</p>
</td></tr>
<tr><td><code id="api-table_+3A_quiet">quiet</code></td>
<td>
<p>If <code>FALSE</code>, displays progress bar; if <code>TRUE</code> is silent;
if <code>NA</code> picks based on whether or not you're in an interactive context.</p>
</td></tr>
<tr><td><code id="api-table_+3A_values">values</code></td>
<td>
<p>Data frame of values to insert.</p>
</td></tr>
<tr><td><code id="api-table_+3A_destination_uris">destination_uris</code></td>
<td>
<p>A character vector of fully-qualified Google Cloud
Storage URIs where the extracted table should be written. Can export
up to 1 Gb of data per file. Use a wild card URI (e.g.
<code style="white-space: pre;">&#8288;gs://[YOUR_BUCKET]/file-name-*.json&#8288;</code>) to automatically create any
number of files.</p>
</td></tr>
<tr><td><code id="api-table_+3A_source_uris">source_uris</code></td>
<td>
<p>The fully-qualified URIs that point to your data in
Google Cloud.
</p>
<p>For Google Cloud Storage URIs: Each URI can contain one
''*'&ldquo; wildcard character and it must come after the 'bucket' name.
Size limits related to load jobs apply to external data sources.
</p>
<p>For Google Cloud Bigtable URIs: Exactly one URI can be specified and
it has be a fully specified and valid HTTPS URL for a Google Cloud
Bigtable table. For Google Cloud Datastore backups: Exactly one URI
can be specified. Also, the '*' wildcard character is not allowed.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>bq_table_copy()</code>, <code>bq_table_create()</code>, <code>bq_table_delete()</code>, <code>bq_table_upload()</code>:
an invisible <a href="#topic+bq_table">bq_table</a>
</p>
</li>
<li> <p><code>bq_table_exists()</code>: either <code>TRUE</code> or <code>FALSE</code>.
</p>
</li>
<li> <p><code>bq_table_size()</code>: the size of the table in bytes
</p>
</li>
<li> <p><code>bq_table_fields()</code>: a <a href="#topic+bq_fields">bq_fields</a>.
</p>
</li></ul>



<h3>Google BigQuery API documentation</h3>


<ul>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/insert">insert</a>
</p>
</li>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/get">get</a>
</p>
</li>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/tables/delete">delete</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
ds &lt;- bq_test_dataset()

bq_mtcars &lt;- bq_table(ds, "mtcars")
bq_table_exists(bq_mtcars)

bq_table_create(
  bq_mtcars,
  fields = mtcars,
  friendly_name = "Motor Trend Car Road Tests",
  description = "The data was extracted from the 1974 Motor Trend US magazine",
  labels = list(category = "example")
)
bq_table_exists(bq_mtcars)

bq_table_upload(bq_mtcars, mtcars)

bq_table_fields(bq_mtcars)
bq_table_size(bq_mtcars)
str(bq_table_meta(bq_mtcars))

bq_table_delete(bq_mtcars)
bq_table_exists(bq_mtcars)

my_natality &lt;- bq_table(ds, "mynatality")
bq_table_copy("publicdata.samples.natality", my_natality)

</code></pre>

<hr>
<h2 id='bigquery'>BigQuery DBI driver</h2><span id='topic+bigquery'></span><span id='topic+dbi_driver'></span><span id='topic+dbConnect+2CBigQueryDriver-method'></span>

<h3>Description</h3>

<p>Creates a BigQuery DBI driver for use in <code><a href="DBI.html#topic+dbConnect">DBI::dbConnect()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'BigQueryDriver'
dbConnect(
  drv,
  project,
  dataset = NULL,
  billing = project,
  page_size = 10000,
  quiet = NA,
  use_legacy_sql = FALSE,
  bigint = c("integer", "integer64", "numeric", "character"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bigquery_+3A_drv">drv</code></td>
<td>
<p>an object that inherits from <a href="DBI.html#topic+DBIDriver-class">DBIDriver</a>,
or an existing <a href="DBI.html#topic+DBIConnection-class">DBIConnection</a>
object (in order to clone an existing connection).</p>
</td></tr>
<tr><td><code id="bigquery_+3A_project">project</code>, <code id="bigquery_+3A_dataset">dataset</code></td>
<td>
<p>Project and dataset identifiers</p>
</td></tr>
<tr><td><code id="bigquery_+3A_billing">billing</code></td>
<td>
<p>Identifier of project to bill.</p>
</td></tr>
<tr><td><code id="bigquery_+3A_page_size">page_size</code></td>
<td>
<p>Number of items per page.</p>
</td></tr>
<tr><td><code id="bigquery_+3A_quiet">quiet</code></td>
<td>
<p>If <code>FALSE</code>, displays progress bar; if <code>TRUE</code> is silent;
if <code>NA</code> picks based on whether or not you're in an interactive context.</p>
</td></tr>
<tr><td><code id="bigquery_+3A_use_legacy_sql">use_legacy_sql</code></td>
<td>
<p>If <code>TRUE</code> will use BigQuery's legacy SQL format.</p>
</td></tr>
<tr><td><code id="bigquery_+3A_bigint">bigint</code></td>
<td>
<p>The R type that BigQuery's 64-bit integer types should be mapped to.
The default is <code>"integer"</code> which returns R's <code>integer</code> type but results in <code>NA</code> for
values above/below +/- 2147483647. <code>"integer64"</code> returns a <a href="bit64.html#topic+bit64-package">bit64::integer64</a>,
which allows the full range of 64 bit integers.</p>
</td></tr>
<tr><td><code id="bigquery_+3A_...">...</code></td>
<td>
<p>Other arguments for compatibility with generic; currently ignored.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>
con &lt;- DBI::dbConnect(
  bigquery(),
  project = "publicdata",
  dataset = "samples",
  billing = bq_test_project()
)
con
DBI::dbListTables(con)
DBI::dbReadTable(con, "natality", n_max = 10)

# Create a temporary dataset to explore
ds &lt;- bq_test_dataset()
con &lt;- DBI::dbConnect(
  bigquery(),
  project = ds$project,
  dataset = ds$dataset
)
DBI::dbWriteTable(con, "mtcars", mtcars)
DBI::dbReadTable(con, "mtcars")[1:6, ]

DBI::dbGetQuery(con, "SELECT count(*) FROM mtcars")

res &lt;- DBI::dbSendQuery(con, "SELECT cyl, mpg FROM mtcars")
dbColumnInfo(res)
dbFetch(res, 10)
dbFetch(res, -1)
DBI::dbHasCompleted(res)

</code></pre>

<hr>
<h2 id='bq_auth'>Authorize bigrquery</h2><span id='topic+bq_auth'></span>

<h3>Description</h3>

<p>Authorize bigrquery to view and manage your BigQuery projects. This function is a
wrapper around <code><a href="gargle.html#topic+token_fetch">gargle::token_fetch()</a></code>.
</p>
<p>By default, you are directed to a web browser, asked to sign in to your
Google account, and to grant bigrquery permission to operate on your
behalf with Google BigQuery. By default, with your permission, these user
credentials are cached in a folder below your home directory, from where
they can be automatically refreshed, as necessary. Storage at the user
level means the same token can be used across multiple projects and
tokens are less likely to be synced to the cloud by accident.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_auth(
  email = gargle::gargle_oauth_email(),
  path = NULL,
  scopes = c("https://www.googleapis.com/auth/bigquery",
    "https://www.googleapis.com/auth/cloud-platform"),
  cache = gargle::gargle_oauth_cache(),
  use_oob = gargle::gargle_oob_default(),
  token = NULL
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bq_auth_+3A_email">email</code></td>
<td>
<p>Optional. If specified, <code>email</code> can take several different
forms:
</p>

<ul>
<li> <p><code>"jane@gmail.com"</code>, i.e. an actual email address. This allows the user to
target a specific Google identity. If specified, this is used for token
lookup, i.e. to determine if a suitable token is already available in the
cache. If no such token is found, <code>email</code> is used to pre-select the targeted
Google identity in the OAuth chooser. (Note, however, that the email
associated with a token when it's cached is always determined from the token
itself, never from this argument).
</p>
</li>
<li> <p><code>"*@example.com"</code>, i.e. a domain-only glob pattern. This can be helpful if
you need code that &quot;just works&quot; for both <code>alice@example.com</code> and
<code>bob@example.com</code>.
</p>
</li>
<li> <p><code>TRUE</code> means that you are approving email auto-discovery. If exactly one
matching token is found in the cache, it will be used.
</p>
</li>
<li> <p><code>FALSE</code> or <code>NA</code> mean that you want to ignore the token cache and force a
new OAuth dance in the browser.
</p>
</li></ul>

<p>Defaults to the option named <code>"gargle_oauth_email"</code>, retrieved by
<code><a href="gargle.html#topic+gargle_oauth_email">gargle_oauth_email()</a></code> (unless a wrapper package implements different
default behavior).</p>
</td></tr>
<tr><td><code id="bq_auth_+3A_path">path</code></td>
<td>
<p>JSON identifying the service account, in one of the forms
supported for the <code>txt</code> argument of <code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> (typically, a
file path or JSON string).</p>
</td></tr>
<tr><td><code id="bq_auth_+3A_scopes">scopes</code></td>
<td>
<p>A character vector of scopes to request.
Pick from those listed at <a href="https://developers.google.com/identity/protocols/oauth2/scopes">https://developers.google.com/identity/protocols/oauth2/scopes</a>.</p>
</td></tr>
<tr><td><code id="bq_auth_+3A_cache">cache</code></td>
<td>
<p>Specifies the OAuth token cache. Defaults to the option named
<code>"gargle_oauth_cache"</code>, retrieved via <code><a href="gargle.html#topic+gargle_oauth_cache">gargle_oauth_cache()</a></code>.</p>
</td></tr>
<tr><td><code id="bq_auth_+3A_use_oob">use_oob</code></td>
<td>
<p>Whether to use out-of-band authentication (or, perhaps, a
variant implemented by gargle and known as &quot;pseudo-OOB&quot;) when first
acquiring the token. Defaults to the value returned by
<code><a href="gargle.html#topic+gargle_oob_default">gargle_oob_default()</a></code>. Note that (pseudo-)OOB auth only affects
the initial OAuth dance. If we retrieve (and possibly refresh) a
cached token, <code>use_oob</code> has no effect.
</p>
<p>If the OAuth client is provided implicitly by a wrapper package, its type
probably defaults to the value returned by
<code><a href="gargle.html#topic+gargle_oauth_client_type">gargle_oauth_client_type()</a></code>. You can take control of the client
type by setting <code>options(gargle_oauth_client_type = "web")</code> or
<code>options(gargle_oauth_client_type = "installed")</code>.</p>
</td></tr>
<tr><td><code id="bq_auth_+3A_token">token</code></td>
<td>
<p>A token with class <a href="httr.html#topic+Token-class">Token2.0</a> or an object of
httr's class <code>request</code>, i.e. a token that has been prepared with
<code><a href="httr.html#topic+config">httr::config()</a></code> and has a <a href="httr.html#topic+Token-class">Token2.0</a> in the
<code>auth_token</code> component.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Most users, most of the time, do not need to call <code>bq_auth()</code>
explicitly &ndash; it is triggered by the first action that requires
authorization. Even when called, the default arguments often suffice.
</p>
<p>However, when necessary, <code>bq_auth()</code> allows the user to explicitly:
</p>

<ul>
<li><p> Declare which Google identity to use, via an <code>email</code> specification.
</p>
</li>
<li><p> Use a service account token or workload identity federation via
<code>path</code>.
</p>
</li>
<li><p> Bring your own <code>token</code>.
</p>
</li>
<li><p> Customize <code>scopes</code>.
</p>
</li>
<li><p> Use a non-default <code>cache</code> folder or turn caching off.
</p>
</li>
<li><p> Explicitly request out-of-band (OOB) auth via <code>use_oob</code>.
</p>
</li></ul>

<p>If you are interacting with R within a browser (applies to RStudio
Server, Posit Workbench, Posit Cloud, and Google Colaboratory), you need
OOB auth or the pseudo-OOB variant. If this does not happen
automatically, you can request it explicitly with <code>use_oob = TRUE</code> or,
more persistently, by setting an option via
<code>options(gargle_oob_default = TRUE)</code>.
</p>
<p>The choice between conventional OOB or pseudo-OOB auth is determined
by the type of OAuth client. If the client is of the &quot;installed&quot; type,
<code>use_oob = TRUE</code> results in conventional OOB auth. If the client is of
the &quot;web&quot; type, <code>use_oob = TRUE</code> results in pseudo-OOB auth. Packages
that provide a built-in OAuth client can usually detect which type of
client to use. But if you need to set this explicitly, use the
<code>"gargle_oauth_client_type"</code> option:
</p>
<div class="sourceCode r"><pre>options(gargle_oauth_client_type = "web")       # pseudo-OOB
# or, alternatively
options(gargle_oauth_client_type = "installed") # conventional OOB
</pre></div>
<p>For details on the many ways to find a token, see
<code><a href="gargle.html#topic+token_fetch">gargle::token_fetch()</a></code>. For deeper control over auth, use
<code><a href="#topic+bq_auth_configure">bq_auth_configure()</a></code> to bring your own OAuth client or API key.
To learn more about gargle options, see <a href="gargle.html#topic+gargle_options">gargle::gargle_options</a>.
</p>


<h3>See Also</h3>

<p>Other auth functions: 
<code><a href="#topic+bq_auth_configure">bq_auth_configure</a>()</code>,
<code><a href="#topic+bq_deauth">bq_deauth</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
## load/refresh existing credentials, if available
## otherwise, go to browser for authentication and authorization
bq_auth()

## force use of a token associated with a specific email
bq_auth(email = "jenny@example.com")

## force a menu where you can choose from existing tokens or
## choose to get a new one
bq_auth(email = NA)

## use a 'read only' scope, so it's impossible to change data
bq_auth(
  scopes = "https://www.googleapis.com/auth/devstorage.read_only"
)

## use a service account token
bq_auth(path = "foofy-83ee9e7c9c48.json")

## End(Not run)

</code></pre>

<hr>
<h2 id='bq_auth_configure'>Edit and view auth configuration</h2><span id='topic+bq_auth_configure'></span><span id='topic+bq_oauth_client'></span>

<h3>Description</h3>

<p>These functions give more control over and visibility into the auth
configuration than <code><a href="#topic+bq_auth">bq_auth()</a></code> does. <code>bq_auth_configure()</code>
lets the user specify their own:
</p>

<ul>
<li><p> OAuth client, which is used when obtaining a user token.
</p>
</li></ul>

<p>See the <code>vignette("get-api-credentials", package = "gargle")</code>
for more.
If the user does not configure these settings, internal defaults
are used.
</p>
<p><code>bq_oauth_client()</code> retrieves the currently configured OAuth client.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_auth_configure(client, path, app = deprecated())

bq_oauth_client()
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bq_auth_configure_+3A_client">client</code></td>
<td>
<p>A Google OAuth client, presumably constructed via
<code><a href="gargle.html#topic+gargle_oauth_client_from_json">gargle::gargle_oauth_client_from_json()</a></code>. Note, however, that it is
preferred to specify the client with JSON, using the <code>path</code> argument.</p>
</td></tr>
<tr><td><code id="bq_auth_configure_+3A_path">path</code></td>
<td>
<p>JSON downloaded from <a href="https://console.cloud.google.com">Google Cloud Console</a>, containing a client id and
secret, in one of the forms supported for the <code>txt</code> argument of
<code><a href="jsonlite.html#topic+fromJSON">jsonlite::fromJSON()</a></code> (typically, a file path or JSON string).</p>
</td></tr>
<tr><td><code id="bq_auth_configure_+3A_app">app</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Replaced by the <code>client</code>
argument.</p>
</td></tr>
</table>


<h3>Value</h3>


<ul>
<li> <p><code>bq_auth_configure()</code>: An object of R6 class
<a href="gargle.html#topic+AuthState-class">gargle::AuthState</a>, invisibly.
</p>
</li>
<li> <p><code>bq_oauth_client()</code>: the current user-configured OAuth client.
</p>
</li></ul>



<h3>See Also</h3>

<p>Other auth functions: 
<code><a href="#topic+bq_auth">bq_auth</a>()</code>,
<code><a href="#topic+bq_deauth">bq_deauth</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'># see and store the current user-configured OAuth client (probably `NULL`)
(original_client &lt;- bq_oauth_client())

# the preferred way to configure your own client is via a JSON file
# downloaded from Google Developers Console
# this example JSON is indicative, but fake
path_to_json &lt;- system.file(
  "extdata", "data", "client_secret_123.googleusercontent.com.json",
  package = "bigrquery"
)
bq_auth_configure(path = path_to_json)

# confirm the changes
bq_oauth_client()

# restore original auth config
bq_auth_configure(client = original_client)
</code></pre>

<hr>
<h2 id='bq_deauth'>Clear current token</h2><span id='topic+bq_deauth'></span>

<h3>Description</h3>

<p>Clears any currently stored token. The next time bigrquery needs a token, the
token acquisition process starts over, with a fresh call to <code><a href="#topic+bq_auth">bq_auth()</a></code> and,
therefore, internally, a call to <code><a href="gargle.html#topic+token_fetch">gargle::token_fetch()</a></code>. Unlike some other
packages that use gargle, bigrquery is not usable in a de-authorized state.
Therefore, calling <code>bq_deauth()</code> only clears the token, i.e. it does NOT
imply that subsequent requests are made with an API key in lieu of a token.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_deauth()
</code></pre>


<h3>See Also</h3>

<p>Other auth functions: 
<code><a href="#topic+bq_auth">bq_auth</a>()</code>,
<code><a href="#topic+bq_auth_configure">bq_auth_configure</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
bq_deauth()

## End(Not run)
</code></pre>

<hr>
<h2 id='bq_field'>BigQuery field (and fields) class</h2><span id='topic+bq_field'></span><span id='topic+bq_fields'></span><span id='topic+as_bq_field'></span><span id='topic+as_bq_fields'></span>

<h3>Description</h3>

<p><code>bq_field()</code> and <code>bq_fields()</code> create; <code>as_bq_field()</code> and <code>as_bq_fields()</code>
coerce from lists.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_field(name, type, mode = "NULLABLE", fields = list(), description = NULL)

bq_fields(x)

as_bq_field(x)

as_bq_fields(x)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bq_field_+3A_name">name</code></td>
<td>
<p>The field name. The name must contain only letters (a-z, A-Z),
numbers (0-9), or underscores (_), and must start with a letter or
underscore. The maximum length is 300 characters.</p>
</td></tr>
<tr><td><code id="bq_field_+3A_type">type</code></td>
<td>
<p>The field data type. Possible values include:
<code>"STRING"</code>, <code>"BYTES"</code>, <code>"INTEGER"</code>, <code>"FLOAT"</code>, <code>"BOOLEAN"</code>, <code>"TIMESTAMP"</code>,
<code>"DATE"</code>, <code>"TIME"</code>, <code>"DATETIME"</code>, <code>"GEOGRAPHY"</code>, <code>"NUMERIC"</code>,
<code>"BIGNUMERIC"</code>, <code>"JSON"</code>, <code>"RECORD"</code>.</p>
</td></tr>
<tr><td><code id="bq_field_+3A_mode">mode</code></td>
<td>
<p>The field mode. Possible values include: <code>"NULLABLE"</code>,
<code>"REQUIRED"</code>, and <code>"REPEATED"</code>.</p>
</td></tr>
<tr><td><code id="bq_field_+3A_fields">fields</code></td>
<td>
<p>For a field of type &quot;record&quot;, a list of sub-fields.</p>
</td></tr>
<tr><td><code id="bq_field_+3A_description">description</code></td>
<td>
<p>The field description. The maximum length is 1,024
characters.</p>
</td></tr>
<tr><td><code id="bq_field_+3A_x">x</code></td>
<td>
<p>A list of <code>bg_fields</code></p>
</td></tr>
</table>


<h3>See Also</h3>

<p><code>bq_field()</code> corresponds to a <code>TableFieldSchema</code>, see
<a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#TableFieldSchema">https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#TableFieldSchema</a>
for more details.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bq_field("name", "string")

as_bq_fields(list(
  list(name = "name", type = "string"),
  bq_field("age", "integer")
))

# as_bq_fields() can also take a data frame
as_bq_fields(mtcars)
</code></pre>

<hr>
<h2 id='bq_has_token'>Is there a token on hand?</h2><span id='topic+bq_has_token'></span>

<h3>Description</h3>

<p>Reports whether bigrquery has stored a token, ready for use in downstream
requests.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_has_token()
</code></pre>


<h3>Value</h3>

<p>Logical.
</p>


<h3>See Also</h3>

<p>Other low-level API functions: 
<code><a href="#topic+bq_token">bq_token</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bq_has_token()
</code></pre>

<hr>
<h2 id='bq_oauth_app'>Get currently configured OAuth app (deprecated)</h2><span id='topic+bq_oauth_app'></span>

<h3>Description</h3>

<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a>
</p>
<p>In light of the new <code><a href="gargle.html#topic+gargle_oauth_client_from_json">gargle::gargle_oauth_client()</a></code> constructor and class of
the same name, <code>bq_oauth_app()</code> is being replaced by
<code><a href="#topic+bq_oauth_client">bq_oauth_client()</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_oauth_app()
</code></pre>

<hr>
<h2 id='bq_param'>Explicitly define query parameters</h2><span id='topic+bq_param'></span><span id='topic+bq_param_scalar'></span><span id='topic+bq_param_array'></span>

<h3>Description</h3>

<p>By default, bigrquery will assume vectors of length 1 are scalars,
and longer vectors are arrays. If you need to pass a length-1 array,
you'll need to explicitly use <code>bq_param_array()</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_param(value, type = NULL, name = NULL)

bq_param_scalar(value, type = NULL, name = NULL)

bq_param_array(value, type = NULL, name = NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bq_param_+3A_value">value</code></td>
<td>
<p>vector of parameter values</p>
</td></tr>
<tr><td><code id="bq_param_+3A_type">type</code></td>
<td>
<p>BigQuery type of the parameter</p>
</td></tr>
<tr><td><code id="bq_param_+3A_name">name</code></td>
<td>
<p>name of the parameter in the query, omitting the <code>@</code></p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'># bq_param() automatically picks scalar vs array based on length
bq_param("a")
bq_param(c("a", "b", "c"))

# use bq_param_array() to create a length-1 array
bq_param_array("a")
</code></pre>

<hr>
<h2 id='bq_projects'>List available projects</h2><span id='topic+bq_projects'></span>

<h3>Description</h3>

<p>List all projects that you have access to. You can also work with
<a href="https://cloud.google.com/bigquery/public-data/">public datasets</a>,
but you will need to provide a <code>billing</code> project whenever you perform
any non-free operation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_projects(page_size = 100, max_pages = 1, warn = TRUE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bq_projects_+3A_page_size">page_size</code></td>
<td>
<p>Number of items per page.</p>
</td></tr>
<tr><td><code id="bq_projects_+3A_max_pages">max_pages</code></td>
<td>
<p>Maximum number of pages to retrieve. Use <code>Inf</code> to retrieve
all pages (this may take a long time!)</p>
</td></tr>
<tr><td><code id="bq_projects_+3A_warn">warn</code></td>
<td>
<p>If <code>TRUE</code>, warn when there are unretrieved pages.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A character vector.
</p>


<h3>Google BigQuery API documentation</h3>


<ul>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/projects/list">list</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
bq_projects()

</code></pre>

<hr>
<h2 id='bq_query'>Submit query to BigQuery</h2><span id='topic+bq_query'></span><span id='topic+bq_project_query'></span><span id='topic+bq_dataset_query'></span>

<h3>Description</h3>

<p>These submit a query (using <code><a href="#topic+bq_perform_query">bq_perform_query()</a></code>) and then wait for it
complete (with <code><a href="#topic+bq_job_wait">bq_job_wait()</a></code>). All BigQuery queries save their results
into a table (temporary or otherwise), so these functions return a <a href="#topic+bq_table">bq_table</a>
which you can then query for more information.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_project_query(x, query, destination_table = NULL, ..., quiet = NA)

bq_dataset_query(
  x,
  query,
  destination_table = NULL,
  ...,
  billing = NULL,
  quiet = NA
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bq_query_+3A_x">x</code></td>
<td>
<p>Either a project (a string) or a <a href="#topic+bq_dataset">bq_dataset</a>.</p>
</td></tr>
<tr><td><code id="bq_query_+3A_query">query</code></td>
<td>
<p>SQL query string.</p>
</td></tr>
<tr><td><code id="bq_query_+3A_destination_table">destination_table</code></td>
<td>
<p>A <a href="#topic+bq_table">bq_table</a> where results should be stored.
If not supplied, results will be saved to a temporary table that lives
in a special dataset. You must supply this parameter for large
queries (&gt; 128 MB compressed).</p>
</td></tr>
<tr><td><code id="bq_query_+3A_...">...</code></td>
<td>
<p>Passed on to <code><a href="#topic+bq_perform_query">bq_perform_query()</a></code></p>
</td></tr>
<tr><td><code id="bq_query_+3A_quiet">quiet</code></td>
<td>
<p>If <code>FALSE</code>, displays progress bar; if <code>TRUE</code> is silent;
if <code>NA</code> picks based on whether or not you're in an interactive context.</p>
</td></tr>
<tr><td><code id="bq_query_+3A_billing">billing</code></td>
<td>
<p>If you query a dataset that you only have read access
for, such as a public dataset, you must also submit a <code>billing</code> project.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <a href="#topic+bq_table">bq_table</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
# Querying a project requires full name in query
tb &lt;- bq_project_query(
  bq_test_project(),
  "SELECT count(*) FROM publicdata.samples.natality"
)
bq_table_fields(tb)
bq_table_download(tb)

# Querying a dataset sets default dataset so you can use bare table name,
# but for public data, you'll need to set a project to bill.
ds &lt;- bq_dataset("publicdata", "samples")
tb &lt;- bq_dataset_query(ds,
  query = "SELECT count(*) FROM natality",
  billing = bq_test_project()
)
bq_table_download(tb)

tb &lt;- bq_dataset_query(ds,
  query = "SELECT count(*) FROM natality WHERE state = @state",
  parameters = list(state = "KS"),
  billing = bq_test_project()
)
bq_table_download(tb)

</code></pre>

<hr>
<h2 id='bq_refs'>S3 classes for BigQuery datasets, tables and jobs</h2><span id='topic+bq_dataset'></span><span id='topic+as_bq_dataset'></span><span id='topic+bq_table'></span><span id='topic+as_bq_table'></span><span id='topic+bq_job'></span><span id='topic+as_bq_job'></span>

<h3>Description</h3>

<p>Create references to BigQuery datasets, jobs, and tables. Each class
has a constructor function (<code>bq_dataset()</code>, <code>bq_table()</code>, <code>bq_job()</code>)
and a coercion function (<code>as_bq_dataset()</code>, <code>as_bq_table()</code>, <code>as_bq_job()</code>).
The coercions functions come with methods for strings (which find components
by splitting on <code>.</code>), and lists (which look for named components like
<code>projectId</code> or <code>project_id</code>).
</p>
<p>All <code>bq_table_</code>, <code>bq_dataset_</code> and <code>bq_job_</code> functions call the appropriate
coercion functions on their first argument, allowing you to flexible specify
their inputs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_dataset(project, dataset)

as_bq_dataset(x, ..., error_arg = caller_arg(x), error_call = caller_env())

bq_table(project, dataset, table = NULL, type = "TABLE")

as_bq_table(x, ..., error_arg = caller_arg(x), error_call = caller_env())

bq_job(project, job, location = "US")

as_bq_job(x, ..., error_arg = caller_arg(x), error_call = caller_env())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bq_refs_+3A_project">project</code>, <code id="bq_refs_+3A_dataset">dataset</code>, <code id="bq_refs_+3A_table">table</code>, <code id="bq_refs_+3A_job">job</code>, <code id="bq_refs_+3A_type">type</code></td>
<td>
<p>Individual project, dataset, table,
job identifiers and table type (strings).
</p>
<p>For <code>bq_table()</code>, you if supply a <code>bq_dataset</code> as the first argument,
the 2nd argument will be interpreted as the <code>table</code></p>
</td></tr>
<tr><td><code id="bq_refs_+3A_x">x</code></td>
<td>
<p>An object to coerce to a <code>bq_job</code>, <code>bq_dataset</code>, or <code>bq_table</code>.
Built-in methods handle strings and lists.</p>
</td></tr>
<tr><td><code id="bq_refs_+3A_...">...</code></td>
<td>
<p>Other arguments passed on to methods.</p>
</td></tr>
<tr><td><code id="bq_refs_+3A_error_arg">error_arg</code></td>
<td>
<p>An argument name as a string. This argument
will be mentioned in error messages as the input that is at the
origin of a problem.</p>
</td></tr>
<tr><td><code id="bq_refs_+3A_error_call">error_call</code></td>
<td>
<p>The execution environment of a currently
running function, e.g. <code>caller_env()</code>. The function will be
mentioned in error messages as the source of the error. See the
<code>call</code> argument of <code><a href="rlang.html#topic+abort">abort()</a></code> for more information.</p>
</td></tr>
<tr><td><code id="bq_refs_+3A_location">location</code></td>
<td>
<p>Job location</p>
</td></tr>
</table>


<h3>See Also</h3>

<p><a href="#topic+api-job">api-job</a>, <a href="#topic+api-perform">api-perform</a>, <a href="#topic+api-dataset">api-dataset</a>, and <a href="#topic+api-table">api-table</a> for
functions that work with these objects.
</p>


<h3>Examples</h3>

<pre><code class='language-R'># Creation ------------------------------------------------
samples &lt;- bq_dataset("publicdata", "samples")
natality &lt;- bq_table("publicdata", "samples", "natality")
natality

# Or
bq_table(samples, "natality")

bq_job("bigrquery-examples", "m0SgFu2ycbbge6jgcvzvflBJ_Wft")

# Coercion ------------------------------------------------
as_bq_dataset("publicdata.shakespeare")
as_bq_table("publicdata.samples.natality")

as_bq_table(list(
  project_id = "publicdata",
  dataset_id = "samples",
  table_id = "natality"
))

as_bq_job(list(
  projectId = "bigrquery-examples",
  jobId = "job_m0SgFu2ycbbge6jgcvzvflBJ_Wft",
  location = "US"
))

</code></pre>

<hr>
<h2 id='bq_table_download'>Download table data</h2><span id='topic+bq_table_download'></span>

<h3>Description</h3>

<p>This retrieves rows in chunks of <code>page_size</code>. It is most suitable for results
of smaller queries (&lt;100 MB, say). For larger queries, it is better to
export the results to a CSV file stored on google cloud and use the
bq command line tool to download locally.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_table_download(
  x,
  n_max = Inf,
  page_size = NULL,
  start_index = 0L,
  max_connections = 6L,
  quiet = NA,
  bigint = c("integer", "integer64", "numeric", "character"),
  max_results = deprecated()
)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bq_table_download_+3A_x">x</code></td>
<td>
<p>A <a href="#topic+bq_table">bq_table</a></p>
</td></tr>
<tr><td><code id="bq_table_download_+3A_n_max">n_max</code></td>
<td>
<p>Maximum number of results to retrieve. Use <code>Inf</code> to retrieve all
rows.</p>
</td></tr>
<tr><td><code id="bq_table_download_+3A_page_size">page_size</code></td>
<td>
<p>The number of rows requested per chunk. It is recommended to
leave this unspecified until you have evidence that the <code>page_size</code>
selected automatically by <code>bq_table_download()</code> is problematic.
</p>
<p>When <code>page_size = NULL</code> bigrquery determines a conservative, natural chunk
size empirically. If you specify the <code>page_size</code>, it is important that each
chunk fits on one page, i.e. that the requested row limit is low enough to
prevent the API from paginating based on response size.</p>
</td></tr>
<tr><td><code id="bq_table_download_+3A_start_index">start_index</code></td>
<td>
<p>Starting row index (zero-based).</p>
</td></tr>
<tr><td><code id="bq_table_download_+3A_max_connections">max_connections</code></td>
<td>
<p>Number of maximum simultaneous connections to
BigQuery servers.</p>
</td></tr>
<tr><td><code id="bq_table_download_+3A_quiet">quiet</code></td>
<td>
<p>If <code>FALSE</code>, displays progress bar; if <code>TRUE</code> is silent;
if <code>NA</code> picks based on whether or not you're in an interactive context.</p>
</td></tr>
<tr><td><code id="bq_table_download_+3A_bigint">bigint</code></td>
<td>
<p>The R type that BigQuery's 64-bit integer types should be
mapped to. The default is <code>"integer"</code>, which returns R's <code>integer</code> type,
but results in <code>NA</code> for values above/below +/- 2147483647. <code>"integer64"</code>
returns a <a href="bit64.html#topic+bit64-package">bit64::integer64</a>, which allows the full range of 64 bit
integers.</p>
</td></tr>
<tr><td><code id="bq_table_download_+3A_max_results">max_results</code></td>
<td>
<p><a href="https://lifecycle.r-lib.org/articles/stages.html#deprecated"><img src="../help/figures/lifecycle-deprecated.svg" alt='[Deprecated]' /></a> Deprecated. Please use
<code>n_max</code> instead.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Because data retrieval may generate list-columns and the <code>data.frame</code>
print method can have problems with list-columns, this method returns
a tibble. If you need a <code>data.frame</code>, coerce the results with
<code><a href="base.html#topic+as.data.frame">as.data.frame()</a></code>.
</p>


<h3>Complex data</h3>

<p>bigrquery will retrieve nested and repeated columns in to list-columns
as follows:
</p>

<ul>
<li><p> Repeated values (arrays) will become a list-column of vectors.
</p>
</li>
<li><p> Records will become list-columns of named lists.
</p>
</li>
<li><p> Repeated records will become list-columns of data frames.
</p>
</li></ul>



<h3>Larger datasets</h3>

<p>In my timings, this code takes around 1 minute per 100 MB of data.
If you need to download considerably more than this, I recommend:
</p>

<ul>
<li><p> Export a <code>.csv</code> file to Cloud Storage using <code><a href="#topic+bq_table_save">bq_table_save()</a></code>.
</p>
</li>
<li><p> Use the <code>gsutil</code> command line utility to download it.
</p>
</li>
<li><p> Read the csv file into R with <code>readr::read_csv()</code> or <code>data.table::fread()</code>.
</p>
</li></ul>

<p>Unfortunately you can not export nested or repeated formats into CSV, and
the formats that BigQuery supports (arvn and ndjson) that allow for
nested/repeated values, are not well supported in R.
</p>


<h3>Google BigQuery API documentation</h3>


<ul>
<li> <p><a href="https://cloud.google.com/bigquery/docs/reference/rest/v2/tabledata/list">list</a>
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'>
df &lt;- bq_table_download("publicdata.samples.natality", n_max = 35000)

</code></pre>

<hr>
<h2 id='bq_test_project'>Project to use for testing bigrquery</h2><span id='topic+bq_test_project'></span><span id='topic+bq_test_init'></span><span id='topic+bq_test_dataset'></span><span id='topic+bq_testable'></span><span id='topic+bq_authable'></span><span id='topic+gs_test_bucket'></span><span id='topic+gs_test_object'></span>

<h3>Description</h3>

<p>You'll need to set the <code>BIGQUERY_TEST_PROJECT</code> (name of a project) and
<code>BIGQUERY_TEST_BUCKET</code> (name of bucket) env vars in order to run bigrquery
tests locally. I recommend creating a new project because the tests involve
both reading and writing in BigQuery and Cloud Storage.
</p>
<p>The <code>BIGQUERY_TEST_PROJECT</code> must have billing enabled for the project. While
logged in, via <code>bq_auth()</code>, as a user with permission to work in
<code>BIGQUERY_TEST_PROJECT</code>, run <code>bq_test_init()</code> once to perform some setup.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_test_project()

bq_test_init(name = "basedata")

bq_test_dataset(name = random_name(), location = "US")

bq_testable()

bq_authable()

gs_test_bucket()

gs_test_object(name = random_name())
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bq_test_project_+3A_name">name</code></td>
<td>
<p>Dataset name - used only for testing.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>bq_test_project()</code> returns the name of a project suitable for use in
testing. <code>bq_test_dataset()</code> creates a temporary dataset whose lifetime is
tied to the lifetime of the object that it returns.
</p>


<h3>Testing</h3>

<p>In tests, <code>bq_test_project()</code> (and hence <code>bq_test_dataset()</code>) will
automatically skip if auth and a test project are not available.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
ds &lt;- bq_test_dataset()
bq_mtcars &lt;- bq_table_upload(bq_table(ds, "mtcars"), mtcars)

# dataset and table will be automatically deleted when ds is GC'd

</code></pre>

<hr>
<h2 id='bq_token'>Produce configured token</h2><span id='topic+bq_token'></span>

<h3>Description</h3>

<p>For internal use or for those programming around the BigQuery API.
Returns a token pre-processed with <code><a href="httr.html#topic+config">httr::config()</a></code>. Most users
do not need to handle tokens &quot;by hand&quot; or, even if they need some
control, <code><a href="#topic+bq_auth">bq_auth()</a></code> is what they need. If there is no current
token, <code><a href="#topic+bq_auth">bq_auth()</a></code> is called to either load from cache or
initiate OAuth2.0 flow.
If auth has been deactivated via <code><a href="#topic+bq_deauth">bq_deauth()</a></code>, <code>bq_token()</code>
returns <code>NULL</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_token()
</code></pre>


<h3>Value</h3>

<p>A <code>request</code> object (an S3 class provided by <a href="httr.html#topic+httr-package">httr</a>).
</p>


<h3>See Also</h3>

<p>Other low-level API functions: 
<code><a href="#topic+bq_has_token">bq_has_token</a>()</code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
bq_token()

## End(Not run)
</code></pre>

<hr>
<h2 id='bq_user'>Get info on current user</h2><span id='topic+bq_user'></span>

<h3>Description</h3>

<p>Reveals the email address of the user associated with the current token.
If no token has been loaded yet, this function does not initiate auth.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bq_user()
</code></pre>


<h3>Value</h3>

<p>An email address or, if no token has been loaded, <code>NULL</code>.
</p>


<h3>See Also</h3>

<p><code><a href="gargle.html#topic+token-info">gargle::token_userinfo()</a></code>, <code><a href="gargle.html#topic+token-info">gargle::token_email()</a></code>,
<code><a href="gargle.html#topic+token-info">gargle::token_tokeninfo()</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
bq_user()

## End(Not run)
</code></pre>

<hr>
<h2 id='DBI'>DBI methods</h2><span id='topic+DBI'></span><span id='topic+BigQueryDriver-class'></span><span id='topic+dbConnect+2Cbq_dataset-method'></span><span id='topic+show+2CBigQueryDriver-method'></span><span id='topic+dbGetInfo+2CBigQueryDriver-method'></span><span id='topic+dbIsValid+2CBigQueryDriver-method'></span><span id='topic+dbDataType+2CBigQueryDriver-method'></span><span id='topic+BigQueryConnection-class'></span><span id='topic+show+2CBigQueryConnection-method'></span><span id='topic+dbIsValid+2CBigQueryConnection-method'></span><span id='topic+dbDisconnect+2CBigQueryConnection-method'></span><span id='topic+dbSendQuery+2CBigQueryConnection+2Ccharacter-method'></span><span id='topic+dbExecute+2CBigQueryConnection+2Ccharacter-method'></span><span id='topic+dbQuoteString+2CBigQueryConnection+2Ccharacter-method'></span><span id='topic+dbQuoteString+2CBigQueryConnection+2CSQL-method'></span><span id='topic+dbQuoteIdentifier+2CBigQueryConnection+2Ccharacter-method'></span><span id='topic+dbQuoteIdentifier+2CBigQueryConnection+2CSQL-method'></span><span id='topic+dbQuoteLiteral+2CBigQueryConnection+2Clogical-method'></span><span id='topic+dbDataType+2CBigQueryConnection-method'></span><span id='topic+dbWriteTable+2CBigQueryConnection+2Ccharacter+2Cdata.frame-method'></span><span id='topic+dbWriteTable+2CBigQueryConnection+2CId+2Cdata.frame-method'></span><span id='topic+dbWriteTable+2CBigQueryConnection+2CAsIs+2Cdata.frame-method'></span><span id='topic+dbAppendTable+2CBigQueryConnection+2Ccharacter+2Cdata.frame-method'></span><span id='topic+dbAppendTable+2CBigQueryConnection+2CId+2Cdata.frame-method'></span><span id='topic+dbAppendTable+2CBigQueryConnection+2CAsIs+2Cdata.frame-method'></span><span id='topic+dbCreateTable+2CBigQueryConnection-method'></span><span id='topic+dbReadTable+2CBigQueryConnection+2Ccharacter-method'></span><span id='topic+dbReadTable+2CBigQueryConnection+2CId-method'></span><span id='topic+dbReadTable+2CBigQueryConnection+2CAsIs-method'></span><span id='topic+dbListTables+2CBigQueryConnection-method'></span><span id='topic+dbExistsTable+2CBigQueryConnection+2Ccharacter-method'></span><span id='topic+dbExistsTable+2CBigQueryConnection+2CId-method'></span><span id='topic+dbExistsTable+2CBigQueryConnection+2CAsIs-method'></span><span id='topic+dbListFields+2CBigQueryConnection+2Ccharacter-method'></span><span id='topic+dbListFields+2CBigQueryConnection+2CId-method'></span><span id='topic+dbListFields+2CBigQueryConnection+2CAsIs-method'></span><span id='topic+dbRemoveTable+2CBigQueryConnection+2Ccharacter-method'></span><span id='topic+dbRemoveTable+2CBigQueryConnection+2CId-method'></span><span id='topic+dbRemoveTable+2CBigQueryConnection+2CAsIs-method'></span><span id='topic+dbGetInfo+2CBigQueryConnection-method'></span><span id='topic+dbBegin+2CBigQueryConnection-method'></span><span id='topic+dbCommit+2CBigQueryConnection-method'></span><span id='topic+dbRollback+2CBigQueryConnection-method'></span><span id='topic+BigQueryResult-class'></span><span id='topic+show+2CBigQueryResult-method'></span><span id='topic+dbIsValid+2CBigQueryResult-method'></span><span id='topic+dbClearResult+2CBigQueryResult-method'></span><span id='topic+dbFetch+2CBigQueryResult-method'></span><span id='topic+dbHasCompleted+2CBigQueryResult-method'></span><span id='topic+dbGetStatement+2CBigQueryResult-method'></span><span id='topic+dbColumnInfo+2CBigQueryResult-method'></span><span id='topic+dbGetRowCount+2CBigQueryResult-method'></span><span id='topic+dbGetRowsAffected+2CBigQueryResult-method'></span><span id='topic+dbBind+2CBigQueryResult-method'></span>

<h3>Description</h3>

<p>Implementations of pure virtual functions defined in the <code>DBI</code> package.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'bq_dataset'
dbConnect(drv, ...)

## S4 method for signature 'BigQueryDriver'
show(object)

## S4 method for signature 'BigQueryDriver'
dbGetInfo(dbObj, ...)

## S4 method for signature 'BigQueryDriver'
dbIsValid(dbObj, ...)

## S4 method for signature 'BigQueryDriver'
dbDataType(dbObj, obj, ...)

## S4 method for signature 'BigQueryConnection'
show(object)

## S4 method for signature 'BigQueryConnection'
dbIsValid(dbObj, ...)

## S4 method for signature 'BigQueryConnection'
dbDisconnect(conn, ...)

## S4 method for signature 'BigQueryConnection,character'
dbSendQuery(conn, statement, ..., params = NULL)

## S4 method for signature 'BigQueryConnection,character'
dbExecute(conn, statement, ...)

## S4 method for signature 'BigQueryConnection,character'
dbQuoteString(conn, x, ...)

## S4 method for signature 'BigQueryConnection,SQL'
dbQuoteString(conn, x, ...)

## S4 method for signature 'BigQueryConnection,character'
dbQuoteIdentifier(conn, x, ...)

## S4 method for signature 'BigQueryConnection,SQL'
dbQuoteIdentifier(conn, x, ...)

## S4 method for signature 'BigQueryConnection,logical'
dbQuoteLiteral(conn, x, ...)

## S4 method for signature 'BigQueryConnection'
dbDataType(dbObj, obj, ...)

## S4 method for signature 'BigQueryConnection,character,data.frame'
dbWriteTable(
  conn,
  name,
  value,
  ...,
  overwrite = FALSE,
  append = FALSE,
  field.types = NULL,
  temporary = FALSE,
  row.names = NA
)

## S4 method for signature 'BigQueryConnection,Id,data.frame'
dbWriteTable(
  conn,
  name,
  value,
  ...,
  overwrite = FALSE,
  append = FALSE,
  field.types = NULL,
  temporary = FALSE,
  row.names = NA
)

## S4 method for signature 'BigQueryConnection,AsIs,data.frame'
dbWriteTable(
  conn,
  name,
  value,
  ...,
  overwrite = FALSE,
  append = FALSE,
  field.types = NULL,
  temporary = FALSE,
  row.names = NA
)

## S4 method for signature 'BigQueryConnection,character,data.frame'
dbAppendTable(conn, name, value, ..., row.names = NULL)

## S4 method for signature 'BigQueryConnection,Id,data.frame'
dbAppendTable(conn, name, value, ..., row.names = NULL)

## S4 method for signature 'BigQueryConnection,AsIs,data.frame'
dbAppendTable(conn, name, value, ..., row.names = NULL)

## S4 method for signature 'BigQueryConnection'
dbCreateTable(conn, name, fields, ..., row.names = NULL, temporary = FALSE)

## S4 method for signature 'BigQueryConnection'
dbCreateTable(conn, name, fields, ..., row.names = NULL, temporary = FALSE)

## S4 method for signature 'BigQueryConnection,character'
dbReadTable(conn, name, ...)

## S4 method for signature 'BigQueryConnection,Id'
dbReadTable(conn, name, ...)

## S4 method for signature 'BigQueryConnection,AsIs'
dbReadTable(conn, name, ...)

## S4 method for signature 'BigQueryConnection'
dbListTables(conn, ...)

## S4 method for signature 'BigQueryConnection,character'
dbExistsTable(conn, name, ...)

## S4 method for signature 'BigQueryConnection,Id'
dbExistsTable(conn, name, ...)

## S4 method for signature 'BigQueryConnection,AsIs'
dbExistsTable(conn, name, ...)

## S4 method for signature 'BigQueryConnection,character'
dbListFields(conn, name, ...)

## S4 method for signature 'BigQueryConnection,Id'
dbListFields(conn, name, ...)

## S4 method for signature 'BigQueryConnection,AsIs'
dbListFields(conn, name, ...)

## S4 method for signature 'BigQueryConnection,character'
dbRemoveTable(conn, name, ...)

## S4 method for signature 'BigQueryConnection,Id'
dbRemoveTable(conn, name, ...)

## S4 method for signature 'BigQueryConnection,AsIs'
dbRemoveTable(conn, name, ...)

## S4 method for signature 'BigQueryConnection'
dbGetInfo(dbObj, ...)

## S4 method for signature 'BigQueryConnection'
dbBegin(conn, ...)

## S4 method for signature 'BigQueryConnection'
dbCommit(conn, ...)

## S4 method for signature 'BigQueryConnection'
dbRollback(conn, ...)

## S4 method for signature 'BigQueryResult'
show(object)

## S4 method for signature 'BigQueryResult'
dbIsValid(dbObj, ...)

## S4 method for signature 'BigQueryResult'
dbClearResult(res, ...)

## S4 method for signature 'BigQueryResult'
dbFetch(res, n = -1, ...)

## S4 method for signature 'BigQueryResult'
dbHasCompleted(res, ...)

## S4 method for signature 'BigQueryResult'
dbGetStatement(res, ...)

## S4 method for signature 'BigQueryResult'
dbColumnInfo(res, ...)

## S4 method for signature 'BigQueryResult'
dbGetRowCount(res, ...)

## S4 method for signature 'BigQueryResult'
dbGetRowsAffected(res, ...)

## S4 method for signature 'BigQueryResult'
dbBind(res, params, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="DBI_+3A_...">...</code></td>
<td>
<p>Other arguments to methods.</p>
</td></tr>
<tr><td><code id="DBI_+3A_object">object</code></td>
<td>
<p>Any R object</p>
</td></tr>
<tr><td><code id="DBI_+3A_dbobj">dbObj</code></td>
<td>
<p>An object inheriting from <a href="DBI.html#topic+DBIObject-class">DBIObject</a>,
i.e. <a href="DBI.html#topic+DBIDriver-class">DBIDriver</a>, <a href="DBI.html#topic+DBIConnection-class">DBIConnection</a>,
or a <a href="DBI.html#topic+DBIResult-class">DBIResult</a></p>
</td></tr>
<tr><td><code id="DBI_+3A_obj">obj</code></td>
<td>
<p>An R object whose SQL type we want to determine.</p>
</td></tr>
<tr><td><code id="DBI_+3A_conn">conn</code></td>
<td>
<p>A <a href="DBI.html#topic+DBIConnection-class">DBIConnection</a> object, as returned by
<code><a href="DBI.html#topic+dbConnect">dbConnect()</a></code>.</p>
</td></tr>
<tr><td><code id="DBI_+3A_statement">statement</code></td>
<td>
<p>a character string containing SQL.</p>
</td></tr>
<tr><td><code id="DBI_+3A_params">params</code></td>
<td>
<p>For <code>dbBind()</code>, a list of values, named or unnamed,
or a data frame, with one element/column per query parameter.
For <code>dbBindArrow()</code>, values as a nanoarrow stream,
with one column per query parameter.</p>
</td></tr>
<tr><td><code id="DBI_+3A_x">x</code></td>
<td>
<p>A character vector to quote as string.</p>
</td></tr>
<tr><td><code id="DBI_+3A_name">name</code></td>
<td>
<p>The table name, passed on to <code><a href="DBI.html#topic+dbQuoteIdentifier">dbQuoteIdentifier()</a></code>. Options are:
</p>

<ul>
<li><p> a character string with the unquoted DBMS table name,
e.g. <code>"table_name"</code>,
</p>
</li>
<li><p> a call to <code><a href="DBI.html#topic+Id">Id()</a></code> with components to the fully qualified table name,
e.g. <code>Id(schema = "my_schema", table = "table_name")</code>
</p>
</li>
<li><p> a call to <code><a href="DBI.html#topic+SQL">SQL()</a></code> with the quoted and fully qualified table name
given verbatim, e.g. <code>SQL('"my_schema"."table_name"')</code>
</p>
</li></ul>
</td></tr>
<tr><td><code id="DBI_+3A_value">value</code></td>
<td>
<p>A <a href="base.html#topic+data.frame">data.frame</a> (or coercible to data.frame).</p>
</td></tr>
<tr><td><code id="DBI_+3A_overwrite">overwrite</code></td>
<td>
<p>a logical specifying whether to overwrite an existing table
or not. Its default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="DBI_+3A_append">append</code></td>
<td>
<p>a logical specifying whether to append to an existing table
in the DBMS.  Its default is <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="DBI_+3A_field.types">field.types</code>, <code id="DBI_+3A_temporary">temporary</code></td>
<td>
<p>Ignored. Included for compatibility with
generic.</p>
</td></tr>
<tr><td><code id="DBI_+3A_row.names">row.names</code></td>
<td>
<p>A logical specifying whether the <code>row.names</code> should be
output to the output DBMS table; if <code>TRUE</code>, an extra field whose name
will be whatever the R identifier <code>"row.names"</code> maps to the DBMS (see
<code><a href="DBI.html#topic+make.db.names">DBI::make.db.names()</a></code>). If <code>NA</code> will add rows names if
they are characters, otherwise will ignore.</p>
</td></tr>
<tr><td><code id="DBI_+3A_fields">fields</code></td>
<td>
<p>Either a character vector or a data frame.
</p>
<p>A named character vector: Names are column names, values are types.
Names are escaped with <code><a href="DBI.html#topic+dbQuoteIdentifier">dbQuoteIdentifier()</a></code>.
Field types are unescaped.
</p>
<p>A data frame: field types are generated using
<code><a href="DBI.html#topic+dbDataType">dbDataType()</a></code>.</p>
</td></tr>
<tr><td><code id="DBI_+3A_res">res</code></td>
<td>
<p>An object inheriting from <a href="DBI.html#topic+DBIResult-class">DBIResult</a>.</p>
</td></tr>
<tr><td><code id="DBI_+3A_n">n</code></td>
<td>
<p>maximum number of records to retrieve per fetch. Use <code>n = -1</code>
or <code>n = Inf</code>
to retrieve all pending records.  Some implementations may recognize other
special values.</p>
</td></tr>
</table>

<hr>
<h2 id='src_bigquery'>A BigQuery data source for dplyr.</h2><span id='topic+src_bigquery'></span>

<h3>Description</h3>

<p>Create the connection to the database with <code>DBI::dbConnect()</code> then
use <code><a href="dplyr.html#topic+tbl">dplyr::tbl()</a></code> to connect to tables within that database. Generally,
it's best to provide the fully qualified name of the table (i.e.
<code>project.dataset.table</code>) but if you supply a default <code>dataset</code> in the
connection, you can use just the table name. (This, however, will
prevent you from making joins across datasets.)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>src_bigquery(project, dataset, billing = project, max_pages = 10)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="src_bigquery_+3A_project">project</code></td>
<td>
<p>project id or name</p>
</td></tr>
<tr><td><code id="src_bigquery_+3A_dataset">dataset</code></td>
<td>
<p>dataset name</p>
</td></tr>
<tr><td><code id="src_bigquery_+3A_billing">billing</code></td>
<td>
<p>billing project, if different to <code>project</code></p>
</td></tr>
<tr><td><code id="src_bigquery_+3A_max_pages">max_pages</code></td>
<td>
<p>(IGNORED) maximum pages returned by a query</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 
library(dplyr)

# To run this example, replace billing with the id of one of your projects
# set up for billing
con &lt;- DBI::dbConnect(bigquery(), project = bq_test_project())

shakespeare &lt;- con %&gt;% tbl("publicdata.samples.shakespeare")
shakespeare
shakespeare %&gt;%
  group_by(word) %&gt;%
  summarise(n = sum(word_count, na.rm = TRUE)) %&gt;%
  arrange(desc(n))

## End(Not run)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
