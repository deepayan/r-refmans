<!DOCTYPE html><html lang="en"><head><title>Help for package flexclust</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {flexclust}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#achieve'><p>Achievement Test Scores for New Haven Schools</p></a></li>
<li><a href='#auto'>
<p>Automobile Customer Survey Data</p></a></li>
<li><a href='#barplot-methods'><p>Barplot/chart Methods in Package &lsquo;flexclust&rsquo;</p></a></li>
<li><a href='#bclust'><p>Bagged Clustering</p></a></li>
<li><a href='#birth'><p>Birth and Death Rates</p></a></li>
<li><a href='#bootFlexclust'><p>Bootstrap Flexclust Algorithms</p></a></li>
<li><a href='#bundestag'><p>German Parliament Election Data</p></a></li>
<li><a href='#bwplot-methods'><p>Box-Whisker Plot Methods in Package &lsquo;flexclust&rsquo;</p></a></li>
<li><a href='#cclust'><p>Convex Clustering</p></a></li>
<li><a href='#clusterSim'><p>Cluster Similarity Matrix</p></a></li>
<li><a href='#conversion'><p>Conversion Between S3 Partition Objects and KCCA</p></a></li>
<li><a href='#dentitio'><p>Dentition of Mammals</p></a></li>
<li><a href='#dist2'><p>Compute Pairwise Distances Between Two Data sets</p></a></li>
<li><a href='#distances'><p>Distance and Centroid Computation</p></a></li>
<li><a href='#flexclustControl-class'><p>Classes &quot;flexclustControl&quot; and &quot;cclustControl&quot;</p></a></li>
<li><a href='#flxColors'><p>Flexclust Color Palettes</p></a></li>
<li><a href='#histogram-methods'><p>Methods for Function histogram in Package &lsquo;flexclust&rsquo;</p></a></li>
<li><a href='#image-methods'><p>Methods for Function image in Package &lsquo;flexclust&rsquo;</p></a></li>
<li><a href='#info'><p>Get Information on Fitted Flexclust Objects</p></a></li>
<li><a href='#kcca'><p>K-Centroids Cluster Analysis</p></a></li>
<li><a href='#kcca2df'><p>Convert Cluster Result to Data Frame</p></a></li>
<li><a href='#milk'><p>Milk of Mammals</p></a></li>
<li><a href='#Nclus'><p>Artificial Example with 4 Gaussians</p></a></li>
<li><a href='#nutrient'><p>Nutrients in Meat, Fish and Fowl</p></a></li>
<li><a href='#pairs-methods'><p>Methods for Function pairs in Package &lsquo;flexclust&rsquo;</p></a></li>
<li><a href='#parameters'><p>Get Centroids from KCCA Object</p></a></li>
<li><a href='#plot-methods'><p>Methods for Function plot in Package &lsquo;flexclust&rsquo;</p></a></li>
<li><a href='#predict-methods'><p>Predict Cluster Membership</p></a></li>
<li><a href='#priceFeature'><p>Artificial 2d Market Segment Data</p></a></li>
<li><a href='#projAxes'><p>Add Arrows for Projected Axes to a Plot</p></a></li>
<li><a href='#propBarchart'><p>Barcharts and Boxplots for Columns of a Data Matrix Split by Groups</p></a></li>
<li><a href='#qtclust'><p>Stochastic QT Clustering</p></a></li>
<li><a href='#randIndex'><p>Compare Partitions</p></a></li>
<li><a href='#randomTour'><p>Plot a Random Tour</p></a></li>
<li><a href='#relabel'>
<p>Relabel Cluster Results.</p></a></li>
<li><a href='#shadow'><p>Cluster Shadows and Silhouettes</p></a></li>
<li><a href='#shadowStars'><p>Shadow Stars</p></a></li>
<li><a href='#slsaplot'>
<p>Segment Level Stability Across Solutions Plot.</p></a></li>
<li><a href='#slswFlexclust'>
<p>Segment Level Stability Within Solution.</p></a></li>
<li><a href='#stepFlexclust'><p>Run Flexclust Algorithms Repeatedly</p></a></li>
<li><a href='#stripes'><p>Stripes Plot</p></a></li>
<li><a href='#vacmot'>
<p>Vacation Motives of Australians</p></a></li>
<li><a href='#volunteers'>
<p>Motivation of Australian Volunteers</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Version:</td>
<td>1.5.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2025-02-27</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Title:</td>
<td>Flexible Cluster Algorithms</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 2.14.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>graphics, grid, lattice, methods, modeltools, parallel, stats,
stats4, class</td>
</tr>
<tr>
<td>Suggests:</td>
<td>ellipse, clue, cluster, seriation, skmeans</td>
</tr>
<tr>
<td>Description:</td>
<td>The main function kcca implements a general framework for
  k-centroids cluster analysis supporting arbitrary distance measures
  and centroid computation. Further cluster methods include hard
  competitive learning, neural gas, and QT clustering. There are
  numerous visualization methods for cluster results (neighborhood
  graphs, convex cluster hulls, barcharts of centroids, ...), and
  bootstrap methods for the analysis of cluster stability.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a></td>
</tr>
<tr>
<td>LazyLoad:</td>
<td>yes</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>yes</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-27 21:19:24 UTC; gruen</td>
</tr>
<tr>
<td>Author:</td>
<td>Friedrich Leisch <a href="https://orcid.org/0000-0001-7278-1983"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [aut] (maintainer up to 2024),
  Evgenia Dimitriadou [ctb],
  Lena Ortega Menjivar
    <a href="https://orcid.org/0000-0001-5785-4021"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [ctb],
  Dominik Ernst <a href="https://orcid.org/0009-0005-5579-2636"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb],
  Bettina Grün <a href="https://orcid.org/0000-0001-7265-4773"><img alt="ORCID iD"  src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a>
    [ctb, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Bettina Grün &lt;Bettina.Gruen@R-project.org&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-28 06:40:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='achieve'>Achievement Test Scores for New Haven Schools</h2><span id='topic+achieve'></span>

<h3>Description</h3>

<p>Measurements at the beginning of the 4th grade (when the national
average is 4.0) and of the 6th grade in 25 schools in New Haven. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(achieve)</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 4 variables.
</p>

<dl>
<dt><code>read4</code></dt><dd><p>4th grade reading.</p>
</dd>
<dt><code>arith4</code></dt><dd><p>4th grade arithmetic.</p>
</dd>
<dt><code>read6</code></dt><dd><p>6th grade reading.</p>
</dd>
<dt><code>arith6</code></dt><dd><p>6th grade arithmetic.</p>
</dd>
</dl>



<h3>References</h3>

<p>John A. Hartigan: Clustering Algorithms. Wiley, New York, 1975.
</p>

<hr>
<h2 id='auto'>
Automobile Customer Survey Data
</h2><span id='topic+auto'></span>

<h3>Description</h3>

<p>A German manufacturer of premium cars asked customers approximately 3
months after a car purchase which characteristics of the car were most
important for the decision to buy the car. The survey was done in 1983
and the data set contains all responses without missing values.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(auto)</code></pre>


<h3>Format</h3>

<p>A data frame with 793 observations on the following 46 variables.
</p>

<dl>
<dt><code>model</code></dt><dd><p>A factor with levels <code>A</code>, <code>B</code>,
<code>C</code>, or <code>D</code>; model bought by the customer.</p>
</dd>
<dt><code>gear</code></dt><dd><p>A factor with levels <code>4 gears</code>, <code>5
	econo</code>, <code>5 sport</code>, or <code>automatic</code>.</p>
</dd>
<dt><code>leasing</code></dt><dd><p>A logical vector, was leasing used to finance
the car?</p>
</dd>
<dt><code>usage</code></dt><dd><p>A factor with levels <code>private</code>, <code>both</code>, <code>business</code>.</p>
</dd>
<dt><code>previous_model</code></dt><dd><p>A factor describing which type of car
was owned directly before the purchase.</p>
</dd>
<dt><code>other_consider</code></dt><dd><p>A factor with levels <code>same manuf</code>,
<code>other manuf</code>, <code>both</code>, or <code>none</code>.</p>
</dd>
<dt><code>test_drive</code></dt><dd><p>A logical vector, did you do a test drive?</p>
</dd>
<dt><code>info_adv</code></dt><dd><p>A logical vector, was advertising an
important source of information?</p>
</dd>
<dt><code>info_exp</code></dt><dd><p>A logical vector, was experience an
important source of information?</p>
</dd>
<dt><code>info_rec</code></dt><dd><p>A logical vector, were recommendations an
important source of information?</p>
</dd>
<dt><code>ch_clarity</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_economy</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_driving_properties</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_service</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_interior</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_quality</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_technology</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_model_continuity</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_comfort</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_reliability</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_handling</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_reputation</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_concept</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_character</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_power</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_resale_value</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_styling</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_safety</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_sporty</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_consumption</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>ch_space</code></dt><dd><p>A logical vector.</p>
</dd>
<dt><code>satisfaction</code></dt><dd><p>A numeric vector describing overall
satisfaction (1=very good, 10=very bad).</p>
</dd>
<dt><code>good1</code></dt><dd><p>Conception, styling, dimensions.</p>
</dd>
<dt><code>good2</code></dt><dd><p>Auto body.</p>
</dd>
<dt><code>good3</code></dt><dd><p>Driving and coupled axles.</p>
</dd>
<dt><code>good4</code></dt><dd><p>Engine.</p>
</dd>
<dt><code>good5</code></dt><dd><p>Electronics.</p>
</dd>
<dt><code>good6</code></dt><dd><p>Financing and customer service.</p>
</dd>
<dt><code>good7</code></dt><dd><p>Other.</p>
</dd>
<dt><code>sporty</code></dt><dd><p>What do you think about the balance of
sportiness and comfort? (<code>good</code>, <code>more sport</code>, <code>more comfort</code>).</p>
</dd>
<dt><code>drive_char</code></dt><dd><p>Driving characteristis (<code>gentle</code> &lt; <code>speedy</code> &lt; <code>powerfull</code> &lt; <code>extreme</code>).</p>
</dd>
<dt><code>tempo</code></dt><dd><p>Which average speed do you prefer on German
Autobahn in km/h? (<code>&lt; 130</code> &lt; <code>130-150</code> &lt; <code>150-180</code> &lt; <code>&gt; 180</code>)</p>
</dd>
<dt><code>consumption</code></dt><dd><p>An ordered factor with levels <code>low</code> &lt; <code>ok</code> &lt; <code>high</code> &lt; <code>too high</code>.</p>
</dd>
<dt><code>gender</code></dt><dd><p>A factor with levels <code>male</code> and <code>female</code></p>
</dd>
<dt><code>occupation</code></dt><dd><p>A factor with levels <code>self-employed</code>,
<code>freelance</code>, and <code>employee</code>.</p>
</dd>
<dt><code>household</code></dt><dd><p>Size of household, an ordered factor with levels <code>1-2</code> &lt; <code>&gt;=3</code>.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The original German data are in the public domain and available
from LMU Munich (doi:10.5282/ubm/data.14). The variable names and
help page were translated to English and converted into Rd format
by Friedrich Leisch.
</p>


<h3>References</h3>

<p>Open Data LMU (1983): Umfrage unter Kunden einer Automobilfirma,
doi:10.5282/ubm/data.14
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(auto)
summary(auto)
</code></pre>

<hr>
<h2 id='barplot-methods'>Barplot/chart Methods in Package &lsquo;flexclust&rsquo;</h2><span id='topic+barplot+2Ckcca-method'></span><span id='topic+barplot+2Ckccasimple-method'></span><span id='topic+barchart+2Ckcca-method'></span><span id='topic+barchart+2Ckccasimple-method'></span><span id='topic+barchart+2Chclust-method'></span><span id='topic+barchart+2Cbclust-method'></span>

<h3>Description</h3>

<p>Barplot of cluster centers or other cluster statistics.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'kcca'
barplot(height, bycluster = TRUE, oneplot = TRUE,
    data = NULL, FUN = colMeans, main = deparse(substitute(height)), 
    which = 1:height@k, names.arg = NULL,
    oma = par("oma"), col = NULL, mcol = "darkred", srt = 45, ...)

## S4 method for signature 'kcca'
barchart(x, data, xlab="", strip.labels=NULL,
    strip.prefix="Cluster ", col=NULL, mcol="darkred", mlcol=mcol,
    which=NULL, legend=FALSE, shade=FALSE, diff=NULL, byvar=FALSE,
    clusters=1:x@k, ...)
## S4 method for signature 'hclust'
barchart(x, data, xlab="", strip.labels=NULL,
    strip.prefix="Cluster ", col=NULL, mcol="darkred", mlcol=mcol,
    which=NULL, shade=FALSE, diff=NULL, byvar=FALSE, k=2, ...)
## S4 method for signature 'bclust'
barchart(x, data, xlab="", strip.labels=NULL,
       strip.prefix="Cluster ", col=NULL, mcol="darkred", mlcol=mcol, 
       which=NULL, legend=FALSE, shade=FALSE, diff=NULL, byvar=FALSE,
       k=x@k, clusters=1:k, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="barplot-methods_+3A_height">height</code>, <code id="barplot-methods_+3A_x">x</code></td>
<td>
<p>An object of class <code>"kcca"</code>.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_bycluster">bycluster</code></td>
<td>
<p>If <code>TRUE</code>, then each barplot shows one
cluster. If <code>FALSE</code>, then each barplot compares all cluster for
one input variable.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_oneplot">oneplot</code></td>
<td>
<p>If <code>TRUE</code>, all barplots are plotted together on
one page, else each plot is on a separate page.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_data">data</code></td>
<td>
<p>If not <code>NULL</code>, cluster membership is predicted for
the new data and used for the plots. By default the
values from the training data are used. Ignored by the <code>barchart</code>
method.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_fun">FUN</code></td>
<td>
<p>The function to be applied to each cluster for calculating
the bar heights. Only used, if <code>data</code> is not <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_which">which</code></td>
<td>
<p>For <code>barplot</code> index number of clusters for the plot,
for <code>barchart</code> index numbers or names of variables to plot.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_names.arg">names.arg</code></td>
<td>
<p>A vector of names to be plotted below each bar.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_main">main</code>, <code id="barplot-methods_+3A_oma">oma</code>, <code id="barplot-methods_+3A_xlab">xlab</code>, <code id="barplot-methods_+3A_...">...</code></td>
<td>
<p>Graphical parameters.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_col">col</code></td>
<td>
<p>Vector of colors for the clusters.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_mcol">mcol</code>, <code id="barplot-methods_+3A_mlcol">mlcol</code></td>
<td>
<p>If not <code>NULL</code>, the value of
<code>FUN</code> for the complete data set is plotted over each bar as a
point with color <code>mcol</code> and a line segment starting in zero
with color <code>mlcol</code>.</p>
</td></tr> 
<tr><td><code id="barplot-methods_+3A_srt">srt</code></td>
<td>
<p>Number between 0 and 90, rotation of the x-axis labels.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_strip.labels">strip.labels</code></td>
<td>
<p>Vector of strings for the strips of the Trellis
display.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_strip.prefix">strip.prefix</code></td>
<td>
<p>Prefix string for the strips of the Trellis
display.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_legend">legend</code></td>
<td>
<p>If <code>TRUE</code>, the barchart is always plotted on the
current graphics device and a legend is added to the bottom of the
plot.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_shade">shade</code></td>
<td>
<p>If <code>TRUE</code>, only bars with large absolute or relative
deviation deviation from the  sample mean of the respective
variables are plotted in color.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_diff">diff</code></td>
<td>
<p>A numerical vector of length two with absolute and
relative deviations for shading, default is <code class="reqn">max/4</code> absolute
deviation and 50% relative deviation.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_byvar">byvar</code></td>
<td>
<p>If <code>TRUE</code>, a panel is plotted for each variable. By
default a panel is plotted for each cluster.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_clusters">clusters</code></td>
<td>
<p>Integer vector of clusters to plot.</p>
</td></tr>
<tr><td><code id="barplot-methods_+3A_k">k</code></td>
<td>
<p>Integer specifying the desired number of clusters.</p>
</td></tr>
</table>


<h3>Note</h3>

<p>The flexclust barchart method uses a horizontal arrangements of
the bars, and sorts them from top to bottom. Default barcharts in
lattice are the other way round (bottom to top). See the examples
below how this affects, e.g., manual labels for the y axis.
</p>
<p>The <code>barplot</code> method is legacy code and only maintained to keep up
with changes in R, all active development is done on <code>barchart</code>.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Sara Dolnicar and Friedrich Leisch. Using graphical statistics to
better understand market segmentation solutions. International Journal
of Market Research, 56(2), 97-120, 2014.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>  cl &lt;- cclust(iris[,-5], k=3)
  barplot(cl)
  barplot(cl, bycluster=FALSE)

  ## plot the maximum instead of mean value per cluster:
  barplot(cl, bycluster=FALSE, data=iris[,-5],
          FUN=function(x) apply(x,2,max))

  ## use lattice for plotting:
  barchart(cl)
  ## automatic abbreviation of labels
  barchart(cl, scales=list(abbreviate=TRUE))
  ## origin of bars at zero
  barchart(cl, scales=list(abbreviate=TRUE), origin=0)

  ## Use manual labels. Note that the flexclust barchart orders bars
  ## from top to bottom (the default does it the other way round), hence
  ## we have to rev() the labels:
  LAB &lt;- c("SL", "SW", "PL", "PW")
  barchart(cl, scales=list(y=list(labels=rev(LAB))), origin=0)

  ## deviation of each cluster center from the population means
  barchart(cl, origin=rev(cl@xcent), mlcol=NULL)

  ## use shading to highlight large deviations from population mean
  barchart(cl, shade=TRUE)

  ## use smaller deviation limit than default and add a legend
  barchart(cl, shade=TRUE, diff=0.2, legend=TRUE)
</code></pre>

<hr>
<h2 id='bclust'>Bagged Clustering</h2><span id='topic+bclust'></span><span id='topic+plot+2Cbclust+2Cmissing-method'></span><span id='topic+clusters+2Cbclust+2Cmissing-method'></span><span id='topic+parameters+2Cbclust-method'></span>

<h3>Description</h3>

<p>Cluster the data in <code>x</code> using the bagged clustering
algorithm. A partitioning cluster algorithm such as
<code><a href="#topic+cclust">cclust</a></code> is run repeatedly on bootstrap samples from the
original data. The resulting cluster centers are then combined using
the hierarchical cluster algorithm <code><a href="stats.html#topic+hclust">hclust</a></code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bclust(x, k = 2, base.iter = 10, base.k = 20, minsize = 0,
       dist.method = "euclidian", hclust.method = "average",
       FUN = "cclust", verbose = TRUE, final.cclust = FALSE,
       resample = TRUE, weights = NULL, maxcluster = base.k, ...)
## S4 method for signature 'bclust,missing'
plot(x, y, maxcluster = x@maxcluster, main = "", ...)
## S4 method for signature 'bclust,missing'
clusters(object, newdata, k, ...)
## S4 method for signature 'bclust'
parameters(object, k)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bclust_+3A_x">x</code></td>
<td>
<p>Matrix of inputs (or object of class <code>"bclust"</code> for plot).</p>
</td></tr>
<tr><td><code id="bclust_+3A_k">k</code></td>
<td>
<p>Number of clusters.</p>
</td></tr>
<tr><td><code id="bclust_+3A_base.iter">base.iter</code></td>
<td>
<p>Number of runs of the base cluster algorithm.</p>
</td></tr>
<tr><td><code id="bclust_+3A_base.k">base.k</code></td>
<td>
<p>Number of centers used in each repetition of the
base method.</p>
</td></tr>
<tr><td><code id="bclust_+3A_minsize">minsize</code></td>
<td>
<p>Minimum number of points in a base cluster.</p>
</td></tr>
<tr><td><code id="bclust_+3A_dist.method">dist.method</code></td>
<td>
<p>Distance method used for the hierarchical
clustering, see <code><a href="stats.html#topic+dist">dist</a></code> for available distances.</p>
</td></tr>
<tr><td><code id="bclust_+3A_hclust.method">hclust.method</code></td>
<td>
<p>Linkage method used for the hierarchical
clustering, see <code><a href="stats.html#topic+hclust">hclust</a></code> for available methods.</p>
</td></tr>
<tr><td><code id="bclust_+3A_fun">FUN</code></td>
<td>
<p>Partitioning cluster method used as base algorithm.</p>
</td></tr>
<tr><td><code id="bclust_+3A_verbose">verbose</code></td>
<td>
<p>Output status messages.</p>
</td></tr>
<tr><td><code id="bclust_+3A_final.cclust">final.cclust</code></td>
<td>
<p>If <code>TRUE</code>, a final cclust step is performed
using the output of the bagged clustering as initialization.</p>
</td></tr>
<tr><td><code id="bclust_+3A_resample">resample</code></td>
<td>
<p>Logical, if <code>TRUE</code> the base method is run on
bootstrap samples of <code>x</code>, else directly on <code>x</code>.</p>
</td></tr>
<tr><td><code id="bclust_+3A_weights">weights</code></td>
<td>
<p>Vector of length <code>nrow(x)</code>, weights for the
resampling. By default all observations have equal weight.</p>
</td></tr>
<tr><td><code id="bclust_+3A_maxcluster">maxcluster</code></td>
<td>
<p>Maximum number of clusters memberships are to be
computed for.</p>
</td></tr>
<tr><td><code id="bclust_+3A_object">object</code></td>
<td>
<p>Object of class <code>"bclust"</code>.</p>
</td></tr>
<tr><td><code id="bclust_+3A_main">main</code></td>
<td>
<p>Main title of the plot.</p>
</td></tr>
<tr><td><code id="bclust_+3A_...">...</code></td>
<td>
<p>Optional arguments top be passed to the base method
in <code>bclust</code>, ignored in <code>plot</code>.</p>
</td></tr>
<tr><td><code id="bclust_+3A_y">y</code></td>
<td>
<p>Missing.</p>
</td></tr>
<tr><td><code id="bclust_+3A_newdata">newdata</code></td>
<td>
<p>An optional data matrix with the same number of columns
as the cluster centers. If omitted, the fitted values are used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>First, <code>base.iter</code> bootstrap samples of the original data in
<code>x</code> are created by drawing with replacement. The base cluster
method is run on each of these samples with <code>base.k</code>
centers. The <code>base.method</code> must be the name of a partitioning
cluster function returning an object with the same slots as the
return value of <code><a href="#topic+cclust">cclust</a></code>.
</p>
<p>This results in a collection of <code>iter.base * base.centers</code>
centers, which are subsequently clustered using the hierarchical
method <code><a href="stats.html#topic+hclust">hclust</a></code>. Base centers with less than
<code>minsize</code> points in there respective partitions are removed
before the hierarchical clustering.  The resulting dendrogram is
then cut to produce <code>k</code> clusters.
</p>


<h3>Value</h3>

<p><code>bclust</code> returns objects of class
<code>"bclust"</code> including the slots
</p>
<table role = "presentation">
<tr><td><code>hclust</code></td>
<td>
<p>Return value of the hierarchical clustering of the
collection of base centers (Object of class <code>"hclust"</code>).</p>
</td></tr>
<tr><td><code>cluster</code></td>
<td>
<p>Vector with indices of the clusters the inputs are
assigned to.</p>
</td></tr>
<tr><td><code>centers</code></td>
<td>
<p>Matrix of centers of the final clusters. Only useful,
if the hierarchical clustering method produces convex clusters.</p>
</td></tr>
<tr><td><code>allcenters</code></td>
<td>
<p>Matrix of all <code>iter.base * base.centers</code>
centers found in the base runs.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Friedrich Leisch. Bagged clustering. Working Paper 51, SFB &ldquo;Adaptive
Information Systems and Modeling in Economics and Management
Science&rdquo;, August 1999. <a href="https://doi.org/10.57938/9b129f95-b53b-44ce-a129-5b7a1168d832">doi:10.57938/9b129f95-b53b-44ce-a129-5b7a1168d832</a>
</p>
<p>Sara Dolnicar and Friedrich Leisch. Winter tourist segments in
Austria: Identifying stable vacation styles using bagged clustering
techniques. Journal of Travel Research, 41(3):281-292, 2003.
</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+hclust">hclust</a></code>, <code><a href="#topic+cclust">cclust</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(iris)
bc1 &lt;- bclust(iris[,1:4], 3, base.k=5)
plot(bc1)

table(clusters(bc1, k=3))
parameters(bc1, k=3)
</code></pre>

<hr>
<h2 id='birth'>Birth and Death Rates</h2><span id='topic+birth'></span>

<h3>Description</h3>

<p>Birth and death rates for 70 countries.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(birth)</code></pre>


<h3>Format</h3>

<p>A data frame with 70 observations on the following 2 variables.
</p>

<dl>
<dt><code>birth</code></dt><dd><p>Birth rate (in percent).</p>
</dd>
<dt><code>death</code></dt><dd><p>Death rate (in percent).</p>
</dd>
</dl>



<h3>References</h3>

<p>John A. Hartigan: Clustering Algorithms. Wiley, New York, 1975.
</p>

<hr>
<h2 id='bootFlexclust'>Bootstrap Flexclust Algorithms</h2><span id='topic+bootFlexclust'></span><span id='topic+bootFlexclust-class'></span><span id='topic+show+2CbootFlexclust-method'></span><span id='topic+summary+2CbootFlexclust-method'></span><span id='topic+plot+2CbootFlexclust+2Cmissing-method'></span><span id='topic+boxplot+2CbootFlexclust-method'></span><span id='topic+densityplot+2CbootFlexclust-method'></span>

<h3>Description</h3>

<p>Runs clustering algorithms repeatedly for different numbers of
clusters on bootstrap replica of the original data and returns
corresponding cluster assignments, centroids and (adjusted) Rand indices
comparing pairs of partitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>bootFlexclust(x, k, nboot=100, correct=TRUE, seed=NULL,
              multicore=TRUE, verbose=FALSE, ...)

## S4 method for signature 'bootFlexclust'
summary(object)
## S4 method for signature 'bootFlexclust,missing'
plot(x, y, ...)
## S4 method for signature 'bootFlexclust'
boxplot(x, ...)
## S4 method for signature 'bootFlexclust'
densityplot(x, data, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bootFlexclust_+3A_x">x</code>, <code id="bootFlexclust_+3A_k">k</code>, <code id="bootFlexclust_+3A_...">...</code></td>
<td>
<p>Passed to <code><a href="#topic+stepFlexclust">stepFlexclust</a></code>.</p>
</td></tr>
<tr><td><code id="bootFlexclust_+3A_nboot">nboot</code></td>
<td>
<p>Number of bootstrap pairs of partitions.</p>
</td></tr>
<tr><td><code id="bootFlexclust_+3A_correct">correct</code></td>
<td>
<p>Logical, correct the Rand index for agreement by chance
also called adjusted Rand index)?</p>
</td></tr>
<tr><td><code id="bootFlexclust_+3A_seed">seed</code></td>
<td>
<p>If not <code>NULL</code>, a call to <code>set.seed()</code> is made
before any clustering is done.</p>
</td></tr>
<tr><td><code id="bootFlexclust_+3A_multicore">multicore</code></td>
<td>
<p>If <code>TRUE</code>, use package <span class="pkg">parallel</span> for
parallel processing. In addition, it may be a workstation cluster
object as returned by <code><a href="parallel.html#topic+makeCluster">makeCluster</a></code>, see
examples below.</p>
</td></tr>
<tr><td><code id="bootFlexclust_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, show progress information during
computations. Will not work with <code>multicore=TRUE</code>.</p>
</td></tr>
<tr><td><code id="bootFlexclust_+3A_y">y</code>, <code id="bootFlexclust_+3A_data">data</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="bootFlexclust_+3A_object">object</code></td>
<td>
<p>An object of class <code>"bootFlexclust"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Availability of <span class="pkg">multicore</span> is checked
when <span class="pkg">flexclust</span> is loaded. This information is stored and can be
obtained using
<code>getOption("flexclust")$have_multicore</code>. Set to <code>FALSE</code>
for debugging and more sensible error messages in case something
goes wrong.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>See Also</h3>

<p><code><a href="#topic+stepFlexclust">stepFlexclust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## Not run: 

## data uniform on unit square
x &lt;- matrix(runif(400), ncol=2)

cl &lt;- FALSE

## to run bootstrap replications on a workstation cluster do the following:
library("parallel")
cl &lt;- makeCluster(2, type = "PSOCK")
clusterCall(cl, function() require("flexclust"))


## 50 bootstrap replicates for speed in example,
## use more for real applications
bcl &lt;- bootFlexclust(x, k=2:7, nboot=50, FUN=cclust, multicore=cl)

bcl
summary(bcl)

## splitting the square into four quadrants should be the most stable
## solution (increase nboot if not)
plot(bcl)
densityplot(bcl, from=0)

## End(Not run)</code></pre>

<hr>
<h2 id='bundestag'>German Parliament Election Data</h2><span id='topic+bundestag'></span><span id='topic+btw2002'></span><span id='topic+btw2005'></span><span id='topic+btw2009'></span>

<h3>Description</h3>

<p>Results of the elections 2002, 2005 or 2009 for the German Bundestag, the
first chamber of the German parliament.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(btw2002)
data(btw2005)
data(btw2009)
bundestag(year, second=TRUE, percent=TRUE, nazero=TRUE, state=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bundestag_+3A_year">year</code></td>
<td>
<p>Numeric or character, year of the election.</p>
</td></tr>
<tr><td><code id="bundestag_+3A_second">second</code></td>
<td>
<p>Logical, return second or first votes?</p>
</td></tr>
<tr><td><code id="bundestag_+3A_percent">percent</code></td>
<td>
<p>Logical, return percentages or absolute numbers?</p>
</td></tr>
<tr><td><code id="bundestag_+3A_nazero">nazero</code></td>
<td>
<p>Logical, convert <code>NA</code>s to 0?</p>
</td></tr>
<tr><td><code id="bundestag_+3A_state">state</code></td>
<td>
<p>Logical or character. If <code>TRUE</code> then only column <code>state</code>
from the corresponding data frame is returned, and all other
arguments are ignored. If character, then it is used as pattern to
<code><a href="base.html#topic+grep">grep</a></code> for the corresponding state(s), see examples.</p>
</td></tr>
</table>


<h3>Format</h3>

<p><code>btw200x</code> are data frames with 299 rows
(corresponding to constituencies) and 17 columns. All columns except
<code>state</code> are numeric.
</p>

<dl>
<dt><code>state</code></dt><dd><p>Factor, the 16 German federal states.</p>
</dd>
<dt><code>eligible</code></dt><dd><p>Number of citizens eligible to vote.</p>
</dd>
<dt><code>votes</code></dt><dd><p>Number of eligible citizens who did vote.</p>
</dd>
<dt><code>invalid1, invalid2</code></dt><dd><p>Number of invalid first and second votes (see
details below).</p>
</dd>
<dt><code>valid1, valid2</code></dt><dd><p>Number of valid first and second votes.</p>
</dd>
<dt><code>SPD1, SPD2</code></dt><dd><p>Number of first and second votes for the Social Democrats.</p>
</dd>
<dt><code>UNION1, UNION2</code></dt><dd><p>Number of first and second votes for CDU/CSU,
the conservative Christian Democrats.</p>
</dd>
<dt><code>GRUENE1, GRUENE2</code></dt><dd><p>Number of first and second votes for the
Green Party.</p>
</dd>
<dt><code>FDP1, FDP2</code></dt><dd><p>Number of first and second votes for the Liberal Party.</p>
</dd>
<dt><code>LINKE1, LINKE2</code></dt><dd><p>Number of first and second votes for the Left
Party (PDS in 2002).</p>
</dd>
</dl>

<p>Missing values indicate that a party did not candidate in the
corresponding constituency.
</p>


<h3>Details</h3>

<p><code>btw200x</code> are the original data sets.
<code>bundestag()</code> is a helper function which extracts first
or second votes, calculates percentages (number of votes for a party divided by
number of valid votes), replaces missing values by zero, and converts
the result from a data frame to a matrix.  By default
it returns the percentage of second votes for each party, which
determines the number of seats each party gets in parliament.
</p>


<h3>German Federal Elections</h3>

<p> Half of the Members of the German
Bundestag are elected directly from Germany's 299 constituencies, the
other half on the parties' state lists.  Accordingly, each voter has
two votes in the elections to the German Bundestag. The first vote,
allowing voters to elect their local representatives to the Bundestag,
decides which candidates are sent to Parliament from the
constituencies.
</p>
<p>The second vote is cast for a party list. And it is this second vote
that determines the relative strengths of the parties represented in
the Bundestag.  At least 598 Members of the German Bundestag are
elected in this way. In addition to this, there are certain
circumstances in which some candidates win what
are known as &ldquo;overhang mandates&rdquo; when the seats are being
distributed.
</p>


<h3>References</h3>

<p>Homepage of the Bundestag:
<a href="https://www.bundestag.de">https://www.bundestag.de</a>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>p02 &lt;- bundestag(2002)
pairs(p02)
p05 &lt;- bundestag(2005)
pairs(p05)
p09 &lt;- bundestag(2009)
pairs(p09)

state &lt;- bundestag(2002, state=TRUE)
table(state)

start.with.b &lt;- bundestag(2002, state="^B")
table(start.with.b)

pairs(p09, col=2-(state=="Bayern"))
</code></pre>

<hr>
<h2 id='bwplot-methods'>Box-Whisker Plot Methods in Package &lsquo;flexclust&rsquo;</h2><span id='topic+bwplot+2Ckcca-method'></span><span id='topic+bwplot+2Ckccasimple-method'></span><span id='topic+bwplot+2Cbclust-method'></span>

<h3>Description</h3>

<p>Seperate boxplot of variables in each cluster in comparison with
boxplot for complete sample.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'kcca'
bwplot(x, data, xlab="",
       strip.labels=NULL, strip.prefix="Cluster ",
       col=NULL, shade=!is.null(shadefun), shadefun=NULL, byvar=FALSE, ...)
## S4 method for signature 'bclust'
bwplot(x, k=x@k, xlab="", strip.labels=NULL, 
       strip.prefix="Cluster ", clusters=1:k, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="bwplot-methods_+3A_x">x</code></td>
<td>
<p>An object of class <code>"kcca"</code> or <code>"bclust"</code>.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_data">data</code></td>
<td>
<p>If not <code>NULL</code>, cluster membership is predicted for
the new data and used for the plots. By default the
values from the training data are used.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_xlab">xlab</code>, <code id="bwplot-methods_+3A_...">...</code></td>
<td>
<p>Graphical parameters.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_col">col</code></td>
<td>
<p>Vector of colors for the clusters.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_strip.labels">strip.labels</code></td>
<td>
<p>Vector of strings for the strips of the Trellis
display.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_strip.prefix">strip.prefix</code></td>
<td>
<p>Prefix string for the strips of the Trellis
display.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_shade">shade</code></td>
<td>
<p>If <code>TRUE</code>, only boxes with larger 
deviation from the median or quartiles of the total
population of the respective variables are filled with color.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_shadefun">shadefun</code></td>
<td>
<p>A function or name of a function to compute which
boxes are shaded, e.g. <code>"medianInside"</code> (default)
or <code>"boxOverlap"</code>.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_byvar">byvar</code></td>
<td>
<p>If <code>TRUE</code>, a panel is plotted for each variable. By
default a panel is plotted for each group.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_k">k</code></td>
<td>
<p>Number of clusters.</p>
</td></tr>
<tr><td><code id="bwplot-methods_+3A_clusters">clusters</code></td>
<td>
<p>Integer vector of clusters to plot.</p>
</td></tr>
</table>


<h3>Examples</h3>

<pre><code class='language-R'>  set.seed(1)
  cl &lt;- cclust(iris[,-5], k=3, save.data=TRUE)
  bwplot(cl)
  bwplot(cl, byvar=TRUE)

  ## fill only boxes with color which do not contain the overall median
  ## (grey dot of background box)
  bwplot(cl, shade=TRUE)

  ## fill only boxes with color which do not overlap with the box of the
  ## complete sample (grey background box)
  bwplot(cl, shadefun="boxOverlap")
</code></pre>

<hr>
<h2 id='cclust'>Convex Clustering</h2><span id='topic+cclust'></span>

<h3>Description</h3>

<p>Perform k-means clustering, hard competitive learning or neural gas on
a data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>cclust(x, k, dist = "euclidean", method = "kmeans",
       weights=NULL, control=NULL, group=NULL, simple=FALSE,
       save.data=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="cclust_+3A_x">x</code></td>
<td>
<p>A numeric matrix of data, or an object that can be coerced to
such a matrix (such as a numeric vector or a data frame with all
numeric columns).</p>
</td></tr>
<tr><td><code id="cclust_+3A_k">k</code></td>
<td>
<p>Either the number of clusters, or a vector of cluster
assignments, or a matrix of initial
(distinct) cluster centroids.  If a number, a random set of (distinct)
rows in <code>x</code> is chosen as the initial centroids.</p>
</td></tr>
<tr><td><code id="cclust_+3A_dist">dist</code></td>
<td>
<p>Distance measure, one of <code>"euclidean"</code> (mean square
distance) or <code>"manhattan "</code> (absolute distance).</p>
</td></tr>
<tr><td><code id="cclust_+3A_method">method</code></td>
<td>
<p>Clustering algorithm: one of <code>"kmeans"</code>,
<code>"hardcl"</code> or <code>"neuralgas"</code>, see details below.</p>
</td></tr>
<tr><td><code id="cclust_+3A_weights">weights</code></td>
<td>
<p>An optional vector of weights for the observations
(rows of the <code>x</code>) to be used in the fitting
process. Works only in combination with hard competitive learning.</p>
</td></tr>
<tr><td><code id="cclust_+3A_control">control</code></td>
<td>
<p>An object of class <code>"cclustControl"</code>.</p>
</td></tr>
<tr><td><code id="cclust_+3A_group">group</code></td>
<td>
<p>Currently ignored.</p>
</td></tr>
<tr><td><code id="cclust_+3A_simple">simple</code></td>
<td>
<p>Return an object of class <code>"kccasimple"</code>?</p>
</td></tr>
<tr><td><code id="cclust_+3A_save.data">save.data</code></td>
<td>
<p>Save a copy of <code>x</code> in the return object?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function uses the same computational engine as the earlier
function of the same name from package &lsquo;cclust&rsquo;. The main difference
is that it returns an S4 object of class <code>"kcca"</code>, hence all
available methods for <code>"kcca"</code> objects can be used. By default
<code><a href="#topic+kcca">kcca</a></code> and <code>cclust</code> use exactly the same algorithm,
but <code>cclust</code> will usually be much faster because it uses compiled
code.
</p>
<p>If <code>dist</code> is <code>"euclidean"</code>, the distance between the cluster
center and the data points is the Euclidian distance (ordinary kmeans
algorithm), and cluster means are used as centroids.
If <code>"manhattan"</code>, the distance between the cluster
center and the data points is the sum of the absolute values of the
distances, and the column-wise cluster medians are used as centroids.
</p>
<p>If <code>method</code> is <code>"kmeans"</code>, the classic kmeans algorithm as
given by MacQueen (1967) is
used, which works by repeatedly moving all cluster
centers to the mean of their respective Voronoi sets. If
<code>"hardcl"</code>,
on-line updates are used (AKA hard competitive learning), which work by
randomly drawing an observation from <code>x</code> and moving the closest
center towards that point (e.g., Ripley 1996). If
<code>"neuralgas"</code> then the  neural gas algorithm by Martinetz et al
(1993) is used. It is similar to hard competitive learning, but in
addition to the closest centroid also the second closest centroid is
moved in each iteration.
</p>


<h3>Value</h3>

<p>An object of class <code>"kcca"</code>.
</p>


<h3>Author(s)</h3>

<p>Evgenia Dimitriadou and Friedrich Leisch</p>


<h3>References</h3>

<p>MacQueen, J. (1967).  Some methods for classification and analysis of
multivariate observations. In <em>Proceedings of the Fifth Berkeley
Symposium on  Mathematical Statistics and  Probability</em>,
eds L. M. Le Cam &amp; J. Neyman, 1, pp. 281&ndash;297. Berkeley, CA:
University of California Press.
</p>
<p>Martinetz T., Berkovich S., and Schulten K (1993). &lsquo;Neural-Gas&rsquo;
Network for Vector Quantization and its Application to Time-Series
Prediction. IEEE Transactions on Neural Networks, 4 (4), pp. 558&ndash;569.
</p>
<p>Ripley, B. D. (1996)
<em>Pattern Recognition and Neural Networks.</em> Cambridge.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+cclustControl-class">cclustControl-class</a></code>, <code><a href="#topic+kcca">kcca</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## a 2-dimensional example
x &lt;- rbind(matrix(rnorm(100, sd=0.3), ncol=2),
           matrix(rnorm(100, mean=1, sd=0.3), ncol=2))
cl &lt;- cclust(x,2)
plot(x, col=predict(cl))
points(cl@centers, pch="x", cex=2, col=3) 

## a 3-dimensional example 
x &lt;- rbind(matrix(rnorm(150, sd=0.3), ncol=3),
           matrix(rnorm(150, mean=2, sd=0.3), ncol=3),
           matrix(rnorm(150, mean=4, sd=0.3), ncol=3))
cl &lt;- cclust(x, 6, method="neuralgas", save.data=TRUE)
pairs(x, col=predict(cl))
plot(cl)
</code></pre>

<hr>
<h2 id='clusterSim'>Cluster Similarity Matrix</h2><span id='topic+clusterSim'></span><span id='topic+clusterSim+2Ckcca-method'></span><span id='topic+clusterSim+2Ckccasimple-method'></span>

<h3>Description</h3>

<p>Returns a matrix of cluster similarities. Currently two methods for
computing similarities of clusters are implemented, see details below.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'kcca'
clusterSim(object, data=NULL, method=c("shadow", "centers"), 
           symmetric=FALSE, ...)
## S4 method for signature 'kccasimple'
clusterSim(object, data=NULL, method=c("shadow", "centers"), 
           symmetric=FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="clusterSim_+3A_object">object</code></td>
<td>
<p>Fitted object.</p>
</td></tr>
<tr><td><code id="clusterSim_+3A_data">data</code></td>
<td>
<p>Data to use for computation of the shadow values. If
the cluster object <code>x</code> was created with <code>save.data=TRUE</code>,
then these are used by default. Ignored if <code>method="centers"</code>.</p>
</td></tr>
<tr><td><code id="clusterSim_+3A_method">method</code></td>
<td>
<p>Type of similarities, see details below.</p>
</td></tr>
<tr><td><code id="clusterSim_+3A_symmetric">symmetric</code></td>
<td>
<p>Compute symmetric or asymmetric shadow values?
Ignored if <code>method="centers"</code>.</p>
</td></tr>
<tr><td><code id="clusterSim_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>method="shadow"</code> (the default), then the similarity of two
clusters is proportional to the number of points in a cluster, where
the centroid of the other cluster is second-closest. See Leisch (2006,
2008) for detailed formulas.
</p>
<p>If <code>method="centers"</code>, then first the pairwise distances between
all centroids are computed and rescaled to [0,1]. The similarity
between tow clusters is then simply 1 minus the rescaled distance.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Friedrich Leisch. A Toolbox for K-Centroids Cluster Analysis.
Computational Statistics and Data Analysis, 51 (2), 526&ndash;544, 2006.
</p>
<p>Friedrich Leisch. Visualizing cluster analysis and finite mixture
models. In Chun houh Chen, Wolfgang Haerdle, and Antony Unwin, editors,
Handbook of Data Visualization, Springer Handbooks of Computational
Statistics. Springer Verlag, 2008.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>example(Nclus)

clusterSim(cl)
clusterSim(cl, symmetric=TRUE)

## should have similar structure but will be numerically different:
clusterSim(cl, symmetric=TRUE, data=Nclus[sample(1:550, 200),])

## different concept of cluster similarity
clusterSim(cl, method="centers")
</code></pre>

<hr>
<h2 id='conversion'>Conversion Between S3 Partition Objects and KCCA</h2><span id='topic+as.kcca'></span><span id='topic+as.kcca.hclust'></span><span id='topic+as.kcca.kmeans'></span><span id='topic+as.kcca.partition'></span><span id='topic+as.kcca.skmeans'></span><span id='topic+coerce+2Ckccasimple+2Ckmeans-method'></span><span id='topic+Cutree'></span>

<h3>Description</h3>

<p>These functions can be used to convert the results from cluster
functions like
<code><a href="stats.html#topic+kmeans">kmeans</a></code> or <code><a href="cluster.html#topic+pam">pam</a></code> to objects
of class <code>"kcca"</code> and vice versa.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>as.kcca(object, ...)

## S3 method for class 'hclust'
as.kcca(object, data, k, family=NULL, save.data=FALSE, ...)
## S3 method for class 'kmeans'
as.kcca(object, data, save.data=FALSE, ...)
## S3 method for class 'partition'
as.kcca(object, data=NULL, save.data=FALSE, ...)
## S3 method for class 'skmeans'
as.kcca(object, data, save.data=FALSE, ...)
## S4 method for signature 'kccasimple,kmeans'
coerce(from, to="kmeans", strict=TRUE)

Cutree(tree, k=NULL, h=NULL)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="conversion_+3A_object">object</code></td>
<td>
<p>Fitted object.</p>
</td></tr>
<tr><td><code id="conversion_+3A_data">data</code></td>
<td>
<p>Data which were used to obtain the clustering. For
<code>"partition"</code> objects
created by functions from package cluster this is optional, if
<code>object</code> contains the data.</p>
</td></tr>
<tr><td><code id="conversion_+3A_save.data">save.data</code></td>
<td>
<p>Save a copy of the data in the return object?</p>
</td></tr>
<tr><td><code id="conversion_+3A_k">k</code></td>
<td>
<p>Number of clusters.</p>
</td></tr>
<tr><td><code id="conversion_+3A_family">family</code></td>
<td>
<p>Object of class <code>"kccaFamily"</code>, can be omitted for
some known distances.</p>
</td></tr>
<tr><td><code id="conversion_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
<tr><td><code id="conversion_+3A_from">from</code>, <code id="conversion_+3A_to">to</code>, <code id="conversion_+3A_strict">strict</code></td>
<td>
<p>Usual arguments for <code><a href="methods.html#topic+coerce">coerce</a></code></p>
</td></tr>
<tr><td><code id="conversion_+3A_tree">tree</code></td>
<td>
<p>A tree as produced by <code><a href="stats.html#topic+hclust">hclust</a></code>.</p>
</td></tr>
<tr><td><code id="conversion_+3A_h">h</code></td>
<td>
<p>Numeric scalar or vector with heights where the tree should
be cut.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The standard <code><a href="stats.html#topic+cutree">cutree</a></code> function orders clusters such that
observation one is in cluster one, the first observation (as ordered
in the data set) not in cluster one is in cluster two,
etc. <code>Cutree</code> orders clusters as shown in the dendrogram from
left to right such that similar clusters have similar numbers. The
latter is used when converting to <code>kcca</code>. 
</p>
<p>For hierarchical clustering the cluster memberships of the converted
object can be different from the result of <code>Cutree</code>,
because one KCCA-iteration has to be performed in order to obtain a
valid <code>kcca</code> object. In this case a warning is issued.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Nclus)

cl1 &lt;- kmeans(Nclus, 4)
cl1
cl1a &lt;- as.kcca(cl1, Nclus)
cl1a
cl1b &lt;- as(cl1a, "kmeans")



library("cluster")
cl2 &lt;- pam(Nclus, 4)
cl2
cl2a &lt;- as.kcca(cl2)
cl2a
## the same
cl2b &lt;- as.kcca(cl2, Nclus)
cl2b



## hierarchical clustering
hc &lt;- hclust(dist(USArrests))
plot(hc)
rect.hclust(hc, k=3)
c3 &lt;- Cutree(hc, k=3)
k3 &lt;- as.kcca(hc, USArrests, k=3)
barchart(k3)
table(c3, clusters(k3))
</code></pre>

<hr>
<h2 id='dentitio'>Dentition of Mammals</h2><span id='topic+dentitio'></span>

<h3>Description</h3>

<p>Mammal's teeth divided into the 4 groups: incisors, canines, premolars
and molars. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(dentitio)</code></pre>


<h3>Format</h3>

<p>A data frame with 66 observations on the following 8 variables.
</p>

<dl>
<dt><code>top.inc</code></dt><dd><p>Top incisors.</p>
</dd>
<dt><code>bot.inc</code></dt><dd><p>Bottom incisors.</p>
</dd>
<dt><code>top.can</code></dt><dd><p>Top canines.</p>
</dd>
<dt><code>bot.can</code></dt><dd><p>Bottom canines.</p>
</dd>
<dt><code>top.pre</code></dt><dd><p>Top premolars.</p>
</dd>
<dt><code>bot.pre</code></dt><dd><p>Bottom premolars.</p>
</dd>
<dt><code>top.mol</code></dt><dd><p>Top molars.</p>
</dd>
<dt><code>bot.mol</code></dt><dd><p>Bottom molars.</p>
</dd>
</dl>



<h3>References</h3>

<p>John A. Hartigan: Clustering Algorithms. Wiley, New York, 1975.
</p>

<hr>
<h2 id='dist2'>Compute Pairwise Distances Between Two Data sets</h2><span id='topic+dist2'></span>

<h3>Description</h3>

<p>This function computes and returns the distance matrix computed by
using the specified distance measure to compute the pairwise distances
between the rows of two data matrices.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dist2(x, y, method = "euclidean", p=2)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="dist2_+3A_x">x</code></td>
<td>
<p>A data matrix.</p>
</td></tr>
<tr><td><code id="dist2_+3A_y">y</code></td>
<td>
<p>A vector or second data matrix.</p>
</td></tr>
<tr><td><code id="dist2_+3A_method">method</code></td>
<td>
<p>the distance measure to be used. This must be one of
<code>"euclidean"</code>, <code>"maximum"</code>, <code>"manhattan"</code>,
<code>"canberra"</code>, <code>"binary"</code> or <code>"minkowski"</code>. Any
unambiguous substring can be given.</p>
</td></tr>
<tr><td><code id="dist2_+3A_p">p</code></td>
<td>
<p>The power of the Minkowski distance.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This is a two-data-set equivalent of the standard function
<code><a href="stats.html#topic+dist">dist</a></code>. It returns a matrix of all pairwise
distances between rows in <code>x</code> and <code>y</code>. The current
implementation is efficient only if <code>y</code> has not too many
rows (the code is vectorized in <code>x</code> but not in <code>y</code>).
</p>


<h3>Note</h3>

<p>The definition of Canberra distance was wrong for negative data
prior to version 1.3-5.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>See Also</h3>

<p><code><a href="stats.html#topic+dist">dist</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(20), ncol=4)
rownames(x) = paste("X", 1:nrow(x), sep=".")
y &lt;- matrix(rnorm(12), ncol=4)
rownames(y) = paste("Y", 1:nrow(y), sep=".")

dist2(x, y)
dist2(x, y, "man")

data(milk)
dist2(milk[1:5,], milk[4:6,])
</code></pre>

<hr>
<h2 id='distances'>Distance and Centroid Computation</h2><span id='topic+distances'></span><span id='topic+centAngle'></span><span id='topic+centMean'></span><span id='topic+centMedian'></span><span id='topic+centOptim01'></span><span id='topic+centOptim'></span><span id='topic+distAngle'></span><span id='topic+distCanberra'></span><span id='topic+distCor'></span><span id='topic+distEuclidean'></span><span id='topic+distJaccard'></span><span id='topic+distManhattan'></span><span id='topic+distMax'></span><span id='topic+distMinkowski'></span>

<h3>Description</h3>

<p>Helper functions to create <code><a href="#topic+kccaFamily">kccaFamily</a></code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>distAngle(x, centers)
distCanberra(x, centers)
distCor(x, centers)
distEuclidean(x, centers)
distJaccard(x, centers)
distManhattan(x, centers)
distMax(x, centers)
distMinkowski(x, centers, p=2)

centAngle(x)
centMean(x)
centMedian(x)

centOptim(x, dist)
centOptim01(x, dist)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="distances_+3A_x">x</code></td>
<td>
<p>A data matrix.</p>
</td></tr>
<tr><td><code id="distances_+3A_centers">centers</code></td>
<td>
<p>A matrix of centroids.</p>
</td></tr>
<tr><td><code id="distances_+3A_p">p</code></td>
<td>
<p>The power of the Minkowski distance.</p>
</td></tr>
<tr><td><code id="distances_+3A_dist">dist</code></td>
<td>
<p>A distance function.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>

<hr>
<h2 id='flexclustControl-class'>Classes &quot;flexclustControl&quot; and &quot;cclustControl&quot;</h2><span id='topic+cclustControl'></span><span id='topic+flexclustControl'></span><span id='topic+flexclustControl-class'></span><span id='topic+coerce+2Clist+2CflexclustControl-method'></span><span id='topic+coerce+2CNULL+2CflexclustControl-method'></span><span id='topic+cclustControl-class'></span><span id='topic+coerce+2Clist+2CcclustControl-method'></span><span id='topic+coerce+2CNULL+2CcclustControl-method'></span>

<h3>Description</h3>

<p>Hyperparameters for cluster algorithms.</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form
<code>new("flexclustControl", ...)</code>. In addition, named lists can be
coerced to <code>flexclustControl</code>
objects, names are completed if unique (see examples).
</p>


<h3>Slots</h3>

<p>Objects of class <code>"flexclustControl"</code> have the following slots:
</p>

<dl>
<dt><code>iter.max</code>:</dt><dd><p>Maximum number of iterations.</p>
</dd>
<dt><code>tolerance</code>:</dt><dd><p>The algorithm is stopped when the
(relative) change of the optimization criterion is smaller than
<code>tolerance</code>.</p>
</dd>
<dt><code>verbose</code>:</dt><dd><p>If a positive integer, then progress is
reported every <code>verbose</code> iterations. If 0,
no output is generated during model fitting.</p>
</dd>
<dt><code>classify</code>:</dt><dd><p>Character string, one of <code>"auto"</code>,
<code>"weighted"</code>, <code>"hard"</code> or <code>"simann"</code>.</p>
</dd>
<dt><code>initcent</code>:</dt><dd><p>Character string, name of function for
initial centroids, currently <code>"randomcent"</code> (the default) and
<code>"kmeanspp"</code> are available.</p>
</dd>
<dt><code>gamma</code>:</dt><dd><p>Gamma value for weighted hard competitive
learning.</p>
</dd>
<dt><code>simann</code>:</dt><dd><p>Parameters for simulated annealing
optimization (only used when <code>classify="simann"</code>).</p>
</dd>
<dt><code>ntry</code>:</dt><dd><p>Number of trials per iteration for QT clustering.</p>
</dd>
<dt><code>min.size</code>:</dt><dd><p>Clusters smaller than this value are treated
as outliers.</p>
</dd>
</dl>

<p>Objects of class <code>"cclustControl"</code> inherit from
<code>"flexclustControl"</code> and have the following additional slots:
</p>

<dl>
<dt><code>method</code>:</dt><dd><p>Learning rate for hard competitive learning,
one of <code>"polynomial"</code> or <code>"exponential"</code>.</p>
</dd>
<dt><code>pol.rate</code>:</dt><dd><p>Positive number for polynomial learning rate
of form <code class="reqn">1/iter^{par}</code>.</p>
</dd>
<dt><code>exp.rate</code></dt><dd><p>Vector of length 2 with parameters for
exponential learning rate of form
<code class="reqn">par1*(par2/par1)^{(iter/iter.max)}</code></p>
</dd></dl>
<p>.
</p>
<dl>
<dt><code>ng.rate</code>:</dt><dd><p>Vector of length 4 with parameters for neural
gas, see details below.</p>
</dd>
</dl>



<h3>Learning Rate of Neural Gas</h3>

<p>The neural gas algorithm uses updates of form
</p>
<p style="text-align: center;"><code class="reqn">cnew = cold + e*exp(-m/l)*(x - cold)</code>
</p>

<p>for every centroid, where <code class="reqn">m</code> is the order (minus 1) of the
centroid with
respect to distance to data point <code class="reqn">x</code> (0=closest, 1=second,
...). The parameters <code class="reqn">e</code> and <code class="reqn">l</code> are given by
</p>
<p style="text-align: center;"><code class="reqn">e = par1*(par2/par1)^{(iter/iter.max)},</code>
</p>

<p style="text-align: center;"><code class="reqn">l = par3*(par4/par3)^{(iter/iter.max)}.</code>
</p>

<p>See Martinetz et al (1993) for details of the algorithm, and the
examples section on how to obtain default values.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Martinetz T., Berkovich S., and Schulten K. (1993). &quot;Neural-Gas
Network for Vector Quantization and its Application to Time-Series
Prediction.&quot; IEEE Transactions on Neural Networks, 4 (4), pp. 558&ndash;569.
</p>
<p>Arthur D. and Vassilvitskii S. (2007). &quot;k-means++: the advantages of
careful seeding&quot;. Proceedings of the 18th annual ACM-SIAM symposium on
Discrete algorithms. pp. 1027-1035.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+kcca">kcca</a></code>, <code><a href="#topic+cclust">cclust</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## have a look at the defaults
new("flexclustControl")

## corce a list
mycont &lt;- list(iter=500, tol=0.001, class="w")
as(mycont, "flexclustControl")

## some additional slots
as(mycont, "cclustControl")

## default values for ng.rate
new("cclustControl")@ng.rate
</code></pre>

<hr>
<h2 id='flxColors'>Flexclust Color Palettes</h2><span id='topic+flxColors'></span><span id='topic+flxPalette'></span>

<h3>Description</h3>

<p>Create and access palettes for the plot methods.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  flxColors(n=1:8, color=c("full","medium", "light","dark"), grey=FALSE)
  flxPalette(n, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="flxColors_+3A_n">n</code></td>
<td>
<p>Index number of color to return (1 to 8) for <code>flxColor</code>,
number of colors to return for <code>flxPalette()</code>.</p>
</td></tr>
<tr><td><code id="flxColors_+3A_color">color</code></td>
<td>
<p>Type of color, see details.</p>
</td></tr>
<tr><td><code id="flxColors_+3A_grey">grey</code></td>
<td>
<p>Return grey value corresponding to palette.</p>
</td></tr>
<tr><td><code id="flxColors_+3A_...">...</code></td>
<td>
<p>Passed on to <code>flxColors()</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function creates color palettes in HCL space for up to 8
colors. All palettes have constant chroma and luminance, only the hue
of the colors change within a palette.
</p>
<p>Palettes <code>"full"</code> and <code>"dark"</code> have the same luminance, and
palettes <code>"medium"</code> and <code>"light"</code> have the same luminance.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>See Also</h3>

<p><code><a href="grDevices.html#topic+hcl">hcl</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>opar &lt;- par(c("mfrow", "mar", "xaxt"))
par(mfrow=c(2, 2), mar=c(0, 0, 2, 0), yaxt="n")

x &lt;- rep(1, 8)

barplot(x, col = flxColors(color="full"), main="full")
barplot(x, col = flxColors(color="dark"), main="dark")
barplot(x, col = flxColors(color="medium"), main="medium")
barplot(x, col = flxColors(color="light"), main="light")

par(opar)
</code></pre>

<hr>
<h2 id='histogram-methods'>Methods for Function histogram in Package &lsquo;flexclust&rsquo;</h2><span id='topic+histogram+2Ckccasimple+2Cmissing-method'></span><span id='topic+histogram+2Ckccasimple+2Cdata.frame-method'></span><span id='topic+histogram+2Ckccasimple+2Cmatrix-method'></span>

<h3>Description</h3>

<p>Plot a histogram of the similarity of each observation to each
cluster. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'kccasimple,missing'
histogram(x, data, xlab="", ...)
## S4 method for signature 'kccasimple,data.frame'
histogram(x, data, xlab="", ...)
## S4 method for signature 'kccasimple,matrix'
histogram(x, data, xlab="Similarity",
          power=1, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="histogram-methods_+3A_x">x</code></td>
<td>
<p>An object of class <code>"kccasimple"</code>.</p>
</td></tr>
<tr><td><code id="histogram-methods_+3A_data">data</code></td>
<td>
<p>If not missing, the distance and thus similarity
between observations and cluster centers is determined for
the new data and used for the plots. By default the values
from the training data are used.</p>
</td></tr>
<tr><td><code id="histogram-methods_+3A_xlab">xlab</code></td>
<td>
<p>Label for the x-axis.</p>
</td></tr>
<tr><td><code id="histogram-methods_+3A_power">power</code></td>
<td>
<p>Numeric indicating how similarities are transformed, for
more details see Dolnicar et al. (2018).</p>
</td></tr>
<tr><td><code id="histogram-methods_+3A_...">...</code></td>
<td>
<p>Additional arguments passed to
<code><a href="lattice.html#topic+histogram">histogram</a></code>.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Dolnicar S., Gruen B., and Leisch F. (2018) Market Segmentation
Analysis: Understanding It, Doing It, and Making It Useful. Springer
Singapore.
</p>

<hr>
<h2 id='image-methods'>Methods for Function image in Package &lsquo;flexclust&rsquo;</h2><span id='topic+image+2Ckcca-method'></span><span id='topic+image+2Ckccasimple-method'></span>

<h3>Description</h3>

<p>Image plot of cluster segments overlaid by neighbourhood graph.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'kcca'
image(x, which = 1:2, npoints = 100,
         xlab = "", ylab = "", fastcol = TRUE, col=NULL,
         clwd=0, graph=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="image-methods_+3A_x">x</code></td>
<td>
<p>An object of class <code>"kcca"</code>.</p>
</td></tr>
<tr><td><code id="image-methods_+3A_which">which</code></td>
<td>
<p>Index number of dimensions of input space to plot.</p>
</td></tr>
<tr><td><code id="image-methods_+3A_npoints">npoints</code></td>
<td>
<p>Number of grid points for image.</p>
</td></tr>
<tr><td><code id="image-methods_+3A_fastcol">fastcol</code></td>
<td>
<p>If <code>TRUE</code>, a greedy algorithm is used for the
background colors of the segments, which may result in neighbouring
segments having the same color. If <code>FALSE</code>, neighbouring
segments always have different colors at a speed penalty.</p>
</td></tr>
<tr><td><code id="image-methods_+3A_col">col</code></td>
<td>
<p>Vector of background colors for the segments.</p>
</td></tr>
<tr><td><code id="image-methods_+3A_clwd">clwd</code></td>
<td>
<p>Line width of contour lines at cluster boundaries, use
larger values for <code>npoints</code> than the default to get smooth
lines. (Warning: We really need a smarter way to draw cluster
boundaries!)</p>
</td></tr>
<tr><td><code id="image-methods_+3A_graph">graph</code></td>
<td>
<p>Logical, add a neighborhood graph to the plot?</p>
</td></tr>
<tr><td><code id="image-methods_+3A_xlab">xlab</code>, <code id="image-methods_+3A_ylab">ylab</code>, <code id="image-methods_+3A_...">...</code></td>
<td>
<p>Graphical parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This works only for <code>"kcca"</code> objects, no method is available for
&quot;kccasimple&quot; objects.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>See Also</h3>

<p><code><a href="#topic+kcca">kcca</a></code>
</p>

<hr>
<h2 id='info'>Get Information on Fitted Flexclust Objects</h2><span id='topic+info+2Cflexclust+2Ccharacter-method'></span>

<h3>Description</h3>

<p>Returns descriptive information about fitted flexclust objects like
cluster sizes or sum of within-cluster distances.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'flexclust,character'
info(object, which, drop=TRUE, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="info_+3A_object">object</code></td>
<td>
<p>Fitted object.</p>
</td></tr>
<tr><td><code id="info_+3A_which">which</code></td>
<td>
<p>Which information to get. Use <code>which="help"</code> to list
available information.</p>
</td></tr>
<tr><td><code id="info_+3A_drop">drop</code></td>
<td>
<p>Logical. If <code>TRUE</code> the result is coerced to the lowest
possible dimension.</p>
</td></tr>
<tr><td><code id="info_+3A_...">...</code></td>
<td>
<p>Passed to methods.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>info</code> can be used to access slots of fitted flexclust
objects in a portable way, and in addition computes some
meta-information like sum of within-cluster distances.
</p>
<p>Function <code><a href="modeltools.html#topic+infoCheck">infoCheck</a></code> returns a logical value that is <code>TRUE</code>
if the requested information can be computed from the <code>object</code>.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>See Also</h3>

<p><code><a href="modeltools.html#topic+info">info</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Nclus")
plot(Nclus)

cl1 &lt;- cclust(Nclus, k=4)
summary(cl1)

## these two are the same
info(cl1)
info(cl1, "help")

## cluster sizes
i1 &lt;- info(cl1, "size")
i1

## average within cluster distances
i2 &lt;- info(cl1, "av_dist")
i2

## the sum of all within-cluster distances
i3 &lt;- info(cl1, "distsum")
i3

## sum(i1*i2) must of course be the same as i3
stopifnot(all.equal(sum(i1*i2), i3))



## This should return TRUE
modeltools::infoCheck(cl1, "size")
## and this FALSE
modeltools::infoCheck(cl1, "Homer Simpson")
## both combined
i4 &lt;- modeltools::infoCheck(cl1, c("size", "Homer Simpson"))
i4

stopifnot(all.equal(i4, c(TRUE, FALSE)))
</code></pre>

<hr>
<h2 id='kcca'>K-Centroids Cluster Analysis</h2><span id='topic+kcca'></span><span id='topic+kccaFamily'></span><span id='topic+flexclust-class'></span><span id='topic+kcca-class'></span><span id='topic+kccasimple-class'></span><span id='topic+kccaFamily-class'></span><span id='topic+show+2Ckccasimple-method'></span><span id='topic+summary+2Ckccasimple-method'></span>

<h3>Description</h3>

<p>Perform k-centroids clustering on a data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kcca(x, k, family=kccaFamily("kmeans"), weights=NULL,
     group=NULL, control=NULL, simple=FALSE, save.data=FALSE)
kccaFamily(which=NULL, dist=NULL, cent=NULL, name=which, preproc = NULL,
           genDist=NULL, trim=0, groupFun = "minSumClusters")

## S4 method for signature 'kccasimple'
summary(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kcca_+3A_x">x</code></td>
<td>
<p>A numeric matrix of data, or an object that can be coerced to
such a matrix using <a href="base.html#topic+data.matrix">data.matrix</a>.</p>
</td></tr>
<tr><td><code id="kcca_+3A_k">k</code></td>
<td>
<p>Either the number of clusters, or a vector of cluster
assignments, or a matrix of initial
(distinct) cluster centroids.  If a number, a random set of (distinct)
rows in <code>x</code> is chosen as the initial centroids.</p>
</td></tr>
<tr><td><code id="kcca_+3A_family">family</code></td>
<td>
<p>Object of class <code>"kccaFamily"</code>.</p>
</td></tr>
<tr><td><code id="kcca_+3A_weights">weights</code></td>
<td>
<p>An optional vector of weights to be used in the clustering
process, cannot be combined with all families.</p>
</td></tr>
<tr><td><code id="kcca_+3A_group">group</code></td>
<td>
<p>An optional grouping vector for the data, see details
below.</p>
</td></tr>
<tr><td><code id="kcca_+3A_control">control</code></td>
<td>
<p>An object of class <code>"flexclustControl"</code>.</p>
</td></tr>
<tr><td><code id="kcca_+3A_simple">simple</code></td>
<td>
<p>Return an object of class <code>"kccasimple"</code>?</p>
</td></tr>
<tr><td><code id="kcca_+3A_save.data">save.data</code></td>
<td>
<p>Save a copy of <code>x</code> in the return object?</p>
</td></tr>
<tr><td><code id="kcca_+3A_which">which</code></td>
<td>
<p>One of <code>"kmeans"</code>, <code>"kmedians"</code>,
<code>"angle"</code>, <code>"jaccard"</code>, or <code>"ejaccard"</code>.</p>
</td></tr>
<tr><td><code id="kcca_+3A_name">name</code></td>
<td>
<p>Optional long name for family, used only for show methods.</p>
</td></tr>
<tr><td><code id="kcca_+3A_dist">dist</code></td>
<td>
<p>A function for distance computation, ignored
if <code>which</code> is specified.</p>
</td></tr>
<tr><td><code id="kcca_+3A_cent">cent</code></td>
<td>
<p>A function for centroid computation, ignored
if <code>which</code> is specified.</p>
</td></tr>
<tr><td><code id="kcca_+3A_preproc">preproc</code></td>
<td>
<p>Function for data preprocessing. Defaults to
<code>function(x) x</code>.</p>
</td></tr>
<tr><td><code id="kcca_+3A_gendist">genDist</code></td>
<td>
<p>Function for updating the family object based on
<code>x</code>.</p>
</td></tr>
<tr><td><code id="kcca_+3A_trim">trim</code></td>
<td>
<p>A number in between 0 and 0.5, if non-zero then trimmed
means are used for the <code>kmeans</code> family, ignored by all other
families.</p>
</td></tr>
<tr><td><code id="kcca_+3A_groupfun">groupFun</code></td>
<td>
<p>Function or name of function to obtain clusters for
grouped data, see details below.</p>
</td></tr>
<tr><td><code id="kcca_+3A_object">object</code></td>
<td>
<p>Object of class <code>"kcca"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>See the paper <em>A Toolbox for K-Centroids Cluster Analysis</em>
referenced below for details.
</p>


<h3>Value</h3>

<p>Function <code>kcca</code> returns objects of class <code>"kcca"</code> or
<code>"kccasimple"</code> depending on the value of argument
<code>simple</code>. The simpler objects contain fewer slots and hence are
faster to compute, but contain no auxiliary information used by the
plotting methods. Most plot methods for <code>"kccasimple"</code> objects do
nothing and return a warning. If only centroids, cluster membership or
prediction for new data are of interest, then the simple objects are
sufficient.
</p>


<h3>Predefined Families</h3>

<p>Function <code>kccaFamily()</code> currently has the following predefined
families (distance / centroid):
</p>

<dl>
<dt>kmeans:</dt><dd><p>Euclidean distance / mean</p>
</dd>
<dt>kmedians:</dt><dd><p>Manhattan distance / median</p>
</dd>
<dt>angle:</dt><dd><p>angle between observation and centroid / standardized
mean</p>
</dd>
<dt>jaccard:</dt><dd><p>Jaccard distance / numeric optimization</p>
</dd>
<dt>ejaccard:</dt><dd><p>Jaccard distance / mean</p>
</dd>
</dl>

<p>See Leisch (2006) for details on all combinations.
</p>


<h3>Group Constraints</h3>

  
<p>If <code>group</code> is not <code>NULL</code>, then observations from the same
group are restricted to belong to the same cluster (must-link
constraint) or different clusters (cannot-link constraint) during the
fitting process. If <code>groupFun = "minSumClusters"</code>, then all group
members are 
assign to the cluster where the center has minimal average distance to
the group members. If <code>groupFun = "majorityClusters"</code>, then all
group members are assigned to the cluster the majority would belong to
without a constraint. 
</p>
<p><code>groupFun = "differentClusters"</code> implements a cannot-link
constraint, i.e., members of one group are not allowed to belong to
the same cluster. The optimal allocation for each group is found by
solving a linear sum assignment problem using
<code><a href="clue.html#topic+solve_LSAP">solve_LSAP</a></code>. Obviously the group sizes must be smaller
than the number of clusters in this case.
</p>
<p>Ties are broken at random in all cases.
Note that at the moment not all methods for fitted
<code>"kcca"</code> objects respect the grouping information, most
importantly the plot method when a data argument is specified. 
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Friedrich Leisch. A Toolbox for K-Centroids Cluster Analysis.
Computational Statistics and Data Analysis, 51 (2), 526&ndash;544, 2006.
</p>
<p>Friedrich Leisch and Bettina Gruen. Extending standard cluster
algorithms to allow for group constraints. In Alfredo Rizzi and
Maurizio Vichi, editors, Compstat 2006-Proceedings in Computational
Statistics, pages 885-892. Physica Verlag, Heidelberg, Germany, 2006.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stepFlexclust">stepFlexclust</a></code>, <code><a href="#topic+cclust">cclust</a></code>,
<code><a href="#topic+distances">distances</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Nclus")
plot(Nclus)

## try kmeans 
cl1 &lt;- kcca(Nclus, k=4)
cl1

image(cl1)
points(Nclus)

## A barplot of the centroids 
barplot(cl1)


## now use k-medians and kmeans++ initialization, cluster centroids
## should be similar...

cl2 &lt;- kcca(Nclus, k=4, family=kccaFamily("kmedians"),
           control=list(initcent="kmeanspp"))
cl2

## ... but the boundaries of the partitions have a different shape
image(cl2)
points(Nclus)
</code></pre>

<hr>
<h2 id='kcca2df'>Convert Cluster Result to Data Frame</h2><span id='topic+kcca2df'></span>

<h3>Description</h3>

<p>Convert object of class <code>"kcca"</code> to a data frame in long format.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>kcca2df(object, data)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="kcca2df_+3A_object">object</code></td>
<td>
<p>Object of class <code>"kcca"</code>.</p>
</td></tr>
<tr><td><code id="kcca2df_+3A_data">data</code></td>
<td>
<p>Optional data if not saved in <code>object</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A <code>data.frame</code> with columns <code>value</code>, <code>variable</code> and
<code>group</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>c.iris &lt;- cclust(iris[,-5], 3, save.data=TRUE)
df.c.iris &lt;- kcca2df(c.iris)
summary(df.c.iris)
densityplot(~value|variable+group, data=df.c.iris)
</code></pre>

<hr>
<h2 id='milk'>Milk of Mammals</h2><span id='topic+milk'></span>

<h3>Description</h3>

<p>The data set contains the ingredients of mammal's milk of 25 animals.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(milk)</code></pre>


<h3>Format</h3>

<p>A data frame with 25 observations on the following 5 variables (all in
percent). 
</p>

<dl>
<dt><code>water</code></dt><dd><p>Water.</p>
</dd>
<dt><code>protein</code></dt><dd><p>Protein.</p>
</dd>
<dt><code>fat</code></dt><dd><p>Fat.</p>
</dd>
<dt><code>lactose</code></dt><dd><p>Lactose.</p>
</dd>
<dt><code>ash</code></dt><dd><p>Ash.</p>
</dd>
</dl>



<h3>References</h3>

<p>John A. Hartigan: Clustering Algorithms. Wiley, New York, 1975.
</p>

<hr>
<h2 id='Nclus'>Artificial Example with 4 Gaussians</h2><span id='topic+Nclus'></span>

<h3>Description</h3>

<p>A simple artificial regression example with 4 clusters, all of
them having a Gaussian distribution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(Nclus)
</code></pre>


<h3>Details</h3>

<p>The <code>Nclus</code> data set can be re-created by loading package
<span class="pkg">flexmix</span> and running <code>ExNclus(100)</code> 
using <code>set.seed(2602)</code>. It has been saved as a data set for
simplicity of examples only.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Nclus)
cl &lt;- cclust(Nclus, k=4, simple=FALSE, save.data=TRUE)
plot(cl)
</code></pre>

<hr>
<h2 id='nutrient'>Nutrients in Meat, Fish and Fowl</h2><span id='topic+nutrient'></span>

<h3>Description</h3>

<p>The data set contains the measurements of nutrients in several types
of meat, fish and fowl.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(nutrient)</code></pre>


<h3>Format</h3>

<p>A data frame with 27 observations on the following 5 variables.
</p>

<dl>
<dt><code>energy</code></dt><dd><p>Food energy (calories).</p>
</dd>
<dt><code>protein</code></dt><dd><p>Protein (grams).</p>
</dd>
<dt><code>fat</code></dt><dd><p>Fat (grams).</p>
</dd>
<dt><code>calcium</code></dt><dd><p>calcium (milli grams).</p>
</dd>
<dt><code>iron</code></dt><dd><p>Iron (milli grams).</p>
</dd>
</dl>



<h3>References</h3>

<p>John A. Hartigan: Clustering Algorithms. Wiley, New York, 1975.
</p>

<hr>
<h2 id='pairs-methods'>Methods for Function pairs in Package &lsquo;flexclust&rsquo;</h2><span id='topic+pairs+2Ckcca-method'></span><span id='topic+pairs+2Ckccasimple-method'></span>

<h3>Description</h3>

<p>Plot a matrix of neighbourhood graphs.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S4 method for signature 'kcca'
pairs(x, which=NULL, project=NULL, oma=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="pairs-methods_+3A_x">x</code></td>
<td>
<p>An object of class <code>"kcca"</code></p>
</td></tr>
<tr><td><code id="pairs-methods_+3A_which">which</code></td>
<td>
<p>Index numbers of dimensions of (projected) input space
to plot, default is to plot all dimensions.</p>
</td></tr>
<tr><td><code id="pairs-methods_+3A_project">project</code></td>
<td>
<p>Projection object for which a <code>predict</code> method
exists, e.g., the result of <code><a href="stats.html#topic+prcomp">prcomp</a></code>.</p>
</td></tr>
<tr><td><code id="pairs-methods_+3A_oma">oma</code></td>
<td>
<p>Outer margin.</p>
</td></tr>
<tr><td><code id="pairs-methods_+3A_...">...</code></td>
<td>
<p>Passed to the <code>plot</code> method.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This works only for <code>"kcca"</code> objects, no method is available for
&quot;kccasimple&quot; objects.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>

<hr>
<h2 id='parameters'>Get Centroids from KCCA Object</h2><span id='topic+parameters'></span><span id='topic+parameters+2Ckccasimple-method'></span>

<h3>Description</h3>

<p>Returns the matrix of centroids of a fitted object of class <code>"kcca"</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'kccasimple'
parameters(object, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="parameters_+3A_object">object</code></td>
<td>
<p>Fitted object.</p>
</td></tr>
<tr><td><code id="parameters_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>

<hr>
<h2 id='plot-methods'>Methods for Function plot in Package &lsquo;flexclust&rsquo;</h2><span id='topic+plot+2Ckcca+2Cmissing-method'></span><span id='topic+plot+2Ckccasimple+2Cmissing-method'></span>

<h3>Description</h3>

<p>Plot the neighbourhood graph of a cluster solution together with
projected data points.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>  ## S4 method for signature 'kcca,missing'
plot(x, y, which=1:2, project=NULL,
         data=NULL, points=TRUE, hull=TRUE, hull.args=NULL, 
         number = TRUE, simlines=TRUE,
         lwd=1, maxlwd=8*lwd, cex=1.5, numcol=FALSE, nodes=16,
         add=FALSE, xlab="", ylab="", xlim = NULL,
         ylim = NULL, pch=NULL, col=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="plot-methods_+3A_x">x</code></td>
<td>
<p>An object of class <code>"kcca"</code></p>
</td></tr>
<tr><td><code id="plot-methods_+3A_y">y</code></td>
<td>
<p>Not used</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_which">which</code></td>
<td>
<p>Index numbers of dimensions of (projected) input space
to plot.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_project">project</code></td>
<td>
<p>Projection object for which a <code>predict</code> method
exists, e.g., the result of <code><a href="stats.html#topic+prcomp">prcomp</a></code>.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_data">data</code></td>
<td>
<p>Data to include in plot. If the cluster object <code>x</code>
was created with <code>save.data=TRUE</code>, then these are used by default.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_points">points</code></td>
<td>
<p>Logical, shall data points be plotted (if available)?</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_hull">hull</code></td>
<td>
<p>If <code>TRUE</code>, then hulls of the data are plotted (if available).
Can either be a logical value, one of the strings <code>"convex"</code>
(the default) or <code>"ellipse"</code>, or a function for plotting the
hulls.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_hull.args">hull.args</code></td>
<td>
<p>A list of arguments for the hull function.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_number">number</code></td>
<td>
<p>Logical, plot number labels in nodes of graph?</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_numcol">numcol</code>, <code id="plot-methods_+3A_cex">cex</code></td>
<td>
<p>Color and size of number labels in nodes of
graph. If <code>numcol</code> is logical, it switches between black and
the color of the clusters, else it is taken as a vector of colors.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_nodes">nodes</code></td>
<td>
<p>Plotting symbol to use for nodes if no numbers are drawn.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_simlines">simlines</code></td>
<td>
<p>Logical, plot edges of graph?</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_lwd">lwd</code>, <code id="plot-methods_+3A_maxlwd">maxlwd</code></td>
<td>
<p>Numerical, thickness of lines.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_add">add</code></td>
<td>
<p>Logical, add to existing plot?</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_xlab">xlab</code>, <code id="plot-methods_+3A_ylab">ylab</code></td>
<td>
<p>Axis labels.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_xlim">xlim</code>, <code id="plot-methods_+3A_ylim">ylim</code></td>
<td>
<p>Axis range.</p>
</td></tr>
<tr><td><code id="plot-methods_+3A_pch">pch</code>, <code id="plot-methods_+3A_col">col</code>, <code id="plot-methods_+3A_...">...</code></td>
<td>
<p>Plotting symbols and colors for data points.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This works only for <code>"kcca"</code> objects, no method is available for
&quot;kccasimple&quot; objects. 
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Friedrich Leisch. Visualizing cluster analysis and finite mixture
models. In Chun houh Chen, Wolfgang Haerdle, and Antony Unwin, editors,
Handbook of Data Visualization, Springer Handbooks of Computational
Statistics. Springer Verlag, 2008.
</p>

<hr>
<h2 id='predict-methods'>Predict Cluster Membership</h2><span id='topic+predict+2Ckccasimple-method'></span><span id='topic+clusters+2Cflexclust+2Cmissing-method'></span><span id='topic+clusters+2Cflexclust+2CANY-method'></span>

<h3>Description</h3>

<p>Return either the cluster membership of training data or predict for
new data.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'kccasimple'
predict(object, newdata, ...)
## S4 method for signature 'flexclust,ANY'
clusters(object, newdata, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict-methods_+3A_object">object</code></td>
<td>
<p>Object of class inheriting from <code>"flexclust"</code>.</p>
</td></tr>
<tr><td><code id="predict-methods_+3A_newdata">newdata</code></td>
<td>
<p>An optional data matrix with the same number of columns
as the cluster centers. If omitted, the fitted values are used.</p>
</td></tr>
<tr><td><code id="predict-methods_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>clusters</code> can be used on any object of class <code>"flexclust"</code>
and returns the cluster memberships of the training data.
</p>
<p><code>predict</code> can be used only on objects of class <code>"kcca"</code>
(which inherit from <code>"flexclust"</code>). If no <code>newdata</code> argument
is specified, the function is identical to <code>clusters</code>, if
<code>newdata</code> is specified, then cluster memberships for the new data
are predicted. <code>clusters(object, newdata, ...)</code> is an alias for
<code>predict(object, newdata, ...)</code>.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>

<hr>
<h2 id='priceFeature'>Artificial 2d Market Segment Data</h2><span id='topic+priceFeature'></span><span id='topic+plot.priceFeature'></span>

<h3>Description</h3>

<p>Simple artificial 2-dimensional data to demonstrate clustering for market
segmentation. One dimension is the hypothetical feature
sophistication (or performance or quality, etc) of a product, the
second dimension the price customers are willing to pay for the
product.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>priceFeature(n, which=c("2clust", "3clust", "3clustold", "5clust",
                        "ellipse", "triangle", "circle", "square",
                        "largesmall"))
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="priceFeature_+3A_n">n</code></td>
<td>
<p>Sample size.</p>
</td></tr>
<tr><td><code id="priceFeature_+3A_which">which</code></td>
<td>
<p>Shape of data set.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Sara Dolnicar and Friedrich Leisch. Evaluation of structure and
reproducibility of cluster solutions using the bootstrap. Marketing
Letters, 21:83-101, 2010.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>plot(priceFeature(200, "2clust"))
plot(priceFeature(200, "3clust"))
plot(priceFeature(200, "3clustold"))
plot(priceFeature(200, "5clust"))
plot(priceFeature(200, "ell"))
plot(priceFeature(200, "tri"))
plot(priceFeature(200, "circ"))
plot(priceFeature(200, "square"))
plot(priceFeature(200, "largesmall"))
</code></pre>

<hr>
<h2 id='projAxes'>Add Arrows for Projected Axes to a Plot</h2><span id='topic+projAxes'></span><span id='topic+projAxes-class'></span><span id='topic+plot+2CprojAxes+2Cmissing-method'></span><span id='topic+placeLabels'></span><span id='topic+placeLabels+2CprojAxes-method'></span>

<h3>Description</h3>

<p>Adds arrows for original coordinate axes to a projection
plot.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>projAxes(object, which=1:2, center=NULL,
                     col="red", radius=NULL,
                     minradius=0.1, textargs=list(col=col),
                     col.names=getColnames(object),
                     which.names="", group = NULL, groupFun = colMeans,
                     plot=TRUE, ...)

placeLabels(object)
## S4 method for signature 'projAxes'
placeLabels(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="projAxes_+3A_object">object</code></td>
<td>
<p>Return value of a projection method like
<code><a href="stats.html#topic+prcomp">prcomp</a></code>.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_which">which</code></td>
<td>
<p>Index number of dimensions of (projected) input space
that have been plotted.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_center">center</code></td>
<td>
<p>Center of the coordinate system to use in projected
space. Default is the center of the plotting region.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_col">col</code></td>
<td>
<p>Color of arrows.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_radius">radius</code></td>
<td>
<p>Relative size of the arrows.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_minradius">minradius</code></td>
<td>
<p>Minimum radius of arrows to include (relative to
arrow size).</p>
</td></tr>
<tr><td><code id="projAxes_+3A_textargs">textargs</code></td>
<td>
<p>List of arguments for <code><a href="graphics.html#topic+text">text</a></code>.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_col.names">col.names</code></td>
<td>
<p>Variable names of the original data.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_which.names">which.names</code></td>
<td>
<p>A regular expression which variable names to
include in the plot.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_group">group</code></td>
<td>
<p>An optional grouping variable for the original
coordinates. Coordinates with group <code>NA</code> are omitted.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_groupfun">groupFun</code></td>
<td>
<p>Function used to aggregate the projected coordinates
if <code>group</code> is specified.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_plot">plot</code></td>
<td>
<p>Logical,if <code>TRUE</code> the axes are added to the current plot.</p>
</td></tr>
<tr><td><code id="projAxes_+3A_...">...</code></td>
<td>
<p>Passed to  <code><a href="graphics.html#topic+arrows">arrows</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p><code>projAxes</code> invisibly returns an object of class
<code>"projAxes"</code>, which can be
added to an existing plot by its <code>plot</code>
method.</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(milk)
milk.pca &lt;- prcomp(milk, scale=TRUE)

## create a biplot step by step
plot(predict(milk.pca), type="n")
text(predict(milk.pca), rownames(milk), col="green", cex=0.8)
projAxes(milk.pca)

## the same, but arrows are blue, centered at origin and all arrows are
## plotted 
plot(predict(milk.pca), type="n")
text(predict(milk.pca), rownames(milk), col="green", cex=0.8)
projAxes(milk.pca, col="blue", center=0, minradius=0)

## use points instead of text, plot PC2 and PC3, manual radius
## specification, store result
plot(predict(milk.pca)[,c(2,3)])
arr &lt;- projAxes(milk.pca, which=c(2,3), radius=1.2, plot=FALSE)
plot(arr)

## Not run: 

## manually try to find new places for the labels: each arrow is marked
## active in turn, use the left mouse button to find a better location
## for the label. Use the right mouse button to go on to the next
## variable.

arr1 &lt;- placeLabels(arr)

## now do the plot again:
plot(predict(milk.pca)[,c(2,3)])
plot(arr1)

## End(Not run)

</code></pre>

<hr>
<h2 id='propBarchart'>Barcharts and Boxplots for Columns of a Data Matrix Split by Groups</h2><span id='topic+propBarchart'></span><span id='topic+propBarchart-class'></span><span id='topic+show+2CpropBarchart-method'></span><span id='topic+summary+2CpropBarchart-method'></span><span id='topic+groupBWplot'></span>

<h3>Description</h3>

<p>Split a binary or numeric matrix by a grouping variable,
run a series of tests on all variables, adjust for multiple testing
and graphically represent results.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>propBarchart(x, g, alpha=0.05, correct="holm", test="prop.test",
             sort=FALSE, strip.prefix="", strip.labels=NULL,
             which=NULL, byvar=FALSE, ...)

## S4 method for signature 'propBarchart'
summary(object, ...)

groupBWplot(x, g, alpha=0.05, correct="holm", xlab="", col=NULL,
            shade=!is.null(shadefun), shadefun=NULL,
            strip.prefix="", strip.labels=NULL, which=NULL, byvar=FALSE,
            ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="propBarchart_+3A_x">x</code></td>
<td>
<p>A binary data matrix.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_g">g</code></td>
<td>
<p>A factor specifying the groups.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_alpha">alpha</code></td>
<td>
<p>Significance level for test of differences in
proportions.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_correct">correct</code></td>
<td>
<p>Correction method for multiple testing, passed to
<code><a href="stats.html#topic+p.adjust">p.adjust</a></code>.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_test">test</code></td>
<td>
<p>Test to use for detecting significant differences in
proportions.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_sort">sort</code></td>
<td>
<p>Logical, sort variables by total sample mean?</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_strip.prefix">strip.prefix</code></td>
<td>
<p>Character string prepended to strips of the
<code><a href="lattice.html#topic+barchart">barchart</a></code> (the remainder of the strip are group
levels and group sizes). Ignored if <code>strip.labels</code> is specified.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_strip.labels">strip.labels</code></td>
<td>
<p>Character vector of labels to use for strips of
<code><a href="lattice.html#topic+barchart">barchart</a></code>.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_which">which</code></td>
<td>
<p>Index numbers or names of variables to plot.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_byvar">byvar</code></td>
<td>
<p>If <code>TRUE</code>, a panel is plotted for each variable. By
default a panel is plotted for each group.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_...">...</code></td>
<td>
<p>Passed on to <code><a href="lattice.html#topic+barchart">barchart</a></code>
or <code><a href="lattice.html#topic+bwplot">bwplot</a></code>.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_object">object</code></td>
<td>
<p>Return value of <code>propBarchart</code>.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_xlab">xlab</code></td>
<td>
<p>A title for the x-axis: see <code><a href="graphics.html#topic+title">title</a></code>. 
The default is <code>""</code>.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_col">col</code></td>
<td>
<p>Vector of colors for the panels.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_shade">shade</code></td>
<td>
<p>If <code>TRUE</code>, only variables with significant 
differences in median are filled with color.</p>
</td></tr>
<tr><td><code id="propBarchart_+3A_shadefun">shadefun</code></td>
<td>
<p>A function or name of a function to compute which
boxes are shaded, e.g. <code>"kruskalTest"</code> (default),
<code>"medianInside"</code> or <code>"boxOverlap"</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Function <code>propBarchart</code> splits a binary data matrix into
subgroups, computes the percentage of ones in each column and compares
the proportions in the groups using <code><a href="stats.html#topic+prop.test">prop.test</a></code>. The
p-values for all variables are adjusted for multiple testing and a
barchart of group percentages is drawn highlighting variables with
significant differences in proportion. The <code>summary</code> method can
be used to create a corresponding table for publications.
</p>
<p>Function <code>groupBWplot</code> takes a general numeric matrix, also
splits into subgroups and uses boxes instead of bars. By default
<code><a href="stats.html#topic+kruskal.test">kruskal.test</a></code> is used to compute significant differences
in location, in addition the heuristics from
<code><a href="#topic+bwplot+2Ckcca-method">bwplot,kcca-method</a></code> can be used. Boxes of the complete sample
are used as reference in the background.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>See Also</h3>

<p><code><a href="#topic+barplot-methods">barplot-methods</a></code>,
<code><a href="#topic+bwplot+2Ckcca-method">bwplot,kcca-method</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'> ## create a binary matrix from the iris data plus a random noise column
 x &lt;- apply(iris[,-5], 2, function(z) z&gt;median(z))
 x &lt;- cbind(x, Noise=sample(0:1, 150, replace=TRUE))

 ## There are significant differences in all 4 original variables, Noise
 ## has most likely no significant difference (of course the difference
 ## will be significant in alpha percent of all random samples).
 p &lt;- propBarchart(x, iris$Species)
 p
 summary(p)
 propBarchart(x, iris$Species, byvar=TRUE)
 
 x &lt;- iris[,-5]
 x &lt;- cbind(x, Noise=rnorm(150, mean=3))
 groupBWplot(x, iris$Species)
 groupBWplot(x, iris$Species, shade=TRUE)
 groupBWplot(x, iris$Species, shadefun="medianInside")
 groupBWplot(x, iris$Species, shade=TRUE, byvar=TRUE)
</code></pre>

<hr>
<h2 id='qtclust'>Stochastic QT Clustering</h2><span id='topic+qtclust'></span>

<h3>Description</h3>

<p>Perform stochastic QT clustering on a data matrix.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>qtclust(x, radius, family = kccaFamily("kmeans"), control = NULL,
        save.data=FALSE, kcca=FALSE)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="qtclust_+3A_x">x</code></td>
<td>
<p>A numeric matrix of data, or an object that can be coerced to
such a matrix (such as a numeric vector or a data frame with all
numeric columns).</p>
</td></tr>
<tr><td><code id="qtclust_+3A_radius">radius</code></td>
<td>
<p>Maximum radius of clusters.</p>
</td></tr>
<tr><td><code id="qtclust_+3A_family">family</code></td>
<td>
<p>Object of class <code>"kccaFamily"</code> specifying the
distance measure to be used.</p>
</td></tr>
<tr><td><code id="qtclust_+3A_control">control</code></td>
<td>
<p>An object of class <code>"flexclustControl"</code>
specifying the minimum number of observations per cluster
(<code>min.size</code>), and trials per iteration (<code>ntry</code>, see details
below).</p>
</td></tr></table>
<p>.
</p>
<table role = "presentation">
<tr><td><code id="qtclust_+3A_save.data">save.data</code></td>
<td>
<p>Save a copy of <code>x</code> in the return object?</p>
</td></tr>
<tr><td><code id="qtclust_+3A_kcca">kcca</code></td>
<td>
<p>Run <code><a href="#topic+kcca">kcca</a></code> after the QT cluster algorithm has
converged?</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This function implements a variation of the QT clustering algorithm by
Heyer et al. (1999), see Scharl and Leisch (2006). The main difference
is that in each iteration not
all possible cluster start points are considered, but only a random
sample of size <code>control@ntry</code>. We also consider only points as initial
centers where at least one other point is within a circle with radius
<code>radius</code>.  In most cases the resulting
solutions are almost
the same at a considerable speed increase, in some cases even better
solutions are obtained than with the original algorithm. If
<code>control@ntry</code> is set to the size of the data set, an algorithm
similar to the original algorithm as proposed by Heyer et al. (1999)
is obtained.
</p>


<h3>Value</h3>

<p>Function <code>qtclust</code> by default returns objects of class
<code>"kccasimple"</code>. If argument <code>kcca</code> is <code>TRUE</code>, function
<code>kcca()</code> is run afterwards (initialized on the QT cluster
solution). Data points
not clustered by the QT cluster algorithm are omitted from the
<code>kcca()</code> iterations, but filled back into the return
object. All plot methods defined for objects of class <code>"kcca"</code>
can be used.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Heyer, L. J., Kruglyak, S., Yooseph, S. (1999). Exploring expression data:
Identification and analysis of coexpressed genes. Genome Research 9,
1106&ndash;1115.
</p>
<p>Theresa Scharl and Friedrich Leisch. The stochastic QT-clust
algorithm: evaluation of stability and variance on time-course
microarray data. In Alfredo Rizzi and Maurizio Vichi, editors,
Compstat 2006 &ndash; Proceedings in Computational Statistics, pages
1015-1022. Physica Verlag, Heidelberg, Germany, 2006.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(10*runif(1000), ncol=2)

## maximum distrance of point to cluster center is 3
cl1 &lt;- qtclust(x, radius=3)

## maximum distrance of point to cluster center is 1
## -&gt; more clusters, longer runtime
cl2 &lt;- qtclust(x, radius=1)

opar &lt;- par(c("mfrow","mar"))
par(mfrow=c(2,1), mar=c(2.1,2.1,1,1))
plot(x, col=predict(cl1), xlab="", ylab="")
plot(x, col=predict(cl2), xlab="", ylab="")
par(opar)
</code></pre>

<hr>
<h2 id='randIndex'>Compare Partitions</h2><span id='topic+comPart'></span><span id='topic+comPart+2Cflexclust+2Cflexclust-method'></span><span id='topic+comPart+2Cnumeric+2Cnumeric-method'></span><span id='topic+comPart+2Cflexclust+2Cnumeric-method'></span><span id='topic+comPart+2Cnumeric+2Cflexclust-method'></span><span id='topic+randIndex'></span><span id='topic+randIndex+2Ctable+2Cmissing-method'></span><span id='topic+randIndex+2CANY+2CANY-method'></span>

<h3>Description</h3>

<p>Compute the (adjusted) Rand, Jaccard and Fowlkes-Mallows
index for agreement of two partitions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>comPart(x, y, type=c("ARI","RI","J","FM"))
## S4 method for signature 'flexclust,flexclust'
comPart(x, y, type)
## S4 method for signature 'numeric,numeric'
comPart(x, y, type)
## S4 method for signature 'flexclust,numeric'
comPart(x, y, type)
## S4 method for signature 'numeric,flexclust'
comPart(x, y, type)

randIndex(x, y, correct=TRUE, original=!correct)
## S4 method for signature 'table,missing'
randIndex(x, y, correct=TRUE, original=!correct)
## S4 method for signature 'ANY,ANY'
randIndex(x, y, correct=TRUE, original=!correct)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="randIndex_+3A_x">x</code></td>
<td>
<p>Either a 2-dimensional cross-tabulation of cluster
assignments (for <code>randIndex</code> only), an object inheriting from
class <code>"flexclust"</code>, 
or an integer vector of cluster memberships.</p>
</td></tr>
<tr><td><code id="randIndex_+3A_y">y</code></td>
<td>
<p>An object inheriting from class
<code>"flexclust"</code>, or an integer vector of cluster memberships.</p>
</td></tr>
<tr><td><code id="randIndex_+3A_type">type</code></td>
<td>
<p>character vector of abbreviations of indices to compute.</p>
</td></tr>
<tr><td><code id="randIndex_+3A_correct">correct</code>, <code id="randIndex_+3A_original">original</code></td>
<td>
<p>Logical, correct the Rand index for agreement by chance?</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A vector of indices.</p>


<h3>Rand Index</h3>

<p>Let <code class="reqn">A</code> denote the number of all pairs of data
points which are either put into the same cluster by both partitions or
put into different clusters by both partitions. Conversely, let <code class="reqn">D</code>
denote the number of all pairs of data points that are put into one
cluster in one partition, but into different clusters by the other
partition.  The partitions disagree for all pairs <code class="reqn">D</code> and
agree for all pairs <code class="reqn">A</code>. We can measure the agreement by the Rand
index <code class="reqn">A/(A+D)</code> which is invariant with respect to permutations of
cluster labels.
</p>
<p>The index has to be corrected for agreement by chance if the sizes
of the clusters are not uniform (which is usually the case), or if there
are many clusters, see Hubert &amp; Arabie (1985) for details.
</p>


<h3>Jaccard Index</h3>

<p>If the number of clusters is very large, then usually the vast
majority of pairs of points will not be in the same cluster. The
Jaccard index tries to account for this by using only pairs of points
that are in the same cluster in the defintion of <code class="reqn">A</code>.
</p>


<h3>Fowlkes-Mallows</h3>

<p>Let <code class="reqn">A</code> again be the pairs of points that
are in the same cluster in both partitions. Fowlkes-Mallows divides
this number by the geometric mean of the sums of the number of pairs in each
cluster of the two partitions.  This gives the probability that a pair
of points which are in the same cluster in one partition are also in the
same cluster in the other partition.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Lawrence Hubert and Phipps Arabie. Comparing partitions.
Journal of Classification, 2, 193&ndash;218, 1985.
</p>
<p>Marina Meila. Comparing clusterings - an axiomatic view. In Stefan
Wrobel and Luc De Raedt, editors, Proceedings of the International
Machine Learning Conference (ICML). ACM Press, 2005.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>## no class correlations: corrected Rand almost zero
g1 &lt;- sample(1:5, size=1000, replace=TRUE)
g2 &lt;- sample(1:5, size=1000, replace=TRUE)
tab &lt;- table(g1, g2)
randIndex(tab)

## uncorrected version will be large, because there are many points
## which are assigned to different clusters in both cases
randIndex(tab, correct=FALSE)
comPart(g1, g2)

## let pairs (g1=1,g2=1) and (g1=3,g2=3) agree better
k &lt;- sample(1:1000, size=200)
g1[k] &lt;- 1
g2[k] &lt;- 1
k &lt;- sample(1:1000, size=200)
g1[k] &lt;- 3
g2[k] &lt;- 3
tab &lt;- table(g1, g2)

## the index should be larger than before
randIndex(tab, correct=TRUE, original=TRUE)
comPart(g1, g2)
</code></pre>

<hr>
<h2 id='randomTour'>Plot a Random Tour</h2><span id='topic+randomTour'></span><span id='topic+randomTourMatrix'></span><span id='topic+randomTour+2CANY-method'></span><span id='topic+randomTour+2Cflexclust-method'></span><span id='topic+randomTour+2Cmatrix-method'></span>

<h3>Description</h3>

<p>Create a series of projection plots corresponding to a random tour
through the data. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>randomTour(object, ...)

## S4 method for signature 'ANY'
randomTour(object, ...)
## S4 method for signature 'matrix'
randomTour(object, ...)
## S4 method for signature 'flexclust'
randomTour(object, data=NULL, col=NULL, ...)

randomTourMatrix(x, directions=10,
                 steps=100, sec=4, sleep = sec/steps,
                 axiscol=2, axislab=colnames(x),
                 center=NULL, radius=1, minradius=0.01, asp=1,
                 ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="randomTour_+3A_object">object</code>, <code id="randomTour_+3A_x">x</code></td>
<td>
<p>A matrix or an object of class <code>"flexclust"</code>.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_data">data</code></td>
<td>
<p>Data to include in plot.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_col">col</code></td>
<td>
<p>Plotting colors for data points.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_directions">directions</code></td>
<td>
<p>Integer value, how many different directions are
toured.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_steps">steps</code></td>
<td>
<p>Integer, number of steps in each direction.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_sec">sec</code></td>
<td>
<p>Numerical, lower bound for the number of seconds each
direction takes.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_sleep">sleep</code></td>
<td>
<p>Numerical, sleep for as many seconds after each picture
has been plotted.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_axiscol">axiscol</code></td>
<td>
<p>If not <code>NULL</code>, then arrows are plotted for
projections of the original coordinate axes in these colors.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_axislab">axislab</code></td>
<td>
<p>Optional labels for the projected axes.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_center">center</code></td>
<td>
<p>Center of the coordinate system to use in projected
space. Default is the center of the plotting region.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_radius">radius</code></td>
<td>
<p>Relative size of the arrows.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_minradius">minradius</code></td>
<td>
<p>Minimum radius of arrows to include.</p>
</td></tr>
<tr><td><code id="randomTour_+3A_asp">asp</code>, <code id="randomTour_+3A_...">...</code></td>
<td>
<p>Passed on to <code>randomTourMatrix</code> and from there to <code>plot</code>.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Two random locations are chosen, and data then projected onto
hyperplanes which are orthogonal to <code>step</code> vectors interpolating
the two locations. The first two coordinates of the projected data are
plotted. If <code>directions</code> is larger than one, then after the first
<code>steps</code> plots one more random location is chosen, and the
procedure is repeated from the current position to the
new location, etc..
</p>
<p>The whole procedure is similar to a grand tour, but no attempt is made
to optimize subsequent directions, <code>randomTour</code> simply chooses a random
direction in each iteration. Use <code>rggobi</code> for the real thing.
</p>
<p>Obviously the function needs a reasonably fast computer and graphics
device to give a smooth impression, for <code><a href="grDevices.html#topic+x11">x11</a></code> it may be
necessary to use <code>type="Xlib"</code> rather than cairo.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>Examples</h3>

<pre><code class='language-R'>if(interactive()){
  par(ask=FALSE)
  randomTour(iris[,1:4], axiscol=2:5)
  randomTour(iris[,1:4], col=as.numeric(iris$Species), axiscol=4)

  x &lt;- matrix(runif(300), ncol=3)
  x &lt;- rbind(x, x+1, x+2)
  cl &lt;- cclust(x, k=3, save.data=TRUE)

  randomTour(cl, center=0, axiscol="black")

  ## now use predicted cluster membership for new data as colors
  randomTour(cl, center=0, axiscol="black",
             data=matrix(rnorm(3000, mean=1, sd=2), ncol=3))
}
</code></pre>

<hr>
<h2 id='relabel'>
Relabel Cluster Results.
</h2><span id='topic+relabel'></span><span id='topic+relabel+2Ckccasimple+2Ccharacter-method'></span><span id='topic+relabel+2Ckccasimple+2Cinteger-method'></span><span id='topic+relabel+2Ckccasimple+2Cmissing-method'></span><span id='topic+relabel+2CstepFlexclust+2Ccharacter-method'></span><span id='topic+relabel+2CstepFlexclust+2Cinteger-method'></span><span id='topic+relabel+2CstepFlexclust+2Cmissing-method'></span>

<h3>Description</h3>

<p>The clusters are relabelled to obtain a unique labeling.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>relabel(object, by, ...)
## S4 method for signature 'kccasimple,character'
relabel(object, by, which = NULL, ...)
## S4 method for signature 'kccasimple,integer'
relabel(object, by, ...)
## S4 method for signature 'kccasimple,missing'
relabel(object, by, ...)
## S4 method for signature 'stepFlexclust,integer'
relabel(object, by = "series", ...)
## S4 method for signature 'stepFlexclust,missing'
relabel(object, by, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="relabel_+3A_object">object</code></td>
<td>
<p>An object of class <code>"kccasimple"</code> or
<code>"stepFlexclust"</code>.</p>
</td></tr>
<tr><td><code id="relabel_+3A_by">by</code></td>
<td>
<p>If a character vector, it needs to be one of <code>"mean"</code>,
<code>"median"</code>, <code>"variable"</code>, <code>"manual"</code>,
<code>"centers"</code>, <code>"shadow"</code>, <code>"symmshadow"</code> or
<code>"series"</code>.
If missing, <code>"mean"</code> or <code>"series"</code> is used depending on if
<code>object</code> is of class <code>"kccasimple"</code> or
<code>"stepFlexclust"</code>.
If an integer vector, it needs to indicate the new ordering.</p>
</td></tr>
<tr><td><code id="relabel_+3A_which">which</code></td>
<td>
<p>Either an integer vector indiating the ordering or a
vector of length one indicating the variable used for ordering.</p>
</td></tr>
<tr><td><code id="relabel_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If <code>by</code> is a character vector with value <code>"mean"</code> or
<code>"median"</code>, the clusters are ordered by the mean or median values
over all variables for each cluster. If <code>by = "manual"</code>
<code>which</code> needs to be a vector indicating the ordering.  If
<code>by = "variable"</code> <code>which</code> needs to be indicate the variable
which is used to determine the ordering. If <code>by</code> is
<code>"centers"</code>, <code>"shadow"</code> or <code>"symmshadow"</code>, cluster
similarities are calculated using <code>clusterSim</code> and used to
determine an ordering using <code>seriate</code> from package
<span class="pkg">seriation</span>.
</p>
<p>If <code>by = "series"</code> the relabeling is performed over a series of
clustering to minimize the misclassification.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>See Also</h3>

<p><code><a href="#topic+clusterSim">clusterSim</a></code>, <code><a href="seriation.html#topic+seriate">seriate</a></code></p>

<hr>
<h2 id='shadow'>Cluster Shadows and Silhouettes</h2><span id='topic+shadow'></span><span id='topic+shadow+2Ckccasimple-method'></span><span id='topic+show+2Cshadow-method'></span><span id='topic+plot+2Cshadow+2CANY-method'></span><span id='topic+Silhouette'></span><span id='topic+Silhouette+2Ckcca-method'></span><span id='topic+show+2CSilhouette-method'></span><span id='topic+plot+2CSilhouette+2CANY-method'></span>

<h3>Description</h3>

<p>Compute and plot shadows and silhouettes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>## S4 method for signature 'kccasimple'
shadow(object, ...)
## S4 method for signature 'kcca'
Silhouette(object, data=NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shadow_+3A_object">object</code></td>
<td>
<p>An object of class <code>"kcca"</code> or
<code>"kccasimple"</code>.</p>
</td></tr>
<tr><td><code id="shadow_+3A_data">data</code></td>
<td>
<p>Data to compute silhouette values for. If the cluster
<code>object</code> was created with <code>save.data=TRUE</code>, then these are
used by default.</p>
</td></tr>
<tr><td><code id="shadow_+3A_...">...</code></td>
<td>
<p>Currently not used.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The shadow value of each data point is defined as twice the distance to
the closest centroid divided by the sum of distances to closest and
second-closest centroid. If the shadow values of a point is close to 0, then the
point is close to its cluster centroid. If the shadow value is close to 1, it
is almost equidistant to the two centroids. Thus, a cluster that is
well separated from all other clusters should have many points with
small shadow values.
</p>
<p>The silhouette value of a data point is defined as the scaled difference
between the average dissimilarity of a point to all points in its own
cluster to the smallest average dissimilarity to the points of a
different cluster. Large silhouette values indicate good separation.
</p>
<p>The main difference between silhouette values and shadow values is that
we replace average dissimilarities to points in a cluster by
dissimilarities to point averages (=centroids).  See Leisch (2009) for
details.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Friedrich Leisch. Neighborhood graphs, stripes and shadow plots for
cluster visualization. Statistics and Computing, 2009. Accepted for
publication on 2009-06-16.
</p>


<h3>See Also</h3>

<p><code><a href="cluster.html#topic+silhouette">silhouette</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Nclus)
set.seed(1)
c5 &lt;- cclust(Nclus, 5, save.data=TRUE)
c5
plot(c5)

## high shadow values indicate clusters with *bad* separation
shadow(c5)
plot(shadow(c5))

## high Silhouette values indicate clusters with *good* separation
Silhouette(c5)
plot(Silhouette(c5))
</code></pre>

<hr>
<h2 id='shadowStars'>Shadow Stars</h2><span id='topic+shadowStars'></span><span id='topic+panelShadowViolin'></span><span id='topic+panelShadowBP'></span><span id='topic+panelShadowSkeleton'></span><span id='topic+panelShadowStripes'></span>

<h3>Description</h3>

<p>Shadow star plots and corresponding panel functions.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>shadowStars(object, which=1:2, project=NULL,
            width=1, varwidth=FALSE,
            panel=panelShadowStripes,
            box=NULL, col=NULL, add=FALSE, ...)

panelShadowStripes(x, col, ...)
panelShadowViolin(x, ...)
panelShadowBP(x, ...)
panelShadowSkeleton(x, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="shadowStars_+3A_object">object</code></td>
<td>
<p>An object of class <code>"kcca"</code>.</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_which">which</code></td>
<td>
<p>Index numbers of dimensions of (projected) input space
to plot.</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_project">project</code></td>
<td>
<p>Projection object for which a <code>predict</code> method
exists, e.g., the result of <code><a href="stats.html#topic+prcomp">prcomp</a></code>.</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_width">width</code></td>
<td>
<p>Width of vertices connecting the cluster centroids.</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_varwidth">varwidth</code></td>
<td>
<p>Logical, shall all vertices have the same width or
should the width be proportional to number of points shown on the
vertex?</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_panel">panel</code></td>
<td>
<p>Function used to draw vertices.</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_box">box</code></td>
<td>
<p>Color of rectangle drawn around each vertex.</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_col">col</code></td>
<td>
<p>A vector of colors for the clusters.</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_add">add</code></td>
<td>
<p>Logical, start a new plot?</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_...">...</code></td>
<td>
<p>Passed on to panel function.</p>
</td></tr>
<tr><td><code id="shadowStars_+3A_x">x</code></td>
<td>
<p>Shadow values of data points corresponding to the vertex.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The shadow value of each data point is defined as twice the distance to
the closest centroid divided by the sum of distances to closest and
second-closest centroid. If the shadow values of a point is close to 0,
then the point is close to its cluster centroid. If the shadow value is
close to 1, it is almost equidistant to the two centroids. Thus, a
cluster that is well separated from all other clusters should have many
points with small shadow values.
</p>
<p>The neighborhood graph of a cluster solution connects two centroids by a
vertex if at least one data point has the two centroids as closest and
second closest. The width of the vertex is proportional to the sum of
shadow values of all points having these two as closest and second
closest. A shadow star depicts the distribution of shadow values on the
vertex, see Leisch (2009) for details.
</p>
<p>Currently four panel functions are available:
</p>

<dl>
<dt><code>panelShadowStripes</code>:</dt><dd><p>line segment for each shadow value.</p>
</dd>
<dt><code>panelShadowViolin</code>:</dt><dd><p>violin plot of shadow values.</p>
</dd>
<dt><code>panelShadowBP</code>:</dt><dd><p>box-percentile plot of shadow values.</p>
</dd>
<dt><code>panelShadowSkeleton</code>:</dt><dd><p>average shadow value.</p>
</dd>
</dl>



<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Friedrich Leisch. Neighborhood graphs, stripes and shadow plots for
cluster visualization. Statistics and Computing, 2009. Accepted for
publication on 2009-06-16.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+shadow">shadow</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data(Nclus)
set.seed(1)
c5 &lt;- cclust(Nclus, 5, save.data=TRUE)
c5
plot(c5)

shadowStars(c5)
shadowStars(c5, varwidth=TRUE)

shadowStars(c5, panel=panelShadowViolin)
shadowStars(c5, panel=panelShadowBP)

## always use varwidth=TRUE with panelShadowSkeleton, otherwise a few
## large shadow values can lead to misleading results:
shadowStars(c5, panel=panelShadowSkeleton)
shadowStars(c5, panel=panelShadowSkeleton, varwidth=TRUE)
</code></pre>

<hr>
<h2 id='slsaplot'>
Segment Level Stability Across Solutions Plot.
</h2><span id='topic+slsaplot'></span>

<h3>Description</h3>

<p>Create a segment level stability across solutions plot, possibly
using an additional variable for coloring the nodes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slsaplot(object, nodecol = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slsaplot_+3A_object">object</code></td>
<td>
<p>An object returned by <code>stepFlexclust</code>.</p>
</td></tr>
<tr><td><code id="slsaplot_+3A_nodecol">nodecol</code></td>
<td>
<p>A numeric vector of length equal to the number of
observations clustered in <code>object</code> which represents
an additional variable where a cluster-specific mean is calculated
and used to color the nodes.</p>
</td></tr>
<tr><td><code id="slsaplot_+3A_...">...</code></td>
<td>
<p>Additional graphical parameters to modify the plot.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>For more details see Dolnicar and Leisch (2017) and Dolnicar et
al. (2018).
</p>


<h3>Value</h3>

<p>List of length equal to the number of different cluster solutions
minus one containing numeric vectors of the entropy values used by
default to color the nodes.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch
</p>


<h3>References</h3>

<p>Dolnicar S. and Leisch F. (2017) &quot;Using Segment Level Stability
to Select Target Segments in Data-Driven Market Segmentation Studies&quot;
Marketing Letters, 28 (3), pp. 423&ndash;436.
</p>
<p>Dolnicar S., Gruen B., and Leisch F. (2018) Market Segmentation
Analysis: Understanding It, Doing It, and Making It Useful. Springer
Singapore.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+stepFlexclust">stepFlexclust</a></code>, <code><a href="#topic+relabel">relabel</a></code>, <code><a href="#topic+slswFlexclust">slswFlexclust</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Nclus")
cl25 &lt;- stepFlexclust(Nclus, k=2:5)
slsaplot(cl25)
cl25 &lt;- relabel(cl25)
slsaplot(cl25)
</code></pre>

<hr>
<h2 id='slswFlexclust'>
Segment Level Stability Within Solution.
</h2><span id='topic+slswFlexclust'></span><span id='topic+plot+2CresampleFlexclust+2Cmissing-method'></span><span id='topic+boxplot+2CresampleFlexclust-method'></span><span id='topic+densityplot+2CresampleFlexclust-method'></span><span id='topic+show+2CresampleFlexclust-method'></span><span id='topic+summary+2CresampleFlexclust-method'></span>

<h3>Description</h3>

<p>Assess segment level stability within solution.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>slswFlexclust(x, object, ...)
## S4 method for signature 'resampleFlexclust,missing'
plot(x, y, ...)
## S4 method for signature 'resampleFlexclust'
boxplot(x, which=1, ylab=NULL, ...)
## S4 method for signature 'resampleFlexclust'
densityplot(x, data, which=1, ...)
## S4 method for signature 'resampleFlexclust'
summary(object)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="slswFlexclust_+3A_x">x</code></td>
<td>
<p>A numeric matrix of data, or an object that can be coerced to
such a matrix (such as a numeric vector or a data frame with all
numeric columns) passed to <code><a href="#topic+stepFlexclust">stepFlexclust</a></code>.</p>
</td></tr>
<tr><td><code id="slswFlexclust_+3A_object">object</code></td>
<td>
<p>Object of class <code>"kcca"</code> for <code>slwsFlexclust</code>
and <code>"resampleFlexclust"</code> for the summary method.</p>
</td></tr>
<tr><td><code id="slswFlexclust_+3A_y">y</code></td>
<td>
<p>Missing.</p>
</td></tr>
<tr><td><code id="slswFlexclust_+3A_which">which</code></td>
<td>
<p>Integer or character indicating which validation measure
is used for plotting.</p>
</td></tr>
<tr><td><code id="slswFlexclust_+3A_ylab">ylab</code></td>
<td>
<p>Axis label.</p>
</td></tr>
<tr><td><code id="slswFlexclust_+3A_data">data</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="slswFlexclust_+3A_...">...</code></td>
<td>
<p>Additional arguments; for details see below.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Additional arguments in <code>slswFlexclust</code> are argument <code>nsamp</code>
which is by default equal to 100 and allows to change the number of
bootstrap pairs drawn.  Argument <code>seed</code> allows to set a random
seed and argument <code>multicore</code> is by default <code>TRUE</code> and
indicates if bootstrap samples should be drawn in parallel. Argument
<code>verbose</code> is by default equal to <code>FALSE</code> and if <code>TRUE</code>
progress information is shown during computations.
</p>
<p>There are plotting as well as printing and summary methods implemented
for objects of class <code>"resampleFlexclust"</code>. In addition to a
standard <code>plot</code> method also methods for <code>densityplot</code> and
<code>boxplot</code> are provided.
</p>
<p>For more details see Dolnicar and Leisch (2017) and Dolnicar et
al. (2018).
</p>


<h3>Value</h3>

<p>An object of class <code>"resampleFlexclust"</code>.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch
</p>


<h3>References</h3>

<p>Dolnicar S. and Leisch F. (2017) &quot;Using Segment Level Stability
to Select Target Segments in Data-Driven Market Segmentation Studies&quot;
Marketing Letters, 28 (3), pp. 423&ndash;436.
</p>
<p>Dolnicar S., Gruen B., and Leisch F. (2018) Market Segmentation
Analysis: Understanding It, Doing It, and Making It Useful. Springer
Singapore.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+slsaplot">slsaplot</a></code></p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Nclus")
cl3 &lt;- kcca(Nclus, k = 3)
slsw.cl3 &lt;- slswFlexclust(Nclus, cl3, nsamp = 20)
plot(Nclus, col = clusters(cl3))
plot(slsw.cl3)
densityplot(slsw.cl3)
boxplot(slsw.cl3)
</code></pre>

<hr>
<h2 id='stepFlexclust'>Run Flexclust Algorithms Repeatedly</h2><span id='topic+stepFlexclust'></span><span id='topic+stepcclust'></span><span id='topic+stepFlexclust-class'></span><span id='topic+show+2CstepFlexclust-method'></span><span id='topic+plot+2CstepFlexclust+2Cmissing-method'></span><span id='topic+getModel'></span><span id='topic+getModel+2CstepFlexclust-method'></span><span id='topic++5B+5B+2CstepFlexclust+2CANY+2Cmissing-method'></span>

<h3>Description</h3>

<p>Runs clustering algorithms repeatedly for different numbers of
clusters and returns the minimum within cluster distance solution for
each.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stepFlexclust(x, k, nrep=3, verbose=TRUE, FUN = kcca, drop=TRUE,
              group=NULL, simple=FALSE, save.data=FALSE, seed=NULL,
              multicore=TRUE, ...)

stepcclust(...)

## S4 method for signature 'stepFlexclust,missing'
plot(x, y,
  type=c("barplot", "lines"), totaldist=NULL,
  xlab=NULL, ylab=NULL, ...)

## S4 method for signature 'stepFlexclust'
getModel(object, which=1)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stepFlexclust_+3A_x">x</code>, <code id="stepFlexclust_+3A_...">...</code></td>
<td>
<p>Passed to <code><a href="#topic+kcca">kcca</a></code> or <code><a href="#topic+cclust">cclust</a></code>.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_k">k</code></td>
<td>
<p>A vector of integers passed in turn to the <code>k</code> argument
of <code><a href="#topic+kcca">kcca</a></code></p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_nrep">nrep</code></td>
<td>
<p>For each value of <code>k</code> run <code><a href="#topic+kcca">kcca</a></code>
<code>nrep</code> times and keep only the best solution.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_fun">FUN</code></td>
<td>
<p>Cluster function to use, typically <code>kcca</code> or
<code><a href="#topic+cclust">cclust</a></code>.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_verbose">verbose</code></td>
<td>
<p>If <code>TRUE</code>, show progress information during
computations.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_drop">drop</code></td>
<td>
<p>If <code>TRUE</code> and <code>K</code> is of length 1, then a single
cluster object is returned instead of a <code>"stepFlexclust"</code>
object.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_group">group</code></td>
<td>
<p>An optional grouping vector for the data, see
<code><a href="#topic+kcca">kcca</a></code> for details.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_simple">simple</code></td>
<td>
<p>Return an object of class <code>"kccasimple"</code>?</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_save.data">save.data</code></td>
<td>
<p>Save a copy of <code>x</code> in the return object?</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_seed">seed</code></td>
<td>
<p>If not <code>NULL</code>, a call to <code>set.seed()</code> is made
before any clustering is done.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_multicore">multicore</code></td>
<td>
<p>If <code>TRUE</code>, use <code>mclapply()</code> from package
<span class="pkg">parallel</span> for parallel processing.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_y">y</code></td>
<td>
<p>Not used.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_type">type</code></td>
<td>
<p>Create a barplot or lines plot.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_totaldist">totaldist</code></td>
<td>
<p>Include value for 1-cluster solution in plot? Default
is <code>TRUE</code> if <code>K</code> contains <code>2</code>, else <code>FALSE</code>.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_xlab">xlab</code>, <code id="stepFlexclust_+3A_ylab">ylab</code></td>
<td>
<p>Graphical parameters.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_object">object</code></td>
<td>
<p>Object of class <code>"stepFlexclust"</code>.</p>
</td></tr>
<tr><td><code id="stepFlexclust_+3A_which">which</code></td>
<td>
<p>Number of model to get. If character, interpreted as
number of clusters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>stepcclust</code> is a simple wrapper for
<code>stepFlexclust(...,FUN=cclust)</code>.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>Examples</h3>

<pre><code class='language-R'>data("Nclus")
plot(Nclus)

## multicore off for CRAN checks
cl1 &lt;- stepFlexclust(Nclus, k=2:7, FUN=cclust, multicore=FALSE)
cl1

plot(cl1)

# two ways to do the same:
getModel(cl1, 4)
cl1[[4]]

opar &lt;- par("mfrow")
par(mfrow=c(2, 2))
for(k in 3:6){
  image(getModel(cl1, as.character(k)), data=Nclus)
  title(main=paste(k, "clusters"))
}
par(opar)
</code></pre>

<hr>
<h2 id='stripes'>Stripes Plot</h2><span id='topic+stripes'></span>

<h3>Description</h3>

<p>Plot distance of data points to cluster centroids using stripes.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stripes(object, groups=NULL, type=c("first", "second", "all"),
        beside=(type!="first"), col=NULL, gp.line=NULL, gp.bar=NULL,
        gp.bar2=NULL, number=TRUE, legend=!is.null(groups),
        ylim=NULL, ylab="distance from centroid",
        margins=c(2,5,3,2), ...)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="stripes_+3A_object">object</code></td>
<td>
<p>An object of class <code>"kcca"</code>.</p>
</td></tr>
<tr><td><code id="stripes_+3A_groups">groups</code></td>
<td>
<p>Grouping variable to color-code the stripes. By default
cluster membership is used as <code>groups</code>.</p>
</td></tr>
<tr><td><code id="stripes_+3A_type">type</code></td>
<td>
<p>Plot distance to closest, closest and second-closest or
to all centroids?</p>
</td></tr>
<tr><td><code id="stripes_+3A_beside">beside</code></td>
<td>
<p>Logical, make different stripes for different clusters?</p>
</td></tr>
<tr><td><code id="stripes_+3A_col">col</code></td>
<td>
<p>Vector of colors for clusters or groups.</p>
</td></tr>
<tr><td><code id="stripes_+3A_gp.line">gp.line</code>, <code id="stripes_+3A_gp.bar">gp.bar</code>, <code id="stripes_+3A_gp.bar2">gp.bar2</code></td>
<td>
<p>Graphical parameters for horizontal
lines and background rectangular areas, see
<code><a href="grid.html#topic+gpar">gpar</a></code>.</p>
</td></tr>
<tr><td><code id="stripes_+3A_number">number</code></td>
<td>
<p>Logical, write cluster numbers on x-axis?</p>
</td></tr>
<tr><td><code id="stripes_+3A_legend">legend</code></td>
<td>
<p>Logical, plot a legend for the groups?</p>
</td></tr>
<tr><td><code id="stripes_+3A_ylim">ylim</code>, <code id="stripes_+3A_ylab">ylab</code></td>
<td>
<p>Graphical parameters for y-axis.</p>
</td></tr>
<tr><td><code id="stripes_+3A_margins">margins</code></td>
<td>
<p>Margin of the plot.</p>
</td></tr>
<tr><td><code id="stripes_+3A_...">...</code></td>
<td>
<p>Further graphical parameters.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>A simple, yet very effective plot for visualizing the distance of each
point from its closest and second-closest cluster centroids is a
stripes plot. For each of the k clusters we have a rectangular area,
which we optionally vertically
divide into k smaller rectangles (<code>beside=TRUE</code>). Then we draw a
horizontal line segment for each data point marking the distance of
the data point from the corresponding centroid.
</p>


<h3>Author(s)</h3>

<p>Friedrich Leisch</p>


<h3>References</h3>

<p>Friedrich Leisch. Neighborhood graphs, stripes and shadow plots for
cluster visualization. Statistics and Computing, 20(4), 457&ndash;469, 2010.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>bw05 &lt;- bundestag(2005)
bavaria &lt;- bundestag(2005, state="Bayern")

set.seed(1)
c4 &lt;- cclust(bw05, k=4, save.data=TRUE)
plot(c4)

stripes(c4)
stripes(c4, beside=TRUE)

stripes(c4, type="sec")
stripes(c4, type="sec", beside=FALSE)
stripes(c4, type="all")

stripes(c4, groups=bavaria)

## ugly, but shows how colors of all parts can be changed
library("grid")
stripes(c4, type="all",
        gp.bar=gpar(col="red", lwd=3, fill="white"),
        gp.bar2=gpar(col="green", lwd=3, fill="black"))

</code></pre>

<hr>
<h2 id='vacmot'>
Vacation Motives of Australians
</h2><span id='topic+vacmot'></span><span id='topic+vacmot6'></span><span id='topic+vacmotdesc'></span>

<h3>Description</h3>

<p>In 2006 a sample of 1000 respondents representative for the adult Australian
population was asked about their environmental
behaviour when on vacation. In addition the survey also included a
list of statements about vacation motives like &quot;I want to rest and
relax,&quot; &quot;I use my holiday for the health and beauty of my body,&quot; and
&quot;Cultural offers and sights are a crucial factor.&quot;. Answers are binary
(&quot;applies&quot;, &quot;does not apply&quot;).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(vacmot)</code></pre>


<h3>Format</h3>

<p>Data frame <code>vacmot</code> has 1000 observations on 20 binary
variables on travel motives. Data frame <code>vacmotdesc</code> has 1000
observation on sociodemographic descriptor variables, mean moral
obligation to protect the environment score, mean NEP score, and
mean environmental behaviour score, see Dolnicar &amp; Leisch
(2008) for details.
In addition integer vector <code>vacmot6</code> contains the 6
cluster partition presented in Dolnicar &amp; Leisch (2008).
</p>


<h3>Source</h3>

<p>The data set was collected by the Institute for Innovation in
Business and Social Research, University of Wollongong (NSW, Australia). 
</p>


<h3>References</h3>

<p>Sara Dolnicar and Friedrich Leisch. An investigation of tourists'
patterns of obligation to protect the environment. Journal of Travel
Research, 46:381-391, 2008.
</p>
<p>Sara Dolnicar and Friedrich Leisch. Using graphical statistics to
better understand market segmentation solutions. International Journal
of Market Research, 56(2):97-120, 2014.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>data(vacmot)
summary(vacmotdesc)
dotchart(sort(colMeans(vacmot)))

## reproduce Figure 6 from Dolnicar &amp; Leisch (2008)
cl6 &lt;- kcca(vacmot, k=vacmot6, control=list(iter=0))
barchart(cl6)
</code></pre>

<hr>
<h2 id='volunteers'>
Motivation of Australian Volunteers
</h2><span id='topic+volunteers'></span>

<h3>Description</h3>

<p>Part of an Australian survey on motivation of volunteers
to work for non-profit organisations like Red Cross, State Emergency
Service, Rural Fire Service, Surf Life Saving, Rotary, Parents and
Citizens Associations, etc.. 
</p>


<h3>Usage</h3>

<pre><code class='language-R'>data(volunteers)</code></pre>


<h3>Format</h3>

<p>A data frame with 1415 observations on the following 21 variables: age
and gender of respondents plus 19 binary motivation items (1 applies/
0 does not apply).
</p>

<dl>
<dt><code>GENDER</code></dt><dd><p>Gender of respondent.</p>
</dd>
<dt><code>AGEG</code></dt><dd><p>Age group, a factor with categorized age of respondents.</p>
</dd>
<dt><code>meet.people</code></dt><dd><p>I can meet different types of people.</p>
</dd>
<dt><code>no.one.else</code></dt><dd><p>There is no-one else to do the work.</p>
</dd>
<dt><code>example</code></dt><dd><p>It sets a good example for others.</p>
</dd>
<dt><code>socialise</code></dt><dd><p>I can socialise with people who are like me.</p>
</dd>
<dt><code>help.others</code></dt><dd><p>It gives me the chance to help others.</p>
</dd>
<dt><code>give.back</code></dt><dd><p>I can give something back to society.</p>
</dd>
<dt><code>career</code></dt><dd><p>It will help my career prospects.</p>
</dd>
<dt><code>lonely</code></dt><dd><p>It makes me feel less lonely.</p>
</dd>
<dt><code>active</code></dt><dd><p>It keeps me active.</p>
</dd>
<dt><code>community</code></dt><dd><p>It will improve my community.</p>
</dd>
<dt><code>cause</code></dt><dd><p>I can support an important cause.</p>
</dd>
<dt><code>faith</code></dt><dd><p>I can put faith into action.</p>
</dd>
<dt><code>services</code></dt><dd><p>I want to maintain services that I may use one day.</p>
</dd>
<dt><code>children</code></dt><dd><p>My children are involved with the organisation.</p>
</dd>
<dt><code>good.job</code></dt><dd><p>I feel like I am doing a good job.</p>
</dd>
<dt><code>benefited</code></dt><dd><p>I know someone who has benefited from the organisation.</p>
</dd>
<dt><code>network</code></dt><dd><p>I can build a network of contacts.</p>
</dd>
<dt><code>recognition</code></dt><dd><p>I can gain recognition within the community.</p>
</dd>
<dt><code>mind.off</code></dt><dd><p>It takes my mind off other things.</p>
</dd>
</dl>



<h3>Source</h3>

<p>The volunteering data was collected by the Institute for Innovation in
Business and Social Research, University of Wollongong (NSW, Australia),
using funding from Bushcare Wollongong and the Australian Research
Council under the ARC Linkage Grant scheme (LP0453682).
</p>


<h3>References</h3>

<p>Melanie Randle and Sara Dolnicar. Not Just Any Volunteers: Segmenting the
Market to Attract the High-Contributors. Journal of Non-profit and
Public Sector Marketing, 21(3), 271-282, 2009.
</p>
<p>Melanie Randle and Sara Dolnicar. Self-congruity and volunteering: A
multi-organisation comparison. European Journal of Marketing, 45(5),
739-758, 2011.
</p>
<p>Melanie Randle, Friedrich Leisch, and Sara Dolnicar. Competition or
collaboration? The effect of non-profit brand image on volunteer
recruitment strategy. Journal of Brand Management, 20(8):689-704, 2013. 
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
