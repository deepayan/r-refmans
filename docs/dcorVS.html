<!DOCTYPE html><html><head><title>Help for package dcorVS</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {dcorVS}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#dcorVS-package'>
<p>Variable Selection Algorithms Using the Distance Correlation.</p></a></li>
<li><a href='#Backward selection algorithms using the distance correlation'>
<p>Backward selection algorithms using the distance correlation</p></a></li>
<li><a href='#MMPC and the FBED variable selection algorithms using the distance correlation'>
<p>MMPC and the FBED variable selection algorithms using the distance correlation</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Variable Selection Algorithms Using the Distance Correlation</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0</td>
</tr>
<tr>
<td>Date:</td>
<td>2023-10-17</td>
</tr>
<tr>
<td>Author:</td>
<td>Michail Tsagris [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Michail Tsagris &lt;mtsagris@uoc.gr&gt;</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 4.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>dcov, Rfast, stats</td>
</tr>
<tr>
<td>Description:</td>
<td>The 'FBED' and 'mmpc' variable selection algorithms have been implemented using the distance correlation. The references include: Tsamardinos I., Aliferis C. F. and Statnikov A. (2003). "Time and sample efficient discovery of Markovblankets and direct causal relations". In Proceedings of the ninth ACM SIGKDD international Conference. &lt;<a href="https://doi.org/10.1145%2F956750.956838">doi:10.1145/956750.956838</a>&gt;. Borboudakis G. and Tsamardinos I. (2019). "Forward-backward selection with early dropping". Journal of Machine Learning Research, 20(8): 1&ndash;39. &lt;<a href="https://doi.org/10.48550%2FarXiv.1705.10770">doi:10.48550/arXiv.1705.10770</a>&gt;. Huo X. and Szekely G.J. (2016). "Fast computing for distance covariance". Technometrics, 58(4): 435&ndash;447. &lt;<a href="https://doi.org/10.1080%2F00401706.2015.1054435">doi:10.1080/00401706.2015.1054435</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://www.r-project.org/Licenses/GPL-2">GPL-2</a> | <a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a> [expanded from: GPL (&ge; 2)]</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2023-10-17 11:07:26 UTC; mtsag</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2023-10-18 14:10:02 UTC</td>
</tr>
</table>
<hr>
<h2 id='dcorVS-package'>
Variable Selection Algorithms Using the Distance Correlation.
</h2><span id='topic+dcorVS-package'></span>

<h3>Description</h3>

<p>The 'FBED' and 'mmpc' variable selection algorithms have been implemented using the distance correlation.
</p>


<h3>Details</h3>


<table>
<tr>
 <td style="text-align: left;">
Package: </td><td style="text-align: left;"> dcorVS</td>
</tr>
<tr>
 <td style="text-align: left;">
Type: </td><td style="text-align: left;"> Package</td>
</tr>
<tr>
 <td style="text-align: left;">
Version: </td><td style="text-align: left;"> 1.0</td>
</tr>
<tr>
 <td style="text-align: left;">
Date: </td><td style="text-align: left;"> 2023-10-17</td>
</tr>
<tr>
 <td style="text-align: left;">
License: </td><td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
 <td style="text-align: left;">
</td>
</tr>

</table>



<h3>Maintainers</h3>

<p>Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>Author(s)</h3>

<p>Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Szekely G.J., Rizzo M.L. and Bakirov N.K. (2007). Measuring and Testing Independence
by Correlation of Distances. Annals of Statistics, 35(6): 2769&ndash;2794.
</p>
<p>Szekely G.J. and Rizzo M. L. (2014). Partial distance correlation with methods for dissimilarities.
Annals of Statistics, 42(6): 2382&ndash;2412.
</p>
<p>Huo X. and Szekely G.J. (2016). Fast computing for distance covariance.
Technometrics, 58(4): 435&ndash;447.
</p>
<p>Tsamardinos I., Aliferis C. F. and Statnikov A. (2003). Time and sample efficient discovery of Markov
blankets and direct causal relations. In Proceedings of the ninth ACM SIGKDD international Conference
on Knowledge Discovery and Data Mining (pp. 673&ndash;678). ACM.
</p>
<p>Brown L. E., Tsamardinos I. and Aliferis C. F. (2004). A novel algorithm for scalable and accurate
Bayesian network learning. Medinfo, 711&ndash;715.
</p>
<p>Borboudakis G. and Tsamardinos I. (2019). Forward-backward selection with early dropping.
Journal of Machine Learning Research, 20(8): 1&ndash;39.
</p>

<hr>
<h2 id='Backward+20selection+20algorithms+20using+20the+20distance+20correlation'>
Backward selection algorithms using the distance correlation
</h2><span id='topic+dcor.bsmmpc'></span><span id='topic+dcor.bs'></span>

<h3>Description</h3>

<p>Backward selection algorithms using the distance correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcor.bsmmpc(y, x, max_k = 3, alpha = 0.05, B = 999)
dcor.bs(y, x, alpha = 0.05)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="Backward+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_y">y</code></td>
<td>

<p>A numerical vector with the response variable.
</p>
</td></tr>
<tr><td><code id="Backward+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the predictor variables.
</p>
</td></tr>
<tr><td><code id="Backward+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_max_k">max_k</code></td>
<td>

<p>The maximum conditioning set to use in the conditional indepedence test (see Details).
Integer, default value is 3.
</p>
</td></tr>
<tr><td><code id="Backward+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_alpha">alpha</code></td>
<td>

<p>The significance level for assessing the p-values. Default value is 0.05.
</p>
</td></tr>
<tr><td><code id="Backward+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_b">B</code></td>
<td>

<p>The number of permutations to execute to compute the p-value of the distance correlation.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The max_k option in the mmpc algorithm: the maximum size of the conditioning set to use in the
conditioning independence test. Larger values provide more accurate results, at the cost of higher
computational times. When the sample size is small (e.g., <code class="reqn">&lt;50</code> observations) the max_k parameter
should be 3 for example, otherwise the conditional independence test may not be able to provide
reliable results.
</p>
<p>The dcor.bs() performs the classical backward selection.
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The duration of the algorithm.
</p>
</td></tr>
<tr><td><code>res</code></td>
<td>

<p>A matrix with all variables and their corresponding (logarithm) of the p-values of the updated associations. 
For the mmpc algorithm, the final p-value is the maximum p-value among the two p-values in the end.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Szekely G.J., Rizzo M.L. and Bakirov N.K. (2007). Measuring and Testing Independence
by Correlation of Distances. Annals of Statistics, 35(6): 2769&ndash;2794.
</p>
<p>Szekely G.J. and Rizzo M. L. (2014). Partial distance correlation with methods for dissimilarities.
Annals of Statistics, 42(6): 2382&ndash;2412.
</p>
<p>Huo X. and Szekely G.J. (2016). Fast computing for distance covariance.
Technometrics, 58(4): 435&ndash;447.
</p>
<p>Tsamardinos I., Aliferis C. F. and Statnikov A. (2003). Time and sample efficient discovery of Markov
blankets and direct causal relations. In Proceedings of the ninth ACM SIGKDD international Conference
on Knowledge Discovery and Data Mining (pp. 673&ndash;678). ACM.
</p>
<p>Brown L. E., Tsamardinos I. and Aliferis C. F. (2004). A novel algorithm for scalable and accurate
Bayesian network learning. Medinfo, 711&ndash;715.
</p>
<p>Borboudakis G. and Tsamardinos I. (2019). Forward-backward selection with early dropping. 
Journal of Machine Learning Research, 20(8): 1&ndash;39.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dcor.fbed">dcor.fbed</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
x &lt;- matrix( rnorm(100 * 10), ncol = 10 )
a &lt;- dcor.bs(y, x)
</code></pre>

<hr>
<h2 id='MMPC+20and+20the+20FBED+20variable+20selection+20algorithms+20using+20the+20distance+20correlation'>
MMPC and the FBED variable selection algorithms using the distance correlation
</h2><span id='topic+dcor.mmpc'></span><span id='topic+dcor.fbed'></span>

<h3>Description</h3>

<p>MMPC and the FBED variable selection algorithms using the distance correlation.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>dcor.mmpc(y, x, max_k = 3, alpha = 0.05, B = 999, backward = TRUE)
dcor.fbed(y, x, alpha = 0.05, K = 0, backward = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="MMPC+2B20and+2B20the+2B20FBED+2B20variable+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_y">y</code></td>
<td>

<p>A numerical vector with the response variable.
</p>
</td></tr>
<tr><td><code id="MMPC+2B20and+2B20the+2B20FBED+2B20variable+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_x">x</code></td>
<td>

<p>A numerical matrix with the predictor variables.
</p>
</td></tr>
<tr><td><code id="MMPC+2B20and+2B20the+2B20FBED+2B20variable+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_max_k">max_k</code></td>
<td>

<p>The maximum conditioning set to use in the conditional indepedence test (see Details).
Integer, default value is 3.
</p>
</td></tr>
<tr><td><code id="MMPC+2B20and+2B20the+2B20FBED+2B20variable+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_alpha">alpha</code></td>
<td>

<p>The significance level for assessing the p-values. Default value is 0.05.
</p>
</td></tr>
<tr><td><code id="MMPC+2B20and+2B20the+2B20FBED+2B20variable+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_b">B</code></td>
<td>

<p>The number of permutations to execute to compute the p-value of the distance correlation.
</p>
</td></tr>
<tr><td><code id="MMPC+2B20and+2B20the+2B20FBED+2B20variable+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_k">K</code></td>
<td>

<p>How many times should the process of the Forward Early Dropping be repeated? The default value is 0.
</p>
</td></tr>
<tr><td><code id="MMPC+2B20and+2B20the+2B20FBED+2B20variable+2B20selection+2B20algorithms+2B20using+2B20the+2B20distance+2B20correlation_+3A_backward">backward</code></td>
<td>

<p>Should the backward selection take place? The default value is set to TRUE.
</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The FBED algorithm is a variation of the usual forward selection. At every step, the most significant
variable enters the selected variables set. In addition, only the significant variables stay and are
further examined. The non signifcant ones are dropped. This goes until no variable can enter the set.
The user has the option to re-do this step 1 or more times (the argument K). In the end, a backward
selection is performed to remove falsely selected variables. Note that you may have specified, for
example, K=10, but the maximum value FBED used can be 4 for example.
</p>
<p>The max_k option in the mmpc algorithm: the maximum size of the conditioning set to use in the
conditioning independence test. Larger values provide more accurate results, at the cost of higher
computational times. When the sample size is small (e.g., <code class="reqn">&lt;50</code> observations) the max_k parameter
should be 3 for example, otherwise the conditional independence test may not be able to provide
reliable results.
</p>
<p>Both the MMPC (Tsamardinos, Aliferis and Statnikov, 2003) and FBED algortihms
(Borboudakis and Tsamardinos, 2019) are performed though by utilizing the distance correlation
(Szekely et al., 2007, Szekely and Rizzo 2014, Huo and Szekely, 2016).
</p>


<h3>Value</h3>

<p>A list including:
</p>
<table>
<tr><td><code>runtime</code></td>
<td>

<p>The duration of the algorithm.
</p>
</td></tr>
<tr><td><code>res</code></td>
<td>

<p>A matrix with the selected variables and their corresponding (logarithm) of the p-values of the updated associations. For the mmpc algorithm, the final p-value is the maximum p-value among the two p-values in the end.
</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Michail Tsagris.
</p>
<p>R implementation and documentation: Michail Tsagris <a href="mailto:mtsagris@uoc.gr">mtsagris@uoc.gr</a>.
</p>


<h3>References</h3>

<p>Szekely G.J., Rizzo M.L. and Bakirov N.K. (2007). Measuring and Testing Independence
by Correlation of Distances. Annals of Statistics, 35(6): 2769&ndash;2794.
</p>
<p>Szekely G.J. and Rizzo M. L. (2014). Partial distance correlation with methods for dissimilarities.
Annals of Statistics, 42(6): 2382&ndash;2412.
</p>
<p>Huo X. and Szekely G.J. (2016). Fast computing for distance covariance.
Technometrics, 58(4): 435&ndash;447.
</p>
<p>Tsamardinos I., Aliferis C. F. and Statnikov A. (2003). Time and sample efficient discovery of Markov
blankets and direct causal relations. In Proceedings of the ninth ACM SIGKDD international Conference
on Knowledge Discovery and Data Mining (pp. 673&ndash;678). ACM.
</p>
<p>Brown L. E., Tsamardinos I. and Aliferis C. F. (2004). A novel algorithm for scalable and accurate
Bayesian network learning. Medinfo, 711&ndash;715.
</p>
<p>Borboudakis G. and Tsamardinos I. (2019). Forward-backward selection with early dropping. 
Journal of Machine Learning Research, 20(8): 1&ndash;39.
</p>


<h3>See Also</h3>

<p><code><a href="#topic+dcor.bs">dcor.bs</a> </code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>y &lt;- rnorm(100)
x &lt;- matrix( rnorm(100 * 50), ncol = 50 )
a &lt;- dcor.fbed(y, x, backward = FALSE)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
