<!DOCTYPE html><html><head><title>Help for package Ecume</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {Ecume}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#%&gt;%'><p>Pipe operator</p></a></li>
<li><a href='#classifier_test'><p>Classifier k-sample test</p></a></li>
<li><a href='#ks_test'><p>Weighted KS Test</p></a></li>
<li><a href='#mmd_test'><p>Perform the Maximum Mean Discrepancy unbiased bootstrap test</p></a></li>
<li><a href='#stouffer_zscore'><p>Stouffer</p></a></li>
<li><a href='#wasserstein_permut'><p>Permutation test based on Wasserstein distance</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Equality of 2 (or k) Continuous Univariate and Multivariate
Distributions</td>
</tr>
<tr>
<td>Version:</td>
<td>0.9.1</td>
</tr>
<tr>
<td>Description:</td>
<td>We implement (or re-implements in R) a variety of statistical tools. They are focused on non-parametric two-sample (or k-sample) distribution comparisons in the univariate or multivariate case. See the vignette for more info.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>biocViews:</td>
<td>Software, Infrastructure</td>
</tr>
<tr>
<td>Imports:</td>
<td>stats, spatstat.geom, spatstat (&ge; 2.0-0), magrittr, caret,
dplyr, e1071, methods, pbapply, kernlab, transport</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.1.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>testthat, covr, knitr, rmarkdown</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2021-03-15 02:16:58 UTC; hector</td>
</tr>
<tr>
<td>Author:</td>
<td>Hector Roux de Bezieux
    <a href="https://orcid.org/0000-0002-1489-8339"><img alt="ORCID iD"src="https://cloud.R-project.org/web/orcid.svg" style="width:16px; height:16px; margin-left:4px; margin-right:4px; vertical-align:middle" /></a> [aut, cre]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Hector Roux de Bezieux &lt;hector.rouxdebezieux@berkeley.edu&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2021-03-15 05:30:07 UTC</td>
</tr>
</table>
<hr>
<h2 id='+25+26gt+3B+25'>Pipe operator</h2><span id='topic++25+3E+25'></span>

<h3>Description</h3>

<p>See <code>magrittr::<a href="magrittr.html#topic+pipe">%&gt;%</a></code> for details.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>lhs %&gt;% rhs
</code></pre>


<h3>Value</h3>

<p>The pipe
</p>


<h3>Examples</h3>

<pre><code class='language-R'>2 %&gt;% seq_len()
</code></pre>

<hr>
<h2 id='classifier_test'>Classifier k-sample test</h2><span id='topic+classifier_test'></span>

<h3>Description</h3>

<p>Classifier k-sample test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>classifier_test(
  x,
  y,
  split = 0.7,
  thresh = 0,
  method = "knn",
  control = caret::trainControl(method = "cv"),
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="classifier_test_+3A_x">x</code></td>
<td>
<p>Samples from the first distribution or a list of samples
from k distribution</p>
</td></tr>
<tr><td><code id="classifier_test_+3A_y">y</code></td>
<td>
<p>Samples from the second distribution. Only used if x is a vector.</p>
</td></tr>
<tr><td><code id="classifier_test_+3A_split">split</code></td>
<td>
<p>How to split the data between training and test. Default to .7</p>
</td></tr>
<tr><td><code id="classifier_test_+3A_thresh">thresh</code></td>
<td>
<p>Value to add to the null hypothesis. See details.</p>
</td></tr>
<tr><td><code id="classifier_test_+3A_method">method</code></td>
<td>
<p>Which model(s) to use during training. Default to knn.</p>
</td></tr>
<tr><td><code id="classifier_test_+3A_control">control</code></td>
<td>
<p>Control parameters when fitting the methods.
See <a href="caret.html#topic+trainControl">trainControl</a></p>
</td></tr>
<tr><td><code id="classifier_test_+3A_...">...</code></td>
<td>
<p>Other parameters passed to <a href="caret.html#topic+train">train</a></p>
</td></tr>
</table>


<h3>Details</h3>

<p>See Lopez-Paz et .al for more background on those tests.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>

<ul>
<li> <p><em>statistic</em> the value of the test statistic.
</p>
</li>
<li> <p><em>p.value</em> the p-value of the test.
</p>
</li></ul>



<h3>References</h3>

<p>Lopez-Paz, D., &amp; Oquab, M. (2016). Revisiting Classifier Two-Sample Tests, 1â€“15. Retrieved from http://arxiv.org/abs/1610.06545
</p>


<h3>Examples</h3>

<pre><code class='language-R'> x &lt;- matrix(c(runif(100, 0, 1),
               runif(100, -1, 1)),
             ncol = 2)
 y &lt;- matrix(c(runif(100, 0, 3),
               runif(100, -1, 1)),
             ncol = 2)
 classifier_test(x, y)
</code></pre>

<hr>
<h2 id='ks_test'>Weighted KS Test</h2><span id='topic+ks_test'></span>

<h3>Description</h3>

<p>Weighted Kolmogorov-Smirnov Two-Sample Test with threshold
</p>


<h3>Usage</h3>

<pre><code class='language-R'>ks_test(x, y, thresh = 0.05, w_x = rep(1, length(x)), w_y = rep(1, length(y)))
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="ks_test_+3A_x">x</code></td>
<td>
<p>Vector of values sampled from the first distribution</p>
</td></tr>
<tr><td><code id="ks_test_+3A_y">y</code></td>
<td>
<p>Vector of values sampled from the second distribution</p>
</td></tr>
<tr><td><code id="ks_test_+3A_thresh">thresh</code></td>
<td>
<p>The threshold needed to clear between the two cumulative distributions</p>
</td></tr>
<tr><td><code id="ks_test_+3A_w_x">w_x</code></td>
<td>
<p>The observation weights for x</p>
</td></tr>
<tr><td><code id="ks_test_+3A_w_y">w_y</code></td>
<td>
<p>The observation weights for y</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The usual Kolmogorov-Smirnov test for two vectors <strong>X</strong> and <strong>Y</strong>, of size m
and n rely on the empirical cdfs <code class="reqn">E_x</code> and <code class="reqn">E_y</code> and the test statistic
</p>
<p style="text-align: center;"><code class="reqn">D = sup_{t\in (X, Y)} |E_x(x) - E_y(x))</code>
</p>
<p>.
This modified Kolmogorov-Smirnov test relies on two modifications.
</p>

<ul>
<li><p> Using observation weights for both vectors <strong>X</strong> and <strong>Y</strong>: Those
weights are used in two places, while modifying the usual KS test. First, the
empirical cdfs are updates to account for the weights. Secondly, the effective
sample sizes are also modified. This is inspired from
<a href="https://stackoverflow.com/a/55664242/13768995">https://stackoverflow.com/a/55664242/13768995</a>, using Monahan (2011).
</p>
</li>
<li><p> Testing against a threshold: the test statistic is thresholded such
that <code class="reqn">D = max(D - thresh, 0)</code>. Since <code class="reqn">0\le D\le 1</code>, the value of
the threshold is also between 0 and 1, representing an effect size for the
difference.
</p>
</li></ul>



<h3>Value</h3>

<p>A list with class <code>"htest"</code> containing the following components:
</p>

<ul>
<li> <p><em>statistic</em> the value of the test statistic.
</p>
</li>
<li> <p><em>p.value</em> the p-value of the test.
</p>
</li>
<li> <p><em>alternative</em> a character string describing the alternative hypothesis.
</p>
</li>
<li> <p><em>method</em> a character string indicating what type of test was performed.
</p>
</li>
<li> <p><em>data.name</em> a character string giving the name(s) of the data.
</p>
</li></ul>



<h3>References</h3>

<p>Monahan, J. (2011). <em>Numerical Methods of Statistics</em> (2nd ed.,
Cambridge Series in Statistical and Probabilistic Mathematics). Cambridge:
Cambridge University Press. doi:10.1017/CBO9780511977176
</p>


<h3>Examples</h3>

<pre><code class='language-R'> x &lt;- runif(100)
 y &lt;- runif(100, min = .5, max = .5)
 ks_test(x, y, thresh = .001)
</code></pre>

<hr>
<h2 id='mmd_test'>Perform the Maximum Mean Discrepancy unbiased bootstrap test</h2><span id='topic+mmd_test'></span>

<h3>Description</h3>

<p>Maximum Mean Discrepancy Unbiased Test
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mmd_test(
  x,
  y,
  kernel = "rbfdot",
  type = ifelse(min(nrow(x), nrow(y)) &lt; 1000, "unbiased", "linear"),
  null = c("permutation", "exact"),
  iterations = 10^3,
  frac = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="mmd_test_+3A_x">x</code></td>
<td>
<p>d-dimensional samples from the first distribution</p>
</td></tr>
<tr><td><code id="mmd_test_+3A_y">y</code></td>
<td>
<p>d-dimensional samples from the first distribution</p>
</td></tr>
<tr><td><code id="mmd_test_+3A_kernel">kernel</code></td>
<td>
<p>A character that must match a known kernel. See details.</p>
</td></tr>
<tr><td><code id="mmd_test_+3A_type">type</code></td>
<td>
<p>Which statistic to use. One of 'unbiased' or 'linear'. See
Gretton et al for details. Default to 'unbiased' if the two vectors are of
length less than <code>1000</code> and to 'linear' otherwise.</p>
</td></tr>
<tr><td><code id="mmd_test_+3A_null">null</code></td>
<td>
<p>How to asses the null distribution. This can only be set to exact
if the <code>type</code> is 'unbiased' and the <code>kernel</code> is 'rbf'.</p>
</td></tr>
<tr><td><code id="mmd_test_+3A_iterations">iterations</code></td>
<td>
<p>How many iterations to do to simulate the null distribution.
Default to 10^4. Only used if <code>null</code> is 'permutations'</p>
</td></tr>
<tr><td><code id="mmd_test_+3A_frac">frac</code></td>
<td>
<p>For the linear statistic, how many points to sample. See details.</p>
</td></tr>
<tr><td><code id="mmd_test_+3A_...">...</code></td>
<td>
<p>Further arguments passed to kernel functions</p>
</td></tr>
</table>


<h3>Details</h3>

<p>This computes the MMD^2u unbiased statistic or the MMDl linear statistic
from Gretton et al. The code relies on the pairwise_kernel function from the
python module sklearn. To list the available kernels, see the examples.
</p>


<h3>Value</h3>

<p>A list containing the following components:
</p>

<ul>
<li> <p><em>statistic</em> the value of the test statistic.
</p>
</li>
<li> <p><em>p.value</em> the p-value of the test.
</p>
</li></ul>



<h3>References</h3>

<p>Gretton, A., Borgwardt, K., Rasch, M. J., SchÃ¶lkopf, B., &amp; Smola, A. (2012).
<em>A Kernel Two-Sample Test</em> Journal of Machine Learning Research (2012)
</p>


<h3>Examples</h3>

<pre><code class='language-R'>x &lt;- matrix(rnorm(1000, 0, 1), ncol = 10)
y &lt;- matrix(rnorm(1000, 0, 2), ncol = 10)
mmd_test(x, y)
mmd_test(x, y, type = "linear")
x &lt;- matrix(rnorm(1000, 0, 1), ncol = 10)
y &lt;- matrix(rnorm(1000, 0, 1), ncol = 10)
 # Set iterations to small number for runtime
 # Increase for more accurate results
mmd_test(x, y, iterations = 10^2)
</code></pre>

<hr>
<h2 id='stouffer_zscore'>Stouffer</h2><span id='topic+stouffer_zscore'></span>

<h3>Description</h3>

<p>Stouffer's Z-score method
</p>


<h3>Usage</h3>

<pre><code class='language-R'>stouffer_zscore(pvals, weights = rep(1, seq_along(pvals)), side = "two")
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="stouffer_zscore_+3A_pvals">pvals</code></td>
<td>
<p>A vector of p-values</p>
</td></tr>
<tr><td><code id="stouffer_zscore_+3A_weights">weights</code></td>
<td>
<p>A vector of weights</p>
</td></tr>
<tr><td><code id="stouffer_zscore_+3A_side">side</code></td>
<td>
<p>How the p-values were generated. One of 'right',
'left' or 'two'.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Given a set of i.i.d p-values and associated weights, it combines the
p-values <code class="reqn">p_i</code>. Letting <code class="reqn">\phi</code> be the standard normal cumulative distribution function
and <code class="reqn">Z_i =\phi^{-1} (1-p_i)</code>, the meta-analysis Z-score is
</p>
<p style="text-align: center;"><code class="reqn">Z = (\sum w_i Z_i) * (\sum (w_i)^2)^(-1/2)</code>
</p>



<h3>Value</h3>

<p>A list containing the following components:
</p>

<ul>
<li> <p><em>statistic</em> the value of the test statistic.
</p>
</li>
<li> <p><em>p.value</em> the p-value of the test.
</p>
</li></ul>



<h3>References</h3>

<p>Samuel Andrew Stouffer. <em>Adjustment during army life</em>.  Princeton University Press, 1949.
</p>


<h3>Examples</h3>

<pre><code class='language-R'> pvals &lt;- runif(100, 0, 1)
 weights &lt;- runif(100, 0, 1)
 stouffer_zscore(pvals, weights)
</code></pre>

<hr>
<h2 id='wasserstein_permut'>Permutation test based on Wasserstein distance</h2><span id='topic+wasserstein_permut'></span>

<h3>Description</h3>

<p>Permutation test based on Wasserstein distance
</p>


<h3>Usage</h3>

<pre><code class='language-R'>wasserstein_permut(
  x,
  y,
  iterations = 10^4,
  fast = nrow(x) + nrow(y) &gt; 10^3,
  S = NULL,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="wasserstein_permut_+3A_x">x</code></td>
<td>
<p>Samples from the first distribution</p>
</td></tr>
<tr><td><code id="wasserstein_permut_+3A_y">y</code></td>
<td>
<p>Samples from the second distribution. Only used if x is a vector.</p>
</td></tr>
<tr><td><code id="wasserstein_permut_+3A_iterations">iterations</code></td>
<td>
<p>How many iterations to do to simulate the null distribution.
Default to 10^4.</p>
</td></tr>
<tr><td><code id="wasserstein_permut_+3A_fast">fast</code></td>
<td>
<p>If true, uses the <a href="transport.html#topic+subwasserstein">subwasserstein</a>
approximate function. Default to true if there are more than 1,000 samples
total.</p>
</td></tr>
<tr><td><code id="wasserstein_permut_+3A_s">S</code></td>
<td>
<p>Number of samples to use in approximate mode. Must be set if <code>fast=TRUE</code>.
See <a href="transport.html#topic+subwasserstein">subwasserstein</a>.</p>
</td></tr>
<tr><td><code id="wasserstein_permut_+3A_...">...</code></td>
<td>
<p>Other parameters passed to <a href="transport.html#topic+wasserstein">wasserstein</a> or
<a href="transport.html#topic+wasserstein1d">wasserstein1d</a></p>
</td></tr>
</table>


<h3>Value</h3>

<p>A list containing the following components:
</p>

<ul>
<li> <p><em>statistic</em> the Wasserstein distance between x and y.
</p>
</li>
<li> <p><em>p.value</em> the p-value of the permutation test.
</p>
</li></ul>



<h3>Examples</h3>

<pre><code class='language-R'> x &lt;- matrix(c(runif(100, 0, 1),
               runif(100, -1, 1)),
             ncol = 2)
 y &lt;- matrix(c(runif(100, 0, 3),
               runif(100, -1, 1)),
             ncol = 2)
 # Set iterations to small number for runtime
 # Increase for more accurate results
 wasserstein_permut(x, y, iterations = 10^2)
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
