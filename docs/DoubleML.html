<!DOCTYPE html><html><head><title>Help for package DoubleML</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {DoubleML}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#double_ml_data_from_data_frame'><p>Wrapper for Double machine learning data-backend initialization from</p>
data.frame.</a></li>
<li><a href='#double_ml_data_from_matrix'><p>Wrapper for Double machine learning data-backend initialization</p>
from matrix.</a></li>
<li><a href='#DoubleML'><p>Abstract class DoubleML</p></a></li>
<li><a href='#DoubleMLClusterData'><p>Double machine learning data-backend for data with cluster variables</p></a></li>
<li><a href='#DoubleMLData'><p>Double machine learning data-backend</p></a></li>
<li><a href='#DoubleMLIIVM'><p>Double machine learning for interactive IV regression models</p></a></li>
<li><a href='#DoubleMLIRM'><p>Double machine learning for interactive regression models</p></a></li>
<li><a href='#DoubleMLPLIV'><p>Double machine learning for partially linear IV regression models</p></a></li>
<li><a href='#DoubleMLPLR'><p>Double machine learning for partially linear regression models</p></a></li>
<li><a href='#fetch_401k'><p>Data set on financial wealth and 401(k) plan participation.</p></a></li>
<li><a href='#fetch_bonus'><p>Data set on the Pennsylvania Reemployment Bonus experiment.</p></a></li>
<li><a href='#make_iivm_data'><p>Generates data from a interactive IV regression (IIVM) model.</p></a></li>
<li><a href='#make_irm_data'><p>Generates data from a interactive regression (IRM) model.</p></a></li>
<li><a href='#make_pliv_CHS2015'><p>Generates data from a partially linear IV regression model used in</p>
Chernozhukov, Hansen and Spindler (2015).</a></li>
<li><a href='#make_pliv_multiway_cluster_CKMS2021'><p>Generates data from a partially linear IV regression model with</p>
multiway cluster sample used in Chiang et al. (2021).</a></li>
<li><a href='#make_plr_CCDDHNR2018'><p>Generates data from a partially linear regression model used in</p>
Chernozhukov et al. (2018)</a></li>
<li><a href='#make_plr_turrell2018'><p>Generates data from a partially linear regression model used in a blog</p>
article by Turrell (2018).</a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Double Machine Learning in R</td>
</tr>
<tr>
<td>Version:</td>
<td>1.0.1</td>
</tr>
<tr>
<td>Description:</td>
<td>Implementation of the double/debiased machine learning framework of
    Chernozhukov et al. (2018) &lt;<a href="https://doi.org/10.1111%2Fectj.12097">doi:10.1111/ectj.12097</a>&gt; for partially linear
    regression models, partially linear instrumental variable regression models,
    interactive regression models and interactive instrumental variable
    regression models. 'DoubleML' allows estimation of the nuisance parts in
    these models by machine learning methods and computation of the Neyman
    orthogonal score functions. 'DoubleML' is built on top of 'mlr3' and the
    'mlr3' ecosystem. The object-oriented implementation of 'DoubleML' based on
    the 'R6' package is very flexible. More information available in the
    publication in the Journal of Statistical Software: &lt;<a href="https://doi.org/10.18637%2Fjss.v108.i03">doi:10.18637/jss.v108.i03</a>&gt;.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>URL:</td>
<td><a href="https://docs.doubleml.org/stable/index.html">https://docs.doubleml.org/stable/index.html</a>,
<a href="https://github.com/DoubleML/doubleml-for-r/">https://github.com/DoubleML/doubleml-for-r/</a></td>
</tr>
<tr>
<td>BugReports:</td>
<td><a href="https://github.com/DoubleML/doubleml-for-r/issues">https://github.com/DoubleML/doubleml-for-r/issues</a></td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>Depends:</td>
<td>R (&ge; 3.5.0)</td>
</tr>
<tr>
<td>Imports:</td>
<td>R6 (&ge; 2.4.1), data.table (&ge; 1.12.8), stats, checkmate, mlr3
(&ge; 0.5.0), mlr3tuning (&ge; 0.3.0), mvtnorm, utils,
clusterGeneration, readstata13, mlr3learners (&ge; 0.3.0),
mlr3misc</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.1</td>
</tr>
<tr>
<td>Suggests:</td>
<td>knitr, rmarkdown, testthat, covr, patrick (&ge; 0.1.0), paradox
(&ge; 0.4.0), dplyr, glmnet, lgr, ranger, sandwich, AER, rpart,
bbotk, mlr3pipelines</td>
</tr>
<tr>
<td>VignetteBuilder:</td>
<td>knitr</td>
</tr>
<tr>
<td>Collate:</td>
<td>'double_ml.R' 'double_ml_data.R' 'double_ml_iivm.R'
'double_ml_irm.R' 'double_ml_pliv.R' 'double_ml_plr.R'
'helper.R' 'datasets.R' 'zzz.R'</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2024-06-05 12:57:32 UTC; runner</td>
</tr>
<tr>
<td>Author:</td>
<td>Philipp Bach [aut, cre],
  Victor Chernozhukov [aut],
  Malte S. Kurz [aut],
  Martin Spindler [aut],
  Klaassen Sven [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Philipp Bach &lt;philipp.bach@uni-hamburg.de&gt;</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2024-06-05 16:40:13 UTC</td>
</tr>
</table>
<hr>
<h2 id='double_ml_data_from_data_frame'>Wrapper for Double machine learning data-backend initialization from
data.frame.</h2><span id='topic+double_ml_data_from_data_frame'></span>

<h3>Description</h3>

<p>Initalization of DoubleMLData from <code>data.frame</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>double_ml_data_from_data_frame(
  df,
  x_cols = NULL,
  y_col = NULL,
  d_cols = NULL,
  z_cols = NULL,
  cluster_cols = NULL,
  use_other_treat_as_covariate = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="double_ml_data_from_data_frame_+3A_df">df</code></td>
<td>
<p>(<code>data.frame()</code>)<br />
Data object.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_data_frame_+3A_x_cols">x_cols</code></td>
<td>
<p>(<code>NULL</code>, <code>character()</code>) <br />
The covariates. If <code>NULL</code>, all variables (columns of <code>data</code>) which are
neither specified as outcome variable <code>y_col</code>, nor as treatment variables
<code>d_cols</code>, nor as instrumental variables <code>z_cols</code> are used as covariates.
Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_data_frame_+3A_y_col">y_col</code></td>
<td>
<p>(<code>character(1)</code>) <br />
The outcome variable.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_data_frame_+3A_d_cols">d_cols</code></td>
<td>
<p>(<code>character()</code>) <br />
The treatment variable(s).</p>
</td></tr>
<tr><td><code id="double_ml_data_from_data_frame_+3A_z_cols">z_cols</code></td>
<td>
<p>(<code>NULL</code>, <code>character()</code>) <br />
The instrumental variables. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_data_frame_+3A_cluster_cols">cluster_cols</code></td>
<td>
<p>(<code>NULL</code>, <code>character()</code>) <br />
The cluster variables. Default is <code>NULL</code>.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_data_frame_+3A_use_other_treat_as_covariate">use_other_treat_as_covariate</code></td>
<td>
<p>(<code>logical(1)</code>) <br />
Indicates whether in the multiple-treatment case the other treatment
variables should be added as covariates. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a new instance of class <code>DoubleMLData</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>df = make_plr_CCDDHNR2018(return_type = "data.frame")
x_names = names(df)[grepl("X", names(df))]
obj_dml_data = double_ml_data_from_data_frame(
  df = df, x_cols = x_names,
  y_col = "y", d_cols = "d")
# Input: Data frame, Output: DoubleMLData object
</code></pre>

<hr>
<h2 id='double_ml_data_from_matrix'>Wrapper for Double machine learning data-backend initialization
from matrix.</h2><span id='topic+double_ml_data_from_matrix'></span>

<h3>Description</h3>

<p>Initalization of DoubleMLData from <code>matrix()</code> objects.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>double_ml_data_from_matrix(
  X = NULL,
  y,
  d,
  z = NULL,
  cluster_vars = NULL,
  data_class = "DoubleMLData",
  use_other_treat_as_covariate = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="double_ml_data_from_matrix_+3A_x">X</code></td>
<td>
<p>(<code>matrix()</code>) <br />
Matrix of covariates.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_matrix_+3A_y">y</code></td>
<td>
<p>(<code>numeric()</code>) <br />
Vector of outcome variable.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_matrix_+3A_d">d</code></td>
<td>
<p>(<code>matrix()</code>) <br />
Matrix of treatment variables.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_matrix_+3A_z">z</code></td>
<td>
<p>(<code>matrix()</code>) <br />
Matrix of instruments.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_matrix_+3A_cluster_vars">cluster_vars</code></td>
<td>
<p>(<code>matrix()</code>) <br />
Matrix of cluster variables.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_matrix_+3A_data_class">data_class</code></td>
<td>
<p>(<code>character(1)</code>) <br />
Class of returned object. By default, an object of class <code>DoubleMLData</code> is
returned. Setting <code>data_class = "data.table"</code> returns an object of class
<code>data.table</code>.</p>
</td></tr>
<tr><td><code id="double_ml_data_from_matrix_+3A_use_other_treat_as_covariate">use_other_treat_as_covariate</code></td>
<td>
<p>(<code>logical(1)</code>) <br />
Indicates whether in the multiple-treatment case the other treatment
variables should be added as covariates. Default is <code>TRUE</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>Creates a new instance of class <code>DoubleMLData</code>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>matrix_list = make_plr_CCDDHNR2018(return_type = "matrix")
obj_dml_data = double_ml_data_from_matrix(
  X = matrix_list$X,
  y = matrix_list$y,
  d = matrix_list$d)
</code></pre>

<hr>
<h2 id='DoubleML'>Abstract class DoubleML</h2><span id='topic+DoubleML'></span>

<h3>Description</h3>

<p>Abstract base class that can't be initialized.
</p>


<h3>Format</h3>

<p><a href="R6.html#topic+R6Class">R6::R6Class</a> object.
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>all_coef</code></dt><dd><p>(<code>matrix()</code>) <br />
Estimates of the causal parameter(s) for the <code>n_rep</code> different sample
splits after calling <code>fit()</code>.</p>
</dd>
<dt><code>all_dml1_coef</code></dt><dd><p>(<code>array()</code>) <br />
Estimates of the causal parameter(s) for the <code>n_rep</code> different sample
splits after calling <code>fit()</code> with <code>dml_procedure = "dml1"</code>.</p>
</dd>
<dt><code>all_se</code></dt><dd><p>(<code>matrix()</code>) <br />
Standard errors of the causal parameter(s) for the <code>n_rep</code> different
sample splits after calling <code>fit()</code>.</p>
</dd>
<dt><code>apply_cross_fitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether cross-fitting should be applied. Default is <code>TRUE</code>.</p>
</dd>
<dt><code>boot_coef</code></dt><dd><p>(<code>matrix()</code>) <br />
Bootstrapped coefficients for the causal parameter(s) after calling
<code>fit()</code> and <code>bootstrap()</code>.</p>
</dd>
<dt><code>boot_t_stat</code></dt><dd><p>(<code>matrix()</code>) <br />
Bootstrapped t-statistics for the causal parameter(s) after calling
<code>fit()</code> and <code>bootstrap()</code>.</p>
</dd>
<dt><code>coef</code></dt><dd><p>(<code>numeric()</code>) <br />
Estimates for the causal parameter(s) after calling <code>fit()</code>.</p>
</dd>
<dt><code>data</code></dt><dd><p>(<code><a href="data.table.html#topic+data.table">data.table</a></code>)<br />
Data object.</p>
</dd>
<dt><code>dml_procedure</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character()</code> (<code>"dml1"</code> or <code>"dml2"</code>) specifying the double machine
learning algorithm. Default is <code>"dml2"</code>.</p>
</dd>
<dt><code>draw_sample_splitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the sample splitting should be drawn during
initialization of the object. Default is <code>TRUE</code>.</p>
</dd>
<dt><code>learner</code></dt><dd><p>(named <code>list()</code>) <br />
The machine learners for the nuisance functions.</p>
</dd>
<dt><code>n_folds</code></dt><dd><p>(<code>integer(1)</code>) <br />
Number of folds. Default is <code>5</code>.</p>
</dd>
<dt><code>n_rep</code></dt><dd><p>(<code>integer(1)</code>) <br />
Number of repetitions for the sample splitting. Default is <code>1</code>.</p>
</dd>
<dt><code>params</code></dt><dd><p>(named <code>list()</code>) <br />
The hyperparameters of the learners.</p>
</dd>
<dt><code>psi</code></dt><dd><p>(<code>array()</code>) <br />
Value of the score function
<code class="reqn">\psi(W;\theta, \eta)=\psi_a(W;\eta) \theta + \psi_b (W; \eta)</code>
after calling <code>fit()</code>.</p>
</dd>
<dt><code>psi_a</code></dt><dd><p>(<code>array()</code>) <br />
Value of the score function component <code class="reqn">\psi_a(W;\eta)</code> after
calling <code>fit()</code>.</p>
</dd>
<dt><code>psi_b</code></dt><dd><p>(<code>array()</code>) <br />
Value of the score function component <code class="reqn">\psi_b(W;\eta)</code> after
calling <code>fit()</code>.</p>
</dd>
<dt><code>predictions</code></dt><dd><p>(<code>array()</code>) <br />
Predictions of the nuisance models after calling
<code>fit(store_predictions=TRUE)</code>.</p>
</dd>
<dt><code>models</code></dt><dd><p>(<code>array()</code>) <br />
The fitted nuisance models after calling
<code>fit(store_models=TRUE)</code>.</p>
</dd>
<dt><code>pval</code></dt><dd><p>(<code>numeric()</code>) <br />
p-values for the causal parameter(s) after calling <code>fit()</code>.</p>
</dd>
<dt><code>score</code></dt><dd><p>(<code>character(1)</code>, <code style="white-space: pre;">&#8288;function()&#8288;</code>) <br />
A <code>character(1)</code> or <code style="white-space: pre;">&#8288;function()&#8288;</code> specifying the score function.</p>
</dd>
<dt><code>se</code></dt><dd><p>(<code>numeric()</code>) <br />
Standard errors for the causal parameter(s) after calling <code>fit()</code>.</p>
</dd>
<dt><code>smpls</code></dt><dd><p>(<code>list()</code>) <br />
The partition used for cross-fitting.</p>
</dd>
<dt><code>smpls_cluster</code></dt><dd><p>(<code>list()</code>) <br />
The partition of clusters used for cross-fitting.</p>
</dd>
<dt><code>t_stat</code></dt><dd><p>(<code>numeric()</code>) <br />
t-statistics for the causal parameter(s) after calling <code>fit()</code>.</p>
</dd>
<dt><code>tuning_res</code></dt><dd><p>(named <code>list()</code>) <br />
Results from hyperparameter tuning.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DoubleML-new"><code>DoubleML$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-print"><code>DoubleML$print()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-fit"><code>DoubleML$fit()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-bootstrap"><code>DoubleML$bootstrap()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-split_samples"><code>DoubleML$split_samples()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-set_sample_splitting"><code>DoubleML$set_sample_splitting()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-tune"><code>DoubleML$tune()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-summary"><code>DoubleML$summary()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-confint"><code>DoubleML$confint()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-learner_names"><code>DoubleML$learner_names()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-params_names"><code>DoubleML$params_names()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-set_ml_nuisance_params"><code>DoubleML$set_ml_nuisance_params()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-p_adjust"><code>DoubleML$p_adjust()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-get_params"><code>DoubleML$get_params()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleML-clone"><code>DoubleML$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-DoubleML-new"></a>



<h4>Method <code>new()</code></h4>

<p>DoubleML is an abstract class that can't be initialized.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$new()</pre></div>


<hr>
<a id="method-DoubleML-print"></a>



<h4>Method <code>print()</code></h4>

<p>Print DoubleML objects.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$print()</pre></div>


<hr>
<a id="method-DoubleML-fit"></a>



<h4>Method <code>fit()</code></h4>

<p>Estimate DoubleML models.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$fit(store_predictions = FALSE, store_models = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>store_predictions</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the predictions for the nuisance functions should be
stored in field <code>predictions</code>. Default is <code>FALSE</code>.</p>
</dd>
<dt><code>store_models</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the fitted models for the nuisance functions should be
stored in field <code>models</code> if you want to analyze the models or extract
information like variable importance. Default is <code>FALSE</code>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleML-bootstrap"></a>



<h4>Method <code>bootstrap()</code></h4>

<p>Multiplier bootstrap for DoubleML models.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$bootstrap(method = "normal", n_rep_boot = 500)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>method</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code> (<code>"Bayes"</code>, <code>"normal"</code> or <code>"wild"</code>) specifying the
multiplier bootstrap method.</p>
</dd>
<dt><code>n_rep_boot</code></dt><dd><p>(<code>integer(1)</code>) <br />
The number of bootstrap replications.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleML-split_samples"></a>



<h4>Method <code>split_samples()</code></h4>

<p>Draw sample splitting for DoubleML models.
</p>
<p>The samples are drawn according to the attributes <code>n_folds</code>, <code>n_rep</code>
and <code>apply_cross_fitting</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$split_samples()</pre></div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleML-set_sample_splitting"></a>



<h4>Method <code>set_sample_splitting()</code></h4>

<p>Set the sample splitting for DoubleML models.
</p>
<p>The attributes <code>n_folds</code> and <code>n_rep</code> are derived from the provided
partition.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$set_sample_splitting(smpls)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>smpls</code></dt><dd><p>(<code>list()</code>) <br />
A nested <code>list()</code>. The outer lists needs to provide an entry per
repeated sample splitting (length of the list is set as <code>n_rep</code>).
The inner list is a named <code>list()</code> with names <code>train_ids</code> and <code>test_ids</code>.
The entries in <code>train_ids</code> and <code>test_ids</code> must be partitions per fold
(length of <code>train_ids</code> and <code>test_ids</code> is set as <code>n_folds</code>).</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>



<h5>Examples</h5>

<div class="r example copy">
<pre>library(DoubleML)
library(mlr3)
set.seed(2)
obj_dml_data = make_plr_CCDDHNR2018(n_obs=10)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data,
                              lrn("regr.rpart"), lrn("regr.rpart"))

# simple sample splitting with two folds and without cross-fitting
smpls = list(list(train_ids = list(c(1, 2, 3, 4, 5)),
                  test_ids = list(c(6, 7, 8, 9, 10))))
dml_plr_obj$set_sample_splitting(smpls)

# sample splitting with two folds and cross-fitting but no repeated cross-fitting
smpls = list(list(train_ids = list(c(1, 2, 3, 4, 5), c(6, 7, 8, 9, 10)),
                  test_ids = list(c(6, 7, 8, 9, 10), c(1, 2, 3, 4, 5))))
dml_plr_obj$set_sample_splitting(smpls)

# sample splitting with two folds and repeated cross-fitting with n_rep = 2
smpls = list(list(train_ids = list(c(1, 2, 3, 4, 5), c(6, 7, 8, 9, 10)),
                  test_ids = list(c(6, 7, 8, 9, 10), c(1, 2, 3, 4, 5))),
             list(train_ids = list(c(1, 3, 5, 7, 9), c(2, 4, 6, 8, 10)),
                  test_ids = list(c(2, 4, 6, 8, 10), c(1, 3, 5, 7, 9))))
dml_plr_obj$set_sample_splitting(smpls)
</pre>
</div>


<hr>
<a id="method-DoubleML-tune"></a>



<h4>Method <code>tune()</code></h4>

<p>Hyperparameter-tuning for DoubleML models.
</p>
<p>The hyperparameter-tuning is performed using the tuning methods provided
in the <a href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package. For more
information on tuning in <a href="https://mlr3.mlr-org.com/">mlr3</a>, we refer to
the section on parameter tuning in the
<a href="https://mlr3book.mlr-org.com/chapters/chapter4/hyperparameter_optimization.html">mlr3 book</a>.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$tune(
  param_set,
  tune_settings = list(n_folds_tune = 5, rsmp_tune = mlr3::rsmp("cv", folds = 5), measure
    = NULL, terminator = mlr3tuning::trm("evals", n_evals = 20), algorithm =
    mlr3tuning::tnr("grid_search"), resolution = 5),
  tune_on_folds = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>param_set</code></dt><dd><p>(named <code>list()</code>) <br />
A named <code>list</code> with a parameter grid for each nuisance model/learner
(see method <code>learner_names()</code>). The parameter grid must be an object of
class <a href="paradox.html#topic+ParamSet">ParamSet</a>.</p>
</dd>
<dt><code>tune_settings</code></dt><dd><p>(named <code>list()</code>) <br />
A named <code>list()</code> with arguments passed to the hyperparameter-tuning with
<a href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> to set up
<a href="mlr3tuning.html#topic+TuningInstanceSingleCrit">TuningInstance</a> objects.
<code>tune_settings</code> has entries
</p>

<ul>
<li> <p><code>terminator</code> (<a href="bbotk.html#topic+Terminator">Terminator</a>) <br />
A <a href="bbotk.html#topic+Terminator">Terminator</a> object. Specification of <code>terminator</code>
is required to perform tuning.
</p>
</li>
<li> <p><code>algorithm</code> (<a href="mlr3tuning.html#topic+Tuner">Tuner</a> or <code>character(1)</code>) <br />
A <a href="mlr3tuning.html#topic+Tuner">Tuner</a> object (recommended) or key passed to the
respective dictionary to specify the tuning algorithm used in
<a href="mlr3tuning.html#topic+tnr">tnr()</a>. <code>algorithm</code> is passed as an argument to
<a href="mlr3tuning.html#topic+tnr">tnr()</a>. If <code>algorithm</code> is not specified by the users,
default is set to <code>"grid_search"</code>. If set to <code>"grid_search"</code>, then
additional argument <code>"resolution"</code> is required.
</p>
</li>
<li> <p><code>rsmp_tune</code> (<a href="mlr3.html#topic+Resampling">Resampling</a> or <code>character(1)</code>)<br />
A <a href="mlr3.html#topic+Resampling">Resampling</a> object (recommended) or option passed
to <a href="mlr3.html#topic+mlr_sugar">rsmp()</a> to initialize a
<a href="mlr3.html#topic+Resampling">Resampling</a> for parameter tuning in <code>mlr3</code>.
If not specified by the user, default is set to <code>"cv"</code>
(cross-validation).
</p>
</li>
<li> <p><code>n_folds_tune</code> (<code>integer(1)</code>, optional) <br />
If <code>rsmp_tune = "cv"</code>, number of folds used for cross-validation.
If not specified by the user, default is set to <code>5</code>.
</p>
</li>
<li> <p><code>measure</code> (<code>NULL</code>, named <code>list()</code>, optional) <br />
Named list containing the measures used for parameter tuning. Entries in
list must either be <a href="mlr3.html#topic+Measure">Measure</a> objects or keys to be
passed to passed to <a href="mlr3.html#topic+mlr_sugar">msr()</a>. The names of the entries must
match the learner names (see method <code>learner_names()</code>). If set to <code>NULL</code>,
default measures are used, i.e., <code>"regr.mse"</code> for continuous outcome
variables and <code>"classif.ce"</code> for binary outcomes.
</p>
</li>
<li> <p><code>resolution</code> (<code>character(1)</code>) <br /> The key passed to the respective
dictionary to specify  the tuning algorithm used in
<a href="mlr3tuning.html#topic+tnr">tnr()</a>. <code>resolution</code> is passed as an argument to
<a href="mlr3tuning.html#topic+tnr">tnr()</a>.
</p>
</li></ul>
</dd>
<dt><code>tune_on_folds</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the tuning should be done fold-specific or globally.
Default is <code>FALSE</code>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleML-summary"></a>



<h4>Method <code>summary()</code></h4>

<p>Summary for DoubleML models after calling <code>fit()</code>.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$summary(digits = max(3L, getOption("digits") - 3L))</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>digits</code></dt><dd><p>(<code>integer(1)</code>) <br />
The number of significant digits to use when printing.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DoubleML-confint"></a>



<h4>Method <code>confint()</code></h4>

<p>Confidence intervals for DoubleML models.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$confint(parm, joint = FALSE, level = 0.95)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>parm</code></dt><dd><p>(<code>numeric()</code> or <code>character()</code>) <br />
A specification of which parameters are to be given confidence intervals
among the variables for which inference was done, either a vector of
numbers or a vector of names. If missing, all parameters are considered
(default).</p>
</dd>
<dt><code>joint</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether joint confidence intervals are computed.
Default is <code>FALSE</code>.</p>
</dd>
<dt><code>level</code></dt><dd><p>(<code>numeric(1)</code>) <br />
The confidence level. Default is <code>0.95</code>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>A <code>matrix()</code> with the confidence interval(s).
</p>


<hr>
<a id="method-DoubleML-learner_names"></a>



<h4>Method <code>learner_names()</code></h4>

<p>Returns the names of the learners.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$learner_names()</pre></div>



<h5>Returns</h5>

<p><code>character()</code> with names of learners.
</p>


<hr>
<a id="method-DoubleML-params_names"></a>



<h4>Method <code>params_names()</code></h4>

<p>Returns the names of the nuisance models with hyperparameters.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$params_names()</pre></div>



<h5>Returns</h5>

<p><code>character()</code> with names of nuisance models with hyperparameters.
</p>


<hr>
<a id="method-DoubleML-set_ml_nuisance_params"></a>



<h4>Method <code>set_ml_nuisance_params()</code></h4>

<p>Set hyperparameters for the nuisance models of DoubleML models.
</p>
<p>Note that in the current implementation, either all parameters have to
be set globally or all parameters have to be provided fold-specific.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$set_ml_nuisance_params(
  learner = NULL,
  treat_var = NULL,
  params,
  set_fold_specific = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt><dd><p>(<code>character(1)</code>) <br />
The nuisance model/learner (see method <code>params_names</code>).</p>
</dd>
<dt><code>treat_var</code></dt><dd><p>(<code>character(1)</code>) <br />
The treatment varaible (hyperparameters can be set treatment-variable
specific).</p>
</dd>
<dt><code>params</code></dt><dd><p>(named <code>list()</code>) <br />
A named <code>list()</code> with estimator parameters. Parameters are used for all
folds by default. Alternatively, parameters can be passed in a
fold-specific way if option  <code>fold_specific</code>is <code>TRUE</code>. In this case, the
outer list needs to be of length <code>n_rep</code> and the inner list of length
<code>n_folds</code>.</p>
</dd>
<dt><code>set_fold_specific</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates if the parameters passed in <code>params</code> should be passed in
fold-specific way. Default is <code>FALSE</code>. If <code>TRUE</code>, the outer list needs
to be of length <code>n_rep</code> and the inner list of length <code>n_folds</code>.
Note that in the current implementation, either all parameters have to
be set globally or all parameters have to be provided fold-specific.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleML-p_adjust"></a>



<h4>Method <code>p_adjust()</code></h4>

<p>Multiple testing adjustment for DoubleML models.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$p_adjust(method = "romano-wolf", return_matrix = TRUE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>method</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code>(<code>"romano-wolf"</code>, <code>"bonferroni"</code>, <code>"holm"</code>, etc)
specifying the adjustment method. In addition to <code>"romano-wolf"</code>,
all methods implemented in <a href="stats.html#topic+p.adjust">p.adjust()</a> can be
applied. Default is <code>"romano-wolf"</code>.</p>
</dd>
<dt><code>return_matrix</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates if the output is returned as a matrix with corresponding
coefficient names.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p><code>numeric()</code> with adjusted p-values. If <code>return_matrix = TRUE</code>,
a <code>matrix()</code> with adjusted p_values.
</p>


<hr>
<a id="method-DoubleML-get_params"></a>



<h4>Method <code>get_params()</code></h4>

<p>Get hyperparameters for the nuisance model of DoubleML models.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$get_params(learner)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt><dd><p>(<code>character(1)</code>) <br />
The nuisance model/learner (see method <code>params_names()</code>)</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>named <code>list()</code>with paramers for the nuisance model/learner.
</p>


<hr>
<a id="method-DoubleML-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleML$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other DoubleML: 
<code><a href="#topic+DoubleMLIIVM">DoubleMLIIVM</a></code>,
<code><a href="#topic+DoubleMLIRM">DoubleMLIRM</a></code>,
<code><a href="#topic+DoubleMLPLIV">DoubleMLPLIV</a></code>,
<code><a href="#topic+DoubleMLPLR">DoubleMLPLR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
## ------------------------------------------------
## Method `DoubleML$set_sample_splitting`
## ------------------------------------------------

library(DoubleML)
library(mlr3)
set.seed(2)
obj_dml_data = make_plr_CCDDHNR2018(n_obs=10)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data,
                              lrn("regr.rpart"), lrn("regr.rpart"))

# simple sample splitting with two folds and without cross-fitting
smpls = list(list(train_ids = list(c(1, 2, 3, 4, 5)),
                  test_ids = list(c(6, 7, 8, 9, 10))))
dml_plr_obj$set_sample_splitting(smpls)

# sample splitting with two folds and cross-fitting but no repeated cross-fitting
smpls = list(list(train_ids = list(c(1, 2, 3, 4, 5), c(6, 7, 8, 9, 10)),
                  test_ids = list(c(6, 7, 8, 9, 10), c(1, 2, 3, 4, 5))))
dml_plr_obj$set_sample_splitting(smpls)

# sample splitting with two folds and repeated cross-fitting with n_rep = 2
smpls = list(list(train_ids = list(c(1, 2, 3, 4, 5), c(6, 7, 8, 9, 10)),
                  test_ids = list(c(6, 7, 8, 9, 10), c(1, 2, 3, 4, 5))),
             list(train_ids = list(c(1, 3, 5, 7, 9), c(2, 4, 6, 8, 10)),
                  test_ids = list(c(2, 4, 6, 8, 10), c(1, 3, 5, 7, 9))))
dml_plr_obj$set_sample_splitting(smpls)
</code></pre>

<hr>
<h2 id='DoubleMLClusterData'>Double machine learning data-backend for data with cluster variables</h2><span id='topic+DoubleMLClusterData'></span>

<h3>Description</h3>

<p>Double machine learning data-backend for data with cluster variables.
</p>
<p><code>DoubleMLClusterData</code> objects can be initialized from a
<a href="data.table.html#topic+data.table">data.table</a>. Alternatively <code>DoubleML</code> provides
functions to initialize from a collection of <code>matrix</code> objects or
a <code>data.frame</code>. The following functions can be used to create a new
instance of <code>DoubleMLClusterData</code>.
</p>

<ul>
<li> <p><code>DoubleMLClusterData$new()</code> for initialization from a <code>data.table</code>.
</p>
</li>
<li> <p><code><a href="#topic+double_ml_data_from_matrix">double_ml_data_from_matrix()</a></code> for initialization from <code>matrix</code> objects,
</p>
</li>
<li> <p><code><a href="#topic+double_ml_data_from_data_frame">double_ml_data_from_data_frame()</a></code> for initialization from a <code>data.frame</code>.
</p>
</li></ul>



<h3>Super class</h3>

<p><code><a href="#topic+DoubleMLData">DoubleML::DoubleMLData</a></code> -&gt; <code>DoubleMLClusterData</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>cluster_cols</code></dt><dd><p>(<code>character()</code>)<br />
The cluster variable(s).</p>
</dd>
<dt><code>x_cols</code></dt><dd><p>(<code>NULL</code>, <code>character()</code>) <br />
The covariates. If <code>NULL</code>, all variables (columns of <code>data</code>) which are
neither specified as outcome variable <code>y_col</code>, nor as treatment variables
<code>d_cols</code>, nor as instrumental variables <code>z_cols</code>, nor as cluster
variables <code>cluster_cols</code> are used as covariates.
Default is <code>NULL</code>.</p>
</dd>
<dt><code>n_cluster_vars</code></dt><dd><p>(<code>integer(1)</code>) <br />
The number of cluster variables.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DoubleMLClusterData-new"><code>DoubleMLClusterData$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLClusterData-print"><code>DoubleMLClusterData$print()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLClusterData-set_data_model"><code>DoubleMLClusterData$set_data_model()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLClusterData-clone"><code>DoubleMLClusterData$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-DoubleMLClusterData-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLClusterData$new(
  data = NULL,
  x_cols = NULL,
  y_col = NULL,
  d_cols = NULL,
  cluster_cols = NULL,
  z_cols = NULL,
  use_other_treat_as_covariate = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>(<code><a href="data.table.html#topic+data.table">data.table</a></code>, <code>data.frame()</code>)<br />
Data object.</p>
</dd>
<dt><code>x_cols</code></dt><dd><p>(<code>NULL</code>, <code>character()</code>) <br />
The covariates. If <code>NULL</code>, all variables (columns of <code>data</code>) which are
neither specified as outcome variable <code>y_col</code>, nor as treatment variables
<code>d_cols</code>, nor as instrumental variables <code>z_cols</code> are used as covariates.
Default is <code>NULL</code>.</p>
</dd>
<dt><code>y_col</code></dt><dd><p>(<code>character(1)</code>) <br />
The outcome variable.</p>
</dd>
<dt><code>d_cols</code></dt><dd><p>(<code>character()</code>) <br />
The treatment variable(s).</p>
</dd>
<dt><code>cluster_cols</code></dt><dd><p>(<code>character()</code>) <br />
The cluster variable(s).</p>
</dd>
<dt><code>z_cols</code></dt><dd><p>(<code>NULL</code>, <code>character()</code>) <br />
The instrumental variables. Default is <code>NULL</code>.</p>
</dd>
<dt><code>use_other_treat_as_covariate</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether in the multiple-treatment case the other treatment
variables should be added as covariates. Default is <code>TRUE</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DoubleMLClusterData-print"></a>



<h4>Method <code>print()</code></h4>

<p>Print DoubleMLClusterData objects.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLClusterData$print()</pre></div>


<hr>
<a id="method-DoubleMLClusterData-set_data_model"></a>



<h4>Method <code>set_data_model()</code></h4>

<p>Setter function for <code>data_model</code>. The function implements the causal model
as specified by the user via <code>y_col</code>, <code>d_cols</code>, <code>x_cols</code>, <code>z_cols</code> and
<code>cluster_cols</code> and assigns the role for the treatment variables in the
multiple-treatment case.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLClusterData$set_data_model(treatment_var)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>treatment_var</code></dt><dd><p>(<code>character()</code>)<br />
Active treatment variable that will be set to <code>treat_col</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DoubleMLClusterData-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLClusterData$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>library(DoubleML)
dt = make_pliv_multiway_cluster_CKMS2021(return_type = "data.table")
obj_dml_data = DoubleMLClusterData$new(dt,
  y_col = "Y",
  d_cols = "D",
  z_cols = "Z",
  cluster_cols = c("cluster_var_i", "cluster_var_j"))
</code></pre>

<hr>
<h2 id='DoubleMLData'>Double machine learning data-backend</h2><span id='topic+DoubleMLData'></span>

<h3>Description</h3>

<p>Double machine learning data-backend.
</p>
<p><code>DoubleMLData</code> objects can be initialized from a
<a href="data.table.html#topic+data.table">data.table</a>. Alternatively <code>DoubleML</code> provides
functions to initialize from a collection of <code>matrix</code> objects or
a <code>data.frame</code>. The following functions can be used to create a new
instance of <code>DoubleMLData</code>.
</p>

<ul>
<li> <p><code>DoubleMLData$new()</code> for initialization from a <code>data.table</code>.
</p>
</li>
<li> <p><code><a href="#topic+double_ml_data_from_matrix">double_ml_data_from_matrix()</a></code> for initialization from <code>matrix</code> objects,
</p>
</li>
<li> <p><code><a href="#topic+double_ml_data_from_data_frame">double_ml_data_from_data_frame()</a></code> for initialization from a <code>data.frame</code>.
</p>
</li></ul>



<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>all_variables</code></dt><dd><p>(<code>character()</code>)<br />
All variables available in the dataset.</p>
</dd>
<dt><code>d_cols</code></dt><dd><p>(<code>character()</code>)<br />
The treatment variable(s).</p>
</dd>
<dt><code>data</code></dt><dd><p>(<code><a href="data.table.html#topic+data.table">data.table</a></code>)<br />
Data object.</p>
</dd>
<dt><code>data_model</code></dt><dd><p>(<code><a href="data.table.html#topic+data.table">data.table</a></code>)<br />
Internal data object that implements the causal model as specified by
the user via <code>y_col</code>, <code>d_cols</code>, <code>x_cols</code> and <code>z_cols</code>.</p>
</dd>
<dt><code>n_instr</code></dt><dd><p>(<code>NULL</code>, <code>integer(1)</code>) <br />
The number of instruments.</p>
</dd>
<dt><code>n_obs</code></dt><dd><p>(<code>integer(1)</code>) <br />
The number of observations.</p>
</dd>
<dt><code>n_treat</code></dt><dd><p>(<code>integer(1)</code>) <br />
The number of treatment variables.</p>
</dd>
<dt><code>other_treat_cols</code></dt><dd><p>(<code>NULL</code>, <code>character()</code>) <br />
If <code>use_other_treat_as_covariate</code> is <code>TRUE</code>, <code>other_treat_cols</code> are the
treatment variables that are not &quot;active&quot; in the multiple-treatment case.
These variables then are internally added to the covariates <code>x_cols</code> during
the fitting stage. If <code>use_other_treat_as_covariate</code> is <code>FALSE</code>,
<code>other_treat_cols</code> is <code>NULL</code>.</p>
</dd>
<dt><code>treat_col</code></dt><dd><p>(<code>character(1)</code>) <br />
&quot;Active&quot; treatment variable in the multiple-treatment case.</p>
</dd>
<dt><code>use_other_treat_as_covariate</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether in the multiple-treatment case the other treatment
variables should be added as covariates. Default is <code>TRUE</code>.</p>
</dd>
<dt><code>x_cols</code></dt><dd><p>(<code>NULL</code>, <code>character()</code>) <br />
The covariates. If <code>NULL</code>, all variables (columns of <code>data</code>) which are
neither specified as outcome variable <code>y_col</code>, nor as treatment variables
<code>d_cols</code>, nor as instrumental variables <code>z_cols</code> are used as covariates.
Default is <code>NULL</code>.</p>
</dd>
<dt><code>y_col</code></dt><dd><p>(<code>character(1)</code>) <br />
The outcome variable.</p>
</dd>
<dt><code>z_cols</code></dt><dd><p>(<code>NULL</code>, <code>character()</code>) <br />
The instrumental variables. Default is <code>NULL</code>.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DoubleMLData-new"><code>DoubleMLData$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLData-print"><code>DoubleMLData$print()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLData-set_data_model"><code>DoubleMLData$set_data_model()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLData-clone"><code>DoubleMLData$clone()</code></a>
</p>
</li></ul>


<hr>
<a id="method-DoubleMLData-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this <a href="R6.html#topic+R6Class">R6</a> class.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLData$new(
  data = NULL,
  x_cols = NULL,
  y_col = NULL,
  d_cols = NULL,
  z_cols = NULL,
  use_other_treat_as_covariate = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>(<code><a href="data.table.html#topic+data.table">data.table</a></code>, <code>data.frame()</code>)<br />
Data object.</p>
</dd>
<dt><code>x_cols</code></dt><dd><p>(<code>NULL</code>, <code>character()</code>) <br />
The covariates. If <code>NULL</code>, all variables (columns of <code>data</code>) which are
neither specified as outcome variable <code>y_col</code>, nor as treatment variables
<code>d_cols</code>, nor as instrumental variables <code>z_cols</code> are used as covariates.
Default is <code>NULL</code>.</p>
</dd>
<dt><code>y_col</code></dt><dd><p>(<code>character(1)</code>) <br />
The outcome variable.</p>
</dd>
<dt><code>d_cols</code></dt><dd><p>(<code>character()</code>) <br />
The treatment variable(s).</p>
</dd>
<dt><code>z_cols</code></dt><dd><p>(<code>NULL</code>, <code>character()</code>) <br />
The instrumental variables. Default is <code>NULL</code>.</p>
</dd>
<dt><code>use_other_treat_as_covariate</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether in the multiple-treatment case the other treatment
variables should be added as covariates. Default is <code>TRUE</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DoubleMLData-print"></a>



<h4>Method <code>print()</code></h4>

<p>Print DoubleMLData objects.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLData$print()</pre></div>


<hr>
<a id="method-DoubleMLData-set_data_model"></a>



<h4>Method <code>set_data_model()</code></h4>

<p>Setter function for <code>data_model</code>. The function implements the causal
model as specified by the user via <code>y_col</code>, <code>d_cols</code>, <code>x_cols</code> and
<code>z_cols</code> and assigns the role for the treatment variables in the
multiple-treatment case.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLData$set_data_model(treatment_var)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>treatment_var</code></dt><dd><p>(<code>character()</code>)<br />
Active treatment variable that will be set to <code>treat_col</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DoubleMLData-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLData$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>Examples</h3>

<pre><code class='language-R'>library(DoubleML)
df = make_plr_CCDDHNR2018(return_type = "data.table")
obj_dml_data = DoubleMLData$new(df,
  y_col = "y",
  d_cols = "d")
</code></pre>

<hr>
<h2 id='DoubleMLIIVM'>Double machine learning for interactive IV regression models</h2><span id='topic+DoubleMLIIVM'></span>

<h3>Description</h3>

<p>Double machine learning for interactive IV regression models.
</p>


<h3>Format</h3>

<p><a href="R6.html#topic+R6Class">R6::R6Class</a> object inheriting from <a href="#topic+DoubleML">DoubleML</a>.
</p>


<h3>Details</h3>

<p>Interactive IV regression (IIVM) models take the form
</p>
<p><code class="reqn">Y = \ell_0(D,X) + \zeta</code>,
</p>
<p><code class="reqn">Z = m_0(X) + V</code>,
</p>
<p>with <code class="reqn">E[\zeta|X,Z]=0</code> and <code class="reqn">E[V|X] = 0</code>. <code class="reqn">Y</code> is the outcome
variable, <code class="reqn">D \in \{0,1\}</code> is the binary treatment variable and
<code class="reqn">Z \in \{0,1\}</code> is a binary instrumental variable. Consider the functions
<code class="reqn">g_0</code>, <code class="reqn">r_0</code> and <code class="reqn">m_0</code>, where <code class="reqn">g_0</code> maps the support of
<code class="reqn">(Z,X)</code> to <code class="reqn">R</code> and <code class="reqn">r_0</code> and <code class="reqn">m_0</code>, respectively, map the
support of <code class="reqn">(Z,X)</code> and <code class="reqn">X</code> to <code class="reqn">(\epsilon, 1-\epsilon)</code> for some
<code class="reqn">\epsilon \in (1, 1/2)</code>, such that
</p>
<p><code class="reqn">Y = g_0(Z,X) + \nu,</code>
</p>
<p><code class="reqn">D = r_0(Z,X) + U,</code>
</p>
<p><code class="reqn">Z = m_0(X) + V,</code>
</p>
<p>with <code class="reqn">E[\nu|Z,X]=0</code>, <code class="reqn">E[U|Z,X]=0</code> and <code class="reqn">E[V|X]=0</code>. The target
parameter of interest in this model is the local average treatment effect
(LATE),
</p>
<p><code class="reqn">\theta_0 = \frac{E[g_0(1,X)] - E[g_0(0,X)]}{E[r_0(1,X)] - E[r_0(0,X)]}.</code>
</p>


<h3>Super class</h3>

<p><code><a href="#topic+DoubleML">DoubleML::DoubleML</a></code> -&gt; <code>DoubleMLIIVM</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>subgroups</code></dt><dd><p>(named <code>list(2)</code>) <br />
Named <code>list(2)</code> with options to adapt to cases with and without the
subgroups of always-takers and never-takes.
The entry <code>always_takers</code>(<code>logical(1)</code>) speficies whether there are
always takers in the sample. The entry <code>never_takers</code> (<code>logical(1)</code>)
speficies whether there are never takers in the sample.</p>
</dd>
<dt><code>trimming_rule</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code> specifying the trimming approach.</p>
</dd>
<dt><code>trimming_threshold</code></dt><dd><p>(<code>numeric(1)</code>) <br />
The threshold used for timming.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DoubleMLIIVM-new"><code>DoubleMLIIVM$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLIIVM-clone"><code>DoubleMLIIVM$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="bootstrap"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-bootstrap'><code>DoubleML::DoubleML$bootstrap()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="confint"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-confint'><code>DoubleML::DoubleML$confint()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="fit"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-fit'><code>DoubleML::DoubleML$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="get_params"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-get_params'><code>DoubleML::DoubleML$get_params()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="learner_names"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-learner_names'><code>DoubleML::DoubleML$learner_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="p_adjust"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-p_adjust'><code>DoubleML::DoubleML$p_adjust()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="params_names"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-params_names'><code>DoubleML::DoubleML$params_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="print"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-print'><code>DoubleML::DoubleML$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="set_ml_nuisance_params"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-set_ml_nuisance_params'><code>DoubleML::DoubleML$set_ml_nuisance_params()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="set_sample_splitting"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-set_sample_splitting'><code>DoubleML::DoubleML$set_sample_splitting()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="split_samples"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-split_samples'><code>DoubleML::DoubleML$split_samples()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="summary"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-summary'><code>DoubleML::DoubleML$summary()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="tune"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-tune'><code>DoubleML::DoubleML$tune()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-DoubleMLIIVM-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLIIVM$new(
  data,
  ml_g,
  ml_m,
  ml_r,
  n_folds = 5,
  n_rep = 1,
  score = "LATE",
  subgroups = list(always_takers = TRUE, never_takers = TRUE),
  dml_procedure = "dml2",
  trimming_rule = "truncate",
  trimming_threshold = 1e-12,
  draw_sample_splitting = TRUE,
  apply_cross_fitting = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>(<code>DoubleMLData</code>) <br />
The <code>DoubleMLData</code> object providing the data and specifying the variables
of the causal model.</p>
</dd>
<dt><code>ml_g</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>,
<code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code>, <code><a href="mlr3.html#topic+Learner">Learner</a></code>,
<code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
For binary treatment outcomes, an object of the class
<code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code> can be passed, for example
<code>lrn("classif.cv_glmnet", s = "lambda.min")</code>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "regr"</code> or <code>task_type = "classif"</code> can be passed,
respectively, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. <br />
<code>ml_g</code> refers to the nuisance function <code class="reqn">g_0(Z,X) = E[Y|X,Z]</code>.</p>
</dd>
<dt><code>ml_m</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code>,
<code><a href="mlr3.html#topic+Learner">Learner</a></code>, <code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "classif"</code> can be passed, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("classif.cv_glmnet", s = "lambda.min")</code>. <br />
<code>ml_m</code> refers to the nuisance function <code class="reqn">m_0(X) = E[Z|X]</code>.</p>
</dd>
<dt><code>ml_r</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code>,
<code><a href="mlr3.html#topic+Learner">Learner</a></code>, <code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "classif"</code> can be passed, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("classif.cv_glmnet", s = "lambda.min")</code>. <br />
<code>ml_r</code> refers to the nuisance function <code class="reqn">r_0(Z,X) = E[D|X,Z]</code>.</p>
</dd>
<dt><code>n_folds</code></dt><dd><p>(<code>integer(1)</code>)<br />
Number of folds. Default is <code>5</code>.</p>
</dd>
<dt><code>n_rep</code></dt><dd><p>(<code>integer(1)</code>) <br />
Number of repetitions for the sample splitting. Default is <code>1</code>.</p>
</dd>
<dt><code>score</code></dt><dd><p>(<code>character(1)</code>, <code style="white-space: pre;">&#8288;function()&#8288;</code>) <br />
A <code>character(1)</code> (<code>"LATE"</code> is the only choice) specifying the score
function.
If a <code style="white-space: pre;">&#8288;function()&#8288;</code> is provided, it must be of the form
<code style="white-space: pre;">&#8288;function(y, z, d, g0_hat, g1_hat, m_hat, r0_hat, r1_hat, smpls)&#8288;</code> and
the returned output must be a named <code>list()</code> with elements <code>psi_a</code> and
<code>psi_b</code>. Default is <code>"LATE"</code>.</p>
</dd>
<dt><code>subgroups</code></dt><dd><p>(named <code>list(2)</code>) <br />
Named <code>list(2)</code> with options to adapt to cases with and without the
subgroups of always-takers and never-takes. The entry
<code>always_takers</code>(<code>logical(1)</code>) speficies whether there are always takers
in the sample. The entry <code>never_takers</code> (<code>logical(1)</code>) speficies whether
there are never takers in the sample. Default is
<code>list(always_takers = TRUE, never_takers = TRUE)</code>.</p>
</dd>
<dt><code>dml_procedure</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code> (<code>"dml1"</code> or <code>"dml2"</code>) specifying the double machine
learning algorithm. Default is <code>"dml2"</code>.</p>
</dd>
<dt><code>trimming_rule</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code> (<code>"truncate"</code> is the only choice) specifying the
trimming approach. Default is <code>"truncate"</code>.</p>
</dd>
<dt><code>trimming_threshold</code></dt><dd><p>(<code>numeric(1)</code>) <br />
The threshold used for timming. Default is <code>1e-12</code>.</p>
</dd>
<dt><code>draw_sample_splitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the sample splitting should be drawn during
initialization of the object. Default is <code>TRUE</code>.</p>
</dd>
<dt><code>apply_cross_fitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether cross-fitting should be applied. Default is <code>TRUE</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DoubleMLIIVM-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLIIVM$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other DoubleML: 
<code><a href="#topic+DoubleML">DoubleML</a></code>,
<code><a href="#topic+DoubleMLIRM">DoubleMLIRM</a></code>,
<code><a href="#topic+DoubleMLPLIV">DoubleMLPLIV</a></code>,
<code><a href="#topic+DoubleMLPLR">DoubleMLPLR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
set.seed(2)
ml_g = lrn("regr.ranger",
  num.trees = 100, mtry = 20,
  min.node.size = 2, max.depth = 5)
ml_m = lrn("classif.ranger",
  num.trees = 100, mtry = 20,
  min.node.size = 2, max.depth = 5)
ml_r = ml_m$clone()
obj_dml_data = make_iivm_data(
  theta = 0.5, n_obs = 1000,
  alpha_x = 1, dim_x = 20)
dml_iivm_obj = DoubleMLIIVM$new(obj_dml_data, ml_g, ml_m, ml_r)
dml_iivm_obj$fit()
dml_iivm_obj$summary()


## Not run: 
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(data.table)
set.seed(2)
ml_g = lrn("regr.rpart")
ml_m = lrn("classif.rpart")
ml_r = ml_m$clone()
obj_dml_data = make_iivm_data(
  theta = 0.5, n_obs = 1000,
  alpha_x = 1, dim_x = 20)
dml_iivm_obj = DoubleMLIIVM$new(obj_dml_data, ml_g, ml_m, ml_r)
param_grid = list(
  "ml_g" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)),
  "ml_m" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)),
  "ml_r" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)))
# minimum requirements for tune_settings
tune_settings = list(
  terminator = mlr3tuning::trm("evals", n_evals = 5),
  algorithm = mlr3tuning::tnr("grid_search", resolution = 5))
dml_iivm_obj$tune(param_set = param_grid, tune_settings = tune_settings)
dml_iivm_obj$fit()
dml_iivm_obj$summary()

## End(Not run)

</code></pre>

<hr>
<h2 id='DoubleMLIRM'>Double machine learning for interactive regression models</h2><span id='topic+DoubleMLIRM'></span>

<h3>Description</h3>

<p>Double machine learning for interactive regression models.
</p>


<h3>Format</h3>

<p><a href="R6.html#topic+R6Class">R6::R6Class</a> object inheriting from <a href="#topic+DoubleML">DoubleML</a>.
</p>


<h3>Details</h3>

<p>Interactive regression (IRM) models take the form
</p>
<p><code class="reqn">Y = g_0(D,X) + U</code>,
</p>
<p><code class="reqn">D = m_0(X) + V</code>,
</p>
<p>with <code class="reqn">E[U|X,D]=0</code> and <code class="reqn">E[V|X] = 0</code>. <code class="reqn">Y</code> is the outcome variable
and <code class="reqn">D \in \{0,1\}</code> is the binary treatment variable. We consider
estimation of the average treamtent effects when treatment effects are
fully heterogeneous. Target parameters of interest in this model are the
average treatment effect (ATE),
</p>
<p><code class="reqn">\theta_0 = E[g_0(1,X) - g_0(0,X)]</code>
</p>
<p>and the average treament effect on the treated (ATTE),
</p>
<p><code class="reqn">\theta_0 = E[g_0(1,X) - g_0(0,X)|D=1]</code>.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+DoubleML">DoubleML::DoubleML</a></code> -&gt; <code>DoubleMLIRM</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>trimming_rule</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code> specifying the trimming approach.</p>
</dd>
<dt><code>trimming_threshold</code></dt><dd><p>(<code>numeric(1)</code>) <br />
The threshold used for timming.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DoubleMLIRM-new"><code>DoubleMLIRM$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLIRM-clone"><code>DoubleMLIRM$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="bootstrap"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-bootstrap'><code>DoubleML::DoubleML$bootstrap()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="confint"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-confint'><code>DoubleML::DoubleML$confint()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="fit"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-fit'><code>DoubleML::DoubleML$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="get_params"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-get_params'><code>DoubleML::DoubleML$get_params()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="learner_names"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-learner_names'><code>DoubleML::DoubleML$learner_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="p_adjust"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-p_adjust'><code>DoubleML::DoubleML$p_adjust()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="params_names"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-params_names'><code>DoubleML::DoubleML$params_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="print"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-print'><code>DoubleML::DoubleML$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="set_ml_nuisance_params"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-set_ml_nuisance_params'><code>DoubleML::DoubleML$set_ml_nuisance_params()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="set_sample_splitting"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-set_sample_splitting'><code>DoubleML::DoubleML$set_sample_splitting()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="split_samples"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-split_samples'><code>DoubleML::DoubleML$split_samples()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="summary"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-summary'><code>DoubleML::DoubleML$summary()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="tune"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-tune'><code>DoubleML::DoubleML$tune()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-DoubleMLIRM-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLIRM$new(
  data,
  ml_g,
  ml_m,
  n_folds = 5,
  n_rep = 1,
  score = "ATE",
  trimming_rule = "truncate",
  trimming_threshold = 1e-12,
  dml_procedure = "dml2",
  draw_sample_splitting = TRUE,
  apply_cross_fitting = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>(<code>DoubleMLData</code>) <br />
The <code>DoubleMLData</code> object providing the data and specifying the variables
of the causal model.</p>
</dd>
<dt><code>ml_g</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>,
<code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code>, <code><a href="mlr3.html#topic+Learner">Learner</a></code>,
<code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
For binary treatment outcomes, an object of the class
<code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code> can be passed, for example
<code>lrn("classif.cv_glmnet", s = "lambda.min")</code>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "regr"</code> or <code>task_type = "classif"</code> can be passed,
respectively, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. <br />
<code>ml_g</code> refers to the nuisance function <code class="reqn">g_0(X) = E[Y|X,D]</code>.</p>
</dd>
<dt><code>ml_m</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code>,
<code><a href="mlr3.html#topic+Learner">Learner</a></code>, <code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "classif"</code> can be passed, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("classif.cv_glmnet", s = "lambda.min")</code>. <br />
<code>ml_m</code> refers to the nuisance function <code class="reqn">m_0(X) = E[D|X]</code>.</p>
</dd>
<dt><code>n_folds</code></dt><dd><p>(<code>integer(1)</code>)<br />
Number of folds. Default is <code>5</code>.</p>
</dd>
<dt><code>n_rep</code></dt><dd><p>(<code>integer(1)</code>) <br />
Number of repetitions for the sample splitting. Default is <code>1</code>.</p>
</dd>
<dt><code>score</code></dt><dd><p>(<code>character(1)</code>, <code style="white-space: pre;">&#8288;function()&#8288;</code>) <br />
A <code>character(1)</code> (<code>"ATE"</code> or <code>ATTE</code>) or a <code style="white-space: pre;">&#8288;function()&#8288;</code> specifying the
score function. If a <code style="white-space: pre;">&#8288;function()&#8288;</code>
is provided, it must be of the form
<code style="white-space: pre;">&#8288;function(y, d, g0_hat, g1_hat, m_hat, smpls)&#8288;</code> and the returned output
must be a named <code>list()</code> with elements <code>psi_a</code> and <code>psi_b</code>.
Default is <code>"ATE"</code>.</p>
</dd>
<dt><code>trimming_rule</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code> (<code>"truncate"</code> is the only choice) specifying the
trimming approach. Default is <code>"truncate"</code>.</p>
</dd>
<dt><code>trimming_threshold</code></dt><dd><p>(<code>numeric(1)</code>) <br />
The threshold used for timming. Default is <code>1e-12</code>.</p>
</dd>
<dt><code>dml_procedure</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code> (<code>"dml1"</code> or <code>"dml2"</code>) specifying the double machine
learning algorithm. Default is <code>"dml2"</code>.</p>
</dd>
<dt><code>draw_sample_splitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the sample splitting should be drawn during
initialization of the object. Default is <code>TRUE</code>.</p>
</dd>
<dt><code>apply_cross_fitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether cross-fitting should be applied. Default is <code>TRUE</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DoubleMLIRM-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLIRM$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other DoubleML: 
<code><a href="#topic+DoubleML">DoubleML</a></code>,
<code><a href="#topic+DoubleMLIIVM">DoubleMLIIVM</a></code>,
<code><a href="#topic+DoubleMLPLIV">DoubleMLPLIV</a></code>,
<code><a href="#topic+DoubleMLPLR">DoubleMLPLR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
set.seed(2)
ml_g = lrn("regr.ranger",
  num.trees = 100, mtry = 20,
  min.node.size = 2, max.depth = 5)
ml_m = lrn("classif.ranger",
  num.trees = 100, mtry = 20,
  min.node.size = 2, max.depth = 5)
obj_dml_data = make_irm_data(theta = 0.5)
dml_irm_obj = DoubleMLIRM$new(obj_dml_data, ml_g, ml_m)
dml_irm_obj$fit()
dml_irm_obj$summary()

## Not run: 
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(mlr3uning)
library(data.table)
set.seed(2)
ml_g = lrn("regr.rpart")
ml_m = lrn("classif.rpart")
obj_dml_data = make_irm_data(theta = 0.5)
dml_irm_obj = DoubleMLIRM$new(obj_dml_data, ml_g, ml_m)

param_grid = list(
  "ml_g" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)),
  "ml_m" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)))

# minimum requirements for tune_settings
tune_settings = list(
  terminator = mlr3tuning::trm("evals", n_evals = 5),
  algorithm = mlr3tuning::tnr("grid_search", resolution = 5))
dml_irm_obj$tune(param_set = param_grid, tune_settings = tune_settings)
dml_irm_obj$fit()
dml_irm_obj$summary()

## End(Not run)

</code></pre>

<hr>
<h2 id='DoubleMLPLIV'>Double machine learning for partially linear IV regression models</h2><span id='topic+DoubleMLPLIV'></span>

<h3>Description</h3>

<p>Double machine learning for partially linear IV regression models.
</p>


<h3>Format</h3>

<p><a href="R6.html#topic+R6Class">R6::R6Class</a> object inheriting from <a href="#topic+DoubleML">DoubleML</a>.
</p>


<h3>Details</h3>

<p>Partially linear IV regression (PLIV) models take the form
</p>
<p><code class="reqn">Y - D\theta_0 = g_0(X) + \zeta</code>,
</p>
<p><code class="reqn">Z = m_0(X) + V</code>,
</p>
<p>with <code class="reqn">E[\zeta|Z,X]=0</code> and <code class="reqn">E[V|X] = 0</code>. <code class="reqn">Y</code> is the outcome variable variable, <code class="reqn">D</code> is the policy variable of interest and <code class="reqn">Z</code> denotes one or multiple instrumental variables. The high-dimensional vector <code class="reqn">X = (X_1, \ldots, X_p)</code> consists of other confounding covariates, and <code class="reqn">\zeta</code> and <code class="reqn">V</code> are stochastic errors.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+DoubleML">DoubleML::DoubleML</a></code> -&gt; <code>DoubleMLPLIV</code>
</p>


<h3>Active bindings</h3>

<div class="r6-active-bindings">

<dl>
<dt><code>partialX</code></dt><dd><p>(<code>logical(1)</code>)  <br />
Indicates whether covariates <code class="reqn">X</code> should be partialled out.</p>
</dd>
<dt><code>partialZ</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether instruments <code class="reqn">Z</code> should be partialled out.</p>
</dd>
</dl>

</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DoubleMLPLIV-new"><code>DoubleMLPLIV$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLPLIV-set_ml_nuisance_params"><code>DoubleMLPLIV$set_ml_nuisance_params()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLPLIV-tune"><code>DoubleMLPLIV$tune()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLPLIV-clone"><code>DoubleMLPLIV$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="bootstrap"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-bootstrap'><code>DoubleML::DoubleML$bootstrap()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="confint"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-confint'><code>DoubleML::DoubleML$confint()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="fit"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-fit'><code>DoubleML::DoubleML$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="get_params"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-get_params'><code>DoubleML::DoubleML$get_params()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="learner_names"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-learner_names'><code>DoubleML::DoubleML$learner_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="p_adjust"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-p_adjust'><code>DoubleML::DoubleML$p_adjust()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="params_names"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-params_names'><code>DoubleML::DoubleML$params_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="print"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-print'><code>DoubleML::DoubleML$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="set_sample_splitting"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-set_sample_splitting'><code>DoubleML::DoubleML$set_sample_splitting()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="split_samples"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-split_samples'><code>DoubleML::DoubleML$split_samples()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="summary"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-summary'><code>DoubleML::DoubleML$summary()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-DoubleMLPLIV-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLIV$new(
  data,
  ml_l,
  ml_m,
  ml_r,
  ml_g = NULL,
  partialX = TRUE,
  partialZ = FALSE,
  n_folds = 5,
  n_rep = 1,
  score = "partialling out",
  dml_procedure = "dml2",
  draw_sample_splitting = TRUE,
  apply_cross_fitting = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>(<code>DoubleMLData</code>) <br />
The <code>DoubleMLData</code> object providing the data and specifying the variables
of the causal model.</p>
</dd>
<dt><code>ml_l</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>,
<code><a href="mlr3.html#topic+Learner">Learner</a></code>, <code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>.  <br />
<code>ml_l</code> refers to the nuisance function <code class="reqn">l_0(X) = E[Y|X]</code>.</p>
</dd>
<dt><code>ml_m</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>,
<code><a href="mlr3.html#topic+Learner">Learner</a></code>, <code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>. <br />
<code>ml_m</code> refers to the nuisance function <code class="reqn">m_0(X) = E[Z|X]</code>.</p>
</dd>
<dt><code>ml_r</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>,
<code><a href="mlr3.html#topic+Learner">Learner</a></code>, <code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>. <br />
<code>ml_r</code> refers to the nuisance function <code class="reqn">r_0(X) = E[D|X]</code>.</p>
</dd>
<dt><code>ml_g</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>,
<code><a href="mlr3.html#topic+Learner">Learner</a></code>, <code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>. <br />
<code>ml_g</code> refers to the nuisance function <code class="reqn">g_0(X) = E[Y - D\theta_0|X]</code>.
Note: The learner <code>ml_g</code> is only required for the score <code>'IV-type'</code>.
Optionally, it can be specified and estimated for callable scores.</p>
</dd>
<dt><code>partialX</code></dt><dd><p>(<code>logical(1)</code>)  <br />
Indicates whether covariates <code class="reqn">X</code> should be partialled out.
Default is <code>TRUE</code>.</p>
</dd>
<dt><code>partialZ</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether instruments <code class="reqn">Z</code> should be partialled out.
Default is <code>FALSE</code>.</p>
</dd>
<dt><code>n_folds</code></dt><dd><p>(<code>integer(1)</code>)<br />
Number of folds. Default is <code>5</code>.</p>
</dd>
<dt><code>n_rep</code></dt><dd><p>(<code>integer(1)</code>) <br />
Number of repetitions for the sample splitting. Default is <code>1</code>.</p>
</dd>
<dt><code>score</code></dt><dd><p>(<code>character(1)</code>, <code style="white-space: pre;">&#8288;function()&#8288;</code>) <br />
A <code>character(1)</code> (<code>"partialling out"</code> or <code>"IV-type"</code>) or a <code style="white-space: pre;">&#8288;function()&#8288;</code>
specifying the score function.
If a <code style="white-space: pre;">&#8288;function()&#8288;</code> is provided, it must be of the form
<code style="white-space: pre;">&#8288;function(y, z, d, l_hat, m_hat, r_hat, g_hat, smpls)&#8288;</code> and
the returned output must be a named <code>list()</code> with elements
<code>psi_a</code> and <code>psi_b</code>. Default is <code>"partialling out"</code>.</p>
</dd>
<dt><code>dml_procedure</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code> (<code>"dml1"</code> or <code>"dml2"</code>) specifying the double machine
learning algorithm. Default is <code>"dml2"</code>.</p>
</dd>
<dt><code>draw_sample_splitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the sample splitting should be drawn during
initialization of the object. Default is <code>TRUE</code>.</p>
</dd>
<dt><code>apply_cross_fitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether cross-fitting should be applied. Default is <code>TRUE</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DoubleMLPLIV-set_ml_nuisance_params"></a>



<h4>Method <code>set_ml_nuisance_params()</code></h4>

<p>Set hyperparameters for the nuisance models of DoubleML models.
</p>
<p>Note that in the current implementation, either all parameters have to
be set globally or all parameters have to be provided fold-specific.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLIV$set_ml_nuisance_params(
  learner = NULL,
  treat_var = NULL,
  params,
  set_fold_specific = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt><dd><p>(<code>character(1)</code>) <br />
The nuisance model/learner (see method <code>params_names</code>).</p>
</dd>
<dt><code>treat_var</code></dt><dd><p>(<code>character(1)</code>) <br />
The treatment varaible (hyperparameters can be set treatment-variable
specific).</p>
</dd>
<dt><code>params</code></dt><dd><p>(named <code>list()</code>) <br />
A named <code>list()</code> with estimator parameters. Parameters are used for all
folds by default. Alternatively, parameters can be passed in a
fold-specific way if option  <code>fold_specific</code>is <code>TRUE</code>. In this case, the
outer list needs to be of length <code>n_rep</code> and the inner list of length
<code>n_folds</code>.</p>
</dd>
<dt><code>set_fold_specific</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates if the parameters passed in <code>params</code> should be passed in
fold-specific way. Default is <code>FALSE</code>. If <code>TRUE</code>, the outer list needs
to be of length <code>n_rep</code> and the inner list of length <code>n_folds</code>.
Note that in the current implementation, either all parameters have to
be set globally or all parameters have to be provided fold-specific.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleMLPLIV-tune"></a>



<h4>Method <code>tune()</code></h4>

<p>Hyperparameter-tuning for DoubleML models.
</p>
<p>The hyperparameter-tuning is performed using the tuning methods provided
in the <a href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package. For more
information on tuning in <a href="https://mlr3.mlr-org.com/">mlr3</a>, we refer to
the section on parameter tuning in the
<a href="https://mlr3book.mlr-org.com/chapters/chapter4/hyperparameter_optimization.html">mlr3 book</a>.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLIV$tune(
  param_set,
  tune_settings = list(n_folds_tune = 5, rsmp_tune = mlr3::rsmp("cv", folds = 5), measure
    = NULL, terminator = mlr3tuning::trm("evals", n_evals = 20), algorithm =
    mlr3tuning::tnr("grid_search"), resolution = 5),
  tune_on_folds = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>param_set</code></dt><dd><p>(named <code>list()</code>) <br />
A named <code>list</code> with a parameter grid for each nuisance model/learner
(see method <code>learner_names()</code>). The parameter grid must be an object of
class <a href="paradox.html#topic+ParamSet">ParamSet</a>.</p>
</dd>
<dt><code>tune_settings</code></dt><dd><p>(named <code>list()</code>) <br />
A named <code>list()</code> with arguments passed to the hyperparameter-tuning with
<a href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> to set up
<a href="mlr3tuning.html#topic+TuningInstanceSingleCrit">TuningInstance</a> objects.
<code>tune_settings</code> has entries
</p>

<ul>
<li> <p><code>terminator</code> (<a href="bbotk.html#topic+Terminator">Terminator</a>) <br />
A <a href="bbotk.html#topic+Terminator">Terminator</a> object. Specification of <code>terminator</code>
is required to perform tuning.
</p>
</li>
<li> <p><code>algorithm</code> (<a href="mlr3tuning.html#topic+Tuner">Tuner</a> or <code>character(1)</code>) <br />
A <a href="mlr3tuning.html#topic+Tuner">Tuner</a> object (recommended) or key passed to the
respective dictionary to specify the tuning algorithm used in
<a href="mlr3tuning.html#topic+tnr">tnr()</a>. <code>algorithm</code> is passed as an argument to
<a href="mlr3tuning.html#topic+tnr">tnr()</a>. If <code>algorithm</code> is not specified by the users,
default is set to <code>"grid_search"</code>. If set to <code>"grid_search"</code>, then
additional argument <code>"resolution"</code> is required.
</p>
</li>
<li> <p><code>rsmp_tune</code> (<a href="mlr3.html#topic+Resampling">Resampling</a> or <code>character(1)</code>)<br />
A <a href="mlr3.html#topic+Resampling">Resampling</a> object (recommended) or option passed
to <a href="mlr3.html#topic+mlr_sugar">rsmp()</a> to initialize a
<a href="mlr3.html#topic+Resampling">Resampling</a> for parameter tuning in <code>mlr3</code>.
If not specified by the user, default is set to <code>"cv"</code>
(cross-validation).
</p>
</li>
<li> <p><code>n_folds_tune</code> (<code>integer(1)</code>, optional) <br />
If <code>rsmp_tune = "cv"</code>, number of folds used for cross-validation.
If not specified by the user, default is set to <code>5</code>.
</p>
</li>
<li> <p><code>measure</code> (<code>NULL</code>, named <code>list()</code>, optional) <br />
Named list containing the measures used for parameter tuning. Entries in
list must either be <a href="mlr3.html#topic+Measure">Measure</a> objects or keys to be
passed to passed to <a href="mlr3.html#topic+mlr_sugar">msr()</a>. The names of the entries must
match the learner names (see method <code>learner_names()</code>). If set to <code>NULL</code>,
default measures are used, i.e., <code>"regr.mse"</code> for continuous outcome
variables and <code>"classif.ce"</code> for binary outcomes.
</p>
</li>
<li> <p><code>resolution</code> (<code>character(1)</code>) <br /> The key passed to the respective
dictionary to specify  the tuning algorithm used in
<a href="mlr3tuning.html#topic+tnr">tnr()</a>. <code>resolution</code> is passed as an argument to
<a href="mlr3tuning.html#topic+tnr">tnr()</a>.
</p>
</li></ul>
</dd>
<dt><code>tune_on_folds</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the tuning should be done fold-specific or globally.
Default is <code>FALSE</code>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleMLPLIV-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLIV$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other DoubleML: 
<code><a href="#topic+DoubleML">DoubleML</a></code>,
<code><a href="#topic+DoubleMLIIVM">DoubleMLIIVM</a></code>,
<code><a href="#topic+DoubleMLIRM">DoubleMLIRM</a></code>,
<code><a href="#topic+DoubleMLPLR">DoubleMLPLR</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
set.seed(2)
ml_l = lrn("regr.ranger", num.trees = 100, mtry = 20, min.node.size = 2, max.depth = 5)
ml_m = ml_l$clone()
ml_r = ml_l$clone()
obj_dml_data = make_pliv_CHS2015(alpha = 1, n_obs = 500, dim_x = 20, dim_z = 1)
dml_pliv_obj = DoubleMLPLIV$new(obj_dml_data, ml_l, ml_m, ml_r)
dml_pliv_obj$fit()
dml_pliv_obj$summary()


## Not run: 
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(data.table)
set.seed(2)
ml_l = lrn("regr.rpart")
ml_m = ml_l$clone()
ml_r = ml_l$clone()
obj_dml_data = make_pliv_CHS2015(
  alpha = 1, n_obs = 500, dim_x = 20,
  dim_z = 1)
dml_pliv_obj = DoubleMLPLIV$new(obj_dml_data, ml_l, ml_m, ml_r)
param_grid = list(
  "ml_l" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)),
  "ml_m" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)),
  "ml_r" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)))

# minimum requirements for tune_settings
tune_settings = list(
  terminator = mlr3tuning::trm("evals", n_evals = 5),
  algorithm = mlr3tuning::tnr("grid_search", resolution = 5))
dml_pliv_obj$tune(param_set = param_grid, tune_settings = tune_settings)
dml_pliv_obj$fit()
dml_pliv_obj$summary()

## End(Not run)
</code></pre>

<hr>
<h2 id='DoubleMLPLR'>Double machine learning for partially linear regression models</h2><span id='topic+DoubleMLPLR'></span>

<h3>Description</h3>

<p>Double machine learning for partially linear regression models.
</p>


<h3>Format</h3>

<p><a href="R6.html#topic+R6Class">R6::R6Class</a> object inheriting from <a href="#topic+DoubleML">DoubleML</a>.
</p>


<h3>Details</h3>

<p>Partially linear regression (PLR) models take the form
</p>
<p><code class="reqn">Y = D\theta_0 + g_0(X) + \zeta,</code>
</p>
<p><code class="reqn">D = m_0(X) + V,</code>
</p>
<p>with <code class="reqn">E[\zeta|D,X]=0</code> and <code class="reqn">E[V|X] = 0</code>. <code class="reqn">Y</code> is the outcome
variable variable and <code class="reqn">D</code> is the policy variable of interest.
The high-dimensional vector <code class="reqn">X = (X_1, \ldots, X_p)</code> consists of other
confounding covariates, and <code class="reqn">\zeta</code> and <code class="reqn">V</code> are stochastic errors.
</p>


<h3>Super class</h3>

<p><code><a href="#topic+DoubleML">DoubleML::DoubleML</a></code> -&gt; <code>DoubleMLPLR</code>
</p>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-DoubleMLPLR-new"><code>DoubleMLPLR$new()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLPLR-set_ml_nuisance_params"><code>DoubleMLPLR$set_ml_nuisance_params()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLPLR-tune"><code>DoubleMLPLR$tune()</code></a>
</p>
</li>
<li> <p><a href="#method-DoubleMLPLR-clone"><code>DoubleMLPLR$clone()</code></a>
</p>
</li></ul>



<details><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="bootstrap"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-bootstrap'><code>DoubleML::DoubleML$bootstrap()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="confint"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-confint'><code>DoubleML::DoubleML$confint()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="fit"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-fit'><code>DoubleML::DoubleML$fit()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="get_params"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-get_params'><code>DoubleML::DoubleML$get_params()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="learner_names"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-learner_names'><code>DoubleML::DoubleML$learner_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="p_adjust"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-p_adjust'><code>DoubleML::DoubleML$p_adjust()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="params_names"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-params_names'><code>DoubleML::DoubleML$params_names()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="print"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-print'><code>DoubleML::DoubleML$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="set_sample_splitting"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-set_sample_splitting'><code>DoubleML::DoubleML$set_sample_splitting()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="split_samples"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-split_samples'><code>DoubleML::DoubleML$split_samples()</code></a></span></li>
<li><span class="pkg-link" data-pkg="DoubleML" data-topic="DoubleML" data-id="summary"><a href='../../DoubleML/html/DoubleML.html#method-DoubleML-summary'><code>DoubleML::DoubleML$summary()</code></a></span></li>
</ul>
</details>

<hr>
<a id="method-DoubleMLPLR-new"></a>



<h4>Method <code>new()</code></h4>

<p>Creates a new instance of this R6 class.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLR$new(
  data,
  ml_l,
  ml_m,
  ml_g = NULL,
  n_folds = 5,
  n_rep = 1,
  score = "partialling out",
  dml_procedure = "dml2",
  draw_sample_splitting = TRUE,
  apply_cross_fitting = TRUE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>data</code></dt><dd><p>(<code>DoubleMLData</code>) <br />
The <code>DoubleMLData</code> object providing the data and specifying the
variables of the causal model.</p>
</dd>
<dt><code>ml_l</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>,
<code><a href="mlr3.html#topic+Learner">Learner</a></code>, <code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>. <br />
<code>ml_l</code> refers to the nuisance function <code class="reqn">l_0(X) = E[Y|X]</code>.</p>
</dd>
<dt><code>ml_m</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>,
<code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code>, <code><a href="mlr3.html#topic+Learner">Learner</a></code>,
<code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
For binary treatment variables, an object of the class
<code><a href="mlr3.html#topic+LearnerClassif">LearnerClassif</a></code> can be passed, for example
<code>lrn("classif.cv_glmnet", s = "lambda.min")</code>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "regr"</code> or <code>task_type = "classif"</code> can be passed,
respectively, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. <br />
<code>ml_m</code> refers to the nuisance function <code class="reqn">m_0(X) = E[D|X]</code>.</p>
</dd>
<dt><code>ml_g</code></dt><dd><p>(<code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>,
<code><a href="mlr3.html#topic+Learner">Learner</a></code>, <code>character(1)</code>) <br />
A learner of the class <code><a href="mlr3.html#topic+LearnerRegr">LearnerRegr</a></code>, which is
available from <a href="https://mlr3.mlr-org.com/index.html">mlr3</a> or its
extension packages <a href="https://mlr3learners.mlr-org.com/">mlr3learners</a> or
<a href="https://mlr3extralearners.mlr-org.com/">mlr3extralearners</a>.
Alternatively, a <code><a href="mlr3.html#topic+Learner">Learner</a></code> object with public field
<code>task_type = "regr"</code> can be passed, for example of class
<code><a href="mlr3pipelines.html#topic+mlr_learners_graph">GraphLearner</a></code>. The learner can possibly
be passed with specified parameters, for example
<code>lrn("regr.cv_glmnet", s = "lambda.min")</code>. <br />
<code>ml_g</code> refers to the nuisance function <code class="reqn">g_0(X) = E[Y - D\theta_0|X]</code>.
Note: The learner <code>ml_g</code> is only required for the score <code>'IV-type'</code>.
Optionally, it can be specified and estimated for callable scores.</p>
</dd>
<dt><code>n_folds</code></dt><dd><p>(<code>integer(1)</code>)<br />
Number of folds. Default is <code>5</code>.</p>
</dd>
<dt><code>n_rep</code></dt><dd><p>(<code>integer(1)</code>) <br />
Number of repetitions for the sample splitting. Default is <code>1</code>.</p>
</dd>
<dt><code>score</code></dt><dd><p>(<code>character(1)</code>, <code style="white-space: pre;">&#8288;function()&#8288;</code>) <br />
A <code>character(1)</code> (<code>"partialling out"</code> or <code>"IV-type"</code>) or a <code style="white-space: pre;">&#8288;function()&#8288;</code>
specifying the score function.
If a <code style="white-space: pre;">&#8288;function()&#8288;</code> is provided, it must be of the form
<code style="white-space: pre;">&#8288;function(y, d, l_hat, m_hat, g_hat, smpls)&#8288;</code> and
the returned output must be a named <code>list()</code> with elements <code>psi_a</code> and
<code>psi_b</code>. Default is <code>"partialling out"</code>.</p>
</dd>
<dt><code>dml_procedure</code></dt><dd><p>(<code>character(1)</code>) <br />
A <code>character(1)</code> (<code>"dml1"</code> or <code>"dml2"</code>) specifying the double machine
learning algorithm. Default is <code>"dml2"</code>.</p>
</dd>
<dt><code>draw_sample_splitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the sample splitting should be drawn during
initialization of the object. Default is <code>TRUE</code>.</p>
</dd>
<dt><code>apply_cross_fitting</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether cross-fitting should be applied. Default is <code>TRUE</code>.</p>
</dd>
</dl>

</div>


<hr>
<a id="method-DoubleMLPLR-set_ml_nuisance_params"></a>



<h4>Method <code>set_ml_nuisance_params()</code></h4>

<p>Set hyperparameters for the nuisance models of DoubleML models.
</p>
<p>Note that in the current implementation, either all parameters have to
be set globally or all parameters have to be provided fold-specific.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLR$set_ml_nuisance_params(
  learner = NULL,
  treat_var = NULL,
  params,
  set_fold_specific = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>learner</code></dt><dd><p>(<code>character(1)</code>) <br />
The nuisance model/learner (see method <code>params_names</code>).</p>
</dd>
<dt><code>treat_var</code></dt><dd><p>(<code>character(1)</code>) <br />
The treatment varaible (hyperparameters can be set treatment-variable
specific).</p>
</dd>
<dt><code>params</code></dt><dd><p>(named <code>list()</code>) <br />
A named <code>list()</code> with estimator parameters. Parameters are used for all
folds by default. Alternatively, parameters can be passed in a
fold-specific way if option  <code>fold_specific</code>is <code>TRUE</code>. In this case, the
outer list needs to be of length <code>n_rep</code> and the inner list of length
<code>n_folds</code>.</p>
</dd>
<dt><code>set_fold_specific</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates if the parameters passed in <code>params</code> should be passed in
fold-specific way. Default is <code>FALSE</code>. If <code>TRUE</code>, the outer list needs
to be of length <code>n_rep</code> and the inner list of length <code>n_folds</code>.
Note that in the current implementation, either all parameters have to
be set globally or all parameters have to be provided fold-specific.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleMLPLR-tune"></a>



<h4>Method <code>tune()</code></h4>

<p>Hyperparameter-tuning for DoubleML models.
</p>
<p>The hyperparameter-tuning is performed using the tuning methods provided
in the <a href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> package. For more
information on tuning in <a href="https://mlr3.mlr-org.com/">mlr3</a>, we refer to
the section on parameter tuning in the
<a href="https://mlr3book.mlr-org.com/chapters/chapter4/hyperparameter_optimization.html">mlr3 book</a>.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLR$tune(
  param_set,
  tune_settings = list(n_folds_tune = 5, rsmp_tune = mlr3::rsmp("cv", folds = 5), measure
    = NULL, terminator = mlr3tuning::trm("evals", n_evals = 20), algorithm =
    mlr3tuning::tnr("grid_search"), resolution = 5),
  tune_on_folds = FALSE
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>param_set</code></dt><dd><p>(named <code>list()</code>) <br />
A named <code>list</code> with a parameter grid for each nuisance model/learner
(see method <code>learner_names()</code>). The parameter grid must be an object of
class <a href="paradox.html#topic+ParamSet">ParamSet</a>.</p>
</dd>
<dt><code>tune_settings</code></dt><dd><p>(named <code>list()</code>) <br />
A named <code>list()</code> with arguments passed to the hyperparameter-tuning with
<a href="https://mlr3tuning.mlr-org.com/">mlr3tuning</a> to set up
<a href="mlr3tuning.html#topic+TuningInstanceSingleCrit">TuningInstance</a> objects.
<code>tune_settings</code> has entries
</p>

<ul>
<li> <p><code>terminator</code> (<a href="bbotk.html#topic+Terminator">Terminator</a>) <br />
A <a href="bbotk.html#topic+Terminator">Terminator</a> object. Specification of <code>terminator</code>
is required to perform tuning.
</p>
</li>
<li> <p><code>algorithm</code> (<a href="mlr3tuning.html#topic+Tuner">Tuner</a> or <code>character(1)</code>) <br />
A <a href="mlr3tuning.html#topic+Tuner">Tuner</a> object (recommended) or key passed to the
respective dictionary to specify the tuning algorithm used in
<a href="mlr3tuning.html#topic+tnr">tnr()</a>. <code>algorithm</code> is passed as an argument to
<a href="mlr3tuning.html#topic+tnr">tnr()</a>. If <code>algorithm</code> is not specified by the users,
default is set to <code>"grid_search"</code>. If set to <code>"grid_search"</code>, then
additional argument <code>"resolution"</code> is required.
</p>
</li>
<li> <p><code>rsmp_tune</code> (<a href="mlr3.html#topic+Resampling">Resampling</a> or <code>character(1)</code>)<br />
A <a href="mlr3.html#topic+Resampling">Resampling</a> object (recommended) or option passed
to <a href="mlr3.html#topic+mlr_sugar">rsmp()</a> to initialize a
<a href="mlr3.html#topic+Resampling">Resampling</a> for parameter tuning in <code>mlr3</code>.
If not specified by the user, default is set to <code>"cv"</code>
(cross-validation).
</p>
</li>
<li> <p><code>n_folds_tune</code> (<code>integer(1)</code>, optional) <br />
If <code>rsmp_tune = "cv"</code>, number of folds used for cross-validation.
If not specified by the user, default is set to <code>5</code>.
</p>
</li>
<li> <p><code>measure</code> (<code>NULL</code>, named <code>list()</code>, optional) <br />
Named list containing the measures used for parameter tuning. Entries in
list must either be <a href="mlr3.html#topic+Measure">Measure</a> objects or keys to be
passed to passed to <a href="mlr3.html#topic+mlr_sugar">msr()</a>. The names of the entries must
match the learner names (see method <code>learner_names()</code>). If set to <code>NULL</code>,
default measures are used, i.e., <code>"regr.mse"</code> for continuous outcome
variables and <code>"classif.ce"</code> for binary outcomes.
</p>
</li>
<li> <p><code>resolution</code> (<code>character(1)</code>) <br /> The key passed to the respective
dictionary to specify  the tuning algorithm used in
<a href="mlr3tuning.html#topic+tnr">tnr()</a>. <code>resolution</code> is passed as an argument to
<a href="mlr3tuning.html#topic+tnr">tnr()</a>.
</p>
</li></ul>
</dd>
<dt><code>tune_on_folds</code></dt><dd><p>(<code>logical(1)</code>) <br />
Indicates whether the tuning should be done fold-specific or globally.
Default is <code>FALSE</code>.</p>
</dd>
</dl>

</div>



<h5>Returns</h5>

<p>self
</p>


<hr>
<a id="method-DoubleMLPLR-clone"></a>



<h4>Method <code>clone()</code></h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>DoubleMLPLR$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p>
</dd>
</dl>

</div>




<h3>See Also</h3>

<p>Other DoubleML: 
<code><a href="#topic+DoubleML">DoubleML</a></code>,
<code><a href="#topic+DoubleMLIIVM">DoubleMLIIVM</a></code>,
<code><a href="#topic+DoubleMLIRM">DoubleMLIRM</a></code>,
<code><a href="#topic+DoubleMLPLIV">DoubleMLPLIV</a></code>
</p>


<h3>Examples</h3>

<pre><code class='language-R'>
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(data.table)
set.seed(2)
ml_g = lrn("regr.ranger", num.trees = 10, max.depth = 2)
ml_m = ml_g$clone()
obj_dml_data = make_plr_CCDDHNR2018(alpha = 0.5)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_g, ml_m)
dml_plr_obj$fit()
dml_plr_obj$summary()


## Not run: 
library(DoubleML)
library(mlr3)
library(mlr3learners)
library(mlr3tuning)
library(data.table)
set.seed(2)
ml_l = lrn("regr.rpart")
ml_m = ml_l$clone()
obj_dml_data = make_plr_CCDDHNR2018(alpha = 0.5)
dml_plr_obj = DoubleMLPLR$new(obj_dml_data, ml_l, ml_m)

param_grid = list(
  "ml_l" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)),
  "ml_m" = paradox::ps(
    cp = paradox::p_dbl(lower = 0.01, upper = 0.02),
    minsplit = paradox::p_int(lower = 1, upper = 2)))

# minimum requirements for tune_settings
tune_settings = list(
  terminator = mlr3tuning::trm("evals", n_evals = 5),
  algorithm = mlr3tuning::tnr("grid_search", resolution = 5))
dml_plr_obj$tune(param_set = param_grid, tune_settings = tune_settings)
dml_plr_obj$fit()
dml_plr_obj$summary()

## End(Not run)
</code></pre>

<hr>
<h2 id='fetch_401k'>Data set on financial wealth and 401(k) plan participation.</h2><span id='topic+fetch_401k'></span>

<h3>Description</h3>

<p>Preprocessed data set on financial wealth and 401(k) plan participation.
The raw data files are preprocessed to reproduce the examples in
Chernozhukov et al. (2020).
An internet connection is required to sucessfully download the data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fetch_401k(
  return_type = "DoubleMLData",
  polynomial_features = FALSE,
  instrument = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fetch_401k_+3A_return_type">return_type</code></td>
<td>
<p>(<code>character(1)</code>) <br />
If <code>"DoubleMLData"</code>, returns a <code>DoubleMLData</code> object.
If <code>"data.frame"</code> returns a <code>data.frame()</code>.
If <code>"data.table"</code> returns a <code>data.table()</code>.
Default is <code>"DoubleMLData"</code>.</p>
</td></tr>
<tr><td><code id="fetch_401k_+3A_polynomial_features">polynomial_features</code></td>
<td>
<p>(<code>logical(1)</code>) <br />
If <code>TRUE</code> polynomial freatures are added
(see replication file of Chernozhukov et al. (2018)).</p>
</td></tr>
<tr><td><code id="fetch_401k_+3A_instrument">instrument</code></td>
<td>
<p>(<code>logical(1)</code>) <br />
If <code>TRUE</code>, the returned data object contains the variables <code>e401</code> and <code>p401</code>.
If <code>return_type = "DoubleMLData"</code>, the variable <code>e401</code> is used as an
instrument for the endogenous treatment variable <code>p401</code>.
If <code>FALSE</code>, <code>p401</code> is removed from the data set.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variable description, based on the supplementary material of
Chernozhukov et al. (2020):
</p>

<ul>
<li><p> net_tfa: net total financial assets
</p>
</li>
<li><p> e401: = 1 if employer offers 401(k)
</p>
</li>
<li><p> p401: = 1 if individual participates in a 401(k) plan
</p>
</li>
<li><p> age: age
</p>
</li>
<li><p> inc: income
</p>
</li>
<li><p> fsize: family size
</p>
</li>
<li><p> educ: years of education
</p>
</li>
<li><p> db: = 1 if individual has defined benefit pension
</p>
</li>
<li><p> marr: = 1 if married
</p>
</li>
<li><p> twoearn: = 1 if two-earner household
</p>
</li>
<li><p> pira: = 1 if individual participates in IRA plan
</p>
</li>
<li><p> hown: = 1 if home owner
</p>
</li></ul>

<p>The supplementary data of the study by Chernozhukov et al. (2018) is
available at
<a href="https://academic.oup.com/ectj/article/21/1/C1/5056401#supplementary-data">https://academic.oup.com/ectj/article/21/1/C1/5056401#supplementary-data</a>.
</p>


<h3>Value</h3>

<p>A data object according to the choice of <code>return_type</code>.
</p>


<h3>References</h3>

<p>Abadie, A. (2003), Semiparametric instrumental variable
estimation of treatment response models.
Journal of Econometrics, 113(2): 231-263.
</p>
<p>Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E.,
Hansen, C., Newey, W. and Robins, J. (2018), Double/debiased machine learning
for treatment and structural parameters.
The Econometrics Journal, 21: C1-C68. <a href="https://doi.org/10.1111/ectj.12097">doi:10.1111/ectj.12097</a>.
</p>

<hr>
<h2 id='fetch_bonus'>Data set on the Pennsylvania Reemployment Bonus experiment.</h2><span id='topic+fetch_bonus'></span>

<h3>Description</h3>

<p>Preprocessed data set on the Pennsylvania Reemploymnent Bonus experiment.
The raw data files are preprocessed to reproduce the examples in
Chernozhukov et al. (2020).
An internet connection is required to sucessfully download the data set.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>fetch_bonus(return_type = "DoubleMLData", polynomial_features = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="fetch_bonus_+3A_return_type">return_type</code></td>
<td>
<p>(<code>character(1)</code>) <br />
If <code>"DoubleMLData"</code>, returns a <code>DoubleMLData</code> object.
If <code>"data.frame"</code> returns a <code>data.frame()</code>.
If <code>"data.table"</code> returns a <code>data.table()</code>. Default is <code>"DoubleMLData"</code>.</p>
</td></tr>
<tr><td><code id="fetch_bonus_+3A_polynomial_features">polynomial_features</code></td>
<td>
<p>(<code>logical(1)</code>) <br />
If <code>TRUE</code> polynomial freatures are added (see replication file of
Chernozhukov et al. (2018)).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Variable description, based on the supplementary material of
Chernozhukov et al. (2020):
</p>

<ul>
<li><p> abdt:  chronological time of enrollment of each claimant in the
Pennsylvania reemployment bonus experiment.
</p>
</li>
<li><p> tg:  indicates the treatment group (bonus amount - qualification period)
of each claimant.
</p>
</li>
<li><p> inuidur1:  a measure of length (in weeks) of the first spell of
unemployment
</p>
</li>
<li><p> inuidur2:  a second measure for the length (in weeks) of
</p>
</li>
<li><p> female:  dummy variable; it indicates if the claimant's sex is
female (=1) or male (=0).
</p>
</li>
<li><p> black: dummy variable; it indicates a person of black race (=1).
</p>
</li>
<li><p> hispanic:  dummy variable; it indicates a person of hispanic race (=1).
</p>
</li>
<li><p> othrace: dummy variable; it indicates a non-white, non-black,
not-hispanic person (=1).
</p>
</li>
<li><p> dep1: dummy variable; indicates if the number of dependents of each
claimant is equal to 1 (=1).
</p>
</li>
<li><p> dep2: dummy variable; indicates if the number of dependents of each
claimant is equal to 2 (=1).
</p>
</li>
<li><p> q1-q6: six dummy variables indicating the quarter of experiment during
which each claimant enrolled.
</p>
</li>
<li><p> recall:  takes the value of 1 if the claimant answered &ldquo;yes&rdquo; when was
asked if he/she had any expectation to be recalled
</p>
</li>
<li><p> agelt35: takes the value of 1 if the claimant's age is less than 35
and 0 otherwise.
</p>
</li>
<li><p> agegt54: takes the value of 1 if the claimant's age is more than 54
and 0 otherwise.
</p>
</li>
<li><p> durable: it takes the value of 1 if the occupation of the claimant was in
the sector of durable manufacturing and 0 otherwise.
</p>
</li>
<li><p> nondurable:  it takes the value of 1 if the occupation of the claimant was
in the sector of nondurable manufacturing and 0 otherwise.
</p>
</li>
<li><p> lusd:  it takes the value of 1 if the claimant filed in Coatesville,
Reading, or Lancaster and 0 otherwise.
</p>
</li>
<li><p> These three sites were considered to be located in areas characterized by
low unemployment rate and short duration of unemployment.
</p>
</li>
<li><p> husd:  it takes the value of 1 if the claimant filed in Lewistown,
Pittston, or Scranton and 0 otherwise.
</p>
</li>
<li><p> These three sites were considered to be located in areas characterized by
high unemployment rate and short duration of unemployment.
</p>
</li>
<li><p> muld:  it takes the value of 1 if the claimant filed in Philadelphia-North,
Philadelphia-Uptown, McKeesport, Erie, or Butler and 0 otherwise.
</p>
</li>
<li><p> These three sites were considered to be located in areas characterized by
moderate unemployment rate and long duration of unemployment.&quot;
</p>
</li></ul>

<p>The supplementary data of the study by Chernozhukov et al. (2018) is
available at <a href="https://academic.oup.com/ectj/article/21/1/C1/5056401#supplementary-data">https://academic.oup.com/ectj/article/21/1/C1/5056401#supplementary-data</a>.
</p>
<p>The supplementary data of the study by Bilias (2000) is available at
<a href="https://www.journaldata.zbw.eu/dataset/sequential-testing-of-duration-data-the-case-of-the-pennsylvania-reemployment-bonus-experiment">https://www.journaldata.zbw.eu/dataset/sequential-testing-of-duration-data-the-case-of-the-pennsylvania-reemployment-bonus-experiment</a>.
</p>


<h3>Value</h3>

<p>A data object according to the choice of <code>return_type</code>.
</p>


<h3>References</h3>

<p>Bilias Y. (2000), Sequential Testing of Duration Data:
The Case of Pennsylvania ‘Reemployment Bonus’ Experiment. Journal of Applied
Econometrics, 15(6): 575-594.
</p>
<p>Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E.,
Hansen, C., Newey, W. and Robins, J. (2018), Double/debiased machine learning
for treatment and structural parameters.
The Econometrics Journal, 21: C1-C68. <a href="https://doi.org/10.1111/ectj.12097">doi:10.1111/ectj.12097</a>.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>library(DoubleML)
df_bonus = fetch_bonus(return_type = "data.table")
obj_dml_data_bonus = DoubleMLData$new(df_bonus,
  y_col = "inuidur1",
  d_cols = "tg",
  x_cols = c(
    "female", "black", "othrace", "dep1", "dep2",
    "q2", "q3", "q4", "q5", "q6", "agelt35", "agegt54",
    "durable", "lusd", "husd"
  )
)
obj_dml_data_bonus
</code></pre>

<hr>
<h2 id='make_iivm_data'>Generates data from a interactive IV regression (IIVM) model.</h2><span id='topic+make_iivm_data'></span>

<h3>Description</h3>

<p>Generates data from a interactive IV regression (IIVM) model.
The data generating process is defined as
</p>
<p><code class="reqn">d_i = 1\left\lbrace \alpha_x Z + v_i &gt; 0 \right\rbrace,</code>
</p>
<p><code class="reqn">y_i = \theta d_i + x_i' \beta + u_i,</code>
</p>
<p><code class="reqn">Z \sim \textstyle{Bernoulli} (0.5)</code> and
</p>
<p><code class="reqn">\left(\begin{array}{c} u_i \\ v_i \end{array} \right) \sim
\mathcal{N}\left(0, \left(\begin{array}{cc} 1 &amp; 0.3 \\ 0.3 &amp; 1
\end{array} \right) \right).</code>
</p>
<p>The covariates :<code class="reqn">x_i \sim \mathcal{N}(0, \Sigma)</code>, where  <code class="reqn">\Sigma</code>
is a matrix with entries
<code class="reqn">\Sigma_{kj} = 0.5^{|j-k|}</code> and <code class="reqn">\beta</code> is a <code>dim_x</code>-vector with
entries <code class="reqn">\beta_j=\frac{1}{j^2}</code>.
</p>
<p>The data generating process is inspired by a process used in the
simulation experiment of Farbmacher, Gruber and Klaaßen (2020).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_iivm_data(
  n_obs = 500,
  dim_x = 20,
  theta = 1,
  alpha_x = 0.2,
  return_type = "DoubleMLData"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_iivm_data_+3A_n_obs">n_obs</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of observations to simulate.</p>
</td></tr>
<tr><td><code id="make_iivm_data_+3A_dim_x">dim_x</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of covariates.</p>
</td></tr>
<tr><td><code id="make_iivm_data_+3A_theta">theta</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the causal parameter.</p>
</td></tr>
<tr><td><code id="make_iivm_data_+3A_alpha_x">alpha_x</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the parameter <code class="reqn">\alpha_x</code>.</p>
</td></tr>
<tr><td><code id="make_iivm_data_+3A_return_type">return_type</code></td>
<td>
<p>(<code>character(1)</code>) <br />
If <code>"DoubleMLData"</code>, returns a <code>DoubleMLData</code> object.
If <code>"data.frame"</code> returns a <code>data.frame()</code>.
If <code>"data.table"</code> returns a <code>data.table()</code>.
If <code>"matrix"</code> a named <code>list()</code> with entries <code>X</code>, <code>y</code>, <code>d</code> and <code>z</code>
is returned.
Every entry in the list is a <code>matrix()</code> object.  Default is <code>"DoubleMLData"</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Farbmacher, H., Guber, R. and Klaaßen, S. (2020).
Instrument Validity Tests with Causal Forests.
MEA Discussion Paper No. 13-2020.
Available at SSRN:<a href="https://doi.org/10.2139/ssrn.3619201">doi:10.2139/ssrn.3619201</a>.
</p>

<hr>
<h2 id='make_irm_data'>Generates data from a interactive regression (IRM) model.</h2><span id='topic+make_irm_data'></span>

<h3>Description</h3>

<p>Generates data from a interactive regression (IRM) model.
The data generating process is defined as
</p>
<p><code class="reqn">d_i = 1\left\lbrace \frac{\exp(c_d x_i' \beta)}{1+\exp(c_d x_i' \beta)}
&gt; v_i \right\rbrace,</code>
</p>
<p><code class="reqn"> y_i = \theta d_i + c_y x_i' \beta d_i + \zeta_i,</code>
</p>
<p>with <code class="reqn">v_i \sim \mathcal{U}(0,1)</code>, <code class="reqn">\zeta_i \sim \mathcal{N}(0,1)</code>
and covariates <code class="reqn">x_i \sim \mathcal{N}(0, \Sigma)</code>, where <code class="reqn">\Sigma</code>
is a matrix with entries <code class="reqn">\Sigma_{kj} = 0.5^{|j-k|}</code>.
<code class="reqn">\beta</code> is a <code>dim_x</code>-vector with entries <code class="reqn">\beta_j = \frac{1}{j^2}</code>
and the constancts <code class="reqn">c_y</code> and <code class="reqn">c_d</code> are given by
</p>
<p><code class="reqn"> c_y = \sqrt{\frac{R_y^2}{(1-R_y^2) \beta' \Sigma \beta}},</code>
</p>
<p><code class="reqn">c_d = \sqrt{\frac{(\pi^2 /3) R_d^2}{(1-R_d^2) \beta' \Sigma \beta}}.</code>
</p>
<p>The data generating process is inspired by a process used in the simulation
experiment (see Appendix P) of Belloni et al. (2017).
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_irm_data(
  n_obs = 500,
  dim_x = 20,
  theta = 0,
  R2_d = 0.5,
  R2_y = 0.5,
  return_type = "DoubleMLData"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_irm_data_+3A_n_obs">n_obs</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of observations to simulate.</p>
</td></tr>
<tr><td><code id="make_irm_data_+3A_dim_x">dim_x</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of covariates.</p>
</td></tr>
<tr><td><code id="make_irm_data_+3A_theta">theta</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the causal parameter.</p>
</td></tr>
<tr><td><code id="make_irm_data_+3A_r2_d">R2_d</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the parameter <code class="reqn">R_d^2</code>.</p>
</td></tr>
<tr><td><code id="make_irm_data_+3A_r2_y">R2_y</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the parameter <code class="reqn">R_y^2</code>.</p>
</td></tr>
<tr><td><code id="make_irm_data_+3A_return_type">return_type</code></td>
<td>
<p>(<code>character(1)</code>) <br />
If <code>"DoubleMLData"</code>, returns a <code>DoubleMLData</code> object.
If <code>"data.frame"</code> returns a <code>data.frame()</code>.
If <code>"data.table"</code> returns a <code>data.table()</code>.
If <code>"matrix"</code> a named <code>list()</code> with entries <code>X</code>, <code>y</code>, <code>d</code> and <code>z</code>
is returned.
Every entry in the list is a <code>matrix()</code> object.  Default is <code>"DoubleMLData"</code>.</p>
</td></tr>
</table>


<h3>References</h3>

<p>Belloni, A., Chernozhukov, V., Fernández-Val, I. and
Hansen, C. (2017). Program Evaluation and Causal Inference With
High-Dimensional Data. Econometrica, 85: 233-298.
</p>

<hr>
<h2 id='make_pliv_CHS2015'>Generates data from a partially linear IV regression model used in
Chernozhukov, Hansen and Spindler (2015).</h2><span id='topic+make_pliv_CHS2015'></span>

<h3>Description</h3>

<p>Generates data from a partially linear IV regression model used in
Chernozhukov, Hansen and Spindler (2015). The data generating process
is defined as
</p>
<p><code class="reqn">z_i = \Pi x_i + \zeta_i,</code>
</p>
<p><code class="reqn">d_i = x_i'\gamma + z_i'\delta + u_i,</code>
</p>
<p><code class="reqn">y_i = \alpha d_i + x_i'\beta + \epsilon_i,</code>
</p>
<p>with
</p>
<p><code class="reqn">\left(\begin{array}{c} \varepsilon_i \\ u_i \\ \zeta_i \\ x_i
\end{array} \right)
\sim \mathcal{N}\left(0,
\left(\begin{array}{cccc} 1 &amp; 0.6 &amp; 0 &amp; 0 \\ 0.6 &amp; 1 &amp; 0 &amp; 0
\\ 0 &amp; 0 &amp; 0.25 I_{p_n^z} &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; \Sigma \end{array}
\right) \right)</code>
</p>
<p>where <code class="reqn">\Sigma</code> is a <code class="reqn">p_n^x \times p_n^x</code> matrix with entries
<code class="reqn">\Sigma_{kj} = 0.5^{|j-k|}</code> and
<code class="reqn">I_{p_n^z}</code> is the <code class="reqn">p^z_n \times p^z_n</code>
identity matrix. <code class="reqn">\beta=\gamma</code> iis a <code class="reqn">p^x_n</code>-vector with entries
<code class="reqn">\beta_j = \frac{1}{j^2}</code>, <code class="reqn">\delta</code> is a <code class="reqn">p^z_n</code>-vector with
entries <code class="reqn">\delta_j = \frac{1}{j^2}</code> and
<code class="reqn">\Pi = (I_{p_n^z}, O_{p_n^z \times (p_n^x - p_n^z)})</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_pliv_CHS2015(
  n_obs,
  alpha = 1,
  dim_x = 200,
  dim_z = 150,
  return_type = "DoubleMLData"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_pliv_CHS2015_+3A_n_obs">n_obs</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of observations to simulate.</p>
</td></tr>
<tr><td><code id="make_pliv_CHS2015_+3A_alpha">alpha</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the causal parameter.</p>
</td></tr>
<tr><td><code id="make_pliv_CHS2015_+3A_dim_x">dim_x</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of covariates.</p>
</td></tr>
<tr><td><code id="make_pliv_CHS2015_+3A_dim_z">dim_z</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of instruments.</p>
</td></tr>
<tr><td><code id="make_pliv_CHS2015_+3A_return_type">return_type</code></td>
<td>
<p>(<code>character(1)</code>) <br />
If <code>"DoubleMLData"</code>, returns a <code>DoubleMLData</code> object.
If <code>"data.frame"</code> returns a <code>data.frame()</code>.
If <code>"data.table"</code> returns a <code>data.table()</code>.
If <code>"matrix"</code> a named <code>list()</code> with entries <code>X</code>, <code>y</code>, <code>d</code> and
<code>z</code> is returned.
Every entry in the list is a <code>matrix()</code> object.  Default is <code>"DoubleMLData"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data object according to the choice of <code>return_type</code>.
</p>


<h3>References</h3>

<p>Chernozhukov, V., Hansen, C. and Spindler, M. (2015),
Post-Selection and Post-Regularization Inference in Linear Models with
Many Controls and Instruments.
American Economic Review: Papers and Proceedings, 105 (5): 486-90.
</p>

<hr>
<h2 id='make_pliv_multiway_cluster_CKMS2021'>Generates data from a partially linear IV regression model with
multiway cluster sample used in Chiang et al. (2021).</h2><span id='topic+make_pliv_multiway_cluster_CKMS2021'></span>

<h3>Description</h3>

<p>Generates data from a partially linear IV regression model with multiway
cluster sample used in Chiang et al. (2021). The data generating process
is defined as
</p>
<p><code class="reqn">Z_{ij} = X_{ij}' \xi_0 + V_{ij},</code>
</p>
<p><code class="reqn">D_{ij} = Z_{ij}' \pi_{10} + X_{ij}' \pi_{20} + v_{ij},</code>
</p>
<p><code class="reqn">Y_{ij} = D_{ij} \theta + X_{ij}' \zeta_0 + \varepsilon_{ij},</code>
</p>
<p>with
</p>
<p><code class="reqn">X_{ij} = (1 - \omega_1^X - \omega_2^X) \alpha_{ij}^X
+ \omega_1^X \alpha_{i}^X + \omega_2^X \alpha_{j}^X,</code>
</p>
<p><code class="reqn">\varepsilon_{ij} = (1 - \omega_1^\varepsilon - \omega_2^\varepsilon) \alpha_{ij}^\varepsilon
+ \omega_1^\varepsilon \alpha_{i}^\varepsilon + \omega_2^\varepsilon \alpha_{j}^\varepsilon,</code>
</p>
<p><code class="reqn">v_{ij} = (1 - \omega_1^v - \omega_2^v) \alpha_{ij}^v
+ \omega_1^v \alpha_{i}^v + \omega_2^v \alpha_{j}^v,</code>
</p>
<p><code class="reqn">V_{ij} = (1 - \omega_1^V - \omega_2^V) \alpha_{ij}^V
+ \omega_1^V \alpha_{i}^V + \omega_2^V \alpha_{j}^V,</code>
</p>
<p>and <code class="reqn">\alpha_{ij}^X, \alpha_{i}^X, \alpha_{j}^X \sim \mathcal{N}(0, \Sigma)</code>
where <code class="reqn">\Sigma</code> is a <code class="reqn">p_x \times p_x</code> matrix with entries
<code class="reqn">\Sigma_{kj} = s_X^{|j-k|}</code>.
</p>
<p>Further
</p>
<p><code class="reqn">\left(\begin{array}{c} \alpha_{ij}^\varepsilon \\ \alpha_{ij}^v \end{array}\right),
\left(\begin{array}{c} \alpha_{i}^\varepsilon \\ \alpha_{i}^v \end{array}\right),
\left(\begin{array}{c} \alpha_{j}^\varepsilon \\ \alpha_{j}^v \end{array}\right)
\sim \mathcal{N}\left(0, \left(\begin{array}{cc} 1 &amp; s_{\varepsilon v} \\
s_{\varepsilon v} &amp; 1 \end{array}\right) \right)</code>
</p>
<p>and <code class="reqn">\alpha_{ij}^V, \alpha_{i}^V, \alpha_{j}^V \sim \mathcal{N}(0, 1)</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_pliv_multiway_cluster_CKMS2021(
  N = 25,
  M = 25,
  dim_X = 100,
  theta = 1,
  return_type = "DoubleMLClusterData",
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_pliv_multiway_cluster_CKMS2021_+3A_n">N</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of observations (first dimension).</p>
</td></tr>
<tr><td><code id="make_pliv_multiway_cluster_CKMS2021_+3A_m">M</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of observations (second dimension).</p>
</td></tr>
<tr><td><code id="make_pliv_multiway_cluster_CKMS2021_+3A_dim_x">dim_X</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of covariates.</p>
</td></tr>
<tr><td><code id="make_pliv_multiway_cluster_CKMS2021_+3A_theta">theta</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the causal parameter.</p>
</td></tr>
<tr><td><code id="make_pliv_multiway_cluster_CKMS2021_+3A_return_type">return_type</code></td>
<td>
<p>(<code>character(1)</code>) <br />
If <code>"DoubleMLClusterData"</code>, returns a <code>DoubleMLClusterData</code> object.
If <code>"data.frame"</code> returns a <code>data.frame()</code>.
If <code>"data.table"</code> returns a <code>data.table()</code>.
If <code>"matrix"</code> a named <code>list()</code> with entries <code>X</code>, <code>y</code>, <code>d</code>, <code>z</code> and
<code>cluster_vars</code> is returned.
Every entry in the list is a <code>matrix()</code> object.  Default is <code>"DoubleMLClusterData"</code>.</p>
</td></tr>
<tr><td><code id="make_pliv_multiway_cluster_CKMS2021_+3A_...">...</code></td>
<td>
<p>Additional keyword arguments to set non-default values for the parameters
<code class="reqn">\pi_{10}=1.0</code>,
<code class="reqn">\omega_X = \omega_{\varepsilon} = \omega_V = \omega_v = (0.25, 0.25)</code>,
<code class="reqn">s_X = s_{\varepsilon v} = 0.25</code>, or the <code class="reqn">p_x</code>-vectors
<code class="reqn">\zeta_0 = \pi_{20} = \xi_0</code> with default entries
<code class="reqn">\zeta_{0})_j = 0.5^j</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data object according to the choice of <code>return_type</code>.
</p>


<h3>References</h3>

<p>Chiang, H. D., Kato K., Ma, Y. and Sasaki, Y. (2021),
Multiway Cluster Robust Double/Debiased Machine Learning,
Journal of Business &amp; Economic Statistics,
<a href="https://doi.org/10.1080/07350015.2021.1895815">doi:10.1080/07350015.2021.1895815</a>, https://arxiv.org/abs/1909.03489.
</p>

<hr>
<h2 id='make_plr_CCDDHNR2018'>Generates data from a partially linear regression model used in
Chernozhukov et al. (2018)</h2><span id='topic+make_plr_CCDDHNR2018'></span>

<h3>Description</h3>

<p>Generates data from a partially linear regression model used in
Chernozhukov et al. (2018) for Figure 1.
The data generating process is defined as
</p>
<p><code class="reqn">d_i = m_0(x_i) + s_1 v_i,</code>
</p>
<p><code class="reqn">y_i = \alpha d_i + g_0(x_i) + s_2 \zeta_i,</code>
</p>
<p>with <code class="reqn">v_i \sim \mathcal{N}(0,1)</code> and
<code class="reqn">\zeta_i \sim \mathcal{N}(0,1),</code>.
The covariates are distributed as <code class="reqn">x_i \sim \mathcal{N}(0, \Sigma)</code>,
where  <code class="reqn">\Sigma</code> is a matrix with entries <code class="reqn">\Sigma_{kj} = 0.7^{|j-k|}</code>.
The nuisance functions are given by
</p>
<p><code class="reqn">m_0(x_i) = a_0 x_{i,1} + a_1 \frac{\exp(x_{i,3})}{1+\exp(x_{i,3})},</code>
</p>
<p><code class="reqn">g_0(x_i) = b_0 \frac{\exp(x_{i,1})}{1+\exp(x_{i,1})} + b_1 x_{i,3},</code>
</p>
<p>with <code class="reqn">a_0=1</code>, <code class="reqn">a_1=0.25</code>, <code class="reqn">s_1=1</code>, <code class="reqn">b_0=1</code>, <code class="reqn">b_1=0.25</code>,
<code class="reqn">s_2=1</code>.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_plr_CCDDHNR2018(
  n_obs = 500,
  dim_x = 20,
  alpha = 0.5,
  return_type = "DoubleMLData"
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_plr_CCDDHNR2018_+3A_n_obs">n_obs</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of observations to simulate.</p>
</td></tr>
<tr><td><code id="make_plr_CCDDHNR2018_+3A_dim_x">dim_x</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of covariates.</p>
</td></tr>
<tr><td><code id="make_plr_CCDDHNR2018_+3A_alpha">alpha</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the causal parameter.</p>
</td></tr>
<tr><td><code id="make_plr_CCDDHNR2018_+3A_return_type">return_type</code></td>
<td>
<p>(<code>character(1)</code>) <br />
If <code>"DoubleMLData"</code>, returns a <code>DoubleMLData</code> object.
If <code>"data.frame"</code> returns a <code>data.frame()</code>.
If <code>"data.table"</code> returns a <code>data.table()</code>.
If <code>"matrix"</code> a named <code>list()</code> with entries <code>X</code>, <code>y</code> and <code>d</code> is returned.
Every entry in the list is a <code>matrix()</code> object.  Default is <code>"DoubleMLData"</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data object according to the choice of <code>return_type</code>.
</p>


<h3>References</h3>

<p>Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E.,
Hansen, C., Newey, W. and Robins, J. (2018), Double/debiased machine learning
for treatment and structural parameters.
The Econometrics Journal, 21: C1-C68. <a href="https://doi.org/10.1111/ectj.12097">doi:10.1111/ectj.12097</a>.
</p>

<hr>
<h2 id='make_plr_turrell2018'>Generates data from a partially linear regression model used in a blog
article by Turrell (2018).</h2><span id='topic+make_plr_turrell2018'></span>

<h3>Description</h3>

<p>Generates data from a partially linear regression model used in a blog
article by Turrell (2018). The data generating process is defined as
</p>
<p><code class="reqn">d_i = m_0(x_i' b) + v_i,</code>
</p>
<p><code class="reqn">y_i = \theta d_i + g_0(x_i' b) + u_i,</code>
</p>
<p>with <code class="reqn">v_i \sim \mathcal{N}(0,1)</code>, <code class="reqn">u_i \sim \mathcal{N}(0,1)</code>, and
covariates <code class="reqn">x_i \sim \mathcal{N}(0, \Sigma)</code>, where  <code class="reqn">\Sigma</code>
is a random symmetric, positive-definite matrix generated with
<code><a href="clusterGeneration.html#topic+genPositiveDefMat">clusterGeneration::genPositiveDefMat()</a></code>. <code class="reqn">b</code> is a vector with entries
<code class="reqn">b_j=\frac{1}{j}</code> and the nuisance functions are given by
</p>
<p><code class="reqn">m_0(x_i) = \frac{1}{2 \pi}
\frac{\sinh(\gamma)}{\cosh(\gamma) - \cos(x_i-\nu)},</code>
</p>
<p><code class="reqn">g_0(x_i) = \sin(x_i)^2.</code>
</p>


<h3>Usage</h3>

<pre><code class='language-R'>make_plr_turrell2018(
  n_obs = 100,
  dim_x = 20,
  theta = 0.5,
  return_type = "DoubleMLData",
  nu = 0,
  gamma = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr><td><code id="make_plr_turrell2018_+3A_n_obs">n_obs</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of observations to simulate.</p>
</td></tr>
<tr><td><code id="make_plr_turrell2018_+3A_dim_x">dim_x</code></td>
<td>
<p>(<code>integer(1)</code>) <br />
The number of covariates.</p>
</td></tr>
<tr><td><code id="make_plr_turrell2018_+3A_theta">theta</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the causal parameter.</p>
</td></tr>
<tr><td><code id="make_plr_turrell2018_+3A_return_type">return_type</code></td>
<td>
<p>(<code>character(1)</code>) <br />
If <code>"DoubleMLData"</code>, returns a <code>DoubleMLData</code> object.
If <code>"data.frame"</code> returns a <code>data.frame()</code>.
If <code>"data.table"</code> returns a <code>data.table()</code>.
If <code>"matrix"</code> a named <code>list()</code> with entries <code>X</code>, <code>y</code> and <code>d</code> is returned.
Every entry in the list is a <code>matrix()</code> object.  Default is <code>"DoubleMLData"</code>.</p>
</td></tr>
<tr><td><code id="make_plr_turrell2018_+3A_nu">nu</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the parameter <code class="reqn">\nu</code>. Default is <code>0</code>.</p>
</td></tr>
<tr><td><code id="make_plr_turrell2018_+3A_gamma">gamma</code></td>
<td>
<p>(<code>numeric(1)</code>) <br />
The value of the parameter <code class="reqn">\gamma</code>. Default is <code>1</code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>A data object according to the choice of <code>return_type</code>.
</p>


<h3>References</h3>

<p>Turrell, A. (2018), Econometrics in Python part I - Double
machine learning, Markov Wanderer: A blog on economics, science, coding and
data.
<a href="https://aeturrell.com/blog/posts/econometrics-in-python-parti-ml/">https://aeturrell.com/blog/posts/econometrics-in-python-parti-ml/</a>.
</p>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
