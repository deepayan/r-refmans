<!DOCTYPE html><html lang="en"><head><title>Help for package IFTPredictor</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R-nav.css" />
</head><body><div class="container"><nav class="package" aria-label="Topic Navigation">
<div class="dropdown-menu">
<h1>Package {IFTPredictor}</h1>
<h2>Contents</h2>
<ul class="menu">
<li><a href='#mydata'><p>Example Dataset for DIFtree</p></a></li>
<li><a href='#predict_item_responses'><p>Predictions Using Item-Focused Tree Models</p></a></li>
</ul>
</div>
<hr>
</nav>
<main>
<table role='presentation'>
<tr>
<td>Type:</td>
<td>Package</td>
</tr>
<tr>
<td>Title:</td>
<td>Predictions Using Item-Focused Tree Models</td>
</tr>
<tr>
<td>Version:</td>
<td>0.1.0</td>
</tr>
<tr>
<td>Author:</td>
<td>Muditha L. Bodawatte Gedara [aut, cre],
  Barret A. Monchka [aut],
  Lisa M. Lix [aut]</td>
</tr>
<tr>
<td>Maintainer:</td>
<td>Muditha L. Bodawatte Gedara &lt;muditha.lakmali.1993@gmail.com&gt;</td>
</tr>
<tr>
<td>Description:</td>
<td>This function predicts item response probabilities and item 
  responses using the item-focused tree model. The item-focused tree model
  combines logistic regression with recursive partitioning to detect 
  Differential Item Functioning in dichotomous items. The model applies 
  partitioning rules to the data, splitting it into homogeneous subgroups, and 
  uses logistic regression within each subgroup to explain the data. 
  Differential Item Functioning detection is achieved by examining potential 
  group differences in item response patterns. This method is useful for 
  understanding how different predictors, such as demographic or psychological 
  factors, influence item responses across subgroups.</td>
</tr>
<tr>
<td>License:</td>
<td><a href="https://opensource.org/licenses/mit-license.php">MIT</a> + file LICENSE</td>
</tr>
<tr>
<td>Encoding:</td>
<td>UTF-8</td>
</tr>
<tr>
<td>LazyData:</td>
<td>true</td>
</tr>
<tr>
<td>Imports:</td>
<td>DIFtree</td>
</tr>
<tr>
<td>Suggests:</td>
<td>devtools, testthat (&ge; 3.0.0)</td>
</tr>
<tr>
<td>RoxygenNote:</td>
<td>7.3.2</td>
</tr>
<tr>
<td>Config/testthat/edition:</td>
<td>3</td>
</tr>
<tr>
<td>NeedsCompilation:</td>
<td>no</td>
</tr>
<tr>
<td>Packaged:</td>
<td>2025-02-13 04:19:09 UTC; mudithalakmali</td>
</tr>
<tr>
<td>Repository:</td>
<td>CRAN</td>
</tr>
<tr>
<td>Date/Publication:</td>
<td>2025-02-13 11:30:28 UTC</td>
</tr>
</table>
<hr>
<h2 id='mydata'>Example Dataset for DIFtree</h2><span id='topic+mydata'></span>

<h3>Description</h3>

<p>A dataset used for demonstrating the IFTPredictor package. This dataset includes response data (columns 1-20)
and covariate data (columns 21-24)
</p>


<h3>Usage</h3>

<pre><code class='language-R'>mydata
</code></pre>


<h3>Format</h3>

<p>A data frame with 500 rows and 24 variables:
</p>

<dl>
<dt>V1</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 1.</p>
</dd>
<dt>V2</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 2.</p>
</dd>
<dt>V3</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 3.</p>
</dd>
<dt>V4</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 4.</p>
</dd>
<dt>V5</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 5.</p>
</dd>
<dt>V6</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 6.</p>
</dd>
<dt>V7</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 7.</p>
</dd>
<dt>V8</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 8.</p>
</dd>
<dt>V9</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 9.</p>
</dd>
<dt>V10</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 10.</p>
</dd>
<dt>V11</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 11.</p>
</dd>
<dt>V12</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 12.</p>
</dd>
<dt>V13</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 13.</p>
</dd>
<dt>V14</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 14.</p>
</dd>
<dt>V15</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 15.</p>
</dd>
<dt>V16</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 16.</p>
</dd>
<dt>V17</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 17.</p>
</dd>
<dt>V18</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 18.</p>
</dd>
<dt>V19</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 19.</p>
</dd>
<dt>V20</dt><dd><p>Binary response variable (numeric: 0 or 1) representing item 20.</p>
</dd>
<dt>x1</dt><dd><p>An integer variable (e.g., a grouping factor or categorical covariate).</p>
</dd>
<dt>x2</dt><dd><p>A continuous numeric covariate.</p>
</dd>
<dt>x3</dt><dd><p>An integer variable (binary: 0 or 1).</p>
</dd>
<dt>x4</dt><dd><p>A continuous numeric covariate.</p>
</dd>
</dl>



<h3>Examples</h3>

<pre><code class='language-R'>data("mydata", package = "IFTPredictor")
head(mydata)
</code></pre>

<hr>
<h2 id='predict_item_responses'>Predictions Using Item-Focused Tree Models</h2><span id='topic+predict_item_responses'></span>

<h3>Description</h3>

<p>This function predicts item response probabilities and item responses using the item-focused tree (IFT) model.
The item-focused tree model combines logistic regression with recursive partitioning to detect Differential Item Functioning (DIF)
in dichotomous items. The model applies partitioning rules to the data, splitting it into homogeneous subgroups,
and uses logistic regression within each subgroup to explain the data. Differential Item Functioning detection is achieved by examining
potential group differences in item response patterns. This model produces tree diagrams to visualize homogeneous
subgroups within the population exhibiting similar response patterns and may therefore be helpful for developing personalized interventions and optimizing resource allocation in healthcare.
</p>


<h3>Usage</h3>

<pre><code class='language-R'>predict_item_responses(model, dataset, total_score)
</code></pre>


<h3>Arguments</h3>

<table role = "presentation">
<tr><td><code id="predict_item_responses_+3A_model">model</code></td>
<td>
<p>A DIFtree model object.</p>
</td></tr>
<tr><td><code id="predict_item_responses_+3A_dataset">dataset</code></td>
<td>
<p>A data frame containing the required data. The 'total_score' column must be included.</p>
</td></tr>
<tr><td><code id="predict_item_responses_+3A_total_score">total_score</code></td>
<td>
<p>The name of the column in the dataset representing the total score (e.g., &quot;total_score&quot;).</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The logistic regression model for the <code class="reqn">i</code>-th PROM item is defined as:
</p>
<p style="text-align: center;"><code class="reqn">
\log \left( \frac{P(Y_{pi} = 1 \mid S_{p}, g)}{P(Y_{pi} = 0 \mid S_{p}, g)} \right) = \eta_{pi} = \beta_{0i} + S_{p} \beta_{i} + \gamma_{ig},
</code>
</p>

<p>where,
<code class="reqn">Y_{pi} \in \{0, 1\}</code>: The response of person <code class="reqn">p</code> to the <code class="reqn">i</code>-th item.
<code class="reqn">p = 1, 2, \dots, P</code>: The number of persons.
<code class="reqn">i = 1, 2, \dots, I</code>: The number of items.
<code class="reqn">g</code>: Group membership (<code class="reqn">g = 0</code> for the reference group, <code class="reqn">g = 1</code> for the focal group).
<code class="reqn">S_p</code>: The ability level (e.g., total PROM score) of person <code class="reqn">p</code>.
<code class="reqn">\beta_{0i}</code>: The intercept or item difficulty parameter.
<code class="reqn">\beta_{i}</code>: The slope or item discrimination parameter.
<code class="reqn">\gamma_{ig}</code>: The group-specific parameter.
</p>
<p>The IFT model extends this logistic regression model for DIF detection for the <code class="reqn">i</code>-th PROM item:
</p>
<p style="text-align: center;"><code class="reqn">
\eta_{pi} = \beta_i S_p + \left[ \gamma_{ik} I(x_{pl} \leq c_l) + \gamma_{ir} I(x_{pl} &gt; c_l) \right],
</code>
</p>

<p>where,
<code class="reqn">l = 1, \dots, L</code>: The number of partitions.
<code class="reqn">c_l</code>: The threshold for the <code class="reqn">l</code>-th variable.
<code class="reqn">x_{pl} \leq c_l</code> and <code class="reqn">x_{pl} &gt; c_l</code>: The subgroups defined by tree partitions.
<code class="reqn">I(\cdot)</code>: The indicator function (1 if true, 0 otherwise).
<code class="reqn">\gamma_{ik}</code> and <code class="reqn">\gamma_{ir}</code>: Subgroup-specific intercepts for logistic regression models in partitioned regions.
The terminal or leaf nodes of the tree represent the final groups of patients with similar response patterns.
The IFT model assumes unidimensionality, and the covariates <code class="reqn">x_{pl}</code> can be either continuous or categorical.
</p>
<p>If an item is never chosen for splitting, it is assumed to be free of DIF. The equation for an item free of DIF can be defined as:
</p>
<p style="text-align: center;"><code class="reqn">
\eta_{pi} = \beta_i S_p + \beta_0i,
</code>
</p>



<h3>Value</h3>

<p>A list containing:
</p>
<table role = "presentation">
<tr><td><code>equations</code></td>
<td>
<p>A set of logistic regression equations generated for each item.</p>
</td></tr>
<tr><td><code>predictions</code></td>
<td>
<p>A dataset with predicted probabilities (<code class="reqn">p</code>) and item responses (<code class="reqn">I</code>), where <code class="reqn">I = 1</code> if <code class="reqn">p \geq 0.5</code>, and <code class="reqn">I = 0</code> otherwise.</p>
</td></tr>
</table>


<h3>Author(s)</h3>

<p>Muditha L. Bodawatte Gedara (muditha.lakmali.1993@gmail.com),
Barret A. Monchka,
Lisa M. Lix
</p>


<h3>References</h3>

<p>Berger, Moritz and Tutz, Gerhard (2016): Detection of Uniform and Non-Uniform Differential Item Functioning by Item Focused Trees,
Journal of Educational and Behavioral Statistics 41(6), 559-592.
</p>


<h3>See Also</h3>

<p><code><a href="DIFtree.html#topic+DIFtree">DIFtree</a></code> for training the DIFtree model.
</p>


<h3>Examples</h3>

<pre><code class='language-R'>if (requireNamespace("DIFtree", quietly = TRUE)) {
  # Load DIFtree
  library(DIFtree)

# Load the dataset
data("mydata", package = "IFTPredictor")

# Observe the data
head(mydata)

# Extract response and covariate data
mydata&lt;-mydata[,c(4:6,21:23)] # Items 4 to 6 will be tested for DIF across covariates 21 to 23
Y &lt;- mydata[, 1:3]  # Specify items you want to test for DIF (i.e.,items 1 to 3)
X &lt;- mydata[, 4:6]  # Covariates

# Create total score column calculating total item score for each patient
mydata$total_score &lt;- rowSums(mydata[, 1:3])

# Fit the DIFtree model (Y = response data, X = covariate data)
mod &lt;- DIFtree(Y, X, model = "Logistic", type = "udif", alpha = 0.05, nperm = 5, trace = TRUE)

# Predict item responses using the model and the total score
result &lt;- predict_item_responses(mod, dataset = mydata, total_score = "total_score")

} else {
  message("The 'DIFtree' package is not installed. Please install it to run this example.")
}
</code></pre>

</main>

</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-r.min.js"></script>
</body></html>
